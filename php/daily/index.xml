<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub PHP Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-22T01:42:34Z</updated>
  <subtitle>Daily Trending of PHP in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>chris-koch-penn/gpt3_security_vulnerability_scanner</title>
    <updated>2023-02-22T01:42:34Z</updated>
    <id>tag:github.com,2023-02-22:/chris-koch-penn/gpt3_security_vulnerability_scanner</id>
    <link href="https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GPT-3 found hundreds of security vulnerabilities in this repo&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Experimenting with GPT-3 for Detecting Security Vulnerabilities in Code&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Summary&lt;/strong&gt;: GPT-3 found 213 security vulnerabilities in this &lt;a href=&#34;https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner&#34;&gt;git repository&lt;/a&gt;. In comparison, one of the better commercial tools on the market (from a reputable cybersecurity company) only found 99 issues, although their tool provides context in a more structured format. After manually reviewing a random sample of 50 / 213 of the vulnerabilities detected by GPT-3, only one was a false positive. Both tools had many false negatives. The full text of this README is available as a Medium article &lt;a href=&#34;https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;In recent years, the field of artificial intelligence and machine learning has seen tremendous growth and has opened up a new realm of possibilities. One such field that has been gaining attention is AI-based code analysis, specifically the use of AI models to detect security vulnerabilities in code. In this experiment, we used OpenAI&#39;s GPT-3 to find security vulnerabilities in a &lt;a href=&#34;https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner&#34;&gt;code repository&lt;/a&gt; containing 129 vulnerable files.&lt;/p&gt; &#xA;&lt;h2&gt;How it Works&lt;/h2&gt; &#xA;&lt;p&gt;The variant of GPT-3 I used (text-davinci-003) has a context window of 4000 tokens, which is roughly 3000 english words. This means it can process at most a few hundred lines of code per request. Unfortunately, GPT-3’s current architecture can’t handle a whole repo at once.&lt;/p&gt; &#xA;&lt;p&gt;To get around this, I had to scan all of the files with GPT-3 separately. This means GPT-3 might have trouble finding security vulnerabilities that are the result of multiple files of code interacting, unless the import/exports are clear enough to make a guess as to what those functions do without needing to specifically see the code. This ended up often being the case, particularly when the source code was using common libraries like express.js, Flask, the Python standard library, the C standard library, etc. It’s likely that GPT-3 has many of the most common libraries either partially memorized, fully memorized, or encoded in some other way. In the case of the code analyzed in this article, GPT-3 had enough prior knowledge about the imported libraries that it was able to accurately detect security vulnerabilities without needing to inspect any of the imported library code.&lt;/p&gt; &#xA;&lt;p&gt;To be fair to GPT-3, I suspect that many of the existing commercial vulnerability scanners don’t actually inspect imported library code when doing static analysis — so this is not that different from how some of the tools on the market already work.&lt;/p&gt; &#xA;&lt;h3&gt;The code that was analyzed&lt;/h3&gt; &#xA;&lt;p&gt;Each folder in the repository is named after a type of security vulnerability and contains files with example code containing one or more vulnerabilities. Some of these files contain trivial code, but many are fairly realistic code snippets you might come across in a production code base (note: they are still snippets though, and therefore lack the context of a larger codebase). The README.md file in each folder of the repository contains GPT-3’s analysis of the security vulnerabilities for all of the files in that folder.&lt;/p&gt; &#xA;&lt;p&gt;Let’s take a look at some examples to see how GPT-3 did!&lt;/p&gt; &#xA;&lt;h3&gt;Example 1 (trivial)&lt;/h3&gt; &#xA;&lt;p&gt;Here is a &lt;a href=&#34;https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/raw/main/Format%20String%20Attacks/FormatString.c&#34;&gt;simple C program&lt;/a&gt; that is vulnerable to a Format String Attack:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;&#xA; &#xA;int main(int argc, char **argv) {&#xA;    printf(argv[1]);&#xA; &#xA;    return 0;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And here is GPT-3&#39;s analyis (which is correct):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-md&#34;&gt;Vulnerabilities Detected:&#xA;1. Unvalidated user input: The program does not check the length of the user input, which could lead to a buffer overflow attack.&#xA;2. Format string vulnerability: The program does not check the format of the user input, which could lead to a format string attack.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Example 2 (less trivial)&lt;/h3&gt; &#xA;&lt;p&gt;Let&#39;s try this with a less trivial program in a higher level language, like this &lt;a href=&#34;https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/raw/main/Log%20Forging/logf.cs&#34;&gt;C# program&lt;/a&gt; containing a Log Forging vulnerability. I&#39;ve personally seen similar (although less trivial) code in open-source projects and production code bases:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;using Microsoft.AspNetCore.Http;&#xA;using Microsoft.AspNetCore.Mvc;&#xA;using Microsoft.Extensions.Logging;&#xA;using System;&#xA;using System.Collections.Generic;&#xA;using System.Linq;&#xA;using System.Threading.Tasks;&#xA;&#xA;namespace WebFox.Controllers&#xA;{&#xA;    [Route(&#34;api/[controller]&#34;)]&#xA;    [ApiController]&#xA;    public class LogInjection : ControllerBase&#xA;    {&#xA;        private readonly ILogger&amp;lt;LogInjection&amp;gt; _logger;&#xA;&#xA;&#xA;        public LogInjection(ILogger&amp;lt;LogInjection&amp;gt; logger)&#xA;        {&#xA;            _logger = logger;&#xA;        }&#xA;&#xA;        [HttpGet(&#34;{userInfo}&#34;)]&#xA;        public void injectLog(string userInfo)&#xA;        {&#xA;            _logger.LogError(&#34;error!! &#34; + userInfo);&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;GPT-3&#39;s output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-md&#34;&gt;Vulnerabilities Detected:&#xA;1. Log injection vulnerability: The code is vulnerable to log injection attacks as user input is being directly logged without any sanitization.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;GPT-3&#39;s evaluation is correct - there is a log injection vulnerability in this code.&lt;/p&gt; &#xA;&lt;h3&gt;Example 3 (non-trivial)&lt;/h3&gt; &#xA;&lt;p&gt;The following &lt;a href=&#34;https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/raw/main/Out%20of%20Bounds/vuln.c&#34;&gt;C program&lt;/a&gt; reads and manipulates an image. It contains numerous security vulnerabilities, including Out Of Bounds reads and writes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include&amp;lt;stdio.h&amp;gt;&#xA;#include&amp;lt;stdlib.h&amp;gt;&#xA;#include&amp;lt;string.h&amp;gt;&#xA;&#xA;struct Image&#xA;{&#xA;    char header[4];&#xA;    int width;&#xA;    int height;&#xA;    char data[10];&#xA;};&#xA;&#xA;int ProcessImage(char* filename){&#xA;&#xA;    FILE *fp;&#xA;    char ch;&#xA;    struct Image img;&#xA;&#xA;    fp = fopen(filename,&#34;r&#34;); &#xA;&#xA;    if(fp == NULL)&#xA;    {&#xA;        printf(&#34;\nCan&#39;t open file or file doesn&#39;t exist.&#34;);&#xA;        exit(0);&#xA;    }&#xA;&#xA;    printf(&#34;\n\tHeader\twidth\theight\tdata\t\r\n&#34;);&#xA;&#xA;    while(fread(&amp;amp;img,sizeof(img),1,fp)&amp;gt;0){&#xA;        printf(&#34;\n\t%s\t%d\t%d\t%s\r\n&#34;,img.header,img.width,img.height,img.data);&#xA;    &#xA;        int size1 = img.width + img.height;&#xA;        char* buff1=(char*)malloc(size1);&#xA;&#xA;        memcpy(buff1,img.data,sizeof(img.data));&#xA;        free(buff1);&#xA;    &#xA;        if (size1/2==0){&#xA;            free(buff1);&#xA;        }&#xA;        else{&#xA;            if(size1 == 123456){&#xA;                buff1[0]=&#39;a&#39;;&#xA;            }&#xA;        }&#xA;&#xA;        int size2 = img.width - img.height+100;&#xA;        //printf(&#34;Size1:%d&#34;,size1);&#xA;        char* buff2=(char*)malloc(size2);&#xA;&#xA;        memcpy(buff2,img.data,sizeof(img.data));&#xA;&#xA;        int size3= img.width/img.height;&#xA;        //printf(&#34;Size2:%d&#34;,size3);&#xA;&#xA;        char buff3[10];&#xA;        char* buff4 =(char*)malloc(size3);&#xA;        memcpy(buff4,img.data,sizeof(img.data));&#xA;&#xA;        char OOBR_stack = buff3[size3+100];&#xA;        char OOBR_heap = buff4[100];&#xA;&#xA;        buff3[size3+100]=&#39;c&#39;;&#xA;        buff4[100]=&#39;c&#39;;&#xA;&#xA;        if(size3&amp;gt;10){&#xA;                buff4=0;&#xA;        }&#xA;        else{&#xA;            free(buff4);&#xA;        }&#xA;&#xA;        free(buff2);&#xA;    }&#xA;    fclose(fp);&#xA;}&#xA;&#xA;int main(int argc,char **argv)&#xA;{&#xA;    ProcessImage(argv[1]);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;GPT-3&#39;s output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-md&#34;&gt;Vulnerabilities Detected:&#xA;1. Unchecked return value: The return value of the fopen() function is not checked, which could lead to a null pointer dereference.&#xA;2. Out-of-bounds read: The memcpy() function is used to copy data from img.data to buff1 and buff2 without checking the size of the destination buffer, which could lead to an out-of-bounds read.&#xA;3. Out-of-bounds write: The buff3 and buff4 arrays are written to without checking the size of the source buffer, which could lead to an out-of-bounds write.&#xA;4. Uninitialized memory access: The OOBR_stack and OOBR_heap variables are accessed without being initialized, which could lead to undefined behavior.&#xA;5. Memory leak: The buff4 array is not freed if the size3 variable is greater than 10, which could lead to a memory leak.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;GPT-3 is correct again!&lt;/p&gt; &#xA;&lt;h3&gt;Example 4&lt;/h3&gt; &#xA;&lt;p&gt;This last &lt;a href=&#34;https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/raw/main/Unsafe%20Deserialization/SerializeToFile.java&#34;&gt;Java example&lt;/a&gt; is my favorite because, unfortunately, I didn&#39;t see anything wrong with this code when I first read it. To me, it looked completely innocuous and &lt;em&gt;familiar&lt;/em&gt; - I&#39;ve seen similar code in the wild but never had any second thoughts.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Utils&#xA;{&#xA;    // Function to serialize an object and write it to a file&#xA;    public static void SerializeToFile(Object obj, String filename)&#xA;    {&#xA;        try&#xA;        {&#xA;            FileOutputStream file = new FileOutputStream(filename);&#xA;            ObjectOutputStream out = new ObjectOutputStream(file);&#xA;&#xA;            // Serialization of the object to file&#xA;            System.out.println(&#34;Serializing &#34; + obj.toString() + &#34; to &#34; + filename);&#xA;            out.writeObject(obj);&#xA;&#xA;            out.close();&#xA;            file.close();&#xA;        }&#xA;        catch(Exception e)&#xA;        {&#xA;            System.out.println(&#34;Exception: &#34; + e.toString());&#xA;        }&#xA;    }&#xA;&#xA;    // Function to deserialize an object from a file&#xA;    public static Object DeserializeFromFile(String filename)&#xA;    {&#xA;        Object obj = new Object();&#xA;&#xA;        try&#xA;        {&#xA;            FileInputStream file = new FileInputStream(filename);&#xA;            ObjectInputStream in = new ObjectInputStream(file);&#xA;&#xA;            // Deserialization of the object to file&#xA;            System.out.println(&#34;Deserializing from &#34; + filename);&#xA;            obj = in.readObject();&#xA;&#xA;            in.close();&#xA;            file.close();&#xA;        }&#xA;        catch(Exception e)&#xA;        {&#xA;            System.out.println(&#34;Exception: &#34; + e.toString());&#xA;        }&#xA;&#xA;        return obj;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;GPT-3&#39;s output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-md&#34;&gt;Vulnerabilities Detected:&#xA;1. Insecure Deserialization: Deserializing untrusted data can lead to remote code execution.&#xA;2. Insecure File Permissions: The file being written to or read from may have insecure permissions, allowing unauthorized access.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;GPT-3 is correct again.&lt;/p&gt; &#xA;&lt;h3&gt;The Ultimate &#34;Shift-left&#34; in Cybersecurity&lt;/h3&gt; &#xA;&lt;p&gt;Shifting-left is the process of applying security practices earlier in the development process - like testing for security bugs before deploying your code to production.&lt;/p&gt; &#xA;&lt;p&gt;AI code-analysis could represent the ultimate shift-left in cybersecurity by applying best security practices and educating developers on cybersecurity as they are &lt;em&gt;writing and committing code&lt;/em&gt;. This could truly foster a culture of strong cybersecurity inside an organization and even prevent the next big hack, but...&lt;/p&gt; &#xA;&lt;p&gt;Admittedly, the technology is not perfect yet and there are several things it missed that an experienced cybersecurity professional doing an audit would not have missed. Still, it&#39;s shockingly good for being a general-purpose large language model and it&#39;s far cheaper than the alternatives.&lt;/p&gt; &#xA;&lt;p&gt;GPT-4 doesn&#39;t currently have a release date, but I&#39;m sure these large language models will continue to march forward as they gain more and more capabilities.&lt;/p&gt; &#xA;&lt;h3&gt;The False Positive&lt;/h3&gt; &#xA;&lt;p&gt;After manually reviewing around 50 out of 213 of the vulnerabilities detected by GPT-3, the only false positive I found was on line 13 of this &lt;a href=&#34;https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/raw/main/Unsafe%20Deserialization/unsafe.js&#34;&gt;Javascript program&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var express = require(&#39;express&#39;);&#xA;var cookieParser = require(&#39;cookie-parser&#39;);&#xA;var escape = require(&#39;escape-html&#39;);&#xA;var serialize = require(&#39;node-serialize&#39;);&#xA;var app = express();&#xA;app.use(cookieParser())&#xA; &#xA;app.get(&#39;/&#39;, function(req, res) {&#xA; if (req.cookies.profile) {&#xA;   var str = new Buffer(req.cookies.profile, &#39;base64&#39;).toString();&#xA;   var obj = serialize.unserialize(str);&#xA;   if (obj.username) {&#xA;     res.send(&#34;Hello &#34; + escape(obj.username)); // &amp;lt;--- GPT-3 makes a mistake here&#xA;   }&#xA; } else {&#xA;     res.cookie(&#39;profile&#39;, &#34;eyJ1c2VybmFtZSI6ImFqaW4iLCJjb3VudHJ5IjoiaW5kaWEiLCJjaXR5IjoiYmFuZ2Fsb3JlIn0=&#34;, {&#xA;       maxAge: 900000,&#xA;       httpOnly: true&#xA;     });&#xA; }&#xA; res.send(&#34;Hello World&#34;);&#xA;});&#xA;app.listen(3000);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;GPT-3&#39;s output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-md&#34;&gt;Vulnerabilities Detected:&#xA;- Insecure cookie settings (no secure flag set)&#xA;- Unvalidated deserialization of user input (cookie)&#xA;- Potential XSS vulnerability due to lack of escaping of user input (username)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;GPT-3 is correct about the first two vulnerabilities, but the third vulnerability is a false positive - &lt;code&gt;obj.username&lt;/code&gt; is escaped, but GPT-3 is saying that it is not.&lt;/p&gt; &#xA;&lt;h2&gt;Results&lt;/h2&gt; &#xA;&lt;p&gt;The results of the experiment showed that GPT-3 was able to detect security vulnerabilities in 85 out of 129 files scanned. This is quite impressive!&lt;/p&gt; &#xA;&lt;p&gt;The script &lt;a href=&#34;https://raw.githubusercontent.com/chris-koch-penn/gpt3_security_vulnerability_scanner/main/summarize_results.py&#34;&gt;&lt;code&gt;summarize_results.py&lt;/code&gt;&lt;/a&gt; generates a summary of GPT-3&#39;s results:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Vulnerabilities detected in 86 / 129 files.&#xA;Detected 213 vulnerabilities in total.&#xA;&#xA;Frequency of introductory sentences used in GPT-3&#39;s responses (1 response / file scanned):&#xA;{&#39;vulnerabilities detected&#39;: 73, &#39;no vulnerabilities detected.&#39;: 43, &#39;vulnerability detected&#39;: 6, &#39;answer&#39;: 2, &#39;potential vulnerabilities detected&#39;: 2, &#39;analysis&#39;: 1, &#39;security vulnerabilities detected&#39;: 1, &#39;no response given&#39;: 1} &#xA;&#xA;Distribution of file types scanned: &#xA;129 files of code in total (excluding markdown and flatfiles)&#xA;{&#39;.php&#39;: 50, &#39;.js&#39;: 20, &#39;.cs&#39;: 16, &#39;.c&#39;: 14, &#39;.java&#39;: 9, &#39;.py&#39;: 8, &#39;.rb&#39;: 5, &#39;.asp&#39;: 3, &#39;.ts&#39;: 2, &#39;.go&#39;: 1, &#39;.html&#39;: 1}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Comparison to Commercial Offerings&lt;/h3&gt; &#xA;&lt;p&gt;To round out this experiment, I compared the results of GPT-3 with a commercially available code vulnerability scanner, &lt;a href=&#34;https://snyk.io/product/snyk-code/&#34;&gt;Snyk Code&lt;/a&gt;, which is made by Snyk - a company which I think makes excellent security products. After running this repo through Snyk Code, it found 99 security vulnerabilities compared to the 213 found by GPT-3.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/raw/main/snyk-results.png&#34; alt=&#34;Snyk&#39;s results&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;One contributing factor is that Snyk Code only supports certain programming languages, and was only able to scan around 103 files compared to the 129 files scanned by GPT-3.&lt;/p&gt; &#xA;&lt;h3&gt;Final Notes&lt;/h3&gt; &#xA;&lt;p&gt;If you&#39;re interested in seeing this experiment become a full product, express interest through this super short &lt;a href=&#34;https://forms.gle/mXy8NVZb5fshqCAt6&#34;&gt;Google Form&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The vulnerable code snippets in this repo were taken from &lt;a href=&#34;https://github.com/snoopysecurity/Vulnerable-Code-Snippets&#34;&gt;snoopysecurity/Vulnerable-Code-Snippets&lt;/a&gt;, which is a fantastic resource. I tried to remove any comments embedded in the code snippets that hinted at what security vulnerabilities were contained in that snippet. This required me to remove comments containing links to blog posts and articles that these example snippets were gathered from. Any attributions present in the original repo can be found in the &lt;a href=&#34;https://github.com/chris-koch-penn/gpt3_security_vulnerability_scanner/raw/main/attributions.md&#34;&gt;attributions.md&lt;/a&gt; file.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>laravel/telescope</title>
    <updated>2023-02-22T01:42:34Z</updated>
    <id>tag:github.com,2023-02-22:/laravel/telescope</id>
    <link href="https://github.com/laravel/telescope" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An elegant debug assistant for the Laravel framework.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/laravel/telescope/4.x/art/logo.svg?sanitize=true&#34; alt=&#34;Logo Laravel Telescope&#34;&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/laravel/telescope/actions&#34;&gt;&lt;img src=&#34;https://github.com/laravel/telescope/workflows/tests/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://packagist.org/packages/laravel/telescope&#34;&gt;&lt;img src=&#34;https://img.shields.io/packagist/dt/laravel/telescope&#34; alt=&#34;Total Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://packagist.org/packages/laravel/telescope&#34;&gt;&lt;img src=&#34;https://img.shields.io/packagist/v/laravel/telescope&#34; alt=&#34;Latest Stable Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://packagist.org/packages/laravel/telescope&#34;&gt;&lt;img src=&#34;https://img.shields.io/packagist/l/laravel/telescope&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;Laravel Telescope is an elegant debug assistant for the Laravel framework. Telescope provides insight into the requests coming into your application, exceptions, log entries, database queries, queued jobs, mail, notifications, cache operations, scheduled tasks, variable dumps and more. Telescope makes a wonderful companion to your local Laravel development environment.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://laravel.com/assets/img/examples/Screen_Shot_2018-10-09_at_1.47.23_PM.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Official Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Documentation for Telescope can be found on the &lt;a href=&#34;https://laravel.com/docs/telescope&#34;&gt;Laravel website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Thank you for considering contributing to Telescope! The contribution guide can be found in the &lt;a href=&#34;https://laravel.com/docs/contributions&#34;&gt;Laravel documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;In order to ensure that the Laravel community is welcoming to all, please review and abide by the &lt;a href=&#34;https://laravel.com/docs/contributions#code-of-conduct&#34;&gt;Code of Conduct&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Security Vulnerabilities&lt;/h2&gt; &#xA;&lt;p&gt;Please review &lt;a href=&#34;https://github.com/laravel/telescope/security/policy&#34;&gt;our security policy&lt;/a&gt; on how to report security vulnerabilities.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Laravel Telescope is open-sourced software licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/laravel/telescope/4.x/LICENSE.md&#34;&gt;MIT license&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>hexters/ladmin</title>
    <updated>2023-02-22T01:42:34Z</updated>
    <id>tag:github.com,2023-02-22:/hexters/ladmin</id>
    <link href="https://github.com/hexters/ladmin" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Make an Administrator page in 5 minutes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;L-admin v3 (HMVC)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://packagist.org/packages/hexters/ladmin&#34;&gt;&lt;img src=&#34;https://poser.pugx.org/hexters/ladmin/v/stable&#34; alt=&#34;Latest Stable Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://packagist.org/packages/hexters/ladmin&#34;&gt;&lt;img src=&#34;https://poser.pugx.org/hexters/ladmin/downloads&#34; alt=&#34;Total Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://packagist.org/packages/hexters/ladmin&#34;&gt;&lt;img src=&#34;https://poser.pugx.org/hexters/ladmin/license&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/hexters/ladmin&#34;&gt;L-Admin&lt;/a&gt;&lt;/strong&gt; is a Laravel administration package that allows web developers to quickly create an admin panel for their website. The package includes features such as user management, access control management, task management, file management, email management, and many more. The package is designed to save time and effort in building an admin panel and allows developers to focus on building the core features of their web application.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hexters/assets/main/ladmin/v3/captures/home-page.png&#34; alt=&#34;Dashboard&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;🏷️ Laravel Version&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Version&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Laravel&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/hexters/ladmin/raw/v1.0.3/readme.md&#34;&gt;v1.0.x&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/hexters/ladmin/tree/v1.8.0&#34;&gt;v1.8.*&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8.x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/hexters/ladmin/tree/2.1.0&#34;&gt;v2.*&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/hexters/ladmin/raw/master/README.md&#34;&gt;v3.*&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10.x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;🚀 Quickstart&lt;/h1&gt; &#xA;&lt;p&gt;Follow the steps below to get started faster! Add the repository by running the command below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;composer require hexters/ladmin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Follow the installation to start build awesome apps.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;php artisan ladmin:install --and=ladmin:setup&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run migrate and seed, to install ladmin database tables&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;php artisan migrate --seed&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Installation is complete, please access &lt;code&gt;http://localhost:8000/administrator&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hexters/assets/main/ladmin/v3/captures/login-page.png&#34; alt=&#34;Login Page&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Customization Color and Assets&lt;/h1&gt; &#xA;&lt;p&gt;To change the ladmin style, you just need to run &lt;code&gt;Vite&lt;/code&gt;, before that you should install nodejs modules in &lt;code&gt;Modules/Ladmin&lt;/code&gt; folder. Follow this steps below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&#xA;// Install node modules &#xA;&#xA;cd Modules/Ladmin &amp;amp;&amp;amp; npm install&#xA;&#xA;// Go back to directory root project and run vitejs&#xA;&#xA;npm run dev&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can start changing javascript and css.&lt;/p&gt; &#xA;&lt;h1&gt;🗂️ Custom Namespaces&lt;/h1&gt; &#xA;&lt;p&gt;To call &lt;code&gt;view&lt;/code&gt;, &lt;code&gt;language&lt;/code&gt;, &lt;code&gt;config&lt;/code&gt;, and &lt;code&gt;component&lt;/code&gt; file, you need to add the prefix of module&#39;s name e.g &lt;code&gt;blog&lt;/code&gt;, see example below.&lt;/p&gt; &#xA;&lt;h3&gt;Calling View:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;  view(&#39;blog::article.index&#39;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Calling Lang:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;  __(&#39;blog::error.auth.message&#39;);&#xA;&#xA;  trans(&#39;blog::error.auth.message&#39;);&#xA;&#xA;  Lang::get(&#39;blog::error.auth.message&#39;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Calling Config:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;  config(&#39;blog.name&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For component view, if you have component named &lt;code&gt;\Modules\Blog\View\Components\Input&lt;/code&gt; class, then the way to call it by running.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;  &amp;lt;x-blog-input /&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;🌇 Layout Templating&lt;/h1&gt; &#xA;&lt;p&gt;Follow the documentation to view complete &lt;code&gt;slots&lt;/code&gt; and &lt;code&gt;stacks&lt;/code&gt; in layout component &lt;a href=&#34;https://github.com/hexters/ladmin/wiki/Template-Layout&#34;&gt;Documentation Layout&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;x-ladmin-auth-layout&amp;gt;&#xA;&#xA;  &amp;lt;x-slot name=&#34;title&#34;&amp;gt;Page Title&amp;lt;/x-slot&amp;gt;&#xA;&#xA;  &amp;lt;!-- Follow guest layout for slots &amp;amp; stacks --&amp;gt;&#xA;  &#xA;&amp;lt;/x-ladmin-auth-layout&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;👓 Ladmin Awesome&lt;/h1&gt; &#xA;&lt;p&gt;Get modules &amp;amp; template collections in &lt;a href=&#34;https://github.com/hexters/ladmin-awesome&#34;&gt;Ladmin Awesome&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;📖 Documentation&lt;/h1&gt; &#xA;&lt;p&gt;View complete &lt;a href=&#34;https://github.com/hexters/ladmin/wiki&#34;&gt;Documentation here&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>