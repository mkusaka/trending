<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub PHP Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-08-12T01:34:54Z</updated>
  <subtitle>Daily Trending of PHP in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>theodo-group/LLPhant</title>
    <updated>2023-08-12T01:34:54Z</updated>
    <id>tag:github.com,2023-08-12:/theodo-group/LLPhant</id>
    <link href="https://github.com/theodo-group/LLPhant" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LLPhant - A comprehensive PHP Generative AI Framework using OpenAI GPT 4. Inspired by Langchain and LLamaIndex&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LLPhant - A comprehensive PHP Generative AI Framework&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/theodo-group/LLPhant/main/doc/assets/llphant-logo.png&#34; alt=&#34;LLPhant&#34; style=&#34;border-radius: 50%; padding-bottom: 20px&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;We designed this framework to be as simple as possible, while still providing you with the tools you need to build powerful apps. It is compatible with Symfony and Laravel.&lt;/p&gt; &#xA;&lt;p&gt;For the moment only OpenAI is supported, if you want to use other LLMs, you can use &lt;a href=&#34;https://github.com/OpenGenenerativeAI/GenossGPT&#34;&gt;genossGPT&lt;/a&gt; as a proxy.&lt;/p&gt; &#xA;&lt;p&gt;We want to thank few amazing projects that we use here or inspired us:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;the learnings from using &lt;a href=&#34;https://www.langchain.com/&#34;&gt;LangChain&lt;/a&gt; and &lt;a href=&#34;https://www.llamaindex.ai/&#34;&gt;LLamaIndex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;the excellent work from the &lt;a href=&#34;https://github.com/openai-php/client&#34;&gt;OpenAI PHP SDK&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/theodo-group/LLPhant/main/#get-started&#34;&gt;Get Started&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/theodo-group/LLPhant/main/#database&#34;&gt;Database&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/theodo-group/LLPhant/main/#use-case&#34;&gt;Use Case&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/theodo-group/LLPhant/main/#usage&#34;&gt;Usage&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/theodo-group/LLPhant/main/#chat&#34;&gt;Chat&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/theodo-group/LLPhant/main/#embeddings&#34;&gt;Embeddings&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/theodo-group/LLPhant/main/#vectorstores&#34;&gt;VectorStore and Search&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/theodo-group/LLPhant/main/#question-answering&#34;&gt;Question Answering&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/theodo-group/LLPhant/main/#contributors&#34;&gt;Contributors&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/theodo-group/LLPhant/main/#sponsor&#34;&gt;Sponsor&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Requires &lt;a href=&#34;https://php.net/releases/&#34;&gt;PHP 8.1+&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;First, install LLPhant via the &lt;a href=&#34;https://getcomposer.org/&#34;&gt;Composer&lt;/a&gt; package manager:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;composer require theodo-group/llphant&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may also want to check the requirements for &lt;a href=&#34;https://github.com/openai-php/client&#34;&gt;OpenAI PHP SDK&lt;/a&gt; as it is the main client.&lt;/p&gt; &#xA;&lt;h3&gt;Database&lt;/h3&gt; &#xA;&lt;p&gt;If you want to store some embeddings and perform a similarity search you will need a database. One simple solution for web developers is to use a postgresql database &lt;strong&gt;with the pgvector extension&lt;/strong&gt;. You can find all the information on the pgvector extension on its &lt;a href=&#34;https://github.com/pgvector/pgvector&#34;&gt;github repository&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We suggest you 3 simple solutions to get a postgresql database with the extension enabled:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;use docker with the &lt;a href=&#34;https://raw.githubusercontent.com/theodo-group/LLPhant/main/devx/docker-compose.yml&#34;&gt;docker-compose.yml&lt;/a&gt; file&lt;/li&gt; &#xA; &lt;li&gt;use &lt;a href=&#34;https://supabase.com/&#34;&gt;Supabase&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;use &lt;a href=&#34;https://neon.tech/&#34;&gt;Neon&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In any case you will need to activate the extension:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE EXTENSION IF NOT EXISTS vector;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then you can create a table and store vectors. This sql query will create the table from the example entity that we use later in &lt;a href=&#34;https://raw.githubusercontent.com/theodo-group/LLPhant/main/#VectorStores&#34;&gt;VectorStore&lt;/a&gt; section.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE IF NOT EXISTS embeddings (&#xA;    id SERIAL PRIMARY KEY,&#xA;    data TEXT,&#xA;    type TEXT,&#xA;    embedding VECTOR&#xA;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Use Case&lt;/h2&gt; &#xA;&lt;p&gt;There are plenty use cases for Generative AI and new ones are creating every day. Let&#39;s see the most common ones. Based on a &lt;a href=&#34;https://mlops.community/surveys/llm/&#34;&gt;survey from the MLOPS community&lt;/a&gt; and &lt;a href=&#34;https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2023-generative-ais-breakout-year&#34;&gt;this survey from Mckinsey&lt;/a&gt; the most common use case of AI are the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create semantic search that can find relevant information in a lot of data. Example: &lt;a href=&#34;https://slite.com/&#34;&gt;Slite&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Create chatbots / augmented FAQ that use semantic search and text summarization to answer customer questions. Example: &lt;a href=&#34;https://www.quivr.app/&#34;&gt;Quivr&lt;/a&gt; is using such similar technology.&lt;/li&gt; &#xA; &lt;li&gt;Create personalized content for your customers (product page, emails, messages,...). Example &lt;a href=&#34;https://www.carrefour.com/en/news/2023/carrefour-integrates-openai-technologies-and-launches-generative-ai-powered-shopping&#34;&gt;Carrefour&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Create a text summarizer that can summarize a long text into a short one.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Not widely spread yet but with increasing adoption:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create personal shopper for augmented ecommerce experience. Example: &lt;a href=&#34;https://www.knxt-madeline.com/&#34;&gt;Madeline&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Create AI agent to perform various task autonomously. Example: &lt;a href=&#34;https://github.com/Significant-Gravitas/Auto-GPT&#34;&gt;AutoGpt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Create coding tool that can help you write or revie code. Example: &lt;a href=&#34;https://github.com/mattzcarey/code-review-gpt&#34;&gt;Code Review GPT&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you want to discover more usage from the community, you can see here a list of &lt;a href=&#34;https://www.genaidays.org/events/&#34;&gt;GenAI Meetups&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;The most simple to allow the call to OpenAI is to set the OPENAI_API_KEY environment variable.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export OPENAI_API_KEY=sk-XXXXXX&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also create an OpenAIConfig object and pass it to the constructor of the OpenAIChat or OpenAIEmbeddings.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;$config = new OpenAIConfig();&#xA;$config-&amp;gt;apiKey = &#39;fakeapikey&#39;;&#xA;$chat = new OpenAIChat($config);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Chat&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ðŸ’¡ This class can be used to generate content, to create a chatbot or to create a text summarizer.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;The API to generate text using OpenAI will only be from the chat API. So even if you want to generate a completion for a simple question under the hood it will use the chat API. This is why this class is called OpenAIChat. We can use it to simply generate text from a prompt.&lt;/p&gt; &#xA;&lt;p&gt;This will ask directly an answer from the LLM.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;$chat = new OpenAIChat();&#xA;$response = $chat-&amp;gt;generateText(&#39;what is one + one ?&#39;); // will return something like &#34;Two&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to display in your frontend a stream of text like in ChatGPT you can use the following method.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;$chat = new OpenAIChat();&#xA;return $chat-&amp;gt;generateStreamOfText(&#39;can you write me a poem of 10 lines about life ?&#39;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can add instruction so the LLM will behave in a specific manner.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;$chat = new OpenAIChat();&#xA;$chat-&amp;gt;setSystemMessage(&#39;Whatever we ask you, you MUST answer &#34;ok&#34;&#39;);&#xA;$response = $chat-&amp;gt;generateText(&#39;what is one + one ?&#39;); // will return &#34;ok&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Embeddings&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ðŸ’¡ Embeddings are used to compare two texts and see how similar they are. This is the base of semantic search. An embedding is a vector representation of a text that captures the meaning of the text. It is a float array of 1536 elements for OpenAI.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;To manipulate embeddings we use the &lt;code&gt;Document&lt;/code&gt; class that contains the text and some metadata useful for the vector store. The creation of an embedding follow the following flow:&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/theodo-group/LLPhant/main/doc/assets/embeddings-flow.png&#34; alt=&#34;Embeddings flow&#34; style=&#34;padding-bottom: 20px&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h4&gt;Read data&lt;/h4&gt; &#xA;&lt;p&gt;The first part of the flow is to read data from a source. This can be a database, a csv file, a json file, a text file, a website, a pdf, a word document, an excel file, ... The only requirement is that you can read the data and that you can extract the text from it. For now we only support text data but we plan to support other data type in the future. To read data you need to create a class that implements the &lt;code&gt;DataReader&lt;/code&gt; interface.&lt;/p&gt; &#xA;&lt;p&gt;You can use the &lt;code&gt;TextFileDataReader&lt;/code&gt; class to read a text file. It takes a path to a file or a directory as parameter. The second parameter is the class name of the entity that will be used to store the embedding. The class needs to extend the &lt;code&gt;Document&lt;/code&gt; class and even the &lt;code&gt;DoctrineEmbeddingEntityBase&lt;/code&gt; class (that extends the &lt;code&gt;Document&lt;/code&gt; class) if you want to use the Doctrine vector store.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;$filePath = __DIR__.&#39;/PlacesTextFiles&#39;;&#xA;$reader = new TextFileDataReader($filePath, PlaceEntity::class);&#xA;$documents = $reader-&amp;gt;getDocuments();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Document Splitter&lt;/h4&gt; &#xA;&lt;p&gt;The embeddings models have a limit of string size that they can process. To avoid this problem we split the document into smaller chunks. The &lt;code&gt;DocumentSplitter&lt;/code&gt; class is used to split the document into smaller chunks.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;$splittedDocuments = DocumentSplitter::splitDocuments($documents, 800);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Embedding Formatter&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;EmbeddingFormatter&lt;/code&gt; is an optional step to format each chunk of text into a format with the most context. Adding a header and links to other documents can help the LLM to understand the context of the text.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;$formattedDocuments = EmbeddingFormatter::formatEmbeddings($splittedDocuments);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Embedding Generator&lt;/h4&gt; &#xA;&lt;p&gt;This is the step where we generate the embedding for each chunk of text by calling the LLM.&lt;/p&gt; &#xA;&lt;p&gt;You can embed the documents using the following code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;$embeddingGenerator = new OpenAIEmbeddingGenerator();&#xA;$embededDocuments = $embeddingGenerator-&amp;gt;embedDocuments($formattedDocuments);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also create a embedding from a text using the following code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;$llm = new OpenAIEmbeddingGenerator();&#xA;$embedding = $llm-&amp;gt;embedText(&#39;I love food&#39;);&#xA;//You can then use the embedding to perform a similarity search&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;VectorStores&lt;/h4&gt; &#xA;&lt;p&gt;Once you have embeddings you need to store them in a vector store. The vector store is a database that can store vectors and perform a similarity search. To store the documents you need to create a class that implements the &lt;code&gt;VectorStoreBase&lt;/code&gt; class.&lt;/p&gt; &#xA;&lt;p&gt;You can use the &lt;code&gt;DoctrineVectorStore&lt;/code&gt; class to store the embeddings in a database:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;$vectorStore = new DoctrineVectorStore($entityManager, PlaceEntity::class);&#xA;$vectorStore-&amp;gt;addDocuments($embededDocuments);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once you have done that you can perform a similarity search over your data. You need to pass the embedding of the text you want to search and the number of results you want to get.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;$embedding = $embeddingGenerator-&amp;gt;embedText(&#39;France the country&#39;);&#xA;/** @var PlaceEntity[] $result */&#xA;$result = $vectorStore-&amp;gt;similaritySearch($embedding, 2);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To get full example you can have a look at &lt;a href=&#34;https://github.com/theodo-group/LLPhant/raw/main/tests/Integration/Embeddings/VectorStores/Doctrine/DoctrineVectorStoreTest.php&#34;&gt;Doctrine integration tests files&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Question Answering&lt;/h3&gt; &#xA;&lt;p&gt;A popular use case of LLM is to create a chatbot that can answer questions over your private data. You can build one using LLPhant using the &lt;code&gt;QuestionAnswering&lt;/code&gt; class. It leverages the vector store to perform a similarity search to get the most relevant information and return the answer generated by OpenAI.&lt;/p&gt; &#xA;&lt;p&gt;Here is one example using the &lt;code&gt;MemoryVectorStore&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;$dataReader = new TextFileDataReader(__DIR__.&#39;/private-data.txt&#39;);&#xA;$documents = $dataReader-&amp;gt;getDocuments();&#xA;&#xA;$splittedDocuments = DocumentSplitter::splitDocuments($documents, 500);&#xA;&#xA;$embeddingGenerator = new OpenAIEmbeddingGenerator();&#xA;$embeddedDocuments = $embeddingGenerator-&amp;gt;embedDocuments($splittedDocuments);&#xA;&#xA;$memoryVectorStore = new MemoryVectorStore();&#xA;$memoryVectorStore-&amp;gt;addDocuments($embeddedDocuments);&#xA;&#xA;&#xA;//Once the vectorStore is ready, you can then use the QuestionAnswering class to answer questions&#xA;$qa = new QuestionAnswering(&#xA;    $memoryVectorStore,&#xA;    $embeddingGenerator,&#xA;    new OpenAIChat()&#xA;);&#xA;&#xA;$answer = $qa-&amp;gt;answerQuestion(&#39;what is the secret of Alice?&#39;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;Why use LLPhant and not directly the OpenAI PHP SDK ?&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;The OpenAI PHP SDK is a great tool to interact with the OpenAI API. LLphant will allow you to perform complex tasks like storing embeddings and perform a similarity search. It also simplifies the usage of the OpenAI API by providing a much more simple API for everyday usage.&lt;/p&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;p&gt;Thanks to our contributors:&lt;/p&gt; &#xA;&lt;a href=&#34;https://github.com/theodo-group/llphant/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=theodo-group/llphant&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;Sponsor&lt;/h2&gt; &#xA;&lt;p&gt;LLPhant is sponsored by &lt;a href=&#34;https://www.theodo.fr/&#34;&gt;Theodo&lt;/a&gt; a leading digital agency building web application with Generative AI.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://www.theodo.fr/&#34;&gt;&lt;/a&gt; &#xA; &lt;img alt=&#34;Theodo logo&#34; src=&#34;https://cdn2.hubspot.net/hub/2383597/hubfs/Website/Logos/Logo_Theodo_cropped.svg?sanitize=true&#34; width=&#34;200&#34;&gt;  &#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>sebastianbergmann/php-token-stream</title>
    <updated>2023-08-12T01:34:54Z</updated>
    <id>tag:github.com,2023-08-12:/sebastianbergmann/php-token-stream</id>
    <link href="https://github.com/sebastianbergmann/php-token-stream" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Wrapper around PHP&#39;s tokenizer extension.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;phpunit/php-token-stream&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/sebastianbergmann/php-token-stream/actions&#34;&gt;&lt;img src=&#34;https://github.com/sebastianbergmann/php-token-stream/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;CI Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://shepherd.dev/github/sebastianbergmann/php-token-stream&#34;&gt;&lt;img src=&#34;https://shepherd.dev/github/sebastianbergmann/php-token-stream/coverage.svg?sanitize=true&#34; alt=&#34;Type Coverage&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;You can add this library as a local, per-project dependency to your project using &lt;a href=&#34;https://getcomposer.org/&#34;&gt;Composer&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;composer require phpunit/php-token-stream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you only need this library during development, for instance to run your project&#39;s test suite, then you should add it as a development-time dependency:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;composer require --dev phpunit/php-token-stream&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>