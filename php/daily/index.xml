<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub PHP Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-08-29T01:33:11Z</updated>
  <subtitle>Daily Trending of PHP in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>CodeWithKyrian/transformers-php</title>
    <updated>2024-08-29T01:33:11Z</updated>
    <id>tag:github.com,2024-08-29:/CodeWithKyrian/transformers-php</id>
    <link href="https://github.com/CodeWithKyrian/transformers-php" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Transformers PHP is a toolkit for PHP developers to add machine learning magic to their projects easily.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; TransformersPHP &lt;/h1&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt; &lt;p&gt;State-of-the-art Machine Learning for PHP&lt;/p&gt; &lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://packagist.org/packages/codewithkyrian/transformers&#34;&gt;&lt;img src=&#34;https://img.shields.io/packagist/dt/codewithkyrian/transformers&#34; alt=&#34;Total Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://packagist.org/packages/codewithkyrian/transformers&#34;&gt;&lt;img src=&#34;https://img.shields.io/packagist/v/codewithkyrian/transformers&#34; alt=&#34;Latest Stable Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/CodeWithKyrian/transformers-php/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/codewithkyrian/transformers-php&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/codewithkyrian/transformers-php&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/repo-size/codewithkyrian/transformers-php&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;TransformersPHP is designed to be functionally equivalent to the Python library, while still maintaining the same level of performance and ease of use. This library is built on top of the Hugging Face&#39;s Transformers library, which provides thousands of pre-trained models in 100+ languages. It is designed to be a simple and easy-to-use library for PHP developers using a similar API to the Python library. These models can be used for a variety of tasks, including text generation, summarization, translation, and more.&lt;/p&gt; &#xA;&lt;p&gt;TransformersPHP uses &lt;a href=&#34;https://onnxruntime.ai/&#34;&gt;ONNX Runtime&lt;/a&gt; to run the models, which is a high-performance scoring engine for Open Neural Network Exchange (ONNX) models. You can easily convert any PyTorch or TensorFlow model to ONNX and use it with TransformersPHP using &lt;a href=&#34;https://github.com/huggingface/optimum#onnx--onnx-runtime&#34;&gt;ü§ó Optimum&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;TO learn more about the library and how it works, head over to our &lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/introduction&#34;&gt;extensive documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Quick tour&lt;/h2&gt; &#xA;&lt;p&gt;Because TransformersPHP is designed to be functionally equivalent to the Python library, it&#39;s super easy to learn from existing Python or Javascript code. We provide the &lt;code&gt;pipeline&lt;/code&gt; API, which is a high-level, easy-to-use API that groups together a model with its necessary preprocessing and postprocessing steps.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;b&gt;Python (original)&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;b&gt;PHP (ours)&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;b&gt;Javascript (Xenova)&lt;/b&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import pipeline&#xA;&#xA;# Allocate a pipeline for sentiment-analysis&#xA;pipe = pipeline(&#39;sentiment-analysis&#39;)&#xA;&#xA;out = pipe(&#39;I love transformers!&#39;)&#xA;# [{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.999806941}]&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;use function Codewithkyrian\Transformers\Pipelines\pipeline;&#xA;&#xA;// Allocate a pipeline for sentiment-analysis&#xA;$pipe = pipeline(&#39;sentiment-analysis&#39;);&#xA;&#xA;$out = $pipe(&#39;I love transformers!&#39;);&#xA;// [{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.999808732}]&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import {pipeline} from &#39;@xenova/transformers&#39;;&#xA;&#xA;// Allocate a pipeline for sentiment-analysis&#xA;let pipe = await pipeline(&#39;sentiment-analysis&#39;);&#xA;&#xA;let out = await pipe(&#39;I love transformers!&#39;);&#xA;// [{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.999817686}]&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;You can also use a different model by specifying the model id or path as the second argument to the &lt;code&gt;pipeline&lt;/code&gt; function. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;use function Codewithkyrian\Transformers\Pipelines\pipeline;&#xA;&#xA;// Allocate a pipeline for translation&#xA;$pipe = pipeline(&#39;translation&#39;, &#39;Xenova/distilbert-base-uncased-finetuned-sst-2-english&#39;);&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;You can install the library via Composer. This is the recommended way to install the library.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;composer require codewithkyrian/transformers&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!CAUTION] The ONNX library is platform-specific, so it&#39;s important to run the composer require command on the target platform where the code will be executed. In most cases, this will be your development machine or a server where you deploy your application, but if you&#39;re using a Docker container, run the &lt;code&gt;composer require&lt;/code&gt; command inside that container.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;PHP FFI Extension&lt;/h2&gt; &#xA;&lt;p&gt;TransformersPHP uses the PHP FFI extension to interact with the ONNX runtime. The FFI extension is included by default in PHP 7.4 and later, but it may not be enabled by default. If the FFI extension is not enabled, you can enable it by uncommenting(remove the &lt;code&gt;;&lt;/code&gt; from the beginning of the line) the following line in your &lt;code&gt;php.ini&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;extension = ffi&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Also, you need to set the &lt;code&gt;ffi.enable&lt;/code&gt; directive to &lt;code&gt;true&lt;/code&gt; in your &lt;code&gt;php.ini&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;ffi.enable = true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After making these changes, restart your web server or PHP-FPM service, and you should be good to go.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;For more detailed information on how to use the library, check out the documentation : &lt;a href=&#34;https://codewithkyrian.github.io/transformers-php&#34;&gt;https://codewithkyrian.github.io/transformers-php&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;By default, TransformersPHP uses hosted pretrained ONNX models. For supported tasks, models that have been converted to work with &lt;a href=&#34;https://huggingface.co/models?library=transformers.js&#34;&gt;Xenova&#39;s Transformers.js&lt;/a&gt; on HuggingFace should work out of the box with TransformersPHP.&lt;/p&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;You can configure the behaviour of the TransformersPHP library as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;use Codewithkyrian\Transformers\Transformers;&#xA;&#xA;Transformers::setup()&#xA;    -&amp;gt;setCacheDir(&#39;...&#39;) // Set the default cache directory for transformers models. Defaults to `.transformers-cache/models`&#xA;    -&amp;gt;setRemoteHost(&#39;...&#39;) // Set the remote host for downloading models. Defaults to `https://huggingface.co`&#xA;    -&amp;gt;setRemotePathTemplate(&#39;...&#39;) // Set the remote path template for downloading models. Defaults to `{model}/resolve/{revision}/{file}`&#xA;    -&amp;gt;setAuthToken(&#39;...&#39;) // Set the auth token for downloading models. Defaults to `null`&#xA;    -&amp;gt;setUserAgent(&#39;...&#39;) // Set the user agent for downloading models. Defaults to `transformers-php/{version}`&#xA;    -&amp;gt;setImageDriver(&#39;...&#39;) // Set the image driver for processing images. Defaults to `IMAGICK&#39;&#xA;    -&amp;gt;apply(); // Apply the configuration&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can call the &lt;code&gt;set&lt;/code&gt; methods in any order, or leave any out entirely, in which case, it uses the default values. For more information on the configuration options and what they mean, checkout the &lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/configuration&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Convert your models to ONNX&lt;/h2&gt; &#xA;&lt;p&gt;TransformersPHP only works with ONNX models, therefore, you must convert your PyTorch, TensorFlow or JAX models to ONNX. It is recommended to use &lt;a href=&#34;https://huggingface.co/docs/optimum&#34;&gt;ü§ó Optimum&lt;/a&gt; to perform the conversion and quantization of your model.&lt;/p&gt; &#xA;&lt;h2&gt;Pre-Download Models&lt;/h2&gt; &#xA;&lt;p&gt;By default, TransformersPHP automatically retrieves model weights (ONNX format) from the Hugging Face model hub when you first use a pipeline or pretrained model. This can lead to a slight delay during the initial use. To improve the user experience, it&#39;s recommended to pre-download the models you intend to use before running them in your PHP application, especially for larger models. One way to do that is run the request once manually, but TransformersPHP also comes with a command line tool to help you do just that:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./vendor/bin/transformers download &amp;lt;model_identifier&amp;gt; [&amp;lt;task&amp;gt;] [options]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Explanation of Arguments:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&amp;lt;model_identifier&amp;gt;&lt;/strong&gt;: This specifies the model you want to download. You can find model identifiers by browsing the Hugging Face model hub (&lt;a href=&#34;https://huggingface.co/models?library=transformers.js&#34;&gt;https://huggingface.co/models?library=transformers.js&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[&amp;lt;task&amp;gt;]&lt;/strong&gt;: (Optional) This parameter allows for downloading task-specific configurations and weights. This can be helpful if you know the specific task you&#39;ll be using the model for (e.g., &#34;text2text-generation&#34;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[options]&lt;/strong&gt;: (Optional) You can further customize the download process with additional options: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;--cache_dir=&amp;lt;directory&amp;gt;&lt;/strong&gt;: Specify a directory to store downloaded models (defaults to the configured cache). You can use -c as a shortcut in the command.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;--quantized=&amp;lt;true|false&amp;gt;&lt;/strong&gt;: Download the quantized model version if available (defaults to true). Quantized models are smaller and faster, but may have slightly lower accuracy. Use -q as a shortcut in the command.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!CAUTION] Remember to add your cache directory to your &lt;code&gt;.gitignore&lt;/code&gt; file to avoid committing the downloaded models to your git repository.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Supported tasks/models&lt;/h2&gt; &#xA;&lt;p&gt;This package is a WIP, but here&#39;s a list of tasks and architectures currently tested and supported by TransformersPHP.&lt;/p&gt; &#xA;&lt;h3&gt;Tasks&lt;/h3&gt; &#xA;&lt;h4&gt;Natural Language Processing&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Task&lt;/th&gt; &#xA;   &lt;th&gt;ID&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Supported?&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/fill-mask&#34;&gt;Fill-Mask&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;fill-mask&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Masking some of the words in a sentence and predicting which words should replace those masks.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/question-answering&#34;&gt;Question Answering&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;question-answering&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Retrieve the answer to a question from a given text.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/sentence-similarity&#34;&gt;Sentence Similarity&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;sentence-similarity&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Determining how similar two texts are.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/summarization&#34;&gt;Summarization&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;summarization&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Producing a shorter version of a document while preserving its important information.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tasks/table-question-answering&#34;&gt;Table Question Answering&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;table-question-answering&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Answering a question about information from a given table.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/text-classification&#34;&gt;Text Classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;text-classification&lt;/code&gt; or &lt;code&gt;sentiment-analysis&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Assigning a label or class to a given text.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/text-generation&#34;&gt;Text Generation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;text-generation&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Producing new text by predicting the next word in a sequence.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/text-to-text-generation&#34;&gt;Text-to-text Generation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;text2text-generation&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Converting one text sequence into another text sequence.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/token-classification&#34;&gt;Token Classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;token-classification&lt;/code&gt; or &lt;code&gt;ner&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Assigning a label to each token in a text.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/translation&#34;&gt;Translation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;translation&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Converting text from one language to another.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/zero-shot-classification&#34;&gt;Zero-Shot Classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;zero-shot-classification&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Classifying text into classes that are unseen during training.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Vision&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Task&lt;/th&gt; &#xA;   &lt;th&gt;ID&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Supported?&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/depth-estimation&#34;&gt;Depth Estimation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;depth-estimation&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Predicting the depth of objects present in an image.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/image-classification&#34;&gt;Image Classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;image-classification&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Assigning a label or class to an entire image.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/image-segmentation&#34;&gt;Image Segmentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;image-segmentation&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Divides an image into segments where each pixel is mapped to an object. This task has multiple variants such as instance segmentation, panoptic segmentation and semantic segmentation.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/image-to-image&#34;&gt;Image-to-Image&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;image-to-image&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Transforming a source image to match the characteristics of a target image or a target image domain.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/mask-generation&#34;&gt;Mask Generation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;mask-generation&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Generate masks for the objects in an image.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/object-detection&#34;&gt;Object Detection&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;object-detection&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Identify objects of certain defined classes within an image.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Audio&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Task&lt;/th&gt; &#xA;   &lt;th&gt;ID&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Supported?&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tasks/audio-classification&#34;&gt;Audio Classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;audio-classification&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Assigning a label or class to a given audio.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tasks/audio-to-audio&#34;&gt;Audio-to-Audio&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;Generating audio from an input audio source.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tasks/automatic-speech-recognition&#34;&gt;Automatic Speech Recognition&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;automatic-speech-recognition&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Transcribing a given audio into text.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tasks/text-to-speech&#34;&gt;Text-to-Speech&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;text-to-speech&lt;/code&gt; or &lt;code&gt;text-to-audio&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Generating natural-sounding speech given text input.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Tabular&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Task&lt;/th&gt; &#xA;   &lt;th&gt;ID&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Supported?&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tasks/tabular-classification&#34;&gt;Tabular Classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;Classifying a target category (a group) based on set of attributes.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tasks/tabular-regression&#34;&gt;Tabular Regression&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;Predicting a numerical value given a set of attributes.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Multimodal&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Task&lt;/th&gt; &#xA;   &lt;th&gt;ID&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Supported?&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tasks/document-question-answering&#34;&gt;Document Question Answering&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;document-question-answering&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Answering questions on document images.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/feature-extraction&#34;&gt;Feature Extraction&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;feature-extraction&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Transforming raw data into numerical features that can be processed while preserving the information in the original dataset.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/image-feature-extraction&#34;&gt;Image Feature Extraction&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;image-feature-extraction&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Extracting features from images.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/image-to-text&#34;&gt;Image-to-Text&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;image-to-text&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Output text from a given image.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tasks/text-to-image&#34;&gt;Text-to-Image&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;text-to-image&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Generates images from input text.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tasks/visual-question-answering&#34;&gt;Visual Question Answering&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;visual-question-answering&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Answering open-ended questions based on an image.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/learn/audio-course/chapter4/classification_models#zero-shot-audio-classification&#34;&gt;Zero-Shot Audio Classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;zero-shot-audio-classification&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Classifying audios into classes that are unseen during training.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/zero-shot-image-classification&#34;&gt;Zero-Shot Image Classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;zero-shot-image-classification&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Classifying images into classes that are unseen during training.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://codewithkyrian.github.io/transformers-php/zero-shot-object-detection&#34;&gt;Zero-Shot Object Detection&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;zero-shot-object-detection&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Identify objects of classes that are unseen during training.&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Reinforcement Learning&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Task&lt;/th&gt; &#xA;   &lt;th&gt;ID&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Supported?&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tasks/reinforcement-learning&#34;&gt;Reinforcement Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;Learning from actions by interacting with an environment through trial and error and receiving rewards (negative or positive) as feedback.&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Models&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/albert&#34;&gt;ALBERT&lt;/a&gt;&lt;/strong&gt; (from Google Research and the Toyota Technological Institute at Chicago) released with the paper &lt;a href=&#34;https://arxiv.org/abs/1909.11942&#34;&gt;ALBERT: A Lite BERT for Self-supervised Learning of Language Representations&lt;/a&gt;, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/bart&#34;&gt;BART&lt;/a&gt;&lt;/strong&gt; (from Facebook) released with the paper &lt;a href=&#34;https://arxiv.org/abs/1910.13461&#34;&gt;BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension&lt;/a&gt; by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/bert&#34;&gt;BERT&lt;/a&gt;&lt;/strong&gt; (from Google) released with the paper &lt;a href=&#34;https://arxiv.org/abs/1810.04805&#34;&gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/a&gt; by Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/bert-generation&#34;&gt;BERT For Sequence Generation&lt;/a&gt;&lt;/strong&gt; (from Google) released with the paper &lt;a href=&#34;https://arxiv.org/abs/1907.12461&#34;&gt;Leveraging Pre-trained Checkpoints for Sequence Generation Tasks&lt;/a&gt; by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/bertweet&#34;&gt;BERTweet&lt;/a&gt;&lt;/strong&gt; (from VinAI Research) released with the paper &lt;a href=&#34;https://aclanthology.org/2020.emnlp-demos.2/&#34;&gt;BERTweet: A pre-trained language model for English Tweets&lt;/a&gt; by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/bigbird_pegasus&#34;&gt;BigBird-Pegasus&lt;/a&gt;&lt;/strong&gt; (from Google Research) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2007.14062&#34;&gt;Big Bird: Transformers for Longer Sequences&lt;/a&gt; by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/big_bird&#34;&gt;BigBird-RoBERTa&lt;/a&gt;&lt;/strong&gt; (from Google Research) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2007.14062&#34;&gt;Big Bird: Transformers for Longer Sequences&lt;/a&gt; by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/clip&#34;&gt;CLIP&lt;/a&gt;&lt;/strong&gt; (from OpenAI) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2103.00020&#34;&gt;Learning Transferable Visual Models From Natural Language Supervision&lt;/a&gt; by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/codegen&#34;&gt;CodeGen&lt;/a&gt;&lt;/strong&gt; (from Salesforce) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2203.13474&#34;&gt;A Conversational Paradigm for Program Synthesis&lt;/a&gt; by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/convbert&#34;&gt;ConvBERT&lt;/a&gt;&lt;/strong&gt; (from YituTech) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2008.02496&#34;&gt;ConvBERT: Improving BERT with Span-based Dynamic Convolution&lt;/a&gt; by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/deberta&#34;&gt;DeBERTa&lt;/a&gt;&lt;/strong&gt; (from Microsoft) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2006.03654&#34;&gt;DeBERTa: Decoding-enhanced BERT with Disentangled Attention&lt;/a&gt; by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/deberta-v2&#34;&gt;DeBERTa-v2&lt;/a&gt;&lt;/strong&gt; (from Microsoft) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2006.03654&#34;&gt;DeBERTa: Decoding-enhanced BERT with Disentangled Attention&lt;/a&gt; by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/detr&#34;&gt;DETR&lt;/a&gt;&lt;/strong&gt; (from Facebook) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2005.12872&#34;&gt;End-to-End Object Detection with Transformers&lt;/a&gt; by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/distilbert&#34;&gt;DistilBERT&lt;/a&gt;&lt;/strong&gt; (from HuggingFace), released together with the paper &lt;a href=&#34;https://arxiv.org/abs/1910.01108&#34;&gt;DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter&lt;/a&gt; by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into &lt;a href=&#34;https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation&#34;&gt;DistilGPT2&lt;/a&gt;, RoBERTa into &lt;a href=&#34;https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation&#34;&gt;DistilRoBERTa&lt;/a&gt;, Multilingual BERT into &lt;a href=&#34;https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation&#34;&gt;DistilmBERT&lt;/a&gt; and a German version of DistilBERT.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/donut&#34;&gt;Donut&lt;/a&gt;&lt;/strong&gt; (from NAVER), released together with the paper &lt;a href=&#34;https://arxiv.org/abs/2111.15664&#34;&gt;OCR-free Document Understanding Transformer&lt;/a&gt; by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/electra&#34;&gt;ELECTRA&lt;/a&gt;&lt;/strong&gt; (from Google Research/Stanford University) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2003.10555&#34;&gt;ELECTRA: Pre-training text encoders as discriminators rather than generators&lt;/a&gt; by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/flan-t5&#34;&gt;FLAN-T5&lt;/a&gt;&lt;/strong&gt; (from Google AI) released in the repository &lt;a href=&#34;https://github.com/google-research/t5x/raw/main/docs/models.md#flan-t5-checkpoints&#34;&gt;google-research/t5x&lt;/a&gt; by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/gpt2&#34;&gt;GPT-2&lt;/a&gt;&lt;/strong&gt; (from OpenAI) released with the paper &lt;a href=&#34;https://blog.openai.com/better-language-models/&#34;&gt;Language Models are Unsupervised Multitask Learners&lt;/a&gt; by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/gptj&#34;&gt;GPT-J&lt;/a&gt;&lt;/strong&gt; (from EleutherAI) released in the repository &lt;a href=&#34;https://github.com/kingoflolz/mesh-transformer-jax/&#34;&gt;kingoflolz/mesh-transformer-jax&lt;/a&gt; by Ben Wang and Aran Komatsuzaki.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/gpt_bigcode&#34;&gt;GPTBigCode&lt;/a&gt;&lt;/strong&gt; (from BigCode) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2301.03988&#34;&gt;SantaCoder: don&#39;t reach for the stars!&lt;/a&gt; by Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert, Francesco De Toni, Bernardo Garc√≠a del R√≠o, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/m2m_100&#34;&gt;M2M100&lt;/a&gt;&lt;/strong&gt; (from Facebook) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2010.11125&#34;&gt;Beyond English-Centric Multilingual Machine Translation&lt;/a&gt; by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/mobilebert&#34;&gt;MobileBERT&lt;/a&gt;&lt;/strong&gt; (from CMU/Google Brain) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2004.02984&#34;&gt;MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices&lt;/a&gt; by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/owlvit&#34;&gt;OWL-ViT&lt;/a&gt;&lt;/strong&gt; (from Google AI) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2205.06230&#34;&gt;Simple Open-Vocabulary Object Detection with Vision Transformers&lt;/a&gt; by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/owlv2&#34;&gt;OWLv2&lt;/a&gt;&lt;/strong&gt; (from Google AI) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2306.09683&#34;&gt;Scaling Open-Vocabulary Object Detection&lt;/a&gt; by Matthias Minderer, Alexey Gritsenko, Neil Houlsby.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/roberta&#34;&gt;RoBERTa&lt;/a&gt;&lt;/strong&gt; (from Facebook), released together with the paper &lt;a href=&#34;https://arxiv.org/abs/1907.11692&#34;&gt;RoBERTa: A Robustly Optimized BERT Pretraining Approach&lt;/a&gt; by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/roberta-prelayernorm&#34;&gt;RoBERTa-PreLayerNorm&lt;/a&gt;&lt;/strong&gt; (from Facebook) released with the paper &lt;a href=&#34;https://arxiv.org/abs/1904.01038&#34;&gt;fairseq: A Fast, Extensible Toolkit for Sequence Modeling&lt;/a&gt; by Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/roformer&#34;&gt;RoFormer&lt;/a&gt;&lt;/strong&gt; (from ZhuiyiTechnology), released together with the paper &lt;a href=&#34;https://arxiv.org/abs/2104.09864&#34;&gt;RoFormer: Enhanced Transformer with Rotary Position Embedding&lt;/a&gt; by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/main/model_doc/siglip&#34;&gt;SigLIP&lt;/a&gt;&lt;/strong&gt; (from Google AI) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2303.15343&#34;&gt;Sigmoid Loss for Language Image Pre-Training&lt;/a&gt; by Xiaohua Zhai, Basil Mustafa, Alexander Kolesnikov, Lucas Beyer.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/swin2sr&#34;&gt;Swin2SR&lt;/a&gt;&lt;/strong&gt; (from University of W√ºrzburg) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2209.11345&#34;&gt;Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration&lt;/a&gt; by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/t5&#34;&gt;T5&lt;/a&gt;&lt;/strong&gt; (from Google AI) released with the paper &lt;a href=&#34;https://arxiv.org/abs/1910.10683&#34;&gt;Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer&lt;/a&gt; by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/t5v1.1&#34;&gt;T5v1.1&lt;/a&gt;&lt;/strong&gt; (from Google AI) released in the repository &lt;a href=&#34;https://github.com/google-research/text-to-text-transfer-transformer/raw/main/released_checkpoints.md#t511&#34;&gt;google-research/text-to-text-transfer-transformer&lt;/a&gt; by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/trocr&#34;&gt;TrOCR&lt;/a&gt;&lt;/strong&gt; (from Microsoft), released together with the paper &lt;a href=&#34;https://arxiv.org/abs/2109.10282&#34;&gt;TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models&lt;/a&gt; by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/vit&#34;&gt;Vision Transformer (ViT)&lt;/a&gt;&lt;/strong&gt; (from Google AI) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2010.11929&#34;&gt;An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale&lt;/a&gt; by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/yolos&#34;&gt;YOLOS&lt;/a&gt;&lt;/strong&gt; (from Huazhong University of Science &amp;amp; Technology) released with the paper &lt;a href=&#34;https://arxiv.org/abs/2106.00666&#34;&gt;You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection&lt;/a&gt; by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
</feed>