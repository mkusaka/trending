<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Swift Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-09T01:44:52Z</updated>
  <subtitle>Daily Trending of Swift in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>SerenaKit/Samra</title>
    <updated>2023-03-09T01:44:52Z</updated>
    <id>tag:github.com,2023-03-09:/SerenaKit/Samra</id>
    <link href="https://github.com/SerenaKit/Samra" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Proper, full-fledged native Asset Catalog explorer &amp; editor for macOS.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Samra&lt;/h1&gt; &#xA;&lt;p&gt;A macOS Application to explore and edit Asset Catalog (.car) files on macOS, with a nicer native, modern-feeling UI that does not crash every couple of seconds.&lt;/p&gt; &#xA;&lt;img width=&#34;800&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/48022799/222929188-7eb62314-8433-42c6-baf5-5d851b679998.png&#34;&gt; &#xA;&lt;h2&gt;Why Samra?&lt;/h2&gt; &#xA;&lt;p&gt;There are a few existing asset catalog viewer applications for macOS, however, none felt feature complete, Samra offers the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Browse through the Asset Catalog file&lt;/li&gt; &#xA; &lt;li&gt;Show all types of objects (renditions) in it, not just images (colors, pdfs, image sets, etc)&lt;/li&gt; &#xA; &lt;li&gt;Ability to edit icons/images &amp;amp; colors&lt;/li&gt; &#xA; &lt;li&gt;Search in Asset Catalog for renditions by name&lt;/li&gt; &#xA; &lt;li&gt;View detailed information about each rendition, such as lookup name, width, height, appearance (if it&#39;s meant for dark mode or light mode) and other type-specific information (ie, RGB values for colors).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What versions does this support?&lt;/h2&gt; &#xA;&lt;p&gt;macOS 10.15.1+&lt;/p&gt; &#xA;&lt;h2&gt;How can I download this?&lt;/h2&gt; &#xA;&lt;p&gt;Download the .app from the Releases&lt;/p&gt; &#xA;&lt;h2&gt;Preview&lt;/h2&gt; &#xA;&lt;img width=&#34;962&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/48022799/222929053-45e75bed-4398-4670-8280-dfbd1ff13eb2.png&#34;&gt; &#xA;&lt;img width=&#34;1099&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/48022799/222929119-4f9e043c-fdbf-4e39-9137-f344fc693da4.png&#34;&gt; &#xA;&lt;img width=&#34;493&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/48022799/222929132-4e5ee546-18b5-492f-a4a6-5599c1b76a20.png&#34;&gt; &#xA;&lt;img width=&#34;753&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/48022799/222929151-6355f60a-757e-4b17-bc4a-cb25213e8e8c.png&#34;&gt;</summary>
  </entry>
  <entry>
    <title>heysaik/ChatGPTKit</title>
    <updated>2023-03-09T01:44:52Z</updated>
    <id>tag:github.com,2023-03-09:/heysaik/ChatGPTKit</id>
    <link href="https://github.com/heysaik/ChatGPTKit" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Swift Package to communicate with the ChatGPT API from OpenAI&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGPTKit&lt;/h1&gt; &#xA;&lt;p&gt;A very simple Swifty API to use ChatGPT from OpenAI. Please let me know if you find any errors.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;In your Xcode project, go to File -&amp;gt; Add Packages&lt;/li&gt; &#xA; &lt;li&gt;Enter the package URL: &lt;code&gt;https://github.com/heysaik/ChatGPTKit&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Click on &lt;strong&gt;Add Package&lt;/strong&gt; and let Xcode install the Swift Package&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;let chattyGPT = ChatGPTKit(apiKey: &#34;YOUR-API-KEY&#34;)&#xA;var history = [Message(role: .system, content: &#34;You are a bot designed to aid mental health.&#34;), Message(role: .user, content: &#34;Hello! I&#39;m feeling rather sad today.&#34;)]&#xA;&#xA;switch try await chattyGPT.performCompletions(messages: history) {&#xA;case .success(let response):&#xA;    if let firstResponse = response.choices?.first {&#xA;        history.append(firstResponse.message)&#xA;        print(firstResponse.message.content)&#xA;    }&#xA;case .failure(let error):&#xA;    print(error.message)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Types&lt;/h2&gt; &#xA;&lt;p&gt;This can help you understand how to use the package better. This is an exact Swift copy of the response object from the OpenAI API.&lt;/p&gt; &#xA;&lt;h3&gt;Model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;enum Model {&#xA;    case turbo&#xA;    case turbo31&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Role&lt;/h3&gt; &#xA;&lt;p&gt;Typically, a conversation is formatted with a system message first, followed by alternating user and assistant messages.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The system message helps set the behavior of the assistant.&lt;/li&gt; &#xA; &lt;li&gt;The user messages help instruct the assistant. They can be generated by the end users of an application, or set by a developer as an instruction.&lt;/li&gt; &#xA; &lt;li&gt;The assistant messages help store prior responses. They can also be written by a developer to help give examples of desired behavior.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;enum Role {&#xA;    case system&#xA;    case user&#xA;    case assistant&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Message&lt;/h3&gt; &#xA;&lt;p&gt;Messages must be an array of message objects, where each object has a role (either “system”, “user”, or “assistant”) and content (the content of the message). Conversations can be as short as 1 message or fill many pages.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;struct Message {&#xA;    var role: Role&#xA;    var content: String&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;APIUsage&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;struct APIUsage {&#xA;    var prompt_tokens: Int&#xA;    var completion_tokens: Int&#xA;    var total_tokens: Int&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ResponseChoice&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;struct ResponseChoice {&#xA;    var index: Int&#xA;    var message: Message&#xA;    var finish_reason: String&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Response&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;struct Response {&#xA;    var id: String&#xA;    var object: String&#xA;    var created: Int&#xA;    var choices: [ResponseChoice]&#xA;    var usage: APIUsage&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;APIError&lt;/h3&gt; &#xA;&lt;p&gt;APIError is the default Error type this package returns. If the OpenAI API returns an error, it will be of this type and you can get the code, message, and type. If there is another error from the client side, you can read the error property to understand the error.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;struct APIError: Error {&#xA;    public var code: Int?&#xA;    public var message: String&#xA;    public var type: String?&#xA;    public var error: Error?&#xA;    &#xA;    public init(code: Int? = nil, message: String, type: String? = nil, error: Error? = nil) {&#xA;        self.code = code&#xA;        self.message = message&#xA;        self.type = type&#xA;        self.error = error&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ErrorResponse&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;struct ErrorResponse {&#xA;    var error: APIError&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Compatibility&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;iOS 13.0+&lt;/li&gt; &#xA; &lt;li&gt;macOS 13.0+&lt;/li&gt; &#xA; &lt;li&gt;watchOS 9.0+&lt;/li&gt; &#xA; &lt;li&gt;tvOS 16.0+&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>