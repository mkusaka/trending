<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-17T01:47:10Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>alexschachne/leap-ai-avatars</title>
    <updated>2023-04-17T01:47:10Z</updated>
    <id>tag:github.com,2023-04-17:/alexschachne/leap-ai-avatars</id>
    <link href="https://github.com/alexschachne/leap-ai-avatars" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;leap ai avatars ‚ö°Ô∏è&lt;/h1&gt; &#xA;&lt;p&gt;welcome! this repo has everything you need to have a working ai avatars product out-of-the-box built with Leap AI. ‚ú®&lt;/p&gt; &#xA;&lt;p&gt;try it out &lt;a href=&#34;https://ai-avatars.vercel.app/&#34;&gt;here&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;p&gt;let&#39;s get started by forking this repository (button top right), and downloading it to your computer. from there follow the below :)&lt;/p&gt; &#xA;&lt;h3&gt;run it locally&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open the terminal&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;npm install&lt;/code&gt; to grab the neccesary packages&lt;/li&gt; &#xA; &lt;li&gt;Hit &lt;code&gt;npm run dev&lt;/code&gt; to start your server on &lt;code&gt;http://localhost:3000&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;how to get ai avatars&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Upload 3-10 photos of yourself&lt;/li&gt; &#xA; &lt;li&gt;Add your API Key from Leap AI&lt;/li&gt; &#xA; &lt;li&gt;(Optional) add your model ID from Leap AI to use your existing models&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;making it your own&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Head to &lt;code&gt;pages/index.tsx&lt;/code&gt; for editing text, prompts, and colors to match your theme&lt;/li&gt; &#xA; &lt;li&gt;Adjust prompts and subjectKeyword (ie. @me) in &lt;code&gt;helpers/prompts.ts&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Adjust the number of images generated w/ the numberOfImages parameter in &lt;code&gt;/pages/api/generate&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;deploy to the world&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Push all your changes to Github (or another git provider)&lt;/li&gt; &#xA; &lt;li&gt;Head to vercel.app, import your repo, and hit deploy&lt;/li&gt; &#xA; &lt;li&gt;note: you will need vercel pro plan or &lt;code&gt;/pages/api/generate&lt;/code&gt; call will likely timeout after 10 sec. You can also deploy on &lt;a href=&#34;https://zeet.co/&#34;&gt;Zeet&lt;/a&gt; to avoid this issue.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;you&#39;ve got off localhost üëè&lt;/h3&gt; &#xA;&lt;p&gt;This is huge! You&#39;ve got an AI Avatars app running on the web, and you can share it with the world.&lt;/p&gt; &#xA;&lt;p&gt;if you got value from this -- plz give us a star üôÇ‚≠ê&lt;/p&gt; &#xA;&lt;p&gt;built w/ ‚ù§Ô∏è by &lt;a href=&#34;https://twitter.com/thealexshaq&#34;&gt;alex&lt;/a&gt; with &lt;a href=&#34;https://tryleap.ai&#34;&gt;Leap AI&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ericciarla/babyagijs</title>
    <updated>2023-04-17T01:47:10Z</updated>
    <id>tag:github.com,2023-04-17:/ericciarla/babyagijs</id>
    <link href="https://github.com/ericciarla/babyagijs" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AI-powered task management system in Javascript&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;BabyAGI JS&lt;/h1&gt; &#xA;&lt;p&gt;BabyAGI JS is a JavaScript-based AI agent that creates, prioritizes, and executes tasks using the GPT 3.5 or GPT 4 architecture. It integrates with OpenAI&#39;s language model to create a powerful AI that can handle a wide range of tasks.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Task creation: Generates new tasks based on the current context and objectives.&lt;/li&gt; &#xA; &lt;li&gt;Task prioritization: Reorders tasks according to their importance and relevance to the main objective.&lt;/li&gt; &#xA; &lt;li&gt;Task execution: Performs tasks and returns results.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to use&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repository.&lt;/li&gt; &#xA; &lt;li&gt;Add API keys to your .env&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;OPENAI_API_KEY=&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Install the required dependencies using &lt;code&gt;npm install&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Write your code in the &lt;code&gt;src&lt;/code&gt; directory.&lt;/li&gt; &#xA; &lt;li&gt;Run your program with &lt;code&gt;npm run start&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Main Files&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;code&gt;src/index.ts&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;This file initializes the BabyAGI agent with the required configurations, including the language model and objective. It imports the &lt;code&gt;BabyAGI&lt;/code&gt; class from &lt;code&gt;babyagi.js&lt;/code&gt; and creates a new instance to perform tasks based on the given objective.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;src/babyagi.ts&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;This file contains the core implementation of the BabyAGI agent. It defines three main classes, &lt;code&gt;TaskCreationChain&lt;/code&gt;, &lt;code&gt;TaskPrioritizationChain&lt;/code&gt;, and &lt;code&gt;ExecutionChain&lt;/code&gt;, which are responsible for creating, prioritizing, and executing tasks, respectively.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;BabyAGI&lt;/code&gt; class combines these three classes and provides methods to add tasks, print tasks, and execute tasks. The &lt;code&gt;call&lt;/code&gt; method is the main entry point to start the agent&#39;s task processing loop.&lt;/p&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;The following is an example of how to use the BabyAGI agent:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Set the objective in &lt;code&gt;src/index.ts&lt;/code&gt;:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const OBJECTIVE = &#39;Integrate stripe in typescript&#39;;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Run the program with &lt;code&gt;npm run start&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The BabyAGI agent will create, prioritize, and execute tasks based on the given objective.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions to improve BabyAGI JS. Feel free to open an issue or submit a pull request.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the MIT License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>riwigefi/light-gpt</title>
    <updated>2023-04-17T01:47:10Z</updated>
    <id>tag:github.com,2023-04-17:/riwigefi/light-gpt</id>
    <link href="https://github.com/riwigefi/light-gpt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Light-GPT is an interactive website project based on the GPT-3.5-Turbo Model.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Light-GPT&lt;/h1&gt; &#xA;&lt;p&gt;Light-GPT is an interactive website project based on the GPT-3.5-Turbo model. It is built using the Next.js framework and deployed on the Vercel cloud platform. It is a pure front-end lightweight application.&lt;/p&gt; &#xA;&lt;p&gt;Github: &lt;a href=&#34;https://github.com/riwigefi/light-gpt&#34;&gt;https://github.com/riwigefi/light-gpt&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Demo: &lt;a href=&#34;https://light-gpt.vercel.app&#34;&gt;https://light-gpt.vercel.app&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;A pure front-end application based on the GPT-3.5-Turbo model, using API KEY to request OpenAI&#39;s dialogue interface in the front-end, supporting streaming data, and displaying robot replies on the webpage in a typewriter effect.&lt;/li&gt; &#xA; &lt;li&gt;After deployment, users can set their API KEY on the front-end page. With scientific internet access, the Q&amp;amp;A speed will be very fast. The user&#39;s API KEY will be saved on the client-side, which means there is no risk of leakage.&lt;/li&gt; &#xA; &lt;li&gt;Supports new thematic dialogues and viewing of historical thematic dialogues. All dialogue data is stored in the IndexedDB of the browser, which means that dialogue data records are saved locally and there is no risk of data leakage.&lt;/li&gt; &#xA; &lt;li&gt;AI replies to programming-related questions support multiple syntax highlighting and one-click code copying. Dialogues support image export and PDF export.&lt;/li&gt; &#xA; &lt;li&gt;The application is adapted for both PC and mobile devices, making it convenient to use.&lt;/li&gt; &#xA; &lt;li&gt;DIY, supporting setting user avatars and AI avatars.&lt;/li&gt; &#xA; &lt;li&gt;Support generating images based on text.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Site Preview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/riwigefi/light-gpt/master/public/light-mode-site.png&#34; alt=&#34;Site Preview Light Mode&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/riwigefi/light-gpt/master/public/dark-mode-site.png&#34; alt=&#34;Site Preview Dark Mode&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Local Deployment&lt;/h2&gt; &#xA;&lt;p&gt;To deploy Light-GPT locally, follow these steps (requires node16.14.2 or higher):&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download the project to your local machine:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/riwigefi/light-gpt.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Navigate to the project directory and install dependencies:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd light-gpt&#xA;pnpm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Start the application:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pnpm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The project will now be available for preview at &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt;. Enter your API KEY on the front-end page to start chatting.&lt;/p&gt; &#xA;&lt;h2&gt;Vercel Online Deployment&lt;/h2&gt; &#xA;&lt;p&gt;To deploy Light-GPT on Vercel&#39;s cloud platform:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Register for a Vercel account at &lt;a href=&#34;https://vercel.com&#34;&gt;Vercel&lt;/a&gt;. A mobile verification code is required.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Fork the &lt;a href=&#34;https://github.com/riwigefi/light-gpt&#34;&gt;light-gpt&lt;/a&gt; repository to your own Github account.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Log in to the Vercel platform, click &#34;Add New&#34;, select &#34;Project&#34;, and then import the Github project you just forked. Click &#34;Deploy&#34;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Docker Local Deployment&lt;/h2&gt; &#xA;&lt;p&gt;For those who prefer to use Docker for local deployment:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Pull the latest Docker image:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker pull whynotisme/light-gpt:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Run the image and map port 3000 to port 3000:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -p 3000:3000 whynotisme/light-gpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Light-GPT&lt;/h1&gt; &#xA;&lt;p&gt;Light-GPT ÊòØ‰∏Ä‰∏™Âü∫‰∫é GPT-3.5-Turbo Ê®°ÂûãÁöÑ‰∫§‰∫íÂºèÁΩëÁ´ôÈ°πÁõÆÔºå‰ΩøÁî® Next.js Ê°ÜÊû∂ÊûÑÂª∫Ôºå‰ΩøÁî® Vercel ‰∫ëÂπ≥Âè∞ÈÉ®ÁΩ≤ÔºåÊòØ‰∏Ä‰∏™Á∫ØÂâçÁ´ØÁöÑËΩªÈáèÁ∫ßÂ∫îÁî®„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Github ‰ª£Á†ÅÂ∫ì: &lt;a href=&#34;https://github.com/riwigefi/light-gpt&#34;&gt;https://github.com/riwigefi/light-gpt&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;ÊºîÁ§∫Á´ôÁÇπ: &lt;a href=&#34;https://light-gpt.vercel.app&#34;&gt;https://light-gpt.vercel.app&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ÂäüËÉΩ&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Á∫ØÂâçÁ´ØÂ∫îÁî®ÔºåÂü∫‰∫é GPT-3.5-Turbo Ê®°ÂûãÔºå‰ΩøÁî® API KEY Âú®ÂâçÁ´ØËØ∑Ê±Ç OpenAI ÁöÑÂØπËØùÊé•Âè£ÔºåÊîØÊåÅÊµÅÂºèÊï∞ÊçÆÔºåÈ°µÈù¢‰ª•ÊâìÂ≠óÊú∫ÊïàÊûúÊòæÁ§∫Êú∫Âô®‰∫∫ÂõûÂ§ç„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÈÉ®ÁΩ≤ÂêéÔºåÁî®Êà∑Âú®ÂâçÁ´ØÈ°µÈù¢ËÆæÁΩÆËá™Â∑±ÁöÑ API KEYÔºåÁßëÂ≠¶‰∏äÁΩëÁöÑÊÉÖÂÜµ‰∏ãÔºåÈóÆÁ≠îÈÄüÂ∫¶‰ºöÂæàÂø´„ÄÇÁî®Êà∑ËÆæÁΩÆÁöÑ API KEY Â∞Ü‰øùÂ≠òÂú®ÂÆ¢Êà∑Á´ØÔºåÂÆåÂÖ®Ê≤°ÊúâÊ≥ÑÊºèÈ£éÈô©„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅÊñ∞ÁöÑ‰∏ªÈ¢òÂØπËØùÂíåÊü•ÁúãÂéÜÂè≤‰∏ªÈ¢òÂØπËØù„ÄÇÊâÄÊúâÂØπËØùÊï∞ÊçÆÈÉΩÂ≠òÂÇ®Âú®ÊµèËßàÂô®ÁöÑ IndexedDB ‰∏≠Ôºå‰πüÂ∞±ÊòØËØ¥ÂØπËØùÊï∞ÊçÆËÆ∞ÂΩïÊòØ‰øùÂ≠òÂú®Êú¨Âú∞ÁöÑÔºå‰∏ç‰ºöÊúâÊï∞ÊçÆÊ≥ÑÊºèÈ£éÈô©„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;AI ÂõûÂ§çÊîØÊåÅÂ§öÁßçËØ≠Ê≥ïÈ´ò‰∫ÆÂíå‰∏ÄÈîÆÂ§çÂà∂‰ª£Á†ÅÂäüËÉΩÔºåÈíàÂØπÁºñÁ®ãÁõ∏ÂÖ≥ÈóÆÈ¢ò„ÄÇÂØπËØùÊîØÊåÅÂõæÁâáÂíå PDF ÂØºÂá∫„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;Â∫îÁî®ÈÄÇÈÖç‰∫Ü PC Âíå Mobile ËÆæÂ§áÔºåÊñπ‰æø‰ΩøÁî®„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅ DIYÔºåÊîØÊåÅËÆæÁΩÆÁî®Êà∑Â§¥ÂÉèÂíå AI Â§¥ÂÉè„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÊîØÊåÅÊ†πÊçÆÊñáÂ≠óÁîüÊàêÂõæÁâá&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Á´ôÁÇπÈ¢ÑËßà&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/riwigefi/light-gpt/master/public/light-mode-site.png&#34; alt=&#34;Site Preview Light Mode&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/riwigefi/light-gpt/master/public/dark-mode-site.png&#34; alt=&#34;Site Preview Dark Mode&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Êú¨Âú∞ÈÉ®ÁΩ≤&lt;/h2&gt; &#xA;&lt;p&gt;Ë¶ÅÂú®Êú¨Âú∞ÈÉ®ÁΩ≤ Light-GPTÔºåÊåâÁÖß‰ª•‰∏ãÊ≠•È™§Êìç‰Ωú(ÈúÄË¶Å node16.14.2 Âèä‰ª•‰∏äÁâàÊú¨)Ôºö&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Â∞ÜÈ°πÁõÆ‰∏ãËΩΩÂà∞Êú¨Âú∞:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/riwigefi/light-gpt.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;ËøõÂÖ•È°πÁõÆÁõÆÂΩïÂπ∂ÂÆâË£Ö‰æùËµñÈ°π:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd light-gpt&#xA;pnpm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;ÂêØÂä®Â∫îÁî®Á®ãÂ∫è:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pnpm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ËøôÊ†∑ÔºåÈ°πÁõÆÂ∞±ËÉΩÂú® &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt; ‰∏äÈ¢ÑËßà‰∫Ü„ÄÇÂú®ÂâçÁ´ØÈ°µÈù¢ËæìÂÖ•‰Ω†ÁöÑ API KEYÔºåÂ∞±ÂèØ‰ª•ÊÑâÂø´ÂØπËØù‰∫Ü„ÄÇ&lt;/p&gt; &#xA;&lt;h2&gt;Vercel Á∫ø‰∏äÈÉ®ÁΩ≤&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Ê≥®ÂÜå‰∏Ä‰∏™ Vercel ‰∫ëÂπ≥Âè∞ÈÉ®ÁΩ≤Ë¥¶Âè∑ÔºåËÆøÈóÆ &lt;a href=&#34;https://vercel.com&#34;&gt;Vercel&lt;/a&gt;„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;Â∞Ü &lt;a href=&#34;https://github.com/riwigefi/light-gpt&#34;&gt;light-gpt&lt;/a&gt; ÂΩìÂâç‰ªìÂ∫ì fork Âà∞‰Ω†ÁöÑ Github„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;ÁôªÂΩï Vercel Âπ≥Âè∞ÔºåÁÇπÂáª &#34;Add New&#34;ÔºåÈÄâÊã© &#34;Project&#34;ÔºåÁÑ∂Âêé import ÂàöÂàö fork ÁöÑ Github È°πÁõÆÔºåÁÇπÂáªÈÉ®ÁΩ≤Âç≥ÂèØ„ÄÇ&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Docker Êú¨Âú∞ÈÉ®ÁΩ≤&lt;/h2&gt; &#xA;&lt;p&gt;‰∏∫Êñπ‰æø‰ΩøÁî®ÔºåÊú¨È°πÁõÆ‰πüÊèê‰æõ‰∫Ü Docker ÈïúÂÉè„ÄÇ&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ÊãâÂèñÊúÄÊñ∞ÁöÑ Docker ÈïúÂÉè:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker pull whynotisme/light-gpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;ËøêË°åÈïúÂÉè ÔºåÂ∞Ü Docker ÂÆπÂô®ÂÜÖÁöÑÁ´ØÂè£ 3000 Êò†Â∞ÑÂà∞‰∏ªÊú∫ÁöÑÁ´ØÂè£ 3000 ‰∏ä:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -p 3000:3000 whynotisme/light-gpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ÈáçË¶ÅÊèêÁ§∫&lt;/h2&gt; &#xA;&lt;p&gt;Êú¨Âú∞ÈÉ®ÁΩ≤Êó∂ÔºåÂè™ÈúÄË¶ÅÊîØÊåÅÊµèËßàÂô®ÂèØÁßëÂ≠¶‰∏äÁΩëÂç≥ÂèØÔºåÂõ†‰∏∫ËØ∑Ê±ÇÊòØÂú®ÊµèËßàÂô®ÂèëËµ∑ÁöÑ„ÄÇ&lt;strong&gt;Áî±‰∫é OpenAi È£éÊéßÊîøÁ≠ñÔºåËØ∑Âä°ÂøÖ‰øùËØÅ‰Ω†ÊòØÁßëÂ≠¶‰∏äÁΩëÁéØÂ¢ÉÔºå‰Ω†ÂèØ‰ª•Ê≠£Â∏∏ËÆøÈóÆ open ai ÂÆòÁΩëÔºåÂ¶ÇÊûú‰∏çËÉΩÔºåËØ∑‰∏çË¶ÅËÆæÁΩÆ api key ËøõË°åË∞ÉËØïÔºåÂê¶Âàô‰ºöÊúâÂºÇÂ∏∏È£éÈô©&lt;/strong&gt;&lt;/p&gt;</summary>
  </entry>
</feed>