<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-04T01:38:56Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>RedisInsight/RedisInsight</title>
    <updated>2022-12-04T01:38:56Z</updated>
    <id>tag:github.com,2022-12-04:/RedisInsight/RedisInsight</id>
    <link href="https://github.com/RedisInsight/RedisInsight" rel="alternate"></link>
    <summary type="html">&lt;p&gt;RedisInsight&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/RedisInsight/RedisInsight/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/RedisInsight/RedisInsight.svg?sort=semver&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://circleci.com/gh/RedisInsight/RedisInsight/tree/main&#34;&gt;&lt;img src=&#34;https://circleci.com/gh/RedisInsight/RedisInsight/tree/main.svg?style=svg&#34; alt=&#34;CircleCI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://lgtm.com/projects/g/RedisInsight/RedisInsight/alerts/&#34;&gt;&lt;img src=&#34;https://img.shields.io/lgtm/alerts/g/RedisInsight/RedisInsight.svg?logo=lgtm&amp;amp;logoWidth=18&#34; alt=&#34;Total alerts&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;img src=&#34;https://redis.com/wp-content/uploads/2019/11/ico-redisinsight.svg?sanitize=true&#34; alt=&#34;logo&#34; width=&#34;25&#34;&gt; RedisInsight - Developer GUI for Redis, by Redis.&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://forum.redis.com/c/redisinsight/65&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Forum-RedisInsight-red&#34; alt=&#34;Forum&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/QUkjSsk&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/697882427875393627?style=flat-square&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;RedisInsight is a visual tool that provides capabilities to design, develop and optimize your Redis application. Query, analyse and interact with your Redis data. &lt;a href=&#34;https://redis.com/redis-enterprise/redis-insight/#insight-form&#34;&gt;Download it here&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/RedisInsight/RedisInsight/main/.github/redisinsight_browser.png&#34; alt=&#34;RedisInsight Browser screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Built with love using &lt;a href=&#34;https://www.electronjs.org/&#34;&gt;Electron&lt;/a&gt;, &lt;a href=&#34;https://microsoft.github.io/monaco-editor/&#34;&gt;Monaco Editor&lt;/a&gt; and NodeJS.&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;RedisInsight is an intuitive and efficient GUI for Redis, allowing you to interact with your databases and manage your dataâ€”with built-in support for Redis modules.&lt;/p&gt; &#xA;&lt;h3&gt;RedisInsight Highlights:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Browse, filter, visualise your key-value Redis data structures and see key values in different formats (including JSON, Hex, ASCII, etc.)&lt;/li&gt; &#xA; &lt;li&gt;CRUD support for Lists, Hashes, Strings, Sets, Sorted Sets, and Streams&lt;/li&gt; &#xA; &lt;li&gt;CRUD support for &lt;a href=&#34;https://oss.redis.com/redisjson/&#34;&gt;RedisJSON&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Profiler - analyze every command sent to Redis in real-time&lt;/li&gt; &#xA; &lt;li&gt;SlowLog - analyze slow operations in Redis instances based on the &lt;a href=&#34;https://github.com/RedisInsight/RedisInsight/releases#:~:text=results%20of%20the-,Slowlog,-command%20to%20analyze&#34;&gt;Slowlog&lt;/a&gt; command&lt;/li&gt; &#xA; &lt;li&gt;Pub/Sub - support for &lt;a href=&#34;https://redis.io/docs/manual/pubsub/&#34;&gt;Redis pub/sub&lt;/a&gt;, enabling subscription to channels and posting messages to channels&lt;/li&gt; &#xA; &lt;li&gt;Bulk actions - Delete the keys in bulk based on the filters set in Browser or Tree view&lt;/li&gt; &#xA; &lt;li&gt;Introducing Workbench - advanced command line interface with intelligent command auto-complete, complex data visualizations and support for the raw mode&lt;/li&gt; &#xA; &lt;li&gt;Command auto-complete support for &lt;a href=&#34;https://oss.redis.com/redisearch/&#34;&gt;RediSearch&lt;/a&gt;, &lt;a href=&#34;https://oss.redis.com/redisjson/&#34;&gt;RedisJSON&lt;/a&gt;, &lt;a href=&#34;https://oss.redis.com/redisgraph/&#34;&gt;RedisGraph&lt;/a&gt;, &lt;a href=&#34;https://oss.redis.com/redistimeseries/&#34;&gt;RedisTimeSeries&lt;/a&gt;, &lt;a href=&#34;https://oss.redis.com/redisai/&#34;&gt;RedisAI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Visualizations of your &lt;a href=&#34;https://oss.redis.com/redisearch/&#34;&gt;RediSearch&lt;/a&gt; index, queries, and aggregations&lt;/li&gt; &#xA; &lt;li&gt;Ability to build your own data visualization plugins&lt;/li&gt; &#xA; &lt;li&gt;Built-in click-through guides for Redis capabilities&lt;/li&gt; &#xA; &lt;li&gt;Oficially supported for Redis OSS, &lt;a href=&#34;https://redis.com/try-free/&#34;&gt;Redis Cloud&lt;/a&gt;. Works with Microsoft Azure Cache for Redis (official support upcoming).&lt;/li&gt; &#xA; &lt;li&gt;Available for macOS (including M1), Windows and Linux&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Check out the &lt;a href=&#34;https://docs.redis.com/latest/ri/release-notes/&#34;&gt;release notes&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Get started with RedisInsight&lt;/h2&gt; &#xA;&lt;p&gt;This repository includes the code for the GA version of RedisInsight 2.0. Check out the &lt;a href=&#34;https://redis.com/blog/introducing-redisinsight-2/&#34;&gt;blogpost&lt;/a&gt; announcing it.&lt;/p&gt; &#xA;&lt;h3&gt;Installable&lt;/h3&gt; &#xA;&lt;p&gt;Available to download for free from &lt;a href=&#34;https://redis.com/redis-enterprise/redis-insight/#insight-form&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Build&lt;/h3&gt; &#xA;&lt;p&gt;Alternatively you can also build from source. See our wiki for instructions.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/RedisInsight/RedisInsight/wiki/How-to-build-and-contribute&#34;&gt;How to build&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Feedback&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Request a new &lt;a href=&#34;https://github.com/RedisInsight/RedisInsight/issues/new?assignees=&amp;amp;labels=&amp;amp;template=feature_request.md&amp;amp;title=%5BFeature+Request%5D%3A&#34;&gt;feature&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Upvote &lt;a href=&#34;https://github.com/RedisInsight/RedisInsight/issues?q=is%3Aopen+is%3Aissue+label%3Afeature+sort%3Areactions-%2B1-desc&#34;&gt;popular feature requests&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;File a &lt;a href=&#34;https://github.com/RedisInsight/RedisInsight/issues/new?assignees=&amp;amp;labels=&amp;amp;template=bug_report.md&amp;amp;title=%5BBug%5D%3A&#34;&gt;bug&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;RedisInsight Plugins&lt;/h2&gt; &#xA;&lt;p&gt;With RedisInsight you can now also extend the core functionality by building your own data visualizations. See our wiki for more information.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/RedisInsight/RedisInsight/wiki/Plugin-Documentation&#34;&gt;Plugin Documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;If you would like to contribute to the code base or fix and issue, please consult the wiki.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/RedisInsight/RedisInsight/wiki/How-to-build-and-contribute&#34;&gt;How to build and contribute&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Telemetry&lt;/h2&gt; &#xA;&lt;p&gt;RedisInsight includes an opt-in telemetry system, that is leveraged to help improve the developer experience (DX) within the app. We value your privacy, so stay assured, that all the data collected is anonymised.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;RedisInsight is licensed under &lt;a href=&#34;https://raw.githubusercontent.com/RedisInsight/RedisInsight/main/LICENSE&#34;&gt;SSPL&lt;/a&gt; license.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>amandaghassaei/gpu-io</title>
    <updated>2022-12-04T01:38:56Z</updated>
    <id>tag:github.com,2022-12-04:/amandaghassaei/gpu-io</id>
    <link href="https://github.com/amandaghassaei/gpu-io" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A GPU-accelerated computing library for physics simulations and other mathematical calculations&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;gpu-io&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://apps.amandaghassaei.com/gpu-io/examples/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/amandaghassaei/gpu-io/main/docs/main-image.jpg&#34; alt=&#34;gpu-io main image&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.npmjs.com/package/gpu-io&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/gpu-io&#34; alt=&#34;NPM Package&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://bundlephobia.com/result?p=gpu-io&#34;&gt;&lt;img src=&#34;https://img.shields.io/bundlephobia/min/gpu-io&#34; alt=&#34;Build Size&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.npmtrends.com/gpu-io&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/dw/gpu-io&#34; alt=&#34;NPM Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/amandaghassaei/gpu-io/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/l/gpu-io&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A GPU-accelerated computing library for physics simulations and other mathematical calculations&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;gpu-io is a WebGL library that helps you easily compose GPU-accelerated computing workflows. This library can be used for a variety of applications including real-time physics simulations, particle/agent-based simulations, cellular automata, image processing, and general purpose GPU computations. gpu-io supports rendering directly to the WebGL canvas and has some built-in features that make interactivity easy. See &lt;a href=&#34;https://apps.amandaghassaei.com/gpu-io/examples/&#34;&gt;Examples&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;p&gt;Designed for WebGL 2.0 (if available), with fallbacks to support WebGL 1.0 - so it should run on practically any mobile or older browsers. WebGPU support is planned in the future.&lt;/p&gt; &#xA;&lt;h3&gt;Motivation&lt;/h3&gt; &#xA;&lt;p&gt;The main motivation behind gpu-io is to make it easier to compose GPU-accelerated applications without worrying too much about low-level WebGL details. This library manages WebGL state, implements shader and program caching, and deals with issues of available WebGL versions or spec inconsistencies across different browsers/hardware. It should significantly cut down on the amount of boilerplate code and state management you need to do in your applications. At the same time, gpu-io gives you enough low-level control to write extremely efficient programs for computationally demanding applications.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.khronos.org/blog/webgl-2-achieves-pervasive-support-from-all-major-web-browsers&#34;&gt;As of Feb 2022, WebGL2 has now been rolled out to all major platforms&lt;/a&gt; (including mobile Safari and Microsoft Edge) - but even among WebGL2 implementations, there are differences in behavior across browsers (especially mobile). Additionally, you may still come across non-WebGL2 enabled browsers in the wild for some time. gpu-io rigorously checks for these gotchas and uses software polyfills to patch any issues so you don&#39;t have to worry about it. gpu-io will also attempt to automatically &lt;a href=&#34;https://github.com/amandaghassaei/gpu-io/raw/main/docs/GLSL1_Support.md&#34;&gt;convert your GLSL3 shader code into GLSL1&lt;/a&gt; so that it can run in WebGL1 in a pinch. See &lt;a href=&#34;https://github.com/amandaghassaei/gpu-io/tree/main/tests#browser-support&#34;&gt;tests/README.md&lt;/a&gt; for more information on browser support.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/amandaghassaei/gpu-io/main/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/amandaghassaei/gpu-io/main/#use&#34;&gt;Use&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/amandaghassaei/gpu-io/main/#examples&#34;&gt;Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/amandaghassaei/gpu-io/main/#api&#34;&gt;API&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/amandaghassaei/gpu-io/main/#compatibility-with-threejs&#34;&gt;Compatibility with Threejs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/amandaghassaei/gpu-io/main/#limitationsnotes&#34;&gt;Limitations/Notes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/amandaghassaei/gpu-io/main/#acknowledgements&#34;&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/amandaghassaei/gpu-io/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/amandaghassaei/gpu-io/main/#development&#34;&gt;Development&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Install via npm&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;npm install gpu-io&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;And import into your project:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import { GPUComposer, GPULayer, GPUProgram } from &#39;gpu-io&#39;;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Import into HTML&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;OR&lt;/em&gt; you can add &lt;a href=&#34;https://raw.githubusercontent.com/amandaghassaei/gpu-io/main/dist/gpu-io.js&#34;&gt;gpu-io.js&lt;/a&gt; or &lt;a href=&#34;https://raw.githubusercontent.com/amandaghassaei/gpu-io/main/dist/gpu-io.min.js&#34;&gt;gpu-io.min.js&lt;/a&gt; to your html directly:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;html&amp;gt;&#xA;  &amp;lt;head&amp;gt;&#xA;    &amp;lt;script src=&#34;gpu-io.js&#34;&amp;gt;&amp;lt;/script&amp;gt;&#xA;  &amp;lt;/head&amp;gt;&#xA;  &amp;lt;body&amp;gt;&#xA;  &amp;lt;/body&amp;gt;&#xA;&amp;lt;/html&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;GPUIO will be accessible globally:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const { GPUComposer, GPULayer, GPUProgram } = GPUIO;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Use&lt;/h2&gt; &#xA;&lt;p&gt;A simple example of how to use gpu-io to simulate 2D diffusion:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import {&#xA;  GPUComposer,&#xA;  GPULayer,&#xA;  GPUProgram,&#xA;  renderAmplitudeProgram,&#xA;  FLOAT,&#xA;  INT,&#xA;  REPEAT,&#xA;  NEAREST,&#xA;} from &#39;gpu-io&#39;;&#xA;&#xA;// Init a canvas element.&#xA;const canvas = document.createElement(&#39;canvas&#39;);&#xA;document.body.appendChild(canvas);&#xA;&#xA;// Init a composer.&#xA;const composer = new GPUComposer({ canvas });&#xA;&#xA;// Init a layer of float data filled with noise.&#xA;const noise = new Float32Array(canvas.width * canvas.height);&#xA;noise.forEach((el, i) =&amp;gt; noise[i] = Math.random());&#xA;const state = new GPULayer(composer, {&#xA;  name: &#39;state&#39;,&#xA;  dimensions: [canvas.width, canvas.height],&#xA;  numComponents: 1, // Scalar state has one component.&#xA;  type: FLOAT,&#xA;  filter: NEAREST,&#xA;  // Use 2 buffers so we can toggle read/write&#xA;  // from one to the other.&#xA;  numBuffers: 2,&#xA;  wrapX: REPEAT,&#xA;  wrapY: REPEAT,&#xA;  array: noise,&#xA;});&#xA;&#xA;// Init a program to diffuse state.&#xA;const diffuseProgram = new GPUProgram(composer, {&#xA;  name: &#39;render&#39;,&#xA;  fragmentShader: `&#xA;    in vec2 v_uv;&#xA;&#xA;    uniform sampler2D u_state;&#xA;    uniform vec2 u_pxSize;&#xA;&#xA;    out float out_result;&#xA;&#xA;    void main() {&#xA;      // Compute the discrete Laplacian.&#xA;      // https://en.wikipedia.org/wiki/Discrete_Laplace_operator&#xA;      float center = texture(u_state, v_uv).x;&#xA;      float n = texture(u_state, v_uv + vec2(0, u_pxSize.y)).x;&#xA;      float s = texture(u_state, v_uv - vec2(0, u_pxSize.y)).x;&#xA;      float e = texture(u_state, v_uv + vec2(u_pxSize.x, 0)).x;&#xA;      float w = texture(u_state, v_uv - vec2(u_pxSize.x, 0)).x;&#xA;      const float diffusionRate = 0.1;&#xA;      out_result =&#xA;        center + diffusionRate * (n + s + e + w - 4.0 * center);&#xA;    }&#xA;  `,&#xA;  uniforms: [&#xA;    { // Index of sampler2D uniform to assign to value &#34;u_state&#34;.&#xA;      name: &#39;u_state&#39;,&#xA;      value: 0,&#xA;      type: INT,&#xA;    },&#xA;    { // Calculate the size of a 1 px step in UV coordinates.&#xA;      name: &#39;u_pxSize&#39;,&#xA;      value: [1 / canvas.width, 1 / canvas.height],&#xA;      type: FLOAT,&#xA;    },&#xA;  ],&#xA;});&#xA;&#xA;// Init a program to render state to canvas.&#xA;// See https://github.com/amandaghassaei/gpu-io/tree/main/docs#gpuprogram-helper-functions&#xA;// for more built-in GPUPrograms to use.&#xA;const renderProgram = renderAmplitudeProgram(composer, {&#xA;  name: &#39;render&#39;,&#xA;  type: state.type,&#xA;  components: &#39;x&#39;,&#xA;});&#xA;&#xA;// Simulation/render loop.&#xA;function loop() {&#xA;  window.requestAnimationFrame(loop);&#xA;&#xA;  // Diffuse state and write result to state.&#xA;  composer.step({&#xA;    program: diffuseProgram,&#xA;    input: state,&#xA;    output: state,&#xA;  });&#xA;&#xA;  // If no &#34;output&#34;, will draw to canvas.&#xA;  composer.step({&#xA;    program: renderProgram,&#xA;    input: state,&#xA;  });&#xA;}&#xA;loop(); // Start animation loop.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://apps.amandaghassaei.com/gpu-io/examples/demo/&#34;&gt;Demo this code&lt;/a&gt; - You should see the noise slowly blur, refresh the page to start it over.&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;Check out the &lt;a href=&#34;https://apps.amandaghassaei.com/gpu-io/examples/&#34;&gt;Examples page&lt;/a&gt; to really understand how gpu-io works and how to easily create touch interactions in your application. Source code for all examples can be found in the &lt;a href=&#34;https://github.com/amandaghassaei/gpu-io/tree/main/examples&#34;&gt;examples/&lt;/a&gt; folder.&lt;/p&gt; &#xA;&lt;p&gt;Please let me know if you have something that you would like to add to the examples page!&lt;/p&gt; &#xA;&lt;h2&gt;API&lt;/h2&gt; &#xA;&lt;p&gt;Full API documentation can be found in the &lt;a href=&#34;https://github.com/amandaghassaei/gpu-io/tree/main/docs&#34;&gt;docs/&lt;/a&gt; folder.&lt;/p&gt; &#xA;&lt;p&gt;More information about writing GLSL shaders for gpu-io can be found at &lt;a href=&#34;https://github.com/amandaghassaei/gpu-io/raw/main/docs/GLSL.md&#34;&gt;docs/GLSL&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Compatibility with Threejs&lt;/h2&gt; &#xA;&lt;p&gt;gpu-io can share a webgl context with Threejs so that both libraries will be able to access shared memory on the gpu:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import THREE from &#39;three&#39;;&#xA;import {&#xA;  GPUComposer,&#xA;  GPULayer,&#xA;  FLOAT,&#xA;  CLAMP_TO_EDGE,&#xA;  LINEAR,&#xA;} from &#39;gpu-io&#39;;&#xA;&#xA;const renderer = new THREE.WebGLRenderer();&#xA;// Use renderer.autoClear = false if you want to overlay threejs stuff&#xA;// on top of things rendered to the screen from gpu-io.&#xA;// renderer.autoClear = false;&#xA;&#xA;const composer = GPUComposer.initWithThreeRenderer(renderer);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Data is passed between gpu-io and Threejs via WebGLTextures. To bind a GPULayer to a Threejs Texture:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const layer1 = new GPULayer(composer, {&#xA;  name: &#39;layer1&#39;,&#xA;  dimensions: [100, 100],&#xA;  type: FLOAT,&#xA;  numComponents: 1,&#xA;});&#xA;&#xA;const texture = new THREE.Texture();&#xA;// Link webgl texture to threejs object.&#xA;layer1.attachToThreeTexture(texture);&#xA;&#xA;// Use texture in threejs scene.&#xA;const mesh = new THREE.Mesh(&#xA;  new PlaneBufferGeometry(1, 1),&#xA;  new MeshBasicMaterial({&#xA;    map: texture,&#xA;  }),&#xA;);&#xA;&#xA;// After threejs initialization - undo any changes threejs has made to WebGL state.&#xA;composer.undoThreeState();&#xA;&#xA;loop() {&#xA;  // Compute things with gpu-io.&#xA;  composer.step({&#xA;    program: myProgram,&#xA;    output: layer1,&#xA;  });&#xA;&#xA;  ....&#xA;&#xA;  // Reset WebGL state back to what threejs is expecting&#xA;  // (otherwise we get WebGL errors).&#xA;  composer.resetThreeState();&#xA;  // Render threejs scene.&#xA;  // Updates to layer1 will propagate to texture without any&#xA;  // additional needsUpdate flags.&#xA;  renderer.render(scene, camera);&#xA;  // Undo any changes threejs has made to WebGL state.&#xA;  composer.undoThreeState();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;More info about using gpu-io with Threejs can be found in the &lt;a href=&#34;https://github.com/amandaghassaei/gpu-io/tree/main/examples/wave2d&#34;&gt;Threejs Example&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Limitations/Notes&lt;/h2&gt; &#xA;&lt;h3&gt;Limitations&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;gpu-io currently only supports GPULayers with 1D or 2D arrays of dense data. 3D textures are not officially supported by the library. You can still compute 3D simulations in gpu-io, you will just need to pass in your 3D position data as a 1D list to a GPULayer and then access it in the fragment shader using .xyz. TODO: make example for this.&lt;/li&gt; &#xA; &lt;li&gt;gpu-io does not currently allow you to pass in your own vertex shaders. Currently all computation is happening in user-specified fragment shaders; vertex shaders are managed internally.&lt;/li&gt; &#xA; &lt;li&gt;In order for the WRAP/FILTER polyfilling to work correctly, any calls to texture() must contain a direct reference to the sampler2D that it should operate on. For example:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-glsl&#34;&gt;varying vec2 v_uv;&#xA;&#xA;uniform sampler2D u_sampler1;&#xA;uniform sampler2D u_sampler2;&#xA;&#xA;out vec4 out_result;&#xA;&#xA;vec4 lookupSampler2(vec2 uv) {&#xA;  // This is good, it passes u_sampler2 directly to texture().&#xA;  return texture(u_sampler2, uv);&#xA;}&#xA;&#xA;vec4 lookupSampler(sampler2D sampler, vec2 uv) {&#xA;  // At compile time it is hard to say which sampler&#xA;  // is passed to texture().&#xA;  // This will not be polyfilled, it will throw a warning.&#xA;  return texture(sampler, uv);&#xA;}&#xA;&#xA;void main() {&#xA;  // This is good, it passes u_sampler1 directly to texture().&#xA;  vec2 position = texture(u_sampler1, v_uv).xy;&#xA;&#xA;  ....&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;GLSL Version&lt;/h3&gt; &#xA;&lt;p&gt;gpu-io defaults to using WebGL2 (if available) with GLSL version 300 (GLSL3) but you can set it to use WebGL1 or GLSL version 100 (GLSL1) by passing &lt;code&gt;contextID&lt;/code&gt; or &lt;code&gt;glslVersion&lt;/code&gt; parameters to &lt;code&gt;GPUComposer&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import {&#xA;  GPUComposer,&#xA;  GLSL1,&#xA;  WEBGL1,&#xA;} from &#39;gpu-io&#39;;&#xA;&#xA;// Init with WebGL2 (if available) with GLSL1.&#xA;const composer1 = new GPUComposer({&#xA;  canvas: document.createElement(&#39;canvas&#39;),&#xA;  glslVersion: GLSL1,&#xA;});&#xA;&#xA;// Init with WebGL1 with GLSL1 (GLSL3 is not supported in WebGL1).&#xA;const composer2 = new GPUComposer({&#xA;  canvas: document.createElement(&#39;canvas&#39;),&#xA;  contextID: WEBGL1,&#xA;});&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/amandaghassaei/gpu-io/raw/main/docs/classes/GPUComposer.md#constructor&#34;&gt;docs&amp;gt;GPUComposer&amp;gt;constructor&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;p&gt;gpu-io will automatically convert any GLSL3 shaders to GLSL1 when targeting WebGL1. If supporting WebGL1/GLSL1 is important to you, see the &lt;a href=&#34;https://github.com/amandaghassaei/gpu-io/raw/main/docs/GLSL1_Support.md&#34;&gt;GLSL1 Support&lt;/a&gt; doc for more info about what functions/types/operators are available in gpu-io&#39;s flavor of GLSL1.&lt;/p&gt; &#xA;&lt;h3&gt;Transform Feedback&lt;/h3&gt; &#xA;&lt;p&gt;You might notice that gpu-io does not use any transform feedback to handle computations on GPULayers. Transform feedback is great for things like particle simulations and other types of physics that is computed on the vertex level as opposed to the pixel level. It is still absolutely possible to perform these types of simulations using gpu-io (see &lt;a href=&#34;https://apps.amandaghassaei.com/gpu-io/examples/&#34;&gt;Examples&lt;/a&gt;), but currently all the computation happens in a fragment shader. There are a few reasons for this:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The main use case for gpu-io is to operate on 2D spatially-distributed state (i.e. fields) stored in textures using fragment shaders. There is additional support for 1D arrays and lines/particles, but that is secondary functionality.&lt;/li&gt; &#xA; &lt;li&gt;Transform feedback is only supported in WebGL2. At the time I first started writing this in 2020, WebGL2 was not supported by mobile Safari. Though that has changed recently, for now I&#39;d like to support all functionality in gpu-io in WebGL1/GLSL1 as well.&lt;/li&gt; &#xA; &lt;li&gt;The API is simpler if we constrain computations to the fragment shader only.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;My current plan is to wait for &lt;a href=&#34;https://web.dev/gpu/&#34;&gt;WebGPU&lt;/a&gt; to officially launch by default in some browsers, and then re-evaluate some of the design decisions made in gpu-io. WebGL puts artificial constraints on the current API by forcing general-purpose computing to happen in a vertex and fragment shader rendering pipeline rather than a compute pipeline, so I&#39;d like to get away from WebGL in the long term â€“ and using transform feedback feels like a step backwards at this point.&lt;/p&gt; &#xA;&lt;h3&gt;Precision&lt;/h3&gt; &#xA;&lt;p&gt;By default all shaders in gpu-io are inited with highp precision floats and ints, but they will fall back to mediump if highp is not available (this is the same convention used by Threejs). More info in &lt;a href=&#34;https://github.com/amandaghassaei/gpu-io/raw/main/src/glsl/common/precision.ts&#34;&gt;src/glsl/common/precision.ts&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can override these defaults by specifying &lt;code&gt;intPrecision&lt;/code&gt; and &lt;code&gt;floatPrecision&lt;/code&gt; in GPUComposer&#39;s constructor:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import {&#xA;  GPUComposer,&#xA;  PRECISION_LOW_P,&#xA;  PRECISION_MEDIUM_P,&#xA;  PRECISION_HIGH_P,&#xA;} from &#39;gpu-io&#39;;&#xA;&#xA;const composer = new GPUComposer({&#xA;  canvas: document.getElementById(&#39;webgl-canvas&#39;),&#xA;  intPrecision: PRECISION_MEDIUM_P,&#xA;  floatPrecision: PRECISION_MEDIUM_P,&#xA;});&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Of course, you can also always manually specify the precision of a particular variable in your shader code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-glsl&#34;&gt;in vec2 v_uv;&#xA;&#xA;// u_state is a BYTE array, so we can set its precision to lowp.&#xA;uniform lowp isampler2D u_state;&#xA;&#xA;out vec4 out_result;&#xA;&#xA;void main() {&#xA;  lowp int state = texture(u_state, v_uv).r;&#xA;  ....&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note: even if highp is specified in your shader code, gpu-io will convert to mediump if the current browser does not support highp (the alternative would be to throw an error).&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;I&#39;ve also included the following helper functions to test the precision of mediump on your device and determine whether highp is supported:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import {&#xA;  isHighpSupportedInVertexShader,&#xA;  isHighpSupportedInFragmentShader,&#xA;  getVertexShaderMediumpPrecision,&#xA;  getFragmentShaderMediumpPrecision,&#xA;} from &#39;gpu-io&#39;;&#xA;&#xA;// Prints &#39;highp&#39; or &#39;mediump&#39; depending on returned precision of&#xA;// mediump (16+bit or 32+bit).&#xA;// On many devices (esp desktop) mediump defaults to 32bit.&#xA;// See https://webglfundamentals.org/webgl/lessons/webgl-precision-issues.html&#xA;// for more info.&#xA;console.log(getVertexShaderMediumpPrecision());&#xA;console.log(getFragmentShaderMediumpPrecision());&#xA;&#xA;// Print true or false depending on highp support of browser/device.&#xA;console.log(isHighpSupportedInVertexShader());&#xA;console.log(isHighpSupportedInFragmentShader());&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;I used a few codebases as reference when writing this, thanks to their authors for making these repos available:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mrdoob/three.js/&#34;&gt;three.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/regl-project/regl&#34;&gt;regl&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gpujs/gpu.js/&#34;&gt;gpu.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://webglfundamentals.org/webgl/lessons/webgl-boilerplate.html&#34;&gt;WebGL Boilerplate&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gpfault.net/posts/webgl2-particles.txt.html&#34;&gt;GPU Accelerated Particles with WebGL 2&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Other resources:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/WebGL_best_practices&#34;&gt;WebGL best practices&lt;/a&gt; by Mozilla&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://shadertoyunofficial.wordpress.com/2016/07/22/compatibility-issues-in-shadertoy-webglsl/&#34;&gt;Compatibility issues in Shadertoy / webGLSL&lt;/a&gt; Shadertoy â€“ Unofficial&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This work is distributed under an MIT license. Note that gpu-io depends on a few npm packages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.npmjs.com/package/@amandaghassaei/type-checks&#34;&gt;@amandaghassaei/type-checks&lt;/a&gt; - MIT license, no dependencies.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.npmjs.com/package/@petamoriken/float16&#34;&gt;@petamoriken/float16&lt;/a&gt; - MIT license, no dependencies.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.npmjs.com/package/changedpi&#34;&gt;changedpi&lt;/a&gt; - MIT license, no dependencies.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.npmjs.com/package/file-saver&#34;&gt;file-saver&lt;/a&gt; - MIT license, no dependencies.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;p&gt;Update 10/2022: I&#39;m switching gears a bit to focus on some new projects, but I&#39;ll be continuing to use gpu-io as the foundation for almost everything I&#39;m working on. I expect that some new features will be added to this over the next six months or so, but can&#39;t be super involved in helping to debug issues you may run into. Feel free to log &lt;a href=&#34;https://github.com/amandaghassaei/gpu-io/issues&#34;&gt;issues&lt;/a&gt;, but don&#39;t expect a super prompt response! See the &lt;a href=&#34;https://apps.amandaghassaei.com/gpu-io/examples/&#34;&gt;Examples&lt;/a&gt; for more info about how to use this library.&lt;/p&gt; &#xA;&lt;p&gt;Pull requests welcome! I hope this library is useful to others, but I also realize that I have some very specific needs that have influenced the direction of this code â€“ so we&#39;ll see what happens. Please &lt;a href=&#34;https://twitter.com/amandaghassaei&#34;&gt;let me know&lt;/a&gt; if you end up using this, I&#39;d love to see what you&#39;re making!&lt;/p&gt; &#xA;&lt;h3&gt;Compiling with Webpack&lt;/h3&gt; &#xA;&lt;p&gt;Compiled with &lt;a href=&#34;https://www.npmjs.com/package/webpack&#34;&gt;webpack&lt;/a&gt;. To build ts files from &lt;code&gt;src&lt;/code&gt; to js in &lt;code&gt;dist&lt;/code&gt; run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm install&#xA;npm run build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Automated Testing&lt;/h3&gt; &#xA;&lt;p&gt;I&#39;m using mocha + karma + chai + headless Chrome to test the components of gpu-io, following the setup described in &lt;a href=&#34;https://developer.chrome.com/blog/headless-karma-mocha-chai/&#34;&gt;Automated testing with Headless Chrome&lt;/a&gt;. Those tests are located in &lt;a href=&#34;https://github.com/amandaghassaei/gpu-io/raw/main/tests/mocha/&#34;&gt;tests/mocha/&lt;/a&gt;. To run the automated tests, use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm run test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The automated tests do not get full code coverage yet, but I&#39;m planning to add to them when I go back to implement WebGPU features in this library.&lt;/p&gt; &#xA;&lt;h3&gt;Browser/Device Testing&lt;/h3&gt; &#xA;&lt;p&gt;I&#39;ve also included a webpage for testing various functions of this library in a browser/hardware combo of your choice. This page is current hosted at &lt;a href=&#34;https://apps.amandaghassaei.com/gpu-io/tests/&#34;&gt;apps.amandaghassaei.com/gpu-io/tests/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Note: The detected OS and browser version may not always be 100% accurate.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/amandaghassaei/gpu-io/raw/main/tests/README.md#browser-support&#34;&gt;tests/README#browser-support&lt;/a&gt; for results of various browser/hardware combos.&lt;/p&gt;</summary>
  </entry>
</feed>