<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-14T01:44:12Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>siinghd/player-custom-seekbar</title>
    <updated>2023-12-14T01:44:12Z</updated>
    <id>tag:github.com,2023-12-14:/siinghd/player-custom-seekbar</id>
    <link href="https://github.com/siinghd/player-custom-seekbar" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;player-custom-seekbar&lt;/h1&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Integration with the existing codebase to support segmented seekbars, similar to YouTube.&lt;/li&gt; &#xA; &lt;li&gt;Ability to divide the player&#39;s seekbar into specified segments.&lt;/li&gt; &#xA; &lt;li&gt;A &lt;code&gt;scrollToSegment&lt;/code&gt; function to navigate to the beginning of a selected segment.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Implementation&lt;/h2&gt; &#xA;&lt;p&gt;Do look at each section&lt;/p&gt; &#xA;&lt;h1&gt;Next.js Frontend&lt;/h1&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The frontend should call the backend to retrieve thumbnails or segment data and pass this information to the video component.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Implementation&lt;/h2&gt; &#xA;&lt;p&gt;Look at the code :(&lt;/p&gt; &#xA;&lt;h1&gt;Backend&lt;/h1&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Utilize &lt;code&gt;chunks.sh&lt;/code&gt; script to upload files to the backend.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Detailed Documentation&lt;/h2&gt; &#xA;&lt;p&gt;For more information on setting up and running the backend, including the use of the &lt;code&gt;chunks.sh&lt;/code&gt; script for file uploads, please refer to the backend README(.)md:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/siinghd/player-custom-seekbar/main/backend/README.md&#34;&gt;Link to backend README.md&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>gregsadetsky/sagittarius</title>
    <updated>2023-12-14T01:44:12Z</updated>
    <id>tag:github.com,2023-12-14:/gregsadetsky/sagittarius</id>
    <link href="https://github.com/gregsadetsky/sagittarius" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Remake of the Google Gemini Fake Demo, Except Using GPT-4 and It&#39;s Real&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;A Remake of the Google Gemini Fake Demo, Except Using GPT-4 and It&#39;s Real&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=__nL7Vc0OCg&#34;&gt;Original video here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=1RrkRA7wuoE&#34;&gt;Heads-to-heads comparison of Gemini Pro and GPT-4&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;how to build&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;clone this repo, cd into it&lt;/li&gt; &#xA; &lt;li&gt;duplicate &lt;code&gt;.env.example&lt;/code&gt; and name the copy &lt;code&gt;.env&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;fill out the &lt;code&gt;VITE_OPENAI_KEY=&lt;/code&gt; value with your OpenAI api key. you must have access to the &lt;code&gt;gpt-4-vision-preview&lt;/code&gt; model&lt;/li&gt; &#xA; &lt;li&gt;you can also try out the Gemini API if you have a key -- fill out &lt;code&gt;VITE_GEMINI_KEY&lt;/code&gt; in the same &lt;code&gt;.env&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;then, run:&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;npm install&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;npm run dev&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;the demo will be running at &lt;a href=&#34;http://localhost:5173&#34;&gt;http://localhost:5173&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;note: the in-browser speech recognition works best in Google Chrome&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ykhli/AI-tamago</title>
    <updated>2023-12-14T01:44:12Z</updated>
    <id>tag:github.com,2023-12-14:/ykhli/AI-tamago</id>
    <link href="https://github.com/ykhli/AI-tamago" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A local-ready LLM-generated and LLM-driven virtual pet with thoughts and feelings. 100% Javascript.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Tamago ü•öüê£&lt;/h1&gt; &#xA;&lt;p&gt;An 100% local, LLM-generated and driven virtual pet with thoughts, feelings and feedback. Revive your fond memories of Tamagotchi! &lt;a href=&#34;https://ai-tamago.fly.dev/&#34;&gt;https://ai-tamago.fly.dev/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;All ascii animations are generated using chatgpt (included prompts in the repo).&lt;/p&gt; &#xA;&lt;p&gt;Have questions? Join &lt;a href=&#34;https://discord.gg/TsWCNVvRP5&#34;&gt;AI Stack devs&lt;/a&gt; and find me in #ai-tamago channel.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Demo&lt;/strong&gt; ü™Ñ&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ykhli/AI-tamago/assets/3489963/8d7cb2ac-537a-45d4-98a5-1802b773e364&#34;&gt;https://github.com/ykhli/AI-tamago/assets/3489963/8d7cb2ac-537a-45d4-98a5-1802b773e364&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Stack&lt;/h2&gt; &#xA;&lt;h3&gt;Local Mode&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ü¶ô Inference: &lt;a href=&#34;https://github.com/jmorganca/ollama&#34;&gt;Ollama&lt;/a&gt;, with options to use OpenAI or &lt;a href=&#34;https://replicate.com/&#34;&gt;Replicate&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üîî Game state: &lt;a href=&#34;https://www.inngest.com/&#34;&gt;Inngest&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üíª Transactional &amp;amp; vector database: &lt;a href=&#34;https://supabase.com/docs/guides/database/extensions/pgvector&#34;&gt;Supabase pgvector&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üß† LLM Orchestration: &lt;a href=&#34;https://js.langchain.com/docs/&#34;&gt;Langchain.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üñºÔ∏è App logic: &lt;a href=&#34;https://nextjs.org/&#34;&gt;Next.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üßÆ Embeddings generation: &lt;a href=&#34;https://github.com/xenova/transformers.js&#34;&gt;Transformer.js&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/Xenova/all-MiniLM-L6-v2&#34;&gt; all-MiniLM-L6-v2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üñåÔ∏è UI: &lt;a href=&#34;https://v0.dev/&#34;&gt;Vercel v0&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Prod Mode&lt;/h3&gt; &#xA;&lt;p&gt;All of above, plus:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üîê Auth &amp;amp; User Management: &lt;a href=&#34;https://clerk.com/&#34;&gt;Clerk&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;‚òÅÔ∏è Hosting: &lt;a href=&#34;https://fly.io/&#34;&gt;Fly&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ü•á Rate Limiting: &lt;a href=&#34;https://upstash.com/&#34;&gt;Upstash&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üöÄ &lt;a href=&#34;https://raw.githubusercontent.com/ykhli/AI-tamago/main/#quickstart&#34;&gt;Quickstart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üíª &lt;a href=&#34;https://raw.githubusercontent.com/ykhli/AI-tamago/main/#deployment-guide&#34;&gt;Deployment Guide&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.docker.com/get-started&#34;&gt;Install Docker&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;h3&gt;1. Fork and Clone repo&lt;/h3&gt; &#xA;&lt;p&gt;Fork the repo to your Github account, then run the following command to clone the repo:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:[YOUR_GITHUB_ACCOUNT_NAME]/AI-tamago.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Install dependencies&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd ai-tamago&#xA;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;All client side tamagotchi code is in Tamagotchi.tsx&lt;/p&gt; &#xA;&lt;h3&gt;3. Install Ollama&lt;/h3&gt; &#xA;&lt;p&gt;Instructions are &lt;a href=&#34;https://github.com/jmorganca/ollama#macos&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;4. Run Supabase locally&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install Supabase CLI&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;brew install supabase/tap/supabase&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Start Supabase&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Make sure you are under &lt;code&gt;/ai-tamago&lt;/code&gt; directory and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;supabase start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Tips: To run migrations or reset database -- seed.sql and migrations will run &lt;code&gt;supabase db reset&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;5. Fill in secrets&lt;/h3&gt; &#xA;&lt;p&gt;Note: The secrets here are for your &lt;strong&gt;local&lt;/strong&gt; supabase instance&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cp .env.local.example .env.local&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then get &lt;code&gt;SUPABASE_PRIVATE_KEY&lt;/code&gt; by running&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;supabase status&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Copy &lt;code&gt;service_role key&lt;/code&gt; and save it as &lt;code&gt;SUPABASE_PRIVATE_KEY&lt;/code&gt; in &lt;code&gt;.env.local&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;6. Set up Inngest&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;npx inngest-cli@latest dev&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Make sure your app is up and running -- Inngest functions (which are used to drive game state) should register automatically.&lt;/p&gt; &#xA;&lt;h3&gt;7. Run app locally&lt;/h3&gt; &#xA;&lt;p&gt;Now you are ready to test out the app locally! To do this, simply run &lt;code&gt;npm run dev&lt;/code&gt; under the project root and visit &lt;code&gt;http://localhost:3000&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Deployment Guide&lt;/h2&gt; &#xA;&lt;p&gt;Now you have played with the AI tamago locally -- it&#39;s time to deploy it somewhere more permanent so you can access it anytime!&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;0. Choose which model you want to use in production&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you want to test out using Chatgpt in prod, simply remove &lt;code&gt;LLM_MODEL=ollama&lt;/code&gt; from &lt;code&gt;.env.local&lt;/code&gt; and fill in &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;If you want to try &lt;a href=&#34;https://replicate.com/&#34;&gt;Replicate&lt;/a&gt;, set &lt;code&gt;LLM_MODEL=replicate_llama&lt;/code&gt; and fill in &lt;code&gt;REPLICATE_API_TOKEN&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;If you want to deploy Ollama yourself, you can follow this awesome guide -- &lt;a href=&#34;https://fly.io/blog/scaling-llm-ollama/&#34;&gt;Scaling Large Language Models to zero with Ollama&lt;/a&gt;. It is possible to run Ollama on a &lt;code&gt;performance-4x&lt;/code&gt; Fly VM (CPU) with &lt;code&gt;100gb&lt;/code&gt; volume, but if you can get access to GPUs they are much faster. Join Fly&#39;s GPU waitlist &lt;a href=&#34;https://fly.io/gpu&#34;&gt;here&lt;/a&gt; if you don&#39;t yet have access!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;1. Switch to &lt;code&gt;deploy&lt;/code&gt; branch -- this branch includes everything you need to deploy an app like &lt;a href=&#34;https://ai-tamago.fly.dev/&#34;&gt;this&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;git co deploy&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;This branch contains a multi-tenancy-ready (thanks to Clerk) app, which means every user can get their own AI-tamago, and has token limit built in -- you can set how many times a user can send requests in the app (see &lt;code&gt;ratelimit.ts&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;2. Move to Supabase Cloud:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a Supabase project &lt;a href=&#34;https://supabase.com/&#34;&gt;here&lt;/a&gt;, then go to Project Settings -&amp;gt; API. Fill out secrets in &lt;code&gt;.env.local&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;SUPABASE_URL&lt;/code&gt; is the URL value under &#34;Project URL&#34;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;SUPABASE_PRIVATE_KEY&lt;/code&gt; is the key starts with &lt;code&gt;ey&lt;/code&gt; under Project API Keys&lt;/li&gt; &#xA; &lt;li&gt;Copy Supabase project id, which you can find from the url &lt;a href=&#34;https://supabase.com/dashboard/project/%5Bproject-id%5D&#34;&gt;https://supabase.com/dashboard/project/[project-id]&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;From your Ai-tamago project root, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;supabase link --project-ref [insert project-id]&#xA;supabase migration up&#xA;supabase db reset --linked&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;3. Create Upstash Redis instance for rate limiting&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;This will make sure no one user calls any API too many times and taking up all the inference workloads. We are using Upstash&#39;s &lt;a href=&#34;https://upstash.com/blog/upstash-ratelimit&#34;&gt;awesome rate limiting SDK&lt;/a&gt; here.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Sign in to &lt;a href=&#34;https://upstash.com/&#34;&gt;Upstash&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Under &#34;Redis&#34; on the top nav, click on &#34;Create Database&#34;&lt;/li&gt; &#xA; &lt;li&gt;Give it a name, and then select regions and other options based on your preference. Click on &#34;Create&#34;&lt;/li&gt; &#xA; &lt;li&gt;Scroll down to &#34;REST API&#34; section and click on &#34;.env&#34;. Now you can copy paste both environment variables (&lt;code&gt;UPSTASH_REDIS_REST_URL&lt;/code&gt; and &lt;code&gt;UPSTASH_REDIS_REST_TOKEN&lt;/code&gt;) to your .env.local&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;4. Now you are ready to deploy everything on Fly.io!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Register an account on fly.io and then &lt;a href=&#34;https://fly.io/docs/hands-on/install-flyctl/&#34;&gt;install flyctl&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;fly launch&lt;/code&gt; under project root. This will generate a &lt;code&gt;fly.toml&lt;/code&gt; that includes all the configurations you will need&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;fly scale memory 512&lt;/code&gt; to scale up the fly vm memory for this app.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;fly deploy --ha=false&lt;/code&gt; to deploy the app. The --ha flag makes sure fly only spins up one instance, which is included in the free plan.&lt;/li&gt; &#xA; &lt;li&gt;For any other non-localhost environment, the existing Clerk development instance should continue to work. You can upload the secrets to Fly by running &lt;code&gt;cat .env.local | fly secrets import&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;If you want to make this a real product, you should create a prod environment under the &lt;a href=&#34;https://dashboard.clerk.com/&#34;&gt;current Clerk instance&lt;/a&gt;. For more details on deploying a production app with Clerk, check out their documentation &lt;a href=&#34;https://clerk.com/docs/deployments/overview&#34;&gt;here&lt;/a&gt;. &lt;strong&gt;Note that you will likely need to manage your own domain and do domain verification as part of the process.&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Create a new file &lt;code&gt;.env.prod&lt;/code&gt; locally and fill in all the production-environment secrets. Remember to update &lt;code&gt;NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY&lt;/code&gt; and &lt;code&gt;CLERK_SECRET_KEY&lt;/code&gt; by copying secrets from Clerk&#39;s production instance -&lt;code&gt;cat .env.prod | fly secrets import&lt;/code&gt; to upload secrets.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you have questions, join &lt;a href=&#34;https://discord.gg/TsWCNVvRP5&#34;&gt;AI Stack devs&lt;/a&gt; and find me in #ai-tamago channel.&lt;/p&gt; &#xA;&lt;h2&gt;Other Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://clerk.com/docs/quickstarts/nextjs&#34;&gt;Adding auth with Clerk&lt;/a&gt; - takes &amp;lt; 5mins&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.inngest.com/docs/deploy&#34;&gt;Inngest deployment guide&lt;/a&gt;&lt;a href=&#34;https://www.inngest.com/docs/deploy&#34;&gt;https://www.inngest.com/docs/deploy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fly.io/blog/scaling-llm-ollama/&#34;&gt;Running Ollama on Fly.io&lt;/a&gt;&lt;a href=&#34;https://fly.io/blog/scaling-llm-ollama/&#34;&gt;https://fly.io/blog/scaling-llm-ollama/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fly.io/docs/js/frameworks/nextjs/#:~:text=Deploy%20an%20existing%20NextJS%20app&amp;amp;text=First%2C%20install%20flyctl%2C%20your%20Fly,the%20root%20of%20your%20application.&amp;amp;text=Creating%20app%20in%20%2FUsers%2Fme,source%20code%20Detected%20a%20Next.&#34;&gt;Run a next.js app on Fly.io&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>