<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-17T01:48:29Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ChatGPTNextWeb/ChatGPT-Next-Web</title>
    <updated>2023-12-17T01:48:29Z</updated>
    <id>tag:github.com,2023-12-17:/ChatGPTNextWeb/ChatGPT-Next-Web</id>
    <link href="https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A well-designed cross-platform ChatGPT UI (Web / PWA / Linux / Win / MacOS). 一键拥有你自己的跨平台 ChatGPT 应用。&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/images/icon.svg?sanitize=true&#34; alt=&#34;icon&#34;&gt; &#xA; &lt;h1 align=&#34;center&#34;&gt;ChatGPT Next Web&lt;/h1&gt; &#xA; &lt;p&gt;English / &lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/README_CN.md&#34;&gt;简体中文&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;One-Click to get well-designed cross-platform ChatGPT web UI.&lt;/p&gt; &#xA; &lt;p&gt;一键免费部署你的跨平台私人 ChatGPT 应用。&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://chatgpt.nextweb.fun&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Web-PWA-orange?logo=microsoftedge&#34; alt=&#34;Web&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Windows-blue?logo=windows&#34; alt=&#34;Windows&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-MacOS-black?logo=apple&#34; alt=&#34;MacOS&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Linux-333?logo=ubuntu&#34; alt=&#34;Linux&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://chatgpt.nextweb.fun/&#34;&gt;Web App&lt;/a&gt; / &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/releases&#34;&gt;Desktop App&lt;/a&gt; / &lt;a href=&#34;https://discord.gg/YCkeafCafC&#34;&gt;Discord&lt;/a&gt; / &lt;a href=&#34;https://twitter.com/mortiest_ricky&#34;&gt;Twitter&lt;/a&gt; / &lt;a href=&#34;https://www.buymeacoffee.com/yidadaa&#34;&gt;Buy Me a Coffee&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://chatgpt.nextweb.fun/&#34;&gt;网页版&lt;/a&gt; / &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/releases&#34;&gt;客户端&lt;/a&gt; / &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/issues&#34;&gt;反馈&lt;/a&gt; / &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/discussions/1724&#34;&gt;QQ 群&lt;/a&gt; / &lt;a href=&#34;https://user-images.githubusercontent.com/16968934/227772541-5bcd52d8-61b7-488c-a203-0330d8006e2b.jpg&#34;&gt;打赏开发者&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FYidadaa%2FChatGPT-Next-Web&amp;amp;env=OPENAI_API_KEY&amp;amp;env=CODE&amp;amp;project-name=chatgpt-next-web&amp;amp;repository-name=ChatGPT-Next-Web&#34;&gt;&lt;img src=&#34;https://vercel.com/button&#34; alt=&#34;Deploy with Vercel&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://gitpod.io/#https://github.com/Yidadaa/ChatGPT-Next-Web&#34;&gt;&lt;img src=&#34;https://gitpod.io/button/open-in-gitpod.svg?sanitize=true&#34; alt=&#34;Open in Gitpod&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/images/cover.png&#34; alt=&#34;cover&#34;&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Deploy for free with one-click&lt;/strong&gt; on Vercel in under 1 minute&lt;/li&gt; &#xA; &lt;li&gt;Compact client (~5MB) on Linux/Windows/MacOS, &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/releases&#34;&gt;download it now&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Fully compatible with self-deployed llms, recommended for use with &lt;a href=&#34;https://github.com/josStorer/RWKV-Runner&#34;&gt;RWKV-Runner&lt;/a&gt; or &lt;a href=&#34;https://github.com/go-skynet/LocalAI&#34;&gt;LocalAI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Privacy first, all data stored locally in the browser&lt;/li&gt; &#xA; &lt;li&gt;Markdown support: LaTex, mermaid, code highlight, etc.&lt;/li&gt; &#xA; &lt;li&gt;Responsive design, dark mode and PWA&lt;/li&gt; &#xA; &lt;li&gt;Fast first screen loading speed (~100kb), support streaming response&lt;/li&gt; &#xA; &lt;li&gt;New in v2: create, share and debug your chat tools with prompt templates (mask)&lt;/li&gt; &#xA; &lt;li&gt;Awesome prompts powered by &lt;a href=&#34;https://github.com/PlexPt/awesome-chatgpt-prompts-zh&#34;&gt;awesome-chatgpt-prompts-zh&lt;/a&gt; and &lt;a href=&#34;https://github.com/f/awesome-chatgpt-prompts&#34;&gt;awesome-chatgpt-prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Automatically compresses chat history to support long conversations while also saving your tokens&lt;/li&gt; &#xA; &lt;li&gt;I18n: English, 简体中文, 繁体中文, 日本語, Français, Español, Italiano, Türkçe, Deutsch, Tiếng Việt, Русский, Čeština, 한국어, Indonesia&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; System Prompt: pin a user defined prompt as system prompt &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/issues/138&#34;&gt;#138&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; User Prompt: user can edit and save custom prompts to prompt list&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Prompt Template: create a new chat with pre-defined in-context prompts &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/issues/993&#34;&gt;#993&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Share as image, share to ShareGPT &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/pull/1741&#34;&gt;#1741&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Desktop App with tauri&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Self-host Model: Fully compatible with &lt;a href=&#34;https://github.com/josStorer/RWKV-Runner&#34;&gt;RWKV-Runner&lt;/a&gt;, as well as server deployment of &lt;a href=&#34;https://github.com/go-skynet/LocalAI&#34;&gt;LocalAI&lt;/a&gt;: llama/gpt4all/rwkv/vicuna/koala/gpt4all-j/cerebras/falcon/dolly etc.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Plugins: support network search, calculator, any other apis etc. &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/issues/165&#34;&gt;#165&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What&#39;s New&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🚀 v2.0 is released, now you can create prompt templates, turn your ideas into reality! Read this: &lt;a href=&#34;https://www.allabtai.com/prompt-engineering-tips-zero-one-and-few-shot-prompting/&#34;&gt;ChatGPT Prompt Engineering Tips: Zero, One and Few Shot Prompting&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;🚀 v2.7 let&#39;s share conversations as image, or share to ShareGPT!&lt;/li&gt; &#xA; &lt;li&gt;🚀 v2.8 now we have a client that runs across all platforms!&lt;/li&gt; &#xA; &lt;li&gt;🚀 v2.9.11 you can use azure endpoint now.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;主要功能&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;在 1 分钟内使用 Vercel &lt;strong&gt;免费一键部署&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;提供体积极小（~5MB）的跨平台客户端（Linux/Windows/MacOS）, &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/releases&#34;&gt;下载地址&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;完整的 Markdown 支持：LaTex 公式、Mermaid 流程图、代码高亮等等&lt;/li&gt; &#xA; &lt;li&gt;精心设计的 UI，响应式设计，支持深色模式，支持 PWA&lt;/li&gt; &#xA; &lt;li&gt;极快的首屏加载速度（~100kb），支持流式响应&lt;/li&gt; &#xA; &lt;li&gt;隐私安全，所有数据保存在用户浏览器本地&lt;/li&gt; &#xA; &lt;li&gt;预制角色功能（面具），方便地创建、分享和调试你的个性化对话&lt;/li&gt; &#xA; &lt;li&gt;海量的内置 prompt 列表，来自&lt;a href=&#34;https://github.com/PlexPt/awesome-chatgpt-prompts-zh&#34;&gt;中文&lt;/a&gt;和&lt;a href=&#34;https://github.com/f/awesome-chatgpt-prompts&#34;&gt;英文&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;自动压缩上下文聊天记录，在节省 Token 的同时支持超长对话&lt;/li&gt; &#xA; &lt;li&gt;多国语言支持：English, 简体中文, 繁体中文, 日本語, Español, Italiano, Türkçe, Deutsch, Tiếng Việt, Русский, Čeština, 한국어, Indonesia&lt;/li&gt; &#xA; &lt;li&gt;拥有自己的域名？好上加好，绑定后即可在任何地方&lt;strong&gt;无障碍&lt;/strong&gt;快速访问&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;开发计划&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 为每个对话设置系统 Prompt &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/issues/138&#34;&gt;#138&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 允许用户自行编辑内置 Prompt 列表&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 预制角色：使用预制角色快速定制新对话 &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/issues/993&#34;&gt;#993&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 分享为图片，分享到 ShareGPT 链接 &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/pull/1741&#34;&gt;#1741&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 使用 tauri 打包桌面应用&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 支持自部署的大语言模型：开箱即用 &lt;a href=&#34;https://github.com/josStorer/RWKV-Runner&#34;&gt;RWKV-Runner&lt;/a&gt; ，服务端部署 &lt;a href=&#34;https://github.com/go-skynet/LocalAI&#34;&gt;LocalAI 项目&lt;/a&gt; llama / gpt4all / rwkv / vicuna / koala / gpt4all-j / cerebras / falcon / dolly 等等，或者使用 &lt;a href=&#34;https://github.com/xusenlinzy/api-for-open-llm&#34;&gt;api-for-open-llm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 插件机制，支持联网搜索、计算器、调用其他平台 api &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/issues/165&#34;&gt;#165&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;最新动态&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🚀 v2.0 已经发布，现在你可以使用面具功能快速创建预制对话了！ 了解更多： &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/issues/138&#34;&gt;ChatGPT 提示词高阶技能：零次、一次和少样本提示&lt;/a&gt;。&lt;/li&gt; &#xA; &lt;li&gt;💡 想要更方便地随时随地使用本项目？可以试下这款桌面插件：&lt;a href=&#34;https://github.com/mushan0x0/AI0x0.com&#34;&gt;https://github.com/mushan0x0/AI0x0.com&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;🚀 v2.7 现在可以将会话分享为图片了，也可以分享到 ShareGPT 的在线链接。&lt;/li&gt; &#xA; &lt;li&gt;🚀 v2.8 发布了横跨 Linux/Windows/MacOS 的体积极小的客户端。&lt;/li&gt; &#xA; &lt;li&gt;🚀 v2.9.11 现在可以使用自定义 Azure 服务了。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/README_CN.md#%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8&#34;&gt;简体中文 &amp;gt; 如何开始使用&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Get &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;OpenAI API Key&lt;/a&gt;;&lt;/li&gt; &#xA; &lt;li&gt;Click &lt;a href=&#34;https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FYidadaa%2FChatGPT-Next-Web&amp;amp;env=OPENAI_API_KEY&amp;amp;env=CODE&amp;amp;project-name=chatgpt-next-web&amp;amp;repository-name=ChatGPT-Next-Web&#34;&gt;&lt;img src=&#34;https://vercel.com/button&#34; alt=&#34;Deploy with Vercel&#34;&gt;&lt;/a&gt;, remember that &lt;code&gt;CODE&lt;/code&gt; is your page password;&lt;/li&gt; &#xA; &lt;li&gt;Enjoy :)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/faq-cn.md&#34;&gt;简体中文 &amp;gt; 常见问题&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/faq-en.md&#34;&gt;English &amp;gt; FAQ&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Keep Updated&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/README_CN.md#%E4%BF%9D%E6%8C%81%E6%9B%B4%E6%96%B0&#34;&gt;简体中文 &amp;gt; 如何保持代码更新&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;If you have deployed your own project with just one click following the steps above, you may encounter the issue of &#34;Updates Available&#34; constantly showing up. This is because Vercel will create a new project for you by default instead of forking this project, resulting in the inability to detect updates correctly.&lt;/p&gt; &#xA;&lt;p&gt;We recommend that you follow the steps below to re-deploy:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Delete the original repository;&lt;/li&gt; &#xA; &lt;li&gt;Use the fork button in the upper right corner of the page to fork this project;&lt;/li&gt; &#xA; &lt;li&gt;Choose and deploy in Vercel again, &lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/vercel-cn.md&#34;&gt;please see the detailed tutorial&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Enable Automatic Updates&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;If you encounter a failure of Upstream Sync execution, please manually sync fork once.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;After forking the project, due to the limitations imposed by GitHub, you need to manually enable Workflows and Upstream Sync Action on the Actions page of the forked project. Once enabled, automatic updates will be scheduled every hour:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/images/enable-actions.jpg&#34; alt=&#34;Automatic Updates&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/images/enable-actions-sync.jpg&#34; alt=&#34;Enable Automatic Updates&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Manually Updating Code&lt;/h3&gt; &#xA;&lt;p&gt;If you want to update instantly, you can check out the &lt;a href=&#34;https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/syncing-a-fork&#34;&gt;GitHub documentation&lt;/a&gt; to learn how to synchronize a forked project with upstream code.&lt;/p&gt; &#xA;&lt;p&gt;You can star or watch this project or follow author to get release notifications in time.&lt;/p&gt; &#xA;&lt;h2&gt;Access Password&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/README_CN.md#%E9%85%8D%E7%BD%AE%E9%A1%B5%E9%9D%A2%E8%AE%BF%E9%97%AE%E5%AF%86%E7%A0%81&#34;&gt;简体中文 &amp;gt; 如何增加访问密码&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;This project provides limited access control. Please add an environment variable named &lt;code&gt;CODE&lt;/code&gt; on the vercel environment variables page. The value should be passwords separated by comma like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;code1,code2,code3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After adding or modifying this environment variable, please redeploy the project for the changes to take effect.&lt;/p&gt; &#xA;&lt;h2&gt;Environment Variables&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/README_CN.md#%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F&#34;&gt;简体中文 &amp;gt; 如何配置 api key、访问密码、接口代理&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;&lt;code&gt;CODE&lt;/code&gt; (optional)&lt;/h3&gt; &#xA;&lt;p&gt;Access password, separated by comma.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt; (required)&lt;/h3&gt; &#xA;&lt;p&gt;Your openai api key, join multiple api keys with comma.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;BASE_URL&lt;/code&gt; (optional)&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Default: &lt;code&gt;https://api.openai.com&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Examples: &lt;code&gt;http://your-openai-proxy.com&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Override openai api request base url.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;OPENAI_ORG_ID&lt;/code&gt; (optional)&lt;/h3&gt; &#xA;&lt;p&gt;Specify OpenAI organization ID.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;AZURE_URL&lt;/code&gt; (optional)&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Example: https://{azure-resource-url}/openai/deployments/{deploy-name}&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Azure deploy url.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;AZURE_API_KEY&lt;/code&gt; (optional)&lt;/h3&gt; &#xA;&lt;p&gt;Azure Api Key.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;AZURE_API_VERSION&lt;/code&gt; (optional)&lt;/h3&gt; &#xA;&lt;p&gt;Azure Api Version, find it at &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#chat-completions&#34;&gt;Azure Documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;HIDE_USER_API_KEY&lt;/code&gt; (optional)&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Default: Empty&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;If you do not want users to input their own API key, set this value to 1.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;DISABLE_GPT4&lt;/code&gt; (optional)&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Default: Empty&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;If you do not want users to use GPT-4, set this value to 1.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;ENABLE_BALANCE_QUERY&lt;/code&gt; (optional)&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Default: Empty&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;If you do want users to query balance, set this value to 1, or you should set it to 0.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;DISABLE_FAST_LINK&lt;/code&gt; (optional)&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Default: Empty&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;If you want to disable parse settings from url, set this to 1.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;CUSTOM_MODELS&lt;/code&gt; (optional)&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Default: Empty Example: &lt;code&gt;+llama,+claude-2,-gpt-3.5-turbo,gpt-4-1106-preview=gpt-4-turbo&lt;/code&gt; means add &lt;code&gt;llama, claude-2&lt;/code&gt; to model list, and remove &lt;code&gt;gpt-3.5-turbo&lt;/code&gt; from list, and display &lt;code&gt;gpt-4-1106-preview&lt;/code&gt; as &lt;code&gt;gpt-4-turbo&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;To control custom models, use &lt;code&gt;+&lt;/code&gt; to add a custom model, use &lt;code&gt;-&lt;/code&gt; to hide a model, use &lt;code&gt;name=displayName&lt;/code&gt; to customize model name, separated by comma.&lt;/p&gt; &#xA;&lt;p&gt;User &lt;code&gt;-all&lt;/code&gt; to disable all default models, &lt;code&gt;+all&lt;/code&gt; to enable all default models.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;NodeJS &amp;gt;= 18, Docker &amp;gt;= 20&lt;/p&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/README_CN.md#%E5%BC%80%E5%8F%91&#34;&gt;简体中文 &amp;gt; 如何进行二次开发&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitpod.io/#https://github.com/Yidadaa/ChatGPT-Next-Web&#34;&gt;&lt;img src=&#34;https://gitpod.io/button/open-in-gitpod.svg?sanitize=true&#34; alt=&#34;Open in Gitpod&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Before starting development, you must create a new &lt;code&gt;.env.local&lt;/code&gt; file at project root, and place your api key into it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;OPENAI_API_KEY=&amp;lt;your api key here&amp;gt;&#xA;&#xA;# if you are not able to access openai service, use this BASE_URL&#xA;BASE_URL=https://chatgpt1.nextweb.fun/api/proxy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Local Development&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 1. install nodejs and yarn first&#xA;# 2. config local env vars in `.env.local`&#xA;# 3. run&#xA;yarn install&#xA;yarn dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Deployment&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/README_CN.md#%E9%83%A8%E7%BD%B2&#34;&gt;简体中文 &amp;gt; 如何部署到私人服务器&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Docker (Recommended)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker pull yidadaa/chatgpt-next-web&#xA;&#xA;docker run -d -p 3000:3000 \&#xA;   -e OPENAI_API_KEY=sk-xxxx \&#xA;   -e CODE=your-password \&#xA;   yidadaa/chatgpt-next-web&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can start service behind a proxy:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d -p 3000:3000 \&#xA;   -e OPENAI_API_KEY=sk-xxxx \&#xA;   -e CODE=your-password \&#xA;   -e PROXY_URL=http://localhost:7890 \&#xA;   yidadaa/chatgpt-next-web&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If your proxy needs password, use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;-e PROXY_URL=&#34;http://127.0.0.1:7890 user pass&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Shell&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bash &amp;lt;(curl -s https://raw.githubusercontent.com/Yidadaa/ChatGPT-Next-Web/main/scripts/setup.sh)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Synchronizing Chat Records (UpStash)&lt;/h2&gt; &#xA;&lt;p&gt;| &lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/synchronise-chat-logs-cn.md&#34;&gt;简体中文&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/synchronise-chat-logs-en.md&#34;&gt;English&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/synchronise-chat-logs-es.md&#34;&gt;Italiano&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/synchronise-chat-logs-ja.md&#34;&gt;日本語&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/synchronise-chat-logs-ko.md&#34;&gt;한국어&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Please go to the [docs][./docs] directory for more documentation instructions.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/cloudflare-pages-en.md&#34;&gt;Deploy with cloudflare (Deprecated)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/faq-en.md&#34;&gt;Frequent Ask Questions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/translation.md&#34;&gt;How to add a new translation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/vercel-cn.md&#34;&gt;How to use Vercel (No English)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/user-manual-cn.md&#34;&gt;User Manual (Only Chinese, WIP)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Screenshots&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/images/settings.png&#34; alt=&#34;Settings&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/images/more.png&#34; alt=&#34;More&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Translation&lt;/h2&gt; &#xA;&lt;p&gt;If you want to add a new translation, read this &lt;a href=&#34;https://raw.githubusercontent.com/ChatGPTNextWeb/ChatGPT-Next-Web/main/docs/translation.md&#34;&gt;document&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Donation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/yidadaa&#34;&gt;Buy Me a Coffee&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Special Thanks&lt;/h2&gt; &#xA;&lt;h3&gt;Sponsor&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;仅列出捐赠金额 &amp;gt;= 100RMB 的用户。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/mushan0x0&#34;&gt;@mushan0x0&lt;/a&gt; &lt;a href=&#34;https://github.com/ClarenceDan&#34;&gt;@ClarenceDan&lt;/a&gt; &lt;a href=&#34;https://github.com/zhangjia&#34;&gt;@zhangjia&lt;/a&gt; &lt;a href=&#34;https://github.com/hoochanlon&#34;&gt;@hoochanlon&lt;/a&gt; &lt;a href=&#34;https://github.com/relativequantum&#34;&gt;@relativequantum&lt;/a&gt; &lt;a href=&#34;https://github.com/desenmeng&#34;&gt;@desenmeng&lt;/a&gt; &lt;a href=&#34;https://github.com/webees&#34;&gt;@webees&lt;/a&gt; &lt;a href=&#34;https://github.com/chazzhou&#34;&gt;@chazzhou&lt;/a&gt; &lt;a href=&#34;https://github.com/hauy&#34;&gt;@hauy&lt;/a&gt; &lt;a href=&#34;https://github.com/Corwin006&#34;&gt;@Corwin006&lt;/a&gt; &lt;a href=&#34;https://github.com/yankunsong&#34;&gt;@yankunsong&lt;/a&gt; &lt;a href=&#34;https://github.com/ypwhs&#34;&gt;@ypwhs&lt;/a&gt; &lt;a href=&#34;https://github.com/fxxxchao&#34;&gt;@fxxxchao&lt;/a&gt; &lt;a href=&#34;https://github.com/hotic&#34;&gt;@hotic&lt;/a&gt; &lt;a href=&#34;https://github.com/WingCH&#34;&gt;@WingCH&lt;/a&gt; &lt;a href=&#34;https://github.com/jtung4&#34;&gt;@jtung4&lt;/a&gt; &lt;a href=&#34;https://github.com/micozhu&#34;&gt;@micozhu&lt;/a&gt; &lt;a href=&#34;https://github.com/jhansion&#34;&gt;@jhansion&lt;/a&gt; &lt;a href=&#34;https://github.com/Sha1rholder&#34;&gt;@Sha1rholder&lt;/a&gt; &lt;a href=&#34;https://github.com/AnsonHyq&#34;&gt;@AnsonHyq&lt;/a&gt; &lt;a href=&#34;https://github.com/synwith&#34;&gt;@synwith&lt;/a&gt; &lt;a href=&#34;https://github.com/piksonGit&#34;&gt;@piksonGit&lt;/a&gt; &lt;a href=&#34;https://github.com/ouyangzhiping&#34;&gt;@ouyangzhiping&lt;/a&gt; &lt;a href=&#34;https://github.com/wenjiavv&#34;&gt;@wenjiavv&lt;/a&gt; &lt;a href=&#34;https://github.com/LeXwDeX&#34;&gt;@LeXwDeX&lt;/a&gt; &lt;a href=&#34;https://github.com/Licoy&#34;&gt;@Licoy&lt;/a&gt; &lt;a href=&#34;https://github.com/shangmin2009&#34;&gt;@shangmin2009&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Contributor&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web/graphs/contributors&#34;&gt;Contributors&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;LICENSE&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://opensource.org/license/mit/&#34;&gt;MIT&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>hrishioa/wishful-search</title>
    <updated>2023-12-17T01:48:29Z</updated>
    <id>tag:github.com,2023-12-17:/hrishioa/wishful-search</id>
    <link href="https://github.com/hrishioa/wishful-search" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Natural language search for complex JSON arrays, with AI Quickstart.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/hrishioa/wishful-search&#34;&gt;&lt;img src=&#34;https://github.com/hrishioa/wishful-search/assets/973967/ebd2d4cc-12d5-4916-b7c2-26cd234905d6&#34; alt=&#34;WishfulSearch&#34; width=&#34;100&#34;&gt;&lt;/a&gt; &lt;br&gt; WishfulSearch &lt;br&gt; &lt;/h1&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt;Multi-model natural language search for any JSON.&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://twitter.com/hrishioa&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/hrishi?style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/Apache-2.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/hrishioa/wishful-search/master/#key-features&#34;&gt;Key Features&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/hrishioa/wishful-search/master/#installation&#34;&gt;Installation&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/hrishioa/wishful-search/master/#usage&#34;&gt;Usage&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/hrishioa/wishful-search/master/#example-movies&#34;&gt;Demo: Search Movies&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/hrishioa/wishful-search/master/#how-it-works&#34;&gt;How it works&lt;/a&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://github.com/hrishioa/wishful-search/assets/973967/34e2fa82-2ae2-442a-972d-a2ab97d51d5e&#34; alt=&#34;output2&#34;&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;WishfulSearch is a natural language search module for JSON arrays. Take any JSON array you have (notifications, movies, flights, people) and filter it with complex questions. WishfulSearch takes care of the prompting, database management, object-to-relational conversion and query formatting.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;This repo is the work of one overworked dev, and meant to be for educational purposes. Use at your own risk!&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;If you aren&#39;t new here, &lt;a href=&#34;https://raw.githubusercontent.com/hrishioa/wishful-search/master/#autosearch&#34;&gt;check out autosearch!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Key Features&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI Quickstart - just bring an object&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Generate everything you need to use the library from a single, untyped JS object. Schema, functions, all of it.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Database Batteries Included&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;WishfulSearch comes included with a performant sqlite database bundled for use, managed by the module.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Server and client-side&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Includes &lt;a href=&#34;https://cdn.jsdelivr.net/npm/wishful-search@0.0.3/release/wishful-search.min.js&#34;&gt;bundled file from CDN&lt;/a&gt; to import as a script, or install from npm.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automated few-shot generation&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Use a smarter model to generate few-shot examples from a few questions, retemplate and insert into a prompt of a local model for instantly better results.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-model&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;GPT, Claude, Mistral adapters (OpenAI, Anthropic and &lt;a href=&#34;https://ollama.ai/&#34;&gt;Ollama&lt;/a&gt;) are provided, with specific-model template generation from the same input with advanced things like model-resume. Feel free to swap models midway through a conversation!&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Single production dependency&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The only prod dependency is &lt;a href=&#34;https://github.com/sql-js/sql.js&#34;&gt;sql.js&lt;/a&gt;, so you&#39;re not dragging along &lt;a href=&#34;https://nodesource.com/blog/is-guy-fieri-in-your-node-js-packages/&#34;&gt;Guy Fieri&lt;/a&gt; if you don&#39;t want to.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Exposed prompts - do your own thing&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Use the entire functionality, or don&#39;t. Most key functions are exposed, including those for prompt generation. Use as you wish.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Better Search&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Search history&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The LLM is appropriately fed past queries, so users can ask contextual questions (&#39;What trains go to paris?&#39; followed by &#39;any leaving at 10 am&#39;) and have auto-merged filters.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Automated Dynamic Enums&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The structured DDL format used internally (and generated by the AI Quickstart) contains the option for you to propose static examples for each column, to make the contents of a field clear to the model. WishfulSearch can also dynamically generate example values (with type detection) on each insert, so this is done with no effort. It can also pick the most frequent values in a column, or find the range and pass that on for token savings.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Safer search&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;While running auto-generated queries can never be properly safe. WishfulSearch implements a few filters to sanitize the output, as well only having the LLM generate partial queries to try and improve safety. Ideally this is used in cases where having the entire db exposed to the user is not a security risk.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;p&gt;Server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm i wishful-search&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Client:&lt;/p&gt; &#xA;&lt;p&gt;Just get the &lt;a href=&#34;https://cdn.jsdelivr.net/npm/wishful-search@0.0.3/release/wishful-search.min.js&#34;&gt;bundled wishfulsearch.js&lt;/a&gt;, or compile a smaller one yourself from source. More instructions coming if this ends up a common use-case.&lt;/p&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;h3&gt;Selecting your model&lt;/h3&gt; &#xA;&lt;p&gt;You&#39;ll need an OpenAI or Anthropic instance (unless you&#39;re using Ollama and &lt;a href=&#34;https://mistral.ai/news/announcing-mistral-7b/&#34;&gt;Mistral&lt;/a&gt;, in which case you just need to pull in an adapter).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import OpenAI from &#39;openai&#39;;&#xA;const openai = new OpenAI();&#xA;&#xA;import Anthropic from &#39;@anthropic-ai/sdk&#39;;&#xA;const anthropic = new Anthropic();&#xA;&#xA;const GPTLLMAdapter = LLMAdapters.getOpenAIAdapter(openai, {&#xA;  model: &#39;gpt-4&#39;,&#xA;});&#xA;&#xA;const ClaudeLLMAdapter = LLMAdapters.getClaudeAdapter(&#xA;  Anthropic.HUMAN_PROMPT,&#xA;  Anthropic.AI_PROMPT,&#xA;  anthropic,&#xA;  {&#xA;    model: &#39;claude-2&#39;,&#xA;  },&#xA;);&#xA;&#xA;const MistralLLMAdapter = LLMAdapters.getMistralAdapter({&#xA;  model: &#39;mistral&#39;,&#xA;  temperature: 0.1,&#xA;});&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can now use any of these for the Quickstart or Search functions.&lt;/p&gt; &#xA;&lt;h2&gt;AI Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;WishfulSearch needs three things from you:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Structured DDL: This is just an object that encodes the column names, types, examples, description and so on, in the SQL tables that are created.&lt;/li&gt; &#xA; &lt;li&gt;ObjectToRelational Function: This is the function that takes a (nested) object and converts it to flat rows that can be inserted into tables.&lt;/li&gt; &#xA; &lt;li&gt;Primary table and column: Just the name of the main table (usually the first one) and the column inside the main table to be used as the retrieval id.&lt;/li&gt; &#xA; &lt;li&gt;(Optional) Few-shot learning: &lt;a href=&#34;https://olickel.com/everything-i-know-about-prompting-llms#fewshotlearningtakethebotfishing&#34;&gt;This is the most useful thing you can do&lt;/a&gt; to improve performance. Look through the examples, or generate your own at runtime with a function call.&lt;/li&gt; &#xA; &lt;li&gt;(Optional) sql.js wasm file: If you use this client-side, you&#39;ll need to provide a URL or a file that sql.js can use to do it&#39;s thing. &lt;a href=&#34;https://github.com/sql-js/sql.js#usage&#34;&gt;You can look here&lt;/a&gt; for more information.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;All of the required pieces can be generated by the AI Quickstart:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import OpenAI from &#39;openai&#39;;&#xA;const openai = new OpenAI();&#xA;import { autoAnalyzeObject, LLMAdapters } from &#39;wishful-search&#39;;&#xA;const GPTLLMAdapter = LLMAdapters.getOpenAIAdapter(openai, {&#xA;  model: &#39;gpt-4&#39;,&#xA;});&#xA;const results = await autoAnalyzeObject(&#xA;  movies[0],&#xA;  GPTLLMAdapter.callLLM,&#xA;  &#39;~/tmp&#39;,&#xA;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;GPT-4 and Claude-2 perform similarly and are recommended.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;results&lt;/code&gt; will contain the same info as an &lt;code&gt;analysis_{date}.md&lt;/code&gt; file placed in the directory of your choice. The file should contain instructions, along with the structured DDL and the ObjectToRelational function. Make sure to read the code - if your objects are complex it might need some tweaking - before you use it!&lt;/p&gt; &#xA;&lt;p&gt;Smart models can get you 99% of the way there in most cases, but some common things to look out for:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;No dynamic enum settings in the structured DDL - you may not need these, but GPT-4 finds it hard to recommend any.&lt;/li&gt; &#xA; &lt;li&gt;No default values in case your objects are sometimes missing fields. We generate the entire thing from a single object, so the model simply doesn&#39;t know which fields are missing or optional. Providing your own typespec as a parameter should fix this.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Create&lt;/h3&gt; &#xA;&lt;p&gt;Once you have these, you can create a new WishfulSearch instance:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;const wishfulSearchEngine = await WishfulSearchEngine.create(&#xA;    &#39;movies&#39;, // Name for your search instance, for labelling&#xA;    MOVIES_DDL, // Structured DDL&#xA;    {&#xA;      table: &#39;Movies&#39;, // Primary table&#xA;      column: &#39;id&#39;, // Primary id column&#xA;    },&#xA;    movieToRows, // Object to relational function&#xA;    {&#xA;      enableTodaysDate: true, // Inform the model about the date&#xA;      fewShotLearning: [], // Few-shot examples&#xA;    },&#xA;    GPT4LLMAdapter.callLLM, // LLM calling function&#xA;    (movie: Movie) =&amp;gt; movie.id, // Object to id function&#xA;    true, // Save question history?&#xA;    true, // Enable dynamic enums on insert?&#xA;    true // Sort dynamic enums by frequency? Light performance penalty on insert but better searches and token savings&#xA;  &#x9;undefined // sql.js wasm URL&#xA;  );&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Insert&lt;/h3&gt; &#xA;&lt;p&gt;You can insert your objects into the instance by simply passing them in:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;const errors = wishfulSearchEngine.insert(TEST_MOVIES);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In this case, any insertion errors are passed back to you as an array. If you enable the second parameter, all insertion is rolled back when an error is encountered, and an exception is thrown.&lt;/p&gt; &#xA;&lt;h3&gt;AI Few-shot generation&lt;/h3&gt; &#xA;&lt;p&gt;Use larger models to teach smaller models how to behave in a few lines! Import a smarter model adapter (see above) and pass it into &lt;code&gt;autoGenerateFewShot&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;await wishfulSearchEngine.autoGenerateFewShot(&#xA;  SmarterLLMAdapter.callLLM,&#xA;  [&#xA;    {&#xA;      question: &#39;something romantic?&#39;,&#xA;    },&#xA;    {&#xA;      question: &#39;from the 80s?&#39;,&#xA;    },&#xA;    {&#xA;      question: &#39;okay sci-fi instead.&#39;,&#xA;      clearHistory: true,&#xA;    },&#xA;  ],&#xA;  false, // Should we remove questions that don&#39;t get results?&#xA;  false, // throw an error on invalid questions&#xA;  true, // Be verbose&#xA;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;clearHistory&lt;/code&gt; is recommended in between, to teach the model when to reset the filters based on user questions.&lt;/p&gt; &#xA;&lt;p&gt;The function also returns the same format of question-answers used to create the instance, so you can save or edit it - or mix and match with generations from different models!&lt;/p&gt; &#xA;&lt;h3&gt;Search&lt;/h3&gt; &#xA;&lt;p&gt;This is the easy bit.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;const results = (await wishfulSearchEngine.search(&#xA;  &#39;Something romantic but not very short from the 80s&#39;,&#xA;)) as Movie[];&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Autosearch&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/hrishioa/wishful-search/assets/973967/e7ed6b50-5963-4f04-84b3-2fc02c8303e2&#34;&gt;https://github.com/hrishioa/wishful-search/assets/973967/e7ed6b50-5963-4f04-84b3-2fc02c8303e2&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Autosearch adds analysis and looping to iteratively improve results. Standard search is blind - while the LLM is made aware of the contents of the tables, it doesn&#39;t know how it did.&lt;/p&gt; &#xA;&lt;p&gt;Autosearch provides this information back to the LLM, along with results of past rounds, to hypothesize about what the user wants, and what is being delivered. For more complex searches - where you have the tokens and time - this can greatly improve results. See &lt;code&gt;/tests/movies.autosearch.ts&lt;/code&gt; for an example.&lt;/p&gt; &#xA;&lt;p&gt;The function documentation explains each parameter for autosearch in more detail.&lt;/p&gt; &#xA;&lt;h1&gt;Example: Movies&lt;/h1&gt; &#xA;&lt;p&gt;The demo shows filters in the &lt;a href=&#34;https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/&#34;&gt;Kaggle movies&lt;/a&gt; dataset.&lt;/p&gt; &#xA;&lt;p&gt;To use:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download &lt;code&gt;movies_metadata.csv&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Place it in &lt;code&gt;tests/data&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;tests/movies.run.ts&lt;/code&gt; with &lt;code&gt;npx ts-node tests/movies.run.ts&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You can uncomment the different adapters for GPT, Claude, Mistral. Comment and uncomment the few-shot generation to see how behavior changes. Have fun!&lt;/p&gt; &#xA;&lt;h1&gt;How it works&lt;/h1&gt; &#xA;&lt;p&gt;A few things happen in order to perform a search:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The JSON objects are converted to relational tables with foreign-keys and stored in the embedded sqlite db.&lt;/li&gt; &#xA; &lt;li&gt;Dynamic enum values are generated to help inform the LLM about the contents of each relevant column.&lt;/li&gt; &#xA; &lt;li&gt;User queries are translated into complete context, including table structure, contents, past questions, and passed to the LLM to generate a SQL query that retrieves the relevant ids.&lt;/li&gt; &#xA; &lt;li&gt;Results of the query are (optionally) used to retrieve the relevant object and returned to the caller.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Authenticating with APIs&lt;/h2&gt; &#xA;&lt;p&gt;The simplest and safest method is going to be using &lt;code&gt;export OPENAI_API_KEY=XXXX&lt;/code&gt; or &lt;code&gt;export ANTHROPIC_API_KEY=XXXX&lt;/code&gt; before running your code. You can also instantiate your &lt;code&gt;openai&lt;/code&gt; and &lt;code&gt;anthropic&lt;/code&gt; objects with the API keys inside, as per the guides linked for each sdk above.&lt;/p&gt; &#xA;&lt;h2&gt;Other utilities&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;llm-adapters.ts&lt;/code&gt; exposes the templating functions for each model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;WishfulSearchEngine&lt;/code&gt; exposes the following additional functions: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;generateSearchMessages&lt;/code&gt; returns (in OpenAI message format) the messages that go to the LLM to generate the query.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;searchWithPartialQuery&lt;/code&gt; can be used to perform the search with the query response you get from the LLM.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Where are the prompts?&lt;/h2&gt; &#xA;&lt;p&gt;I tend to read repos prompt first. In this case, most of the complexity is in formatting the output and injecting things at the right time, but if you&#39;d like to do the same, here are the prompts for &lt;a href=&#34;https://raw.githubusercontent.com/hrishioa/wishful-search/master/src/auto-analyze.ts&#34;&gt;AI Quickstart&lt;/a&gt; and for &lt;a href=&#34;https://raw.githubusercontent.com/hrishioa/wishful-search/master/src/magic-search.ts&#34;&gt;Search&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;TODO&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Tests: More robust tests are needed before production usage. Unfortunately that&#39;s outside my scope at the moment, but I&#39;ll update the repo if I get around to it! Help would be appreciated.&lt;/li&gt; &#xA; &lt;li&gt;Client-side testing: The client-side bundle has been tested in a limited fashion. It&#39;s hard to keep running all the toolchains without automated testing for now. If you run into any issues, let me know.&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>HerbertHe/iptv-sources</title>
    <updated>2023-12-17T01:48:29Z</updated>
    <id>tag:github.com,2023-12-17:/HerbertHe/iptv-sources</id>
    <link href="https://github.com/HerbertHe/iptv-sources" rel="alternate"></link>
    <summary type="html">&lt;p&gt;自动抓取更新iptv源 Autoupdate iptv sources&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;iptv-sources&lt;/h1&gt; &#xA;&lt;p&gt;Autoupdate iptv sources&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/herberthe0229/iptv-sources&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/automated/herberthe0229/iptv-sources?style=flat-square&#34; alt=&#34;Docker Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/herberthe0229/iptv-sources&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/v/herberthe0229/iptv-sources?style=flat-square&#34; alt=&#34;Docker Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/herberthe0229/iptv-sources&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/image-size/herberthe0229/iptv-sources/latest?style=flat-square&#34; alt=&#34;Docker Image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/herberthe0229/iptv-sources&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/herberthe0229/iptv-sources?style=flat-square&#34; alt=&#34;Docker Pulls&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/herberthe0229/iptv-sources&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/stars/herberthe0229/iptv-sources?style=flat-square&#34; alt=&#34;Docker Stars&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Join discord: &lt;a href=&#34;https://discord.gg/betxHcsTqa&#34;&gt;&lt;img src=&#34;https://discord.badge.ibert.me/api/server/betxHcsTqa&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Sources are from:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://epg.pw/test_channel_page.html&#34;&gt;https://epg.pw/test_channel_page.html&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/iptv-org/iptv&#34;&gt;iptv.org&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/YueChan/Live&#34;&gt;YueChan/Live&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/YanG-1989/m3u&#34;&gt;YanG-1989/m3u&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/fanmingming/live&#34;&gt;fanmingming/live&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://m3u.ibert.me&#34;&gt;https://m3u.ibert.me&lt;/a&gt; to get more.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Use CDN &lt;strong&gt;(Not recommended)&lt;/strong&gt;: You can use &lt;code&gt;https://fastly.jsdelivr.net/gh/HerbertHe/iptv-sources@gh-pages/&lt;/code&gt; to replace &lt;code&gt;https://m3u.ibert.me/&lt;/code&gt; for using CDN Service. Due to the &lt;strong&gt;Cache Policy&lt;/strong&gt; of CDN, the content wouldn&#39;t be the latest, the m3u files would be updated every &lt;strong&gt;3 hours&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;使用 CDN &lt;strong&gt;（不建议）&lt;/strong&gt;：你可以通过 &lt;code&gt;https://fastly.jsdelivr.net/gh/HerbertHe/iptv-sources@gh-pages/&lt;/code&gt; 替换 &lt;code&gt;https://m3u.ibert.me/&lt;/code&gt; 来使用 CDN 服务。由于 CDN 的 &lt;strong&gt;缓存策略&lt;/strong&gt;，内容不会是最新的，m3u 文件每 &lt;strong&gt;3 小时&lt;/strong&gt; 会更新一次。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Deploy by yourself&lt;/h2&gt; &#xA;&lt;p&gt;You can also deploy the project by yourself with docker.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --name iptv-sources -p 3000:8080 -d herberthe0229/iptv-sources:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run &lt;code&gt;docker ps&lt;/code&gt; to get container status.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Wait a minute, visit &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Then, you can use &lt;code&gt;http://localhost:3000&lt;/code&gt; instead of &lt;code&gt;https://m3u.ibert.me&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For example: &lt;code&gt;https://m3u.ibert.me/cn.m3u&lt;/code&gt; -&amp;gt; &lt;code&gt;http://localhost:3000/cn.m3u&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Or, you can also deploy with your own server &amp;amp; domain.&lt;/p&gt; &#xA;&lt;h2&gt;Crontab&lt;/h2&gt; &#xA;&lt;p&gt;Maybe you want to set schedule for auto-updating per 2 hours.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Download bash script file &lt;code&gt;iptv-sources.sh&lt;/code&gt; &lt;a href=&#34;https://fastly.jsdelivr.net/gh/HerbertHe/iptv-sources@main/iptv-sources.sh&#34;&gt;https://fastly.jsdelivr.net/gh/HerbertHe/iptv-sources@main/iptv-sources.sh&lt;/a&gt; to your homedir.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Edit you crontab:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;crontab -e&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Press keyboard &lt;code&gt;i&lt;/code&gt; for adding schedule.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Add:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cron&#34;&gt;0 */2 * * * /bin/sh ~/iptv-sources.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Press keyboard &lt;code&gt;ESC&lt;/code&gt; to exit edit mode&lt;/li&gt; &#xA; &lt;li&gt;Type &lt;code&gt;:wq&lt;/code&gt; to save&lt;/li&gt; &#xA; &lt;li&gt;Restart crontab service&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;service crond restart&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;LICENSE&lt;/h2&gt; &#xA;&lt;p&gt;MIT © Herbert He 2023&lt;/p&gt;</summary>
  </entry>
</feed>