<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-04-25T01:34:45Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>mishushakov/llm-scraper</title>
    <updated>2024-04-25T01:34:45Z</updated>
    <id>tag:github.com,2024-04-25:/mishushakov/llm-scraper</id>
    <link href="https://github.com/mishushakov/llm-scraper" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Turn any webpage into structured data using LLMs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LLM Scraper&lt;/h1&gt; &#xA;&lt;img width=&#34;1800&#34; alt=&#34;Screenshot 2024-04-20 at 23 11 16&#34; src=&#34;https://github.com/mishushakov/llm-scraper/assets/10400064/ab00e048-a9ff-43b6-81d5-2e58090e2e65&#34;&gt; &#xA;&lt;p&gt;LLM Scraper is a TypeScript library that allows you to convert &lt;strong&gt;any&lt;/strong&gt; webpages into structured data using LLMs.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] Under the hood, it uses function calling to convert pages to structured data. You can find more about this approach &lt;a href=&#34;https://til.simonwillison.net/gpt3/openai-python-functions-data-extraction&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Supports &lt;strong&gt;Local (GGUF)&lt;/strong&gt;, OpenAI, Groq chat models&lt;/li&gt; &#xA; &lt;li&gt;Schemas defined with Zod&lt;/li&gt; &#xA; &lt;li&gt;Full type-safety with TypeScript&lt;/li&gt; &#xA; &lt;li&gt;Based on Playwright framework&lt;/li&gt; &#xA; &lt;li&gt;Streaming when crawling multiple pages&lt;/li&gt; &#xA; &lt;li&gt;Supports 4 input modes: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;html&lt;/code&gt; for loading raw HTML&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;markdown&lt;/code&gt; for loading markdown&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;text&lt;/code&gt; for loading extracted text (using &lt;a href=&#34;https://github.com/mozilla/readability&#34;&gt;Readability.js&lt;/a&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;image&lt;/code&gt; for loading a screenshot (multi-modal only)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Make sure to give it a star!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;img width=&#34;165&#34; alt=&#34;Screenshot 2024-04-20 at 22 13 32&#34; src=&#34;https://github.com/mishushakov/llm-scraper/assets/10400064/11e2a79f-a835-48c4-9f85-5c104ca7bb49&#34;&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Install the required dependencies from npm:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;npm i zod playwright llm-scraper&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Initialize your LLM:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import OpenAI from &#39;openai&#39;&#xA;const model = new OpenAI()&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Local&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import { LlamaModel } from &#39;node-llama-cpp&#39;&#xA;const model = new LlamaModel({ modelPath: &#39;model.gguf&#39; })&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create a new browser instance and attach LLMScraper to it:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import { chromium } from &#39;playwright&#39;&#xA;import LLMScraper from &#39;llm-scraper&#39;&#xA;&#xA;const browser = await chromium.launch()&#xA;const scraper = new LLMScraper(browser, model)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;In this example, we&#39;re extracting top stories from HackerNews:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ts&#34;&gt;import { chromium } from &#39;playwright&#39;&#xA;import { z } from &#39;zod&#39;&#xA;import OpenAI from &#39;openai&#39;&#xA;import LLMScraper from &#39;llm-scraper&#39;&#xA;&#xA;// Launch a browser instance&#xA;const browser = await chromium.launch()&#xA;&#xA;// Initialize LLM provider&#xA;const llm = new OpenAI()&#xA;&#xA;// Create a new LLMScraper&#xA;const scraper = new LLMScraper(browser, llm)&#xA;&#xA;// Define schema to extract contents into&#xA;const schema = z.object({&#xA;  top: z&#xA;    .array(&#xA;      z.object({&#xA;        title: z.string(),&#xA;        points: z.number(),&#xA;        by: z.string(),&#xA;        commentsURL: z.string(),&#xA;      })&#xA;    )&#xA;    .length(5)&#xA;    .describe(&#39;Top 5 stories on Hacker News&#39;),&#xA;})&#xA;&#xA;// URLs to scrape&#xA;const urls = [&#39;https://news.ycombinator.com&#39;]&#xA;&#xA;// Run the scraper&#xA;const pages = await scraper.run(urls, {&#xA;  model: &#39;gpt-4-turbo&#39;,&#xA;  schema,&#xA;  mode: &#39;html&#39;,&#xA;  closeOnFinish: true,&#xA;})&#xA;&#xA;// Stream the result from LLM&#xA;for await (const page of pages) {&#xA;  console.log(page.data)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;As an open-source project, we welcome contributions from the community. If you are experiencing any bugs or want to add some improvements, please feel free to open an issue or pull request.&lt;/p&gt;</summary>
  </entry>
</feed>