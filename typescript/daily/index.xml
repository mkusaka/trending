<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-05T01:45:19Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Nutlope/roomGPT</title>
    <updated>2023-03-05T01:45:19Z</updated>
    <id>tag:github.com,2023-03-05:/Nutlope/roomGPT</id>
    <link href="https://github.com/Nutlope/roomGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Upload a photo of your room to generate your dream room with AI.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href=&#34;https://roomGPT.io&#34;&gt;roomGPT.io&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;This project generates designs of your room with AI.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://roomGPT.io&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Nutlope/roomGPT/main/public/screenshot.png&#34; alt=&#34;Room GPT&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;How it works&lt;/h2&gt; &#xA;&lt;p&gt;It uses an ML model called &lt;a href=&#34;https://github.com/lllyasviel/ControlNet&#34;&gt;ControlNet&lt;/a&gt; to generate variations of rooms. This application gives you the ability to upload a photo of any room, which will send it through this ML Model using a Next.js API route, and return your generated room. The ML Model is hosted on &lt;a href=&#34;https://replicate.com&#34;&gt;Replicate&lt;/a&gt; and &lt;a href=&#34;https://upload.io&#34;&gt;Upload&lt;/a&gt; is used for image storage.&lt;/p&gt; &#xA;&lt;h2&gt;Running Locally&lt;/h2&gt; &#xA;&lt;h3&gt;Cloning the repository the local machine.&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/Nutlope/roomGPT&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Creating a account on Replicate to get an API key.&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Go to &lt;a href=&#34;https://replicate.com/&#34;&gt;Replicate&lt;/a&gt; to make an account.&lt;/li&gt; &#xA; &lt;li&gt;Click on your profile picture in the top right corner, and click on &#34;Dashboard&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Click on &#34;Account&#34; in the navbar. And, here you can find your API token, copy it.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Storing the API keys in .env&lt;/h3&gt; &#xA;&lt;p&gt;Create a file in root directory of project with env. And store your API key in it, as shown in the .example.env file.&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;d also like to do rate limiting, create an account on UpStash, create a Redis database, and populate the two environment variables in &lt;code&gt;.env&lt;/code&gt; as well. If you don&#39;t want to do rate limiting, you don&#39;t need to make any changes.&lt;/p&gt; &#xA;&lt;h3&gt;Installing the dependencies.&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running the application.&lt;/h3&gt; &#xA;&lt;p&gt;Then, run the application in the command line and it will be available at &lt;code&gt;http://localhost:3000&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;One-Click Deploy&lt;/h2&gt; &#xA;&lt;p&gt;Deploy the example using &lt;a href=&#34;https://vercel.com?utm_source=github&amp;amp;utm_medium=readme&amp;amp;utm_campaign=vercel-examples&#34;&gt;Vercel&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://vercel.com/new/clone?repository-url=https://github.com/Nutlope/roomGPT&amp;amp;env=REPLICATE_API_KEY&amp;amp;project-name=room-GPT&amp;amp;repo-name=roomGPT&#34;&gt;&lt;img src=&#34;https://vercel.com/button&#34; alt=&#34;Deploy with Vercel&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>circlestarzero/EX-chatGPT</title>
    <updated>2023-03-05T01:45:19Z</updated>
    <id>tag:github.com,2023-03-05:/circlestarzero/EX-chatGPT</id>
    <link href="https://github.com/circlestarzero/EX-chatGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Let ChatGPT truly learn how to go online and call APIs! &#39;EX-ChatGPT&#39; can rival and even surpass NewBing&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;EX-chatGPT introduction&lt;/h1&gt; &#xA;&lt;h2&gt;update&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;update OpenAI GPT3.5 Turbo offical API support, super fast and cheap.&lt;/li&gt; &#xA; &lt;li&gt;update extra API calls and search summarizations to give a more comprehensive and detailed answer.&lt;/li&gt; &#xA; &lt;li&gt;update chat history token optimizer, and the web mode can response according to the chat history.Add token cost counter. &lt;img src=&#34;https://raw.githubusercontent.com/circlestarzero/EX-chatGPT/main/img/webHistory.jpg&#34; alt=&#34;history&#34;&gt;&lt;/li&gt; &#xA; &lt;li&gt;upate web chatmode selection in webpage and optimize the prompt and the token cost, and restrict the token limit. &lt;img src=&#34;https://raw.githubusercontent.com/circlestarzero/EX-chatGPT/main/img/mode.jpg&#34; alt=&#34;mode&#34;&gt;&lt;/li&gt; &#xA; &lt;li&gt;update better suppoer chinese query and add current date info &lt;img src=&#34;https://raw.githubusercontent.com/circlestarzero/EX-chatGPT/main/img/date.jpg&#34; alt=&#34;date&#34;&gt;&lt;/li&gt; &#xA; &lt;li&gt;update web chatmode and fix some bugs&lt;/li&gt; &#xA; &lt;li&gt;update api config&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Background&lt;/h2&gt; &#xA;&lt;p&gt;&#34;ChatGPT as Inherent Toolformer&#34; means that ChatGPT has the ability to become a tool for various tasks without requiring additional adjustments.&lt;/p&gt; &#xA;&lt;p&gt;However, ChatGPT has some limitations such as being unable to connect to the internet and difficulty solving math problems.&lt;/p&gt; &#xA;&lt;p&gt;ToolFormer enables language models to use specific tools for different tasks. Can ChatGPT be equipped with ToolFormer&#39;s abilities?&lt;/p&gt; &#xA;&lt;p&gt;The challenge is how to adapt ToolFormer&#39;s API generation process to ChatGPT.&lt;/p&gt; &#xA;&lt;p&gt;Recent experiments demonstrate that given a specific prompt, ChatGPT has a natural ability to create APIs for text.&lt;/p&gt; &#xA;&lt;p&gt;Therefore, it can be concluded that ChatGPT has inherent ToolFormer capabilities!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.04761&#34;&gt;Toolformer Paper&lt;/a&gt; the subproject WebChatGPT enchanced is based on &lt;a href=&#34;https://github.com/qunash/chatgpt-advanced&#34;&gt;WebChatGPT chrome extension&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV19Y411r7Bd/&#34;&gt;ExChatGPT-bilibili&lt;/a&gt; API call Demos: &lt;img src=&#34;https://raw.githubusercontent.com/circlestarzero/EX-chatGPT/main/img/API.jpg&#34; alt=&#34;API&#34;&gt; QA Demos: &lt;img src=&#34;https://raw.githubusercontent.com/circlestarzero/EX-chatGPT/main/img/math.jpg&#34; alt=&#34;math&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/circlestarzero/EX-chatGPT/main/img/zhihuq0.jpg&#34; alt=&#34;zhihu&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/circlestarzero/EX-chatGPT/main/img/zhihuq1.jpg&#34; alt=&#34;zhihu&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/circlestarzero/EX-chatGPT/main/img/zhihuq2.jpg&#34; alt=&#34;zhihu&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/circlestarzero/EX-chatGPT/main/img/zhihuq3.jpg&#34; alt=&#34;zhihu&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;h2&gt;Ex-chatGPT&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;pip install&lt;/code&gt; &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;fill your &lt;code&gt;API keys&lt;/code&gt; in &lt;code&gt;apikey.ini&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;Google api key and search engine id&lt;/code&gt; &lt;a href=&#34;https://developers.google.com/custom-search/v1/overview?hl=en&#34;&gt;apply&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;wolframAlpha app id key&lt;/code&gt; &lt;a href=&#34;https://products.wolframalpha.com/api/&#34;&gt;apply&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;openAI api key&lt;/code&gt;(new feature) or &lt;code&gt;chatGPT access_token&lt;/code&gt;(old version) &lt;a href=&#34;https://platform.openai.com&#34;&gt;apply&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;run the &lt;code&gt;main.py&lt;/code&gt; and click the local url like &lt;code&gt;http://127.0.0.1:5000/&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;change the mode in the selection box, now have &lt;code&gt;chat,detail,web&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;WebChatGPTEnhance&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;fill you &lt;code&gt;Googgle api key and client id&lt;/code&gt; in &lt;code&gt;chatGPTChromeEhance/src/util/apiManager.ts/getDefaultAPI&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;run &lt;code&gt;npm install&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;run &lt;code&gt;npm run build-prod&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;get the extension in &lt;code&gt;chatGPTChromeEhance/build&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;add your &lt;code&gt;prompts&lt;/code&gt; and &lt;code&gt;APIs&lt;/code&gt; in option page. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;APIs&lt;/code&gt; and &lt;code&gt;prompts&lt;/code&gt; examples are in &lt;code&gt;/WebChatGPTAPI&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;wolframAlpha&lt;/code&gt; needs to run local sever - &lt;code&gt;WebChatGPTAPI/WolframLocalServer.py&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>mckaywrigley/paul-graham-gpt</title>
    <updated>2023-03-05T01:45:19Z</updated>
    <id>tag:github.com,2023-03-05:/mckaywrigley/paul-graham-gpt</id>
    <link href="https://github.com/mckaywrigley/paul-graham-gpt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AI search &amp; chat for all of Paul Grahamâ€™s essays.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Paul Graham GPT&lt;/h1&gt; &#xA;&lt;p&gt;AI-powered search and chat for &lt;a href=&#34;https://twitter.com/paulg&#34;&gt;Paul Graham&#39;s&lt;/a&gt; &lt;a href=&#34;http://www.paulgraham.com/articles.html&#34;&gt;essays&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;All code &amp;amp; data used is 100% open-source.&lt;/p&gt; &#xA;&lt;h2&gt;Dataset&lt;/h2&gt; &#xA;&lt;p&gt;The dataset is a CSV file containing all text &amp;amp; embeddings used.&lt;/p&gt; &#xA;&lt;p&gt;Download it &lt;a href=&#34;https://drive.google.com/file/d/1BxcPw2mn0VYFucc62wlt9H0nQiOu38ki/view?usp=sharing&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;I recommend getting familiar with fetching, cleaning, and storing data as outlined in the scraping and embedding scripts below, but feel free to skip those steps and just use the dataset.&lt;/p&gt; &#xA;&lt;h2&gt;How It Works&lt;/h2&gt; &#xA;&lt;p&gt;Paul Graham GPT provides 2 things:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;A search interface.&lt;/li&gt; &#xA; &lt;li&gt;A chat interface.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Search&lt;/h3&gt; &#xA;&lt;p&gt;Search was created with &lt;a href=&#34;https://platform.openai.com/docs/guides/embeddings&#34;&gt;OpenAI Embeddings&lt;/a&gt; (&lt;code&gt;text-embedding-ada-002&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;First, we loop over the essays and generate embeddings for each chunk of text.&lt;/p&gt; &#xA;&lt;p&gt;Then in the app we take the user&#39;s search query, generate an embedding, and use the result to find the most similar passages from the book.&lt;/p&gt; &#xA;&lt;p&gt;The comparison is done using cosine similarity across our database of vectors.&lt;/p&gt; &#xA;&lt;p&gt;Our database is a Postgres database with the &lt;a href=&#34;https://github.com/pgvector/pgvector&#34;&gt;pgvector&lt;/a&gt; extension hosted on &lt;a href=&#34;https://supabase.com/&#34;&gt;Supabase&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Results are ranked by similarity score and returned to the user.&lt;/p&gt; &#xA;&lt;h3&gt;Chat&lt;/h3&gt; &#xA;&lt;p&gt;Chat builds on top of search. It uses search results to create a prompt that is fed into GPT-3.5-turbo.&lt;/p&gt; &#xA;&lt;p&gt;This allows for a chat-like experience where the user can ask questions about the book and get answers.&lt;/p&gt; &#xA;&lt;h2&gt;Running Locally&lt;/h2&gt; &#xA;&lt;p&gt;Here&#39;s a quick overview of how to run it locally.&lt;/p&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Set up OpenAI&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You&#39;ll need an OpenAI API key to generate embeddings.&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Set up Supabase and create a database&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Note: You don&#39;t have to use Supabase. Use whatever method you prefer to store your data. But I like Supabase and think it&#39;s easy to use.&lt;/p&gt; &#xA;&lt;p&gt;There is a schema.sql file in the root of the repo that you can use to set up the database.&lt;/p&gt; &#xA;&lt;p&gt;Run that in the SQL editor in Supabase as directed.&lt;/p&gt; &#xA;&lt;p&gt;I recommend turning on Row Level Security and setting up a service role to use with the app.&lt;/p&gt; &#xA;&lt;h3&gt;Repo Setup&lt;/h3&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Clone repo&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/mckaywrigley/paul-graham-gpt.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Install dependencies&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm i&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;Set up environment variables&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Create a .env.local file in the root of the repo with the following variables:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;OPENAI_API_KEY=&#xA;&#xA;NEXT_PUBLIC_SUPABASE_URL=&#xA;SUPABASE_SERVICE_ROLE_KEY=&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Dataset&lt;/h3&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;Run scraping script&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run scrape&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This scrapes all of the essays from Paul Graham&#39;s website and saves them to a json file.&lt;/p&gt; &#xA;&lt;ol start=&#34;7&#34;&gt; &#xA; &lt;li&gt;Run embedding script&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run embed&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This reads the json file, generates embeddings for each chunk of text, and saves the results to your database.&lt;/p&gt; &#xA;&lt;p&gt;There is a 200ms delay between each request to avoid rate limiting.&lt;/p&gt; &#xA;&lt;p&gt;This process will take 20-30 minutes.&lt;/p&gt; &#xA;&lt;h3&gt;App&lt;/h3&gt; &#xA;&lt;ol start=&#34;8&#34;&gt; &#xA; &lt;li&gt;Run app&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;Thanks to &lt;a href=&#34;https://twitter.com/paulg&#34;&gt;Paul Graham&lt;/a&gt; for his writing.&lt;/p&gt; &#xA;&lt;p&gt;I highly recommend you read his essays.&lt;/p&gt; &#xA;&lt;p&gt;3 years ago they convinced me to learn to code, and it changed my life.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions, feel free to reach out to me on &lt;a href=&#34;https://twitter.com/mckaywrigley&#34;&gt;Twitter&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Notes&lt;/h2&gt; &#xA;&lt;p&gt;I sacrificed composability for simplicity in the app.&lt;/p&gt; &#xA;&lt;p&gt;Yes, you can make things more modular and reusable.&lt;/p&gt; &#xA;&lt;p&gt;But I kept pretty much everything in the homepage component for the sake of simplicity.&lt;/p&gt;</summary>
  </entry>
</feed>