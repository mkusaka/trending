<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-18T01:40:31Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ReactiveX/rxjs</title>
    <updated>2022-12-18T01:40:31Z</updated>
    <id>tag:github.com,2022-12-18:/ReactiveX/rxjs</id>
    <link href="https://github.com/ReactiveX/rxjs" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A reactive programming library for JavaScript&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ReactiveX/rxjs/master/docs_app/src/assets/images/logos/Rx_Logo_S.png&#34; alt=&#34;RxJS Logo&#34; width=&#34;86&#34; height=&#34;86&#34;&gt; RxJS: Reactive Extensions For JavaScript&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/reactivex/rxjs/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt; &lt;a href=&#34;http://badge.fury.io/js/rxjs&#34;&gt;&lt;img src=&#34;https://badge.fury.io/js/rxjs.svg?sanitize=true&#34; alt=&#34;npm version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/Reactive-Extensions/RxJS?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/Join%20Chat.svg?sanitize=true&#34; alt=&#34;Join the chat at https://gitter.im/Reactive-Extensions/RxJS&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;The Roadmap from RxJS 7 to 8&lt;/h1&gt; &#xA;&lt;p&gt;Curious what&#39;s next for RxJS? Follow along with &lt;a href=&#34;https://github.com/ReactiveX/rxjs/issues/6367&#34;&gt;Issue 6367&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;RxJS 7&lt;/h1&gt; &#xA;&lt;h3&gt;FOR 6.X PLEASE GO TO &lt;a href=&#34;https://github.com/ReactiveX/rxjs/tree/6.x&#34;&gt;THE 6.x BRANCH&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Reactive Extensions Library for JavaScript. This is a rewrite of &lt;a href=&#34;https://github.com/Reactive-Extensions/RxJS&#34;&gt;Reactive-Extensions/RxJS&lt;/a&gt; and is the latest production-ready version of RxJS. This rewrite is meant to have better performance, better modularity, better debuggable call stacks, while staying mostly backwards compatible, with some breaking changes that reduce the API surface.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ReactiveX/rxjs/master/LICENSE.txt&#34;&gt;Apache 2.0 License&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ReactiveX/rxjs/master/CODE_OF_CONDUCT.md&#34;&gt;Code of Conduct&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ReactiveX/rxjs/master/CONTRIBUTING.md&#34;&gt;Contribution Guidelines&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ReactiveX/rxjs/master/docs_app/content/maintainer-guidelines.md&#34;&gt;Maintainer Guidelines&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://rxjs.dev/&#34;&gt;API Documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Versions In This Repository&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ReactiveX/rxjs/commits/master&#34;&gt;master&lt;/a&gt; - This is all of the current work, which is against v7 of RxJS right now&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ReactiveX/rxjs/tree/6.x&#34;&gt;6.x&lt;/a&gt; - This is the branch for version 6.X&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Most PRs should be made to &lt;strong&gt;master&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Important&lt;/h2&gt; &#xA;&lt;p&gt;By contributing or commenting on issues in this repository, whether you&#39;ve read them or not, you&#39;re agreeing to the &lt;a href=&#34;https://raw.githubusercontent.com/ReactiveX/rxjs/master/CODE_OF_CONDUCT.md&#34;&gt;Contributor Code of Conduct&lt;/a&gt;. Much like traffic laws, ignorance doesn&#39;t grant you immunity.&lt;/p&gt; &#xA;&lt;h2&gt;Installation and Usage&lt;/h2&gt; &#xA;&lt;h3&gt;ES6 via npm&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;npm install rxjs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It&#39;s recommended to pull in the Observable creation methods you need directly from &lt;code&gt;&#39;rxjs&#39;&lt;/code&gt; as shown below with &lt;code&gt;range&lt;/code&gt;. If you&#39;re using RxJS version 7.2 or above, you can pull in any operator you need from the same spot, &lt;code&gt;&#39;rxjs&#39;&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ts&#34;&gt;import { range, filter, map } from &#39;rxjs&#39;;&#xA;&#xA;range(1, 200)&#xA;  .pipe(&#xA;    filter(x =&amp;gt; x % 2 === 1),&#xA;    map(x =&amp;gt; x + x)&#xA;  )&#xA;  .subscribe(x =&amp;gt; console.log(x));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you&#39;re using RxJS version below 7.2, you can pull in any operator you need from one spot, under &lt;code&gt;&#39;rxjs/operators&#39;&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ts&#34;&gt;import { range } from &#39;rxjs&#39;;&#xA;import { filter, map } from &#39;rxjs/operators&#39;;&#xA;&#xA;range(1, 200)&#xA;  .pipe(&#xA;    filter(x =&amp;gt; x % 2 === 1),&#xA;    map(x =&amp;gt; x + x)&#xA;  )&#xA;  .subscribe(x =&amp;gt; console.log(x));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;CDN&lt;/h3&gt; &#xA;&lt;p&gt;For CDN, you can use &lt;a href=&#34;https://unpkg.com/&#34;&gt;unpkg&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://unpkg.com/rxjs@%5E7/dist/bundles/rxjs.umd.min.js&#34;&gt;https://unpkg.com/rxjs@^7/dist/bundles/rxjs.umd.min.js&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The global namespace for rxjs is &lt;code&gt;rxjs&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const { range } = rxjs;&#xA;const { filter, map } = rxjs.operators;&#xA;&#xA;range(1, 200)&#xA;  .pipe(&#xA;    filter(x =&amp;gt; x % 2 === 1),&#xA;    map(x =&amp;gt; x + x)&#xA;  )&#xA;  .subscribe(x =&amp;gt; console.log(x));&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Goals&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Smaller overall bundles sizes&lt;/li&gt; &#xA; &lt;li&gt;Provide better performance than preceding versions of RxJS&lt;/li&gt; &#xA; &lt;li&gt;To model/follow the &lt;a href=&#34;https://github.com/zenparsing/es-observable&#34;&gt;Observable Spec Proposal&lt;/a&gt; to the observable&lt;/li&gt; &#xA; &lt;li&gt;Provide more modular file structure in a variety of formats&lt;/li&gt; &#xA; &lt;li&gt;Provide more debuggable call stacks than preceding versions of RxJS&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Building/Testing&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;npm run compile&lt;/code&gt; build everything&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;npm test&lt;/code&gt; run tests&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;npm run dtslint&lt;/code&gt; run dtslint tests&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Adding documentation&lt;/h2&gt; &#xA;&lt;p&gt;We appreciate all contributions to the documentation of any type. All of the information needed to get the docs app up and running locally as well as how to contribute can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/ReactiveX/rxjs/master/docs_app&#34;&gt;documentation directory&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>opencv/cvat</title>
    <updated>2022-12-18T01:40:31Z</updated>
    <id>tag:github.com,2022-12-18:/opencv/cvat</id>
    <link href="https://github.com/opencv/cvat" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Annotate better with CVAT, the industry-leading data engine for machine learning. Used and trusted by teams at any scale, for data of any scale.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/site/content/en/images/cvat_poster_with_name.png&#34; alt=&#34;CVAT logo&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Computer Vision Annotation Tool (CVAT)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.producthunt.com/posts/cvat-computer-vision-annotation-tool?utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-cvat-computer-vision-annotation-tool&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=353415&amp;amp;theme=light&#34; alt=&#34;CVAT ‚Äì Computer Vision Annotation Tool - The open data annotation platform for AI | Product Hunt&#34; style=&#34;width: 250px; height: 54px;&#34; width=&#34;250&#34; height=&#34;54&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/opencv/cvat/actions&#34;&gt;&lt;img src=&#34;https://github.com/opencv/cvat/workflows/CI/badge.svg?branch=develop&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/opencv-cvat&#34;&gt;&lt;img src=&#34;https://img.shields.io/gitter/room/opencv-cvat/public?style=flat&#34; alt=&#34;Gitter chat&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/fNR3eXfk6C&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1000789942802337834?label=discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://coveralls.io/github/cvat-ai/cvat?branch=develop&#34;&gt;&lt;img src=&#34;https://coveralls.io/repos/github/cvat-ai/cvat/badge.svg?branch=develop&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/cvat/server&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/cvat/server.svg?style=flat-square&amp;amp;label=server%20pulls&#34; alt=&#34;server pulls&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/cvat/ui&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/cvat/ui.svg?style=flat-square&amp;amp;label=UI%20pulls&#34; alt=&#34;ui pulls&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://zenodo.org/badge/latestdoi/139156354&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/139156354.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;CVAT is an interactive video and image annotation tool for computer vision. It is used by tens of thousands of users and companies around the world. Our mission is to help developers, companies, and organizations around the world to solve real problems using the Data-centric AI approach.&lt;/p&gt; &#xA;&lt;p&gt;CVAT is free and open-source.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A new repo&lt;/strong&gt;: CVAT core team moved the active development of the tool to this new repository.&lt;/p&gt; &#xA;&lt;p&gt;Start using CVAT online for free: &lt;a href=&#34;https://cvat.ai&#34;&gt;cvat.ai&lt;/a&gt;. Or set it up as a self-hosted solution: &lt;a href=&#34;https://opencv.github.io/cvat/docs/administration/basics/installation/&#34;&gt;Self-hosted Installation Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/site/content/en/images/cvat-ai-screencast.gif&#34; alt=&#34;CVAT screencast&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick start ‚ö°&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opencv.github.io/cvat/docs/administration/basics/installation/&#34;&gt;Installation guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opencv.github.io/cvat/docs/manual/&#34;&gt;Manual&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opencv.github.io/cvat/docs/contributing/&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cvat-ai/datumaro/raw/develop/README.md&#34;&gt;Datumaro dataset framework&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/#api&#34;&gt;Server API&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/#sdk&#34;&gt;Python SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/#cli&#34;&gt;Command line tool&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opencv.github.io/cvat/docs/manual/advanced/xml_format/&#34;&gt;XML annotation format&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opencv.github.io/cvat/docs/administration/basics/aws-deployment-guide/&#34;&gt;AWS Deployment Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opencv.github.io/cvat/docs/faq/&#34;&gt;Frequently asked questions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/#where-to-ask-questions&#34;&gt;Where to ask questions&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Partners ‚ù§Ô∏è&lt;/h2&gt; &#xA;&lt;p&gt;CVAT is used by teams all over the world. In the list, you can find key companies which help us support the product or an essential part of our ecosystem. If you use us, please drop us a line at &lt;a href=&#34;mailto:contact+github@cvat.ai&#34;&gt;contact@cvat.ai&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hmt.ai&#34;&gt;Human Protocol&lt;/a&gt; uses CVAT as a way of adding annotation service to the Human Protocol.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fiftyone.ai&#34;&gt;FiftyOne&lt;/a&gt; is an open-source dataset curation and model analysis tool for visualizing, exploring, and improving computer vision datasets and models that are &lt;a href=&#34;https://voxel51.com/docs/fiftyone/integrations/cvat.html&#34;&gt;tightly integrated&lt;/a&gt; with CVAT for annotation and label refinement.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Public datasets&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/smhassanerfani/atlantis&#34;&gt;ATLANTIS&lt;/a&gt;, an open-source dataset for semantic segmentation of waterbody images, developed by &lt;a href=&#34;http://ce.sc.edu/iwers/&#34;&gt;iWERS&lt;/a&gt; group in the Department of Civil and Environmental Engineering at the University of South Carolina is using CVAT.&lt;/p&gt; &#xA;&lt;p&gt;For developing a semantic segmentation dataset using CVAT, see:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S1364815222000391&#34;&gt;ATLANTIS published article&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/smhassanerfani/atlantis/tree/master/adk&#34;&gt;ATLANTIS Development Kit&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLIfLGY-zZChS5trt7Lc3MfNhab7OWl2BR&#34;&gt;ATLANTIS annotation tutorial videos&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;CVAT online: &lt;a href=&#34;https://cvat.ai&#34;&gt;cvat.ai&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;This is an online version of CVAT. It&#39;s free, efficient, and easy to use.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cvat.ai&#34;&gt;cvat.ai&lt;/a&gt; runs the latest version of the tool. You can create up to 10 tasks there and upload up to 500Mb of data to annotate. It will only be visible to you or the people you assign to it.&lt;/p&gt; &#xA;&lt;p&gt;For now, it does not have &lt;a href=&#34;https://opencv.github.io/cvat/docs/administration/advanced/analytics/&#34;&gt;analytics features&lt;/a&gt; like management and monitoring the data annotation team.&lt;/p&gt; &#xA;&lt;p&gt;We plan to enhance &lt;a href=&#34;https://cvat.ai&#34;&gt;cvat.ai&lt;/a&gt; with new powerful features. Stay tuned!&lt;/p&gt; &#xA;&lt;h2&gt;Prebuilt Docker images üê≥&lt;/h2&gt; &#xA;&lt;p&gt;Prebuilt docker images are the easiest way to start using CVAT locally. They are available on Docker Hub:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hub.docker.com/r/cvat/server&#34;&gt;cvat/server&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hub.docker.com/r/cvat/ui&#34;&gt;cvat/ui&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The images have been downloaded more than 1M times so far.&lt;/p&gt; &#xA;&lt;h2&gt;Screencasts üé¶&lt;/h2&gt; &#xA;&lt;p&gt;Here are some screencasts showing how to use CVAT.&lt;/p&gt; &#xA;&lt;!--lint disable maximum-line-length--&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PL0to7Ng4PuuYQT4eXlHb_oIlq_RPeuasN&#34;&gt;Computer Vision Annotation Course&lt;/a&gt;: we introduce our course series designed to help you annotate data faster and better using CVAT. This course is about CVAT deployment and integrations, it includes presentations and covers the following topics:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Speeding up your data annotation process: introduction to CVAT and Datumaro&lt;/strong&gt;. What problems do CVAT and Datumaro solve, and how they can speed up your model training process. Some resources you can use to learn more about how to use them.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Deployment and use CVAT&lt;/strong&gt;. Use the app online at &lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/app.cvat.ai&#34;&gt;app.cvat.ai&lt;/a&gt;. A local deployment. A containerized local deployment with docker-compose (for regular use), and a local cluster deployment with Kubernetes (for enterprise users). A 2-minute tour of the interface, a breakdown of CVAT‚Äôs internals, and a demonstration of how to deploy CVAT using docker-compose.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PL0to7Ng4Puua37NJVMIShl_pzqJTigFzg&#34;&gt;Product tour&lt;/a&gt;: in this course, we show how to use CVAT, and help to get familiar with CVAT functionality and interfaces. This course does not cover integrations and is dedicated solely to CVAT. It covers the following topics:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Pipeline&lt;/strong&gt;. In this video, we show how to use &lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/app.cvat.ai&#34;&gt;app.cvat.ai&lt;/a&gt;: how to sign up, upload your data, annotate it, and download it.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!--lint enable maximum-line-length--&gt; &#xA;&lt;p&gt;For feedback, please see &lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/#contact-us&#34;&gt;Contact us&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;API&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opencv.github.io/cvat/docs/api_sdk/api/&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;SDK&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install with &lt;code&gt;pip install cvat-sdk&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pypi.org/project/cvat-sdk/&#34;&gt;PyPI package homepage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opencv.github.io/cvat/docs/api_sdk/sdk/&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;CLI&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install with &lt;code&gt;pip install cvat-cli&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pypi.org/project/cvat-cli/&#34;&gt;PyPI package homepage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opencv.github.io/cvat/docs/api_sdk/cli/&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Supported annotation formats&lt;/h2&gt; &#xA;&lt;p&gt;CVAT supports multiple annotation formats. You can select the format after clicking the &lt;strong&gt;Upload annotation&lt;/strong&gt; and &lt;strong&gt;Dump annotation&lt;/strong&gt; buttons. &lt;a href=&#34;https://github.com/cvat-ai/datumaro&#34;&gt;Datumaro&lt;/a&gt; dataset framework allows additional dataset transformations with its command line tool and Python library.&lt;/p&gt; &#xA;&lt;p&gt;For more information about the supported formats, see: &lt;a href=&#34;https://opencv.github.io/cvat/docs/manual/advanced/formats/&#34;&gt;Annotation Formats&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;!--lint disable maximum-line-length--&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Annotation format&lt;/th&gt; &#xA;   &lt;th&gt;Import&lt;/th&gt; &#xA;   &lt;th&gt;Export&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://opencv.github.io/cvat/docs/manual/advanced/xml_format/#annotation&#34;&gt;CVAT for images&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://opencv.github.io/cvat/docs/manual/advanced/xml_format/#interpolation&#34;&gt;CVAT for a video&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/cvat-ai/datumaro&#34;&gt;Datumaro&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://host.robots.ox.ac.uk/pascal/VOC/&#34;&gt;PASCAL VOC&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Segmentation masks from &lt;a href=&#34;http://host.robots.ox.ac.uk/pascal/VOC/&#34;&gt;PASCAL VOC&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://pjreddie.com/darknet/yolo/&#34;&gt;YOLO&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://cocodataset.org/#format-data&#34;&gt;MS COCO Object Detection&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://cocodataset.org/#format-data&#34;&gt;MS COCO Keypoints Detection&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.tensorflow.org/tutorials/load_data/tfrecord&#34;&gt;TFrecord&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://motchallenge.net/&#34;&gt;MOT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.vision.rwth-aachen.de/page/mots&#34;&gt;MOTS PNG&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://labelme.csail.mit.edu/Release3.0&#34;&gt;LabelMe 3.0&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.image-net.org&#34;&gt;ImageNet&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/&#34;&gt;CamVid&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://shuoyang1213.me/WIDERFACE/&#34;&gt;WIDER Face&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ox-vgg/vgg_face2&#34;&gt;VGGFace2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.aitribune.com/dataset/2018051063&#34;&gt;Market-1501&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://rrc.cvc.uab.es/?ch=2&#34;&gt;ICDAR13/15&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://storage.googleapis.com/openimages/web/index.html&#34;&gt;Open Images V6&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.cityscapes-dataset.com/login/&#34;&gt;Cityscapes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.cvlibs.net/datasets/kitti/&#34;&gt;KITTI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.cvlibs.net/datasets/kitti/raw_data.php&#34;&gt;Kitti Raw Format&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://vis-www.cs.umass.edu/lfw/&#34;&gt;LFW&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.supervise.ly/data-organization/00_ann_format_navi&#34;&gt;Supervisely Point Cloud Format&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!--lint enable maximum-line-length--&gt; &#xA;&lt;h2&gt;Deep learning serverless functions for automatic labeling&lt;/h2&gt; &#xA;&lt;p&gt;CVAT supports automatic labeling. It can speed up the annotation process up to 10x. Here is a list of the algorithms we support, and the platforms they can be run on:&lt;/p&gt; &#xA;&lt;!--lint disable maximum-line-length--&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Framework&lt;/th&gt; &#xA;   &lt;th&gt;CPU&lt;/th&gt; &#xA;   &lt;th&gt;GPU&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/openvino/dextr/nuclio&#34;&gt;Deep Extreme Cut&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;interactor&lt;/td&gt; &#xA;   &lt;td&gt;OpenVINO&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/openvino/omz/public/faster_rcnn_inception_v2_coco/nuclio&#34;&gt;Faster RCNN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;detector&lt;/td&gt; &#xA;   &lt;td&gt;OpenVINO&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/openvino/omz/public/mask_rcnn_inception_resnet_v2_atrous_coco/nuclio&#34;&gt;Mask RCNN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;detector&lt;/td&gt; &#xA;   &lt;td&gt;OpenVINO&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/openvino/omz/public/yolo-v3-tf/nuclio&#34;&gt;YOLO v3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;detector&lt;/td&gt; &#xA;   &lt;td&gt;OpenVINO&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/openvino/omz/intel/person-reidentification-retail-300/nuclio&#34;&gt;Object reidentification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;reid&lt;/td&gt; &#xA;   &lt;td&gt;OpenVINO&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/openvino/omz/intel/semantic-segmentation-adas-0001/nuclio&#34;&gt;Semantic segmentation for ADAS&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;detector&lt;/td&gt; &#xA;   &lt;td&gt;OpenVINO&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/openvino/omz/intel/text-detection-0004/nuclio&#34;&gt;Text detection v4&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;detector&lt;/td&gt; &#xA;   &lt;td&gt;OpenVINO&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/pytorch/ultralytics/yolov5/nuclio&#34;&gt;YOLO v5&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;detector&lt;/td&gt; &#xA;   &lt;td&gt;PyTorch&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/pytorch/foolwood/siammask/nuclio&#34;&gt;SiamMask&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;tracker&lt;/td&gt; &#xA;   &lt;td&gt;PyTorch&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/pytorch/dschoerk/transt/nuclio&#34;&gt;TransT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;tracker&lt;/td&gt; &#xA;   &lt;td&gt;PyTorch&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/pytorch/saic-vul/fbrs/nuclio&#34;&gt;f-BRS&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;interactor&lt;/td&gt; &#xA;   &lt;td&gt;PyTorch&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/pytorch/saic-vul/hrnet/nuclio&#34;&gt;HRNet&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;interactor&lt;/td&gt; &#xA;   &lt;td&gt;PyTorch&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/pytorch/shiyinzhang/iog/nuclio&#34;&gt;Inside-Outside Guidance&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;interactor&lt;/td&gt; &#xA;   &lt;td&gt;PyTorch&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/tensorflow/faster_rcnn_inception_v2_coco/nuclio&#34;&gt;Faster RCNN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;detector&lt;/td&gt; &#xA;   &lt;td&gt;TensorFlow&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/tensorflow/matterport/mask_rcnn/nuclio&#34;&gt;Mask RCNN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;detector&lt;/td&gt; &#xA;   &lt;td&gt;TensorFlow&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/pytorch/facebookresearch/detectron2/retinanet/nuclio&#34;&gt;RetinaNet&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;detector&lt;/td&gt; &#xA;   &lt;td&gt;PyTorch&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/serverless/openvino/omz/intel/face-detection-0205/nuclio&#34;&gt;Face Detection&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;detector&lt;/td&gt; &#xA;   &lt;td&gt;OpenVINO&lt;/td&gt; &#xA;   &lt;td&gt;‚úîÔ∏è&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!--lint enable maximum-line-length--&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The code is released under the &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;MIT License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;This software uses LGPL-licensed libraries from the &lt;a href=&#34;https://www.ffmpeg.org&#34;&gt;FFmpeg&lt;/a&gt; project. The exact steps on how FFmpeg was configured and compiled can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/opencv/cvat/develop/Dockerfile&#34;&gt;Dockerfile&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;FFmpeg is an open-source framework licensed under LGPL and GPL. See &lt;a href=&#34;https://www.ffmpeg.org/legal.html&#34;&gt;https://www.ffmpeg.org/legal.html&lt;/a&gt;. You are solely responsible for determining if your use of FFmpeg requires any additional licenses. CVAT.ai Corporation is not responsible for obtaining any such licenses, nor liable for any licensing fees due in connection with your use of FFmpeg.&lt;/p&gt; &#xA;&lt;h2&gt;Contact us&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitter.im/opencv-cvat/public&#34;&gt;Gitter&lt;/a&gt; to ask CVAT usage-related questions. Typically questions get answered fast by the core team or community. There you can also browse other common questions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/S6sRHhuQ7K&#34;&gt;Discord&lt;/a&gt; is the place to also ask questions or discuss any other stuff related to CVAT.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/company/cvat-ai/&#34;&gt;LinkedIn&lt;/a&gt; for the company and work-related questions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/@cvat-ai&#34;&gt;YouTube&lt;/a&gt; to see screencast and tutorials about the CVAT.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/cvat-ai/cvat/issues&#34;&gt;GitHub issues&lt;/a&gt; for feature requests or bug reports. If it&#39;s a bug, please add the steps to reproduce it.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://stackoverflow.com/search?q=%23cvat&#34;&gt;#cvat&lt;/a&gt; tag on StackOverflow is one more way to ask questions and get our support.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;mailto:contact+github@cvat.ai&#34;&gt;contact@cvat.ai&lt;/a&gt; to reach out to us if you need commercial support.&lt;/p&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.intel.ai/introducing-cvat&#34;&gt;Intel AI blog: New Computer Vision Tool Accelerates Annotation of Digital Images and Video&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://software.intel.com/en-us/articles/computer-vision-annotation-tool-a-universal-approach-to-data-annotation&#34;&gt;Intel Software: Computer Vision Annotation Tool: A Universal Approach to Data Annotation&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://venturebeat.com/2019/03/05/intel-open-sources-cvat-a-toolkit-for-data-labeling/&#34;&gt;VentureBeat: Intel open-sources CVAT, a toolkit for data labeling&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;!-- prettier-ignore-start --&gt; &#xA;  &lt;!-- Badges --&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>expo/expo</title>
    <updated>2022-12-18T01:40:31Z</updated>
    <id>tag:github.com,2022-12-18:/expo/expo</id>
    <link href="https://github.com/expo/expo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An open-source platform for making universal native apps with React. Expo runs on Android, iOS, and the web.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://expo.dev/&#34;&gt; &lt;img alt=&#34;expo sdk&#34; height=&#34;128&#34; src=&#34;https://raw.githubusercontent.com/expo/expo/main/.github/resources/banner.png&#34;&gt; &lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 align=&#34;center&#34;&gt;&lt;a href=&#34;https://expo.dev/&#34;&gt;Expo&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;a href=&#34;https://expo.dev/&#34;&gt; &lt;/a&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a aria-label=&#34;SDK version&#34; href=&#34;https://www.npmjs.com/package/expo&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;Expo SDK version&#34; src=&#34;https://img.shields.io/npm/v/expo.svg?style=flat-square&amp;amp;label=SDK&amp;amp;labelColor=000000&amp;amp;color=4630EB&#34;&gt; &lt;/a&gt; &lt;a aria-label=&#34;Join our forums&#34; href=&#34;https://forums.expo.dev&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;Forums&#34; src=&#34;https://img.shields.io/badge/Ask%20Questions%20-blue.svg?style=flat-square&amp;amp;logo=discourse&amp;amp;logoWidth=15&amp;amp;labelColor=000000&amp;amp;color=4630EB&#34;&gt; &lt;/a&gt; &lt;a aria-label=&#34;Join our Discord&#34; href=&#34;https://chat.expo.dev&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;Discord&#34; src=&#34;https://img.shields.io/discord/695411232856997968.svg?style=flat-square&amp;amp;labelColor=000000&amp;amp;color=4630EB&amp;amp;logo=discord&amp;amp;logoColor=FFFFFF&amp;amp;label=&#34;&gt; &lt;/a&gt; &lt;a aria-label=&#34;Expo is free to use&#34; href=&#34;https://github.com/expo/expo/raw/main/LICENSE&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;License: MIT&#34; src=&#34;https://img.shields.io/badge/License-MIT-success.svg?style=flat-square&amp;amp;color=33CC12&#34; target=&#34;_blank&#34;&gt; &lt;/a&gt; &lt;a aria-label=&#34;expo downloads&#34; href=&#34;http://www.npmtrends.com/expo&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;Downloads&#34; src=&#34;https://img.shields.io/npm/dm/expo.svg?style=flat-square&amp;amp;labelColor=gray&amp;amp;color=33CC12&amp;amp;label=Downloads&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a aria-label=&#34;try expo with snack&#34; href=&#34;https://snack.expo.dev&#34;&gt;&lt;b&gt;Try Expo in the Browser&lt;/b&gt;&lt;/a&gt; | &lt;a aria-label=&#34;expo documentation&#34; href=&#34;https://docs.expo.dev&#34;&gt;Read the Documentation üìö&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt; &lt;a aria-label=&#34;Follow @expo on Twitter&#34; href=&#34;https://twitter.com/intent/follow?screen_name=expo&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;Twitter: expo&#34; src=&#34;https://img.shields.io/twitter/follow/expo.svg?style=flat-square&amp;amp;label=Follow%20%40expo&amp;amp;logo=TWITTER&amp;amp;logoColor=FFFFFF&amp;amp;labelColor=00aced&amp;amp;logoWidth=15&amp;amp;color=lightgray&#34; target=&#34;_blank&#34;&gt; &lt;/a&gt; &lt;a aria-label=&#34;Follow Expo on Medium&#34; href=&#34;https://blog.expo.dev&#34;&gt; &lt;img align=&#34;right&#34; alt=&#34;Medium: exposition&#34; src=&#34;https://img.shields.io/badge/Learn%20more%20on%20our%20blog-lightgray.svg?style=flat-square&#34; target=&#34;_blank&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/#-documentation&#34;&gt;üìö Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/#-project-layout&#34;&gt;üó∫ Project Layout&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/#-badges&#34;&gt;üèÖ Badges&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/#-contributing&#34;&gt;üëè Contributing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/#-faq&#34;&gt;‚ùì FAQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/#-the-team&#34;&gt;üíô The Team&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Expo is an open-source platform for making universal native apps that run on Android, iOS, and the web. It includes a universal runtime and libraries that let you build native apps by writing React and JavaScript. This repository is where the Expo client software is developed, and includes the client apps, modules, apps, CLI, and more. &lt;a href=&#34;https://expo.dev/eas&#34;&gt;Expo Application Services (EAS)&lt;/a&gt; is a platform of hosted services that are deeply integrated with Expo open source tools. EAS helps you build, ship, and iterate on your app as an individual or a team.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://expo.dev/guidelines&#34;&gt;Click here to view the Expo Community Guidelines&lt;/a&gt;. Thank you for helping keep the Expo community open and welcoming!&lt;/p&gt; &#xA;&lt;h2&gt;üìö Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Learn about building and deploying universal apps &lt;a aria-label=&#34;expo documentation&#34; href=&#34;https://docs.expo.dev&#34;&gt;in our official docs!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.expo.dev/&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.expo.dev/versions/latest/&#34;&gt;API Reference&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.expo.dev/workflow/customizing/&#34;&gt;Using Custom Native Modules&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üó∫ Project Layout&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/packages&#34;&gt;&lt;code&gt;packages&lt;/code&gt;&lt;/a&gt; All the source code for Expo modules, if you want to edit a library or just see how it works this is where you&#39;ll find it.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/apps&#34;&gt;&lt;code&gt;apps&lt;/code&gt;&lt;/a&gt; This is where you can find Expo projects which are linked to the development modules. You&#39;ll do most of your testing in here.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/docs&#34;&gt;&lt;code&gt;docs&lt;/code&gt;&lt;/a&gt; The source code for &lt;strong&gt;&lt;a href=&#34;https://docs.expo.dev&#34;&gt;https://docs.expo.dev&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/templates&#34;&gt;&lt;code&gt;templates&lt;/code&gt;&lt;/a&gt; The template projects you get when you run &lt;code&gt;npx create-expo-app&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/react-native-lab&#34;&gt;&lt;code&gt;react-native-lab&lt;/code&gt;&lt;/a&gt; This is our fork of &lt;code&gt;react-native&lt;/code&gt; used to build Expo Go.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/guides&#34;&gt;&lt;code&gt;guides&lt;/code&gt;&lt;/a&gt; In-depth tutorials for advanced topics like contributing to the client.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/android&#34;&gt;&lt;code&gt;android&lt;/code&gt;&lt;/a&gt; contains the Android project.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/home&#34;&gt;&lt;code&gt;home&lt;/code&gt;&lt;/a&gt; contains the JavaScript source code of the app.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/ios&#34;&gt;&lt;code&gt;ios&lt;/code&gt;&lt;/a&gt; contains the iOS project.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/ios&#34;&gt;&lt;code&gt;ios/Exponent.xcworkspace&lt;/code&gt;&lt;/a&gt; is the Xcode workspace. Always open this instead of &lt;code&gt;Exponent.xcodeproj&lt;/code&gt; because the workspace also loads the CocoaPods dependencies.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/tools&#34;&gt;&lt;code&gt;tools&lt;/code&gt;&lt;/a&gt; contains build and configuration tools.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/template-files&#34;&gt;&lt;code&gt;template-files&lt;/code&gt;&lt;/a&gt; contains templates for files that require private keys. They are populated using the keys in &lt;code&gt;template-files/keys.json&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/template-files/ios/dependencies.json&#34;&gt;&lt;code&gt;template-files/ios/dependencies.json&lt;/code&gt;&lt;/a&gt; specifies the CocoaPods dependencies of the app.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üèÖ Badges&lt;/h2&gt; &#xA;&lt;p&gt;Let everyone know your app can be run instantly in the &lt;em&gt;Expo Go&lt;/em&gt; app! &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://expo.dev/client&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Runs%20with%20Expo%20Go-000.svg?style=flat-square&amp;amp;logo=EXPO&amp;amp;labelColor=f3f3f3&amp;amp;logoColor=000&#34; alt=&#34;runs with Expo Go&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://expo.dev/client&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Runs%20with%20Expo%20Go-4630EB.svg?style=flat-square&amp;amp;logo=EXPO&amp;amp;labelColor=f3f3f3&amp;amp;logoColor=000&#34; alt=&#34;runs with Expo Go&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-md&#34;&gt;[![runs with Expo Go](https://img.shields.io/badge/Runs%20with%20Expo%20Go-000.svg?style=flat-square&amp;amp;logo=EXPO&amp;amp;labelColor=f3f3f3&amp;amp;logoColor=000)](https://expo.dev/client)&#xA;&#xA;[![runs with Expo Go](https://img.shields.io/badge/Runs%20with%20Expo%20Go-4630EB.svg?style=flat-square&amp;amp;logo=EXPO&amp;amp;labelColor=f3f3f3&amp;amp;logoColor=000)](https://expo.dev/client)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üëè Contributing&lt;/h2&gt; &#xA;&lt;p&gt;If you like Expo and want to help make it better then check out our &lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt;! Check out the &lt;a href=&#34;https://github.com/expo/expo/tree/main/packages/%40expo/cli&#34;&gt;CLI package&lt;/a&gt; to work on the Expo CLI.&lt;/p&gt; &#xA;&lt;h2&gt;‚ùì FAQ&lt;/h2&gt; &#xA;&lt;p&gt;If you have questions about Expo and want answers, then check out our &lt;a href=&#34;https://docs.expo.dev/versions/latest/introduction/faq/&#34;&gt;Frequently Asked Questions&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;p&gt;If you still have questions you can ask them on our &lt;a href=&#34;https://forums.expo.dev&#34;&gt;forums&lt;/a&gt;, &lt;a href=&#34;https://chat.expo.dev&#34;&gt;Discord&lt;/a&gt; or on Twitter &lt;a href=&#34;https://twitter.com/expo&#34;&gt;@Expo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üíô The Team&lt;/h2&gt; &#xA;&lt;p&gt;Curious about who makes Expo? Here are our &lt;a href=&#34;https://expo.dev/about&#34;&gt;team members&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The Expo source code is made available under the &lt;a href=&#34;https://raw.githubusercontent.com/expo/expo/main/LICENSE&#34;&gt;MIT license&lt;/a&gt;. Some of the dependencies are licensed differently, with the BSD license, for example.&lt;/p&gt; &#xA;&lt;img alt=&#34;Star the Expo repo on GitHub to support the project&#34; src=&#34;https://user-images.githubusercontent.com/9664363/185428788-d762fd5d-97b3-4f59-8db7-f72405be9677.gif&#34; width=&#34;50%&#34;&gt;</summary>
  </entry>
</feed>