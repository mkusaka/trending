<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-11-24T01:36:00Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>mastra-ai/mastra</title>
    <updated>2024-11-24T01:36:00Z</updated>
    <id>tag:github.com,2024-11-24:/mastra-ai/mastra</id>
    <link href="https://github.com/mastra-ai/mastra" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The TypeScript AI framework.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Mastra&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://mastra.ai&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mastra-ai/mastra/main/mastra-homepage.png&#34; alt=&#34;Mastra framework homepage&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Mastra is an opinionated Typescript framework that helps you build AI applications and features quickly. It gives you the set of primitives you need: workflows, agents, RAG, integrations, syncs and evals. You can run Mastra on your local machine, or deploy to a serverless cloud.&lt;/p&gt; &#xA;&lt;p&gt;The main Mastra features are:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Features&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mastra.ai/docs/guide/how-to/00-llm-models&#34;&gt;LLM Models&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Mastra supports a variety of LLM providers, including OpenAI, Anthropic, Google Gemini. You can choose the specific model and provider, choose system and user prompts, and decide whether to stream the response.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mastra.ai/docs/guide/how-to/01-creating-agents&#34;&gt;Agents&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Agents are systems where the language model chooses a sequence of actions. In Mastra, agents provide LLM models with tools, workflows, and synced data. Agents can call your own functions or APIs of third-party integrations and access knowledge bases you build.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mastra.ai/docs/guide/how-to/02-adding-tools&#34;&gt;Tools&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Tools are typed functions that can be executed by agents or workflows, with built-in integration access and parameter validation. Each tool has a schema that defines its inputs, an executor function that implements its logic, and access to configured integrations.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mastra.ai/docs/guide/how-to/03-building-workflows&#34;&gt;Workflows&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Workflows are durable graph-based state machines. They have loops, branching, wait for human input, embed other workflows, do error handling, retries, parsing and so on. They can be built in code or with a visual editor. Each step in a workflow has built-in OpenTelemetry tracing.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mastra.ai/docs/guide/how-to/04-knowledge-sources&#34;&gt;RAG&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Retrieval-augemented generation (RAG) lets you construct a knowledge base for agents. RAG is an ETL pipeline with specific querying techniques, including chunking, embedding, and vector search.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mastra.ai/docs/guide/how-to/06-adding-integrations&#34;&gt;Integrations &amp;amp; Syncs&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;In Mastra, syncs are async functions that can be deployed as background tasks across different execution environments. Integrations are auto-generated, type-safe API clients for third-party services that can be used as tools for agents or steps in workflows.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mastra.ai/docs/guide/how-to/08-running-evals&#34;&gt;Evals&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Evals are automated tests that evaluate LLM outputs using model-graded, rule-based, and statistical methods. Each eval returns a normalized score between 0-1 that can be logged and compared. Evals can be customized with your own prompts and scoring functions.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Node.js (v20.0+)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Get an LLM provider API key&lt;/h2&gt; &#xA;&lt;p&gt;If you don&#39;t have an API key for an LLM provider, you can get one from the following services:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://platform.openai.com/&#34;&gt;OpenAI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://console.anthropic.com/settings/keys&#34;&gt;Anthropic&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.google.dev/gemini-api/docs&#34;&gt;Google Gemini&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you don&#39;t have an account with these providers, you can sign up and get an API key. OpenAI and Anthropic require a credit card to get an API key. Gemini does not and has a generous free tier for its API.&lt;/p&gt; &#xA;&lt;h2&gt;Create a new project&lt;/h2&gt; &#xA;&lt;p&gt;As a first step, create a project directory and navigate into it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir hello-mastra&#xA;cd hello-mastra&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, initialize a TypeScript project using npm:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm init -y&#xA;npm install typescript tsx @types/node @mastra/core@alpha --save-dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Add an index.ts file&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir src&#xA;touch src/index.ts&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, add this code to &lt;code&gt;src/index.ts&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import { Agent } from &#39;@mastra/core&#39;;&#xA;&#xA;async function main() {&#xA;  const agent = new Agent({&#xA;    name: &#39;story-writer&#39;,&#xA;    maxSteps: 3,&#xA;    model: {&#xA;      provider: &#39;OPEN_AI&#39;,&#xA;      name: &#39;gpt-4o&#39;,&#xA;      toolChoice: &#39;auto&#39;&#xA;    },&#xA;    instructions: `You are a helpful assistant who writes creative stories.`,&#xA;    tools: {},&#xA;  });&#xA;&#xA;  const result = await agent.text({&#xA;    messages: [&#34;Write a short story about a robot learning to paint.&#34;]&#xA;  });&#xA;&#xA;  console.log(&#34;Agent response:&#34;, result.text);&#xA;}&#xA;&#xA;main();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run the script&lt;/h3&gt; &#xA;&lt;p&gt;Finally, run the script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;OPENAI_API_KEY=&amp;lt;your-openai-api-key&amp;gt; npx tsx src/index.ts&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you&#39;re using Anthropic, set the &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;. If you&#39;re using Gemini, set the &lt;code&gt;GOOGLE_GENERATIVE_AI_API_KEY&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>