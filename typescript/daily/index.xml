<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-04-14T01:38:15Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>voideditor/void</title>
    <updated>2025-04-14T01:38:15Z</updated>
    <id>tag:github.com,2025-04-14:/voideditor/void</id>
    <link href="https://github.com/voideditor/void" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Welcome to Void.&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/voideditor/void/main/src/vs/workbench/browser/parts/editor/media/slice_of_void.png&#34; alt=&#34;Void Welcome&#34; width=&#34;300&#34; height=&#34;300&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Void is the open-source Cursor alternative.&lt;/p&gt; &#xA;&lt;p&gt;This repo contains the full sourcecode for Void. We are currently in &lt;a href=&#34;https://voideditor.com/email&#34;&gt;open beta&lt;/a&gt; for Discord members (see the &lt;code&gt;announcements&lt;/code&gt; channel), with a waitlist for our official release. If you&#39;re new, welcome!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;üëã &lt;a href=&#34;https://discord.gg/RSNjgaugJs&#34;&gt;Discord&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üî® &lt;a href=&#34;https://github.com/voideditor/void/raw/main/HOW_TO_CONTRIBUTE.md&#34;&gt;Contribute&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üöô &lt;a href=&#34;https://github.com/orgs/voideditor/projects/2&#34;&gt;Roadmap&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üìù &lt;a href=&#34;https://voideditor.com/changelog&#34;&gt;Changelog&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üß≠ &lt;a href=&#34;https://github.com/voideditor/void/raw/main/VOID_CODEBASE_GUIDE.md&#34;&gt;Codebase Guide&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Feel free to attend a weekly meeting in our Discord channel if you&#39;d like to contribute!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To get started working on Void, see &lt;a href=&#34;https://github.com/voideditor/void/raw/main/HOW_TO_CONTRIBUTE.md&#34;&gt;Contributing&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;We&#39;re open to collaborations and suggestions of all types - just reach out.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Reference&lt;/h2&gt; &#xA;&lt;p&gt;Void is a fork of the &lt;a href=&#34;https://github.com/microsoft/vscode&#34;&gt;vscode&lt;/a&gt; repository. For a guide to the VSCode/Void codebase, see &lt;a href=&#34;https://github.com/voideditor/void/raw/main/VOID_CODEBASE_GUIDE.md&#34;&gt;our Codebase Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;Feel free to reach out in our Discord or contact us via email: &lt;a href=&#34;mailto:hello@voideditor.com&#34;&gt;hello@voideditor.com&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>googleapis/js-genai</title>
    <updated>2025-04-14T01:38:15Z</updated>
    <id>tag:github.com,2025-04-14:/googleapis/js-genai</id>
    <link href="https://github.com/googleapis/js-genai" rel="alternate"></link>
    <summary type="html">&lt;p&gt;TypeScript/JavaScript SDK for Gemini and Vertex AI. [PREVIEW]&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Google Gen AI SDK for TypeScript and JavaScript&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.npmjs.com/package/@google/genai&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/dw/%40google%2Fgenai&#34; alt=&#34;NPM Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.npmjs.com/package/@google/genai&#34;&gt;&lt;img src=&#34;https://img.shields.io/node/v/%40google%2Fgenai&#34; alt=&#34;Node Current&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;Documentation:&lt;/strong&gt; &lt;a href=&#34;https://googleapis.github.io/js-genai/&#34;&gt;https://googleapis.github.io/js-genai/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;The Google Gen AI JavaScript SDK is designed for TypeScript and JavaScript developers to build applications powered by Gemini. The SDK supports both the &lt;a href=&#34;https://ai.google.dev/gemini-api/docs&#34;&gt;Gemini Developer API&lt;/a&gt; and &lt;a href=&#34;https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview&#34;&gt;Vertex AI&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The Google Gen AI SDK is designed to work with Gemini 2.0 features.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] &lt;strong&gt;SDK Preview:&lt;/strong&gt; See: &lt;a href=&#34;https://raw.githubusercontent.com/googleapis/js-genai/main/#preview-launch&#34;&gt;Preview Launch&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!CAUTION] &lt;strong&gt;API Key Security:&lt;/strong&gt; Avoid exposing API keys in client-side code. Use server-side implementations in production environments.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Node.js version 18 or later&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;To install the SDK, run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;npm install @google/genai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;The simplest way to get started is to using an API key from &lt;a href=&#34;https://aistudio.google.com/apikey&#34;&gt;Google AI Studio&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import {GoogleGenAI} from &#39;@google/genai&#39;;&#xA;const GEMINI_API_KEY = process.env.GEMINI_API_KEY;&#xA;&#xA;const ai = new GoogleGenAI({apiKey: GEMINI_API_KEY});&#xA;&#xA;async function main() {&#xA;  const response = await ai.models.generateContent({&#xA;    model: &#39;gemini-2.0-flash-001&#39;,&#xA;    contents: &#39;Why is the sky blue?&#39;,&#xA;  });&#xA;  console.log(response.text);&#xA;}&#xA;&#xA;main();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Web quickstart&lt;/h2&gt; &#xA;&lt;p&gt;The package contents are also available unzipped in the &lt;code&gt;package/&lt;/code&gt; directory of the bucket, so an equivalent web example is:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;!DOCTYPE html&amp;gt;&#xA;&amp;lt;html lang=&#34;en&#34;&amp;gt;&#xA;  &amp;lt;head&amp;gt;&#xA;    &amp;lt;meta charset=&#34;UTF-8&#34; /&amp;gt;&#xA;    &amp;lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34; /&amp;gt;&#xA;    &amp;lt;title&amp;gt;Using My Package&amp;lt;/title&amp;gt;&#xA;  &amp;lt;/head&amp;gt;&#xA;  &amp;lt;body&amp;gt;&#xA;    &amp;lt;script type=&#34;module&#34;&amp;gt;&#xA;      import {GoogleGenAI} from &#39;https://cdn.jsdelivr.net/npm/@google/genai@latest/+esm&#39;&#xA;&#xA;          const ai = new GoogleGenAI({apiKey:&#34;GEMINI_API_KEY&#34;});&#xA;&#xA;          async function main() {&#xA;            const response = await ai.models.generateContent({&#xA;              model: &#39;gemini-2.0-flash-001&#39;,&#xA;              contents: &#39;Why is the sky blue?&#39;,&#xA;            });&#xA;            console.log(response.text);&#xA;          }&#xA;&#xA;          main();&#xA;    &amp;lt;/script&amp;gt;&#xA;  &amp;lt;/body&amp;gt;&#xA;&amp;lt;/html&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Initialization&lt;/h2&gt; &#xA;&lt;p&gt;The Google Gen AI SDK provides support for both the &lt;a href=&#34;https://ai.google.dev/gemini-api/docs&#34;&gt;Google AI Studio&lt;/a&gt; and &lt;a href=&#34;https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview&#34;&gt;Vertex AI&lt;/a&gt; implementations of the Gemini API.&lt;/p&gt; &#xA;&lt;h3&gt;Gemini Developer API&lt;/h3&gt; &#xA;&lt;p&gt;For server-side applications, initialize using an API key, which can be acquired from &lt;a href=&#34;https://aistudio.google.com/apikey&#34;&gt;Google AI Studio&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import { GoogleGenAI } from &#39;@google/genai&#39;;&#xA;const ai = new GoogleGenAI({apiKey: &#39;GEMINI_API_KEY&#39;});&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Browser&lt;/h4&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!CAUTION] &lt;strong&gt;API Key Security:&lt;/strong&gt; Avoid exposing API keys in client-side code. Use server-side implementations in production environments.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;In the browser the initialization code is identical:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import { GoogleGenAI } from &#39;@google/genai&#39;;&#xA;const ai = new GoogleGenAI({apiKey: &#39;GEMINI_API_KEY&#39;});&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Vertex AI&lt;/h3&gt; &#xA;&lt;p&gt;Sample code for VertexAI initialization:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import { GoogleGenAI } from &#39;@google/genai&#39;;&#xA;&#xA;const ai = new GoogleGenAI({&#xA;    vertexai: true,&#xA;    project: &#39;your_project&#39;,&#xA;    location: &#39;your_location&#39;,&#xA;});&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;GoogleGenAI overview&lt;/h2&gt; &#xA;&lt;p&gt;All API features are accessed through an instance of the &lt;code&gt;GoogleGenAI&lt;/code&gt; classes. The submodules bundle together related API methods:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://googleapis.github.io/js-genai/classes/models.Models.html&#34;&gt;&lt;code&gt;ai.models&lt;/code&gt;&lt;/a&gt;: Use &lt;code&gt;models&lt;/code&gt; to query models (&lt;code&gt;generateContent&lt;/code&gt;, &lt;code&gt;generateImages&lt;/code&gt;, ...), or examine their metadata.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://googleapis.github.io/js-genai/classes/caches.Caches.html&#34;&gt;&lt;code&gt;ai.caches&lt;/code&gt;&lt;/a&gt;: Create and manage &lt;code&gt;caches&lt;/code&gt; to reduce costs when repeatedly using the same large prompt prefix.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://googleapis.github.io/js-genai/classes/chats.Chats.html&#34;&gt;&lt;code&gt;ai.chats&lt;/code&gt;&lt;/a&gt;: Create local stateful &lt;code&gt;chat&lt;/code&gt; objects to simplify multi turn interactions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://googleapis.github.io/js-genai/classes/files.Files.html&#34;&gt;&lt;code&gt;ai.files&lt;/code&gt;&lt;/a&gt;: Upload &lt;code&gt;files&lt;/code&gt; to the API and reference them in your prompts. This reduces bandwidth if you use a file many times, and handles files too large to fit inline with your prompt.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://googleapis.github.io/js-genai/classes/live.Live.html&#34;&gt;&lt;code&gt;ai.live&lt;/code&gt;&lt;/a&gt;: Start a &lt;code&gt;live&lt;/code&gt; session for real time interaction, allows text + audio + video input, and text or audio output.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Samples&lt;/h2&gt; &#xA;&lt;p&gt;More samples can be found in the &lt;a href=&#34;https://github.com/googleapis/js-genai/tree/main/sdk-samples&#34;&gt;github samples directory&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Streaming&lt;/h3&gt; &#xA;&lt;p&gt;For quicker, more responsive API interactions use the &lt;code&gt;generateContentStream&lt;/code&gt; method which yields chunks as they&#39;re generated:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import {GoogleGenAI} from &#39;@google/genai&#39;;&#xA;const GEMINI_API_KEY = process.env.GEMINI_API_KEY;&#xA;&#xA;const ai = new GoogleGenAI({apiKey: GEMINI_API_KEY});&#xA;&#xA;async function main() {&#xA;  const response = await ai.models.generateContentStream({&#xA;    model: &#39;gemini-2.0-flash-001&#39;,&#xA;    contents: &#39;Write a 100-word poem.&#39;,&#xA;  });&#xA;  for await (const chunk of response) {&#xA;    console.log(chunk.text);&#xA;  }&#xA;}&#xA;&#xA;main();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Function Calling&lt;/h3&gt; &#xA;&lt;p&gt;To let Gemini to interact with external systems, you can provide provide &lt;code&gt;functionDeclaration&lt;/code&gt; objects as &lt;code&gt;tools&lt;/code&gt;. To use these tools it&#39;s a 4 step&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Declare the function name, description, and parameters&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Call &lt;code&gt;generateContent&lt;/code&gt; with function calling enabled&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Use the returned &lt;code&gt;FunctionCall&lt;/code&gt; parameters to call your actual function&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Send the result back to the model (with history, easier in &lt;code&gt;ai.chat&lt;/code&gt;) as a &lt;code&gt;FunctionResponse&lt;/code&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import {GoogleGenAI, FunctionCallingConfigMode, FunctionDeclaration, Type} from &#39;@google/genai&#39;;&#xA;const GEMINI_API_KEY = process.env.GEMINI_API_KEY;&#xA;&#xA;async function main() {&#xA;  const controlLightDeclaration: FunctionDeclaration = {&#xA;    name: &#39;controlLight&#39;,&#xA;    parameters: {&#xA;      type: Type.OBJECT,&#xA;      description: &#39;Set the brightness and color temperature of a room light.&#39;,&#xA;      properties: {&#xA;        brightness: {&#xA;          type: Type.NUMBER,&#xA;          description:&#xA;              &#39;Light level from 0 to 100. Zero is off and 100 is full brightness.&#39;,&#xA;        },&#xA;        colorTemperature: {&#xA;          type: Type.STRING,&#xA;          description:&#xA;              &#39;Color temperature of the light fixture which can be `daylight`, `cool`, or `warm`.&#39;,&#xA;        },&#xA;      },&#xA;      required: [&#39;brightness&#39;, &#39;colorTemperature&#39;],&#xA;    },&#xA;  };&#xA;&#xA;  const ai = new GoogleGenAI({apiKey: GEMINI_API_KEY});&#xA;  const response = await ai.models.generateContent({&#xA;    model: &#39;gemini-2.0-flash-001&#39;,&#xA;    contents: &#39;Dim the lights so the room feels cozy and warm.&#39;,&#xA;    config: {&#xA;      toolConfig: {&#xA;        functionCallingConfig: {&#xA;          // Force it to call any function&#xA;          mode: FunctionCallingConfigMode.ANY,&#xA;          allowedFunctionNames: [&#39;controlLight&#39;],&#xA;        }&#xA;      },&#xA;      tools: [{functionDeclarations: [controlLightDeclaration]}]&#xA;    }&#xA;  });&#xA;&#xA;  console.log(response.functionCalls);&#xA;}&#xA;&#xA;main();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Preview Launch&lt;/h2&gt; &#xA;&lt;p&gt;The SDK is curently in a preview launch stage, per &lt;a href=&#34;https://cloud.google.com/products?hl=en#section-22&#34;&gt;Google&#39;s launch stages&lt;/a&gt; this means:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;At Preview, products or features are ready for testing by customers. Preview offerings are often publicly announced, but are not necessarily feature-complete, and no SLAs or technical support commitments are provided for these. Unless stated otherwise by Google, Preview offerings are intended for use in test environments only. The average Preview stage lasts about six months.&lt;/p&gt; &#xA;&lt;/blockquote&gt;</summary>
  </entry>
</feed>