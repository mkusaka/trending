<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-09-19T01:41:16Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>langchain-ai/langchain-nextjs-template</title>
    <updated>2023-09-19T01:41:16Z</updated>
    <id>tag:github.com,2023-09-19:/langchain-ai/langchain-nextjs-template</id>
    <link href="https://github.com/langchain-ai/langchain-nextjs-template" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LangChain + Next.js starter template&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ü¶úÔ∏èüîó LangChain + Next.js Starter Template&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://codespaces.new/langchain-ai/langchain-nextjs-template&#34;&gt;&lt;img src=&#34;https://github.com/codespaces/badge.svg?sanitize=true&#34; alt=&#34;Open in GitHub Codespaces&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flangchain-ai%2Flangchain-nextjs-template&#34;&gt;&lt;img src=&#34;https://vercel.com/button&#34; alt=&#34;Deploy with Vercel&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This template scaffolds a LangChain.js + Next.js starter app. It showcases how to use and combine LangChain modules for several use cases. Specifically:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/langchain-nextjs-template/main/app/api/chat/route.ts&#34;&gt;Simple chat&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/langchain-nextjs-template/main/app/api/chat/structured_output/route.ts&#34;&gt;Returning structured output from an LLM call&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/langchain-nextjs-template/main/app/api/chat/agents/route.ts&#34;&gt;Answering complex, multi-step questions with agents&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/langchain-nextjs-template/main/app/api/chat/retrieval/route.ts&#34;&gt;Retrieval augmented generation (RAG) with a chain and a vector store&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/langchain-nextjs-template/main/app/api/chat/retrieval_agents/route.ts&#34;&gt;Retrieval augmented generation (RAG) with an agent and a vector store&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Most of them use Vercel&#39;s &lt;a href=&#34;https://github.com/vercel-labs/ai&#34;&gt;AI SDK&lt;/a&gt; to stream tokens to the client and display the incoming messages.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/langchain-nextjs-template/main/public/images/agent-convo.gif&#34; alt=&#34;Demo GIF&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can check out a hosted version of this repo here: &lt;a href=&#34;https://langchain-nextjs-template.vercel.app/&#34;&gt;https://langchain-nextjs-template.vercel.app/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;First, clone this repo and download it locally.&lt;/p&gt; &#xA;&lt;p&gt;Next, you&#39;ll need to set up environment variables in your repo&#39;s &lt;code&gt;.env.local&lt;/code&gt; file. Copy the &lt;code&gt;.env.example&lt;/code&gt; file to &lt;code&gt;.env.local&lt;/code&gt;. To start with the basic examples, you&#39;ll just need to add your OpenAI API key.&lt;/p&gt; &#xA;&lt;p&gt;Next, install the required packages using your preferred package manager (e.g. &lt;code&gt;yarn&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;Now you&#39;re ready to run the development server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yarn dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt; with your browser to see the result! Ask the bot something and you&#39;ll see a streamed response:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/langchain-nextjs-template/main/public/images/chat-conversation.png&#34; alt=&#34;A streaming conversation between the user and the AI&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can start editing the page by modifying &lt;code&gt;app/page.tsx&lt;/code&gt;. The page auto-updates as you edit the file.&lt;/p&gt; &#xA;&lt;p&gt;Backend logic lives in &lt;code&gt;app/api/chat/route.ts&lt;/code&gt;. From here, you can change the prompt and model, or add other modules and logic.&lt;/p&gt; &#xA;&lt;h2&gt;üß± Structured Output&lt;/h2&gt; &#xA;&lt;p&gt;The second example shows how to have a model return output according to a specific schema using OpenAI Functions. Click the &lt;code&gt;Structured Output&lt;/code&gt; link in the navbar to try it out:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/langchain-nextjs-template/main/public/images/structured-output-conversation.png&#34; alt=&#34;A streaming conversation between the user and an AI agent&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The chain in this example uses a &lt;a href=&#34;https://zod.dev&#34;&gt;popular library called Zod&lt;/a&gt; to construct a schema, then formats it in the way OpenAI expects. It then passes that schema as a function into OpenAI and passes a &lt;code&gt;function_call&lt;/code&gt; parameter to force OpenAI to return arguments in the specified format.&lt;/p&gt; &#xA;&lt;p&gt;For more details, &lt;a href=&#34;https://js.langchain.com/docs/modules/chains/popular/structured_output&#34;&gt;check out this documentation page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;ü¶ú Agents&lt;/h2&gt; &#xA;&lt;p&gt;To try out the agent example, you&#39;ll need to give the agent access to the internet by populating the &lt;code&gt;SERPAPI_API_KEY&lt;/code&gt; in &lt;code&gt;.env.local&lt;/code&gt;. Head over to &lt;a href=&#34;https://serpapi.com/&#34;&gt;the SERP API website&lt;/a&gt; and get an API key if you don&#39;t already have one.&lt;/p&gt; &#xA;&lt;p&gt;You can then click the &lt;code&gt;Agent&lt;/code&gt; example and try asking it more complex questions:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/langchain-nextjs-template/main/public/images/agent-conversation.png&#34; alt=&#34;A streaming conversation between the user and an AI agent&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This example uses the OpenAI Functions agent, but there are a few other options you can try as well. See &lt;a href=&#34;https://js.langchain.com/docs/modules/agents/agent_types/&#34;&gt;this documentation page for more details&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üê∂ Retrieval&lt;/h2&gt; &#xA;&lt;p&gt;The retrieval examples both use Supabase as a vector store. However, you can swap in &lt;a href=&#34;https://js.langchain.com/docs/modules/data_connection/vectorstores/integrations/&#34;&gt;another supported vector store&lt;/a&gt; if preferred by changing the code under &lt;code&gt;app/api/retrieval/ingest/route.ts&lt;/code&gt;, &lt;code&gt;app/api/chat/retrieval/route.ts&lt;/code&gt;, and &lt;code&gt;app/api/chat/retrieval_agents/route.ts&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For Supabase, follow &lt;a href=&#34;https://js.langchain.com/docs/modules/data_connection/vectorstores/integrations/supabase&#34;&gt;these instructions&lt;/a&gt; to set up your database, then get your database URL and private key and paste them into &lt;code&gt;.env.local&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can then switch to the &lt;code&gt;Retrieval&lt;/code&gt; and &lt;code&gt;Retrieval Agent&lt;/code&gt; examples. The default document text is pulled from the LangChain.js retrieval use case docs, but you can change them to whatever text you&#39;d like.&lt;/p&gt; &#xA;&lt;p&gt;For a given text, you&#39;ll only need to press &lt;code&gt;Upload&lt;/code&gt; once. Pressing it again will re-ingest the docs, resulting in duplicates. You can clear your Supabase vector store by navigating to the console and running &lt;code&gt;DELETE FROM docuemnts;&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;After splitting, embedding, and uploading some text, you&#39;re ready to ask questions!&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/langchain-nextjs-template/main/public/images/retrieval-chain-conversation.png&#34; alt=&#34;A streaming conversation between the user and an AI retrieval chain&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/langchain-nextjs-template/main/public/images/retrieval-agent-conversation.png&#34; alt=&#34;A streaming conversation between the user and an AI retrieval agent&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;For more info on retrieval chains, &lt;a href=&#34;https://js.langchain.com/docs/use_cases/question_answering/&#34;&gt;see this page&lt;/a&gt;. The specific variant of the conversational retrieval chain used here is composed using LangChain Expression Language, which you can &lt;a href=&#34;https://js.langchain.com/docs/guides/expression_language/cookbook&#34;&gt;read more about here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For more info on retrieval agents, &lt;a href=&#34;https://js.langchain.com/docs/use_cases/question_answering/conversational_retrieval_agents&#34;&gt;see this page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üìö Learn More&lt;/h2&gt; &#xA;&lt;p&gt;The example chains in the &lt;code&gt;app/api/chat/route.ts&lt;/code&gt; and &lt;code&gt;app/api/chat/retrieval/route.ts&lt;/code&gt; files use &lt;a href=&#34;https://js.langchain.com/docs/guides/expression_language/interface&#34;&gt;LangChain Expression Language&lt;/a&gt; to compose different LangChain modules together. You can integrate other retrievers, agents, preconfigured chains, and more too, though keep in mind &lt;code&gt;BytesOutputParser&lt;/code&gt; is meant to be used directly with model output.&lt;/p&gt; &#xA;&lt;p&gt;To learn more about what you can do with LangChain.js, check out the docs here:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://js.langchain.com/docs/&#34;&gt;https://js.langchain.com/docs/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;‚ñ≤ Deploy on Vercel&lt;/h2&gt; &#xA;&lt;p&gt;When ready, you can deploy your app on the &lt;a href=&#34;https://vercel.com/new?utm_medium=default-template&amp;amp;filter=next.js&amp;amp;utm_source=create-next-app&amp;amp;utm_campaign=create-next-app-readme&#34;&gt;Vercel Platform&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Check out the &lt;a href=&#34;https://nextjs.org/docs/deployment&#34;&gt;Next.js deployment documentation&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Thank You!&lt;/h2&gt; &#xA;&lt;p&gt;Thanks for reading! If you have any questions or comments, reach out to us on Twitter &lt;a href=&#34;https://twitter.com/langchainai&#34;&gt;@LangChainAI&lt;/a&gt;, or &lt;a href=&#34;https://discord.gg/langchain&#34;&gt;click here to join our Discord server&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>truongdn-it/nextjs-core-project</title>
    <updated>2023-09-19T01:41:16Z</updated>
    <id>tag:github.com,2023-09-19:/truongdn-it/nextjs-core-project</id>
    <link href="https://github.com/truongdn-it/nextjs-core-project" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Nextjs Core Project&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;NEXTJS CORE PROJECT&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;-----Author: TruongDN-----&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;em&gt;Lu√¥n vi·∫øt m√£ s·∫°ch&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;em&gt;Nghƒ© tr∆∞·ªõc khi code&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;em&gt;Code c√≥ t√¢m&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;em&gt;S·∫µn s√†ng d·∫°y nhau&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;em&gt;Tr√°ch nhi·ªám v·ªõi c√¥ng vi·ªác&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;em&gt;Ch·ªß ƒë·ªông th·∫£o lu·∫≠n&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Commit Rules&lt;/h2&gt; &#xA;&lt;p&gt;Must create branch follow below rules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;build&lt;/li&gt; &#xA; &lt;li&gt;chore&lt;/li&gt; &#xA; &lt;li&gt;ci&lt;/li&gt; &#xA; &lt;li&gt;docs&lt;/li&gt; &#xA; &lt;li&gt;feat&lt;/li&gt; &#xA; &lt;li&gt;fix&lt;/li&gt; &#xA; &lt;li&gt;perf&lt;/li&gt; &#xA; &lt;li&gt;refactor&lt;/li&gt; &#xA; &lt;li&gt;revert&lt;/li&gt; &#xA; &lt;li&gt;style&lt;/li&gt; &#xA; &lt;li&gt;test&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Example: &lt;code&gt;feat: first commit&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Branch Rules&lt;/h2&gt; &#xA;&lt;p&gt;Must create branch follow below rules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;feat/&lt;/li&gt; &#xA; &lt;li&gt;feedback/&lt;/li&gt; &#xA; &lt;li&gt;hotfix/&lt;/li&gt; &#xA; &lt;li&gt;revert/&lt;/li&gt; &#xA; &lt;li&gt;reset/&lt;/li&gt; &#xA; &lt;li&gt;force/&lt;/li&gt; &#xA; &lt;li&gt;refactor/&lt;/li&gt; &#xA; &lt;li&gt;fix/&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Example: &lt;code&gt;git checkout -b feat/feature-a&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Note: &lt;em&gt;Underscore to be not allow!!!&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Run Locally&lt;/h2&gt; &#xA;&lt;p&gt;Clone the project&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  git clone https://link-to-project&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Go to the project directory&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  cd my-project&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install dependencies&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  npm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Start the server&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>unknownskl/greenlight</title>
    <updated>2023-09-19T01:41:16Z</updated>
    <id>tag:github.com,2023-09-19:/unknownskl/greenlight</id>
    <link href="https://github.com/unknownskl/greenlight" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Greenlight is an open-source client for xCloud and Xbox home streaming made in Typescript.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Greenlight&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/unknownskl/greenlight/actions/workflows/build.yml&#34;&gt;&lt;img src=&#34;https://github.com/unknownskl/greenlight/actions/workflows/build.yml/badge.svg?sanitize=true&#34; alt=&#34;Build/release&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Greenlight is an open-source client for xCloud and xHome streaming made in Javascript and Typescript. The client is an application wrapper around &lt;a href=&#34;https://github.com/unknownskl/xbox-xcloud-player&#34;&gt;xbox-xcloud-player&lt;/a&gt;. Application runs on Linux, mac, Windows and Steam Deck.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;DISCLAIMER: Greenlight is not affiliated with Microsoft, Xbox or Moonlight. All rights and trademarks are property of their respective owners.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Stream video and audio from the Xbox One and Xbox Series&lt;/li&gt; &#xA; &lt;li&gt;Support for gamepad controls&lt;/li&gt; &#xA; &lt;li&gt;Supports rumble on xCloud&lt;/li&gt; &#xA; &lt;li&gt;Keyboard controls&lt;/li&gt; &#xA; &lt;li&gt;Build-in online friends list&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/unknownskl/greenlight/main-v2/images/main.png&#34; width=&#34;400&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/unknownskl/greenlight/main-v2/images/stream.png&#34; width=&#34;400&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Keyboard controls&lt;/h3&gt; &#xA;&lt;p&gt;The following keys are mapped as following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Dpad: Keypad direction controls&#xA;Buttons: A, B, X, Y, Backspace (Mapped as B), Enter (Mapped as A)&#xA;Nexus (Xbox button): N&#xA;Left Bumper: [&#xA;Right Bumper: ]&#xA;Left Trigger: -&#xA;Right Trigger: =&#xA;View: V&#xA;Menu: M&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Streaming stats&lt;/h3&gt; &#xA;&lt;p&gt;During the stream you can show extra debug statistics that contain extra data about the buffer queues and other information. To bring this up you have to press &lt;code&gt;~&lt;/code&gt; on your keyboard.&lt;/p&gt; &#xA;&lt;p&gt;On the left bottom you can see the status (Altough not always accurate). The right top you can find the FPS of the video and audio decoders including the latency. On the right bottom you can find debug information about the buffer queues and other information that is useful for debugging perposes.&lt;/p&gt; &#xA;&lt;p&gt;When possible always provide this information with your issue when possible (if it is related).&lt;/p&gt; &#xA;&lt;h3&gt;Online friends list&lt;/h3&gt; &#xA;&lt;p&gt;The application also provides a way to see which of your friends are online. This can be useful when you want to quickly check if anyone is online to play with :)&lt;/p&gt; &#xA;&lt;h2&gt;Steam Deck Setup&lt;/h2&gt; &#xA;&lt;p&gt;This application is reported to be working on the Steam Deck with some small bugs and side-effects. You can map one of the Steam Deck back buttons to the &#39;N&#39; key to simulate the Xbox button.&lt;/p&gt; &#xA;&lt;h3&gt;Optional launch arguments&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Argument&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;--fullscreen&lt;/td&gt; &#xA;   &lt;td&gt;Starts the application in fullscreen&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;--connect=&#xA;    &lt;value&gt;&lt;/value&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Will start stream once the user is authenticated.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;For console use &lt;code&gt;F000000000000000&lt;/code&gt; format and for xCloud use &lt;code&gt;xcloud_&amp;lt;title&amp;gt;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;To close the application&lt;/h3&gt; &#xA;&lt;p&gt;Click on the Xbox logo on the left top. It will ask you to confirm to close the window.&lt;/p&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;You can either compile the project yourself or download the (unsigned) executable from the &lt;a href=&#34;https://github.com/unknownskl/greenlight/releases&#34;&gt;releases&lt;/a&gt; page&lt;/p&gt; &#xA;&lt;h2&gt;Local Development&lt;/h2&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Rust (&lt;a href=&#34;https://rustup.rs/&#34;&gt;https://rustup.rs/&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;NodeJS (&lt;a href=&#34;https://nodejs.org/&#34;&gt;https://nodejs.org/&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Yarn (&lt;a href=&#34;https://yarnpkg.com/&#34;&gt;https://yarnpkg.com/&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Steps to get up and running&lt;/h3&gt; &#xA;&lt;p&gt;Clone the repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/unknownskl/greenlight.git&#xA;cd greenlight&#xA;git submodule update --init --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;yarn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run development build:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;yarn dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create production build:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;yarn build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Changelog&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/unknownskl/greenlight/main-v2/CHANGELOG.md&#34;&gt;changelog&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>