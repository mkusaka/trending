<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-01-07T01:36:10Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ohcnetwork/care_fe</title>
    <updated>2025-01-07T01:36:10Z</updated>
    <id>tag:github.com,2025-01-07:/ohcnetwork/care_fe</id>
    <link href="https://github.com/ohcnetwork/care_fe" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Care is a Digital Public Good enabling TeleICU &amp; Decentralised Administration of Healthcare Capacity across States.&lt;/p&gt;&lt;hr&gt;&lt;a href=&#34;https://ohc.network/&#34;&gt; &lt;p align=&#34;center&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://raw.githubusercontent.com/ohcnetwork/branding/refs/heads/main/Care/SVG/Logo/Care-Logo_gradient_mark_with_white_wordmark.svg&#34;&gt; &#xA;   &lt;img alt=&#34;CARE Logo&#34; src=&#34;https://raw.githubusercontent.com/ohcnetwork/branding/refs/heads/main/Care/SVG/Logo/Care-Logo_gradient_mark_with_dark_wordmark.svg?sanitize=true&#34; width=&#34;400&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/p&gt; &lt;/a&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;b&gt;Our goal is to continuously improve the quality and accessibility of public healthcare services using digital tools.&lt;/b&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt;&lt;a href=&#34;https://care.ohc.network&#34; target=&#34;_blank&#34;&gt;üöÄ Staging Deployment&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;center&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://app.netlify.com/sites/care-ohc/deploys&#34;&gt;&lt;img src=&#34;https://api.netlify.com/api/v1/badges/de76351f-b1f0-4bf8-8445-d9faf6391b13/deploy-status&#34; alt=&#34;Netlify Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/center&gt; &#xA;&lt;p align=&#34;center&#34;&gt;Auto deployed to &lt;a href=&#34;https://care.ohc.network/&#34;&gt;care.ohc.network&lt;/a&gt; for &lt;code&gt;develop&lt;/code&gt; branch. All pull requests have preview builds powered by &lt;a href=&#34;https://netlify.com&#34;&gt;Netlify&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/links/0&#34;&gt;&lt;img src=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/images/0&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/links/1&#34;&gt;&lt;img src=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/images/1&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/links/2&#34;&gt;&lt;img src=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/images/2&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/links/3&#34;&gt;&lt;img src=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/images/3&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/links/4&#34;&gt;&lt;img src=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/images/4&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/links/5&#34;&gt;&lt;img src=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/images/5&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/links/6&#34;&gt;&lt;img src=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/images/6&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/links/7&#34;&gt;&lt;img src=&#34;https://sourcerer.io/fame/tomahawk-pilot/ohcnetwork/care_fe/images/7&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/ohcnetwork/care_fe/workflows/Code%20scanning%20-%20action/badge.svg?sanitize=true&#34; alt=&#34;Code scanning - action&#34;&gt; &lt;img src=&#34;https://github.com/ohcnetwork/care_fe/workflows/OSSAR/badge.svg?sanitize=true&#34; alt=&#34;OSSAR&#34;&gt; &lt;a href=&#34;https://cloud.cypress.io/projects/wf7d2m/runs&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint?url=https://cloud.cypress.io/badge/simple/wf7d2m/develop&amp;amp;style=flat&amp;amp;logo=cypress&#34; alt=&#34;Cypress Tests&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://github.com/ohcnetwork/care_fe/workflows/CARE%20Develop%20Registry/badge.svg?sanitize=true&#34; alt=&#34;Staging Release&#34;&gt; &lt;img src=&#34;https://github.com/ohcnetwork/care_fe/workflows/Production%20Release/badge.svg?sanitize=true&#34; alt=&#34;Production Release&#34;&gt; &lt;a href=&#34;https://www.codacy.com/gh/ohcnetwork/care_fe?utm_source=github.com&amp;amp;utm_medium=referral&amp;amp;utm_content=ohcnetwork/care_fe&amp;amp;utm_campaign=Badge_Grade&#34;&gt;&lt;img src=&#34;https://api.codacy.com/project/badge/Grade/200482ab117e4b5397ff3f5ae5719aa2&#34; alt=&#34;Codacy Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codeclimate.com/github/ohcnetwork/care_fe/maintainability&#34;&gt;&lt;img src=&#34;https://api.codeclimate.com/v1/badges/f1438f693aa459805301/maintainability&#34; alt=&#34;Maintainability&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üí¨ Comment on the issue if you are willing to take it up, and link the pull request with the issue.&lt;/li&gt; &#xA; &lt;li&gt;üè∑Ô∏è Tag &lt;code&gt;@ohcnetwork/care-fe-code-reviewers&lt;/code&gt; for faster resolution.&lt;/li&gt; &#xA; &lt;li&gt;üì∏ Attach screenshots in the pull requests showing the changes made in the UI.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Install the required dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;First-time setup&lt;/h4&gt; &#xA;&lt;p&gt;For first-time setup, run the following command to generate the pluginMap and install plugin configurations:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm run setup&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;üèÉ Run the app in development mode&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once the development server has started, open &lt;a href=&#34;http://localhost:4000&#34;&gt;localhost:4000&lt;/a&gt; in your browser. The page will be automatically reloaded when you make edits and save. You will also see any lint errors in the console.&lt;/p&gt; &#xA;&lt;h4&gt;üîë Staging API Credentials&lt;/h4&gt; &#xA;&lt;p&gt;Authenticate to staging API with any of the following credentials&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;- username: devdistrictadmin&#xA;  password: Coronasafe@123&#xA;  role: Administrator&#xA;&#xA;- username: staffdev&#xA;  password: Coronasafe@123&#xA;  role: Nurse&#xA;&#xA;- username: doctordev&#xA;  password: Coronasafe@123&#xA;  role: Doctor&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Contributing to CARE&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a branch with branch name of the format &lt;code&gt;issues/{issue#}/{short-name}&lt;/code&gt; (example &lt;code&gt;issues/7001/edit-prescriptions&lt;/code&gt;) from the latest &lt;a href=&#34;https://github.com/ohcnetwork/care_fe/tree/develop&#34;&gt;&lt;code&gt;develop&lt;/code&gt;&lt;/a&gt; branch when starting to work on an issue.&lt;/li&gt; &#xA; &lt;li&gt;Once the changes are pushed to the branch, make a pull request with a meaningful title (example: &#34;üíä Adds support for editing prescriptions&#34; #6369)&lt;/li&gt; &#xA; &lt;li&gt;Ensure the issue number is mentioned in the PR with a closing tag by following the PR body template. (Refer: &lt;a href=&#34;https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword&#34;&gt;Linking a pull request to an issue&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Once the code review is done, the PR will be marked with a &#34;Needs Testing&#34; label where it&#39;ll be queued for QA testing.&lt;/li&gt; &#xA; &lt;li&gt;Once tested, the PR would be marked with a &#34;Tested&#34; label and would be queued for merge.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Translations&lt;/h3&gt; &#xA;&lt;p&gt;All strings must be encased in i18n translations. New translation strings must be specified in &lt;code&gt;src&lt;/code&gt;-&amp;gt;&lt;code&gt;Locale&lt;/code&gt;-&amp;gt;&lt;code&gt;en&lt;/code&gt;. Do not add translations for languages other than english through pull requests. Other language translations can be contributed through &lt;a href=&#34;https://crowdin.com/project/ohccarefe&#34;&gt;Crowdin&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Testing&lt;/h3&gt; &#xA;&lt;p&gt;To ensure the quality of our pull requests, we use a variety of tools:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Automated E2E Testing:&lt;/strong&gt; We use Cypress for end-to-end testing to automatically verify the functionality and performance of our code.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Manual Real Device Testing:&lt;/strong&gt; We use BrowserStack to manually test our code on real devices, ensuring compatibility and functionality across different platforms and browsers.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;üß™ Run cypress tests&lt;/h4&gt; &#xA;&lt;p&gt;To run cypress tests locally, you&#39;ll need to setup the backend to run locally and load dummy data required for cypress to the database. See &lt;a href=&#34;https://github.com/ohcnetwork/care#self-hosting&#34;&gt;docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Once backend is running locally, you&#39;ll have to ensure your local front-end is connected to local backend, by setting the &lt;code&gt;REACT_CARE_API_URL&lt;/code&gt; env.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-env&#34;&gt;#.env&#xA;REACT_CARE_API_URL=http://127.0.0.1:9000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once done, start the development server by running&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once development server is running, then run the cypress tests in either of the ways described below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm run cypress:run        # To run all tests in headless mode.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm run cypress:run:gui    # To run all tests in headed mode.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm run cypress:open       # To debug and run tests individually.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Failed test screenshots are saved in &lt;code&gt;cypress/screenshots&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;All test videos are saved in &lt;code&gt;cypress/videos&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìñ Documentations&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.ohc.network/docs/care&#34;&gt;CARE Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://careapi.ohc.network/swagger/&#34;&gt;Swagger API Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.coronasafe.network/care-testing-documentation/&#34;&gt;Testing Documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üöÄ Production&lt;/h2&gt; &#xA;&lt;h4&gt;Build the app for production&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm run build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Builds the app for production to the &lt;code&gt;build&lt;/code&gt; folder. It correctly bundles React in production mode and optimizes the build for the best performance.&lt;/p&gt; &#xA;&lt;h4&gt;Start a production &lt;code&gt;http-server&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm run preview&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Starts a production http-server in local to run the project with Service worker. The build is minified and the filenames include the hashes.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;üöÄ Your app is ready to be deployed!&lt;/strong&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>av/harbor</title>
    <updated>2025-01-07T01:36:10Z</updated>
    <id>tag:github.com,2025-01-07:/av/harbor</id>
    <link href="https://github.com/av/harbor" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Effortlessly run LLM backends, APIs, frontends, and services with one command.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://github.com/av/harbor/raw/main/docs/harbor-2.png&#34; alt=&#34;Harbor project logo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/av/harbor/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/tag/av/harbor&#34; alt=&#34;GitHub Tag&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.npmjs.com/package/@avcodes/harbor&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/%40avcodes%2Fharbor?labelColor=red&amp;amp;color=white&#34; alt=&#34;NPM Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/llm-harbor/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/llm-harbor?labelColor=blue&#34; alt=&#34;PyPI - Version&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/repo-size/av/harbor&#34; alt=&#34;GitHub repo size&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/directory-file-count/av/harbor?type=file&amp;amp;extension=yml&amp;amp;label=compose%20files&amp;amp;color=orange&#34; alt=&#34;GitHub repo file or directory count&#34;&gt; &lt;a href=&#34;https://visitorbadge.io/status?path=av%2Fharbor&#34;&gt;&lt;img src=&#34;https://api.visitorbadge.io/api/visitors?path=av%2Fharbor&amp;amp;countColor=%23263759&amp;amp;style=flat&#34; alt=&#34;Visitors&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/languages/count/av/harbor&#34; alt=&#34;GitHub language count&#34;&gt; &lt;a href=&#34;https://discord.gg/8nDRphrhSF&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Discord-Harbor-blue?logo=discord&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Effortlessly run LLM backends, APIs, frontends, and services with one command.&lt;/p&gt; &#xA;&lt;p&gt;Harbor is a containerized LLM toolkit that allows you to run LLMs and additional services. It consists of a CLI and a companion App that allows you to manage and run AI services with ease.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/av/harbor/wiki/harbor-app-3.png&#34; alt=&#34;Screenshot of Harbor CLI and App together&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Services&lt;/h2&gt; &#xA;&lt;h5&gt;UIs&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/av/harbor/wiki/2.1.1-Frontend:-Open-WebUI&#34;&gt;Open WebUI&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.1.2-Frontend:-ComfyUI&#34;&gt;ComfyUI&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.1.3-Frontend:-LibreChat&#34;&gt;LibreChat&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.1.4-Frontend:-ChatUI&#34;&gt;HuggingFace ChatUI&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.1.5-Frontend:-Lobe-Chat&#34;&gt;Lobe Chat&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.1.6-Frontend:-hollama&#34;&gt;Hollama&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.1.7-Frontend:-parllama&#34;&gt;parllama&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.1.8-Frontend:-BionicGPT&#34;&gt;BionicGPT&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.1.9-Frontend:-AnythingLLM&#34;&gt;AnythingLLM&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.1.10-Frontend:-Chat-Nio&#34;&gt;Chat Nio&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Backends&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.1-Backend:-Ollama&#34;&gt;Ollama&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.2-Backend:-llama.cpp&#34;&gt;llama.cpp&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.3-Backend:-vLLM&#34;&gt;vLLM&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.4-Backend:-TabbyAPI&#34;&gt;TabbyAPI&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.5-Backend:-Aphrodite-Engine&#34;&gt;Aphrodite Engine&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.6-Backend:-mistral.rs&#34;&gt;mistral.rs&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.7-Backend:-openedai-speech&#34;&gt;openedai-speech&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.14-Backend:-Faster-Whisper&#34;&gt;faster-whisper-server&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.8-Backend:-Parler&#34;&gt;Parler&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.9-Backend:-text-generation-inference&#34;&gt;text-generation-inference&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.10-Backend:-lmdeploy&#34;&gt;LMDeploy&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.11-Backend:-AirLLM&#34;&gt;AirLLM&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.12-Backend:-SGLang&#34;&gt;SGLang&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.13-Backend:-KTransformers&#34;&gt;KTransformers&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.2.15-Backend:-Nexa-SDK&#34;&gt;Nexa SDK&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Satellites&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/av/harbor/wiki/5.1.-Harbor-Bench&#34;&gt;Harbor Bench&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/5.2.-Harbor-Boost&#34;&gt;Harbor Boost&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.1-Satellite:-SearXNG&#34;&gt;SearXNG&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.2-Satellite:-Perplexica&#34;&gt;Perplexica&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.3-Satellite:-Dify&#34;&gt;Dify&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.4-Satellite:-Plandex&#34;&gt;Plandex&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.5-Satellite:-LiteLLM&#34;&gt;LiteLLM&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.6-Satellite:-langfuse&#34;&gt;LangFuse&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.7-Satellite:-Open-Interpreter&#34;&gt;Open Interpreter&lt;/a&gt; ‚¶Å Ô∏é&lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.8-Satellite:-cloudflared&#34;&gt;cloudflared&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.9-Satellite:-cmdh&#34;&gt;cmdh&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.10-Satellite:-fabric&#34;&gt;fabric&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.11-Satellite:-txtai-RAG&#34;&gt;txtai RAG&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.12-Satellite:-TextGrad&#34;&gt;TextGrad&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.13-Satellite:-aider&#34;&gt;Aider&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.14-Satellite:-aichat&#34;&gt;aichat&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.16-Satellite:-omnichain&#34;&gt;omnichain&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.17-Satellite:-lm-evaluation-harness&#34;&gt;lm-evaluation-harness&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.18-Satellite:-JupyterLab&#34;&gt;JupyterLab&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.19-Satellite:-ol1&#34;&gt;ol1&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.20-Satellite:-OpenHands&#34;&gt;OpenHands&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.21-Satellite:-LitLytics&#34;&gt;LitLytics&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.22-Satellite:-Repopack&#34;&gt;Repopack&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.23-Satellite:-n8n&#34;&gt;n8n&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.24-Satellite:-Bolt.new&#34;&gt;Bolt.new&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.25-Satellite:-Open-WebUI-Pipelines&#34;&gt;Open WebUI Pipelines&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.26-Satellite:-Qdrant&#34;&gt;Qdrant&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.27-Satellite:-K6&#34;&gt;K6&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.28-Satellite:-Promptfoo&#34;&gt;Promptfoo&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.29-Satellite:-Webtop&#34;&gt;Webtop&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.30-Satellite:-OmniParser&#34;&gt;OmniParser&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.31-Satellite:-Flowise&#34;&gt;Flowise&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.32-Satellite:-LangFlow&#34;&gt;Langflow&lt;/a&gt; ‚¶ÅÔ∏é &lt;a href=&#34;https://github.com/av/harbor/wiki/2.3.33-Satellite:-OptiLLM&#34;&gt;OptiLLM&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/av/harbor/wiki/2.-Services&#34;&gt;services documentation&lt;/a&gt; for a brief overview of each.&lt;/p&gt; &#xA;&lt;h2&gt;Blitz Tour&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/wiki/av/harbor/harbor-arch-diag.png&#34; alt=&#34;Diagram outlining Harbor&#39;s service structure&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Run Harbor with default services:&#xA;# Open WebUI and Ollama&#xA;harbor up&#xA;&#xA;# Run Harbor with additional services&#xA;# Running SearXNG automatically enables Web RAG in Open WebUI&#xA;harbor up searxng&#xA;&#xA;# Run additional/alternative LLM Inference backends&#xA;# Open Webui is automatically connected to them.&#xA;harbor up llamacpp tgi litellm vllm tabbyapi aphrodite sglang ktransformers&#xA;&#xA;# Run different Frontends&#xA;harbor up librechat chatui bionicgpt hollama&#xA;&#xA;# Get a free quality boost with&#xA;# built-in optimizing proxy&#xA;harbor up boost&#xA;&#xA;# Use FLUX in Open WebUI in one command&#xA;harbor up comfyui&#xA;&#xA;# Use custom models for supported backends&#xA;harbor llamacpp model https://huggingface.co/user/repo/model.gguf&#xA;&#xA;# Shortcut to HF Hub to find the models&#xA;harbor hf find gguf gemma-2&#xA;# Use HFDownloader and official HF CLI to download models&#xA;harbor hf dl -m google/gemma-2-2b-it -c 10 -s ./hf&#xA;harbor hf download google/gemma-2-2b-it&#xA;&#xA;# Where possible, cache is shared between the services&#xA;harbor tgi model google/gemma-2-2b-it&#xA;harbor vllm model google/gemma-2-2b-it&#xA;harbor aphrodite model google/gemma-2-2b-it&#xA;harbor tabbyapi model google/gemma-2-2b-it-exl2&#xA;harbor mistralrs model google/gemma-2-2b-it&#xA;harbor opint model google/gemma-2-2b-it&#xA;harbor sglang model google/gemma-2-2b-it&#xA;&#xA;# Convenience tools for docker setup&#xA;harbor logs llamacpp&#xA;harbor exec llamacpp ./scripts/llama-bench --help&#xA;harbor shell vllm&#xA;&#xA;# Tell your shell exactly what you think about it&#xA;harbor opint&#xA;harbor aider&#xA;harbor aichat&#xA;harbor cmdh&#xA;&#xA;# Use fabric to LLM-ify your linux pipes&#xA;cat ./file.md | harbor fabric --pattern extract_extraordinary_claims | grep &#34;LK99&#34;&#xA;&#xA;# Access service CLIs without installing them&#xA;harbor hf scan-cache&#xA;harbor ollama list&#xA;&#xA;# Open services from the CLI&#xA;harbor open webui&#xA;harbor open llamacpp&#xA;# Print yourself a QR to quickly open the&#xA;# service on your phone&#xA;harbor qr&#xA;# Feeling adventurous? Expose your harbor&#xA;# to the internet&#xA;harbor tunnel&#xA;&#xA;# Config management&#xA;harbor config list&#xA;harbor config set webui.host.port 8080&#xA;&#xA;# Create and manage config profiles&#xA;harbor profile save l370b&#xA;harbor profile use default&#xA;&#xA;# Lookup recently used harbor commands&#xA;harbor history&#xA;&#xA;# Eject from Harbor into a standalone Docker Compose setup&#xA;# Will export related services and variables into a standalone file.&#xA;harbor eject searxng llamacpp &amp;gt; docker-compose.harbor.yml&#xA;&#xA;# Run a build-in LLM benchmark with&#xA;# your own tasks&#xA;harbor bench run&#xA;&#xA;# Gimmick/Fun Area&#xA;&#xA;# Argument scrambling, below commands are all the same as above&#xA;# Harbor doesn&#39;t care if it&#39;s &#34;vllm model&#34; or &#34;model vllm&#34;, it&#39;ll&#xA;# figure it out.&#xA;harbor model vllm&#xA;harbor vllm model&#xA;&#xA;harbor config get webui.name&#xA;harbor get config webui_name&#xA;&#xA;harbor tabbyapi shell&#xA;harbor shell tabbyapi&#xA;&#xA;# 50% gimmick, 50% useful&#xA;# Ask harbor about itself&#xA;harbor how to ping ollama container from the webui?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Harbor App Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/a5cd2ef1-3208-400a-8866-7abd85808503&#34;&gt;https://github.com/user-attachments/assets/a5cd2ef1-3208-400a-8866-7abd85808503&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;In the demo, Harbor App is used to launch a default stack with &lt;a href=&#34;https://raw.githubusercontent.com/av/harbor/main/2.2.1-Backend:-Ollama&#34;&gt;Ollama&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/av/harbor/main/2.1.1-Frontend:-Open-WebUI&#34;&gt;Open WebUI&lt;/a&gt; services. Later, &lt;a href=&#34;https://raw.githubusercontent.com/av/harbor/main/2.3.1-Satellite:-SearXNG&#34;&gt;SearXNG&lt;/a&gt; is also started, and WebUI can connect to it for the Web RAG right out of the box. After that, &lt;a href=&#34;https://raw.githubusercontent.com/av/harbor/main/5.2.-Harbor-Boost&#34;&gt;Harbor Boost&lt;/a&gt; is also started and connected to the WebUI automatically to induce more creative outputs. As a final step, Harbor config is adjusted in the App for the &lt;a href=&#34;https://raw.githubusercontent.com/av/harbor/main/5.2.-Harbor-Boost#klmbr---boost-llm-creativity&#34;&gt;&lt;code&gt;klmbr&lt;/code&gt;&lt;/a&gt; module in the &lt;a href=&#34;https://raw.githubusercontent.com/av/harbor/main/5.2.-Harbor-Boost&#34;&gt;Harbor Boost&lt;/a&gt;, which makes the output unparseable for the LLM (yet still undetstandable for humans).&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/av/harbor/wiki/1.0.-Installing-Harbor&#34;&gt;Installing Harbor&lt;/a&gt;&lt;br&gt; Guides to install Harbor CLI and App&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/av/harbor/wiki/1.-Harbor-User-Guide&#34;&gt;Harbor User Guide&lt;/a&gt;&lt;br&gt; High-level overview of working with Harbor&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/av/harbor/wiki/1.1-Harbor-App&#34;&gt;Harbor App&lt;/a&gt;&lt;br&gt; Overview and manual for the Harbor companion application&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/av/harbor/wiki/2.-Services&#34;&gt;Harbor Services&lt;/a&gt;&lt;br&gt; Catalog of services available in Harbor&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/av/harbor/wiki/3.-Harbor-CLI-Reference&#34;&gt;Harbor CLI Reference&lt;/a&gt;&lt;br&gt; Read more about Harbor CLI commands and options. Read about supported services and the ways to configure them.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/av/harbor/wiki/4.-Compatibility&#34;&gt;Compatibility&lt;/a&gt;&lt;br&gt; Known compatibility issues between the services and models as well as possible workarounds.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/av/harbor/wiki/5.1.-Harbor-Bench&#34;&gt;Harbor Bench&lt;/a&gt;&lt;br&gt; Documentation for the built-in LLM benchmarking service.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/av/harbor/wiki/5.2.-Harbor-Boost&#34;&gt;Harbor Boost&lt;/a&gt;&lt;br&gt; Documentation for the built-in LLM optimiser proxy.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/av/harbor/wiki/6.-Harbor-Compose-Setup&#34;&gt;Harbor Compose Setup&lt;/a&gt;&lt;br&gt; Read about the way Harbor uses Docker Compose to manage services.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/av/harbor/wiki/7.-Adding-A-New-Service&#34;&gt;Adding A New Service&lt;/a&gt;&lt;br&gt; Documentation on bringing more services into the Harbor toolkit.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Convenience factor&lt;/li&gt; &#xA; &lt;li&gt;Workflow/setup centralisation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you&#39;re comfortable with Docker and Linux administration - you likely don&#39;t need Harbor per se to manage your local LLM environment. However, you&#39;re also likely to eventually arrive to a similar solution. I know this for a fact, since I was rocking pretty much similar setup, just without all the whistles and bells.&lt;/p&gt; &#xA;&lt;p&gt;Harbor is not designed as a deployment solution, but rather as a helper for the local LLM development environment. It&#39;s a good starting point for experimenting with LLMs and related services.&lt;/p&gt; &#xA;&lt;p&gt;You can later eject from Harbor and use the services in your own setup, or continue using Harbor as a base for your own configuration.&lt;/p&gt; &#xA;&lt;h2&gt;Overview and Features&lt;/h2&gt; &#xA;&lt;p&gt;This project consists of a fairly large shell CLI, fairly small &lt;code&gt;.env&lt;/code&gt; file and enourmous (for one repo) amount of &lt;code&gt;docker-compose&lt;/code&gt; files.&lt;/p&gt; &#xA;&lt;h4&gt;Features&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Manage local LLM stack with a concise CLI&lt;/li&gt; &#xA; &lt;li&gt;Convenience utilities for common tasks (model management, configuration, service debug, URLs, tunnels, etc.)&lt;/li&gt; &#xA; &lt;li&gt;Access service CLIs (&lt;code&gt;hf&lt;/code&gt;, &lt;code&gt;ollama&lt;/code&gt;, etc.) via Docker without install&lt;/li&gt; &#xA; &lt;li&gt;Services are pre-configured to work together (contributions welcome)&lt;/li&gt; &#xA; &lt;li&gt;Host cache is shared and reused - Hugging Face, ollama, etc.&lt;/li&gt; &#xA; &lt;li&gt;Co-located service configs&lt;/li&gt; &#xA; &lt;li&gt;Built-in LLM benchmarking service&lt;/li&gt; &#xA; &lt;li&gt;Manage configuration profiles for different use cases&lt;/li&gt; &#xA; &lt;li&gt;Eject to run without harbor with &lt;code&gt;harbor eject&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>