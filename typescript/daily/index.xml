<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-19T01:38:28Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>xiaoxian521/pure-admin-thin</title>
    <updated>2022-12-19T01:38:28Z</updated>
    <id>tag:github.com,2022-12-19:/xiaoxian521/pure-admin-thin</id>
    <link href="https://github.com/xiaoxian521/pure-admin-thin" rel="alternate"></link>
    <summary type="html">&lt;p&gt;vue-pure-admin官方精简版&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;vue-pure-admin精简版（非国际化版本）&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/xiaoxian521/pure-admin-thin/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/xiaoxian521/vue-pure-admin.svg?sanitize=true&#34; alt=&#34;license&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;中文&lt;/strong&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/xiaoxian521/pure-admin-thin/main/README.en-US.md&#34;&gt;English&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;介绍&lt;/h2&gt; &#xA;&lt;p&gt;精简版是基于 &lt;a href=&#34;https://github.com/xiaoxian521/vue-pure-admin&#34;&gt;vue-pure-admin&lt;/a&gt; 提炼出的架子，包含主体功能，更适合实际项目开发，打包后的大小在全局引入 &lt;a href=&#34;https://element-plus.org&#34;&gt;element-plus&lt;/a&gt; 的情况下仍然低于 &lt;code&gt;2.3MB&lt;/code&gt;，并且会永久同步完整版的代码。开启 &lt;code&gt;brotli&lt;/code&gt; 压缩和 &lt;code&gt;cdn&lt;/code&gt; 替换本地库模式后，打包大小低于 &lt;code&gt;350kb&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;版本选择&lt;/h2&gt; &#xA;&lt;p&gt;当前是非国际化版本哦，如果您需要国际化版本 &lt;a href=&#34;https://github.com/xiaoxian521/pure-admin-thin/tree/i18n&#34;&gt;请点击&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;配套视频&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1534y1S7HV&#34;&gt;点我查看教程&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV17g411T7rq&#34;&gt;点我查看 UI 设计&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;配套文档&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yiming_chang.gitee.io/pure-admin-doc&#34;&gt;点我查看国内文档站&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://xiaoxian521.github.io/pure-admin-doc&#34;&gt;点我查看国外文档站&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;维护者&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/xiaoxian521&#34;&gt;xiaoxian521&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;捐赠&lt;/h2&gt; &#xA;&lt;p&gt;如果你觉得这个项目对您有帮助，可以帮作者买一杯果汁 🍹 表示支持&lt;/p&gt; &#xA;&lt;img src=&#34;https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f69bf13c5b854ed5b699807cafa0e3ce~tplv-k3u1fbpfcp-zoom-in-crop-mark:1304:0:0:0.awebp?&#34; width=&#34;150px&#34; height=&#34;150px&#34;&gt; &#xA;&lt;h2&gt;QQ 交流群&lt;/h2&gt; &#xA;&lt;p&gt;一群已满，下面是二群，群里严禁 &lt;code&gt;黄&lt;/code&gt; 、 &lt;code&gt;赌&lt;/code&gt; 、 &lt;code&gt;毒&lt;/code&gt; 、 &lt;code&gt;vpn&lt;/code&gt; 等违法行为！&lt;/p&gt; &#xA;&lt;img src=&#34;http://yiming_chang.gitee.io/pure-admin-doc/img/support/qq.png&#34; width=&#34;150px&#34; height=&#34;225px&#34;&gt; &#xA;&lt;h2&gt;用法&lt;/h2&gt; &#xA;&lt;h3&gt;安装依赖&lt;/h3&gt; &#xA;&lt;p&gt;pnpm install&lt;/p&gt; &#xA;&lt;h3&gt;安装一个包&lt;/h3&gt; &#xA;&lt;p&gt;pnpm add 包名&lt;/p&gt; &#xA;&lt;h3&gt;卸载一个包&lt;/h3&gt; &#xA;&lt;p&gt;pnpm remove 包名&lt;/p&gt; &#xA;&lt;p&gt;我认为你应该先 &lt;code&gt;fork&lt;/code&gt; 项目去开发，以便我更新时您可以同步拉取更新！！！&lt;/p&gt; &#xA;&lt;h2&gt;⚠️ 注意&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;精简版不接受任何 &lt;code&gt;issues&lt;/code&gt; 和 &lt;code&gt;pr&lt;/code&gt;，如果有问题请到完整版 &lt;a href=&#34;https://github.com/xiaoxian521/vue-pure-admin/issues/new/choose&#34;&gt;issues&lt;/a&gt; 去提，谢谢！！！&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;许可证&lt;/h2&gt; &#xA;&lt;p&gt;原则上不收取任何费用及版权，可以放心使用，不过如需二次开源（比如用此平台二次开发并开源）请联系作者获取许可！&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/xiaoxian521/pure-admin-thin/main/LICENSE&#34;&gt;MIT © xiaoxian521-2020&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>kx-Huang/ChatGPT-on-WeChat</title>
    <updated>2022-12-19T01:38:28Z</updated>
    <id>tag:github.com,2022-12-19:/kx-Huang/ChatGPT-on-WeChat</id>
    <link href="https://github.com/kx-Huang/ChatGPT-on-WeChat" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🤖️ Deploy your WeChat bot powered by OpenAI within 2 steps! 两步部署你的微信人工智能聊天机器人！🤖️&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGPT on WeChat! &lt;img src=&#34;https://img.shields.io/badge/License-ISC-yellow.svg?sanitize=true&#34; alt=&#34;License: ISC&#34;&gt; &lt;a href=&#34;https://wakatime.com/badge/user/7d2c2fc8-bd1d-4e1e-bb2b-b49c6120ed53/project/205c561e-69ba-4478-b07f-f5bc7a0ed394&#34;&gt;&lt;img src=&#34;https://wakatime.com/badge/user/7d2c2fc8-bd1d-4e1e-bb2b-b49c6120ed53/project/205c561e-69ba-4478-b07f-f5bc7a0ed394.svg?sanitize=true&#34; alt=&#34;wakatime&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://visitor-badge.glitch.me/badge?page_id=kx-Huang.ChatGPT-on-WeChat&amp;amp;left_color=gray&amp;amp;right_color=blue&#34; alt=&#34;&#34;&gt; &#xA; &lt;!-- omit in toc --&gt;&lt;/h1&gt; &#xA;&lt;p&gt;Turn your WeChat into an auto-reply bot powered by ChatGPT!&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/doc/img/demo.png&#34; alt=&#34;Your Chat Bot in Group Chat!&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement &amp;amp; Features &#xA; &lt;!-- omit in toc --&gt;&lt;/h2&gt; &#xA;&lt;p&gt;This project is implemented based on &lt;a href=&#34;https://github.com/fuergaosi233/wechat-chatgpt&#34;&gt;this amazing project&lt;/a&gt; and &lt;a href=&#34;https://github.com/wechaty/wechaty&#34;&gt;Wechaty&lt;/a&gt; SDK, but with a major adjustment: using the official OpenAI &lt;code&gt;API Key&lt;/code&gt; to replace the previous pesudo-browser method, so it has the following features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;More stable and robust connection to &lt;code&gt;ChatGPT&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Can be deployed on cloud servers with no connection error (which the aforementioned project currently can&#39;t)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;0. Table of Content &#xA; &lt;!-- omit in toc --&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#1-how-to-deploy-this-bot&#34;&gt;1. How to Deploy this Bot?&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#11-deploy-in-local&#34;&gt;1.1 Deploy in Local&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#111-get-your-openai-api-keys-for-chatgpt&#34;&gt;1.1.1 Get your OpenAI API keys for &lt;code&gt;ChatGPT&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#112-configure-environment-variables&#34;&gt;1.1.2 Configure Environment Variables&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#113-setup-the-docker&#34;&gt;1.1.3 Setup the Docker&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#114-login-your-wechat&#34;&gt;1.1.4 Login your WeChat&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#12-deploy-on-cloud&#34;&gt;1.2 Deploy on Cloud&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#121-configure-on-railway&#34;&gt;1.2.1 Configure on &lt;code&gt;Railway&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#122-deploy--login-on-railway&#34;&gt;1.2.2 Deploy &amp;amp; Login on &lt;code&gt;Railway&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#2-any-fancy-advanced-settings&#34;&gt;2. Any Fancy Advanced Settings?&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#21-config-chatgpt-models&#34;&gt;2.1 Config &lt;code&gt;ChatGPT&lt;/code&gt; Models&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#22-config-chatgpt-features&#34;&gt;2.2 Config &lt;code&gt;ChatGPT&lt;/code&gt; Features&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#23-config-auto-reply-in-error&#34;&gt;2.3 Config Auto Reply in Error&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#24-add-customized-task-handler&#34;&gt;2.4 Add Customized Task Handler&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#3-how-to-contribute-to-this-project&#34;&gt;3. How to Contribute to this Project?&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;1. How to Deploy this Bot?&lt;/h2&gt; &#xA;&lt;p&gt;You can &lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#11-deploy-in-local&#34;&gt;deploy in local&lt;/a&gt; or &lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#12-deploy-on-cloud&#34;&gt;deploy on cloud&lt;/a&gt;, whatever you want.&lt;/p&gt; &#xA;&lt;h3&gt;1.1 Deploy in Local&lt;/h3&gt; &#xA;&lt;h4&gt;1.1.1 Get your OpenAI API keys for &lt;code&gt;ChatGPT&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;openaiApiKey&lt;/code&gt; can be generated in the &lt;a href=&#34;https://beta.openai.com/account/api-keys&#34;&gt;&lt;strong&gt;API Keys Page&lt;/strong&gt; in your OpenAI account&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;openaiOrganizationID&lt;/code&gt; is optional, which can be found in the &lt;a href=&#34;https://beta.openai.com/account/org-settings&#34;&gt;&lt;strong&gt;Settings Page&lt;/strong&gt; in your Open AI account&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;1.1.2 Configure Environment Variables&lt;/h4&gt; &#xA;&lt;p&gt;You can copy the template &lt;code&gt;config.yaml.example&lt;/code&gt; into a new file &lt;code&gt;config.yaml&lt;/code&gt;, and paste the configurations:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;openaiApiKey: &#34;&amp;lt;your_openai_api_key&amp;gt;&#34;&#xA;openaiOrganizationID: &#34;&amp;lt;your_organization_id&amp;gt;&#34;&#xA;chatgptTriggerKeyword: &#34;&amp;lt;your_keyword&amp;gt;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or you can export the environment variables listed in &lt;code&gt;.env.sample&lt;/code&gt; to your system, which is a more encouraged method to keep your &lt;code&gt;OpenAI API Key&lt;/code&gt; safe:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export OPENAI_API_KEY=&#34;sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&#34;&#xA;export OPENAI_ORGANIZATION_KEY=&#34;org-XXXXXXXXXXXXXXX&#34;&#xA;export CHATGPT_TRIGGER_KEYWORD=&#34;Hi bot:&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please note:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;chatgptTriggerKeyword&lt;/code&gt; is the keyword which can trigger auto-reply: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;In private chat, the message &lt;strong&gt;starts with&lt;/strong&gt; it will trigger auto-reply&lt;/li&gt; &#xA;   &lt;li&gt;In group chat, the message &lt;strong&gt;starts with&lt;/strong&gt; &lt;code&gt;@Name &amp;lt;keyword&amp;gt;&lt;/code&gt; will trigger auto-reply (Here &lt;code&gt;@Name &lt;/code&gt; means &#34;@ the bot&#34; in the group chat)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;chatgptTriggerKeyword&lt;/code&gt; can be &lt;strong&gt;empty string&lt;/strong&gt;, which means: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;In private chat, &lt;strong&gt;every messages&lt;/strong&gt; will trigger auto-reply&lt;/li&gt; &#xA;   &lt;li&gt;In group chat, only &lt;strong&gt;&#34;@ the bot&#34;&lt;/strong&gt; will trigger auto-reply&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;1.1.3 Setup the Docker&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Setup Docker Image&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker build -t chatgpt-on-wechat .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Setup Docker Container&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -v $(pwd)/config.yaml:/app/config.yaml chatgpt-on-wechat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;1.1.4 Login your WeChat&lt;/h4&gt; &#xA;&lt;p&gt;Once you deploy the bot successfully, just follow the &lt;code&gt;terminal&lt;/code&gt; or &lt;code&gt;Logs&lt;/code&gt; in Docker container prompt carefully:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Scan the QR Code with mobile WeChat&lt;/li&gt; &#xA; &lt;li&gt;Click &#34;Log in&#34; to allow desktop login (where our bot stays)&lt;/li&gt; &#xA; &lt;li&gt;Wait a few seconds and start chatting!&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;🤖 &lt;strong&gt;Enjoy your powerful chat bot!&lt;/strong&gt; 🤖&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;1.2 Deploy on Cloud&lt;/h3&gt; &#xA;&lt;p&gt;Click the button below to fork this repo and deploy with Railway!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://railway.app/new/template/zKIfYk?referralCode=D6wD0x&#34;&gt;&lt;img src=&#34;https://railway.app/button.svg?sanitize=true&#34; alt=&#34;Deploy on Railway&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;1.2.1 Configure on &lt;code&gt;Railway&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;p&gt;Fill in the following blanks:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Your forked repo name (can be any name you like)&lt;/li&gt; &#xA; &lt;li&gt;Choose make it private or not (also up to you)&lt;/li&gt; &#xA; &lt;li&gt;Environment variables (for how to get OpenAI API keys, please refer to &lt;a href=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/#111-get-your-openai-api-keys-for-chatgpt&#34;&gt;1.1.1 Get your OpenAI API keys for &lt;code&gt;ChatGPT&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/doc/img/Railway_config.png&#34; alt=&#34;Railway Config&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please note:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Make sure the environment variables are set in RailWay instead of writing directly in &lt;code&gt;config.yaml&lt;/code&gt;. It&#39;s really &lt;strong&gt;NOT&lt;/strong&gt; recommended to implicitly write out your &lt;code&gt;OpenAI API Key&lt;/code&gt; in public repo. Anyone with your key can get access to the OpenAI API services, and it&#39;s possbile for you to lose money if you pay for that.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;1.2.2 Deploy &amp;amp; Login on &lt;code&gt;Railway&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;p&gt;The deploy process is automatic. It may take a few minutes for the first time. As you see the &lt;code&gt;Success&lt;/code&gt;, click the tab to see the details. (which is your secret WeChat console!)&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/doc/img/Railway_deploy.png&#34; alt=&#34;Railway Deploy&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Click &lt;code&gt;Deply Logs&lt;/code&gt; and you will see everything is setting up, wait for a QR Code to pop up. Scan it as if you are login to your desktop WeChat, and click &#34;Log in&#34; on your mobile WeChat.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/doc/img/Railway_QRCode.png&#34; alt=&#34;Railway Scan QR Code&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Finally, everything is good to go! You will see the logs when people sending you messagem, and whenever the ChatGPT bot is auto-triggered to reply.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kx-Huang/ChatGPT-on-WeChat/master/doc/img/Railway_log.png&#34; alt=&#34;Railway Log&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;🤖 &lt;strong&gt;Enjoy your powerful chat bot!&lt;/strong&gt; 🤖&lt;/p&gt; &#xA;&lt;h2&gt;2. Any Fancy Advanced Settings?&lt;/h2&gt; &#xA;&lt;h3&gt;2.1 Config &lt;code&gt;ChatGPT&lt;/code&gt; Models&lt;/h3&gt; &#xA;&lt;p&gt;You can change whatever &lt;code&gt;ChatGPT&lt;/code&gt; Models you like to handle task at different capability &amp;amp; time-consumption trade-off. (e.g. model with better capability costs more time to respond)&lt;/p&gt; &#xA;&lt;p&gt;Currently, we use the latest &lt;code&gt;text-davinci-003&lt;/code&gt; model, which is:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Most capable GPT-3 model. Can do any task the other models can do, often with higher quality, longer output and better instruction-following. Also supports inserting completions within text.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Also, for the same model, we can configure dozens of parameter. (e.g. answer randomness, maximum word limit...)&lt;/p&gt; &#xA;&lt;p&gt;You can configure all of them in &lt;code&gt;src/chatgpt.js&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;const ChatGPTModelConfig = {&#xA;  // this model field is required&#xA;  model: &#34;text-davinci-003&#34;,&#xA;  // add your ChatGPT model parameters below&#xA;  temperature: 0.9,&#xA;  max_tokens: 2000,&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more details, please refer to &lt;a href=&#34;https://beta.openai.com/docs/models/overview&#34;&gt;OpenAI Models Doc&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;2.2 Config &lt;code&gt;ChatGPT&lt;/code&gt; Features&lt;/h3&gt; &#xA;&lt;p&gt;You can change whatever &lt;code&gt;ChatGPT&lt;/code&gt; features you like to handle different types of tasks. (e.g. complete text, edit text, generate image...)&lt;/p&gt; &#xA;&lt;p&gt;Currently, we use &lt;code&gt;createCompletion()&lt;/code&gt; to generate or manipulate text for daily usage, which:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Creates a completion for the provided prompt and parameters&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;You can configure in &lt;code&gt;src/chatgpt.js&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;const response = await this.OpenAI.createCompletion({&#xA;  ...ChatGPTModelConfig,&#xA;  prompt: inputMessage,&#xA;});&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Of course you can ask how to edit text in current mode, but the outcome may fall short of expectations.&lt;/p&gt; &#xA;&lt;p&gt;For more details, please refer to &lt;a href=&#34;https://beta.openai.com/docs/api-reference/introduction&#34;&gt;OpenAI API Doc&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;2.3 Config Auto Reply in Error&lt;/h3&gt; &#xA;&lt;p&gt;When &lt;code&gt;ChatGPT&lt;/code&gt; encounters some errors (e.g. over-crowded traffic, no authorization, ...), the chat bot will auto-reply the pre-configured message.&lt;/p&gt; &#xA;&lt;p&gt;You can change it in &lt;code&gt;src/chatgpt.js&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;const chatgptErrorMessage = &#34;🤖️：麦扣的机器人摆烂了，请稍后再试～&#34;;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;2.4 Add Customized Task Handler&lt;/h3&gt; &#xA;&lt;p&gt;You can add your own task handlers to expand the ability of this chat bot!&lt;/p&gt; &#xA;&lt;p&gt;Currently, add task handler in &lt;code&gt;src/main.ts&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;// e.g. if a message starts with &#34;Hello&#34;, the bot sends &#34;World!&#34;&#xA;if (message.text().startsWith(&#34;Hello&#34;)) {&#xA;  await message.say(&#34;World!&#34;);&#xA;  return;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Of course, stuffing all handlers in &lt;code&gt;main&lt;/code&gt; function is really a &lt;strong&gt;BAD&lt;/strong&gt; habit in coding. As a result, we will fix this in future updates to do logic separation.&lt;/p&gt; &#xA;&lt;h2&gt;3. How to Contribute to this Project?&lt;/h2&gt; &#xA;&lt;p&gt;You can raise some issues, fork this repo, commit your code, submit pull request, and after code review, we can merge your patch. I&#39;m really looking forward to develop more interesting features!&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>hmartiro/riffusion-app</title>
    <updated>2022-12-19T01:38:28Z</updated>
    <id>tag:github.com,2022-12-19:/hmartiro/riffusion-app</id>
    <link href="https://github.com/hmartiro/riffusion-app" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Stable diffusion for real-time music generation&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Riffusion App&lt;/h1&gt; &#xA;&lt;p&gt;Riffusion is an app for real-time music generation with stable diffusion.&lt;/p&gt; &#xA;&lt;p&gt;Read about it at &lt;a href=&#34;https://www.riffusion.com/about&#34;&gt;https://www.riffusion.com/about&lt;/a&gt; and try it at &lt;a href=&#34;https://www.riffusion.com/&#34;&gt;https://www.riffusion.com/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Web app: &lt;a href=&#34;https://github.com/hmartiro/riffusion-app&#34;&gt;https://github.com/hmartiro/riffusion-app&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Inference server: &lt;a href=&#34;https://github.com/hmartiro/riffusion-inference&#34;&gt;https://github.com/hmartiro/riffusion-inference&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Model checkpoint: &lt;a href=&#34;https://huggingface.co/riffusion/riffusion-model-v1&#34;&gt;https://huggingface.co/riffusion/riffusion-model-v1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Google Colab notebook: &lt;a href=&#34;https://colab.research.google.com/drive/1FhH3HlN8Ps_Pr9OR6Qcfbfz7utDvICl0?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Gradio Web Demo: &lt;a href=&#34;https://huggingface.co/spaces/fffiloni/spectrogram-to-music&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This repository contains the interactive web app that powers the website.&lt;/p&gt; &#xA;&lt;p&gt;It is built with Next.js, React, Typescript, three.js, Tailwind, and Vercel.&lt;/p&gt; &#xA;&lt;h2&gt;Run&lt;/h2&gt; &#xA;&lt;p&gt;This is a &lt;a href=&#34;https://nextjs.org/&#34;&gt;Next.js&lt;/a&gt; project bootstrapped with &lt;a href=&#34;https://github.com/vercel/next.js/tree/canary/packages/create-next-app&#34;&gt;&lt;code&gt;create-next-app&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Install:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the development server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run dev&#xA;# or&#xA;yarn dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt; with your browser to see the app.&lt;/p&gt; &#xA;&lt;p&gt;The app home is at &lt;code&gt;pages/index.js&lt;/code&gt;. The page auto-updates as you edit the file. The about page is at &lt;code&gt;pages/about.tsx&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;pages/api&lt;/code&gt; directory is mapped to &lt;code&gt;/api/*&lt;/code&gt;. Files in this directory are treated as &lt;a href=&#34;https://nextjs.org/docs/api-routes/introduction&#34;&gt;API routes&lt;/a&gt; instead of React pages.&lt;/p&gt; &#xA;&lt;h2&gt;Inference Server&lt;/h2&gt; &#xA;&lt;p&gt;To actually generate model outputs, we need a model backend that responds to inference requests via API. If you have a large GPU that can run stable diffusion in under five seconds, clone and run the instructions in the &lt;a href=&#34;https://github.com/hmartiro/riffusion-inference&#34;&gt;inference server&lt;/a&gt; to run the Flask app.&lt;/p&gt; &#xA;&lt;p&gt;This app also has a configuration to run with &lt;a href=&#34;https://www.baseten.co/&#34;&gt;Baseten&lt;/a&gt; for auto-scaling and load balancing. To use BaseTen, you need an API key.&lt;/p&gt; &#xA;&lt;p&gt;To configure these backends, add a &lt;code&gt;.env.local&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# URL to your flask instance&#xA;RIFFUSION_FLASK_URL=http://127.0.0.1:3013/run_inference/&#xA;&#xA;# Whether to use baseten as the model backend&#xA;NEXT_PUBLIC_RIFFUSION_USE_BASETEN=false&#xA;&#xA;# If using BaseTen, the URL and API key&#xA;RIFFUSION_BASETEN_URL=https://app.baseten.co/applications/XXX&#xA;RIFFUSION_BASETEN_API_KEY=XXX&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you build on this work, please cite it as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@software{Forsgren_Martiros_2022,&#xA;  author = {Forsgren, Seth* and Martiros, Hayk*},&#xA;  title = {{Riffusion - Stable diffusion for real-time music generation}},&#xA;  url = {https://riffusion.com/about},&#xA;  year = {2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>