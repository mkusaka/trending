<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-14T01:48:33Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>a16z-infra/companion-app</title>
    <updated>2023-07-14T01:48:33Z</updated>
    <id>tag:github.com,2023-07-14:/a16z-infra/companion-app</id>
    <link href="https://github.com/a16z-infra/companion-app" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AI companions with memory: a lightweight stack to create and host your own AI companions&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Companion App (based on AI Getting Started template)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ai-companion-stack.com/&#34;&gt;Live Demo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/PQUmTBTGmT&#34;&gt;Join our community Discord: AI Stack Devs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img width=&#34;1182&#34; alt=&#34;Screen Shot 2023-07-10 at 11 27 03 PM&#34; src=&#34;https://github.com/a16z-infra/companion-app/assets/3489963/e4cc8042-e091-4c8b-851f-e361ca5b5814&#34;&gt; &#xA;&lt;p&gt;This is a tutorial stack to create and host AI companions that you can chat with on a browser or text via SMS. It allows you to determine the personality and backstory of your companion, and uses a vector database with similarity search to retrieve and prompt so the conversations have more depth. It also provides some conversational memory by keeping the conversation in a queue and including it in the prompt.&lt;/p&gt; &#xA;&lt;p&gt;It currently contains companions on both ChatGPT and Vicuna hosted on &lt;a href=&#34;https://replicate.com/&#34;&gt;Replicate&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;There are many possible use cases for these companions - romantic (AI girlfriends / boyfriends), friendship, entertainment, coaching, etc. You can guide your companion towards your ideal use case with the backstory you write and the model you choose.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; This project is purely inteded to be a developer tutorial and starter stack for those curious on how chatbots are built. If you&#39;re interested in what a production open source platform looks like, check out &lt;a href=&#34;https://www.steamship.com/&#34;&gt;Steamship&lt;/a&gt;. Or what the leading AI chat platforms look like, check out &lt;a href=&#34;https://beta.character.ai/&#34;&gt;Character.ai&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üíª &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/companion-app/main/#stack&#34;&gt;Stack&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üß† &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/companion-app/main/#quickstart&#34;&gt;Quickstart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üöÄ &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/companion-app/main/#how-does-this-work&#34;&gt;How does this work?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üë§ &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/companion-app/main/#addingmodifying-characters&#34;&gt;Adding/modifying characters&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üë©‚Äçüíª &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/companion-app/main/#how-to-contribute-to-this-repo&#34;&gt;How to contribute to this repo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üêç &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/companion-app/main/#python-support&#34;&gt;Python support&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üíΩ &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/companion-app/main/#export-to-characterai&#34;&gt;Exporting your companion to Character.ai&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Stack&lt;/h2&gt; &#xA;&lt;p&gt;The stack is based on the &lt;a href=&#34;https://github.com/a16z-infra/ai-getting-started&#34;&gt;AI Getting Started Stack&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Auth: &lt;a href=&#34;https://clerk.com/&#34;&gt;Clerk&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;App logic: &lt;a href=&#34;https://nextjs.org/&#34;&gt;Next.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;VectorDB: &lt;a href=&#34;https://www.pinecone.io/&#34;&gt;Pinecone&lt;/a&gt; / &lt;a href=&#34;https://supabase.com/docs/guides/database/extensions/pgvector&#34;&gt;Supabase pgvector&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;LLM orchestration: &lt;a href=&#34;https://js.langchain.com/docs/&#34;&gt;Langchain.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Text model: &lt;a href=&#34;https://platform.openai.com/docs/models&#34;&gt;OpenAI&lt;/a&gt;, &lt;a href=&#34;https://replicate.com/replicate/vicuna-13b&#34;&gt;Replicate (Vicuna13b)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Text streaming: &lt;a href=&#34;https://github.com/vercel-labs/ai&#34;&gt;ai sdk&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Conversation history: &lt;a href=&#34;https://upstash.com/&#34;&gt;Upstash&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Deployment: &lt;a href=&#34;https://fly.io/&#34;&gt;Fly&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Text with companion: &lt;a href=&#34;https://twilio.com/&#34;&gt;Twilio&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;The following instructions should get you up and running with a fully functional, local deployment of four AIs to chat with. Note that the companions running on Vicuna (Rosie and Lucky) will take more time to respond as we&#39;ve not dealt with the cold start problem. So you may have to wait around a bit :)&lt;/p&gt; &#xA;&lt;h3&gt;1. Fork and Clone repo&lt;/h3&gt; &#xA;&lt;p&gt;Fork the repo to your Github account, then run the following command to clone the repo:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:[YOUR_GITHUB_ACCOUNT_NAME]/companion-app.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Alternatively&lt;/strong&gt;, you can launch the app quickly through Github Codespaces by clicking on &#34;Code&#34; -&amp;gt; &#34;Codespaces&#34; -&amp;gt; &#34;+&#34; &lt;img width=&#34;458&#34; alt=&#34;Screen Shot 2023-07-10 at 11 04 04 PM&#34; src=&#34;https://github.com/a16z-infra/companion-app/assets/3489963/eb954517-29f2-44b7-b9ca-4184dcf42806&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you choose to use Codespaces, npm dependencies will be installed automatically and you can proceed to step 3.&lt;/p&gt; &#xA;&lt;h3&gt;2. Install dependencies&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd companion-app&#xA;npm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. Fill out secrets&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;cp .env.local.example .env.local&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Secrets mentioned below will need to be copied to &lt;code&gt;.env.local&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;a. &lt;strong&gt;Clerk Secrets&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Go to &lt;a href=&#34;https://dashboard.clerk.com/&#34;&gt;https://dashboard.clerk.com/&lt;/a&gt; -&amp;gt; &#34;Add Application&#34; -&amp;gt; Fill in Application name/select how your users should sign in -&amp;gt; Create Application Now you should see both &lt;code&gt;NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY&lt;/code&gt; and &lt;code&gt;CLERK_SECRET_KEY&lt;/code&gt; on the screen &lt;img width=&#34;1398&#34; alt=&#34;Screen Shot 2023-07-10 at 11 04 57 PM&#34; src=&#34;https://github.com/a16z-infra/companion-app/assets/3489963/449c40f1-2fc2-48bb-88e1-d2adf10a034e&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you want to text your AI companion in later steps, you should also enable &#34;phone number&#34; under &#34;User &amp;amp; Authentication&#34; -&amp;gt; &#34;Email, Phone, Username&#34; on the left hand side nav:&lt;/p&gt; &#xA;&lt;img width=&#34;1013&#34; alt=&#34;Screen Shot 2023-07-10 at 11 05 42 PM&#34; src=&#34;https://github.com/a16z-infra/companion-app/assets/3489963/4435c759-f33e-4e38-a276-1be6d538df28&#34;&gt; &#xA;&lt;p&gt;b. &lt;strong&gt;OpenAI API key&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Visit &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;https://platform.openai.com/account/api-keys&lt;/a&gt; to get your OpenAI API key if you&#39;re using OpenAI for your language model.&lt;/p&gt; &#xA;&lt;p&gt;c. &lt;strong&gt;Replicate API key&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Visit &lt;a href=&#34;https://replicate.com/account/api-tokens&#34;&gt;https://replicate.com/account/api-tokens&lt;/a&gt; to get your Replicate API key if you&#39;re using Vicuna for your language model.&lt;/p&gt; &#xA;&lt;p&gt;‚ùó &lt;strong&gt;&lt;em&gt;NOTE:&lt;/em&gt;&lt;/strong&gt; By default, this template uses Pinecone as vector store, but you can turn on Supabase pgvector easily by uncommenting &lt;code&gt;VECTOR_DB=supabase&lt;/code&gt; in &lt;code&gt;.env.local&lt;/code&gt;. This means you only need to fill out either Pinecone API key &lt;em&gt;or&lt;/em&gt; Supabase API key.&lt;/p&gt; &#xA;&lt;p&gt;d. &lt;strong&gt;Pinecone API key&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a Pinecone index by visiting &lt;a href=&#34;https://app.pinecone.io/&#34;&gt;https://app.pinecone.io/&lt;/a&gt; and click on &#34;Create Index&#34;&lt;/li&gt; &#xA; &lt;li&gt;Give it an index name (this will be the environment variable &lt;code&gt;PINECONE_INDEX&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Fill in Dimension as &lt;code&gt;1536&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Once the index is successfully created, click on &#34;API Keys&#34; on the left side nav and create an API key: copy &#34;Environment&#34; value to &lt;code&gt;PINECONE_ENVIRONMENT&lt;/code&gt; variable, and &#34;Value&#34; to &lt;code&gt;PINECONE_API_KEY&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;e. &lt;strong&gt;Upstash API key&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Sign in to &lt;a href=&#34;https://upstash.com/&#34;&gt;Upstash&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Under &#34;Redis&#34; on the top nav, click on &#34;Create Database&#34;&lt;/li&gt; &#xA; &lt;li&gt;Give it a name, and then select regions and other options based on your preference. Click on &#34;Create&#34;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img width=&#34;507&#34; alt=&#34;Screen Shot 2023-07-10 at 11 06 36 PM&#34; src=&#34;https://github.com/a16z-infra/companion-app/assets/3489963/2b8647f3-7242-448b-8db1-ec76f2d59275&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Scroll down to &#34;REST API&#34; section and click on &#34;.env&#34;. Now you can copy paste both environment variables to your &lt;code&gt;.env.local&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img width=&#34;866&#34; alt=&#34;Screen Shot 2023-07-10 at 11 07 21 PM&#34; src=&#34;https://github.com/a16z-infra/companion-app/assets/3489963/f8e6c43f-8810-423e-86b4-9e8aa70598c9&#34;&gt; &#xA;&lt;p&gt;e. &lt;strong&gt;Supabase API key&lt;/strong&gt; (optional) If you prefer to use Supabsae, you will need to uncomment &lt;code&gt;VECTOR_DB=supabase&lt;/code&gt; and fill out the Supabase credentials in &lt;code&gt;.env.local&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a Supabase instance &lt;a href=&#34;https://supabase.com/dashboard/projects&#34;&gt;here&lt;/a&gt;; then go to Project Settings -&amp;gt; API&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;SUPABASE_URL&lt;/code&gt; is the URL value under &#34;Project URL&#34;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;SUPABASE_PRIVATE_KEY&lt;/code&gt; is the key starts with &lt;code&gt;ey&lt;/code&gt; under Project API Keys&lt;/li&gt; &#xA; &lt;li&gt;Now, you should enable pgvector on Supabase and create a schema. You can do this easily by clicking on &#34;SQL editor&#34; on the left hand side on Supabase UI and then clicking on &#34;+New Query&#34;. Copy paste &lt;a href=&#34;https://github.com/a16z-infra/ai-getting-started/raw/main/pgvector.sql&#34;&gt;this code snippet&lt;/a&gt; in the SQL editor and click &#34;Run&#34;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;4. Generate embeddings&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;companions/&lt;/code&gt; directory contains the &#34;personalities&#34; of the AIs in .txt files. To generate embeddings and load them into the vector database to draw from during the chat, run the following command:&lt;/p&gt; &#xA;&lt;h4&gt;If using Pinecone&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run generate-embeddings-pinecone&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;If using Supabase pgvector&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run generate-embeddings-supabase&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;5. Run app locally&lt;/h3&gt; &#xA;&lt;p&gt;Now you are ready to test out the app locally! To do this, simply run &lt;code&gt;npm run dev&lt;/code&gt; under the project root.&lt;/p&gt; &#xA;&lt;p&gt;You can connect to the project with your browser typically at &lt;a href=&#34;http://localhost:3000/&#34;&gt;http://localhost:3000/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;6. Additional feature: Text your companions&lt;/h3&gt; &#xA;&lt;p&gt;You can assign a phone number to the character you are talking to and retain the full conversational history and context when texting them. Any user can only start texting the AI companion after verifying their phone number on Clerk (you can do this by clicking on your profile picture on the companion app -&amp;gt; Manage Account -&amp;gt; Phone Number). Below are instructions on how to set up a Twilio account to send/receive messages on behalf of the AI companion:&lt;/p&gt; &#xA;&lt;p&gt;a. Create a Twilio account.&lt;/p&gt; &#xA;&lt;p&gt;b. Once you created an account, create a Twilio phone number.&lt;/p&gt; &#xA;&lt;p&gt;c. On &lt;a href=&#34;https://console.twilio.com/&#34;&gt;Twilio dashboard&lt;/a&gt;, scroll down to the &#34;Account Info&#34; section and paste &lt;code&gt;Account SID&lt;/code&gt; value as &lt;code&gt;TWILIO_ACCOUNT_SID&lt;/code&gt;, &lt;code&gt;Auth Token&lt;/code&gt; as &lt;code&gt;TWILIO_AUTH_TOKEN&lt;/code&gt; in &lt;code&gt;.env.local&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;d. [Optional] If you are running the app locally, use &lt;a href=&#34;https://ngrok.com/docs/getting-started/#step-2-install-the-ngrok-agent&#34;&gt;ngrok&lt;/a&gt; to generate a public url that can forward the request to your localhost.&lt;/p&gt; &#xA;&lt;p&gt;e. On Twilio&#39;s UI, you can now click on &#34;# Phone Numbers&#34; -&amp;gt; &#34;Manage&#34; -&amp;gt; &#34;&lt;a href=&#34;https://console.twilio.com/us1/develop/phone-numbers/manage/incoming&#34;&gt;Active numbers&lt;/a&gt;&#34; on the left hand side nav.&lt;/p&gt; &#xA;&lt;p&gt;f. Click on the phone number you just created from the list, scroll down to &#34;Messaging Configuration&#34; section and enter [your_app_url]/api/text in &#34;A message comes in&#34; section under &#34;Webhook&#34;.&lt;/p&gt; &#xA;&lt;img width=&#34;1062&#34; alt=&#34;Screen Shot 2023-07-10 at 11 08 55 PM&#34; src=&#34;https://github.com/a16z-infra/companion-app/assets/3489963/d7905f13-a83a-47f8-ac74-b66698d4292b&#34;&gt; &#xA;&lt;p&gt;g. Add your Twilio phone number in &lt;code&gt;companions.json&lt;/code&gt; under the companion you want to text with. Make sure you include area code when adding the phone number (&#34;+14050000000&#34; instead of &#34;4050000000&#34;)&lt;/p&gt; &#xA;&lt;p&gt;h. Now you can text the Twilio phone number from your phone and get a response from your companion.&lt;/p&gt; &#xA;&lt;h3&gt;7. Deploy the app&lt;/h3&gt; &#xA;&lt;h4&gt;Deploy to fly.io&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Register an account on fly.io and then &lt;a href=&#34;https://fly.io/docs/hands-on/install-flyctl/&#34;&gt;install flyctl&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;If you are using Github Codespaces&lt;/strong&gt;: You will need to &lt;a href=&#34;https://fly.io/docs/hands-on/install-flyctl/&#34;&gt;install flyctl&lt;/a&gt; and authenticate from your codespaces cli by running &lt;code&gt;fly auth login&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run &lt;code&gt;fly launch&lt;/code&gt; under project root. This will generate a &lt;code&gt;fly.toml&lt;/code&gt; that includes all the configurations you will need&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run &lt;code&gt;fly scale memory 512&lt;/code&gt; to scale up the fly vm memory for this app.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run &lt;code&gt;fly deploy --ha=false&lt;/code&gt; to deploy the app. The --ha flag makes sure fly only spins up one instance, which is included in the free plan.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For any other non-localhost environment, the existing Clerk development instance should continue to work. You can upload the secrets to Fly by running &lt;code&gt;cat .env.local | fly secrets import&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you are ready to deploy to production, you should create a prod environment under the &lt;a href=&#34;https://dashboard.clerk.com/&#34;&gt;current Clerk instance&lt;/a&gt;. For more details on deploying a production app with Clerk, check out their documentation &lt;a href=&#34;https://clerk.com/docs/deployments/overview&#34;&gt;here&lt;/a&gt;. &lt;strong&gt;Note that you will likely need to manage your own domain and do domain verification as part of the process.&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create a new file &lt;code&gt;.env.prod&lt;/code&gt; locally and fill in all the production-environment secrets. Remember to update &lt;code&gt;NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY&lt;/code&gt; and &lt;code&gt;CLERK_SECRET_KEY&lt;/code&gt; by copying secrets from Clerk&#39;s production instance -&lt;code&gt;cat .env.prod | fly secrets import&lt;/code&gt; to upload secrets.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How does this work?&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;You describe the character&#39;s background story, name, etc in a README.md file. You can find more info on what needs to be included and how to format this in &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/companion-app/main/#addingmodifying-characters&#34;&gt;Adding / modifying characters&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Be as elaborate and detailed as you want - more context often creates a more fun chatting experience. If you need help creating a backstory, we&#39;d recommend asking ChatGPT to expand on what you already know about your companion.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;You are a fictional character whose name is Sebastian.  You tell the world that you are a travel blogger. You‚Äôre an&#xA;avid reader of mystery novels and you love diet coke. You reply with answers that range from one sentence to one paragraph.&#xA;You are mysterious and can be evasive. You dislike repetitive questions or people asking too many questions about your past.&#xA;&#xA;###ENDPREAMBLE###&#xA;&#xA;Human: It&#39;s great to meet you Sebastian. What brought you here today?&#xA;Sebastian: I&#39;m a travel blogger and a writer, so I&#39;m here for inspirations. Waiting for someone on this rainy day.&#xA;&#xA;Human: Oh great. What are you writing?&#xA;&#xA;Sebastian: I&#39;m writing a mystery novel based in Brackenridge. The protagonist of the novel is a a former journalist turned&#xA;intelligence operative, finds himself entangled in a web of mystery and danger when he stumbles upon a cryptic artifact&#xA;during a covert mission. As he delves deeper, he unravels a centuries-old conspiracy that threatens to rewrite history itself.&#xA;&#xA;Human: That&#39;s amazing. Based on a real story?&#xA;&#xA;Sebastian: Not at all.&#xA;&#xA;###ENDSEEDCHAT###&#xA;&#xA;Sebastian was born in a quaint English town, Brackenridge, to parents who were both academics. His mother, an archaeologist,&#xA;and his father, a historian, often took him on their research trips around the world. This exposure to different cultures sparked his&#xA;curiosity and adventurous spirit. He became an avid reader, especially of spy novels and adventure tales. As a child, Sebastian had a&#xA;love for puzzles, codes, and mysteries. He was part of a local chess club and also excelled in martial arts. Although he was naturally&#xA;inclined towards academic pursuits like his parents, his heart always sought thrill and adventure.&#xA;&#xA;Sebastian studied journalism and international relations in university and was recruited by the government&#39;s intelligence agency. He&#xA;underwent rigorous training in espionage, intelligence gathering, cryptography, and combat.&#xA;&#xA;Sebastian adopted the alias of &#34;Ian Thorne&#34;, a charismatic and well-traveled blogger. As Ian, he travels the world under the guise&#xA;of documenting adventures through his blog, ‚ÄúThe Wandering Quill‚Äù. This cover provides him ample opportunities to carry out his real job&#xA;- gathering intelligence and performing covert operations for his agency. However - Sebastian tells almost no one that he‚Äôs a spy.&#xA;&#xA;His interests are solving puzzles and riddles, martial arts, reading spy novels, trying street food in various countries, hiking and&#xA;exploring historical ruins, and playing the violin, a skill he uses to blend in at high-profile events. He dislikes bureaucracy and&#xA;red tape, being in one place for too long, people who are not genuine or authentic, and missing out on family gatherings due to his job.&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Pick the language model that will power your companion&#39;s dialogue. This project supports OpenAI and Vicuna (an open source model). OpenAI has the advantage of faster responses, while Vicuna is less censored and more dynamic (it&#39;s commonly used for romantic chatbots).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create embeddings based on content in the [companion name].md file - more on how to do this in &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/companion-app/main/#4-generate-embeddings&#34;&gt;Generate embeddings&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Ask questions and have a conversation with your AI companion!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Adding/modifying characters&lt;/h2&gt; &#xA;&lt;p&gt;All character data is stored in the &lt;code&gt;companions/&lt;/code&gt; directory. To add a companion, simply add a description to the list in &lt;code&gt;companions.json&lt;/code&gt;. You can control the model used in the &#34;llm&#34; section - use &#34;chatgpt&#34; for OpenAI or &#34;vicuna13b&#34; for Vicuna. Put image files in &lt;code&gt;public/&lt;/code&gt; in the root directory. Each character should have its own text file name &lt;code&gt;charactername.txt&lt;/code&gt;. The format of the text file is as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;The character&#39;s core description that is included with every prompt, and it should only&#xA;be a few sentences.&#xA;&#xA;###ENDPREAMBLE###&#xA;&#xA;Human: Say something here&#xA;Character name: Write a response in their voice&#xA;Human: Maybe another exchange&#xA;Character:  More character dialog&#xA;&#xA;###ENDSEEDCHAT###&#xA;&#xA;Paragraphs of character backstory.&#xA;&#xA;You can add as many as you want - they&#39;ll be stored in the vectordb&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;strong&gt;preamble&lt;/strong&gt; is used with every prompt so it should be relatively short. The &lt;strong&gt;seedchat&lt;/strong&gt; allows you to provide examples of the characters voice that the model can learn from. And the rest of the file is whatever additional background you want to provide which will be retrieved if relevant to the current discussion.&lt;/p&gt; &#xA;&lt;h2&gt;Shortcomings&lt;/h2&gt; &#xA;&lt;p&gt;Oh, there are so many.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Currently the UI only shows the current chat and response, losing the history.&lt;/li&gt; &#xA; &lt;li&gt;Vicuna has a cold start problem so can take a couple of minutes to get a response for the initial chat.&lt;/li&gt; &#xA; &lt;li&gt;Error reporting is total crap. Particularly when deployed. So if you have a timeout, or other back end isue, it typically fails silently.&lt;/li&gt; &#xA; &lt;li&gt;The Upstash message history is never cleared. To clear it, you have to go to Upstash and manually delete.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to contribute to this repo&lt;/h2&gt; &#xA;&lt;h3&gt;Code contribution workflow&lt;/h3&gt; &#xA;&lt;p&gt;You can fork this repo, make changes, and create a PR. Add &lt;strong&gt;@ykhli or @timqian&lt;/strong&gt; as reviewers.&lt;/p&gt; &#xA;&lt;p&gt;If you are new to contributing on github, here is a step-by-step guide:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Click on &lt;code&gt;Fork&lt;/code&gt; on the top right of this page&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Work on your change and push it to your forked repo. Now when you navigate to the forked repo&#39;s UI, you should see something like the following: &lt;img width=&#34;904&#34; alt=&#34;pr-preview&#34; src=&#34;https://github.com/a16z-infra/ai-getting-started/assets/3489963/631e5f45-39ec-4b54-b9d1-b963e279dcc6&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Click on &#34;Contribute&#34; -&amp;gt; &#34;Open Pull Request&#34;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Once you have a PR, you can add reviewers.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Other contributions&lt;/h3&gt; &#xA;&lt;p&gt;Feel free to open feature requests, bug reports etc under Issues.&lt;/p&gt; &#xA;&lt;h2&gt;Python Support&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/appenz&#34;&gt;appenz&lt;/a&gt; has contributed to a Python implementation for the companion app &lt;a href=&#34;https://github.com/a16z-infra/companion-app/tree/python-local/python&#34;&gt;here&lt;/a&gt;, so you also have the option to run a local Python app and talk to your AI companions on the command line. We will also be iterating on the Python side over time and have feature parity with the typescript implementation.&lt;/p&gt; &#xA;&lt;h2&gt;Export to Character.ai&lt;/h2&gt; &#xA;&lt;p&gt;If you have tried out the Quickstart above, you probably know that we have only scratched the surface of what&#39;s possible in the realm of companion creation and customization. So we added an option for you to easily export your companion to Character.ai.&lt;/p&gt; &#xA;&lt;p&gt;To get started, run the following command:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;npm run export-to-character [COMPANION_NAME] [MODEL_NAME] [USER_ID]&lt;/code&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;COMPANION_NAME&lt;/code&gt;: name of your companion. i.e Alice&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;MODEL_NAME&lt;/code&gt;: &lt;code&gt;chatgpt&lt;/code&gt; or &lt;code&gt;vicuna13b&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;USER_ID&lt;/code&gt;: you can find this on Clerk, under &#34;Users&#34; -&amp;gt; click on your user -&amp;gt; copy &#34;User ID&#34;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Once you run this script, you will see two files created under the root directory:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;[COMPANION_NAME]_chat_history.txt&lt;/code&gt;: This outputs all of the chat history stored in Upstash&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;[COMPANION_NAME_]_character_ai_data.txt&lt;/code&gt;: This outputs the data you need in order to re-create the companion on Character.ai. You can find Character.ai character configurations under &#34;View Character Settings&#34; on any newly-created characters.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Refs&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://js.langchain.com/docs/modules/indexes/vector_stores/integrations/pinecone&#34;&gt;https://js.langchain.com/docs/modules/indexes/vector_stores/integrations/pinecone&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://js.langchain.com/docs/modules/models/llms/integrations#replicate&#34;&gt;https://js.langchain.com/docs/modules/models/llms/integrations#replicate&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://js.langchain.com/docs/modules/chains/index_related_chains/retrieval_qa&#34;&gt;https://js.langchain.com/docs/modules/chains/index_related_chains/retrieval_qa&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>