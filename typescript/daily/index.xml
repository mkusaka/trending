<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-11T02:44:09Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>SawyerHood/draw-a-ui</title>
    <updated>2023-11-11T02:44:09Z</updated>
    <id>tag:github.com,2023-11-11:/SawyerHood/draw-a-ui</id>
    <link href="https://github.com/SawyerHood/draw-a-ui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Draw a mockup and generate html for it&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;draw-a-ui&lt;/h1&gt; &#xA;&lt;p&gt;This is an app that uses tldraw and the gpt-4-vision api to generate html based on a wireframe you draw.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/SawyerHood/draw-a-ui/main/demo.gif&#34; alt=&#34;A demo of the app&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This works by just taking the current canvas SVG, converting it to a PNG, and sending that png to gpt-4-vision with instructions to return a single html file with tailwind.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Disclaimer: This is a demo and is not intended for production use. It doesn&#39;t have any auth so you will go broke if you deploy it.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;This is a Next.js app. To get started run the following commands in the root directory of the project. You will need an OpenAI API key with access to the GPT-4 Vision API.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo &#34;OPENAI_API_KEY=sk-your-key&#34; &amp;gt; .env.local&#xA;npm install&#xA;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt; with your browser to see the result.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>nftblackmagic/GptAssist-starter</title>
    <updated>2023-11-11T02:44:09Z</updated>
    <id>tag:github.com,2023-11-11:/nftblackmagic/GptAssist-starter</id>
    <link href="https://github.com/nftblackmagic/GptAssist-starter" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Welcome to OpenAI Starter!&lt;/h2&gt; &#xA;&lt;p&gt;This repository is designed as a NEXTJS starter kit for anyone looking to get up to speed with the latest features offered by OpenAI. Whether you&#39;re a developer, researcher, or just an AI enthusiast, this space is curated to help you understand and experiment with OpenAI&#39;s cutting-edge advancements.&lt;/p&gt; &#xA;&lt;h2&gt;What&#39;s Inside?&lt;/h2&gt; &#xA;&lt;p&gt;Within this repository, you&#39;ll find a collection of resources, code snippets, and tutorials that demystify OpenAI&#39;s newest features. We aim to provide a hands-on approach to learning, enabling you to:&lt;/p&gt; &#xA;&lt;h3&gt;Roadmap&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; ask and answer chat with gpt4-turbo/gpt4-V (useGPT)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; chatbot with gpt4-turbo/gpt4-V&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; assistants api (useMessage, useRun, useThread)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; TTS and whisper (useAudio)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; dall-e 3&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; streaming output&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To begin, simply clone this repository, and follow the installation instructions. You&#39;ll be running your first experiments in no time!&lt;/p&gt; &#xA;&lt;h3&gt;create .env.local file and add your openai api key&lt;/h3&gt; &#xA;&lt;p&gt;First, run the development server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run dev&#xA;# or&#xA;yarn dev&#xA;# or&#xA;pnpm dev&#xA;# or&#xA;bun dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt; with your browser to see the result.&lt;/p&gt; &#xA;&lt;p&gt;You can start editing the page by modifying &lt;code&gt;pages/index.tsx&lt;/code&gt;. The page auto-updates as you edit the file.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;pages/api&lt;/code&gt; directory is mapped to &lt;code&gt;/api/*&lt;/code&gt;. Files in this directory are treated as &lt;a href=&#34;https://nextjs.org/docs/api-routes/introduction&#34;&gt;API routes&lt;/a&gt; instead of React pages.&lt;/p&gt; &#xA;&lt;p&gt;This project uses &lt;a href=&#34;https://nextjs.org/docs/basic-features/font-optimization&#34;&gt;&lt;code&gt;next/font&lt;/code&gt;&lt;/a&gt; to automatically optimize and load Inter, a custom Google Font.&lt;/p&gt; &#xA;&lt;h2&gt;Learn More&lt;/h2&gt; &#xA;&lt;p&gt;To learn more about Next.js, take a look at the following resources:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nextjs.org/docs&#34;&gt;Next.js Documentation&lt;/a&gt; - learn about Next.js features and API.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nextjs.org/learn&#34;&gt;Learn Next.js&lt;/a&gt; - an interactive Next.js tutorial.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://platform.openai.com/docs/api-reference/introduction&#34;&gt;OPENAI api&lt;/a&gt; - openai tutorial.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions from the community! If you have suggestions, bug reports, or contributions, please open an issue or pull request.&lt;/p&gt; &#xA;&lt;p&gt;Join us in demystifying the power of AI and making it accessible to all. Happy exploring!&lt;/p&gt;</summary>
  </entry>
</feed>