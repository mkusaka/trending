<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-13T01:46:09Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>lumalabs/luma-web-examples</title>
    <updated>2023-12-13T01:46:09Z</updated>
    <id>tag:github.com,2023-12-13:/lumalabs/luma-web-examples</id>
    <link href="https://github.com/lumalabs/luma-web-examples" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Luma Web Examples, use lumalabs.ai captures directly in your three.js or other WebGL projects!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href=&#34;https://lumalabs.ai&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/assets/logo.svg?sanitize=true&#34; alt=&#34;luma-logo&#34;&gt;&lt;/a&gt; Luma WebGL Library&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;luma-web&lt;/code&gt; is a &lt;a href=&#34;https://www.npmjs.com/package/@lumaai/luma-web&#34;&gt;npm package&lt;/a&gt; for rendering photoreal interactive scenes captured by the &lt;a href=&#34;https://lumalabs.ai/&#34;&gt;Luma app&lt;/a&gt;. It includes &lt;code&gt;LumaSplatsWebGL&lt;/code&gt;, which is a WebGL-only gaussian splatting implementation designed to be integrated with 3D frameworks, and &lt;code&gt;LumaSplatsThree&lt;/code&gt;, which is a Three.js implementation that uses &lt;code&gt;LumaSplatsWebGL&lt;/code&gt; under the hood. For these examples we&#39;ll use &lt;a href=&#34;https://threejs.org/&#34;&gt;Three.js&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Request features and report bugs on our &lt;a href=&#34;https://github.com/lumalabs/luma-web-library&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/assets/images/github-mark-16.svg?sanitize=true&#34; alt=&#34;github-logo&#34;&gt; GitHub repo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Contents&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#getting-started&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#background-removal&#34;&gt;Background Removal&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#three-fog&#34;&gt;Three Fog&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#scene-lighting&#34;&gt;Scene Lighting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#custom-shaders&#34;&gt;Custom Shaders&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#react-three-fiber&#34;&gt;React Three Fiber&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#transmission&#34;&gt;Transmission&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#vr&#34;&gt;VR&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#getting-started&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/assets/images/hello-world-preview.jpg&#34; alt=&#34;hello-world-demo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;To get started, install the package:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install @lumaai/luma-web&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And import the &lt;code&gt;LumaSplatsThree&lt;/code&gt; class:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ts&#34;&gt;import { LumaSplatsThree } from &#34;@lumaai/luma-web&#34;;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or if using a browser, include the script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;script src=&#34;https://unpkg.com/@lumaai/luma-web&#34;&amp;gt;&amp;lt;/script&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then in your code, import the &lt;code&gt;LumaSplatsThree&lt;/code&gt; class, create an instance with a source, and add it to your scene.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;source&lt;/code&gt; can be either of:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;URL to a capture on &lt;a href=&#34;https://lumalabs.ai&#34;&gt;lumalabs.ai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;path to a luma splats file or folder containing a luma splats artifacts&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/src/DemoHelloWorld.ts&#34;&gt;DemoHelloWorld.ts&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ts&#34;&gt;let splats = new LumaSplatsThree({&#xA;&#x9;source: &#39;https://lumalabs.ai/capture/ca9ea966-ca24-4ec1-ab0f-af665cb546ff&#39;,&#xA;});&#xA;&#xA;scene.add(splats);&#xA;&#xA;scene.add(createText());&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Splats will integrate with the three.js rendering pipeline and interact with other objects via depth testing. However, splats do not currently write to the depth buffer themselves.&lt;/p&gt; &#xA;&lt;h3&gt;Performance tips&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use &lt;code&gt;antialias: false&lt;/code&gt; when creating the renderer to disable MSAA on the canvas. Splats are already anti-aliased and the high instance count in splats is expensive to render with MSAA&lt;/li&gt; &#xA; &lt;li&gt;Set &lt;code&gt;enableThreeShaderIntegration: false&lt;/code&gt; to disable integration with the three.js rendering pipeline. This will disable features like fog and tone mapping, but will improve performance&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Background Removal&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#background-removal&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/assets/images/background-removal-preview.jpg&#34; alt=&#34;background-removal-demo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Luma scenes can include multiple semantic layers. By default, all layers are rendered. To filter layers, use the &lt;code&gt;semanticsMask&lt;/code&gt; property. This is a bit mask, so for example, to show only the foreground layer, set &lt;code&gt;semanticsMask = LumaSplatsSemantics.FOREGROUND&lt;/code&gt;. To show both foreground and background, set &lt;code&gt;semanticsMask = LumaSplatsSemantics.FOREGROUND | LumaSplatsSemantics.BACKGROUND&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/src/DemoBackgroundRemoval.ts&#34;&gt;DemoBackgroundRemoval.ts&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ts&#34;&gt;import { LumaSplatsSemantics, LumaSplatsThree } from &#34;@lumaai/luma-web&#34;;&#xA;&#xA;let splats = new LumaSplatsThree({&#xA;&#x9;source: &#39;https://lumalabs.ai/capture/1b5f3e33-3900-4398-8795-b585ae13fd2d&#39;,&#xA;});&#xA;&#xA;scene.add(splats);&#xA;&#xA;// filter splats to only show foreground layers&#xA;splats.semanticsMask = LumaSplatsSemantics.FOREGROUND;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Three Fog&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#three-fog&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/assets/images/three.js-fog-preview.jpg&#34; alt=&#34;three.js-fog-demo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Luma splats integrate with the three.js rendering pipeline including features like tone mapping, color spaces and fog. Ensure &lt;code&gt;enableThreeShaderIntegration&lt;/code&gt; is set to &lt;code&gt;true&lt;/code&gt; (the default) and set the scene fog&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/src/DemoFog.ts&#34;&gt;DemoFog.ts&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ts&#34;&gt;scene.fog = new FogExp2(new Color(0xe0e1ff).convertLinearToSRGB(), 0.15);&#xA;scene.background = scene.fog.color;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Scene Lighting&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#scene-lighting&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/assets/images/scene-lighting-preview.jpg&#34; alt=&#34;scene-lighting-demo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s possible to illuminate three.js scenes with Luma splats. To do so, we can render a cubemap of the splats and use it as the scene environment. This is done by calling &lt;code&gt;captureCubemap()&lt;/code&gt; on the splats object. We first wait for the splats to fully load before capturing the cubemap. To ensure the splats are fully rendered at the time of capture, we disable the loading animation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/src/DemoLighting.ts&#34;&gt;DemoLighting.ts&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ts&#34;&gt;let splats = new LumaSplatsThree({&#xA;&#x9;source: &#39;https://lumalabs.ai/capture/4da7cf32-865a-4515-8cb9-9dfc574c90c2&#39;,&#xA;&#xA;&#x9;// disable loading animation so model is fully rendered after onLoad&#xA;&#x9;loadingAnimationEnabled: false,&#xA;});&#xA;&#xA;splats.onLoad = () =&amp;gt; {&#xA;&#x9;splats.captureCubemap(renderer).then((capturedTexture) =&amp;gt; {&#xA;&#x9;&#x9;scene.environment = capturedTexture;&#xA;&#x9;&#x9;scene.background = capturedTexture;&#xA;&#x9;&#x9;scene.backgroundBlurriness = 0.5;&#xA;&#x9;});&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Custom Shaders&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#custom-shaders&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/assets/images/custom-shaders-preview.jpg&#34; alt=&#34;custom-shaders-demo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can inject code into the splat shaders to customize them. To do this, call &lt;code&gt;setShaderHooks({ ... })&lt;/code&gt; on your splat and provide GLSL functions, uniforms and globals to override default behavior. For example, in this demo we apply a transform matrix to each splat by setting the vertex shader hook &lt;code&gt;getSplatTransform&lt;/code&gt;. It generates a transform matrix for time-varying sinusoidal offset to the y coordinate.&lt;/p&gt; &#xA;&lt;p&gt;The syntax for shader hook function is a GLSL function without a function name. The GLSL function arguments and return are given as documentation on the shader hook fields (see below).&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/src/DemoCustomShaders.ts&#34;&gt;DemoCustomShaders.ts&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ts&#34;&gt;splats.setShaderHooks({&#xA;&#x9;vertexShaderHooks: {&#xA;&#x9;&#x9;additionalUniforms: {&#xA;&#x9;&#x9;&#x9;time_s: [&#39;float&#39;, uniformTime],&#xA;&#x9;&#x9;},&#xA;&#xA;&#x9;&#x9;getSplatTransform: /*glsl*/`&#xA;&#x9;&#x9;&#x9;(vec3 position, uint layersBitmask) {&#xA;&#x9;&#x9;&#x9;&#x9;// sin wave on x-axis&#xA;&#x9;&#x9;&#x9;&#x9;float x = 0.;&#xA;&#x9;&#x9;&#x9;&#x9;float z = 0.;&#xA;&#x9;&#x9;&#x9;&#x9;float y = sin(position.x * 1.0 + time_s) * 0.1;&#xA;&#x9;&#x9;&#x9;&#x9;return mat4(&#xA;&#x9;&#x9;&#x9;&#x9;&#x9;1., 0., 0., 0,&#xA;&#x9;&#x9;&#x9;&#x9;&#x9;0., 1., 0., 0,&#xA;&#x9;&#x9;&#x9;&#x9;&#x9;0., 0., 1., 0,&#xA;&#x9;&#x9;&#x9;&#x9;&#x9;x,  y,  z, 1.&#xA;&#x9;&#x9;&#x9;&#x9;);&#xA;&#x9;&#x9;&#x9;}&#xA;&#x9;&#x9;`,&#xA;&#x9;}&#xA;});&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Shader Hook API&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;type LumaShaderHooks = {&#xA;&#xA;&#x9;/** Hooks added to the vertex shader */&#xA;&#x9;vertexShaderHooks?: {&#xA;&#x9;&#x9;additionalUniforms?: { [name: string]: [UniformTypeGLSL, { value: any }] },&#xA;&#xA;&#x9;&#x9;/** Inject into global space (for example, to add a varying) */&#xA;&#x9;&#x9;additionalGlobals?: string,&#xA;&#xA;&#x9;&#x9;/**&#xA;&#x9;&#x9; * Example `(vec3 splatPosition, uint layersBitmask) { return mat4(1.); }`&#xA;&#x9;&#x9; * @param {vec3} splatPosition, object-space&#xA;&#x9;&#x9; * @param {uint} layersBitmask, bit mask of layers, where bit 0 is background and bit 1 is foreground&#xA;&#x9;&#x9; * @returns {mat4} per-splat local transform&#xA;&#x9;&#x9; */&#xA;&#x9;&#x9;getSplatTransform?: string,&#xA;&#xA;&#x9;&#x9;/**&#xA;&#x9;&#x9; * Executed at the end of the main function after gl_Position is set&#xA;&#x9;&#x9; * &#xA;&#x9;&#x9; * Example `() {&#xA;&#x9;&#x9; *  vPosition = gl_Position;&#xA;&#x9;&#x9; * }`&#xA;&#x9;&#x9; * @returns {void}&#xA;&#x9;&#x9; */&#xA;&#x9;&#x9;onMainEnd?: string,&#xA;&#xA;&#x9;&#x9;/**&#xA;&#x9;&#x9; * Example `(vec4 splatColor, vec3 splatPosition) { return pow(splatColor.rgb, vec3(2.2), splatColor.a); }`&#xA;&#x9;&#x9; * Use `gl_Position` is available&#xA;&#x9;&#x9; * @param {vec4} splatColor, default splat color&#xA;&#x9;&#x9; * @param {vec3} splatPosition, object-space&#xA;&#x9;&#x9; * @param {uint} layersBitmask, bit mask of layers, where bit 0 is background and bit 1 is foreground&#xA;&#x9;&#x9; * @returns {vec4} updated splat color&#xA;&#x9;&#x9; */&#xA;&#x9;&#x9;getSplatColor?: string,&#xA;&#x9;},&#xA;&#xA;&#x9;/** Hooks added to the fragment shader */&#xA;&#x9;fragmentShaderHooks?: {&#xA;&#x9;&#x9;additionalUniforms?: { [name: string]: [UniformTypeGLSL, { value: any }] },&#xA;&#xA;&#x9;&#x9;/** Inject into global space (for example, to add a varying) */&#xA;&#x9;&#x9;additionalGlobals?: string,&#xA;&#xA;&#x9;&#x9;/**&#xA;&#x9;&#x9; * Example `(vec4 fragColor) { return tonemap(fragColor); }`&#xA;&#x9;&#x9; * @param {vec4} fragColor, default fragment color&#xA;&#x9;&#x9; * @returns {vec4} updated fragment color&#xA;&#x9;&#x9; */&#xA;&#x9;&#x9;getFragmentColor?: string,&#xA;&#x9;}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;React Three Fiber&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#react-three-fiber&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/assets/images/react-three-fiber-preview.jpg&#34; alt=&#34;react-three-fiber-demo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Luma splats can be used with &lt;a href=&#34;https://docs.pmnd.rs/&#34;&gt;React Three Fiber&lt;/a&gt;, a React renderer for Three.js. To do so, we need to extend R3F to include the &lt;code&gt;LumaSplatsThree&lt;/code&gt; class. This is done by calling &lt;code&gt;extend&lt;/code&gt; with the class and a name (in this case &lt;code&gt;LumaSplats&lt;/code&gt; which will be used as the component name). If using TypeScript, we also need to declare the component type.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/src/DemoReactThreeFiber.tsx&#34;&gt;DemoReactThreeFiber.tsx&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import { Object3DNode, extend } from &#39;@react-three/fiber&#39;;&#xA;import { LumaSplatsThree, LumaSplatsSemantics } from &#34;@lumaai/luma-web&#34;;&#xA;&#xA;// Make LumaSplatsThree available to R3F&#xA;extend( { LumaSplats: LumaSplatsThree } );&#xA;&#xA;// For typeScript support:&#xA;declare module &#39;@react-three/fiber&#39; {&#xA;  interface ThreeElements {&#xA;    lumaSplats: Object3DNode&amp;lt;LumaSplatsThree, typeof LumaSplatsThree&amp;gt;&#xA;  }&#xA;}&#xA;&#xA;function Scene() {&#xA;&#x9;return &amp;lt;lumaSplats&#xA;&#x9;&#x9;semanticsMask={LumaSplatsSemantics.FOREGROUND}&#xA;&#x9;&#x9;source=&#39;https://lumalabs.ai/capture/822bac8d-70d6-404e-aaae-f89f46672c67&#39;&#xA;&#x9;&#x9;position={[-1, 0, 0]}&#xA;&#x9;&#x9;scale={0.5}&#xA;&#x9;/&amp;gt;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Transmission&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#transmission&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/assets/images/transmission-preview.jpg&#34; alt=&#34;transmission-demo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Splats can be used in combination with three.js transmission effects, however some care should be taken to make this work. Splats are considered &lt;code&gt;transparent&lt;/code&gt; materials in three.js which means by default they&#39;re not rendered in the transmissive pass, so initially you won&#39;t see your splats in transmissive materials. To fix we set &lt;code&gt;splats.material.transparent = false;&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In this example, we draw two splat scenes, one inside a refractive globe and the other outside. To make this work, we want the inner splat scene to &lt;em&gt;only&lt;/em&gt; render to the transmission buffer and the outer to the canvas. We do this by checking the render target before rendering and selectively disabling.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/src/DemoTransmission.ts&#34;&gt;DemoTransmission.ts&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;// inner splat&#xA;let globeSplats = new LumaSplatsThree({&#xA;&#x9;// Chateau de Menthon - Annecy&#xA;&#x9;source: &#39;https://lumalabs.ai/capture/da82625c-9c8d-4d05-a9f7-3367ecab438c&#39;,&#xA;&#x9;enableThreeShaderIntegration: true,&#xA;&#x9;onBeforeRender: (renderer) =&amp;gt; {&#xA;&#x9;&#x9;// disable MSAA on render targets (in this case the transmission render target)&#xA;&#x9;&#x9;// this improves splatting performance&#xA;&#x9;&#x9;let target = renderer.getRenderTarget();&#xA;&#x9;&#x9;if (target) {&#xA;&#x9;&#x9;&#x9;target.samples = 0;&#xA;&#x9;&#x9;}&#xA;&#xA;&#x9;&#x9;// only render in targets and not the canvas&#xA;&#x9;&#x9;globeSplats.preventDraw = target == null;&#xA;&#x9;}&#xA;});&#xA;&#xA;// disable transparency so the renderer considers it an opaque object&#xA;// opaque objects are rendered in the transmission pass (whereas transparent objects are not)&#xA;globeSplats.material.transparent = false;&#xA;&#xA;scene.add(globeSplats);&#xA;&#xA;// outer splat&#xA;let environmentSplats = new LumaSplatsThree({&#xA;&#x9;// Arosa Hörnli - Switzerland&#xA;&#x9;source: &#39;https://lumalabs.ai/capture/4da7cf32-865a-4515-8cb9-9dfc574c90c2&#39;,&#xA;&#x9;// disable animation for lighting capture&#xA;&#x9;loadingAnimationEnabled: false,&#xA;&#x9;// disable three.js shader integration for performance&#xA;&#x9;enableThreeShaderIntegration: false,&#xA;});&#xA;&#xA;scene.add(environmentSplats);&#xA;&#xA;// add a refractive transmissive sphere&#xA;let glassSphere = new Mesh(&#xA;&#x9;new SphereGeometry(1, 32, 32),&#xA;&#x9;new MeshPhysicalMaterial({&#xA;&#x9;&#x9;roughness: 0,&#xA;&#x9;&#x9;metalness: 0,&#xA;&#x9;&#x9;transmission: 1,&#xA;&#x9;&#x9;ior: 1.341,&#xA;&#x9;&#x9;thickness: 1.52,&#xA;&#x9;&#x9;envMapIntensity: 1.2,&#xA;&#x9;&#x9;clearcoat: 1,&#xA;&#x9;&#x9;side: FrontSide,&#xA;&#x9;&#x9;transparent: true,&#xA;&#x9;})&#xA;);&#xA;&#xA;scene.add(glassSphere);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;VR&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/#vr&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/assets/images/vr-preview.jpg&#34; alt=&#34;vr-demo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Viewing your splats in VR is as simple as enabling XR in three.js and adding a VR button. View this demo with a VR headset (or through a headset browser) and click &#34;Enter VR&#34;! It will work best on PC VR, standalone VR tends to struggle with splats presently&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lumalabs/luma-web-examples/main/src/DemoVR.ts&#34;&gt;DemoVR.ts&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import { VRButton } from &#34;three/examples/jsm/webxr/VRButton.js&#34;;&#xA;&#xA;renderer.xr.enabled = true;&#xA;&#xA;let vrButton = VRButton.createButton(renderer);&#xA;&#xA;document.body.appendChild(vrButton);&#xA;&#xA;let splats = new LumaSplatsThree({&#xA;&#x9;// Kind Humanoid @RyanHickman&#xA;&#x9;source: &#39;https://lumalabs.ai/capture/83e9aae8-7023-448e-83a6-53ccb377ec86&#39;,&#xA;});&#xA;&#xA;scene.add(splats);&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>samchon/typia</title>
    <updated>2023-12-13T01:46:09Z</updated>
    <id>tag:github.com,2023-12-13:/samchon/typia</id>
    <link href="https://github.com/samchon/typia" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Super-fast/easy runtime validations and serializations through transformation&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Typia&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://typia.io/logo.png&#34; alt=&#34;Typia Logo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/samchon/typia/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true&#34; alt=&#34;GitHub license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.npmjs.com/package/typia&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/typia.svg?sanitize=true&#34; alt=&#34;npm version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.npmjs.com/package/typia&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/dm/typia.svg?sanitize=true&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/samchon/typia/actions?query=workflow%3Abuild&#34;&gt;&lt;img src=&#34;https://github.com/samchon/typia/workflows/build/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://typia.io/docs/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/guide-documents-forestgreen&#34; alt=&#34;Guide Documents&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;// RUNTIME VALIDATORS&#xA;export function is&amp;lt;T&amp;gt;(input: unknown): input is T; // returns boolean&#xA;export function assert&amp;lt;T&amp;gt;(input: unknown): T; // throws TypeGuardError&#xA;export function assertGuard&amp;lt;T&amp;gt;(input: unknown): asserts input is T;&#xA;export function validate&amp;lt;T&amp;gt;(input: unknown): IValidation&amp;lt;T&amp;gt;; // detailed&#xA;&#xA;// JSON FUNCTIONS&#xA;export namespace json {&#xA;    export function application&amp;lt;T&amp;gt;(): IJsonApplication; // JSON schema&#xA;    export function assertParse&amp;lt;T&amp;gt;(input: string): T; // type safe parser&#xA;    export function assertStringify&amp;lt;T&amp;gt;(input: T): string; // safe and faster&#xA;}&#xA;&#xA;// PROTOCOL BUFFER&#xA;export namespace protobuf {&#xA;    export function message&amp;lt;T&amp;gt;(): string; // Protocol Buffer message&#xA;    export function assertDecode&amp;lt;T&amp;gt;(buffer: Uint8Array): T; // safe decoder&#xA;    export function assertEncode&amp;lt;T&amp;gt;(input: T): Uint8Array; // safe encoder&#xA;}&#xA;&#xA;// RANDOM GENERATOR&#xA;export function random&amp;lt;T&amp;gt;(g?: Partial&amp;lt;IRandomGenerator&amp;gt;): T;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Typia is a transformer library supporting below features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Super-fast Runtime Validators&lt;/li&gt; &#xA; &lt;li&gt;Enhanced JSON functions&lt;/li&gt; &#xA; &lt;li&gt;Protocol Buffer encoder and decoder&lt;/li&gt; &#xA; &lt;li&gt;Random data generator&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Only one line&lt;/strong&gt; required, with pure TypeScript type&lt;/li&gt; &#xA;  &lt;li&gt;Runtime validator is &lt;strong&gt;20,000x faster&lt;/strong&gt; than &lt;code&gt;class-validator&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;JSON serialization is &lt;strong&gt;200x faster&lt;/strong&gt; than &lt;code&gt;class-transformer&lt;/code&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Sponsors&lt;/h2&gt; &#xA;&lt;p&gt;Thanks for your support.&lt;/p&gt; &#xA;&lt;p&gt;Your donation encourages &lt;code&gt;typia&lt;/code&gt; development.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://opencollective.com/typia&#34;&gt;&lt;img src=&#34;https://opencollective.com/typia/badge.svg?avatarHeight=75&amp;amp;width=600&#34; alt=&#34;Sponsers&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Playground&lt;/h2&gt; &#xA;&lt;p&gt;You can experience how typia works by &lt;a href=&#34;https://typia.io/playground&#34;&gt;playground website&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;💻 &lt;a href=&#34;https://typia.io/playground&#34;&gt;https://typia.io/playground&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Guide Documents&lt;/h2&gt; &#xA;&lt;p&gt;Check out the document in the &lt;a href=&#34;https://typia.io/docs/&#34;&gt;website&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;h3&gt;🏠 Home&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/setup/&#34;&gt;Setup&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/pure/&#34;&gt;Pure TypeScript&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;📖 Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Runtime Validators &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/validators/assert/&#34;&gt;&lt;code&gt;assert()&lt;/code&gt; function&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/validators/is/&#34;&gt;&lt;code&gt;is()&lt;/code&gt; function&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/validators/validate/&#34;&gt;&lt;code&gt;validate()&lt;/code&gt; function&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/validators/tags/&#34;&gt;Special Tags&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Enhanced JSON &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/json/stringify/&#34;&gt;&lt;code&gt;stringify()&lt;/code&gt; functions&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/json/parse/&#34;&gt;&lt;code&gt;parse()&lt;/code&gt; functions&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/json/schema&#34;&gt;JSON Schema&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Protocol Buffer &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/protobuf/message&#34;&gt;Message Schema&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/protobuf/decode/&#34;&gt;&lt;code&gt;decode()&lt;/code&gt; functions&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/protobuf/encode/&#34;&gt;&lt;code&gt;encode()&lt;/code&gt; functions&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/random/&#34;&gt;Random Generator&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/misc/&#34;&gt;Miscellaneous&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;🔗 Appendix&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Utillization Cases &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/utilization/nestjs/&#34;&gt;NestJS&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/utilization/prisma/&#34;&gt;Prisma&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://typia.io/docs/utilization/trpc/&#34;&gt;tRPC&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/samchon/typia/tree/master/packages/benchmark/results/11th%20Gen%20Intel(R)%20Core(TM)%20i5-1135G7%20%40%202.40GHz&#34;&gt;⇲ Benchmark Result&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dev.to/samchon/series/22474&#34;&gt;⇲ &lt;code&gt;dev.to&lt;/code&gt; Articles&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>SecureAI-Tools/SecureAI-Tools</title>
    <updated>2023-12-13T01:46:09Z</updated>
    <id>tag:github.com,2023-12-13:/SecureAI-Tools/SecureAI-Tools</id>
    <link href="https://github.com/SecureAI-Tools/SecureAI-Tools" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Private and secure AI tools for everyone&#39;s productivity.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SecureAI Tools&lt;/h1&gt; &#xA;&lt;p&gt;Private and secure AI tools for everyone&#39;s productivity.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/YTyPGHcYP9&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/YTyPGHcYP9?style=flat&amp;amp;compact=true&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Highlights&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Chat with AI&lt;/strong&gt;: Allows you to chat with AI models (i.e. ChatGPT).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Chat with Documents&lt;/strong&gt;: Allows you to chat with documents (PDFs for now). Demo videos below&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Local inference&lt;/strong&gt;: Runs AI models locally. Supports 100+ open-source (and semi-open-source) AI models through &lt;a href=&#34;https://ollama.ai/library&#34;&gt;Ollama&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Built-in authentication&lt;/strong&gt;: A simple email/password authentication so it can be opened to internet and accessed from anywhere.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Built-in user management&lt;/strong&gt;: So family members or coworkers can use it as well if desired.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Self-hosting optimized&lt;/strong&gt;: Comes with necessary scripts and docker-compose files to get started in under 5 minutes.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Demos&lt;/h2&gt; &#xA;&lt;h4&gt;Chat with documents demo: OpenAI&#39;s GPT3.5&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Br2D3G9O47s&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/Br2D3G9O47s/0.jpg&#34; alt=&#34;Chat with documents demo: OpenAI&#39;s GPT3.5&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Chat with documents demo: Locally running Mistral (M2 MacBook)&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=UvRHL6f_w74&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/UvRHL6f_w74/0.jpg&#34; alt=&#34;Chat with documents demo: Locally running Mistral&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;h3&gt;Docker Compose [Recommended]&lt;/h3&gt; &#xA;&lt;h4&gt;1. Create a directory&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir secure-ai-tools &amp;amp;&amp;amp; cd secure-ai-tools&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2. Run set-up script&lt;/h4&gt; &#xA;&lt;p&gt;The script downloads &lt;code&gt;docker-compose.yml&lt;/code&gt; and generates a &lt;code&gt;.env&lt;/code&gt; file with sensible defaults.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -sL https://github.com/SecureAI-Tools/SecureAI-Tools/releases/latest/download/set-up.sh | sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;3. [Optional] Edit &lt;code&gt;.env&lt;/code&gt; file&lt;/h4&gt; &#xA;&lt;p&gt;Customize the &lt;code&gt;.env&lt;/code&gt; file created in the above step to your liking.&lt;/p&gt; &#xA;&lt;h4&gt;4. [Optional] On Linux machine with Nvidia GPUs, enable GPU support&lt;/h4&gt; &#xA;&lt;p&gt;To accelerate inference on Linux machines, you will need to enable GPUs. This is not strictly required as the inference service will run on CPU-only mode as well, but it will be slow on CPU. So if your machine has Nvidia GPU then this step is recommended.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installation&#34;&gt;Nvidia container toolkit&lt;/a&gt; if not already installed.&lt;/li&gt; &#xA; &lt;li&gt;Uncomment the &lt;code&gt;deploy:&lt;/code&gt; block in &lt;code&gt;docker-compose.yml&lt;/code&gt; file. It gives inference service access to Nvidia GPUs.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;5. Run docker compose&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;6. Post-installation set-up&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Login at &lt;a href=&#34;http://localhost:28669/log-in&#34;&gt;http://localhost:28669/log-in&lt;/a&gt; using the initial credentials below, and change the password.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Email&lt;/p&gt; &lt;pre&gt;&lt;code&gt;bruce@wayne-enterprises.com&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Password&lt;/p&gt; &lt;pre&gt;&lt;code&gt;SecureAIToolsFTW!&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Set up the AI model by going to &lt;a href=&#34;http://localhost:28669/-/settings?tab=ai&#34;&gt;http://localhost:28669/-/settings?tab=ai&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Navigate to &lt;a href=&#34;http://localhost:28669/-&#34;&gt;http://localhost:28669/-&lt;/a&gt; and start using AI tools&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Features wishlist&lt;/h2&gt; &#xA;&lt;p&gt;A set of features on our todo list (in no particular order).&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;✅ Chat with documents&lt;/li&gt; &#xA; &lt;li&gt;✅ Support for OpenAI, Claude etc APIs&lt;/li&gt; &#xA; &lt;li&gt;Support for markdown rendering&lt;/li&gt; &#xA; &lt;li&gt;Chat sharing&lt;/li&gt; &#xA; &lt;li&gt;Mobile friendly UI&lt;/li&gt; &#xA; &lt;li&gt;Specify AI model at chat-creation time&lt;/li&gt; &#xA; &lt;li&gt;Prompt templates library&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>