<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-12-31T01:37:36Z</updated>
  <subtitle>Daily Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Vali-98/ChatterUI</title>
    <updated>2025-12-31T01:37:36Z</updated>
    <id>tag:github.com,2025-12-31:/Vali-98/ChatterUI</id>
    <link href="https://github.com/Vali-98/ChatterUI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Simple frontend for LLMs built in react-native.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatterUI - A simple app for LLMs&lt;/h1&gt; &#xA;&lt;p&gt;ChatterUI is a native mobile frontend for LLMs.&lt;/p&gt; &#xA;&lt;p&gt;Run LLMs on device or connect to various commercial or open source APIs. ChatterUI aims to provide a mobile-friendly interface with fine-grained control over chat structuring.&lt;/p&gt; &#xA;&lt;p&gt;If you like the app, feel free support me here:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ko-fi.com/vali98&#34; target=&#34;_blank&#34;&gt;&lt;img height=&#34;35&#34; style=&#34;border:0px;height:46px;&#34; src=&#34;https://az743702.vo.msecnd.net/cdn/kofi3.png?v=0&#34; border=&#34;0&#34; alt=&#34;Support me on ko-fi.com&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div&gt;&#xA;  Chat With Characters or Assistants &#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://github.com/Vali-98/ChatterUI/raw/master/assets/screenshots/characterlist.png&#34; width=&#34;150&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/Vali-98/ChatterUI/raw/master/assets/screenshots/chat.png&#34; width=&#34;150&#34;&gt; &#xA; &lt;br&gt; Use on-device Models or APIs &#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://github.com/Vali-98/ChatterUI/raw/master/assets/screenshots/models.png&#34; width=&#34;150&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/Vali-98/ChatterUI/raw/master/assets/screenshots/api.png&#34; width=&#34;150&#34;&gt; &#xA; &lt;br&gt; Modify And Customize &#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://github.com/Vali-98/ChatterUI/raw/master/assets/screenshots/charactereditor.png&#34; width=&#34;150&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/Vali-98/ChatterUI/raw/master/assets/screenshots/settings.png&#34; width=&#34;150&#34;&gt; &#xA; &lt;br&gt; Personalize Yourself &#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://github.com/Vali-98/ChatterUI/raw/master/assets/screenshots/usereditor.png&#34; width=&#34;150&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/Vali-98/ChatterUI/raw/master/assets/screenshots/userlist.png&#34; width=&#34;150&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Features:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run LLMs on-device in Local Mode&lt;/li&gt; &#xA; &lt;li&gt;Connect to various APIs in Remote Mode&lt;/li&gt; &#xA; &lt;li&gt;Chat with characters. (Supports the Character Card v2 specification.)&lt;/li&gt; &#xA; &lt;li&gt;Create and manage multiple chats per character.&lt;/li&gt; &#xA; &lt;li&gt;Customize Sampler fields and Instruct formatting&lt;/li&gt; &#xA; &lt;li&gt;Integrates with your deviceâ€™s text-to-speech (TTS) engine&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;p&gt;Download and install latest APK from the &lt;a href=&#34;https://github.com/Vali-98/ChatterUI/releases/latest&#34;&gt;releases&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;p&gt;&lt;i&gt;iOS is Currently unavailable due to lacking iOS hardware for development&lt;/i&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Local Mode&lt;/h2&gt; &#xA;&lt;p&gt;ChatterUI uses a &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt; under the hood to run gguf files on device. A custom adapter is used to integrate with react-native: &lt;a href=&#34;https://github.com/Vali-98/cui-llama.rn&#34;&gt;cui-llama.rn&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;To use on-device inferencing, first enable Local Mode, then go to Models &amp;gt; Import Model / Use External Model and choose a gguf model that can fit on your device&#39;s memory. The importing functions are as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Import Model: Copies the model file into ChatterUI, potentially speeding up startup time.&lt;/li&gt; &#xA; &lt;li&gt;Use External Model: Uses a model from your device storage directly, removing the need to copy large files into ChatterUI but with a slight delay in load times.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;After that, you can load the model and begin chatting!&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Note: For devices with Snapdragon 8 Gen 1 and above or Exynos 2200+, it is recommended to use the Q4_0 quantization for optimized performance.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Remote Mode&lt;/h2&gt; &#xA;&lt;p&gt;Remote Mode allows you to connect to a few common APIs from both commercial and open source projects.&lt;/p&gt; &#xA;&lt;h3&gt;Open Source Backends:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;koboldcpp&lt;/li&gt; &#xA; &lt;li&gt;text-generation-webui&lt;/li&gt; &#xA; &lt;li&gt;Ollama&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Dedicated API:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;OpenAI&lt;/li&gt; &#xA; &lt;li&gt;Claude &lt;em&gt;(with ability to use a proxy)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;Cohere&lt;/li&gt; &#xA; &lt;li&gt;Open Router&lt;/li&gt; &#xA; &lt;li&gt;Mancer&lt;/li&gt; &#xA; &lt;li&gt;AI Horde&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Generic backends:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Generic Text Completions&lt;/li&gt; &#xA; &lt;li&gt;Generic Chat Completions&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;em&gt;These should be compliant with any Text Completion/Chat Completion backends such as Groq or Infermatic.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Custom APIs:&lt;/h3&gt; &#xA;&lt;p&gt;Is your API provider missing? ChatterUI allows you to define APIs using its template system.&lt;/p&gt; &#xA;&lt;p&gt;Read more about it &lt;a href=&#34;https://github.com/Vali-98/ChatterUI/discussions/126&#34;&gt;here!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;h3&gt;Android&lt;/h3&gt; &#xA;&lt;p&gt;To run a development build, follow these simple steps:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install any Java 17/21 SDK of your choosing&lt;/li&gt; &#xA; &lt;li&gt;Install &lt;code&gt;android-sdk&lt;/code&gt; via &lt;code&gt;Android Studio&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Clone the repo:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/Vali-98/ChatterUI.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install dependencies via npm and run via Expo:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm install&#xA;npx expo run:android&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Building an APK&lt;/h4&gt; &#xA;&lt;p&gt;Requires Node.js, Java 17/21 SDK and Android SDK. Expo uses EAS to build apps which requires a Linux environment.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repo.&lt;/li&gt; &#xA; &lt;li&gt;Rename the &lt;code&gt;eas.json.example&lt;/code&gt; to &lt;code&gt;eas.json&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Modify &lt;code&gt;&#34;ANDROID_SDK_ROOT&#34;&lt;/code&gt; to the directory of your Android SDK&lt;/li&gt; &#xA; &lt;li&gt;Run the following:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm install&#xA;eas build --platform android --local&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;IOS&lt;/h3&gt; &#xA;&lt;p&gt;Currently untested as I do not own hardware for iOS development. Assistance here would be greatly appreciated!&lt;/p&gt; &#xA;&lt;p&gt;Possible issues:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;cui-llama.rn lacking Swift implementation for cui-specific functions&lt;/li&gt; &#xA; &lt;li&gt;cui-fs having no Swift integration&lt;/li&gt; &#xA; &lt;li&gt;Platform specific shadows&lt;/li&gt; &#xA; &lt;li&gt;Exporting files not using shareAsync&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt; - the underlying engine to run LLMs&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mybigday/llama.rn&#34;&gt;llama.rn&lt;/a&gt; - the original react-native llama.cpp adapter&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>