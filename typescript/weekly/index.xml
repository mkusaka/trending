<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-06-02T01:57:07Z</updated>
  <subtitle>Weekly Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>rashadphz/farfalle</title>
    <updated>2024-06-02T01:57:07Z</updated>
    <id>tag:github.com,2024-06-02:/rashadphz/farfalle</id>
    <link href="https://github.com/rashadphz/farfalle" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ğŸ” AI search engine - self-host with local or cloud LLMs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Farfalle&lt;/h1&gt; &#xA;&lt;p&gt;Open-source AI-powered search engine. (Perplexity Clone)&lt;/p&gt; &#xA;&lt;p&gt;Run your local LLM (&lt;strong&gt;llama3&lt;/strong&gt;, &lt;strong&gt;gemma&lt;/strong&gt;, &lt;strong&gt;mistral&lt;/strong&gt;, &lt;strong&gt;phi3&lt;/strong&gt;) or use cloud models (&lt;strong&gt;Groq/Llama3&lt;/strong&gt;, &lt;strong&gt;OpenAI/gpt4-o&lt;/strong&gt;)&lt;/p&gt; &#xA;&lt;p&gt;Demo answering questions with phi3 on my M1 Macbook Pro:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/rashadphz/farfalle/assets/20783686/9cda83b8-0d3c-4a81-83ee-ff8cce323fee&#34;&gt;https://github.com/rashadphz/farfalle/assets/20783686/9cda83b8-0d3c-4a81-83ee-ff8cce323fee&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Please feel free to contact me on &lt;a href=&#34;https://twitter.com/rashadphz&#34;&gt;Twitter&lt;/a&gt; or &lt;a href=&#34;https://github.com/rashadphz/farfalle/issues/new&#34;&gt;create an issue&lt;/a&gt; if you have any questions.&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ’» Live Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://farfalle.dev/&#34;&gt;farfalle.dev&lt;/a&gt; (Cloud models only)&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“– Overview&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸ› ï¸ &lt;a href=&#34;https://raw.githubusercontent.com/rashadphz/farfalle/main/#%EF%B8%8F-tech-stack&#34;&gt;Tech Stack&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ğŸƒğŸ¿â€â™‚ï¸ &lt;a href=&#34;https://raw.githubusercontent.com/rashadphz/farfalle/main/#%EF%B8%8F-getting-started&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ğŸš€ &lt;a href=&#34;https://raw.githubusercontent.com/rashadphz/farfalle/main/#-deploy&#34;&gt;Deploy&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ›£ï¸ Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add support for local LLMs through Ollama&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Docker deployment setup&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add support for &lt;a href=&#34;https://github.com/searxng/searxng&#34;&gt;searxng&lt;/a&gt;. Eliminates the need for external dependencies.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Create a pre-built Docker Image&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Chat History&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Chat with local files&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ› ï¸ Tech Stack&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Frontend: &lt;a href=&#34;https://nextjs.org/&#34;&gt;Next.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Backend: &lt;a href=&#34;https://fastapi.tiangolo.com/&#34;&gt;FastAPI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Search API: &lt;a href=&#34;https://github.com/searxng/searxng&#34;&gt;SearXNG&lt;/a&gt;, &lt;a href=&#34;https://tavily.com/&#34;&gt;Tavily&lt;/a&gt;, &lt;a href=&#34;https://serper.dev/&#34;&gt;Serper&lt;/a&gt;, &lt;a href=&#34;https://www.microsoft.com/en-us/bing/apis/bing-web-search-api&#34;&gt;Bing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Logging: &lt;a href=&#34;https://pydantic.dev/logfire&#34;&gt;Logfire&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Rate Limiting: &lt;a href=&#34;https://redis.io/&#34;&gt;Redis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Components: &lt;a href=&#34;https://ui.shadcn.com/&#34;&gt;shadcn/ui&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Search with multiple search providers (Tavily, Searxng, Serper, Bing)&lt;/li&gt; &#xA; &lt;li&gt;Answer questions with cloud models (OpenAI/gpt4-o, OpenAI/gpt3.5-turbo, Groq/Llama3)&lt;/li&gt; &#xA; &lt;li&gt;Answer questions with local models (llama3, mistral, gemma, phi3)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸƒğŸ¿â€â™‚ï¸ Getting Started Locally&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.docker.com/get-docker/&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ollama.com/download&#34;&gt;Ollama&lt;/a&gt; (If running local models) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Download any of the supported models: &lt;strong&gt;llama3&lt;/strong&gt;, &lt;strong&gt;mistral&lt;/strong&gt;, &lt;strong&gt;gemma&lt;/strong&gt;, &lt;strong&gt;phi3&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Start ollama server &lt;code&gt;ollama serve&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Get API Keys&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://app.tavily.com/home&#34;&gt;Tavily (Optional)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://serper.dev/dashboard&#34;&gt;Serper (Optional)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://platform.openai.com/api-keys&#34;&gt;OpenAI (Optional)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/bing/apis/bing-web-search-api&#34;&gt;Bing (Optional)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://console.groq.com/keys&#34;&gt;Groq (Optional)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;1. Clone the Repo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:rashadphz/farfalle.git&#xA;cd farfalle&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Add Environment Variables&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;touch .env&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Add the following variables to the .env file:&lt;/p&gt; &#xA;&lt;h4&gt;Search Provider&lt;/h4&gt; &#xA;&lt;p&gt;You can use Tavily, Searxng, Serper, or Bing as the search provider.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Searxng&lt;/strong&gt; (No API Key Required)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;SEARCH_PROVIDER=searxng&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Tavily&lt;/strong&gt; (Requires API Key)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;TAVILY_API_KEY=...&#xA;SEARCH_PROVIDER=tavily&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Serper&lt;/strong&gt; (Requires API Key)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;SERPER_API_KEY=...&#xA;SEARCH_PROVIDER=serper&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bing&lt;/strong&gt; (Requires API Key)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;BING_API_KEY=...&#xA;SEARCH_PROVIDER=bing&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Optional&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Cloud Models&#xA;OPENAI_API_KEY=...&#xA;GROQ_API_KEY=...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. Run Containers&lt;/h3&gt; &#xA;&lt;p&gt;This requires Docker Compose version 2.22.0 or later.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker-compose -f docker-compose.dev.yaml up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Visit &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt; to view the app.&lt;/p&gt; &#xA;&lt;p&gt;For custom setup instructions, see &lt;a href=&#34;https://raw.githubusercontent.com/rashadphz/farfalle/main/custom-setup-instructions.md&#34;&gt;custom-setup-instructions.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸš€ Deploy&lt;/h2&gt; &#xA;&lt;h3&gt;Backend&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://render.com/deploy?repo=https://github.com/rashadphz/farfalle&#34;&gt;&lt;img src=&#34;https://render.com/images/deploy-to-render-button.svg?sanitize=true&#34; alt=&#34;Deploy to Render&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;After the backend is deployed, copy the web service URL to your clipboard. It should look something like: &lt;a href=&#34;https://some-service-name.onrender.com&#34;&gt;https://some-service-name.onrender.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Frontend&lt;/h3&gt; &#xA;&lt;p&gt;Use the copied backend URL in the &lt;code&gt;NEXT_PUBLIC_API_URL&lt;/code&gt; environment variable when deploying with Vercel.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Frashadphz%2Ffarfalle&amp;amp;env=NEXT_PUBLIC_API_URL&amp;amp;envDescription=URL%20for%20your%20backend%20application.%20For%20backends%20deployed%20with%20Render%2C%20the%20URL%20will%20look%20like%20this%3A%20https%3A%2F%2F%5Bsome-hostname%5D.onrender.com&amp;amp;root-directory=src%2Ffrontend&#34;&gt;&lt;img src=&#34;https://vercel.com/button&#34; alt=&#34;Deploy with Vercel&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;And you&#39;re done! ğŸ¥³&lt;/p&gt; &#xA;&lt;h2&gt;Use Farfalle as a Search Engine&lt;/h2&gt; &#xA;&lt;p&gt;To use Farfalle as your default search engine, follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Visit the settings of your browser&lt;/li&gt; &#xA; &lt;li&gt;Go to &#39;Search Engines&#39;&lt;/li&gt; &#xA; &lt;li&gt;Create a new search engine entry using this URL: &lt;a href=&#34;http://localhost:3000/?q=%s&#34;&gt;http://localhost:3000/?q=%s&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Add the search engine.&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>ragapp/ragapp</title>
    <updated>2024-06-02T01:57:07Z</updated>
    <id>tag:github.com,2024-06-02:/ragapp/ragapp</id>
    <link href="https://github.com/ragapp/ragapp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The easiest way to use Agentic RAG in any enterprise&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt;&lt;img alt=&#34;Logo - RAGapp&#34; src=&#34;https://raw.githubusercontent.com/ragapp/ragapp/main/docs/logo.png&#34;&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;strong&gt;The easiest way to use Agentic RAG in any enterprise.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;As simple to configure as &lt;a href=&#34;https://openai.com/index/introducing-gpts&#34; target=&#34;_blank&#34;&gt;OpenAI&#39;s custom GPTs&lt;/a&gt;, but deployable in your own cloud infrastructure using Docker. Built using &lt;a href=&#34;https://github.com/run-llama/llama_index&#34;&gt;LlamaIndex&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/ragapp/ragapp/main/#get-started&#34;&gt;&lt;strong&gt;Get Started&lt;/strong&gt;&lt;/a&gt; Â· &lt;a href=&#34;https://raw.githubusercontent.com/ragapp/ragapp/main/#endpoints&#34;&gt;&lt;strong&gt;Endpoints&lt;/strong&gt;&lt;/a&gt; Â· &lt;a href=&#34;https://raw.githubusercontent.com/ragapp/ragapp/main/#deployment&#34;&gt;&lt;strong&gt;Deployment&lt;/strong&gt;&lt;/a&gt; Â· &lt;a href=&#34;https://raw.githubusercontent.com/ragapp/ragapp/main/#contact&#34;&gt;&lt;strong&gt;Contact&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;img alt=&#34;Screenshot&#34; src=&#34;https://raw.githubusercontent.com/ragapp/ragapp/main/docs/screenshot.png&#34;&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;p&gt;To run, start a docker container with our image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -p 8000:8000 ragapp/ragapp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, access the Admin UI at &lt;a href=&#34;http://localhost:8000/admin&#34;&gt;http://localhost:8000/admin&lt;/a&gt; to configure your RAGapp.&lt;/p&gt; &#xA;&lt;p&gt;You can use hosted AI models from OpenAI or Gemini, and local models using &lt;a href=&#34;https://ollama.com/&#34;&gt;Ollama&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Endpoints&lt;/h2&gt; &#xA;&lt;p&gt;The docker container exposes the following endpoints:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Admin UI: &lt;a href=&#34;http://localhost:8000/admin&#34;&gt;http://localhost:8000/admin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Chat UI: &lt;a href=&#34;http://localhost:8000&#34;&gt;http://localhost:8000&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;API: &lt;a href=&#34;http://localhost:8000/docs&#34;&gt;http://localhost:8000/docs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: The Chat UI and API are only functional if the RAGapp is configured.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;RAGapp doesn&#39;t come with any authentication layer by design. Just protect the &lt;code&gt;/admin&lt;/code&gt; path in your cloud environment to secure your RAGapp.&lt;/p&gt; &#xA;&lt;h2&gt;Deployment&lt;/h2&gt; &#xA;&lt;h3&gt;Using Docker Compose&lt;/h3&gt; &#xA;&lt;p&gt;We provide a &lt;code&gt;docker-compose.yml&lt;/code&gt; file to make deploying RAGapp with &lt;a href=&#34;https://ollama.com/&#34;&gt;Ollama&lt;/a&gt; and &lt;a href=&#34;https://qdrant.tech/&#34;&gt;Qdrant&lt;/a&gt; easy in your own infrastructure.&lt;/p&gt; &#xA;&lt;p&gt;Using the &lt;code&gt;MODEL&lt;/code&gt; environment variable, you can specify which model to use, e.g. &lt;a href=&#34;https://ollama.com/library/llama3&#34;&gt;&lt;code&gt;llama3&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;MODEL=llama3 docker-compose up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you don&#39;t specify the &lt;code&gt;MODEL&lt;/code&gt; variable, the default model used is &lt;code&gt;phi3&lt;/code&gt;, which is less capable than &lt;code&gt;llama3&lt;/code&gt; but faster to download.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: The &lt;code&gt;setup&lt;/code&gt; container in the &lt;code&gt;docker-compose.yml&lt;/code&gt; file will download the selected model into the &lt;a href=&#34;https://raw.githubusercontent.com/ragapp/ragapp/main/ollama/&#34;&gt;&lt;code&gt;ollama&lt;/code&gt;&lt;/a&gt; folder - this will take a few minutes.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Using the &lt;code&gt;OLLAMA_BASE_URL&lt;/code&gt; environment variables, you can specify which Ollama host to use. If you don&#39;t specify the &lt;code&gt;OLLAMA_BASE_URL&lt;/code&gt; variable, the default points to the Ollama instance started by Docker Compose (&lt;code&gt;http://ollama:11434&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re running a local Ollama instance, you can choose to connect it to RAGapp by setting the &lt;code&gt;OLLAMA_BASE_URL&lt;/code&gt; variable to &lt;code&gt;http://host.docker.internal:11434&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;MODEL=llama3 OLLAMA_BASE_URL=http://host.docker.internal:11434 docker-compose up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is necessary if you&#39;re running RAGapp on macOS, as Docker for Mac does not support GPU acceleration.&lt;/p&gt; &#xA;&lt;p&gt;To enable Docker access to NVIDIA GPUs on Linux, &lt;a href=&#34;https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html&#34;&gt;install the NVIDIA Container Toolkit&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Kubernetes&lt;/h3&gt; &#xA;&lt;p&gt;It&#39;s easy to deploy RAGapp in your own cloud infrastructure. Customized K8S deployment descriptors are coming soon.&lt;/p&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;poetry install --no-root&#xA;make build-frontends&#xA;make dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: To check out the admin UI during development, please go to &lt;a href=&#34;http://localhost:3000/admin&#34;&gt;http://localhost:3000/admin&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;Questions, feature requests or found a bug? &lt;a href=&#34;https://github.com/ragapp/ragapp/issues/new/choose&#34;&gt;Open an issue&lt;/a&gt; or reach out to &lt;a href=&#34;https://github.com/marcusschiesser&#34;&gt;marcusschiesser&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>AIsouler/GKD_subscription</title>
    <updated>2024-06-02T01:57:07Z</updated>
    <id>tag:github.com,2024-06-02:/AIsouler/GKD_subscription</id>
    <link href="https://github.com/AIsouler/GKD_subscription" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GKD ç¬¬ä¸‰æ–¹è®¢é˜…è§„åˆ™&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;@AIsouler/GKD_subscription&lt;/h1&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;å£°æ˜&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;æœ¬ä»“åº“ä»…ä¾›æœ¬äººå­¦ä¹ ä½¿ç”¨ï¼Œå…¶ä»–äººçš„ä»»ä½•è¡Œä¸ºå‡ä¸æœ¬äººæ— å…³&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ç²¾åŠ›æœ‰é™ï¼Œéšç¼˜æ›´æ–°&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;è¯´æ˜&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;ä»…å¯ç”¨ &lt;code&gt;å¼€å±å¹¿å‘Š&lt;/code&gt; ä¸€ç±»è§„åˆ™ï¼Œå…¶å®ƒæ‰€æœ‰è§„åˆ™å‡éœ€æ‰‹åŠ¨æ‰“å¼€ï¼Œè§„åˆ™ç±»åˆ«é‡Œå¯ä»¥æ‰¹é‡å¼€å¯æŸä¸€ç±»è§„åˆ™&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;è®¢é˜…é“¾æ¥ï¼š&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;npmmirroræºï¼ˆå›½å†…ï¼‰&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;https://registry.npmmirror.com/@aisouler/gkd_subscription/latest/files/dist/AIsouler_gkd.json5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GitHubæº&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;https://raw.githubusercontent.com/AIsouler/GKD_subscription/main/dist/AIsouler_gkd.json5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å½“å‰ç‰ˆæœ¬: v89&lt;/p&gt; &#xA;&lt;p&gt;å½“å‰è®¢é˜…æ–‡ä»¶å·²é€‚é… 744 ä¸ªåº”ç”¨ï¼Œå…±æœ‰ 1730 åº”ç”¨è§„åˆ™ç»„ï¼Œ3 å…¨å±€è§„åˆ™ç»„&lt;/p&gt; &#xA;&lt;p&gt;æŸ¥çœ‹ &lt;a href=&#34;https://raw.githubusercontent.com/AIsouler/GKD_subscription/main/dist/README.md&#34;&gt;é€‚é… APP åˆ—è¡¨&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;æŸ¥çœ‹ &lt;a href=&#34;https://github.com/Adpro-Team/GKD_THS_List&#34;&gt;ç¬¬ä¸‰æ–¹è®¢é˜…è§„åˆ™æ±‡æ€»&lt;/a&gt; By &lt;a href=&#34;https://github.com/adproqwq&#34;&gt;@adproqwq&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;æŸ¥çœ‹ &lt;a href=&#34;https://github.com/Snoopy1866/blogs/tree/main/software/gkd&#34;&gt;GKDåŸºç¡€ä½¿ç”¨ã€è§„åˆ™ç¼–å†™æ•™ç¨‹&lt;/a&gt; By &lt;a href=&#34;https://github.com/Snoopy1866&#34;&gt;@Snoopy1866&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;æ‚¨å¯ä»¥ä½¿ç”¨ &lt;a href=&#34;https://github.com/gkd-kit/subscription-template&#34;&gt;GKDè®¢é˜…æ¨¡æ¿&lt;/a&gt; å¿«é€Ÿæ„å»ºè‡ªå·±çš„è®¢é˜…&lt;/p&gt; &#xA;&lt;p&gt;å¦‚ä½•ç¼–å†™è®¢é˜…/è´¡çŒ®æ­¤é¡¹ç›® -&amp;gt; &lt;a href=&#34;https://raw.githubusercontent.com/AIsouler/GKD_subscription/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;æ„Ÿè°¢ä»¥ä¸‹é¡¹ç›®&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/gkd-kit/subscription&#34;&gt;gkd-kit/subscription&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;æ„Ÿè°¢ä»¥ä¸‹å¼€å‘è€…çš„è´¡çŒ®&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=AIsouler/GKD_subscription&amp;amp;_v=89&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#AIsouler/GKD_subscription&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=AIsouler/GKD_subscription&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>