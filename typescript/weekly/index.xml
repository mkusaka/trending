<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-12T02:02:01Z</updated>
  <subtitle>Weekly Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ddiu8081/chatgpt-demo</title>
    <updated>2023-03-12T02:02:01Z</updated>
    <id>tag:github.com,2023-03-12:/ddiu8081/chatgpt-demo</id>
    <link href="https://github.com/ddiu8081/chatgpt-demo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A demo repo based on OpenAI API (gpt-3.5-turbo)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGPT-API Demo&lt;/h1&gt; &#xA;&lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/ddiu8081/chatgpt-demo/main/README.zh-CN.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;A demo repo based on &lt;a href=&#34;https://platform.openai.com/docs/guides/chat&#34;&gt;OpenAI GPT-3.5 Turbo API.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;üçø Live preview&lt;/strong&gt;: &lt;a href=&#34;https://chatgpt.ddiu.me&#34;&gt;https://chatgpt.ddiu.me&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;‚ö†Ô∏è Notice: Our API Key limit has been exhausted. So the demo site is not available now.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.staticaly.com/gh/yzh990918/static@master/chat-logo.webp&#34; alt=&#34;chat-logo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Running Locally&lt;/h2&gt; &#xA;&lt;h3&gt;Pre environment&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Node&lt;/strong&gt;: Check that both your development environment and deployment environment are using &lt;code&gt;Node v18&lt;/code&gt; or later. You can use &lt;a href=&#34;https://github.com/nvm-sh/nvm&#34;&gt;nvm&lt;/a&gt; to manage multiple &lt;code&gt;node&lt;/code&gt; versions locally„ÄÇ &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; node -v&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;PNPM&lt;/strong&gt;: We recommend using &lt;a href=&#34;https://pnpm.io/&#34;&gt;pnpm&lt;/a&gt; to manage dependencies. If you have never installed pnpm, you can install it with the following command: &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; npm i -g pnpm&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;OPENAI_API_KEY&lt;/strong&gt;: Before running this application, you need to obtain the API key from OpenAI. You can register the API key at &lt;a href=&#34;https://beta.openai.com/signup&#34;&gt;https://beta.openai.com/signup&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Getting Started&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install dependencies &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; pnpm install&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Copy the &lt;code&gt;.env.example&lt;/code&gt; file, then rename it to &lt;code&gt;.env&lt;/code&gt;, and add your &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;OpenAI API key&lt;/a&gt; to the &lt;code&gt;.env&lt;/code&gt; file. &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; OPENAI_API_KEY=sk-xxx...&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Run the application, the local project runs on &lt;code&gt;http://localhost:3000/&lt;/code&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; pnpm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Deploy&lt;/h2&gt; &#xA;&lt;h3&gt;Deploy With Vercel&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fddiu8081%2Fchatgpt-demo&amp;amp;env=OPENAI_API_KEY&amp;amp;envDescription=OpenAI%20API%20Key&amp;amp;envLink=https%3A%2F%2Fplatform.openai.com%2Faccount%2Fapi-keys&#34;&gt;&lt;img src=&#34;https://vercel.com/button&#34; alt=&#34;Deploy with Vercel&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.staticaly.com/gh/yzh990918/static@master/20230310/image.4wzfb79qt7k0.webp&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Deploy With Netlify&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://app.netlify.com/start/deploy?repository=https://github.com/ddiu8081/chatgpt-demo#OPENAI_API_KEY=&amp;amp;HTTPS_PROXY=&amp;amp;OPENAI_API_BASE_URL=&amp;amp;HEAD_SCRIPTS=&amp;amp;SECRET_KEY=&#34;&gt;&lt;img src=&#34;https://www.netlify.com/img/deploy/button.svg?sanitize=true&#34; alt=&#34;Deploy with Netlify&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Step-by-step deployment tutorial:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ddiu8081/chatgpt-demo/fork&#34;&gt;Fork&lt;/a&gt; this projectÔºåGo to &lt;a href=&#34;https://app.netlify.com/start&#34;&gt;https://app.netlify.com/start&lt;/a&gt; new Site, select the project you &lt;code&gt;forked&lt;/code&gt; done, and connect it with your &lt;code&gt;GitHub&lt;/code&gt; account.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.staticaly.com/gh/yzh990918/static@master/20230310/image.3nlt4hgzb16o.webp&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.staticaly.com/gh/yzh990918/static@master/20230310/image.5fhfouap270g.webp&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Select the branch you want to deploy, then configure environment variables in the project settings.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.staticaly.com/gh/yzh990918/static@master/20230311/image.gfs9lx8c854.webp&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Select the default build command and output directory, Click the &lt;code&gt;Deploy Site&lt;/code&gt; button to start deploying the site„ÄÇ&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.staticaly.com/gh/yzh990918/static@master/20230311/image.4jky9e1wbojk.webp&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Deploy with Docker&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# build&#xA;docker-compose build .&#xA;# run&#xA;docker-compose up -d&#xA;# stop&#xA;docker-compose down&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Deploy on more servers&lt;/h3&gt; &#xA;&lt;p&gt;Please refer to the official deployment documentationÔºö&lt;a href=&#34;https://docs.astro.build/en/guides/deploy&#34;&gt;https://docs.astro.build/en/guides/deploy&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Environment Variables&lt;/h2&gt; &#xA;&lt;p&gt;You can control the website through environment variables.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Default&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Your API Key for OpenAI.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;HTTPS_PROXY&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Provide proxy for OpenAI API. e.g. &lt;code&gt;http://127.0.0.1:7890&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;OPENAI_API_BASE_URL&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Custom base url for OpenAI API.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;https://api.openai.com&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;HEAD_SCRIPTS&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Inject analytics or other scripts before &lt;code&gt;&amp;lt;/head&amp;gt;&lt;/code&gt; of the page&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;SECRET_KEY&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Secret string for the project. Use for generating signatures for API calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;SITE_PASSWORD&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Set password for site. If not set, site will be public&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Frequently Asked Questions&lt;/h2&gt; &#xA;&lt;p&gt;Q: TypeError: fetch failed (can&#39;t connect to OpenAI Api)&lt;/p&gt; &#xA;&lt;p&gt;A: Configure environment variables &lt;code&gt;HTTPS_PROXY&lt;/code&gt;Ôºåreference: &lt;a href=&#34;https://github.com/ddiu8081/chatgpt-demo/issues/34&#34;&gt;https://github.com/ddiu8081/chatgpt-demo/issues/34&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Q: throw new TypeError(${context} is not a ReadableStream.)&lt;/p&gt; &#xA;&lt;p&gt;A: The Node version needs to be &lt;code&gt;v18&lt;/code&gt; or laterÔºåreference: &lt;a href=&#34;https://github.com/ddiu8081/chatgpt-demo/issues/65&#34;&gt;https://github.com/ddiu8081/chatgpt-demo/issues/65&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;This project exists thanks to all those who contributed.&lt;/p&gt; &#xA;&lt;p&gt;Thank you to all our supporters!üôè&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ddiu8081/chatgpt-demo/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contributors.nn.ci/api?repo=ddiu8081/chatgpt-demo&#34; alt=&#34;img&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MIT ¬© &lt;a href=&#34;https://github.com/ddiu8081/chatgpt-demo/raw/main/LICENSE&#34;&gt;ddiu8081&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>JimmyLv/BibiGPT</title>
    <updated>2023-03-12T02:02:01Z</updated>
    <id>tag:github.com,2023-03-12:/JimmyLv/BibiGPT</id>
    <link href="https://github.com/JimmyLv/BibiGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;BibiGPT ¬∑ Èü≥ËßÜÈ¢ëÂÜÖÂÆπ‰∏ÄÈîÆÊÄªÁªìÔºöÂìîÂì©ÂìîÂì©‰∏®YouTube‰∏®Êí≠ÂÆ¢‰∏®‰ºöËÆÆ‰∏®Êú¨Âú∞Êñá‰ª∂Á≠â (Âéü BiliGPT ÁúÅÊµÅÁ•ûÂô® &amp; ËØæ‰ª£Ë°®)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ü§ñ BibiGPT ¬∑ Èü≥ËßÜÈ¢ëÂÜÖÂÆπ‰∏ÄÈîÆÊÄªÁªì &lt;a href=&#34;https://b.jimmylv.cn/&#34;&gt;b.jimmylv.cn&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;üéâ (Âéü BiliGPT)ÔºåÁé∞Â∑≤ÁªèÊîØÊåÅÔºöÂìîÂì©ÂìîÂì©‰∏® YouTube ËßÜÈ¢ëÂÜÖÂÆπ‰∏ÄÈîÆÊÄªÁªìÔºå‚ÄúÁúÅÊµÅÁ•ûÂô® &amp;amp; ËØæ‰ª£Ë°®‚Äù„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;üöß ÂºÄÂèë‰∏≠ÔºöÊîØÊåÅÊí≠ÂÆ¢‰∏®‰ºöËÆÆ‰∏®Êú¨Âú∞Èü≥ËßÜÈ¢ëÊñá‰ª∂Á≠âËæìÂÖ•ÔºåPrompt ÂíåËæìÂá∫Á´ØÂùáÂú®ÊåÅÁª≠Ëø≠‰ª£‰∏≠ÔºåÊï¨ËØ∑ÊúüÂæÖÔºÅ&lt;/p&gt; &#xA;&lt;p&gt;Â§áÁî®Âú∞ÂùÄÔºö&lt;a href=&#34;https://chat-bilibili-video.vercel.app&#34;&gt;https://chat-bilibili-video.vercel.app&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;üé¨ This project summarizes Bilibili/YouTube/Podcast/Meeting/... videos or audios for you using AI.&lt;/p&gt; &#xA;&lt;p&gt;ü§Ø Inspired by &lt;a href=&#34;https://github.com/Nutlope/news-summarizer&#34;&gt;Nutlope/news-summarizer&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://github.com/zhengbangbo/chat-simplifier/&#34;&gt;zhengbangbo/chat-simplifier&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://github.com/lxfater/BilibiliSummary&#34;&gt;lxfater/BilibiliSummary&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/Jimmy_JingLv/status/1630137750572728320?s=20&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JimmyLv/BibiGPT/main/public/BibiGPT.gif&#34; alt=&#34;BibiGPTÈü≥ËßÜÈ¢ëÊÄªÁªìÁ•ûÂô®&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;üöÄ First Launch: &lt;a href=&#34;https://www.bilibili.com/video/BV1fX4y1Q7Ux/?vd_source=dd5a650b0ad84edd0d54bb18196ecb86&#34;&gt;„ÄêBibiGPT„ÄëAI Ëá™Âä®ÊÄªÁªì B Á´ôËßÜÈ¢ëÂÜÖÂÆπÔºåGPT-3 Êô∫ËÉΩÊèêÂèñÂπ∂ÊÄªÁªìÂ≠óÂπï&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;How it works&lt;/h2&gt; &#xA;&lt;p&gt;This project uses the &lt;a href=&#34;https://openai.com/api/&#34;&gt;OpenAI ChatGPT API&lt;/a&gt; (specifically, gpt-3.5-turbo) and &lt;a href=&#34;https://vercel.com/features/edge-functions&#34;&gt;Vercel Edge functions&lt;/a&gt; with streaming and &lt;a href=&#34;https://console.upstash.com/&#34;&gt;Upstash&lt;/a&gt; for Redis cache and rate limiting. It fetches the content on a Bilibili video, sends it in a prompt to the GPT-3 API to summarize it via a Vercel Edge function, then streams the response back to the application.&lt;/p&gt; &#xA;&lt;h2&gt;Saving costs&lt;/h2&gt; &#xA;&lt;p&gt;Projects like this can get expensive so in order to save costs if you want to make your own version and share it publicly, I recommend three things:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 1. Implement rate limiting so people can&#39;t abuse your site&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 2. Implement caching to avoid expensive AI re-generations&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 3. Use &lt;code&gt;text-curie-001&lt;/code&gt; instead of &lt;code&gt;text-dacinci-003&lt;/code&gt; in the &lt;code&gt;summarize&lt;/code&gt; edge function&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Running Locally&lt;/h2&gt; &#xA;&lt;p&gt;After cloning the repo, go to &lt;a href=&#34;https://beta.openai.com/account/api-keys&#34;&gt;OpenAI&lt;/a&gt; to make an account and put your API key in a file called &lt;code&gt;.env&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Then, run the application in the command line and it will be available at &lt;code&gt;http://localhost:3000&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;One-Click Deploy&lt;/h2&gt; &#xA;&lt;p&gt;Deploy the example using &lt;a href=&#34;https://vercel.com?utm_source=github&amp;amp;utm_medium=readme&amp;amp;utm_campaign=vercel-examples&#34;&gt;Vercel&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://vercel.com/new/clone?repository-url=https://github.com/JimmyLv/BibiGPT&amp;amp;env=OPENAI_API_KEY&amp;amp;project-name=chat-bilibili-video&amp;amp;repo-name=chat-bilibili-video&#34;&gt;&lt;img src=&#34;https://vercel.com/button&#34; alt=&#34;Deploy with Vercel&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Support -&amp;gt; Contact Me&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JimmyLv/BibiGPT/main/public/wechat.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>mckaywrigley/paul-graham-gpt</title>
    <updated>2023-03-12T02:02:01Z</updated>
    <id>tag:github.com,2023-03-12:/mckaywrigley/paul-graham-gpt</id>
    <link href="https://github.com/mckaywrigley/paul-graham-gpt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AI search &amp; chat for all of Paul Graham‚Äôs essays.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Paul Graham GPT&lt;/h1&gt; &#xA;&lt;p&gt;AI-powered search and chat for &lt;a href=&#34;https://twitter.com/paulg&#34;&gt;Paul Graham&#39;s&lt;/a&gt; &lt;a href=&#34;http://www.paulgraham.com/articles.html&#34;&gt;essays&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;All code &amp;amp; data used is 100% open-source.&lt;/p&gt; &#xA;&lt;h2&gt;Dataset&lt;/h2&gt; &#xA;&lt;p&gt;The dataset is a CSV file containing all text &amp;amp; embeddings used.&lt;/p&gt; &#xA;&lt;p&gt;Download it &lt;a href=&#34;https://drive.google.com/file/d/1BxcPw2mn0VYFucc62wlt9H0nQiOu38ki/view?usp=sharing&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;I recommend getting familiar with fetching, cleaning, and storing data as outlined in the scraping and embedding scripts below, but feel free to skip those steps and just use the dataset.&lt;/p&gt; &#xA;&lt;h2&gt;How It Works&lt;/h2&gt; &#xA;&lt;p&gt;Paul Graham GPT provides 2 things:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;A search interface.&lt;/li&gt; &#xA; &lt;li&gt;A chat interface.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Search&lt;/h3&gt; &#xA;&lt;p&gt;Search was created with &lt;a href=&#34;https://platform.openai.com/docs/guides/embeddings&#34;&gt;OpenAI Embeddings&lt;/a&gt; (&lt;code&gt;text-embedding-ada-002&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;First, we loop over the essays and generate embeddings for each chunk of text.&lt;/p&gt; &#xA;&lt;p&gt;Then in the app we take the user&#39;s search query, generate an embedding, and use the result to find the most similar passages from the book.&lt;/p&gt; &#xA;&lt;p&gt;The comparison is done using cosine similarity across our database of vectors.&lt;/p&gt; &#xA;&lt;p&gt;Our database is a Postgres database with the &lt;a href=&#34;https://github.com/pgvector/pgvector&#34;&gt;pgvector&lt;/a&gt; extension hosted on &lt;a href=&#34;https://supabase.com/&#34;&gt;Supabase&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Results are ranked by similarity score and returned to the user.&lt;/p&gt; &#xA;&lt;h3&gt;Chat&lt;/h3&gt; &#xA;&lt;p&gt;Chat builds on top of search. It uses search results to create a prompt that is fed into GPT-3.5-turbo.&lt;/p&gt; &#xA;&lt;p&gt;This allows for a chat-like experience where the user can ask questions about the book and get answers.&lt;/p&gt; &#xA;&lt;h2&gt;Running Locally&lt;/h2&gt; &#xA;&lt;p&gt;Here&#39;s a quick overview of how to run it locally.&lt;/p&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Set up OpenAI&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You&#39;ll need an OpenAI API key to generate embeddings.&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Set up Supabase and create a database&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Note: You don&#39;t have to use Supabase. Use whatever method you prefer to store your data. But I like Supabase and think it&#39;s easy to use.&lt;/p&gt; &#xA;&lt;p&gt;There is a schema.sql file in the root of the repo that you can use to set up the database.&lt;/p&gt; &#xA;&lt;p&gt;Run that in the SQL editor in Supabase as directed.&lt;/p&gt; &#xA;&lt;p&gt;I recommend turning on Row Level Security and setting up a service role to use with the app.&lt;/p&gt; &#xA;&lt;h3&gt;Repo Setup&lt;/h3&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Clone repo&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/mckaywrigley/paul-graham-gpt.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Install dependencies&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm i&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;Set up environment variables&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Create a .env.local file in the root of the repo with the following variables:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;OPENAI_API_KEY=&#xA;&#xA;NEXT_PUBLIC_SUPABASE_URL=&#xA;SUPABASE_SERVICE_ROLE_KEY=&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Dataset&lt;/h3&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;Run scraping script&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run scrape&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This scrapes all of the essays from Paul Graham&#39;s website and saves them to a json file.&lt;/p&gt; &#xA;&lt;ol start=&#34;7&#34;&gt; &#xA; &lt;li&gt;Run embedding script&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run embed&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This reads the json file, generates embeddings for each chunk of text, and saves the results to your database.&lt;/p&gt; &#xA;&lt;p&gt;There is a 200ms delay between each request to avoid rate limiting.&lt;/p&gt; &#xA;&lt;p&gt;This process will take 20-30 minutes.&lt;/p&gt; &#xA;&lt;h3&gt;App&lt;/h3&gt; &#xA;&lt;ol start=&#34;8&#34;&gt; &#xA; &lt;li&gt;Run app&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;Thanks to &lt;a href=&#34;https://twitter.com/paulg&#34;&gt;Paul Graham&lt;/a&gt; for his writing.&lt;/p&gt; &#xA;&lt;p&gt;I highly recommend you read his essays.&lt;/p&gt; &#xA;&lt;p&gt;3 years ago they convinced me to learn to code, and it changed my life.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions, feel free to reach out to me on &lt;a href=&#34;https://twitter.com/mckaywrigley&#34;&gt;Twitter&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Notes&lt;/h2&gt; &#xA;&lt;p&gt;I sacrificed composability for simplicity in the app.&lt;/p&gt; &#xA;&lt;p&gt;Yes, you can make things more modular and reusable.&lt;/p&gt; &#xA;&lt;p&gt;But I kept pretty much everything in the homepage component for the sake of simplicity.&lt;/p&gt;</summary>
  </entry>
</feed>