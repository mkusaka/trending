<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub TypeScript Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-01T01:50:16Z</updated>
  <subtitle>Monthly Trending of TypeScript in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>enricoros/big-AGI</title>
    <updated>2024-05-01T01:50:16Z</updated>
    <id>tag:github.com,2024-05-01:/enricoros/big-AGI</id>
    <link href="https://github.com/enricoros/big-AGI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Generative AI suite powered by state-of-the-art models and providing advanced AI/AGI functions. It features AI personas, AGI functions, multi-model chats, text-to-image, voice, response streaming, code highlighting and execution, PDF import, presets for developers, much more. Deploy on-prem or in the cloud.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;BIG-AGI üß†‚ú®&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to big-AGI, the AI suite for professionals that need function, form, simplicity, and speed. Powered by the latest models from 12 vendors and open-source servers, &lt;code&gt;big-AGI&lt;/code&gt; offers best-in-class Chats, &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/470&#34;&gt;Beams&lt;/a&gt;, and &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/354&#34;&gt;Calls&lt;/a&gt; with AI personas, visualizations, coding, drawing, side-by-side chatting, and more -- all wrapped in a polished UX.&lt;/p&gt; &#xA;&lt;p&gt;Stay ahead of the curve with big-AGI. üöÄ Pros &amp;amp; Devs love big-AGI. ü§ñ&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://big-agi.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/BIG--AGI.com-%23096bde?style=for-the-badge&amp;amp;logo=vercel&amp;amp;label=launch&#34; alt=&#34;Official Website&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Or fork &amp;amp; run on Vercel&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fenricoros%2Fbig-AGI&amp;amp;env=OPENAI_API_KEY&amp;amp;envDescription=Backend%20API%20keys%2C%20optional%20and%20may%20be%20overridden%20by%20the%20UI.&amp;amp;envLink=https%3A%2F%2Fgithub.com%2Fenricoros%2Fbig-AGI%2Fblob%2Fmain%2Fdocs%2Fenvironment-variables.md&amp;amp;project-name=big-AGI&#34;&gt;&lt;img src=&#34;https://vercel.com/button&#34; alt=&#34;Deploy with Vercel&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üëâ &lt;a href=&#34;https://github.com/users/enricoros/projects/4/views/2&#34;&gt;roadmap&lt;/a&gt; üëâ &lt;a href=&#34;https://raw.githubusercontent.com/enricoros/big-AGI/main/docs/installation.md&#34;&gt;installation&lt;/a&gt; üëâ &lt;a href=&#34;https://raw.githubusercontent.com/enricoros/big-AGI/main/docs/README.md&#34;&gt;documentation&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h4&gt;What&#39;s New in 1.15.1 ¬∑ April 10, 2024 (minor release, models support)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Support for the newly released Gemini Pro 1.5 models&lt;/li&gt; &#xA; &lt;li&gt;Support for the new OpenAI 2024-04-09 Turbo models&lt;/li&gt; &#xA; &lt;li&gt;Ctrl+S and Ctrl+O to save/load chats on desktop&lt;/li&gt; &#xA; &lt;li&gt;Resilience fixes after the large success of 1.15.0&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: Beam-2 and new larger features are being cooked outside of &lt;code&gt;main&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;3,000 Commits Milestone ¬∑ April 7, 2024&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/enricoros/big-AGI/assets/32999/47fddbb1-9bd6-4b58-ace4-781dfcb80923&#34; alt=&#34;big-AGI Milestone&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ü•á Today we &lt;b&gt;celebrate commit 3000&lt;/b&gt; in just over one year, and going stronger üöÄ&lt;/li&gt; &#xA; &lt;li&gt;üì¢Ô∏è Thanks everyone for your support and words of love for Big-AGI, we are committed to creating the best AI experiences for everyone.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;What&#39;s New in 1.15.0 ¬∑ April 1, 2024 ¬∑ Beam&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚ö†Ô∏è &lt;a href=&#34;https://big-agi.com/blog/beam-multi-model-ai-reasoning&#34;&gt;&lt;strong&gt;Beam&lt;/strong&gt;: the multi-model AI chat&lt;/a&gt;. find better answers, faster - a game-changer for brainstorming, decision-making, and creativity. &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/443&#34;&gt;#443&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Managed Deployments &lt;strong&gt;Auto-Configuration&lt;/strong&gt;: simplify the UI models setup with backend-set models. &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/436&#34;&gt;#436&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Message &lt;strong&gt;Starring ‚≠ê&lt;/strong&gt;: star important messages within chats, to attach them later. &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/476&#34;&gt;#476&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Enhanced the default Persona&lt;/li&gt; &#xA; &lt;li&gt;Fixes to Gemini models and SVGs, improvements to UI and icons&lt;/li&gt; &#xA; &lt;li&gt;Beast release, over 430 commits, 10,000+ lines changed: &lt;a href=&#34;https://github.com/enricoros/big-AGI/releases/tag/v1.15.0&#34;&gt;release notes&lt;/a&gt;, and changes &lt;a href=&#34;https://github.com/enricoros/big-AGI/compare/v1.14.1...v1.15.0&#34;&gt;v1.14.1...v1.15.0&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;What&#39;s New in 1.14.1 ¬∑ March 7, 2024 ¬∑ Modelmorphic&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Anthropic&lt;/strong&gt; &lt;a href=&#34;https://www.anthropic.com/news/claude-3-family&#34;&gt;Claude-3&lt;/a&gt; model family support. &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/443&#34;&gt;#443&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;New &lt;strong&gt;&lt;a href=&#34;https://www.perplexity.ai/&#34;&gt;Perplexity&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&#34;https://groq.com/&#34;&gt;Groq&lt;/a&gt;&lt;/strong&gt; integration (thanks @Penagwin). &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/407&#34;&gt;#407&lt;/a&gt;, &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/427&#34;&gt;#427&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://localai.io/models/&#34;&gt;LocalAI&lt;/a&gt;&lt;/strong&gt; deep integration, including support for &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/411&#34;&gt;model galleries&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Mistral&lt;/strong&gt; Large and Google &lt;strong&gt;Gemini 1.5&lt;/strong&gt; support&lt;/li&gt; &#xA; &lt;li&gt;Performance optimizations: runs &lt;a href=&#34;https://twitter.com/enricoros/status/1756553038293303434?utm_source=localhost:3000&amp;amp;utm_medium=big-agi&#34;&gt;much faster&lt;/a&gt;, saves lots of power, reduces memory usage&lt;/li&gt; &#xA; &lt;li&gt;Enhanced UX with auto-sizing charts, refined search and folder functionalities, perfected scaling&lt;/li&gt; &#xA; &lt;li&gt;And with more UI improvements, documentation, bug fixes (20 tickets), and developer enhancements&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;What&#39;s New in 1.13.0 ¬∑ Feb 8, 2024 ¬∑ Multi + Mind&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/enricoros/big-AGI/assets/32999/01732528-730e-41dc-adc7-511385686b13&#34;&gt;https://github.com/enricoros/big-AGI/assets/32999/01732528-730e-41dc-adc7-511385686b13&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Side-by-Side Split Windows&lt;/strong&gt;: multitask with parallel conversations. &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/208&#34;&gt;#208&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi-Chat Mode&lt;/strong&gt;: message everyone, all at once. &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/388&#34;&gt;#388&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Export tables as CSV&lt;/strong&gt;: big thanks to @aj47. &lt;a href=&#34;https://github.com/enricoros/big-AGI/pull/392&#34;&gt;#392&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Adjustable text size: customize density. &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/399&#34;&gt;#399&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Dev2 Persona Technology Preview&lt;/li&gt; &#xA; &lt;li&gt;Better looking chats with improved spacing, fonts, and menus&lt;/li&gt; &#xA; &lt;li&gt;More: new video player, &lt;a href=&#34;https://github.com/enricoros/big-AGI/raw/main/docs/config-local-lmstudio.md&#34;&gt;LM Studio tutorial&lt;/a&gt; (thanks @aj47), &lt;a href=&#34;https://github.com/enricoros/big-AGI/raw/main/docs/deploy-database.md&#34;&gt;MongoDB support&lt;/a&gt; (thanks @ranfysvalle02), and speedups&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;What&#39;s New in 1.12.0 ¬∑ Jan 26, 2024 ¬∑ AGI Hotline&lt;/summary&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/enricoros/big-AGI/assets/32999/95ceb03c-945d-4fdd-9a9f-3317beb54f3f&#34;&gt;https://github.com/enricoros/big-AGI/assets/32999/95ceb03c-945d-4fdd-9a9f-3317beb54f3f&lt;/a&gt;&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Voice Calls&lt;/strong&gt;: real-time voice call your personas out of the blue or in relation to a chat &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/354&#34;&gt;#354&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Support &lt;strong&gt;OpenAI 0125&lt;/strong&gt; Models. &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/364&#34;&gt;#364&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Rename or Auto-Rename chats. &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/222&#34;&gt;#222&lt;/a&gt;, &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/360&#34;&gt;#360&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;More control over &lt;strong&gt;Link Sharing&lt;/strong&gt; &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/356&#34;&gt;#356&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Accessibility&lt;/strong&gt; to screen readers &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/358&#34;&gt;#358&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Export chats to Markdown &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/337&#34;&gt;#337&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Paste tables from Excel &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/286&#34;&gt;#286&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Ollama model updates and context window detection fixes &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/309&#34;&gt;#309&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;What&#39;s New in 1.11.0 ¬∑ Jan 16, 2024 ¬∑ Singularity&lt;/summary&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/enricoros/big-AGI/assets/1590910/a6b8e172-0726-4b03-a5e5-10cfcb110c68&#34;&gt;https://github.com/enricoros/big-AGI/assets/1590910/a6b8e172-0726-4b03-a5e5-10cfcb110c68&lt;/a&gt;&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Find chats&lt;/strong&gt;: search in titles and content, with frequency ranking. &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/329&#34;&gt;#329&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Commands&lt;/strong&gt;: command auto-completion (type &#39;/&#39;). &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/327&#34;&gt;#327&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://www.together.ai/products#inference&#34;&gt;Together AI&lt;/a&gt;&lt;/strong&gt; inference platform support (good speed and newer models). &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/346&#34;&gt;#346&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Persona Creator history, deletion, custom creation, fix llm API timeouts&lt;/li&gt; &#xA;  &lt;li&gt;Enable adding up to five custom OpenAI-compatible endpoints&lt;/li&gt; &#xA;  &lt;li&gt;Developer enhancements: new &#39;Actiles&#39; framework&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;What&#39;s New in 1.10.0 ¬∑ Jan 6, 2024 ¬∑ The Year of AGI&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;New UI&lt;/strong&gt;: for both desktop and mobile, sets the stage for future scale. &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/201&#34;&gt;#201&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Conversation Folders&lt;/strong&gt;: enhanced conversation organization. &lt;a href=&#34;https://github.com/enricoros/big-AGI/issues/321&#34;&gt;#321&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://lmstudio.ai/&#34;&gt;LM Studio&lt;/a&gt;&lt;/strong&gt; support and improved token management&lt;/li&gt; &#xA;  &lt;li&gt;Resizable panes in split-screen conversations.&lt;/li&gt; &#xA;  &lt;li&gt;Large performance optimizations&lt;/li&gt; &#xA;  &lt;li&gt;Developer enhancements: new UI framework, updated documentation for proxy settings on browserless/docker&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;For full details and former releases, check out the &lt;a href=&#34;https://raw.githubusercontent.com/enricoros/big-AGI/main/docs/changelog.md&#34;&gt;changelog&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üëâ Key Features ‚ú®&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;img src=&#34;https://img.shields.io/badge/Advanced%20AI-32383e?style=for-the-badge&amp;amp;logo=ai&amp;amp;logoColor=white&#34; alt=&#34;Advanced AI&#34;&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;img src=&#34;https://img.shields.io/badge/100%2B%20AI%20Models-32383e?style=for-the-badge&amp;amp;logo=ai&amp;amp;logoColor=white&#34; alt=&#34;100+ AI Models&#34;&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;img src=&#34;https://img.shields.io/badge/Flow--state%20UX-32383e?style=for-the-badge&amp;amp;logo=flow&amp;amp;logoColor=white&#34; alt=&#34;Flow-state UX&#34;&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;img src=&#34;https://img.shields.io/badge/Privacy%20First-32383e?style=for-the-badge&amp;amp;logo=privacy&amp;amp;logoColor=white&#34; alt=&#34;Privacy First&#34;&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;img src=&#34;https://img.shields.io/badge/Fun%20To%20Use-f22a85?style=for-the-badge&amp;amp;logo=tools&amp;amp;logoColor=white&#34; alt=&#34;Advanced Tools&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Chat&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;Call&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;Beam&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;Draw&lt;/strong&gt;, ...&lt;/td&gt; &#xA;   &lt;td&gt;Local &amp;amp; Cloud&lt;br&gt;Open &amp;amp; Closed&lt;br&gt;Cheap &amp;amp; Heavy&lt;br&gt;Google, Mistral, ...&lt;/td&gt; &#xA;   &lt;td&gt;Attachments&lt;br&gt;Diagrams&lt;br&gt;Multi-Chat&lt;br&gt;Mobile-first UI&lt;/td&gt; &#xA;   &lt;td&gt;Stored Locally&lt;br&gt;Easy self-Host&lt;br&gt;Local actions&lt;br&gt;Data = Gold&lt;/td&gt; &#xA;   &lt;td&gt;AI Personas&lt;br&gt;Voice Modes&lt;br&gt;Screen Capture&lt;br&gt;Camera + OCR&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/enricoros/big-AGI/main/docs/pixels/big-AGI-compo-20240201_small.png&#34; alt=&#34;big-AGI screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can easily configure 100s of AI models in big-AGI:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;strong&gt;AI models&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;em&gt;supported vendors&lt;/em&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Opensource Servers&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://localai.com&#34;&gt;LocalAI&lt;/a&gt; (multimodal) ¬∑ &lt;a href=&#34;https://ollama.com/&#34;&gt;Ollama&lt;/a&gt; ¬∑ &lt;a href=&#34;https://github.com/oobabooga/text-generation-webui&#34;&gt;Oobabooga&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Local Servers&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://lmstudio.ai/&#34;&gt;LM Studio&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Multimodal services&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/ai-services/openai-service&#34;&gt;Azure&lt;/a&gt; ¬∑ &lt;a href=&#34;https://ai.google.dev/&#34;&gt;Google Gemini&lt;/a&gt; ¬∑ &lt;a href=&#34;https://platform.openai.com/docs/overview&#34;&gt;OpenAI&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Language services&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://anthropic.com&#34;&gt;Anthropic&lt;/a&gt; ¬∑ &lt;a href=&#34;https://wow.groq.com/&#34;&gt;Groq&lt;/a&gt; ¬∑ &lt;a href=&#34;https://mistral.ai/&#34;&gt;Mistral&lt;/a&gt; ¬∑ &lt;a href=&#34;https://openrouter.ai/&#34;&gt;OpenRouter&lt;/a&gt; ¬∑ &lt;a href=&#34;https://www.perplexity.ai/&#34;&gt;Perplexity&lt;/a&gt; ¬∑ &lt;a href=&#34;https://www.together.ai/&#34;&gt;Together AI&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Image services&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://prodia.com/&#34;&gt;Prodia&lt;/a&gt; (SDXL)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Speech services&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://elevenlabs.io&#34;&gt;ElevenLabs&lt;/a&gt; (Voice synthesis / cloning)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Add extra functionality with these integrations:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;strong&gt;More&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;em&gt;integrations&lt;/em&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Web Browse&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://www.browserless.io/&#34;&gt;Browserless&lt;/a&gt; ¬∑ &lt;a href=&#34;https://pptr.dev/&#34;&gt;Puppeteer&lt;/a&gt;-based&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Web Search&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://programmablesearchengine.google.com/&#34;&gt;Google CSE&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Code Editors&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://codepen.io/pen/&#34;&gt;CodePen&lt;/a&gt; ¬∑ &lt;a href=&#34;https://stackblitz.com/&#34;&gt;StackBlitz&lt;/a&gt; ¬∑ &lt;a href=&#34;https://jsfiddle.net/&#34;&gt;JSFiddle&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Sharing&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://paste.gg/&#34;&gt;Paste.gg&lt;/a&gt; (Paste chats)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Tracking&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://www.helicone.ai&#34;&gt;Helicone&lt;/a&gt; (LLM Observability)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üöÄ Installation&lt;/h2&gt; &#xA;&lt;p&gt;To get started with big-AGI, follow our comprehensive &lt;a href=&#34;https://raw.githubusercontent.com/enricoros/big-AGI/main/docs/installation.md&#34;&gt;Installation Guide&lt;/a&gt;. The guide covers various installation options, whether you&#39;re spinning it up on your local computer, deploying on Vercel, on Cloudflare, or rolling it out through Docker.&lt;/p&gt; &#xA;&lt;p&gt;Whether you&#39;re a developer, system integrator, or enterprise user, you&#39;ll find step-by-step instructions to set up big-AGI quickly and easily.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/enricoros/big-AGI/main/docs/installation.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Installation%20Guide-blue?style=for-the-badge&amp;amp;logo=read-the-docs&amp;amp;logoColor=white&#34; alt=&#34;Installation Guide&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Or bring your API keys and jump straight into our free instance on &lt;a href=&#34;https://big-agi.com&#34;&gt;big-AGI.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;üåü Get Involved!&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/MkH4qj2Jp9&#34;&gt;&lt;img src=&#34;https://discordapp.com/api/guilds/1098796266906980422/widget.png?style=banner2&#34; alt=&#34;Official Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; üì¢Ô∏è &lt;a href=&#34;https://discord.gg/MkH4qj2Jp9&#34;&gt;&lt;strong&gt;Chat with us&lt;/strong&gt; on Discord&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; ‚≠ê &lt;strong&gt;Give us a star&lt;/strong&gt; on GitHub üëÜ&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; üöÄ &lt;strong&gt;Do you like code&lt;/strong&gt;? You&#39;ll love this gem of a project! &lt;a href=&#34;https://github.com/users/enricoros/projects/4/views/4&#34;&gt;&lt;em&gt;Pick up a task!&lt;/em&gt;&lt;/a&gt; - &lt;em&gt;easy&lt;/em&gt; to &lt;em&gt;pro&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; üí° Got a feature suggestion? &lt;a href=&#34;https://github.com/enricoros/big-agi/issues/new?&amp;amp;template=roadmap-request.md&#34;&gt;&lt;em&gt;Add your roadmap ideas&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; ‚ú® &lt;a href=&#34;https://raw.githubusercontent.com/enricoros/big-AGI/main/docs/installation.md&#34;&gt;Deploy&lt;/a&gt; your &lt;a href=&#34;https://raw.githubusercontent.com/enricoros/big-AGI/main/docs/customizations.md&#34;&gt;fork&lt;/a&gt; for your friends and family, or &lt;a href=&#34;https://raw.githubusercontent.com/enricoros/big-AGI/main/docs/customizations.md&#34;&gt;customize it for work&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;2023-2024 ¬∑ Enrico Ros x &lt;a href=&#34;https://big-agi.com&#34;&gt;big-AGI&lt;/a&gt; ¬∑ License: &lt;a href=&#34;https://raw.githubusercontent.com/enricoros/big-AGI/main/LICENSE&#34;&gt;MIT&lt;/a&gt; ¬∑ Made with üíô&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>langfuse/langfuse</title>
    <updated>2024-05-01T01:50:16Z</updated>
    <id>tag:github.com,2024-05-01:/langfuse/langfuse</id>
    <link href="https://github.com/langfuse/langfuse" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ü™¢ Open source LLM engineering platform: Observability, metrics, evals, prompt management, playground, datasets. Integrates with LlamaIndex, Langchain, OpenAI SDK, LiteLLM, and more. üçäYC W23&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://github.com/langfuse/langfuse/assets/121163007/6035f0f3-d691-4963-b5d0-10cf506e9d42&#34; alt=&#34;Langfuse GitHub Banner&#34;&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;div&gt; &#xA;  &lt;h3&gt; &lt;a href=&#34;https://cloud.langfuse.com&#34;&gt; &lt;strong&gt;Sign up&lt;/strong&gt; &lt;/a&gt; ¬∑ &lt;a href=&#34;https://langfuse.com/docs/deployment/self-host&#34;&gt; &lt;strong&gt;Self Host&lt;/strong&gt; &lt;/a&gt; ¬∑ &lt;a href=&#34;https://langfuse.com/demo&#34;&gt; &lt;strong&gt;Demo (live data)&lt;/strong&gt; &lt;/a&gt; &lt;/h3&gt; &#xA; &lt;/div&gt; &#xA; &lt;div&gt; &#xA;  &lt;a href=&#34;https://langfuse.com/docs&#34;&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/a&gt; ¬∑ &#xA;  &lt;a href=&#34;https://langfuse.com/issues&#34;&gt;&lt;strong&gt;Report Bug&lt;/strong&gt;&lt;/a&gt; ¬∑ &#xA;  &lt;a href=&#34;https://langfuse.com/ideas&#34;&gt;&lt;strong&gt;Feature Request&lt;/strong&gt;&lt;/a&gt; ¬∑ &#xA;  &lt;a href=&#34;https://langfuse.com/changelog&#34;&gt;&lt;strong&gt;Changelog&lt;/strong&gt;&lt;/a&gt; ¬∑ &#xA;  &lt;a href=&#34;https://langfuse.com/roadmap&#34;&gt;&lt;strong&gt;Roadmap&lt;/strong&gt;&lt;/a&gt; ¬∑ &#xA;  &lt;a href=&#34;https://langfuse.com/discord&#34;&gt;&lt;strong&gt;Discord&lt;/strong&gt;&lt;/a&gt; &#xA; &lt;/div&gt; &#xA; &lt;span&gt;Langfuse uses &lt;a href=&#34;https://github.com/orgs/langfuse/discussions&#34;&gt;&lt;strong&gt;Github Discussions&lt;/strong&gt;&lt;/a&gt; for Support and Feature Requests.&lt;/span&gt; &#xA; &lt;br&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt; &#xA;  &lt;a href=&#34;https://github.com/langfuse/langfuse/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-red.svg?style=flat-square&#34; alt=&#34;MIT License&#34;&gt;&lt;/a&gt; &#xA;  &lt;a href=&#34;https://www.ycombinator.com/companies/langfuse&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Y%20Combinator-W23-orange?style=flat-square&#34; alt=&#34;Y Combinator W23&#34;&gt;&lt;/a&gt; &#xA;  &lt;a href=&#34;https://github.com/langfuse/langfuse/pkgs/container/langfuse&#34;&gt;&lt;img alt=&#34;Docker Image&#34; src=&#34;https://img.shields.io/badge/docker-langfuse-blue?logo=Docker&amp;amp;logoColor=white&amp;amp;style=flat-square&#34;&gt;&lt;/a&gt; &#xA;  &lt;a href=&#34;https://www.npmjs.com/package/langfuse&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/langfuse?style=flat-square&amp;amp;label=npm+langfuse&#34; alt=&#34;langfuse npm package&#34;&gt;&lt;/a&gt; &#xA;  &lt;a href=&#34;https://pypi.python.org/pypi/langfuse&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/langfuse.svg?style=flat-square&amp;amp;label=pypi+langfuse&#34; alt=&#34;langfuse Python package on PyPi&#34;&gt;&lt;/a&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;Unmute video for voice-over&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/langfuse/langfuse/assets/2834609/a94062e9-c782-4ee9-af59-dee6370149a8&#34;&gt;https://github.com/langfuse/langfuse/assets/2834609/a94062e9-c782-4ee9-af59-dee6370149a8&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Develop&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Observability:&lt;/strong&gt; Instrument your app and start ingesting traces to Langfuse (&lt;a href=&#34;https://langfuse.com/docs/get-started&#34;&gt;Quickstart&lt;/a&gt;, &lt;a href=&#34;https://langfuse.com/docs/integrations&#34;&gt;Integrations&lt;/a&gt; &lt;a href=&#34;https://langfuse.com/docs/tracing&#34;&gt;Tracing&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Langfuse UI:&lt;/strong&gt; Inspect and debug complex logs (&lt;a href=&#34;https://langfuse.com/docs/demo&#34;&gt;Demo&lt;/a&gt;, &lt;a href=&#34;https://langfuse.com/docs/tracing&#34;&gt;Tracing&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Prompt Management:&lt;/strong&gt; Manage, version and deploy prompts from within Langfuse (&lt;a href=&#34;https://langfuse.com/docs/prompts/get-started&#34;&gt;Prompt Management&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Prompt Engineering:&lt;/strong&gt; Test and iterate on your prompts with the &lt;a href=&#34;https://langfuse.com/docs/playground&#34;&gt;LLM Playground&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Monitor&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Analytics:&lt;/strong&gt; Track metrics (cost, latency, quality) and gain insights from dashboards &amp;amp; data exports (&lt;a href=&#34;https://langfuse.com/docs/analytics&#34;&gt;Analytics&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Evals:&lt;/strong&gt; Collect and calculate scores for your LLM completions (&lt;a href=&#34;https://langfuse.com/docs/scores&#34;&gt;Scores &amp;amp; Evaluations&lt;/a&gt;) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Run model-based evaluations (&lt;a href=&#34;https://langfuse.com/docs/scores/model-based-evals&#34;&gt;Model-based evaluations&lt;/a&gt;) within Langfuse&lt;/li&gt; &#xA;   &lt;li&gt;Collect user feedback (&lt;a href=&#34;https://langfuse.com/docs/scores/user-feedback&#34;&gt;User Feedback&lt;/a&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;Manually score observations in Langfuse (&lt;a href=&#34;https://langfuse.com/docs/scores/manually&#34;&gt;Manual Scores&lt;/a&gt;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Test&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Experiments:&lt;/strong&gt; Track and test app behaviour before deploying a new version &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Datasets let you test expected in and output pairs and benchmark performance before deploying (&lt;a href=&#34;https://langfuse.com/docs/datasets&#34;&gt;Datasets&lt;/a&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;Track versions and releases in your application (&lt;a href=&#34;https://langfuse.com/docs/experimentation&#34;&gt;Experimentation&lt;/a&gt;, &lt;a href=&#34;https://langfuse.com/docs/prompts&#34;&gt;Prompt Management&lt;/a&gt;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Get started&lt;/h2&gt; &#xA;&lt;h3&gt;Langfuse Cloud&lt;/h3&gt; &#xA;&lt;p&gt;Managed deployment by the Langfuse team, generous free-tier (hobby plan), no credit card required.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://cloud.langfuse.com&#34;&gt;¬ª Langfuse Cloud&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Localhost (docker)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Clone repository&#xA;git clone https://github.com/langfuse/langfuse.git&#xA;cd langfuse&#xA;&#xA;# Run server and database&#xA;docker compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://langfuse.com/docs/deployment/local&#34;&gt;‚Üí Learn more about deploying locally&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Self-host (docker)&lt;/h3&gt; &#xA;&lt;p&gt;Langfuse is simple to self-host and keep updated. It currently requires only a single docker container. &lt;a href=&#34;https://langfuse.com/docs/deployment/self-host&#34;&gt;‚Üí Self Hosting Instructions&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Templated deployments: &lt;a href=&#34;https://langfuse.com/docs/deployment/self-host#platform-specific-information&#34;&gt;Railway, GCP Cloud Run, AWS Fargate, Kubernetes and others&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;h3&gt;API Keys&lt;/h3&gt; &#xA;&lt;p&gt;You need a Langfuse public and secret key to get started. Sign up &lt;a href=&#34;https://cloud.langfuse.com&#34;&gt;here&lt;/a&gt; and find them in your project settings.&lt;/p&gt; &#xA;&lt;h3&gt;Ingesting Data ¬∑ Instrumenting Your Application&lt;/h3&gt; &#xA;&lt;p&gt;Note: We recommend using our fully async, typed &lt;a href=&#34;https://langfuse.com/docs/sdk&#34;&gt;SDKs&lt;/a&gt; that allow you to instrument any LLM application with any underlying model. They are available in &lt;a href=&#34;https://langfuse.com/docs/sdk/python&#34;&gt;Python (Decorators)&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://langfuse.com/docs/sdk/typescript&#34;&gt;JS/TS&lt;/a&gt;. The SDKs will always be the most fully featured and stable way to ingest data into Langfuse.&lt;/p&gt; &#xA;&lt;p&gt;You may want to use another integration to get started quickly or implement a use case that we do not yet support. However, we recommend to migrate to the Langfuse SDKs over time to ensure performance and stability.&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://langfuse.com/docs/get-started&#34;&gt;‚Üí Quickstart&lt;/a&gt; to integrate Langfuse.&lt;/p&gt; &#xA;&lt;h3&gt;Integrations&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Integration&lt;/th&gt; &#xA;   &lt;th&gt;Supports&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://langfuse.com/docs/sdk&#34;&gt;&lt;strong&gt;SDK&lt;/strong&gt; - &lt;em&gt;recommended&lt;/em&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Python, JS/TS&lt;/td&gt; &#xA;   &lt;td&gt;Manual instrumentation using the SDKs for full flexibility.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://langfuse.com/docs/integrations/openai&#34;&gt;OpenAI SDK&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Python, JS/TS&lt;/td&gt; &#xA;   &lt;td&gt;Automated instrumentation of OpenAI SDK.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://langfuse.com/docs/integrations/langchain&#34;&gt;Langchain&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Python, JS/TS&lt;/td&gt; &#xA;   &lt;td&gt;Instrumentation via Langchain callbacks.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://langfuse.com/docs/integrations/llama-index&#34;&gt;LlamaIndex&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Python&lt;/td&gt; &#xA;   &lt;td&gt;Automated instrumentation via LlamaIndex callback system.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://langfuse.com/docs/api&#34;&gt;API&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Directly call the public API. OpenAPI spec available.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;External projects/packages that integrate with Langfuse:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://langfuse.com/docs/integrations/litellm&#34;&gt;LiteLLM&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Use any LLM as a drop in replacement for GPT. Use Azure, OpenAI, Cohere, Anthropic, Ollama, VLLM, Sagemaker, HuggingFace, Replicate (100+ LLMs).&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://langfuse.com/docs/integrations/flowise&#34;&gt;Flowise&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;JS/TS no-code builder for customized LLM flows.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://langfuse.com/docs/integrations/langflow&#34;&gt;Langflow&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Python-based UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://langfuse.com/docs/integrations/superagent&#34;&gt;Superagent&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Open Source AI Assistant Framework &amp;amp; API for prototyping and deployment of agents.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Questions and feedback&lt;/h2&gt; &#xA;&lt;h3&gt;Ideas and roadmap&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/orgs/langfuse/discussions&#34;&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://langfuse.com/idea&#34;&gt;Feature Requests&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://langfuse.com/roadmap&#34;&gt;Roadmap&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Support and feedback&lt;/h3&gt; &#xA;&lt;p&gt;In order of preference the best way to communicate with us:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/orgs/langfuse/discussions&#34;&gt;GitHub Discussions&lt;/a&gt;: Contribute &lt;a href=&#34;https://langfuse.com/idea&#34;&gt;ideas&lt;/a&gt; &lt;a href=&#34;https://github.com/orgs/langfuse/discussions/categories/support&#34;&gt;support requests&lt;/a&gt; and &lt;a href=&#34;https://github.com/langfuse/langfuse/issues/new?labels=%F0%9F%90%9E%E2%9D%94+unconfirmed+bug&amp;amp;projects=&amp;amp;template=bug_report.yml&amp;amp;title=bug%3A+&#34;&gt;report bugs&lt;/a&gt; (preferred as we create a permanent, indexed artifact for other community members)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://langfuse.com/discord&#34;&gt;Discord&lt;/a&gt;: community support&lt;/li&gt; &#xA; &lt;li&gt;Privately: contact at langfuse dot com&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing to Langfuse&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Vote on &lt;a href=&#34;https://github.com/orgs/langfuse/discussions/categories/ideas&#34;&gt;Ideas&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Raise and comment on &lt;a href=&#34;https://github.com/langfuse/langfuse/issues&#34;&gt;Issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Open a PR - see &lt;a href=&#34;https://raw.githubusercontent.com/langfuse/langfuse/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for details on how to setup a development environment.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This repository is MIT licensed, except for the &lt;code&gt;ee&lt;/code&gt; folders. See &lt;a href=&#34;https://raw.githubusercontent.com/langfuse/langfuse/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; and &lt;a href=&#34;https://langfuse.com/docs/open-source&#34;&gt;docs&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Misc&lt;/h2&gt; &#xA;&lt;h3&gt;GET API to export your data&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://langfuse.com/docs/integrations/api&#34;&gt;&lt;strong&gt;GET routes&lt;/strong&gt;&lt;/a&gt; to use data in downstream applications (e.g. embedded analytics).&lt;/p&gt; &#xA;&lt;h3&gt;Security &amp;amp; Privacy&lt;/h3&gt; &#xA;&lt;p&gt;We take data security and privacy seriously. Please refer to our &lt;a href=&#34;https://langfuse.com/security&#34;&gt;Security and Privacy&lt;/a&gt; page for more information.&lt;/p&gt; &#xA;&lt;h3&gt;Telemetry&lt;/h3&gt; &#xA;&lt;p&gt;By default, Langfuse automatically reports basic usage statistics of self-hosted instances to a centralized server (PostHog).&lt;/p&gt; &#xA;&lt;p&gt;This helps us to:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Understand how Langfuse is used and improve the most relevant features.&lt;/li&gt; &#xA; &lt;li&gt;Track overall usage for internal and external (e.g. fundraising) reporting.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;None of the data is shared with third parties and does not include any sensitive information. We want to be super transparent about this and you can find the exact data we collect &lt;a href=&#34;https://raw.githubusercontent.com/langfuse/langfuse/main/web/src/features/telemetry/index.ts&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can opt-out by setting &lt;code&gt;TELEMETRY_ENABLED=false&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>developersdigest/llm-answer-engine</title>
    <updated>2024-05-01T01:50:16Z</updated>
    <id>tag:github.com,2024-05-01:/developersdigest/llm-answer-engine</id>
    <link href="https://github.com/developersdigest/llm-answer-engine" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Build a Perplexity-Inspired Answer Engine Using Next.js, Groq, Mixtral, Langchain, OpenAI, Brave &amp; Serper&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;Perplexity-Inspired LLM Answer Engine&lt;/h1&gt; &#xA;&lt;div&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;a href=&#34;https://twitter.com/dev__digest&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/X/Twitter-000000?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white&#34;&gt; &lt;/a&gt; &#xA;  &lt;a href=&#34;https://www.youtube.com/@developersdigest&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/YouTube-FF0000?style=for-the-badge&amp;amp;logo=youtube&amp;amp;logoColor=white&#34;&gt; &lt;/a&gt; &#xA; &lt;/div&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;a href=&#34;https://trendshift.io/repositories/8642&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://trendshift.io/api/badge/repositories/8642&#34; alt=&#34;developersdigest%2Fllm-answer-engine | Trendshift&#34; style=&#34;width: 250px; height: 55px;&#34; width=&#34;250&#34; height=&#34;55&#34;&gt;&lt;/a&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExcjVodHcyZWd0MDJtd2RiN2xqbGdtOTdrYzZiMnhlMmZidDRzYm15dSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/PXkHjFlbgty03C6TAL/giphy.gif&#34;&gt;&#xA; &lt;br&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;This repository contains the code and instructions needed to build a sophisticated answer engine that leverages the capabilities of &lt;a href=&#34;https://www.groq.com/&#34;&gt;Groq&lt;/a&gt;, &lt;a href=&#34;https://mistral.ai/news/mixtral-of-experts/&#34;&gt;Mistral AI&#39;s Mixtral&lt;/a&gt;, &lt;a href=&#34;https://js.langchain.com/docs/&#34;&gt;Langchain.JS&lt;/a&gt;, &lt;a href=&#34;https://search.brave.com/&#34;&gt;Brave Search&lt;/a&gt;, &lt;a href=&#34;https://serper.dev/&#34;&gt;Serper API&lt;/a&gt;, and &lt;a href=&#34;https://openai.com/&#34;&gt;OpenAI&lt;/a&gt;. Designed to efficiently return sources, answers, images, videos, and follow-up questions based on user queries, this project is an ideal starting point for developers interested in natural language processing and search technologies.&lt;/p&gt; &#xA;&lt;h2&gt;YouTube Tutorials&lt;/h2&gt; &#xA;&lt;div style=&#34;display: flex; justify-content: space-between;&#34;&gt; &#xA; &lt;div style=&#34;text-align: center;&#34;&gt; &#xA;  &lt;a href=&#34;https://youtu.be/kFC-OWw7G8k&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/43ZCeBTcsS8/0.jpg&#34; alt=&#34;Tutorial 2&#34; style=&#34;max-height: 150px;&#34;&gt;&lt;br&gt; &lt;span style=&#34;font-size: 12px;&#34;&gt;Build a Perplexity-Inspired Answer Engine Using Groq, Mixtral, Langchain, Brave &amp;amp; OpenAI in 10 Min&lt;/span&gt; &lt;/a&gt; &#xA; &lt;/div&gt; &#xA; &lt;div style=&#34;text-align: center;&#34;&gt; &#xA;  &lt;a href=&#34;https://youtu.be/43ZCeBTcsS8&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/kFC-OWw7G8k/0.jpg&#34; alt=&#34;Tutorial 1&#34; style=&#34;max-height: 150px;&#34;&gt;&lt;br&gt; &lt;span style=&#34;font-size: 12px;&#34;&gt;Build a Next.JS Answer Engine with Vercel AI SDK, Groq, Mistral, Langchain, OpenAI, Brave &amp;amp; Serper&lt;/span&gt; &lt;/a&gt; &#xA; &lt;/div&gt; &#xA; &lt;div style=&#34;text-align: center;&#34;&gt; &#xA;  &lt;a href=&#34;https://youtu.be/kV2U7ttqE-g&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/kV2U7ttqE-g/0.jpg&#34; alt=&#34;Tutorial 3&#34; style=&#34;max-height: 150px;&#34;&gt;&lt;br&gt; &lt;span style=&#34;font-size: 12px;&#34;&gt;Answer Engine: Groq Function Calling - Next.js, AI SDK, Mixtral, Langchain, OpenAI, Brave &amp;amp; Serper&lt;/span&gt; &lt;/a&gt; &#xA; &lt;/div&gt; &#xA; &lt;div style=&#34;text-align: center;&#34;&gt; &#xA;  &lt;a href=&#34;https://youtu.be/3_aNVu6EU3Y&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/3_aNVu6EU3Y/0.jpg&#34; alt=&#34;Tutorial 4&#34; style=&#34;max-height: 150px;&#34;&gt;&lt;br&gt; &lt;span style=&#34;font-size: 12px;&#34;&gt;Answer Engine: How to Set up Rate Limiting in Next.JS with Upstash Redis&lt;/span&gt; &lt;/a&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Technologies Used&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Next.js&lt;/strong&gt;: A React framework for building server-side rendered and static web applications.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Tailwind CSS&lt;/strong&gt;: A utility-first CSS framework for rapidly building custom user interfaces.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Vercel AI SDK&lt;/strong&gt;: The Vercel AI SDK is a library for building AI-powered streaming text and chat UIs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Groq &amp;amp; Mixtral&lt;/strong&gt;: Technologies for processing and understanding user queries.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Langchain.JS&lt;/strong&gt;: A JavaScript library focused on text operations, such as text splitting and embeddings.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Brave Search&lt;/strong&gt;: A privacy-focused search engine used for sourcing relevant content and images.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Serper API&lt;/strong&gt;: Used for fetching relevant video and image results based on the user&#39;s query.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;OpenAI Embeddings&lt;/strong&gt;: Used for creating vector representations of text chunks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Cheerio&lt;/strong&gt;: Utilized for HTML parsing, allowing the extraction of content from web pages.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Ollama (Optional)&lt;/strong&gt;: Used for streaming inference and embeddings.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Upstash Redis Rate Limiting (Optional)&lt;/strong&gt;: Used for setting up rate limiting for the application.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ensure Node.js and npm are installed on your machine.&lt;/li&gt; &#xA; &lt;li&gt;Obtain API keys from OpenAI, Groq, Brave Search, and Serper.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Obtaining API Keys&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;OpenAI API Key&lt;/strong&gt;: &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;Generate your OpenAI API key here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Groq API Key&lt;/strong&gt;: &lt;a href=&#34;https://console.groq.com/keys&#34;&gt;Get your Groq API key here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Brave Search API Key&lt;/strong&gt;: &lt;a href=&#34;https://brave.com/search/api/&#34;&gt;Obtain your Brave Search API key here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Serper API Key&lt;/strong&gt;: &lt;a href=&#34;https://serper.dev/&#34;&gt;Get your Serper API key here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repository: &lt;pre&gt;&lt;code&gt;git clone https://github.com/developersdigest/llm-answer-engine.git&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Install the required dependencies: &lt;pre&gt;&lt;code&gt;npm install&#xA;&lt;/code&gt;&lt;/pre&gt; or &lt;pre&gt;&lt;code&gt;bun install&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the root of your project and add your API keys: &lt;pre&gt;&lt;code&gt;OPENAI_API_KEY=your_openai_api_key&#xA;GROQ_API_KEY=your_groq_api_key&#xA;BRAVE_SEARCH_API_KEY=your_brave_search_api_key&#xA;SERPER_API=your_serper_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Running the Server&lt;/h3&gt; &#xA;&lt;p&gt;To start the server, execute:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;bun run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;the server will be listening on the specified port.&lt;/p&gt; &#xA;&lt;h2&gt;Editing the Configuration&lt;/h2&gt; &#xA;&lt;p&gt;The configuration file is located in the &lt;code&gt;app/config.tsx&lt;/code&gt; file. You can modify the following values&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;useOllamaInference: false,&lt;/li&gt; &#xA; &lt;li&gt;useOllamaEmbeddings: false,&lt;/li&gt; &#xA; &lt;li&gt;inferenceModel: &#39;mixtral-8x7b-32768&#39;,&lt;/li&gt; &#xA; &lt;li&gt;inferenceAPIKey: process.env.GROQ_API_KEY,&lt;/li&gt; &#xA; &lt;li&gt;embeddingsModel: &#39;text-embedding-3-small&#39;,&lt;/li&gt; &#xA; &lt;li&gt;textChunkSize: 800,&lt;/li&gt; &#xA; &lt;li&gt;textChunkOverlap: 200,&lt;/li&gt; &#xA; &lt;li&gt;numberOfSimilarityResults: 2,&lt;/li&gt; &#xA; &lt;li&gt;numberOfPagesToScan: 10,&lt;/li&gt; &#xA; &lt;li&gt;nonOllamaBaseURL: &#39;&lt;a href=&#34;https://api.groq.com/openai/v1&#34;&gt;https://api.groq.com/openai/v1&lt;/a&gt;&#39;&lt;/li&gt; &#xA; &lt;li&gt;useFunctionCalling: true&lt;/li&gt; &#xA; &lt;li&gt;useRateLimiting: false&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Function Calling Support (Beta)&lt;/h3&gt; &#xA;&lt;p&gt;Currently, function calling is supported with the following capabilities:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Maps and Locations (Serper Locations API)&lt;/li&gt; &#xA; &lt;li&gt;Shopping (Serper Shopping API)&lt;/li&gt; &#xA; &lt;li&gt;TradingView Stock Data (Free Widget)&lt;/li&gt; &#xA; &lt;li&gt;Any functionality that you would like to see here, please open an issue or submit a PR.&lt;/li&gt; &#xA; &lt;li&gt;To enable function calling and conditional streaming UI (currently in beta), ensure useFunctionCalling is set to true in the config file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ollama Support (Partially supported)&lt;/h3&gt; &#xA;&lt;p&gt;Currently, streaming text responses are supported for Ollama, but follow-up questions are not yet supported.&lt;/p&gt; &#xA;&lt;p&gt;Embeddings are supported, however, time-to-first-token can be quite long when using both a local embedding model as well as a local model for the streaming inference. I recommended decreasing a number of the RAG values specified in the &lt;code&gt;app/config.tsx&lt;/code&gt; file to decrease the time-to-first-token when using Ollama.&lt;/p&gt; &#xA;&lt;p&gt;To get started, make sure you have the Ollama running model on your local machine and set within the config the model you would like to use and set use OllamaInference and/or useOllamaEmbeddings to true.&lt;/p&gt; &#xA;&lt;p&gt;Note: When &#39;useOllamaInference&#39; is set to true, the model will be used for both text generation, but it will skip the follow-up questions inference step when using Ollama.&lt;/p&gt; &#xA;&lt;p&gt;More info: &lt;a href=&#34;https://ollama.com/blog/openai-compatibility&#34;&gt;https://ollama.com/blog/openai-compatibility&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Roadmap&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[] Add AI Gateway to support multiple models and embeddings. (OpenAI, Azure OpenAI, Anyscale, Google Gemini &amp;amp; Palm, Anthropic, Cohere, Together AI, Perplexity, Mistral, Nomic, AI21, Stability AI, DeepInfra, Ollama, etc) &lt;code&gt;https://github.com/Portkey-AI/gateway&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;[] Add a settings component to allow users to select the model, embeddings model, and other parameters from the UI&lt;/li&gt; &#xA; &lt;li&gt;[] Add support for follow-up questions when using Ollama&lt;/li&gt; &#xA; &lt;li&gt;[Complete - Beta] Add support for dynamic and conditionally rendered UI components based on the user&#39;s query&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExN284d3p5azAyNHpubm9mb2F0cnB6MWdtcTdnd2Nkb2d1ZnRtMG0yYiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/OMpt8ZbBsjphZz6mue/giphy.gif&#34; alt=&#34;Example&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[Completed] Add dark mode support based on the user&#39;s system preference&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExZDQxdHR0NWc4MHl6cDBsNmpiMGNyeWNwbnE4MjZlb29oZGRsODBhMCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/QjINYAx6le5PMY020A/giphy.gif&#34; alt=&#34;Example&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Backend + Node Only Express API&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/43ZCeBTcsS8&#34;&gt;Watch the express tutorial here&lt;/a&gt; for a detailed guide on setting up and running this project. In addition to the Next.JS version of the project, there is a backend only version that uses Node.js and Express. Which is located in the &#39;express-api&#39; directory. This is a standalone version of the project that can be used as a reference for building a similar API. There is also a readme file in the &#39;express-api&#39; directory that explains how to run the backend version.&lt;/p&gt; &#xA;&lt;h3&gt;Upstash Redis Rate Limiting&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/3_aNVu6EU3Y&#34;&gt;Watch the Upstash Redis Rate Limiting tutorial here&lt;/a&gt; for a detailed guide on setting up and running this project. Upstash Redis Rate Limiting is a free tier service that allows you to set up rate limiting for your application. It provides a simple and easy-to-use interface for configuring and managing rate limits. With Upstash, you can easily set limits on the number of requests per user, IP address, or other criteria. This can help prevent abuse and ensure that your application is not overwhelmed with requests.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions to the project are welcome. Feel free to fork the repository, make your changes, and submit a pull request. You can also open issues to suggest improvements or report bugs.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the MIT License.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#developersdigest/llm-answer-engine&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=developersdigest/llm-answer-engine&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;I&#39;m the developer behind Developers Digest. If you find my work helpful or enjoy what I do, consider supporting me. Here are a few ways you can do that:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Patreon&lt;/strong&gt;: Support me on Patreon at &lt;a href=&#34;https://www.patreon.com/DevelopersDigest&#34;&gt;patreon.com/DevelopersDigest&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Buy Me A Coffee&lt;/strong&gt;: You can buy me a coffee at &lt;a href=&#34;https://www.buymeacoffee.com/developersdigest&#34;&gt;buymeacoffee.com/developersdigest&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Website&lt;/strong&gt;: Check out my website at &lt;a href=&#34;https://developersdigest.tech&#34;&gt;developersdigest.tech&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Github&lt;/strong&gt;: Follow me on GitHub at &lt;a href=&#34;https://github.com/developersdigest&#34;&gt;github.com/developersdigest&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Twitter&lt;/strong&gt;: Follow me on Twitter at &lt;a href=&#34;https://twitter.com/dev__digest&#34;&gt;twitter.com/dev__digest&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>