<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Dart Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-08-29T01:29:35Z</updated>
  <subtitle>Daily Trending of Dart in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>livekit/client-sdk-flutter</title>
    <updated>2024-08-29T01:29:35Z</updated>
    <id>tag:github.com,2024-08-29:/livekit/client-sdk-flutter</id>
    <link href="https://github.com/livekit/client-sdk-flutter" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Flutter Client SDK for LiveKit&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; &#xA; &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;/.github/banner_dark.png&#34;&gt; &#xA; &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;/.github/banner_light.png&#34;&gt; &#xA; &lt;img style=&#34;width:100%;&#34; alt=&#34;The LiveKit icon, the name of the repository and some sample code in the background.&#34; src=&#34;https://raw.githubusercontent.com/livekit/client-sdk-flutter/main/.github/banner_light.png&#34;&gt; &#xA;&lt;/picture&gt; &#xA;&lt;!--END_BANNER_IMAGE--&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pub.dev/packages/livekit_client&#34;&gt;&lt;img src=&#34;https://img.shields.io/pub/v/livekit_client?label=livekit_client&amp;amp;color=blue&#34; alt=&#34;pub package&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;LiveKit Flutter SDK&lt;/h1&gt; &#xA;&lt;!--BEGIN_DESCRIPTION--&gt; &#xA;&lt;p&gt;Use this SDK to add realtime video, audio and data features to your Flutter app. By connecting to &lt;a href=&#34;https://livekit.io/&#34;&gt;LiveKit&lt;/a&gt; Cloud or a self-hosted server, you can quickly build applications such as multi-modal AI, live streaming, or video calls with just a few lines of code.&lt;/p&gt; &#xA;&lt;!--END_DESCRIPTION--&gt; &#xA;&lt;p&gt;This package is published to pub.dev as &lt;a href=&#34;https://pub.dev/packages/livekit_client&#34;&gt;livekit_client&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Docs&lt;/h2&gt; &#xA;&lt;p&gt;More Docs and guides are available at &lt;a href=&#34;https://docs.livekit.io&#34;&gt;https://docs.livekit.io&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Supported platforms&lt;/h2&gt; &#xA;&lt;p&gt;LiveKit client SDK for Flutter is designed to work across all platforms supported by Flutter:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Android&lt;/li&gt; &#xA; &lt;li&gt;iOS&lt;/li&gt; &#xA; &lt;li&gt;Web&lt;/li&gt; &#xA; &lt;li&gt;macOS&lt;/li&gt; &#xA; &lt;li&gt;Windows&lt;/li&gt; &#xA; &lt;li&gt;Linux&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Example app&lt;/h2&gt; &#xA;&lt;p&gt;We built a multi-user conferencing app as an example in the &lt;a href=&#34;https://raw.githubusercontent.com/livekit/client-sdk-flutter/main/example/&#34;&gt;example/&lt;/a&gt; folder. LiveKit is compatible cross-platform: you could join the same room using any of our supported realtime SDKs.&lt;/p&gt; &#xA;&lt;p&gt;Online demo: &lt;a href=&#34;https://livekit.github.io/client-sdk-flutter/&#34;&gt;https://livekit.github.io/client-sdk-flutter/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Include this package to your &lt;code&gt;pubspec.yaml&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;---&#xA;dependencies:&#xA;  livekit_client: &amp;lt;version&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;iOS&lt;/h3&gt; &#xA;&lt;p&gt;Camera and microphone usage need to be declared in your &lt;code&gt;Info.plist&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dict&amp;gt;&#xA;  ...&#xA;  &amp;lt;key&amp;gt;NSCameraUsageDescription&amp;lt;/key&amp;gt;&#xA;  &amp;lt;string&amp;gt;$(PRODUCT_NAME) uses your camera&amp;lt;/string&amp;gt;&#xA;  &amp;lt;key&amp;gt;NSMicrophoneUsageDescription&amp;lt;/key&amp;gt;&#xA;  &amp;lt;string&amp;gt;$(PRODUCT_NAME) uses your microphone&amp;lt;/string&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Your application can still run the voice call when it is switched to the background if the background mode is enabled. Select the app target in Xcode, click the Capabilities tab, enable Background Modes, and check &lt;strong&gt;Audio, AirPlay, and Picture in Picture&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Your &lt;code&gt;Info.plist&lt;/code&gt; should have the following entries.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dict&amp;gt;&#xA;  ...&#xA;  &amp;lt;key&amp;gt;UIBackgroundModes&amp;lt;/key&amp;gt;&#xA;  &amp;lt;array&amp;gt;&#xA;    &amp;lt;string&amp;gt;audio&amp;lt;/string&amp;gt;&#xA;  &amp;lt;/array&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Notes&lt;/h4&gt; &#xA;&lt;p&gt;Since &lt;a href=&#34;https://developer.apple.com/news/upcoming-requirements/?id=06062022a&#34;&gt;xcode 14&lt;/a&gt; no longer supports 32bit builds, and our latest version is based on libwebrtc m104+ the iOS framework no longer supports 32bit builds, we strongly recommend upgrading to flutter 3.3.0+. if you are using flutter 3.0.0 or below, there is a high chance that your flutter app cannot be compiled correctly due to the missing i386 and arm 32bit framework &lt;a href=&#34;https://github.com/livekit/client-sdk-flutter/issues/132&#34;&gt;#132&lt;/a&gt; &lt;a href=&#34;https://github.com/livekit/client-sdk-flutter/issues/172&#34;&gt;#172&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can try to modify your &lt;code&gt;{projects_dir}/ios/Podfile&lt;/code&gt; to fix this issue.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;post_install do |installer|&#xA;  installer.pods_project.targets.each do |target|&#xA;    flutter_additional_ios_build_settings(target)&#xA;&#xA;    target.build_configurations.each do |config|&#xA;&#xA;      # Workaround for https://github.com/flutter/flutter/issues/64502&#xA;      config.build_settings[&#39;ONLY_ACTIVE_ARCH&#39;] = &#39;YES&#39; # &amp;lt;= this line&#xA;&#xA;    end&#xA;  end&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For iOS, the minimum supported deployment target is &lt;code&gt;12.1&lt;/code&gt;. You will need to add the following to your Podfile.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;platform :ios, &#39;12.1&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may need to delete &lt;code&gt;Podfile.lock&lt;/code&gt; and re-run &lt;code&gt;pod install&lt;/code&gt; after updating deployment target.&lt;/p&gt; &#xA;&lt;h3&gt;Android&lt;/h3&gt; &#xA;&lt;p&gt;We require a set of permissions that need to be declared in your &lt;code&gt;AppManifest.xml&lt;/code&gt;. These are required by Flutter WebRTC, which we depend on.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;manifest xmlns:android=&#34;http://schemas.android.com/apk/res/android&#34; package=&#34;com.your.package&#34;&amp;gt;&#xA;  &amp;lt;uses-feature android:name=&#34;android.hardware.camera&#34; /&amp;gt;&#xA;  &amp;lt;uses-feature android:name=&#34;android.hardware.camera.autofocus&#34; /&amp;gt;&#xA;  &amp;lt;uses-permission android:name=&#34;android.permission.CAMERA&#34; /&amp;gt;&#xA;  &amp;lt;uses-permission android:name=&#34;android.permission.RECORD_AUDIO&#34; /&amp;gt;&#xA;  &amp;lt;uses-permission android:name=&#34;android.permission.ACCESS_NETWORK_STATE&#34; /&amp;gt;&#xA;  &amp;lt;uses-permission android:name=&#34;android.permission.CHANGE_NETWORK_STATE&#34; /&amp;gt;&#xA;  &amp;lt;uses-permission android:name=&#34;android.permission.MODIFY_AUDIO_SETTINGS&#34; /&amp;gt;&#xA;  &amp;lt;uses-permission android:name=&#34;android.permission.BLUETOOTH&#34; android:maxSdkVersion=&#34;30&#34; /&amp;gt;&#xA;  &amp;lt;uses-permission android:name=&#34;android.permission.BLUETOOTH_CONNECT&#34; /&amp;gt;&#xA;  &amp;lt;uses-permission android:name=&#34;android.permission.BLUETOOTH_ADMIN&#34; android:maxSdkVersion=&#34;30&#34; /&amp;gt;&#xA;  ...&#xA;&amp;lt;/manifest&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For using the bluetooth headset correctly on the android device, you need to add &lt;code&gt;permission_handler&lt;/code&gt; to your project. And call the following code after launching your app for the first time.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;import &#39;package:permission_handler/permission_handler.dart&#39;;&#xA;&#xA;Future&amp;lt;void&amp;gt; _checkPermissions() async {&#xA;  var status = await Permission.bluetooth.request();&#xA;  if (status.isPermanentlyDenied) {&#xA;    print(&#39;Bluetooth Permission disabled&#39;);&#xA;  }&#xA;  status = await Permission.bluetoothConnect.request();&#xA;  if (status.isPermanentlyDenied) {&#xA;    print(&#39;Bluetooth Connect Permission disabled&#39;);&#xA;  }&#xA;}&#xA;&#xA;void main() async {&#xA;  WidgetsFlutterBinding.ensureInitialized();&#xA;  await _checkPermissions();&#xA;  runApp(MyApp());&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Audio Modes&lt;/h4&gt; &#xA;&lt;p&gt;By default, we use the &lt;code&gt;communication&lt;/code&gt; audio mode on Android which works best for two-way voice communication.&lt;/p&gt; &#xA;&lt;p&gt;If your app is media playback oriented and does not need the use of the device&#39;s microphone, you can use the &lt;code&gt;media&lt;/code&gt; audio mode which will provide better audio quality.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;import &#39;package:flutter_webrtc/flutter_webrtc.dart&#39; as webrtc;&#xA;&#xA;Future&amp;lt;void&amp;gt; _initializeAndroidAudioSettings() async {&#xA;  await webrtc.WebRTC.initialize(options: {&#xA;    &#39;androidAudioConfiguration&#39;: webrtc.AndroidAudioConfiguration.media.toMap()&#xA;  });&#xA;  webrtc.Helper.setAndroidAudioConfiguration(&#xA;      webrtc.AndroidAudioConfiguration.media);&#xA;}&#xA;&#xA;void main() async {&#xA;  await _initializeAudioSettings();&#xA;  runApp(const MyApp());&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: the audio routing will become controlled by the system and cannot be manually changed with functions like &lt;code&gt;Hardware.selectAudioOutput&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Desktop support&lt;/h3&gt; &#xA;&lt;p&gt;In order to enable Flutter desktop development, please follow &lt;a href=&#34;https://docs.flutter.dev/desktop#set-up&#34;&gt;instructions here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;On Windows &lt;a href=&#34;https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=community&amp;amp;rel=16&#34;&gt;VS 2019&lt;/a&gt; is needed (link in flutter docs will download VS 2022).&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Connecting to a room, publish video &amp;amp; audio&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;final roomOptions = RoomOptions(&#xA;  adaptiveStream: true,&#xA;  dynacast: true,&#xA;  // ... your room options&#xA;)&#xA;&#xA;final room = Room();&#xA;&#xA;// you can use `prepareConnection` to speed up connection.&#xA;await room.prepareConnection(url, token);&#xA;&#xA;await room.connect(url, token, roomOptions: roomOptions);&#xA;&#xA;try {&#xA;  // video will fail when running in ios simulator&#xA;  await room.localParticipant.setCameraEnabled(true);&#xA;} catch (error) {&#xA;  print(&#39;Could not publish video, error: $error&#39;);&#xA;}&#xA;&#xA;await room.localParticipant.setMicrophoneEnabled(true);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Screen sharing&lt;/h3&gt; &#xA;&lt;p&gt;Screen sharing is supported across all platforms. You can enable it with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;room.localParticipant.setScreenShareEnabled(true);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Android&lt;/h4&gt; &#xA;&lt;p&gt;On Android, you will have to use a &lt;a href=&#34;https://developer.android.com/develop/background-work/services/fg-service-types#media-projection&#34;&gt;media projection foreground service&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In our example, we use the &lt;code&gt;flutter_background&lt;/code&gt; package to handle this. In the app&#39;s AndroidManifest.xml file, declare the service with the appropriate types and permissions as following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;manifest xmlns:android=&#34;http://schemas.android.com/apk/res/android&#34;&amp;gt;&#xA;  &amp;lt;!-- Required permissions for screen share --&amp;gt;&#xA;  &amp;lt;uses-permission android:name=&#34;android.permission.FOREGROUND_SERVICE&#34; /&amp;gt;&#xA;  &amp;lt;uses-permission android:name=&#34;android.permission.FOREGROUND_SERVICE_MEDIA_PROJECTION&#34; /&amp;gt;&#xA;  &amp;lt;application&amp;gt;&#xA;    ...&#xA;    &amp;lt;service&#xA;        android:name=&#34;de.julianassmann.flutter_background.IsolateHolderService&#34;&#xA;        android:enabled=&#34;true&#34;&#xA;        android:exported=&#34;false&#34;&#xA;        android:foregroundServiceType=&#34;mediaProjection&#34; /&amp;gt;&#xA;  &amp;lt;/application&amp;gt;&#xA;&amp;lt;/manifest&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Before starting the background service and enabling screen share, you &lt;strong&gt;must&lt;/strong&gt; call &lt;code&gt;Helper.requestCapturePermission()&lt;/code&gt; from &lt;code&gt;flutter_webrtc&lt;/code&gt;, and only proceed if it returns true.&lt;/p&gt; &#xA;&lt;h4&gt;iOS&lt;/h4&gt; &#xA;&lt;p&gt;On iOS, a broadcast extension is needed in order to capture screen content from other apps. See &lt;a href=&#34;https://github.com/flutter-webrtc/flutter-webrtc/wiki/iOS-Screen-Sharing#broadcast-extension-quick-setup&#34;&gt;setup guide&lt;/a&gt; for instructions.&lt;/p&gt; &#xA;&lt;h4&gt;Desktop(Windows/macOS)&lt;/h4&gt; &#xA;&lt;p&gt;On dekstop you can use &lt;code&gt;ScreenSelectDialog&lt;/code&gt; to select the window or screen you want to share.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;try {&#xA;  final source = await showDialog&amp;lt;DesktopCapturerSource&amp;gt;(&#xA;    context: context,&#xA;    builder: (context) =&amp;gt; ScreenSelectDialog(),&#xA;  );&#xA;  if (source == null) {&#xA;    print(&#39;cancelled screenshare&#39;);&#xA;    return;&#xA;  }&#xA;  print(&#39;DesktopCapturerSource: ${source.id}&#39;);&#xA;  var track = await LocalVideoTrack.createScreenShareTrack(&#xA;    ScreenShareCaptureOptions(&#xA;      sourceId: source.id,&#xA;      maxFrameRate: 15.0,&#xA;    ),&#xA;  );&#xA;  await room.localParticipant.publishVideoTrack(track);&#xA;} catch (e) {&#xA;  print(&#39;could not publish screen sharing: $e&#39;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;End to End Encryption&lt;/h3&gt; &#xA;&lt;p&gt;LiveKit supports end-to-end encryption for audio/video data sent over the network. By default, the native platform can support E2EE without any settings, but for flutter web, you need to use the following steps to create &lt;code&gt;e2ee.worker.dart.js&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# for example app&#xA;dart compile js web/e2ee.worker.dart -o example/web/e2ee.worker.dart.js -m&#xA;# for your project&#xA;export YOU_PROJECT_DIR=your_project_dir&#xA;git clone https://github.com/livekit/client-sdk-flutter.git&#xA;cd client-sdk-flutter &amp;amp;&amp;amp; flutter pub get&#xA;dart compile js web/e2ee.worker.dart -o ${YOU_PROJECT_DIR}/web/e2ee.worker.dart.js -m&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Advanced track manipulation&lt;/h3&gt; &#xA;&lt;p&gt;The setCameraEnabled/setMicrophoneEnabled helpers are wrappers around the Track API.&lt;/p&gt; &#xA;&lt;p&gt;You can also manually create and publish tracks:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;var localVideo = await LocalVideoTrack.createCameraTrack();&#xA;await room.localParticipant.publishVideoTrack(localVideo);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Rendering video&lt;/h3&gt; &#xA;&lt;p&gt;Each track can be rendered separately with the provided &lt;code&gt;VideoTrackRenderer&lt;/code&gt; widget.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;VideoTrack? track;&#xA;&#xA;@override&#xA;Widget build(BuildContext context) {&#xA;  if (track != null) {&#xA;    return VideoTrackRenderer(track);&#xA;  } else {&#xA;    return Container(&#xA;      color: Colors.grey,&#xA;    );&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Audio handling&lt;/h3&gt; &#xA;&lt;p&gt;Audio tracks are played automatically as long as you are subscribed to them.&lt;/p&gt; &#xA;&lt;h3&gt;Handling changes&lt;/h3&gt; &#xA;&lt;p&gt;LiveKit client makes it simple to build declarative UI that reacts to state changes. It notifies changes in two ways&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;ChangeNotifier&lt;/code&gt; - generic notification of changes. This is useful when you are building reactive UI and only care about changes that may impact rendering.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;EventsListener&amp;lt;Event&amp;gt;&lt;/code&gt; - listener pattern to listen to specific events (see &lt;a href=&#34;https://github.com/livekit/client-sdk-flutter/raw/main/lib/src/events.dart&#34;&gt;events.dart&lt;/a&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This example will show you how to use both to react to room events.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;class RoomWidget extends StatefulWidget {&#xA;  final Room room;&#xA;&#xA;  RoomWidget(this.room);&#xA;&#xA;  @override&#xA;  State&amp;lt;StatefulWidget&amp;gt; createState() {&#xA;    return _RoomState();&#xA;  }&#xA;}&#xA;&#xA;class _RoomState extends State&amp;lt;RoomWidget&amp;gt; {&#xA;  late final EventsListener&amp;lt;RoomEvent&amp;gt; _listener = widget.room.createListener();&#xA;&#xA;  @override&#xA;  void initState() {&#xA;    super.initState();&#xA;    // used for generic change updates&#xA;    widget.room.addListener(_onChange);&#xA;&#xA;    // used for specific events&#xA;    _listener&#xA;      ..on&amp;lt;RoomDisconnectedEvent&amp;gt;((_) {&#xA;        // handle disconnect&#xA;      })&#xA;      ..on&amp;lt;ParticipantConnectedEvent&amp;gt;((e) {&#xA;        print(&#34;participant joined: ${e.participant.identity}&#34;);&#xA;      })&#xA;  }&#xA;&#xA;  @override&#xA;  void dispose() {&#xA;    // be sure to dispose listener to stop listening to further updates&#xA;    _listener.dispose();&#xA;    widget.room.removeListener(_onChange);&#xA;    super.dispose();&#xA;  }&#xA;&#xA;  void _onChange() {&#xA;    // perform computations and then call setState&#xA;    // setState will trigger a build&#xA;    setState(() {&#xA;      // your updates here&#xA;    });&#xA;  }&#xA;&#xA;  @override&#xA;  Widget build(BuildContext context) {&#xA;    // your build function&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Similarly, you could do the same when rendering participants. Reacting to changes makes it possible to handle tracks published/unpublished or re-ordering participants in your UI.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;class VideoView extends StatefulWidget {&#xA;  final Participant participant;&#xA;&#xA;  VideoView(this.participant);&#xA;&#xA;  @override&#xA;  State&amp;lt;StatefulWidget&amp;gt; createState() {&#xA;    return _VideoViewState();&#xA;  }&#xA;}&#xA;&#xA;class _VideoViewState extends State&amp;lt;VideoView&amp;gt; {&#xA;  TrackPublication? videoPub;&#xA;&#xA;  @override&#xA;  void initState() {&#xA;    super.initState();&#xA;    widget.participant.addListener(this._onParticipantChanged);&#xA;    // trigger initial change&#xA;    _onParticipantChanged();&#xA;  }&#xA;&#xA;  @override&#xA;  void dispose() {&#xA;    widget.participant.removeListener(this._onParticipantChanged);&#xA;    super.dispose();&#xA;  }&#xA;&#xA;  @override&#xA;  void didUpdateWidget(covariant VideoView oldWidget) {&#xA;    oldWidget.participant.removeListener(_onParticipantChanged);&#xA;    widget.participant.addListener(_onParticipantChanged);&#xA;    _onParticipantChanged();&#xA;    super.didUpdateWidget(oldWidget);&#xA;  }&#xA;&#xA;  void _onParticipantChanged() {&#xA;    var subscribedVideos = widget.participant.videoTracks.values.where((pub) {&#xA;      return pub.kind == TrackType.VIDEO &amp;amp;&amp;amp;&#xA;          !pub.isScreenShare &amp;amp;&amp;amp;&#xA;          pub.subscribed;&#xA;    });&#xA;&#xA;    setState(() {&#xA;      if (subscribedVideos.length &amp;gt; 0) {&#xA;        var videoPub = subscribedVideos.first;&#xA;        // when muted, show placeholder&#xA;        if (!videoPub.muted) {&#xA;          this.videoPub = videoPub;&#xA;          return;&#xA;        }&#xA;      }&#xA;      this.videoPub = null;&#xA;    });&#xA;  }&#xA;&#xA;  @override&#xA;  Widget build(BuildContext context) {&#xA;    var videoPub = this.videoPub;&#xA;    if (videoPub != null) {&#xA;      return VideoTrackRenderer(videoPub.track as VideoTrack);&#xA;    } else {&#xA;      return Container(&#xA;        color: Colors.grey,&#xA;      );&#xA;    }&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Mute, unmute local tracks&lt;/h3&gt; &#xA;&lt;p&gt;On &lt;code&gt;LocalTrackPublication&lt;/code&gt;s, you could control if the track is muted by setting its &lt;code&gt;muted&lt;/code&gt; property. Changing the mute status will generate an &lt;code&gt;onTrackMuted&lt;/code&gt; or &lt;code&gt;onTrack Unmuted&lt;/code&gt; delegate call for the local participant. Other participant will receive the status change as well.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;// mute track&#xA;trackPub.muted = true;&#xA;&#xA;// unmute track&#xA;trackPub.muted = false;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Subscriber controls&lt;/h3&gt; &#xA;&lt;p&gt;When subscribing to remote tracks, the client has precise control over status of its subscriptions. You could subscribe or unsubscribe to a track, change its quality, or disabling the track temporarily.&lt;/p&gt; &#xA;&lt;p&gt;These controls are accessible on the &lt;code&gt;RemoteTrackPublication&lt;/code&gt; object.&lt;/p&gt; &#xA;&lt;p&gt;For more info, see &lt;a href=&#34;https://docs.livekit.io/guides/room/receive#subscriber-controls&#34;&gt;Subscriber controls&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Getting help / Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please join us on &lt;a href=&#34;https://livekit.io/join-slack&#34;&gt;Slack&lt;/a&gt; to get help from our devs / community members. We welcome your contributions(PRs) and details can be discussed there.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Apache License 2.0&lt;/p&gt; &#xA;&lt;h2&gt;Thanks&lt;/h2&gt; &#xA;&lt;p&gt;A huge thank you to &lt;a href=&#34;https://github.com/flutter-webrtc/flutter-webrtc&#34;&gt;flutter-webrtc&lt;/a&gt; for making it possible to use WebRTC in Flutter.&lt;/p&gt; &#xA;&lt;!--BEGIN_REPO_NAV--&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&lt;table&gt; &#xA; &lt;thead&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;th colspan=&#34;2&#34;&gt;LiveKit Ecosystem&lt;/th&gt;&#xA;  &lt;/tr&gt;&#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;Realtime SDKs&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/livekit/components-js&#34;&gt;React Components&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/client-sdk-js&#34;&gt;Browser&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/components-swift&#34;&gt;Swift Components&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/client-sdk-swift&#34;&gt;iOS/macOS/visionOS&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/client-sdk-android&#34;&gt;Android&lt;/a&gt; · &lt;b&gt;Flutter&lt;/b&gt; · &lt;a href=&#34;https://github.com/livekit/client-sdk-react-native&#34;&gt;React Native&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/rust-sdks&#34;&gt;Rust&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/node-sdks&#34;&gt;Node.js&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/python-sdks&#34;&gt;Python&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/client-sdk-unity-web&#34;&gt;Unity (web)&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/client-sdk-unity&#34;&gt;Unity (beta)&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;Server APIs&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/livekit/node-sdks&#34;&gt;Node.js&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/server-sdk-go&#34;&gt;Golang&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/server-sdk-ruby&#34;&gt;Ruby&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/server-sdk-kotlin&#34;&gt;Java/Kotlin&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/python-sdks&#34;&gt;Python&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/rust-sdks&#34;&gt;Rust&lt;/a&gt; · &lt;a href=&#34;https://github.com/agence104/livekit-server-sdk-php&#34;&gt;PHP (community)&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;Agents Frameworks&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/livekit/agents&#34;&gt;Python&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/agent-playground&#34;&gt;Playground&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;Services&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/livekit/livekit&#34;&gt;LiveKit server&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/egress&#34;&gt;Egress&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/ingress&#34;&gt;Ingress&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/sip&#34;&gt;SIP&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;Resources&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.livekit.io&#34;&gt;Docs&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit-examples&#34;&gt;Example apps&lt;/a&gt; · &lt;a href=&#34;https://livekit.io/cloud&#34;&gt;Cloud&lt;/a&gt; · &lt;a href=&#34;https://docs.livekit.io/home/self-hosting/deployment&#34;&gt;Self-hosting&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/livekit-cli&#34;&gt;CLI&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!--END_REPO_NAV--&gt;</summary>
  </entry>
</feed>