<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Dart Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-22T01:32:37Z</updated>
  <subtitle>Daily Trending of Dart in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>denyocrworld/fic-exercises</title>
    <updated>2022-11-22T01:32:37Z</updated>
    <id>tag:github.com,2022-11-22:/denyocrworld/fic-exercises</id>
    <link href="https://github.com/denyocrworld/fic-exercises" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;blank_fire_setstate&lt;/h1&gt; &#xA;&lt;p&gt;A new Flutter project.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;This project is a starting point for a Flutter application.&lt;/p&gt; &#xA;&lt;p&gt;A few resources to get you started if this is your first Flutter project:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.flutter.dev/get-started/codelab&#34;&gt;Lab: Write your first Flutter app&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.flutter.dev/cookbook&#34;&gt;Cookbook: Useful Flutter samples&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For help getting started with Flutter development, view the &lt;a href=&#34;https://docs.flutter.dev/&#34;&gt;online documentation&lt;/a&gt;, which offers tutorials, samples, guidance on mobile development, and a full API reference.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>am15h/tflite_flutter_helper</title>
    <updated>2022-11-22T01:32:37Z</updated>
    <id>tag:github.com,2022-11-22:/am15h/tflite_flutter_helper</id>
    <link href="https://github.com/am15h/tflite_flutter_helper" rel="alternate"></link>
    <summary type="html">&lt;p&gt;TensorFlow Lite Flutter Helper Library&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TensorFlow Lite Flutter Helper Library&lt;/h1&gt; &#xA;&lt;p&gt;TFLite Flutter Helper Library brings &lt;a href=&#34;https://www.tensorflow.org/lite/inference_with_metadata/lite_support&#34;&gt;TFLite Support Library&lt;/a&gt; and &lt;a href=&#34;https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview&#34;&gt;TFLite Support Task Library&lt;/a&gt; to Flutter and helps users to develop ML and deploy TFLite models onto mobile devices quickly without compromising on performance.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Setup TFLite Flutter Plugin&lt;/h3&gt; &#xA;&lt;p&gt;Follow the initial setup instructions given &lt;a href=&#34;https://github.com/am15h/tflite_flutter_plugin#most-important-initial-setup&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Basic image manipulation and conversion&lt;/h3&gt; &#xA;&lt;p&gt;TFLite Helper depends on &lt;a href=&#34;https://pub.dev/packages/image&#34;&gt;flutter image package&lt;/a&gt; internally for Image Processing.&lt;/p&gt; &#xA;&lt;p&gt;The TensorFlow Lite Support Library has a suite of basic image manipulation methods such as crop and resize. To use it, create an &lt;code&gt;ImageProcessor&lt;/code&gt; and add the required operations. To convert the image into the tensor format required by the TensorFlow Lite interpreter, create a &lt;code&gt;TensorImage&lt;/code&gt; to be used as input:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;// Initialization code&#xA;// Create an ImageProcessor with all ops required. For more ops, please&#xA;// refer to the ImageProcessor Ops section in this README.&#xA;ImageProcessor imageProcessor = ImageProcessorBuilder()&#xA;  .add(ResizeOp(224, 224, ResizeMethod.NEAREST_NEIGHBOUR))&#xA;  .build();&#xA;&#xA;// Create a TensorImage object from a File&#xA;TensorImage tensorImage = TensorImage.fromFile(imageFile);&#xA;&#xA;// Preprocess the image.&#xA;// The image for imageFile will be resized to (224, 224)&#xA;tensorImage = imageProcessor.process(tensorImage);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Sample app: &lt;a href=&#34;https://github.com/am15h/tflite_flutter_helper/tree/master/example/image_classification&#34;&gt;Image Classification&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Basic audio data processing&lt;/h3&gt; &#xA;&lt;p&gt;The TensorFlow Lite Support Library also defines a TensorAudio class wrapping some basic audio data processing methods.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;TensorAudio tensorAudio = TensorAudio.create(&#xA;    TensorAudioFormat.create(1, sampleRate), size);&#xA;tensorAudio.loadShortBytes(audioBytes);&#xA;&#xA;TensorBuffer inputBuffer = tensorAudio.tensorBuffer;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Sample app: &lt;a href=&#34;https://github.com/am15h/tflite_flutter_helper/tree/master/example/audio_classification&#34;&gt;Audio Classification&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Create output objects and run the model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;// Create a container for the result and specify that this is a quantized model.&#xA;// Hence, the &#39;DataType&#39; is defined as UINT8 (8-bit unsigned integer)&#xA;TensorBuffer probabilityBuffer =&#xA;    TensorBuffer.createFixedSize(&amp;lt;int&amp;gt;[1, 1001], TfLiteType.uint8);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Loading the model and running inference:&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;import &#39;package:tflite_flutter/tflite_flutter.dart&#39;;&#xA;&#xA;try {&#xA;    // Create interpreter from asset.&#xA;    Interpreter interpreter =&#xA;        await Interpreter.fromAsset(&#34;mobilenet_v1_1.0_224_quant.tflite&#34;);&#xA;    interpreter.run(tensorImage.buffer, probabilityBuffer.buffer);&#xA;} catch (e) {&#xA;    print(&#39;Error loading model: &#39; + e.toString());&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Accessing the result&lt;/h3&gt; &#xA;&lt;p&gt;Developers can access the output directly through &lt;code&gt;probabilityBuffer.getDoubleList()&lt;/code&gt;. If the model produces a quantized output, remember to convert the result. For the MobileNet quantized model, the developer needs to divide each output value by 255 to obtain the probability ranging from 0 (least likely) to 1 (most likely) for each category.&lt;/p&gt; &#xA;&lt;h3&gt;Optional: Mapping results to labels&lt;/h3&gt; &#xA;&lt;p&gt;Developers can also optionally map the results to labels. First, copy the text file containing labels into the moduleâ€™s assets directory. Next, load the label file using the following code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;List&amp;lt;String&amp;gt; labels = await FileUtil.loadLabels(&#34;assets/labels.txt&#34;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The following snippet demonstrates how to associate the probabilities with category labels:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;TensorLabel tensorLabel = TensorLabel.fromList(&#xA;      labels, probabilityProcessor.process(probabilityBuffer));&#xA;&#xA;Map&amp;lt;String, double&amp;gt; doubleMap = tensorLabel.getMapWithFloatValue();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ImageProcessor Architecture&lt;/h3&gt; &#xA;&lt;p&gt;The design of the ImageProcessor allowed the image manipulation operations to be defined up front and optimised during the build process. The ImageProcessor currently supports three basic preprocessing operations:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;int cropSize = min(_inputImage.height, _inputImage.width);&#xA;&#xA;ImageProcessor imageProcessor = ImageProcessorBuilder()&#xA;    // Center crop the image to the largest square possible&#xA;    .add(ResizeWithCropOrPadOp(cropSize, cropSize))&#xA;    // Resize using Bilinear or Nearest neighbour&#xA;    .add(ResizeOp(224, 224, ResizeMethod.NEAREST_NEIGHBOUR))&#xA;    // Rotation clockwise in 90 degree increments&#xA;    .add(Rot90Op(rotationDegrees ~/ 90))&#xA;    .add(NormalizeOp(127.5, 127.5))&#xA;    .add(QuantizeOp(128.0, 1 / 128.0))&#xA;    .build();&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See more details &lt;a href=&#34;https://www.tensorflow.org/lite/convert/metadata#normalization_and_quantization_parameters&#34;&gt;here&lt;/a&gt; about normalization and quantization.&lt;/p&gt; &#xA;&lt;h3&gt;Quantization&lt;/h3&gt; &#xA;&lt;p&gt;The TensorProcessor can be used to quantize input tensors or dequantize output tensors. For example, when processing a quantized output TensorBuffer, the developer can use DequantizeOp to dequantize the result to a floating point probability between 0 and 1:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;// Post-processor which dequantize the result&#xA;TensorProcessor probabilityProcessor =&#xA;    TensorProcessorBuilder().add(DequantizeOp(0, 1 / 255.0)).build();&#xA;TensorBuffer dequantizedBuffer =&#xA;    probabilityProcessor.process(probabilityBuffer);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Reading Qunatization Params&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;// Quantization Params of input tensor at index 0&#xA;QuantizationParams inputParams = interpreter.getInputTensor(0).params;&#xA;&#xA;// Quantization Params of output tensor at index 0&#xA;QuantizationParams outputParams = interpreter.getOutputTensor(0).params;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Task Library&lt;/h2&gt; &#xA;&lt;p&gt;Currently, Text based models like &lt;code&gt;NLClassifier&lt;/code&gt;, &lt;code&gt;BertNLClassifier&lt;/code&gt; and &lt;code&gt;BertQuestionAnswerer&lt;/code&gt; are available to use with the Flutter Task Library.&lt;/p&gt; &#xA;&lt;h3&gt;Integrate Natural Langugae Classifier&lt;/h3&gt; &#xA;&lt;p&gt;The Task Library&#39;s &lt;code&gt;NLClassifier&lt;/code&gt; API classifies input text into different categories, and is a versatile and configurable API that can handle most text classification models. Detailed guide is available &lt;a href=&#34;https://www.tensorflow.org/lite/inference_with_metadata/task_library/nl_classifier&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;final classifier = await NLClassifier.createFromAsset(&#39;assets/$_modelFileName&#39;,&#xA;        options: NLClassifierOptions());&#xA;List&amp;lt;Category&amp;gt; predictions = classifier.classify(rawText);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Sample app: &lt;a href=&#34;https://github.com/am15h/tflite_flutter_helper/tree/master/example/text_classification_task&#34;&gt;Text Classification&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Integrate BERT natural language classifier&lt;/h3&gt; &#xA;&lt;p&gt;The Task Library &lt;code&gt;BertNLClassifier&lt;/code&gt; API is very similar to the &lt;code&gt;NLClassifier&lt;/code&gt; that classifies input text into different categories, except that this API is specially tailored for Bert related models that require Wordpiece and Sentencepiece tokenizations outside the TFLite model. Detailed guide is available &lt;a href=&#34;https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_nl_classifier&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;final classifier = await BertNLClassifier.createFromAsset(&#39;assets/$_modelFileName&#39;,&#xA;        options: BertNLClassifierOptions());&#xA;List&amp;lt;Category&amp;gt; predictions = classifier.classify(rawText);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Integrate BERT question answerer&lt;/h3&gt; &#xA;&lt;p&gt;The Task Library &lt;code&gt;BertQuestionAnswerer&lt;/code&gt; API loads a Bert model and answers questions based on the content of a given passage. For more information, see the documentation for the Question-Answer model &lt;a href=&#34;https://www.tensorflow.org/lite/models/bert_qa/overview&#34;&gt;here&lt;/a&gt;. Detailed guide is available &lt;a href=&#34;https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_question_answerer&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;final bertQuestionAnswerer = await BertQuestionAnswerer.createFromAsset(&#39;assets/$_modelFileName&#39;);&#xA;List&amp;lt;QaAnswer&amp;gt; answeres = bertQuestionAnswerer.answer(context, question);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Sample app: &lt;a href=&#34;https://github.com/am15h/tflite_flutter_helper/tree/master/example/bert_question_answer&#34;&gt;Bert Question Answerer Sample&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>