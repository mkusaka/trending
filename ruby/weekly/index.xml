<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Ruby Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-06-22T01:44:54Z</updated>
  <subtitle>Weekly Trending of Ruby in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>openai/openai-ruby</title>
    <updated>2025-06-22T01:44:54Z</updated>
    <id>tag:github.com,2025-06-22:/openai/openai-ruby</id>
    <link href="https://github.com/openai/openai-ruby" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official Ruby SDK for the OpenAI API&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OpenAI Ruby API library&lt;/h1&gt; &#xA;&lt;p&gt;The OpenAI Ruby library provides convenient access to the OpenAI REST API from any Ruby 3.2.0+ application. It ships with comprehensive types &amp;amp; docstrings in Yard, RBS, and RBI – &lt;a href=&#34;https://github.com/openai/openai-ruby#Sorbet&#34;&gt;see below&lt;/a&gt; for usage with Sorbet. The standard library&#39;s &lt;code&gt;net/http&lt;/code&gt; is used as the HTTP transport, with connection pooling via the &lt;code&gt;connection_pool&lt;/code&gt; gem.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Documentation for releases of this gem can be found &lt;a href=&#34;https://gemdocs.org/gems/openai&#34;&gt;on RubyDoc&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The REST API documentation can be found on &lt;a href=&#34;https://platform.openai.com/docs&#34;&gt;platform.openai.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;To use this gem, install via Bundler by adding the following to your application&#39;s &lt;code&gt;Gemfile&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;!-- x-release-please-start-version --&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;gem &#34;openai&#34;, &#34;~&amp;gt; 0.9.0&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- x-release-please-end --&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;require &#34;bundler/setup&#34;&#xA;require &#34;openai&#34;&#xA;&#xA;openai = OpenAI::Client.new(&#xA;  api_key: ENV[&#34;OPENAI_API_KEY&#34;] # This is the default and can be omitted&#xA;)&#xA;&#xA;chat_completion = openai.chat.completions.create(&#xA;  messages: [{role: &#34;user&#34;, content: &#34;Say this is a test&#34;}],&#xA;  model: :&#34;gpt-4.1&#34;&#xA;)&#xA;&#xA;puts(chat_completion)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Streaming&lt;/h3&gt; &#xA;&lt;p&gt;We provide support for streaming responses using Server-Sent Events (SSE).&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;coming soon:&lt;/strong&gt; &lt;code&gt;openai.chat.completions.stream&lt;/code&gt; will soon come with Python SDK-style higher-level streaming responses support.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;stream = openai.chat.completions.stream_raw(&#xA;  messages: [{role: &#34;user&#34;, content: &#34;Say this is a test&#34;}],&#xA;  model: :&#34;gpt-4.1&#34;&#xA;)&#xA;&#xA;stream.each do |completion|&#xA;  puts(completion)&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Pagination&lt;/h3&gt; &#xA;&lt;p&gt;List methods in the OpenAI API are paginated.&lt;/p&gt; &#xA;&lt;p&gt;This library provides auto-paginating iterators with each list response, so you do not have to request successive pages manually:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;page = openai.fine_tuning.jobs.list(limit: 20)&#xA;&#xA;# Fetch single item from page.&#xA;job = page.data[0]&#xA;puts(job.id)&#xA;&#xA;# Automatically fetches more pages as needed.&#xA;page.auto_paging_each do |job|&#xA;  puts(job.id)&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, you can use the &lt;code&gt;#next_page?&lt;/code&gt; and &lt;code&gt;#next_page&lt;/code&gt; methods for more granular control working with pages.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;if page.next_page?&#xA;  new_page = page.next_page&#xA;  puts(new_page.data[0].id)&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;File uploads&lt;/h3&gt; &#xA;&lt;p&gt;Request parameters that correspond to file uploads can be passed as raw contents, a &lt;a href=&#34;https://rubyapi.org/3.2/o/pathname&#34;&gt;&lt;code&gt;Pathname&lt;/code&gt;&lt;/a&gt; instance, &lt;a href=&#34;https://rubyapi.org/3.2/o/stringio&#34;&gt;&lt;code&gt;StringIO&lt;/code&gt;&lt;/a&gt;, or more.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;require &#34;pathname&#34;&#xA;&#xA;# Use `Pathname` to send the filename and/or avoid paging a large file into memory:&#xA;file_object = openai.files.create(file: Pathname(&#34;input.jsonl&#34;), purpose: &#34;fine-tune&#34;)&#xA;&#xA;# Alternatively, pass file contents or a `StringIO` directly:&#xA;file_object = openai.files.create(file: File.read(&#34;input.jsonl&#34;), purpose: &#34;fine-tune&#34;)&#xA;&#xA;puts(file_object.id)&#xA;&#xA;# Or, to control the filename and/or content type:&#xA;image = OpenAI::FilePart.new(Pathname(&#39;dog.jpg&#39;), content_type: &#39;image/jpeg&#39;)&#xA;edited = openai.images.edit(&#xA;  prompt: &#34;make this image look like a painting&#34;,&#xA;  model: &#34;gpt-image-1&#34;,&#xA;  size: &#39;1024x1024&#39;,&#xA;  image: image&#xA;)&#xA;&#xA;puts(edited.data.first)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that you can also pass a raw &lt;code&gt;IO&lt;/code&gt; descriptor, but this disables retries, as the library can&#39;t be sure if the descriptor is a file or pipe (which cannot be rewound).&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://platform.openai.com/docs/guides/structured-outputs&#34;&gt;Structured outputs&lt;/a&gt; and function calling&lt;/h3&gt; &#xA;&lt;p&gt;This SDK ships with helpers in &lt;code&gt;OpenAI::BaseModel&lt;/code&gt;, &lt;code&gt;OpenAI::ArrayOf&lt;/code&gt;, &lt;code&gt;OpenAI::EnumOf&lt;/code&gt;, and &lt;code&gt;OpenAI::UnionOf&lt;/code&gt; to help you define the supported JSON schemas used in making structured outputs and function calling requests.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Snippet&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# Participant model with an optional last_name and an enum for status&#xA;class Participant &amp;lt; OpenAI::BaseModel&#xA;  required :first_name, String&#xA;  required :last_name, String, nil?: true&#xA;  required :status, OpenAI::EnumOf[:confirmed, :unconfirmed, :tentative]&#xA;end&#xA;&#xA;# CalendarEvent model with a list of participants.&#xA;class CalendarEvent &amp;lt; OpenAI::BaseModel&#xA;  required :name, String&#xA;  required :date, String&#xA;  required :participants, OpenAI::ArrayOf[Participant]&#xA;end&#xA;&#xA;&#xA;client = OpenAI::Client.new&#xA;&#xA;response = client.responses.create(&#xA;  model: &#34;gpt-4o-2024-08-06&#34;,&#xA;  input: [&#xA;    {role: :system, content: &#34;Extract the event information.&#34;},&#xA;    {&#xA;      role: :user,&#xA;      content: &amp;lt;&amp;lt;~CONTENT&#xA;        Alice Shah and Lena are going to a science fair on Friday at 123 Main St. in San Diego.&#xA;        They have also invited Jasper Vellani and Talia Groves - Jasper has not responded and Talia said she is thinking about it.&#xA;      CONTENT&#xA;    }&#xA;  ],&#xA;  text: CalendarEvent&#xA;)&#xA;&#xA;response&#xA;  .output&#xA;  .flat_map { _1.content }&#xA;  # filter out refusal responses&#xA;  .grep_v(OpenAI::Models::Responses::ResponseOutputRefusal)&#xA;  .each do |content|&#xA;    # parsed is an instance of `CalendarEvent`&#xA;    pp(content.parsed)&#xA;  end&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://github.com/openai/openai-ruby/tree/main/examples&#34;&gt;examples&lt;/a&gt; directory for more usage examples for helper usage.&lt;/p&gt; &#xA;&lt;p&gt;To make the equivalent request using raw JSON schema format, you would do the following:&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Snippet&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;response = client.responses.create(&#xA;  model: &#34;gpt-4o-2024-08-06&#34;,&#xA;  input: [&#xA;    {role: :system, content: &#34;Extract the event information.&#34;},&#xA;    {&#xA;      role: :user,&#xA;      content: &#34;...&#34;&#xA;    }&#xA;  ],&#xA;  text: {&#xA;    format: {&#xA;      type: :json_schema,&#xA;      name: &#34;CalendarEvent&#34;,&#xA;      strict: true,&#xA;      schema: {&#xA;        type: &#34;object&#34;,&#xA;        properties: {&#xA;          name: {type: &#34;string&#34;},&#xA;          date: {type: &#34;string&#34;},&#xA;          participants: {&#xA;            type: &#34;array&#34;,&#xA;            items: {&#xA;              type: &#34;object&#34;,&#xA;              properties: {&#xA;                first_name: {type: &#34;string&#34;},&#xA;                last_name: {type: %w[string null]},&#xA;                status: {type: &#34;string&#34;, enum: %w[confirmed unconfirmed tentative]}&#xA;              },&#xA;              required: %w[first_name last_name status],&#xA;              additionalProperties: false&#xA;            }&#xA;          }&#xA;        },&#xA;        required: %w[name date participants],&#xA;        additionalProperties: false&#xA;      }&#xA;    }&#xA;  }&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Handling errors&lt;/h3&gt; &#xA;&lt;p&gt;When the library is unable to connect to the API, or if the API returns a non-success status code (i.e., 4xx or 5xx response), a subclass of &lt;code&gt;OpenAI::Errors::APIError&lt;/code&gt; will be thrown:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;begin&#xA;  job = openai.fine_tuning.jobs.create(model: :&#34;babbage-002&#34;, training_file: &#34;file-abc123&#34;)&#xA;rescue OpenAI::Errors::APIConnectionError =&amp;gt; e&#xA;  puts(&#34;The server could not be reached&#34;)&#xA;  puts(e.cause)  # an underlying Exception, likely raised within `net/http`&#xA;rescue OpenAI::Errors::RateLimitError =&amp;gt; e&#xA;  puts(&#34;A 429 status code was received; we should back off a bit.&#34;)&#xA;rescue OpenAI::Errors::APIStatusError =&amp;gt; e&#xA;  puts(&#34;Another non-200-range status code was received&#34;)&#xA;  puts(e.status)&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Error codes are as follows:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Cause&lt;/th&gt; &#xA;   &lt;th&gt;Error Type&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HTTP 400&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;BadRequestError&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HTTP 401&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;AuthenticationError&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HTTP 403&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;PermissionDeniedError&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HTTP 404&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;NotFoundError&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HTTP 409&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ConflictError&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HTTP 422&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;UnprocessableEntityError&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HTTP 429&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;RateLimitError&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HTTP &amp;gt;= 500&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;InternalServerError&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Other HTTP error&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;APIStatusError&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Timeout&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;APITimeoutError&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Network error&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;APIConnectionError&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Retries&lt;/h3&gt; &#xA;&lt;p&gt;Certain errors will be automatically retried 2 times by default, with a short exponential backoff.&lt;/p&gt; &#xA;&lt;p&gt;Connection errors (for example, due to a network connectivity problem), 408 Request Timeout, 409 Conflict, 429 Rate Limit, &amp;gt;=500 Internal errors, and timeouts will all be retried by default.&lt;/p&gt; &#xA;&lt;p&gt;You can use the &lt;code&gt;max_retries&lt;/code&gt; option to configure or disable this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# Configure the default for all requests:&#xA;openai = OpenAI::Client.new(&#xA;  max_retries: 0 # default is 2&#xA;)&#xA;&#xA;# Or, configure per-request:&#xA;openai.chat.completions.create(&#xA;  messages: [{role: &#34;user&#34;, content: &#34;How can I get the name of the current day in JavaScript?&#34;}],&#xA;  model: :&#34;gpt-4.1&#34;,&#xA;  request_options: {max_retries: 5}&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Timeouts&lt;/h3&gt; &#xA;&lt;p&gt;By default, requests will time out after 600 seconds. You can use the timeout option to configure or disable this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# Configure the default for all requests:&#xA;openai = OpenAI::Client.new(&#xA;  timeout: nil # default is 600&#xA;)&#xA;&#xA;# Or, configure per-request:&#xA;openai.chat.completions.create(&#xA;  messages: [{role: &#34;user&#34;, content: &#34;How can I list all files in a directory using Python?&#34;}],&#xA;  model: :&#34;gpt-4.1&#34;,&#xA;  request_options: {timeout: 5}&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On timeout, &lt;code&gt;OpenAI::Errors::APITimeoutError&lt;/code&gt; is raised.&lt;/p&gt; &#xA;&lt;p&gt;Note that requests that time out are retried by default.&lt;/p&gt; &#xA;&lt;h2&gt;Advanced concepts&lt;/h2&gt; &#xA;&lt;h3&gt;BaseModel&lt;/h3&gt; &#xA;&lt;p&gt;All parameter and response objects inherit from &lt;code&gt;OpenAI::Internal::Type::BaseModel&lt;/code&gt;, which provides several conveniences, including:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;All fields, including unknown ones, are accessible with &lt;code&gt;obj[:prop]&lt;/code&gt; syntax, and can be destructured with &lt;code&gt;obj =&amp;gt; {prop: prop}&lt;/code&gt; or pattern-matching syntax.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Structural equivalence for equality; if two API calls return the same values, comparing the responses with == will return true.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Both instances and the classes themselves can be pretty-printed.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Helpers such as &lt;code&gt;#to_h&lt;/code&gt;, &lt;code&gt;#deep_to_h&lt;/code&gt;, &lt;code&gt;#to_json&lt;/code&gt;, and &lt;code&gt;#to_yaml&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Making custom or undocumented requests&lt;/h3&gt; &#xA;&lt;h4&gt;Undocumented properties&lt;/h4&gt; &#xA;&lt;p&gt;You can send undocumented parameters to any endpoint, and read undocumented response properties, like so:&lt;/p&gt; &#xA;&lt;p&gt;Note: the &lt;code&gt;extra_&lt;/code&gt; parameters of the same name overrides the documented parameters.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;chat_completion =&#xA;  openai.chat.completions.create(&#xA;    messages: [{role: &#34;user&#34;, content: &#34;How can I get the name of the current day in JavaScript?&#34;}],&#xA;    model: :&#34;gpt-4.1&#34;,&#xA;    request_options: {&#xA;      extra_query: {my_query_parameter: value},&#xA;      extra_body: {my_body_parameter: value},&#xA;      extra_headers: {&#34;my-header&#34;: value}&#xA;    }&#xA;  )&#xA;&#xA;puts(chat_completion[:my_undocumented_property])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Undocumented request params&lt;/h4&gt; &#xA;&lt;p&gt;If you want to explicitly send an extra param, you can do so with the &lt;code&gt;extra_query&lt;/code&gt;, &lt;code&gt;extra_body&lt;/code&gt;, and &lt;code&gt;extra_headers&lt;/code&gt; under the &lt;code&gt;request_options:&lt;/code&gt; parameter when making a request, as seen in the examples above.&lt;/p&gt; &#xA;&lt;h4&gt;Undocumented endpoints&lt;/h4&gt; &#xA;&lt;p&gt;To make requests to undocumented endpoints while retaining the benefit of auth, retries, and so on, you can make requests using &lt;code&gt;client.request&lt;/code&gt;, like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;response = client.request(&#xA;  method: :post,&#xA;  path: &#39;/undocumented/endpoint&#39;,&#xA;  query: {&#34;dog&#34;: &#34;woof&#34;},&#xA;  headers: {&#34;useful-header&#34;: &#34;interesting-value&#34;},&#xA;  body: {&#34;hello&#34;: &#34;world&#34;}&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Concurrency &amp;amp; connection pooling&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;OpenAI::Client&lt;/code&gt; instances are threadsafe, but are only fork-safe when there are no in-flight HTTP requests.&lt;/p&gt; &#xA;&lt;p&gt;Each instance of &lt;code&gt;OpenAI::Client&lt;/code&gt; has its own HTTP connection pool with a default size of 99. As such, we recommend instantiating the client once per application in most settings.&lt;/p&gt; &#xA;&lt;p&gt;When all available connections from the pool are checked out, requests wait for a new connection to become available, with queue time counting towards the request timeout.&lt;/p&gt; &#xA;&lt;p&gt;Unless otherwise specified, other classes in the SDK do not have locks protecting their underlying data structure.&lt;/p&gt; &#xA;&lt;h2&gt;Sorbet&lt;/h2&gt; &#xA;&lt;p&gt;This library provides comprehensive &lt;a href=&#34;https://sorbet.org/docs/rbi&#34;&gt;RBI&lt;/a&gt; definitions and has no dependency on sorbet-runtime.&lt;/p&gt; &#xA;&lt;p&gt;You can provide typesafe request parameters like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;openai.chat.completions.create(&#xA;  messages: [OpenAI::Chat::ChatCompletionUserMessageParam.new(role: &#34;user&#34;, content: &#34;Say this is a test&#34;)],&#xA;  model: :&#34;gpt-4.1&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or, equivalently:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# Hashes work, but are not typesafe:&#xA;openai.chat.completions.create(&#xA;  messages: [{role: &#34;user&#34;, content: &#34;Say this is a test&#34;}],&#xA;  model: :&#34;gpt-4.1&#34;&#xA;)&#xA;&#xA;# You can also splat a full Params class:&#xA;params = OpenAI::Chat::CompletionCreateParams.new(&#xA;  messages: [OpenAI::Chat::ChatCompletionUserMessageParam.new(role: &#34;user&#34;, content: &#34;Say this is a test&#34;)],&#xA;  model: :&#34;gpt-4.1&#34;&#xA;)&#xA;openai.chat.completions.create(**params)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Enums&lt;/h3&gt; &#xA;&lt;p&gt;Since this library does not depend on &lt;code&gt;sorbet-runtime&lt;/code&gt;, it cannot provide &lt;a href=&#34;https://sorbet.org/docs/tenum&#34;&gt;&lt;code&gt;T::Enum&lt;/code&gt;&lt;/a&gt; instances. Instead, we provide &#34;tagged symbols&#34; instead, which is always a primitive at runtime:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# :low&#xA;puts(OpenAI::ReasoningEffort::LOW)&#xA;&#xA;# Revealed type: `T.all(OpenAI::ReasoningEffort, Symbol)`&#xA;T.reveal_type(OpenAI::ReasoningEffort::LOW)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Enum parameters have a &#34;relaxed&#34; type, so you can either pass in enum constants or their literal value:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# Using the enum constants preserves the tagged type information:&#xA;openai.chat.completions.create(&#xA;  reasoning_effort: OpenAI::ReasoningEffort::LOW,&#xA;  # …&#xA;)&#xA;&#xA;# Literal values are also permissible:&#xA;openai.chat.completions.create(&#xA;  reasoning_effort: :low,&#xA;  # …&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Versioning&lt;/h2&gt; &#xA;&lt;p&gt;This package follows &lt;a href=&#34;https://semver.org/spec/v2.0.0.html&#34;&gt;SemVer&lt;/a&gt; conventions. As the library is in initial development and has a major version of &lt;code&gt;0&lt;/code&gt;, APIs may change at any time.&lt;/p&gt; &#xA;&lt;p&gt;This package considers improvements to the (non-runtime) &lt;code&gt;*.rbi&lt;/code&gt; and &lt;code&gt;*.rbs&lt;/code&gt; type definitions to be non-breaking changes.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;Ruby 3.2.0 or higher.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/openai/openai-ruby/tree/main/CONTRIBUTING.md&#34;&gt;the contributing documentation&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>