<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Ruby Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-10T01:44:56Z</updated>
  <subtitle>Daily Trending of Ruby in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>serpapi/clauneck</title>
    <updated>2023-07-10T01:44:56Z</updated>
    <id>tag:github.com,2023-07-10:/serpapi/clauneck</id>
    <link href="https://github.com/serpapi/clauneck" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A tool for scraping emails, social media accounts, and much more information from websites using Google Search Results.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;Clauneck&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://rubygems.org/gems/clauneck&#34;&gt;&lt;img src=&#34;https://img.shields.io/gem/v/clauneck.svg?sanitize=true&#34; alt=&#34;Gem Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/serpapi/clauneck/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/serpapi/clauneck.svg?sanitize=true&#34; alt=&#34;Contributors&#34;&gt;&lt;/a&gt;  &lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/serpapi/clauneck/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/serpapi/clauneck.svg?sanitize=true&#34; alt=&#34;Forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/serpapi/clauneck/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/serpapi/clauneck.svg?sanitize=true&#34; alt=&#34;Stargazers&#34;&gt;&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/serpapi/clauneck/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/serpapi/clauneck.svg?sanitize=true&#34; alt=&#34;Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/serpapi/clauneck/issues?q=is%3Aissue+is%3Aclosed&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-closed/serpapi/clauneck.svg?sanitize=true&#34; alt=&#34;Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/serpapi/clauneck/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/serpapi/clauneck.svg?sanitize=true&#34; alt=&#34;MIT License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/73674035/251452240-e80b12d7-0c7a-40fc-9cbc-bb3bcb7986a8.png&#34; alt=&#34;Clauneck Information Scraper&#34; width=&#34;50%&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Clauneck&lt;/code&gt; is a Ruby gem designed to scrape specific information from a series of URLs, either directly provided or fetched from Google search results via &lt;a href=&#34;https://serpapi.com/search-api&#34;&gt;SerpApi&#39;s Google Search API&lt;/a&gt;. It extracts and matches patterns such as email addresses and social media handles from the web pages, and stores the results in a CSV file.&lt;/p&gt; &#xA;&lt;p&gt;Unlike Google Chrome extensions that need you to visit webpages one by one, Clauneck excels in bringing the list of websites to you by leveraging &lt;a href=&#34;https://serpapi.com/search-api&#34;&gt;SerpApi’s Google Search API&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://serpapi.com/blog/cold-email-marketing-with-open-source-email-extractor/&#34;&gt;Cold Email Marketing with Open-Source Email Extractor&lt;/a&gt;: A Blog Post about the usecase of the tool&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;The End Result&lt;/h2&gt; &#xA;&lt;p&gt;The script will write the results in a CSV file. If it cannot find any one of the information on a website, it will label it as &lt;code&gt;null&lt;/code&gt;. For unknown errors happening in-between (connection errors, encoding errors, etc.) the fields will be filled with as &lt;code&gt;error&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Website&lt;/th&gt; &#xA;   &lt;th&gt;Information&lt;/th&gt; &#xA;   &lt;th&gt;Type of Information&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;serpapi.com&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;contact@serpapi.com&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Email&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;serpapi.com&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;serpapicom&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Instagram&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;serpapi.com&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;serpapicom&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Facebook&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;serpapi.com&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;serp_api&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Twitter&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;serpapi.com&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Tiktok&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;serpapi.com&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;channel/UCUgIHlYBOD3yA3yDIRhg_mg&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Youtube&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;serpapi.com&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;serpapi&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Github&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;serpapi.com&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;serpapi&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Medium&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;Since &lt;a href=&#34;https://serpapi.com&#34;&gt;SerpApi&lt;/a&gt; offers free credits that renew every month, and the user can access a list of free public proxies online, this tool’s pricing is technically free. You may extract data from approximately 10,000 pages (100 results in 1 page, and up to 100 pages) with a free account from &lt;a href=&#34;https://serpapi.com&#34;&gt;SerpApi&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For collecting URLs to scrape, one of the following is required: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;SerpApi API Key: You may &lt;a href=&#34;https://serpapi.com/users/sign_up&#34;&gt;Register to Claim Free Credits&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;List of URLs in a text document (The URLs should be Google web cache links that start with &lt;code&gt;https://webcache.googleusercontent.com&lt;/code&gt;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;For scraping URLs, one of the following is required: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;List of Proxies in a text document (You may use public proxies. Only HTTP proxies are accepted.)&lt;/li&gt; &#xA;   &lt;li&gt;Rotating Proxy IP&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Add this line to your application&#39;s Gemfile:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;gem &#39;clauneck&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then execute:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ bundle install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or install it yourself as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ gem install clauneck&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Basic Usage&lt;/h2&gt; &#xA;&lt;p&gt;You can use &lt;code&gt;Clauneck&lt;/code&gt; as a command line tool or within your Ruby scripts.&lt;/p&gt; &#xA;&lt;h3&gt;Basic Command line usage&lt;/h3&gt; &#xA;&lt;p&gt;In the command line, use the &lt;code&gt;clauneck&lt;/code&gt; command with options as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;clauneck --api_key YOUR_SERPAPI_KEY --output results.csv --q &#34;site:*.ai AND inurl:/contact OR inurl:/contact-us&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Basic Ruby script usage&lt;/h3&gt; &#xA;&lt;p&gt;In your Ruby script, call &lt;code&gt;Clauneck.run&lt;/code&gt; method:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;require &#39;clauneck&#39;&#xA;&#xA;api_key = &#34;&amp;lt;SerpApi API Key&amp;gt;&#34; # Visit https://serpapi.com/users/sign_up to get free credits.&#xA;params = {&#xA;  &#34;q&#34;: &#34;site:*.ai AND inurl:/contact OR inurl:/contact-us&#34;&#xA;}&#xA;&#xA;Clauneck.run(api_key: api_key, params: params)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Advanced Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Using Advanced Search Parameters&lt;/h3&gt; &#xA;&lt;p&gt;You can visit the Documentation for &lt;a href=&#34;https://serpapi.com/search-api&#34;&gt;SerpApi&#39;s Google Search API&lt;/a&gt; to get insight on which parameters you can use to construct searches.&lt;/p&gt; &#xA;&lt;img width=&#34;1470&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/73674035/251473233-4be601c1-846b-4ae6-bb65-4c45aa22667d.png&#34;&gt; &#xA;&lt;h3&gt;Using Advanced Search Operators&lt;/h3&gt; &#xA;&lt;p&gt;Google allows different search operators in queries to be made. This enhances your abilty to customize your search and get more precise results. For example, this search query: &lt;code&gt;&#34;site:*.ai AND inurl:/contact OR inurl:/contact-us&#34;&lt;/code&gt; will search for websites ending with &lt;code&gt;.ai&lt;/code&gt; and at &lt;code&gt;/contact&lt;/code&gt; or &lt;code&gt;/contact-us&lt;/code&gt; paths.&lt;/p&gt; &#xA;&lt;p&gt;You may check out &lt;a href=&#34;https://ahrefs.com/blog/google-advanced-search-operators/&#34;&gt;Google Search Operators: The Complete List (44 Advanced Operators)&lt;/a&gt; for a list of more operators&lt;/p&gt; &#xA;&lt;h3&gt;Using Proxies for Scraping in a Text Document&lt;/h3&gt; &#xA;&lt;p&gt;You can utilize your own proxies for scraping web caches of the links you have acquired. Only HTTP proxies are accepted. The proxies should be in the following format&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;http://username:password@ip:port&#xA;http://username:password@another-ip:another-port&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or if they are public proxies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;http://ip:port&#xA;http://another-ip:another-port&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can add --proxy option in the command line to utilize the file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;clauneck --api_key YOUR_SERPAPI_KEY --proxy proxies.txt --output results.csv --q &#34;site:*.ai AND inurl:/contact OR inurl:/contact-us&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or use the rotating proxy link directly:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;clauneck --api_key YOUR_SERPAPI_KEY --proxy &#34;http://username:password@ip:port&#34; --output results.csv --q &#34;site:*.ai AND inurl:/contact OR inurl:/contact-us&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may also use it in a script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-rb&#34;&gt;api_key = &#34;&amp;lt;SerpApi API Key&amp;gt;&#34; # Visit https://serpapi.com/users/sign_up to get free credits.&#xA;params = {&#xA;  &#34;q&#34;: &#34;site:*.ai AND inurl:/contact OR inurl:/contact-us&#34;&#xA;}&#xA;proxy = &#34;proxies.txt&#34;&#xA;&#xA;Clauneck.run(api_key: api_key, params: params, proxy: proxy)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or directly use the rotating proxy link:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-rb&#34;&gt;api_key = &#34;&amp;lt;SerpApi API Key&amp;gt;&#34; # Visit https://serpapi.com/users/sign_up to get free credits.&#xA;params = {&#xA;  &#34;q&#34;: &#34;site:*.ai AND inurl:/contact OR inurl:/contact-us&#34;&#xA;}&#xA;proxy = &#34;http://username:password@ip:port&#34;&#xA;&#xA;Clauneck.run(api_key: api_key, params: params, proxy: proxy)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The System IP Address will be used if no proxy is provided. The user can use System IP for small-scale projects. But it is not recommended.&lt;/p&gt; &#xA;&lt;h3&gt;Using Google Search URL to Scrape links with SerpApi&lt;/h3&gt; &#xA;&lt;p&gt;Instead of providing search parameters, the user can directly feed a Google Search URL for the web cache links to be collected by &lt;a href=&#34;https://serpapi.com/search-api&#34;&gt;SerpApi&#39;s Google Search API&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Using URLs to Scrape in a Text Document&lt;/h3&gt; &#xA;&lt;p&gt;The user may utilize their own list of URLs to be scraped. The URLs should start with &lt;code&gt;https://webcache.googleusercontent.com&lt;/code&gt;, and be added to each line. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;https://webcache.googleusercontent.com/search?q=cache:LItv_3DO2N8J:https://serpapi.com/&amp;amp;cd=10&amp;amp;hl=en&amp;amp;ct=clnk&amp;amp;gl=cy&#xA;https://webcache.googleusercontent.com/search?q=cache:_gaXFsYVmCgJ:https://serpapi.com/search-api&amp;amp;cd=9&amp;amp;hl=en&amp;amp;ct=clnk&amp;amp;gl=cy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can find cached links manually from Google Searches as shown below:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/73674035/251461862-5cc1e279-9d5c-4885-aebd-317512ae62ea.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Options&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;Clauneck&lt;/code&gt; accepts the following options:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--api_key&lt;/code&gt;: Your SerpApi key. It is required if you&#39;re not providing the &lt;code&gt;--urls&lt;/code&gt; option.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--proxy&lt;/code&gt;: Your proxy file or proxy URL. Defaults to system IP if not provided.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--pages&lt;/code&gt;: The number of pages to fetch from Google using SerpApi. Defaults to &lt;code&gt;1&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--output&lt;/code&gt;: The CSV output file where to store the results. Defaults to &lt;code&gt;output.csv&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--google_url&lt;/code&gt;: The Google URL that contains the webpages you want to scrape. It should be a Google Search Results URL.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--urls&lt;/code&gt;: The URLs you want to scrape. If provided, the gem will not fetch URLs from Google.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--help&lt;/code&gt;: Shows the help message and exits.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Bug reports and pull requests are welcome on GitHub at &lt;a href=&#34;https://github.com/serpapi/clauneck&#34;&gt;https://github.com/serpapi/clauneck&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The gem is available as open source under the terms of the &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;MIT License&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>