<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Ruby Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-21T01:34:35Z</updated>
  <subtitle>Daily Trending of Ruby in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>rails/solid_queue</title>
    <updated>2024-03-21T01:34:35Z</updated>
    <id>tag:github.com,2024-03-21:/rails/solid_queue</id>
    <link href="https://github.com/rails/solid_queue" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Database-backed Active Job backend&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Solid Queue&lt;/h1&gt; &#xA;&lt;p&gt;Solid Queue is a DB-based queuing backend for &lt;a href=&#34;https://edgeguides.rubyonrails.org/active_job_basics.html&#34;&gt;Active Job&lt;/a&gt;, designed with simplicity and performance in mind.&lt;/p&gt; &#xA;&lt;p&gt;Besides regular job enqueuing and processing, Solid Queue supports delayed jobs, concurrency controls, pausing queues, numeric priorities per job, priorities by queue order, and bulk enqueuing (&lt;code&gt;enqueue_all&lt;/code&gt; for Active Job&#39;s &lt;code&gt;perform_all_later&lt;/code&gt;). &lt;em&gt;Improvements to logging and instrumentation, a better CLI tool, a way to run within an existing process in &#34;async&#34; mode, and some way of specifying unique jobs are coming very soon.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Solid Queue can be used with SQL databases such as MySQL, PostgreSQL or SQLite, and it leverages the &lt;code&gt;FOR UPDATE SKIP LOCKED&lt;/code&gt; clause, if available, to avoid blocking and waiting on locks when polling jobs. It relies on Active Job for retries, discarding, error handling, serialization, or delays, and it&#39;s compatible with Ruby on Rails multi-threading.&lt;/p&gt; &#xA;&lt;h2&gt;Installation and usage&lt;/h2&gt; &#xA;&lt;p&gt;Add this line to your application&#39;s Gemfile:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;gem &#34;solid_queue&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then execute:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ bundle&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or install it yourself as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ gem install solid_queue&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now, you need to install the necessary migrations and configure the Active Job&#39;s adapter. You can do both at once using the provided generator:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ bin/rails generate solid_queue:install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will set &lt;code&gt;solid_queue&lt;/code&gt; as the Active Job&#39;s adapter in production, and will copy the required migration over to your app.&lt;/p&gt; &#xA;&lt;p&gt;Alternatively, you can add only the migration to your app:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ bin/rails solid_queue:install:migrations&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And set Solid Queue as your Active Job&#39;s queue backend manually, in your environment config:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# config/environments/production.rb&#xA;config.active_job.queue_adapter = :solid_queue&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, you can set only specific jobs to use Solid Queue as their backend if you&#39;re migrating from another adapter and want to move jobs progressively:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# app/jobs/my_job.rb&#xA;&#xA;class MyJob &amp;lt; ApplicationJob&#xA;  self.queue_adapter = :solid_queue&#xA;  # ...&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, you need to run the migrations:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ bin/rails db:migrate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After this, you&#39;ll be ready to enqueue jobs using Solid Queue, but you need to start Solid Queue&#39;s supervisor to run them.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ bundle exec rake solid_queue:start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will start processing jobs in all queues using the default configuration. See &lt;a href=&#34;https://raw.githubusercontent.com/rails/solid_queue/main/#configuration&#34;&gt;below&lt;/a&gt; to learn more about configuring Solid Queue.&lt;/p&gt; &#xA;&lt;p&gt;For small projects, you can run Solid Queue on the same machine as your webserver. When you&#39;re ready to scale, Solid Queue supports horizontal scaling out-of-the-box. You can run Solid Queue on a separate server from your webserver, or even run &lt;code&gt;bundle exec rake solid_queue:start&lt;/code&gt; on multiple machines at the same time. If you&#39;d like to designate some machines to be only dispatchers or only workers, use &lt;code&gt;bundle exec rake solid_queue:dispatch&lt;/code&gt; or &lt;code&gt;bundle exec rake solid_queue:work&lt;/code&gt;, respectively.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;Besides Rails 7.1, Solid Queue works best with MySQL 8+ or PostgreSQL 9.5+, as they support &lt;code&gt;FOR UPDATE SKIP LOCKED&lt;/code&gt;. You can use it with older versions, but in that case, you might run into lock waits if you run multiple workers for the same queue.&lt;/p&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;h3&gt;Workers and dispatchers&lt;/h3&gt; &#xA;&lt;p&gt;We have three types of processes in Solid Queue:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;Workers&lt;/em&gt; are in charge of picking jobs ready to run from queues and processing them. They work off the &lt;code&gt;solid_queue_ready_executions&lt;/code&gt; table.&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;Dispatchers&lt;/em&gt; are in charge of selecting jobs scheduled to run in the future that are due and &lt;em&gt;dispatching&lt;/em&gt; them, which is simply moving them from the &lt;code&gt;solid_queue_scheduled_executions&lt;/code&gt; table over to the &lt;code&gt;solid_queue_ready_executions&lt;/code&gt; table so that workers can pick them up. They&#39;re also in charge of managing &lt;a href=&#34;https://raw.githubusercontent.com/rails/solid_queue/main/#recurring-tasks&#34;&gt;recurring tasks&lt;/a&gt;, dispatching jobs to process them according to their schedule. On top of that, they do some maintenance work related to &lt;a href=&#34;https://raw.githubusercontent.com/rails/solid_queue/main/#concurrency-controls&#34;&gt;concurrency controls&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;em&gt;supervisor&lt;/em&gt; forks workers and dispatchers according to the configuration, controls their heartbeats, and sends them signals to stop and start them when needed.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;By default, Solid Queue will try to find your configuration under &lt;code&gt;config/solid_queue.yml&lt;/code&gt;, but you can set a different path using the environment variable &lt;code&gt;SOLID_QUEUE_CONFIG&lt;/code&gt;. This is what this configuration looks like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;production:&#xA;  dispatchers:&#xA;    - polling_interval: 1&#xA;      batch_size: 500&#xA;      concurrency_maintenance_interval: 300&#xA;  workers:&#xA;    - queues: &#34;*&#34;&#xA;      threads: 3&#xA;      polling_interval: 2&#xA;    - queues: [ real_time, background ]&#xA;      threads: 5&#xA;      polling_interval: 0.1&#xA;      processes: 3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Everything is optional. If no configuration is provided, Solid Queue will run with one dispatcher and one worker with default settings.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;polling_interval&lt;/code&gt;: the time interval in seconds that workers and dispatchers will wait before checking for more jobs. This time defaults to &lt;code&gt;1&lt;/code&gt; second for dispatchers and &lt;code&gt;0.1&lt;/code&gt; seconds for workers.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;batch_size&lt;/code&gt;: the dispatcher will dispatch jobs in batches of this size. The default is 500.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;concurrency_maintenance_interval&lt;/code&gt;: the time interval in seconds that the dispatcher will wait before checking for blocked jobs that can be unblocked. Read more about &lt;a href=&#34;https://raw.githubusercontent.com/rails/solid_queue/main/#concurrency-controls&#34;&gt;concurrency controls&lt;/a&gt; to learn more about this setting. It defaults to &lt;code&gt;600&lt;/code&gt; seconds.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;queues&lt;/code&gt;: the list of queues that workers will pick jobs from. You can use &lt;code&gt;*&lt;/code&gt; to indicate all queues (which is also the default and the behaviour you&#39;ll get if you omit this). You can provide a single queue, or a list of queues as an array. Jobs will be polled from those queues in order, so for example, with &lt;code&gt;[ real_time, background ]&lt;/code&gt;, no jobs will be taken from &lt;code&gt;background&lt;/code&gt; unless there aren&#39;t any more jobs waiting in &lt;code&gt;real_time&lt;/code&gt;. You can also provide a prefix with a wildcard to match queues starting with a prefix. For example:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;staging:&#xA;  workers:&#xA;    - queues: staging*&#xA;      threads: 3&#xA;      polling_interval: 5&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This will create a worker fetching jobs from all queues starting with &lt;code&gt;staging&lt;/code&gt;. The wildcard &lt;code&gt;*&lt;/code&gt; is only allowed on its own or at the end of a queue name; you can&#39;t specify queue names such as &lt;code&gt;*_some_queue&lt;/code&gt;. These will be ignored.&lt;/p&gt; &lt;p&gt;Finally, you can combine prefixes with exact names, like &lt;code&gt;[ staging*, background ]&lt;/code&gt;, and the behaviour with respect to order will be the same as with only exact names.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;threads&lt;/code&gt;: this is the max size of the thread pool that each worker will have to run jobs. Each worker will fetch this number of jobs from their queue(s), at most and will post them to the thread pool to be run. By default, this is &lt;code&gt;3&lt;/code&gt;. Only workers have this setting.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;processes&lt;/code&gt;: this is the number of worker processes that will be forked by the supervisor with the settings given. By default, this is &lt;code&gt;1&lt;/code&gt;, just a single process. This setting is useful if you want to dedicate more than one CPU core to a queue or queues with the same configuration. Only workers have this setting.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;concurrency_maintenance&lt;/code&gt;: whether the dispatcher will perform the concurrency maintenance work. This is &lt;code&gt;true&lt;/code&gt; by default, and it&#39;s useful if you don&#39;t use any &lt;a href=&#34;https://raw.githubusercontent.com/rails/solid_queue/main/#concurrency-controls&#34;&gt;concurrency controls&lt;/a&gt; and want to disable it or if you run multiple dispatchers and want some of them to just dispatch jobs without doing anything else.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;recurring_tasks&lt;/code&gt;: a list of recurring tasks the dispatcher will manage. Read more details about this one in the &lt;a href=&#34;https://raw.githubusercontent.com/rails/solid_queue/main/#recurring-tasks&#34;&gt;Recurring tasks&lt;/a&gt; section.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Queue order and priorities&lt;/h3&gt; &#xA;&lt;p&gt;As mentioned above, if you specify a list of queues for a worker, these will be polled in the order given, such as for the list &lt;code&gt;real_time,background&lt;/code&gt;, no jobs will be taken from &lt;code&gt;background&lt;/code&gt; unless there aren&#39;t any more jobs waiting in &lt;code&gt;real_time&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Active Job also supports positive integer priorities when enqueuing jobs. In Solid Queue, the smaller the value, the higher the priority. The default is &lt;code&gt;0&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;This is useful when you run jobs with different importance or urgency in the same queue. Within the same queue, jobs will be picked in order of priority, but in a list of queues, the queue order takes precedence, so in the previous example with &lt;code&gt;real_time,background&lt;/code&gt;, jobs in the &lt;code&gt;real_time&lt;/code&gt; queue will be picked before jobs in the &lt;code&gt;background&lt;/code&gt; queue, even if those in the &lt;code&gt;background&lt;/code&gt; queue have a higher priority (smaller value) set.&lt;/p&gt; &#xA;&lt;p&gt;We recommend not mixing queue order with priorities but either choosing one or the other, as that will make job execution order more straightforward for you.&lt;/p&gt; &#xA;&lt;h3&gt;Threads, processes and signals&lt;/h3&gt; &#xA;&lt;p&gt;Workers in Solid Queue use a thread pool to run work in multiple threads, configurable via the &lt;code&gt;threads&lt;/code&gt; parameter above. Besides this, parallelism can be achieved via multiple processes on one machine (configurable via different workers or the &lt;code&gt;processes&lt;/code&gt; parameter above) or by horizontal scaling.&lt;/p&gt; &#xA;&lt;p&gt;The supervisor is in charge of managing these processes, and it responds to the following signals:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;TERM&lt;/code&gt;, &lt;code&gt;INT&lt;/code&gt;: starts graceful termination. The supervisor will send a &lt;code&gt;TERM&lt;/code&gt; signal to its supervised processes, and it&#39;ll wait up to &lt;code&gt;SolidQueue.shutdown_timeout&lt;/code&gt; time until they&#39;re done. If any supervised processes are still around by then, it&#39;ll send a &lt;code&gt;QUIT&lt;/code&gt; signal to them to indicate they must exit.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;QUIT&lt;/code&gt;: starts immediate termination. The supervisor will send a &lt;code&gt;QUIT&lt;/code&gt; signal to its supervised processes, causing them to exit immediately.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When receiving a &lt;code&gt;QUIT&lt;/code&gt; signal, if workers still have jobs in-flight, these will be returned to the queue when the processes are deregistered.&lt;/p&gt; &#xA;&lt;p&gt;If processes have no chance of cleaning up before exiting (e.g. if someone pulls a cable somewhere), in-flight jobs might remain claimed by the processes executing them. Processes send heartbeats, and the supervisor checks and prunes processes with expired heartbeats, which will release any claimed jobs back to their queues. You can configure both the frequency of heartbeats and the threshold to consider a process dead. See the section below for this.&lt;/p&gt; &#xA;&lt;h3&gt;Other configuration settings&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: The settings in this section should be set in your &lt;code&gt;config/application.rb&lt;/code&gt; or your environment config like this: &lt;code&gt;config.solid_queue.silence_polling = true&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;There are several settings that control how Solid Queue works that you can set as well:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;logger&lt;/code&gt;: the logger you want Solid Queue to use. Defaults to the app logger.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;app_executor&lt;/code&gt;: the &lt;a href=&#34;https://guides.rubyonrails.org/threading_and_code_execution.html#executor&#34;&gt;Rails executor&lt;/a&gt; used to wrap asynchronous operations, defaults to the app executor&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;on_thread_error&lt;/code&gt;: custom lambda/Proc to call when there&#39;s an error within a thread that takes the exception raised as argument. Defaults to&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;-&amp;gt; (exception) { Rails.error.report(exception, handled: false) }&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;connects_to&lt;/code&gt;: a custom database configuration that will be used in the abstract &lt;code&gt;SolidQueue::Record&lt;/code&gt; Active Record model. This is required to use a different database than the main app. For example:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# Use a separate DB for Solid Queue&#xA;config.solid_queue.connects_to = { database: { writing: :solid_queue_primary, reading: :solid_queue_replica } }&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;use_skip_locked&lt;/code&gt;: whether to use &lt;code&gt;FOR UPDATE SKIP LOCKED&lt;/code&gt; when performing locking reads. This will be automatically detected in the future, and for now, you&#39;d only need to set this to &lt;code&gt;false&lt;/code&gt; if your database doesn&#39;t support it. For MySQL, that&#39;d be versions &amp;lt; 8, and for PostgreSQL, versions &amp;lt; 9.5. If you use SQLite, this has no effect, as writes are sequential.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;process_heartbeat_interval&lt;/code&gt;: the heartbeat interval that all processes will follow—defaults to 60 seconds.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;process_alive_threshold&lt;/code&gt;: how long to wait until a process is considered dead after its last heartbeat—defaults to 5 minutes.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;shutdown_timeout&lt;/code&gt;: time the supervisor will wait since it sent the &lt;code&gt;TERM&lt;/code&gt; signal to its supervised processes before sending a &lt;code&gt;QUIT&lt;/code&gt; version to them requesting immediate termination—defaults to 5 seconds.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;silence_polling&lt;/code&gt;: whether to silence Active Record logs emitted when polling for both workers and dispatchers—defaults to &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;supervisor_pidfile&lt;/code&gt;: path to a pidfile that the supervisor will create when booting to prevent running more than one supervisor in the same host, or in case you want to use it for a health check. It&#39;s &lt;code&gt;nil&lt;/code&gt; by default.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;preserve_finished_jobs&lt;/code&gt;: whether to keep finished jobs in the &lt;code&gt;solid_queue_jobs&lt;/code&gt; table—defaults to &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;clear_finished_jobs_after&lt;/code&gt;: period to keep finished jobs around, in case &lt;code&gt;preserve_finished_jobs&lt;/code&gt; is true—defaults to 1 day. &lt;strong&gt;Note:&lt;/strong&gt; Right now, there&#39;s no automatic cleanup of finished jobs. You&#39;d need to do this by periodically invoking &lt;code&gt;SolidQueue::Job.clear_finished_in_batches&lt;/code&gt;, but this will happen automatically in the near future.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;default_concurrency_control_period&lt;/code&gt;: the value to be used as the default for the &lt;code&gt;duration&lt;/code&gt; parameter in &lt;a href=&#34;https://raw.githubusercontent.com/rails/solid_queue/main/#concurrency-controls&#34;&gt;concurrency controls&lt;/a&gt;. It defaults to 3 minutes.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Concurrency controls&lt;/h2&gt; &#xA;&lt;p&gt;Solid Queue extends Active Job with concurrency controls, that allows you to limit how many jobs of a certain type or with certain arguments can run at the same time. When limited in this way, jobs will be blocked from running, and they&#39;ll stay blocked until another job finishes and unblocks them, or after the set expiry time (concurrency limit&#39;s &lt;em&gt;duration&lt;/em&gt;) elapses. Jobs are never discarded or lost, only blocked.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;class MyJob &amp;lt; ApplicationJob&#xA;  limits_concurrency to: max_concurrent_executions, key: -&amp;gt;(arg1, arg2, **) { ... }, duration: max_interval_to_guarantee_concurrency_limit, group: concurrency_group&#xA;&#xA;  # ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;key&lt;/code&gt; is the only required parameter, and it can be a symbol, a string or a proc that receives the job arguments as parameters and will be used to identify the jobs that need to be limited together. If the proc returns an Active Record record, the key will be built from its class name and &lt;code&gt;id&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;to&lt;/code&gt; is &lt;code&gt;1&lt;/code&gt; by default, and &lt;code&gt;duration&lt;/code&gt; is set to &lt;code&gt;SolidQueue.default_concurrency_control_period&lt;/code&gt; by default, which itself defaults to &lt;code&gt;3 minutes&lt;/code&gt;, but that you can configure as well.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;group&lt;/code&gt; is used to control the concurrency of different job classes together. It defaults to the job class name.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When a job includes these controls, we&#39;ll ensure that, at most, the number of jobs (indicated as &lt;code&gt;to&lt;/code&gt;) that yield the same &lt;code&gt;key&lt;/code&gt; will be performed concurrently, and this guarantee will last for &lt;code&gt;duration&lt;/code&gt; for each job enqueued. Note that there&#39;s no guarantee about &lt;em&gt;the order of execution&lt;/em&gt;, only about jobs being performed at the same time (overlapping).&lt;/p&gt; &#xA;&lt;p&gt;For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;class DeliverAnnouncementToContactJob &amp;lt; ApplicationJob&#xA;  limits_concurrency to: 2, key: -&amp;gt;(contact) { contact.account }, duration: 5.minutes&#xA;&#xA;  def perform(contact)&#xA;    # ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Where &lt;code&gt;contact&lt;/code&gt; and &lt;code&gt;account&lt;/code&gt; are &lt;code&gt;ActiveRecord&lt;/code&gt; records. In this case, we&#39;ll ensure that at most two jobs of the kind &lt;code&gt;DeliverAnnouncementToContact&lt;/code&gt; for the same account will run concurrently. If, for any reason, one of those jobs takes longer than 5 minutes or doesn&#39;t release its concurrency lock within 5 minutes of acquiring it, a new job with the same key might gain the lock.&lt;/p&gt; &#xA;&lt;p&gt;Let&#39;s see another example using &lt;code&gt;group&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;class Box::MovePostingsByContactToDesignatedBoxJob &amp;lt; ApplicationJob&#xA;  limits_concurrency key: -&amp;gt;(contact) { contact }, duration: 15.minutes, group: &#34;ContactActions&#34;&#xA;&#xA;  def perform(contact)&#xA;    # ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;class Bundle::RebundlePostingsJob &amp;lt; ApplicationJob&#xA;  limits_concurrency key: -&amp;gt;(bundle) { bundle.contact }, duration: 15.minutes, group: &#34;ContactActions&#34;&#xA;&#xA;  def perform(bundle)&#xA;    # ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In this case, if we have a &lt;code&gt;Box::MovePostingsByContactToDesignatedBoxJob&lt;/code&gt; job enqueued for a contact record with id &lt;code&gt;123&lt;/code&gt; and another &lt;code&gt;Bundle::RebundlePostingsJob&lt;/code&gt; job enqueued simultaneously for a bundle record that references contact &lt;code&gt;123&lt;/code&gt;, only one of them will be allowed to proceed. The other one will stay blocked until the first one finishes (or 15 minutes pass, whatever happens first).&lt;/p&gt; &#xA;&lt;p&gt;Note that the &lt;code&gt;duration&lt;/code&gt; setting depends indirectly on the value for &lt;code&gt;concurrency_maintenance_interval&lt;/code&gt; that you set for your dispatcher(s), as that&#39;d be the frequency with which blocked jobs are checked and unblocked. In general, you should set &lt;code&gt;duration&lt;/code&gt; in a way that all your jobs would finish well under that duration and think of the concurrency maintenance task as a failsafe in case something goes wrong.&lt;/p&gt; &#xA;&lt;p&gt;Finally, failed jobs that are automatically or manually retried work in the same way as new jobs that get enqueued: they get in the queue for gaining the lock, and whenever they get it, they&#39;ll be run. It doesn&#39;t matter if they had gained the lock already in the past.&lt;/p&gt; &#xA;&lt;h2&gt;Failed jobs and retries&lt;/h2&gt; &#xA;&lt;p&gt;Solid Queue doesn&#39;t include any automatic retry mechanism, it &lt;a href=&#34;https://edgeguides.rubyonrails.org/active_job_basics.html#retrying-or-discarding-failed-jobs&#34;&gt;relies on Active Job for this&lt;/a&gt;. Jobs that fail will be kept in the system, and a &lt;em&gt;failed execution&lt;/em&gt; (a record in the &lt;code&gt;solid_queue_failed_executions&lt;/code&gt; table) will be created for these. The job will stay there until manually discarded or re-enqueued. You can do this in a console as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;failed_execution = SolidQueue::FailedExecution.find(...) # Find the failed execution related to your job&#xA;failed_execution.error # inspect the error&#xA;&#xA;failed_execution.retry # This will re-enqueue the job as if it was enqueued for the first time&#xA;failed_execution.discard # This will delete the job from the system&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;However, we recommend taking a look at &lt;a href=&#34;https://github.com/basecamp/mission_control-jobs&#34;&gt;mission_control-jobs&lt;/a&gt;, a dashboard where, among other things, you can examine and retry/discard failed jobs.&lt;/p&gt; &#xA;&lt;h2&gt;Puma plugin&lt;/h2&gt; &#xA;&lt;p&gt;We provide a Puma plugin if you want to run the Solid Queue&#39;s supervisor together with Puma and have Puma monitor and manage it. You just need to add&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;plugin :solid_queue&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to your &lt;code&gt;puma.rb&lt;/code&gt; configuration.&lt;/p&gt; &#xA;&lt;h2&gt;Jobs and transactional integrity&lt;/h2&gt; &#xA;&lt;p&gt;&lt;span&gt;⚠&lt;/span&gt; Having your jobs in the same ACID-compliant database as your application data enables a powerful yet sharp tool: taking advantage of transactional integrity to ensure some action in your app is not committed unless your job is also committed. This can be very powerful and useful, but it can also backfire if you base some of your logic on this behaviour, and in the future, you move to another active job backend, or if you simply move Solid Queue to its own database, and suddenly the behaviour changes under you.&lt;/p&gt; &#xA;&lt;p&gt;If you prefer not to rely on this, or avoid relying on it unintentionally, you should make sure that:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Your jobs relying on specific records are always enqueued on &lt;a href=&#34;https://guides.rubyonrails.org/active_record_callbacks.html#after-commit-and-after-rollback&#34;&gt;&lt;code&gt;after_commit&lt;/code&gt; callbacks&lt;/a&gt; or otherwise from a place where you&#39;re certain that whatever data the job will use has been committed to the database before the job is enqueued.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Or, to opt out completely from this behaviour, configure a database for Solid Queue, even if it&#39;s the same as your app, ensuring that a different connection on the thread handling requests or running jobs for your app will be used to enqueue jobs. For example:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;class ApplicationRecord &amp;lt; ActiveRecord::Base&#xA;  self.abstract_class = true&#xA;&#xA;  connects_to database: { writing: :primary, reading: :replica }&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;config.solid_queue.connects_to = { database: { writing: :primary, reading: :replica } }&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Inspiration&lt;/h2&gt; &#xA;&lt;p&gt;Solid Queue has been inspired by &lt;a href=&#34;https://github.com/resque/resque&#34;&gt;resque&lt;/a&gt; and &lt;a href=&#34;https://github.com/bensheldon/good_job&#34;&gt;GoodJob&lt;/a&gt;. We recommend checking out these projects as they&#39;re great examples from which we&#39;ve learnt a lot.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The gem is available as open source under the terms of the &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;MIT License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Recurring tasks&lt;/h2&gt; &#xA;&lt;p&gt;Solid Queue supports defining recurring tasks that run at specific times in the future, on a regular basis like cron jobs. These are managed by dispatcher processes and as such, they can be defined in the dispatcher&#39;s configuration like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;  dispatchers:&#xA;    - polling_interval: 1&#xA;      batch_size: 500&#xA;      recurring_tasks:&#xA;        my_periodic_job:&#xA;          class: MyJob&#xA;          args: [ 42, { status: &#34;custom_status&#34; } ]&#xA;          schedule: every second&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;recurring_tasks&lt;/code&gt; is a hash/dictionary, and the key will be the task key internally. Each task needs to have a class, which will be the job class to enqueue, and a schedule. The schedule is parsed using &lt;a href=&#34;https://github.com/floraison/fugit&#34;&gt;Fugit&lt;/a&gt;, so it accepts anything &lt;a href=&#34;https://github.com/floraison/fugit?tab=readme-ov-file#fugitcron&#34;&gt;that Fugit accepts as a cron&lt;/a&gt;. You can also provide arguments to be passed to the job, as a single argument, a hash, or an array of arguments that can also include kwargs as the last element in the array.&lt;/p&gt; &#xA;&lt;p&gt;The job in the example configuration above will be enqueued every second as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;MyJob.perform_later(42, status: &#34;custom_status&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Tasks are enqueued at their corresponding times by the dispatcher that owns them, and each task schedules the next one. This is pretty much &lt;a href=&#34;https://github.com/bensheldon/good_job/raw/994ecff5323bf0337e10464841128fda100750e6/lib/good_job/cron_manager.rb&#34;&gt;inspired by what GoodJob does&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s possible to run multiple dispatchers with the same &lt;code&gt;recurring_tasks&lt;/code&gt; configuration. To avoid enqueuing duplicate tasks at the same time, an entry in a new &lt;code&gt;solid_queue_recurring_executions&lt;/code&gt; table is created in the same transaction as the job is enqueued. This table has a unique index on &lt;code&gt;task_key&lt;/code&gt; and &lt;code&gt;run_at&lt;/code&gt;, ensuring only one entry per task per time will be created. This only works if you have &lt;code&gt;preserve_finished_jobs&lt;/code&gt; set to &lt;code&gt;true&lt;/code&gt; (the default), and the guarantee applies as long as you keep the jobs around.&lt;/p&gt; &#xA;&lt;p&gt;Finally, it&#39;s possible to configure jobs that aren&#39;t handled by Solid Queue. That&#39;s it, you can a have a job like this in your app:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;class MyResqueJob &amp;lt; ApplicationJob&#xA;  self.queue_adapter = :resque&#xA;&#xA;  def perform(arg)&#xA;    # ..&#xA;  end&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can still configure this in Solid Queue:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;  dispatchers:&#xA;    - recurring_tasks:&#xA;        my_periodic_resque_job:&#xA;          class: MyResqueJob&#xA;          args: 22&#xA;          schedule: &#34;*/5 * * * *&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and the job will be enqueued via &lt;code&gt;perform_later&lt;/code&gt; so it&#39;ll run in Resque. However, in this case we won&#39;t track any &lt;code&gt;solid_queue_recurring_execution&lt;/code&gt; record for it and there won&#39;t be any guarantees that the job is enqueued only once each time.&lt;/p&gt;</summary>
  </entry>
</feed>