<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Ruby Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-05-05T01:37:18Z</updated>
  <subtitle>Daily Trending of Ruby in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>crmne/ruby_llm</title>
    <updated>2025-05-05T01:37:18Z</updated>
    <id>tag:github.com,2025-05-05:/crmne/ruby_llm</id>
    <link href="https://github.com/crmne/ruby_llm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Stop juggling AI SDKs! RubyLLM offers one delightful Ruby interface for OpenAI, Anthropic, Gemini, Bedrock, OpenRouter, DeepSeek, Ollama &amp; compatible APIs. Chat, Vision, Audio, PDF, Images, Embeddings, Tools, Streaming &amp; Rails integration.&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://raw.githubusercontent.com/crmne/ruby_llm/main/docs/assets/images/logotype.svg?sanitize=true&#34; alt=&#34;RubyLLM&#34; height=&#34;120&#34; width=&#34;250&#34;&gt; &#xA;&lt;p&gt;&lt;strong&gt;A delightful Ruby way to work with AI.&lt;/strong&gt; RubyLLM provides &lt;strong&gt;one&lt;/strong&gt; beautiful, Ruby-like interface to interact with modern AI models. Chat, generate images, create embeddings, and use tools ‚Äì all with clean, expressive code that feels like Ruby, not like patching together multiple services.&lt;/p&gt; &#xA;&lt;div class=&#34;provider-icons&#34;&gt; &#xA; &lt;img src=&#34;https://registry.npmmirror.com/@lobehub/icons-static-svg/latest/files/icons/anthropic-text.svg?sanitize=true&#34; alt=&#34;Anthropic&#34; class=&#34;logo-small&#34;&gt; &amp;nbsp; &#xA; &lt;img src=&#34;https://registry.npmmirror.com/@lobehub/icons-static-svg/latest/files/icons/bedrock-color.svg?sanitize=true&#34; alt=&#34;Bedrock&#34; class=&#34;logo-medium&#34;&gt; &#xA; &lt;img src=&#34;https://registry.npmmirror.com/@lobehub/icons-static-svg/latest/files/icons/bedrock-text.svg?sanitize=true&#34; alt=&#34;Bedrock&#34; class=&#34;logo-small&#34;&gt; &amp;nbsp; &#xA; &lt;img src=&#34;https://registry.npmmirror.com/@lobehub/icons-static-svg/latest/files/icons/deepseek-color.svg?sanitize=true&#34; alt=&#34;DeepSeek&#34; class=&#34;logo-medium&#34;&gt; &#xA; &lt;img src=&#34;https://registry.npmmirror.com/@lobehub/icons-static-svg/latest/files/icons/deepseek-text.svg?sanitize=true&#34; alt=&#34;DeepSeek&#34; class=&#34;logo-small&#34;&gt; &amp;nbsp; &#xA; &lt;img src=&#34;https://registry.npmmirror.com/@lobehub/icons-static-svg/latest/files/icons/gemini-brand-color.svg?sanitize=true&#34; alt=&#34;Gemini&#34; class=&#34;logo-large&#34;&gt; &amp;nbsp; &#xA; &lt;img src=&#34;https://registry.npmmirror.com/@lobehub/icons-static-svg/latest/files/icons/ollama.svg?sanitize=true&#34; alt=&#34;Ollama&#34; class=&#34;logo-medium&#34;&gt; &#xA; &lt;img src=&#34;https://registry.npmmirror.com/@lobehub/icons-static-svg/latest/files/icons/ollama-text.svg?sanitize=true&#34; alt=&#34;Ollama&#34; class=&#34;logo-medium&#34;&gt; &amp;nbsp; &#xA; &lt;img src=&#34;https://registry.npmmirror.com/@lobehub/icons-static-svg/latest/files/icons/openai.svg?sanitize=true&#34; alt=&#34;OpenAI&#34; class=&#34;logo-medium&#34;&gt; &#xA; &lt;img src=&#34;https://registry.npmmirror.com/@lobehub/icons-static-svg/latest/files/icons/openai-text.svg?sanitize=true&#34; alt=&#34;OpenAI&#34; class=&#34;logo-medium&#34;&gt; &amp;nbsp; &#xA; &lt;img src=&#34;https://registry.npmmirror.com/@lobehub/icons-static-svg/latest/files/icons/openrouter.svg?sanitize=true&#34; alt=&#34;OpenRouter&#34; class=&#34;logo-medium&#34;&gt; &#xA; &lt;img src=&#34;https://registry.npmmirror.com/@lobehub/icons-static-svg/latest/files/icons/openrouter-text.svg?sanitize=true&#34; alt=&#34;OpenRouter&#34; class=&#34;logo-small&#34;&gt; &amp;nbsp; &#xA;&lt;/div&gt; &#xA;&lt;div class=&#34;badge-container&#34;&gt; &#xA; &lt;a href=&#34;https://badge.fury.io/rb/ruby_llm&#34;&gt;&lt;img src=&#34;https://badge.fury.io/rb/ruby_llm.svg?sanitize=true&#34; alt=&#34;Gem Version&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/testdouble/standard&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/code_style-standard-brightgreen.svg?sanitize=true&#34; alt=&#34;Ruby Style Guide&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://rubygems.org/gems/ruby_llm&#34;&gt;&lt;img alt=&#34;Gem Downloads&#34; src=&#34;https://img.shields.io/gem/dt/ruby_llm&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://codecov.io/gh/crmne/ruby_llm&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/crmne/ruby_llm/branch/main/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;ü§∫ Battle tested at &lt;a href=&#34;https://chatwithwork.com&#34;&gt;üí¨ Chat with Work&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;The problem with AI libraries&lt;/h2&gt; &#xA;&lt;p&gt;Every AI provider comes with its own client library, its own response format, its own conventions for streaming, and its own way of handling errors. Want to use multiple providers? Prepare to juggle incompatible APIs and bloated dependencies.&lt;/p&gt; &#xA;&lt;p&gt;RubyLLM fixes all that. One beautiful API for everything. One consistent format. Minimal dependencies ‚Äî just Faraday and Zeitwerk. Because working with AI should be a joy, not a chore.&lt;/p&gt; &#xA;&lt;h2&gt;What makes it great&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# Just ask questions&#xA;chat = RubyLLM.chat&#xA;chat.ask &#34;What&#39;s the best way to learn Ruby?&#34;&#xA;&#xA;# Analyze images&#xA;chat.ask &#34;What&#39;s in this image?&#34;, with: { image: &#34;ruby_conf.jpg&#34; }&#xA;&#xA;# Analyze audio recordings&#xA;chat.ask &#34;Describe this meeting&#34;, with: { audio: &#34;meeting.wav&#34; }&#xA;&#xA;# Analyze documents&#xA;chat.ask &#34;Summarize this document&#34;, with: { pdf: &#34;contract.pdf&#34; }&#xA;&#xA;# Stream responses in real-time&#xA;chat.ask &#34;Tell me a story about a Ruby programmer&#34; do |chunk|&#xA;  print chunk.content&#xA;end&#xA;&#xA;# Generate images&#xA;RubyLLM.paint &#34;a sunset over mountains in watercolor style&#34;&#xA;&#xA;# Create vector embeddings&#xA;RubyLLM.embed &#34;Ruby is elegant and expressive&#34;&#xA;&#xA;# Let AI use your code&#xA;class Weather &amp;lt; RubyLLM::Tool&#xA;  description &#34;Gets current weather for a location&#34;&#xA;  param :latitude, desc: &#34;Latitude (e.g., 52.5200)&#34;&#xA;  param :longitude, desc: &#34;Longitude (e.g., 13.4050)&#34;&#xA;&#xA;  def execute(latitude:, longitude:)&#xA;    url = &#34;https://api.open-meteo.com/v1/forecast?latitude=#{latitude}&amp;amp;longitude=#{longitude}&amp;amp;current=temperature_2m,wind_speed_10m&#34;&#xA;&#xA;    response = Faraday.get(url)&#xA;    data = JSON.parse(response.body)&#xA;  rescue =&amp;gt; e&#xA;    { error: e.message }&#xA;  end&#xA;end&#xA;&#xA;chat.with_tool(Weather).ask &#34;What&#39;s the weather in Berlin? (52.5200, 13.4050)&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Core Capabilities&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üí¨ &lt;strong&gt;Unified Chat:&lt;/strong&gt; Converse with models from OpenAI, Anthropic, Gemini, Bedrock, OpenRouter, DeepSeek, Ollama, or any OpenAI-compatible API using &lt;code&gt;RubyLLM.chat&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;üëÅÔ∏è &lt;strong&gt;Vision:&lt;/strong&gt; Analyze images within chats.&lt;/li&gt; &#xA; &lt;li&gt;üîä &lt;strong&gt;Audio:&lt;/strong&gt; Transcribe and understand audio content.&lt;/li&gt; &#xA; &lt;li&gt;üìÑ &lt;strong&gt;PDF Analysis:&lt;/strong&gt; Extract information and summarize PDF documents.&lt;/li&gt; &#xA; &lt;li&gt;üñºÔ∏è &lt;strong&gt;Image Generation:&lt;/strong&gt; Create images with &lt;code&gt;RubyLLM.paint&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;üìä &lt;strong&gt;Embeddings:&lt;/strong&gt; Generate text embeddings for vector search with &lt;code&gt;RubyLLM.embed&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;üîß &lt;strong&gt;Tools (Function Calling):&lt;/strong&gt; Let AI models call your Ruby code using &lt;code&gt;RubyLLM::Tool&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;üöÇ &lt;strong&gt;Rails Integration:&lt;/strong&gt; Easily persist chats, messages, and tool calls using &lt;code&gt;acts_as_chat&lt;/code&gt; and &lt;code&gt;acts_as_message&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;üåä &lt;strong&gt;Streaming:&lt;/strong&gt; Process responses in real-time with idiomatic Ruby blocks.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Add to your Gemfile:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;gem &#39;ruby_llm&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then &lt;code&gt;bundle install&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Configure your API keys (using environment variables is recommended):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# config/initializers/ruby_llm.rb or similar&#xA;RubyLLM.configure do |config|&#xA;  config.openai_api_key = ENV.fetch(&#39;OPENAI_API_KEY&#39;, nil)&#xA;  # Add keys ONLY for providers you intend to use&#xA;  # config.anthropic_api_key = ENV.fetch(&#39;ANTHROPIC_API_KEY&#39;, nil)&#xA;  # ... see Configuration guide for all options ...&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://rubyllm.com/installation&#34;&gt;Installation Guide&lt;/a&gt; for full details.&lt;/p&gt; &#xA;&lt;h2&gt;Rails Integration&lt;/h2&gt; &#xA;&lt;p&gt;Add persistence to your chat models effortlessly:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;# app/models/chat.rb&#xA;class Chat &amp;lt; ApplicationRecord&#xA;  acts_as_chat # Automatically saves messages &amp;amp; tool calls&#xA;  # ... your other model logic ...&#xA;end&#xA;&#xA;# app/models/message.rb&#xA;class Message &amp;lt; ApplicationRecord&#xA;  acts_as_message&#xA;  # ...&#xA;end&#xA;&#xA;# app/models/tool_call.rb (if using tools)&#xA;class ToolCall &amp;lt; ApplicationRecord&#xA;  acts_as_tool_call&#xA;  # ...&#xA;end&#xA;&#xA;# Now interacting with a Chat record persists the conversation:&#xA;chat_record = Chat.create!(model_id: &#34;gpt-4.1-nano&#34;)&#xA;chat_record.ask(&#34;Explain Active Record callbacks.&#34;) # User &amp;amp; Assistant messages saved&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Check the &lt;a href=&#34;https://rubyllm.com/guides/rails&#34;&gt;Rails Integration Guide&lt;/a&gt; for more.&lt;/p&gt; &#xA;&lt;h2&gt;Learn More&lt;/h2&gt; &#xA;&lt;p&gt;Dive deeper with the official documentation:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://rubyllm.com/installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://rubyllm.com/configuration&#34;&gt;Configuration&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Guides:&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://rubyllm.com/guides/getting-started&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://rubyllm.com/guides/chat&#34;&gt;Chatting with AI Models&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://rubyllm.com/guides/tools&#34;&gt;Using Tools&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://rubyllm.com/guides/streaming&#34;&gt;Streaming Responses&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://rubyllm.com/guides/rails&#34;&gt;Rails Integration&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://rubyllm.com/guides/image-generation&#34;&gt;Image Generation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://rubyllm.com/guides/embeddings&#34;&gt;Embeddings&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://rubyllm.com/guides/models&#34;&gt;Working with Models&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://rubyllm.com/guides/error-handling&#34;&gt;Error Handling&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://rubyllm.com/guides/available-models&#34;&gt;Available Models&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions! Please see &lt;a href=&#34;https://raw.githubusercontent.com/crmne/ruby_llm/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for details on setup, testing, and contribution guidelines.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Released under the MIT License.&lt;/p&gt;</summary>
  </entry>
</feed>