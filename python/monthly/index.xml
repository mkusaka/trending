<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-04T02:31:40Z</updated>
  <subtitle>Monthly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>iperov/DeepFaceLab</title>
    <updated>2022-06-04T02:31:40Z</updated>
    <id>tag:github.com,2022-06-04:/iperov/DeepFaceLab</id>
    <link href="https://github.com/iperov/DeepFaceLab" rel="alternate"></link>
    <summary type="html">&lt;p&gt;DeepFaceLab is the leading software for creating deepfakes.&lt;/p&gt;&lt;hr&gt;&lt;table align=&#34;center&#34; border=&#34;0&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h1&gt;DeepFaceLab&lt;/h1&gt; &lt;a href=&#34;https://arxiv.org/abs/2005.05535&#34;&gt; &lt;/a&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.05535&#34;&gt;&lt;img src=&#34;https://static.arxiv.org/static/browse/0.3.0/images/icons/favicon.ico&#34; width=&#34;14&#34;&gt; &lt;/a&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.05535&#34;&gt;https://arxiv.org/abs/2005.05535&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;the leading software for creating deepfakes&lt;/h3&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/DFL_welcome.png&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/logo_tensorflow.png&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/logo_cuda.png&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/logo_directx.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &lt;p&gt;&lt;/p&gt; &lt;p&gt;More than 95% of deepfake videos are created with DeepFaceLab.&lt;/p&gt; &lt;p&gt;DeepFaceLab is used by such popular youtube channels as&lt;/p&gt; &#xA;    &lt;table&gt; &#xA;     &lt;thead&gt; &#xA;      &lt;tr&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/tiktok_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.tiktok.com/@deeptomcruise&#34;&gt;deeptomcruise&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/tiktok_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.tiktok.com/@1facerussia&#34;&gt;1facerussia&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/tiktok_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.tiktok.com/@arnoldschwarzneggar&#34;&gt;arnoldschwarzneggar&lt;/a&gt;&lt;/th&gt; &#xA;      &lt;/tr&gt; &#xA;     &lt;/thead&gt; &#xA;    &lt;/table&gt; &#xA;    &lt;table&gt; &#xA;     &lt;thead&gt; &#xA;      &lt;tr&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/tiktok_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.tiktok.com/@mariahcareyathome?&#34;&gt;mariahcareyathome?&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/tiktok_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.tiktok.com/@diepnep&#34;&gt;diepnep&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/tiktok_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.tiktok.com/@mr__heisenberg&#34;&gt;mr__heisenberg&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/tiktok_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.tiktok.com/@deepcaprio&#34;&gt;deepcaprio&lt;/a&gt;&lt;/th&gt; &#xA;      &lt;/tr&gt; &#xA;     &lt;/thead&gt; &#xA;    &lt;/table&gt; &#xA;    &lt;table&gt; &#xA;     &lt;thead&gt; &#xA;      &lt;tr&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCGf4OlX_aTt8DlrgiH3jN3g/videos&#34;&gt;VFXChris Ume&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCZXbWcv7fSZFTAZV4beckyw/videos&#34;&gt;Sham00k&lt;/a&gt;&lt;/th&gt; &#xA;      &lt;/tr&gt; &#xA;     &lt;/thead&gt; &#xA;    &lt;/table&gt; &#xA;    &lt;table&gt; &#xA;     &lt;thead&gt; &#xA;      &lt;tr&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=A91P2qtPT54&amp;amp;list=PLayt6616lBclvOprvrC8qKGCO-mAhPRux&#34;&gt;Collider videos&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCC0lK2Zo2BMXX-k1Ks0r7dg/videos&#34;&gt;iFake&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCFh3gL0a8BS21g-DHvXZEeQ/videos&#34;&gt;NextFace&lt;/a&gt;&lt;/th&gt; &#xA;      &lt;/tr&gt; &#xA;     &lt;/thead&gt; &#xA;    &lt;/table&gt; &#xA;    &lt;table&gt; &#xA;     &lt;thead&gt; &#xA;      &lt;tr&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCC5BbFxqLQgfnWPhprmQLVg&#34;&gt;Futuring Machine&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCRzgK52MmetD9aG8pDOID3g&#34;&gt;RepresentUS&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/c/corridorcrew/videos&#34;&gt;Corridor Crew&lt;/a&gt;&lt;/th&gt; &#xA;      &lt;/tr&gt; &#xA;     &lt;/thead&gt; &#xA;    &lt;/table&gt; &#xA;    &lt;table&gt; &#xA;     &lt;thead&gt; &#xA;      &lt;tr&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCkHecfDTcSazNZSKPEhtPVQ&#34;&gt;DeepFaker&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/c/DeepFakesinmovie/videos&#34;&gt;DeepFakes in movie&lt;/a&gt;&lt;/th&gt; &#xA;      &lt;/tr&gt; &#xA;     &lt;/thead&gt; &#xA;    &lt;/table&gt; &#xA;    &lt;table&gt; &#xA;     &lt;thead&gt; &#xA;      &lt;tr&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCkNFhcYNLQ5hr6A6lZ56mKA&#34;&gt;DeepFakeCreator&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/user/Jarkancio/videos&#34;&gt;Jarkan&lt;/a&gt;&lt;/th&gt; &#xA;      &lt;/tr&gt; &#xA;     &lt;/thead&gt; &#xA;    &lt;/table&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h1&gt;What can I do using DeepFaceLab?&lt;/h1&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Replace the face&lt;/h2&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/replace_the_face.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;De-age the face&lt;/h2&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/deage_0_1.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/deage_0_2.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=Ddx5B-84ebo&#34;&gt;https://www.youtube.com/watch?v=Ddx5B-84ebo&lt;/a&gt;&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Replace the head&lt;/h2&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/head_replace_0_1.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/head_replace_0_2.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=xr5FHd0AdlQ&#34;&gt;https://www.youtube.com/watch?v=xr5FHd0AdlQ&lt;/a&gt;&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/head_replace_1_1.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/head_replace_1_2.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=RTjgkhMugVw&#34;&gt;https://www.youtube.com/watch?v=RTjgkhMugVw&lt;/a&gt;&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/head_replace_2_1.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/head_replace_2_2.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=R9f7WD0gKPo&#34;&gt;https://www.youtube.com/watch?v=R9f7WD0gKPo&lt;/a&gt;&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Manipulate politicians lips&lt;/h2&gt; &lt;p&gt;(voice replacement is not included!) (also requires a skill in video editors such as &lt;em&gt;Adobe After Effects&lt;/em&gt; or &lt;em&gt;Davinci Resolve&lt;/em&gt;)&lt;/p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/political_speech2.jpg&#34; align=&#34;center&#34;&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=IvY-Abd2FfM&#34;&gt;https://www.youtube.com/watch?v=IvY-Abd2FfM&lt;/a&gt;&lt;/p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/political_speech3.jpg&#34; align=&#34;center&#34;&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=ERQlaJ_czHU&#34;&gt;https://www.youtube.com/watch?v=ERQlaJ_czHU&lt;/a&gt;&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h1&gt;Deepfake native resolution progress&lt;/h1&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/deepfake_progress.png&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/make_everything_ok.png&#34; align=&#34;center&#34;&gt; &lt;p&gt;Unfortunately, there is no &#34;make everything ok&#34; button in DeepFaceLab. You should spend time studying the workflow and growing your skills. A skill in programs such as &lt;em&gt;AfterEffects&lt;/em&gt; or &lt;em&gt;Davinci Resolve&lt;/em&gt; is also desirable.&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Mini tutorial&lt;/h2&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=kOIMXt8KK8M&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/mini_tutorial.jpg&#34; align=&#34;center&#34;&gt; &lt;/a&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Releases&lt;/h2&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://tinyurl.com/2p9cvt25&#34;&gt;Windows (magnet link)&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Last release. Use torrent client to download.&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mega.nz/folder/Po0nGQrA#dbbttiNWojCt8jzD4xYaPw&#34;&gt;Windows (Mega.nz)&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Contains new and prev releases.&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://disk.yandex.ru/d/7i5XTKIKVg5UUg&#34;&gt;Windows (yandex.ru)&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Contains new and prev releases.&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://github.com/chervonij/DFL-Colab&#34;&gt;Google Colab (github)&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;by @chervonij . You can train fakes for free using Google Colab.&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://github.com/nagadit/DeepFaceLab_Linux&#34;&gt;Linux (github)&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;by @nagadit&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://github.com/elemantalcode/dfl&#34;&gt;CentOS Linux (github)&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;May be outdated. By @elemantalcode&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table align=&#34;center&#34; border=&#34;0&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Links&lt;/h2&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h3&gt;Guides and tutorials&lt;/h3&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide&#34;&gt;DeepFaceLab guide&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Main guide&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?pid=18459#pid18459&#34;&gt;Faceset creation guide&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;How to create the right faceset&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/thread-guide-deepfacelab-google-colab-tutorial&#34;&gt;Google Colab guide&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Guide how to train the fake on Google Colab&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/thread-deepfacelab-2-0-compositing-in-davinci-resolve-vegas-pro-and-after-effects&#34;&gt;Compositing&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;To achieve the highest quality, compose deepfake manually in video editors such as Davinci Resolve or Adobe AfterEffects&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/thread-deepfacelab-2-0-discussion-tips-suggestions&#34;&gt;Discussion and suggestions&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h3&gt;Supplementary material&lt;/h3&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/forum-celebrity-facesets&#34;&gt;Ready to work facesets&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Celebrity facesets made by community&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/forum-trained-models&#34;&gt;Pretrained models&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Pretrained models made by community&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h3&gt;Communication groups&lt;/h3&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://discord.gg/S2h7kPySQp&#34;&gt;Discord&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Official discord channel. English / Russian.&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://t.me/joinchat/ElkhqlgJ0I5HhdJyFar80w&#34;&gt;Telegram group&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Official telegram group. English / Russian. For anonymous communication. Don&#39;t forget to hide your phone number&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/forum-russian-community&#34;&gt;Русский форум&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/&#34;&gt;mrdeepfakes&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;the biggest NSFW English community&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://www.reddit.com/r/DeepFakesSFW/new/&#34;&gt;reddit r/DeepFakesSFW/&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Post your deepfakes there !&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://www.reddit.com/r/RUdeepfakes/new/&#34;&gt;reddit r/RUdeepfakes/&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Постим русские дипфейки сюда !&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; QQ群1095077489 &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;中文交流QQ群，商务合作找群主&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://www.dfldata.xyz&#34;&gt;dfldata.xyz&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;中文交流论坛，免费软件教程、模型、人脸数据&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://www.deepfaker.xyz/&#34;&gt;deepfaker.xyz&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;中文学习站（非官方)&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Related works&lt;/h2&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://github.com/iperov/DeepFaceLive&#34;&gt;DeepFaceLive&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Real-time face swap for PC streaming or video calls&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://github.com/neuralchen/SimSwap&#34;&gt;neuralchen/SimSwap&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Swapping face using ONE single photo 一张图免训练换脸&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://github.com/deepfakes/faceswap&#34;&gt;deepfakes/faceswap&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Something that was before DeepFaceLab and still remains in the past&lt;/td&gt;&#xA;  &lt;/tr&gt;  &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table align=&#34;center&#34; border=&#34;0&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;How I can help the project?&lt;/h2&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h3&gt;Sponsor deepfake research and DeepFaceLab development.&lt;/h3&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;!--&#xA;&lt;tr&gt;&lt;td colspan=2 align=&#34;center&#34;&gt;&#xA;&lt;a href=&#34;https://www.paypal.com/paypalme/DeepFaceLab&#34;&gt;Donate via Paypal&lt;/a&gt;&#xA;&lt;/td&gt;&lt;/tr&gt;&#xA;--&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;a href=&#34;https://money.yandex.ru/to/41001142318065&#34;&gt;Donate via Yandex.Money&lt;/a&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; bitcoin:bc1qkhh7h0gwwhxgg6h6gpllfgstkd645fefrd5s6z &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h3&gt;Collect facesets&lt;/h3&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p&gt;You can collect faceset of any celebrity that can be used in DeepFaceLab and share it &lt;a href=&#34;https://mrdeepfakes.com/forums/forum-celebrity-facesets&#34;&gt;in the community&lt;/a&gt;&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h3&gt;Star this repo&lt;/h3&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p&gt;Register github account and push &#34;Star&#34; button.&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table align=&#34;center&#34; border=&#34;0&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Meme zone&lt;/h2&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/meme1.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/meme2.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/meme3.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;h2&gt;You don&#39;t need deepfake detector. You need to stop lying.&lt;/h2&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34; width=&#34;10%&#34;&gt; &lt;img src=&#34;https://i.imgur.com/z0e0xFB.jpg&#34; align=&#34;center&#34;&gt; &lt;p&gt;V.I. Lenin&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p&gt;&lt;sub&gt;#deepfacelab #deepfakes #faceswap #face-swap #deep-learning #deeplearning #deep-neural-networks #deepface #deep-face-swap #fakeapp #fake-app #neural-networks #neural-nets #tensorflow #cuda #nvidia&lt;/sub&gt;&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt;</summary>
  </entry>
  <entry>
    <title>deepfakes/faceswap</title>
    <updated>2022-06-04T02:31:40Z</updated>
    <id>tag:github.com,2022-06-04:/deepfakes/faceswap</id>
    <link href="https://github.com/deepfakes/faceswap" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Deepfakes Software For All&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;deepfakes_faceswap&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://faceswap.dev&#34;&gt;&lt;img src=&#34;https://i.imgur.com/zHvjHnb.png&#34;&gt;&lt;/a&gt; &lt;br&gt;FaceSwap is a tool that utilizes deep learning to recognize and swap faces in pictures and videos. &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://i.imgur.com/nWHFLDf.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.patreon.com/bePatron?u=23238350&#34;&gt;&lt;img src=&#34;https://c5.patreon.com/external/logo/become_a_patron_button.png&#34;&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&#34;https://discord.gg/FC54sYg&#34;&gt;&lt;img src=&#34;https://i.imgur.com/gIpztkv.png&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=r1jng79a5xc&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/r1jng79a5xc/0.jpg&#34;&gt;&lt;/a&gt; &lt;br&gt;Jennifer Lawrence/Steve Buscemi FaceSwap using the Villain model &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/deepfakes/faceswap&#34;&gt;&lt;img src=&#34;https://travis-ci.org/deepfakes/faceswap.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://faceswap.readthedocs.io/en/latest/?badge=latest&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/faceswap/badge/?version=latest&#34; alt=&#34;Documentation Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Make sure you check out &lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/INSTALL.md&#34;&gt;INSTALL.md&lt;/a&gt; before getting started.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#deepfakes_faceswap&#34;&gt;deepfakes_faceswap&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#manifesto&#34;&gt;Manifesto&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#faceswap-has-ethical-uses&#34;&gt;FaceSwap has ethical uses.&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#how-to-setup-and-run-the-project&#34;&gt;How To setup and run the project&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#overview&#34;&gt;Overview&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#extract&#34;&gt;Extract&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#train&#34;&gt;Train&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#convert&#34;&gt;Convert&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#gui&#34;&gt;GUI&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#general-notes&#34;&gt;General notes:&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#help-i-need-support&#34;&gt;Help I need support!&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#discord-server&#34;&gt;Discord Server&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#faceswap-forum&#34;&gt;FaceSwap Forum&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#donate&#34;&gt;Donate&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#patreon&#34;&gt;Patreon&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#one-time-donations&#34;&gt;One time Donations&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#torzdf&#34;&gt;@torzdf&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#andenixa&#34;&gt;@andenixa&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#how-to-contribute&#34;&gt;How to contribute&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#for-people-interested-in-the-generative-models&#34;&gt;For people interested in the generative models&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#for-devs&#34;&gt;For devs&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#for-non-dev-advanced-users&#34;&gt;For non-dev advanced users&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#for-end-users&#34;&gt;For end-users&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#for-haters&#34;&gt;For haters&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#about-githubcomdeepfakes&#34;&gt;About github.com/deepfakes&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#what-is-this-repo&#34;&gt;What is this repo?&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#why-this-repo&#34;&gt;Why this repo?&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#why-is-it-named-deepfakes-if-it-is-not-udeepfakes&#34;&gt;Why is it named &#39;deepfakes&#39; if it is not /u/deepfakes?&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#what-if-udeepfakes-feels-bad-about-that&#34;&gt;What if /u/deepfakes feels bad about that?&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#about-machine-learning&#34;&gt;About machine learning&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/#how-does-a-computer-know-how-to-recognizeshape-faces-how-does-machine-learning-work-what-is-a-neural-network&#34;&gt;How does a computer know how to recognize/shape faces? How does machine learning work? What is a neural network?&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Manifesto&lt;/h1&gt; &#xA;&lt;h2&gt;FaceSwap has ethical uses.&lt;/h2&gt; &#xA;&lt;p&gt;When faceswapping was first developed and published, the technology was groundbreaking, it was a huge step in AI development. It was also completely ignored outside of academia because the code was confusing and fragmentary. It required a thorough understanding of complicated AI techniques and took a lot of effort to figure it out. Until one individual brought it together into a single, cohesive collection. It ran, it worked, and as is so often the way with new technology emerging on the internet, it was immediately used to create inappropriate content. Despite the inappropriate uses the software was given originally, it was the first AI code that anyone could download, run and learn by experimentation without having a Ph.D. in math, computer theory, psychology, and more. Before &#34;deepfakes&#34; these techniques were like black magic, only practiced by those who could understand all of the inner workings as described in esoteric and endlessly complicated books and papers.&lt;/p&gt; &#xA;&lt;p&gt;&#34;Deepfakes&#34; changed all that and anyone could participate in AI development. To us, developers, the release of this code opened up a fantastic learning opportunity. It allowed us to build on ideas developed by others, collaborate with a variety of skilled coders, experiment with AI whilst learning new skills and ultimately contribute towards an emerging technology which will only see more mainstream use as it progresses.&lt;/p&gt; &#xA;&lt;p&gt;Are there some out there doing horrible things with similar software? Yes. And because of this, the developers have been following strict ethical standards. Many of us don&#39;t even use it to create videos, we just tinker with the code to see what it does. Sadly, the media concentrates only on the unethical uses of this software. That is, unfortunately, the nature of how it was first exposed to the public, but it is not representative of why it was created, how we use it now, or what we see in its future. Like any technology, it can be used for good or it can be abused. It is our intention to develop FaceSwap in a way that its potential for abuse is minimized whilst maximizing its potential as a tool for learning, experimenting and, yes, for legitimate faceswapping.&lt;/p&gt; &#xA;&lt;p&gt;We are not trying to denigrate celebrities or to demean anyone. We are programmers, we are engineers, we are Hollywood VFX artists, we are activists, we are hobbyists, we are human beings. To this end, we feel that it&#39;s time to come out with a standard statement of what this software is and isn&#39;t as far as us developers are concerned.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;FaceSwap is not for creating inappropriate content.&lt;/li&gt; &#xA; &lt;li&gt;FaceSwap is not for changing faces without consent or with the intent of hiding its use.&lt;/li&gt; &#xA; &lt;li&gt;FaceSwap is not for any illicit, unethical, or questionable purposes.&lt;/li&gt; &#xA; &lt;li&gt;FaceSwap exists to experiment and discover AI techniques, for social or political commentary, for movies, and for any number of ethical and reasonable uses.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We are very troubled by the fact that FaceSwap can be used for unethical and disreputable things. However, we support the development of tools and techniques that can be used ethically as well as provide education and experience in AI for anyone who wants to learn it hands-on. We will take a zero tolerance approach to anyone using this software for any unethical purposes and will actively discourage any such uses.&lt;/p&gt; &#xA;&lt;h1&gt;How To setup and run the project&lt;/h1&gt; &#xA;&lt;p&gt;FaceSwap is a Python program that will run on multiple Operating Systems including Windows, Linux, and MacOS.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/INSTALL.md&#34;&gt;INSTALL.md&lt;/a&gt; for full installation instructions. You will need a modern GPU with CUDA support for best performance. AMD GPUs are partially supported.&lt;/p&gt; &#xA;&lt;h1&gt;Overview&lt;/h1&gt; &#xA;&lt;p&gt;The project has multiple entry points. You will have to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Gather photos and/or videos&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Extract&lt;/strong&gt; faces from your raw photos&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Train&lt;/strong&gt; a model on the faces extracted from the photos/videos&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Convert&lt;/strong&gt; your sources with the model&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Check out &lt;a href=&#34;https://raw.githubusercontent.com/deepfakes/faceswap/master/USAGE.md&#34;&gt;USAGE.md&lt;/a&gt; for more detailed instructions.&lt;/p&gt; &#xA;&lt;h2&gt;Extract&lt;/h2&gt; &#xA;&lt;p&gt;From your setup folder, run &lt;code&gt;python faceswap.py extract&lt;/code&gt;. This will take photos from &lt;code&gt;src&lt;/code&gt; folder and extract faces into &lt;code&gt;extract&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;h2&gt;Train&lt;/h2&gt; &#xA;&lt;p&gt;From your setup folder, run &lt;code&gt;python faceswap.py train&lt;/code&gt;. This will take photos from two folders containing pictures of both faces and train a model that will be saved inside the &lt;code&gt;models&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;h2&gt;Convert&lt;/h2&gt; &#xA;&lt;p&gt;From your setup folder, run &lt;code&gt;python faceswap.py convert&lt;/code&gt;. This will take photos from &lt;code&gt;original&lt;/code&gt; folder and apply new faces into &lt;code&gt;modified&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;h2&gt;GUI&lt;/h2&gt; &#xA;&lt;p&gt;Alternatively, you can run the GUI by running &lt;code&gt;python faceswap.py gui&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h1&gt;General notes:&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;All of the scripts mentioned have &lt;code&gt;-h&lt;/code&gt;/&lt;code&gt;--help&lt;/code&gt; options with arguments that they will accept. You&#39;re smart, you can figure out how this works, right?!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;NB: there is a conversion tool for video. This can be accessed by running &lt;code&gt;python tools.py effmpeg -h&lt;/code&gt;. Alternatively, you can use &lt;a href=&#34;https://www.ffmpeg.org&#34;&gt;ffmpeg&lt;/a&gt; to convert video into photos, process images, and convert images back to the video.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Some tips:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Reusing existing models will train much faster than starting from nothing. If there is not enough training data, start with someone who looks similar, then switch the data.&lt;/p&gt; &#xA;&lt;h1&gt;Help I need support!&lt;/h1&gt; &#xA;&lt;h2&gt;Discord Server&lt;/h2&gt; &#xA;&lt;p&gt;Your best bet is to join the &lt;a href=&#34;https://discord.gg/FC54sYg&#34;&gt;FaceSwap Discord server&lt;/a&gt; where there are plenty of users willing to help. Please note that, like this repo, this is a SFW Server!&lt;/p&gt; &#xA;&lt;h2&gt;FaceSwap Forum&lt;/h2&gt; &#xA;&lt;p&gt;Alternatively, you can post questions in the &lt;a href=&#34;https://faceswap.dev/forum&#34;&gt;FaceSwap Forum&lt;/a&gt;. Please do not post general support questions in this repo as they are liable to be deleted without response.&lt;/p&gt; &#xA;&lt;h1&gt;Donate&lt;/h1&gt; &#xA;&lt;p&gt;The developers work tirelessly to improve and develop FaceSwap. Many hours have been put in to provide the software as it is today, but this is an extremely time-consuming process with no financial reward. If you enjoy using the software, please consider donating to the devs, so they can spend more time implementing improvements.&lt;/p&gt; &#xA;&lt;h2&gt;Patreon&lt;/h2&gt; &#xA;&lt;p&gt;The best way to support us is through our Patreon page:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.patreon.com/bePatron?u=23238350&#34;&gt;&lt;img src=&#34;https://c5.patreon.com/external/logo/become_a_patron_button.png&#34; alt=&#34;become-a-patron&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;One time Donations&lt;/h2&gt; &#xA;&lt;p&gt;Alternatively you can give a one off donation to any of our Devs:&lt;/p&gt; &#xA;&lt;h3&gt;@torzdf&lt;/h3&gt; &#xA;&lt;p&gt;There is very little FaceSwap code that hasn&#39;t been touched by torzdf. He is responsible for implementing the GUI, FAN aligner, MTCNN detector and porting the Villain, DFL-H128 and DFaker models to FaceSwap, as well as significantly improving many areas of the code.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bitcoin:&lt;/strong&gt; bc1qpm22suz59ylzk0j7qk5e4c7cnkjmve2rmtrnc6&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Ethereum:&lt;/strong&gt; 0xd3e954dC241B87C4E8E1A801ada485DC1d530F01&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Monero:&lt;/strong&gt; 45dLrtQZ2pkHizBpt3P3yyJKkhcFHnhfNYPMSnz3yVEbdWm3Hj6Kr5TgmGAn3Far8LVaQf1th2n3DJVTRkfeB5ZkHxWozSX&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Paypal:&lt;/strong&gt; &lt;a href=&#34;https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=JZ8PP3YE9J62L&#34;&gt;&lt;img src=&#34;https://www.paypalobjects.com/en_GB/i/btn/btn_donate_SM.gif&#34; alt=&#34;torzdf&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;@andenixa&lt;/h3&gt; &#xA;&lt;p&gt;Creator of the Unbalanced and OHR models, as well as expanding various capabilities within the training process. Andenixa is currently working on new models and will take requests for donations.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Paypal:&lt;/strong&gt; &lt;a href=&#34;https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=NRVLQYGS6NWTU&#34;&gt;&lt;img src=&#34;https://www.paypalobjects.com/en_GB/i/btn/btn_donate_SM.gif&#34; alt=&#34;andenixa&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;How to contribute&lt;/h1&gt; &#xA;&lt;h2&gt;For people interested in the generative models&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Go to the &#39;faceswap-model&#39; to discuss/suggest/commit alternatives to the current algorithm.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;For devs&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Read this README entirely&lt;/li&gt; &#xA; &lt;li&gt;Fork the repo&lt;/li&gt; &#xA; &lt;li&gt;Play with it&lt;/li&gt; &#xA; &lt;li&gt;Check issues with the &#39;dev&#39; tag&lt;/li&gt; &#xA; &lt;li&gt;For devs more interested in computer vision and openCV, look at issues with the &#39;opencv&#39; tag. Also feel free to add your own alternatives/improvements&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;For non-dev advanced users&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Read this README entirely&lt;/li&gt; &#xA; &lt;li&gt;Clone the repo&lt;/li&gt; &#xA; &lt;li&gt;Play with it&lt;/li&gt; &#xA; &lt;li&gt;Check issues with the &#39;advuser&#39; tag&lt;/li&gt; &#xA; &lt;li&gt;Also go to the &#39;&lt;a href=&#34;https://faceswap.dev/forum&#34;&gt;faceswap Forum&lt;/a&gt;&#39; and help others.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;For end-users&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Get the code here and play with it if you can&lt;/li&gt; &#xA; &lt;li&gt;You can also go to the &lt;a href=&#34;https://faceswap.dev/forum&#34;&gt;faceswap Forum&lt;/a&gt; and help or get help from others.&lt;/li&gt; &#xA; &lt;li&gt;Be patient. This is a relatively new technology for developers as well. Much effort is already being put into making this program easy to use for the average user. It just takes time!&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Notice&lt;/strong&gt; Any issue related to running the code has to be opened in the &lt;a href=&#34;https://faceswap.dev/forum&#34;&gt;faceswap Forum&lt;/a&gt;!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;For haters&lt;/h2&gt; &#xA;&lt;p&gt;Sorry, no time for that.&lt;/p&gt; &#xA;&lt;h1&gt;About github.com/deepfakes&lt;/h1&gt; &#xA;&lt;h2&gt;What is this repo?&lt;/h2&gt; &#xA;&lt;p&gt;It is a community repository for active users.&lt;/p&gt; &#xA;&lt;h2&gt;Why this repo?&lt;/h2&gt; &#xA;&lt;p&gt;The joshua-wu repo seems not active. Simple bugs like missing &lt;em&gt;http://&lt;/em&gt; in front of urls have not been solved since days.&lt;/p&gt; &#xA;&lt;h2&gt;Why is it named &#39;deepfakes&#39; if it is not /u/deepfakes?&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Because a typosquat would have happened sooner or later as project grows&lt;/li&gt; &#xA; &lt;li&gt;Because we wanted to recognize the original author&lt;/li&gt; &#xA; &lt;li&gt;Because it will better federate contributors and users&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;What if /u/deepfakes feels bad about that?&lt;/h2&gt; &#xA;&lt;p&gt;This is a friendly typosquat, and it is fully dedicated to the project. If /u/deepfakes wants to take over this repo/user and drive the project, he is welcomed to do so (Raise an issue, and he will be contacted on Reddit). Please do not send /u/deepfakes messages for help with the code you find here.&lt;/p&gt; &#xA;&lt;h1&gt;About machine learning&lt;/h1&gt; &#xA;&lt;h2&gt;How does a computer know how to recognize/shape faces? How does machine learning work? What is a neural network?&lt;/h2&gt; &#xA;&lt;p&gt;It&#39;s complicated. Here&#39;s a good video that makes the process understandable: &lt;a href=&#34;https://www.youtube.com/watch?v=R9OHn5ZF4Uo&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/R9OHn5ZF4Uo/0.jpg&#34; alt=&#34;How Machines Learn&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s a slightly more in depth video that tries to explain the basic functioning of a neural network: &lt;a href=&#34;https://www.youtube.com/watch?v=aircAruvnKk&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/aircAruvnKk/0.jpg&#34; alt=&#34;How Machines Learn&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;tl;dr: training data + trial and error&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>PaddlePaddle/PaddleSpeech</title>
    <updated>2022-06-04T02:31:40Z</updated>
    <id>tag:github.com,2022-06-04:/PaddlePaddle/PaddleSpeech</id>
    <link href="https://github.com/PaddlePaddle/PaddleSpeech" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Easy-to-use Speech Toolkit including SOTA/Streaming ASR with punctuation, influential TTS with text frontend, Speaker Verification System and End-to-End Speech Simultaneous Translation.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/README_cn.md&#34;&gt;简体中文&lt;/a&gt;|English)&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/images/PaddleSpeech_logo.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-red.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/PaddlePaddle/PaddleSpeech?color=ffa&#34;&gt;&lt;/a&gt; &lt;a href=&#34;support os&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.7+-aff.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/PaddlePaddle/PaddleSpeech?color=9ea&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/commits&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/commit-activity/m/PaddlePaddle/PaddleSpeech?color=3af&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/PaddlePaddle/PaddleSpeech?color=9cc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/PaddlePaddle/PaddleSpeech?color=ccf&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/=https://pypi.org/project/paddlespeech/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/PaddleSpeech&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/=https://pypi.org/project/paddlespeech/&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/badge/paddlespeech&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h4&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#quick-start&#34;&gt; Quick Start &lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#quick-start-server&#34;&gt; Quick Start Server &lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#quick-start-streaming-server&#34;&gt; Quick Start Streaming Server&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#documents&#34;&gt; Documents &lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#model-list&#34;&gt; Models List &lt;/a&gt; | &lt;a href=&#34;https://aistudio.baidu.com/aistudio/education/group/info/25130&#34;&gt; AIStudio Courses &lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/abs/2205.12007&#34;&gt; Paper &lt;/a&gt; | &lt;a href=&#34;https://gitee.com/paddlepaddle/PaddleSpeech&#34;&gt; Gitee &lt;/a&gt; &lt;/h4&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;PaddleSpeech&lt;/strong&gt; is an open-source toolkit on &lt;a href=&#34;https://github.com/PaddlePaddle/Paddle&#34;&gt;PaddlePaddle&lt;/a&gt; platform for a variety of critical tasks in speech and audio, with the state-of-art and influential models.&lt;/p&gt; &#xA;&lt;h5&gt;Speech Recognition&lt;/h5&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table style=&#34;width:100%&#34;&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt; Input Audio &lt;/th&gt; &#xA;    &lt;th width=&#34;550&#34;&gt; Recognition Result &lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://paddlespeech.bj.bcebos.com/PaddleAudio/en.wav&#34; rel=&#34;nofollow&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/images/audio_icon.png&#34; width=&#34;200 style=&#34; max-width: 100%;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;/td&gt; &#xA;    &lt;td&gt;I knocked at the door on the ancient side of the building.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://paddlespeech.bj.bcebos.com/PaddleAudio/zh.wav&#34; rel=&#34;nofollow&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/images/audio_icon.png&#34; width=&#34;200&#34; style=&#34;max-width: 100%;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;/td&gt; &#xA;    &lt;td&gt;我认为跑步最重要的就是给我带来了身体健康。&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;h5&gt;Speech Translation (English to Chinese)&lt;/h5&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table style=&#34;width:100%&#34;&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt; Input Audio &lt;/th&gt; &#xA;    &lt;th width=&#34;550&#34;&gt; Translations Result &lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://paddlespeech.bj.bcebos.com/PaddleAudio/en.wav&#34; rel=&#34;nofollow&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/images/audio_icon.png&#34; width=&#34;200 style=&#34; max-width: 100%;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;/td&gt; &#xA;    &lt;td&gt;我 在 这栋 建筑 的 古老 门上 敲门。&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;h5&gt;Text-to-Speech&lt;/h5&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table style=&#34;width:100%&#34;&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th width=&#34;550&#34;&gt; Input Text&lt;/th&gt; &#xA;    &lt;th&gt;Synthetic Audio&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Life was like a box of chocolates, you never know what you&#39;re gonna get.&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/tacotron2_ljspeech_waveflow_samples_0.2/sentence_1.wav&#34; rel=&#34;nofollow&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/images/audio_icon.png&#34; width=&#34;200&#34; style=&#34;max-width: 100%;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;早上好，今天是2020/10/29，最低温度是-3°C。&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/parakeet_espnet_fs2_pwg_demo/tn_g2p/parakeet/001.wav&#34; rel=&#34;nofollow&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/images/audio_icon.png&#34; width=&#34;200&#34; style=&#34;max-width: 100%;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;季姬寂，集鸡，鸡即棘鸡。棘鸡饥叽，季姬及箕稷济鸡。鸡既济，跻姬笈，季姬忌，急咭鸡，鸡急，继圾几，季姬急，即籍箕击鸡，箕疾击几伎，伎即齑，鸡叽集几基，季姬急极屐击鸡，鸡既殛，季姬激，即记《季姬击鸡记》。&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/jijiji.wav&#34; rel=&#34;nofollow&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/images/audio_icon.png&#34; width=&#34;200&#34; style=&#34;max-width: 100%;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;For more synthesized audios, please refer to &lt;a href=&#34;https://paddlespeech.readthedocs.io/en/latest/tts/demo.html&#34;&gt;PaddleSpeech Text-to-Speech samples&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h5&gt;Punctuation Restoration&lt;/h5&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table style=&#34;width:100%&#34;&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th width=&#34;390&#34;&gt; Input Text &lt;/th&gt; &#xA;    &lt;th width=&#34;390&#34;&gt; Output Text &lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;今天的天气真不错啊你下午有空吗我想约你一起去吃饭&lt;/td&gt; &#xA;    &lt;td&gt;今天的天气真不错啊！你下午有空吗？我想约你一起去吃饭。&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Features&lt;/h3&gt; &#xA;&lt;p&gt;Via the easy-to-use, efficient, flexible and scalable implementation, our vision is to empower both industrial application and academic research, including training, inference &amp;amp; testing modules, and deployment process. To be more specific, this toolkit features at:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;📦 &lt;strong&gt;Ease of Use&lt;/strong&gt;: low barriers to install, &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#quick-start&#34;&gt;CLI&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#quick-start-server&#34;&gt;Server&lt;/a&gt;, and &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#quick-start-streaming-server&#34;&gt;Streaming Server&lt;/a&gt; is available to quick-start your journey.&lt;/li&gt; &#xA; &lt;li&gt;🏆 &lt;strong&gt;Align to the State-of-the-Art&lt;/strong&gt;: we provide high-speed and ultra-lightweight models, and also cutting-edge technology.&lt;/li&gt; &#xA; &lt;li&gt;🏆 &lt;strong&gt;Streaming ASR and TTS System&lt;/strong&gt;: we provide production ready streaming asr and streaming tts system.&lt;/li&gt; &#xA; &lt;li&gt;💯 &lt;strong&gt;Rule-based Chinese frontend&lt;/strong&gt;: our frontend contains Text Normalization and Grapheme-to-Phoneme (G2P, including Polyphone and Tone Sandhi). Moreover, we use self-defined linguistic rules to adapt Chinese context.&lt;/li&gt; &#xA; &lt;li&gt;📦 &lt;strong&gt;Varieties of Functions that Vitalize both Industrial and Academia&lt;/strong&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;🛎️ &lt;em&gt;Implementation of critical audio tasks&lt;/em&gt;: this toolkit contains audio functions like Automatic Speech Recognition, Text-to-Speech Synthesis, Speaker Verfication, KeyWord Spotting, Audio Classification, and Speech Translation, etc.&lt;/li&gt; &#xA;   &lt;li&gt;🔬 &lt;em&gt;Integration of mainstream models and datasets&lt;/em&gt;: the toolkit implements modules that participate in the whole pipeline of the speech tasks, and uses mainstream datasets like LibriSpeech, LJSpeech, AIShell, CSMSC, etc. See also &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#model-list&#34;&gt;model list&lt;/a&gt; for more details.&lt;/li&gt; &#xA;   &lt;li&gt;🧩 &lt;em&gt;Cascaded models application&lt;/em&gt;: as an extension of the typical traditional audio tasks, we combine the workflows of the aforementioned tasks with other fields like Natural language processing (NLP) and Computer Vision (CV).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Recent Update&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;👑 2022.05.13: Release &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/asr/PPASR.md&#34;&gt;PP-ASR&lt;/a&gt;、&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/tts/PPTTS.md&#34;&gt;PP-TTS&lt;/a&gt;、&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/vpr/PPVPR.md&#34;&gt;PP-VPR&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;👏🏻 2022.05.06: &lt;code&gt;Streaming ASR&lt;/code&gt; with &lt;code&gt;Punctuation Restoration&lt;/code&gt; and &lt;code&gt;Token Timestamp&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;👏🏻 2022.05.06: &lt;code&gt;Server&lt;/code&gt; is available for &lt;code&gt;Speaker Verification&lt;/code&gt;, and &lt;code&gt;Punctuation Restoration&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;👏🏻 2022.04.28: &lt;code&gt;Streaming Server&lt;/code&gt; is available for &lt;code&gt;Automatic Speech Recognition&lt;/code&gt; and &lt;code&gt;Text-to-Speech&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;👏🏻 2022.03.28: &lt;code&gt;Server&lt;/code&gt; is available for &lt;code&gt;Audio Classification&lt;/code&gt;, &lt;code&gt;Automatic Speech Recognition&lt;/code&gt; and &lt;code&gt;Text-to-Speech&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;👏🏻 2022.03.28: &lt;code&gt;CLI&lt;/code&gt; is available for &lt;code&gt;Speaker Verification&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;🤗 2021.12.14: &lt;a href=&#34;https://huggingface.co/spaces/KPatrick/PaddleSpeechASR&#34;&gt;ASR&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/spaces/KPatrick/PaddleSpeechTTS&#34;&gt;TTS&lt;/a&gt; Demos on Hugging Face Spaces are available!&lt;/li&gt; &#xA; &lt;li&gt;👏🏻 2021.12.10: &lt;code&gt;CLI&lt;/code&gt; is available for &lt;code&gt;Audio Classification&lt;/code&gt;, &lt;code&gt;Automatic Speech Recognition&lt;/code&gt;, &lt;code&gt;Speech Translation (English to Chinese)&lt;/code&gt; and &lt;code&gt;Text-to-Speech&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Community&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Scan the QR code below with your Wechat, you can access to official technical exchange group and get the bonus ( more than 20GB learning materials, such as papers, codes and videos ) and the live link of the lessons. Look forward to your participation.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/23690325/169763015-cbd8e28d-602c-4723-810d-dbc6da49441e.jpg&#34; width=&#34;200&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;We strongly recommend our users to install PaddleSpeech in &lt;strong&gt;Linux&lt;/strong&gt; with &lt;em&gt;python&amp;gt;=3.7&lt;/em&gt;. Up to now, &lt;strong&gt;Linux&lt;/strong&gt; supports CLI for the all our tasks, &lt;strong&gt;Mac OSX&lt;/strong&gt; and &lt;strong&gt;Windows&lt;/strong&gt; only supports PaddleSpeech CLI for Audio Classification, Speech-to-Text and Text-to-Speech. To install &lt;code&gt;PaddleSpeech&lt;/code&gt;, please see &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/install.md&#34;&gt;installation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;quickstart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;Developers can have a try of our models with &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/paddlespeech/cli/README.md&#34;&gt;PaddleSpeech Command Line&lt;/a&gt;. Change &lt;code&gt;--input&lt;/code&gt; to test your own audio/text.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Audio Classification&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech cls --input input.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Speaker Verification&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;paddlespeech vector --task spk --input input_16k.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Automatic Speech Recognition&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech asr --lang zh --input input_16k.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;web demo for Automatic Speech Recognition is integrated to &lt;a href=&#34;https://huggingface.co/spaces&#34;&gt;Huggingface Spaces&lt;/a&gt; with &lt;a href=&#34;https://github.com/gradio-app/gradio&#34;&gt;Gradio&lt;/a&gt;. See Demo: &lt;a href=&#34;https://huggingface.co/spaces/KPatrick/PaddleSpeechASR&#34;&gt;ASR Demo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Speech Translation&lt;/strong&gt; (English to Chinese) (not support for Mac and Windows now)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech st --input input_16k.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Text-to-Speech&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech tts --input &#34;你好，欢迎使用飞桨深度学习框架！&#34; --output output.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;web demo for Text to Speech is integrated to &lt;a href=&#34;https://huggingface.co/spaces&#34;&gt;Huggingface Spaces&lt;/a&gt; with &lt;a href=&#34;https://github.com/gradio-app/gradio&#34;&gt;Gradio&lt;/a&gt;. See Demo: &lt;a href=&#34;https://huggingface.co/spaces/KPatrick/PaddleSpeechTTS&#34;&gt;TTS Demo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Text Postprocessing&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Punctuation Restoration &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;paddlespeech text --task punc --input 今天的天气真不错啊你下午有空吗我想约你一起去吃饭&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Batch Process&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;echo -e &#34;1 欢迎光临。\n2 谢谢惠顾。&#34; | paddlespeech tts&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Shell Pipeline&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ASR + Punctuation Restoration&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;paddlespeech asr --input ./zh.wav | paddlespeech text --task punc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more command lines, please see: &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos&#34;&gt;demos&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you want to try more functions like training and tuning, please have a look at &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/asr/quick_start.md&#34;&gt;Speech-to-Text Quick Start&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/tts/quick_start.md&#34;&gt;Text-to-Speech Quick Start&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;quickstartserver&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start Server&lt;/h2&gt; &#xA;&lt;p&gt;Developers can have a try of our speech server with &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/paddlespeech/server/README.md&#34;&gt;PaddleSpeech Server Command Line&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Start server&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech_server start --config_file ./paddlespeech/server/conf/application.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Access Speech Recognition Services&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech_client asr --server_ip 127.0.0.1 --port 8090 --input input_16k.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Access Text to Speech Services&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech_client tts --server_ip 127.0.0.1 --port 8090 --input &#34;您好，欢迎使用百度飞桨语音合成服务。&#34; --output output.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Access Audio Classification Services&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech_client cls --server_ip 127.0.0.1 --port 8090 --input input.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information about server command lines, please see: &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/speech_server&#34;&gt;speech server demos&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;quickstartstreamingserver&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start Streaming Server&lt;/h2&gt; &#xA;&lt;p&gt;Developers can have a try of &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/streaming_asr_server/README.md&#34;&gt;streaming asr&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/streaming_tts_server/README.md&#34;&gt;streaming tts&lt;/a&gt; server.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Start Streaming Speech Recognition Server&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;paddlespeech_server start --config_file ./demos/streaming_asr_server/conf/application.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Access Streaming Speech Recognition Services&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;paddlespeech_client asr_online --server_ip 127.0.0.1 --port 8090 --input input_16k.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Start Streaming Text to Speech Server&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;paddlespeech_server start --config_file ./demos/streaming_tts_server/conf/tts_online_application.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Access Streaming Text to Speech Services&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;paddlespeech_client tts_online --server_ip 127.0.0.1 --port 8092 --protocol http --input &#34;您好，欢迎使用百度飞桨语音合成服务。&#34; --output output.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information please see: &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/streaming_asr_server/README.md&#34;&gt;streaming asr&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/streaming_tts_server/README.md&#34;&gt;streaming tts&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;ModelList&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Model List&lt;/h2&gt; &#xA;&lt;p&gt;PaddleSpeech supports a series of most popular models. They are summarized in &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/released_model.md&#34;&gt;released models&lt;/a&gt; and attached with available pretrained models.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;SpeechToText&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Speech-to-Text&lt;/strong&gt; contains &lt;em&gt;Acoustic Model&lt;/em&gt;, &lt;em&gt;Language Model&lt;/em&gt;, and &lt;em&gt;Speech Translation&lt;/em&gt;, with the following details:&lt;/p&gt; &#xA;&lt;table style=&#34;width:100%&#34;&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Speech-to-Text Module Type&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Model Type&lt;/th&gt; &#xA;   &lt;th&gt;Example&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;4&#34;&gt;Speech Recogination&lt;/td&gt; &#xA;   &lt;td rowspan=&#34;2&#34;&gt;Aishell&lt;/td&gt; &#xA;   &lt;td&gt;DeepSpeech2 RNN + Conv based Models&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell/asr0&#34;&gt;deepspeech2-aishell&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Transformer based Attention Models &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell/asr1&#34;&gt;u2.transformer.conformer-aishell&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; Librispeech&lt;/td&gt; &#xA;   &lt;td&gt;Transformer based Attention Models &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/librispeech/asr0&#34;&gt;deepspeech2-librispeech&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/librispeech/asr1&#34;&gt;transformer.conformer.u2-librispeech&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/librispeech/asr2&#34;&gt;transformer.conformer.u2-kaldi-librispeech&lt;/a&gt; &lt;/td&gt;  &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TIMIT&lt;/td&gt; &#xA;   &lt;td&gt;Unified Streaming &amp;amp; Non-streaming Two-pass&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/timit/asr1&#34;&gt; u2-timit&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Alignment&lt;/td&gt; &#xA;   &lt;td&gt;THCHS30&lt;/td&gt; &#xA;   &lt;td&gt;MFA&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/.examples/thchs30/align0&#34;&gt;mfa-thchs30&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;1&#34;&gt;Language Model&lt;/td&gt; &#xA;   &lt;td colspan=&#34;2&#34;&gt;Ngram Language Model&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/other/ngram_lm&#34;&gt;kenlm&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;2&#34;&gt;Speech Translation (English to Chinese)&lt;/td&gt; &#xA;   &lt;td rowspan=&#34;2&#34;&gt;TED En-Zh&lt;/td&gt; &#xA;   &lt;td&gt;Transformer + ASR MTL&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ted_en_zh/st0&#34;&gt;transformer-ted&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FAT + Transformer + ASR MTL&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ted_en_zh/st1&#34;&gt;fat-st-ted&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a name=&#34;TextToSpeech&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Text-to-Speech&lt;/strong&gt; in PaddleSpeech mainly contains three modules: &lt;em&gt;Text Frontend&lt;/em&gt;, &lt;em&gt;Acoustic Model&lt;/em&gt; and &lt;em&gt;Vocoder&lt;/em&gt;. Acoustic Model and Vocoder models are listed as follow:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt; Text-to-Speech Module Type &lt;/th&gt; &#xA;   &lt;th&gt; Model Type &lt;/th&gt; &#xA;   &lt;th&gt; Dataset &lt;/th&gt; &#xA;   &lt;th&gt; Example &lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; Text Frontend &lt;/td&gt; &#xA;   &lt;td colspan=&#34;2&#34;&gt;   &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/other/tn&#34;&gt;tn&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/other/g2p&#34;&gt;g2p&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;4&#34;&gt;Acoustic Model&lt;/td&gt; &#xA;   &lt;td&gt;Tacotron2&lt;/td&gt; &#xA;   &lt;td&gt;LJSpeech / CSMSC&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ljspeech/tts0&#34;&gt;tacotron2-ljspeech&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/tts0&#34;&gt;tacotron2-csmsc&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Transformer TTS&lt;/td&gt; &#xA;   &lt;td&gt;LJSpeech&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ljspeech/tts1&#34;&gt;transformer-ljspeech&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SpeedySpeech&lt;/td&gt; &#xA;   &lt;td&gt;CSMSC&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/tts2&#34;&gt;speedyspeech-csmsc&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FastSpeech2&lt;/td&gt; &#xA;   &lt;td&gt;LJSpeech / VCTK / CSMSC / AISHELL-3&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ljspeech/tts3&#34;&gt;fastspeech2-ljspeech&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/vctk/tts3&#34;&gt;fastspeech2-vctk&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/tts3&#34;&gt;fastspeech2-csmsc&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/tts3&#34;&gt;fastspeech2-aishell3&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;6&#34;&gt;Vocoder&lt;/td&gt; &#xA;   &lt;td&gt;WaveFlow&lt;/td&gt; &#xA;   &lt;td&gt;LJSpeech&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ljspeech/voc0&#34;&gt;waveflow-ljspeech&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Parallel WaveGAN&lt;/td&gt; &#xA;   &lt;td&gt;LJSpeech / VCTK / CSMSC / AISHELL-3&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ljspeech/voc1&#34;&gt;PWGAN-ljspeech&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/vctk/voc1&#34;&gt;PWGAN-vctk&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/voc1&#34;&gt;PWGAN-csmsc&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/voc1&#34;&gt;PWGAN-aishell3&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Multi Band MelGAN&lt;/td&gt; &#xA;   &lt;td&gt;CSMSC&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/voc3&#34;&gt;Multi Band MelGAN-csmsc&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Style MelGAN&lt;/td&gt; &#xA;   &lt;td&gt;CSMSC&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/voc4&#34;&gt;Style MelGAN-csmsc&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HiFiGAN&lt;/td&gt; &#xA;   &lt;td&gt;LJSpeech / VCTK / CSMSC / AISHELL-3&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ljspeech/voc5&#34;&gt;HiFiGAN-ljspeech&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/vctk/voc5&#34;&gt;HiFiGAN-vctk&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/voc5&#34;&gt;HiFiGAN-csmsc&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/voc5&#34;&gt;HiFiGAN-aishell3&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;WaveRNN&lt;/td&gt; &#xA;   &lt;td&gt;CSMSC&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/voc6&#34;&gt;WaveRNN-csmsc&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;3&#34;&gt;Voice Cloning&lt;/td&gt; &#xA;   &lt;td&gt;GE2E&lt;/td&gt; &#xA;   &lt;td&gt;Librispeech, etc.&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/other/ge2e&#34;&gt;ge2e&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GE2E + Tacotron2&lt;/td&gt; &#xA;   &lt;td&gt;AISHELL-3&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/vc0&#34;&gt;ge2e-tacotron2-aishell3&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GE2E + FastSpeech2&lt;/td&gt; &#xA;   &lt;td&gt;AISHELL-3&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/vc1&#34;&gt;ge2e-fastspeech2-aishell3&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a name=&#34;AudioClassification&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Audio Classification&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table style=&#34;width:100%&#34;&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt; Task &lt;/th&gt; &#xA;   &lt;th&gt; Dataset &lt;/th&gt; &#xA;   &lt;th&gt; Model Type &lt;/th&gt; &#xA;   &lt;th&gt; Example &lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Audio Classification&lt;/td&gt; &#xA;   &lt;td&gt;ESC-50&lt;/td&gt; &#xA;   &lt;td&gt;PANN&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/esc50/cls0&#34;&gt;pann-esc50&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a name=&#34;SpeakerVerification&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Speaker Verification&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table style=&#34;width:100%&#34;&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt; Task &lt;/th&gt; &#xA;   &lt;th&gt; Dataset &lt;/th&gt; &#xA;   &lt;th&gt; Model Type &lt;/th&gt; &#xA;   &lt;th&gt; Example &lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Speaker Verification&lt;/td&gt; &#xA;   &lt;td&gt;VoxCeleb12&lt;/td&gt; &#xA;   &lt;td&gt;ECAPA-TDNN&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/voxceleb/sv0&#34;&gt;ecapa-tdnn-voxceleb12&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a name=&#34;PunctuationRestoration&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Punctuation Restoration&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table style=&#34;width:100%&#34;&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt; Task &lt;/th&gt; &#xA;   &lt;th&gt; Dataset &lt;/th&gt; &#xA;   &lt;th&gt; Model Type &lt;/th&gt; &#xA;   &lt;th&gt; Example &lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Punctuation Restoration&lt;/td&gt; &#xA;   &lt;td&gt;IWLST2012_zh&lt;/td&gt; &#xA;   &lt;td&gt;Ernie Linear&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/iwslt2012/punc0&#34;&gt;iwslt2012-punc0&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Documents&lt;/h2&gt; &#xA;&lt;p&gt;Normally, &lt;a href=&#34;https://paperswithcode.com/area/speech&#34;&gt;Speech SoTA&lt;/a&gt;, &lt;a href=&#34;https://paperswithcode.com/area/audio&#34;&gt;Audio SoTA&lt;/a&gt; and &lt;a href=&#34;https://paperswithcode.com/area/music&#34;&gt;Music SoTA&lt;/a&gt; give you an overview of the hot academic topics in the related area. To focus on the tasks in PaddleSpeech, you will find the following guidelines are helpful to grasp the core ideas.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/install.md&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#quickstart&#34;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/README.md&#34;&gt;Some Demos&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Tutorials &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/asr/quick_start.md&#34;&gt;Automatic Speech Recognition&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/asr/models_introduction.md&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/asr/data_preparation.md&#34;&gt;Data Preparation&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/asr/ngram_lm.md&#34;&gt;Ngram LM&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/tts/quick_start.md&#34;&gt;Text-to-Speech&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/tts/models_introduction.md&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/tts/advanced_usage.md&#34;&gt;Advanced Usage&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/tts/zh_text_frontend.md&#34;&gt;Chinese Rule Based Text Frontend&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://paddlespeech.readthedocs.io/en/latest/tts/demo.html&#34;&gt;Test Audio Samples&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Speaker Verification &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/audio_searching/README.md&#34;&gt;Audio Searching&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/speaker_verification/README.md&#34;&gt;Speaker Verification&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/audio_tagging/README.md&#34;&gt;Audio Classification&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/speech_translation/README.md&#34;&gt;Speech Translation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/speech_server/README.md&#34;&gt;Speech Server&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/released_model.md&#34;&gt;Released Models&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#SpeechToText&#34;&gt;Speech-to-Text&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#TextToSpeech&#34;&gt;Text-to-Speech&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#AudioClassification&#34;&gt;Audio Classification&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#SpeakerVerification&#34;&gt;Speaker Verification&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#PunctuationRestoration&#34;&gt;Punctuation Restoration&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#Community&#34;&gt;Community&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#contribution&#34;&gt;Welcome to contribute&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#License&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The Text-to-Speech module is originally called &lt;a href=&#34;https://github.com/PaddlePaddle/Parakeet&#34;&gt;Parakeet&lt;/a&gt;, and now merged with this repository. If you are interested in academic research about this task, please see &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/docs/source/tts#overview&#34;&gt;TTS research overview&lt;/a&gt;. Also, &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/raw/develop/docs/source/tts/models_introduction.md&#34;&gt;this document&lt;/a&gt; is a good guideline for the pipeline components.&lt;/p&gt; &#xA;&lt;h2&gt;⭐ Examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/JiehangXie/PaddleBoBo&#34;&gt;PaddleBoBo&lt;/a&gt;: Use PaddleSpeech TTS to generate virtual human voice.&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA; &lt;a href=&#34;https://www.bilibili.com/video/BV1cL411V71o?share_source=copy_web&#34;&gt;&lt;img src=&#34;https://ai-studio-static-online.cdn.bcebos.com/06fd746ab32042f398fb6f33f873e6869e846fe63c214596ae37860fe8103720&#34; width=&#34;500px&#34;&gt;&lt;/a&gt;&#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://paddlespeech.readthedocs.io/en/latest/demo_video.html&#34;&gt;PaddleSpeech Demo Video&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/jerryuhoo/VTuberTalk&#34;&gt;VTuberTalk&lt;/a&gt;: Use PaddleSpeech TTS and ASR to clone voice from videos.&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/jerryuhoo/VTuberTalk/main/gui/gui.png&#34; width=&#34;500px&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;To cite PaddleSpeech for research, please use the following format.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-tex&#34;&gt;@inproceedings{zhang2022paddlespeech,&#xA;    title = {PaddleSpeech: An Easy-to-Use All-in-One Speech Toolkit},&#xA;    author = {Hui Zhang, Tian Yuan, Junkun Chen, Xintong Li, Renjie Zheng, Yuxin Huang, Xiaojie Chen, Enlei Gong, Zeyu Chen, Xiaoguang Hu, dianhai yu, Yanjun Ma, Liang Huang},&#xA;    booktitle = {Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations},&#xA;    year = {2022},&#xA;    publisher = {Association for Computational Linguistics},&#xA;}&#xA;&#xA;@inproceedings{zheng2021fused,&#xA;  title={Fused acoustic and text encoding for multimodal bilingual pretraining and speech translation},&#xA;  author={Zheng, Renjie and Chen, Junkun and Ma, Mingbo and Huang, Liang},&#xA;  booktitle={International Conference on Machine Learning},&#xA;  pages={12736--12746},&#xA;  year={2021},&#xA;  organization={PMLR}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a name=&#34;contribution&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contribute to PaddleSpeech&lt;/h2&gt; &#xA;&lt;p&gt;You are warmly welcome to submit questions in &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/discussions&#34;&gt;discussions&lt;/a&gt; and bug reports in &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/issues&#34;&gt;issues&lt;/a&gt;! Also, we highly appreciate if you are willing to contribute to this project!&lt;/p&gt; &#xA;&lt;h3&gt;Contributors&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/zh794390558&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/3038472?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Jackwaterveg&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/87408988?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/yt605155624&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/24568452?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/kuke&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/3064195?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/xinghai-sun&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/7038341?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pkuyym&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/5782283?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/KPatr1ck&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/22954146?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/LittleChenCc&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/10339970?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/745165806&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/20623194?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Mingxue-Xu&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/92848346?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/chrisxu2016&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/18379485?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lfchener&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/6771821?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/luotao1&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/6836917?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/wanghaoshuang&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/7534971?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/gongel&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/24390500?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/mmglove&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/38800877?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/iclementine&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/16222986?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ZeyuChen&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/1371212?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/AK391&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/81195143?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/qingqing01&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/7845005?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ericxk&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/4719594?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/kvinwang&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/6442159?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/jiqiren11&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/82639260?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/AshishKarel&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/58069375?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/chesterkuo&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/6285069?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/tensor-tang&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/21351065?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/hysunflower&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/52739577?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/wwhu&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/6081200?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lispc&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/2833376?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/jerryuhoo&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/24245709?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/harisankarh&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/1307053?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Jackiexiao&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/18050469?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/limpidezza&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/71760778?v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/yeyupiaoling&#34;&gt;yeyupiaoling&lt;/a&gt;/&lt;a href=&#34;https://github.com/yeyupiaoling/PPASR&#34;&gt;PPASR&lt;/a&gt;/&lt;a href=&#34;https://github.com/yeyupiaoling/PaddlePaddle-DeepSpeech&#34;&gt;PaddlePaddle-DeepSpeech&lt;/a&gt;/&lt;a href=&#34;https://github.com/yeyupiaoling/VoiceprintRecognition-PaddlePaddle&#34;&gt;VoiceprintRecognition-PaddlePaddle&lt;/a&gt;/&lt;a href=&#34;https://github.com/yeyupiaoling/AudioClassification-PaddlePaddle&#34;&gt;AudioClassification-PaddlePaddle&lt;/a&gt; for years of attention, constructive advice and great help.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/mymagicpower&#34;&gt;mymagicpower&lt;/a&gt; for the Java implementation of ASR upon &lt;a href=&#34;https://github.com/mymagicpower/AIAS/tree/main/3_audio_sdks/asr_sdk&#34;&gt;short&lt;/a&gt; and &lt;a href=&#34;https://github.com/mymagicpower/AIAS/tree/main/3_audio_sdks/asr_long_audio_sdk&#34;&gt;long&lt;/a&gt; audio files.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/JiehangXie&#34;&gt;JiehangXie&lt;/a&gt;/&lt;a href=&#34;https://github.com/JiehangXie/PaddleBoBo&#34;&gt;PaddleBoBo&lt;/a&gt; for developing Virtual Uploader(VUP)/Virtual YouTuber(VTuber) with PaddleSpeech TTS function.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/745165806&#34;&gt;745165806&lt;/a&gt;/&lt;a href=&#34;https://github.com/745165806/PaddleSpeechTask&#34;&gt;PaddleSpeechTask&lt;/a&gt; for contributing Punctuation Restoration model.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/745165806&#34;&gt;kslz&lt;/a&gt; for supplementary Chinese documents.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/awmmmm&#34;&gt;awmmmm&lt;/a&gt; for contributing fastspeech2 aishell3 conformer pretrained model.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/phecda-xu&#34;&gt;phecda-xu&lt;/a&gt;/&lt;a href=&#34;https://github.com/phecda-xu/PaddleDubbing&#34;&gt;PaddleDubbing&lt;/a&gt; for developing a dubbing tool with GUI based on PaddleSpeech TTS model.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/jerryuhoo&#34;&gt;jerryuhoo&lt;/a&gt;/&lt;a href=&#34;https://github.com/jerryuhoo/VTuberTalk&#34;&gt;VTuberTalk&lt;/a&gt; for developing a GUI tool based on PaddleSpeech TTS and code for making datasets from videos based on PaddleSpeech ASR.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Besides, PaddleSpeech depends on a lot of open source repositories. See &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/reference.md&#34;&gt;references&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;PaddleSpeech is provided under the &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/LICENSE&#34;&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>