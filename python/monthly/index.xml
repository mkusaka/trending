<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-04-01T02:10:40Z</updated>
  <subtitle>Monthly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>abi/screenshot-to-code</title>
    <updated>2024-04-01T02:10:40Z</updated>
    <id>tag:github.com,2024-04-01:/abi/screenshot-to-code</id>
    <link href="https://github.com/abi/screenshot-to-code" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Drop in a screenshot and convert it to clean code (HTML/Tailwind/React/Vue)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;screenshot-to-code&lt;/h1&gt; &#xA;&lt;p&gt;A simple tool to convert screenshots, mockups and Figma designs into clean, functional code using AI.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/abi/screenshot-to-code/assets/23818/6cebadae-2fe3-4986-ac6a-8fb9db030045&#34;&gt;https://github.com/abi/screenshot-to-code/assets/23818/6cebadae-2fe3-4986-ac6a-8fb9db030045&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Supported stacks:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;HTML + Tailwind&lt;/li&gt; &#xA; &lt;li&gt;React + Tailwind&lt;/li&gt; &#xA; &lt;li&gt;Vue + Tailwind&lt;/li&gt; &#xA; &lt;li&gt;Bootstrap&lt;/li&gt; &#xA; &lt;li&gt;Ionic + Tailwind&lt;/li&gt; &#xA; &lt;li&gt;SVG&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Supported AI models:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GPT-4 Vision&lt;/li&gt; &#xA; &lt;li&gt;Claude 3 Sonnet (faster, and on par or better than GPT-4 vision for many inputs)&lt;/li&gt; &#xA; &lt;li&gt;DALL-E 3 for image generation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/abi/screenshot-to-code/main/#-examples&#34;&gt;Examples&lt;/a&gt; section below for more demos.&lt;/p&gt; &#xA;&lt;p&gt;We also just added experimental support for taking a video/screen recording of a website in action and turning that into a functional prototype.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/abi/screenshot-to-code/assets/23818/8758ffa4-9483-4b9b-bb66-abd6d1594c33&#34; alt=&#34;google in app quick 3&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/abi/screenshot-to-code/wiki/Screen-Recording-to-Code&#34;&gt;Learn more about video here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/_abi_&#34;&gt;Follow me on Twitter for updates&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Try It Out!&lt;/h2&gt; &#xA;&lt;p&gt;üÜï &lt;a href=&#34;https://screenshottocode.com&#34;&gt;Try it live on the hosted version&lt;/a&gt; (bring your own OpenAI key - &lt;strong&gt;your key must have access to GPT-4 Vision. See &lt;a href=&#34;https://raw.githubusercontent.com/abi/screenshot-to-code/main/#%EF%B8%8F-faqs&#34;&gt;FAQ&lt;/a&gt; section below for details&lt;/strong&gt;). Or see &lt;a href=&#34;https://raw.githubusercontent.com/abi/screenshot-to-code/main/#-getting-started&#34;&gt;Getting Started&lt;/a&gt; below for local install instructions.&lt;/p&gt; &#xA;&lt;h2&gt;üõ† Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;The app has a React/Vite frontend and a FastAPI backend. You will need an OpenAI API key with access to the GPT-4 Vision API or an Anthropic key if you want to use Claude Sonnet, or for experimental video support.&lt;/p&gt; &#xA;&lt;p&gt;Run the backend (I use Poetry for package management - &lt;code&gt;pip install poetry&lt;/code&gt; if you don&#39;t have it):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd backend&#xA;echo &#34;OPENAI_API_KEY=sk-your-key&#34; &amp;gt; .env&#xA;poetry install&#xA;poetry shell&#xA;poetry run uvicorn main:app --reload --port 7001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to use Anthropic, add the &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt; to &lt;code&gt;backend/.env&lt;/code&gt; with your API key from Anthropic.&lt;/p&gt; &#xA;&lt;p&gt;Run the frontend:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd frontend&#xA;yarn&#xA;yarn dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open &lt;a href=&#34;http://localhost:5173&#34;&gt;http://localhost:5173&lt;/a&gt; to use the app.&lt;/p&gt; &#xA;&lt;p&gt;If you prefer to run the backend on a different port, update VITE_WS_BACKEND_URL in &lt;code&gt;frontend/.env.local&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;For debugging purposes, if you don&#39;t want to waste GPT4-Vision credits, you can run the backend in mock mode (which streams a pre-recorded response):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;MOCK=true poetry run uvicorn main:app --reload --port 7001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Docker&lt;/h2&gt; &#xA;&lt;p&gt;If you have Docker installed on your system, in the root directory, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo &#34;OPENAI_API_KEY=sk-your-key&#34; &amp;gt; .env&#xA;docker-compose up -d --build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The app will be up and running at &lt;a href=&#34;http://localhost:5173&#34;&gt;http://localhost:5173&lt;/a&gt;. Note that you can&#39;t develop the application with this setup as the file changes won&#39;t trigger a rebuild.&lt;/p&gt; &#xA;&lt;h2&gt;üôã‚Äç‚ôÇÔ∏è FAQs&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;I&#39;m running into an error when setting up the backend. How can I fix it?&lt;/strong&gt; &lt;a href=&#34;https://github.com/abi/screenshot-to-code/issues/3#issuecomment-1814777959&#34;&gt;Try this&lt;/a&gt;. If that still doesn&#39;t work, open an issue.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;How do I get an OpenAI API key?&lt;/strong&gt; See &lt;a href=&#34;https://github.com/abi/screenshot-to-code/raw/main/Troubleshooting.md&#34;&gt;https://github.com/abi/screenshot-to-code/blob/main/Troubleshooting.md&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;How can I configure an OpenAI proxy?&lt;/strong&gt; - you can configure the OpenAI base URL if you need to use a proxy: Set OPENAI_BASE_URL in the &lt;code&gt;backend/.env&lt;/code&gt; or directly in the UI in the settings dialog&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;How can I update the backend host that my front-end connects to?&lt;/strong&gt; - Configure VITE_HTTP_BACKEND_URL and VITE_WS_BACKEND_URL in front/.env.local For example, set VITE_HTTP_BACKEND_URL=&lt;a href=&#34;http://124.10.20.1:7001&#34;&gt;http://124.10.20.1:7001&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;How can I provide feedback?&lt;/strong&gt; For feedback, feature requests and bug reports, open an issue or ping me on &lt;a href=&#34;https://twitter.com/_abi_&#34;&gt;Twitter&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìö Examples&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;NYTimes&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Original&lt;/th&gt; &#xA;   &lt;th&gt;Replica&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;1238&#34; alt=&#34;Screenshot 2023-11-20 at 12 54 03 PM&#34; src=&#34;https://github.com/abi/screenshot-to-code/assets/23818/3b644dfa-9ca6-4148-84a7-3405b6671922&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;1414&#34; alt=&#34;Screenshot 2023-11-20 at 12 59 56 PM&#34; src=&#34;https://github.com/abi/screenshot-to-code/assets/23818/26201c9f-1a28-4f35-a3b1-1f04e2b8ce2a&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Instagram page (with not Taylor Swift pics)&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/abi/screenshot-to-code/assets/23818/503eb86a-356e-4dfc-926a-dabdb1ac7ba1&#34;&gt;https://github.com/abi/screenshot-to-code/assets/23818/503eb86a-356e-4dfc-926a-dabdb1ac7ba1&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Hacker News&lt;/strong&gt; but it gets the colors wrong at first so we nudge it&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/abi/screenshot-to-code/assets/23818/3fec0f77-44e8-4fb3-a769-ac7410315e5d&#34;&gt;https://github.com/abi/screenshot-to-code/assets/23818/3fec0f77-44e8-4fb3-a769-ac7410315e5d&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üåç Hosted Version&lt;/h2&gt; &#xA;&lt;p&gt;üÜï &lt;a href=&#34;https://screenshottocode.com&#34;&gt;Try it here&lt;/a&gt; (bring your own OpenAI key - &lt;strong&gt;your key must have access to GPT-4 Vision. See &lt;a href=&#34;https://raw.githubusercontent.com/abi/screenshot-to-code/main/#%EF%B8%8F-faqs&#34;&gt;FAQ&lt;/a&gt; section for details&lt;/strong&gt;). Or see &lt;a href=&#34;https://raw.githubusercontent.com/abi/screenshot-to-code/main/#-getting-started&#34;&gt;Getting Started&lt;/a&gt; for local install instructions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/abiraja&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png&#34; alt=&#34;&amp;quot;Buy Me A Coffee&amp;quot;&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>langgenius/dify</title>
    <updated>2024-04-01T02:10:40Z</updated>
    <id>tag:github.com,2024-04-01:/langgenius/dify</id>
    <link href="https://github.com/langgenius/dify" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Dify is an open-source LLM app building platform. It has the core tech required to build AI-native apps, including RAG, agent capabilities, model management, observability and more, packaged into one intuitive interface.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://dify.ai&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langgenius/dify/main/images/describe.png&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/README.md&#34;&gt;English&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/README_CN.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/README_JA.md&#34;&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/README_ES.md&#34;&gt;Espa√±ol&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/README_KL.md&#34;&gt;Klingon&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/README_FR.md&#34;&gt;Fran√ßais&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://dify.ai&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;Static Badge&#34; src=&#34;https://img.shields.io/badge/AI-Dify?logo=AI&amp;amp;logoColor=%20%23f5f5f5&amp;amp;label=Dify&amp;amp;labelColor=%20%23155EEF&amp;amp;color=%23EAECF0&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/FngNHpbcY7&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/1082486657678311454?logo=discord&#34; alt=&#34;chat on Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/intent/follow?screen_name=dify_ai&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/twitter/follow/dify_ai?style=social&amp;amp;logo=X&#34; alt=&#34;follow on Twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/u/langgenius&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;Docker Pulls&#34; src=&#34;https://img.shields.io/docker/pulls/langgenius/dify-web&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6&#34; target=&#34;_blank&#34;&gt; üìå Check out Dify Premium on AWS and deploy it to your own AWS VPC with one-click. &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dify&lt;/strong&gt; is an LLM application development platform that has helped built over &lt;strong&gt;100,000&lt;/strong&gt; applications. It integrates BaaS and LLMOps, covering the essential tech stack for building generative AI-native applications, including a built-in RAG engine. Dify allows you to &lt;strong&gt;deploy your own version of Assistants API and GPTs, based on any LLMs.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langgenius/dify/main/images/demo.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Using our Cloud Services&lt;/h2&gt; &#xA;&lt;p&gt;You can try out &lt;a href=&#34;https://dify.ai&#34;&gt;Dify.AI Cloud&lt;/a&gt; now. It provides all the capabilities of the self-deployed version, and includes 200 free requests to OpenAI GPT-3.5.&lt;/p&gt; &#xA;&lt;h3&gt;Looking to purchase via AWS?&lt;/h3&gt; &#xA;&lt;p&gt;Check out &lt;a href=&#34;https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6&#34;&gt;Dify Premium on AWS&lt;/a&gt; and deploy it to your own AWS VPC with one-click.&lt;/p&gt; &#xA;&lt;h2&gt;Dify vs. LangChain vs. Assistants API&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Feature&lt;/th&gt; &#xA;   &lt;th&gt;Dify.AI&lt;/th&gt; &#xA;   &lt;th&gt;Assistants API&lt;/th&gt; &#xA;   &lt;th&gt;LangChain&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Programming Approach&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;API-oriented&lt;/td&gt; &#xA;   &lt;td&gt;API-oriented&lt;/td&gt; &#xA;   &lt;td&gt;Python Code-oriented&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Ecosystem Strategy&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Open Source&lt;/td&gt; &#xA;   &lt;td&gt;Close Source&lt;/td&gt; &#xA;   &lt;td&gt;Open Source&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;RAG Engine&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Supported&lt;/td&gt; &#xA;   &lt;td&gt;Supported&lt;/td&gt; &#xA;   &lt;td&gt;Not Supported&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Prompt IDE&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Included&lt;/td&gt; &#xA;   &lt;td&gt;Included&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Supported LLMs&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Rich Variety&lt;/td&gt; &#xA;   &lt;td&gt;OpenAI-only&lt;/td&gt; &#xA;   &lt;td&gt;Rich Variety&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Local Deployment&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Supported&lt;/td&gt; &#xA;   &lt;td&gt;Not Supported&lt;/td&gt; &#xA;   &lt;td&gt;Not Applicable&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langgenius/dify/main/images/models.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;1. LLM Support&lt;/strong&gt;: Integration with OpenAI&#39;s GPT family of models, or the open-source Llama2 family models. In fact, Dify supports mainstream commercial models and open-source models (locally deployed or based on MaaS).&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;2. Prompt IDE&lt;/strong&gt;: Visual orchestration of applications and services based on LLMs with your team.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3. RAG Engine&lt;/strong&gt;: Includes various RAG capabilities based on full-text indexing or vector database embeddings, allowing direct upload of PDFs, TXTs, and other text formats.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;4. AI Agent&lt;/strong&gt;: Based on Function Calling and ReAct, the Agent inference framework allows users to customize tools, what you see is what you get. Dify provides more than a dozen built-in tool calling capabilities, such as Google Search, DELL¬∑E, Stable Diffusion, WolframAlpha, etc.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;5. Continuous Operations&lt;/strong&gt;: Monitor and analyze application logs and performance, continuously improving Prompts, datasets, or models using production data.&lt;/p&gt; &#xA;&lt;h2&gt;Before You Start&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Star us on GitHub, and be instantly notified for new releases!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/langgenius/dify/assets/100913391/95f37259-7370-4456-a9f0-0bc01ef8642f&#34; alt=&#34;star-us&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dify.ai&#34;&gt;Website&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.dify.ai&#34;&gt;Docs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.dify.ai/getting-started/install-self-hosted&#34;&gt;Deployment Docs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.dify.ai/getting-started/faq&#34;&gt;FAQ&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Install the Community Edition&lt;/h2&gt; &#xA;&lt;h3&gt;System Requirements&lt;/h3&gt; &#xA;&lt;p&gt;Before installing Dify, make sure your machine meets the following minimum system requirements:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;CPU &amp;gt;= 2 Core&lt;/li&gt; &#xA; &lt;li&gt;RAM &amp;gt;= 4GB&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Quick Start&lt;/h3&gt; &#xA;&lt;p&gt;The easiest way to start the Dify server is to run our &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/docker/docker-compose.yaml&#34;&gt;docker-compose.yml&lt;/a&gt; file. Before running the installation command, make sure that &lt;a href=&#34;https://docs.docker.com/get-docker/&#34;&gt;Docker&lt;/a&gt; and &lt;a href=&#34;https://docs.docker.com/compose/install/&#34;&gt;Docker Compose&lt;/a&gt; are installed on your machine:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd docker&#xA;docker compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After running, you can access the Dify dashboard in your browser at &lt;a href=&#34;http://localhost/install&#34;&gt;http://localhost/install&lt;/a&gt; and start the initialization installation process.&lt;/p&gt; &#xA;&lt;h4&gt;Deploy with Helm Chart&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://helm.sh/&#34;&gt;Helm Chart&lt;/a&gt; version, which allows Dify to be deployed on Kubernetes.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/douban/charts/tree/master/charts/dify&#34;&gt;Helm Chart by @LeoQuote&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/BorisPolonsky/dify-helm&#34;&gt;Helm Chart by @BorisPolonsky&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Configuration&lt;/h3&gt; &#xA;&lt;p&gt;If you need to customize the configuration, please refer to the comments in our &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/docker/docker-compose.yaml&#34;&gt;docker-compose.yml&lt;/a&gt; file and manually set the environment configuration. After making the changes, please run &lt;code&gt;docker-compose up -d&lt;/code&gt; again. You can see the full list of environment variables in our &lt;a href=&#34;https://docs.dify.ai/getting-started/install-self-hosted/environments&#34;&gt;docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#langgenius/dify&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=langgenius/dify&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;For those who&#39;d like to contribute code, see our &lt;a href=&#34;https://github.com/langgenius/dify/raw/main/CONTRIBUTING.md&#34;&gt;Contribution Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.&lt;/p&gt; &#xA;&lt;h3&gt;Contributors&lt;/h3&gt; &#xA;&lt;a href=&#34;https://github.com/langgenius/dify/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=langgenius/dify&#34;&gt; &lt;/a&gt; &#xA;&lt;h3&gt;Translations&lt;/h3&gt; &#xA;&lt;p&gt;We are looking for contributors to help with translating Dify to languages other than Mandarin or English. If you are interested in helping, please see the &lt;a href=&#34;https://github.com/langgenius/dify/raw/main/web/i18n/README.md&#34;&gt;i18n README&lt;/a&gt; for more information, and leave us a comment in the &lt;code&gt;global-users&lt;/code&gt; channel of our &lt;a href=&#34;https://discord.gg/8Tpq4AcN9c&#34;&gt;Discord Community Server&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Community &amp;amp; Support&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://feedback.dify.ai/&#34;&gt;Canny&lt;/a&gt;. Best for: sharing feedback and checking out our feature roadmap.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/langgenius/dify/issues&#34;&gt;GitHub Issues&lt;/a&gt;. Best for: bugs you encounter using Dify.AI, and feature proposals. See our &lt;a href=&#34;https://github.com/langgenius/dify/raw/main/CONTRIBUTING.md&#34;&gt;Contribution Guide&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;mailto:hello@dify.ai?subject=%5BGitHub%5DQuestions%20About%20Dify&#34;&gt;Email Support&lt;/a&gt;. Best for: questions you have about using Dify.AI.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.gg/FngNHpbcY7&#34;&gt;Discord&lt;/a&gt;. Best for: sharing your applications and hanging out with the community.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/dify_ai&#34;&gt;Twitter&lt;/a&gt;. Best for: sharing your applications and hanging out with the community.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;mailto:business@dify.ai?subject=%5BGitHub%5DBusiness%20License%20Inquiry&#34;&gt;Business Contact&lt;/a&gt;. Best for: business inquiries of licensing Dify.AI for commercial use.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Direct Meetings&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Help us make Dify better. Reach out directly to us&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Point of Contact&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Purpose&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://cal.com/guchenhe/15min&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://i.postimg.cc/fWBqSmjP/Git-Hub-README-Button-3x.png&#34; border=&#34;0&#34; alt=&#34;Git-Hub-README-Button-3x&#34; height=&#34;60&#34; width=&#34;214&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Product design feedback, user experience discussions, feature planning and roadmaps.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://cal.com/pinkbanana&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://i.postimg.cc/LsRTh87D/Git-Hub-README-Button-2x.png&#34; border=&#34;0&#34; alt=&#34;Git-Hub-README-Button-2x&#34; height=&#34;60&#34; width=&#34;225&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Technical support, issues, or feature requests&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Security Disclosure&lt;/h2&gt; &#xA;&lt;p&gt;To protect your privacy, please avoid posting security issues on GitHub. Instead, send your questions to &lt;a href=&#34;mailto:security@dify.ai&#34;&gt;security@dify.ai&lt;/a&gt; and we will provide you with a more detailed answer.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This repository is available under the &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/LICENSE&#34;&gt;Dify Open Source License&lt;/a&gt;, which is essentially Apache 2.0 with a few additional restrictions.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>myshell-ai/MeloTTS</title>
    <updated>2024-04-01T02:10:40Z</updated>
    <id>tag:github.com,2024-04-01:/myshell-ai/MeloTTS</id>
    <link href="https://github.com/myshell-ai/MeloTTS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;High-quality multi-lingual text-to-speech library by MyShell.ai. Support English, Spanish, French, Chinese, Japanese and Korean.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;div&gt;&#xA;  &amp;nbsp;&#xA; &lt;/div&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/myshell-ai/MeloTTS/main/logo.png&#34; width=&#34;300&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;MeloTTS is a &lt;strong&gt;high-quality multi-lingual&lt;/strong&gt; text-to-speech library by &lt;a href=&#34;https://myshell.ai&#34;&gt;MyShell.ai&lt;/a&gt;. Supported languages include:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Language&lt;/th&gt; &#xA;   &lt;th&gt;Example&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;English (American)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/en/EN-US/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;English (British)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/en/EN-BR/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;English (Indian)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/en/EN_INDIA/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;English (Australian)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/en/EN-AU/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;English (Default)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/en/EN-Default/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Spanish&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/es/ES/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;French&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/fr/FR/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese (mix EN)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/zh/ZH/speed_1.0/sent_008.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Japanese&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/jp/JP/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Korean&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/kr/KR/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Some other features include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The Chinese speaker supports &lt;code&gt;mixed Chinese and English&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Fast enough for &lt;code&gt;CPU real-time inference&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/myshell-ai/MeloTTS/main/docs/quick_use.md&#34;&gt;Use without Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/myshell-ai/MeloTTS/main/docs/install.md&#34;&gt;Install and Use Locally&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/myshell-ai/MeloTTS/main/docs/training.md&#34;&gt;Training on Custom Dataset&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The Python API and model cards can be found in &lt;a href=&#34;https://github.com/myshell-ai/MeloTTS/raw/main/docs/install.md#python-api&#34;&gt;this repo&lt;/a&gt; or on &lt;a href=&#34;https://huggingface.co/myshell-ai&#34;&gt;HuggingFace&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Join the Community&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Discord&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Join our &lt;a href=&#34;https://discord.gg/myshell&#34;&gt;Discord community&lt;/a&gt; and select the &lt;code&gt;Developer&lt;/code&gt; role upon joining to gain exclusive access to our developer-only channel! Don&#39;t miss out on valuable discussions and collaboration opportunities.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you find this work useful, please consider contributing to this repo.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/fakerybakery&#34;&gt;@fakerybakery&lt;/a&gt; for adding the Web UI and CLI part.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Authors&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://wl-zhao.github.io&#34;&gt;Wenliang Zhao&lt;/a&gt; at Tsinghua University&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yuxumin.github.io&#34;&gt;Xumin Yu&lt;/a&gt; at Tsinghua University&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.qinzy.tech&#34;&gt;Zengyi Qin&lt;/a&gt; at MIT and MyShell&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Citation&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@software{zhao2024melo,&#xA;  author={Zhao, Wenliang and Yu, Xumin and Qin, Zengyi},&#xA;  title = {MeloTTS: High-quality Multi-lingual Multi-accent Text-to-Speech},&#xA;  url = {https://github.com/myshell-ai/MeloTTS},&#xA;  year = {2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This library is under MIT License, which means it is free for both commercial and non-commercial use.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;This implementation is based on &lt;a href=&#34;https://github.com/coqui-ai/TTS&#34;&gt;TTS&lt;/a&gt;, &lt;a href=&#34;https://github.com/jaywalnut310/vits&#34;&gt;VITS&lt;/a&gt;, &lt;a href=&#34;https://github.com/daniilrobnikov/vits2&#34;&gt;VITS2&lt;/a&gt; and &lt;a href=&#34;https://github.com/fishaudio/Bert-VITS2&#34;&gt;Bert-VITS2&lt;/a&gt;. We appreciate their awesome work.&lt;/p&gt;</summary>
  </entry>
</feed>