<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-01T01:48:43Z</updated>
  <subtitle>Monthly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>unslothai/unsloth</title>
    <updated>2024-05-01T01:48:43Z</updated>
    <id>tag:github.com,2024-05-01:/unslothai/unsloth</id>
    <link href="https://github.com/unslothai/unsloth" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Finetune Llama 3, Mistral &amp; Gemma LLMs 2-5x faster with 80% less memory&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://unsloth.ai&#34;&gt;&#xA;   &lt;picture&gt; &#xA;    &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20white%20text.png&#34;&gt; &#xA;    &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20black%20text.png&#34;&gt; &#xA;    &lt;img alt=&#34;unsloth logo&#34; src=&#34;https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20black%20text.png&#34; height=&#34;110&#34; style=&#34;max-width: 100%;&#34;&gt; &#xA;   &lt;/picture&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp?usp=sharing&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/unslothai/unsloth/main/images/start free finetune button.png&#34; height=&#34;48&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/u54VK8m8tk&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/unslothai/unsloth/main/images/Discord button.png&#34; height=&#34;48&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://ko-fi.com/unsloth&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/unslothai/unsloth/main/images/buy me a coffee button.png&#34; height=&#34;48&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Finetune Llama 3, Mistral &amp;amp; Gemma 2-5x faster with 80% less memory!&lt;/h3&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://i.ibb.co/sJ7RhGG/image-41.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;‚ú® Finetune for Free&lt;/h2&gt; &#xA;&lt;p&gt;All notebooks are &lt;strong&gt;beginner friendly&lt;/strong&gt;! Add your dataset, click &#34;Run All&#34;, and you&#39;ll get a 2x faster finetuned model which can be exported to GGUF, vLLM or uploaded to Hugging Face.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Unsloth supports&lt;/th&gt; &#xA;   &lt;th&gt;Free Notebooks&lt;/th&gt; &#xA;   &lt;th&gt;Performance&lt;/th&gt; &#xA;   &lt;th&gt;Memory use&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3 (8B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp?usp=sharing&#34;&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;2x faster&lt;/td&gt; &#xA;   &lt;td&gt;60% less&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Mistral (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_?usp=sharing&#34;&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;2.2x faster&lt;/td&gt; &#xA;   &lt;td&gt;73% less&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Gemma (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/10NbwlsRChbma1v55m8LAPYG15uQv6HLo?usp=sharing&#34;&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;2.4x faster&lt;/td&gt; &#xA;   &lt;td&gt;71% less&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;ORPO&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/11t4njE3c4Lxl-07OD8lJSMKkfyJml3Tn?usp=sharing&#34;&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.9x faster&lt;/td&gt; &#xA;   &lt;td&gt;43% less&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;DPO Zephyr&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing&#34;&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.9x faster&lt;/td&gt; &#xA;   &lt;td&gt;43% less&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Phi-3 (3.8B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1NvkBmkHfucGO3Ve9s1NKZvMNlw5p83ym?usp=sharing&#34;&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;2x faster&lt;/td&gt; &#xA;   &lt;td&gt;50% less&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;TinyLlama&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing&#34;&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;3.9x faster&lt;/td&gt; &#xA;   &lt;td&gt;74% less&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Benchmarking compared to FA2 + Hugging Face combined.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Kaggle Notebooks&lt;/strong&gt; for &lt;a href=&#34;https://www.kaggle.com/code/danielhanchen/kaggle-llama-3-8b-unsloth-notebook&#34;&gt;Llama-3 8b&lt;/a&gt;, &lt;a href=&#34;https://www.kaggle.com/code/danielhanchen/kaggle-gemma-7b-unsloth-notebook/&#34;&gt;Gemma 7b&lt;/a&gt;, &lt;a href=&#34;https://www.kaggle.com/code/danielhanchen/kaggle-mistral-7b-unsloth-notebook&#34;&gt;Mistral 7b&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;This &lt;a href=&#34;https://colab.research.google.com/drive/1XamvWYinY6FOSX9GLvnqSjjsNflxdhNc?usp=sharing&#34;&gt;conversational notebook&lt;/a&gt; is useful for Llama-3. And ChatML for &lt;a href=&#34;https://colab.research.google.com/drive/1Aau3lgPzeZKQ-98h69CCu1UJcvIBLmy2?usp=sharing&#34;&gt;Mistral 7b&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;This &lt;a href=&#34;https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing&#34;&gt;text completion notebook&lt;/a&gt; is for continued pretraining / raw text.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ü¶• Unsloth.ai News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üì£ NEW! &lt;a href=&#34;https://colab.research.google.com/drive/135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp?usp=sharing&#34;&gt;Llama-3 8b&lt;/a&gt; now works! Llama-3 70b also works (change the model name in the notebook).&lt;/li&gt; &#xA; &lt;li&gt;üì£ NEW! &lt;a href=&#34;https://colab.research.google.com/drive/11t4njE3c4Lxl-07OD8lJSMKkfyJml3Tn?usp=sharing&#34;&gt;ORPO support&lt;/a&gt; is here!&lt;/li&gt; &#xA; &lt;li&gt;üì£ NEW! &lt;a href=&#34;https://colab.research.google.com/drive/1NvkBmkHfucGO3Ve9s1NKZvMNlw5p83ym?usp=sharing&#34;&gt;Phi-3 3.8b support&lt;/a&gt; is here!&lt;/li&gt; &#xA; &lt;li&gt;üì£ NEW! We cut memory usage by a &lt;a href=&#34;https://unsloth.ai/blog/long-context&#34;&gt;further 30%&lt;/a&gt; and now support fine-tuning of LLMs with &lt;a href=&#34;https://unsloth.ai/blog/long-context&#34;&gt;4x longer context windows&lt;/a&gt;! No change required if you&#39;re using our notebooks. To enable, simply change 1 line:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = FastLanguageModel.get_peft_model(&#xA;    model,&#xA;    use_gradient_checkpointing = &#34;unsloth&#34;, # &amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üì£ &lt;a href=&#34;https://colab.research.google.com/drive/19lwcRk_ZQ_ZtX-qzFP3qZBBHZNcMD1hh?usp=sharing&#34;&gt;CodeGemma&lt;/a&gt; now works along with &lt;a href=&#34;https://colab.research.google.com/drive/10NbwlsRChbma1v55m8LAPYG15uQv6HLo?usp=sharing&#34;&gt;Gemma 7b&lt;/a&gt; and &lt;a href=&#34;https://colab.research.google.com/drive/15gGm7x_jTm017_Ic8e317tdIpDG53Mtu?usp=sharing&#34;&gt;Gemma 2b&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üì£ &lt;a href=&#34;https://colab.research.google.com/drive/1aqlNQi7MMJbynFDyOQteD2t0yVfjb9Zh?usp=sharing&#34;&gt;2x faster inference&lt;/a&gt; added for all our models&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üîó Links and Resources&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Links&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;üìö &lt;strong&gt;Wiki &amp;amp; FAQ&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/unslothai/unsloth/wiki&#34;&gt;Read Our Wiki&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img height=&#34;14&#34; src=&#34;https://upload.wikimedia.org/wikipedia/commons/6/6f/Logo_of_Twitter.svg?sanitize=true&#34;&gt;&amp;nbsp; &lt;strong&gt;Twitter (aka X)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://twitter.com/unslothai&#34;&gt;Follow us on X&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;üìú &lt;strong&gt;Documentation&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/unslothai/unsloth/tree/main#-documentation&#34;&gt;Read The Doc&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;üíæ &lt;strong&gt;Installation&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/unslothai/unsloth/tree/main#installation-instructions&#34;&gt;unsloth/README.md&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ü•á &lt;strong&gt;Benchmarking&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/unslothai/unsloth/tree/main#-performance-benchmarking&#34;&gt;Performance Tables&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;üåê &lt;strong&gt;Released Models&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/unsloth&#34;&gt;Unsloth Releases&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;‚úçÔ∏è &lt;strong&gt;Blog&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://unsloth.ai/blog&#34;&gt;Read our Blogs&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;‚≠ê Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;All kernels written in &lt;a href=&#34;https://openai.com/research/triton&#34;&gt;OpenAI&#39;s Triton&lt;/a&gt; language. &lt;strong&gt;Manual backprop engine&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;0% loss in accuracy&lt;/strong&gt; - no approximation methods - all exact.&lt;/li&gt; &#xA; &lt;li&gt;No change of hardware. Supports NVIDIA GPUs since 2018+. Minimum CUDA Capability 7.0 (V100, T4, Titan V, RTX 20, 30, 40x, A100, H100, L40 etc) &lt;a href=&#34;https://developer.nvidia.com/cuda-gpus&#34;&gt;Check your GPU!&lt;/a&gt; GTX 1070, 1080 works, but is slow.&lt;/li&gt; &#xA; &lt;li&gt;Works on &lt;strong&gt;Linux&lt;/strong&gt; and &lt;strong&gt;Windows&lt;/strong&gt; via WSL.&lt;/li&gt; &#xA; &lt;li&gt;Supports 4bit and 16bit QLoRA / LoRA finetuning via &lt;a href=&#34;https://github.com/TimDettmers/bitsandbytes&#34;&gt;bitsandbytes&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Open source trains 5x faster - see &lt;a href=&#34;https://unsloth.ai/&#34;&gt;Unsloth Pro&lt;/a&gt; for up to &lt;strong&gt;30x faster training&lt;/strong&gt;!&lt;/li&gt; &#xA; &lt;li&gt;If you trained a model with ü¶•Unsloth, you can use this cool sticker! &amp;nbsp; &lt;img src=&#34;https://raw.githubusercontent.com/unslothai/unsloth/main/images/made with unsloth.png&#34; height=&#34;50&#34; align=&#34;center&#34;&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ü•á Performance Benchmarking&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For the full list of &lt;strong&gt;reproducable&lt;/strong&gt; benchmarking tables, &lt;a href=&#34;https://unsloth.ai/blog/mistral-benchmark#Benchmark%20tables&#34;&gt;go to our website&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;1 A100 40GB&lt;/th&gt; &#xA;   &lt;th&gt;ü§óHugging Face&lt;/th&gt; &#xA;   &lt;th&gt;Flash Attention&lt;/th&gt; &#xA;   &lt;th&gt;ü¶•Unsloth Open Source&lt;/th&gt; &#xA;   &lt;th&gt;ü¶•&lt;a href=&#34;https://unsloth.ai/pricing&#34;&gt;Unsloth Pro&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;1x&lt;/td&gt; &#xA;   &lt;td&gt;1.04x&lt;/td&gt; &#xA;   &lt;td&gt;1.98x&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;15.64x&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LAION Chip2&lt;/td&gt; &#xA;   &lt;td&gt;1x&lt;/td&gt; &#xA;   &lt;td&gt;0.92x&lt;/td&gt; &#xA;   &lt;td&gt;1.61x&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;20.73x&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OASST&lt;/td&gt; &#xA;   &lt;td&gt;1x&lt;/td&gt; &#xA;   &lt;td&gt;1.19x&lt;/td&gt; &#xA;   &lt;td&gt;2.17x&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;14.83x&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Slim Orca&lt;/td&gt; &#xA;   &lt;td&gt;1x&lt;/td&gt; &#xA;   &lt;td&gt;1.18x&lt;/td&gt; &#xA;   &lt;td&gt;2.22x&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;14.82x&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Benchmarking table below was conducted by &lt;a href=&#34;https://huggingface.co/blog/unsloth-trl&#34;&gt;ü§óHugging Face&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Free Colab T4&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;ü§óHugging Face&lt;/th&gt; &#xA;   &lt;th&gt;Pytorch 2.1.1&lt;/th&gt; &#xA;   &lt;th&gt;ü¶•Unsloth&lt;/th&gt; &#xA;   &lt;th&gt;ü¶• VRAM reduction&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama-2 7b&lt;/td&gt; &#xA;   &lt;td&gt;OASST&lt;/td&gt; &#xA;   &lt;td&gt;1x&lt;/td&gt; &#xA;   &lt;td&gt;1.19x&lt;/td&gt; &#xA;   &lt;td&gt;1.95x&lt;/td&gt; &#xA;   &lt;td&gt;-43.3%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral 7b&lt;/td&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;1x&lt;/td&gt; &#xA;   &lt;td&gt;1.07x&lt;/td&gt; &#xA;   &lt;td&gt;1.56x&lt;/td&gt; &#xA;   &lt;td&gt;-13.7%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Tiny Llama 1.1b&lt;/td&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;1x&lt;/td&gt; &#xA;   &lt;td&gt;2.06x&lt;/td&gt; &#xA;   &lt;td&gt;3.87x&lt;/td&gt; &#xA;   &lt;td&gt;-73.8%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DPO with Zephyr&lt;/td&gt; &#xA;   &lt;td&gt;Ultra Chat&lt;/td&gt; &#xA;   &lt;td&gt;1x&lt;/td&gt; &#xA;   &lt;td&gt;1.09x&lt;/td&gt; &#xA;   &lt;td&gt;1.55x&lt;/td&gt; &#xA;   &lt;td&gt;-18.6%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.ibb.co/sJ7RhGG/image-41.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üíæ Installation Instructions&lt;/h2&gt; &#xA;&lt;h3&gt;Conda Installation&lt;/h3&gt; &#xA;&lt;p&gt;Select either &lt;code&gt;pytorch-cuda=11.8&lt;/code&gt; for CUDA 11.8 or &lt;code&gt;pytorch-cuda=12.1&lt;/code&gt; for CUDA 12.1. If you have &lt;code&gt;mamba&lt;/code&gt;, use &lt;code&gt;mamba&lt;/code&gt; instead of &lt;code&gt;conda&lt;/code&gt; for faster solving. See this &lt;a href=&#34;https://github.com/unslothai/unsloth/issues/73&#34;&gt;Github issue&lt;/a&gt; for help on debugging Conda installs.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create --name unsloth_env python=3.10&#xA;conda activate unsloth_env&#xA;&#xA;conda install pytorch-cuda=&amp;lt;12.1/11.8&amp;gt; pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers&#xA;&#xA;pip install &#34;unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;&#xA;pip install --no-deps trl peft accelerate bitsandbytes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Pip Installation&lt;/h3&gt; &#xA;&lt;p&gt;Do &lt;strong&gt;NOT&lt;/strong&gt; use this if you have Anaconda. You must use the Conda install method, or else stuff will BREAK.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Find your CUDA version via&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch; torch.version.cuda&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;For Pytorch 2.1.0: You can update Pytorch via Pip (interchange &lt;code&gt;cu121&lt;/code&gt; / &lt;code&gt;cu118&lt;/code&gt;). Go to &lt;a href=&#34;https://pytorch.org/&#34;&gt;https://pytorch.org/&lt;/a&gt; to learn more. Select either &lt;code&gt;cu118&lt;/code&gt; for CUDA 11.8 or &lt;code&gt;cu121&lt;/code&gt; for CUDA 12.1. If you have a RTX 3060 or higher (A100, H100 etc), use the &lt;code&gt;&#34;ampere&#34;&lt;/code&gt; path. For Pytorch 2.1.1: go to step 3. For Pytorch 2.2.0: go to step 4.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install --upgrade --force-reinstall --no-cache-dir torch==2.1.0 triton \&#xA;  --index-url https://download.pytorch.org/whl/cu121&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install &#34;unsloth[cu118] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;pip install &#34;unsloth[cu121] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;pip install &#34;unsloth[cu118-ampere] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;pip install &#34;unsloth[cu121-ampere] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;For Pytorch 2.1.1: Use the &lt;code&gt;&#34;ampere&#34;&lt;/code&gt; path for newer RTX 30xx GPUs or higher.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install --upgrade --force-reinstall --no-cache-dir torch==2.1.1 triton \&#xA;  --index-url https://download.pytorch.org/whl/cu121&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install &#34;unsloth[cu118-torch211] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;pip install &#34;unsloth[cu121-torch211] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;pip install &#34;unsloth[cu118-ampere-torch211] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;pip install &#34;unsloth[cu121-ampere-torch211] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;For Pytorch 2.2.0: Use the &lt;code&gt;&#34;ampere&#34;&lt;/code&gt; path for newer RTX 30xx GPUs or higher.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install --upgrade --force-reinstall --no-cache-dir torch==2.2.0 triton \&#xA;  --index-url https://download.pytorch.org/whl/cu121&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install &#34;unsloth[cu118-torch220] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;pip install &#34;unsloth[cu121-torch220] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;pip install &#34;unsloth[cu118-ampere-torch220] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;pip install &#34;unsloth[cu121-ampere-torch220] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;If you get errors, try the below first, then go back to step 1:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install --upgrade pip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;For Pytorch 2.2.1:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# RTX 3090, 4090 Ampere GPUs:&#xA;pip install &#34;unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes&#xA;&#xA;# Pre Ampere RTX 2080, T4, GTX 1080 GPUs:&#xA;pip install &#34;unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;pip install --no-deps xformers trl peft accelerate bitsandbytes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;7&#34;&gt; &#xA; &lt;li&gt;To troubleshoot installs try the below (all must succeed). Xformers should mostly all be available.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nvcc&#xA;python -m xformers.info&#xA;python -m bitsandbytes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üìú Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Go to our &lt;a href=&#34;https://github.com/unslothai/unsloth/wiki&#34;&gt;Wiki page&lt;/a&gt; for saving to GGUF, checkpointing, evaluation and more!&lt;/li&gt; &#xA; &lt;li&gt;We support Huggingface&#39;s TRL, Trainer, Seq2SeqTrainer or even Pytorch code!&lt;/li&gt; &#xA; &lt;li&gt;We&#39;re in ü§óHugging Face&#39;s official docs! Check out the &lt;a href=&#34;https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth&#34;&gt;SFT docs&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/docs/trl/main/en/dpo_trainer#accelerate-dpo-fine-tuning-using-unsloth&#34;&gt;DPO docs&lt;/a&gt;!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from unsloth import FastLanguageModel&#xA;import torch&#xA;from trl import SFTTrainer&#xA;from transformers import TrainingArguments&#xA;from datasets import load_dataset&#xA;max_seq_length = 2048 # Supports RoPE Scaling interally, so choose any!&#xA;# Get LAION dataset&#xA;url = &#34;https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl&#34;&#xA;dataset = load_dataset(&#34;json&#34;, data_files = {&#34;train&#34; : url}, split = &#34;train&#34;)&#xA;&#xA;# 4bit pre quantized models we support for 4x faster downloading + no OOMs.&#xA;fourbit_models = [&#xA;    &#34;unsloth/mistral-7b-bnb-4bit&#34;,&#xA;    &#34;unsloth/mistral-7b-instruct-v0.2-bnb-4bit&#34;,&#xA;    &#34;unsloth/llama-2-7b-bnb-4bit&#34;,&#xA;    &#34;unsloth/gemma-7b-bnb-4bit&#34;,&#xA;    &#34;unsloth/gemma-7b-it-bnb-4bit&#34;, # Instruct version of Gemma 7b&#xA;    &#34;unsloth/gemma-2b-bnb-4bit&#34;,&#xA;    &#34;unsloth/gemma-2b-it-bnb-4bit&#34;, # Instruct version of Gemma 2b&#xA;    &#34;unsloth/llama-3-8b-bnb-4bit&#34;, # [NEW] 15 Trillion token Llama-3&#xA;    &#34;unsloth/Phi-3-mini-4k-instruct-bnb-4bit&#34;,&#xA;] # More models at https://huggingface.co/unsloth&#xA;&#xA;model, tokenizer = FastLanguageModel.from_pretrained(&#xA;    model_name = &#34;unsloth/llama-3-8b-bnb-4bit&#34;,&#xA;    max_seq_length = max_seq_length,&#xA;    dtype = None,&#xA;    load_in_4bit = True,&#xA;)&#xA;&#xA;# Do model patching and add fast LoRA weights&#xA;model = FastLanguageModel.get_peft_model(&#xA;    model,&#xA;    r = 16,&#xA;    target_modules = [&#34;q_proj&#34;, &#34;k_proj&#34;, &#34;v_proj&#34;, &#34;o_proj&#34;,&#xA;                      &#34;gate_proj&#34;, &#34;up_proj&#34;, &#34;down_proj&#34;,],&#xA;    lora_alpha = 16,&#xA;    lora_dropout = 0, # Supports any, but = 0 is optimized&#xA;    bias = &#34;none&#34;,    # Supports any, but = &#34;none&#34; is optimized&#xA;    # [NEW] &#34;unsloth&#34; uses 30% less VRAM, fits 2x larger batch sizes!&#xA;    use_gradient_checkpointing = &#34;unsloth&#34;, # True or &#34;unsloth&#34; for very long context&#xA;    random_state = 3407,&#xA;    max_seq_length = max_seq_length,&#xA;    use_rslora = False,  # We support rank stabilized LoRA&#xA;    loftq_config = None, # And LoftQ&#xA;)&#xA;&#xA;trainer = SFTTrainer(&#xA;    model = model,&#xA;    train_dataset = dataset,&#xA;    dataset_text_field = &#34;text&#34;,&#xA;    max_seq_length = max_seq_length,&#xA;    tokenizer = tokenizer,&#xA;    args = TrainingArguments(&#xA;        per_device_train_batch_size = 2,&#xA;        gradient_accumulation_steps = 4,&#xA;        warmup_steps = 10,&#xA;        max_steps = 60,&#xA;        fp16 = not torch.cuda.is_bf16_supported(),&#xA;        bf16 = torch.cuda.is_bf16_supported(),&#xA;        logging_steps = 1,&#xA;        output_dir = &#34;outputs&#34;,&#xA;        optim = &#34;adamw_8bit&#34;,&#xA;        seed = 3407,&#xA;    ),&#xA;)&#xA;trainer.train()&#xA;&#xA;# Go to https://github.com/unslothai/unsloth/wiki for advanced tips like&#xA;# (1) Saving to GGUF / merging to 16bit for vLLM&#xA;# (2) Continued training from a saved LoRA adapter&#xA;# (3) Adding an evaluation loop / OOMs&#xA;# (4) Cutomized chat templates&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a name=&#34;DPO&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;DPO Support&lt;/h2&gt; &#xA;&lt;p&gt;DPO (Direct Preference Optimization), PPO, Reward Modelling all seem to work as per 3rd party independent testing from &lt;a href=&#34;https://github.com/hiyouga/LLaMA-Factory&#34;&gt;Llama-Factory&lt;/a&gt;. We have a preliminary Google Colab notebook for reproducing Zephyr on Tesla T4 here: &lt;a href=&#34;https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing&#34;&gt;notebook&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We&#39;re in ü§óHugging Face&#39;s official docs! We&#39;re on the &lt;a href=&#34;https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth&#34;&gt;SFT docs&lt;/a&gt; and the &lt;a href=&#34;https://huggingface.co/docs/trl/main/en/dpo_trainer#accelerate-dpo-fine-tuning-using-unsloth&#34;&gt;DPO docs&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from unsloth import FastLanguageModel, PatchDPOTrainer&#xA;PatchDPOTrainer()&#xA;import torch&#xA;from transformers import TrainingArguments&#xA;from trl import DPOTrainer&#xA;&#xA;model, tokenizer = FastLanguageModel.from_pretrained(&#xA;    model_name = &#34;unsloth/zephyr-sft-bnb-4bit&#34;,&#xA;    max_seq_length = max_seq_length,&#xA;    dtype = None,&#xA;    load_in_4bit = True,&#xA;)&#xA;&#xA;# Do model patching and add fast LoRA weights&#xA;model = FastLanguageModel.get_peft_model(&#xA;    model,&#xA;    r = 64,&#xA;    target_modules = [&#34;q_proj&#34;, &#34;k_proj&#34;, &#34;v_proj&#34;, &#34;o_proj&#34;,&#xA;                      &#34;gate_proj&#34;, &#34;up_proj&#34;, &#34;down_proj&#34;,],&#xA;    lora_alpha = 64,&#xA;    lora_dropout = 0, # Supports any, but = 0 is optimized&#xA;    bias = &#34;none&#34;,    # Supports any, but = &#34;none&#34; is optimized&#xA;    # [NEW] &#34;unsloth&#34; uses 30% less VRAM, fits 2x larger batch sizes!&#xA;    use_gradient_checkpointing = &#34;unsloth&#34;, # True or &#34;unsloth&#34; for very long context&#xA;    random_state = 3407,&#xA;    max_seq_length = max_seq_length,&#xA;)&#xA;&#xA;dpo_trainer = DPOTrainer(&#xA;    model = model,&#xA;    ref_model = None,&#xA;    args = TrainingArguments(&#xA;        per_device_train_batch_size = 4,&#xA;        gradient_accumulation_steps = 8,&#xA;        warmup_ratio = 0.1,&#xA;        num_train_epochs = 3,&#xA;        fp16 = not torch.cuda.is_bf16_supported(),&#xA;        bf16 = torch.cuda.is_bf16_supported(),&#xA;        logging_steps = 1,&#xA;        optim = &#34;adamw_8bit&#34;,&#xA;        seed = 42,&#xA;        output_dir = &#34;outputs&#34;,&#xA;    ),&#xA;    beta = 0.1,&#xA;    train_dataset = YOUR_DATASET_HERE,&#xA;    # eval_dataset = YOUR_DATASET_HERE,&#xA;    tokenizer = tokenizer,&#xA;    max_length = 1024,&#xA;    max_prompt_length = 512,&#xA;)&#xA;dpo_trainer.train()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ü•á Detailed Benchmarking Tables&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Click &#34;Code&#34; for fully reproducible examples&lt;/li&gt; &#xA; &lt;li&gt;&#34;Unsloth Equal&#34; is a preview of our PRO version, with code stripped out. All settings and the loss curve remains identical.&lt;/li&gt; &#xA; &lt;li&gt;For the full list of benchmarking tables, &lt;a href=&#34;https://unsloth.ai/blog/mistral-benchmark#Benchmark%20tables&#34;&gt;go to our website&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;1 A100 40GB&lt;/th&gt; &#xA;   &lt;th&gt;ü§óHugging Face&lt;/th&gt; &#xA;   &lt;th&gt;Flash Attention 2&lt;/th&gt; &#xA;   &lt;th&gt;ü¶•Unsloth Open&lt;/th&gt; &#xA;   &lt;th&gt;Unsloth Equal&lt;/th&gt; &#xA;   &lt;th&gt;Unsloth Pro&lt;/th&gt; &#xA;   &lt;th&gt;Unsloth Max&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;1x&lt;/td&gt; &#xA;   &lt;td&gt;1.04x&lt;/td&gt; &#xA;   &lt;td&gt;1.98x&lt;/td&gt; &#xA;   &lt;td&gt;2.48x&lt;/td&gt; &#xA;   &lt;td&gt;5.32x&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;15.64x&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;code&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1u4dBeM-0vGNVmmO6X7cScAut-Hyt4KDF?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1fgTOxpMbVjloQBvZyz4lF4BacKSZOB2A?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1YIPY_18xm-K0iJDgvNkRoJsgkPMPAO3G?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1ANW8EFL3LVyTD7Gq4TkheC1Z7Rxw-rHp?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;seconds&lt;/td&gt; &#xA;   &lt;td&gt;1040&lt;/td&gt; &#xA;   &lt;td&gt;1001&lt;/td&gt; &#xA;   &lt;td&gt;525&lt;/td&gt; &#xA;   &lt;td&gt;419&lt;/td&gt; &#xA;   &lt;td&gt;196&lt;/td&gt; &#xA;   &lt;td&gt;67&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;memory MB&lt;/td&gt; &#xA;   &lt;td&gt;18235&lt;/td&gt; &#xA;   &lt;td&gt;15365&lt;/td&gt; &#xA;   &lt;td&gt;9631&lt;/td&gt; &#xA;   &lt;td&gt;8525&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;% saved&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;15.74&lt;/td&gt; &#xA;   &lt;td&gt;47.18&lt;/td&gt; &#xA;   &lt;td&gt;53.25&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Llama-Factory 3rd party benchmarking&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-Comparison&#34;&gt;Link to performance table.&lt;/a&gt; TGS: tokens per GPU per second. Model: LLaMA2-7B. GPU: NVIDIA A100 * 1. Batch size: 4. Gradient accumulation: 2. LoRA rank: 8. Max length: 1024.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Bits&lt;/th&gt; &#xA;   &lt;th&gt;TGS&lt;/th&gt; &#xA;   &lt;th&gt;GRAM&lt;/th&gt; &#xA;   &lt;th&gt;Speed&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HF&lt;/td&gt; &#xA;   &lt;td&gt;16&lt;/td&gt; &#xA;   &lt;td&gt;2392&lt;/td&gt; &#xA;   &lt;td&gt;18GB&lt;/td&gt; &#xA;   &lt;td&gt;100%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HF+FA2&lt;/td&gt; &#xA;   &lt;td&gt;16&lt;/td&gt; &#xA;   &lt;td&gt;2954&lt;/td&gt; &#xA;   &lt;td&gt;17GB&lt;/td&gt; &#xA;   &lt;td&gt;123%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unsloth+FA2&lt;/td&gt; &#xA;   &lt;td&gt;16&lt;/td&gt; &#xA;   &lt;td&gt;4007&lt;/td&gt; &#xA;   &lt;td&gt;16GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;168%&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HF&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;2415&lt;/td&gt; &#xA;   &lt;td&gt;9GB&lt;/td&gt; &#xA;   &lt;td&gt;101%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unsloth+FA2&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;3726&lt;/td&gt; &#xA;   &lt;td&gt;7GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;160%&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Performance comparisons between popular models&lt;/h3&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Click for specific model benchmarking tables (Mistral 7b, CodeLlama 34b etc.)&lt;/summary&gt; &#xA; &lt;h3&gt;Mistral 7b&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;1 A100 40GB&lt;/th&gt; &#xA;    &lt;th&gt;Hugging Face&lt;/th&gt; &#xA;    &lt;th&gt;Flash Attention 2&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Open&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Equal&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Pro&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Max&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Mistral 7B Slim Orca&lt;/td&gt; &#xA;    &lt;td&gt;1x&lt;/td&gt; &#xA;    &lt;td&gt;1.15x&lt;/td&gt; &#xA;    &lt;td&gt;2.15x&lt;/td&gt; &#xA;    &lt;td&gt;2.53x&lt;/td&gt; &#xA;    &lt;td&gt;4.61x&lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;13.69x&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;code&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1mePk3KzwTD81hr5mcNcs_AX3Kbg_Ha0x?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1dgHxjvTmX6hb0bPcLp26RXSE6_n9DKj7?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1SKrKGV-BZoU4kv5q3g0jtE_OhRgPtrrQ?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/18yOiyX0T81mTwZqOALFSCX_tSAqju6aD?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;seconds&lt;/td&gt; &#xA;    &lt;td&gt;1813&lt;/td&gt; &#xA;    &lt;td&gt;1571&lt;/td&gt; &#xA;    &lt;td&gt;842&lt;/td&gt; &#xA;    &lt;td&gt;718&lt;/td&gt; &#xA;    &lt;td&gt;393&lt;/td&gt; &#xA;    &lt;td&gt;132&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;memory MB&lt;/td&gt; &#xA;    &lt;td&gt;32853&lt;/td&gt; &#xA;    &lt;td&gt;19385&lt;/td&gt; &#xA;    &lt;td&gt;12465&lt;/td&gt; &#xA;    &lt;td&gt;10271&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;% saved&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;40.99&lt;/td&gt; &#xA;    &lt;td&gt;62.06&lt;/td&gt; &#xA;    &lt;td&gt;68.74&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h3&gt;CodeLlama 34b&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;1 A100 40GB&lt;/th&gt; &#xA;    &lt;th&gt;Hugging Face&lt;/th&gt; &#xA;    &lt;th&gt;Flash Attention 2&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Open&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Equal&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Pro&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Max&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Code Llama 34B&lt;/td&gt; &#xA;    &lt;td&gt;OOM ‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;0.99x&lt;/td&gt; &#xA;    &lt;td&gt;1.87x&lt;/td&gt; &#xA;    &lt;td&gt;2.61x&lt;/td&gt; &#xA;    &lt;td&gt;4.27x&lt;/td&gt; &#xA;    &lt;td&gt;12.82x&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;code&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1ykfz3BqrtC_AUFegCzUQjjfUNlxp6Otc?usp=sharing&#34;&gt;‚ñ∂Ô∏è Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/12ZypxQh7OC6kBXvWZI-5d05I4m-B_hoR?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1gdHyAx8XJsz2yNV-DHvbHjR1iCef5Qmh?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1fm7wqx9MJ0kRrwKOfmLkK1Rmw-pySahB?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;seconds&lt;/td&gt; &#xA;    &lt;td&gt;1953&lt;/td&gt; &#xA;    &lt;td&gt;1982&lt;/td&gt; &#xA;    &lt;td&gt;1043&lt;/td&gt; &#xA;    &lt;td&gt;748&lt;/td&gt; &#xA;    &lt;td&gt;458&lt;/td&gt; &#xA;    &lt;td&gt;152&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;memory MB&lt;/td&gt; &#xA;    &lt;td&gt;40000&lt;/td&gt; &#xA;    &lt;td&gt;33217&lt;/td&gt; &#xA;    &lt;td&gt;27413&lt;/td&gt; &#xA;    &lt;td&gt;22161&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;% saved&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;16.96&lt;/td&gt; &#xA;    &lt;td&gt;31.47&lt;/td&gt; &#xA;    &lt;td&gt;44.60&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h3&gt;1 Tesla T4&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;1 T4 16GB&lt;/th&gt; &#xA;    &lt;th&gt;Hugging Face&lt;/th&gt; &#xA;    &lt;th&gt;Flash Attention&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Open&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Pro Equal&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Pro&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Max&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Alpaca&lt;/td&gt; &#xA;    &lt;td&gt;1x&lt;/td&gt; &#xA;    &lt;td&gt;1.09x&lt;/td&gt; &#xA;    &lt;td&gt;1.69x&lt;/td&gt; &#xA;    &lt;td&gt;1.79x&lt;/td&gt; &#xA;    &lt;td&gt;2.93x&lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;8.3x&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;code&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1XpLIV4s8Bj5uryB-X2gqM88oRGHEGdaB?usp=sharing&#34;&gt;‚ñ∂Ô∏è Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1LyXu6CjuymQg6ddHX8g1dpUvrMa1nn4L?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1gsv4LpY7C32otl1rgRo5wXTk4HIitXoM?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1VtULwRQwhEnVdNryjm27zXfdSM1tNfFK?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;seconds&lt;/td&gt; &#xA;    &lt;td&gt;1599&lt;/td&gt; &#xA;    &lt;td&gt;1468&lt;/td&gt; &#xA;    &lt;td&gt;942&lt;/td&gt; &#xA;    &lt;td&gt;894&lt;/td&gt; &#xA;    &lt;td&gt;545&lt;/td&gt; &#xA;    &lt;td&gt;193&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;memory MB&lt;/td&gt; &#xA;    &lt;td&gt;7199&lt;/td&gt; &#xA;    &lt;td&gt;7059&lt;/td&gt; &#xA;    &lt;td&gt;6459&lt;/td&gt; &#xA;    &lt;td&gt;5443&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;% saved&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;1.94&lt;/td&gt; &#xA;    &lt;td&gt;10.28&lt;/td&gt; &#xA;    &lt;td&gt;24.39&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h3&gt;2 Tesla T4s via DDP&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;2 T4 DDP&lt;/th&gt; &#xA;    &lt;th&gt;Hugging Face&lt;/th&gt; &#xA;    &lt;th&gt;Flash Attention&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Open&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Equal&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Pro&lt;/th&gt; &#xA;    &lt;th&gt;Unsloth Max&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Alpaca&lt;/td&gt; &#xA;    &lt;td&gt;1x&lt;/td&gt; &#xA;    &lt;td&gt;0.99x&lt;/td&gt; &#xA;    &lt;td&gt;4.95x&lt;/td&gt; &#xA;    &lt;td&gt;4.44x&lt;/td&gt; &#xA;    &lt;td&gt;7.28x&lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;20.61x&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;code&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/danielhanchen/hf-original-alpaca-t4-ddp&#34;&gt;‚ñ∂Ô∏è Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/danielhanchen/hf-sdpa-alpaca-t4-ddp&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/danielhanchen/unsloth-alpaca-t4-ddp&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;seconds&lt;/td&gt; &#xA;    &lt;td&gt;9882&lt;/td&gt; &#xA;    &lt;td&gt;9946&lt;/td&gt; &#xA;    &lt;td&gt;1996&lt;/td&gt; &#xA;    &lt;td&gt;2227&lt;/td&gt; &#xA;    &lt;td&gt;1357&lt;/td&gt; &#xA;    &lt;td&gt;480&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;memory MB&lt;/td&gt; &#xA;    &lt;td&gt;9176&lt;/td&gt; &#xA;    &lt;td&gt;9128&lt;/td&gt; &#xA;    &lt;td&gt;6904&lt;/td&gt; &#xA;    &lt;td&gt;6782&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;% saved&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;0.52&lt;/td&gt; &#xA;    &lt;td&gt;24.76&lt;/td&gt; &#xA;    &lt;td&gt;26.09&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Performance comparisons on 1 Tesla T4 GPU:&lt;/h3&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Click for Time taken for 1 epoch&lt;/summary&gt; &#xA; &lt;p&gt;One Tesla T4 on Google Colab &lt;code&gt;bsz = 2, ga = 4, max_grad_norm = 0.3, num_train_epochs = 1, seed = 3047, lr = 2e-4, wd = 0.01, optim = &#34;adamw_8bit&#34;, schedule = &#34;linear&#34;, schedule_steps = 10&lt;/code&gt;&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;System&lt;/th&gt; &#xA;    &lt;th&gt;GPU&lt;/th&gt; &#xA;    &lt;th&gt;Alpaca (52K)&lt;/th&gt; &#xA;    &lt;th&gt;LAION OIG (210K)&lt;/th&gt; &#xA;    &lt;th&gt;Open Assistant (10K)&lt;/th&gt; &#xA;    &lt;th&gt;SlimOrca (518K)&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Huggingface&lt;/td&gt; &#xA;    &lt;td&gt;1 T4&lt;/td&gt; &#xA;    &lt;td&gt;23h 15m&lt;/td&gt; &#xA;    &lt;td&gt;56h 28m&lt;/td&gt; &#xA;    &lt;td&gt;8h 38m&lt;/td&gt; &#xA;    &lt;td&gt;391h 41m&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Unsloth Open&lt;/td&gt; &#xA;    &lt;td&gt;1 T4&lt;/td&gt; &#xA;    &lt;td&gt;13h 7m (1.8x)&lt;/td&gt; &#xA;    &lt;td&gt;31h 47m (1.8x)&lt;/td&gt; &#xA;    &lt;td&gt;4h 27m (1.9x)&lt;/td&gt; &#xA;    &lt;td&gt;240h 4m (1.6x)&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Unsloth Pro&lt;/td&gt; &#xA;    &lt;td&gt;1 T4&lt;/td&gt; &#xA;    &lt;td&gt;3h 6m (7.5x)&lt;/td&gt; &#xA;    &lt;td&gt;5h 17m (10.7x)&lt;/td&gt; &#xA;    &lt;td&gt;1h 7m (7.7x)&lt;/td&gt; &#xA;    &lt;td&gt;59h 53m (6.5x)&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Unsloth Max&lt;/td&gt; &#xA;    &lt;td&gt;1 T4&lt;/td&gt; &#xA;    &lt;td&gt;2h 39m (8.8x)&lt;/td&gt; &#xA;    &lt;td&gt;4h 31m (12.5x)&lt;/td&gt; &#xA;    &lt;td&gt;0h 58m (8.9x)&lt;/td&gt; &#xA;    &lt;td&gt;51h 30m (7.6x)&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;p&gt;&lt;strong&gt;Peak Memory Usage&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;System&lt;/th&gt; &#xA;    &lt;th&gt;GPU&lt;/th&gt; &#xA;    &lt;th&gt;Alpaca (52K)&lt;/th&gt; &#xA;    &lt;th&gt;LAION OIG (210K)&lt;/th&gt; &#xA;    &lt;th&gt;Open Assistant (10K)&lt;/th&gt; &#xA;    &lt;th&gt;SlimOrca (518K)&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Huggingface&lt;/td&gt; &#xA;    &lt;td&gt;1 T4&lt;/td&gt; &#xA;    &lt;td&gt;7.3GB&lt;/td&gt; &#xA;    &lt;td&gt;5.9GB&lt;/td&gt; &#xA;    &lt;td&gt;14.0GB&lt;/td&gt; &#xA;    &lt;td&gt;13.3GB&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Unsloth Open&lt;/td&gt; &#xA;    &lt;td&gt;1 T4&lt;/td&gt; &#xA;    &lt;td&gt;6.8GB&lt;/td&gt; &#xA;    &lt;td&gt;5.7GB&lt;/td&gt; &#xA;    &lt;td&gt;7.8GB&lt;/td&gt; &#xA;    &lt;td&gt;7.7GB&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Unsloth Pro&lt;/td&gt; &#xA;    &lt;td&gt;1 T4&lt;/td&gt; &#xA;    &lt;td&gt;6.4GB&lt;/td&gt; &#xA;    &lt;td&gt;6.4GB&lt;/td&gt; &#xA;    &lt;td&gt;6.4GB&lt;/td&gt; &#xA;    &lt;td&gt;6.4GB&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Unsloth Max&lt;/td&gt; &#xA;    &lt;td&gt;1 T4&lt;/td&gt; &#xA;    &lt;td&gt;11.4GB&lt;/td&gt; &#xA;    &lt;td&gt;12.4GB&lt;/td&gt; &#xA;    &lt;td&gt;11.9GB&lt;/td&gt; &#xA;    &lt;td&gt;14.4GB&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Click for Performance Comparisons on 2 Tesla T4 GPUs via DDP:&lt;/summary&gt; **Time taken for 1 epoch** &#xA; &lt;p&gt;Two Tesla T4s on Kaggle &lt;code&gt;bsz = 2, ga = 4, max_grad_norm = 0.3, num_train_epochs = 1, seed = 3047, lr = 2e-4, wd = 0.01, optim = &#34;adamw_8bit&#34;, schedule = &#34;linear&#34;, schedule_steps = 10&lt;/code&gt;&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;System&lt;/th&gt; &#xA;    &lt;th&gt;GPU&lt;/th&gt; &#xA;    &lt;th&gt;Alpaca (52K)&lt;/th&gt; &#xA;    &lt;th&gt;LAION OIG (210K)&lt;/th&gt; &#xA;    &lt;th&gt;Open Assistant (10K)&lt;/th&gt; &#xA;    &lt;th&gt;SlimOrca (518K) *&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Huggingface&lt;/td&gt; &#xA;    &lt;td&gt;2 T4&lt;/td&gt; &#xA;    &lt;td&gt;84h 47m&lt;/td&gt; &#xA;    &lt;td&gt;163h 48m&lt;/td&gt; &#xA;    &lt;td&gt;30h 51m&lt;/td&gt; &#xA;    &lt;td&gt;1301h 24m *&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Unsloth Pro&lt;/td&gt; &#xA;    &lt;td&gt;2 T4&lt;/td&gt; &#xA;    &lt;td&gt;3h 20m (25.4x)&lt;/td&gt; &#xA;    &lt;td&gt;5h 43m (28.7x)&lt;/td&gt; &#xA;    &lt;td&gt;1h 12m (25.7x)&lt;/td&gt; &#xA;    &lt;td&gt;71h 40m (18.1x) *&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Unsloth Max&lt;/td&gt; &#xA;    &lt;td&gt;2 T4&lt;/td&gt; &#xA;    &lt;td&gt;3h 4m (27.6x)&lt;/td&gt; &#xA;    &lt;td&gt;5h 14m (31.3x)&lt;/td&gt; &#xA;    &lt;td&gt;1h 6m (28.1x)&lt;/td&gt; &#xA;    &lt;td&gt;54h 20m (23.9x) *&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;p&gt;&lt;strong&gt;Peak Memory Usage on a Multi GPU System (2 GPUs)&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;System&lt;/th&gt; &#xA;    &lt;th&gt;GPU&lt;/th&gt; &#xA;    &lt;th&gt;Alpaca (52K)&lt;/th&gt; &#xA;    &lt;th&gt;LAION OIG (210K)&lt;/th&gt; &#xA;    &lt;th&gt;Open Assistant (10K)&lt;/th&gt; &#xA;    &lt;th&gt;SlimOrca (518K) *&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Huggingface&lt;/td&gt; &#xA;    &lt;td&gt;2 T4&lt;/td&gt; &#xA;    &lt;td&gt;8.4GB | 6GB&lt;/td&gt; &#xA;    &lt;td&gt;7.2GB | 5.3GB&lt;/td&gt; &#xA;    &lt;td&gt;14.3GB | 6.6GB&lt;/td&gt; &#xA;    &lt;td&gt;10.9GB | 5.9GB *&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Unsloth Pro&lt;/td&gt; &#xA;    &lt;td&gt;2 T4&lt;/td&gt; &#xA;    &lt;td&gt;7.7GB | 4.9GB&lt;/td&gt; &#xA;    &lt;td&gt;7.5GB | 4.9GB&lt;/td&gt; &#xA;    &lt;td&gt;8.5GB | 4.9GB&lt;/td&gt; &#xA;    &lt;td&gt;6.2GB | 4.7GB *&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Unsloth Max&lt;/td&gt; &#xA;    &lt;td&gt;2 T4&lt;/td&gt; &#xA;    &lt;td&gt;10.5GB | 5GB&lt;/td&gt; &#xA;    &lt;td&gt;10.6GB | 5GB&lt;/td&gt; &#xA;    &lt;td&gt;10.6GB | 5GB&lt;/td&gt; &#xA;    &lt;td&gt;10.5GB | 5GB *&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Slim Orca &lt;code&gt;bsz=1&lt;/code&gt; for all benchmarks since &lt;code&gt;bsz=2&lt;/code&gt; OOMs. We can handle &lt;code&gt;bsz=2&lt;/code&gt;, but we benchmark it with &lt;code&gt;bsz=1&lt;/code&gt; for consistency.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.ibb.co/sJ7RhGG/image-41.png&#34; alt=&#34;&#34;&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Thank You to&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/HuyNguyen-hust&#34;&gt;HuyNguyen-hust&lt;/a&gt; for making &lt;a href=&#34;https://github.com/unslothai/unsloth/pull/238&#34;&gt;RoPE Embeddings 28% faster&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/RandomInternetPreson&#34;&gt;RandomInternetPreson&lt;/a&gt; for confirming WSL support&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/152334H&#34;&gt;152334H&lt;/a&gt; for experimental DPO support&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/atgctg&#34;&gt;atgctg&lt;/a&gt; for syntax highlighting&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>PKU-YuanGroup/Open-Sora-Plan</title>
    <updated>2024-05-01T01:48:43Z</updated>
    <id>tag:github.com,2024-05-01:/PKU-YuanGroup/Open-Sora-Plan</id>
    <link href="https://github.com/PKU-YuanGroup/Open-Sora-Plan" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This project aim to reproduce Sora (Open AI T2V model), we wish the open source community contribute to this project.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Open-Sora Plan&lt;/h1&gt; &#xA;&lt;!--&#xA;[[Project Page]](https://pku-yuangroup.github.io/Open-Sora-Plan/) [[‰∏≠Êñá‰∏ªÈ°µ]](https://pku-yuangroup.github.io/Open-Sora-Plan/blog_cn.html)&#xA;--&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/vqGmpjkSaz&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Discord-join-blueviolet?logo=discord&amp;amp;amp&#34; alt=&#34;slack badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/issues/53#issuecomment-1987226516&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%E5%BE%AE%E4%BF%A1-%E5%8A%A0%E5%85%A5-green?logo=wechat&amp;amp;amp&#34; alt=&#34;WeChat badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://x.com/LinBin46984/status/1763476690385424554?s=20&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Twitter@LinBin46984-black?logo=twitter&amp;amp;logoColor=1D9BF0&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://huggingface.co/spaces/LanguageBind/Open-Sora-Plan-v1.0.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97-Open%20In%20Spaces-blue.svg?sanitize=true&#34; alt=&#34;hf_space&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/fffiloni/Open-Sora-Plan-v1-0-0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97-Open%20In%20Spaces-blue.svg?sanitize=true&#34; alt=&#34;hf_space&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://replicate.com/camenduru/open-sora-plan-512x512&#34;&gt;&lt;img src=&#34;https://replicate.com/camenduru/open-sora-plan-512x512/badge&#34; alt=&#34;Replicate demo and cloud API&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/camenduru/Open-Sora-Plan-jupyter/blob/main/Open_Sora_Plan_jupyter.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-yellow&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors-anon/PKU-YuanGroup/Open-Sora-Plan?style=flat&amp;amp;label=Contributors&#34; alt=&#34;GitHub repo contributors&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/commits/main/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/commit-activity/m/PKU-YuanGroup/Open-Sora-Plan?label=Commit&#34; alt=&#34;GitHub Commit&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-pr-closed-raw/PKU-YuanGroup/Open-Sora-Plan.svg?label=Merged+PRs&amp;amp;color=green&#34; alt=&#34;Pr&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PKU-YuanGroup/Video-LLaVA/issues?q=is%3Aopen+is%3Aissue&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/PKU-YuanGroup/Open-Sora-Plan?color=critical&amp;amp;label=Issues&#34; alt=&#34;GitHub issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PKU-YuanGroup/Video-LLaVA/issues?q=is%3Aissue+is%3Aclosed&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-closed/PKU-YuanGroup/Open-Sora-Plan?color=success&amp;amp;label=Issues&#34; alt=&#34;GitHub closed issues&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/PKU-YuanGroup/Open-Sora-Plan?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Stars&#34; alt=&#34;GitHub repo stars&#34;&gt;&lt;/a&gt;&amp;nbsp; &lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/network&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/PKU-YuanGroup/Open-Sora-Plan?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Forks&#34; alt=&#34;GitHub repo forks&#34;&gt;&lt;/a&gt;&amp;nbsp; &lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/watchers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/watchers/PKU-YuanGroup/Open-Sora-Plan?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Watchers&#34; alt=&#34;GitHub repo watchers&#34;&gt;&lt;/a&gt;&amp;nbsp; &lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/archive/refs/heads/main.zip&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/repo-size/PKU-YuanGroup/Open-Sora-Plan?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Repo%20Size&#34; alt=&#34;GitHub repo size&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;We are thrilled to present &lt;strong&gt;Open-Sora-Plan v1.0.0&lt;/strong&gt;, which significantly enhances video generation quality and text control capabilities. See our &lt;a href=&#34;https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/docs/Report-v1.0.0.md&#34;&gt;report&lt;/a&gt;. We are training for higher resolution (&amp;gt;1024) as well as longer duration (&amp;gt;10s) videos, here is a preview of the next release. We show compressed .gif on GitHub, which loses some quality.&lt;/p&gt; &#xA;&lt;p&gt;Thanks to &lt;strong&gt;HUAWEI Ascend NPU Team&lt;/strong&gt; for supporting us.&lt;/p&gt; &#xA;&lt;p&gt;ÁõÆÂâçÂ∑≤ÊîØÊåÅÂõΩ‰∫ßAIËäØÁâá(Âçé‰∏∫ÊòáËÖæÔºåÊúüÂæÖÊõ¥Â§öÂõΩ‰∫ßÁÆóÂäõËäØÁâá)ËøõË°åÊé®ÁêÜÔºå‰∏ã‰∏ÄÊ≠•Â∞ÜÊîØÊåÅÂõΩ‰∫ßÁÆóÂäõËÆ≠ÁªÉÔºåÂÖ∑‰ΩìÂèØÂèÇËÄÉÊòáËÖæÂàÜÊîØ&lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/tree/hw&#34;&gt;hw branch&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;257√ó512√ó512 (10s)&lt;/th&gt; &#xA;   &lt;th&gt;65√ó1024√ó1024 (2.7s)&lt;/th&gt; &#xA;   &lt;th&gt;65√ó1024√ó1024 (2.7s)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/assets/88202804/37c29fcb-47ba-4c6e-9ce8-612f0eab6634&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/assets/88202804/6362c3ad-b1c4-4c36-8737-ad8a1e1dbed4&#34; width=&#34;448&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/assets/88202804/d90dd228-611b-44b7-93f4-fa99e224bd11&#34; width=&#34;448&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Time-lapse of a coastal landscape transitioning from sunrise to nightfall...&lt;/td&gt; &#xA;   &lt;td&gt;A quiet beach at dawn, the waves gently lapping at the shore and the sky painted in pastel hues....&lt;/td&gt; &#xA;   &lt;td&gt;Sunset over the sea.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;65√ó512√ó512 (2.7s)&lt;/th&gt; &#xA;   &lt;th&gt;65√ó512√ó512 (2.7s)&lt;/th&gt; &#xA;   &lt;th&gt;65√ó512√ó512 (2.7s)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/assets/88202804/deca421b-dbc5-4d16-a80b-89c1d8b4fce7&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/assets/88202804/7cddd996-7c17-4d8e-a47d-e57c0930a91d&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/assets/88202804/029ed424-e977-470b-a39d-ebc2d3e61c1c&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;A serene underwater scene featuring a sea turtle swimming...&lt;/td&gt; &#xA;   &lt;td&gt;Yellow and black tropical fish dart through the sea.&lt;/td&gt; &#xA;   &lt;td&gt;a dynamic interaction between the ocean and a large rock...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/assets/88202804/900e7293-9c7c-4844-b7e7-c0b0b9f7e055&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/assets/88202804/a710d498-5f43-4553-be12-e80f9d5b442e&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/assets/88202804/1d350503-98f6-4e88-8802-2dd915357726&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;The dynamic movement of tall, wispy grasses swaying in the wind...&lt;/td&gt; &#xA;   &lt;td&gt;Slow pan upward of blazing oak fire in an indoor fireplace.&lt;/td&gt; &#xA;   &lt;td&gt;A serene waterfall cascading down moss-covered rocks...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;üí™ Goal&lt;/h2&gt; &#xA;&lt;p&gt;This project aims to create a simple and scalable repo, to reproduce &lt;a href=&#34;https://openai.com/sora&#34;&gt;Sora&lt;/a&gt; (OpenAI, but we prefer to call it &#34;ClosedAI&#34; ). We wish the open-source community can contribute to this project. Pull requests are welcome!!!&lt;/p&gt; &#xA;&lt;p&gt;Êú¨È°πÁõÆÂ∏åÊúõÈÄöËøáÂºÄÊ∫êÁ§æÂå∫ÁöÑÂäõÈáèÂ§çÁé∞SoraÔºåÁî±ÂåóÂ§ß-ÂÖîÂ±ïAIGCËÅîÂêàÂÆûÈ™åÂÆ§ÂÖ±ÂêåÂèëËµ∑ÔºåÂΩìÂâçÁâàÊú¨Á¶ªÁõÆÊ†áÂ∑ÆË∑ù‰ªçÁÑ∂ËæÉÂ§ßÔºå‰ªçÈúÄÊåÅÁª≠ÂÆåÂñÑÂíåÂø´ÈÄüËø≠‰ª£ÔºåÊ¨¢ËøéPull requestÔºÅÔºÅÔºÅ&lt;/p&gt; &#xA;&lt;p&gt;Project stages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Primary&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Setup the codebase and train an un-conditional model on a landscape dataset.&lt;/li&gt; &#xA; &lt;li&gt;Train models that boost resolution and duration.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Extensions&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Conduct text2video experiments on landscape dataset.&lt;/li&gt; &#xA; &lt;li&gt;Train the 1080p model on video2text dataset.&lt;/li&gt; &#xA; &lt;li&gt;Control model with more conditions.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;div style=&#34;display: flex; justify-content: center;&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/assets/88202804/6b3095e9-88e8-4481-9b1b-ff9aaa25caf1&#34; width=&#34;200&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/assets/88202804/f0a2ebca-6d25-4f94-be29-bd0a29cd9230&#34; width=&#34;600&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;üì∞ News&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;[2024.04.09]&lt;/strong&gt; üöÄ Excited to share our latest exploration on metamorphic time-lapse video generation: &lt;a href=&#34;https://github.com/PKU-YuanGroup/MagicTime&#34;&gt;MagicTime&lt;/a&gt;, which learns real-world physics knowledge from time-lapse videos. Here is the dataset for train (updating): &lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Dataset&#34;&gt;Open-Sora-Dataset&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;[2024.04.07]&lt;/strong&gt; üî•üî•üî• Today, we are thrilled to present Open-Sora-Plan v1.0.0, which significantly enhances video generation quality and text control capabilities. See our &lt;a href=&#34;https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/docs/Report-v1.0.0.md&#34;&gt;report&lt;/a&gt;. Thanks to HUAWEI NPU for supporting us.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;[2024.03.27]&lt;/strong&gt; üöÄüöÄüöÄ We release the report of &lt;a href=&#34;https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/docs/CausalVideoVAE.md&#34;&gt;VideoCausalVAE&lt;/a&gt;, which supports both images and videos. We present our reconstructed video in this demonstration as follows. The text-to-video model is on the way.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;[2024.03.10]&lt;/strong&gt; üöÄüöÄüöÄ This repo supports training a latent size of 225√ó90√ó90 (t√óh√ów), which means we are able to &lt;strong&gt;train 1 minute of 1080P video with 30FPS&lt;/strong&gt; (2√ó interpolated frames and 2√ó super resolution) under class-condition.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;[2024.03.08]&lt;/strong&gt; We support the training code of text condition with 16 frames of 512x512. The code is mainly borrowed from &lt;a href=&#34;https://github.com/Vchitect/Latte&#34;&gt;Latte&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;[2024.03.07]&lt;/strong&gt; We support training with 128 frames (when sample rate = 3, which is about 13 seconds) of 256x256, or 64 frames (which is about 6 seconds) of 512x512.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;[2024.03.05]&lt;/strong&gt; See our latest &lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan?tab=readme-ov-file#todo&#34;&gt;todo&lt;/a&gt;, pull requests are welcome.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;[2024.03.04]&lt;/strong&gt; We re-organize and modulize our code to make it easy to &lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan?tab=readme-ov-file#how-to-contribute-to-the-open-sora-plan-community&#34;&gt;contribute&lt;/a&gt; to the project, to contribute please see the &lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan?tab=readme-ov-file#repo-structure&#34;&gt;Repo structure&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;[2024.03.03]&lt;/strong&gt; We open some &lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/discussions&#34;&gt;discussions&lt;/a&gt; to clarify several issues.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;[2024.03.01]&lt;/strong&gt; Training code is available now! Learn more on our &lt;a href=&#34;https://pku-yuangroup.github.io/Open-Sora-Plan/&#34;&gt;project page&lt;/a&gt;. Please feel free to watch üëÄ this repository for the latest updates.&lt;/p&gt; &#xA;&lt;h2&gt;‚úä Todo&lt;/h2&gt; &#xA;&lt;h4&gt;Setup the codebase and train an unconditional model on landscape dataset&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Fix typos &amp;amp; Update readme. ü§ù Thanks to &lt;a href=&#34;https://github.com/mio2333&#34;&gt;@mio2333&lt;/a&gt;, &lt;a href=&#34;https://github.com/CreamyLong&#34;&gt;@CreamyLong&lt;/a&gt;, &lt;a href=&#34;https://github.com/chg0901&#34;&gt;@chg0901&lt;/a&gt;, &lt;a href=&#34;https://github.com/Nyx-177&#34;&gt;@Nyx-177&lt;/a&gt;, &lt;a href=&#34;https://github.com/HowardLi1984&#34;&gt;@HowardLi1984&lt;/a&gt;, &lt;a href=&#34;https://github.com/sennnnn&#34;&gt;@sennnnn&lt;/a&gt;, &lt;a href=&#34;https://github.com/Jason-fan20&#34;&gt;@Jason-fan20&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Setup environment. ü§ù Thanks to &lt;a href=&#34;https://github.com/nameless1117&#34;&gt;@nameless1117&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add docker file. ‚åõ [WIP] ü§ù Thanks to &lt;a href=&#34;https://github.com/Mon-ius&#34;&gt;@Mon-ius&lt;/a&gt;, &lt;a href=&#34;https://github.com/SimonLeeGit&#34;&gt;@SimonLeeGit&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Enable type hints for functions. ü§ù Thanks to &lt;a href=&#34;https://github.com/RuslanPeresy&#34;&gt;@RuslanPeresy&lt;/a&gt;, üôè &lt;strong&gt;[Need your contribution]&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Resume from checkpoint.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add Video-VQVAE model, which is borrowed from &lt;a href=&#34;https://github.com/wilson1yan/VideoGPT&#34;&gt;VideoGPT&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Support variable aspect ratios, resolutions, durations training on &lt;a href=&#34;https://github.com/facebookresearch/DiT&#34;&gt;DiT&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Support Dynamic mask input inspired by &lt;a href=&#34;https://github.com/whlzy/FiT&#34;&gt;FiT&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add class-conditioning on embeddings.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Incorporating &lt;a href=&#34;https://github.com/Vchitect/Latte&#34;&gt;Latte&lt;/a&gt; as main codebase.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add VAE model, which is borrowed from &lt;a href=&#34;https://github.com/CompVis/latent-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Joint dynamic mask input with VAE.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add VQVAE from &lt;a href=&#34;https://github.com/CompVis/taming-transformers&#34;&gt;VQGAN&lt;/a&gt;. üôè &lt;strong&gt;[Need your contribution]&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Make the codebase ready for the cluster training. Add SLURM scripts. üôè &lt;strong&gt;[Need your contribution]&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Refactor VideoGPT. ü§ù Thanks to &lt;a href=&#34;https://github.com/qqingzheng&#34;&gt;@qqingzheng&lt;/a&gt;, &lt;a href=&#34;https://github.com/luo3300612&#34;&gt;@luo3300612&lt;/a&gt;, &lt;a href=&#34;https://github.com/sennnnn&#34;&gt;@sennnnn&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add sampling script.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add DDP sampling script. ‚åõ [WIP]&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Use accelerate on multi-node. ü§ù Thanks to &lt;a href=&#34;https://github.com/sysuyy&#34;&gt;@sysuyy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Incorporate &lt;a href=&#34;https://github.com/willisma/SiT&#34;&gt;SiT&lt;/a&gt;. ü§ù Thanks to &lt;a href=&#34;https://github.com/khan-yin&#34;&gt;@khan-yin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add evaluation scripts (FVD, CLIP score). ü§ù Thanks to &lt;a href=&#34;https://github.com/rain305f&#34;&gt;@rain305f&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Train models that boost resolution and duration&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add &lt;a href=&#34;https://arxiv.org/abs/2306.15595&#34;&gt;PI&lt;/a&gt; to support out-of-domain size. ü§ù Thanks to &lt;a href=&#34;https://github.com/jpthu17&#34;&gt;@jpthu17&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add 2D RoPE to improve generalization ability as &lt;a href=&#34;https://github.com/whlzy/FiT&#34;&gt;FiT&lt;/a&gt;. ü§ù Thanks to &lt;a href=&#34;https://github.com/jpthu17&#34;&gt;@jpthu17&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Compress KV according to &lt;a href=&#34;https://pixart-alpha.github.io/PixArt-sigma-project&#34;&gt;PixArt-sigma&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Support deepspeed for videogpt training. ü§ù Thanks to &lt;a href=&#34;https://github.com/sennnnn&#34;&gt;@sennnnn&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Train a &lt;strong&gt;low dimension&lt;/strong&gt; Video-AE, whether it is VAE or VQVAE.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Extract offline feature.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Train with offline feature.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add frame interpolation model. ü§ù Thanks to &lt;a href=&#34;https://github.com/yunyangge&#34;&gt;@yunyangge&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add super resolution model. ü§ù Thanks to &lt;a href=&#34;https://github.com/Linzy19&#34;&gt;@Linzy19&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add accelerate to automatically manage training.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Joint training with images.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Implement &lt;a href=&#34;https://github.com/Anima-Lab/MaskDiT&#34;&gt;MaskDiT&lt;/a&gt; technique for fast training. üôè &lt;strong&gt;[Need your contribution]&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Incorporate &lt;a href=&#34;https://arxiv.org/abs/2307.06304&#34;&gt;NaViT&lt;/a&gt;. üôè &lt;strong&gt;[Need your contribution]&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add &lt;a href=&#34;https://github.com/arthur-qiu/FreeNoise-LaVie&#34;&gt;FreeNoise&lt;/a&gt; support for training-free longer video generation. üôè &lt;strong&gt;[Need your contribution]&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Conduct text2video experiments on landscape dataset.&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Load pretrained weights from &lt;a href=&#34;https://github.com/Vchitect/Latte&#34;&gt;Latte&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Implement &lt;a href=&#34;https://github.com/magic-research/piecewise-rectified-flow&#34;&gt;PeRFlow&lt;/a&gt; for improving the sampling process. üôè &lt;strong&gt;[Need your contribution]&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Finish data loading, pre-processing utils.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add T5 support.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add CLIP support. ü§ù Thanks to &lt;a href=&#34;https://github.com/Ytimed2020&#34;&gt;@Ytimed2020&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add text2image training script.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add prompt captioner. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Collect training data. &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Need video-text pairs with caption. üôè &lt;strong&gt;[Need your contribution]&lt;/strong&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Extract multi-frame descriptions by large image-language models. ü§ù Thanks to &lt;a href=&#34;https://github.com/HowardLi1984&#34;&gt;@HowardLi1984&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Extract video description by large video-language models. üôè &lt;strong&gt;[Need your contribution]&lt;/strong&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Integrate captions to get a dense caption by using a large language model, such as GPT-4. ü§ù Thanks to &lt;a href=&#34;https://github.com/HowardLi1984&#34;&gt;@HowardLi1984&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Train a captioner to refine captions. üöÄ &lt;strong&gt;[Require more computation]&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Train the 1080p model on video2text dataset&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Looking for a suitable dataset, welcome to discuss and recommend. üôè &lt;strong&gt;[Need your contribution]&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add synthetic video created by game engines or 3D representations. üôè &lt;strong&gt;[Need your contribution]&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Finish data loading, and pre-processing utils.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Support memory friendly training. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add flash-attention2 from pytorch.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add xformers. ü§ù Thanks to &lt;a href=&#34;https://github.com/jialin-zhao&#34;&gt;@jialin-zhao&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Support mixed precision training.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add gradient checkpoint.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Support for ReBased and Ring attention. ü§ù Thanks to &lt;a href=&#34;https://github.com/kabachuha&#34;&gt;@kabachuha&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Train using the deepspeed engine. ü§ù Thanks to &lt;a href=&#34;https://github.com/sennnnn&#34;&gt;@sennnnn&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Train with a text condition. Here we could conduct different experiments: üöÄ &lt;strong&gt;[Require more computation]&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Train with T5 conditioning.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Train with CLIP conditioning.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Train with CLIP + T5 conditioning (probably costly during training and experiments).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Control model with more condition&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Incorporating &lt;a href=&#34;https://github.com/lllyasviel/ControlNet&#34;&gt;ControlNet&lt;/a&gt;. ‚åõ [WIP] üôè &lt;strong&gt;[Need your contribution]&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìÇ Repo structure (WIP)&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;‚îú‚îÄ‚îÄ README.md&#xA;‚îú‚îÄ‚îÄ docs&#xA;‚îÇ   ‚îú‚îÄ‚îÄ Data.md                    -&amp;gt; Datasets description.&#xA;‚îÇ   ‚îú‚îÄ‚îÄ Contribution_Guidelines.md -&amp;gt; Contribution guidelines description.&#xA;‚îú‚îÄ‚îÄ scripts                        -&amp;gt; All scripts.&#xA;‚îú‚îÄ‚îÄ opensora&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ dataset&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ models&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ ae                     -&amp;gt; Compress videos to latents&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ imagebase&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ vae&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îî‚îÄ‚îÄ vqvae&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îî‚îÄ‚îÄ videobase&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp;     ‚îú‚îÄ‚îÄ vae&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp;     ‚îî‚îÄ‚îÄ vqvae&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ captioner&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ diffusion              -&amp;gt; Denoise latents&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ diffusion         &#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ dit&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ latte&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îî‚îÄ‚îÄ unet&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ frame_interpolation&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ super_resolution&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îî‚îÄ‚îÄ text_encoder&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ sample&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ train                      -&amp;gt; Training code&#xA;‚îÇ&amp;nbsp;&amp;nbsp; ‚îî‚îÄ‚îÄ utils&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üõ†Ô∏è Requirements and Installation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repository and navigate to Open-Sora-Plan folder&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/PKU-YuanGroup/Open-Sora-Plan&#xA;cd Open-Sora-Plan&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Install required packages&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda create -n opensora python=3.8 -y&#xA;conda activate opensora&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Install additional packages for training cases&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -e &#34;.[train]&#34;&#xA;pip install flash-attn --no-build-isolation&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Install optional requirements such as static type checking:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -e &#39;.[dev]&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üóùÔ∏è Usage&lt;/h2&gt; &#xA;&lt;h3&gt;ü§ó Demo&lt;/h3&gt; &#xA;&lt;h4&gt;Gradio Web UI &lt;a href=&#34;https://github.com/gradio-app/gradio&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/gradio-app/gradio&#34;&gt;&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;Highly recommend trying out our web demo by the following command. We also provide &lt;a href=&#34;https://huggingface.co/spaces/LanguageBind/Open-Sora-Plan-v1.0.0&#34;&gt;online demo&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/LanguageBind/Open-Sora-Plan-v1.0.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97-Open%20In%20Spaces-blue.svg?sanitize=true&#34; alt=&#34;hf_space&#34;&gt;&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/spaces/fffiloni/Open-Sora-Plan-v1-0-0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97-Open%20In%20Spaces-blue.svg?sanitize=true&#34; alt=&#34;hf_space&#34;&gt;&lt;/a&gt; in Huggingface Spaces.&lt;/p&gt; &#xA;&lt;p&gt;ü§ù Enjoying the &lt;a href=&#34;https://replicate.com/camenduru/open-sora-plan-512x512&#34;&gt;&lt;img src=&#34;https://replicate.com/camenduru/open-sora-plan-512x512/badge&#34; alt=&#34;Replicate demo and cloud API&#34;&gt;&lt;/a&gt; and &lt;a href=&#34;https://colab.research.google.com/github/camenduru/Open-Sora-Plan-jupyter/blob/main/Open_Sora_Plan_jupyter.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;, created by &lt;a href=&#34;https://github.com/camenduru&#34;&gt;@camenduru&lt;/a&gt;, who generously supports our research!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m opensora.serve.gradio_web_server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;CLI Inference&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sh scripts/text_condition/sample_video.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Datasets&lt;/h3&gt; &#xA;&lt;p&gt;Refer to &lt;a href=&#34;https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/docs/Data.md&#34;&gt;Data.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Evaluation&lt;/h3&gt; &#xA;&lt;p&gt;Refer to the document &lt;a href=&#34;https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/docs/EVAL.md&#34;&gt;EVAL.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Causal Video VAE&lt;/h3&gt; &#xA;&lt;h4&gt;Reconstructing&lt;/h4&gt; &#xA;&lt;p&gt;Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;python examples/rec_imvi_vae.py --video_path test_video.mp4 --rec_path output_video.mp4 --fps 24 --resolution 512 --crop_size 512 --num_frames 128 --sample_rate 1 --ae CausalVAEModel_4x8x8 --model_path pretrained_488_release --enable_tiling --enable_time_chunk&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Parameter explanation:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--enable_tiling&lt;/code&gt;: This parameter is a flag to enable a tiling conv.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;--enable_time_chunk&lt;/code&gt;: This parameter is a flag to enable a time chunking. This will block the video in the temporal dimension and reconstruct the long video. This is only an operation performed in the video space, not the latent space, and cannot be used for training.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Training and Eval&lt;/h4&gt; &#xA;&lt;p&gt;Please refer to the document &lt;a href=&#34;https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/docs/Train_And_Eval_CausalVideoVAE.md&#34;&gt;CausalVideoVAE&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;VideoGPT VQVAE&lt;/h3&gt; &#xA;&lt;p&gt;Please refer to the document &lt;a href=&#34;https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/docs/VQVAE.md&#34;&gt;VQVAE&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Video Diffusion Transformer&lt;/h3&gt; &#xA;&lt;h4&gt;Training&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;sh scripts/text_condition/train_videoae_17x256x256.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;sh scripts/text_condition/train_videoae_65x256x256.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;sh scripts/text_condition/train_videoae_65x512x512.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üöÄ Improved Training Performance&lt;/h2&gt; &#xA;&lt;p&gt;In comparison to the original implementation, we implement a selection of training speed acceleration and memory saving features including gradient checkpointing, mixed precision training, and pre-extracted features, xformers, deepspeed. Some data points using &lt;strong&gt;a batch size of 1 with a A100&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;h3&gt;64√ó32√ó32 (origin size: 256√ó256√ó256)&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;gradient checkpointing&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;mixed precision&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;xformers&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;feature pre-extraction&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;deepspeed config&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;compress kv&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;training speed&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;memory&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.64 steps/sec&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;43G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Zero2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.66 steps/sec&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Zero2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.66 steps/sec&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;15G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Zero2 offload&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.33 steps/sec&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Zero2 offload&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.31 steps/sec&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;128√ó64√ó64 (origin size: 512√ó512√ó512)&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;gradient checkpointing&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;mixed precision&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;xformers&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;feature pre-extraction&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;deepspeed config&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;compress kv&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;training speed&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;memory&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.08 steps/sec&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;77G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Zero2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.08 steps/sec&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;41G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Zero2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.09 steps/sec&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;36G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Zero2 offload&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.07 steps/sec&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;39G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Zero2 offload&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úî&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.07 steps/sec&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;üí° How to Contribute to the Open-Sora Plan Community&lt;/h2&gt; &#xA;&lt;p&gt;We greatly appreciate your contributions to the Open-Sora Plan open-source community and helping us make it even better than it is now!&lt;/p&gt; &#xA;&lt;p&gt;For more details, please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/docs/Contribution_Guidelines.md&#34;&gt;Contribution Guidelines&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üëç Acknowledgement&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Vchitect/Latte&#34;&gt;Latte&lt;/a&gt;: The &lt;strong&gt;main codebase&lt;/strong&gt; we built upon and it is an wonderful video generated model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/PixArt-alpha/PixArt-alpha&#34;&gt;PixArt-alpha&lt;/a&gt;: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/wilson1yan/VideoGPT&#34;&gt;VideoGPT&lt;/a&gt;: Video Generation using VQ-VAE and Transformers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/DiT&#34;&gt;DiT&lt;/a&gt;: Scalable Diffusion Models with Transformers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/whlzy/FiT&#34;&gt;FiT&lt;/a&gt;: Flexible Vision Transformer for Diffusion Model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.15595&#34;&gt;Positional Interpolation&lt;/a&gt;: Extending Context Window of Large Language Models via Positional Interpolation.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üîí License&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for details.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!--&#xA;## ‚ú® Star History&#xA;&#xA;[![Star History](https://api.star-history.com/svg?repos=PKU-YuanGroup/Open-Sora-Plan)](https://star-history.com/#PKU-YuanGroup/Open-Sora-Plan&amp;Date)&#xA;--&gt; &#xA;&lt;h2&gt;‚úèÔ∏è Citing&lt;/h2&gt; &#xA;&lt;h3&gt;BibTeX&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@software{pku_yuan_lab_and_tuzhan_ai_etc_2024_10948109,&#xA;  author       = {PKU-Yuan Lab and Tuzhan AI etc.},&#xA;  title        = {Open-Sora-Plan},&#xA;  month        = apr,&#xA;  year         = 2024,&#xA;  publisher    = {GitHub},&#xA;  doi          = {10.5281/zenodo.10948109},&#xA;  url          = {https://doi.org/10.5281/zenodo.10948109}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Latest DOI&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zenodo.org/records/10948109&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/DOI/10.5281/zenodo.10948109.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ü§ù Community contributors&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/PKU-YuanGroup/Open-Sora-Plan/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=PKU-YuanGroup/Open-Sora-Plan&#34;&gt; &lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Asabeneh/30-Days-Of-Python</title>
    <updated>2024-05-01T01:48:43Z</updated>
    <id>tag:github.com,2024-05-01:/Asabeneh/30-Days-Of-Python</id>
    <link href="https://github.com/Asabeneh/30-Days-Of-Python" rel="alternate"></link>
    <summary type="html">&lt;p&gt;30 days of Python programming challenge is a step-by-step guide to learn the Python programming language in 30 days. This challenge may take more than100 days, follow your own pace. These videos may help too: https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üêç 30 Days Of Python&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;# Day&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Topics&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;01&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/readme.md&#34;&gt;Introduction&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;02&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/02_Day_Variables_builtin_functions/02_variables_builtin_functions.md&#34;&gt;Variables, Built-in Functions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;03&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/03_Day_Operators/03_operators.md&#34;&gt;Operators&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;04&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/04_Day_Strings/04_strings.md&#34;&gt;Strings&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;05&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/05_Day_Lists/05_lists.md&#34;&gt;Lists&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;06&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/06_Day_Tuples/06_tuples.md&#34;&gt;Tuples&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;07&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/07_Day_Sets/07_sets.md&#34;&gt;Sets&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;08&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/08_Day_Dictionaries/08_dictionaries.md&#34;&gt;Dictionaries&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;09&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/09_Day_Conditionals/09_conditionals.md&#34;&gt;Conditionals&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/10_Day_Loops/10_loops.md&#34;&gt;Loops&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;11&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/11_Day_Functions/11_functions.md&#34;&gt;Functions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;12&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/12_Day_Modules/12_modules.md&#34;&gt;Modules&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;13&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/13_Day_List_comprehension/13_list_comprehension.md&#34;&gt;List Comprehension&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;14&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/14_Day_Higher_order_functions/14_higher_order_functions.md&#34;&gt;Higher Order Functions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;15&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/15_Day_Python_type_errors/15_python_type_errors.md&#34;&gt;Python Type Errors&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/16_Day_Python_date_time/16_python_datetime.md&#34;&gt;Python Date time&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;17&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/17_Day_Exception_handling/17_exception_handling.md&#34;&gt;Exception Handling&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;18&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/18_Day_Regular_expressions/18_regular_expressions.md&#34;&gt;Regular Expressions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;19&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/19_Day_File_handling/19_file_handling.md&#34;&gt;File Handling&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/20_Day_Python_package_manager/20_python_package_manager.md&#34;&gt;Python Package Manager&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;21&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/21_Day_Classes_and_objects/21_classes_and_objects.md&#34;&gt;Classes and Objects&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;22&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/22_Day_Web_scraping/22_web_scraping.md&#34;&gt;Web Scraping&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;23&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/23_Day_Virtual_environment/23_virtual_environment.md&#34;&gt;Virtual Environment&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;24&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/24_Day_Statistics/24_statistics.md&#34;&gt;Statistics&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;25&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/25_Day_Pandas/25_pandas.md&#34;&gt;Pandas&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;26&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/26_Day_Python_web/26_python_web.md&#34;&gt;Python web&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;27&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/27_Day_Python_with_mongodb/27_python_with_mongodb.md&#34;&gt;Python with MongoDB&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;28&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/28_Day_API/28_API.md&#34;&gt;API&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;29&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/29_Day_Building_API/29_building_API.md&#34;&gt;Building API&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;30&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/30_Day_Conclusions/30_conclusions.md&#34;&gt;Conclusions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;üß°üß°üß° HAPPY CODING üß°üß°üß°&lt;/p&gt; &#xA;&lt;div&gt; &#xA; &lt;small&gt;Support the &lt;strong&gt;author&lt;/strong&gt; to create more educational materials&lt;/small&gt; &#xA; &lt;br&gt; &#xA; &lt;a href=&#34;https://www.paypal.me/asabeneh&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/paypal_lg.png&#34; alt=&#34;Paypal Logo&#34; style=&#34;width:10%&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt; 30 Days Of Python: Day 1 - Introduction&lt;/h1&gt; &#xA; &lt;a class=&#34;header-badge&#34; target=&#34;_blank&#34; href=&#34;https://www.linkedin.com/in/asabeneh/&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&amp;amp;logo=linkedin&amp;amp;style=social&#34;&gt; &lt;/a&gt; &#xA; &lt;a class=&#34;header-badge&#34; target=&#34;_blank&#34; href=&#34;https://twitter.com/Asabeneh&#34;&gt; &lt;img alt=&#34;Twitter Follow&#34; src=&#34;https://img.shields.io/twitter/follow/asabeneh?style=social&#34;&gt; &lt;/a&gt; &#xA; &lt;p&gt;&lt;sub&gt;Author: &lt;a href=&#34;https://www.linkedin.com/in/asabeneh/&#34; target=&#34;_blank&#34;&gt;Asabeneh Yetayeh&lt;/a&gt;&lt;br&gt; &lt;small&gt; Second Edition: July, 2021&lt;/small&gt; &lt;/sub&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/02_Day_Variables_builtin_functions/02_variables_builtin_functions.md&#34;&gt;Day 2 &amp;gt;&amp;gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/30DaysOfPython_banner3@2x.png&#34; alt=&#34;30DaysOfPython&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#-30-days-of-python&#34;&gt;üêç 30 Days Of Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#-day-1&#34;&gt;üìò Day 1&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#welcome&#34;&gt;Welcome&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#why-python-&#34;&gt;Why Python ?&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#environment-setup&#34;&gt;Environment Setup&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#installing-python&#34;&gt;Installing Python&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-shell&#34;&gt;Python Shell&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#installing-visual-studio-code&#34;&gt;Installing Visual Studio Code&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#how-to-use-visual-studio-code&#34;&gt;How to use visual studio code&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#basic-python&#34;&gt;Basic Python&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-syntax&#34;&gt;Python Syntax&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-indentation&#34;&gt;Python Indentation&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#comments&#34;&gt;Comments&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#data-types&#34;&gt;Data types&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#number&#34;&gt;Number&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#string&#34;&gt;String&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#booleans&#34;&gt;Booleans&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#list&#34;&gt;List&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#dictionary&#34;&gt;Dictionary&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#tuple&#34;&gt;Tuple&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#set&#34;&gt;Set&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#checking-data-types&#34;&gt;Checking Data types&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-file&#34;&gt;Python File&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#-exercises---day-1&#34;&gt;üíª Exercises - Day 1&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#exercise-level-1&#34;&gt;Exercise: Level 1&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#exercise-level-2&#34;&gt;Exercise: Level 2&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#exercise-level-3&#34;&gt;Exercise: Level 3&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;üìò Day 1&lt;/h1&gt; &#xA;&lt;h2&gt;Welcome&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Congratulations&lt;/strong&gt; for deciding to participate in a &lt;em&gt;30 days of Python&lt;/em&gt; programming challenge . In this challenge you will learn everything you need to be a python programmer and the whole concept of programming. In the end of the challenge you will get a &lt;em&gt;30DaysOfPython&lt;/em&gt; programming challenge certificate.&lt;/p&gt; &#xA;&lt;p&gt;If you would like to actively engage in the challenge, you may join the &lt;a href=&#34;https://t.me/ThirtyDaysOfPython&#34;&gt;30DaysOfPython challenge&lt;/a&gt; telegram group.&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;Python is a high-level programming language for general-purpose programming. It is an open source, interpreted, objected-oriented programming language. Python was created by a Dutch programmer, Guido van Rossum. The name of Python programming language was derived from a British sketch comedy series, &lt;em&gt;Monty Python&#39;s Flying Circus&lt;/em&gt;. The first version was released on February 20, 1991. This 30 days of Python challenge will help you learn the latest version of Python, Python 3 step by step. The topics are broken down into 30 days, where each day contains several topics with easy-to-understand explanations, real-world examples, many hands on exercises and projects.&lt;/p&gt; &#xA;&lt;p&gt;This challenge is designed for beginners and professionals who want to learn python programming language. It may take 30 to 100 days to complete the challenge, people who actively participate on the telegram group have a high probability of completing the challenge.&lt;/p&gt; &#xA;&lt;p&gt;This challenge is easy to read, written in conversational English, engaging, motivating and at the same time, it is very demanding. You need to allocate much time to finish this challenge. If you are a visual learner, you may get the video lesson on &lt;a href=&#34;https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw&#34;&gt; Washera&lt;/a&gt; YouTube channel. You may start from &lt;a href=&#34;https://youtu.be/OCCWZheOesI&#34;&gt;Python for Absolute Beginners video&lt;/a&gt;. Subscribe the channel, comment and ask questions on YouTube vidoes and be proactive, the author will eventually notice you.&lt;/p&gt; &#xA;&lt;p&gt;The author likes to hear your opinion about the challenge, share the author by expressing your thoughts about the 30DaysOfPython challenge. You can leave your testimonial on this &lt;a href=&#34;https://testimonial-vdzd.onrender.com/&#34;&gt;link&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Why Python ?&lt;/h2&gt; &#xA;&lt;p&gt;It is a programming language which is very close to human language and because of that it is easy to learn and use. Python is used by various industries and companies (including Google). It has been used to develop web applications, desktop applications, system adminstration, and machine learning libraries. Python is highly embraced language in the data science and machine learning community. I hope this is enough to convince you to start learning Python. Python is eating the world and you are killing it before it eats you.&lt;/p&gt; &#xA;&lt;h2&gt;Environment Setup&lt;/h2&gt; &#xA;&lt;h3&gt;Installing Python&lt;/h3&gt; &#xA;&lt;p&gt;To run a python script you need to install python. Let&#39;s &lt;a href=&#34;https://www.python.org/&#34;&gt;download&lt;/a&gt; python. If your are a windows user. Click the button encircled in red.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.python.org/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/installing_on_windows.png&#34; alt=&#34;installing on Windows&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you are a macOS user. Click the button encircled in red.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.python.org/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/installing_on_macOS.png&#34; alt=&#34;installing on Windows&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;To check if python is installed write the following command on your device terminal.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python --version&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/python_versio.png&#34; alt=&#34;Python Version&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;As you can see from the terminal, I am using &lt;em&gt;Python 3.7.5&lt;/em&gt; version at the moment. Your version of Python might be different from mine by but it should be 3.6 or above. If you mange to see the python version, well done. Python has been installed on your machine. Continue to the next section.&lt;/p&gt; &#xA;&lt;h3&gt;Python Shell&lt;/h3&gt; &#xA;&lt;p&gt;Python is an interpreted scripting language, so it does not need to be compiled. It means it executes the code line by line. Python comes with a &lt;em&gt;Python Shell (Python Interactive Shell)&lt;/em&gt;. It is used to execute a single python command and get the result.&lt;/p&gt; &#xA;&lt;p&gt;Python Shell waits for the Python code from the user. When you enter the code, it interprets the code and shows the result in the next line. Open your terminal or command prompt(cmd) and write:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/opening_python_shell.png&#34; alt=&#34;Python Scripting Shell&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The Python interactive shell is opened and it is waiting for you to write Python code(Python script). You will write your Python script next to this symbol &amp;gt;&amp;gt;&amp;gt; and then click Enter. Let us write our very first script on the Python scripting shell.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/adding_on_python_shell.png&#34; alt=&#34;Python script on Python shell&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Well done, you wrote your first Python script on Python interactive shell. How do we close the Python interactive shell ? To close the shell, next to this symbol &amp;gt;&amp;gt; write &lt;strong&gt;exit()&lt;/strong&gt; command and press Enter.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/exit_from_shell.png&#34; alt=&#34;Exit from python shell&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Now, you know how to open the Python interactive shell and how to exit from it.&lt;/p&gt; &#xA;&lt;p&gt;Python will give you results if you write scripts that Python understands, if not it returns errors. Let&#39;s make a deliberate mistake and see what Python will return.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/invalid_syntax_error.png&#34; alt=&#34;Invalid Syntax Error&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;As you can see from the returned error, Python is so clever that it knows the mistake we made and which was &lt;em&gt;Syntax Error: invalid syntax&lt;/em&gt;. Using x as multiplication in Python is a syntax error because (x) is not a valid syntax in Python. Instead of (&lt;strong&gt;x&lt;/strong&gt;) we use asterisk (*) for multiplication. The returned error clearly shows what to fix.&lt;/p&gt; &#xA;&lt;p&gt;The process of identifying and removing errors from a program is called &lt;em&gt;debugging&lt;/em&gt;. Let us debug it by putting * in place of &lt;strong&gt;x&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/fixing_syntax_error.png&#34; alt=&#34;Fixing Syntax Error&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Our bug was fixed, the code ran and we got a result we were expecting. As a programmer you will see such kind of errors on daily basis. It is good to know how to debug. To be good at debugging you should understand what kind of errors you are facing. Some of the Python errors you may encounter are &lt;em&gt;SyntaxError&lt;/em&gt;, &lt;em&gt;IndexError&lt;/em&gt;, &lt;em&gt;NameError&lt;/em&gt;, &lt;em&gt;ModuleNotFoundError&lt;/em&gt;, &lt;em&gt;KeyError&lt;/em&gt;, &lt;em&gt;ImportError&lt;/em&gt;, &lt;em&gt;AttributeError&lt;/em&gt;, &lt;em&gt;TypeError&lt;/em&gt;, &lt;em&gt;ValueError&lt;/em&gt;, &lt;em&gt;ZeroDivisionError&lt;/em&gt; etc. We will see more about different Python &lt;strong&gt;&lt;em&gt;error types&lt;/em&gt;&lt;/strong&gt; in later sections.&lt;/p&gt; &#xA;&lt;p&gt;Let us practice more how to use Python interactive shell. Go to your terminal or command prompt and write the word &lt;strong&gt;python&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/opening_python_shell.png&#34; alt=&#34;Python Scripting Shell&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The Python interactive shell is opened. Let us do some basic mathematical operations (addition, subtraction, multiplication, division, modulus, exponential).&lt;/p&gt; &#xA;&lt;p&gt;Let us do some maths first before we write any Python code:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2 + 3 is 5&lt;/li&gt; &#xA; &lt;li&gt;3 - 2 is 1&lt;/li&gt; &#xA; &lt;li&gt;3 * 2 is 6&lt;/li&gt; &#xA; &lt;li&gt;3 / 2 is 1.5&lt;/li&gt; &#xA; &lt;li&gt;3 ** 2 is the same as 3 * 3&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In python we have the following additional operations:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;3 % 2 = 1 =&amp;gt; which means finding the remainder&lt;/li&gt; &#xA; &lt;li&gt;3 // 2 = 1 =&amp;gt; which means removing the remainder&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Let us change the above mathematical expressions to Python code. The Python shell has been opened and let us write a comment at the very beginning of the shell.&lt;/p&gt; &#xA;&lt;p&gt;A &lt;em&gt;comment&lt;/em&gt; is a part of the code which is not executed by python. So we can leave some text in our code to make our code more readable. Python does not run the comment part. A comment in python starts with hash(#) symbol. This is how you write a comment in python&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt; # comment starts with hash&#xA; # this is a python comment, because it starts with a (#) symbol&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/maths_on_python_shell.png&#34; alt=&#34;Maths on python shell&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Before we move on to the next section, let us practice more on the Python interactive shell. Close the opened shell by writing &lt;em&gt;exit()&lt;/em&gt; on the shell and open it again and let us practice how to write text on the Python shell.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/writing_string_on_shell.png&#34; alt=&#34;Writing String on python shell&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Installing Visual Studio Code&lt;/h3&gt; &#xA;&lt;p&gt;The Python interactive shell is good to try and test small script codes but it will not be for a big project. In real work environment, developers use different code editors to write codes. In this 30 days of Python programming challenge we will use visual studio code. Visual studio code is a very popular open source text editor. I am a fan of vscode and I would recommend to &lt;a href=&#34;https://code.visualstudio.com/&#34;&gt;download&lt;/a&gt; visual studio code, but if you are in favor of other editors, feel free to follow with what you have.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://code.visualstudio.com/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/vscode.png&#34; alt=&#34;Visual Studio Code&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you installed visual studio code, let us see how to use it. If you prefer a video, you can follow this Visual Studio Code for Python &lt;a href=&#34;https://www.youtube.com/watch?v=bn7Cx4z-vSo&#34;&gt;Video tutorial&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;How to use visual studio code&lt;/h4&gt; &#xA;&lt;p&gt;Open the visual studio code by double clicking the visual studio icon. When you open it you will get this kind of interface. Try to interact with the labeled icons.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/vscode_ui.png&#34; alt=&#34;Visual studio Code&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Create a folder named 30DaysOfPython on your desktop. Then open it using visual studio code.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/how_to_open_project_on_vscode.png&#34; alt=&#34;Opening Project on Visual studio&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/opening_project.png&#34; alt=&#34;Opening a project&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;After opening it you will see shortcuts for creating files and folders inside of 30DaysOfPython project&#39;s directory. As you can see below, I have created the very first file, helloworld.py. You can do the same.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/helloworld.png&#34; alt=&#34;Creating a python file&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;After a long day of coding, you want to close your code editor, right? This is how you will close the opened project.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/closing_opened_project.png&#34; alt=&#34;Closing project&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Congratulations, you have finished setting up the development environment. Let us start coding.&lt;/p&gt; &#xA;&lt;h2&gt;Basic Python&lt;/h2&gt; &#xA;&lt;h3&gt;Python Syntax&lt;/h3&gt; &#xA;&lt;p&gt;A Python script can be written in Python interactive shell or in the code editor. A Python file has an extension .py.&lt;/p&gt; &#xA;&lt;h3&gt;Python Indentation&lt;/h3&gt; &#xA;&lt;p&gt;An indentation is a white space in a text. Indentation in many languages is used to increase code readability, however Python uses indentation to create block of codes. In other programming languages curly brackets are used to create blocks of codes instead of indentation. One of the common bugs when writing python code is wrong indentation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/indentation.png&#34; alt=&#34;Indentation Error&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Comments&lt;/h3&gt; &#xA;&lt;p&gt;Comments are very important to make the code more readable and to leave remarks in our code. Python does not run comment parts of our code. Any text starting with hash(#) in Python is a comment.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example: Single Line Comment&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;    # This is the first comment&#xA;    # This is the second comment&#xA;    # Python is eating the world&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example: Multiline Comment&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Triple quote can be used for multiline comment if it is not assigned to a variable&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&#34;&#34;&#34;This is multiline comment&#xA;multiline comment takes multiple lines.&#xA;python is eating the world&#xA;&#34;&#34;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Data types&lt;/h3&gt; &#xA;&lt;p&gt;In Python there are several types of data types. Let us get started with the most common ones. Different data types will be covered in detail in other sections. For the time being, let us just go through the different data types and get familiar with them. You do not have to have a clear understanding now.&lt;/p&gt; &#xA;&lt;h4&gt;Number&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Integer: Integer(negative, zero and positive) numbers Example: ... -3, -2, -1, 0, 1, 2, 3 ...&lt;/li&gt; &#xA; &lt;li&gt;Float: Decimal number Example ... -3.5, -2.25, -1.0, 0.0, 1.1, 2.2, 3.5 ...&lt;/li&gt; &#xA; &lt;li&gt;Complex Example 1 + j, 2 + 4j&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;String&lt;/h4&gt; &#xA;&lt;p&gt;A collection of one or more characters under a single or double quote. If a string is more than one sentence then we use a triple quote.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;&#39;Asabeneh&#39;&#xA;&#39;Finland&#39;&#xA;&#39;Python&#39;&#xA;&#39;I love teaching&#39;&#xA;&#39;I hope you are enjoying the first day of 30DaysOfPython Challenge&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Booleans&lt;/h4&gt; &#xA;&lt;p&gt;A boolean data type is either a True or False value. T and F should be always uppercase.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    True  #  Is the light on? If it is on, then the value is True&#xA;    False # Is the light on? If it is off, then the value is False&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;List&lt;/h4&gt; &#xA;&lt;p&gt;Python list is an ordered collection which allows to store different data type items. A list is similar to an array in JavaScript.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;[0, 1, 2, 3, 4, 5]  # all are the same data types - a list of numbers&#xA;[&#39;Banana&#39;, &#39;Orange&#39;, &#39;Mango&#39;, &#39;Avocado&#39;] # all the same data types - a list of strings (fruits)&#xA;[&#39;Finland&#39;,&#39;Estonia&#39;, &#39;Sweden&#39;,&#39;Norway&#39;] # all the same data types - a list of strings (countries)&#xA;[&#39;Banana&#39;, 10, False, 9.81] # different data types in the list - string, integer, boolean and float&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Dictionary&lt;/h4&gt; &#xA;&lt;p&gt;A Python dictionary object is an unordered collection of data in a key value pair format.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;{&#xA;&#39;first_name&#39;:&#39;Asabeneh&#39;,&#xA;&#39;last_name&#39;:&#39;Yetayeh&#39;,&#xA;&#39;country&#39;:&#39;Finland&#39;, &#xA;&#39;age&#39;:250, &#xA;&#39;is_married&#39;:True,&#xA;&#39;skills&#39;:[&#39;JS&#39;, &#39;React&#39;, &#39;Node&#39;, &#39;Python&#39;]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Tuple&lt;/h4&gt; &#xA;&lt;p&gt;A tuple is an ordered collection of different data types like list but tuples can not be modified once they are created. They are immutable.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;(&#39;Asabeneh&#39;, &#39;Pawel&#39;, &#39;Brook&#39;, &#39;Abraham&#39;, &#39;Lidiya&#39;) # Names&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;(&#39;Earth&#39;, &#39;Jupiter&#39;, &#39;Neptune&#39;, &#39;Mars&#39;, &#39;Venus&#39;, &#39;Saturn&#39;, &#39;Uranus&#39;, &#39;Mercury&#39;) # planets&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Set&lt;/h4&gt; &#xA;&lt;p&gt;A set is a collection of data types similar to list and tuple. Unlike list and tuple, set is not an ordered collection of items. Like in Mathematics, set in Python stores only unique items.&lt;/p&gt; &#xA;&lt;p&gt;In later sections, we will go in detail about each and every Python data type.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;{2, 4, 3, 5}&#xA;{3.14, 9.81, 2.7} # order is not important in set&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Checking Data types&lt;/h3&gt; &#xA;&lt;p&gt;To check the data type of certain data/variable we use the &lt;strong&gt;type&lt;/strong&gt; function. In the following terminal you will see different python data types:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/checking_data_types.png&#34; alt=&#34;Checking Data types&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Python File&lt;/h3&gt; &#xA;&lt;p&gt;First open your project folder, 30DaysOfPython. If you don&#39;t have this folder, create a folder name called 30DaysOfPython. Inside this folder, create a file called helloworld.py. Now, let&#39;s do what we did on python interactive shell using visual studio code.&lt;/p&gt; &#xA;&lt;p&gt;The Python interactive shell was printing without using &lt;strong&gt;print&lt;/strong&gt; but on visual studio code to see our result we should use a built in function _print(). The &lt;em&gt;print()&lt;/em&gt; built-in function takes one or more arguments as follows &lt;em&gt;print(&#39;arument1&#39;, &#39;argument2&#39;, &#39;argument3&#39;)&lt;/em&gt;. See the examples below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;The file name is helloworld.py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;# Day 1 - 30DaysOfPython Challenge&#xA;&#xA;print(2 + 3)             # addition(+)&#xA;print(3 - 1)             # subtraction(-)&#xA;print(2 * 3)             # multiplication(*)&#xA;print(3 / 2)             # division(/)&#xA;print(3 ** 2)            # exponential(**)&#xA;print(3 % 2)             # modulus(%)&#xA;print(3 // 2)            # Floor division operator(//)&#xA;&#xA;# Checking data types&#xA;print(type(10))          # Int&#xA;print(type(3.14))        # Float&#xA;print(type(1 + 3j))      # Complex number&#xA;print(type(&#39;Asabeneh&#39;))  # String&#xA;print(type([1, 2, 3]))   # List&#xA;print(type({&#39;name&#39;:&#39;Asabeneh&#39;})) # Dictionary&#xA;print(type({9.8, 3.14, 2.7}))    # Set&#xA;print(type((9.8, 3.14, 2.7)))    # Tuple&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run the python file check the image below. You can run the python file either by running the green button on Visual Studio Code or by typing &lt;em&gt;python helloworld.py&lt;/em&gt; in the terminal .&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/running_python_script.png&#34; alt=&#34;Running python script&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;üåï You are amazing. You have just completed day 1 challenge and you are on your way to greatness. Now do some exercises for your brain and muscles.&lt;/p&gt; &#xA;&lt;h2&gt;üíª Exercises - Day 1&lt;/h2&gt; &#xA;&lt;h3&gt;Exercise: Level 1&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Check the python version you are using&lt;/li&gt; &#xA; &lt;li&gt;Open the python interactive shell and do the following operations. The operands are 3 and 4. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;addition(+)&lt;/li&gt; &#xA;   &lt;li&gt;subtraction(-)&lt;/li&gt; &#xA;   &lt;li&gt;multiplication(*)&lt;/li&gt; &#xA;   &lt;li&gt;modulus(%)&lt;/li&gt; &#xA;   &lt;li&gt;division(/)&lt;/li&gt; &#xA;   &lt;li&gt;exponential(**)&lt;/li&gt; &#xA;   &lt;li&gt;floor division operator(//)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Write strings on the python interactive shell. The strings are the following: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Your name&lt;/li&gt; &#xA;   &lt;li&gt;Your family name&lt;/li&gt; &#xA;   &lt;li&gt;Your country&lt;/li&gt; &#xA;   &lt;li&gt;I am enjoying 30 days of python&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Check the data types of the following data: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;10&lt;/li&gt; &#xA;   &lt;li&gt;9.8&lt;/li&gt; &#xA;   &lt;li&gt;3.14&lt;/li&gt; &#xA;   &lt;li&gt;4 - 4j&lt;/li&gt; &#xA;   &lt;li&gt;[&#39;Asabeneh&#39;, &#39;Python&#39;, &#39;Finland&#39;]&lt;/li&gt; &#xA;   &lt;li&gt;Your name&lt;/li&gt; &#xA;   &lt;li&gt;Your family name&lt;/li&gt; &#xA;   &lt;li&gt;Your country&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Exercise: Level 2&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create a folder named day_1 inside 30DaysOfPython folder. Inside day_1 folder, create a python file helloworld.py and repeat questions 1, 2, 3 and 4. Remember to use &lt;em&gt;print()&lt;/em&gt; when you are working on a python file. Navigate to the directory where you have saved your file, and run it.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Exercise: Level 3&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Write an example for different Python data types such as Number(Integer, Float, Complex), String, Boolean, List, Tuple, Set and Dictionary.&lt;/li&gt; &#xA; &lt;li&gt;Find an &lt;a href=&#34;https://en.wikipedia.org/wiki/Euclidean_distance#:~:text=In%20mathematics%2C%20the%20Euclidean%20distance,being%20called%20the%20Pythagorean%20distance.&#34;&gt;Euclidian distance&lt;/a&gt; between (2, 3) and (10, 8)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;üéâ CONGRATULATIONS ! üéâ&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/02_Day_Variables_builtin_functions/02_variables_builtin_functions.md&#34;&gt;Day 2 &amp;gt;&amp;gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>