<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-01T02:31:58Z</updated>
  <subtitle>Monthly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>searxng/searxng</title>
    <updated>2022-08-01T02:31:58Z</updated>
    <id>tag:github.com,2022-08-01:/searxng/searxng</id>
    <link href="https://github.com/searxng/searxng" rel="alternate"></link>
    <summary type="html">&lt;p&gt;SearXNG is a free internet metasearch engine which aggregates results from various search services and databases. Users are neither tracked nor profiled.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. SPDX-License-Identifier: AGPL-3.0-or-later&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;.. figure:: &lt;a href=&#34;https://raw.githubusercontent.com/searxng/searxng/master/src/brand/searxng.svg&#34;&gt;https://raw.githubusercontent.com/searxng/searxng/master/src/brand/searxng.svg&lt;/a&gt; :target: &lt;a href=&#34;https://docs.searxng.org/&#34;&gt;https://docs.searxng.org/&lt;/a&gt; :alt: SearXNG :width: 100% :align: center&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Privacy-respecting, hackable &lt;code&gt;metasearch engine&lt;/code&gt;_&lt;/p&gt; &#xA;&lt;p&gt;If you are looking for running instances, ready to use, then visit searx.space_. Otherwise jump to the user_, admin_ and developer_ handbooks you will find on our homepage_.&lt;/p&gt; &#xA;&lt;p&gt;|SearXNG install| |SearXNG homepage| |SearXNG wiki| |AGPL License| |Issues| |commits| |weblate| |SearXNG logo|&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;.. _searx.space: &lt;a href=&#34;https://searx.space&#34;&gt;https://searx.space&lt;/a&gt; .. _user: &lt;a href=&#34;https://docs.searxng.org/user&#34;&gt;https://docs.searxng.org/user&lt;/a&gt; .. _admin: &lt;a href=&#34;https://docs.searxng.org/admin&#34;&gt;https://docs.searxng.org/admin&lt;/a&gt; .. _developer: &lt;a href=&#34;https://docs.searxng.org/dev&#34;&gt;https://docs.searxng.org/dev&lt;/a&gt; .. _homepage: &lt;a href=&#34;https://docs.searxng.org/&#34;&gt;https://docs.searxng.org/&lt;/a&gt; .. _metasearch engine: &lt;a href=&#34;https://en.wikipedia.org/wiki/Metasearch_engine&#34;&gt;https://en.wikipedia.org/wiki/Metasearch_engine&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. |SearXNG logo| image:: &lt;a href=&#34;https://raw.githubusercontent.com/searxng/searxng/master/src/brand/searxng-wordmark.svg&#34;&gt;https://raw.githubusercontent.com/searxng/searxng/master/src/brand/searxng-wordmark.svg&lt;/a&gt; :target: &lt;a href=&#34;https://docs.searxng.org/&#34;&gt;https://docs.searxng.org/&lt;/a&gt; :width: 5%&lt;/p&gt; &#xA;&lt;p&gt;.. |SearXNG install| image:: &lt;a href=&#34;https://img.shields.io/badge/-install-blue&#34;&gt;https://img.shields.io/badge/-install-blue&lt;/a&gt; :target: &lt;a href=&#34;https://docs.searxng.org/admin/installation.html&#34;&gt;https://docs.searxng.org/admin/installation.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. |SearXNG homepage| image:: &lt;a href=&#34;https://img.shields.io/badge/-homepage-blue&#34;&gt;https://img.shields.io/badge/-homepage-blue&lt;/a&gt; :target: &lt;a href=&#34;https://docs.searxng.org/&#34;&gt;https://docs.searxng.org/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. |SearXNG wiki| image:: &lt;a href=&#34;https://img.shields.io/badge/-wiki-blue&#34;&gt;https://img.shields.io/badge/-wiki-blue&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/searxng/searxng/wiki&#34;&gt;https://github.com/searxng/searxng/wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. |AGPL License| image:: &lt;a href=&#34;https://img.shields.io/badge/license-AGPL-blue.svg&#34;&gt;https://img.shields.io/badge/license-AGPL-blue.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/searxng/searxng/raw/master/LICENSE&#34;&gt;https://github.com/searxng/searxng/blob/master/LICENSE&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. |Issues| image:: &lt;a href=&#34;https://img.shields.io/github/issues/searxng/searxng?color=yellow&amp;amp;label=issues&#34;&gt;https://img.shields.io/github/issues/searxng/searxng?color=yellow&amp;amp;label=issues&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/searxng/searxng/issues&#34;&gt;https://github.com/searxng/searxng/issues&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. |PR| image:: &lt;a href=&#34;https://img.shields.io/github/issues-pr-raw/searxng/searxng?color=yellow&amp;amp;label=PR&#34;&gt;https://img.shields.io/github/issues-pr-raw/searxng/searxng?color=yellow&amp;amp;label=PR&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/searxng/searxng/pulls&#34;&gt;https://github.com/searxng/searxng/pulls&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. |commits| image:: &lt;a href=&#34;https://img.shields.io/github/commit-activity/y/searxng/searxng?color=yellow&amp;amp;label=commits&#34;&gt;https://img.shields.io/github/commit-activity/y/searxng/searxng?color=yellow&amp;amp;label=commits&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/searxng/searxng/commits/master&#34;&gt;https://github.com/searxng/searxng/commits/master&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. |weblate| image:: &lt;a href=&#34;https://weblate.bubu1.eu/widgets/searxng/-/searxng/svg-badge.svg&#34;&gt;https://weblate.bubu1.eu/widgets/searxng/-/searxng/svg-badge.svg&lt;/a&gt; :target: &lt;a href=&#34;https://weblate.bubu1.eu/projects/searxng/&#34;&gt;https://weblate.bubu1.eu/projects/searxng/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Contact&lt;/h1&gt; &#xA;&lt;p&gt;Come join us if you have questions or just want to chat about SearXNG.&lt;/p&gt; &#xA;&lt;p&gt;Matrix &lt;code&gt;#searxng:matrix.org &amp;lt;https://matrix.to/#/#searxng:matrix.org&amp;gt;&lt;/code&gt;_&lt;/p&gt; &#xA;&lt;p&gt;IRC &lt;code&gt;#searxng on libera.chat &amp;lt;https://web.libera.chat/?channel=#searxng&amp;gt;&lt;/code&gt;_ which is bridged to Matrix.&lt;/p&gt; &#xA;&lt;h1&gt;Differences to searx&lt;/h1&gt; &#xA;&lt;p&gt;SearXNG is a fork of &lt;code&gt;searx&lt;/code&gt;_. Here are some of the changes:&lt;/p&gt; &#xA;&lt;p&gt;.. _searx: &lt;a href=&#34;https://github.com/searx/searx&#34;&gt;https://github.com/searx/searx&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;User experience&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Huge update of the simple theme:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;usable on desktop, tablet and mobile&lt;/li&gt; &#xA;   &lt;li&gt;light and dark versions (you can choose in the preferences)&lt;/li&gt; &#xA;   &lt;li&gt;support right-to-left languages&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;see the screenshots &amp;lt;https://dev.searxng.org/screenshots.html&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;the translations are up to date, you can contribute on &lt;code&gt;Weblate&lt;/code&gt;_&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;the preferences page has been updated:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;you can see which engines are reliable or not&lt;/li&gt; &#xA;   &lt;li&gt;engines are grouped inside each tab&lt;/li&gt; &#xA;   &lt;li&gt;each engine has a description&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;thanks to the anonymous metrics, it is easier to report a bug of an engine and thus engines get fixed more quickly&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;if you don&#39;t want any metrics to be recorded, you can &lt;code&gt;disable them on the server &amp;lt;https://docs.searxng.org/admin/engines/settings.html#general&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;administrator can &lt;code&gt;block and/or replace the URLs in the search results &amp;lt;https://github.com/searxng/searxng/blob/5c1c0817c3996c5670a545d05831d234d21e6217/searx/settings.yml#L191-L199&amp;gt;&lt;/code&gt;_&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;you don&#39;t need &lt;code&gt;Morty&lt;/code&gt;_ to proxy the images even on a public instance&lt;/li&gt; &#xA; &lt;li&gt;you don&#39;t need &lt;code&gt;Filtron&lt;/code&gt;_ to block bots, we implemented the builtin &lt;code&gt;limiter&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;you get a well maintained &lt;code&gt;Docker image&lt;/code&gt;_, now also built for ARM64 and ARM/v7 architectures&lt;/li&gt; &#xA; &lt;li&gt;alternatively we have up to date installation scripts&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;.. _Docker image: &lt;a href=&#34;https://github.com/searxng/searxng-docker&#34;&gt;https://github.com/searxng/searxng-docker&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing is easier&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;readable debug log&lt;/li&gt; &#xA; &lt;li&gt;contributions to the themes are made easier, check out our &lt;code&gt;Development Quickstart&lt;/code&gt;_ guide&lt;/li&gt; &#xA; &lt;li&gt;a lot of code cleanup and bug fixes&lt;/li&gt; &#xA; &lt;li&gt;the dependencies are up to date&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;.. _Morty: &lt;a href=&#34;https://github.com/asciimoo/morty&#34;&gt;https://github.com/asciimoo/morty&lt;/a&gt; .. _Filtron: &lt;a href=&#34;https://github.com/searxng/filtron&#34;&gt;https://github.com/searxng/filtron&lt;/a&gt; .. _limiter: &lt;a href=&#34;https://docs.searxng.org/src/searx.plugins.limiter.html&#34;&gt;https://docs.searxng.org/src/searx.plugins.limiter.html&lt;/a&gt; .. _Weblate: &lt;a href=&#34;https://weblate.bubu1.eu/projects/searxng/searxng/&#34;&gt;https://weblate.bubu1.eu/projects/searxng/searxng/&lt;/a&gt; .. _Development Quickstart: &lt;a href=&#34;https://docs.searxng.org/dev/quickstart.html&#34;&gt;https://docs.searxng.org/dev/quickstart.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Translations&lt;/h1&gt; &#xA;&lt;p&gt;We need translators, suggestions are welcome at &lt;a href=&#34;https://weblate.bubu1.eu/projects/searxng/searxng/&#34;&gt;https://weblate.bubu1.eu/projects/searxng/searxng/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. figure:: &lt;a href=&#34;https://weblate.bubu1.eu/widgets/searxng/-/multi-auto.svg&#34;&gt;https://weblate.bubu1.eu/widgets/searxng/-/multi-auto.svg&lt;/a&gt; :target: &lt;a href=&#34;https://weblate.bubu1.eu/projects/searxng/&#34;&gt;https://weblate.bubu1.eu/projects/searxng/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Make a donation&lt;/h1&gt; &#xA;&lt;p&gt;You can support the SearXNG project by clicking on the donation page: &lt;a href=&#34;https://docs.searxng.org/donate.html&#34;&gt;https://docs.searxng.org/donate.html&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>karpathy/minGPT</title>
    <updated>2022-08-01T02:31:58Z</updated>
    <id>tag:github.com,2022-08-01:/karpathy/minGPT</id>
    <link href="https://github.com/karpathy/minGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A minimal PyTorch re-implementation of the OpenAI GPT (Generative Pretrained Transformer) training&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;minGPT&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/karpathy/minGPT/master/mingpt.jpg&#34; alt=&#34;mingpt&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;A PyTorch re-implementation of &lt;a href=&#34;https://github.com/openai/gpt-2&#34;&gt;GPT&lt;/a&gt;, both training and inference. minGPT tries to be small, clean, interpretable and educational, as most of the currently available GPT model implementations can a bit sprawling. GPT is not a complicated model and this implementation is appropriately about 300 lines of code (see &lt;a href=&#34;https://raw.githubusercontent.com/karpathy/minGPT/master/mingpt/model.py&#34;&gt;mingpt/model.py&lt;/a&gt;). All that&#39;s going on is that a sequence of indices feeds into a &lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34;&gt;Transformer&lt;/a&gt;, and a probability distribution over the next index in the sequence comes out. The majority of the complexity is just being clever with batching (both across examples and over sequence length) for efficiency.&lt;/p&gt; &#xA;&lt;p&gt;The minGPT library is three files: &lt;a href=&#34;https://raw.githubusercontent.com/karpathy/minGPT/master/mingpt/model.py&#34;&gt;mingpt/model.py&lt;/a&gt; contains the actual Transformer model definition, &lt;a href=&#34;https://raw.githubusercontent.com/karpathy/minGPT/master/mingpt/bpe.py&#34;&gt;mingpt/bpe.py&lt;/a&gt; contains a mildly refactored Byte Pair Encoder that translates between text and sequences of integers exactly like OpenAI did in GPT, &lt;a href=&#34;https://raw.githubusercontent.com/karpathy/minGPT/master/mingpt/trainer.py&#34;&gt;mingpt/trainer.py&lt;/a&gt; is (GPT-independent) PyTorch boilerplate code that trains the model. Then there are a number of demos and projects that use the library in the &lt;code&gt;projects&lt;/code&gt; folder:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;projects/adder&lt;/code&gt; trains a GPT from scratch to add numbers (inspired by the addition section in the GPT-3 paper)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;projects/chargpt&lt;/code&gt; trains a GPT to be a character-level language model on some input text file&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;demo.ipynb&lt;/code&gt; shows a minimal usage of the &lt;code&gt;GPT&lt;/code&gt; and &lt;code&gt;Trainer&lt;/code&gt; in a notebook format on a simple sorting example&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;generate.ipynb&lt;/code&gt; shows how one can load a pretrained GPT2 and generate text given some prompt&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;Here&#39;s how you&#39;d instantiate a GPT-2 (124M param version):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mingpt.model import GPT&#xA;model_config = GPT.get_default_config()&#xA;model_config.model_type = &#39;gpt2&#39;&#xA;model_config.vocab_size = 50257 # openai&#39;s model vocabulary&#xA;model_config.block_size = 1024  # openai&#39;s model block_size (i.e. input context length)&#xA;model = GPT(model_config)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And here&#39;s how you&#39;d train it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# your subclass of torch.utils.data.Dataset that emits example&#xA;# torch LongTensor of lengths up to 1024, with integers from [0,50257)&#xA;train_dataset = YourDataset()&#xA;&#xA;from mingpt.trainer import Trainer&#xA;train_config = Trainer.get_default_config()&#xA;train_config.learning_rate = 5e-4 # many possible options, see the file&#xA;train_config.max_iters = 1000&#xA;train_config.batch_size = 32&#xA;trainer = Trainer(train_config, model, train_dataset)&#xA;trainer.run()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;code&gt;demo.ipynb&lt;/code&gt; for a more concrete example.&lt;/p&gt; &#xA;&lt;h3&gt;Unit tests&lt;/h3&gt; &#xA;&lt;p&gt;Coverage is not super amazing just yet but:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m unittest discover tests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;todos&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;add gpt-2 finetuning demo on arbitrary given text file&lt;/li&gt; &#xA; &lt;li&gt;add dialog agent demo&lt;/li&gt; &#xA; &lt;li&gt;better docs of outcomes for existing projects (adder, chargpt)&lt;/li&gt; &#xA; &lt;li&gt;add mixed precision and related training scaling goodies&lt;/li&gt; &#xA; &lt;li&gt;distributed training support&lt;/li&gt; &#xA; &lt;li&gt;reproduce some benchmarks in projects/, e.g. text8 or other language modeling&lt;/li&gt; &#xA; &lt;li&gt;proper logging instead of print statement amateur hour haha&lt;/li&gt; &#xA; &lt;li&gt;i probably should have a requirements.txt file...&lt;/li&gt; &#xA; &lt;li&gt;it should be possible to load in many other model weights other than just gpt2-*&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;References&lt;/h3&gt; &#xA;&lt;p&gt;Code:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/gpt-2&#34;&gt;openai/gpt-2&lt;/a&gt; has the model definition in TensorFlow, but not the training code&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/image-gpt&#34;&gt;openai/image-gpt&lt;/a&gt; has some more modern gpt-3 like modification in its code, good reference as well&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;huggingface/transformers&lt;/a&gt; has a &lt;a href=&#34;https://github.com/huggingface/transformers/tree/master/examples/pytorch/language-modeling&#34;&gt;language-modeling example&lt;/a&gt;. It is full-featured but as a result also somewhat challenging to trace. E.g. some large functions have as much as 90% unused code behind various branching statements that is unused in the default setting of simple language modeling&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Papers + some implementation notes:&lt;/p&gt; &#xA;&lt;h4&gt;Improving Language Understanding by Generative Pre-Training (GPT-1)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Our model largely follows the original transformer work&lt;/li&gt; &#xA; &lt;li&gt;We trained a 12-layer decoder-only transformer with masked self-attention heads (768 dimensional states and 12 attention heads). For the position-wise feed-forward networks, we used 3072 dimensional inner states.&lt;/li&gt; &#xA; &lt;li&gt;Adam max learning rate of 2.5e-4. (later GPT-3 for this model size uses 6e-4)&lt;/li&gt; &#xA; &lt;li&gt;LR decay: increased linearly from zero over the first 2000 updates and annealed to 0 using a cosine schedule&lt;/li&gt; &#xA; &lt;li&gt;We train for 100 epochs on minibatches of 64 randomly sampled, contiguous sequences of 512 tokens.&lt;/li&gt; &#xA; &lt;li&gt;Since layernorm is used extensively throughout the model, a simple weight initialization of N(0, 0.02) was sufficient&lt;/li&gt; &#xA; &lt;li&gt;bytepair encoding (BPE) vocabulary with 40,000 merges&lt;/li&gt; &#xA; &lt;li&gt;residual, embedding, and attention dropouts with a rate of 0.1 for regularization.&lt;/li&gt; &#xA; &lt;li&gt;modified version of L2 regularization proposed in (37), with w = 0.01 on all non bias or gain weights&lt;/li&gt; &#xA; &lt;li&gt;For the activation function, we used the Gaussian Error Linear Unit (GELU).&lt;/li&gt; &#xA; &lt;li&gt;We used learned position embeddings instead of the sinusoidal version proposed in the original work&lt;/li&gt; &#xA; &lt;li&gt;For finetuning: We add dropout to the classifier with a rate of 0.1. learning rate of 6.25e-5 and a batchsize of 32. 3 epochs. We use a linear learning rate decay schedule with warmup over 0.2% of training. Œª was set to 0.5.&lt;/li&gt; &#xA; &lt;li&gt;GPT-1 model is 12 layers and d_model 768, ~117M params&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Language Models are Unsupervised Multitask Learners (GPT-2)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;LayerNorm was moved to the input of each sub-block, similar to a pre-activation residual network&lt;/li&gt; &#xA; &lt;li&gt;an additional layer normalization was added after the final self-attention block.&lt;/li&gt; &#xA; &lt;li&gt;modified initialization which accounts for the accumulation on the residual path with model depth is used. We scale the weights of residual layers at initialization by a factor of 1/‚àöN where N is the number of residual layers. (weird because in their released code i can only find a simple use of the old 0.02... in their release of image-gpt I found it used for c_proj, and even then only for attn, not for mlp. huh. &lt;a href=&#34;https://github.com/openai/image-gpt/raw/master/src/model.py&#34;&gt;https://github.com/openai/image-gpt/blob/master/src/model.py&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;the vocabulary is expanded to 50,257&lt;/li&gt; &#xA; &lt;li&gt;increase the context size from 512 to 1024 tokens&lt;/li&gt; &#xA; &lt;li&gt;larger batchsize of 512 is used&lt;/li&gt; &#xA; &lt;li&gt;GPT-2 used 48 layers and d_model 1600 (vs. original 12 layers and d_model 768). ~1.542B params&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Language Models are Few-Shot Learners (GPT-3)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GPT-3: 96 layers, 96 heads, with d_model of 12,288 (175B parameters).&lt;/li&gt; &#xA; &lt;li&gt;GPT-1-like: 12 layers, 12 heads, d_model 768 (125M)&lt;/li&gt; &#xA; &lt;li&gt;We use the same model and architecture as GPT-2, including the modified initialization, pre-normalization, and reversible tokenization described therein&lt;/li&gt; &#xA; &lt;li&gt;we use alternating dense and locally banded sparse attention patterns in the layers of the transformer, similar to the Sparse Transformer&lt;/li&gt; &#xA; &lt;li&gt;we always have the feedforward layer four times the size of the bottleneck layer, dff = 4 ‚àó dmodel&lt;/li&gt; &#xA; &lt;li&gt;all models use a context window of nctx = 2048 tokens.&lt;/li&gt; &#xA; &lt;li&gt;Adam with Œ≤1 = 0.9, Œ≤2 = 0.95, and eps = 10‚àí8&lt;/li&gt; &#xA; &lt;li&gt;All models use weight decay of 0.1 to provide a small amount of regularization. (NOTE: GPT-1 used 0.01 I believe, see above)&lt;/li&gt; &#xA; &lt;li&gt;clip the global norm of the gradient at 1.0&lt;/li&gt; &#xA; &lt;li&gt;Linear LR warmup over the first 375 million tokens. Then use cosine decay for learning rate down to 10% of its value, over 260 billion tokens.&lt;/li&gt; &#xA; &lt;li&gt;gradually increase the batch size linearly from a small value (32k tokens) to the full value over the first 4-12 billion tokens of training, depending on the model size.&lt;/li&gt; &#xA; &lt;li&gt;full 2048-sized time context window is always used, with a special END OF DOCUMENT token delimiter&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Generative Pretraining from Pixels (Image GPT)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;When working with images, we pick the identity permutation œÄi = i for 1 ‚â§ i ‚â§ n, also known as raster order.&lt;/li&gt; &#xA; &lt;li&gt;we create our own 9-bit color palette by clustering (R, G, B) pixel values using k-means with k = 512.&lt;/li&gt; &#xA; &lt;li&gt;Our largest model, iGPT-XL, contains L = 60 layers and uses an embedding size of d = 3072 for a total of 6.8B parameters.&lt;/li&gt; &#xA; &lt;li&gt;Our next largest model, iGPT-L, is essentially identical to GPT-2 with L = 48 layers, but contains a slightly smaller embedding size of d = 1536 (vs 1600) for a total of 1.4B parameters.&lt;/li&gt; &#xA; &lt;li&gt;We use the same model code as GPT-2, except that we initialize weights in the layerdependent fashion as in Sparse Transformer (Child et al., 2019) and zero-initialize all projections producing logits.&lt;/li&gt; &#xA; &lt;li&gt;We also train iGPT-M, a 455M parameter model with L = 36 and d = 1024&lt;/li&gt; &#xA; &lt;li&gt;iGPT-S, a 76M parameter model with L = 24 and d = 512 (okay, and how many heads? looks like the Github code claims 8)&lt;/li&gt; &#xA; &lt;li&gt;When pre-training iGPT-XL, we use a batch size of 64 and train for 2M iterations, and for all other models we use a batch size of 128 and train for 1M iterations.&lt;/li&gt; &#xA; &lt;li&gt;Adam with Œ≤1 = 0.9 and Œ≤2 = 0.95&lt;/li&gt; &#xA; &lt;li&gt;The learning rate is warmed up for one epoch, and then decays to 0&lt;/li&gt; &#xA; &lt;li&gt;We did not use weight decay because applying a small weight decay of 0.01 did not change representation quality.&lt;/li&gt; &#xA; &lt;li&gt;iGPT-S lr 0.003&lt;/li&gt; &#xA; &lt;li&gt;No dropout is used.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;License&lt;/h3&gt; &#xA;&lt;p&gt;MIT&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>mindsdb/mindsdb</title>
    <updated>2022-08-01T02:31:58Z</updated>
    <id>tag:github.com,2022-08-01:/mindsdb/mindsdb</id>
    <link href="https://github.com/mindsdb/mindsdb" rel="alternate"></link>
    <summary type="html">&lt;p&gt;In-Database Machine Learning&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;img width=&#34;300&#34; src=&#34;https://github.com/mindsdb/mindsdb_native/raw/stable/assets/MindsDBColorPurp@3x.png?raw=true&#34; alt=&#34;MindsDB&#34;&gt; &lt;br&gt; &lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/mindsdb/mindsdb/actions&#34;&gt;&lt;img src=&#34;https://github.com/mindsdb/mindsdb/workflows/MindsDB%20workflow/badge.svg?sanitize=true&#34; alt=&#34;MindsDB workflow&#34;&gt;&lt;/a&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.python.org/downloads/&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.7.x%20|%203.8.x|%203.9.x-brightgreen.svg&#34; alt=&#34;Python supported&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/MindsDB/&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/MindsDB.svg?sanitize=true&#34; alt=&#34;PyPi Version&#34;&gt;&lt;/a&gt; &lt;img alt=&#34;PyPI - Downloads&#34; src=&#34;https://img.shields.io/pypi/dm/Mindsdb&#34;&gt; &lt;a href=&#34;https://hub.docker.com/u/mindsdb&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/mindsdb/mindsdb&#34; alt=&#34;Docker pulls&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/website?url=https%3A%2F%2Fwww.mindsdb.com%2F&#34; alt=&#34;MindsDB Website&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://join.slack.com/t/mindsdbcommunity/shared_invite/zt-o8mrmx3l-5ai~5H66s6wlxFfBMVI6wQ&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/slack-@mindsdbcommunity-brightgreen.svg?logo=slack &#34; alt=&#34;MindsDB Community&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://deepnote.com/project/Machine-Learning-With-SQL-8GDF7bc7SzKlhBLorqoIcw/%2Fmindsdb_demo.ipynb&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://deepnote.com/buttons/launch-in-deepnote-white.svg?sanitize=true&#34; alt=&#34;Launch in Deepnote&#34;&gt;&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA; &lt;h3 align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&#34;&gt;Website&lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href=&#34;https://docs.mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&#34;&gt;Docs&lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href=&#34;https://join.slack.com/t/mindsdbcommunity/shared_invite/zt-o8mrmx3l-5ai~5H66s6wlxFfBMVI6wQ&#34;&gt;Community Slack&lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href=&#34;https://github.com/mindsdb/mindsdb/projects&#34;&gt;Contribute&lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href=&#34;https://cloud.mindsdb.com&#34;&gt;Demo&lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href=&#34;https://github.com/mindsdb/mindsdb/raw/staging/integrations_contest.md&#34;&gt;Integrations Contest&lt;/a&gt; &lt;/h3&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&#34;&gt;MindsDB&lt;/a&gt; ML-SQL Server enables machine learning workflows for the most powerful databases and datawarehouses using SQL. &lt;a href=&#34;https://twitter.com/intent/tweet?text=Machine%20Learning%20inside%20Databases%20&amp;amp;url=https://www.mindsdb.com&amp;amp;via=mindsdb&amp;amp;hashtags=ai,ml,machine_learning,neural_networks,databases,sql&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url/http/shields.io.svg?style=social&#34; alt=&#34;Tweet&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Developers can quickly add AI capabilities to your applications.&lt;/li&gt; &#xA; &lt;li&gt;Data Scientists can streamline MLOps by deploying ML models as AI Tables.&lt;/li&gt; &#xA; &lt;li&gt;Data Analysts can easily make forecasts on complex data (like multivariate time-series with high cardinality) and visualize them in BI tools like Tableau.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;NEW!&lt;/strong&gt; Check-out the new MindsDB &lt;a href=&#34;https://github.com/mindsdb/mindsdb/raw/staging/integrations_contest.md&#34;&gt;Dev üí° challenge&lt;/a&gt; (and the cash&lt;span&gt;üíµ&lt;/span&gt; prizes) for democratizing machine learning!&lt;/p&gt; &#xA;&lt;p&gt;If you like our project then we would really appreciate &lt;strong&gt;a Star ‚≠ê!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Also, check-out the &lt;a href=&#34;https://mindsdb.com/community?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&#34;&gt;rewards and community programs.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/mindsdb/mindsdb#installation&#34;&gt;Installation&lt;/a&gt; - &lt;a href=&#34;https://github.com/mindsdb/mindsdb#overview&#34;&gt;Overview&lt;/a&gt; - &lt;a href=&#34;https://github.com/mindsdb/mindsdb#features&#34;&gt;Features&lt;/a&gt; - &lt;a href=&#34;https://github.com/mindsdb/mindsdb#database-integrations&#34;&gt;Database Integrations&lt;/a&gt; - &lt;a href=&#34;https://github.com/mindsdb/mindsdb#quickstart&#34;&gt;Quickstart&lt;/a&gt; - &lt;a href=&#34;https://github.com/mindsdb/mindsdb#documentation&#34;&gt;Documentation&lt;/a&gt; - &lt;a href=&#34;https://github.com/mindsdb/mindsdb#support&#34;&gt;Support&lt;/a&gt; - &lt;a href=&#34;https://github.com/mindsdb/mindsdb#contribution&#34;&gt;Contributing&lt;/a&gt; - &lt;a href=&#34;https://github.com/mindsdb/mindsdb#mailing-lists&#34;&gt;Mailing lists&lt;/a&gt; - &lt;a href=&#34;https://github.com/mindsdb/mindsdb#license&#34;&gt;License&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt; Machine Learning using SQL &lt;br&gt; &lt;br&gt; &lt;img width=&#34;600&#34; src=&#34;https://docs.mindsdb.com/assets/mdb_image.png&#34; alt=&#34;MindsDB&#34;&gt; &lt;/h2&gt; &#xA;&lt;img width=&#34;1222&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/5898506/172740218-61db5eec-1bcf-4832-99d9-308709a426a7.png&#34;&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;You can try Mindsdb ML SQL server here &lt;a href=&#34;https://cloud.mindsdb.com&#34;&gt;(demo)&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;To install the latest version of MindsDB please pull the following Docker image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker pull mindsdb/mindsdb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or, use PyPI:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install mindsdb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;MindsDB automates and abstracts machine learning models through virtual AI Tables:&lt;/p&gt; &#xA;&lt;p&gt;Apart from abstracting ML models as AI Tables inside databases, MindsDB has a set of unique capabilities as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Easily make predictions over very complex multivariate time-series data with high cardinality&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;An open JSON-AI syntax to tune ML models and optimize ML pipelines in a declarative way&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;How it works:&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Let MindsDB connect to your database.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Train a Predictor using a single SQL statement (make MindsDB learn from historical data automatically) or import your own ML model to a Predictor via JSON-AI .&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Make predictions with SQL statements (Predictor is exposed as virtual AI Tables). There‚Äôs no need to deploy models since they are already part of the data layer.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Check our &lt;a href=&#34;https://docs.mindsdb.com/?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&#34;&gt;docs&lt;/a&gt; and &lt;a href=&#34;https://mindsdb.com/blog/?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&#34;&gt;blog&lt;/a&gt; for tutorials and use case examples.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Automatic data pre-processing, feature engineering and encoding&lt;/li&gt; &#xA; &lt;li&gt;Classification, regression, time-series tasks&lt;/li&gt; &#xA; &lt;li&gt;Bring models to production without ‚Äútraditional deployment‚Äù as AI Tables&lt;/li&gt; &#xA; &lt;li&gt;Get mModels‚Äô accuracy scoring and confidence intervals for each prediction&lt;/li&gt; &#xA; &lt;li&gt;Join ML models with existing data&lt;/li&gt; &#xA; &lt;li&gt;Anomaly detection&lt;/li&gt; &#xA; &lt;li&gt;Model explainability analysis&lt;/li&gt; &#xA; &lt;li&gt;GPU support for models‚Äô training&lt;/li&gt; &#xA; &lt;li&gt;Open JSON-AI syntax to build models and bring your own ML blocks in a declarative way&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Database Integrations&lt;/h2&gt; &#xA;&lt;p&gt;MindsDB works with most of the SQL and NoSQL databases and data Streams for real-time ML.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Connect your Data&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Apache Kafka-808080?style=for-the-badge&amp;amp;logo=apache-kafka&amp;amp;logoColor=white&#34; alt=&#34;Connect Apache Kafka&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Amazon%20Redshift-0466C8?style=for-the-badge&amp;amp;logo=amazon-aws&amp;amp;logoColor=white&#34; alt=&#34;Connect Amazon Redshift&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Cassandra-1287B1?style=for-the-badge&amp;amp;logo=apache%20cassandra&amp;amp;logoColor=white&#34; alt=&#34;Connect Cassandra&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Clickhouse-e6e600?style=for-the-badge&amp;amp;logo=clickhouse&amp;amp;logoColor=white&#34; alt=&#34;Connect Clickhouse&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/CockroachDB-426EDF?style=for-the-badge&amp;amp;logo=cockroach-labs&amp;amp;logoColor=white&#34; alt=&#34;Connect CockroachDB&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/MariaDB-003545?style=for-the-badge&amp;amp;logo=mariadb&amp;amp;logoColor=white&#34; alt=&#34;Connect MariaDB&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Microsoft%20SQL%20Sever-CC2927?style=for-the-badge&amp;amp;logo=microsoft%20sql%20server&amp;amp;logoColor=white&#34; alt=&#34;Connect SQL Server&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/MongoDB-4EA94B?style=for-the-badge&amp;amp;logo=mongodb&amp;amp;logoColor=white&#34; alt=&#34;Connect MongoDB&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/MySQL-00758F?style=for-the-badge&amp;amp;logo=mysql&amp;amp;logoColor=white&#34; alt=&#34;Connect MySQL&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&amp;amp;logo=postgresql&amp;amp;logoColor=white&#34; alt=&#34;Connect PostgreSQL&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/QuestDB-d14671?style=for-the-badge&amp;amp;logo=questdb&amp;amp;logoColor=white&#34; alt=&#34;Connect QuestDB&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/redis-%23DD0031.svg?&amp;amp;style=for-the-badge&amp;amp;logo=redis&amp;amp;logoColor=white&#34; alt=&#34;Connect Redis&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/ScyllaDB-53CADD?style=for-the-badge&amp;amp;logo=scylladbb&amp;amp;logoColor=white&#34; alt=&#34;Connect ScyllaDB&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Singlestore-5f07b4?style=for-the-badge&amp;amp;logo=singlestore&amp;amp;logoColor=white&#34; alt=&#34;Connect Singlestore&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Snowflake-35aedd?style=for-the-badge&amp;amp;logo=snowflake&amp;amp;logoColor=blue&#34; alt=&#34;Connect Snowflake&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mindsdb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Trino-dd00a1?style=for-the-badge&amp;amp;logo=trino&amp;amp;logoColor=white&#34; alt=&#34;Connect Trino&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/mindsdb/mindsdb/issues/new?assignees=&amp;amp;labels=&amp;amp;template=feature-mindsdb-request.yaml&#34;&gt;&lt;span&gt;‚ùì&lt;/span&gt; &lt;span&gt;üëã&lt;/span&gt; Missing integration?&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;To get your hands on MindsDB, we recommend using the &lt;a href=&#34;https://docs.mindsdb.com/setup/self-hosted/docker/?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&#34;&gt;Docker image&lt;/a&gt; or simply sign up for a &lt;a href=&#34;https://cloud.mindsdb.com/signup?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&#34;&gt;free cloud account&lt;/a&gt;. Feel free to browse &lt;a href=&#34;https://docs.mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&#34;&gt;documentation&lt;/a&gt; for other installation methods and tutorials.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;You can find the complete documentation of MindsDB at &lt;a href=&#34;https://docs.mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&#34;&gt;docs.mindsdb.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;If you found a bug, please submit an &lt;a href=&#34;https://github.com/mindsdb/mindsdb/issues&#34;&gt;issue on Github&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To get community support, you can:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Post at MindsDB &lt;a href=&#34;https://join.slack.com/t/mindsdbcommunity/shared_invite/zt-o8mrmx3l-5ai~5H66s6wlxFfBMVI6wQ&#34;&gt;Slack community&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Ask for help at our &lt;a href=&#34;https://github.com/mindsdb/mindsdb/discussions&#34;&gt;Github Discussions&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Ask a question at &lt;a href=&#34;https://stackoverflow.com/questions/tagged/mindsdb&#34;&gt;Stackoverflow&lt;/a&gt; with a MindsDB tag.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you need commercial support, please &lt;a href=&#34;https://mindsdb.com/contact/?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&#34;&gt;contact&lt;/a&gt; the MindsDB team.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;A great place to start contributing to MindsDB will be our GitHub projects for &lt;span&gt;üèÅ&lt;/span&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Community writers &lt;a href=&#34;https://github.com/mindsdb/mindsdb/projects/7&#34;&gt;dashboard tasks&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Community code contributors &lt;a href=&#34;https://github.com/mindsdb/mindsdb/projects/8&#34;&gt;dashboard tasks&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Also, we are always open to suggestions so feel free to open new issues with your ideas and we can give you guidance!&lt;/p&gt; &#xA;&lt;p&gt;Being part of the core team is accessible to anyone who is motivated and wants to be part of that journey! If you&#39;d like to contribute to the project, refer to the &lt;a href=&#34;https://docs.mindsdb.com/contribute/?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&#34;&gt;contributing documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Please note that this project is released with a &lt;a href=&#34;https://github.com/mindsdb/mindsdb/raw/stable/CODE_OF_CONDUCT.md&#34;&gt;Contributor Code of Conduct&lt;/a&gt;. By participating in this project, you agree to abide by its terms.&lt;/p&gt; &#xA;&lt;h3&gt;Current contributors&lt;/h3&gt; &#xA;&lt;a href=&#34;https://github.com/mindsdb/mindsdb/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contributors-img.web.app/image?repo=mindsdb/mindsdb&#34;&gt; &lt;/a&gt; &#xA;&lt;p&gt;Made with &lt;a href=&#34;https://contributors-img.web.app&#34;&gt;contributors-img&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Mailing lists&lt;/h2&gt; &#xA;&lt;p&gt;Subscribe to MindsDB Monthly &lt;a href=&#34;https://mindsdb.com/newsletter/?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&#34;&gt;Community Newsletter&lt;/a&gt; to get general announcements, release notes, information about MindsDB events, and the latest blog posts. You may also join our &lt;a href=&#34;https://mindsdb.com/beta-tester/?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&#34;&gt;beta-users&lt;/a&gt; group, and get access to new beta features.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MindsDB is licensed under &lt;a href=&#34;https://github.com/mindsdb/mindsdb/raw/master/LICENSE&#34;&gt;GNU General Public License v3.0&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>