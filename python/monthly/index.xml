<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-10-01T02:02:03Z</updated>
  <subtitle>Monthly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>AUTOMATIC1111/stable-diffusion-webui</title>
    <updated>2022-10-01T02:02:03Z</updated>
    <id>tag:github.com,2022-10-01:/AUTOMATIC1111/stable-diffusion-webui</id>
    <link href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Stable Diffusion web UI&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stable Diffusion web UI&lt;/h1&gt; &#xA;&lt;p&gt;A browser interface based on Gradio library for Stable Diffusion.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/txt2img_Screenshot.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Check the &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts&#34;&gt;custom scripts&lt;/a&gt; wiki page for extra scripts developed by users.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features&#34;&gt;Detailed feature showcase with images&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Original txt2img and img2img modes&lt;/li&gt; &#xA; &lt;li&gt;One click install and run script (but you still must install python and git)&lt;/li&gt; &#xA; &lt;li&gt;Outpainting&lt;/li&gt; &#xA; &lt;li&gt;Inpainting&lt;/li&gt; &#xA; &lt;li&gt;Prompt&lt;/li&gt; &#xA; &lt;li&gt;Stable Diffusion upscale&lt;/li&gt; &#xA; &lt;li&gt;Attention, specify parts of text that the model should pay more attention to &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;a man in a ((txuedo)) - will pay more attentinoto tuxedo&lt;/li&gt; &#xA;   &lt;li&gt;a man in a (txuedo:1.21) - alternative syntax&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Loopback, run img2img procvessing multiple times&lt;/li&gt; &#xA; &lt;li&gt;X/Y plot, a way to draw a 2 dimensional plot of images with different parameters&lt;/li&gt; &#xA; &lt;li&gt;Textual Inversion &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;have as many embeddings as you want and use any names you like for them&lt;/li&gt; &#xA;   &lt;li&gt;use multiple embeddings with different numbers of vectors per token&lt;/li&gt; &#xA;   &lt;li&gt;works with half precision floating point numbers&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Extras tab with: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;GFPGAN, neural network that fixes faces&lt;/li&gt; &#xA;   &lt;li&gt;CodeFormer, face restoration tool as an alternative to GFPGAN&lt;/li&gt; &#xA;   &lt;li&gt;RealESRGAN, neural network upscaler&lt;/li&gt; &#xA;   &lt;li&gt;ESRGAN, neural network upscaler with a lot of third party models&lt;/li&gt; &#xA;   &lt;li&gt;SwinIR, neural network upscaler&lt;/li&gt; &#xA;   &lt;li&gt;LDSR, Latent diffusion super resolution upscaling&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Resizing aspect ratio options&lt;/li&gt; &#xA; &lt;li&gt;Sampling method selection&lt;/li&gt; &#xA; &lt;li&gt;Interrupt processing at any time&lt;/li&gt; &#xA; &lt;li&gt;4GB video card support (also reports of 2GB working)&lt;/li&gt; &#xA; &lt;li&gt;Correct seeds for batches&lt;/li&gt; &#xA; &lt;li&gt;Prompt length validation &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;get length of prompt in tokensas you type&lt;/li&gt; &#xA;   &lt;li&gt;get a warning after geenration if some text was truncated&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Generation parameters &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;parameters you used to generate images are saved with that image&lt;/li&gt; &#xA;   &lt;li&gt;in PNG chunks for PNG, in EXIF for JPEG&lt;/li&gt; &#xA;   &lt;li&gt;can drag the image to PNG info tab to restore generation parameters and automatically copy them into UI&lt;/li&gt; &#xA;   &lt;li&gt;can be disabled in settings&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Settings page&lt;/li&gt; &#xA; &lt;li&gt;Running arbitrary python code from UI (must run with commandline flag to enable)&lt;/li&gt; &#xA; &lt;li&gt;Mouseover hints for most UI elements&lt;/li&gt; &#xA; &lt;li&gt;Possible to change defaults/mix/max/step values for UI elements via text config&lt;/li&gt; &#xA; &lt;li&gt;Random artist button&lt;/li&gt; &#xA; &lt;li&gt;Tiling support, a checkbox to create images that can be tiled like textures&lt;/li&gt; &#xA; &lt;li&gt;Progress bar and live image generation preview&lt;/li&gt; &#xA; &lt;li&gt;Negative prompt, an extra text field that allows you to list what you don&#39;t want to see in generated image&lt;/li&gt; &#xA; &lt;li&gt;Styles, a way to save part of prompt and easily apply them via dropdown later&lt;/li&gt; &#xA; &lt;li&gt;Variations, a way to generate same image but with tiny differences&lt;/li&gt; &#xA; &lt;li&gt;Seed resizing, a way to generate same image but at slightly different resolution&lt;/li&gt; &#xA; &lt;li&gt;CLIP interrogator, a button that tries to guess prompt from an image&lt;/li&gt; &#xA; &lt;li&gt;Prompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midway&lt;/li&gt; &#xA; &lt;li&gt;Batch Processing, process a group of files using img2img&lt;/li&gt; &#xA; &lt;li&gt;Img2img Alternative&lt;/li&gt; &#xA; &lt;li&gt;Highres Fix, a convenience option to produce high resolution pictures in one click without usual distortions&lt;/li&gt; &#xA; &lt;li&gt;Reloading checkpoints on the fly&lt;/li&gt; &#xA; &lt;li&gt;Checkpoint Merger, a tab that allows you to merge two checkpoints into one&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts&#34;&gt;Custom scripts&lt;/a&gt; with many extensions from community&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation and Running&lt;/h2&gt; &#xA;&lt;p&gt;Make sure the required &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies&#34;&gt;dependencies&lt;/a&gt; are met and follow the instructions available for both &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs&#34;&gt;NVidia&lt;/a&gt; (recommended) and &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs&#34;&gt;AMD&lt;/a&gt; GPUs.&lt;/p&gt; &#xA;&lt;p&gt;Alternatively, use Google Colab:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1kw3egmSn-KgWsikYvOMjJkVDsPLjEMzl&#34;&gt;Colab, maintained by Akaibu&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1Iy-xW9t1-OQWhb0hNxueGij8phCyluOh&#34;&gt;Colab, original by me, outdated&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Automatic Installation on Windows&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://www.python.org/downloads/windows/&#34;&gt;Python 3.10.6&lt;/a&gt;, checking &#34;Add Python to PATH&#34;&lt;/li&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://git-scm.com/download/win&#34;&gt;git&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Download the stable-diffusion-webui repository, for example by running &lt;code&gt;git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Place &lt;code&gt;model.ckpt&lt;/code&gt; in the &lt;code&gt;models&lt;/code&gt; directory (see &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies&#34;&gt;dependencies&lt;/a&gt; for where to get it).&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;&lt;em&gt;(Optional)&lt;/em&gt;&lt;/em&gt; Place &lt;code&gt;GFPGANv1.4.pth&lt;/code&gt; in the base directory, alongside &lt;code&gt;webui.py&lt;/code&gt; (see &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies&#34;&gt;dependencies&lt;/a&gt; for where to get it).&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;webui-user.bat&lt;/code&gt; from Windows Explorer as normal, non-administrator, user.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Automatic Installation on Linux&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install the dependencies:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Debian-based:&#xA;sudo apt install wget git python3 python3-venv&#xA;# Red Hat-based:&#xA;sudo dnf install wget git python3&#xA;# Arch-based:&#xA;sudo pacman -S wget git python3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;To install in &lt;code&gt;/home/$(whoami)/stable-diffusion-webui/&lt;/code&gt;, run:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bash &amp;lt;(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Installation on Apple Silicon&lt;/h3&gt; &#xA;&lt;p&gt;Find the instructions &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Here&#39;s how to add code to this repo: &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;The documentation was moved from this README over to the project&#39;s &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki&#34;&gt;wiki&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Stable Diffusion - &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;https://github.com/CompVis/stable-diffusion&lt;/a&gt;, &lt;a href=&#34;https://github.com/CompVis/taming-transformers&#34;&gt;https://github.com/CompVis/taming-transformers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;k-diffusion - &lt;a href=&#34;https://github.com/crowsonkb/k-diffusion.git&#34;&gt;https://github.com/crowsonkb/k-diffusion.git&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;GFPGAN - &lt;a href=&#34;https://github.com/TencentARC/GFPGAN.git&#34;&gt;https://github.com/TencentARC/GFPGAN.git&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CodeFormer - &lt;a href=&#34;https://github.com/sczhou/CodeFormer&#34;&gt;https://github.com/sczhou/CodeFormer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ESRGAN - &lt;a href=&#34;https://github.com/xinntao/ESRGAN&#34;&gt;https://github.com/xinntao/ESRGAN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;SwinIR - &lt;a href=&#34;https://github.com/JingyunLiang/SwinIR&#34;&gt;https://github.com/JingyunLiang/SwinIR&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;LDSR - &lt;a href=&#34;https://github.com/Hafiidz/latent-diffusion&#34;&gt;https://github.com/Hafiidz/latent-diffusion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Ideas for optimizations - &lt;a href=&#34;https://github.com/basujindal/stable-diffusion&#34;&gt;https://github.com/basujindal/stable-diffusion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Doggettx - Cross Attention layer optimization - &lt;a href=&#34;https://github.com/Doggettx/stable-diffusion&#34;&gt;https://github.com/Doggettx/stable-diffusion&lt;/a&gt;, original idea for prompt editing.&lt;/li&gt; &#xA; &lt;li&gt;Idea for SD upscale - &lt;a href=&#34;https://github.com/jquesnelle/txt2imghd&#34;&gt;https://github.com/jquesnelle/txt2imghd&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Noise generation for outpainting mk2 - &lt;a href=&#34;https://github.com/parlance-zz/g-diffuser-bot&#34;&gt;https://github.com/parlance-zz/g-diffuser-bot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CLIP interrogator idea and borrowing some code - &lt;a href=&#34;https://github.com/pharmapsychotic/clip-interrogator&#34;&gt;https://github.com/pharmapsychotic/clip-interrogator&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Initial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.&lt;/li&gt; &#xA; &lt;li&gt;(You)&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>TheAlgorithms/Python</title>
    <updated>2022-10-01T02:02:03Z</updated>
    <id>tag:github.com,2022-10-01:/TheAlgorithms/Python</id>
    <link href="https://github.com/TheAlgorithms/Python" rel="alternate"></link>
    <summary type="html">&lt;p&gt;All Algorithms implemented in Python&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;!-- Title: --&gt; &#xA; &lt;a href=&#34;https://github.com/TheAlgorithms/&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/TheAlgorithms/website/1cd824df116b27029f17c2d1b42d81731f28a920/public/logo.svg?sanitize=true&#34; height=&#34;100&#34;&gt; &lt;/a&gt; &#xA; &lt;h1&gt;&lt;a href=&#34;https://github.com/TheAlgorithms/&#34;&gt;The Algorithms&lt;/a&gt; - Python&lt;/h1&gt; &#xA; &lt;!-- Labels: --&gt; &#xA; &lt;!-- First row: --&gt; &#xA; &lt;a href=&#34;https://gitpod.io/#https://github.com/TheAlgorithms/Python&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod&amp;amp;style=flat-square&#34; height=&#34;20&#34; alt=&#34;Gitpod Ready-to-Code&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/TheAlgorithms/Python/raw/master/CONTRIBUTING.md&#34;&gt; &lt;img src=&#34;https://img.shields.io/static/v1.svg?label=Contributions&amp;amp;message=Welcome&amp;amp;color=0059b3&amp;amp;style=flat-square&#34; height=&#34;20&#34; alt=&#34;Contributions Welcome&#34;&gt; &lt;/a&gt; &#xA; &lt;img src=&#34;https://img.shields.io/github/repo-size/TheAlgorithms/Python.svg?label=Repo%20size&amp;amp;style=flat-square&#34; height=&#34;20&#34;&gt; &#xA; &lt;a href=&#34;https://discord.gg/c7MnfGFGa6&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/808045925556682782.svg?logo=discord&amp;amp;colorB=7289DA&amp;amp;style=flat-square&#34; height=&#34;20&#34; alt=&#34;Discord chat&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://gitter.im/TheAlgorithms&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&amp;amp;logo=gitter&amp;amp;style=flat-square&#34; height=&#34;20&#34; alt=&#34;Gitter chat&#34;&gt; &lt;/a&gt; &#xA; &lt;!-- Second row: --&gt; &#xA; &lt;br&gt; &#xA; &lt;a href=&#34;https://github.com/TheAlgorithms/Python/actions&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/workflow/status/TheAlgorithms/Python/build?label=CI&amp;amp;logo=github&amp;amp;style=flat-square&#34; height=&#34;20&#34; alt=&#34;GitHub Workflow Status&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://lgtm.com/projects/g/TheAlgorithms/Python/alerts&#34;&gt; &lt;img src=&#34;https://img.shields.io/lgtm/alerts/github/TheAlgorithms/Python.svg?label=LGTM&amp;amp;logo=LGTM&amp;amp;style=flat-square&#34; height=&#34;20&#34; alt=&#34;LGTM&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/pre-commit/pre-commit&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; height=&#34;20&#34; alt=&#34;pre-commit&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/psf/black&#34;&gt; &lt;img src=&#34;https://img.shields.io/static/v1?label=code%20style&amp;amp;message=black&amp;amp;color=black&amp;amp;style=flat-square&#34; height=&#34;20&#34; alt=&#34;code style: black&#34;&gt; &lt;/a&gt; &#xA; &lt;!-- Short description: --&gt; &#xA; &lt;h3&gt;All algorithms implemented in Python - for education&lt;/h3&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Implementations are for learning purposes only. As they may be less efficient than the implementations in the Python standard library, use them at your discretion.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Read through our &lt;a href=&#34;https://raw.githubusercontent.com/TheAlgorithms/Python/master/CONTRIBUTING.md&#34;&gt;Contribution Guidelines&lt;/a&gt; before you contribute.&lt;/p&gt; &#xA;&lt;h2&gt;Community Channels&lt;/h2&gt; &#xA;&lt;p&gt;We&#39;re on &lt;a href=&#34;https://discord.gg/c7MnfGFGa6&#34;&gt;Discord&lt;/a&gt; and &lt;a href=&#34;https://gitter.im/TheAlgorithms&#34;&gt;Gitter&lt;/a&gt;! Community channels are great for you to ask questions and get help. Please join us!&lt;/p&gt; &#xA;&lt;h2&gt;List of Algorithms&lt;/h2&gt; &#xA;&lt;p&gt;See our &lt;a href=&#34;https://raw.githubusercontent.com/TheAlgorithms/Python/master/DIRECTORY.md&#34;&gt;directory&lt;/a&gt; for easier navigation and better overview of the project.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>PaddlePaddle/PaddleOCR</title>
    <updated>2022-10-01T02:02:03Z</updated>
    <id>tag:github.com,2022-10-01:/PaddlePaddle/PaddleOCR</id>
    <link href="https://github.com/PaddlePaddle/PaddleOCR" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Awesome multilingual OCR toolkits based on PaddlePaddle (practical ultra lightweight OCR system, support 80+ languages recognition, provide data annotation and synthesis tools, support training and deployment among server, mobile, embedded and IoT devices)&lt;/p&gt;&lt;hr&gt;&lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/README_ch.md&#34;&gt;简体中文&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/PaddleOCR_log.png&#34; align=&#34;middle&#34; width=&#34;600&#34;&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;left&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-dfd.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleOCR/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/PaddlePaddle/PaddleOCR?color=ffa&#34;&gt;&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.7+-aff.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/format/PaddleOCR?color=c77&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/PaddleOCR/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/PaddleOCR?color=9cf&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleOCR/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/PaddlePaddle/PaddleOCR?color=ccf&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;PaddleOCR aims to create multilingual, awesome, leading, and practical OCR tools that help users train better models and apply them into practice.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/imgs_results/PP-OCRv3/en/en_4.png&#34; width=&#34;800&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/imgs_results/ch_ppocr_mobile_v2.0/00006737.jpg&#34; width=&#34;800&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;📣 Recent updates&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;🔥2022.8.24 Release PaddleOCR &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleOCR/tree/release/2.6&#34;&gt;release/2.6&lt;/a&gt;&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Release &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/&#34;&gt;PP-Structurev2&lt;/a&gt;，with functions and performance fully upgraded, adapted to Chinese scenes, and new support for &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/recovery&#34;&gt;Layout Recovery&lt;/a&gt; and &lt;strong&gt;one line command to convert PDF to Word&lt;/strong&gt;;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/layout&#34;&gt;Layout Analysis&lt;/a&gt; optimization: model storage reduced by 95%, while speed increased by 11 times, and the average CPU time-cost is only 41ms;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/table&#34;&gt;Table Recognition&lt;/a&gt; optimization: 3 optimization strategies are designed, and the model accuracy is improved by 6% under comparable time consumption;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/kie&#34;&gt;Key Information Extraction&lt;/a&gt; optimization：a visual-independent model structure is designed, the accuracy of semantic entity recognition is increased by 2.8%, and the accuracy of relation extraction is increased by 9.1%.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;🔥2022.8 Release &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/applications/README_en.md&#34;&gt;OCR scene application collection&lt;/a&gt;&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Release &lt;strong&gt;9 vertical models&lt;/strong&gt; such as digital tube, LCD screen, license plate, handwriting recognition model, high-precision SVTR model, etc, covering the main OCR vertical applications in general, manufacturing, finance, and transportation industries.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.8 Add implementation of &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_overview_en.md&#34;&gt;8 cutting-edge algorithms&lt;/a&gt;&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Text Detection: &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_det_fcenet_en.md&#34;&gt;FCENet&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_det_db_en.md&#34;&gt;DB++&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Text Recognition: &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_rec_vitstr_en.md&#34;&gt;ViTSTR&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_rec_abinet_en.md&#34;&gt;ABINet&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_rec_visionlan_en.md&#34;&gt;VisionLAN&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_rec_spin_en.md&#34;&gt;SPIN&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_rec_robustscanner_en.md&#34;&gt;RobustScanner&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Table Recognition: &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_table_master_en.md&#34;&gt;TableMaster&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.5.9 Release PaddleOCR &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleOCR/tree/release/2.5&#34;&gt;release/2.5&lt;/a&gt;&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Release &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/ppocr_introduction_en.md#pp-ocrv3&#34;&gt;PP-OCRv3&lt;/a&gt;: With comparable speed, the effect of Chinese scene is further improved by 5% compared with PP-OCRv2, the effect of English scene is improved by 11%, and the average recognition accuracy of 80 language multilingual models is improved by more than 5%.&lt;/li&gt; &#xA;   &lt;li&gt;Release &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/PPOCRLabel&#34;&gt;PPOCRLabelv2&lt;/a&gt;: Add the annotation function for table recognition task, key information extraction task and irregular text image.&lt;/li&gt; &#xA;   &lt;li&gt;Release interactive e-book &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/ocr_book_en.md&#34;&gt;&lt;em&gt;&#34;Dive into OCR&#34;&lt;/em&gt;&lt;/a&gt;, covers the cutting-edge theory and code practice of OCR full stack technology.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/update_en.md&#34;&gt;more&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🌟 Features&lt;/h2&gt; &#xA;&lt;p&gt;PaddleOCR support a variety of cutting-edge algorithms related to OCR, and developed industrial featured models/solution &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/ppocr_introduction_en.md&#34;&gt;PP-OCR&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/README.md&#34;&gt;PP-Structure&lt;/a&gt; on this basis, and get through the whole process of data production, model training, compression, inference and deployment.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/25809855/186171245-40abc4d7-904f-4949-ade1-250f86ed3a90.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;It is recommended to start with the “quick experience” in the document tutorial&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;⚡ Quick Experience&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Web online experience for the ultra-lightweight OCR: &lt;a href=&#34;https://www.paddlepaddle.org.cn/hub/scene/ocr&#34;&gt;Online Experience&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Mobile DEMO experience (based on EasyEdge and Paddle-Lite, supports iOS and Android systems): &lt;a href=&#34;https://ai.baidu.com/easyedge/app/openSource?from=paddlelite&#34;&gt;Sign in to the website to obtain the QR code for installing the App&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;One line of code quick use: &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/quickstart_en.md&#34;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a name=&#34;book&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;📚 E-book: &lt;em&gt;Dive Into OCR&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/ocr_book_en.md&#34;&gt;Dive Into OCR &lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a name=&#34;Community&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;👫 Community&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;For international developers, we regard &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleOCR/discussions&#34;&gt;PaddleOCR Discussions&lt;/a&gt; as our international community platform. All ideas and questions can be discussed here in English.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For Chinese develops, Scan the QR code below with your Wechat, you can join the official technical discussion group. For richer community content, please refer to &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/README_ch.md&#34;&gt;中文README&lt;/a&gt;, looking forward to your participation.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/dygraph/doc/joinus.PNG&#34; width=&#34;150&#34; height=&#34;150&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;a name=&#34;Supported-Chinese-model-list&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🛠️ PP-OCR Series Model List（Update on September 8th）&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model introduction&lt;/th&gt; &#xA;   &lt;th&gt;Model name&lt;/th&gt; &#xA;   &lt;th&gt;Recommended scene&lt;/th&gt; &#xA;   &lt;th&gt;Detection model&lt;/th&gt; &#xA;   &lt;th&gt;Direction classifier&lt;/th&gt; &#xA;   &lt;th&gt;Recognition model&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese and English ultra-lightweight PP-OCRv3 model（16.2M）&lt;/td&gt; &#xA;   &lt;td&gt;ch_PP-OCRv3_xx&lt;/td&gt; &#xA;   &lt;td&gt;Mobile &amp;amp; Server&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_det_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_det_distill_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_rec_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_rec_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;English ultra-lightweight PP-OCRv3 model（13.4M）&lt;/td&gt; &#xA;   &lt;td&gt;en_PP-OCRv3_xx&lt;/td&gt; &#xA;   &lt;td&gt;Mobile &amp;amp; Server&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_distill_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_rec_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_rec_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese and English ultra-lightweight PP-OCRv2 model（11.6M）&lt;/td&gt; &#xA;   &lt;td&gt;ch_PP-OCRv2_xx&lt;/td&gt; &#xA;   &lt;td&gt;Mobile &amp;amp; Server&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/PP-OCRv2/chinese/ch_PP-OCRv2_det_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/PP-OCRv2/chinese/ch_PP-OCRv2_det_distill_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/PP-OCRv2/chinese/ch_PP-OCRv2_rec_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/PP-OCRv2/chinese/ch_PP-OCRv2_rec_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese and English ultra-lightweight PP-OCR model (9.4M)&lt;/td&gt; &#xA;   &lt;td&gt;ch_ppocr_mobile_v2.0_xx&lt;/td&gt; &#xA;   &lt;td&gt;Mobile &amp;amp; server&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_det_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_det_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_rec_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_rec_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese and English general PP-OCR model (143.4M)&lt;/td&gt; &#xA;   &lt;td&gt;ch_ppocr_server_v2.0_xx&lt;/td&gt; &#xA;   &lt;td&gt;Server&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_server_v2.0_det_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_server_v2.0_det_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_server_v2.0_rec_infer.tar&#34;&gt;inference model&lt;/a&gt; / &lt;a href=&#34;https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_server_v2.0_rec_train.tar&#34;&gt;trained model&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For more model downloads (including multiple languages), please refer to &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/models_list_en.md&#34;&gt;PP-OCR series model downloads&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;For a new language request, please refer to &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/#language_requests&#34;&gt;Guideline for new language_requests&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;For structural document analysis models, please refer to &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/docs/models_list_en.md&#34;&gt;PP-Structure models&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;📖 Tutorials&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/environment_en.md&#34;&gt;Environment Preparation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/ppocr_introduction_en.md&#34;&gt;PP-OCR 🔥&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/quickstart_en.md&#34;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/models_en.md&#34;&gt;Model Zoo&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/training_en.md&#34;&gt;Model training&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/detection_en.md&#34;&gt;Text Detection&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/recognition_en.md&#34;&gt;Text Recognition&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/angle_class_en.md&#34;&gt;Text Direction Classification&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Model Compression &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/deploy/slim/quantization/README_en.md&#34;&gt;Model Quantization&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/deploy/slim/prune/README_en.md&#34;&gt;Model Pruning&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/knowledge_distillation_en.md&#34;&gt;Knowledge Distillation&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/deploy/README.md&#34;&gt;Inference and Deployment&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/inference_ppocr_en.md&#34;&gt;Python Inference&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/deploy/cpp_infer/readme.md&#34;&gt;C++ Inference&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/deploy/pdserving/README.md&#34;&gt;Serving&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/deploy/lite/readme.md&#34;&gt;Mobile&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/deploy/paddle2onnx/readme.md&#34;&gt;Paddle2ONNX&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/deploy/paddlecloud/README.md&#34;&gt;PaddleCloud&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/benchmark_en.md&#34;&gt;Benchmark&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/README.md&#34;&gt;PP-Structure 🔥&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/docs/quickstart_en.md&#34;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/docs/models_list_en.md&#34;&gt;Model Zoo&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/training_en.md&#34;&gt;Model training&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/layout/README.md&#34;&gt;Layout Analysis&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/table/README.md&#34;&gt;Table Recognition&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/kie/README.md&#34;&gt;Key Information Extraction&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/deploy/README.md&#34;&gt;Inference and Deployment&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/docs/inference_en.md&#34;&gt;Python Inference&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/deploy/cpp_infer/readme.md&#34;&gt;C++ Inference&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/deploy/hubserving/readme_en.md&#34;&gt;Serving&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_overview_en.md&#34;&gt;Academic Algorithms&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_overview_en.md&#34;&gt;Text detection&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_overview_en.md&#34;&gt;Text recognition&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_overview_en.md&#34;&gt;End-to-end OCR&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_overview_en.md&#34;&gt;Table Recognition&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/algorithm_overview_en.md&#34;&gt;Key Information Extraction&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/add_new_algorithm_en.md&#34;&gt;Add New Algorithms to PaddleOCR&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Data Annotation and Synthesis &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/PPOCRLabel/README.md&#34;&gt;Semi-automatic Annotation Tool: PPOCRLabel&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/StyleText/README.md&#34;&gt;Data Synthesis Tool: Style-Text&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/data_annotation_en.md&#34;&gt;Other Data Annotation Tools&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/data_synthesis_en.md&#34;&gt;Other Data Synthesis Tools&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Datasets &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/dataset/datasets_en.md&#34;&gt;General OCR Datasets(Chinese/English)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/dataset/handwritten_datasets_en.md&#34;&gt;HandWritten_OCR_Datasets(Chinese)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/dataset/vertical_and_multilingual_datasets_en.md&#34;&gt;Various OCR Datasets(multilingual)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/dataset/layout_datasets_en.md&#34;&gt;Layout Analysis&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/dataset/table_datasets_en.md&#34;&gt;Table Recognition&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/dataset/kie_datasets_en.md&#34;&gt;Key Information Extraction&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/tree_en.md&#34;&gt;Code Structure&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/#Visualization&#34;&gt;Visualization&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/#Community&#34;&gt;Community&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/#language_requests&#34;&gt;New language requests&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/FAQ_en.md&#34;&gt;FAQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/reference_en.md&#34;&gt;References&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/#LICENSE&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a name=&#34;Visualization&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;👀 Visualization &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/doc_en/visualization_en.md&#34;&gt;more&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;PP-OCRv3 Chinese model&lt;/summary&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/imgs_results/PP-OCRv3/ch/PP-OCRv3-pic001.jpg&#34; width=&#34;800&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/imgs_results/PP-OCRv3/ch/PP-OCRv3-pic002.jpg&#34; width=&#34;800&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/imgs_results/PP-OCRv3/ch/PP-OCRv3-pic003.jpg&#34; width=&#34;800&#34;&gt; &#xA; &lt;/div&gt; &#xA;&lt;/details&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;PP-OCRv3 English model&lt;/summary&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/imgs_results/PP-OCRv3/en/en_1.png&#34; width=&#34;800&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/imgs_results/PP-OCRv3/en/en_2.png&#34; width=&#34;800&#34;&gt; &#xA; &lt;/div&gt; &#xA;&lt;/details&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;PP-OCRv3 Multilingual model&lt;/summary&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/imgs_results/PP-OCRv3/multi_lang/japan_2.jpg&#34; width=&#34;800&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/doc/imgs_results/PP-OCRv3/multi_lang/korean_1.jpg&#34; width=&#34;800&#34;&gt; &#xA; &lt;/div&gt; &#xA;&lt;/details&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;PP-Structurev2&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;layout analysis + table recognition&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppstructure/docs/table/ppstructure.GIF&#34; width=&#34;800&#34;&gt; &#xA; &lt;/div&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;SER (Semantic entity recognition)&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://user-images.githubusercontent.com/25809855/186094456-01a1dd11-1433-4437-9ab2-6480ac94ec0a.png&#34; width=&#34;600&#34;&gt; &#xA; &lt;/div&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://user-images.githubusercontent.com/14270174/185310636-6ce02f7c-790d-479f-b163-ea97a5a04808.jpg&#34; width=&#34;600&#34;&gt; &#xA; &lt;/div&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://user-images.githubusercontent.com/14270174/185539517-ccf2372a-f026-4a7c-ad28-c741c770f60a.png&#34; width=&#34;600&#34;&gt; &#xA; &lt;/div&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;RE (Relation Extraction)&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://user-images.githubusercontent.com/25809855/186094813-3a8e16cc-42e5-4982-b9f4-0134dfb5688d.png&#34; width=&#34;600&#34;&gt; &#xA; &lt;/div&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://user-images.githubusercontent.com/14270174/185393805-c67ff571-cf7e-4217-a4b0-8b396c4f22bb.jpg&#34; width=&#34;600&#34;&gt; &#xA; &lt;/div&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://user-images.githubusercontent.com/14270174/185540080-0431e006-9235-4b6d-b63d-0b3c6e1de48f.jpg&#34; width=&#34;600&#34;&gt; &#xA; &lt;/div&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;a name=&#34;language_requests&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🇺🇳 Guideline for New Language Requests&lt;/h2&gt; &#xA;&lt;p&gt;If you want to request a new language support, a PR with 1 following files are needed：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;In folder &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.6/ppocr/utils/dict&#34;&gt;ppocr/utils/dict&lt;/a&gt;, it is necessary to submit the dict text to this path and name it with &lt;code&gt;{language}_dict.txt&lt;/code&gt; that contains a list of all characters. Please see the format example from other files in that folder.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;If your language has unique elements, please tell me in advance within any way, such as useful links, wikipedia and so on.&lt;/p&gt; &#xA;&lt;p&gt;More details, please refer to &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleOCR/issues/1048&#34;&gt;Multilingual OCR Development Plan&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;LICENSE&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;📄 License&lt;/h2&gt; &#xA;&lt;p&gt;This project is released under &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleOCR/raw/master/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>