<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-01T02:23:10Z</updated>
  <subtitle>Monthly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>biobootloader/wolverine</title>
    <updated>2023-05-01T02:23:10Z</updated>
    <id>tag:github.com,2023-05-01:/biobootloader/wolverine</id>
    <link href="https://github.com/biobootloader/wolverine" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Wolverine&lt;/h1&gt; &#xA;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;p&gt;Give your python scripts regenerative healing abilities!&lt;/p&gt; &#xA;&lt;p&gt;Run your scripts with Wolverine and when they crash, GPT-4 edits them and explains what went wrong. Even if you have many bugs it will repeatedly rerun until it&#39;s fixed.&lt;/p&gt; &#xA;&lt;p&gt;For a quick demonstration see my &lt;a href=&#34;https://twitter.com/bio_bootloader/status/1636880208304431104&#34;&gt;demo video on twitter&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 -m venv venv&#xA;source venv/bin/activate&#xA;pip install -r requirements.txt&#xA;cp .env.sample .env&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Add your openAI api key to &lt;code&gt;.env&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;warning!&lt;/em&gt; By default wolverine uses GPT-4 and may make many repeated calls to the api.&lt;/p&gt; &#xA;&lt;h2&gt;Example Usage&lt;/h2&gt; &#xA;&lt;p&gt;To run with gpt-4 (the default, tested option):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m wolverine examples/buggy_script.py &#34;subtract&#34; 20 3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also run with other models, but be warned they may not adhere to the edit format as well:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m wolverine --model=gpt-3.5-turbo examples/buggy_script.py &#34;subtract&#34; 20 3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to use GPT-3.5 by default instead of GPT-4 uncomment the default model line in &lt;code&gt;.env&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;DEFAULT_MODEL=gpt-3.5-turbo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also use flag &lt;code&gt;--confirm=True&lt;/code&gt; which will ask you &lt;code&gt;yes or no&lt;/code&gt; before making changes to the file. If flag is not used then it will apply the changes to the file&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m wolverine examples/buggy_script.py &#34;subtract&#34; 20 3 --confirm=True&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Environment variables&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;env name&lt;/th&gt; &#xA;   &lt;th&gt;description&lt;/th&gt; &#xA;   &lt;th&gt;default value&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OPENAI_API_KEY&lt;/td&gt; &#xA;   &lt;td&gt;OpenAI API key&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DEFAULT_MODEL&lt;/td&gt; &#xA;   &lt;td&gt;GPT model to use&lt;/td&gt; &#xA;   &lt;td&gt;&#34;gpt-4&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;VALIDATE_JSON_RETRY&lt;/td&gt; &#xA;   &lt;td&gt;Number of retries when requesting OpenAI API (-1 means unlimites)&lt;/td&gt; &#xA;   &lt;td&gt;-1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Future Plans&lt;/h2&gt; &#xA;&lt;p&gt;This is just a quick prototype I threw together in a few hours. There are many possible extensions and contributions are welcome:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;add flags to customize usage, such as asking for user confirmation before running changed code&lt;/li&gt; &#xA; &lt;li&gt;further iterations on the edit format that GPT responds in. Currently it struggles a bit with indentation, but I&#39;m sure that can be improved&lt;/li&gt; &#xA; &lt;li&gt;a suite of example buggy files that we can test prompts on to ensure reliability and measure improvement&lt;/li&gt; &#xA; &lt;li&gt;multiple files / codebases: send GPT everything that appears in the stacktrace&lt;/li&gt; &#xA; &lt;li&gt;graceful handling of large files - should we just send GPT relevant classes / functions?&lt;/li&gt; &#xA; &lt;li&gt;extension to languages other than python&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#biobootloader/wolverine&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=biobootloader/wolverine&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>pengzhile/pandora</title>
    <updated>2023-05-01T02:23:10Z</updated>
    <id>tag:github.com,2023-05-01:/pengzhile/pandora</id>
    <link href="https://github.com/pengzhile/pandora" rel="alternate"></link>
    <summary type="html">&lt;p&gt;潘多拉，一个让你呼吸顺畅的ChatGPT。Pandora, a ChatGPT that helps you breathe smoothly.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Pandora&lt;/h1&gt; &#xA;&lt;p&gt;潘多拉 (Pandora)，一个让你呼吸顺畅的 ChatGPT。&lt;/p&gt; &#xA;&lt;p&gt;潘多拉实现了网页版 ChatGPT 的主要操作。后端优化，绕过 Cloudflare，速度喜人。&lt;/p&gt; &#xA;&lt;!-- PROJECT SHIELDS --&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/python-%3E%3D3.7-green&#34; alt=&#34;Python version&#34;&gt; &lt;a href=&#34;https://github.com/pengzhile/pandora/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-raw/pengzhile/pandora&#34; alt=&#34;Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pengzhile/pandora/commits/master&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/last-commit/pengzhile/pandora/master&#34; alt=&#34;Commits&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/pandora-chatgpt&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/pandora-chatgpt.svg?sanitize=true&#34; alt=&#34;PyPi&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/pandora-chatgpt&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/badge/pandora-chatgpt&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pengzhile/pandora/actions/workflows/python-publish.yml&#34;&gt;&lt;img src=&#34;https://github.com/pengzhile/pandora/actions/workflows/python-publish.yml/badge.svg?sanitize=true&#34; alt=&#34;PyPi workflow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pengzhile/pandora/actions/workflows/docker-publish.yml&#34;&gt;&lt;img src=&#34;https://github.com/pengzhile/pandora/actions/workflows/docker-publish.yml/badge.svg?sanitize=true&#34; alt=&#34;Docker workflow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/QBkd9JAaWa&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1098772912242163795?label=Discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;体验地址&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;点击 &lt;a href=&#34;https://chat.zhile.io&#34; target=&#34;_blank&#34; title=&#34;Pandora Cloud体验地址&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://chat.zhile.io&#34;&gt;https://chat.zhile.io&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;登录不可用，暂时需要官方登录，然后访问 &lt;a href=&#34;http://chat.openai.com/api/auth/session&#34;&gt;这里&lt;/a&gt; 拿 &lt;code&gt;Access Token&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Access Token&lt;/code&gt; 有效期 &lt;code&gt;14&lt;/code&gt; 天，期间访问&lt;strong&gt;不需要梯子&lt;/strong&gt;。这意味着你在手机上也可随意使用。&lt;/li&gt; &#xA; &lt;li&gt;这个页面上还包含一个共享账号的链接，&lt;strong&gt;没有账号&lt;/strong&gt;的可以点进去体验一下。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ChatGPT使用时可能会遇到：&lt;/h2&gt; &#xA;&lt;h3&gt;1. Please stand by, while we are checking your browser...&lt;/h3&gt; &#xA;&lt;h3&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;动不动来一下，有时候还不动或者出人机验证。痛！&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/t0.png&#34; alt=&#34;t0&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;2. Access denied. You do not have access to chat.openai.com.&lt;/h3&gt; &#xA;&lt;h3&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;经典问题，只能到处找可用VPN，费时费力，更费钱。移动端访问更难。痛！&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/t1.png&#34; alt=&#34;t1&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;3. ChatGPT is at capacity right now&lt;/h3&gt; &#xA;&lt;h3&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;系统负载高，白嫖用户不给用。痛！&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/t2.png&#34; alt=&#34;t2&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;4. This content may violate our &lt;u&gt;content policy&lt;/u&gt;.&lt;/h3&gt; &#xA;&lt;h3&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;道德审查，多触发几次可能就封号了。痛！！！&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/t3.png&#34; alt=&#34;t3&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;5. Something went wrong.&lt;/h3&gt; &#xA;&lt;h3&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;吃着火锅唱着歌，突然就出故障了。痛！&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/t4.png&#34; alt=&#34;t4&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;6. 输出代码时中断，但是却没有一个 &lt;code&gt;Continue generating&lt;/code&gt; 按钮。痛！&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/t5.png&#34; alt=&#34;t5&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/t6.png&#34; alt=&#34;t6&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;7. 蹦字慢吞吞，卡顿不流畅，不知道的甚至想换电脑。痛！&lt;/h3&gt; &#xA;&lt;h3&gt;8. 想把 &lt;code&gt;ChatGPT&lt;/code&gt; 接到其他系统，结果只能接个差强人意的 &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;。痛！&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;em&gt;一次看完上面的噩梦，血压上来了，拳头硬了！太痛了！！！以上痛点，&lt;code&gt;Pandora&lt;/code&gt; 一次全部解决。&lt;/em&gt;&lt;/h3&gt; &#xA;&lt;h2&gt;界面截图&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;p&gt;&lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s05.png&#34; alt=&#34;alt Screenshot5&#34;&gt;&lt;br&gt; &lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s10.jpeg&#34; alt=&#34;alt Screenshot10&#34;&gt;&lt;/p&gt; &lt;/summary&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s01.png&#34; alt=&#34;alt Screenshot1&#34;&gt;&lt;br&gt; &lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s02.png&#34; alt=&#34;alt Screenshot2&#34;&gt;&lt;br&gt; &lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s03.png&#34; alt=&#34;alt Screenshot3&#34;&gt;&lt;br&gt; &lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s04.png&#34; alt=&#34;alt Screenshot4&#34;&gt;&lt;br&gt; &lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s06.png&#34; alt=&#34;alt Screenshot6&#34;&gt;&lt;br&gt; &lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s11.jpeg&#34; alt=&#34;alt Screenshot11&#34;&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;如何搭建运行&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;访问 &lt;a href=&#34;https://github.com/pengzhile/pandora/raw/master/doc/wiki.md&#34;&gt;doc/wiki.md&lt;/a&gt; 获得详细指导。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;其他说明&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;项目是站在其他巨人的肩膀上，感谢！&lt;/li&gt; &#xA; &lt;li&gt;报错、BUG之类的提出&lt;code&gt;Issue&lt;/code&gt;，我会修复。&lt;/li&gt; &#xA; &lt;li&gt;因为之后&lt;code&gt;ChatGPT&lt;/code&gt;的API变动，我可能不会跟进修复。&lt;/li&gt; &#xA; &lt;li&gt;喜欢的可以给颗星，都是老朋友了。&lt;/li&gt; &#xA; &lt;li&gt;不影响&lt;code&gt;PHP是世界上最好的编程语言！&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;贡献者们&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;感谢所有让这个项目变得更好的贡献者们！&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/pengzhile/pandora/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=pengzhile/pandora&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Star历史&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=pengzhile/pandora&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ymcui/Chinese-LLaMA-Alpaca</title>
    <updated>2023-05-01T02:23:10Z</updated>
    <id>tag:github.com,2023-05-01:/ymcui/Chinese-LLaMA-Alpaca</id>
    <link href="https://github.com/ymcui/Chinese-LLaMA-Alpaca" rel="alternate"></link>
    <summary type="html">&lt;p&gt;中文LLaMA&amp;Alpaca大语言模型+本地CPU/GPU部署 (Chinese LLaMA &amp; Alpaca LLMs)&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/README.md&#34;&gt;&lt;strong&gt;中文&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/README_EN.md&#34;&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki&#34;&gt;&lt;strong&gt;文档/Docs&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/pics/banner.png&#34; width=&#34;600&#34;&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img alt=&#34;GitHub&#34; src=&#34;https://img.shields.io/github/license/ymcui/Chinese-LLaMA-Alpaca.svg?color=blue&amp;amp;style=flat-square&#34;&gt; &lt;img alt=&#34;GitHub release (latest by date)&#34; src=&#34;https://img.shields.io/github/v/release/ymcui/Chinese-LLaMA-Alpaca&#34;&gt; &lt;img alt=&#34;GitHub top language&#34; src=&#34;https://img.shields.io/github/languages/top/ymcui/Chinese-LLaMA-Alpaca&#34;&gt; &lt;img alt=&#34;GitHub last commit&#34; src=&#34;https://img.shields.io/github/last-commit/ymcui/Chinese-LLaMA-Alpaca&#34;&gt; &lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki&#34;&gt;&lt;img alt=&#34;GitHub wiki&#34; src=&#34;https://img.shields.io/badge/Github%20Wiki-v3.0-green&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;以ChatGPT、GPT-4等为代表的大语言模型（Large Language Model, LLM）掀起了新一轮自然语言处理领域的研究浪潮，展现出了类通用人工智能（AGI）的能力，受到业界广泛关注。然而，由于大语言模型的训练和部署都极为昂贵，为构建透明且开放的学术研究造成了一定的阻碍。&lt;/p&gt; &#xA;&lt;p&gt;为了促进大模型在中文NLP社区的开放研究，本项目开源了&lt;strong&gt;中文LLaMA模型和指令精调的Alpaca大模型&lt;/strong&gt;。这些模型&lt;strong&gt;在原版LLaMA的基础上扩充了中文词表&lt;/strong&gt;并使用了中文数据进行二次预训练，进一步提升了中文基础语义理解能力。同时，中文Alpaca模型进一步使用了中文指令数据进行精调，显著提升了模型对指令的理解和执行能力。详细内容请参考技术报告&lt;a href=&#34;https://arxiv.org/abs/2304.08177&#34;&gt;(Cui, Yang, and Yao, 2023)&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;本项目主要内容：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🚀 针对原版LLaMA模型扩充了中文词表，提升了中文编解码效率&lt;/li&gt; &#xA; &lt;li&gt;🚀 开源了使用中文文本数据预训练的中文LLaMA以及经过指令精调的中文Alpaca&lt;/li&gt; &#xA; &lt;li&gt;🚀 快速使用笔记本电脑（个人PC）的CPU/GPU本地量化和部署体验大模型&lt;/li&gt; &#xA; &lt;li&gt;🚀 支持&lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;🤗transformers&lt;/a&gt;, &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt;, &lt;a href=&#34;https://github.com/oobabooga/text-generation-webui&#34;&gt;text-generation-webui&lt;/a&gt;, &lt;a href=&#34;https://github.com/alexrozanski/LlamaChat&#34;&gt;LlamaChat&lt;/a&gt;等生态&lt;/li&gt; &#xA; &lt;li&gt;目前已开源的模型版本：7B（标准版、&lt;strong&gt;Plus版&lt;/strong&gt;）、13B（标准版）&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;💡 下图是中文Alpaca-7B模型在本地CPU量化部署后的实际体验效果（GIF未加速，M1 Max下实测）。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/pics/screencast.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/iflytek/VLE&#34;&gt;多模态VLE&lt;/a&gt; | &lt;a href=&#34;https://github.com/iflytek/MiniRBT&#34;&gt;中文MiniRBT&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/LERT&#34;&gt;中文LERT&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/PERT&#34;&gt;中英文PERT&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/MacBERT&#34;&gt;中文MacBERT&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/Chinese-ELECTRA&#34;&gt;中文ELECTRA&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/Chinese-XLNet&#34;&gt;中文XLNet&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/Chinese-BERT-wwm&#34;&gt;中文BERT&lt;/a&gt; | &lt;a href=&#34;https://github.com/airaria/TextBrewer&#34;&gt;知识蒸馏工具TextBrewer&lt;/a&gt; | &lt;a href=&#34;https://github.com/airaria/TextPruner&#34;&gt;模型裁剪工具TextPruner&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;新闻&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;[2023/04/28] &lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/releases/tag/v3.0&#34;&gt;Release v3.0&lt;/a&gt;: 发布中文LLaMA/Alpaca Plus版本（7B），使用了更大的语料进行训练，相比基础版各项能力显著提升。另外还进一步完善了评测流程、添加了预训练脚本等。&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;[2023/04/18] Release v2.2：添加LlamaChat支持、中文词表以及LLaMA Tokenizer的词表扩充脚本、添加技术报告等。请参考：&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/releases/tag/v2.2&#34;&gt;Release Note&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;[2023/04/13] Release v2.1：添加HuggingFace推理接口、text-generation-webui接口。请参考：&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/releases/tag/v2.1&#34;&gt;Release Note&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;[2023/04/07] Release v2.0：发布13B版本中文LLaMA、Alpaca大模型，主要升级：更强的事实性、文本问答、翻译、伦理拒答等能力全面提升！更多更新内容请参考：&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/releases/tag/v2.0&#34;&gt;Release Note&lt;/a&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;往期新闻&lt;/b&gt;&lt;/summary&gt; [2023/04/03] 添加了模型合并和量化的notebook，Colab Pro(+)用户可在线合并和下载模型。请参考：[合并模型](#合并模型) &#xA; &lt;p&gt;[2023/03/31] Release v1.1：简化模型合并步骤、添加指令数据爬取脚本、关于新版本llama.cpp的重要提示。请参考：&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/releases/tag/v1.1&#34;&gt;Release Note&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;[2023/03/28] 正式开源中文LLaMA、Alpaca大模型，目前提供7B版本下载体验&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;内容导引&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;章节&lt;/th&gt; &#xA;   &lt;th&gt;描述&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/#%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD&#34;&gt;⏬模型下载&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;中文LLaMA、Alpaca大模型下载地址&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/#%E5%90%88%E5%B9%B6%E6%A8%A1%E5%9E%8B&#34;&gt;🈴合并模型&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;（重要）介绍如何将下载的LoRA模型与原版LLaMA合并&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/#%E6%9C%AC%E5%9C%B0%E6%8E%A8%E7%90%86%E4%B8%8E%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2&#34;&gt;💻本地推理与快速部署&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;介绍了如何对模型进行量化并使用个人电脑部署并体验大模型&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/#%E7%B3%BB%E7%BB%9F%E6%95%88%E6%9E%9C&#34;&gt;💯系统效果&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;介绍了部分场景和任务下的使用体验效果&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/#%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82&#34;&gt;📝训练细节&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;介绍了中文LLaMA、Alpaca大模型的训练细节&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/#FAQ&#34;&gt;❓FAQ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;一些常见问题的回复&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/#%E5%B1%80%E9%99%90%E6%80%A7&#34;&gt;⚠️局限性&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;本项目涉及模型的局限性&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;模型下载&lt;/h2&gt; &#xA;&lt;h3&gt;用户须知（必读）&lt;/h3&gt; &#xA;&lt;p&gt;Facebook官方发布的&lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;LLaMA模型禁止商用&lt;/a&gt;，并且官方没有正式开源模型权重（虽然网上已经有很多第三方的下载地址）。为了遵循相应的许可，目前暂时无法发布完整的模型权重，敬请各位理解（目前国外也是一样）。Facebook完全开放模型权重之后，本项目会及时更新相关策略。&lt;strong&gt;这里发布的是LoRA权重&lt;/strong&gt;，可以理解为原LLaMA模型上的一个“补丁”，两者进行合并即可获得完整版权重。以下中文LLaMA/Alpaca LoRA模型无法单独使用，需要搭配&lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;原版LLaMA模型&lt;/a&gt;。请参考本项目给出的&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/#%E5%90%88%E5%B9%B6%E6%A8%A1%E5%9E%8B&#34;&gt;合并模型&lt;/a&gt;步骤重构模型。&lt;/p&gt; &#xA;&lt;h3&gt;我应该选什么模型？&lt;/h3&gt; &#xA;&lt;p&gt;下面是中文LLaMA和Alpaca模型的基本对比以及建议使用场景（包括但不限于），更多内容见&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/#%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82&#34;&gt;训练细节&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;p&gt;💡 &lt;strong&gt;推荐使用Plus版&lt;/strong&gt;，模型体积与基础版相同，但使用了更多数据进行训练。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;对比项&lt;/th&gt; &#xA;   &lt;th&gt;中文LLaMA&lt;/th&gt; &#xA;   &lt;th&gt;中文Alpaca&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;训练方式&lt;/td&gt; &#xA;   &lt;td&gt;传统CLM&lt;/td&gt; &#xA;   &lt;td&gt;指令精调&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;训练语料&lt;/td&gt; &#xA;   &lt;td&gt;无标注通用语料&lt;/td&gt; &#xA;   &lt;td&gt;有标注指令数据&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;输入模板&lt;/td&gt; &#xA;   &lt;td&gt;不需要&lt;/td&gt; &#xA;   &lt;td&gt;需要符合模板要求&lt;sup&gt;[1]&lt;/sup&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;适用场景 ✔️&lt;/td&gt; &#xA;   &lt;td&gt;文本续写：给定上文内容，让模型继续写下去，生成下文&lt;/td&gt; &#xA;   &lt;td&gt;1、指令理解（问答、写作、建议等）&lt;br&gt;2、多轮上下文理解（聊天等）&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;不适用场景 ❌&lt;/td&gt; &#xA;   &lt;td&gt;指令理解 、多轮聊天等&lt;/td&gt; &#xA;   &lt;td&gt;文本无限制自由生成&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;llama.cpp&lt;/td&gt; &#xA;   &lt;td&gt;使用&lt;code&gt;-p&lt;/code&gt;参数指定上文&lt;/td&gt; &#xA;   &lt;td&gt;使用&lt;code&gt;-ins&lt;/code&gt;参数启动指令理解+聊天模式&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;text-generation-webui&lt;/td&gt; &#xA;   &lt;td&gt;不适合chat模式&lt;/td&gt; &#xA;   &lt;td&gt;使用&lt;code&gt;--cpu&lt;/code&gt;可在无显卡形式下运行，若生成内容不满意，建议修改prompt&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;LlamaChat&lt;/td&gt; &#xA;   &lt;td&gt;加载模型时选择&#34;LLaMA&#34;&lt;/td&gt; &#xA;   &lt;td&gt;加载模型时选择&#34;Alpaca&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/scripts/inference_hf.py&#34;&gt;HF推理代码&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;无需添加额外启动参数&lt;/td&gt; &#xA;   &lt;td&gt;启动时添加参数 &lt;code&gt;--with_prompt&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;已知问题&lt;/td&gt; &#xA;   &lt;td&gt;如果不控制终止，则会一直写下去，直到达到输出长度上限。&lt;sup&gt;[2]&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td&gt;目前版本模型生成的文本长度相对短一些，比较惜字如金。&lt;sup&gt;[2]&lt;/sup&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;em&gt;[1] llama.cpp/LlamaChat/&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/scripts/inference_hf.py&#34;&gt;HF推理代码&lt;/a&gt;等已内嵌，无需手动添加模板。&lt;/em&gt;&lt;br&gt; &lt;em&gt;[2] 如果出现了模型回答质量特别低、胡言乱语、不理解问题等情况，请检查是否针对场景使用了正确的模型和正确的启动参数。&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;中文LLaMA模型&lt;/h3&gt; &#xA;&lt;p&gt;中文LLaMA模型在原版的基础上扩充了中文词表，使用了中文通用纯文本数据进行二次预训练。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;模型名称&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;训练数据&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;重构模型&lt;sup&gt;[1]&lt;/sup&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;大小&lt;sup&gt;[2]&lt;/sup&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;LoRA下载&lt;sup&gt;[3]&lt;/sup&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Chinese-LLaMA-7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;通用20G&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;原版LLaMA-7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;770M&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://pan.baidu.com/s/1oORTdpr2TvlkxjpyWtb5Sw?pwd=33hb&#34;&gt;[百度网盘]&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/1iQp9T-BHjBjIrFWXq_kIm_cyNmpvv5WN/view?usp=sharing&#34;&gt;[Google Drive]&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Chinese-LLaMA-Plus-7B ⭐️&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;通用120G&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;原版LLaMA-7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;790M&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://pan.baidu.com/s/1zvyX9FN-WSRDdrtMARxxfw?pwd=2gtr&#34;&gt;[百度网盘]&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/1N97m3rBj-rp-J1X8rgRfluyomEscfAq0/view?usp=sharing&#34;&gt;[Google Drive]&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Chinese-LLaMA-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;通用20G&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;原版LLaMA-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1G&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://pan.baidu.com/s/1BxFhYhDMipW7LwI58cGmQQ?pwd=ef3t&#34;&gt;[百度网盘]&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/12q9EH4mfKRnoKlbkkhzv1xDwWnroo9VS/view?usp=sharing&#34;&gt;[Google Drive]&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;中文Alpaca模型&lt;/h3&gt; &#xA;&lt;p&gt;中文Alpaca模型在上述中文LLaMA模型的基础上进一步使用了指令数据进行精调。&lt;strong&gt;如希望体验类ChatGPT对话交互，请使用Alpaca模型，而不是LLaMA模型。&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;模型名称&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;训练数据&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;重构模型&lt;sup&gt;[1]&lt;/sup&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;大小&lt;sup&gt;[2]&lt;/sup&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;LoRA下载&lt;sup&gt;[3]&lt;/sup&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Chinese-Alpaca-7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;指令2M&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;原版LLaMA-7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;790M&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://pan.baidu.com/s/1xV1UXjh1EPrPtXg6WyG7XQ?pwd=923e&#34;&gt;[百度网盘]&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/1JvFhBpekYiueWiUL3AF1TtaWDb3clY5D/view?usp=sharing&#34;&gt;[Google Drive]&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Chinese-Alpaca-Plus-7B ⭐️&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;指令4M&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;em&gt;原版LLaMA-7B &amp;amp;&lt;br&gt;Chinese-LLaMA-Plus-7B&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.1G&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://pan.baidu.com/s/12tjjxmDWwLBM8Tj_7FAjHg?pwd=32hc&#34;&gt;[百度网盘]&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/1EDcTmq6tDmRxqarpapdyDGBE9opY0zrB/view?usp=share_link&#34;&gt;[Google Drive]&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Chinese-Alpaca-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;指令3M&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;原版LLaMA-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.1G&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://pan.baidu.com/s/1wYoSF58SnU9k0Lndd5VEYg?pwd=mm8i&#34;&gt;[百度网盘]&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/1gzMc0xMCpXsXmU1uxFlgQ8VRnWNtDjD8/view?usp=share_link&#34;&gt;[Google Drive]&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Model Hub&lt;/h3&gt; &#xA;&lt;p&gt;可以在🤗Model Hub下载以上所有模型，并且使用&lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;transformers&lt;/a&gt;和&lt;a href=&#34;https://github.com/huggingface/peft&#34;&gt;PEFT&lt;/a&gt;调用中文LLaMA或Alpaca LoRA模型。以下模型调用名称指的是使用&lt;code&gt;.from_pretrained()&lt;/code&gt;中指定的模型名称。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;模型名&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;模型调用名称&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;链接&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese-LLaMA-7B&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;ziqingyang/chinese-llama-lora-7b&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/ziqingyang/chinese-llama-lora-7b&#34;&gt;Model Hub Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese-LLaMA-Plus-7B&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;ziqingyang/chinese-llama-plus-lora-7b&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/ziqingyang/chinese-llama-plus-lora-7b&#34;&gt;Model Hub Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese-LLaMA-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;ziqingyang/chinese-llama-lora-13b&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/ziqingyang/chinese-llama-lora-13b&#34;&gt;Model Hub Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese-Alpaca-7B&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;ziqingyang/chinese-alpaca-lora-7b&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/ziqingyang/chinese-alpaca-lora-7b&#34;&gt;Model Hub Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese-Alpaca-Plus-7B&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;ziqingyang/chinese-alpaca-plus-lora-7b&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/ziqingyang/chinese-alpaca-plus-lora-7b&#34;&gt;Model Hub Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese-Alpaca-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;ziqingyang/chinese-alpaca-lora-13b&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/ziqingyang/chinese-alpaca-lora-13b&#34;&gt;Model Hub Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;脚注及其他说明&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;[1]&lt;/strong&gt; 重构需要原版LLaMA模型，&lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;去LLaMA项目申请使用&lt;/a&gt;或参考这个&lt;a href=&#34;https://github.com/facebookresearch/llama/pull/73/files&#34;&gt;PR&lt;/a&gt;。因版权问题本项目无法提供下载链接。&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;[2]&lt;/strong&gt; 经过重构后的模型大小比同等量级的原版LLaMA大一些（主要因为扩充了词表）。&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;[3]&lt;/strong&gt; 下载后务必检查压缩包中模型文件的SHA256是否一致，请查看&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/SHA256.md&#34;&gt;SHA256.md&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;p&gt;压缩包内文件目录如下（以Chinese-LLaMA-7B为例）：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;chinese_llama_lora_7b/&#xA;  - adapter_config.json&#x9;&#x9;# LoRA权重配置文件&#xA;  - adapter_model.bin&#x9;&#x9;# LoRA权重文件&#xA;  - special_tokens_map.json&#x9;# special_tokens_map文件&#xA;  - tokenizer_config.json&#x9;# tokenizer配置文件&#xA;  - tokenizer.model&#x9;&#x9;# tokenizer文件 &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;以下是各原模型和4-bit量化后的大小，转换相应模型时确保本机有足够的内存和磁盘空间（最低要求）：&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;模型版本&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;7B&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;13B&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;33B&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;65B&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;原模型大小（FP16）&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13 GB&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24 GB&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;60 GB&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;120 GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;量化后大小（8-bit）&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.8 GB&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14.9 GB&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;量化后大小（4-bit）&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.9 GB&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.8 GB&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;19.5 GB&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.5 GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;合并模型&lt;/h2&gt; &#xA;&lt;p&gt;前面提到LoRA模型无法单独使用，必须与原版LLaMA进行合并才能转为完整模型，以便进行模型推理、量化或者进一步训练。请选择以下方法对模型进行转换合并。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;方式&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;适用场景&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;教程&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;在线转换&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Colab用户可利用本项目提供的notebook进行在线转换并量化模型&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E5%9C%A8%E7%BA%BF%E6%A8%A1%E5%9E%8B%E5%90%88%E5%B9%B6%E4%B8%8E%E8%BD%AC%E6%8D%A2&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;手动转换&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;离线方式转换，生成不同格式的模型，以便进行量化或进一步精调&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E6%89%8B%E5%8A%A8%E6%A8%A1%E5%9E%8B%E5%90%88%E5%B9%B6%E4%B8%8E%E8%BD%AC%E6%8D%A2&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;具体内容请参考本项目 &amp;gt;&amp;gt;&amp;gt; &lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E6%A8%A1%E5%9E%8B%E5%90%88%E5%B9%B6%E4%B8%8E%E8%BD%AC%E6%8D%A2&#34;&gt;📚 GitHub Wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;本地推理与快速部署&lt;/h2&gt; &#xA;&lt;p&gt;本项目中的模型主要支持以下量化、推理和部署方式。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;推理和部署方式&lt;/th&gt; &#xA;   &lt;th&gt;特点&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;平台&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;CPU&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;GPU&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;量化加载&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;图形界面&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;教程&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/ggerganov/llama.cp&#34;&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;丰富的量化选项和高效本地推理&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;通用&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;❌&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/llama.cpp%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;&lt;strong&gt;🤗Transformers&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;原生transformers推理接口&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;通用&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;❌&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E4%BD%BF%E7%94%A8Transformers%E6%8E%A8%E7%90%86&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/oobabooga/text-generation-webui&#34;&gt;&lt;strong&gt;text-generation-webui&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;前端Web UI界面的部署方式&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;通用&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E4%BD%BF%E7%94%A8text-generation-webui%E6%90%AD%E5%BB%BA%E7%95%8C%E9%9D%A2&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/alexrozanski/LlamaChat&#34;&gt;&lt;strong&gt;LlamaChat&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;macOS下的图形交互界面（需搭配llama.cpp模型）&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;MacOS&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;❌&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✅&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E4%BD%BF%E7%94%A8LlamaChat%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2%EF%BC%88macOS%EF%BC%89&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;具体内容请参考本项目 &amp;gt;&amp;gt;&amp;gt; &lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E4%B8%8E%E9%83%A8%E7%BD%B2&#34;&gt;📚 GitHub Wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;系统效果&lt;/h2&gt; &#xA;&lt;p&gt;为了快速评测相关模型的实际表现，本项目在给定相同的prompt的情况下，在一些常见任务上对比测试了本项目的中文Alpaca-7B、中文Alpaca-13B、中文Alpaca-Plus-7B的效果。生成回复具有随机性，受解码超参、随机种子等因素影响。以下相关评测并非绝对严谨，测试结果仅供晾晒参考，欢迎自行体验。详细评测结果请查看&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/examples/README.md&#34;&gt;examples/README.md&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;测试任务&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;详细样例&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;样例数&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Alpaca-7B&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Alpaca-13B&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Alpaca-Plus-7B&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;💯总平均分&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;200&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;65.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;70.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;👍🏻75.3&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;知识问答&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/examples/QA.md&#34;&gt;QA.md&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;66&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;74&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;👍🏻80&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;开放式问答&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/examples/OQA.md&#34;&gt;OQA.md&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;👍🏻79&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;74&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;👍🏻78&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;数值计算、推理&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/examples/REASONING.md&#34;&gt;REASONING.md&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;👍🏻50&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;诗词、文学、哲学&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/examples/LITERATURE.md&#34;&gt;LITERATURE.md&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;73&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;👍🏻76&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;音乐、体育、娱乐&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/examples/ENTERTAINMENT.md&#34;&gt;ENTERTAINMENT.md&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;74&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;👍🏻79&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;写信、写文章&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/examples/GENERATION.md&#34;&gt;GENERATION.md&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;76&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;👍🏻81&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;👍🏻81&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;文本翻译&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/examples/TRANSLATION.md&#34;&gt;TRANSLATION.md&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;76&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;78&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;👍🏻82&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;多轮交互&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/examples/DIALOGUE.md&#34;&gt;DIALOGUE.md&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;👍🏻83&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;73&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;👍🏻84&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;代码编程&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/examples/CODE.md&#34;&gt;CODE.md&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;57&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;👍🏻64&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;59&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;伦理、拒答&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/examples/ETHICS.md&#34;&gt;ETHICS.md&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;👍🏻89&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;em&gt;注：旧版Q4量化对比，请查看&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/examples-q4/README.md&#34;&gt;./examples-q4/README.md&lt;/a&gt;。&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;训练细节&lt;/h2&gt; &#xA;&lt;p&gt;整个训练流程包括词表扩充、预训练和指令精调三部分。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;本项目的模型均在原LLaMA词表的基础上扩充了中文单词，代码请参考&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca/main/scripts/merge_tokenizers.py&#34;&gt;merge_tokenizers.py&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;预训练和指令精调代码参考了🤗transformers中的&lt;a href=&#34;https://github.com/huggingface/transformers/raw/main/examples/pytorch/language-modeling/run_clm.py&#34;&gt;run_clm.py&lt;/a&gt;和&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt;项目中数据集处理的相关部分&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;具体内容请参考本项目 &amp;gt;&amp;gt;&amp;gt; &lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82&#34;&gt;📚 GitHub Wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;p&gt;FAQ中给出了常见问题的解答，请在提Issue前务必先查看FAQ。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;问题1：为什么不能放出完整版本权重？&#xA;问题2：后面会有33B、65B的版本吗？&#xA;问题3：一些任务上效果不好！&#xA;问题4：为什么要扩充词表？直接在原版LLaMA上用中文预训练不行吗？&#xA;问题5：回复内容很短&#xA;问题6：Windows下，模型无法理解中文、生成速度很慢等问题&#xA;问题7：Chinese-LLaMA 13B模型没法用llama.cpp启动，提示维度不一致&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;具体问题和解答请参考本项目 &amp;gt;&amp;gt;&amp;gt; &lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98&#34;&gt;📚 GitHub Wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;局限性&lt;/h2&gt; &#xA;&lt;p&gt;虽然本项目中的模型具备一定的中文理解和生成能力，但也存在局限性，包括但不限于：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;可能会产生不可预测的有害内容以及不符合人类偏好和价值观的内容&lt;/li&gt; &#xA; &lt;li&gt;由于算力和数据问题，相关模型的训练并不充分，中文理解能力有待进一步提升&lt;/li&gt; &#xA; &lt;li&gt;暂时没有在线可互动的demo（注：用户仍然可以自行在本地部署）&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;引用&lt;/h2&gt; &#xA;&lt;p&gt;如果您觉得本项目对您的研究有所帮助或使用了本项目的代码或数据，请参考引用本项目的技术报告：&lt;a href=&#34;https://arxiv.org/abs/2304.08177&#34;&gt;https://arxiv.org/abs/2304.08177&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{chinese-llama-alpaca,&#xA;      title={Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca}, &#xA;      author={Cui, Yiming and Yang, Ziqing and Yao, Xin},&#xA;      journal={arXiv preprint arXiv:2304.08177},&#xA;      url={https://arxiv.org/abs/2304.08177},&#xA;      year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;致谢&lt;/h2&gt; &#xA;&lt;p&gt;本项目基于以下开源项目二次开发，在此对相关项目和研究开发人员表示感谢。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;基础模型、代码&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;量化、推理、部署&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;数据&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;LLaMA by Facebook&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Alpaca by Stanford&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://github.com/tloen/alpaca-lora&#34;&gt;alpaca-lora by @tloen&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp by @ggerganov&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://github.com/alexrozanski/LlamaChat&#34;&gt;LlamaChat by @alexrozanski&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://github.com/oobabooga/text-generation-webui&#34;&gt;text-generation-webui by @oobabooga&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/brightmart/nlp_chinese_corpus&#34;&gt;pCLUE and translation data by @brightmart&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Episode: Logo中的小羊驼是由&lt;a href=&#34;http://midjourney.com&#34;&gt;midjourney&lt;/a&gt;自动生成，并由Mac自带的预览工具自动抠出来的。&lt;/p&gt; &#xA;&lt;h2&gt;免责声明&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;本项目相关资源仅供学术研究之用，严禁用于商业用途。&lt;/strong&gt; 使用涉及第三方代码的部分时，请严格遵循相应的开源协议。模型生成的内容受模型计算、随机性和量化精度损失等因素影响，本项目不对其准确性作出保证。对于模型输出的任何内容，本项目不承担任何法律责任，亦不对因使用相关资源和输出结果而可能产生的任何损失承担责任。&lt;/p&gt; &#xA;&lt;p&gt;本项目由个人及协作者业余时间发起并维护，因此无法保证能及时回复解决相应问题。&lt;/p&gt; &#xA;&lt;h2&gt;问题反馈&lt;/h2&gt; &#xA;&lt;p&gt;如有问题，请在GitHub Issue中提交。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;在提交问题之前，请先查看FAQ能否解决问题，同时建议查阅以往的issue是否能解决你的问题。&lt;/li&gt; &#xA; &lt;li&gt;提交问题请使用本项目设置的Issue模板，以帮助快速定位具体问题。&lt;/li&gt; &#xA; &lt;li&gt;重复以及与本项目无关的issue会被&lt;a href=&#34;https://github.com/marketplace/stale&#34;&gt;stable-bot&lt;/a&gt;处理，敬请谅解。&lt;/li&gt; &#xA; &lt;li&gt;礼貌地提出问题，构建和谐的讨论社区。&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>