<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Monthly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-03T02:29:49Z</updated>
  <subtitle>Monthly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>pittcsc/Summer2023-Internships</title>
    <updated>2022-06-03T02:29:49Z</updated>
    <id>tag:github.com,2022-06-03:/pittcsc/Summer2023-Internships</id>
    <link href="https://github.com/pittcsc/Summer2023-Internships" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Collection of Summer 2023 tech internships!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Summer 2023 Tech Internships by Pitt CSC üåÜüê¢&lt;/h1&gt; &#xA;&lt;p&gt;And we&#39;re back! Use this repo to share and keep track of software, tech, CS, PM, quant internships for Summer 2023. List maintained by &lt;a href=&#34;https://pittcsc.org/&#34;&gt;the Pitt Computer Science Club&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h3&gt; Thanks for a great two years üíñüíñ &lt;/h3&gt; &#xA; &lt;p&gt; &lt;img src=&#34;https://api.star-history.com/svg?repos=pittcsc/Summer2022-Internships&amp;amp;type=Date&#34; width=&#34;500&#34; alt=&#34;Star History&#34;&gt; &lt;/p&gt; &#xA; &lt;i&gt;Want to reach millions of CS students? Email &lt;a href=&#34;mailto:pittcsc@gmail.com?subject=Sponsoring the CSC Internship Repo&#34;&gt;pittcsc@gmail.com&lt;/a&gt; for partnership opportunities!&lt;/i&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt; &lt;a href=&#34;https://simplify.jobs/?utm_source=pittcsc&amp;amp;utm_medium=internships_repo&#34;&gt; &lt;b&gt;Applying to internships?&lt;/b&gt; &lt;br&gt; Autofill all your applications in a single click. &lt;br&gt; &lt;/a&gt;&lt;/p&gt;&#xA; &lt;div&gt;&#xA;  &lt;a href=&#34;https://simplify.jobs/?utm_source=pittcsc&amp;amp;utm_medium=internships_repo&#34;&gt; &lt;img src=&#34;https://res.cloudinary.com/dpeo4xcnc/image/upload/v1636594918/simplify_pittcsc.png&#34; width=&#34;450&#34; alt=&#34;Simplify&#34;&gt; &lt;/a&gt;&#xA; &lt;/div&gt;&#xA; &lt;a href=&#34;https://simplify.jobs/?utm_source=pittcsc&amp;amp;utm_medium=internships_repo&#34;&gt; &lt;/a&gt; &#xA; &lt;sub&gt;&lt;i&gt;Stop manually re-entering your information. Simplify‚Äôs extension helps you autofill internship applications on millions of sites.&lt;/i&gt;&lt;/sub&gt; &#xA; &lt;p&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; &lt;strong&gt;This repository is only for internships/co-ops in the United States, Canada or for Remote positions&lt;span&gt;üåé&lt;/span&gt;.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;üß† For tips on the internship process check out the &lt;a href=&#34;https://www.pittcs.wiki/zero-to-offer&#34;&gt;Zero to Offer&lt;/a&gt; üß†&lt;/p&gt; &#xA;&lt;p&gt;üôè &lt;strong&gt;Contribute by submitting a &lt;a href=&#34;https://github.com/susam/gitpr#create-pull-request&#34;&gt;pull request&lt;/a&gt;!&lt;/strong&gt; üôè&lt;/p&gt; &#xA;&lt;h2&gt;The List üëî&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Location&lt;/th&gt; &#xA;   &lt;th&gt;Notes&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.optiver.com/working-at-optiver/career-opportunities/5674025002/&#34;&gt;Optiver&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Chicago, IL&lt;/td&gt; &#xA;   &lt;td&gt;Interest&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://boards.greenhouse.io/bridgewater89/jobs/4076389002&#34;&gt;Bridgewater Associates&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Westport, CT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://fiverings.avature.net/careers/FolderDetail/New-York-New-York-United-States-Quantitative-Trading-Intern-Summer-2023/586&#34;&gt;Five Rings&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;NYC, NY&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://cvent.me/RLRe57?RefId=refWC2021&#34;&gt;Greylock Techfair&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Virtual&lt;/td&gt; &#xA;   &lt;td&gt;Not an internship but a great career fair, Learn more &lt;a href=&#34;https://greylock.com/university-programs/&#34;&gt;here&lt;/a&gt;!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://careers.aqr.com/jobs/university-open-positions/greenwich-ct/2023-summer-internship-express-interest/2194349?gh_jid=2194349#/&#34;&gt;AQR&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Greenwich, CT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://tas-creditsuisse.taleo.net/careersection/campus/moresearch.ftl&#34;&gt;Credit Suisse&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Raleigh, NC; NYC, NY&lt;/td&gt; &#xA;   &lt;td&gt;Search for &lt;code&gt;2023 Americas Technology Summer Analyst&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://jobs.citi.com/job/new-york/quantitative-analysis-summer-analyst-north-america-2023/287/28553736048&#34;&gt;Citi&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;New York, New York&lt;/td&gt; &#xA;   &lt;td&gt;Quantitative Analysis&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.amazon.jobs/en/jobs/1999770/amazon-robotics-software-development-engineer-sde-intern-summer-2023&#34;&gt;Amazon Robotics&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Greater Boston, MA&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://careers.sig.com/job/6289/Trading-Intern-Summer-2023-Expression-of-Interest&#34;&gt;SIG&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Philadelphia, PA&lt;/td&gt; &#xA;   &lt;td&gt;Quant Trading Expression of Interest&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;We love our contributors ‚ù§Ô∏è‚ù§Ô∏è&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Make a &lt;a href=&#34;https://github.com/susam/gitpr#create-pull-request&#34;&gt;pull request&lt;/a&gt; to help contribute.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/owini&#34;&gt;owini&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gintass&#34;&gt;GintasS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/EParmar18&#34;&gt;EParmar18&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/itscrystalli&#34;&gt;itscrystalli&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>ageitgey/face_recognition</title>
    <updated>2022-06-03T02:29:49Z</updated>
    <id>tag:github.com,2022-06-03:/ageitgey/face_recognition</id>
    <link href="https://github.com/ageitgey/face_recognition" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The world&#39;s simplest facial recognition api for Python and the command line&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Face Recognition&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;You can also read a translated version of this file &lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/README_Simplified_Chinese.md&#34;&gt;in Chinese ÁÆÄ‰Ωì‰∏≠ÊñáÁâà&lt;/a&gt; or &lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/README_Korean.md&#34;&gt;in Korean ÌïúÍµ≠Ïñ¥&lt;/a&gt; or &lt;a href=&#34;https://github.com/m-i-k-i/face_recognition/raw/master/README_Japanese.md&#34;&gt;in Japanese Êó•Êú¨Ë™û&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Recognize and manipulate faces from Python or from the command line with the world&#39;s simplest face recognition library.&lt;/p&gt; &#xA;&lt;p&gt;Built using &lt;a href=&#34;http://dlib.net/&#34;&gt;dlib&lt;/a&gt;&#39;s state-of-the-art face recognition built with deep learning. The model has an accuracy of 99.38% on the &lt;a href=&#34;http://vis-www.cs.umass.edu/lfw/&#34;&gt;Labeled Faces in the Wild&lt;/a&gt; benchmark.&lt;/p&gt; &#xA;&lt;p&gt;This also provides a simple &lt;code&gt;face_recognition&lt;/code&gt; command line tool that lets you do face recognition on a folder of images from the command line!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pypi.python.org/pypi/face_recognition&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/face_recognition.svg?sanitize=true&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ageitgey/face_recognition/actions?query=workflow%3ACI&#34;&gt;&lt;img src=&#34;https://github.com/ageitgey/face_recognition/workflows/CI/badge.svg?branch=master&amp;amp;event=push&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://face-recognition.readthedocs.io/en/latest/?badge=latest&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/face-recognition/badge/?version=latest&#34; alt=&#34;Documentation Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;h4&gt;Find faces in pictures&lt;/h4&gt; &#xA;&lt;p&gt;Find all the faces that appear in a picture:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cloud.githubusercontent.com/assets/896692/23625227/42c65360-025d-11e7-94ea-b12f28cb34b4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import face_recognition&#xA;image = face_recognition.load_image_file(&#34;your_file.jpg&#34;)&#xA;face_locations = face_recognition.face_locations(image)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Find and manipulate facial features in pictures&lt;/h4&gt; &#xA;&lt;p&gt;Get the locations and outlines of each person&#39;s eyes, nose, mouth and chin.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cloud.githubusercontent.com/assets/896692/23625282/7f2d79dc-025d-11e7-8728-d8924596f8fa.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import face_recognition&#xA;image = face_recognition.load_image_file(&#34;your_file.jpg&#34;)&#xA;face_landmarks_list = face_recognition.face_landmarks(image)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finding facial features is super useful for lots of important stuff. But you can also use it for really stupid stuff like applying &lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/digital_makeup.py&#34;&gt;digital make-up&lt;/a&gt; (think &#39;Meitu&#39;):&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cloud.githubusercontent.com/assets/896692/23625283/80638760-025d-11e7-80a2-1d2779f7ccab.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Identify faces in pictures&lt;/h4&gt; &#xA;&lt;p&gt;Recognize who appears in each photo.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cloud.githubusercontent.com/assets/896692/23625229/45e049b6-025d-11e7-89cc-8a71cf89e713.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import face_recognition&#xA;known_image = face_recognition.load_image_file(&#34;biden.jpg&#34;)&#xA;unknown_image = face_recognition.load_image_file(&#34;unknown.jpg&#34;)&#xA;&#xA;biden_encoding = face_recognition.face_encodings(known_image)[0]&#xA;unknown_encoding = face_recognition.face_encodings(unknown_image)[0]&#xA;&#xA;results = face_recognition.compare_faces([biden_encoding], unknown_encoding)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can even use this library with other Python libraries to do real-time face recognition:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cloud.githubusercontent.com/assets/896692/24430398/36f0e3f0-13cb-11e7-8258-4d0c9ce1e419.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/facerec_from_webcam_faster.py&#34;&gt;this example&lt;/a&gt; for the code.&lt;/p&gt; &#xA;&lt;h2&gt;Online Demos&lt;/h2&gt; &#xA;&lt;p&gt;User-contributed shared Jupyter notebook demo (not officially supported): &lt;a href=&#34;https://beta.deepnote.org/launch?template=face_recognition&#34;&gt;&lt;img src=&#34;https://beta.deepnote.org/buttons/try-in-a-jupyter-notebook.svg?sanitize=true&#34; alt=&#34;Deepnote&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.3+ or Python 2.7&lt;/li&gt; &#xA; &lt;li&gt;macOS or Linux (Windows not officially supported, but might work)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation Options:&lt;/h3&gt; &#xA;&lt;h4&gt;Installing on Mac or Linux&lt;/h4&gt; &#xA;&lt;p&gt;First, make sure you have dlib already installed with Python bindings:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gist.github.com/ageitgey/629d75c1baac34dfa5ca2a1928a7aeaf&#34;&gt;How to install dlib from source on macOS or Ubuntu&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Then, make sure you have cmake installed:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;brew install cmake&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Finally, install this module from pypi using &lt;code&gt;pip3&lt;/code&gt; (or &lt;code&gt;pip2&lt;/code&gt; for Python 2):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip3 install face_recognition&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, you can try this library with &lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt;, see &lt;a href=&#34;https://raw.githubusercontent.com/ageitgey/face_recognition/master/#deployment&#34;&gt;this section&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you are having trouble with installation, you can also try out a &lt;a href=&#34;https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b&#34;&gt;pre-configured VM&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Installing on an Nvidia Jetson Nano board&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/@ageitgey/build-a-hardware-based-face-recognition-system-for-150-with-the-nvidia-jetson-nano-and-python-a25cb8c891fd&#34;&gt;Jetson Nano installation instructions&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Please follow the instructions in the article carefully. There is current a bug in the CUDA libraries on the Jetson Nano that will cause this library to fail silently if you don&#39;t follow the instructions in the article to comment out a line in dlib and recompile it.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Installing on Raspberry Pi 2+&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gist.github.com/ageitgey/1ac8dbe8572f3f533df6269dab35df65&#34;&gt;Raspberry Pi 2+ installation instructions&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Installing on FreeBSD&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pkg install graphics/py-face_recognition&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Installing on Windows&lt;/h4&gt; &#xA;&lt;p&gt;While Windows isn&#39;t officially supported, helpful users have posted instructions on how to install this library:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/issues/175#issue-257710508&#34;&gt;@masoudr&#39;s Windows 10 installation guide (dlib + face_recognition)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Installing a pre-configured Virtual Machine image&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b&#34;&gt;Download the pre-configured VM image&lt;/a&gt; (for VMware Player or VirtualBox).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Command-Line Interface&lt;/h3&gt; &#xA;&lt;p&gt;When you install &lt;code&gt;face_recognition&lt;/code&gt;, you get two simple command-line programs:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;face_recognition&lt;/code&gt; - Recognize faces in a photograph or folder full for photographs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;face_detection&lt;/code&gt; - Find faces in a photograph or folder full for photographs.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;&lt;code&gt;face_recognition&lt;/code&gt; command line tool&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;face_recognition&lt;/code&gt; command lets you recognize faces in a photograph or folder full for photographs.&lt;/p&gt; &#xA;&lt;p&gt;First, you need to provide a folder with one picture of each person you already know. There should be one image file for each person with the files named according to who is in the picture:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cloud.githubusercontent.com/assets/896692/23582466/8324810e-00df-11e7-82cf-41515eba704d.png&#34; alt=&#34;known&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Next, you need a second folder with the files you want to identify:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cloud.githubusercontent.com/assets/896692/23582465/81f422f8-00df-11e7-8b0d-75364f641f58.png&#34; alt=&#34;unknown&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Then in you simply run the command &lt;code&gt;face_recognition&lt;/code&gt;, passing in the folder of known people and the folder (or single image) with unknown people and it tells you who is in each image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/&#xA;&#xA;/unknown_pictures/unknown.jpg,Barack Obama&#xA;/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There&#39;s one line in the output for each face. The data is comma-separated with the filename and the name of the person found.&lt;/p&gt; &#xA;&lt;p&gt;An &lt;code&gt;unknown_person&lt;/code&gt; is a face in the image that didn&#39;t match anyone in your folder of known people.&lt;/p&gt; &#xA;&lt;h4&gt;&lt;code&gt;face_detection&lt;/code&gt; command line tool&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;face_detection&lt;/code&gt; command lets you find the location (pixel coordinatates) of any faces in an image.&lt;/p&gt; &#xA;&lt;p&gt;Just run the command &lt;code&gt;face_detection&lt;/code&gt;, passing in a folder of images to check (or a single image):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ face_detection  ./folder_with_pictures/&#xA;&#xA;examples/image1.jpg,65,215,169,112&#xA;examples/image2.jpg,62,394,211,244&#xA;examples/image2.jpg,95,941,244,792&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It prints one line for each face that was detected. The coordinates reported are the top, right, bottom and left coordinates of the face (in pixels).&lt;/p&gt; &#xA;&lt;h5&gt;Adjusting Tolerance / Sensitivity&lt;/h5&gt; &#xA;&lt;p&gt;If you are getting multiple matches for the same person, it might be that the people in your photos look very similar and a lower tolerance value is needed to make face comparisons more strict.&lt;/p&gt; &#xA;&lt;p&gt;You can do that with the &lt;code&gt;--tolerance&lt;/code&gt; parameter. The default tolerance value is 0.6 and lower numbers make face comparisons more strict:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ face_recognition --tolerance 0.54 ./pictures_of_people_i_know/ ./unknown_pictures/&#xA;&#xA;/unknown_pictures/unknown.jpg,Barack Obama&#xA;/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to see the face distance calculated for each match in order to adjust the tolerance setting, you can use &lt;code&gt;--show-distance true&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ face_recognition --show-distance true ./pictures_of_people_i_know/ ./unknown_pictures/&#xA;&#xA;/unknown_pictures/unknown.jpg,Barack Obama,0.378542298956785&#xA;/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person,None&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;More Examples&lt;/h5&gt; &#xA;&lt;p&gt;If you simply want to know the names of the people in each photograph but don&#39;t care about file names, you could do this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/ | cut -d &#39;,&#39; -f2&#xA;&#xA;Barack Obama&#xA;unknown_person&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Speeding up Face Recognition&lt;/h5&gt; &#xA;&lt;p&gt;Face recognition can be done in parallel if you have a computer with multiple CPU cores. For example, if your system has 4 CPU cores, you can process about 4 times as many images in the same amount of time by using all your CPU cores in parallel.&lt;/p&gt; &#xA;&lt;p&gt;If you are using Python 3.4 or newer, pass in a &lt;code&gt;--cpus &amp;lt;number_of_cpu_cores_to_use&amp;gt;&lt;/code&gt; parameter:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ face_recognition --cpus 4 ./pictures_of_people_i_know/ ./unknown_pictures/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also pass in &lt;code&gt;--cpus -1&lt;/code&gt; to use all CPU cores in your system.&lt;/p&gt; &#xA;&lt;h4&gt;Python Module&lt;/h4&gt; &#xA;&lt;p&gt;You can import the &lt;code&gt;face_recognition&lt;/code&gt; module and then easily manipulate faces with just a couple of lines of code. It&#39;s super easy!&lt;/p&gt; &#xA;&lt;p&gt;API Docs: &lt;a href=&#34;https://face-recognition.readthedocs.io/en/latest/face_recognition.html&#34;&gt;https://face-recognition.readthedocs.io&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h5&gt;Automatically find all the faces in an image&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import face_recognition&#xA;&#xA;image = face_recognition.load_image_file(&#34;my_picture.jpg&#34;)&#xA;face_locations = face_recognition.face_locations(image)&#xA;&#xA;# face_locations is now an array listing the co-ordinates of each face!&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/find_faces_in_picture.py&#34;&gt;this example&lt;/a&gt; to try it out.&lt;/p&gt; &#xA;&lt;p&gt;You can also opt-in to a somewhat more accurate deep-learning-based face detection model.&lt;/p&gt; &#xA;&lt;p&gt;Note: GPU acceleration (via NVidia&#39;s CUDA library) is required for good performance with this model. You&#39;ll also want to enable CUDA support when compliling &lt;code&gt;dlib&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import face_recognition&#xA;&#xA;image = face_recognition.load_image_file(&#34;my_picture.jpg&#34;)&#xA;face_locations = face_recognition.face_locations(image, model=&#34;cnn&#34;)&#xA;&#xA;# face_locations is now an array listing the co-ordinates of each face!&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/find_faces_in_picture_cnn.py&#34;&gt;this example&lt;/a&gt; to try it out.&lt;/p&gt; &#xA;&lt;p&gt;If you have a lot of images and a GPU, you can also &lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/find_faces_in_batches.py&#34;&gt;find faces in batches&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h5&gt;Automatically locate the facial features of a person in an image&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import face_recognition&#xA;&#xA;image = face_recognition.load_image_file(&#34;my_picture.jpg&#34;)&#xA;face_landmarks_list = face_recognition.face_landmarks(image)&#xA;&#xA;# face_landmarks_list is now an array with the locations of each facial feature in each face.&#xA;# face_landmarks_list[0][&#39;left_eye&#39;] would be the location and outline of the first person&#39;s left eye.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/find_facial_features_in_picture.py&#34;&gt;this example&lt;/a&gt; to try it out.&lt;/p&gt; &#xA;&lt;h5&gt;Recognize faces in images and identify who they are&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import face_recognition&#xA;&#xA;picture_of_me = face_recognition.load_image_file(&#34;me.jpg&#34;)&#xA;my_face_encoding = face_recognition.face_encodings(picture_of_me)[0]&#xA;&#xA;# my_face_encoding now contains a universal &#39;encoding&#39; of my facial features that can be compared to any other picture of a face!&#xA;&#xA;unknown_picture = face_recognition.load_image_file(&#34;unknown.jpg&#34;)&#xA;unknown_face_encoding = face_recognition.face_encodings(unknown_picture)[0]&#xA;&#xA;# Now we can see the two face encodings are of the same person with `compare_faces`!&#xA;&#xA;results = face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)&#xA;&#xA;if results[0] == True:&#xA;    print(&#34;It&#39;s a picture of me!&#34;)&#xA;else:&#xA;    print(&#34;It&#39;s not a picture of me!&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/recognize_faces_in_pictures.py&#34;&gt;this example&lt;/a&gt; to try it out.&lt;/p&gt; &#xA;&lt;h2&gt;Python Code Examples&lt;/h2&gt; &#xA;&lt;p&gt;All the examples are available &lt;a href=&#34;https://github.com/ageitgey/face_recognition/tree/master/examples&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Face Detection&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/find_faces_in_picture.py&#34;&gt;Find faces in a photograph&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/find_faces_in_picture_cnn.py&#34;&gt;Find faces in a photograph (using deep learning)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/find_faces_in_batches.py&#34;&gt;Find faces in batches of images w/ GPU (using deep learning)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/blur_faces_on_webcam.py&#34;&gt;Blur all the faces in a live video using your webcam (Requires OpenCV to be installed)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Facial Features&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/find_facial_features_in_picture.py&#34;&gt;Identify specific facial features in a photograph&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/digital_makeup.py&#34;&gt;Apply (horribly ugly) digital make-up&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Facial Recognition&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/recognize_faces_in_pictures.py&#34;&gt;Find and recognize unknown faces in a photograph based on photographs of known people&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/identify_and_draw_boxes_on_faces.py&#34;&gt;Identify and draw boxes around each person in a photo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/face_distance.py&#34;&gt;Compare faces by numeric face distance instead of only True/False matches&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/facerec_from_webcam.py&#34;&gt;Recognize faces in live video using your webcam - Simple / Slower Version (Requires OpenCV to be installed)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/facerec_from_webcam_faster.py&#34;&gt;Recognize faces in live video using your webcam - Faster Version (Requires OpenCV to be installed)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/facerec_from_video_file.py&#34;&gt;Recognize faces in a video file and write out new video file (Requires OpenCV to be installed)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/facerec_on_raspberry_pi.py&#34;&gt;Recognize faces on a Raspberry Pi w/ camera&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/web_service_example.py&#34;&gt;Run a web service to recognize faces via HTTP (Requires Flask to be installed)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/face_recognition_knn.py&#34;&gt;Recognize faces with a K-nearest neighbors classifier&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ageitgey/face_recognition/raw/master/examples/face_recognition_svm.py&#34;&gt;Train multiple images per person then recognize faces using a SVM&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Creating a Standalone Executable&lt;/h2&gt; &#xA;&lt;p&gt;If you want to create a standalone executable that can run without the need to install &lt;code&gt;python&lt;/code&gt; or &lt;code&gt;face_recognition&lt;/code&gt;, you can use &lt;a href=&#34;https://github.com/pyinstaller/pyinstaller&#34;&gt;PyInstaller&lt;/a&gt;. However, it requires some custom configuration to work with this library. See &lt;a href=&#34;https://github.com/ageitgey/face_recognition/issues/357&#34;&gt;this issue&lt;/a&gt; for how to do it.&lt;/p&gt; &#xA;&lt;h2&gt;Articles and Guides that cover &lt;code&gt;face_recognition&lt;/code&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;My article on how Face Recognition works: &lt;a href=&#34;https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78&#34;&gt;Modern Face Recognition with Deep Learning&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Covers the algorithms and how they generally work&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pyimagesearch.com/2018/06/18/face-recognition-with-opencv-python-and-deep-learning/&#34;&gt;Face recognition with OpenCV, Python, and deep learning&lt;/a&gt; by Adrian Rosebrock &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Covers how to use face recognition in practice&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pyimagesearch.com/2018/06/25/raspberry-pi-face-recognition/&#34;&gt;Raspberry Pi Face Recognition&lt;/a&gt; by Adrian Rosebrock &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Covers how to use this on a Raspberry Pi&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pyimagesearch.com/2018/07/09/face-clustering-with-python/&#34;&gt;Face clustering with Python&lt;/a&gt; by Adrian Rosebrock &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Covers how to automatically cluster photos based on who appears in each photo using unsupervised learning&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How Face Recognition Works&lt;/h2&gt; &#xA;&lt;p&gt;If you want to learn how face location and recognition work instead of depending on a black box library, &lt;a href=&#34;https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78&#34;&gt;read my article&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Caveats&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The face recognition model is trained on adults and does not work very well on children. It tends to mix up children quite easy using the default comparison threshold of 0.6.&lt;/li&gt; &#xA; &lt;li&gt;Accuracy may vary between ethnic groups. Please see &lt;a href=&#34;https://github.com/ageitgey/face_recognition/wiki/Face-Recognition-Accuracy-Problems#question-face-recognition-works-well-with-european-individuals-but-overall-accuracy-is-lower-with-asian-individuals&#34;&gt;this wiki page&lt;/a&gt; for more details.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;deployment&#34;&gt;Deployment to Cloud Hosts (Heroku, AWS, etc)&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Since &lt;code&gt;face_recognition&lt;/code&gt; depends on &lt;code&gt;dlib&lt;/code&gt; which is written in C++, it can be tricky to deploy an app using it to a cloud hosting provider like Heroku or AWS.&lt;/p&gt; &#xA;&lt;p&gt;To make things easier, there&#39;s an example Dockerfile in this repo that shows how to run an app built with &lt;code&gt;face_recognition&lt;/code&gt; in a &lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt; container. With that, you should be able to deploy to any service that supports Docker images.&lt;/p&gt; &#xA;&lt;p&gt;You can try the Docker image locally by running: &lt;code&gt;docker-compose up --build&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;There are also &lt;a href=&#34;https://raw.githubusercontent.com/ageitgey/face_recognition/master/docker/README.md&#34;&gt;several prebuilt Docker images.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Linux users with a GPU (drivers &amp;gt;= 384.81) and &lt;a href=&#34;https://github.com/NVIDIA/nvidia-docker&#34;&gt;Nvidia-Docker&lt;/a&gt; installed can run the example on the GPU: Open the &lt;a href=&#34;https://raw.githubusercontent.com/ageitgey/face_recognition/master/docker-compose.yml&#34;&gt;docker-compose.yml&lt;/a&gt; file and uncomment the &lt;code&gt;dockerfile: Dockerfile.gpu&lt;/code&gt; and &lt;code&gt;runtime: nvidia&lt;/code&gt; lines.&lt;/p&gt; &#xA;&lt;h2&gt;Having problems?&lt;/h2&gt; &#xA;&lt;p&gt;If you run into problems, please read the &lt;a href=&#34;https://github.com/ageitgey/face_recognition/wiki/Common-Errors&#34;&gt;Common Errors&lt;/a&gt; section of the wiki before filing a github issue.&lt;/p&gt; &#xA;&lt;h2&gt;Thanks&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Many, many thanks to &lt;a href=&#34;https://github.com/davisking&#34;&gt;Davis King&lt;/a&gt; (&lt;a href=&#34;https://twitter.com/nulhom&#34;&gt;@nulhom&lt;/a&gt;) for creating dlib and for providing the trained facial feature detection and face encoding models used in this library. For more information on the ResNet that powers the face encodings, check out his &lt;a href=&#34;http://blog.dlib.net/2017/02/high-quality-face-recognition-with-deep.html&#34;&gt;blog post&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Thanks to everyone who works on all the awesome Python data science libraries like numpy, scipy, scikit-image, pillow, etc, etc that makes this kind of stuff so easy and fun in Python.&lt;/li&gt; &#xA; &lt;li&gt;Thanks to &lt;a href=&#34;https://github.com/audreyr/cookiecutter&#34;&gt;Cookiecutter&lt;/a&gt; and the &lt;a href=&#34;https://github.com/audreyr/cookiecutter-pypackage&#34;&gt;audreyr/cookiecutter-pypackage&lt;/a&gt; project template for making Python project packaging way more tolerable.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>