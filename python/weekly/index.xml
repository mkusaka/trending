<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-19T02:03:40Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>microsoft/visual-chatgpt</title>
    <updated>2023-03-19T02:03:40Z</updated>
    <id>tag:github.com,2023-03-19:/microsoft/visual-chatgpt</id>
    <link href="https://github.com/microsoft/visual-chatgpt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official repo for the paper: Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Visual ChatGPT&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Visual ChatGPT&lt;/strong&gt; connects ChatGPT and a series of Visual Foundation Models to enable &lt;strong&gt;sending&lt;/strong&gt; and &lt;strong&gt;receiving&lt;/strong&gt; images during chatting.&lt;/p&gt; &#xA;&lt;p&gt;See our paper: &lt;a href=&#34;https://arxiv.org/abs/2303.04671&#34;&gt;&lt;font size=&#34;5&#34;&gt;Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models&lt;/font&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;a src=&#34;https://img.shields.io/badge/%F0%9F%A4%97-Open%20in%20Spaces-blue&#34; href=&#34;https://huggingface.co/spaces/microsoft/visual_chatgpt&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97-Open%20in%20Spaces-blue&#34; alt=&#34;Open in Spaces&#34;&gt; &lt;/a&gt; &#xA;&lt;a src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; href=&#34;https://colab.research.google.com/drive/11BtP3h-w0dZjA-X8JsS9_eo8OeGYvxXB&#34;&gt; &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;Updates:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Add custom GPU/CPU assignment&lt;/li&gt; &#xA; &lt;li&gt;Add windows support&lt;/li&gt; &#xA; &lt;li&gt;Merge HuggingFace ControlNet, Remove download.sh&lt;/li&gt; &#xA; &lt;li&gt;Add Prompt Decorator&lt;/li&gt; &#xA; &lt;li&gt;Add HuggingFace and Colab Demo&lt;/li&gt; &#xA; &lt;li&gt;Clean Requirements&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Insight &amp;amp; Goal:&lt;/h2&gt; &#xA;&lt;p&gt;One the one hand, &lt;strong&gt;ChatGPT (or LLMs)&lt;/strong&gt; serves as a &lt;strong&gt;general interface&lt;/strong&gt; that provides a broad and diverse understanding of a wide range of topics. On the other hand, &lt;strong&gt;Foundation Models&lt;/strong&gt; serve as &lt;strong&gt;domain experts&lt;/strong&gt; by providing deep knowledge in specific domains. By leveraging &lt;strong&gt;both general and deep knowledge&lt;/strong&gt;, we aim at building an AI that is capable of handling various tasks.&lt;/p&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/visual-chatgpt/main/assets/demo_short.gif&#34; width=&#34;750&#34;&gt; &#xA;&lt;h2&gt;System Architecture&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/visual-chatgpt/main/assets/figure.jpg&#34; alt=&#34;Logo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;# clone the repo&#xA;git clone https://github.com/microsoft/visual-chatgpt.git&#xA;&#xA;# Go to directory&#xA;cd visual-chatgpt&#xA;&#xA;# create a new environment&#xA;conda create -n visgpt python=3.8&#xA;&#xA;# activate the new environment&#xA;conda activate visgpt&#xA;&#xA;#  prepare the basic environments&#xA;pip install -r requirements.txt&#xA;&#xA;# prepare your private OpenAI key (for Linux)&#xA;export OPENAI_API_KEY={Your_Private_Openai_Key}&#xA;&#xA;# prepare your private OpenAI key (for Windows)&#xA;set OPENAI_API_KEY={Your_Private_Openai_Key}&#xA;&#xA;# Start Visual ChatGPT !&#xA;# You can specify the GPU/CPU assignment by &#34;--load&#34;, the parameter indicates which &#xA;# Visual Foundation Model to use and where it will be loaded to&#xA;# The model and device are separated by underline &#39;_&#39;, the different models are separated by comma &#39;,&#39;&#xA;# The available Visual Foundation Models can be found in the following table&#xA;# For example, if you want to load ImageCaptioning to cpu and Text2Image to cuda:0&#xA;# You can use: &#34;ImageCaptioning_cpu,Text2Image_cuda:0&#34;&#xA;&#xA;# Advice for CPU Users&#xA;python visual_chatgpt.py --load ImageCaptioning_cpu,Text2Image_cpu&#xA;&#xA;# Advice for 1 Tesla T4 15GB  (Google Colab)                       &#xA;python visual_chatgpt.py --load &#34;ImageCaptioning_cuda:0,Text2Image_cuda:0&#34;&#xA;                                &#xA;# Advice for 4 Tesla V100 32GB                            &#xA;python visual_chatgpt.py --load &#34;ImageCaptioning_cuda:0,ImageEditing_cuda:0,&#xA;    Text2Image_cuda:1,Image2Canny_cpu,CannyText2Image_cuda:1,&#xA;    Image2Depth_cpu,DepthText2Image_cuda:1,VisualQuestionAnswering_cuda:2,&#xA;    InstructPix2Pix_cuda:2,Image2Scribble_cpu,ScribbleText2Image_cuda:2,&#xA;    Image2Seg_cpu,SegText2Image_cuda:2,Image2Pose_cpu,PoseText2Image_cuda:2,&#xA;    Image2Hed_cpu,HedText2Image_cuda:3,Image2Normal_cpu,&#xA;    NormalText2Image_cuda:3,Image2Line_cpu,LineText2Image_cuda:3&#34;&#xA;                             &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;GPU memory usage&lt;/h2&gt; &#xA;&lt;p&gt;Here we list the GPU memory usage of each visual foundation model, you can specify which one you like:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Foundation Model&lt;/th&gt; &#xA;   &lt;th&gt;GPU Memory (MB)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ImageEditing&lt;/td&gt; &#xA;   &lt;td&gt;3981&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;InstructPix2Pix&lt;/td&gt; &#xA;   &lt;td&gt;2827&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Text2Image&lt;/td&gt; &#xA;   &lt;td&gt;3385&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ImageCaptioning&lt;/td&gt; &#xA;   &lt;td&gt;1209&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Image2Canny&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CannyText2Image&lt;/td&gt; &#xA;   &lt;td&gt;3531&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Image2Line&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LineText2Image&lt;/td&gt; &#xA;   &lt;td&gt;3529&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Image2Hed&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HedText2Image&lt;/td&gt; &#xA;   &lt;td&gt;3529&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Image2Scribble&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ScribbleText2Image&lt;/td&gt; &#xA;   &lt;td&gt;3531&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Image2Pose&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PoseText2Image&lt;/td&gt; &#xA;   &lt;td&gt;3529&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Image2Seg&lt;/td&gt; &#xA;   &lt;td&gt;919&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SegText2Image&lt;/td&gt; &#xA;   &lt;td&gt;3529&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Image2Depth&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DepthText2Image&lt;/td&gt; &#xA;   &lt;td&gt;3531&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Image2Normal&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;NormalText2Image&lt;/td&gt; &#xA;   &lt;td&gt;3529&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;VisualQuestionAnswering&lt;/td&gt; &#xA;   &lt;td&gt;1495&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;We appreciate the open source of the following projects:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/huggingface&#34;&gt;Hugging Face&lt;/a&gt;   &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt;   &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt;   &lt;a href=&#34;https://github.com/lllyasviel/ControlNet&#34;&gt;ControlNet&lt;/a&gt;   &lt;a href=&#34;https://github.com/timothybrooks/instruct-pix2pix&#34;&gt;InstructPix2Pix&lt;/a&gt;   &lt;a href=&#34;https://github.com/timojl/clipseg&#34;&gt;CLIPSeg&lt;/a&gt;   &lt;a href=&#34;https://github.com/salesforce/BLIP&#34;&gt;BLIP&lt;/a&gt;  &lt;/p&gt; &#xA;&lt;h2&gt;Contact Information&lt;/h2&gt; &#xA;&lt;p&gt;For help or issues using the Visual ChatGPT, please submit a GitHub issue.&lt;/p&gt; &#xA;&lt;p&gt;For other communications, please contact Chenfei WU (&lt;a href=&#34;mailto:chewu@microsoft.com&#34;&gt;chewu@microsoft.com&lt;/a&gt;) or Nan DUAN (&lt;a href=&#34;mailto:nanduan@microsoft.com&#34;&gt;nanduan@microsoft.com&lt;/a&gt;).&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>edtechre/pybroker</title>
    <updated>2023-03-19T02:03:40Z</updated>
    <id>tag:github.com,2023-03-19:/edtechre/pybroker</id>
    <link href="https://github.com/edtechre/pybroker" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Algorithmic Trading in Python with Machine Learning&lt;/p&gt;&lt;hr&gt;&lt;h1&gt; &lt;img src=&#34;https://github.com/edtechre/pybroker/raw/master/docs/_static/pybroker-logo.png?raw=true&#34; alt=&#34;PyBroker&#34;&gt; &lt;/h1&gt; &#xA;&lt;h2&gt;Algorithmic Trading in Python with Machine Learning&lt;/h2&gt; &#xA;&lt;p&gt;Are you looking to enhance your trading strategies with the power of Python and machine learning? Then you need to check out &lt;strong&gt;PyBroker&lt;/strong&gt;! This Python framework is designed for developing algorithmic trading strategies, with a focus on strategies that use machine learning. With PyBroker, you can easily create and fine-tune trading rules, build powerful models, and gain valuable insights into your strategy’s performance.&lt;/p&gt; &#xA;&lt;h2&gt;Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A super-fast backtesting engine built in &lt;a href=&#34;https://numpy.org/&#34;&gt;NumPy&lt;/a&gt; and accelerated with &lt;a href=&#34;https://numba.pydata.org/&#34;&gt;Numba&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The ability to create and execute trading rules and models across multiple instruments with ease.&lt;/li&gt; &#xA; &lt;li&gt;Access to historical data from &lt;a href=&#34;https://alpaca.markets/&#34;&gt;Alpaca&lt;/a&gt; and &lt;a href=&#34;https://finance.yahoo.com/&#34;&gt;Yahoo Finance&lt;/a&gt;, or from &lt;a href=&#34;https://www.pybroker.com/en/latest/notebooks/7.%20Creating%20a%20Custom%20Data%20Source.html&#34;&gt;your own data provider&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The option to train and backtest models using &lt;a href=&#34;https://www.pybroker.com/en/latest/notebooks/6.%20Training%20a%20Model.html#Walkforward-Analysis&#34;&gt;Walkforward Analysis&lt;/a&gt;, which simulates how the strategy would perform during actual trading.&lt;/li&gt; &#xA; &lt;li&gt;More reliable trading metrics that use randomized &lt;a href=&#34;https://en.wikipedia.org/wiki/Bootstrapping_(statistics)&#34;&gt;bootstrapping&lt;/a&gt; to provide more accurate results.&lt;/li&gt; &#xA; &lt;li&gt;Caching of downloaded data, indicators, and models to speed up your development process.&lt;/li&gt; &#xA; &lt;li&gt;Parallelized computations that enable faster performance.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;With PyBroker, you&#39;ll have all the tools you need to create winning trading strategies backed by data and machine learning. Start using PyBroker today and take your trading to the next level!&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;PyBroker supports Python 3.9+ on Windows, Mac, and Linux. You can install PyBroker using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    pip install lib-pybroker&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or you can clone the Git repository with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    git clone https://github.com/edtechre/pybroker&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;A Quick Example&lt;/h2&gt; &#xA;&lt;p&gt;Get a glimpse of what backtesting with PyBroker looks like with these code snippets:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Rule-based Strategy&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;   from pybroker import Strategy, YFinance, highest&#xA;&#xA;   def exec_fn(ctx):&#xA;      # Require at least 20 days of data.&#xA;      if ctx.bars &amp;lt; 20:&#xA;         return&#xA;      # Get the rolling 10 day high.&#xA;      high_10d = ctx.indicator(&#39;high_10d&#39;)&#xA;      # Buy on a new 10 day high.&#xA;      if not ctx.long_pos() and high_10d[-1] &amp;gt; high_10d[-2]:&#xA;         ctx.buy_shares = 100&#xA;         # Hold the position for 2 days.&#xA;         ctx.hold_bars = 2&#xA;&#xA;   strategy = Strategy(YFinance(), start_date=&#39;1/1/2022&#39;, end_date=&#39;7/1/2022&#39;)&#xA;   strategy.add_execution(&#xA;      exec_fn, [&#39;AAPL&#39;, &#39;MSFT&#39;], indicators=highest(&#39;high_10d&#39;, &#39;close&#39;, period=10))&#xA;   result = strategy.backtest()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Model-based Strategy&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;   import pybroker&#xA;   from pybroker import Alpaca, Strategy&#xA;&#xA;   def train_fn(train_data, test_data, ticker):&#xA;      # Train the model using indicators stored in train_data.&#xA;      ...&#xA;      return trained_model&#xA;&#xA;   # Register the model and its training function with PyBroker.&#xA;   my_model = pybroker.model(&#39;my_model&#39;, train_fn, indicators=[...])&#xA;&#xA;   def exec_fn(ctx):&#xA;      preds = ctx.preds(&#39;my_model&#39;)&#xA;      # Open a long position given my_model&#39;s latest prediction.&#xA;      if not ctx.long_pos() and preds[-1] &amp;gt; buy_threshold:&#xA;         ctx.buy_shares = 100&#xA;      # Close the long position given my_model&#39;s latest prediction.&#xA;      elif ctx.long_pos() and preds[-1] &amp;lt; sell_threshold:&#xA;         ctx.sell_all_shares()&#xA;&#xA;   alpaca = Alpaca(api_key=..., api_secret=...)&#xA;   strategy = Strategy(alpaca, start_date=&#39;1/1/2022&#39;, end_date=&#39;7/1/2022&#39;)&#xA;   strategy.add_execution(exec_fn, [&#39;AAPL&#39;, &#39;MSFT&#39;], models=my_model)&#xA;   # Run Walkforward Analysis on 1 minute data using 5 windows with 50/50 train/test data.&#xA;   result = strategy.walkforward(timeframe=&#39;1m&#39;, windows=5, train_size=0.5)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;User Guide&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pybroker.com/en/latest/notebooks/1.%20Getting%20Started%20with%20Data%20Sources.html&#34;&gt;Getting Started with Data Sources&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pybroker.com/en/latest/notebooks/2.%20Backtesting%20a%20Strategy.html&#34;&gt;Backtesting a Strategy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pybroker.com/en/latest/notebooks/3.%20Evaluating%20with%20Bootstrap%20Metrics.html&#34;&gt;Evaluating with Bootstrap Metrics&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pybroker.com/en/latest/notebooks/4.%20Ranking%20and%20Position%20Sizing.html&#34;&gt;Ranking and Position Sizing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pybroker.com/en/latest/notebooks/5.%20Writing%20Indicators.html&#34;&gt;Writing Indicators&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pybroker.com/en/latest/notebooks/6.%20Training%20a%20Model.html&#34;&gt;Training a Model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pybroker.com/en/latest/notebooks/7.%20Creating%20a%20Custom%20Data%20Source.html&#34;&gt;Creating a Custom Data Source&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Online Documentation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.pybroker.com&#34;&gt;The full reference documentation is hosted at &lt;strong&gt;www.pybroker.com&lt;/strong&gt;.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;img src=&#34;https://github.com/edtechre/pybroker/raw/master/docs/_static/email-image.png?raw=true&#34;&gt;</summary>
  </entry>
  <entry>
    <title>pynecone-io/pynecone</title>
    <updated>2023-03-19T02:03:40Z</updated>
    <id>tag:github.com,2023-03-19:/pynecone-io/pynecone</id>
    <link href="https://github.com/pynecone-io/pynecone" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🕸 Web apps in pure Python 🐍&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1 align=&#34;center&#34;&gt; &lt;img width=&#34;600&#34; src=&#34;https://raw.githubusercontent.com/pynecone-io/pynecone/main/docs/images/logo.svg#gh-light-mode-only&#34; alt=&#34;Pynecone Logo&#34;&gt; &lt;img width=&#34;600&#34; src=&#34;https://raw.githubusercontent.com/pynecone-io/pynecone/main/docs/images/logo_white.svg#gh-dark-mode-only&#34; alt=&#34;Pynecone Logo&#34;&gt; &lt;/h1&gt; &#xA; &lt;p&gt;&lt;strong&gt;Build performant, customizable web apps in pure Python.&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://badge.fury.io/py/pynecone&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/pynecone.svg?sanitize=true&#34; alt=&#34;PyPI version&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://github.com/pynecone-io/pynecone/actions/workflows/build.yml/badge.svg?sanitize=true&#34; alt=&#34;tests&#34;&gt; &lt;img src=&#34;https://img.shields.io/pypi/pyversions/pynecone-io.svg?sanitize=true&#34; alt=&#34;versions&#34;&gt; &lt;a href=&#34;https://opensource.org/licenses/Apache-2.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache_2.0-yellowgreen.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://discord.gg/T5WSbC2YtQ&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1029853095527727165?color=%237289da&amp;amp;label=Discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;div align=&#34;left&#34;&gt; &#xA;  &lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;  &lt;p&gt;Pynecone is a full-stack Python framework that makes it easy to build and deploy web apps in minutes. All the information for getting started can be found in this README. However, a more detailed explanation of the following topics can be found on our website:&lt;/p&gt; &#xA;  &lt;div align=&#34;center&#34;&gt; &#xA;   &lt;h3&gt;&lt;a href=&#34;https://pynecone.io/docs/getting-started/introduction&#34;&gt;Docs&lt;/a&gt; | &lt;a href=&#34;https://pynecone.io/docs/library&#34;&gt;Component Library&lt;/a&gt; | &lt;a href=&#34;https://pynecone.io/docs/gallery&#34;&gt;Gallery&lt;/a&gt; | &lt;a href=&#34;https://pynecone.io/docs/hosting/deploy&#34;&gt;Deployment&lt;/a&gt;&lt;/h3&gt; &#xA;   &lt;div align=&#34;left&#34;&gt; &#xA;    &lt;h2&gt;Installation&lt;/h2&gt; &#xA;    &lt;p&gt;Pynecone requires the following to get started:&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Python 3.7+&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://nodejs.org/en/&#34;&gt;Node.js 12.22.0+&lt;/a&gt; (Don&#39;t worry, you&#39;ll never have to write any Javascript)&lt;/li&gt; &#xA;    &lt;/ul&gt; &#xA;    &lt;pre&gt;&lt;code&gt;$ pip install pynecone&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;h2&gt;Create your first Pynecone App&lt;/h2&gt; &#xA;    &lt;p&gt;Installing Pynecone also installs the &lt;code&gt;pc&lt;/code&gt; command line tool. Test that the install was successful by creating a new project.&lt;/p&gt; &#xA;    &lt;p&gt;Replace my_app_name with your project name:&lt;/p&gt; &#xA;    &lt;pre&gt;&lt;code&gt;$ mkdir my_app_name&#xA;$ cd my_app_name&#xA;$ pc init&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;p&gt;When you run this command for the first time, we will download and install &lt;a href=&#34;https://bun.sh/&#34;&gt;bun&lt;/a&gt; automatically.&lt;/p&gt; &#xA;    &lt;p&gt;This command initializes a template app in your new directory. You can run this app in development mode:&lt;/p&gt; &#xA;    &lt;pre&gt;&lt;code&gt;$ pc run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;p&gt;You should see your app running at &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt;.&lt;/p&gt; &#xA;    &lt;p&gt;Now you can modify the source code in &lt;code&gt;my_app_name/my_app_name.py&lt;/code&gt;. Pynecone has fast refreshes so you can see your changes instantly when you save your code.&lt;/p&gt; &#xA;    &lt;h2&gt;Example Pynecone App&lt;/h2&gt; &#xA;    &lt;p&gt;Let&#39;s go over an example of creating a UI around DALL·E. For simplicity of the example below, we call the OpenAI DALL·E API, but you could replace this with any ML model locally.&lt;/p&gt; &#xA;    &lt;div align=&#34;center&#34;&gt; &#xA;     &lt;img src=&#34;https://raw.githubusercontent.com/pynecone-io/pynecone/main/docs/images/dalle.gif&#34; alt=&#34;drawing&#34; width=&#34;550&#34; style=&#34;border-radius:2%&#34;&gt; &#xA;     &lt;div align=&#34;left&#34;&gt; &#xA;      &lt;p&gt;Here is the complete code to create this. This is all done in one Python file!&lt;/p&gt; &#xA;      &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pynecone as pc&#xA;import openai&#xA;&#xA;openai.api_key = &#34;YOUR_API_KEY&#34;&#xA;&#xA;class State(pc.State):&#xA;    &#34;&#34;&#34;The app state.&#34;&#34;&#34;&#xA;    prompt = &#34;&#34;&#xA;    image_url = &#34;&#34;&#xA;    image_processing = False&#xA;    image_made = False&#xA;&#xA;    def process_image(self):&#xA;        &#34;&#34;&#34;Set the image processing flag to true and indicate image is not made yet.&#34;&#34;&#34;&#xA;        self.image_processing = True&#xA;        self.image_made = False        &#xA;&#xA;    def get_image(self):&#xA;        &#34;&#34;&#34;Get the image from the prompt.&#34;&#34;&#34;&#xA;        response = openai.Image.create(prompt=self.prompt, n=1, size=&#34;1024x1024&#34;)&#xA;        self.image_url = response[&#34;data&#34;][0][&#34;url&#34;]&#xA;        self.image_processing = False&#xA;        self.image_made = True&#xA;&#xA;def index():&#xA;    return pc.center(&#xA;        pc.vstack(&#xA;            pc.heading(&#34;DALL·E&#34;, font_size=&#34;1.5em&#34;),&#xA;            pc.input(placeholder=&#34;Enter a prompt..&#34;, on_blur=State.set_prompt),&#xA;            pc.button(&#xA;                &#34;Generate Image&#34;,&#xA;                on_click=[State.process_image, State.get_image],&#xA;                width=&#34;100%&#34;,&#xA;            ),&#xA;            pc.divider(),&#xA;            pc.cond(&#xA;                State.image_processing,&#xA;                pc.circular_progress(is_indeterminate=True),&#xA;                pc.cond(&#xA;                     State.image_made,&#xA;                     pc.image(&#xA;                         src=State.image_url,&#xA;                         height=&#34;25em&#34;,&#xA;                         width=&#34;25em&#34;,&#xA;                    )&#xA;                )&#xA;            ),&#xA;            bg=&#34;white&#34;,&#xA;            padding=&#34;2em&#34;,&#xA;            shadow=&#34;lg&#34;,&#xA;            border_radius=&#34;lg&#34;,&#xA;        ),&#xA;        width=&#34;100%&#34;,&#xA;        height=&#34;100vh&#34;,&#xA;        bg=&#34;radial-gradient(circle at 22% 11%,rgba(62, 180, 137,.20),hsla(0,0%,100%,0) 19%)&#34;,&#xA;    )&#xA;&#xA;# Add state and page to the app.&#xA;app = pc.App(state=State)&#xA;app.add_page(index, title=&#34;Pynecone:DALL·E&#34;)&#xA;app.compile()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;      &lt;p&gt;Let&#39;s break this down.&lt;/p&gt; &#xA;      &lt;h3&gt;&lt;strong&gt;UI In Pynecone&lt;/strong&gt;&lt;/h3&gt; &#xA;      &lt;p&gt;Let&#39;s start with the UI.&lt;/p&gt; &#xA;      &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def index():&#xA;    return pc.center(&#xA;        ...&#xA;    )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;      &lt;p&gt;This &lt;code&gt;index&lt;/code&gt; function defines the frontend of the app.&lt;/p&gt; &#xA;      &lt;p&gt;We use different components such as &lt;code&gt;center&lt;/code&gt;, &lt;code&gt;vstack&lt;/code&gt;, &lt;code&gt;input&lt;/code&gt;, and &lt;code&gt;button&lt;/code&gt; to build the frontend. Components can be nested within each other to create complex layouts. And you can use keyword args to style them with the full power of CSS.&lt;/p&gt; &#xA;      &lt;p&gt;Pynecone comes with &lt;a href=&#34;https://pynecone.io/docs/library&#34;&gt;60+ built-in components&lt;/a&gt; to help you get started. We are actively adding more components, plus it&#39;s easy to &lt;a href=&#34;https://pynecone.io/docs/advanced-guide/wrapping-react&#34;&gt;create your own components&lt;/a&gt;.&lt;/p&gt; &#xA;      &lt;h3&gt;&lt;strong&gt;State&lt;/strong&gt;&lt;/h3&gt; &#xA;      &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class State(pc.State):&#xA;    &#34;&#34;&#34;The app state.&#34;&#34;&#34;&#xA;    prompt = &#34;&#34;&#xA;    image_url = &#34;&#34;&#xA;    image_processing = False&#xA;    image_made = False&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;      &lt;p&gt;The state defines all the variables (called vars) in an app that can change and the functions that change them. Here the state is comprised of a &lt;code&gt;prompt&lt;/code&gt; and &lt;code&gt;image_url&lt;/code&gt;. There are also the booleans &lt;code&gt;image_processing&lt;/code&gt; and &lt;code&gt;image_made&lt;/code&gt; to indicate when to show the circular progress and image.&lt;/p&gt; &#xA;      &lt;h3&gt;&lt;strong&gt;Event Handlers&lt;/strong&gt;&lt;/h3&gt; &#xA;      &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    def process_image(self):&#xA;        &#34;&#34;&#34;Set the image processing flag to true and indicate image is not made yet.&#34;&#34;&#34;&#xA;        self.image_processing = True&#xA;        self.image_made = False        &#xA;&#xA;    def get_image(self):&#xA;        &#34;&#34;&#34;Get the image from the prompt.&#34;&#34;&#34;&#xA;        response = openai.Image.create(prompt=self.prompt, n=1, size=&#34;1024x1024&#34;)&#xA;        self.image_url = response[&#34;data&#34;][0][&#34;url&#34;]&#xA;        self.image_processing = False&#xA;        self.image_made = True&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;      &lt;p&gt;Within the state, we define functions called event handlers that change the state vars. Event handlers are the way that we can modify the state in Pynecone. They can be called in response to user actions, such as clicking a button or typing in a text box. These actions are called events.&lt;/p&gt; &#xA;      &lt;p&gt;Our DALL·E. app has two event handlers, &lt;code&gt;process_image&lt;/code&gt; to indicate that the image is being generated and &lt;code&gt;get_image&lt;/code&gt;, which calls the OpenAI API.&lt;/p&gt; &#xA;      &lt;h3&gt;&lt;strong&gt;Routing&lt;/strong&gt;&lt;/h3&gt; &#xA;      &lt;p&gt;Finally we define our app and tell it what state to use.&lt;/p&gt; &#xA;      &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;app = pc.App(state=State)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;      &lt;p&gt;We add a route from the root of the app to the index component. We also add a title that will show up in the page preview/ browser tab.&lt;/p&gt; &#xA;      &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;app.add_page(index, title=&#34;Pynecone:DALL-E&#34;)&#xA;app.compile()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;      &lt;p&gt;You can create a multi-page app by adding more routes.&lt;/p&gt; &#xA;      &lt;h2&gt;Status&lt;/h2&gt; &#xA;      &lt;p&gt;Pynecone launched in December 2022.&lt;/p&gt; &#xA;      &lt;p&gt;As of March 2023, we are in the &lt;strong&gt;Public Beta&lt;/strong&gt; stage.&lt;/p&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;span&gt;✅&lt;/span&gt; &lt;strong&gt;Public Alpha&lt;/strong&gt;: Anyone can install and use Pynecone. There may be issues, but we are working to resolve them actively.&lt;/li&gt; &#xA;       &lt;li&gt;&lt;span&gt;🔶&lt;/span&gt; &lt;strong&gt;Public Beta&lt;/strong&gt;: Stable enough for non-enterprise use-cases.&lt;/li&gt; &#xA;       &lt;li&gt;&lt;strong&gt;Public Hosting Beta&lt;/strong&gt;: &lt;strong&gt;Optionally&lt;/strong&gt; Deploy and Host your own apps on Pynecone!&lt;/li&gt; &#xA;       &lt;li&gt;&lt;strong&gt;Public&lt;/strong&gt;: Pynecone is production ready.&lt;/li&gt; &#xA;      &lt;/ul&gt; &#xA;      &lt;p&gt;Pynecone has new releases and features coming every week! Make sure to: &lt;span&gt;⭐&lt;/span&gt; star and &lt;span&gt;👀&lt;/span&gt; watch this repository to stay up to date.&lt;/p&gt; &#xA;      &lt;h2&gt;Contributing&lt;/h2&gt; &#xA;      &lt;p&gt;We welcome contributions of any size! Below are some good ways to get started in the Pynecone community.&lt;/p&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;strong&gt;Join Our Discord&lt;/strong&gt;: Our &lt;a href=&#34;https://discord.gg/T5WSbC2YtQ&#34;&gt;Discord&lt;/a&gt; is the best place to get help on your Pynecone project and to discuss how you can contribute.&lt;/li&gt; &#xA;       &lt;li&gt;&lt;strong&gt;GitHub Discussions&lt;/strong&gt;: A great way to talk about features you want added or things that are confusing/need clarification.&lt;/li&gt; &#xA;       &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: These are an excellent way to report bugs. Additionally, you can try and solve an existing issue and submit a PR.&lt;/li&gt; &#xA;      &lt;/ul&gt; &#xA;      &lt;p&gt;We are actively looking for contributors, no matter your skill level or experience.&lt;/p&gt; &#xA;      &lt;h2&gt;License&lt;/h2&gt; &#xA;      &lt;p&gt;Pynecone is open-source and licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/pynecone-io/pynecone/main/LICENSE&#34;&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt; &#xA;     &lt;/div&gt;&#xA;    &lt;/div&gt;&#xA;   &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA; &lt;/div&gt;&#xA;&lt;/div&gt;</summary>
  </entry>
</feed>