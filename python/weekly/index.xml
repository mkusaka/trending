<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-03-02T01:56:12Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>eosphoros-ai/DB-GPT</title>
    <updated>2025-03-02T01:56:12Z</updated>
    <id>tag:github.com,2025-03-02:/eosphoros-ai/DB-GPT</id>
    <link href="https://github.com/eosphoros-ai/DB-GPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AI Native Data App Development framework with AWEL(Agentic Workflow Expression Language) and Agents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DB-GPT: AI Native Data App Development framework with AWEL(Agentic Workflow Expression Language) and Agents&lt;/h1&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/eosphoros-ai/DB-GPT/main/assets/LOGO.png&#34; width=&#34;100%&#34;&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt; &lt;a href=&#34;https://github.com/eosphoros-ai/DB-GPT&#34;&gt; &lt;img alt=&#34;stars&#34; src=&#34;https://img.shields.io/github/stars/eosphoros-ai/db-gpt?style=social&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/eosphoros-ai/DB-GPT&#34;&gt; &lt;img alt=&#34;forks&#34; src=&#34;https://img.shields.io/github/forks/eosphoros-ai/db-gpt?style=social&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt; &lt;img alt=&#34;License: MIT&#34; src=&#34;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/eosphoros-ai/DB-GPT/releases&#34;&gt; &lt;img alt=&#34;Release Notes&#34; src=&#34;https://img.shields.io/github/release/eosphoros-ai/DB-GPT&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/eosphoros-ai/DB-GPT/issues&#34;&gt; &lt;img alt=&#34;Open Issues&#34; src=&#34;https://img.shields.io/github/issues-raw/eosphoros-ai/DB-GPT&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://discord.gg/7uQnPuveTY&#34;&gt; &lt;img alt=&#34;Discord&#34; src=&#34;https://dcbadge.vercel.app/api/server/7uQnPuveTY?compact=true&amp;amp;style=flat&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://join.slack.com/t/slack-inu2564/shared_invite/zt-29rcnyw2b-N~ubOD9kFc7b7MDOAM1otA&#34;&gt; &lt;img alt=&#34;Slack&#34; src=&#34;https://badgen.net/badge/Slack/Join%20DB-GPT/0abd59?icon=slack&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://codespaces.new/eosphoros-ai/DB-GPT&#34;&gt; &lt;img alt=&#34;Open in GitHub Codespaces&#34; src=&#34;https://github.com/codespaces/badge.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eosphoros-ai/DB-GPT/main/README.zh.md&#34;&gt;&lt;strong&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/eosphoros-ai/DB-GPT/main/README.ja.md&#34;&gt;&lt;strong&gt;Êó•Êú¨Ë™û&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://discord.gg/7uQnPuveTY&#34;&gt;&lt;strong&gt;Discord&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://docs.dbgpt.site&#34;&gt;&lt;strong&gt;Documents&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/eosphoros-ai/DB-GPT/raw/main/README.zh.md#%E8%81%94%E7%B3%BB%E6%88%91%E4%BB%AC&#34;&gt;&lt;strong&gt;ÂæÆ‰ø°&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/eosphoros-ai/community&#34;&gt;&lt;strong&gt;Community&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/pdf/2312.17449.pdf&#34;&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;What is DB-GPT?&lt;/h2&gt; &#xA;&lt;p&gt;ü§ñ &lt;strong&gt;DB-GPT is an open source AI native data app development framework with AWEL(Agentic Workflow Expression Language) and agents&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The purpose is to build infrastructure in the field of large models, through the development of multiple technical capabilities such as multi-model management (SMMF), Text2SQL effect optimization, RAG framework and optimization, Multi-Agents framework collaboration, AWEL (agent workflow orchestration), etc. Which makes large model applications with data simpler and more convenient.&lt;/p&gt; &#xA;&lt;p&gt;üöÄ &lt;strong&gt;In the Data 3.0 era, based on models and databases, enterprises and developers can build their own bespoke applications with less code.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;DISCKAIMER&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eosphoros-ai/DB-GPT/main/DISCKAIMER.md&#34;&gt;disckaimer&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;AI-Native Data App&lt;/h3&gt; &#xA;&lt;hr&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://docs.dbgpt.cn/docs/changelog/Released_V0.6.0&#34;&gt;Released V0.6.0 | A set of significant upgrades&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;&#34;&gt;The AWEL upgrade to 2.0&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;&#34;&gt;GraphRAG&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;&#34;&gt;AI Native Data App construction and management&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;&#34;&gt;The GPT-Vis upgrade, supporting a variety of visualization charts&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;&#34;&gt;Support Text2NLU and Text2GQL fine-tuning&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;&#34;&gt;Support Intent recognition, slot filling, and Prompt management&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/a2f0a875-df8c-4f0d-89a3-eed321c02113&#34; alt=&#34;app_chat_v0 6&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/c8cc85bb-e3c2-4fab-8fb9-7b4b469d0611&#34; alt=&#34;app_manage_chat_data_v0 6&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/b15d6ebe-54c4-4527-a16d-02fbbaf20dc9&#34; alt=&#34;chat_dashboard_display_v0 6&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/40761507-a1e1-49d4-b49a-3dd9a5ea41cc&#34; alt=&#34;agent_prompt_awel_v0 6&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eosphoros-ai/DB-GPT/main/#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eosphoros-ai/DB-GPT/main/#install&#34;&gt;Install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eosphoros-ai/DB-GPT/main/#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eosphoros-ai/DB-GPT/main/#contribution&#34;&gt;Contribution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eosphoros-ai/DB-GPT/main/#contact-information&#34;&gt;Contact&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;The architecture of DB-GPT is shown in the following figure:&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/eosphoros-ai/DB-GPT/main/assets/dbgpt.png&#34; width=&#34;800&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;The core capabilities include the following parts:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;RAG (Retrieval Augmented Generation)&lt;/strong&gt;: RAG is currently the most practically implemented and urgently needed domain. DB-GPT has already implemented a framework based on RAG, allowing users to build knowledge-based applications using the RAG capabilities of DB-GPT.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;GBI (Generative Business Intelligence)&lt;/strong&gt;: Generative BI is one of the core capabilities of the DB-GPT project, providing the foundational data intelligence technology to build enterprise report analysis and business insights.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Fine-tuning Framework&lt;/strong&gt;: Model fine-tuning is an indispensable capability for any enterprise to implement in vertical and niche domains. DB-GPT provides a complete fine-tuning framework that integrates seamlessly with the DB-GPT project. In recent fine-tuning efforts, an accuracy rate based on the Spider dataset has been achieved at 82.5%.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data-Driven Multi-Agents Framework&lt;/strong&gt;: DB-GPT offers a data-driven self-evolving multi-agents framework, aiming to continuously make decisions and execute based on data.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data Factory&lt;/strong&gt;: The Data Factory is mainly about cleaning and processing trustworthy knowledge and data in the era of large models.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data Sources&lt;/strong&gt;: Integrating various data sources to seamlessly connect production business data to the core capabilities of DB-GPT.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;SubModule&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/eosphoros-ai/DB-GPT-Hub&#34;&gt;DB-GPT-Hub&lt;/a&gt; Text-to-SQL workflow with high performance by applying Supervised Fine-Tuning (SFT) on Large Language Models (LLMs).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/eosphoros-ai/dbgpts&#34;&gt;dbgpts&lt;/a&gt; dbgpts is the official repository which contains some data apps„ÄÅAWEL operators„ÄÅAWEL workflow templates and agents which build upon DB-GPT.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Text2SQL Finetune&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;support llms&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; LLaMA&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; LLaMA-2&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; BLOOM&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; BLOOMZ&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Falcon&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Baichuan&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Baichuan2&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; InternLM&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Qwen&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; XVERSE&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; ChatGLM2&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;SFT Accuracy As of October 10, 2023, through the fine-tuning of an open-source model with 13 billion parameters using this project, we have achieved execution accuracy on the Spider dataset that surpasses even GPT-4!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/eosphoros-ai/DB-GPT-Hub&#34;&gt;More Information about Text2SQL finetune&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/eosphoros-ai/DB-GPT-Plugins&#34;&gt;DB-GPT-Plugins&lt;/a&gt; DB-GPT Plugins that can run Auto-GPT plugin directly&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/eosphoros-ai/GPT-Vis&#34;&gt;GPT-Vis&lt;/a&gt; Visualization protocol&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&amp;amp;logo=docker&amp;amp;logoColor=white&#34; alt=&#34;Docker&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&amp;amp;logo=linux&amp;amp;logoColor=black&#34; alt=&#34;Linux&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/mac%20os-000000?style=for-the-badge&amp;amp;logo=macos&amp;amp;logoColor=F0F0F0&#34; alt=&#34;macOS&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Windows-0078D6?style=for-the-badge&amp;amp;logo=windows&amp;amp;logoColor=white&#34; alt=&#34;Windows&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/overview&#34;&gt;&lt;strong&gt;Usage Tutorial&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/installation&#34;&gt;&lt;strong&gt;Install&lt;/strong&gt;&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/installation/docker&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/installation/sourcecode&#34;&gt;Source Code&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/quickstart&#34;&gt;&lt;strong&gt;Quickstart&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/operation_manual&#34;&gt;&lt;strong&gt;Application&lt;/strong&gt;&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/cookbook/app/data_analysis_app_develop&#34;&gt;Development Guide&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/application/app_usage&#34;&gt;App Usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/application/awel_flow_usage&#34;&gt;AWEL Flow Usage&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/operation_manual/advanced_tutorial/debugging&#34;&gt;&lt;strong&gt;Debugging&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/application/advanced_tutorial/cli&#34;&gt;&lt;strong&gt;Advanced Usage&lt;/strong&gt;&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/application/advanced_tutorial/smmf&#34;&gt;SMMF&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/application/fine_tuning_manual/dbgpt_hub&#34;&gt;Finetune&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/awel/tutorial&#34;&gt;AWEL&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;At present, we have introduced several key features to showcase our current capabilities:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Private Domain Q&amp;amp;A &amp;amp; Data Processing&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The DB-GPT project offers a range of functionalities designed to improve knowledge base construction and enable efficient storage and retrieval of both structured and unstructured data. These functionalities include built-in support for uploading multiple file formats, the ability to integrate custom data extraction plug-ins, and unified vector storage and retrieval capabilities for effectively managing large volumes of information.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-Data Source &amp;amp; GBI(Generative Business intelligence)&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The DB-GPT project facilitates seamless natural language interaction with diverse data sources, including Excel, databases, and data warehouses. It simplifies the process of querying and retrieving information from these sources, empowering users to engage in intuitive conversations and gain insights. Moreover, DB-GPT supports the generation of analytical reports, providing users with valuable data summaries and interpretations.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-Agents&amp;amp;Plugins&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;It offers support for custom plug-ins to perform various tasks and natively integrates the Auto-GPT plug-in model. The Agents protocol adheres to the Agent Protocol standard.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automated Fine-tuning text2SQL&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;We&#39;ve also developed an automated fine-tuning lightweight framework centred on large language models (LLMs), Text2SQL datasets, LoRA/QLoRA/Pturning, and other fine-tuning methods. This framework simplifies Text-to-SQL fine-tuning, making it as straightforward as an assembly line process. &lt;a href=&#34;https://github.com/eosphoros-ai/DB-GPT-Hub&#34;&gt;DB-GPT-Hub&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;SMMF(Service-oriented Multi-model Management Framework)&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;We offer extensive model support, including dozens of large language models (LLMs) from both open-source and API agents, such as LLaMA/LLaMA2, Baichuan, ChatGLM, Wenxin, Tongyi, Zhipu, and many more.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;News &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2.5-72B-Instruct&#34;&gt;Qwen2.5-72B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2.5-32B-Instruct&#34;&gt;Qwen2.5-32B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2.5-14B-Instruct&#34;&gt;Qwen2.5-14B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2.5-7B-Instruct&#34;&gt;Qwen2.5-7B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2.5-3B-Instruct&#34;&gt;Qwen2.5-3B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct&#34;&gt;Qwen2.5-1.5B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct&#34;&gt;Qwen2.5-0.5B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct&#34;&gt;Qwen2.5-Coder-7B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B-Instruct&#34;&gt;Qwen2.5-Coder-1.5B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct&#34;&gt;Meta-Llama-3.1-405B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct&#34;&gt;Meta-Llama-3.1-70B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct&#34;&gt;Meta-Llama-3.1-8B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/google/gemma-2-27b-it&#34;&gt;gemma-2-27b-it&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/google/gemma-2-9b-it&#34;&gt;gemma-2-9b-it&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Instruct&#34;&gt;DeepSeek-Coder-V2-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct&#34;&gt;DeepSeek-Coder-V2-Lite-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2-57B-A14B-Instruct&#34;&gt;Qwen2-57B-A14B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2-72B-Instruct&#34;&gt;Qwen2-72B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2-7B-Instruct&#34;&gt;Qwen2-7B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2-1.5B-Instruct&#34;&gt;Qwen2-1.5B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2-0.5B-Instruct&#34;&gt;Qwen2-0.5B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/THUDM/glm-4-9b-chat&#34;&gt;glm-4-9b-chat&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3&#34;&gt;Phi-3&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/01-ai/Yi-1.5-34B-Chat&#34;&gt;Yi-1.5-34B-Chat&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/01-ai/Yi-1.5-9B-Chat&#34;&gt;Yi-1.5-9B-Chat&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/01-ai/Yi-1.5-6B-Chat&#34;&gt;Yi-1.5-6B-Chat&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen1.5-110B-Chat&#34;&gt;Qwen1.5-110B-Chat&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen1.5-MoE-A2.7B-Chat&#34;&gt;Qwen1.5-MoE-A2.7B-Chat&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct&#34;&gt;Meta-Llama-3-70B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct&#34;&gt;Meta-Llama-3-8B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/CodeQwen1.5-7B-Chat&#34;&gt;CodeQwen1.5-7B-Chat&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen1.5-32B-Chat&#34;&gt;Qwen1.5-32B-Chat&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Nexusflow/Starling-LM-7B-beta&#34;&gt;Starling-LM-7B-beta&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/google/gemma-7b-it&#34;&gt;gemma-7b-it&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/google/gemma-2b-it&#34;&gt;gemma-2b-it&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0&#34;&gt;SOLAR-10.7B&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1&#34;&gt;Mixtral-8x7B&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/Qwen/Qwen-72B-Chat&#34;&gt;Qwen-72B-Chat&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;üî•üî•üî• &lt;a href=&#34;https://huggingface.co/01-ai/Yi-34B-Chat&#34;&gt;Yi-34B-Chat&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.site/docs/modules/smmf&#34;&gt;More Supported LLMs&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Privacy and Security&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;We ensure the privacy and security of data through the implementation of various technologies, including privatized large models and proxy desensitization.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Support Datasources&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://docs.dbgpt.cn/docs/modules/connections&#34;&gt;Datasources&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Image&lt;/h2&gt; &#xA;&lt;p&gt;üåê &lt;a href=&#34;https://www.codewithgpu.com/i/eosphoros-ai/DB-GPT/dbgpt&#34;&gt;AutoDL Image&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Language Switching&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;In the .env configuration file, modify the LANGUAGE parameter to switch to different languages. The default is English (Chinese: zh, English: en, other languages to be added later).&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contribution&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To check detailed guidelines for new contributions, please refer &lt;a href=&#34;https://github.com/eosphoros-ai/DB-GPT/raw/main/CONTRIBUTING.md&#34;&gt;how to contribute&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Contributors Wall&lt;/h3&gt; &#xA;&lt;a href=&#34;https://github.com/eosphoros-ai/DB-GPT/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=eosphoros-ai/DB-GPT&amp;amp;max=200&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;Licence&lt;/h2&gt; &#xA;&lt;p&gt;The MIT License (MIT)&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you want to understand the overall architecture of DB-GPT, please cite &lt;a href=&#34;https://arxiv.org/abs/2312.17449&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt; and &lt;a href=&#34;https:// arxiv.org/abs/2404.10209&#34; target=&#34;_blank&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you want to learn about using DB-GPT for Agent development, please cite the &lt;a href=&#34;https://arxiv.org/abs/2412.13520&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{xue2023dbgpt,&#xA;      title={DB-GPT: Empowering Database Interactions with Private Large Language Models}, &#xA;      author={Siqiao Xue and Caigao Jiang and Wenhui Shi and Fangyin Cheng and Keting Chen and Hongjun Yang and Zhiping Zhang and Jianshan He and Hongyang Zhang and Ganglin Wei and Wang Zhao and Fan Zhou and Danrui Qi and Hong Yi and Shaodong Liu and Faqiang Chen},&#xA;      year={2023},&#xA;      journal={arXiv preprint arXiv:2312.17449},&#xA;      url={https://arxiv.org/abs/2312.17449}&#xA;}&#xA;@misc{huang2024romasrolebasedmultiagentdatabase,&#xA;      title={ROMAS: A Role-Based Multi-Agent System for Database monitoring and Planning}, &#xA;      author={Yi Huang and Fangyin Cheng and Fan Zhou and Jiahui Li and Jian Gong and Hongjun Yang and Zhidong Fan and Caigao Jiang and Siqiao Xue and Faqiang Chen},&#xA;      year={2024},&#xA;      eprint={2412.13520},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.AI},&#xA;      url={https://arxiv.org/abs/2412.13520}, &#xA;}&#xA;@inproceedings{xue2024demonstration,&#xA;      title={Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models}, &#xA;      author={Siqiao Xue and Danrui Qi and Caigao Jiang and Wenhui Shi and Fangyin Cheng and Keting Chen and Hongjun Yang and Zhiping Zhang and Jianshan He and Hongyang Zhang and Ganglin Wei and Wang Zhao and Fan Zhou and Hong Yi and Shaodong Liu and Hongjun Yang and Faqiang Chen},&#xA;      year={2024},&#xA;      booktitle = &#34;Proceedings of the VLDB Endowment&#34;,&#xA;      url={https://arxiv.org/abs/2404.10209}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contact Information&lt;/h2&gt; &#xA;&lt;p&gt;We are working on building a community, if you have any ideas for building the community, feel free to contact us. &lt;a href=&#34;https://discord.gg/7uQnPuveTY&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/7uQnPuveTY?compact=true&amp;amp;style=flat&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#csunny/DB-GPT&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=csunny/DB-GPT&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/PIKE-RAG</title>
    <updated>2025-03-02T01:56:12Z</updated>
    <id>tag:github.com,2025-03-02:/microsoft/PIKE-RAG</id>
    <link href="https://github.com/microsoft/PIKE-RAG" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/microsoft/PIKE-RAG/main/docs/source/images/logo/PIKE-RAG_horizontal_black-font.svg?sanitize=true&#34; alt=&#34;PIKE-RAG&#34; style=&#34;width: 80%; max-width: 100%; height: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://pike-rag.azurewebsites.net/&#34;&gt;üåêOnline Demo&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2501.11551&#34;&gt;üìäTechnical Report&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/PIKE-RAG/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/microsoft/PIKE-RAG&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/microsoft/PIKE-RAG/actions/workflows/github-code-scanning/codeql&#34;&gt;&lt;img src=&#34;https://github.com/microsoft/PIKE-RAG/actions/workflows/github-code-scanning/codeql/badge.svg?sanitize=true&#34; alt=&#34;CodeQL&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/microsoft/PIKE-RAG/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/microsoft/PIKE-RAG&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/microsoft/PIKE-RAG/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/release-date-pre/microsoft/PIKE-RAG&#34; alt=&#34;ReleaseDate&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/microsoft/PIKE-RAG/commits/main&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/commits-since/microsoft/PIKE-RAG/latest/main&#34; alt=&#34;Commits&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/microsoft/PIKE-RAG/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-pr/microsoft/PIKE-RAG&#34; alt=&#34;Pull Requests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/microsoft/PIKE-RAG/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/microsoft/PIKE-RAG&#34; alt=&#34;Issues&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation&lt;/h1&gt; &#xA;&lt;h2&gt;Why PIKE-RAG?&lt;/h2&gt; &#xA;&lt;p&gt;In recent years, Retrieval Augmented Generation (RAG) systems have made significant progress in extending the capabilities of Large Language Models (LLM) through external retrieval. However, these systems still face challenges in meeting the complex and diverse needs of real-world industrial applications. Relying solely on direct retrieval is insufficient for extracting deep domain-specific knowledge from professional corpora and performing logical reasoning. To address this issue, we propose the PIKE-RAG (sPecIalized KnowledgE and Rationale Augmented Generation) method, which focuses on extracting, understanding, and applying domain-specific knowledge while building coherent reasoning logic to gradually guide LLMs toward accurate responses.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/microsoft/PIKE-RAG/main/docs/source/images/readme/pipeline.png&#34; alt=&#34;Overview of PIKE-RAG Framework&#34; style=&#34;width: 80%; max-width: 100%; height: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;PIKE-RAG framework mainly consists of several basic modules, including document parsing, knowledge extraction, knowledge storage, knowledge retrieval, knowledge organization, knowledge-centric reasoning, and task decomposition and coordination. By adjusting the submodules within the main modules, it is possible to achieve RAG systems that focus on different capabilities to meet the diverse needs of real-world scenarios.&lt;/p&gt; &#xA;&lt;p&gt;For example, in case &lt;em&gt;patient&#39;s historical medical records searching&lt;/em&gt;, it focuses on the &lt;em&gt;factual information retrieval capability&lt;/em&gt;. The main challenges are that (1) the understanding and extraction of knowledge are often hindered by inappropriate knowledge segmentation, disrupting semantic coherence, leading to a complex and inefficient retrieval process; (2) commonly used embedding-based knowledge retrieval is limited by embedding models&#39; ability to align professional terms and aliases, reducing system accuracy. With PIKE-RAG, we can improve the accuracy of knowledge extraction and retrieval by using context-aware segmentation techniques, automatic term label alignment techniques, and multi-granularity knowledge extraction methods during the knowledge extraction process, thereby enhancing factual information retrieval capability, as shown in the pipeline below.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/microsoft/PIKE-RAG/main/docs/source/images/readme/L1_pipeline.png&#34; alt=&#34;A Pipeline Focusing on Factual Information Retrieval&#34; style=&#34;width: 80%; max-width: 100%; height: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;For complex task like &lt;em&gt;reasonable treatment plans and coping measures suggestions for patients&lt;/em&gt;, it requires more advanced capabilities: strong domain-specific knowledge are required to accurately understand the task and sometimes reasonably decompose it; advanced data retrieval, processing and organization techniques are also required for potential tendency prediction; while multi-agents planning will also be useful to take considerations of both creativity and reliance. In such case, a richer pipeline below can be initialized to achieve this.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/microsoft/PIKE-RAG/main/docs/source/images/readme/L4_pipeline.png&#34; alt=&#34;A Pipeline Focusing on Fact-based Innovation and Generation&#34; style=&#34;width: 80%; max-width: 100%; height: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;In public benchmark tests, PIKE-RAG demonstrated excellent performance on several multi-hop question answering datasets such as HotpotQA, 2WikiMultiHopQA, and MuSiQue. Compared to existing benchmark methods, PIKE-RAG excelled in metrics like accuracy and F1 score. On the HotpotQA dataset, PIKE-RAG achieved an accuracy of 87.6%, on 2WikiMultiHopQA it reached 82.0%, and on the more challenging MuSiQue dataset, it achieved 59.6%. These results indicate that PIKE-RAG has significant advantages in handling complex reasoning tasks, especially in scenarios that require integrating multi-source information and performing multi-step reasoning.&lt;/p&gt; &#xA;&lt;p&gt;PIKE-RAG has been tested and significantly improved question answering accuracy in fields such as industrial manufacturing, mining, and pharmaceuticals. In the future, we will continue to explore its application in more fields. Additionally, we will continue to explore other forms of knowledge and logic and their optimal adaptation to specific scenarios.&lt;/p&gt; &#xA;&lt;h2&gt;For More Details&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üìä &lt;a href=&#34;https://arxiv.org/abs/2501.11551&#34;&gt;Technical Report&lt;/a&gt; will illustrate the industrial RAG problem classification, introduce the main components in PIKE-RAG, and show some experimental results in public benchmarks.&lt;/li&gt; &#xA; &lt;li&gt;üåê &lt;a href=&#34;https://pike-rag.azurewebsites.net/&#34;&gt;Online Demo&lt;/a&gt; is a show-case of our Knowledge-Aware decomposition pipeline for L2 RAG task.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repo and set up the Python environment, refer to &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PIKE-RAG/main/docs/guides/environment.md&#34;&gt;this document&lt;/a&gt;;&lt;/li&gt; &#xA; &lt;li&gt;Create a &lt;code&gt;.env&lt;/code&gt; file to save your endpoint information (and some other environment variables if needed), refer to &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PIKE-RAG/main/docs/guides/env_file.md&#34;&gt;this document&lt;/a&gt;;&lt;/li&gt; &#xA; &lt;li&gt;Modify the &lt;em&gt;yaml config&lt;/em&gt; files and try the scripts under &lt;em&gt;examples/&lt;/em&gt;, refer to &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PIKE-RAG/main/docs/guides/examples.md&#34;&gt;this document&lt;/a&gt;;&lt;/li&gt; &#xA; &lt;li&gt;Build up your own pipeline and/or add your own components!&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&#34;https://cla.opensource.microsoft.com&#34;&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h2&gt;Trademarks&lt;/h2&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>OpenSPG/KAG</title>
    <updated>2025-03-02T01:56:12Z</updated>
    <id>tag:github.com,2025-03-02:/OpenSPG/KAG</id>
    <link href="https://github.com/OpenSPG/KAG" rel="alternate"></link>
    <summary type="html">&lt;p&gt;KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs. It is used to build logical reasoning and factual Q&amp;A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;KAG: Knowledge Augmented Generation&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://spg.openkg.cn/en-US&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/OpenSPG/KAG/master/_static/images/OpenSPG-1.png&#34; width=&#34;520&#34; alt=&#34;openspg logo&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenSPG/KAG/master/README.md&#34;&gt;English&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/OpenSPG/KAG/master/README_cn.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/OpenSPG/KAG/master/README_ja.md&#34;&gt;Êó•Êú¨Ë™ûÁâà„Éâ„Ç≠„É•„É°„É≥„Éà&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://arxiv.org/pdf/2409.13731&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2409.13731-b31b1b&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/OpenSPG/KAG/releases/latest&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/v/release/OpenSPG/KAG?color=blue&amp;amp;label=Latest%20Release&#34; alt=&#34;Latest Release&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://openspg.yuque.com/ndx6g9/docs_en&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/User%20Guide-1e8b93?logo=readthedocs&amp;amp;logoColor=f5f5f5&#34; alt=&#34;User Guide&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/OpenSPG/KAG/raw/main/LICENSE&#34;&gt; &lt;img height=&#34;21&#34; src=&#34;https://img.shields.io/badge/License-Apache--2.0-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4&#34; alt=&#34;license&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://discord.gg/PURG77zhQ7&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/1329648479709958236?style=for-the-badge&amp;amp;logo=discord&amp;amp;label=Discord&#34; alt=&#34;Discord&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h1&gt;1. What is KAG?&lt;/h1&gt; &#xA;&lt;p&gt;KAG is a logical reasoning and Q&amp;amp;A framework based on the &lt;a href=&#34;https://github.com/OpenSPG/openspg&#34;&gt;OpenSPG&lt;/a&gt; engine and large language models, which is used to build logical reasoning and Q&amp;amp;A solutions for vertical domain knowledge bases. KAG can effectively overcome the ambiguity of traditional RAG vector similarity calculation and the noise problem of GraphRAG introduced by OpenIE. KAG supports logical reasoning and multi-hop fact Q&amp;amp;A, etc., and is significantly better than the current SOTA method.&lt;/p&gt; &#xA;&lt;p&gt;The goal of KAG is to build a knowledge-enhanced LLM service framework in professional domains, supporting logical reasoning, factual Q&amp;amp;A, etc. KAG fully integrates the logical and factual characteristics of the KGs. Its core features include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Knowledge and Chunk Mutual Indexing structure to integrate more complete contextual text information&lt;/li&gt; &#xA; &lt;li&gt;Knowledge alignment using conceptual semantic reasoning to alleviate the noise problem caused by OpenIE&lt;/li&gt; &#xA; &lt;li&gt;Schema-constrained knowledge construction to support the representation and construction of domain expert knowledge&lt;/li&gt; &#xA; &lt;li&gt;Logical form-guided hybrid reasoning and retrieval to support logical reasoning and multi-hop reasoning Q&amp;amp;A&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;‚≠êÔ∏è Star our repository to stay up-to-date with exciting new features and improvements! Get instant notifications for new releases! üåü&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenSPG/KAG/master/_static/images/star-kag.gif&#34; alt=&#34;Star KAG&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;2. Core Features&lt;/h1&gt; &#xA;&lt;h2&gt;2.1 Knowledge Representation&lt;/h2&gt; &#xA;&lt;p&gt;In the context of private knowledge bases, unstructured data, structured information, and business expert experience often coexist. KAG references the DIKW hierarchy to upgrade SPG to a version that is friendly to LLMs.&lt;/p&gt; &#xA;&lt;p&gt;For unstructured data such as news, events, logs, and books, as well as structured data like transactions, statistics, and approvals, along with business experience and domain knowledge rules, KAG employs techniques such as layout analysis, knowledge extraction, property normalization, and semantic alignment to integrate raw business data and expert rules into a unified business knowledge graph.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenSPG/KAG/master/_static/images/kag-diag.jpg&#34; alt=&#34;KAG Diagram&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This makes it compatible with schema-free information extraction and schema-constrained expertise construction on the same knowledge type (e. G., entity type, event type), and supports the cross-index representation between the graph structure and the original text block.&lt;/p&gt; &#xA;&lt;p&gt;This mutual index representation is helpful to the construction of inverted index based on graph structure, and promotes the unified representation and reasoning of logical forms.&lt;/p&gt; &#xA;&lt;h2&gt;2.2 Mixed Reasoning Guided by Logic Forms&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenSPG/KAG/master/_static/images/kag-lf-solver.png&#34; alt=&#34;Logical Form Solver&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;KAG proposes a logically formal guided hybrid solution and inference engine.&lt;/p&gt; &#xA;&lt;p&gt;The engine includes three types of operators: planning, reasoning, and retrieval, which transform natural language problems into problem solving processes that combine language and notation.&lt;/p&gt; &#xA;&lt;p&gt;In this process, each step can use different operators, such as exact match retrieval, text retrieval, numerical calculation or semantic reasoning, so as to realize the integration of four different problem solving processes: Retrieval, Knowledge Graph reasoning, language reasoning and numerical calculation.&lt;/p&gt; &#xA;&lt;h1&gt;3. Release Notes&lt;/h1&gt; &#xA;&lt;h2&gt;3.1 Latest Updates&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2025.01.07 : Support domain knowledge injection, domain schema customization, QFS tasks support, Visual query analysis, enables schema-constraint mode for extraction, etc.&lt;/li&gt; &#xA; &lt;li&gt;2024.11.21 : Support Word docs upload, model invoke concurrency setting, User experience optimization, etc.&lt;/li&gt; &#xA; &lt;li&gt;2024.10.25 : KAG initial release&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;3.2 Future Plans&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Logical reasoning optimization, conversational tasks support&lt;/li&gt; &#xA; &lt;li&gt;kag-model release, kag solution for event reasoning knowledge graph and medical knowledge graph&lt;/li&gt; &#xA; &lt;li&gt;kag front-end open source, distributed build support, mathematical reasoning optimization&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;4. Quick Start&lt;/h1&gt; &#xA;&lt;h2&gt;4.1 product-based (for ordinary users)&lt;/h2&gt; &#xA;&lt;h3&gt;4.1.1 Engine &amp;amp; Dependent Image Installation&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Recommend System Version:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;macOS UserÔºömacOS Monterey 12.6 or later&#xA;Linux UserÔºöCentOS 7 / Ubuntu 20.04 or later&#xA;Windows UserÔºöWindows 10 LTSC 2021 or later&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Software Requirements:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;macOS / Linux UserÔºöDockerÔºåDocker Compose&#xA;Windows UserÔºöWSL 2 / Hyper-VÔºåDockerÔºåDocker Compose&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Use the following commands to download the docker-compose.yml file and launch the services with Docker Compose.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# set the HOME environment variable (only Windows users need to execute this command)&#xA;# set HOME=%USERPROFILE%&#xA;&#xA;curl -sSL https://raw.githubusercontent.com/OpenSPG/openspg/refs/heads/master/dev/release/docker-compose-west.yml -o docker-compose-west.yml&#xA;docker compose -f docker-compose-west.yml up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;4.1.2 Use the product&lt;/h3&gt; &#xA;&lt;p&gt;Navigate to the default url of the KAG product with your browser: &lt;a href=&#34;http://127.0.0.1:8887&#34;&gt;http://127.0.0.1:8887&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Default Username: openspg&#xA;Default password: openspg@kag&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://openspg.yuque.com/ndx6g9/cwh47i/rs7gr8g4s538b1n7#rtOlA&#34;&gt;KAG usage (product mode)&lt;/a&gt; for detailed introduction.&lt;/p&gt; &#xA;&lt;h2&gt;4.2 toolkit-based (for developers)&lt;/h2&gt; &#xA;&lt;h3&gt;4.2.1 Engine &amp;amp; Dependent Image Installation&lt;/h3&gt; &#xA;&lt;p&gt;Refer to the 3.1 section to complete the installation of the engine &amp;amp; dependent image.&lt;/p&gt; &#xA;&lt;h3&gt;4.2.2 Installation of KAG&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;macOS / Linux developers&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;# Create conda env: conda create -n kag-demo python=3.10 &amp;amp;&amp;amp; conda activate kag-demo&#xA;&#xA;# Clone code: git clone https://github.com/OpenSPG/KAG.git&#xA;&#xA;# Install KAG: cd KAG &amp;amp;&amp;amp; pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Windows developers&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;# Install the official Python 3.8.10 or later, install Git.&#xA;&#xA;# Create and activate Python venv: py -m venv kag-demo &amp;amp;&amp;amp; kag-demo\Scripts\activate&#xA;&#xA;# Clone code: git clone https://github.com/OpenSPG/KAG.git&#xA;&#xA;# Install KAG: cd KAG &amp;amp;&amp;amp; pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;4.2.3 Use the toolkit&lt;/h3&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://openspg.yuque.com/ndx6g9/cwh47i/rs7gr8g4s538b1n7#cikso&#34;&gt;KAG usage (developer mode)&lt;/a&gt; guide for detailed introduction of the toolkit. Then you can use the built-in components to reproduce the performance results of the built-in datasets, and apply those components to new busineness scenarios.&lt;/p&gt; &#xA;&lt;h1&gt;5. Technical Architecture&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenSPG/KAG/master/_static/images/kag-arch.png&#34; alt=&#34;KAG technical architecture&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The KAG framework includes three parts: kg-builder, kg-solver, and kag-model. This release only involves the first two parts, kag-model will be gradually open source release in the future.&lt;/p&gt; &#xA;&lt;p&gt;kg-builder implements a knowledge representation that is friendly to large-scale language models (LLM). Based on the hierarchical structure of DIKW (data, information, knowledge and wisdom), IT upgrades SPG knowledge representation ability, and is compatible with information extraction without schema constraints and professional knowledge construction with schema constraints on the same knowledge type (such as entity type and event type), it also supports the mutual index representation between the graph structure and the original text block, which supports the efficient retrieval of the reasoning question and answer stage.&lt;/p&gt; &#xA;&lt;p&gt;kg-solver uses a logical symbol-guided hybrid solving and reasoning engine that includes three types of operators: planning, reasoning, and retrieval, to transform natural language problems into a problem-solving process that combines language and symbols. In this process, each step can use different operators, such as exact match retrieval, text retrieval, numerical calculation or semantic reasoning, so as to realize the integration of four different problem solving processes: Retrieval, Knowledge Graph reasoning, language reasoning and numerical calculation.&lt;/p&gt; &#xA;&lt;h1&gt;6. Community &amp;amp; Support&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;GitHub&lt;/strong&gt;: &lt;a href=&#34;https://github.com/OpenSPG/KAG&#34;&gt;https://github.com/OpenSPG/KAG&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Website&lt;/strong&gt;: &lt;a href=&#34;https://spg.openkg.cn/&#34;&gt;https://spg.openkg.cn/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Discord &lt;a href=&#34;https://discord.gg/PURG77zhQ7&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/1329648479709958236?style=for-the-badge&amp;amp;logo=discord&amp;amp;label=Discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Join our &lt;a href=&#34;https://discord.gg/PURG77zhQ7&#34;&gt;Discord&lt;/a&gt; community.&lt;/p&gt; &#xA;&lt;h2&gt;WeChat&lt;/h2&gt; &#xA;&lt;p&gt;Follow OpenSPG Official Account to get technical articles and product updates about OpenSPG and KAG.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/OpenSPG/KAG/master/_static/images/openspg-qr.png&#34; alt=&#34;Contact Us: OpenSPG QR-code&#34; width=&#34;200&#34;&gt; &#xA;&lt;p&gt;Scan the QR code below to join our WeChat group.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/OpenSPG/KAG/master/_static/images/robot-qr.JPG&#34; alt=&#34;Join WeChat group&#34; width=&#34;200&#34;&gt; &#xA;&lt;h1&gt;7. Differences between KAG, RAG, and GraphRAG&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;KAG introduction and applications&lt;/strong&gt;: &lt;a href=&#34;https://github.com/orgs/OpenSPG/discussions/52&#34;&gt;https://github.com/orgs/OpenSPG/discussions/52&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;8. Citation&lt;/h1&gt; &#xA;&lt;p&gt;If you use this software, please cite it as below:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2409.13731&#34;&gt;KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;KGFabric: A Scalable Knowledge Graph Warehouse for Enterprise Data Interconnection&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{liang2024kag,&#xA;  title={KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation},&#xA;  author={Liang, Lei and Sun, Mengshu and Gui, Zhengke and Zhu, Zhongshu and Jiang, Zhouyu and Zhong, Ling and Qu, Yuan and Zhao, Peilong and Bo, Zhongpu and Yang, Jin and others},&#xA;  journal={arXiv preprint arXiv:2409.13731},&#xA;  year={2024}&#xA;}&#xA;&#xA;@article{yikgfabric,&#xA;  title={KGFabric: A Scalable Knowledge Graph Warehouse for Enterprise Data Interconnection},&#xA;  author={Yi, Peng and Liang, Lei and Da Zhang, Yong Chen and Zhu, Jinye and Liu, Xiangyu and Tang, Kun and Chen, Jialin and Lin, Hao and Qiu, Leijie and Zhou, Jun}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenSPG/KAG/master/LICENSE&#34;&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>