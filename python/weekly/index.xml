<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-04T01:57:45Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>facebookresearch/codellama</title>
    <updated>2024-02-04T01:57:45Z</updated>
    <id>tag:github.com,2024-02-04:/facebookresearch/codellama</id>
    <link href="https://github.com/facebookresearch/codellama" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Inference code for CodeLlama models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Introducing Code Llama&lt;/h1&gt; &#xA;&lt;p&gt;Code Llama is a family of large language models for code based on &lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;Llama 2&lt;/a&gt; providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama was developed by fine-tuning Llama 2 using a higher sampling of code. As with Llama 2, we applied considerable safety mitigations to the fine-tuned versions of the model. For detailed information on model training, architecture and parameters, evaluations, responsible AI and safety refer to our &lt;a href=&#34;https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/&#34;&gt;research paper&lt;/a&gt;. Output generated by code generation features of the Llama Materials, including Code Llama, may be subject to third party licenses, including, without limitation, open source licenses.&lt;/p&gt; &#xA;&lt;p&gt;We are unlocking the power of large language models and our latest version of Code Llama is now accessible to individuals, creators, researchers and businesses of all sizes so that they can experiment, innovate and scale their ideas responsibly. This release includes model weights and starting code for pretrained and fine-tuned Llama language models — ranging from 7B to 34B parameters.&lt;/p&gt; &#xA;&lt;p&gt;This repository is intended as a minimal example to load &lt;a href=&#34;https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/&#34;&gt;Code Llama&lt;/a&gt; models and run inference.&lt;/p&gt; &#xA;&lt;h2&gt;Download&lt;/h2&gt; &#xA;&lt;p&gt;In order to download the model weights and tokenizers, please visit the &lt;a href=&#34;https://ai.meta.com/resources/models-and-libraries/llama-downloads/&#34;&gt;Meta website&lt;/a&gt; and accept our License.&lt;/p&gt; &#xA;&lt;p&gt;Once your request is approved, you will receive a signed URL over email. Then run the download.sh script, passing the URL provided when prompted to start the download. Make sure that you copy the URL text itself, &lt;strong&gt;do not use the &#39;Copy link address&#39; option&lt;/strong&gt; when you right click the URL. If the copied URL text starts with: &lt;a href=&#34;https://download.llamameta.net&#34;&gt;https://download.llamameta.net&lt;/a&gt;, you copied it correctly. If the copied URL text starts with: &lt;a href=&#34;https://l.facebook.com&#34;&gt;https://l.facebook.com&lt;/a&gt;, you copied it the wrong way.&lt;/p&gt; &#xA;&lt;p&gt;Pre-requisites: make sure you have &lt;code&gt;wget&lt;/code&gt; and &lt;code&gt;md5sum&lt;/code&gt; installed. Then to run the script: &lt;code&gt;bash download.sh&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Keep in mind that the links expire after 24 hours and a certain amount of downloads. If you start seeing errors such as &lt;code&gt;403: Forbidden&lt;/code&gt;, you can always re-request a link.&lt;/p&gt; &#xA;&lt;h3&gt;Model sizes&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Size&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;~12.55GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;13B&lt;/td&gt; &#xA;   &lt;td&gt;24GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;34B&lt;/td&gt; &#xA;   &lt;td&gt;63GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;70B&lt;/td&gt; &#xA;   &lt;td&gt;131GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;In a conda environment with PyTorch / CUDA available, clone the repo and run in the top-level directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;p&gt;Different models require different model-parallel (MP) values:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;MP&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;13B&lt;/td&gt; &#xA;   &lt;td&gt;2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;34B&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;70B&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;All models, except the 70B python and instruct versions, support sequence lengths up to 100,000 tokens, but we pre-allocate the cache according to &lt;code&gt;max_seq_len&lt;/code&gt; and &lt;code&gt;max_batch_size&lt;/code&gt; values. So set those according to your hardware and use-case.&lt;/p&gt; &#xA;&lt;h3&gt;Pretrained Code Models&lt;/h3&gt; &#xA;&lt;p&gt;The Code Llama and Code Llama - Python models are not fine-tuned to follow instructions. They should be prompted so that the expected answer is the natural continuation of the prompt.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;code&gt;example_completion.py&lt;/code&gt; for some examples. To illustrate, see command below to run it with the &lt;code&gt;CodeLlama-7b&lt;/code&gt; model (&lt;code&gt;nproc_per_node&lt;/code&gt; needs to be set to the &lt;code&gt;MP&lt;/code&gt; value):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;torchrun --nproc_per_node 1 example_completion.py \&#xA;    --ckpt_dir CodeLlama-7b/ \&#xA;    --tokenizer_path CodeLlama-7b/tokenizer.model \&#xA;    --max_seq_len 128 --max_batch_size 4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Pretrained code models are: the Code Llama models &lt;code&gt;CodeLlama-7b&lt;/code&gt;, &lt;code&gt;CodeLlama-13b&lt;/code&gt;, &lt;code&gt;CodeLlama-34b&lt;/code&gt;, &lt;code&gt;CodeLlama-70b&lt;/code&gt; and the Code Llama - Python models &lt;code&gt;CodeLlama-7b-Python&lt;/code&gt;, &lt;code&gt;CodeLlama-13b-Python&lt;/code&gt;, &lt;code&gt;CodeLlama-34b-Python&lt;/code&gt;, &lt;code&gt;CodeLlama-70b-Python&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Code Infilling&lt;/h3&gt; &#xA;&lt;p&gt;Code Llama and Code Llama - Instruct 7B and 13B models are capable of filling in code given the surrounding context.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;code&gt;example_infilling.py&lt;/code&gt; for some examples. The &lt;code&gt;CodeLlama-7b&lt;/code&gt; model can be run for infilling with the command below (&lt;code&gt;nproc_per_node&lt;/code&gt; needs to be set to the &lt;code&gt;MP&lt;/code&gt; value):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;torchrun --nproc_per_node 1 example_infilling.py \&#xA;    --ckpt_dir CodeLlama-7b/ \&#xA;    --tokenizer_path CodeLlama-7b/tokenizer.model \&#xA;    --max_seq_len 192 --max_batch_size 4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Pretrained infilling models are: the Code Llama models &lt;code&gt;CodeLlama-7b&lt;/code&gt; and &lt;code&gt;CodeLlama-13b&lt;/code&gt; and the Code Llama - Instruct models &lt;code&gt;CodeLlama-7b-Instruct&lt;/code&gt;, &lt;code&gt;CodeLlama-13b-Instruct&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Fine-tuned Instruction Models&lt;/h3&gt; &#xA;&lt;p&gt;Code Llama - Instruct models are fine-tuned to follow instructions. To get the expected features and performance for the 7B, 13B and 34B variants, a specific formatting defined in &lt;a href=&#34;https://github.com/facebookresearch/codellama/raw/main/llama/generation.py#L319-L361&#34;&gt;&lt;code&gt;chat_completion()&lt;/code&gt;&lt;/a&gt; needs to be followed, including the &lt;code&gt;INST&lt;/code&gt; and &lt;code&gt;&amp;lt;&amp;lt;SYS&amp;gt;&amp;gt;&lt;/code&gt; tags, &lt;code&gt;BOS&lt;/code&gt; and &lt;code&gt;EOS&lt;/code&gt; tokens, and the whitespaces and linebreaks in between (we recommend calling &lt;code&gt;strip()&lt;/code&gt; on inputs to avoid double-spaces). &lt;code&gt;CodeLlama-70b-Instruct&lt;/code&gt; requires a separate turn-based prompt format defined in &lt;a href=&#34;https://github.com/facebookresearch/codellama/raw/main/llama/generation.py#L506-L548&#34;&gt;&lt;code&gt;dialog_prompt_tokens()&lt;/code&gt;&lt;/a&gt;. You can use &lt;code&gt;chat_completion()&lt;/code&gt; directly to generate answers with all instruct models; it will automatically perform the required formatting.&lt;/p&gt; &#xA;&lt;p&gt;You can also deploy additional classifiers for filtering out inputs and outputs that are deemed unsafe. See the llama-recipes repo for &lt;a href=&#34;https://github.com/facebookresearch/llama-recipes/raw/main/src/llama_recipes/inference/safety_utils.py&#34;&gt;an example&lt;/a&gt; of how to add a safety checker to the inputs and outputs of your inference code.&lt;/p&gt; &#xA;&lt;p&gt;Examples using &lt;code&gt;CodeLlama-7b-Instruct&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;torchrun --nproc_per_node 1 example_instructions.py \&#xA;    --ckpt_dir CodeLlama-7b-Instruct/ \&#xA;    --tokenizer_path CodeLlama-7b-Instruct/tokenizer.model \&#xA;    --max_seq_len 512 --max_batch_size 4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Fine-tuned instruction-following models are: the Code Llama - Instruct models &lt;code&gt;CodeLlama-7b-Instruct&lt;/code&gt;, &lt;code&gt;CodeLlama-13b-Instruct&lt;/code&gt;, &lt;code&gt;CodeLlama-34b-Instruct&lt;/code&gt;, &lt;code&gt;CodeLlama-70b-Instruct&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Code Llama is a new technology that carries potential risks with use. Testing conducted to date has not — and could not — cover all scenarios. In order to help developers address these risks, we have created the &lt;a href=&#34;https://github.com/facebookresearch/llama/raw/main/Responsible-Use-Guide.pdf&#34;&gt;Responsible Use Guide&lt;/a&gt;. More details can be found in our research papers as well.&lt;/p&gt; &#xA;&lt;h2&gt;Issues&lt;/h2&gt; &#xA;&lt;p&gt;Please report any software “bug”, or other problems with the models through one of the following means:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Reporting issues with the model: &lt;a href=&#34;http://github.com/facebookresearch/codellama&#34;&gt;github.com/facebookresearch/codellama&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Reporting risky content generated by the model: &lt;a href=&#34;http://developers.facebook.com/llama_output_feedback&#34;&gt;developers.facebook.com/llama_output_feedback&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Reporting bugs and security concerns: &lt;a href=&#34;http://facebook.com/whitehat/info&#34;&gt;facebook.com/whitehat/info&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Model Card&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/codellama/main/MODEL_CARD.md&#34;&gt;MODEL_CARD.md&lt;/a&gt; for the model card of Code Llama.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Our model and weights are licensed for both researchers and commercial entities, upholding the principles of openness. Our mission is to empower individuals, and industry through this opportunity, while fostering an environment of discovery and ethical AI advancements.&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://github.com/facebookresearch/llama/raw/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file, as well as our accompanying &lt;a href=&#34;https://github.com/facebookresearch/llama/raw/main/USE_POLICY.md&#34;&gt;Acceptable Use Policy&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/&#34;&gt;Code Llama Research Paper&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.meta.com/blog/code-llama-large-language-model-coding/&#34;&gt;Code Llama Blog Post&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>langgenius/dify</title>
    <updated>2024-02-04T01:57:45Z</updated>
    <id>tag:github.com,2024-02-04:/langgenius/dify</id>
    <link href="https://github.com/langgenius/dify" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An Open-Source Assistants API and GPTs alternative. Dify.AI is an LLM application development platform. It integrates the concepts of Backend as a Service and LLMOps, covering the core tech stack required for building generative AI-native applications, including a built-in RAG engine.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://dify.ai&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langgenius/dify/main/images/describe.png&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/README.md&#34;&gt;English&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/README_CN.md&#34;&gt;简体中文&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/README_JA.md&#34;&gt;日本語&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/README_ES.md&#34;&gt;Español&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/README_KL.md&#34;&gt;Klingon&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/README_FR.md&#34;&gt;Français&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://dify.ai&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;Static Badge&#34; src=&#34;https://img.shields.io/badge/AI-Dify?logo=AI&amp;amp;logoColor=%20%23f5f5f5&amp;amp;label=Dify&amp;amp;labelColor=%20%23155EEF&amp;amp;color=%23EAECF0&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/FngNHpbcY7&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/1082486657678311454?logo=discord&#34; alt=&#34;chat on Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/intent/follow?screen_name=dify_ai&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/twitter/follow/dify_ai?style=social&amp;amp;logo=X&#34; alt=&#34;follow on Twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/u/langgenius&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;Docker Pulls&#34; src=&#34;https://img.shields.io/docker/pulls/langgenius/dify-web&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://dify.ai/blog/dify-ai-unveils-ai-agent-creating-gpts-and-assistants-with-various-llms&#34; target=&#34;_blank&#34;&gt; Dify.AI Unveils AI Agent: Creating GPTs and Assistants with Various LLMs &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dify&lt;/strong&gt; is an LLM application development platform that has helped built over &lt;strong&gt;100,000&lt;/strong&gt; applications. It integrates BaaS and LLMOps, covering the essential tech stack for building generative AI-native applications, including a built-in RAG engine. Dify allows you to &lt;strong&gt;deploy your own version of Assistants API and GPTs, based on any LLMs.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langgenius/dify/main/images/demo.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Using our Cloud Services&lt;/h2&gt; &#xA;&lt;p&gt;You can try out &lt;a href=&#34;https://dify.ai&#34;&gt;Dify.AI Cloud&lt;/a&gt; now. It provides all the capabilities of the self-deployed version, and includes 200 free requests to OpenAI GPT-3.5.&lt;/p&gt; &#xA;&lt;h2&gt;Dify vs. LangChain vs. Assistants API&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Feature&lt;/th&gt; &#xA;   &lt;th&gt;Dify.AI&lt;/th&gt; &#xA;   &lt;th&gt;Assistants API&lt;/th&gt; &#xA;   &lt;th&gt;LangChain&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Programming Approach&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;API-oriented&lt;/td&gt; &#xA;   &lt;td&gt;API-oriented&lt;/td&gt; &#xA;   &lt;td&gt;Python Code-oriented&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Ecosystem Strategy&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Open Source&lt;/td&gt; &#xA;   &lt;td&gt;Close Source&lt;/td&gt; &#xA;   &lt;td&gt;Open Source&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;RAG Engine&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Supported&lt;/td&gt; &#xA;   &lt;td&gt;Supported&lt;/td&gt; &#xA;   &lt;td&gt;Not Supported&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Prompt IDE&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Included&lt;/td&gt; &#xA;   &lt;td&gt;Included&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Supported LLMs&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Rich Variety&lt;/td&gt; &#xA;   &lt;td&gt;OpenAI-only&lt;/td&gt; &#xA;   &lt;td&gt;Rich Variety&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Local Deployment&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Supported&lt;/td&gt; &#xA;   &lt;td&gt;Not Supported&lt;/td&gt; &#xA;   &lt;td&gt;Not Applicable&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langgenius/dify/main/images/models.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;1. LLM Support&lt;/strong&gt;: Integration with OpenAI&#39;s GPT family of models, or the open-source Llama2 family models. In fact, Dify supports mainstream commercial models and open-source models (locally deployed or based on MaaS).&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;2. Prompt IDE&lt;/strong&gt;: Visual orchestration of applications and services based on LLMs with your team.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3. RAG Engine&lt;/strong&gt;: Includes various RAG capabilities based on full-text indexing or vector database embeddings, allowing direct upload of PDFs, TXTs, and other text formats.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;4. AI Agent&lt;/strong&gt;: Based on Function Calling and ReAct, the Agent inference framework allows users to customize tools, what you see is what you get. Dify provides more than a dozen built-in tool calling capabilities, such as Google Search, DELL·E, Stable Diffusion, WolframAlpha, etc.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;5. Continuous Operations&lt;/strong&gt;: Monitor and analyze application logs and performance, continuously improving Prompts, datasets, or models using production data.&lt;/p&gt; &#xA;&lt;h2&gt;Before You Start&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Star us on GitHub, and be instantly notified for new releases!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/langgenius/dify/assets/100913391/95f37259-7370-4456-a9f0-0bc01ef8642f&#34; alt=&#34;star-us&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dify.ai&#34;&gt;Website&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.dify.ai&#34;&gt;Docs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.dify.ai/getting-started/install-self-hosted&#34;&gt;Deployment Docs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.dify.ai/getting-started/faq&#34;&gt;FAQ&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Install the Community Edition&lt;/h2&gt; &#xA;&lt;h3&gt;System Requirements&lt;/h3&gt; &#xA;&lt;p&gt;Before installing Dify, make sure your machine meets the following minimum system requirements:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;CPU &amp;gt;= 2 Core&lt;/li&gt; &#xA; &lt;li&gt;RAM &amp;gt;= 4GB&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Quick Start&lt;/h3&gt; &#xA;&lt;p&gt;The easiest way to start the Dify server is to run our &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/docker/docker-compose.yaml&#34;&gt;docker-compose.yml&lt;/a&gt; file. Before running the installation command, make sure that &lt;a href=&#34;https://docs.docker.com/get-docker/&#34;&gt;Docker&lt;/a&gt; and &lt;a href=&#34;https://docs.docker.com/compose/install/&#34;&gt;Docker Compose&lt;/a&gt; are installed on your machine:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd docker&#xA;docker compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After running, you can access the Dify dashboard in your browser at &lt;a href=&#34;http://localhost/install&#34;&gt;http://localhost/install&lt;/a&gt; and start the initialization installation process.&lt;/p&gt; &#xA;&lt;h3&gt;Helm Chart&lt;/h3&gt; &#xA;&lt;p&gt;Big thanks to @BorisPolonsky for providing us with a &lt;a href=&#34;https://helm.sh/&#34;&gt;Helm Chart&lt;/a&gt; version, which allows Dify to be deployed on Kubernetes. You can go to &lt;a href=&#34;https://github.com/BorisPolonsky/dify-helm&#34;&gt;https://github.com/BorisPolonsky/dify-helm&lt;/a&gt; for deployment information.&lt;/p&gt; &#xA;&lt;h3&gt;Configuration&lt;/h3&gt; &#xA;&lt;p&gt;If you need to customize the configuration, please refer to the comments in our &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/docker/docker-compose.yaml&#34;&gt;docker-compose.yml&lt;/a&gt; file and manually set the environment configuration. After making the changes, please run &lt;code&gt;docker-compose up -d&lt;/code&gt; again. You can see the full list of environment variables in our &lt;a href=&#34;https://docs.dify.ai/getting-started/install-self-hosted/environments&#34;&gt;docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#langgenius/dify&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=langgenius/dify&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;For those who&#39;d like to contribute code, see our &lt;a href=&#34;https://github.com/langgenius/dify/raw/main/CONTRIBUTING.md&#34;&gt;Contribution Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.&lt;/p&gt; &#xA;&lt;h3&gt;Contributors&lt;/h3&gt; &#xA;&lt;a href=&#34;https://github.com/langgenius/dify/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=langgenius/dify&#34;&gt; &lt;/a&gt; &#xA;&lt;h3&gt;Translations&lt;/h3&gt; &#xA;&lt;p&gt;We are looking for contributors to help with translating Dify to languages other than Mandarin or English. If you are interested in helping, please see the &lt;a href=&#34;https://github.com/langgenius/dify/raw/main/web/i18n/README_EN.md&#34;&gt;i18n README&lt;/a&gt; for more information, and leave us a comment in the &lt;code&gt;global-users&lt;/code&gt; channel of our &lt;a href=&#34;https://discord.gg/AhzKf7dNgk&#34;&gt;Discord Community Server&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Community &amp;amp; Support&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://feedback.dify.ai/&#34;&gt;Canny&lt;/a&gt;. Best for: sharing feedback and checking out our feature roadmap.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/langgenius/dify/issues&#34;&gt;GitHub Issues&lt;/a&gt;. Best for: bugs you encounter using Dify.AI, and feature proposals. See our &lt;a href=&#34;https://github.com/langgenius/dify/raw/main/CONTRIBUTING.md&#34;&gt;Contribution Guide&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;mailto:hello@dify.ai?subject=%5BGitHub%5DQuestions%20About%20Dify&#34;&gt;Email Support&lt;/a&gt;. Best for: questions you have about using Dify.AI.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.gg/FngNHpbcY7&#34;&gt;Discord&lt;/a&gt;. Best for: sharing your applications and hanging out with the community.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/dify_ai&#34;&gt;Twitter&lt;/a&gt;. Best for: sharing your applications and hanging out with the community.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;mailto:business@dify.ai?subject=%5BGitHub%5DBusiness%20License%20Inquiry&#34;&gt;Business Contact&lt;/a&gt;. Best for: business inquiries of licensing Dify.AI for commercial use.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Direct Meetings&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Help us make Dify better. Reach out directly to us&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Point of Contact&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Purpose&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://cal.com/guchenhe/15min&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://i.postimg.cc/fWBqSmjP/Git-Hub-README-Button-3x.png&#34; border=&#34;0&#34; alt=&#34;Git-Hub-README-Button-3x&#34; height=&#34;60&#34; width=&#34;214&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Product design feedback, user experience discussions, feature planning and roadmaps.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://cal.com/pinkbanana&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://i.postimg.cc/LsRTh87D/Git-Hub-README-Button-2x.png&#34; border=&#34;0&#34; alt=&#34;Git-Hub-README-Button-2x&#34; height=&#34;60&#34; width=&#34;225&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Technical support, issues, or feature requests&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Security Disclosure&lt;/h2&gt; &#xA;&lt;p&gt;To protect your privacy, please avoid posting security issues on GitHub. Instead, send your questions to &lt;a href=&#34;mailto:security@dify.ai&#34;&gt;security@dify.ai&lt;/a&gt; and we will provide you with a more detailed answer.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This repository is available under the &lt;a href=&#34;https://raw.githubusercontent.com/langgenius/dify/main/LICENSE&#34;&gt;Dify Open Source License&lt;/a&gt;, which is essentially Apache 2.0 with a few additional restrictions.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>xNul/palworld-host-save-fix</title>
    <updated>2024-02-04T01:57:45Z</updated>
    <id>tag:github.com,2024-02-04:/xNul/palworld-host-save-fix</id>
    <link href="https://github.com/xNul/palworld-host-save-fix" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Fixes the bug which forces a player to create a new character when they already have a save. Useful for migrating maps from co-op to dedicated servers and from one dedicated server to another.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Palworld Host Save Fix&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;h3&gt;&lt;span&gt;⚠&lt;/span&gt; This tool is experimental. Be careful of data loss and &lt;em&gt;always&lt;/em&gt; make a backup. &lt;span&gt;⚠&lt;/span&gt;&lt;/h3&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Fixes the bug which forces a player to create a new character when they already have a save.&lt;/p&gt; &#xA;&lt;p&gt;Palworld save files are different depending on the type of server you are running. Co-op, Windows dedicated server, Linux dedicated server, SteamCMD dedicated server, all of these are different types of Palworld servers and if you try to migrate a save file from one type of server to another, you can run into a player save bug which forces you to create a new character.&lt;/p&gt; &#xA;&lt;p&gt;For example:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Moving a Windows co-op save to a Windows dedicated server will force the host to create a new character and lose their save.&lt;/li&gt; &#xA; &lt;li&gt;Moving a Windows dedicated server save to a Linux dedicated server will force all players to create a new character and lose their save.&lt;/li&gt; &#xA; &lt;li&gt;Moving a Linux dedicated server save to a Windows dedicated server will force all players to create a new character and lose their save.&lt;/li&gt; &#xA; &lt;li&gt;Moving a Windows co-op save to a Linux dedicated server will force all players to create a new character and lose their save.&lt;/li&gt; &#xA; &lt;li&gt;Etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The bug happens because players are identified and correlated to their save via their GUID. These different types of servers generate player GUIDs differently so when a player joins, the server generates a new GUID that doesn&#39;t match the old save&#39;s GUID and because of this, doesn&#39;t realize the player already has a save.&lt;/p&gt; &#xA;&lt;p&gt;To fix this bug, we&#39;ve made a script that takes the GUID of the player on the new server and applies it to the player save from the old server so that the new server will use the player save from the old server.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Dependencies:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python &amp;gt;=3.10&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/trumank/uesave-rs&#34;&gt;uesave-rs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Using the GUI:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Open Command Prompt in the folder&lt;/li&gt; &#xA; &lt;li&gt;Run command &lt;code&gt;python gui.py&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Select the location of uesave.exe and your save folder&lt;/li&gt; &#xA; &lt;li&gt;Select your old GUID and your new GUID from the dropdowns&lt;/li&gt; &#xA; &lt;li&gt;Enable the guild fix if required&lt;/li&gt; &#xA; &lt;li&gt;Hit the button to run the command&lt;/li&gt; &#xA; &lt;li&gt;Read the warning in Command Prompt&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python fix-host-save.py &amp;lt;uesave.exe&amp;gt; &amp;lt;save_path&amp;gt; &amp;lt;new_guid&amp;gt; &amp;lt;old_guid&amp;gt; &amp;lt;guild_fix&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;&amp;lt;uesave.exe&amp;gt;&lt;/code&gt; - Path to your uesave.exe&lt;br&gt; &lt;code&gt;&amp;lt;save_path&amp;gt;&lt;/code&gt; - Path to your save folder&lt;br&gt; &lt;code&gt;&amp;lt;new_guid&amp;gt;&lt;/code&gt; - GUID of the player on the new server&lt;br&gt; &lt;code&gt;&amp;lt;old_guid&amp;gt;&lt;/code&gt; - GUID of the player from the old server&lt;br&gt; &lt;code&gt;&amp;lt;guild_fix&amp;gt;&lt;/code&gt; - True or False. Apply the fix for the &lt;a href=&#34;https://raw.githubusercontent.com/xNul/palworld-host-save-fix/main/#guild-bug&#34;&gt;[Guild bug]&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python fix-host-save.py &#34;C:\Users\John\.cargo\bin\uesave.exe&#34; &#34;C:\Users\John\Desktop\my_temporary_folder\2E85FD38BAA792EB1D4C09386F3A3CDA&#34; 6E80B1A6000000000000000000000000 00000000000000000000000000000001 False&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;How to migrate a co-op save to a Windows dedicated server&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;Only my co-op host isn&#39;t able to use their character on the dedicated server.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Prerequisites:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install the dependencies &lt;a href=&#34;https://raw.githubusercontent.com/xNul/palworld-host-save-fix/main/#usage&#34;&gt;above&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The dedicated server is installed, running, and you&#39;re able to join it.&lt;/li&gt; &#xA; &lt;li&gt;Follow the workaround &lt;a href=&#34;https://raw.githubusercontent.com/xNul/palworld-host-save-fix/main/#guild-bug&#34;&gt;below&lt;/a&gt; for the [Guild bug] in co-op before moving the save.&lt;/li&gt; &#xA; &lt;li&gt;If you have a Viewing Cage, follow the workaround &lt;a href=&#34;https://raw.githubusercontent.com/xNul/palworld-host-save-fix/main/#viewing-cage-bug&#34;&gt;below&lt;/a&gt; for the [Viewing Cage bug] in co-op before moving the save.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Copy your desired save&#39;s folder from &lt;code&gt;C:\Users\&amp;lt;username&amp;gt;\AppData\Local\Pal\Saved\SaveGames\&amp;lt;random_numbers&amp;gt;&lt;/code&gt; to your dedicated server at &lt;code&gt;PalServer\Pal\Saved\SaveGames\0&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;In the &lt;code&gt;PalServer\Pal\Saved\Config\WindowsServer\GameUserSettings.ini&lt;/code&gt; file, change the &lt;code&gt;DedicatedServerName&lt;/code&gt; to match your save folder&#39;s name. For example, if your save folder&#39;s name is &lt;code&gt;2E85FD38BAA792EB1D4C09386F3A3CDA&lt;/code&gt;, the &lt;code&gt;DedicatedServerName&lt;/code&gt; changes to &lt;code&gt;DedicatedServerName=2E85FD38BAA792EB1D4C09386F3A3CDA&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Delete &lt;code&gt;PalServer\Pal\Saved\SaveGames\0\&amp;lt;your_save_here&amp;gt;\WorldOption.sav&lt;/code&gt; to allow modification of &lt;code&gt;PalWorldSettings.ini&lt;/code&gt;. Players will have to choose their respawn point again, but nothing else is affected as far as I can tell.&lt;/li&gt; &#xA; &lt;li&gt;Confirm you can connect to your save on the dedicated server and that the world is the one you want. You can connect to the dedicated server and check the world with a character that does not belong to the co-op host.&lt;/li&gt; &#xA; &lt;li&gt;Afterwards, the co-op host must create a new character on the dedicated server. A new &lt;code&gt;.sav&lt;/code&gt; file should appear in &lt;code&gt;PalServer\Pal\Saved\SaveGames\0\&amp;lt;your_save_here&amp;gt;\Players&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The name of that new &lt;code&gt;.sav&lt;/code&gt; file is the co-op host&#39;s new GUID. We will need the co-op host&#39;s new GUID for the script to work.&lt;/li&gt; &#xA; &lt;li&gt;Shut the server down and then copy the entire save folder in the dedicated server at &lt;code&gt;PalServer\Pal\Saved\SaveGames\0\&amp;lt;your_save_here&amp;gt;&lt;/code&gt; (it must be the save folder with the co-op host&#39;s new character!) into a temporary folder and remember the path for the temporary folder because it&#39;s needed to run the script.&lt;/li&gt; &#xA; &lt;li&gt;If you have not already done so, install &lt;a href=&#34;https://github.com/trumank/uesave-rs&#34;&gt;uesave-rs&lt;/a&gt; and get the file path to its install location. If the path does not have &lt;code&gt;uesave.exe&lt;/code&gt; at the end, it&#39;s wrong.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Make a backup of your save folder!&lt;/strong&gt; This is an experimental script and has known bugs so always keep a backup copy of your save folder.&lt;/li&gt; &#xA; &lt;li&gt;Run the script using the command in the &lt;a href=&#34;https://raw.githubusercontent.com/xNul/palworld-host-save-fix/main/#usage&#34;&gt;Usage section&lt;/a&gt; with the information you&#39;ve gathered, using &lt;code&gt;00000000000000000000000000000001&lt;/code&gt; as the co-op host&#39;s old GUID, and make sure to set &lt;code&gt;&amp;lt;guild_fix&amp;gt;&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Copy the save folder from the temporary folder back to the dedicated server. Move the save folder you had in the dedicated server somewhere else or rename it to something different.&lt;/li&gt; &#xA; &lt;li&gt;Start the server back up and have the co-op host join the server with their fixed character.&lt;/li&gt; &#xA; &lt;li&gt;If, after 5 minutes of play, your Pals won&#39;t attack for you or do work in the base, follow the &lt;a href=&#34;https://raw.githubusercontent.com/xNul/palworld-host-save-fix/main/#pal-bug&#34;&gt;[Pal bug] workaround&lt;/a&gt; to fix them.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;How to migrate a Windows/Linux dedicated server save to a Linux/Windows dedicated server&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;No player, co-op host or otherwise, is able to use their character on the dedicated server.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Note: This method relies on the [Guild bug] fix even though the fix itself has bugs because with this migration process, every player loses access to their character and they all have to be fixed so there is no &#39;good&#39; character who can hold the guild for other players as in the co-op to dedicated server migration process &lt;a href=&#34;https://raw.githubusercontent.com/xNul/palworld-host-save-fix/main/#how-to-migrate-a-co-op-save-to-a-windows-dedicated-server&#34;&gt;above&lt;/a&gt;. Progress on the [Guild bug] fix is ongoing and it will hopefully be completely fixed soon.&lt;/p&gt; &#xA;&lt;p&gt;Prerequisites:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install the dependencies &lt;a href=&#34;https://raw.githubusercontent.com/xNul/palworld-host-save-fix/main/#usage&#34;&gt;above&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The new dedicated server is installed, running, and you&#39;re able to join it.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Copy the save folder from your old dedicated server to your new dedicated server.&lt;/li&gt; &#xA; &lt;li&gt;In the &lt;code&gt;PalServer\Pal\Saved\Config\WindowsorLinuxServer\GameUserSettings.ini&lt;/code&gt; file of the new server, change the &lt;code&gt;DedicatedServerName&lt;/code&gt; to match your save folder&#39;s name. For example, if your save folder&#39;s name is &lt;code&gt;2E85FD38BAA792EB1D4C09386F3A3CDA&lt;/code&gt;, the &lt;code&gt;DedicatedServerName&lt;/code&gt; changes to &lt;code&gt;DedicatedServerName=2E85FD38BAA792EB1D4C09386F3A3CDA&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Start the new server and have every player create a new character. When a player creates a new character, a new &lt;code&gt;.sav&lt;/code&gt; file will appear in &lt;code&gt;PalServer\Pal\Saved\SaveGames\0\&amp;lt;your_save_here&amp;gt;\Players&lt;/code&gt;. The name of that new &lt;code&gt;.sav&lt;/code&gt; file is the player&#39;s new GUID. Make sure to keep track of all old GUIDs, new GUIDs, and which player they belong to.&lt;/li&gt; &#xA; &lt;li&gt;Shut the server down and then copy the entire save folder from the new server at &lt;code&gt;PalServer\Pal\Saved\SaveGames\0\&amp;lt;your_save_here&amp;gt;&lt;/code&gt; (it must be the save folder with all the new characters!) into a temporary folder and remember the path for the temporary folder because it&#39;s needed to run the script.&lt;/li&gt; &#xA; &lt;li&gt;If you have not already done so, install &lt;a href=&#34;https://github.com/trumank/uesave-rs&#34;&gt;uesave-rs&lt;/a&gt; and get the file path to its install location. If the path does not have &lt;code&gt;uesave.exe&lt;/code&gt; at the end, it&#39;s wrong.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Make a backup of your save folder!&lt;/strong&gt; This is an experimental script and has known bugs so always keep a backup copy of your save folder.&lt;/li&gt; &#xA; &lt;li&gt;For each player&#39;s corresponding new GUID and old GUID pair, run the script using the command in the &lt;a href=&#34;https://raw.githubusercontent.com/xNul/palworld-host-save-fix/main/#usage&#34;&gt;Usage section&lt;/a&gt; and make sure to set &lt;code&gt;&amp;lt;guild_fix&amp;gt;&lt;/code&gt; to &lt;code&gt;True&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Copy the save folder from the temporary folder back to the dedicated server. Move the save folder you had in the dedicated server somewhere else or rename it to something different.&lt;/li&gt; &#xA; &lt;li&gt;Start the server back up and have each player join the server with their fixed character.&lt;/li&gt; &#xA; &lt;li&gt;If, after 5 minutes of play, a player&#39;s Pals won&#39;t attack for them or do work in their base, have them follow the &lt;a href=&#34;https://raw.githubusercontent.com/xNul/palworld-host-save-fix/main/#pal-bug&#34;&gt;[Pal bug] workaround&lt;/a&gt; to fix them.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;How to migrate a Windows dedicated server save to co-op&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/xNul/palworld-host-save-fix/issues/12#issuecomment-1904052304&#34;&gt;Apparently this is possible&lt;/a&gt; but I haven&#39;t tried it yet. Instructions should be very similar to &#34;How to migrate a co-op save to a Windows dedicated server&#34; but where you use the &lt;code&gt;00000000000000000000000000000001&lt;/code&gt; GUID as the new GUID and the player&#39;s current GUID on the dedicated server as the old GUID.&lt;/p&gt; &#xA;&lt;p&gt;If someone wants to make sure this kind of migration works and then create the instructions to do it, I&#39;d accept a PR for them.&lt;/p&gt; &#xA;&lt;h2&gt;Known bugs&lt;/h2&gt; &#xA;&lt;h3&gt;[Guild bug]&lt;/h3&gt; &#xA;&lt;p&gt;Details: Guild membership doesn&#39;t work properly after fixing a character. This is likely happening because there&#39;s some guild configuration being missed in the character migration from the old save to the new save.&lt;/p&gt; &#xA;&lt;p&gt;Workaround: [Co-op Only] In co-op, before moving the save, transfer ownership from the co-op host&#39;s character to another character and have the co-op host&#39;s character leave the guild. Fixes the issue entirely. Doesn&#39;t work when all players lose their save data because there is no working player to hold the guild.&lt;/p&gt; &#xA;&lt;h3&gt;[Pal bug]&lt;/h3&gt; &#xA;&lt;p&gt;Details: Pals owned by the player won&#39;t do anything at the base. This is likely caused by the Pals not being registered with the correct guild.&lt;/p&gt; &#xA;&lt;p&gt;Workaround: On the new server, after the save has been fixed, have each player&#39;s character go into their base, drop on the ground and pick up every single Pal they own, including the base workers. This can be done using the &#34;Drop&#34; button in the Party menu. This will re-register the Pals with the correct guild and fix the issue entirely.&lt;/p&gt; &#xA;&lt;h3&gt;[Viewing Cage bug]&lt;/h3&gt; &#xA;&lt;p&gt;Details: The Viewing Cage &lt;a href=&#34;https://tech.palworldgame.com/dedicated-server-guide#qa&#34;&gt;isn&#39;t officially supported&lt;/a&gt; on dedicated servers so if you have built one in co-op, it needs to be removed from your co-op save before migrating it to your dedicated server.&lt;/p&gt; &#xA;&lt;p&gt;Workaround: [Co-op Only] If you have built a Viewing Cage, it needs to be removed from your co-op save before migrating it to your dedicated server.&lt;/p&gt; &#xA;&lt;h3&gt;[Left Click bug]&lt;/h3&gt; &#xA;&lt;p&gt;Details: After applying the fix, some players experience a bug where you can&#39;t hold your left mouse button to attack. It seems like this only happens if you didn&#39;t do the &lt;a href=&#34;https://raw.githubusercontent.com/xNul/palworld-host-save-fix/main/#guild-bug&#34;&gt;[Guild bug] workaround&lt;/a&gt; but I&#39;m not sure.&lt;/p&gt; &#xA;&lt;p&gt;Workaround: If you leave the guild and rejoin, it goes away. Thanks &lt;a href=&#34;https://www.reddit.com/r/Palworld/comments/19axeqs/autoswing_not_working/kiq85zr/&#34;&gt;/u/skalibran&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h3&gt;Credit to &lt;a href=&#34;https://gist.github.com/cheahjs/300239464dd84fe6902893b6b9250fd0&#34;&gt;cheahjs&lt;/a&gt; for his very useful script helping me to make this fix!&lt;/h3&gt; &#xA;&lt;h3&gt;Appreciate any help testing and resolving bugs.&lt;/h3&gt;</summary>
  </entry>
</feed>