<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-24T01:57:46Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>chatanywhere/GPT_API_free</title>
    <updated>2023-12-24T01:57:46Z</updated>
    <id>tag:github.com,2023-12-24:/chatanywhere/GPT_API_free</id>
    <link href="https://github.com/chatanywhere/GPT_API_free" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Free ChatGPT API Keyï¼Œå…è´¹ChatGPT APIï¼Œæ”¯æŒGPT4 APIï¼ˆå…è´¹ï¼‰ï¼ŒChatGPTå›½å†…å¯ç”¨å…è´¹è½¬å‘APIï¼Œç›´è¿æ— éœ€ä»£ç†ã€‚å¯ä»¥æ­é…ChatBoxç­‰è½¯ä»¶/æ’ä»¶ä½¿ç”¨ï¼Œæå¤§é™ä½æ¥å£ä½¿ç”¨æˆæœ¬ã€‚å›½å†…å³å¯æ— é™åˆ¶ç•…å¿«èŠå¤©ã€‚&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/chatanywhere/GPT_API_free/main/images/logo.png&#34; alt=&#34;icon&#34; width=&#34;50px&#34;&gt; &#xA; &lt;h1 align=&#34;center&#34;&gt;GPT-API-free&lt;/h1&gt; &#xA; &lt;p&gt;æ”¯æŒ &lt;strong&gt;GPT-4&lt;/strong&gt; / GPT-3.5-Turbo / GPT-3.5-Turbo-16K / embeddings / DALLÂ·E / whisper / text-davinci&lt;/p&gt; &#xA; &lt;p&gt;å›½å†…åŠ¨æ€åŠ é€Ÿ ç›´è¿æ— éœ€ä»£ç†&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chatanywhere/GPT_API_free/main/#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8&#34;&gt;å¿«é€Ÿå¼€å§‹&lt;/a&gt; / &lt;a href=&#34;https://chatanywhere.apifox.cn/&#34;&gt;APIæ–‡æ¡£&lt;/a&gt; / &lt;a href=&#34;https://api.chatanywhere.org/v1/oauth/free/github/render&#34;&gt;ç”³è¯·å†…æµ‹å…è´¹Key&lt;/a&gt; / &lt;a href=&#34;https://peiqi.shop/&#34;&gt;æ”¯æŒä»˜è´¹Key&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://qm.qq.com/cgi-bin/qm/qr?k=OFhxu4Z3qI-c-76QJfC2LLXfKGr0g-57&amp;amp;jump_from=webapi&amp;amp;authKey=Kzuf7g4fsE0ZAM7RN+7XvivEANxgDVqDbUs3WI6cB98pt4pFzq/3L8NMiMOy+mo1&#34;&gt;QQç¾¤: 780366686&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;éšç§å£°æ˜&lt;/h2&gt; &#xA;&lt;p&gt;è¯¥é¡¹ç›®é«˜åº¦é‡è§†éšç§ï¼Œè‡´åŠ›äºä¿æŠ¤å…¶ç”¨æˆ·çš„éšç§ã€‚è¯¥é¡¹ç›®ä¸ä¼šä»¥ä»»ä½•æ–¹å¼æ”¶é›†ã€è®°å½•æˆ–å­˜å‚¨ç”¨æˆ·è¾“å…¥çš„ä»»ä½•æ–‡æœ¬æˆ–ç”± OpenAI æœåŠ¡å™¨è¿”å›çš„ä»»ä½•æ–‡æœ¬ã€‚è¯¥é¡¹ç›®ä¸ä¼šå‘ OpenAI æˆ–ä»»ä½•ç¬¬ä¸‰æ–¹æä¾›æœ‰å…³ API è°ƒç”¨è€…çš„èº«ä»½çš„ä»»ä½•ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä½†ä¸é™äº IP åœ°å€å’Œç”¨æˆ·ä»£ç†å­—ç¬¦ä¸²ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ä½†OpenAIå®˜æ–¹ä¼šæ ¹æ®å…¶&lt;a href=&#34;https://platform.openai.com/docs/data-usage-policies&#34;&gt;æ•°æ®ä½¿ç”¨æ”¿ç­–&lt;/a&gt;ä¿ç•™ 30 å¤©çš„æ•°æ®ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;æ›´æ–°æ—¥å¿—&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023å¹´6æœˆ14æ—¥&lt;/strong&gt; é€‚é…GPT-3.5-Turbo-16Kï¼Œå…è´¹keyä¹Ÿæ”¯æŒ16kæ¨¡å‹ï¼›ä»˜è´¹keyè·Ÿéšå®˜æ–¹ä»·æ ¼é™ä½æ”¶è´¹ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023å¹´6æœˆ15æ—¥&lt;/strong&gt; é€‚é…0613ç‰ˆæœ¬æ–°å¢çš„functionsã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023å¹´6æœˆ18æ—¥&lt;/strong&gt; æ–°å¢å¯¹è¯­éŸ³è½¬æ–‡å­—æ¨¡å‹Whisperæ”¯æŒã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023å¹´8æœˆ4æ—¥&lt;/strong&gt; å…è´¹Keyä¸å†æ”¯æŒgpt-3.5-turbo-16kæ¨¡å‹è°ƒç”¨ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023å¹´9æœˆ7æ—¥&lt;/strong&gt; chatapi.chatanywhere.cné•œåƒç«™ä¸å†å‘å›½å†…ç”¨æˆ·æä¾›æœåŠ¡ï¼Œä¸å½±å“APIçš„æ­£å¸¸ä½¿ç”¨ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023å¹´11æœˆ8æ—¥&lt;/strong&gt; æ”¯æŒ1106ç‰ˆæœ¬å„æ¨¡å‹ï¼Œæ”¯æŒTTSæ–‡æœ¬è½¬è¯­éŸ³æ¨¡å‹ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023å¹´11æœˆ19æ—¥&lt;/strong&gt; æ”¯æŒgpt-4-1106-previewæ¨¡å‹ï¼Œä»·æ ¼ä»…åŸå…ˆgpt-4æ¨¡å‹çš„ä¸‰åˆ†ä¹‹ä¸€åˆ°äºŒåˆ†ä¹‹ä¸€ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023å¹´11æœˆ29æ—¥&lt;/strong&gt; å¼€æ”¾å…è´¹APIçš„gpt-4æƒé™ï¼Œæ¯å¤©å¯ä»¥å…è´¹ä½¿ç”¨10æ¬¡ã€‚ï¼ˆä¸ä¿è¯èƒ½é•¿æœŸæä¾›ï¼‰&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ç‰¹ç‚¹&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;æ”¯æŒModels, Embedding, text-davinci, GPT-3.5-Turbo, GPT-3.5-Turbo-16K(å…è´¹ç‰ˆä¸æ”¯æŒ), &lt;em&gt;&lt;strong&gt;GPT-4&lt;/strong&gt;&lt;/em&gt;, &lt;em&gt;&lt;strong&gt;DALLE&lt;/strong&gt;&lt;/em&gt;(å…è´¹ç‰ˆä¸æ”¯æŒ), &lt;em&gt;&lt;strong&gt;Whisper&lt;/strong&gt;&lt;/em&gt;(å…è´¹ç‰ˆä¸æ”¯æŒ)ã€‚ï¼ˆå…è´¹ç‰ˆå°±å¯ä»¥æ”¯æŒAutoGPT, gpt_academic, langchainç­‰ï¼‰&lt;/li&gt; &#xA; &lt;li&gt;å…è´¹ç‰ˆæ”¯æŒGPT-4ï¼Œä¸€å¤©10æ¬¡ã€‚ï¼ˆå…è´¹ç‰ˆgpt-4ç›¸å¯¹æ…¢ä¸€äº›ï¼Œä»˜è´¹ç‰ˆæ›´ç¨³å®šï¼‰&lt;/li&gt; &#xA; &lt;li&gt;ä¸å®˜æ–¹å®Œå…¨ä¸€è‡´çš„æ¥å£æ ‡å‡†ï¼Œå…¼å®¹å„ç§è½¯ä»¶/æ’ä»¶ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æ”¯æŒæµå¼å“åº”ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å›½å†…çº¿è·¯ä½¿ç”¨åŠ¨æ€åŠ é€Ÿï¼Œä½“éªŒè¿œä¼˜äºä½¿ç”¨ä»£ç†è¿æ¥å®˜æ–¹ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æ— éœ€ç§‘å­¦ä¸Šç½‘ï¼Œå›½å†…ç¯å¢ƒç›´æ¥å¯ç”¨ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ä¸ªäººå®Œå…¨å…è´¹ä½¿ç”¨ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;ğŸš©æ³¨æ„äº‹é¡¹&lt;/h2&gt; &#xA;&lt;p&gt;â—ï¸&lt;em&gt;è¿‘æœŸOpenAIé¢‘ç¹å‡ºé”™ï¼Œå¦‚æœé‡åˆ°æ— å›å¤ï¼ŒæŠ¥é”™ç­‰æƒ…å†µï¼Œå¯ä»¥æŸ¥çœ‹ status.openai.com ï¼Œå¾ˆå¤§å¯èƒ½æ˜¯OpenAIå®˜æ–¹æœåŠ¡é—®é¢˜ã€‚&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;â—ï¸&lt;strong&gt;å…è´¹API Keyä»…å¯ç”¨äºä¸ªäººéå•†ä¸šç”¨é€”ï¼Œæ•™è‚²ï¼Œéè¥åˆ©æ€§ç§‘ç ”å·¥ä½œä¸­ã€‚ä¸¥ç¦å•†ç”¨ï¼Œä¸¥ç¦å¤§è§„æ¨¡è®­ç»ƒå•†ç”¨æ¨¡å‹ï¼è®­ç»ƒç§‘ç ”ç”¨æ¨¡å‹è¯·æå‰åŠ ç¾¤è”ç³»æˆ‘ä»¬ã€‚&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;â—ï¸æˆ‘ä»¬å°†ä¸å®šæœŸå¯¹è¢«æ»¥ç”¨çš„Keyè¿›è¡Œå°ç¦ï¼Œå¦‚å‘ç°è‡ªå·±çš„keyè¢«è¯¯å°è¯·é€šè¿‡QQç¾¤è”ç³»æˆ‘ä»¬ã€‚&lt;/p&gt; &#xA;&lt;p&gt;â—ï¸æˆ‘ä»¬çš„ç³»ç»Ÿä»…ä¾›å†…éƒ¨è¯„ä¼°æµ‹è¯•ä½¿ç”¨ï¼Œå•†ç”¨æˆ–é¢å‘å¤§ä¼—ä½¿ç”¨è¯·è‡ªè¡Œæ‰¿æ‹…é£é™©ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ä¸ºäº†è¯¥é¡¹ç›®é•¿ä¹…å‘å±•ï¼Œå…è´¹API Keyé™åˆ¶&lt;strong&gt;60è¯·æ±‚/å°æ—¶/IP&amp;amp;Key&lt;/strong&gt;è°ƒç”¨é¢‘ç‡ï¼Œä¹Ÿå°±æ˜¯è¯´ä½ å¦‚æœåœ¨ä¸€ä¸ªIPä¸‹ä½¿ç”¨å¤šä¸ªKeyï¼Œæ‰€æœ‰Keyçš„æ¯å°æ—¶è¯·æ±‚æ•°æ€»å’Œä¸èƒ½è¶…è¿‡60ï¼›åŒç†ï¼Œä½ å¦‚æœå°†ä¸€ä¸ªKeyç”¨äºå¤šä¸ªIPï¼Œè¿™ä¸ªKeyçš„æ¯å°æ—¶è¯·æ±‚æ•°ä¹Ÿä¸èƒ½è¶…è¿‡60ã€‚(&lt;strong&gt;ä»˜è´¹ç‰ˆAPIæ²¡æœ‰è¿™ä¸ªé™åˆ¶&lt;/strong&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;å…è´¹ä½¿ç”¨&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸš€&lt;a href=&#34;https://api.chatanywhere.org/v1/oauth/free/github/render&#34;&gt;ç”³è¯·é¢†å–å†…æµ‹å…è´¹API Key&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;å…è´¹ç‰ˆæ”¯æŒgpt-3.5-turbo, embedding, gpt-4ã€‚å…¶ä¸­gpt-4ç”±äºä»·æ ¼è¿‡é«˜ï¼Œæ¯24å°æ—¶é™åˆ¶10æ¬¡è°ƒç”¨ï¼Œä¸”ä¸æ”¯æŒæµå¼ä¼ è¾“ã€‚éœ€è¦æ›´ç¨³å®šå¿«é€Ÿçš„gpt-4è¯·ä½¿ç”¨ä»˜è´¹ç‰ˆã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;è½¬å‘Host1: &lt;code&gt;https://api.chatanywhere.tech&lt;/code&gt; (å›½å†…ä¸­è½¬ï¼Œå»¶æ—¶æ›´ä½ï¼Œhost1å’Œhost2äºŒé€‰ä¸€)&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;è½¬å‘Host2: &lt;code&gt;https://api.chatanywhere.com.cn&lt;/code&gt; (å›½å†…ä¸­è½¬ï¼Œå»¶æ—¶æ›´ä½ï¼Œhost1å’Œhost2äºŒé€‰ä¸€)&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;è½¬å‘Host3: &lt;code&gt;https://api.chatanywhere.cn&lt;/code&gt; (å›½å¤–ä½¿ç”¨,å›½å†…éœ€è¦å…¨å±€ä»£ç†)&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;æˆ‘ä»¬ä¼šå®šæœŸæ ¹æ®ä½¿ç”¨é‡è¿›è¡Œç›¸åº”çš„æ‰©å®¹ï¼Œåªè¦ä¸è¢«å®˜æ–¹åˆ¶è£æˆ‘ä»¬ä¼šä¸€ç›´æä¾›å…è´¹APIï¼Œå¦‚æœè¯¥é¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¿˜è¯·ä¸ºæˆ‘ä»¬ç‚¹ä¸€ä¸ª&lt;em&gt;&lt;strong&gt;Star&lt;/strong&gt;&lt;/em&gt;ã€‚å¦‚æœé‡åˆ°é—®é¢˜å¯ä»¥åœ¨&lt;a href=&#34;https://github.com/chatanywhere/GPT_API_free/issues&#34;&gt;Issues&lt;/a&gt;ä¸­åé¦ˆï¼Œæœ‰ç©ºä¼šè§£ç­”ã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¯¥API Keyç”¨äºè½¬å‘APIï¼Œéœ€è¦å°†Hostæ”¹ä¸º&lt;code&gt;api.chatanywhere.tech&lt;/code&gt;(å›½å†…é¦–é€‰)æˆ–è€…&lt;code&gt;api.chatanywhere.cn&lt;/code&gt;(å›½å¤–ä½¿ç”¨ï¼Œå›½å†…éœ€è¦å…¨å±€ä»£ç†)ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ä»˜è´¹ç‰ˆAPI&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;çº¯å…¬ç›Šæä¾›å…è´¹Keyæ˜¾ç„¶ä¸æ˜¯èƒ½æŒä¹…è¿è¥ä¸‹å»çš„æ–¹æ¡ˆï¼Œæ‰€ä»¥æˆ‘ä»¬å¼•å…¥ä»˜è´¹API Keyç»´æŒé¡¹ç›®çš„æ—¥å¸¸å¼€é”€ï¼Œä»¥ä¿ƒè¿›é¡¹ç›®çš„è‰¯æ€§å¾ªç¯ï¼Œè¿˜æœ›å¤§å®¶ç†è§£ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://peiqi.shop/&#34;&gt;è´­ä¹°ä½ä»·ä»˜è´¹Key&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;æ”¯æŒ&lt;strong&gt;æ›´ç¨³å®šæ›´å¿«é€Ÿçš„GPT4 API&lt;/strong&gt;ï¼ŒGPT4ä½“éªŒæ›´å¥½ï¼Œæ— é™ä½¿ç”¨ï¼Œä»·æ ¼ä»…å®˜æ–¹ä»·æ ¼85æŠ˜ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æ€§ä»·æ¯”é«˜ï¼Œé™¤äº†GPT4çš„å…¶ä»–æ¨¡å‹ä»·æ ¼ç›¸å½“äºå®˜ç½‘ä»·æ ¼ä¸ƒåˆ†ä¹‹ä¸€ã€‚&lt;/li&gt; &#xA; &lt;li&gt;åŒå®˜ç½‘è®¡è´¹ç­–ç•¥ï¼Œæµå¼é—®ç­”ä½¿ç”¨tiktokenåº“å‡†ç¡®è®¡ç®—Tokensï¼Œéæµå¼é—®ç­”ç›´æ¥ä½¿ç”¨å®˜æ–¹è¿”å›Tokensç”¨é‡è®¡è´¹ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ä½™é¢ä¸ä¼šè¿‡æœŸï¼Œæ°¸ä¹…æœ‰æ•ˆã€‚æ ¹æ®ç”¨æˆ·åé¦ˆ30å—é’±ä¸ªäººä¸­åº¦ä½¿ç”¨GPT3.5ä¼°è®¡èƒ½ç”¨ä¸€å¹´ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æ‰€æœ‰çš„æ¥å£éƒ½ä¿è¯è½¬å‘è‡ªOpenAIå®˜æ–¹æ¥å£ï¼Œépeoã€plusç­‰ä¸ç¨³å®šæ–¹æ¡ˆï¼Œæ— æ°´åˆ†ï¼Œä¸æºå‡ï¼Œä¿è¯ç¨³å®šæ€§ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;å¦‚ä½•ä½¿ç”¨&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ç”±äºé¢‘ç¹çš„æ¶æ„è¯·æ±‚ï¼Œæˆ‘ä»¬ä¸å†ç›´æ¥æä¾›å…¬å…±çš„å…è´¹Keyï¼Œç°åœ¨éœ€è¦ä½ ä½¿ç”¨ä½ çš„Githubè´¦å·ç»‘å®šæ¥é¢†å–ä½ è‡ªå·±çš„å…è´¹Keyã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸš€&lt;a href=&#34;https://api.chatanywhere.org/v1/oauth/free/github/render&#34;&gt;ç”³è¯·é¢†å–å†…æµ‹å…è´¹API Key&lt;/a&gt; æˆ– &lt;a href=&#34;https://peiqi.shop/&#34;&gt;è´­ä¹°å†…æµ‹ä»˜è´¹API Key&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;è½¬å‘Host1: &lt;code&gt;https://api.chatanywhere.tech&lt;/code&gt; (å›½å†…ä¸­è½¬ï¼Œå»¶æ—¶æ›´ä½ï¼Œhost1å’Œhost2äºŒé€‰ä¸€)&lt;/li&gt; &#xA; &lt;li&gt;è½¬å‘Host2: &lt;code&gt;https://api.chatanywhere.com.cn&lt;/code&gt; (å›½å†…ä¸­è½¬ï¼Œå»¶æ—¶æ›´ä½ï¼Œhost1å’Œhost2äºŒé€‰ä¸€)&lt;/li&gt; &#xA; &lt;li&gt;è½¬å‘Host3: &lt;code&gt;https://api.chatanywhere.cn&lt;/code&gt; (å›½å¤–ä½¿ç”¨,å›½å†…éœ€è¦å…¨å±€ä»£ç†)&lt;/li&gt; &#xA; &lt;li&gt;ä½™é¢å’Œä½¿ç”¨è®°å½•æŸ¥è¯¢ï¼ˆé€šçŸ¥å…¬å‘Šä¹Ÿä¼šå‘åœ¨è¿™é‡Œï¼‰: &lt;a href=&#34;https://api.chatanywhere.tech/&#34;&gt;ä½™é¢æŸ¥è¯¢åŠå…¬å‘Š&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;è½¬å‘APIæ— æ³•ç›´æ¥å‘å®˜æ–¹æ¥å£api.openai.comå‘èµ·è¯·æ±‚ï¼Œéœ€è¦å°†è¯·æ±‚åœ°å€æ”¹ä¸ºapi.chatanywhere.techæ‰å¯ä»¥ä½¿ç”¨ï¼Œå¤§éƒ¨åˆ†æ’ä»¶å’Œè½¯ä»¶éƒ½å¯ä»¥ä¿®æ”¹ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;å¸¸è§è½¯ä»¶/æ’ä»¶ä½¿ç”¨æ–¹æ³•&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;strong&gt;python openaiå®˜æ–¹åº“ï¼ˆä½¿ç”¨AutoGPTï¼Œlangchainç­‰ï¼‰&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;ç¤ºä¾‹ä»£ç è¯·å‚è€ƒ&lt;a href=&#34;https://raw.githubusercontent.com/chatanywhere/GPT_API_free/main/demo.py&#34;&gt;demo.py&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;æ–¹æ³•ä¸€&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import openai&#xA;openai.api_base = &#34;https://api.chatanywhere.tech/v1&#34;&#xA;# openai.api_base = &#34;https://api.chatanywhere.cn/v1&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;æ–¹æ³•äºŒï¼ˆæ–¹æ³•ä¸€ä¸èµ·ä½œç”¨ç”¨è¿™ä¸ªï¼‰&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;ä¿®æ”¹ç¯å¢ƒå˜é‡OPENAI_API_BASEï¼Œå„ä¸ªç³»ç»Ÿæ€ä¹ˆæ”¹ç¯å¢ƒå˜é‡è¯·è‡ªè¡Œæœç´¢ï¼Œä¿®æ”¹ç¯å¢ƒå˜é‡åä¸èµ·ä½œç”¨è¯·é‡å¯ç³»ç»Ÿã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;OPENAI_API_BASE=https://api.chatanywhere.tech/v1&#xA;æˆ– OPENAI_API_BASE=https://api.chatanywhere.cn/v1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;&lt;strong&gt;å¼€æºgpt_academic&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;æ‰¾åˆ°&lt;code&gt;config.py&lt;/code&gt;æ–‡ä»¶ä¸­çš„&lt;code&gt;API_URL_REDIRECT&lt;/code&gt;é…ç½®å¹¶ä¿®æ”¹ä¸ºä»¥ä¸‹å†…å®¹ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;API_URL_REDIRECT = {&#34;https://api.openai.com/v1/chat/completions&#34;: &#34;https://api.chatanywhere.tech/v1/chat/completions&#34;}&#xA;# API_URL_REDIRECT = {&#34;https://api.openai.com/v1/chat/completions&#34;: &#34;https://api.chatanywhere.cn/v1/chat/completions&#34;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;&lt;strong&gt;BotGem(AMA)&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;ChatGPTæ¡Œé¢åº”ç”¨ï¼Œæ”¯æŒå…¨å¹³å°ï¼Œ&lt;em&gt;&lt;strong&gt;æ”¯æŒgpt-4-vision&lt;/strong&gt;&lt;/em&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ä¸‹è½½é“¾æ¥ï¼š&lt;a href=&#34;https://bytemyth.com/ama&#34;&gt;https://bytemyth.com/ama&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;ä½¿ç”¨æ–¹æ³•ï¼šä¸‹è½½å®‰è£…ååœ¨è®¾ç½®ä¸­å¦‚å›¾è®¾ç½®ï¼Œå¹¶ç‚¹å‡»æ›´æ–°ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/chatanywhere/GPT_API_free/main/images/botgem.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;ChatBox&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;ChatGPTå¼€æºæ¡Œé¢åº”ç”¨ï¼Œæ”¯æŒå…¨éƒ¨æ¡Œé¢å¹³å°ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ä¸‹è½½é“¾æ¥ï¼š&lt;a href=&#34;https://github.com/Bin-Huang/chatbox/releases&#34;&gt;https://github.com/Bin-Huang/chatbox/releases&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;ä½¿ç”¨æ–¹æ³•ï¼šå¦‚å›¾åœ¨è®¾ç½®ä¸­å¡«å…¥è´­ä¹°çš„å¯†é’¥ï¼Œå¹¶å°†ä»£ç†è®¾ç½®ä¸º&lt;code&gt;https://api.chatanywhere.tech&lt;/code&gt;å³å¯&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/chatanywhere/GPT_API_free/main/images/chatbox.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Zoteroæ’ä»¶&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;pdfé˜…è¯»æ’ä»¶zotero-gpt&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;ä¸‹è½½é“¾æ¥ï¼š&lt;a href=&#34;https://github.com/MuiseDestiny/zotero-gpt/releases&#34;&gt;https://github.com/MuiseDestiny/zotero-gpt/releases&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;å®‰è£…å¥½æ’ä»¶åä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è®¾ç½®ï¼Œè¿˜æ˜¯ä¸ä¼šå¯ä»¥å»bç«™æœæ•™ç¨‹ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;/api https://api.chatanywhere.tech&#xA;&#xA;/secretKey è´­ä¹°çš„è½¬å‘key è®°ä½åˆ«å¿˜è®°å¸¦sk-&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/chatanywhere/GPT_API_free/main/images/zotero-gpt.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ç¿»è¯‘æ’ä»¶zotero-pdf-translate&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;ä¸‹è½½é“¾æ¥ï¼š&lt;a href=&#34;https://github.com/windingwind/zotero-pdf-translate/releases&#34;&gt;https://github.com/windingwind/zotero-pdf-translate/releases&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;æ¥å£åœ°å€å¡«å†™: &lt;a href=&#34;https://api.chatanywhere.tech/v1/chat/completions&#34;&gt;https://api.chatanywhere.tech/v1/chat/completions&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;ä¸ç”¨ç®¡çŠ¶æ€æ˜¯å¦æ˜¾ç¤ºå¯ç”¨ å¡«ä¸Šä¹‹åå°±å¯ä»¥äº†&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/chatanywhere/GPT_API_free/main/images/zotero-pdf-translate.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;æµè§ˆå™¨æ’ä»¶ChatGPT Sidebar&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;å®˜ç½‘é“¾æ¥ï¼š&lt;a href=&#34;https://chatgpt-sidebar.com/&#34;&gt;https://chatgpt-sidebar.com/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;å®‰è£…å¥½æ’ä»¶åè¿›å…¥è®¾ç½®é¡µé¢ï¼Œå¦‚å›¾æ‰€ç¤ºä¿®æ”¹è®¾ç½®ï¼Œå°†urlä¿®æ”¹ä¸º &lt;code&gt;https://api.chatanywhere.tech&lt;/code&gt; ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/chatanywhere/GPT_API_free/main/images/sidebar.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Jetbrainsæ’ä»¶ChatGPT - Easycode&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/chatanywhere/GPT_API_free/main/images/jet1.png&#34; width=&#34;200&#34;&gt; &#xA;&lt;p&gt;å®‰è£…å¥½æ’ä»¶ååœ¨Settings &amp;gt; Tools &amp;gt; OpenAI &amp;gt; GPT 3.5 Turboä¸­å¦‚å›¾æ‰€ç¤ºé…ç½®å¥½æ’ä»¶ï¼Œé‡ç‚¹è¦å°†Server Settings ä¿®æ”¹ä¸º &lt;code&gt;https://api.chatanywhere.tech/v1/chat/completions&lt;/code&gt; ã€‚å¹¶å‹¾é€‰Customize Serverã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/chatanywhere/GPT_API_free/main/images/jet2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Raycast æ’ä»¶ ChatGPT&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;åœ¨ Raycast Store ä¸­æ‰¾åˆ° ChatGPT æ’ä»¶ï¼Œå¹¶æŒ‰ç…§æç¤ºå®‰è£…ï¼š &lt;img src=&#34;https://raw.githubusercontent.com/chatanywhere/GPT_API_free/main/images/raycast1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å®‰è£…å®Œæˆååœ¨è¯¥æ’ä»¶é…ç½®ä¸­çš„ &lt;code&gt;API Key&lt;/code&gt; ä¸­å¡«å…¥æˆ‘ä»¬çš„API Keyï¼Œä»¥åŠé€‰ä¸­ &lt;code&gt;Change API Endpoint&lt;/code&gt;ï¼Œå¹¶åœ¨ &lt;code&gt;API Endpoint&lt;/code&gt; ä¸­å¡«å…¥ &lt;code&gt;https://api.chatanywhere.tech/v1&lt;/code&gt; &lt;img src=&#34;https://raw.githubusercontent.com/chatanywhere/GPT_API_free/main/images/raycast2.png&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/chatanywhere/GPT_API_free/main/images/raycast3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ğŸº enjoy it~ &lt;img src=&#34;https://raw.githubusercontent.com/chatanywhere/GPT_API_free/main/images/raycast4.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;APIæŠ¥é”™è¯´æ˜&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Overloadé”™è¯¯&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;å…·ä½“é”™è¯¯ä¿¡æ¯ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;{&#xA;  &#34;error&#34;: {&#xA;    &#34;message&#34;: &#34;That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID xxxxxxxxxxxx in your message.)&#34;,&#xA;    &#34;type&#34;: &#34;server_error&#34;,&#xA;    &#34;param&#34;: null,&#xA;    &#34;code&#34;: null&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;è¯¥é”™è¯¯ç”±äºOpenAIå®˜æ–¹æœåŠ¡å™¨è´Ÿè½½é«˜å¼•èµ·ï¼Œä¸è½¬å‘æœåŠ¡å™¨è´Ÿè½½æ— å…³ã€‚ä¸€èˆ¬ä¸€æ®µæ—¶é—´åæ¢å¤ï¼Œå¯ä»¥ç­‰å‡ ç§’åå†è¯•ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#chatanywhere/GPT_API_free&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=chatanywhere/GPT_API_free&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>d2l-ai/d2l-zh</title>
    <updated>2023-12-24T01:57:46Z</updated>
    <id>tag:github.com,2023-12-24:/d2l-ai/d2l-zh</id>
    <link href="https://github.com/d2l-ai/d2l-zh" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹ï¼šé¢å‘ä¸­æ–‡è¯»è€…ã€èƒ½è¿è¡Œã€å¯è®¨è®ºã€‚ä¸­è‹±æ–‡ç‰ˆè¢«70å¤šä¸ªå›½å®¶çš„500å¤šæ‰€å¤§å­¦ç”¨äºæ•™å­¦ã€‚&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ï¼ˆDive into Deep Learningï¼ŒD2L.aiï¼‰&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zh.d2l.ai&#34;&gt;ç¬¬äºŒç‰ˆï¼šzh.D2L.ai&lt;/a&gt; | &lt;a href=&#34;https://zh-v1.d2l.ai/&#34;&gt;ç¬¬ä¸€ç‰ˆï¼šzh-v1.D2L.ai&lt;/a&gt; | å®‰è£…å’Œä½¿ç”¨ä¹¦ä¸­æºä»£ç ï¼š &lt;a href=&#34;https://zh.d2l.ai/chapter_installation/index.html&#34;&gt;ç¬¬äºŒç‰ˆ&lt;/a&gt; &lt;a href=&#34;https://zh-v1.d2l.ai/chapter_prerequisite/install.html&#34;&gt;ç¬¬ä¸€ç‰ˆ&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5 align=&#34;center&#34;&gt;&lt;i&gt;ç†è§£æ·±åº¦å­¦ä¹ çš„æœ€ä½³æ–¹æ³•æ˜¯å­¦ä»¥è‡´ç”¨ã€‚&lt;/i&gt;&lt;/h5&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;200&#34; src=&#34;https://raw.githubusercontent.com/d2l-ai/d2l-zh/master/static/frontpage/_images/eq.jpg&#34;&gt; &lt;img width=&#34;200&#34; src=&#34;https://raw.githubusercontent.com/d2l-ai/d2l-zh/master/static/frontpage/_images/figure.jpg&#34;&gt; &lt;img width=&#34;200&#34; src=&#34;https://raw.githubusercontent.com/d2l-ai/d2l-zh/master/static/frontpage/_images/code.jpg&#34;&gt; &lt;img width=&#34;200&#34; src=&#34;https://raw.githubusercontent.com/d2l-ai/d2l-zh/master/static/frontpage/_images/notebook.gif&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;æœ¬å¼€æºé¡¹ç›®ä»£è¡¨äº†æˆ‘ä»¬çš„ä¸€ç§å°è¯•ï¼šæˆ‘ä»¬å°†æ•™ç»™è¯»è€…æ¦‚å¿µã€èƒŒæ™¯çŸ¥è¯†å’Œä»£ç ï¼›æˆ‘ä»¬å°†åœ¨åŒä¸€ä¸ªåœ°æ–¹é˜è¿°å‰–æé—®é¢˜æ‰€éœ€çš„æ‰¹åˆ¤æ€§æ€ç»´ã€è§£å†³é—®é¢˜æ‰€éœ€çš„æ•°å­¦çŸ¥è¯†ï¼Œä»¥åŠå®ç°è§£å†³æ–¹æ¡ˆæ‰€éœ€çš„å·¥ç¨‹æŠ€èƒ½ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æˆ‘ä»¬çš„ç›®æ ‡æ˜¯åˆ›å»ºä¸€ä¸ªä¸ºå®ç°ä»¥ä¸‹ç›®æ ‡çš„ç»Ÿä¸€èµ„æºï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;æ‰€æœ‰äººå‡å¯åœ¨ç½‘ä¸Šå…è´¹è·å–ï¼›&lt;/li&gt; &#xA; &lt;li&gt;æä¾›è¶³å¤Ÿçš„æŠ€æœ¯æ·±åº¦ï¼Œä»è€Œå¸®åŠ©è¯»è€…å®é™…æˆä¸ºæ·±åº¦å­¦ä¹ åº”ç”¨ç§‘å­¦å®¶ï¼šæ—¢ç†è§£æ•°å­¦åŸç†ï¼Œåˆèƒ½å¤Ÿå®ç°å¹¶ä¸æ–­æ”¹è¿›æ–¹æ³•ï¼›&lt;/li&gt; &#xA; &lt;li&gt;åŒ…å«å¯è¿è¡Œçš„ä»£ç ï¼Œä¸ºè¯»è€…å±•ç¤ºå¦‚ä½•åœ¨å®é™…ä¸­è§£å†³é—®é¢˜ã€‚è¿™æ ·ä¸ä»…ç›´æ¥å°†æ•°å­¦å…¬å¼å¯¹åº”æˆå®é™…ä»£ç ï¼Œè€Œä¸”å¯ä»¥ä¿®æ”¹ä»£ç ã€è§‚å¯Ÿç»“æœå¹¶åŠæ—¶è·å–ç»éªŒï¼›&lt;/li&gt; &#xA; &lt;li&gt;å…è®¸æˆ‘ä»¬å’Œæ•´ä¸ªç¤¾åŒºä¸æ–­å¿«é€Ÿè¿­ä»£å†…å®¹ï¼Œä»è€Œç´§è·Ÿä»åœ¨é«˜é€Ÿå‘å±•çš„æ·±åº¦å­¦ä¹ é¢†åŸŸï¼›&lt;/li&gt; &#xA; &lt;li&gt;ç”±åŒ…å«æœ‰å…³æŠ€æœ¯ç»†èŠ‚é—®ç­”çš„è®ºå›ä½œä¸ºè¡¥å……ï¼Œä½¿å¤§å®¶å¯ä»¥ç›¸äº’ç­”ç–‘å¹¶äº¤æ¢ç»éªŒã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h5 align=&#34;center&#34;&gt;å°†æœ¬ä¹¦ï¼ˆä¸­è‹±æ–‡ç‰ˆï¼‰ç”¨ä½œæ•™ææˆ–å‚è€ƒä¹¦çš„å¤§å­¦&lt;/h5&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;400&#34; src=&#34;https://d2l.ai/_images/map.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·Star (â˜…) æœ¬ä»“åº“æˆ–å¼•ç”¨æœ¬ä¹¦çš„è‹±æ–‡ç‰ˆï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@book{zhang2023dive,&#xA;    title={Dive into Deep Learning},&#xA;    author={Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},&#xA;    publisher={Cambridge University Press},&#xA;    note={\url{https://D2L.ai}},&#xA;    year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;æœ¬ä¹¦çš„è‹±æ–‡ç‰ˆ&lt;/h2&gt; &#xA;&lt;p&gt;è™½ç„¶çº¸è´¨ä¹¦å·²å‡ºç‰ˆï¼Œä½†æ·±åº¦å­¦ä¹ é¢†åŸŸä¾ç„¶åœ¨è¿…é€Ÿå‘å±•ã€‚ä¸ºäº†å¾—åˆ°æ¥è‡ªæ›´å¹¿æ³›çš„è‹±æ–‡å¼€æºç¤¾åŒºçš„å¸®åŠ©ï¼Œä»è€Œæå‡æœ¬ä¹¦è´¨é‡ï¼Œæœ¬ä¹¦çš„æ–°ç‰ˆå°†ç»§ç»­ç”¨è‹±æ–‡ç¼–å†™ï¼Œå¹¶æ¬å›ä¸­æ–‡ç‰ˆã€‚&lt;/p&gt; &#xA;&lt;p&gt;æ¬¢è¿å…³æ³¨æœ¬ä¹¦çš„&lt;a href=&#34;https://github.com/d2l-ai/d2l-en&#34;&gt;è‹±æ–‡å¼€æºé¡¹ç›®&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ä¸­è‹±æ–‡æ•™å­¦èµ„æº&lt;/h2&gt; &#xA;&lt;p&gt;åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡ 2019 å¹´æ˜¥å­¦æœŸ &lt;a href=&#34;http://courses.d2l.ai/berkeley-stat-157/index.html&#34;&gt;&lt;em&gt;Introduction to Deep Learning&lt;/em&gt; è¯¾ç¨‹&lt;/a&gt;æ•™æï¼ˆåŒæ—¶æä¾›å«æ•™å­¦è§†é¢‘åœ°å€çš„&lt;a href=&#34;https://github.com/d2l-ai/berkeley-stat-157/tree/master/slides-zh&#34;&gt;ä¸­æ–‡ç‰ˆè¯¾ä»¶&lt;/a&gt;ï¼‰ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;å­¦æœ¯ç•Œæ¨è&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;Dive into this book if you want to dive into deep learning!&#34;&lt;/p&gt; &#xA; &lt;b&gt;â€” éŸ©å®¶ç‚œï¼ŒACM é™¢å£«ã€IEEE é™¢å£«ï¼Œç¾å›½ä¼Šåˆ©è¯ºä¼Šå¤§å­¦é¦™æ§Ÿåˆ†æ ¡è®¡ç®—æœºç³» Michael Aiken Chair æ•™æˆ&lt;/b&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;This is a highly welcome addition to the machine learning literature.&#34;&lt;/p&gt; &#xA; &lt;b&gt;â€” Bernhard SchÃ¶lkopfï¼ŒACM é™¢å£«ã€å¾·å›½å›½å®¶ç§‘å­¦é™¢é™¢å£«ï¼Œå¾·å›½é©¬å…‹æ–¯â€¢æ™®æœ—å…‹ç ”ç©¶æ‰€æ™ºèƒ½ç³»ç»Ÿé™¢é™¢é•¿&lt;/b&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;ä¹¦ä¸­ä»£ç å¯è°“â€˜æ‰€å­¦å³æ‰€ç”¨â€™ã€‚&#34;&lt;/p&gt; &#xA; &lt;b&gt;â€” å‘¨å¿—åï¼ŒACM é™¢å£«ã€IEEE é™¢å£«ã€AAAS é™¢å£«ï¼Œå—äº¬å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ç³»ä¸»ä»»&lt;/b&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;è¿™æœ¬ä¹¦å¯ä»¥å¸®åŠ©æ·±åº¦å­¦ä¹ å®è·µè€…å¿«é€Ÿæå‡è‡ªå·±çš„èƒ½åŠ›ã€‚&#34;&lt;/p&gt; &#xA; &lt;b&gt;â€” å¼ æ½¼ï¼ŒASA é™¢å£«ã€IMS é™¢å£«ï¼Œé¦™æ¸¯ç§‘æŠ€å¤§å­¦è®¡ç®—æœºç³»å’Œæ•°å­¦ç³»æ•™æˆ&lt;/b&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;å·¥ä¸šç•Œæ¨è&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;ä¸€æœ¬ä¼˜ç§€çš„æ·±åº¦å­¦ä¹ æ•™æï¼Œå€¼å¾—ä»»ä½•æƒ³äº†è§£æ·±åº¦å­¦ä¹ ä½•ä»¥å¼•çˆ†äººå·¥æ™ºèƒ½é©å‘½çš„äººå…³æ³¨ã€‚&#34;&lt;/p&gt; &#xA; &lt;b&gt;â€” é»„ä»å‹‹ï¼ŒNVIDIAåˆ›å§‹äºº &amp;amp; CEO&lt;/b&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹æ˜¯æœ€é€‚åˆå·¥ä¸šç•Œç ”å‘å·¥ç¨‹å¸ˆå­¦ä¹ çš„ã€‚æˆ‘æ¯«æ— ä¿ç•™åœ°å‘å¹¿å¤§çš„è¯»è€…ä»¬å¼ºçƒˆæ¨èã€‚&#34;&lt;/p&gt; &#xA; &lt;b&gt;â€” ä½™å‡¯ï¼Œåœ°å¹³çº¿å…¬å¸åˆ›å§‹äºº &amp;amp; CEO&lt;/b&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;å¼ºçƒˆæ¨èè¿™æœ¬ä¹¦ï¼æˆ‘ç‰¹åˆ«èµèµè¿™ç§æ‰‹è„‘ä¸€ä½“çš„å­¦ä¹ æ–¹å¼ã€‚&#34;&lt;/p&gt; &#xA; &lt;b&gt;â€” æ¼†è¿œï¼Œå¤æ—¦å¤§å­¦â€œæµ©æ¸…â€æ•™æˆã€äººå·¥æ™ºèƒ½åˆ›æ–°ä¸äº§ä¸šç ”ç©¶é™¢é™¢é•¿&lt;/b&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹æ˜¯ä¸€æœ¬å¾ˆå®¹æ˜“è®©å­¦ä¹ è€…ä¸Šç˜¾çš„ä¹¦ã€‚&#34;&lt;/p&gt; &#xA; &lt;b&gt;â€” æ²ˆå¼ºï¼Œå°†é—¨åˆ›æŠ•åˆ›å§‹åˆä¼™äºº&lt;/b&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;è´¡çŒ®&lt;/h2&gt; &#xA;&lt;p&gt;æ„Ÿè°¢&lt;a href=&#34;https://github.com/d2l-ai/d2l-zh/graphs/contributors&#34;&gt;ç¤¾åŒºè´¡çŒ®è€…ä»¬&lt;/a&gt;ä¸ºæ¯ä¸€ä½è¯»è€…æ”¹è¿›è¿™æœ¬å¼€æºä¹¦ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zh.d2l.ai/chapter_appendix-tools-for-deep-learning/contributing.html&#34;&gt;å¦‚ä½•è´¡çŒ®&lt;/a&gt; | &lt;a href=&#34;https://zh.d2l.ai/chapter_preface/index.html&#34;&gt;è‡´è°¢&lt;/a&gt; | &lt;a href=&#34;https://discuss.d2l.ai/c/chinese-version/16&#34;&gt;è®¨è®ºæˆ–æŠ¥å‘Šé—®é¢˜&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/d2l-ai/d2l-zh/master/INFO.md&#34;&gt;å…¶ä»–&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/promptbase</title>
    <updated>2023-12-24T01:57:46Z</updated>
    <id>tag:github.com,2023-12-24:/microsoft/promptbase</id>
    <link href="https://github.com/microsoft/promptbase" rel="alternate"></link>
    <summary type="html">&lt;p&gt;All things prompt engineering&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;promptbase&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;promptbase&lt;/code&gt; is an evolving collection of resources, best practices, and example scripts for eliciting the best performance from foundation models like &lt;code&gt;GPT-4&lt;/code&gt;. We currently host scripts demonstrating the &lt;a href=&#34;https://arxiv.org/abs/2311.16452&#34;&gt;&lt;code&gt;Medprompt&lt;/code&gt; methodology&lt;/a&gt;, including examples of how we further extended this collection of prompting techniques (&#34;&lt;code&gt;Medprompt+&lt;/code&gt;&#34;) into non-medical domains:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Benchmark&lt;/th&gt; &#xA;   &lt;th&gt;GPT-4 Prompt&lt;/th&gt; &#xA;   &lt;th&gt;GPT-4 Results&lt;/th&gt; &#xA;   &lt;th&gt;Gemini Ultra Results&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MMLU&lt;/td&gt; &#xA;   &lt;td&gt;Medprompt+&lt;/td&gt; &#xA;   &lt;td&gt;90.10%&lt;/td&gt; &#xA;   &lt;td&gt;90.04%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GSM8K&lt;/td&gt; &#xA;   &lt;td&gt;Zero-shot&lt;/td&gt; &#xA;   &lt;td&gt;95.3%&lt;/td&gt; &#xA;   &lt;td&gt;94.4%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MATH&lt;/td&gt; &#xA;   &lt;td&gt;Zero-shot&lt;/td&gt; &#xA;   &lt;td&gt;68.4%&lt;/td&gt; &#xA;   &lt;td&gt;53.2%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HumanEval&lt;/td&gt; &#xA;   &lt;td&gt;Zero-shot&lt;/td&gt; &#xA;   &lt;td&gt;87.8%&lt;/td&gt; &#xA;   &lt;td&gt;74.4%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BIG-Bench-Hard&lt;/td&gt; &#xA;   &lt;td&gt;Few-shot + CoT&lt;/td&gt; &#xA;   &lt;td&gt;89.0%&lt;/td&gt; &#xA;   &lt;td&gt;83.6%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DROP&lt;/td&gt; &#xA;   &lt;td&gt;Zero-shot + CoT&lt;/td&gt; &#xA;   &lt;td&gt;83.7%&lt;/td&gt; &#xA;   &lt;td&gt;82.4%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HellaSwag&lt;/td&gt; &#xA;   &lt;td&gt;10-shot&lt;/td&gt; &#xA;   &lt;td&gt;95.3%&lt;/td&gt; &#xA;   &lt;td&gt;87.8%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;In the near future, &lt;code&gt;promptbase&lt;/code&gt; will also offer further case studies and structured interviews around the scientific process we take behind prompt engineering. We&#39;ll also offer specialized deep dives into specialized tooling that accentuates the prompt engineering process. Stay tuned!&lt;/p&gt; &#xA;&lt;h2&gt;&lt;code&gt;Medprompt&lt;/code&gt; and The Power of Prompting&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;em&gt;&#34;Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine&#34; (H. Nori, Y. T. Lee, S. Zhang, D. Carignan, R. Edgar, N. Fusi, N. King, J. Larson, Y. Li, W. Liu, R. Luo, S. M. McKinney, R. O. Ness, H. Poon, T. Qin, N. Usuyama, C. White, E. Horvitz 2023)&lt;/em&gt; &lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;pre&gt;&#xA;&lt;p&gt;@article{nori2023can,&#xA;title={Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine},&#xA;author={Nori, Harsha and Lee, Yin Tat and Zhang, Sheng and Carignan, Dean and Edgar, Richard and Fusi, Nicolo and King, Nicholas and Larson, Jonathan and Li, Yuanzhi and Liu, Weishung and others},&#xA;journal={arXiv preprint arXiv:2311.16452},&#xA;year={2023}&#xA;}&#xA;&lt;/p&gt;&lt;/pre&gt; &#xA; &lt;a href=&#34;https://arxiv.org/pdf/1909.09223.pdf&#34;&gt;Paper link&lt;/a&gt;&#xA; &lt;p&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/promptbase/main/images/medprompt_radar.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;In a recent &lt;a href=&#34;https://arxiv.org/abs/2311.16452&#34;&gt;study&lt;/a&gt;, we showed how the composition of several prompting strategies into a method that we refer to as &lt;code&gt;Medprompt&lt;/code&gt; can efficiently steer generalist models like GPT-4 to achieve top performance, even when compared to models specifically finetuned for medicine. &lt;code&gt;Medprompt&lt;/code&gt; composes three distinct strategies together -- including dynamic few-shot selection, self-generated chain of thought, and choice-shuffle ensembling -- to elicit specialist level performance from GPT-4. We briefly describe these strategies here:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/promptbase/main/images/medprompt_sa_graphic.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic Few Shots&lt;/strong&gt;: Few-shot learning -- providing several examples of the task and response to a foundation model -- enables models quickly adapt to a specific domain and learn to follow the task format. For simplicity and efficiency, the few-shot examples applied in prompting for a particular task are typically fixed; they are unchanged across test examples. This necessitates that the few-shot examples selected are broadly representative and relevant to a wide distribution of text examples. One approach to meeting these requirements is to have domain experts carefully hand-craft exemplars. Even so, this approach cannot guarantee that the curated, fixed few-shot examples will be appropriately representative of every test example. However, with enough available data, we can select &lt;em&gt;different&lt;/em&gt; few-shot examples for different task inputs. We refer to this approach as employing dynamic few-shot examples. The method makes use of a mechanism to identify examples based on their similarity to the case at hand. For Medprompt, we did the following to identify representative few shot examples: Given a test example, we choose k training examples that are semantically similar using a k-NN clustering in the embedding space. Specifically, we first use OpenAI&#39;s &lt;code&gt;text-embedding-ada-002&lt;/code&gt; model to embed candidate exemplars for few-shot learning. Then, for each test question x, we retrieve its nearest k neighbors x1, x2, ..., xk from the training set (according to distance in the embedding space of text-embedding-ada-002). These examples -- the ones most similar in embedding space to the test question -- are ultimately registered in the prompt.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Self-Generated Chain of Thought (CoT)&lt;/strong&gt;: Chain-of-thought (CoT) uses natural language statements, such as â€œLetâ€™s think step by step,â€ to explicitly encourage the model to generate a series of intermediate reasoning steps. The approach has been found to significantly improve the ability of foundation models to perform complex reasoning. Most approaches to chain-of-thought center on the use of experts to manually compose few-shot examples with chains of thought for prompting. Rather than rely on human experts, we pursued a mechanism to automate the creation of chain-of-thought examples. We found that we could simply ask GPT-4 to generate chain-of-thought for the training examples, with appropriate guardrails for reducing risk of hallucination via incorrect reasoning chains.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Majority Vote Ensembling&lt;/strong&gt;: &lt;a href=&#34;https://en.wikipedia.org/wiki/Ensemble_learning&#34;&gt;Ensembling&lt;/a&gt; refers to combining the output of several algorithms together to yield better predictive performance than any individual algorithm. Frontier models like &lt;code&gt;GPT-4&lt;/code&gt; benefit from ensembling of their own outputs. A simple technique is to have a variety of prompts, or a single prompt with varied &lt;code&gt;temperature&lt;/code&gt;, and report the most frequent answer amongst the ensemble constituents. For multiple choice questions, we employ a further trick that increases the diversity of the ensemble called &lt;code&gt;choice-shuffling&lt;/code&gt;, where we shuffle the relative order of the answer choices before generating each reasoning path. We then select the most consistent answer, i.e., the one that is least sensitive to choice shuffling, which increases the robustness of the answer.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The combination of these three techniques led to breakthrough performance in Medprompt for medical challenge questions. Implementation details of these techniques can be found here: &lt;a href=&#34;https://github.com/microsoft/promptbase/tree/main/src/promptbase/mmlu&#34;&gt;https://github.com/microsoft/promptbase/tree/main/src/promptbase/mmlu&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;code&gt;Medprompt+&lt;/code&gt; | Extending the power of prompting&lt;/h2&gt; &#xA;&lt;p&gt;Here we provide some intuitive details on how we extended the &lt;code&gt;medprompt&lt;/code&gt; prompting framework to elicit even stronger out-of-domain performance on the MMLU (Measuring Massive Multitask Language Understanding) benchmark. MMLU was established as a test of general knowledge and reasoning powers of large language models. The complete MMLU benchmark contains tens of thousands of challenge problems of different forms across 57 areas from basic mathematics to United States history, law, computer science, engineering, medicine, and more.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/promptbase/main/images/mmlu_accuracy_ablation.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;We found that applying Medprompt without modification to the whole MMLU achieved a score of 89.1%. Not bad for a single policy working across a great diversity of problems! But could we push Medprompt to do better? Simply scaling-up MedPrompt can yield further benefits. As a first step, we increased the number of ensembled calls from five to 20. This boosted performance to 89.56%.&lt;/p&gt; &#xA;&lt;p&gt;On working to push further with refinement of Medprompt, we noticed that performance was relatively poor for specific topics of the MMLU. MMLU contains a great diversity of types of questions, depending on the discipline and specific benchmark at hand. How might we push GPT-4 to perform even better on MMLU given the diversity of problems?&lt;/p&gt; &#xA;&lt;p&gt;We focused on extension to a portfolio approach based on the observation that some topical areas tend to ask questions that would require multiple steps of reasoning and perhaps a scratch pad to keep track of multiple parts of a solution. Other areas seek factual answers that follow more directly from questions. Medprompt employs â€œchain-of-thoughtâ€ (CoT) reasoning, resonating with multi-step solving. We wondered if the sophisticated Medprompt-classic approach might do less well on very simple questions and if the system might do better if a simpler method were used for the factual queries.&lt;/p&gt; &#xA;&lt;p&gt;Following this argument, we found that we could boost the performance on MMLU by extending MedPrompt with a simple two-method prompt portfolio. We add to the classic Medprompt a set of 10 simple, direct few-shot prompts soliciting an answer directly without Chain of Thought. We then ask GPT-4 for help with deciding on the best strategy for each topic area and question. As a screening call, for each question we first ask GPT-4:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Question&#xA;{{ question }}&#xA; &#xA;# Task&#xA;Does answering the question above require a scratch-pad?&#xA;A. Yes&#xA;B. No&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If GPT-4 thinks the question does require a scratch-pad, then the contribution of the Chain-of-Thought component of the ensemble is doubled. If it doesn&#39;t, we halve that contribution (and let the ensemble instead depend more on the direct few-shot prompts). Dynamically leveraging the appropriate prompting technique in the ensemble led to a further +0.5% performance improvement across the MMLU.&lt;/p&gt; &#xA;&lt;p&gt;We note that Medprompt+ relies on accessing confidence scores (logprobs) from GPT-4. These are not publicly available via the current API but will be enabled for all in the near future.&lt;/p&gt; &#xA;&lt;h2&gt;Running Scripts&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: Some scripts hosted here are published for reference on methodology, but may not be immediately executable against public APIs. We&#39;re working hard on making the pipelines easier to run &#34;out of the box&#34; over the next few days, and appreciate your patience in the interim!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;First, clone the repo and install the promptbase package:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd src&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, decide which tests you&#39;d like to run. You can choose from:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;bigbench&lt;/li&gt; &#xA; &lt;li&gt;drop&lt;/li&gt; &#xA; &lt;li&gt;gsm8k&lt;/li&gt; &#xA; &lt;li&gt;humaneval&lt;/li&gt; &#xA; &lt;li&gt;math&lt;/li&gt; &#xA; &lt;li&gt;mmlu&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Before running the tests, you will need to download the datasets from the original sources (see below) and place them in the &lt;code&gt;src/promptbase/datasets&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;p&gt;After downloading datasets and installing the promptbase package, you can run a test with:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;python -m promptbase dataset_name&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;For example:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;python -m promptbase gsm8k&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Dataset Links&lt;/h2&gt; &#xA;&lt;p&gt;To run evaluations, download these datasets and add them to /src/promptbase/datasets/&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;MMLU: &lt;a href=&#34;https://github.com/hendrycks/test&#34;&gt;https://github.com/hendrycks/test&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;HumanEval: &lt;a href=&#34;https://huggingface.co/datasets/openai_humaneval&#34;&gt;https://huggingface.co/datasets/openai_humaneval&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;DROP: &lt;a href=&#34;https://allenai.org/data/drop&#34;&gt;https://allenai.org/data/drop&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;GSM8K: &lt;a href=&#34;https://github.com/openai/grade-school-math&#34;&gt;https://github.com/openai/grade-school-math&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;MATH: &lt;a href=&#34;https://huggingface.co/datasets/hendrycks/competition_math&#34;&gt;https://huggingface.co/datasets/hendrycks/competition_math&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Big-Bench-Hard: &lt;a href=&#34;https://github.com/suzgunmirac/BIG-Bench-Hard&#34;&gt;https://github.com/suzgunmirac/BIG-Bench-Hard&lt;/a&gt; The contents of this repo need to be put into a directory called &lt;code&gt;BigBench&lt;/code&gt; in the &lt;code&gt;datasets&lt;/code&gt; directory&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Other Resources:&lt;/h2&gt; &#xA;&lt;p&gt;Medprompt Blog: &lt;a href=&#34;https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/&#34;&gt;https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Medprompt Research Paper: &lt;a href=&#34;https://arxiv.org/abs/2311.16452&#34;&gt;https://arxiv.org/abs/2311.16452&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Medprompt+: &lt;a href=&#34;https://www.microsoft.com/en-us/research/blog/steering-at-the-frontier-extending-the-power-of-prompting/&#34;&gt;https://www.microsoft.com/en-us/research/blog/steering-at-the-frontier-extending-the-power-of-prompting/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Microsoft Introduction to Prompt Engineering: &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering&#34;&gt;https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Microsoft Advanced Prompt Engineering Guide: &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions&#34;&gt;https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>