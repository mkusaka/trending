<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-07T02:00:10Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>TencentARC/GFPGAN</title>
    <updated>2022-08-07T02:00:10Z</updated>
    <id>tag:github.com,2022-08-07:/TencentARC/GFPGAN</id>
    <link href="https://github.com/TencentARC/GFPGAN" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GFPGAN aims at developing Practical Algorithms for Real-world Face Restoration.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/TencentARC/GFPGAN/master/assets/gfpgan_logo.png&#34; height=&#34;130&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;&#xA; &lt;div align=&#34;center&#34;&gt;&#xA;  &lt;b&gt;&lt;a href=&#34;https://raw.githubusercontent.com/TencentARC/GFPGAN/master/README.md&#34;&gt;English&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/TencentARC/GFPGAN/master/README_CN.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/b&gt;&#xA; &lt;/div&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/TencentARC/GFPGAN/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/downloads/TencentARC/GFPGAN/total.svg?sanitize=true&#34; alt=&#34;download&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/gfpgan/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/gfpgan&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/TencentARC/GFPGAN/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/TencentARC/GFPGAN&#34; alt=&#34;Open issue&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/TencentARC/GFPGAN/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-closed/TencentARC/GFPGAN&#34; alt=&#34;Closed issue&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/TencentARC/GFPGAN/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true&#34; alt=&#34;LICENSE&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/TencentARC/GFPGAN/raw/master/.github/workflows/pylint.yml&#34;&gt;&lt;img src=&#34;https://github.com/TencentARC/GFPGAN/actions/workflows/pylint.yml/badge.svg?sanitize=true&#34; alt=&#34;python lint&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/TencentARC/GFPGAN/raw/master/.github/workflows/publish-pip.yml&#34;&gt;&lt;img src=&#34;https://github.com/TencentARC/GFPGAN/actions/workflows/publish-pip.yml/badge.svg?sanitize=true&#34; alt=&#34;Publish-pip&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1sVsoBd9AjckIXThgtZhGrHRfFI6UUYOo&#34;&gt;Colab Demo&lt;/a&gt; for GFPGAN &lt;a href=&#34;https://colab.research.google.com/drive/1sVsoBd9AjckIXThgtZhGrHRfFI6UUYOo&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;google colab logo&#34;&gt;&lt;/a&gt;; (Another &lt;a href=&#34;https://colab.research.google.com/drive/1Oa1WwKB4M4l1GmR7CtswDVgOCOeSLChA?usp=sharing&#34;&gt;Colab Demo&lt;/a&gt; for the original paper model)&lt;/li&gt; &#xA; &lt;li&gt;Online demo: &lt;a href=&#34;https://huggingface.co/spaces/akhaliq/GFPGAN&#34;&gt;Huggingface&lt;/a&gt; (return only the cropped face)&lt;/li&gt; &#xA; &lt;li&gt;Online demo: &lt;a href=&#34;https://replicate.com/xinntao/gfpgan&#34;&gt;Replicate.ai&lt;/a&gt; (may need to sign in, return the whole image)&lt;/li&gt; &#xA; &lt;li&gt;Online demo: &lt;a href=&#34;https://app.baseten.co/applications/Q04Lz0d/operator_views/8qZG6Bg&#34;&gt;Baseten.co&lt;/a&gt; (backed by GPU, returns the whole image)&lt;/li&gt; &#xA; &lt;li&gt;We provide a &lt;em&gt;clean&lt;/em&gt; version of GFPGAN, which can run without CUDA extensions. So that it can run in &lt;strong&gt;Windows&lt;/strong&gt; or on &lt;strong&gt;CPU mode&lt;/strong&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;üöÄ&lt;/span&gt; &lt;strong&gt;Thanks for your interest in our work. You may also want to check our new updates on the &lt;em&gt;tiny models&lt;/em&gt; for &lt;em&gt;anime images and videos&lt;/em&gt; in &lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN/raw/master/docs/anime_video_model.md&#34;&gt;Real-ESRGAN&lt;/a&gt;&lt;/strong&gt; &lt;span&gt;üòä&lt;/span&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;GFPGAN aims at developing a &lt;strong&gt;Practical Algorithm for Real-world Face Restoration&lt;/strong&gt;.&lt;br&gt; It leverages rich and diverse priors encapsulated in a pretrained face GAN (&lt;em&gt;e.g.&lt;/em&gt;, StyleGAN2) for blind face restoration.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;‚ùì&lt;/span&gt; Frequently Asked Questions can be found in &lt;a href=&#34;https://raw.githubusercontent.com/TencentARC/GFPGAN/master/FAQ.md&#34;&gt;FAQ.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;üö©&lt;/span&gt; &lt;strong&gt;Updates&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;span&gt;üî•&lt;/span&gt;&lt;span&gt;üî•&lt;/span&gt;&lt;span&gt;‚úÖ&lt;/span&gt; Add &lt;strong&gt;&lt;a href=&#34;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth&#34;&gt;V1.3 model&lt;/a&gt;&lt;/strong&gt;, which produces &lt;strong&gt;more natural&lt;/strong&gt; restoration results, and better results on &lt;em&gt;very low-quality&lt;/em&gt; / &lt;em&gt;high-quality&lt;/em&gt; inputs. See more in &lt;a href=&#34;https://raw.githubusercontent.com/TencentARC/GFPGAN/master/#european_castle-model-zoo&#34;&gt;Model zoo&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/TencentARC/GFPGAN/master/Comparisons.md&#34;&gt;Comparisons.md&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;‚úÖ&lt;/span&gt; Integrated to &lt;a href=&#34;https://huggingface.co/spaces&#34;&gt;Huggingface Spaces&lt;/a&gt; with &lt;a href=&#34;https://github.com/gradio-app/gradio&#34;&gt;Gradio&lt;/a&gt;. See &lt;a href=&#34;https://huggingface.co/spaces/akhaliq/GFPGAN&#34;&gt;Gradio Web Demo&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;‚úÖ&lt;/span&gt; Support enhancing non-face regions (background) with &lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN&#34;&gt;Real-ESRGAN&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;‚úÖ&lt;/span&gt; We provide a &lt;em&gt;clean&lt;/em&gt; version of GFPGAN, which does not require CUDA extensions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;‚úÖ&lt;/span&gt; We provide an updated model without colorizing faces.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;If GFPGAN is helpful in your photos/projects, please help to &lt;span&gt;‚≠ê&lt;/span&gt; this repo or recommend it to your friends. Thanks&lt;span&gt;üòä&lt;/span&gt; Other recommended projects:&lt;br&gt; &lt;span&gt;‚ñ∂&lt;/span&gt; &lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN&#34;&gt;Real-ESRGAN&lt;/a&gt;: A practical algorithm for general image restoration&lt;br&gt; &lt;span&gt;‚ñ∂&lt;/span&gt; &lt;a href=&#34;https://github.com/xinntao/BasicSR&#34;&gt;BasicSR&lt;/a&gt;: An open-source image and video restoration toolbox&lt;br&gt; &lt;span&gt;‚ñ∂&lt;/span&gt; &lt;a href=&#34;https://github.com/xinntao/facexlib&#34;&gt;facexlib&lt;/a&gt;: A collection that provides useful face-relation functions&lt;br&gt; &lt;span&gt;‚ñ∂&lt;/span&gt; &lt;a href=&#34;https://github.com/xinntao/HandyView&#34;&gt;HandyView&lt;/a&gt;: A PyQt5-based image viewer that is handy for view and comparison&lt;br&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;span&gt;üìñ&lt;/span&gt; GFP-GAN: Towards Real-World Blind Face Restoration with Generative Facial Prior&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2101.04061&#34;&gt;Paper&lt;/a&gt;] ‚ÄÉ [&lt;a href=&#34;https://xinntao.github.io/projects/gfpgan&#34;&gt;Project Page&lt;/a&gt;] ‚ÄÉ [Demo] &lt;br&gt; &lt;a href=&#34;https://xinntao.github.io/&#34;&gt;Xintao Wang&lt;/a&gt;, &lt;a href=&#34;https://yu-li.github.io/&#34;&gt;Yu Li&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/citations?hl=en&amp;amp;user=KjQLROoAAAAJ&#34;&gt;Honglun Zhang&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=4oXBp9UAAAAJ&amp;amp;hl=en&#34;&gt;Ying Shan&lt;/a&gt; &lt;br&gt; Applied Research Center (ARC), Tencent PCG&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://xinntao.github.io/projects/GFPGAN_src/gfpgan_teaser.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;&lt;span&gt;üîß&lt;/span&gt; Dependencies and Installation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python &amp;gt;= 3.7 (Recommend to use &lt;a href=&#34;https://www.anaconda.com/download/#linux&#34;&gt;Anaconda&lt;/a&gt; or &lt;a href=&#34;https://docs.conda.io/en/latest/miniconda.html&#34;&gt;Miniconda&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch &amp;gt;= 1.7&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Option: NVIDIA GPU + &lt;a href=&#34;https://developer.nvidia.com/cuda-downloads&#34;&gt;CUDA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Option: Linux&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;We now provide a &lt;em&gt;clean&lt;/em&gt; version of GFPGAN, which does not require customized CUDA extensions. &lt;br&gt; If you want to use the original model in our paper, please see &lt;a href=&#34;https://raw.githubusercontent.com/TencentARC/GFPGAN/master/PaperModel.md&#34;&gt;PaperModel.md&lt;/a&gt; for installation.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Clone repo&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/TencentARC/GFPGAN.git&#xA;cd GFPGAN&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install dependent packages&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Install basicsr - https://github.com/xinntao/BasicSR&#xA;# We use BasicSR for both training and inference&#xA;pip install basicsr&#xA;&#xA;# Install facexlib - https://github.com/xinntao/facexlib&#xA;# We use face detection and face restoration helper in the facexlib package&#xA;pip install facexlib&#xA;&#xA;pip install -r requirements.txt&#xA;python setup.py develop&#xA;&#xA;# If you want to enhance the background (non-face) regions with Real-ESRGAN,&#xA;# you also need to install the realesrgan package&#xA;pip install realesrgan&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;&lt;span&gt;‚ö°&lt;/span&gt; Quick Inference&lt;/h2&gt; &#xA;&lt;p&gt;We take the v1.3 version for an example. More models can be found &lt;a href=&#34;https://raw.githubusercontent.com/TencentARC/GFPGAN/master/#european_castle-model-zoo&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Download pre-trained models: &lt;a href=&#34;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth&#34;&gt;GFPGANv1.3.pth&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Inference!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python inference_gfpgan.py -i inputs/whole_imgs -o results -v 1.3 -s 2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;Usage: python inference_gfpgan.py -i inputs/whole_imgs -o results -v 1.3 -s 2 [options]...&#xA;&#xA;  -h                   show this help&#xA;  -i input             Input image or folder. Default: inputs/whole_imgs&#xA;  -o output            Output folder. Default: results&#xA;  -v version           GFPGAN model version. Option: 1 | 1.2 | 1.3. Default: 1.3&#xA;  -s upscale           The final upsampling scale of the image. Default: 2&#xA;  -bg_upsampler        background upsampler. Default: realesrgan&#xA;  -bg_tile             Tile size for background sampler, 0 for no tile during testing. Default: 400&#xA;  -suffix              Suffix of the restored faces&#xA;  -only_center_face    Only restore the center face&#xA;  -aligned             Input are aligned faces&#xA;  -ext                 Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to use the original model in our paper, please see &lt;a href=&#34;https://raw.githubusercontent.com/TencentARC/GFPGAN/master/PaperModel.md&#34;&gt;PaperModel.md&lt;/a&gt; for installation and inference.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;üè∞&lt;/span&gt; Model Zoo&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Version&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Model Name&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;V1.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth&#34;&gt;GFPGANv1.3.pth&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Based on V1.2; &lt;strong&gt;more natural&lt;/strong&gt; restoration results; better results on very low-quality / high-quality inputs.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;V1.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth&#34;&gt;GFPGANCleanv1-NoCE-C2.pth&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No colorization; no CUDA extensions are required. Trained with more data with pre-processing.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;V1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/TencentARC/GFPGAN/releases/download/v0.1.0/GFPGANv1.pth&#34;&gt;GFPGANv1.pth&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;The paper model, with colorization.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The comparisons are in &lt;a href=&#34;https://raw.githubusercontent.com/TencentARC/GFPGAN/master/Comparisons.md&#34;&gt;Comparisons.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Note that V1.3 is not always better than V1.2. You may need to select different models based on your purpose and inputs.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Version&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Strengths&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Weaknesses&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;V1.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úì natural outputs&lt;br&gt; ‚úìbetter results on very low-quality inputs &lt;br&gt; ‚úì work on relatively high-quality inputs &lt;br&gt;‚úì can have repeated (twice) restorations&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úó not very sharp &lt;br&gt; ‚úó have a slight change on identity&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;V1.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úì sharper output &lt;br&gt; ‚úì with beauty makeup&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úó some outputs are unnatural&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;You can find &lt;strong&gt;more models (such as the discriminators)&lt;/strong&gt; here: [&lt;a href=&#34;https://drive.google.com/drive/folders/17rLiFzcUMoQuhLnptDsKolegHWwJOnHu?usp=sharing&#34;&gt;Google Drive&lt;/a&gt;], OR [&lt;a href=&#34;https://share.weiyun.com/ShYoCCoc&#34;&gt;Tencent Cloud ËÖæËÆØÂæÆ‰∫ë&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;üíª&lt;/span&gt; Training&lt;/h2&gt; &#xA;&lt;p&gt;We provide the training codes for GFPGAN (used in our paper). &lt;br&gt; You could improve it according to your own needs.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Tips&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;More high quality faces can improve the restoration quality.&lt;/li&gt; &#xA; &lt;li&gt;You may need to perform some pre-processing, such as beauty makeup.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;Procedures&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;(You can try a simple version ( &lt;code&gt;options/train_gfpgan_v1_simple.yml&lt;/code&gt;) that does not require face component landmarks.)&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Dataset preparation: &lt;a href=&#34;https://github.com/NVlabs/ffhq-dataset&#34;&gt;FFHQ&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Download pre-trained models and other data. Put them in the &lt;code&gt;experiments/pretrained_models&lt;/code&gt; folder.&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/TencentARC/GFPGAN/releases/download/v0.1.0/StyleGAN2_512_Cmul1_FFHQ_B12G4_scratch_800k.pth&#34;&gt;Pre-trained StyleGAN2 model: StyleGAN2_512_Cmul1_FFHQ_B12G4_scratch_800k.pth&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/TencentARC/GFPGAN/releases/download/v0.1.0/FFHQ_eye_mouth_landmarks_512.pth&#34;&gt;Component locations of FFHQ: FFHQ_eye_mouth_landmarks_512.pth&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/TencentARC/GFPGAN/releases/download/v0.1.0/arcface_resnet18.pth&#34;&gt;A simple ArcFace model: arcface_resnet18.pth&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Modify the configuration file &lt;code&gt;options/train_gfpgan_v1.yml&lt;/code&gt; accordingly.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Training&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;python -m torch.distributed.launch --nproc_per_node=4 --master_port=22021 gfpgan/train.py -opt options/train_gfpgan_v1.yml --launcher pytorch&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;&lt;span&gt;üìú&lt;/span&gt; License and Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;GFPGAN is released under Apache License Version 2.0.&lt;/p&gt; &#xA;&lt;h2&gt;BibTeX&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@InProceedings{wang2021gfpgan,&#xA;    author = {Xintao Wang and Yu Li and Honglun Zhang and Ying Shan},&#xA;    title = {Towards Real-World Blind Face Restoration with Generative Facial Prior},&#xA;    booktitle={The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},&#xA;    year = {2021}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;span&gt;üìß&lt;/span&gt; Contact&lt;/h2&gt; &#xA;&lt;p&gt;If you have any question, please email &lt;code&gt;xintao.wang@outlook.com&lt;/code&gt; or &lt;code&gt;xintaowang@tencent.com&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Datalux/Osintgram</title>
    <updated>2022-08-07T02:00:10Z</updated>
    <id>tag:github.com,2022-08-07:/Datalux/Osintgram</id>
    <link href="https://github.com/Datalux/Osintgram" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Osintgram is a OSINT tool on Instagram. It offers an interactive shell to perform analysis on Instagram account of any users by its nickname&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Osintgram üîéüì∏&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Datalux/Osintgram/releases/tag/1.3&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/version-1.3-green&#34; alt=&#34;version-1.3&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://img.shields.io/badge/license-GPLv3-blue&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-GPLv3-blue&#34; alt=&#34;GPLv3&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://img.shields.io/badge/language-Python3-red&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/language-Python3-red&#34; alt=&#34;Python3&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://t.me/osintgram&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Telegram-Channel-blue.svg?sanitize=true&#34; alt=&#34;Telegram&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://img.shields.io/badge/Docker-Supported-blue&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Docker-Supported-blue&#34; alt=&#34;Docker&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Osintgram is a &lt;strong&gt;OSINT&lt;/strong&gt; tool on Instagram to collect, analyze, and run reconnaissance.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/Datalux/Osintgram/master/.img/carbon.png&#34; width=&#34;900&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Disclaimer: &lt;strong&gt;FOR EDUCATIONAL PURPOSE ONLY! The contributors do not assume any responsibility for the use of this tool.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Warning: It is advisable to &lt;strong&gt;not&lt;/strong&gt; use your own/primary account when using this tool.&lt;/p&gt; &#xA;&lt;h2&gt;Tools and Commands üß∞&lt;/h2&gt; &#xA;&lt;p&gt;Osintgram offers an interactive shell to perform analysis on Instagram account of any users by its nickname. You can get:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;- addrs           Get all registered addressed by target photos&#xA;- captions        Get user&#39;s photos captions&#xA;- comments        Get total comments of target&#39;s posts&#xA;- followers       Get target followers&#xA;- followings      Get users followed by target&#xA;- fwersemail      Get email of target followers&#xA;- fwingsemail     Get email of users followed by target&#xA;- fwersnumber     Get phone number of target followers&#xA;- fwingsnumber    Get phone number of users followed by target&#xA;- hashtags        Get hashtags used by target&#xA;- info            Get target info&#xA;- likes           Get total likes of target&#39;s posts&#xA;- mediatype       Get user&#39;s posts type (photo or video)&#xA;- photodes        Get description of target&#39;s photos&#xA;- photos          Download user&#39;s photos in output folder&#xA;- propic          Download user&#39;s profile picture&#xA;- stories         Download user&#39;s stories  &#xA;- tagged          Get list of users tagged by target&#xA;- wcommented      Get a list of user who commented target&#39;s photos&#xA;- wtagged         Get a list of user who tagged target&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can find detailed commands usage &lt;a href=&#34;https://raw.githubusercontent.com/Datalux/Osintgram/master/doc/COMMANDS.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Datalux/Osintgram/releases/tag/1.3&#34;&gt;&lt;strong&gt;Latest version&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/Datalux/Osintgram/master/doc/COMMANDS.md&#34;&gt;Commands&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/Datalux/Osintgram/master/doc/CHANGELOG.md&#34;&gt;CHANGELOG&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Can I access the contents of a private profile?&lt;/strong&gt; No, you cannot get information on private profiles. You can only get information from a public profile or a profile you follow. The tools that claim to be successful are scams!&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;What is and how I can bypass the &lt;code&gt;challenge_required&lt;/code&gt; error?&lt;/strong&gt; The &lt;code&gt;challenge_required&lt;/code&gt; error means that Instagram notice a suspicious behavior on your profile, so needs to check if you are a real person or a bot. To avoid this you should follow the suggested link and complete the required operation (insert a code, confirm email, etc)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Installation ‚öôÔ∏è&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Fork/Clone/Download this repo&lt;/p&gt; &lt;p&gt;&lt;code&gt;git clone https://github.com/Datalux/Osintgram.git&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Navigate to the directory&lt;/p&gt; &lt;p&gt;&lt;code&gt;cd Osintgram&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create a virtual environment for this project&lt;/p&gt; &lt;p&gt;&lt;code&gt;python3 -m venv venv&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Load the virtual environment&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;On Windows Powershell: &lt;code&gt;.\venv\Scripts\activate.ps1&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;On Linux and Git Bash: &lt;code&gt;source venv/bin/activate&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open the &lt;code&gt;credentials.ini&lt;/code&gt; file in the &lt;code&gt;config&lt;/code&gt; folder and write your Instagram account username and password in the corresponding fields&lt;/p&gt; &lt;p&gt;Alternatively, you can run the &lt;code&gt;make setup&lt;/code&gt; command to populate this file for you.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run the main.py script in one of two ways&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;As an interactive prompt &lt;code&gt;python3 main.py &amp;lt;target username&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Or execute your command straight away &lt;code&gt;python3 main.py &amp;lt;target username&amp;gt; --command &amp;lt;command&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Docker Quick Start üê≥&lt;/h2&gt; &#xA;&lt;p&gt;This section will explain how you can quickly use this image with &lt;code&gt;Docker&lt;/code&gt; or &lt;code&gt;Docker-compose&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;p&gt;Before you can use either &lt;code&gt;Docker&lt;/code&gt; or &lt;code&gt;Docker-compose&lt;/code&gt;, please ensure you do have the following prerequisites met.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt; installed - &lt;a href=&#34;https://docs.docker.com/get-docker/&#34;&gt;link&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Docker-composed&lt;/strong&gt; installed (if using Docker-compose) - &lt;a href=&#34;https://docs.docker.com/compose/install/&#34;&gt;link&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Credentials&lt;/strong&gt; configured - This can be done manually or by running the &lt;code&gt;make setup&lt;/code&gt; command from the root of this repo&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Your container will fail if you do not do step #3 and configure your credentials&lt;/p&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;If docker is installed you can build an image and run this as a container.&lt;/p&gt; &#xA;&lt;p&gt;Build:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker build -t osintgram .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --rm -it -v &#34;$PWD/output:/home/osintgram/output&#34; osintgram &amp;lt;target&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The &lt;code&gt;&amp;lt;target&amp;gt;&lt;/code&gt; is the Instagram account you wish to use as your target for recon.&lt;/li&gt; &#xA; &lt;li&gt;The required &lt;code&gt;-i&lt;/code&gt; flag enables an interactive terminal to use commands within the container. &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/run/#assign-name-and-allocate-pseudo-tty---name--it&#34;&gt;docs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The required &lt;code&gt;-v&lt;/code&gt; flag mounts a volume between your local filesystem and the container to save to the &lt;code&gt;./output/&lt;/code&gt; folder. &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/run/#mount-volume--v---read-only&#34;&gt;docs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The optional &lt;code&gt;--rm&lt;/code&gt; flag removes the container filesystem on completion to prevent cruft build-up. &lt;a href=&#34;https://docs.docker.com/engine/reference/run/#clean-up---rm&#34;&gt;docs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The optional &lt;code&gt;-t&lt;/code&gt; flag allocates a pseudo-TTY which allows colored output. &lt;a href=&#34;https://docs.docker.com/engine/reference/run/#foreground&#34;&gt;docs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Using &lt;code&gt;docker-compose&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;You can use the &lt;code&gt;docker-compose.yml&lt;/code&gt; file this single command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose run osintgram &amp;lt;target&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Where &lt;code&gt;target&lt;/code&gt; is the Instagram target for recon.&lt;/p&gt; &#xA;&lt;p&gt;Alternatively you may run &lt;code&gt;docker-compose&lt;/code&gt; with the &lt;code&gt;Makefile&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;make run&lt;/code&gt; - Builds and Runs with compose. Prompts for a &lt;code&gt;target&lt;/code&gt; before running.&lt;/p&gt; &#xA;&lt;h3&gt;Makefile (easy mode)&lt;/h3&gt; &#xA;&lt;p&gt;For ease of use with Docker-compose, a &lt;code&gt;Makefile&lt;/code&gt; has been provided.&lt;/p&gt; &#xA;&lt;p&gt;Here is a sample work flow to spin up a container and run &lt;code&gt;osintgram&lt;/code&gt; with just two commands!&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;make setup&lt;/code&gt; - Sets up your Instagram credentials&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;make run&lt;/code&gt; - Builds and Runs a osintgram container and prompts for a target&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Sample workflow for development:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;make setup&lt;/code&gt; - Sets up your Instagram credentials&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;make build-run-testing&lt;/code&gt; - Builds an Runs a container without invoking the &lt;code&gt;main.py&lt;/code&gt; script. Useful for an &lt;code&gt;it&lt;/code&gt; Docker session for development&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;make cleanup-testing&lt;/code&gt; - Cleans up the testing container created from &lt;code&gt;build-run-testing&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Development version üíª&lt;/h2&gt; &#xA;&lt;p&gt;To use the development version with the latest feature and fixes just switch to &lt;code&gt;development&lt;/code&gt; branch using Git:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;git checkout development&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;and update to last version using:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;git pull origin development&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Updating ‚¨áÔ∏è&lt;/h2&gt; &#xA;&lt;p&gt;To update Osintgram with the stable release just pull the latest commit using Git.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Make sure you are in the master branch running: &lt;code&gt;git checkout master&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Download the latest version: &lt;code&gt;git pull origin master&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Contributing üí°&lt;/h2&gt; &#xA;&lt;p&gt;You can propose a feature request opening an issue or a pull request.&lt;/p&gt; &#xA;&lt;p&gt;Here is a list of Osintgram&#39;s contributors:&lt;/p&gt; &#xA;&lt;a href=&#34;https://github.com/Datalux/Osintgram/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contributors-img.web.app/image?repo=Datalux/Osintgram&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;External library üîó&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ping/instagram_private_api&#34;&gt;Instagram API&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>tobymao/sqlglot</title>
    <updated>2022-08-07T02:00:10Z</updated>
    <id>tag:github.com,2022-08-07:/tobymao/sqlglot</id>
    <link href="https://github.com/tobymao/sqlglot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Python SQL Parser and Transpiler&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SQLGlot&lt;/h1&gt; &#xA;&lt;p&gt;SQLGlot is a no dependency Python SQL parser, transpiler, and optimizer. It can be used to format SQL or translate between different dialects like &lt;a href=&#34;https://duckdb.org/&#34;&gt;DuckDB&lt;/a&gt;, &lt;a href=&#34;https://prestodb.io/&#34;&gt;Presto&lt;/a&gt;, &lt;a href=&#34;https://spark.apache.org/&#34;&gt;Spark&lt;/a&gt;, and &lt;a href=&#34;https://cloud.google.com/bigquery/&#34;&gt;BigQuery&lt;/a&gt;. It aims to read a wide variety of SQL inputs and output syntatically correct SQL in the targeted dialects.&lt;/p&gt; &#xA;&lt;p&gt;It is a very comprehensive generic SQL parser with a robust &lt;a href=&#34;https://raw.githubusercontent.com/tobymao/sqlglot/main/tests&#34;&gt;test suite&lt;/a&gt;. It is also quite &lt;a href=&#34;https://raw.githubusercontent.com/tobymao/sqlglot/main/#benchmarks&#34;&gt;performant&lt;/a&gt; while being written purely in Python.&lt;/p&gt; &#xA;&lt;p&gt;You can easily &lt;a href=&#34;https://raw.githubusercontent.com/tobymao/sqlglot/main/#custom-dialects&#34;&gt;customize&lt;/a&gt; the parser, &lt;a href=&#34;https://raw.githubusercontent.com/tobymao/sqlglot/main/#metadata&#34;&gt;analyze&lt;/a&gt; queries, traverse expression trees, and programmatically &lt;a href=&#34;https://raw.githubusercontent.com/tobymao/sqlglot/main/#build-and-modify-sql&#34;&gt;build&lt;/a&gt; SQL.&lt;/p&gt; &#xA;&lt;p&gt;Syntax &lt;a href=&#34;https://raw.githubusercontent.com/tobymao/sqlglot/main/#parser-errors&#34;&gt;errors&lt;/a&gt; are highlighted and dialect incompatibilities can warn or raise depending on configurations.&lt;/p&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;From PyPI&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip3 install sqlglot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or with a local checkout&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip3 install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;Easily translate from one dialect to another. For example, date/time functions vary from dialects and can be hard to deal with.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import sqlglot&#xA;sqlglot.transpile(&#34;SELECT EPOCH_MS(1618088028295)&#34;, read=&#39;duckdb&#39;, write=&#39;hive&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT TO_UTC_TIMESTAMP(FROM_UNIXTIME(1618088028295 / 1000, &#39;yyyy-MM-dd HH:mm:ss&#39;), &#39;UTC&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;SQLGlot can even translate custom time formats.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import sqlglot&#xA;sqlglot.transpile(&#34;SELECT STRFTIME(x, &#39;%y-%-m-%S&#39;)&#34;, read=&#39;duckdb&#39;, write=&#39;hive&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT DATE_FORMAT(x, &#39;yy-M-ss&#39;)&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Formatting and Transpiling&lt;/h2&gt; &#xA;&lt;p&gt;Read in a SQL statement with a CTE and CASTING to a REAL and then transpiling to Spark.&lt;/p&gt; &#xA;&lt;p&gt;Spark uses backticks as identifiers and the REAL type is transpiled to FLOAT.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import sqlglot&#xA;&#xA;sql = &#34;&#34;&#34;WITH baz AS (SELECT a, c FROM foo WHERE a = 1) SELECT f.a, b.b, baz.c, CAST(&#34;b&#34;.&#34;a&#34; AS REAL) d FROM foo f JOIN bar b ON f.a = b.a LEFT JOIN baz ON f.a = baz.a&#34;&#34;&#34;&#xA;sqlglot.transpile(sql, write=&#39;spark&#39;, identify=True, pretty=True)[0]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;WITH `baz` AS (&#xA;  SELECT&#xA;    `a`,&#xA;    `c`&#xA;  FROM `foo`&#xA;  WHERE&#xA;    `a` = 1&#xA;)&#xA;SELECT&#xA;  `f`.`a`,&#xA;  `b`.`b`,&#xA;  `baz`.`c`,&#xA;  CAST(`b`.`a` AS FLOAT) AS `d`&#xA;FROM `foo` AS `f`&#xA;JOIN `bar` AS `b`&#xA;  ON `f`.`a` = `b`.`a`&#xA;LEFT JOIN `baz`&#xA;  ON `f`.`a` = `baz`.`a`&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Metadata&lt;/h2&gt; &#xA;&lt;p&gt;You can explore SQL with expression helpers to do things like find columns and tables.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sqlglot import parse_one, exp&#xA;&#xA;# print all column references (a and b)&#xA;for column in parse_one(&#34;SELECT a, b + 1 AS c FROM d&#34;).find_all(exp.Column):&#xA;  print(column.alias_or_name)&#xA;&#xA;# find all projections in select statements (a and c)&#xA;for select in parse_one(&#34;SELECT a, b + 1 AS c FROM d&#34;).find_all(exp.Select):&#xA;  for projection in select.expressions:&#xA;    print(projection.alias_or_name)&#xA;&#xA;# find all tables (x, y, z)&#xA;for table in parse_one(&#34;SELECT * FROM x JOIN y JOIN z&#34;).find_all(exp.Table):&#xA;  print(table.name)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Parser Errors&lt;/h2&gt; &#xA;&lt;p&gt;A syntax error will result in a parser error.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;transpile(&#34;SELECT foo( FROM bar&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;sqlglot.errors.ParseError: Expecting ). Line 1, Col: 13. select foo( &lt;strong&gt;FROM&lt;/strong&gt; bar&lt;/p&gt; &#xA;&lt;h2&gt;Unsupported Errors&lt;/h2&gt; &#xA;&lt;p&gt;Presto APPROX_DISTINCT supports the accuracy argument which is not supported in Spark.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;transpile(&#xA;    &#39;SELECT APPROX_DISTINCT(a, 0.1) FROM foo&#39;,&#xA;    read=&#39;presto&#39;,&#xA;    write=&#39;spark&#39;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;WARNING:root:APPROX_COUNT_DISTINCT does not support accuracy&#xA;&#xA;SELECT APPROX_COUNT_DISTINCT(a) FROM foo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Build and Modify SQL&lt;/h2&gt; &#xA;&lt;p&gt;SQLGlot supports incrementally building sql expressions.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sqlglot import select, condition&#xA;&#xA;where = condition(&#34;x=1&#34;).and_(&#34;y=1&#34;)&#xA;select(&#34;*&#34;).from_(&#34;y&#34;).where(where).sql()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Which outputs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT * FROM y WHERE x = 1 AND y = 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also modify a parsed tree:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sqlglot import parse_one&#xA;&#xA;parse_one(&#34;SELECT x FROM y&#34;).from_(&#34;z&#34;).sql()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Which outputs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT x FROM y, z&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There is also a way to recursively transform the parsed tree by applying a mapping function to each tree node:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sqlglot import exp, parse_one&#xA;&#xA;expression_tree = parse_one(&#34;SELECT a FROM x&#34;)&#xA;&#xA;def transformer(node):&#xA;    if isinstance(node, exp.Column) and node.name == &#34;a&#34;:&#xA;        return parse_one(&#34;FUN(a)&#34;)&#xA;    return node&#xA;&#xA;transformed_tree = expression_tree.transform(transformer)&#xA;transformed_tree.sql()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Which outputs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT FUN(a) FROM x&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;SQL Optimizer&lt;/h2&gt; &#xA;&lt;p&gt;SQLGlot can rewrite queries into an &#34;optimized&#34; form. It performs a variety of &lt;a href=&#34;https://raw.githubusercontent.com/tobymao/sqlglot/main/sqlglot/optimizer/optimizer.py&#34;&gt;techniques&lt;/a&gt; to create a new canonical AST. This AST can be used to standaradize queries or provide the foundations for implementing an actual engine.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import sqlglot&#xA;from sqlglot.optimizer import optimize&#xA;&#xA;&amp;gt;&amp;gt;&amp;gt;&#xA;optimize(&#xA;    sqlglot.parse_one(&#34;&#34;&#34;&#xA;    SELECT A OR (B OR (C AND D))&#xA;    FROM x&#xA;    WHERE Z = date &#39;2021-01-01&#39; + INTERVAL &#39;1&#39; month OR 1 = 0&#xA;    &#34;&#34;&#34;),&#xA;    schema={&#34;x&#34;: {&#34;A&#34;: &#34;INT&#34;, &#34;B&#34;: &#34;INT&#34;, &#34;C&#34;: &#34;INT&#34;, &#34;D&#34;: &#34;INT&#34;, &#34;Z&#34;: &#34;STRING&#34;}}&#xA;).sql(pretty=True)&#xA;&#xA;&#34;&#34;&#34;&#xA;SELECT&#xA;  (&#xA;    &#34;x&#34;.&#34;A&#34;&#xA;    OR &#34;x&#34;.&#34;B&#34;&#xA;    OR &#34;x&#34;.&#34;C&#34;&#xA;  )&#xA;  AND (&#xA;    &#34;x&#34;.&#34;A&#34;&#xA;    OR &#34;x&#34;.&#34;B&#34;&#xA;    OR &#34;x&#34;.&#34;D&#34;&#xA;  ) AS &#34;_col_0&#34;&#xA;FROM &#34;x&#34; AS &#34;x&#34;&#xA;WHERE&#xA;  &#34;x&#34;.&#34;Z&#34; = CAST(&#39;2021-02-01&#39; AS DATE)&#xA;&#34;&#34;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;SQL Annotations&lt;/h2&gt; &#xA;&lt;p&gt;SQLGlot supports annotations in the sql expression. This is an experimental feature that is not part of any of the SQL standards but it can be useful when needing to annotate what a selected field is supposed to be. Below is an example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT&#xA;  user #primary_key,&#xA;  country&#xA;FROM users&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;AST Introspection&lt;/h2&gt; &#xA;&lt;p&gt;You can see the AST version of the sql by calling repr.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sqlglot import parse_one&#xA;repr(parse_one(&#34;SELECT a + 1 AS z&#34;))&#xA;&#xA;(SELECT expressions:&#xA;  (ALIAS this:&#xA;    (ADD this:&#xA;      (COLUMN this:&#xA;        (IDENTIFIER this: a, quoted: False)), expression:&#xA;      (LITERAL this: 1, is_string: False)), alias:&#xA;    (IDENTIFIER this: z, quoted: False)))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;AST Diff&lt;/h2&gt; &#xA;&lt;p&gt;SQLGlot can calculate the difference between two expressions and output changes in a form of a sequence of actions needed to transform a source expression into a target one.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sqlglot import diff, parse_one&#xA;diff(parse_one(&#34;SELECT a + b, c, d&#34;), parse_one(&#34;SELECT c, a - b, d&#34;))&#xA;&#xA;[&#xA;  Remove(expression=(ADD this:&#xA;    (COLUMN this:&#xA;      (IDENTIFIER this: a, quoted: False)), expression:&#xA;    (COLUMN this:&#xA;      (IDENTIFIER this: b, quoted: False)))),&#xA;  Insert(expression=(SUB this:&#xA;    (COLUMN this:&#xA;      (IDENTIFIER this: a, quoted: False)), expression:&#xA;    (COLUMN this:&#xA;      (IDENTIFIER this: b, quoted: False)))),&#xA;  Move(expression=(COLUMN this:&#xA;    (IDENTIFIER this: c, quoted: False))),&#xA;  Keep(source=(IDENTIFIER this: b, quoted: False), target=(IDENTIFIER this: b, quoted: False)),&#xA;  ...&#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Custom Dialects&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tobymao/sqlglot/main/sqlglot/dialects&#34;&gt;Dialects&lt;/a&gt; can be added by subclassing Dialect.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sqlglot import exp&#xA;from sqlglot.dialects.dialect import Dialect&#xA;from sqlglot.generator import Generator&#xA;from sqlglot.tokens import Tokenizer, TokenType&#xA;&#xA;&#xA;class Custom(Dialect):&#xA;    identifier = &#34;`&#34;&#xA;&#xA;    class Tokenizer(Tokenizer):&#xA;        QUOTES = [&#34;&#39;&#34;, &#39;&#34;&#39;]&#xA;&#xA;        KEYWORDS = {&#xA;            **Tokenizer.KEYWORDS,&#xA;            &#34;INT64&#34;: TokenType.BIGINT,&#xA;            &#34;FLOAT64&#34;: TokenType.DOUBLE,&#xA;        }&#xA;&#xA;    class Generator(Generator):&#xA;        TRANSFORMS = {exp.Array: lambda self, e: f&#34;[{self.expressions(e)}]&#34;}&#xA;&#xA;        TYPE_MAPPING = {&#xA;            exp.DataType.Type.TINYINT: &#34;INT64&#34;,&#xA;            exp.DataType.Type.SMALLINT: &#34;INT64&#34;,&#xA;            exp.DataType.Type.INT: &#34;INT64&#34;,&#xA;            exp.DataType.Type.BIGINT: &#34;INT64&#34;,&#xA;            exp.DataType.Type.DECIMAL: &#34;NUMERIC&#34;,&#xA;            exp.DataType.Type.FLOAT: &#34;FLOAT64&#34;,&#xA;            exp.DataType.Type.DOUBLE: &#34;FLOAT64&#34;,&#xA;            exp.DataType.Type.BOOLEAN: &#34;BOOL&#34;,&#xA;            exp.DataType.Type.TEXT: &#34;STRING&#34;,&#xA;        }&#xA;&#xA;&#xA;Dialects[&#34;custom&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Benchmarks&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tobymao/sqlglot/main/benchmarks&#34;&gt;Benchmarks&lt;/a&gt; run on Python 3.10.5 in seconds.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Query&lt;/th&gt; &#xA;   &lt;th&gt;sqlglot&lt;/th&gt; &#xA;   &lt;th&gt;sqltree&lt;/th&gt; &#xA;   &lt;th&gt;sqlparse&lt;/th&gt; &#xA;   &lt;th&gt;moz_sql_parser&lt;/th&gt; &#xA;   &lt;th&gt;sqloxide&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;tpch&lt;/td&gt; &#xA;   &lt;td&gt;0.01192 (1.0)&lt;/td&gt; &#xA;   &lt;td&gt;0.01176 (0.986)&lt;/td&gt; &#xA;   &lt;td&gt;0.04785 (4.012)&lt;/td&gt; &#xA;   &lt;td&gt;0.07195 (6.033)&lt;/td&gt; &#xA;   &lt;td&gt;0.00109 (0.092)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;short&lt;/td&gt; &#xA;   &lt;td&gt;0.00096 (1.0)&lt;/td&gt; &#xA;   &lt;td&gt;0.00092 (0.962)&lt;/td&gt; &#xA;   &lt;td&gt;0.00317 (3.305)&lt;/td&gt; &#xA;   &lt;td&gt;0.00482 (5.017)&lt;/td&gt; &#xA;   &lt;td&gt;6.69349 (0.069)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;long&lt;/td&gt; &#xA;   &lt;td&gt;0.01142 (1.0)&lt;/td&gt; &#xA;   &lt;td&gt;0.01022 (0.895)&lt;/td&gt; &#xA;   &lt;td&gt;0.04224 (3.698)&lt;/td&gt; &#xA;   &lt;td&gt;0.06460 (5.655)&lt;/td&gt; &#xA;   &lt;td&gt;0.00091 (0.080)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;crazy&lt;/td&gt; &#xA;   &lt;td&gt;0.04056 (1.0)&lt;/td&gt; &#xA;   &lt;td&gt;0.03593 (0.885)&lt;/td&gt; &#xA;   &lt;td&gt;11.1451 (274.7)&lt;/td&gt; &#xA;   &lt;td&gt;1.01040 (24.91)&lt;/td&gt; &#xA;   &lt;td&gt;0.00550 (0.135)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Run Tests and Lint&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;./format_code.sh&#xA;./run_checks.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Optional Dependencies&lt;/h2&gt; &#xA;&lt;p&gt;SQLGlot uses &lt;a href=&#34;https://github.com/dateutil/dateutil&#34;&gt;dateutil&lt;/a&gt; to simplify literal timedelta expressions. The optimizer will not simplify expressions like&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;x + interval &#39;1&#39; month&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;if the module cannot be found.&lt;/p&gt;</summary>
  </entry>
</feed>