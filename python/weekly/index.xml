<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-03T01:56:11Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>run-llama/rags</title>
    <updated>2023-12-03T01:56:11Z</updated>
    <id>tag:github.com,2023-12-03:/run-llama/rags</id>
    <link href="https://github.com/run-llama/rags" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Build ChatGPT over your data, all with natural language&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RAGs&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/run-llama/rags/assets/4858925/a6204550-b3d1-4cde-b308-8d944e5d3058&#34;&gt;https://github.com/run-llama/rags/assets/4858925/a6204550-b3d1-4cde-b308-8d944e5d3058&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;RAGs is a Streamlit app that lets you create a RAG pipeline from a data source using natural language.&lt;/p&gt; &#xA;&lt;p&gt;You get to do the following:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Describe your task (e.g. &#34;load this web page&#34;) and the parameters you want from your RAG systems (e.g. &#34;i want to retrieve X number of docs&#34;)&lt;/li&gt; &#xA; &lt;li&gt;Go into the config view and view/alter generated parameters (top-k, summarization, etc.) as needed.&lt;/li&gt; &#xA; &lt;li&gt;Query the RAG agent over data with your questions.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;This project is inspired by &lt;a href=&#34;https://openai.com/blog/introducing-gpts&#34;&gt;GPTs&lt;/a&gt;, launched by OpenAI.&lt;/p&gt; &#xA;&lt;h2&gt;Installation and Setup&lt;/h2&gt; &#xA;&lt;p&gt;Clone this project, go into the &lt;code&gt;rags&lt;/code&gt; project folder. We recommend creating a virtual env for dependencies (&lt;code&gt;python3 -m venv .venv&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;poetry install --with dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, we use OpenAI for both the builder agent as well as the generated RAG agent. Add &lt;code&gt;.streamlit/secrets.toml&lt;/code&gt; in the home folder.&lt;/p&gt; &#xA;&lt;p&gt;Then put the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;openai_key = &#34;&amp;lt;openai_key&amp;gt;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then run the app from the &#34;home page&#34; file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;streamlit run 1_🏠_Home.py&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Detailed Overview&lt;/h2&gt; &#xA;&lt;p&gt;The app contains the following sections, corresponding to the steps listed above.&lt;/p&gt; &#xA;&lt;h3&gt;1. 🏠 Home Page&lt;/h3&gt; &#xA;&lt;p&gt;This is the section where you build a RAG pipeline by instructing the &#34;builder agent&#34;. Typically to setup a RAG pipeline you need the following components:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Describe the dataset. Currently we support either &lt;strong&gt;a single local file&lt;/strong&gt; or a &lt;strong&gt;web page&lt;/strong&gt;. We&#39;re open to suggestions here!&lt;/li&gt; &#xA; &lt;li&gt;Describe the task. Concretely this description will be used to initialize the &#34;system prompt&#34; of the LLM powering the RAG pipeline.&lt;/li&gt; &#xA; &lt;li&gt;Define the typical parameters for a RAG setup. See the below section for the list of parameters.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;2. ⚙️ RAG Config&lt;/h3&gt; &#xA;&lt;p&gt;This section contains the RAG parameters, generated by the &#34;builder agent&#34; in the previous section. In this section, you have a UI showcasing the generated parameters and have full freedom to manually edit/change them as necessary.&lt;/p&gt; &#xA;&lt;p&gt;Currently the set of parameters is as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;System Prompt&lt;/li&gt; &#xA; &lt;li&gt;Include Summarization: whether to also add a summarization tool (instead of only doing top-k retrieval.)&lt;/li&gt; &#xA; &lt;li&gt;Top-K&lt;/li&gt; &#xA; &lt;li&gt;Chunk Size&lt;/li&gt; &#xA; &lt;li&gt;Embed Model&lt;/li&gt; &#xA; &lt;li&gt;LLM&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you manually change parameters, you can press the &#34;Update Agent&#34; button in order to update the agent.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-{tip}&#34;&gt;If you don&#39;t see the `Update Agent` button, that&#39;s because you haven&#39;t created the agent yet. Please go to the previous &#34;Home&#34; page and complete the setup process.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We can always add more parameters to make this more &#34;advanced&#34; 🛠️, but thought this would be a good place to start.&lt;/p&gt; &#xA;&lt;h3&gt;3. Generated RAG Agent&lt;/h3&gt; &#xA;&lt;p&gt;Once your RAG agent is created, you have access to this page.&lt;/p&gt; &#xA;&lt;p&gt;This is a standard chatbot interface where you can query the RAG agent and it will answer questions over your data.&lt;/p&gt; &#xA;&lt;p&gt;It will be able to pick the right RAG tools (either top-k vector search or optionally summarization) in order to fulfill the query.&lt;/p&gt; &#xA;&lt;h2&gt;Supported LLMs and Embeddings&lt;/h2&gt; &#xA;&lt;h3&gt;Builder Agent&lt;/h3&gt; &#xA;&lt;p&gt;By default the builder agent uses OpenAI. This is defined in the &lt;code&gt;builder_config.py&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;p&gt;You can customize this to whatever LLM you want (an example is provided for Anthropic).&lt;/p&gt; &#xA;&lt;p&gt;Note that GPT-4 variants will give the most reliable results in terms of actually constructing an agent (we couldn&#39;t get Claude to work).&lt;/p&gt; &#xA;&lt;h3&gt;Generated RAG Agent&lt;/h3&gt; &#xA;&lt;p&gt;You can set the configuration either through natural language or manually for both the embedding model and LLM.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;LLM&lt;/strong&gt;: We support the following LLMs, but you need to explicitly specify the ID to the builder agent. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;OpenAI: ID is &#34;openai:&amp;lt;model_name&amp;gt;&#34; e.g. &#34;openai:gpt-4-1106-preview&#34;&lt;/li&gt; &#xA;   &lt;li&gt;Anthropic: ID is &#34;anthropic:&amp;lt;model_name&amp;gt;&#34; e.g. &#34;anthropic:claude-2&#34;&lt;/li&gt; &#xA;   &lt;li&gt;Replicate: ID is &#34;replicate:&amp;lt;model_name&amp;gt;&#34;&lt;/li&gt; &#xA;   &lt;li&gt;HuggingFace: ID is &#34;local:&amp;lt;model_name&amp;gt;&#34; e.g. &#34;local:BAAI/bge-small-en&#34;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Embeddings&lt;/strong&gt;: Supports text-embedding-ada-002 by default, but also supports Hugging Face models. To use a hugging face model simply prepend with local, e.g. local:BAAI/bge-small-en.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;p&gt;Running into issues? Please file a GitHub issue or join our &lt;a href=&#34;https://discord.gg/dGcwcsnxhU&#34;&gt;Discord&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;This app was built with &lt;a href=&#34;https://github.com/run-llama/llama_index&#34;&gt;LlamaIndex Python&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;See our launch blog post &lt;a href=&#34;https://blog.llamaindex.ai/introducing-rags-your-personalized-chatgpt-experience-over-your-data-2b9d140769b1&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>srbhr/Resume-Matcher</title>
    <updated>2023-12-03T01:56:11Z</updated>
    <id>tag:github.com,2023-12-03:/srbhr/Resume-Matcher</id>
    <link href="https://github.com/srbhr/Resume-Matcher" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Resume Matcher is an open source, free tool to improve your resume. It works by using language models to compare and rank resumes with job descriptions.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://www.resumematcher.fyi&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/Assets/img/header_image.png&#34; alt=&#34;Resume Matcher&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;Resume Matcher&lt;/h1&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://dsc.gg/resume-matcher&#34;&gt;𝙹𝚘𝚒𝚗 𝙳𝚒𝚜𝚌𝚘𝚛𝚍&lt;/a&gt; ✦ &lt;a href=&#34;https://resumematcher.fyi&#34;&gt;𝚆𝚎𝚋𝚜𝚒𝚝𝚎&lt;/a&gt; ✦ &lt;a href=&#34;https://resume-matcher.streamlit.app/&#34;&gt;𝙳𝚎𝚖𝚘&lt;/a&gt; ✦ &lt;a href=&#34;https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#how-to-install&#34;&gt;𝙷𝚘𝚠 𝚝𝚘 𝙸𝚗𝚜𝚝𝚊𝚕𝚕 &lt;/a&gt; ✦ &lt;a href=&#34;https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#join-us-contribute&#34;&gt;𝙲𝚘𝚗𝚝𝚛𝚒𝚋𝚞𝚝𝚎&lt;/a&gt; ✦ &lt;a href=&#34;https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#please-support-the-development-by-donating&#34;&gt;𝙳𝚘𝚗𝚊𝚝𝚎&lt;/a&gt; ✦ &lt;a href=&#34;https://twitter.com/_srbhr_&#34;&gt;𝚃𝚠𝚒𝚝𝚝𝚎𝚛&lt;/a&gt;&lt;/p&gt; &#xA; &lt;hr&gt; &#xA; &lt;h3&gt;Resume Matcher is an AI Based Free &amp;amp; Open Source Tool. To tailor your resume to a job description. Find the matching keywords, improve the readability and gain deep insights into your resume.&lt;/h3&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/stars/srbhr/Resume-Matcher?style=flat-square&amp;amp;color=EA1179&#34; alt=&#34;Stars&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/srbhr/Resume-Matcher?style=flat-square&amp;amp;color=525FE1&#34; alt=&#34;Apache 2.0&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/issues/srbhr/Resume-Matcher?style=flat-square&amp;amp;color=F86F03&#34; alt=&#34;Issues&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/forks/srbhr/Resume-Matcher?style=flat-square&amp;amp;color=0079FF&#34; alt=&#34;Forks&#34;&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://discord.gg/t3Y9HEuV34&#34;&gt;&lt;img src=&#34;https://custom-icon-badges.demolab.com/badge/Discord-blue?style=flat-square&amp;amp;logo=discord&amp;amp;color=F0FF42&amp;amp;logoColor=293462&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/_srbhr_&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/@__srbhr__-000000?style=flat-square&amp;amp;logo=x&amp;amp;logoColor=white&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.resumematcher.fyi&#34;&gt;&lt;img src=&#34;https://custom-icon-badges.demolab.com/badge/www.resumematcher.fyi-gold?style=flat-square&amp;amp;logo=globe&amp;amp;logoColor=black&#34; alt=&#34;Resume Matcher&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;Upvote us on &lt;a href=&#34;https://www.producthunt.com/products/resume-matcher&#34;&gt;ProductHunt 🚀&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.producthunt.com/posts/resume-matcher?utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-resume-matcher&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=401261&amp;amp;theme=light&#34; alt=&#34;Resume Matcher - Free and Open-Source ATS Tool to Match Resumes to Job Desc. | Product Hunt&#34; style=&#34;width: 180px; height: 50px;&#34; width=&#34;200&#34; height=&#34;54&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;strong&gt;Don&#39;t let your resume be a roadblock from getting your next job. Use Resume Matcher!&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/Assets/img/Resume_Matcher_Gif.gif&#34; alt=&#34;Resume_Matcher_streamlit_demo&#34;&gt;&lt;/p&gt; &#xA; &lt;h2&gt;How does it work?&lt;/h2&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;The Resume Matcher takes your resume and job descriptions as input, parses them using Python, and mimics the functionalities of an ATS, providing you with insights and suggestions to make your resume ATS-friendly.&lt;/p&gt; &#xA;&lt;p&gt;The process is as follows:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Parsing&lt;/strong&gt;: The system uses Python to parse both your resume and the provided job description, just like an ATS would.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Keyword Extraction&lt;/strong&gt;: The tool uses advanced machine learning algorithms to extract the most relevant keywords from the job description. These keywords represent the skills, qualifications, and experiences the employer seeks.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Key Terms Extraction&lt;/strong&gt;: Beyond keyword extraction, the tool uses textacy to identify the main key terms or themes in the job description. This step helps in understanding the broader context of what the resume is about.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Vector Similarity Using Qdrant&lt;/strong&gt;: The tool uses &lt;a href=&#34;https://github.com/qdrant/qdrant&#34;&gt;Qdrant&lt;/a&gt;, a highly efficient vector similarity search tool, to measure how closely your resume matches the job description. The more similar they are, the higher the likelihood that your resume will pass the ATS screening.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h2&gt;How to install&lt;/h2&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Follow these steps to set up the environment and run the application.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Fork the repository &lt;a href=&#34;https://github.com/srbhr/Resume-Matcher/fork&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Clone the forked repository.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/&amp;lt;YOUR-USERNAME&amp;gt;/Resume-Matcher.git&#xA;cd Resume-Matcher&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create a Python Virtual Environment:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Using &lt;a href=&#34;https://learnpython.com/blog/how-to-use-virtualenv-python/&#34;&gt;virtualenv&lt;/a&gt;:&lt;/p&gt; &lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: Check how to install virtualenv on your system here &lt;a href=&#34;https://learnpython.com/blog/how-to-use-virtualenv-python/&#34;&gt;link&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;virtualenv env&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;OR&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Create a Python Virtual Environment:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m venv env&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Activate the Virtual Environment.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;On Windows.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;env\Scripts\activate&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;On macOS and Linux.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;source env/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;OPTIONAL (For pyenv users)&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Run the application with pyenv (Refer this &lt;a href=&#34;https://realpython.com/intro-to-pyenv/#installing-pyenv&#34;&gt;article&lt;/a&gt;)&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Build dependencies (on ubuntu)&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo apt-get install -y make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev python openssl&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code&gt;&#xA;sudo apt-get install build-essential zlib1g-dev libffi-dev libssl-dev libbz2-dev libreadline-dev libsqlite3-dev liblzma-dev libncurses-dev&#xA;&#xA;sudo apt-get install python-tk python3-tk tk-dev&#xA;&#xA;sudo apt-get install build-essential zlib1g-dev libffi-dev libssl-dev libbz2-dev libreadline-dev libsqlite3-dev liblzma-dev&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;pyenv installer&lt;/p&gt; &lt;pre&gt;&lt;code&gt;   curl https://pyenv.run | bash&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Install desired python version&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  pyenv install -v 3.11.0&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;pyenv with virtual enviroment&lt;/p&gt; &lt;pre&gt;&lt;code&gt;   pyenv virtualenv 3.11.0 venv&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Activate virtualenv with pyenv&lt;/p&gt; &lt;pre&gt;&lt;code&gt;   pyenv activate venv&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install Dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Prepare Data:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Resumes: Place your resumes in PDF format in the &lt;code&gt;Data/Resumes&lt;/code&gt; folder. Remove any existing contents in this folder.&lt;/li&gt; &#xA;   &lt;li&gt;Job Descriptions: Place your job descriptions in PDF format in the &lt;code&gt;Data/JobDescription&lt;/code&gt; folder. Remove any existing contents in this folder.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Parse Resumes to JSON:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python run_first.py&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run the Application:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;streamlit run streamlit_app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: For local versions, you do not need to run &#34;streamlit_second.py&#34; as it is specifically for deploying to Streamlit servers.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Additional Note&lt;/strong&gt;: The Vector Similarity part is precomputed to optimize performance due to the resource-intensive nature of sentence encoders that require significant GPU and RAM resources. If you are interested in leveraging this feature in a Google Colab environment for free, refer to the upcoming blog (link to be provided) for further guidance.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Build the image and start application&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    docker-compose up&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open &lt;code&gt;localhost:80&lt;/code&gt; on your browser&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Running the Web Application&lt;/h3&gt; &#xA;&lt;p&gt;The full stack Next.js (React and FastAPI) web application allows users to interact with the Resume Matcher tool interactively via a web browser.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!WARNING] The results returned from through the web app are currently entirely mocked / faked. This means that the results returned are not real and are just for demonstration purposes. This will be implemented with real data results in a future release.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;To run the full stack web application (frontend client and backend api servers), follow the instructions over on the &lt;a href=&#34;https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/webapp/README.md&#34;&gt;webapp README&lt;/a&gt; file.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Google Colab&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create an account in ngrok and get you token&lt;/li&gt; &#xA; &lt;li&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/img_1.png&#34; alt=&#34;img_1.png&#34;&gt;&lt;/li&gt; &#xA; &lt;li&gt;Go to archive/resume_matcher_colab.ipynb and run the notebook.&lt;/li&gt; &#xA; &lt;li&gt;Enter your ngrok token and run the notebook.&lt;/li&gt; &#xA; &lt;li&gt;Copy the url and open it in your browser.&lt;/li&gt; &#xA; &lt;li&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/img_2.png&#34; alt=&#34;img_2.png&#34;&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Cohere and Qdrant&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Visit &lt;a href=&#34;https://dashboard.cohere.ai/welcome/register&#34;&gt;Cohere website registration&lt;/a&gt; and create an account.&lt;/li&gt; &#xA; &lt;li&gt;Go to API keys and copy your cohere api key.&lt;/li&gt; &#xA; &lt;li&gt;Visit &lt;a href=&#34;https://cloud.qdrant.io/&#34;&gt;Qdrant website&lt;/a&gt; and create an account.&lt;/li&gt; &#xA; &lt;li&gt;Get your api key and cluster url.&lt;/li&gt; &#xA; &lt;li&gt;Go to open dashboard in qdrant and enter your api key &lt;strong&gt;for only the first time&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/Assets/img/quadrant_cloud.png&#34; height=&#34;60%&#34; width=&#34;60%&#34;&gt; 6. Now create a yaml file named config.yml in Scripts/Similarity/ folder. 7. The format for the conifg file should be as below: ```yaml cohere: api_key: cohere_key qdrant: api_key: qdrant_api_key url: qdrant_cluster_url ``` 8. Please replace your values without any quotes. &#xA;&lt;p&gt;&lt;em&gt;Note: Please make sure that Qdrant_client&#39;s version is higher than v1.1&lt;/em&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h2&gt;Join Us, Contribute!&lt;/h2&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Pull Requests &amp;amp; Issues are not just welcomed, they&#39;re celebrated! Let&#39;s create together.&lt;/p&gt; &#xA;&lt;p&gt;🎉 Join our lively &lt;a href=&#34;https://dsc.gg/resume-matcher&#34;&gt;Discord&lt;/a&gt; community and discuss away!&lt;/p&gt; &#xA;&lt;p&gt;💡 Spot a problem? Create an issue!&lt;/p&gt; &#xA;&lt;p&gt;👩‍💻 Dive in and help resolve existing &lt;a href=&#34;https://github.com/srbhr/Resume-Matcher/issues&#34;&gt;issues&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;🔔 Share your thoughts in our &lt;a href=&#34;https://github.com/srbhr/Resume-Matcher/discussions&#34;&gt;Discussions &amp;amp; Announcements&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;🚀 Explore and improve our &lt;a href=&#34;https://github.com/srbhr/website-for-resume-matcher&#34;&gt;Landing Page&lt;/a&gt;. PRs always welcome!&lt;/p&gt; &#xA;&lt;p&gt;📚 Contribute to the &lt;a href=&#34;https://github.com/srbhr/Resume-Matcher-Docs&#34;&gt;Resume Matcher Docs&lt;/a&gt; and help people get started with using the software.&lt;/p&gt; &#xA;&lt;h4&gt;Tech Stack&lt;/h4&gt; &#xA;&lt;p&gt;Current:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python webapp in Streamlit.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-3776AB?style=flat-square&amp;amp;logo=python&amp;amp;color=blue&amp;amp;logoColor=green&#34; alt=&#34;Python&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;In Development:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Check the &lt;a href=&#34;https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/webapp/&#34;&gt;webapp&lt;/a&gt; folder for a Next JS app in development. (In Development)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-FFD43B?style=flat-square&amp;amp;logo=python&amp;amp;logoColor=blue&#34; alt=&#34;Python&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Tailwind_CSS-38B2AC?style=flat-square&amp;amp;logo=tailwind-css&amp;amp;logoColor=white&#34; alt=&#34;Tailwind CSS&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Next-black?style=flat-square&amp;amp;logo=next.js&amp;amp;logoColor=white&#34; alt=&#34;Next JS&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/FastAPI-005571?style=flat-square&amp;amp;logo=fastapi&#34; alt=&#34;FastAPI&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/TypeScript-007ACC?style=flat-square&amp;amp;logo=typescript&amp;amp;logoColor=white&#34; alt=&#34;TypeScript&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/HTML5-E34F26?style=flat-square&amp;amp;logo=html5&amp;amp;logoColor=white&#34; alt=&#34;HTML5&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/CSS3-1572B6?style=flat-square&amp;amp;logo=css3&amp;amp;logoColor=white&#34; alt=&#34;CSS3&#34;&gt; &lt;img src=&#34;https://custom-icon-badges.demolab.com/badge/And_More-white?style=flat-square&amp;amp;logo=plus&amp;amp;logoColor=black&#34; alt=&#34;&amp;amp; More&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h2&gt;Please support the development by donating.&lt;/h2&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://buymeacoffee.com/srbhr&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&amp;amp;logo=buy-me-a-coffee&amp;amp;logoColor=black&#34; alt=&#34;BuyMeACoffee&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/sponsors/srbhr&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/sponsor-30363D?style=for-the-badge&amp;amp;logo=GitHub-Sponsors&amp;amp;logoColor=#white&#34; alt=&#34;Sponsor on GitHub&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Heads Up! 📝&lt;/h3&gt; &#xA;&lt;p&gt;Your support means the world to us 💙. We&#39;re nurturing this project with an open-source community spirit, and we have an ambitious roadmap ahead! Here are some ways you could contribute and make a significant impact:&lt;/p&gt; &#xA;&lt;p&gt;✨ Transform our Streamlit dashboard into something more robust.&lt;/p&gt; &#xA;&lt;p&gt;💡 Improve our parsing algorithm, making data more accessible.&lt;/p&gt; &#xA;&lt;p&gt;🖋 Share your insights and experiences in a blog post to help others.&lt;/p&gt; &#xA;&lt;p&gt;Take the leap, contribute, and let&#39;s grow together! 🚀&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Our Contributors ✨&lt;/h3&gt; &#xA;&lt;a href=&#34;https://github.com/srbhr/Resume-Matcher/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=srbhr/Resume-Matcher&#34;&gt; &lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>tinygrad/tinygrad</title>
    <updated>2023-12-03T01:56:11Z</updated>
    <id>tag:github.com,2023-12-03:/tinygrad/tinygrad</id>
    <link href="https://github.com/tinygrad/tinygrad" rel="alternate"></link>
    <summary type="html">&lt;p&gt;You like pytorch? You like micrograd? You love tinygrad! ❤️&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://tinygrad.org&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/logo.png&#34; alt=&#34;logo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;tinygrad: For something between &lt;a href=&#34;https://github.com/pytorch/pytorch&#34;&gt;PyTorch&lt;/a&gt; and &lt;a href=&#34;https://github.com/karpathy/micrograd&#34;&gt;karpathy/micrograd&lt;/a&gt;. Maintained by &lt;a href=&#34;https://tinygrad.org&#34;&gt;tiny corp&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;h3&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/tinygrad/tinygrad&#34;&gt;Homepage&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs&#34;&gt;Documentation&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/examples&#34;&gt;Examples&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/showcase.md&#34;&gt;Showcase&lt;/a&gt; | &lt;a href=&#34;https://discord.gg/ZjZadyC7PK&#34;&gt;Discord&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/tinygrad/tinygrad/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/tinygrad/tinygrad&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/tinygrad/tinygrad/actions/workflows/test.yml&#34;&gt;&lt;img src=&#34;https://github.com/tinygrad/tinygrad/actions/workflows/test.yml/badge.svg?sanitize=true&#34; alt=&#34;Unit Tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/ZjZadyC7PK&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1068976834382925865&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;This may not be the best deep learning framework, but it is a deep learning framework.&lt;/p&gt; &#xA;&lt;p&gt;Due to its extreme simplicity, it aims to be the easiest framework to add new accelerators to, with support for both inference and training. If XLA is CISC, tinygrad is RISC.&lt;/p&gt; &#xA;&lt;p&gt;tinygrad is still alpha software, but we &lt;a href=&#34;https://geohot.github.io/blog/jekyll/update/2023/05/24/the-tiny-corp-raised-5M.html&#34;&gt;raised some money&lt;/a&gt; to make it good. Someday, we will tape out chips.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;h3&gt;LLaMA and Stable Diffusion&lt;/h3&gt; &#xA;&lt;p&gt;tinygrad can run &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/showcase.md#llama&#34;&gt;LLaMA&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/showcase.md#stable-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h3&gt;Laziness&lt;/h3&gt; &#xA;&lt;p&gt;Try a matmul. See how, despite the style, it is fused into one kernel with the power of laziness.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;DEBUG=3 python3 -c &#34;from tinygrad import Tensor;&#xA;N = 1024; a, b = Tensor.rand(N, N), Tensor.rand(N, N);&#xA;c = (a.reshape(N, 1, N) * b.permute(1,0).reshape(1, N, N)).sum(axis=2);&#xA;print((c.numpy() - (a.numpy() @ b.numpy())).mean())&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And we can change &lt;code&gt;DEBUG&lt;/code&gt; to &lt;code&gt;4&lt;/code&gt; to see the generated code.&lt;/p&gt; &#xA;&lt;h3&gt;Neural networks&lt;/h3&gt; &#xA;&lt;p&gt;As it turns out, 90% of what you need for neural networks are a decent autograd/tensor library. Throw in an optimizer, a data loader, and some compute, and you have all you need.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from tinygrad import Tensor, nn&#xA;&#xA;class LinearNet:&#xA;  def __init__(self):&#xA;    self.l1 = Tensor.kaiming_uniform(784, 128)&#xA;    self.l2 = Tensor.kaiming_uniform(128, 10)&#xA;  def __call__(self, x:Tensor) -&amp;gt; Tensor:&#xA;    return x.flatten(1).dot(self.l1).relu().dot(self.l2)&#xA;&#xA;model = LinearNet()&#xA;optim = nn.optim.Adam([model.l1, model.l2], lr=0.001)&#xA;&#xA;x, y = Tensor.rand(4, 1, 28, 28), Tensor([2,4,3,7])  # replace with real mnist dataloader&#xA;&#xA;for i in range(10):&#xA;  optim.zero_grad()&#xA;  loss = model(x).sparse_categorical_crossentropy(y).backward()&#xA;  optim.step()&#xA;  print(i, loss.item())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/examples/beautiful_mnist.py&#34;&gt;examples/beautiful_mnist.py&lt;/a&gt; for the full version that gets 98% in ~5 seconds&lt;/p&gt; &#xA;&lt;h2&gt;Accelerators&lt;/h2&gt; &#xA;&lt;p&gt;tinygrad already supports numerous accelerators, including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_cpu.py&#34;&gt;CPU&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_gpu.py&#34;&gt;GPU (OpenCL)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_clang.py&#34;&gt;C Code (Clang)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_llvm.py&#34;&gt;LLVM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_metal.py&#34;&gt;METAL&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_cuda.py&#34;&gt;CUDA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/extra/triton/triton.py&#34;&gt;Triton&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_torch.py&#34;&gt;PyTorch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_hip.py&#34;&gt;HIP&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_webgpu.py&#34;&gt;WebGPU&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;And it is easy to add more! Your accelerator of choice only needs to support a total of 26 (optionally 27) low level ops. More information can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/adding_new_accelerators.md&#34;&gt;documentation for adding new accelerators&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;The current recommended way to install tinygrad is from source.&lt;/p&gt; &#xA;&lt;h3&gt;From source&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/tinygrad/tinygrad.git&#xA;cd tinygrad&#xA;python3 -m pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Don&#39;t forget the &lt;code&gt;.&lt;/code&gt; at the end!&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Documentation along with a quick start guide can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs&#34;&gt;docs/&lt;/a&gt; directory.&lt;/p&gt; &#xA;&lt;h3&gt;Quick example comparing to PyTorch&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from tinygrad import Tensor&#xA;&#xA;x = Tensor.eye(3, requires_grad=True)&#xA;y = Tensor([[2.0,0,-2.0]], requires_grad=True)&#xA;z = y.matmul(x).sum()&#xA;z.backward()&#xA;&#xA;print(x.grad.numpy())  # dz/dx&#xA;print(y.grad.numpy())  # dz/dy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The same thing but in PyTorch:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import torch&#xA;&#xA;x = torch.eye(3, requires_grad=True)&#xA;y = torch.tensor([[2.0,0,-2.0]], requires_grad=True)&#xA;z = y.matmul(x).sum()&#xA;z.backward()&#xA;&#xA;print(x.grad.numpy())  # dz/dx&#xA;print(y.grad.numpy())  # dz/dy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;There has been a lot of interest in tinygrad lately. Here are some basic guidelines for contributing:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Bug fixes are the best and always welcome! Like &lt;a href=&#34;https://github.com/tinygrad/tinygrad/pull/421/files&#34;&gt;this one&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;If you don&#39;t understand the code you are changing, don&#39;t change it!&lt;/li&gt; &#xA; &lt;li&gt;All code golf PRs will be closed, but &lt;a href=&#34;https://github.com/tinygrad/tinygrad/pull/372/files&#34;&gt;conceptual cleanups&lt;/a&gt; are great.&lt;/li&gt; &#xA; &lt;li&gt;Features are welcome. Though if you are adding a feature, you need to include tests.&lt;/li&gt; &#xA; &lt;li&gt;Improving test coverage is great, with reliable non-brittle tests.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Additional guidelines can be found in &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Running tests&lt;/h3&gt; &#xA;&lt;p&gt;For more examples on how to run the full test suite please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/.github/workflows/test.yml&#34;&gt;CI workflow&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Some examples:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python3 -m pip install -e &#39;.[testing]&#39;&#xA;python3 -m pytest&#xA;python3 -m pytest -v -k TestTrain&#xA;python3 ./test/models/test_train.py TestTrain.test_efficientnet&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>