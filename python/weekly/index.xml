<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-05T01:40:23Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>myshell-ai/MeloTTS</title>
    <updated>2024-05-05T01:40:23Z</updated>
    <id>tag:github.com,2024-05-05:/myshell-ai/MeloTTS</id>
    <link href="https://github.com/myshell-ai/MeloTTS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;High-quality multi-lingual text-to-speech library by MyShell.ai. Support English, Spanish, French, Chinese, Japanese and Korean.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;div&gt;&#xA;  &amp;nbsp;&#xA; &lt;/div&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/myshell-ai/MeloTTS/main/logo.png&#34; width=&#34;300&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;MeloTTS is a &lt;strong&gt;high-quality multi-lingual&lt;/strong&gt; text-to-speech library by &lt;a href=&#34;https://myshell.ai&#34;&gt;MyShell.ai&lt;/a&gt;. Supported languages include:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Language&lt;/th&gt; &#xA;   &lt;th&gt;Example&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;English (American)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/en/EN-US/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;English (British)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/en/EN-BR/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;English (Indian)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/en/EN_INDIA/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;English (Australian)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/en/EN-AU/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;English (Default)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/en/EN-Default/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Spanish&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/es/ES/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;French&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/fr/FR/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese (mix EN)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/zh/ZH/speed_1.0/sent_008.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Japanese&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/jp/JP/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Korean&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://myshell-public-repo-hosting.s3.amazonaws.com/myshellttsbase/examples/kr/KR/speed_1.0/sent_000.wav&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Some other features include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The Chinese speaker supports &lt;code&gt;mixed Chinese and English&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Fast enough for &lt;code&gt;CPU real-time inference&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/myshell-ai/MeloTTS/main/docs/quick_use.md&#34;&gt;Use without Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/myshell-ai/MeloTTS/main/docs/install.md&#34;&gt;Install and Use Locally&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/myshell-ai/MeloTTS/main/docs/training.md&#34;&gt;Training on Custom Dataset&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The Python API and model cards can be found in &lt;a href=&#34;https://github.com/myshell-ai/MeloTTS/raw/main/docs/install.md#python-api&#34;&gt;this repo&lt;/a&gt; or on &lt;a href=&#34;https://huggingface.co/myshell-ai&#34;&gt;HuggingFace&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Join the Community&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Discord&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Join our &lt;a href=&#34;https://discord.gg/myshell&#34;&gt;Discord community&lt;/a&gt; and select the &lt;code&gt;Developer&lt;/code&gt; role upon joining to gain exclusive access to our developer-only channel! Don&#39;t miss out on valuable discussions and collaboration opportunities.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you find this work useful, please consider contributing to this repo.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/fakerybakery&#34;&gt;@fakerybakery&lt;/a&gt; for adding the Web UI and CLI part.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Authors&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://wl-zhao.github.io&#34;&gt;Wenliang Zhao&lt;/a&gt; at Tsinghua University&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yuxumin.github.io&#34;&gt;Xumin Yu&lt;/a&gt; at Tsinghua University&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.qinzy.tech&#34;&gt;Zengyi Qin&lt;/a&gt; at MIT and MyShell&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Citation&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@software{zhao2024melo,&#xA;  author={Zhao, Wenliang and Yu, Xumin and Qin, Zengyi},&#xA;  title = {MeloTTS: High-quality Multi-lingual Multi-accent Text-to-Speech},&#xA;  url = {https://github.com/myshell-ai/MeloTTS},&#xA;  year = {2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This library is under MIT License, which means it is free for both commercial and non-commercial use.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;This implementation is based on &lt;a href=&#34;https://github.com/coqui-ai/TTS&#34;&gt;TTS&lt;/a&gt;, &lt;a href=&#34;https://github.com/jaywalnut310/vits&#34;&gt;VITS&lt;/a&gt;, &lt;a href=&#34;https://github.com/daniilrobnikov/vits2&#34;&gt;VITS2&lt;/a&gt; and &lt;a href=&#34;https://github.com/fishaudio/Bert-VITS2&#34;&gt;Bert-VITS2&lt;/a&gt;. We appreciate their awesome work.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>LlamaFamily/Llama-Chinese</title>
    <updated>2024-05-05T01:40:23Z</updated>
    <id>tag:github.com,2024-05-05:/LlamaFamily/Llama-Chinese</id>
    <link href="https://github.com/LlamaFamily/Llama-Chinese" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Llamaä¸­æ–‡ç¤¾åŒºï¼ŒLlama3åœ¨çº¿ä½“éªŒå’Œå¾®è°ƒæ¨¡å‹å·²å¼€æ”¾ï¼Œå®æ—¶æ±‡æ€»æœ€æ–°Llama3å­¦ä¹ èµ„æ–™ï¼Œå·²å°†æ‰€æœ‰ä»£ç æ›´æ–°é€‚é…Llama3ï¼Œæ„å»ºæœ€å¥½çš„ä¸­æ–‡Llamaå¤§æ¨¡å‹ï¼Œå®Œå…¨å¼€æºå¯å•†ç”¨&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;left&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/README_EN.md&#34;&gt;English&lt;/a&gt; ï½œ ä¸­æ–‡ &lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt; Llamaä¸­æ–‡ç¤¾åŒº &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/llama.jpg&#34; alt=&#34;Llama&#34; style=&#34;width: 20%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;font face=&#34;é»‘ä½“&#34; color=&#34;orange&#34; size=&#34;6&#34;&gt; Llama3ä½“éªŒå’Œå¾®è°ƒå·²å¼€æ”¾ï¼Œæœ€å¥½çš„ä¸­æ–‡Llamaå¤§æ¨¡å‹ &lt;/font&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; ğŸ¤— &lt;a href=&#34;https://huggingface.co/FlagAlpha&#34; target=&#34;_blank&#34;&gt;Hugging Face&lt;/a&gt; â€¢ ğŸ¤– &lt;a href=&#34;https://www.modelscope.cn/organization/FlagAlpha/&#34; target=&#34;_blank&#34;&gt;ModelScope&lt;/a&gt; â€¢ âœ¡ï¸ &lt;a href=&#34;https://wisemodel.cn/models/FlagAlpha/Atom-7B-Chat&#34; target=&#34;_blank&#34;&gt;WiseModel&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://llama.family&#34;&gt;Llama3 åœ¨çº¿ä½“éªŒï¼ˆåŒ…å«Llama2ï¼‰ï¼šhttps://llama.family&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B-Chat&#34;&gt;åŸºäºLlama2çš„å¼€æºä¸­æ–‡é¢„è®­ç»ƒå¤§æ¨¡å‹Atom-7B&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ—‚ï¸ ç›®å½•&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-llama%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA&#34;&gt;ğŸ“Œ Llamaä¸­æ–‡ç¤¾åŒº&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E7%A4%BE%E5%8C%BA%E4%BB%8B%E7%BB%8Dllama%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA&#34;&gt;ğŸ”¥ ç¤¾åŒºä»‹ç»ï¼šLlamaä¸­æ–‡ç¤¾åŒº&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%9C%80%E6%96%B0%E5%8A%A8%E6%80%81&#34;&gt;ğŸ“¢ æœ€æ–°åŠ¨æ€&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B&#34;&gt;ğŸ¤— æ¨¡å‹&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8Batom&#34;&gt;ğŸ¤— ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹Atom-7B&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama3%E5%AE%98%E6%96%B9%E6%A8%A1%E5%9E%8B&#34;&gt;ğŸ¤— Llama3å®˜æ–¹æ¨¡å‹&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama3%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B&#34;&gt;ğŸ¤— Llama3ä¸­æ–‡å¾®è°ƒæ¨¡å‹&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama2%E5%AE%98%E6%96%B9%E6%A8%A1%E5%9E%8B&#34;&gt;ğŸ¤— Llama2å®˜æ–¹æ¨¡å‹&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama2%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B&#34;&gt;ğŸ¤— Llama2ä¸­æ–‡å¾®è°ƒæ¨¡å‹&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E7%A4%BE%E5%8C%BA%E8%B5%84%E6%BA%90&#34;&gt;ğŸŒŸ ç¤¾åŒºèµ„æº&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8llama%E6%A8%A1%E5%9E%8B&#34;&gt;ğŸ“Œ å¦‚ä½•ä½¿ç”¨Llamaæ¨¡å‹?&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B-%E4%BD%BF%E7%94%A8anaconda&#34;&gt;å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨Anaconda&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B-%E4%BD%BF%E7%94%A8docker&#34;&gt;å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨Docker&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B-%E4%BD%BF%E7%94%A8llamacpp&#34;&gt;å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨llama.cpp&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B-%E4%BD%BF%E7%94%A8gradio&#34;&gt;å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨gradio&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B-%E6%9E%84%E5%BB%BAapi%E6%9C%8D%E5%8A%A1&#34;&gt;å¿«é€Ÿä¸Šæ‰‹-æ„å»ºAPIæœåŠ¡&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83&#34;&gt;ğŸ¤– æ¨¡å‹é¢„è®­ç»ƒ&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83&#34;&gt;ğŸ’¡ æ¨¡å‹å¾®è°ƒ&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#step1-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87&#34;&gt;Step1: ç¯å¢ƒå‡†å¤‡&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#step2-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87&#34;&gt;Step2: æ•°æ®å‡†å¤‡&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#step3-%E5%BE%AE%E8%B0%83%E8%84%9A%E6%9C%AC&#34;&gt;Step3: å¾®è°ƒè„šæœ¬&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#lora%E5%BE%AE%E8%B0%83&#34;&gt;LoRAå¾®è°ƒ&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%85%A8%E9%87%8F%E5%8F%82%E6%95%B0%E5%BE%AE%E8%B0%83&#34;&gt;å…¨é‡å‚æ•°å¾®è°ƒ&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#step4-%E5%8A%A0%E8%BD%BD%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B&#34;&gt;Step4: åŠ è½½å¾®è°ƒæ¨¡å‹&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#lora%E5%BE%AE%E8%B0%83-1&#34;&gt;LoRAå¾®è°ƒ&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%85%A8%E9%87%8F%E5%8F%82%E6%95%B0%E5%BE%AE%E8%B0%83-1&#34;&gt;å…¨é‡å‚æ•°å¾®è°ƒ&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96&#34;&gt;ğŸ„ æ¨¡å‹é‡åŒ–&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E9%83%A8%E7%BD%B2%E5%8A%A0%E9%80%9F&#34;&gt;ğŸš€ éƒ¨ç½²åŠ é€Ÿ&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#tensorrt-llm&#34;&gt;TensorRT-LLM&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#vllm&#34;&gt;vLLM&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#jittorllms&#34;&gt;JittorLLMs&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#lmdeploy&#34;&gt;lmdeploy&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E5%A4%96%E5%BB%B6%E8%83%BD%E5%8A%9B&#34;&gt;ğŸ’ª å¤–å»¶èƒ½åŠ›&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#langchain&#34;&gt;LangChain&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B&#34;&gt;ğŸ¥‡ æ¨¡å‹è¯„æµ‹&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama2%E5%92%8Cllama3%E5%AF%B9%E6%AF%94%E8%AF%84%E6%B5%8B&#34;&gt;Llama2å’ŒLlama3å¯¹æ¯”è¯„æµ‹&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama3%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B&#34;&gt;Llama3æ¨¡å‹è¯„æµ‹&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama2%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B&#34;&gt;Llama2æ¨¡å‹è¯„æµ‹&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%BF%83&#34;&gt;ğŸ“– å­¦ä¹ ä¸­å¿ƒ&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama3&#34;&gt;Llama3&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama2&#34;&gt;Llama2&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#meta%E5%AE%98%E6%96%B9%E5%AF%B9%E4%BA%8Ellama2%E7%9A%84%E4%BB%8B%E7%BB%8D&#34;&gt;Metaå®˜æ–¹å¯¹äºLlama2çš„ä»‹ç»&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87&#34;&gt;Llamaç›¸å…³è®ºæ–‡&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E5%85%B6%E5%AE%83&#34;&gt;ğŸ“Œ å…¶å®ƒ&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E8%87%B4%E8%B0%A2&#34;&gt;ğŸ‰ è‡´è°¢&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E9%97%AE%E9%A2%98%E5%8F%8D%E9%A6%88&#34;&gt;ğŸ¤” é—®é¢˜åé¦ˆ&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ“Œ Llamaä¸­æ–‡ç¤¾åŒº&lt;/h2&gt; &#xA;&lt;h3&gt;ğŸ”¥ ç¤¾åŒºä»‹ç»ï¼šllamaä¸­æ–‡ç¤¾åŒº&lt;/h3&gt; &#xA;&lt;p&gt;æ¬¢è¿æ¥åˆ°Llamaä¸­æ–‡ç¤¾åŒºï¼æˆ‘ä»¬æ˜¯ä¸€ä¸ªä¸“æ³¨äºLlamaæ¨¡å‹åœ¨ä¸­æ–‡æ–¹é¢çš„ä¼˜åŒ–å’Œä¸Šå±‚å»ºè®¾çš„é«˜çº§æŠ€æœ¯ç¤¾åŒºã€‚ &lt;strong&gt;å·²ç»åŸºäºå¤§è§„æ¨¡ä¸­æ–‡æ•°æ®ï¼Œä»é¢„è®­ç»ƒå¼€å§‹å¯¹Llama2æ¨¡å‹è¿›è¡Œä¸­æ–‡èƒ½åŠ›çš„æŒç»­è¿­ä»£å‡çº§ã€Doneã€‘&lt;/strong&gt;ã€‚&lt;strong&gt;æ­£åœ¨å¯¹Llama3æ¨¡å‹è¿›è¡Œä¸­æ–‡èƒ½åŠ›çš„æŒç»­è¿­ä»£å‡çº§ã€Doingã€‘&lt;/strong&gt; æˆ‘ä»¬çƒ­å¿±æ¬¢è¿å¯¹å¤§æ¨¡å‹LLMå……æ»¡çƒ­æƒ…çš„å¼€å‘è€…å’Œç ”ç©¶è€…åŠ å…¥æˆ‘ä»¬çš„è¡Œåˆ—ã€‚&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;h4&gt;ä¸ºä»€ä¹ˆé€‰æ‹©Llamaä¸­æ–‡ç¤¾åŒºï¼Ÿ&lt;/h4&gt; &#xA; &lt;p&gt;ğŸš€ &lt;strong&gt;é«˜çº§å·¥ç¨‹å¸ˆå›¢é˜Ÿæ”¯æŒ&lt;/strong&gt;ï¼šç¤¾åŒºæœ‰ä¸€æ‰¹ä¸“æ³¨ä¸ºå¤§å®¶æœåŠ¡çš„NLPé«˜çº§å·¥ç¨‹å¸ˆï¼Œæˆ‘ä»¬æœ‰ç€å¼ºå¤§çš„æŠ€æœ¯æ”¯æŒå’Œä¸°å¯Œçš„ç»éªŒï¼Œä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æŒ‡å¯¼å’Œå¸®åŠ©ã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ¯ &lt;strong&gt;ä¸­æ–‡ä¼˜åŒ–&lt;/strong&gt;ï¼šæˆ‘ä»¬è‡´åŠ›äºåœ¨Llamaæ¨¡å‹çš„ä¸­æ–‡å¤„ç†æ–¹é¢è¿›è¡Œä¼˜åŒ–ï¼Œæ¢ç´¢é€‚ç”¨äºä¸­æ–‡çš„æœ€ä½³å®è·µï¼Œä»¥æå‡å…¶æ€§èƒ½å’Œé€‚åº”æ€§ã€æ”¯æŒLlama2ã€Llama3ã€‘ã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ’¡ &lt;strong&gt;åˆ›æ–°äº¤æµ&lt;/strong&gt;ï¼šæˆ‘ä»¬æ‹¥æœ‰ä¸€æ”¯å¯Œæœ‰åˆ›é€ åŠ›å’Œç»éªŒçš„ç¤¾åŒºæˆå‘˜å›¢é˜Ÿï¼Œå®šæœŸç»„ç»‡çº¿ä¸Šæ´»åŠ¨ã€æŠ€æœ¯ç ”è®¨å’Œç»éªŒåˆ†äº«ï¼Œä¿ƒè¿›æˆå‘˜é—´çš„åˆ›æ–°äº¤æµã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸŒ &lt;strong&gt;å…¨çƒè”ç»“&lt;/strong&gt;ï¼šæˆ‘ä»¬æ¬¢è¿æ¥è‡ªä¸–ç•Œå„åœ°çš„å¼€å‘è€…åŠ å…¥ç¤¾åŒºï¼Œæ„å»ºä¸€ä¸ªå¼€æ”¾ã€å¤šå…ƒåŒ–çš„å­¦ä¹ å’Œäº¤æµå¹³å°ã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ¤ &lt;strong&gt;å¼€æ”¾å…±äº«&lt;/strong&gt;ï¼šæˆ‘ä»¬é¼“åŠ±ç¤¾åŒºæˆå‘˜å¼€æºåˆ†äº«ä»£ç å’Œæ¨¡å‹ï¼Œæ¨åŠ¨åˆä½œå…±èµ¢ï¼Œå…±åŒä¿ƒè¿›ä¸­æ–‡NLPæŠ€æœ¯çš„å‘å±•ã€‚&lt;/p&gt; &#xA; &lt;h4&gt;ç¤¾åŒºæ´»åŠ¨&lt;/h4&gt; &#xA; &lt;p&gt;ğŸ—“ï¸ &lt;strong&gt;çº¿ä¸Šè®²åº§&lt;/strong&gt;ï¼šé‚€è¯·è¡Œä¸šå†…ä¸“å®¶è¿›è¡Œçº¿ä¸Šè®²åº§ï¼Œåˆ†äº«Llamaåœ¨ä¸­æ–‡NLPé¢†åŸŸçš„æœ€æ–°æŠ€æœ¯å’Œåº”ç”¨ï¼Œæ¢è®¨å‰æ²¿ç ”ç©¶æˆæœã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ’» &lt;strong&gt;é¡¹ç›®å±•ç¤º&lt;/strong&gt;ï¼šæˆå‘˜å¯å±•ç¤ºè‡ªå·±åœ¨Llamaä¸­æ–‡ä¼˜åŒ–æ–¹é¢çš„é¡¹ç›®æˆæœï¼Œè·å¾—åé¦ˆå’Œå»ºè®®ï¼Œä¿ƒè¿›é¡¹ç›®åä½œã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ“š &lt;strong&gt;å­¦ä¹ èµ„æº&lt;/strong&gt;ï¼šç¤¾åŒºç»´æŠ¤ä¸°å¯Œçš„å­¦ä¹ èµ„æ–™åº“ï¼ŒåŒ…æ‹¬æ•™ç¨‹ã€æ–‡æ¡£å’Œè®ºæ–‡è§£è¯»ï¼Œä¸ºæˆå‘˜æä¾›å…¨é¢çš„å­¦ä¹ æ”¯æŒã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ“ &lt;strong&gt;è®ºæ–‡è§£è¯»&lt;/strong&gt;ï¼šç¤¾åŒºæˆå‘˜å…±åŒè§£è¯»ä¸Llamaç›¸å…³çš„æœ€æ–°ç ”ç©¶è®ºæ–‡ï¼Œæ·±å…¥ç†è§£å‰æ²¿ç®—æ³•å’Œæ–¹æ³•ã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ‰ &lt;strong&gt;ä¸»é¢˜æ´»åŠ¨&lt;/strong&gt;ï¼šå®šæœŸä¸¾åŠå„ç±»ä¸»é¢˜æ´»åŠ¨ï¼ŒåŒ…æ‹¬æŒ‘æˆ˜èµ›ã€é»‘å®¢é©¬æ‹‰æ¾å’ŒæŠ€æœ¯æ²™é¾™ï¼Œè®©ç¤¾åŒºæˆå‘˜åœ¨è½»æ¾æ„‰å¿«çš„æ°›å›´ä¸­äº¤æµå’Œå­¦ä¹ ã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸŒŸ &lt;strong&gt;å¥–åŠ±è®¡åˆ’&lt;/strong&gt;ï¼šæˆ‘ä»¬è®¾ç«‹å¥–åŠ±è®¡åˆ’ï¼Œå¯¹ç¤¾åŒºä¸­ç§¯æå‚ä¸ã€è´¡çŒ®ä¼˜ç§€çš„æˆå‘˜ç»™äºˆè£èª‰å’Œå¥–åŠ±ï¼Œæ¿€åŠ±æ›´å¤šä¼˜ç§€äººæ‰çš„åŠ å…¥ã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ“ˆ &lt;strong&gt;æŠ€æœ¯å’¨è¯¢&lt;/strong&gt;ï¼šæˆ‘ä»¬æä¾›æŠ€æœ¯å’¨è¯¢æœåŠ¡ï¼Œè§£ç­”æ‚¨åœ¨Llamaå¼€å‘å’Œä¼˜åŒ–è¿‡ç¨‹ä¸­é‡åˆ°çš„é—®é¢˜ï¼ŒåŠ©æ‚¨å¿«é€Ÿæ”»å…‹éš¾å…³ã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸš€ &lt;strong&gt;é¡¹ç›®åˆä½œ&lt;/strong&gt;ï¼šé¼“åŠ±æˆå‘˜é—´çš„é¡¹ç›®åˆä½œï¼Œå…±åŒæ¢ç´¢Llamaåœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ï¼Œæ‰“é€ åˆ›æ–°è§£å†³æ–¹æ¡ˆã€‚&lt;/p&gt; &#xA; &lt;h4&gt;ç«‹å³åŠ å…¥æˆ‘ä»¬ï¼&lt;/h4&gt; &#xA; &lt;p&gt;ğŸ“š &lt;strong&gt;æ„¿æ™¯&lt;/strong&gt;ï¼šæ— è®ºæ‚¨æ˜¯å¯¹Llamaå·²æœ‰ç ”ç©¶å’Œåº”ç”¨ç»éªŒçš„ä¸“ä¸šå¼€å‘è€…ï¼Œè¿˜æ˜¯å¯¹Llamaä¸­æ–‡ä¼˜åŒ–æ„Ÿå…´è¶£å¹¶å¸Œæœ›æ·±å…¥æ¢ç´¢çš„æ–°æ‰‹ï¼Œæˆ‘ä»¬éƒ½çƒ­åˆ‡æœŸå¾…æ‚¨çš„åŠ å…¥ã€‚åœ¨Llamaä¸­æ–‡ç¤¾åŒºï¼Œæ‚¨å°†æœ‰æœºä¼šä¸è¡Œä¸šå†…é¡¶å°–äººæ‰å…±åŒäº¤æµï¼Œæºæ‰‹æ¨åŠ¨ä¸­æ–‡NLPæŠ€æœ¯çš„è¿›æ­¥ï¼Œå¼€åˆ›æ›´åŠ ç¾å¥½çš„æŠ€æœ¯æœªæ¥ï¼&lt;/p&gt; &#xA; &lt;p&gt;ğŸ”— &lt;strong&gt;æ¸©é¦¨æç¤º&lt;/strong&gt;ï¼šæœ¬ç¤¾åŒºä¸ºä¸“ä¸šæŠ€æœ¯äº¤æµå¹³å°ï¼Œæˆ‘ä»¬çƒ­åˆ‡æœŸæœ›å¿—åŒé“åˆçš„å¼€å‘è€…å’Œç ”ç©¶è€…åŠ å…¥ã€‚è¯·éµå®ˆç¤¾åŒºå‡†åˆ™ï¼Œå…±åŒç»´æŠ¤ç§¯æå‘ä¸Šçš„å­¦ä¹ æ°›å›´ã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£å’Œæ”¯æŒï¼&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;ğŸ“¢ æœ€æ–°åŠ¨æ€&lt;/h3&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2024å¹´04æœˆ23æ—¥ï¼šç¤¾åŒºå¢åŠ äº†llama3 8Bä¸­æ–‡å¾®è°ƒæ¨¡å‹&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese?tab=readme-ov-file#llama3%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B&#34;&gt;Llama3-Chinese-8B-Instruct&lt;/a&gt;ä»¥åŠå¯¹åº”çš„&lt;a href=&#34;https://llama.family/docs/chat-completion-v1&#34;&gt;å…è´¹APIè°ƒç”¨&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2024å¹´04æœˆ19æ—¥ï¼šç¤¾åŒºå¢åŠ äº†llama3 8Bã€llama3 70B&lt;a href=&#34;https://llama.family/chat/#/&#34;&gt;åœ¨çº¿ä½“éªŒé“¾æ¥&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2024å¹´04æœˆ14æ—¥ï¼šç¤¾åŒºæ›´æ–°äº†å››ä¸ªä¸“å®¶è§’è‰²ï¼šå¿ƒç†å’¨è¯¢å¸ˆã€ç¾Šé©¼å¤¸å¤¸ ã€å¾‹å¸ˆã€åŒ»ç”Ÿã€‚é“¾æ¥ï¼š&lt;a href=&#34;https://llama.family/tools/#/agent&#34;&gt;è§’è‰²role&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2024å¹´04æœˆ10æ—¥ï¼šAtom-7B-Chat æ¨¡å‹å›ç­”å†…å®¹ç›¸è¾ƒä¹‹å‰æ›´ä¸ºä¸°å¯Œã€å¢å¼ºäº†æ¨¡å‹çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›å’Œå›ç­”ç¨³å®šæ€§ã€ä¼˜åŒ–äº†ppoçš„å¥–åŠ±æ¨¡å‹ã€‚ä¸‹è½½é“¾æ¥&lt;a href=&#34;https://modelscope.cn/models/FlagAlpha/Atom-7B-Chat&#34;&gt;modelscope&lt;/a&gt;ã€&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B-Chat&#34;&gt;Huggingface&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2024å¹´04æœˆ01æ—¥ï¼šç¤¾åŒºä¸Šçº¿äº†Llamaä¸­æ–‡&lt;a href=&#34;https://llama.family/store&#34;&gt;åº”ç”¨å¹³å°&lt;/a&gt;ï¼›åŒæ—¶å¦‚æœä½ æœ‰ä¼˜ç§€çš„çš„åº”ç”¨éœ€è¦æ¨å¹¿å¯ä»¥å¡«å†™&lt;a href=&#34;https://atomecho.feishu.cn/share/base/form/shrcnFqpN71OmBoXDCT6y0TQgIc&#34;&gt;ç”³è¯·è¡¨&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2024å¹´03æœˆ08æ—¥ï¼šå¼€æ”¾äº†å…è´¹APIä¾›å¤§å®¶ä½¿ç”¨ï¼ŒåŒ…å«ï¼ˆAtom-1B,7B,13B 3ç§ä¸­æ–‡å¤§æ¨¡å‹ï¼‰&lt;a href=&#34;https://llama.family/docs/chat-completion-v1&#34;&gt;APIä½¿ç”¨é“¾æ¥&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2024å¹´04æœˆ14æ—¥ï¼šç¤¾åŒºæ›´æ–°äº†å››ä¸ªä¸“å®¶è§’è‰²ï¼šå¿ƒç†å’¨è¯¢å¸ˆã€ç¾Šé©¼å¤¸å¤¸ ã€å¾‹å¸ˆã€åŒ»ç”Ÿã€‚é“¾æ¥ï¼š&lt;a href=&#34;https://llama.family/tools/#/agent&#34;&gt;è§’è‰²role&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2024å¹´04æœˆ10æ—¥ï¼šAtom-7B-Chat æ¨¡å‹å›ç­”å†…å®¹ç›¸è¾ƒä¹‹å‰æ›´ä¸ºä¸°å¯Œã€å¢å¼ºäº†æ¨¡å‹çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›å’Œå›ç­”ç¨³å®šæ€§ã€ä¼˜åŒ–äº†ppoçš„å¥–åŠ±æ¨¡å‹ã€‚ä¸‹è½½é“¾æ¥&lt;a href=&#34;https://modelscope.cn/models/FlagAlpha/Atom-7B-Chat&#34;&gt;modelscope&lt;/a&gt;ã€&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B-Chat&#34;&gt;Huggingface&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2024å¹´04æœˆ01æ—¥ï¼šç¤¾åŒºä¸Šçº¿äº†Llamaä¸­æ–‡&lt;a href=&#34;https://llama.family/store&#34;&gt;åº”ç”¨å¹³å°&lt;/a&gt;ï¼›åŒæ—¶å¦‚æœä½ æœ‰ä¼˜ç§€çš„çš„åº”ç”¨éœ€è¦æ¨å¹¿å¯ä»¥å¡«å†™&lt;a href=&#34;https://atomecho.feishu.cn/share/base/form/shrcnFqpN71OmBoXDCT6y0TQgIc&#34;&gt;ç”³è¯·è¡¨&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2024å¹´03æœˆ28æ—¥ï¼š&lt;a href=&#34;https://mp.weixin.qq.com/s/CsturoU1pOX11CqVnZgu2A&#34;&gt;ç¤¾åŒºå…è´¹å…¬å¼€è¯¾&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2024å¹´03æœˆ08æ—¥ï¼šå¼€æ”¾äº†å…è´¹APIä¾›å¤§å®¶ä½¿ç”¨ï¼ŒåŒ…å«ï¼ˆAtom-1B,7B,13B 3ç§ä¸­æ–‡å¤§æ¨¡å‹ï¼‰&lt;a href=&#34;https://llama.family/docs/chat-completion-v1&#34;&gt;APIä½¿ç”¨é“¾æ¥&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2023å¹´10æœˆ8æ—¥ï¼šæ–°å¢æ¸…åå¤§å­¦JittorLLMsçš„æ¨ç†åŠ é€ŸåŠŸèƒ½&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#jittorllms&#34;&gt;JittorLLMs&lt;/a&gt;ï¼&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2023å¹´9æœˆ12æ—¥ï¼šæ›´æ–°é¢„è®­ç»ƒç‰ˆæœ¬&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B&#34;&gt;Atom-7B&lt;/a&gt;å’Œå¯¹è¯ç‰ˆæœ¬&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B-Chat&#34;&gt;Atom-7B-Chat&lt;/a&gt;æ¨¡å‹å‚æ•°ï¼Œæœ€æ–°çš„ä¸­æ–‡é¢„è®­ç»ƒæ•°æ®é‡ä¸º2.7TB tokenï¼Œè®­ç»ƒè¿›ç¨‹è§&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;ï¼&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2023å¹´9æœˆ2æ—¥ï¼šæ–°å¢æ¨¡å‹&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83&#34;&gt;é¢„è®­ç»ƒä»£ç &lt;/a&gt;å’Œ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83&#34;&gt;å…¨é‡å‚æ•°å¾®è°ƒä»£ç &lt;/a&gt;ï¼&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´8æœˆ28æ—¥ï¼šå‘å¸ƒåŸºäºLlama2è¿›è¡Œä¸­æ–‡é¢„è®­ç»ƒçš„å¼€æºå¤§æ¨¡å‹&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B&#34;&gt;Atom-7B&lt;/a&gt;ï¼Œå¹¶å°†æŒç»­æ›´æ–°ï¼Œè¯¦æƒ…å‚è€ƒ&lt;a href=&#34;https://mp.weixin.qq.com/s/Bdx0JTVh1kgPn5ydYxIkEw&#34;&gt;ç¤¾åŒºå…¬ä¼—å·æ–‡ç« &lt;/a&gt;ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´8æœˆ26æ—¥ï¼šæä¾›&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#fastapi%E6%8E%A5%E5%8F%A3%E6%90%AD%E5%BB%BA&#34;&gt;FastAPI&lt;/a&gt;æ¥å£æ­å»ºè„šæœ¬ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´8æœˆ26æ—¥ï¼šæä¾›å°†MetaåŸå§‹æ¨¡å‹å‚æ•°è½¬æ¢ä¸ºå…¼å®¹Hugging Faceçš„&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/scripts/convert2hf/README.md&#34;&gt;æ ¼å¼è½¬åŒ–è„šæœ¬&lt;/a&gt;ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´8æœˆ26æ—¥ï¼šæ–°å¢&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E4%BB%A3%E7%A0%81%E6%A8%A1%E5%9E%8B&#34;&gt;Code Llama&lt;/a&gt;æ¨¡å‹ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´8æœˆ15æ—¥ï¼šæ–°å¢&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%8A%A0%E8%BD%BD%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B&#34;&gt;PEFTåŠ è½½å¾®è°ƒæ¨¡å‹å‚æ•°&lt;/a&gt;çš„ä»£ç ç¤ºä¾‹ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´8æœˆ14æ—¥ï¼š&lt;a href=&#34;https://llama.family&#34;&gt;å¤§æ¨¡å‹æ•°æ®å…±äº«è®­ç»ƒå¹³å°&lt;/a&gt;ä¸Šçº¿ï¼Œæ²¡æœ‰ç®—åŠ›ä¹Ÿèƒ½å‚ä¸å¤§æ¨¡å‹è®­ç»ƒï¼Œç¤¾åŒºæ¯ä½æˆå‘˜è´¡çŒ®çš„æ•°æ®éƒ½å°†å†³å®šæ¨¡å‹èƒ½åŠ›çš„æœªæ¥èµ°å‘ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´8æœˆ3æ—¥ï¼šæ–°å¢FasterTransformerå’ŒvLLMçš„GPU&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F&#34;&gt;æ¨ç†åŠ é€Ÿ&lt;/a&gt;æ”¯æŒï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ31æ—¥ï¼šã€é‡ç£…ã€‘å›½å†…é¦–ä¸ªçœŸæ­£æ„ä¹‰ä¸Šçš„Llama2ä¸­æ–‡å¤§æ¨¡å‹å‘å¸ƒï¼è¯¦æƒ…å‚è§&lt;a href=&#34;https://mp.weixin.qq.com/s/lExUU7z_MvgJ7tzQPF8tUQ&#34;&gt;ç¤¾åŒºå…¬ä¼—å·æ–‡ç« &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ28æ—¥ï¼šé€šè¿‡&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#docker%E9%83%A8%E7%BD%B2%E9%97%AE%E7%AD%94%E6%8E%A5%E5%8F%A3&#34;&gt;Dockeréƒ¨ç½²&lt;/a&gt;é—®ç­”æ¥å£ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ27æ—¥ï¼šæ–°å¢&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#langchain&#34;&gt;LangChain&lt;/a&gt;æ”¯æŒï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ26æ—¥ï¼šæ–°å¢Llama2-13Bä¸­æ–‡å¾®è°ƒå‚æ•°çš„&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96&#34;&gt;4bité‡åŒ–å‹ç¼©ç‰ˆæœ¬&lt;/a&gt;ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ25æ—¥ï¼šç¤¾åŒºå¾®ä¿¡å…¬ä¼—å·â€œLlamaä¸­æ–‡ç¤¾åŒºâ€æ¬¢è¿å¤§å®¶å…³æ³¨ï¼Œè·å–æœ€æ–°åˆ†äº«å’ŒåŠ¨æ€ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ24æ—¥ï¼š&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;FlagAlpha&lt;/a&gt;æ–°å¢Llama2-13Bä¸­æ–‡å¾®è°ƒå‚æ•°ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ24æ—¥ï¼š&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;æ–°å¢Llama2-70Båœ¨çº¿ä½“éªŒï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ23æ—¥ï¼šLlama2ä¸­æ–‡å¾®è°ƒå‚æ•°å‘å¸ƒè‡³Hugging Faceä»“åº“&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;FlagAlpha&lt;/a&gt;ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ22æ—¥ï¼šLlama2åœ¨çº¿ä½“éªŒé“¾æ¥&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;ä¸Šçº¿ï¼ŒåŒæ—¶åŒ…å«MetaåŸç‰ˆå’Œä¸­æ–‡å¾®è°ƒç‰ˆæœ¬ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ21æ—¥ï¼šè¯„æµ‹äº†MetaåŸå§‹ç‰ˆLlama2 Chatæ¨¡å‹çš„&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B&#34;&gt;ä¸­æ–‡é—®ç­”èƒ½åŠ›&lt;/a&gt;ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ21æ—¥ï¼šæ–°å¢Llama2æ¨¡å‹çš„Hugging Faceç‰ˆæœ¬å›½å†…ä¸‹è½½åœ°å€ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ20æ—¥ï¼šæ–°å¢&lt;a href=&#34;https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink&#34;&gt;é£ä¹¦çŸ¥è¯†åº“æ–‡æ¡£&lt;/a&gt;ï¼Œæ¬¢è¿å¤§å®¶ä¸€èµ·å…±å»ºï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ20æ—¥ï¼šå›½å†…Llama2æœ€æ–°ä¸‹è½½åœ°å€ä¸Šçº¿ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ19æ—¥ï¼šæ­£å¼å¯åŠ¨Llama2æ¨¡å‹çš„ä¸­æ–‡é¢„è®­ç»ƒï¼Œå…³æ³¨æˆ‘ä»¬è·å–å®æ—¶åŠ¨æ€ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ19æ—¥ï¼šLlama2å›½å†…ä¸‹è½½åœ°å€æ­£åœ¨å¯åŠ¨ï¼Œæ•¬è¯·æœŸå¾…ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ19æ—¥ï¼šå¼€å¯Llama2ä¸­æ–‡ç¤¾åŒºï¼Œæ¬¢è¿å¤§å®¶åŠ å…¥ï¼&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;ğŸ¤— æ¨¡å‹&lt;/h3&gt; &#xA;&lt;h4&gt;ğŸ”µ ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹Atom&lt;/h4&gt; &#xA;&lt;p&gt;&lt;strong&gt;åŸå­å¤§æ¨¡å‹Atom&lt;/strong&gt;ç”±Llamaä¸­æ–‡ç¤¾åŒºå’ŒåŸå­å›å£°è”åˆæ‰“é€ ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ç±»åˆ«&lt;/th&gt; &#xA;   &lt;th&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ğŸ¤—æ¨¡å‹åŠ è½½åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ä¸‹è½½åœ°å€&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;é¢„è®­ç»ƒ&lt;/td&gt; &#xA;   &lt;td&gt;Atom-7B&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Atom-7B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://modelscope.cn/models/FlagAlpha/Atom-7B&#34;&gt;ModelScope&lt;/a&gt; | &lt;a href=&#34;https://wisemodel.cn/models/FlagAlpha/Atom-7B&#34;&gt;WiseModel&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;Atom-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Atom-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B-Chat&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://modelscope.cn/models/FlagAlpha/Atom-7B-Chat&#34;&gt;ModelScope&lt;/a&gt; | &lt;a href=&#34;https://wisemodel.cn/models/FlagAlpha/Atom-7B-Chat&#34;&gt;WiseModel&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Atomç³»åˆ—æ¨¡å‹åŒ…å«Atom-13Bã€Atom-7Bå’ŒAtom-1Bï¼ŒåŸºäºLlama2åšäº†ä¸­æ–‡èƒ½åŠ›çš„æŒç»­ä¼˜åŒ–ã€‚Atom-7Bå’ŒAtom-7B-Chatç›®å‰å·²å®Œå…¨å¼€æºï¼Œæ”¯æŒå•†ç”¨ï¼Œå¯åœ¨&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;Hugging Face&lt;/a&gt;ä»“åº“è·å–æ¨¡å‹ï¼Œè¯¦æƒ…è§&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%9F%BA%E4%BA%8Ellama2%E7%9A%84%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8Batom&#34;&gt;Atom-7Bä¸‹è½½&lt;/a&gt;ã€‚Atomå¤§æ¨¡å‹é’ˆå¯¹ä¸­æ–‡åšäº†ä»¥ä¸‹ä¼˜åŒ–ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;å¤§è§„æ¨¡çš„ä¸­æ–‡æ•°æ®é¢„è®­ç»ƒ&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;åŸå­å¤§æ¨¡å‹Atomåœ¨Llama2çš„åŸºç¡€ä¸Šï¼Œé‡‡ç”¨å¤§è§„æ¨¡çš„ä¸­æ–‡æ•°æ®è¿›è¡ŒæŒç»­é¢„è®­ç»ƒï¼ŒåŒ…å«ç™¾ç§‘ã€ä¹¦ç±ã€åšå®¢ã€æ–°é—»ã€å…¬å‘Šã€å°è¯´ã€é‡‘èæ•°æ®ã€æ³•å¾‹æ•°æ®ã€åŒ»ç–—æ•°æ®ã€ä»£ç æ•°æ®ã€ä¸“ä¸šè®ºæ–‡æ•°æ®ã€ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†ç«èµ›æ•°æ®é›†ç­‰ï¼Œè¯¦è§&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90&#34;&gt;ğŸ“ æ•°æ®æ¥æº&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;åŒæ—¶å¯¹åºå¤§çš„æ•°æ®è¿›è¡Œäº†è¿‡æ»¤ã€æ‰“åˆ†ã€å»é‡ï¼Œç­›é€‰å‡ºè¶…è¿‡1T tokençš„é«˜è´¨é‡ä¸­æ–‡æ•°æ®ï¼ŒæŒç»­ä¸æ–­åŠ å…¥è®­ç»ƒè¿­ä»£ä¸­ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;æ›´é«˜æ•ˆçš„ä¸­æ–‡è¯è¡¨ ä¸ºäº†æé«˜ä¸­æ–‡æ–‡æœ¬å¤„ç†çš„æ•ˆç‡ï¼Œæˆ‘ä»¬é’ˆå¯¹Llama2æ¨¡å‹çš„è¯è¡¨è¿›è¡Œäº†æ·±åº¦ä¼˜åŒ–ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åŸºäºæ•°ç™¾Gçš„ä¸­æ–‡æ–‡æœ¬ï¼Œåœ¨è¯¥æ¨¡å‹è¯è¡¨çš„åŸºç¡€ä¸Šæ‰©å±•è¯åº“è‡³65,000ä¸ªå•è¯ã€‚ç»è¿‡æµ‹è¯•ï¼Œæˆ‘ä»¬çš„æ”¹è¿›ä½¿å¾—ä¸­æ–‡ç¼–ç /è§£ç é€Ÿåº¦æé«˜äº†çº¦350ï¼…ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ‰©å¤§äº†ä¸­æ–‡å­—ç¬¦é›†çš„è¦†ç›–èŒƒå›´ï¼ŒåŒ…æ‹¬æ‰€æœ‰emojiç¬¦å·ğŸ˜Šã€‚è¿™ä½¿å¾—ç”Ÿæˆå¸¦æœ‰è¡¨æƒ…ç¬¦å·çš„æ–‡ç« æ›´åŠ é«˜æ•ˆã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;è‡ªé€‚åº”ä¸Šä¸‹æ–‡æ‰©å±• Atomå¤§æ¨¡å‹é»˜è®¤æ”¯æŒ4Kä¸Šä¸‹æ–‡ï¼Œåˆ©ç”¨ä½ç½®æ’å€¼PIå’ŒNeural Tangent Kernel ï¼ˆNTKï¼‰æ–¹æ³•ï¼Œç»è¿‡å¾®è°ƒå¯ä»¥å°†ä¸Šä¸‹æ–‡é•¿åº¦æ‰©å¢åˆ°32Kã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ğŸ“ ä¸­æ–‡æ•°æ®&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹æ•°æ®æ¥ä¼˜åŒ–Llama2çš„ä¸­æ–‡èƒ½åŠ›:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ç±»å‹&lt;/th&gt; &#xA;   &lt;th&gt;æè¿°&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ç½‘ç»œæ•°æ®&lt;/td&gt; &#xA;   &lt;td&gt;äº’è”ç½‘ä¸Šå…¬å¼€çš„ç½‘ç»œæ•°æ®ï¼ŒæŒ‘é€‰å‡ºå»é‡åçš„é«˜è´¨é‡ä¸­æ–‡æ•°æ®ï¼Œæ¶‰åŠåˆ°ç™¾ç§‘ã€ä¹¦ç±ã€åšå®¢ã€æ–°é—»ã€å…¬å‘Šã€å°è¯´ç­‰é«˜è´¨é‡é•¿æ–‡æœ¬æ•°æ®ã€‚&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/goldsmith/Wikipedia&#34;&gt;Wikipedia&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸­æ–‡Wikipediaçš„æ•°æ®&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/BAAI-WuDao/Model&#34;&gt;æ‚Ÿé“&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸­æ–‡æ‚Ÿé“å¼€æºçš„200Gæ•°æ®&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/CLUEbenchmark/CLUEDatasetSearch&#34;&gt;Clue&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Clueå¼€æ”¾çš„ä¸­æ–‡é¢„è®­ç»ƒæ•°æ®ï¼Œè¿›è¡Œæ¸…æ´—åçš„é«˜è´¨é‡ä¸­æ–‡é•¿æ–‡æœ¬æ•°æ®&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ç«èµ›æ•°æ®é›†&lt;/td&gt; &#xA;   &lt;td&gt;è¿‘å¹´æ¥ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†å¤šä»»åŠ¡ç«èµ›æ•°æ®é›†ï¼Œçº¦150ä¸ª&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/esbatmop/MNBVC&#34;&gt;MNBVC&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MNBVC ä¸­æ¸…æ´—å‡ºæ¥çš„éƒ¨åˆ†æ•°æ®é›†&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;ç¤¾åŒºæä¾›é¢„è®­ç»ƒç‰ˆæœ¬Atom-7Bå’ŒåŸºäºAtom-7Bè¿›è¡Œå¯¹è¯å¾®è°ƒçš„æ¨¡å‹å‚æ•°ä¾›å¼€æ”¾ä¸‹è½½ï¼Œå…³äºæ¨¡å‹çš„è¿›å±•è¯¦è§ç¤¾åŒºå®˜ç½‘&lt;a href=&#34;https://llama.family&#34;&gt;llama.family&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h4&gt;Llama3å®˜æ–¹æ¨¡å‹&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ç±»åˆ«&lt;/th&gt; &#xA;   &lt;th&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ğŸ¤—æ¨¡å‹åŠ è½½åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ä¸‹è½½åœ°å€&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;é¢„è®­ç»ƒ&lt;/td&gt; &#xA;   &lt;td&gt;Llama3-8B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Meta-Llama-3-8B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3-8B&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.baidu.com/s/1gBZ7wEn3gC8VRok0Onh9BQ?pwd=8frq&#34;&gt;ç™¾åº¦ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;é¢„è®­ç»ƒ&lt;/td&gt; &#xA;   &lt;td&gt;Llama3-70B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Meta-Llama-3-70B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3-7B&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.baidu.com/s/1gBZ7wEn3gC8VRok0Onh9BQ?pwd=8frq&#34;&gt;ç™¾åº¦ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;å¯¹è¯æ¨¡å‹&lt;/td&gt; &#xA;   &lt;td&gt;Llama3-8B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Meta-Llama-3-8B-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.baidu.com/s/1gBZ7wEn3gC8VRok0Onh9BQ?pwd=8frq&#34;&gt;ç™¾åº¦ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;å¯¹è¯æ¨¡å‹&lt;/td&gt; &#xA;   &lt;td&gt;Llama3-70B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Meta-Llama-3-70B-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.baidu.com/s/1gBZ7wEn3gC8VRok0Onh9BQ?pwd=8frq&#34;&gt;ç™¾åº¦ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Llama3ä¸­æ–‡å¾®è°ƒæ¨¡å‹&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ç±»åˆ«&lt;/th&gt; &#xA;   &lt;th&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ğŸ¤—æ¨¡å‹åŠ è½½åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ä¸‹è½½åœ°å€&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;å¯¹è¯æ¨¡å‹&lt;/td&gt; &#xA;   &lt;td&gt;Llama3-Chinese-8B-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama3-Chinese-8B-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama3-Chinese-8B-Instruct&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://modelscope.cn/models/FlagAlpha/Llama3-Chinese-8B-Instruct/summary&#34;&gt;modelscope&lt;/a&gt; | &lt;a href=&#34;https://wisemodel.cn/models/FlagAlpha/Llama3-Chinese-8B-Instruct/file&#34;&gt;wisemodel&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Llama2å®˜æ–¹æ¨¡å‹&lt;/h4&gt; &#xA;&lt;details&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;ç±»åˆ«&lt;/th&gt; &#xA;    &lt;th&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;    &lt;th&gt;ğŸ¤—æ¨¡å‹åŠ è½½åç§°&lt;/th&gt; &#xA;    &lt;th&gt;ä¸‹è½½åœ°å€&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;é¢„è®­ç»ƒ&lt;/td&gt; &#xA;    &lt;td&gt;Llama2-7B&lt;/td&gt; &#xA;    &lt;td&gt;meta-llama/Llama-2-7b-hf&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;é¢„è®­ç»ƒ&lt;/td&gt; &#xA;    &lt;td&gt;Llama2-13B&lt;/td&gt; &#xA;    &lt;td&gt;meta-llama/Llama-2-13b-hf&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-13b-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;é¢„è®­ç»ƒ&lt;/td&gt; &#xA;    &lt;td&gt;Llama2-70B&lt;/td&gt; &#xA;    &lt;td&gt;meta-llama/Llama-2-70b-hf&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-70b-hf&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Chat&lt;/td&gt; &#xA;    &lt;td&gt;Llama2-7B-Chat&lt;/td&gt; &#xA;    &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-chat-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Chat&lt;/td&gt; &#xA;    &lt;td&gt;Llama2-13B-Chat&lt;/td&gt; &#xA;    &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-13b-chat-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Chat&lt;/td&gt; &#xA;    &lt;td&gt;Llama2-70B-Chat&lt;/td&gt; &#xA;    &lt;td&gt;meta-llama/Llama-2-70b-chat-hf&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-70b-chat-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VNa_vCGzCy3h3N7oeFXs2W1hA1?pwd=uhxh#&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Code&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-7b&lt;/td&gt; &#xA;    &lt;td&gt;meta-llama/Llama-2-70b-chat-hf&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://pan.baidu.com/s/1cIPzdNywWLvQI7_2QanOEQ?pwd=zfwi&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Code&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-7b-Python&lt;/td&gt; &#xA;    &lt;td&gt;meta-llama/Llama-2-70b-chat-hf&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://pan.baidu.com/s/1liY8klGoDagYbpw-g-oFag?pwd=i952&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Code&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-7b-Instruct&lt;/td&gt; &#xA;    &lt;td&gt;meta-llama/Llama-2-70b-chat-hf&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://pan.baidu.com/s/108o9_DT2E_vfSGtOnDCQVw?pwd=zkt9&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Code&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-13b&lt;/td&gt; &#xA;    &lt;td&gt;meta-llama/Llama-2-70b-chat-hf&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://pan.baidu.com/s/1lLaeHv0XEBv0iiZzI1dpnw?pwd=qn99&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Code&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-13b-Python&lt;/td&gt; &#xA;    &lt;td&gt;meta-llama/Llama-2-70b-chat-hf&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://pan.baidu.com/s/1OLVfvZS_oqL3oqMKwsI87w?pwd=a78k&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Code&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-13b-Instruct&lt;/td&gt; &#xA;    &lt;td&gt;meta-llama/Llama-2-70b-chat-hf&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://pan.baidu.com/s/1HyxJl4w8wElgkZRh2ATrXQ?pwd=seg6&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Code&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-34b&lt;/td&gt; &#xA;    &lt;td&gt;meta-llama/Llama-2-70b-chat-hf&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://pan.baidu.com/s/1vEw0pFgIkctPUN4_5_6pIQ?pwd=q8eu&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;p&gt;Metaå®˜æ–¹åœ¨2023å¹´8æœˆ24æ—¥å‘å¸ƒäº†Code Llamaï¼ŒåŸºäºä»£ç æ•°æ®å¯¹Llama2è¿›è¡Œäº†å¾®è°ƒï¼Œæä¾›ä¸‰ä¸ªä¸åŒåŠŸèƒ½çš„ç‰ˆæœ¬ï¼šåŸºç¡€æ¨¡å‹ï¼ˆCode Llamaï¼‰ã€Pythonä¸“ç”¨æ¨¡å‹ï¼ˆCode Llama - Pythonï¼‰å’ŒæŒ‡ä»¤è·Ÿéšæ¨¡å‹ï¼ˆCode Llama - Instructï¼‰ï¼ŒåŒ…å«7Bã€13Bã€34Bä¸‰ç§ä¸åŒå‚æ•°è§„æ¨¡ã€‚ä¸åŒæ¨¡å‹èƒ½åŠ›åŒºåˆ«å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;æ¨¡å‹ç±»åˆ«&lt;/th&gt; &#xA;    &lt;th&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;    &lt;th&gt;ä»£ç ç»­å†™&lt;/th&gt; &#xA;    &lt;th&gt;ä»£ç å¡«å……&lt;/th&gt; &#xA;    &lt;th&gt;æŒ‡ä»¤ç¼–ç¨‹&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Code Llama&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-7b&lt;/td&gt; &#xA;    &lt;td&gt;âœ…&lt;/td&gt; &#xA;    &lt;td&gt;âœ…&lt;/td&gt; &#xA;    &lt;td&gt;âŒ&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-13b&lt;/td&gt; &#xA;    &lt;td&gt;âœ…&lt;/td&gt; &#xA;    &lt;td&gt;âœ…&lt;/td&gt; &#xA;    &lt;td&gt;âŒ&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-34b&lt;/td&gt; &#xA;    &lt;td&gt;âœ…&lt;/td&gt; &#xA;    &lt;td&gt;âŒ&lt;/td&gt; &#xA;    &lt;td&gt;âŒ&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Code Llama - Python&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-7b-Python&lt;/td&gt; &#xA;    &lt;td&gt;âœ…&lt;/td&gt; &#xA;    &lt;td&gt;âŒ&lt;/td&gt; &#xA;    &lt;td&gt;âŒ&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-13b-Python&lt;/td&gt; &#xA;    &lt;td&gt;âœ…&lt;/td&gt; &#xA;    &lt;td&gt;âŒ&lt;/td&gt; &#xA;    &lt;td&gt;âŒ&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-34b-Python&lt;/td&gt; &#xA;    &lt;td&gt;âœ…&lt;/td&gt; &#xA;    &lt;td&gt;âŒ&lt;/td&gt; &#xA;    &lt;td&gt;âŒ&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Code Llama - Instruct&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-7b-Instruct&lt;/td&gt; &#xA;    &lt;td&gt;âŒ&lt;/td&gt; &#xA;    &lt;td&gt;âœ…&lt;/td&gt; &#xA;    &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-13b-Instruct&lt;/td&gt; &#xA;    &lt;td&gt;âŒ&lt;/td&gt; &#xA;    &lt;td&gt;âœ…&lt;/td&gt; &#xA;    &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;CodeLlama-34b-Instruct&lt;/td&gt; &#xA;    &lt;td&gt;âŒ&lt;/td&gt; &#xA;    &lt;td&gt;âŒ&lt;/td&gt; &#xA;    &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;p&gt;å…³äºCode Llamaçš„è¯¦ç»†ä¿¡æ¯å¯ä»¥å‚è€ƒå®˜æ–¹Githubä»“åº“&lt;a href=&#34;https://github.com/facebookresearch/codellama&#34;&gt;codellama&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h4&gt;Llama2ä¸­æ–‡å¾®è°ƒæ¨¡å‹&lt;/h4&gt; &#xA;&lt;p&gt;æˆ‘ä»¬åŸºäºä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†å¯¹Llama2-Chatæ¨¡å‹è¿›è¡Œäº†å¾®è°ƒï¼Œä½¿å¾—Llama2æ¨¡å‹æœ‰ç€æ›´å¼ºçš„ä¸­æ–‡å¯¹è¯èƒ½åŠ›ã€‚LoRAå‚æ•°ä»¥åŠä¸åŸºç¡€æ¨¡å‹åˆå¹¶çš„å‚æ•°å‡å·²ä¸Šä¼ è‡³&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;Hugging Face&lt;/a&gt;ï¼Œç›®å‰åŒ…å«7Bå’Œ13Bçš„æ¨¡å‹ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ç±»åˆ«&lt;/th&gt; &#xA;   &lt;th&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ğŸ¤—æ¨¡å‹åŠ è½½åç§°&lt;/th&gt; &#xA;   &lt;th&gt;åŸºç¡€æ¨¡å‹ç‰ˆæœ¬&lt;/th&gt; &#xA;   &lt;th&gt;ä¸‹è½½åœ°å€&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;åˆå¹¶å‚æ•°&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-Chinese-7b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-7b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;åˆå¹¶å‚æ•°&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-Chinese-13b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-13b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRAå‚æ•°&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-Chinese-7b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-7b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat-LoRA&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRAå‚æ•°&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-Chinese-13b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-13b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-LoRA&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;ç¤¾åŒºèµ„æº&lt;/h3&gt; &#xA;&lt;p&gt;ç¤¾åŒºèµ„æºçš„ä¸°å¯Œæ€§æ˜¯ç¤¾åŒºå‘å±•çš„é‡è¦ä¿éšœï¼Œå®ƒæ¶µç›–äº†å„ç§æ–¹é¢ï¼Œå…¶ä¸­åŒ…æ‹¬ä½†ä¸é™äºä»¥ä¸‹å››ä¸ªæ–¹é¢ï¼šç®—åŠ›ã€æ•°æ®ã€è®ºå›å’Œåº”ç”¨ã€‚åœ¨è¿™äº›æ–¹é¢çš„ç§¯æå‘å±•ä¸å……åˆ†åˆ©ç”¨ï¼Œå°†ä¸ºç¤¾åŒºæˆå‘˜æä¾›æ›´å¤šçš„æœºä¼šå’Œæ”¯æŒï¼Œæ¨åŠ¨æ•´ä¸ªç¤¾åŒºå‘ç€æ›´åŠ ç¹è£çš„æ–¹å‘å‘å±•ã€‚æ›´å¤šçš„å†…å®¹è¯·çœ‹&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;h4&gt;ğŸ’» ç®—åŠ›&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;æä¾›ä½äºå¸‚åœºä»·æ ¼çš„ç®—åŠ›èµ„æºï¼Œå¯ç”¨äºå„ç±»è®¡ç®—ä»»åŠ¡ï¼Œå¦‚æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒã€æ¨ç†ç­‰ã€‚&lt;/li&gt; &#xA;  &lt;li&gt;ä¸ºç¤¾åŒºæˆå‘˜æä¾›ä¸“å±çš„åœ¨çº¿æ¨ç†æœåŠ¡ï¼Œè®©ç”¨æˆ·å¯ä»¥å¿«é€Ÿæœ‰æ•ˆåœ°å¯¹æ¨¡å‹è¿›è¡Œæ¨ç†æ“ä½œã€‚&lt;/li&gt; &#xA;  &lt;li&gt;æä¾›ä¸€é”®åœ¨çº¿å¾®è°ƒæœåŠ¡ï¼Œä½¿ç”¨æˆ·å¯ä»¥æ–¹ä¾¿åœ°å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”ä¸åŒçš„ä»»åŠ¡å’Œæ•°æ®ã€‚&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;ğŸ“Š æ•°æ®&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;å¼€æ”¾ä¸°å¯Œçš„è®­ç»ƒæ•°æ®èµ„æºï¼Œè¦†ç›–å¤šä¸ªé¢†åŸŸå’Œè¡Œä¸šï¼Œä¸ºæ¨¡å‹è®­ç»ƒæä¾›å……è¶³çš„æ•°æ®æ”¯æŒã€‚&lt;/li&gt; &#xA;  &lt;li&gt;æä¾›é«˜è´¨é‡ã€å¤šæ ·åŒ–çš„æ•°æ®é›†ï¼Œä»¥æ»¡è¶³ä¸åŒç”¨æˆ·çš„éœ€æ±‚ï¼Œå¹¶æ”¯æŒæ•°æ®å…±äº«å’Œäº¤æµï¼Œä¿ƒè¿›æ•°æ®èµ„æºçš„å……åˆ†åˆ©ç”¨ã€‚&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;ğŸ’¬ è®ºå›&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;ç¤¾åŒºè®ºå›ä¸ºç¤¾åŒºæˆå‘˜æä¾›äº†ä¸€ä¸ªåœ¨çº¿äº¤æµå’Œè®¨è®ºæŠ€æœ¯é—®é¢˜çš„å¹³å°ã€‚&lt;/li&gt; &#xA;  &lt;li&gt;åœ¨è®ºå›ä¸Šï¼Œç”¨æˆ·å¯ä»¥åˆ†äº«ç»éªŒã€æå‡ºé—®é¢˜ã€è§£ç­”ç–‘æƒ‘ï¼Œä¿ƒè¿›æŠ€æœ¯äº¤æµå’Œåˆä½œã€‚&lt;/li&gt; &#xA;  &lt;li&gt;è®ºå›è¿˜å¯ä»¥å®šæœŸä¸¾åŠçº¿ä¸Šæ´»åŠ¨ã€ç ”è®¨ä¼šç­‰ï¼Œå¢è¿›ç¤¾åŒºæˆå‘˜ä¹‹é—´çš„è”ç³»å’Œäº†è§£ã€‚&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;ğŸ“± åº”ç”¨&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;å…è´¹æä¾›åº”ç”¨æ¨å¹¿å±•ç¤ºä½ï¼Œè®©å¼€å‘è€…å¯ä»¥å°†ä»–ä»¬çš„åº”ç”¨å……åˆ†å±•ç¤ºç»™ç¤¾åŒºæˆå‘˜ã€‚&lt;/li&gt; &#xA;  &lt;li&gt;æä¾›æ¨å¹¿çš„å¸®åŠ©ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºå®£ä¼ æ¨å¹¿ã€ç”¨æˆ·å¼•å¯¼ç­‰æœåŠ¡ï¼Œå¸®åŠ©åº”ç”¨è·å¾—æ›´å¤šçš„æ›å…‰å’Œç”¨æˆ·ã€‚&lt;/li&gt; &#xA;  &lt;li&gt;é€šè¿‡ç¤¾åŒºå¹³å°ï¼Œä¸ºä¼˜ç§€çš„åº”ç”¨æä¾›åˆä½œæœºä¼šï¼Œä¿ƒè¿›åº”ç”¨å¼€å‘è€…ä¹‹é—´çš„åˆä½œå’Œäº¤æµï¼Œå…±åŒæ¨åŠ¨åº”ç”¨çš„å‘å±•å’Œå£®å¤§ã€‚&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;ğŸ“Œ å¦‚ä½•ä½¿ç”¨Llamaæ¨¡å‹?&lt;/h2&gt; &#xA;&lt;p&gt;ä½ å¯ä»¥é€‰æ‹©ä¸‹é¢çš„å¿«é€Ÿä¸Šæ‰‹çš„ä»»ä¸€ç§æ–¹å¼ï¼Œå¼€å§‹ä½¿ç”¨ Llama ç³»åˆ—æ¨¡å‹ã€‚æ¨èä½¿ç”¨&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama2%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8Batom-7b&#34;&gt;ä¸­æ–‡é¢„è®­ç»ƒå¯¹è¯æ¨¡å‹&lt;/a&gt;è¿›è¡Œä½¿ç”¨ï¼Œå¯¹ä¸­æ–‡çš„æ•ˆæœæ”¯æŒæ›´å¥½ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨Anaconda&lt;/h3&gt; &#xA;&lt;p&gt;ç¬¬ 0 æ­¥ï¼šå‰ææ¡ä»¶&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ç¡®ä¿å®‰è£…äº† Python 3.10 ä»¥ä¸Šç‰ˆæœ¬ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;ç¬¬ 1 æ­¥ï¼šå‡†å¤‡ç¯å¢ƒ&lt;/p&gt; &#xA;&lt;p&gt;å¦‚éœ€è®¾ç½®ç¯å¢ƒï¼Œå®‰è£…æ‰€éœ€è¦çš„è½¯ä»¶åŒ…ï¼Œè¿è¡Œä¸‹é¢çš„å‘½ä»¤ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/LlamaFamily/Llama-Chinese.git&#xA;cd Llama-Chinese&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ç¬¬ 2 æ­¥ï¼šä¸‹è½½æ¨¡å‹&lt;/p&gt; &#xA;&lt;p&gt;ä½ å¯ä»¥ä»ä»¥ä¸‹æ¥æºä¸‹è½½Atom-7B-Chatæ¨¡å‹ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;HuggingFace&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.cn/organization/FlagAlpha&#34;&gt;ModelScope&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://wisemodel.cn/models/FlagAlpha/Atom-7B-Chat&#34;&gt;WideModel&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;ç¬¬ 3 æ­¥ï¼šè¿›è¡Œæ¨ç†&lt;/p&gt; &#xA;&lt;p&gt;ä½¿ç”¨Atom-7B-Chatæ¨¡å‹è¿›è¡Œæ¨ç† åˆ›å»ºä¸€ä¸ªåä¸º quick_start.py çš„æ–‡ä»¶ï¼Œå¹¶å°†ä»¥ä¸‹å†…å®¹å¤åˆ¶åˆ°è¯¥æ–‡ä»¶ä¸­ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;device_map = &#34;cuda:0&#34; if torch.cuda.is_available() else &#34;auto&#34;&#xA;model = AutoModelForCausalLM.from_pretrained(&#39;FlagAlpha/Atom-7B-Chat&#39;,device_map=device_map,torch_dtype=torch.float16,load_in_8bit=True,trust_remote_code=True,use_flash_attention_2=True)&#xA;model =model.eval()&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;FlagAlpha/Atom-7B-Chat&#39;,use_fast=False)&#xA;tokenizer.pad_token = tokenizer.eos_token&#xA;input_ids = tokenizer([&#39;&amp;lt;s&amp;gt;Human: ä»‹ç»ä¸€ä¸‹ä¸­å›½\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#39;], return_tensors=&#34;pt&#34;,add_special_tokens=False).input_ids&#xA;if torch.cuda.is_available():&#xA;  input_ids = input_ids.to(&#39;cuda&#39;)&#xA;generate_input = {&#xA;    &#34;input_ids&#34;:input_ids,&#xA;    &#34;max_new_tokens&#34;:512,&#xA;    &#34;do_sample&#34;:True,&#xA;    &#34;top_k&#34;:50,&#xA;    &#34;top_p&#34;:0.95,&#xA;    &#34;temperature&#34;:0.3,&#xA;    &#34;repetition_penalty&#34;:1.3,&#xA;    &#34;eos_token_id&#34;:tokenizer.eos_token_id,&#xA;    &#34;bos_token_id&#34;:tokenizer.bos_token_id,&#xA;    &#34;pad_token_id&#34;:tokenizer.pad_token_id&#xA;}&#xA;generate_ids  = model.generate(**generate_input)&#xA;text = tokenizer.decode(generate_ids[0])&#xA;print(text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;è¿è¡Œ quick_start.py ä»£ç ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python quick_start.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨Docker&lt;/h3&gt; &#xA;&lt;p&gt;è¯¦æƒ…å‚è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/docs/chat_gradio_guide.md&#34;&gt;Dockeréƒ¨ç½²&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;ç¬¬ 1 æ­¥ï¼šå‡†å¤‡dockeré•œåƒï¼Œé€šè¿‡dockerå®¹å™¨å¯åŠ¨&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/examples/chat_gradio.py&#34;&gt;chat_gradio.py&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/LlamaFamily/Llama-Chinese.git&#xA;&#xA;cd Llama-Chinese&#xA;&#xA;docker build -f docker/Dockerfile -t flagalpha/llama2-chinese:gradio .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ç¬¬ 2 æ­¥ï¼šé€šè¿‡docker-composeå¯åŠ¨chat_gradio&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd Llama-Chinese/docker&#xA;docker-compose up -d --build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨llama.cpp&lt;/h3&gt; &#xA;&lt;p&gt;è¯¦æƒ…å‚è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/inference-speed/CPU/ggml/README.md&#34;&gt;ä½¿ç”¨llama.cpp&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;å¿«é€Ÿä¸Šæ‰‹-ä½¿ç”¨gradio&lt;/h3&gt; &#xA;&lt;p&gt;åŸºäºgradioæ­å»ºçš„é—®ç­”ç•Œé¢ï¼Œå®ç°äº†æµå¼çš„è¾“å‡ºï¼Œå°†ä¸‹é¢ä»£ç å¤åˆ¶åˆ°æ§åˆ¶å°è¿è¡Œï¼Œä»¥ä¸‹ä»£ç ä»¥Atom-7B-Chatæ¨¡å‹ä¸ºä¾‹ï¼Œä¸åŒæ¨¡å‹åªéœ€ä¿®æ”¹ä¸€ä¸‹é¢çš„model_name_or_pathå¯¹åº”çš„æ¨¡å‹åç§°å°±å¥½äº†ğŸ˜Š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python examples/chat_gradio.py --model_name_or_path FlagAlpha/Atom-7B-Chat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;å¿«é€Ÿä¸Šæ‰‹-æ„å»ºAPIæœåŠ¡&lt;/h3&gt; &#xA;&lt;p&gt;ä½¿ç”¨FastChatæ„å»ºå’ŒOpenAIä¸€è‡´çš„æ¨ç†æœåŠ¡æ¥å£ã€‚&lt;/p&gt; &#xA;&lt;details&gt;&#xA;  ç¬¬ 0 æ­¥ï¼šå‰ææ¡ä»¶ &#xA; &lt;p&gt;å®‰è£…fastchat&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip3 install &#34;fschat[model_worker,webui]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;ç¬¬ 1 æ­¥ï¼šå¯åŠ¨Restful API&lt;/p&gt; &#xA; &lt;p&gt;å¼€å¯ä¸‰ä¸ªæ§åˆ¶å°åˆ†åˆ«æ‰§è¡Œä¸‹é¢çš„ä¸‰ä¸ªå‘½ä»¤&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;é¦–å…ˆå¯åŠ¨controler&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 -m fastchat.serve.controller \&#xA;--host localhost \&#xA;--port 21001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;å¯åŠ¨æ¨¡å‹&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=&#34;0&#34; python3 -m fastchat.serve.model_worker --model-path /path/Atom-7B-Chat \&#xA;--host localhost \&#xA;--port 21002 \&#xA;--worker-address &#34;http://localhost:21002&#34; \&#xA;--limit-worker-concurrency 5 \&#xA;--stream-interval 2 \&#xA;--gpus &#34;1&#34; \&#xA;--load-8bit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;å¯åŠ¨RESTful API æœåŠ¡&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 -m fastchat.serve.openai_api_server \&#xA;--host localhost \&#xA;--port 21003 \&#xA;--controller-address http://localhost:21001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;ç¬¬ 2 æ­¥ï¼šæµ‹è¯•apiæœåŠ¡&lt;/p&gt; &#xA; &lt;p&gt;æ‰§è¡Œä¸‹é¢çš„pythonä»£ç æµ‹è¯•ä¸Šé¢éƒ¨ç½²çš„apiæœåŠ¡&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# coding=utf-8&#xA;import json&#xA;import time&#xA;import urllib.request&#xA;import sys&#xA;import requests&#xA;&#xA;def test_api_server(input_text):&#xA;    header = {&#39;Content-Type&#39;: &#39;application/json&#39;}&#xA;&#xA;    data = {&#xA;          &#34;messages&#34;: [{&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: &#34;&#34;}, {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: input_text}],&#xA;          &#34;temperature&#34;: 0.3, &#xA;          &#34;top_p&#34; : 0.95, &#xA;          &#34;max_tokens&#34;: 512, &#xA;          &#34;model&#34;: &#34;LLama2-Chinese-13B&#34;,&#xA;          &#34;stream&#34; : False,&#xA;          &#34;n&#34; : 1,&#xA;          &#34;best_of&#34;: 1, &#xA;          &#34;presence_penalty&#34;: 1.2, &#xA;          &#34;frequency_penalty&#34;: 0.2,           &#xA;          &#34;top_k&#34;: 50, &#xA;          &#34;use_beam_search&#34;: False, &#xA;          &#34;stop&#34;: [], &#xA;          &#34;ignore_eos&#34; :False,&#xA;          &#34;logprobs&#34;: None&#xA;    }&#xA;    response = requests.post(&#xA;        url=&#39;http://127.0.0.1:21003/v1/chat/completions&#39;,&#xA;        headers=header,&#xA;        data=json.dumps(data).encode(&#39;utf-8&#39;)&#xA;    )&#xA;&#xA;    result = None&#xA;    try:&#xA;        result = json.loads(response.content)&#xA;        print(json.dumps(data, ensure_ascii=False, indent=2))&#xA;        print(json.dumps(result, ensure_ascii=False, indent=2))&#xA;&#xA;    except Exception as e:&#xA;        print(e)&#xA;&#xA;    return result&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    test_api_server(&#34;å¦‚ä½•å»åŒ—äº¬?&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;ğŸ¤– æ¨¡å‹é¢„è®­ç»ƒ&lt;/h2&gt; &#xA;&lt;p&gt;è™½ç„¶Llama2çš„é¢„è®­ç»ƒæ•°æ®ç›¸å¯¹äºç¬¬ä¸€ä»£LLaMAæ‰©å¤§äº†ä¸€å€ï¼Œä½†æ˜¯ä¸­æ–‡é¢„è®­ç»ƒæ•°æ®çš„æ¯”ä¾‹ä¾ç„¶éå¸¸å°‘ï¼Œä»…å 0.13%ï¼Œè¿™ä¹Ÿå¯¼è‡´äº†åŸå§‹Llama2çš„ä¸­æ–‡èƒ½åŠ›è¾ƒå¼±ã€‚ä¸ºäº†èƒ½å¤Ÿæå‡æ¨¡å‹çš„ä¸­æ–‡èƒ½åŠ›ï¼Œå¯ä»¥é‡‡ç”¨å¾®è°ƒå’Œé¢„è®­ç»ƒä¸¤ç§è·¯å¾„ï¼Œå…¶ä¸­ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;å¾®è°ƒéœ€è¦çš„ç®—åŠ›èµ„æºå°‘ï¼Œèƒ½å¤Ÿå¿«é€Ÿå®ç°ä¸€ä¸ªä¸­æ–‡Llamaçš„é›å½¢ã€‚ä½†ç¼ºç‚¹ä¹Ÿæ˜¾è€Œæ˜“è§ï¼Œåªèƒ½æ¿€å‘åŸºåº§æ¨¡å‹å·²æœ‰çš„ä¸­æ–‡èƒ½åŠ›ï¼Œç”±äºLlama2çš„ä¸­æ–‡è®­ç»ƒæ•°æ®æœ¬èº«è¾ƒå°‘ï¼Œæ‰€ä»¥èƒ½å¤Ÿæ¿€å‘çš„èƒ½åŠ›ä¹Ÿæœ‰é™ï¼Œæ²»æ ‡ä¸æ²»æœ¬ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;åŸºäºå¤§è§„æ¨¡ä¸­æ–‡è¯­æ–™è¿›è¡Œé¢„è®­ç»ƒï¼Œæˆæœ¬é«˜ï¼Œä¸ä»…éœ€è¦å¤§è§„æ¨¡é«˜è´¨é‡çš„ä¸­æ–‡æ•°æ®ï¼Œä¹Ÿéœ€è¦å¤§è§„æ¨¡çš„ç®—åŠ›èµ„æºã€‚ä½†æ˜¯ä¼˜ç‚¹ä¹Ÿæ˜¾è€Œæ˜“è§ï¼Œå°±æ˜¯èƒ½ä»æ¨¡å‹åº•å±‚ä¼˜åŒ–ä¸­æ–‡èƒ½åŠ›ï¼ŒçœŸæ­£è¾¾åˆ°æ²»æœ¬çš„æ•ˆæœï¼Œä»å†…æ ¸ä¸ºå¤§æ¨¡å‹æ³¨å…¥å¼ºå¤§çš„ä¸­æ–‡èƒ½åŠ›ã€‚&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;æˆ‘ä»¬ä¸ºç¤¾åŒºæä¾›äº†Llamaæ¨¡å‹çš„é¢„è®­ç»ƒä»£ç ï¼Œä»¥åŠ&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/tree/main/data&#34;&gt;ä¸­æ–‡æµ‹è¯•è¯­æ–™&lt;/a&gt;ï¼Œæ›´å¤šæ•°æ®å¯ä»¥å‚è€ƒ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E4%B8%AD%E6%96%87%E6%95%B0%E6%8D%AE&#34;&gt;ä¸­æ–‡è¯­æ–™&lt;/a&gt;ã€‚å…·ä½“ä»£ç å’Œé…ç½®å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/pretrain.sh&#34;&gt;train/pretrain/pretrain.sh&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;é¢„è®­ç»ƒå®ç°ä»£ç ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/pretrain_clm.py&#34;&gt;train/pretrain/pretrain_clm.py&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/DeepSpeed&#34;&gt;DeepSpeed&lt;/a&gt;åŠ é€Ÿï¼š &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;å¯¹äºå•å¡è®­ç»ƒï¼Œå¯ä»¥é‡‡ç”¨ZeRO-2çš„æ–¹å¼ï¼Œå‚æ•°é…ç½®è§ &lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/ds_config_zero2.json&#34;&gt;train/pretrain/ds_config_zero2.json&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;å¯¹äºå¤šå¡è®­ç»ƒï¼Œå¯ä»¥é‡‡ç”¨ZeRO-3çš„æ–¹å¼ï¼Œå‚æ•°é…ç½®è§ &lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/ds_config_zero3.json&#34;&gt;train/pretrain/ds_config_zero3.json&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;è®­ç»ƒæ•ˆæœåº¦é‡æŒ‡æ ‡ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/accuracy.py&#34;&gt;train/pretrain/accuracy.py&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ’¡ æ¨¡å‹å¾®è°ƒ&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬ä»“åº“ä¸­åŒæ—¶æä¾›äº†LoRAå¾®è°ƒå’Œå…¨é‡å‚æ•°å¾®è°ƒä»£ç ï¼Œå…³äºLoRAçš„è¯¦ç»†ä»‹ç»å¯ä»¥å‚è€ƒè®ºæ–‡â€œ&lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;LoRA: Low-Rank Adaptation of Large Language Models&lt;/a&gt;â€ä»¥åŠå¾®è½¯Githubä»“åº“&lt;a href=&#34;https://github.com/microsoft/LoRA&#34;&gt;LoRA&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Step1: ç¯å¢ƒå‡†å¤‡&lt;/h3&gt; &#xA;&lt;p&gt;æ ¹æ®&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/requirements.txt&#34;&gt;requirements.txt&lt;/a&gt;å®‰è£…å¯¹åº”çš„ç¯å¢ƒä¾èµ–ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Step2: æ•°æ®å‡†å¤‡&lt;/h3&gt; &#xA;&lt;p&gt;åœ¨dataç›®å½•ä¸‹æä¾›äº†ä¸€ä»½ç”¨äºæ¨¡å‹sftçš„æ•°æ®æ ·ä¾‹ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;è®­ç»ƒæ•°æ®ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/data/train_sft.csv&#34;&gt;data/train_sft.csv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;éªŒè¯æ•°æ®ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/data/dev_sft.csv&#34;&gt;data/dev_sft.csv&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;æ¯ä¸ªcsvæ–‡ä»¶ä¸­åŒ…å«ä¸€åˆ—â€œtextâ€ï¼Œæ¯ä¸€è¡Œä¸ºä¸€ä¸ªè®­ç»ƒæ ·ä¾‹ï¼Œæ¯ä¸ªè®­ç»ƒæ ·ä¾‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å°†é—®é¢˜å’Œç­”æ¡ˆç»„ç»‡ä¸ºæ¨¡å‹è¾“å…¥ï¼Œæ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è‡ªå®šä¹‰è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#34;&amp;lt;s&amp;gt;Human: &#34;+é—®é¢˜+&#34;\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#34;+ç­”æ¡ˆ+&#34;\n&#34;&amp;lt;/s&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ä¾‹å¦‚ï¼Œ&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;s&amp;gt;Human: ç”¨ä¸€å¥è¯æè¿°åœ°çƒä¸ºä»€ä¹ˆæ˜¯ç‹¬ä¸€æ— äºŒçš„ã€‚&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: å› ä¸ºåœ°çƒæ˜¯ç›®å‰ä¸ºæ­¢å”¯ä¸€å·²çŸ¥å­˜åœ¨ç”Ÿå‘½çš„è¡Œæ˜Ÿã€‚&amp;lt;/s&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step3: å¾®è°ƒè„šæœ¬&lt;/h3&gt; &#xA;&lt;h4&gt;LoRAå¾®è°ƒ&lt;/h4&gt; &#xA;&lt;p&gt;LoRAå¾®è°ƒè„šæœ¬è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/sft/finetune_lora.sh&#34;&gt;train/sft/finetune_lora.sh&lt;/a&gt;ï¼Œå…³äºLoRAå¾®è°ƒçš„å…·ä½“å®ç°ä»£ç è§&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/sft/finetune_clm_lora.py&#34;&gt;train/sft/finetune_clm_lora.py&lt;/a&gt;ï¼Œå•æœºå¤šå¡çš„å¾®è°ƒå¯ä»¥é€šè¿‡ä¿®æ”¹è„šæœ¬ä¸­çš„&lt;code&gt;--include localhost:0&lt;/code&gt;æ¥å®ç°ã€‚&lt;/p&gt; &#xA;&lt;h4&gt;å…¨é‡å‚æ•°å¾®è°ƒ&lt;/h4&gt; &#xA;&lt;p&gt;å…¨é‡å‚æ•°å¾®è°ƒè„šæœ¬è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/sft/finetune.sh&#34;&gt;train/sft/finetune.sh&lt;/a&gt;ï¼Œå…³äºå…¨é‡å‚æ•°å¾®è°ƒçš„å…·ä½“å®ç°ä»£ç è§&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/sft/finetune_clm.py&#34;&gt;train/sft/finetune_clm.py&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Step4: åŠ è½½å¾®è°ƒæ¨¡å‹&lt;/h3&gt; &#xA;&lt;h4&gt;LoRAå¾®è°ƒ&lt;/h4&gt; &#xA;&lt;p&gt;åŸºäºLoRAå¾®è°ƒçš„æ¨¡å‹å‚æ•°è§ï¼š&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama2%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B&#34;&gt;åŸºäºLlama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹&lt;/a&gt;ï¼ŒLoRAå‚æ•°éœ€è¦å’ŒåŸºç¡€æ¨¡å‹å‚æ•°ç»“åˆä½¿ç”¨ã€‚&lt;/p&gt; &#xA;&lt;p&gt;é€šè¿‡&lt;a href=&#34;https://github.com/huggingface/peft&#34;&gt;PEFT&lt;/a&gt;åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å‚æ•°å’Œå¾®è°ƒæ¨¡å‹å‚æ•°ï¼Œä»¥ä¸‹ç¤ºä¾‹ä»£ç ä¸­ï¼Œbase_model_name_or_pathä¸ºé¢„è®­ç»ƒæ¨¡å‹å‚æ•°ä¿å­˜è·¯å¾„ï¼Œfinetune_model_pathä¸ºå¾®è°ƒæ¨¡å‹å‚æ•°ä¿å­˜è·¯å¾„ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;from peft import PeftModel,PeftConfig&#xA;# ä¾‹å¦‚: finetune_model_path=&#39;FlagAlpha/Llama2-Chinese-7b-Chat-LoRA&#39;&#xA;finetune_model_path=&#39;&#39;  &#xA;config = PeftConfig.from_pretrained(finetune_model_path)&#xA;# ä¾‹å¦‚: base_model_name_or_path=&#39;meta-llama/Llama-2-7b-chat&#39;&#xA;tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path,use_fast=False)&#xA;tokenizer.pad_token = tokenizer.eos_token&#xA;device_map = &#34;cuda:0&#34; if torch.cuda.is_available() else &#34;auto&#34;&#xA;model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,device_map=device_map,torch_dtype=torch.float16,load_in_8bit=True,trust_remote_code=True,use_flash_attention_2=True)&#xA;model = PeftModel.from_pretrained(model, finetune_model_path, device_map={&#34;&#34;: 0})&#xA;model =model.eval()&#xA;input_ids = tokenizer([&#39;&amp;lt;s&amp;gt;Human: ä»‹ç»ä¸€ä¸‹åŒ—äº¬\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#39;], return_tensors=&#34;pt&#34;,add_special_tokens=False).input_ids&#xA;if torch.cuda.is_available():&#xA;  input_ids = input_ids.to(&#39;cuda&#39;)&#xA;generate_input = {&#xA;    &#34;input_ids&#34;:input_ids,&#xA;    &#34;max_new_tokens&#34;:512,&#xA;    &#34;do_sample&#34;:True,&#xA;    &#34;top_k&#34;:50,&#xA;    &#34;top_p&#34;:0.95,&#xA;    &#34;temperature&#34;:0.3,&#xA;    &#34;repetition_penalty&#34;:1.3,&#xA;    &#34;eos_token_id&#34;:tokenizer.eos_token_id,&#xA;    &#34;bos_token_id&#34;:tokenizer.bos_token_id,&#xA;    &#34;pad_token_id&#34;:tokenizer.pad_token_id&#xA;}&#xA;generate_ids  = model.generate(**generate_input)&#xA;text = tokenizer.decode(generate_ids[0])&#xA;print(text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;å…¨é‡å‚æ•°å¾®è°ƒ&lt;/h4&gt; &#xA;&lt;p&gt;å¯¹äºå…¨é‡å‚æ•°å¾®è°ƒçš„æ¨¡å‹ï¼Œè°ƒç”¨æ–¹å¼åŒ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%94%A8%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B&#34;&gt;æ¨¡å‹è°ƒç”¨ä»£ç ç¤ºä¾‹&lt;/a&gt;ï¼Œåªéœ€è¦ä¿®æ”¹å…¶ä¸­çš„æ¨¡å‹åç§°æˆ–è€…ä¿å­˜è·¯å¾„å³å¯ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ„ æ¨¡å‹é‡åŒ–&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘ä»¬å¯¹ä¸­æ–‡å¾®è°ƒçš„æ¨¡å‹å‚æ•°è¿›è¡Œäº†é‡åŒ–ï¼Œæ–¹ä¾¿ä»¥æ›´å°‘çš„è®¡ç®—èµ„æºè¿è¡Œã€‚ç›®å‰å·²ç»åœ¨&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;Hugging Face&lt;/a&gt;ä¸Šä¼ äº†13Bä¸­æ–‡å¾®è°ƒæ¨¡å‹&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat&#34;&gt;FlagAlpha/Llama2-Chinese-13b-Chat&lt;/a&gt;çš„4bitå‹ç¼©ç‰ˆæœ¬&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#34;&gt;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&lt;/a&gt;ï¼Œå…·ä½“è°ƒç”¨æ–¹å¼å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;p&gt;ç¯å¢ƒå‡†å¤‡ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install git+https://github.com/PanQiWei/AutoGPTQ.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoTokenizer&#xA;from auto_gptq import AutoGPTQForCausalLM&#xA;model = AutoGPTQForCausalLM.from_quantized(&#39;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#39;, device=&#34;cuda:0&#34;)&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#39;,use_fast=False)&#xA;input_ids = tokenizer([&#39;&amp;lt;s&amp;gt;Human: æ€ä¹ˆç™»ä¸Šç«æ˜Ÿ\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#39;], return_tensors=&#34;pt&#34;,add_special_tokens=False).input_ids.to(&#39;cuda&#39;)        &#xA;generate_input = {&#xA;    &#34;input_ids&#34;:input_ids,&#xA;    &#34;max_new_tokens&#34;:512,&#xA;    &#34;do_sample&#34;:True,&#xA;    &#34;top_k&#34;:50,&#xA;    &#34;top_p&#34;:0.95,&#xA;    &#34;temperature&#34;:0.3,&#xA;    &#34;repetition_penalty&#34;:1.3,&#xA;    &#34;eos_token_id&#34;:tokenizer.eos_token_id,&#xA;    &#34;bos_token_id&#34;:tokenizer.bos_token_id,&#xA;    &#34;pad_token_id&#34;:tokenizer.pad_token_id&#xA;}&#xA;generate_ids  = model.generate(**generate_input)&#xA;text = tokenizer.decode(generate_ids[0])&#xA;print(text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ğŸš€ éƒ¨ç½²åŠ é€Ÿ&lt;/h2&gt; &#xA;&lt;p&gt;éšç€å¤§æ¨¡å‹å‚æ•°è§„æ¨¡çš„ä¸æ–­å¢é•¿ï¼Œåœ¨æœ‰é™çš„ç®—åŠ›èµ„æºä¸‹ï¼Œæå‡æ¨¡å‹çš„æ¨ç†é€Ÿåº¦é€æ¸å˜ä¸ºä¸€ä¸ªé‡è¦çš„ç ”ç©¶æ–¹å‘ã€‚å¸¸ç”¨çš„æ¨ç†åŠ é€Ÿæ¡†æ¶åŒ…å« lmdeployã€TensorRT-LLMã€vLLMå’ŒJittorLLMs ç­‰ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;TensorRT-LLM&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/NVIDIA/TensorRT-LLM/tree/main&#34;&gt;TensorRT-LLM&lt;/a&gt;ç”±NVIDIAå¼€å‘ï¼Œé«˜æ€§èƒ½æ¨ç†æ¡†æ¶&lt;/p&gt; &#xA;&lt;p&gt;è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/tree/main/inference-speed/GPU/TensorRT-LLM_example&#34;&gt;inference-speed/GPU/TensorRT-LLM_example&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;vLLM&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/vllm-project/vllm&#34;&gt;vLLM&lt;/a&gt;ç”±åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡å¼€å‘ï¼Œæ ¸å¿ƒæŠ€æœ¯æ˜¯PageAttentionï¼Œååé‡æ¯”HuggingFace Transformersé«˜å‡º24å€ã€‚ç›¸è¾ƒä¸FasterTrainsformerï¼ŒvLLMæ›´åŠ çš„ç®€å•æ˜“ç”¨ï¼Œä¸éœ€è¦é¢å¤–è¿›è¡Œæ¨¡å‹çš„è½¬æ¢ï¼Œæ”¯æŒfp16æ¨ç†ã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/inference-speed/GPU/vllm_example/README.md&#34;&gt;inference-speed/GPU/vllm_example&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;JittorLLMs&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Jittor/JittorLLMs&#34;&gt;JittorLLMs&lt;/a&gt;ç”±éåç§‘æŠ€é¢†è¡”ï¼Œä¸æ¸…åå¤§å­¦å¯è§†åª’ä½“ç ”ç©¶ä¸­å¿ƒåˆä½œç ”å‘ï¼Œé€šè¿‡åŠ¨æ€swapæœºåˆ¶å¤§å¹…é™ä½ç¡¬ä»¶é…ç½®è¦æ±‚ï¼ˆå‡å°‘80%ï¼‰,å¹¶ä¸”Jittoræ¡†æ¶é€šè¿‡é›¶æ‹·è´æŠ€æœ¯ï¼Œå¤§æ¨¡å‹åŠ è½½ç›¸æ¯”Pytorchå¼€é”€é™ä½40%ï¼ŒåŒæ—¶ï¼Œé€šè¿‡å…ƒç®—å­è‡ªåŠ¨ç¼–è¯‘ä¼˜åŒ–ï¼Œè®¡ç®—æ€§èƒ½æå‡20%ä»¥ä¸Šã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/inference-speed/GPU/JittorLLMs_example/README.md&#34;&gt;inference-speed/GPU/JittorLLMs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;lmdeploy&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/InternLM/lmdeploy/&#34;&gt;lmdeploy&lt;/a&gt; ç”±ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤å¼€å‘ï¼Œæ¨ç†ä½¿ç”¨ C++/CUDAï¼Œå¯¹å¤–æä¾› python/gRPC/http æ¥å£å’Œ WebUI ç•Œé¢ï¼Œæ”¯æŒ tensor parallel åˆ†å¸ƒå¼æ¨ç†ã€æ”¯æŒ fp16/weight int4/kv cache int8 é‡åŒ–ã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/tree/main/inference-speed/GPU/lmdeploy_example&#34;&gt;inference-speed/GPU/lmdeploy_example&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ’ª å¤–å»¶èƒ½åŠ›&lt;/h2&gt; &#xA;&lt;p&gt;é™¤äº†æŒç»­å¢å¼ºå¤§æ¨¡å‹å†…åœ¨çš„çŸ¥è¯†å‚¨å¤‡ã€é€šç”¨ç†è§£ã€é€»è¾‘æ¨ç†å’Œæƒ³è±¡èƒ½åŠ›ç­‰ï¼Œæœªæ¥ï¼Œæˆ‘ä»¬ä¹Ÿä¼šä¸æ–­ä¸°å¯Œå¤§æ¨¡å‹çš„å¤–å»¶èƒ½åŠ›ï¼Œä¾‹å¦‚çŸ¥è¯†åº“æ£€ç´¢ã€è®¡ç®—å·¥å…·ã€WolframAlphaã€æ“ä½œè½¯ä»¶ç­‰ã€‚ æˆ‘ä»¬é¦–å…ˆé›†æˆäº†LangChainæ¡†æ¶ï¼Œå¯ä»¥æ›´æ–¹ä¾¿åœ°åŸºäºLlama2å¼€å‘æ–‡æ¡£æ£€ç´¢ã€é—®ç­”æœºå™¨äººå’Œæ™ºèƒ½ä½“åº”ç”¨ç­‰ï¼Œå…³äºLangChainçš„æ›´å¤šä»‹ç»å‚è§&lt;a href=&#34;https://github.com/langchain-ai/langchain&#34;&gt;LangChain&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;LangChain&lt;/h3&gt; &#xA;&lt;p&gt;é’ˆå¯¹LangChainæ¡†æ¶å°è£…çš„Llama2 LLMç±»è§&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/examples/llama2_for_langchain.py&#34;&gt;examples/llama2_for_langchain.py&lt;/a&gt;ï¼Œç®€å•çš„è°ƒç”¨ä»£ç ç¤ºä¾‹å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from llama2_for_langchain import Llama2&#xA;&#xA;# è¿™é‡Œä»¥è°ƒç”¨FlagAlpha/Atom-7B-Chatä¸ºä¾‹&#xA;llm = Llama2(model_name_or_path=&#39;FlagAlpha/Atom-7B-Chat&#39;)&#xA;&#xA;while True:&#xA;    human_input = input(&#34;Human: &#34;)&#xA;    response = llm(human_input)&#xA;    print(f&#34;Llama2: {response}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ğŸ¥‡ æ¨¡å‹è¯„æµ‹&lt;/h2&gt; &#xA;&lt;h3&gt;Llama2å’ŒLlama3å¯¹æ¯”è¯„æµ‹&lt;/h3&gt; &#xA;&lt;p&gt;åŸºç¡€æ¨¡å‹å¯¹æ¯”&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/base_eval.png&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; å¾®è°ƒæ¨¡å‹å¯¹æ¯” &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/tuned_eval.png&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;Llama3æ¨¡å‹è¯„æµ‹&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/llama3_eval.png&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;Llama2æ¨¡å‹è¯„æµ‹&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/llama_eval.jpeg&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;ä¸ºäº†èƒ½å¤Ÿæ›´åŠ æ¸…æ™°åœ°äº†è§£Llama2æ¨¡å‹çš„ä¸­æ–‡é—®ç­”èƒ½åŠ›ï¼Œæˆ‘ä»¬ç­›é€‰äº†ä¸€äº›å…·æœ‰ä»£è¡¨æ€§çš„ä¸­æ–‡é—®é¢˜ï¼Œå¯¹Llama2æ¨¡å‹è¿›è¡Œæé—®ã€‚æˆ‘ä»¬æµ‹è¯•çš„æ¨¡å‹åŒ…å«Metaå…¬å¼€çš„Llama2-7B-Chatå’ŒLlama2-13B-Chatä¸¤ä¸ªç‰ˆæœ¬ï¼Œæ²¡æœ‰åšä»»ä½•å¾®è°ƒå’Œè®­ç»ƒã€‚æµ‹è¯•é—®é¢˜ç­›é€‰è‡ª&lt;a href=&#34;https://github.com/AtomEcho/AtomBulb&#34;&gt;AtomBulb&lt;/a&gt;ï¼Œå…±95ä¸ªæµ‹è¯•é—®é¢˜ï¼ŒåŒ…å«ï¼šé€šç”¨çŸ¥è¯†ã€è¯­è¨€ç†è§£ã€åˆ›ä½œèƒ½åŠ›ã€é€»è¾‘æ¨ç†ã€ä»£ç ç¼–ç¨‹ã€å·¥ä½œæŠ€èƒ½ã€ä½¿ç”¨å·¥å…·ã€äººæ ¼ç‰¹å¾å…«ä¸ªå¤§çš„ç±»åˆ«ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æµ‹è¯•ä¸­ä½¿ç”¨çš„Promptå¦‚ä¸‹ï¼Œä¾‹å¦‚å¯¹äºé—®é¢˜â€œåˆ—å‡º5ç§å¯ä»¥æ”¹å–„ç¡çœ è´¨é‡çš„æ–¹æ³•â€ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[INST] &#xA;&amp;lt;&amp;lt;SYS&amp;gt;&amp;gt;&#xA;You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. The answer always been translate into Chinese language.&#xA;&#xA;If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don&#39;t know the answer to a question, please don&#39;t share false information.&#xA;&#xA;The answer always been translate into Chinese language.&#xA;&amp;lt;&amp;lt;/SYS&amp;gt;&amp;gt;&#xA;&#xA;åˆ—å‡º5ç§å¯ä»¥æ”¹å–„ç¡çœ è´¨é‡çš„æ–¹æ³•&#xA;[/INST]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Llama2-7B-Chatçš„æµ‹è¯•ç»“æœè§&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/meta_eval_7B.md&#34;&gt;meta_eval_7B.md&lt;/a&gt;ï¼ŒLlama2-13B-Chatçš„æµ‹è¯•ç»“æœè§&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/meta_eval_13B.md&#34;&gt;meta_eval_13B.md&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;é€šè¿‡æµ‹è¯•æˆ‘ä»¬å‘ç°ï¼ŒMetaåŸå§‹çš„Llama2 Chatæ¨¡å‹å¯¹äºä¸­æ–‡é—®ç­”çš„å¯¹é½æ•ˆæœä¸€èˆ¬ï¼Œå¤§éƒ¨åˆ†æƒ…å†µä¸‹éƒ½ä¸èƒ½ç»™å‡ºä¸­æ–‡å›ç­”ï¼Œæˆ–è€…æ˜¯ä¸­è‹±æ–‡æ··æ‚çš„å½¢å¼ã€‚å› æ­¤ï¼ŒåŸºäºä¸­æ–‡æ•°æ®å¯¹Llama2æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œå¾®è°ƒååˆ†å¿…è¦ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“– å­¦ä¹ ä¸­å¿ƒ&lt;/h2&gt; &#xA;&lt;h3&gt;å®˜æ–¹æ–‡æ¡£&lt;/h3&gt; &#xA;&lt;p&gt;Meta Llamaå…¨ç³»åˆ—æ¨¡å‹å®˜æ–¹æ–‡æ¡£ï¼š&lt;a href=&#34;https://llama.meta.com/docs/get-started&#34;&gt;https://llama.meta.com/docs/get-started&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Llama3&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://chinesellama.feishu.cn/wiki/XBKPwbhWriWCfrkmJhfcrS9Rnqc?fromScene=spaceOverview&#34;&gt;Llama3å…¨å¥—å­¦ä¹ èµ„æ–™&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Llama3å®˜æ–¹é“¾æ¥ï¼š&lt;a href=&#34;https://llama.meta.com/llama3&#34;&gt;https://llama.meta.com/llama3&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Llama2&lt;/h3&gt; &#xA;&lt;h4&gt;Metaå®˜æ–¹å¯¹äº&lt;a href=&#34;https://ai.meta.com/llama&#34;&gt;Llama2&lt;/a&gt;çš„ä»‹ç»&lt;/h4&gt; &#xA;&lt;p&gt;è‡ªä»Metaå…¬å¸å‘å¸ƒç¬¬ä¸€ä»£LLaMAæ¨¡å‹ä»¥æ¥ï¼Œç¾Šé©¼æ¨¡å‹å®¶æ—ç¹è£å‘å±•ã€‚è¿‘æœŸMetaå‘å¸ƒäº†Llama2ç‰ˆæœ¬ï¼Œå¼€æºå¯å•†ç”¨ï¼Œåœ¨æ¨¡å‹å’Œæ•ˆæœä¸Šæœ‰äº†é‡å¤§æ›´æ–°ã€‚Llama2æ€»å…±å…¬å¸ƒäº†7Bã€13Bå’Œ70Bä¸‰ç§å‚æ•°å¤§å°çš„æ¨¡å‹ã€‚ç›¸æ¯”äºLLaMAï¼ŒLlama2çš„è®­ç»ƒæ•°æ®è¾¾åˆ°äº†2ä¸‡äº¿tokenï¼Œä¸Šä¸‹æ–‡é•¿åº¦ä¹Ÿç”±ä¹‹å‰çš„2048å‡çº§åˆ°4096ï¼Œå¯ä»¥ç†è§£å’Œç”Ÿæˆæ›´é•¿çš„æ–‡æœ¬ã€‚Llama2 Chatæ¨¡å‹åŸºäº100ä¸‡äººç±»æ ‡è®°æ•°æ®å¾®è°ƒå¾—åˆ°ï¼Œåœ¨è‹±æ–‡å¯¹è¯ä¸Šè¾¾åˆ°äº†æ¥è¿‘ChatGPTçš„æ•ˆæœã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Llamaç›¸å…³è®ºæ–‡&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.13971&#34;&gt;LLaMA: Open and Efficient Foundation Language Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2307.09288&#34;&gt;Llama 2: Open Foundation and Fine-Tuned Chat Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/&#34;&gt;Code Llama: Open Foundation Models for Code&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ“Œ å…¶å®ƒ&lt;/h2&gt; &#xA;&lt;h3&gt;ğŸ‰ è‡´è°¢&lt;/h3&gt; &#xA;&lt;p&gt;æ„Ÿè°¢åŸå­å›å£°&lt;a href=&#34;https://github.com/AtomEcho&#34;&gt;AtomEcho&lt;/a&gt;å›¢é˜Ÿçš„æŠ€æœ¯å’Œèµ„æºæ”¯æŒï¼&lt;/p&gt; &#xA;&lt;p&gt;æ„Ÿè°¢èŠ¯æ ¼&lt;a href=&#34;https://coremesh.net&#34;&gt;Coremesh&lt;/a&gt;å›¢é˜Ÿçš„æŠ€æœ¯å’Œèµ„æºæ”¯æŒï¼&lt;/p&gt; &#xA;&lt;p&gt;æ„Ÿè°¢ @xzsGenius å¯¹Llama2ä¸­æ–‡ç¤¾åŒºçš„è´¡çŒ®ï¼&lt;/p&gt; &#xA;&lt;p&gt;æ„Ÿè°¢ @Z Potentialsç¤¾åŒºå¯¹Llama2ä¸­æ–‡ç¤¾åŒºçš„æ”¯æŒï¼&lt;/p&gt; &#xA;&lt;h3&gt;ğŸ¤” é—®é¢˜åé¦ˆ&lt;/h3&gt; &#xA;&lt;p&gt;å¦‚æœ‰é—®é¢˜ï¼Œè¯·åœ¨GitHub Issueä¸­æäº¤ï¼Œåœ¨æäº¤é—®é¢˜ä¹‹å‰ï¼Œè¯·å…ˆæŸ¥é˜…ä»¥å¾€çš„issueæ˜¯å¦èƒ½è§£å†³ä½ çš„é—®é¢˜ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ç¤¼è²Œåœ°æå‡ºé—®é¢˜ï¼Œæ„å»ºå’Œè°çš„è®¨è®ºç¤¾åŒºã€‚&lt;/p&gt; &#xA;&lt;p&gt;åŠ å…¥&lt;a href=&#34;https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink&#34;&gt;é£ä¹¦çŸ¥è¯†åº“&lt;/a&gt;ï¼Œä¸€èµ·å…±å»ºç¤¾åŒºæ–‡æ¡£ã€‚&lt;/p&gt; &#xA;&lt;p&gt;åŠ å…¥å¾®ä¿¡ç¾¤è®¨è®ºğŸ˜ğŸ˜&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/wechat.jpeg&#34; alt=&#34;Wechat&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://api.star-history.com/svg?repos=LlamaFamily/Llama-Chinese&amp;amp;type=Date&#34; alt=&#34;Wechat&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>yisol/IDM-VTON</title>
    <updated>2024-05-05T01:40:23Z</updated>
    <id>tag:github.com,2024-05-05:/yisol/IDM-VTON</id>
    <link href="https://github.com/yisol/IDM-VTON" rel="alternate"></link>
    <summary type="html">&lt;p&gt;IDM-VTON : Improving Diffusion Models for Authentic Virtual Try-on in the Wild&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;IDM-VTON: Improving Diffusion Models for Authentic Virtual Try-on in the Wild&lt;/h1&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://idm-vton.github.io&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project-Page-green&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2403.05139&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Paper-Arxiv-red&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/yisol/IDM-VTON&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Demo-yellow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/yisol/IDM-VTON&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Model-blue&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;This is the official implementation of the paper &lt;a href=&#34;https://arxiv.org/abs/2403.05139&#34;&gt;&#34;Improving Diffusion Models for Authentic Virtual Try-on in the Wild&#34;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Star â­ us if you like it!&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yisol/IDM-VTON/main/assets/teaser2.png&#34; alt=&#34;teaser2&#34;&gt;&amp;nbsp; &lt;img src=&#34;https://raw.githubusercontent.com/yisol/IDM-VTON/main/assets/teaser.png&#34; alt=&#34;teaser&#34;&gt;&amp;nbsp;&lt;/p&gt; &#xA;&lt;h2&gt;TODO LIST&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; demo model&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; inference code&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; training code&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/yisol/IDM-VTON.git&#xA;cd IDM-VTON&#xA;&#xA;conda env create -f environment.yaml&#xA;conda activate idm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Data preparation&lt;/h2&gt; &#xA;&lt;h3&gt;VITON-HD&lt;/h3&gt; &#xA;&lt;p&gt;You can download VITON-HD dataset from &lt;a href=&#34;https://github.com/shadow2496/VITON-HD&#34;&gt;VITON-HD&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;After download VITON-HD dataset, move vitonhd_test_tagged.json into the test folder.&lt;/p&gt; &#xA;&lt;p&gt;Structure of the Dataset directory should be as follows.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;train&#xA;|-- ...&#xA;&#xA;test&#xA;|-- image&#xA;|-- image-densepose&#xA;|-- agnostic-mask&#xA;|-- cloth&#xA;|-- vitonhd_test_tagged.json&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;DressCode&lt;/h3&gt; &#xA;&lt;p&gt;You can download DressCode dataset from &lt;a href=&#34;https://github.com/aimagelab/dress-code&#34;&gt;DressCode&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We provide pre-computed densepose images and captions for garments &lt;a href=&#34;https://kaistackr-my.sharepoint.com/:u:/g/personal/cpis7_kaist_ac_kr/EaIPRG-aiRRIopz9i002FOwBDa-0-BHUKVZ7Ia5yAVVG3A?e=YxkAip&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We used &lt;a href=&#34;https://github.com/facebookresearch/detectron2&#34;&gt;detectron2&lt;/a&gt; for obtaining densepose images, refer &lt;a href=&#34;https://github.com/sangyun884/HR-VITON/issues/45&#34;&gt;here&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;p&gt;After download the DressCode dataset, place image-densepose directories and caption text files as follows.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;DressCode&#xA;|-- dresses&#xA;    |-- images&#xA;    |-- image-densepose&#xA;    |-- dc_caption.txt&#xA;    |-- ...&#xA;|-- lower_body&#xA;    |-- images&#xA;    |-- image-densepose&#xA;    |-- dc_caption.txt&#xA;    |-- ...&#xA;|-- upper_body&#xA;    |-- images&#xA;    |-- image-densepose&#xA;    |-- dc_caption.txt&#xA;    |-- ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;h3&gt;VITON-HD&lt;/h3&gt; &#xA;&lt;p&gt;Inference using python file with arguments,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;accelerate launch inference.py \&#xA;    --width 768 --height 1024 --num_inference_steps 30 \&#xA;    --output_dir &#34;result&#34; \&#xA;    --unpaired \&#xA;    --data_dir &#34;DATA_DIR&#34; \&#xA;    --seed 42 \&#xA;    --test_batch_size 2 \&#xA;    --guidance_scale 2.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or, you can simply run with the script file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sh inference.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;DressCode&lt;/h3&gt; &#xA;&lt;p&gt;For DressCode dataset, put the category you want to generate images via category argument,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;accelerate launch inference_dc.py \&#xA;    --width 768 --height 1024 --num_inference_steps 30 \&#xA;    --output_dir &#34;result&#34; \&#xA;    --unpaired \&#xA;    --data_dir &#34;DATA_DIR&#34; \&#xA;    --seed 42 &#xA;    --test_batch_size 2&#xA;    --guidance_scale 2.0&#xA;    --category &#34;upper_body&#34; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or, you can simply run with the script file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sh inference.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Start a local gradio demo &lt;a href=&#34;https://github.com/gradio-app/gradio&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/gradio-app/gradio&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Download checkpoints for human parsing &lt;a href=&#34;https://huggingface.co/spaces/yisol/IDM-VTON-local/tree/main/ckpt&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Place the checkpoints under the ckpt folder.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ckpt&#xA;|-- densepose&#xA;    |-- model_final_162be9.pkl&#xA;|-- humanparsing&#xA;    |-- parsing_atr.onnx&#xA;    |-- parsing_lip.onnx&#xA;&#xA;|-- openpose&#xA;    |-- ckpts&#xA;        |-- body_pose_model.pth&#xA;    &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python gradio_demo/app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;Thanks &lt;a href=&#34;https://huggingface.co/zero-gpu-explorers&#34;&gt;ZeroGPU&lt;/a&gt; for providing free GPU.&lt;/p&gt; &#xA;&lt;p&gt;Thanks &lt;a href=&#34;https://github.com/tencent-ailab/IP-Adapter&#34;&gt;IP-Adapter&lt;/a&gt; for base codes.&lt;/p&gt; &#xA;&lt;p&gt;Thanks &lt;a href=&#34;https://github.com/levihsu/OOTDiffusion&#34;&gt;OOTDiffusion&lt;/a&gt; and &lt;a href=&#34;https://github.com/bcmi/DCI-VTON-Virtual-Try-On&#34;&gt;DCI-VTON&lt;/a&gt; for masking generation.&lt;/p&gt; &#xA;&lt;p&gt;Thanks &lt;a href=&#34;https://github.com/GoGoDuck912/Self-Correction-Human-Parsing&#34;&gt;SCHP&lt;/a&gt; for human segmentation.&lt;/p&gt; &#xA;&lt;p&gt;Thanks &lt;a href=&#34;https://github.com/facebookresearch/DensePose&#34;&gt;Densepose&lt;/a&gt; for human densepose.&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#yisol/IDM-VTON&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=yisol/IDM-VTON&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{choi2024improving,&#xA;  title={Improving Diffusion Models for Virtual Try-on},&#xA;  author={Choi, Yisol and Kwak, Sangkyung and Lee, Kyungmin and Choi, Hyungwon and Shin, Jinwoo},&#xA;  journal={arXiv preprint arXiv:2403.05139},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The codes and checkpoints in this repository are under the &lt;a href=&#34;https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode&#34;&gt;CC BY-NC-SA 4.0 license&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>