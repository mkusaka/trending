<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-09T02:00:02Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>twitter/the-algorithm-ml</title>
    <updated>2023-04-09T02:00:02Z</updated>
    <id>tag:github.com,2023-04-09:/twitter/the-algorithm-ml</id>
    <link href="https://github.com/twitter/the-algorithm-ml" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Source code for Twitter&#39;s Recommendation Algorithm&lt;/p&gt;&lt;hr&gt;&lt;p&gt;This project open sources some of the ML models used at Twitter.&lt;/p&gt; &#xA;&lt;p&gt;Currently these are:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;The &#34;For You&#34; Heavy Ranker (projects/home/recap).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;TwHIN embeddings (projects/twhin) &lt;a href=&#34;https://arxiv.org/abs/2202.05387&#34;&gt;https://arxiv.org/abs/2202.05387&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;This project can be run inside a python virtualenv. We have only tried this on Linux machines and because we use torchrec it works best with an Nvidia GPU. To setup run&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./images/init_venv.sh&lt;/code&gt; (Linux only).&lt;/p&gt; &#xA;&lt;p&gt;The READMEs of each project contain instructions about how to run each project.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>stochasticai/xturing</title>
    <updated>2023-04-09T02:00:02Z</updated>
    <id>tag:github.com,2023-04-09:/stochasticai/xturing</id>
    <link href="https://github.com/stochasticai/xturing" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Build and control your own LLMs&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/.github/stochastic_logo_light.svg#gh-light-mode-only&#34; width=&#34;250&#34; alt=&#34;Stochastic.ai&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/.github/stochastic_logo_dark.svg#gh-dark-mode-only&#34; width=&#34;250&#34; alt=&#34;Stochastic.ai&#34;&gt; &lt;/p&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt;Build and control your own LLMs&lt;/h3&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;code&gt;xturing&lt;/code&gt; provides fast, efficient and simple fine-tuning of LLMs, such as LLaMA, GPT-J, GPT-2, OPT, Cerebras-GPT, Galactica, and more. By providing an easy-to-use interface for personalizing LLMs to your own data and application, xTuring makes it simple to build and control LLMs. The entire process can be done inside your computer or in your private cloud, ensuring data privacy and security.&lt;/p&gt; &#xA;&lt;p&gt;With &lt;code&gt;xturing&lt;/code&gt; you can,&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ingest data from different sources and preprocess them to a format LLMs can understand&lt;/li&gt; &#xA; &lt;li&gt;Scale from single to multiple GPUs for faster fine-tuning&lt;/li&gt; &#xA; &lt;li&gt;Leverage memory-efficient techniques (i.e. INT4, LoRA fine-tuning) to reduce your hardware costs by up to 90% of the time&lt;/li&gt; &#xA; &lt;li&gt;Explore different fine-tuning methods and benchmark them to find the best performing model&lt;/li&gt; &#xA; &lt;li&gt;Evaluate fine-tuned models on well-defined metrics for in-depth analysis&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://pypi.org/project/xturing/&#34;&gt; &lt;img src=&#34;https://img.shields.io/pypi/v/xturing?style=for-the-badge&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://xturing.stochastic.ai/&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Documentation-blue?logo=GitBook&amp;amp;logoColor=white&amp;amp;style=for-the-badge&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://discord.gg/TgHXuSJEk6&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Chat-FFFFFF?logo=discord&amp;amp;style=for-the-badge&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üåü &lt;em&gt;New feature&lt;/em&gt; - INT4 fine-tuning with LLaMA LoRA&lt;/h2&gt; &#xA;&lt;p&gt;We are excited to announce the latest enhancement to our &lt;code&gt;xTuring&lt;/code&gt; library: INT4 fine-tuning demo. With this update, you can fine-tune LLMs like LLaMA with LoRA architecture in INT4 precision with less than &lt;code&gt;6GB&lt;/code&gt; of VRAM. This breakthrough significantly reduces memory requirements and accelerates the fine-tuning process, allowing you to achieve state-of-the-art performance with less computational resources.&lt;/p&gt; &#xA;&lt;p&gt;More information about INT4 fine-tuning and benchmarks can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/int4_finetuning/README.md&#34;&gt;INT4 README&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can check out the &lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/int4_finetuning/LLaMA_lora_int4.ipynb&#34;&gt;LLaMA INT4 fine-tuning example&lt;/a&gt; to see how it works.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;CLI playground&lt;/h2&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/.github/cli-playground.gif&#34; width=&#34;100%&#34; style=&#34;margin: 0 1%;&#34;&gt; &#xA;&lt;h2&gt;UI playground&lt;/h2&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/.github/ui-playground2.gif&#34; width=&#34;100%&#34; style=&#34;margin: 0 1%;&#34;&gt; &#xA;&lt;h2&gt;‚öôÔ∏è Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install xturing&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üöÄ Quickstart&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from xturing.datasets import InstructionDataset&#xA;from xturing.models import BaseModel&#xA;&#xA;# Load the dataset&#xA;instruction_dataset = InstructionDataset(&#34;./alpaca_data&#34;)&#xA;&#xA;# Initialize the model&#xA;model = BaseModel.create(&#34;llama_lora&#34;)&#xA;&#xA;# Finetune the model&#xA;model.finetune(dataset=instruction_dataset)&#xA;&#xA;# Perform inference&#xA;output = model.generate(texts=[&#34;Why LLM models are becoming so important?&#34;])&#xA;&#xA;print(&#34;Generated output by the model: {}&#34;.format(output))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can find the data folder &lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/llama/alpaca_data&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üìö Tutorials&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/llama/preparing_your_dataset.py&#34;&gt;Preparing your dataset&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/cerebras/cerebras_lora_int8.ipynb&#34;&gt;Cerebras-GPT fine-tuning with LoRA and INT8&lt;/a&gt; ‚ÄÇ &lt;a href=&#34;https://colab.research.google.com/drive/1eKq3oF7dnK8KuIfsTE70Gvvniwr1O9D0?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/cerebras/cerebras_lora.ipynb&#34;&gt;Cerebras-GPT fine-tuning with LoRA&lt;/a&gt; ‚ÄÇ &lt;a href=&#34;https://colab.research.google.com/drive/1VjqQhstm5pT4EjPjx4Je7b3W2X1V3vDo?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/llama/llama_lora_int8.py&#34;&gt;LLaMA with LoRA and INT8&lt;/a&gt; ‚ÄÇ &lt;a href=&#34;https://colab.research.google.com/drive/1SQUXq1AMZPSLD4mk3A3swUIc6Y2dclme?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/llama/llama_lora.py&#34;&gt;LLaMA with LoRA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/llama/llama.py&#34;&gt;LLaMA easy fine-tuning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/gptj/gptj_lora_int8.py&#34;&gt;GPT-J efficient fine-tuning with LoRA and INT8&lt;/a&gt; ‚ÄÇ &lt;a href=&#34;https://colab.research.google.com/drive/1hB_8s1V9K4IzifmlmN2AovGEJzTB1c7e?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/gptj/gptj_lora.py&#34;&gt;GPT-J fine-tuning with LoRA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/galactica/galactica_lora_int8.py&#34;&gt;Galactica fine-tuning with LoRA and INT8&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/galactica/galactica_lora.py&#34;&gt;Galactica fine-tuning with LoRA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/opt/opt_lora_int8.py&#34;&gt;OPT fine-tuning with LoRA and INT8&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/opt/opt_lora.py&#34;&gt;OPT fine-tuning with LoRA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/gpt2/gpt2_lora.py&#34;&gt;GPT-2 fine-tuning with LoRA&lt;/a&gt; ‚ÄÇ &lt;a href=&#34;https://drive.google.com/file/d/1Sh-ocNpKn9pS7jv6oBb_Q8DitFyj1avL/view?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üìä Performance&lt;/h2&gt; &#xA;&lt;p&gt;Here is a comparison for the performance of different fine-tuning techniques on the LLaMA 7B model. We use the &lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/examples/llama/alpaca_data/&#34;&gt;Alpaca dataset&lt;/a&gt; for fine-tuning. The dataset contains 52K instructions.&lt;/p&gt; &#xA;&lt;p&gt;Hardware:&lt;/p&gt; &#xA;&lt;p&gt;4xA100 40GB GPU, 335GB CPU RAM&lt;/p&gt; &#xA;&lt;p&gt;Fine-tuning parameters:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;{&#xA;  &#39;maximum sequence length&#39;: 512,&#xA;  &#39;batch size&#39;: 1,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;LLaMA 7B&lt;/th&gt; &#xA;   &lt;th&gt;DeepSpeed + CPU Offloading&lt;/th&gt; &#xA;   &lt;th&gt;LoRA + DeepSpeed&lt;/th&gt; &#xA;   &lt;th&gt;LoRA + DeepSpeed + CPU Offloading&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPU&lt;/td&gt; &#xA;   &lt;td&gt;33.5 GB&lt;/td&gt; &#xA;   &lt;td&gt;23.7 GB&lt;/td&gt; &#xA;   &lt;td&gt;21.9 GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CPU&lt;/td&gt; &#xA;   &lt;td&gt;190 GB&lt;/td&gt; &#xA;   &lt;td&gt;10.2 GB&lt;/td&gt; &#xA;   &lt;td&gt;14.9 GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Time per epoch&lt;/td&gt; &#xA;   &lt;td&gt;21 hours&lt;/td&gt; &#xA;   &lt;td&gt;20 mins&lt;/td&gt; &#xA;   &lt;td&gt;20 mins&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Please submit your performance results on other GPUs.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üìé Fine-tuned model checkpoints&lt;/h2&gt; &#xA;&lt;p&gt;We have already fine-tuned some models that you can use as your base or start playing with. Here is how you would load them:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from xturing.models import BaseModel&#xA;model = BaseModel.load(&#34;x/distilgpt2_lora_finetuned_alpaca&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;model&lt;/th&gt; &#xA;   &lt;th&gt;dataset&lt;/th&gt; &#xA;   &lt;th&gt;Path&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DistilGPT-2 LoRA&lt;/td&gt; &#xA;   &lt;td&gt;alpaca&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;x/distilgpt2_lora_finetuned_alpaca&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA LoRA&lt;/td&gt; &#xA;   &lt;td&gt;alpaca&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;x/llama_lora_finetuned_alpaca&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üìà Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Support for LLaMA, GPT-J, GPT-2, OPT, Cerebras-GPT, Galactica and Bloom models&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Dataset generation using self-instruction&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 2x more memory-efficient fine-tuning vs LoRA and unsupervised fine-tuning&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; INT8 low-precision fine-tuning support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Supports OpenAI, Cohere and AI21 Studio model APIs for dataset generation&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Added fine-tuned checkpoints for some models to the hub&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; INT4 LLaMA LoRA fine-tuning demo&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Evaluation of LLM models&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Support for Stable Diffusion&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;ü§ù Help and Support&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions, you can create an issue on this repository.&lt;/p&gt; &#xA;&lt;p&gt;You can also join our &lt;a href=&#34;https://discord.gg/TgHXuSJEk6&#34;&gt;Discord server&lt;/a&gt; and start a discussion in the &lt;code&gt;#xturing&lt;/code&gt; channel.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üìù License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üåé Contributing&lt;/h2&gt; &#xA;&lt;p&gt;As an open source project in a rapidly evolving field, we welcome contributions of all kinds, including new features and better documentation. Please read our &lt;a href=&#34;https://raw.githubusercontent.com/stochasticai/xturing/main/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt; to learn how you can get involved.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>binary-husky/chatgpt_academic</title>
    <updated>2023-04-09T02:00:02Z</updated>
    <id>tag:github.com,2023-04-09:/binary-husky/chatgpt_academic</id>
    <link href="https://github.com/binary-husky/chatgpt_academic" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ÁßëÁ†îÂ∑•‰Ωú‰∏ìÁî®ChatGPTÊãìÂ±ïÔºåÁâπÂà´‰ºòÂåñÂ≠¶ÊúØPaperÊ∂¶Ëâ≤‰ΩìÈ™åÔºåÊîØÊåÅËá™ÂÆö‰πâÂø´Êç∑ÊåâÈíÆÔºåÊîØÊåÅËá™ÂÆö‰πâÂáΩÊï∞Êèí‰ª∂ÔºåÊîØÊåÅmarkdownË°®Ê†ºÊòæÁ§∫ÔºåTexÂÖ¨ÂºèÂèåÊòæÁ§∫Ôºå‰ª£Á†ÅÊòæÁ§∫ÂäüËÉΩÂÆåÂñÑÔºåÊñ∞Â¢ûÊú¨Âú∞Python/C++/GoÈ°πÁõÆÊ†ëÂâñÊûêÂäüËÉΩ/È°πÁõÆÊ∫ê‰ª£Á†ÅËá™ËØëËß£ËÉΩÂäõÔºåÊñ∞Â¢ûPDFÂíåWordÊñáÁåÆÊâπÈáèÊÄªÁªìÂäüËÉΩ/PDFËÆ∫ÊñáÂÖ®ÊñáÁøªËØëÂäüËÉΩ&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGPT Â≠¶ÊúØ‰ºòÂåñ&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Â¶ÇÊûúÂñúÊ¨¢Ëøô‰∏™È°πÁõÆÔºåËØ∑ÁªôÂÆÉ‰∏Ä‰∏™StarÔºõÂ¶ÇÊûú‰Ω†ÂèëÊòé‰∫ÜÊõ¥Â•ΩÁî®ÁöÑÂø´Êç∑ÈîÆÊàñÂáΩÊï∞Êèí‰ª∂ÔºåÊ¨¢ËøéÂèëissueÊàñËÄÖpull requestsÔºàdevÂàÜÊîØÔºâ&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you like this project, please give it a Star. If you&#39;ve come up with more useful academic shortcuts or functional plugins, feel free to open an issue or pull request Ôºàto &lt;code&gt;dev&lt;/code&gt; branchÔºâ.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;1.ËØ∑Ê≥®ÊÑèÂè™Êúâ‚ÄúÁ∫¢È¢úËâ≤‚ÄùÊ†áËØÜÁöÑÂáΩÊï∞Êèí‰ª∂ÔºàÊåâÈíÆÔºâÊâçÊîØÊåÅËØªÂèñÊñá‰ª∂„ÄÇÁõÆÂâçÂØπpdf/wordÊ†ºÂºèÊñá‰ª∂ÁöÑÊîØÊåÅÊèí‰ª∂Ê≠£Âú®ÈÄêÊ≠•ÂÆåÂñÑ‰∏≠ÔºåÈúÄË¶ÅÊõ¥Â§ödeveloperÁöÑÂ∏ÆÂä©„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;2.Êú¨È°πÁõÆ‰∏≠ÊØè‰∏™Êñá‰ª∂ÁöÑÂäüËÉΩÈÉΩÂú®Ëá™ËØëËß£&lt;a href=&#34;https://github.com/binary-husky/chatgpt_academic/wiki/chatgpt-academic%E9%A1%B9%E7%9B%AE%E8%87%AA%E8%AF%91%E8%A7%A3%E6%8A%A5%E5%91%8A&#34;&gt;&lt;code&gt;self_analysis.md&lt;/code&gt;&lt;/a&gt;ËØ¶ÁªÜËØ¥Êòé„ÄÇÈöèÁùÄÁâàÊú¨ÁöÑËø≠‰ª£ÔºåÊÇ®‰πüÂèØ‰ª•ÈöèÊó∂Ëá™Ë°åÁÇπÂáªÁõ∏ÂÖ≥ÂáΩÊï∞Êèí‰ª∂ÔºåË∞ÉÁî®GPTÈáçÊñ∞ÁîüÊàêÈ°πÁõÆÁöÑËá™ÊàëËß£ÊûêÊä•Âëä„ÄÇÂ∏∏ËßÅÈóÆÈ¢òÊ±áÊÄªÂú®&lt;a href=&#34;https://github.com/binary-husky/chatgpt_academic/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98&#34;&gt;&lt;code&gt;wiki&lt;/code&gt;&lt;/a&gt;ÂΩì‰∏≠„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;3.Â¶ÇÊûúÊÇ®‰∏çÂ§™‰π†ÊÉØÈÉ®ÂàÜ‰∏≠ÊñáÂëΩÂêçÁöÑÂáΩÊï∞„ÄÅÊ≥®ÈáäÊàñËÄÖÁïåÈù¢ÔºåÊÇ®ÂèØ‰ª•ÈöèÊó∂ÁÇπÂáªÁõ∏ÂÖ≥ÂáΩÊï∞Êèí‰ª∂ÔºåË∞ÉÁî®ChatGPT‰∏ÄÈîÆÁîüÊàêÁ∫ØËã±ÊñáÁöÑÈ°πÁõÆÊ∫ê‰ª£Á†Å„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;4.È°πÁõÆ‰ΩøÁî®OpenAIÁöÑgpt-3.5-turboÊ®°ÂûãÔºåÊúüÂæÖgpt-4Êó©ÁÇπÊîæÂÆΩÈó®ÊßõüòÇ&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;ÂäüËÉΩ&lt;/th&gt; &#xA;    &lt;th&gt;ÊèèËø∞&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‰∏ÄÈîÆÊ∂¶Ëâ≤&lt;/td&gt; &#xA;    &lt;td&gt;ÊîØÊåÅ‰∏ÄÈîÆÊ∂¶Ëâ≤„ÄÅ‰∏ÄÈîÆÊü•ÊâæËÆ∫ÊñáËØ≠Ê≥ïÈîôËØØ&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‰∏ÄÈîÆ‰∏≠Ëã±‰∫íËØë&lt;/td&gt; &#xA;    &lt;td&gt;‰∏ÄÈîÆ‰∏≠Ëã±‰∫íËØë&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‰∏ÄÈîÆ‰ª£Á†ÅËß£Èáä&lt;/td&gt; &#xA;    &lt;td&gt;ÂèØ‰ª•Ê≠£Á°ÆÊòæÁ§∫‰ª£Á†Å„ÄÅËß£Èáä‰ª£Á†Å&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV14s4y1E7jN&#34;&gt;Ëá™ÂÆö‰πâÂø´Êç∑ÈîÆ&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;ÊîØÊåÅËá™ÂÆö‰πâÂø´Êç∑ÈîÆ&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1rc411W7Dr&#34;&gt;ÈÖçÁΩÆ‰ª£ÁêÜÊúçÂä°Âô®&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;ÊîØÊåÅÈÖçÁΩÆ‰ª£ÁêÜÊúçÂä°Âô®&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Ê®°ÂùóÂåñËÆæËÆ°&lt;/td&gt; &#xA;    &lt;td&gt;ÊîØÊåÅËá™ÂÆö‰πâÈ´òÈò∂ÁöÑÂÆûÈ™åÊÄßÂäüËÉΩ‰∏é[ÂáΩÊï∞Êèí‰ª∂]ÔºåÊèí‰ª∂ÊîØÊåÅ&lt;a href=&#34;https://github.com/binary-husky/chatgpt_academic/wiki/%E5%87%BD%E6%95%B0%E6%8F%92%E4%BB%B6%E6%8C%87%E5%8D%97&#34;&gt;ÁÉ≠Êõ¥Êñ∞&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1cj411A7VW&#34;&gt;Ëá™ÊàëÁ®ãÂ∫èÂâñÊûê&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;[ÂáΩÊï∞Êèí‰ª∂] ‰∏ÄÈîÆËØªÊáÇÊú¨È°πÁõÆÁöÑÊ∫ê‰ª£Á†Å&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1cj411A7VW&#34;&gt;Á®ãÂ∫èÂâñÊûê&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;[ÂáΩÊï∞Êèí‰ª∂] ‰∏ÄÈîÆÂèØ‰ª•ÂâñÊûêÂÖ∂‰ªñPython/C/C++/JavaÈ°πÁõÆÊ†ë&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;ËØªËÆ∫Êñá&lt;/td&gt; &#xA;    &lt;td&gt;[ÂáΩÊï∞Êèí‰ª∂] ‰∏ÄÈîÆËß£ËØªlatexËÆ∫ÊñáÂÖ®ÊñáÂπ∂ÁîüÊàêÊëòË¶Å&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;ÊâπÈáèÊ≥®ÈáäÁîüÊàê&lt;/td&gt; &#xA;    &lt;td&gt;[ÂáΩÊï∞Êèí‰ª∂] ‰∏ÄÈîÆÊâπÈáèÁîüÊàêÂáΩÊï∞Ê≥®Èáä&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;chatÂàÜÊûêÊä•ÂëäÁîüÊàê&lt;/td&gt; &#xA;    &lt;td&gt;[ÂáΩÊï∞Êèí‰ª∂] ËøêË°åÂêéËá™Âä®ÁîüÊàêÊÄªÁªìÊ±áÊä•&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1LM4y1279X&#34;&gt;arxivÂ∞èÂä©Êâã&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;[ÂáΩÊï∞Êèí‰ª∂] ËæìÂÖ•arxivÊñáÁ´†urlÂç≥ÂèØ‰∏ÄÈîÆÁøªËØëÊëòË¶Å+‰∏ãËΩΩPDF&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1KT411x7Wn&#34;&gt;PDFËÆ∫ÊñáÂÖ®ÊñáÁøªËØëÂäüËÉΩ&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;[ÂáΩÊï∞Êèí‰ª∂] PDFËÆ∫ÊñáÊèêÂèñÈ¢òÁõÆ&amp;amp;ÊëòË¶Å+ÁøªËØëÂÖ®ÊñáÔºàÂ§öÁ∫øÁ®ãÔºâ&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV19L411U7ia&#34;&gt;Ë∞∑Ê≠åÂ≠¶ÊúØÁªüÂêàÂ∞èÂä©Êâã&lt;/a&gt; (Version&amp;gt;=2.45)&lt;/td&gt; &#xA;    &lt;td&gt;[ÂáΩÊï∞Êèí‰ª∂] ÁªôÂÆö‰ªªÊÑèË∞∑Ê≠åÂ≠¶ÊúØÊêúÁ¥¢È°µÈù¢URLÔºåËÆ©gptÂ∏Æ‰Ω†ÈÄâÊã©ÊúâË∂£ÁöÑÊñáÁ´†&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;ÂÖ¨ÂºèÊòæÁ§∫&lt;/td&gt; &#xA;    &lt;td&gt;ÂèØ‰ª•ÂêåÊó∂ÊòæÁ§∫ÂÖ¨ÂºèÁöÑtexÂΩ¢ÂºèÂíåÊ∏≤ÊüìÂΩ¢Âºè&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;ÂõæÁâáÊòæÁ§∫&lt;/td&gt; &#xA;    &lt;td&gt;ÂèØ‰ª•Âú®markdown‰∏≠ÊòæÁ§∫ÂõæÁâá&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Â§öÁ∫øÁ®ãÂáΩÊï∞Êèí‰ª∂ÊîØÊåÅ&lt;/td&gt; &#xA;    &lt;td&gt;ÊîØÊåÅÂ§öÁ∫øË∞ÉÁî®chatgptÔºå‰∏ÄÈîÆÂ§ÑÁêÜÊµ∑ÈáèÊñáÊú¨ÊàñÁ®ãÂ∫è&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;ÊîØÊåÅGPTËæìÂá∫ÁöÑmarkdownË°®Ê†º&lt;/td&gt; &#xA;    &lt;td&gt;ÂèØ‰ª•ËæìÂá∫ÊîØÊåÅGPTÁöÑmarkdownË°®Ê†º&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;ÂêØÂä®ÊöóËâ≤gradio&lt;a href=&#34;https://github.com/binary-husky/chatgpt_academic/issues/173&#34;&gt;‰∏ªÈ¢ò&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Âú®ÊµèËßàÂô®urlÂêéÈù¢Ê∑ªÂä†&lt;code&gt;/?__dark-theme=true&lt;/code&gt;ÂèØ‰ª•ÂàáÊç¢dark‰∏ªÈ¢ò&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;huggingfaceÂÖçÁßëÂ≠¶‰∏äÁΩë&lt;a href=&#34;https://huggingface.co/spaces/qingxu98/gpt-academic&#34;&gt;Âú®Á∫ø‰ΩìÈ™å&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;ÁôªÈôÜhuggingfaceÂêéÂ§çÂà∂&lt;a href=&#34;https://huggingface.co/spaces/qingxu98/gpt-academic&#34;&gt;Ê≠§Á©∫Èó¥&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚Ä¶‚Ä¶&lt;/td&gt; &#xA;    &lt;td&gt;‚Ä¶‚Ä¶&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;!-- - Êñ∞ÁïåÈù¢ÔºàÂ∑¶Ôºömaster‰∏ªÂàÜÊîØ, Âè≥ÔºödevÂºÄÂèëÂâçÊ≤øÔºâ --&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Êñ∞ÁïåÈù¢&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/230361456-61078362-a966-4eb5-b49e-3c62ef18b860.gif&#34; width=&#34;700&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ÊâÄÊúâÊåâÈíÆÈÉΩÈÄöËøáËØªÂèñfunctional.pyÂä®ÊÄÅÁîüÊàêÔºåÂèØÈöèÊÑèÂä†Ëá™ÂÆö‰πâÂäüËÉΩÔºåËß£ÊîæÁ≤òË¥¥Êùø&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;img/ÂÖ¨Âºè.gif&#34; width=&#34;700&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ê∂¶Ëâ≤/Á∫†Èîô&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;img/Ê∂¶Ëâ≤.gif&#34; width=&#34;700&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ÊîØÊåÅGPTËæìÂá∫ÁöÑmarkdownË°®Ê†º&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/binary-husky/chatgpt_academic/master/img/demo2.jpg&#34; width=&#34;500&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Â¶ÇÊûúËæìÂá∫ÂåÖÂê´ÂÖ¨ÂºèÔºå‰ºöÂêåÊó∂‰ª•texÂΩ¢ÂºèÂíåÊ∏≤ÊüìÂΩ¢ÂºèÊòæÁ§∫ÔºåÊñπ‰æøÂ§çÂà∂ÂíåÈòÖËØª&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/230598842-1d7fcddd-815d-40ee-af60-baf488a199df.png&#34; width=&#34;700&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ÊáíÂæóÁúãÈ°πÁõÆ‰ª£Á†ÅÔºüÊï¥‰∏™Â∑•Á®ãÁõ¥Êé•ÁªôchatgptÁÇ´Âò¥Èáå&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/226935232-6b6a73ce-8900-4aee-93f9-733c7e6fef53.png&#34; width=&#34;700&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Áõ¥Êé•ËøêË°å (Windows, Linux or MacOS)&lt;/h2&gt; &#xA;&lt;h3&gt;1. ‰∏ãËΩΩÈ°πÁõÆ&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/binary-husky/chatgpt_academic.git&#xA;cd chatgpt_academic&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. ÈÖçÁΩÆAPI_KEYÂíå‰ª£ÁêÜËÆæÁΩÆ&lt;/h3&gt; &#xA;&lt;p&gt;Âú®&lt;code&gt;config.py&lt;/code&gt;‰∏≠ÔºåÈÖçÁΩÆ Êµ∑Â§ñProxy Âíå OpenAI API KEYÔºåËØ¥ÊòéÂ¶Ç‰∏ã&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;1. Â¶ÇÊûú‰Ω†Âú®ÂõΩÂÜÖÔºåÈúÄË¶ÅËÆæÁΩÆÊµ∑Â§ñ‰ª£ÁêÜÊâçËÉΩÂ§üÈ°∫Âà©‰ΩøÁî® OpenAI APIÔºåËÆæÁΩÆÊñπÊ≥ïËØ∑‰ªîÁªÜÈòÖËØªconfig.pyÔºà1.‰øÆÊîπÂÖ∂‰∏≠ÁöÑUSE_PROXY‰∏∫True; 2.ÊåâÁÖßËØ¥Êòé‰øÆÊîπÂÖ∂‰∏≠ÁöÑproxiesÔºâ„ÄÇ&#xA;2. ÈÖçÁΩÆ OpenAI API KEY„ÄÇ‰Ω†ÈúÄË¶ÅÂú® OpenAI ÂÆòÁΩë‰∏äÊ≥®ÂÜåÂπ∂Ëé∑Âèñ API KEY„ÄÇ‰∏ÄÊó¶‰Ω†ÊãøÂà∞‰∫Ü API KEYÔºåÂú® config.py Êñá‰ª∂ÈáåÈÖçÁΩÆÂ•ΩÂç≥ÂèØ„ÄÇ&#xA;3. ‰∏é‰ª£ÁêÜÁΩëÁªúÊúâÂÖ≥ÁöÑissueÔºàÁΩëÁªúË∂ÖÊó∂„ÄÅ‰ª£ÁêÜ‰∏çËµ∑‰ΩúÁî®ÔºâÊ±áÊÄªÂà∞ https://github.com/binary-husky/chatgpt_academic/issues/1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ÔºàP.S. Á®ãÂ∫èËøêË°åÊó∂‰ºö‰ºòÂÖàÊ£ÄÊü•ÊòØÂê¶Â≠òÂú®Âêç‰∏∫&lt;code&gt;config_private.py&lt;/code&gt;ÁöÑÁßÅÂØÜÈÖçÁΩÆÊñá‰ª∂ÔºåÂπ∂Áî®ÂÖ∂‰∏≠ÁöÑÈÖçÁΩÆË¶ÜÁõñ&lt;code&gt;config.py&lt;/code&gt;ÁöÑÂêåÂêçÈÖçÁΩÆ„ÄÇÂõ†Ê≠§ÔºåÂ¶ÇÊûúÊÇ®ËÉΩÁêÜËß£Êàë‰ª¨ÁöÑÈÖçÁΩÆËØªÂèñÈÄªËæëÔºåÊàë‰ª¨Âº∫ÁÉàÂª∫ËÆÆÊÇ®Âú®&lt;code&gt;config.py&lt;/code&gt;ÊóÅËæπÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫&lt;code&gt;config_private.py&lt;/code&gt;ÁöÑÊñ∞ÈÖçÁΩÆÊñá‰ª∂ÔºåÂπ∂Êää&lt;code&gt;config.py&lt;/code&gt;‰∏≠ÁöÑÈÖçÁΩÆËΩ¨ÁßªÔºàÂ§çÂà∂ÔºâÂà∞&lt;code&gt;config_private.py&lt;/code&gt;‰∏≠„ÄÇ&lt;code&gt;config_private.py&lt;/code&gt;‰∏çÂèógitÁÆ°ÊéßÔºåÂèØ‰ª•ËÆ©ÊÇ®ÁöÑÈöêÁßÅ‰ø°ÊÅØÊõ¥Âä†ÂÆâÂÖ®„ÄÇÔºâ&lt;/p&gt; &#xA;&lt;h3&gt;3. ÂÆâË£Ö‰æùËµñ&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# ÔºàÈÄâÊã©‰∏ÄÔºâÊé®Ëçê&#xA;python -m pip install -r requirements.txt   &#xA;&#xA;# ÔºàÈÄâÊã©‰∫åÔºâÂ¶ÇÊûúÊÇ®‰ΩøÁî®anacondaÔºåÊ≠•È™§‰πüÊòØÁ±ª‰ººÁöÑÔºö&#xA;# ÔºàÈÄâÊã©‰∫å.1Ôºâconda create -n gptac_venv python=3.11&#xA;# ÔºàÈÄâÊã©‰∫å.2Ôºâconda activate gptac_venv&#xA;# ÔºàÈÄâÊã©‰∫å.3Ôºâpython -m pip install -r requirements.txt&#xA;&#xA;# Â§áÊ≥®Ôºö‰ΩøÁî®ÂÆòÊñπpipÊ∫êÊàñËÄÖÈòøÈáåpipÊ∫êÔºåÂÖ∂‰ªñpipÊ∫êÔºàÂ¶Ç‰∏Ä‰∫õÂ§ßÂ≠¶ÁöÑpipÔºâÊúâÂèØËÉΩÂá∫ÈóÆÈ¢òÔºå‰∏¥Êó∂Êç¢Ê∫êÊñπÊ≥ïÔºö &#xA;# python -m pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;4. ËøêË°å&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;5. ÊµãËØïÂÆûÈ™åÊÄßÂäüËÉΩ&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;- ÊµãËØïC++È°πÁõÆÂ§¥Êñá‰ª∂ÂàÜÊûê&#xA;    inputÂå∫Âüü ËæìÂÖ• `./crazy_functions/test_project/cpp/libJPG` Ôºå ÁÑ∂ÂêéÁÇπÂáª &#34;[ÂÆûÈ™å] Ëß£ÊûêÊï¥‰∏™C++È°πÁõÆÔºàinputËæìÂÖ•È°πÁõÆÊ†πË∑ØÂæÑÔºâ&#34;&#xA;- ÊµãËØïÁªôLatexÈ°πÁõÆÂÜôÊëòË¶Å&#xA;    inputÂå∫Âüü ËæìÂÖ• `./crazy_functions/test_project/latex/attention` Ôºå ÁÑ∂ÂêéÁÇπÂáª &#34;[ÂÆûÈ™å] ËØªtexËÆ∫ÊñáÂÜôÊëòË¶ÅÔºàinputËæìÂÖ•È°πÁõÆÊ†πË∑ØÂæÑÔºâ&#34;&#xA;- ÊµãËØïPythonÈ°πÁõÆÂàÜÊûê&#xA;    inputÂå∫Âüü ËæìÂÖ• `./crazy_functions/test_project/python/dqn` Ôºå ÁÑ∂ÂêéÁÇπÂáª &#34;[ÂÆûÈ™å] Ëß£ÊûêÊï¥‰∏™pyÈ°πÁõÆÔºàinputËæìÂÖ•È°πÁõÆÊ†πË∑ØÂæÑÔºâ&#34;&#xA;- ÊµãËØïËá™Êàë‰ª£Á†ÅËß£ËØª&#xA;    ÁÇπÂáª &#34;[ÂÆûÈ™å] ËØ∑Ëß£ÊûêÂπ∂Ëß£ÊûÑÊ≠§È°πÁõÆÊú¨Ë∫´&#34;&#xA;- ÊµãËØïÂÆûÈ™åÂäüËÉΩÊ®°ÊùøÂáΩÊï∞ÔºàË¶ÅÊ±ÇgptÂõûÁ≠îÂéÜÂè≤‰∏äÁöÑ‰ªäÂ§©ÂèëÁîü‰∫Ü‰ªÄ‰πàÔºâÔºåÊÇ®ÂèØ‰ª•Ê†πÊçÆÊ≠§ÂáΩÊï∞‰∏∫Ê®°ÊùøÔºåÂÆûÁé∞Êõ¥Â§çÊùÇÁöÑÂäüËÉΩ&#xA;    ÁÇπÂáª &#34;[ÂÆûÈ™å] ÂÆûÈ™åÂäüËÉΩÂáΩÊï∞Ê®°Êùø&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;‰ΩøÁî®docker (Linux)&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# ‰∏ãËΩΩÈ°πÁõÆ&#xA;git clone https://github.com/binary-husky/chatgpt_academic.git&#xA;cd chatgpt_academic&#xA;# ÈÖçÁΩÆ Êµ∑Â§ñProxy Âíå OpenAI API KEY&#xA;Áî®‰ªªÊÑèÊñáÊú¨ÁºñËæëÂô®ÁºñËæë config.py&#xA;# ÂÆâË£Ö&#xA;docker build -t gpt-academic .&#xA;# ËøêË°å&#xA;docker run --rm -it --net=host gpt-academic&#xA;&#xA;# ÊµãËØïÂÆûÈ™åÊÄßÂäüËÉΩ&#xA;## ÊµãËØïËá™Êàë‰ª£Á†ÅËß£ËØª&#xA;ÁÇπÂáª &#34;[ÂÆûÈ™å] ËØ∑Ëß£ÊûêÂπ∂Ëß£ÊûÑÊ≠§È°πÁõÆÊú¨Ë∫´&#34;&#xA;## ÊµãËØïÂÆûÈ™åÂäüËÉΩÊ®°ÊùøÂáΩÊï∞ÔºàË¶ÅÊ±ÇgptÂõûÁ≠îÂéÜÂè≤‰∏äÁöÑ‰ªäÂ§©ÂèëÁîü‰∫Ü‰ªÄ‰πàÔºâÔºåÊÇ®ÂèØ‰ª•Ê†πÊçÆÊ≠§ÂáΩÊï∞‰∏∫Ê®°ÊùøÔºåÂÆûÁé∞Êõ¥Â§çÊùÇÁöÑÂäüËÉΩ&#xA;ÁÇπÂáª &#34;[ÂÆûÈ™å] ÂÆûÈ™åÂäüËÉΩÂáΩÊï∞Ê®°Êùø&#34;&#xA;##ÔºàËØ∑Ê≥®ÊÑèÂú®docker‰∏≠ËøêË°åÊó∂ÔºåÈúÄË¶ÅÈ¢ùÂ§ñÊ≥®ÊÑèÁ®ãÂ∫èÁöÑÊñá‰ª∂ËÆøÈóÆÊùÉÈôêÈóÆÈ¢òÔºâ&#xA;## ÊµãËØïC++È°πÁõÆÂ§¥Êñá‰ª∂ÂàÜÊûê&#xA;inputÂå∫Âüü ËæìÂÖ• ./crazy_functions/test_project/cpp/libJPG Ôºå ÁÑ∂ÂêéÁÇπÂáª &#34;[ÂÆûÈ™å] Ëß£ÊûêÊï¥‰∏™C++È°πÁõÆÔºàinputËæìÂÖ•È°πÁõÆÊ†πË∑ØÂæÑÔºâ&#34;&#xA;## ÊµãËØïÁªôLatexÈ°πÁõÆÂÜôÊëòË¶Å&#xA;inputÂå∫Âüü ËæìÂÖ• ./crazy_functions/test_project/latex/attention Ôºå ÁÑ∂ÂêéÁÇπÂáª &#34;[ÂÆûÈ™å] ËØªtexËÆ∫ÊñáÂÜôÊëòË¶ÅÔºàinputËæìÂÖ•È°πÁõÆÊ†πË∑ØÂæÑÔºâ&#34;&#xA;## ÊµãËØïPythonÈ°πÁõÆÂàÜÊûê&#xA;inputÂå∫Âüü ËæìÂÖ• ./crazy_functions/test_project/python/dqn Ôºå ÁÑ∂ÂêéÁÇπÂáª &#34;[ÂÆûÈ™å] Ëß£ÊûêÊï¥‰∏™pyÈ°πÁõÆÔºàinputËæìÂÖ•È°πÁõÆÊ†πË∑ØÂæÑÔºâ&#34;&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ÂÖ∂‰ªñÈÉ®ÁΩ≤ÊñπÂºè&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;‰ΩøÁî®WSL2ÔºàWindows Subsystem for Linux Â≠êÁ≥ªÁªüÔºâ ËØ∑ËÆøÈóÆ&lt;a href=&#34;https://github.com/binary-husky/chatgpt_academic/wiki/%E4%BD%BF%E7%94%A8WSL2%EF%BC%88Windows-Subsystem-for-Linux-%E5%AD%90%E7%B3%BB%E7%BB%9F%EF%BC%89%E9%83%A8%E7%BD%B2&#34;&gt;ÈÉ®ÁΩ≤wiki-1&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;nginxËøúÁ®ãÈÉ®ÁΩ≤ ËØ∑ËÆøÈóÆ&lt;a href=&#34;https://github.com/binary-husky/chatgpt_academic/wiki/%E8%BF%9C%E7%A8%8B%E9%83%A8%E7%BD%B2%E7%9A%84%E6%8C%87%E5%AF%BC&#34;&gt;ÈÉ®ÁΩ≤wiki-2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Ëá™ÂÆö‰πâÊñ∞ÁöÑ‰æøÊç∑ÊåâÈíÆÔºàÂ≠¶ÊúØÂø´Êç∑ÈîÆËá™ÂÆö‰πâÔºâ&lt;/h2&gt; &#xA;&lt;p&gt;ÊâìÂºÄfunctional.pyÔºåÊ∑ªÂä†Êù°ÁõÆÂ¶Ç‰∏ãÔºåÁÑ∂ÂêéÈáçÂêØÁ®ãÂ∫èÂç≥ÂèØ„ÄÇÔºàÂ¶ÇÊûúÊåâÈíÆÂ∑≤ÁªèÊ∑ªÂä†ÊàêÂäüÂπ∂ÂèØËßÅÔºåÈÇ£‰πàÂâçÁºÄ„ÄÅÂêéÁºÄÈÉΩÊîØÊåÅÁÉ≠‰øÆÊîπÔºåÊó†ÈúÄÈáçÂêØÁ®ãÂ∫èÂç≥ÂèØÁîüÊïà„ÄÇÔºâ ‰æãÂ¶Ç&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#34;Ë∂ÖÁ∫ßËã±ËØë‰∏≠&#34;: {&#xA;&#xA;    # ÂâçÁºÄÔºå‰ºöË¢´Âä†Âú®‰Ω†ÁöÑËæìÂÖ•‰πãÂâç„ÄÇ‰æãÂ¶ÇÔºåÁî®Êù•ÊèèËø∞‰Ω†ÁöÑË¶ÅÊ±ÇÔºå‰æãÂ¶ÇÁøªËØë„ÄÅËß£Èáä‰ª£Á†Å„ÄÅÊ∂¶Ëâ≤Á≠âÁ≠â&#xA;    &#34;Prefix&#34;: &#34;ËØ∑ÁøªËØëÊää‰∏ãÈù¢‰∏ÄÊÆµÂÜÖÂÆπÊàê‰∏≠ÊñáÔºåÁÑ∂ÂêéÁî®‰∏Ä‰∏™markdownË°®Ê†ºÈÄê‰∏ÄËß£ÈáäÊñá‰∏≠Âá∫Áé∞ÁöÑ‰∏ìÊúâÂêçËØçÔºö\n\n&#34;, &#xA;    &#xA;    # ÂêéÁºÄÔºå‰ºöË¢´Âä†Âú®‰Ω†ÁöÑËæìÂÖ•‰πãÂêé„ÄÇ‰æãÂ¶ÇÔºåÈÖçÂêàÂâçÁºÄÂèØ‰ª•Êää‰Ω†ÁöÑËæìÂÖ•ÂÜÖÂÆπÁî®ÂºïÂè∑ÂúàËµ∑Êù•„ÄÇ&#xA;    &#34;Suffix&#34;: &#34;&#34;,&#xA;    &#xA;},&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/226899272-477c2134-ed71-4326-810c-29891fe4a508.png&#34; width=&#34;500&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Â¶ÇÊûú‰Ω†ÂèëÊòé‰∫ÜÊõ¥Â•ΩÁî®ÁöÑÂ≠¶ÊúØÂø´Êç∑ÈîÆÔºåÊ¨¢ËøéÂèëissueÊàñËÄÖpull requestsÔºÅ&lt;/p&gt; &#xA;&lt;h2&gt;ÈÖçÁΩÆ‰ª£ÁêÜ&lt;/h2&gt; &#xA;&lt;h3&gt;ÊñπÊ≥ï‰∏ÄÔºöÂ∏∏ËßÑÊñπÊ≥ï&lt;/h3&gt; &#xA;&lt;p&gt;Âú®&lt;code&gt;config.py&lt;/code&gt;‰∏≠‰øÆÊîπÁ´ØÂè£‰∏é‰ª£ÁêÜËΩØ‰ª∂ÂØπÂ∫î&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/226571294-37a47cd9-4d40-4c16-97a2-d360845406f7.png&#34; width=&#34;500&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/226838985-e5c95956-69c2-4c23-a4dd-cd7944eeb451.png&#34; width=&#34;500&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;ÈÖçÁΩÆÂÆåÊàêÂêéÔºå‰Ω†ÂèØ‰ª•Áî®‰ª•‰∏ãÂëΩ‰ª§ÊµãËØï‰ª£ÁêÜÊòØÂê¶Â∑•‰ΩúÔºåÂ¶ÇÊûú‰∏ÄÂàáÊ≠£Â∏∏Ôºå‰∏ãÈù¢ÁöÑ‰ª£Á†ÅÂ∞ÜËæìÂá∫‰Ω†ÁöÑ‰ª£ÁêÜÊúçÂä°Âô®ÊâÄÂú®Âú∞Ôºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python check_proxy.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ÊñπÊ≥ï‰∫åÔºöÁ∫ØÊñ∞ÊâãÊïôÁ®ã&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/binary-husky/chatgpt_academic/wiki/%E4%BB%A3%E7%90%86%E8%BD%AF%E4%BB%B6%E9%97%AE%E9%A2%98%E7%9A%84%E6%96%B0%E6%89%8B%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%88%E6%96%B9%E6%B3%95%E5%8F%AA%E9%80%82%E7%94%A8%E4%BA%8E%E6%96%B0%E6%89%8B%EF%BC%89&#34;&gt;Á∫ØÊñ∞ÊâãÊïôÁ®ã&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ÂÖºÂÆπÊÄßÊµãËØï&lt;/h2&gt; &#xA;&lt;h3&gt;ÂõæÁâáÊòæÁ§∫Ôºö&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/228737599-bf0a9d9c-1808-4f43-ae15-dfcc7af0f295.png&#34; width=&#34;800&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Â¶ÇÊûú‰∏Ä‰∏™Á®ãÂ∫èËÉΩÂ§üËØªÊáÇÂπ∂ÂâñÊûêËá™Â∑±Ôºö&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/226936850-c77d7183-0749-4c1c-9875-fd4891842d0c.png&#34; width=&#34;800&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/226936618-9b487e4b-ab5b-4b6e-84c6-16942102e917.png&#34; width=&#34;800&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;ÂÖ∂‰ªñ‰ªªÊÑèPython/CppÈ°πÁõÆÂâñÊûêÔºö&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/226935232-6b6a73ce-8900-4aee-93f9-733c7e6fef53.png&#34; width=&#34;800&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/226969067-968a27c1-1b9c-486b-8b81-ab2de8d3f88a.png&#34; width=&#34;800&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;LatexËÆ∫Êñá‰∏ÄÈîÆÈòÖËØªÁêÜËß£‰∏éÊëòË¶ÅÁîüÊàê&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/227504406-86ab97cd-f208-41c3-8e4a-7000e51cf980.png&#34; width=&#34;800&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Ëá™Âä®Êä•ÂëäÁîüÊàê&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/227503770-fe29ce2c-53fd-47b0-b0ff-93805f0c2ff4.png&#34; height=&#34;300&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/227504617-7a497bb3-0a2a-4b50-9a8a-95ae60ea7afd.png&#34; height=&#34;300&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/227504005-efeaefe0-b687-49d0-bf95-2d7b7e66c348.png&#34; height=&#34;300&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Ê®°ÂùóÂåñÂäüËÉΩËÆæËÆ°&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/229288270-093643c1-0018-487a-81e6-1d7809b6e90f.png&#34; height=&#34;400&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/227504931-19955f78-45cd-4d1c-adac-e71e50957915.png&#34; height=&#34;400&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Ê∫ê‰ª£Á†ÅËΩ¨ËØëËã±Êñá&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/229720562-fe6c3508-6142-4635-a83d-21eb3669baee.png&#34; height=&#34;400&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Todo ‰∏é ÁâàÊú¨ËßÑÂàí:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;version 3 (Todo):&lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ÊîØÊåÅgpt4ÂíåÂÖ∂‰ªñÊõ¥Â§öllm&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;version 2.4+ (Todo):&lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ÊÄªÁªìÂ§ßÂ∑•Á®ãÊ∫ê‰ª£Á†ÅÊó∂ÊñáÊú¨ËøáÈïø„ÄÅtokenÊ∫¢Âá∫ÁöÑÈóÆÈ¢ò&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ÂÆûÁé∞È°πÁõÆÊâìÂåÖÈÉ®ÁΩ≤&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ÂáΩÊï∞Êèí‰ª∂ÂèÇÊï∞Êé•Âè£‰ºòÂåñ&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Ëá™Êõ¥Êñ∞&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;version 2.4: (1)Êñ∞Â¢ûPDFÂÖ®ÊñáÁøªËØëÂäüËÉΩ; (2)Êñ∞Â¢ûËæìÂÖ•Âå∫ÂàáÊç¢‰ΩçÁΩÆÁöÑÂäüËÉΩ; (3)Êñ∞Â¢ûÂûÇÁõ¥Â∏ÉÂ±ÄÈÄâÈ°π; (4)Â§öÁ∫øÁ®ãÂáΩÊï∞Êèí‰ª∂‰ºòÂåñ„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;version 2.3: Â¢ûÂº∫Â§öÁ∫øÁ®ã‰∫§‰∫íÊÄß&lt;/li&gt; &#xA; &lt;li&gt;version 2.2: ÂáΩÊï∞Êèí‰ª∂ÊîØÊåÅÁÉ≠ÈáçËΩΩ&lt;/li&gt; &#xA; &lt;li&gt;version 2.1: ÂèØÊäòÂè†ÂºèÂ∏ÉÂ±Ä&lt;/li&gt; &#xA; &lt;li&gt;version 2.0: ÂºïÂÖ•Ê®°ÂùóÂåñÂáΩÊï∞Êèí‰ª∂&lt;/li&gt; &#xA; &lt;li&gt;version 1.0: Âü∫Á°ÄÂäüËÉΩ&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ÂèÇËÄÉ‰∏éÂ≠¶‰π†&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;‰ª£Á†Å‰∏≠ÂèÇËÄÉ‰∫ÜÂæàÂ§öÂÖ∂‰ªñ‰ºòÁßÄÈ°πÁõÆ‰∏≠ÁöÑËÆæËÆ°Ôºå‰∏ªË¶ÅÂåÖÊã¨Ôºö&#xA;&#xA;# ÂÄüÈâ¥È°πÁõÆ1ÔºöÂÄüÈâ¥‰∫ÜChuanhuChatGPT‰∏≠ËØªÂèñOpenAI jsonÁöÑÊñπÊ≥ï„ÄÅËÆ∞ÂΩïÂéÜÂè≤ÈóÆËØ¢ËÆ∞ÂΩïÁöÑÊñπÊ≥ï‰ª•Âèägradio queueÁöÑ‰ΩøÁî®ÊäÄÂ∑ß&#xA;https://github.com/GaiZhenbiao/ChuanhuChatGPT&#xA;&#xA;# ÂÄüÈâ¥È°πÁõÆ2ÔºöÂÄüÈâ¥‰∫Ümdtex2html‰∏≠ÂÖ¨ÂºèÂ§ÑÁêÜÁöÑÊñπÊ≥ï&#xA;https://github.com/polarwinkel/mdtex2html&#xA;&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>