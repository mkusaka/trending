<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-10-27T01:42:15Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Guovin/TV</title>
    <updated>2024-10-27T01:42:15Z</updated>
    <id>tag:github.com,2024-10-27:/Guovin/TV</id>
    <link href="https://github.com/Guovin/TV" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ğŸ“ºIPTVç”µè§†ç›´æ’­æºæ›´æ–°å·¥å…·ğŸš€ï¼šåŒ…å«ğŸ’°å¤®è§†(ä»˜è´¹)ã€ğŸ“¡å«è§†ã€ğŸ å¹¿ä¸œã€ğŸŒŠæ¸¯Â·æ¾³Â·å°ã€ğŸ¬ç”µå½±ã€ğŸ¥å’ªå’•ã€ğŸ€ä½“è‚²ã€ğŸªåŠ¨ç”»ã€ğŸ®æ¸¸æˆã€ğŸµéŸ³ä¹ã€ğŸ›ç»å…¸å‰§åœºï¼›æ”¯æŒè‡ªå®šä¹‰å¢åŠ é¢‘é“ï¼›æ”¯æŒç»„æ’­æºã€é…’åº—æºã€è®¢é˜…æºã€å…³é”®å­—æœç´¢ï¼›æ¯å¤©è‡ªåŠ¨æ›´æ–°ä¸¤æ¬¡ï¼Œç»“æœå¯ç”¨äºTVBoxç­‰æ’­æ”¾è½¯ä»¶ï¼›æ”¯æŒå·¥ä½œæµã€Docker(amd64/arm64)ã€å‘½ä»¤è¡Œã€GUIè¿è¡Œæ–¹å¼ | IPTV live TV source update tool&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Guovin/TV/master/static/images/logo.png&#34; alt=&#34;logo&#34;&gt; &#xA; &lt;h1 align=&#34;center&#34;&gt;IPTVç”µè§†ç›´æ’­æºæ›´æ–°å·¥å…·&lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA; è‡ªå®šä¹‰é¢‘é“èœå•ï¼Œæ ¹æ®æ¨¡æ¿é¢‘é“ï¼Œè‡ªåŠ¨è·å–å¹¶æ›´æ–°æœ€æ–°çš„ç›´æ’­æºæ¥å£ï¼Œæµ‹é€Ÿæ ¡éªŒåç”Ÿæˆå¯ç”¨çš„æ¥å£æ–‡ä»¶&#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA; é»˜è®¤ç»“æœåŒ…å«ï¼šğŸ“ºå¤®è§†é¢‘é“ã€ğŸ’°å¤®è§†ä»˜è´¹é¢‘é“ã€ğŸ“¡å«è§†é¢‘é“ã€ğŸ å¹¿ä¸œé¢‘é“ã€ğŸŒŠæ¸¯Â·æ¾³Â·å°é¢‘é“ã€ğŸ¬ç”µå½±é¢‘é“ã€ğŸ¥å’ªå’•ç›´æ’­ã€ğŸ€ä½“è‚²é¢‘é“ã€ğŸªåŠ¨ç”»é¢‘é“ã€ğŸ®æ¸¸æˆé¢‘é“ã€ğŸµéŸ³ä¹é¢‘é“ã€ğŸ›ç»å…¸å‰§åœº&#xA;&lt;/div&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;å…·ä½“é¢‘é“&lt;/summary&gt; &#xA; &lt;div&gt;&#xA;   ğŸ“ºå¤®è§†é¢‘é“: CCTV-1, CCTV-2, CCTV-3, CCTV-4, CCTV-5, CCTV-5+, CCTV-6, CCTV-7, CCTV-8, CCTV-9, CCTV-10, CCTV-11, CCTV-12, CCTV-13, CCTV-14, CCTV-15, CCTV-16, CCTV-17, CETV1, CETV2, CETV4, CETV5 &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   ğŸ’°å¤®è§†ä»˜è´¹é¢‘é“: æ–‡åŒ–ç²¾å“, å¤®è§†å°çƒ, é£äº‘éŸ³ä¹, ç¬¬ä¸€å‰§åœº, é£äº‘å‰§åœº, æ€€æ—§å‰§åœº, å¥³æ€§æ—¶å°š, é«˜å°”å¤«ç½‘çƒ, é£äº‘è¶³çƒ, ç”µè§†æŒ‡å—, ä¸–ç•Œåœ°ç†, å…µå™¨ç§‘æŠ€ &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   ğŸ“¡å«è§†é¢‘é“: å¹¿ä¸œå«è§†, é¦™æ¸¯å«è§†, æµ™æ±Ÿå«è§†, æ¹–å—å«è§†, åŒ—äº¬å«è§†, æ¹–åŒ—å«è§†, é»‘é¾™æ±Ÿå«è§†, å®‰å¾½å«è§†, é‡åº†å«è§†, ä¸œæ–¹å«è§†, ä¸œå—å«è§†, ç”˜è‚ƒå«è§†, å¹¿è¥¿å«è§†, è´µå·å«è§†, æµ·å—å«è§†, æ²³åŒ—å«è§†, æ²³å—å«è§†, å‰æ—å«è§†, æ±Ÿè‹å«è§†, æ±Ÿè¥¿å«è§†, è¾½å®å«è§†, å†…è’™å¤å«è§†, å®å¤å«è§†, é’æµ·å«è§†, å±±ä¸œå«è§†, å±±è¥¿å«è§†, é™•è¥¿å«è§†, å››å·å«è§†, æ·±åœ³å«è§†, ä¸‰æ²™å«è§†, å¤©æ´¥å«è§†, è¥¿è—å«è§†, æ–°ç–†å«è§†, äº‘å—å«è§† &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   ğŸ å¹¿ä¸œé¢‘é“: å¹¿ä¸œç æ±Ÿ, å¹¿ä¸œä½“è‚², å¹¿ä¸œæ–°é—», å¹¿ä¸œå«è§†, å¤§æ¹¾åŒºå«è§†, å¹¿å·å½±è§†, å¹¿å·ç«èµ›, æ±Ÿé—¨ç»¼åˆ, æ±Ÿé—¨ä¾¨ä¹¡ç”Ÿæ´», ä½›å±±ç»¼åˆ, æ·±åœ³å«è§†, æ±•å¤´ç»¼åˆ, æ±•å¤´ç»æµ, æ±•å¤´æ–‡æ—…, èŒ‚åç»¼åˆ, èŒ‚åå…¬å…± &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   ğŸŒŠæ¸¯Â·æ¾³Â·å°: ç¿¡ç¿ å°, æ˜ç å°, å‡¤å‡°ä¸­æ–‡, å‡¤å‡°èµ„è®¯, å‡¤å‡°é¦™æ¸¯, å‡¤å‡°å«è§†, TVBSäºšæ´², é¦™æ¸¯å«è§†, çº¬æ¥ä½“è‚², çº¬æ¥è‚²ä¹, J2, Viutv, ä¸‰ç«‹å°æ¹¾, æ— çº¿æ–°é—», ä¸‰ç«‹æ–°é—», ä¸œæ£®ç»¼åˆ, ä¸œæ£®è¶…è§†, ä¸œæ£®ç”µå½±, Nowå‰§é›†, Nowåå‰§, é–å¤©èµ„è®¯, æ˜Ÿå«å¨±ä¹, å«è§†å¡å¼ &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   ğŸ¬ç”µå½±é¢‘é“: CHCå®¶åº­å½±é™¢, CHCåŠ¨ä½œç”µå½±, CHCé«˜æ¸…ç”µå½±, æ·˜å‰§åœº, æ·˜å¨±ä¹, æ·˜ç”µå½±, NewTVæƒŠæ‚šæ‚¬ç–‘, NewTVåŠ¨ä½œç”µå½±, é»‘è“ç”µå½±, çº¬æ¥ç”µå½±, é–å¤©æ˜ ç”», é–å¤©æˆå‰§, æ˜Ÿå«å¨±ä¹, è‰¾å°”è¾¾å¨±ä¹, ç»å…¸ç”µå½±, IPTVç»å…¸ç”µå½±, å¤©æ˜ ç»å…¸, æ— çº¿æ˜Ÿæ²³, æ˜Ÿç©ºå«è§†, ç§äººå½±é™¢, ä¸œæ£®ç”µå½±, é¾™ç¥¥ç”µå½±, ä¸œæ£®æ´‹ç‰‡, ä¸œæ£®è¶…è§† &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   ğŸ¥å’ªå’•ç›´æ’­: å’ªå’•ç›´æ’­1-45 &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   ğŸ€ä½“è‚²é¢‘é“: CCTV-5, CCTV-5+, å¹¿ä¸œä½“è‚², çº¬æ¥ä½“è‚², äº”æ˜Ÿä½“è‚², ä½“è‚²èµ›äº‹, åŠ²çˆ†ä½“è‚², çˆ±ä½“è‚², è¶…çº§ä½“è‚², ç²¾å“ä½“è‚², å¹¿å·ç«èµ›, æ·±åœ³ä½“è‚², ç¦å»ºä½“è‚², è¾½å®ä½“è‚², å±±ä¸œä½“è‚², æˆéƒ½ä½“è‚², å¤©æ´¥ä½“è‚², æ±Ÿè‹ä½“è‚², å®‰å¾½ç»¼è‰ºä½“è‚², å‰æ—ç¯®çƒ, ç›å½©ç¯®çƒ, ç›å½©ç¾½æ¯›çƒ, ç›å½©å¹¿åœºèˆ, é£äº‘è¶³çƒ, è¶³çƒé¢‘é“, é­…åŠ›è¶³çƒ, å¤©å…ƒå›´æ£‹, å¿«ä¹å‚é’“, JJæ–—åœ°ä¸» &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   ğŸªåŠ¨ç”»é¢‘é“: å°‘å„¿åŠ¨ç”», å¡é…·åŠ¨ç”», åŠ¨æ¼«ç§€åœº, æ–°åŠ¨æ¼«, é’æ˜¥åŠ¨æ¼«, çˆ±åŠ¨æ¼«, ä¸­å½•åŠ¨æ¼«, å®å®åŠ¨ç”», CNå¡é€š, ä¼˜æ¼«å¡é€š, é‡‘é¹°å¡é€š, ç›å½©å°‘å„¿, é»‘è“åŠ¨ç”», ç‚«åŠ¨å¡é€š, 24Hå›½æ¼«çƒ­æ’­, æµ™æ±Ÿå°‘å„¿, æ²³åŒ—å°‘å„¿ç§‘æ•™, ä¸ƒé¾™ç , ç«å½±å¿è€…, æµ·ç»µå®å®, ä¸­åå°å½“å®¶, æ–—ç ´è‹ç©¹ç„å¹»å‰§, çŒ«å’Œè€é¼ , ç»å…¸åŠ¨æ¼«, èœ¡ç¬”å°æ–°, æ¼«ç”»è§£è¯´ &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   ğŸ®æ¸¸æˆé¢‘é“: æ¸¸æˆé£äº‘, æ¸¸æˆç«æŠ€, ç”µç«æ¸¸æˆ, æµ·çœ‹ç”µç«, ç”µç«å¤©å ‚, çˆ±ç”µç« &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   ğŸµéŸ³ä¹é¢‘é“: CCTV-15, é£äº‘éŸ³ä¹, éŸ³ä¹ç°åœº, éŸ³ä¹ä¹‹å£°, æ½®æµéŸ³ä¹, å¤©æ´¥éŸ³ä¹, éŸ³ä¹å¹¿æ’­, éŸ³ä¹è°ƒé¢‘å¹¿æ’­ &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   ğŸ›ç»å…¸å‰§åœº: ç¬‘å‚²æ±Ÿæ¹–, å¤©é¾™å…«éƒ¨, é¹¿é¼è®°, ä»™å‰‘å¥‡ä¾ ä¼ , è¥¿æ¸¸è®°, ä¸‰å›½æ¼”ä¹‰, æ°´æµ’ä¼ , æ–°ç™½å¨˜å­ä¼ å¥‡, å¤©é¾™å…«éƒ¨, æµå…¬æ¸¸è®°, å°ç¥æ¦œ, é—¯å…³ä¸œ, ä¸Šæµ·æ»©, å°„é›•è‹±é›„ä¼  &#xA; &lt;/div&gt; &#xA;&lt;/details&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/Guovin/TV/releases/latest&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/v/release/guovin/tv&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://www.python.org/&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/python-%20%3E%3D%203.8-47c219&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/Guovin/TV/releases/latest&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/downloads/guovin/tv/total&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/repository/docker/guovern/tv-requests&#34;&gt; &lt;img src=&#34;https://img.shields.io/docker/pulls/guovern/tv-requests?label=docker:requests&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/repository/docker/guovern/tv-driver&#34;&gt; &lt;img src=&#34;https://img.shields.io/docker/pulls/guovern/tv-driver?label=docker:driver&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Guovin/TV/master/README_en.md&#34;&gt;English&lt;/a&gt; | ä¸­æ–‡&lt;/p&gt; &#xA;&lt;h2&gt;ç‰¹ç‚¹&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;è‡ªå®šä¹‰æ¨¡æ¿ï¼Œç”Ÿæˆæ‚¨æƒ³è¦çš„é¢‘é“&lt;/li&gt; &#xA; &lt;li&gt;æ”¯æŒå¤šç§è·å–æºæ–¹å¼ï¼šç»„æ’­æºã€é…’åº—æºã€è®¢é˜…æºã€å…³é”®å­—æœç´¢&lt;/li&gt; &#xA; &lt;li&gt;æ¥å£æµ‹é€ŸéªŒæ•ˆï¼Œå“åº”æ—¶é—´ã€åˆ†è¾¨ç‡ä¼˜å…ˆçº§ï¼Œè¿‡æ»¤æ— æ•ˆæ¥å£&lt;/li&gt; &#xA; &lt;li&gt;å®šæ—¶æ‰§è¡Œï¼ŒåŒ—äº¬æ—¶é—´æ¯æ—¥ 6:00 ä¸ 18:00 æ‰§è¡Œæ›´æ–°&lt;/li&gt; &#xA; &lt;li&gt;æ”¯æŒå¤šç§è¿è¡Œæ–¹å¼ï¼šå·¥ä½œæµã€å‘½ä»¤è¡Œã€GUI è½¯ä»¶ã€Docker(amd64/arm64)&lt;/li&gt; &#xA; &lt;li&gt;æ›´å¤šåŠŸèƒ½è¯·è§&lt;a href=&#34;https://raw.githubusercontent.com/Guovin/TV/master/docs/config.md&#34;&gt;é…ç½®å‚æ•°&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;æœ€æ–°ç»“æœï¼š&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æ¥å£æºï¼š&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  https://ghproxy.net/raw.githubusercontent.com/Guovin/TV/gd/output/result.m3u&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æ•°æ®æºï¼š&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  https://ghproxy.net/raw.githubusercontent.com/Guovin/TV/gd/source.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;é…ç½®&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Guovin/TV/master/docs/config.md&#34;&gt;é…ç½®å‚æ•°&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;å¿«é€Ÿä¸Šæ‰‹&lt;/h2&gt; &#xA;&lt;h3&gt;æ–¹å¼ä¸€ï¼šå·¥ä½œæµæ›´æ–°&lt;/h3&gt; &#xA;&lt;p&gt;Fork æœ¬é¡¹ç›®å¹¶å¼€å¯å·¥ä½œæµæ›´æ–°ï¼Œå…·ä½“æ­¥éª¤è¯·è§&lt;a href=&#34;https://raw.githubusercontent.com/Guovin/TV/master/docs/tutorial.md&#34;&gt;è¯¦ç»†æ•™ç¨‹&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;æ–¹å¼äºŒï¼šå‘½ä»¤è¡Œæ›´æ–°&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pip3 install pipenv&#xA;pipenv install&#xA;pipenv run build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;æ–¹å¼ä¸‰ï¼šGUI è½¯ä»¶æ›´æ–°&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;ä¸‹è½½&lt;a href=&#34;https://github.com/Guovin/TV/releases&#34;&gt;æ›´æ–°å·¥å…·è½¯ä»¶&lt;/a&gt;ï¼Œæ‰“å¼€è½¯ä»¶ï¼Œç‚¹å‡»æ›´æ–°ï¼Œå³å¯å®Œæˆæ›´æ–°&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;æˆ–è€…åœ¨é¡¹ç›®ç›®å½•ä¸‹è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå³å¯æ‰“å¼€ GUI è½¯ä»¶ï¼š&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pipenv run ui&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/Guovin/TV/master/docs/images/ui.png&#34; alt=&#34;æ›´æ–°å·¥å…·è½¯ä»¶&#34; title=&#34;æ›´æ–°å·¥å…·è½¯ä»¶&#34; style=&#34;height:600px&#34;&gt; &#xA;&lt;h3&gt;æ–¹å¼å››ï¼šDocker æ›´æ–°&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;requestsï¼šè½»é‡çº§ï¼Œæ€§èƒ½è¦æ±‚ä½ï¼Œæ›´æ–°é€Ÿåº¦å¿«ï¼Œç¨³å®šæ€§ä¸ç¡®å®šï¼ˆæ¨èè®¢é˜…æºä½¿ç”¨æ­¤ç‰ˆæœ¬ï¼‰&lt;/li&gt; &#xA; &lt;li&gt;driverï¼šæ€§èƒ½è¦æ±‚è¾ƒé«˜ï¼Œæ›´æ–°é€Ÿåº¦è¾ƒæ…¢ï¼Œç¨³å®šæ€§ã€æˆåŠŸç‡é«˜ï¼›ä¿®æ”¹é…ç½® open_driver = False å¯åˆ‡æ¢åˆ° request ç‰ˆæœ¬ï¼ˆæ¨èé…’åº—æºã€ç»„æ’­æºã€å…³é”®å­—æœç´¢ä½¿ç”¨æ­¤ç‰ˆæœ¬ï¼‰&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;å»ºè®®éƒ½è¯•ç”¨ä¸€æ¬¡ï¼Œé€‰æ‹©è‡ªå·±åˆé€‚çš„ç‰ˆæœ¬ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;1. æ‹‰å–é•œåƒï¼š&#xA;requestsï¼š&#xA;docker pull guovern/tv-requests:latest&#xA;&#xA;driverï¼š&#xA;docker pull guovern/tv-driver:latest&#xA;&#xA;2. è¿è¡Œå®¹å™¨ï¼š&#xA;docker run -d -p 8000:8000 guovern/tv-requests æˆ– tv-driver&#xA;&#xA;å·æŒ‚è½½å‚æ•°ï¼ˆå¯é€‰ï¼‰ï¼š&#xA;å®ç°å®¿ä¸»æœºæ–‡ä»¶ä¸å®¹å™¨æ–‡ä»¶åŒæ­¥ï¼Œä¿®æ”¹æ¨¡æ¿ã€é…ç½®ã€è·å–æ›´æ–°ç»“æœæ–‡ä»¶å¯ç›´æ¥åœ¨å®¿ä¸»æœºæ–‡ä»¶å¤¹ä¸‹æ“ä½œ&#xA;&#xA;é…ç½®æ–‡ä»¶ï¼š&#xA;-v å®¿ä¸»æœºè·¯å¾„/config:/tv-requests/config æˆ– tv-driver/config&#xA;&#xA;ç»“æœæ–‡ä»¶ï¼š&#xA;-v å®¿ä¸»æœºè·¯å¾„/output:/tv-requests/output æˆ– tv-driver/output&#xA;&#xA;ä¾‹ï¼šdocker run -v /etc/docker/config:/tv-requests/config -v /etc/docker/output:/tv-requests/output -d -p 8000:8000 guovern/tv-requests&#xA;&#xA;3. æŸ¥çœ‹æ›´æ–°ç»“æœï¼šè®¿é—®ï¼ˆåŸŸå:8000ï¼‰&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;æ³¨ï¼šæ–¹å¼ä¸€è‡³ä¸‰æ›´æ–°å®Œæˆåçš„ç»“æœæ–‡ä»¶é“¾æ¥ï¼š&lt;a href=&#34;http://%E6%9C%AC%E5%9C%B0&#34;&gt;http://æœ¬åœ°&lt;/a&gt; ip:8000 æˆ– &lt;a href=&#34;http://localhost:8000&#34;&gt;http://localhost:8000&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;h2&gt;æ›´æ–°æ—¥å¿—&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Guovin/TV/master/CHANGELOG.md&#34;&gt;æ›´æ–°æ—¥å¿—&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;è®¸å¯è¯&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Guovin/TV/master/LICENSE&#34;&gt;MIT&lt;/a&gt; License Â© 2024-PRESENT &lt;a href=&#34;https://github.com/guovin&#34;&gt;Govin&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;èµèµ&lt;/h2&gt; &#xA;&lt;div&gt;&#xA; è¯·æˆ‘å–æ¯å’–å•¡â˜•ï¸å§~&#xA;&lt;/div&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;æ”¯ä»˜å®&lt;/th&gt; &#xA;   &lt;th&gt;å¾®ä¿¡&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Guovin/TV/master/static/images/alipay.jpg&#34; alt=&#34;æ”¯ä»˜å®æ‰«ç &#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Guovin/TV/master/static/images/appreciate.jpg&#34; alt=&#34;å¾®ä¿¡æ‰«ç &#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;å…è´£å£°æ˜&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ äº¤æµç”¨é€”ï¼Œæ¥å£æ•°æ®å‡æ¥æºäºç½‘ç»œï¼Œå¦‚æœ‰ä¾µæƒï¼Œè¯·è”ç³»åˆ é™¤&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>crewAIInc/crewAI</title>
    <updated>2024-10-27T01:42:15Z</updated>
    <id>tag:github.com,2024-10-27:/crewAIInc/crewAI</id>
    <link href="https://github.com/crewAIInc/crewAI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/docs/crewai_logo.png&#34; alt=&#34;Logo of CrewAI, two people rowing on a boat&#34;&gt;&lt;/p&gt; &#xA; &lt;h1&gt;&lt;strong&gt;CrewAI&lt;/strong&gt;&lt;/h1&gt; &#xA; &lt;p&gt;ğŸ¤– &lt;strong&gt;CrewAI&lt;/strong&gt;: Cutting-edge framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.&lt;/p&gt; &#xA; &lt;h3&gt; &lt;p&gt;&lt;a href=&#34;https://www.crewai.com/&#34;&gt;Homepage&lt;/a&gt; | &lt;a href=&#34;https://docs.crewai.com/&#34;&gt;Documentation&lt;/a&gt; | &lt;a href=&#34;https://chatg.pt/DWjSBZn&#34;&gt;Chat with Docs&lt;/a&gt; | &lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples&#34;&gt;Examples&lt;/a&gt; | &lt;a href=&#34;https://community.crewai.com&#34;&gt;Discourse&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/crewAIInc/crewAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/joaomdmoura/crewAI&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-green.svg?sanitize=true&#34; alt=&#34;License: MIT&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Table of contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#why-crewai&#34;&gt;Why CrewAI?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#getting-started&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#key-features&#34;&gt;Key Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#examples&#34;&gt;Examples&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#quick-tutorial&#34;&gt;Quick Tutorial&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#write-job-descriptions&#34;&gt;Write Job Descriptions&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#trip-planner&#34;&gt;Trip Planner&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#stock-analysis&#34;&gt;Stock Analysis&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#connecting-your-crew-to-a-model&#34;&gt;Connecting Your Crew to a Model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#how-crewai-compares&#34;&gt;How CrewAI Compares&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#contribution&#34;&gt;Contribution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#telemetry&#34;&gt;Telemetry&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why CrewAI?&lt;/h2&gt; &#xA;&lt;p&gt;The power of AI collaboration has too much to offer. CrewAI is designed to enable AI agents to assume roles, share goals, and operate in a cohesive unit - much like a well-oiled crew. Whether you&#39;re building a smart assistant platform, an automated customer service ensemble, or a multi-agent research team, CrewAI provides the backbone for sophisticated multi-agent interactions.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To get started with CrewAI, follow these simple steps:&lt;/p&gt; &#xA;&lt;h3&gt;1. Installation&lt;/h3&gt; &#xA;&lt;p&gt;Ensure you have Python &amp;gt;=3.10 &amp;lt;=3.13 installed on your system. CrewAI uses &lt;a href=&#34;https://docs.astral.sh/uv/&#34;&gt;UV&lt;/a&gt; for dependency management and package handling, offering a seamless setup and execution experience.&lt;/p&gt; &#xA;&lt;p&gt;First, install CrewAI:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install crewai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to install the &#39;crewai&#39; package along with its optional features that include additional tools for agents, you can do so by using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install &#39;crewai[tools]&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The command above installs the basic package and also adds extra components which require more dependencies to function.&lt;/p&gt; &#xA;&lt;h3&gt;2. Setting Up Your Crew with the YAML Configuration&lt;/h3&gt; &#xA;&lt;p&gt;To create a new CrewAI project, run the following CLI (Command Line Interface) command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;crewai create crew &amp;lt;project_name&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command creates a new project folder with the following structure:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;my_project/&#xA;â”œâ”€â”€ .gitignore&#xA;â”œâ”€â”€ pyproject.toml&#xA;â”œâ”€â”€ README.md&#xA;â”œâ”€â”€ .env&#xA;â””â”€â”€ src/&#xA;    â””â”€â”€ my_project/&#xA;        â”œâ”€â”€ __init__.py&#xA;        â”œâ”€â”€ main.py&#xA;        â”œâ”€â”€ crew.py&#xA;        â”œâ”€â”€ tools/&#xA;        â”‚   â”œâ”€â”€ custom_tool.py&#xA;        â”‚   â””â”€â”€ __init__.py&#xA;        â””â”€â”€ config/&#xA;            â”œâ”€â”€ agents.yaml&#xA;            â””â”€â”€ tasks.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can now start developing your crew by editing the files in the &lt;code&gt;src/my_project&lt;/code&gt; folder. The &lt;code&gt;main.py&lt;/code&gt; file is the entry point of the project, the &lt;code&gt;crew.py&lt;/code&gt; file is where you define your crew, the &lt;code&gt;agents.yaml&lt;/code&gt; file is where you define your agents, and the &lt;code&gt;tasks.yaml&lt;/code&gt; file is where you define your tasks.&lt;/p&gt; &#xA;&lt;h4&gt;To customize your project, you can:&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Modify &lt;code&gt;src/my_project/config/agents.yaml&lt;/code&gt; to define your agents.&lt;/li&gt; &#xA; &lt;li&gt;Modify &lt;code&gt;src/my_project/config/tasks.yaml&lt;/code&gt; to define your tasks.&lt;/li&gt; &#xA; &lt;li&gt;Modify &lt;code&gt;src/my_project/crew.py&lt;/code&gt; to add your own logic, tools, and specific arguments.&lt;/li&gt; &#xA; &lt;li&gt;Modify &lt;code&gt;src/my_project/main.py&lt;/code&gt; to add custom inputs for your agents and tasks.&lt;/li&gt; &#xA; &lt;li&gt;Add your environment variables into the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Example of a simple crew with a sequential process:&lt;/h4&gt; &#xA;&lt;p&gt;Instatiate your crew:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;crewai create crew latest-ai-development&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Modify the files as needed to fit your use case:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;agents.yaml&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# src/my_project/config/agents.yaml&#xA;researcher:&#xA;  role: &amp;gt;&#xA;    {topic} Senior Data Researcher&#xA;  goal: &amp;gt;&#xA;    Uncover cutting-edge developments in {topic}&#xA;  backstory: &amp;gt;&#xA;    You&#39;re a seasoned researcher with a knack for uncovering the latest&#xA;    developments in {topic}. Known for your ability to find the most relevant&#xA;    information and present it in a clear and concise manner.&#xA;      &#xA;reporting_analyst:&#xA;  role: &amp;gt;&#xA;    {topic} Reporting Analyst&#xA;  goal: &amp;gt;&#xA;    Create detailed reports based on {topic} data analysis and research findings&#xA;  backstory: &amp;gt;&#xA;    You&#39;re a meticulous analyst with a keen eye for detail. You&#39;re known for&#xA;    your ability to turn complex data into clear and concise reports, making&#xA;    it easy for others to understand and act on the information you provide.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;tasks.yaml&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# src/my_project/config/tasks.yaml&#xA;research_task:&#xA;  description: &amp;gt;&#xA;    Conduct a thorough research about {topic}&#xA;    Make sure you find any interesting and relevant information given&#xA;    the current year is 2024.&#xA;  expected_output: &amp;gt;&#xA;    A list with 10 bullet points of the most relevant information about {topic}&#xA;  agent: researcher&#xA;&#xA;reporting_task:&#xA;  description: &amp;gt;&#xA;    Review the context you got and expand each topic into a full section for a report.&#xA;    Make sure the report is detailed and contains any and all relevant information.&#xA;  expected_output: &amp;gt;&#xA;    A fully fledge reports with the mains topics, each with a full section of information.&#xA;    Formatted as markdown without &#39;```&#39;&#xA;  agent: reporting_analyst&#xA;  output_file: report.md&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;crew.py&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# src/my_project/crew.py&#xA;from crewai import Agent, Crew, Process, Task&#xA;from crewai.project import CrewBase, agent, crew, task&#xA;from crewai_tools import SerperDevTool&#xA;&#xA;@CrewBase&#xA;class LatestAiDevelopmentCrew():&#xA;&#x9;&#34;&#34;&#34;LatestAiDevelopment crew&#34;&#34;&#34;&#xA;&#xA;&#x9;@agent&#xA;&#x9;def researcher(self) -&amp;gt; Agent:&#xA;&#x9;&#x9;return Agent(&#xA;&#x9;&#x9;&#x9;config=self.agents_config[&#39;researcher&#39;],&#xA;&#x9;&#x9;&#x9;verbose=True,&#xA;&#x9;&#x9;&#x9;tools=[SerperDevTool()]&#xA;&#x9;&#x9;)&#xA;&#xA;&#x9;@agent&#xA;&#x9;def reporting_analyst(self) -&amp;gt; Agent:&#xA;&#x9;&#x9;return Agent(&#xA;&#x9;&#x9;&#x9;config=self.agents_config[&#39;reporting_analyst&#39;],&#xA;&#x9;&#x9;&#x9;verbose=True&#xA;&#x9;&#x9;)&#xA;&#xA;&#x9;@task&#xA;&#x9;def research_task(self) -&amp;gt; Task:&#xA;&#x9;&#x9;return Task(&#xA;&#x9;&#x9;&#x9;config=self.tasks_config[&#39;research_task&#39;],&#xA;&#x9;&#x9;)&#xA;&#xA;&#x9;@task&#xA;&#x9;def reporting_task(self) -&amp;gt; Task:&#xA;&#x9;&#x9;return Task(&#xA;&#x9;&#x9;&#x9;config=self.tasks_config[&#39;reporting_task&#39;],&#xA;&#x9;&#x9;&#x9;output_file=&#39;report.md&#39;&#xA;&#x9;&#x9;)&#xA;&#xA;&#x9;@crew&#xA;&#x9;def crew(self) -&amp;gt; Crew:&#xA;&#x9;&#x9;&#34;&#34;&#34;Creates the LatestAiDevelopment crew&#34;&#34;&#34;&#xA;&#x9;&#x9;return Crew(&#xA;&#x9;&#x9;&#x9;agents=self.agents, # Automatically created by the @agent decorator&#xA;&#x9;&#x9;&#x9;tasks=self.tasks, # Automatically created by the @task decorator&#xA;&#x9;&#x9;&#x9;process=Process.sequential,&#xA;&#x9;&#x9;&#x9;verbose=True,&#xA;&#x9;&#x9;) &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;main.py&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python&#xA;# src/my_project/main.py&#xA;import sys&#xA;from latest_ai_development.crew import LatestAiDevelopmentCrew&#xA;&#xA;def run():&#xA;    &#34;&#34;&#34;&#xA;    Run the crew.&#xA;    &#34;&#34;&#34;&#xA;    inputs = {&#xA;        &#39;topic&#39;: &#39;AI Agents&#39;&#xA;    }&#xA;    LatestAiDevelopmentCrew().crew().kickoff(inputs=inputs)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. Running Your Crew&lt;/h3&gt; &#xA;&lt;p&gt;Before running your crew, make sure you have the following keys set as environment variables in your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;An &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;OpenAI API key&lt;/a&gt; (or other LLM API key): &lt;code&gt;OPENAI_API_KEY=sk-...&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;A &lt;a href=&#34;https://serper.dev/&#34;&gt;Serper.dev&lt;/a&gt; API key: &lt;code&gt;SERPER_API_KEY=YOUR_KEY_HERE&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Lock the dependencies and install them by using the CLI command but first, navigate to your project directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd my_project&#xA;crewai install (Optional)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run your crew, execute the following command in the root of your project:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;crewai run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python src/my_project/main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If an error happens due to the usage of poetry, please run the following command to update your crewai package:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;crewai update&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You should see the output in the console and the &lt;code&gt;report.md&lt;/code&gt; file should be created in the root of your project with the full final report.&lt;/p&gt; &#xA;&lt;p&gt;In addition to the sequential process, you can use the hierarchical process, which automatically assigns a manager to the defined crew to properly coordinate the planning and execution of tasks through delegation and validation of results. &lt;a href=&#34;https://docs.crewai.com/core-concepts/Processes/&#34;&gt;See more about the processes here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Role-Based Agent Design&lt;/strong&gt;: Customize agents with specific roles, goals, and tools.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Autonomous Inter-Agent Delegation&lt;/strong&gt;: Agents can autonomously delegate tasks and inquire amongst themselves, enhancing problem-solving efficiency.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Flexible Task Management&lt;/strong&gt;: Define tasks with customizable tools and assign them to agents dynamically.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Processes Driven&lt;/strong&gt;: Currently only supports &lt;code&gt;sequential&lt;/code&gt; task execution and &lt;code&gt;hierarchical&lt;/code&gt; processes, but more complex processes like consensual and autonomous are being worked on.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Save output as file&lt;/strong&gt;: Save the output of individual tasks as a file, so you can use it later.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Parse output as Pydantic or Json&lt;/strong&gt;: Parse the output of individual tasks as a Pydantic model or as a Json if you want to.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Works with Open Source Models&lt;/strong&gt;: Run your crew using Open AI or open source models refer to the &lt;a href=&#34;https://docs.crewai.com/how-to/LLM-Connections/&#34;&gt;Connect CrewAI to LLMs&lt;/a&gt; page for details on configuring your agents&#39; connections to models, even ones running locally!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/docs/crewAI-mindmap.png&#34; alt=&#34;CrewAI Mind Map&#34; title=&#34;CrewAI Mind Map&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;You can test different real life examples of AI crews in the &lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples?tab=readme-ov-file&#34;&gt;CrewAI-examples repo&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples/tree/main/landing_page_generator&#34;&gt;Landing Page Generator&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.crewai.com/how-to/Human-Input-on-Execution&#34;&gt;Having Human input on the execution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples/tree/main/trip_planner&#34;&gt;Trip Planner&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples/tree/main/stock_analysis&#34;&gt;Stock Analysis&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Quick Tutorial&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=tnejrr-0a94&#34; title=&#34;CrewAI Tutorial&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/tnejrr-0a94/maxresdefault.jpg&#34; alt=&#34;CrewAI Tutorial&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Write Job Descriptions&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples/tree/main/job-posting&#34;&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=u98wEMz-9to&#34; title=&#34;Jobs postings&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/u98wEMz-9to/maxresdefault.jpg&#34; alt=&#34;Jobs postings&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Trip Planner&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples/tree/main/trip_planner&#34;&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=xis7rWp-hjs&#34; title=&#34;Trip Planner&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/xis7rWp-hjs/maxresdefault.jpg&#34; alt=&#34;Trip Planner&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Stock Analysis&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples/tree/main/stock_analysis&#34;&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=e0Uj4yWdaAg&#34; title=&#34;Stock Analysis&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/e0Uj4yWdaAg/maxresdefault.jpg&#34; alt=&#34;Stock Analysis&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Connecting Your Crew to a Model&lt;/h2&gt; &#xA;&lt;p&gt;CrewAI supports using various LLMs through a variety of connection options. By default your agents will use the OpenAI API when querying the model. However, there are several other ways to allow your agents to connect to models. For example, you can configure your agents to use a local model via the Ollama tool.&lt;/p&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://docs.crewai.com/how-to/LLM-Connections/&#34;&gt;Connect CrewAI to LLMs&lt;/a&gt; page for details on configuring you agents&#39; connections to models.&lt;/p&gt; &#xA;&lt;h2&gt;How CrewAI Compares&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;CrewAI&#39;s Advantage&lt;/strong&gt;: CrewAI is built with production in mind. It offers the flexibility of Autogen&#39;s conversational agents and the structured process approach of ChatDev, but without the rigidity. CrewAI&#39;s processes are designed to be dynamic and adaptable, fitting seamlessly into both development and production workflows.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Autogen&lt;/strong&gt;: While Autogen does good in creating conversational agents capable of working together, it lacks an inherent concept of process. In Autogen, orchestrating agents&#39; interactions requires additional programming, which can become complex and cumbersome as the scale of tasks grows.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;ChatDev&lt;/strong&gt;: ChatDev introduced the idea of processes into the realm of AI agents, but its implementation is quite rigid. Customizations in ChatDev are limited and not geared towards production environments, which can hinder scalability and flexibility in real-world applications.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contribution&lt;/h2&gt; &#xA;&lt;p&gt;CrewAI is open-source and we welcome contributions. If you&#39;re looking to contribute, please:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fork the repository.&lt;/li&gt; &#xA; &lt;li&gt;Create a new branch for your feature.&lt;/li&gt; &#xA; &lt;li&gt;Add your feature or improvement.&lt;/li&gt; &#xA; &lt;li&gt;Send a pull request.&lt;/li&gt; &#xA; &lt;li&gt;We appreciate your input!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installing Dependencies&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uv lock&#xA;uv sync&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Virtual Env&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uv venv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Pre-commit hooks&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pre-commit install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running Tests&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uv run pytest .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running static type checks&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uvx mypy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Packaging&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uv build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Installing Locally&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install dist/*.tar.gz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Telemetry&lt;/h2&gt; &#xA;&lt;p&gt;CrewAI uses anonymous telemetry to collect usage data with the main purpose of helping us improve the library by focusing our efforts on the most used features, integrations and tools.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s pivotal to understand that &lt;strong&gt;NO data is collected&lt;/strong&gt; concerning prompts, task descriptions, agents&#39; backstories or goals, usage of tools, API calls, responses, any data processed by the agents, or secrets and environment variables, with the exception of the conditions mentioned. When the &lt;code&gt;share_crew&lt;/code&gt; feature is enabled, detailed data including task descriptions, agents&#39; backstories or goals, and other specific attributes are collected to provide deeper insights while respecting user privacy. We don&#39;t offer a way to disable it now, but we will in the future.&lt;/p&gt; &#xA;&lt;p&gt;Data collected includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Version of CrewAI &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;So we can understand how many users are using the latest version&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Version of Python &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;So we can decide on what versions to better support&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;General OS (e.g. number of CPUs, macOS/Windows/Linux) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;So we know what OS we should focus on and if we could build specific OS related features&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Number of agents and tasks in a crew &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;So we make sure we are testing internally with similar use cases and educate people on the best practices&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Crew Process being used &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand where we should focus our efforts&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;If Agents are using memory or allowing delegation &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand if we improved the features or maybe even drop them&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;If Tasks are being executed in parallel or sequentially &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand if we should focus more on parallel execution&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Language model being used &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Improved support on most used languages&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Roles of agents in a crew &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand high level use cases so we can build better tools, integrations and examples about it&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Tools names available &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand out of the publically available tools, which ones are being used the most so we can improve them&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Users can opt-in to Further Telemetry, sharing the complete telemetry data by setting the &lt;code&gt;share_crew&lt;/code&gt; attribute to &lt;code&gt;True&lt;/code&gt; on their Crews. Enabling &lt;code&gt;share_crew&lt;/code&gt; results in the collection of detailed crew and task execution data, including &lt;code&gt;goal&lt;/code&gt;, &lt;code&gt;backstory&lt;/code&gt;, &lt;code&gt;context&lt;/code&gt;, and &lt;code&gt;output&lt;/code&gt; of tasks. This enables a deeper insight into usage patterns while respecting the user&#39;s choice to share.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;CrewAI is released under the &lt;a href=&#34;https://github.com/crewAIInc/crewAI/raw/main/LICENSE&#34;&gt;MIT License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Frequently Asked Questions (FAQ)&lt;/h2&gt; &#xA;&lt;h3&gt;Q: What is CrewAI?&lt;/h3&gt; &#xA;&lt;p&gt;A: CrewAI is a cutting-edge framework for orchestrating role-playing, autonomous AI agents. It enables agents to work together seamlessly, tackling complex tasks through collaborative intelligence.&lt;/p&gt; &#xA;&lt;h3&gt;Q: How do I install CrewAI?&lt;/h3&gt; &#xA;&lt;p&gt;A: You can install CrewAI using pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install crewai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For additional tools, use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install &#39;crewai[tools]&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Q: Can I use CrewAI with local models?&lt;/h3&gt; &#xA;&lt;p&gt;A: Yes, CrewAI supports various LLMs, including local models. You can configure your agents to use local models via tools like Ollama &amp;amp; LM Studio. Check the &lt;a href=&#34;https://docs.crewai.com/how-to/LLM-Connections/&#34;&gt;LLM Connections documentation&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h3&gt;Q: What are the key features of CrewAI?&lt;/h3&gt; &#xA;&lt;p&gt;A: Key features include role-based agent design, autonomous inter-agent delegation, flexible task management, process-driven execution, output saving as files, and compatibility with both open-source and proprietary models.&lt;/p&gt; &#xA;&lt;h3&gt;Q: How does CrewAI compare to other AI orchestration tools?&lt;/h3&gt; &#xA;&lt;p&gt;A: CrewAI is designed with production in mind, offering flexibility similar to Autogen&#39;s conversational agents and structured processes like ChatDev, but with more adaptability for real-world applications.&lt;/p&gt; &#xA;&lt;h3&gt;Q: Is CrewAI open-source?&lt;/h3&gt; &#xA;&lt;p&gt;A: Yes, CrewAI is open-source and welcomes contributions from the community.&lt;/p&gt; &#xA;&lt;h3&gt;Q: Does CrewAI collect any data?&lt;/h3&gt; &#xA;&lt;p&gt;A: CrewAI uses anonymous telemetry to collect usage data for improvement purposes. No sensitive data (like prompts, task descriptions, or API calls) is collected. Users can opt-in to share more detailed data by setting &lt;code&gt;share_crew=True&lt;/code&gt; on their Crews.&lt;/p&gt; &#xA;&lt;h3&gt;Q: Where can I find examples of CrewAI in action?&lt;/h3&gt; &#xA;&lt;p&gt;A: You can find various real-life examples in the &lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples&#34;&gt;CrewAI-examples repository&lt;/a&gt;, including trip planners, stock analysis tools, and more.&lt;/p&gt; &#xA;&lt;h3&gt;Q: How can I contribute to CrewAI?&lt;/h3&gt; &#xA;&lt;p&gt;A: Contributions are welcome! You can fork the repository, create a new branch for your feature, add your improvement, and send a pull request. Check the Contribution section in the README for more details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>OpenInterpreter/open-interpreter</title>
    <updated>2024-10-27T01:42:15Z</updated>
    <id>tag:github.com,2024-10-27:/OpenInterpreter/open-interpreter</id>
    <link href="https://github.com/OpenInterpreter/open-interpreter" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A natural language interface for computers&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;â— Open Interpreter&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://discord.gg/Hvz9Axh84z&#34;&gt; &lt;img alt=&#34;Discord&#34; src=&#34;https://img.shields.io/discord/1146610656779440188?logo=discord&amp;amp;style=flat&amp;amp;logoColor=white&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenInterpreter/open-interpreter/main/docs/README_JA.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88-%E6%97%A5%E6%9C%AC%E8%AA%9E-white.svg?sanitize=true&#34; alt=&#34;JA doc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenInterpreter/open-interpreter/main/docs/README_ZH.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%E6%96%87%E6%A1%A3-%E4%B8%AD%E6%96%87%E7%89%88-white.svg?sanitize=true&#34; alt=&#34;ZH doc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenInterpreter/open-interpreter/main/docs/README_ES.md&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Espa%C3%B1ol-white.svg?sanitize=true&#34; alt=&#34;ES doc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenInterpreter/open-interpreter/main/docs/README_UK.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%D0%A3%D0%BA%D1%80%D0%B0%D1%97%D0%BD%D1%81%D1%8C%D0%BA%D0%B0-white.svg?sanitize=true&#34; alt=&#34;UK doc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenInterpreter/open-interpreter/main/docs/README_IN.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Hindi-white.svg?sanitize=true&#34; alt=&#34;IN doc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenInterpreter/open-interpreter/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?label=license&amp;amp;message=AGPL&amp;amp;color=white&amp;amp;style=flat&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;br&gt;&lt;a href=&#34;https://0ggfznkwh4j.typeform.com/to/G21i9lJ2&#34;&gt;Get early access to the desktop app&lt;/a&gt;â€ â€ |â€ â€ &lt;a href=&#34;https://docs.openinterpreter.com/&#34;&gt;Documentation&lt;/a&gt;&lt;br&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;img alt=&#34;local_explorer&#34; src=&#34;https://github.com/OpenInterpreter/open-interpreter/assets/63927363/d941c3b4-b5ad-4642-992c-40edf31e2e7a&#34;&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install open-interpreter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Not working? Read our &lt;a href=&#34;https://docs.openinterpreter.com/getting-started/setup&#34;&gt;setup guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;interpreter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;strong&gt;Open Interpreter&lt;/strong&gt; lets LLMs run code (Python, Javascript, Shell, and more) locally. You can chat with Open Interpreter through a ChatGPT-like interface in your terminal by running &lt;code&gt;$ interpreter&lt;/code&gt; after installing.&lt;/p&gt; &#xA;&lt;p&gt;This provides a natural-language interface to your computer&#39;s general-purpose capabilities:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create and edit photos, videos, PDFs, etc.&lt;/li&gt; &#xA; &lt;li&gt;Control a Chrome browser to perform research&lt;/li&gt; &#xA; &lt;li&gt;Plot, clean, and analyze large datasets&lt;/li&gt; &#xA; &lt;li&gt;...etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;âš ï¸ Note: You&#39;ll be asked to approve code before it&#39;s run.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/OpenInterpreter/open-interpreter/assets/63927363/37152071-680d-4423-9af3-64836a6f7b60&#34;&gt;https://github.com/OpenInterpreter/open-interpreter/assets/63927363/37152071-680d-4423-9af3-64836a6f7b60&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;An interactive demo is also available on Google Colab:&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1WKmRXZgsErej2xUriKzxrEAXdxMSgWbb?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Along with an example voice interface, inspired by &lt;em&gt;Her&lt;/em&gt;:&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1NojYGHDgxH6Y1G1oxThEBBb2AtyODBIK&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install open-interpreter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Terminal&lt;/h3&gt; &#xA;&lt;p&gt;After installation, simply run &lt;code&gt;interpreter&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;interpreter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Python&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from interpreter import interpreter&#xA;&#xA;interpreter.chat(&#34;Plot AAPL and META&#39;s normalized stock prices&#34;) # Executes a single command&#xA;interpreter.chat() # Starts an interactive chat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;GitHub Codespaces&lt;/h3&gt; &#xA;&lt;p&gt;Press the &lt;code&gt;,&lt;/code&gt; key on this repository&#39;s GitHub page to create a codespace. After a moment, you&#39;ll receive a cloud virtual machine environment pre-installed with open-interpreter. You can then start interacting with it directly and freely confirm its execution of system commands without worrying about damaging the system.&lt;/p&gt; &#xA;&lt;h2&gt;Comparison to ChatGPT&#39;s Code Interpreter&lt;/h2&gt; &#xA;&lt;p&gt;OpenAI&#39;s release of &lt;a href=&#34;https://openai.com/blog/chatgpt-plugins#code-interpreter&#34;&gt;Code Interpreter&lt;/a&gt; with GPT-4 presents a fantastic opportunity to accomplish real-world tasks with ChatGPT.&lt;/p&gt; &#xA;&lt;p&gt;However, OpenAI&#39;s service is hosted, closed-source, and heavily restricted:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;No internet access.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://wfhbrian.com/mastering-chatgpts-code-interpreter-list-of-python-packages/&#34;&gt;Limited set of pre-installed packages&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;100 MB maximum upload, 120.0 second runtime limit.&lt;/li&gt; &#xA; &lt;li&gt;State is cleared (along with any generated files or links) when the environment dies.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Open Interpreter overcomes these limitations by running in your local environment. It has full access to the internet, isn&#39;t restricted by time or file size, and can utilize any package or library.&lt;/p&gt; &#xA;&lt;p&gt;This combines the power of GPT-4&#39;s Code Interpreter with the flexibility of your local development environment.&lt;/p&gt; &#xA;&lt;h2&gt;Commands&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; The Generator Update (0.1.5) introduced streaming:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;message = &#34;What operating system are we on?&#34;&#xA;&#xA;for chunk in interpreter.chat(message, display=False, stream=True):&#xA;  print(chunk)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Interactive Chat&lt;/h3&gt; &#xA;&lt;p&gt;To start an interactive chat in your terminal, either run &lt;code&gt;interpreter&lt;/code&gt; from the command line:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;interpreter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or &lt;code&gt;interpreter.chat()&lt;/code&gt; from a .py file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;interpreter.chat()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;You can also stream each chunk:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;message = &#34;What operating system are we on?&#34;&#xA;&#xA;for chunk in interpreter.chat(message, display=False, stream=True):&#xA;  print(chunk)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Programmatic Chat&lt;/h3&gt; &#xA;&lt;p&gt;For more precise control, you can pass messages directly to &lt;code&gt;.chat(message)&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;interpreter.chat(&#34;Add subtitles to all videos in /videos.&#34;)&#xA;&#xA;# ... Streams output to your terminal, completes task ...&#xA;&#xA;interpreter.chat(&#34;These look great but can you make the subtitles bigger?&#34;)&#xA;&#xA;# ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Start a New Chat&lt;/h3&gt; &#xA;&lt;p&gt;In Python, Open Interpreter remembers conversation history. If you want to start fresh, you can reset it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;interpreter.messages = []&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Save and Restore Chats&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;interpreter.chat()&lt;/code&gt; returns a List of messages, which can be used to resume a conversation with &lt;code&gt;interpreter.messages = messages&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;messages = interpreter.chat(&#34;My name is Killian.&#34;) # Save messages to &#39;messages&#39;&#xA;interpreter.messages = [] # Reset interpreter (&#34;Killian&#34; will be forgotten)&#xA;&#xA;interpreter.messages = messages # Resume chat from &#39;messages&#39; (&#34;Killian&#34; will be remembered)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Customize System Message&lt;/h3&gt; &#xA;&lt;p&gt;You can inspect and configure Open Interpreter&#39;s system message to extend its functionality, modify permissions, or give it more context.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;interpreter.system_message += &#34;&#34;&#34;&#xA;Run shell commands with -y so the user doesn&#39;t have to confirm them.&#xA;&#34;&#34;&#34;&#xA;print(interpreter.system_message)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Change your Language Model&lt;/h3&gt; &#xA;&lt;p&gt;Open Interpreter uses &lt;a href=&#34;https://docs.litellm.ai/docs/providers/&#34;&gt;LiteLLM&lt;/a&gt; to connect to hosted language models.&lt;/p&gt; &#xA;&lt;p&gt;You can change the model by setting the model parameter:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;interpreter --model gpt-3.5-turbo&#xA;interpreter --model claude-2&#xA;interpreter --model command-nightly&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In Python, set the model on the object:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;interpreter.llm.model = &#34;gpt-3.5-turbo&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.litellm.ai/docs/providers/&#34;&gt;Find the appropriate &#34;model&#34; string for your language model here.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Running Open Interpreter locally&lt;/h3&gt; &#xA;&lt;h4&gt;Terminal&lt;/h4&gt; &#xA;&lt;p&gt;Open Interpreter can use OpenAI-compatible server to run models locally. (LM Studio, jan.ai, ollama etc)&lt;/p&gt; &#xA;&lt;p&gt;Simply run &lt;code&gt;interpreter&lt;/code&gt; with the api_base URL of your inference server (for LM studio it is &lt;code&gt;http://localhost:1234/v1&lt;/code&gt; by default):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;interpreter --api_base &#34;http://localhost:1234/v1&#34; --api_key &#34;fake_key&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively you can use Llamafile without installing any third party software just by running&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;interpreter --local&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;for a more detailed guide check out &lt;a href=&#34;https://www.youtube.com/watch?v=CEs51hGWuGU?si=cN7f6QhfT4edfG5H&#34;&gt;this video by Mike Bird&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;How to run LM Studio in the background.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download &lt;a href=&#34;https://lmstudio.ai/&#34;&gt;https://lmstudio.ai/&lt;/a&gt; then start it.&lt;/li&gt; &#xA; &lt;li&gt;Select a model then click &lt;strong&gt;â†“ Download&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Click the &lt;strong&gt;â†”ï¸&lt;/strong&gt; button on the left (below ğŸ’¬).&lt;/li&gt; &#xA; &lt;li&gt;Select your model at the top, then click &lt;strong&gt;Start Server&lt;/strong&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Once the server is running, you can begin your conversation with Open Interpreter.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Local mode sets your &lt;code&gt;context_window&lt;/code&gt; to 3000, and your &lt;code&gt;max_tokens&lt;/code&gt; to 1000. If your model has different requirements, set these parameters manually (see below).&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;Python&lt;/h4&gt; &#xA;&lt;p&gt;Our Python package gives you more control over each setting. To replicate and connect to LM Studio, use these settings:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from interpreter import interpreter&#xA;&#xA;interpreter.offline = True # Disables online features like Open Procedures&#xA;interpreter.llm.model = &#34;openai/x&#34; # Tells OI to send messages in OpenAI&#39;s format&#xA;interpreter.llm.api_key = &#34;fake_key&#34; # LiteLLM, which we use to talk to LM Studio, requires this&#xA;interpreter.llm.api_base = &#34;http://localhost:1234/v1&#34; # Point this at any OpenAI compatible server&#xA;&#xA;interpreter.chat()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Context Window, Max Tokens&lt;/h4&gt; &#xA;&lt;p&gt;You can modify the &lt;code&gt;max_tokens&lt;/code&gt; and &lt;code&gt;context_window&lt;/code&gt; (in tokens) of locally running models.&lt;/p&gt; &#xA;&lt;p&gt;For local mode, smaller context windows will use less RAM, so we recommend trying a much shorter window (~1000) if it&#39;s failing / if it&#39;s slow. Make sure &lt;code&gt;max_tokens&lt;/code&gt; is less than &lt;code&gt;context_window&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;interpreter --local --max_tokens 1000 --context_window 3000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Verbose mode&lt;/h3&gt; &#xA;&lt;p&gt;To help you inspect Open Interpreter we have a &lt;code&gt;--verbose&lt;/code&gt; mode for debugging.&lt;/p&gt; &#xA;&lt;p&gt;You can activate verbose mode by using its flag (&lt;code&gt;interpreter --verbose&lt;/code&gt;), or mid-chat:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ interpreter&#xA;...&#xA;&amp;gt; %verbose true &amp;lt;- Turns on verbose mode&#xA;&#xA;&amp;gt; %verbose false &amp;lt;- Turns off verbose mode&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Interactive Mode Commands&lt;/h3&gt; &#xA;&lt;p&gt;In the interactive mode, you can use the below commands to enhance your experience. Here&#39;s a list of available commands:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Available Commands:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;%verbose [true/false]&lt;/code&gt;: Toggle verbose mode. Without arguments or with &lt;code&gt;true&lt;/code&gt; it enters verbose mode. With &lt;code&gt;false&lt;/code&gt; it exits verbose mode.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;%reset&lt;/code&gt;: Resets the current session&#39;s conversation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;%undo&lt;/code&gt;: Removes the previous user message and the AI&#39;s response from the message history.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;%tokens [prompt]&lt;/code&gt;: (&lt;em&gt;Experimental&lt;/em&gt;) Calculate the tokens that will be sent with the next prompt as context and estimate their cost. Optionally calculate the tokens and estimated cost of a &lt;code&gt;prompt&lt;/code&gt; if one is provided. Relies on &lt;a href=&#34;https://docs.litellm.ai/docs/completion/token_usage#2-cost_per_token&#34;&gt;LiteLLM&#39;s &lt;code&gt;cost_per_token()&lt;/code&gt; method&lt;/a&gt; for estimated costs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;%help&lt;/code&gt;: Show the help message.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Configuration / Profiles&lt;/h3&gt; &#xA;&lt;p&gt;Open Interpreter allows you to set default behaviors using &lt;code&gt;yaml&lt;/code&gt; files.&lt;/p&gt; &#xA;&lt;p&gt;This provides a flexible way to configure the interpreter without changing command-line arguments every time.&lt;/p&gt; &#xA;&lt;p&gt;Run the following command to open the profiles directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;interpreter --profiles&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can add &lt;code&gt;yaml&lt;/code&gt; files there. The default profile is named &lt;code&gt;default.yaml&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Multiple Profiles&lt;/h4&gt; &#xA;&lt;p&gt;Open Interpreter supports multiple &lt;code&gt;yaml&lt;/code&gt; files, allowing you to easily switch between configurations:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;interpreter --profile my_profile.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Sample FastAPI Server&lt;/h2&gt; &#xA;&lt;p&gt;The generator update enables Open Interpreter to be controlled via HTTP REST endpoints:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# server.py&#xA;&#xA;from fastapi import FastAPI&#xA;from fastapi.responses import StreamingResponse&#xA;from interpreter import interpreter&#xA;&#xA;app = FastAPI()&#xA;&#xA;@app.get(&#34;/chat&#34;)&#xA;def chat_endpoint(message: str):&#xA;    def event_stream():&#xA;        for result in interpreter.chat(message, stream=True):&#xA;            yield f&#34;data: {result}\n\n&#34;&#xA;&#xA;    return StreamingResponse(event_stream(), media_type=&#34;text/event-stream&#34;)&#xA;&#xA;@app.get(&#34;/history&#34;)&#xA;def history_endpoint():&#xA;    return interpreter.messages&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install fastapi uvicorn&#xA;uvicorn server:app --reload&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also start a server identical to the one above by simply running &lt;code&gt;interpreter.server()&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Android&lt;/h2&gt; &#xA;&lt;p&gt;The step-by-step guide for installing Open Interpreter on your Android device can be found in the &lt;a href=&#34;https://github.com/MikeBirdTech/open-interpreter-termux&#34;&gt;open-interpreter-termux repo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Safety Notice&lt;/h2&gt; &#xA;&lt;p&gt;Since generated code is executed in your local environment, it can interact with your files and system settings, potentially leading to unexpected outcomes like data loss or security risks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;âš ï¸ Open Interpreter will ask for user confirmation before executing code.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can run &lt;code&gt;interpreter -y&lt;/code&gt; or set &lt;code&gt;interpreter.auto_run = True&lt;/code&gt; to bypass this confirmation, in which case:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Be cautious when requesting commands that modify files or system settings.&lt;/li&gt; &#xA; &lt;li&gt;Watch Open Interpreter like a self-driving car, and be prepared to end the process by closing your terminal.&lt;/li&gt; &#xA; &lt;li&gt;Consider running Open Interpreter in a restricted environment like Google Colab or Replit. These environments are more isolated, reducing the risks of executing arbitrary code.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;There is &lt;strong&gt;experimental&lt;/strong&gt; support for a &lt;a href=&#34;https://github.com/OpenInterpreter/open-interpreter/raw/main/docs/SAFE_MODE.md&#34;&gt;safe mode&lt;/a&gt; to help mitigate some risks.&lt;/p&gt; &#xA;&lt;h2&gt;How Does it Work?&lt;/h2&gt; &#xA;&lt;p&gt;Open Interpreter equips a &lt;a href=&#34;https://platform.openai.com/docs/guides/gpt/function-calling&#34;&gt;function-calling language model&lt;/a&gt; with an &lt;code&gt;exec()&lt;/code&gt; function, which accepts a &lt;code&gt;language&lt;/code&gt; (like &#34;Python&#34; or &#34;JavaScript&#34;) and &lt;code&gt;code&lt;/code&gt; to run.&lt;/p&gt; &#xA;&lt;p&gt;We then stream the model&#39;s messages, code, and your system&#39;s outputs to the terminal as Markdown.&lt;/p&gt; &#xA;&lt;h1&gt;Access Documentation Offline&lt;/h1&gt; &#xA;&lt;p&gt;The full &lt;a href=&#34;https://docs.openinterpreter.com/&#34;&gt;documentation&lt;/a&gt; is accessible on-the-go without the need for an internet connection.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://nodejs.org/en&#34;&gt;Node&lt;/a&gt; is a pre-requisite:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Version 18.17.0 or any later 18.x.x version.&lt;/li&gt; &#xA; &lt;li&gt;Version 20.3.0 or any later 20.x.x version.&lt;/li&gt; &#xA; &lt;li&gt;Any version starting from 21.0.0 onwards, with no upper limit specified.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Install &lt;a href=&#34;https://mintlify.com/&#34;&gt;Mintlify&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm i -g mintlify@latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Change into the docs directory and run the appropriate command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Assuming you&#39;re at the project&#39;s root directory&#xA;cd ./docs&#xA;&#xA;# Run the documentation server&#xA;mintlify dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A new browser window should open. The documentation will be available at &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt; as long as the documentation server is running.&lt;/p&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;Thank you for your interest in contributing! We welcome involvement from the community.&lt;/p&gt; &#xA;&lt;p&gt;Please see our &lt;a href=&#34;https://github.com/OpenInterpreter/open-interpreter/raw/main/docs/CONTRIBUTING.md&#34;&gt;contributing guidelines&lt;/a&gt; for more details on how to get involved.&lt;/p&gt; &#xA;&lt;h1&gt;Roadmap&lt;/h1&gt; &#xA;&lt;p&gt;Visit &lt;a href=&#34;https://github.com/OpenInterpreter/open-interpreter/raw/main/docs/ROADMAP.md&#34;&gt;our roadmap&lt;/a&gt; to preview the future of Open Interpreter.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This software is not affiliated with OpenAI.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/OpenInterpreter/open-interpreter/assets/63927363/1b19a5db-b486-41fd-a7a1-fe2028031686&#34; alt=&#34;thumbnail-ncu&#34;&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Having access to a junior programmer working at the speed of your fingertips ... can make new workflows effortless and efficient, as well as open the benefits of programming to new audiences.&lt;/p&gt; &#xA; &lt;p&gt;â€” &lt;em&gt;OpenAI&#39;s Code Interpreter Release&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt;</summary>
  </entry>
</feed>