<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-09-24T01:58:55Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>aiwaves-cn/agents</title>
    <updated>2023-09-24T01:58:55Z</updated>
    <id>tag:github.com,2023-09-24:/aiwaves-cn/agents</id>
    <link href="https://github.com/aiwaves-cn/agents" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An Open-source Framework for Autonomous Language Agents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aiwaves-cn/agents/master/assets/agents-logo.png&#34; width=&#34;300&#34;&gt; &lt;/p&gt;&lt;/h1&gt; &#xA;&lt;h2&gt;&lt;p align=&#34;center&#34; style=&#34;display:inline-block;&#34;&gt;&lt;font face=&#34;Calisto MT&#34;&gt;&lt;font size=&#34;4&#34;&gt;An Open-source Framework for Autonomous Language Agents&lt;/font&gt;&lt;/font&gt;&lt;/p&gt;&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/pdf/2309.07870.pdf&#34;&gt;[ğŸ“„ Paper]&lt;/a&gt; &lt;a href=&#34;http://www.aiwaves-agents.com/&#34;&gt;[ğŸŒ Website]&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aiwaves-cn/agents/master/#web-demos&#34;&gt;[ğŸ¤–ï¸ Demos]&lt;/a&gt; &lt;a href=&#34;https://discord.gg/DDPBeFt7&#34;&gt;[ğŸ”¥ Discord]&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aiwaves-cn/agents/master/assets/wechat.jpg&#34;&gt;[ğŸ”¥ Wechat Group] &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Agents&lt;/strong&gt; is an open-source library/framework for building autonomous language agents. The library is carefully engineered to support important features including &lt;strong&gt;long-short term memory&lt;/strong&gt;, &lt;strong&gt;tool usage&lt;/strong&gt;, &lt;strong&gt;web navigation&lt;/strong&gt;, &lt;strong&gt;multi-agent communication&lt;/strong&gt;, and brand new features including &lt;strong&gt;human-agent interaction&lt;/strong&gt; and &lt;strong&gt;symbolic control&lt;/strong&gt;. With &lt;strong&gt;Agents&lt;/strong&gt;, one can customize a language agent or a multi-agent system by simply filling in a config file in natural language and deploy the language agents in a terminal, a Gradio interface, or a backend service.&lt;/p&gt; &#xA;&lt;p&gt;One major difference between &lt;strong&gt;Agents&lt;/strong&gt; and other existing frameworks for language agents is that our framework allows users to provide fine-grained control and guidance to language agents via an &lt;strong&gt;SOP (Standard Operation Process)&lt;/strong&gt;. An SOP defines subgoals/subtasks for the overall task and allows users to customize a fine-grained workflow for the language agents.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aiwaves-cn/agents/master/assets/agents-cover.png&#34; width=&#34;800&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“¢ Updates&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Support LLM-based SOP generation&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 2023.9.20 Deploy Demos on Huggingface Space&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 2023.9.12 Official Release&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ’¡ Highlights&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Long-short Term Memory&lt;/strong&gt;: Language agents in the library are equipped with both long-term memory implemented via VectorDB + Semantic Search and short-term memory (working memory) maintained and updated by an LLM.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Tool Usage&lt;/strong&gt;: Language agents in the library can use any external tools via &lt;a href=&#34;https://platform.openai.com/docs/guides/gpt/function-calling&#34;&gt;function-calling&lt;/a&gt; and developers can add customized tools/APIs &lt;a href=&#34;https://github.com/aiwaves-cn/agents/raw/master/src/agents/Component/ToolComponent.py&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Web Navigation&lt;/strong&gt;: Language agents in the library can use search engines to navigate the web and get useful information.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi-agent Communication&lt;/strong&gt;: In addition to single language agents, the library supports building multi-agent systems in which language agents can communicate with other language agents and the environment. Different from most existing frameworks for multi-agent systems that use pre-defined rules to control the order for agents&#39; action, &lt;strong&gt;Agents&lt;/strong&gt; includes a &lt;em&gt;controller&lt;/em&gt; function that dynamically decides which agent will perform the next action using an LLM by considering the previous actions, the environment, and the target of the current states. This makes multi-agent communication more flexible.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Human-Agent interaction&lt;/strong&gt;: In addition to letting language agents communicate with each other in an environment, our framework seamlessly supports human users to play the role of the agent by himself/herself and input his/her own actions, and interact with other language agents in the environment.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Symbolic Control&lt;/strong&gt;: Different from existing frameworks for language agents that only use a simple task description to control the entire multi-agent system over the whole task completion process, &lt;strong&gt;Agents&lt;/strong&gt; allows users to use an &lt;strong&gt;SOP (Standard Operation Process)&lt;/strong&gt; that defines subgoals/subtasks for the overall task to customize fine-grained workflows for the language agents.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ›  Installation&lt;/h2&gt; &#xA;&lt;h4&gt;Option 1. Build from source&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/aiwaves-cn/agents.git&#xA;cd agents&#xA;pip install -e . &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Option 2. Install via PyPI&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install ai-agents&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ğŸ“¦ Usage&lt;/h2&gt; &#xA;&lt;h3&gt;ğŸ› ï¸ Generate the config file&lt;/h3&gt; &#xA;&lt;h4&gt;Option 1. Fill in the config template manually&lt;/h4&gt; &#xA;&lt;p&gt;Modify &lt;code&gt;example/{Muti|Single_Agent}/{target_agent}/config.json&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Option 2. Try our &lt;a href=&#34;http://www.aiwaves.cn/create-agent/&#34;&gt;WebUI&lt;/a&gt; for customizing the config file.&lt;/h4&gt; &#xA;&lt;p&gt;Haven&#39;t figured out how to write the JSON file yet? Check out our &lt;a href=&#34;https://agents-readthedocsio.readthedocs.io/en/latest/index.html&#34;&gt;documentation&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h3&gt;ğŸ¤–ï¸ The Agent Hub&lt;/h3&gt; &#xA;&lt;p&gt;We provide an &lt;strong&gt;AgentHub&lt;/strong&gt;, where you can search for interesting Agents shared by us or other developers, try them out or use them as the starting point to customize your own agent. We encourage you to share your customized agents to help others build their own agents more easily! You can share your customized agents by submitting PRs that adds configs and customized codes &lt;a href=&#34;https://github.com/aiwaves-cn/agents/tree/master/examples/Community_Agent&#34;&gt;here&lt;/a&gt;. You can also send us your own config files and codes for customized agents by &lt;a href=&#34;mailto:contact@aiwaves.cn&#34;&gt;email&lt;/a&gt;, and we will share your examples and acknowledge your contribution in future updates!&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;A WebUI for automatically uploading of your customized agents will be available soon!&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“· Examples and Demos&lt;/h2&gt; &#xA;&lt;p&gt;We have provided exemplar config files, code, and demos for both single-agent and multi-agent systems &lt;a href=&#34;https://github.com/aiwaves-cn/agents/tree/master/examples&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Web demos&lt;/h3&gt; &#xA;&lt;h4&gt;Note&lt;/h4&gt; &#xA;&lt;p&gt;1.Due to massive traffic, our online demos may suffer from long queue time and unstable issues. &lt;strong&gt;Please follow our &lt;a href=&#34;https://github.com/aiwaves-cn/agents/raw/master/examples/README.md&#34;&gt;quick start guide&lt;/a&gt;) and deploy language agents locally for testing. Or checkout our &lt;a href=&#34;http://www.aiwaves-agents.com/&#34;&gt;website&lt;/a&gt;&lt;/strong&gt;. 2.Software Company is unable to generate executable code online, &lt;strong&gt;if you wish to generate executable code directly, please run it locally :)&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.aiwaves.cn/customer-service-agent/&#34;&gt;Customer Service Agent&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/spaces/AIWaves/Debate&#34;&gt;Debate&lt;/a&gt;[now on Huggingface Space]&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/spaces/AIWaves/Software_Company&#34;&gt;Software Company&lt;/a&gt;[now on Huggingface Space]&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.aiwaves.cn/fiction-studio/&#34;&gt;Fiction Studio&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing to Agents&lt;/h2&gt; &#xA;&lt;p&gt;We appreciate your interest in contributing to our open-source initiative. Please feel free to submit a PR or share your thoughts on how to improve the library in Issues!&lt;/p&gt; &#xA;&lt;h2&gt;Noteï¼š&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;When running the code, we will download an embedding model, which will cause the code to run slowly. We will adjust it to the API interface later&lt;/li&gt; &#xA; &lt;li&gt;Currently, the shopping assistant cannot be used. We will replace the API later. Stay tuned&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;ğŸ“š Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Please check our &lt;a href=&#34;https://agents-readthedocsio.readthedocs.io/en/latest/index.html&#34;&gt;documentation&lt;/a&gt; for detailed documentation of the framework.&lt;/p&gt; &#xA;&lt;h2&gt;â­ Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#aiwaves-cn/agents&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=aiwaves-cn/agents&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find our repo useful in your research, please kindly consider cite:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-angular2&#34;&gt;@misc{zhou2023agents,&#xA;      title={Agents: An Open-source Framework for Autonomous Language Agents}, &#xA;      author={Wangchunshu Zhou and Yuchen Eleanor Jiang and Long Li and Jialong Wu and Tiannan Wang and Shi Qiu and Jintian Zhang and Jing Chen and Ruipu Wu and Shuai Wang and Shiding Zhu and Jiyu Chen and Wentao Zhang and Ningyu Zhang and Huajun Chen and Peng Cui and Mrinmaya Sachan},&#xA;      year={2023},&#xA;      eprint={2309.07870},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CL}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>CorentinJ/Real-Time-Voice-Cloning</title>
    <updated>2023-09-24T01:58:55Z</updated>
    <id>tag:github.com,2023-09-24:/CorentinJ/Real-Time-Voice-Cloning</id>
    <link href="https://github.com/CorentinJ/Real-Time-Voice-Cloning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Clone a voice in 5 seconds to generate arbitrary speech in real-time&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Real-Time Voice Cloning&lt;/h1&gt; &#xA;&lt;p&gt;This repository is an implementation of &lt;a href=&#34;https://arxiv.org/pdf/1806.04558.pdf&#34;&gt;Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis&lt;/a&gt; (SV2TTS) with a vocoder that works in real-time. This was my &lt;a href=&#34;https://matheo.uliege.be/handle/2268.2/6801&#34;&gt;master&#39;s thesis&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;SV2TTS is a deep learning framework in three stages. In the first stage, one creates a digital representation of a voice from a few seconds of audio. In the second and third stages, this representation is used as reference to generate speech given arbitrary text.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Video demonstration&lt;/strong&gt; (click the picture):&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=-O_hYhToKoA&#34;&gt;&lt;img src=&#34;https://i.imgur.com/8lFUlgz.png&#34; alt=&#34;Toolbox demo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Papers implemented&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;URL&lt;/th&gt; &#xA;   &lt;th&gt;Designation&lt;/th&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Implementation source&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/1806.04558.pdf&#34;&gt;&lt;strong&gt;1806.04558&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;SV2TTS&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;This repo&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/1802.08435.pdf&#34;&gt;1802.08435&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;WaveRNN (vocoder)&lt;/td&gt; &#xA;   &lt;td&gt;Efficient Neural Audio Synthesis&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/fatchord/WaveRNN&#34;&gt;fatchord/WaveRNN&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/1703.10135.pdf&#34;&gt;1703.10135&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Tacotron (synthesizer)&lt;/td&gt; &#xA;   &lt;td&gt;Tacotron: Towards End-to-End Speech Synthesis&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/fatchord/WaveRNN&#34;&gt;fatchord/WaveRNN&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/1710.10467.pdf&#34;&gt;1710.10467&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GE2E (encoder)&lt;/td&gt; &#xA;   &lt;td&gt;Generalized End-To-End Loss for Speaker Verification&lt;/td&gt; &#xA;   &lt;td&gt;This repo&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Heads up&lt;/h2&gt; &#xA;&lt;p&gt;Like everything else in Deep Learning, this repo is quickly getting old. Many other open-source repositories or SaaS apps (often paying) will give you a better audio quality than this repository will. If you care about the fidelity of the voice you&#39;re cloning, and its expressivity, here are some personal recommendations of alternative voice cloning solutions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Check out &lt;a href=&#34;https://github.com/coqui-ai/tts&#34;&gt;CoquiTTS&lt;/a&gt; for an open source repository that is more up-to-date, with a better voice cloning quality and more functionalities.&lt;/li&gt; &#xA; &lt;li&gt;Check out &lt;a href=&#34;https://paperswithcode.com/task/speech-synthesis/&#34;&gt;paperswithcode&lt;/a&gt; for other repositories and recent research in the field of speech synthesis.&lt;/li&gt; &#xA; &lt;li&gt;Check out &lt;a href=&#34;https://www.resemble.ai/&#34;&gt;Resemble.ai&lt;/a&gt; (disclaimer: I work there) for state of the art voice cloning with little hassle.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;h3&gt;1. Install Requirements&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Both Windows and Linux are supported. A GPU is recommended for training and for inference speed, but is not mandatory.&lt;/li&gt; &#xA; &lt;li&gt;Python 3.7 is recommended. Python 3.5 or greater should work, but you&#39;ll probably have to tweak the dependencies&#39; versions. I recommend setting up a virtual environment using &lt;code&gt;venv&lt;/code&gt;, but this is optional.&lt;/li&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://ffmpeg.org/download.html#get-packages&#34;&gt;ffmpeg&lt;/a&gt;. This is necessary for reading audio files.&lt;/li&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;PyTorch&lt;/a&gt;. Pick the latest stable version, your operating system, your package manager (pip by default) and finally pick any of the proposed CUDA versions if you have a GPU, otherwise pick CPU. Run the given command.&lt;/li&gt; &#xA; &lt;li&gt;Install the remaining requirements with &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;2. (Optional) Download Pretrained Models&lt;/h3&gt; &#xA;&lt;p&gt;Pretrained models are now downloaded automatically. If this doesn&#39;t work for you, you can manually download them &lt;a href=&#34;https://github.com/CorentinJ/Real-Time-Voice-Cloning/wiki/Pretrained-models&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;3. (Optional) Test Configuration&lt;/h3&gt; &#xA;&lt;p&gt;Before you download any dataset, you can begin by testing your configuration with:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;python demo_cli.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;If all tests pass, you&#39;re good to go.&lt;/p&gt; &#xA;&lt;h3&gt;4. (Optional) Download Datasets&lt;/h3&gt; &#xA;&lt;p&gt;For playing with the toolbox alone, I only recommend downloading &lt;a href=&#34;https://www.openslr.org/resources/12/train-clean-100.tar.gz&#34;&gt;&lt;code&gt;LibriSpeech/train-clean-100&lt;/code&gt;&lt;/a&gt;. Extract the contents as &lt;code&gt;&amp;lt;datasets_root&amp;gt;/LibriSpeech/train-clean-100&lt;/code&gt; where &lt;code&gt;&amp;lt;datasets_root&amp;gt;&lt;/code&gt; is a directory of your choosing. Other datasets are supported in the toolbox, see &lt;a href=&#34;https://github.com/CorentinJ/Real-Time-Voice-Cloning/wiki/Training#datasets&#34;&gt;here&lt;/a&gt;. You&#39;re free not to download any dataset, but then you will need your own data as audio files or you will have to record it with the toolbox.&lt;/p&gt; &#xA;&lt;h3&gt;5. Launch the Toolbox&lt;/h3&gt; &#xA;&lt;p&gt;You can then try the toolbox:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;python demo_toolbox.py -d &amp;lt;datasets_root&amp;gt;&lt;/code&gt;&lt;br&gt; or&lt;br&gt; &lt;code&gt;python demo_toolbox.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;depending on whether you downloaded any datasets. If you are running an X-server or if you have the error &lt;code&gt;Aborted (core dumped)&lt;/code&gt;, see &lt;a href=&#34;https://github.com/CorentinJ/Real-Time-Voice-Cloning/issues/11#issuecomment-504733590&#34;&gt;this issue&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>pjialin/py12306</title>
    <updated>2023-09-24T01:58:55Z</updated>
    <id>tag:github.com,2023-09-24:/pjialin/py12306</id>
    <link href="https://github.com/pjialin/py12306" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ğŸš‚ 12306 è´­ç¥¨åŠ©æ‰‹ï¼Œæ”¯æŒé›†ç¾¤ï¼Œå¤šè´¦å·ï¼Œå¤šä»»åŠ¡è´­ç¥¨ä»¥åŠ Web é¡µé¢ç®¡ç†&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ğŸš‚ py12306 è´­ç¥¨åŠ©æ‰‹&lt;/h1&gt; &#xA;&lt;p&gt;åˆ†å¸ƒå¼ï¼Œå¤šè´¦å·ï¼Œå¤šä»»åŠ¡è´­ç¥¨&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; å¤šæ—¥æœŸæŸ¥è¯¢ä½™ç¥¨&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; è‡ªåŠ¨æ‰“ç ä¸‹å•&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; ç”¨æˆ·çŠ¶æ€æ¢å¤&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; ç”µè¯è¯­éŸ³é€šçŸ¥&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; å¤šè´¦å·ã€å¤šä»»åŠ¡ã€å¤šçº¿ç¨‹æ”¯æŒ&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; å•ä¸ªä»»åŠ¡å¤šç«™ç‚¹æŸ¥è¯¢&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; åˆ†å¸ƒå¼è¿è¡Œ&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Docker æ”¯æŒ&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; åŠ¨æ€ä¿®æ”¹é…ç½®æ–‡ä»¶&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; é‚®ä»¶é€šçŸ¥&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Web ç®¡ç†é¡µé¢&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; å¾®ä¿¡æ¶ˆæ¯é€šçŸ¥&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; ä»£ç†æ± æ”¯æŒ (&lt;a href=&#34;https://github.com/pjialin/pyproxy-async&#34;&gt;pyproxy-async&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ä½¿ç”¨&lt;/h2&gt; &#xA;&lt;p&gt;py12306 éœ€è¦è¿è¡Œåœ¨ python 3.6 ä»¥ä¸Šç‰ˆæœ¬ï¼ˆå…¶å®ƒç‰ˆæœ¬æš‚æœªæµ‹è¯•)&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;1. å®‰è£…ä¾èµ–&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/pjialin/py12306&#xA;&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;2. é…ç½®ç¨‹åº&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp env.py.example env.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;è‡ªåŠ¨æ‰“ç &lt;/p&gt; &#xA;&lt;p&gt;ï¼ˆè‹¥å¿«å·²åœæ­¢æœåŠ¡ï¼Œç›®å‰åªèƒ½è®¾ç½®&lt;strong&gt;free&lt;/strong&gt;æ‰“ç æ¨¡å¼ï¼‰ free å·²å¯¹æ¥åˆ°æ‰“ç å…±äº«å¹³å°ï¼Œ&lt;a href=&#34;https://py12306-helper.pjialin.com/&#34;&gt;https://py12306-helper.pjialin.com&lt;/a&gt;ï¼Œæ¬¢è¿å‚ä¸åˆ†äº«&lt;/p&gt; &#xA;&lt;p&gt;è¯­éŸ³é€šçŸ¥&lt;/p&gt; &#xA;&lt;p&gt;è¯­éŸ³éªŒè¯ç ä½¿ç”¨çš„æ˜¯é˜¿é‡Œäº‘ API å¸‚åœºä¸Šçš„ä¸€ä¸ªæœåŠ¡å•†ï¼Œéœ€è¦åˆ° &lt;a href=&#34;https://market.aliyun.com/products/56928004/cmapi026600.html&#34;&gt;https://market.aliyun.com/products/56928004/cmapi026600.html&lt;/a&gt; è´­ä¹°åå°† appcode å¡«å†™åˆ°é…ç½®ä¸­&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3. å¯åŠ¨å‰æµ‹è¯•&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;ç›®å‰æä¾›äº†ä¸€äº›ç®€å•çš„æµ‹è¯•ï¼ŒåŒ…æ‹¬ç”¨æˆ·è´¦å·æ£€æµ‹ï¼Œä¹˜å®¢ä¿¡æ¯æ£€æµ‹ï¼Œè½¦ç«™æ£€æµ‹ç­‰&lt;/p&gt; &#xA;&lt;p&gt;å¼€å§‹æµ‹è¯• -t&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py -t&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æµ‹è¯•é€šçŸ¥æ¶ˆæ¯ (è¯­éŸ³, é‚®ä»¶) -t -n&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# é»˜è®¤ä¸ä¼šè¿›è¡Œé€šçŸ¥æµ‹è¯•ï¼Œè¦å¯¹é€šçŸ¥è¿›è¡Œæµ‹è¯•éœ€è¦åŠ ä¸Š -n å‚æ•° &#xA;python main.py -t -n&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;4. è¿è¡Œç¨‹åº&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;å‚æ•°åˆ—è¡¨&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;-t æµ‹è¯•é…ç½®ä¿¡æ¯&lt;/li&gt; &#xA; &lt;li&gt;-t -n æµ‹è¯•é…ç½®ä¿¡æ¯ä»¥åŠé€šçŸ¥æ¶ˆæ¯&lt;/li&gt; &#xA; &lt;li&gt;-c æŒ‡å®šè‡ªå®šä¹‰é…ç½®æ–‡ä»¶ä½ç½®&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;åˆ†å¸ƒå¼é›†ç¾¤&lt;/h3&gt; &#xA;&lt;p&gt;é›†ç¾¤ä¾èµ–äº redisï¼Œç›®å‰æ”¯æŒæƒ…å†µ&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;å•å°ä¸»èŠ‚ç‚¹å¤šä¸ªå­èŠ‚ç‚¹åŒæ—¶è¿è¡Œ&lt;/li&gt; &#xA; &lt;li&gt;ä¸»èŠ‚ç‚¹å®•æœºåè‡ªåŠ¨åˆ‡æ¢æå‡å­èŠ‚ç‚¹ä¸ºä¸»èŠ‚ç‚¹&lt;/li&gt; &#xA; &lt;li&gt;ä¸»èŠ‚ç‚¹æ¢å¤åè‡ªåŠ¨æ¢å¤ä¸ºçœŸå®ä¸»èŠ‚ç‚¹&lt;/li&gt; &#xA; &lt;li&gt;é…ç½®é€šè¿‡ä¸»èŠ‚ç‚¹åŒæ­¥åˆ°æ‰€æœ‰å­èŠ‚ç‚¹&lt;/li&gt; &#xA; &lt;li&gt;ä¸»èŠ‚ç‚¹é…ç½®ä¿®æ”¹åæ— éœ€é‡å¯å­èŠ‚ç‚¹ï¼Œæ”¯æŒè‡ªåŠ¨æ›´æ–°&lt;/li&gt; &#xA; &lt;li&gt;å­èŠ‚ç‚¹æ¶ˆæ¯å®æ—¶åŒæ­¥åˆ°ä¸»èŠ‚ç‚¹&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;ä½¿ç”¨&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;å°†é…ç½®æ–‡ä»¶çš„ä¸­ &lt;code&gt;CLUSTER_ENABLED&lt;/code&gt; æ‰“å¼€å³å¼€å¯åˆ†å¸ƒå¼&lt;/p&gt; &#xA;&lt;p&gt;ç›®å‰æä¾›äº†ä¸€ä¸ªå•ç‹¬çš„å­èŠ‚ç‚¹é…ç½®æ–‡ä»¶ &lt;code&gt;env.slave.py.example&lt;/code&gt; å°†æ–‡ä»¶ä¿®æ”¹ä¸º &lt;code&gt;env.slave.py&lt;/code&gt;ï¼Œ é€šè¿‡ &lt;code&gt;python main.py -c env.slave.py&lt;/code&gt; å³å¯å¿«é€Ÿå¯åŠ¨&lt;/p&gt; &#xA;&lt;h2&gt;Docker ä½¿ç”¨&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;1. å°†é…ç½®æ–‡ä»¶ä¸‹è½½åˆ°æœ¬åœ°&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --rm pjialin/py12306 cat /config/env.py &amp;gt; env.py&#xA;# æˆ–&#xA;curl https://raw.githubusercontent.com/pjialin/py12306/master/env.docker.py.example -o env.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;2. ä¿®æ”¹å¥½é…ç½®åè¿è¡Œ&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --rm --name py12306 -p 8008:8008 -d -v $(pwd):/config -v py12306:/data pjialin/py12306&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å½“å‰ç›®å½•ä¼šå¤šä¸€ä¸ª 12306.log çš„æ—¥å¿—æ–‡ä»¶ï¼Œ &lt;code&gt;tail -f 12306.log&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Docker-compose ä¸­ä½¿ç”¨&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;1. å¤åˆ¶é…ç½®æ–‡ä»¶&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cp docker-compose.yml.example docker-compose.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;2. ä» docker-compose è¿è¡Œ&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;åœ¨&lt;code&gt;docker-compose.yml&lt;/code&gt;æ‰€åœ¨çš„ç›®å½•ä½¿ç”¨å‘½ä»¤&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker-compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Web ç®¡ç†é¡µé¢&lt;/h2&gt; &#xA;&lt;p&gt;ç›®å‰æ”¯æŒç”¨æˆ·å’Œä»»åŠ¡ä»¥åŠå®æ—¶æ—¥å¿—æŸ¥çœ‹ï¼Œæ›´å¤šåŠŸèƒ½åç»­ä¼šä¸æ–­åŠ å…¥&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ä½¿ç”¨&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;æ‰“å¼€ Web åŠŸèƒ½éœ€è¦å°†é…ç½®ä¸­çš„ &lt;code&gt;WEB_ENABLE&lt;/code&gt; æ‰“å¼€ï¼Œå¯åŠ¨ç¨‹åºåè®¿é—®å½“å‰ä¸»æœºåœ°å€ + ç«¯å£å· (é»˜è®¤ 8008) å³å¯ï¼Œå¦‚ &lt;a href=&#34;http://127.0.0.1:8008&#34;&gt;http://127.0.0.1:8008&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;æ›´æ–°&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;19-01-10 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;æ”¯æŒåˆ†å¸ƒå¼é›†ç¾¤&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;19-01-11 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;é…ç½®æ–‡ä»¶æ”¯æŒåŠ¨æ€ä¿®æ”¹&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;19-01-12 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;æ–°å¢å…è´¹æ‰“ç &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;19-01-14 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;æ–°å¢ Web é¡µé¢æ”¯æŒ&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;19-01-15 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;æ–°å¢ é’‰é’‰é€šçŸ¥&lt;/li&gt; &#xA;   &lt;li&gt;æ–°å¢ Telegram é€šçŸ¥&lt;/li&gt; &#xA;   &lt;li&gt;æ–°å¢ ServerChan å’Œ PushBear å¾®ä¿¡æ¨é€&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;19-01-18 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;æ–°å¢ CDN æŸ¥è¯¢&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;æˆªå›¾&lt;/h2&gt; &#xA;&lt;h3&gt;Web ç®¡ç†é¡µé¢&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/pjialin/py12306/raw/master/data/images/web.png&#34; alt=&#34;Web ç®¡ç†é¡µé¢å›¾ç‰‡&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;ä¸‹å•æˆåŠŸ&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/pjialin/py12306/raw/master/data/images/order_success.png&#34; alt=&#34;ä¸‹å•æˆåŠŸå›¾ç‰‡&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;å…³äºé˜²å°&lt;/h3&gt; &#xA;&lt;p&gt;ç›®å‰æŸ¥è¯¢å’Œç™»å½•æ“ä½œæ˜¯åˆ†å¼€çš„ï¼ŒæŸ¥è¯¢æ˜¯ä¸ä¾èµ–ç”¨æˆ·æ˜¯å¦ç™»å½•ï¼Œæ”¾åœ¨ A äº‘ T äº‘å®¹æ˜“è¢«é™åˆ¶ ipï¼Œå»ºè®®åœ¨å…¶å®ƒç½‘ç»œç¯å¢ƒä¸‹è¿è¡Œ&lt;/p&gt; &#xA;&lt;p&gt;QQ äº¤æµç¾¤ &lt;a href=&#34;https://jq.qq.com/?_wv=1027&amp;amp;k=5PgzDwV&#34;&gt;780289875&lt;/a&gt;ï¼ŒTG ç¾¤ &lt;a href=&#34;https://t.me/joinchat/F3sSegrF3x8KAmsd1mTu7w&#34;&gt;Py12306 äº¤æµ&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Online IDE&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitpod.io#https://github.com/pjialin/py12306&#34;&gt;&lt;img src=&#34;https://gitpod.io/button/open-in-gitpod.svg?sanitize=true&#34; alt=&#34;åœ¨ Gitpod ä¸­æ‰“å¼€&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Thanks&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æ„Ÿè°¢å¤§ä½¬ &lt;a href=&#34;https://github.com/testerSunshine/12306&#34;&gt;testerSunshine&lt;/a&gt;ï¼Œå€Ÿé‰´äº†éƒ¨åˆ†å®ç°&lt;/li&gt; &#xA; &lt;li&gt;æ„Ÿè°¢æ‰€æœ‰æä¾› pr çš„å¤§ä½¬&lt;/li&gt; &#xA; &lt;li&gt;æ„Ÿè°¢å¤§ä½¬ &lt;a href=&#34;https://github.com/zhaipro/easy12306&#34;&gt;zhaipro&lt;/a&gt; çš„éªŒè¯ç æœ¬åœ°è¯†åˆ«æ¨¡å‹ä¸ç®—æ³•&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/pjialin/py12306/raw/master/LICENSE&#34;&gt;Apache License.&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>