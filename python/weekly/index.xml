<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-10-27T01:42:15Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Guovin/TV</title>
    <updated>2024-10-27T01:42:15Z</updated>
    <id>tag:github.com,2024-10-27:/Guovin/TV</id>
    <link href="https://github.com/Guovin/TV" rel="alternate"></link>
    <summary type="html">&lt;p&gt;📺IPTV电视直播源更新工具🚀：包含💰央视(付费)、📡卫视、🏠广东、🌊港·澳·台、🎬电影、🎥咪咕、🏀体育、🪁动画、🎮游戏、🎵音乐、🏛经典剧场；支持自定义增加频道；支持组播源、酒店源、订阅源、关键字搜索；每天自动更新两次，结果可用于TVBox等播放软件；支持工作流、Docker(amd64/arm64)、命令行、GUI运行方式 | IPTV live TV source update tool&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Guovin/TV/master/static/images/logo.png&#34; alt=&#34;logo&#34;&gt; &#xA; &lt;h1 align=&#34;center&#34;&gt;IPTV电视直播源更新工具&lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA; 自定义频道菜单，根据模板频道，自动获取并更新最新的直播源接口，测速校验后生成可用的接口文件&#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA; 默认结果包含：📺央视频道、💰央视付费频道、📡卫视频道、🏠广东频道、🌊港·澳·台频道、🎬电影频道、🎥咪咕直播、🏀体育频道、🪁动画频道、🎮游戏频道、🎵音乐频道、🏛经典剧场&#xA;&lt;/div&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;具体频道&lt;/summary&gt; &#xA; &lt;div&gt;&#xA;   📺央视频道: CCTV-1, CCTV-2, CCTV-3, CCTV-4, CCTV-5, CCTV-5+, CCTV-6, CCTV-7, CCTV-8, CCTV-9, CCTV-10, CCTV-11, CCTV-12, CCTV-13, CCTV-14, CCTV-15, CCTV-16, CCTV-17, CETV1, CETV2, CETV4, CETV5 &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   💰央视付费频道: 文化精品, 央视台球, 风云音乐, 第一剧场, 风云剧场, 怀旧剧场, 女性时尚, 高尔夫网球, 风云足球, 电视指南, 世界地理, 兵器科技 &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   📡卫视频道: 广东卫视, 香港卫视, 浙江卫视, 湖南卫视, 北京卫视, 湖北卫视, 黑龙江卫视, 安徽卫视, 重庆卫视, 东方卫视, 东南卫视, 甘肃卫视, 广西卫视, 贵州卫视, 海南卫视, 河北卫视, 河南卫视, 吉林卫视, 江苏卫视, 江西卫视, 辽宁卫视, 内蒙古卫视, 宁夏卫视, 青海卫视, 山东卫视, 山西卫视, 陕西卫视, 四川卫视, 深圳卫视, 三沙卫视, 天津卫视, 西藏卫视, 新疆卫视, 云南卫视 &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   🏠广东频道: 广东珠江, 广东体育, 广东新闻, 广东卫视, 大湾区卫视, 广州影视, 广州竞赛, 江门综合, 江门侨乡生活, 佛山综合, 深圳卫视, 汕头综合, 汕头经济, 汕头文旅, 茂名综合, 茂名公共 &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   🌊港·澳·台: 翡翠台, 明珠台, 凤凰中文, 凤凰资讯, 凤凰香港, 凤凰卫视, TVBS亚洲, 香港卫视, 纬来体育, 纬来育乐, J2, Viutv, 三立台湾, 无线新闻, 三立新闻, 东森综合, 东森超视, 东森电影, Now剧集, Now华剧, 靖天资讯, 星卫娱乐, 卫视卡式 &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   🎬电影频道: CHC家庭影院, CHC动作电影, CHC高清电影, 淘剧场, 淘娱乐, 淘电影, NewTV惊悚悬疑, NewTV动作电影, 黑莓电影, 纬来电影, 靖天映画, 靖天戏剧, 星卫娱乐, 艾尔达娱乐, 经典电影, IPTV经典电影, 天映经典, 无线星河, 星空卫视, 私人影院, 东森电影, 龙祥电影, 东森洋片, 东森超视 &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   🎥咪咕直播: 咪咕直播1-45 &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   🏀体育频道: CCTV-5, CCTV-5+, 广东体育, 纬来体育, 五星体育, 体育赛事, 劲爆体育, 爱体育, 超级体育, 精品体育, 广州竞赛, 深圳体育, 福建体育, 辽宁体育, 山东体育, 成都体育, 天津体育, 江苏体育, 安徽综艺体育, 吉林篮球, 睛彩篮球, 睛彩羽毛球, 睛彩广场舞, 风云足球, 足球频道, 魅力足球, 天元围棋, 快乐垂钓, JJ斗地主 &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   🪁动画频道: 少儿动画, 卡酷动画, 动漫秀场, 新动漫, 青春动漫, 爱动漫, 中录动漫, 宝宝动画, CN卡通, 优漫卡通, 金鹰卡通, 睛彩少儿, 黑莓动画, 炫动卡通, 24H国漫热播, 浙江少儿, 河北少儿科教, 七龙珠, 火影忍者, 海绵宝宝, 中华小当家, 斗破苍穹玄幻剧, 猫和老鼠, 经典动漫, 蜡笔小新, 漫画解说 &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   🎮游戏频道: 游戏风云, 游戏竞技, 电竞游戏, 海看电竞, 电竞天堂, 爱电竞 &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   🎵音乐频道: CCTV-15, 风云音乐, 音乐现场, 音乐之声, 潮流音乐, 天津音乐, 音乐广播, 音乐调频广播 &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt;&#xA;   🏛经典剧场: 笑傲江湖, 天龙八部, 鹿鼎记, 仙剑奇侠传, 西游记, 三国演义, 水浒传, 新白娘子传奇, 天龙八部, 济公游记, 封神榜, 闯关东, 上海滩, 射雕英雄传 &#xA; &lt;/div&gt; &#xA;&lt;/details&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/Guovin/TV/releases/latest&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/v/release/guovin/tv&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://www.python.org/&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/python-%20%3E%3D%203.8-47c219&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/Guovin/TV/releases/latest&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/downloads/guovin/tv/total&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/repository/docker/guovern/tv-requests&#34;&gt; &lt;img src=&#34;https://img.shields.io/docker/pulls/guovern/tv-requests?label=docker:requests&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/repository/docker/guovern/tv-driver&#34;&gt; &lt;img src=&#34;https://img.shields.io/docker/pulls/guovern/tv-driver?label=docker:driver&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Guovin/TV/master/README_en.md&#34;&gt;English&lt;/a&gt; | 中文&lt;/p&gt; &#xA;&lt;h2&gt;特点&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;自定义模板，生成您想要的频道&lt;/li&gt; &#xA; &lt;li&gt;支持多种获取源方式：组播源、酒店源、订阅源、关键字搜索&lt;/li&gt; &#xA; &lt;li&gt;接口测速验效，响应时间、分辨率优先级，过滤无效接口&lt;/li&gt; &#xA; &lt;li&gt;定时执行，北京时间每日 6:00 与 18:00 执行更新&lt;/li&gt; &#xA; &lt;li&gt;支持多种运行方式：工作流、命令行、GUI 软件、Docker(amd64/arm64)&lt;/li&gt; &#xA; &lt;li&gt;更多功能请见&lt;a href=&#34;https://raw.githubusercontent.com/Guovin/TV/master/docs/config.md&#34;&gt;配置参数&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;最新结果：&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;接口源：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  https://ghproxy.net/raw.githubusercontent.com/Guovin/TV/gd/output/result.m3u&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;数据源：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  https://ghproxy.net/raw.githubusercontent.com/Guovin/TV/gd/source.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;配置&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Guovin/TV/master/docs/config.md&#34;&gt;配置参数&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;快速上手&lt;/h2&gt; &#xA;&lt;h3&gt;方式一：工作流更新&lt;/h3&gt; &#xA;&lt;p&gt;Fork 本项目并开启工作流更新，具体步骤请见&lt;a href=&#34;https://raw.githubusercontent.com/Guovin/TV/master/docs/tutorial.md&#34;&gt;详细教程&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;方式二：命令行更新&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pip3 install pipenv&#xA;pipenv install&#xA;pipenv run build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;方式三：GUI 软件更新&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;下载&lt;a href=&#34;https://github.com/Guovin/TV/releases&#34;&gt;更新工具软件&lt;/a&gt;，打开软件，点击更新，即可完成更新&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;或者在项目目录下运行以下命令，即可打开 GUI 软件：&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pipenv run ui&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/Guovin/TV/master/docs/images/ui.png&#34; alt=&#34;更新工具软件&#34; title=&#34;更新工具软件&#34; style=&#34;height:600px&#34;&gt; &#xA;&lt;h3&gt;方式四：Docker 更新&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;requests：轻量级，性能要求低，更新速度快，稳定性不确定（推荐订阅源使用此版本）&lt;/li&gt; &#xA; &lt;li&gt;driver：性能要求较高，更新速度较慢，稳定性、成功率高；修改配置 open_driver = False 可切换到 request 版本（推荐酒店源、组播源、关键字搜索使用此版本）&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;建议都试用一次，选择自己合适的版本。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;1. 拉取镜像：&#xA;requests：&#xA;docker pull guovern/tv-requests:latest&#xA;&#xA;driver：&#xA;docker pull guovern/tv-driver:latest&#xA;&#xA;2. 运行容器：&#xA;docker run -d -p 8000:8000 guovern/tv-requests 或 tv-driver&#xA;&#xA;卷挂载参数（可选）：&#xA;实现宿主机文件与容器文件同步，修改模板、配置、获取更新结果文件可直接在宿主机文件夹下操作&#xA;&#xA;配置文件：&#xA;-v 宿主机路径/config:/tv-requests/config 或 tv-driver/config&#xA;&#xA;结果文件：&#xA;-v 宿主机路径/output:/tv-requests/output 或 tv-driver/output&#xA;&#xA;例：docker run -v /etc/docker/config:/tv-requests/config -v /etc/docker/output:/tv-requests/output -d -p 8000:8000 guovern/tv-requests&#xA;&#xA;3. 查看更新结果：访问（域名:8000）&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;注：方式一至三更新完成后的结果文件链接：&lt;a href=&#34;http://%E6%9C%AC%E5%9C%B0&#34;&gt;http://本地&lt;/a&gt; ip:8000 或 &lt;a href=&#34;http://localhost:8000&#34;&gt;http://localhost:8000&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;h2&gt;更新日志&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Guovin/TV/master/CHANGELOG.md&#34;&gt;更新日志&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;许可证&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Guovin/TV/master/LICENSE&#34;&gt;MIT&lt;/a&gt; License © 2024-PRESENT &lt;a href=&#34;https://github.com/guovin&#34;&gt;Govin&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;赞赏&lt;/h2&gt; &#xA;&lt;div&gt;&#xA; 请我喝杯咖啡☕️吧~&#xA;&lt;/div&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;支付宝&lt;/th&gt; &#xA;   &lt;th&gt;微信&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Guovin/TV/master/static/images/alipay.jpg&#34; alt=&#34;支付宝扫码&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Guovin/TV/master/static/images/appreciate.jpg&#34; alt=&#34;微信扫码&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;免责声明&lt;/h2&gt; &#xA;&lt;p&gt;本项目仅供学习交流用途，接口数据均来源于网络，如有侵权，请联系删除&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>crewAIInc/crewAI</title>
    <updated>2024-10-27T01:42:15Z</updated>
    <id>tag:github.com,2024-10-27:/crewAIInc/crewAI</id>
    <link href="https://github.com/crewAIInc/crewAI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/docs/crewai_logo.png&#34; alt=&#34;Logo of CrewAI, two people rowing on a boat&#34;&gt;&lt;/p&gt; &#xA; &lt;h1&gt;&lt;strong&gt;CrewAI&lt;/strong&gt;&lt;/h1&gt; &#xA; &lt;p&gt;🤖 &lt;strong&gt;CrewAI&lt;/strong&gt;: Cutting-edge framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.&lt;/p&gt; &#xA; &lt;h3&gt; &lt;p&gt;&lt;a href=&#34;https://www.crewai.com/&#34;&gt;Homepage&lt;/a&gt; | &lt;a href=&#34;https://docs.crewai.com/&#34;&gt;Documentation&lt;/a&gt; | &lt;a href=&#34;https://chatg.pt/DWjSBZn&#34;&gt;Chat with Docs&lt;/a&gt; | &lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples&#34;&gt;Examples&lt;/a&gt; | &lt;a href=&#34;https://community.crewai.com&#34;&gt;Discourse&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/crewAIInc/crewAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/joaomdmoura/crewAI&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-green.svg?sanitize=true&#34; alt=&#34;License: MIT&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Table of contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#why-crewai&#34;&gt;Why CrewAI?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#getting-started&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#key-features&#34;&gt;Key Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#examples&#34;&gt;Examples&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#quick-tutorial&#34;&gt;Quick Tutorial&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#write-job-descriptions&#34;&gt;Write Job Descriptions&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#trip-planner&#34;&gt;Trip Planner&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#stock-analysis&#34;&gt;Stock Analysis&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#connecting-your-crew-to-a-model&#34;&gt;Connecting Your Crew to a Model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#how-crewai-compares&#34;&gt;How CrewAI Compares&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#contribution&#34;&gt;Contribution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#telemetry&#34;&gt;Telemetry&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why CrewAI?&lt;/h2&gt; &#xA;&lt;p&gt;The power of AI collaboration has too much to offer. CrewAI is designed to enable AI agents to assume roles, share goals, and operate in a cohesive unit - much like a well-oiled crew. Whether you&#39;re building a smart assistant platform, an automated customer service ensemble, or a multi-agent research team, CrewAI provides the backbone for sophisticated multi-agent interactions.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To get started with CrewAI, follow these simple steps:&lt;/p&gt; &#xA;&lt;h3&gt;1. Installation&lt;/h3&gt; &#xA;&lt;p&gt;Ensure you have Python &amp;gt;=3.10 &amp;lt;=3.13 installed on your system. CrewAI uses &lt;a href=&#34;https://docs.astral.sh/uv/&#34;&gt;UV&lt;/a&gt; for dependency management and package handling, offering a seamless setup and execution experience.&lt;/p&gt; &#xA;&lt;p&gt;First, install CrewAI:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install crewai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to install the &#39;crewai&#39; package along with its optional features that include additional tools for agents, you can do so by using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install &#39;crewai[tools]&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The command above installs the basic package and also adds extra components which require more dependencies to function.&lt;/p&gt; &#xA;&lt;h3&gt;2. Setting Up Your Crew with the YAML Configuration&lt;/h3&gt; &#xA;&lt;p&gt;To create a new CrewAI project, run the following CLI (Command Line Interface) command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;crewai create crew &amp;lt;project_name&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command creates a new project folder with the following structure:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;my_project/&#xA;├── .gitignore&#xA;├── pyproject.toml&#xA;├── README.md&#xA;├── .env&#xA;└── src/&#xA;    └── my_project/&#xA;        ├── __init__.py&#xA;        ├── main.py&#xA;        ├── crew.py&#xA;        ├── tools/&#xA;        │   ├── custom_tool.py&#xA;        │   └── __init__.py&#xA;        └── config/&#xA;            ├── agents.yaml&#xA;            └── tasks.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can now start developing your crew by editing the files in the &lt;code&gt;src/my_project&lt;/code&gt; folder. The &lt;code&gt;main.py&lt;/code&gt; file is the entry point of the project, the &lt;code&gt;crew.py&lt;/code&gt; file is where you define your crew, the &lt;code&gt;agents.yaml&lt;/code&gt; file is where you define your agents, and the &lt;code&gt;tasks.yaml&lt;/code&gt; file is where you define your tasks.&lt;/p&gt; &#xA;&lt;h4&gt;To customize your project, you can:&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Modify &lt;code&gt;src/my_project/config/agents.yaml&lt;/code&gt; to define your agents.&lt;/li&gt; &#xA; &lt;li&gt;Modify &lt;code&gt;src/my_project/config/tasks.yaml&lt;/code&gt; to define your tasks.&lt;/li&gt; &#xA; &lt;li&gt;Modify &lt;code&gt;src/my_project/crew.py&lt;/code&gt; to add your own logic, tools, and specific arguments.&lt;/li&gt; &#xA; &lt;li&gt;Modify &lt;code&gt;src/my_project/main.py&lt;/code&gt; to add custom inputs for your agents and tasks.&lt;/li&gt; &#xA; &lt;li&gt;Add your environment variables into the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Example of a simple crew with a sequential process:&lt;/h4&gt; &#xA;&lt;p&gt;Instatiate your crew:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;crewai create crew latest-ai-development&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Modify the files as needed to fit your use case:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;agents.yaml&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# src/my_project/config/agents.yaml&#xA;researcher:&#xA;  role: &amp;gt;&#xA;    {topic} Senior Data Researcher&#xA;  goal: &amp;gt;&#xA;    Uncover cutting-edge developments in {topic}&#xA;  backstory: &amp;gt;&#xA;    You&#39;re a seasoned researcher with a knack for uncovering the latest&#xA;    developments in {topic}. Known for your ability to find the most relevant&#xA;    information and present it in a clear and concise manner.&#xA;      &#xA;reporting_analyst:&#xA;  role: &amp;gt;&#xA;    {topic} Reporting Analyst&#xA;  goal: &amp;gt;&#xA;    Create detailed reports based on {topic} data analysis and research findings&#xA;  backstory: &amp;gt;&#xA;    You&#39;re a meticulous analyst with a keen eye for detail. You&#39;re known for&#xA;    your ability to turn complex data into clear and concise reports, making&#xA;    it easy for others to understand and act on the information you provide.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;tasks.yaml&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# src/my_project/config/tasks.yaml&#xA;research_task:&#xA;  description: &amp;gt;&#xA;    Conduct a thorough research about {topic}&#xA;    Make sure you find any interesting and relevant information given&#xA;    the current year is 2024.&#xA;  expected_output: &amp;gt;&#xA;    A list with 10 bullet points of the most relevant information about {topic}&#xA;  agent: researcher&#xA;&#xA;reporting_task:&#xA;  description: &amp;gt;&#xA;    Review the context you got and expand each topic into a full section for a report.&#xA;    Make sure the report is detailed and contains any and all relevant information.&#xA;  expected_output: &amp;gt;&#xA;    A fully fledge reports with the mains topics, each with a full section of information.&#xA;    Formatted as markdown without &#39;```&#39;&#xA;  agent: reporting_analyst&#xA;  output_file: report.md&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;crew.py&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# src/my_project/crew.py&#xA;from crewai import Agent, Crew, Process, Task&#xA;from crewai.project import CrewBase, agent, crew, task&#xA;from crewai_tools import SerperDevTool&#xA;&#xA;@CrewBase&#xA;class LatestAiDevelopmentCrew():&#xA;&#x9;&#34;&#34;&#34;LatestAiDevelopment crew&#34;&#34;&#34;&#xA;&#xA;&#x9;@agent&#xA;&#x9;def researcher(self) -&amp;gt; Agent:&#xA;&#x9;&#x9;return Agent(&#xA;&#x9;&#x9;&#x9;config=self.agents_config[&#39;researcher&#39;],&#xA;&#x9;&#x9;&#x9;verbose=True,&#xA;&#x9;&#x9;&#x9;tools=[SerperDevTool()]&#xA;&#x9;&#x9;)&#xA;&#xA;&#x9;@agent&#xA;&#x9;def reporting_analyst(self) -&amp;gt; Agent:&#xA;&#x9;&#x9;return Agent(&#xA;&#x9;&#x9;&#x9;config=self.agents_config[&#39;reporting_analyst&#39;],&#xA;&#x9;&#x9;&#x9;verbose=True&#xA;&#x9;&#x9;)&#xA;&#xA;&#x9;@task&#xA;&#x9;def research_task(self) -&amp;gt; Task:&#xA;&#x9;&#x9;return Task(&#xA;&#x9;&#x9;&#x9;config=self.tasks_config[&#39;research_task&#39;],&#xA;&#x9;&#x9;)&#xA;&#xA;&#x9;@task&#xA;&#x9;def reporting_task(self) -&amp;gt; Task:&#xA;&#x9;&#x9;return Task(&#xA;&#x9;&#x9;&#x9;config=self.tasks_config[&#39;reporting_task&#39;],&#xA;&#x9;&#x9;&#x9;output_file=&#39;report.md&#39;&#xA;&#x9;&#x9;)&#xA;&#xA;&#x9;@crew&#xA;&#x9;def crew(self) -&amp;gt; Crew:&#xA;&#x9;&#x9;&#34;&#34;&#34;Creates the LatestAiDevelopment crew&#34;&#34;&#34;&#xA;&#x9;&#x9;return Crew(&#xA;&#x9;&#x9;&#x9;agents=self.agents, # Automatically created by the @agent decorator&#xA;&#x9;&#x9;&#x9;tasks=self.tasks, # Automatically created by the @task decorator&#xA;&#x9;&#x9;&#x9;process=Process.sequential,&#xA;&#x9;&#x9;&#x9;verbose=True,&#xA;&#x9;&#x9;) &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;main.py&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python&#xA;# src/my_project/main.py&#xA;import sys&#xA;from latest_ai_development.crew import LatestAiDevelopmentCrew&#xA;&#xA;def run():&#xA;    &#34;&#34;&#34;&#xA;    Run the crew.&#xA;    &#34;&#34;&#34;&#xA;    inputs = {&#xA;        &#39;topic&#39;: &#39;AI Agents&#39;&#xA;    }&#xA;    LatestAiDevelopmentCrew().crew().kickoff(inputs=inputs)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. Running Your Crew&lt;/h3&gt; &#xA;&lt;p&gt;Before running your crew, make sure you have the following keys set as environment variables in your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;An &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;OpenAI API key&lt;/a&gt; (or other LLM API key): &lt;code&gt;OPENAI_API_KEY=sk-...&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;A &lt;a href=&#34;https://serper.dev/&#34;&gt;Serper.dev&lt;/a&gt; API key: &lt;code&gt;SERPER_API_KEY=YOUR_KEY_HERE&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Lock the dependencies and install them by using the CLI command but first, navigate to your project directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd my_project&#xA;crewai install (Optional)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run your crew, execute the following command in the root of your project:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;crewai run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python src/my_project/main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If an error happens due to the usage of poetry, please run the following command to update your crewai package:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;crewai update&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You should see the output in the console and the &lt;code&gt;report.md&lt;/code&gt; file should be created in the root of your project with the full final report.&lt;/p&gt; &#xA;&lt;p&gt;In addition to the sequential process, you can use the hierarchical process, which automatically assigns a manager to the defined crew to properly coordinate the planning and execution of tasks through delegation and validation of results. &lt;a href=&#34;https://docs.crewai.com/core-concepts/Processes/&#34;&gt;See more about the processes here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Role-Based Agent Design&lt;/strong&gt;: Customize agents with specific roles, goals, and tools.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Autonomous Inter-Agent Delegation&lt;/strong&gt;: Agents can autonomously delegate tasks and inquire amongst themselves, enhancing problem-solving efficiency.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Flexible Task Management&lt;/strong&gt;: Define tasks with customizable tools and assign them to agents dynamically.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Processes Driven&lt;/strong&gt;: Currently only supports &lt;code&gt;sequential&lt;/code&gt; task execution and &lt;code&gt;hierarchical&lt;/code&gt; processes, but more complex processes like consensual and autonomous are being worked on.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Save output as file&lt;/strong&gt;: Save the output of individual tasks as a file, so you can use it later.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Parse output as Pydantic or Json&lt;/strong&gt;: Parse the output of individual tasks as a Pydantic model or as a Json if you want to.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Works with Open Source Models&lt;/strong&gt;: Run your crew using Open AI or open source models refer to the &lt;a href=&#34;https://docs.crewai.com/how-to/LLM-Connections/&#34;&gt;Connect CrewAI to LLMs&lt;/a&gt; page for details on configuring your agents&#39; connections to models, even ones running locally!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/crewAIInc/crewAI/main/docs/crewAI-mindmap.png&#34; alt=&#34;CrewAI Mind Map&#34; title=&#34;CrewAI Mind Map&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;You can test different real life examples of AI crews in the &lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples?tab=readme-ov-file&#34;&gt;CrewAI-examples repo&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples/tree/main/landing_page_generator&#34;&gt;Landing Page Generator&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.crewai.com/how-to/Human-Input-on-Execution&#34;&gt;Having Human input on the execution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples/tree/main/trip_planner&#34;&gt;Trip Planner&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples/tree/main/stock_analysis&#34;&gt;Stock Analysis&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Quick Tutorial&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=tnejrr-0a94&#34; title=&#34;CrewAI Tutorial&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/tnejrr-0a94/maxresdefault.jpg&#34; alt=&#34;CrewAI Tutorial&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Write Job Descriptions&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples/tree/main/job-posting&#34;&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=u98wEMz-9to&#34; title=&#34;Jobs postings&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/u98wEMz-9to/maxresdefault.jpg&#34; alt=&#34;Jobs postings&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Trip Planner&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples/tree/main/trip_planner&#34;&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=xis7rWp-hjs&#34; title=&#34;Trip Planner&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/xis7rWp-hjs/maxresdefault.jpg&#34; alt=&#34;Trip Planner&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Stock Analysis&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples/tree/main/stock_analysis&#34;&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=e0Uj4yWdaAg&#34; title=&#34;Stock Analysis&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/e0Uj4yWdaAg/maxresdefault.jpg&#34; alt=&#34;Stock Analysis&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Connecting Your Crew to a Model&lt;/h2&gt; &#xA;&lt;p&gt;CrewAI supports using various LLMs through a variety of connection options. By default your agents will use the OpenAI API when querying the model. However, there are several other ways to allow your agents to connect to models. For example, you can configure your agents to use a local model via the Ollama tool.&lt;/p&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://docs.crewai.com/how-to/LLM-Connections/&#34;&gt;Connect CrewAI to LLMs&lt;/a&gt; page for details on configuring you agents&#39; connections to models.&lt;/p&gt; &#xA;&lt;h2&gt;How CrewAI Compares&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;CrewAI&#39;s Advantage&lt;/strong&gt;: CrewAI is built with production in mind. It offers the flexibility of Autogen&#39;s conversational agents and the structured process approach of ChatDev, but without the rigidity. CrewAI&#39;s processes are designed to be dynamic and adaptable, fitting seamlessly into both development and production workflows.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Autogen&lt;/strong&gt;: While Autogen does good in creating conversational agents capable of working together, it lacks an inherent concept of process. In Autogen, orchestrating agents&#39; interactions requires additional programming, which can become complex and cumbersome as the scale of tasks grows.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;ChatDev&lt;/strong&gt;: ChatDev introduced the idea of processes into the realm of AI agents, but its implementation is quite rigid. Customizations in ChatDev are limited and not geared towards production environments, which can hinder scalability and flexibility in real-world applications.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contribution&lt;/h2&gt; &#xA;&lt;p&gt;CrewAI is open-source and we welcome contributions. If you&#39;re looking to contribute, please:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fork the repository.&lt;/li&gt; &#xA; &lt;li&gt;Create a new branch for your feature.&lt;/li&gt; &#xA; &lt;li&gt;Add your feature or improvement.&lt;/li&gt; &#xA; &lt;li&gt;Send a pull request.&lt;/li&gt; &#xA; &lt;li&gt;We appreciate your input!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installing Dependencies&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uv lock&#xA;uv sync&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Virtual Env&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uv venv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Pre-commit hooks&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pre-commit install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running Tests&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uv run pytest .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running static type checks&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uvx mypy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Packaging&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uv build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Installing Locally&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install dist/*.tar.gz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Telemetry&lt;/h2&gt; &#xA;&lt;p&gt;CrewAI uses anonymous telemetry to collect usage data with the main purpose of helping us improve the library by focusing our efforts on the most used features, integrations and tools.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s pivotal to understand that &lt;strong&gt;NO data is collected&lt;/strong&gt; concerning prompts, task descriptions, agents&#39; backstories or goals, usage of tools, API calls, responses, any data processed by the agents, or secrets and environment variables, with the exception of the conditions mentioned. When the &lt;code&gt;share_crew&lt;/code&gt; feature is enabled, detailed data including task descriptions, agents&#39; backstories or goals, and other specific attributes are collected to provide deeper insights while respecting user privacy. We don&#39;t offer a way to disable it now, but we will in the future.&lt;/p&gt; &#xA;&lt;p&gt;Data collected includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Version of CrewAI &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;So we can understand how many users are using the latest version&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Version of Python &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;So we can decide on what versions to better support&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;General OS (e.g. number of CPUs, macOS/Windows/Linux) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;So we know what OS we should focus on and if we could build specific OS related features&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Number of agents and tasks in a crew &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;So we make sure we are testing internally with similar use cases and educate people on the best practices&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Crew Process being used &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand where we should focus our efforts&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;If Agents are using memory or allowing delegation &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand if we improved the features or maybe even drop them&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;If Tasks are being executed in parallel or sequentially &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand if we should focus more on parallel execution&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Language model being used &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Improved support on most used languages&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Roles of agents in a crew &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand high level use cases so we can build better tools, integrations and examples about it&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Tools names available &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand out of the publically available tools, which ones are being used the most so we can improve them&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Users can opt-in to Further Telemetry, sharing the complete telemetry data by setting the &lt;code&gt;share_crew&lt;/code&gt; attribute to &lt;code&gt;True&lt;/code&gt; on their Crews. Enabling &lt;code&gt;share_crew&lt;/code&gt; results in the collection of detailed crew and task execution data, including &lt;code&gt;goal&lt;/code&gt;, &lt;code&gt;backstory&lt;/code&gt;, &lt;code&gt;context&lt;/code&gt;, and &lt;code&gt;output&lt;/code&gt; of tasks. This enables a deeper insight into usage patterns while respecting the user&#39;s choice to share.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;CrewAI is released under the &lt;a href=&#34;https://github.com/crewAIInc/crewAI/raw/main/LICENSE&#34;&gt;MIT License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Frequently Asked Questions (FAQ)&lt;/h2&gt; &#xA;&lt;h3&gt;Q: What is CrewAI?&lt;/h3&gt; &#xA;&lt;p&gt;A: CrewAI is a cutting-edge framework for orchestrating role-playing, autonomous AI agents. It enables agents to work together seamlessly, tackling complex tasks through collaborative intelligence.&lt;/p&gt; &#xA;&lt;h3&gt;Q: How do I install CrewAI?&lt;/h3&gt; &#xA;&lt;p&gt;A: You can install CrewAI using pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install crewai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For additional tools, use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install &#39;crewai[tools]&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Q: Can I use CrewAI with local models?&lt;/h3&gt; &#xA;&lt;p&gt;A: Yes, CrewAI supports various LLMs, including local models. You can configure your agents to use local models via tools like Ollama &amp;amp; LM Studio. Check the &lt;a href=&#34;https://docs.crewai.com/how-to/LLM-Connections/&#34;&gt;LLM Connections documentation&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h3&gt;Q: What are the key features of CrewAI?&lt;/h3&gt; &#xA;&lt;p&gt;A: Key features include role-based agent design, autonomous inter-agent delegation, flexible task management, process-driven execution, output saving as files, and compatibility with both open-source and proprietary models.&lt;/p&gt; &#xA;&lt;h3&gt;Q: How does CrewAI compare to other AI orchestration tools?&lt;/h3&gt; &#xA;&lt;p&gt;A: CrewAI is designed with production in mind, offering flexibility similar to Autogen&#39;s conversational agents and structured processes like ChatDev, but with more adaptability for real-world applications.&lt;/p&gt; &#xA;&lt;h3&gt;Q: Is CrewAI open-source?&lt;/h3&gt; &#xA;&lt;p&gt;A: Yes, CrewAI is open-source and welcomes contributions from the community.&lt;/p&gt; &#xA;&lt;h3&gt;Q: Does CrewAI collect any data?&lt;/h3&gt; &#xA;&lt;p&gt;A: CrewAI uses anonymous telemetry to collect usage data for improvement purposes. No sensitive data (like prompts, task descriptions, or API calls) is collected. Users can opt-in to share more detailed data by setting &lt;code&gt;share_crew=True&lt;/code&gt; on their Crews.&lt;/p&gt; &#xA;&lt;h3&gt;Q: Where can I find examples of CrewAI in action?&lt;/h3&gt; &#xA;&lt;p&gt;A: You can find various real-life examples in the &lt;a href=&#34;https://github.com/crewAIInc/crewAI-examples&#34;&gt;CrewAI-examples repository&lt;/a&gt;, including trip planners, stock analysis tools, and more.&lt;/p&gt; &#xA;&lt;h3&gt;Q: How can I contribute to CrewAI?&lt;/h3&gt; &#xA;&lt;p&gt;A: Contributions are welcome! You can fork the repository, create a new branch for your feature, add your improvement, and send a pull request. Check the Contribution section in the README for more details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>OpenInterpreter/open-interpreter</title>
    <updated>2024-10-27T01:42:15Z</updated>
    <id>tag:github.com,2024-10-27:/OpenInterpreter/open-interpreter</id>
    <link href="https://github.com/OpenInterpreter/open-interpreter" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A natural language interface for computers&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;● Open Interpreter&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://discord.gg/Hvz9Axh84z&#34;&gt; &lt;img alt=&#34;Discord&#34; src=&#34;https://img.shields.io/discord/1146610656779440188?logo=discord&amp;amp;style=flat&amp;amp;logoColor=white&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenInterpreter/open-interpreter/main/docs/README_JA.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88-%E6%97%A5%E6%9C%AC%E8%AA%9E-white.svg?sanitize=true&#34; alt=&#34;JA doc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenInterpreter/open-interpreter/main/docs/README_ZH.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%E6%96%87%E6%A1%A3-%E4%B8%AD%E6%96%87%E7%89%88-white.svg?sanitize=true&#34; alt=&#34;ZH doc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenInterpreter/open-interpreter/main/docs/README_ES.md&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Espa%C3%B1ol-white.svg?sanitize=true&#34; alt=&#34;ES doc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenInterpreter/open-interpreter/main/docs/README_UK.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%D0%A3%D0%BA%D1%80%D0%B0%D1%97%D0%BD%D1%81%D1%8C%D0%BA%D0%B0-white.svg?sanitize=true&#34; alt=&#34;UK doc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenInterpreter/open-interpreter/main/docs/README_IN.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Hindi-white.svg?sanitize=true&#34; alt=&#34;IN doc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenInterpreter/open-interpreter/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?label=license&amp;amp;message=AGPL&amp;amp;color=white&amp;amp;style=flat&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;br&gt;&lt;a href=&#34;https://0ggfznkwh4j.typeform.com/to/G21i9lJ2&#34;&gt;Get early access to the desktop app&lt;/a&gt;‎ ‎ |‎ ‎ &lt;a href=&#34;https://docs.openinterpreter.com/&#34;&gt;Documentation&lt;/a&gt;&lt;br&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;img alt=&#34;local_explorer&#34; src=&#34;https://github.com/OpenInterpreter/open-interpreter/assets/63927363/d941c3b4-b5ad-4642-992c-40edf31e2e7a&#34;&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install open-interpreter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Not working? Read our &lt;a href=&#34;https://docs.openinterpreter.com/getting-started/setup&#34;&gt;setup guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;interpreter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;strong&gt;Open Interpreter&lt;/strong&gt; lets LLMs run code (Python, Javascript, Shell, and more) locally. You can chat with Open Interpreter through a ChatGPT-like interface in your terminal by running &lt;code&gt;$ interpreter&lt;/code&gt; after installing.&lt;/p&gt; &#xA;&lt;p&gt;This provides a natural-language interface to your computer&#39;s general-purpose capabilities:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create and edit photos, videos, PDFs, etc.&lt;/li&gt; &#xA; &lt;li&gt;Control a Chrome browser to perform research&lt;/li&gt; &#xA; &lt;li&gt;Plot, clean, and analyze large datasets&lt;/li&gt; &#xA; &lt;li&gt;...etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;⚠️ Note: You&#39;ll be asked to approve code before it&#39;s run.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/OpenInterpreter/open-interpreter/assets/63927363/37152071-680d-4423-9af3-64836a6f7b60&#34;&gt;https://github.com/OpenInterpreter/open-interpreter/assets/63927363/37152071-680d-4423-9af3-64836a6f7b60&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;An interactive demo is also available on Google Colab:&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1WKmRXZgsErej2xUriKzxrEAXdxMSgWbb?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Along with an example voice interface, inspired by &lt;em&gt;Her&lt;/em&gt;:&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1NojYGHDgxH6Y1G1oxThEBBb2AtyODBIK&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install open-interpreter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Terminal&lt;/h3&gt; &#xA;&lt;p&gt;After installation, simply run &lt;code&gt;interpreter&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;interpreter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Python&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from interpreter import interpreter&#xA;&#xA;interpreter.chat(&#34;Plot AAPL and META&#39;s normalized stock prices&#34;) # Executes a single command&#xA;interpreter.chat() # Starts an interactive chat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;GitHub Codespaces&lt;/h3&gt; &#xA;&lt;p&gt;Press the &lt;code&gt;,&lt;/code&gt; key on this repository&#39;s GitHub page to create a codespace. After a moment, you&#39;ll receive a cloud virtual machine environment pre-installed with open-interpreter. You can then start interacting with it directly and freely confirm its execution of system commands without worrying about damaging the system.&lt;/p&gt; &#xA;&lt;h2&gt;Comparison to ChatGPT&#39;s Code Interpreter&lt;/h2&gt; &#xA;&lt;p&gt;OpenAI&#39;s release of &lt;a href=&#34;https://openai.com/blog/chatgpt-plugins#code-interpreter&#34;&gt;Code Interpreter&lt;/a&gt; with GPT-4 presents a fantastic opportunity to accomplish real-world tasks with ChatGPT.&lt;/p&gt; &#xA;&lt;p&gt;However, OpenAI&#39;s service is hosted, closed-source, and heavily restricted:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;No internet access.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://wfhbrian.com/mastering-chatgpts-code-interpreter-list-of-python-packages/&#34;&gt;Limited set of pre-installed packages&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;100 MB maximum upload, 120.0 second runtime limit.&lt;/li&gt; &#xA; &lt;li&gt;State is cleared (along with any generated files or links) when the environment dies.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Open Interpreter overcomes these limitations by running in your local environment. It has full access to the internet, isn&#39;t restricted by time or file size, and can utilize any package or library.&lt;/p&gt; &#xA;&lt;p&gt;This combines the power of GPT-4&#39;s Code Interpreter with the flexibility of your local development environment.&lt;/p&gt; &#xA;&lt;h2&gt;Commands&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; The Generator Update (0.1.5) introduced streaming:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;message = &#34;What operating system are we on?&#34;&#xA;&#xA;for chunk in interpreter.chat(message, display=False, stream=True):&#xA;  print(chunk)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Interactive Chat&lt;/h3&gt; &#xA;&lt;p&gt;To start an interactive chat in your terminal, either run &lt;code&gt;interpreter&lt;/code&gt; from the command line:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;interpreter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or &lt;code&gt;interpreter.chat()&lt;/code&gt; from a .py file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;interpreter.chat()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;You can also stream each chunk:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;message = &#34;What operating system are we on?&#34;&#xA;&#xA;for chunk in interpreter.chat(message, display=False, stream=True):&#xA;  print(chunk)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Programmatic Chat&lt;/h3&gt; &#xA;&lt;p&gt;For more precise control, you can pass messages directly to &lt;code&gt;.chat(message)&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;interpreter.chat(&#34;Add subtitles to all videos in /videos.&#34;)&#xA;&#xA;# ... Streams output to your terminal, completes task ...&#xA;&#xA;interpreter.chat(&#34;These look great but can you make the subtitles bigger?&#34;)&#xA;&#xA;# ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Start a New Chat&lt;/h3&gt; &#xA;&lt;p&gt;In Python, Open Interpreter remembers conversation history. If you want to start fresh, you can reset it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;interpreter.messages = []&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Save and Restore Chats&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;interpreter.chat()&lt;/code&gt; returns a List of messages, which can be used to resume a conversation with &lt;code&gt;interpreter.messages = messages&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;messages = interpreter.chat(&#34;My name is Killian.&#34;) # Save messages to &#39;messages&#39;&#xA;interpreter.messages = [] # Reset interpreter (&#34;Killian&#34; will be forgotten)&#xA;&#xA;interpreter.messages = messages # Resume chat from &#39;messages&#39; (&#34;Killian&#34; will be remembered)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Customize System Message&lt;/h3&gt; &#xA;&lt;p&gt;You can inspect and configure Open Interpreter&#39;s system message to extend its functionality, modify permissions, or give it more context.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;interpreter.system_message += &#34;&#34;&#34;&#xA;Run shell commands with -y so the user doesn&#39;t have to confirm them.&#xA;&#34;&#34;&#34;&#xA;print(interpreter.system_message)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Change your Language Model&lt;/h3&gt; &#xA;&lt;p&gt;Open Interpreter uses &lt;a href=&#34;https://docs.litellm.ai/docs/providers/&#34;&gt;LiteLLM&lt;/a&gt; to connect to hosted language models.&lt;/p&gt; &#xA;&lt;p&gt;You can change the model by setting the model parameter:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;interpreter --model gpt-3.5-turbo&#xA;interpreter --model claude-2&#xA;interpreter --model command-nightly&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In Python, set the model on the object:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;interpreter.llm.model = &#34;gpt-3.5-turbo&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.litellm.ai/docs/providers/&#34;&gt;Find the appropriate &#34;model&#34; string for your language model here.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Running Open Interpreter locally&lt;/h3&gt; &#xA;&lt;h4&gt;Terminal&lt;/h4&gt; &#xA;&lt;p&gt;Open Interpreter can use OpenAI-compatible server to run models locally. (LM Studio, jan.ai, ollama etc)&lt;/p&gt; &#xA;&lt;p&gt;Simply run &lt;code&gt;interpreter&lt;/code&gt; with the api_base URL of your inference server (for LM studio it is &lt;code&gt;http://localhost:1234/v1&lt;/code&gt; by default):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;interpreter --api_base &#34;http://localhost:1234/v1&#34; --api_key &#34;fake_key&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively you can use Llamafile without installing any third party software just by running&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;interpreter --local&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;for a more detailed guide check out &lt;a href=&#34;https://www.youtube.com/watch?v=CEs51hGWuGU?si=cN7f6QhfT4edfG5H&#34;&gt;this video by Mike Bird&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;How to run LM Studio in the background.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download &lt;a href=&#34;https://lmstudio.ai/&#34;&gt;https://lmstudio.ai/&lt;/a&gt; then start it.&lt;/li&gt; &#xA; &lt;li&gt;Select a model then click &lt;strong&gt;↓ Download&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Click the &lt;strong&gt;↔️&lt;/strong&gt; button on the left (below 💬).&lt;/li&gt; &#xA; &lt;li&gt;Select your model at the top, then click &lt;strong&gt;Start Server&lt;/strong&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Once the server is running, you can begin your conversation with Open Interpreter.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Local mode sets your &lt;code&gt;context_window&lt;/code&gt; to 3000, and your &lt;code&gt;max_tokens&lt;/code&gt; to 1000. If your model has different requirements, set these parameters manually (see below).&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;Python&lt;/h4&gt; &#xA;&lt;p&gt;Our Python package gives you more control over each setting. To replicate and connect to LM Studio, use these settings:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from interpreter import interpreter&#xA;&#xA;interpreter.offline = True # Disables online features like Open Procedures&#xA;interpreter.llm.model = &#34;openai/x&#34; # Tells OI to send messages in OpenAI&#39;s format&#xA;interpreter.llm.api_key = &#34;fake_key&#34; # LiteLLM, which we use to talk to LM Studio, requires this&#xA;interpreter.llm.api_base = &#34;http://localhost:1234/v1&#34; # Point this at any OpenAI compatible server&#xA;&#xA;interpreter.chat()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Context Window, Max Tokens&lt;/h4&gt; &#xA;&lt;p&gt;You can modify the &lt;code&gt;max_tokens&lt;/code&gt; and &lt;code&gt;context_window&lt;/code&gt; (in tokens) of locally running models.&lt;/p&gt; &#xA;&lt;p&gt;For local mode, smaller context windows will use less RAM, so we recommend trying a much shorter window (~1000) if it&#39;s failing / if it&#39;s slow. Make sure &lt;code&gt;max_tokens&lt;/code&gt; is less than &lt;code&gt;context_window&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;interpreter --local --max_tokens 1000 --context_window 3000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Verbose mode&lt;/h3&gt; &#xA;&lt;p&gt;To help you inspect Open Interpreter we have a &lt;code&gt;--verbose&lt;/code&gt; mode for debugging.&lt;/p&gt; &#xA;&lt;p&gt;You can activate verbose mode by using its flag (&lt;code&gt;interpreter --verbose&lt;/code&gt;), or mid-chat:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ interpreter&#xA;...&#xA;&amp;gt; %verbose true &amp;lt;- Turns on verbose mode&#xA;&#xA;&amp;gt; %verbose false &amp;lt;- Turns off verbose mode&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Interactive Mode Commands&lt;/h3&gt; &#xA;&lt;p&gt;In the interactive mode, you can use the below commands to enhance your experience. Here&#39;s a list of available commands:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Available Commands:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;%verbose [true/false]&lt;/code&gt;: Toggle verbose mode. Without arguments or with &lt;code&gt;true&lt;/code&gt; it enters verbose mode. With &lt;code&gt;false&lt;/code&gt; it exits verbose mode.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;%reset&lt;/code&gt;: Resets the current session&#39;s conversation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;%undo&lt;/code&gt;: Removes the previous user message and the AI&#39;s response from the message history.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;%tokens [prompt]&lt;/code&gt;: (&lt;em&gt;Experimental&lt;/em&gt;) Calculate the tokens that will be sent with the next prompt as context and estimate their cost. Optionally calculate the tokens and estimated cost of a &lt;code&gt;prompt&lt;/code&gt; if one is provided. Relies on &lt;a href=&#34;https://docs.litellm.ai/docs/completion/token_usage#2-cost_per_token&#34;&gt;LiteLLM&#39;s &lt;code&gt;cost_per_token()&lt;/code&gt; method&lt;/a&gt; for estimated costs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;%help&lt;/code&gt;: Show the help message.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Configuration / Profiles&lt;/h3&gt; &#xA;&lt;p&gt;Open Interpreter allows you to set default behaviors using &lt;code&gt;yaml&lt;/code&gt; files.&lt;/p&gt; &#xA;&lt;p&gt;This provides a flexible way to configure the interpreter without changing command-line arguments every time.&lt;/p&gt; &#xA;&lt;p&gt;Run the following command to open the profiles directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;interpreter --profiles&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can add &lt;code&gt;yaml&lt;/code&gt; files there. The default profile is named &lt;code&gt;default.yaml&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Multiple Profiles&lt;/h4&gt; &#xA;&lt;p&gt;Open Interpreter supports multiple &lt;code&gt;yaml&lt;/code&gt; files, allowing you to easily switch between configurations:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;interpreter --profile my_profile.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Sample FastAPI Server&lt;/h2&gt; &#xA;&lt;p&gt;The generator update enables Open Interpreter to be controlled via HTTP REST endpoints:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# server.py&#xA;&#xA;from fastapi import FastAPI&#xA;from fastapi.responses import StreamingResponse&#xA;from interpreter import interpreter&#xA;&#xA;app = FastAPI()&#xA;&#xA;@app.get(&#34;/chat&#34;)&#xA;def chat_endpoint(message: str):&#xA;    def event_stream():&#xA;        for result in interpreter.chat(message, stream=True):&#xA;            yield f&#34;data: {result}\n\n&#34;&#xA;&#xA;    return StreamingResponse(event_stream(), media_type=&#34;text/event-stream&#34;)&#xA;&#xA;@app.get(&#34;/history&#34;)&#xA;def history_endpoint():&#xA;    return interpreter.messages&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install fastapi uvicorn&#xA;uvicorn server:app --reload&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also start a server identical to the one above by simply running &lt;code&gt;interpreter.server()&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Android&lt;/h2&gt; &#xA;&lt;p&gt;The step-by-step guide for installing Open Interpreter on your Android device can be found in the &lt;a href=&#34;https://github.com/MikeBirdTech/open-interpreter-termux&#34;&gt;open-interpreter-termux repo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Safety Notice&lt;/h2&gt; &#xA;&lt;p&gt;Since generated code is executed in your local environment, it can interact with your files and system settings, potentially leading to unexpected outcomes like data loss or security risks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;⚠️ Open Interpreter will ask for user confirmation before executing code.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can run &lt;code&gt;interpreter -y&lt;/code&gt; or set &lt;code&gt;interpreter.auto_run = True&lt;/code&gt; to bypass this confirmation, in which case:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Be cautious when requesting commands that modify files or system settings.&lt;/li&gt; &#xA; &lt;li&gt;Watch Open Interpreter like a self-driving car, and be prepared to end the process by closing your terminal.&lt;/li&gt; &#xA; &lt;li&gt;Consider running Open Interpreter in a restricted environment like Google Colab or Replit. These environments are more isolated, reducing the risks of executing arbitrary code.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;There is &lt;strong&gt;experimental&lt;/strong&gt; support for a &lt;a href=&#34;https://github.com/OpenInterpreter/open-interpreter/raw/main/docs/SAFE_MODE.md&#34;&gt;safe mode&lt;/a&gt; to help mitigate some risks.&lt;/p&gt; &#xA;&lt;h2&gt;How Does it Work?&lt;/h2&gt; &#xA;&lt;p&gt;Open Interpreter equips a &lt;a href=&#34;https://platform.openai.com/docs/guides/gpt/function-calling&#34;&gt;function-calling language model&lt;/a&gt; with an &lt;code&gt;exec()&lt;/code&gt; function, which accepts a &lt;code&gt;language&lt;/code&gt; (like &#34;Python&#34; or &#34;JavaScript&#34;) and &lt;code&gt;code&lt;/code&gt; to run.&lt;/p&gt; &#xA;&lt;p&gt;We then stream the model&#39;s messages, code, and your system&#39;s outputs to the terminal as Markdown.&lt;/p&gt; &#xA;&lt;h1&gt;Access Documentation Offline&lt;/h1&gt; &#xA;&lt;p&gt;The full &lt;a href=&#34;https://docs.openinterpreter.com/&#34;&gt;documentation&lt;/a&gt; is accessible on-the-go without the need for an internet connection.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://nodejs.org/en&#34;&gt;Node&lt;/a&gt; is a pre-requisite:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Version 18.17.0 or any later 18.x.x version.&lt;/li&gt; &#xA; &lt;li&gt;Version 20.3.0 or any later 20.x.x version.&lt;/li&gt; &#xA; &lt;li&gt;Any version starting from 21.0.0 onwards, with no upper limit specified.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Install &lt;a href=&#34;https://mintlify.com/&#34;&gt;Mintlify&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm i -g mintlify@latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Change into the docs directory and run the appropriate command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Assuming you&#39;re at the project&#39;s root directory&#xA;cd ./docs&#xA;&#xA;# Run the documentation server&#xA;mintlify dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A new browser window should open. The documentation will be available at &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt; as long as the documentation server is running.&lt;/p&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;Thank you for your interest in contributing! We welcome involvement from the community.&lt;/p&gt; &#xA;&lt;p&gt;Please see our &lt;a href=&#34;https://github.com/OpenInterpreter/open-interpreter/raw/main/docs/CONTRIBUTING.md&#34;&gt;contributing guidelines&lt;/a&gt; for more details on how to get involved.&lt;/p&gt; &#xA;&lt;h1&gt;Roadmap&lt;/h1&gt; &#xA;&lt;p&gt;Visit &lt;a href=&#34;https://github.com/OpenInterpreter/open-interpreter/raw/main/docs/ROADMAP.md&#34;&gt;our roadmap&lt;/a&gt; to preview the future of Open Interpreter.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This software is not affiliated with OpenAI.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/OpenInterpreter/open-interpreter/assets/63927363/1b19a5db-b486-41fd-a7a1-fe2028031686&#34; alt=&#34;thumbnail-ncu&#34;&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Having access to a junior programmer working at the speed of your fingertips ... can make new workflows effortless and efficient, as well as open the benefits of programming to new audiences.&lt;/p&gt; &#xA; &lt;p&gt;— &lt;em&gt;OpenAI&#39;s Code Interpreter Release&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt;</summary>
  </entry>
</feed>