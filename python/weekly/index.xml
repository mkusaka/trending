<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-05T02:04:37Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>lucidrains/imagen-pytorch</title>
    <updated>2022-06-05T02:04:37Z</updated>
    <id>tag:github.com,2022-06-05:/lucidrains/imagen-pytorch</id>
    <link href="https://github.com/lucidrains/imagen-pytorch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Implementation of Imagen, Google&#39;s Text-to-Image Neural Network, in Pytorch&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lucidrains/imagen-pytorch/main/imagen.png&#34; width=&#34;450px&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Imagen - Pytorch (wip)&lt;/h2&gt; &#xA;&lt;p&gt;Implementation of &lt;a href=&#34;https://gweb-research-imagen.appspot.com/&#34;&gt;Imagen&lt;/a&gt;, Google&#39;s Text-to-Image Neural Network that beats DALL-E2, in Pytorch. It is the new SOTA for text-to-image synthesis.&lt;/p&gt; &#xA;&lt;p&gt;Architecturally, it is actually much simpler than DALL-E2. It consists of a cascading DDPM conditioned on text embeddings from a large pretrained T5 model (attention network). It also contains dynamic clipping for improved classifier free guidance, noise level conditioning, and a memory efficient unet design.&lt;/p&gt; &#xA;&lt;p&gt;It appears neither CLIP nor prior network is needed after all. And so research continues.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=xqDeAz0U-R4&#34;&gt;AI Coffee Break with Letitia&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Please join &lt;a href=&#34;https://discord.gg/xBPBXfcFHd&#34;&gt;&lt;img alt=&#34;Join us on Discord&#34; src=&#34;https://img.shields.io/discord/823813159592001537?color=5865F2&amp;amp;logo=discord&amp;amp;logoColor=white&#34;&gt;&lt;/a&gt; if you are interested in helping out with the replication with the &lt;a href=&#34;https://laion.ai/&#34;&gt;LAION&lt;/a&gt; community&lt;/p&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pip install imagen-pytorch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from imagen_pytorch import Unet, Imagen&#xA;&#xA;# unet for imagen&#xA;&#xA;unet1 = Unet(&#xA;    dim = 32,&#xA;    cond_dim = 512,&#xA;    dim_mults = (1, 2, 4, 8),&#xA;    num_resnet_blocks = 3,&#xA;    layer_attns = (False, True, True, True),&#xA;    layer_cross_attns = (False, True, True, True)&#xA;)&#xA;&#xA;unet2 = Unet(&#xA;    dim = 32,&#xA;    cond_dim = 512,&#xA;    dim_mults = (1, 2, 4, 8),&#xA;    num_resnet_blocks = (2, 4, 8, 8),&#xA;    layer_attns = (False, False, False, True),&#xA;    layer_cross_attns = (False, False, False, True)&#xA;)&#xA;&#xA;# imagen, which contains the unets above (base unet and super resoluting ones)&#xA;&#xA;imagen = Imagen(&#xA;    unets = (unet1, unet2),&#xA;    image_sizes = (64, 256),&#xA;    beta_schedules = (&#39;cosine&#39;, &#39;linear&#39;),&#xA;    timesteps = 1000,&#xA;    cond_drop_prob = 0.5&#xA;).cuda()&#xA;&#xA;# mock images (get a lot of this) and text encodings from large T5&#xA;&#xA;text_embeds = torch.randn(4, 256, 768).cuda()&#xA;text_masks = torch.ones(4, 256).bool().cuda()&#xA;images = torch.randn(4, 3, 256, 256).cuda()&#xA;&#xA;# feed images into imagen, training each unet in the cascade&#xA;&#xA;for i in (1, 2):&#xA;    loss = imagen(images, text_embeds = text_embeds, text_masks = text_masks, unet_number = i)&#xA;    loss.backward()&#xA;&#xA;# do the above for many many many many steps&#xA;# now you can sample an image based on the text embeddings from the cascading ddpm&#xA;&#xA;images = imagen.sample(texts = [&#xA;    &#39;a whale breaching from afar&#39;,&#xA;    &#39;young girl blowing out candles on her birthday cake&#39;,&#xA;    &#39;fireworks with blue and green sparkles&#39;&#xA;], cond_scale = 2.)&#xA;&#xA;images.shape # (3, 3, 256, 256)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;With the &lt;code&gt;ImagenTrainer&lt;/code&gt; wrapper class, the exponential moving averages for all of the U-nets in the cascading DDPM will be automatically taken care of when calling &lt;code&gt;update&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from imagen_pytorch import Unet, Imagen, ImagenTrainer&#xA;&#xA;# unet for imagen&#xA;&#xA;unet1 = Unet(&#xA;    dim = 32,&#xA;    cond_dim = 512,&#xA;    dim_mults = (1, 2, 4, 8),&#xA;    num_resnet_blocks = 3,&#xA;    layer_attns = (False, True, True, True),&#xA;)&#xA;&#xA;unet2 = Unet(&#xA;    dim = 32,&#xA;    cond_dim = 512,&#xA;    dim_mults = (1, 2, 4, 8),&#xA;    num_resnet_blocks = (2, 4, 8, 8),&#xA;    layer_attns = (False, False, False, True),&#xA;    layer_cross_attns = (False, False, False, True)&#xA;)&#xA;&#xA;# imagen, which contains the unets above (base unet and super resoluting ones)&#xA;&#xA;imagen = Imagen(&#xA;    unets = (unet1, unet2),&#xA;    text_encoder_name = &#39;t5-large&#39;,&#xA;    image_sizes = (64, 256),&#xA;    beta_schedules = (&#39;cosine&#39;, &#39;linear&#39;),&#xA;    timesteps = 1000,&#xA;    cond_drop_prob = 0.5&#xA;).cuda()&#xA;&#xA;# wrap imagen with the trainer class&#xA;&#xA;trainer = ImagenTrainer(imagen)&#xA;&#xA;# mock images (get a lot of this) and text encodings from large T5&#xA;&#xA;text_embeds = torch.randn(64, 256, 1024).cuda()&#xA;text_masks = torch.ones(64, 256).bool().cuda()&#xA;images = torch.randn(64, 3, 256, 256).cuda()&#xA;&#xA;# feed images into imagen, training each unet in the cascade&#xA;&#xA;for i in (1, 2):&#xA;    loss = trainer(&#xA;        images,&#xA;        text_embeds = text_embeds,&#xA;        text_masks = text_masks,&#xA;        unet_number = i,&#xA;        max_batch_size = 4        # auto divide the batch of 64 up into batch size of 4 and accumulate gradients, so it all fits in memory&#xA;    )&#xA;&#xA;    trainer.update(unet_number = i)&#xA;&#xA;# do the above for many many many many steps&#xA;# now you can sample an image based on the text embeddings from the cascading ddpm&#xA;&#xA;images = trainer.sample(texts = [&#xA;    &#39;a puppy looking anxiously at a giant donut on the table&#39;,&#xA;    &#39;the milky way galaxy in the style of monet&#39;&#xA;], cond_scale = 2.)&#xA;&#xA;images.shape # (2, 3, 256, 256)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Shoutouts&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://stability.ai/&#34;&gt;StabilityAI&lt;/a&gt; for the generous sponsorship, as well as my other sponsors out there&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/&#34;&gt;ðŸ¤— Huggingface&lt;/a&gt; for their amazing transformers library. The text encoder portion is pretty much taken care of because of them&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/jorgemcgomes&#34;&gt;Jorge Gomes&lt;/a&gt; for helping out with the T5 loading code and advice on the correct T5 version&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/crowsonkb&#34;&gt;Katherine Crowson&lt;/a&gt;, for her &lt;a href=&#34;https://github.com/crowsonkb/v-diffusion-jax/raw/master/diffusion/utils.py&#34;&gt;beautiful code&lt;/a&gt;, which helped me understand the continuous time version of gaussian diffusion&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You? It isn&#39;t done yet, chip in if you are a researcher or skilled ML engineer&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Todo&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; use huggingface transformers for T5-small text embeddings&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; add dynamic thresholding&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; add dynamic thresholding DALLE2 and video-diffusion repository as well&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; allow for one to set T5-large (and perhaps small factory method to take in any huggingface transformer)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; add the lowres noise level with the pseudocode in appendix, and figure out what is this sweep they do at inference time&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; port over some training code from DALLE2&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; need to be able to use a different noise schedule per unet (cosine was used for base, but linear for SR)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; just make one master-configurable unet&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; complete resnet block (biggan inspired? but with groupnorm) - complete self attention&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; complete conditioning embedding block (and make it completely configurable, whether it be attention, film etc)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; consider using perceiver-resampler from &lt;a href=&#34;https://github.com/lucidrains/flamingo-pytorch&#34;&gt;https://github.com/lucidrains/flamingo-pytorch&lt;/a&gt; in place of attention pooling&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; add attention pooling option, in addition to cross attention and film&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; add optional cosine decay schedule with warmup, for each unet, to trainer&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; figure out if learned variance was used at all, and remove it if it was inconsequential&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; switch to continuous timesteps instead of discretized, as it seems that is what they used for all stages - first figure out the linear noise schedule case from the variational ddpm paper &lt;a href=&#34;https://openreview.net/forum?id=2LdBqxc1Yv&#34;&gt;https://openreview.net/forum?id=2LdBqxc1Yv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; exercise efficient attention expertise + explore skip layer excitation&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; try out grid attention&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citations&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{Saharia2022PhotorealisticTD,&#xA;    title   = {Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},&#xA;    author  = {Chitwan Saharia and William Chan and Saurabh Saxena and Lala Li and Jay Whang and Emily L. Denton and Seyed Kamyar Seyed Ghasemipour and Burcu Karagol Ayan and Seyedeh Sara Mahdavi and Raphael Gontijo Lopes and Tim Salimans and Jonathan Ho and David Fleet and Mohammad Norouzi},&#xA;    year    = {2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{Tu2022MaxViTMV,&#xA;    title   = {MaxViT: Multi-Axis Vision Transformer},&#xA;    author  = {Zhengzhong Tu and Hossein Talebi and Han Zhang and Feng Yang and Peyman Milanfar and Alan Conrad Bovik and Yinxiao Li},&#xA;    year    = {2022},&#xA;    url     = {https://arxiv.org/abs/2204.01697}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{Alayrac2022Flamingo,&#xA;    title   = {Flamingo: a Visual Language Model for Few-Shot Learning},&#xA;    author  = {Jean-Baptiste Alayrac et al},&#xA;    year    = {2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>faif/python-patterns</title>
    <updated>2022-06-05T02:04:37Z</updated>
    <id>tag:github.com,2022-06-05:/faif/python-patterns</id>
    <link href="https://github.com/faif/python-patterns" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A collection of design patterns/idioms in Python&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;python-patterns&lt;/h1&gt; &#xA;&lt;p&gt;A collection of design patterns and idioms in Python.&lt;/p&gt; &#xA;&lt;h2&gt;Current Patterns&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Creational Patterns&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Pattern&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/creational/abstract_factory.py&#34;&gt;abstract_factory&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;use a generic function with specific factories&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/creational/borg.py&#34;&gt;borg&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;a singleton with shared-state among instances&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/creational/builder.py&#34;&gt;builder&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;instead of using multiple constructors, builder object receives parameters and returns constructed objects&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/creational/factory.py&#34;&gt;factory&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;delegate a specialized function/method to create instances&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/creational/lazy_evaluation.py&#34;&gt;lazy_evaluation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;lazily-evaluated property pattern in Python&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/creational/pool.py&#34;&gt;pool&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;preinstantiate and maintain a group of instances of the same type&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/creational/prototype.py&#34;&gt;prototype&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;use a factory and clones of a prototype for new instances (if instantiation is expensive)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Structural Patterns&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Pattern&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/structural/3-tier.py&#34;&gt;3-tier&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;data&amp;lt;-&amp;gt;business logic&amp;lt;-&amp;gt;presentation separation (strict relationships)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/structural/adapter.py&#34;&gt;adapter&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;adapt one interface to another using a white-list&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/structural/bridge.py&#34;&gt;bridge&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;a client-provider middleman to soften interface changes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/structural/composite.py&#34;&gt;composite&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;lets clients treat individual objects and compositions uniformly&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/structural/decorator.py&#34;&gt;decorator&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;wrap functionality with other functionality in order to affect outputs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/structural/facade.py&#34;&gt;facade&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;use one class as an API to a number of others&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/structural/flyweight.py&#34;&gt;flyweight&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;transparently reuse existing instances of objects with similar/identical state&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/structural/front_controller.py&#34;&gt;front_controller&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;single handler requests coming to the application&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/structural/mvc.py&#34;&gt;mvc&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;model&amp;lt;-&amp;gt;view&amp;lt;-&amp;gt;controller (non-strict relationships)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/structural/proxy.py&#34;&gt;proxy&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;an object funnels operations to something else&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Behavioral Patterns&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Pattern&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/chain_of_responsibility.py&#34;&gt;chain_of_responsibility&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;apply a chain of successive handlers to try and process the data&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/catalog.py&#34;&gt;catalog&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;general methods will call different specialized methods based on construction parameter&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/chaining_method.py&#34;&gt;chaining_method&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;continue callback next object method&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/command.py&#34;&gt;command&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;bundle a command and arguments to call later&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/iterator.py&#34;&gt;iterator&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;traverse a container and access the container&#39;s elements&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/iterator_alt.py&#34;&gt;iterator&lt;/a&gt; (alt. impl.)&lt;/td&gt; &#xA;   &lt;td&gt;traverse a container and access the container&#39;s elements&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/mediator.py&#34;&gt;mediator&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;an object that knows how to connect other objects and act as a proxy&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/memento.py&#34;&gt;memento&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;generate an opaque token that can be used to go back to a previous state&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/observer.py&#34;&gt;observer&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;provide a callback for notification of events/changes to data&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/publish_subscribe.py&#34;&gt;publish_subscribe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;a source syndicates events/data to 0+ registered listeners&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/registry.py&#34;&gt;registry&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;keep track of all subclasses of a given class&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/specification.py&#34;&gt;specification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;business rules can be recombined by chaining the business rules together using boolean logic&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/state.py&#34;&gt;state&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;logic is organized into a discrete number of potential states and the next state that can be transitioned to&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/strategy.py&#34;&gt;strategy&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;selectable operations over the same data&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/template.py&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;an object imposes a structure but takes pluggable components&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/visitor.py&#34;&gt;visitor&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;invoke a callback for all items of a collection&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Design for Testability Patterns&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Pattern&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/dependency_injection.py&#34;&gt;dependency_injection&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;3 variants of dependency injection&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Fundamental Patterns&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Pattern&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/fundamental/delegation_pattern.py&#34;&gt;delegation_pattern&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;an object handles a request by delegating to a second object (the delegate)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Others&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Pattern&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/other/blackboard.py&#34;&gt;blackboard&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;architectural model, assemble different sub-system knowledge to build a solution, AI approach - non gang of four pattern&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/other/graph_search.py&#34;&gt;graph_search&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;graphing algorithms - non gang of four pattern&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/other/hsm/hsm.py&#34;&gt;hsm&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;hierarchical state machine - non gang of four pattern&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Videos&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=bsyjSW46TDg&#34;&gt;Design Patterns in Python by Peter Ullrich&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=G5OeYHCJuv0&#34;&gt;Sebastian BuczyÅ„ski - Why you don&#39;t need design patterns in Python?&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=imW-trt0i9I&#34;&gt;You Don&#39;t Need That!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=PfgEU3W0kyU&#34;&gt;Pluggable Libs Through Design Patterns&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;When an implementation is added or modified, please review the following guidelines:&lt;/p&gt; &#xA;&lt;h5&gt;Docstrings&lt;/h5&gt; &#xA;&lt;p&gt;Add module level description in form of a docstring with links to corresponding references or other useful information.&lt;/p&gt; &#xA;&lt;p&gt;Add &#34;Examples in Python ecosystem&#34; section if you know some. It shows how patterns could be applied to real-world problems.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/structural/facade.py&#34;&gt;facade.py&lt;/a&gt; has a good example of detailed description, but sometimes the shorter one as in &lt;a href=&#34;https://raw.githubusercontent.com/faif/python-patterns/master/patterns/behavioral/template.py&#34;&gt;template.py&lt;/a&gt; would suffice.&lt;/p&gt; &#xA;&lt;h5&gt;Python 2 compatibility&lt;/h5&gt; &#xA;&lt;p&gt;To see Python 2 compatible versions of some patterns please check-out the &lt;a href=&#34;https://github.com/faif/python-patterns/tree/legacy&#34;&gt;legacy&lt;/a&gt; tag.&lt;/p&gt; &#xA;&lt;h5&gt;Update README&lt;/h5&gt; &#xA;&lt;p&gt;When everything else is done - update corresponding part of README.&lt;/p&gt; &#xA;&lt;h5&gt;Travis CI&lt;/h5&gt; &#xA;&lt;p&gt;Please run &lt;code&gt;tox&lt;/code&gt; or &lt;code&gt;tox -e ci37&lt;/code&gt; before submitting a patch to be sure your changes will pass CI.&lt;/p&gt; &#xA;&lt;p&gt;You can also run &lt;code&gt;flake8&lt;/code&gt; or &lt;code&gt;pytest&lt;/code&gt; commands manually. Examples can be found in &lt;code&gt;tox.ini&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing via issue triage &lt;a href=&#34;https://www.codetriage.com/faif/python-patterns&#34;&gt;&lt;img src=&#34;https://www.codetriage.com/faif/python-patterns/badges/users.svg?sanitize=true&#34; alt=&#34;Open Source Helpers&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;You can triage issues and pull requests which may include reproducing bug reports or asking for vital information, such as version numbers or reproduction instructions. If you would like to start triaging issues, one easy way to get started is to &lt;a href=&#34;https://www.codetriage.com/faif/python-patterns&#34;&gt;subscribe to python-patterns on CodeTriage&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>github/copilot-docs</title>
    <updated>2022-06-05T02:04:37Z</updated>
    <id>tag:github.com,2022-06-05:/github/copilot-docs</id>
    <link href="https://github.com/github/copilot-docs" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Documentation for GitHub Copilot&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GitHub Copilot &lt;img src=&#34;https://img.shields.io/badge/version-technical_preview-green&#34; alt=&#34;Version&#34;&gt;&lt;/h1&gt; &#xA;&lt;img width=&#34;128&#34; alt=&#34;GitHub Copilot Logo&#34; src=&#34;https://user-images.githubusercontent.com/28068/123712981-02676c80-d839-11eb-919a-96ee0c895e15.png&#34;&gt; &#xA;&lt;p&gt;Welcome to the GitHub Copilot user community! In this repository, you can find documentation, walkthroughs, examples, and the latest resources you need to use GitHub Copilot.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To install GitHub Copilot, check out the Getting Started guides:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/github/copilot-docs/main/docs/visualstudiocode/gettingstarted.md#getting-started-with-github-copilot-in-visual-studio-code&#34;&gt;Visual Studio Code&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/github/copilot-docs/main/docs/visualstudio/gettingstarted.md#getting-started-with-github-copilot-in-visual-studio&#34;&gt;Visual Studio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/github/copilot-docs/main/docs/jetbrains/gettingstarted.md#getting-started-with-github-copilot-in-jetbrains&#34;&gt;JetBrains&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/github/copilot.vim#getting-started&#34;&gt;Neovim&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For a tour of GitHub Copilot, visit the homepage at &lt;a href=&#34;https://copilot.github.com&#34;&gt;copilot.github.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;How to get help&lt;/h2&gt; &#xA;&lt;p&gt;Have a question, or want to provide feedback? Visit the &lt;a href=&#34;https://github.com/github/feedback/discussions/categories/copilot-feedback&#34;&gt;Feedback forum&lt;/a&gt; to ask questions, share bugs or feedback, or chat with other users in the Preview. The GitHub Copilot team will respond as often as possible, but we also welcome you to share your experiences and help others in the community.&lt;/p&gt; &#xA;&lt;h2&gt;Safety&lt;/h2&gt; &#xA;&lt;p&gt;We take safety seriously and are constantly working to improve GitHub Copilot. If you discover dangerous, biased, or offensive output from GitHub Copilot, please report it privately to &lt;a href=&#34;mailto:copilot-safety@github.com&#34;&gt;copilot-safety@github.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Useful links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://copilot.github.com&#34;&gt;GitHub Copilot homepage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/github/copilot-docs/main/gallery&#34;&gt;Gallery&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/github/copilot-docs/main/docs&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/github/feedback/discussions/categories/copilot-feedback&#34;&gt;Feedback forum&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Code of conduct&lt;/h2&gt; &#xA;&lt;p&gt;All users of GitHub Copilot are expected to comply with our &lt;a href=&#34;https://raw.githubusercontent.com/github/copilot-docs/main/CODE_OF_CONDUCT.md&#34;&gt;Code of Conduct&lt;/a&gt;. By participating in this repository, you are also agreeing to the same &lt;a href=&#34;https://help.github.com/articles/github-terms-of-service/&#34;&gt;Terms of Service&lt;/a&gt; that you agree to when using GitHub.com.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Content in this repository is released under &lt;a href=&#34;https://raw.githubusercontent.com/github/copilot-docs/main/LICENSE.txt&#34;&gt;CC-BY-4.0&lt;/a&gt;. When using the GitHub logos, be sure to follow the &lt;a href=&#34;https://github.com/logos&#34;&gt;GitHub logo guidelines&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>