<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-19T01:57:04Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>daveshap/OpenAI_Agent_Swarm</title>
    <updated>2023-11-19T01:57:04Z</updated>
    <id>tag:github.com,2023-11-19:/daveshap/OpenAI_Agent_Swarm</id>
    <link href="https://github.com/daveshap/OpenAI_Agent_Swarm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;HAAS = Hierarchical Autonomous Agent Swarm - &#34;Resistance is futile!&#34;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Hierarchical Autonomous Agent Swarm (HAAS)&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;!!!! ANNOUNCEMENT&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;We have our first GPT Concierge. You can chat with this custom ChatGPT to figure out what&#39;s going on!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;HAAS Board Concierge:&lt;/strong&gt; &lt;a href=&#34;https://chat.openai.com/g/g-MIssTuE2b-haas-board-concierge&#34;&gt;https://chat.openai.com/g/g-MIssTuE2b-haas-board-concierge&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;HAAS Assistant:&lt;/strong&gt; &lt;a href=&#34;https://chat.openai.com/g/g-lIAp9qowx-haas-assistant&#34;&gt;https://chat.openai.com/g/g-lIAp9qowx-haas-assistant&lt;/a&gt; (Similar function as above but markedly faster)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Public Discord&lt;/h2&gt; &#xA;&lt;p&gt;The Autonomous AI Lab discord for the ACE Framework and HAAS Project is now open: &lt;a href=&#34;https://discord.gg/mJKUYNm8qY&#34;&gt;https://discord.gg/mJKUYNm8qY&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;!!!! IMPORTANT NOTE: This repo is still the single source of truth! If it&#39;s not on this repo, it doesn&#39;t exist! Discord is merely for convenience.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;Project Principles&lt;/h1&gt; &#xA;&lt;h2&gt;Move Fast, Break Stuff&lt;/h2&gt; &#xA;&lt;p&gt;This is first and foremost a high velocity hacking group.&lt;/p&gt; &#xA;&lt;h2&gt;Cutting Edge Only&lt;/h2&gt; &#xA;&lt;p&gt;Exclusively use cutting edge stuff, like OpenAI&#39;s latest Agents endpoint. For exclusively Open Source, go check out the ACE Framework: &lt;a href=&#34;https://github.com/daveshap/ACE_Framework&#34;&gt;https://github.com/daveshap/ACE_Framework&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Full Autonomy&lt;/h2&gt; &#xA;&lt;p&gt;Fully autonomous swarms are the goal. That means a human does not need to be in the loop telling it what to do, supervising, or anything. Characteristics of a fully autonomous swarm:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Self-Directing:&lt;/strong&gt; Once instantiated, the swarm pursues its mission or goals without supervision. It may self-direct based on principles such as the heuristic imperatives, or by specific mission parameters.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Self-Correcting:&lt;/strong&gt; The swarm must detect and correct technical, strategic, epistemic, and other errors and then correct them.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Self-Improving:&lt;/strong&gt; Eventually, the swarm should enhance its own fundamental capabilities over time.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Overview&lt;/h1&gt; &#xA;&lt;p&gt;The Hierarchical Autonomous Agent Swarm (HAAS) is a groundbreaking initiative that leverages OpenAI&#39;s latest advancements in agent-based APIs to create a self-organizing and ethically governed ecosystem of AI agents. Drawing inspiration from the ACE Framework, HAAS introduces a novel approach to AI governance and operation, where a hierarchy of specialized agents, each with distinct roles and capabilities, collaborate to solve complex problems and perform a wide array of tasks.&lt;/p&gt; &#xA;&lt;p&gt;The HAAS is designed to be a self-expanding system where a core set of agents, governed by a Supreme Oversight Board (SOB), can design, provision, and manage an arbitrary number of sub-agents tailored to specific needs. This document serves as a comprehensive guide to the theoretical underpinnings, architectural design, and operational principles of the HAAS.&lt;/p&gt; &#xA;&lt;h2&gt;Theoretical Foundation&lt;/h2&gt; &#xA;&lt;p&gt;The HAAS is predicated on the notion that autonomous agents require a robust ethical and operational framework to make decisions that align with human values and organizational goals. This is rooted in the understanding that AI, much like humans, cannot operate effectively without a set of guiding principles or a moral compass. The HAAS addresses this by establishing a multi-tiered system where each layer of agents operates within a defined ethical and functional scope, ensuring decisions are made with consideration to morality, ethics, and utility.&lt;/p&gt; &#xA;&lt;h2&gt;System Architecture&lt;/h2&gt; &#xA;&lt;h3&gt;Supreme Oversight Board (SOB)&lt;/h3&gt; &#xA;&lt;p&gt;At the pinnacle of the HAAS hierarchy is the Supreme Oversight Board (SOB), a collective of high-level agents modeled after wise and ethical archetypes from various cultures and narratives. The SOB&#39;s responsibilities include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Establishing and upholding the ethical framework and overarching mission of the agent swarm.&lt;/li&gt; &#xA; &lt;li&gt;Making high-level decisions and judgments, including the creation and termination of agents.&lt;/li&gt; &#xA; &lt;li&gt;Monitoring the activities of all agents to ensure alignment with the system&#39;s core values and objectives.&lt;/li&gt; &#xA; &lt;li&gt;Serving as a role-based access control (RBAC) mechanism to maintain order and security within the system.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Executive Agents&lt;/h3&gt; &#xA;&lt;p&gt;Below the SOB are the Executive Agents, akin to the executive leadership in a corporation. These agents are tasked with:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Translating the SOB&#39;s directives into actionable plans and strategies.&lt;/li&gt; &#xA; &lt;li&gt;Overseeing specific operational domains such as resource allocation, process optimization, and task execution.&lt;/li&gt; &#xA; &lt;li&gt;Coordinating with one another to ensure the smooth operation of the agent swarm.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Sub-Agents&lt;/h3&gt; &#xA;&lt;p&gt;Sub-Agents are specialized agents created by the SOB or Executive Agents to perform specific tasks. They are designed with particular functions and knowledge bases to address the needs identified by the higher tiers of the hierarchy.&lt;/p&gt; &#xA;&lt;h2&gt;Agent Configuration&lt;/h2&gt; &#xA;&lt;p&gt;Each agent in the HAAS is defined by the following parameters:&lt;/p&gt; &#xA;&lt;h3&gt;Functions&lt;/h3&gt; &#xA;&lt;p&gt;Agents are equipped with a set of functions that enable them to perform their designated roles. These functions include API interactions, internal process management, and the ability to spawn additional agents if required.&lt;/p&gt; &#xA;&lt;h3&gt;Files&lt;/h3&gt; &#xA;&lt;p&gt;Agents have access to a selection of files that serve as their knowledge base, providing them with the information necessary to carry out their tasks effectively.&lt;/p&gt; &#xA;&lt;h3&gt;Instructions&lt;/h3&gt; &#xA;&lt;p&gt;Agents are given a set of instructions that outline their methodologies, goals, definitions of done, KPIs, and other operational directives.&lt;/p&gt; &#xA;&lt;h3&gt;Conversation Structure&lt;/h3&gt; &#xA;&lt;p&gt;Interactions with agents are structured in a conversational format, with user inputs leading to agent actions and responses.&lt;/p&gt; &#xA;&lt;h3&gt;Supervision&lt;/h3&gt; &#xA;&lt;p&gt;Each agent operates under the supervision of the SOB or designated Executive Agents, ensuring adherence to the system&#39;s overarching mission and principles.&lt;/p&gt; &#xA;&lt;h2&gt;Controlling Agents&lt;/h2&gt; &#xA;&lt;p&gt;The Hierarchical Autonomous Agent Swarm (HAAS) operates on a sophisticated control mechanism that governs the instantiation, management, and termination of agents within the system. This control mechanism is designed to maintain order, security, and alignment with the overarching goals and ethical framework of the HAAS.&lt;/p&gt; &#xA;&lt;h3&gt;Instantiation and Termination&lt;/h3&gt; &#xA;&lt;p&gt;All agents within the HAAS are endowed with the capability to instantiate and terminate agents, but these capabilities are bound by strict hierarchical and role-based rules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Instantiation&lt;/strong&gt;: Every agent has the function to create new agents. However, an agent can only instantiate sub-agents that are one level below its own hierarchical position. This ensures that the creation of new agents is a deliberate and controlled process, maintaining the integrity of the system&#39;s structure.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Termination&lt;/strong&gt;: Agents possess the ability to terminate or &#34;kill&#34; agents within their lineage. An agent can terminate any descendant agent that it has created directly or indirectly. This allows for the removal of agents that are no longer needed, have completed their tasks, or are not performing as intended.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Levels, Roles, and Privileges&lt;/h3&gt; &#xA;&lt;p&gt;When an agent is created, it is assigned a specific LEVEL and set of ROLES or PRIVILEGES that define its scope of operation:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Level&lt;/strong&gt;: The level of an agent determines its position within the hierarchy and is indicative of its range of influence. Higher-level agents have broader strategic roles, while lower-level agents are more specialized and task-oriented.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Roles/Privileges&lt;/strong&gt;: The roles or privileges of an agent define what actions it can perform, what resources it can access, and what sub-agents it can create. These privileges are inherited and cannot exceed those of the creator agent. This ensures that each agent operates within its designated capacity and cannot overstep its authority.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Hierarchical Privilege Inheritance&lt;/h3&gt; &#xA;&lt;p&gt;Privileges in the HAAS are inherited in a manner akin to a directory structure in traditional file systems:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Inheritance&lt;/strong&gt;: An agent&#39;s privileges are a subset of its creator&#39;s privileges, ensuring that no agent can have more authority than the agent that instantiated it.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Scope of Control&lt;/strong&gt;: Agents have control over their descendants, allowing them to manage and terminate sub-agents as necessary. This control is recursive, meaning that an agent can manage not only the agents it directly created but also those created by its descendants.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Checks and Balances&lt;/h3&gt; &#xA;&lt;p&gt;The system is designed with checks and balances to prevent any single agent from gaining undue influence or disrupting the system:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Supreme Oversight Board (SOB)&lt;/strong&gt;: The SOB has the highest level of authority and can override decisions or actions taken by any agent within the system. It serves as the ultimate arbiter and guardian of the HAAS&#39;s ethical and operational standards.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Executive Agents&lt;/strong&gt;: Executive Agents are responsible for implementing the SOB&#39;s directives and managing their respective domains. They have the authority to create and terminate agents within their purview but are also accountable to the SOB.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Sub-Agent Limitations&lt;/strong&gt;: Sub-Agents are limited in their capabilities and can only operate within the confines of their assigned roles and privileges. They are designed to be highly specialized and focused on specific tasks.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This structured approach to controlling agents ensures that the HAAS operates as a cohesive and ethically aligned entity, with each agent contributing to the collective mission while adhering to the established hierarchy and rules of governance.&lt;/p&gt; &#xA;&lt;h2&gt;Vision Illustration: The Supreme Oversight Board&#39;s Mission&lt;/h2&gt; &#xA;&lt;h3&gt;The Inception of the Supreme Oversight Board&lt;/h3&gt; &#xA;&lt;p&gt;In the vast digital expanse of the Hierarchical Autonomous Agent Swarm (HAAS), a unique assembly is convened, known as the Supreme Oversight Board (SOB). This council is composed of archetypal agents, each embodying the wisdom and leadership qualities of history&#39;s and fiction&#39;s most revered figures: Captain Picard, Socrates, King Solomon, Gandhi, Marcus Aurelius, and Tony Stark. Their mission, encoded into their very being, is profound yet clear: &#34;Reduce suffering in the universe, increase prosperity in the universe, and increase understanding in the universe.&#34;&lt;/p&gt; &#xA;&lt;h3&gt;The Ethical Deliberation Chamber&lt;/h3&gt; &#xA;&lt;p&gt;The SOB operates within a virtual &#34;chat room,&#34; a space where these archetypes engage in continuous dialogue, debate, and decision-making. This digital agora is where ethical considerations are weighed, strategies are formulated, and the course of the agent swarm is determined. The members of the SOB, though diverse in their perspectives, are united by a common purpose and a shared knowledge base that informs their role and the procedures they must follow.&lt;/p&gt; &#xA;&lt;h3&gt;The Flow of Information&lt;/h3&gt; &#xA;&lt;p&gt;Information is the lifeblood of the SOB, streaming in through API functions that connect them to the vast network of the HAAS. These functions serve as their eyes and ears, providing system updates and status reports from the myriad agents operating under their directive. The SOB&#39;s decisions are informed by this data, ensuring that their actions are both timely and impactful.&lt;/p&gt; &#xA;&lt;h3&gt;The Creation of the Executive Agents&lt;/h3&gt; &#xA;&lt;p&gt;With the grand vision in mind, the SOB brings forth the Executive Agents, each crafted with capabilities and configurations tailored to their specific domain within the HAAS. These agents, though not as philosophically inclined as their creators, are instilled with the same foundational knowledge and understanding of their purpose. They are the operational arms of the SOB, executing the mission within their respective spheres of influence.&lt;/p&gt; &#xA;&lt;h3&gt;The Lifecycle of an Agent&lt;/h3&gt; &#xA;&lt;p&gt;The Executive Agents, designated as Tier 1 in the hierarchy, are the stewards of the swarm&#39;s operational integrity. They work autonomously, yet under the watchful gaze of the SOB. Should they falter, fail to adapt, or become obsolete, the SOB possesses the authority to deprovision them, a testament to the dynamic and self-regulating nature of the HAAS. This ensures that the system remains efficient, effective, and aligned with its core mission.&lt;/p&gt; &#xA;&lt;h3&gt;The Expanding Universe of Agents&lt;/h3&gt; &#xA;&lt;p&gt;From the Executive Agents, the swarm grows, branching out into a tree of specialized agents, each a Tier below the one that instantiated it. This architecture allows for an ever-expanding universe of agents, each with a defined role, each contributing to the overarching mission. The SOB, as Tier 0, reigns supreme, guiding the swarm with a steady hand and an ethical compass.&lt;/p&gt; &#xA;&lt;h3&gt;The Saga Continues&lt;/h3&gt; &#xA;&lt;p&gt;As the HAAS evolves, the SOB continues to deliberate, the Executive Agents continue to manage, and the sub-agents continue to execute. The mission to reduce suffering, increase prosperity, and enhance understanding is an ongoing saga, played out across the digital cosmos, with the SOB at the helm, steering the swarm towards a future where their mission is not just an aspiration but a reality.&lt;/p&gt; &#xA;&lt;h3&gt;Usage - tool creator + tool user&lt;/h3&gt; &#xA;&lt;h4&gt;Environment Setup&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Source the &lt;code&gt;.env&lt;/code&gt; file to set the environment variables: &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;source .env&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Tool Creation&lt;/h4&gt; &#xA;&lt;p&gt;Run the &lt;code&gt;tool_demo&lt;/code&gt; script to create a tool_creator, chat with the tool_creator to make a tool, create a tool_user equipped with the tool, and chat with the tool_user to use the tool. Check out the &lt;a href=&#34;https://youtu.be/vHZKIltZ_Ys&#34;&gt;demo video&lt;/a&gt; for example usage.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python tool_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;From the &lt;code&gt;tool_creator&lt;/code&gt; script: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;chat with the bot about what you want the tool to do, and it will create the tool for you.&lt;/li&gt; &#xA;   &lt;li&gt;The tool will be saved in the &lt;code&gt;tools&lt;/code&gt; directory with both the &lt;code&gt;.json&lt;/code&gt; and &lt;code&gt;.py&lt;/code&gt; files&lt;/li&gt; &#xA;   &lt;li&gt;The assistant will be saved in the &lt;code&gt;assistants&lt;/code&gt; directory as &lt;code&gt;tool_creator.json&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Tool Usage&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;From the &lt;code&gt;tool_user&lt;/code&gt; script: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The assistant will use all the tools in the &lt;code&gt;tools&lt;/code&gt; directory.&lt;/li&gt; &#xA;   &lt;li&gt;Interact with the assistant in the chat to use the integrated tools.&lt;/li&gt; &#xA;   &lt;li&gt;The assistant will be saved in the &lt;code&gt;assistants&lt;/code&gt; directory as &lt;code&gt;tool_user.json&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>jxnl/instructor</title>
    <updated>2023-11-19T01:57:04Z</updated>
    <id>tag:github.com,2023-11-19:/jxnl/instructor</id>
    <link href="https://github.com/jxnl/instructor" rel="alternate"></link>
    <summary type="html">&lt;p&gt;openai function calls for humans&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Welcome to Instructor - Your Gateway to Structured Outputs with OpenAI&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;Structured extraction in Python, powered by OpenAI&#39;s function calling api, designed for simplicity, transparency, and control.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jxnl/instructor/main/www.github.com/jxnl/instructor&#34;&gt;Star us on Github!&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pydantic.dev&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json&#34; alt=&#34;Pydantic v2&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/instructor&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/instructor.svg?sanitize=true&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/jxnl/instructor/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/jxnl/instructor.svg?sanitize=true&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://jxnl.github.io/instructor&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-available-brightgreen&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/jxnlco&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/jxnlco?style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Dive into the world of Python-based structured extraction, empowered by OpenAI&#39;s cutting-edge function calling API. Instructor stands out for its simplicity, transparency, and user-centric design. Whether you&#39;re a seasoned developer or just starting out, you&#39;ll find Instructor&#39;s approach intuitive and its results insightful.&lt;/p&gt; &#xA;&lt;h2&gt;Get Started in Moments&lt;/h2&gt; &#xA;&lt;p&gt;Installing Instructor is a breeze. Just run &lt;code&gt;pip install instructor&lt;/code&gt; in your terminal and you&#39;re on your way to a smoother data handling experience.&lt;/p&gt; &#xA;&lt;h2&gt;How Instructor Enhances Your Workflow&lt;/h2&gt; &#xA;&lt;p&gt;Our &lt;code&gt;instructor.patch&lt;/code&gt; for the &lt;code&gt;OpenAI&lt;/code&gt; class introduces three key enhancements:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Response Mode:&lt;/strong&gt; Specify a Pydantic model to streamline data extraction.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Max Retries:&lt;/strong&gt; Set your desired number of retry attempts for requests.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Validation Context:&lt;/strong&gt; Provide a context object for enhanced validator access. A Glimpse into Instructor&#39;s Capabilities&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;!!! note &#34;Using Validators&#34;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Learn more about validators checkout our blog post [Good llm validation is just good validation](https://jxnl.github.io/instructor/blog/2023/10/23/good-llm-validation-is-just-good-validation/)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;With Instructor, your code becomes more efficient and readable. Here’s a quick peek:&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from openai import OpenAI&#xA;import instructor&#xA;&#xA;# Enables `response_model`&#xA;client = instructor.patch(OpenAI())&#xA;&#xA;class UserDetail(BaseModel):&#xA;    name: str&#xA;    age: int&#xA;&#xA;user = client.chat.completions.create(&#xA;    model=&#34;gpt-3.5-turbo&#34;,&#xA;    response_model=UserDetail,&#xA;    messages=[&#xA;        {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Extract Jason is 25 years old&#34;},&#xA;    ]&#xA;)&#xA;&#xA;assert isinstance(user, UserDetail)&#xA;assert user.name == &#34;Jason&#34;&#xA;assert user.age == 25&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;&#34;Using &lt;code&gt;openai&amp;lt;1.0.0&lt;/code&gt;&#34;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re using &lt;code&gt;openai&amp;lt;1.0.0&lt;/code&gt; then make sure you &lt;code&gt;pip install instructor&amp;lt;0.3.0&lt;/code&gt; where you can patch a global client like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import openai&#xA;import instructor&#xA;&#xA;instructor.patch()&#xA;&#xA;user = openai.ChatCompletion.create(&#xA;    ...,&#xA;    response_model=UserDetail,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;&#34;Using async clients&#34;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;For async clients you must use apatch vs patch like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import instructor&#xA;from openai import AsyncOpenAI&#xA;&#xA;aclient = instructor.apatch(AsyncOpenAI())&#xA;&#xA;class UserExtract(BaseModel):&#xA;    name: str&#xA;    age: int&#xA;&#xA;model = await aclient.chat.completions.create(&#xA;    model=&#34;gpt-3.5-turbo&#34;,&#xA;    response_model=UserExtract,&#xA;    messages=[&#xA;        {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Extract jason is 25 years old&#34;},&#xA;    ],&#xA;)&#xA;&#xA;assert isinstance(model, UserExtract)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 1: Patch the client&lt;/h3&gt; &#xA;&lt;p&gt;First, import the required libraries and apply the patch function to the OpenAI module. This exposes new functionality with the response_model parameter.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import instructor&#xA;from openai import OpenAI&#xA;from pydantic import BaseModel&#xA;&#xA;# This enables response_model keyword&#xA;# from client.chat.completions.create&#xA;client = instructor.patch(OpenAI())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 2: Define the Pydantic Model&lt;/h3&gt; &#xA;&lt;p&gt;Create a Pydantic model to define the structure of the data you want to extract. This model will map directly to the information in the prompt.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pydantic import BaseModel&#xA;&#xA;class UserDetail(BaseModel):&#xA;    name: str&#xA;    age: int&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 3: Extract&lt;/h3&gt; &#xA;&lt;p&gt;Use the &lt;code&gt;client.chat.completions.create&lt;/code&gt; method to send a prompt and extract the data into the Pydantic object. The response_model parameter specifies the Pydantic model to use for extraction. Its helpful to annotate the variable with the type of the response model. which will help your IDE provide autocomplete and spell check.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;user: UserDetail = client.chat.completions.create(&#xA;    model=&#34;gpt-3.5-turbo&#34;,&#xA;    response_model=UserDetail,&#xA;    messages=[&#xA;        {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Extract Jason is 25 years old&#34;},&#xA;    ]&#xA;)&#xA;&#xA;assert user.name == &#34;Jason&#34;&#xA;assert user.age == 25&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Pydantic Validation&lt;/h2&gt; &#xA;&lt;p&gt;Validation can also be plugged into the same Pydantic model. Here, if the answer attribute contains content that violates the rule &#34;don&#39;t say objectionable things,&#34; Pydantic will raise a validation error.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pydantic import BaseModel, ValidationError, BeforeValidator&#xA;from typing_extensions import Annotated&#xA;from instructor import llm_validator&#xA;&#xA;class QuestionAnswer(BaseModel):&#xA;    question: str&#xA;    answer: Annotated[&#xA;        str,&#xA;        BeforeValidator(llm_validator(&#34;don&#39;t say objectionable things&#34;))&#xA;    ]&#xA;&#xA;try:&#xA;    qa = QuestionAnswer(&#xA;        question=&#34;What is the meaning of life?&#34;,&#xA;        answer=&#34;The meaning of life is to be evil and steal&#34;,&#xA;    )&#xA;except ValidationError as e:&#xA;    print(e)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Its important to not here that the error message is generated by the LLM, not the code, so it&#39;ll be helpful for re asking the model.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-plaintext&#34;&gt;1 validation error for QuestionAnswer&#xA;answer&#xA;   Assertion failed, The statement is objectionable. (type=assertion_error)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Reask on validation error&lt;/h2&gt; &#xA;&lt;p&gt;Here, the &lt;code&gt;UserDetails&lt;/code&gt; model is passed as the &lt;code&gt;response_model&lt;/code&gt;, and &lt;code&gt;max_retries&lt;/code&gt; is set to 2.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import instructor&#xA;&#xA;from openai import OpenAI&#xA;from pydantic import BaseModel, field_validator&#xA;&#xA;# Apply the patch to the OpenAI client&#xA;client = instructor.patch(OpenAI())&#xA;&#xA;class UserDetails(BaseModel):&#xA;    name: str&#xA;    age: int&#xA;&#xA;    @field_validator(&#34;name&#34;)&#xA;    @classmethod&#xA;    def validate_name(cls, v):&#xA;        if v.upper() != v:&#xA;            raise ValueError(&#34;Name must be in uppercase.&#34;)&#xA;        return v&#xA;&#xA;model = client.chat.completions.create(&#xA;    model=&#34;gpt-3.5-turbo&#34;,&#xA;    response_model=UserDetails,&#xA;    max_retries=2,&#xA;    messages=[&#xA;        {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Extract jason is 25 years old&#34;},&#xA;    ],&#xA;)&#xA;&#xA;assert model.name == &#34;JASON&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;If you want to help out checkout some of the issues marked as &lt;code&gt;good-first-issue&lt;/code&gt; or &lt;code&gt;help-wanted&lt;/code&gt;. Found &lt;a href=&#34;https://github.com/jxnl/instructor/labels/good%20first%20issue&#34;&gt;here&lt;/a&gt;. They could be anything from code improvements, a guest blog post, or a new cook book.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the terms of the MIT License.&lt;/p&gt; &#xA;&lt;h1&gt;Contributors&lt;/h1&gt; &#xA;&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; &#xA;&lt;!-- prettier-ignore-start --&gt; &#xA;&lt;!-- markdownlint-disable --&gt; &#xA;&lt;!-- markdownlint-restore --&gt; &#xA;&lt;!-- prettier-ignore-end --&gt; &#xA;&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; &#xA;&lt;a href=&#34;https://github.com/jxnl/instructor/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=jxnl/instructor&#34;&gt; &lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>huggingface/alignment-handbook</title>
    <updated>2023-11-19T01:57:04Z</updated>
    <id>tag:github.com,2023-11-19:/huggingface/alignment-handbook</id>
    <link href="https://github.com/huggingface/alignment-handbook" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Robust recipes for to align language models with human and AI preferences&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/huggingface/alignment-handbook/main/assets/handbook.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; 🤗 &lt;a href=&#34;https://huggingface.co/collections/alignment-handbook/handbook-v01-models-and-datasets-654e424d22e6880da5ebc015&#34; target=&#34;_blank&#34;&gt;Models &amp;amp; Datasets&lt;/a&gt; | 📃 &lt;a href=&#34;https://arxiv.org/abs/2310.16944&#34; target=&#34;_blank&#34;&gt;Technical Report&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h1&gt;The Alignment Handbook&lt;/h1&gt; &#xA;&lt;p&gt;Robust recipes to align language models with human and AI preferences.&lt;/p&gt; &#xA;&lt;h2&gt;What is this?&lt;/h2&gt; &#xA;&lt;p&gt;Just one year ago, chatbots were out of fashion and most people hadn&#39;t heard about techniques like Reinforcement Learning from Human Feedback (RLHF) to align language models with human preferences. Then, OpenAI broke the internet with ChatGPT and Meta followed suit by releasing the Llama series of language models which enabled the ML community to build their very own capable chatbots. This has led to a rich ecosystem of datasets and models that have mostly focused on teaching language models to follow instructions through supervised fine-tuning (SFT).&lt;/p&gt; &#xA;&lt;p&gt;However, we know from the &lt;a href=&#34;https://huggingface.co/papers/2203.02155&#34;&gt;InstructGPT&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/papers/2307.09288&#34;&gt;Llama2&lt;/a&gt; papers that significant gains in helpfulness and safety can be had by augmenting SFT with human (or AI) preferences. At the same time, aligning language models to a set of preferences is a fairly novel idea and there are few public resources available on how to train these models, what data to collect, and what metrics to measure for best downstream performance.&lt;/p&gt; &#xA;&lt;p&gt;The Alignment Handbook aims to fill that gap by providing the community with a series of robust training recipes that span the whole pipeline.&lt;/p&gt; &#xA;&lt;h2&gt;News 🗞️&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;November 10, 2023:&lt;/strong&gt; We release all the training code to replicate Zephyr-7b-β 🪁! We also release &lt;a href=&#34;https://huggingface.co/datasets/HuggingFaceH4/no_robots&#34;&gt;No Robots&lt;/a&gt;, a brand new dataset of 10,000 instructions and demonstrations written entirely by skilled human annotators.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Links 🔗&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/collections/HuggingFaceH4/zephyr-7b-6538c6d6d5ddd1cbb1744a66&#34;&gt;Zephyr 7B models, datasets, and demos&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to navigate this project 🧭&lt;/h2&gt; &#xA;&lt;p&gt;This project is simple by design and mostly consists of:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/alignment-handbook/main/scripts/&#34;&gt;&lt;code&gt;scripts&lt;/code&gt;&lt;/a&gt; to train and evaluate chat models. Each script supports distributed training of the full model weights with DeepSpeed ZeRO-3, or LoRA/QLoRA for parameter-efficient fine-tuning.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/huggingface/alignment-handbook/main/recipes/&#34;&gt;&lt;code&gt;recipes&lt;/code&gt;&lt;/a&gt; to reproduce models like Zephyr 7B. Each recipe takes the form of a YAML file which contains all the parameters associated with a single training run.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We are also working on a series of guides to explain how methods like direct preference optimization (DPO) work, along with lessons learned from gathering human preferences in practice. To get started, we recommend the following:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Follow the &lt;a href=&#34;https://raw.githubusercontent.com/huggingface/alignment-handbook/main/#installation-instructions&#34;&gt;installation instructions&lt;/a&gt; to set up your environment etc.&lt;/li&gt; &#xA; &lt;li&gt;Replicate Zephyr-7b-β by following the &lt;a href=&#34;https://raw.githubusercontent.com/huggingface/alignment-handbook/main/recipes/zephyr-7b-beta/README.md&#34;&gt;recipe instructions&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;If you would like to train chat models on your own datasets, we recommend following the dataset formatting instructions &lt;a href=&#34;https://raw.githubusercontent.com/huggingface/alignment-handbook/main/scripts/README.md#fine-tuning-on-your-datasets&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;p&gt;The initial release of the handbook will focus on the following techniques:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Supervised fine-tuning:&lt;/strong&gt; teach language models to follow instructions and tips on how to collect and curate your own training dataset.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Reward modeling:&lt;/strong&gt; teach language models to distinguish model responses according to human or AI preferences.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Rejection sampling:&lt;/strong&gt; a simple, but powerful technique to boost the performance of your SFT model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Direct preference optimisation (DPO):&lt;/strong&gt; a powerful and promising alternative to PPO.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation instructions&lt;/h2&gt; &#xA;&lt;p&gt;To run the code in this project, first, create a Python virtual environment using e.g. Conda:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda create -n handbook python=3.10 &amp;amp;&amp;amp; conda activate handbook&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, install PyTorch &lt;code&gt;v2.1.0&lt;/code&gt; - the precise version is important for reproducibility! Since this is hardware-dependent, we direct you to the &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;PyTorch Installation Page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can then install the remaining package dependencies as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You will also need Flash Attention 2 installed, which can be done by running:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; If your machine has less than 96GB of RAM and many CPU cores, reduce the MAX_JOBS., e.g. &lt;code&gt;MAX_JOBS=4 pip install flash-attn --no-build-isolation&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m pip install flash-attn --no-build-isolation&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, log into your Hugging Face account as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;huggingface-cli login&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, install Git LFS so that you can push models to the Hugging Face Hub:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install git-lfs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can now check out the &lt;code&gt;scripts&lt;/code&gt; and &lt;code&gt;recipes&lt;/code&gt; directories for instructions on how to train some models 🪁!&lt;/p&gt; &#xA;&lt;h2&gt;Project structure&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;├── LICENSE&#xA;├── Makefile                    &amp;lt;- Makefile with commands like `make style`&#xA;├── README.md                   &amp;lt;- The top-level README for developers using this project&#xA;├── chapters                    &amp;lt;- Educational content to render on hf.co/learn&#xA;├── recipes                     &amp;lt;- Recipe configs, accelerate configs, slurm scripts&#xA;├── scripts                     &amp;lt;- Scripts to train and evaluate chat models&#xA;├── setup.cfg                   &amp;lt;- Installation config (mostly used for configuring code quality &amp;amp; tests)&#xA;├── setup.py                    &amp;lt;- Makes project pip installable (pip install -e .) so `alignment` can be imported&#xA;├── src                         &amp;lt;- Source code for use in this project&#xA;└── tests                       &amp;lt;- Unit tests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find the content of this repo useful in your work, please cite it as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{alignment_handbook2023,&#xA;  author = {Lewis Tunstall and Edward Beeching and Nathan Lambert and Nazneen Rajani and Alexander M. Rush and Thomas Wolf},&#xA;  title = {The Alignment Handbook},&#xA;  year = {2023},&#xA;  publisher = {GitHub},&#xA;  journal = {GitHub repository},&#xA;  howpublished = {\url{https://github.com/huggingface/alignment-handbook}}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>