<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-10-29T02:00:02Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>cpacker/MemGPT</title>
    <updated>2023-10-29T02:00:02Z</updated>
    <id>tag:github.com,2023-10-29:/cpacker/MemGPT</id>
    <link href="https://github.com/cpacker/MemGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Teaching LLMs memory management for unbounded context üìöü¶ô&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cpacker/MemGPT/main/#user-content-memgpt&#34;&gt;&lt;img src=&#34;https://memgpt.ai/assets/img/memgpt_logo_circle.png&#34; alt=&#34;MemGPT logo&#34; width=&#34;75&#34; align=&#34;right&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://memgpt.ai&#34;&gt;MemGPT&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;strong&gt;Try out our MemGPT chatbot on &lt;a href=&#34;https://discord.gg/9GEQrxmVyE&#34;&gt;Discord&lt;/a&gt;!&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;‚≠ê NEW: You can now run MemGPT with &lt;a href=&#34;https://github.com/cpacker/MemGPT/discussions/67&#34;&gt;local LLMs&lt;/a&gt; and &lt;a href=&#34;https://github.com/cpacker/MemGPT/discussions/65&#34;&gt;AutoGen&lt;/a&gt;! ‚≠ê &lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://discord.gg/9GEQrxmVyE&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1161736243340640419?label=Discord&amp;amp;logo=discord&amp;amp;logoColor=5865F2&amp;amp;style=flat-square&amp;amp;color=5865F2&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2310.08560&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2310.08560-B31B1B?logo=arxiv&amp;amp;style=flat-square&#34; alt=&#34;arXiv 2310.08560&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;&lt;h2&gt;ü§ñ Create perpetual chatbots with self-editing memory!&lt;/h2&gt;&lt;/summary&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;br&gt; &#xA;  &lt;img src=&#34;https://memgpt.ai/assets/img/demo.gif&#34; alt=&#34;MemGPT demo video&#34; width=&#34;800&#34;&gt; &#xA; &lt;/div&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;h2&gt;üóÉÔ∏è Chat with your data - talk to your SQL database or your local files!&lt;/h2&gt;&lt;/summary&gt; &#xA; &lt;strong&gt;SQL Database&lt;/strong&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://memgpt.ai/assets/img/sql_demo.gif&#34; alt=&#34;MemGPT demo video for sql search&#34; width=&#34;800&#34;&gt; &#xA; &lt;/div&gt; &#xA; &lt;strong&gt;Local files&lt;/strong&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://memgpt.ai/assets/img/preload_archival_demo.gif&#34; alt=&#34;MemGPT demo video for sql search&#34; width=&#34;800&#34;&gt; &#xA; &lt;/div&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;h2&gt;üìÑ You can also talk to docs - for example ask about &lt;a href=&#34;https://raw.githubusercontent.com/cpacker/MemGPT/main/memgpt/personas/examples/docqa&#34;&gt;LlamaIndex&lt;/a&gt;!&lt;/h2&gt;&lt;/summary&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://memgpt.ai/assets/img/docqa_demo.gif&#34; alt=&#34;MemGPT demo video for llamaindex api docs search&#34; width=&#34;800&#34;&gt; &#xA; &lt;/div&gt; &#xA; &lt;details&gt; &#xA;  &lt;summary&gt;&lt;b&gt;ChatGPT (GPT-4) when asked the same question:&lt;/b&gt;&lt;/summary&gt; &#xA;  &lt;div align=&#34;center&#34;&gt; &#xA;   &lt;img src=&#34;https://memgpt.ai/assets/img/llama_index_gpt4.png&#34; alt=&#34;GPT-4 when asked about llamaindex api docs&#34; width=&#34;800&#34;&gt; &#xA;  &lt;/div&gt; (Question from https://github.com/run-llama/llama_index/issues/7756) &#xA; &lt;/details&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Quick setup&lt;/h2&gt; &#xA;&lt;p&gt;Join &lt;a href=&#34;https://discord.gg/9GEQrxmVyE&#34;&gt;Discord&lt;/a&gt; and message the MemGPT bot (in the &lt;code&gt;#memgpt&lt;/code&gt; channel). Then run the following commands (messaged to &#34;MemGPT Bot&#34;):&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;/profile&lt;/code&gt; (to create your profile)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/key&lt;/code&gt; (to enter your OpenAI key)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/create&lt;/code&gt; (to create a MemGPT chatbot)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Make sure your privacy settings on this server are open so that MemGPT Bot can DM you: &lt;br&gt; MemGPT ‚Üí Privacy Settings ‚Üí Direct Messages set to ON&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://memgpt.ai/assets/img/discord/dm_settings.png&#34; alt=&#34;set DMs settings on MemGPT server to be open in MemGPT so that MemGPT Bot can message you&#34; width=&#34;400&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;You can see the full list of available commands when you enter &lt;code&gt;/&lt;/code&gt; into the message box.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://memgpt.ai/assets/img/discord/slash_commands.png&#34; alt=&#34;MemGPT Bot slash commands&#34; width=&#34;400&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;What is MemGPT?&lt;/h2&gt; &#xA;&lt;p&gt;Memory-GPT (or MemGPT in short) is a system that intelligently manages different memory tiers in LLMs in order to effectively provide extended context within the LLM&#39;s limited context window. For example, MemGPT knows when to push critical information to a vector database and when to retrieve it later in the chat, enabling perpetual conversations. Learn more about MemGPT in our &lt;a href=&#34;https://arxiv.org/abs/2310.08560&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Running MemGPT locally&lt;/h2&gt; &#xA;&lt;p&gt;Install MemGPT:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install pymemgpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To update the package, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install pymemgpt -U&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Add your OpenAI API key to your environment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# on Linux/Mac&#xA;export OPENAI_API_KEY=YOUR_API_KEY&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# on Windows&#xA;set OPENAI_API_KEY=YOUR_API_KEY&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# on Windows (PowerShell)&#xA;$Env:OPENAI_API_KEY = &#34;YOUR_API_KEY&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run MemGPT for as a conversation agent in CLI mode, simply run &lt;code&gt;memgpt&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;memgpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;Debugging command not found&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;p&gt;If you get &lt;code&gt;command not found&lt;/code&gt; (Linux/MacOS), or a &lt;code&gt;CommandNotFoundException&lt;/code&gt; (Windows), the directory where pip installs scripts is not in your PATH. You can either add that directory to your path (&lt;code&gt;pip show pip | grep Scripts&lt;/code&gt;) or instead just run:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python -m memgpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;strong&gt;Building from source&lt;/strong&gt;&lt;/summary&gt; &#xA; &lt;p&gt;Clone this repo: &lt;code&gt;git clone https://github.com/cpacker/MemGPT.git&lt;/code&gt;&lt;/p&gt; &#xA; &lt;p&gt;Using poetry:&lt;/p&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Install poetry: &lt;code&gt;pip install poetry&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Run &lt;code&gt;poetry install&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Run &lt;code&gt;poetry run memgpt&lt;/code&gt;&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;p&gt;Using pip:&lt;/p&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Run &lt;code&gt;pip install -e .&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Run &lt;code&gt;python3 main.py&lt;/code&gt;&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;If you&#39;re using Azure OpenAI, set these variables instead:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# see https://github.com/openai/openai-python#microsoft-azure-endpoints&#xA;export AZURE_OPENAI_KEY = ...&#xA;export AZURE_OPENAI_ENDPOINT = ...&#xA;export AZURE_OPENAI_VERSION = ...&#xA;&#xA;# set the below if you are using deployment ids&#xA;export AZURE_OPENAI_DEPLOYMENT = ...&#xA;export AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT = ...&#xA;&#xA;# then use the --use_azure_openai flag&#xA;memgpt --use_azure_openai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To create a new starter user or starter persona (that MemGPT gets initialized with), create a new &lt;code&gt;.txt&lt;/code&gt; file in &lt;code&gt;~/.memgpt/humans&lt;/code&gt; or &lt;code&gt;~/.memgpt/personas&lt;/code&gt;, then use the &lt;code&gt;--persona&lt;/code&gt; or &lt;code&gt;--human&lt;/code&gt; flag when running &lt;code&gt;main.py&lt;/code&gt;. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# assuming you created a new file ~/.memgpt/humans/me.txt&#xA;memgpt&#xA;# Select me.txt during configuration process&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;-- OR --&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# assuming you created a new file ~/.memgpt/humans/me.txt&#xA;memgpt --human me.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also specify any of the starter users in &lt;a href=&#34;https://raw.githubusercontent.com/cpacker/MemGPT/main/memgpt/humans/examples&#34;&gt;/memgpt/humans/examples&lt;/a&gt; or any of the starter personas in &lt;a href=&#34;https://raw.githubusercontent.com/cpacker/MemGPT/main/memgpt/personas/examples&#34;&gt;/memgpt/personas/examples&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;GPT-3.5 support&lt;/h3&gt; &#xA;&lt;p&gt;You can run MemGPT with GPT-3.5 as the LLM instead of GPT-4:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;memgpt&#xA;# Select gpt-3.5 during configuration process&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;-- OR --&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;memgpt --model gpt-3.5-turbo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note that this is experimental gpt-3.5-turbo support. It&#39;s quite buggy compared to gpt-4, but it should be runnable.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Please report any bugs you encounter regarding MemGPT running on GPT-3.5 to &lt;a href=&#34;https://github.com/cpacker/MemGPT/issues/59&#34;&gt;https://github.com/cpacker/MemGPT/issues/59&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Local LLM support&lt;/h3&gt; &#xA;&lt;p&gt;You can run MemGPT with local LLMs too. See &lt;a href=&#34;https://raw.githubusercontent.com/cpacker/MemGPT/main/memgpt/local_llm&#34;&gt;instructions here&lt;/a&gt; and report any bugs/improvements here &lt;a href=&#34;https://github.com/cpacker/MemGPT/discussions/67&#34;&gt;https://github.com/cpacker/MemGPT/discussions/67&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;main.py&lt;/code&gt; flags&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;--first&#xA;  allows you to send the first message in the chat (by default, MemGPT will send the first message)&#xA;--debug&#xA;  enables debugging output&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Configure via legacy flags&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;--model&#xA;  select which model to use (&#39;gpt-4&#39;, &#39;gpt-3.5-turbo-0613&#39;, &#39;gpt-3.5-turbo&#39;)&#xA;--persona&#xA;  load a specific persona file&#xA;--human&#xA;  load a specific human file&#xA;--archival_storage_faiss_path=&amp;lt;ARCHIVAL_STORAGE_FAISS_PATH&amp;gt;&#xA;  load in document database (backed by FAISS index)&#xA;--archival_storage_files=&#34;&amp;lt;ARCHIVAL_STORAGE_FILES_GLOB_PATTERN&amp;gt;&#34;&#xA;  pre-load files into archival memory&#xA;--archival_storage_files_compute_embeddings=&#34;&amp;lt;ARCHIVAL_STORAGE_FILES_GLOB_PATTERN&amp;gt;&#34;&#xA;  pre-load files into archival memory and also compute embeddings for embedding search&#xA;--archival_storage_sqldb=&amp;lt;SQLDB_PATH&amp;gt;&#xA;  load in SQL database&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Interactive CLI commands&lt;/h3&gt; &#xA;&lt;p&gt;These are the commands for the CLI, &lt;strong&gt;not the Discord bot&lt;/strong&gt;! The Discord bot has separate commands you can see in Discord by typing &lt;code&gt;/&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;While using MemGPT via the CLI (not Discord!) you can run various commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;//&#xA;  toggle multiline input mode&#xA;/exit&#xA;  exit the CLI&#xA;/save&#xA;  save a checkpoint of the current agent/conversation state&#xA;/load&#xA;  load a saved checkpoint&#xA;/dump&#xA;  view the current message log (see the contents of main context)&#xA;/memory&#xA;  print the current contents of agent memory&#xA;/pop&#xA;  undo the last message in the conversation&#xA;/heartbeat&#xA;  send a heartbeat system message to the agent&#xA;/memorywarning&#xA;  send a memory warning system message to the agent&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Example applications&lt;/h2&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;&lt;h3&gt;Use MemGPT to talk to your Database!&lt;/h3&gt;&lt;/summary&gt; &#xA; &lt;p&gt;MemGPT&#39;s archival memory let&#39;s you load your database and talk to it! To motivate this use-case, we have included a toy example.&lt;/p&gt; &#xA; &lt;p&gt;Consider the &lt;code&gt;test.db&lt;/code&gt; already included in the repository.&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;id&lt;/th&gt; &#xA;    &lt;th&gt;name&lt;/th&gt; &#xA;    &lt;th&gt;age&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;1&lt;/td&gt; &#xA;    &lt;td&gt;Alice&lt;/td&gt; &#xA;    &lt;td&gt;30&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;2&lt;/td&gt; &#xA;    &lt;td&gt;Bob&lt;/td&gt; &#xA;    &lt;td&gt;25&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;3&lt;/td&gt; &#xA;    &lt;td&gt;Charlie&lt;/td&gt; &#xA;    &lt;td&gt;35&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;p&gt;To talk to this database, run:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;memgpt --archival_storage_sqldb=memgpt/personas/examples/sqldb/test.db&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;And then you can input the path to your database, and your query.&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Please enter the path to the database. test.db&#xA;...&#xA;Enter your message: How old is Bob?&#xA;...&#xA;ü§ñ Bob is 25 years old.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;h3&gt;Loading local files into archival memory&lt;/h3&gt;&lt;/summary&gt; MemGPT enables you to chat with your data locally -- this example gives the workflow for loading documents into MemGPT&#39;s archival memory. &#xA; &lt;p&gt;To run our example where you can search over the SEC 10-K filings of Uber, Lyft, and Airbnb,&lt;/p&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt; &lt;p&gt;Download the .txt files from &lt;a href=&#34;https://huggingface.co/datasets/MemGPT/example-sec-filings/tree/main&#34;&gt;Hugging Face&lt;/a&gt; and place them in &lt;code&gt;memgpt/personas/examples/preload_archival&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;In the root &lt;code&gt;MemGPT&lt;/code&gt; directory, run&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;memgpt --archival_storage_files=&#34;memgpt/personas/examples/preload_archival/*.txt&#34; --persona=memgpt_doc --human=basic&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;p&gt;If you would like to load your own local files into MemGPT&#39;s archival memory, run the command above but replace &lt;code&gt;--archival_storage_files=&#34;memgpt/personas/examples/preload_archival/*.txt&#34;&lt;/code&gt; with your own file glob expression (enclosed in quotes).&lt;/p&gt; &#xA; &lt;h4&gt;Enhance with embeddings search&lt;/h4&gt; &#xA; &lt;p&gt;In the root &lt;code&gt;MemGPT&lt;/code&gt; directory, run&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;memgpt main.py --archival_storage_files_compute_embeddings=&#34;&amp;lt;GLOB_PATTERN&amp;gt;&#34; --persona=memgpt_doc --human=basic&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;This will generate embeddings, stick them into a FAISS index, and write the index to a directory, and then output:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;  To avoid computing embeddings next time, replace --archival_storage_files_compute_embeddings=&amp;lt;GLOB_PATTERN&amp;gt; with&#xA;    --archival_storage_faiss_path=&amp;lt;DIRECTORY_WITH_EMBEDDINGS&amp;gt; (if your files haven&#39;t changed).&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;If you want to reuse these embeddings, run&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;memgpt --archival_storage_faiss_path=&#34;&amp;lt;DIRECTORY_WITH_EMBEDDINGS&amp;gt;&#34; --persona=memgpt_doc --human=basic&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;h3&gt;Talking to LlamaIndex API Docs&lt;/h3&gt;&lt;/summary&gt; &#xA; &lt;p&gt;MemGPT also enables you to chat with docs -- try running this example to talk to the LlamaIndex API docs!&lt;/p&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt; &lt;p&gt;a. Download LlamaIndex API docs and FAISS index from &lt;a href=&#34;https://huggingface.co/datasets/MemGPT/llamaindex-api-docs&#34;&gt;Hugging Face&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Make sure you have git-lfs installed (https://git-lfs.com)&#xA;git lfs install&#xA;git clone https://huggingface.co/datasets/MemGPT/llamaindex-api-docs&#xA;mv llamaindex-api-docs&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;-- OR --&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;b. Build the index:&lt;/p&gt; &#xA;   &lt;ol&gt; &#xA;    &lt;li&gt;Build &lt;code&gt;llama_index&lt;/code&gt; API docs with &lt;code&gt;make text&lt;/code&gt;. Instructions &lt;a href=&#34;https://github.com/run-llama/llama_index/raw/main/docs/DOCS_README.md&#34;&gt;here&lt;/a&gt;. Copy over the generated &lt;code&gt;_build/text&lt;/code&gt; folder to &lt;code&gt;memgpt/personas/docqa&lt;/code&gt;.&lt;/li&gt; &#xA;    &lt;li&gt;Generate embeddings and FAISS index. &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd memgpt/personas/docqa&#xA;python3 scrape_docs.py&#xA;python3 generate_embeddings_for_docs.py all_docs.jsonl&#xA;python3 build_index.py --embedding_files all_docs.embeddings.jsonl --output_index_file all_docs.index&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;/ol&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;In the root &lt;code&gt;MemGPT&lt;/code&gt; directory, run&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;memgpt --archival_storage_faiss_path=&amp;lt;ARCHIVAL_STORAGE_FAISS_PATH&amp;gt; --persona=memgpt_doc --human=basic&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;where &lt;code&gt;ARCHIVAL_STORAGE_FAISS_PATH&lt;/code&gt; is the directory where &lt;code&gt;all_docs.jsonl&lt;/code&gt; and &lt;code&gt;all_docs.index&lt;/code&gt; are located. If you downloaded from Hugging Face, it will be &lt;code&gt;memgpt/personas/docqa/llamaindex-api-docs&lt;/code&gt;. If you built the index yourself, it will be &lt;code&gt;memgpt/personas/docqa&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ol&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;If you have any further questions, or have anything to share, we are excited to hear your feedback!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;By default MemGPT will use &lt;code&gt;gpt-4&lt;/code&gt;, so your API key will require &lt;code&gt;gpt-4&lt;/code&gt; API access&lt;/li&gt; &#xA; &lt;li&gt;For issues and feature requests, please &lt;a href=&#34;https://github.com/cpacker/MemGPT/issues&#34;&gt;open a GitHub issue&lt;/a&gt; or message us on our &lt;code&gt;#support&lt;/code&gt; channel on &lt;a href=&#34;https://discord.gg/9GEQrxmVyE&#34;&gt;Discord&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Datasets&lt;/h2&gt; &#xA;&lt;p&gt;Datasets used in our &lt;a href=&#34;https://arxiv.org/abs/2310.08560&#34;&gt;paper&lt;/a&gt; can be downloaded at &lt;a href=&#34;https://huggingface.co/MemGPT&#34;&gt;Hugging Face&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Project Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Release MemGPT Discord bot demo (perpetual chatbot)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add additional workflows (load SQL/text into MemGPT external context)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Integration tests&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Integrate with AutoGen (&lt;a href=&#34;https://github.com/cpacker/MemGPT/discussions/65&#34;&gt;discussion&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add official gpt-3.5-turbo support (&lt;a href=&#34;https://github.com/cpacker/MemGPT/discussions/66&#34;&gt;discussion&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; CLI UI improvements (&lt;a href=&#34;https://github.com/cpacker/MemGPT/issues/11&#34;&gt;issue&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add support for other LLM backends (&lt;a href=&#34;https://github.com/cpacker/MemGPT/issues/18&#34;&gt;issue&lt;/a&gt;, &lt;a href=&#34;https://github.com/cpacker/MemGPT/discussions/67&#34;&gt;discussion&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Release MemGPT family of open models (eg finetuned Mistral) (&lt;a href=&#34;https://github.com/cpacker/MemGPT/discussions/67&#34;&gt;discussion&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;Reminder: if you do not plan on modifying the source code, simply install MemGPT with &lt;code&gt;pip install pymemgpt&lt;/code&gt;!&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;First, install Poetry using &lt;a href=&#34;https://python-poetry.org/docs/#installing-with-the-official-installer&#34;&gt;the official instructions here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Then, you can install MemGPT from source with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:cpacker/MemGPT.git&#xA;poetry shell&#xA;poetry install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We recommend installing pre-commit to ensure proper formatting during development:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install pre-commit&#xA;pre-commit install&#xA;pre-commit run --all-files&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Contributing&lt;/h3&gt; &#xA;&lt;p&gt;We welcome pull requests! Please run the formatter before submitting a pull request:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;poetry run black . -l 140&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>waymo-research/waymax</title>
    <updated>2023-10-29T02:00:02Z</updated>
    <id>tag:github.com,2023-10-29:/waymo-research/waymax</id>
    <link href="https://github.com/waymo-research/waymax" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A JAX-based simulator for autonomous driving research.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Waymax: An accelerated simulator for autonomous driving research.&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/waymo-research/waymax/actions/workflows/ci-build.yml/badge.svg?sanitize=true&#34; alt=&#34;Continuous integration&#34;&gt; &lt;a href=&#34;https://arxiv.org/abs/2310.08710&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/cs.RO-2310.08710-b31b1b?logo=arxiv&amp;amp;logoColor=red&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://waymo-research.github.io/waymax/docs/&#34;&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://waymo-research.github.io/waymax/docs/getting_started.html&#34;&gt;&lt;strong&gt;Tutorials&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;Waymax is a lightweight, multi-agent, JAX-based simulator for autonomous driving research based on the &lt;a href=&#34;https://waymo.com/open/&#34;&gt;Waymo Open Motion Dataset&lt;/a&gt;. Waymax is designed to support research for all aspects of behavior research in autonomous driving - from closed-loop simulation for planning and sim agent research to open-loop behavior prediction. Objects (e.g. vehicles, pedestrians) are represented as bounding boxes, rather than raw sensor outputs, in order to distill behavior research into its simplest form.&lt;/p&gt; &#xA;&lt;p&gt;As all components are entirely written in JAX, Waymax is easily distributed and deployed on hardware accelerators, such as GPUs and &lt;a href=&#34;https://cloud.google.com/tpu&#34;&gt;TPUs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Waymax can be installed via pip using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install --upgrade pip&#xA;pip install git+https://github.com/waymo-research/waymax.git@main#egg=waymo-waymax&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://github.com/google/jax#installation&#34;&gt;JAX&lt;/a&gt; for specific instructions on how to setup JAX with GPU/CUDA support if needed.&lt;/p&gt; &#xA;&lt;h3&gt;Configure access to Waymo Open Motion Dataset&lt;/h3&gt; &#xA;&lt;p&gt;Waymax is designed to work with the Waymo Open Motion dataset out of the box.&lt;/p&gt; &#xA;&lt;p&gt;A simple way to configure access is the following:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Apply for &lt;a href=&#34;https://waymo.com/open&#34;&gt;Waymo Open Dataset&lt;/a&gt; access.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install &lt;a href=&#34;https://cloud.google.com/sdk/docs/install&#34;&gt;gcloud CLI&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run &lt;code&gt;gcloud auth login &amp;lt;your_email&amp;gt;&lt;/code&gt; with the same email used for step 1.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run &lt;code&gt;gcloud auth application-default login&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Please reference &lt;a href=&#34;https://www.tensorflow.org/datasets/gcs#authentication&#34;&gt;TF Datasets&lt;/a&gt; for alternative methods to authentication.&lt;/p&gt; &#xA;&lt;h2&gt;Components&lt;/h2&gt; &#xA;&lt;p&gt;Structurally, Waymax is comprised of a collection of libraries for loading Open Motion data, visualization, computing common metrics, intelligent sim agents, and adapters to common RL interfaces such as &lt;a href=&#34;https://github.com/deepmind/dm_env&#34;&gt;dm-env&lt;/a&gt;. These libraries can be used as standalone modules, or used together in full closed-loop simulation.&lt;/p&gt; &#xA;&lt;h3&gt;Dataloading&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;waymax.dataloader&lt;/code&gt; module contains utilities for loading data from the &lt;a href=&#34;https://waymo.com/open/&#34;&gt;Waymo Open Motion Dataset&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from waymax import config&#xA;from waymax import dataloader&#xA;&#xA;scenarios = dataloader.simulator_state_generator(config.WOD_1_1_0_TRAINING)&#xA;scenario = next(scenarios)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Metrics&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;waymax.metrics&lt;/code&gt; module defines commonly used metrics for evaluating agents. These metrics can be used to evaluate simulated rollouts, or open-loop predictions from behavior models. Supported metrics include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/waymo-research/waymax/tree/main/waymax/metrics/overlap.py&#34;&gt;Overlap&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/waymo-research/waymax/tree/main/waymax/metrics/roadgraph.py&#34;&gt;Offroad&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/waymo-research/waymax/tree/main/waymax/metrics/roadgraph.py&#34;&gt;Wrong-way&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/waymo-research/waymax/tree/main/waymax/metrics/route.py&#34;&gt;Route-following&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/waymo-research/waymax/tree/main/waymax/metrics/comfort.py&#34;&gt;Kinematic infeasibility&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/waymo-research/waymax/tree/main/waymax/metrics/imitation.py&#34;&gt;Log divergence (MSE)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Agents&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;waymax.agents&lt;/code&gt; module defines intelligent simulated agents for realistic simulation. Waymax currently supports:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Log-playback&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/waymo-research/waymax/tree/main/waymax/agents/waypoint_following_agent.py&#34;&gt;IDM&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Environments and dynamics&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;waymax.env&lt;/code&gt; module defines a stateless, closed-loop simulator interface as well as adapters to common RL interfaces such as &lt;a href=&#34;https://github.com/deepmind/dm_env&#34;&gt;dm-env&lt;/a&gt; and &lt;a href=&#34;https://github.com/google/brax&#34;&gt;brax&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;A multi-agent simulation with rewards computed for all agents can be run as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from waymax import env, config, dynamics, datatypes&#xA;&#xA;# Initialization&#xA;dynamics_model = dynamics.InvertibleBicycleModel()&#xA;env_config = config.EnvironmentConfig()&#xA;scenarios = dataloader.simulator_state_generator(config.WOD_1_1_0_TRAINING)&#xA;waymax_env = env.MultiAgentEnvironment(dynamics_model, env_config)&#xA;&#xA;# Rollout&#xA;state = waymax_env.reset(next(scenarios))&#xA;total_returns = 0&#xA;while not state.is_done:&#xA;  action = datatypes.Action(data=..., valid=...)  # Compute action here&#xA;  total_returns += waymax_env.reward(state, action)&#xA;  state = waymax_env.step(state, action)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Tutorials&lt;/h2&gt; &#xA;&lt;p&gt;We provide a few &lt;a href=&#34;https://github.com/waymo-research/waymax/raw/main/docs/notebooks&#34;&gt;colab tutorials&lt;/a&gt; for getting started:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/waymo-research/waymax/raw/main/docs/notebooks/data_demo.ipynb&#34;&gt;data_demo.ipynb&lt;/a&gt; shows how to load the data and use the top-down view visualization.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/waymo-research/waymax/raw/main/docs/notebooks/multi_actors_demo.ipynb&#34;&gt;multi_actors_demo.ipynb&lt;/a&gt; shows how to instantiate multiple agents and run a simple closed-loop simulation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/waymo-research/waymax/raw/main/docs/notebooks/wosac_submission_via_waymax.ipynb&#34;&gt;wosac_submission_via_waymax.ipynb&lt;/a&gt; shows how to create a Waymo Open Sim Agents Challenge submission file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citing Waymax&lt;/h2&gt; &#xA;&lt;p&gt;If you use Waymax for your own research, please cite Waymax in accordance with the requirements of the Waymax License Agreement for Non-Commercial Use, including using the following bibtex entry:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{waymax,&#xA;title={Waymax: An Accelerated, Data-Driven&#xA;Simulator for Large-Scale Autonomous Driving Research},&#xA;author={Cole Gulino and Justin Fu and Wenjie&#xA;Luo and George Tucker and Eli Bronstein and Yiren Lu and Jean Harb and Xinlei Pan and Yan Wang and Xiangyu Chen and John&#xA;D. Co-Reyes and Rishabh Agarwal and Rebecca Roelofs and Yao Lu and Nico Montali and Paul Mougin and Zoey Yang and&#xA;Brandyn White and Aleksandra Faust, and Rowan McAllister and Dragomir Anguelov and Benjamin Sapp},&#xA;booktitle={Proceedings of the Neural Information Processing Systems Track on Datasets and&#xA;Benchmarks},year={2023}}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>commaai/openpilot</title>
    <updated>2023-10-29T02:00:02Z</updated>
    <id>tag:github.com,2023-10-29:/commaai/openpilot</id>
    <link href="https://github.com/commaai/openpilot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;openpilot is an open source driver assistance system. openpilot performs the functions of Automated Lane Centering and Adaptive Cruise Control for 250+ supported car makes and models.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://github.com/commaai/openpilot/assets/4038174/f1081737-8718-4241-a22a-3ceba526361a&#34; alt=&#34;openpilot on the comma 3X&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Table of Contents&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/#what-is-openpilot&#34;&gt;What is openpilot?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/#running-on-a-dedicated-device-in-a-car&#34;&gt;Running in a car&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/#running-on-pc&#34;&gt;Running on PC&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/#community-and-contributing&#34;&gt;Community and Contributing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/#user-data-and-comma-account&#34;&gt;User Data and comma Account&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/#safety-and-testing&#34;&gt;Safety and Testing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/#directory-structure&#34;&gt;Directory Structure&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/#licensing&#34;&gt;Licensing&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;What is openpilot?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://github.com/commaai/openpilot&#34;&gt;openpilot&lt;/a&gt; is an open source driver assistance system. Currently, openpilot performs the functions of Adaptive Cruise Control (ACC), Automated Lane Centering (ALC), Forward Collision Warning (FCW), and Lane Departure Warning (LDW) for a growing variety of &lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/docs/CARS.md&#34;&gt;supported car makes, models, and model years&lt;/a&gt;. In addition, while openpilot is engaged, a camera-based Driver Monitoring (DM) feature alerts distracted and asleep drivers. See more about &lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/docs/INTEGRATION.md&#34;&gt;the vehicle integration&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/docs/LIMITATIONS.md&#34;&gt;limitations&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/NmBfgOanCyk&#34; title=&#34;Video By Greer Viau&#34;&gt;&lt;img src=&#34;https://i.imgur.com/1w8c6d2.jpg&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/VHKyqZ7t8Gw&#34; title=&#34;Video By Logan LeGrand&#34;&gt;&lt;img src=&#34;https://i.imgur.com/LnBucik.jpg&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/VxiR4iyBruo&#34; title=&#34;Video By Charlie Kim&#34;&gt;&lt;img src=&#34;https://i.imgur.com/4Qoy48c.jpg&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/-IkImTe1NYE&#34; title=&#34;Video By Aragon&#34;&gt;&lt;img src=&#34;https://i.imgur.com/04VNzPf.jpg&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/iIUICQkdwFQ&#34; title=&#34;Video By Logan LeGrand&#34;&gt;&lt;img src=&#34;https://i.imgur.com/b1LHQTy.jpg&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/XOsa0FsVIsg&#34; title=&#34;Video By PinoyDrives&#34;&gt;&lt;img src=&#34;https://i.imgur.com/6FG0Bd8.jpg&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/bCwcJ98R_Xw&#34; title=&#34;Video By JS&#34;&gt;&lt;img src=&#34;https://i.imgur.com/zO18CbW.jpg&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/BQ0tF3MTyyc&#34; title=&#34;Video By Tsai-Fi&#34;&gt;&lt;img src=&#34;https://i.imgur.com/eZzelq3.jpg&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Running on a dedicated device in a car&lt;/h2&gt; &#xA;&lt;p&gt;To use openpilot in a car, you need four things&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Supported Device:&lt;/strong&gt; A comma 3/3X. You can purchase these devices from (&lt;a href=&#34;https://comma.ai/shop/comma-3x&#34;&gt;https://comma.ai/shop/comma-3x&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Software:&lt;/strong&gt; The setup procedure for the comma 3/3X allows users to enter a URL for custom software. To install the release version of openpilot, use the URL &lt;code&gt;openpilot.comma.ai&lt;/code&gt;. To install openpilot master (for more advanced users), use the URL &lt;code&gt;installer.comma.ai/commaai/master&lt;/code&gt;. You can replace &#34;commaai&#34; with another GitHub username to install a fork.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Supported Car:&lt;/strong&gt; Ensure that you have one of &lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/docs/CARS.md&#34;&gt;the 250+ supported cars&lt;/a&gt;. openpilot supports a wide range of car makes including Honda, Toyota, Hyundai, Nissan, Kia, Chrysler, Lexus, Acura, Audi, VW, Ford, and many more. If your car is not officially listed as supported but has adaptive cruise control and lane-keeping assist, it&#39;s likely capable of running openpilot.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Car Harness:&lt;/strong&gt; You will also need a &lt;a href=&#34;https://comma.ai/shop/car-harness&#34;&gt;car harness&lt;/a&gt; to connect your comma 3/3X to your car. We have detailed instructions for &lt;a href=&#34;https://comma.ai/setup&#34;&gt;how to install the harness and device in a car&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Running on PC&lt;/h2&gt; &#xA;&lt;p&gt;All openpilot services can run as usual on a PC without requiring special hardware or a car. You can also run openpilot on recorded or simulated data to develop or experiment with openpilot.&lt;/p&gt; &#xA;&lt;p&gt;With openpilot&#39;s tools, you can plot logs, replay drives, and watch the full-res camera streams. See &lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/tools/README.md&#34;&gt;the tools README&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;p&gt;You can also run openpilot in simulation &lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/tools/sim/README.md&#34;&gt;with the CARLA simulator&lt;/a&gt;. This allows openpilot to drive around a virtual car on your Ubuntu machine. The whole setup should only take a few minutes but does require a decent GPU.&lt;/p&gt; &#xA;&lt;p&gt;A PC running openpilot can also control your vehicle if it is connected to a &lt;a href=&#34;https://github.com/commaai/openpilot/tree/master/tools/webcam&#34;&gt;webcam&lt;/a&gt;, a &lt;a href=&#34;https://comma.ai/shop/products/panda&#34;&gt;black panda&lt;/a&gt;, and a &lt;a href=&#34;https://comma.ai/shop/products/car-harness&#34;&gt;harness&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Community and Contributing&lt;/h2&gt; &#xA;&lt;p&gt;openpilot is developed by &lt;a href=&#34;https://comma.ai/&#34;&gt;comma&lt;/a&gt; and by users like you. We welcome both pull requests and issues on &lt;a href=&#34;http://github.com/commaai/openpilot&#34;&gt;GitHub&lt;/a&gt;. Bug fixes and new car ports are encouraged. Check out &lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/docs/CONTRIBUTING.md&#34;&gt;the contributing docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Documentation related to openpilot development can be found on &lt;a href=&#34;https://docs.comma.ai&#34;&gt;docs.comma.ai&lt;/a&gt;. Information about running openpilot (e.g. FAQ, fingerprinting, troubleshooting, custom forks, community hardware) should go on the &lt;a href=&#34;https://github.com/commaai/openpilot/wiki&#34;&gt;wiki&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can add support for your car by following guides we have written for &lt;a href=&#34;https://blog.comma.ai/how-to-write-a-car-port-for-openpilot/&#34;&gt;Brand&lt;/a&gt; and &lt;a href=&#34;https://blog.comma.ai/openpilot-port-guide-for-toyota-models/&#34;&gt;Model&lt;/a&gt; ports. Generally, a car with adaptive cruise control and lane keep assist is a good candidate. &lt;a href=&#34;https://discord.comma.ai&#34;&gt;Join our Discord&lt;/a&gt; to discuss car ports: most car makes have a dedicated channel.&lt;/p&gt; &#xA;&lt;p&gt;Want to get paid to work on openpilot? &lt;a href=&#34;https://comma.ai/jobs#open-positions&#34;&gt;comma is hiring&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;And &lt;a href=&#34;https://twitter.com/comma_ai&#34;&gt;follow us on Twitter&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;User Data and comma Account&lt;/h2&gt; &#xA;&lt;p&gt;By default, openpilot uploads the driving data to our servers. You can also access your data through &lt;a href=&#34;https://connect.comma.ai/&#34;&gt;comma connect&lt;/a&gt;. We use your data to train better models and improve openpilot for everyone.&lt;/p&gt; &#xA;&lt;p&gt;openpilot is open source software: the user is free to disable data collection if they wish to do so.&lt;/p&gt; &#xA;&lt;p&gt;openpilot logs the road-facing cameras, CAN, GPS, IMU, magnetometer, thermal sensors, crashes, and operating system logs. The driver-facing camera is only logged if you explicitly opt-in in settings. The microphone is not recorded.&lt;/p&gt; &#xA;&lt;p&gt;By using openpilot, you agree to &lt;a href=&#34;https://comma.ai/privacy&#34;&gt;our Privacy Policy&lt;/a&gt;. You understand that use of this software or its related services will generate certain types of user data, which may be logged and stored at the sole discretion of comma. By accepting this agreement, you grant an irrevocable, perpetual, worldwide right to comma for the use of this data.&lt;/p&gt; &#xA;&lt;h2&gt;Safety and Testing&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;openpilot observes ISO26262 guidelines, see &lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/docs/SAFETY.md&#34;&gt;SAFETY.md&lt;/a&gt; for more details.&lt;/li&gt; &#xA; &lt;li&gt;openpilot has software-in-the-loop &lt;a href=&#34;https://raw.githubusercontent.com/commaai/openpilot/master/.github/workflows/selfdrive_tests.yaml&#34;&gt;tests&lt;/a&gt; that run on every commit.&lt;/li&gt; &#xA; &lt;li&gt;The code enforcing the safety model lives in panda and is written in C, see &lt;a href=&#34;https://github.com/commaai/panda#code-rigor&#34;&gt;code rigor&lt;/a&gt; for more details.&lt;/li&gt; &#xA; &lt;li&gt;panda has software-in-the-loop &lt;a href=&#34;https://github.com/commaai/panda/tree/master/tests/safety&#34;&gt;safety tests&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Internally, we have a hardware-in-the-loop Jenkins test suite that builds and unit tests the various processes.&lt;/li&gt; &#xA; &lt;li&gt;panda has additional hardware-in-the-loop &lt;a href=&#34;https://github.com/commaai/panda/raw/master/Jenkinsfile&#34;&gt;tests&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;We run the latest openpilot in a testing closet containing 10 comma devices continuously replaying routes.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Directory Structure&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;.&#xA;‚îú‚îÄ‚îÄ cereal              # The messaging spec and libs used for all logs&#xA;‚îú‚îÄ‚îÄ common              # Library like functionality we&#39;ve developed here&#xA;‚îú‚îÄ‚îÄ docs                # Documentation&#xA;‚îú‚îÄ‚îÄ opendbc             # Files showing how to interpret data from cars&#xA;‚îú‚îÄ‚îÄ panda               # Code used to communicate on CAN&#xA;‚îú‚îÄ‚îÄ third_party         # External libraries&#xA;‚îî‚îÄ‚îÄ system              # Generic services&#xA;    ‚îú‚îÄ‚îÄ camerad         # Driver to capture images from the camera sensors&#xA;    ‚îú‚îÄ‚îÄ hardware        # Hardware abstraction classes&#xA;    ‚îú‚îÄ‚îÄ logcatd         # systemd journal as a service&#xA;    ‚îú‚îÄ‚îÄ loggerd         # Logger and uploader of car data&#xA;    ‚îú‚îÄ‚îÄ proclogd        # Logs information from /proc&#xA;    ‚îú‚îÄ‚îÄ sensord         # IMU interface code&#xA;    ‚îî‚îÄ‚îÄ ubloxd          # u-blox GNSS module interface code&#xA;‚îî‚îÄ‚îÄ selfdrive           # Code needed to drive the car&#xA;    ‚îú‚îÄ‚îÄ assets          # Fonts, images, and sounds for UI&#xA;    ‚îú‚îÄ‚îÄ athena          # Allows communication with the app&#xA;    ‚îú‚îÄ‚îÄ boardd          # Daemon to talk to the board&#xA;    ‚îú‚îÄ‚îÄ car             # Car specific code to read states and control actuators&#xA;    ‚îú‚îÄ‚îÄ controls        # Planning and controls&#xA;    ‚îú‚îÄ‚îÄ debug           # Tools to help you debug and do car ports&#xA;    ‚îú‚îÄ‚îÄ locationd       # Precise localization and vehicle parameter estimation&#xA;    ‚îú‚îÄ‚îÄ manager         # Daemon that starts/stops all other daemons as needed&#xA;    ‚îú‚îÄ‚îÄ modeld          # Driving and monitoring model runners&#xA;    ‚îú‚îÄ‚îÄ monitoring      # Daemon to determine driver attention&#xA;    ‚îú‚îÄ‚îÄ navd            # Turn-by-turn navigation&#xA;    ‚îú‚îÄ‚îÄ test            # Unit tests, system tests, and a car simulator&#xA;    ‚îî‚îÄ‚îÄ ui              # The UI&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Licensing&lt;/h2&gt; &#xA;&lt;p&gt;openpilot is released under the MIT license. Some parts of the software are released under other licenses as specified.&lt;/p&gt; &#xA;&lt;p&gt;Any user of this software shall indemnify and hold harmless Comma.ai, Inc. and its directors, officers, employees, agents, stockholders, affiliates, subcontractors and customers from and against all allegations, claims, actions, suits, demands, damages, liabilities, obligations, losses, settlements, judgments, costs and expenses (including without limitation attorneys‚Äô fees and costs) which arise out of, relate to or result from any use of this software by user.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;THIS IS ALPHA QUALITY SOFTWARE FOR RESEARCH PURPOSES ONLY. THIS IS NOT A PRODUCT. YOU ARE RESPONSIBLE FOR COMPLYING WITH LOCAL LAWS AND REGULATIONS. NO WARRANTY EXPRESSED OR IMPLIED.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://d1qb2nb5cznatu.cloudfront.net/startups/i/1061157-bc7e9bf3b246ece7322e6ffe653f6af8-medium_jpg.jpg?buster=1458363130&#34; width=&#34;75&#34;&gt; &lt;img src=&#34;https://cdn-images-1.medium.com/max/1600/1*C87EjxGeMPrkTuVRVWVg4w.png&#34; width=&#34;225&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/commaai/openpilot/actions&#34;&gt;&lt;img src=&#34;https://github.com/commaai/openpilot/workflows/openpilot%20tests/badge.svg?event=push&#34; alt=&#34;openpilot tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/commaai/openpilot&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/commaai/openpilot/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>