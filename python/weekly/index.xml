<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-11T02:00:02Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>TransformerOptimus/SuperAGI</title>
    <updated>2023-06-11T02:00:02Z</updated>
    <id>tag:github.com,2023-06-11:/TransformerOptimus/SuperAGI</id>
    <link href="https://github.com/TransformerOptimus/SuperAGI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;‚ö°Ô∏è&gt; SuperAGI - A dev-first open source autonomous AI agent framework. Enabling developers to build, manage &amp; run useful autonomous agents quickly and reliably.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://superagi.com//#gh-light-mode-only&#34;&gt; &lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Logo-dark.svg?sanitize=true&#34; width=&#34;318px&#34; alt=&#34;SuperAGI logo&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://superagi.com//#gh-dark-mode-only&#34;&gt; &lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Logo-light.svg?sanitize=true&#34; width=&#34;318px&#34; alt=&#34;SuperAGI logo&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;i&gt;Open-source framework to build, manage and run useful Autonomous AI Agents&lt;/i&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/TransformerOptimus/SuperAGI/fork&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/forks/TransformerOptimus/SuperAGI?style=for-the-badge&#34; alt=&#34;SuperAGI forks&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/TransformerOptimus/SuperAGI/stargazers&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/TransformerOptimus/SuperAGI?style=for-the-badge&#34; alt=&#34;SuperAGI stars&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/TransformerOptimus/SuperAGI/pulls&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/issues-pr/TransformerOptimus/SuperAGI?style=for-the-badge&#34; alt=&#34;SuperAGI pull-requests&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/TransformerOptimus/SuperAGI/releases&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/release/TransformerOptimus/SuperAGI?&amp;amp;label=Latest&amp;amp;style=for-the-badge&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/TransformerOptimus/SuperAGI/commits&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/commits-since/TransformerOptimus/SuperAGI/v0.0.3.svg?style=for-the-badge&#34; alt=&#34;SuperAGI Commits&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;b&gt;Follow SuperAGI &lt;/b&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://twitter.com/_superAGI&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/twitter/follow/_superAGI?label=Follow: _superAGI&amp;amp;style=social&#34; alt=&#34;Follow _superAGI&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://www.reddit.com/r/Super_AGI&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url?label=/r/Super_AGI&amp;amp;logo=reddit&amp;amp;style=social&amp;amp;url=https://github.com/TransformerOptimus/SuperAGI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/dXbRe5BHJC&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/1107593006032355359?label=Join%20SuperAGI&amp;amp;logo=discord&amp;amp;style=social&#34; alt=&#34;Join SuperAGI Discord Community&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://superagi.com&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url?label=SuperAGI Website&amp;amp;logo=website&amp;amp;style=social&amp;amp;url=https://github.com/TransformerOptimus/SuperAGI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/@_superagi&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url?label=Youtube&amp;amp;logo=youtube&amp;amp;style=social&amp;amp;url=https://github.com/TransformerOptimus/SuperAGI&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;b&gt;Share SuperAGI Repository&lt;/b&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://twitter.com/intent/tweet?text=Check%20this%20GitHub%20repository%20out.%20SuperAGI%20-%20Let%27s%20you%20easily%20build,%20manage%20and%20run%20useful%20autonomous%20AI%20agents.&amp;amp;url=https://github.com/TransformerOptimus/SuperAGI&amp;amp;hashtags=SuperAGI,AGI,Autonomics,future&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/twitter/follow/_superAGI?label=Share Repo on Twitter&amp;amp;style=social&#34; alt=&#34;Follow _superAGI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://t.me/share/url?text=Check%20this%20GitHub%20repository%20out.%20SuperAGI%20-%20Let%27s%20you%20easily%20build,%20manage%20and%20run%20useful%20autonomous%20AI%20agents.&amp;amp;url=https://github.com/TransformerOptimus/SuperAGI&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url?label=Telegram&amp;amp;logo=Telegram&amp;amp;style=social&amp;amp;url=https://github.com/TransformerOptimus/SuperAGI&#34; alt=&#34;Share on Telegram&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://api.whatsapp.com/send?text=Check%20this%20GitHub%20repository%20out.%20SuperAGI%20-%20Let&#39;s%20you%20easily%20build,%20manage%20and%20run%20useful%20autonomous%20AI%20agents.%20https://github.com/TransformerOptimus/SuperAGI&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url?label=whatsapp&amp;amp;logo=whatsapp&amp;amp;style=social&amp;amp;url=https://github.com/TransformerOptimus/SuperAGI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.reddit.com/submit?url=https://github.com/TransformerOptimus/SuperAGI&amp;amp;title=Check%20this%20GitHub%20repository%20out.%20SuperAGI%20-%20Let&#39;s%20you%20easily%20build,%20manage%20and%20run%20useful%20autonomous%20AI%20agents.&#xA;&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/twitter/url?label=Reddit&amp;amp;logo=Reddit&amp;amp;style=social&amp;amp;url=https://github.com/TransformerOptimus/SuperAGI&#34; alt=&#34;Share on Reddit&#34;&gt; &lt;/a&gt; &lt;a href=&#34;mailto:?subject=Check%20this%20GitHub%20repository%20out.&amp;amp;body=SuperAGI%20-%20Let%27s%20you%20easily%20build,%20manage%20and%20run%20useful%20autonomous%20AI%20agents.%3A%0Ahttps://github.com/TransformerOptimus/SuperAGI&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url?label=Gmail&amp;amp;logo=Gmail&amp;amp;style=social&amp;amp;url=https://github.com/TransformerOptimus/SuperAGI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.buymeacoffee.com/superagi&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;23&#34; width=&#34;100&#34; style=&#34;border-radius:1px&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;üí° Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Provision, Spawn &amp;amp; Deploy Autonomous AI Agents&lt;/li&gt; &#xA; &lt;li&gt;Extend Agent Capabilities with Tools&lt;/li&gt; &#xA; &lt;li&gt;Run Concurrent Agents Seamlessly&lt;/li&gt; &#xA; &lt;li&gt;Graphical User Interface&lt;/li&gt; &#xA; &lt;li&gt;Action Console&lt;/li&gt; &#xA; &lt;li&gt;Multiple Vector DBs&lt;/li&gt; &#xA; &lt;li&gt;Multi-Modal Agents&lt;/li&gt; &#xA; &lt;li&gt;Agent Trajectory Fine-Tuning&lt;/li&gt; &#xA; &lt;li&gt;Performance Telemetry&lt;/li&gt; &#xA; &lt;li&gt;Optimized Token Usage&lt;/li&gt; &#xA; &lt;li&gt;Agent Memory Storage&lt;/li&gt; &#xA; &lt;li&gt;Looping Detection Heuristics&lt;/li&gt; &#xA; &lt;li&gt;Concurrent Agents&lt;/li&gt; &#xA; &lt;li&gt;Resource Manager&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üõ† Tools&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Group-113609.png&#34; height=&#34;50px&#34; width=&#34;50px&#34; alt=&#34;Slack&#34; valign=&#34;middle&#34; title=&#34;Slack&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Group-113612.png&#34; height=&#34;50px&#34; width=&#34;50px&#34; alt=&#34;Email&#34; valign=&#34;middle&#34; title=&#34;Email&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Group-113610.png&#34; height=&#34;50px&#34; width=&#34;50px&#34; alt=&#34;Jira&#34; valign=&#34;middle&#34; title=&#34;Jira&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Group-113611.png&#34; height=&#34;50px&#34; width=&#34;50px&#34; alt=&#34;File Manager&#34; valign=&#34;middle&#34; title=&#34;File Manager&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Group-113613.png&#34; height=&#34;50px&#34; width=&#34;50px&#34; alt=&#34;Google Search&#34; valign=&#34;middle&#34; title=&#34;Google Search&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Group-113615.png&#34; height=&#34;50px&#34; width=&#34;50px&#34; alt=&#34;Dall-E&#34; valign=&#34;middle&#34; title=&#34;Dall-E&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Group-113614.png&#34; height=&#34;50px&#34; width=&#34;50px&#34; alt=&#34;Github&#34; valign=&#34;middle&#34; title=&#34;Github&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Group-113616.png&#34; height=&#34;50px&#34; width=&#34;50px&#34; alt=&#34;Web Interaction&#34; valign=&#34;middle&#34; title=&#34;Web Interaction&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Group-113617.png&#34; height=&#34;50px&#34; width=&#34;50px&#34; alt=&#34;Zapier&#34; valign=&#34;middle&#34; title=&#34;Zapier&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Group-113618.png&#34; height=&#34;50px&#34; width=&#34;50px&#34; alt=&#34;Instagram&#34; valign=&#34;middle&#34; title=&#34;Instagram&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Group-113619.png&#34; height=&#34;50px&#34; width=&#34;50px&#34; alt=&#34;Trello&#34; valign=&#34;middle&#34; title=&#34;Trello&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Group-113620.png&#34; height=&#34;50px&#34; width=&#34;50px&#34; alt=&#34;Google Analytics&#34; valign=&#34;middle&#34; title=&#34;Google Analytics&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Group-113622.png&#34; height=&#34;50px&#34; width=&#34;50px&#34; alt=&#34;Duckduckgo&#34; valign=&#34;middle&#34; title=&#34;Duckduckgo&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Group-113621.png&#34; height=&#34;50px&#34; width=&#34;50px&#34; alt=&#34;Discord&#34; valign=&#34;middle&#34; title=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt; &lt;h2&gt;üíª Screenshots&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;GUI&lt;/strong&gt;&lt;/p&gt; &lt;/a&gt;&#xA;&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/TransformerOptimus/SuperAGI/main/#&#34;&gt; &lt;/a&gt;&lt;a href=&#34;https://superagi.com//#gh-light-mode-only&#34;&gt; &lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Light-dashboard.png&#34; alt=&#34;SuperAGI logo&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://superagi.com//#gh-dark-mode-only&#34;&gt; &lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/Dark-Dashboard.png&#34; alt=&#34;SuperAGI logo&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;üõ£ Roadmap&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/users/TransformerOptimus/projects/1&#34;&gt;Click here to checkout the latest roadmap üîó&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;‚öôÔ∏è Setting up&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download the repo using &lt;code&gt;git clone https://github.com/TransformerOptimus/SuperAGI.git&lt;/code&gt; in your terminal or directly from github page in zip format.&lt;/li&gt; &#xA; &lt;li&gt;Navigate to the directory using &lt;code&gt;cd SuperAGI&lt;/code&gt; and create a copy of &lt;code&gt;config_template.yaml&lt;/code&gt; and name it &lt;code&gt;config.yaml&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Enter your unique OpenAI API Key, Google key, Custom search engine ID without any quotes or spaces in &lt;code&gt;config.yaml&lt;/code&gt; file. Follow the links below to get your keys:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Keys&lt;/th&gt; &#xA;   &lt;th&gt;Accessing the keys&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;OpenAI API Key&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Sign up and create an API key at &lt;a href=&#34;https://beta.openai.com/signup/&#34;&gt;OpenAI Developer&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Google API key&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Create a project in the &lt;a href=&#34;https://console.cloud.google.com/&#34;&gt;Google Cloud Console&lt;/a&gt; and enable the API you need (for example: Google Custom Search JSON API). Then, create an API key in the &#34;Credentials&#34; section.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Custom search engine ID&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Visit &lt;a href=&#34;https://programmablesearchengine.google.com/about/&#34;&gt;Google Programmable Search Engine&lt;/a&gt; to create a custom search engine for your application and obtain the search engine ID.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Ensure that Docker is installed in your system, if not, Install it from &lt;a href=&#34;https://docs.docker.com/get-docker/&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Once you have Docker Desktop running, run command : &lt;code&gt;docker-compose up --build&lt;/code&gt; in SuperAGI directory. Open your browser and go to &lt;code&gt;localhost:3000&lt;/code&gt; to see SuperAGI running.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;‚ö†Ô∏è Under Development!&lt;/h2&gt; &#xA;&lt;p&gt;This project is under active development and may still have issues. We appreciate your understanding and patience. If you encounter any problems, please first check the open issues. If your issue is not listed, kindly create a new issue detailing the error or problem you experienced. Thank you for your support!&lt;/p&gt; &#xA;&lt;h2&gt;üìΩ Curated Videos&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;How To Install SuperAGI on:&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/iSPHZ1onQ44&#34;&gt;Github Codespaces&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/Unj5NLNTkLY&#34;&gt;Windows/MacOS/Linux&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;üë©‚Äçüíª Contributors&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/TransformerOptimus&#34;&gt;&lt;img src=&#34;https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/133493246?v=4&amp;amp;w=50&amp;amp;h=50&amp;amp;mask=circle&#34; alt=&#34;TransformerOptimus&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Cptsnowcrasher&#34;&gt;&lt;img src=&#34;https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/133322218?v=4&amp;amp;w=50&amp;amp;h=50&amp;amp;mask=circle&#34; alt=&#34;Cptsnowcrasher&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/vectorcrow&#34;&gt;&lt;img src=&#34;https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/133646556?v=4&amp;amp;w=50&amp;amp;h=50&amp;amp;mask=circle&#34; alt=&#34;vectorcrow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Akki-jain&#34;&gt;&lt;img src=&#34;https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/92881074?v=4&amp;amp;w=50&amp;amp;h=50&amp;amp;mask=circle&#34; alt=&#34;Akki-jain&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Autocop-Agent&#34;&gt;&lt;img src=&#34;https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/129729746?v=4&amp;amp;w=50&amp;amp;h=50&amp;amp;mask=circle&#34; alt=&#34;Autocop-Agent&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/COLONAYUSH&#34;&gt;&lt;img src=&#34;https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/60507126?v=4&amp;amp;w=50&amp;amp;h=50&amp;amp;mask=circle&#34; alt=&#34;COLONAYUSH&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/luciferlinx101&#34;&gt;&lt;img src=&#34;https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/129729795?v=4&amp;amp;w=50&amp;amp;h=50&amp;amp;mask=circle&#34; alt=&#34;luciferlinx101&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/mukundans89&#34;&gt;&lt;img src=&#34;https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/101278493?v=4&amp;amp;w=50&amp;amp;h=50&amp;amp;mask=circle&#34; alt=&#34;mukundans89&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/Fluder-Paradyne&#34;&gt;&lt;img src=&#34;https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/121793617?v=4&amp;amp;w=50&amp;amp;h=50&amp;amp;mask=circle&#34; alt=&#34;Fluder-Paradyne&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/nborthy&#34;&gt;&lt;img src=&#34;https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/101320057?v=4&amp;amp;w=50&amp;amp;h=50&amp;amp;mask=circle&#34; alt=&#34;nborthy&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/nihirr&#34;&gt;&lt;img src=&#34;https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/122777244?v=4&amp;amp;w=50&amp;amp;h=50&amp;amp;mask=circle&#34; alt=&#34;nihirr&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/Tarraann&#34;&gt;&lt;img src=&#34;https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/97586318?v=4&amp;amp;w=50&amp;amp;h=50&amp;amp;mask=circle&#34; alt=&#34;Tarraann&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;‚≠êStar History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#TransformerOptimus/SuperAGI&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=TransformerOptimus/SuperAGI&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/TransformerOptimus/SuperAGI#&#34;&gt;&lt;img src=&#34;https://superagi.com/wp-content/uploads/2023/05/backToTopButton.png&#34; alt=&#34;Back to top&#34; height=&#34;29&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Visualize-ML/Book3_Elements-of-Mathematics</title>
    <updated>2023-06-11T02:00:02Z</updated>
    <id>tag:github.com,2023-06-11:/Visualize-ML/Book3_Elements-of-Mathematics</id>
    <link href="https://github.com/Visualize-ML/Book3_Elements-of-Mathematics" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Book_3_„ÄäÊï∞Â≠¶Ë¶ÅÁ¥†„Äã | È∏¢Â∞æËä±‰π¶Ôºö‰ªéÂä†Âáè‰πòÈô§Âà∞Êú∫Âô®Â≠¶‰π†Ôºõ‰∏äÊû∂ÔºõÊ¨¢ËøéÁªßÁª≠Á∫†ÈîôÔºåÁ∫†ÈîôÂ§öÁöÑÂêåÂ≠¶Ëøò‰ºöÊúâËµ†‰π¶ÔºÅ&lt;/p&gt;&lt;hr&gt;&lt;p&gt;„ÄäÊï∞Â≠¶Ë¶ÅÁ¥†„Äã‰∫îÊäòÂÖ•Âè£Ôºö &lt;a href=&#34;https://zhuanlan.zhihu.com/p/620243026&#34;&gt;https://zhuanlan.zhihu.com/p/620243026&lt;/a&gt; &lt;br&gt; „ÄäÁü©ÈòµÂäõÈáè„Äã‰∫îÊäòÂÖ•Âè£Ôºö &lt;a href=&#34;https://zhuanlan.zhihu.com/p/634253719&#34;&gt;https://zhuanlan.zhihu.com/p/634253719&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Áúã‰∏™‰∫∫ÊÉÖÂÜµÔºåÂºÄÊ∫êËµÑÊ∫êÔºåÊ∞∏‰πÖÊúâÊïàÂìà„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Á∫†ÈîôÂ§öÁöÑÂêåÂ≠¶‰ºöÂæóÂà∞Ëµ†‰π¶Ôºå‰ª•Á§∫ÊÑüË∞¢„ÄÇ&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>mlc-ai/mlc-llm</title>
    <updated>2023-06-11T02:00:02Z</updated>
    <id>tag:github.com,2023-06-11:/mlc-ai/mlc-llm</id>
    <link href="https://github.com/mlc-ai/mlc-llm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Enable everyone to develop, optimize and deploy AI models natively on everyone&#39;s devices.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MLC LLM&lt;/h1&gt; &#xA;&lt;p&gt;| &lt;a href=&#34;https://mlc.ai/mlc-llm/&#34;&gt;Project Page&lt;/a&gt; | &lt;a href=&#34;https://mlc.ai/blog/2023/05/01/bringing-accelerated-llm-to-consumer-hardware&#34;&gt;Blog&lt;/a&gt; | &lt;a href=&#34;https://mlc.ai/web-llm/&#34;&gt;WebLLM&lt;/a&gt; | &lt;a href=&#34;https://mlc.ai/web-stable-diffusion/&#34;&gt;WebStableDiffusion&lt;/a&gt; | &lt;a href=&#34;https://discord.gg/9Xpy2HGBuD&#34;&gt;Discord&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;MLC LLM is a &lt;strong&gt;universal solution&lt;/strong&gt; that allows &lt;strong&gt;any language models&lt;/strong&gt; to be &lt;strong&gt;deployed natively&lt;/strong&gt; on a diverse set of hardware backends and native applications, plus a &lt;strong&gt;productive framework&lt;/strong&gt; for everyone to further optimize model performance for their own use cases.&lt;/p&gt; &#xA;&lt;p&gt;Our mission is to &lt;strong&gt;enable everyone to develop, optimize and deploy AI models natively on everyone&#39;s devices&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Everything runs locally with no server support and accelerated with local GPUs on your phone and laptops. &lt;a href=&#34;https://github.com/mlc-ai/mlc-llm/issues/15&#34;&gt;Supported platforms&lt;/a&gt; include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;iPhone, iPad;&lt;/li&gt; &#xA; &lt;li&gt;Android phones;&lt;/li&gt; &#xA; &lt;li&gt;Apple Silicon and x86 MacBooks;&lt;/li&gt; &#xA; &lt;li&gt;AMD, Intel and NVIDIA GPUs via Vulkan on Windows and Linux;&lt;/li&gt; &#xA; &lt;li&gt;NVIDIA GPUs via CUDA on Windows and Linux;&lt;/li&gt; &#xA; &lt;li&gt;WebGPU on browsers (through companion project &lt;a href=&#34;https://github.com/mlc-ai/web-llm/tree/main&#34;&gt;WebLLM&lt;/a&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://discord.gg/9Xpy2HGBuD&#34;&gt;Click here to join our Discord server!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://mlc.ai/mlc-llm/&#34;&gt;Check out our instruction page to try out!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/mlc-ai/mlc-llm/main/site/gif/ios-demo.gif&#34; height=&#34;700&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;What is MLC LLM?&lt;/h2&gt; &#xA;&lt;p&gt;In recent years, there has been remarkable progress in generative artificial intelligence (AI) and large language models (LLMs), which are becoming increasingly prevalent. Thanks to open-source initiatives, it is now possible to develop personal AI assistants using open-sourced models. However, LLMs tend to be resource-intensive and computationally demanding. To create a scalable service, developers may need to rely on powerful clusters and expensive hardware to run model inference. Additionally, deploying LLMs presents several challenges, such as their ever-evolving model innovation, memory constraints, and the need for potential optimization techniques.&lt;/p&gt; &#xA;&lt;p&gt;The goal of this project is to enable the development, optimization, and deployment of AI models for inference across a range of devices, including not just server-class hardware, but also users&#39; browsers, laptops, and mobile apps. To achieve this, we need to address the diverse nature of compute devices and deployment environments. Some of the key challenges include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Supporting different models of CPUs, GPUs, and potentially other co-processors and accelerators.&lt;/li&gt; &#xA; &lt;li&gt;Deploying on the native environment of user devices, which may not have python or other necessary dependencies readily available.&lt;/li&gt; &#xA; &lt;li&gt;Addressing memory constraints by carefully planning allocation and aggressively compressing model parameters.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;MLC LLM offers a repeatable, systematic, and customizable workflow that empowers developers and AI system researchers to implement models and optimizations in a productivity-focused, Python-first approach. This methodology enables quick experimentation with new models, new ideas and new compiler passes, followed by native deployment to the desired targets. Furthermore, we are continuously expanding LLM acceleration by broadening TVM backends to make model compilation more transparent and efficient.&lt;/p&gt; &#xA;&lt;h2&gt;How does MLC Enable Universal Native Deployment?&lt;/h2&gt; &#xA;&lt;p&gt;The cornerstone of our solution is machine learning compilation (&lt;a href=&#34;https://mlc.ai/&#34;&gt;MLC&lt;/a&gt;), which we leverage to efficiently deploy AI models. We build on the shoulders of open-source ecosystems, including tokenizers from Hugging Face and Google, as well as open-source LLMs like Llama, Vicuna, Dolly, MOSS, RWKV and more. Our primary workflow is based on &lt;a href=&#34;https://github.com/apache/tvm/tree/unity&#34;&gt;Apache TVM Unity&lt;/a&gt;, an exciting ongoing development in the Apache TVM Community.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Dynamic shape: We bake a language model as a TVM IRModule with native dynamic shape support, avoiding the need for extra padding to the maximum length and reducing both computation amount and memory usage.&lt;/li&gt; &#xA; &lt;li&gt;Composable ML compilation optimizations: we perform many model deployment optimizations, such as better compilation code transformation, fusion, memory planning, library offloading and manual code optimization can be easily incorporated as TVM&#39;s IRModule transformations exposed as Python APIs.&lt;/li&gt; &#xA; &lt;li&gt;Quantization: We utilize low-bit quantizations to compress the model weights and leverage TVM&#39;s loop-level TensorIR to quickly customize code generations for different compression encoding schemes.&lt;/li&gt; &#xA; &lt;li&gt;Runtime: The final generated libraries run on the native environment, with TVM runtime that comes with minimal dependencies, which supports various GPU driver APIs and native language bindings (C, JavaScript, etc).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/mlc-ai/mlc-llm/main/site/img/diag.svg?sanitize=true&#34; alt=&#34;Architecture Diagram&#34; height=&#34;&#34;&gt; &#xA;&lt;p&gt;Additionally, we also provide a lightweight C++-based example CLI app that showcases how to wrap up the compiled artifacts and necessary pre/post-processing, which will hopefully clarify the workflow to embed them into native applications.&lt;/p&gt; &#xA;&lt;p&gt;As a starting point, MLC generates GPU shaders for CUDA, Vulkan and Metal. It is possible to add more support, such as OpenCL, sycl, webgpu-native, through improvements to TVM compiler and runtime. MLC also supports various CPU targets including ARM and x86 via LLVM.&lt;/p&gt; &#xA;&lt;p&gt;We heavily rely on open-source ecosystem, more specifically, &lt;a href=&#34;https://discuss.tvm.apache.org/t/establish-tvm-unity-connection-a-technical-strategy/13344&#34;&gt;TVM Unity&lt;/a&gt;, an exciting latest development in the TVM project that enables python-first interactive MLC development experiences that allows us to easily compose new optimizations all in Python, and incrementally bring our app to the environment of interest. We also leveraged optimizations such as fused quantization kernels, first class dynamic shape support and diverse GPU backends.&lt;/p&gt; &#xA;&lt;h2&gt;Building from Source&lt;/h2&gt; &#xA;&lt;p&gt;There are two ways to build MLC LLM from source. The first is to use a Hugging Face URL to directly download the model parameters, and the second is to use a local directory that contains the parameters.&lt;/p&gt; &#xA;&lt;h3&gt;Hugging Face URL&lt;/h3&gt; &#xA;&lt;p&gt;To download the weights from an existing Hugging Face repository for a supported model, you can follow the instructions below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Create a new conda environment and install dependencies&#xA;conda create -n mlc-llm-env python&#xA;conda activate mlc-llm-env&#xA;pip install torch transformers # Install PyTorch and Hugging Face transformers&#xA;pip install -I mlc_ai_nightly -f https://mlc.ai/wheels # Install TVM&#xA;&#xA;# Install Git and Git-LFS if you haven&#39;t already.&#xA;# They are used for downloading the model weights from Hugging Face.&#xA;conda install git git-lfs&#xA;git lfs install&#xA;&#xA;# Clone the MLC LLM repo&#xA;git clone --recursive https://github.com/mlc-ai/mlc-llm.git&#xA;cd mlc-llm&#xA;&#xA;# Create the local build directory and compile the model&#xA;# This will automatically download the parameters, tokenizer, and config from Hugging Face&#xA;python build.py --hf-path=databricks/dolly-v2-3b&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After a successful build, the compiled model will be available at &lt;code&gt;dist/dolly-v2-3b-q3f16_0&lt;/code&gt; (the exact path will vary depending on your model type and specified quantization). Follow the platform specific instructions to build and run MLC LLM for &lt;a href=&#34;https://github.com/mlc-ai/mlc-llm/raw/main/ios/README.md&#34;&gt;iOS&lt;/a&gt;, &lt;a href=&#34;https://github.com/mlc-ai/mlc-llm/raw/main/android/README.md&#34;&gt;Android&lt;/a&gt;, and &lt;a href=&#34;https://github.com/mlc-ai/mlc-llm/tree/main/cpp/README.md&#34;&gt;CLI&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Local Directory&lt;/h3&gt; &#xA;&lt;p&gt;If you have a local directory that has the model parameters, the tokenizer, and a &lt;code&gt;config.json&lt;/code&gt; file for a supported model, you can instead run the following build command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Create the local build directory and compile the model&#xA;python build.py --model=/path/to/local/directory&#xA;&#xA;# If the model path is in the form of `dist/models/model_name`,&#xA;# we can simplify the build command to&#xA;# python build.py --model=model_name&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Similarly, the compiled model will be available at &lt;code&gt;dist/dolly-v2-3b-q3f16_0&lt;/code&gt;, where the exact path will vary depending on your model type and specified quantization. Follow the platform specific instructions to build and run MLC LLM for &lt;a href=&#34;https://github.com/mlc-ai/mlc-llm/raw/main/ios/README.md&#34;&gt;iOS&lt;/a&gt;, &lt;a href=&#34;https://github.com/mlc-ai/mlc-llm/raw/main/android/README.md&#34;&gt;Android&lt;/a&gt;, and &lt;a href=&#34;https://github.com/mlc-ai/mlc-llm/tree/main/cpp/README.md&#34;&gt;CLI&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You might also be interested in &lt;a href=&#34;https://github.com/mlc-ai/web-llm/tree/main&#34;&gt;WebLLM&lt;/a&gt;, our companion derived project that focus on bringing LLM to browsers.&lt;/li&gt; &#xA; &lt;li&gt;Project page for &lt;a href=&#34;https://raw.githubusercontent.com/mlc-ai/mlc-llm/main/site/index.md&#34;&gt;instructions&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/mlc-ai/mlc-llm/main/ios/README.md&#34;&gt;Local build Instructions for ios App&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;You might want to check out our online public &lt;a href=&#34;https://mlc.ai&#34;&gt;Machine Learning Compilation course&lt;/a&gt; for a systematic walkthrough of our approaches.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;This project is initiated by members from CMU catalyst, UW SAMPL, SJTU, OctoML and the MLC community. We would love to continue developing and supporting the open-source ML community.&lt;/p&gt; &#xA;&lt;p&gt;This project is only possible thanks to the shoulders open-source ecosystems that we stand on. We want to thank the Apache TVM community and developers of the TVM Unity effort. The open-source ML community members made these models publicly available. PyTorch and Hugging Face communities that make these models accessible. We would like to thank the teams behind Vicuna, SentencePiece, LLaMA, Alpaca, MOSS and RWKV. We also would like to thank the Vulkan, Swift, C++, Python Rust communities that enables this project.&lt;/p&gt;</summary>
  </entry>
</feed>