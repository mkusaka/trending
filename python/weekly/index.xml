<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-11T01:51:42Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Fanghua-Yu/SUPIR</title>
    <updated>2024-02-11T01:51:42Z</updated>
    <id>tag:github.com,2024-02-11:/Fanghua-Yu/SUPIR</id>
    <link href="https://github.com/Fanghua-Yu/SUPIR" rel="alternate"></link>
    <summary type="html">&lt;p&gt;SUPIR aims at developing Practical Algorithms for Photo-Realistic Image Restoration In the Wild&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2401.13627&#34;&gt;Paper&lt;/a&gt;] ‚ÄÉ [&lt;a href=&#34;http://supir.xpixel.group/&#34;&gt;Project Page&lt;/a&gt;] ‚ÄÉ [Online Demo (Coming soon)] &lt;br&gt; Fanghua, Yu, &lt;a href=&#34;https://www.jasongt.com/&#34;&gt;Jinjin Gu&lt;/a&gt;, Zheyuan Li, Jinfan Hu, Xiangtao Kong, &lt;a href=&#34;https://xinntao.github.io/&#34;&gt;Xintao Wang&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com.hk/citations?user=GUxrycUAAAAJ&#34;&gt;Jingwen He&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com.hk/citations?user=gFtI-8QAAAAJ&#34;&gt;Yu Qiao&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ&#34;&gt;Chao Dong&lt;/a&gt; &lt;br&gt; Shenzhen Institute of Advanced Technology; Shanghai AI Laboratory; University of Sydney; The Hong Kong Polytechnic University; ARC Lab, Tencent PCG; The Chinese University of Hong Kong &lt;br&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Fanghua-Yu/SUPIR/master/assets/teaser.png&#34;&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;üîß Dependencies and Installation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Clone repo&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/Fanghua-Yu/SUPIR.git&#xA;cd SUPIR&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install dependent packages&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n SUPIR python=3.8 -y&#xA;conda activate SUPIR&#xA;pip install --upgrade pip&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Download Checkpoints&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;Dependent Models&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/openai/clip-vit-large-patch14&#34;&gt;SDXL CLIP Encoder-1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k&#34;&gt;SDXL CLIP Encoder-2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/sd_xl_base_1.0_0.9vae.safetensors&#34;&gt;SDXL base 1.0_0.9vae&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/openai/clip-vit-large-patch14-336&#34;&gt;LLaVA CLIP&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/liuhaotian/llava-v1.5-13b&#34;&gt;LLaVA v1.5 13B&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Models we provided:&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;SUPIR-v0Q&lt;/code&gt;: (Coming Soon) Google Drive, Baidu Netdisk&lt;/p&gt; &lt;p&gt;Default training settings with paper. High generalization and high image quality in most cases.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;SUPIR-v0F&lt;/code&gt;: (Coming Soon) Google Drive, Baidu Netdisk&lt;/p&gt; &lt;p&gt;Training with light degradation settings. Stage1 encoder of &lt;code&gt;SUPIR-v0F&lt;/code&gt; remains more details when facing light degradations.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Edit Custom Path for Checkpoints &lt;pre&gt;&lt;code&gt;* [CKPT_PTH.py] --&amp;gt; LLAVA_CLIP_PATH, LLAVA_MODEL_PATH, SDXL_CLIP1_PATH, SDXL_CLIP2_CACHE_DIR &#xA;* [options/SUPIR_v0.yaml] --&amp;gt; SDXL_CKPT, SUPIR_CKPT_Q, SUPIR_CKPT_F&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;‚ö° Quick Inference&lt;/h2&gt; &#xA;&lt;h3&gt;Usage of SUPIR&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;Usage: &#xA;-- python test.py [options] &#xA;-- python gradio_demo.py [interactive options]&#xA;&#xA;--img_dir                Input folder.&#xA;--save_dir               Output folder.&#xA;--upscale                Upsampling ratio of given inputs. Default: 1&#xA;--SUPIR_sign             Model selection. Default: &#39;Q&#39;; Options: [&#39;F&#39;, &#39;Q&#39;]&#xA;--seed                   Random seed. Default: 1234&#xA;--min_size               Minimum resolution of output images. Default: 1024&#xA;--edm_steps              Numb of steps for EDM Sampling Scheduler. Default: 50&#xA;--s_stage1               Control Strength of Stage1. Default: -1 (negative means invalid)&#xA;--s_churn                Original hy-param of EDM. Default: 5&#xA;--s_noise                Original hy-param of EDM. Default: 1.003&#xA;--s_cfg                  Classifier-free guidance scale for prompts. Default: 7.5&#xA;--s_stage2               Control Strength of Stage2. Default: 1.0&#xA;--num_samples            Number of samples for each input. Default: 1&#xA;--a_prompt               Additive positive prompt for all inputs. &#xA;    Default: &#39;Cinematic, High Contrast, highly detailed, taken using a Canon EOS R camera, &#xA;    hyper detailed photo - realistic maximum detail, 32k, Color Grading, ultra HD, extreme&#xA;     meticulous detailing, skin pore detailing, hyper sharpness, perfect without deformations.&#39;&#xA;--n_prompt               Fixed negative prompt for all inputs. &#xA;    Default: &#39;painting, oil painting, illustration, drawing, art, sketch, oil painting, &#xA;    cartoon, CG Style, 3D render, unreal engine, blurring, dirty, messy, worst quality, &#xA;    low quality, frames, watermark, signature, jpeg artifacts, deformed, lowres, over-smooth&#39;&#xA;--color_fix_type         Color Fixing Type. Default: &#39;Wavelet&#39;; Options: [&#39;None&#39;, &#39;AdaIn&#39;, &#39;Wavelet&#39;]&#xA;--linear_CFG             Linearly (with sigma) increase CFG from &#39;spt_linear_CFG&#39; to s_cfg. Default: False&#xA;--linear_s_stage2        Linearly (with sigma) increase s_stage2 from &#39;spt_linear_s_stage2&#39; to s_stage2. Default: False&#xA;--spt_linear_CFG         Start point of linearly increasing CFG. Default: 1.0&#xA;--spt_linear_s_stage2    Start point of linearly increasing s_stage2. Default: 0.0&#xA;--ae_dtype               Inference data type of AutoEncoder. Default: &#39;bf16&#39;; Options: [&#39;fp32&#39;, &#39;bf16&#39;]&#xA;--diff_dtype             Inference data type of Diffusion. Default: &#39;fp16&#39;; Options: [&#39;fp32&#39;, &#39;fp16&#39;, &#39;bf16&#39;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Python Script&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;# Seek for best quality for most cases&#xA;CUDA_VISIBLE_DEVICES=0,1 python test.py --img_dir &#39;/opt/data/private/LV_Dataset/DiffGLV-Test-All/RealPhoto60/LQ&#39; --save_dir ./results-Q --SUPIR_sign Q --upscale 2&#xA;# for light degradation and high fidelity&#xA;CUDA_VISIBLE_DEVICES=0,1 python test.py --img_dir &#39;/opt/data/private/LV_Dataset/DiffGLV-Test-All/RealPhoto60/LQ&#39; --save_dir ./results-F --SUPIR_sign F --upscale 2 --s_cfg 4.0 --linear_CFG&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Gradio Demo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;CUDA_VISIBLE_DEVICES=0,1 python gradio_demo.py --ip 0.0.0.0 --port 6688&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Online Demo (Coming Soon)&lt;/h3&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;BibTeX&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{yu2024scaling,&#xA;  title={Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild}, &#xA;  author={Fanghua Yu and Jinjin Gu and Zheyuan Li and Jinfan Hu and Xiangtao Kong and Xintao Wang and Jingwen He and Yu Qiao and Chao Dong},&#xA;  year={2024},&#xA;  eprint={2401.13627},&#xA;  archivePrefix={arXiv},&#xA;  primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üìß Contact&lt;/h2&gt; &#xA;&lt;p&gt;If you have any question, please email &lt;code&gt;fanghuayu96@gmail.com&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>X-PLUG/MobileAgent</title>
    <updated>2024-02-11T01:51:42Z</updated>
    <id>tag:github.com,2024-02-11:/X-PLUG/MobileAgent</id>
    <link href="https://github.com/X-PLUG/MobileAgent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/X-PLUG/MobileAgent/main/assets/logo.png?v=1&amp;amp;type=image&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://arxiv.org/abs/2401.16158&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Arxiv-2401.16158-b31b1b.svg?logo=arXiv&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://huggingface.co/papers/2401.16158&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/ü§ó-Paper%20In%20HF-red.svg&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA;  Junyang Wang&#xA; &lt;sup&gt;1&lt;/sup&gt;, Haiyang Xu&#xA; &lt;sup&gt;2‚Ä†&lt;/sup&gt;, Jiabo Ye&#xA; &lt;sup&gt;2&lt;/sup&gt;, Ming Yan&#xA; &lt;sup&gt;2‚Ä†&lt;/sup&gt;, &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA;  Weizhou Shen&#xA; &lt;sup&gt;2&lt;/sup&gt;, Ji Zhang&#xA; &lt;sup&gt;2&lt;/sup&gt;, Fei Huang&#xA; &lt;sup&gt;2&lt;/sup&gt;, Jitao Sang&#xA; &lt;sup&gt;1‚Ä†&lt;/sup&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA;  {junyangwang, jtsang}@bjtu.edu.cn, {shuofeng.xhy, ym119608}@alibaba-inc.com &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;sup&gt;1&lt;/sup&gt;Beijing Jiaotong University &#xA; &lt;sup&gt;2&lt;/sup&gt;Alibaba Group &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;sup&gt;‚Ä†&lt;/sup&gt;Corresponding author &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;üìãIntroduction&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/X-PLUG/MobileAgent/main/assets/example.png?v=1&amp;amp;type=image&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Pure visual solution, independent of XML and system metadata.&lt;/li&gt; &#xA; &lt;li&gt;Unrestricted operation scope, capable of multi-app operations.&lt;/li&gt; &#xA; &lt;li&gt;Multiple visual perception tools for operation localization.&lt;/li&gt; &#xA; &lt;li&gt;No need for exploration and training, plug and play.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üì¢News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2.5] üî•üî•We provide a &lt;strong&gt;free&lt;/strong&gt; API and deploy the entire process for experiencing Mobile Agent, even if &lt;strong&gt;you don&#39;t have an OpenAI API Key&lt;/strong&gt;. Check out &lt;a href=&#34;https://raw.githubusercontent.com/X-PLUG/MobileAgent/main/#quick_start&#34;&gt;Quick Start&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;[2.2] üî•We are deploying the demo based on Gradio and users will be able to upload the screenshots.&lt;/li&gt; &#xA; &lt;li&gt;[1.31] üî•Our code is available! Welcome to try Mobile-Agent.&lt;/li&gt; &#xA; &lt;li&gt;[1.31] üî•Human-operated data in Mobile-Eval is in preparation and will be open-sourced soon.&lt;/li&gt; &#xA; &lt;li&gt;[1.30] Our paper is available at &lt;a href=&#34;https://arxiv.org/abs/2401.16158&#34;&gt;LINK&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;[1.30] Our evaluation results on Mobile-Eval are available.&lt;/li&gt; &#xA; &lt;li&gt;[1.30] The code and Mobile-Eval benchmark are coming soon!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üì∫Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/X-PLUG/MobileAgent/assets/127390760/26c48fb0-67ed-4df6-97b2-aa0c18386d31&#34;&gt;https://github.com/X-PLUG/MobileAgent/assets/127390760/26c48fb0-67ed-4df6-97b2-aa0c18386d31&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üîßPreparation&lt;/h2&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/X-PLUG/MobileAgent.git&#xA;cd MobileAgent&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Preparation for Connecting Mobile Device&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download the &lt;a href=&#34;https://developer.android.com/tools/releases/platform-tools?hl=en&#34;&gt;Android Debug Bridge&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Turn on the ADB debugging switch on your Android phone, it needs to be turned on in the developer options first.&lt;/li&gt; &#xA; &lt;li&gt;Connect your phone to the computer with a data cable and select &#34;Transfer files&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Test your ADB environment as follow: &lt;code&gt;/path/to/adb devices&lt;/code&gt;. If the connected devices are displayed, the preparation is complete.&lt;/li&gt; &#xA; &lt;li&gt;If you are using a MAC or Linux system, make sure to turn on adb permissions as follow: &lt;code&gt;sudo chmod +x /path/to/adb&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;If you are using Windows system, the path will be &lt;code&gt;xx/xx/adb.exe&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;a id=&#34;quick_start&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üîßQuick Start&lt;/h2&gt; &#xA;&lt;h3&gt;Note&lt;/h3&gt; &#xA;&lt;p&gt;‚ùóSince the GPT-4V will have severe hallucinations when perceiving non-English screenshots, we strongly recommend using Mobile-Agent under English-only systems and apps to ensure the performance. ‚ùóDue to current limited resources, please contact us to get a free API Key consisting of a &lt;strong&gt;url&lt;/strong&gt; and a &lt;strong&gt;token&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Email: &lt;a href=&#34;mailto:junyangwang@bjtu.edu.cn&#34;&gt;junyangwang@bjtu.edu.cn&lt;/a&gt;, &lt;a href=&#34;mailto:junyangwang287@gmail.com&#34;&gt;junyangwang287@gmail.com&lt;/a&gt;(If the former cannot be reached)&lt;/li&gt; &#xA; &lt;li&gt;WeChat: Wangjunyang0410&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Run&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;python run_api.py --adb_path /path/to/adb --url &#34;The url you got&#34; --token &#34;The token you got&#34; --instruction &#34;your instruction&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üîßGetting Started with your own API Key&lt;/h2&gt; &#xA;&lt;h3&gt;Preparation for Visual Perception Tools&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download the icon detection model &lt;a href=&#34;https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth&#34;&gt;Grounding DION&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The text detection model will be automatically downloaded from modelscope after you run Mobile-Agent.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Run&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;python run.py --grounding_ckpt /path/to/GroundingDION --adb_path /path/to/adb --api &#34;your API_TOKEN&#34; --instruction &#34;your instruction&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;API_TOKEN is an API Key from OpenAI with the permission to access &lt;code&gt;gpt-4-vision-preview&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üì±Mobile-Eval&lt;/h2&gt; &#xA;&lt;p&gt;Mobile-Eval is a benchmark designed for evaluating the performance of mobile device agents. This benchmark includes 10 mainstream single-app scenarios and 1 multi-app scenario.&lt;/p&gt; &#xA;&lt;p&gt;For each scenario, we have designed three instructions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Instruction 1: relatively simple and basic task&lt;/li&gt; &#xA; &lt;li&gt;Instruction 2: additional requirements added on top of the difficulty of Instruction 1&lt;/li&gt; &#xA; &lt;li&gt;Instruction 3: user demands with no explicit task indication&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The detailed content of Mobile-Eval is as follows:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Application&lt;/th&gt; &#xA;   &lt;th&gt;Instruction&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Alibaba.com&lt;/td&gt; &#xA;   &lt;td&gt;1. Help me find caps in Alibaba.com.&lt;br&gt;2. Help me find caps in Alibaba.com. If the &#34;Add to cart&#34; is available in the item information page, please add the item to my cart.&lt;br&gt;3. I want to buy a cap. I&#39;ve heard things are cheap on Alibaba.com. Maybe you can find it for me.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Amazon Music&lt;/td&gt; &#xA;   &lt;td&gt;1. Search singer Jay Chou in Amazon Music.&lt;br&gt;2. Search a music about &#34;agent&#34; in Amazon Music and play it.&lt;br&gt;3. I want to listen music to relax. Find an App to help me.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chrome&lt;/td&gt; &#xA;   &lt;td&gt;1. Search result for today&#39;s Lakers game.&lt;br&gt;2. Search the information about Taylor Swift.&lt;br&gt;3. I want to know the result for today&#39;s Lakers game. Find an App to help me.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gmail&lt;/td&gt; &#xA;   &lt;td&gt;1. Send an empty email to to {address}.&lt;br&gt;2. Send an email to {address}n to tell my new work.&lt;br&gt;3. I want to let my friend know my new work, and his address is {address}. Find an App to help me.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Google Maps&lt;/td&gt; &#xA;   &lt;td&gt;1. Navigate to Hangzhou West Lake.&lt;br&gt;2. Navigate to a nearby gas station.&lt;br&gt;3. I want to go to Hangzhou West Lake, but I don&#39;t know the way. Find an App to help me.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Google Play&lt;/td&gt; &#xA;   &lt;td&gt;1. Download WhatsApp in Play Store.&lt;br&gt;2. Download Instagram in Play Store.&lt;br&gt;3. I want WhatsApp on my phone. Find an App to help me.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Notes&lt;/td&gt; &#xA;   &lt;td&gt;1. Create a new note in Notes.&lt;br&gt;2. Create a new note in Notes and write &#34;Hello, this is a note&#34;, then save it.&lt;br&gt;3. I suddenly have something to record, so help me find an App and write down the following content: meeting at 3pm.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Settings&lt;/td&gt; &#xA;   &lt;td&gt;1. Turn on the dark mode.&lt;br&gt;2. Turn on the airplane mode.&lt;br&gt;3. I want to see the real time internet speed at the battery level, please turn on this setting for me.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TikTok&lt;/td&gt; &#xA;   &lt;td&gt;1. Swipe a video about pet cat in TikTok and click a &#34;like&#34; for this video.&lt;br&gt;2. Swipe a video about pet cat in TikTok and comment &#34;Ohhhh, so cute cat!&#34;.&lt;br&gt;3. Swipe videos in TikTok. Click &#34;like&#34; for 3 pet video cat.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;YouTube&lt;/td&gt; &#xA;   &lt;td&gt;1. Search for videos about Stephen Curry on YouTube.&lt;br&gt;2. Search for videos about Stephen Curry on YouTube and open &#34;Comments&#34; to comment &#34;Oh, chef, your basketball spirit has always inspired me&#34;.&lt;br&gt;3. I need you to help me show my love for Stephen Curry on YouTube.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Multi-App&lt;/td&gt; &#xA;   &lt;td&gt;1. Open the calendar and look at today&#39;s date, then go to Notes and create a new note to write &#34;Today is {today&#39;s data}&#34;.&lt;br&gt;2. Check the temperature in the next 5 days, and then create a new note in Notes and write a temperature analysis.&lt;br&gt;3. Search the result for today&#39;s Lakers game, and then create a note in Notes to write a sport news for this result.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;üìùEvaluation results&lt;/h2&gt; &#xA;&lt;p&gt;We evaluated Mobile-Agent on Mobile-Eval. The evaluation results are available at &lt;a href=&#34;https://github.com/X-PLUG/MobileAgent/tree/main/results&#34;&gt;LINK&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;We have stored the evaluation results for the 10 apps and the multi-app scenario in folders named after each app.&lt;/li&gt; &#xA; &lt;li&gt;The numbers within each app&#39;s folder represent the results for different types of instruction within that app.&lt;/li&gt; &#xA; &lt;li&gt;For example, if you want to view the results of Mobile-Agent for the second instruction in Google Maps, you should go to the following path:&lt;code&gt;results/Google Maps/2&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;If the last action of Mobile-Agent is not &#34;stop&#34;, it indicates that Mobile-Agent did not complete the corresponding instruction. During the evaluation, we manually terminated these cases where completion was not possible.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìÑTo-do List&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Development of Mobile-Agent app on Android platform.&lt;/li&gt; &#xA; &lt;li&gt;Adaptation to other mobile device platforms.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìëCitation&lt;/h2&gt; &#xA;&lt;p&gt;If you find Mobile-Agent useful for your research and applications, please cite using this BibTeX:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{wang2024mobile,&#xA;  title={Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception},&#xA;  author={Wang, Junyang and Xu, Haiyang and Ye, Jiabo and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao},&#xA;  journal={arXiv preprint arXiv:2401.16158},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üì¶Related Projects&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/IDEA-Research/GroundingDINO&#34;&gt;GroundingDINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/CLIP&#34;&gt;CLIP: Contrastive Language-Image Pretraining&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>g1879/DrissionPage</title>
    <updated>2024-02-11T01:51:42Z</updated>
    <id>tag:github.com,2024-02-11:/g1879/DrissionPage</id>
    <link href="https://github.com/g1879/DrissionPage" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Âü∫‰∫épythonÁöÑÁΩëÈ°µËá™Âä®ÂåñÂ∑•ÂÖ∑„ÄÇÊó¢ËÉΩÊéßÂà∂ÊµèËßàÂô®Ôºå‰πüËÉΩÊî∂ÂèëÊï∞ÊçÆÂåÖ„ÄÇÂèØÂÖºÈ°æÊµèËßàÂô®Ëá™Âä®ÂåñÁöÑ‰æøÂà©ÊÄßÂíårequestsÁöÑÈ´òÊïàÁéá„ÄÇÂäüËÉΩÂº∫Â§ßÔºåÂÜÖÁΩÆÊó†Êï∞‰∫∫ÊÄßÂåñËÆæËÆ°Âíå‰æøÊç∑ÂäüËÉΩ„ÄÇËØ≠Ê≥ïÁÆÄÊ¥ÅËÄå‰ºòÈõÖÔºå‰ª£Á†ÅÈáèÂ∞ë„ÄÇ&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://g1879.gitee.io/drissionpagedocs&#34;&gt;‰∏≠ÊñáÊñáÊ°£&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;‚ú®Ô∏è Overview&lt;/h1&gt; &#xA;&lt;p&gt;DrissionPage is a python-based web page automation tool.&lt;/p&gt; &#xA;&lt;p&gt;It can control the browser, send and receive data packets, and combine the two into one.&lt;/p&gt; &#xA;&lt;p&gt;It can take into account the convenience of browser automation and the high efficiency of requests.&lt;/p&gt; &#xA;&lt;p&gt;It is powerful and has countless built-in user-friendly designs and convenient functions.&lt;/p&gt; &#xA;&lt;p&gt;Its syntax is concise and elegant, the amount of code is small, and it is friendly to novices.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitee.com/g1879/DrissionPage/stargazers&#34;&gt;&lt;img src=&#34;https://gitee.com/g1879/DrissionPage/badge/star.svg?theme=dark&#34; alt=&#34; star&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Project address: &lt;a href=&#34;https://gitee.com/g1879/DrissionPage&#34;&gt;gitee&lt;/a&gt; | &lt;a href=&#34;https://github.com/g1879/DrissionPage&#34;&gt;github&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Your star is my greatest supportüíñ&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Supported systems: Windows, Linux, Mac&lt;/p&gt; &#xA;&lt;p&gt;python version: 3.6 and above&lt;/p&gt; &#xA;&lt;p&gt;Supported browsers: Chromium core browsers (such as Chrome and Edge), electron applications&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;üõ† How to use&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;üìñ Usage documentation:&lt;/strong&gt; &lt;a href=&#34;https://g1879.gitee.io/drissionpagedocs&#34;&gt;Click to view&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Communication QQ group:&lt;/strong&gt; 636361957&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;üìï background&lt;/h1&gt; &#xA;&lt;p&gt;When using requests for data collection, when facing a website to log in to, you have to analyze data packets and JS source code, construct complex requests, and often have to deal with anti-crawling methods such as verification codes, JS obfuscation, and signature parameters. The threshold is high and the development efficiency is low. high. Using a browser can largely bypass these pitfalls, but the browser is not very efficient.&lt;/p&gt; &#xA;&lt;p&gt;Therefore, the original intention of this library is to combine them into one and achieve &#34;fast writing&#34; and &#34;fast running&#34; at the same time. It can switch the corresponding mode when different needs are needed, and provide a humanized usage method to improve development and operation efficiency. In addition to merging the two, this library also encapsulates commonly used functions in web page units, providing very simple operations and statements, allowing users to reduce considerations of details and focus on function implementation. Implement powerful functions in a simple way and make your code more elegant.&lt;/p&gt; &#xA;&lt;p&gt;The previous version was implemented by repackaging selenium. Starting from 3.0, the author started from scratch, redeveloped the bottom layer, got rid of the dependence on selenium, enhanced functions, and improved operating efficiency.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;üí° Concept&lt;/h1&gt; &#xA;&lt;p&gt;Simple yet powerful!&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;‚òÄÔ∏è Features and Highlights&lt;/h1&gt; &#xA;&lt;p&gt;After long-term practice, the author has stepped through countless pitfalls, and all the experiences he has summarized have been written down in this library.&lt;/p&gt; &#xA;&lt;h2&gt;üéá Powerful self-developed core&lt;/h2&gt; &#xA;&lt;p&gt;This library uses a fully self-developed kernel, has built-in N number of practical functions, and has integrated and optimized common functions. Compared with selenium, it has the following advantages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;No webdriver features&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;No need to download different drivers for different browser versions&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Runs faster&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Can find elements across &lt;code&gt;&amp;lt;iframe&amp;gt;&lt;/code&gt; without switching in and out&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Treat &lt;code&gt;&amp;lt;iframe&amp;gt;&lt;/code&gt; as a normal element. After obtaining it, you can directly search for elements in it, making the logic clearer.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You can operate multiple tabs in the browser at the same time, even if the tab is inactive, no need to switch&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Can directly read the browser cache to save images without using the GUI to click save&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You can take screenshots of the entire web page, including parts outside the viewport (supported by browsers 90 and above)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Can handle shadow-root in non-open state&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üéá Highlighted features&lt;/h2&gt; &#xA;&lt;p&gt;In addition to the above advantages, this library also has numerous built-in humanized designs.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Minimalist grammar rules. Integrate a large number of commonly used functions to make the code more elegant&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Positioning elements is easier and the function is more powerful and stable&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Ubiquitous wait and auto-retry functionality. Make unstable networks easier to control, programs more stable, and writing more worry-free&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Provide powerful download tools. You can also enjoy fast and reliable download functions when operating the browser&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Allows repeated use of already open browsers. No need to start the browser from scratch every time, making debugging very convenient&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Use ini files to save commonly used configurations and call them automatically, providing convenient settings and staying away from complicated configuration items.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Built-in lxml as a parsing engine, the parsing speed is improved by several orders of magnitude&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Encapsulated using POM mode, which can be directly used for testing and easy to expand.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Highly integrated convenient functions, reflected in every detail&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;There are many details, so I won‚Äôt list them all here. You are welcome to experience them in actual use:)&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;üîñ Version History&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://g1879.gitee.io/drissionpagedocs/history/introduction/&#34;&gt;Click to view version history&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;üñêüèª Disclaimer&lt;/h1&gt; &#xA;&lt;p&gt;Please do not apply DrissionPage to any work that may violate legal regulations and moral constraints. Please use DrissionPage in a friendly manner, comply with the spider agreement, and do not use DrissionPage for any illegal purposes. If you choose to use DrissionPage This means that you abide by this agreement. The author does not bear any legal risks and losses caused by your violation of this agreement. You will be responsible for all consequences.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;‚òï Buy me coffee&lt;/h1&gt; &#xA;&lt;p&gt;If this project is helpful to you, why not buy the author a cup of coffee :)&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://g1879.gitee.io/drissionpagedocs/assets/images/code-cf68de50a2f331a2aa0d39c9aebbbe2c.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>