<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-31T01:53:18Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>cubiq/ComfyUI_IPAdapter_plus</title>
    <updated>2024-03-31T01:53:18Z</updated>
    <id>tag:github.com,2024-03-31:/cubiq/ComfyUI_IPAdapter_plus</id>
    <link href="https://github.com/cubiq/ComfyUI_IPAdapter_plus" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ComfyUI IPAdapter plus&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/comfyanonymous/ComfyUI&#34;&gt;ComfyUI&lt;/a&gt; reference implementation for &lt;a href=&#34;https://github.com/tencent-ailab/IP-Adapter/&#34;&gt;IPAdapter&lt;/a&gt; models.&lt;/p&gt; &#xA;&lt;p&gt;IPAdapter implementation that follows the ComfyUI way of doing things. The code is memory efficient, fast, and shouldn&#39;t break with Comfy updates.&lt;/p&gt; &#xA;&lt;h1&gt;Sponsorship&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/sponsors/cubiq&#34;&gt;&lt;span&gt;‚ù§Ô∏è&lt;/span&gt; Github Sponsor&lt;/a&gt; | &lt;a href=&#34;https://paypal.me/matt3o&#34;&gt;&lt;span&gt;ü™ô&lt;/span&gt; Paypal&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;If you like my work and wish to see updates and new features please consider sponsoring my projects.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cubiq/ComfyUI_IPAdapter_plus&#34;&gt;ComfyUI IPAdapter Plus&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cubiq/ComfyUI_InstantID&#34;&gt;ComfyUI InstantID (Native)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cubiq/ComfyUI_essentials&#34;&gt;ComfyUI Essentials&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cubiq/Comfy_Dungeon&#34;&gt;ComfyUI FaceAnalysis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cubiq/Comfy_Dungeon&#34;&gt;Comfy Dungeon&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Not to mention the documentation and videos tutorials. Check my &lt;strong&gt;ComfyUI Advanced Understanding&lt;/strong&gt; videos on YouTube for example.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=_C7kR2TFIX0&#34;&gt;ComfyUI Advanced Understanding part 1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=ijqXnW_9gzc&#34;&gt;ComfyUI Advanced Understanding part 2&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;I&#39;m talking especially to companies here, &lt;strong&gt;if you are making a profit out of Open Source code the only way to keep getting updates, bug fixes and documentation is by giving something back to those projects.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Please contact me if you are interested in a sponsorship at &lt;em&gt;matt3o@gmail&lt;/em&gt; or consider a &lt;a href=&#34;https://github.com/sponsors/cubiq&#34;&gt;Github Sponsorship&lt;/a&gt; or &lt;a href=&#34;https://paypal.me/matt3o&#34;&gt;PayPal&lt;/a&gt; (Matteo &#34;matt3o&#34; Spinelli). For &lt;em&gt;sponsorships&lt;/em&gt; of $50+, let me know if you&#39;d like to be mentioned in this readme file.&lt;/p&gt; &#xA;&lt;h1&gt;Current sponsors&lt;/h1&gt; &#xA;&lt;p&gt;I really need to thank &lt;a href=&#34;https://www.nathanshipley.com/&#34;&gt;Nathan Shipley&lt;/a&gt; for his generous donation. Go check his website, he&#39;s terribly talented.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;‚ö†&lt;/span&gt; IPAdapter V2: complete Code rewrite warning &lt;span&gt;‚ö†&lt;/span&gt;&lt;/h2&gt; &#xA;&lt;p&gt;The new code is not compatible with the previous version of IPAdapter. There is no &lt;code&gt;IPAdapter Apply&lt;/code&gt; node anymore but the &lt;code&gt;IPAdapter Advanced&lt;/code&gt; node is a drop in replacement. Delete the old node, add the new one and connect the pipelines as they were before. Everything should work.&lt;/p&gt; &#xA;&lt;p&gt;Check the &lt;code&gt;example&lt;/code&gt; directory for most of the old and new features.&lt;/p&gt; &#xA;&lt;h2&gt;Important updates&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;2024/03/23&lt;/strong&gt;: Complete code rewrite!. &lt;strong&gt;This is a breaking update!&lt;/strong&gt; Your previous workflows won&#39;t work and you&#39;ll need to recreate them. You&#39;ve been warned! After the update, refresh your browser, delete the old IPAdapter nodes and create the new ones.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;(I removed all previous updates because they were about the previous version of the extension)&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is it?&lt;/h2&gt; &#xA;&lt;p&gt;The IPAdapter are very powerful models for image-to-image conditioning. The subject or even just the style of the reference image can be applied to a generation. Think of it as a 1-image lora.&lt;/p&gt; &#xA;&lt;h2&gt;Example workflow&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/cubiq/ComfyUI_IPAdapter_plus/main/examples/&#34;&gt;example directory&lt;/a&gt; has many workflows that cover all IPAdapter functionalities.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cubiq/ComfyUI_IPAdapter_plus/main/examples/demo_workflow.jpg&#34; alt=&#34;IPAdapter Example workflow&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Video Tutorials&lt;/h2&gt; &#xA;&lt;a href=&#34;https://youtu.be/_JzDcgKgghY&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/_JzDcgKgghY/hqdefault.jpg&#34; alt=&#34;Watch the video&#34;&gt; &lt;/a&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;span&gt;‚≠ê&lt;/span&gt; &lt;a href=&#34;https://youtu.be/_JzDcgKgghY&#34;&gt;New IPAdapter features&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;The following videos are about the previous version of IPAdapter, but they still contain valuable information.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ü§ì&lt;/span&gt; &lt;a href=&#34;https://youtu.be/7m9ZZFU3HWo&#34;&gt;Basic usage video&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;span&gt;üöÄ&lt;/span&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=mJQ62ly7jrg&#34;&gt;Advanced features video&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;span&gt;üë∫&lt;/span&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=vqG1VXKteQg&#34;&gt;Attention Masking video&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=ddYbhv3WgWw&#34;&gt;Animation Features video&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Download or git clone this repository inside &lt;code&gt;ComfyUI/custom_nodes/&lt;/code&gt; directory or use the Manager. IPAdapter always requires the latest version of ComfyUI. If something doesn&#39;t work be sure to upgrade. Beware that the automatic update of the manager sometimes doesn&#39;t work and you may need to upgrade manually.&lt;/p&gt; &#xA;&lt;p&gt;There&#39;s now a &lt;em&gt;Unified Model Loader&lt;/em&gt;, for it to work you need to name the files exactly as described below. The legacy loaders work with any file name but you have to select them manually. The models can be placed into sub-directories.&lt;/p&gt; &#xA;&lt;p&gt;Remember you can also use any custom location setting an &lt;code&gt;ipadapter&lt;/code&gt; entry in the &lt;code&gt;extra_model_paths.yaml&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;/ComfyUI/models/clip_vision&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter/resolve/main/models/image_encoder/model.safetensors&#34;&gt;CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors&lt;/a&gt;, download and rename&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/image_encoder/model.safetensors&#34;&gt;CLIP-ViT-bigG-14-laion2B-39B-b160k.safetensors&lt;/a&gt;, download and rename&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/ComfyUI/models/ipadapter&lt;/code&gt;, create it if not present &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15.safetensors&#34;&gt;ip-adapter_sd15.safetensors&lt;/a&gt;, Basic model, average strength&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15_light_v11.bin&#34;&gt;ip-adapter_sd15_light_v11.bin&lt;/a&gt;, Light impact model&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter-plus_sd15.safetensors&#34;&gt;ip-adapter-plus_sd15.safetensors&lt;/a&gt;, Plus model, very strong&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter-plus-face_sd15.safetensors&#34;&gt;ip-adapter-plus-face_sd15.safetensors&lt;/a&gt;, Face model, portraits&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter-full-face_sd15.safetensors&#34;&gt;ip-adapter-full-face_sd15.safetensors&lt;/a&gt;, Stronger face model, not necessarily better&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15_vit-G.safetensors&#34;&gt;ip-adapter_sd15_vit-G.safetensors&lt;/a&gt;, Base model, &lt;strong&gt;requires bigG clip vision encoder&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter_sdxl_vit-h.safetensors&#34;&gt;ip-adapter_sdxl_vit-h.safetensors&lt;/a&gt;, SDXL model&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter-plus_sdxl_vit-h.safetensors&#34;&gt;ip-adapter-plus_sdxl_vit-h.safetensors&lt;/a&gt;, SDXL plus model&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter-plus-face_sdxl_vit-h.safetensors&#34;&gt;ip-adapter-plus-face_sdxl_vit-h.safetensors&lt;/a&gt;, SDXL face model&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter_sdxl.safetensors&#34;&gt;ip-adapter_sdxl.safetensors&lt;/a&gt;, vit-G SDXL model, &lt;strong&gt;requires bigG clip vision encoder&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Deprecated&lt;/strong&gt; &lt;a href=&#34;https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15_light.safetensors&#34;&gt;ip-adapter_sd15_light.safetensors&lt;/a&gt;, v1.0 Light impact model&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;FaceID&lt;/strong&gt; models require &lt;code&gt;insightface&lt;/code&gt;, you need to install it in your ComfyUI environment. Check &lt;a href=&#34;https://github.com/cubiq/ComfyUI_IPAdapter_plus/issues/162&#34;&gt;this issue&lt;/a&gt; for help. Remember that most FaceID models also need a LoRA.&lt;/p&gt; &#xA;&lt;p&gt;For the Unified Loader to work the files need to be named exactly as shown in the table below.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;/ComfyUI/models/ipadapter&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid_sd15.bin&#34;&gt;ip-adapter-faceid_sd15.bin&lt;/a&gt;, base FaceID model&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-plusv2_sd15.bin&#34;&gt;ip-adapter-faceid-plusv2_sd15.bin&lt;/a&gt;, FaceID plus v2&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-portrait-v11_sd15.bin&#34;&gt;ip-adapter-faceid-portrait-v11_sd15.bin&lt;/a&gt;, text prompt style transfer for portraits&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid_sdxl.bin&#34;&gt;ip-adapter-faceid_sdxl.bin&lt;/a&gt;, SDXL base FaceID&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-plusv2_sdxl.bin&#34;&gt;ip-adapter-faceid-plusv2_sdxl.bin&lt;/a&gt;, SDXL plus v2&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-portrait_sdxl.bin&#34;&gt;ip-adapter-faceid-portrait_sdxl.bin&lt;/a&gt;, SDXL text prompt style transfer&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Deprecated&lt;/strong&gt; &lt;a href=&#34;https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-plus_sd15.bin&#34;&gt;ip-adapter-faceid-plus_sd15.bin&lt;/a&gt;, FaceID plus v1&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Deprecated&lt;/strong&gt; &lt;a href=&#34;https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-portrait-v11_sd15.bin&#34;&gt;ip-adapter-faceid-portrait_sd15.bin&lt;/a&gt;, v1 of the portrait model&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Most FaceID models require a LoRA. If you use the &lt;code&gt;IPAdapter Unified Loader FaceID&lt;/code&gt; it will be loaded automatically if you follow the naming convention. Otherwise you have to load them manually, be careful each FaceID model has to be paired with its own specific LoRA.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;/ComfyUI/models/loras&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid_sd15_lora.safetensors&#34;&gt;ip-adapter-faceid_sd15_lora.safetensors&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-plusv2_sd15_lora.safetensors&#34;&gt;ip-adapter-faceid-plusv2_sd15_lora.safetensors&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid_sdxl_lora.safetensors&#34;&gt;ip-adapter-faceid_sdxl_lora.safetensors&lt;/a&gt;, SDXL FaceID LoRA&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-plusv2_sdxl_lora.safetensors&#34;&gt;ip-adapter-faceid-plusv2_sdxl_lora.safetensors&lt;/a&gt;, SDXL plus v2 LoRA&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Deprecated&lt;/strong&gt; &lt;a href=&#34;https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-plus_sd15_lora.safetensors&#34;&gt;ip-adapter-faceid-plus_sd15_lora.safetensors&lt;/a&gt;, LoRA for the deprecated FaceID plus v1 model&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All models can be found on &lt;a href=&#34;https://huggingface.co/h94&#34;&gt;huggingface&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Community&#39;s models&lt;/h3&gt; &#xA;&lt;p&gt;The community has backed some interesting IPAdapter models, if you know of other IPAdapter models please let me know.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;/ComfyUI/models/ipadapter&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/ostris/ip-composition-adapter/resolve/main/ip_plus_composition_sd15.safetensors&#34;&gt;ip_plus_composition_sd15.safetensors&lt;/a&gt;, general composition ignoring style and content, more about it &lt;a href=&#34;https://huggingface.co/ostris/ip-composition-adapter&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/ostris/ip-composition-adapter/resolve/main/ip_plus_composition_sdxl.safetensors&#34;&gt;ip_plus_composition_sdxl.safetensors&lt;/a&gt;, SDXL version&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Generic suggestions&lt;/h2&gt; &#xA;&lt;p&gt;There are many workflows included in the &lt;a href=&#34;https://raw.githubusercontent.com/cubiq/ComfyUI_IPAdapter_plus/main/examples/&#34;&gt;examples&lt;/a&gt; directory. Please check them before asking for support.&lt;/p&gt; &#xA;&lt;p&gt;Usually it&#39;s a good idea to lower the &lt;code&gt;weight&lt;/code&gt; to at least &lt;code&gt;0.8&lt;/code&gt; and increase the number steps. To increase adherece to the prompt you may try to change the &lt;strong&gt;weight type&lt;/strong&gt; in the &lt;code&gt;IPAdapter Advanced&lt;/code&gt; node.&lt;/p&gt; &#xA;&lt;h2&gt;Nodes reference&lt;/h2&gt; &#xA;&lt;p&gt;Below I&#39;m trying to document all the nodes. It&#39;s still very incomplete, be sure to check back later.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;span&gt;ü™¢&lt;/span&gt; IPAdapter Unified Loader&lt;/h3&gt; &#xA;&lt;p&gt;Loads the full stack of models needed for IPAdapter to function. The returned object will contain information regarding the &lt;strong&gt;ipadapter&lt;/strong&gt; and &lt;strong&gt;clip vision models&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Multiple unified loaders should always be daisy chained through the &lt;code&gt;ipadapter&lt;/code&gt; in/out. &lt;strong&gt;Failing to do so will cause all models to be loaded twice.&lt;/strong&gt; For &lt;strong&gt;the first&lt;/strong&gt; unified loader the &lt;code&gt;ipadapter&lt;/code&gt; input &lt;strong&gt;should never be connected&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Inputs&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;model&lt;/strong&gt;, main ComfyUI model pipeline&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Optional Inputs&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;ipadapter&lt;/strong&gt;, it&#39;s important to note that this is optional and used exclusively to daisy chain unified loaders. &lt;strong&gt;The &lt;code&gt;ipadapter&lt;/code&gt; input is never connected in the first &lt;code&gt;IPAdapter Unified Loader&lt;/code&gt; of the chain.&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Outputs&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;model&lt;/strong&gt;, the model pipeline is used exclusively for configuration, the model comes out of this node untouched and it can be considered a reroute. Note that this is different from the Unified Loader FaceID that actually alters the model with a LoRA.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ipadapter&lt;/strong&gt;, connect this to any ipadater node. Each node will automatically detect if the &lt;code&gt;ipadapter&lt;/code&gt; object contains the full stack of models or just one (like in the case &lt;a href=&#34;https://raw.githubusercontent.com/cubiq/ComfyUI_IPAdapter_plus/main/#ipadapter-model-loader&#34;&gt;IPAdapter Model Loader&lt;/a&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;span&gt;ü™¢&lt;/span&gt; IPAdapter Model Loader&lt;/h3&gt; &#xA;&lt;p&gt;Loads the IPAdapter model only. The returned object will be the IPAdapter model contrary to the &lt;a href=&#34;https://raw.githubusercontent.com/cubiq/ComfyUI_IPAdapter_plus/main/#ipadapter-unified-loader&#34;&gt;Unified loader&lt;/a&gt; that contains the full stack of models.&lt;/p&gt; &#xA;&lt;h4&gt;Configuration parameters&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;ipadapter_file&lt;/strong&gt;, the main IPAdapter model. It must be located into &lt;code&gt;ComfyUI/models/ipadapter&lt;/code&gt; or in any path specified in the &lt;code&gt;extra_model_paths.yaml&lt;/code&gt; configuration file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Outputs&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;IPADAPTER&lt;/strong&gt;, contains the loaded model only. Note that &lt;code&gt;IPADAPTER&lt;/code&gt; will have a different structure when loaded by the &lt;a href=&#34;https://raw.githubusercontent.com/cubiq/ComfyUI_IPAdapter_plus/main/#ipadapter-unified-loader&#34;&gt;Unified Loader&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;span&gt;ü™¢&lt;/span&gt; IPAdapter Advanced&lt;/h3&gt; &#xA;&lt;p&gt;This node contains all the options to fine tune the IPAdapter models. It is a drop in replacement for the old &lt;code&gt;IPAdapter Apply&lt;/code&gt; that is no longer available. If you have an old workflow, delete the existing &lt;code&gt;IPadapter Apply&lt;/code&gt; node, add &lt;code&gt;IPAdapter Advanced&lt;/code&gt; and connect all the pipes as before.&lt;/p&gt; &#xA;&lt;h4&gt;Inputs&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;model&lt;/strong&gt;, main model pipeline.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ipadapter&lt;/strong&gt;, the IPAdapter model. It can be connected to the &lt;a href=&#34;https://raw.githubusercontent.com/cubiq/ComfyUI_IPAdapter_plus/main/#ipadapter-model-loader&#34;&gt;IPAdapter Model Loader&lt;/a&gt; or any of the Unified Loaders. If a Unified loader is used anywhere in the workflow and you don&#39;t need a different model, it&#39;s always adviced to reuse the previous &lt;code&gt;ipadapter&lt;/code&gt; pipeline.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;image&lt;/strong&gt;, the reference image used to generate the positive conditioning. It should be a square image, other aspect ratios are automatically cropped in the center.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Optional inputs&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;image_negative&lt;/strong&gt;, image used to generate the negative conditioning. This is optional and normally handled by the code. It is possible to send noise or actually any image to instruct the model about what we don&#39;t want to see in the composition.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;attn_mask&lt;/strong&gt;, a mask that will be applied during the image generation. &lt;strong&gt;The mask should have the same size or at least the same aspect ratio of the latent&lt;/strong&gt;. The mask will define the area of influence of the IPAdapter models on the final image. Black zones won&#39;t be affected, white zones will get maximum influence. It can be a grayscale mask.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;clip_vision&lt;/strong&gt;, this is optional if using any of the Unified loaders. If using the &lt;a href=&#34;https://raw.githubusercontent.com/cubiq/ComfyUI_IPAdapter_plus/main/#knot-ipadapter-model-loader&#34;&gt;IPAdapter Model Loader&lt;/a&gt; you also have to provide the clip vision model with a &lt;code&gt;Load CLIP Vision&lt;/code&gt; node.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Configuration parameters&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;weight&lt;/strong&gt;, weight of the IPAdapter model. For &lt;code&gt;linear&lt;/code&gt; &lt;code&gt;weight_type&lt;/code&gt; (the default), a good starting point is 0.8. If you use other weight types you can experiment with higher values.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;weight_type&lt;/strong&gt;, this is how the IPAdapter is applied to the UNet block. For example &lt;code&gt;ease-in&lt;/code&gt; means that the input blocks have higher weight than the output ones. &lt;code&gt;week input&lt;/code&gt; means that the whole input block has lower weight. &lt;code&gt;style transfer (SDXL)&lt;/code&gt; only works with SDXL and it&#39;s a very powerful tool to tranfer only the style of an image but not its content. This parameter hugely impacts how the composition reacts to the text prompting.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;combine_embeds&lt;/strong&gt;, when sending more than one reference image the embeddings can be sent one after the other (&lt;code&gt;concat&lt;/code&gt;) or combined in various ways. For low spec GPUs it is adviced to &lt;code&gt;average&lt;/code&gt; the embeds if you send multiple images. &lt;code&gt;subtract&lt;/code&gt; subtracts the embeddings of the second image to the first; in case of 3 or more images they are averaged and subtracted to the first.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;start_at/end_at&lt;/strong&gt;, this is the timestepping. Defines at what percentage point of the generation to start applying the IPAdapter model. The initial steps are the most important so if you start later (eg: &lt;code&gt;start_at=0.3&lt;/code&gt;) the generated image will have a very light conditioning.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;embeds_scaling&lt;/strong&gt;, the way the IPAdapter models are applied to the K,V. This parameter has a small impact on how the model reacts to text prompting. &lt;code&gt;K+mean(V) w/ C penalty&lt;/code&gt; grants good quality at high weights (&amp;gt;1.0) without burning the image.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Troubleshooting&lt;/h2&gt; &#xA;&lt;p&gt;Please check the &lt;a href=&#34;https://github.com/cubiq/ComfyUI_IPAdapter_plus/issues/108&#34;&gt;troubleshooting&lt;/a&gt; before posting a new issue. Also remember to check the previous closed issues.&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tencent-ailab/IP-Adapter/&#34;&gt;IPAdapter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/comfyanonymous/ComfyUI&#34;&gt;ComfyUI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/laksjdjf/IPAdapter-ComfyUI/&#34;&gt;laksjdjf&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>krishnaik06/The-Grand-Complete-Data-Science-Materials</title>
    <updated>2024-03-31T01:53:18Z</updated>
    <id>tag:github.com,2024-03-31:/krishnaik06/The-Grand-Complete-Data-Science-Materials</id>
    <link href="https://github.com/krishnaik06/The-Grand-Complete-Data-Science-Materials" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Grand Complete Data Science Guide With Videos And Materials&lt;/h1&gt; &#xA;&lt;h2&gt;1. Complete Python Playlist For Data Analytics And Data Science&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python In English: &lt;a href=&#34;https://www.youtube.com/watch?v=bPrmA1SEN2k&amp;amp;list=PLZoTAELRMXVNUL99R4bDlVYsncUNvwUBB&#34;&gt;https://www.youtube.com/watch?v=bPrmA1SEN2k&amp;amp;list=PLZoTAELRMXVNUL99R4bDlVYsncUNvwUBB&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Python In Hindi: &lt;a href=&#34;https://www.youtube.com/watch?v=MJd9d9Mpxg0&amp;amp;list=PLTDARY42LDV4qqiJd1Z1tShm3mp9-rP4v&#34;&gt;https://www.youtube.com/watch?v=MJd9d9Mpxg0&amp;amp;list=PLTDARY42LDV4qqiJd1Z1tShm3mp9-rP4v&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;2. Complete Stats Playlist For Data Analytics And Data Science&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Stats In English One Shot: &lt;a href=&#34;https://www.youtube.com/watch?v=LZzq1zSL1bs&#34;&gt;https://www.youtube.com/watch?v=LZzq1zSL1bs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Stats In English Detailed Playlist: &lt;a href=&#34;https://www.youtube.com/watch?v=zRUliXuwJCQ&amp;amp;list=PLZoTAELRMXVMhVyr3Ri9IQ-t5QPBtxzJO&#34;&gt;https://www.youtube.com/watch?v=zRUliXuwJCQ&amp;amp;list=PLZoTAELRMXVMhVyr3Ri9IQ-t5QPBtxzJO&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Stats In Hindi Detailed Playlist: &lt;a href=&#34;https://www.youtube.com/watch?v=7y3XckjaVOw&amp;amp;list=PLTDARY42LDV6YHSRo669_uDDGmUEmQnDJ&#34;&gt;https://www.youtube.com/watch?v=7y3XckjaVOw&amp;amp;list=PLTDARY42LDV6YHSRo669_uDDGmUEmQnDJ&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;3. Complete SQL For Data Analytics And Data Science&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Complete SQl Detailed Playlist English: &lt;a href=&#34;https://www.youtube.com/watch?v=us1XyayQ6fU&amp;amp;list=PLZoTAELRMXVNMRWlVf0bDDSxNEn38u9Cl&#34;&gt;https://www.youtube.com/watch?v=us1XyayQ6fU&amp;amp;list=PLZoTAELRMXVNMRWlVf0bDDSxNEn38u9Cl&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Complete SQL Detailed Playlist Hindi : &lt;strong&gt;Coming Soon&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Complete SQL One Shot : &lt;strong&gt;Coming Soon&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;4. Git And Github Tutorials&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Git and Github Tutorials In English: &lt;a href=&#34;https://www.youtube.com/watch?v=GW7B6vwktPA&amp;amp;list=PLZoTAELRMXVOSsBerFZKsdCaA4RYr4RGW&#34;&gt;https://www.youtube.com/watch?v=GW7B6vwktPA&amp;amp;list=PLZoTAELRMXVOSsBerFZKsdCaA4RYr4RGW&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Git and Github Tutorials In Hindi: &lt;a href=&#34;https://www.youtube.com/watch?v=8KtY8ihZ8ME&#34;&gt;https://www.youtube.com/watch?v=8KtY8ihZ8ME&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;5. EDA And Feature Engineering And Feature Selection&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Feature Engineering Detailed Playlist: &lt;a href=&#34;https://www.youtube.com/watch?v=6WDFfaYtN6s&amp;amp;list=PLZoTAELRMXVPwYGE2PXD3x0bfKnR0cJjN&#34;&gt;https://www.youtube.com/watch?v=6WDFfaYtN6s&amp;amp;list=PLZoTAELRMXVPwYGE2PXD3x0bfKnR0cJjN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Feature Selection Detailed Playlist: &lt;a href=&#34;https://www.youtube.com/watch?v=uMlU2JaiOd8&amp;amp;list=PLZoTAELRMXVPgjwJ8VyRoqmfNs2CJwhVH&#34;&gt;https://www.youtube.com/watch?v=uMlU2JaiOd8&amp;amp;list=PLZoTAELRMXVPgjwJ8VyRoqmfNs2CJwhVH&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;EDA Detailed Playlist : &lt;a href=&#34;https://www.youtube.com/watch?v=F-X82zhIfBo&amp;amp;list=PLxvLUL96MOO6F8x2fLgFlNrJVcKPQuS3a&#34;&gt;https://www.youtube.com/watch?v=F-X82zhIfBo&amp;amp;list=PLxvLUL96MOO6F8x2fLgFlNrJVcKPQuS3a&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;6. Machine Learning Playlist&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Detailed ML Playlist In English: &lt;a href=&#34;https://www.youtube.com/watch?v=bPrmA1SEN2k&amp;amp;list=PLZoTAELRMXVPBTrWtJkn3wWQxZkmTXGwe&#34;&gt;https://www.youtube.com/watch?v=bPrmA1SEN2k&amp;amp;list=PLZoTAELRMXVPBTrWtJkn3wWQxZkmTXGwe&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;New ML Playlist 2023 In English(In Progress)- &lt;a href=&#34;https://www.youtube.com/watch?v=ip4WxEZwEPc&amp;amp;list=PLZoTAELRMXVPMbdMTjwolBI0cJcvASePD&#34;&gt;https://www.youtube.com/watch?v=ip4WxEZwEPc&amp;amp;list=PLZoTAELRMXVPMbdMTjwolBI0cJcvASePD&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Machine Learning One Shot In English: &lt;a href=&#34;https://www.youtube.com/watch?v=JxgmHe2NyeY&#34;&gt;https://www.youtube.com/watch?v=JxgmHe2NyeY&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Machine Learning Playlist In Hindi: &lt;a href=&#34;https://www.youtube.com/watch?v=7uwa9aPbBRU&amp;amp;list=PLTDARY42LDV7WGmlzZtY-w9pemyPrKNUZ&#34;&gt;https://www.youtube.com/watch?v=7uwa9aPbBRU&amp;amp;list=PLTDARY42LDV7WGmlzZtY-w9pemyPrKNUZ&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;7. Complete Deep Learning And NLP Playlist:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Complete Deep Learning And NLP Detailed Playlist In English: &lt;a href=&#34;https://www.youtube.com/watch?v=YFNKnUhm_-s&amp;amp;list=PLZoTAELRMXVPGU70ZGsckrMdr0FteeRUi&#34;&gt;https://www.youtube.com/watch?v=YFNKnUhm_-s&amp;amp;list=PLZoTAELRMXVPGU70ZGsckrMdr0FteeRUi&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Complete NLP Live Playlist English: &lt;a href=&#34;https://www.youtube.com/watch?v=w3coRFpyddQ&amp;amp;list=PLZoTAELRMXVNNrHSKv36Lr3_156yCo6Nn&#34;&gt;https://www.youtube.com/watch?v=w3coRFpyddQ&amp;amp;list=PLZoTAELRMXVNNrHSKv36Lr3_156yCo6Nn&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Complete Deep Learning And NLP Playlist Hindi: &lt;strong&gt;Coming soon&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;8. Important Frameworks for Production Deployments&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Flask Detailed Playlist In English: &lt;a href=&#34;https://www.youtube.com/watch?v=4L_xAWDRs7w&amp;amp;list=PLZoTAELRMXVPBaLN3e-uoVRR9hlRFRfUc&#34;&gt;https://www.youtube.com/watch?v=4L_xAWDRs7w&amp;amp;list=PLZoTAELRMXVPBaLN3e-uoVRR9hlRFRfUc&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Flask One Shot Hindi: &lt;a href=&#34;https://www.youtube.com/watch?v=KF-rDqQfqz0&#34;&gt;https://www.youtube.com/watch?v=KF-rDqQfqz0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Gradio Framework: &lt;a href=&#34;https://www.youtube.com/watch?v=wruyZWre2sM&#34;&gt;https://www.youtube.com/watch?v=wruyZWre2sM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;BentoML: &lt;a href=&#34;https://www.youtube.com/watch?v=i_FtfdOKa2M&#34;&gt;https://www.youtube.com/watch?v=i_FtfdOKa2M&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;MLflow and Dagshub: &lt;a href=&#34;https://www.youtube.com/watch?v=qdcHHrsXA48&#34;&gt;https://www.youtube.com/watch?v=qdcHHrsXA48&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;9. Complete AWS Sagemaker And Sagemaker Studio Tools&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Sagemaker Detailed Playlist: &lt;a href=&#34;https://www.youtube.com/watch?v=LkR3GNDB0HI&amp;amp;list=PLZoTAELRMXVONh5mHrXowH6-dgyWoC_Ew&#34;&gt;https://www.youtube.com/watch?v=LkR3GNDB0HI&amp;amp;list=PLZoTAELRMXVONh5mHrXowH6-dgyWoC_Ew&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Sagemaker End to End Projects- &lt;strong&gt;Coming Soon&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;10. Complete MLOPS tutorials&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Complete Dockers In One Shot English: &lt;a href=&#34;https://www.youtube.com/watch?v=8vmKtS8W7IQ&#34;&gt;https://www.youtube.com/watch?v=8vmKtS8W7IQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;MLFLOW End to End Tutorials With Deployment: &lt;a href=&#34;https://www.youtube.com/watch?v=pxk1Fr33-L4&#34;&gt;https://www.youtube.com/watch?v=pxk1Fr33-L4&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Evidently AI Model Monitoring: &lt;a href=&#34;https://www.youtube.com/watch?v=cgc3dSEAel0&#34;&gt;https://www.youtube.com/watch?v=cgc3dSEAel0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Complete Docker In One Shot Hindi: &lt;strong&gt;Coming soon&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Complete Github Action In English: &lt;strong&gt;Coming soon&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Complete Kubernetes And Kubeflow Tutorials: &lt;strong&gt;Coming Soon&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;11. End To End ML,DL and NLP Projects- Entire Lifecycle Till Deployment Using Open Source Tools&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;End To End ML Projects Playlist In English: &lt;a href=&#34;https://www.youtube.com/watch?v=S_F_c9e2bz4&amp;amp;list=PLZoTAELRMXVPS-dOaVbAux22vzqdgoGhG&amp;amp;index=1&#34;&gt;https://www.youtube.com/watch?v=S_F_c9e2bz4&amp;amp;list=PLZoTAELRMXVPS-dOaVbAux22vzqdgoGhG&amp;amp;index=1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;End To End ML Playlist In Hindi: &lt;a href=&#34;https://www.youtube.com/watch?v=NuwUnRpxq2c&amp;amp;list=PLTDARY42LDV7jzL_f68SY-eOQ9tY2lYvR&#34;&gt;https://www.youtube.com/watch?v=NuwUnRpxq2c&amp;amp;list=PLTDARY42LDV7jzL_f68SY-eOQ9tY2lYvR&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;12. Generative AI And Open AI Playlist:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;OPENAI Playlist English(In Progress): &lt;a href=&#34;https://www.youtube.com/watch?v=CbpsDMwFG2g&amp;amp;list=PLZoTAELRMXVMTWGW9iS45ZTcMsntos6VO&#34;&gt;https://www.youtube.com/watch?v=CbpsDMwFG2g&amp;amp;list=PLZoTAELRMXVMTWGW9iS45ZTcMsntos6VO&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Langchain Playlist(In Progress): &lt;a href=&#34;https://www.youtube.com/watch?v=_FpT1cwcSLg&amp;amp;list=PLZoTAELRMXVORE4VF7WQ_fAl0L1Gljtar&#34;&gt;https://www.youtube.com/watch?v=_FpT1cwcSLg&amp;amp;list=PLZoTAELRMXVORE4VF7WQ_fAl0L1Gljtar&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ChainLit Playlist &lt;strong&gt;(In Progress)&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;13. Pyspark Complete Tutorials&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Pyspark Detailed Playlist: &lt;a href=&#34;https://www.youtube.com/watch?v=WyZmM6K7ubc&amp;amp;list=PLZoTAELRMXVNjiiawhzZ0afHcPvC8jpcg&#34;&gt;https://www.youtube.com/watch?v=WyZmM6K7ubc&amp;amp;list=PLZoTAELRMXVNjiiawhzZ0afHcPvC8jpcg&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;14. Complete Data Science,Machine Learning And Deep Learning Interview Questions&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/iNeuronai/interview-question-data-science-&#34;&gt;https://github.com/iNeuronai/interview-question-data-science-&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Internships&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://internship.ineuron.ai/&#34;&gt;https://internship.ineuron.ai/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Data Science TrackerSheet For Learning&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://drive.google.com/file/d/18doA_wMja2nAawcE6imIcfnEMf-Pir2n/view&#34;&gt;https://drive.google.com/file/d/18doA_wMja2nAawcE6imIcfnEMf-Pir2n/view&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Youtube Channels For Referring All Videos. Consider Subscribing and pressing the bell icon.&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Krish Naik : &lt;a href=&#34;https://www.youtube.com/@krishnaik06&#34;&gt;https://www.youtube.com/@krishnaik06&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Krish Naik Hindi: &lt;a href=&#34;https://www.youtube.com/@krishnaikhindi&#34;&gt;https://www.youtube.com/@krishnaikhindi&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Success Stories By Krish(Coming up): &lt;a href=&#34;https://www.youtube.com/channel/UCNSHtBgZ3dhcpv190JrK_LQ&#34;&gt;https://www.youtube.com/channel/UCNSHtBgZ3dhcpv190JrK_LQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Support Channel and Join this channel to get access to perks: &lt;a href=&#34;https://www.youtube.com/channel/UCNU_lfiiWBdtULKOw6X0Dig/join&#34;&gt;https://www.youtube.com/channel/UCNU_lfiiWBdtULKOw6X0Dig/join&lt;/a&gt; our Data Science Project&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Join Our Data Science Project Neuron&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ineuron.ai/one-neuron/Data-science-Projects-Neuron?source=one_neuron_listing&#34;&gt;https://ineuron.ai/one-neuron/Data-science-Projects-Neuron?source=one_neuron_listing&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>FujiwaraChoki/MoneyPrinter</title>
    <updated>2024-03-31T01:53:18Z</updated>
    <id>tag:github.com,2024-03-31:/FujiwaraChoki/MoneyPrinter</id>
    <link href="https://github.com/FujiwaraChoki/MoneyPrinter" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Automate Creation of YouTube Shorts using MoviePy.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MoneyPrinter üí∏&lt;/h1&gt; &#xA;&lt;p&gt;Automate the creation of YouTube Shorts locally, simply by providing a video topic to talk about.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt; Please make sure you look through existing/closed issues before opening your own. If it&#39;s just a question, please join our &lt;a href=&#34;https://dsc.gg/fuji-community&#34;&gt;discord&lt;/a&gt; and ask there.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;üé•&lt;/strong&gt; Watch the video on &lt;a href=&#34;https://youtu.be/mkZsaDA2JnA?si=pNne3MnluRVkWQbE&#34;&gt;YouTube&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Installation üì•&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;MoneyPrinter&lt;/code&gt; requires Python 3.11 to run effectively. If you don&#39;t have Python installed, you can download it from &lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;After you finished installing Python, you can install &lt;code&gt;MoneyPrinter&lt;/code&gt; by following the steps below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/FujiwaraChoki/MoneyPrinter.git&#xA;cd MoneyPrinter&#xA;&#xA;# Install requirements&#xA;pip install -r requirements.txt&#xA;&#xA;# Copy .env.example and fill out values&#xA;cp .env.example .env&#xA;&#xA;# Run the backend server&#xA;cd Backend&#xA;python main.py&#xA;&#xA;# Run the frontend server&#xA;cd ../Frontend&#xA;python -m http.server 3000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinter/main/.env.example&#34;&gt;&lt;code&gt;.env.example&lt;/code&gt;&lt;/a&gt; for the required environment variables.&lt;/p&gt; &#xA;&lt;p&gt;If you need help, open &lt;a href=&#34;https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinter/main/EnvironmentVariables.md&#34;&gt;EnvironmentVariables.md&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Usage üõ†Ô∏è&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Copy the &lt;code&gt;.env.example&lt;/code&gt; file to &lt;code&gt;.env&lt;/code&gt; and fill in the required values&lt;/li&gt; &#xA; &lt;li&gt;Open &lt;code&gt;http://localhost:3000&lt;/code&gt; in your browser&lt;/li&gt; &#xA; &lt;li&gt;Enter a topic to talk about&lt;/li&gt; &#xA; &lt;li&gt;Click on the &#34;Generate&#34; button&lt;/li&gt; &#xA; &lt;li&gt;Wait for the video to be generated&lt;/li&gt; &#xA; &lt;li&gt;The video&#39;s location is &lt;code&gt;MoneyPrinter/output.mp4&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Music üéµ&lt;/h2&gt; &#xA;&lt;p&gt;To use your own music, compress all your MP3 Files into a ZIP file and upload it somewhere. Provide the link to the ZIP file in the Frontend.&lt;/p&gt; &#xA;&lt;p&gt;It is recommended to use Services such as &lt;a href=&#34;https://filebin.net&#34;&gt;Filebin&lt;/a&gt; to upload your ZIP file. If you decide to use Filebin, provide the Frontend with the absolute path to the ZIP file by using More -&amp;gt; Download File, e.g. (use this &lt;a href=&#34;https://filebin.net/klylrens0uk2pnrg/drive-download-20240209T180019Z-001.zip&#34;&gt;Popular TT songs ZIP&lt;/a&gt;, not this &lt;a href=&#34;https://filebin.net/2avx134kdibc4c3q&#34;&gt;Popular TT songs&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;p&gt;You can also just move your MP3 files into the &lt;code&gt;Songs&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;h2&gt;Fonts üÖ∞&lt;/h2&gt; &#xA;&lt;p&gt;Add your fonts to the &lt;code&gt;fonts/&lt;/code&gt; folder, and load them by specifying the font name on line &lt;code&gt;124&lt;/code&gt; in &lt;code&gt;Backend/video.py&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Automatic YouTube Uploading üé•&lt;/h2&gt; &#xA;&lt;p&gt;MoneyPrinter now includes functionality to automatically upload generated videos to YouTube.&lt;/p&gt; &#xA;&lt;p&gt;To use this feature, you need to:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create a project inside your Google Cloud Platform -&amp;gt; &lt;a href=&#34;https://console.cloud.google.com/&#34;&gt;GCP&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Obtain &lt;code&gt;client_secret.json&lt;/code&gt; from the project and add it to the Backend/ directory.&lt;/li&gt; &#xA; &lt;li&gt;Enable the YouTube v3 API in your project -&amp;gt; &lt;a href=&#34;https://console.cloud.google.com/apis/library/youtube.googleapis.com&#34;&gt;GCP-API-Library&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Create an &lt;code&gt;OAuth consent screen&lt;/code&gt; and add yourself (the account of your YouTube channel) to the testers.&lt;/li&gt; &#xA; &lt;li&gt;Enable the following scopes in the &lt;code&gt;OAuth consent screen&lt;/code&gt; for your project:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#39;https://www.googleapis.com/auth/youtube&#39;&#xA;&#39;https://www.googleapis.com/auth/youtube.upload&#39;&#xA;&#39;https://www.googleapis.com/auth/youtubepartner&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After this, you can generate the videos and you will be prompted to authenticate yourself.&lt;/p&gt; &#xA;&lt;p&gt;The authentication process creates and stores a &lt;code&gt;main.py-oauth2.json&lt;/code&gt; file inside the Backend/ directory. Keep this file to maintain authentication, or delete it to re-authenticate (for example, with a different account).&lt;/p&gt; &#xA;&lt;p&gt;Videos are uploaded as private by default. For a completely automated workflow, change the privacyStatus in main.py to your desired setting (&#34;public&#34;, &#34;private&#34;, or &#34;unlisted&#34;).&lt;/p&gt; &#xA;&lt;p&gt;For videos that have been locked as private due to upload via an unverified API service, you will not be able to appeal. You‚Äôll need to re-upload the video via a verified API service or via the YouTube app/site. The unverified API service can also apply for an API audit. So make sure to verify your API, see &lt;a href=&#34;https://support.google.com/cloud/answer/13463073&#34;&gt;OAuth App Verification Help Center&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;FAQ ü§î&lt;/h2&gt; &#xA;&lt;h3&gt;How do I get the TikTok session ID?&lt;/h3&gt; &#xA;&lt;p&gt;You can obtain your TikTok session ID by logging into TikTok in your browser and copying the value of the &lt;code&gt;sessionid&lt;/code&gt; cookie.&lt;/p&gt; &#xA;&lt;h3&gt;My ImageMagick binary is not being detected&lt;/h3&gt; &#xA;&lt;p&gt;Make sure you set your path to the ImageMagick binary correctly in the &lt;code&gt;.env&lt;/code&gt; file, it should look something like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-env&#34;&gt;IMAGEMAGICK_BINARY=&#34;C:\\Program Files\\ImageMagick-7.1.0-Q16\\magick.exe&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Don&#39;t forget to use double backslashes (&lt;code&gt;\\&lt;/code&gt;) in the path, instead of one.&lt;/p&gt; &#xA;&lt;h3&gt;I can&#39;t install &lt;code&gt;playsound&lt;/code&gt;: Wheel failed to build&lt;/h3&gt; &#xA;&lt;p&gt;If you&#39;re having trouble installing &lt;code&gt;playsound&lt;/code&gt;, you can try installing it using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -U wheel&#xA;pip install -U playsound&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you were not able to find your solution, please ask in the discord or create a new issue, so that the community can help you.&lt;/p&gt; &#xA;&lt;h2&gt;Donate üéÅ&lt;/h2&gt; &#xA;&lt;p&gt;If you like and enjoy &lt;code&gt;MoneyPrinter&lt;/code&gt;, and would like to donate, you can do that by clicking on the button on the right hand side of the repository. ‚ù§Ô∏è You will have your name (and/or logo) added to this repository as a supporter as a sign of appreciation.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing ü§ù&lt;/h2&gt; &#xA;&lt;p&gt;Pull Requests will not be accepted for the time-being.&lt;/p&gt; &#xA;&lt;h2&gt;Star History üåü&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#FujiwaraChoki/MoneyPrinter&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=FujiwaraChoki/MoneyPrinter&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License üìù&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinter/main/LICENSE&#34;&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; file for more information.&lt;/p&gt;</summary>
  </entry>
</feed>