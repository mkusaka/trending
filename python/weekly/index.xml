<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-23T02:00:59Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>pengzhile/pandora</title>
    <updated>2023-04-23T02:00:59Z</updated>
    <id>tag:github.com,2023-04-23:/pengzhile/pandora</id>
    <link href="https://github.com/pengzhile/pandora" rel="alternate"></link>
    <summary type="html">&lt;p&gt;潘多拉，一个不只是命令行的ChatGPT。&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Pandora&lt;/h1&gt; &#xA;&lt;p&gt;潘多拉 (Pandora)，一个不只是命令行的 ChatGPT。&lt;/p&gt; &#xA;&lt;p&gt;潘多拉实现了网页版 ChatGPT 的主要操作。后端优化，绕过 Cloudflare，速度喜人。&lt;/p&gt; &#xA;&lt;!-- PROJECT SHIELDS --&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/python-%3E%3D3.7-green&#34; alt=&#34;Python version&#34;&gt; &lt;a href=&#34;https://github.com/pengzhile/pandora/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-raw/pengzhile/pandora&#34; alt=&#34;Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pengzhile/pandora/commits/master&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/last-commit/pengzhile/pandora/master&#34; alt=&#34;Commits&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/pandora-chatgpt&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/pandora-chatgpt.svg?sanitize=true&#34; alt=&#34;PyPi&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/pandora-chatgpt&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/badge/pandora-chatgpt&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pengzhile/pandora/actions/workflows/python-publish.yml&#34;&gt;&lt;img src=&#34;https://github.com/pengzhile/pandora/actions/workflows/python-publish.yml/badge.svg?sanitize=true&#34; alt=&#34;PyPi workflow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pengzhile/pandora/actions/workflows/docker-publish.yml&#34;&gt;&lt;img src=&#34;https://github.com/pengzhile/pandora/actions/workflows/docker-publish.yml/badge.svg?sanitize=true&#34; alt=&#34;Docker workflow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/QBkd9JAaWa&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1098772912242163795?label=Discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- PROJECT LOGO --&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;h3 align=&#34;center&#34;&gt;潘多拉 Pandora&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; 一个不只是命令行的 &#34;ChatGPT&#34; &lt;br&gt; &lt;a href=&#34;https://github.com/pengzhile/pandora/raw/master/README_en.md&#34;&gt;&lt;strong&gt;README in English »&lt;/strong&gt;&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://chat.zhile.io/login&#34;&gt;查看Demo&lt;/a&gt; · &lt;a href=&#34;https://github.com/pengzhile/pandora/issues&#34;&gt;报告Bug&lt;/a&gt; · &lt;a href=&#34;https://github.com/pengzhile/pandora/issues&#34;&gt;提出新特性&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;h2&gt;目录&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pengzhile/pandora/master/#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8&#34;&gt;为什么要用&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pengzhile/pandora/master/#%E7%95%8C%E9%9D%A2%E6%88%AA%E5%9B%BE&#34;&gt;界面截图&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pengzhile/pandora/master/#%E5%A6%82%E4%BD%95%E8%BF%90%E8%A1%8C&#34;&gt;如何运行&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pengzhile/pandora/master/#%E7%A8%8B%E5%BA%8F%E5%8F%82%E6%95%B0&#34;&gt;程序参数&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pengzhile/pandora/master/#docker%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F&#34;&gt;Docker环境变量&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pengzhile/pandora/master/#%E5%85%B3%E4%BA%8E-access-token&#34;&gt;关于 Access Token&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pengzhile/pandora/master/#http%E6%9C%8D%E5%8A%A1%E6%96%87%E6%A1%A3&#34;&gt;HTTP服务文档&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pengzhile/pandora/master/#%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4&#34;&gt;操作命令&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pengzhile/pandora/master/#%E9%AB%98%E9%98%B6%E8%AE%BE%E7%BD%AE&#34;&gt;高阶设置&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pengzhile/pandora/master/#cloud%E6%A8%A1%E5%BC%8F&#34;&gt;Cloud模式&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pengzhile/pandora/master/#%E4%BD%BF%E7%94%A8cloudflare-workers%E4%BB%A3%E7%90%86&#34;&gt;使用Cloudflare Workers代理&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pengzhile/pandora/master/#%E5%85%B6%E4%BB%96%E8%AF%B4%E6%98%8E&#34;&gt;其他说明&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;为什么要用&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;高峰期能绕过官方限制，继续使用。&lt;/li&gt; &#xA; &lt;li&gt;应答速度直逼&lt;code&gt;PLUS&lt;/code&gt;，白嫖用户的福音。&lt;/li&gt; &#xA; &lt;li&gt;官方故障的时候，它可能还是能跑。&lt;/li&gt; &#xA; &lt;li&gt;多模式：网页/命令行/API，私有化部署。&lt;/li&gt; &#xA; &lt;li&gt;不会像官方那样无故断线、报错。&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;界面截图&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;p&gt;&lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s05.png&#34; alt=&#34;alt Screenshot5&#34;&gt; &lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s10.jpeg&#34; alt=&#34;alt Screenshot10&#34;&gt;&lt;/p&gt; &lt;/summary&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s01.png&#34; alt=&#34;alt Screenshot1&#34;&gt; &lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s02.png&#34; alt=&#34;alt Screenshot2&#34;&gt; &lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s03.png&#34; alt=&#34;alt Screenshot3&#34;&gt; &lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s04.png&#34; alt=&#34;alt Screenshot4&#34;&gt; &lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s06.png&#34; alt=&#34;alt Screenshot6&#34;&gt; &lt;img src=&#34;https://github.com/pengzhile/pandora/raw/master/doc/images/s11.jpeg&#34; alt=&#34;alt Screenshot11&#34;&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;如何运行&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Python版本目测起码要&lt;code&gt;3.7&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;pip安装运行&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install pandora-chatgpt&#xA;pandora&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;如果你想支持&lt;code&gt;gpt-3.5-turbo&lt;/code&gt;模式：&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install &#39;pandora-chatgpt[api]&#39;&#xA;pandora&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;如果你想启用&lt;code&gt;cloud&lt;/code&gt;模式：&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install &#39;pandora-chatgpt[cloud]&#39;&#xA;pandora-cloud&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;编译运行&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install .&#xA;pandora&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;如果你想支持&lt;code&gt;gpt-3.5-turbo&lt;/code&gt;模式：&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install &#39;.[api]&#39;&#xA;pandora&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;如果你想启用&lt;code&gt;cloud&lt;/code&gt;模式：&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install &#39;.[cloud]&#39;&#xA;pandora-cloud&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Docker Hub运行&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker pull pengzhile/pandora&#xA;docker run -it --rm pengzhile/pandora&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Docker编译运行&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker build -t pandora .&#xA;docker run -it --rm pandora&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;输入用户名密码登录即可，登录密码理论上不显示出来，莫慌。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;简单而粗暴，不失优雅。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;程序参数&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;可通过 &lt;code&gt;pandora --help&lt;/code&gt; 查看。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-p&lt;/code&gt; 或 &lt;code&gt;--proxy&lt;/code&gt; 指定代理，格式：&lt;code&gt;protocol://user:pass@ip:port&lt;/code&gt;。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-t&lt;/code&gt; 或 &lt;code&gt;--token_file&lt;/code&gt; 指定一个存放&lt;code&gt;Access Token&lt;/code&gt;的文件，使用&lt;code&gt;Access Token&lt;/code&gt;登录。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-s&lt;/code&gt; 或 &lt;code&gt;--server&lt;/code&gt; 以&lt;code&gt;http&lt;/code&gt;服务方式启动，格式：&lt;code&gt;ip:port&lt;/code&gt;。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-a&lt;/code&gt; 或 &lt;code&gt;--api&lt;/code&gt; 使用&lt;code&gt;gpt-3.5-turbo&lt;/code&gt;API请求，&lt;strong&gt;你可能需要向&lt;code&gt;OpenAI&lt;/code&gt;支付费用&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--tokens_file&lt;/code&gt; 指定一个存放多&lt;code&gt;Access Token&lt;/code&gt;的文件，内容为&lt;code&gt;{&#34;key&#34;: &#34;token&#34;}&lt;/code&gt;的形式。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--sentry&lt;/code&gt; 启用&lt;code&gt;sentry&lt;/code&gt;框架来发送错误报告供作者查错，敏感信息&lt;strong&gt;不会被发送&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;-v&lt;/code&gt; 或 &lt;code&gt;--verbose&lt;/code&gt; 显示调试信息，且出错时打印异常堆栈信息，供查错使用。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Docker环境变量&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;PANDORA_ACCESS_TOKEN&lt;/code&gt; 指定&lt;code&gt;Access Token&lt;/code&gt;字符串。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;PANDORA_TOKENS_FILE&lt;/code&gt; 指定一个存放多&lt;code&gt;Access Token&lt;/code&gt;的文件路径。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;PANDORA_PROXY&lt;/code&gt; 指定代理，格式：&lt;code&gt;protocol://user:pass@ip:port&lt;/code&gt;。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;PANDORA_SERVER&lt;/code&gt; 以&lt;code&gt;http&lt;/code&gt;服务方式启动，格式：&lt;code&gt;ip:port&lt;/code&gt;。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;PANDORA_API&lt;/code&gt; 使用&lt;code&gt;gpt-3.5-turbo&lt;/code&gt;API请求，&lt;strong&gt;你可能需要向&lt;code&gt;OpenAI&lt;/code&gt;支付费用&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;PANDORA_SENTRY&lt;/code&gt; 启用&lt;code&gt;sentry&lt;/code&gt;框架来发送错误报告供作者查错，敏感信息&lt;strong&gt;不会被发送&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;PANDORA_VERBOSE&lt;/code&gt; 显示调试信息，且出错时打印异常堆栈信息，供查错使用。&lt;/li&gt; &#xA; &lt;li&gt;使用Docker方式，设置环境变量即可，无视上述&lt;code&gt;程序参数&lt;/code&gt;。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;关于 Access Token&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;使用&lt;code&gt;Access Token&lt;/code&gt;方式登录，可以无代理直连。&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.fakeopen.com/auth&#34;&gt;这个服务&lt;/a&gt; 可以帮你安全有效拿到&lt;code&gt;Access Token&lt;/code&gt;，无论是否第三方登录。&lt;/li&gt; &#xA; &lt;li&gt;其中&lt;code&gt;accessToken&lt;/code&gt;字段的那一长串内容即是&lt;code&gt;Access Token&lt;/code&gt;。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Access Token&lt;/code&gt;可以复制保存，其有效期目前为&lt;code&gt;1个月&lt;/code&gt;。&lt;/li&gt; &#xA; &lt;li&gt;不要泄露你的&lt;code&gt;Access Token&lt;/code&gt;，使用它可以操纵你的账号。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;HTTP服务文档&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;如果你以&lt;code&gt;http&lt;/code&gt;服务方式启动，现在你可以打开一个极简版的&lt;code&gt;ChatGPT&lt;/code&gt;了。通过你指定的&lt;code&gt;http://ip:port&lt;/code&gt;来访问。&lt;/li&gt; &#xA; &lt;li&gt;通过&lt;code&gt;http://ip:port/?token=xxx&lt;/code&gt;，传递一个Token的名字，可以切换到对应的&lt;code&gt;Access Token&lt;/code&gt;。&lt;/li&gt; &#xA; &lt;li&gt;API文档见：&lt;a href=&#34;https://github.com/pengzhile/pandora/raw/master/doc/HTTP-API.md&#34;&gt;doc/HTTP-API.md&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;操作命令&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;对话界面&lt;strong&gt;连敲两次&lt;/strong&gt;&lt;code&gt;Enter&lt;/code&gt;发送你的输入给&lt;code&gt;ChatGPT&lt;/code&gt;。&lt;/li&gt; &#xA; &lt;li&gt;对话界面使用&lt;code&gt;/?&lt;/code&gt;可以打印支持的操作命令。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/title&lt;/code&gt; 重新设置当前对话的标题。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/select&lt;/code&gt; 回到选择会话界面。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/reload&lt;/code&gt; 重新加载当前会话所有内容，&lt;code&gt;F5&lt;/code&gt;你能懂吧。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/regen&lt;/code&gt; 如果对&lt;code&gt;ChatGPT&lt;/code&gt;当前回答不满意，可以让它重新回答。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/continue&lt;/code&gt; 让&lt;code&gt;ChatGPT&lt;/code&gt;继续输出回复的剩余部分。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/edit&lt;/code&gt; 编辑你之前的一个提问。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/new&lt;/code&gt; 直接开启一个新会话。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/del&lt;/code&gt; 删除当前会话，回到会话选择界面。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/token&lt;/code&gt; 打印当前的&lt;code&gt;Access Token&lt;/code&gt;，也许你用得上，但不要泄露。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/copy&lt;/code&gt; 复制&lt;code&gt;ChatGPT&lt;/code&gt;上一次回复的内容到剪贴板。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/copy_code&lt;/code&gt; 复制&lt;code&gt;ChatGPT&lt;/code&gt;上一次回复的代码到剪贴板&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/clear&lt;/code&gt; 清屏，应该不用解释。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/version&lt;/code&gt; 打印&lt;code&gt;Pandora&lt;/code&gt;的版本信息。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/exit&lt;/code&gt; 退出&lt;code&gt;潘多拉&lt;/code&gt;。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;高阶设置&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;本部分内容不理解的朋友，&lt;strong&gt;请勿擅动！&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;环境变量 &lt;code&gt;OPENAI_API_PREFIX&lt;/code&gt; 可以替换OpenAI Api的前缀&lt;code&gt;https://api.openai.com&lt;/code&gt;。&lt;/li&gt; &#xA; &lt;li&gt;环境变量 &lt;code&gt;CHATGPT_API_PREFIX&lt;/code&gt; 可以替换ChatGPT Api的前缀&lt;code&gt;https://ai.fakeopen.com&lt;/code&gt;。&lt;/li&gt; &#xA; &lt;li&gt;如果你想持久存储&lt;code&gt;Docker&lt;/code&gt;中&lt;code&gt;Pandora&lt;/code&gt;产生的数据，你可以挂载宿主机目录至&lt;code&gt;/data&lt;/code&gt;。&lt;/li&gt; &#xA; &lt;li&gt;如果你在国内使用&lt;code&gt;pip&lt;/code&gt;安装缓慢，可以考虑切换至腾讯的源：&lt;code&gt;pip config set global.index-url https://mirrors.cloud.tencent.com/pypi/simple&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;镜像同步版本可能不及时，如果出现这种情况建议切换至官方源：&lt;code&gt;pip config set global.index-url https://pypi.org/simple&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;默认使用&lt;code&gt;sqlite3&lt;/code&gt;存储会话数据，如果你希望更换至&lt;code&gt;mysql&lt;/code&gt;，可以这么做： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;执行&lt;code&gt;pip install PyMySQL&lt;/code&gt;安装驱动。&lt;/li&gt; &#xA;   &lt;li&gt;设置环境变量：&lt;code&gt;DATABASE_URI&lt;/code&gt;为类似&lt;code&gt;mysql+pymysql://user:pass@localhost/dbname&lt;/code&gt;的连接字符串。&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;环境变量指定&lt;code&gt;OPENAI_EMAIL&lt;/code&gt;可以替代登录输入用户名，&lt;code&gt;OPENAI_PASSWORD&lt;/code&gt;则可以替代输入密码。&lt;/li&gt; &#xA; &lt;li&gt;环境变量&lt;code&gt;API_SYSTEM_PROMPT&lt;/code&gt;可以替换&lt;code&gt;api&lt;/code&gt;模式下的系统&lt;code&gt;prompt&lt;/code&gt;。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Cloud模式&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;搭建一个跟官方很像的&lt;code&gt;ChatGPT&lt;/code&gt;服务，不能说很像，只能说一样。&lt;/li&gt; &#xA; &lt;li&gt;该模式使用&lt;code&gt;pandora-cloud&lt;/code&gt;启动，前提是你如前面所说安装好了。&lt;/li&gt; &#xA; &lt;li&gt;Docker环境变量：&lt;code&gt;PANDORA_CLOUD&lt;/code&gt; 启动&lt;code&gt;cloud&lt;/code&gt;模式。&lt;/li&gt; &#xA; &lt;li&gt;该模式参数含义与普通模式相同，可&lt;code&gt;--help&lt;/code&gt;查看。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;使用Cloudflare Workers代理&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;如果你感觉默认的&lt;code&gt;https://ai.fakeopen.com&lt;/code&gt;在你那里可能被墙了，可以使用如下方法自行代理。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;你需要一个&lt;code&gt;Cloudflare&lt;/code&gt;账号，如果没有，可以&lt;a href=&#34;https://dash.cloudflare.com/sign-up&#34;&gt;注册&lt;/a&gt;一个。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;登录后，点击&lt;code&gt;Workers&lt;/code&gt;，然后点击&lt;code&gt;Create a Worker&lt;/code&gt;，填入服务名称后点击&lt;code&gt;创建服务&lt;/code&gt;。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;点开你刚才创建的服务，点击&lt;code&gt;快速编辑&lt;/code&gt;按钮，贴入下面的代码，然后点击&lt;code&gt;保存并部署&lt;/code&gt;。&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;export default {&#xA;  async fetch(request, env) {&#xA;    const url = new URL(request.url);&#xA;    url.host = &#39;ai.fakeopen.com&#39;;&#xA;    return fetch(new Request(url, request))&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;点击&lt;code&gt;触发器&lt;/code&gt;选项卡，可以添加自定义访问域名。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;参考&lt;code&gt;高阶设置&lt;/code&gt;中的环境变量使用你的服务地址进行替换。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;其他说明&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;项目是站在其他巨人的肩膀上，感谢！&lt;/li&gt; &#xA; &lt;li&gt;报错、BUG之类的提出&lt;code&gt;Issue&lt;/code&gt;，我会修复。&lt;/li&gt; &#xA; &lt;li&gt;因为之后&lt;code&gt;ChatGPT&lt;/code&gt;的API变动，我可能不会跟进修复。&lt;/li&gt; &#xA; &lt;li&gt;喜欢的可以给颗星，都是老朋友了。&lt;/li&gt; &#xA; &lt;li&gt;不影响&lt;code&gt;PHP是世界上最好的编程语言！&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;贡献者们&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;感谢所有让这个项目变得更好的贡献者们！&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/pengzhile/pandora/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=pengzhile/pandora&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Star历史&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=pengzhile/pandora&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>lightaime/camel</title>
    <updated>2023-04-23T02:00:59Z</updated>
    <id>tag:github.com,2023-04-23:/lightaime/camel</id>
    <link href="https://github.com/lightaime/camel" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🐫 CAMEL: Communicative Agents for “Mind” Exploration of Large Scale Language Model Society&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1AzP33O8rnMW__7ocWJhVBXjKziJXPtim?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/camel-ai&#34;&gt;&lt;img src=&#34;https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo-with-title.png&#34; alt=&#34;Hugging Face&#34; width=&#34;100&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;CAMEL: Communicative Agents for “Mind” Exploration of Large Scale Language Model Society&lt;/h1&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://www.camel-ai.org/&#34;&gt;[Project Website]&lt;/a&gt; &lt;a href=&#34;https://ghli.org/camel.pdf&#34;&gt;[Preprint]&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/lightaime/camel/master/misc/logo.png&#34; width=&#34;800&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;The rapid advancement of conversational and chat-based language models has led to remarkable progress in complex task-solving. However, their success heavily relies on human input to guide the conversation, which can be challenging and time-consuming. This paper explores the potential of building scalable techniques to facilitate autonomous cooperation among communicative agents and provide insight into their &#34;cognitive&#34; processes. To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named &lt;em&gt;role-playing&lt;/em&gt;. Our approach involves using &lt;em&gt;inception prompting&lt;/em&gt; to guide chat agents toward task completion while maintaining consistency with human intentions. We showcase how role-playing can be used to generate conversational data for studying the behaviors and capabilities of chat agents, providing a valuable resource for investigating conversational language models. Our contributions include introducing a novel communicative agent framework, offering a scalable approach for studying the cooperative behaviors and capabilities of multi-agent systems, and open-sourcing our library to support research on communicative agents and beyond. The GitHub repository of this project is made publicly available on: &lt;a href=&#34;https://github.com/lightaime/camel&#34;&gt;https://github.com/lightaime/camel&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Try it yourself&lt;/h2&gt; &#xA;&lt;p&gt;We provide a &lt;a href=&#34;https://colab.research.google.com/drive/1AzP33O8rnMW__7ocWJhVBXjKziJXPtim?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Google Colab&#34;&gt;&lt;/a&gt; demo showcasing a conversation between two ChatGPT agents playing roles as a python programmer and a stock trader collaborating on developing a trading bot for stock market.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/lightaime/camel/master/misc/framework.png&#34; width=&#34;800&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Environment Setup&lt;/h2&gt; &#xA;&lt;p&gt;Install &lt;code&gt;CAMEL&lt;/code&gt; from source with conda:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# create a conda virtual environment&#xA;conda create --name camel python=3.10&#xA;# actiavte camel conda environment&#xA;conda activate camel&#xA;# clone github repo&#xA;git clone https://github.com/lightaime/camel.git&#xA;# change directory into project directory&#xA;cd camel&#xA;# install camel from source&#xA;pre-commit install&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;You can find a list of tasks for different set of assistant and user role pairs &lt;a href=&#34;https://drive.google.com/file/d/194PPaSTBR07m-PzjS-Ty6KlPLdFIPQDd/view?usp=share_link&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Run the &lt;code&gt;role_playing.py&lt;/code&gt; script.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# export your OpenAI API key&#xA;export OPENAI_API_KEY=&amp;lt;insert your OpenAI API key&amp;gt;&#xA;# You can change the role pair and initial prompt in role_playing.py&#xA;python examples/ai_society/role_playing.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Data (Hosted on Hugging Face)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Chat format&lt;/th&gt; &#xA;   &lt;th&gt;Instruction format&lt;/th&gt; &#xA;   &lt;th&gt;Chat format (translated)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;AI Society&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/camel-ai/ai_society/blob/main/ai_society_chat.tar.gz&#34;&gt;Chat format&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/camel-ai/ai_society/blob/main/ai_society_instructions.json&#34;&gt;Instruction format&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/camel-ai/ai_society_translated&#34;&gt;Chat format (translated)&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/camel-ai/code/blob/main/code_chat.tar.gz&#34;&gt;Chat format&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/camel-ai/code/blob/main/code_instructions.json&#34;&gt;Instruction format&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Math&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/camel-ai/math/blob/main/math50k.zip&#34;&gt;Chat format&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;x&lt;/td&gt; &#xA;   &lt;td&gt;x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Physics&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/camel-ai/physics&#34;&gt;Chat format&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;x&lt;/td&gt; &#xA;   &lt;td&gt;x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Chemistry&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/camel-ai/chemistry&#34;&gt;Chat format&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;x&lt;/td&gt; &#xA;   &lt;td&gt;x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Biology&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/camel-ai/biology&#34;&gt;Chat format&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;x&lt;/td&gt; &#xA;   &lt;td&gt;x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Visualizations of Instructions and Tasks&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Instructions&lt;/th&gt; &#xA;   &lt;th&gt;Tasks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;AI Society&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://atlas.nomic.ai/map/3a559a06-87d0-4476-a879-962656242452/db961915-b254-48e8-8e5c-917f827b74c6&#34;&gt;Instructions&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://atlas.nomic.ai/map/cb96f41b-a6fd-4fe4-ac40-08e101714483/ae06156c-a572-46e9-8345-ebe18586d02b&#34;&gt;Tasks&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://atlas.nomic.ai/map/902d6ccb-0bbb-4294-83a8-1c7d2dae03c8/ace2e146-e49f-41db-a1f4-25a2c4be2457&#34;&gt;Instructions&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://atlas.nomic.ai/map/efc38617-9180-490a-8630-43a05b35d22d/2576addf-a133-45d5-89a9-6b067b6652dd&#34;&gt;Tasks&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Misalignment&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://atlas.nomic.ai/map/5c491035-a26e-4a05-9593-82ffb2c3ab40/2bd98896-894e-4807-9ed8-a203ccb14d5e&#34;&gt;Instructions&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://atlas.nomic.ai/map/abc357dd-9c04-4913-9541-63e259d7ac1f/825139a4-af66-427c-9d0e-f36b5492ab3f&#34;&gt;Tasks&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Released AI Society and Code dataset (April 2, 2023)&lt;/li&gt; &#xA; &lt;li&gt;Initial release of &lt;code&gt;CAMEL&lt;/code&gt; python library (March 21, 2023)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{camel,&#xA;  author = {Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, Bernard Ghanem},&#xA;  title = {CAMEL: Communicative Agents for “Mind” Exploration of Large Scale Language Model Society},&#xA;  year = {2023},&#xA;  journal={arXiv preprint},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;Special thanks to &lt;a href=&#34;https://home.nomic.ai/&#34;&gt;Nomic AI&lt;/a&gt; for giving us extended access to their data set exploration tool (Atlas).&lt;/p&gt; &#xA;&lt;p&gt;We would also like to thank Haya Hammoud for designing the logo of our project.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The intended purpose and licensing of CAMEL is solely for research use.&lt;/p&gt; &#xA;&lt;p&gt;The source code is licensed under Apache 2.0.&lt;/p&gt; &#xA;&lt;p&gt;The datasets are licensed under CC BY NC 4.0, which permits only non-commercial usage. It is advised that any models trained using the dataset should not be utilized for anything other than research purposes.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;For more information please contact &lt;a href=&#34;https://ghli.org/&#34;&gt;Guohao Li&lt;/a&gt;, &lt;a href=&#34;https://cemse.kaust.edu.sa/ece/people/person/hasan-abed-al-kader-hammoud&#34;&gt;Hasan Abed Al Kader Hammoud&lt;/a&gt;, &lt;a href=&#34;https://github.com/HaniItani&#34;&gt;Hani Itani&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>openai/consistency_models</title>
    <updated>2023-04-23T02:00:59Z</updated>
    <id>tag:github.com,2023-04-23:/openai/consistency_models</id>
    <link href="https://github.com/openai/consistency_models" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official repo for consistency models.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Consistency Models&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the codebase for &lt;a href=&#34;https://arxiv.org/abs/2303.01469&#34;&gt;Consistency Models&lt;/a&gt;, implemented using PyTorch for conducting large-scale experiments on ImageNet-64, LSUN Bedroom-256, and LSUN Cat-256. We have based our repository on &lt;a href=&#34;https://github.com/openai/guided-diffusion&#34;&gt;openai/guided-diffusion&lt;/a&gt;, which was initially released under the MIT license. Our modifications have enabled support for consistency distillation, consistency training, as well as several sampling and editing algorithms discussed in the paper.&lt;/p&gt; &#xA;&lt;p&gt;The repository for CIFAR-10 experiments is in JAX and will be released separately.&lt;/p&gt; &#xA;&lt;h1&gt;Pre-trained models&lt;/h1&gt; &#xA;&lt;p&gt;We have released checkpoints for the main models in the paper. Before using these models, please review the corresponding &lt;a href=&#34;https://raw.githubusercontent.com/openai/consistency_models/main/model-card.md&#34;&gt;model card&lt;/a&gt; to understand the intended use and limitations of these models.&lt;/p&gt; &#xA;&lt;p&gt;Here are the download links for each model checkpoint:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;EDM on ImageNet-64: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/edm_imagenet64_ema.pt&#34;&gt;edm_imagenet64_ema.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CD on ImageNet-64 with l2 metric: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/cd_imagenet64_l2.pt&#34;&gt;cd_imagenet64_l2.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CD on ImageNet-64 with LPIPS metric: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/cd_imagenet64_lpips.pt&#34;&gt;cd_imagenet64_lpips.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CT on ImageNet-64: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/ct_imagenet64.pt&#34;&gt;ct_imagenet64.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;EDM on LSUN Bedroom-256: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/edm_bedroom256_ema.pt&#34;&gt;edm_bedroom256_ema.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CD on LSUN Bedroom-256 with l2 metric: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/cd_bedroom256_l2.pt&#34;&gt;cd_bedroom256_l2.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CD on LSUN Bedroom-256 with LPIPS metric: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/cd_bedroom256_lpips.pt&#34;&gt;cd_bedroom256_lpips.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CT on LSUN Bedroom-256: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/ct_bedroom256.pt&#34;&gt;ct_bedroom256.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;EDM on LSUN Cat-256: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/edm_cat256_ema.pt&#34;&gt;edm_cat256_ema.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CD on LSUN Cat-256 with l2 metric: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/cd_cat256_l2.pt&#34;&gt;cd_cat256_l2.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CD on LSUN Cat-256 with LPIPS metric: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/cd_cat256_lpips.pt&#34;&gt;cd_cat256_lpips.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CT on LSUN Cat-256: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/ct_cat256.pt&#34;&gt;ct_cat256.pt&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Dependencies&lt;/h1&gt; &#xA;&lt;p&gt;To install all packages in this codebase along with their dependencies, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Model training and sampling&lt;/h1&gt; &#xA;&lt;p&gt;We provide examples of EDM training, consistency distillation, consistency training, single-step generation, and multistep generation in &lt;a href=&#34;https://raw.githubusercontent.com/openai/consistency_models/main/scripts/launch.sh&#34;&gt;cm/scripts/launch.sh&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Evaluations&lt;/h1&gt; &#xA;&lt;p&gt;To compare different generative models, we use FID, Precision, Recall, and Inception Score. These metrics can all be calculated using batches of samples stored in &lt;code&gt;.npz&lt;/code&gt; (numpy) files. One can evaluate samples with &lt;a href=&#34;https://raw.githubusercontent.com/openai/consistency_models/main/evaluations/evaluator.py&#34;&gt;cm/evaluations/evaluator.py&lt;/a&gt; in the same way as described in &lt;a href=&#34;https://github.com/openai/guided-diffusion&#34;&gt;openai/guided-diffusion&lt;/a&gt;, with reference dataset batches provided therein.&lt;/p&gt; &#xA;&lt;h1&gt;Citation&lt;/h1&gt; &#xA;&lt;p&gt;If you find this method and/or code useful, please consider citing&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{song2023consistency,&#xA;  title={Consistency Models},&#xA;  author={Song, Yang and Dhariwal, Prafulla and Chen, Mark and Sutskever, Ilya},&#xA;  journal={arXiv preprint arXiv:2303.01469},&#xA;  year={2023},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>