<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-08-04T01:43:37Z</updated>
  <subtitle>Weekly Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>lllyasviel/stable-diffusion-webui-forge</title>
    <updated>2024-08-04T01:43:37Z</updated>
    <id>tag:github.com,2024-08-04:/lllyasviel/stable-diffusion-webui-forge</id>
    <link href="https://github.com/lllyasviel/stable-diffusion-webui-forge" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Under Construction&lt;/h1&gt; &#xA;&lt;p&gt;WebUI Forge is under a week of major revision right now between 2024 Aug 1 and Aug 7. To join the test, just update to the latest unstable version.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Current Progress (2024 Aug 3):&lt;/strong&gt; Backend Rewrite is 80% finished - remaining 30 hours to begin making it stable; remaining 48 hours to begin supporting many new things.&lt;/p&gt; &#xA;&lt;p&gt;For downloading previous versions, see &lt;a href=&#34;https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/849&#34;&gt;Previous Versions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Stable Diffusion WebUI Forge&lt;/h1&gt; &#xA;&lt;p&gt;Stable Diffusion WebUI Forge is a platform on top of &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;Stable Diffusion WebUI&lt;/a&gt; (based on &lt;a href=&#34;https://www.gradio.app/&#34;&gt;Gradio&lt;/a&gt;) to make development easier, optimize resource management, speed up inference, and study experimental features.&lt;/p&gt; &#xA;&lt;p&gt;The name &#34;Forge&#34; is inspired from &#34;Minecraft Forge&#34;. This project is aimed at becoming SD WebUI&#39;s Forge.&lt;/p&gt; &#xA;&lt;p&gt;Forge is currently based on SD-WebUI 1.10.1 at &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/82a973c04367123ae98bd9abdf80d9eda9b910e2&#34;&gt;this commit&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Installing Forge&lt;/h1&gt; &#xA;&lt;p&gt;If you are proficient in Git and you want to install Forge as another branch of SD-WebUI, please see &lt;a href=&#34;https://github.com/continue-revolution/sd-webui-animatediff/raw/forge/master/docs/how-to-use.md#you-have-a1111-and-you-know-git&#34;&gt;here&lt;/a&gt;. In this way, you can reuse all SD checkpoints and all extensions you installed previously in your OG SD-WebUI, but you should know what you are doing.&lt;/p&gt; &#xA;&lt;p&gt;If you know what you are doing, you can install Forge using same method as SD-WebUI. (Install Git, Python, Git Clone the forge repo &lt;code&gt;https://github.com/lllyasviel/stable-diffusion-webui-forge.git&lt;/code&gt; and then run webui-user.bat).&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Or you can just use this one-click installation package (with git and python included).&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/download/latest/webui_forge_cu121_torch21.7z&#34;&gt;&amp;gt;&amp;gt;&amp;gt; Click Here to Download One-Click Package &amp;lt;&amp;lt;&amp;lt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;After you download, you uncompress, use &lt;code&gt;update.bat&lt;/code&gt; to update, and use &lt;code&gt;run.bat&lt;/code&gt; to run.&lt;/p&gt; &#xA;&lt;p&gt;Note that running &lt;code&gt;update.bat&lt;/code&gt; is important, otherwise you may be using a previous version with potential bugs unfixed.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/lllyasviel/stable-diffusion-webui-forge/assets/19834515/c49bd60d-82bd-4086-9859-88d472582b94&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Previous Versions&lt;/h3&gt; &#xA;&lt;p&gt;You can download previous versions &lt;a href=&#34;https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/849&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Forge Status&lt;/h1&gt; &#xA;&lt;p&gt;Based on manual test one-by-one:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Component&lt;/th&gt; &#xA;   &lt;th&gt;Status&lt;/th&gt; &#xA;   &lt;th&gt;Last Test&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Basic Diffusion&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPU Memory Management System&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRAs&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;All Preprocessors&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;All ControlNets&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;All IP-Adapters&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;All Instant-IDs&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;All Reference-only Methods&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;All Integrated Extensions&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Popular Extensions (Adetailer, etc)&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gradio 4 UIs&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gradio 4 Forge Canvas&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRA/Checkpoint Selection UI for Gradio 4&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Photopea/OpenposeEditor/etc for ControlNet&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Wacom 128 level touch pressure support for Canvas&lt;/td&gt; &#xA;   &lt;td&gt;Normal&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 15&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Microsoft Surface touch pressure support for Canvas&lt;/td&gt; &#xA;   &lt;td&gt;Broken, pending fix&lt;/td&gt; &#xA;   &lt;td&gt;2024 July 29&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Feel free to open issue if anything is broken and I will take a look every several days. If I do not update this &#34;Forge Status&#34; then it means I cannot reproduce any problem. In that case, fresh re-install should help most.&lt;/p&gt; &#xA;&lt;h1&gt;Under Construction&lt;/h1&gt; &#xA;&lt;p&gt;This Readme is under construction ... more docs/wiki coming soon ...&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>meta-llama/llama</title>
    <updated>2024-08-04T01:43:37Z</updated>
    <id>tag:github.com,2024-08-04:/meta-llama/llama</id>
    <link href="https://github.com/meta-llama/llama" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Inference code for Llama models&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;&lt;strong&gt;Note of deprecation&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Thank you for developing with Llama models. As part of the Llama 3.1 release, we’ve consolidated GitHub repos and added some additional repos as we’ve expanded Llama’s functionality into being an e2e Llama Stack. Please use the following repos going forward:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-models&#34;&gt;llama-models&lt;/a&gt; - Central repo for the foundation models including basic utilities, model cards, license and use policies&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/PurpleLlama&#34;&gt;PurpleLlama&lt;/a&gt; - Key component of Llama Stack focusing on safety risks and inference time mitigations&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-toolchain&#34;&gt;llama-toolchain&lt;/a&gt; - Model development (inference/fine-tuning/safety shields/synthetic data generation) interfaces and canonical implementations&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-agentic-system&#34;&gt;llama-agentic-system&lt;/a&gt; - E2E standalone Llama Stack system, along with opinionated underlying interface, that enables creation of agentic applications&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-recipes&#34;&gt;llama-recipes&lt;/a&gt; - Community driven scripts and integrations&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you have any questions, please feel free to file an issue on any of the above repos and we will do our best to respond in a timely manner.&lt;/p&gt; &#xA;&lt;p&gt;Thank you!&lt;/p&gt; &#xA;&lt;h1&gt;(Deprecated) Llama 2&lt;/h1&gt; &#xA;&lt;p&gt;We are unlocking the power of large language models. Llama 2 is now accessible to individuals, creators, researchers, and businesses of all sizes so that they can experiment, innovate, and scale their ideas responsibly.&lt;/p&gt; &#xA;&lt;p&gt;This release includes model weights and starting code for pre-trained and fine-tuned Llama language models — ranging from 7B to 70B parameters.&lt;/p&gt; &#xA;&lt;p&gt;This repository is intended as a minimal example to load &lt;a href=&#34;https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/&#34;&gt;Llama 2&lt;/a&gt; models and run inference. For more detailed examples leveraging Hugging Face, see &lt;a href=&#34;https://github.com/facebookresearch/llama-recipes/&#34;&gt;llama-recipes&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Updates post-launch&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama/main/UPDATES.md&#34;&gt;UPDATES.md&lt;/a&gt;. Also for a running list of frequently asked questions, see &lt;a href=&#34;https://ai.meta.com/llama/faq/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Download&lt;/h2&gt; &#xA;&lt;p&gt;In order to download the model weights and tokenizer, please visit the &lt;a href=&#34;https://ai.meta.com/resources/models-and-libraries/llama-downloads/&#34;&gt;Meta website&lt;/a&gt; and accept our License.&lt;/p&gt; &#xA;&lt;p&gt;Once your request is approved, you will receive a signed URL over email. Then run the download.sh script, passing the URL provided when prompted to start the download.&lt;/p&gt; &#xA;&lt;p&gt;Pre-requisites: Make sure you have &lt;code&gt;wget&lt;/code&gt; and &lt;code&gt;md5sum&lt;/code&gt; installed. Then run the script: &lt;code&gt;./download.sh&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Keep in mind that the links expire after 24 hours and a certain amount of downloads. If you start seeing errors such as &lt;code&gt;403: Forbidden&lt;/code&gt;, you can always re-request a link.&lt;/p&gt; &#xA;&lt;h3&gt;Access to Hugging Face&lt;/h3&gt; &#xA;&lt;p&gt;We are also providing downloads on &lt;a href=&#34;https://huggingface.co/meta-llama&#34;&gt;Hugging Face&lt;/a&gt;. You can request access to the models by acknowledging the license and filling the form in the model card of a repo. After doing so, you should get access to all the Llama models of a version (Code Llama, Llama 2, or Llama Guard) within 1 hour.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;You can follow the steps below to quickly get up and running with Llama 2 models. These steps will let you run quick inference locally. For more examples, see the &lt;a href=&#34;https://github.com/facebookresearch/llama-recipes&#34;&gt;Llama 2 recipes repository&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;In a conda env with PyTorch / CUDA available clone and download this repository.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;In the top-level directory run:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Visit the &lt;a href=&#34;https://ai.meta.com/resources/models-and-libraries/llama-downloads/&#34;&gt;Meta website&lt;/a&gt; and register to download the model/s.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Once registered, you will get an email with a URL to download the models. You will need this URL when you run the download.sh script.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Once you get the email, navigate to your downloaded llama repository and run the download.sh script.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Make sure to grant execution permissions to the download.sh script&lt;/li&gt; &#xA;   &lt;li&gt;During this process, you will be prompted to enter the URL from the email.&lt;/li&gt; &#xA;   &lt;li&gt;Do not use the “Copy Link” option but rather make sure to manually copy the link from the email.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Once the model/s you want have been downloaded, you can run the model locally using the command below:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;torchrun --nproc_per_node 1 example_chat_completion.py \&#xA;    --ckpt_dir llama-2-7b-chat/ \&#xA;    --tokenizer_path tokenizer.model \&#xA;    --max_seq_len 512 --max_batch_size 6&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Replace &lt;code&gt;llama-2-7b-chat/&lt;/code&gt; with the path to your checkpoint directory and &lt;code&gt;tokenizer.model&lt;/code&gt; with the path to your tokenizer model.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;code&gt;–nproc_per_node&lt;/code&gt; should be set to the &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama/main/#inference&#34;&gt;MP&lt;/a&gt; value for the model you are using.&lt;/li&gt; &#xA; &lt;li&gt;Adjust the &lt;code&gt;max_seq_len&lt;/code&gt; and &lt;code&gt;max_batch_size&lt;/code&gt; parameters as needed.&lt;/li&gt; &#xA; &lt;li&gt;This example runs the &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama/main/example_chat_completion.py&#34;&gt;example_chat_completion.py&lt;/a&gt; found in this repository but you can change that to a different .py file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;p&gt;Different models require different model-parallel (MP) values:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;MP&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;13B&lt;/td&gt; &#xA;   &lt;td&gt;2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;70B&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;All models support sequence length up to 4096 tokens, but we pre-allocate the cache according to &lt;code&gt;max_seq_len&lt;/code&gt; and &lt;code&gt;max_batch_size&lt;/code&gt; values. So set those according to your hardware.&lt;/p&gt; &#xA;&lt;h3&gt;Pretrained Models&lt;/h3&gt; &#xA;&lt;p&gt;These models are not finetuned for chat or Q&amp;amp;A. They should be prompted so that the expected answer is the natural continuation of the prompt.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;code&gt;example_text_completion.py&lt;/code&gt; for some examples. To illustrate, see the command below to run it with the llama-2-7b model (&lt;code&gt;nproc_per_node&lt;/code&gt; needs to be set to the &lt;code&gt;MP&lt;/code&gt; value):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;torchrun --nproc_per_node 1 example_text_completion.py \&#xA;    --ckpt_dir llama-2-7b/ \&#xA;    --tokenizer_path tokenizer.model \&#xA;    --max_seq_len 128 --max_batch_size 4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Fine-tuned Chat Models&lt;/h3&gt; &#xA;&lt;p&gt;The fine-tuned models were trained for dialogue applications. To get the expected features and performance for them, a specific formatting defined in &lt;a href=&#34;https://github.com/facebookresearch/llama/raw/main/llama/generation.py#L212&#34;&gt;&lt;code&gt;chat_completion&lt;/code&gt;&lt;/a&gt; needs to be followed, including the &lt;code&gt;INST&lt;/code&gt; and &lt;code&gt;&amp;lt;&amp;lt;SYS&amp;gt;&amp;gt;&lt;/code&gt; tags, &lt;code&gt;BOS&lt;/code&gt; and &lt;code&gt;EOS&lt;/code&gt; tokens, and the whitespaces and breaklines in between (we recommend calling &lt;code&gt;strip()&lt;/code&gt; on inputs to avoid double-spaces).&lt;/p&gt; &#xA;&lt;p&gt;You can also deploy additional classifiers for filtering out inputs and outputs that are deemed unsafe. See the llama-recipes repo for &lt;a href=&#34;https://github.com/facebookresearch/llama-recipes/raw/main/examples/inference.py&#34;&gt;an example&lt;/a&gt; of how to add a safety checker to the inputs and outputs of your inference code.&lt;/p&gt; &#xA;&lt;p&gt;Examples using llama-2-7b-chat:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;torchrun --nproc_per_node 1 example_chat_completion.py \&#xA;    --ckpt_dir llama-2-7b-chat/ \&#xA;    --tokenizer_path tokenizer.model \&#xA;    --max_seq_len 512 --max_batch_size 6&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Llama 2 is a new technology that carries potential risks with use. Testing conducted to date has not — and could not — cover all scenarios. In order to help developers address these risks, we have created the &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama/main/Responsible-Use-Guide.pdf&#34;&gt;Responsible Use Guide&lt;/a&gt;. More details can be found in our research paper as well.&lt;/p&gt; &#xA;&lt;h2&gt;Issues&lt;/h2&gt; &#xA;&lt;p&gt;Please report any software “bug”, or other problems with the models through one of the following means:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Reporting issues with the model: &lt;a href=&#34;http://github.com/facebookresearch/llama&#34;&gt;github.com/facebookresearch/llama&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Reporting risky content generated by the model: &lt;a href=&#34;http://developers.facebook.com/llama_output_feedback&#34;&gt;developers.facebook.com/llama_output_feedback&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Reporting bugs and security concerns: &lt;a href=&#34;http://facebook.com/whitehat/info&#34;&gt;facebook.com/whitehat/info&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Model Card&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama/main/MODEL_CARD.md&#34;&gt;MODEL_CARD.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Our model and weights are licensed for both researchers and commercial entities, upholding the principles of openness. Our mission is to empower individuals, and industry through this opportunity, while fostering an environment of discovery and ethical AI advancements.&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file, as well as our accompanying &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama/main/USE_POLICY.md&#34;&gt;Acceptable Use Policy&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/&#34;&gt;Research Paper&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.meta.com/resources/models-and-libraries/llama&#34;&gt;Llama 2 technical overview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.meta.com/llama/open-innovation-ai-research-community/&#34;&gt;Open Innovation AI Research Community&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For common questions, the FAQ can be found &lt;a href=&#34;https://ai.meta.com/llama/faq/&#34;&gt;here&lt;/a&gt; which will be kept up to date over time as new questions arise.&lt;/p&gt; &#xA;&lt;h2&gt;Original Llama&lt;/h2&gt; &#xA;&lt;p&gt;The repo for the original llama release is in the &lt;a href=&#34;https://github.com/facebookresearch/llama/tree/llama_v1&#34;&gt;&lt;code&gt;llama_v1&lt;/code&gt;&lt;/a&gt; branch.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>freqtrade/freqtrade</title>
    <updated>2024-08-04T01:43:37Z</updated>
    <id>tag:github.com,2024-08-04:/freqtrade/freqtrade</id>
    <link href="https://github.com/freqtrade/freqtrade" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Free, open source crypto trading bot&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade_poweredby.svg?sanitize=true&#34; alt=&#34;freqtrade&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/freqtrade/freqtrade/actions/&#34;&gt;&lt;img src=&#34;https://github.com/freqtrade/freqtrade/workflows/Freqtrade%20CI/badge.svg?sanitize=true&#34; alt=&#34;Freqtrade CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.21105/joss.04864&#34;&gt;&lt;img src=&#34;https://joss.theoj.org/papers/10.21105/joss.04864/status.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://coveralls.io/github/freqtrade/freqtrade?branch=develop&#34;&gt;&lt;img src=&#34;https://coveralls.io/repos/github/freqtrade/freqtrade/badge.svg?branch=develop&amp;amp;service=github&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.freqtrade.io&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/freqtrade/badge/&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codeclimate.com/github/freqtrade/freqtrade/maintainability&#34;&gt;&lt;img src=&#34;https://api.codeclimate.com/v1/badges/5737e6d668200b7518ff/maintainability&#34; alt=&#34;Maintainability&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Freqtrade is a free and open source crypto trading bot written in Python. It is designed to support all major exchanges and be controlled via Telegram or webUI. It contains backtesting, plotting and money management tools as well as strategy optimization by machine learning.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade-screenshot.png&#34; alt=&#34;freqtrade&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This software is for educational purposes only. Do not risk money which you are afraid to lose. USE THE SOFTWARE AT YOUR OWN RISK. THE AUTHORS AND ALL AFFILIATES ASSUME NO RESPONSIBILITY FOR YOUR TRADING RESULTS.&lt;/p&gt; &#xA;&lt;p&gt;Always start by running a trading bot in Dry-run and do not engage money before you understand how it works and what profit/loss you should expect.&lt;/p&gt; &#xA;&lt;p&gt;We strongly recommend you to have coding and Python knowledge. Do not hesitate to read the source code and understand the mechanism of this bot.&lt;/p&gt; &#xA;&lt;h2&gt;Supported Exchange marketplaces&lt;/h2&gt; &#xA;&lt;p&gt;Please read the &lt;a href=&#34;https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/exchanges.md&#34;&gt;exchange specific notes&lt;/a&gt; to learn about eventual, special configurations needed for each exchange.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.binance.com/&#34;&gt;Binance&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://bitmart.com/&#34;&gt;Bitmart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://bingx.com/invite/0EM9RX&#34;&gt;BingX&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.gate.io/ref/6266643&#34;&gt;Gate.io&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.htx.com/&#34;&gt;HTX&lt;/a&gt; (Former Huobi)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://kraken.com/&#34;&gt;Kraken&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://okx.com/&#34;&gt;OKX&lt;/a&gt; (Former OKEX)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/ccxt/ccxt/&#34;&gt;potentially many others&lt;/a&gt;. &lt;em&gt;(We cannot guarantee they will work)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Supported Futures Exchanges (experimental)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.binance.com/&#34;&gt;Binance&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.gate.io/ref/6266643&#34;&gt;Gate.io&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://okx.com/&#34;&gt;OKX&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://bybit.com/&#34;&gt;Bybit&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please make sure to read the &lt;a href=&#34;https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/exchanges.md&#34;&gt;exchange specific notes&lt;/a&gt;, as well as the &lt;a href=&#34;https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/leverage.md&#34;&gt;trading with leverage&lt;/a&gt; documentation before diving in.&lt;/p&gt; &#xA;&lt;h3&gt;Community tested&lt;/h3&gt; &#xA;&lt;p&gt;Exchanges confirmed working by the community:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://bitvavo.com/&#34;&gt;Bitvavo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.kucoin.com/&#34;&gt;Kucoin&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;We invite you to read the bot documentation to ensure you understand how the bot is working.&lt;/p&gt; &#xA;&lt;p&gt;Please find the complete documentation on the &lt;a href=&#34;https://www.freqtrade.io&#34;&gt;freqtrade website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Based on Python 3.9+&lt;/strong&gt;: For botting on any operating system - Windows, macOS and Linux.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Persistence&lt;/strong&gt;: Persistence is achieved through sqlite.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Dry-run&lt;/strong&gt;: Run the bot without paying money.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Backtesting&lt;/strong&gt;: Run a simulation of your buy/sell strategy.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Strategy Optimization by machine learning&lt;/strong&gt;: Use machine learning to optimize your buy/sell strategy parameters with real exchange data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Adaptive prediction modeling&lt;/strong&gt;: Build a smart strategy with FreqAI that self-trains to the market via adaptive machine learning methods. &lt;a href=&#34;https://www.freqtrade.io/en/stable/freqai/&#34;&gt;Learn more&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Edge position sizing&lt;/strong&gt; Calculate your win rate, risk reward ratio, the best stoploss and adjust your position size before taking a position for each specific market. &lt;a href=&#34;https://www.freqtrade.io/en/stable/edge/&#34;&gt;Learn more&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Whitelist crypto-currencies&lt;/strong&gt;: Select which crypto-currency you want to trade or use dynamic whitelists.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Blacklist crypto-currencies&lt;/strong&gt;: Select which crypto-currency you want to avoid.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Builtin WebUI&lt;/strong&gt;: Builtin web UI to manage your bot.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Manageable via Telegram&lt;/strong&gt;: Manage the bot with Telegram.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Display profit/loss in fiat&lt;/strong&gt;: Display your profit/loss in fiat currency.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Performance status report&lt;/strong&gt;: Provide a performance status of your current trades.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quick start&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://www.freqtrade.io/en/stable/docker_quickstart/&#34;&gt;Docker Quickstart documentation&lt;/a&gt; on how to get started quickly.&lt;/p&gt; &#xA;&lt;p&gt;For further (native) installation methods, please refer to the &lt;a href=&#34;https://www.freqtrade.io/en/stable/installation/&#34;&gt;Installation documentation page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Basic Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Bot commands&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;usage: freqtrade [-h] [-V]&#xA;                 {trade,create-userdir,new-config,new-strategy,download-data,convert-data,convert-trade-data,list-data,backtesting,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-hyperopts,list-markets,list-pairs,list-strategies,list-timeframes,show-trades,test-pairlist,install-ui,plot-dataframe,plot-profit,webserver}&#xA;                 ...&#xA;&#xA;Free, open source crypto trading bot&#xA;&#xA;positional arguments:&#xA;  {trade,create-userdir,new-config,new-strategy,download-data,convert-data,convert-trade-data,list-data,backtesting,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-hyperopts,list-markets,list-pairs,list-strategies,list-timeframes,show-trades,test-pairlist,install-ui,plot-dataframe,plot-profit,webserver}&#xA;    trade               Trade module.&#xA;    create-userdir      Create user-data directory.&#xA;    new-config          Create new config&#xA;    new-strategy        Create new strategy&#xA;    download-data       Download backtesting data.&#xA;    convert-data        Convert candle (OHLCV) data from one format to&#xA;                        another.&#xA;    convert-trade-data  Convert trade data from one format to another.&#xA;    list-data           List downloaded data.&#xA;    backtesting         Backtesting module.&#xA;    edge                Edge module.&#xA;    hyperopt            Hyperopt module.&#xA;    hyperopt-list       List Hyperopt results&#xA;    hyperopt-show       Show details of Hyperopt results&#xA;    list-exchanges      Print available exchanges.&#xA;    list-hyperopts      Print available hyperopt classes.&#xA;    list-markets        Print markets on exchange.&#xA;    list-pairs          Print pairs on exchange.&#xA;    list-strategies     Print available strategies.&#xA;    list-timeframes     Print available timeframes for the exchange.&#xA;    show-trades         Show trades.&#xA;    test-pairlist       Test your pairlist configuration.&#xA;    install-ui          Install FreqUI&#xA;    plot-dataframe      Plot candles with indicators.&#xA;    plot-profit         Generate plot showing profits.&#xA;    webserver           Webserver module.&#xA;&#xA;optional arguments:&#xA;  -h, --help            show this help message and exit&#xA;  -V, --version         show program&#39;s version number and exit&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Telegram RPC commands&lt;/h3&gt; &#xA;&lt;p&gt;Telegram is not mandatory. However, this is a great way to control your bot. More details and the full command list on the &lt;a href=&#34;https://www.freqtrade.io/en/latest/telegram-usage/&#34;&gt;documentation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;/start&lt;/code&gt;: Starts the trader.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/stop&lt;/code&gt;: Stops the trader.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/stopentry&lt;/code&gt;: Stop entering new trades.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/status &amp;lt;trade_id&amp;gt;|[table]&lt;/code&gt;: Lists all or specific open trades.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/profit [&amp;lt;n&amp;gt;]&lt;/code&gt;: Lists cumulative profit from all finished trades, over the last n days.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/forceexit &amp;lt;trade_id&amp;gt;|all&lt;/code&gt;: Instantly exits the given trade (Ignoring &lt;code&gt;minimum_roi&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/fx &amp;lt;trade_id&amp;gt;|all&lt;/code&gt;: Alias to &lt;code&gt;/forceexit&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/performance&lt;/code&gt;: Show performance of each finished trade grouped by pair&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/balance&lt;/code&gt;: Show account balance per currency.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/daily &amp;lt;n&amp;gt;&lt;/code&gt;: Shows profit or loss per day, over the last n days.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/help&lt;/code&gt;: Show help message.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/version&lt;/code&gt;: Show version.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Development branches&lt;/h2&gt; &#xA;&lt;p&gt;The project is currently setup in two main branches:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; - This branch has often new features, but might also contain breaking changes. We try hard to keep this branch as stable as possible.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;stable&lt;/code&gt; - This branch contains the latest stable release. This branch is generally well tested.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;feat/*&lt;/code&gt; - These are feature branches, which are being worked on heavily. Please don&#39;t use these unless you want to test a specific feature.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;h3&gt;Help / Discord&lt;/h3&gt; &#xA;&lt;p&gt;For any questions not covered by the documentation or for further information about the bot, or to simply engage with like-minded individuals, we encourage you to join the Freqtrade &lt;a href=&#34;https://discord.gg/p7nuUNVfP7&#34;&gt;discord server&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue&#34;&gt;Bugs / Issues&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;If you discover a bug in the bot, please &lt;a href=&#34;https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue&#34;&gt;search the issue tracker&lt;/a&gt; first. If it hasn&#39;t been reported, please &lt;a href=&#34;https://github.com/freqtrade/freqtrade/issues/new/choose&#34;&gt;create a new issue&lt;/a&gt; and ensure you follow the template guide so that the team can assist you as quickly as possible.&lt;/p&gt; &#xA;&lt;p&gt;For every &lt;a href=&#34;https://github.com/freqtrade/freqtrade/issues/new/choose&#34;&gt;issue&lt;/a&gt; created, kindly follow up and mark satisfaction or reminder to close issue when equilibrium ground is reached.&lt;/p&gt; &#xA;&lt;p&gt;--Maintain github&#39;s &lt;a href=&#34;https://docs.github.com/en/site-policy/github-terms/github-community-code-of-conduct&#34;&gt;community policy&lt;/a&gt;--&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/freqtrade/freqtrade/labels/enhancement&#34;&gt;Feature Requests&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Have you a great idea to improve the bot you want to share? Please, first search if this feature was not &lt;a href=&#34;https://github.com/freqtrade/freqtrade/labels/enhancement&#34;&gt;already discussed&lt;/a&gt;. If it hasn&#39;t been requested, please &lt;a href=&#34;https://github.com/freqtrade/freqtrade/issues/new/choose&#34;&gt;create a new request&lt;/a&gt; and ensure you follow the template guide so that it does not get lost in the bug reports.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/freqtrade/freqtrade/pulls&#34;&gt;Pull Requests&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Feel like the bot is missing a feature? We welcome your pull requests!&lt;/p&gt; &#xA;&lt;p&gt;Please read the &lt;a href=&#34;https://github.com/freqtrade/freqtrade/raw/develop/CONTRIBUTING.md&#34;&gt;Contributing document&lt;/a&gt; to understand the requirements before sending your pull-requests.&lt;/p&gt; &#xA;&lt;p&gt;Coding is not a necessity to contribute - maybe start with improving the documentation? Issues labeled &lt;a href=&#34;https://github.com/freqtrade/freqtrade/labels/good%20first%20issue&#34;&gt;good first issue&lt;/a&gt; can be good first contributions, and will help get you familiar with the codebase.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; before starting any major new feature work, &lt;em&gt;please open an issue describing what you are planning to do&lt;/em&gt; or talk to us on &lt;a href=&#34;https://discord.gg/p7nuUNVfP7&#34;&gt;discord&lt;/a&gt; (please use the #dev channel for this). This will ensure that interested parties can give valuable feedback on the feature, and let others know that you are working on it.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Always create your PR against the &lt;code&gt;develop&lt;/code&gt; branch, not &lt;code&gt;stable&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;h3&gt;Up-to-date clock&lt;/h3&gt; &#xA;&lt;p&gt;The clock must be accurate, synchronized to a NTP server very frequently to avoid problems with communication to the exchanges.&lt;/p&gt; &#xA;&lt;h3&gt;Minimum hardware required&lt;/h3&gt; &#xA;&lt;p&gt;To run this bot we recommend you a cloud instance with a minimum of:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Minimal (advised) system requirements: 2GB RAM, 1GB disk space, 2vCPU&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Software requirements&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://docs.python-guide.org/en/latest/starting/installation/&#34;&gt;Python &amp;gt;= 3.9&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pip.pypa.io/en/stable/installing/&#34;&gt;pip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://git-scm.com/book/en/v2/Getting-Started-Installing-Git&#34;&gt;git&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ta-lib.github.io/ta-lib-python/&#34;&gt;TA-Lib&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://virtualenv.pypa.io/en/stable/installation.html&#34;&gt;virtualenv&lt;/a&gt; (Recommended)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.docker.com/products/docker&#34;&gt;Docker&lt;/a&gt; (Recommended)&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>