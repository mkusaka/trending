<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-04T01:40:03Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Sanster/IOPaint</title>
    <updated>2024-02-04T01:40:03Z</updated>
    <id>tag:github.com,2024-02-04:/Sanster/IOPaint</id>
    <link href="https://github.com/Sanster/IOPaint" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Image inpainting tool powered by SOTA AI Model. Remove any unwanted object, defect, people from your pictures or erase and replace(powered by stable diffusion) any thing on your pictures.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;IOPaint&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt;A free and open-source inpainting &amp;amp; outpainting tool powered by SOTA AI model.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/Sanster/IOPaint&#34;&gt; &lt;img alt=&#34;total download&#34; src=&#34;https://pepy.tech/badge/iopaint&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/iopaint&#34;&gt; &lt;img alt=&#34;version&#34; src=&#34;https://img.shields.io/pypi/v/iopaint&#34;&gt; &lt;/a&gt; &lt;a href=&#34;&#34;&gt; &lt;img alt=&#34;python version&#34; src=&#34;https://img.shields.io/pypi/pyversions/iopaint&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Erase&lt;/th&gt; &#xA;   &lt;th&gt;Replace Object&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#xA;    &lt;video src=&#34;https://github.com/Sanster/IOPaint/assets/3998421/264bc27c-0abd-4d8b-bb1e-0078ab264c4a&#34;&gt;&lt;/video&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;video src=&#34;https://github.com/Sanster/IOPaint/assets/3998421/1de5c288-e0e1-4f32-926d-796df0655846&#34;&gt;&lt;/video&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Draw Text&lt;/th&gt; &#xA;   &lt;th&gt;Out-painting&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#xA;    &lt;video src=&#34;https://github.com/Sanster/IOPaint/assets/3998421/ffd4eda4-f7d4-4693-93d8-d2cd5aa7c6d6&#34;&gt;&lt;/video&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;video src=&#34;https://github.com/Sanster/IOPaint/assets/3998421/c4af8aef-8c29-49e0-96eb-0aae2f768da2&#34;&gt;&lt;/video&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;h3&gt;Start webui&lt;/h3&gt; &#xA;&lt;p&gt;IOPaint provides a convenient webui for using the latest AI models to edit your images. You can install and start IOPaint easily by running following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# In order to use GPU, install cuda version of pytorch first.&#xA;# pip3 install torch==2.1.2 torchvision==0.16.2 --index-url https://download.pytorch.org/whl/cu118&#xA;# AMD GPU users, please utilize the following command, only works on linux, as pytorch is not yet supported on Windows with ROCm.&#xA;# pip3 install torch==2.1.2 torchvision==0.16.2 --index-url https://download.pytorch.org/whl/rocm5.6&#xA;&#xA;pip3 install iopaint&#xA;iopaint start --model=lama --device=cpu --port=8080&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That&#39;s it, you can start using IOPaint by visiting &lt;a href=&#34;http://localhost:8080&#34;&gt;http://localhost:8080&lt;/a&gt; in your web browser.&lt;/p&gt; &#xA;&lt;h3&gt;Batch processing&lt;/h3&gt; &#xA;&lt;p&gt;You can also use IOPaint in the command line to batch process images:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;iopaint run --model=lama --device=cpu \&#xA;--input=/path/to/image_folder \&#xA;--mask=/path/to/mask_folder \&#xA;--output=output_dir&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;--input&lt;/code&gt; is the folder containing input images, &lt;code&gt;--mask&lt;/code&gt; is the folder containing corresponding mask images. When &lt;code&gt;--mask&lt;/code&gt; is a path to a mask file, all images will be processed using this mask.&lt;/p&gt; &#xA;&lt;p&gt;You can see more information about the available models and plugins supported by IOPaint below.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Completely free and open-source, fully self-hosted, support CPU &amp;amp; GPU &amp;amp; Apple Silicon&lt;/li&gt; &#xA; &lt;li&gt;Supports various AI models: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.iopaint.com/models#erase-models&#34;&gt;Erase models&lt;/a&gt;: These models can be used to remove unwanted object, defect, watermarks, people from image. I have also developed a macOS native app called &lt;a href=&#34;https://opticlean.io/&#34;&gt;OptiClean&lt;/a&gt; that provides this feature.&lt;/li&gt; &#xA;   &lt;li&gt;Stable Diffusion models: You can use any Stable Diffusion Inpainting(or normal) models from &lt;a href=&#34;https://huggingface.co/models?other=stable-diffusion&#34;&gt;Huggingface&lt;/a&gt; in IOPaint. Some popular used models include: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/runwayml/stable-diffusion-inpainting&#34;&gt;runwayml/stable-diffusion-inpainting&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/diffusers/stable-diffusion-xl-1.0-inpainting-0.1&#34;&gt;diffusers/stable-diffusion-xl-1.0-inpainting-0.1&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/andregn/Realistic_Vision_V3.0-inpainting&#34;&gt;andregn/Realistic_Vision_V3.0-inpainting&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/Lykon/dreamshaper-8-inpainting&#34;&gt;Lykon/dreamshaper-8-inpainting&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/Sanster/anything-4.0-inpainting&#34;&gt;Sanster/anything-4.0-inpainting&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/Sanster/PowerPaint-V1-stable-diffusion-inpainting&#34;&gt;Sanster/PowerPaint-V1-stable-diffusion-inpainting&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Other Diffusion models: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/Sanster/AnyText&#34;&gt;Sanster/AnyText&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/timbrooks/instruct-pix2pix&#34;&gt;timbrooks/instruct-pix2pix&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/Fantasy-Studio/Paint-by-Example&#34;&gt;Fantasy-Studio/Paint-by-Example&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder-inpaint&#34;&gt;kandinsky-community/kandinsky-2-2-decoder-inpaint&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Plugins &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://iopaint.com/plugins/interactive_seg&#34;&gt;Segment Anything&lt;/a&gt;: Accurate and fast interactive object segmentation&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://iopaint.com/plugins/rembg&#34;&gt;RemoveBG&lt;/a&gt;: Remove image background or generate masks for foreground objects&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://iopaint.com/plugins/anime_seg&#34;&gt;Anime Segmentation&lt;/a&gt;: Similar to RemoveBG, the model is specifically trained for anime images.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://iopaint.com/plugins/RealESRGAN&#34;&gt;RealESRGAN&lt;/a&gt;: Super Resolution&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://iopaint.com/plugins/GFPGAN&#34;&gt;GFPGAN&lt;/a&gt;: Face Restoration&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://iopaint.com/plugins/RestoreFormer&#34;&gt;RestoreFormer&lt;/a&gt;: Face Restoration&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://iopaint.com/file_manager&#34;&gt;FileManager&lt;/a&gt;: Browse your pictures conveniently and save them directly to the output directory.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>allenai/OLMo</title>
    <updated>2024-02-04T01:40:03Z</updated>
    <id>tag:github.com,2024-02-04:/allenai/OLMo</id>
    <link href="https://github.com/allenai/OLMo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Modeling, training, eval, and inference code for OLMo&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;!-- &lt;img src=&#34;https://github.com/allenai/OLMo/assets/8812459/774ac485-a535-4768-8f7c-db7be20f5cc3&#34; width=&#34;300&#34;/&gt; --&gt; &#xA; &lt;img src=&#34;https://allenai.org/olmo/olmo-7b-animation.gif&#34; alt=&#34;OLMo Logo&#34; width=&#34;800&#34; style=&#34;margin-left:&#39;auto&#39; margin-right:&#39;auto&#39; display:&#39;block&#39;&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;br&gt; &#xA; &lt;h1&gt;OLMo: Open Language Model&lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/allenai/OLMo/raw/main/LICENSE&#34;&gt; &lt;img alt=&#34;GitHub License&#34; src=&#34;https://img.shields.io/github/license/allenai/OLMo&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/allenai/OLMo/releases&#34;&gt; &lt;img alt=&#34;GitHub release&#34; src=&#34;https://img.shields.io/github/release/allenai/OLMo.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://arxiv.org/pdf/2402.00838.pdf&#34;&gt; &lt;img alt=&#34;Paper URL&#34; src=&#34;https://img.shields.io/badge/arxiv-2402.00838-blue&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;OLMo is a repository for training and using AI2&#39;s state-of-the-art open language models. It is built by scientists, for scientists.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;First install &lt;a href=&#34;https://pytorch.org&#34;&gt;PyTorch&lt;/a&gt; according to the instructions specific to your operating system.&lt;/p&gt; &#xA;&lt;p&gt;To install from source (recommended for training/fine-tuning) run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/allenai/OLMo.git&#xA;cd OLMo&#xA;pip install -e .[all]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Otherwise you can install the model code by itself directly from PyPI with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install ai2-olmo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Models overview&lt;/h2&gt; &#xA;&lt;p&gt;The core models in the OLMo family released so far are (all trained on the &lt;a href=&#34;https://huggingface.co/datasets/allenai/dolma&#34;&gt;Dolma dataset&lt;/a&gt;):&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Training Tokens&lt;/th&gt; &#xA;   &lt;th&gt;Context Length&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/allenai/OLMo-1B&#34;&gt;OLMo 1B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;3 Trillion&lt;/td&gt; &#xA;   &lt;td&gt;2048&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/allenai/OLMo-7B&#34;&gt;OLMo 7B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;2.5 Trillion&lt;/td&gt; &#xA;   &lt;td&gt;2048&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/allenai/OLMo-7B-Twin-2T&#34;&gt;OLMo 7B Twin 2T&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;2 Trillion&lt;/td&gt; &#xA;   &lt;td&gt;2048&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Fine-tuning&lt;/h2&gt; &#xA;&lt;p&gt;To fine-tune an OLMo model using our trainer you&#39;ll first need to prepare your dataset by tokenizing it and saving the tokens IDs to a flat numpy memory-mapped array. See &lt;a href=&#34;https://raw.githubusercontent.com/allenai/OLMo/main/scripts/prepare_tulu_data.py&#34;&gt;&lt;code&gt;scripts/prepare_tulu_data.py&lt;/code&gt;&lt;/a&gt; for an example with the Tulu V2 dataset, which can be easily modified for other datasets.&lt;/p&gt; &#xA;&lt;p&gt;Next, prepare your training config. There are many examples in the &lt;a href=&#34;https://raw.githubusercontent.com/allenai/OLMo/main/configs&#34;&gt;&lt;code&gt;configs/&lt;/code&gt;&lt;/a&gt; directory that you can use as a starting point. The most important thing is to make sure the model parameters (the &lt;code&gt;model&lt;/code&gt; field in the config) match up with the checkpoint you&#39;re starting from. To be safe you can always start from the config that comes with the model checkpoint. At a minimum you&#39;ll need to make the following changes to the config or provide the corresponding overrides from the command line:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Update &lt;code&gt;load_path&lt;/code&gt; to point to the checkpoint you want to start from.&lt;/li&gt; &#xA; &lt;li&gt;Set &lt;code&gt;reset_trainer_state&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Update &lt;code&gt;data.paths&lt;/code&gt; to point to the &lt;code&gt;token_ids.npy&lt;/code&gt; file you generated.&lt;/li&gt; &#xA; &lt;li&gt;Optionally update &lt;code&gt;data.label_mask_paths&lt;/code&gt; to point to the &lt;code&gt;label_mask.npy&lt;/code&gt; file you generated, unless you don&#39;t need special masking for the loss.&lt;/li&gt; &#xA; &lt;li&gt;Update &lt;code&gt;evaluators&lt;/code&gt; to add/remove in-loop evaluations.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Once you&#39;re satisfied with your training config, you can launch the training job via &lt;code&gt;torchrun&lt;/code&gt;. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;torchrun --nproc_per_node=8 scripts/train.py {path_to_train_config} \&#xA;    --data.paths=[{path_to_data}/input_ids.npy] \&#xA;    --data.label_mask_paths=[{path_to_data}/label_mask.npy] \&#xA;    --load_path={path_to_checkpoint} \&#xA;    --reset_trainer_state&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: passing CLI overrides like &lt;code&gt;--reset_trainer_state&lt;/code&gt; is only necessary if you didn&#39;t update those fields in your config.&lt;/p&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;p&gt;You can utilize our HuggingFace integration to run inference on the olmo checkpoints:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from hf_olmo import * # registers the Auto* classes&#xA;&#xA;from transformers import AutoModelForCausalLM, AutoTokenizer&#xA;&#xA;olmo = AutoModelForCausalLM.from_pretrained(&#34;allenai/OLMo-7B&#34;)&#xA;tokenizer = AutoTokenizer.from_pretrained(&#34;allenai/OLMo-7B&#34;)&#xA;&#xA;message = [&#34;Language modeling is &#34;]&#xA;inputs = tokenizer(message, return_tensors=&#39;pt&#39;, return_token_type_ids=False)&#xA;response = olmo.generate(**inputs, max_new_tokens=100, do_sample=True, top_k=50, top_p=0.95)&#xA;print(tokenizer.batch_decode(response, skip_special_tokens=True)[0])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, with the huggingface pipeline abstraction:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import pipeline&#xA;olmo_pipe = pipeline(&#34;text-generation&#34;, model=&#34;allenai/OLMo-7B&#34;)&#xA;print(olmo_pipe(&#34;Language modeling is&#34;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Inference on finetuned checkpoints&lt;/h3&gt; &#xA;&lt;p&gt;If you finetune the model using the code above, you can use the conversion script to convert a native OLMo checkpoint to a HuggingFace-compatible checkpoint&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python hf_olmo/convert_olmo_to_hf.py --checkpoint-dir /path/to/checkpoint&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Quantization&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;olmo = AutoModelForCausalLM.from_pretrained(&#34;allenai/OLMo-7B&#34;, torch_dtype=torch.float16, load_in_8bit=True)  # requires bitsandbytes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The quantized model is more sensitive to typing / cuda, so it is recommended to pass the inputs as inputs.input_ids.to(&#39;cuda&#39;) to avoid potential issues.&lt;/p&gt; &#xA;&lt;h2&gt;Evaluation&lt;/h2&gt; &#xA;&lt;p&gt;Additional tools for evaluating OLMo models are available at the &lt;a href=&#34;https://github.com/allenai/ai2-olmo-eval&#34;&gt;OLMo Eval&lt;/a&gt; repo.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>g1879/DrissionPage</title>
    <updated>2024-02-04T01:40:03Z</updated>
    <id>tag:github.com,2024-02-04:/g1879/DrissionPage</id>
    <link href="https://github.com/g1879/DrissionPage" rel="alternate"></link>
    <summary type="html">&lt;p&gt;åŸºäºpythonçš„ç½‘é¡µè‡ªåŠ¨åŒ–å·¥å…·ã€‚æ—¢èƒ½æ§åˆ¶æµè§ˆå™¨ï¼Œä¹Ÿèƒ½æ”¶å‘æ•°æ®åŒ…ã€‚å¯å…¼é¡¾æµè§ˆå™¨è‡ªåŠ¨åŒ–çš„ä¾¿åˆ©æ€§å’Œrequestsçš„é«˜æ•ˆç‡ã€‚åŠŸèƒ½å¼ºå¤§ï¼Œå†…ç½®æ— æ•°äººæ€§åŒ–è®¾è®¡å’Œä¾¿æ·åŠŸèƒ½ã€‚è¯­æ³•ç®€æ´è€Œä¼˜é›…ï¼Œä»£ç é‡å°‘ã€‚&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;âœ¨ï¸ æ¦‚è¿°&lt;/h1&gt; &#xA;&lt;p&gt;DrissionPage æ˜¯ä¸€ä¸ªåŸºäº python çš„ç½‘é¡µè‡ªåŠ¨åŒ–å·¥å…·ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å®ƒæ—¢èƒ½æ§åˆ¶æµè§ˆå™¨ï¼Œä¹Ÿèƒ½æ”¶å‘æ•°æ®åŒ…ï¼Œè¿˜èƒ½æŠŠä¸¤è€…åˆè€Œä¸ºä¸€ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å¯å…¼é¡¾æµè§ˆå™¨è‡ªåŠ¨åŒ–çš„ä¾¿åˆ©æ€§å’Œ requests çš„é«˜æ•ˆç‡ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å®ƒåŠŸèƒ½å¼ºå¤§ï¼Œå†…ç½®æ— æ•°äººæ€§åŒ–è®¾è®¡å’Œä¾¿æ·åŠŸèƒ½ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å®ƒçš„è¯­æ³•ç®€æ´è€Œä¼˜é›…ï¼Œä»£ç é‡å°‘ï¼Œå¯¹æ–°æ‰‹å‹å¥½ã€‚&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitee.com/g1879/DrissionPage/stargazers&#34;&gt;&lt;img src=&#34;https://gitee.com/g1879/DrissionPage/badge/star.svg?theme=dark&#34; alt=&#34;star&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitee.com/g1879/DrissionPage/members&#34;&gt;&lt;img src=&#34;https://gitee.com/g1879/DrissionPage/badge/fork.svg?theme=dark&#34; alt=&#34;fork&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;é¡¹ç›®åœ°å€ï¼š&lt;a href=&#34;https://gitee.com/g1879/DrissionPage&#34;&gt;gitee&lt;/a&gt; | &lt;a href=&#34;https://github.com/g1879/DrissionPage&#34;&gt;github&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;æ‚¨çš„æ˜Ÿæ˜Ÿæ˜¯å¯¹æˆ‘æœ€å¤§çš„æ”¯æŒğŸ’–&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;æ”¯æŒç³»ç»Ÿï¼šWindowsã€Linuxã€Mac&lt;/p&gt; &#xA;&lt;p&gt;python ç‰ˆæœ¬ï¼š3.6 åŠä»¥ä¸Š&lt;/p&gt; &#xA;&lt;p&gt;æ”¯æŒæµè§ˆå™¨ï¼šChromium å†…æ ¸æµè§ˆå™¨(å¦‚ Chrome å’Œ Edge)ï¼Œelectron åº”ç”¨&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;ğŸ›  å¦‚ä½•ä½¿ç”¨&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;ğŸ“– ä½¿ç”¨æ–‡æ¡£ï¼š&lt;/strong&gt; &lt;a href=&#34;https://g1879.gitee.io/drissionpagedocs&#34;&gt;ç‚¹å‡»æŸ¥çœ‹&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;äº¤æµ QQ ç¾¤ï¼š&lt;/strong&gt; 636361957&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;ğŸ“• èƒŒæ™¯&lt;/h1&gt; &#xA;&lt;p&gt;ç”¨ requests åšæ•°æ®é‡‡é›†é¢å¯¹è¦ç™»å½•çš„ç½‘ç«™æ—¶ï¼Œè¦åˆ†ææ•°æ®åŒ…ã€JS æºç ï¼Œæ„é€ å¤æ‚çš„è¯·æ±‚ï¼Œå¾€å¾€è¿˜è¦åº”ä»˜éªŒè¯ç ã€JS æ··æ·†ã€ç­¾åå‚æ•°ç­‰åçˆ¬æ‰‹æ®µï¼Œé—¨æ§›è¾ƒé«˜ï¼Œå¼€å‘æ•ˆç‡ä¸é«˜ã€‚ ä½¿ç”¨æµè§ˆå™¨ï¼Œå¯ä»¥å¾ˆå¤§ç¨‹åº¦ä¸Šç»•è¿‡è¿™äº›å‘ï¼Œä½†æµè§ˆå™¨è¿è¡Œæ•ˆç‡ä¸é«˜ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å› æ­¤ï¼Œè¿™ä¸ªåº“è®¾è®¡åˆè¡·ï¼Œæ˜¯å°†å®ƒä»¬åˆè€Œä¸ºä¸€ï¼ŒåŒæ—¶å®ç°â€œå†™å¾—å¿«â€å’Œâ€œè·‘å¾—å¿«â€ã€‚èƒ½å¤Ÿåœ¨ä¸åŒéœ€è¦æ—¶åˆ‡æ¢ç›¸åº”æ¨¡å¼ï¼Œå¹¶æä¾›ä¸€ç§äººæ€§åŒ–çš„ä½¿ç”¨æ–¹æ³•ï¼Œæé«˜å¼€å‘å’Œè¿è¡Œæ•ˆç‡ã€‚&lt;br&gt; é™¤äº†åˆå¹¶ä¸¤è€…ï¼Œæœ¬åº“è¿˜ä»¥ç½‘é¡µä¸ºå•ä½å°è£…äº†å¸¸ç”¨åŠŸèƒ½ï¼Œæä¾›éå¸¸ç®€ä¾¿çš„æ“ä½œå’Œè¯­å¥ï¼Œä½¿ç”¨æˆ·å¯å‡å°‘è€ƒè™‘ç»†èŠ‚ï¼Œä¸“æ³¨åŠŸèƒ½å®ç°ã€‚ ä»¥ç®€å•çš„æ–¹å¼å®ç°å¼ºå¤§çš„åŠŸèƒ½ï¼Œä½¿ä»£ç æ›´ä¼˜é›…ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ä»¥å‰çš„ç‰ˆæœ¬æ˜¯å¯¹ selenium è¿›è¡Œé‡æ–°å°è£…å®ç°çš„ã€‚ä» 3.0 å¼€å§‹ï¼Œä½œè€…å¦èµ·ç‚‰ç¶ï¼Œå¯¹åº•å±‚è¿›è¡Œäº†é‡æ–°å¼€å‘ï¼Œæ‘†è„±å¯¹ selenium çš„ä¾èµ–ï¼Œå¢å¼ºäº†åŠŸèƒ½ï¼Œæå‡äº†è¿è¡Œæ•ˆç‡ã€‚&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;ğŸ’¡ ç†å¿µ&lt;/h1&gt; &#xA;&lt;p&gt;ç®€æ´è€Œå¼ºå¤§ï¼&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;â˜€ï¸ ç‰¹æ€§å’Œäº®ç‚¹&lt;/h1&gt; &#xA;&lt;p&gt;ä½œè€…ç»è¿‡é•¿æœŸå®è·µï¼Œè¸©è¿‡æ— æ•°å‘ï¼Œæ€»ç»“å‡ºçš„ç»éªŒå…¨å†™åˆ°è¿™ä¸ªåº“é‡Œäº†ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ‡ å¼ºå¤§çš„è‡ªç ”å†…æ ¸&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬åº“é‡‡ç”¨å…¨è‡ªç ”çš„å†…æ ¸ï¼Œå†…ç½®äº† N å¤šå®ç”¨åŠŸèƒ½ï¼Œå¯¹å¸¸ç”¨åŠŸèƒ½ä½œäº†æ•´åˆå’Œä¼˜åŒ–ï¼Œå¯¹æ¯” seleniumï¼Œæœ‰ä»¥ä¸‹ä¼˜ç‚¹ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;æ—  webdriver ç‰¹å¾&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;æ— éœ€ä¸ºä¸åŒç‰ˆæœ¬çš„æµè§ˆå™¨ä¸‹è½½ä¸åŒçš„é©±åŠ¨&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;è¿è¡Œé€Ÿåº¦æ›´å¿«&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å¯ä»¥è·¨&lt;code&gt;&amp;lt;iframe&amp;gt;&lt;/code&gt;æŸ¥æ‰¾å…ƒç´ ï¼Œæ— éœ€åˆ‡å…¥åˆ‡å‡º&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;æŠŠ&lt;code&gt;&amp;lt;iframe&amp;gt;&lt;/code&gt;çœ‹ä½œæ™®é€šå…ƒç´ ï¼Œè·å–åå¯ç›´æ¥åœ¨å…¶ä¸­æŸ¥æ‰¾å…ƒç´ ï¼Œé€»è¾‘æ›´æ¸…æ™°&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å¯ä»¥åŒæ—¶æ“ä½œæµè§ˆå™¨ä¸­çš„å¤šä¸ªæ ‡ç­¾é¡µï¼Œå³ä½¿æ ‡ç­¾é¡µä¸ºéæ¿€æ´»çŠ¶æ€ï¼Œæ— éœ€åˆ‡æ¢&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å¯ä»¥ç›´æ¥è¯»å–æµè§ˆå™¨ç¼“å­˜æ¥ä¿å­˜å›¾ç‰‡ï¼Œæ— éœ€ç”¨ GUI ç‚¹å‡»å¦å­˜&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å¯ä»¥å¯¹æ•´ä¸ªç½‘é¡µæˆªå›¾ï¼ŒåŒ…æ‹¬è§†å£å¤–çš„éƒ¨åˆ†ï¼ˆ90ä»¥ä¸Šç‰ˆæœ¬æµè§ˆå™¨æ”¯æŒï¼‰&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å¯å¤„ç†é&lt;code&gt;open&lt;/code&gt;çŠ¶æ€çš„ shadow-root&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ‡ äº®ç‚¹åŠŸèƒ½&lt;/h2&gt; &#xA;&lt;p&gt;é™¤äº†ä»¥ä¸Šä¼˜ç‚¹ï¼Œæœ¬åº“è¿˜å†…ç½®äº†æ— æ•°äººæ€§åŒ–è®¾è®¡ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;æç®€çš„è¯­æ³•è§„åˆ™ã€‚é›†æˆå¤§é‡å¸¸ç”¨åŠŸèƒ½ï¼Œä»£ç æ›´ä¼˜é›…&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å®šä½å…ƒç´ æ›´åŠ å®¹æ˜“ï¼ŒåŠŸèƒ½æ›´å¼ºå¤§ç¨³å®š&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;æ— å¤„ä¸åœ¨çš„ç­‰å¾…å’Œè‡ªåŠ¨é‡è¯•åŠŸèƒ½ã€‚ä½¿ä¸ç¨³å®šçš„ç½‘ç»œå˜å¾—æ˜“äºæ§åˆ¶ï¼Œç¨‹åºæ›´ç¨³å®šï¼Œç¼–å†™æ›´çœå¿ƒ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;æä¾›å¼ºå¤§çš„ä¸‹è½½å·¥å…·ã€‚æ“ä½œæµè§ˆå™¨æ—¶ä¹Ÿèƒ½äº«å—å¿«æ·å¯é çš„ä¸‹è½½åŠŸèƒ½&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å…è®¸åå¤ä½¿ç”¨å·²ç»æ‰“å¼€çš„æµè§ˆå™¨ã€‚æ— é¡»æ¯æ¬¡è¿è¡Œä»å¤´å¯åŠ¨æµè§ˆå™¨ï¼Œè°ƒè¯•è¶…æ–¹ä¾¿&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ä½¿ç”¨ ini æ–‡ä»¶ä¿å­˜å¸¸ç”¨é…ç½®ï¼Œè‡ªåŠ¨è°ƒç”¨ï¼Œæä¾›ä¾¿æ·çš„è®¾ç½®ï¼Œè¿œç¦»ç¹æ‚çš„é…ç½®é¡¹&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å†…ç½® lxml ä½œä¸ºè§£æå¼•æ“ï¼Œè§£æé€Ÿåº¦æˆå‡ ä¸ªæ•°é‡çº§æå‡&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ä½¿ç”¨ POM æ¨¡å¼å°è£…ï¼Œå¯ç›´æ¥ç”¨äºæµ‹è¯•ï¼Œä¾¿äºæ‰©å±•&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;é«˜åº¦é›†æˆçš„ä¾¿åˆ©åŠŸèƒ½ï¼Œä»æ¯ä¸ªç»†èŠ‚ä¸­ä½“ç°&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;è¿˜æœ‰å¾ˆå¤šç»†èŠ‚ï¼Œè¿™é‡Œä¸ä¸€ä¸€åˆ—ä¸¾ï¼Œæ¬¢è¿å®é™…ä½¿ç”¨ä¸­ä½“éªŒï¼šï¼‰&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;ğŸ”– ç‰ˆæœ¬å†å²&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://g1879.gitee.io/drissionpagedocs/history/introduction/&#34;&gt;ç‚¹å‡»æŸ¥çœ‹ç‰ˆæœ¬å†å²&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;ğŸ–ğŸ» å…è´£å£°æ˜&lt;/h1&gt; &#xA;&lt;p&gt;è¯·å‹¿å°† DrissionPage åº”ç”¨åˆ°ä»»ä½•å¯èƒ½ä¼šè¿åæ³•å¾‹è§„å®šå’Œé“å¾·çº¦æŸçš„å·¥ä½œä¸­,è¯·å‹å–„ä½¿ç”¨ DrissionPageï¼Œéµå®ˆèœ˜è››åè®®ï¼Œä¸è¦å°† DrissionPage ç”¨äºä»»ä½•éæ³•ç”¨é€”ã€‚å¦‚æ‚¨é€‰æ‹©ä½¿ç”¨ DrissionPage å³ä»£è¡¨æ‚¨éµå®ˆæ­¤åè®®ï¼Œä½œè€…ä¸æ‰¿æ‹…ä»»ä½•ç”±äºæ‚¨è¿åæ­¤åè®®å¸¦æ¥ä»»ä½•çš„æ³•å¾‹é£é™©å’ŒæŸå¤±ï¼Œä¸€åˆ‡åæœç”±æ‚¨æ‰¿æ‹…ã€‚&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;â˜• è¯·æˆ‘å–å’–å•¡&lt;/h1&gt; &#xA;&lt;p&gt;å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼Œä¸å¦¨è¯·ä½œè€…æˆ‘å–æ¯å’–å•¡ ï¼šï¼‰&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://gitee.com/g1879/DrissionPageDocs/raw/master/docs/imgs/code.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>