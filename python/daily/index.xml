<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-10T01:35:38Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Stability-AI/stablediffusion</title>
    <updated>2022-12-10T01:35:38Z</updated>
    <id>tag:github.com,2022-12-10:/Stability-AI/stablediffusion</id>
    <link href="https://github.com/Stability-AI/stablediffusion" rel="alternate"></link>
    <summary type="html">&lt;p&gt;High-Resolution Image Synthesis with Latent Diffusion Models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stable Diffusion Version 2&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/assets/stable-samples/txt2img/768/merged-0006.png&#34; alt=&#34;t2i&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/assets/stable-samples/txt2img/768/merged-0002.png&#34; alt=&#34;t2i&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/assets/stable-samples/txt2img/768/merged-0005.png&#34; alt=&#34;t2i&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repository contains &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt; models trained from scratch and will be continuously updated with new checkpoints. The following list provides an overview of all currently available models. More coming soon.&lt;/p&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;December 7, 2022&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Version 2.1&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;New stable diffusion model (&lt;em&gt;Stable Diffusion 2.1-v&lt;/em&gt;, &lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-2-1&#34;&gt;HuggingFace&lt;/a&gt;) at 768x768 resolution and (&lt;em&gt;Stable Diffusion 2.1-base&lt;/em&gt;, &lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-2-1-base&#34;&gt;HuggingFace&lt;/a&gt;) at 512x512 resolution, both based on the same number of parameters and architecture as 2.0 and fine-tuned on 2.0, on a less restrictive NSFW filtering of the &lt;a href=&#34;https://laion.ai/blog/laion-5b/&#34;&gt;LAION-5B&lt;/a&gt; dataset. Per default, the attention operation of the model is evaluated at full precision when &lt;code&gt;xformers&lt;/code&gt; is not installed. To enable fp16 (which can cause numerical instabilities with the vanilla attention module on the v2.1 model) , run your script with &lt;code&gt;ATTN_PRECISION=fp16 python &amp;lt;thescript.py&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;November 24, 2022&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Version 2.0&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;New stable diffusion model (&lt;em&gt;Stable Diffusion 2.0-v&lt;/em&gt;) at 768x768 resolution. Same number of parameters in the U-Net as 1.5, but uses &lt;a href=&#34;https://github.com/mlfoundations/open_clip&#34;&gt;OpenCLIP-ViT/H&lt;/a&gt; as the text encoder and is trained from scratch. &lt;em&gt;SD 2.0-v&lt;/em&gt; is a so-called &lt;a href=&#34;https://arxiv.org/abs/2202.00512&#34;&gt;v-prediction&lt;/a&gt; model.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The above model is finetuned from &lt;em&gt;SD 2.0-base&lt;/em&gt;, which was trained as a standard noise-prediction model on 512x512 images and is also made available.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Added a &lt;a href=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/#image-upscaling-with-stable-diffusion&#34;&gt;x4 upscaling latent text-guided diffusion model&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;New &lt;a href=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/#depth-conditional-stable-diffusion&#34;&gt;depth-guided stable diffusion model&lt;/a&gt;, finetuned from &lt;em&gt;SD 2.0-base&lt;/em&gt;. The model is conditioned on monocular depth estimates inferred via &lt;a href=&#34;https://github.com/isl-org/MiDaS&#34;&gt;MiDaS&lt;/a&gt; and can be used for structure-preserving img2img and shape-conditional synthesis.&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/assets/stable-samples/depth2img/depth2img01.png&#34; alt=&#34;d2i&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;A &lt;a href=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/#image-inpainting-with-stable-diffusion&#34;&gt;text-guided inpainting model&lt;/a&gt;, finetuned from SD &lt;em&gt;2.0-base&lt;/em&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We follow the &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;original repository&lt;/a&gt; and provide basic inference scripts to sample from the models.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;em&gt;The original Stable Diffusion model was created in a collaboration with &lt;a href=&#34;https://arxiv.org/abs/2202.00512&#34;&gt;CompVis&lt;/a&gt; and &lt;a href=&#34;https://runwayml.com/&#34;&gt;RunwayML&lt;/a&gt; and builds upon the work:&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ommer-lab.com/research/latent-diffusion-models/&#34;&gt;&lt;strong&gt;High-Resolution Image Synthesis with Latent Diffusion Models&lt;/strong&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/rromb&#34;&gt;Robin Rombach&lt;/a&gt;*, &lt;a href=&#34;https://github.com/ablattmann&#34;&gt;Andreas Blattmann&lt;/a&gt;*, &lt;a href=&#34;https://github.com/qp-qp&#34;&gt;Dominik Lorenz&lt;/a&gt;, &lt;a href=&#34;https://github.com/pesser&#34;&gt;Patrick Esser&lt;/a&gt;, &lt;a href=&#34;https://hci.iwr.uni-heidelberg.de/Staff/bommer&#34;&gt;Bj√∂rn Ommer&lt;/a&gt;&lt;br&gt; &lt;em&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html&#34;&gt;CVPR &#39;22 Oral&lt;/a&gt; | &lt;a href=&#34;https://github.com/CompVis/latent-diffusion&#34;&gt;GitHub&lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/abs/2112.10752&#34;&gt;arXiv&lt;/a&gt; | &lt;a href=&#34;https://ommer-lab.com/research/latent-diffusion-models/&#34;&gt;Project page&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;and &lt;a href=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/#shout-outs&#34;&gt;many others&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Stable Diffusion is a latent text-to-image diffusion model.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;You can update an existing &lt;a href=&#34;https://github.com/CompVis/latent-diffusion&#34;&gt;latent diffusion&lt;/a&gt; environment by running&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda install pytorch==1.12.1 torchvision==0.13.1 -c pytorch&#xA;pip install transformers==4.19.2 diffusers invisible-watermark&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;xformers efficient attention&lt;/h4&gt; &#xA;&lt;p&gt;For more efficiency and speed on GPUs, we highly recommended installing the &lt;a href=&#34;https://github.com/facebookresearch/xformers&#34;&gt;xformers&lt;/a&gt; library.&lt;/p&gt; &#xA;&lt;p&gt;Tested on A100 with CUDA 11.4. Installation needs a somewhat recent version of nvcc and gcc/g++, obtain those, e.g., via&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commandline&#34;&gt;export CUDA_HOME=/usr/local/cuda-11.4&#xA;conda install -c nvidia/label/cuda-11.4.0 cuda-nvcc&#xA;conda install -c conda-forge gcc&#xA;conda install -c conda-forge gxx_linux-64=9.5.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, run the following (compiling takes up to 30 min).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commandline&#34;&gt;cd ..&#xA;git clone https://github.com/facebookresearch/xformers.git&#xA;cd xformers&#xA;git submodule update --init --recursive&#xA;pip install -r requirements.txt&#xA;pip install -e .&#xA;cd ../stablediffusion&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Upon successful installation, the code will automatically default to &lt;a href=&#34;https://github.com/facebookresearch/xformers&#34;&gt;memory efficient attention&lt;/a&gt; for the self- and cross-attention layers in the U-Net and autoencoder.&lt;/p&gt; &#xA;&lt;h2&gt;General Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;Stable Diffusion models are general text-to-image diffusion models and therefore mirror biases and (mis-)conceptions that are present in their training data. Although efforts were made to reduce the inclusion of explicit pornographic material, &lt;strong&gt;we do not recommend using the provided weights for services or products without additional safety mechanisms and considerations. The weights are research artifacts and should be treated as such.&lt;/strong&gt; Details on the training procedure and data, as well as the intended use of the model can be found in the corresponding &lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-2&#34;&gt;model card&lt;/a&gt;. The weights are available via &lt;a href=&#34;https://huggingface.co/StabilityAI&#34;&gt;the StabilityAI organization at Hugging Face&lt;/a&gt; under the &lt;a href=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/LICENSE-MODEL&#34;&gt;CreativeML Open RAIL++-M License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Stable Diffusion v2&lt;/h2&gt; &#xA;&lt;p&gt;Stable Diffusion v2 refers to a specific configuration of the model architecture that uses a downsampling-factor 8 autoencoder with an 865M UNet and OpenCLIP ViT-H/14 text encoder for the diffusion model. The &lt;em&gt;SD 2-v&lt;/em&gt; model produces 768x768 px outputs.&lt;/p&gt; &#xA;&lt;p&gt;Evaluations with different classifier-free guidance scales (1.5, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0) and 50 DDIM sampling steps show the relative improvements of the checkpoints:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/assets/model-variants.jpg&#34; alt=&#34;sd evaluation results&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Text-to-Image&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/assets/stable-samples/txt2img/merged-0003.png&#34; alt=&#34;txt2img-stable2&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/assets/stable-samples/txt2img/merged-0001.png&#34; alt=&#34;txt2img-stable2&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Stable Diffusion 2 is a latent diffusion model conditioned on the penultimate text embeddings of a CLIP ViT-H/14 text encoder. We provide a &lt;a href=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/#reference-sampling-script&#34;&gt;reference script for sampling&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Reference Sampling Script&lt;/h4&gt; &#xA;&lt;p&gt;This script incorporates an &lt;a href=&#34;https://github.com/ShieldMnt/invisible-watermark&#34;&gt;invisible watermarking&lt;/a&gt; of the outputs, to help viewers &lt;a href=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/scripts/tests/test_watermark.py&#34;&gt;identify the images as machine-generated&lt;/a&gt;. We provide the configs for the &lt;em&gt;SD2-v&lt;/em&gt; (768px) and &lt;em&gt;SD2-base&lt;/em&gt; (512px) model.&lt;/p&gt; &#xA;&lt;p&gt;First, download the weights for &lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-2-1&#34;&gt;&lt;em&gt;SD2.1-v&lt;/em&gt;&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-2-1-base&#34;&gt;&lt;em&gt;SD2.1-base&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To sample from the &lt;em&gt;SD2.1-v&lt;/em&gt; model, run the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/txt2img.py --prompt &#34;a professional photograph of an astronaut riding a horse&#34; --ckpt &amp;lt;path/to/768model.ckpt/&amp;gt; --config configs/stable-diffusion/v2-inference-v.yaml --H 768 --W 768  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or try out the Web Demo: &lt;a href=&#34;https://huggingface.co/spaces/stabilityai/stable-diffusion&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To sample from the base model, use&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/txt2img.py --prompt &#34;a professional photograph of an astronaut riding a horse&#34; --ckpt &amp;lt;path/to/model.ckpt/&amp;gt; --config &amp;lt;path/to/config.yaml/&amp;gt;  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, this uses the &lt;a href=&#34;https://arxiv.org/abs/2010.02502&#34;&gt;DDIM sampler&lt;/a&gt;, and renders images of size 768x768 (which it was trained on) in 50 steps. Empirically, the v-models can be sampled with higher guidance scales.&lt;/p&gt; &#xA;&lt;p&gt;Note: The inference config for all model versions is designed to be used with EMA-only checkpoints. For this reason &lt;code&gt;use_ema=False&lt;/code&gt; is set in the configuration, otherwise the code will try to switch from non-EMA to EMA weights.&lt;/p&gt; &#xA;&lt;h3&gt;Image Modification with Stable Diffusion&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/assets/stable-samples/depth2img/merged-0000.png&#34; alt=&#34;depth2img-stable2&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Depth-Conditional Stable Diffusion&lt;/h4&gt; &#xA;&lt;p&gt;To augment the well-established &lt;a href=&#34;https://github.com/CompVis/stable-diffusion#image-modification-with-stable-diffusion&#34;&gt;img2img&lt;/a&gt; functionality of Stable Diffusion, we provide a &lt;em&gt;shape-preserving&lt;/em&gt; stable diffusion model.&lt;/p&gt; &#xA;&lt;p&gt;Note that the original method for image modification introduces significant semantic changes w.r.t. the initial image. If that is not desired, download our &lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-2-depth&#34;&gt;depth-conditional stable diffusion&lt;/a&gt; model and the &lt;code&gt;dpt_hybrid&lt;/code&gt; MiDaS &lt;a href=&#34;https://github.com/intel-isl/DPT/releases/download/1_0/dpt_hybrid-midas-501f0c75.pt&#34;&gt;model weights&lt;/a&gt;, place the latter in a folder &lt;code&gt;midas_models&lt;/code&gt; and sample via&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/gradio/depth2img.py configs/stable-diffusion/v2-midas-inference.yaml &amp;lt;path-to-ckpt&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;streamlit run scripts/streamlit/depth2img.py configs/stable-diffusion/v2-midas-inference.yaml &amp;lt;path-to-ckpt&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This method can be used on the samples of the base model itself. For example, take &lt;a href=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/assets/stable-samples/depth2img/old_man.png&#34;&gt;this sample&lt;/a&gt; generated by an anonymous discord user. Using the &lt;a href=&#34;https://gradio.app&#34;&gt;gradio&lt;/a&gt; or &lt;a href=&#34;https://streamlit.io/&#34;&gt;streamlit&lt;/a&gt; script &lt;code&gt;depth2img.py&lt;/code&gt;, the MiDaS model first infers a monocular depth estimate given this input, and the diffusion model is then conditioned on the (relative) depth output.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;b&gt; depth2image &lt;/b&gt;&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/assets/stable-samples/depth2img/d2i.gif/&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;This model is particularly useful for a photorealistic style; see the &lt;a href=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/assets/stable-samples/depth2img&#34;&gt;examples&lt;/a&gt;. For a maximum strength of 1.0, the model removes all pixel-based information and only relies on the text prompt and the inferred monocular depth estimate.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/assets/stable-samples/depth2img/merged-0005.png&#34; alt=&#34;depth2img-stable3&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Classic Img2Img&lt;/h4&gt; &#xA;&lt;p&gt;For running the &#34;classic&#34; img2img, use&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/img2img.py --prompt &#34;A fantasy landscape, trending on artstation&#34; --init-img &amp;lt;path-to-img.jpg&amp;gt; --strength 0.8 --ckpt &amp;lt;path/to/model.ckpt&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and adapt the checkpoint and config paths accordingly.&lt;/p&gt; &#xA;&lt;h3&gt;Image Upscaling with Stable Diffusion&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/assets/stable-samples/upscaling/merged-dog.png&#34; alt=&#34;upscaling-x4&#34;&gt; After &lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler&#34;&gt;downloading the weights&lt;/a&gt;, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/gradio/superresolution.py configs/stable-diffusion/x4-upscaling.yaml &amp;lt;path-to-checkpoint&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;streamlit run scripts/streamlit/superresolution.py -- configs/stable-diffusion/x4-upscaling.yaml &amp;lt;path-to-checkpoint&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;for a Gradio or Streamlit demo of the text-guided x4 superresolution model.&lt;br&gt; This model can be used both on real inputs and on synthesized examples. For the latter, we recommend setting a higher &lt;code&gt;noise_level&lt;/code&gt;, e.g. &lt;code&gt;noise_level=100&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Image Inpainting with Stable Diffusion&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/assets/stable-inpainting/merged-leopards.png&#34; alt=&#34;inpainting-stable2&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-2-inpainting&#34;&gt;Download the SD 2.0-inpainting checkpoint&lt;/a&gt; and run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/gradio/inpainting.py configs/stable-diffusion/v2-inpainting-inference.yaml &amp;lt;path-to-checkpoint&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;streamlit run scripts/streamlit/inpainting.py -- configs/stable-diffusion/v2-inpainting-inference.yaml &amp;lt;path-to-checkpoint&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;for a Gradio or Streamlit demo of the inpainting model. This scripts adds invisible watermarking to the demo in the &lt;a href=&#34;https://github.com/runwayml/stable-diffusion/raw/main/scripts/inpaint_st.py&#34;&gt;RunwayML&lt;/a&gt; repository, but both should work interchangeably with the checkpoints/configs.&lt;/p&gt; &#xA;&lt;h2&gt;Shout-Outs&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Thanks to &lt;a href=&#34;https://huggingface.co/&#34;&gt;Hugging Face&lt;/a&gt; and in particular &lt;a href=&#34;https://github.com/apolinario&#34;&gt;Apolin√°rio&lt;/a&gt; for support with our model releases!&lt;/li&gt; &#xA; &lt;li&gt;Stable Diffusion would not be possible without &lt;a href=&#34;https://laion.ai/&#34;&gt;LAION&lt;/a&gt; and their efforts to create open, large-scale datasets.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://twitter.com/deepfloydai&#34;&gt;DeepFloyd team&lt;/a&gt; at Stability AI, for creating the subset of &lt;a href=&#34;https://laion.ai/blog/laion-5b/&#34;&gt;LAION-5B&lt;/a&gt; dataset used to train the model.&lt;/li&gt; &#xA; &lt;li&gt;Stable Diffusion 2.0 uses &lt;a href=&#34;https://laion.ai/blog/large-openclip/&#34;&gt;OpenCLIP&lt;/a&gt;, trained by &lt;a href=&#34;https://github.com/rom1504&#34;&gt;Romain Beaumont&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Our codebase for the diffusion models builds heavily on &lt;a href=&#34;https://github.com/openai/guided-diffusion&#34;&gt;OpenAI&#39;s ADM codebase&lt;/a&gt; and &lt;a href=&#34;https://github.com/lucidrains/denoising-diffusion-pytorch&#34;&gt;https://github.com/lucidrains/denoising-diffusion-pytorch&lt;/a&gt;. Thanks for open-sourcing!&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;CompVis&lt;/a&gt; initial stable diffusion release&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pesser&#34;&gt;Patrick&lt;/a&gt;&#39;s &lt;a href=&#34;https://github.com/runwayml/stable-diffusion/raw/main/scripts/inpaint_st.py&#34;&gt;implementation&lt;/a&gt; of the streamlit demo for inpainting.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;img2img&lt;/code&gt; is an application of &lt;a href=&#34;https://arxiv.org/abs/2108.01073&#34;&gt;SDEdit&lt;/a&gt; by &lt;a href=&#34;https://cs.stanford.edu/~chenlin/&#34;&gt;Chenlin Meng&lt;/a&gt; from the &lt;a href=&#34;https://cs.stanford.edu/~ermon/website/&#34;&gt;Stanford AI Lab&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/(https://github.com/CompVis/latent-diffusion/pull/51)&#34;&gt;Kat&#39;s implementation&lt;/a&gt; of the &lt;a href=&#34;https://arxiv.org/abs/2202.09778&#34;&gt;PLMS&lt;/a&gt; sampler, and &lt;a href=&#34;https://github.com/crowsonkb/k-diffusion&#34;&gt;more&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2206.00927&#34;&gt;DPMSolver&lt;/a&gt; &lt;a href=&#34;https://github.com/CompVis/stable-diffusion/pull/440&#34;&gt;integration&lt;/a&gt; by &lt;a href=&#34;https://github.com/LuChengTHU&#34;&gt;Cheng Lu&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Facebook&#39;s &lt;a href=&#34;https://github.com/facebookresearch/xformers&#34;&gt;xformers&lt;/a&gt; for efficient attention computation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/isl-org/MiDaS&#34;&gt;MiDaS&lt;/a&gt; for monocular depth estimation.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The code in this repository is released under the MIT License.&lt;/p&gt; &#xA;&lt;p&gt;The weights are available via &lt;a href=&#34;https://huggingface.co/StabilityAI&#34;&gt;the StabilityAI organization at Hugging Face&lt;/a&gt;, and released under the &lt;a href=&#34;https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/LICENSE-MODEL&#34;&gt;CreativeML Open RAIL++-M License&lt;/a&gt; License.&lt;/p&gt; &#xA;&lt;h2&gt;BibTeX&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{rombach2021highresolution,&#xA;      title={High-Resolution Image Synthesis with Latent Diffusion Models}, &#xA;      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Bj√∂rn Ommer},&#xA;      year={2021},&#xA;      eprint={2112.10752},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>qwj/python-proxy</title>
    <updated>2022-12-10T01:35:38Z</updated>
    <id>tag:github.com,2022-12-10:/qwj/python-proxy</id>
    <link href="https://github.com/qwj/python-proxy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;HTTP/HTTP2/HTTP3/Socks4/Socks5/Shadowsocks/ShadowsocksR/SSH/Redirect/Pf TCP/UDP asynchronous tunnel proxy implemented in Python 3 asyncio.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;python-proxy&lt;/h1&gt; &#xA;&lt;p&gt;|made-with-python| |PyPI-version| |Hit-Count| |Downloads| |Downloads-month| |Downloads-week|&lt;/p&gt; &#xA;&lt;p&gt;.. |made-with-python| image:: &lt;a href=&#34;https://img.shields.io/badge/Made%20with-Python-1f425f.svg&#34;&gt;https://img.shields.io/badge/Made%20with-Python-1f425f.svg&lt;/a&gt; :target: &lt;a href=&#34;https://www.python.org/&#34;&gt;https://www.python.org/&lt;/a&gt; .. |PyPI-version| image:: &lt;a href=&#34;https://badge.fury.io/py/pproxy.svg&#34;&gt;https://badge.fury.io/py/pproxy.svg&lt;/a&gt; :target: &lt;a href=&#34;https://pypi.python.org/pypi/pproxy/&#34;&gt;https://pypi.python.org/pypi/pproxy/&lt;/a&gt; .. |Hit-Count| image:: &lt;a href=&#34;http://hits.dwyl.io/qwj/python-proxy.svg&#34;&gt;http://hits.dwyl.io/qwj/python-proxy.svg&lt;/a&gt; :target: &lt;a href=&#34;https://pypi.python.org/pypi/pproxy/&#34;&gt;https://pypi.python.org/pypi/pproxy/&lt;/a&gt; .. |Downloads| image:: &lt;a href=&#34;https://pepy.tech/badge/pproxy&#34;&gt;https://pepy.tech/badge/pproxy&lt;/a&gt; :target: &lt;a href=&#34;https://pepy.tech/project/pproxy&#34;&gt;https://pepy.tech/project/pproxy&lt;/a&gt; .. |Downloads-month| image:: &lt;a href=&#34;https://pepy.tech/badge/pproxy/month&#34;&gt;https://pepy.tech/badge/pproxy/month&lt;/a&gt; :target: &lt;a href=&#34;https://pepy.tech/project/pproxy&#34;&gt;https://pepy.tech/project/pproxy&lt;/a&gt; .. |Downloads-week| image:: &lt;a href=&#34;https://pepy.tech/badge/pproxy/week&#34;&gt;https://pepy.tech/badge/pproxy/week&lt;/a&gt; :target: &lt;a href=&#34;https://pepy.tech/project/pproxy&#34;&gt;https://pepy.tech/project/pproxy&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;HTTP/HTTP2/HTTP3/Socks4/Socks5/Shadowsocks/SSH/Redirect/Pf/QUIC TCP/UDP asynchronous tunnel proxy implemented in Python3 asyncio.&lt;/p&gt; &#xA;&lt;h2&gt;QuickStart&lt;/h2&gt; &#xA;&lt;p&gt;.. code:: rst&lt;/p&gt; &#xA;&lt;p&gt;$ pip3 install pproxy Successfully installed pproxy-1.9.5 $ pproxy Serving on :8080 by http,socks4,socks5 ^C $ pproxy -l ss://chacha20:abc@:8080 Serving on :8080 by ss (chacha20-py)&lt;/p&gt; &#xA;&lt;p&gt;Optional: (better performance with C ciphers)&lt;/p&gt; &#xA;&lt;p&gt;.. code:: rst&lt;/p&gt; &#xA;&lt;p&gt;$ pip3 install pproxy[accelerated] Successfully installed pycryptodome-3.6.4&lt;/p&gt; &#xA;&lt;p&gt;Apply OS system-wide proxy: (MacOS, Windows)&lt;/p&gt; &#xA;&lt;p&gt;.. code:: rst&lt;/p&gt; &#xA;&lt;p&gt;$ pproxy -r ss://chacha20:abc@server_ip:8080 --sys -vv Serving on :8080 by http,socks4,socks5 System proxy setting -&amp;gt; socks5 localhost:8080 socks5 ::1:57345 -&amp;gt; ss server_ip:8080 -&amp;gt; slack.com:443 socks5 ::1:57345 -&amp;gt; ss server_ip:8080 -&amp;gt; &lt;a href=&#34;http://www.google.com:443&#34;&gt;www.google.com:443&lt;/a&gt; ..... (all local traffic log) ......&lt;/p&gt; &#xA;&lt;p&gt;Apply CLI proxy: (MacOS, Linux)&lt;/p&gt; &#xA;&lt;p&gt;.. code:: rst&lt;/p&gt; &#xA;&lt;p&gt;$ export http_proxy=&lt;a href=&#34;http://localhost:8080&#34;&gt;http://localhost:8080&lt;/a&gt; $ export https_proxy=&lt;a href=&#34;http://localhost:8080&#34;&gt;http://localhost:8080&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Run With Docker&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;pproxy&lt;/code&gt; Docker container has both python3 (with Cryptodome for performance optimizations) and &lt;code&gt;pypy&lt;/code&gt; versions available.&lt;/p&gt; &#xA;&lt;p&gt;Python3:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;docker run -it -p 8080:8080 mosajjal/pproxy:latest -l http://:8080 -vv&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Pypy3:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;docker run -it -p 8080:8080 mosajjal/pproxy:latest-pypy -l http://:8080 -vv&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lightweight single-thread asynchronous IO.&lt;/li&gt; &#xA; &lt;li&gt;Pure python, no additional library required.&lt;/li&gt; &#xA; &lt;li&gt;Proxy client/server for TCP/UDP.&lt;/li&gt; &#xA; &lt;li&gt;Schedule (load balance) among remote servers.&lt;/li&gt; &#xA; &lt;li&gt;Incoming traffic auto-detect.&lt;/li&gt; &#xA; &lt;li&gt;Tunnel/jump/backward-jump support.&lt;/li&gt; &#xA; &lt;li&gt;Unix domain socket support.&lt;/li&gt; &#xA; &lt;li&gt;HTTP v2, HTTP v3 (QUIC)&lt;/li&gt; &#xA; &lt;li&gt;User/password authentication support.&lt;/li&gt; &#xA; &lt;li&gt;Filter/block hostname by regex patterns.&lt;/li&gt; &#xA; &lt;li&gt;SSL/TLS client/server support.&lt;/li&gt; &#xA; &lt;li&gt;Shadowsocks OTA (One-Time-Auth_), SSR plugins.&lt;/li&gt; &#xA; &lt;li&gt;Statistics by bandwidth and traffic.&lt;/li&gt; &#xA; &lt;li&gt;PAC support for javascript configuration.&lt;/li&gt; &#xA; &lt;li&gt;Iptables/Pf NAT redirect packet tunnel.&lt;/li&gt; &#xA; &lt;li&gt;System proxy auto-setting support.&lt;/li&gt; &#xA; &lt;li&gt;Client/Server API provided.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;.. _One-Time-Auth: &lt;a href=&#34;https://shadowsocks.org/en/spec/one-time-auth.html&#34;&gt;https://shadowsocks.org/en/spec/one-time-auth.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Protocols&lt;/h2&gt; &#xA;&lt;p&gt;+-------------------+------------+------------+------------+------------+--------------+ | Name | TCP server | TCP client | UDP server | UDP client | scheme | +===================+============+============+============+============+==============+ | http (connect) | ‚úî | ‚úî | | | http:// | +-------------------+ +------------+------------+------------+--------------+ | http | | ‚úî | | | httponly:// | | (get,post,etc) | | | | | (as client) | +-------------------+------------+------------+------------+------------+--------------+ | http v2 (connect) | ‚úî | ‚úî | | | h2:// | +-------------------+------------+------------+------------+------------+--------------+ | http v3 (connect) | ‚úî by UDP | ‚úî by UDP | | | h3:// | +-------------------+------------+------------+------------+------------+--------------+ | https | ‚úî | ‚úî | | | http+ssl:// | +-------------------+------------+------------+------------+------------+--------------+ | socks4 | ‚úî | ‚úî | | | socks4:// | +-------------------+------------+------------+------------+------------+--------------+ | socks5 | ‚úî | ‚úî | ‚úî udp-only | ‚úî udp-only | socks5:// | +-------------------+------------+------------+------------+------------+--------------+ | socks5 over TLS | ‚úî | ‚úî | | | socks5+ssl://| +-------------------+------------+------------+------------+------------+--------------+ | shadowsocks | ‚úî | ‚úî | ‚úî | ‚úî | ss:// | +-------------------+------------+------------+------------+------------+--------------+ | shadowsocks aead | ‚úî | ‚úî | | | ss:// | +-------------------+------------+------------+------------+------------+--------------+ | shadowsocksR | ‚úî | ‚úî | | | ssr:// | +-------------------+------------+------------+------------+------------+--------------+ | trojan | ‚úî | ‚úî | | | trojan:// | +-------------------+------------+------------+------------+------------+--------------+ | ssh tunnel | | ‚úî | | | ssh:// | +-------------------+------------+------------+------------+------------+--------------+ | quic | ‚úî by UDP | ‚úî by UDP | ‚úî | ‚úî | http+quic:// | +-------------------+------------+------------+------------+------------+--------------+ | iptables nat | ‚úî | | | | redir:// | +-------------------+------------+------------+------------+------------+--------------+ | pfctl nat (macos) | ‚úî | | | | pf:// | +-------------------+------------+------------+------------+------------+--------------+ | echo | ‚úî | | ‚úî | | echo:// | +-------------------+------------+------------+------------+------------+--------------+ | tunnel | ‚úî | ‚úî | ‚úî | ‚úî | tunnel:// | | (raw socket) | | | | | tunnel{ip}://| +-------------------+------------+------------+------------+------------+--------------+ | websocket | ‚úî | ‚úî | | | ws:// | | (simple tunnel) | | | | | ws{dst_ip}://| +-------------------+------------+------------+------------+------------+--------------+ | xxx over TLS | ‚úî | ‚úî | | | xxx+ssl:// | +-------------------+------------+------------+------------+------------+--------------+ | AUTO DETECT | ‚úî | | ‚úî | | a+b+c+d:// | +-------------------+------------+------------+------------+------------+--------------+&lt;/p&gt; &#xA;&lt;h2&gt;Scheduling Algorithms&lt;/h2&gt; &#xA;&lt;p&gt;+-------------------+------------+------------+------------+------------+ | Name | TCP | UDP | Parameter | Default | +===================+============+============+============+============+ | first_available | ‚úî | ‚úî | -s fa | ‚úî | +-------------------+------------+------------+------------+------------+ | round_robin | ‚úî | ‚úî | -s rr | | +-------------------+------------+------------+------------+------------+ | random_choice | ‚úî | ‚úî | -s rc | | +-------------------+------------+------------+------------+------------+ | least_connection | ‚úî | | -s lc | | +-------------------+------------+------------+------------+------------+&lt;/p&gt; &#xA;&lt;h2&gt;Requirement&lt;/h2&gt; &#xA;&lt;p&gt;pycryptodome_ is an optional library to enable faster (C version) cipher. &lt;strong&gt;pproxy&lt;/strong&gt; has many built-in pure python ciphers. They are lightweight and stable, but slower than C ciphers. After speedup with PyPy_, pure python ciphers can get similar performance as C version. If the performance is important and don&#39;t have PyPy_, install pycryptodome_ instead.&lt;/p&gt; &#xA;&lt;p&gt;asyncssh_ is an optional library to enable ssh tunnel client support.&lt;/p&gt; &#xA;&lt;p&gt;These are some performance benchmarks between Python and C ciphers (dataset: 8M):&lt;/p&gt; &#xA;&lt;p&gt;+---------------------+----------------+ | chacha20-c | 0.64 secs | +---------------------+----------------+ | chacha20-py (pypy3) | 1.32 secs | +---------------------+----------------+ | chacha20-py | 48.86 secs | +---------------------+----------------+&lt;/p&gt; &#xA;&lt;p&gt;PyPy3 Quickstart:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: rst&lt;/p&gt; &#xA;&lt;p&gt;$ pypy3 -m ensurepip $ pypy3 -m pip install asyncio pproxy&lt;/p&gt; &#xA;&lt;p&gt;.. _pycryptodome: &lt;a href=&#34;https://pycryptodome.readthedocs.io/en/latest/src/introduction.html&#34;&gt;https://pycryptodome.readthedocs.io/en/latest/src/introduction.html&lt;/a&gt; .. _asyncssh: &lt;a href=&#34;https://asyncssh.readthedocs.io/en/latest/&#34;&gt;https://asyncssh.readthedocs.io/en/latest/&lt;/a&gt; .. _PyPy: &lt;a href=&#34;http://pypy.org&#34;&gt;http://pypy.org&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;.. code:: rst&lt;/p&gt; &#xA;&lt;p&gt;$ pproxy -h usage: pproxy [-h] [-l LISTEN] [-r RSERVER] [-ul ULISTEN] [-ur URSERVER] [-b BLOCK] [-a ALIVED] [-v] [--ssl SSLFILE] [--pac PAC] [--get GETS] [--sys] [--test TESTURL] [--version]&lt;/p&gt; &#xA;&lt;p&gt;Proxy server that can tunnel among remote servers by regex rules. Supported protocols: http,socks4,socks5,shadowsocks,shadowsocksr,redirect,pf,tunnel&lt;/p&gt; &#xA;&lt;p&gt;optional arguments: -h, --help show this help message and exit -l LISTEN tcp server uri (default: http+socks4+socks5://:8080/) -r RSERVER tcp remote server uri (default: direct) -ul ULISTEN udp server setting uri (default: none) -ur URSERVER udp remote server uri (default: direct) -b BLOCK block regex rules -a ALIVED interval to check remote alive (default: no check) -s {fa,rr,rc,lc} scheduling algorithm (default: first_available) -v print verbose output --ssl SSLFILE certfile[,keyfile] if server listen in ssl mode --pac PAC http PAC path --get GETS http custom {path,file} --sys change system proxy setting (mac, windows) --test TEST test this url for all remote proxies and exit --version show program&#39;s version number and exit&lt;/p&gt; &#xA;&lt;p&gt;Online help: &lt;a href=&#34;https://github.com/qwj/python-proxy&#34;&gt;https://github.com/qwj/python-proxy&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;URI Syntax&lt;/h2&gt; &#xA;&lt;p&gt;.. code:: rst&lt;/p&gt; &#xA;&lt;p&gt;{scheme}://[{cipher}@]{netloc}/[@{localbind}][,{plugins}][?{rules}][#{auth}]&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;scheme&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Currently supported scheme: http, socks, ss, ssl, secure. You can use + to link multiple protocols together.&lt;/p&gt; &lt;p&gt;+----------+-----------------------------+ | http | http protocol (CONNECT) | +----------+-----------------------------+ | httponly | http protocol (GET/POST) | +----------+-----------------------------+ | socks4 | socks4 protocol | +----------+-----------------------------+ | socks5 | socks5 protocol | +----------+-----------------------------+ | ss | shadowsocks protocol | +----------+-----------------------------+ | ssr | shadowsocksr (SSR) protocol | +----------+-----------------------------+ | trojan | trojan_ protocol | +----------+-----------------------------+ | ssh | ssh client tunnel | +----------+-----------------------------+ | redir | redirect (iptables nat) | +----------+-----------------------------+ | pf | pfctl (macos pf nat) | +----------+-----------------------------+ | ssl | unsecured ssl/tls (no cert) | +----------+-----------------------------+ | secure | secured ssl/tls (cert) | +----------+-----------------------------+ | tunnel | raw connection | +----------+-----------------------------+ | ws | websocket connection | +----------+-----------------------------+ | echo | echo-back service | +----------+-----------------------------+ | direct | direct connection | +----------+-----------------------------+&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;.. _trojan: &lt;a href=&#34;https://trojan-gfw.github.io/trojan/protocol&#34;&gt;https://trojan-gfw.github.io/trojan/protocol&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&#34;http://&#34; accepts GET/POST/CONNECT as server, sends CONNECT as client. &#34;httponly://&#34; sends &#34;GET/POST&#34; as client, works only on http traffic.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Valid schemes: http://, http+socks4+socks5://, http+ssl://, ss+secure://, http+socks5+ss://&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Invalid schemes: ssl://, secure://&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;cipher&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Cipher&#39;s format: &#34;cipher_name:cipher_key&#34;. Cipher can be base64-encoded. So cipher string with &#34;YWVzLTEyOC1nY206dGVzdA==&#34; is equal to &#34;aes-128-gcm:test&#34;.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Full cipher support list:&lt;/p&gt; &lt;p&gt;+-----------------+------------+-----------+-------------+ | Cipher | Key Length | IV Length | Score (0-5) | +=================+============+===========+=============+ | table-py | any | 0 | 0 (lowest) | +-----------------+------------+-----------+-------------+ | rc4 | 16 | 0 | 0 (lowest) | +-----------------+------------+-----------+-------------+ | rc4-md5 | 16 | 16 | 0.5 | +-----------------+------------+-----------+-------------+ | chacha20 | 32 | 8 | 5 (highest) | +-----------------+------------+-----------+-------------+ | chacha20-ietf | 32 | 12 | 5 | +-----------------+------------+-----------+-------------+ | chacha20-ietf- | | | | | poly1305-py | 32 | 32 | AEAD | +-----------------+------------+-----------+-------------+ | salsa20 | 32 | 8 | 4.5 | +-----------------+------------+-----------+-------------+ | aes-128-cfb | 16 | 16 | 3 | | | | | | | aes-128-cfb8 | | | | | | | | | | aes-128-cfb1-py | | | slow | +-----------------+------------+-----------+-------------+ | aes-192-cfb | 24 | 16 | 3.5 | | | | | | | aes-192-cfb8 | | | | | | | | | | aes-192-cfb1-py | | | slow | +-----------------+------------+-----------+-------------+ | aes-256-cfb | 32 | 16 | 4.5 | | | | | | | aes-256-ctr | | | | | | | | | | aes-256-ofb | | | | | | | | | | aes-256-cfb8 | | | | | | | | | | aes-256-cfb1-py | | | slow | +-----------------+------------+-----------+-------------+ | aes-256-gcm | 32 | 32 | AEAD | | | | | | | aes-192-gcm | 24 | 24 | AEAD | | | | | | | aes-128-gcm | 16 | 16 | AEAD | +-----------------+------------+-----------+-------------+ | camellia-256-cfb| 32 | 16 | 4 | | | | | | | camellia-192-cfb| 24 | 16 | 4 | | | | | | | camellia-128-cfb| 16 | 16 | 4 | +-----------------+------------+-----------+-------------+ | bf-cfb | 16 | 8 | 1 | +-----------------+------------+-----------+-------------+ | cast5-cfb | 16 | 8 | 2.5 | +-----------------+------------+-----------+-------------+ | des-cfb | 8 | 8 | 1.5 | +-----------------+------------+-----------+-------------+ | rc2-cfb-py | 16 | 8 | 2 | +-----------------+------------+-----------+-------------+ | idea-cfb-py | 16 | 8 | 2.5 | +-----------------+------------+-----------+-------------+ | seed-cfb-py | 16 | 16 | 2 | +-----------------+------------+-----------+-------------+&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;em&gt;pproxy&lt;/em&gt; ciphers have pure python implementations. Program will switch to C cipher if there is C implementation available within pycryptodome_. Otherwise, use pure python cipher.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;AEAD ciphers use additional payload after each packet. The underlying protocol is different. Specifications: AEAD_.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Some pure python ciphers (aes-256-cfb1-py) is quite slow, and is not recommended to use without PyPy speedup. Try install pycryptodome_ and use C version cipher instead.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;To enable OTA encryption with shadowsocks, add &#39;!&#39; immediately after cipher name.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;netloc&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;It can be &#34;hostname:port&#34; or &#34;/unix_domain_socket&#34;. If the hostname is empty, server will listen on all interfaces.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Valid netloc: localhost:8080, 0.0.0.0:8123, /tmp/domain_socket, :8123&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;localbind&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;It can be &#34;@in&#34; or @ipv4_address or @ipv6_address&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Valid localbind: @in, @192.168.1.15, @::1&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;plugins&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;It can be multiple plugins joined by &#34;,&#34;. Supported plugins: plain, origin, http_simple, tls1.2_ticket_auth, verify_simple, verify_deflate&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Valid plugins: /,tls1.2_ticket_auth,verify_simple&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;rules&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The filename that contains regex rules&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;auth&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The username, colon &#39;:&#39;, and the password&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;URIs can be joined by &#34;__&#34; to indicate tunneling by jump. For example, ss://1.2.3.4:1324__&lt;a href=&#34;http://4.5.6.7:4321&#34;&gt;http://4.5.6.7:4321&lt;/a&gt; make remote connection to the first shadowsocks proxy server, and then jump to the second http proxy server.&lt;/p&gt; &#xA;&lt;p&gt;.. _AEAD: &lt;a href=&#34;http://shadowsocks.org/en/spec/AEAD-Ciphers.html&#34;&gt;http://shadowsocks.org/en/spec/AEAD-Ciphers.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Client API&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;TCP Client API&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;import asyncio, pproxy&lt;/p&gt; &lt;p&gt;async def test_tcp(proxy_uri): conn = pproxy.Connection(proxy_uri) reader, writer = await conn.tcp_connect(&#39;google.com&#39;, 80) writer.write(b&#39;GET / HTTP/1.1\r\n\r\n&#39;) data = await reader.read(1024*16) print(data.decode())&lt;/p&gt; &lt;p&gt;asyncio.run(test_tcp(&#39;ss://aes-256-cfb:password@remote_host:remote_port&#39;))&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;UDP Client API&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;import asyncio, pproxy&lt;/p&gt; &lt;p&gt;async def test_udp(proxy_uri): conn = pproxy.Connection(proxy_uri) answer = asyncio.Future() await conn.udp_sendto(&#39;8.8.8.8&#39;, 53, b&#39;hello the world&#39;, answer.set_result) await answer print(answer.result())&lt;/p&gt; &lt;p&gt;asyncio.run(test_udp(&#39;ss://chacha20:password@remote_host:remote_port&#39;))&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Server API&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Server API example:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;import asyncio import pproxy&lt;/p&gt; &lt;p&gt;server = pproxy.Server(&#39;ss://0.0.0.0:1234&#39;) remote = pproxy.Connection(&#39;ss://1.2.3.4:5678&#39;) args = dict( rserver = [remote], verbose = print )&lt;/p&gt; &lt;p&gt;loop = asyncio.get_event_loop() handler = loop.run_until_complete(server.start_server(args)) try: loop.run_forever() except KeyboardInterrupt: print(&#39;exit!&#39;)&lt;/p&gt; &lt;p&gt;handler.close() loop.run_until_complete(handler.wait_closed()) loop.run_until_complete(loop.shutdown_asyncgens()) loop.close()&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Regex rule&lt;/p&gt; &lt;p&gt;Define regex file &#34;rules&#34; as follow:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;#google domains (?:.+.)?google.&lt;em&gt;.com (?:.+.)?gstatic.com (?:.+.)?gmail.com (?:.+.)?ntp.org (?:.+.)?glpals.com (?:.+.)?akamai.&lt;/em&gt;.net (?:.+.)?ggpht.com (?:.+.)?android.com (?:.+.)?gvt1.com (?:.+.)?youtube.*.com (?:.+.)?ytimg.com (?:.+.)?goo.gl (?:.+.)?youtu.be (?:.+.)?google..+&lt;/p&gt; &lt;p&gt;Then start &lt;em&gt;pproxy&lt;/em&gt;&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -r &lt;a href=&#34;http://aa.bb.cc.dd:8080?rules&#34;&gt;http://aa.bb.cc.dd:8080?rules&lt;/a&gt; -vv Serving on :8080 by http,socks4,socks5 http ::1:57768 -&amp;gt; http aa.bb.cc.dd:8080 -&amp;gt; &lt;a href=&#34;http://www.googleapis.com:443&#34;&gt;www.googleapis.com:443&lt;/a&gt; http ::1:57772 -&amp;gt; &lt;a href=&#34;http://www.yahoo.com:80&#34;&gt;www.yahoo.com:80&lt;/a&gt; socks4 ::1:57770 -&amp;gt; http aa.bb.cc.dd:8080 -&amp;gt; &lt;a href=&#34;http://www.youtube.com:443&#34;&gt;www.youtube.com:443&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;em&gt;pproxy&lt;/em&gt; will serve incoming traffic by http/socks4/socks5 auto-detect protocol, redirect all google traffic to http proxy aa.bb.cc.dd:8080, and visit all other traffic directly from local.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Use cipher&lt;/p&gt; &lt;p&gt;Add cipher encryption to make sure data can&#39;t be intercepted. Run &lt;em&gt;pproxy&lt;/em&gt; locally as:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l ss://:8888 -r ss://chacha20:&lt;a href=&#34;mailto:cipher_key@aa.bb.cc.dd&#34;&gt;cipher_key@aa.bb.cc.dd&lt;/a&gt;:12345 -vv&lt;/p&gt; &lt;p&gt;Next, run pproxy.py remotely on server &#34;aa.bb.cc.dd&#34;. The base64 encoded string of &#34;chacha20:cipher_key&#34; is also supported:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l ss://chacha20:cipher_key@:12345&lt;/p&gt; &lt;p&gt;The same as:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l ss://Y2hhY2hhMjA6Y2lwaGVyX2tleQ==@:12345&lt;/p&gt; &lt;p&gt;The traffic between local and aa.bb.cc.dd is encrypted by stream cipher Chacha20 with secret key &#34;cipher_key&#34;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Unix domain socket&lt;/p&gt; &lt;p&gt;A more complex example:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l ss://salsa20!:complex_cipher_key@/tmp/pproxy_socket -r http+ssl://domain1.com:443#username:password&lt;/p&gt; &lt;p&gt;&lt;em&gt;pproxy&lt;/em&gt; listen on the unix domain socket &#34;/tmp/pproxy_socket&#34; with cipher &#34;salsa20&#34; and key &#34;complex_cipher_key&#34;. OTA packet protocol is enabled by adding ! after cipher name. The traffic is tunneled to remote https proxy with simple http authentication.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;SSL/TLS server&lt;/p&gt; &lt;p&gt;If you want to listen in SSL/TLS, you must specify ssl certificate and private key files by parameter &#34;--ssl&#34;:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l http+ssl://0.0.0.0:443 -l &lt;a href=&#34;http://0.0.0.0:80&#34;&gt;http://0.0.0.0:80&lt;/a&gt; --ssl server.crt,server.key --pac /autopac&lt;/p&gt; &lt;p&gt;&lt;em&gt;pproxy&lt;/em&gt; listen on both 80 HTTP and 443 HTTPS ports, use the specified SSL/TLS certificate and private key files. The &#34;--pac&#34; enable PAC feature, so you can put &#34;&lt;a href=&#34;https://yourdomain.com/autopac&#34;&gt;https://yourdomain.com/autopac&lt;/a&gt;&#34; path in your device&#39;s auto-configure url.&lt;/p&gt; &lt;p&gt;Simple guide for generating self-signed ssl certificates:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ openssl genrsa -des3 -out server.key 1024 $ openssl req -new -key server.key -out server.csr $ cp server.key server.key.org $ openssl rsa -in server.key.org -out server.key $ openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;SSR plugins&lt;/p&gt; &lt;p&gt;ShadowsocksR example with plugin &#34;tls1.2_ticket_auth&#34; to emulate common tls traffic:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l ssr://chacha20:mypass@0.0.0.0:443/,tls1.2_ticket_auth,verify_simple&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Local bind ip&lt;/p&gt; &lt;p&gt;If you want to route the traffic by different local bind, use the @localbind URI syntax. For example, server has three ip interfaces: 192.168.1.15, 111.0.0.1, 112.0.0.1. You want to route traffic matched by &#34;rule1&#34; to 111.0.0.2 and traffic matched by &#34;rule2&#34; to 222.0.0.2, and the remaining traffic directly:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l ss://:8000/@in -r ss://111.0.0.2:8000/@111.0.0.1?rule1 -r ss://222.0.0.2:8000/@222.0.0.1?rule2&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Redirect/Pf protocol&lt;/p&gt; &lt;p&gt;IPTable NAT redirect example (Ubuntu):&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ sudo iptables -t nat -A OUTPUT -p tcp --dport 80 -j REDIRECT --to-ports 5555 $ pproxy -l redir://:5555 -r http://remote_http_server:3128 -vv&lt;/p&gt; &lt;p&gt;The above example illustrates how to redirect all local output tcp traffic with destination port 80 to localhost port 5555 listened by &lt;strong&gt;pproxy&lt;/strong&gt;, and then tunnel the traffic to remote http proxy.&lt;/p&gt; &lt;p&gt;PF redirect example (MacOS):&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ sudo pfctl -ef /dev/stdin rdr pass on lo0 inet proto tcp from any to any port 80 -&amp;gt; 127.0.0.1 port 8080 pass out on en0 route-to lo0 inet proto tcp from any to any port 80 keep state ^D $ sudo pproxy -l pf://:8080 -r socks5://remote_socks5_server:1324 -vv&lt;/p&gt; &lt;p&gt;Make sure &lt;strong&gt;pproxy&lt;/strong&gt; runs in root mode (sudo), otherwise it cannot redirect pf packet.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Multiple jumps example&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -r http://server1__ss://server2__socks://server3&lt;/p&gt; &lt;p&gt;&lt;em&gt;pproxy&lt;/em&gt; will connect to server1 first, tell server1 connect to server2, and tell server2 connect to server3, and make real traffic by server3.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Raw connection tunnel&lt;/p&gt; &lt;p&gt;TCP raw connection tunnel example:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l tunnel{google.com}://:80 $ curl -H &#34;Host: google.com&#34; &lt;a href=&#34;http://localhost&#34;&gt;http://localhost&lt;/a&gt;&lt;/p&gt; &lt;p&gt;UDP dns tunnel example:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -ul tunnel{8.8.8.8}://:53 $ nslookup google.com localhost&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;UDP more complicated example&lt;/p&gt; &lt;p&gt;Run the shadowsocks udp proxy on remote machine:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -ul ss://remote_server:13245&lt;/p&gt; &lt;p&gt;Run the commands on local machine:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -ul tunnel{8.8.8.8}://:53 -ur ss://remote_server:13245 -vv UDP tunnel 127.0.0.1:60573 -&amp;gt; ss remote_server:13245 -&amp;gt; 8.8.8.8:53 UDP tunnel 127.0.0.1:60574 -&amp;gt; ss remote_server:13245 -&amp;gt; 8.8.8.8:53 ... $ nslookup google.com localhost&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Load balance example&lt;/p&gt; &lt;p&gt;Specify multiple -r server, and a scheduling algorithm (rr = round_robin, rc = random_choice, lc = least_connection):&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -r &lt;a href=&#34;http://server1&#34;&gt;http://server1&lt;/a&gt; -r ss://server2 -r socks5://server3 -s rr -vv http ::1:42356 -&amp;gt; http server1 -&amp;gt; google.com:443 http ::1:42357 -&amp;gt; ss server2 -&amp;gt; google.com:443 http ::1:42358 -&amp;gt; socks5 server3 -&amp;gt; google.com:443 http ::1:42359 -&amp;gt; http server1 -&amp;gt; google.com:443 ... $ pproxy -ul tunnel://:53 -ur tunnel://8.8.8.8:53 -ur tunnel://8.8.4.4:53 -s rc -vv UDP tunnel ::1:35378 -&amp;gt; tunnel 8.8.8.8:53 UDP tunnel ::1:35378 -&amp;gt; tunnel 8.8.4.4:53 ...&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;WebSocket example&lt;/p&gt; &lt;p&gt;WebSocket protocol is similar to Tunnel protocol. It is raw and doesn&#39;t support any proxy function. It can connect to other proxy like Tunnel protocol.&lt;/p&gt; &lt;p&gt;First run pproxy on remote machine:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l ws://:80 -r tunnel:///tmp/myproxy -v $ pproxy -l ss://chacha20:abc@/tmp/myproxy -v&lt;/p&gt; &lt;p&gt;Run pproxy on local machine:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l tunnel://:1234 -r ws://remote_ip:80 -vv&lt;/p&gt; &lt;p&gt;Then port :1234 on local machine is connected to the /tmp/myproxy on remote machine by WebSocket tunnel. You can specify any proxy protocol details on /tmp/myproxy.&lt;/p&gt; &lt;p&gt;It is a good practice to use some CDN in the middle of local/remote machines. CDN with WebSocket support can hide remote machine&#39;s real IP from public.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Backward proxy&lt;/p&gt; &lt;p&gt;Sometimes, the proxy server hides behind an NAT router and doesn&#39;t have a public ip. The client side has a public ip &#34;client_ip&#34;. Backward proxy feature enables the server to connect backward to client and wait for proxy requests.&lt;/p&gt; &lt;p&gt;Run &lt;strong&gt;pproxy&lt;/strong&gt; client as follows:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l http://:8080 -r http+in://:8081 -v&lt;/p&gt; &lt;p&gt;Run &lt;strong&gt;pproxy&lt;/strong&gt; server as follows:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l http+in://client_ip:8081&lt;/p&gt; &lt;p&gt;Server connects to client_ip:8081 and waits for client proxy requests. The protocol http specified is just an example. It can be any protocol and cipher &lt;strong&gt;pproxy&lt;/strong&gt; supports. The scheme &#34;&lt;strong&gt;in&lt;/strong&gt;&#34; should exist in URI to inform &lt;strong&gt;pproxy&lt;/strong&gt; that it is a backward proxy.&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l http+in://jumpserver__http://client_ip:8081&lt;/p&gt; &lt;p&gt;It is a complicated example. Server connects to client_ip:8081 by jump &lt;a href=&#34;http://jumpserver&#34;&gt;http://jumpserver&lt;/a&gt;. The backward proxy works through jumps.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;SSH client tunnel&lt;/p&gt; &lt;p&gt;SSH client tunnel support is enabled by installing additional library asyncssh_. After &#34;pip3 install asyncssh&#34;, you can specify &#34;&lt;strong&gt;ssh&lt;/strong&gt;&#34; as scheme to proxy via ssh client tunnel.&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l http://:8080 -r ssh://remote_server.com/#login:password&lt;/p&gt; &lt;p&gt;If a client private key is used to authenticate, put double colon &#34;::&#34; between login and private key path.&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l http://:8080 -r ssh://remote_server.com/#login::private_key_path&lt;/p&gt; &lt;p&gt;SSH connection known_hosts feature is disabled by default.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;SSH jump&lt;/p&gt; &lt;p&gt;SSH jump is supported by using &#34;__&#34; concatenation&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -r ssh://server1__ssh://server2__ssh://server3&lt;/p&gt; &lt;p&gt;First connection to server1 is made. Second, ssh connection to server2 is made from server1. Finally, connect to server3, and use server3 for proxying traffic.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;SSH remote forward&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l ssh://server__tunnel://0.0.0.0:1234 -r tunnel://127.0.0.1:1234&lt;/p&gt; &lt;p&gt;TCP :1234 on remote server is forwarded to 127.0.0.1:1234 on local server&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy -l ssh://server1__ssh://server2__ss://0.0.0.0:1234 -r ss://server3:1234&lt;/p&gt; &lt;p&gt;It is a complicated example. SSH server2 is jumped from SSH server1, and ss://0.0.0.0:1234 on server2 is listened. Traffic is forwarded to ss://server3:1234.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Trojan protocol example&lt;/p&gt; &lt;p&gt;Normally trojan:// should be used together with ssl://. You should specify the SSL crt/key file for ssl usage. A typical trojan server would be:&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pproxy --ssl ssl.crt,ssl.key -l trojan+tunnel{localhost:80}+ssl://:443#yourpassword -vv&lt;/p&gt; &lt;p&gt;If trojan password doesn&#39;t match, the tunnal{localhost:80} will be switched to. It looks exactly the same as a common HTTPS website.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;QUIC protocol example&lt;/p&gt; &lt;p&gt;QUIC is a UDP stream protocol used in HTTP/3. Library &lt;strong&gt;aioquic&lt;/strong&gt; is required if you want to proxy via QUIC. QUIC is listened on UDP port, but can handle TCP or UDP traffic. If you want to handle TCP traffic, you should use &#34;-l quic+http&#34; instead of &#34;-ul quic+http&#34;.&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pip3 install aioquic $ pproxy --ssl ssl.crt,ssl.key -l quic+http://:1234&lt;/p&gt; &lt;p&gt;On the client:&lt;/p&gt; &lt;p&gt;$ pproxy -r quic+&lt;a href=&#34;http://server:1234&#34;&gt;http://server:1234&lt;/a&gt;&lt;/p&gt; &lt;p&gt;QUIC protocol can transfer a lot of TCP streams on one single UDP stream. If the connection number is hugh, QUIC can benefit by reducing TCP handshake time.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;VPN Server Example&lt;/p&gt; &lt;p&gt;You can run VPN server simply by installing pvpn (python vpn), a lightweight VPN server with pproxy tunnel feature.&lt;/p&gt; &lt;p&gt;.. code:: rst&lt;/p&gt; &lt;p&gt;$ pip3 install pvpn Successfully installed pvpn-0.2.1 $ pvpn -wg 9999 -r http://remote_server:remote_port Serving on UDP :500 :4500... Serving on UDP :9000 (WIREGUARD)... TCP xx.xx.xx.xx:xx -&amp;gt; HTTP xx.xx.xx.xx:xx -&amp;gt; xx.xx.xx.xx:xx&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Projects&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;python-vpn &amp;lt;https://github.com/qwj/python-vpn&amp;gt;&lt;/code&gt;_ - VPN Server (IPSec,IKE,IKEv2,L2TP,WireGuard) in pure python&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;shadowproxy &amp;lt;https://github.com/guyingbo/shadowproxy&amp;gt;&lt;/code&gt;_ - Awesome python proxy implementation by guyingbo&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>labteral/chatgpt-python</title>
    <updated>2022-12-10T01:35:38Z</updated>
    <id>tag:github.com,2022-12-10:/labteral/chatgpt-python</id>
    <link href="https://github.com/labteral/chatgpt-python" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Unofficial Python SDK for OpenAI&#39;s ChatGPT&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://pypi.python.org/pypi/chatgpt/&#34;&gt;&lt;img alt=&#34;PyPi&#34; src=&#34;https://img.shields.io/pypi/v/chatgpt.svg?style=flat-square&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/labteral/chatgpt-python/raw/master/LICENSE&#34;&gt;&lt;img alt=&#34;License&#34; src=&#34;https://img.shields.io/github/license/labteral/chatgpt-python.svg?style=flat-square&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt; &lt;b&gt;ChatGPT Python SDK&lt;/b&gt; &lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.buymeacoffee.com/brunneis&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;35px&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Install or update&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -U chatgpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Create a file with your credentials&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; &amp;nbsp; Please, update the library. Note the change in the config file.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Create the file &lt;code&gt;config.json&lt;/code&gt; in your working directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;    &#34;email&#34;: &#34;email@example.org&#34;,&#xA;    &#34;password&#34;: &#34;xxx&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;CLI&lt;/h3&gt; &#xA;&lt;p&gt;You can launch the CLI with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;chatgpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m chatgpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;These are the available commands:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;reset&lt;/code&gt;: forget the context of the current conversation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;clear&lt;/code&gt;: clear the terminal.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;exit&lt;/code&gt;: exit the CLI.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;SDK&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from chatgpt import Conversation&#xA;&#xA;conversation = Conversation()&#xA;print(&#xA;    conversation.chat(&#xA;        &#34;We are going to start a conversation. &#34;&#xA;        &#34;I will speak English and you will speak Portuguese.&#34;&#xA;    )&#xA;)&#xA;print(conversation.chat(&#34;What&#39;s the color of the sky?&#34;))&#xA;&#xA;# The AI will forget it was speaking Portuguese&#xA;conversation.reset()&#xA;print(conversation.chat(&#34;What&#39;s the color of the sun?&#34;))&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>