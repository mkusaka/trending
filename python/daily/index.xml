<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-04-11T01:35:03Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>blasty/JiaTansSSHAgent</title>
    <updated>2024-04-11T01:35:03Z</updated>
    <id>tag:github.com,2024-04-11:/blasty/JiaTansSSHAgent</id>
    <link href="https://github.com/blasty/JiaTansSSHAgent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Jia Tan&#39;s SSH Agent&lt;/h1&gt; &#xA;&lt;p&gt;Simple SSH Agent that implements some of the XZ sshd backdoor functionality.&lt;/p&gt; &#xA;&lt;p&gt;For those who want to more easily explore the backdoor using a typical SSH client.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/blasty/JiaTansSSHAgent/master/assets/demo.png&#34; alt=&#34;demo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Generate your own ed448 private key &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;openssl genpkey -algorithm ED448 -outform PEM -out privkey.pem&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Patch your liblzma.so with the ed448 pubkey &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;python3 scripts/patch_liblzma.py privkey.pem liblzma.so liblzma_patched.so&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Patch your SSH client to skip verification of the certificate: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Look for this section in openssh&#39;s &lt;code&gt;sshkey.c&lt;/code&gt; and commment it out:&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;if ((ret = sshkey_verify(key-&amp;gt;cert-&amp;gt;signature_key, sig, slen,&#xA;           sshbuf_ptr(key-&amp;gt;cert-&amp;gt;certblob), signed_len, NULL, 0, NULL)) != 0)&#xA;{&#xA;&#x9;goto out;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;python3 -m virtualenv venv &amp;amp;&amp;amp; . venv/bin/activate &amp;amp;&amp;amp; pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;python3 agent.py /tmp/agent ./privkey.pem&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;SSH_AUTH_SOCK=/tmp/agent ./ssh root@localhost&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;log in with any password :)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;-- blasty &lt;code&gt;&amp;lt;peter@haxx.in&amp;gt;&lt;/code&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Filimoa/open-parse</title>
    <updated>2024-04-11T01:35:03Z</updated>
    <id>tag:github.com,2024-04-11:/Filimoa/open-parse</id>
    <link href="https://github.com/Filimoa/open-parse" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Improved file parsing for LLMâ€™s&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://sergey-filimonov.nyc3.digitaloceanspaces.com/open-parse/open-parse-with-text-tp-logo.webp&#34; width=&#34;350&#34;&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;strong&gt;Easily chunk complex documents the same way a human would.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Chunking documents is a challenging task that underpins any RAG system. High quality results are critical to a sucessful AI application, yet most open-source libraries are limited in their ability to handle complex documents.&lt;/p&gt; &#xA;&lt;p&gt;Open Parse is designed to fill this gap by providing a flexible, easy-to-use library capable of visually discerning document layouts and chunking them effectively.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;How is this different from other layout parsers?&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;h4&gt;âœ‚ï¸ Text Splitting&lt;/h4&gt; &#xA; &lt;p&gt;Text splitting converts a file to raw text and &lt;a href=&#34;https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/token_text_splitter/&#34;&gt;slices it up&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;You lose the ability to easily overlay the chunk on the original pdf&lt;/li&gt; &#xA;  &lt;li&gt;You ignore the underlying semantic structure of the file - headings, sections, bullets represent valuable information.&lt;/li&gt; &#xA;  &lt;li&gt;No support for tables, images or markdown.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;ğŸ¤– ML Layout Parsers&lt;/h4&gt; &#xA; &lt;p&gt;There&#39;s some of fantastic libraries like &lt;a href=&#34;https://github.com/Layout-Parser/layout-parser&#34;&gt;layout-parser&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;While they can identify various elements like text blocks, images, and tables, but they are not built to group related content effectively.&lt;/li&gt; &#xA;  &lt;li&gt;They strictly focus on layout parsing - you will need to add another model to extract markdown from the images, parse tables, group nodes, etc.&lt;/li&gt; &#xA;  &lt;li&gt;We&#39;ve found performance to be sub-optimal on many documents while also being computationally heavy.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;ğŸ’¼ Commercial Solutions&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Typically priced at â‰ˆ $10 / 1k pages. See &lt;a href=&#34;https://cloud.google.com/document-ai&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;https://aws.amazon.com/textract/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://www.reducto.ai/&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt;Requires sharing your data with a vendor&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Highlights&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ” Visually-Driven:&lt;/strong&gt; Open-Parse visually analyzes documents for superior LLM input, going beyond naive text splitting.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;âœï¸ Markdown Support:&lt;/strong&gt; Basic markdown support for parsing headings, bold and italics.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“Š High-Precision Table Support:&lt;/strong&gt; Extract tables into clean Markdown formats with accuracy that surpasses traditional tools.&lt;/p&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;&lt;i&gt;Examples&lt;/i&gt;&lt;/summary&gt; The following examples were parsed with unitable. &#xA;   &lt;br&gt; &#xA;   &lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://sergey-filimonov.nyc3.digitaloceanspaces.com/open-parse/unitable-parsing-sample.webp&#34; width=&#34;650&#34;&gt; &lt;/p&gt; &#xA;   &lt;br&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ› ï¸ Extensible:&lt;/strong&gt; Easily implement your own post-processing steps.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ’¡Intuitive:&lt;/strong&gt; Great editor support. Completion everywhere. Less time debugging.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ¯ Easy:&lt;/strong&gt; Designed to be easy to use and learn. Less time reading docs.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://sergey-filimonov.nyc3.digitaloceanspaces.com/open-parse/marked-up-doc-2.webp&#34; width=&#34;250&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;h4&gt;Basic Example&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import openparse&#xA;&#xA;basic_doc_path = &#34;./sample-docs/mobile-home-manual.pdf&#34;&#xA;parser = openparse.DocumentParser()&#xA;parsed_basic_doc = parser.parse(basic_doc_path)&#xA;&#xA;for node in parsed_basic_doc.nodes:&#xA;    print(node)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;ğŸ““ Try the sample notebook&lt;/strong&gt; &lt;a href=&#34;https://colab.research.google.com/drive/1Z5B5gsnmhFKEFL-5yYIcoox7-jQao8Ep?usp=sharing&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Semantic Processing Example&lt;/h4&gt; &#xA;&lt;p&gt;Chunking documents is fundamentally about grouping similar semantic nodes together. By embedding the text of each node, we can then cluster them together based on their similarity.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from openparse import processing, DocumentParser&#xA;&#xA;semantic_pipeline = processing.SemanticIngestionPipeline(&#xA;    openai_api_key=OPEN_AI_KEY,&#xA;    model=&#34;text-embedding-3-large&#34;,&#xA;    min_tokens=64,&#xA;    max_tokens=1024,&#xA;)&#xA;parser = DocumentParser(&#xA;    processing_pipeline=semantic_pipeline,&#xA;)&#xA;parsed_content = parser.parse(basic_doc_path)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;ğŸ““ Sample notebook&lt;/strong&gt; &lt;a href=&#34;https://github.com/Filimoa/open-parse/raw/main/src/cookbooks/semantic_processing.ipynb&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Serializing Results&lt;/h4&gt; &#xA;&lt;p&gt;Uses pydantic under the hood so you can serialize results with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;parsed_content.dict()&#xA;&#xA;# or to convert to a valid json dict&#xA;parsed_content.json()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;Python 3.8+&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dealing with PDF&#39;s:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pdfminer/pdfminer.six&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;pdfminer.six&lt;/a&gt; Fully open source.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Extracting Tables:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pymupdf/PyMuPDF&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;PyMuPDF&lt;/a&gt; has some table detection functionality. Please see their &lt;a href=&#34;https://mupdf.com/licensing/index.html#commercial&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;license&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/microsoft/table-transformer-detection&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;Table Transformer&lt;/a&gt; is a deep learning approach.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/poloclub/unitable&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;unitable&lt;/a&gt; is another transformers based approach with &lt;strong&gt;state-of-the-art&lt;/strong&gt; performance.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h4&gt;1. Core Library&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;pip install openparse&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Enabling OCR Support&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;p&gt;PyMuPDF will already contain all the logic to support OCR functions. But it additionally does need Tesseractâ€™s language support data, so installation of Tesseract-OCR is still required.&lt;/p&gt; &#xA;&lt;p&gt;The language support folder location must be communicated either via storing it in the environment variable &#34;TESSDATA_PREFIX&#34;, or as a parameter in the applicable functions.&lt;/p&gt; &#xA;&lt;p&gt;So for a working OCR functionality, make sure to complete this checklist:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Install Tesseract.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Locate Tesseractâ€™s language support folder. Typically you will find it here:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Windows: &lt;code&gt;C:/Program Files/Tesseract-OCR/tessdata&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Unix systems: &lt;code&gt;/usr/share/tesseract-ocr/5/tessdata&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Set the environment variable TESSDATA_PREFIX&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Windows: &lt;code&gt;setx TESSDATA_PREFIX &#34;C:/Program Files/Tesseract-OCR/tessdata&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Unix systems: &lt;code&gt;declare -x TESSDATA_PREFIX= /usr/share/tesseract-ocr/5/tessdata&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;em&gt;On Windows systems, this must happen outside Python â€“ before starting your script. Just manipulating os.environ will not work!&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h4&gt;2. ML Table Detection (Optional)&lt;/h4&gt; &#xA;&lt;p&gt;This repository provides an optional feature to parse content from tables using a variety of deep learning models.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;pip install &#34;openparse[ml]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then download the model weights with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;openparse-download&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can run the parsing with the following.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;parser = openparse.DocumentParser(&#xA;        table_args={&#xA;            &#34;parsing_algorithm&#34;: &#34;unitable&#34;,&#xA;            &#34;min_table_confidence&#34;: 0.8,&#xA;        },&#xA;)&#xA;parsed_nodes = parser.parse(pdf_path)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note we currently use &lt;a href=&#34;https://github.com/microsoft/table-transformer&#34;&gt;table-transformers&lt;/a&gt; for all table detection and we find its performance to be subpar. This negatively affects the downstream results of unitable. If you&#39;re aware of a better model please open an Issue - the unitable team mentioned they might add this soon too.&lt;/p&gt; &#xA;&lt;h2&gt;Cookbooks&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Filimoa/open-parse/tree/main/src/cookbooks&#34;&gt;https://github.com/Filimoa/open-parse/tree/main/src/cookbooks&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://filimoa.github.io/open-parse/&#34;&gt;https://filimoa.github.io/open-parse/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Sponsors&lt;/h2&gt; &#xA;&lt;!-- sponsors --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.data.threesigma.ai/filings-ai&#34; target=&#34;_blank&#34; title=&#34;Three Sigma: AI for insurance filings.&#34;&gt;&lt;img src=&#34;https://sergey-filimonov.nyc3.digitaloceanspaces.com/open-parse/marketing/three-sigma-wide.png&#34; width=&#34;250&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- /sponsors --&gt; &#xA;&lt;p&gt;Does your use case need something special? Reach &lt;a href=&#34;https://www.linkedin.com/in/sergey-osu/&#34;&gt;out&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>LlamaFamily/Llama-Chinese</title>
    <updated>2024-04-11T01:35:03Z</updated>
    <id>tag:github.com,2024-04-11:/LlamaFamily/Llama-Chinese</id>
    <link href="https://github.com/LlamaFamily/Llama-Chinese" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Llamaä¸­æ–‡ç¤¾åŒºï¼Œæœ€å¥½çš„ä¸­æ–‡Llamaå¤§æ¨¡å‹ï¼Œå®Œå…¨å¼€æºå¯å•†ç”¨&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;left&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/README_EN.md&#34;&gt;English&lt;/a&gt; ï½œ ä¸­æ–‡ &lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt; Llama-Chinese &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/llama.png&#34; alt=&#34;Llama&#34; style=&#34;width: 20%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;font face=&#34;é»‘ä½“&#34; color=&#34;orange&#34; size=&#34;6&#34;&gt; æœ€å¥½çš„ä¸­æ–‡Llamaå¤§æ¨¡å‹ &lt;/font&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://llama.family&#34;&gt;åœ¨çº¿ä½“éªŒï¼šllama.family&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B-Chat&#34;&gt;åŸºäºLlama2çš„å¼€æºä¸­æ–‡é¢„è®­ç»ƒå¤§æ¨¡å‹Atom-7B&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ—‚ï¸ å†…å®¹å¯¼å¼•&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E7%A4%BE%E5%8C%BA%E4%BB%8B%E7%BB%8Dllama%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA&#34;&gt;ğŸ”¥ ç¤¾åŒºä»‹ç»ï¼šLlamaä¸­æ–‡ç¤¾åŒº&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E7%A4%BE%E5%8C%BA%E5%85%AC%E5%91%8A&#34;&gt;ğŸ“¢ ç¤¾åŒºå…¬å‘Š&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E5%9B%BD%E5%86%85llama2%E6%9C%80%E6%96%B0%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80&#34;&gt;ğŸ¼ å›½å†…Llama2æœ€æ–°ä¸‹è½½åœ°å€&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-atom%E5%A4%A7%E6%A8%A1%E5%9E%8B&#34;&gt;ğŸ”µ Atomå¤§æ¨¡å‹&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%A4%A7%E8%A7%84%E6%A8%A1%E7%9A%84%E4%B8%AD%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E8%AE%AD%E7%BB%83&#34;&gt;å¤§è§„æ¨¡çš„ä¸­æ–‡æ•°æ®é¢„è®­ç»ƒ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E6%9B%B4%E9%AB%98%E6%95%88%E7%9A%84%E4%B8%AD%E6%96%87%E8%AF%8D%E8%A1%A8&#34;&gt;æ›´é«˜æ•ˆçš„ä¸­æ–‡è¯è¡¨&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E8%87%AA%E9%80%82%E5%BA%94%E4%B8%8A%E4%B8%8B%E6%96%87%E6%89%A9%E5%B1%95&#34;&gt;è‡ªé€‚åº”ä¸Šä¸‹æ–‡æ‰©å±•&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E4%B8%AD%E6%96%87%E6%95%B0%E6%8D%AE&#34;&gt;ğŸ“ ä¸­æ–‡æ•°æ®&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2&#34;&gt;â¬ æ¨¡å‹éƒ¨ç½²&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD&#34;&gt;æ¨¡å‹ä¸‹è½½&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#meta%E5%AE%98%E6%96%B9llama2%E6%A8%A1%E5%9E%8B&#34;&gt;Metaå®˜æ–¹Llama2æ¨¡å‹&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%9F%BA%E4%BA%8Ellama2%E7%9A%84%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B&#34;&gt;åŸºäºLlama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%9F%BA%E4%BA%8Ellama2%E7%9A%84%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8Batom&#34;&gt;åŸºäºLlama2çš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹Atom&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%94%A8%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B&#34;&gt;æ¨¡å‹è°ƒç”¨ä»£ç ç¤ºä¾‹&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#fastapi%E6%8E%A5%E5%8F%A3%E6%90%AD%E5%BB%BA&#34;&gt;FastAPIæ¥å£æ­å»º&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#gradio%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E9%97%AE%E7%AD%94%E5%B9%B3%E5%8F%B0&#34;&gt;Gradioå¿«é€Ÿæ­å»ºé—®ç­”å¹³å°&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#docker%E9%83%A8%E7%BD%B2%E9%97%AE%E7%AD%94%E6%8E%A5%E5%8F%A3&#34;&gt;Dockeréƒ¨ç½²é—®ç­”æ¥å£&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83&#34;&gt;ğŸ¤– æ¨¡å‹é¢„è®­ç»ƒ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83&#34;&gt;ğŸ’¡ æ¨¡å‹å¾®è°ƒ&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#step1-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87&#34;&gt;Step1: ç¯å¢ƒå‡†å¤‡&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#step2-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87&#34;&gt;Step2: æ•°æ®å‡†å¤‡&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#step3-%E5%BE%AE%E8%B0%83%E8%84%9A%E6%9C%AC&#34;&gt;Step3: å¾®è°ƒè„šæœ¬&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#lora%E5%BE%AE%E8%B0%83&#34;&gt;LoRAå¾®è°ƒ&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%85%A8%E9%87%8F%E5%8F%82%E6%95%B0%E5%BE%AE%E8%B0%83&#34;&gt;å…¨é‡å‚æ•°å¾®è°ƒ&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#step4-%E5%8A%A0%E8%BD%BD%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B&#34;&gt;Step4: åŠ è½½å¾®è°ƒæ¨¡å‹&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#lora%E5%BE%AE%E8%B0%83-1&#34;&gt;LoRAå¾®è°ƒ&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%85%A8%E9%87%8F%E5%8F%82%E6%95%B0%E5%BE%AE%E8%B0%83-1&#34;&gt;å…¨é‡å‚æ•°å¾®è°ƒ&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96&#34;&gt;ğŸ„ æ¨¡å‹é‡åŒ–&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F&#34;&gt;ğŸš€ æ¨ç†åŠ é€Ÿ&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#TensorRT-LLM&#34;&gt;TensorRT-LLM&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#vllm&#34;&gt;vLLM&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#jittorllms&#34;&gt;JittorLLMs&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#lmdeploy&#34;&gt;lmdeploy&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B&#34;&gt;ğŸ¥‡ æ¨¡å‹è¯„æµ‹&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E5%A4%96%E5%BB%B6%E8%83%BD%E5%8A%9B&#34;&gt;ğŸ’ª å¤–å»¶èƒ½åŠ›&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#langchain&#34;&gt;LangChain&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E4%BB%A3%E7%A0%81%E6%A8%A1%E5%9E%8B&#34;&gt;ğŸ ä»£ç æ¨¡å‹&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99&#34;&gt;ğŸ“– å­¦ä¹ èµ„æ–™&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#meta%E5%AE%98%E6%96%B9%E5%AF%B9%E4%BA%8Ellama2%E7%9A%84%E4%BB%8B%E7%BB%8D&#34;&gt;Metaå®˜æ–¹å¯¹äºLlama2çš„ä»‹ç»&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87&#34;&gt;Llamaç›¸å…³è®ºæ–‡&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama2%E7%9A%84%E8%AF%84%E6%B5%8B%E7%BB%93%E6%9E%9C&#34;&gt;Llama2çš„è¯„æµ‹ç»“æœ&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E8%87%B4%E8%B0%A2&#34;&gt;ğŸ‰ è‡´è°¢&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E9%97%AE%E9%A2%98%E5%8F%8D%E9%A6%88&#34;&gt;ğŸ¤” é—®é¢˜åé¦ˆ&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ”¥ ç¤¾åŒºä»‹ç»ï¼šLlamaä¸­æ–‡ç¤¾åŒº&lt;/h2&gt; &#xA;&lt;p&gt;æ¬¢è¿æ¥åˆ°Llamaä¸­æ–‡ç¤¾åŒºï¼æˆ‘ä»¬æ˜¯ä¸€ä¸ªä¸“æ³¨äºLlamaæ¨¡å‹åœ¨ä¸­æ–‡æ–¹é¢çš„ä¼˜åŒ–å’Œä¸Šå±‚å»ºè®¾çš„é«˜çº§æŠ€æœ¯ç¤¾åŒºã€‚ &lt;strong&gt;*åŸºäºå¤§è§„æ¨¡ä¸­æ–‡æ•°æ®ï¼Œä»é¢„è®­ç»ƒå¼€å§‹å¯¹Llama2æ¨¡å‹è¿›è¡Œä¸­æ–‡èƒ½åŠ›çš„æŒç»­è¿­ä»£å‡çº§*&lt;/strong&gt;ã€‚ æˆ‘ä»¬çƒ­å¿±æ¬¢è¿å¯¹å¤§æ¨¡å‹LLMå……æ»¡çƒ­æƒ…çš„å¼€å‘è€…å’Œç ”ç©¶è€…åŠ å…¥æˆ‘ä»¬çš„è¡Œåˆ—ã€‚&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;h3&gt;ä¸ºä»€ä¹ˆé€‰æ‹©Llama2ä¸­æ–‡ç¤¾åŒºï¼Ÿ&lt;/h3&gt; &#xA; &lt;p&gt;ğŸš€ &lt;strong&gt;é«˜çº§å·¥ç¨‹å¸ˆå›¢é˜Ÿæ”¯æŒ&lt;/strong&gt;ï¼šç¤¾åŒºæœ‰ä¸€æ‰¹ä¸“æ³¨ä¸ºå¤§å®¶æœåŠ¡çš„NLPé«˜çº§å·¥ç¨‹å¸ˆï¼Œæˆ‘ä»¬æœ‰ç€å¼ºå¤§çš„æŠ€æœ¯æ”¯æŒå’Œä¸°å¯Œçš„ç»éªŒï¼Œä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æŒ‡å¯¼å’Œå¸®åŠ©ã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ¯ &lt;strong&gt;ä¸­æ–‡ä¼˜åŒ–&lt;/strong&gt;ï¼šæˆ‘ä»¬è‡´åŠ›äºåœ¨Llama2æ¨¡å‹çš„ä¸­æ–‡å¤„ç†æ–¹é¢è¿›è¡Œä¼˜åŒ–ï¼Œæ¢ç´¢é€‚ç”¨äºä¸­æ–‡çš„æœ€ä½³å®è·µï¼Œä»¥æå‡å…¶æ€§èƒ½å’Œé€‚åº”æ€§ã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ’¡ &lt;strong&gt;åˆ›æ–°äº¤æµ&lt;/strong&gt;ï¼šæˆ‘ä»¬æ‹¥æœ‰ä¸€æ”¯å¯Œæœ‰åˆ›é€ åŠ›å’Œç»éªŒçš„ç¤¾åŒºæˆå‘˜å›¢é˜Ÿï¼Œå®šæœŸç»„ç»‡çº¿ä¸Šæ´»åŠ¨ã€æŠ€æœ¯ç ”è®¨å’Œç»éªŒåˆ†äº«ï¼Œä¿ƒè¿›æˆå‘˜é—´çš„åˆ›æ–°äº¤æµã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸŒ &lt;strong&gt;å…¨çƒè”ç»“&lt;/strong&gt;ï¼šæˆ‘ä»¬æ¬¢è¿æ¥è‡ªä¸–ç•Œå„åœ°çš„å¼€å‘è€…åŠ å…¥ç¤¾åŒºï¼Œæ„å»ºä¸€ä¸ªå¼€æ”¾ã€å¤šå…ƒåŒ–çš„å­¦ä¹ å’Œäº¤æµå¹³å°ã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ¤ &lt;strong&gt;å¼€æ”¾å…±äº«&lt;/strong&gt;ï¼šæˆ‘ä»¬é¼“åŠ±ç¤¾åŒºæˆå‘˜å¼€æºåˆ†äº«ä»£ç å’Œæ¨¡å‹ï¼Œæ¨åŠ¨åˆä½œå…±èµ¢ï¼Œå…±åŒä¿ƒè¿›ä¸­æ–‡NLPæŠ€æœ¯çš„å‘å±•ã€‚&lt;/p&gt; &#xA; &lt;h3&gt;ç¤¾åŒºæ´»åŠ¨&lt;/h3&gt; &#xA; &lt;p&gt;ğŸ—“ï¸ &lt;strong&gt;çº¿ä¸Šè®²åº§&lt;/strong&gt;ï¼šé‚€è¯·è¡Œä¸šå†…ä¸“å®¶è¿›è¡Œçº¿ä¸Šè®²åº§ï¼Œåˆ†äº«Llama2åœ¨ä¸­æ–‡NLPé¢†åŸŸçš„æœ€æ–°æŠ€æœ¯å’Œåº”ç”¨ï¼Œæ¢è®¨å‰æ²¿ç ”ç©¶æˆæœã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ’» &lt;strong&gt;é¡¹ç›®å±•ç¤º&lt;/strong&gt;ï¼šæˆå‘˜å¯å±•ç¤ºè‡ªå·±åœ¨Llama2ä¸­æ–‡ä¼˜åŒ–æ–¹é¢çš„é¡¹ç›®æˆæœï¼Œè·å¾—åé¦ˆå’Œå»ºè®®ï¼Œä¿ƒè¿›é¡¹ç›®åä½œã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ“š &lt;strong&gt;å­¦ä¹ èµ„æº&lt;/strong&gt;ï¼šç¤¾åŒºç»´æŠ¤ä¸°å¯Œçš„å­¦ä¹ èµ„æ–™åº“ï¼ŒåŒ…æ‹¬æ•™ç¨‹ã€æ–‡æ¡£å’Œè®ºæ–‡è§£è¯»ï¼Œä¸ºæˆå‘˜æä¾›å…¨é¢çš„å­¦ä¹ æ”¯æŒã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ“ &lt;strong&gt;è®ºæ–‡è§£è¯»&lt;/strong&gt;ï¼šç¤¾åŒºæˆå‘˜å…±åŒè§£è¯»ä¸Llama2ç›¸å…³çš„æœ€æ–°ç ”ç©¶è®ºæ–‡ï¼Œæ·±å…¥ç†è§£å‰æ²¿ç®—æ³•å’Œæ–¹æ³•ã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ‰ &lt;strong&gt;ä¸»é¢˜æ´»åŠ¨&lt;/strong&gt;ï¼šå®šæœŸä¸¾åŠå„ç±»ä¸»é¢˜æ´»åŠ¨ï¼ŒåŒ…æ‹¬æŒ‘æˆ˜èµ›ã€é»‘å®¢é©¬æ‹‰æ¾å’ŒæŠ€æœ¯æ²™é¾™ï¼Œè®©ç¤¾åŒºæˆå‘˜åœ¨è½»æ¾æ„‰å¿«çš„æ°›å›´ä¸­äº¤æµå’Œå­¦ä¹ ã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸŒŸ &lt;strong&gt;å¥–åŠ±è®¡åˆ’&lt;/strong&gt;ï¼šæˆ‘ä»¬è®¾ç«‹å¥–åŠ±è®¡åˆ’ï¼Œå¯¹ç¤¾åŒºä¸­ç§¯æå‚ä¸ã€è´¡çŒ®ä¼˜ç§€çš„æˆå‘˜ç»™äºˆè£èª‰å’Œå¥–åŠ±ï¼Œæ¿€åŠ±æ›´å¤šä¼˜ç§€äººæ‰çš„åŠ å…¥ã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸ“ˆ &lt;strong&gt;æŠ€æœ¯å’¨è¯¢&lt;/strong&gt;ï¼šæˆ‘ä»¬æä¾›æŠ€æœ¯å’¨è¯¢æœåŠ¡ï¼Œè§£ç­”æ‚¨åœ¨Llama2å¼€å‘å’Œä¼˜åŒ–è¿‡ç¨‹ä¸­é‡åˆ°çš„é—®é¢˜ï¼ŒåŠ©æ‚¨å¿«é€Ÿæ”»å…‹éš¾å…³ã€‚&lt;/p&gt; &#xA; &lt;p&gt;ğŸš€ &lt;strong&gt;é¡¹ç›®åˆä½œ&lt;/strong&gt;ï¼šé¼“åŠ±æˆå‘˜é—´çš„é¡¹ç›®åˆä½œï¼Œå…±åŒæ¢ç´¢Llama2åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ï¼Œæ‰“é€ åˆ›æ–°è§£å†³æ–¹æ¡ˆã€‚&lt;/p&gt; &#xA; &lt;h3&gt;ç«‹å³åŠ å…¥æˆ‘ä»¬ï¼&lt;/h3&gt; &#xA; &lt;p&gt;ğŸ“š &lt;strong&gt;æ„¿æ™¯&lt;/strong&gt;ï¼šæ— è®ºæ‚¨æ˜¯å¯¹Llama2å·²æœ‰ç ”ç©¶å’Œåº”ç”¨ç»éªŒçš„ä¸“ä¸šå¼€å‘è€…ï¼Œè¿˜æ˜¯å¯¹Llama2ä¸­æ–‡ä¼˜åŒ–æ„Ÿå…´è¶£å¹¶å¸Œæœ›æ·±å…¥æ¢ç´¢çš„æ–°æ‰‹ï¼Œæˆ‘ä»¬éƒ½çƒ­åˆ‡æœŸå¾…æ‚¨çš„åŠ å…¥ã€‚åœ¨Llama2ä¸­æ–‡ç¤¾åŒºï¼Œæ‚¨å°†æœ‰æœºä¼šä¸è¡Œä¸šå†…é¡¶å°–äººæ‰å…±åŒäº¤æµï¼Œæºæ‰‹æ¨åŠ¨ä¸­æ–‡NLPæŠ€æœ¯çš„è¿›æ­¥ï¼Œå¼€åˆ›æ›´åŠ ç¾å¥½çš„æŠ€æœ¯æœªæ¥ï¼&lt;/p&gt; &#xA; &lt;p&gt;ğŸ”— &lt;strong&gt;æ¸©é¦¨æç¤º&lt;/strong&gt;ï¼šæœ¬ç¤¾åŒºä¸ºä¸“ä¸šæŠ€æœ¯äº¤æµå¹³å°ï¼Œæˆ‘ä»¬çƒ­åˆ‡æœŸæœ›å¿—åŒé“åˆçš„å¼€å‘è€…å’Œç ”ç©¶è€…åŠ å…¥ã€‚è¯·éµå®ˆç¤¾åŒºå‡†åˆ™ï¼Œå…±åŒç»´æŠ¤ç§¯æå‘ä¸Šçš„å­¦ä¹ æ°›å›´ï¼Œä»»ä½•ä¸Llama2æ— å…³çš„å†…å®¹å’Œå¹¿å‘Šå°†è¢«æ¸…ç†ã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£å’Œæ”¯æŒï¼&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;ğŸ“¢ ç¤¾åŒºå…¬å‘Š&lt;/h2&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2024å¹´03æœˆ08æ—¥ï¼šå¼€æ”¾äº†å…è´¹APIä¾›å¤§å®¶ä½¿ç”¨ï¼ŒåŒ…å«ï¼ˆAtom-1B,7B,13B 3ç§ä¸­æ–‡å¤§æ¨¡å‹ï¼‰&lt;a href=&#34;https://llama.family/docs/chat-completion-v1&#34;&gt;APIä½¿ç”¨é“¾æ¥&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2023å¹´10æœˆ8æ—¥ï¼šæ–°å¢æ¸…åå¤§å­¦JittorLLMsçš„æ¨ç†åŠ é€ŸåŠŸèƒ½&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#jittorllms&#34;&gt;JittorLLMs&lt;/a&gt;ï¼&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2023å¹´9æœˆ12æ—¥ï¼šæ›´æ–°é¢„è®­ç»ƒç‰ˆæœ¬&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B&#34;&gt;Atom-7B&lt;/a&gt;å’Œå¯¹è¯ç‰ˆæœ¬&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B-Chat&#34;&gt;Atom-7B-Chat&lt;/a&gt;æ¨¡å‹å‚æ•°ï¼Œæœ€æ–°çš„ä¸­æ–‡é¢„è®­ç»ƒæ•°æ®é‡ä¸º100B tokenï¼Œè®­ç»ƒè¿›ç¨‹è§&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;ï¼&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2023å¹´9æœˆ2æ—¥ï¼šæ–°å¢æ¨¡å‹&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83&#34;&gt;é¢„è®­ç»ƒä»£ç &lt;/a&gt;å’Œ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83&#34;&gt;å…¨é‡å‚æ•°å¾®è°ƒä»£ç &lt;/a&gt;ï¼&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2023å¹´8æœˆ28æ—¥ï¼šå‘å¸ƒåŸºäºLlama2è¿›è¡Œä¸­æ–‡é¢„è®­ç»ƒçš„å¼€æºå¤§æ¨¡å‹&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B&#34;&gt;Atom-7B&lt;/a&gt;ï¼Œå¹¶å°†æŒç»­æ›´æ–°ï¼Œè¯¦æƒ…å‚è€ƒ&lt;a href=&#34;https://mp.weixin.qq.com/s/Bdx0JTVh1kgPn5ydYxIkEw&#34;&gt;ç¤¾åŒºå…¬ä¼—å·æ–‡ç« &lt;/a&gt;ï¼&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2023å¹´8æœˆ26æ—¥ï¼šæä¾›&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#fastapi%E6%8E%A5%E5%8F%A3%E6%90%AD%E5%BB%BA&#34;&gt;FastAPI&lt;/a&gt;æ¥å£æ­å»ºè„šæœ¬ï¼&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2023å¹´8æœˆ26æ—¥ï¼šæä¾›å°†MetaåŸå§‹æ¨¡å‹å‚æ•°è½¬æ¢ä¸ºå…¼å®¹Hugging Faceçš„&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/scripts/convert2hf/README.md&#34;&gt;æ ¼å¼è½¬åŒ–è„šæœ¬&lt;/a&gt;ï¼&lt;/p&gt; &#xA;&lt;p&gt;ã€æœ€æ–°ã€‘2023å¹´8æœˆ26æ—¥ï¼šæ–°å¢&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E4%BB%A3%E7%A0%81%E6%A8%A1%E5%9E%8B&#34;&gt;Code Llama&lt;/a&gt;æ¨¡å‹ï¼&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´8æœˆ15æ—¥ï¼šæ–°å¢&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%8A%A0%E8%BD%BD%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B&#34;&gt;PEFTåŠ è½½å¾®è°ƒæ¨¡å‹å‚æ•°&lt;/a&gt;çš„ä»£ç ç¤ºä¾‹ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´8æœˆ14æ—¥ï¼š&lt;a href=&#34;https://llama.family&#34;&gt;å¤§æ¨¡å‹æ•°æ®å…±äº«è®­ç»ƒå¹³å°&lt;/a&gt;ä¸Šçº¿ï¼Œæ²¡æœ‰ç®—åŠ›ä¹Ÿèƒ½å‚ä¸å¤§æ¨¡å‹è®­ç»ƒï¼Œç¤¾åŒºæ¯ä½æˆå‘˜è´¡çŒ®çš„æ•°æ®éƒ½å°†å†³å®šæ¨¡å‹èƒ½åŠ›çš„æœªæ¥èµ°å‘ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´8æœˆ3æ—¥ï¼šæ–°å¢FasterTransformerå’ŒvLLMçš„GPU&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F&#34;&gt;æ¨ç†åŠ é€Ÿ&lt;/a&gt;æ”¯æŒï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ31æ—¥ï¼šã€é‡ç£…ã€‘å›½å†…é¦–ä¸ªçœŸæ­£æ„ä¹‰ä¸Šçš„Llama2ä¸­æ–‡å¤§æ¨¡å‹å‘å¸ƒï¼è¯¦æƒ…å‚è§&lt;a href=&#34;https://mp.weixin.qq.com/s/lExUU7z_MvgJ7tzQPF8tUQ&#34;&gt;ç¤¾åŒºå…¬ä¼—å·æ–‡ç« &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ28æ—¥ï¼šé€šè¿‡&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#docker%E9%83%A8%E7%BD%B2%E9%97%AE%E7%AD%94%E6%8E%A5%E5%8F%A3&#34;&gt;Dockeréƒ¨ç½²&lt;/a&gt;é—®ç­”æ¥å£ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ27æ—¥ï¼šæ–°å¢&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#langchain&#34;&gt;LangChain&lt;/a&gt;æ”¯æŒï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ26æ—¥ï¼šæ–°å¢Llama2-13Bä¸­æ–‡å¾®è°ƒå‚æ•°çš„&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96&#34;&gt;4bité‡åŒ–å‹ç¼©ç‰ˆæœ¬&lt;/a&gt;ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ25æ—¥ï¼šç¤¾åŒºå¾®ä¿¡å…¬ä¼—å·â€œLlamaä¸­æ–‡ç¤¾åŒºâ€æ¬¢è¿å¤§å®¶å…³æ³¨ï¼Œè·å–æœ€æ–°åˆ†äº«å’ŒåŠ¨æ€ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ24æ—¥ï¼š&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;FlagAlpha&lt;/a&gt;æ–°å¢Llama2-13Bä¸­æ–‡å¾®è°ƒå‚æ•°ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ24æ—¥ï¼š&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;æ–°å¢Llama2-70Båœ¨çº¿ä½“éªŒï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ23æ—¥ï¼šLlama2ä¸­æ–‡å¾®è°ƒå‚æ•°å‘å¸ƒè‡³Hugging Faceä»“åº“&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;FlagAlpha&lt;/a&gt;ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ22æ—¥ï¼šLlama2åœ¨çº¿ä½“éªŒé“¾æ¥&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;ä¸Šçº¿ï¼ŒåŒæ—¶åŒ…å«MetaåŸç‰ˆå’Œä¸­æ–‡å¾®è°ƒç‰ˆæœ¬ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ21æ—¥ï¼šè¯„æµ‹äº†MetaåŸå§‹ç‰ˆLlama2 Chatæ¨¡å‹çš„&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B&#34;&gt;ä¸­æ–‡é—®ç­”èƒ½åŠ›&lt;/a&gt;ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ21æ—¥ï¼šæ–°å¢Llama2æ¨¡å‹çš„Hugging Faceç‰ˆæœ¬å›½å†…ä¸‹è½½åœ°å€ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ20æ—¥ï¼šæ–°å¢&lt;a href=&#34;https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink&#34;&gt;é£ä¹¦çŸ¥è¯†åº“æ–‡æ¡£&lt;/a&gt;ï¼Œæ¬¢è¿å¤§å®¶ä¸€èµ·å…±å»ºï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ20æ—¥ï¼šå›½å†…Llama2æœ€æ–°ä¸‹è½½åœ°å€ä¸Šçº¿ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ19æ—¥ï¼šæ­£å¼å¯åŠ¨Llama2æ¨¡å‹çš„ä¸­æ–‡é¢„è®­ç»ƒï¼Œå…³æ³¨æˆ‘ä»¬è·å–å®æ—¶åŠ¨æ€ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ19æ—¥ï¼šLlama2å›½å†…ä¸‹è½½åœ°å€æ­£åœ¨å¯åŠ¨ï¼Œæ•¬è¯·æœŸå¾…ï¼&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023å¹´7æœˆ19æ—¥ï¼šå¼€å¯Llama2ä¸­æ–‡ç¤¾åŒºï¼Œæ¬¢è¿å¤§å®¶åŠ å…¥ï¼&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;ğŸ¼ å›½å†…Llama2æœ€æ–°ä¸‹è½½åœ°å€&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬ä»“åº“ä¸­çš„ä»£ç ç¤ºä¾‹ä¸»è¦æ˜¯åŸºäºHugging Faceç‰ˆæœ¬å‚æ•°è¿›è¡Œè°ƒç”¨ï¼Œæˆ‘ä»¬æä¾›äº†è„šæœ¬å°†Metaå®˜ç½‘å‘å¸ƒçš„æ¨¡å‹å‚æ•°è½¬æ¢ä¸ºHugging Faceæ”¯æŒçš„æ ¼å¼ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡transformersåº“è¿›è¡ŒåŠ è½½ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/scripts/convert2hf/README.md&#34;&gt;å‚æ•°æ ¼å¼è½¬åŒ–&lt;/a&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-7Bå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_kR2fwuJdG1F3CoF33rwpIA1?pwd=z9kf&#34;&gt;https://pan.xunlei.com/s/VN_kR2fwuJdG1F3CoF33rwpIA1?pwd=z9kf&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-7B-Chatå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_kQa1_HBvV-X9QVI6jV2kOA1?pwd=xmra&#34;&gt;https://pan.xunlei.com/s/VN_kQa1_HBvV-X9QVI6jV2kOA1?pwd=xmra&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-13Bå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_izibaMDoptluWodzJw4cRA1?pwd=2qqb&#34;&gt;https://pan.xunlei.com/s/VN_izibaMDoptluWodzJw4cRA1?pwd=2qqb&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-13B-Chatå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_iyyponyapjIDLXJCNfqy7A1?pwd=t3xw&#34;&gt;https://pan.xunlei.com/s/VN_iyyponyapjIDLXJCNfqy7A1?pwd=t3xw&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-7B Hugging Faceç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep&#34;&gt;https://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-7B-Chat Hugging Faceç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir&#34;&gt;https://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-13B Hugging Faceç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf&#34;&gt;https://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-13B-Chat Hugging Faceç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg&#34;&gt;https://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-70B-Chat Hugging Faceç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VNa_vCGzCy3h3N7oeFXs2W1hA1?pwd=uhxh#&#34;&gt;https://pan.xunlei.com/s/VNa_vCGzCy3h3N7oeFXs2W1hA1?pwd=uhxh#&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;CodeLlama-7bå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.baidu.com/s/1cIPzdNywWLvQI7_2QanOEQ?pwd=zfwi&#34;&gt;https://pan.baidu.com/s/1cIPzdNywWLvQI7_2QanOEQ?pwd=zfwi&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;CodeLlama-7b-Pythonå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.baidu.com/s/1liY8klGoDagYbpw-g-oFag?pwd=i952&#34;&gt;https://pan.baidu.com/s/1liY8klGoDagYbpw-g-oFag?pwd=i952&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;CodeLlama-7b-Instructå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.baidu.com/s/108o9_DT2E_vfSGtOnDCQVw?pwd=zkt9&#34;&gt;https://pan.baidu.com/s/108o9_DT2E_vfSGtOnDCQVw?pwd=zkt9&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;CodeLlama-13bå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.baidu.com/s/1lLaeHv0XEBv0iiZzI1dpnw?pwd=qn99&#34;&gt;https://pan.baidu.com/s/1lLaeHv0XEBv0iiZzI1dpnw?pwd=qn99&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;CodeLlama-13b-Pythonå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.baidu.com/s/1OLVfvZS_oqL3oqMKwsI87w?pwd=a78k&#34;&gt;https://pan.baidu.com/s/1OLVfvZS_oqL3oqMKwsI87w?pwd=a78k&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;CodeLlama-13b-Instructå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.baidu.com/s/1HyxJl4w8wElgkZRh2ATrXQ?pwd=seg6&#34;&gt;https://pan.baidu.com/s/1HyxJl4w8wElgkZRh2ATrXQ?pwd=seg6&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;CodeLlama-34bå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.baidu.com/s/1vEw0pFgIkctPUN4_5_6pIQ?pwd=q8eu&#34;&gt;https://pan.baidu.com/s/1vEw0pFgIkctPUN4_5_6pIQ?pwd=q8eu&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;ğŸ”µ Atomå¤§æ¨¡å‹&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;åŸå­å¤§æ¨¡å‹Atom&lt;/strong&gt;ç”±Llamaä¸­æ–‡ç¤¾åŒºå’ŒåŸå­å›å£°è”åˆæ‰“é€ ï¼Œåœ¨ä¸­æ–‡å¤§æ¨¡å‹è¯„æµ‹æ¦œå•C-Evalä¸­ä½å±…å‰åï¼ˆ8æœˆ21æ—¥è¯„æµ‹æäº¤æ—¶é—´ï¼‰ã€‚&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/ceval.jpg&#34; alt=&#34;ceval&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Atomç³»åˆ—æ¨¡å‹åŒ…å«Atom-7Bå’ŒAtom-13Bï¼ŒåŸºäºLlama2åšäº†ä¸­æ–‡èƒ½åŠ›çš„æŒç»­ä¼˜åŒ–ã€‚Atom-7Bå’ŒAtom-7B-Chatç›®å‰å·²å®Œå…¨å¼€æºï¼Œæ”¯æŒå•†ç”¨ï¼Œå¯åœ¨&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;Hugging Face&lt;/a&gt;ä»“åº“è·å–æ¨¡å‹ï¼Œè¯¦æƒ…è§&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%9F%BA%E4%BA%8Ellama2%E7%9A%84%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8Batom&#34;&gt;Atom-7Bä¸‹è½½&lt;/a&gt;ã€‚Atomå¤§æ¨¡å‹é’ˆå¯¹ä¸­æ–‡åšäº†ä»¥ä¸‹ä¼˜åŒ–ï¼š&lt;/p&gt; &#xA;&lt;h3&gt;å¤§è§„æ¨¡çš„ä¸­æ–‡æ•°æ®é¢„è®­ç»ƒ&lt;/h3&gt; &#xA;&lt;p&gt;åŸå­å¤§æ¨¡å‹Atomåœ¨Llama2çš„åŸºç¡€ä¸Šï¼Œé‡‡ç”¨å¤§è§„æ¨¡çš„ä¸­æ–‡æ•°æ®è¿›è¡ŒæŒç»­é¢„è®­ç»ƒï¼ŒåŒ…å«ç™¾ç§‘ã€ä¹¦ç±ã€åšå®¢ã€æ–°é—»ã€å…¬å‘Šã€å°è¯´ã€é‡‘èæ•°æ®ã€æ³•å¾‹æ•°æ®ã€åŒ»ç–—æ•°æ®ã€ä»£ç æ•°æ®ã€ä¸“ä¸šè®ºæ–‡æ•°æ®ã€ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†ç«èµ›æ•°æ®é›†ç­‰ï¼Œè¯¦è§&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90&#34;&gt;ğŸ“ æ•°æ®æ¥æº&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;åŒæ—¶å¯¹åºå¤§çš„æ•°æ®è¿›è¡Œäº†è¿‡æ»¤ã€æ‰“åˆ†ã€å»é‡ï¼Œç­›é€‰å‡ºè¶…è¿‡1T tokençš„é«˜è´¨é‡ä¸­æ–‡æ•°æ®ï¼ŒæŒç»­ä¸æ–­åŠ å…¥è®­ç»ƒè¿­ä»£ä¸­ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;æ›´é«˜æ•ˆçš„ä¸­æ–‡è¯è¡¨&lt;/h3&gt; &#xA;&lt;p&gt;ä¸ºäº†æé«˜ä¸­æ–‡æ–‡æœ¬å¤„ç†çš„æ•ˆç‡ï¼Œæˆ‘ä»¬é’ˆå¯¹Llama2æ¨¡å‹çš„è¯è¡¨è¿›è¡Œäº†æ·±åº¦ä¼˜åŒ–ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åŸºäºæ•°ç™¾Gçš„ä¸­æ–‡æ–‡æœ¬ï¼Œåœ¨è¯¥æ¨¡å‹è¯è¡¨çš„åŸºç¡€ä¸Šæ‰©å±•è¯åº“è‡³65,000ä¸ªå•è¯ã€‚ç»è¿‡æµ‹è¯•ï¼Œæˆ‘ä»¬çš„æ”¹è¿›ä½¿å¾—ä¸­æ–‡ç¼–ç /è§£ç é€Ÿåº¦æé«˜äº†çº¦350ï¼…ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ‰©å¤§äº†ä¸­æ–‡å­—ç¬¦é›†çš„è¦†ç›–èŒƒå›´ï¼ŒåŒ…æ‹¬æ‰€æœ‰emojiç¬¦å·ğŸ˜Šã€‚è¿™ä½¿å¾—ç”Ÿæˆå¸¦æœ‰è¡¨æƒ…ç¬¦å·çš„æ–‡ç« æ›´åŠ é«˜æ•ˆã€‚&lt;/p&gt; &#xA;&lt;h3&gt;è‡ªé€‚åº”ä¸Šä¸‹æ–‡æ‰©å±•&lt;/h3&gt; &#xA;&lt;p&gt;Atomå¤§æ¨¡å‹é»˜è®¤æ”¯æŒ4Kä¸Šä¸‹æ–‡ï¼Œåˆ©ç”¨ä½ç½®æ’å€¼PIå’ŒNeural Tangent Kernel ï¼ˆNTKï¼‰æ–¹æ³•ï¼Œç»è¿‡å¾®è°ƒå¯ä»¥å°†ä¸Šä¸‹æ–‡é•¿åº¦æ‰©å¢åˆ°32Kã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“ ä¸­æ–‡æ•°æ®&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹æ•°æ®æ¥ä¼˜åŒ–Llama2çš„ä¸­æ–‡èƒ½åŠ›:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ç±»å‹&lt;/th&gt; &#xA;   &lt;th&gt;æè¿°&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ç½‘ç»œæ•°æ®&lt;/td&gt; &#xA;   &lt;td&gt;äº’è”ç½‘ä¸Šå…¬å¼€çš„ç½‘ç»œæ•°æ®ï¼ŒæŒ‘é€‰å‡ºå»é‡åçš„é«˜è´¨é‡ä¸­æ–‡æ•°æ®ï¼Œæ¶‰åŠåˆ°ç™¾ç§‘ã€ä¹¦ç±ã€åšå®¢ã€æ–°é—»ã€å…¬å‘Šã€å°è¯´ç­‰é«˜è´¨é‡é•¿æ–‡æœ¬æ•°æ®ã€‚&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/goldsmith/Wikipedia&#34;&gt;Wikipedia&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸­æ–‡Wikipediaçš„æ•°æ®&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/BAAI-WuDao/Model&#34;&gt;æ‚Ÿé“&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸­æ–‡æ‚Ÿé“å¼€æºçš„200Gæ•°æ®&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/CLUEbenchmark/CLUEDatasetSearch&#34;&gt;Clue&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Clueå¼€æ”¾çš„ä¸­æ–‡é¢„è®­ç»ƒæ•°æ®ï¼Œè¿›è¡Œæ¸…æ´—åçš„é«˜è´¨é‡ä¸­æ–‡é•¿æ–‡æœ¬æ•°æ®&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ç«èµ›æ•°æ®é›†&lt;/td&gt; &#xA;   &lt;td&gt;è¿‘å¹´æ¥ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†å¤šä»»åŠ¡ç«èµ›æ•°æ®é›†ï¼Œçº¦150ä¸ª&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/esbatmop/MNBVC&#34;&gt;MNBVC&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MNBVC ä¸­æ¸…æ´—å‡ºæ¥çš„éƒ¨åˆ†æ•°æ®é›†&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;å¸Œæœ›å¤§å®¶å¦‚æœæœ‰è¾ƒé«˜è´¨é‡çš„æ•°æ®é›†èƒ½å¤Ÿæä¾›ç»™æˆ‘ä»¬ï¼Œä¸èƒœæ„Ÿæ¿€!ğŸ’•ğŸ’•&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;â¬ æ¨¡å‹éƒ¨ç½²&lt;/h2&gt; &#xA;&lt;p&gt;Metaåœ¨ğŸ¤—Hugging Faceä¸Šæä¾›äº†æ‰€æœ‰æ¨¡å‹çš„ä¸‹è½½é“¾æ¥ï¼š&lt;a href=&#34;https://huggingface.co/meta-llama&#34;&gt;https://huggingface.co/meta-llama&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Llamaä¸­æ–‡ç¤¾åŒºçš„ä¸­æ–‡æ¨¡å‹ä¸‹è½½é“¾æ¥ï¼š&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;https://huggingface.co/FlagAlpha&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;æ¨¡å‹ä¸‹è½½&lt;/h3&gt; &#xA;&lt;h4&gt;Metaå®˜æ–¹Llama2æ¨¡å‹&lt;/h4&gt; &#xA;&lt;p&gt;Llama2é¢„è®­ç»ƒæ¨¡å‹åŒ…å«7Bã€13Bå’Œ70Bä¸‰ä¸ªç‰ˆæœ¬ã€‚Llama2-Chatæ¨¡å‹åŸºäºé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œäº†ç›‘ç£å¾®è°ƒï¼Œå…·å¤‡æ›´å¼ºçš„å¯¹è¯èƒ½åŠ›ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ç±»åˆ«&lt;/th&gt; &#xA;   &lt;th&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ğŸ¤—æ¨¡å‹åŠ è½½åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ä¸‹è½½åœ°å€&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;é¢„è®­ç»ƒ&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-7B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;é¢„è®­ç»ƒ&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-13B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-13b-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;é¢„è®­ç»ƒ&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-70B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-70b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-70b-hf&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-chat-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-13B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-13b-chat-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-70B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-70b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-70b-chat-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VNa_vCGzCy3h3N7oeFXs2W1hA1?pwd=uhxh#&#34;&gt;è¿…é›·ç½‘ç›˜&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;åŸºäºLlama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹&lt;/h4&gt; &#xA;&lt;p&gt;æˆ‘ä»¬åŸºäºä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†å¯¹Llama2-Chatæ¨¡å‹è¿›è¡Œäº†å¾®è°ƒï¼Œä½¿å¾—Llama2æ¨¡å‹æœ‰ç€æ›´å¼ºçš„ä¸­æ–‡å¯¹è¯èƒ½åŠ›ã€‚LoRAå‚æ•°ä»¥åŠä¸åŸºç¡€æ¨¡å‹åˆå¹¶çš„å‚æ•°å‡å·²ä¸Šä¼ è‡³&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;Hugging Face&lt;/a&gt;ï¼Œç›®å‰åŒ…å«7Bå’Œ13Bçš„æ¨¡å‹ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ç±»åˆ«&lt;/th&gt; &#xA;   &lt;th&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ğŸ¤—æ¨¡å‹åŠ è½½åç§°&lt;/th&gt; &#xA;   &lt;th&gt;åŸºç¡€æ¨¡å‹ç‰ˆæœ¬&lt;/th&gt; &#xA;   &lt;th&gt;ä¸‹è½½åœ°å€&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;åˆå¹¶å‚æ•°&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-Chinese-7b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-7b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;åˆå¹¶å‚æ•°&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-Chinese-13b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-13b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRAå‚æ•°&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-Chinese-7b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-7b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat-LoRA&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRAå‚æ•°&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-Chinese-13b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-13b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-LoRA&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;åŸºäºLlama2çš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹Atom&lt;/h4&gt; &#xA;&lt;p&gt;ç¤¾åŒºæä¾›é¢„è®­ç»ƒç‰ˆæœ¬Atom-7Bå’ŒåŸºäºAtom-7Bè¿›è¡Œå¯¹è¯å¾®è°ƒçš„æ¨¡å‹å‚æ•°ä¾›å¼€æ”¾ä¸‹è½½ï¼Œæ¨¡å‹å‚æ•°ä¼šæŒç»­ä¸æ–­æ›´æ–°ï¼Œå…³äºæ¨¡å‹çš„è¿›å±•è¯¦è§ç¤¾åŒºå®˜ç½‘&lt;a href=&#34;https://llama.family&#34;&gt;llama.family&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ç±»åˆ«&lt;/th&gt; &#xA;   &lt;th&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ğŸ¤—æ¨¡å‹åŠ è½½åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ä¸‹è½½åœ°å€&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;é¢„è®­ç»ƒ&lt;/td&gt; &#xA;   &lt;td&gt;Atom-7B&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Atom-7B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://modelscope.cn/models/FlagAlpha/Atom-7B&#34;&gt;ModelScope&lt;/a&gt; | &lt;a href=&#34;https://wisemodel.cn/models/FlagAlpha/Atom-7B&#34;&gt;WiseModel&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;Atom-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Atom-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B-Chat&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://modelscope.cn/models/FlagAlpha/Atom-7B-Chat&#34;&gt;ModelScope&lt;/a&gt; | &lt;a href=&#34;https://wisemodel.cn/models/FlagAlpha/Atom-7B-Chat&#34;&gt;WiseModel&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;æ¨¡å‹è°ƒç”¨ä»£ç ç¤ºä¾‹&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;device_map = &#34;cuda:0&#34; if torch.cuda.is_available() else &#34;auto&#34;&#xA;model = AutoModelForCausalLM.from_pretrained(&#39;FlagAlpha/Atom-7B-Chat&#39;,device_map=device_map,torch_dtype=torch.float16,load_in_8bit=True,trust_remote_code=True,use_flash_attention_2=True)&#xA;model =model.eval()&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;FlagAlpha/Atom-7B-Chat&#39;,use_fast=False)&#xA;tokenizer.pad_token = tokenizer.eos_token&#xA;input_ids = tokenizer([&#39;&amp;lt;s&amp;gt;Human: ä»‹ç»ä¸€ä¸‹ä¸­å›½\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#39;], return_tensors=&#34;pt&#34;,add_special_tokens=False).input_ids&#xA;if torch.cuda.is_available():&#xA;  input_ids = input_ids.to(&#39;cuda&#39;)&#xA;generate_input = {&#xA;    &#34;input_ids&#34;:input_ids,&#xA;    &#34;max_new_tokens&#34;:512,&#xA;    &#34;do_sample&#34;:True,&#xA;    &#34;top_k&#34;:50,&#xA;    &#34;top_p&#34;:0.95,&#xA;    &#34;temperature&#34;:0.3,&#xA;    &#34;repetition_penalty&#34;:1.3,&#xA;    &#34;eos_token_id&#34;:tokenizer.eos_token_id,&#xA;    &#34;bos_token_id&#34;:tokenizer.bos_token_id,&#xA;    &#34;pad_token_id&#34;:tokenizer.pad_token_id&#xA;}&#xA;generate_ids  = model.generate(**generate_input)&#xA;text = tokenizer.decode(generate_ids[0])&#xA;print(text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;FastAPIæ¥å£æ­å»º&lt;/h3&gt; &#xA;&lt;p&gt;ä¸ºäº†æ–¹ä¾¿é€šè¿‡APIæ–¹å¼è°ƒç”¨æ¨¡å‹ï¼Œæˆ‘ä»¬æä¾›äº†è„šæœ¬ç”¨æ¥å¿«é€Ÿæ­å»º&lt;a href=&#34;https://github.com/tiangolo/fastapi&#34;&gt;FastAPI&lt;/a&gt;æ¥å£ï¼Œç›¸å…³æµ‹è¯•ä»£ç ä¸APIå‚æ•°è®¾ç½®è§&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/scripts/api/README.md&#34;&gt;API è°ƒç”¨&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Gradioå¿«é€Ÿæ­å»ºé—®ç­”å¹³å°&lt;/h3&gt; &#xA;&lt;p&gt;åŸºäºgradioæ­å»ºçš„é—®ç­”ç•Œé¢ï¼Œå®ç°äº†æµå¼çš„è¾“å‡ºï¼Œå°†ä¸‹é¢ä»£ç å¤åˆ¶åˆ°æ§åˆ¶å°è¿è¡Œï¼Œä»¥ä¸‹ä»£ç ä»¥Atom-7Bæ¨¡å‹ä¸ºä¾‹ï¼Œ&lt;font color=&#34;#006600&#34;&gt;ä¸åŒæ¨¡å‹åªéœ€ä¿®æ”¹ä¸€ä¸‹ä»£ç é‡Œçš„æ¨¡å‹åç§°å°±å¥½äº†ğŸ˜Š&lt;/font&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python examples/chat_gradio.py --model_name_or_path FlagAlpha/Atom-7B-Chat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Dockeréƒ¨ç½²é—®ç­”æ¥å£&lt;/h3&gt; &#xA;&lt;p&gt;è¯¦æƒ…å‚è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/docs/chat_gradio_guide.md&#34;&gt;Dockeréƒ¨ç½²&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡dockeré•œåƒï¼Œé€šè¿‡dockerå®¹å™¨å¯åŠ¨&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/examples/chat_gradio.py&#34;&gt;chat_gradio.py&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/LlamaFamily/Llama-Chinese.git&#xA;&#xA;cd Llama-Chinese&#xA;&#xA;docker build -f docker/Dockerfile -t flagalpha/llama2-chinese:gradio .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ç¬¬äºŒæ­¥ï¼šé€šè¿‡docker-composeå¯åŠ¨chat_gradio&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd Llama-Chinese/docker&#xA;docker-compose up -d --build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ğŸ¤– æ¨¡å‹é¢„è®­ç»ƒ&lt;/h2&gt; &#xA;&lt;p&gt;è™½ç„¶Llama2çš„é¢„è®­ç»ƒæ•°æ®ç›¸å¯¹äºç¬¬ä¸€ä»£LLaMAæ‰©å¤§äº†ä¸€å€ï¼Œä½†æ˜¯ä¸­æ–‡é¢„è®­ç»ƒæ•°æ®çš„æ¯”ä¾‹ä¾ç„¶éå¸¸å°‘ï¼Œä»…å 0.13%ï¼Œè¿™ä¹Ÿå¯¼è‡´äº†åŸå§‹Llama2çš„ä¸­æ–‡èƒ½åŠ›è¾ƒå¼±ã€‚ä¸ºäº†èƒ½å¤Ÿæå‡æ¨¡å‹çš„ä¸­æ–‡èƒ½åŠ›ï¼Œå¯ä»¥é‡‡ç”¨å¾®è°ƒå’Œé¢„è®­ç»ƒä¸¤ç§è·¯å¾„ï¼Œå…¶ä¸­ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;å¾®è°ƒéœ€è¦çš„ç®—åŠ›èµ„æºå°‘ï¼Œèƒ½å¤Ÿå¿«é€Ÿå®ç°ä¸€ä¸ªä¸­æ–‡Llamaçš„é›å½¢ã€‚ä½†ç¼ºç‚¹ä¹Ÿæ˜¾è€Œæ˜“è§ï¼Œåªèƒ½æ¿€å‘åŸºåº§æ¨¡å‹å·²æœ‰çš„ä¸­æ–‡èƒ½åŠ›ï¼Œç”±äºLlama2çš„ä¸­æ–‡è®­ç»ƒæ•°æ®æœ¬èº«è¾ƒå°‘ï¼Œæ‰€ä»¥èƒ½å¤Ÿæ¿€å‘çš„èƒ½åŠ›ä¹Ÿæœ‰é™ï¼Œæ²»æ ‡ä¸æ²»æœ¬ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;åŸºäºå¤§è§„æ¨¡ä¸­æ–‡è¯­æ–™è¿›è¡Œé¢„è®­ç»ƒï¼Œæˆæœ¬é«˜ï¼Œä¸ä»…éœ€è¦å¤§è§„æ¨¡é«˜è´¨é‡çš„ä¸­æ–‡æ•°æ®ï¼Œä¹Ÿéœ€è¦å¤§è§„æ¨¡çš„ç®—åŠ›èµ„æºã€‚ä½†æ˜¯ä¼˜ç‚¹ä¹Ÿæ˜¾è€Œæ˜“è§ï¼Œå°±æ˜¯èƒ½ä»æ¨¡å‹åº•å±‚ä¼˜åŒ–ä¸­æ–‡èƒ½åŠ›ï¼ŒçœŸæ­£è¾¾åˆ°æ²»æœ¬çš„æ•ˆæœï¼Œä»å†…æ ¸ä¸ºå¤§æ¨¡å‹æ³¨å…¥å¼ºå¤§çš„ä¸­æ–‡èƒ½åŠ›ã€‚&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;æˆ‘ä»¬ä¸ºç¤¾åŒºæä¾›äº†Llamaæ¨¡å‹çš„é¢„è®­ç»ƒä»£ç ï¼Œä»¥åŠ&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/tree/main/data&#34;&gt;ä¸­æ–‡æµ‹è¯•è¯­æ–™&lt;/a&gt;ï¼Œæ›´å¤šæ•°æ®å¯ä»¥å‚è€ƒ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E4%B8%AD%E6%96%87%E6%95%B0%E6%8D%AE&#34;&gt;ä¸­æ–‡è¯­æ–™&lt;/a&gt;ã€‚å…·ä½“ä»£ç å’Œé…ç½®å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/pretrain.sh&#34;&gt;train/pretrain/pretrain.sh&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;é¢„è®­ç»ƒå®ç°ä»£ç ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/pretrain_clm.py&#34;&gt;train/pretrain/pretrain_clm.py&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/DeepSpeed&#34;&gt;DeepSpeed&lt;/a&gt;åŠ é€Ÿï¼š &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;å¯¹äºå•å¡è®­ç»ƒï¼Œå¯ä»¥é‡‡ç”¨ZeRO-2çš„æ–¹å¼ï¼Œå‚æ•°é…ç½®è§ &lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/ds_config_zero2.json&#34;&gt;train/pretrain/ds_config_zero2.json&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;å¯¹äºå¤šå¡è®­ç»ƒï¼Œå¯ä»¥é‡‡ç”¨ZeRO-3çš„æ–¹å¼ï¼Œå‚æ•°é…ç½®è§ &lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/ds_config_zero3.json&#34;&gt;train/pretrain/ds_config_zero3.json&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;è®­ç»ƒæ•ˆæœåº¦é‡æŒ‡æ ‡ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/accuracy.py&#34;&gt;train/pretrain/accuracy.py&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ’¡ æ¨¡å‹å¾®è°ƒ&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬ä»“åº“ä¸­åŒæ—¶æä¾›äº†LoRAå¾®è°ƒå’Œå…¨é‡å‚æ•°å¾®è°ƒä»£ç ï¼Œå…³äºLoRAçš„è¯¦ç»†ä»‹ç»å¯ä»¥å‚è€ƒè®ºæ–‡â€œ&lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;LoRA: Low-Rank Adaptation of Large Language Models&lt;/a&gt;â€ä»¥åŠå¾®è½¯Githubä»“åº“&lt;a href=&#34;https://github.com/microsoft/LoRA&#34;&gt;LoRA&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Step1: ç¯å¢ƒå‡†å¤‡&lt;/h3&gt; &#xA;&lt;p&gt;æ ¹æ®&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/requirements.txt&#34;&gt;requirements.txt&lt;/a&gt;å®‰è£…å¯¹åº”çš„ç¯å¢ƒä¾èµ–ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Step2: æ•°æ®å‡†å¤‡&lt;/h3&gt; &#xA;&lt;p&gt;åœ¨dataç›®å½•ä¸‹æä¾›äº†ä¸€ä»½ç”¨äºæ¨¡å‹sftçš„æ•°æ®æ ·ä¾‹ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;è®­ç»ƒæ•°æ®ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/data/train_sft.csv&#34;&gt;data/train_sft.csv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;éªŒè¯æ•°æ®ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/data/dev_sft.csv&#34;&gt;data/dev_sft.csv&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;æ¯ä¸ªcsvæ–‡ä»¶ä¸­åŒ…å«ä¸€åˆ—â€œtextâ€ï¼Œæ¯ä¸€è¡Œä¸ºä¸€ä¸ªè®­ç»ƒæ ·ä¾‹ï¼Œæ¯ä¸ªè®­ç»ƒæ ·ä¾‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å°†é—®é¢˜å’Œç­”æ¡ˆç»„ç»‡ä¸ºæ¨¡å‹è¾“å…¥ï¼Œæ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è‡ªå®šä¹‰è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#34;&amp;lt;s&amp;gt;Human: &#34;+é—®é¢˜+&#34;\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#34;+ç­”æ¡ˆ&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ä¾‹å¦‚ï¼Œ&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;s&amp;gt;Human: ç”¨ä¸€å¥è¯æè¿°åœ°çƒä¸ºä»€ä¹ˆæ˜¯ç‹¬ä¸€æ— äºŒçš„ã€‚&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: å› ä¸ºåœ°çƒæ˜¯ç›®å‰ä¸ºæ­¢å”¯ä¸€å·²çŸ¥å­˜åœ¨ç”Ÿå‘½çš„è¡Œæ˜Ÿã€‚&amp;lt;/s&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step3: å¾®è°ƒè„šæœ¬&lt;/h3&gt; &#xA;&lt;h4&gt;LoRAå¾®è°ƒ&lt;/h4&gt; &#xA;&lt;p&gt;LoRAå¾®è°ƒè„šæœ¬è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/sft/finetune_lora.sh&#34;&gt;train/sft/finetune_lora.sh&lt;/a&gt;ï¼Œå…³äºLoRAå¾®è°ƒçš„å…·ä½“å®ç°ä»£ç è§&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/sft/finetune_clm_lora.py&#34;&gt;train/sft/finetune_clm_lora.py&lt;/a&gt;ï¼Œå•æœºå¤šå¡çš„å¾®è°ƒå¯ä»¥é€šè¿‡ä¿®æ”¹è„šæœ¬ä¸­çš„&lt;code&gt;--include localhost:0&lt;/code&gt;æ¥å®ç°ã€‚&lt;/p&gt; &#xA;&lt;h4&gt;å…¨é‡å‚æ•°å¾®è°ƒ&lt;/h4&gt; &#xA;&lt;p&gt;å…¨é‡å‚æ•°å¾®è°ƒè„šæœ¬è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/sft/finetune.sh&#34;&gt;train/sft/finetune.sh&lt;/a&gt;ï¼Œå…³äºå…¨é‡å‚æ•°å¾®è°ƒçš„å…·ä½“å®ç°ä»£ç è§&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/sft/finetune_clm.py&#34;&gt;train/sft/finetune_clm.py&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Step4: åŠ è½½å¾®è°ƒæ¨¡å‹&lt;/h3&gt; &#xA;&lt;h4&gt;LoRAå¾®è°ƒ&lt;/h4&gt; &#xA;&lt;p&gt;åŸºäºLoRAå¾®è°ƒçš„æ¨¡å‹å‚æ•°è§ï¼š&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%9F%BA%E4%BA%8Ellama2%E7%9A%84%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B&#34;&gt;åŸºäºLlama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹&lt;/a&gt;ï¼ŒLoRAå‚æ•°éœ€è¦å’ŒåŸºç¡€æ¨¡å‹å‚æ•°ç»“åˆä½¿ç”¨ã€‚&lt;/p&gt; &#xA;&lt;p&gt;é€šè¿‡&lt;a href=&#34;https://github.com/huggingface/peft&#34;&gt;PEFT&lt;/a&gt;åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å‚æ•°å’Œå¾®è°ƒæ¨¡å‹å‚æ•°ï¼Œä»¥ä¸‹ç¤ºä¾‹ä»£ç ä¸­ï¼Œbase_model_name_or_pathä¸ºé¢„è®­ç»ƒæ¨¡å‹å‚æ•°ä¿å­˜è·¯å¾„ï¼Œfinetune_model_pathä¸ºå¾®è°ƒæ¨¡å‹å‚æ•°ä¿å­˜è·¯å¾„ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;from peft import PeftModel,PeftConfig&#xA;# ä¾‹å¦‚: finetune_model_path=&#39;FlagAlpha/Llama2-Chinese-7b-Chat-LoRA&#39;&#xA;finetune_model_path=&#39;&#39;  &#xA;config = PeftConfig.from_pretrained(finetune_model_path)&#xA;# ä¾‹å¦‚: base_model_name_or_path=&#39;meta-llama/Llama-2-7b-chat&#39;&#xA;tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path,use_fast=False)&#xA;tokenizer.pad_token = tokenizer.eos_token&#xA;device_map = &#34;cuda:0&#34; if torch.cuda.is_available() else &#34;auto&#34;&#xA;model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,device_map=device_map,torch_dtype=torch.float16,load_in_8bit=True,trust_remote_code=True,use_flash_attention_2=True)&#xA;model = PeftModel.from_pretrained(model, finetune_model_path, device_map={&#34;&#34;: 0})&#xA;model =model.eval()&#xA;input_ids = tokenizer([&#39;&amp;lt;s&amp;gt;Human: ä»‹ç»ä¸€ä¸‹åŒ—äº¬\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#39;], return_tensors=&#34;pt&#34;,add_special_tokens=False).input_ids&#xA;if torch.cuda.is_available():&#xA;  input_ids = input_ids.to(&#39;cuda&#39;)&#xA;generate_input = {&#xA;    &#34;input_ids&#34;:input_ids,&#xA;    &#34;max_new_tokens&#34;:512,&#xA;    &#34;do_sample&#34;:True,&#xA;    &#34;top_k&#34;:50,&#xA;    &#34;top_p&#34;:0.95,&#xA;    &#34;temperature&#34;:0.3,&#xA;    &#34;repetition_penalty&#34;:1.3,&#xA;    &#34;eos_token_id&#34;:tokenizer.eos_token_id,&#xA;    &#34;bos_token_id&#34;:tokenizer.bos_token_id,&#xA;    &#34;pad_token_id&#34;:tokenizer.pad_token_id&#xA;}&#xA;generate_ids  = model.generate(**generate_input)&#xA;text = tokenizer.decode(generate_ids[0])&#xA;print(text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;å…¨é‡å‚æ•°å¾®è°ƒ&lt;/h4&gt; &#xA;&lt;p&gt;å¯¹äºå…¨é‡å‚æ•°å¾®è°ƒçš„æ¨¡å‹ï¼Œè°ƒç”¨æ–¹å¼åŒ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%94%A8%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B&#34;&gt;æ¨¡å‹è°ƒç”¨ä»£ç ç¤ºä¾‹&lt;/a&gt;ï¼Œåªéœ€è¦ä¿®æ”¹å…¶ä¸­çš„æ¨¡å‹åç§°æˆ–è€…ä¿å­˜è·¯å¾„å³å¯ã€‚&lt;/p&gt; &#xA;&lt;!-- ## ğŸš€ æœªæ¥è®¡åˆ’ --&gt; &#xA;&lt;h2&gt;ğŸ„ æ¨¡å‹é‡åŒ–&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘ä»¬å¯¹ä¸­æ–‡å¾®è°ƒçš„æ¨¡å‹å‚æ•°è¿›è¡Œäº†é‡åŒ–ï¼Œæ–¹ä¾¿ä»¥æ›´å°‘çš„è®¡ç®—èµ„æºè¿è¡Œã€‚ç›®å‰å·²ç»åœ¨&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;Hugging Face&lt;/a&gt;ä¸Šä¼ äº†13Bä¸­æ–‡å¾®è°ƒæ¨¡å‹&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat&#34;&gt;FlagAlpha/Llama2-Chinese-13b-Chat&lt;/a&gt;çš„4bitå‹ç¼©ç‰ˆæœ¬&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#34;&gt;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&lt;/a&gt;ï¼Œå…·ä½“è°ƒç”¨æ–¹å¼å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;p&gt;ç¯å¢ƒå‡†å¤‡ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install git+https://github.com/PanQiWei/AutoGPTQ.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoTokenizer&#xA;from auto_gptq import AutoGPTQForCausalLM&#xA;model = AutoGPTQForCausalLM.from_quantized(&#39;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#39;, device=&#34;cuda:0&#34;)&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#39;,use_fast=False)&#xA;input_ids = tokenizer([&#39;&amp;lt;s&amp;gt;Human: æ€ä¹ˆç™»ä¸Šç«æ˜Ÿ\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#39;], return_tensors=&#34;pt&#34;,add_special_tokens=False).input_ids.to(&#39;cuda&#39;)        &#xA;generate_input = {&#xA;    &#34;input_ids&#34;:input_ids,&#xA;    &#34;max_new_tokens&#34;:512,&#xA;    &#34;do_sample&#34;:True,&#xA;    &#34;top_k&#34;:50,&#xA;    &#34;top_p&#34;:0.95,&#xA;    &#34;temperature&#34;:0.3,&#xA;    &#34;repetition_penalty&#34;:1.3,&#xA;    &#34;eos_token_id&#34;:tokenizer.eos_token_id,&#xA;    &#34;bos_token_id&#34;:tokenizer.bos_token_id,&#xA;    &#34;pad_token_id&#34;:tokenizer.pad_token_id&#xA;}&#xA;generate_ids  = model.generate(**generate_input)&#xA;text = tokenizer.decode(generate_ids[0])&#xA;print(text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ğŸš€ æ¨ç†åŠ é€Ÿ&lt;/h2&gt; &#xA;&lt;p&gt;éšç€å¤§æ¨¡å‹å‚æ•°è§„æ¨¡çš„ä¸æ–­å¢é•¿ï¼Œåœ¨æœ‰é™çš„ç®—åŠ›èµ„æºä¸‹ï¼Œæå‡æ¨¡å‹çš„æ¨ç†é€Ÿåº¦é€æ¸å˜ä¸ºä¸€ä¸ªé‡è¦çš„ç ”ç©¶æ–¹å‘ã€‚å¸¸ç”¨çš„æ¨ç†åŠ é€Ÿæ¡†æ¶åŒ…å« lmdeployã€FasterTransformerã€vLLMå’ŒJittorLLMs ç­‰ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;TensorRT-LLM&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/NVIDIA/TensorRT-LLM/tree/main&#34;&gt;TensorRT-LLM&lt;/a&gt;ç”±NVIDIAå¼€å‘ï¼Œé«˜æ€§èƒ½æ¨ç†æ¡†æ¶&lt;/p&gt; &#xA;&lt;p&gt;è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/tree/main/inference-speed/GPU/TensorRT-LLM_example&#34;&gt;inference-speed/GPU/TensorRT-LLM_example&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;vLLM&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/vllm-project/vllm&#34;&gt;vLLM&lt;/a&gt;ç”±åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡å¼€å‘ï¼Œæ ¸å¿ƒæŠ€æœ¯æ˜¯PageAttentionï¼Œååé‡æ¯”HuggingFace Transformersé«˜å‡º24å€ã€‚ç›¸è¾ƒä¸FasterTrainsformerï¼ŒvLLMæ›´åŠ çš„ç®€å•æ˜“ç”¨ï¼Œä¸éœ€è¦é¢å¤–è¿›è¡Œæ¨¡å‹çš„è½¬æ¢ï¼Œæ”¯æŒfp16æ¨ç†ã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/inference-speed/GPU/vllm_example/README.md&#34;&gt;inference-speed/GPU/vllm_example&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;JittorLLMs&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Jittor/JittorLLMs&#34;&gt;JittorLLMs&lt;/a&gt;ç”±éåç§‘æŠ€é¢†è¡”ï¼Œä¸æ¸…åå¤§å­¦å¯è§†åª’ä½“ç ”ç©¶ä¸­å¿ƒåˆä½œç ”å‘ï¼Œé€šè¿‡åŠ¨æ€swapæœºåˆ¶å¤§å¹…é™ä½ç¡¬ä»¶é…ç½®è¦æ±‚ï¼ˆå‡å°‘80%ï¼‰,å¹¶ä¸”Jittoræ¡†æ¶é€šè¿‡é›¶æ‹·è´æŠ€æœ¯ï¼Œå¤§æ¨¡å‹åŠ è½½ç›¸æ¯”Pytorchå¼€é”€é™ä½40%ï¼ŒåŒæ—¶ï¼Œé€šè¿‡å…ƒç®—å­è‡ªåŠ¨ç¼–è¯‘ä¼˜åŒ–ï¼Œè®¡ç®—æ€§èƒ½æå‡20%ä»¥ä¸Šã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/inference-speed/GPU/JittorLLMs_example/README.md&#34;&gt;inference-speed/GPU/JittorLLMs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;lmdeploy&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/InternLM/lmdeploy/&#34;&gt;lmdeploy&lt;/a&gt; ç”±ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤å¼€å‘ï¼Œæ¨ç†ä½¿ç”¨ C++/CUDAï¼Œå¯¹å¤–æä¾› python/gRPC/http æ¥å£å’Œ WebUI ç•Œé¢ï¼Œæ”¯æŒ tensor parallel åˆ†å¸ƒå¼æ¨ç†ã€æ”¯æŒ fp16/weight int4/kv cache int8 é‡åŒ–ã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¯¦ç»†çš„æ¨ç†æ–‡æ¡£è§ï¼š&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/tree/main/inference-speed/GPU/lmdeploy_example&#34;&gt;inference-speed/GPU/lmdeploy_example&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ¥‡ æ¨¡å‹è¯„æµ‹&lt;/h2&gt; &#xA;&lt;p&gt;ä¸ºäº†èƒ½å¤Ÿæ›´åŠ æ¸…æ™°åœ°äº†è§£Llama2æ¨¡å‹çš„ä¸­æ–‡é—®ç­”èƒ½åŠ›ï¼Œæˆ‘ä»¬ç­›é€‰äº†ä¸€äº›å…·æœ‰ä»£è¡¨æ€§çš„ä¸­æ–‡é—®é¢˜ï¼Œå¯¹Llama2æ¨¡å‹è¿›è¡Œæé—®ã€‚æˆ‘ä»¬æµ‹è¯•çš„æ¨¡å‹åŒ…å«Metaå…¬å¼€çš„Llama2-7B-Chatå’ŒLlama2-13B-Chatä¸¤ä¸ªç‰ˆæœ¬ï¼Œæ²¡æœ‰åšä»»ä½•å¾®è°ƒå’Œè®­ç»ƒã€‚æµ‹è¯•é—®é¢˜ç­›é€‰è‡ª&lt;a href=&#34;https://github.com/AtomEcho/AtomBulb&#34;&gt;AtomBulb&lt;/a&gt;ï¼Œå…±95ä¸ªæµ‹è¯•é—®é¢˜ï¼ŒåŒ…å«ï¼šé€šç”¨çŸ¥è¯†ã€è¯­è¨€ç†è§£ã€åˆ›ä½œèƒ½åŠ›ã€é€»è¾‘æ¨ç†ã€ä»£ç ç¼–ç¨‹ã€å·¥ä½œæŠ€èƒ½ã€ä½¿ç”¨å·¥å…·ã€äººæ ¼ç‰¹å¾å…«ä¸ªå¤§çš„ç±»åˆ«ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æµ‹è¯•ä¸­ä½¿ç”¨çš„Promptå¦‚ä¸‹ï¼Œä¾‹å¦‚å¯¹äºé—®é¢˜â€œåˆ—å‡º5ç§å¯ä»¥æ”¹å–„ç¡çœ è´¨é‡çš„æ–¹æ³•â€ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[INST] &#xA;&amp;lt;&amp;lt;SYS&amp;gt;&amp;gt;&#xA;You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. The answer always been translate into Chinese language.&#xA;&#xA;If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don&#39;t know the answer to a question, please don&#39;t share false information.&#xA;&#xA;The answer always been translate into Chinese language.&#xA;&amp;lt;&amp;lt;/SYS&amp;gt;&amp;gt;&#xA;&#xA;åˆ—å‡º5ç§å¯ä»¥æ”¹å–„ç¡çœ è´¨é‡çš„æ–¹æ³•&#xA;[/INST]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Llama2-7B-Chatçš„æµ‹è¯•ç»“æœè§&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/meta_eval_7B.md&#34;&gt;meta_eval_7B.md&lt;/a&gt;ï¼ŒLlama2-13B-Chatçš„æµ‹è¯•ç»“æœè§&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/meta_eval_13B.md&#34;&gt;meta_eval_13B.md&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;é€šè¿‡æµ‹è¯•æˆ‘ä»¬å‘ç°ï¼ŒMetaåŸå§‹çš„Llama2 Chatæ¨¡å‹å¯¹äºä¸­æ–‡é—®ç­”çš„å¯¹é½æ•ˆæœä¸€èˆ¬ï¼Œå¤§éƒ¨åˆ†æƒ…å†µä¸‹éƒ½ä¸èƒ½ç»™å‡ºä¸­æ–‡å›ç­”ï¼Œæˆ–è€…æ˜¯ä¸­è‹±æ–‡æ··æ‚çš„å½¢å¼ã€‚å› æ­¤ï¼ŒåŸºäºä¸­æ–‡æ•°æ®å¯¹Llama2æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œå¾®è°ƒååˆ†å¿…è¦ï¼Œæˆ‘ä»¬çš„ä¸­æ–‡ç‰ˆLlama2æ¨¡å‹ä¹Ÿå·²ç»åœ¨è®­ç»ƒä¸­ï¼Œè¿‘æœŸå°†å¯¹ç¤¾åŒºå¼€æ”¾ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ’ª å¤–å»¶èƒ½åŠ›&lt;/h2&gt; &#xA;&lt;p&gt;é™¤äº†æŒç»­å¢å¼ºå¤§æ¨¡å‹å†…åœ¨çš„çŸ¥è¯†å‚¨å¤‡ã€é€šç”¨ç†è§£ã€é€»è¾‘æ¨ç†å’Œæƒ³è±¡èƒ½åŠ›ç­‰ï¼Œæœªæ¥ï¼Œæˆ‘ä»¬ä¹Ÿä¼šä¸æ–­ä¸°å¯Œå¤§æ¨¡å‹çš„å¤–å»¶èƒ½åŠ›ï¼Œä¾‹å¦‚çŸ¥è¯†åº“æ£€ç´¢ã€è®¡ç®—å·¥å…·ã€WolframAlphaã€æ“ä½œè½¯ä»¶ç­‰ã€‚ æˆ‘ä»¬é¦–å…ˆé›†æˆäº†LangChainæ¡†æ¶ï¼Œå¯ä»¥æ›´æ–¹ä¾¿åœ°åŸºäºLlama2å¼€å‘æ–‡æ¡£æ£€ç´¢ã€é—®ç­”æœºå™¨äººå’Œæ™ºèƒ½ä½“åº”ç”¨ç­‰ï¼Œå…³äºLangChainçš„æ›´å¤šä»‹ç»å‚è§&lt;a href=&#34;https://github.com/langchain-ai/langchain&#34;&gt;LangChain&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;LangChain&lt;/h3&gt; &#xA;&lt;p&gt;é’ˆå¯¹LangChainæ¡†æ¶å°è£…çš„Llama2 LLMç±»è§&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/examples/llama2_for_langchain.py&#34;&gt;examples/llama2_for_langchain.py&lt;/a&gt;ï¼Œç®€å•çš„è°ƒç”¨ä»£ç ç¤ºä¾‹å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from llama2_for_langchain import Llama2&#xA;&#xA;# è¿™é‡Œä»¥è°ƒç”¨FlagAlpha/Atom-7B-Chatä¸ºä¾‹&#xA;llm = Llama2(model_name_or_path=&#39;FlagAlpha/Atom-7B-Chat&#39;)&#xA;&#xA;while True:&#xA;    human_input = input(&#34;Human: &#34;)&#xA;    response = llm(human_input)&#xA;    print(f&#34;Llama2: {response}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ğŸ ä»£ç æ¨¡å‹&lt;/h2&gt; &#xA;&lt;p&gt;Metaå®˜æ–¹åœ¨2023å¹´8æœˆ24æ—¥å‘å¸ƒäº†Code Llamaï¼ŒåŸºäºä»£ç æ•°æ®å¯¹Llama2è¿›è¡Œäº†å¾®è°ƒï¼Œæä¾›ä¸‰ä¸ªä¸åŒåŠŸèƒ½çš„ç‰ˆæœ¬ï¼šåŸºç¡€æ¨¡å‹ï¼ˆCode Llamaï¼‰ã€Pythonä¸“ç”¨æ¨¡å‹ï¼ˆCode Llama - Pythonï¼‰å’ŒæŒ‡ä»¤è·Ÿéšæ¨¡å‹ï¼ˆCode Llama - Instructï¼‰ï¼ŒåŒ…å«7Bã€13Bã€34Bä¸‰ç§ä¸åŒå‚æ•°è§„æ¨¡ã€‚ä¸åŒæ¨¡å‹èƒ½åŠ›åŒºåˆ«å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;æ¨¡å‹ç±»åˆ«&lt;/th&gt; &#xA;   &lt;th&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ä»£ç ç»­å†™&lt;/th&gt; &#xA;   &lt;th&gt;ä»£ç å¡«å……&lt;/th&gt; &#xA;   &lt;th&gt;æŒ‡ä»¤ç¼–ç¨‹&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Code Llama&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-7b&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;âŒ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-13b&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;âŒ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-34b&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;âŒ&lt;/td&gt; &#xA;   &lt;td&gt;âŒ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Code Llama - Python&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-7b-Python&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;âŒ&lt;/td&gt; &#xA;   &lt;td&gt;âŒ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-13b-Python&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;âŒ&lt;/td&gt; &#xA;   &lt;td&gt;âŒ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-34b-Python&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;âŒ&lt;/td&gt; &#xA;   &lt;td&gt;âŒ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Code Llama - Instruct&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-7b-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;âŒ&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-13b-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;âŒ&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-34b-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;âŒ&lt;/td&gt; &#xA;   &lt;td&gt;âŒ&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;æˆ‘ä»¬æä¾›äº†Code Llamaçš„&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E5%9B%BD%E5%86%85Llama2%E6%9C%80%E6%96%B0%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80&#34;&gt;å›½å†…ä¸‹è½½é“¾æ¥&lt;/a&gt;ä»¥åŠåœ¨çº¿ä½“éªŒåœ°å€&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;ï¼Œå…³äºCode Llamaçš„è¯¦ç»†ä¿¡æ¯å¯ä»¥å‚è€ƒå®˜æ–¹Githubä»“åº“&lt;a href=&#34;https://github.com/facebookresearch/codellama&#34;&gt;codellama&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“– å­¦ä¹ èµ„æ–™&lt;/h2&gt; &#xA;&lt;h3&gt;Metaå®˜æ–¹å¯¹äº&lt;a href=&#34;https://ai.meta.com/llama&#34;&gt;Llama2&lt;/a&gt;çš„ä»‹ç»&lt;/h3&gt; &#xA;&lt;p&gt;è‡ªä»Metaå…¬å¸å‘å¸ƒç¬¬ä¸€ä»£LLaMAæ¨¡å‹ä»¥æ¥ï¼Œç¾Šé©¼æ¨¡å‹å®¶æ—ç¹è£å‘å±•ã€‚è¿‘æœŸMetaå‘å¸ƒäº†Llama2ç‰ˆæœ¬ï¼Œå¼€æºå¯å•†ç”¨ï¼Œåœ¨æ¨¡å‹å’Œæ•ˆæœä¸Šæœ‰äº†é‡å¤§æ›´æ–°ã€‚Llama2æ€»å…±å…¬å¸ƒäº†7Bã€13Bå’Œ70Bä¸‰ç§å‚æ•°å¤§å°çš„æ¨¡å‹ã€‚ç›¸æ¯”äºLLaMAï¼ŒLlama2çš„è®­ç»ƒæ•°æ®è¾¾åˆ°äº†2ä¸‡äº¿tokenï¼Œä¸Šä¸‹æ–‡é•¿åº¦ä¹Ÿç”±ä¹‹å‰çš„2048å‡çº§åˆ°4096ï¼Œå¯ä»¥ç†è§£å’Œç”Ÿæˆæ›´é•¿çš„æ–‡æœ¬ã€‚Llama2 Chatæ¨¡å‹åŸºäº100ä¸‡äººç±»æ ‡è®°æ•°æ®å¾®è°ƒå¾—åˆ°ï¼Œåœ¨è‹±æ–‡å¯¹è¯ä¸Šè¾¾åˆ°äº†æ¥è¿‘ChatGPTçš„æ•ˆæœã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Llamaç›¸å…³è®ºæ–‡&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.13971&#34;&gt;LLaMA: Open and Efficient Foundation Language Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2307.09288&#34;&gt;Llama 2: Open Foundation and Fine-Tuned Chat Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/&#34;&gt;Code Llama: Open Foundation Models for Code&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Llama2çš„è¯„æµ‹ç»“æœ&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/llama_eval.jpeg&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;ğŸ‰ è‡´è°¢&lt;/h2&gt; &#xA;&lt;p&gt;æ„Ÿè°¢åŸå­å›å£°&lt;a href=&#34;https://github.com/AtomEcho&#34;&gt;AtomEcho&lt;/a&gt;å›¢é˜Ÿçš„æŠ€æœ¯å’Œèµ„æºæ”¯æŒï¼&lt;/p&gt; &#xA;&lt;p&gt;æ„Ÿè°¢èŠ¯æ ¼&lt;a href=&#34;https://coremesh.net&#34;&gt;Coremesh&lt;/a&gt;å›¢é˜Ÿçš„æŠ€æœ¯å’Œèµ„æºæ”¯æŒï¼&lt;/p&gt; &#xA;&lt;p&gt;æ„Ÿè°¢ @xzsGenius å¯¹Llama2ä¸­æ–‡ç¤¾åŒºçš„è´¡çŒ®ï¼&lt;/p&gt; &#xA;&lt;p&gt;æ„Ÿè°¢ @Z Potentialsç¤¾åŒºå¯¹Llama2ä¸­æ–‡ç¤¾åŒºçš„æ”¯æŒï¼&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ¤” é—®é¢˜åé¦ˆ&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœ‰é—®é¢˜ï¼Œè¯·åœ¨GitHub Issueä¸­æäº¤ï¼Œåœ¨æäº¤é—®é¢˜ä¹‹å‰ï¼Œè¯·å…ˆæŸ¥é˜…ä»¥å¾€çš„issueæ˜¯å¦èƒ½è§£å†³ä½ çš„é—®é¢˜ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ç¤¼è²Œåœ°æå‡ºé—®é¢˜ï¼Œæ„å»ºå’Œè°çš„è®¨è®ºç¤¾åŒºã€‚&lt;/p&gt; &#xA;&lt;p&gt;åŠ å…¥&lt;a href=&#34;https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink&#34;&gt;é£ä¹¦çŸ¥è¯†åº“&lt;/a&gt;ï¼Œä¸€èµ·å…±å»ºç¤¾åŒºæ–‡æ¡£ã€‚&lt;/p&gt; &#xA;&lt;p&gt;åŠ å…¥å¾®ä¿¡ç¾¤è®¨è®ºğŸ˜ğŸ˜&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/wechat.jpeg&#34; alt=&#34;Wechat&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://api.star-history.com/svg?repos=LlamaFamily/Llama-Chinese&amp;amp;type=Date&#34; alt=&#34;Wechat&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt;</summary>
  </entry>
</feed>