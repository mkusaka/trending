<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-09-19T01:37:14Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>opengeos/leafmap</title>
    <updated>2023-09-19T01:37:14Z</updated>
    <id>tag:github.com,2023-09-19:/opengeos/leafmap</id>
    <link href="https://github.com/opengeos/leafmap" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Python package for interactive mapping and geospatial analysis with minimal coding in a Jupyter environment&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Welcome to leafmap&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://demo.leafmap.org&#34;&gt;&lt;img src=&#34;https://jupyterlite.rtfd.io/en/latest/_static/badge.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://studiolab.sagemaker.aws/import/github/opengeos/leafmap/blob/master/examples/notebooks/00_key_features.ipynb&#34;&gt;&lt;img src=&#34;https://studiolab.sagemaker.aws/studiolab.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pccompute.westeurope.cloudapp.azure.com/compute/hub/user-redirect/git-pull?repo=https://github.com/opengeos/leafmap&amp;amp;urlpath=lab/tree/leafmap/examples/notebooks/00_key_features.ipynb&amp;amp;branch=master&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Open-Planetary%20Computer-black?style=flat&amp;amp;logo=microsoft&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gishub.org/leafmap-colab&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gishub.org/leafmap-binder&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/leafmap&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/leafmap.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://anaconda.org/conda-forge/leafmap&#34;&gt;&lt;img src=&#34;https://img.shields.io/conda/vn/conda-forge/leafmap.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/projects/leafmap&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/badge/leafmap&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://leafmap.org&#34;&gt;&lt;img src=&#34;https://github.com/opengeos/leafmap/workflows/docs/badge.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/opengeos/leafmap/actions&#34;&gt;&lt;img src=&#34;https://github.com/opengeos/leafmap/workflows/Linux%20build/badge.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://youtube.com/@giswqs&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/YouTube-Channel-red&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.21105/joss.03414&#34;&gt;&lt;img src=&#34;https://joss.theoj.org/papers/10.21105/joss.03414/status.svg?sanitize=true&#34; alt=&#34;status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/opengeos/leafmap/raw/master/docs/assets/logo.png&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/opengeos/leafmap/master/docs/assets/logo_rect.png&#34; alt=&#34;logo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Python package for geospatial analysis and interactive mapping in a Jupyter environment.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GitHub repo: &lt;a href=&#34;https://github.com/opengeos/leafmap&#34;&gt;https://github.com/opengeos/leafmap&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Documentation: &lt;a href=&#34;https://leafmap.org&#34;&gt;https://leafmap.org&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;PyPI: &lt;a href=&#34;https://pypi.org/project/leafmap&#34;&gt;https://pypi.org/project/leafmap&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Conda-forge: &lt;a href=&#34;https://anaconda.org/conda-forge/leafmap&#34;&gt;https://anaconda.org/conda-forge/leafmap&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Leafmap tutorials on YouTube: &lt;a href=&#34;https://youtube.com/@giswqs&#34;&gt;https://youtube.com/@giswqs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Free software: &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;MIT license&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Leafmap&lt;/strong&gt; is a Python package for interactive mapping and geospatial analysis with minimal coding in a Jupyter environment. It is a spin-off project of the &lt;a href=&#34;https://geemap.org&#34;&gt;geemap&lt;/a&gt; Python package, which was designed specifically to work with &lt;a href=&#34;https://earthengine.google.com&#34;&gt;Google Earth Engine&lt;/a&gt; (GEE). However, not everyone in the geospatial community has access to the GEE cloud computing platform. Leafmap is designed to fill this gap for non-GEE users. It is a free and open-source Python package that enables users to analyze and visualize geospatial data with minimal coding in a Jupyter environment, such as Google Colab, Jupyter Notebook, and JupyterLab. Leafmap is built upon several open-source packages, such as &lt;a href=&#34;https://github.com/python-visualization/folium&#34;&gt;folium&lt;/a&gt; and &lt;a href=&#34;https://github.com/jupyter-widgets/ipyleaflet&#34;&gt;ipyleaflet&lt;/a&gt; (for creating interactive maps), &lt;a href=&#34;https://github.com/jblindsay/whitebox-tools&#34;&gt;WhiteboxTools&lt;/a&gt; and &lt;a href=&#34;https://github.com/opengeos/whiteboxgui&#34;&gt;whiteboxgui&lt;/a&gt; (for analyzing geospatial data), and &lt;a href=&#34;https://github.com/jupyter-widgets/ipywidgets&#34;&gt;ipywidgets&lt;/a&gt; (for designing interactive graphical user interface [GUI]). Leafmap has a toolset with various interactive tools that allow users to load vector and raster data onto the map without coding. In addition, users can use the powerful analytical backend (i.e., WhiteboxTools) to perform geospatial analysis directly within the leafmap user interface without writing a single line of code. The WhiteboxTools library currently contains &lt;strong&gt;500+&lt;/strong&gt; tools for advanced geospatial analysis, such as &lt;a href=&#34;https://jblindsay.github.io/wbt_book/available_tools/gis_analysis.html&#34;&gt;GIS Analysis&lt;/a&gt;, &lt;a href=&#34;https://jblindsay.github.io/wbt_book/available_tools/geomorphometric_analysis.html&#34;&gt;Geomorphometric Analysis&lt;/a&gt;, &lt;a href=&#34;https://jblindsay.github.io/wbt_book/available_tools/hydrological_analysis.html&#34;&gt;Hydrological Analysis&lt;/a&gt;, &lt;a href=&#34;https://jblindsay.github.io/wbt_book/available_tools/lidar_tools.html&#34;&gt;LiDAR Data Analysis&lt;/a&gt;, &lt;a href=&#34;https://jblindsay.github.io/wbt_book/available_tools/mathand_stats_tools.html&#34;&gt;Mathematical and Statistical Analysis&lt;/a&gt;, and &lt;a href=&#34;https://jblindsay.github.io/wbt_book/available_tools/stream_network_analysis.html&#34;&gt;Stream Network Analysis&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;p&gt;This project is supported by Amazon Web Services (&lt;a href=&#34;https://aws.amazon.com&#34;&gt;AWS&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h2&gt;Statement of Need&lt;/h2&gt; &#xA;&lt;p&gt;There is a plethora of Python packages for geospatial analysis, such as &lt;a href=&#34;https://geopandas.org&#34;&gt;geopandas&lt;/a&gt; for vector data analysis and &lt;a href=&#34;https://docs.xarray.dev&#34;&gt;xarray&lt;/a&gt; for raster data analysis. As listed at &lt;a href=&#34;https://pyviz.org&#34;&gt;pyviz.org&lt;/a&gt;, there are also many options for plotting data on a map in Python, ranging from libraries focused specifically on maps like &lt;a href=&#34;https://ipyleaflet.readthedocs.io&#34;&gt;ipyleaflet&lt;/a&gt; and &lt;a href=&#34;https://python-visualization.github.io/folium&#34;&gt;folium&lt;/a&gt; to general-purpose plotting tools that also support geospatial data types, such as &lt;a href=&#34;https://hvplot.pyviz.org&#34;&gt;hvPlot&lt;/a&gt;, &lt;a href=&#34;http://bokeh.org&#34;&gt;bokeh&lt;/a&gt;, and &lt;a href=&#34;https://plotly.com/python&#34;&gt;plotly&lt;/a&gt;. While these tools provide powerful capabilities, displaying geospatial data from different file formats on an interactive map and performing basic analyses can be challenging, especially for users with limited coding skills. Furthermore, many tools lack bi-directional communication between the frontend (browser) and the backend (Python), limiting their interactivity and usability for exploring map data.&lt;/p&gt; &#xA;&lt;p&gt;Leafmap addresses these challenges by leveraging the bidirectional communication provided by ipyleaflet, enabling users to load and visualize geospatial datasets with just one line of code. Leafmap also provides an interactive graphical user interface (GUI) for loading geospatial datasets without any coding. It is designed for anyone who wants to analyze and visualize geospatial data interactively in a Jupyter environment, making it particularly accessible for novice users with limited programming skills. Advanced programmers can also benefit from leafmap for geospatial data analysis and building interactive web applications.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Launch the interactive notebook tutorial for the &lt;strong&gt;leafmap&lt;/strong&gt; Python package with JupyterLite, Google Colab, Binder, or Amazon Sagemaker Studio Lab now:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://demo.leafmap.org&#34;&gt;&lt;img src=&#34;https://jupyterlite.rtfd.io/en/latest/_static/badge.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gishub.org/leafmap-colab&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gishub.org/leafmap-binder&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://studiolab.sagemaker.aws/import/github/opengeos/leafmap/blob/master/examples/notebooks/00_key_features.ipynb&#34;&gt;&lt;img src=&#34;https://studiolab.sagemaker.aws/studiolab.svg?sanitize=true&#34; alt=&#34;Open In Studio Lab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Check out this excellent article on Medium - &lt;a href=&#34;https://link.medium.com/HRRKDcynYgb&#34;&gt;Leafmap a new Python Package for Geospatial data science&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;To learn more about leafmap, check out the leafmap documentation website - &lt;a href=&#34;https://leafmap.org&#34;&gt;https://leafmap.org&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/abd8pTH.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Key Features&lt;/h2&gt; &#xA;&lt;p&gt;Leafmap offers a wide range of features and capabilities that empower geospatial data scientists, researchers, and developers to unlock the potential of their data. Some of the key features include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Creating an interactive map with just one line of code:&lt;/strong&gt; Leafmap makes it easy to create an interactive map by providing a simple API that allows you to load and visualize geospatial datasets with minimal coding.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Switching between different mapping backends:&lt;/strong&gt; Leafmap supports multiple mapping backends, including ipyleaflet, folium, kepler.gl, pydeck, and bokeh. You can switch between these backends to create maps with different visualization styles and capabilities.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Changing basemaps interactively:&lt;/strong&gt; Leafmap allows you to change basemaps interactively, providing a variety of options such as OpenStreetMap, Stamen Terrain, CartoDB Positron, and many more.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Adding XYZ, WMS, and vector tile services:&lt;/strong&gt; You can easily add XYZ, WMS, and vector tile services to your map, allowing you to overlay additional geospatial data from various sources.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Displaying vector data:&lt;/strong&gt; Leafmap supports various vector data formats, including Shapefile, GeoJSON, GeoPackage, and any vector format supported by GeoPandas. You can load and display vector data on the map, enabling you to visualize and analyze spatial features.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Displaying raster data:&lt;/strong&gt; Leafmap allows you to load and display raster data, such as GeoTIFFs, on the map. This feature is useful for visualizing satellite imagery, digital elevation models, and other gridded datasets.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Creating custom legends and colorbars:&lt;/strong&gt; Leafmap provides tools for customizing legends and colorbars on the map, allowing you to represent data values with different colors and corresponding labels.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Creating split-panel maps and linked maps:&lt;/strong&gt; With Leafmap, you can create split-panel maps to compare different datasets side by side. You can also create linked maps that synchronize interactions between multiple maps, providing a coordinated view of different spatial data.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Downloading and visualizing OpenStreetMap data:&lt;/strong&gt; Leafmap allows you to download and visualize OpenStreetMap data, providing access to detailed street maps, buildings, and other points of interest.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Creating and editing vector data interactively:&lt;/strong&gt; Leafmap includes tools for creating and editing vector data interactively on the map. You can draw points, lines, and polygons, and modify them as needed.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Searching for geospatial data:&lt;/strong&gt; Leafmap provides functionality for searching and accessing geospatial data from sources such as SpatialTemporal Asset Catalogs (STAC), Microsoft Planetary Computer, AWS Open Data Registry, and OpenAerialMap.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Inspecting pixel values interactively:&lt;/strong&gt; Leafmap allows you to interactively inspect pixel values in raster datasets, helping you analyze and understand the data at a more granular level.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Creating choropleth maps and heat maps:&lt;/strong&gt; Leafmap supports the creation of choropleth maps, where colors represent different data values for specific geographic areas. You can also create heat maps to visualize data density.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Displaying data from a PostGIS database:&lt;/strong&gt; Leafmap provides tools for connecting to a PostGIS database and displaying spatial data stored in the database on the map.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Creating time series animations:&lt;/strong&gt; Leafmap enables the creation of time series animations from both vector and raster data, allowing you to visualize temporal changes in your geospatial datasets.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Analyzing geospatial data with whitebox:&lt;/strong&gt; Leafmap integrates with WhiteboxTools and whiteboxgui, providing a suite of geospatial analyses, such as hydrological analysis, terrain analysis, and LiDAR processing.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Segmenting and classifying remote sensing imagery:&lt;/strong&gt; Leafmap integrates the segment-geospatial package, which provides tools for segmenting and classifying remote sensing imagery using deep learning algorithms.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Building interactive web apps:&lt;/strong&gt; Leafmap supports the development of interactive web applications using frameworks like Voila, Streamlit, and Solara. This allows you to share your geospatial analyses and visualizations with others in a user-friendly web interface.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;These features and capabilities make leafmap a powerful tool for geospatial data exploration, analysis, and visualization. Whether you are a beginner or an experienced geospatial data scientist, leafmap provides an accessible and efficient way to work with geospatial data in Python.&lt;/p&gt; &#xA;&lt;h2&gt;Citations&lt;/h2&gt; &#xA;&lt;p&gt;If you find &lt;strong&gt;leafmap&lt;/strong&gt; useful in your research, please consider citing the following paper to support my work. Thank you for your support.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Wu, Q. (2021). Leafmap: A Python package for interactive mapping and geospatial analysis with minimal coding in a Jupyter environment. &lt;em&gt;Journal of Open Source Software&lt;/em&gt;, 6(63), 3414. &lt;a href=&#34;https://doi.org/10.21105/joss.03414&#34;&gt;https://doi.org/10.21105/joss.03414&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://wetlands.io/file/images/leafmap_demo.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;YouTube Channel&lt;/h2&gt; &#xA;&lt;p&gt;I have created a &lt;a href=&#34;https://youtube.com/@giswqs&#34;&gt;YouTube Channel&lt;/a&gt; for sharing geospatial tutorials. You can subscribe to my channel for regular updates. If there is any specific tutorial you would like to see, please submit a feature request &lt;a href=&#34;https://github.com/opengeos/leafmap/issues&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtube.com/@giswqs&#34;&gt;&lt;img src=&#34;https://wetlands.io/file/images/youtube.png&#34; alt=&#34;Earth Engine Tutorials on YouTube&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>kbre93/every-breath-you-take</title>
    <updated>2023-09-19T01:37:14Z</updated>
    <id>tag:github.com,2023-09-19:/kbre93/every-breath-you-take</id>
    <link href="https://github.com/kbre93/every-breath-you-take" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Heart Rate Variability Training with the Polar H10 Monitor&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Every Breath You Take ‚Äì Heart Rate Variability Training with the Polar H10 Monitor&lt;/h1&gt; &#xA;&lt;p&gt;Through controlled breathing it is possible to regulate your body&#39;s stress reponse. This application allows you to measure and train this effect with a Polar H10 Heart Rate monitor.&lt;/p&gt; &#xA;&lt;p&gt;Heart rate variability, the small changes in heart rate from beat-to-beat, is a reliable measure of stress response. Heart rate variability reflects the balance between the two sides of the autonomic nervous system: the fight-or-flight response (from the sympathetic nervous system) and the rest-and-digest response (from the parasympathetic nervous system).&lt;/p&gt; &#xA;&lt;p&gt;In any moment it is possible to restore balance to the autonomic nervous system by breathing slower and deeper. With every breath you take, you can set the pace of your breathing rate, measure your breathing control with the chest accelerometer, and see how heart rate variability responds.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kbre93/every-breath-you-take/master/img/screen_record.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Connect and stream from a Polar H10, acceleration and heart rate data&lt;/li&gt; &#xA; &lt;li&gt;Live breathing control feedback and adjustable pace setting&lt;/li&gt; &#xA; &lt;li&gt;Track breathing and heart rate oscillations in real-time&lt;/li&gt; &#xA; &lt;li&gt;Explore how heart rate vairability repsonses to different breathing rates&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation and usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m venv venv&#xA;source venv/bin/activate  # On Windows, use `my_project_env\Scripts\activate`&#xA;pip install -r requirements.txt&#xA;python EBYT.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The program will automatically connect to your Polar device. For best breathing detection, ensure the Polar H10 is fitted around the widest part of the ribcage, stay seated and still while recording.&lt;/p&gt; &#xA;&lt;p&gt;Set the breathing pace with the slider (in breaths per minute), and follow the cadence as the gold circle expands and contracts. The blue circle shows your breathing control.&lt;/p&gt; &#xA;&lt;p&gt;Track each breath cycle in the top graph, and how heart rate oscillates in repsonse.&lt;/p&gt; &#xA;&lt;p&gt;Adjust breathing pace and control to target the green zone of heart rate variability in the bottom graph (&amp;gt; 150 ms).&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Feedback, bug reports, and pull requests are welcome. Feel free to submit an issue or create a pull request on GitHub.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>junruxiong/IncarnaMind</title>
    <updated>2023-09-19T01:37:14Z</updated>
    <id>tag:github.com,2023-09-19:/junruxiong/IncarnaMind</id>
    <link href="https://github.com/junruxiong/IncarnaMind" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Connect and chat with your multiple documents (pdf and txt) through GPT and Claude LLMs in a minute&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üß† IncarnaMind&lt;/h1&gt; &#xA;&lt;h2&gt;üëÄ In a Nutshell&lt;/h2&gt; &#xA;&lt;p&gt;IncarnaMind enables you to chat with your personal documents üìÅ (PDF, TXT) using Large Language Models (LLMs) like GPT (&lt;a href=&#34;https://raw.githubusercontent.com/junruxiong/IncarnaMind/main/#high-level-architecture&#34;&gt;architecture overview&lt;/a&gt;). While OpenAI has recently launched a fine-tuning API for GPT models, it doesn&#39;t enable the base pretrained models to learn new data, and the responses can be prone to factual hallucinations. Utilize our &lt;a href=&#34;https://raw.githubusercontent.com/junruxiong/IncarnaMind/main/#sliding-window-chunking&#34;&gt;Sliding Window Chunking&lt;/a&gt; mechanism and Emsemble Retriever enable efficient querying of both fine-grained and coarse-grained information within your ground truth documents to augment the LLMs.&lt;/p&gt; &#xA;&lt;p&gt;Please feel free to use it and welcome any feedback and new feature suggestions üôå.&lt;/p&gt; &#xA;&lt;p&gt;Powered by &lt;a href=&#34;https://github.com/langchain-ai/langchain&#34;&gt;Langchain&lt;/a&gt; and &lt;a href=&#34;https://github.com/chroma-core/chroma&#34;&gt;Chroma DB&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üíª Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/junruxiong/IncarnaMind/assets/44308338/89d479fb-de90-4f7c-b166-e54f7bc7344c&#34;&gt;https://github.com/junruxiong/IncarnaMind/assets/44308338/89d479fb-de90-4f7c-b166-e54f7bc7344c&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üí° Challenges Addressed&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Fixed Chunking&lt;/strong&gt;: Our Sliding Window Chunking technique provides a balanced solution in terms of time, computing power, and performance.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Precision vs. Semantics&lt;/strong&gt;: Small chunks enable fine-grained information retrieval, while large chunks focus on coarse-grained data. We leverage both embedding-based and BM25 methods for a hybrid search approach.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Single-Document Limitation&lt;/strong&gt;: IncarnaMind supports multi-document querying, breaking the one-document-at-a-time barrier.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Stability&lt;/strong&gt;: We use Chains instead of Agent to ensure stable parsing across different LLMs.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üéØ Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Adaptive Chunking&lt;/strong&gt;: Dynamically adjust the size and position of text chunks to improve retrieval augmented generation (RAG).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-Document Conversational QA&lt;/strong&gt;: Perform simmple and multi-hop queries across multiple documents simultaneously.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;File Compatibility&lt;/strong&gt;: Supports both PDF and TXT file formats.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;LLM Model Compatibility&lt;/strong&gt;: Supports both OpenAI GPT and Anthropic Claude models.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üèó Architecture&lt;/h2&gt; &#xA;&lt;h3&gt;High Level Architecture&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/junruxiong/IncarnaMind/main/figs/High_Level_Architecture.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Sliding Window Chunking&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/junruxiong/IncarnaMind/main/figs/Sliding_Window_Chunking.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;1. Installation&lt;/h3&gt; &#xA;&lt;p&gt;The installation is simple, you just need run few commands.&lt;/p&gt; &#xA;&lt;h4&gt;1.0. Prerequisites&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;3.8 ‚â§ Python &amp;lt; 3.11 with &lt;a href=&#34;https://www.anaconda.com/download&#34;&gt;Conda&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://beta.openai.com/signup&#34;&gt;OpenAI API Key&lt;/a&gt; or &lt;a href=&#34;https://console.anthropic.com/account/keys&#34;&gt;Anthropic Claude API Key&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;And of course, your own documents.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;1.1. Clone the repository&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/junruxiong/IncarnaMind&#xA;cd IncarnaMind&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;1.2. Setup&lt;/h4&gt; &#xA;&lt;p&gt;Create Conda virtual environment&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda create -n IncarnaMind python=3.10&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Activate&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda activate IncarnaMind&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install all requirements&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Setup your API keys in &lt;strong&gt;configparser.ini&lt;/strong&gt; file&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[tokens]&#xA;OPENAI_API_KEY = sk-(replace_me)&#xA;and/or&#xA;ANTHROPIC_API_KEY = sk-(replace_me)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;(Optional) Setup your custom parameters in &lt;strong&gt;configparser.ini&lt;/strong&gt; file&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[parameters]&#xA;PARAMETERS 1 = (replace_me)&#xA;PARAMETERS 2 = (replace_me)&#xA;...&#xA;PARAMETERS n = (replace_me)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Usage&lt;/h3&gt; &#xA;&lt;h4&gt;2.1. Upload and process your files&lt;/h4&gt; &#xA;&lt;p&gt;Put all your files (please name each file correctly to maximize the performance) into the &lt;strong&gt;/data&lt;/strong&gt; directory and run the following command to ingest all data: (You can delete example files in the &lt;strong&gt;/data&lt;/strong&gt; directory before running the command)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python docs2db.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2.2. Run&lt;/h4&gt; &#xA;&lt;p&gt;In order to start the conversation, run a command like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2.3. Chat and ask any questions&lt;/h4&gt; &#xA;&lt;p&gt;Wait for the script to require your input like the below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Human:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2.4. Others&lt;/h4&gt; &#xA;&lt;p&gt;When you start a chat, the system will automatically generate a &lt;strong&gt;IncarnaMind.log&lt;/strong&gt; file. If you want to edit the logging, please edit in the &lt;strong&gt;configparser.ini&lt;/strong&gt; file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[logging]&#xA;enabled = True&#xA;level = INFO&#xA;filename = IncarnaMind.log&#xA;format = %(asctime)s [%(levelname)s] %(name)s: %(message)s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üö´ Limitations&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Citation is not supported for current version, but will release soon.&lt;/li&gt; &#xA; &lt;li&gt;Limited asynchronous capabilities.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìù Upcoming Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Frontend UI interface&lt;/li&gt; &#xA; &lt;li&gt;OCR support&lt;/li&gt; &#xA; &lt;li&gt;Asynchronous optimization&lt;/li&gt; &#xA; &lt;li&gt;Support open source LLMs&lt;/li&gt; &#xA; &lt;li&gt;Support more document formats&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìë License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/junruxiong/IncarnaMind/main/LICENSE&#34;&gt;Apache 2.0 License&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üñã Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you want to cite our work, please use the following bibtex entry:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{IncarnaMind2023,&#xA;  author = {Junru Xiong},&#xA;  title = {IncarnaMind},&#xA;  year = {2023},&#xA;  publisher = {GitHub},&#xA;  journal = {GitHub Repository},&#xA;  howpublished = {\url{https://github.com/junruxiong/IncarnaMind}}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>