<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-12T01:43:23Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>triple-Mu/YOLOv8-TensorRT</title>
    <updated>2023-01-12T01:43:23Z</updated>
    <id>tag:github.com,2023-01-12:/triple-Mu/YOLOv8-TensorRT</id>
    <link href="https://github.com/triple-Mu/YOLOv8-TensorRT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;YOLOv8 using TensorRT accelerate !&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;YOLOv8-TensorRT&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;YOLOv8&lt;/code&gt; using TensorRT accelerate !&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/triple-Mu/YOLOv8-TensorRT&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https%3A%2F%2Factions-badge.atrox.dev%2Fatrox%2Fsync-dotenv%2Fbadge&amp;amp;style=flat&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/triple-Mu/YOLOv8-TensorRT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-3.8--3.10-FFD43B?logo=python&#34; alt=&#34;Python Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://developer.nvidia.com/tensorrt&#34;&gt;&lt;img src=&#34;https://badgen.net/badge/icon/tensorrt?icon=azurepipelines&amp;amp;label&#34; alt=&#34;img&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/triple-Mu/YOLOv8-TensorRT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/CPP-11%2F14-yellow&#34; alt=&#34;C++&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/triple-Mu/YOLOv8-TensorRT/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://badgen.net/github/license/triple-Mu/YOLOv8-TensorRT&#34; alt=&#34;img&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/triple-Mu/YOLOv8-TensorRT/pulls&#34;&gt;&lt;img src=&#34;https://badgen.net/github/prs/triple-Mu/YOLOv8-TensorRT&#34; alt=&#34;img&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/triple-Mu/YOLOv8-TensorRT&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/triple-Mu/YOLOv8-TensorRT.svg?style=social&amp;amp;label=Star&amp;amp;maxAge=2592000&#34; alt=&#34;img&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Prepare the environment&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Install TensorRT follow &lt;a href=&#34;https://developer.nvidia.com/nvidia-tensorrt-8x-download&#34;&gt;&lt;code&gt;TensorRT offical website&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install python requirement.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install -r requirement.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;(optional) Install &lt;a href=&#34;https://github.com/ultralytics/ultralytics&#34;&gt;&lt;code&gt;ultralytics&lt;/code&gt;&lt;/a&gt; package for ONNX export or TensorRT API building.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install ultralytics&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can download pretrained pytorch model by:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;wget https://github.com/ultralytics/ultralytics/releases/download/v8.0.0/yolov8n.pt&#xA;wget https://github.com/ultralytics/ultralytics/releases/download/v8.0.0/yolov8s.pt&#xA;wget https://github.com/ultralytics/ultralytics/releases/download/v8.0.0/yolov8m.pt&#xA;wget https://github.com/ultralytics/ultralytics/releases/download/v8.0.0/yolov8l.pt&#xA;wget https://github.com/ultralytics/ultralytics/releases/download/v8.0.0/yolov8x.pt&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Build TensorRT engine by ONNX&lt;/h1&gt; &#xA;&lt;h2&gt;Export ONNX by &lt;code&gt;ultralytics&lt;/code&gt; API&lt;/h2&gt; &#xA;&lt;p&gt;You can export your onnx model by &lt;code&gt;ultralytics&lt;/code&gt; API and add postprocess into model at the same time.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python export.py \&#xA;--weights yolov8s.pt \&#xA;--iou-thres 0.65 \&#xA;--conf-thres 0.25 \&#xA;--topk 100 \&#xA;--opset 11 \&#xA;--sim \&#xA;--input-shape 1 3 640 640 \&#xA;--device cuda:0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Description of all arguments&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--weights&lt;/code&gt; : The PyTorch model you trained.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--iou-thres&lt;/code&gt; : IOU threshold for NMS plugin.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--conf-thres&lt;/code&gt; : Confidence threshold for NMS plugin.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--topk&lt;/code&gt; : Max number of detection bboxes.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--opset&lt;/code&gt; : ONNX opset version, default is 11.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--sim&lt;/code&gt; : Whether to simplify your onnx model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--input-shape&lt;/code&gt; : Input shape for you model, should be 4 dimensions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--device&lt;/code&gt; : The CUDA deivce you export engine .&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You will get an onnx model whose prefix is the same as input weights.&lt;/p&gt; &#xA;&lt;h2&gt;Preprocessed ONNX model&lt;/h2&gt; &#xA;&lt;p&gt;If you just want to taste first, you can dowload the onnx model which are exported by &lt;code&gt;YOLOv8&lt;/code&gt; package and modified by me.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://triplemu.oss-cn-beijing.aliyuncs.com/YOLOv8/ONNX/yolov8n_nms.onnx?OSSAccessKeyId=LTAI5tN1dgmZD4PF8AJUXp3J&amp;amp;Expires=1772936700&amp;amp;Signature=r6HgJTTcCSAxQxD9bKO9qBTtigQ%3D&#34;&gt;&lt;strong&gt;YOLOv8-n&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://triplemu.oss-cn-beijing.aliyuncs.com/YOLOv8/ONNX/yolov8s_nms.onnx?OSSAccessKeyId=LTAI5tN1dgmZD4PF8AJUXp3J&amp;amp;Expires=1682936722&amp;amp;Signature=JjxQFx1YElcVdsCaMoj81KJ4a5s%3D&#34;&gt;&lt;strong&gt;YOLOv8-s&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://triplemu.oss-cn-beijing.aliyuncs.com/YOLOv8/ONNX/yolov8m_nms.onnx?OSSAccessKeyId=LTAI5tN1dgmZD4PF8AJUXp3J&amp;amp;Expires=1682936739&amp;amp;Signature=IRKBELdVFemD7diixxxgzMYqsWg%3D&#34;&gt;&lt;strong&gt;YOLOv8-m&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://triplemu.oss-cn-beijing.aliyuncs.com/YOLOv8/ONNX/yolov8l_nms.onnx?OSSAccessKeyId=LTAI5tN1dgmZD4PF8AJUXp3J&amp;amp;Expires=1682936763&amp;amp;Signature=RGkJ4G2XJ4J%2BNiki5cJi3oBkDnA%3D&#34;&gt;&lt;strong&gt;YOLOv8-l&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://triplemu.oss-cn-beijing.aliyuncs.com/YOLOv8/ONNX/yolov8x_nms.onnx?OSSAccessKeyId=LTAI5tN1dgmZD4PF8AJUXp3J&amp;amp;Expires=1673936778&amp;amp;Signature=3o%2F7QKhiZg1dW3I6sDrY4ug6MQU%3D&#34;&gt;&lt;strong&gt;YOLOv8-x&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;1. By TensorRT ONNX Python api&lt;/h2&gt; &#xA;&lt;p&gt;You can export TensorRT engine from ONNX by &lt;a href=&#34;https://raw.githubusercontent.com/triple-Mu/YOLOv8-TensorRT/main/build.py&#34;&gt;&lt;code&gt;build.py&lt;/code&gt; &lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python build.py \&#xA;--weights yolov8s.onnx \&#xA;--iou-thres 0.65 \&#xA;--conf-thres 0.25 \&#xA;--topk 100 \&#xA;--fp16  \&#xA;--device cuda:0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Description of all arguments&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--weights&lt;/code&gt; : The ONNX model you download.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--iou-thres&lt;/code&gt; : IOU threshold for NMS plugin.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--conf-thres&lt;/code&gt; : Confidence threshold for NMS plugin.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--topk&lt;/code&gt; : Max number of detection bboxes.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--fp16&lt;/code&gt; : Whether to export half-precision engine.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--device&lt;/code&gt; : The CUDA deivce you export engine .&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can modify &lt;code&gt;iou-thres&lt;/code&gt; &lt;code&gt;conf-thres&lt;/code&gt; &lt;code&gt;topk&lt;/code&gt; by yourself.&lt;/p&gt; &#xA;&lt;h2&gt;2. By trtexec tools&lt;/h2&gt; &#xA;&lt;p&gt;You can export TensorRT engine by &lt;a href=&#34;https://github.com/NVIDIA/TensorRT/tree/main/samples/trtexec&#34;&gt;&lt;code&gt;trtexec&lt;/code&gt;&lt;/a&gt; tools.&lt;/p&gt; &#xA;&lt;p&gt;Usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/usr/src/tensorrt/bin/trtexec --onnx=yolov8s.onnx --saveEngine=yolov8s.engine --fp16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;If you installed TensorRT by a debian package, then the installation path of &lt;code&gt;trtexec&lt;/code&gt; is &lt;code&gt;/usr/src/tensorrt/bin/trtexec&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;If you installed TensorRT by a tar package, then the installation path of &lt;code&gt;trtexec&lt;/code&gt; is under the &lt;code&gt;bin&lt;/code&gt; folder in the path you decompressed&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Build TensorRT engine by API&lt;/h1&gt; &#xA;&lt;p&gt;When you want to build engine by api. You should generate the pickle weights parameters first.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python gen_pkl.py -w yolov8s.pt -o yolov8s.pkl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You will get a &lt;code&gt;yolov8s.pkl&lt;/code&gt; which contain the operators&#39; parameters. And you can rebuild &lt;code&gt;yolov8s&lt;/code&gt; model in TensorRT api.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python build.py \&#xA;--weights yolov8s.pkl \&#xA;--iou-thres 0.65 \&#xA;--conf-thres 0.25 \&#xA;--topk 100 \&#xA;--fp16  \&#xA;--input-shape 1 3 640 640 \&#xA;--device cuda:0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Notice !!!&lt;/strong&gt;&lt;/em&gt; Now we only support static input shape model build by TensorRT api. You&#39;d best give the legal&lt;code&gt;input-shape&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Infer images by the engine which you export or build&lt;/h1&gt; &#xA;&lt;h2&gt;1. Python infer&lt;/h2&gt; &#xA;&lt;p&gt;You can infer images with the engine by &lt;a href=&#34;https://raw.githubusercontent.com/triple-Mu/YOLOv8-TensorRT/main/infer.py&#34;&gt;&lt;code&gt;infer.py&lt;/code&gt;&lt;/a&gt; .&lt;/p&gt; &#xA;&lt;p&gt;Usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python3 infer.py --engine yolov8s.engine --imgs data --show --out-dir outputs --device cuda:0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Description of all arguments&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--engine&lt;/code&gt; : The Engine you export.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--imgs&lt;/code&gt; : The images path you want to detect.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--show&lt;/code&gt; : Whether to show detection results.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--out-dir&lt;/code&gt; : Where to save detection results images. It will not work when use &lt;code&gt;--show&lt;/code&gt; flag.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--device&lt;/code&gt; : The CUDA deivce you use.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--profile&lt;/code&gt; : Profile the TensorRT engine.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;2. C++ infer&lt;/h2&gt; &#xA;&lt;p&gt;You can infer with c++ in &lt;a href=&#34;https://raw.githubusercontent.com/triple-Mu/YOLOv8-TensorRT/main/csrc/end2end&#34;&gt;&lt;code&gt;csrc/end2end&lt;/code&gt;&lt;/a&gt; .&lt;/p&gt; &#xA;&lt;p&gt;Build:&lt;/p&gt; &#xA;&lt;p&gt;Please set you own librarys in &lt;a href=&#34;https://raw.githubusercontent.com/triple-Mu/YOLOv8-TensorRT/main/csrc/end2end/CMakeLists.txt&#34;&gt;&lt;code&gt;CMakeLists.txt&lt;/code&gt;&lt;/a&gt; and modify you own config in &lt;a href=&#34;https://raw.githubusercontent.com/triple-Mu/YOLOv8-TensorRT/main/csrc/end2end/include/config.h&#34;&gt;&lt;code&gt;config.h&lt;/code&gt;&lt;/a&gt; such as &lt;code&gt;CLASS_NAMES&lt;/code&gt; and &lt;code&gt;COLORS&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export root=${PWD}&#xA;cd src/end2end&#xA;mkdir build&#xA;cmake ..&#xA;make&#xA;mv yolov8 ${root}&#xA;cd ${root}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# infer image&#xA;./yolov8 yolov8s.engine data/bus.jpg&#xA;# infer images&#xA;./yolov8 yolov8s.engine data&#xA;# infer video&#xA;./yolov8 yolov8s.engine data/test.mp4 # the video path&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Profile you engine&lt;/h1&gt; &#xA;&lt;p&gt;If you want to profile the TensorRT engine:&lt;/p&gt; &#xA;&lt;p&gt;Usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python3 infer.py --engine yolov8s.engine --profile&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;DeepStream Deploy&lt;/h1&gt; &#xA;&lt;p&gt;See more in &lt;a href=&#34;https://raw.githubusercontent.com/triple-Mu/YOLOv8-TensorRT/main/csrc/deepstream/README.md&#34;&gt;&lt;code&gt;README.md&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>pandas-dev/pandas</title>
    <updated>2023-01-12T01:43:23Z</updated>
    <id>tag:github.com,2023-01-12:/pandas-dev/pandas</id>
    <link href="https://github.com/pandas-dev/pandas" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://pandas.pydata.org/static/img/pandas.svg?sanitize=true&#34;&gt;&#xA; &lt;br&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;pandas: powerful Python data analysis toolkit&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pypi.org/project/pandas/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/pandas.svg?sanitize=true&#34; alt=&#34;PyPI Latest Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://anaconda.org/anaconda/pandas/&#34;&gt;&lt;img src=&#34;https://anaconda.org/conda-forge/pandas/badges/version.svg?sanitize=true&#34; alt=&#34;Conda Latest Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.5281/zenodo.3509134&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/DOI/10.5281/zenodo.3509134.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/pandas/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/status/pandas.svg?sanitize=true&#34; alt=&#34;Package Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pandas-dev/pandas/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/l/pandas.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/pandas-dev/pandas&#34;&gt;&lt;img src=&#34;https://codecov.io/github/pandas-dev/pandas/coverage.svg?branch=main&#34; alt=&#34;Coverage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/pandas&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/personalized-badge/pandas?period=month&amp;amp;units=international_system&amp;amp;left_color=black&amp;amp;right_color=orange&amp;amp;left_text=PyPI%20downloads%20per%20month&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/join_Slack-information-brightgreen.svg?logo=slack&#34; alt=&#34;Slack&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://numfocus.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&amp;amp;colorA=E1523D&amp;amp;colorB=007D8A&#34; alt=&#34;Powered by NumFOCUS&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/psf/black&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true&#34; alt=&#34;Code style: black&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pycqa.github.io/isort/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&amp;amp;labelColor=ef8336&#34; alt=&#34;Imports: isort&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is it?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;pandas&lt;/strong&gt; is a Python package that provides fast, flexible, and expressive data structures designed to make working with &#34;relational&#34; or &#34;labeled&#34; data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, &lt;strong&gt;real world&lt;/strong&gt; data analysis in Python. Additionally, it has the broader goal of becoming &lt;strong&gt;the most powerful and flexible open source data analysis / manipulation tool available in any language&lt;/strong&gt;. It is already well on its way towards this goal.&lt;/p&gt; &#xA;&lt;h2&gt;Main Features&lt;/h2&gt; &#xA;&lt;p&gt;Here are just a few of the things that pandas does well:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Easy handling of &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html&#34;&gt;&lt;strong&gt;missing data&lt;/strong&gt;&lt;/a&gt; (represented as &lt;code&gt;NaN&lt;/code&gt;, &lt;code&gt;NA&lt;/code&gt;, or &lt;code&gt;NaT&lt;/code&gt;) in floating point as well as non-floating point data&lt;/li&gt; &#xA; &lt;li&gt;Size mutability: columns can be &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#column-selection-addition-deletion&#34;&gt;&lt;strong&gt;inserted and deleted&lt;/strong&gt;&lt;/a&gt; from DataFrame and higher dimensional objects&lt;/li&gt; &#xA; &lt;li&gt;Automatic and explicit &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html?highlight=alignment#intro-to-data-structures&#34;&gt;&lt;strong&gt;data alignment&lt;/strong&gt;&lt;/a&gt;: objects can be explicitly aligned to a set of labels, or the user can simply ignore the labels and let &lt;code&gt;Series&lt;/code&gt;, &lt;code&gt;DataFrame&lt;/code&gt;, etc. automatically align the data for you in computations&lt;/li&gt; &#xA; &lt;li&gt;Powerful, flexible &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#group-by-split-apply-combine&#34;&gt;&lt;strong&gt;group by&lt;/strong&gt;&lt;/a&gt; functionality to perform split-apply-combine operations on data sets, for both aggregating and transforming data&lt;/li&gt; &#xA; &lt;li&gt;Make it &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dataframe&#34;&gt;&lt;strong&gt;easy to convert&lt;/strong&gt;&lt;/a&gt; ragged, differently-indexed data in other Python and NumPy data structures into DataFrame objects&lt;/li&gt; &#xA; &lt;li&gt;Intelligent label-based &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#slicing-ranges&#34;&gt;&lt;strong&gt;slicing&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#advanced&#34;&gt;&lt;strong&gt;fancy indexing&lt;/strong&gt;&lt;/a&gt;, and &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing&#34;&gt;&lt;strong&gt;subsetting&lt;/strong&gt;&lt;/a&gt; of large data sets&lt;/li&gt; &#xA; &lt;li&gt;Intuitive &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#database-style-dataframe-or-named-series-joining-merging&#34;&gt;&lt;strong&gt;merging&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#joining-on-index&#34;&gt;&lt;strong&gt;joining&lt;/strong&gt;&lt;/a&gt; data sets&lt;/li&gt; &#xA; &lt;li&gt;Flexible &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html&#34;&gt;&lt;strong&gt;reshaping&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html&#34;&gt;&lt;strong&gt;pivoting&lt;/strong&gt;&lt;/a&gt; of data sets&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#hierarchical-indexing-multiindex&#34;&gt;&lt;strong&gt;Hierarchical&lt;/strong&gt;&lt;/a&gt; labeling of axes (possible to have multiple labels per tick)&lt;/li&gt; &#xA; &lt;li&gt;Robust IO tools for loading data from &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#csv-text-files&#34;&gt;&lt;strong&gt;flat files&lt;/strong&gt;&lt;/a&gt; (CSV and delimited), &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#excel-files&#34;&gt;&lt;strong&gt;Excel files&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#sql-queries&#34;&gt;&lt;strong&gt;databases&lt;/strong&gt;&lt;/a&gt;, and saving/loading data from the ultrafast &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#hdf5-pytables&#34;&gt;&lt;strong&gt;HDF5 format&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#time-series-date-functionality&#34;&gt;&lt;strong&gt;Time series&lt;/strong&gt;&lt;/a&gt;-specific functionality: date range generation and frequency conversion, moving window statistics, date shifting and lagging&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Where to get it&lt;/h2&gt; &#xA;&lt;p&gt;The source code is currently hosted on GitHub at: &lt;a href=&#34;https://github.com/pandas-dev/pandas&#34;&gt;https://github.com/pandas-dev/pandas&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Binary installers for the latest released version are available at the &lt;a href=&#34;https://pypi.org/project/pandas&#34;&gt;Python Package Index (PyPI)&lt;/a&gt; and on &lt;a href=&#34;https://docs.conda.io/en/latest/&#34;&gt;Conda&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# conda&#xA;conda install pandas&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# or PyPI&#xA;pip install pandas&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.numpy.org&#34;&gt;NumPy - Adds support for large, multi-dimensional arrays, matrices and high-level mathematical functions to operate on these arrays&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dateutil.readthedocs.io/en/stable/index.html&#34;&gt;python-dateutil - Provides powerful extensions to the standard datetime module&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/stub42/pytz&#34;&gt;pytz - Brings the Olson tz database into Python which allows accurate and cross platform timezone calculations&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/install.html#dependencies&#34;&gt;full installation instructions&lt;/a&gt; for minimum supported versions of required, recommended and optional dependencies.&lt;/p&gt; &#xA;&lt;h2&gt;Installation from sources&lt;/h2&gt; &#xA;&lt;p&gt;To install pandas from source you need &lt;a href=&#34;https://cython.org/&#34;&gt;Cython&lt;/a&gt; in addition to the normal dependencies above. Cython can be installed from PyPI:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install cython&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the &lt;code&gt;pandas&lt;/code&gt; directory (same one where you found this file after cloning the git repo), execute:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python setup.py install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or for installing in &lt;a href=&#34;https://pip.pypa.io/en/latest/cli/pip_install/#install-editable&#34;&gt;development mode&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python -m pip install -e . --no-build-isolation --no-use-pep517&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or alternatively&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python setup.py develop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See the full instructions for &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/getting_started/install.html#installing-from-source&#34;&gt;installing from source&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pandas-dev/pandas/main/LICENSE&#34;&gt;BSD 3&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;The official documentation is hosted on PyData.org: &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable&#34;&gt;https://pandas.pydata.org/pandas-docs/stable&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Background&lt;/h2&gt; &#xA;&lt;p&gt;Work on &lt;code&gt;pandas&lt;/code&gt; started at &lt;a href=&#34;https://www.aqr.com/&#34;&gt;AQR&lt;/a&gt; (a quantitative hedge fund) in 2008 and has been under active development since then.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Help&lt;/h2&gt; &#xA;&lt;p&gt;For usage questions, the best place to go to is &lt;a href=&#34;https://stackoverflow.com/questions/tagged/pandas&#34;&gt;StackOverflow&lt;/a&gt;. Further, general questions and discussions can also take place on the &lt;a href=&#34;https://groups.google.com/forum/?fromgroups#!forum/pydata&#34;&gt;pydata mailing list&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Discussion and Development&lt;/h2&gt; &#xA;&lt;p&gt;Most development discussions take place on GitHub in this repo. Further, the &lt;a href=&#34;https://mail.python.org/mailman/listinfo/pandas-dev&#34;&gt;pandas-dev mailing list&lt;/a&gt; can also be used for specialized discussions or design issues, and a &lt;a href=&#34;https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack&#34;&gt;Slack channel&lt;/a&gt; is available for quick development related questions.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing to pandas &lt;a href=&#34;https://www.codetriage.com/pandas-dev/pandas&#34;&gt;&lt;img src=&#34;https://www.codetriage.com/pandas-dev/pandas/badges/users.svg?sanitize=true&#34; alt=&#34;Open Source Helpers&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;All contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome.&lt;/p&gt; &#xA;&lt;p&gt;A detailed overview on how to contribute can be found in the &lt;strong&gt;&lt;a href=&#34;https://pandas.pydata.org/docs/dev/development/contributing.html&#34;&gt;contributing guide&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you are simply looking to start working with the pandas codebase, navigate to the &lt;a href=&#34;https://github.com/pandas-dev/pandas/issues&#34;&gt;GitHub &#34;issues&#34; tab&lt;/a&gt; and start looking through interesting issues. There are a number of issues listed under &lt;a href=&#34;https://github.com/pandas-dev/pandas/issues?labels=Docs&amp;amp;sort=updated&amp;amp;state=open&#34;&gt;Docs&lt;/a&gt; and &lt;a href=&#34;https://github.com/pandas-dev/pandas/issues?labels=good+first+issue&amp;amp;sort=updated&amp;amp;state=open&#34;&gt;good first issue&lt;/a&gt; where you could start out.&lt;/p&gt; &#xA;&lt;p&gt;You can also triage issues which may include reproducing bug reports, or asking for vital information such as version numbers or reproduction instructions. If you would like to start triaging issues, one easy way to get started is to &lt;a href=&#34;https://www.codetriage.com/pandas-dev/pandas&#34;&gt;subscribe to pandas on CodeTriage&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Or maybe through using pandas you have an idea of your own or are looking for something in the documentation and thinking ‘this can be improved’...you can do something about it!&lt;/p&gt; &#xA;&lt;p&gt;Feel free to ask questions on the &lt;a href=&#34;https://groups.google.com/forum/?fromgroups#!forum/pydata&#34;&gt;mailing list&lt;/a&gt; or on &lt;a href=&#34;https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack&#34;&gt;Slack&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;As contributors and maintainers to this project, you are expected to abide by pandas&#39; code of conduct. More information can be found at: &lt;a href=&#34;https://github.com/pandas-dev/.github/raw/master/CODE_OF_CONDUCT.md&#34;&gt;Contributor Code of Conduct&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>cosmicpb/FascistFree</title>
    <updated>2023-01-12T01:43:23Z</updated>
    <id>tag:github.com,2023-01-12:/cosmicpb/FascistFree</id>
    <link href="https://github.com/cosmicpb/FascistFree" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Detectando rostos em vídeos&lt;/h1&gt; &#xA;&lt;p&gt;Com este código, você precisa apenas executá-lo e indicar o link do vídeo no YouTube. Assim que isso for feito, o programa pedirá um nome para o arquivo.&lt;/p&gt; &#xA;&lt;p&gt;Depois disso, todos os rostos que forem aparecendo serão detectados e enviados para uma pasta dentro do diretório do programa.&lt;/p&gt; &#xA;&lt;h2&gt;Instação&lt;/h2&gt; &#xA;&lt;p&gt;Faça o download do código utilizando GIT ou utilize o ZIP disponível aqui no portal do GitHub.&lt;/p&gt; &#xA;&lt;p&gt;*IMPORTANTE salientar que o código NÃO IDENTIFICA faces, apenas detecta-as em qualquer vídeo que for submetido ao algoritmo, podendo ser utilizado para outros fins como seleção de rosto de atores em filmes e novelas.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/cosmicpb/FascistFree.git&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usando o script com o docker-compose&lt;/h2&gt; &#xA;&lt;p&gt;Passo 1 - Acesse o repositório do projeto:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd FascistFree&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Passo 2 - Gere o container:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-compose build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Passo 3 - Execute o container alterando o link para o seu link do YouTube:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;LINK=https://www.youtube.com/watch?v=xxxx docker-compose run app&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Será gerada na pasta &lt;code&gt;dump&lt;/code&gt; as imagens encontradas&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Nota: &lt;a href=&#34;https://docs.docker.com/compose/install/&#34;&gt;Clique aqui&lt;/a&gt; caso você não tenha o docker-compose instalado.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Usando o script&lt;/h2&gt; &#xA;&lt;p&gt;Passo 1 - Acesse o repositório do projeto:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd FascistFree&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Passo 2 - Instale as Libs (Bibliotecas) necessárias através do gerenciador de pacotes &#34;pip&#34;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Passo 3 - Execute o script Python:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python3 main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://uploaddeimagens.com.br/images/004/289/753/original/1.png?1673290162&#34; alt=&#34;alt text&#34;&gt; Serão criadas duas novas pastas:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;video-opencv (com todos os frames capturados)&lt;/li&gt; &#xA; &lt;li&gt;video-faces (com todas as faces detectadas nos frames capturados)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;O código está capturando 1 frame por segundo. Para mudar esta taxa, modifique a seguinte linha de código:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;SAVING_FRAMES_PER_SECOND = 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Developed by Paulo&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;FREE ASSANGE&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Free Software, Hell Yeah!&lt;/strong&gt;&lt;/p&gt;</summary>
  </entry>
</feed>