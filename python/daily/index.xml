<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-09T01:38:58Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>google/style-aligned</title>
    <updated>2023-12-09T01:38:58Z</updated>
    <id>tag:github.com,2023-12-09:/google/style-aligned</id>
    <link href="https://github.com/google/style-aligned" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official code for &#34;Style Aligned Image Generation via Shared Attention&#34;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Style Aligned Image Generation via Shared Attention&lt;/h1&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://style-aligned-gen.github.io&#34;&gt;Project Page&lt;/a&gt;   &lt;a href=&#34;https://style-aligned-gen.github.io/data/StyleAligned.pdf&#34;&gt;Paper&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;This code was tested with Python 3.11, &lt;a href=&#34;https://pytorch.org/&#34;&gt;Pytorch 2.1&lt;/a&gt; and &lt;a href=&#34;https://github.com/huggingface/diffusers&#34;&gt;Diffusers 0.16&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/google/style-aligned/main/style_aligned_sdxl.ipynb&#34;&gt;&lt;strong&gt;style_aligned_sdxl&lt;/strong&gt;&lt;/a&gt; notebook for generating style aligned images using &lt;a href=&#34;https://huggingface.co/docs/diffusers/using-diffusers/sdxl&#34;&gt;SDXL&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/google/style-aligned/main/doc/sa_example.jpg&#34; alt=&#34;alt text&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/google/style-aligned/main/style_aligned_transfer_sdxl.ipynb&#34;&gt;&lt;strong&gt;style_aligned_transfer_sdxl&lt;/strong&gt;&lt;/a&gt; notebook for generating images with a style from reference image using &lt;a href=&#34;https://huggingface.co/docs/diffusers/using-diffusers/sdxl&#34;&gt;SDXL&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/google/style-aligned/main/doc/sa_transfer_example.jpeg&#34; alt=&#34;alt text&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/google/style-aligned/main/style_aligned_w_controlnet.ipynb&#34;&gt;&lt;strong&gt;style_aligned_w_controlnet&lt;/strong&gt;&lt;/a&gt; notebook for generating style aligned and depth conditioned images using SDXL with &lt;a href=&#34;https://arxiv.org/abs/2302.05543&#34;&gt;ControlNet-Depth&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/google/style-aligned/main/doc/cn_example.jpg&#34; alt=&#34;alt text&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/style-aligned/main/style_aligned_w_multidiffusion.ipynb&#34;&gt;&lt;strong&gt;style_aligned_w_multidiffusion&lt;/strong&gt;&lt;/a&gt; can be used for generating style aligned panoramas using &lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-2&#34;&gt;SD V2&lt;/a&gt; with &lt;a href=&#34;https://multidiffusion.github.io/&#34;&gt;MultiDiffusion&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/google/style-aligned/main/doc/md_example.jpg&#34; alt=&#34;alt text&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;TODOs&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Adding demo.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; StyleAligned from an input image.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Multi-style with MultiDiffusion.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; StyleAligned with DreamBooth&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This is not an officially supported Google product.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>fortra/impacket</title>
    <updated>2023-12-09T01:38:58Z</updated>
    <id>tag:github.com,2023-12-09:/fortra/impacket</id>
    <link href="https://github.com/fortra/impacket" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Impacket is a collection of Python classes for working with network protocols.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Impacket&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pypi.python.org/pypi/impacket/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/impacket.svg?sanitize=true&#34; alt=&#34;Latest Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/fortra/impacket/actions/workflows/build_and_test.yml&#34;&gt;&lt;img src=&#34;https://github.com/fortra/impacket/actions/workflows/build_and_test.yml/badge.svg?sanitize=true&#34; alt=&#34;Build and test Impacket&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;FORTRA. Copyright (C) 2023 Fortra. All rights reserved.&lt;/p&gt; &#xA;&lt;p&gt;Impacket was originally created by &lt;a href=&#34;https://www.secureauth.com/labs/open-source-tools/impacket&#34;&gt;SecureAuth&lt;/a&gt;, and now maintained by Fortra&#39;s Core Security.&lt;/p&gt; &#xA;&lt;p&gt;Impacket is a collection of Python classes for working with network protocols. Impacket is focused on providing low-level programmatic access to the packets and for some protocols (e.g. SMB1-3 and MSRPC) the protocol implementation itself. Packets can be constructed from scratch, as well as parsed from raw data, and the object-oriented API makes it simple to work with deep hierarchies of protocols. The library provides a set of tools as examples of what can be done within the context of this library.&lt;/p&gt; &#xA;&lt;h2&gt;What protocols are featured?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ethernet, Linux &#34;Cooked&#34; capture.&lt;/li&gt; &#xA; &lt;li&gt;IP, TCP, UDP, ICMP, IGMP, ARP.&lt;/li&gt; &#xA; &lt;li&gt;IPv4 and IPv6 Support.&lt;/li&gt; &#xA; &lt;li&gt;NMB and SMB1, SMB2 and SMB3 (high-level implementations).&lt;/li&gt; &#xA; &lt;li&gt;MSRPC version 5, over different transports: TCP, SMB/TCP, SMB/NetBIOS and HTTP.&lt;/li&gt; &#xA; &lt;li&gt;Plain, NTLM and Kerberos authentications, using password/hashes/tickets/keys.&lt;/li&gt; &#xA; &lt;li&gt;Portions/full implementation of the following MSRPC interfaces: EPM, DTYPES, LSAD, LSAT, NRPC, RRP, SAMR, SRVS, WKST, SCMR, BKRP, DHCPM, EVEN6, MGMT, SASEC, TSCH, DCOM, WMI, OXABREF, NSPI, OXNSPI.&lt;/li&gt; &#xA; &lt;li&gt;Portions of TDS (MSSQL) and LDAP protocol implementations.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Maintainer&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.coresecurity.com/&#34;&gt;Core Security&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Table of Contents&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/fortra/impacket/master/#getting-impacket&#34;&gt;Getting Impacket&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/fortra/impacket/master/#setup&#34;&gt;Setup&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/fortra/impacket/master/#testing&#34;&gt;Testing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/fortra/impacket/master/#licensing&#34;&gt;Licensing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/fortra/impacket/master/#disclaimer&#34;&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/fortra/impacket/master/#contact-us&#34;&gt;Contact Us&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Getting Impacket&lt;/h1&gt; &#xA;&lt;h3&gt;Latest version&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Impacket v0.11.0&lt;/p&gt; &lt;p&gt;&lt;a href=&#34;https://pypi.python.org/pypi/impacket/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/impacket.svg?sanitize=true&#34; alt=&#34;Python versions&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/fortra/impacket/releases&#34;&gt;Current and past releases&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Development version&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Impacket v0.12.0-dev (&lt;strong&gt;&lt;a href=&#34;https://github.com/fortra/impacket/tree/master&#34;&gt;master branch&lt;/a&gt;&lt;/strong&gt;)&lt;/p&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/fortra/impacket/tree/master&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.6%20%7C%203.7%20%7C%203.8%20%7C%203.9%20%7C%203.10-blue.svg?sanitize=true&#34; alt=&#34;Python versions&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Setup&lt;/h1&gt; &#xA;&lt;h3&gt;Quick start&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;ℹ&lt;/span&gt; We recommend using &lt;code&gt;pipx&lt;/code&gt; over &lt;code&gt;pip&lt;/code&gt; for system-wide installations.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;In order to grab the latest stable release run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 -m pipx install impacket&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to play with the unreleased changes, download the development version from the &lt;a href=&#34;https://github.com/fortra/impacket/tree/master&#34;&gt;master branch&lt;/a&gt;, extract the package, and execute the following command from the directory where Impacket has been unpacked:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 -m pipx install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Docker Support&lt;/h3&gt; &#xA;&lt;p&gt;Build Impacket&#39;s image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  $ docker build -t &#34;impacket:latest&#34; .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Using Impacket&#39;s image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  $ docker run -it --rm &#34;impacket:latest&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Testing&lt;/h1&gt; &#xA;&lt;p&gt;The library leverages the &lt;a href=&#34;https://docs.pytest.org/&#34;&gt;pytest&lt;/a&gt; framework for organizing and marking test cases, &lt;a href=&#34;https://tox.readthedocs.io/&#34;&gt;tox&lt;/a&gt; to automate the process of running them across supported Python versions, and &lt;a href=&#34;https://coverage.readthedocs.io/&#34;&gt;coverage&lt;/a&gt; to obtain coverage statistics.&lt;/p&gt; &#xA;&lt;p&gt;A &lt;a href=&#34;https://raw.githubusercontent.com/fortra/impacket/master/TESTING.md&#34;&gt;comprehensive testing guide&lt;/a&gt; is available.&lt;/p&gt; &#xA;&lt;h1&gt;Licensing&lt;/h1&gt; &#xA;&lt;p&gt;This software is provided under a slightly modified version of the Apache Software License. See the accompanying &lt;a href=&#34;https://raw.githubusercontent.com/fortra/impacket/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for more information.&lt;/p&gt; &#xA;&lt;p&gt;SMBv1 and NetBIOS support based on Pysmb by Michael Teo.&lt;/p&gt; &#xA;&lt;h1&gt;Disclaimer&lt;/h1&gt; &#xA;&lt;p&gt;The spirit of this Open Source initiative is to help security researchers, and the community, speed up research and educational activities related to the implementation of networking protocols and stacks.&lt;/p&gt; &#xA;&lt;p&gt;The information in this repository is for research and educational purposes and not meant to be used in production environments and/or as part of commercial products.&lt;/p&gt; &#xA;&lt;p&gt;If you desire to use this code or some part of it for your own uses, we recommend applying proper security development life cycle and secure coding practices, as well as generate and track the respective indicators of compromise according to your needs.&lt;/p&gt; &#xA;&lt;h1&gt;Contact Us&lt;/h1&gt; &#xA;&lt;p&gt;Whether you want to report a bug, send a patch, or give some suggestions on this package, reach out to us at &lt;a href=&#34;https://www.coresecurity.com/about/contact&#34;&gt;https://www.coresecurity.com/about/contact&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For security-related questions check our &lt;a href=&#34;https://raw.githubusercontent.com/fortra/impacket/master/SECURITY.md&#34;&gt;security policy&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>huggingface/optimum-nvidia</title>
    <updated>2023-12-09T01:38:58Z</updated>
    <id>tag:github.com,2023-12-09:/huggingface/optimum-nvidia</id>
    <link href="https://github.com/huggingface/optimum-nvidia" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;Optimum-NVIDIA&lt;/h1&gt; &#xA; &lt;h4&gt; Optimized inference with NVIDIA and Hugging Face &lt;/h4&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/docs/optimum/index&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-latest-brightgreen.svg?style=flat&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.python.org/downloads/release/python-31012/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.10.12-green&#34; alt=&#34;python&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://developer.nvidia.com/cuda-downloads&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/cuda-12.2-green&#34; alt=&#34;cuda&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/nvidia/tensorrt-llm&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/TensorRT--LLM-0.6.1-green&#34; alt=&#34;trt-llm&#34;&gt;&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/release-0.1.0-green&#34; alt=&#34;version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/huggingface/optimum-nvidia/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-blue&#34; alt=&#34;license&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;hr&gt; &#xA; &lt;div align=&#34;left&#34;&gt; &#xA;  &lt;p&gt;Optimum-NVIDIA delivers the best inference performance on the NVIDIA platform through Hugging Face. Run LLaMA 2 at 1,200 tokens/second (up to 28x faster than the framework) by changing just a single line in your existing transformers code.&lt;/p&gt; &#xA; &lt;/div&gt;&#xA;&lt;/div&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;p&gt;You can use a Docker container to try Optimum-NVIDIA today. Images are available on the Hugging Face Docker Hub.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker pull huggingface/optimum-nvidia&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- You can also build from source with the Dockerfile provided here. &#xA;&#xA;```bash&#xA;git clone git@github.com:huggingface/optimum-nvidia.git&#xA;cd optimum-nvidia&#xA;docker build Dockerfile&#xA;docker run optimum-nvidia&#xA;``` --&gt; &#xA;&lt;p&gt;An Optimum-NVIDIA package that can be installed with &lt;code&gt;pip&lt;/code&gt; will be made available soon.&lt;/p&gt; &#xA;&lt;h1&gt;Quickstart Guide&lt;/h1&gt; &#xA;&lt;h2&gt;Pipelines&lt;/h2&gt; &#xA;&lt;p&gt;Hugging Face pipelines provide a simple yet powerful abstraction to quickly set up inference. If you already have a pipeline from transformers, you can unlock the performance benefits of Optimum-NVIDIA by just changing one line.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;- from transformers.pipelines import pipeline&#xA;+ from optimum.nvidia.pipelines import pipeline&#xA;&#xA;pipe = pipeline(&#39;text-generation&#39;, &#39;meta-llama/Llama-2-7b-chat-hf&#39;, use_fp8=True)&#xA;pipe(&#34;Describe a real-world application of AI in sustainable energy.&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Generate&lt;/h2&gt; &#xA;&lt;p&gt;If you want control over advanced features like quantization and token seleciton strategies, we recommend using the &lt;code&gt;generate()&lt;/code&gt; API. Just like with &lt;code&gt;pipelines&lt;/code&gt;, switching from existing transformers code is super simple.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;- from transformers import LlamaForCausalLM&#xA;+ from optimum.nvidia import LlamaForCausalLM&#xA;from transformers import AutoTokenizer&#xA;&#xA;tokenizer = AutoTokenizer.from_pretrained(&#34;meta-llama/Llama-2-7b-chat-hf&#34;, padding_side=&#34;left&#34;)&#xA;&#xA;model = LlamaForCausalLM.from_pretrained(&#xA;  &#34;meta-llama/Llama-2-7b-chat-hf&#34;,&#xA;+ use_fp8=True,  &#xA;)&#xA;&#xA;model_inputs = tokenizer([&#34;How is autonomous vehicle technology transforming the future of transportation and urban planning?&#34;], return_tensors=&#34;pt&#34;).to(&#34;cuda&#34;)&#xA;&#xA;generated_ids = model.generate(&#xA;                    **model_inputs, &#xA;                    top_k=40, &#xA;                    top_p=0.7, &#xA;                    repetition_penalty=10,&#xA;)&#xA;&#xA;tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To learn more about text generation with LLMs, check out &lt;a href=&#34;https://huggingface.co/docs/transformers/llm_tutorial&#34;&gt;this guide&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;!-- For more details, read our [documentation](https://huggingface.com/docs/optimum/nvidia/index). --&gt; &#xA;&lt;h1&gt;Support Matrix&lt;/h1&gt; &#xA;&lt;p&gt;We test Optimum-NVIDIA on 4090, L40S, and H100 Tensor Core GPUs, though it is expected to work on any GPU based on the following architectures:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Volta&lt;/li&gt; &#xA; &lt;li&gt;Turing&lt;/li&gt; &#xA; &lt;li&gt;Ampere&lt;/li&gt; &#xA; &lt;li&gt;Hopper&lt;/li&gt; &#xA; &lt;li&gt;Ada-Lovelace&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note that FP8 support is only available on GPUs based on Hopper and Ada-Lovelace architectures.&lt;/p&gt; &#xA;&lt;p&gt;Optimum-NVIDIA works on Linux will support Windows soon.&lt;/p&gt; &#xA;&lt;p&gt;Optimum-NVIDIA currently accelerates text-generation with LLaMAForCausalLM, and we are actively working to expand support to include more model architectures and tasks.&lt;/p&gt; &#xA;&lt;!-- Optimum-NVIDIA supports the following model architectures and tasks:&#xA;&#xA;| Model             | Tasks           |&#xA;| :----             | :----           |&#xA;| LLaMAForCausalLM  | TextGeneration  |&#xA;| Additional Models | Coming soon     | --&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;Check out our &lt;a href=&#34;https://raw.githubusercontent.com/huggingface/optimum-nvidia/main/CONTRIBUTING.md&#34;&gt;Contributing Guide&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>