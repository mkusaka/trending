<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-26T01:41:38Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>LawRefBook/Laws</title>
    <updated>2023-04-26T01:41:38Z</updated>
    <id>tag:github.com,2023-04-26:/LawRefBook/Laws</id>
    <link href="https://github.com/LawRefBook/Laws" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;hr&gt; &#xA;&lt;h2&gt;draft: true&lt;/h2&gt; &#xA;&lt;h2&gt;贡献指南&lt;/h2&gt; &#xA;&lt;p&gt;app 在设计的时候将法律法规和 app 本身分离开了, 只需要增加法条和修改 data.json 即可添加某部法律..&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;首先将法律法规按照 &lt;a href=&#34;https://raw.githubusercontent.com/LawRefBook/Laws/master/%E6%B3%95%E5%BE%8B%E6%B3%95%E8%A7%84%E6%A8%A1%E7%89%88.md&#34;&gt;法律法规模版&lt;/a&gt; 排版好，放入文件夹 &lt;code&gt;法律法规&lt;/code&gt; 下合适的位置&lt;/li&gt; &#xA; &lt;li&gt;使用脚本 &lt;code&gt;python3 scripts/update.py&lt;/code&gt; （脚本会自动处理，将新增法律加入列表以及合适的位置）&lt;/li&gt; &#xA; &lt;li&gt;提交更改，并提 pr&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;PS 如果你有发现某部法律不完整，有问题，或者需要新增某些，但又不会自己提 pr，你可以在提一个 issue，或者直接联系设置中我的邮箱，我会在下个版本修复或增加&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>OpenBMB/BMTools</title>
    <updated>2023-04-26T01:41:38Z</updated>
    <id>tag:github.com,2023-04-26:/OpenBMB/BMTools</id>
    <link href="https://github.com/OpenBMB/BMTools" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Tool Learning for Big Models, Open-Source Solutions of ChatGPT-Plugins&lt;/p&gt;&lt;hr&gt;&lt;div style=&#34;text-align: center;&#34;&gt; &#xA; &lt;h1&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/BMTools/main/docs/logo.png&#34; height=&#34;28px&#34;&gt; BMTools&lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;em&gt;Read this in &lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/BMTools/main/README_zh.md&#34;&gt;Chinese&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;BMTools is an open-source repository that extends language models using tools and serves as a platform for the community to build and share tools. In this repository, you can (1) easily build a plugin by writing python functions (2) use external ChatGPT-Plugins.&lt;/p&gt; &#xA;&lt;p&gt;This project is inspired by the open-source project &lt;a href=&#34;https://github.com/hwchase17/langchain/&#34;&gt;LangChain&lt;/a&gt; and optimized for the usage of open-sourced tools like &lt;a href=&#34;https://openai.com/blog/chatgpt-plugins&#34;&gt;ChatGPT-Plugins&lt;/a&gt;, striving to achieve the open-source academic version of ChatGPT-Plugins.&lt;/p&gt; &#xA;&lt;p&gt;Current version of BMTools is far from perfect, we will continue to improve it.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;A demo of using BMTools to manipulate tools for meta analysis.&lt;/strong&gt; &lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/BMTools/main/docs/meta0423.gif&#34; alt=&#34;A demo of BMTools&#34;&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What&#39;s New&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/4/24 &lt;a href=&#34;https://github.com/Significant-Gravitas/Auto-GPT&#34;&gt;Auto-GPT&lt;/a&gt; is supported in BMTools.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/4/14 &lt;a href=&#34;https://github.com/yoheinakajima/babyagi&#34;&gt;BabyAGI&lt;/a&gt; is supported in BMTools.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;1. Setup&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone git@github.com:OpenBMB/BMTools.git&#xA;python setup.py develop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;2. Use existing tools&lt;/h2&gt; &#xA;&lt;h3&gt;2.1 Set up tools&lt;/h3&gt; &#xA;&lt;h4&gt;2.1.1 Local tools&lt;/h4&gt; &#xA;&lt;p&gt;Add your api keys to secret_keys.sh, then start the local tools&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;source secret_keys.sh&#xA;python host_local_tools.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then set the url of the plugin to &lt;code&gt;http://127.0.0.1:8079/tools/{tool_name}/&lt;/code&gt; (Remember the tailing &lt;code&gt;/&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;h4&gt;2.1.2 Use online ChatGPT-Plugins&lt;/h4&gt; &#xA;&lt;p&gt;Just load it with the URL pointed to the &lt;code&gt;.well-known/ai-plugin.json&lt;/code&gt; For example, set the url to &lt;code&gt;https://www.klarna.com/&lt;/code&gt;, where &lt;code&gt;https://www.klarna.com/.well-known/ai-plugin.json&lt;/code&gt; is a valid configuration.&lt;/p&gt; &#xA;&lt;h3&gt;2.2 Use a single tool&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bmtools.agent.singletool import load_single_tools, STQuestionAnswerer&#xA;&#xA;tool_name, tool_url = &#39;klarna&#39;,  &#39;https://www.klarna.com/&#39;&#xA;tool_name, tool_config = load_single_tools(tool_name, tool_url)&#xA;print(tool_name, tool_config)&#xA;stqa =  STQuestionAnswerer()&#xA;&#xA;agent = stqa.load_tools(tool_name, tool_config)&#xA;agent(&#34;{Your Question}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2.3 Use multiple tools&lt;/h3&gt; &#xA;&lt;p&gt;We can use multiple tools at the same time. Basically, the language model will do it recursively. It will treat the whole tool as an API, send questions to it, and the tool calls its sub-APIs to solve the question and send it back to parent tools. This functionality will be useful in the upcoming Chat mode.&lt;/p&gt; &#xA;&lt;p&gt;Try this functionality using scripts like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bmtools.agent.tools_controller import load_valid_tools, MTQuestionAnswerer&#xA;tools_mappings = {&#xA;    &#34;klarna&#34;: &#34;https://www.klarna.com/&#34;,&#xA;    &#34;chemical-prop&#34;: &#34;http://127.0.0.1:8079/tools/chemical-prop/&#34;,&#xA;    &#34;wolframalpha&#34;: &#34;http://127.0.0.1:8079/tools/wolframalpha/&#34;,&#xA;}&#xA;&#xA;tools = load_valid_tools(tools_mappings)&#xA;&#xA;qa =  MTQuestionAnswerer(openai_api_key=&#39;&#39;, all_tools=tools)&#xA;&#xA;agent = qa.build_runner()&#xA;&#xA;agent(&#34;How many benzene rings are there in 9H-Carbazole-3-carboxaldehyde? and what is sin(x)*exp(x)&#39;s plot, what is it integrated from 0 to 1? &#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2.4 Use the web demo&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Add your plugin to the mappings at beginning of web_demo.py&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Start the webdemo&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python web_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;3. Use customized tools&lt;/h2&gt; &#xA;&lt;h3&gt;3.1 Develop a tool locally&lt;/h3&gt; &#xA;&lt;p&gt;To develop a tool locally, you need to write a python function to build the tool and register it to the registry.&lt;/p&gt; &#xA;&lt;p&gt;For example, you can write a tool that can execute python code and return the result. The following is a sample code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bmtools.tools import Tool&#xA;from pydantic import BaseModel&#xA;&#xA;class ExecutionQuery(BaseModel):&#xA;    code: str&#xA;&#xA;class ExecutionResult(BaseModel):&#xA;    result: str&#xA;&#xA;def build_python_tool(config) -&amp;gt; Tool:&#xA;    tool = Tool(&#xA;        &#34;PythonTool&#34;,&#xA;        &#34;A plugin that can execute python code&#34;,&#xA;        name_for_model=&#34;python&#34;, &#xA;        description_for_model=&#34;A plugin that can execute python code&#34;,&#xA;        contact_email=&#34;your@email&#34;,&#xA;    )&#xA;&#xA;    @tool.post(&#34;/execute&#34;)&#xA;    def execute_python_code(query : ExecutionQuery) -&amp;gt; ExecutionResult:&#xA;        return ExecutionResult(&#xA;            result=eval(query.code)&#xA;        )&#xA;    &#xA;    return tool&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then you need to register the tool to the registry using the following code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bmtools.tools import register&#xA;&#xA;@register(&#34;python&#34;)&#xA;def register_python_tool():&#xA;    return build_python_tool&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here we register the tool with the name &lt;code&gt;python&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;3.2 Contributing to BMTools&lt;/h3&gt; &#xA;&lt;p&gt;After you have developed a tool, you can contribute it to BMTools by following the steps below:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Fork this repository&lt;/li&gt; &#xA; &lt;li&gt;Create a folder in &lt;code&gt;bmtools/tools/{tool_name}&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Add an &lt;code&gt;api.py&lt;/code&gt; to the folder: &lt;code&gt;bmtools/tools/{tool_name}/api.py&lt;/code&gt; and a &lt;code&gt;__init__.py&lt;/code&gt; to the folder: &lt;code&gt;bmtools/tools/{tool_name}/__init__.py&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Register the tool in the &lt;code&gt;__init__.py&lt;/code&gt; file you created in step 3 using the code in section 3.1&lt;/li&gt; &#xA; &lt;li&gt;Import your tool in the &lt;code&gt;__init__.py&lt;/code&gt; file under bmtools/tools&lt;/li&gt; &#xA; &lt;li&gt;Add a &lt;code&gt;test.py&lt;/code&gt; to test your tool automatically&lt;/li&gt; &#xA; &lt;li&gt;Add a &lt;code&gt;readme.md&lt;/code&gt; in your folder containing a brief introduction, contributor information, or anything you want to let others know.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;4. Optimize your tool&#39;s prompt&lt;/h2&gt; &#xA;&lt;p&gt;The functions you wrote will be converted into an interface compatible with the OpenAI plugin. The AI models will read the name, description of the tools, as well as the name and descriptions of the tools&#39; APIs. You can adjust the following aspect to make your API better understood by AI models.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;(1) &lt;code&gt;name_for_model&lt;/code&gt; (tell the model what the tool is)&lt;/li&gt; &#xA; &lt;li&gt;(2) &lt;code&gt;description_for_model&lt;/code&gt; (this will be displayed to the model before the tool is called, and you can include information on how to use the APIs)&lt;/li&gt; &#xA; &lt;li&gt;(3) The function name for each API function, as well as the name in &lt;code&gt;@tool.get()&lt;/code&gt;. It&#39;s best if these two names match, as the name plays an important role in the model&#39;s API selection.&lt;/li&gt; &#xA; &lt;li&gt;(4) The function&#39;s doc string (can suggest to the model whether to use this API or not)&lt;/li&gt; &#xA; &lt;li&gt;(5) The function&#39;s return value, which can provide the model with error messages to guide its next steps, such as retrying or indicating a preferred next step&lt;/li&gt; &#xA; &lt;li&gt;(6) Reduce the errors in your API function.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;A simple example to refer to is the &lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/BMTools/main/bmtools/tools/wolframalpha/&#34;&gt;Wolfram Alpha API&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you use BMTools in your research, please cite:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{qin2023tool,&#xA;      title={Tool Learning with Foundation Models}, &#xA;      author={Yujia Qin and Shengding Hu and Yankai Lin and Weize Chen and Ning Ding and Ganqu Cui and Zheni Zeng and Yufei Huang and Chaojun Xiao and Chi Han and Yi Ren Fung and Yusheng Su and Huadong Wang and Cheng Qian and Runchu Tian and Kunlun Zhu and Shihao Liang and Xingyu Shen and Bokai Xu and Zhen Zhang and Yining Ye and Bowen Li and Ziwei Tang and Jing Yi and Yuzhang Zhu and Zhenning Dai and Lan Yan and Xin Cong and Yaxi Lu and Weilin Zhao and Yuxiang Huang and Junxi Yan and Xu Han and Xian Sun and Dahai Li and Jason Phang and Cheng Yang and Tongshuang Wu and Heng Ji and Zhiyuan Liu and Maosong Sun},&#xA;      year={2023},&#xA;      eprint={2304.08354},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CL}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>xtekky/chatgpt-clone</title>
    <updated>2023-04-26T01:41:38Z</updated>
    <id>tag:github.com,2023-04-26:/xtekky/chatgpt-clone</id>
    <link href="https://github.com/xtekky/chatgpt-clone" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ChatGPT interface with better UI&lt;/p&gt;&lt;hr&gt;&lt;p&gt;working again ; ) I am very busy at the moment so I would be very thankful for contributions and PR&#39;s&lt;/p&gt; &#xA;&lt;h2&gt;To do&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[&amp;nbsp;] Double confirm when deleting conversation&lt;/li&gt; &#xA; &lt;li&gt;[&amp;nbsp;] loading / exporting a conversation&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; remember user preferences&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; theme changer&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; speech output and input (elevenlabs; ex: &lt;a href=&#34;https://github.com/cogentapps/chat-with-gpt&#34;&gt;https://github.com/cogentapps/chat-with-gpt&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; load files, ex: &lt;a href=&#34;https://github.com/mayooear/gpt4-pdf-chatbot-langchain&#34;&gt;https://github.com/mayooear/gpt4-pdf-chatbot-langchain&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; better documentation and cross-platfotm (docker for ex)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; use react / faster backend language ? (newbies may be more confused and discouraged to use it)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;ChatGPT Clone&lt;/h1&gt; &#xA;&lt;p&gt;feel free to improve the code / suggest improvements&lt;/p&gt; &#xA;&lt;img width=&#34;1470&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/98614666/232768610-fdeada85-3d21-4cf9-915e-a0ec9f3b7a9f.png&#34;&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To get started with this project, you&#39;ll need to clone the repository and set up a virtual environment. This will allow you to install the required dependencies without affecting your system-wide Python installation.&lt;/p&gt; &#xA;&lt;h3&gt;Prequisites&lt;/h3&gt; &#xA;&lt;p&gt;Before you can set up a virtual environment, you&#39;ll need to have Python installed on your system. You can download Python from the official website: &lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;https://www.python.org/downloads/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Cloning the Repository&lt;/h3&gt; &#xA;&lt;p&gt;Run the following command to clone the repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/xtekky/chatgpt-clone.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Setting up a Virtual Environment&lt;/h3&gt; &#xA;&lt;p&gt;To set up a virtual environment, follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Navigate to the root directory of your project.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd chatgpt-clone&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Run the following command to create a new virtual environment:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m venv venv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Activate the virtual environment by running the following command:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;source venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you&#39;re on Windows, the command will be slightly different:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;venv\Scripts\activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Install the required dependencies by running the following command:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running the Application&lt;/h3&gt; &#xA;&lt;p&gt;To run the application, make sure the virtual environment is active and run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python run.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;The easiest way to run ChatGPT Clone is by using docker&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker-compose up&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>