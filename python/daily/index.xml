<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-08T01:44:09Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>WPeace-HcH/WPeChatGPT</title>
    <updated>2023-03-08T01:44:09Z</updated>
    <id>tag:github.com,2023-03-08:/WPeace-HcH/WPeChatGPT</id>
    <link href="https://github.com/WPeace-HcH/WPeChatGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A plugin for IDA that can help to analyze binary file and it uses OpenAI&#39;s ChatGPT training API.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;WPeChatGPT&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;A plugin for IDA&lt;/strong&gt; that can help to analyze binary file, it based on Gepetto which uses OpenAI&#39;s davinci-003 model.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;当前 &lt;em&gt;WPeChatGPT&lt;/em&gt; 支持的&lt;strong&gt;功能&lt;/strong&gt;包括：&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;分析函数的使用环境、预期目的、函数功能。&lt;/li&gt; &#xA;   &lt;li&gt;重命名函数的变量。&lt;/li&gt; &#xA;   &lt;li&gt;尝试用 python3 对函数进行还原，此功能主要是针对较小块的函数（如一个异或解密函数）。&lt;/li&gt; &#xA;   &lt;li&gt;在当前函数中查找是否存在漏洞。&lt;/li&gt; &#xA;   &lt;li&gt;尝试用 python 对漏洞函数生成对应的 EXP。&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;WPeChatGPT&lt;/em&gt; 插件使用的是 OpenAI 基于GPT训练的 &lt;strong&gt;text-davinci-003&lt;/strong&gt; 模型。&lt;br&gt; &lt;em&gt;v2.0&lt;/em&gt; 版本后使用 OpenAI 最新的 &lt;strong&gt;gpt-3.5-turbo&lt;/strong&gt; 模型（The same as &lt;strong&gt;ChatGPT&lt;/strong&gt;）。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;ChatGPT 的分析结果&lt;strong&gt;仅供参考&lt;/strong&gt;，不然我们这些分析师就当场失业了。XD&lt;/p&gt; &#xA;&lt;h2&gt;更新历史&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Version&lt;/th&gt; &#xA;   &lt;th&gt;Date&lt;/th&gt; &#xA;   &lt;th&gt;Comment&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.0&lt;/td&gt; &#xA;   &lt;td&gt;2023-02-28&lt;/td&gt; &#xA;   &lt;td&gt;Based on Gepetto.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.1&lt;/td&gt; &#xA;   &lt;td&gt;2023-03-02&lt;/td&gt; &#xA;   &lt;td&gt;1. 删除分析加解密的功能。&lt;br&gt;2. 增加 python 还原函数的功能。&lt;br&gt;3. 修改了一些细节。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.2&lt;/td&gt; &#xA;   &lt;td&gt;2023-03-03&lt;/td&gt; &#xA;   &lt;td&gt;1. 增加查找函数中二进制漏洞的功能。&lt;br&gt;2. 增加尝试自动生成对应 EXP 的功能。&lt;br&gt;3. 修改了一些细节。&lt;br&gt;（由于OpenAI服务器卡顿原因未测试上传）&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.0&lt;/td&gt; &#xA;   &lt;td&gt;2023-03-06&lt;/td&gt; &#xA;   &lt;td&gt;1. 完成测试 &lt;em&gt;v1.2&lt;/em&gt; 版本漏洞相关功能。&lt;br&gt;2. 改用 OpenAI 最新发布的 &lt;strong&gt;gpt-3.5-turbo&lt;/strong&gt; 模型。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.1&lt;/td&gt; &#xA;   &lt;td&gt;2023-03-07&lt;/td&gt; &#xA;   &lt;td&gt;Fix API problem about timed out.（详见节&lt;em&gt;&lt;strong&gt;关于 OpenAI-API 报错&lt;/strong&gt;&lt;/em&gt;）&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;安装&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;运行如下命令安装所需包。&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r ./requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;修改脚本 &lt;code&gt;WPeChatGPT.py&lt;/code&gt; 添加 API key 到变量 &lt;em&gt;&lt;strong&gt;openai.api_key&lt;/strong&gt;&lt;/em&gt;。&lt;/li&gt; &#xA; &lt;li&gt;复制脚本文件 &lt;code&gt;WPeChatGPT.py&lt;/code&gt; 到 IDA 的 plugins 文件夹, 最后重启 IDA 后即可使用。&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;! NOTE&lt;/code&gt;&lt;/strong&gt;：需要把 &lt;strong&gt;IDA 的环境&lt;/strong&gt;设置为 &lt;strong&gt;python3&lt;/strong&gt;，WPeChatGPT &lt;em&gt;2.0&lt;/em&gt; 版本后需要使用&lt;strong&gt;最新的 OpenAI Python 包&lt;/strong&gt;。&lt;/p&gt; &#xA;&lt;h2&gt;使用方法&lt;/h2&gt; &#xA;&lt;p&gt;支持在 IDA 中使用&lt;strong&gt;右键、菜单栏或快捷键&lt;/strong&gt;任一。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;快捷键：&lt;br&gt; &lt;code&gt;函数分析 = &#34;Ctrl-Alt-G&#34;&lt;/code&gt;&lt;br&gt; &lt;code&gt;重命名函数变量 = &#34;Ctrl-Alt-R&#34;&lt;/code&gt;&lt;br&gt; &lt;code&gt;二进制漏洞查找 = &#34;Ctrl-Alt-E&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;伪代码窗口右键：&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;  &lt;img src=&#34;https://github.com/WPeace-HcH/WPeChatGPT/raw/main/IMG/menuInPseudocode.png&#34; width=&#34;788&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;菜单栏：Edit $\Rightarrow$ WPeChatGPT&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;  &lt;img src=&#34;https://github.com/WPeace-HcH/WPeChatGPT/raw/main/IMG/menuInEdit.png&#34; width=&#34;360&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;示例&lt;/h2&gt; &#xA;&lt;p&gt;使用方式：&lt;/p&gt; &#xA;&lt;p&gt;  &lt;img src=&#34;https://github.com/WPeace-HcH/WPeChatGPT/raw/main/IMG/useExample.gif&#34; width=&#34;790&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;函数分析效果展示：&lt;/p&gt; &#xA;&lt;p&gt;  &lt;img src=&#34;https://github.com/WPeace-HcH/WPeChatGPT/raw/main/IMG/resultExample.gif&#34; width=&#34;790&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;二进制漏洞查找效果展示：&lt;/p&gt; &#xA;&lt;p&gt;  &lt;img src=&#34;https://github.com/WPeace-HcH/WPeChatGPT/raw/main/IMG/vulnExample.gif&#34; width=&#34;790&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;关于 OpenAI-API 报错&lt;/h2&gt; &#xA;&lt;p&gt;  从 2023.3.2 开始我经常遇到 API 报错，开始以为是服务器不稳定的问题（因为在我这里时好时坏），但是由于有太多反馈说都遇到了相关错误，所以我先去了 OpenAI 查看 API Status 之后发现其运行情况良好，因此发现可能并不是我所想的服务器问题，于是进行了相关问题的搜索及调试，以下是我对 OpenAI API 连接问题的处理方法：&lt;/p&gt; &#xA;&lt;p&gt;  首先前提，插件已经在&lt;strong&gt;科学上网&lt;/strong&gt;的条件下运行。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;在科学上网的条件下，如果发现插件多次尝试都无法正常连接 API，那么需要查询一下 python 的 urllib3 版本（1.26 版本存在代理问题）。 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;可以使用如下命令对 urllib3 进行回退修复：&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code&gt;pip uninstall urllib3&#xA;pip install urllib3==1.25.11&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;如果 urllib3 版本没错或重装 1.25 版本还是存在 API 访问问题的话，那么请下载最新版本，对插件指定代理： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;将下面三行代码取消注释，然后把代理地址及端口信息填入 &lt;em&gt;&lt;strong&gt;proxies&lt;/strong&gt;&lt;/em&gt; 变量即可：&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code&gt;#print(&#34;WPeChatGPT has appointed the proxy.&#34;)&#xA;#proxies = {&#39;http&#39;: &#34;http://127.0.0.1:7890&#34;, &#39;https&#39;: &#34;http://127.0.0.1:7890&#34;}&#xA;#openai.proxy = proxies&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;联系我&lt;/h2&gt; &#xA;&lt;p&gt;如果使用插件时遇到问题或有任何疑问，欢迎留言或发送邮件联系我。&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;The project is based on &lt;em&gt;Gepetto&lt;/em&gt; and inspired by it, you can visit &lt;a href=&#34;https://github.com/JusticeRage/Gepetto&#34;&gt;https://github.com/JusticeRage/Gepetto&lt;/a&gt; to learn about the original method.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>QiuChenly/QQFlacMusicDownloader</title>
    <updated>2023-03-08T01:44:09Z</updated>
    <id>tag:github.com,2023-03-08:/QiuChenly/QQFlacMusicDownloader</id>
    <link href="https://github.com/QiuChenly/QQFlacMusicDownloader" rel="alternate"></link>
    <summary type="html">&lt;p&gt;[秋城落叶] QQ 音乐源无损歌曲下载&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;项目介绍&lt;/h1&gt; &#xA;&lt;p&gt;Create &amp;amp; Design By QiuChenly.&lt;/p&gt; &#xA;&lt;p&gt;这是一个批量下载 QQ 音乐/酷我音乐/网易云会员无损音质歌曲的脚本,技术含量并不是很大,仅供参考。&lt;/p&gt; &#xA;&lt;p&gt;提示：由于QQ音乐接口访问频率限制 有时候歌曲获取不到 多刷新几次就好了&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;前端技术: Vue3+TS+Pinia+ElementUI Plus&#xA;&#xA;后端技术: Python3.9 + Flask + Concurrency协程&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;使用方法&lt;/h1&gt; &#xA;&lt;h3&gt;如果你需要生成 requirements.txt 文件&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install pipreqs # 安装&#xA;pipreqs ./ --encoding=utf8 --force # 在文件夹中执行&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;1. 安装环境&lt;/h3&gt; &#xA;&lt;p&gt;首先安装最新的 python3 到你的操作系统里。&lt;/p&gt; &#xA;&lt;p&gt;以下所有操作皆默认假设当前目录在(Windows) D:/Downloads/QQFlacDownloader/ 或者(Unix/Linux) ~/Download/QQFlacDownloader/&lt;/p&gt; &#xA;&lt;p&gt;如果安装依赖包出现 404 错误或者太慢，可以用下面的代码切换到清华大学服务器安装。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 设置python的依赖安装镜像服务器为清华大学服务器&#xA;# &#xA;pip3 config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip3 install -r requirements.txt # 安装软件依赖必须包&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. 进入软件包目录下启动软件&lt;/h3&gt; &#xA;&lt;p&gt;终端/控制台 进入到本文件所在的目录 执行以下指令:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 MainServer.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;启动后应该能看到这些信息，即表示你启动成功。 &lt;img src=&#34;https://raw.githubusercontent.com/QiuChenly/QQFlacMusicDownloader/main/img_1.png&#34; alt=&#34;img_1.png&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;然后google chrome之类的浏览器打开&lt;a href=&#34;http://127.0.0.1:8899&#34;&gt;http://127.0.0.1:8899&lt;/a&gt;即可打开新世界&lt;/p&gt; &#xA;&lt;h1&gt;新特性&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;功能&lt;/th&gt; &#xA;   &lt;th&gt;状态&lt;/th&gt; &#xA;   &lt;th&gt;附加说明&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;网易云会员歌曲解析下载&lt;/td&gt; &#xA;   &lt;td&gt;已完成&lt;/td&gt; &#xA;   &lt;td&gt;版权问题灰色歌曲没有CDN资源缓存 无法下载&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;酷我音乐无损音质下载&lt;/td&gt; &#xA;   &lt;td&gt;已完成&lt;/td&gt; &#xA;   &lt;td&gt;部分没有flac音质版本的歌曲可能无法下载&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;QQ音乐无损会员/高解析度无损下载&lt;/td&gt; &#xA;   &lt;td&gt;已完成&lt;/td&gt; &#xA;   &lt;td&gt;第三方服务器好像已经挂了 估计这个服务器qq被封了 暂时用不了 搜索不到歌曲的话多搜索几次或者换酷我接口&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;基于web的友好界面出来啦&lt;/p&gt; &#xA;&lt;h2&gt;&lt;img src=&#34;https://raw.githubusercontent.com/QiuChenly/QQFlacMusicDownloader/main/md/media/img_2.png&#34; alt=&#34;img_2.png&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/QiuChenly/QQFlacMusicDownloader/main/md/media/img_3.png&#34; alt=&#34;img_3.png&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/QiuChenly/QQFlacMusicDownloader/main/md/media/img_1.png&#34; alt=&#34;img_1.png&#34;&gt;&lt;/h2&gt; &#xA;&lt;h1&gt;声明&lt;/h1&gt; &#xA;&lt;p&gt;本代码 GPLV3 授权使用，禁止商业用途，仅供研究学习 python 技术使用，不得使用本代码进行任何形式的牟利/贩卖/传播，禁止在 qq 群传播，本项目仅供个人私下研究学习使用，请支持 QQ 正版音乐！&lt;/p&gt; &#xA;&lt;p&gt;下载的音乐文件在试听后请在 24 小时内删除，谢谢！ 仅限在中国大陆的宪法许可情况下使用，用户造成的一切法律责任与后果都由您自己独自承担，作者概不负责！&lt;/p&gt; &#xA;&lt;p&gt;本项目仅限研究交流学习使用。&lt;/p&gt; &#xA;&lt;h1&gt;其他资料&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/QiuChenly/QQFlacMusicDownloader/main/md/README.md&#34;&gt;早期接口 QMD Apk的逆向过程&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>gligen/GLIGEN</title>
    <updated>2023-03-08T01:44:09Z</updated>
    <id>tag:github.com,2023-03-08:/gligen/GLIGEN</id>
    <link href="https://github.com/gligen/GLIGEN" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Open-Set Grounded Text-to-Image Generation&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GLIGEN: Open-Set Grounded Text-to-Image Generation (CVPR 2023)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://yuheng-li.github.io/&#34;&gt;Yuheng Li&lt;/a&gt;, &lt;a href=&#34;https://hliu.cc&#34;&gt;Haotian Liu&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.ca/citations?user=HDiw-TsAAAAJ&amp;amp;hl=en/&#34;&gt;Qingyang Wu&lt;/a&gt;, &lt;a href=&#34;https://pages.cs.wisc.edu/~fmu/&#34;&gt;Fangzhou Mu&lt;/a&gt;, &lt;a href=&#34;https://jwyang.github.io/&#34;&gt;Jianwei Yang&lt;/a&gt;, &lt;a href=&#34;https://www.microsoft.com/en-us/research/people/jfgao/&#34;&gt;Jianfeng Gao&lt;/a&gt;, &lt;a href=&#34;https://chunyuan.li/&#34;&gt;Chunyuan Li*&lt;/a&gt;, &lt;a href=&#34;https://pages.cs.wisc.edu/~yongjaelee/&#34;&gt;Yong Jae Lee*&lt;/a&gt; (*Co-senior authors)&lt;/p&gt; &#xA;&lt;p&gt;[&lt;a href=&#34;https://gligen.github.io/&#34;&gt;Project Page&lt;/a&gt;] [&lt;a href=&#34;https://arxiv.org/abs/2301.07093&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/spaces/gligen/demo&#34;&gt;Demo&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/-MCkU7IAGKs&#34;&gt;YouTube Video&lt;/a&gt;] &lt;img src=&#34;https://raw.githubusercontent.com/gligen/GLIGEN/master/figures/concept.gif&#34; alt=&#34;Teaser figure&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/-MCkU7IAGKs&#34;&gt;&lt;img src=&#34;https://github.com/gligen/GLIGEN/raw/master/figures/teaser_v4.png&#34; alt=&#34;IMAGE ALT TEXT HERE&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Go beyond text prompt with GLIGEN: enable new capabilities on frozen text-to-image generation models to ground on various prompts, including box, keypoints and images.&lt;/li&gt; &#xA; &lt;li&gt;GLIGEN’s zero-shot performance on COCO and LVIS outperforms that of existing supervised layout-to-image baselines by a large margin.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;span&gt;🔥&lt;/span&gt; News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.03.05]&lt;/strong&gt; Gradio demo code is released at &lt;a href=&#34;https://github.com/gligen/GLIGEN/tree/master/demo&#34;&gt;&lt;code&gt;GLIGEN/demo&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.03.03]&lt;/strong&gt; Code base and checkpoints are released.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.02.28]&lt;/strong&gt; Paper is accepted to CVPR 2023.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.01.17]&lt;/strong&gt; GLIGEN paper and demo is released.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;We provide &lt;a href=&#34;https://raw.githubusercontent.com/gligen/GLIGEN/master/env_docker/Dockerfile&#34;&gt;dockerfile&lt;/a&gt; to setup environment.&lt;/p&gt; &#xA;&lt;h2&gt;Download GLIGEN models&lt;/h2&gt; &#xA;&lt;p&gt;We provide five checkpoints for different use scenarios. All models here are based on SD-V-1.4.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Mode&lt;/th&gt; &#xA;   &lt;th&gt;Modality&lt;/th&gt; &#xA;   &lt;th&gt;Download&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Generation&lt;/td&gt; &#xA;   &lt;td&gt;Box+Text&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/gligen/gligen-generation-text-box/blob/main/diffusion_pytorch_model.bin&#34;&gt;HF Hub&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Generation&lt;/td&gt; &#xA;   &lt;td&gt;Box+Text+Image&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/gligen/gligen-generation-text-image-box/blob/main/diffusion_pytorch_model.bin&#34;&gt;HF Hub&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Generation&lt;/td&gt; &#xA;   &lt;td&gt;Keypoint&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/gligen/gligen-generation-keypoint/blob/main/diffusion_pytorch_model.bin&#34;&gt;HF Hub&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Inpainting&lt;/td&gt; &#xA;   &lt;td&gt;Box+Text&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/gligen/gligen-inpainting-text-box/blob/main/diffusion_pytorch_model.bin&#34;&gt;HF Hub&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Inpainting&lt;/td&gt; &#xA;   &lt;td&gt;Box+Text+Image&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/gligen/gligen-inpainting-text-image-box/blob/main/diffusion_pytorch_model.bin&#34;&gt;HF Hub&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Inference: Generate images with GLIGEN&lt;/h2&gt; &#xA;&lt;p&gt;We provide one script to generate images using provided checkpoints. First download models and put them in &lt;code&gt;gligen_checkpoints&lt;/code&gt;. Then run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python gligen_inference.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example samples for each checkpoint will be saved in &lt;code&gt;generation_samples&lt;/code&gt;. One can check &lt;code&gt;gligen_inference.py&lt;/code&gt; for more details about interface.&lt;/p&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;h3&gt;Grounded generation training&lt;/h3&gt; &#xA;&lt;p&gt;One need to first prepare data for different grounding modality conditions. Refer &lt;a href=&#34;https://raw.githubusercontent.com/gligen/GLIGEN/master/DATA/README.MD&#34;&gt;data&lt;/a&gt; for the data we used for different GLIGEN models. Once data is ready, the following command is used to train GLIGEN. (We support multi-GPUs training)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ptyhon main.py --name=your_experiment_name  --yaml_file=path_to_your_yaml_config&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;--yaml_file&lt;/code&gt; is the most important argument and below we will use one example to explain key components so that one can be familiar with our code and know how to customize training on their own grounding modalities. The other args are self-explanatory by their names. The experiment will be saved in &lt;code&gt;OUTPUT_ROOT/name&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;One can refer &lt;code&gt;configs/flicker_text.yaml&lt;/code&gt; as one example. One can see that there are 5 components defining this yaml: &lt;strong&gt;diffusion&lt;/strong&gt;, &lt;strong&gt;model&lt;/strong&gt;, &lt;strong&gt;autoencoder&lt;/strong&gt;, &lt;strong&gt;text_encoder&lt;/strong&gt;, &lt;strong&gt;train_dataset_names&lt;/strong&gt; and &lt;strong&gt;grounding_tokenizer_input&lt;/strong&gt;. Typecially, &lt;strong&gt;diffusion&lt;/strong&gt;, &lt;strong&gt;autoencoder&lt;/strong&gt; and &lt;strong&gt;text_encoder&lt;/strong&gt; should not be changed as they are defined by Stable Diffusion. One should pay attention to following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Within &lt;strong&gt;model&lt;/strong&gt; we add new argument &lt;strong&gt;grounding_tokenizer&lt;/strong&gt; which defines a network producing grounding tokens. This network will be instantized in the model. One can refer to &lt;code&gt;ldm/modules/diffusionmodules/grounding_net_example.py&lt;/code&gt; for more details about defining this network.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;grounding_tokenizer_input&lt;/strong&gt; will define a network taking in batch data from dataloader and produce input for the grounding_tokenizer. In other words, it is an intermediante class between dataloader and grounding_tokenizer. One can refer &lt;code&gt;grounding_input/__init__.py&lt;/code&gt; for details about defining this class.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;train_dataset_names&lt;/strong&gt; should be listing a serial of names of datasets (all datasets will be concatenated internally, thus it is useful to combine datasets for training). Each dataset name should be first registered in &lt;code&gt;dataset/catalog.py&lt;/code&gt;. We have listed all dataset we used; if one needs to train GLIGEN on their own modality dataset, please don&#39;t forget first list its name there.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Grounded inpainting training&lt;/h3&gt; &#xA;&lt;p&gt;GLIGEN also supports inpainting training. The following command can be used:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ptyhon main.py --name=your_experiment_name  --yaml_file=path_to_your_yaml_config --inpaint_mode=True  --ckpt=path_to_an_adapted_model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Typecially, we first train GLIGEN on generation task (e.g., text grounded generation) and this model has 4 channels for input conv (latent space of Stable Diffusion), then we modify the saved checkpoint to 9 channels with addition 5 channels initilized with 0. This continue training can lead to faster convergence and better results. path_to_an_adapted_model refers to this modified checkpoint, &lt;code&gt;convert_ckpt.py&lt;/code&gt; can be used for modifying checkpoint. &lt;strong&gt;NOTE:&lt;/strong&gt; yaml file is the same for generation and inpainting training, one only need to change &lt;code&gt;--inpaint_mode&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{li2023gligen,&#xA;  title={GLIGEN: Open-Set Grounded Text-to-Image Generation},&#xA;  author={Li, Yuheng and Liu, Haotian and Wu, Qingyang and Mu, Fangzhou and Yang, Jianwei and Gao, Jianfeng and Li, Chunyuan and Lee, Yong Jae},&#xA;  journal={CVPR},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;The original GLIGEN was partly implemented and trained during an internship at Microsoft. This repo re-implements GLIGEN in PyTorch with university GPUs after the internship. Despite the minor implementation differences, this repo aims to reproduce the results and observations in the paper for research purposes.&lt;/p&gt;</summary>
  </entry>
</feed>