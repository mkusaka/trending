<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-09-20T01:38:37Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>NExT-GPT/NExT-GPT</title>
    <updated>2023-09-20T01:38:37Z</updated>
    <id>tag:github.com,2023-09-20:/NExT-GPT/NExT-GPT</id>
    <link href="https://github.com/NExT-GPT/NExT-GPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Code and models for NExT-GPT: Any-to-Any Multimodal Large Language Model&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/code/nextgpt.png&#34; style=&#34;width: 5%&#34;&gt; NExT-GPT: Any-to-Any Multimodal LLM&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://chocowu.github.io/&#34;&gt;Shengqiong Wu&lt;/a&gt;, &lt;a href=&#34;http://haofei.vip/&#34;&gt;Hao Fei&lt;/a&gt;*, &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/#&#34;&gt;Leigang Qu&lt;/a&gt;, &lt;a href=&#34;https://jiwei0523.github.io/&#34;&gt;Wei Ji&lt;/a&gt;, and &lt;a href=&#34;https://www.chuatatseng.com/&#34;&gt;Tat-Seng Chua&lt;/a&gt;. (*Correspondence )&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.nextcenter.org/&#34;&gt;NExT++&lt;/a&gt;, School of Computing, National University of Singapore&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://next-gpt.github.io/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project-Page-Green&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/#&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Demo-Page-purple&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/pdf/2309.05519&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Paper-PDF-orange&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/License-BSD-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=aqw2SCWeWD0&#34;&gt;&lt;img src=&#34;https://badges.aleen42.com/src/youtube.svg?sanitize=true&#34; alt=&#34;YouTube&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repository hosts the code, data and model weight of &lt;strong&gt;NExT-GPT&lt;/strong&gt;, the first end-to-end MM-LLM that perceives input and generates output in arbitrary combinations (any-to-any) of text, image, video, and audio and beyond.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;🎉 News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; [2023.09.15] 🚀🚀 Release the code of NExT-GPT in version &lt;code&gt;7b_tiva_v0&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;👉 TODO&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Release checkpoints (projection layers).&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Release MosIT data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Updating NExT-GPT in more types&amp;amp;sizes of LLMs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Empowering NExT-GPT with more modalities of inputs&amp;amp;outputs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; ...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Example Demos&lt;/h2&gt; &#xA;&lt;p&gt;Here we showcase examples generated from NExT-GPT. For more examples, kindly visit the &lt;a href=&#34;https://next-gpt.github.io/&#34;&gt;webpage&lt;/a&gt;, or the online live &lt;a href=&#34;https://9f10951d8cbe53e698.gradio.live&#34;&gt;demo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/NExT-GPT/NExT-GPT/assets/18722770/0c2b3d88-a533-4899-ab44-65580fe54538&#34;&gt;https://github.com/NExT-GPT/NExT-GPT/assets/18722770/0c2b3d88-a533-4899-ab44-65580fe54538&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/NExT-GPT/NExT-GPT/assets/18722770/eb1319a6-38aa-4546-a96e-163207e7de93&#34;&gt;https://github.com/NExT-GPT/NExT-GPT/assets/18722770/eb1319a6-38aa-4546-a96e-163207e7de93&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/NExT-GPT/NExT-GPT/assets/18722770/36bec0ad-9bad-4bcf-bc37-92b028f1bc6a&#34;&gt;https://github.com/NExT-GPT/NExT-GPT/assets/18722770/36bec0ad-9bad-4bcf-bc37-92b028f1bc6a&lt;/a&gt;&lt;/p&gt; &#xA;&lt;span id=&#34;introduction&#34;&gt;&lt;/span&gt; &#xA;&lt;h2&gt;Brief Introduction&lt;/h2&gt; &#xA;&lt;p&gt;NExt-GPT is built on top of existing pre-trained LLM, multimodal encoder and SoTA diffusion models, with sufficient end-to-end instruction tuning.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;a target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/figures/framework.png&#34; alt=&#34;Video-LLaMA&#34; style=&#34;width: 90%; min-width: 200px; display: block; margin: auto;&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multimodal Encoding Stage.&lt;/strong&gt; Leveraging established encoders to encode inputs in various modalities, where these representations are projected into language-like representations comprehensible to the LLM through a projection layer.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;LLM Understanding and Reasoning Stage.&lt;/strong&gt; Harnessing an existing open-sourced LLM as the core to process input information for semantic understanding and reasoning. The LLM not only directly generates text tokens but also produces unique “modality signal” tokens that serve as instructions to dictate the decoding layers whether &amp;amp; what modal content to output correspondingly.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multimodal Generation Stage.&lt;/strong&gt; Receiving the multimodal signals with specific instructions from LLM (if any), the Transformer-based output projection layers map the signal token representations into the ones that are understandable to following multimodal decoders.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For more technical details, kindly refer to the &lt;a href=&#34;https://arxiv.org/pdf/2309.05519.pdf&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;span id=&#34;Usage&#34;&gt;&lt;/span&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;span id=&#34;all_catelogue&#34;&gt;&lt;/span&gt; &#xA;&lt;h3&gt;Table of Contents:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;#Code Structure&#34;&gt;1. Code Structure&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;#Environment Preparation&#34;&gt;2. Environment Preparation &lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;#Training on Your Own&#34;&gt;3. Training/Adapting NExt-GPT on Your Own&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;#Prepare Pre-trained Checkpoint&#34;&gt;3.1. Preparing Pre-trained Checkpoint&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;#Prepare Dataset&#34;&gt;3.2. Preparing Dataset &lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;#Precompute Embeddings&#34;&gt;3.3. Precomputing Embeddings&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;#Train NExT-GPT&#34;&gt;3.4. Training NExT-GPT&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;#Run NExT-GPT System&#34;&gt;4. Running NExT-GPT System&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;#Prepare checkpoints&#34;&gt;4.1. Preparing checkpoints&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;#Deploy Demo System&#34;&gt;4.2. Deploying Demo System&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;span id=&#34;Code Structure&#34;&gt;&lt;/span&gt; &#xA;&lt;h3&gt;1. Code Structure&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;├── figures&#xA;├── data&#xA;│   ├── T-X_pair_data  &#xA;│   │   ├── audiocap                      # text-autio pairs data&#xA;│   │   │   ├── audios                    # audio files&#xA;│   │   │   └── audiocap.json             # the audio captions&#xA;│   │   ├── cc3m                          # text-image paris data&#xA;│   │   │   ├── images                    # image files&#xA;│   │   │   └── cc3m.json                 # the image captions&#xA;│   │   └── webvid                        # text-video pairs data&#xA;│   │   │   ├── videos                    # video files&#xA;│   │   │   └── webvid.json               # the video captions&#xA;│   ├── IT_data                           # instruction data&#xA;│   │   ├── T+X-T_data                    # text+[image/audio/video] to text instruction data&#xA;│   │   │   ├── alpaca                    # textual instruction data&#xA;│   │   │   ├── llava                     # visual instruction data&#xA;│   │   ├── T-T+X                         # synthesized text to text+[image/audio/video] instruction data&#xA;│   │   └── MosIT                         # Modality-switching Instruction Tuning instruction data&#xA;├── code&#xA;│   ├── config&#xA;│   │   ├── base.yaml                     # the model configuration &#xA;│   │   ├── stage_1.yaml                  # enc-side alignment training configuration&#xA;│   │   ├── stage_2.yaml                  # dec-side alignment training configuration&#xA;│   │   └── stage_3.yaml                  # instruction-tuning configuration&#xA;│   ├── dsconfig&#xA;│   │   ├── stage_1.json                  # deepspeed configuration for enc-side alignment training&#xA;│   │   ├── stage_2.json                  # deepspeed configuration for dec-side alignment training&#xA;│   │   └── stage_3.json                  # deepspeed configuration for instruction-tuning training&#xA;│   ├── datast&#xA;│   │   ├── base_dataset.py&#xA;│   │   ├── cc3m_datast.py                # process and load text-image pair dataset&#xA;│   │   ├── audiocap_datast.py            # process and load text-audio pair dataset&#xA;│   │   ├── webvid_dataset.py             # process and load text-video pair dataset&#xA;│   │   └── instruction_dataset.py        # process and load instruction pair dataset&#xA;│   ├── model                     &#xA;│   │   ├── ImageBind                     # the code from ImageBind Model&#xA;│   │   ├── common&#xA;│   │   ├── anyToImageVideoAudio.py       # the main model file&#xA;│   │   ├── agent.py&#xA;│   │   ├── modeling_llama.py&#xA;│   │   ├── custom_ad.py                  # the audio diffusion &#xA;│   │   ├── custom_sd.py                  # the image diffusion&#xA;│   │   ├── custom_vd.py                  # the video diffusion&#xA;│   │   ├── layers.py                     # the output projection layers&#xA;│   │   └── ...  &#xA;│   ├── scripts&#xA;│   │   ├── train.sh                      # training NExT-GPT script&#xA;│   │   └── app.sh                        # deploying demo script&#xA;│   ├── header.py&#xA;│   ├── process_embeddings.py             # precompute the captions embeddings&#xA;│   ├── train.py                          # training&#xA;│   ├── inference.py                      # inference&#xA;│   ├── demo_app.py                       # deploy Gradio demonstration &#xA;│   └── ...&#xA;├── ckpt                           &#xA;│   ├── delta_ckpt                        # tunable NExT-GPT params&#xA;│   │   ├── nextgpt         &#xA;│   │   │   ├── 7b_tiva_v0                # the directory to save the log file&#xA;│   │   │   │   ├── log                   # the logs&#xA;│   └── ...       &#xA;│   ├── pretrained_ckpt                   # frozen params of pretrained modules&#xA;│   │   ├── imagebind_ckpt&#xA;│   │   │   ├──huge                       # version&#xA;│   │   │   │   └──imagebind_huge.pth&#xA;│   │   ├── vicuna_ckpt&#xA;│   │   │   ├── 7b_v0                     # version&#xA;│   │   │   │   ├── config.json&#xA;│   │   │   │   ├── pytorch_model-00001-of-00002.bin&#xA;│   │   │   │   ├── tokenizer.model&#xA;│   │   │   │   └── ...&#xA;├── LICENCE.md&#xA;├── README.md&#xA;└── requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;span id=&#34;Environment Preparation&#34;&gt;&lt;/span&gt; &#xA;&lt;h3&gt;2. Environment Preparation &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/#all_catelogue&#34;&gt;[Back to Top]&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Please first clone the repo and install the required environment, which can be done by running the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda env create -n nextgpt python=3.8&#xA;&#xA;conda activate nextgpt&#xA;&#xA;# CUDA 11.6&#xA;conda install pytorch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 pytorch-cuda=11.6 -c pytorch -c nvidia&#xA;&#xA;git clone https://github.com/NExT-GPT/NExT-GPT.git&#xA;cd NExT-GPT&#xA;&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;span id=&#34;Training on Your Own&#34;&gt;&lt;/span&gt; &#xA;&lt;h3&gt;3. Training/Adapting NExt-GPT on Your Own&lt;/h3&gt; &#xA;&lt;h4&gt;&lt;/h4&gt; &#xA;&lt;span id=&#34;Prepare Pre-trained Checkpoint&#34;&gt;&lt;/span&gt; &#xA;&lt;h4&gt;3.1. Preparing Pre-trained Checkpoint &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/#all_catelogue&#34;&gt;[Back to Top]&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;NExT-GPT is trained based on following excellent existing models. Please follow the instructions to prepare the checkpoints.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;ImageBind&lt;/code&gt; is the unified image/video/audio encoder. The pre-trained checkpoint can be downloaded from &lt;a href=&#34;https://dl.fbaipublicfiles.com/imagebind/imagebind_huge.pth&#34;&gt;here&lt;/a&gt; with version &lt;code&gt;huge&lt;/code&gt;. Afterward, put the &lt;code&gt;imagebind_huge.pth&lt;/code&gt; file at &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/ckpt/pretrained_ckpt/imagebind_ckpt/&#34;&gt;[./ckpt/pretrained_ckpt/imagebind_ckpt/huge]&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Vicuna&lt;/code&gt;: first prepare the LLaMA by following the instructions &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/ckpt/pretrained_ckpt/prepare_vicuna.md&#34;&gt;[here]&lt;/a&gt;. Then put the pre-trained model at &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/ckpt/pretrained_ckpt/vicuna_ckpt/&#34;&gt;[./ckpt/pretrained_ckpt/vicuna_ckpt/]&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Image Diffusion&lt;/code&gt; is used to generate images. NExT-GPT uses &lt;a href=&#34;https://huggingface.co/runwayml/stable-diffusion-v1-5&#34;&gt;Stable Diffusion&lt;/a&gt; with version &lt;code&gt; v1-5&lt;/code&gt;. (&lt;em&gt;will be automatically downloaded&lt;/em&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Audio Diffusion&lt;/code&gt; for producing audio content. NExT-GPT employs &lt;a href=&#34;https://github.com/haoheliu/AudioLDM&#34;&gt;AudioLDM&lt;/a&gt; with version &lt;code&gt;l-full&lt;/code&gt;. (&lt;em&gt;will be automatically downloaded&lt;/em&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Video Diffusion&lt;/code&gt; for the video generation. We employ &lt;a href=&#34;https://huggingface.co/cerspense/zeroscope_v2_576w&#34;&gt;ZeroScope&lt;/a&gt; with version &lt;code&gt;v2_576w&lt;/code&gt;. (&lt;em&gt;will be automatically downloaded&lt;/em&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;span id=&#34;Prepare Dataset&#34;&gt;&lt;/span&gt; &#xA;&lt;h4&gt;3.2. Preparing Dataset &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/#all_catelogue&#34;&gt;[Back to Top]&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;Please download the following datasets used for model training:&lt;/p&gt; &#xA;&lt;p&gt;A) T-X pairs data&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;CC3M&lt;/code&gt; of &lt;em&gt;&lt;strong&gt;text-image&lt;/strong&gt;&lt;/em&gt; pairs, please follow this instruction &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/T-X_pair_data/cc3m/prepare.md&#34;&gt;[here]&lt;/a&gt;. Then put the data at &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/T-X_pair_data/cc3m&#34;&gt;[./data/T-X_pair_data/cc3m]&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;WebVid&lt;/code&gt; of &lt;em&gt;&lt;strong&gt;text-video&lt;/strong&gt;&lt;/em&gt; pairs, see the &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/T-X_pair_data/webvid/prepare.md&#34;&gt;[instruction]&lt;/a&gt;. The file should be saved at &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/T-X_pair_data/webvid&#34;&gt;[./data/T-X_pair_data/webvid]&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;AudioCap&lt;/code&gt; of &lt;em&gt;&lt;strong&gt;text-audio&lt;/strong&gt;&lt;/em&gt; pairs, see the &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/T-X_pair_data/audiocap/prepare.md&#34;&gt;[instruction]&lt;/a&gt;. Save the data in &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/T-X_pair_data/audiocap&#34;&gt;[./data/T-X_pair_data/audiocap]&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;B) Instruction data&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;T+X-T&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;LLaVA&lt;/code&gt; of the &lt;em&gt;&lt;strong&gt;visual instruction data&lt;/strong&gt;&lt;/em&gt;, download it from &lt;a href=&#34;https://github.com/haotian-liu/LLaVA/raw/main/docs/Data.md&#34;&gt;here&lt;/a&gt;, and then put it at &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/IT_data/T+X-T_data/llava/&#34;&gt;[./data/IT_data/T+X-T_data/llava]&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;Alpaca&lt;/code&gt; of the &lt;em&gt;&lt;strong&gt;textual instruction data&lt;/strong&gt;&lt;/em&gt;, download it from &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;here&lt;/a&gt;, and then put it at &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/IT_data/T+X-T_data/alpaca/&#34;&gt;[./data/IT_data/T+X-T_data/alpaca/]&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;VideoChat&lt;/code&gt;, download the &lt;em&gt;&lt;strong&gt;video instruction data&lt;/strong&gt;&lt;/em&gt; &lt;a href=&#34;https://github.com/OpenGVLab/InternVideo/tree/main/Data/instruction_data&#34;&gt;here&lt;/a&gt;, and then put it at &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/IT_data/T+X-T_data/videochat/&#34;&gt;[./data/IT_data/T+X-T_data/videochat/]&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;T-X+T&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Run the following commands to construct the data. Please ensure the above &lt;code&gt;T+X-T&lt;/code&gt; datasets are prepared. Afterward, the &lt;code&gt;T-X+T&lt;/code&gt; file &lt;code&gt;instruction_data.json&lt;/code&gt; will be saved at &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/IT_data/T-T+X_data&#34;&gt;[./data/IT_data/T-T+X_data]&lt;/a&gt;. &lt;pre&gt;&lt;code class=&#34;language-angular2html&#34;&gt;cd ./code/dataset/&#xA;python instruction_dataset.py&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;MosIT&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Download the file from &lt;a href=&#34;&#34;&gt;here&lt;/a&gt;, put them in &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/IT_data/MosIT_data/&#34;&gt;[./data/IT_data/MosIT_data/]&lt;/a&gt;. (&lt;em&gt;We are in the process of finalizing the data and handling the copyright issue. Will release later.&lt;/em&gt;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;span id=&#34;Precompute Embeddings&#34;&gt;&lt;/span&gt; &#xA;&lt;h4&gt;3.3. Precomputing Embeddings &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/#all_catelogue&#34;&gt;[Back to Top]&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;In decoding-side alignment training, we minimize the distance between the representation of signal tokens and captions. To save costs of time and memory, we precompute the text embeddings for image, audio and video captions using the text encoder within the respective diffusion models.&lt;/p&gt; &#xA;&lt;p&gt;Please run this command before the following training of NExT-GPT, where the produced &lt;code&gt;embedding&lt;/code&gt; file will be saved at &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/embed&#34;&gt;[./data/embed]&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-angular2html&#34;&gt;cd ./code/&#xA;python process_embeddings.py ../data/T-X_pair_data/cc3m/cc3m.json image ../data/embed/ runwayml/stable-diffusion-v1-5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note of arguments:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;args[1]: path of caption file;&lt;/li&gt; &#xA; &lt;li&gt;args[2]: modality, which can be &lt;code&gt;image&lt;/code&gt;, &lt;code&gt;video&lt;/code&gt;, and &lt;code&gt;audio&lt;/code&gt;;&lt;/li&gt; &#xA; &lt;li&gt;args[3]: saving path of embedding file;&lt;/li&gt; &#xA; &lt;li&gt;args[4]: corresponding pre-trained diffusion model name.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;span id=&#34;Train NExT-GPT&#34;&gt;&lt;/span&gt; &#xA;&lt;h4&gt;3.4. Training NExT-GPT &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/#all_catelogue&#34;&gt;[Back to Top]&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;First of all, please refer to the base configuration file &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/code/config/base.yaml&#34;&gt;[./code/config/base.yaml]&lt;/a&gt; for the basic system setting of overall modules.&lt;/p&gt; &#xA;&lt;p&gt;Then, the training of NExT-GPT starts with this script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-angular2html&#34;&gt;cd ./code&#xA;bash scripts/train.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Specifying the command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-angular2html&#34;&gt;deepspeed --include localhost:0 --master_addr 127.0.0.1 --master_port 28459 train.py \&#xA;    --model nextgpt \&#xA;    --stage 1\&#xA;    --dataset cc3m\&#xA;    --data_path  ../data/T-X_pair_data/cc3m/cc3m.json\&#xA;    --mm_root_path ../data/T-X_pair_data/cc3m/images/\&#xA;    --embed_path ../data/embed/\&#xA;    --save_path  ../ckpt/delta_ckpt/nextgpt/7b/\&#xA;    --log_path ../ckpt/delta_ckpt/nextgpt/7b/log/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where the key arguments are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--include&lt;/code&gt;: &lt;code&gt;localhost:0&lt;/code&gt; indicating the GPT cuda number &lt;code&gt;0&lt;/code&gt; of deepspeed.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--stage&lt;/code&gt;: training stage.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--dataset&lt;/code&gt;: the dataset name for training model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--data_path&lt;/code&gt;: the data path for the training file.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--mm_root_path&lt;/code&gt;: the data path for the image/video/audio file.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--embed_path&lt;/code&gt;: the data path for the text embedding file.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--save_path&lt;/code&gt;: the directory which saves the trained delta weights. This directory will be automatically created.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--log_path&lt;/code&gt;: the directory which saves the log file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The whole NExT-GPT training involves 3 steps:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Step-1&lt;/strong&gt;: Encoding-side LLM-centric Multimodal Alignment. This stage trains the &lt;em&gt;&lt;strong&gt;input projection layer&lt;/strong&gt;&lt;/em&gt; while freezing the ImageBind, LLM, output projection layer.&lt;/p&gt; &lt;p&gt;Just run the above &lt;code&gt;train.sh&lt;/code&gt; script by setting:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;--stage 1&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--dataset x&lt;/code&gt;, where &lt;code&gt;x&lt;/code&gt; varies from [&lt;code&gt;cc3m&lt;/code&gt;, &lt;code&gt;webvid&lt;/code&gt;, &lt;code&gt;audiocap&lt;/code&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--data_path ../.../xxx.json&lt;/code&gt;, where &lt;code&gt;xxx&lt;/code&gt; is the file name of the data in &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/T-X_pair_data&#34;&gt;[./data/T-X_pair_data]&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--mm_root_path .../.../x&lt;/code&gt;, &lt;code&gt;x&lt;/code&gt; varies from [&lt;code&gt;images&lt;/code&gt;, &lt;code&gt;audios&lt;/code&gt;, &lt;code&gt;videos&lt;/code&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;Also refer to the running config file &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/code/config/stage_1.yaml&#34;&gt;[./code/config/stage_1.yaml]&lt;/a&gt; and deepspeed config file &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/code/dsconfig/stage_1.yaml&#34;&gt;[./code/dsconfig/stage_1.yaml]&lt;/a&gt; for more step-wise configurations.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Step-2&lt;/strong&gt;: Decoding-side Instruction-following Alignment. This stage trains the &lt;em&gt;&lt;strong&gt;output projection layers&lt;/strong&gt;&lt;/em&gt; while freezing the ImageBind, LLM, input projection layers.&lt;/p&gt; &lt;p&gt;Just run the above &lt;code&gt;train.sh&lt;/code&gt; script by setting:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;--stage 2&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--dataset x&lt;/code&gt;, where &lt;code&gt;x&lt;/code&gt; varies from [&lt;code&gt;cc3m&lt;/code&gt;, &lt;code&gt;webvid&lt;/code&gt;, &lt;code&gt;audiocap&lt;/code&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--data_path ../.../xxx.json&lt;/code&gt;, where &lt;code&gt;xxx&lt;/code&gt; is the file name of the data in &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/T-X_pair_data&#34;&gt;[./data/T-X_pair_data]&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--mm_root_path .../.../x&lt;/code&gt;, &lt;code&gt;x&lt;/code&gt; varies from [&lt;code&gt;images&lt;/code&gt;, &lt;code&gt;audios&lt;/code&gt;, &lt;code&gt;videos&lt;/code&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;Also refer to the running config file &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/code/config/stage_2.yaml&#34;&gt;[./code/config/stage_2.yaml]&lt;/a&gt; and deepspeed config file &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/code/dsconfig/stage_2.yaml&#34;&gt;[./code/dsconfig/stage_2.yaml]&lt;/a&gt; for more step-wise configurations.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Step-3&lt;/strong&gt;: Instruction Tuning. This stage instruction-tune 1) the &lt;em&gt;&lt;strong&gt;LLM&lt;/strong&gt;&lt;/em&gt; via LoRA, 2) &lt;em&gt;&lt;strong&gt;input projection layer&lt;/strong&gt;&lt;/em&gt; and 3) &lt;em&gt;&lt;strong&gt;output projection layer&lt;/strong&gt;&lt;/em&gt; on the instruction dataset.&lt;/p&gt; &lt;p&gt;Just run the above &lt;code&gt;train.sh&lt;/code&gt; script by setting:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;--stage 3&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--dataset instruction&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--data_path ../.../xxx.json&lt;/code&gt;, where &lt;code&gt;xxx&lt;/code&gt; is the file name of the data in &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/IT_data/T+X-T_data&#34;&gt;[./data/IT_data/T+X-T_data]&lt;/a&gt; or data in &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/IT_data/T+X-T_data&#34;&gt;[./data/IT_data/T+X-T_data]&lt;/a&gt; or data in &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/data/IT_data/MosIT_data&#34;&gt;[./data/IT_data/MosIT_data]&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--mm_root_path .../.../x&lt;/code&gt;, &lt;code&gt;x&lt;/code&gt; varies from [&lt;code&gt;images&lt;/code&gt;, &lt;code&gt;audios&lt;/code&gt;, &lt;code&gt;videos&lt;/code&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;Also refer to the running config file &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/code/config/stage_3.yaml&#34;&gt;[./code/config/stage_3.yaml]&lt;/a&gt; and deepspeed config file &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/code/dsconfig/stage_3.yaml&#34;&gt;[./code/dsconfig/stage_3.yaml]&lt;/a&gt; for more step-wise configurations.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;span id=&#34;Run NExT-GPT System&#34;&gt;&lt;/span&gt; &#xA;&lt;h2&gt;4. Running NExT-GPT System &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/#all_catelogue&#34;&gt;[Back to Top]&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;span id=&#34;Prepare checkpoints&#34;&gt;&lt;/span&gt; &#xA;&lt;h4&gt;4.1. Preparing Checkpoints&lt;/h4&gt; &#xA;&lt;p&gt;First, loading the pre-trained NExT-GPT system.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Step-1&lt;/strong&gt;: load &lt;code&gt;Frozen parameters&lt;/code&gt;. Please refer to &lt;a href=&#34;#Prepare Pre-trained Checkpoint&#34;&gt;3.1 Preparing Pre-trained Checkpoint&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Step-2&lt;/strong&gt;: load &lt;code&gt;Tunable parameters&lt;/code&gt;. Please put the NExT-GPT system in &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/ckpt/delta_ckpt/nextgpt/7b_tiva_v0&#34;&gt;[./ckpt/delta_ckpt/nextgpt/7b_tiva_v0]&lt;/a&gt;. You may either 1) use the params trained yourselves, or 2) download our checkpoints from &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/#&#34;&gt;here&lt;/a&gt;. (&lt;em&gt;We are still working hard on optimizing the system, and will release the params shortly.&lt;/em&gt;)&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;span id=&#34;Deploy Demo System&#34;&gt;&lt;/span&gt; &#xA;&lt;h4&gt;4.2. Deploying Gradio Demo&lt;/h4&gt; &#xA;&lt;p&gt;Upon completion of the checkpoint loading, you can run the demo locally via:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-angular2html&#34;&gt;cd ./code&#xA;bash scripts/app.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Specifying the key arguments as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--nextgpt_ckpt_path&lt;/code&gt;: the path of pre-trained NExT-GPT params.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;For any questions or feedback, feel free to contact &lt;a href=&#34;mailto:swu@u.nus.edu&#34;&gt;Shengqiong Wu&lt;/a&gt; and &lt;a href=&#34;mailto:haofei37@nus.edu.sg&#34;&gt;Hao Fei&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find NextGPT useful in your research or applications, please kindly cite:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@articles{wu2023nextgpt,&#xA;  title={NExT-GPT: Any-to-Any Multimodal LLM},&#xA;  author={Shengqiong Wu and Hao Fei and Leigang Qu and Wei Ji and Tat-Seng Chua},&#xA;  journal = {CoRR},&#xA;  volume = {abs/2309.05519},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;You may refer to related work that serves as foundations for our framework and code repository, &lt;a href=&#34;https://github.com/lm-sys/FastChat&#34;&gt;Vicuna&lt;/a&gt;, &lt;a href=&#34;https://github.com/facebookresearch/ImageBind&#34;&gt;ImageBind&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img&#34;&gt;Stable Diffusion&lt;/a&gt;, &lt;a href=&#34;https://github.com/haoheliu/AudioLDM&#34;&gt;AudioLDM&lt;/a&gt;, and &lt;a href=&#34;https://huggingface.co/cerspense/zeroscope_v2_576w&#34;&gt;Zeroscope&lt;/a&gt;. We also partially draw inspirations from &lt;a href=&#34;https://github.com/yxuansu/PandaGPT&#34;&gt;PandaGPT&lt;/a&gt;, &lt;a href=&#34;https://vpgtrans.github.io/&#34;&gt;VPGTrans&lt;/a&gt;, &lt;a href=&#34;https://github.com/kohjingyu/gill/&#34;&gt;GILL&lt;/a&gt;, &lt;a href=&#34;https://codi-gen.github.io/&#34;&gt;CoDi&lt;/a&gt;, &lt;a href=&#34;https://github.com/DAMO-NLP-SG/Video-LLaMA&#34;&gt;Video-LLaMA&lt;/a&gt;, and &lt;a href=&#34;https://github.com/Vision-CAIR/MiniGPT-4&#34;&gt;MiniGPT-4&lt;/a&gt;. Thanks for their wonderful works.&lt;/p&gt; &#xA;&lt;h2&gt;License Notices&lt;/h2&gt; &#xA;&lt;p&gt;This repository is under &lt;a href=&#34;https://raw.githubusercontent.com/NExT-GPT/NExT-GPT/main/LICENSE.txt&#34;&gt;BSD 3-Clause License&lt;/a&gt;. NExT-GPT is a research project intended for non-commercial use only. One must NOT use the code of NExT-GPT for any illegal, harmful, violent, racist, or sexual purposes. One is strictly prohibited from engaging in any activity that will potentially violate these guidelines. Any potential commercial use of this code should be approved by the authors.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>rev1si0n/lamda</title>
    <updated>2023-09-20T01:38:37Z</updated>
    <id>tag:github.com,2023-09-20:/rev1si0n/lamda</id>
    <link href="https://github.com/rev1si0n/lamda" rel="alternate"></link>
    <summary type="html">&lt;p&gt;⚡️ Android reverse engineering &amp; automation framework | 史上最强安卓抓包/逆向/HOOK &amp; 云手机/远程桌面/自动化辅助框架，你的工作从未如此简单快捷。&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/image/logo.svg?sanitize=true&#34; alt=&#34;LAMDA&#34; width=&#34;256&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;Android reverse engineering &amp;amp; automation framework&lt;/p&gt; &#xA;&lt;p&gt;LAMDA 是一个用于逆向及自动化的辅助框架，它设计为减少安全分析以及应用测试人员的时间及琐碎问题，以编程化的接口替代大量手动操作，它并不是一个单一功能的框架。为了让你大概了解它的用处：你是否会在手机上安装各类代理、插件或者点来点去的设置来完成你的工作？你是否要在异地操作远在千里之外的手机？你是否有编程控制手机的需求？是否还在某些云手机厂商那里购买昂贵的&lt;strong&gt;IP切换&lt;/strong&gt;、&lt;strong&gt;远程ADB调试&lt;/strong&gt;、&lt;strong&gt;RPA自动化&lt;/strong&gt;甚至连 &lt;strong&gt;logcat 日志&lt;/strong&gt;都要付费的服务？如果有，那么对了，只需一个 LAMDA 即可解决这些问题。并且，LAMDA 更注重&lt;strong&gt;分布式&lt;/strong&gt;，事实上，你可以在一台公网服务器上管理散布在世界各地各种网络环境中的设备。当然，LAMDA 可以做到的不止于此。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;零依赖，只需 &lt;strong&gt;root&lt;/strong&gt; 即可&lt;/li&gt; &#xA; &lt;li&gt;前身通过超500台设备压力的稳定生产环境考验&lt;/li&gt; &#xA; &lt;li&gt;可通过扩展模块使用完整的安卓内 Debian (12, bookworm) 环境&lt;/li&gt; &#xA; &lt;li&gt;通过接口轻松设置根证书，配合 http/socks5 代理实现中间人&lt;/li&gt; &#xA; &lt;li&gt;通过 frida 暴露内部 Java 接口（类 &lt;a href=&#34;https://github.com/virjar/sekiro&#34;&gt;virjar/sekiro&lt;/a&gt; 但基于 frida）&lt;/li&gt; &#xA; &lt;li&gt;近乎商业级软件的质量和稳定性，ARM/X86全架构&lt;/li&gt; &#xA; &lt;li&gt;较高的安全性，支持接口及登录认证&lt;/li&gt; &#xA; &lt;li&gt;将你的设备变为移动网络代理&lt;/li&gt; &#xA; &lt;li&gt;部分兼容 uiautomator2&lt;/li&gt; &#xA; &lt;li&gt;设备状态/资源消耗读取&lt;/li&gt; &#xA; &lt;li&gt;系统配置/属性读取修改&lt;/li&gt; &#xA; &lt;li&gt;界面布局检视&lt;/li&gt; &#xA; &lt;li&gt;无线连接内置 root 权限的 WIFI ADB&lt;/li&gt; &#xA; &lt;li&gt;支持自定义启动配置&lt;/li&gt; &#xA; &lt;li&gt;支持模拟器及真机、云手机/无头开发板、Redroid&lt;/li&gt; &#xA; &lt;li&gt;支持安卓 6.0 (M, API 23) - 13 (T, API 33)&lt;/li&gt; &#xA; &lt;li&gt;支持 WSA (Windows Subsystem for Android™️)&lt;/li&gt; &#xA; &lt;li&gt;支持 UDP 协议代理（socks5 UDP 模式）&lt;/li&gt; &#xA; &lt;li&gt;支持 OpenVPN 与代理共存&lt;/li&gt; &#xA; &lt;li&gt;支持 Magisk 开机自启动&lt;/li&gt; &#xA; &lt;li&gt;封装了大量常用接口，只需要会写 Python&lt;/li&gt; &#xA; &lt;li&gt;完全网络化，脱离 USB 数据线/USB 集线器等实体&lt;/li&gt; &#xA; &lt;li&gt;大文件上传下载&lt;/li&gt; &#xA; &lt;li&gt;大大降低门槛以及闲杂琐事上的时间成本&lt;/li&gt; &#xA; &lt;li&gt;获取/重放系统中最近的 Activity&lt;/li&gt; &#xA; &lt;li&gt;唤起应用的 Activity&lt;/li&gt; &#xA; &lt;li&gt;可使用 ssh 登录设备终端&lt;/li&gt; &#xA; &lt;li&gt;只要有网即可连接任意地方运行了 LAMDA 的设备&lt;/li&gt; &#xA; &lt;li&gt;前后台运行 shell 命令，授予撤销应用权限等&lt;/li&gt; &#xA; &lt;li&gt;内置 Storage 用于存储设备变量&lt;/li&gt; &#xA; &lt;li&gt;内置 http/socks5 代理，可设置系统/指定应用的代理&lt;/li&gt; &#xA; &lt;li&gt;内置 frida 15.x, IDA 7.5 server 等工具&lt;/li&gt; &#xA; &lt;li&gt;内置 crontab 定时任务&lt;/li&gt; &#xA; &lt;li&gt;内置 Python3.9 及部分常用模块&lt;/li&gt; &#xA; &lt;li&gt;内置 OpenVPN 可实现全局/非全局的 VPN&lt;/li&gt; &#xA; &lt;li&gt;WIFI 远程桌面（web）&lt;/li&gt; &#xA; &lt;li&gt;WEB 端文件上传下载&lt;/li&gt; &#xA; &lt;li&gt;UI自动化，通过接口实现自动化操作&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;如果觉得以下教程过于复杂看不懂，可以选择观看 &lt;a href=&#34;https://lamda.run/tutorial/video&#34;&gt;视频教程&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/image/demo.gif&#34; alt=&#34;动图演示&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;一键中间人流量分析&lt;/h2&gt; &#xA;&lt;p&gt;支持常规以及国际APP流量分析，DNS流量分析，得益于 &lt;a href=&#34;https://docs.mitmproxy.org/stable/api/events.html&#34;&gt;mitmproxy flow hook&lt;/a&gt;，你可以对任何请求做到最大限度的掌控，mitmproxy 功能足够丰富，你可以使用 Python 脚本实时修改或者捕获应用的请求，也可以通过其 &lt;code&gt;Export&lt;/code&gt; 选项导出特定请求的 &lt;code&gt;curl&lt;/code&gt; 命令或者 &lt;code&gt;HTTPie&lt;/code&gt; 命令，分析重放、拦截修改、功能组合足以替代你用过的任何此类商业/非商业软件。如果你仍不清楚 mitmproxy 是什么以及其具有的能力，请务必先查找相关文档，因为 LAMDA 将会使用 mitmproxy 为你展现应用请求。&lt;/p&gt; &#xA;&lt;p&gt;通过 tools/ 目录下的 &lt;code&gt;globalmitm&lt;/code&gt;，&lt;code&gt;startmitm.py&lt;/code&gt; 实现，使用方法请看其同目录 README。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/image/mitm.gif&#34; alt=&#34;中间人流量分析动图演示&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;拖拽上传&lt;/h2&gt; &#xA;&lt;p&gt;可直接在远程桌面拖拽上传，支持上传整个目录，最大支持单个 256MB 的文件，文件将始终被上传到 &lt;code&gt;/data/usr/uploads&lt;/code&gt; 目录下。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/image/upload.gif&#34; alt=&#34;拖拽上传动图演示&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;远程桌面连接&lt;/h2&gt; &#xA;&lt;p&gt;即使手机不在身边也可以使用浏览器随时操作界面，并且内置了 Python 以及相关 frida 工具，是你的另一个在线 shell。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/image/lamda.gif&#34; alt=&#34;远程桌面动图演示&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;通过代码自动化&lt;/h2&gt; &#xA;&lt;p&gt;直接通过代码点点点，可以替代大部分手动操作。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/image/automation.gif&#34; alt=&#34;自动化动图演示&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;界面布局检视&lt;/h2&gt; &#xA;&lt;p&gt;可在远程桌面即时检视安卓应用的界面布局用以编写自动化代码，点击远程桌面右上角的眼睛图标即可进入模式， 按下 &lt;code&gt;CTRL + R&lt;/code&gt; 刷新布局，再次点击眼睛图标退出。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/image/inspect.gif&#34; alt=&#34;界面布局检视&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;设备目录索引&lt;/h2&gt; &#xA;&lt;p&gt;你可以在浏览器浏览设备上的文件，同时你也可以点击文件名来下载所需的文件。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/image/listing.gif&#34; alt=&#34;目录索引动图演示&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;如果你希望继续看下去，请确保：有一台已经 root 且运行内存大于 2GB，可用存储空间大于 1GB 的安卓设备或者安卓模拟器（推荐使用最新版&lt;strong&gt;夜神&lt;/strong&gt;，&lt;strong&gt;雷电&lt;/strong&gt;模拟器，或者 AVD [Android Studio Virtual Device]）。&lt;strong&gt;不完全支持&lt;/strong&gt; 网易 Mumu，&lt;strong&gt;不支持&lt;/strong&gt;腾讯手游助手、蓝叠以及安卓内虚拟如 VMOS 等），对于真机，推荐运行最接近原生系统的设备如谷歌系、一加、安卓开发板等，或系统仅经过轻度改造的设备。如果你使用的是OPPO/VIVO/华为/小米的设备，经过尝试后无法正常运行，建议改用模拟器。&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;目录&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E7%9B%AE%E5%BD%95&#34;&gt;目录&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%85%8D%E8%B4%A3%E5%A3%B0%E6%98%8E%E5%8F%8A%E6%9D%A1%E6%AC%BE&#34;&gt;免责声明及条款&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%89%8D%E8%A8%80&#34;&gt;前言&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%AE%89%E8%A3%85-lamda&#34;&gt;安装 LAMDA&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9&#34;&gt;注意事项&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%9F%BA%E7%A1%80%E8%A6%81%E6%B1%82&#34;&gt;基础要求&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E7%B3%BB%E7%BB%9F%E8%AE%BE%E7%BD%AE&#34;&gt;系统设置&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E7%BD%91%E7%BB%9C%E8%AE%BE%E7%BD%AE&#34;&gt;网络设置&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%85%B6%E4%BB%96%E8%AE%BE%E7%BD%AE&#34;&gt;其他设置&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%AE%89%E8%A3%85%E5%AE%A2%E6%88%B7%E7%AB%AF&#34;&gt;安装客户端&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%AE%89%E8%A3%85%E6%9C%8D%E5%8A%A1%E7%AB%AF&#34;&gt;安装服务端&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E9%80%9A%E8%BF%87-magisk-%E5%AE%89%E8%A3%85&#34;&gt;通过 Magisk 安装&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85&#34;&gt;手动安装&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%90%AF%E5%8A%A8%E6%9C%8D%E5%8A%A1%E7%AB%AF&#34;&gt;启动服务端&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E9%80%80%E5%87%BA%E6%9C%8D%E5%8A%A1%E7%AB%AF&#34;&gt;退出服务端&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%8D%B8%E8%BD%BD%E6%9C%8D%E5%8A%A1%E7%AB%AF&#34;&gt;卸载服务端&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E4%BD%BF%E7%94%A8-lamda&#34;&gt;使用 LAMDA&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2&#34;&gt;远程桌面&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0&#34;&gt;文件上传&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD&#34;&gt;文件下载&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E7%A7%BB%E5%8A%A8%E4%BB%A3%E7%90%86&#34;&gt;移动代理&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE&#34;&gt;自定义代理配置&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E8%BF%9E%E6%8E%A5%E8%AE%BE%E5%A4%87&#34;&gt;连接设备&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%85%88%E6%9D%A5%E4%B8%80%E4%B8%AA%E7%83%AD%E8%BA%AB&#34;&gt;先来一个热身&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E8%AE%BE%E7%BD%AE%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%90%86&#34;&gt;设置系统代理&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%AE%89%E8%A3%85%E4%B8%AD%E9%97%B4%E4%BA%BA%E8%AF%81%E4%B9%A6&#34;&gt;安装中间人证书&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E8%AE%BE%E7%BD%AE-openvpn&#34;&gt;设置 OpenVPN&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E8%BF%9E%E6%8E%A5%E5%86%85%E7%BD%AE%E7%9A%84-frida&#34;&gt;连接内置的 FRIDA&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E4%BD%BF%E7%94%A8-frida-%E6%9A%B4%E9%9C%B2-java-%E6%8E%A5%E5%8F%A3&#34;&gt;使用 FRIDA 暴露 Java 接口&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E4%BD%BF%E7%94%A8%E5%86%85%E7%BD%AE%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1&#34;&gt;使用内置的定时任务&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E4%BD%BF-lamda-%E5%8F%AF%E8%A2%AB%E4%BB%BB%E6%84%8F%E5%9C%B0%E7%82%B9%E8%BF%9E%E6%8E%A5&#34;&gt;使 LAMDA 可被任意地点连接&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E8%AF%BB%E5%86%99%E5%86%85%E7%BD%AE%E9%94%AE%E5%80%BC%E5%AD%98%E5%82%A8%E5%99%A8&#34;&gt;读写内置键值存储器&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E8%AF%BB%E5%86%99%E7%B3%BB%E7%BB%9F%E5%B1%9E%E6%80%A7&#34;&gt;读写系统属性&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E8%AF%BB%E5%86%99%E7%B3%BB%E7%BB%9F%E8%AE%BE%E7%BD%AE&#34;&gt;读写系统设置&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E8%8E%B7%E5%8F%96%E8%AE%BE%E5%A4%87%E8%BF%90%E8%A1%8C%E7%8A%B6%E6%80%81&#34;&gt;获取设备运行状态&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%9C%A8%E8%AE%BE%E5%A4%87%E4%B8%8A%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4&#34;&gt;在设备上执行命令&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E4%BD%BF%E7%B3%BB%E7%BB%9F%E5%8F%AF%E8%B0%83%E8%AF%95&#34;&gt;使系统可调试&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%90%AF%E5%8A%A8-ida-%E8%B0%83%E8%AF%95%E6%9C%8D%E5%8A%A1&#34;&gt;启动 IDA 调试服务&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E6%97%A0%E7%BA%BF%E8%BF%9E%E6%8E%A5%E5%86%85%E7%BD%AE%E7%9A%84-wifi-adb&#34;&gt;无线连接内置的 WIFI ADB&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C&#34;&gt;文件操作&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%85%B3%E6%9C%BA%E9%87%8D%E5%90%AF&#34;&gt;关机重启&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%BA%94%E7%94%A8%E6%93%8D%E4%BD%9C&#34;&gt;应用操作&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#wifi%E6%93%8D%E4%BD%9C&#34;&gt;WIFI操作&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%9F%BA%E6%9C%ACui%E6%93%8D%E4%BD%9C&#34;&gt;基本UI操作&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E8%BF%9B%E9%98%B6ui%E6%93%8D%E4%BD%9C&#34;&gt;进阶UI操作&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E6%8E%A5%E5%8F%A3%E9%94%81&#34;&gt;接口锁&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E4%BD%BF%E7%94%A8%E5%86%85%E7%BD%AE%E7%BB%88%E7%AB%AF&#34;&gt;使用内置终端&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E4%BD%BF%E7%94%A8-debian-%E7%8E%AF%E5%A2%83%E6%89%A9%E5%B1%95%E6%A8%A1%E5%9D%97&#34;&gt;使用 Debian 环境扩展模块&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%95%99%E7%A8%8B&#34;&gt;工具及教程&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E4%B8%80%E9%94%AE%E4%B8%AD%E9%97%B4%E4%BA%BA&#34;&gt;一键中间人&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%9B%BD%E9%99%85%E4%BB%A3%E7%90%86%E8%BF%9B%E8%A1%8C%E4%B8%AD%E9%97%B4%E4%BA%BA&#34;&gt;国际代理进行中间人&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%AE%89%E8%A3%85-adb-%E5%85%AC%E9%92%A5&#34;&gt;安装 ADB 公钥&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#openvpn-%E6%9C%8D%E5%8A%A1&#34;&gt;OpenVPN 服务&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#socks5-%E6%9C%8D%E5%8A%A1&#34;&gt;SOCKS5 服务&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91%E6%9C%8D%E5%8A%A1&#34;&gt;端口转发服务&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E6%B3%A8%E5%85%A5-frida-rpc-%E8%84%9A%E6%9C%AC&#34;&gt;注入 Frida RPC 脚本&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E7%94%9F%E6%88%90%E5%8A%A0%E5%AF%86%E8%BF%9E%E6%8E%A5%E8%AF%81%E4%B9%A6&#34;&gt;生成加密连接证书&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/#%E5%88%97%E5%87%BA%E5%86%85%E7%BD%91%E8%AE%BE%E5%A4%87&#34;&gt;列出内网设备&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;免责声明及条款&lt;/h1&gt; &#xA;&lt;p&gt;为了下载使用由 rev1si0n (账号 github.com/rev1si0n)（以下简称“本人”）个人开发的软件 LAMDA ，您应当阅读并遵守《用户使用协议》（以下简称“本协议”）。请您务必审慎阅读、充分理解各条款内容，特别是免除或者限制责任的条款，并选择接受或不接受；除非您已阅读并接受本协议所有条款，否则您将无权下载、安装或使用本软件及相关服务。您的下载、安装、使用、获取账号、登录等行为即视为您已阅读并同意受到上述协议的约束；若您需要获得本服务，您（以下称&#34;用户&#34;）应当同意本协议的全部条款并按照页面上的提示完成全部申请使用程序。您可以在本文档的相同目录找到 &lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/DISCLAIMER.TXT&#34;&gt;DISCLAIMER.TXT&lt;/a&gt;，或者点此 &lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/DISCLAIMER.TXT&#34;&gt;免责声明&lt;/a&gt; 查阅。此项目代码库中仅包含开源的客户端库、工具代码。因服务端程序以二进制方式发布，并未开源，所以除以上条款外：&lt;strong&gt;授权您对 LAMDA SERVER 本身进行以恶意代码分析为目的的逆向&lt;/strong&gt;。&lt;/p&gt; &#xA;&lt;p&gt;请确认您已阅读并接受本协议所有条款，否则您将无权下载、安装或使用本软件及相关服务。&lt;/p&gt; &#xA;&lt;h1&gt;前言&lt;/h1&gt; &#xA;&lt;p&gt;LAMDA 是个人开发的免费软件 (freeware)，目前仅客户端库及工具代码是开源的，个人承诺 LAMDA 不会对您及您的设备有任何违规或多余的行为，如果仍有担心，您可以&lt;strong&gt;立即离开&lt;/strong&gt;或者选择&lt;strong&gt;付费&lt;/strong&gt;寻求心理安慰。互相尊重，使用请遵守使用条款。为什么部分开源？因为 LAMDA 亦黑亦白，很容易被不法分子利用使作者或者不明所以的用户处于危险之中，所以请尊重条款使用。建议在 Linux 或者 Mac 系统上操作文档及样例中的代码。部分功能需要配合 &lt;code&gt;tools/&lt;/code&gt; 目录下的工具实现，如何使用请参照 &lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/tools/README.md&#34;&gt;tools/README.md&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;特别注意&lt;/strong&gt;：&lt;strong&gt;请勿在自用设备上运行，当有可能在公网或不信任的网络中使用时，务必确保在启动时指定了PEM证书&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;使用后的副作用&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;你可能会把 Python 代码中的 &lt;code&gt;lambda&lt;/code&gt; 写成 lamda，这是正常现象。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;问题反馈及建议&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;因为安卓被各种设备广泛使用，无法保证百分百的兼容性，可能会有运行异常等各种未知情况，出现的异常情况包括：无故重启，APP经常崩溃，触摸失效或无故乱动等等，冻屏等情况。如果经常遇到，建议停止使用。 点此 &lt;a href=&#34;https://github.com/rev1si0n/lamda/issues/new&#34;&gt;报告问题/建议&lt;/a&gt;，请详细描述并附上机型系统等信息。&lt;/p&gt; &#xA;&lt;p&gt;社区讨论：&lt;a href=&#34;https://t.me/lamda_dev&#34;&gt;电报 t.me/lamda_dev&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;顺便支持作者&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;如果需要购入服务器，可以选择通过下方的&lt;strong&gt;推广链接&lt;/strong&gt;购买云服务。&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://lamda.run/referral/aliyun&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/image/logo-aliyun.png&#34; alt=&#34;阿里云&#34; height=&#34;40&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://lamda.run/referral/tencent&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/image/logo-tencent.svg?sanitize=true&#34; alt=&#34;腾讯云&#34; height=&#34;40&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;安装 LAMDA&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;分为客户端以及服务端，客户端主要是 Python 相关库及接口，服务端则是运行在设备/手机上的服务。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;注意事项&lt;/h2&gt; &#xA;&lt;h3&gt;基础要求&lt;/h3&gt; &#xA;&lt;p&gt;LAMDA 最理想的运行环境是你刚刚 root（如：新建模拟器，自带权限的ROM，Magisk 刚 root），启动前&lt;strong&gt;务必确保&lt;/strong&gt;：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;* 必须关闭 Magisk Hide&#xA;* 必须关闭 frida-server&#xA;* 确认完毕重启设备&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;并且不会在启动后启用任何上述任何标记为&lt;code&gt;必须&lt;/code&gt;的条目。&lt;/p&gt; &#xA;&lt;h3&gt;系统设置&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;检查时区时间&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;打开系统设置，找到日期与时间，检查是否已自动设置&lt;strong&gt;中国标准时间&lt;/strong&gt;或者你所在地的时区，检查时间是否正确或在可接受的误差范围内，如果没有请关闭&lt;strong&gt;使用网络提供的时区&lt;/strong&gt; 以及&lt;strong&gt;网络时间&lt;/strong&gt;，并手动设置时区及时间为你当前所在地的时区及时间。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;关闭无障碍&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;打开系统设置，找到无障碍（系统或更多设置中），关闭或卸载所有使用无障碍的应用（例如 talkback，autojs 等）。&lt;/p&gt; &#xA;&lt;h3&gt;网络设置&lt;/h3&gt; &#xA;&lt;p&gt;对于真机，你只需要确保电脑与手机在同一网络下即可。 对于模拟器，默认创建的模拟器正常情况下与你的本机网络并不互通，如果你使用的是 android x86 (基于 VMWare 的安卓虚拟机)， 请尝试在虚拟机设置中将网络模式设置为桥接模式。对于雷电，夜神等模拟器，需要在其设置中根据提示安装驱动并开启桥接模式随后重启模拟器。 对于 Android Studio 的 Virtual Device，则没有相关设置，如果需要连接 AVD，请先执行 &lt;code&gt;adb forward tcp:65000 tcp:65000&lt;/code&gt;， 并使用 &lt;code&gt;localhost&lt;/code&gt; （不要使用 127.0.0.1）进行连接。&lt;/p&gt; &#xA;&lt;h3&gt;其他设置&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;WSA (Windows Subsystem Android)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;如果使用的是 WSA (Windows Subsystem Android)，请确保 WSA 版本不低于 2210.40000 并且已 root。随后打开 WSA 设置 -&amp;gt; Subsystem Resources -&amp;gt; 选择 Continuous，关闭 Advanced Networking。随后重启 WSA 子系统即可。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;AVD (Android Studio Virtual Device)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;如果使用的是 AVD (Android Studio Virtual Device)，请先使用如下方式扩展默认存储空间的大小。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Pixel_5_API_29 为虚拟机ID，可以使用命令 emulator -list-avds 列出&#xA;# -partition-size 部分新建的 AVD 可用存储空间可能只有百兆，这里修改为 2G&#xA;emulator -avd Pixel_5_API_29 -partition-size 2048 -no-snapshot-load&#xA;# 随后每次启动虚拟机时都使用该命令&#xA;#&#xA;# 可能会遇到找不到 emulator 命令的情况，&#xA;# 请参阅此文档获知此命令的位置 https://developer.android.com/studio/run/emulator-commandline?hl=zh-cn 并将其加入 PATH 变量中&#xA;#&#xA;# 如果你无法完成上面的命令，请手动点击 Android Studio 中的 Virtual Device Manager，新建一个虚拟机，随后找到对应虚拟机并点击后方的编辑按钮（一个笔的符号），&#xA;# 点击 Show Advanced Settings，找到 Storage -&amp;gt; Internal Storage 并将其设置为至少 2GB。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Redroid (android in docker)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;注意目前 LAMDA &lt;strong&gt;3.0&lt;/strong&gt;，&lt;strong&gt;5.0&lt;/strong&gt; &lt;strong&gt;仅支持基于 ARM (aarch64) 宿主机&lt;/strong&gt;的 Redroid，&lt;strong&gt;7.0&lt;/strong&gt; 才支持 x86 版本的 Redroid，你可以通过命令 &lt;code&gt;uname -m&lt;/code&gt; 来检查。&lt;/p&gt; &#xA;&lt;p&gt;如果使用的是 Redroid (android in docker)，以官方建议的 &lt;code&gt;Ubuntu 20.04&lt;/code&gt; 为例，首先安装 linux-modules-extra 相关模块，（注意下列方法可能不适合其他 Linux 发行版，如果你不熟悉 Linux，我们不太建议你继续下面的操作）。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;apt install linux-modules-extra-`uname -r`&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;编辑文件 &lt;code&gt;/etc/modules&lt;/code&gt;，将下列名称复制并插入文件底部，重启当前宿主机。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# redroid modules&#xA;mac80211_hwsim&#xA;&#xA;binder_linux&#xA;ashmem_linux&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;或者&lt;/strong&gt;每次宿主机重启后执行（注意如果不用上述的方法那么每次重启都要这么做）&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;modprobe mac80211_hwsim&#xA;modprobe binder_linux devices=&#34;binder,hwbinder,vndbinder&#34;&#xA;modprobe ashmem_linux&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;最后使用以下命令启动，&lt;code&gt;redroid_gpu_mode&lt;/code&gt; 请根据实际进行修改（注意这与官方写的命令有所不同）。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -itd --rm --privileged --pull always -v /lib/modules:/lib/modules:ro -v ~/redroid:/data -p 127.0.0.1:5555:5555 -p 127.0.0.1:65001:65000 redroid/redroid:12.0.0-latest androidboot.redroid_gpu_mode=guest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;这里将容器 65000 映射到本机 65001 是因为部分工具需要临时绑定到 65000 端口。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;随后，你可以在宿主机上通过 &lt;code&gt;http://127.0.0.1:65001&lt;/code&gt; 访问到 LAMDA。&lt;/p&gt; &#xA;&lt;h2&gt;安装客户端&lt;/h2&gt; &#xA;&lt;p&gt;请使用 3.6 - 3.11 版本的 Python，建议有条件使用 Python 3.9&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip3 install -U lamda&#xA;# 即可&#xA;#&#xA;# 如果需要使用内置 frida，务必使用下列方法安装&#xA;# 你可能需要外网访问来安装 frida，否则可能会卡住许久(~10分钟)直至安装失败&#xA;# 即使之前安装过 frida，也应该重新执行以下命令&#xA;pip3 install -U --force-reinstall &#39;lamda[full]&#39;&#xA;# 如果你安装的服务端是 7.0 (beta) 版本，请执行如下命令安装&#xA;pip3 install -U --force-reinstall &#39;lamda[next]&#39;&#xA;# 请注意完成安装后，你需要同时使用 pip 更新任何依赖 frida&#xA;# 的第三方库例如 frida-tools objection 等（如果安装过的话）&#xA;# 否则后期使用可能会出现难以察觉的异常&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;安装完成后，执行命令 &lt;code&gt;python3 -m lamda.client&lt;/code&gt; 检查是否安装正确。如果出现如下类似报错&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;* AttributeError &#39;NoneType&#39; object has no..&#xA;* TypeError: Couldn&#39;t build proto file..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;可能是因为安装的其它依赖 protobuf 的包产生冲突。请尝试执行如下命令&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip3 install -U --force-reinstall lamda&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;如果仍然存在问题，请创建 virtualenv 来使用。&lt;/p&gt; &#xA;&lt;h2&gt;安装服务端&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;默认方式安装的 LAMDA 没有开启任何认证，其他人可以访问设备上的任意内容，监听你的设备甚至接入设备网络进行进一步控制。请特别留意&lt;code&gt;启用接口认证&lt;/code&gt;的部分，请务必在可以&lt;code&gt;信任的网络&lt;/code&gt;内使用。并且请注意，&lt;code&gt;即使开启了接口认证&lt;/code&gt;，任何&lt;code&gt;有权限登录远程桌面以及使用API&lt;/code&gt;的人仍然对你的设备以及 LAMDA 本身有着完全的访问权限。&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;由于安全性原因，我们不建议将任何相关文件放在 &lt;code&gt;/data/local/*&lt;/code&gt; 目录下。&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;安装前，请先选择合适的架构，可以通过 adb shell 命令 &lt;code&gt;getprop ro.product.cpu.abi&lt;/code&gt; 来获取当前的系统架构。 正常情况下，对于现时代的手机，可以直接选择 &lt;code&gt;arm64-v8a&lt;/code&gt; 版本，而对于模拟器如雷电，你会在新建模拟器时选择32或64位版本的安卓系统， 32位模拟器系统对应 &lt;code&gt;x86&lt;/code&gt;，64位则对应 &lt;code&gt;x86_64&lt;/code&gt;，正常情况下，雷电模拟器默认创建的为基于 &lt;code&gt;x86&lt;/code&gt; 的安卓 7.0 系统。&lt;/p&gt; &#xA;&lt;p&gt;LAMDA 支持设备状态主动上报，你可以编写接口或使用 grafana 来记录设备运行状况，其中包含了系统、网络、内存、CPU、磁盘等等信息。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 如果不清楚这个功能是什么请不要执行，注意替换掉以下链接（需要 root 身份）&#xA;echo &#34;stat-report.url=http://example.com/report&#34; &amp;gt;&amp;gt;/data/properties.local&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;这样 LAMDA 会在启动后&lt;strong&gt;每分钟&lt;/strong&gt;向此链接&lt;strong&gt;POST&lt;/strong&gt;设备状态信息（JSON），由于字段较多，将不在此罗列。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;配置自动更新&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;LAMDA 存在一个自动更新的逻辑，但是由于存在分钟级的服务中断，目前仅限于内部自用。除了存在紧急安全问题或者致命BUG等情况，LAMDA 不会进行任何自动更新，请自行定期在闲时从 github 下载并安装最新版本。&lt;/p&gt; &#xA;&lt;p&gt;如果你确实不在意更新时分钟级的服务不可用，启动 LAMDA 之前写入以下配置文件可以确保 LAMDA 始终为最新版本。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 进入 adb shell 执行（需要 root 身份）&#xA;echo &#34;upgrade.channel=latest&#34; &amp;gt;&amp;gt;/data/properties.local&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;properties.local 启动配置&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;在开始前，有必要介绍一下上面的 &lt;code&gt;properties.local&lt;/code&gt; 文件， properties.local 为 LAMDA 的启动配置文件，通常存储于设备之上，其中包含了 &lt;code&gt;a=b&lt;/code&gt; 类型的字符串， 通过编写此文件，你可以实现在 LAMDA 启动时自动连接到 OpenVPN、代理、端口转发等。 LAMDA 在启动时，会从 &lt;code&gt;/data&lt;/code&gt;, &lt;code&gt;/data/usr&lt;/code&gt; 查找该文件并载入（usr 目录在 LAMDA 首次启动前并不存在，所以你可能需要手动创建）。 你可以在以上三个位置任意一个放置你的 properties.local 配置文件。&lt;/p&gt; &#xA;&lt;p&gt;除了 &lt;code&gt;properties.local&lt;/code&gt;，还有一个从加载远端配置的参数 &lt;code&gt;--properties.remote&lt;/code&gt;，它可以让 LAMDA 在启动时从HTTP服务器下载配置，请继续看往启动 LAMDA 的章节。&lt;/p&gt; &#xA;&lt;p&gt;关于如何编写配置，在各个功能中会有介绍。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;launch.sh 可能出现的错误及解决方法&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 显示 llllaamDaa started 则服务已经正常进入 daemon 模式，可以退出终端&#xA;&#xA;already running     (已经在运行，请不要多次启动)&#xA;invalid TZ area     (时区未设置，在系统时间设置中设置时区即可，可能出现于国外或原生系统上)&#xA;not run as root     (没有以 root 身份运行)&#xA;unsupported sdk     (在不支持的安卓系统上运行)&#xA;abi not match       (使用了错误的 tar.gz 包)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;通过 Magisk 安装&lt;/h3&gt; &#xA;&lt;p&gt;如果你的设备使用了 Magisk，那么你可以以最简单的方法完成安装，并且 LAMDA 可以&lt;strong&gt;开机自启动&lt;/strong&gt;。需要确保 Magisk 版本 &amp;gt;= 20.4 且只支持在 &lt;strong&gt;Magisk App&lt;/strong&gt; 中安装。同时，使用 Magisk 安装更便于统一化，你可以自定义配置，例如，你想要所有使用该 magisk 模块刷入后的 LAMDA 都启用接口认证（certificate）， 或者希望这些设备都在启动时自动连接代理，你只需要编写 properties.local 或者生成PEM证书并重命名为 &lt;code&gt;lamda.pem&lt;/code&gt;（请查看 tools/ 中的工具使用方法）， 随后使用&lt;strong&gt;压缩软件&lt;/strong&gt;打开 &lt;code&gt;lamda-magisk-module.zip&lt;/code&gt;，并将其（&lt;code&gt;lamda.pem&lt;/code&gt; 或者 &lt;code&gt;properties.local&lt;/code&gt;）拖入 &lt;code&gt;common&lt;/code&gt; 文件夹即可实现启动时自动配置！&lt;/p&gt; &#xA;&lt;p&gt;现在，从 &lt;a href=&#34;https://github.com/rev1si0n/lamda/releases&#34;&gt;lamda/releases&lt;/a&gt; 页面下载 &lt;code&gt;lamda-magisk-module.zip&lt;/code&gt;，并将其 push 到 &lt;code&gt;/sdcard&lt;/code&gt;，打开 Magisk App，点击 模块-&amp;gt;从本地安装，选择 lamda-magisk-module.zip 稍作等待即可。&lt;/p&gt; &#xA;&lt;p&gt;刷入成功后，请重启设备。重启后，LAMDA 应该会在开机时自启动。但是为了避免可能的崩溃问题，lamda 会在 30 秒后启动而不是立即启动，你将有足够的时间去禁用 LAMDA 模块（请在开机后2分钟再连接使用 LAMDA）。安装完成后，你无需再看下段手动安装的内容，跳过即可。&lt;/p&gt; &#xA;&lt;h3&gt;手动安装&lt;/h3&gt; &#xA;&lt;p&gt;由于部分老旧设备可能无法通过系统的 &lt;code&gt;tar&lt;/code&gt; 命令来解压 tar.gz 后缀的文件，所以提供了 &lt;code&gt;busybox&lt;/code&gt; 用来作为补充，你可能需要同时下载提供的 busybox。现在已知 getprop 获得的设备架构为 &lt;code&gt;arm64-v8a&lt;/code&gt;，现在将设备连接到当前电脑并确保已授权 ADB、可以正常切换 root。&lt;/p&gt; &#xA;&lt;p&gt;从 &lt;code&gt;release&lt;/code&gt; 页面 &lt;a href=&#34;https://github.com/rev1si0n/lamda/releases&#34;&gt;lamda/releases&lt;/a&gt; 下载 &lt;code&gt;lamda-server-arm64-v8a.tar.gz&lt;/code&gt; 以及 &lt;code&gt;busybox-arm64-v8a&lt;/code&gt;。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 将文件临时推送到 /data/local/tmp&#xA;adb push lamda-server-arm64-v8a.tar.gz /data/local/tmp&#xA;adb push busybox-arm64-v8a /data/local/tmp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;完成后，进入 &lt;code&gt;adb shell&lt;/code&gt;，解包文件：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 你现在应该在 adb shell 内&#xA;# 使用此种方式，服务端程序将被安装到 /data&#xA;# 确保切换为 root 身份&#xA;su&#xA;# 确保上传的 busybox 可执行&#xA;chmod 755 /data/local/tmp/busybox-arm64-v8a&#xA;&#xA;cd /data&#xA;# 解包服务端文件&#xA;/data/local/tmp/busybox-arm64-v8a tar -xzf /data/local/tmp/lamda-server-arm64-v8a.tar.gz&#xA;# 服务将被解压到 /data/server 目录下&#xA;&#xA;# 删除安装包以及 busybox&#xA;rm /data/local/tmp/lamda-server-arm64-v8a.tar.gz&#xA;rm /data/local/tmp/busybox-arm64-v8a&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;启动服务端&lt;/h2&gt; &#xA;&lt;p&gt;使用 Magisk 安装后的 LAMDA 会在开机时自动启动，你只需要在首次安装后重启一次设备即可。而对于手动安装的 LAMDA，在每次&lt;strong&gt;设备重启&lt;/strong&gt;或者&lt;strong&gt;手动退出服务&lt;/strong&gt;后你都需要重新执行以下命令来启动 LAMDA SERVER。&lt;/p&gt; &#xA;&lt;p&gt;进入 adb shell，并切换为 &lt;code&gt;su&lt;/code&gt; root 身份，执行：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 确保为 root 身份&#xA;# 你现在应该在 adb shell 内&#xA;su&#xA;# 启动服务端&#xA;sh /data/server/bin/launch.sh&#xA;#&#xA;# 如果你想要启用加密传输&#xA;# 请先使用 tools/ 中的 cert.py 来生成 PEM 证书&#xA;# 将其push到设备例如 /data/lamda.pem&#xA;# 并将其属主及权限设置为 root 以及 600 (chown root:root lamda.pem; chmod 600 lamda.pem)&#xA;# 并使用以下命令启动，lamda.pem 必须为绝对路径&#xA;sh /data/server/bin/launch.sh --certificate=/data/lamda.pem&#xA;# 这将加密任何通过 LAMDA 产生的通信流量&#xA;#&#xA;# 从远端加载 properties.local&#xA;# 有时候你可能希望从链接加载启动配置，这时你可以将 properties.local 上传到服务器&#xA;# LAMDA 在下载此配置时，会提供当前设备的部分信息如，设备唯一ID，设备型号，当前版本等。&#xA;# 你也可以自行编写web服务来根据这些设备参数分发不同的启动配置&#xA;# 建议使用 HTTPS 链接增加安全性，请确保设备时间正确。&#xA;# 随后使用如下方式启动 LAMDA&#xA;sh /data/server/bin/launch.sh --properties.remote=http://example.com/config/properties.local&#xA;# 对于开启了 Basic Auth 的静态文件服务，同样支持提供用户名密码&#xA;sh /data/server/bin/launch.sh --properties.remote=http://user:password@example.com/config/properties.local&#xA;# 提示：LAMDA 会在超时或者返回 50x 状态码时重试请求，&#xA;# 如果连续 5 次仍然失败，LAMDA 会放弃尝试并继续启动。&#xA;#&#xA;# 当然，可以自定义重试次数但是注意，如果服务器持续无响应，LAMDA 也将永远卡在这里&#xA;# 什么时候需要设置重试次数：刚开机时设备可能并没有网络连接，如果你要在这时启动 LAMDA 你可以增大该值&#xA;sh /data/server/bin/launch.sh --properties.remote=http://example.com/config/properties.local --properties.tries=30&#xA;# 重试机制的每轮等待秒数n会随着重试次数的增加而增加。所以请谨慎设置该值。&#xA;#&#xA;# 如果你需要 LAMDA 监听到特定端口而不是 65000&#xA;# 如果修改，请确保所有内网设备均以相同端口启动&#xA;# 否则设备发现等功能无法正常工作&#xA;sh /data/server/bin/launch.sh --port=8123&#xA;# 请不要绑定 1024 以下的端口&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;静待退出，随即关闭终端，至此服务启动完成。&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：首次启动时有几率出现远程桌面一直加载。发生这种情况时，请首先尝试重启设备并重新启动 lamda。 如果在启动或使用中多次遇到设备黑屏/重启卡顿等类似情况，建议停止使用。&lt;/p&gt; &#xA;&lt;h2&gt;退出服务端&lt;/h2&gt; &#xA;&lt;p&gt;LAMDA 设计为一个 7*24 小时后台运行的服务，不建议频繁启动关闭，如果确需这样做，请务必确保你通过以下两种方式关闭。如需使用接口关闭服务请参照下方 &lt;code&gt;关机重启&lt;/code&gt; 章节，考虑到可能不方便使用接口，你也可以使用以下命令。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kill -SIGUSR2 $(cat /data/usr/lamda.pid)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;LAMDA 服务完全退出可能需要十几秒的时间，请不要连续多次执行此命令。&lt;/p&gt; &#xA;&lt;h2&gt;卸载服务端&lt;/h2&gt; &#xA;&lt;p&gt;LAMDA 对于自身数据的规划非常规范，绝对不会在你的系统中随意放置文件。 你可以通过几条命令完全卸载 lamda，在进行前，请先按照上方 &lt;code&gt;关闭 LAMDA 服务&lt;/code&gt; 执行并等待至少30秒以确保服务正常退出。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 删除 LAMDA 相关目录&#xA;rm -rf /data/server /data/usr&#xA;# 重启设备&#xA;reboot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;使用 LAMDA&lt;/h1&gt; &#xA;&lt;p&gt;设备上的 &lt;code&gt;65000&lt;/code&gt; 端口为本服务的标准公用端口，可能需要记住，但是大部分情况下，你不需要显式提供此端口号。 下面请先在 WLAN 设置中取得&lt;strong&gt;当前设备的IP地址&lt;/strong&gt;，你也可以通过 tools/ 目录里的工具来列出当前网络中的所有设备及IP， 下面将会一直&lt;strong&gt;假设&lt;/strong&gt;设备的IP为 &lt;code&gt;192.168.0.2&lt;/code&gt;。&lt;/p&gt; &#xA;&lt;h2&gt;远程桌面&lt;/h2&gt; &#xA;&lt;p&gt;远程桌面功能仅为 Chrome 95+ 设计，不支持多人访问，不保证兼容所有浏览器，如遇功能不正常请使用 Chrome。&lt;/p&gt; &#xA;&lt;p&gt;在浏览器中打开链接 &lt;code&gt;http://192.168.0.2:65000&lt;/code&gt; 可进入 web 远程桌面，你可以在此操作设备以及通过该界面的root模拟终端执行命令。如果启动服务端时指定了PEM证书 &lt;code&gt;--certificate&lt;/code&gt;，远程桌面将需要你输入密码才能继续访问，并且你需要将 &lt;code&gt;http://&lt;/code&gt; 改为 &lt;code&gt;https://&lt;/code&gt; 使用 HTTPS 的方式访问，你可以使用文本编辑器在PEM证书第一行找到这个固定密码。&lt;/p&gt; &#xA;&lt;p&gt;你也可以自定义远程桌面的 视频帧率(fps)、分辨率缩放比例(res)以及图像质量(quality)。同时，支持 H.264 软编码（部分情况下使用流量更少更流畅，仅支持最新版 Chrome 浏览器）。你可以通过远程桌面右上角的小齿轮进行调整，但是请注意，调整以上参数并不一定会产生正向效果，请依据事实调整。&lt;/p&gt; &#xA;&lt;p&gt;如果需要键盘输入等更加人性化的操作体验，请先看下面的章节 &lt;code&gt;无线连接内置 root 权限的 WIFI ADB&lt;/code&gt;， 完成 adb connect 到 LAMDA 后，安装使用 &lt;a href=&#34;https://github.com/Genymobile/scrcpy&#34;&gt;Genymobile/scrcpy&lt;/a&gt; 或者 &lt;a href=&#34;https://github.com/barry-ran/QtScrcpy&#34;&gt;barry-ran/QtScrcpy&lt;/a&gt; 即可，具体使用方法请查看其使用文档。&lt;/p&gt; &#xA;&lt;h2&gt;文件上传&lt;/h2&gt; &#xA;&lt;p&gt;你可以在此页面直接&lt;strong&gt;拖动文件或目录到右侧终端&lt;/strong&gt;上来上传文件/文件夹到设备，支持同时拖动多个文件或文件夹，单个文件最大不得超过 256MB，最多只支持同时上传 2k 个文件，上传的任何文件权限均为 644，文件将始终上传到 &lt;code&gt;/data/usr/uploads&lt;/code&gt; 目录下。&lt;/p&gt; &#xA;&lt;h2&gt;文件下载&lt;/h2&gt; &#xA;&lt;p&gt;LAMDA 允许你通过浏览器浏览设备上的目录及下载文件，只需要在浏览器打开链接 &lt;code&gt;http://192.168.0.2:65000/fs/&lt;/code&gt; 即可（注意最后面的 &lt;code&gt;/&lt;/code&gt;）。&lt;/p&gt; &#xA;&lt;h2&gt;移动代理&lt;/h2&gt; &#xA;&lt;p&gt;有些时候，你的APP可能在某些网络条件下会发生错误，或者你想处在设备相同的网络IP下做一些测试。 LAMDA 的 tunnel2 功能，支持你将运行 LAMDA 的设备作为 http 网络代理服务器，它同样继承了 LAMDA 的强大功能：你在任何地方都能处在近乎与设备相同的网络之中。你可以通过以下 curl 命令快速体验，你也可以在 Firefox 设置-手动配置代理将 &lt;code&gt;192.168.0.2&lt;/code&gt; 端口 &lt;code&gt;65000&lt;/code&gt; 设置为代理并且勾选 &lt;code&gt;也将此代理用于 HTTPS&lt;/code&gt;，这样你的 Firefox 将会与设备有着相同的出网IP。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 默认代理无需任何认证，但是当你使用了 --certificate 启动时&#xA;# 那么登录用户名为: lamda，密码与远程桌面登录令牌 (token) 相同&#xA;# 建议使用自定义配置 tunnel2.password 自行设置密码&#xA;curl -x http://192.168.0.2:65000 https://httpbin.org/ip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;自定义代理配置&lt;/h3&gt; &#xA;&lt;p&gt;如果你想使用移动网络（4G/5G）作为代理出口。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;# 追加到 properties.local 配置文件&#xA;tunnel2.login=lamda&#xA;tunnel2.password=mypassword&#xA;#&#xA;# iface 存在两个可配置值，即 wlan、rmnet，当 iface 值为 wlan 时，&#xA;# 将自动检测可用 wlan 接口并选择任意一个发出请求，当 iface 为 rmnet 时&#xA;# 将尝试启用移动数据（即使 WIFI 已开启），并将请求从移动网络接口发出。&#xA;# 当配置为 rmnet/wlan 但其接口无网络时，代理将失效。&#xA;# 当未配置时，使用默认网络发出请求。&#xA;#tunnel2.iface=rmnet&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;如果希望从任何地点都可使用设备作为代理，请查看 &lt;code&gt;使 LAMDA 可被任意地点连接&lt;/code&gt; 章节。&lt;/p&gt; &#xA;&lt;h2&gt;连接设备&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;现在，将配合 lamda 库进行介绍，在开始前，请先确保你已经根据上文 &lt;code&gt;客户端安装&lt;/code&gt; 章节正确安装了客户端库。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;建议顺带翻看客户端的源码，并不是需要理解，仅仅是让你能了解到底有什么参数可以使用。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from lamda.client import *&#xA;&#xA;d = Device(&#34;192.168.0.2&#34;)&#xA;# 如果在服务端启用了 certificate 请这样连接&#xA;d = Device(&#34;192.168.0.2&#34;, certificate=&#34;/path/to/lamda.pem&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;或者，如果你熟悉 uiautomator2，也可以通过 u2 来使用部分自动化功能&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import uiautomator2 as u2&#xA;&#xA;# 注意：只兼容约7成主要接口，并且服务端未启用 certificate 选项&#xA;d = u2.connect(&#34;http://192.168.0.2:65000&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;或者，直接执行命令&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 注意这个DEVICE参数是IP，自行替换&#xA;python3 -m lamda.client -device 192.168.0.2&#xA;# 随后可以直接在此 shell 中输入下方语句&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;下文中的 &lt;code&gt;d&lt;/code&gt; 将始终假设为 &lt;code&gt;d = Device(&#34;192.168.0.2&#34;)&lt;/code&gt; 实例。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;先来一个热身&lt;/h2&gt; &#xA;&lt;p&gt;如下方法可以使你的手机发出一声蜂鸣，当有一堆设备的时候，需要定位其中一台，可以调用此接口。（需要手机为非静音状态）&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;d.beep()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;设置系统代理&lt;/h2&gt; &#xA;&lt;p&gt;只支持 http 以及 socks5 代理，不支持 IPv6&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;假设你从服务商处获得的代理为 &lt;a href=&#34;http://123.123.123.123:8080%EF%BC%8C&#34;&gt;http://123.123.123.123:8080，&lt;/a&gt; 仅需如下几行代码来让设备上的 tcp 流量通过此代理&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;profile = GproxyProfile()&#xA;profile.type = GproxyType.HTTP_CONNECT&#xA;&#xA;# 此选项请根据实际情况选择你是否需要&#xA;profile.drop_udp = True&#xA;profile.host = &#34;123.123.123.123&#34;&#xA;profile.port = 8080&#xA;&#xA;d.start_gproxy(profile)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;详细的参数配置信息&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;profile = GproxyProfile()&#xA;# socks5 代理则为 GproxyType.SOCKS5&#xA;profile.type = GproxyType.HTTP_CONNECT&#xA;# 如果你需要重定向 DNS 查询到 114.114.114.114&#xA;# 注意此 DNS 是系统全局的，系统发出的所有DNS将会被转发&#xA;# 如果是与OpenVPN共存的情况，不要设置为OpenVPN的内网DNS服务器，否则可能会导致彻底断网&#xA;# 去掉 nameserver 配置行将使用系统默认 DNS&#xA;#&#xA;# 为什么有此选项：你可以修改一些应用的 dns 域名解析&#xA;profile.nameserver = &#34;114.114.114.114&#34;&#xA;profile.host = &#34;代理服务器地址&#34;&#xA;profile.port = 代理服务器端口&#xA;&#xA;# 如果这个代理服务器需要登录信息（注意：如果没有，请注释或删除如下两行）&#xA;profile.password = &#34;代理服务器登录密码&#34;&#xA;profile.login = &#34;代理服务器登录用户&#34;&#xA;&#xA;# socks5 模式支持 udp 代理，但是 http 代理并不支持&#xA;# 因为 udp 多数情况下并不会被代理，所以禁用 udp 流量是一个不错的选择&#xA;# 当 drop_udp 为 True 时，应用/系统的 UDP 流量将会被屏蔽，默认为 False&#xA;profile.drop_udp = False&#xA;&#xA;# 本地流量是否需要*不经过*代理，如果为 True，本地流量&#xA;# 如 192.168.x.x 10.x.x.x 等路由器内网网段的流量将不会经过代理，默认为 False&#xA;# 注意：如果开启了 udp_proxy，此选项对于 UDP 流量无效&#xA;profile.bypass_local_subnet = True&#xA;&#xA;# 是否需要代理 udp 流量&#xA;# 注意，http 代理服务不支持代理 udp 协议，开启此选项必须使用 socks5 作为代理服务器&#xA;# (GproxyType.SOCKS5)，且 socks5 代理服务器必须配置开启 udp 代理模式，&#xA;# 需要稍加复杂的服务器配置，为了避坑，请参照 tools/socks5 里的介绍进行安装配置&#xA;# 当你使用 http 代理或者 drop_udp 选项为 True，此设置将会被忽略&#xA;profile.udp_proxy = False&#xA;&#xA;# 如果需要仅对特定应用使用代理（例如安卓浏览器，如果是全局则删除这两行）&#xA;app = d.application(&#34;com.android.browser&#34;)&#xA;profile.application.set(app)&#xA;&#xA;#     注意事项以及提示：&#xA;# 设置代理后，正在运行的应用是不会立即使用设置的代理的&#xA;# 因为这些应用在设置代理之前就已经完成了 tcp 连接的建立&#xA;# 所以，需要你手动关闭应用并启动，应用才会通过代理建立连接&#xA;# 也就是说，如果你是做中间人流量分析，那设置代理后&#xA;# 你需要关闭应用再重新打开才会看到应用的请求&#xA;#&#xA;# 注：本机的 DNS 流量始终不会经过代理&#xA;&#xA;# 启动代理&#xA;d.start_gproxy(profile)&#xA;# 关闭代理&#xA;d.stop_gproxy()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;快速搭建一个 socks5 代理&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;LAMDA 在 tools/ 中提供了一个开箱即用同时支持 udp 的 socks5 代理服务 docker，请转到 tools/socks5 目录查看 README.md。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;在 LAMDA 启动时自动连接代理&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;复制下列配置并修改相关配置为你的代理信息&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;gproxy.enable=true&#xA;gproxy.type=http-connect&#xA;gproxy.host=123.333.333.333&#xA;gproxy.port=8080&#xA;gproxy.password=&#xA;gproxy.login=&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;将其追加或者写入到 properties.local，重启 LAMDA 即可。&lt;/p&gt; &#xA;&lt;h2&gt;安装中间人证书&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;建议你使用或参考已经封装好的 tools/ 目录下的 startmitm.py, globalmitm 工具，这里介绍的是相关接口。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;请先确保你已经准备好 fiddler, mitmproxy 给你的证书，对于 mitmproxy， 给你的证书为 pem 格式如下示例。而对于 fiddler，则可能是 crt 格式，直接将该文件路径 作为参数提供即可无需关心任何转换/文件名问题。&lt;/p&gt; &#xA;&lt;p&gt;为了避免浪费不必要的时间，在这里推荐使用 &lt;code&gt;mitmproxy&lt;/code&gt;， 如果你使用的是 &lt;code&gt;Charles&lt;/code&gt; 等，我无法确保你可以一次性完成设置， 因为此类应用配置项目较为复杂且你可能需要理解各种代理类型才能正确配置SSL中间人， 如果你一定要使用，建议使用 Charles 的 socks5 作为代理协议。&lt;/p&gt; &#xA;&lt;p&gt;注意：有可能不支持安卓 13&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os&#xA;&#xA;# 拼接 mitmproxy-ca-cert.pem 文件的路径&#xA;HOME = os.path.expanduser(&#34;~&#34;)&#xA;cert_path = os.path.join(HOME, &#34;.mitmproxy&#34;, &#34;mitmproxy-ca-cert.pem&#34;)&#xA;# 以 mitmproxy 为例，使用如下代码安装证书&#xA;d.install_ca_certificate(cert_path)&#xA;&#xA;# 使用如下代码卸载证书（如不常变化不建议频繁安装卸载）&#xA;d.uninstall_ca_certificate(cert_path)&#xA;# 此证书安装接口是通用的，你可以用它安装任何应用要求你安装的证书&#xA;# 你同样可以用其安装 Fiddler/Charles 要求你安装的证书&#xA;# 只需要提供文件路径即可&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;接着，看 &lt;code&gt;设置 http/socks5 代理&lt;/code&gt; 节，将代理设置为中间人应用监听的地址即可。 按照流程完成后如果没有截获到流量请参加设置代理部分的&lt;strong&gt;特别注意&lt;/strong&gt;。&lt;/p&gt; &#xA;&lt;h2&gt;设置 OpenVPN&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;此 OpenVPN 只支持使用证书登录，可以与 http/socks5 代理共存。 需要注意的是，此功能只包含OpenVPN的主要功能，除了 &lt;code&gt;DNS&lt;/code&gt; 配置，暂无法应用服务端推送的其他配置信息。 这些配置包括但不限于 PAC 代理，http 代理配置等。为了省却你安装服务的麻烦， LAMDA 提供了一个开箱即用的 OpenVPN docker 镜像，它有脚本可以生成下面这个配置，请继续往下看。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;非常建议使用 tools 里的 OpenVPN docker 安装及生成如下连接配置。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;profile = OpenVPNProfile()&#xA;&#xA;# 是否全局 VPN，为 False 时仅路由服务器端推送的特定网段&#xA;profile.all_traffic  = True&#xA;# 服务器端开启的连接协议 (或者为 OpenVPNProto.TCP)&#xA;profile.proto        = OpenVPNProto.UDP&#xA;profile.host         = &#34;OpenVPN 服务器地址&#34;&#xA;profile.port         = OpenVPN 服务器端口&#xA;# 服务器端通道加密方法&#xA;profile.cipher       = OpenVPNCipher.AES_256_GCM&#xA;&#xA;profile.tls_encryption = OpenVPNEncryption.TLS_CRYPT&#xA;profile.tls_key_direction = OpenVPNKeyDirection.KEY_DIRECTION_NONE&#xA;profile.tls_key = &#34;&#34;&#34;&#xA;-----BEGIN OpenVPN Static key V1-----&#xA;tls key / tls auth&#xA;-----END OpenVPN Static key V1-----&#xA;&#34;&#34;&#34;&#xA;&#xA;profile.ca = &#34;&#34;&#34;&#xA;-----BEGIN CERTIFICATE-----&#xA;服务端配置的 ca 证书&#xA;-----END CERTIFICATE-----&#xA;&#34;&#34;&#34;&#xA;&#xA;profile.cert = &#34;&#34;&#34;&#xA;-----BEGIN CERTIFICATE-----&#xA;客户端证书&#xA;-----END CERTIFICATE-----&#xA;&#34;&#34;&#34;&#xA;&#xA;profile.key = &#34;&#34;&#34;&#xA;-----BEGIN PRIVATE KEY-----&#xA;客户端私钥&#xA;-----END PRIVATE KEY-----&#xA;&#34;&#34;&#34;&#xA;&#xA;# 启动 OpenVPN&#xA;d.start_openvpn(profile)&#xA;# 关闭 OpenVPN&#xA;d.stop_openvpn()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;快速搭建一个 OpenVPN 服务&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;LAMDA 在 tools/ 中提供了一个开箱即用的 OpenVPN docker，请转到 tools/openvpn 目录查看 README.md。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;在 LAMDA 启动时自动连接 VPN&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;你可以使用 tools/openvpn 提供的命令来生成 properties.local 配置，请不要自行编写。&lt;/p&gt; &#xA;&lt;h2&gt;连接内置的 FRIDA&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;非逆向工作无需阅读此节&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;启动本框架前后，&lt;strong&gt;请勿&lt;/strong&gt;再次自行启动任何 frida-server，否则有可能会导致系统崩溃。你只需要通过下列代码使用内置 frida 即可。&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;通过代码连接&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 使用 LAMDA 时的做法&#xA;device = d.frida&#xA;device.enumerate_processes()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;等效原生代码&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 仅做示例，为了通用性，请务必使用上述方法&#xA;manager = frida.get_device_manager()&#xA;device = manager.add_remote_device(&#34;192.168.0.2:65000&#34;)&#xA;device.enumerate_processes()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;通过命令行使用&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;对于所有 frida 官方命令行工具，你只需要加上参数 &lt;code&gt;-H 192.168.0.2:65000&lt;/code&gt; 即可。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;frida -H 192.168.0.2:65000 -f com.android.settings&#xA;# 如果你在服务端启动时指定了 certificate 选项，请注意也需要在此加入 --certificate 参数例如&#xA;# 且需要提供 token，这个 token 可以在 lamda.pem 的最后一行找到&#xA;frida -H 192.168.0.2:65000 -f com.android.settings --certificate /path/to/lamda.pem --token f141bce852f70730506f995991450adb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;使用 FRIDA 暴露 Java 接口&lt;/h2&gt; &#xA;&lt;p&gt;这个功能类似于 &lt;a href=&#34;https://github.com/virjar/sekiro&#34;&gt;virjar/sekiro&lt;/a&gt;，关于它的用途请参考 virjar 大佬的 项目。此功能需要你能熟练编写 frida 脚本。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;请转到 tools 目录查看使用方法。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;此功能需要你能熟练编写 frida 脚本。示例中使用的脚本请参照 test-fridarpc.js 文件，特别注意: frida 脚本中 rpc.exports 定义的函数参数以及返回值只能为 int/float/string/list/map 或者任意 js 中&lt;strong&gt;可以被 JSON序列化&lt;/strong&gt;的值。假设设备IP为 192.168.0.2。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;执行以下命令注入 RPC 到 com.android.settings（注意查看是否有报错），下面的相关文件在 tools 目录&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 fridarpc.py -f test-fridarpc.js -a com.android.settings -d 192.168.0.2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;现在已经将接口暴露出来了，只需要请求 &lt;code&gt;http://192.168.0.2:65000/fridarpc/myRpcName/getMyString?args=[&#34;A&#34;,&#34;B&#34;]&lt;/code&gt; 即可得到脚本内方法的返回结果，链接也可以用浏览器打开，接口同时支持 POST 以及 GET，参数列表也可以同时使用多个参数，空列表代表无参数，注意这里的 args 参数序列化后的字符串最长&lt;strong&gt;不能超过&lt;/strong&gt; &lt;code&gt;32KB&lt;/code&gt;（在使用了 --certificate 的情况下，链接需要改为 https 方式）。&lt;/p&gt; &#xA;&lt;p&gt;链接中的两个字符串参数 &#34;A&#34;, &#34;B&#34; 即为注入的脚本中的方法 &lt;code&gt;getMyString(paramA, paramB)&lt;/code&gt; 的位置参数。&lt;/p&gt; &#xA;&lt;p&gt;注意参数的提供形式，是&lt;strong&gt;双引号&lt;/strong&gt;，请&lt;strong&gt;不要手打&lt;/strong&gt;或者&lt;strong&gt;字符串拼接&lt;/strong&gt;这个参数，务必使用 json.dumps([&#34;A&#34;, &#34;B&#34;])&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;用 requests 调用&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import json&#xA;import requests&#xA;url = &#34;http://192.168.0.2:65000/fridarpc/myRpcName/getMyString&#34;&#xA;# 请求接口&#xA;res = requests.post(url, data={&#34;args&#34;: json.dumps([&#34;A&#34;,&#34;B&#34;])})&#xA;print (res.status_code, res.json()[&#34;result&#34;])&#xA;&#xA;#* 状态码 200 一切正常&#xA;#* 状态码 410 需要重新注入脚本或者脚本未注入（目前不支持自动重新注入）&#xA;#* 状态码 500 脚本或参数异常&#xA;#* 状态码 400 参数错误&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;响应结果的格式是固定的，可在浏览器打开查看。同样，配合下面一节的内容，你将可以在公网直接使用接口。&lt;/p&gt; &#xA;&lt;h2&gt;使用内置的定时任务&lt;/h2&gt; &#xA;&lt;p&gt;内置了用于执行定时任务的 cron 服务，这样你可以在设备上定期执行一些脚本，所有规则都将以 root 身份执行。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;此功能需要你会编写 crontab 规则，如果你不清楚 crontab，请先自行了解。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;现在，请打开 web 控制台或者连接设备的 ssh/adb shell，执行命令 &lt;code&gt;crontab -e&lt;/code&gt;，你将进入编辑模式，在英文输入模式下按下字母 &lt;code&gt;i&lt;/code&gt;，随后写下相关规则，并依次按下 &lt;code&gt;ESC&lt;/code&gt;，&lt;code&gt;SHIFT&lt;/code&gt; + &lt;code&gt;:&lt;/code&gt;，输入 &lt;code&gt;wq&lt;/code&gt; 并按下回车来保存即可。受限于安卓休眠机制，息屏后定时任务可能并不会以你期望的时间运行，你可能需要将设备设置为常亮。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;一些规则示例&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code&gt;@reboot      echo 框架启动时执行&#xA;0 */1 * * *  echo 每一小时执行&#xA;* * * * *    echo 每一分钟执行&#xA;0 8 * * *    echo 每天八点执行&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;使 LAMDA 可被任意地点连接&lt;/h2&gt; &#xA;&lt;p&gt;有时候你可能遇到这种情况：你的手机在家里而你不在家该怎么使用呢。 开始前，你可能需要先准备一台公网服务器。为了安全考虑，这里使用的是最保守的配置，最后会说明如何做到完整介绍的功能。&lt;/p&gt; &#xA;&lt;p&gt;因为有了公网服务器，lamda 有很多方法可以做到这个要求，使用 &lt;strong&gt;OpenVPN&lt;/strong&gt; 来实现更加优雅。当然最方便的还是使用 frp。tools 文件夹内都提供了相关服务的 docker 镜像并且这些镜像可以一键命令生成下面的配置信息，可以转到 tools 查看使用方法。&lt;/p&gt; &#xA;&lt;p&gt;本服务使用了较为成熟的端口转发程序 &lt;a href=&#34;https://github.com/fatedier/frp&#34;&gt;fatedier/frp&lt;/a&gt;，关于如何配置服务端，请在此项目中自行探索。注意：请勿将转发后的端口绑定到公网地址，请确保你的公网服务器关闭了所有不必要的端口。 这里给你一个最简单安全的配置，可以直接使用如下命令启动服务端。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;首先在你的公网服务器上执行以下命令启动 frps（注意你可能还需要配置防火墙）&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# frps 版本需要 &amp;gt; v0.45.0&#xA;frps --token lamda --bind_addr 0.0.0.0 --bind_port 6009 --proxy_bind_addr 127.0.0.1 --allow_ports 10000-15000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;然后编写 properties.local&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;复制下列配置并修改&lt;strong&gt;服务器地址&lt;/strong&gt;为你的服务器公网IP&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;fwd.host=服务器地址&#xA;fwd.port=6009&#xA;fwd.rport=12345&#xA;fwd.token=lamda&#xA;fwd.protocol=tcp&#xA;fwd.enable=true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;将其追加或者写入到 properties.local，重启 LAMDA 即可。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;如何透过上面的转发使用 lamda（需要在部署 frps 的那台公网服务器上使用，因为我们绑定了转发的端口到 127.0.0.1）&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from lamda.client import *&#xA;# 端口为上面的 rport&#xA;d = Device(&#34;127.0.0.1&#34;, port=12345)&#xA;# 浏览器打开 http://127.0.0.1:12345 即可访问远程桌面&#xA;# 其余任何接口调用实现均统一，无需做任何改动&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;如何批量转发而不用每次都改写一下 rport 配置&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;如果你需要一次设置多台机器且不在乎每台机器绑定的端口， 你可以将上方配置中的 &lt;code&gt;fwd.rport&lt;/code&gt; 值改为 0，这将导致你的设备被随机绑定到 &lt;code&gt;10000-15000&lt;/code&gt; 的端口范围中， 你可以通过后期轮训端口范围来定位设备转发绑定的对应端口。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;我就是想在任意地方都能连接到设备&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;首先，为了安全起见不建议这么做，如果确实需要这样用的话，建议使用 OpenVPN 将设备和你的电脑置于同一网段的方法来访问。 如果你仍准备使用上述 frp 的方法实现任意访问，请先确保 LAMDA 服务启动时使用了&lt;strong&gt;PEM证书&lt;/strong&gt;，并将启动 frps 命令时的 &lt;code&gt;--proxy_bind_addr 127.0.0.1&lt;/code&gt; 改为 &lt;code&gt;--proxy_bind_addr 0.0.0.0&lt;/code&gt;，这将导致 12345 端口直接绑定到公网。如果你未使用PEM证书启动 lamda，任何人都将可以访问，这是&lt;strong&gt;非常非常危险&lt;/strong&gt;的。 其次需要注意，web 远程桌面的流量始终都是 http 的，如果有人在你和服务器通信之间进行中间人，你的登录凭证可能会被窃取。当然，如果此期间不用 web 桌面将不存在这个问题。&lt;/p&gt; &#xA;&lt;h2&gt;读写内置键值存储器&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Storage 是 LAMDA 内置的键值存储，它具有持久性，即使 LAMDA 重启，你依然可以在下次 LAMDA 启动时读取这些变量。 该 Storage 让你可以在设备中持久化存储信息以供不同的 client API 进程读取。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Storage 的总容量为 128MB，请勿用来存储大量数据。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 获取一个 Storage 对象&#xA;storage = d.stub(&#34;Storage&#34;)&#xA;&#xA;# 清空 Storage 中的所有信息（包括容器）&#xA;storage.clear()&#xA;&#xA;# 清除名为 container_name 的容器中存储的所有键值&#xA;storage.remove(&#34;container_name&#34;)&#xA;&#xA;# 获取一个键值容器对象&#xA;container = storage.use(&#34;container_name&#34;)&#xA;&#xA;# 存储在 Storage 中的 key_name 和 container_name 是安全的&#xA;# 无法通过任何方式读取原始字符串，你必须完整知道容器名称以及 key 才能从容器中读取数据&#xA;# 如果还需要安全的存储值，比如，当该设备会被其他人使用，但是你不想存储的配置被其他人读取，&#xA;# 你可以像以下示例，提供加解密方法，这样即使 LAMDA 被非法访问&#xA;# 非预期的访问者也无法解密容器中存储的任何明文信息&#xA;from lamda.client import FernetCryptor&#xA;# 获取键值容器对象，对该容器的读写均通过 FernetCryptor 加解密&#xA;container = storage.use(&#34;container_name&#34;, cryptor=FernetCryptor, key=&#34;this_is_password&#34;)&#xA;&#xA;# 当然，你也可以自己编写加解密流程&#xA;from lamda.client import BaseCryptor&#xA;class MyCryptor(BaseCryptor):&#xA;  def __init__(self, cryptor_arg=0):&#xA;    # 这里写入你的加解密初始化过程&#xA;  def encrypt(self, data):&#xA;    # 这里写入你的加密过程&#xA;    return data&#xA;  def decrypt(self, data):&#xA;    # 这里写入你的解密过程&#xA;    return data&#xA;# 获取键值容器对象，对该容器的读写均通过 MyCryptor 加解密&#xA;container = storage.use(&#34;container_name&#34;, cryptor=MyCryptor, cryptor_arg=999)&#xA;&#xA;&#xA;# 获取 key_name 的值（如果不存在，则返回 None）&#xA;container.get(&#34;key_name&#34;)&#xA;&#xA;# 获取 key_name 的生存时间（-2 为该键不存在，-1 为无限生存时间）&#xA;# 其他正整数则为该 key 的剩余存活秒数&#xA;container.ttl(&#34;key_name&#34;)&#xA;&#xA;# 设置 key_name 的值为 &#34;value&#34;，并且 10 秒后自动删除&#xA;container.setex(&#34;key_name&#34;, &#34;value&#34;, 10)&#xA;&#xA;# 设置 key_name 的生存时间为 60 秒&#xA;# 60 秒后，该键值将自动被删除&#xA;container.expire(&#34;key_name&#34;, 60)&#xA;&#xA;# 仅当 key_name 不存在时设置该键值&#xA;container.setnx(&#34;key_name&#34;, &#34;value&#34;)&#xA;&#xA;# 设置 key_name 的值为 &#34;value&#34;&#xA;# 其中，值支持任何 msgpack 可序列化的变量&#xA;container.set(&#34;key_name&#34;, [1, 2, 3])&#xA;container.set(&#34;key_name&#34;, {&#34;john&#34;: &#34;due&#34;})&#xA;container.set(&#34;key_name&#34;, b&#34;value&#34;)&#xA;container.set(&#34;key_name&#34;, &#34;value&#34;)&#xA;&#xA;# 检查 key_name 是否存在于容器中&#xA;container.exists(&#34;key_name&#34;)&#xA;# 删除 key_name&#xA;container.delete(&#34;key_name&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;读写系统属性&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;设置/读取系统属性&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 获取 ro.secure 的值&#xA;d.getprop(&#34;ro.secure&#34;)&#xA;&#xA;# 设置 ro.secure 的值&#xA;d.setprop(&#34;ro.secure&#34;, &#34;0&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;读写系统设置&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;设置/读取安卓系统设置&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;settings = d.stub(&#34;Settings&#34;)&#xA;&#xA;# 如果你对以下 screen_brightness 等字符串表示疑惑，请查看下列文档。有些常量&#xA;# 在不同版本的安卓可能并不兼容，以及部分厂商会有自定义的变量，需要注意。&#xA;&#xA;# https://developer.android.com/reference/android/provider/Settings.System&#xA;# https://developer.android.com/reference/android/provider/Settings.Secure&#xA;# https://developer.android.com/reference/android/provider/Settings.Global&#xA;&#xA;# 你可以使用如下代码将系统屏幕的亮度设置为手动&#xA;settings.put_system(&#34;screen_brightness_mode&#34;, &#34;0&#34;)&#xA;&#xA;# 示例：获取并修改屏幕亮度为 5 (0-255)&#xA;settings.get_system(&#34;screen_brightness&#34;)&#xA;settings.put_system(&#34;screen_brightness&#34;, &#34;5&#34;)&#xA;&#xA;# 示例：关闭开发者选项&#xA;settings.get_global(&#34;development_settings_enabled&#34;)&#xA;settings.put_global(&#34;development_settings_enabled&#34;, &#34;0&#34;)&#xA;&#xA;# 示例&#xA;settings.get_secure(&#34;screensaver_enabled&#34;)&#xA;settings.put_secure(&#34;screensaver_enabled&#34;, &#34;0)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;获取设备运行状态&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;status = d.stub(&#34;Status&#34;)&#xA;&#xA;# 获取设备启动时间&#xA;status.get_boot_time()&#xA;&#xA;# 获取设备磁盘使用情况&#xA;status.get_disk_usage(mountpoint=&#34;/data&#34;)&#xA;&#xA;# 获取电池信息&#xA;status.get_battery_info()&#xA;# 获取CPU使用情况&#xA;status.get_cpu_info()&#xA;# 获取总体磁盘读写情况&#xA;status.get_overall_disk_io_info()&#xA;# 获取用户数据磁盘的读写情况 (userdata)&#xA;status.get_userdata_disk_io_info()&#xA;# 获取总体网络收发情况&#xA;status.get_overall_net_io_info()&#xA;# 获取 wlan0 接口的网络收发情况&#xA;status.get_net_io_info(&#34;wlan0&#34;)&#xA;# 获取内存使用情况&#xA;status.get_mem_info()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;在设备上执行命令&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;在设备后台，前台执行 shell 脚本/命令&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 执行前台脚本（执行时间短（0-10秒内）的脚本）&#xA;cmd = d.execute_script(&#34;whoami&#34;)&#xA;print (cmd.exitstatus)&#xA;print (cmd.stdout)&#xA;print (cmd.stderr)&#xA;&#xA;# 执行后台脚本（执行时间长的脚本）&#xA;# 对于后台脚本，因考虑可能用户写出死循环脚本无限输出导致内存占满等问题&#xA;# 暂时无法获知其执行结果&#xA;ID = d.execute_background_script(&#34;sleep 100; exit 0;&#34;)&#xA;# 检查后台脚本是否结束&#xA;d.is_background_script_finished(ID)&#xA;# 强制结束后台脚本&#xA;d.kill_background_script(ID)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;使系统可调试&lt;/h2&gt; &#xA;&lt;p&gt;如果你需要使用JEB，IDA等动态分析，你可能需要设置此标志才能进行，当然也内置了这个功能，你可以这么做而无需永久修改 &lt;code&gt;ro.debuggable&lt;/code&gt;。 但是记住，这个接口你并不是一定需要调用，仅当你看到任何文章/教程让你修改 &lt;code&gt;ro.debuggable&lt;/code&gt; 时使用。&lt;/p&gt; &#xA;&lt;p&gt;注意：调用此接口成功后，系统会自动重启，你可能仍需像首次启动时等待一段时间到本框架恢复&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;慎用，此功能可能不稳定且可能随时移除&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;debug = d.stub(&#34;Debug&#34;)&#xA;&#xA;r = debug.set_debuggable()&#xA;print (r)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;启动 IDA 调试服务&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;内置了 IDA 7.5 服务端&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;debug = d.stub(&#34;Debug&#34;)&#xA;&#xA;# 启动 IDA 32 服务端（端口可自定义）&#xA;debug.start_ida(port=22032)&#xA;# 检查是否已启动&#xA;debug.is_ida_running()&#xA;# 关闭 IDA 32 服务端&#xA;debug.stop_ida()&#xA;# 如果调试的是64位程序，将方法名中的 ida 替换为 ida64 即可&#xA;# 例如&#xA;debug.start_ida64(port=22064)&#xA;#&#xA;# 如果需要自定义 ida-server 的环境变量例如 IDA_LIBC_PATH (同样适用于 start_ida)&#xA;debug.start_ida64(port=22064, IDA_LIBC_PATH=&#34;/apex/com.android.runtime/lib64/bionic/libc.so&#34;)&#xA;# 当你调试的目标程序是32位时使用 start_ida&#xA;# 否则使用 start_ida64&#xA;# 当你的设备系统为32位平台时，start_ida64 将会无效&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;无线连接内置的 WIFI ADB&lt;/h2&gt; &#xA;&lt;p&gt;此 ADB 非全功能 adb，仅支持 shell,pull,push,forward,reverse 等常用功能 通过此功能你将&lt;strong&gt;无需开启开发者模式&lt;/strong&gt;即可连接最高权限的 adb。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;注：jdwp 调试相关功能具有唯一性，与系统内置存在冲突所以此 adb &lt;strong&gt;目前&lt;/strong&gt;不支持。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# LAMDA 内置的 adb 服务完全独立于系统本身提供的 adb 服务&#xA;# 所以在使用之前需要先手动调用以下接口将你的 adb 公钥安装至设备上&#xA;# 否则直接连接将会显示未授权（系统设置开发者模式中授权的秘钥与内置 adb 并不通用）&#xA;#&#xA;# tools 目录下的 adb_pubkey.py 封装了下面接口的安装过程&#xA;# 你可以使用该脚本一键授权，允许本机连接，请查看其 README，以下代码仅做参考说明&#xA;#&#xA;# 这个秘钥文件位于你电脑上的 ~/.android 或者 C:\\Users\xxxx\.android，文件名为 adbkey.pub&#xA;# 如果不存在这个文件但是存在文件 adbkey，请切换到该目录并执行命令&#xA;# adb pubkey adbkey &amp;gt;adbkey.pub 来生成 adbkey.pub&#xA;#&#xA;# 随后使用 python 代码来拼接这个生成的 adbkey.pub 路径&#xA;import os&#xA;keypath = os.path.join(&#34;~&#34;, &#34;.android&#34;, &#34;adbkey.pub&#34;)&#xA;abs_keypath = os.path.expanduser(keypath)&#xA;print (abs_keypath)&#xA;#&#xA;# 然后安装这个 adbkey.pub 到 LAMDA&#xA;d.install_adb_pubkey(abs_keypath)&#xA;# 这样你就可以连接内置 adb 了&#xA;# 通过命令 adb connect 192.168.0.2:65000 连接到设备&#xA;# 你完全可以将其理解为 WIFI ADB&#xA;#&#xA;# 或者如果你需要从 LAMDA 内置 adb 移除这个公钥&#xA;d.uninstall_adb_pubkey(abs_keypath)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;文件操作&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;将文件上传至设备或从其下载文件（支持大文件）&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 下载文件到本地&#xA;d.download_file(&#34;/verity_key&#34;, &#34;写入到的本地文件&#34;)&#xA;&#xA;# 下载文件到 内存/已打开的文件&#xA;from io import BytesIO&#xA;fd = BytesIO()&#xA;d.download_fd(&#34;/verity_key&#34;, fd)&#xA;print (fd.getvalue())&#xA;&#xA;# 注意必须使用 w+b 模式打开被写入文件&#xA;fd = open(&#34;写入到的本地文件&#34;, &#34;wb&#34;)&#xA;d.download_fd(&#34;/verity_key&#34;, fd)&#xA;&#xA;# 上传文件到设备&#xA;d.upload_file(&#34;本地文件路径.txt&#34;, &#34;/data/usr/上传到设备上的文件.txt&#34;)&#xA;&#xA;# 从 内存/已打开的文件 上传文件&#xA;from io import BytesIO&#xA;d.upload_fd(BytesIO(b&#34;fileContent&#34;), &#34;/data/usr/上传到设备上的文件.txt&#34;)&#xA;&#xA;# 注意必须使用 rb 模式打开文件&#xA;fd = open(&#34;myfile.txt&#34;, &#34;rb&#34;)&#xA;d.upload_fd(fd, &#34;/data/usr/上传到设备上的文件.txt&#34;)&#xA;&#xA;# 删除设备上的文件&#xA;d.delete_file(&#34;/data/usr/文件.txt&#34;)&#xA;&#xA;# 修改设备上的文件权限&#xA;d.file_chmod(&#34;/data/usr/文件.txt&#34;, mode=0o777)&#xA;&#xA;# 获取设备上文件的信息&#xA;d.file_stat(&#34;/data/usr/文件.txt&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;关机重启&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 关闭系统（等于关机）&#xA;d.shutdown()&#xA;# 重启系统（等于重启）&#xA;d.reboot()&#xA;&#xA;# 关闭设备上运行的 LAMDA 服务&#xA;d.exit()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;应用操作&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;列出系统上已安装的所有应用的ID&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;d.enumerate_all_pkg_names()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;列出设备上所有正在运行的应用&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;d.enumerate_running_processes()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;获取当前处于前台的应用&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;d.current_application()&#xA;&#xA;# 等价于&#xA;d.application(d.current_application().applicationId)&#xA;&#xA;# 获取当前前台的 activity&#xA;d.current_application().activity&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;启动、获取 Activity&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入 FLAG_ACTIVITY* 常量定义&#xA;from lamda.const import *&#xA;&#xA;# 获取系统中最近的5条活动（最多12条）&#xA;activities = d.get_last_activities(count=5)&#xA;print (activities)&#xA;&#xA;# 你可以直接重放最后一条活动（注意并不是所有活动都可以重放）&#xA;activity = activities[-1]&#xA;print (activity)&#xA;d.start_activity(**activity)&#xA;&#xA;# 手动组装 activity 信息&#xA;# 附加数据只支持 boolean, int, short, long, double, float 以及 string 类型&#xA;d.start_activity(action=&#34;***&#34;, category=&#34;***&#34;, component=&#34;***&#34;,&#xA;                 extras={&#34;boolean&#34;: False, &#34;int&#34;: 1, &#34;string&#34;: &#34;act&#34;, &#34;float&#34;: 1.123},&#xA;                 flags=FLAG_ACTIVITY_NEW_TASK|FLAG_ACTIVITY_CLEAR_TASK,&#xA;                 data=&#34;***&#34;, debug=False)&#xA;&#xA;# flags 的定义请参考文档&#xA;# https://developer.android.com/reference/android/content/Intent#FLAG_ACTIVITY_BROUGHT_TO_FRONT&#xA;# flags 以及 debug 参数不是必须的，只是多了一种可能&#xA;&#xA;# 拨打 10000 客服电话&#xA;d.start_activity(action=&#34;android.intent.action.CALL&#34;, data=&#34;tel:10000&#34;)&#xA;&#xA;# debug 参数代表：是否以调试模式启动该活动&#xA;# 如果你知道 Waitting for debugger，那么它可能对你有用&#xA;# 你可以像下面这样以调试模式启动一个应用（你的设备或者APP需要是可调试的）&#xA;la = d.application(&#34;com.android.settings&#34;).query_launch_activity()&#xA;d.start_activity(**la, debug=True)&#xA;&#xA;# 例如：启动 设置 APP（当然这几乎等价于直接启动app）&#xA;d.start_activity(action=&#34;android.intent.action.MAIN&#34;,&#xA;                 category=&#34;android.intent.category.LAUNCHER&#34;,&#xA;                 component=&#34;com.android.settings/.Settings&#34;)&#xA;&#xA;# 例如：进入证书设置&#xA;d.start_activity(action=&#34;com.android.settings.TRUSTED_CREDENTIALS&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;授予/撤销 APP 权限&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;注意，你应在APP未启动时进行权限设置，在APP请求权限时调用并不会产生帮你点击允许的效果。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;app = d.application(&#34;com.my.app&#34;)&#xA;&#xA;#导入 PERMISSION_READ_PHONE_STATE 常量（版本&amp;gt;3.90）&#xA;from lamda.const import *&#xA;&#xA;# 获取应用所有权限&#xA;app.permissions()&#xA;# 授予 READ_PHONE_STATE 权限&#xA;app.grant(PERMISSION_READ_PHONE_STATE, mode=GrantType.GRANT_ALLOW)&#xA;# 拒绝 READ_PHONE_STATE 权限&#xA;app.grant(PERMISSION_READ_PHONE_STATE, mode=GrantType.GRANT_DENY)&#xA;# 检查是否已授予权限&#xA;app.is_permission_granted(PERMISSION_READ_PHONE_STATE)&#xA;# 撤销已授予的权限&#xA;app.revoke(PERMISSION_READ_PHONE_STATE)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;清除应用缓存，重置应用&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 删除应用的缓存数据&#xA;app = d.application(&#34;com.my.app&#34;)&#xA;app.delete_cache()&#xA;# 重置应用数据&#xA;app.reset_data()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;启动/停止应用&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;app = d.application(&#34;com.my.app&#34;)&#xA;&#xA;# 启动应用&#xA;app.start()&#xA;# 检查应用是否正在前台运行&#xA;app.is_foreground()&#xA;# 关闭应用&#xA;app.stop()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;其他&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;app = d.application(&#34;com.my.app&#34;)&#xA;# 获取应用信息&#xA;app.info()&#xA;&#xA;# 检查应用是否已安装&#xA;app.is_installed()&#xA;# 卸载应用&#xA;app.uninstall()&#xA;&#xA;# 查询该应用的启动 Activity（入口活动）&#xA;app.query_launch_activity()&#xA;&#xA;# 启用应用&#xA;app.enable()&#xA;# 禁用应用&#xA;app.disable()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;WIFI操作&lt;/h2&gt; &#xA;&lt;p&gt;目前WIFI操作部分功能由于可能导致设备异常未实现，仅介绍部分实现的功能&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;wifi = d.stub(&#34;Wifi&#34;)&#xA;&#xA;# 获取wifi bssid,ssid ip 等相关信息&#xA;wifi.status()&#xA;&#xA;# 获取黑名单中的所有 bssid&#xA;wifi.blacklist_get_all()&#xA;&#xA;# 将bssid加入黑名单(将不会显示在wifi列表)&#xA;wifi.blacklist_add(&#34;3c:06:aa:8a:55:66&#34;)&#xA;&#xA;# 清空所有黑名单&#xA;wifi.blacklist_clear()&#xA;&#xA;# 执行 wifi 扫描&#xA;wifi.scan()&#xA;&#xA;# 获取周边 wifi 扫描结果&#xA;wifi.scan_results()&#xA;&#xA;# 获取当前wifi的mac地址&#xA;wifi.get_mac_addr()&#xA;&#xA;# 获取 wifi 信号强度，链接速率&#xA;wifi.signal_poll()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;基本UI操作&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;获取设备信息&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;d.device_info()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;息屏/亮屏相关&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 息屏&#xA;d.sleep()&#xA;# 亮屏&#xA;d.wake_up()&#xA;# 屏幕是否点亮&#xA;d.is_screen_on()&#xA;# 屏幕是否已锁定&#xA;d.is_screen_locked()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;剪切板&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;d.set_clipboard(&#34;剪切板内容&#34;)&#xA;&#xA;# 获取剪切板内容（不支持安卓10+）&#xA;d.get_clipboard()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;物理按键&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 此方法可使用如下17种按键&#xA;# KEY_BACK&#xA;# KEY_CAMERA&#xA;# KEY_CENTER&#xA;# KEY_DELETE&#xA;# KEY_DOWN&#xA;# KEY_ENTER&#xA;# KEY_HOME&#xA;# KEY_LEFT&#xA;# KEY_MENU&#xA;# KEY_POWER&#xA;# KEY_RECENT&#xA;# KEY_RIGHT&#xA;# KEY_SEARCH&#xA;# KEY_UP&#xA;# KEY_VOLUME_DOWN&#xA;# KEY_VOLUME_MUTE&#xA;# KEY_VOLUME_UP&#xA;d.press_key(Keys.KEY_BACK)&#xA;&#xA;# 同时为了可以使用更多按键，也可以使用这个方法&#xA;d.press_keycode(KeyCodes.KEYCODE_CALL)&#xA;# 可使用的 KEYCODE 可以自行查看此文档&#xA;# https://developer.android.com/reference/android/view/KeyEvent#KEYCODE_0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;屏幕截图&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;quality = 60 # 截图质量，默认为全画质&#xA;d.screenshot(quality).save(&#34;screenshot.png&#34;)&#xA;# 截取屏幕上特定区域的图像&#xA;# Bound 的参数 top,left 等定义：&#xA;&#xA;# top:     从距离屏幕顶部向下数 top 个像素&#xA;# bottom:  从距离屏幕顶部向下数 bottom 个像素&#xA;# left:    从距离屏幕左侧向右数 left 个像素&#xA;# right:   到距离屏幕左侧向右数 right 个像素&#xA;&#xA;# 正常情况下 top 永远小于 bottom，left 永远小于 right&#xA;bound = Bound(top=50, bottom=80, left=50, right=80)&#xA;d.screenshot(quality, bound=bound).save(&#34;partial.png&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;点击屏幕上的一个点&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;d.click(Point(x=100, y=100))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;点按点A并将其拖动到点B&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A = Point(x=100, y=100)&#xA;B = Point(x=500, y=500)&#xA;&#xA;d.drag(A, B)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;从点A滑动到点B&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A = Point(x=100, y=100)&#xA;B = Point(x=500, y=500)&#xA;&#xA;d.swipe(A, B)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;稍复杂的多点滑动（九宫格解锁）&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;p1 = Point(x=100, y=100)&#xA;p2 = Point(x=500, y=500)&#xA;p3 = Point(x=200, y=200)&#xA;&#xA;# 从点P1滑动到点P2随后滑动到点P3，可任意个点&#xA;d.swipe_points(p1, p2, p3)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;打开通知栏/快捷设置栏&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;d.open_notification()&#xA;d.open_quick_settings()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;获取页面布局描述XML&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;d.dump_window_hierarchy().getvalue()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;等待界面布局停止刷新&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 单位是毫秒，5*1000 代表5秒&#xA;d.wait_for_idle(5*1000)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;获取最近的 toast&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;d.get_last_toast()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;进阶UI操作&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Selector&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;界面布局检视，首先你需要打开设备的 web 远程桌面。随后，点击远程桌面右上角的眼睛图标进入，此时你将不能再滑动左侧屏幕，你可以点击屏幕上的虚线框来查看对应元素的信息，你可以将其中的部分属性作为 Selector 的参数。 再次点击眼睛图标将关闭布局检视，布局检视并不会随着页面的改变而刷新，它始终是你按下快捷键那一刻的屏幕布局，如果需要刷新布局请手动按下快捷键 &lt;code&gt;CTRL+R&lt;/code&gt;。&lt;/p&gt; &#xA;&lt;p&gt;正常情况下，我们只会使用 &lt;code&gt;resourceId&lt;/code&gt;, &lt;code&gt;clickable&lt;/code&gt;, &lt;code&gt;text&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt; 作为参数。 如果元素存在正常的 resourceId，优先使用其作为 Selector，即：&lt;code&gt;Selector(resourceId=&#34;com.android.systemui:id/mobile_signal_single&#34;)&lt;/code&gt;。 对于无 resourceId，则会使用其 text，即：&lt;code&gt;Selector(text=&#34;点击进入&#34;)&lt;/code&gt;，或者更模糊一点 &lt;code&gt;Selector(textContains=&#34;点击&#34;)&lt;/code&gt; description 与 text 同理，但是 description 用的会比较少。&lt;/p&gt; &#xA;&lt;p&gt;当然，Selector 不止可以使用一个参数，你可以做其他组合，例如 &lt;code&gt;Selector(text=&#34;点击进入&#34;, clickable=True)&lt;/code&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;注意：很少直接用 Selector()，大部分情况下，使用 d() 来进行。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;所有常见的匹配参数：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;text                    文本完全匹配&#xA;textContains            文本包含匹配&#xA;textStartsWith          文本起始匹配&#xA;className               类名匹配&#xA;description             描述完全匹配&#xA;descriptionContains     描述包含匹配&#xA;descriptionStartsWith   描述起始匹配&#xA;clickable               可以点击&#xA;longClickable           可以长按&#xA;scrollable              可滚动&#xA;resourceId              资源ID匹配&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;大部分情况下，你不会直接用到 &lt;code&gt;Selector&lt;/code&gt;，但是间接使用无处不在。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;元素操作&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;上文都是介绍了如何坐标点击这种随意性的东西，现在开始介绍如何操作固定目标元素。首先，你需要知道如何选定元素。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 选择界面上的包含文字 被测APP 的元素&#xA;element = d(textContains=&#34;被测APP&#34;)&#xA;# 当然，你不一定要这样赋值到 element，也可直接使用 d(textContains=&#34;被测APP&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;好了，现在你知道了如何获取元素了，当然，这时并没有获取到，只是代表，你想要在当前界面操作这个元素，下面开始操作。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 我们现在假设，界面上这个 被测APP 是手机上被测APP的图标名称（图标下面的名称）。&#xA;element = d(textContains=&#34;被测APP&#34;)&#xA;# 是否存在该元素&#xA;element.exists()&#xA;# 点击该元素，不存在则会抛出异常&#xA;# Corner.COR_CENTER 代表点击该元素中心点，你可查看 COR_CENTER 定义获取其他可点击的位置&#xA;element.click(corner=Corner.COR_CENTER)&#xA;&#xA;# 点击该元素，不存在不会抛出异常&#xA;element.click_exists(corner=Corner.COR_CENTER)&#xA;&#xA;# 长按该元素，不存在则会抛出异常&#xA;element.long_click(corner=Corner.COR_CENTER)&#xA;&#xA;# 获取元素信息&#xA;element.info()&#xA;&#xA;# 获取元素的中心点坐标&#xA;element.info().bounds.center()&#xA;&#xA;# 获取元素的左上点坐标&#xA;element.info().bounds.corner(&#34;top-left&#34;)&#xA;&#xA;# 获取元素的高度&#xA;element.info().bounds.height&#xA;&#xA;# 获取元素的宽度&#xA;element.info().bounds.width&#xA;&#xA;# 获取元素个数&#xA;element.count()&#xA;&#xA;# 等待元素出现，最多等待10秒&#xA;element.wait_for_exists(10*1000)&#xA;&#xA;# 等待元素消失，最多等待10秒&#xA;element.wait_until_gone(10*1000)&#xA;&#xA;# 获取该元素的截图（不是全屏，只是该元素）&#xA;# quality 为截图质量 1-100&#xA;element.screenshot(quality=60)&#xA;&#xA;# 将此 APP 拖动归类到 购物 文件夹（依据实际情况修改）&#xA;element.drag_to(Selector(text=&#34;购物&#34;))&#xA;&#xA;#########&#xA;# 查找同级或者子级元素&#xA;#########&#xA;# 有时候会有一些重复元素或者无明显特征的元素，很难去定位&#xA;# 这时你可以通过查找子级/同级元素的方法来缩小查找范围&#xA;# 子级元素，举例为：一个聊天登录框，里面的输入框即为登录框的子级元素&#xA;# 同级元素，举例为：聊天输入框里面的用户名和密码框为同级原始（正常情况下）&#xA;form = d(resourceId=&#34;login_form&#34;)&#xA;form.child(index=1)&#xA;# 这将获取到 login_form 下 index 为 0 的元素&#xA;form.child(index=1).sibling()&#xA;# 你也这样来找与 login_form 同级的找回密码按钮&#xA;#（其实已经可以通过字符串判断了，就不需要这样做了，这里只是演示）&#xA;form.sibling(textContains=&#34;找回密码&#34;)&#xA;# 它们本身就是一个element，你可以对其做任何 element 的操作&#xA;&#xA;&#xA;############################&#xA;# 现在 element 改变了其意义，变为选择了输入框&#xA;############################&#xA;&#xA;# 示例为：在一加搜索应用界面的搜索框输入 被测APP&#xA;&#xA;# 注意，不要直接往看似输入框的地方输入文字，可能并无法输入&#xA;# 有些输入框需要点击一次才会进入真正的输入框，请使用此真正输入框的资源ID&#xA;element = d(resourceId=&#34;net.oneplus.launcher:id/search_all_apps&#34;)&#xA;element.set_text(&#34;被测APP&#34;)&#xA;&#xA;# 获取输入的内容&#xA;element.get_text()&#xA;&#xA;# 清空刚刚输入的内容&#xA;element.clear_text_field()&#xA;&#xA;# 配合点击搜索，来完成一次类人的搜索操作。&#xA;&#xA;&#xA;# 滑动操作（列表上下滑动翻页）&#xA;# 注意，这些操作并不保证精度，下面这些方法正常情况下都并不需要选择器，&#xA;# 但是你可根据实际情况自行加入选择器&#xA;&#xA;# 向上滑动， step 自行调整，越多会越慢，比较适合精度要求较高的滑动&#xA;d().swipe(direction=Direction.DIR_UP, step=32)&#xA;# 其他滑动方向：&#xA;#DIR_UP     向上滑动&#xA;#DIR_LEFT   向左滑动&#xA;#DIR_DOWN   向下滑动&#xA;#DIR_RIGHT  向右滑动&#xA;&#xA;#########&#xA;# fling：甩动，即正常人滑动屏幕的行为，较快&#xA;#########&#xA;# 从上向下&#xA;d().fling_from_top_to_bottom()&#xA;# 从下往上&#xA;d().fling_from_bottom_to_top()&#xA;# 从左往右&#xA;d().fling_from_left_to_right()&#xA;# 从右往左&#xA;d().fling_from_right_to_left()&#xA;&#xA;# 其他，一直向下/左右上滑，直到滑动到底&#xA;# 因为并不是一定可以滑动到底或者检测到滑动到底&#xA;# 所以 max_swipes 参数是必须的&#xA;d().fling_from_top_to_bottom_to_end(max_swipes=32)&#xA;d().fling_from_bottom_to_top_to_end(max_swipes=32)&#xA;d().fling_from_left_to_right_to_end(max_swipes=32)&#xA;d().fling_from_right_to_left_to_end(max_swipes=32)&#xA;&#xA;#########&#xA;# scroll: 比较机械性的滑动&#xA;#########&#xA;step = 60&#xA;max_swipes = 32&#xA;# 从上往下滑动 step 步&#xA;d().scroll_from_top_to_bottom(step)&#xA;# 从下往上滑动 step 步&#xA;d().scroll_from_bottom_to_top(step)&#xA;# 从左往右滑动 step 步&#xA;d().scroll_from_left_to_right(step)&#xA;# 从右往左滑动 step 步&#xA;d().scroll_from_right_to_left(step)&#xA;&#xA;# 其他，一直向下/左右上滑，直到滑动到底&#xA;# 同上文 fling 描述&#xA;d().scroll_from_top_to_bottom_to_end(max_swipes, step)&#xA;d().scroll_from_bottom_to_top_to_end(max_swipes, step)&#xA;d().scroll_from_left_to_right_to_end(max_swipes, step)&#xA;d().scroll_from_right_to_left_to_end(max_swipes, step)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;监视器&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;监视器用来监听界面变化并在满足条件时执行设定的操作（点击元素或者按键），这可能对性能或者需要人工介入时产生影响，所以请谨慎使用，默认未开启。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 启动监视器循环&#xA;d.set_watcher_loop_enabled(True)&#xA;&#xA;# 获取监视器是否已启动&#xA;d.get_watcher_loop_enabled()&#xA;&#xA;# 移除系统中应用的所有 watcher，建议每次使用前都执行防止前面任务注册的未删除影响正常处理流程&#xA;d.remove_all_watchers()&#xA;&#xA;# 获取系统中所有已应用的 watcher 名称列表&#xA;d.get_applied_watchers()&#xA;&#xA;# 彻底移除一个 watcher&#xA;d.remove_watcher(name)&#xA;&#xA;# 应用watcher到系统中（当 watcher_loop 启动，此watcher将会生效）&#xA;d.set_watcher_enabled(name, True)&#xA;# 取消应用&#xA;d.set_watcher_enabled(name, False)&#xA;&#xA;# 获取此 watcher 是否应用&#xA;d.get_watcher_enabled(name)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;监视系统界面出现某个元素的次数&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 做一些测试前的清理，当然，并不是每 register 一个就需要这样&#xA;# 只是为了确保测试过程不被干扰&#xA;d.remove_all_watchers()&#xA;d.set_watcher_loop_enabled(True)&#xA;&#xA;# 应用监视界面出现 好的 的次数&#xA;# 第二个参数为数组，可以给多个 Selector 表示条件都满足才会记录&#xA;# 但是不建议超过三个&#xA;d.register_none_op_watcher(&#34;RecordElementAppearTimes&#34;, [Selector(textContains=&#34;好的&#34;)])&#xA;d.set_watcher_enabled(&#34;RecordElementAppearTimes&#34;, True)&#xA;&#xA;# ... 做满足条件的操作&#xA;&#xA;# 获取记录的次数&#xA;d.get_watcher_triggered_count(&#34;RecordElementAppearTimes&#34;)&#xA;&#xA;# 重置记录的次数&#xA;d.reset_watcher_triggered_count(&#34;RecordElementAppearTimes&#34;)&#xA;&#xA;# 移除&#xA;d.remove_watcher(&#34;RecordElementAppearTimes&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;当界面出现匹配元素时点击某个元素&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 做一些测试前的清理，当然，并不是每 register 一个就需要这样&#xA;# 只是为了确保测试过程不被干扰&#xA;d.remove_all_watchers()&#xA;d.set_watcher_loop_enabled(True)&#xA;&#xA;# 示例为，当APP启动后出现用户协议时，自动点击同意&#xA;# 第二个参数为数组，可以给多个 Selector 表示条件都满足才会点击&#xA;# 但是不建议超过三个&#xA;d.register_click_target_selector_watcher(&#34;ClickAcceptWhenShowAggrement&#34;, [Selector(textContains=&#34;用户协议&#34;)],&#xA;                                         Selector(textContains=&#34;同意&#34;, clickable=True))&#xA;d.set_watcher_enabled(&#34;ClickAcceptWhenShowAggrement&#34;, True)&#xA;&#xA;# ... 做满足条件的操作&#xA;&#xA;# 移除&#xA;d.remove_watcher(&#34;ClickAcceptWhenShowAggrement&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;当界面出现匹配元素时点击物理按键&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 做一些测试前的清理，当然，并不是每 register 一个就需要这样&#xA;# 只是为了确保测试过程不被干扰&#xA;d.remove_all_watchers()&#xA;d.set_watcher_loop_enabled(True)&#xA;&#xA;# 示例为，当界面存在 个人中心 时，按下HOME键回到启动屏幕&#xA;# 第二个参数为数组，可以给多个 Selector 表示条件都满足才会点击&#xA;# 但是不建议超过三个&#xA;d.register_press_key_watcher(&#34;PressBackWhenHomePageShows&#34;, [Selector(textContains=&#34;个人中心&#34;)], Keys.KEY_HOME)&#xA;d.set_watcher_enabled(&#34;PressBackWhenHomePageShows&#34;, True)&#xA;&#xA;# ... 做满足条件的操作&#xA;&#xA;# 移除&#xA;d.remove_watcher(&#34;PressBackWhenHomePageShows&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;接口锁&lt;/h2&gt; &#xA;&lt;p&gt;这里的基本功能让你可以锁定接口只能为当前 Device 实例使用。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 获得锁，此锁将在60秒后被自动释放，其他客户端将可以获得锁，你可以更改此时间&#xA;# 但是，如果改得太高因为异常脚本退出，你将近乎永远无法连接设备，你可能需要进行重启&#xA;# 此获得锁接口可重入，重入时等价于 _refresh_lock，建议只调用一次&#xA;d._acquire_lock(leaseTime=60)&#xA;# 刷新锁，每次调用后将锁过期时间设为此 leaseTime&#xA;# 做定期调用来保持设备锁定&#xA;d._refresh_lock(leaseTime=60)&#xA;# 释放锁，其他客户端将可以获得锁&#xA;d._release_lock()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;使用内置终端&lt;/h2&gt; &#xA;&lt;p&gt;这里的内部终端，指的是你通过 web 远程桌面或者 ssh/内置adb 连接的终端，里面内置了一些命令以及Python模块，你可以 直接在里面执行一些操作或者运行一些 Python 代码，甚至可以直接在终端内完成自控，由于兼容性考虑，adb 连接的终端不存在部分命令提示等功能。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;现在假设你已经打开了 web 远程桌面，你应该已经在页面上看到了一个 linux 终端。 执行命令 &lt;code&gt;cd&lt;/code&gt; 可以切换到家目录（默认为 &lt;code&gt;/data/usr&lt;/code&gt;），这是你的工作区，你可以在此存储文件。终端支持命令补全但不支持参数补全，你也可以在终端输入部分命令，随后通过上下键自动填补历史命令。同时，内部提供了一些命令别名，这些命令别名及功能如下。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code&gt;l                  = 命令 ls&#xA;ll                 = 命令 ls -l&#xA;la                 = 命令 ls -la&#xA;py                 = 命令 python&#xA;..                 = 切换到父目录&#xA;...                = 切换到父目录的父目录&#xA;p                  = 切换到上一个目录&#xA;t                  = 切换到 /data/local/tmp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;其他一些实用命令。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code&gt;* python           (Python)&#xA;* strace           (syscall trace)&#xA;* ltrace           (libcall trace)&#xA;* curl             (cURL)&#xA;* fsmon            (文件访问监控)&#xA;* stunnel          (流量加密)&#xA;* redir            (端口转发)&#xA;* scapy            (流量分析)&#xA;* iperf3           (网络性能测试)&#xA;* nano             (文件编辑器)&#xA;* vi               (文件编辑器)&#xA;* ncdu             (查找磁盘文件占用)&#xA;* socat            (网络工具)&#xA;* sqlite3          (读取 SQLite 数据库，支持 cipher)&#xA;* tcpdump          (流量分析)&#xA;* busybox          (命令集合)&#xA;* MemDumper        (https://github.com/kp7742/MemDumper)&#xA;* frida            (frida-tools)&#xA;* frida-ps         (frida-tools)&#xA;* frida-trace      (frida-tools)&#xA;* frida-ls-devices (frida-tools)&#xA;* frida-discover   (frida-tools)&#xA;* frida-kill       (frida-tools)&#xA;* frida-apk        (frida-tools)&#xA;* frida-create     (frida-tools)&#xA;* frida-join       (frida-tools)&#xA;* 等基础 linux 命令&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Python 也内置了一些三方库，注意无法通过 PIP 安装额外的库。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code&gt;* lamda            (自身)&#xA;* capstone         (反汇编引擎)&#xA;* keystone_engine  (汇编引擎)&#xA;* unicorn          (CPU模拟引擎)&#xA;* lief             (二进制程序解析)&#xA;* lxml             (xml/html解析)&#xA;* redis            (redis客户端)&#xA;* tornado          (web框架)&#xA;* pyOpenSSL        (OpenSSL)&#xA;* requests         (requests)&#xA;* scapy            (流量分析)&#xA;* frida            (frida)&#xA;* pyaxmlparser     (APK解析)&#xA;* xmltodict        (xml转dict)&#xA;* msgpack_python   (msgpack)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;这里不会介绍如何使用这些命令或库。&lt;/p&gt; &#xA;&lt;h2&gt;使用 Debian 环境扩展模块&lt;/h2&gt; &#xA;&lt;p&gt;LAMDA 可以通过一个模块创建可在安卓内使用的完整 Debian 环境，你可以使用 apt 安装软件以及进行代码编译，同样，你可以在此环境中自行编译及使用 bpf 相关程序。你可以在 release 页面中找到 &lt;code&gt;lamda-mod-debian-arm64-v8a.tar.gz&lt;/code&gt;（请根据你的机器架构下载对应的安装包）。 然后通过远程桌面或者 内置 adb 等方式，将 lamda-mod-debian-arm64-v8a.tar.gz 上传到设备，随后进行如下安装操作。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;注：该 debian 环境只包含基础的软件包，你需要使用 apt 自行安装 git、python3 等常用命令。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 切换到用户模块目录&#xA;cd /data/usr/modules&#xA;# 假设，该文件被你上传到了 /data/local/tmp&#xA;tar -xzf /data/local/tmp/lamda-mod-debian-arm64-v8a.tar.gz&#xA;# 解包完成&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;解包完成后，当前目录下将会存在一个 &lt;code&gt;debian&lt;/code&gt; 目录，这时，你已经完成了基本的安装，下面介绍如何进入系统。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 首先我们需要获知绝对目录，在以上情况下，绝对目录为 /data/usr/modules/debian&#xA;# 注意：每个根（debian 根系统）同时只支持一个终端实例使用&#xA;# 执行以下命令进入 debian interactive shell&#xA;debian /bin/bash&#xA;# 执行一次 id 命令&#xA;debian /bin/bash -c id&#xA;#&#xA;# 如果你并没有将模块安装于 /data/usr/modules，则需要指定模块位置&#xA;debian --root /path/to/debian /bin/bash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;下面介绍进阶使用方法，你可以使用此 debian 环境自行建立一个 ssh 服务器，或者在此 debian 环境中运行 Python 脚本。 由于每个独立的 debian 环境只支持一个终端实例使用，我们建议用 ssh 的方式，这样，你可以接入多个 shell 到此 debian 环境。 什么是 &lt;code&gt;只支持一个终端实例使用&lt;/code&gt;？就是当你执行 &lt;code&gt;debian /bin/bash&lt;/code&gt; 后并保持使用状态，如果你在其他地方继续执行此命令， 该命令将会返回错误，使你无法再次进入此根系统，除非你将之前的 &lt;code&gt;debian /bin/bash&lt;/code&gt; 退出。&lt;/p&gt; &#xA;&lt;p&gt;现在，我们介绍如何在此 debian 环境中运行一个 ssh 服务以及安装基础的 Python 环境。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 执行命令进入 debian shell&#xA;debian /bin/bash&#xA;# 现在，你应该在 debian shell 中，执行以下命令&#xA;root@localhost: apt update&#xA;root@localhost: apt install -y openssh-server procps python3 python3-pip python3-dev&#xA;root@localhost: echo &#39;PermitRootLogin yes&#39; &amp;gt;&amp;gt;/etc/ssh/sshd_config&#xA;root@localhost: echo &#39;StrictModes no&#39; &amp;gt;&amp;gt;/etc/ssh/sshd_config&#xA;root@localhost: mkdir -p /run/sshd&#xA;root@localhost: # 修改 root 密码&#xA;root@localhost: echo root:lamda|chpasswd&#xA;root@localhost: # 退出 debian 环境&#xA;root@localhost: exit&#xA;# 现在，你已经进入了 lamda 的 shell 环境，执行以下命令来启动 debian 环境中的 ssh 服务&#xA;debian /usr/sbin/sshd -D -e&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;如果你想此 debian ssh 环境随 lamda 一同启动，请执行 &lt;code&gt;crontab -e&lt;/code&gt;，并在其中写下如下规则并重启即可。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;@reboot debian /usr/sbin/sshd -D -e &amp;gt;/data/usr/sshd.log 2&amp;gt;&amp;amp;1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;现在，获取该设备的 IP 地址，随后在你的电脑上执行如下命令并输入密码 lamda 即可登录该 debian shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh root@192.168.x.x (手机IP)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;工具及教程&lt;/h1&gt; &#xA;&lt;p&gt;其中的每个文件夹下都有一份使用说明。&lt;/p&gt; &#xA;&lt;h2&gt;一键中间人&lt;/h2&gt; &#xA;&lt;p&gt;打开 &lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/tools/README.md&#34;&gt;tools/README.md&lt;/a&gt; 查看。&lt;/p&gt; &#xA;&lt;h2&gt;国际代理进行中间人&lt;/h2&gt; &#xA;&lt;p&gt;打开 &lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/tools/README.md&#34;&gt;tools/README.md&lt;/a&gt; 查看。&lt;/p&gt; &#xA;&lt;h2&gt;安装 ADB 公钥&lt;/h2&gt; &#xA;&lt;p&gt;打开 &lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/tools/README.md&#34;&gt;tools/README.md&lt;/a&gt; 查看。&lt;/p&gt; &#xA;&lt;h2&gt;OpenVPN 服务&lt;/h2&gt; &#xA;&lt;p&gt;打开 &lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/tools/README.md&#34;&gt;tools/README.md&lt;/a&gt; 查看。&lt;/p&gt; &#xA;&lt;h2&gt;SOCKS5 服务&lt;/h2&gt; &#xA;&lt;p&gt;打开 &lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/tools/README.md&#34;&gt;tools/README.md&lt;/a&gt; 查看。&lt;/p&gt; &#xA;&lt;h2&gt;端口转发服务&lt;/h2&gt; &#xA;&lt;p&gt;打开 &lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/tools/README.md&#34;&gt;tools/README.md&lt;/a&gt; 查看。&lt;/p&gt; &#xA;&lt;h2&gt;注入 Frida RPC 脚本&lt;/h2&gt; &#xA;&lt;p&gt;打开 &lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/tools/README.md&#34;&gt;tools/README.md&lt;/a&gt; 查看。&lt;/p&gt; &#xA;&lt;h2&gt;生成加密连接证书&lt;/h2&gt; &#xA;&lt;p&gt;打开 &lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/tools/README.md&#34;&gt;tools/README.md&lt;/a&gt; 查看。&lt;/p&gt; &#xA;&lt;h2&gt;列出内网设备&lt;/h2&gt; &#xA;&lt;p&gt;打开 &lt;a href=&#34;https://raw.githubusercontent.com/rev1si0n/lamda/5.0/tools/README.md&#34;&gt;tools/README.md&lt;/a&gt; 查看。&lt;/p&gt; &#xA;&lt;p&gt;如果仍有疑问，请加入社区讨论：&lt;a href=&#34;https://t.me/lamda_dev&#34;&gt;电报 t.me/lamda_dev&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>langchain-ai/chat-langchain</title>
    <updated>2023-09-20T01:38:37Z</updated>
    <id>tag:github.com,2023-09-20:/langchain-ai/chat-langchain</id>
    <link href="https://github.com/langchain-ai/chat-langchain" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;🦜️🔗 Chat LangChain&lt;/h1&gt; &#xA;&lt;p&gt;This repo is an implementation of a locally hosted chatbot specifically focused on question answering over the &lt;a href=&#34;https://langchain.readthedocs.io/en/latest/&#34;&gt;LangChain documentation&lt;/a&gt;. Built with &lt;a href=&#34;https://github.com/hwchase17/langchain/&#34;&gt;LangChain&lt;/a&gt;, &lt;a href=&#34;https://fastapi.tiangolo.com/&#34;&gt;FastAPI&lt;/a&gt;, and &lt;a href=&#34;https://nextjs.org&#34;&gt;Next.js&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Deployed version: &lt;a href=&#34;https://chat.langchain.com&#34;&gt;chat.langchain.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The app leverages LangChain&#39;s streaming support and async API to update the page in real time for multiple users.&lt;/p&gt; &#xA;&lt;h2&gt;✅ Running locally&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install backend dependencies: &lt;code&gt;poetry install&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;python ingest.py&lt;/code&gt; to ingest LangChain docs data into the Weaviate vectorstore (only needs to be done once). &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;You can use other &lt;a href=&#34;https://langchain.readthedocs.io/en/latest/modules/document_loaders.html&#34;&gt;Document Loaders&lt;/a&gt; to load your own data into the vectorstore.&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;Run the backend with &lt;code&gt;make start&lt;/code&gt;. &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Make sure to enter your environment variables to configure the application:&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;pre&gt;&lt;code&gt;export OPENAI_API_KEY=&#xA;export WEAVIATE_URL=&#xA;export WEAVIATE_API_KEY=&#xA;&#xA;# for tracing&#xA;export LANGCHAIN_TRACING_V2=true&#xA;export LANGCHAIN_ENDPOINT=&#34;https://api.smith.langchain.com&#34;&#xA;export LANGCHAIN_API_KEY=&#xA;export LANGCHAIN_PROJECT=&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Install frontend dependencies by running &lt;code&gt;cd chat-langchain&lt;/code&gt;, then &lt;code&gt;yarn&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Run the frontend with &lt;code&gt;yarn dev&lt;/code&gt; for frontend.&lt;/li&gt; &#xA; &lt;li&gt;Open &lt;a href=&#34;http://localhost:3000&#34;&gt;localhost:3000&lt;/a&gt; in your browser.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;📚 Technical description&lt;/h2&gt; &#xA;&lt;p&gt;There are two components: ingestion and question-answering.&lt;/p&gt; &#xA;&lt;p&gt;Ingestion has the following steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Pull html from documentation site as well as the Github Codebase&lt;/li&gt; &#xA; &lt;li&gt;Load html with LangChain&#39;s &lt;a href=&#34;https://python.langchain.com/docs/integrations/document_loaders/recursive_url_loader&#34;&gt;RecursiveURLLoader Loader&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Transform html to text with &lt;a href=&#34;https://python.langchain.com/docs/integrations/document_transformers/html2text&#34;&gt;Html2TextTransformer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Split documents with LangChain&#39;s &lt;a href=&#34;https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html&#34;&gt;RecursiveCharacterTextSplitter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Create a vectorstore of embeddings, using LangChain&#39;s &lt;a href=&#34;https://python.langchain.com/docs/integrations/vectorstores/weaviate&#34;&gt;Weaviate vectorstore wrapper&lt;/a&gt; (with OpenAI&#39;s embeddings).&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Question-Answering has the following steps, all handled by &lt;a href=&#34;https://python.langchain.com/docs/modules/agents/agent_types/openai_functions_agent&#34;&gt;OpenAIFunctionsAgent&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Given the chat history and new user input, determine what a standalone question would be (using GPT-3.5).&lt;/li&gt; &#xA; &lt;li&gt;Given that standalone question, look up relevant documents from the vectorstore.&lt;/li&gt; &#xA; &lt;li&gt;Pass the standalone question and relevant documents to GPT-4 to generate and stream the final answer.&lt;/li&gt; &#xA; &lt;li&gt;Generate a trace URL for the current chat session, as well as the endpoint to collect feedback.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;🚀 Deployment&lt;/h2&gt; &#xA;&lt;p&gt;Deploy the frontend Next.js app as a serverless Edge function on Vercel &lt;a href=&#34;&#34;&gt;by clicking here&lt;/a&gt;. You&#39;ll need to populate the &lt;code&gt;NEXT_PUBLIC_API_BASE_URL&lt;/code&gt; environment variable with the base URL you&#39;ve deployed the backend under (no trailing slash!).&lt;/p&gt; &#xA;&lt;p&gt;Blog Posts:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.langchain.dev/langchain-chat/&#34;&gt;Initial Launch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.langchain.dev/streaming-support-in-langchain/&#34;&gt;Streaming Support&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>