<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-02T01:30:27Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ymcui/Chinese-LLaMA-Alpaca-3</title>
    <updated>2024-05-02T01:30:27Z</updated>
    <id>tag:github.com,2024-05-02:/ymcui/Chinese-LLaMA-Alpaca-3</id>
    <link href="https://github.com/ymcui/Chinese-LLaMA-Alpaca-3" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ä¸­æ–‡ç¾Šé©¼å¤§æ¨¡å‹ä¸‰æœŸé¡¹ç›® (Chinese Llama-3 LLMs) developed from Meta Llama 3&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca-3/main/README.md&#34;&gt;&lt;strong&gt;ğŸ‡¨ğŸ‡³ä¸­æ–‡&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca-3/main/README_EN.md&#34;&gt;&lt;strong&gt;ğŸŒEnglish&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki&#34;&gt;&lt;strong&gt;ğŸ“–æ–‡æ¡£/Docs&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/issues&#34;&gt;&lt;strong&gt;â“æé—®/Issues&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/discussions&#34;&gt;&lt;strong&gt;ğŸ’¬è®¨è®º/Discussions&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;http://llm-arena.ymcui.com/&#34;&gt;&lt;strong&gt;âš”ï¸ç«æŠ€åœº/Arena&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca-3/main/pics/banner.png&#34; width=&#34;800&#34;&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img alt=&#34;GitHub&#34; src=&#34;https://img.shields.io/github/license/ymcui/Chinese-LLaMA-Alpaca-3.svg?color=blue&amp;amp;style=flat-square&#34;&gt; &lt;img alt=&#34;GitHub release (latest by date)&#34; src=&#34;https://img.shields.io/github/v/release/ymcui/Chinese-LLaMA-Alpaca-3&#34;&gt; &lt;img alt=&#34;GitHub top language&#34; src=&#34;https://img.shields.io/github/languages/top/ymcui/Chinese-LLaMA-Alpaca-3&#34;&gt; &lt;a href=&#34;https://app.codacy.com/gh/ymcui/Chinese-LLaMA-Alpaca-3/dashboard?utm_source=gh&amp;amp;utm_medium=referral&amp;amp;utm_content=&amp;amp;utm_campaign=Badge_grade&#34;&gt;&lt;img src=&#34;https://app.codacy.com/project/badge/Grade/142d688425494644b5b156068f55370d&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;æœ¬é¡¹ç›®åŸºäºMetaæœ€æ–°å‘å¸ƒçš„æ–°ä¸€ä»£å¼€æºå¤§æ¨¡å‹&lt;a href=&#34;https://github.com/facebookresearch/llama3&#34;&gt;Llama-3&lt;/a&gt;å¼€å‘ï¼Œæ˜¯Chinese-LLaMA-Alpacaå¼€æºå¤§æ¨¡å‹ç›¸å…³ç³»åˆ—é¡¹ç›®ï¼ˆ&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca&#34;&gt;ä¸€æœŸ&lt;/a&gt;ã€&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&#34;&gt;äºŒæœŸ&lt;/a&gt;ï¼‰çš„ç¬¬ä¸‰æœŸã€‚æœ¬é¡¹ç›®å¼€æºäº†&lt;strong&gt;ä¸­æ–‡Llama-3åŸºåº§æ¨¡å‹å’Œä¸­æ–‡Llama-3-InstructæŒ‡ä»¤ç²¾è°ƒå¤§æ¨¡å‹&lt;/strong&gt;ã€‚è¿™äº›æ¨¡å‹åœ¨åŸç‰ˆLlama-3çš„åŸºç¡€ä¸Šä½¿ç”¨äº†å¤§è§„æ¨¡ä¸­æ–‡æ•°æ®è¿›è¡Œå¢é‡é¢„è®­ç»ƒï¼Œå¹¶ä¸”ä½¿ç”¨ç²¾é€‰æŒ‡ä»¤æ•°æ®è¿›è¡Œç²¾è°ƒï¼Œè¿›ä¸€æ­¥æå‡äº†ä¸­æ–‡åŸºç¡€è¯­ä¹‰å’ŒæŒ‡ä»¤ç†è§£èƒ½åŠ›ï¼Œç›¸æ¯”äºŒä»£ç›¸å…³æ¨¡å‹è·å¾—äº†æ˜¾è‘—æ€§èƒ½æå‡ã€‚&lt;/p&gt; &#xA;&lt;h4&gt;ä¸»è¦å†…å®¹&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸš€ å¼€æºLlama-3-ChineseåŸºåº§æ¨¡å‹å’ŒLlama-3-Chinese-InstructæŒ‡ä»¤æ¨¡å‹&lt;/li&gt; &#xA; &lt;li&gt;ğŸš€ å¼€æºäº†é¢„è®­ç»ƒè„šæœ¬ã€æŒ‡ä»¤ç²¾è°ƒè„šæœ¬ï¼Œç”¨æˆ·å¯æ ¹æ®éœ€è¦è¿›ä¸€æ­¥è®­ç»ƒæˆ–å¾®è°ƒæ¨¡å‹&lt;/li&gt; &#xA; &lt;li&gt;ğŸš€ å¼€æºäº†alpaca_zh_51k, stem_zh_instruction, ruozhiba_gpt4_turboæŒ‡ä»¤ç²¾è°ƒæ•°æ®&lt;/li&gt; &#xA; &lt;li&gt;ğŸš€ æä¾›äº†åˆ©ç”¨ä¸ªäººç”µè„‘CPU/GPUå¿«é€Ÿåœ¨æœ¬åœ°è¿›è¡Œå¤§æ¨¡å‹é‡åŒ–å’Œéƒ¨ç½²çš„æ•™ç¨‹&lt;/li&gt; &#xA; &lt;li&gt;ğŸš€ æ”¯æŒ&lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;ğŸ¤—transformers&lt;/a&gt;, &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt;, &lt;a href=&#34;https://github.com/oobabooga/text-generation-webui&#34;&gt;text-generation-webui&lt;/a&gt;, &lt;a href=&#34;https://github.com/vllm-project/vllm&#34;&gt;vLLM&lt;/a&gt;, &lt;a href=&#34;https://ollama.com&#34;&gt;Ollama&lt;/a&gt;ç­‰Llama-3ç”Ÿæ€&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-Mixtral&#34;&gt;ä¸­æ–‡Mixtralå¤§æ¨¡å‹&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&#34;&gt;ä¸­æ–‡LLaMA-2&amp;amp;Alpaca-2å¤§æ¨¡å‹&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca&#34;&gt;ä¸­æ–‡LLaMA&amp;amp;Alpacaå¤§æ¨¡å‹&lt;/a&gt; | &lt;a href=&#34;https://github.com/airaria/Visual-Chinese-LLaMA-Alpaca&#34;&gt;å¤šæ¨¡æ€ä¸­æ–‡LLaMA&amp;amp;Alpacaå¤§æ¨¡å‹&lt;/a&gt; | &lt;a href=&#34;https://github.com/iflytek/VLE&#34;&gt;å¤šæ¨¡æ€VLE&lt;/a&gt; | &lt;a href=&#34;https://github.com/iflytek/MiniRBT&#34;&gt;ä¸­æ–‡MiniRBT&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/LERT&#34;&gt;ä¸­æ–‡LERT&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/PERT&#34;&gt;ä¸­è‹±æ–‡PERT&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/MacBERT&#34;&gt;ä¸­æ–‡MacBERT&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/Chinese-ELECTRA&#34;&gt;ä¸­æ–‡ELECTRA&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/Chinese-XLNet&#34;&gt;ä¸­æ–‡XLNet&lt;/a&gt; | &lt;a href=&#34;https://github.com/ymcui/Chinese-BERT-wwm&#34;&gt;ä¸­æ–‡BERT&lt;/a&gt; | &lt;a href=&#34;https://github.com/airaria/TextBrewer&#34;&gt;çŸ¥è¯†è’¸é¦å·¥å…·TextBrewer&lt;/a&gt; | &lt;a href=&#34;https://github.com/airaria/TextPruner&#34;&gt;æ¨¡å‹è£å‰ªå·¥å…·TextPruner&lt;/a&gt; | &lt;a href=&#34;https://github.com/airaria/GRAIN&#34;&gt;è’¸é¦è£å‰ªä¸€ä½“åŒ–GRAIN&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;æ–°é—»&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;[2024/04/30] å‘å¸ƒLlama-3-Chinese-8BåŸºåº§æ¨¡å‹å’ŒLlama-3-Chinese-8B-InstructæŒ‡ä»¤æ¨¡å‹ã€‚è¯¦æƒ…æŸ¥çœ‹ï¼š&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/releases/tag/v1.0&#34;&gt;ğŸ“šv1.0ç‰ˆæœ¬å‘å¸ƒæ—¥å¿—&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;[2024/04/19] ğŸš€ æ­£å¼å¯åŠ¨Chinese-LLaMA-Alpaca-3é¡¹ç›®&lt;/p&gt; &#xA;&lt;h2&gt;å†…å®¹å¯¼å¼•&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ç« èŠ‚&lt;/th&gt; &#xA;   &lt;th&gt;æè¿°&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca-3/main/#%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B&#34;&gt;ğŸ’ğŸ»â€â™‚ï¸æ¨¡å‹ç®€ä»‹&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ç®€è¦ä»‹ç»æœ¬é¡¹ç›®ç›¸å…³æ¨¡å‹çš„æŠ€æœ¯ç‰¹ç‚¹&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca-3/main/#%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD&#34;&gt;â¬æ¨¡å‹ä¸‹è½½&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸­æ–‡Llama-3å¤§æ¨¡å‹ä¸‹è½½åœ°å€&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca-3/main/#%E6%8E%A8%E7%90%86%E4%B8%8E%E9%83%A8%E7%BD%B2&#34;&gt;ğŸ’»æ¨ç†ä¸éƒ¨ç½²&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä»‹ç»äº†å¦‚ä½•å¯¹æ¨¡å‹è¿›è¡Œé‡åŒ–å¹¶ä½¿ç”¨ä¸ªäººç”µè„‘éƒ¨ç½²å¹¶ä½“éªŒå¤§æ¨¡å‹&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca-3/main/#%E6%A8%A1%E5%9E%8B%E6%95%88%E6%9E%9C&#34;&gt;ğŸ’¯æ¨¡å‹æ•ˆæœ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä»‹ç»äº†æ¨¡å‹åœ¨éƒ¨åˆ†ä»»åŠ¡ä¸Šçš„æ•ˆæœ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca-3/main/#%E8%AE%AD%E7%BB%83%E4%B8%8E%E7%B2%BE%E8%B0%83&#34;&gt;ğŸ“è®­ç»ƒä¸ç²¾è°ƒ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä»‹ç»äº†å¦‚ä½•è®­ç»ƒå’Œç²¾è°ƒä¸­æ–‡Llama-3å¤§æ¨¡å‹&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca-3/main/#%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98&#34;&gt;â“å¸¸è§é—®é¢˜&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸€äº›å¸¸è§é—®é¢˜çš„å›å¤&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;æ¨¡å‹ç®€ä»‹&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬é¡¹ç›®æ¨å‡ºäº†åŸºäºMeta Llama-3çš„ä¸­æ–‡å¼€æºå¤§æ¨¡å‹Llama-3-Chineseä»¥åŠLlama-3-Chinese-Instructã€‚ä¸»è¦ç‰¹ç‚¹å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;h4&gt;ğŸ“– ä½¿ç”¨åŸç‰ˆLlama-3è¯è¡¨&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Llama-3ç›¸æ¯”å…¶å‰ä¸¤ä»£æ˜¾è‘—æ‰©å……äº†è¯è¡¨å¤§å°ï¼Œç”±32Kæ‰©å……è‡³128Kï¼Œå¹¶ä¸”æ”¹ä¸ºBPEè¯è¡¨&lt;/li&gt; &#xA; &lt;li&gt;åˆæ­¥å®éªŒå‘ç°Llama-3è¯è¡¨çš„ç¼–ç æ•ˆç‡ä¸æˆ‘ä»¬æ‰©å……è¯è¡¨çš„&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&#34;&gt;ä¸­æ–‡LLaMA-2&lt;/a&gt;ç›¸å½“ï¼Œæ•ˆç‡çº¦ä¸ºä¸­æ–‡LLaMA-2è¯è¡¨çš„95%ï¼ˆåŸºäºç»´åŸºç™¾ç§‘æ•°æ®ä¸Šçš„ç¼–ç æ•ˆç‡æµ‹è¯•ï¼‰&lt;/li&gt; &#xA; &lt;li&gt;ç»“åˆæˆ‘ä»¬åœ¨&lt;a href=&#34;https://github.com/ymcui/Chinese-Mixtral&#34;&gt;ä¸­æ–‡Mixtral&lt;/a&gt;ä¸Šçš„ç›¸å…³ç»éªŒåŠå®éªŒç»“è®º[^1]ï¼Œæˆ‘ä»¬&lt;strong&gt;å¹¶æœªå¯¹è¯è¡¨è¿›è¡Œé¢å¤–æ‰©å……&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;[^1]: &lt;a href=&#34;https://arxiv.org/abs/2403.01851&#34;&gt;Cui and Yao, 2024. Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;ğŸš„ é•¿ä¸Šä¸‹æ–‡é•¿åº¦ç”±äºŒä»£4Kæ‰©å±•è‡³8K&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Llama-3å°†åŸç”Ÿä¸Šä¸‹æ–‡çª—å£é•¿åº¦ä»4Kæå‡è‡³8Kï¼Œèƒ½å¤Ÿè¿›ä¸€æ­¥å¤„ç†æ›´é•¿çš„ä¸Šä¸‹æ–‡ä¿¡æ¯&lt;/li&gt; &#xA; &lt;li&gt;ç”¨æˆ·ä¹Ÿå¯é€šè¿‡PIã€NTKã€YaRNç­‰æ–¹æ³•å¯¹æ¨¡å‹è¿›è¡Œé•¿ä¸Šä¸‹æ–‡çš„æ‰©å±•ï¼Œä»¥æ”¯æŒæ›´é•¿æ–‡æœ¬çš„å¤„ç†&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;âš¡ ä½¿ç”¨åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›æœºåˆ¶&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Llama-3é‡‡ç”¨äº†Llama-2ä¸­å¤§å‚æ•°é‡ç‰ˆæœ¬åº”ç”¨çš„åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›ï¼ˆGQAï¼‰æœºåˆ¶ï¼Œèƒ½å¤Ÿè¿›ä¸€æ­¥æå‡æ¨¡å‹çš„æ•ˆç‡&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;ğŸ—’ å…¨æ–°çš„æŒ‡ä»¤æ¨¡æ¿&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Llama-3-Instructé‡‡ç”¨äº†å…¨æ–°çš„æŒ‡ä»¤æ¨¡æ¿ï¼Œä¸Llama-2-chatä¸å…¼å®¹ï¼Œä½¿ç”¨æ—¶åº”éµå¾ªå®˜æ–¹æŒ‡ä»¤æ¨¡æ¿ï¼ˆè§&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca-3/main/#%E6%8C%87%E4%BB%A4%E6%A8%A1%E6%9D%BF&#34;&gt;æŒ‡ä»¤æ¨¡æ¿&lt;/a&gt;ï¼‰&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;æ¨¡å‹ä¸‹è½½&lt;/h2&gt; &#xA;&lt;h3&gt;æ¨¡å‹é€‰æ‹©æŒ‡å¼•&lt;/h3&gt; &#xA;&lt;p&gt;ä»¥ä¸‹æ˜¯æœ¬é¡¹ç›®çš„æ¨¡å‹å¯¹æ¯”ä»¥åŠå»ºè®®ä½¿ç”¨åœºæ™¯ã€‚&lt;strong&gt;å¦‚éœ€èŠå¤©äº¤äº’ï¼Œè¯·é€‰æ‹©Instructç‰ˆã€‚&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;å¯¹æ¯”é¡¹&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Llama-3-Chinese&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Llama-3-Chinese-Instruct&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;æ¨¡å‹ç±»å‹&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸºåº§æ¨¡å‹&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æŒ‡ä»¤/Chatæ¨¡å‹ï¼ˆç±»ChatGPTï¼‰&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;æ¨¡å‹å¤§å°&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8B&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;è®­ç»ƒç±»å‹&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Causal-LM (CLM)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æŒ‡ä»¤ç²¾è°ƒ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;è®­ç»ƒæ–¹å¼&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;LoRA + å…¨é‡emb/lm-head&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;LoRA + å…¨é‡emb/lm-head&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;åˆå§‹åŒ–æ¨¡å‹&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3-8B&#34;&gt;åŸç‰ˆMeta-Llama-3-8B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ä¸­æ–‡Llama-3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;è®­ç»ƒè¯­æ–™&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æ— æ ‡æ³¨é€šç”¨è¯­æ–™ï¼ˆçº¦120GBï¼‰&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æœ‰æ ‡æ³¨æŒ‡ä»¤æ•°æ®ï¼ˆçº¦500ä¸‡æ¡ï¼‰&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;è¯è¡¨å¤§å°&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸç‰ˆè¯è¡¨ï¼ˆ128,256ï¼‰&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸç‰ˆè¯è¡¨ï¼ˆ128,256ï¼‰&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;æ”¯æŒä¸Šä¸‹æ–‡é•¿åº¦&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8K&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8K&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;è¾“å…¥æ¨¡æ¿&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ä¸éœ€è¦&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;éœ€è¦å¥—ç”¨Llama-3-Instructæ¨¡æ¿&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;é€‚ç”¨åœºæ™¯&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æ–‡æœ¬ç»­å†™ï¼šç»™å®šä¸Šæ–‡ï¼Œè®©æ¨¡å‹ç”Ÿæˆä¸‹æ–‡&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æŒ‡ä»¤ç†è§£ï¼šé—®ç­”ã€å†™ä½œã€èŠå¤©ã€äº¤äº’ç­‰&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;ä¸‹è½½åœ°å€&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;ç±»å‹&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;å®Œæ•´ç‰ˆ&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;LoRAç‰ˆ&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;GGUFç‰ˆ&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Llama-3-Chinese-8B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸºåº§æ¨¡å‹&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/hfl/llama-3-chinese-8b&#34;&gt;[ğŸ¤—Hugging Face]&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b&#34;&gt;[ğŸ¤–ModelScope]&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/hfl/llama-3-chinese-8b-lora&#34;&gt;[ğŸ¤—Hugging Face]&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-lora&#34;&gt;[ğŸ¤–ModelScope]&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/hfl/llama-3-chinese-8b-gguf&#34;&gt;[ğŸ¤—Hugging Face]&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-gguf&#34;&gt;[ğŸ¤–ModelScope]&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Llama-3-Chinese-8B-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æŒ‡ä»¤æ¨¡å‹&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/hfl/llama-3-chinese-8b-instruct&#34;&gt;[ğŸ¤—Hugging Face]&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct&#34;&gt;[ğŸ¤–ModelScope]&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/hfl/llama-3-chinese-8b-instruct-lora&#34;&gt;[ğŸ¤—Hugging Face]&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-lora&#34;&gt;[ğŸ¤–ModelScope]&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/hfl/llama-3-chinese-8b-instruct-gguf&#34;&gt;[ğŸ¤—Hugging Face]&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-gguf&#34;&gt;[ğŸ¤–ModelScope]&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;æ¨¡å‹ç±»å‹è¯´æ˜ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;å®Œæ•´æ¨¡å‹&lt;/strong&gt;ï¼šå¯ç›´æ¥ç”¨äºè®­ç»ƒå’Œæ¨ç†ï¼Œæ— éœ€å…¶ä»–åˆå¹¶æ­¥éª¤&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;LoRAæ¨¡å‹&lt;/strong&gt;ï¼šéœ€è¦ä¸åŸç‰ˆ&lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3-8B&#34;&gt;Meta-Llama-3-8B&lt;/a&gt;åˆå¹¶æ‰èƒ½è½¬ä¸ºå®Œæ•´ç‰ˆæ¨¡å‹ï¼Œåˆå¹¶æ–¹æ³•ï¼š&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/model_conversion_zh&#34;&gt;&lt;strong&gt;ğŸ’» æ¨¡å‹åˆå¹¶æ­¥éª¤&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;GGUFæ¨¡å‹&lt;/strong&gt;ï¼š&lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt;æ¨å‡ºçš„é‡åŒ–æ ¼å¼ï¼Œé€‚é…ollamaç­‰å¸¸è§æ¨ç†å·¥å…·ï¼Œæ¨èåªéœ€è¦åšæ¨ç†éƒ¨ç½²çš„ç”¨æˆ·ä¸‹è½½ï¼›æ¨¡å‹ååç¼€ä¸º&lt;code&gt;-im&lt;/code&gt;è¡¨ç¤ºä½¿ç”¨äº†importance matrixè¿›è¡Œé‡åŒ–ï¼Œé€šå¸¸å…·æœ‰æ›´ä½çš„PPLï¼Œå»ºè®®ä½¿ç”¨ï¼ˆç”¨æ³•ä¸å¸¸è§„ç‰ˆç›¸åŒï¼‰&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] è‹¥æ— æ³•è®¿é—®HFï¼Œå¯è€ƒè™‘ä¸€äº›é•œåƒç«™ç‚¹ï¼ˆå¦‚&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca-3/main/hf-mirror.com&#34;&gt;hf-mirror.com&lt;/a&gt;ï¼‰ï¼Œå…·ä½“æ–¹æ³•è¯·è‡ªè¡ŒæŸ¥æ‰¾è§£å†³ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;æ¨ç†ä¸éƒ¨ç½²&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬é¡¹ç›®ä¸­çš„ç›¸å…³æ¨¡å‹ä¸»è¦æ”¯æŒä»¥ä¸‹é‡åŒ–ã€æ¨ç†å’Œéƒ¨ç½²æ–¹å¼ï¼Œå…·ä½“å†…å®¹è¯·å‚è€ƒå¯¹åº”æ•™ç¨‹ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;å·¥å…·&lt;/th&gt; &#xA;   &lt;th&gt;ç‰¹ç‚¹&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;CPU&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;GPU&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;é‡åŒ–&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;GUI&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;API&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;vLLM&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;æ•™ç¨‹&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸°å¯Œçš„GGUFé‡åŒ–é€‰é¡¹å’Œé«˜æ•ˆæœ¬åœ°æ¨ç†&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âŒ&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/llamacpp_zh&#34;&gt;[link]&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;ğŸ¤—transformers&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;åŸç”Ÿtransformersæ¨ç†æ¥å£&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âŒ&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/inference_with_transformers_zh&#34;&gt;[link]&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://platform.openai.com/docs/api-reference&#34;&gt;ä»¿OpenAI APIè°ƒç”¨&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä»¿OpenAI APIæ¥å£çš„æœåŠ¡å™¨Demo&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âŒ&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/openai_api_zh&#34;&gt;[link]&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/oobabooga/text-generation-webui&#34;&gt;text-generation-webui&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;å‰ç«¯Web UIç•Œé¢çš„éƒ¨ç½²æ–¹å¼&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âŒ&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/text-generation-webui_zh&#34;&gt;[link]&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://lmstudio.ai&#34;&gt;LM Studio&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;å¤šå¹³å°èŠå¤©è½¯ä»¶ï¼ˆå¸¦ç•Œé¢ï¼‰&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âŒ&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/lmstudio_zh&#34;&gt;[link]&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/ollama/ollama&#34;&gt;Ollama&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;æœ¬åœ°è¿è¡Œå¤§æ¨¡å‹æ¨ç†&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âŒ&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ…&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âŒ&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/ollama_zh&#34;&gt;[link]&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;æ¨¡å‹æ•ˆæœ&lt;/h2&gt; &#xA;&lt;p&gt;ä¸ºäº†è¯„æµ‹ç›¸å…³æ¨¡å‹çš„æ•ˆæœï¼Œæœ¬é¡¹ç›®åˆ†åˆ«è¿›è¡Œäº†ç”Ÿæˆæ•ˆæœè¯„æµ‹å’Œå®¢è§‚æ•ˆæœè¯„æµ‹ï¼ˆNLUç±»ï¼‰ï¼Œä»ä¸åŒè§’åº¦å¯¹å¤§æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚æ¨èç”¨æˆ·åœ¨è‡ªå·±å…³æ³¨çš„ä»»åŠ¡ä¸Šè¿›è¡Œæµ‹è¯•ï¼Œé€‰æ‹©é€‚é…ç›¸å…³ä»»åŠ¡çš„æ¨¡å‹ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;ç”Ÿæˆæ•ˆæœè¯„æµ‹&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æœ¬é¡¹ç›®ä»¿ç…§&lt;a href=&#34;https://chat.lmsys.org/?arena&#34;&gt;Fastchat Chatbot Arena&lt;/a&gt;æ¨å‡ºäº†æ¨¡å‹åœ¨çº¿å¯¹æˆ˜å¹³å°ï¼Œå¯æµè§ˆå’Œè¯„æµ‹æ¨¡å‹å›å¤è´¨é‡ã€‚å¯¹æˆ˜å¹³å°æä¾›äº†èƒœç‡ã€Eloè¯„åˆ†ç­‰è¯„æµ‹æŒ‡æ ‡ï¼Œå¹¶ä¸”å¯ä»¥æŸ¥çœ‹ä¸¤ä¸¤æ¨¡å‹çš„å¯¹æˆ˜èƒœç‡ç­‰ç»“æœã€‚&lt;strong&gt;âš”ï¸ æ¨¡å‹ç«æŠ€åœºï¼š&lt;a href=&#34;http://llm-arena.ymcui.com/&#34;&gt;http://llm-arena.ymcui.com&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;æœ¬é¡¹ç›®å·²å…¥é©»æœºå™¨ä¹‹å¿ƒSOTA!æ¨¡å‹å¹³å°ï¼ŒåæœŸå°†å®ç°åœ¨çº¿ä½“éªŒï¼š&lt;a href=&#34;https://sota.jiqizhixin.com/project/chinese-llama-alpaca-3&#34;&gt;https://sota.jiqizhixin.com/project/chinese-llama-alpaca-3&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;å®¢è§‚æ•ˆæœè¯„æµ‹&lt;/h3&gt; &#xA;&lt;h4&gt;C-Eval&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cevalbenchmark.com&#34;&gt;C-Eval&lt;/a&gt;æ˜¯ä¸€ä¸ªå…¨é¢çš„ä¸­æ–‡åŸºç¡€æ¨¡å‹è¯„ä¼°å¥—ä»¶ï¼Œå…¶ä¸­éªŒè¯é›†å’Œæµ‹è¯•é›†åˆ†åˆ«åŒ…å«1.3Kå’Œ12.3Kä¸ªé€‰æ‹©é¢˜ï¼Œæ¶µç›–52ä¸ªå­¦ç§‘ã€‚C-Evalæ¨ç†ä»£ç è¯·å‚è€ƒæœ¬é¡¹ç›®ï¼š&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/ceval_zh&#34;&gt;ğŸ“–GitHub Wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Models&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;å‚æ•°é‡&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;ç±»å‹&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Valid (0-shot)&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Valid (5-shot)&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Test (0-shot)&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Test (5-shot)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama-3-Chinese-8B-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æŒ‡ä»¤&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;48.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama-3-Chinese-8B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸºåº§&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3-8B&#34;&gt;Llama-3-8B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸºåº§&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-Mixtral&#34;&gt;Chinese-Mixtral-Instruct&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8x7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æŒ‡ä»¤&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;55.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-Mixtral&#34;&gt;Chinese-Mixtral&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8x7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸºåº§&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;54.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;43.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&#34;&gt;Chinese-Alpaca-2-13B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æŒ‡ä»¤&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&#34;&gt;Chinese-LLaMA-2-13B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸºåº§&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;41.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;CMMLU&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/haonan-li/CMMLU&#34;&gt;CMMLU&lt;/a&gt;æ˜¯å¦ä¸€ä¸ªç»¼åˆæ€§ä¸­æ–‡è¯„æµ‹æ•°æ®é›†ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ä¸­æ–‡è¯­å¢ƒä¸‹çš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼Œæ¶µç›–äº†ä»åŸºç¡€å­¦ç§‘åˆ°é«˜çº§ä¸“ä¸šæ°´å¹³çš„67ä¸ªä¸»é¢˜ï¼Œå…±è®¡11.5Kä¸ªé€‰æ‹©é¢˜ã€‚CMMLUæ¨ç†ä»£ç è¯·å‚è€ƒæœ¬é¡¹ç›®ï¼š&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/cmmlu_zh&#34;&gt;ğŸ“–GitHub Wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Models&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;å‚æ•°é‡&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;ç±»å‹&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Test (0-shot)&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Test (5-shot)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama-3-Chinese-8B-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æŒ‡ä»¤&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama-3-Chinese-8B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸºåº§&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;48.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3-8B&#34;&gt;Llama-3-8B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸºåº§&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-Mixtral&#34;&gt;Chinese-Mixtral-Instruct&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8x7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æŒ‡ä»¤&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;53.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-Mixtral&#34;&gt;Chinese-Mixtral&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8x7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸºåº§&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&#34;&gt;Chinese-Alpaca-2-13B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æŒ‡ä»¤&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;43.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&#34;&gt;Chinese-LLaMA-2-13B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸºåº§&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;MMLU&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/hendrycks/test&#34;&gt;MMLU&lt;/a&gt;æ˜¯ä¸€ä¸ªç”¨äºè¯„æµ‹è‡ªç„¶è¯­è¨€ç†è§£èƒ½åŠ›çš„è‹±æ–‡è¯„æµ‹æ•°æ®é›†ï¼Œæ˜¯å½“ä»Šç”¨äºè¯„æµ‹å¤§æ¨¡å‹èƒ½åŠ›çš„ä¸»è¦æ•°æ®é›†ä¹‹ä¸€ï¼Œå…¶ä¸­éªŒè¯é›†å’Œæµ‹è¯•é›†åˆ†åˆ«åŒ…å«1.5Kå’Œ14.1Kä¸ªé€‰æ‹©é¢˜ï¼Œæ¶µç›–57ä¸ªå­¦ç§‘ã€‚MMLUæ¨ç†ä»£ç è¯·å‚è€ƒæœ¬é¡¹ç›®ï¼š&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/mmlu_zh&#34;&gt;ğŸ“–GitHub Wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Models&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;å‚æ•°é‡&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;ç±»å‹&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Valid (0-shot)&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Valid (5-shot)&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Test (0-shot)&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Test (5-shot)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama-3-Chinese-8B-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æŒ‡ä»¤&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;60.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;59.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama-3-Chinese-8B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸºåº§&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;55.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;58.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;57.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3-8B&#34;&gt;Llama-3-8B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸºåº§&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;58.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;62.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;60.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;65.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-Mixtral&#34;&gt;Chinese-Mixtral-Instruct&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8x7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æŒ‡ä»¤&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;65.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;69.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;67.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;69.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-Mixtral&#34;&gt;Chinese-Mixtral&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8x7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸºåº§&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;63.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;67.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;65.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&#34;&gt;Chinese-Alpaca-2-13B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;æŒ‡ä»¤&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;53.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;53.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&#34;&gt;Chinese-LLaMA-2-13B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;åŸºåº§&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;LongBench&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/THUDM/LongBench&#34;&gt;LongBench&lt;/a&gt;æ˜¯ä¸€ä¸ªå¤§æ¨¡å‹é•¿æ–‡æœ¬ç†è§£èƒ½åŠ›çš„è¯„æµ‹åŸºå‡†ï¼Œç”±6å¤§ç±»ã€20ä¸ªä¸åŒçš„ä»»åŠ¡ç»„æˆï¼Œå¤šæ•°ä»»åŠ¡çš„å¹³å‡é•¿åº¦åœ¨5K-15Kä¹‹é—´ï¼Œå…±åŒ…å«çº¦4.75Kæ¡æµ‹è¯•æ•°æ®ã€‚ä»¥ä¸‹æ˜¯æœ¬é¡¹ç›®æ¨¡å‹åœ¨è¯¥ä¸­æ–‡ä»»åŠ¡ï¼ˆå«ä»£ç ä»»åŠ¡ï¼‰ä¸Šçš„è¯„æµ‹æ•ˆæœã€‚LongBenchæ¨ç†ä»£ç è¯·å‚è€ƒæœ¬é¡¹ç›®ï¼š&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/longbench_zh&#34;&gt;ğŸ“–GitHub Wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Models&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;å‚æ•°é‡&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;å•æ–‡æ¡£QA&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;å¤šæ–‡æ¡£QA&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;æ‘˜è¦&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;FSå­¦ä¹ &lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;ä»£ç &lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;åˆæˆ&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;å¹³å‡&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama-3-Chinese-8B-Instruct&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama-3-Chinese-8B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;19.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3-8B&#34;&gt;Llama-3-8B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;21.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;65.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-Mixtral&#34;&gt;Chinese-Mixtral-Instruct&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8x7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;56.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;89.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;48.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-Mixtral&#34;&gt;Chinese-Mixtral&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8x7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;23.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;23.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&#34;&gt;Chinese-Alpaca-2-13B-16K&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;21.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&#34;&gt;Chinese-LLaMA-2-13B-16K&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;36.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&#34;&gt;Chinese-Alpaca-2-7B-64K&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;39.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&#34;&gt;Chinese-LLaMA-2-7B-64K&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;é‡åŒ–æ•ˆæœè¯„æµ‹&lt;/h3&gt; &#xA;&lt;p&gt;åœ¨llama.cppä¸‹ï¼Œæµ‹è¯•äº†Llama-3-Chinese-8Bï¼ˆåŸºåº§æ¨¡å‹ï¼‰çš„é‡åŒ–æ€§èƒ½ï¼Œå¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚å®æµ‹é€Ÿåº¦ç›¸æ¯”äºŒä»£Llama-2-7Bç•¥æ…¢ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;F16&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Q8_0&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Q6_K&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Q5_K&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Q5_0&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Q4_K&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Q4_0&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Q3_K&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Q2_K&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Size (GB)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;14.97&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;7.95&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;6.14&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5.34&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5.21&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;4.58&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;4.34&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;3.74&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;2.96&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;BPW&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;16.00&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;8.50&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;6.56&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5.70&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5.57&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;4.89&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;4.64&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;4.00&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;3.16&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;PPL&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5.130&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5.135&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5.148&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5.181&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5.222&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5.312&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5.549&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5.755&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;11.859&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;PP Speed&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;5.99&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;6.10&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;7.17&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;7.34&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;6.65&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;6.38&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;6.00&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;6.85&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;6.43&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;TG Speed&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;44.03&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;26.08&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;21.61&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;22.33&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;20.93&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;18.93&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;17.09&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;22.50&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;19.21&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;æ¨¡å‹å¤§å°ï¼šå•ä½GB&lt;/li&gt; &#xA;  &lt;li&gt;BPWï¼ˆBits-Per-Weightï¼‰ï¼šå•ä½å‚æ•°æ¯”ç‰¹ï¼Œä¾‹å¦‚Q8_0å®é™…å¹³å‡ç²¾åº¦ä¸º8.50&lt;/li&gt; &#xA;  &lt;li&gt;PPLï¼ˆå›°æƒ‘åº¦ï¼‰ï¼šä»¥8Kä¸Šä¸‹æ–‡æµ‹é‡ï¼ˆåŸç”Ÿæ”¯æŒé•¿åº¦ï¼‰ï¼Œæ•°å€¼è¶Šä½è¶Šå¥½&lt;/li&gt; &#xA;  &lt;li&gt;PP/TGé€Ÿåº¦ï¼šæä¾›äº†Apple M3 Maxï¼ˆMetalï¼‰çš„æŒ‡ä»¤å¤„ç†ï¼ˆPPï¼‰å’Œæ–‡æœ¬ç”Ÿæˆï¼ˆTGï¼‰é€Ÿåº¦ï¼Œå•ä½ms/tokenï¼Œæ•°å€¼è¶Šä½è¶Šå¿«&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;è®­ç»ƒä¸ç²¾è°ƒ&lt;/h2&gt; &#xA;&lt;h3&gt;æ‰‹åŠ¨è®­ç»ƒä¸ç²¾è°ƒ&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ä½¿ç”¨æ— æ ‡æ³¨æ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼š&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/pt_scripts_zh&#34;&gt;ğŸ“–é¢„è®­ç»ƒè„šæœ¬Wiki&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ä½¿ç”¨æœ‰æ ‡æ³¨æ•°æ®è¿›è¡ŒæŒ‡ä»¤ç²¾è°ƒï¼š&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/sft_scripts_zh&#34;&gt;ğŸ“–æŒ‡ä»¤ç²¾è°ƒè„šæœ¬Wiki&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;æŒ‡ä»¤æ¨¡æ¿&lt;/h3&gt; &#xA;&lt;p&gt;æœ¬é¡¹ç›®Llama-3-Chinese-Instructæ²¿ç”¨åŸç‰ˆLlama-3-Instructçš„æŒ‡ä»¤æ¨¡æ¿ã€‚ä»¥ä¸‹æ˜¯ä¸€ç»„å¯¹è¯ç¤ºä¾‹ï¼š&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id|&amp;gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;You are a helpful assistant. ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚&lt;strong&gt;&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;ä½ å¥½**&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;**&lt;/p&gt; &#xA; &lt;p&gt;ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ&lt;strong&gt;&amp;lt;|eot_id|&amp;gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;æŒ‡ä»¤æ•°æ®&lt;/h3&gt; &#xA;&lt;p&gt;ä»¥ä¸‹æ˜¯æœ¬é¡¹ç›®å¼€æºçš„éƒ¨åˆ†æŒ‡ä»¤æ•°æ®ã€‚è¯¦æƒ…è¯·æŸ¥çœ‹ï¼š&lt;a href=&#34;https://raw.githubusercontent.com/ymcui/Chinese-LLaMA-Alpaca-3/main/data&#34;&gt;ğŸ“š æŒ‡ä»¤æ•°æ®&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;æ•°æ®åç§°&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;è¯´æ˜&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;æ•°é‡&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/hfl/alpaca_zh_51k&#34;&gt;alpaca_zh_51k&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;ä½¿ç”¨gpt-3.5ç¿»è¯‘çš„Alpacaæ•°æ®&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51K&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/hfl/stem_zh_instruction&#34;&gt;stem_zh_instruction&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;ä½¿ç”¨gpt-3.5çˆ¬å–çš„STEMæ•°æ®ï¼ŒåŒ…å«ç‰©ç†ã€åŒ–å­¦ã€åŒ»å­¦ã€ç”Ÿç‰©å­¦ã€åœ°çƒç§‘å­¦&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;256K&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/hfl/ruozhiba_gpt4_turbo&#34;&gt;ruozhiba_gpt4_turbo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;ä½¿ç”¨&lt;code&gt;gpt-4-turbo-2024-04-09&lt;/code&gt;è·å–çš„ruozhibaé—®ç­”æ•°æ®&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2449&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;å¸¸è§é—®é¢˜&lt;/h2&gt; &#xA;&lt;p&gt;è¯·åœ¨æäº¤Issueå‰åŠ¡å¿…å…ˆæŸ¥çœ‹FAQä¸­æ˜¯å¦å·²å­˜åœ¨è§£å†³æ–¹æ¡ˆã€‚å…·ä½“é—®é¢˜å’Œè§£ç­”è¯·å‚è€ƒæœ¬é¡¹ç›® &lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/faq_zh&#34;&gt;ğŸ“–GitHub Wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;é—®é¢˜1ï¼šä¸ºä»€ä¹ˆæ²¡æœ‰åƒä¸€æœŸã€äºŒæœŸé¡¹ç›®ä¸€æ ·åšè¯è¡¨æ‰©å……ï¼Ÿ&#xA;é—®é¢˜2ï¼šä¼šæœ‰70Bç‰ˆæœ¬å‘å¸ƒå—ï¼Ÿ&#xA;é—®é¢˜3ï¼šä¸ºä»€ä¹ˆæŒ‡ä»¤æ¨¡å‹ä¸å«Alpacaäº†ï¼Ÿ&#xA;é—®é¢˜4ï¼šæœ¬ä»“åº“æ¨¡å‹èƒ½å¦å•†ç”¨ï¼Ÿ&#xA;é—®é¢˜5ï¼šä¸ºä»€ä¹ˆä¸å¯¹æ¨¡å‹åšå…¨é‡é¢„è®­ç»ƒè€Œæ˜¯ç”¨LoRAï¼Ÿ&#xA;é—®é¢˜6ï¼šä¸ºä»€ä¹ˆLlama-3-Chineseå¯¹è¯æ•ˆæœä¸å¥½ï¼Ÿ&#xA;é—®é¢˜7ï¼šä¸ºä»€ä¹ˆæŒ‡ä»¤æ¨¡å‹ä¼šå›å¤è¯´è‡ªå·±æ˜¯ChatGPTï¼Ÿ&#xA;é—®é¢˜8ï¼šä¸ºä»€ä¹ˆæ²¡æœ‰åœ¨Meta-Llama-3-Instructä¸Šè®­ç»ƒï¼Ÿ&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;å…è´£å£°æ˜&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬é¡¹ç›®åŸºäºç”±Metaå‘å¸ƒçš„Llama-3æ¨¡å‹è¿›è¡Œå¼€å‘ï¼Œä½¿ç”¨è¿‡ç¨‹ä¸­è¯·ä¸¥æ ¼éµå®ˆLlama-3çš„&lt;a href=&#34;https://github.com/meta-llama/llama3/raw/main/LICENSE&#34;&gt;å¼€æºè®¸å¯åè®®&lt;/a&gt;ã€‚å¦‚æœæ¶‰åŠä½¿ç”¨ç¬¬ä¸‰æ–¹ä»£ç ï¼Œè¯·åŠ¡å¿…éµä»ç›¸å…³çš„å¼€æºè®¸å¯åè®®ã€‚æ¨¡å‹ç”Ÿæˆçš„å†…å®¹å¯èƒ½ä¼šå› ä¸ºè®¡ç®—æ–¹æ³•ã€éšæœºå› ç´ ä»¥åŠé‡åŒ–ç²¾åº¦æŸå¤±ç­‰å½±å“å…¶å‡†ç¡®æ€§ï¼Œå› æ­¤ï¼Œæœ¬é¡¹ç›®ä¸å¯¹æ¨¡å‹è¾“å‡ºçš„å‡†ç¡®æ€§æä¾›ä»»ä½•ä¿è¯ï¼Œä¹Ÿä¸ä¼šå¯¹ä»»ä½•å› ä½¿ç”¨ç›¸å…³èµ„æºå’Œè¾“å‡ºç»“æœäº§ç”Ÿçš„æŸå¤±æ‰¿æ‹…è´£ä»»ã€‚å¦‚æœå°†æœ¬é¡¹ç›®çš„ç›¸å…³æ¨¡å‹ç”¨äºå•†ä¸šç”¨é€”ï¼Œå¼€å‘è€…åº”éµå®ˆå½“åœ°çš„æ³•å¾‹æ³•è§„ï¼Œç¡®ä¿æ¨¡å‹è¾“å‡ºå†…å®¹çš„åˆè§„æ€§ï¼Œæœ¬é¡¹ç›®ä¸å¯¹ä»»ä½•ç”±æ­¤è¡ç”Ÿçš„äº§å“æˆ–æœåŠ¡æ‰¿æ‹…è´£ä»»ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;é—®é¢˜åé¦ˆ&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœ‰ç–‘é—®ï¼Œè¯·åœ¨GitHub Issueä¸­æäº¤ã€‚ç¤¼è²Œåœ°æå‡ºé—®é¢˜ï¼Œæ„å»ºå’Œè°çš„è®¨è®ºç¤¾åŒºã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;åœ¨æäº¤é—®é¢˜ä¹‹å‰ï¼Œè¯·å…ˆæŸ¥çœ‹FAQèƒ½å¦è§£å†³é—®é¢˜ï¼ŒåŒæ—¶å»ºè®®æŸ¥é˜…ä»¥å¾€çš„issueæ˜¯å¦èƒ½è§£å†³ä½ çš„é—®é¢˜ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æäº¤é—®é¢˜è¯·ä½¿ç”¨æœ¬é¡¹ç›®è®¾ç½®çš„Issueæ¨¡æ¿ï¼Œä»¥å¸®åŠ©å¿«é€Ÿå®šä½å…·ä½“é—®é¢˜ã€‚&lt;/li&gt; &#xA; &lt;li&gt;é‡å¤ä»¥åŠä¸æœ¬é¡¹ç›®æ— å…³çš„issueä¼šè¢«&lt;a href=&#34;https://github.com/marketplace/stale&#34;&gt;stable-bot&lt;/a&gt;å¤„ç†ï¼Œæ•¬è¯·è°…è§£ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>dusty-nv/jetson-containers</title>
    <updated>2024-05-02T01:30:27Z</updated>
    <id>tag:github.com,2024-05-02:/dusty-nv/jetson-containers</id>
    <link href="https://github.com/dusty-nv/jetson-containers" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Machine Learning Containers for NVIDIA Jetson and JetPack-L4T&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://www.jetson-ai-lab.com&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/docs/docs/images/header_blueprint_rainbow.jpg&#34; alt=&#34;a header for a software project about building containers for AI and machine learning&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Machine Learning Containers for Jetson and JetPack&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/l4t/l4t-pytorch&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/dusty-nv/jetson-containers/l4t-pytorch_jp51.yml?label=l4t-pytorch&#34; alt=&#34;l4t-pytorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/l4t/l4t-tensorflow&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/dusty-nv/jetson-containers/l4t-tensorflow-tf2_jp51.yml?label=l4t-tensorflow&#34; alt=&#34;l4t-tensorflow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/l4t/l4t-ml&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/dusty-nv/jetson-containers/l4t-ml_jp51.yml?label=l4t-ml&#34; alt=&#34;l4t-ml&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/l4t/l4t-diffusion&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/dusty-nv/jetson-containers/l4t-diffusion_jp51.yml?label=l4t-diffusion&#34; alt=&#34;l4t-diffusion&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/l4t/l4t-text-generation&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/dusty-nv/jetson-containers/l4t-text-generation_jp60.yml?label=l4t-text-generation&#34; alt=&#34;l4t-text-generation&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Modular container build system that provides various &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages&#34;&gt;&lt;strong&gt;AI/ML packages&lt;/strong&gt;&lt;/a&gt; for &lt;a href=&#34;https://developer.nvidia.com/embedded-computing&#34;&gt;NVIDIA Jetson&lt;/a&gt; &lt;span&gt;ğŸš€&lt;/span&gt;&lt;span&gt;ğŸ¤–&lt;/span&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;ML&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/pytorch&#34;&gt;&lt;code&gt;pytorch&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/tensorflow&#34;&gt;&lt;code&gt;tensorflow&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/onnxruntime&#34;&gt;&lt;code&gt;onnxruntime&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/deepstream&#34;&gt;&lt;code&gt;deepstream&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/jupyterlab&#34;&gt;&lt;code&gt;jupyterlab&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/diffusion/stable-diffusion-webui&#34;&gt;&lt;code&gt;stable-diffusion&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;LLM&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/llm/nano_llm&#34;&gt;&lt;code&gt;NanoLLM&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/llm/transformers&#34;&gt;&lt;code&gt;transformers&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/llm/text-generation-webui&#34;&gt;&lt;code&gt;text-generation-webui&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/llm/ollama&#34;&gt;&lt;code&gt;ollama&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/llm/llama_cpp&#34;&gt;&lt;code&gt;llama.cpp&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/llm/exllama&#34;&gt;&lt;code&gt;exllama&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/llm/llava&#34;&gt;&lt;code&gt;llava&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/llm/awq&#34;&gt;&lt;code&gt;awq&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/llm/auto_gptq&#34;&gt;&lt;code&gt;AutoGPTQ&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/llm/mlc&#34;&gt;&lt;code&gt;MLC&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/llm/optimum&#34;&gt;&lt;code&gt;optimum&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/nemo&#34;&gt;&lt;code&gt;nemo&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;L4T&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/l4t/l4t-pytorch&#34;&gt;&lt;code&gt;l4t-pytorch&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/l4t/l4t-tensorflow&#34;&gt;&lt;code&gt;l4t-tensorflow&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/l4t/l4t-ml&#34;&gt;&lt;code&gt;l4t-ml&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/l4t/l4t-diffusion&#34;&gt;&lt;code&gt;l4t-diffusion&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/l4t/l4t-text-generation&#34;&gt;&lt;code&gt;l4t-text-generation&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;VIT&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/vit/nanoowl&#34;&gt;&lt;code&gt;NanoOWL&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/vit/nanosam&#34;&gt;&lt;code&gt;NanoSAM&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/vit/sam&#34;&gt;&lt;code&gt;Segment Anything (SAM)&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/vit/tam&#34;&gt;&lt;code&gt;Track Anything (TAM)&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;CUDA&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/cuda/cupy&#34;&gt;&lt;code&gt;cupy&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/cuda/cuda-python&#34;&gt;&lt;code&gt;cuda-python&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/cuda/pycuda&#34;&gt;&lt;code&gt;pycuda&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/numba&#34;&gt;&lt;code&gt;numba&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/rapids/cudf&#34;&gt;&lt;code&gt;cudf&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/rapids/cuml&#34;&gt;&lt;code&gt;cuml&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Robotics&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/ros&#34;&gt;&lt;code&gt;ros&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/ros&#34;&gt;&lt;code&gt;ros2&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/opencv&#34;&gt;&lt;code&gt;opencv:cuda&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/realsense&#34;&gt;&lt;code&gt;realsense&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/zed&#34;&gt;&lt;code&gt;zed&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;RAG&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/rag/llama-index&#34;&gt;&lt;code&gt;llama-index&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/rag/langchain&#34;&gt;&lt;code&gt;langchain&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/vectordb/nanodb&#34;&gt;&lt;code&gt;NanoDB&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/vectordb/faiss&#34;&gt;&lt;code&gt;FAISS&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/rapids/raft&#34;&gt;&lt;code&gt;RAFT&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Audio&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/audio/whisper&#34;&gt;&lt;code&gt;whisper&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/audio/whisperx&#34;&gt;&lt;code&gt;whisperX&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/audio/piper-tts&#34;&gt;&lt;code&gt;piper&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/audio/riva-client&#34;&gt;&lt;code&gt;riva&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/audio/xtts&#34;&gt;&lt;code&gt;XTTS&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/audio/audiocraft&#34;&gt;&lt;code&gt;audiocraft&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Smart Home&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/smart-home/homeassistant-core&#34;&gt;&lt;code&gt;homeassistant-core&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/smart-home/homeassistant-base&#34;&gt;&lt;code&gt;homeassistant-base&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/smart-home/wyoming/wyoming-whisper&#34;&gt;&lt;code&gt;wyoming-whisper&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/smart-home/wyoming/openwakeword&#34;&gt;&lt;code&gt;wyoming-openwakeword&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/smart-home/wyoming/piper&#34;&gt;&lt;code&gt;wyoming-piper&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/smart-home/wyoming/assist-microphone&#34;&gt;&lt;code&gt;wyoming-assist-microphone&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages&#34;&gt;&lt;strong&gt;&lt;code&gt;packages&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt; directory for the full list, including pre-built container images for JetPack/L4T.&lt;/p&gt; &#xA;&lt;p&gt;Using the included tools, you can easily combine packages together for building your own containers. Want to run ROS2 with PyTorch and Transformers? No problem - just do the &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/docs/setup.md&#34;&gt;system setup&lt;/a&gt;, and build it on your Jetson:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ jetson-containers build --name=my_container pytorch transformers ros:humble-desktop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There are shortcuts for running containers too - this will pull or build a &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/l4t/l4t-pytorch&#34;&gt;&lt;code&gt;l4t-pytorch&lt;/code&gt;&lt;/a&gt; image that&#39;s compatible:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ jetson-containers run $(autotag l4t-pytorch)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;sup&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/docs/run.md&#34;&gt;&lt;code&gt;jetson-containers run&lt;/code&gt;&lt;/a&gt; launches &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/run/&#34;&gt;&lt;code&gt;docker run&lt;/code&gt;&lt;/a&gt; with some added defaults (like &lt;code&gt;--runtime nvidia&lt;/code&gt;, mounted &lt;code&gt;/data&lt;/code&gt; cache and devices)&lt;/sup&gt;&lt;br&gt; &lt;sup&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/docs/run.md#autotag&#34;&gt;&lt;code&gt;autotag&lt;/code&gt;&lt;/a&gt; finds a container image that&#39;s compatible with your version of JetPack/L4T - either locally, pulled from a registry, or by building it.&lt;/sup&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;If you look at any package&#39;s readme (like &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/l4t/l4t-pytorch&#34;&gt;&lt;code&gt;l4t-pytorch&lt;/code&gt;&lt;/a&gt;), it will have detailed instructions for running it.&lt;/p&gt; &#xA;&lt;h4&gt;Changing CUDA Versions&lt;/h4&gt; &#xA;&lt;p&gt;You can rebuild the container stack for different versions of CUDA by setting the &lt;code&gt;CUDA_VERSION&lt;/code&gt; variable:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VERSION=12.4 jetson-containers build transformers&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It will then go off and either pull or build all the dependencies needed, including PyTorch and other packages that would be time-consuming to compile. There is a &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/docs/build.md#pip-server&#34;&gt;Pip server&lt;/a&gt; that caches the wheels to accelerate builds. You can also request specific versions of cuDNN, TensorRT, Python, and PyTorch with similar environment variables like &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/docs/build.md#changing-versions&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.jetson-ai-lab.com&#34;&gt;&lt;img align=&#34;right&#34; width=&#34;200&#34; height=&#34;200&#34; src=&#34;https://nvidia-ai-iot.github.io/jetson-generative-ai-playground/images/JON_Gen-AI-panels.png&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages&#34;&gt;Package List&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/docs/packages.md&#34;&gt;Package Definitions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/docs/setup.md&#34;&gt;System Setup&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/docs/build.md&#34;&gt;Building Containers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/docs/run.md&#34;&gt;Running Containers&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Check out the tutorials at the &lt;a href=&#34;https://www.jetson-ai-lab.com&#34;&gt;&lt;strong&gt;Jetson Generative AI Lab&lt;/strong&gt;&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Refer to the &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/docs/setup.md&#34;&gt;System Setup&lt;/a&gt; page for tips about setting up your Docker daemon and memory/storage tuning.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# install the container tools&#xA;git clone https://github.com/dusty-nv/jetson-containers&#xA;bash jetson-containers/install.sh&#xA;&#xA;# automatically pull &amp;amp; run any container&#xA;jetson-containers run $(autotag l4t-pytorch)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or you can manually run a &lt;a href=&#34;https://hub.docker.com/r/dustynv&#34;&gt;container image&lt;/a&gt; of your choice without using the helper scripts above:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo docker run --runtime nvidia -it --rm --network=host dustynv/l4t-pytorch:r36.2.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Looking for the old jetson-containers? See the &lt;a href=&#34;https://github.com/dusty-nv/jetson-containers/tree/legacy&#34;&gt;&lt;code&gt;legacy&lt;/code&gt;&lt;/a&gt; branch.&lt;/p&gt; &#xA;&lt;h2&gt;Gallery&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=UOjqF3YCGkY&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/docs/docs/images/llamaspeak_llava_clip.gif&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=9ObzbbBTbcc&#34;&gt;Multimodal Voice Chat with LLaVA-1.5 13B on NVIDIA Jetson AGX Orin&lt;/a&gt; (container: &lt;a href=&#34;https://dusty-nv.github.io/NanoLLM/&#34;&gt;&lt;code&gt;NanoLLM&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=hswNSZTvEFE&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/docs/docs/images/llamaspeak_70b_yt.jpg&#34; width=&#34;800px&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=wzLHAgDxMjQ&#34;&gt;Interactive Voice Chat with Llama-2-70B on NVIDIA Jetson AGX Orin&lt;/a&gt; (container: &lt;a href=&#34;https://dusty-nv.github.io/NanoLLM/&#34;&gt;&lt;code&gt;NanoLLM&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=OJT-Ax0CkhU&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/docs/docs/images/nanodb_tennis.jpg&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=wzLHAgDxMjQ&#34;&gt;Realtime Multimodal VectorDB on NVIDIA Jetson&lt;/a&gt; (container: &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/vectordb/nanodb&#34;&gt;&lt;code&gt;nanodb&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.jetson-ai-lab.com/tutorial_nanoowl.html&#34;&gt;&lt;img src=&#34;https://github.com/NVIDIA-AI-IOT/nanoowl/raw/main/assets/jetson_person_2x.gif&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.jetson-ai-lab.com/tutorial_nanoowl.html&#34;&gt;NanoOWL - Open Vocabulary Object Detection ViT&lt;/a&gt; (container: &lt;a href=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/master/packages/vit/nanoowl&#34;&gt;&lt;code&gt;nanoowl&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=w48i8FmVvLA&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/docs/docs/images/live_llava.gif&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://youtu.be/X-OXxPiUTuU&#34;&gt;Live Llava on Jetson AGX Orin&lt;/a&gt; (container: &lt;a href=&#34;https://dusty-nv.github.io/NanoLLM/&#34;&gt;&lt;code&gt;NanoLLM&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=wZq7ynbgRoE&#34;&gt;&lt;img width=&#34;640px&#34; src=&#34;https://raw.githubusercontent.com/dusty-nv/jetson-containers/docs/docs/images/live_llava_bear.jpg&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://youtu.be/X-OXxPiUTuU&#34;&gt;Live Llava 2.0 - VILA + Multimodal NanoDB on Jetson Orin&lt;/a&gt; (container: &lt;a href=&#34;https://dusty-nv.github.io/NanoLLM/&#34;&gt;&lt;code&gt;NanoLLM&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.jetson-ai-lab.com/tutorial_slm.html&#34;&gt;&lt;img src=&#34;https://www.jetson-ai-lab.com/images/slm_console.gif&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.jetson-ai-lab.com/tutorial_slm.html&#34;&gt;Small Language Models (SLM) on Jetson Orin Nano&lt;/a&gt; (container: &lt;a href=&#34;https://dusty-nv.github.io/NanoLLM/&#34;&gt;&lt;code&gt;NanoLLM&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;/blockquote&gt;</summary>
  </entry>
  <entry>
    <title>magic-research/PLLaVA</title>
    <updated>2024-05-02T01:30:27Z</updated>
    <id>tag:github.com,2024-05-02:/magic-research/PLLaVA</id>
    <link href="https://github.com/magic-research/PLLaVA" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official repository for the paper PLLaVA&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h2&gt;&lt;a href=&#34;https://pllava.github.io/&#34;&gt;PLLaVA: Parameter-free LLaVA Extension from Images to Videos for Video Dense Captioning&lt;/a&gt;&lt;/h2&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=_Gu69coAAAAJ&#34;&gt;Lin Xu&lt;/a&gt;, &lt;a href=&#34;https://ermu2001.github.io/me.io/&#34;&gt;Yilin Zhao&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=DdCAbWwAAAAJ&#34;&gt;Daquan Zhou&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=xXMj6_EAAAAJ&#34;&gt;Zhijie Lin&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=_wsommYAAAAJ&#34;&gt;See-Kiong Ng&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com.sg/citations?user=Q8iay0gAAAAJ&amp;amp;hl=en&#34;&gt;Jiashi Feng&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;!-- [![Paper](https://img.shields.io/badge/cs.CV-2311.17005-b31b1b?logo=arxiv&amp;logoColor=red)](https://arxiv.org/abs/2311.17005) --&gt; &#xA;&lt;p&gt;&lt;strong&gt;Project Page: &lt;a href=&#34;https://pllava.github.io/&#34;&gt;PLLaVA&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2404.16994&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2404.16994-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=nAEje8tu18U&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/YouTube-Video-red&#34; alt=&#34;YouTube Video&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/ermu2001/pllava-34b&#34;&gt;&lt;img src=&#34;https://huggingface.co/datasets/huggingface/badges/resolve/main/model-on-hf-sm-dark.svg?sanitize=true&#34; alt=&#34;Model on HF&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://paperswithcode.com/sota/zeroshot-video-question-answer-on-activitynet?p=pllava-parameter-free-llava-extension-from-1&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/pllava-parameter-free-llava-extension-from-1/zeroshot-video-question-answer-on-activitynet&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://paperswithcode.com/sota/zeroshot-video-question-answer-on-msrvtt-qa?p=pllava-parameter-free-llava-extension-from-1&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/pllava-parameter-free-llava-extension-from-1/zeroshot-video-question-answer-on-msrvtt-qa&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://paperswithcode.com/sota/zeroshot-video-question-answer-on-msvd-qa?p=pllava-parameter-free-llava-extension-from-1&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/pllava-parameter-free-llava-extension-from-1/zeroshot-video-question-answer-on-msvd-qa&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://paperswithcode.com/sota/video-question-answering-on-mvbench?p=pllava-parameter-free-llava-extension-from-1&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/pllava-parameter-free-llava-extension-from-1/video-question-answering-on-mvbench&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://paperswithcode.com/sota/zeroshot-video-question-answer-on-tgif-qa?p=pllava-parameter-free-llava-extension-from-1&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/pllava-parameter-free-llava-extension-from-1/zeroshot-video-question-answer-on-tgif-qa&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://paperswithcode.com/sota/video-based-generative-performance-4?p=pllava-parameter-free-llava-extension-from-1&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/pllava-parameter-free-llava-extension-from-1/video-based-generative-performance-4&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://paperswithcode.com/sota/video-based-generative-performance-3?p=pllava-parameter-free-llava-extension-from-1&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/pllava-parameter-free-llava-extension-from-1/video-based-generative-performance-3&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://paperswithcode.com/sota/video-based-generative-performance?p=pllava-parameter-free-llava-extension-from-1&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/pllava-parameter-free-llava-extension-from-1/video-based-generative-performance&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://paperswithcode.com/sota/video-based-generative-performance-2?p=pllava-parameter-free-llava-extension-from-1&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/pllava-parameter-free-llava-extension-from-1/video-based-generative-performance-2&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://paperswithcode.com/sota/video-based-generative-performance-1?p=pllava-parameter-free-llava-extension-from-1&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/pllava-parameter-free-llava-extension-from-1/video-based-generative-performance-1&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://paperswithcode.com/sota/video-based-generative-performance-5?p=pllava-parameter-free-llava-extension-from-1&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/pllava-parameter-free-llava-extension-from-1/video-based-generative-performance-5&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://pllava.github.io&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/assert/logo.png&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;video src=&#34;https://github.com/magic-research/PLLaVA/assets/55656210/a6619702-12d3-489d-bfcc-0ef7105544b2&#34; width=&#34;100%&#34;&gt; &#xA; &lt;/video&gt;&#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;Welcome to PLLAVA!&lt;/p&gt; &#xA;&lt;p&gt;The primary purpose of this repository is to support research and the development of prototype models. It is designed to facilitate ease of experimentation and enable a clear overview of results. Please note that this repo is currently undergoing development and reconstruction.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s important to mention that we have not optimized the response speed of the application or the frontend logic. Our goal is to maintain simplicity, clarity, and ease of development, making it accessible for both researchers and students. If you have suggestions or want to enhance the application&#39;s performance, please feel free to contact us or contribute to the project.&lt;/p&gt; &#xA;&lt;p&gt;We&#39;ve briefly introduce our work in section &lt;a href=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/#%EF%B8%8F-pllava&#34;&gt;PLLAVA&lt;/a&gt;. For more details, feel free to read our paper. Check out section &lt;a href=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/#hammer-usage&#34;&gt;Usage&lt;/a&gt; to start using this repo. If you felt our works interesting, please star us, your support is all we want. If you find our work helpful, feel free to &lt;a href=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/#page_facing_up-citation&#34;&gt;cite&lt;/a&gt; us directly.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;ğŸ”¥&lt;/span&gt; Updates&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;2024/4/24&lt;/strong&gt;: Release: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;We are releasing our code/models/datasets.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ–ï¸ PLLAVA&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://www.youtube.com/embed/nAEje8tu18U?si=GXxjgP93j77FzDbw&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/assert/teaser.jpg&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Abstract&lt;/h3&gt; &#xA;&lt;p&gt;Vision-language pre-training (VLP) has significantly elevated performance across a range of vision-language applications. Yet, the pre-training process for video-related tasks demands an exceptionally high degree of computational and data resources. This paper investigates a straightforward, highly efficient, and resource-light approach to adapting an existing image-language pre-training model for video data. Our preliminary experiments reveal that directly fine-tuning pre-trained image-language models with multiple frames on video datasets leads to performance saturation or even a drop in caption-related tasks. Besides, it is also vulnerable to prompts and tends to provide short descriptions. We conducted a deep analysis and observed that the performance saturation and the vulnerability might be related to the dominant patches that exist in some single video patches. We then propose a simple pooling strategy to smooth the feature distribution along the temporal dimension and thus reduce the dominant impacts from some extreme tokens. The new model is termed Pooling LLaVA, or PLLaVA in short. With the proposed pooling strategy, we achieve new state-of-the-art performance on all evaluated datasets. Notably, on the recent popular Video ChatGPT benchmark, PLLaVA achieves a score of 3.48 out of 5 on average of five evaluated dimensions, which is the new state-of-the-art score on the leaderboard and is 0.31 higher than the previous SOTA results from GPT4V (IG-VLM). On the latest multi-choice benchmark MVBench, PLLaVA achieves 58.1% accuracy on average across 20 sub-tasks, which is the new state-of-the-art result and is 14.5% higher than GPT4V (IG-VLM).&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA; &lt;img src=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/assert/module.png&#34;&gt;&#xA;&lt;/div&gt; &#xA;&lt;h3&gt;SEARCHING FOR OPTIMAL POOLING STRATEGY&lt;/h3&gt; &#xA;&lt;p&gt;There are two dimensions for the pooling strategy: the spatial dimension and the temporal dimension. We empirically found that reducing the spatial dimension with a larger temporal dimension could lead to better model performance, compared to reducing the temporal dimension directly.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA; &lt;img src=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/assert/zeroshot.png&#34;&gt;&#xA;&lt;/div&gt; &#xA;&lt;h3&gt;STATE-OF-THE-ART PERFORMANCE&lt;/h3&gt; &#xA;&lt;p&gt;We compare the performance of PLLAVA with recent popular methods over both question-answer and captioning datasets. The results are shown below.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA; &lt;img src=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/assert/performance.png&#34;&gt;&#xA;&lt;/div&gt; &#xA;&lt;h2&gt;&lt;span&gt;ğŸ”¨&lt;/span&gt; Usage&lt;/h2&gt; &#xA;&lt;p&gt;This section provides guidance on how to run, train, and evaluate our models.&lt;/p&gt; &#xA;&lt;h3&gt;Install&lt;/h3&gt; &#xA;&lt;p&gt;First, you will need to set up the environment and download some pre-trained weights.&lt;/p&gt; &#xA;&lt;p&gt;This repo is built up using &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;transformers&lt;/a&gt; for model construction along with &lt;a href=&#34;https://github.com/huggingface/accelerate&#34;&gt;accelerate&lt;/a&gt; for distributed training. Follow the instructions to install the needed environment.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Above all, the following environment set up is for python 3.10. If you choose to use conda for environment setup, we recommend creating the virtual environment with:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n pllava python=3.10&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Firstly, install &lt;a href=&#34;https://pytorch.org/&#34;&gt;pytorch&lt;/a&gt; from the official website. The code runs on torch 2.2.1, cu118 or cu122. Select the version that suits your drive version.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;torch                       2.2.1+cu118&#xA;torchaudio                  2.2.1+cu118&#xA;torchvision                 0.17.1+cu118&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If your driver version is higher than cu121, you could probably try installing with the following scripts:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Otherwise, you would need to install a torch for your server first, then install the other packages:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.torch.txt # decide your own requirements, (this is for cu11), or install torch directly following the official website.&#xA;pip install -r requirements.no_torch.txt # install the following&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Prepare the model. We prefer to have huggingface models explicitly downloaded to a MODELS directory. However, if you are familiar with huggingface-hub usage, feel free to organize the model yourself.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;python python_scripts/hf.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here are some detailed information of the obtained models:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Link&lt;/th&gt; &#xA;   &lt;th&gt;Initialized From&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;pllava-7b&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/ermu2001/pllava-7b&#34;&gt;&lt;img src=&#34;https://huggingface.co/datasets/huggingface/badges/resolve/main/model-on-hf-sm-dark.svg?sanitize=true&#34; alt=&#34;Model on HF&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/llava-hf/llava-v1.6-vicuna-7b-hf&#34;&gt;llava-hf/llava-v1.6-vicuna-7b-hf Â· Hugging Face&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;pllava-13b&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/ermu2001/pllava-13b&#34;&gt;&lt;img src=&#34;https://huggingface.co/datasets/huggingface/badges/resolve/main/model-on-hf-sm-dark.svg?sanitize=true&#34; alt=&#34;Model on HF&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/llava-hf/llava-v1.6-vicuna-13b-hf&#34;&gt;llava-hf/llava-v1.6-vicuna-13b-hf Â· Hugging Face&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;pllava-34b&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/ermu2001/pllava-34b&#34;&gt;&lt;img src=&#34;https://huggingface.co/datasets/huggingface/badges/resolve/main/model-on-hf-sm-dark.svg?sanitize=true&#34; alt=&#34;Model on HF&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/llava-hf/llava-v1.6-34b-hf&#34;&gt;llava-hf/llava-v1.6-34b-hf Â· Hugging Face&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The model directory should look like this, where you would only need the corresponding model&#39;s weights and directory.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ tree MODELS&#xA;MODELS&#xA;|-- pllava-13b&#xA;|   |-- added_tokens.json&#xA;|   |-- config.json&#xA;|   |-- generation_config.json&#xA;|   |-- model-00001-of-00006.safetensors&#xA;|   |-- model-00002-of-00006.safetensors&#xA;|   |-- model-00003-of-00006.safetensors&#xA;|   |-- model-00004-of-00006.safetensors&#xA;|   |-- model-00005-of-00006.safetensors&#xA;|   |-- model-00006-of-00006.safetensors&#xA;|   |-- model.safetensors.index.json&#xA;|   |-- preprocessor_config.json&#xA;|   |-- processor_config.json&#xA;|   |-- special_tokens_map.json&#xA;|   |-- tokenizer.json&#xA;|   |-- tokenizer.model&#xA;|   `-- tokenizer_config.json&#xA;|-- pllava-34b&#xA;|   |-- added_tokens.json&#xA;|   |-- config.json&#xA;|   |-- generation_config.json&#xA;|   |-- model-00001-of-00015.safetensors&#xA;|   |-- model-00002-of-00015.safetensors&#xA;|   |-- model-00003-of-00015.safetensors&#xA;|   |-- model-00004-of-00015.safetensors&#xA;|   |-- model-00005-of-00015.safetensors&#xA;|   |-- model-00006-of-00015.safetensors&#xA;|   |-- model-00007-of-00015.safetensors&#xA;|   |-- model-00008-of-00015.safetensors&#xA;|   |-- model-00009-of-00015.safetensors&#xA;|   |-- model-00010-of-00015.safetensors&#xA;|   |-- model-00011-of-00015.safetensors&#xA;|   |-- model-00012-of-00015.safetensors&#xA;|   |-- model-00013-of-00015.safetensors&#xA;|   |-- model-00014-of-00015.safetensors&#xA;|   |-- model-00015-of-00015.safetensors&#xA;|   |-- model.safetensors-deprecated&#xA;|   |-- model.safetensors.index.json&#xA;|   |-- preprocessor_config.json&#xA;|   |-- processor_config.json&#xA;|   |-- special_tokens_map.json&#xA;|   |-- tokenizer.json&#xA;|   |-- tokenizer.model&#xA;|   `-- tokenizer_config.json&#xA;|-- pllava-7b&#xA;    |-- added_tokens.json&#xA;    |-- config.json&#xA;    |-- generation_config.json&#xA;    |-- model-00001-of-00003.safetensors&#xA;    |-- model-00002-of-00003.safetensors&#xA;    |-- model-00003-of-00003.safetensors&#xA;    |-- model.safetensors.index.json&#xA;    |-- preprocessor_config.json&#xA;    |-- processor_config.json&#xA;    |-- special_tokens_map.json&#xA;    |-- tokenizer.json&#xA;    |-- tokenizer.model&#xA;    `-- tokenizer_config.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;With the above steps, you should be able to proceed on with the following usages.&lt;/p&gt; &#xA;&lt;h3&gt;Run Application&lt;/h3&gt; &#xA;&lt;p&gt;To run our models, make sure you have downloaded a model pretrained weights from the huggingface spaces. Then, run the following scripts with the corresponding path input. Since we are only training with lora and the projector, the model to be run are determined with:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;model_dir&lt;/strong&gt;: model directory, one with config.json as compatible with transformers. This refers to the base model&#39;s directory, for example &#34;llava-hf/llava-v1.6-vicuna-7b-hf&#34;/&#34;ermu2001/pllava-7b&#34;/&#34;MODELS/pllava-7b&#34;. (default to: MODELS/plave-7b)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;weights_dir&lt;/strong&gt;: your weights directory. could be the same as model_dir, but if you have a weights directory for the lora weights, you should set this weights_dir to that directory to load the lora weights. This directory should be local. Also, it would need to contain a config.json file within. (default to: ${model_dir}).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;model_dir=&#34;model directory&#34;&#xA;weights_dir=&#34;weights directory&#34;&#xA;bash scripts/demo.sh ${model_dir} ${weights_dir}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now check out the application demo and try play with PLLAVA!&lt;/p&gt; &#xA;&lt;h3&gt;Train&lt;/h3&gt; &#xA;&lt;p&gt;Follow the following steps to reproduce our results or train your own variant:&lt;/p&gt; &#xA;&lt;h4&gt;1. Data Preparation&lt;/h4&gt; &#xA;&lt;p&gt;To train our model from a starting Image-aligned Vision LLM, you would need to download the data first. Our data set up is mainly based on the original Videochat2&#39;s training data. Check out &lt;a href=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/DATA.md&#34;&gt;Instruction Data&lt;/a&gt; to prepare the instruction training data. Ideally, setting up a root data directory and alter the code &lt;a href=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/tasks/train/instruction_data.py#L6&#34;&gt;here&lt;/a&gt; would accomodate the data for training most smoothly.&lt;/p&gt; &#xA;&lt;h4&gt;2. Start Training&lt;/h4&gt; &#xA;&lt;p&gt;Now you&#39;re only a few step away from starting the training. Follow the instructions:&lt;/p&gt; &#xA;&lt;h5&gt;Setup Accelerator&lt;/h5&gt; &#xA;&lt;p&gt;Customize a accelerate training config. For example, a simple config using multiple gpus with no distribution strategy (only torch DDP) would look like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;compute_environment: LOCAL_MACHINE&#xA;debug: false&#xA;distributed_type: MULTI_GPU&#xA;downcast_bf16: &#39;no&#39;&#xA;gpu_ids: all&#xA;machine_rank: 0&#xA;main_training_function: main&#xA;mixed_precision: bf16&#xA;num_machines: 1&#xA;num_processes: 8&#xA;rdzv_backend: static&#xA;same_network: true&#xA;tpu_env: []&#xA;tpu_use_cluster: false&#xA;tpu_use_sudo: false&#xA;use_cpu: false&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Check out out the &lt;a href=&#34;https://huggingface.co/docs/accelerate/index&#34;&gt;Accelerate&lt;/a&gt; documents for more details.&lt;/p&gt; &#xA;&lt;h5&gt;Overwatch the training configuration&lt;/h5&gt; &#xA;&lt;p&gt;Next, you should go over a basic training configuration of the training process in &lt;a href=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/tasks/train/config_pllava_nframe.py&#34;&gt;here&lt;/a&gt;. Then passing this file as the first arg to the &lt;a href=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/tasks/train/train_pllava_nframe_accel.py&#34;&gt;training script&lt;/a&gt; would utilize every arguments in the file. You can customize some of the hyper parameters for your own training process by passing them in the format of &#34;key&#34; &#34;value&#34; pair in the following arguments. A example training scripts could be find &lt;a href=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/scripts/train_pllava.sh&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We recommand customize a &lt;a href=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/tasks/train/config_pllava_nframe.py&#34;&gt;configuration&lt;/a&gt; to set up a customized training!&lt;/p&gt; &#xA;&lt;p&gt;With the above steps, you would be able to start the training process. The output would be well organized in the output directory, each a qualified model directory to pass in to demo as weights_dir, since we are only saveing the lora weights and projector weights to avoide redundancy.&lt;/p&gt; &#xA;&lt;h3&gt;Evaluation&lt;/h3&gt; &#xA;&lt;p&gt;This section mainly introduce how to reproduce the evaluation or evaluate your own model.&lt;/p&gt; &#xA;&lt;h4&gt;Set up Evaluation Data&lt;/h4&gt; &#xA;&lt;p&gt;Make sure you set up the &#34;DATAS&#34; directory as in &lt;a href=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/DATA.md&#34;&gt;DATA.md&lt;/a&gt;, then you would be able to run the inference with fortune! The evaluation data directory of DATAS would look like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;DATAS/:&#xA;DATAS/VideoQA:&#xA;DATAS/VideoQA/TGIF_QA:&#xA;                     test_a.json&#xA;                     test_q.json&#xA;DATAS/VideoQA/TGIF_QA/videos:&#xA;                            tumblr_m4387mGrlc1r6m5e8o1_250.gif&#xA;                            ...&#xA;DATAS/VideoQA/TGIF_QA/videos_mp4:&#xA;                                tumblr_m4387mGrlc1r6m5e8o1_250.mp4&#xA;                                ...&#xA;DATAS/VideoQA/TGIF_QA/video_gif:&#xA;                               tumblr_m4387mGrlc1r6m5e8o1_250.gif&#xA;                               ...&#xA;DATAS/VideoQA/MSVD_Zero_Shot_QA:&#xA;                               test_a.json&#xA;                               test_q.json&#xA;DATAS/VideoQA/MSVD_Zero_Shot_QA/videos:&#xA;                                      -4wsuPCjDBc_5_15.avi&#xA;DATAS/VideoQA/MSVD_Zero_Shot_QA/msvd_qa:&#xA;DATAS/VideoQA/ActivityNet:&#xA;                         test_a.json&#xA;                         test_q.json&#xA;DATAS/VideoQA/ActivityNet/all_test:&#xA;                                  v_--tFD65KaK4.mp4&#xA;                                  ...&#xA;DATAS/VideoQA/MSRVTT_Zero_Shot_QA:&#xA;                                 test_a.json&#xA;                                 test_q.json&#xA;DATAS/VideoQA/MSRVTT_Zero_Shot_QA/videos:&#xA;DATAS/VideoQA/MSRVTT_Zero_Shot_QA/videos/all:&#xA;                                            video0.mp4&#xA;                                            ...&#xA;&#xA;DATAS/MVBench:&#xA;             ...&#xA;&#xA;DATAS/Recaption/Inter4K:&#xA;                       annotations.json&#xA;DATAS/Recaption/Inter4K/60fps:&#xA;DATAS/Recaption/Inter4K/60fps/UHD:&#xA;                                 1.mp4&#xA;                                 ...&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Start Evaluate&lt;/h4&gt; &#xA;&lt;p&gt;Once you have construted the evaluation data, you can start the evaluation as in &lt;a href=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/scripts/eval.sh&#34;&gt;here&lt;/a&gt;. This script is for evaluating 7B/13B models. As pllava-34b model uses a slightly different prompting, it is evaluated with this &lt;a href=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/scripts/eval_yiprompt.sh&#34;&gt;script&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;bash scripts/eval.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Same as running the demo, you would need to determine the model_dir and weights_dir to evaluate the model. Feel free to comment out some commands and produce partial evaluation.&lt;/p&gt; &#xA;&lt;h4&gt;Overwatch the Results&lt;/h4&gt; &#xA;&lt;p&gt;The evaluation results would be shown to you with our results gallery demo:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bash scripts/gallery.sh &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Feel free to use the compare version to compare differnt models&#39; results or use the single gallery version to check out one model&#39;s results. They are basically the same. Check out this &lt;a href=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/scripts/gallery.sh&#34;&gt;script&lt;/a&gt; for more details&lt;/p&gt; &#xA;&lt;h4&gt;For Captioning and Recaptioning&lt;/h4&gt; &#xA;&lt;p&gt;Follow instructions at &lt;a href=&#34;https://raw.githubusercontent.com/magic-research/PLLaVA/main/DATA.md#extending-reacptioning&#34;&gt;DATA.md&lt;/a&gt; and you can extend the recaptioning data with a few steps.&lt;/p&gt; &#xA;&lt;p&gt;Feel free to point out high quality dataset of videos, we would proceed on doing captioning on those datasets.&lt;/p&gt; &#xA;&lt;h1&gt;&lt;span&gt;ğŸ“„&lt;/span&gt; Citation&lt;/h1&gt; &#xA;&lt;p&gt;If you find this project useful in your research, please consider cite:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-BibTeX&#34;&gt;@misc{xu2024pllava,&#xA;      title={PLLaVA : Parameter-free LLaVA Extension from Images to Videos for Video Dense Captioning}, &#xA;      author={Lin Xu and Yilin Zhao and Daquan Zhou and Zhijie Lin and See Kiong Ng and Jiashi Feng},&#xA;      year={2024},&#xA;      eprint={2404.16994},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;&lt;span&gt;ğŸ’«&lt;/span&gt; Acknowledgement&lt;/h1&gt; &#xA;&lt;p&gt;This code base is mainly built upon &lt;a href=&#34;https://github.com/OpenGVLab/Ask-Anything/tree/main/video_chat2&#34;&gt;Videochat2&lt;/a&gt;. SALUTE.&lt;/p&gt; &#xA;&lt;p&gt;We would also like to recognize and commend the following open source projects, thank you for your great contribution to the open source community:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/haotian-liu/LLaVA&#34;&gt;LLaVA&lt;/a&gt;: Fantastic Open Source Image LLM Model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mbzuai-oryx/Video-ChatGPT/tree/main&#34;&gt;VideoChatGPT&lt;/a&gt;: Great Evaluation Benchmarking Framework.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/PKU-YuanGroup/Video-LLaVA/tree/main/videollava&#34;&gt;VideoLlava&lt;/a&gt;ï¼šVideo LLM repo with helpful resources.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>