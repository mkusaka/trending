<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-15T01:35:09Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>justakazh/sicat</title>
    <updated>2024-02-15T01:35:09Z</updated>
    <id>tag:github.com,2024-02-15:/justakazh/sicat</id>
    <link href="https://github.com/justakazh/sicat" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The useful exploit finder&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SiCat - The useful exploit finder&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/justakazh/sicat/main/vendor/preview.png&#34; alt=&#34;SiCat Preview&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;SiCat is an advanced exploit search tool designed to identify and gather information about exploits from both open sources and local repositories effectively. With a focus on cybersecurity, SiCat allows users to quickly search online, finding potential vulnerabilities and relevant exploits for ongoing projects or systems.&lt;/p&gt; &#xA;&lt;p&gt;SiCat&#39;s main strength lies in its ability to traverse both online and local resources to collect information about relevant exploitations. This tool aids cybersecurity professionals and researchers in understanding potential security risks, providing valuable insights to enhance system security.&lt;/p&gt; &#xA;&lt;h3&gt;SiCat Resources&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.exploit-db.com/&#34;&gt;Exploit-DB&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://packetstormsecurity.com/&#34;&gt;Packetstorm Security&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.exploitalert.com/&#34;&gt;Exploit Alert&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nvd.nist.gov/&#34;&gt;NVD Database&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rapid7/metasploit-framework/tree/master/modules&#34;&gt;Metasploit Modules&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&#xA;pip  install  -r  requirements.txt&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&#xA;~$ python sicat.py --help&#xA;&#xA;  &#xA;&#xA;_._  _,-&#39;&#34;&#34;`-._&#xA;&#xA;(,-.`._,&#39;( |\`-/|&#xA;&#xA;`-.-&#39; \ )-`( , o o)&#xA;&#xA;`- \`_`&#34;&#39;-&#xA;&#xA;SiCat - The useful exploit finder&#xA;&#xA;@justakazh (https://github.com/justakazh/sicat)&#xA;&#xA;  &#xA;&#xA;usage : sicat.py --help&#xA;&#xA;usage: sicat.py [-h] [-k KEYWORD] [-kv KEYWORD_VERSION] [-nm NMAP] [--nvd] [--packetstorm] [--exploitdb] [--exploitalert] [--msfmodule] [-o OUTPUT] [-ot OUTPUT_TYPE]&#xA;&#xA;  &#xA;&#xA;Script to search for vulnerability and exploitation information.&#xA;&#xA;  &#xA;&#xA;options:&#xA;&#xA;-h,  --help show this help message and exit&#xA;&#xA;-k KEYWORD, --keyword KEYWORD&#xA;&#xA;File name or path to save the output&#xA;&#xA;-kv KEYWORD_VERSION, --keyword_version KEYWORD_VERSION&#xA;&#xA;File name or path to save the output&#xA;&#xA;-nm NMAP, --nmap NMAP&#xA;&#xA;Identify via nmap output&#xA;&#xA;--nvd Use NVD as a source of information&#xA;&#xA;--packetstorm Use PacketStorm as a source of information&#xA;&#xA;--exploitdb Use ExploitDB as a source of information&#xA;&#xA;--exploitalert Use ExploitAlert as a source of information&#xA;&#xA;--msfmodule Use metasploit module as a source of information&#xA;&#xA;-o OUTPUT, --output OUTPUT&#xA;&#xA;path to save the output&#xA;&#xA;-ot OUTPUT_TYPE, --output_type OUTPUT_TYPE&#xA;&#xA;output file type json and html&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Example&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;From keyword&lt;/em&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;python sicat -k telerik --exploitdb --msfmodule&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;From nmap output&lt;/em&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;nmap -sV localhost -oX nmap_out.xml&#xA;python sicat -nm nnmap_out.xml --packetstorm&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;To-do&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Input from nmap result from pipeline&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Nmap multiple host support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Search NSE Script&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contribution&lt;/h2&gt; &#xA;&lt;p&gt;I&#39;m aware that perfection is elusive in coding. If you come across any bugs, feel free to contribute by fixing the code or suggesting new features. Your input is always welcomed and valued.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Lightning-AI/pytorch-lightning</title>
    <updated>2024-02-15T01:35:09Z</updated>
    <id>tag:github.com,2024-02-15:/Lightning-AI/pytorch-lightning</id>
    <link href="https://github.com/Lightning-AI/pytorch-lightning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Pretrain, finetune and deploy AI models on multiple GPUs, TPUs with zero code changes.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img alt=&#34;Lightning&#34; src=&#34;https://pl-public-data.s3.amazonaws.com/assets_lightning/LightningColor.png&#34; width=&#34;800px&#34; style=&#34;max-width: 100%;&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;strong&gt;The deep learning framework to pretrain, finetune and deploy AI models.&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;NEW- Lightning 2.0 features a clean and stable API!!&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;hr&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://lightning.ai/&#34;&gt;Lightning.ai&lt;/a&gt; • &lt;a href=&#34;https://lightning.ai/docs/pytorch/stable/&#34;&gt;PyTorch Lightning&lt;/a&gt; • &lt;a href=&#34;https://lightning.ai/docs/fabric/stable/&#34;&gt;Fabric&lt;/a&gt; • &lt;a href=&#34;https://lightning.ai/docs/app/stable/&#34;&gt;Lightning Apps&lt;/a&gt; • &lt;a href=&#34;https://pytorch-lightning.readthedocs.io/en/stable/&#34;&gt;Docs&lt;/a&gt; • &lt;a href=&#34;https://raw.githubusercontent.com/Lightning-AI/pytorch-lightning/master/#community&#34;&gt;Community&lt;/a&gt; • &lt;a href=&#34;https://lightning.ai/docs/pytorch/stable/generated/CONTRIBUTING.html&#34;&gt;Contribute&lt;/a&gt; • &lt;/p&gt; &#xA; &lt;!-- DO NOT ADD CONDA DOWNLOADS... README CHANGES MUST BE APPROVED BY EDEN OR WILL --&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://pypi.org/project/pytorch-lightning/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/pytorch-lightning&#34; alt=&#34;PyPI - Python Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://badge.fury.io/py/pytorch-lightning&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/pytorch-lightning.svg?sanitize=true&#34; alt=&#34;PyPI Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/pytorch-lightning&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/pytorch-lightning&#34; alt=&#34;PyPI - Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://anaconda.org/conda-forge/lightning&#34;&gt;&lt;img src=&#34;https://img.shields.io/conda/v/conda-forge/lightning?label=conda&amp;amp;color=success&#34; alt=&#34;Conda&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/Lightning-AI/pytorch-lightning&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/Lightning-AI/pytorch-lightning/graph/badge.svg?token=SmzX8mnKlA&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://discord.gg/VptPCZkGNa&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1077906959069626439?style=plastic&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/commit-activity/w/lightning-ai/lightning&#34; alt=&#34;GitHub commit activity&#34;&gt; &lt;a href=&#34;https://github.com/Lightning-AI/lightning/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true&#34; alt=&#34;license&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;!--&#xA;[![CodeFactor](https://www.codefactor.io/repository/github/Lightning-AI/lightning/badge)](https://www.codefactor.io/repository/github/Lightning-AI/lightning)&#xA;--&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Install Lightning&lt;/h2&gt; &#xA;&lt;p&gt;Simple installation from PyPI&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install lightning&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- following section will be skipped from PyPI description --&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Other installation options&lt;/summary&gt; &#xA; &lt;!-- following section will be skipped from PyPI description --&gt; &#xA; &lt;h4&gt;Install with optional dependencies&lt;/h4&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install lightning[&#39;extra&#39;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;Conda&lt;/h4&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda install lightning -c conda-forge&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;Install stable version&lt;/h4&gt; &#xA; &lt;p&gt;Install future release from the source&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install https://github.com/Lightning-AI/lightning/archive/refs/heads/release/stable.zip -U&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;Install bleeding-edge&lt;/h4&gt; &#xA; &lt;p&gt;Install nightly from the source (no guarantees)&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install https://github.com/Lightning-AI/lightning/archive/refs/heads/master.zip -U&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;or from testing PyPI&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -iU https://test.pypi.org/simple/ pytorch-lightning&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;!-- end skipping PyPI description --&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Lightning has 4 core packages&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Lightning-AI/pytorch-lightning/master/#pytorch-lightning-train-and-deploy-pytorch-at-scale&#34;&gt;PyTorch Lightning: Train and deploy PyTorch at scale&lt;/a&gt;. &lt;br&gt; &lt;a href=&#34;https://raw.githubusercontent.com/Lightning-AI/pytorch-lightning/master/#lightning-fabric-expert-control&#34;&gt;Lightning Fabric: Expert control&lt;/a&gt;. &lt;br&gt; &lt;a href=&#34;https://github.com/Lightning-AI/pytorch-lightning/tree/master/src/lightning/data&#34;&gt;Lightning Data: Blazing fast, distributed streaming of training data from cloud storage&lt;/a&gt;. &lt;br&gt; &lt;a href=&#34;https://raw.githubusercontent.com/Lightning-AI/pytorch-lightning/master/#lightning-apps-build-ai-products-and-ml-workflows&#34;&gt;Lightning Apps: Build AI products and ML workflows&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Lightning gives you granular control over how much abstraction you want to add over PyTorch.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://pl-public-data.s3.amazonaws.com/assets_lightning/continuum.png&#34; width=&#34;80%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;PyTorch Lightning: Train and Deploy PyTorch at Scale&lt;/h1&gt; &#xA;&lt;p&gt;PyTorch Lightning is just organized PyTorch - Lightning disentangles PyTorch code to decouple the science from the engineering.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Lightning-AI/pytorch-lightning/master/docs/source-pytorch/_static/images/general/pl_quick_start_full_compressed.gif&#34; alt=&#34;PT to PL&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Hello simple model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# main.py&#xA;# ! pip install torchvision&#xA;import torch, torch.nn as nn, torch.utils.data as data, torchvision as tv, torch.nn.functional as F&#xA;import lightning as L&#xA;&#xA;# --------------------------------&#xA;# Step 1: Define a LightningModule&#xA;# --------------------------------&#xA;# A LightningModule (nn.Module subclass) defines a full *system*&#xA;# (ie: an LLM, diffusion model, autoencoder, or simple image classifier).&#xA;&#xA;&#xA;class LitAutoEncoder(L.LightningModule):&#xA;    def __init__(self):&#xA;        super().__init__()&#xA;        self.encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.ReLU(), nn.Linear(128, 3))&#xA;        self.decoder = nn.Sequential(nn.Linear(3, 128), nn.ReLU(), nn.Linear(128, 28 * 28))&#xA;&#xA;    def forward(self, x):&#xA;        # in lightning, forward defines the prediction/inference actions&#xA;        embedding = self.encoder(x)&#xA;        return embedding&#xA;&#xA;    def training_step(self, batch, batch_idx):&#xA;        # training_step defines the train loop. It is independent of forward&#xA;        x, y = batch&#xA;        x = x.view(x.size(0), -1)&#xA;        z = self.encoder(x)&#xA;        x_hat = self.decoder(z)&#xA;        loss = F.mse_loss(x_hat, x)&#xA;        self.log(&#34;train_loss&#34;, loss)&#xA;        return loss&#xA;&#xA;    def configure_optimizers(self):&#xA;        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)&#xA;        return optimizer&#xA;&#xA;&#xA;# -------------------&#xA;# Step 2: Define data&#xA;# -------------------&#xA;dataset = tv.datasets.MNIST(&#34;.&#34;, download=True, transform=tv.transforms.ToTensor())&#xA;train, val = data.random_split(dataset, [55000, 5000])&#xA;&#xA;# -------------------&#xA;# Step 3: Train&#xA;# -------------------&#xA;autoencoder = LitAutoEncoder()&#xA;trainer = L.Trainer()&#xA;trainer.fit(autoencoder, data.DataLoader(train), data.DataLoader(val))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the model on your terminal&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install torchvision&#xA;python main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Advanced features&lt;/h2&gt; &#xA;&lt;p&gt;Lightning has over &lt;a href=&#34;https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-flags&#34;&gt;40+ advanced features&lt;/a&gt; designed for professional AI research at scale.&lt;/p&gt; &#xA;&lt;p&gt;Here are some examples:&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/features_2.jpg&#34; max-height=&#34;600px&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Train on 1000s of GPUs without code changes&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 8 GPUs&#xA;# no code changes needed&#xA;trainer = Trainer(accelerator=&#34;gpu&#34;, devices=8)&#xA;&#xA;# 256 GPUs&#xA;trainer = Trainer(accelerator=&#34;gpu&#34;, devices=8, num_nodes=32)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Train on other accelerators like TPUs without code changes&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# no code changes needed&#xA;trainer = Trainer(accelerator=&#34;tpu&#34;, devices=8)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;16-bit precision&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# no code changes needed&#xA;trainer = Trainer(precision=16)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Experiment managers&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from lightning import loggers&#xA;&#xA;# tensorboard&#xA;trainer = Trainer(logger=TensorBoardLogger(&#34;logs/&#34;))&#xA;&#xA;# weights and biases&#xA;trainer = Trainer(logger=loggers.WandbLogger())&#xA;&#xA;# comet&#xA;trainer = Trainer(logger=loggers.CometLogger())&#xA;&#xA;# mlflow&#xA;trainer = Trainer(logger=loggers.MLFlowLogger())&#xA;&#xA;# neptune&#xA;trainer = Trainer(logger=loggers.NeptuneLogger())&#xA;&#xA;# ... and dozens more&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Early Stopping&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;es = EarlyStopping(monitor=&#34;val_loss&#34;)&#xA;trainer = Trainer(callbacks=[es])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Checkpointing&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;checkpointing = ModelCheckpoint(monitor=&#34;val_loss&#34;)&#xA;trainer = Trainer(callbacks=[checkpointing])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Export to torchscript (JIT) (production use)&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# torchscript&#xA;autoencoder = LitAutoEncoder()&#xA;torch.jit.save(autoencoder.to_torchscript(), &#34;model.pt&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Export to ONNX (production use)&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# onnx&#xA;with tempfile.NamedTemporaryFile(suffix=&#34;.onnx&#34;, delete=False) as tmpfile:&#xA;    autoencoder = LitAutoEncoder()&#xA;    input_sample = torch.randn((1, 64))&#xA;    autoencoder.to_onnx(tmpfile.name, input_sample, export_params=True)&#xA;    os.path.isfile(tmpfile.name)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Advantages over unstructured PyTorch&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Models become hardware agnostic&lt;/li&gt; &#xA; &lt;li&gt;Code is clear to read because engineering code is abstracted away&lt;/li&gt; &#xA; &lt;li&gt;Easier to reproduce&lt;/li&gt; &#xA; &lt;li&gt;Make fewer mistakes because lightning handles the tricky engineering&lt;/li&gt; &#xA; &lt;li&gt;Keeps all the flexibility (LightningModules are still PyTorch modules), but removes a ton of boilerplate&lt;/li&gt; &#xA; &lt;li&gt;Lightning has dozens of integrations with popular machine learning tools.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Lightning-AI/lightning/tree/master/tests&#34;&gt;Tested rigorously with every new PR&lt;/a&gt;. We test every combination of PyTorch and Python supported versions, every OS, multi GPUs and even TPUs.&lt;/li&gt; &#xA; &lt;li&gt;Minimal running speed overhead (about 300 ms per epoch compared with pure PyTorch).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://lightning.ai/docs/pytorch/stable/&#34;&gt;Read the PyTorch Lightning docs&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Lightning Fabric: Expert control.&lt;/h1&gt; &#xA;&lt;p&gt;Run on any device at any scale with expert-level control over PyTorch training loop and scaling strategy. You can even write your own Trainer.&lt;/p&gt; &#xA;&lt;p&gt;Fabric is designed for the most complex models like foundation model scaling, LLMs, diffusion, transformers, reinforcement learning, active learning. Of any size.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;What to change&lt;/th&gt; &#xA;   &lt;th&gt;Resulting Fabric Code (copy me!)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;sub&gt; &lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;+ import lightning as L&#xA;  import torch; import torchvision as tv&#xA;&#xA; dataset = tv.datasets.CIFAR10(&#34;data&#34;, download=True,&#xA;                               train=True,&#xA;                               transform=tv.transforms.ToTensor())&#xA;&#xA;+ fabric = L.Fabric()&#xA;+ fabric.launch()&#xA;&#xA;  model = tv.models.resnet18()&#xA;  optimizer = torch.optim.SGD(model.parameters(), lr=0.001)&#xA;- device = &#34;cuda&#34; if torch.cuda.is_available() else &#34;cpu&#34;&#xA;- model.to(device)&#xA;+ model, optimizer = fabric.setup(model, optimizer)&#xA;&#xA;  dataloader = torch.utils.data.DataLoader(dataset, batch_size=8)&#xA;+ dataloader = fabric.setup_dataloaders(dataloader)&#xA;&#xA;  model.train()&#xA;  num_epochs = 10&#xA;  for epoch in range(num_epochs):&#xA;      for batch in dataloader:&#xA;          inputs, labels = batch&#xA;-         inputs, labels = inputs.to(device), labels.to(device)&#xA;          optimizer.zero_grad()&#xA;          outputs = model(inputs)&#xA;          loss = torch.nn.functional.cross_entropy(outputs, labels)&#xA;-         loss.backward()&#xA;+         fabric.backward(loss)&#xA;          optimizer.step()&#xA;          print(loss.data)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/sub&gt; &lt;/td&gt;&#xA;   &lt;td&gt; &lt;sub&gt; &lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;import lightning as L&#xA;import torch; import torchvision as tv&#xA;&#xA;dataset = tv.datasets.CIFAR10(&#34;data&#34;, download=True,&#xA;                              train=True,&#xA;                              transform=tv.transforms.ToTensor())&#xA;&#xA;fabric = L.Fabric()&#xA;fabric.launch()&#xA;&#xA;model = tv.models.resnet18()&#xA;optimizer = torch.optim.SGD(model.parameters(), lr=0.001)&#xA;model, optimizer = fabric.setup(model, optimizer)&#xA;&#xA;dataloader = torch.utils.data.DataLoader(dataset, batch_size=8)&#xA;dataloader = fabric.setup_dataloaders(dataloader)&#xA;&#xA;model.train()&#xA;num_epochs = 10&#xA;for epoch in range(num_epochs):&#xA;    for batch in dataloader:&#xA;        inputs, labels = batch&#xA;        optimizer.zero_grad()&#xA;        outputs = model(inputs)&#xA;        loss = torch.nn.functional.cross_entropy(outputs, labels)&#xA;        fabric.backward(loss)&#xA;        optimizer.step()&#xA;        print(loss.data)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/sub&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Key features&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Easily switch from running on CPU to GPU (Apple Silicon, CUDA, …), TPU, multi-GPU or even multi-node training&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Use your available hardware&#xA;# no code changes needed&#xA;fabric = Fabric()&#xA;&#xA;# Run on GPUs (CUDA or MPS)&#xA;fabric = Fabric(accelerator=&#34;gpu&#34;)&#xA;&#xA;# 8 GPUs&#xA;fabric = Fabric(accelerator=&#34;gpu&#34;, devices=8)&#xA;&#xA;# 256 GPUs, multi-node&#xA;fabric = Fabric(accelerator=&#34;gpu&#34;, devices=8, num_nodes=32)&#xA;&#xA;# Run on TPUs&#xA;fabric = Fabric(accelerator=&#34;tpu&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Use state-of-the-art distributed training strategies (DDP, FSDP, DeepSpeed) and mixed precision out of the box&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Use state-of-the-art distributed training techniques&#xA;fabric = Fabric(strategy=&#34;ddp&#34;)&#xA;fabric = Fabric(strategy=&#34;deepspeed&#34;)&#xA;fabric = Fabric(strategy=&#34;fsdp&#34;)&#xA;&#xA;# Switch the precision&#xA;fabric = Fabric(precision=&#34;16-mixed&#34;)&#xA;fabric = Fabric(precision=&#34;64&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;All the device logic boilerplate is handled for you&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;  # no more of this!&#xA;- model.to(device)&#xA;- batch.to(device)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Build your own custom Trainer using Fabric primitives for training checkpointing, logging, and more&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import lightning as L&#xA;&#xA;&#xA;class MyCustomTrainer:&#xA;    def __init__(self, accelerator=&#34;auto&#34;, strategy=&#34;auto&#34;, devices=&#34;auto&#34;, precision=&#34;32-true&#34;):&#xA;        self.fabric = L.Fabric(accelerator=accelerator, strategy=strategy, devices=devices, precision=precision)&#xA;&#xA;    def fit(self, model, optimizer, dataloader, max_epochs):&#xA;        self.fabric.launch()&#xA;&#xA;        model, optimizer = self.fabric.setup(model, optimizer)&#xA;        dataloader = self.fabric.setup_dataloaders(dataloader)&#xA;        model.train()&#xA;&#xA;        for epoch in range(max_epochs):&#xA;            for batch in dataloader:&#xA;                input, target = batch&#xA;                optimizer.zero_grad()&#xA;                output = model(input)&#xA;                loss = loss_fn(output, target)&#xA;                self.fabric.backward(loss)&#xA;                optimizer.step()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;You can find a more extensive example in our &lt;a href=&#34;https://raw.githubusercontent.com/Lightning-AI/pytorch-lightning/master/examples/fabric/build_your_own_trainer&#34;&gt;examples&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;hr&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://lightning.ai/docs/fabric/stable/&#34;&gt;Read the Lightning Fabric docs&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Lightning Apps: Build AI products and ML workflows&lt;/h1&gt; &#xA;&lt;p&gt;Lightning Apps remove the cloud infrastructure boilerplate so you can focus on solving the research or business problems. Lightning Apps can run on the Lightning Cloud, your own cluster or a private cloud.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://pl-public-data.s3.amazonaws.com/assets_lightning/lightning-apps-teaser.png&#34; width=&#34;80%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Hello Lightning app world&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# app.py&#xA;import lightning as L&#xA;&#xA;&#xA;class TrainComponent(L.LightningWork):&#xA;    def run(self, x):&#xA;        print(f&#34;train a model on {x}&#34;)&#xA;&#xA;&#xA;class AnalyzeComponent(L.LightningWork):&#xA;    def run(self, x):&#xA;        print(f&#34;analyze model on {x}&#34;)&#xA;&#xA;&#xA;class WorkflowOrchestrator(L.LightningFlow):&#xA;    def __init__(self) -&amp;gt; None:&#xA;        super().__init__()&#xA;        self.train = TrainComponent(cloud_compute=L.CloudCompute(&#34;cpu&#34;))&#xA;        self.analyze = AnalyzeComponent(cloud_compute=L.CloudCompute(&#34;gpu&#34;))&#xA;&#xA;    def run(self):&#xA;        self.train.run(&#34;CPU machine 1&#34;)&#xA;        self.analyze.run(&#34;GPU machine 2&#34;)&#xA;&#xA;&#xA;app = L.LightningApp(WorkflowOrchestrator())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run on the cloud or locally&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# run on the cloud&#xA;lightning run app app.py --setup --cloud&#xA;&#xA;# run locally&#xA;lightning run app app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://lightning.ai/docs/app/stable/&#34;&gt;Read the Lightning Apps docs&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;h6&gt;Self-supervised Learning&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lightning-bolts.readthedocs.io/en/stable/transforms/self_supervised.html#cpc-transforms&#34;&gt;CPC transforms&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lightning-bolts.readthedocs.io/en/stable/transforms/self_supervised.html#moco-v2-transforms&#34;&gt;Moco v2 transforms&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lightning-bolts.readthedocs.io/en/stable/transforms/self_supervised.html#simclr-transforms&#34;&gt;SimCLR transforms&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h6&gt;Convolutional Architectures&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lightning-bolts.readthedocs.io/en/stable/models/convolutional.html#gpt-2&#34;&gt;GPT-2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lightning-bolts.readthedocs.io/en/stable/models/convolutional.html#unet&#34;&gt;UNet&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h6&gt;Reinforcement Learning&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lightning-bolts.readthedocs.io/en/stable/losses.html#dqn-loss&#34;&gt;DQN Loss&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lightning-bolts.readthedocs.io/en/stable/losses.html#double-dqn-loss&#34;&gt;Double DQN Loss&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lightning-bolts.readthedocs.io/en/stable/losses.html#per-dqn-loss&#34;&gt;Per DQN Loss&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h6&gt;GANs&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lightning-bolts.readthedocs.io/en/stable/models/gans.html#basic-gan&#34;&gt;Basic GAN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lightning-bolts.readthedocs.io/en/stable/models/gans.html#dcgan&#34;&gt;DCGAN&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h6&gt;Classic ML&lt;/h6&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lightning-bolts.readthedocs.io/en/stable/models/classic_ml.html#logistic-regression&#34;&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lightning-bolts.readthedocs.io/en/stable/models/classic_ml.html#linear-regression&#34;&gt;Linear Regression&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Continuous Integration&lt;/h2&gt; &#xA;&lt;p&gt;Lightning is rigorously tested across multiple CPUs, GPUs and TPUs and against major Python and PyTorch versions.&lt;/p&gt; &#xA;&lt;h6&gt;*Codecov is &amp;gt; 90%+ but build delays may show less&lt;/h6&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Current build statuses&lt;/summary&gt; &#xA; &lt;center&gt; &#xA;  &lt;table&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;System / PyTorch ver.&lt;/th&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;1.13&lt;/th&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;2.0&lt;/th&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;2.1&lt;/th&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/thead&gt; &#xA;   &lt;tbody&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Linux py3.9 [GPUs]&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://dev.azure.com/Lightning-AI/lightning/_build/latest?definitionId=24&amp;amp;branchName=master&#34;&gt;&lt;img src=&#34;https://dev.azure.com/Lightning-AI/lightning/_apis/build/status%2Fpytorch-lightning%20%28GPUs%29?branchName=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Linux py3.9 [TPUs]&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/tpu-tests.yml&#34;&gt;&lt;img src=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/tpu-tests.yml/badge.svg?sanitize=true&#34; alt=&#34;Test PyTorch - TPU&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Linux (multiple Python versions)&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml&#34;&gt;&lt;img src=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg?sanitize=true&#34; alt=&#34;Test PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml&#34;&gt;&lt;img src=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg?sanitize=true&#34; alt=&#34;Test PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml&#34;&gt;&lt;img src=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg?sanitize=true&#34; alt=&#34;Test PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;OSX (multiple Python versions)&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml&#34;&gt;&lt;img src=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg?sanitize=true&#34; alt=&#34;Test PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml&#34;&gt;&lt;img src=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg?sanitize=true&#34; alt=&#34;Test PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml&#34;&gt;&lt;img src=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg?sanitize=true&#34; alt=&#34;Test PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Windows (multiple Python versions)&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml&#34;&gt;&lt;img src=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg?sanitize=true&#34; alt=&#34;Test PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml&#34;&gt;&lt;img src=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg?sanitize=true&#34; alt=&#34;Test PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml&#34;&gt;&lt;img src=&#34;https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg?sanitize=true&#34; alt=&#34;Test PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &#xA; &lt;/center&gt; &#xA;&lt;/details&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;The lightning community is maintained by&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lightning.ai/docs/pytorch/latest/community/governance.html&#34;&gt;10+ core contributors&lt;/a&gt; who are all a mix of professional engineers, Research Scientists, and Ph.D. students from top AI labs.&lt;/li&gt; &#xA; &lt;li&gt;800+ community contributors.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Want to help us build Lightning and reduce boilerplate for thousands of researchers? &lt;a href=&#34;https://lightning.ai/docs/pytorch/stable/generated/CONTRIBUTING.html&#34;&gt;Learn how to make your first contribution here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Lightning is also part of the &lt;a href=&#34;https://pytorch.org/ecosystem/&#34;&gt;PyTorch ecosystem&lt;/a&gt; which requires projects to have solid testing, documentation and support.&lt;/p&gt; &#xA;&lt;h3&gt;Asking for help&lt;/h3&gt; &#xA;&lt;p&gt;If you have any questions please:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lightning.ai/docs&#34;&gt;Read the docs&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Lightning-AI/lightning/discussions&#34;&gt;Search through existing Discussions&lt;/a&gt;, or &lt;a href=&#34;https://github.com/Lightning-AI/lightning/discussions/new&#34;&gt;add a new question&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.com/invite/tfXFetEZxv&#34;&gt;Join our discord&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>ncbi/GeneGPT</title>
    <updated>2024-02-15T01:35:09Z</updated>
    <id>tag:github.com,2024-02-15:/ncbi/GeneGPT</id>
    <link href="https://github.com/ncbi/GeneGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Code and data for GeneGPT.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GeneGPT&lt;/h1&gt; &#xA;&lt;p&gt;This directory contains code and data for GeneGPT, a tool-augmented LLM for improved access to biomedical information. &lt;img src=&#34;https://github.com/ncbi/GeneGPT/assets/32558774/a18e142f-0742-4c14-a45f-386e9811c85d&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Introduction&lt;/h1&gt; &#xA;&lt;p&gt;While large language models (LLMs) have been successfully applied to various tasks, they still face challenges with hallucinations, especially for specialized knowledge. We propose GeneGPT, a novel approach to address this challenge by teaching LLMs to exploit biomedical tools, specifically NCBI Web APIs, for answering information-seeking questions. Our approach utilizes in-context learning, coupled with a novel decoding algorithm that can identify and execute API calls. Empirical results show that GeneGPT achieves state-of-the-art (SOTA) performance on eight GeneTuring tasks with an average score of 0.83, largely surpassing previous SOTA (0.44 by New Bing), biomedical LLMs such as BioGPT (0.04), and ChatGPT (0.12). Further analyses suggest that: Firstly, API demonstrations are more effective than documentations for in-context tool learning; Secondly, GeneGPT can generalize to longer chains of API calls and answer multi-hop questions; Lastly, the unique and task-specific errors made by GeneGPT provide valuable insights for future improvements. Our results underline the potential of integrating domain-specific tools with LLMs for improved access and accuracy in specialized knowledge areas.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;The code has been tested with Python 3.9.13. Please first install the required packages by:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You also need an OpenAI API key to run GeneGPT with Codex. Replace the placeholder with your key in &lt;code&gt;config.py&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cat config.py &#xA;API_KEY = &#39;YOUR_OPENAI_API_KEY&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Using GeneGPT&lt;/h2&gt; &#xA;&lt;p&gt;After setting up the environment, one can run GeneGPT on GeneTuring by:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py 111111&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;111111&lt;/code&gt; denotes that all Documentations (Dc.1-2) and Demonstrations (Dm.1-4) are used.&lt;/p&gt; &#xA;&lt;p&gt;To run GeneGPT-slim, simply use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py 001001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;which will only use the Dm.1 and Dm.4 for in-context learning.&lt;/p&gt; &#xA;&lt;h2&gt;Evaluating GeneGPT&lt;/h2&gt; &#xA;&lt;p&gt;One can evaluate the results by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python evaluate.py ${RESULT_DIRECTORY}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For example, we also put our experimental results in &lt;code&gt;geneturing_results&lt;/code&gt; and &lt;code&gt;geneturing_results&lt;/code&gt;. By running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python evaluate.py geneturing_results/001001/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The user can get the evaluation results of GeneGPT-slim:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Evaluating geneturing_results/001001/Gene alias.json&#xA;0.84&#xA;&#xA;Evaluating geneturing_results/001001/Gene disease association.json&#xA;0.6613333333333332&#xA;&#xA;Evaluating geneturing_results/001001/Gene location.json&#xA;0.66&#xA;&#xA;Evaluating geneturing_results/001001/Human genome DNA aligment.json&#xA;0.44&#xA;&#xA;Evaluating geneturing_results/001001/Multi-species DNA aligment.json&#xA;0.88&#xA;&#xA;Evaluating geneturing_results/001001/Gene name conversion.json&#xA;1.0&#xA;&#xA;Evaluating geneturing_results/001001/Protein-coding genes.json&#xA;1.0&#xA;&#xA;Evaluating geneturing_results/001001/Gene SNP association.json&#xA;1.0&#xA;&#xA;Evaluating geneturing_results/001001/SNP location.json&#xA;0.98&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;p&gt;This work was supported by the Intramural Research Programs of the National Institutes of Health, National Library of Medicine.&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This tool shows the results of research conducted in the Computational Biology Branch, NCBI/NLM. The information produced on this website is not intended for direct diagnostic use or medical decision-making without review and oversight by a clinical professional. Individuals should not change their health behavior solely on the basis of information produced on this website. NIH does not independently verify the validity or utility of the information produced by this tool. If you have questions about the information produced on this website, please see a health care professional. More information about NCBI&#39;s disclaimer policy is available.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find this repo helpful, please cite GeneGPT by:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{jin2023genegpt,&#xA;      title={GeneGPT: Augmenting Large Language Models with Domain Tools for Improved Access to Biomedical Information}, &#xA;      author={Qiao Jin and Yifan Yang and Qingyu Chen and Zhiyong Lu},&#xA;      year={2023},&#xA;      eprint={2304.09667},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CL}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>