<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-07T01:44:25Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>microsoft/BioGPT</title>
    <updated>2023-02-07T01:44:25Z</updated>
    <id>tag:github.com,2023-02-07:/microsoft/BioGPT</id>
    <link href="https://github.com/microsoft/BioGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;BioGPT&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the implementation of &lt;a href=&#34;https://academic.oup.com/bib/advance-article/doi/10.1093/bib/bbac409/6713511?guestAccessKey=a66d9b5d-4f83-4017-bb52-405815c907b9&#34;&gt;BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining&lt;/a&gt;, by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.&lt;/p&gt; &#xA;&lt;h1&gt;News!&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;BioGPT-Large model with 1.5B parameters is coming, currently available on PubMedQA task with SOTA performance of 81% accuracy. See &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/BioGPT/main/examples/QA-PubMedQA/&#34;&gt;Question Answering on PubMedQA&lt;/a&gt; for evaluation.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Requirements and Installation&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt; version == 1.12.0&lt;/li&gt; &#xA; &lt;li&gt;Python version == 3.10&lt;/li&gt; &#xA; &lt;li&gt;fairseq version == 0.12.0:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/pytorch/fairseq&#xA;cd fairseq&#xA;git checkout v0.12.0&#xA;pip install .&#xA;python setup.py build_ext --inplace&#xA;cd ..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Moses&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/moses-smt/mosesdecoder.git&#xA;export MOSES=${PWD}/mosesdecoder&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;fastBPE&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/glample/fastBPE.git&#xA;export FASTBPE=${PWD}/fastBPE&#xA;cd fastBPE&#xA;g++ -std=c++11 -pthread -O3 fastBPE/main.cc -IfastBPE -o fast&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;sacremoses&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install sacremoses&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;sklearn&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install scikit-learn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Remember to set the environment variables &lt;code&gt;MOSES&lt;/code&gt; and &lt;code&gt;FASTBPE&lt;/code&gt; to the path of Moses and fastBPE respetively, as they will be required later.&lt;/p&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;h2&gt;Pre-trained models&lt;/h2&gt; &#xA;&lt;p&gt;We provide our pre-trained BioGPT model checkpoint along with fine-tuned checkpoints for downstream tasks&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;URL&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BioGPT&lt;/td&gt; &#xA;   &lt;td&gt;Pre-trained BioGPT model checkpoint&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/Pre-trained-BioGPT.tgz&#34;&gt;link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BioGPT-Large&lt;/td&gt; &#xA;   &lt;td&gt;Pre-trained BioGPT-Large model checkpoint&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/Pre-trained-BioGPT-Large.tgz&#34;&gt;link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BioGPT-QA-PubMedQA-BioGPT&lt;/td&gt; &#xA;   &lt;td&gt;Fine-tuned BioGPT for question answering task on PubMedQA&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/QA-PubMedQA-BioGPT.tgz&#34;&gt;link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BioGPT-QA-PubMEDQA-BioGPT-Large&lt;/td&gt; &#xA;   &lt;td&gt;Fine-tuned BioGPT-Large for question answering task on PubMedQA&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/QA-PubMedQA-BioGPT-Large.tgz&#34;&gt;link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BioGPT-RE-BC5CDR&lt;/td&gt; &#xA;   &lt;td&gt;Fine-tuned BioGPT for relation extraction task on BC5CDR&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/RE-BC5CDR-BioGPT.tgz&#34;&gt;link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BioGPT-RE-DDI&lt;/td&gt; &#xA;   &lt;td&gt;Fine-tuned BioGPT for relation extraction task on DDI&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/RE-DDI-BioGPT.tgz&#34;&gt;link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BioGPT-RE-DTI&lt;/td&gt; &#xA;   &lt;td&gt;Fine-tuned BioGPT for relation extraction task on KD-DTI&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/RE-DTI-BioGPT.tgz&#34;&gt;link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BioGPT-DC-HoC&lt;/td&gt; &#xA;   &lt;td&gt;Fine-tuned BioGPT for document classification task on HoC&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/DC-HoC-BioGPT.tgz&#34;&gt;link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Download them and extract them to the &lt;code&gt;checkpoints&lt;/code&gt; folder of this project.&lt;/p&gt; &#xA;&lt;p&gt;For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir checkpoints&#xA;cd checkpoints&#xA;wget https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/Pre-trained-BioGPT.tgz&#xA;tar -zxvf Pre-trained-BioGPT.tgz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Example Usage&lt;/h2&gt; &#xA;&lt;p&gt;Use pre-trained BioGPT model in your code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from fairseq.models.transformer_lm import TransformerLanguageModel&#xA;m = TransformerLanguageModel.from_pretrained(&#xA;        &#34;checkpoints/Pre-trained-BioGPT&#34;, &#xA;        &#34;checkpoint.pt&#34;, &#xA;        &#34;data&#34;,&#xA;        tokenizer=&#39;moses&#39;, &#xA;        bpe=&#39;fastbpe&#39;, &#xA;        bpe_codes=&#34;data/bpecodes&#34;,&#xA;        min_len=100,&#xA;        max_len_b=1024)&#xA;m.cuda()&#xA;src_tokens = m.encode(&#34;COVID-19 is&#34;)&#xA;generate = m.generate([src_tokens], beam=5)[0]&#xA;output = m.decode(generate[0][&#34;tokens&#34;])&#xA;print(output)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Use fine-tuned BioGPT model on KD-DTI for drug-target-interaction in your code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from src.transformer_lm_prompt import TransformerLanguageModelPrompt&#xA;m = TransformerLanguageModelPrompt.from_pretrained(&#xA;        &#34;checkpoints/RE-DTI-BioGPT&#34;, &#xA;        &#34;checkpoint_avg.pt&#34;, &#xA;        &#34;data/KD-DTI/relis-bin&#34;,&#xA;        tokenizer=&#39;moses&#39;, &#xA;        bpe=&#39;fastbpe&#39;, &#xA;        bpe_codes=&#34;data/bpecodes&#34;,&#xA;        max_len_b=1024,&#xA;        beam=1)&#xA;m.cuda()&#xA;src_text=&#34;&#34; # input text, e.g., a PubMed abstract&#xA;src_tokens = m.encode(src_text)&#xA;generate = m.generate([src_tokens], beam=args.beam)[0]&#xA;output = m.decode(generate[0][&#34;tokens&#34;])&#xA;print(output)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more downstream tasks, please see below.&lt;/p&gt; &#xA;&lt;h2&gt;Downstream tasks&lt;/h2&gt; &#xA;&lt;p&gt;See corresponding folder in &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/BioGPT/main/examples&#34;&gt;examples&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/BioGPT/main/examples/RE-BC5CDR&#34;&gt;Relation Extraction on BC5CDR&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/BioGPT/main/examples/RE-DTI/&#34;&gt;Relation Extraction on KD-DTI&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/BioGPT/main/examples/RE-DDI&#34;&gt;Relation Extraction on DDI&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/BioGPT/main/examples/DC-HoC/&#34;&gt;Document Classification on HoC&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/BioGPT/main/examples/QA-PubMedQA/&#34;&gt;Question Answering on PubMedQA&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/BioGPT/main/examples/text-generation/&#34;&gt;Text Generation&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;BioGPT is MIT-licensed. The license applies to the pre-trained models as well.&lt;/p&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&#34;https://cla.opensource.microsoft.com&#34;&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h1&gt;Trademarks&lt;/h1&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>mmz-001/knowledge_gpt</title>
    <updated>2023-02-07T01:44:25Z</updated>
    <id>tag:github.com,2023-02-07:/mmz-001/knowledge_gpt</id>
    <link href="https://github.com/mmz-001/knowledge_gpt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Accurate answers and instant citations for your documents.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; 📖KnowledgeGPT &lt;/h1&gt; &#xA;&lt;p&gt;Accurate answers and instant citations for your documents.&lt;/p&gt; &#xA;&lt;h2&gt;🔧 Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Upload documents 📁(PDF, DOCX, TXT) and answer questions about them.&lt;/li&gt; &#xA; &lt;li&gt;Cite sources📚 for the answers, with excerpts from the text.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;💻 Running Locally&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repository📂&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/mmz-001/knowledge_gpt&#xA;cd knowledge_gpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Install dependencies with &lt;a href=&#34;https://python-poetry.org/&#34;&gt;Poetry&lt;/a&gt; and activate virtual environment🔨&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;poetry install&#xA;poetry shell&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Run the Streamlit server🚀&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd knowledge_gpt&#xA;streamlit run main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;🚀 Upcoming Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Add support for more formats (e.g. webpages 🕸️, PPTX 📊, etc.)&lt;/li&gt; &#xA; &lt;li&gt;Highlight relevant phrases in citations 🔦&lt;/li&gt; &#xA; &lt;li&gt;Support scanned documents with OCR 📝&lt;/li&gt; &#xA; &lt;li&gt;More customization options (e.g. chain type 🔗, chunk size📏, etc.)&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>amazon-science/mm-cot</title>
    <updated>2023-02-07T01:44:25Z</updated>
    <id>tag:github.com,2023-02-07:/amazon-science/mm-cot</id>
    <link href="https://github.com/amazon-science/mm-cot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official implementation for &#34;Multimodal Chain-of-Thought Reasoning in Language Models&#34; (stay tuned and more will be updated)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Multimodal Chain-of-Thought Reasoning in Language Models&lt;/h1&gt; &#xA;&lt;h5 align=&#34;center&#34;&gt;&lt;i&gt;&#34;Imagine learning a textbook without figures or tables.&#34;&lt;/i&gt;&lt;/h5&gt; &#xA;&lt;p&gt;Multimodal-CoT incorporates vision features in a decoupled training framework. The framework consists of two training stages: (i) rationale generation and (ii) answer inference. Both stages share the same model architecture but differ in the input and output.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/amazon-science/mm-cot/main/vision_features/mm-cot.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;Install all required python dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Datasets&lt;/h2&gt; &#xA;&lt;p&gt;Download the dataset from the following repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;https://github.com/lupantech/ScienceQA/tree/main/data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Download the extracted vision features from &lt;a href=&#34;https://drive.google.com/file/d/13B0hc_F_45-UlqPLKSgRz-ALtFQ8kIJr/view?usp=share_link&#34;&gt;vision_features&lt;/a&gt; and unzip the files under &lt;code&gt;vision_features&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Instructions&lt;/h2&gt; &#xA;&lt;h3&gt;Training&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# rationale generation&#xA;CUDA_VISIBLE_DEVICES=0,1 python main.py \&#xA;    --model allenai/unifiedqa-t5-base \&#xA;    --user_msg rationale --img_type detr \&#xA;    --bs 8 --eval_bs 4 --eval_acc 10 --output_len 512 \&#xA;    --final_eval --prompt_format QCM-LE&#xA;&#xA;# answer inference&#xA;CUDA_VISIBLE_DEVICES=0,1 python main.py \&#xA;    --model allenai/unifiedqa-t5-base \&#xA;    --user_msg answer --img_type detr \&#xA;    --bs 8 --eval_bs 4 --eval_acc 10 --output_len 64 \&#xA;    --final_eval --prompt_format QCMG-A \&#xA;    --eval_le experiments/rationale_allenai-unifiedqa-t5-base_detr_QCM-LE_lr5e-05_bs16_op512_ep20/predictions_ans_eval.json \&#xA;    --test_le experiments/rationale_allenai-unifiedqa-t5-base_detr_QCM-LE_lr5e-05_bs16_op512_ep20/predictions_ans_test.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Inference&lt;/h3&gt; &#xA;&lt;p&gt;Our trained models are available at &lt;a href=&#34;https://drive.google.com/file/d/1FtTYOJPHnWnFfCxNC6M3gar4RAX5E21b/view?usp=share_link&#34;&gt;models&lt;/a&gt;. To use our trained models, please put the them under the &lt;code&gt;models&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# rationale generation&#xA;CUDA_VISIBLE_DEVICES=0,1 python main.py \&#xA;    --model allenai/unifiedqa-t5-base \&#xA;    --user_msg rationale --img_type detr \&#xA;    --bs 8 --eval_bs 4 --eval_acc 10 --output_len 512 \&#xA;    --final_eval --prompt_format QCM-LE \&#xA;    --evaluate_dir models/MM-CoT-UnifiedQA-base-Rationale&#xA;&#xA;# answer inference&#xA;CUDA_VISIBLE_DEVICES=0,1 python main.py \&#xA;    --model allenai/unifiedqa-t5-base \&#xA;    --user_msg answer --img_type detr \&#xA;    --bs 8 --eval_bs 4 --eval_acc 10 --output_len 64 \&#xA;    --final_eval --prompt_format QCMG-A \&#xA;    --eval_le models/rationale/predictions_ans_eval.json \&#xA;    --test_le models/rationale/predictions_ans_test.json \&#xA;    --evaluate_dir models/MM-CoT-UnifiedQA-base-Answer&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citing MM-CoT&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{zhang2023multicot,&#xA;  title={Multimodal Chain-of-Thought Reasoning in Language Models},&#xA;  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Zhao, Hai and Karypis, George and Smola, Alex},&#xA;  journal={arXiv preprint arXiv:2302.00923},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the Apache-2.0 License.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;Part of our codes are adapted from &lt;a href=&#34;https://github.com/lupantech/ScienceQA&#34;&gt;ScienceQA&lt;/a&gt; and &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;Transformers&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We thank Pan Lu for providing parameter size for ScienceQA baselines.&lt;/p&gt;</summary>
  </entry>
</feed>