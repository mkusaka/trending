<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-07-13T01:36:05Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Sitoi/dailycheckin</title>
    <updated>2024-07-13T01:36:05Z</updated>
    <id>tag:github.com,2024-07-13:/Sitoi/dailycheckin</id>
    <link href="https://github.com/Sitoi/dailycheckin" rel="alternate"></link>
    <summary type="html">&lt;p&gt;基于「Docker」/「青龙面板」/「群晖」的每日签到脚本（支持多账号）签到列表: ｜爱奇艺｜全民K歌｜有道云笔记｜百度贴吧｜Bilibili｜V2EX｜AcFun｜什么值得买｜阿里云盘｜i茅台申购｜小米运动｜百度搜索资源平台｜恩山论坛｜奥拉星｜&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://socialify.git.ci/Sitoi/dailycheckin/image?font=Rokkitt&amp;amp;forks=1&amp;amp;issues=1&amp;amp;language=1&amp;amp;name=1&amp;amp;owner=1&amp;amp;pattern=Circuit%20Board&amp;amp;pulls=1&amp;amp;stargazers=1&amp;amp;theme=Dark&#34;&gt; &#xA; &lt;h1&gt;DailyCheckIn&lt;/h1&gt; &#xA; &lt;p&gt;基于「Docker」/「青龙面板」/「群晖」/「本地」的每日签到脚本&lt;/p&gt; &#xA; &lt;!-- SHIELD GROUP --&gt; &#xA; &lt;div id=&#34;shield&#34;&gt; &#xA;  &lt;p&gt;&lt;a href=&#34;https://github.com/sitoi/dailycheckin/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/sitoi/dailycheckin?labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/dailycheckin/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/dailycheckin?labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/sitoi/dailycheckin/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/release-date/sitoi/dailycheckin?labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/sitoi/dailycheckin/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/sitoi/dailycheckin?color=ffcb47&amp;amp;labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/sitoi/dailycheckin/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/sitoi/dailycheckin?color=8ae8ff&amp;amp;labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/sitoi/dailycheckin/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/sitoi/dailycheckin?color=ff80eb&amp;amp;labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/sitoi/dailycheckin/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/sitoi/dailycheckin?color=c4f042&amp;amp;labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;p&gt;&lt;a href=&#34;https://pypi.org/project/dailycheckin/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/dailycheckin?labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/dailycheckin/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/dailycheckin?label=pypi&amp;amp;labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/repository/docker/sitoi/dailycheckin&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/sitoi/dailycheckin?labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/repository/docker/sitoi/dailycheckin&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/image-size/sitoi/dailycheckin?labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/repository/docker/sitoi/dailycheckin&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/stars/sitoi/dailycheckin?labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/sitoi/dailycheckin/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/sitoi/dailycheckin?labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;!-- SHIELD GROUP --&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;✨ 特性&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;📦 支持 Pypi 包安装&lt;/li&gt; &#xA; &lt;li&gt;💻 支持多个平台部署&lt;/li&gt; &#xA; &lt;li&gt;⚙️ 支持多个平台签到&lt;/li&gt; &#xA; &lt;li&gt;📢 支持多个平台通知&lt;/li&gt; &#xA; &lt;li&gt;♾️ 支持多个账号签到&lt;/li&gt; &#xA; &lt;li&gt;🕙 支持定时任务设置&lt;/li&gt; &#xA; &lt;li&gt;🆙 支持项目自动更新&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🦄 教程&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://sitoi.github.io/dailycheckin/&#34;&gt;https://sitoi.github.io/dailycheckin/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🧾 列表&lt;/h2&gt; &#xA;&lt;p&gt;🟢: 正常运行 🔴: 脚本暂不可用 🔵: 可以执行(需更新) 🟡: 待测试 🟤: 看脸&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;状态&lt;/th&gt; &#xA;   &lt;th&gt;任务名称&lt;/th&gt; &#xA;   &lt;th&gt;名称网站&lt;/th&gt; &#xA;   &lt;th&gt;检查日期&lt;/th&gt; &#xA;   &lt;th&gt;备注&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;🟢️&lt;/td&gt; &#xA;   &lt;td&gt;KGQQ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://kg.qq.com/index-pc.html&#34;&gt;全民 K 歌&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;24.02.20&lt;/td&gt; &#xA;   &lt;td&gt;每日签到获取鲜花 每日大约 120 鲜花左右&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;🟢️&lt;/td&gt; &#xA;   &lt;td&gt;YOUDAO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://note.youdao.com/web/&#34;&gt;有道云笔记&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;24.02.20&lt;/td&gt; &#xA;   &lt;td&gt;每日签到获取存储空间&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;🟢️&lt;/td&gt; &#xA;   &lt;td&gt;TIEBA&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://tieba.baidu.com/index.html&#34;&gt;百度贴吧&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;24.02.20&lt;/td&gt; &#xA;   &lt;td&gt;贴吧每日签到&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;🟢️&lt;/td&gt; &#xA;   &lt;td&gt;BILIBILI&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/&#34;&gt;BiliBili&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;24.02.20&lt;/td&gt; &#xA;   &lt;td&gt;直播签到，漫画签到，每日经验任务，自动投币，银瓜子换硬币等功能&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;🟢️&lt;/td&gt; &#xA;   &lt;td&gt;V2EX&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.v2ex.com/&#34;&gt;V2EX&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;24.02.20&lt;/td&gt; &#xA;   &lt;td&gt;铜币奖励&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;🟢️&lt;/td&gt; &#xA;   &lt;td&gt;ACFUN&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.acfun.cn/&#34;&gt;AcFun&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;24.02.20&lt;/td&gt; &#xA;   &lt;td&gt;每日签到香蕉&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;🟢️&lt;/td&gt; &#xA;   &lt;td&gt;IQIYI&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.iqiyi.com/&#34;&gt;爱奇艺&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;24.02.20&lt;/td&gt; &#xA;   &lt;td&gt;① 满签得 7 天会员；② 日常任务 4 成长值；③ 爱奇艺刷时长任务，10 成长值；④ 每日签到随机成长值；⑤ 抽白金会员 5 次；⑥ 摇一摇抽奖 3 次；⑦ 抽奖 3 次&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;🟢️&lt;/td&gt; &#xA;   &lt;td&gt;SMZDM&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.smzdm.com/&#34;&gt;什么值得买&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;24.02.20&lt;/td&gt; &#xA;   &lt;td&gt;签到和抽奖&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;🟢️&lt;/td&gt; &#xA;   &lt;td&gt;ALIYUN&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.aliyundrive.com/drive/&#34;&gt;阿里云盘&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;24.02.20&lt;/td&gt; &#xA;   &lt;td&gt;签到获取免费会员和空间&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;🟢️&lt;/td&gt; &#xA;   &lt;td&gt;ENSHAN&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.right.com.cn/forum/&#34;&gt;恩山无线论坛&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;24.02.20&lt;/td&gt; &#xA;   &lt;td&gt;签到获取硬币和积分&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;🟢️&lt;/td&gt; &#xA;   &lt;td&gt;AOLAXING&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.100bt.com/m/creditMall/?gameId=2#task&#34;&gt;奥拉星&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;24.02.20&lt;/td&gt; &#xA;   &lt;td&gt;签到获取积分&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;🟢️&lt;/td&gt; &#xA;   &lt;td&gt;IMAOTAI&lt;/td&gt; &#xA;   &lt;td&gt;i 茅台&lt;/td&gt; &#xA;   &lt;td&gt;24.02.20&lt;/td&gt; &#xA;   &lt;td&gt;申购生肖茅台&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;🟤&lt;/td&gt; &#xA;   &lt;td&gt;MIMOTION&lt;/td&gt; &#xA;   &lt;td&gt;小米运动&lt;/td&gt; &#xA;   &lt;td&gt;24.02.20&lt;/td&gt; &#xA;   &lt;td&gt;每日小米运动刷步数&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;🟢️&lt;/td&gt; &#xA;   &lt;td&gt;BAIDU&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ziyuan.baidu.com/site/index#/&#34;&gt;百度站点&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;24.02.20&lt;/td&gt; &#xA;   &lt;td&gt;提交网站页面供百度收录&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;💬 通知列表&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;dingtalk（钉钉）&lt;/li&gt; &#xA; &lt;li&gt;企业微信群机器人（企业微信）&lt;/li&gt; &#xA; &lt;li&gt;企业微信应用消息（企业微信）&lt;/li&gt; &#xA; &lt;li&gt;telegram（TG）&lt;/li&gt; &#xA; &lt;li&gt;Bark（iOS）&lt;/li&gt; &#xA; &lt;li&gt;server 酱（微信）&lt;/li&gt; &#xA; &lt;li&gt;server 酱 TURBO（微信）&lt;/li&gt; &#xA; &lt;li&gt;pushplus（微信）&lt;/li&gt; &#xA; &lt;li&gt;Cool Push（QQ,微信,邮箱）&lt;/li&gt; &#xA; &lt;li&gt;qmsg 酱（QQ）&lt;/li&gt; &#xA; &lt;li&gt;飞书（飞书）&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🤝 参与贡献&lt;/h2&gt; &#xA;&lt;p&gt;我们非常欢迎各种形式的贡献。如果你对贡献代码感兴趣，可以查看我们的 GitHub &lt;a href=&#34;https://github.com/sitoi/dailycheckin/issues&#34;&gt;Issues&lt;/a&gt;，大展身手，向我们展示你的奇思妙想。&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/sitoi/dailycheckin/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%AF_pr_welcome-%E2%86%92-ffcb47?labelColor=black&amp;amp;style=for-the-badge&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;💗 感谢我们的贡献者&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/sitoi/dailycheckin/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=sitoi%2Fdailycheckin&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;✨ Star 数&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#sitoi/dailycheckin&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=sitoi/dailycheckin&amp;amp;type=Date&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;📝 License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright © 2021 &lt;a href=&#34;https://github.com/sitoi&#34;&gt;Sitoi&lt;/a&gt;. &lt;br&gt; This project is &lt;a href=&#34;https://github.com/Sitoi/dailycheckin/raw/main/LICENSE&#34;&gt;MIT&lt;/a&gt; licensed.&lt;/p&gt; &#xA;&lt;!-- LINK GROUP --&gt;</summary>
  </entry>
  <entry>
    <title>InternLM/Tutorial</title>
    <updated>2024-07-13T01:36:05Z</updated>
    <id>tag:github.com,2024-07-13:/InternLM/Tutorial</id>
    <link href="https://github.com/InternLM/Tutorial" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LLM Tutorial&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;书生·浦语大模型实战营&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/InternLM/Tutorial/camp1/asset/camp.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;为了推动大模型在更多行业落地开花，让开发者们更高效的学习大模型的开发与应用，上海人工智能实验室重磅推出书生·浦语大模型实战营，为广大开发者搭建大模型学习和实践开发的平台，两周时间带你玩转大模型微调、部署与评测全链路。&lt;/p&gt; &#xA;&lt;p&gt;实战营春季第4补增场火热报名中，欢迎填写&lt;a href=&#34;https://www.wjx.top/vm/Yzzz2mi.aspx?udsid=876275&#34;&gt;表单&lt;/a&gt;报名！&lt;br&gt; 报名成功后加入群聊，私聊助教或者浦语小助手获取免费 A100 算力支持！！！&lt;/p&gt; &#xA;&lt;h2&gt;😊 你将获得&lt;/h2&gt; &#xA;&lt;p&gt;👨‍🏫 实力讲师：来自前沿科研机构、一线大厂和 Github 热门开源项目的讲师手把手教学&lt;br&gt; 💻 算力支持：算力资源免费提供，助力无忧训练大模型&lt;br&gt; 💬 专属社群：助教、讲师全程陪伴，提供录播回放、线上答疑及实战作业辅导&lt;br&gt; 📜 官方认证：优秀学员将获得荣誉证书，优秀项目有机会被官方收录，获得更多展示&lt;/p&gt; &#xA;&lt;h2&gt;📅 课程安排&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;课程时间&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;课程内容&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;讲师&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;资料&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;第 1 节&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;书生·浦语大模型全链路开源体系&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;陈恺 &lt;br&gt;上海人工智能实验室青年科学家&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Rc411b7ns/&#34;&gt;视频&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;第 2 节&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;轻松玩转书生·浦语大模型趣味 Demo&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;宋志学&lt;br&gt;d2l-ai-solutions-manual 开源项目负责人&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/InternLM/Tutorial/camp1/helloworld/hello_world.md&#34;&gt;文档&lt;/a&gt;、&lt;a href=&#34;https://www.bilibili.com/video/BV1Ci4y1z72H&#34;&gt;视频&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;第 3 节&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;基于 InternLM 和 LangChain 搭建你的知识库&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;邹雨衡&lt;br&gt;prompt-engineering-for-developers 开源项目负责人&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/InternLM/Tutorial/camp1/langchain/readme.md&#34;&gt;文档&lt;/a&gt;、&lt;a href=&#34;https://www.bilibili.com/video/BV1sT4y1p71V/&#34;&gt;视频&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;第 4 节&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;XTuner 大模型单卡低成本微调实战&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;汪周谦&lt;br&gt;XTuner 社区贡献者&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/InternLM/Tutorial/camp1/xtuner/README.md&#34;&gt;文档&lt;/a&gt;、&lt;a href=&#34;https://www.bilibili.com/video/BV1yK4y1B75J&#34;&gt;视频&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;第 5 节&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;LMDeploy 大模型量化部署实践&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;长琴&lt;br&gt;HuggingLLM开源项目负责人&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/InternLM/Tutorial/camp1/lmdeploy/lmdeploy.md&#34;&gt;文档&lt;/a&gt;、&lt;a href=&#34;https://www.bilibili.com/video/BV1iW4y1A77P&#34;&gt;视频&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;第 6 节&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;OpenCompass 大模型评测&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;曹茂松&lt;br&gt;OpenCompass 核心开发者&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/InternLM/Tutorial/camp1/opencompass/opencompass_tutorial.md&#34;&gt;文档&lt;/a&gt;、&lt;a href=&#34;https://www.bilibili.com/video/BV1Gg4y1U7uc/&#34;&gt;视频&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;第 7 节&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;彩蛋环节&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;神秘嘉宾&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;文档、视频&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;📝 作业&lt;/h2&gt; &#xA;&lt;p&gt;助教老师将在社群中公布每节课的作业及提交方式&lt;/p&gt; &#xA;&lt;h2&gt;🖥️ 算力平台&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://studio.intern-ai.org.cn/&#34;&gt;https://studio.intern-ai.org.cn/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;问卷中的核销码为邀请码，如额外需要充值算力或者其他任何疑问请联系浦语小助手(微信号搜索：InternLM)&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>apify/crawlee-python</title>
    <updated>2024-07-13T01:36:05Z</updated>
    <id>tag:github.com,2024-07-13:/apify/crawlee-python</id>
    <link href="https://github.com/apify/crawlee-python" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Crawlee—A web scraping and browser automation library for Python to build reliable crawlers. Extract data for AI, LLMs, RAG, or GPTs. Download HTML, PDF, JPG, PNG, and other files from websites. Works with BeautifulSoup, Playwright, and raw HTTP. Both headful and headless mode. With proxy rotation.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;a href=&#34;https://crawlee.dev&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://raw.githubusercontent.com/apify/crawlee-python/master/website/static/img/crawlee-dark.svg?sanitize=true&#34;&gt; &#xA;   &lt;img alt=&#34;Crawlee&#34; src=&#34;https://raw.githubusercontent.com/apify/crawlee-python/master/website/static/img/crawlee-light.svg?sanitize=true&#34; width=&#34;500&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &lt;br&gt; &lt;small&gt;A web scraping and browser automation library&lt;/small&gt; &lt;/h1&gt; &#xA;&lt;p&gt;Crawlee covers your crawling and scraping end-to-end and &lt;strong&gt;helps you build reliable scrapers. Fast.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;🚀 Crawlee for Python is open to early adopters!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Your crawlers will appear almost human-like and fly under the radar of modern bot protections even with the default configuration. Crawlee gives you the tools to crawl the web for links, scrape data and persistently store it in machine-readable formats, without having to worry about the technical details. And thanks to rich configuration options, you can tweak almost any aspect of Crawlee to suit your project&#39;s needs if the default settings don&#39;t cut it.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;👉 &lt;strong&gt;View full documentation, guides and examples on the &lt;a href=&#34;https://crawlee.dev/python/&#34;&gt;Crawlee project website&lt;/a&gt;&lt;/strong&gt; 👈&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;We also have a TypeScript implementation of the Crawlee, which you can explore and utilize for your projects. Visit our GitHub repository for more information &lt;a href=&#34;https://github.com/apify/crawlee&#34;&gt;Crawlee for JS/TS on GitHub&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;We recommend visiting the &lt;a href=&#34;https://crawlee.dev/python/docs/introduction&#34;&gt;Introduction tutorial&lt;/a&gt; in Crawlee documentation for more information.&lt;/p&gt; &#xA;&lt;p&gt;Crawlee is available as the &lt;a href=&#34;https://pypi.org/project/crawlee/&#34;&gt;&lt;code&gt;crawlee&lt;/code&gt;&lt;/a&gt; PyPI package.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install crawlee&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Additional, optional dependencies unlocking more features are shipped as package extras.&lt;/p&gt; &#xA;&lt;p&gt;If you plan to use &lt;code&gt;BeautifulSoupCrawler&lt;/code&gt;, install &lt;code&gt;crawlee&lt;/code&gt; with &lt;code&gt;beautifulsoup&lt;/code&gt; extra:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install &#39;crawlee[beautifulsoup]&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you plan to use &lt;code&gt;PlaywrightCrawler&lt;/code&gt;, install &lt;code&gt;crawlee&lt;/code&gt; with the &lt;code&gt;playwright&lt;/code&gt; extra:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install &#39;crawlee[playwright]&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, install the Playwright dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;playwright install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can install multiple extras at once by using a comma as a separator:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install &#39;crawlee[beautifulsoup,playwright]&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;With Crawlee CLI&lt;/h3&gt; &#xA;&lt;p&gt;The quickest way to get started with Crawlee is by using the Crawlee CLI and selecting one of the prepared templates. First, ensure you have &lt;a href=&#34;https://pipx.pypa.io/&#34;&gt;Pipx&lt;/a&gt; installed:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pipx --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, run the CLI and choose from the available templates:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pipx run crawlee create my-crawler&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you already have &lt;code&gt;crawlee&lt;/code&gt; installed, you can spin it up by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;crawlee create my-crawler&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;Here are some practical examples to help you get started with different types of crawlers in Crawlee. Each example demonstrates how to set up and run a crawler for specific use cases, whether you need to handle simple HTML pages or interact with JavaScript-heavy sites.&lt;/p&gt; &#xA;&lt;h3&gt;BeautifulSoupCrawler&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;BeautifulSoupCrawler&lt;/code&gt; downloads web pages using an HTTP library and provides HTML-parsed content to the user. It uses &lt;a href=&#34;https://pypi.org/project/httpx/&#34;&gt;HTTPX&lt;/a&gt; for HTTP communication and &lt;a href=&#34;https://pypi.org/project/beautifulsoup4/&#34;&gt;BeautifulSoup&lt;/a&gt; for parsing HTML. It is ideal for projects that require efficient extraction of data from HTML content. This crawler has very good performance since it does not use a browser. However, if you need to execute client-side JavaScript, to get your content, this is not going to be enough and you will need to use PlaywrightCrawler. Also if you want to use this crawler, make sure you install &lt;code&gt;crawlee&lt;/code&gt; with &lt;code&gt;beautifulsoup&lt;/code&gt; extra.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio&#xA;&#xA;from crawlee.beautifulsoup_crawler import BeautifulSoupCrawler, BeautifulSoupCrawlingContext&#xA;&#xA;&#xA;async def main() -&amp;gt; None:&#xA;    crawler = BeautifulSoupCrawler(&#xA;        # Limit the crawl to max requests. Remove or increase it for crawling all links.&#xA;        max_requests_per_crawl=10,&#xA;    )&#xA;&#xA;    # Define the default request handler, which will be called for every request.&#xA;    @crawler.router.default_handler&#xA;    async def request_handler(context: BeautifulSoupCrawlingContext) -&amp;gt; None:&#xA;        context.log.info(f&#39;Processing {context.request.url} ...&#39;)&#xA;&#xA;        # Extract data from the page.&#xA;        data = {&#xA;            &#39;url&#39;: context.request.url,&#xA;            &#39;title&#39;: context.soup.title.string if context.soup.title else None,&#xA;        }&#xA;&#xA;        # Push the extracted data to the default dataset.&#xA;        await context.push_data(data)&#xA;&#xA;        # Enqueue all links found on the page.&#xA;        await context.enqueue_links()&#xA;&#xA;    # Run the crawler with the initial list of URLs.&#xA;    await crawler.run([&#39;https://crawlee.dev&#39;])&#xA;&#xA;if __name__ == &#39;__main__&#39;:&#xA;    asyncio.run(main())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;PlaywrightCrawler&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;PlaywrightCrawler&lt;/code&gt; uses a headless browser to download web pages and provides an API for data extraction. It is built on &lt;a href=&#34;https://playwright.dev/&#34;&gt;Playwright&lt;/a&gt;, an automation library designed for managing headless browsers. It excels at retrieving web pages that rely on client-side JavaScript for content generation, or tasks requiring interaction with JavaScript-driven content. For scenarios where JavaScript execution is unnecessary or higher performance is required, consider using the &lt;code&gt;BeautifulSoupCrawler&lt;/code&gt;. Also if you want to use this crawler, make sure you install &lt;code&gt;crawlee&lt;/code&gt; with &lt;code&gt;playwright&lt;/code&gt; extra.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio&#xA;&#xA;from crawlee.playwright_crawler import PlaywrightCrawler, PlaywrightCrawlingContext&#xA;&#xA;&#xA;async def main() -&amp;gt; None:&#xA;    crawler = PlaywrightCrawler(&#xA;        # Limit the crawl to max requests. Remove or increase it for crawling all links.&#xA;        max_requests_per_crawl=10,&#xA;    )&#xA;&#xA;    # Define the default request handler, which will be called for every request.&#xA;    @crawler.router.default_handler&#xA;    async def request_handler(context: PlaywrightCrawlingContext) -&amp;gt; None:&#xA;        context.log.info(f&#39;Processing {context.request.url} ...&#39;)&#xA;&#xA;        # Extract data from the page.&#xA;        data = {&#xA;            &#39;url&#39;: context.request.url,&#xA;            &#39;title&#39;: await context.page.title(),&#xA;        }&#xA;&#xA;        # Push the extracted data to the default dataset.&#xA;        await context.push_data(data)&#xA;&#xA;        # Enqueue all links found on the page.&#xA;        await context.enqueue_links()&#xA;&#xA;    # Run the crawler with the initial list of requests.&#xA;    await crawler.run([&#39;https://crawlee.dev&#39;])&#xA;&#xA;&#xA;if __name__ == &#39;__main__&#39;:&#xA;    asyncio.run(main())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;More examples&lt;/h3&gt; &#xA;&lt;p&gt;Explore our &lt;a href=&#34;https://crawlee.dev/python/docs/examples&#34;&gt;Examples&lt;/a&gt; page in the Crawlee documentation for a wide range of additional use cases and demonstrations.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;Why Crawlee is the preferred choice for web scraping and crawling?&lt;/p&gt; &#xA;&lt;h3&gt;Why use Crawlee instead of just a random HTTP library with an HTML parser?&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Unified interface for &lt;strong&gt;HTTP &amp;amp; headless browser&lt;/strong&gt; crawling.&lt;/li&gt; &#xA; &lt;li&gt;Automatic &lt;strong&gt;parallel crawling&lt;/strong&gt; based on available system resources.&lt;/li&gt; &#xA; &lt;li&gt;Written in Python with &lt;strong&gt;type hints&lt;/strong&gt; - enhances DX (IDE autocompletion) and reduces bugs (static type checking).&lt;/li&gt; &#xA; &lt;li&gt;Automatic &lt;strong&gt;retries&lt;/strong&gt; on errors or when you’re getting blocked.&lt;/li&gt; &#xA; &lt;li&gt;Integrated &lt;strong&gt;proxy rotation&lt;/strong&gt; and session management.&lt;/li&gt; &#xA; &lt;li&gt;Configurable &lt;strong&gt;request routing&lt;/strong&gt; - direct URLs to the appropriate handlers.&lt;/li&gt; &#xA; &lt;li&gt;Persistent &lt;strong&gt;queue for URLs&lt;/strong&gt; to crawl.&lt;/li&gt; &#xA; &lt;li&gt;Pluggable &lt;strong&gt;storage&lt;/strong&gt; of both tabular data and files.&lt;/li&gt; &#xA; &lt;li&gt;Robust &lt;strong&gt;error handling&lt;/strong&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Why to use Crawlee rather than Scrapy?&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Crawlee has out-of-the-box support for &lt;strong&gt;headless browser&lt;/strong&gt; crawling (Playwright).&lt;/li&gt; &#xA; &lt;li&gt;Crawlee has a &lt;strong&gt;minimalistic &amp;amp; elegant interface&lt;/strong&gt; - Set up your scraper with fewer than 10 lines of code.&lt;/li&gt; &#xA; &lt;li&gt;Complete &lt;strong&gt;type hint&lt;/strong&gt; coverage.&lt;/li&gt; &#xA; &lt;li&gt;Based on standard &lt;strong&gt;Asyncio&lt;/strong&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Running on the Apify platform&lt;/h2&gt; &#xA;&lt;p&gt;Crawlee is open-source and runs anywhere, but since it&#39;s developed by &lt;a href=&#34;https://apify.com&#34;&gt;Apify&lt;/a&gt;, it&#39;s easy to set up on the Apify platform and run in the cloud. Visit the &lt;a href=&#34;https://docs.apify.com/sdk/python/&#34;&gt;Apify SDK website&lt;/a&gt; to learn more about deploying Crawlee to the Apify platform.&lt;/p&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;If you find any bug or issue with Crawlee, please &lt;a href=&#34;https://github.com/apify/crawlee-python/issues&#34;&gt;submit an issue on GitHub&lt;/a&gt;. For questions, you can ask on &lt;a href=&#34;https://stackoverflow.com/questions/tagged/apify&#34;&gt;Stack Overflow&lt;/a&gt;, in GitHub Discussions or you can join our &lt;a href=&#34;https://discord.com/invite/jyEM2PRvMU&#34;&gt;Discord server&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Your code contributions are welcome, and you&#39;ll be praised for eternity! If you have any ideas for improvements, either submit an issue or create a pull request. For contribution guidelines and the code of conduct, see &lt;a href=&#34;https://github.com/apify/crawlee-python/raw/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href=&#34;https://github.com/apify/crawlee-python/raw/master/LICENSE.md&#34;&gt;LICENSE.md&lt;/a&gt; file for details.&lt;/p&gt;</summary>
  </entry>
</feed>