<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-09-09T01:34:29Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>baichuan-inc/Baichuan2</title>
    <updated>2023-09-09T01:34:29Z</updated>
    <id>tag:github.com,2023-09-09:/baichuan-inc/Baichuan2</id>
    <link href="https://github.com/baichuan-inc/Baichuan2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A series of large language models developed by Baichuan Intelligent Technology&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt; Baichuan 2 &lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; ğŸ¤— &lt;a href=&#34;https://huggingface.co/baichuan-inc/&#34; target=&#34;_blank&#34;&gt;Hugging Face&lt;/a&gt; â€¢ ğŸ¤– &lt;a href=&#34;https://modelscope.cn/organization/baichuan-inc&#34; target=&#34;_blank&#34;&gt;ModelScope&lt;/a&gt; â€¢ ğŸ’¬ &lt;a href=&#34;https://github.com/baichuan-inc/Baichuan-7B/raw/main/media/wechat.jpeg?raw=true&#34; target=&#34;_blank&#34;&gt;WeChat&lt;/a&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;ğŸš€ &lt;a href=&#34;https://www.baichuan-ai.com/&#34;&gt;ç™¾å·53Bå¤§æ¨¡å‹åœ¨çº¿å¯¹è¯å¹³å°&lt;/a&gt;å·²æ­£å¼å‘å…¬ä¼—å¼€æ”¾ ğŸ‰&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/baichuan-inc/Baichuan2/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/modelscope/modelscope.svg?sanitize=true&#34; alt=&#34;license&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h4 align=&#34;center&#34;&gt; &lt;p&gt; &lt;b&gt;ä¸­æ–‡&lt;/b&gt; | &lt;a href=&#34;https://github.com/baichuan-inc/Baichuan2/raw/main/README_EN.md&#34;&gt;English&lt;/a&gt; &lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;/h4&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;ç›®å½•&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan2/main/#%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D&#34;&gt;ğŸ“– æ¨¡å‹ä»‹ç»&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan2/main/#Benchmark-%E7%BB%93%E6%9E%9C&#34;&gt;ğŸ“Š Benchmark ç»“æœ ğŸ¥‡ğŸ¥‡ğŸ”¥ğŸ”¥&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan2/main/#%E6%8E%A8%E7%90%86%E5%92%8C%E9%83%A8%E7%BD%B2&#34;&gt;âš™ï¸ æ¨ç†å’Œéƒ¨ç½²&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan2/main/#%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83&#34;&gt;ğŸ› ï¸ æ¨¡å‹å¾®è°ƒ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan2/main/#%E4%B8%AD%E9%97%B4-Checkpoints&#34;&gt;ğŸ’¾ ä¸­é—´ Checkpoints ğŸ”¥ğŸ”¥&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan2/main/#%E7%A4%BE%E5%8C%BA%E4%B8%8E%E7%94%9F%E6%80%81&#34;&gt;ğŸ‘¥ ç¤¾åŒºä¸ç”Ÿæ€&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan2/main/#%E5%A3%B0%E6%98%8E%E4%B8%8E%E5%8D%8F%E8%AE%AE&#34;&gt;ğŸ“œ å£°æ˜ä¸åè®®&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;æ¨¡å‹ä»‹ç»&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Baichuan 2 æ˜¯ç™¾å·æ™ºèƒ½æ¨å‡ºçš„&lt;strong&gt;æ–°ä¸€ä»£å¼€æºå¤§è¯­è¨€æ¨¡å‹&lt;/strong&gt;ï¼Œé‡‡ç”¨ &lt;strong&gt;2.6 ä¸‡äº¿&lt;/strong&gt; Tokens çš„é«˜è´¨é‡è¯­æ–™è®­ç»ƒã€‚&lt;/li&gt; &#xA; &lt;li&gt;Baichuan 2 åœ¨å¤šä¸ªæƒå¨çš„ä¸­æ–‡ã€è‹±æ–‡å’Œå¤šè¯­è¨€çš„é€šç”¨ã€é¢†åŸŸ benchmark ä¸Šå–å¾—åŒå°ºå¯¸&lt;strong&gt;æœ€ä½³&lt;/strong&gt;çš„æ•ˆæœã€‚&lt;/li&gt; &#xA; &lt;li&gt;æœ¬æ¬¡å‘å¸ƒåŒ…å«æœ‰ &lt;strong&gt;7B&lt;/strong&gt;ã€&lt;strong&gt;13B&lt;/strong&gt; çš„ &lt;strong&gt;Base&lt;/strong&gt; å’Œ &lt;strong&gt;Chat&lt;/strong&gt; ç‰ˆæœ¬ï¼Œå¹¶æä¾›äº† Chat ç‰ˆæœ¬çš„ &lt;strong&gt;4bits é‡åŒ–&lt;/strong&gt;ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æ‰€æœ‰ç‰ˆæœ¬å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ã€‚åŒæ—¶ï¼Œå¼€å‘è€…é€šè¿‡é‚®ä»¶ç”³è¯·å¹¶è·å¾—å®˜æ–¹å•†ç”¨è®¸å¯åï¼Œå³å¯&lt;strong&gt;å…è´¹å•†ç”¨&lt;/strong&gt;ï¼Œè¯·å‚è€ƒ&lt;a href=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan2/main/#%E5%8D%8F%E8%AE%AE&#34;&gt;åè®®&lt;/a&gt;ç« èŠ‚ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æ¬¢è¿é˜…è¯»æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Š &lt;a href=&#34;https://cdn.baichuan-ai.com/paper/Baichuan2-technical-report.pdf&#34;&gt;Baichuan 2: Open Large-scale Language Models&lt;/a&gt; è·å–æ›´å¤šä¿¡æ¯ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;æœ¬æ¬¡å‘å¸ƒç‰ˆæœ¬å’Œä¸‹è½½é“¾æ¥è§ä¸‹è¡¨ï¼š&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;åŸºåº§æ¨¡å‹&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;å¯¹é½æ¨¡å‹&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;å¯¹é½æ¨¡å‹ 4bits é‡åŒ–&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ğŸ¤— &lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan2-7B-Base&#34;&gt;Baichuan2-7B-Base&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ğŸ¤— &lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat&#34;&gt;Baichuan2-7B-Chat&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ğŸ¤— &lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat-4bits&#34;&gt;Baichuan2-7B-Chat-4bits&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ğŸ¤— &lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan2-13B-Base&#34;&gt;Baichuan2-13B-Base&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ğŸ¤— &lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat&#34;&gt;Baichuan2-13B-Chat&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ğŸ¤— &lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat-4bits&#34;&gt;Baichuan2-13B-Chat-4bits&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Benchmark ç»“æœ&lt;/h1&gt; &#xA;&lt;p&gt;æˆ‘ä»¬åœ¨&lt;a href=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan2/main/#%E9%80%9A%E7%94%A8%E9%A2%86%E5%9F%9F&#34;&gt;é€šç”¨&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan2/main/#%E6%B3%95%E5%BE%8B%E5%8C%BB%E7%96%97&#34;&gt;æ³•å¾‹&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan2/main/#%E6%B3%95%E5%BE%8B%E5%8C%BB%E7%96%97&#34;&gt;åŒ»ç–—&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan2/main/#%E6%95%B0%E5%AD%A6%E4%BB%A3%E7%A0%81&#34;&gt;æ•°å­¦&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan2/main/#%E6%95%B0%E5%AD%A6%E4%BB%A3%E7%A0%81&#34;&gt;ä»£ç &lt;/a&gt;å’Œ&lt;a href=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan2/main/#%E5%A4%9A%E8%AF%AD%E8%A8%80%E7%BF%BB%E8%AF%91&#34;&gt;å¤šè¯­è¨€ç¿»è¯‘&lt;/a&gt;å…­ä¸ªé¢†åŸŸçš„ä¸­è‹±æ–‡å’Œå¤šè¯­è¨€æƒå¨æ•°æ®é›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œäº†å¹¿æ³›æµ‹è¯•ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;é€šç”¨é¢†åŸŸ&lt;/h2&gt; &#xA;&lt;p&gt;åœ¨é€šç”¨é¢†åŸŸæˆ‘ä»¬åœ¨ä»¥ä¸‹æ•°æ®é›†ä¸Šè¿›è¡Œäº† 5-shot æµ‹è¯•ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cevalbenchmark.com/index.html#home&#34;&gt;C-Eval&lt;/a&gt; æ˜¯ä¸€ä¸ªå…¨é¢çš„ä¸­æ–‡åŸºç¡€æ¨¡å‹è¯„æµ‹æ•°æ®é›†ï¼Œæ¶µç›–äº† 52 ä¸ªå­¦ç§‘å’Œå››ä¸ªéš¾åº¦çš„çº§åˆ«ã€‚æˆ‘ä»¬ä½¿ç”¨è¯¥æ•°æ®é›†çš„ dev é›†ä½œä¸º few-shot çš„æ¥æºï¼Œåœ¨ test é›†ä¸Šè¿›è¡Œæµ‹è¯•ã€‚æˆ‘ä»¬é‡‡ç”¨äº† &lt;a href=&#34;https://github.com/baichuan-inc/Baichuan-7B/tree/main&#34;&gt;Baichuan-7B&lt;/a&gt; çš„è¯„æµ‹æ–¹æ¡ˆã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2009.03300&#34;&gt;MMLU&lt;/a&gt; æ˜¯åŒ…å« 57 ä¸ªä»»åŠ¡çš„è‹±æ–‡è¯„æµ‹æ•°æ®é›†ï¼Œæ¶µç›–äº†åˆç­‰æ•°å­¦ã€ç¾å›½å†å²ã€è®¡ç®—æœºç§‘å­¦ã€æ³•å¾‹ç­‰ï¼Œéš¾åº¦è¦†ç›–é«˜ä¸­æ°´å¹³åˆ°ä¸“å®¶æ°´å¹³ï¼Œæ˜¯ç›®å‰ä¸»æµçš„ LLM è¯„æµ‹æ•°æ®é›†ã€‚æˆ‘ä»¬é‡‡ç”¨äº†&lt;a href=&#34;https://github.com/hendrycks/test&#34;&gt;å¼€æº&lt;/a&gt;çš„è¯„æµ‹æ–¹æ¡ˆã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/haonan-li/CMMLU&#34;&gt;CMMLU&lt;/a&gt; æ˜¯ä¸€ä¸ªåŒ…å« 67 ä¸ªä¸»é¢˜çš„ç»¼åˆæ€§æ€§ä¸­æ–‡è¯„ä¼°åŸºå‡†ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ä¸­æ–‡è¯­å¢ƒä¸‹çš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬é‡‡ç”¨äº†å…¶&lt;a href=&#34;https://github.com/haonan-li/CMMLU&#34;&gt;å®˜æ–¹&lt;/a&gt;çš„è¯„æµ‹æ–¹æ¡ˆã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/OpenLMLab/GAOKAO-Bench&#34;&gt;Gaokao&lt;/a&gt; æ˜¯ä¸€ä¸ªä»¥ä¸­å›½é«˜è€ƒé¢˜ä½œä¸ºè¯„æµ‹å¤§è¯­è¨€æ¨¡å‹èƒ½åŠ›çš„æ•°æ®é›†ï¼Œç”¨ä»¥è¯„ä¼°æ¨¡å‹çš„è¯­è¨€èƒ½åŠ›å’Œé€»è¾‘æ¨ç†èƒ½åŠ›ã€‚ æˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶è¿›è¡Œäº†éšæœºåˆ’åˆ†ã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸ C-Eval ç±»ä¼¼çš„è¯„æµ‹æ–¹æ¡ˆã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/AGIEval&#34;&gt;AGIEval&lt;/a&gt; æ—¨åœ¨è¯„ä¼°æ¨¡å‹çš„è®¤çŸ¥å’Œè§£å†³é—®é¢˜ç›¸å…³çš„ä»»åŠ¡ä¸­çš„ä¸€èˆ¬èƒ½åŠ›ã€‚ æˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å››é€‰ä¸€å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶è¿›è¡Œäº†éšæœºåˆ’åˆ†ã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸ C-Eval ç±»ä¼¼çš„è¯„æµ‹æ–¹æ¡ˆã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/lukaemon/bbh&#34;&gt;BBH&lt;/a&gt; æ˜¯ä¸€ä¸ªæŒ‘æˆ˜æ€§ä»»åŠ¡ Big-Bench çš„å­é›†ã€‚Big-Bench ç›®å‰åŒ…æ‹¬ 204 é¡¹ä»»åŠ¡ã€‚ä»»åŠ¡ä¸»é¢˜æ¶‰åŠè¯­è¨€å­¦ã€å„¿ç«¥å‘å±•ã€æ•°å­¦ã€å¸¸è¯†æ¨ç†ã€ç”Ÿç‰©å­¦ã€ç‰©ç†å­¦ã€ç¤¾ä¼šåè§ã€è½¯ä»¶å¼€å‘ç­‰æ–¹é¢ã€‚BBH æ˜¯ä» 204 é¡¹ Big-Bench è¯„æµ‹åŸºå‡†ä»»åŠ¡ä¸­å¤§æ¨¡å‹è¡¨ç°ä¸å¥½çš„ä»»åŠ¡å•ç‹¬æ‹¿å‡ºæ¥å½¢æˆçš„è¯„æµ‹åŸºå‡†ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;7B æ¨¡å‹ç»“æœ&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;C-Eval&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;MMLU&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CMMLU&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Gaokao&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;AGIEval&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;BBH&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3-shot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68.40&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;83.93&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;70.33&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;66.15&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;63.27&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;75.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-3.5 Turbo&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.10&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68.54&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;54.06&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.07&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.13&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.59&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.10&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.10&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.75&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.81&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.17&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.38&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA2-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.90&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.73&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.38&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;25.97&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.53&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;39.16&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;MPT-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.15&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.93&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.00&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.54&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.83&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.20&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Falcon-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.23&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.03&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;25.66&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.24&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.10&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.77&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;ChatGLM2-6B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50.20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.90&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.00&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.44&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.28&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.65&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.80&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.30&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.02&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;36.34&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.44&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.48&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan2-7B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;54.00&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;54.16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;57.07&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.47&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.73&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;41.56&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;13B æ¨¡å‹ç»“æœ&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;C-Eval&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;MMLU&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CMMLU&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Gaokao&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;AGIEval&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;BBH&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3-shot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68.40&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;83.93&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;70.33&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;66.15&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;63.27&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;75.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-3.5 Turbo&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.10&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68.54&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;54.06&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.07&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.13&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.59&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.50&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.30&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.15&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.23&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.22&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;37.89&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA2-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.80&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;55.09&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;37.99&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.83&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.29&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.98&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Vicuna-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.80&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.00&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;36.28&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.11&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.55&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;43.04&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Chinese-Alpaca-Plus-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.80&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;43.90&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.43&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.78&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.46&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.94&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;XVERSE-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;53.70&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;55.21&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;58.44&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.69&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.54&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.06&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan-13B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.40&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.60&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;55.30&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.69&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;43.20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;43.01&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan2-13B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;58.10&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;59.17&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.97&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;54.33&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;48.17&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;48.78&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;æ³•å¾‹ã€åŒ»ç–—&lt;/h2&gt; &#xA;&lt;p&gt;æ³•å¾‹é¢†åŸŸæˆ‘ä»¬ä½¿ç”¨äº† &lt;a href=&#34;https://jecqa.thunlp.org/&#34;&gt;JEC-QA&lt;/a&gt; æ•°æ®é›†ã€‚JEC-QA æ•°æ®é›†æ¥æºäºä¸­å›½å›½å®¶å¸æ³•è€ƒè¯•ã€‚æˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å•é€‰é¢˜ã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸ C-Eval ç±»ä¼¼çš„è¯„æµ‹æ–¹æ¡ˆã€‚&lt;/p&gt; &#xA;&lt;p&gt;åŒ»ç–—é¢†åŸŸåˆ™ä½¿ç”¨é€šç”¨é¢†åŸŸæ•°æ®é›†ï¼ˆC-Evalã€MMLUã€CMMLUï¼‰ä¸­çš„åŒ»å­¦ç›¸å…³å­¦ç§‘ã€&lt;a href=&#34;https://arxiv.org/abs/2009.13081&#34;&gt;MedQA&lt;/a&gt; å’Œ &lt;a href=&#34;https://medmcqa.github.io/&#34;&gt;MedMCQA&lt;/a&gt;ã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸ C-Eval ç±»ä¼¼çš„è¯„æµ‹æ–¹æ¡ˆã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ä¸ºäº†æµ‹è¯•æ–¹ä¾¿ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† C-Eval çš„ val é›†è¿›è¡Œæµ‹è¯•ã€‚&lt;/li&gt; &#xA; &lt;li&gt;MedQA æ•°æ®é›†æ¥æºäºç¾å›½ã€ä¸­å›½çš„åŒ»å­¦è€ƒè¯•ã€‚æˆ‘ä»¬æµ‹è¯•äº† &lt;a href=&#34;https://huggingface.co/datasets/bigbio/med_qa&#34;&gt;MedQAæ•°æ®é›†&lt;/a&gt; ä¸­çš„ USMLE å’Œ MCMLE ä¸¤ä¸ªå­é›†ï¼Œå¹¶é‡‡ç”¨äº†äº”ä¸ªå€™é€‰çš„ç‰ˆæœ¬ã€‚&lt;/li&gt; &#xA; &lt;li&gt;MedMCQA æ•°æ®é›†æ¥æºäºå°åº¦åŒ»å­¦é™¢çš„å…¥å­¦è€ƒè¯•ã€‚æˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å•é€‰é¢˜ã€‚ç”±äº test é›†æ²¡æœ‰ç­”æ¡ˆï¼Œæˆ‘ä»¬ä½¿ç”¨ dev é›†è¿›è¡Œæµ‹è¯•ã€‚&lt;/li&gt; &#xA; &lt;li&gt;é€šç”¨é¢†åŸŸæ•°æ®é›†åŒ…å«çš„åŒ»å­¦ç›¸å…³å­¦ç§‘å¦‚ä¸‹ï¼š &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;C-Eval: clinical_medicine, basic_medicine&lt;/li&gt; &#xA;   &lt;li&gt;MMLU: clinical_knowledge, anatomy, college_medicine, college_biology, nutrition, virology, medical_genetics, professional_medicine&lt;/li&gt; &#xA;   &lt;li&gt;CMMLU: anatomy, clinical_knowledge, college_medicine, genetics, nutrition, traditional_chinese_medicine, virology&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;æˆ‘ä»¬å¯¹ä»¥ä¸Šæ•°æ®é›†è¿›è¡Œäº† 5-shot æµ‹è¯•ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;7B æ¨¡å‹ç»“æœ&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;JEC-QA&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CEval-MMLU-CMMLU&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;MedQA-USMLE&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;MedQA-MCMLE&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;MedMCQA&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;59.32&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;77.16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;80.28&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;74.58&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;72.51&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-3.5 Turbo&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.31&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.17&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;53.81&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.92&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;56.25&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.45&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.34&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.12&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;21.72&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.45&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA2-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;36.75&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.49&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.78&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;37.93&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;MPT-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.45&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.67&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.97&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;19.79&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.96&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Falcon-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;23.66&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;25.33&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;21.29&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;18.07&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.88&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;ChatGLM2-6B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.76&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.54&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.24&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.53&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.22&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.37&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.42&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;39.46&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.39&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan2-7B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.46&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;56.39&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.68&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;54.93&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;41.73&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;13B æ¨¡å‹ç»“æœ&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;JEC-QA&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CEval-MMLU-CMMLU&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;MedQA-USMLE&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;MedQA-MCMLE&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;MedMCQA&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5-shot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;59.32&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;77.16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;80.28&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;74.58&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;72.51&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-3.5 Turbo&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.31&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.17&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;53.81&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.92&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;56.25&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.54&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.14&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.83&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;23.38&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;39.52&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA2-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.08&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.42&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.04&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.74&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Vicuna-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.38&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.99&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.80&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.67&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.66&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Chinese-Alpaca-Plus-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.32&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.31&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.49&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.66&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.87&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;XVERSE-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.42&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;58.08&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.99&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;58.76&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;41.34&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan-13B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;41.34&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.77&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.07&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;43.67&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;39.60&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan2-13B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.40&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;59.33&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.38&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.62&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.86&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;æ•°å­¦ã€ä»£ç &lt;/h2&gt; &#xA;&lt;p&gt;æ•°å­¦é¢†åŸŸæˆ‘ä»¬ä½¿ç”¨ &lt;a href=&#34;https://opencompass.org.cn/&#34;&gt;OpenCompass&lt;/a&gt; è¯„ä¼°æ¡†æ¶ï¼Œå¯¹ &lt;a href=&#34;https://huggingface.co/datasets/gsm8k&#34;&gt;GSM8K&lt;/a&gt; å’Œ &lt;a href=&#34;https://huggingface.co/datasets/competition_math&#34;&gt;MATH&lt;/a&gt; æ•°æ®é›†è¿›è¡Œäº† 4-shot æµ‹è¯•ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GSM8K æ˜¯ç”± OpenAI å‘å¸ƒçš„ä¸€ä¸ªç”± 8.5K é«˜è´¨é‡çš„è¯­è¨€å¤šæ ·åŒ–çš„å°å­¦æ•°å­¦åº”ç”¨é¢˜ç»„æˆçš„æ•°æ®é›†ï¼Œè¦æ±‚æ ¹æ®ç»™å®šçš„åœºæ™¯å’Œä¸¤ä¸ªå¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼Œé€‰æ‹©æœ€åˆç†çš„æ–¹æ¡ˆã€‚&lt;/li&gt; &#xA; &lt;li&gt;MATH æ•°æ®é›†åŒ…å« 12,500 ä¸ªæ•°å­¦é—®é¢˜ï¼ˆå…¶ä¸­ 7500 ä¸ªå±äºè®­ç»ƒé›†ï¼Œ5000 ä¸ªå±äºæµ‹è¯•é›†ï¼‰ï¼Œè¿™äº›é—®é¢˜æ”¶é›†è‡ª AMC 10ã€AMC 12ã€AIME ç­‰æ•°å­¦ç«èµ›ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;ä»£ç é¢†åŸŸåˆ™é‡‡ç”¨äº† &lt;a href=&#34;https://huggingface.co/datasets/openai_humaneval&#34;&gt;HumanEval&lt;/a&gt; å’Œ &lt;a href=&#34;https://huggingface.co/datasets/mbpp&#34;&gt;MBPP&lt;/a&gt; æ•°æ®é›†ã€‚æˆ‘ä»¬ä½¿ç”¨ OpenCompassï¼Œå¯¹ HumanEval è¿›è¡Œäº† 0-shot æµ‹è¯•ï¼ŒMBPP æ•°æ®é›†è¿›è¡Œäº† 3-shot æµ‹è¯•ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;HumanEval ä¸­çš„ç¼–ç¨‹ä»»åŠ¡åŒ…æ‹¬æ¨¡å‹è¯­è¨€ç†è§£ã€æ¨ç†ã€ç®—æ³•å’Œç®€å•æ•°å­¦ï¼Œä»¥è¯„ä¼°æ¨¡å‹åŠŸèƒ½æ­£ç¡®æ€§ï¼Œå¹¶è¡¡é‡æ¨¡å‹çš„é—®é¢˜è§£å†³èƒ½åŠ›ã€‚&lt;/li&gt; &#xA; &lt;li&gt;MBPP åŒ…æ‹¬ 974 ä¸ª Python çŸ­å‡½æ•°ã€ç¨‹åºçš„æ–‡å­—æè¿°ä»¥åŠç”¨äºæ£€æŸ¥åŠŸèƒ½æ­£ç¡®æ€§çš„æµ‹è¯•ç”¨ä¾‹çš„æ•°æ®é›†ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;7B æ¨¡å‹ç»“æœ&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;GSM8K&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;MATH&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;HumanEval&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;MBPP&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3-shot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;89.99&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;69.51&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;63.60&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-3.5 Turbo&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;57.77&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13.96&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.44&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.40&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.78&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.02&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.59&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14.00&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA2-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.22&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.24&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12.80&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14.80&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;MPT-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8.64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.90&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14.02&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;23.40&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Falcon-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5.46&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.68&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10.20&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;ChatGLM2-6B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.89&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6.40&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.15&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.00&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.17&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.54&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6.60&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan2-7B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.49&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5.58&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;18.29&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.20&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;13B æ¨¡å‹ç»“æœ&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;GSM8K&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;MATH&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;HumanEval&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;MBPP&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0-shot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3-shot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;89.99&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;69.51&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;63.60&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-3.5 Turbo&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;57.77&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13.96&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.44&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.40&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20.55&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.68&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;15.24&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;21.40&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA2-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.89&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4.96&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;15.24&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.00&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Vicuna-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.13&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4.36&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.46&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;15.00&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Chinese-Alpaca-Plus-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.98&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.50&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.46&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20.00&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;XVERSE-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;18.20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.18&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;15.85&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.80&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan-13B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.76&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4.84&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.59&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.80&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan2-13B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.77&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10.08&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17.07&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.20&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;å¤šè¯­è¨€ç¿»è¯‘&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘ä»¬é‡‡ç”¨äº† &lt;a href=&#34;https://huggingface.co/datasets/facebook/flores&#34;&gt;Flores-101&lt;/a&gt; æ•°æ®é›†æ¥è¯„ä¼°æ¨¡å‹çš„å¤šè¯­è¨€èƒ½åŠ›ã€‚Flores-101 æ¶µç›–äº†ä¸–ç•Œå„åœ°çš„ 101 ç§è¯­è¨€ã€‚å®ƒçš„æ•°æ®æ¥æºäºæ–°é—»ã€æ—…æ¸¸æŒ‡å—å’Œä¹¦ç±ç­‰å¤šä¸ªä¸åŒé¢†åŸŸã€‚æˆ‘ä»¬é€‰æ‹©äº†è”åˆå›½å®˜æ–¹è¯­è¨€ï¼ˆé˜¿æ‹‰ä¼¯æ–‡ã€ä¸­æ–‡ã€è‹±æ–‡ã€æ³•æ–‡ã€ä¿„æ–‡å’Œè¥¿ç­ç‰™æ–‡ï¼‰ä»¥åŠå¾·æ–‡å’Œæ—¥æ–‡ä½œä¸ºæµ‹è¯•è¯­ç§ã€‚æˆ‘ä»¬ä½¿ç”¨ OpenCompass å¯¹ Flores-101 ä¸­çš„ä¸­-è‹±ã€ä¸­-æ³•ã€ä¸­-è¥¿ç­ç‰™ã€ä¸­-é˜¿æ‹‰ä¼¯ã€ä¸­-ä¿„ã€ä¸­-æ—¥ã€ä¸­-å¾·ç­‰ä¸ƒä¸ªå­ä»»åŠ¡åˆ†åˆ«è¿›è¡Œäº† 8-shot æµ‹è¯•ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;7B æ¨¡å‹ç»“æœ&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CN-EN&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CN-FR&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CN-ES&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CN-AR&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CN-RU&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CN-JP&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CN-DE&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Average&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.94&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.56&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20.01&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10.76&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;18.62&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13.26&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20.83&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20.43&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-3.5 Turbo&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.67&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.15&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;19.58&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10.73&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17.45&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.82&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;19.70&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17.59&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17.27&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12.02&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.54&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.00&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4.47&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.41&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8.73&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.63&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA2-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;25.76&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;15.14&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.92&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.79&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4.99&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.20&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10.15&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10.14&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;MPT-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20.77&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.53&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8.96&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.10&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.54&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.91&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6.54&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.48&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Falcon-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.13&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;15.67&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.28&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.35&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.41&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6.41&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.91&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;ChatGLM2-6B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.28&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.42&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.77&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.78&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.26&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4.61&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6.68&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;25.07&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.51&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12.72&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.41&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6.66&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.24&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.86&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10.50&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan2-7B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.27&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20.87&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.17&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.39&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.21&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.11&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12.76&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13.25&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;13B æ¨¡å‹ç»“æœ&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CN-EN&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CN-FR&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CN-ES&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CN-AR&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CN-RU&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CN-JP&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;CN-DE&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Average&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.94&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.56&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20.01&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10.76&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;18.62&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13.26&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20.83&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20.43&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;GPT-3.5 Turbo&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.67&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.15&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;19.58&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10.73&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17.45&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.82&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;19.70&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17.59&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;21.75&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13.29&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.58&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.61&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.41&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10.66&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10.07&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;LLaMA2-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;25.44&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;19.25&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17.49&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.38&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10.34&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.13&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.13&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12.17&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Vicuna-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.63&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;18.04&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14.67&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.70&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.27&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.59&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10.25&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.31&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Chinese-Alpaca-Plus-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.53&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13.82&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.29&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.28&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.52&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.31&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8.13&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8.27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;XVERSE-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.26&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.03&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.67&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.78&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.61&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.08&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14.26&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14.53&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan-13B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.24&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;20.90&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;15.92&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.98&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.65&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.64&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12.00&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13.19&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Baichuan2-13B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.61&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.11&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;17.27&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.39&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14.17&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.58&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;14.53&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.09&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;æ¨ç†å’Œéƒ¨ç½²&lt;/h1&gt; &#xA;&lt;p&gt;æ¨ç†æ‰€éœ€çš„æ¨¡å‹æƒé‡ã€æºç ã€é…ç½®å·²å‘å¸ƒåœ¨ Hugging Faceï¼Œä¸‹è½½é“¾æ¥è§æœ¬æ–‡æ¡£æœ€å¼€å§‹çš„è¡¨æ ¼ã€‚æˆ‘ä»¬åœ¨æ­¤ç¤ºèŒƒå¤šç§æ¨ç†æ–¹å¼ã€‚ç¨‹åºä¼šè‡ªåŠ¨ä» Hugging Face ä¸‹è½½æ‰€éœ€èµ„æºã€‚&lt;/p&gt; &#xA;&lt;h2&gt;å®‰è£…ä¾èµ–&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Python ä»£ç æ–¹å¼&lt;/h2&gt; &#xA;&lt;h3&gt;Chat æ¨¡å‹æ¨ç†æ–¹æ³•ç¤ºèŒƒ&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; import torch&#xA;&amp;gt;&amp;gt;&amp;gt; from transformers import AutoModelForCausalLM, AutoTokenizer&#xA;&amp;gt;&amp;gt;&amp;gt; from transformers.generation.utils import GenerationConfig&#xA;&amp;gt;&amp;gt;&amp;gt; tokenizer = AutoTokenizer.from_pretrained(&#34;baichuan-inc/Baichuan2-13B-Chat&#34;, use_fast=False, trust_remote_code=True)&#xA;&amp;gt;&amp;gt;&amp;gt; model = AutoModelForCausalLM.from_pretrained(&#34;baichuan-inc/Baichuan2-13B-Chat&#34;, device_map=&#34;auto&#34;, torch_dtype=torch.bfloat16, trust_remote_code=True)&#xA;&amp;gt;&amp;gt;&amp;gt; model.generation_config = GenerationConfig.from_pretrained(&#34;baichuan-inc/Baichuan2-13B-Chat&#34;)&#xA;&amp;gt;&amp;gt;&amp;gt; messages = []&#xA;&amp;gt;&amp;gt;&amp;gt; messages.append({&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;è§£é‡Šä¸€ä¸‹â€œæ¸©æ•…è€ŒçŸ¥æ–°â€&#34;})&#xA;&amp;gt;&amp;gt;&amp;gt; response = model.chat(tokenizer, messages)&#xA;&amp;gt;&amp;gt;&amp;gt; print(response)&#xA;&#34;æ¸©æ•…è€ŒçŸ¥æ–°&#34;æ˜¯ä¸€å¥ä¸­å›½å¤ä»£çš„æˆè¯­ï¼Œå‡ºè‡ªã€Šè®ºè¯­Â·ä¸ºæ”¿ã€‹ç¯‡ã€‚è¿™å¥è¯çš„æ„æ€æ˜¯ï¼šé€šè¿‡å›é¡¾è¿‡å»ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°æ–°çš„çŸ¥è¯†å’Œç†è§£ã€‚æ¢å¥è¯è¯´ï¼Œå­¦ä¹ å†å²å’Œç»éªŒå¯ä»¥è®©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£ç°åœ¨å’Œæœªæ¥ã€‚&#xA;&#xA;è¿™å¥è¯é¼“åŠ±æˆ‘ä»¬åœ¨å­¦ä¹ å’Œç”Ÿæ´»ä¸­ä¸æ–­åœ°å›é¡¾å’Œåæ€è¿‡å»çš„ç»éªŒï¼Œä»è€Œè·å¾—æ–°çš„å¯ç¤ºå’Œæˆé•¿ã€‚é€šè¿‡é‡æ¸©æ—§çš„çŸ¥è¯†å’Œç»å†ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°æ–°çš„è§‚ç‚¹å’Œç†è§£ï¼Œä»è€Œæ›´å¥½åœ°åº”å¯¹ä¸æ–­å˜åŒ–çš„ä¸–ç•Œå’ŒæŒ‘æˆ˜ã€‚&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Base æ¨¡å‹æ¨ç†æ–¹æ³•ç¤ºèŒƒ&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from transformers import AutoModelForCausalLM, AutoTokenizer&#xA;&amp;gt;&amp;gt;&amp;gt; tokenizer = AutoTokenizer.from_pretrained(&#34;baichuan-inc/Baichuan2-13B-Base&#34;, trust_remote_code=True)&#xA;&amp;gt;&amp;gt;&amp;gt; model = AutoModelForCausalLM.from_pretrained(&#34;baichuan-inc/Baichuan2-13B-Base&#34;, device_map=&#34;auto&#34;, trust_remote_code=True)&#xA;&amp;gt;&amp;gt;&amp;gt; inputs = tokenizer(&#39;ç™»é¹³é›€æ¥¼-&amp;gt;ç‹ä¹‹æ¶£\nå¤œé›¨å¯„åŒ—-&amp;gt;&#39;, return_tensors=&#39;pt&#39;)&#xA;&amp;gt;&amp;gt;&amp;gt; inputs = inputs.to(&#39;cuda:0&#39;)&#xA;&amp;gt;&amp;gt;&amp;gt; pred = model.generate(**inputs, max_new_tokens=64, repetition_penalty=1.1)&#xA;&amp;gt;&amp;gt;&amp;gt; print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))&#xA;ç™»é¹³é›€æ¥¼-&amp;gt;ç‹ä¹‹æ¶£&#xA;å¤œé›¨å¯„åŒ—-&amp;gt;æå•†éš&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;åœ¨ä¸Šè¿°ä¸¤æ®µä»£ç ä¸­ï¼Œæ¨¡å‹åŠ è½½æŒ‡å®š &lt;code&gt;device_map=&#39;auto&#39;&lt;/code&gt;ï¼Œä¼šä½¿ç”¨æ‰€æœ‰å¯ç”¨æ˜¾å¡ã€‚å¦‚éœ€æŒ‡å®šä½¿ç”¨çš„è®¾å¤‡ï¼Œå¯ä»¥ä½¿ç”¨ç±»ä¼¼ &lt;code&gt;export CUDA_VISIBLE_DEVICES=0,1&lt;/code&gt;ï¼ˆä½¿ç”¨äº†0ã€1å·æ˜¾å¡ï¼‰çš„æ–¹å¼æ§åˆ¶ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;å‘½ä»¤è¡Œå·¥å…·æ–¹å¼&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python cli_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æœ¬å‘½ä»¤è¡Œå·¥å…·æ˜¯ä¸º Chat åœºæ™¯è®¾è®¡ï¼Œå› æ­¤æˆ‘ä»¬ä¸æ”¯æŒä½¿ç”¨è¯¥å·¥å…·è°ƒç”¨ Base æ¨¡å‹ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ç½‘é¡µ demo æ–¹å¼&lt;/h2&gt; &#xA;&lt;p&gt;ä¾é  streamlit è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œä¼šåœ¨æœ¬åœ°å¯åŠ¨ä¸€ä¸ª web æœåŠ¡ï¼ŒæŠŠæ§åˆ¶å°ç»™å‡ºçš„åœ°å€æ”¾å…¥æµè§ˆå™¨å³å¯è®¿é—®ã€‚æœ¬ç½‘é¡µ demo å·¥å…·æ˜¯ä¸º Chat åœºæ™¯è®¾è®¡ï¼Œå› æ­¤æˆ‘ä»¬ä¸æ”¯æŒä½¿ç”¨è¯¥å·¥å…·è°ƒç”¨ Base æ¨¡å‹ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;streamlit run web_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Baichuan2-13B-Chat ç¤ºä¾‹è¾“å‡º&lt;/h2&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;ä»£ç &lt;/b&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;ç”¨æˆ·ï¼šæ‰¾åˆ°ä¸‹åˆ—æ•°ç»„çš„ä¸­ä½æ•°[3.1,6.2,1.3,8.4,10.5,11.6,2.1]ï¼Œè¯·ç”¨pythonä»£ç å®Œæˆä»¥ä¸ŠåŠŸèƒ½&#xA;&#xA;Baichuan 2ï¼šdef find_median(numbers):&#xA;    numbers.sort()&#xA;    length = len(numbers)&#xA;    if length % 2 == 0:&#xA;        return (numbers[length // 2 - 1] + numbers[length // 2]) / 2&#xA;    else:&#xA;        return numbers[length // 2]&#xA;numbers = [3.1, 6.2, 1.3, 8.4, 10.5, 11.6, 2.1]&#xA;print(find_median(numbers))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;æ•°å­¦&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;ç”¨æˆ·ï¼šé¸¡å’Œå…”åœ¨ä¸€ä¸ªç¬¼å­é‡Œï¼Œå…±æœ‰26ä¸ªå¤´ï¼Œ68åªè„šï¼Œé‚£ä¹ˆé¸¡æœ‰å¤šå°‘åªï¼Œå…”æœ‰å¤šå°‘åªï¼Ÿ&#xA;&#xA;Baichuan 2ï¼šæˆ‘ä»¬å¯ä»¥ç”¨ä»£æ•°æ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å‡è®¾é¸¡çš„æ•°é‡ä¸ºxï¼Œå…”å­çš„æ•°é‡ä¸ºyã€‚æ ¹æ®é¢˜ç›®ç»™å‡ºçš„ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä»¥ä¸‹ä¸¤ä¸ªæ–¹ç¨‹ï¼š&#xA;&#xA;1. x + y = 26 (å¤´çš„æ€»æ•°)&#xA;2. 2x + 4y = 68 (è„šçš„æ€»æ•°)&#xA;&#xA;ç°åœ¨æˆ‘ä»¬éœ€è¦è§£è¿™ä¸ªäºŒå…ƒä¸€æ¬¡æ–¹ç¨‹ç»„ã€‚é¦–å…ˆä»ç¬¬ä¸€ä¸ªæ–¹ç¨‹ä¸­è§£å‡ºxï¼š&#xA;&#xA;x = 26 - y&#xA;&#xA;ç„¶åå°†xçš„è¡¨è¾¾å¼ä»£å…¥ç¬¬äºŒä¸ªæ–¹ç¨‹ï¼š&#xA;&#xA;2(26 - y) + 4y = 68&#xA;52 - 2y + 4y = 68&#xA;2y = 16&#xA;&#xA;æ¥ä¸‹æ¥æˆ‘ä»¬æ±‚è§£yçš„å€¼ï¼š&#xA;&#xA;y = 16 / 2&#xA;y = 8&#xA;&#xA;ç°åœ¨æˆ‘ä»¬å¾—åˆ°äº†å…”å­çš„æ•°é‡æ˜¯8åªã€‚å°†yçš„å€¼ä»£å…¥xçš„è¡¨è¾¾å¼æ±‚å¾—é¸¡çš„æ•°é‡ï¼š&#xA;&#xA;x = 26 - 8&#xA;x = 18&#xA;&#xA;æ‰€ä»¥é¸¡æœ‰18åªï¼Œå…”å­æœ‰8åªã€‚&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;æŒ‡ä»¤è·Ÿéš&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;ç”¨æˆ·ï¼šä»ç°åœ¨å¼€å§‹ï¼Œè¯·ä½ å°†æˆ‘æ¥ä¸‹æ¥è¯´çš„æ¯ä¸€å¥è¯ç¿»è¯‘æˆè‹±è¯­ï¼Œå‡†å¤‡å¥½äº†å—ï¼Ÿ&#xA;&#xA;Baichuan 2ï¼šI&#39;m ready to translate every word you say next into English.&#xA;&#xA;ç”¨æˆ·ï¼šä½ å¥½&#xA;&#xA;Baichuan 2ï¼šHello&#xA;&#xA;ç”¨æˆ·ï¼šæˆ‘æ˜¯Baichuan 2ï¼Œå¾ˆé«˜å…´è®¤è¯†å¤§å®¶&#xA;&#xA;Baichuan 2ï¼šI am Baichuan 2, and I am very happy to meet everyone.&#xA;&#xA;ç”¨æˆ·ï¼šå¸Œæœ›é€šè¿‡å¤§å®¶çš„å…±åŒåŠªåŠ›ï¼Œæ—©æ—¥è¿æ¥AGIæ—¶ä»£çš„åˆ°æ¥&#xA;&#xA;Baichuan 2ï¼šI hope through the joint efforts of all of us, we can welcome the arrival of the AGI era as soon as possible.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;è§£é¢˜&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;ç”¨æˆ·ï¼šä»¥ä¸‹ç‰©ç†å¸¸è¯†é¢˜ç›®ï¼Œå“ªä¸€ä¸ªæ˜¯é”™è¯¯çš„?A.åœ¨è‡ªç„¶ç¯å¢ƒä¸‹ï¼Œå£°éŸ³åœ¨å›ºä½“ä¸­ä¼ æ’­é€Ÿåº¦æœ€å¿«ã€‚B.ç‰›é¡¿ç¬¬ä¸€å®šå¾‹:ä¸€ä¸ªç‰©ä½“å¦‚æœä¸å—åŠ›ä½œç”¨ï¼Œå°†ä¿æŒé™æ­¢æˆ–åŒ€é€Ÿç›´çº¿è¿åŠ¨çš„çŠ¶æ€ã€‚C.ç‰›é¡¿ç¬¬ä¸‰å®šå¾‹:å¯¹äºæ¯ä¸ªä½œç”¨åŠ›ï¼Œéƒ½æœ‰ä¸€ä¸ªç›¸ç­‰è€Œåå‘çš„åä½œç”¨åŠ›ã€‚D.å£°éŸ³åœ¨ç©ºæ°”ä¸­çš„ä¼ æ’­é€Ÿåº¦ä¸º1000m/sã€‚&#xA;&#xA;Baichuan 2ï¼šæœ¬é¢˜è€ƒæŸ¥ç‰©ç†åŸºæœ¬æ¦‚å¿µå’ŒåŸç†çš„ç†è§£å’Œåº”ç”¨èƒ½åŠ›ã€‚&#xA;Aé¡¹ï¼šå£°éŸ³çš„ä¼ æ’­éœ€è¦ä»‹è´¨ï¼Œåœ¨å›ºä½“ã€æ¶²ä½“å’Œæ°”ä½“çš„ä¸‰ç§ä»‹è´¨ä¸­ï¼Œå£°éŸ³åœ¨å›ºä½“ä¸­çš„ä¼ æ’­é€Ÿåº¦æ˜¯æœ€å¿«çš„ï¼Œæ•…Aæ­£ç¡®ï¼› Bé¡¹ï¼šç‰›é¡¿ç¬¬ä¸€å®šå¾‹æ˜¯æƒ¯æ€§å®šå¾‹ï¼Œå…¶å†…å®¹æ˜¯ï¼šä¸€ä¸ªç‰©ä½“å¦‚æœæ²¡æœ‰å—åˆ°å¤–åŠ›çš„ä½œç”¨ï¼Œè¦ä¹ˆä¿æŒé™æ­¢çŠ¶æ€ï¼Œè¦ä¹ˆä¿æŒåŒ€é€Ÿç›´çº¿è¿åŠ¨çŠ¶æ€ï¼Œç›´åˆ°æœ‰å¤–åŠ›è¿«ä½¿å®ƒæ”¹å˜è¿åŠ¨çŠ¶æ€ä¸ºæ­¢ï¼Œæ•…Bæ­£ç¡®ï¼› Cé¡¹ï¼šç‰›é¡¿ç¬¬ä¸‰å®šå¾‹çš„å†…å®¹æ˜¯ï¼šå¯¹äºæ¯ä¸€ä¸ªä½œç”¨åŠ›ï¼Œéƒ½æœ‰ä¸€ä¸ªå¤§å°ç›¸ç­‰ã€æ–¹å‘ç›¸åçš„åä½œç”¨åŠ›ï¼Œè¿™ä¸¤ä¸ªåŠ›åˆ†åˆ«ä½œç”¨åœ¨ä¸¤ä¸ªç›¸äº’ä½œç”¨çš„ç‰©ä½“ä¸Šï¼Œæ•…Cé”™è¯¯ï¼› Dé¡¹ï¼šå£°éŸ³åœ¨ç©ºæ°”ä¸­ä»¥æ³¢çš„å½¢å¼ä¼ æ’­ï¼Œå…¶ä¼ æ’­é€Ÿåº¦ä¸ä»‹è´¨çš„æ¸©åº¦ã€æ¹¿åº¦ç­‰å› ç´ æœ‰å…³ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ï¼Œå£°éŸ³åœ¨ç©ºæ°”ä¸­çš„ä¼ æ’­é€Ÿåº¦çº¦ä¸º340m/så·¦å³ï¼Œè€Œä¸æ˜¯1000m/sï¼Œæ•…Dé”™è¯¯ã€‚ å› æ­¤ï¼Œæœ¬é¢˜çš„æ­£ç¡®ç­”æ¡ˆæ˜¯ D ã€‚&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;pre&gt;&lt;code&gt;ç”¨æˆ·ï¼šI&#39;m Mike ã€‚I am going to have a busy weekendã€‚On Saturdayï¼ŒI am going to learn how to swimã€‚I will go with my fatherã€‚Then we are going to have lunch in the restaurantã€‚In the afternoonï¼Œwe are going to the zooã€‚We are going to see the pandasã€‚On Sundayï¼ŒI will finish my homework in the morningã€‚In the afternoonï¼Œmy parents and I are going to visit my grandparentsã€‚We will have dinner togetherã€‚&#xA;é˜…è¯»çŸ­æ–‡ï¼Œåˆ¤æ–­æ­£ç¡®å’Œé”™è¯¯ï¼æ­£ç¡®è¯·å†™Tï¼Œé”™è¯¯è¯·å†™F:&#xA;1.Mike is going to have a busy weekend()&#xA;2.Mike is going to learn how to swim with his father()&#xA;3.They are going to have lunch at home()&#xA;&#xA;Baichuan 2ï¼š1. Tï¼ˆæ­£ç¡®çš„ï¼‰&#xA;2. Tï¼ˆæ­£ç¡®çš„ï¼‰&#xA;3. Fï¼ˆé”™è¯¯çš„ï¼‰&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;é‡åŒ–éƒ¨ç½²&lt;/h2&gt; &#xA;&lt;p&gt;ä¸ºäº†è®©ä¸åŒçš„ç”¨æˆ·ä»¥åŠä¸åŒçš„å¹³å°éƒ½èƒ½è¿è¡Œ Baichuan 2 æ¨¡å‹ï¼Œæˆ‘ä»¬é’ˆå¯¹ Baichuan 2 æ¨¡å‹åšäº†ç›¸åº”åœ°é‡åŒ–å·¥ä½œï¼ˆåŒ…æ‹¬ Baichuan2-7B-Chat å’Œ Baichuan2-13B-Chatï¼‰ï¼Œæ–¹ä¾¿ç”¨æˆ·å¿«é€Ÿé«˜æ•ˆåœ°åœ¨è‡ªå·±çš„å¹³å°éƒ¨ç½² Baichuan 2 æ¨¡å‹ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;é‡åŒ–æ–¹æ³•&lt;/h3&gt; &#xA;&lt;p&gt;Baichuan 2 çš„é‡‡ç”¨ç¤¾åŒºä¸»æµçš„é‡åŒ–æ–¹æ³•ï¼š&lt;a href=&#34;https://github.com/TimDettmers/bitsandbytes&#34;&gt;BitsAndBytes&lt;/a&gt;ã€‚è¯¥æ–¹æ³•å¯ä»¥ä¿è¯é‡åŒ–åçš„æ•ˆæœåŸºæœ¬ä¸æ‰ç‚¹ï¼Œç›®å‰å·²ç»é›†æˆåˆ° transformers åº“é‡Œï¼Œå¹¶åœ¨ç¤¾åŒºå¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚BitsAndBytes æ”¯æŒ 8bits å’Œ 4bits ä¸¤ç§é‡åŒ–ï¼Œå…¶ä¸­ 4bits æ”¯æŒ FP4 å’Œ NF4 ä¸¤ç§æ ¼å¼ï¼ŒBaichuan 2 é€‰ç”¨ NF4 ä½œä¸º 4bits é‡åŒ–çš„æ•°æ®ç±»å‹ã€‚&lt;/p&gt; &#xA;&lt;p&gt;åŸºäºè¯¥é‡åŒ–æ–¹æ³•ï¼ŒBaichuan 2 æ”¯æŒåœ¨çº¿é‡åŒ–å’Œç¦»çº¿é‡åŒ–ä¸¤ç§æ¨¡å¼ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;åœ¨çº¿é‡åŒ–&lt;/h3&gt; &#xA;&lt;p&gt;å¯¹äºåœ¨çº¿é‡åŒ–ï¼Œæˆ‘ä»¬æ”¯æŒ 8bits å’Œ 4bits é‡åŒ–ï¼Œä½¿ç”¨æ–¹å¼å’Œ &lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan-13B-Chat&#34;&gt;Baichuan-13B&lt;/a&gt; é¡¹ç›®ä¸­çš„æ–¹å¼ç±»ä¼¼ï¼Œåªéœ€è¦å…ˆåŠ è½½æ¨¡å‹åˆ° CPU çš„å†…å­˜é‡Œï¼Œå†è°ƒç”¨&lt;code&gt;quantize()&lt;/code&gt;æ¥å£é‡åŒ–ï¼Œæœ€åè°ƒç”¨ &lt;code&gt;cuda()&lt;/code&gt;å‡½æ•°ï¼Œå°†é‡åŒ–åçš„æƒé‡æ‹·è´åˆ° GPU æ˜¾å­˜ä¸­ã€‚å®ç°æ•´ä¸ªæ¨¡å‹åŠ è½½çš„ä»£ç éå¸¸ç®€å•ï¼Œæˆ‘ä»¬ä»¥ Baichuan2-7B-Chat ä¸ºä¾‹ï¼š&lt;/p&gt; &#xA;&lt;p&gt;8bits åœ¨çº¿é‡åŒ–:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModelForCausalLM.from_pretrained(&#34;baichuan-inc/Baichuan2-7B-Chat&#34;, torch_dtype=torch.float16, trust_remote_code=True)&#xA;model = model.quantize(8).cuda() &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;4bits åœ¨çº¿é‡åŒ–:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModelForCausalLM.from_pretrained(&#34;baichuan-inc/Baichuan2-7B-Chat&#34;, torch_dtype=torch.float16, trust_remote_code=True)&#xA;model = model.quantize(4).cuda() &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ç”¨ &lt;code&gt;from_pretrained&lt;/code&gt; æ¥å£çš„æ—¶å€™ï¼Œç”¨æˆ·ä¸€èˆ¬ä¼šåŠ ä¸Š &lt;code&gt;device_map=&#34;auto&#34;&lt;/code&gt;ï¼Œåœ¨ä½¿ç”¨åœ¨çº¿é‡åŒ–æ—¶ï¼Œéœ€è¦å»æ‰è¿™ä¸ªå‚æ•°ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;ç¦»çº¿é‡åŒ–&lt;/h3&gt; &#xA;&lt;p&gt;ä¸ºäº†æ–¹ä¾¿ç”¨æˆ·çš„ä½¿ç”¨ï¼Œæˆ‘ä»¬æä¾›äº†ç¦»çº¿é‡åŒ–å¥½çš„ 4bits çš„ç‰ˆæœ¬ &lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat-4bits/tree/main&#34;&gt;Baichuan2-7B-Chat-4bits&lt;/a&gt;ï¼Œä¾›ç”¨æˆ·ä¸‹è½½ã€‚ ç”¨æˆ·åŠ è½½ Baichuan2-7B-Chat-4bits æ¨¡å‹å¾ˆç®€å•ï¼Œåªéœ€è¦æ‰§è¡Œ:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModelForCausalLM.from_pretrained(&#34;baichuan-inc/Baichuan2-7B-Chat-4bits&#34;, device_map=&#34;auto&#34;, trust_remote_code=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å¯¹äº 8bits ç¦»çº¿é‡åŒ–ï¼Œæˆ‘ä»¬æ²¡æœ‰æä¾›ç›¸åº”çš„ç‰ˆæœ¬ï¼Œå› ä¸º Hugging Face transformers åº“æä¾›äº†ç›¸åº”çš„ API æ¥å£ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿çš„å®ç° 8bits é‡åŒ–æ¨¡å‹çš„ä¿å­˜å’ŒåŠ è½½ã€‚ç”¨æˆ·å¯ä»¥è‡ªè¡ŒæŒ‰ç…§å¦‚ä¸‹æ–¹å¼å®ç° 8bits çš„æ¨¡å‹ä¿å­˜å’ŒåŠ è½½ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Model saving: model_id is the original model directory, and quant8_saved_dir is the directory where the 8bits quantized model is saved.&#xA;model = AutoModelForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map=&#34;auto&#34;, trust_remote_code=True)&#xA;model.save_pretrained(quant8_saved_dir)&#xA;model = AutoModelForCausalLM.from_pretrained(quant8_saved_dir, device_map=&#34;auto&#34;, trust_remote_code=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;é‡åŒ–æ•ˆæœ&lt;/h3&gt; &#xA;&lt;p&gt;é‡åŒ–å‰åæ˜¾å­˜å ç”¨å¯¹æ¯” (GPU Mem in GB)ï¼š&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Precision&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Baichuan2-7B&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Baichuan2-13B&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;bf16 / fp16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;15.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8bits&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;16.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4bits&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;é‡åŒ–ååœ¨å„ä¸ª benchmark ä¸Šçš„ç»“æœå’ŒåŸå§‹ç‰ˆæœ¬å¯¹æ¯”å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model 5-shot&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;C-Eval&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MMLU&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;CMMLU&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan2-13B-Chat&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;56.74&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;57.32&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;59.68&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan2-13B-Chat-4bits&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;56.05&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;56.24&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;58.82&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan2-7B-Chat&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;54.35&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.93&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;54.99&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan2-7B-Chat-4bits&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;53.04&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.72&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.84&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;C-Eval æ˜¯åœ¨å…¶ val set ä¸Šè¿›è¡Œçš„è¯„æµ‹&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;å¯ä»¥çœ‹åˆ°ï¼Œ4bits ç›¸å¯¹ bfloat16 ç²¾åº¦æŸå¤±åœ¨ 1 - 2 ä¸ªç™¾åˆ†ç‚¹å·¦å³ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;CPU éƒ¨ç½²&lt;/h2&gt; &#xA;&lt;p&gt;Baichuan 2 æ¨¡å‹æ”¯æŒ CPU æ¨ç†ï¼Œä½†éœ€è¦å¼ºè°ƒçš„æ˜¯ï¼ŒCPU çš„æ¨ç†é€Ÿåº¦ç›¸å¯¹è¾ƒæ…¢ã€‚éœ€æŒ‰å¦‚ä¸‹æ–¹å¼ä¿®æ”¹æ¨¡å‹åŠ è½½çš„æ–¹å¼ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Taking Baichuan2-7B-Chat as an example&#xA;model = AutoModelForCausalLM.from_pretrained(&#34;baichuan-inc/Baichuan2-7B-Chat&#34;, torch_dtype=torch.float32, trust_remote_code=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;å¯¹ Baichuan 1 çš„æ¨ç†ä¼˜åŒ–è¿ç§»åˆ° Baichuan 2&lt;/h2&gt; &#xA;&lt;p&gt;ç”±äºå¾ˆå¤šç”¨æˆ·åœ¨ Baichuan 1 (Baichuan-7B, Baichuan-13B)ä¸Šåšäº†å¾ˆå¤šä¼˜åŒ–çš„å·¥ä½œï¼Œä¾‹å¦‚ç¼–è¯‘ä¼˜åŒ–ã€é‡åŒ–ç­‰ï¼Œä¸ºäº†å°†è¿™äº›å·¥ä½œé›¶æˆæœ¬åœ°åº”ç”¨äº Baichuan 2ï¼Œç”¨æˆ·å¯ä»¥å¯¹ Baichuan 2 æ¨¡å‹åšä¸€ä¸ªç¦»çº¿è½¬æ¢ï¼Œè½¬æ¢åå°±å¯ä»¥å½“åš Baichuan 1 æ¨¡å‹æ¥ä½¿ç”¨ã€‚å…·ä½“æ¥è¯´ï¼Œç”¨æˆ·åªéœ€è¦åˆ©ç”¨ä»¥ä¸‹è„šæœ¬ç¦»çº¿å¯¹ Baichuan 2 æ¨¡å‹çš„æœ€åä¸€å±‚ lm_head åšå½’ä¸€åŒ–ï¼Œå¹¶æ›¿æ¢æ‰&lt;code&gt;lm_head.weight&lt;/code&gt;å³å¯ã€‚æ›¿æ¢å®Œåï¼Œå°±å¯ä»¥åƒå¯¹ Baichuan 1 æ¨¡å‹ä¸€æ ·å¯¹è½¬æ¢åçš„æ¨¡å‹åšç¼–è¯‘ä¼˜åŒ–ç­‰å·¥ä½œäº†ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;import os&#xA;ori_model_dir = &#39;your Baichuan 2 model directory&#39;&#xA;# To avoid overwriting the original model, it&#39;s best to save the converted model to another directory before replacing it&#xA;new_model_dir = &#39;your normalized lm_head weight Baichuan 2 model directory&#39;&#xA;model = torch.load(os.path.join(ori_model_dir, &#39;pytorch_model.bin&#39;))&#xA;lm_head_w = model[&#39;lm_head.weight&#39;]&#xA;lm_head_w = torch.nn.functional.normalize(lm_head_w)&#xA;model[&#39;lm_head.weight&#39;] = lm_head_w&#xA;torch.save(model, os.path.join(new_model_dir, &#39;pytorch_model.bin&#39;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;æ¨¡å‹å¾®è°ƒ&lt;/h1&gt; &#xA;&lt;h2&gt;ä¾èµ–å®‰è£…&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/baichuan-inc/Baichuan2.git&#xA;cd Baichuan2/fine-tune&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;å¦‚éœ€ä½¿ç”¨ LoRA ç­‰è½»é‡çº§å¾®è°ƒæ–¹æ³•éœ€é¢å¤–å®‰è£… &lt;a href=&#34;https://github.com/huggingface/peft&#34;&gt;peft&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;å¦‚éœ€ä½¿ç”¨ xFormers è¿›è¡Œè®­ç»ƒåŠ é€Ÿéœ€é¢å¤–å®‰è£… &lt;a href=&#34;https://github.com/facebookresearch/xformers&#34;&gt;xFormers&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;å•æœºè®­ç»ƒ&lt;/h2&gt; &#xA;&lt;p&gt;ä¸‹é¢æˆ‘ä»¬ç»™ä¸€ä¸ªå¾®è°ƒ Baichuan2-7B-Base çš„å•æœºè®­ç»ƒä¾‹å­ã€‚&lt;/p&gt; &#xA;&lt;p&gt;è®­ç»ƒæ•°æ®ï¼š&lt;code&gt;data/belle_chat_ramdon_10k.json&lt;/code&gt;ï¼Œè¯¥æ ·ä¾‹æ•°æ®æ˜¯ä» &lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M&#34;&gt;multiturn_chat_0.8M&lt;/a&gt; é‡‡æ ·å‡º 1 ä¸‡æ¡ï¼Œå¹¶ä¸”åšäº†æ ¼å¼è½¬æ¢ã€‚ä¸»è¦æ˜¯å±•ç¤ºå¤šè½®æ•°æ®æ€ä¹ˆè®­ç»ƒï¼Œä¸ä¿è¯æ•ˆæœã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;hostfile=&#34;&#34;&#xA;deepspeed --hostfile=$hostfile fine-tune.py  \&#xA;    --report_to &#34;none&#34; \&#xA;    --data_path &#34;data/belle_chat_ramdon_10k.json&#34; \&#xA;    --model_name_or_path &#34;baichuan-inc/Baichuan2-7B-Base&#34; \&#xA;    --output_dir &#34;output&#34; \&#xA;    --model_max_length 512 \&#xA;    --num_train_epochs 4 \&#xA;    --per_device_train_batch_size 16 \&#xA;    --gradient_accumulation_steps 1 \&#xA;    --save_strategy epoch \&#xA;    --learning_rate 2e-5 \&#xA;    --lr_scheduler_type constant \&#xA;    --adam_beta1 0.9 \&#xA;    --adam_beta2 0.98 \&#xA;    --adam_epsilon 1e-8 \&#xA;    --max_grad_norm 1.0 \&#xA;    --weight_decay 1e-4 \&#xA;    --warmup_ratio 0.0 \&#xA;    --logging_steps 1 \&#xA;    --gradient_checkpointing True \&#xA;    --deepspeed ds_config.json \&#xA;    --bf16 True \&#xA;    --tf32 True&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;å¤šæœºè®­ç»ƒ&lt;/h2&gt; &#xA;&lt;p&gt;å¤šæœºè®­ç»ƒåªéœ€è¦ç»™ä¸€ä¸‹ hostfile ï¼Œå†…å®¹ç±»ä¼¼å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ip1 slots=8&#xA;ip2 slots=8&#xA;ip3 slots=8&#xA;ip4 slots=8&#xA;....&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;åŒæ—¶åœ¨è®­ç»ƒè„šæœ¬é‡Œé¢æŒ‡å®š hosftfile çš„è·¯å¾„ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;hostfile=&#34;/path/to/hostfile&#34;&#xA;deepspeed --hostfile=$hostfile fine-tune.py  \&#xA;    --report_to &#34;none&#34; \&#xA;    --data_path &#34;data/belle_chat_ramdon_10k.json&#34; \&#xA;    --model_name_or_path &#34;baichuan-inc/Baichuan2-7B-Base&#34; \&#xA;    --output_dir &#34;output&#34; \&#xA;    --model_max_length 512 \&#xA;    --num_train_epochs 4 \&#xA;    --per_device_train_batch_size 16 \&#xA;    --gradient_accumulation_steps 1 \&#xA;    --save_strategy epoch \&#xA;    --learning_rate 2e-5 \&#xA;    --lr_scheduler_type constant \&#xA;    --adam_beta1 0.9 \&#xA;    --adam_beta2 0.98 \&#xA;    --adam_epsilon 1e-8 \&#xA;    --max_grad_norm 1.0 \&#xA;    --weight_decay 1e-4 \&#xA;    --warmup_ratio 0.0 \&#xA;    --logging_steps 1 \&#xA;    --gradient_checkpointing True \&#xA;    --deepspeed ds_config.json \&#xA;    --bf16 True \&#xA;    --tf32 True&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;è½»é‡åŒ–å¾®è°ƒ&lt;/h2&gt; &#xA;&lt;p&gt;ä»£ç å·²ç»æ”¯æŒè½»é‡åŒ–å¾®è°ƒå¦‚ LoRAï¼Œå¦‚éœ€ä½¿ç”¨ä»…éœ€åœ¨ä¸Šé¢çš„è„šæœ¬ä¸­åŠ å…¥ä»¥ä¸‹å‚æ•°ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;--use_lora True&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;LoRA å…·ä½“çš„é…ç½®å¯è§ &lt;code&gt;fine-tune.py&lt;/code&gt; è„šæœ¬ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ä½¿ç”¨ LoRA å¾®è°ƒåå¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤åŠ è½½æ¨¡å‹ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from peft import AutoPeftModelForCausalLM&#xA;model = AutoPeftModelForCausalLM.from_pretrained(&#34;output&#34;, trust_remote_code=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;ä¸­é—´ Checkpoints&lt;/h1&gt; &#xA;&lt;p&gt;é™¤äº†è®­ç»ƒäº† 2.6 ä¸‡äº¿ Tokens çš„ Baichuan2-7B-Base æ¨¡å‹ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†åœ¨æ­¤ä¹‹å‰çš„å¦å¤– 11 ä¸ªä¸­é—´ checkpointsï¼ˆåˆ†åˆ«å¯¹åº”è®­ç»ƒäº†çº¦ 0.2 ~ 2.4 ä¸‡äº¿ Tokensï¼‰ä¾›ç¤¾åŒºç ”ç©¶ä½¿ç”¨ï¼ˆ&lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan2-7B-Intermediate-Checkpoints&#34;&gt;ä¸‹è½½åœ°å€&lt;/a&gt;ï¼‰ã€‚ä¸‹å›¾ç»™å‡ºäº†è¿™äº› checkpoints åœ¨ C-Evalã€MMLUã€CMMLU ä¸‰ä¸ª benchmark ä¸Šçš„æ•ˆæœå˜åŒ–ï¼š&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/baichuan-inc/Baichuan2/raw/main/media/checkpoints.jpeg?raw=true&#34; width=&#34;50%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;ç¤¾åŒºä¸ç”Ÿæ€&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;ğŸ“¢ğŸ“¢ğŸ“¢ æˆ‘ä»¬ä¼šåœ¨æ­¤æŒç»­æ›´æ–°ç¤¾åŒºå’Œç”Ÿæ€å¯¹ Baichuan 2 çš„æ”¯æŒ ğŸ˜€ğŸ˜€ğŸ˜€&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;åä¸ºæ˜‡è…¾&lt;/h2&gt; &#xA;&lt;h3&gt;Pytorch æ¡†æ¶&lt;/h3&gt; &#xA;&lt;p&gt;æ¨¡å‹å¾®è°ƒï¼šBaichuan 2 æ”¯æŒåŸºäºæ˜‡è…¾ NPU çš„ PyTorch + DeepSpeed æ¨¡å‹å¾®è°ƒï¼Œå¾®è°ƒæ‰€éœ€çš„ modelingã€READMEã€ç¤ºä¾‹è„šæœ¬å·²å‘å¸ƒï¼š&lt;a href=&#34;https://gitee.com/ascend/ModelZoo-PyTorch/tree/master/PyTorch/built-in/foundation/Baichuan2/7B&#34;&gt;Baichuan2-7B&lt;/a&gt;ã€Baichuan2-13B æ­£åœ¨é€‚é…ä¸­ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æ¨ç†éƒ¨ç½²ï¼šBaichuan 2 æ”¯æŒæ˜‡è…¾ NPU æ¨ç†ï¼Œæ¨ç†æ‰€éœ€çš„ modelingã€READMEã€ç¤ºä¾‹è„šæœ¬å·²å‘å¸ƒï¼š&lt;a href=&#34;https://gitee.com/ascend/ModelZoo-PyTorch/tree/master/ACL_PyTorch/built-in/foundation_models/baichuan2/7b&#34;&gt;Baichuan2-7B&lt;/a&gt;ã€&lt;a href=&#34;https://gitee.com/ascend/ModelZoo-PyTorch/tree/master/ACL_PyTorch/built-in/foundation_models/baichuan2/13b&#34;&gt;Baichuan2-13B&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;MindSpore æ¡†æ¶&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitee.com/mindspore/mindformers&#34;&gt;MindFormers&lt;/a&gt; æ˜¯ä¸€ä¸ªåŸºäºæ˜‡æ€æ¡†æ¶ï¼ˆMindSporeï¼‰å¹¶æ”¯æŒå¤§æ¨¡å‹è®­ç»ƒã€å¾®è°ƒã€è¯„ä¼°ã€æ¨ç†ã€éƒ¨ç½²çš„å…¨æµç¨‹å¼€å‘å¥—ä»¶ï¼Œ&lt;a href=&#34;https://gitee.com/mindspore/mindformers/tree/dev/research/baichuan2&#34;&gt;Baichuan2-7B / 13B&lt;/a&gt; å·²é›†æˆäºæ­¤å¥—ä»¶ï¼Œæ”¯æŒç”¨æˆ·è¿›è¡Œæ¨¡å‹å¾®è°ƒã€éƒ¨ç½²ï¼Œå…·ä½“ä½¿ç”¨æ–¹å¼å¯è§ &lt;a href=&#34;https://gitee.com/mindspore/mindformers/tree/dev/research/baichuan2/baichuan2.md&#34;&gt;README&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;å¤§æ¨¡å‹ä½“éªŒå¹³å°&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://xihe.mindspore.cn&#34;&gt;æ˜‡æ€å¤§æ¨¡å‹å¹³å°&lt;/a&gt; åŸºäºæ˜‡æ€ MindSpore AI æ¡†æ¶ã€MindFormers å¤§æ¨¡å‹å¼€å‘å¥—ä»¶ä¸æ˜‡è…¾ç¡¬ä»¶ç®—åŠ›ï¼Œå°† &lt;a href=&#34;https://xihe.mindspore.cn/modelzoo/baichuan2_7b_chat&#34;&gt;Baichuan2-7B&lt;/a&gt; å¤§æ¨¡å‹èƒ½åŠ›å¼€æ”¾ç»™å…¬ä¼—ï¼Œæ¬¢è¿å¤§å®¶åœ¨çº¿ä½“éªŒã€‚&lt;/p&gt; &#xA;&lt;h1&gt;å£°æ˜ä¸åè®®&lt;/h1&gt; &#xA;&lt;h2&gt;å£°æ˜&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘ä»¬åœ¨æ­¤å£°æ˜ï¼Œæˆ‘ä»¬çš„å¼€å‘å›¢é˜Ÿå¹¶æœªåŸºäº Baichuan 2 æ¨¡å‹å¼€å‘ä»»ä½•åº”ç”¨ï¼Œæ— è®ºæ˜¯åœ¨ iOSã€Androidã€ç½‘é¡µæˆ–ä»»ä½•å…¶ä»–å¹³å°ã€‚æˆ‘ä»¬å¼ºçƒˆå‘¼åæ‰€æœ‰ä½¿ç”¨è€…ï¼Œä¸è¦åˆ©ç”¨ Baichuan 2 æ¨¡å‹è¿›è¡Œä»»ä½•å±å®³å›½å®¶ç¤¾ä¼šå®‰å…¨æˆ–è¿æ³•çš„æ´»åŠ¨ã€‚å¦å¤–ï¼Œæˆ‘ä»¬ä¹Ÿè¦æ±‚ä½¿ç”¨è€…ä¸è¦å°† Baichuan 2 æ¨¡å‹ç”¨äºæœªç»é€‚å½“å®‰å…¨å®¡æŸ¥å’Œå¤‡æ¡ˆçš„äº’è”ç½‘æœåŠ¡ã€‚æˆ‘ä»¬å¸Œæœ›æ‰€æœ‰çš„ä½¿ç”¨è€…éƒ½èƒ½éµå®ˆè¿™ä¸ªåŸåˆ™ï¼Œç¡®ä¿ç§‘æŠ€çš„å‘å±•èƒ½åœ¨è§„èŒƒå’Œåˆæ³•çš„ç¯å¢ƒä¸‹è¿›è¡Œã€‚&lt;/p&gt; &#xA;&lt;p&gt;æˆ‘ä»¬å·²ç»å°½æˆ‘ä»¬æ‰€èƒ½ï¼Œæ¥ç¡®ä¿æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ•°æ®çš„åˆè§„æ€§ã€‚ç„¶è€Œï¼Œå°½ç®¡æˆ‘ä»¬å·²ç»åšå‡ºäº†å·¨å¤§çš„åŠªåŠ›ï¼Œä½†ç”±äºæ¨¡å‹å’Œæ•°æ®çš„å¤æ‚æ€§ï¼Œä»æœ‰å¯èƒ½å­˜åœ¨ä¸€äº›æ— æ³•é¢„è§çš„é—®é¢˜ã€‚å› æ­¤ï¼Œå¦‚æœç”±äºä½¿ç”¨ Baichuan 2 å¼€æºæ¨¡å‹è€Œå¯¼è‡´çš„ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€å…¬å…±èˆ†è®ºé£é™©ï¼Œæˆ–æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨æ‰€å¸¦æ¥çš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;åè®®&lt;/h2&gt; &#xA;&lt;p&gt;å¯¹æœ¬ä»“åº“æºç çš„ä½¿ç”¨éµå¾ªå¼€æºè®¸å¯åè®® &lt;a href=&#34;https://github.com/baichuan-inc/Baichuan2/raw/main/LICENSE&#34;&gt;Apache 2.0&lt;/a&gt;ã€‚å¯¹ Baichuan 2 æ¨¡å‹çš„ç¤¾åŒºä½¿ç”¨éœ€éµå¾ª&lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/resolve/main/Baichuan%202%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf&#34;&gt;ã€ŠBaichuan 2 æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹&lt;/a&gt;ã€‚Baichuan 2 æ”¯æŒå•†ç”¨ã€‚å¦‚æœå°† Baichuan 2 æ¨¡å‹æˆ–å…¶è¡ç”Ÿå“ç”¨ä½œå•†ä¸šç”¨é€”ï¼Œè¯·æ‚¨é€šè¿‡é‚®ç®± &lt;a href=&#34;mailto:opensource@baichuan-inc.com&#34;&gt;opensource@baichuan-inc.com&lt;/a&gt; è”ç³»è®¸å¯æ–¹ï¼Œç”³è¯·ä¹¦é¢æˆæƒã€‚&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>BerriAI/litellm</title>
    <updated>2023-09-09T01:34:29Z</updated>
    <id>tag:github.com,2023-09-09:/BerriAI/litellm</id>
    <link href="https://github.com/BerriAI/litellm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;lightweight package to simplify LLM API calls - Azure, OpenAI, Cohere, Anthropic, Replicate. Manages input/output translation&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; ğŸš… LiteLLM &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt;Call all LLM APIs using the OpenAI format [Anthropic, Huggingface, Cohere, TogetherAI, Azure, OpenAI, etc.]&lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; &lt;a href=&#34;https://pypi.org/project/litellm/&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/pypi/v/litellm.svg?sanitize=true&#34; alt=&#34;PyPI Version&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/litellm/0.1.1/&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/stable%20version-v0.1.424-blue?color=green&amp;amp;link=https://pypi.org/project/litellm/0.1.1/&#34; alt=&#34;Stable Version&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://dl.circleci.com/status-badge/redirect/gh/BerriAI/litellm/tree/main&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://dl.circleci.com/status-badge/img/gh/BerriAI/litellm/tree/main.svg?style=svg&#34; alt=&#34;CircleCI&#34;&gt; &lt;/a&gt; &lt;img src=&#34;https://img.shields.io/pypi/dm/litellm&#34; alt=&#34;Downloads&#34;&gt; &lt;a href=&#34;https://discord.gg/wuPM9dRgDw&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://dcbadge.vercel.app/api/server/wuPM9dRgDw?style=flat&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://www.ycombinator.com/companies/berriai&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Y%20Combinator-W23-orange?style=flat-square&#34; alt=&#34;Y Combinator W23&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/BerriAI/litellm/issues&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/commit-activity/m/BerriAI/litellm&#34; alt=&#34;git commit activity&#34;&gt; &lt;/a&gt; &lt;/h4&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; &lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/liteLLM_OpenAI.ipynb&#34;&gt; &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt; &lt;/a&gt; &lt;/h4&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; &lt;a href=&#34;https://docs.litellm.ai/docs/providers&#34; target=&#34;_blank&#34;&gt;100+ Supported Models&lt;/a&gt; | &lt;a href=&#34;https://docs.litellm.ai/docs/&#34; target=&#34;_blank&#34;&gt;Docs&lt;/a&gt; | &lt;a href=&#34;https://litellm.ai/playground&#34; target=&#34;_blank&#34;&gt;Demo Website&lt;/a&gt; &lt;/h4&gt; &#xA;&lt;p&gt;LiteLLM manages&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Translating inputs to the provider&#39;s completion and embedding endpoints&lt;/li&gt; &#xA; &lt;li&gt;Guarantees &lt;a href=&#34;https://docs.litellm.ai/docs/completion/output&#34;&gt;consistent output&lt;/a&gt;, text responses will always be available at &lt;code&gt;[&#39;choices&#39;][0][&#39;message&#39;][&#39;content&#39;]&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Exception mapping - common exceptions across providers are mapped to the OpenAI exception types&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;ğŸ¤ Schedule a 1-on-1 Session:&lt;/strong&gt; Book a &lt;a href=&#34;https://calendly.com/d/4mp-gd3-k5k/litellm-1-1-onboarding-chat&#34;&gt;1-on-1 session&lt;/a&gt; with Krrish and Ishaan, the founders, to discuss any issues, provide feedback, or explore how we can improve LiteLLM for you.&lt;/p&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/liteLLM_OpenAI.ipynb&#34;&gt; &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt; &lt;/a&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install litellm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from litellm import completion&#xA;import os&#xA;## set ENV variables&#xA;os.environ[&#34;OPENAI_API_KEY&#34;] = &#34;openai key&#34;&#xA;os.environ[&#34;COHERE_API_KEY&#34;] = &#34;cohere key&#34;&#xA;os.environ[&#34;ANTHROPIC_API_KEY&#34;] = &#34;anthropic key&#34;&#xA;&#xA;messages = [{ &#34;content&#34;: &#34;Hello, how are you?&#34;,&#34;role&#34;: &#34;user&#34;}]&#xA;&#xA;# openai call&#xA;response = completion(model=&#34;gpt-3.5-turbo&#34;, messages=messages)&#xA;&#xA;# cohere call&#xA;response = completion(model=&#34;command-nightly&#34;, messages=messages)&#xA;&#xA;# anthropic&#xA;response = completion(model=&#34;claude-2&#34;, messages=messages)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Stable version&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install litellm==0.1.424&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Streaming&lt;/h2&gt; &#xA;&lt;p&gt;liteLLM supports streaming the model response back, pass &lt;code&gt;stream=True&lt;/code&gt; to get a streaming iterator in response. Streaming is supported for OpenAI, Azure, Anthropic, Huggingface models&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;response = completion(model=&#34;gpt-3.5-turbo&#34;, messages=messages, stream=True)&#xA;for chunk in response:&#xA;    print(chunk[&#39;choices&#39;][0][&#39;delta&#39;])&#xA;&#xA;# claude 2&#xA;result = completion(&#39;claude-2&#39;, messages, stream=True)&#xA;for chunk in result:&#xA;  print(chunk[&#39;choices&#39;][0][&#39;delta&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Support / talk with founders&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://calendly.com/d/4mp-gd3-k5k/berriai-1-1-onboarding-litellm-hosted-version&#34;&gt;Schedule Demo ğŸ‘‹&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.gg/wuPM9dRgDw&#34;&gt;Community Discord ğŸ’­&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Our numbers ğŸ“ +1 (770) 8783-106 / â€­+1 (412) 618-6238â€¬&lt;/li&gt; &#xA; &lt;li&gt;Our emails âœ‰ï¸ &lt;a href=&#34;mailto:ishaan@berri.ai&#34;&gt;ishaan@berri.ai&lt;/a&gt; / &lt;a href=&#34;mailto:krrish@berri.ai&#34;&gt;krrish@berri.ai&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Why did we build this&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Need for simplicity&lt;/strong&gt;: Our code started to get extremely complicated managing &amp;amp; translating calls between Azure, OpenAI, Cohere&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Contributors&lt;/h1&gt; &#xA;&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; &#xA;&lt;!-- prettier-ignore-start --&gt; &#xA;&lt;!-- markdownlint-disable --&gt; &#xA;&lt;!-- markdownlint-restore --&gt; &#xA;&lt;!-- prettier-ignore-end --&gt; &#xA;&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; &#xA;&lt;a href=&#34;https://github.com/BerriAI/litellm/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=BerriAI/litellm&#34;&gt; &lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/promptflow</title>
    <updated>2023-09-09T01:34:29Z</updated>
    <id>tag:github.com,2023-09-09:/microsoft/promptflow</id>
    <link href="https://github.com/microsoft/promptflow" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Build high-quality LLM apps - from prototyping, testing to production deployment and monitoring.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Prompt flow&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pypi.org/project/promptflow/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/promptflow&#34; alt=&#34;Python package&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/promptflow/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/promptflow.svg?maxAge=2592000&#34; alt=&#34;Python&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/promptflow/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/promptflow&#34; alt=&#34;PyPI - Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/microsoft/promptflow/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/microsoft/promptflow&#34; alt=&#34;License: MIT&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Welcome to join us to make Prompt flow better by participating &lt;a href=&#34;https://github.com/microsoft/promptflow/discussions&#34;&gt;discussions&lt;/a&gt;, opening &lt;a href=&#34;https://github.com/microsoft/promptflow/issues/new/choose&#34;&gt;issues&lt;/a&gt;, submitting &lt;a href=&#34;https://github.com/microsoft/promptflow/pulls&#34;&gt;PRs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;strong&gt;Prompt flow&lt;/strong&gt; is a suite of development tools designed to streamline the end-to-end development cycle of LLM-based AI applications, from ideation, prototyping, testing, evaluation to production deployment and monitoring. It makes prompt engineering much easier and enables you to build LLM apps with production quality.&lt;/p&gt; &#xA;&lt;p&gt;With prompt flow, you will be able to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create executable workflows that link LLMs, prompts, Python code and other tools together.&lt;/li&gt; &#xA; &lt;li&gt;Debug and iterate your flows, especially the interaction with LLMs with ease.&lt;/li&gt; &#xA; &lt;li&gt;Evaluate your flow&#39;s quality and performance with larger datasets.&lt;/li&gt; &#xA; &lt;li&gt;Integrate the testing and evaluation into your CI/CD system to ensure quality of your flow.&lt;/li&gt; &#xA; &lt;li&gt;Deploy your flow to the serving platform you choose or integrate into your app&#39;s code base easily.&lt;/li&gt; &#xA; &lt;li&gt;(Optional but highly recommended) Collaborate with your team by leveraging the cloud version of &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/overview-what-is-prompt-flow?view=azureml-api-2&#34;&gt;Prompt flow in Azure AI&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Get Started with Prompt flow âš¡&lt;/h2&gt; &#xA;&lt;p&gt;Develop your LLM apps with Prompt flow: please start with our &lt;a href=&#34;https://microsoft.github.io/promptflow/&#34;&gt;docs&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/promptflow/main/examples/README.md&#34;&gt;examples&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://microsoft.github.io/promptflow/how-to-guides/quick-start.html&#34;&gt;Getting Started with Prompt Flow&lt;/a&gt;: A step by step guidance to invoke your first flow run.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/promptflow/raw/main/examples/tutorials/e2e-development/chat-with-pdf.md&#34;&gt;Tutorial: Chat with PDF&lt;/a&gt;: An end-to-end tutorial on how to build a high quality chat application with prompt flow, including flow development and evaluation with metrics.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Contribute to Prompt flow: please start with our dev setup guide: &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/promptflow/main/docs/dev/dev_setup.md&#34;&gt;dev_setup.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&#34;https://cla.opensource.microsoft.com&#34;&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h2&gt;Trademarks&lt;/h2&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright (c) Microsoft Corporation. All rights reserved.&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/promptflow/main/LICENSE&#34;&gt;MIT&lt;/a&gt; license.&lt;/p&gt;</summary>
  </entry>
</feed>