<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-08-12T01:35:49Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Dicklesworthstone/llm_aided_ocr</title>
    <updated>2024-08-12T01:35:49Z</updated>
    <id>tag:github.com,2024-08-12:/Dicklesworthstone/llm_aided_ocr</id>
    <link href="https://github.com/Dicklesworthstone/llm_aided_ocr" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Enhance Tesseract OCR output for scanned PDFs by applying Large Language Model (LLM) corrections.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LLM-Aided OCR Project&lt;/h1&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;The LLM-Aided OCR Project is an advanced system designed to significantly enhance the quality of Optical Character Recognition (OCR) output. By leveraging cutting-edge natural language processing techniques and large language models (LLMs), this project transforms raw OCR text into highly accurate, well-formatted, and readable documents.&lt;/p&gt; &#xA;&lt;h2&gt;Example Outputs&lt;/h2&gt; &#xA;&lt;p&gt;To see what the LLM-Aided OCR Project can do, check out these example outputs:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Dicklesworthstone/llm_aided_ocr/raw/main/160301289-Warren-Buffett-Katharine-Graham-Letter.pdf&#34;&gt;Original PDF&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Dicklesworthstone/llm_aided_ocr/raw/main/160301289-Warren-Buffett-Katharine-Graham-Letter__raw_ocr_output.txt&#34;&gt;Raw OCR Output&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Dicklesworthstone/llm_aided_ocr/raw/main/160301289-Warren-Buffett-Katharine-Graham-Letter_llm_corrected.md&#34;&gt;LLM-Corrected Markdown Output&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;PDF to image conversion&lt;/li&gt; &#xA; &lt;li&gt;OCR using Tesseract&lt;/li&gt; &#xA; &lt;li&gt;Advanced error correction using LLMs (local or API-based)&lt;/li&gt; &#xA; &lt;li&gt;Smart text chunking for efficient processing&lt;/li&gt; &#xA; &lt;li&gt;Markdown formatting option&lt;/li&gt; &#xA; &lt;li&gt;Header and page number suppression (optional)&lt;/li&gt; &#xA; &lt;li&gt;Quality assessment of the final output&lt;/li&gt; &#xA; &lt;li&gt;Support for both local LLMs and cloud-based API providers (OpenAI, Anthropic)&lt;/li&gt; &#xA; &lt;li&gt;Asynchronous processing for improved performance&lt;/li&gt; &#xA; &lt;li&gt;Detailed logging for process tracking and debugging&lt;/li&gt; &#xA; &lt;li&gt;GPU acceleration for local LLM inference&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Detailed Technical Overview&lt;/h2&gt; &#xA;&lt;h3&gt;PDF Processing and OCR&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;PDF to Image Conversion&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Function: &lt;code&gt;convert_pdf_to_images()&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Uses &lt;code&gt;pdf2image&lt;/code&gt; library to convert PDF pages into images&lt;/li&gt; &#xA;   &lt;li&gt;Supports processing a subset of pages with &lt;code&gt;max_pages&lt;/code&gt; and &lt;code&gt;skip_first_n_pages&lt;/code&gt; parameters&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;OCR Processing&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Function: &lt;code&gt;ocr_image()&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Utilizes &lt;code&gt;pytesseract&lt;/code&gt; for text extraction&lt;/li&gt; &#xA;   &lt;li&gt;Includes image preprocessing with &lt;code&gt;preprocess_image()&lt;/code&gt; function: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Converts image to grayscale&lt;/li&gt; &#xA;     &lt;li&gt;Applies binary thresholding using Otsu&#39;s method&lt;/li&gt; &#xA;     &lt;li&gt;Performs dilation to enhance text clarity&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Text Processing Pipeline&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Chunk Creation&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The &lt;code&gt;process_document()&lt;/code&gt; function splits the full text into manageable chunks&lt;/li&gt; &#xA;   &lt;li&gt;Uses sentence boundaries for natural splits&lt;/li&gt; &#xA;   &lt;li&gt;Implements an overlap between chunks to maintain context&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Error Correction and Formatting&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Core function: &lt;code&gt;process_chunk()&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Two-step process: a. OCR Correction: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Uses LLM to fix OCR-induced errors&lt;/li&gt; &#xA;     &lt;li&gt;Maintains original structure and content b. Markdown Formatting (optional):&lt;/li&gt; &#xA;     &lt;li&gt;Converts text to proper markdown format&lt;/li&gt; &#xA;     &lt;li&gt;Handles headings, lists, emphasis, and more&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Duplicate Content Removal&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Implemented within the markdown formatting step&lt;/li&gt; &#xA;   &lt;li&gt;Identifies and removes exact or near-exact repeated paragraphs&lt;/li&gt; &#xA;   &lt;li&gt;Preserves unique content and ensures text flow&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Header and Page Number Suppression (Optional)&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Can be configured to remove or distinctly format headers, footers, and page numbers&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;LLM Integration&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Flexible LLM Support&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Supports both local LLMs and cloud-based API providers (OpenAI, Anthropic)&lt;/li&gt; &#xA;   &lt;li&gt;Configurable through environment variables&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Local LLM Handling&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Function: &lt;code&gt;generate_completion_from_local_llm()&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Uses &lt;code&gt;llama_cpp&lt;/code&gt; library for local LLM inference&lt;/li&gt; &#xA;   &lt;li&gt;Supports custom grammars for structured output&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;API-based LLM Handling&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Functions: &lt;code&gt;generate_completion_from_claude()&lt;/code&gt; and &lt;code&gt;generate_completion_from_openai()&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Implements proper error handling and retry logic&lt;/li&gt; &#xA;   &lt;li&gt;Manages token limits and adjusts request sizes dynamically&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Asynchronous Processing&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Uses &lt;code&gt;asyncio&lt;/code&gt; for concurrent processing of chunks when using API-based LLMs&lt;/li&gt; &#xA;   &lt;li&gt;Maintains order of processed chunks for coherent final output&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Token Management&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Token Estimation&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Function: &lt;code&gt;estimate_tokens()&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Uses model-specific tokenizers when available&lt;/li&gt; &#xA;   &lt;li&gt;Falls back to &lt;code&gt;approximate_tokens()&lt;/code&gt; for quick estimation&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic Token Adjustment&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Adjusts &lt;code&gt;max_tokens&lt;/code&gt; parameter based on prompt length and model limits&lt;/li&gt; &#xA;   &lt;li&gt;Implements &lt;code&gt;TOKEN_BUFFER&lt;/code&gt; and &lt;code&gt;TOKEN_CUSHION&lt;/code&gt; for safe token management&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Quality Assessment&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Output Quality Evaluation&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Function: &lt;code&gt;assess_output_quality()&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Compares original OCR text with processed output&lt;/li&gt; &#xA;   &lt;li&gt;Uses LLM to provide a quality score and explanation&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Logging and Error Handling&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Comprehensive logging throughout the codebase&lt;/li&gt; &#xA; &lt;li&gt;Detailed error messages and stack traces for debugging&lt;/li&gt; &#xA; &lt;li&gt;Suppresses HTTP request logs to reduce noise&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Configuration and Customization&lt;/h2&gt; &#xA;&lt;p&gt;The project uses a &lt;code&gt;.env&lt;/code&gt; file for easy configuration. Key settings include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;LLM selection (local or API-based)&lt;/li&gt; &#xA; &lt;li&gt;API provider selection&lt;/li&gt; &#xA; &lt;li&gt;Model selection for different providers&lt;/li&gt; &#xA; &lt;li&gt;Token limits and buffer sizes&lt;/li&gt; &#xA; &lt;li&gt;Markdown formatting options&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Output and File Handling&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Raw OCR Output&lt;/strong&gt;: Saved as &lt;code&gt;{base_name}__raw_ocr_output.txt&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;LLM Corrected Output&lt;/strong&gt;: Saved as &lt;code&gt;{base_name}_llm_corrected.md&lt;/code&gt; or &lt;code&gt;.txt&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The script generates detailed logs of the entire process, including timing information and quality assessments.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.12+&lt;/li&gt; &#xA; &lt;li&gt;Tesseract OCR engine&lt;/li&gt; &#xA; &lt;li&gt;PDF2Image library&lt;/li&gt; &#xA; &lt;li&gt;PyTesseract&lt;/li&gt; &#xA; &lt;li&gt;OpenAI API (optional)&lt;/li&gt; &#xA; &lt;li&gt;Anthropic API (optional)&lt;/li&gt; &#xA; &lt;li&gt;Local LLM support (optional, requires compatible GGUF model)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install Pyenv and Python 3.12 (if needed):&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Install Pyenv and python 3.12 if needed and then use it to create venv:&#xA;if ! command -v pyenv &amp;amp;&amp;gt; /dev/null; then&#xA;    sudo apt-get update&#xA;    sudo apt-get install -y build-essential libssl-dev zlib1g-dev libbz2-dev \&#xA;    libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev \&#xA;    xz-utils tk-dev libffi-dev liblzma-dev python3-openssl git&#xA;&#xA;    git clone https://github.com/pyenv/pyenv.git ~/.pyenv&#xA;    echo &#39;export PYENV_ROOT=&#34;$HOME/.pyenv&#34;&#39; &amp;gt;&amp;gt; ~/.zshrc&#xA;    echo &#39;export PATH=&#34;$PYENV_ROOT/bin:$PATH&#34;&#39; &amp;gt;&amp;gt; ~/.zshrc&#xA;    echo &#39;eval &#34;$(pyenv init --path)&#34;&#39; &amp;gt;&amp;gt; ~/.zshrc&#xA;    source ~/.zshrc&#xA;fi&#xA;cd ~/.pyenv &amp;amp;&amp;amp; git pull &amp;amp;&amp;amp; cd -&#xA;pyenv install 3.12&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Set up the project:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Use pyenv to create virtual environment:&#xA;git clone https://github.com/Dicklesworthstone/llm_aided_ocr    &#xA;cd llm_aided_ocr          &#xA;pyenv local 3.12&#xA;python -m venv venv&#xA;source venv/bin/activate&#xA;python -m pip install --upgrade pip&#xA;python -m pip install wheel&#xA;python -m pip install --upgrade setuptools wheel&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Install Tesseract OCR engine (if not already installed):&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;For Ubuntu: &lt;code&gt;sudo apt-get install tesseract-ocr&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;For macOS: &lt;code&gt;brew install tesseract&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;For Windows: Download and install from &lt;a href=&#34;https://github.com/UB-Mannheim/tesseract/wiki&#34;&gt;GitHub&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Set up your environment variables in a &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;USE_LOCAL_LLM=False&#xA;API_PROVIDER=OPENAI&#xA;OPENAI_API_KEY=your_openai_api_key&#xA;ANTHROPIC_API_KEY=your_anthropic_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Place your PDF file in the project directory.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Update the &lt;code&gt;input_pdf_file_path&lt;/code&gt; variable in the &lt;code&gt;main()&lt;/code&gt; function with your PDF filename.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run the script:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python llm_aided_ocr.py&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The script will generate several output files, including the final post-processed text.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;How It Works&lt;/h2&gt; &#xA;&lt;p&gt;The LLM-Aided OCR project employs a multi-step process to transform raw OCR output into high-quality, readable text:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;PDF Conversion&lt;/strong&gt;: Converts input PDF into images using &lt;code&gt;pdf2image&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;OCR&lt;/strong&gt;: Applies Tesseract OCR to extract text from images.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Text Chunking&lt;/strong&gt;: Splits the raw OCR output into manageable chunks for processing.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Error Correction&lt;/strong&gt;: Each chunk undergoes LLM-based processing to correct OCR errors and improve readability.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Markdown Formatting&lt;/strong&gt; (Optional): Reformats the corrected text into clean, consistent Markdown.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Quality Assessment&lt;/strong&gt;: An LLM-based evaluation compares the final output quality to the original OCR text.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Code Optimization&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Concurrent Processing&lt;/strong&gt;: When using API-based models, chunks are processed concurrently to improve speed.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Context Preservation&lt;/strong&gt;: Each chunk includes a small overlap with the previous chunk to maintain context.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Adaptive Token Management&lt;/strong&gt;: The system dynamically adjusts the number of tokens used for LLM requests based on input size and model constraints.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;The project uses a &lt;code&gt;.env&lt;/code&gt; file for configuration. Key settings include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;USE_LOCAL_LLM&lt;/code&gt;: Set to &lt;code&gt;True&lt;/code&gt; to use a local LLM, &lt;code&gt;False&lt;/code&gt; for API-based LLMs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;API_PROVIDER&lt;/code&gt;: Choose between &#34;OPENAI&#34; or &#34;CLAUDE&#34;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;: API keys for respective services.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;CLAUDE_MODEL_STRING&lt;/code&gt;, &lt;code&gt;OPENAI_COMPLETION_MODEL&lt;/code&gt;: Specify the model to use for each provider.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;LOCAL_LLM_CONTEXT_SIZE_IN_TOKENS&lt;/code&gt;: Set the context size for local LLMs.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Output Files&lt;/h2&gt; &#xA;&lt;p&gt;The script generates several output files:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;{base_name}__raw_ocr_output.txt&lt;/code&gt;: Raw OCR output from Tesseract.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;{base_name}_llm_corrected.md&lt;/code&gt;: Final LLM-corrected and formatted text.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Limitations and Future Improvements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The system&#39;s performance is heavily dependent on the quality of the LLM used.&lt;/li&gt; &#xA; &lt;li&gt;Processing very large documents can be time-consuming and may require significant computational resources.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions to this project are welcome! Please fork the repository and submit a pull request with your proposed changes.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the MIT License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>mbrg/power-pwn</title>
    <updated>2024-08-12T01:35:49Z</updated>
    <id>tag:github.com,2024-08-12:/mbrg/power-pwn</id>
    <link href="https://github.com/mbrg/power-pwn" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An offensive security toolset for Microsoft 365 focused on Microsoft Copilot, Copilot Studio and Power Platform&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt; &lt;sup&gt;Maintained by:&lt;/sup&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://www.zenity.io&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/mbrg/power-pwn/main/zenity_logo.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;/p&gt;&#xA; &lt;p&gt; Empower your business, not the adversaries. &lt;/p&gt; &#xA; &lt;p&gt;&lt;/p&gt; &#xA; &lt;hr&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;Power Pwn&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.toolswatch.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Black%20Hat-USA%202024-blue&#34; alt=&#34;Black Hat&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.blackhat.com/sector/2023/arsenal/schedule/index.html#entraid-guest-to-corp-data-dump-with-powerpwn-36105&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/SecTor-23-red&#34; alt=&#34;SecTor 23&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.toolswatch.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Black%20Hat-USA%202023-blue&#34; alt=&#34;Black Hat&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://forum.defcon.org/node/241932&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DEFCON-30-8A2BE2&#34; alt=&#34;DEFCON30&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/mbrg/power-pwn&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/mbrg/power-pwn?icon=github&amp;amp;style=social&#34; alt=&#34;stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/intent/follow?screen_name=mbrg0&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/mbrg0?icon=twitter&amp;amp;style=social&amp;amp;label=Follow&#34; alt=&#34;twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;mailto:michael.bargury@owasp.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/michael.bargury-owasp.org-red?logo=Gmail&#34; alt=&#34;email me&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Power Pwn is an offensive security toolset for Microsoft 365.&lt;/p&gt; &#xA;&lt;p&gt;Install with &lt;code&gt;pip install powerpwn&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Check out our &lt;a href=&#34;https://github.com/mbrg/power-pwn/wiki&#34;&gt;Wiki&lt;/a&gt; for docs, guides and related talks!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=LpdckZyBwvs&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/LpdckZyBwvs/0.jpg&#34; alt=&#34;BlackHat Arsenal USA 2023 - Power Pwn&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mbrg/power-pwn/main/wiki/powerpwn_asci_black.png&#34; alt=&#34;powerpwn&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>