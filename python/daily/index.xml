<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-08-29T01:33:38Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>THUDM/GLM-4</title>
    <updated>2024-08-29T01:33:38Z</updated>
    <id>tag:github.com,2024-08-29:/THUDM/GLM-4</id>
    <link href="https://github.com/THUDM/GLM-4" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GLM-4 series: Open Multilingual Multimodal Chat LMs | å¼€æºå¤šè¯­è¨€å¤šæ¨¡æ€å¯¹è¯æ¨¡å‹&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GLM-4&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; ğŸ“„&lt;a href=&#34;https://arxiv.org/pdf/2406.12793&#34; target=&#34;_blank&#34;&gt; Report &lt;/a&gt; â€¢ ğŸ¤— &lt;a href=&#34;https://huggingface.co/collections/THUDM/glm-4-665fcf188c414b03c2f7e3b7&#34; target=&#34;_blank&#34;&gt;HF Repo&lt;/a&gt; â€¢ ğŸ¤– &lt;a href=&#34;https://modelscope.cn/models/ZhipuAI/glm-4-9b-chat&#34; target=&#34;_blank&#34;&gt;ModelScope&lt;/a&gt; â€¢ ğŸŸ£ &lt;a href=&#34;https://wisemodel.cn/models/ZhipuAI/glm-4-9b-chat&#34; target=&#34;_blank&#34;&gt;WiseModel&lt;/a&gt; â€¢ ğŸ¦ &lt;a href=&#34;https://twitter.com/thukeg&#34; target=&#34;_blank&#34;&gt;Twitter&lt;/a&gt; â€¢ ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ &lt;a href=&#34;https://discord.gg/fK2dz4bg&#34; target=&#34;_blank&#34;&gt;Discord&lt;/a&gt; å’Œ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/GLM-4/main/resources/WECHAT.md&#34; target=&#34;_blank&#34;&gt;å¾®ä¿¡&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; ğŸ“åœ¨ &lt;a href=&#34;https://open.bigmodel.cn/?utm_campaign=open&amp;amp;_channel_track_key=OWTVNma9&#34;&gt;æ™ºè°±AIå¼€æ”¾å¹³å°&lt;/a&gt; ä½“éªŒå’Œä½¿ç”¨æ›´å¤§è§„æ¨¡çš„ GLM å•†ä¸šæ¨¡å‹ã€‚ &lt;/p&gt; &#xA;&lt;p&gt;Read this in &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/GLM-4/main/README_en.md&#34;&gt;English&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;é¡¹ç›®æ›´æ–°&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸ”¥ğŸ”¥ &lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2024/08/15&lt;/code&gt;: æˆ‘ä»¬å¼€æºå…·å¤‡é•¿æ–‡æœ¬è¾“å‡ºèƒ½åŠ›(å•è½®å¯¹è¯å¤§æ¨¡å‹è¾“å‡ºå¯è¶…è¿‡1ä¸‡token) çš„æ¨¡å‹ &lt;a href=&#34;https://huggingface.co/THUDM/LongWriter-glm4-9b&#34;&gt;longwriter-glm4-9b&lt;/a&gt; ä»¥åŠæ•°æ®é›† &lt;a href=&#34;https://huggingface.co/datasets/THUDM/LongWriter-6k&#34;&gt;LongWriter-6k&lt;/a&gt;, æ¬¢è¿åœ¨ &lt;a href=&#34;https://huggingface.co/spaces/THUDM/LongWriter&#34;&gt;Huggingface Space&lt;/a&gt; æˆ– &lt;a href=&#34;https://modelscope.cn/studios/ZhipuAI/LongWriter-glm4-9b-demo&#34;&gt;é­”æ­ç¤¾åŒºç©ºé—´&lt;/a&gt; åœ¨çº¿ä½“éªŒã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ &lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2024/08/12&lt;/code&gt;: GLM-4-9B-Chat æ¨¡å‹ä¾èµ–çš„&lt;code&gt;transformers&lt;/code&gt;ç‰ˆæœ¬å‡çº§åˆ° &lt;code&gt;4.44.0&lt;/code&gt;ï¼Œè¯·é‡æ–°æ‹‰å–é™¤æ¨¡å‹æƒé‡( &lt;code&gt;*.safetensor&lt;/code&gt; æ–‡ä»¶ å’Œ &lt;code&gt;tokenizer.model&lt;/code&gt;)å¤–çš„æ–‡ä»¶å¹¶å‚è€ƒ &lt;code&gt;basic_demo/requirements.txt&lt;/code&gt; ä¸¥æ ¼æ›´æ–°ä¾èµ–ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ &lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2024/07/24&lt;/code&gt;: æˆ‘ä»¬å‘å¸ƒäº†ä¸é•¿æ–‡æœ¬ç›¸å…³çš„æœ€æ–°æŠ€æœ¯è§£è¯»ï¼Œå…³æ³¨ &lt;a href=&#34;https://medium.com/@ChatGLM/glm-long-scaling-pre-trained-model-contexts-to-millions-caa3c48dea85&#34;&gt;è¿™é‡Œ&lt;/a&gt; æŸ¥çœ‹æˆ‘ä»¬åœ¨è®­ç»ƒ GLM-4-9B å¼€æºæ¨¡å‹ä¸­å…³äºé•¿æ–‡æœ¬æŠ€æœ¯çš„æŠ€æœ¯æŠ¥å‘Šã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ &lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2024/7/16&lt;/code&gt;: GLM-4-9B-Chat æ¨¡å‹ä¾èµ–çš„&lt;code&gt;transformers&lt;/code&gt;ç‰ˆæœ¬å‡çº§åˆ° &lt;code&gt;4.42.4&lt;/code&gt;, è¯·æ›´æ–°æ¨¡å‹é…ç½®æ–‡ä»¶å¹¶å‚è€ƒ &lt;code&gt;basic_demo/requirements.txt&lt;/code&gt; æ›´æ–°ä¾èµ–ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ &lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2024/7/9&lt;/code&gt;: GLM-4-9B-Chat æ¨¡å‹å·²é€‚é… &lt;a href=&#34;https://github.com/ollama/ollama&#34;&gt;Ollama&lt;/a&gt;,&lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;Llama.cpp&lt;/a&gt; ï¼Œæ‚¨å¯ä»¥åœ¨&lt;a href=&#34;https://github.com/ggerganov/llama.cpp/pull/8031&#34;&gt;PR&lt;/a&gt; æŸ¥çœ‹å…·ä½“çš„ç»†èŠ‚ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ &lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2024/7/1&lt;/code&gt;: æˆ‘ä»¬æ›´æ–°äº† GLM-4V-9B çš„å¾®è°ƒï¼Œæ‚¨éœ€è¦æ›´æ–°æˆ‘ä»¬çš„æ¨¡å‹ä»“åº“çš„è¿è¡Œæ–‡ä»¶å’Œé…ç½®æ–‡ä»¶ï¼Œ ä»¥æ”¯æŒè¿™ä¸ªåŠŸèƒ½ï¼Œæ›´å¤šå¾®è°ƒç»†èŠ‚ (ä¾‹å¦‚æ•°æ®é›†æ ¼å¼ï¼Œæ˜¾å­˜è¦æ±‚)ï¼Œè¯·å‰å¾€ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/GLM-4/main/finetune_demo&#34;&gt;æŸ¥çœ‹&lt;/a&gt;ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ &lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2024/6/28&lt;/code&gt;: æˆ‘ä»¬ä¸è‹±ç‰¹å°”æŠ€æœ¯å›¢é˜Ÿåˆä½œï¼Œæ”¹è¿›äº† GLM-4-9B-Chat çš„ ITREX å’Œ OpenVINO éƒ¨ç½²æ•™ç¨‹ã€‚æ‚¨å¯ä»¥ä½¿ç”¨è‹±ç‰¹å°” CPU/GPU è®¾å¤‡é«˜æ•ˆéƒ¨ç½² GLM-4-9B å¼€æºæ¨¡å‹ã€‚æ¬¢è¿è®¿é—® &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/GLM-4/main/intel_device_demo&#34;&gt;æŸ¥çœ‹&lt;/a&gt;ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ &lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2024/6/24&lt;/code&gt;: æˆ‘ä»¬æ›´æ–°äº†æ¨¡å‹ä»“åº“çš„è¿è¡Œæ–‡ä»¶å’Œé…ç½®æ–‡ä»¶ï¼Œæ”¯æŒ Flash Attention 2, è¯·æ›´æ–°æ¨¡å‹é…ç½®æ–‡ä»¶å¹¶å‚è€ƒ &lt;code&gt;basic_demo/trans_cli_demo.py&lt;/code&gt; ä¸­çš„ç¤ºä¾‹ä»£ç ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ &lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2024/6/19&lt;/code&gt;: æˆ‘ä»¬æ›´æ–°äº†æ¨¡å‹ä»“åº“çš„è¿è¡Œæ–‡ä»¶å’Œé…ç½®æ–‡ä»¶ï¼Œä¿®å¤äº†éƒ¨åˆ†å·²çŸ¥çš„æ¨¡å‹æ¨ç†çš„é—®é¢˜ï¼Œæ¬¢è¿å¤§å®¶å…‹éš†æœ€æ–°çš„æ¨¡å‹ä»“åº“ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ &lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2024/6/18&lt;/code&gt;: æˆ‘ä»¬å‘å¸ƒ &lt;a href=&#34;https://arxiv.org/pdf/2406.12793&#34;&gt;æŠ€æœ¯æŠ¥å‘Š&lt;/a&gt;, æ¬¢è¿æŸ¥çœ‹ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ &lt;strong&gt;News&lt;/strong&gt;: &lt;code&gt;2024/6/05&lt;/code&gt;: æˆ‘ä»¬å‘å¸ƒ GLM-4-9B ç³»åˆ—å¼€æºæ¨¡å‹&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;æ¨¡å‹ä»‹ç»&lt;/h2&gt; &#xA;&lt;p&gt;GLM-4-9B æ˜¯æ™ºè°± AI æ¨å‡ºçš„æœ€æ–°ä¸€ä»£é¢„è®­ç»ƒæ¨¡å‹ GLM-4 ç³»åˆ—ä¸­çš„å¼€æºç‰ˆæœ¬ã€‚ åœ¨è¯­ä¹‰ã€æ•°å­¦ã€æ¨ç†ã€ä»£ç å’ŒçŸ¥è¯†ç­‰å¤šæ–¹é¢çš„æ•°æ®é›†æµ‹è¯„ä¸­ï¼Œ &lt;strong&gt;GLM-4-9B&lt;/strong&gt; åŠå…¶äººç±»åå¥½å¯¹é½çš„ç‰ˆæœ¬ &lt;strong&gt;GLM-4-9B-Chat&lt;/strong&gt; å‡è¡¨ç°å‡ºè¶…è¶Š Llama-3-8B çš„å“è¶Šæ€§èƒ½ã€‚é™¤äº†èƒ½è¿›è¡Œå¤šè½®å¯¹è¯ï¼ŒGLM-4-9B-Chat è¿˜å…·å¤‡ç½‘é¡µæµè§ˆã€ä»£ç æ‰§è¡Œã€è‡ªå®šä¹‰å·¥å…·è°ƒç”¨ï¼ˆFunction Callï¼‰å’Œé•¿æ–‡æœ¬æ¨ç†ï¼ˆæ”¯æŒæœ€å¤§ 128K ä¸Šä¸‹æ–‡ï¼‰ç­‰é«˜çº§åŠŸèƒ½ã€‚æœ¬ä»£æ¨¡å‹å¢åŠ äº†å¤šè¯­è¨€æ”¯æŒï¼Œæ”¯æŒåŒ…æ‹¬æ—¥è¯­ï¼ŒéŸ©è¯­ï¼Œå¾·è¯­åœ¨å†…çš„ 26 ç§è¯­è¨€ã€‚æˆ‘ä»¬è¿˜æ¨å‡ºäº†æ”¯æŒ 1M ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆçº¦ 200 ä¸‡ä¸­æ–‡å­—ç¬¦ï¼‰çš„ &lt;strong&gt;GLM-4-9B-Chat-1M&lt;/strong&gt; æ¨¡å‹å’ŒåŸºäº GLM-4-9B çš„å¤šæ¨¡æ€æ¨¡å‹ GLM-4V-9Bã€‚&lt;strong&gt;GLM-4V-9B&lt;/strong&gt; å…·å¤‡ 1120 * 1120 é«˜åˆ†è¾¨ç‡ä¸‹çš„ä¸­è‹±åŒè¯­å¤šè½®å¯¹è¯èƒ½åŠ›ï¼Œåœ¨ä¸­è‹±æ–‡ç»¼åˆèƒ½åŠ›ã€æ„ŸçŸ¥æ¨ç†ã€æ–‡å­—è¯†åˆ«ã€å›¾è¡¨ç†è§£ç­‰å¤šæ–¹é¢å¤šæ¨¡æ€è¯„æµ‹ä¸­ï¼ŒGLM-4V-9B è¡¨ç°å‡ºè¶…è¶Š GPT-4-turbo-2024-04-09ã€Gemini 1.0 Proã€Qwen-VL-Max å’Œ Claude 3 Opus çš„å“è¶Šæ€§èƒ½ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;Model List&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Seq Length&lt;/th&gt; &#xA;   &lt;th&gt;Download&lt;/th&gt; &#xA;   &lt;th&gt;Online Demo&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GLM-4-9B&lt;/td&gt; &#xA;   &lt;td&gt;Base&lt;/td&gt; &#xA;   &lt;td&gt;8K&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/THUDM/glm-4-9b&#34;&gt;ğŸ¤— Huggingface&lt;/a&gt; &lt;a href=&#34;https://modelscope.cn/models/ZhipuAI/glm-4-9b&#34;&gt;ğŸ¤– ModelScope&lt;/a&gt; &lt;a href=&#34;https://wisemodel.cn/models/ZhipuAI/glm-4-9b&#34;&gt;ğŸŸ£ WiseModel&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GLM-4-9B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;128K&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/THUDM/glm-4-9b-chat&#34;&gt;ğŸ¤— Huggingface&lt;/a&gt; &lt;a href=&#34;https://modelscope.cn/models/ZhipuAI/glm-4-9b-chat&#34;&gt;ğŸ¤– ModelScope&lt;/a&gt; &lt;a href=&#34;https://wisemodel.cn/models/ZhipuAI/GLM-4-9B-Chat&#34;&gt;ğŸŸ£ WiseModel&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/studios/dash-infer/GLM-4-Chat-DashInfer-Demo/summary&#34;&gt;ğŸ¤– ModelScope CPU&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://modelscope.cn/studios/ZhipuAI/glm-4-9b-chat-vllm/summary&#34;&gt;ğŸ¤– ModelScope vLLM&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GLM-4-9B-Chat-1M&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;1M&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/THUDM/glm-4-9b-chat-1m&#34;&gt;ğŸ¤— Huggingface&lt;/a&gt; &lt;a href=&#34;https://modelscope.cn/models/ZhipuAI/glm-4-9b-chat-1m&#34;&gt;ğŸ¤– ModelScope&lt;/a&gt; &lt;a href=&#34;https://wisemodel.cn/models/ZhipuAI/GLM-4-9B-Chat-1M&#34;&gt;ğŸŸ£ WiseModel&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GLM-4V-9B&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;8K&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/THUDM/glm-4v-9b&#34;&gt;ğŸ¤— Huggingface&lt;/a&gt; &lt;a href=&#34;https://modelscope.cn/models/ZhipuAI/glm-4v-9b&#34;&gt;ğŸ¤– ModelScope&lt;/a&gt; &lt;a href=&#34;https://wisemodel.cn/models/ZhipuAI/GLM-4V-9B&#34;&gt;ğŸŸ£ WiseModel&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/studios/ZhipuAI/glm-4v-9b-Demo/summary&#34;&gt;ğŸ¤– ModelScope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;è¯„æµ‹ç»“æœ&lt;/h2&gt; &#xA;&lt;h3&gt;å¯¹è¯æ¨¡å‹å…¸å‹ä»»åŠ¡&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;AlignBench&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MT-Bench&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;IFEval&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MMLU&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;C-Eval&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;GSM8K&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MATH&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;HumanEval&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;NaturalCodeBench&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Llama-3-8B-Instruct&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6.40&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8.00&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;79.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;62.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;ChatGLM3-6B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5.18&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5.50&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;69.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;72.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;25.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;58.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;GLM-4-9B-Chat&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7.01&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8.35&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;69.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;72.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;75.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;79.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;71.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;åŸºåº§æ¨¡å‹å…¸å‹ä»»åŠ¡&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MMLU&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;C-Eval&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;GPQA&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;GSM8K&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MATH&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;HumanEval&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Llama-3-8B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;66.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Llama-3-8B-Instruct&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;68.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;79.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;62.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;ChatGLM3-6B-Base&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;69.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;72.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;25.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;58.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;GLM-4-9B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;74.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;77.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;84.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;70.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ç”±äº &lt;code&gt;GLM-4-9B&lt;/code&gt; åœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­åŠ å…¥äº†éƒ¨åˆ†æ•°å­¦ã€æ¨ç†ã€ä»£ç ç›¸å…³çš„ instruction æ•°æ®ï¼Œæ‰€ä»¥å°† Llama-3-8B-Instruct ä¹Ÿåˆ—å…¥æ¯”è¾ƒèŒƒå›´ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;é•¿æ–‡æœ¬&lt;/h3&gt; &#xA;&lt;p&gt;åœ¨ 1M çš„ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹è¿›è¡Œ&lt;a href=&#34;https://github.com/LargeWorldModel/LWM/raw/main/scripts/eval_needle.py&#34;&gt;å¤§æµ·æé’ˆå®éªŒ&lt;/a&gt;ï¼Œç»“æœå¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/THUDM/GLM-4/main/resources/eval_needle.jpeg&#34; alt=&#34;needle&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;åœ¨ LongBench-Chat ä¸Šå¯¹é•¿æ–‡æœ¬èƒ½åŠ›è¿›è¡Œäº†è¿›ä¸€æ­¥è¯„æµ‹ï¼Œç»“æœå¦‚ä¸‹:&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/THUDM/GLM-4/main/resources/longbench.png&#34; alt=&#34;æè¿°æ–‡å­—&#34; style=&#34;display: block; margin: auto; width: 65%;&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;å¤šè¯­è¨€èƒ½åŠ›&lt;/h3&gt; &#xA;&lt;p&gt;åœ¨å…­ä¸ªå¤šè¯­è¨€æ•°æ®é›†ä¸Šå¯¹ GLM-4-9B-Chat å’Œ Llama-3-8B-Instruct è¿›è¡Œäº†æµ‹è¯•ï¼Œæµ‹è¯•ç»“æœåŠæ•°æ®é›†å¯¹åº”é€‰å–è¯­è¨€å¦‚ä¸‹è¡¨&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Dataset&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Llama-3-8B-Instruct&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;GLM-4-9B-Chat&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Languages&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;M-MMLU&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;56.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;all&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;FLORES&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;25.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ru, es, de, fr, it, pt, pl, ja, nl, ar, tr, cs, vi, fa, hu, el, ro, sv, uk, fi, ko, da, bg, no&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;MGSM&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;54.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;65.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;zh, en, bn, de, es, fr, ja, ru, sw, te, th&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;XWinograd&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;73.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;zh, en, fr, jp, ru, pt&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;XStoryCloze&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;84.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;90.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;zh, en, ar, es, eu, hi, id, my, ru, sw, te&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;XCOPA&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;73.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;80.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;zh, et, ht, id, it, qu, sw, ta, th, tr, vi&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;å·¥å…·è°ƒç”¨èƒ½åŠ›&lt;/h3&gt; &#xA;&lt;p&gt;æˆ‘ä»¬åœ¨ &lt;a href=&#34;https://github.com/ShishirPatil/gorilla/tree/main/berkeley-function-call-leaderboard&#34;&gt;Berkeley Function Calling Leaderboard&lt;/a&gt; ä¸Šè¿›è¡Œäº†æµ‹è¯•å¹¶å¾—åˆ°äº†ä»¥ä¸‹ç»“æœï¼š&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Overall Acc.&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;AST Summary&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Exec Summary&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Relevance&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Llama-3-8B-Instruct&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;58.88&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;59.25&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;70.01&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.83&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;gpt-4-turbo-2024-04-09&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;81.24&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;82.14&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;78.61&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;88.75&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;ChatGLM3-6B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;57.88&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;62.18&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;69.78&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5.42&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;GLM-4-9B-Chat&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;81.00&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;80.26&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;84.40&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;87.92&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;å¤šæ¨¡æ€èƒ½åŠ›&lt;/h3&gt; &#xA;&lt;p&gt;GLM-4V-9B æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼Œå…·å¤‡è§†è§‰ç†è§£èƒ½åŠ›ï¼Œå…¶ç›¸å…³ç»å…¸ä»»åŠ¡çš„è¯„æµ‹ç»“æœå¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;MMBench-EN-Test&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;MMBench-CN-Test&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;SEEDBench_IMG&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;MMStar&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;MMMU&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;MME&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;HallusionBench&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;AI2D&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;OCRBench&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;gpt-4o-2024-05-13&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;83.4&lt;/td&gt; &#xA;   &lt;td&gt;82.1&lt;/td&gt; &#xA;   &lt;td&gt;77.1&lt;/td&gt; &#xA;   &lt;td&gt;63.9&lt;/td&gt; &#xA;   &lt;td&gt;69.2&lt;/td&gt; &#xA;   &lt;td&gt;2310.3&lt;/td&gt; &#xA;   &lt;td&gt;55.0&lt;/td&gt; &#xA;   &lt;td&gt;84.6&lt;/td&gt; &#xA;   &lt;td&gt;736&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;gpt-4-turbo-2024-04-09&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;81.0&lt;/td&gt; &#xA;   &lt;td&gt;80.2&lt;/td&gt; &#xA;   &lt;td&gt;73.0&lt;/td&gt; &#xA;   &lt;td&gt;56.0&lt;/td&gt; &#xA;   &lt;td&gt;61.7&lt;/td&gt; &#xA;   &lt;td&gt;2070.2&lt;/td&gt; &#xA;   &lt;td&gt;43.9&lt;/td&gt; &#xA;   &lt;td&gt;78.6&lt;/td&gt; &#xA;   &lt;td&gt;656&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;gpt-4-1106-preview&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;77.0&lt;/td&gt; &#xA;   &lt;td&gt;74.4&lt;/td&gt; &#xA;   &lt;td&gt;72.3&lt;/td&gt; &#xA;   &lt;td&gt;49.7&lt;/td&gt; &#xA;   &lt;td&gt;53.8&lt;/td&gt; &#xA;   &lt;td&gt;1771.5&lt;/td&gt; &#xA;   &lt;td&gt;46.5&lt;/td&gt; &#xA;   &lt;td&gt;75.9&lt;/td&gt; &#xA;   &lt;td&gt;516&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;InternVL-Chat-V1.5&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;82.3&lt;/td&gt; &#xA;   &lt;td&gt;80.7&lt;/td&gt; &#xA;   &lt;td&gt;75.2&lt;/td&gt; &#xA;   &lt;td&gt;57.1&lt;/td&gt; &#xA;   &lt;td&gt;46.8&lt;/td&gt; &#xA;   &lt;td&gt;2189.6&lt;/td&gt; &#xA;   &lt;td&gt;47.4&lt;/td&gt; &#xA;   &lt;td&gt;80.6&lt;/td&gt; &#xA;   &lt;td&gt;720&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;LLaVA-Next-Yi-34B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;81.1&lt;/td&gt; &#xA;   &lt;td&gt;79.0&lt;/td&gt; &#xA;   &lt;td&gt;75.7&lt;/td&gt; &#xA;   &lt;td&gt;51.6&lt;/td&gt; &#xA;   &lt;td&gt;48.8&lt;/td&gt; &#xA;   &lt;td&gt;2050.2&lt;/td&gt; &#xA;   &lt;td&gt;34.8&lt;/td&gt; &#xA;   &lt;td&gt;78.9&lt;/td&gt; &#xA;   &lt;td&gt;574&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Step-1V&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;80.7&lt;/td&gt; &#xA;   &lt;td&gt;79.9&lt;/td&gt; &#xA;   &lt;td&gt;70.3&lt;/td&gt; &#xA;   &lt;td&gt;50.0&lt;/td&gt; &#xA;   &lt;td&gt;49.9&lt;/td&gt; &#xA;   &lt;td&gt;2206.4&lt;/td&gt; &#xA;   &lt;td&gt;48.4&lt;/td&gt; &#xA;   &lt;td&gt;79.2&lt;/td&gt; &#xA;   &lt;td&gt;625&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;MiniCPM-Llama3-V2.5&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;77.6&lt;/td&gt; &#xA;   &lt;td&gt;73.8&lt;/td&gt; &#xA;   &lt;td&gt;72.3&lt;/td&gt; &#xA;   &lt;td&gt;51.8&lt;/td&gt; &#xA;   &lt;td&gt;45.8&lt;/td&gt; &#xA;   &lt;td&gt;2024.6&lt;/td&gt; &#xA;   &lt;td&gt;42.4&lt;/td&gt; &#xA;   &lt;td&gt;78.4&lt;/td&gt; &#xA;   &lt;td&gt;725&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen-VL-Max&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;77.6&lt;/td&gt; &#xA;   &lt;td&gt;75.7&lt;/td&gt; &#xA;   &lt;td&gt;72.7&lt;/td&gt; &#xA;   &lt;td&gt;49.5&lt;/td&gt; &#xA;   &lt;td&gt;52.0&lt;/td&gt; &#xA;   &lt;td&gt;2281.7&lt;/td&gt; &#xA;   &lt;td&gt;41.2&lt;/td&gt; &#xA;   &lt;td&gt;75.7&lt;/td&gt; &#xA;   &lt;td&gt;684&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Gemini 1.0 Pro&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;73.6&lt;/td&gt; &#xA;   &lt;td&gt;74.3&lt;/td&gt; &#xA;   &lt;td&gt;70.7&lt;/td&gt; &#xA;   &lt;td&gt;38.6&lt;/td&gt; &#xA;   &lt;td&gt;49.0&lt;/td&gt; &#xA;   &lt;td&gt;2148.9&lt;/td&gt; &#xA;   &lt;td&gt;45.7&lt;/td&gt; &#xA;   &lt;td&gt;72.9&lt;/td&gt; &#xA;   &lt;td&gt;680&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Claude 3 Opus&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;63.3&lt;/td&gt; &#xA;   &lt;td&gt;59.2&lt;/td&gt; &#xA;   &lt;td&gt;64.0&lt;/td&gt; &#xA;   &lt;td&gt;45.7&lt;/td&gt; &#xA;   &lt;td&gt;54.9&lt;/td&gt; &#xA;   &lt;td&gt;1586.8&lt;/td&gt; &#xA;   &lt;td&gt;37.8&lt;/td&gt; &#xA;   &lt;td&gt;70.6&lt;/td&gt; &#xA;   &lt;td&gt;694&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;GLM-4V-9B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;81.1&lt;/td&gt; &#xA;   &lt;td&gt;79.4&lt;/td&gt; &#xA;   &lt;td&gt;76.8&lt;/td&gt; &#xA;   &lt;td&gt;58.7&lt;/td&gt; &#xA;   &lt;td&gt;47.2&lt;/td&gt; &#xA;   &lt;td&gt;2163.8&lt;/td&gt; &#xA;   &lt;td&gt;46.6&lt;/td&gt; &#xA;   &lt;td&gt;81.1&lt;/td&gt; &#xA;   &lt;td&gt;786&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;å¿«é€Ÿè°ƒç”¨&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;ç¡¬ä»¶é…ç½®å’Œç³»ç»Ÿè¦æ±‚ï¼Œè¯·æŸ¥çœ‹&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/GLM-4/main/basic_demo/README.md&#34;&gt;è¿™é‡Œ&lt;/a&gt;ã€‚&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•å¿«é€Ÿè°ƒç”¨ GLM-4-9B-Chat è¯­è¨€æ¨¡å‹&lt;/h3&gt; &#xA;&lt;p&gt;ä½¿ç”¨ transformers åç«¯è¿›è¡Œæ¨ç†:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from transformers import AutoModelForCausalLM, AutoTokenizer&#xA;&#xA;device = &#34;cuda&#34;&#xA;&#xA;tokenizer = AutoTokenizer.from_pretrained(&#34;THUDM/glm-4-9b-chat&#34;, trust_remote_code=True)&#xA;&#xA;query = &#34;ä½ å¥½&#34;&#xA;&#xA;inputs = tokenizer.apply_chat_template([{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: query}],&#xA;                                       add_generation_prompt=True,&#xA;                                       tokenize=True,&#xA;                                       return_tensors=&#34;pt&#34;,&#xA;                                       return_dict=True&#xA;                                       )&#xA;&#xA;inputs = inputs.to(device)&#xA;model = AutoModelForCausalLM.from_pretrained(&#xA;    &#34;THUDM/glm-4-9b-chat&#34;,&#xA;    torch_dtype=torch.bfloat16,&#xA;    low_cpu_mem_usage=True,&#xA;    trust_remote_code=True&#xA;).to(device).eval()&#xA;&#xA;gen_kwargs = {&#34;max_length&#34;: 2500, &#34;do_sample&#34;: True, &#34;top_k&#34;: 1}&#xA;with torch.no_grad():&#xA;    outputs = model.generate(**inputs, **gen_kwargs)&#xA;    outputs = outputs[:, inputs[&#39;input_ids&#39;].shape[1]:]&#xA;    print(tokenizer.decode(outputs[0], skip_special_tokens=True))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ä½¿ç”¨ vLLM åç«¯è¿›è¡Œæ¨ç†:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoTokenizer&#xA;from vllm import LLM, SamplingParams&#xA;&#xA;# GLM-4-9B-Chat-1M&#xA;# max_model_len, tp_size = 1048576, 4&#xA;# å¦‚æœé‡è§ OOM ç°è±¡ï¼Œå»ºè®®å‡å°‘max_model_lenï¼Œæˆ–è€…å¢åŠ tp_size&#xA;max_model_len, tp_size = 131072, 1&#xA;model_name = &#34;THUDM/glm-4-9b-chat&#34;&#xA;prompt = [{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;ä½ å¥½&#34;}]&#xA;&#xA;tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)&#xA;llm = LLM(&#xA;    model=model_name,&#xA;    tensor_parallel_size=tp_size,&#xA;    max_model_len=max_model_len,&#xA;    trust_remote_code=True,&#xA;    enforce_eager=True,&#xA;    # GLM-4-9B-Chat-1M å¦‚æœé‡è§ OOM ç°è±¡ï¼Œå»ºè®®å¼€å¯ä¸‹è¿°å‚æ•°&#xA;    # enable_chunked_prefill=True,&#xA;    # max_num_batched_tokens=8192&#xA;)&#xA;stop_token_ids = [151329, 151336, 151338]&#xA;sampling_params = SamplingParams(temperature=0.95, max_tokens=1024, stop_token_ids=stop_token_ids)&#xA;&#xA;inputs = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)&#xA;outputs = llm.generate(prompts=inputs, sampling_params=sampling_params)&#xA;&#xA;print(outputs[0].outputs[0].text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•å¿«é€Ÿè°ƒç”¨ GLM-4V-9B å¤šæ¨¡æ€æ¨¡å‹&lt;/h3&gt; &#xA;&lt;p&gt;ä½¿ç”¨ transformers åç«¯è¿›è¡Œæ¨ç†:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from PIL import Image&#xA;from transformers import AutoModelForCausalLM, AutoTokenizer&#xA;&#xA;device = &#34;cuda&#34;&#xA;&#xA;tokenizer = AutoTokenizer.from_pretrained(&#34;THUDM/glm-4v-9b&#34;, trust_remote_code=True)&#xA;&#xA;query = &#39;æè¿°è¿™å¼ å›¾ç‰‡&#39;&#xA;image = Image.open(&#34;your image&#34;).convert(&#39;RGB&#39;)&#xA;inputs = tokenizer.apply_chat_template([{&#34;role&#34;: &#34;user&#34;, &#34;image&#34;: image, &#34;content&#34;: query}],&#xA;                                       add_generation_prompt=True, tokenize=True, return_tensors=&#34;pt&#34;,&#xA;                                       return_dict=True)  # chat mode&#xA;&#xA;inputs = inputs.to(device)&#xA;model = AutoModelForCausalLM.from_pretrained(&#xA;    &#34;THUDM/glm-4v-9b&#34;,&#xA;    torch_dtype=torch.bfloat16,&#xA;    low_cpu_mem_usage=True,&#xA;    trust_remote_code=True&#xA;).to(device).eval()&#xA;&#xA;gen_kwargs = {&#34;max_length&#34;: 2500, &#34;do_sample&#34;: True, &#34;top_k&#34;: 1}&#xA;with torch.no_grad():&#xA;    outputs = model.generate(**inputs, **gen_kwargs)&#xA;    outputs = outputs[:, inputs[&#39;input_ids&#39;].shape[1]:]&#xA;    print(tokenizer.decode(outputs[0]))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æ³¨æ„: GLM-4V-9B æš‚ä¸æ”¯æŒä½¿ç”¨ vLLM æ–¹å¼è°ƒç”¨ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;å®Œæ•´é¡¹ç›®åˆ—è¡¨&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœä½ æƒ³æ›´è¿›ä¸€æ­¥äº†è§£ GLM-4-9B ç³»åˆ—å¼€æºæ¨¡å‹ï¼Œæœ¬å¼€æºä»“åº“é€šè¿‡ä»¥ä¸‹å†…å®¹ä¸ºå¼€å‘è€…æä¾›åŸºç¡€çš„ GLM-4-9Bçš„ä½¿ç”¨å’Œå¼€å‘ä»£ç &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/GLM-4/main/basic_demo/README.md&#34;&gt;basic_demo&lt;/a&gt;: åœ¨è¿™é‡ŒåŒ…å«äº†&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ä½¿ç”¨ transformers å’Œ vLLM åç«¯çš„äº¤äº’ä»£ç &lt;/li&gt; &#xA;   &lt;li&gt;OpenAI API åç«¯äº¤äº’ä»£ç &lt;/li&gt; &#xA;   &lt;li&gt;Batch æ¨ç†ä»£ç &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/GLM-4/main/composite_demo/README.md&#34;&gt;composite_demo&lt;/a&gt;: åœ¨è¿™é‡ŒåŒ…å«äº†&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;GLM-4-9B-Chat ä»¥åŠ GLM-4V-9B å¼€æºæ¨¡å‹çš„å®Œæ•´åŠŸèƒ½æ¼”ç¤ºä»£ç ï¼ŒåŒ…å«äº† All Tools èƒ½åŠ›ã€é•¿æ–‡æ¡£è§£è¯»å’Œå¤šæ¨¡æ€èƒ½åŠ›çš„å±•ç¤ºã€‚&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/GLM-4/main/finetune_demo/README.md&#34;&gt;fintune_demo&lt;/a&gt;: åœ¨è¿™é‡ŒåŒ…å«äº†&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;PEFT (LORA, P-Tuning) å¾®è°ƒä»£ç &lt;/li&gt; &#xA;   &lt;li&gt;SFT å¾®è°ƒä»£ç &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;å‹æƒ…é“¾æ¥&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hiyouga/LLaMA-Factory&#34;&gt;LLaMA-Factory&lt;/a&gt;: é«˜æ•ˆå¼€æºå¾®è°ƒæ¡†æ¶ï¼Œå·²æ”¯æŒ GLM-4-9B-Chat è¯­è¨€æ¨¡å‹å¾®è°ƒã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/swift&#34;&gt;SWIFT&lt;/a&gt;: é­”æ­ç¤¾åŒºçš„å¤§æ¨¡å‹/å¤šæ¨¡æ€å¤§æ¨¡å‹è®­ç»ƒæ¡†æ¶ï¼Œå·²æ”¯æŒ GLM-4-9B-Chat / GLM-4V-9B æ¨¡å‹å¾®è°ƒã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/xorbitsai/inference&#34;&gt;Xorbits Inference&lt;/a&gt;: æ€§èƒ½å¼ºå¤§ä¸”åŠŸèƒ½å…¨é¢çš„åˆ†å¸ƒå¼æ¨ç†æ¡†æ¶ï¼Œè½»æ¾ä¸€é”®éƒ¨ç½²ä½ è‡ªå·±çš„æ¨¡å‹æˆ–å†…ç½®çš„å‰æ²¿å¼€æºæ¨¡å‹ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/chatchat-space/Langchain-Chatchat&#34;&gt;LangChain-ChatChat&lt;/a&gt;: åŸºäº Langchain ä¸ ChatGLM ç­‰è¯­è¨€æ¨¡å‹çš„ RAG ä¸ Agent åº”ç”¨&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/datawhalechina/self-llm/tree/master/models/GLM-4&#34;&gt;self-llm&lt;/a&gt;: Datawhale å›¢é˜Ÿçš„æä¾›çš„ GLM-4-9B ç³»åˆ—æ¨¡å‹ä½¿ç”¨æ•™ç¨‹ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/li-plus/chatglm.cpp&#34;&gt;chatglm.cpp&lt;/a&gt;: ç±»ä¼¼ llama.cpp çš„é‡åŒ–åŠ é€Ÿæ¨ç†æ–¹æ¡ˆï¼Œå®ç°ç¬”è®°æœ¬ä¸Šå®æ—¶å¯¹è¯&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;åè®®&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;GLM-4 æ¨¡å‹çš„æƒé‡çš„ä½¿ç”¨åˆ™éœ€è¦éµå¾ª &lt;a href=&#34;https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE&#34;&gt;æ¨¡å‹åè®®&lt;/a&gt;ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;æœ¬å¼€æºä»“åº“çš„ä»£ç åˆ™éµå¾ª &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/GLM-4/main/LICENSE&#34;&gt;Apache 2.0&lt;/a&gt; åè®®ã€‚&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;è¯·æ‚¨ä¸¥æ ¼éµå¾ªå¼€æºåè®®ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;å¼•ç”¨&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œæœ‰å¸®åŠ©çš„è¯ï¼Œè¯·è€ƒè™‘å¼•ç”¨ä¸‹åˆ—è®ºæ–‡ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{glm2024chatglm,&#xA;      title={ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools}, &#xA;      author={Team GLM and Aohan Zeng and Bin Xu and Bowen Wang and Chenhui Zhang and Da Yin and Diego Rojas and Guanyu Feng and Hanlin Zhao and Hanyu Lai and Hao Yu and Hongning Wang and Jiadai Sun and Jiajie Zhang and Jiale Cheng and Jiayi Gui and Jie Tang and Jing Zhang and Juanzi Li and Lei Zhao and Lindong Wu and Lucen Zhong and Mingdao Liu and Minlie Huang and Peng Zhang and Qinkai Zheng and Rui Lu and Shuaiqi Duan and Shudan Zhang and Shulin Cao and Shuxun Yang and Weng Lam Tam and Wenyi Zhao and Xiao Liu and Xiao Xia and Xiaohan Zhang and Xiaotao Gu and Xin Lv and Xinghan Liu and Xinyi Liu and Xinyue Yang and Xixuan Song and Xunkai Zhang and Yifan An and Yifan Xu and Yilin Niu and Yuantao Yang and Yueyan Li and Yushi Bai and Yuxiao Dong and Zehan Qi and Zhaoyu Wang and Zhen Yang and Zhengxiao Du and Zhenyu Hou and Zihan Wang},&#xA;      year={2024},&#xA;      eprint={2406.12793},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={id=&#39;cs.CL&#39; full_name=&#39;Computation and Language&#39; is_active=True alt_name=&#39;cmp-lg&#39; in_archive=&#39;cs&#39; is_general=False description=&#39;Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.&#39;}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{wang2023cogvlm,&#xA;      title={CogVLM: Visual Expert for Pretrained Language Models}, &#xA;      author={Weihan Wang and Qingsong Lv and Wenmeng Yu and Wenyi Hong and Ji Qi and Yan Wang and Junhui Ji and Zhuoyi Yang and Lei Zhao and Xixuan Song and Jiazheng Xu and Bin Xu and Juanzi Li and Yuxiao Dong and Ming Ding and Jie Tang},&#xA;      year={2023},&#xA;      eprint={2311.03079},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>