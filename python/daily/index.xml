<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-08-07T01:33:11Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>bghira/SimpleTuner</title>
    <updated>2024-08-07T01:33:11Z</updated>
    <id>tag:github.com,2024-08-07:/bghira/SimpleTuner</id>
    <link href="https://github.com/bghira/SimpleTuner" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A general fine-tuning kit geared toward Stable Diffusion 2.1, Stable Diffusion 3, DeepFloyd, and SDXL.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SimpleTuner üíπ&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Warning&lt;/strong&gt;: The scripts in this repository have the potential to damage your training data. Always maintain backups before proceeding.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;strong&gt;SimpleTuner&lt;/strong&gt; is a repository dedicated to a set of experimental scripts designed for training optimization. The project is geared towards simplicity, with a focus on making the code easy to read and understand. This codebase serves as a shared academic exercise, and contributions are welcome.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#design-philosophy&#34;&gt;Design Philosophy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#tutorial&#34;&gt;Tutorial&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#features&#34;&gt;Features&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#flux1&#34;&gt;Flux&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#pixart-sigma&#34;&gt;PixArt Sigma&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#stable-diffusion-20--21&#34;&gt;Stable Diffusion 2.0/2.1&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#stable-diffusion-3&#34;&gt;Stable Diffusion 3.0&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#kwai-kolors&#34;&gt;Kwai Kolors&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#hardware-requirements&#34;&gt;Hardware Requirements&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#flux1-dev-schnell&#34;&gt;Flux&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#sdxl-1024px&#34;&gt;SDXL&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#stable-diffusion-2x-768px&#34;&gt;Stable Diffusion (Legacy)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#scripts&#34;&gt;Scripts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#toolkit&#34;&gt;Toolkit&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#setup&#34;&gt;Setup&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#troubleshooting&#34;&gt;Troubleshooting&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Design Philosophy&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Simplicity&lt;/strong&gt;: Aiming to have good default settings for most use cases, so less tinkering is required.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Versatility&lt;/strong&gt;: Designed to handle a wide range of image quantities - from small datasets to extensive collections.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Cutting-Edge Features&lt;/strong&gt;: Only incorporates features that have proven efficacy, avoiding the addition of untested options.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Tutorial&lt;/h2&gt; &#xA;&lt;p&gt;Please fully explore this README before embarking on &lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/TUTORIAL.md&#34;&gt;the tutorial&lt;/a&gt;, as it contains vital information that you might need to know first.&lt;/p&gt; &#xA;&lt;p&gt;For a quick start without reading the full documentation, you can use the &lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/documentation/QUICKSTART.md&#34;&gt;Quick Start&lt;/a&gt; guide.&lt;/p&gt; &#xA;&lt;p&gt;For memory-constrained systems, see the &lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/documentation/DEEPSPEED.md&#34;&gt;DeepSpeed document&lt;/a&gt; which explains how to use ü§óAccelerate to configure Microsoft&#39;s DeepSpeed for optimiser state offload.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Multi-GPU training&lt;/li&gt; &#xA; &lt;li&gt;Image and caption features (embeds) are cached to the hard drive in advance, so that training runs faster and with less memory consumption&lt;/li&gt; &#xA; &lt;li&gt;Aspect bucketing: support for a variety of image sizes and aspect ratios, enabling widescreen and portrait training.&lt;/li&gt; &#xA; &lt;li&gt;Refiner LoRA or full u-net training for SDXL&lt;/li&gt; &#xA; &lt;li&gt;Most models are trainable on a 24G GPU, or even down to 16G at lower base resolutions. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;LoRA training for PixArt, SDXL, SD3, and SD 2.x that uses less than 16G VRAM&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;DeepSpeed integration allowing for &lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/documentation/DEEPSPEED.md&#34;&gt;training SDXL&#39;s full u-net on 12G of VRAM&lt;/a&gt;, albeit very slowly.&lt;/li&gt; &#xA; &lt;li&gt;Quantised LoRA training, using low-precision base model or text encoder weights to reduce VRAM consumption while still allowing DreamBooth.&lt;/li&gt; &#xA; &lt;li&gt;Optional EMA (Exponential moving average) weight network to counteract model overfitting and improve training stability. &lt;strong&gt;Note:&lt;/strong&gt; This does not apply to LoRA.&lt;/li&gt; &#xA; &lt;li&gt;Train directly from an S3-compatible storage provider, eliminating the requirement for expensive local storage. (Tested with Cloudflare R2 and Wasabi S3)&lt;/li&gt; &#xA; &lt;li&gt;For only SDXL and SD 1.x/2.x, full &lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/documentation/CONTROLNET.md&#34;&gt;ControlNet model training&lt;/a&gt; (not ControlLoRA or ControlLite)&lt;/li&gt; &#xA; &lt;li&gt;Training &lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/documentation/MIXTURE_OF_EXPERTS.md&#34;&gt;Mixture of Experts&lt;/a&gt; for lightweight, high-quality diffusion models&lt;/li&gt; &#xA; &lt;li&gt;Webhook support for updating eg. Discord channels with your training progress, validations, and errors&lt;/li&gt; &#xA; &lt;li&gt;Integration with the &lt;a href=&#34;https://huggingface.co&#34;&gt;Hugging Face Hub&lt;/a&gt; for seamless model upload and nice automatically-generated model cards.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Flux.1&lt;/h3&gt; &#xA;&lt;p&gt;Preliminary training support for Flux.1 is included:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Low loss training using SD3 style loss calculations&lt;/li&gt; &#xA; &lt;li&gt;LoRA or full tuning via DeepSpeed ZeRO&lt;/li&gt; &#xA; &lt;li&gt;ControlNet training is not yet supported&lt;/li&gt; &#xA; &lt;li&gt;Train either Schnell or Dev models&lt;/li&gt; &#xA; &lt;li&gt;Quantise the base model using &lt;code&gt;--base_model_precision&lt;/code&gt; to &lt;code&gt;int8-quanto&lt;/code&gt; or &lt;code&gt;fp8-quanto&lt;/code&gt; for major memory savings&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/#flux1-dev-schnell&#34;&gt;hardware requirements&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;PixArt Sigma&lt;/h3&gt; &#xA;&lt;p&gt;SimpleTuner has extensive training integration with PixArt Sigma - both the 600M &amp;amp; 900M models load without any fuss.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Text encoder training is not supported, as T5 is enormous.&lt;/li&gt; &#xA; &lt;li&gt;LoRA and full tuning both work as expected&lt;/li&gt; &#xA; &lt;li&gt;ControlNet training is not yet supported&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/ptx0/pixart-900m-1024-ft-v0.7-stage1&#34;&gt;Two-stage PixArt&lt;/a&gt; training support (see: &lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/documentation/MIXTURE_OF_EXPERTS.md&#34;&gt;MIXTURE_OF_EXPERTS&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/documentation/quickstart/SIGMA.md&#34;&gt;PixArt Quickstart&lt;/a&gt; guide to start training.&lt;/p&gt; &#xA;&lt;h3&gt;Stable Diffusion 2.0 &amp;amp; 2.1&lt;/h3&gt; &#xA;&lt;p&gt;Stable Diffusion 2.1 is known for difficulty during fine-tuning, but this doesn&#39;t have to be the case. Related features in SimpleTuner include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Training only the text encoder&#39;s later layers&lt;/li&gt; &#xA; &lt;li&gt;Enforced zero SNR on the terminal timestep instead of offset noise for clearer images.&lt;/li&gt; &#xA; &lt;li&gt;The use of EMA (exponential moving average) during training to ensure we do not &#34;fry&#34; the model.&lt;/li&gt; &#xA; &lt;li&gt;The ability to train on multiple datasets with different base resolutions in each, eg. 512px and 768px images simultaneously&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Stable Diffusion 3&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;LoRA and full finetuning are supported as usual.&lt;/li&gt; &#xA; &lt;li&gt;ControlNet is not yet implemented.&lt;/li&gt; &#xA; &lt;li&gt;Certain features such as segmented timestep selection and Compel long prompt weighting are not yet supported.&lt;/li&gt; &#xA; &lt;li&gt;Parameters have been optimised to get the best results, validated through from-scratch training of SD3 models&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/documentation/quickstart/SD3.md&#34;&gt;Stable Diffusion 3 Quickstart&lt;/a&gt; to get going.&lt;/p&gt; &#xA;&lt;h3&gt;Kwai Kolors&lt;/h3&gt; &#xA;&lt;p&gt;An SDXL-based model with ChatGLM (General Language Model) 6B as its text encoder, &lt;strong&gt;doubling&lt;/strong&gt; the hidden dimension size and substantially increasing the level of local detail included in the prompt embeds.&lt;/p&gt; &#xA;&lt;p&gt;Kolors support is almost as deep as SDXL, minus ControlNet training support.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Hardware Requirements&lt;/h2&gt; &#xA;&lt;p&gt;EMA (exponential moving average) weights are a memory-heavy affair, but provide fantastic results at the end of training. Options like &lt;code&gt;--ema_cpu_only&lt;/code&gt; can improve this situation by loading EMA weights onto the CPU and then keeping them there.&lt;/p&gt; &#xA;&lt;p&gt;Without EMA, more care must be taken not to drastically change the model leading to &#34;catastrophic forgetting&#34; through the use of regularisation data.&lt;/p&gt; &#xA;&lt;h3&gt;GPU vendors&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;NVIDIA - pretty much anything 3090 and up is a safe bet. YMMV.&lt;/li&gt; &#xA; &lt;li&gt;AMD - SDXL LoRA and UNet are verified working on a 7900 XTX 24GB. Lacking &lt;code&gt;xformers&lt;/code&gt;, it will likely use more memory than Nvidia equivalents&lt;/li&gt; &#xA; &lt;li&gt;Apple - LoRA and full u-net tuning are tested to work on an M3 Max with 128G memory, taking about &lt;strong&gt;12G&lt;/strong&gt; of &#34;Wired&#34; memory and &lt;strong&gt;4G&lt;/strong&gt; of system memory for SDXL. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;You likely need a 24G or greater machine for machine learning with M-series hardware due to the lack of memory-efficient attention.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Flux.1 [dev, schnell]&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A100-40G (LoRA, rank-16 or lower)&lt;/li&gt; &#xA; &lt;li&gt;A100-80G (LoRA, up to rank-256)&lt;/li&gt; &#xA; &lt;li&gt;3x A100-80G (Full tuning, DeepSpeed ZeRO 1)&lt;/li&gt; &#xA; &lt;li&gt;1x A100-80G (Full tuning, DeepSpeed ZeRO 3)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Flux prefers being trained with multiple GPUs.&lt;/p&gt; &#xA;&lt;h3&gt;SDXL, 1024px&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A100-80G (EMA, large batches, LoRA @ insane batch sizes)&lt;/li&gt; &#xA; &lt;li&gt;A6000-48G (EMA@768px, no EMA@1024px, LoRA @ high batch sizes)&lt;/li&gt; &#xA; &lt;li&gt;A100-40G (no EMA@1024px, no EMA@768px, EMA@512px, LoRA @ high batch sizes)&lt;/li&gt; &#xA; &lt;li&gt;4090-24G (no EMA@1024px, batch size 1-4, LoRA @ medium-high batch sizes)&lt;/li&gt; &#xA; &lt;li&gt;4080-12G (LoRA @ low-medium batch sizes)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Stable Diffusion 2.x, 768px&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A100-40, A40, A6000 or better (EMA, 1024px training)&lt;/li&gt; &#xA; &lt;li&gt;NVIDIA RTX 4090 or better (24G, no EMA)&lt;/li&gt; &#xA; &lt;li&gt;NVIDIA RTX 4080 or better (LoRA only)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Scripts&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;ubuntu.sh&lt;/code&gt; - This is a basic &#34;installer&#34; that makes it quick to deploy on a Vast.ai instance. It might not work for every single container image.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;train.sh&lt;/code&gt; - The main training script for SDXL.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;config/config.env.example&lt;/code&gt; - These are training parameters, you should copy to &lt;code&gt;config/config.env&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Toolkit&lt;/h2&gt; &#xA;&lt;p&gt;For more information about the associated toolkit distributed with SimpleTuner, refer to &lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/toolkit/README.md&#34;&gt;the toolkit documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;Detailed setup information is available in the &lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/INSTALL.md&#34;&gt;installation documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Troubleshooting&lt;/h2&gt; &#xA;&lt;p&gt;Enable debug logs for a more detailed insight by adding &lt;code&gt;export SIMPLETUNER_LOG_LEVEL=DEBUG&lt;/code&gt; to your environment file.&lt;/p&gt; &#xA;&lt;p&gt;For performance analysis of the training loop, setting &lt;code&gt;SIMPLETUNER_TRAINING_LOOP_LOG_LEVEL=DEBUG&lt;/code&gt; will have timestamps that hilight any issues in your configuration.&lt;/p&gt; &#xA;&lt;p&gt;For a comprehensive list of options available, consult &lt;a href=&#34;https://raw.githubusercontent.com/bghira/SimpleTuner/main/OPTIONS.md&#34;&gt;this documentation&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>