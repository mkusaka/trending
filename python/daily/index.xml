<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-08-18T01:33:10Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>opendatalab/labelU</title>
    <updated>2024-08-18T01:33:10Z</updated>
    <id>tag:github.com,2024-08-18:/opendatalab/labelU</id>
    <link href="https://github.com/opendatalab/labelU" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Data annotation toolbox supports image, audio and video data.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;article style=&#34;display: flex; flex-direction: column; align-items: center; justify-content: center;&#34;&gt; &#xA;  &lt;p align=&#34;center&#34;&gt;&lt;img width=&#34;300&#34; src=&#34;https://user-images.githubusercontent.com/25022954/209616423-9ab056be-5d62-4eeb-b91d-3b20f64cfcf8.svg?sanitize=true&#34;&gt;&lt;/p&gt; &#xA;  &lt;h1 style=&#34;width: 100%; text-align: center;&#34;&gt;&lt;/h1&gt; &#xA;  &lt;p align=&#34;center&#34;&gt; English | &lt;a href=&#34;https://raw.githubusercontent.com/opendatalab/labelU/main/README_zh-CN.md&#34;&gt;简体中文&lt;/a&gt; &lt;/p&gt; &#xA; &lt;/article&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Product Introduction&lt;/h2&gt; &#xA;&lt;p&gt;LabelU is a comprehensive data annotation platform designed for handling multimodal data. It offers a range of advanced annotation tools and efficient workflows, making it easier for users to tackle annotation tasks involving images, videos, and audio. LabelU is tailored to meet the demands of complex data analysis and model training.&lt;/p&gt; &#xA;&lt;h2&gt;Key Features&lt;/h2&gt; &#xA;&lt;h3&gt;Versatile Image Annotation Tools&lt;/h3&gt; &#xA;&lt;p&gt;LabelU provides a comprehensive set of tools for image annotation, including 2D bounding boxes, semantic segmentation, polylines, and keypoints. These tools can flexibly address a variety of image processing tasks, such as object detection, scene analysis, image recognition, and machine translation, helping users efficiently identify, annotate, and analyze images.&lt;/p&gt; &#xA;&lt;h3&gt;Powerful Video Annotation Capabilities&lt;/h3&gt; &#xA;&lt;p&gt;In the realm of video annotation, LabelU showcases impressive processing capabilities, supporting video segmentation, video classification, and video information extraction. It is highly suitable for applications such as video retrieval, video summarization, and action recognition, enabling users to easily handle long-duration videos, accurately extract key information, and support complex scene analysis, providing high-quality annotated data for subsequent model training.&lt;/p&gt; &#xA;&lt;h3&gt;Efficient Audio Annotation Tools&lt;/h3&gt; &#xA;&lt;p&gt;Audio annotation tools are another key feature of LabelU. These tools possess efficient and precise audio analysis capabilities, supporting audio segmentation, audio classification, and audio information extraction. By visualizing complex sound information, LabelU simplifies the audio data processing workflow, aiding in the development of more accurate models.&lt;/p&gt; &#xA;&lt;h3&gt;Artificial Intelligence Assisted Labelling&lt;/h3&gt; &#xA;&lt;p&gt;LabelU supports one-click loading of pre-annotated data, which can be refined and adjusted according to actual needs. This feature improves the efficiency and accuracy of annotation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/0fa5bc39-20ba-46b6-9839-379a49f692cf&#34;&gt;https://github.com/user-attachments/assets/0fa5bc39-20ba-46b6-9839-379a49f692cf&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Simplicity: Provides a variety of image annotation tools that can be annotated through simple visual configuration.&lt;/li&gt; &#xA; &lt;li&gt;Flexibility: A variety of tools can be freely combined to meet most image, video, and audio annotation needs.&lt;/li&gt; &#xA; &lt;li&gt;Universality: Supports exporting to various data formats, including JSON, COCO, MASK.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;a href=&#34;https://opendatalab.github.io/labelU-Kit/&#34;&gt; &lt;button&gt;Try LabelU annotation toolkit&lt;/button&gt; &lt;/a&gt;&lt;/li&gt;&#xA; &lt;a href=&#34;https://opendatalab.github.io/labelU-Kit/&#34;&gt; &lt;/a&gt;&#xA;&lt;/ul&gt;&#xA;&lt;a href=&#34;https://opendatalab.github.io/labelU-Kit/&#34;&gt; &lt;/a&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;a href=&#34;https://labelu.shlab.tech/&#34;&gt; &lt;button&gt;Try LabelU online&lt;/button&gt; &lt;/a&gt;&lt;/li&gt;&#xA; &lt;a href=&#34;https://labelu.shlab.tech/&#34;&gt; &lt;/a&gt;&#xA;&lt;/ul&gt;&#xA;&lt;a href=&#34;https://labelu.shlab.tech/&#34;&gt; &lt;/a&gt; &#xA;&lt;h3&gt;Local deployment&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://docs.conda.io/en/latest/miniconda.html&#34;&gt;Miniconda&lt;/a&gt;, Choose the corresponding operating system type and download it for installation.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note：&lt;/strong&gt; If your system is MacOS with an Intel chip, please install &lt;a href=&#34;https://repo.anaconda.com/miniconda/&#34;&gt;Miniconda of intel x86_64&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;After the installation is complete, run the following command in the terminal (you can choose the default &#39;y&#39; for prompts during the process):&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n labelu python=3.11&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note：&lt;/strong&gt; For Windows platform, you can run the above command in Anaconda Prompt.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Activate the environment：&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda activate labelu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Install LabelU：&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install labelu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;To install the test version：&lt;code&gt;pip install labelu==&amp;lt;test revision&amp;gt; --pre&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;Run LabelU：&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;labelu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;Visit &lt;a href=&#34;http://localhost:8000/&#34;&gt;http://localhost:8000/&lt;/a&gt; and ready to go.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Local development&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Download and Install miniconda&#xA;# https://docs.conda.io/en/latest/miniconda.html&#xA;&#xA;# Create virtual environment(python = 3.11)&#xA;conda create -n labelu python=3.11&#xA;&#xA;# Activate virtual environment&#xA;conda activate labelu&#xA;&#xA;# Install peotry&#xA;# https://python-poetry.org/docs/#installing-with-the-official-installer&#xA;&#xA;# Install all package dependencies&#xA;poetry install&#xA;&#xA;# Start labelu, server: http://localhost:8000&#xA;uvicorn labelu.main:app --reload&#xA;&#xA;# Update submodule&#xA;git submodule update --remote --merge&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quick start&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opendatalab.github.io/labelU&#34;&gt;Guidance&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Annotation format&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opendatalab.github.io/labelU/#/schema&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{he2024opendatalab,&#xA;  title={Opendatalab: Empowering general artificial intelligence with open datasets},&#xA;  author={He, Conghui and Li, Wei and Jin, Zhenjiang and Xu, Chao and Wang, Bin and Lin, Dahua},&#xA;  journal={arXiv preprint arXiv:2407.13773},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Communication&lt;/h2&gt; &#xA;&lt;p&gt;Welcome to the OpenDataLab official WeChat group！&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img style=&#34;width: 400px&#34; src=&#34;https://user-images.githubusercontent.com/25022954/208374419-2dffb701-321a-4091-944d-5d913de79a15.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/opendatalab/labelU-Kit&#34;&gt;LabelU-kit&lt;/a&gt; Web front-end annotation kit (LabelU is based on this JavaScript kit)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/opendatalab/LabelLLM&#34;&gt;LabelLLM&lt;/a&gt; An Open-source LLM Dialogue Annotation Platform&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/opendatalab/MinerU&#34;&gt;Miner U&lt;/a&gt; A One-stop Open-source High-quality Data Extraction Tool&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is released under the &lt;a href=&#34;https://raw.githubusercontent.com/opendatalab/labelU/main/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>