<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-10-01T01:42:11Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>dreamgaussian/dreamgaussian</title>
    <updated>2023-10-01T01:42:11Z</updated>
    <id>tag:github.com,2023-10-01:/dreamgaussian/dreamgaussian</id>
    <link href="https://github.com/dreamgaussian/dreamgaussian" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Generative Gaussian Splatting for Efficient 3D Content Creation&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DreamGaussian&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the official implementation for &lt;a href=&#34;https://arxiv.org/abs/2309.16653&#34;&gt;DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://dreamgaussian.github.io&#34;&gt;Project Page&lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/abs/2309.16653&#34;&gt;Arxiv&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/dreamgaussian/dreamgaussian/assets/25863658/db860801-7b9c-4b30-9eb9-87330175f5c8&#34;&gt;https://github.com/dreamgaussian/dreamgaussian/assets/25863658/db860801-7b9c-4b30-9eb9-87330175f5c8&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/camenduru/dreamgaussian-colab&#34;&gt;Colab demo&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Image-to-3D: &lt;a href=&#34;https://colab.research.google.com/drive/1sLpYmmLS209-e5eHgcuqdryFRRO6ZhFS?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Text-to-3D: &lt;a href=&#34;https://colab.research.google.com/github/camenduru/dreamgaussian-colab/blob/main/dreamgaussian_colab.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&#xA;# a modified gaussian splatting (+ depth, alpha rendering)&#xA;git clone --recursive https://github.com/ashawkey/diff-gaussian-rasterization&#xA;pip install ./diff-gaussian-rasterization&#xA;&#xA;# simple-knn&#xA;pip install ./simple-knn&#xA;&#xA;# nvdiffrast&#xA;pip install git+https://github.com/NVlabs/nvdiffrast/&#xA;&#xA;# kiuikit&#xA;pip install git+https://github.com/ashawkey/kiuikit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Tested on:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ubuntu 22 with torch 1.12 &amp;amp; CUDA 11.6 on a V100.&lt;/li&gt; &#xA; &lt;li&gt;Windows 10 with torch 2.1 &amp;amp; CUDA 12.1 on a 3070.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Image-to-3D:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;### preprocess&#xA;# background removal and recenter, save rgba at 256x256&#xA;python process.py data/name.jpg&#xA;&#xA;# save at a larger resolution&#xA;python process.py data/name.jpg --size 512&#xA;&#xA;# process all jpg images under a dir&#xA;python process.py data&#xA;&#xA;### training gaussian stage&#xA;# train 500 iters (~1min) and export ckpt &amp;amp; coarse_mesh to logs&#xA;python main.py --config configs/image.yaml input=data/name_rgba.png save_path=name&#xA;&#xA;# gui mode (supports visualizing training)&#xA;python main.py --config configs/image.yaml input=data/name_rgba.png save_path=name gui=True&#xA;&#xA;# load and visualize a saved ckpt&#xA;python main.py --config configs/image.yaml load=logs/name_model.ply gui=True&#xA;&#xA;# use an estimated elevation angle if image is not front-view (e.g., common looking-down image can use -30)&#xA;python main.py --config configs/image.yaml input=data/name_rgba.png save_path=name elevation=-30&#xA;&#xA;### training mesh stage&#xA;# auto load coarse_mesh.obj and refine 50 iters (~1min), export fine_mesh to logs&#xA;python main2.py --config configs/image.yaml input=data/name_rgba.png save_path=name&#xA;&#xA;# specify coarse mesh path explicity&#xA;python main2.py --config configs/image.yaml input=data/name_rgba.png save_path=name mesh=logs/name_mesh.obj&#xA;&#xA;# gui mode&#xA;python main2.py --config configs/image.yaml input=data/name_rgba.png save_path=name gui=True&#xA;&#xA;### visualization&#xA;# gui for visualizing mesh&#xA;python -m kiui.render logs/name.obj&#xA;&#xA;# save 360 degree video of mesh (can run without gui)&#xA;python -m kiui.render logs/name.obj --save_video name.mp4 --wogui&#xA;&#xA;# save 8 view images of mesh (can run without gui)&#xA;python -m kiui.render logs/name.obj --save images/name/ --wogui&#xA;&#xA;### evaluation of CLIP-similarity&#xA;python -m kiui.cli.clip_sim data/name_rgba.png logs/name.obj&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please check &lt;code&gt;./configs/image.yaml&lt;/code&gt; for more options.&lt;/p&gt; &#xA;&lt;p&gt;Text-to-3D:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;### training gaussian stage&#xA;python main.py --config configs/text.yaml prompt=&#34;a photo of an icecream&#34; save_path=icecream&#xA;&#xA;### training mesh stage&#xA;python main2.py --config configs/text.yaml prompt=&#34;a photo of an icecream&#34; save_path=icecream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please check &lt;code&gt;./configs/text.yaml&lt;/code&gt; for more options.&lt;/p&gt; &#xA;&lt;p&gt;Helper scripts:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# run all image samples (*_rgba.png) in ./data&#xA;python scripts/runall.py --dir ./data --gpu 0&#xA;&#xA;# run all text samples (hardcoded in runall_sd.py)&#xA;python scripts/runall_sd.py --gpu 0&#xA;&#xA;# export all ./logs/*.obj to mp4 in ./videos&#xA;python scripts/convert_obj_to_video.py --dir ./logs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;This work is built on many amazing research works and open-source projects, thanks a lot to all the authors for sharing!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/graphdeco-inria/gaussian-splatting&#34;&gt;gaussian-splatting&lt;/a&gt; and &lt;a href=&#34;https://github.com/graphdeco-inria/diff-gaussian-rasterization&#34;&gt;diff-gaussian-rasterization&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/threestudio-project/threestudio&#34;&gt;threestudio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/NVlabs/nvdiffrast&#34;&gt;nvdiffrast&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hoffstadt/DearPyGui&#34;&gt;dearpygui&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{tang2023dreamgaussian,&#xA;  title={DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation},&#xA;  author={Tang, Jiaxiang and Ren, Jiawei and Zhou, Hang and Liu, Ziwei and Zeng, Gang},&#xA;  journal={arXiv preprint arXiv:2309.16653},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>explosion/spacy-llm</title>
    <updated>2023-10-01T01:42:11Z</updated>
    <id>tag:github.com,2023-10-01:/explosion/spacy-llm</id>
    <link href="https://github.com/explosion/spacy-llm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ü¶ô Integrating LLMs into structured NLP pipelines&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://explosion.ai&#34;&gt;&lt;img src=&#34;https://explosion.ai/assets/img/logo.svg?sanitize=true&#34; width=&#34;125&#34; height=&#34;125&#34; align=&#34;right&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;spacy-llm: Integrating LLMs into structured NLP pipelines&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/explosion/spacy-llm/actions/workflows/test.yml&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/explosion/spacy-llm/test.yml?branch=main&#34; alt=&#34;GitHub Workflow Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/spacy-llm/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/spacy-llm.svg?style=flat-square&amp;amp;logo=pypi&amp;amp;logoColor=white&#34; alt=&#34;pypi Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ambv/black&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/code%20style-black-000000.svg?style=flat-square&#34; alt=&#34;Code style: black&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This package integrates Large Language Models (LLMs) into &lt;a href=&#34;https://spacy.io&#34;&gt;spaCy&lt;/a&gt;, featuring a modular system for &lt;strong&gt;fast prototyping&lt;/strong&gt; and &lt;strong&gt;prompting&lt;/strong&gt;, and turning unstructured responses into &lt;strong&gt;robust outputs&lt;/strong&gt; for various NLP tasks, &lt;strong&gt;no training data&lt;/strong&gt; required.&lt;/p&gt; &#xA;&lt;h2&gt;Feature Highlight&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Serializable &lt;code&gt;llm&lt;/code&gt; &lt;strong&gt;component&lt;/strong&gt; to integrate prompts into your spaCy pipeline&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Modular functions&lt;/strong&gt; to define the &lt;a href=&#34;https://spacy.io/api/large-language-models#tasks&#34;&gt;&lt;strong&gt;task&lt;/strong&gt;&lt;/a&gt; (prompting and parsing) and &lt;a href=&#34;https://spacy.io/api/large-language-models#models&#34;&gt;&lt;strong&gt;model&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Interfaces with the APIs of &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://platform.openai.com/docs/api-reference/&#34;&gt;OpenAI&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://docs.cohere.com/reference/generate&#34;&gt;Cohere&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://docs.anthropic.com/claude/reference/&#34;&gt;Anthropic&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Supports open-source LLMs hosted on Hugging Face ü§ó: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/tiiuae&#34;&gt;Falcon&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/databricks&#34;&gt;Dolly&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/meta-llama&#34;&gt;Llama 2&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/openlm-research&#34;&gt;OpenLLaMA&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/stabilityai&#34;&gt;StableLM&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Integration with &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt; ü¶úÔ∏èüîó - all &lt;code&gt;langchain&lt;/code&gt; models and features can be used in &lt;code&gt;spacy-llm&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Tasks available out of the box: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Named Entity Recognition&lt;/li&gt; &#xA;   &lt;li&gt;Text classification&lt;/li&gt; &#xA;   &lt;li&gt;Lemmatization&lt;/li&gt; &#xA;   &lt;li&gt;Relationship extraction&lt;/li&gt; &#xA;   &lt;li&gt;Sentiment analysis&lt;/li&gt; &#xA;   &lt;li&gt;Span categorization&lt;/li&gt; &#xA;   &lt;li&gt;Summarization&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Easy implementation of &lt;strong&gt;your own functions&lt;/strong&gt; via &lt;a href=&#34;https://spacy.io/api/top-level#registry&#34;&gt;spaCy&#39;s registry&lt;/a&gt; for custom prompting, parsing and model integrations&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üß† Motivation&lt;/h2&gt; &#xA;&lt;p&gt;Large Language Models (LLMs) feature powerful natural language understanding capabilities. With only a few (and sometimes no) examples, an LLM can be prompted to perform custom NLP tasks such as text categorization, named entity recognition, coreference resolution, information extraction and more.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://spacy.io&#34;&gt;spaCy&lt;/a&gt; is a well-established library for building systems that need to work with language in various ways. spaCy&#39;s built-in components are generally powered by supervised learning or rule-based approaches.&lt;/p&gt; &#xA;&lt;p&gt;Supervised learning is much worse than LLM prompting for prototyping, but for many tasks it&#39;s much better for production. A transformer model that runs comfortably on a single GPU is extremely powerful, and it&#39;s likely to be a better choice for any task for which you have a well-defined output. You train the model with anything from a few hundred to a few thousand labelled examples, and it will learn to do exactly that. Efficiency, reliability and control are all better with supervised learning, and accuracy will generally be higher than LLM prompting as well.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;spacy-llm&lt;/code&gt; lets you have &lt;strong&gt;the best of both worlds&lt;/strong&gt;. You can quickly initialize a pipeline with components powered by LLM prompts, and freely mix in components powered by other approaches. As your project progresses, you can look at replacing some or all of the LLM-powered components as you require.&lt;/p&gt; &#xA;&lt;p&gt;Of course, there can be components in your system for which the power of an LLM is fully justified. If you want a system that can synthesize information from multiple documents in subtle ways and generate a nuanced summary for you, bigger is better. However, even if your production system needs an LLM for some of the task, that doesn&#39;t mean you need an LLM for all of it. Maybe you want to use a cheap text classification model to help you find the texts to summarize, or maybe you want to add a rule-based system to sanity check the output of the summary. These before-and-after tasks are much easier with a mature and well-thought-out library, which is exactly what spaCy provides.&lt;/p&gt; &#xA;&lt;h2&gt;‚è≥ Install&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;spacy-llm&lt;/code&gt; will be installed automatically in future spaCy versions. For now, you can run the following in the same virtual environment where you already have &lt;code&gt;spacy&lt;/code&gt; &lt;a href=&#34;https://spacy.io/usage&#34;&gt;installed&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m pip install spacy-llm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;‚ö†Ô∏è This package is still experimental and it is possible that changes made to the interface will be breaking in minor version updates.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;üêç Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;Let&#39;s run some text classification using a GPT model from OpenAI.&lt;/p&gt; &#xA;&lt;p&gt;Create a new API key from openai.com or fetch an existing one, and ensure the keys are set as environmental variables. For more background information, see the documentation around setting &lt;a href=&#34;https://spacy.io/api/large-language-models#api-keys&#34;&gt;API keys&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;In Python code&lt;/h3&gt; &#xA;&lt;p&gt;To do some quick experiments, from 0.5.0 onwards you can run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import spacy&#xA;&#xA;nlp = spacy.blank(&#34;en&#34;)&#xA;llm = nlp.add_pipe(&#34;llm_textcat&#34;)&#xA;llm.add_label(&#34;INSULT&#34;)&#xA;llm.add_label(&#34;COMPLIMENT&#34;)&#xA;doc = nlp(&#34;You look gorgeous!&#34;)&#xA;print(doc.cats)&#xA;# {&#34;COMPLIMENT&#34;: 1.0, &#34;INSULT&#34;: 0.0}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By using the &lt;code&gt;llm_textcat&lt;/code&gt; factory, the latest version of the built-in textcat task is used, as well as the default GPT-3-5 model from OpenAI.&lt;/p&gt; &#xA;&lt;h3&gt;Using a config file&lt;/h3&gt; &#xA;&lt;p&gt;To control the various parameters of the &lt;code&gt;llm&lt;/code&gt; pipeline, we can use &lt;a href=&#34;https://spacy.io/api/data-formats#config&#34;&gt;spaCy&#39;s config system&lt;/a&gt;. To start, create a config file &lt;code&gt;config.cfg&lt;/code&gt; containing at least the following (or see the full example &lt;a href=&#34;https://github.com/explosion/spacy-llm/tree/main/usage_examples/textcat_openai&#34;&gt;here&lt;/a&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;[nlp]&#xA;lang = &#34;en&#34;&#xA;pipeline = [&#34;llm&#34;]&#xA;&#xA;[components]&#xA;&#xA;[components.llm]&#xA;factory = &#34;llm&#34;&#xA;&#xA;[components.llm.task]&#xA;@llm_tasks = &#34;spacy.TextCat.v3&#34;&#xA;labels = [&#34;COMPLIMENT&#34;, &#34;INSULT&#34;]&#xA;&#xA;[components.llm.model]&#xA;@llm_models = &#34;spacy.GPT-4.v2&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from spacy_llm.util import assemble&#xA;&#xA;nlp = assemble(&#34;config.cfg&#34;)&#xA;doc = nlp(&#34;You look gorgeous!&#34;)&#xA;print(doc.cats)&#xA;# {&#34;COMPLIMENT&#34;: 1.0, &#34;INSULT&#34;: 0.0}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That&#39;s it! There&#39;s a lot of other features - prompt templating, more tasks, logging etc. For more information on how to use those, check out &lt;a href=&#34;https://spacy.io/api/large-language-models&#34;&gt;https://spacy.io/api/large-language-models&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Ongoing work&lt;/h2&gt; &#xA;&lt;p&gt;In the near future, we will&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Add more example tasks&lt;/li&gt; &#xA; &lt;li&gt;Support a broader range of models&lt;/li&gt; &#xA; &lt;li&gt;Provide more example use-cases and tutorials&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;PRs are always welcome!&lt;/p&gt; &#xA;&lt;h2&gt;üìùÔ∏è Reporting issues&lt;/h2&gt; &#xA;&lt;p&gt;If you have questions regarding the usage of &lt;code&gt;spacy-llm&lt;/code&gt;, or want to give us feedback after giving it a spin, please use the &lt;a href=&#34;https://github.com/explosion/spacy-llm/discussions&#34;&gt;discussion board&lt;/a&gt;. Bug reports can be filed on the &lt;a href=&#34;https://github.com/explosion/spacy-llm/issues&#34;&gt;spaCy issue tracker&lt;/a&gt;. Thank you!&lt;/p&gt; &#xA;&lt;h2&gt;Migration guides&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to our &lt;a href=&#34;https://raw.githubusercontent.com/explosion/spacy-llm/main/migration_guide.md&#34;&gt;migration guide&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>zkMeLabs/zkme-python-seal</title>
    <updated>2023-10-01T01:42:11Z</updated>
    <id>tag:github.com,2023-10-01:/zkMeLabs/zkme-python-seal</id>
    <link href="https://github.com/zkMeLabs/zkme-python-seal" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This library is built upon SEAL-Python, showcasing the power and potential of Homomorphic Encryption (HE) in the context of the zkMe project.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;zkme-he&lt;/h1&gt; &#xA;&lt;p&gt;This library is built upon &lt;a href=&#34;https://github.com/Huelse/SEAL-Python&#34;&gt;&lt;strong&gt;SEAL-Python&lt;/strong&gt;&lt;/a&gt;, showcasing the power and potential of Homomorphic Encryption (HE) in the context of the zkMe project. One of its primary objectives is to demonstrate how HE can be employed to protect sensitive facial feature information of users. Remarkably, it highlights the capability of performing computations directly on encrypted data without the need to decrypt it first. Furthermore, for those technical enthusiasts keen on understanding the intricacies of HE, the library also provides step-by-step Jupyter documentation. This documentation elucidates how HE operates under the classes of SEAL, offering a comprehensive guide for those intrigued by the world of Homomorphic Encryption.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://zk.me&#34;&gt;zkMe&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;zkMe verifies user credentials without disclosing any personal information to anyone. Through the use of innovative zero-knowledge technologies, it is the only KYC solution to be fully decentralized, private-by-design and compliant with global AML requirements. No credential verified through the zkMe app is stored on any centralized storage, making it virtual impossible for any private data leak. The only thing shared (if authorized by you) are yes/no answers to basic elegibility questions such as &#34;are you over 18 years old?&#34;. [https://zk.me/]&lt;/p&gt; &#xA;&lt;h2&gt;Microsoft SEAL For Python&lt;/h2&gt; &#xA;&lt;p&gt;Microsoft &lt;a href=&#34;https://github.com/microsoft/SEAL&#34;&gt;&lt;strong&gt;SEAL&lt;/strong&gt;&lt;/a&gt; is an easy-to-use open-source (&lt;a href=&#34;https://github.com/microsoft/SEAL/raw/master/LICENSE&#34;&gt;MIT licensed&lt;/a&gt;) homomorphic encryption library developed by the Cryptography Research group at Microsoft.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Huelse/SEAL-Python&#34;&gt;&lt;strong&gt;SEAL-Python&lt;/strong&gt;&lt;/a&gt; is a python binding for the Microsoft SEAL library.&lt;/p&gt; &#xA;&lt;p&gt;This project is based on &lt;a href=&#34;https://github.com/Huelse/SEAL-Python&#34;&gt;&lt;strong&gt;SEAL-Python&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zkMeLabs/zkme-python-seal/main/#Environment&#34;&gt;Environment&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zkMeLabs/zkme-python-seal/main/#Prepare&#34;&gt;Prepare&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zkMeLabs/zkme-python-seal/main/#Demo&#34;&gt;Demo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Environment&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.9 or later&lt;/li&gt; &#xA; &lt;li&gt;Check the requirements.txt&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Prepare&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;h4&gt;Install &lt;a href=&#34;https://github.com/Huelse/SEAL-Python&#34;&gt;&lt;strong&gt;SEAL-Python&lt;/strong&gt;&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;Please follow the instructions in the &lt;a href=&#34;https://github.com/Huelse/SEAL-Python&#34;&gt;git library&lt;/a&gt; on Build section. Make sure you have installed the SEAL library and SEAL-Python successfully. The .so file should be in the current directory or you have installed it already.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;All the examples are in the &lt;code&gt;examples&lt;/code&gt; folder and build by &lt;code&gt;jupyter notebook&lt;/code&gt; which is a good tool to learn and test the code.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Basic functions&lt;/p&gt; &lt;p&gt;&lt;code&gt;examples/1_basic_he_func.ipynb&lt;/code&gt;&lt;/p&gt; &lt;p&gt;The basic functions are the same as the C++ SEAL library. Here is a simple example that demonstrates the calculation of the L2 distance using both homomorphic encryption and matrix computation. By comparing the results, one can directly appreciate the use of homomorphic encryption.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>