<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-23T01:44:58Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>vllm-project/vllm</title>
    <updated>2023-06-23T01:44:58Z</updated>
    <id>tag:github.com,2023-06-23:/vllm-project/vllm</id>
    <link href="https://github.com/vllm-project/vllm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A high-throughput and memory-efficient inference and serving engine for LLMs&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://raw.githubusercontent.com/vllm-project/vllm/main/docs/source/assets/logos/vllm-logo-text-dark.png&#34;&gt; &#xA;  &lt;img alt=&#34;vLLM&#34; src=&#34;https://raw.githubusercontent.com/vllm-project/vllm/main/docs/source/assets/logos/vllm-logo-text-light.png&#34; width=&#34;55%&#34;&gt; &#xA; &lt;/picture&gt; &lt;/p&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt; Easy, fast, and cheap LLM serving for everyone &lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; | &lt;a href=&#34;https://vllm.readthedocs.io/en/latest/&#34;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://vllm.ai&#34;&gt;&lt;b&gt;Blog&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/vllm-project/vllm/discussions&#34;&gt;&lt;b&gt;Discussions&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;em&gt;Latest News&lt;/em&gt; üî•&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2023/06] We officially released vLLM! vLLM has powered &lt;a href=&#34;https://chat.lmsys.org&#34;&gt;LMSYS Vicuna and Chatbot Arena&lt;/a&gt; since mid April. Check out our &lt;a href=&#34;https://vllm.ai&#34;&gt;blog post&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;vLLM is a fast and easy-to-use library for LLM inference and serving.&lt;/p&gt; &#xA;&lt;p&gt;vLLM is fast with:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;State-of-the-art serving throughput&lt;/li&gt; &#xA; &lt;li&gt;Efficient management of attention key and value memory with &lt;strong&gt;PagedAttention&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Dynamic batching of incoming requests&lt;/li&gt; &#xA; &lt;li&gt;Optimized CUDA kernels&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;vLLM is flexible and easy to use with:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Seamless integration with popular HuggingFace models&lt;/li&gt; &#xA; &lt;li&gt;High-throughput serving with various decoding algorithms, including &lt;em&gt;parallel sampling&lt;/em&gt;, &lt;em&gt;beam search&lt;/em&gt;, and more&lt;/li&gt; &#xA; &lt;li&gt;Tensor parallelism support for distributed inference&lt;/li&gt; &#xA; &lt;li&gt;Streaming outputs&lt;/li&gt; &#xA; &lt;li&gt;OpenAI-compatible API server&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;vLLM seamlessly supports many Huggingface models, including the following architectures:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GPT-2 (&lt;code&gt;gpt2&lt;/code&gt;, &lt;code&gt;gpt2-xl&lt;/code&gt;, etc.)&lt;/li&gt; &#xA; &lt;li&gt;GPT BigCode (&lt;code&gt;bigcode/starcoder&lt;/code&gt;, &lt;code&gt;bigcode/gpt_bigcode-santacoder&lt;/code&gt;, etc.)&lt;/li&gt; &#xA; &lt;li&gt;GPT-NeoX (&lt;code&gt;EleutherAI/gpt-neox-20b&lt;/code&gt;, &lt;code&gt;databricks/dolly-v2-12b&lt;/code&gt;, &lt;code&gt;stabilityai/stablelm-tuned-alpha-7b&lt;/code&gt;, etc.)&lt;/li&gt; &#xA; &lt;li&gt;LLaMA (&lt;code&gt;lmsys/vicuna-13b-v1.3&lt;/code&gt;, &lt;code&gt;young-geng/koala&lt;/code&gt;, &lt;code&gt;openlm-research/open_llama_13b&lt;/code&gt;, etc.)&lt;/li&gt; &#xA; &lt;li&gt;OPT (&lt;code&gt;facebook/opt-66b&lt;/code&gt;, &lt;code&gt;facebook/opt-iml-max-30b&lt;/code&gt;, etc.)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Install vLLM with pip or &lt;a href=&#34;https://vllm.readthedocs.io/en/latest/getting_started/installation.html#build-from-source&#34;&gt;from source&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install vllm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Visit our &lt;a href=&#34;https://vllm.readthedocs.io/en/latest/&#34;&gt;documentation&lt;/a&gt; to get started.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vllm.readthedocs.io/en/latest/getting_started/installation.html&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vllm.readthedocs.io/en/latest/getting_started/quickstart.html&#34;&gt;Quickstart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vllm.readthedocs.io/en/latest/models/supported_models.html&#34;&gt;Supported Models&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Performance&lt;/h2&gt; &#xA;&lt;p&gt;vLLM outperforms HuggingFace Transformers (HF) by up to 24x and Text Generation Inference (TGI) by up to 3.5x, in terms of throughput. For details, check out our &lt;a href=&#34;https://vllm.ai&#34;&gt;blog post&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://raw.githubusercontent.com/vllm-project/vllm/main/docs/source/assets/figures/perf_a10g_n1_dark.png&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/vllm-project/vllm/main/docs/source/assets/figures/perf_a10g_n1_light.png&#34; width=&#34;45%&#34;&gt; &#xA; &lt;/picture&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://raw.githubusercontent.com/vllm-project/vllm/main/docs/source/assets/figures/perf_a100_n1_dark.png&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/vllm-project/vllm/main/docs/source/assets/figures/perf_a100_n1_light.png&#34; width=&#34;45%&#34;&gt; &#xA; &lt;/picture&gt; &lt;br&gt; &lt;em&gt; Serving throughput when each request asks for 1 output completion. &lt;/em&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://raw.githubusercontent.com/vllm-project/vllm/main/docs/source/assets/figures/perf_a10g_n3_dark.png&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/vllm-project/vllm/main/docs/source/assets/figures/perf_a10g_n3_light.png&#34; width=&#34;45%&#34;&gt; &#xA; &lt;/picture&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://raw.githubusercontent.com/vllm-project/vllm/main/docs/source/assets/figures/perf_a100_n3_dark.png&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/vllm-project/vllm/main/docs/source/assets/figures/perf_a100_n3_light.png&#34; width=&#34;45%&#34;&gt; &#xA; &lt;/picture&gt; &lt;br&gt; &lt;em&gt; Serving throughput when each request asks for 3 output completions. &lt;/em&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome and value any contributions and collaborations. Please check out &lt;a href=&#34;https://raw.githubusercontent.com/vllm-project/vllm/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for how to get involved.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/sample-app-aoai-chatGPT</title>
    <updated>2023-06-23T01:44:58Z</updated>
    <id>tag:github.com,2023-06-23:/microsoft/sample-app-aoai-chatGPT</id>
    <link href="https://github.com/microsoft/sample-app-aoai-chatGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;[PREVIEW] Sample code for a simple web chat experience targeting chatGPT through AOAI.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;[Preview] Sample Chat App with AOAI&lt;/h1&gt; &#xA;&lt;p&gt;This repo contains sample code for a simple chat webapp that integrates with Azure OpenAI. Note: some portions of the app use preview APIs.&lt;/p&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;An existing Azure OpenAI resource and model deployment of a chat model (e.g. &lt;code&gt;gpt-35-turbo&lt;/code&gt;, &lt;code&gt;gpt-4&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;To use Azure OpenAI on your data: an existing Azure Cognitive Search resource and index.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Deploy the app&lt;/h2&gt; &#xA;&lt;h3&gt;Deploy with Azure Developer CLI&lt;/h3&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/sample-app-aoai-chatGPT/main/README_azd.md&#34;&gt;README_azd.md&lt;/a&gt; for detailed instructions.&lt;/p&gt; &#xA;&lt;h3&gt;One click Azure deployment&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fmicrosoft%2Fsample-app-aoai-chatGPT%2Fmain%2Finfrastructure%2Fdeployment.json&#34;&gt;&lt;img src=&#34;https://aka.ms/deploytoazurebutton&#34; alt=&#34;Deploy to Azure&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Click on the Deploy to Azure button and configure your settings in the Azure Portal as described in the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/sample-app-aoai-chatGPT/main/#environment-variables&#34;&gt;Environment variables&lt;/a&gt; section.&lt;/p&gt; &#xA;&lt;p&gt;Please see the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/sample-app-aoai-chatGPT/main/#add-an-identity-provider&#34;&gt;section below&lt;/a&gt; for important information about adding authentication to your app.&lt;/p&gt; &#xA;&lt;h3&gt;Deploy from your local machine&lt;/h3&gt; &#xA;&lt;h4&gt;Local Setup: Basic Chat Experience&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Update the environment variables listed in &lt;code&gt;app.py&lt;/code&gt; as described in the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/sample-app-aoai-chatGPT/main/#environment-variables&#34;&gt;Environment variables&lt;/a&gt; section.&lt;/p&gt; &lt;p&gt;These variables are required:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_OPENAI_RESOURCE&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_OPENAI_MODEL&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_OPENAI_KEY&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;These variables are optional:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_OPENAI_TEMPERATURE&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_OPENAI_TOP_P&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_OPENAI_MAX_TOKENS&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_OPENAI_STOP_SEQUENCE&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_OPENAI_SYSTEM_MESSAGE&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;See the &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#example-response-2&#34;&gt;documentation&lt;/a&gt; for more information on these parameters.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Start the app with &lt;code&gt;start.cmd&lt;/code&gt;. This will build the frontend, install backend dependencies, and then start the app.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You can see the local running app at &lt;a href=&#34;http://127.0.0.1:5000&#34;&gt;http://127.0.0.1:5000&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;Local Setup: Chat with your data (Preview)&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/use-your-data&#34;&gt;More information about Azure OpenAI on your data&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Update the &lt;code&gt;AZURE_OPENAI_*&lt;/code&gt; environment variables as described above.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To connect to your data, you need to specify an Azure Cognitive Search index to use. You can &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/search/search-get-started-portal&#34;&gt;create this index yourself&lt;/a&gt; or use the &lt;a href=&#34;https://oai.azure.com/portal/chat&#34;&gt;Azure AI Studio&lt;/a&gt; to create the index for you.&lt;/p&gt; &lt;p&gt;These variables are required when adding your data:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_SEARCH_SERVICE&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_SEARCH_INDEX&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_SEARCH_KEY&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;These variables are optional:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_SEARCH_USE_SEMANTIC_SEARCH&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_SEARCH_SEMANTIC_SEARCH_CONFIG&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_SEARCH_INDEX_TOP_K&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_SEARCH_ENABLE_IN_DOMAIN&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_SEARCH_CONTENT_COLUMNS&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_SEARCH_FILENAME_COLUMN&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_SEARCH_TITLE_COLUMN&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;AZURE_SEARCH_URL_COLUMN&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Start the app with &lt;code&gt;start.cmd&lt;/code&gt;. This will build the frontend, install backend dependencies, and then start the app.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You can see the local running app at &lt;a href=&#34;http://127.0.0.1:5000&#34;&gt;http://127.0.0.1:5000&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;Deploy with the Azure CLI&lt;/h4&gt; &#xA;&lt;p&gt;You can use the &lt;a href=&#34;https://learn.microsoft.com/en-us/cli/azure/install-azure-cli&#34;&gt;Azure CLI&lt;/a&gt; to deploy the app from your local machine. Make sure you have version 2.48.1 or later.&lt;/p&gt; &#xA;&lt;p&gt;If this is your first time deploying the app, you can use &lt;a href=&#34;https://learn.microsoft.com/en-us/cli/azure/webapp?view=azure-cli-latest#az-webapp-up&#34;&gt;az webapp up&lt;/a&gt;. Run the following command from the root folder of the repo, updating the placeholder values to your desired app name, resource group, location, and subscription. You can also change the SKU if desired.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;az webapp up --runtime PYTHON:3.10 --sku B1 --name &amp;lt;new-app-name&amp;gt; --resource-group &amp;lt;resource-group-name&amp;gt; --location &amp;lt;azure-region&amp;gt; --subscription &amp;lt;subscription-name&amp;gt;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;ve deployed the app previously from the AOAI studio, first run this command to update the appsettings to allow local code deployment:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;az webapp config appsettings set -g &amp;lt;resource-group-name&amp;gt; -n &amp;lt;existing-app-name&amp;gt; --settings WEBSITE_WEBDEPLOY_USE_SCM=false&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Then, use the &lt;code&gt;az webapp up&lt;/code&gt; command to deploy your local code to the existing app:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;az webapp up --runtime PYTHON:3.10 --sku B1 --name &amp;lt;existing-app-name&amp;gt; --resource-group &amp;lt;resource-group-name&amp;gt;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Make sure that the app name and resource group match exactly for the app that was previously deployed.&lt;/p&gt; &#xA;&lt;p&gt;Deployment will take several minutes. When it completes, you should be able to navigate to your app at {app-name}.azurewebsites.net.&lt;/p&gt; &#xA;&lt;h3&gt;Add an identity provider&lt;/h3&gt; &#xA;&lt;p&gt;After deployment, you will need to add an identity provider to provide authentication support in your app. See &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/app-service/scenario-secure-app-authentication-app-service&#34;&gt;this tutorial&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;p&gt;If you don&#39;t add an identity provider, the chat functionality of your app will be blocked to prevent unauthorized access to your resources and data. To remove this restriction, or add further access controls, update the logic in &lt;code&gt;getUserInfoList&lt;/code&gt; in &lt;code&gt;frontend/src/pages/chat/Chat.tsx&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Best Practices&lt;/h2&gt; &#xA;&lt;p&gt;Feel free to fork this repository and make your own modifications to the UX or backend logic. For example, you may want to expose some of the settings in &lt;code&gt;app.py&lt;/code&gt; in the UI for users to try out different behaviors. We recommend keeping these best practices in mind:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Reset the chat session (clear chat) if the user changes any settings. Notify the user that their chat history will be lost.&lt;/li&gt; &#xA; &lt;li&gt;Clearly communicate to the user what impact each setting will have on their experience.&lt;/li&gt; &#xA; &lt;li&gt;When you rotate API keys for your AOAI or ACS resource, be sure to update the app settings for each of your deployed apps to use the new key.&lt;/li&gt; &#xA; &lt;li&gt;Pull in changes from &lt;code&gt;main&lt;/code&gt; frequently to ensure you have the latest bug fixes and improvements, especially when using Azure OpenAI on your data.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Environment variables&lt;/h2&gt; &#xA;&lt;p&gt;Note: settings starting with &lt;code&gt;AZURE_SEARCH&lt;/code&gt; are only needed when using Azure OpenAI on your data. If not connecting to your data, you only need to specify &lt;code&gt;AZURE_OPENAI&lt;/code&gt; settings.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;App Setting&lt;/th&gt; &#xA;   &lt;th&gt;Value&lt;/th&gt; &#xA;   &lt;th&gt;Note&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_SEARCH_SERVICE&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The name of your Azure Cognitive Search resource&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_SEARCH_INDEX&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The name of your Azure Cognitive Search Index&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_SEARCH_KEY&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;An &lt;strong&gt;admin key&lt;/strong&gt; for your Azure Cognitive Search resource&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_SEARCH_USE_SEMANTIC_SEARCH&lt;/td&gt; &#xA;   &lt;td&gt;False&lt;/td&gt; &#xA;   &lt;td&gt;Whether or not to use semantic search&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_SEARCH_SEMANTIC_SEARCH_CONFIG&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The name of the semantic search configuration to use if using semantic search.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_SEARCH_TOP_K&lt;/td&gt; &#xA;   &lt;td&gt;5&lt;/td&gt; &#xA;   &lt;td&gt;The number of documents to retrieve from Azure Cognitive Search.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_SEARCH_ENABLE_IN_DOMAIN&lt;/td&gt; &#xA;   &lt;td&gt;True&lt;/td&gt; &#xA;   &lt;td&gt;Limits responses to only queries relating to your data.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_SEARCH_CONTENT_COLUMNS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;List of fields in your Azure Cognitive Search index that contains the text content of your documents to use when formulating a bot response. Represent these as a string joined with &#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_SEARCH_FILENAME_COLUMN&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;AZURE_SEARCH_FILENAME_COLUMN&lt;/code&gt;: Field from your Azure Cognitive Search index that gives a unique idenitfier of the source of your data to display in the UI.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_SEARCH_TITLE_COLUMN&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Field from your Azure Cognitive Search index that gives a relevant title or header for your data content to display in the UI.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_SEARCH_URL_COLUMN&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Field from your Azure Cognitive Search index that contains a URL for the document, e.g. an Azure Blob Storage URI. This value is not currently used.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_OPENAI_RESOURCE&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;the name of your Azure OpenAI resource&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_OPENAI_MODEL&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The name of your model deployment&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_OPENAI_MODEL_NAME&lt;/td&gt; &#xA;   &lt;td&gt;gpt-35-turbo&lt;/td&gt; &#xA;   &lt;td&gt;The name of the model&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_OPENAI_KEY&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;One of the API keys of your Azure OpenAI resource&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_OPENAI_TEMPERATURE&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. A value of 0 is recommended when using your data.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_OPENAI_TOP_P&lt;/td&gt; &#xA;   &lt;td&gt;1.0&lt;/td&gt; &#xA;   &lt;td&gt;An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. We recommend setting this to 1.0 when using your data.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_OPENAI_MAX_TOKENS&lt;/td&gt; &#xA;   &lt;td&gt;1000&lt;/td&gt; &#xA;   &lt;td&gt;The maximum number of tokens allowed for the generated answer.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_OPENAI_STOP_SEQUENCE&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Up to 4 sequences where the API will stop generating further tokens. Represent these as a string joined with &#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_OPENAI_SYSTEM_MESSAGE&lt;/td&gt; &#xA;   &lt;td&gt;You are an AI assistant that helps people find information.&lt;/td&gt; &#xA;   &lt;td&gt;A brief description of the role and tone the model should use&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_OPENAI_PREVIEW_API_VERSION&lt;/td&gt; &#xA;   &lt;td&gt;2023-06-01-preview&lt;/td&gt; &#xA;   &lt;td&gt;API version when using Azure OpenAI on your data&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AZURE_OPENAI_STREAM&lt;/td&gt; &#xA;   &lt;td&gt;True&lt;/td&gt; &#xA;   &lt;td&gt;Whether or not to use streaming for the response&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&#34;https://cla.opensource.microsoft.com&#34;&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h2&gt;Trademarks&lt;/h2&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>e-johnstonn/FableForge</title>
    <updated>2023-06-23T01:44:58Z</updated>
    <id>tag:github.com,2023-06-23:/e-johnstonn/FableForge</id>
    <link href="https://github.com/e-johnstonn/FableForge" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Generate a picture book from a single prompt using OpenAI function calling, replicate, and Deep Lake&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üìö FableForge&lt;/h1&gt; &#xA;&lt;h2&gt;üìÑ Description&lt;/h2&gt; &#xA;&lt;p&gt;Generate a picture book from a single prompt using &lt;a href=&#34;https://openai.com/blog/function-calling-and-other-api-updates&#34;&gt;OpenAI&#39;s new function calling&lt;/a&gt; and &lt;a href=&#34;https://replicate.com/&#34;&gt;Replicate&#39;s API&lt;/a&gt; for Stable Diffusion. Store all your generated images and corresponding prompts in &lt;a href=&#34;https://www.activeloop.ai/&#34;&gt;Deep Lake&lt;/a&gt;. Check &lt;code&gt;example.pdf&lt;/code&gt; or watch the video below for a peek at the output.&lt;/p&gt; &#xA;&lt;p&gt;Built with &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt;, &lt;a href=&#34;https://www.deeplake.ai/&#34;&gt;Deep Lake&lt;/a&gt;, and &lt;a href=&#34;https://replicate.com/&#34;&gt;Replicate&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;üì∫&lt;/span&gt; Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/e-johnstonn/FableForge/assets/30129211/f9523905-342e-4a33-914d-acd13bd168ec&#34;&gt;https://github.com/e-johnstonn/FableForge/assets/30129211/f9523905-342e-4a33-914d-acd13bd168ec&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üõ† Install&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repository&lt;/li&gt; &#xA; &lt;li&gt;Install requirements.txt&lt;/li&gt; &#xA; &lt;li&gt;Set up your OpenAI and Replicate API keys in &lt;code&gt;keys.env&lt;/code&gt; - More on this below&lt;/li&gt; &#xA; &lt;li&gt;To save your images and prompts, set up your Activeloop Deep Lake token and dataset path in &lt;code&gt;keys.env&lt;/code&gt; - More on this below&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;streamlit run main.py&lt;/code&gt; to start the app!&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;üß† Deep Lake Setup&lt;/h2&gt; &#xA;&lt;p&gt;During the creation of this project, I used Deep Lake to store the generated pictures and prompts in the cloud, as it makes it easy to work with multiple modalities of data (image/text), and displays them in a web UI. To set this up yourself, go to the &lt;a href=&#34;https://www.activeloop.ai/&#34;&gt;Deep Lake website&lt;/a&gt; and make an account. Once logged in, you can click &#34;Train deep learning models&#34;, then &#34;Create dataset&#34;, which will guide you through getting an API token and dataset link. Put the token and dataset path in the &lt;code&gt;keys.env&lt;/code&gt; file and you&#39;re good to go.&lt;/p&gt; &#xA;&lt;h2&gt;üñºÔ∏è Replicate Setup&lt;/h2&gt; &#xA;&lt;p&gt;A Replicate API key is necessary for this app. To get one, go to the &lt;a href=&#34;https://replicate.com/&#34;&gt;Replicate website&lt;/a&gt; and create an account, then take your API key and put it in &lt;code&gt;keys.env&lt;/code&gt;. Replicate provides free image generation for new users.&lt;/p&gt; &#xA;&lt;h2&gt;üìêArchitecture&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/e-johnstonn/FableForge/assets/30129211/54dbaa98-5a89-4af4-8ff2-9640a40e773c&#34; alt=&#34;architecture&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Improvements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;This demo uses Replicate for image generation due to its ease of use. Connect it to your own Stable Diffusion setup (local or cloud-based) for better results. I recommend some combination of &lt;a href=&#34;https://github.com/huggingface/diffusers&#34;&gt;Diffusers&lt;/a&gt; and &lt;a href=&#34;https://github.com/tiangolo/fastapi&#34;&gt;FastAPI&lt;/a&gt; as a starting point.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/e-johnstonn/FableForge/master/LICENSE&#34;&gt;MIT License&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>