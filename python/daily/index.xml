<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-11-07T01:34:03Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>iterative/datachain</title>
    <updated>2024-11-07T01:34:03Z</updated>
    <id>tag:github.com,2024-11-07:/iterative/datachain</id>
    <link href="https://github.com/iterative/datachain" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AI-data warehouse to enrich, transform and analyze data from cloud storages&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;================ |logo| DataChain&lt;/h1&gt; &#xA;&lt;p&gt;|PyPI| |Python Version| |Codecov| |Tests|&lt;/p&gt; &#xA;&lt;p&gt;.. |logo| image:: docs/assets/datachain.svg :height: 24 .. |PyPI| image:: &lt;a href=&#34;https://img.shields.io/pypi/v/datachain.svg&#34;&gt;https://img.shields.io/pypi/v/datachain.svg&lt;/a&gt; :target: &lt;a href=&#34;https://pypi.org/project/datachain/&#34;&gt;https://pypi.org/project/datachain/&lt;/a&gt; :alt: PyPI .. |Python Version| image:: &lt;a href=&#34;https://img.shields.io/pypi/pyversions/datachain&#34;&gt;https://img.shields.io/pypi/pyversions/datachain&lt;/a&gt; :target: &lt;a href=&#34;https://pypi.org/project/datachain&#34;&gt;https://pypi.org/project/datachain&lt;/a&gt; :alt: Python Version .. |Codecov| image:: &lt;a href=&#34;https://codecov.io/gh/iterative/datachain/graph/badge.svg?token=byliXGGyGB&#34;&gt;https://codecov.io/gh/iterative/datachain/graph/badge.svg?token=byliXGGyGB&lt;/a&gt; :target: &lt;a href=&#34;https://codecov.io/gh/iterative/datachain&#34;&gt;https://codecov.io/gh/iterative/datachain&lt;/a&gt; :alt: Codecov .. |Tests| image:: &lt;a href=&#34;https://github.com/iterative/datachain/actions/workflows/tests.yml/badge.svg&#34;&gt;https://github.com/iterative/datachain/actions/workflows/tests.yml/badge.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/iterative/datachain/actions/workflows/tests.yml&#34;&gt;https://github.com/iterative/datachain/actions/workflows/tests.yml&lt;/a&gt; :alt: Tests&lt;/p&gt; &#xA;&lt;p&gt;DataChain is a modern Pythonic data-frame library designed for artificial intelligence. It is made to organize your unstructured data into datasets and wrangle it at scale on your local machine. Datachain does not abstract or hide the AI models and API calls, but helps to integrate them into the postmodern data stack.&lt;/p&gt; &#xA;&lt;h1&gt;Key Features&lt;/h1&gt; &#xA;&lt;p&gt;üìÇ &lt;strong&gt;Storage as a Source of Truth.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Process unstructured data without redundant copies from S3, GCP, Azure, and local file systems.&lt;/li&gt; &#xA; &lt;li&gt;Multimodal data support: images, video, text, PDFs, JSONs, CSVs, parquet.&lt;/li&gt; &#xA; &lt;li&gt;Unite files and metadata together into persistent, versioned, columnar datasets.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;üêç &lt;strong&gt;Python-friendly data pipelines.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Operate on Python objects and object fields.&lt;/li&gt; &#xA; &lt;li&gt;Built-in parallelization and out-of-memory compute without SQL or Spark.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;üß† &lt;strong&gt;Data Enrichment and Processing.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Generate metadata using local AI models and LLM APIs.&lt;/li&gt; &#xA; &lt;li&gt;Filter, join, and group by metadata. Search by vector embeddings.&lt;/li&gt; &#xA; &lt;li&gt;Pass datasets to Pytorch and Tensorflow, or export them back into storage.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;üöÄ &lt;strong&gt;Efficiency.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Parallelization, out-of-memory workloads and data caching.&lt;/li&gt; &#xA; &lt;li&gt;Vectorized operations on Python object fields: sum, count, avg, etc.&lt;/li&gt; &#xA; &lt;li&gt;Optimized vector search.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;.. code:: console&lt;/p&gt; &#xA;&lt;p&gt;$ pip install datachain&lt;/p&gt; &#xA;&lt;h1&gt;Selecting files using JSON metadata&lt;/h1&gt; &#xA;&lt;p&gt;A storage consists of images of cats and dogs (&lt;code&gt;dog.1048.jpg&lt;/code&gt;, &lt;code&gt;cat.1009.jpg&lt;/code&gt;), annotated with ground truth and model inferences in the &#39;json-pairs&#39; format, where each image has a matching JSON file like &lt;code&gt;cat.1009.json&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: json&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;{&#xA;    &#34;class&#34;: &#34;cat&#34;, &#34;id&#34;: &#34;1009&#34;, &#34;num_annotators&#34;: 8,&#xA;    &#34;inference&#34;: {&#34;class&#34;: &#34;dog&#34;, &#34;confidence&#34;: 0.68}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example of downloading only &#34;high-confidence cat&#34; inferred images using JSON metadata:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from datachain import Column, DataChain&#xA;&#xA;meta = DataChain.from_json(&#34;gs://datachain-demo/dogs-and-cats/*json&#34;, object_name=&#34;meta&#34;)&#xA;images = DataChain.from_storage(&#34;gs://datachain-demo/dogs-and-cats/*jpg&#34;)&#xA;&#xA;images_id = images.map(id=lambda file: file.path.split(&#39;.&#39;)[-2])&#xA;annotated = images_id.merge(meta, on=&#34;id&#34;, right_on=&#34;meta.id&#34;)&#xA;&#xA;likely_cats = annotated.filter((Column(&#34;meta.inference.confidence&#34;) &amp;gt; 0.93) \&#xA;                               &amp;amp; (Column(&#34;meta.inference.class_&#34;) == &#34;cat&#34;))&#xA;likely_cats.export_files(&#34;high-confidence-cats/&#34;, signal=&#34;file&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Data curation with a local AI model&lt;/h1&gt; &#xA;&lt;p&gt;Batch inference with a simple sentiment model using the &lt;code&gt;transformers&lt;/code&gt; library:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install transformers&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The code below downloads files the cloud, and applies a user-defined function to each one of them. All files with a positive sentiment detected are then copied to the local directory.&lt;/p&gt; &#xA;&lt;p&gt;.. code:: py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from transformers import pipeline&#xA;from datachain import DataChain, Column&#xA;&#xA;classifier = pipeline(&#34;sentiment-analysis&#34;, device=&#34;cpu&#34;,&#xA;                model=&#34;distilbert/distilbert-base-uncased-finetuned-sst-2-english&#34;)&#xA;&#xA;def is_positive_dialogue_ending(file) -&amp;gt; bool:&#xA;    dialogue_ending = file.read()[-512:]&#xA;    return classifier(dialogue_ending)[0][&#34;label&#34;] == &#34;POSITIVE&#34;&#xA;&#xA;chain = (&#xA;   DataChain.from_storage(&#34;gs://datachain-demo/chatbot-KiT/&#34;,&#xA;                          object_name=&#34;file&#34;, type=&#34;text&#34;)&#xA;   .settings(parallel=8, cache=True)&#xA;   .map(is_positive=is_positive_dialogue_ending)&#xA;   .save(&#34;file_response&#34;)&#xA;)&#xA;&#xA;positive_chain = chain.filter(Column(&#34;is_positive&#34;) == True)&#xA;positive_chain.export_files(&#34;./output&#34;)&#xA;&#xA;print(f&#34;{positive_chain.count()} files were exported&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;13 files were exported&lt;/p&gt; &#xA;&lt;p&gt;.. code:: shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ls output/datachain-demo/chatbot-KiT/&#xA;15.txt 20.txt 24.txt 27.txt 28.txt 29.txt 33.txt 37.txt 38.txt 43.txt ...&#xA;$ ls output/datachain-demo/chatbot-KiT/ | wc -l&#xA;13&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;LLM judging chatbots&lt;/h1&gt; &#xA;&lt;p&gt;LLMs can work as universal classifiers. In the example below, we employ a free API from Mistral to judge the &lt;code&gt;publicly available&lt;/code&gt;_ chatbot dialogs. Please get a free Mistral API key at &lt;a href=&#34;https://console.mistral.ai&#34;&gt;https://console.mistral.ai&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. code:: shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pip install mistralai (Requires version &amp;gt;=1.0.0)&#xA;$ export MISTRAL_API_KEY=_your_key_&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;DataChain can parallelize API calls; the free Mistral tier supports up to 4 requests at the same time.&lt;/p&gt; &#xA;&lt;p&gt;.. code:: py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from mistralai import Mistral&#xA;from datachain import File, DataChain, Column&#xA;&#xA;PROMPT = &#34;Was this dialog successful? Answer in a single word: Success or Failure.&#34;&#xA;&#xA;def eval_dialogue(file: File) -&amp;gt; bool:&#xA;     client = Mistral()&#xA;     response = client.chat.complete(&#xA;         model=&#34;open-mixtral-8x22b&#34;,&#xA;         messages=[{&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: PROMPT},&#xA;                   {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: file.read()}])&#xA;     result = response.choices[0].message.content&#xA;     return result.lower().startswith(&#34;success&#34;)&#xA;&#xA;chain = (&#xA;   DataChain.from_storage(&#34;gs://datachain-demo/chatbot-KiT/&#34;, object_name=&#34;file&#34;)&#xA;   .settings(parallel=4, cache=True)&#xA;   .map(is_success=eval_dialogue)&#xA;   .save(&#34;mistral_files&#34;)&#xA;)&#xA;&#xA;successful_chain = chain.filter(Column(&#34;is_success&#34;) == True)&#xA;successful_chain.export_files(&#34;./output_mistral&#34;)&#xA;&#xA;print(f&#34;{successful_chain.count()} files were exported&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;With the instruction above, the Mistral model considers 31/50 files to hold the successful dialogues:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ls output_mistral/datachain-demo/chatbot-KiT/&#xA;1.txt  15.txt 18.txt 2.txt  22.txt 25.txt 28.txt 33.txt 37.txt 4.txt  41.txt ...&#xA;$ ls output_mistral/datachain-demo/chatbot-KiT/ | wc -l&#xA;31&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Serializing Python-objects&lt;/h1&gt; &#xA;&lt;p&gt;LLM responses may contain valuable information for analytics ‚Äì such as the number of tokens used, or the model performance parameters.&lt;/p&gt; &#xA;&lt;p&gt;Instead of extracting this information from the Mistral response data structure (class &lt;code&gt;ChatCompletionResponse&lt;/code&gt;), DataChain can serialize the entire LLM response to the internal DB:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from mistralai import Mistral&#xA;from mistralai.models import ChatCompletionResponse&#xA;from datachain import File, DataChain, Column&#xA;&#xA;PROMPT = &#34;Was this dialog successful? Answer in a single word: Success or Failure.&#34;&#xA;&#xA;def eval_dialog(file: File) -&amp;gt; ChatCompletionResponse:&#xA;     client = MistralClient()&#xA;     return client.chat(&#xA;         model=&#34;open-mixtral-8x22b&#34;,&#xA;         messages=[{&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: PROMPT},&#xA;                   {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: file.read()}])&#xA;&#xA;chain = (&#xA;   DataChain.from_storage(&#34;gs://datachain-demo/chatbot-KiT/&#34;, object_name=&#34;file&#34;)&#xA;   .settings(parallel=4, cache=True)&#xA;   .map(response=eval_dialog)&#xA;   .map(status=lambda response: response.choices[0].message.content.lower()[:7])&#xA;   .save(&#34;response&#34;)&#xA;)&#xA;&#xA;chain.select(&#34;file.name&#34;, &#34;status&#34;, &#34;response.usage&#34;).show(5)&#xA;&#xA;success_rate = chain.filter(Column(&#34;status&#34;) == &#34;success&#34;).count() / chain.count()&#xA;print(f&#34;{100*success_rate:.1f}% dialogs were successful&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;     file   status      response     response          response&#xA;     name                  usage        usage             usage&#xA;                   prompt_tokens total_tokens completion_tokens&#xA;0   1.txt  success           547          548                 1&#xA;1  10.txt  failure          3576         3578                 2&#xA;2  11.txt  failure           626          628                 2&#xA;3  12.txt  failure          1144         1182                38&#xA;4  13.txt  success          1100         1101                 1&#xA;&#xA;[Limited by 5 rows]&#xA;64.0% dialogs were successful&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Iterating over Python data structures&lt;/h1&gt; &#xA;&lt;p&gt;In the previous examples, datasets were saved in the embedded database (&lt;code&gt;SQLite&lt;/code&gt;_ in folder &lt;code&gt;.datachain&lt;/code&gt; of the working directory). These datasets were automatically versioned, and can be accessed using &lt;code&gt;DataChain.from_dataset(&#34;dataset_name&#34;)&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Here is how to retrieve a saved dataset and iterate over the objects:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;chain = DataChain.from_dataset(&#34;response&#34;)&#xA;&#xA;# Iterating one-by-one: support out-of-memory workflow&#xA;for file, response in chain.limit(5).collect(&#34;file&#34;, &#34;response&#34;):&#xA;    # verify the collected Python objects&#xA;    assert isinstance(response, ChatCompletionResponse)&#xA;&#xA;    status = response.choices[0].message.content[:7]&#xA;    tokens = response.usage.total_tokens&#xA;    print(f&#34;{file.get_uri()}: {status}, file size: {file.size}, tokens: {tokens}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gs://datachain-demo/chatbot-KiT/1.txt: Success, file size: 1776, tokens: 548&#xA;gs://datachain-demo/chatbot-KiT/10.txt: Failure, file size: 11576, tokens: 3578&#xA;gs://datachain-demo/chatbot-KiT/11.txt: Failure, file size: 2045, tokens: 628&#xA;gs://datachain-demo/chatbot-KiT/12.txt: Failure, file size: 3833, tokens: 1207&#xA;gs://datachain-demo/chatbot-KiT/13.txt: Success, file size: 3657, tokens: 1101&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Vectorized analytics over Python objects&lt;/h1&gt; &#xA;&lt;p&gt;Some operations can run inside the DB without deserialization. For instance, let&#39;s calculate the total cost of using the LLM APIs, assuming the Mixtral call costs $2 per 1M input tokens and $6 per 1M output tokens:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;chain = DataChain.from_dataset(&#34;mistral_dataset&#34;)&#xA;&#xA;cost = chain.sum(&#34;response.usage.prompt_tokens&#34;)*0.000002 \&#xA;           + chain.sum(&#34;response.usage.completion_tokens&#34;)*0.000006&#xA;print(f&#34;Spent ${cost:.2f} on {chain.count()} calls&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Spent $0.08 on 50 calls&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;PyTorch data loader&lt;/h1&gt; &#xA;&lt;p&gt;Chain results can be exported or passed directly to PyTorch dataloader. For example, if we are interested in passing image and a label based on file name suffix, the following code will do it:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from torch.utils.data import DataLoader&#xA;from transformers import CLIPProcessor&#xA;&#xA;from datachain import C, DataChain&#xA;&#xA;processor = CLIPProcessor.from_pretrained(&#34;openai/clip-vit-base-patch32&#34;)&#xA;&#xA;chain = (&#xA;    DataChain.from_storage(&#34;gs://datachain-demo/dogs-and-cats/&#34;, type=&#34;image&#34;)&#xA;    .map(label=lambda name: name.split(&#34;.&#34;)[0], params=[&#34;file.name&#34;])&#xA;    .select(&#34;file&#34;, &#34;label&#34;).to_pytorch(&#xA;        transform=processor.image_processor,&#xA;        tokenizer=processor.tokenizer,&#xA;    )&#xA;)&#xA;loader = DataLoader(chain, batch_size=1)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Tutorials&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Getting Started&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Multimodal &amp;lt;https://github.com/iterative/datachain-examples/blob/main/multimodal/clip_fine_tuning.ipynb&amp;gt;&lt;/code&gt;_ (try in &lt;code&gt;Colab &amp;lt;https://colab.research.google.com/github/iterative/datachain-examples/blob/main/multimodal/clip_fine_tuning.ipynb&amp;gt;&lt;/code&gt;__)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;LLM evaluations &amp;lt;https://github.com/iterative/datachain-examples/blob/main/llm/llm_chatbot_evaluation.ipynb&amp;gt;&lt;/code&gt;_ (try in &lt;code&gt;Colab &amp;lt;https://colab.research.google.com/github/iterative/datachain-examples/blob/main/llm/llm_chatbot_evaluation.ipynb&amp;gt;&lt;/code&gt;__)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Reading JSON metadata &amp;lt;https://github.com/iterative/datachain-examples/blob/main/formats/json-metadata-tutorial.ipynb&amp;gt;&lt;/code&gt;_ (try in &lt;code&gt;Colab &amp;lt;https://colab.research.google.com/github/iterative/datachain-examples/blob/main/formats/json-metadata-tutorial.ipynb&amp;gt;&lt;/code&gt;__)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributions&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are very welcome. To learn more, see the &lt;code&gt;Contributor Guide&lt;/code&gt;_.&lt;/p&gt; &#xA;&lt;h2&gt;Community and Support&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Docs &amp;lt;https://datachain.dvc.ai/&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;File an issue&lt;/code&gt;_ if you encounter any problems&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Discord Chat &amp;lt;https://dvc.org/chat&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Email &amp;lt;mailto:support@dvc.org&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Twitter &amp;lt;https://twitter.com/DVCorg&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;.. _PyPI: &lt;a href=&#34;https://pypi.org/&#34;&gt;https://pypi.org/&lt;/a&gt; .. _file an issue: &lt;a href=&#34;https://github.com/iterative/datachain/issues&#34;&gt;https://github.com/iterative/datachain/issues&lt;/a&gt; .. github-only .. _Contributor Guide: CONTRIBUTING.rst .. _Pydantic: &lt;a href=&#34;https://github.com/pydantic/pydantic&#34;&gt;https://github.com/pydantic/pydantic&lt;/a&gt; .. _publicly available: &lt;a href=&#34;https://radar.kit.edu/radar/en/dataset/FdJmclKpjHzLfExE.ExpBot%2B-%2BA%2Bdataset%2Bof%2B79%2Bdialogs%2Bwith%2Ban%2Bexperimental%2Bcustomer%2Bservice%2Bchatbot&#34;&gt;https://radar.kit.edu/radar/en/dataset/FdJmclKpjHzLfExE.ExpBot%2B-%2BA%2Bdataset%2Bof%2B79%2Bdialogs%2Bwith%2Ban%2Bexperimental%2Bcustomer%2Bservice%2Bchatbot&lt;/a&gt; .. _SQLite: &lt;a href=&#34;https://www.sqlite.org/&#34;&gt;https://www.sqlite.org/&lt;/a&gt; .. _Getting Started: &lt;a href=&#34;https://datachain.dvc.ai/&#34;&gt;https://datachain.dvc.ai/&lt;/a&gt; .. |Flowchart| image:: &lt;a href=&#34;https://github.com/iterative/datachain/raw/main/docs/assets/flowchart.png?raw=true&#34;&gt;https://github.com/iterative/datachain/blob/main/docs/assets/flowchart.png?raw=true&lt;/a&gt; :alt: DataChain FlowChart&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>matplotlib/matplotlib</title>
    <updated>2024-11-07T01:34:03Z</updated>
    <id>tag:github.com,2024-11-07:/matplotlib/matplotlib</id>
    <link href="https://github.com/matplotlib/matplotlib" rel="alternate"></link>
    <summary type="html">&lt;p&gt;matplotlib: plotting with Python&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://pypi.org/project/matplotlib/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/matplotlib&#34; alt=&#34;PyPi&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://anaconda.org/conda-forge/matplotlib&#34;&gt;&lt;img src=&#34;https://img.shields.io/conda/vn/conda-forge/matplotlib&#34; alt=&#34;Conda&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/matplotlib&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/matplotlib&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://numfocus.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&amp;amp;colorA=E1523D&amp;amp;colorB=007D8A&#34; alt=&#34;NUMFocus&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discourse.matplotlib.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/help_forum-discourse-blue.svg?sanitize=true&#34; alt=&#34;Discourse help forum&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/matplotlib/matplotlib&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/matplotlib/matplotlib.svg?sanitize=true&#34; alt=&#34;Gitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/matplotlib/matplotlib/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/issue_tracking-github-blue.svg?sanitize=true&#34; alt=&#34;GitHub issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://matplotlib.org/stable/devel/index.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PR-Welcome-%23FF8300.svg?&#34; alt=&#34;Contributing&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/matplotlib/matplotlib/actions?query=workflow%3ATests&#34;&gt;&lt;img src=&#34;https://github.com/matplotlib/matplotlib/workflows/Tests/badge.svg?sanitize=true&#34; alt=&#34;GitHub actions status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://dev.azure.com/matplotlib/matplotlib/_build/latest?definitionId=1&amp;amp;branchName=main&#34;&gt;&lt;img src=&#34;https://dev.azure.com/matplotlib/matplotlib/_apis/build/status/matplotlib.matplotlib?branchName=main&#34; alt=&#34;Azure pipelines status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://ci.appveyor.com/project/matplotlib/matplotlib&#34;&gt;&lt;img src=&#34;https://ci.appveyor.com/api/projects/status/github/matplotlib/matplotlib?branch=main&amp;amp;svg=true&#34; alt=&#34;AppVeyor status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.codecov.io/gh/matplotlib/matplotlib&#34;&gt;&lt;img src=&#34;https://codecov.io/github/matplotlib/matplotlib/badge.svg?branch=main&amp;amp;service=github&#34; alt=&#34;Codecov status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://jacobtomlinson.dev/effver&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/version_scheme-EffVer-0097a7&#34; alt=&#34;EffVer Versioning&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://matplotlib.org/_static/logo2.svg?sanitize=true&#34; alt=&#34;Matplotlib logotype&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.&lt;/p&gt; &#xA;&lt;p&gt;Check out our &lt;a href=&#34;https://matplotlib.org/&#34;&gt;home page&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://matplotlib.org/_static/readme_preview.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Matplotlib produces publication-quality figures in a variety of hardcopy formats and interactive environments across platforms. Matplotlib can be used in Python scripts, Python/IPython shells, web application servers, and various graphical user interface toolkits.&lt;/p&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://matplotlib.org/stable/users/installing/index.html&#34;&gt;install documentation&lt;/a&gt;, which is generated from &lt;code&gt;/doc/install/index.rst&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contribute&lt;/h2&gt; &#xA;&lt;p&gt;You&#39;ve discovered a bug or something else you want to change ‚Äî excellent!&lt;/p&gt; &#xA;&lt;p&gt;You&#39;ve worked out a way to fix it ‚Äî even better!&lt;/p&gt; &#xA;&lt;p&gt;You want to tell us about it ‚Äî best of all!&lt;/p&gt; &#xA;&lt;p&gt;Start at the &lt;a href=&#34;https://matplotlib.org/devdocs/devel/contribute.html&#34;&gt;contributing guide&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discourse.matplotlib.org/&#34;&gt;Discourse&lt;/a&gt; is the discussion forum for general questions and discussions and our recommended starting point.&lt;/p&gt; &#xA;&lt;p&gt;Our active mailing lists (which are mirrored on Discourse) are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mail.python.org/mailman/listinfo/matplotlib-users&#34;&gt;Users&lt;/a&gt; mailing list: &lt;a href=&#34;mailto:matplotlib-users@python.org&#34;&gt;matplotlib-users@python.org&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mail.python.org/mailman/listinfo/matplotlib-announce&#34;&gt;Announcement&lt;/a&gt; mailing list: &lt;a href=&#34;mailto:matplotlib-announce@python.org&#34;&gt;matplotlib-announce@python.org&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mail.python.org/mailman/listinfo/matplotlib-devel&#34;&gt;Development&lt;/a&gt; mailing list: &lt;a href=&#34;mailto:matplotlib-devel@python.org&#34;&gt;matplotlib-devel@python.org&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitter.im/matplotlib/matplotlib&#34;&gt;Gitter&lt;/a&gt; is for coordinating development and asking questions directly related to contributing to matplotlib.&lt;/p&gt; &#xA;&lt;h2&gt;Citing Matplotlib&lt;/h2&gt; &#xA;&lt;p&gt;If Matplotlib contributes to a project that leads to publication, please acknowledge this by citing Matplotlib.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://matplotlib.org/stable/users/project/citing.html&#34;&gt;A ready-made citation entry&lt;/a&gt; is available.&lt;/p&gt;</summary>
  </entry>
</feed>