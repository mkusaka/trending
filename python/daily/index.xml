<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-05-26T01:36:40Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>city96/ComfyUI-GGUF</title>
    <updated>2025-05-26T01:36:40Z</updated>
    <id>tag:github.com,2025-05-26:/city96/ComfyUI-GGUF</id>
    <link href="https://github.com/city96/ComfyUI-GGUF" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GGUF Quantization support for native ComfyUI models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ComfyUI-GGUF&lt;/h1&gt; &#xA;&lt;p&gt;GGUF Quantization support for native ComfyUI models&lt;/p&gt; &#xA;&lt;p&gt;This is currently very much WIP. These custom nodes provide support for model files stored in the GGUF format popularized by &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;While quantization wasn&#39;t feasible for regular UNET models (conv2d), transformer/DiT models such as flux seem less affected by quantization. This allows running it in much lower bits per weight variable bitrate quants on low-end GPUs. For further VRAM savings, a node to load a quantized version of the T5 text encoder is also included.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/70d16d97-c522-4ef4-9435-633f128644c8&#34; alt=&#34;Comfy_Flux1_dev_Q4_0_GGUF_1024&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Note: The &#34;Force/Set CLIP Device&#34; is &lt;strong&gt;NOT&lt;/strong&gt; part of this node pack. Do not install it if you only have one GPU. Do not set it to cuda:0 then complain about OOM errors if you do not undestand what it is for. There is not need to copy the workflow above, just use your own workflow and replace the stock &#34;Load Diffusion Model&#34; with the &#34;Unet Loader (GGUF)&#34; node.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT]&lt;br&gt; Make sure your ComfyUI is on a recent-enough version to support custom ops when loading the UNET-only.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;To install the custom node normally, git clone this repository into your custom nodes folder (&lt;code&gt;ComfyUI/custom_nodes&lt;/code&gt;) and install the only dependency for inference (&lt;code&gt;pip install --upgrade gguf&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/city96/ComfyUI-GGUF&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To install the custom node on a standalone ComfyUI release, open a CMD inside the &#34;ComfyUI_windows_portable&#34; folder (where your &lt;code&gt;run_nvidia_gpu.bat&lt;/code&gt; file is) and use the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/city96/ComfyUI-GGUF ComfyUI/custom_nodes/ComfyUI-GGUF&#xA;.\python_embeded\python.exe -s -m pip install -r .\ComfyUI\custom_nodes\ComfyUI-GGUF\requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On MacOS sequoia, torch 2.4.1 seems to be required, as 2.6.X nightly versions cause a &#34;M1 buffer is not large enough&#34; error. See &lt;a href=&#34;https://github.com/city96/ComfyUI-GGUF/issues/107&#34;&gt;this issue&lt;/a&gt; for more information/workarounds.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Simply use the GGUF Unet loader found under the &lt;code&gt;bootleg&lt;/code&gt; category. Place the .gguf model files in your &lt;code&gt;ComfyUI/models/unet&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;p&gt;LoRA loading is experimental but it should work with just the built-in LoRA loader node(s).&lt;/p&gt; &#xA;&lt;p&gt;Pre-quantized models:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/city96/FLUX.1-dev-gguf&#34;&gt;flux1-dev GGUF&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/city96/FLUX.1-schnell-gguf&#34;&gt;flux1-schnell GGUF&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/city96/stable-diffusion-3.5-large-gguf&#34;&gt;stable-diffusion-3.5-large GGUF&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/city96/stable-diffusion-3.5-large-turbo-gguf&#34;&gt;stable-diffusion-3.5-large-turbo GGUF&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Initial support for quantizing T5 has also been added recently, these can be used using the various &lt;code&gt;*CLIPLoader (gguf)&lt;/code&gt; nodes which can be used inplace of the regular ones. For the CLIP model, use whatever model you were using before for CLIP. The loader can handle both types of files - &lt;code&gt;gguf&lt;/code&gt; and regular &lt;code&gt;safetensors&lt;/code&gt;/&lt;code&gt;bin&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/city96/t5-v1_1-xxl-encoder-gguf&#34;&gt;t5_v1.1-xxl GGUF&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See the instructions in the &lt;a href=&#34;https://github.com/city96/ComfyUI-GGUF/tree/main/tools&#34;&gt;tools&lt;/a&gt; folder for how to create your own quants.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>MaiM-with-u/MaiBot</title>
    <updated>2025-05-26T01:36:40Z</updated>
    <id>tag:github.com,2025-05-26:/MaiM-with-u/MaiBot</id>
    <link href="https://github.com/MaiM-with-u/MaiBot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;麦麦bot，一款专注于 群组聊天 的赛博网友（比较专注）多平台智能体&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; &#xA; &lt;source media=&#34;(max-width: 600px)&#34; srcset=&#34;depends-data/maimai.png&#34; width=&#34;100%&#34;&gt; &#xA; &lt;img alt=&#34;MaiBot&#34; src=&#34;https://raw.githubusercontent.com/MaiM-with-u/MaiBot/main/depends-data/maimai.png&#34; title=&#34;作者:略nd&#34; align=&#34;right&#34; width=&#34;30%&#34;&gt; &#xA;&lt;/picture&gt; &#xA;&lt;h1&gt;麦麦！MaiCore-MaiBot (编辑中)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-3.10+-blue&#34; alt=&#34;Python Version&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/SengokuCola/MaiMBot?label=%E5%8D%8F%E8%AE%AE&#34; alt=&#34;License&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/%E7%8A%B6%E6%80%81-%E5%BC%80%E5%8F%91%E4%B8%AD-yellow&#34; alt=&#34;Status&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/contributors/MaiM-with-u/MaiBot.svg?style=flat&amp;amp;label=%E8%B4%A1%E7%8C%AE%E8%80%85&#34; alt=&#34;Contributors&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/forks/MaiM-with-u/MaiBot.svg?style=flat&amp;amp;label=%E5%88%86%E6%94%AF%E6%95%B0&#34; alt=&#34;forks&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/MaiM-with-u/MaiBot?style=flat&amp;amp;label=%E6%98%9F%E6%A0%87%E6%95%B0&#34; alt=&#34;stars&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/issues/MaiM-with-u/MaiBot&#34; alt=&#34;issues&#34;&gt; &lt;a href=&#34;https://deepwiki.com/DrSmoothl/MaiBot&#34;&gt;&lt;img src=&#34;https://deepwiki.com/badge.svg?sanitize=true&#34; alt=&#34;Ask DeepWiki&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;strong&gt; &lt;a href=&#34;https://www.bilibili.com/video/BV1amAneGE3P&#34;&gt;🌟 演示视频&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/MaiM-with-u/MaiBot/main/#-%E6%9B%B4%E6%96%B0%E5%92%8C%E5%AE%89%E8%A3%85&#34;&gt;🚀 快速入门&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/MaiM-with-u/MaiBot/main/#-%E6%96%87%E6%A1%A3&#34;&gt;📃 教程&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/MaiM-with-u/MaiBot/main/#-%E8%AE%A8%E8%AE%BA&#34;&gt;💬 讨论&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/MaiM-with-u/MaiBot/main/#-%E8%B4%A1%E7%8C%AE%E5%92%8C%E8%87%B4%E8%B0%A2&#34;&gt;🙋 贡献指南&lt;/a&gt; &lt;/strong&gt; &#xA;&lt;h2&gt;🎉 介绍&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;🍔MaiCore 是一个基于大语言模型的可交互智能体&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;💭 &lt;strong&gt;智能对话系统&lt;/strong&gt;：基于 LLM 的自然语言交互。&lt;/li&gt; &#xA; &lt;li&gt;🤔 &lt;strong&gt;实时思维系统&lt;/strong&gt;：模拟人类思考过程。&lt;/li&gt; &#xA; &lt;li&gt;💝 &lt;strong&gt;情感表达系统&lt;/strong&gt;：丰富的表情包和情绪表达。&lt;/li&gt; &#xA; &lt;li&gt;🧠 &lt;strong&gt;持久记忆系统&lt;/strong&gt;：基于 MongoDB 的长期记忆存储。&lt;/li&gt; &#xA; &lt;li&gt;🔄 &lt;strong&gt;动态人格系统&lt;/strong&gt;：自适应的性格特征。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div style=&#34;text-align: center&#34;&gt; &#xA; &lt;a href=&#34;https://www.bilibili.com/video/BV1amAneGE3P&#34; target=&#34;_blank&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(max-width: 600px)&#34; srcset=&#34;depends-data/video.png&#34; width=&#34;100%&#34;&gt; &#xA;   &lt;img src=&#34;https://raw.githubusercontent.com/MaiM-with-u/MaiBot/main/depends-data/video.png&#34; width=&#34;30%&#34; alt=&#34;麦麦演示视频&#34;&gt; &#xA;  &lt;/picture&gt; &lt;br&gt; 👆 点击观看麦麦演示视频 👆 &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;🔥 更新和安装&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;最新版本: v0.6.3&lt;/strong&gt; (&lt;a href=&#34;https://raw.githubusercontent.com/MaiM-with-u/MaiBot/main/changelogs/changelog.md&#34;&gt;更新日志&lt;/a&gt;) 可前往 &lt;a href=&#34;https://github.com/MaiM-with-u/MaiBot/releases/&#34;&gt;Release&lt;/a&gt; 页面下载最新版本 &lt;strong&gt;GitHub 分支说明：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;main&lt;/code&gt;: 稳定发布版本(推荐)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;dev&lt;/code&gt;: 开发测试版本(不稳定)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;classical&lt;/code&gt;: 旧版本(停止维护)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;最新版本部署教程 (MaiCore 版本)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.mai-mai.org/manual/deployment/mmc_deploy_windows.html&#34;&gt;🚀 最新版本部署教程&lt;/a&gt; - 基于 MaiCore 的新版本部署方式(与旧版本不兼容)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!WARNING]&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;从 0.5.x 旧版本升级前请务必阅读：&lt;a href=&#34;https://docs.mai-mai.org/faq/maibot/backup_update.html&#34;&gt;升级指南&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;项目处于活跃开发阶段，功能和 API 可能随时调整。&lt;/li&gt; &#xA;  &lt;li&gt;文档未完善，有问题可以提交 Issue 或者 Discussion。&lt;/li&gt; &#xA;  &lt;li&gt;QQ 机器人存在被限制风险，请自行了解，谨慎使用。&lt;/li&gt; &#xA;  &lt;li&gt;由于持续迭代，可能存在一些已知或未知的 bug。&lt;/li&gt; &#xA;  &lt;li&gt;由于程序处于开发中，可能消耗较多 token。&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;💬 讨论&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://qm.qq.com/q/VQ3XZrWgMs&#34;&gt;一群&lt;/a&gt; | &lt;a href=&#34;https://qm.qq.com/q/wGePTl1UyY&#34;&gt;四群&lt;/a&gt; | &lt;a href=&#34;https://qm.qq.com/q/RzmCiRtHEW&#34;&gt;二群&lt;/a&gt; | &lt;a href=&#34;https://qm.qq.com/q/JxvHZnxyec&#34;&gt;五群&lt;/a&gt;(已满) | &lt;a href=&#34;https://qm.qq.com/q/wlH5eT8OmQ&#34;&gt;三群&lt;/a&gt;(已满)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;📚 文档&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;部分内容可能更新不够及时，请注意版本对应&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.mai-mai.org&#34;&gt;📚 核心 Wiki 文档&lt;/a&gt; - 项目最全面的文档中心，你可以了解麦麦有关的一切。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;设计理念(原始时代的火花)&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;千石可乐说：&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;这个项目最初只是为了给牛牛 bot 添加一点额外的功能，但是功能越写越多，最后决定重写。其目的是为了创造一个活跃在 QQ 群聊的&#34;生命体&#34;。目的并不是为了写一个功能齐全的机器人，而是一个尽可能让人感知到真实的类人存在。&lt;/li&gt; &#xA;  &lt;li&gt;程序的功能设计理念基于一个核心的原则：&#34;最像而不是好&#34;。&lt;/li&gt; &#xA;  &lt;li&gt;如果人类真的需要一个 AI 来陪伴自己，并不是所有人都需要一个完美的，能解决所有问题的&#34;helpful assistant&#34;，而是一个会犯错的，拥有自己感知和想法的&#34;生命形式&#34;。&lt;/li&gt; &#xA;  &lt;li&gt;代码会保持开源和开放，但个人希望 MaiMbot 的运行时数据保持封闭，尽量避免以显式命令来对其进行控制和调试。我认为一个你无法完全掌控的个体才更能让你感觉到它的自主性，而视其成为一个对话机器。&lt;/li&gt; &#xA;  &lt;li&gt;SengokuCola&lt;del&gt;纯编程外行，面向 cursor 编程，很多代码写得不好多多包涵&lt;/del&gt;已得到大脑升级。&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;🙋 贡献和致谢&lt;/h2&gt; &#xA;&lt;p&gt;你可以阅读&lt;a href=&#34;https://docs.mai-mai.org/develop/&#34;&gt;开发文档&lt;/a&gt;来更好的了解麦麦!&lt;br&gt; MaiCore 是一个开源项目，我们非常欢迎你的参与。你的贡献，无论是提交 bug 报告、功能需求还是代码 pr，都对项目非常宝贵。我们非常感谢你的支持！🎉&lt;br&gt; 但无序的讨论会降低沟通效率，进而影响问题的解决速度，因此在提交任何贡献前，请务必先阅读本项目的&lt;a href=&#34;https://raw.githubusercontent.com/MaiM-with-u/MaiBot/main/docs/CONTRIBUTE.md&#34;&gt;贡献指南&lt;/a&gt;。(待补完)&lt;/p&gt; &#xA;&lt;h3&gt;贡献者&lt;/h3&gt; &#xA;&lt;p&gt;感谢各位大佬！&lt;/p&gt; &#xA;&lt;a href=&#34;https://github.com/MaiM-with-u/MaiBot/graphs/contributors&#34;&gt; &lt;img alt=&#34;contributors&#34; src=&#34;https://contrib.rocks/image?repo=MaiM-with-u/MaiBot&#34;&gt; &lt;/a&gt; &#xA;&lt;h3&gt;致谢&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://space.bilibili.com/1344099355&#34;&gt;略nd&lt;/a&gt;: 为麦麦绘制人设。&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/NapNeko/NapCatQQ&#34;&gt;NapCat&lt;/a&gt;: 现代化的基于 NTQQ 的 Bot 协议端实现。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;也感谢每一位给麦麦发展提出宝贵意见与建议的用户，感谢陪伴麦麦走到现在的你们！&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;📌 注意事项&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!WARNING] 使用本项目前必须阅读和同意&lt;a href=&#34;https://raw.githubusercontent.com/MaiM-with-u/MaiBot/main/EULA.md&#34;&gt;用户协议&lt;/a&gt;和&lt;a href=&#34;https://raw.githubusercontent.com/MaiM-with-u/MaiBot/main/PRIVACY.md&#34;&gt;隐私协议&lt;/a&gt;。&lt;br&gt; 本应用生成内容来自人工智能模型，由 AI 生成，请仔细甄别，请勿用于违反法律的用途，AI 生成内容不代表本项目团队的观点和立场。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;麦麦仓库状态&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://repobeats.axiom.co/api/embed/9faca9fccfc467931b87dd357b60c6362b5cfae0.svg?sanitize=true&#34; alt=&#34;Alt&#34; title=&#34;麦麦仓库状态&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Star 趋势&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://starchart.cc/MaiM-with-u/MaiBot&#34;&gt;&lt;img src=&#34;https://starchart.cc/MaiM-with-u/MaiBot.svg?variant=adaptive&#34; alt=&#34;Star 趋势&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;GPL-3.0&lt;/p&gt;</summary>
  </entry>
</feed>