<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-07-21T01:35:07Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>hkchengrex/XMem</title>
    <updated>2022-07-21T01:35:07Z</updated>
    <id>tag:github.com,2022-07-21:/hkchengrex/XMem</id>
    <link href="https://github.com/hkchengrex/XMem" rel="alternate"></link>
    <summary type="html">&lt;p&gt;[ECCV 2022] XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;XMem&lt;/h1&gt; &#xA;&lt;h2&gt;Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hkchengrex.github.io/&#34;&gt;Ho Kei Cheng&lt;/a&gt;, &lt;a href=&#34;https://www.alexander-schwing.de/&#34;&gt;Alexander Schwing&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;University of Illinois Urbana-Champaign&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2207.07115&#34;&gt;[arXiv]&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/pdf/2207.07115.pdf&#34;&gt;[PDF]&lt;/a&gt; &lt;a href=&#34;https://hkchengrex.github.io/XMem/&#34;&gt;[Project Page]&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/drive/1RXK5QsUo2-CnOiy5AOSjoZggPVHOPh1m?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;Handling long-term occlusion:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/7107196/177921527-7a1bd593-2162-4598-9adf-f2112763fccf.mp4&#34;&gt;https://user-images.githubusercontent.com/7107196/177921527-7a1bd593-2162-4598-9adf-f2112763fccf.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Very-long video; masked layer insertion:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/7107196/179089789-3d69adea-0405-4c83-ac28-45f59fe1e1c1.mp4&#34;&gt;https://user-images.githubusercontent.com/7107196/179089789-3d69adea-0405-4c83-ac28-45f59fe1e1c1.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.youtube.com/watch?v=q5Xr0F4a0iU&#34;&gt;https://www.youtube.com/watch?v=q5Xr0F4a0iU&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Out-of-domain case:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/7107196/177920383-161f1da1-33f9-48b3-b8b2-09e450432e2b.mp4&#34;&gt;https://user-images.githubusercontent.com/7107196/177920383-161f1da1-33f9-48b3-b8b2-09e450432e2b.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Source: ã‹ãã‚„æ§˜ã¯å‘Šã‚‰ã›ãŸã„ ï½å¤©æ‰ãŸã¡ã®æ‹æ„›é ­è„³æˆ¦ï½ Ep.3; A1 Pictures&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hkchengrex/XMem/main/docs/FAILURE_CASES.md&#34;&gt;[Failure Cases]&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Handle very long videos with limited GPU memory usage.&lt;/li&gt; &#xA; &lt;li&gt;Quite fast. Expect ~20 FPS even with long videos (hardware dependent).&lt;/li&gt; &#xA; &lt;li&gt;Come with a GUI (modified from &lt;a href=&#34;https://github.com/hkchengrex/MiVOS/tree/MiVOS-STCN&#34;&gt;MiVOS&lt;/a&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Table of Contents&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hkchengrex/XMem/main/#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hkchengrex/XMem/main/docs/RESULTS.md&#34;&gt;Results&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hkchengrex/XMem/main/docs/DEMO.md&#34;&gt;Interactive GUI demo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hkchengrex/XMem/main/#traininginference&#34;&gt;Training/inference&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hkchengrex/XMem/main/#citation&#34;&gt;Citation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Introduction&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://imgur.com/ToE2frx.jpg&#34; alt=&#34;framework&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;We frame Video Object Segmentation (VOS), first and foremost, as a &lt;em&gt;memory&lt;/em&gt; problem. Prior works mostly use a single type of feature memory. This can be in the form of network weights (i.e., online learning), last frame segmentation (e.g., MaskTrack), spatial hidden representation (e.g., Conv-RNN-based methods), spatial-attentional features (e.g., STM, STCN, AOT), or some sort of long-term compact features (e.g., AFB-URR).&lt;/p&gt; &#xA;&lt;p&gt;Methods with a short memory span are not robust to changes while those with a large memory bank are subject to a catastrophic increase in computation and GPU memory usage. Attempts at long-term attentional VOS like AFB-URR compress features eagerly as soon as they are generated, leading to a loss of feature resolution.&lt;/p&gt; &#xA;&lt;p&gt;Our method is inspired by the Atkinson-Shiffrin human memory model that has a &lt;em&gt;sensory memory&lt;/em&gt;, a &lt;em&gt;working memory&lt;/em&gt;, and a &lt;em&gt;long-term memory&lt;/em&gt;. These memory stores have different temporal scales and complement each other in our memory reading mechanism. It performs well in both short-term and long-term video datasets, handling videos with more than 10,000 frames with ease.&lt;/p&gt; &#xA;&lt;h3&gt;Training/inference&lt;/h3&gt; &#xA;&lt;p&gt;First, install the required python packages and datasets following &lt;a href=&#34;https://raw.githubusercontent.com/hkchengrex/XMem/main/docs/GETTING_STARTED.md&#34;&gt;GETTING_STARTED.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For training, see &lt;a href=&#34;https://raw.githubusercontent.com/hkchengrex/XMem/main/docs/TRAINING.md&#34;&gt;TRAINING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For inference, see &lt;a href=&#34;https://raw.githubusercontent.com/hkchengrex/XMem/main/docs/INFERENCE.md&#34;&gt;INFERENCE.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Citation&lt;/h3&gt; &#xA;&lt;p&gt;Please cite our paper if you find this repo useful!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{cheng2022xmem,&#xA;  title={{XMem}: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model},&#xA;  author={Cheng, Ho Kei and Alexander G. Schwing},&#xA;  booktitle={ECCV},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Related projects that this paper is developed upon:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{cheng2021stcn,&#xA;  title={Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation},&#xA;  author={Cheng, Ho Kei and Tai, Yu-Wing and Tang, Chi-Keung},&#xA;  booktitle={NeurIPS},&#xA;  year={2021}&#xA;}&#xA;&#xA;@inproceedings{cheng2021mivos,&#xA;  title={Modular Interactive Video Object Segmentation: Interaction-to-Mask, Propagation and Difference-Aware Fusion},&#xA;  author={Cheng, Ho Kei and Tai, Yu-Wing and Tang, Chi-Keung},&#xA;  booktitle={CVPR},&#xA;  year={2021}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We use f-BRS in the interactive demo: &lt;a href=&#34;https://github.com/saic-vul/fbrs_interactive_segmentation&#34;&gt;https://github.com/saic-vul/fbrs_interactive_segmentation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;And if you want to cite the datasets:&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;p&gt;bibtex&lt;/p&gt; &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{shi2015hierarchicalECSSD,&#xA;  title={Hierarchical image saliency detection on extended CSSD},&#xA;  author={Shi, Jianping and Yan, Qiong and Xu, Li and Jia, Jiaya},&#xA;  booktitle={TPAMI},&#xA;  year={2015},&#xA;}&#xA;&#xA;@inproceedings{wang2017DUTS,&#xA;  title={Learning to Detect Salient Objects with Image-level Supervision},&#xA;  author={Wang, Lijun and Lu, Huchuan and Wang, Yifan and Feng, Mengyang &#xA;  and Wang, Dong, and Yin, Baocai and Ruan, Xiang}, &#xA;  booktitle={CVPR},&#xA;  year={2017}&#xA;}&#xA;&#xA;@inproceedings{FSS1000,&#xA;  title = {FSS-1000: A 1000-Class Dataset for Few-Shot Segmentation},&#xA;  author = {Li, Xiang and Wei, Tianhan and Chen, Yau Pun and Tai, Yu-Wing and Tang, Chi-Keung},&#xA;  booktitle={CVPR},&#xA;  year={2020}&#xA;}&#xA;&#xA;@inproceedings{zeng2019towardsHRSOD,&#xA;  title = {Towards High-Resolution Salient Object Detection},&#xA;  author = {Zeng, Yi and Zhang, Pingping and Zhang, Jianming and Lin, Zhe and Lu, Huchuan},&#xA;  booktitle = {ICCV},&#xA;  year = {2019}&#xA;}&#xA;&#xA;@inproceedings{cheng2020cascadepsp,&#xA;  title={{CascadePSP}: Toward Class-Agnostic and Very High-Resolution Segmentation via Global and Local Refinement},&#xA;  author={Cheng, Ho Kei and Chung, Jihoon and Tai, Yu-Wing and Tang, Chi-Keung},&#xA;  booktitle={CVPR},&#xA;  year={2020}&#xA;}&#xA;&#xA;@inproceedings{xu2018youtubeVOS,&#xA;  title={Youtube-vos: A large-scale video object segmentation benchmark},&#xA;  author={Xu, Ning and Yang, Linjie and Fan, Yuchen and Yue, Dingcheng and Liang, Yuchen and Yang, Jianchao and Huang, Thomas},&#xA;  booktitle = {ECCV},&#xA;  year={2018}&#xA;}&#xA;&#xA;@inproceedings{perazzi2016benchmark,&#xA;  title={A benchmark dataset and evaluation methodology for video object segmentation},&#xA;  author={Perazzi, Federico and Pont-Tuset, Jordi and McWilliams, Brian and Van Gool, Luc and Gross, Markus and Sorkine-Hornung, Alexander},&#xA;  booktitle={CVPR},&#xA;  year={2016}&#xA;}&#xA;&#xA;@inproceedings{denninger2019blenderproc,&#xA;  title={BlenderProc},&#xA;  author={Denninger, Maximilian and Sundermeyer, Martin and Winkelbauer, Dominik and Zidan, Youssef and Olefir, Dmitry and Elbadrawy, Mohamad and Lodhi, Ahsan and Katam, Harinandan},&#xA;  booktitle={arXiv:1911.01911},&#xA;  year={2019}&#xA;}&#xA;&#xA;@inproceedings{shapenet2015,&#xA;  title       = {{ShapeNet: An Information-Rich 3D Model Repository}},&#xA;  author      = {Chang, Angel Xuan and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and Xiao, Jianxiong and Yi, Li and Yu, Fisher},&#xA;  booktitle   = {arXiv:1512.03012},&#xA;  year        = {2015}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;Contact: &lt;a href=&#34;mailto:hkchengrex@gmail.com&#34;&gt;hkchengrex@gmail.com&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>RimoChan/unvcode</title>
    <updated>2022-07-21T01:35:07Z</updated>
    <id>tag:github.com,2022-07-21:/RimoChan/unvcode</id>
    <link href="https://github.com/RimoChan/unvcode" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ã€å¹¼å¥³Codeã€‘åå’Œè°è¶…çº§æ­¦å™¨ï¼&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ã€å¹¼å¥³Codeã€‘åå’Œè°è¶…çº§æ­¦å™¨ï¼&lt;/h1&gt; &#xA;&lt;p&gt;ä½ è¿˜åœ¨å› ä¸ºåœ¨ç¾¤åé‡ŒåŠ å…¥è‰²å›¾è€Œè¢«QQæ”¹æˆä¸€ä¸ªã€Œ*ã€è€Œè‹¦æ¼å—ï¼Ÿä½ è¿˜åœ¨å› ä¸ºåœ¨çº¢åŒ…ç¥ç¦é‡Œå†™ã€Œå¹´è½»äººå¥½å¥½è‡ªæ…°ã€è€Œç™½ç™½èŠ±é’±å—ï¼Ÿ&lt;/p&gt; &#xA;&lt;p&gt;å¿«ä½¿ç”¨&lt;strong&gt;å¹¼å¥³Code&lt;/strong&gt;å§ï¼&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;å¹¼å¥³Code&lt;/strong&gt;ä½¿ç”¨Librianå¹¼å¥³å¨±ä¹ä¸­å¿ƒæœ€æ–°ç ”å‘çš„&lt;strong&gt;unvcode&lt;/strong&gt;ï¼Œå¯ä»¥å¿«é€Ÿè§£å†³ä½ çš„ä¸€åˆ‡é—®é¢˜ï¼&lt;/p&gt; &#xA;&lt;h2&gt;åŸç†&lt;/h2&gt; &#xA;&lt;p&gt;åœ¨unicodeä¸­&lt;sub&gt;(æ³¨æ„è¿™ä¸æ˜¯unvcode)&lt;/sub&gt;ï¼Œæœ‰å¾ˆå¤šå­—ï¼Œå®ƒä»¬çœ‹èµ·æ¥é•¿å¾—å¾ˆåƒï¼Œä½†æ˜¯å®ƒä»¬çš„ordä¸ä¸€æ ·ã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¿™æ ·ä¸€æ¥ï¼Œåªè¦æŠŠå­—ç¬¦ä¸²é‡ŒåŸæœ¬çš„å­—â€¦â€¦å•Šï¼Œç‚¹åˆ°ä¸ºæ­¢ï¼Œå†è¯´ä¸‹å»å°±ä¸å¥½ç©äº†ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;æ•ˆæœ&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/RimoChan/unvcode/slave/doc/2333.jpg&#34; alt=&#34;./doc/2333.jpg&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;å¹¼å¥³Code&lt;/strong&gt;çœŸæ˜¯å¤ªæ£’äº†ï¼&lt;/p&gt; &#xA;&lt;h2&gt;åœ¨çº¿Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://unvcode.librian.net/&#34;&gt;https://unvcode.librian.net/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;å› ä¸ºJSå¤„ç†å›¾åƒå¾ˆéº»çƒ¦ï¼Œæ‰€ä»¥è¿™æ˜¯æŠŠä¸­é—´ç»“æœæ‰“è¡¨åˆ°ä»£ç é‡Œçš„ï¼Œå¦‚æœå’ŒPythonçš„è¾“å‡ºå¯¹ä¸é½æ˜¯æ­£å¸¸ç°è±¡ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;æ¥å£&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def unvcode(s: str, skip_ascii=True, mse=0.1) -&amp;gt; Tuple[str, Tuple[float, ...]]:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;è¾“å…¥ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè¿”å›æ”¹å˜åçš„å­—ç¬¦ä¸²ã€æ¯ä¸ªå­—ç¬¦è¢«æ”¹å˜åä¸åŸæœ¬çš„åƒç´ å·®å¼‚&lt;sub&gt;(æ²¡å˜å°±æ˜¯None)&lt;/sub&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å¦‚æœ&lt;code&gt;skip_ascii&lt;/code&gt;å¼€å¯åˆ™ä¼šè·³è¿‡asciiå­—ç¬¦ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;mse&lt;/code&gt;æ˜¯å­—ç¬¦ç›¸ä¼¼åº¦çš„é˜ˆå€¼ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æ ·ä¾‹:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import unvcode&#xA;s, var = unvcode.unvcode(&#39;Librianå¹¼å¥³å¨±ä¹ä¸­å¿ƒå¼€ä¸šäº†ï¼Œæ³¨å†Œå³é€è‰²å›¾ï¼&#39;)&#xA;print(s) &#xA;print(var) &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;è¾“å‡º:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Librianå¹¼â¼¥å¨±ä¹ã†—â¼¼å¼€ä¸šï¦ºï¼Œæ³¨å†Œå³é€â¾Šå›¾ï¼&#xA;(None, None, None, None, None, None, None, None, 0.0, None, None, 0.009146429779930796, 0.0, None, None, 0.0, None, None, None, None, None, 0.0, None, None)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æ³¨æ„ï¼Œè¿™å¥è¯çœ‹èµ·æ¥çš„æ ·å­å–å†³äºä½ çš„ç³»ç»Ÿå­—ä½“ï¼Œæ‰€ä»¥æˆ‘ä¹Ÿä¸çŸ¥é“å®ƒä¼šæ˜¯ä»€ä¹ˆæ ·çš„â€¦â€¦å› ä¸ºæœ‰ä¸€äº›å­—åœ¨Aå­—ä½“ä¸‹çœ‹èµ·æ¥æ˜¯ä¸€æ ·çš„ï¼Œä½†æ˜¯åœ¨Bå­—ä½“ä¸‹çœ‹èµ·æ¥å°±ä¸ä¸€æ ·ã€‚&lt;/p&gt; &#xA;&lt;p&gt;é»˜è®¤çš„å­—ä½“æ˜¯æ€æºå®‹ä½“ï¼Œæ€æºå®‹ä½“å¥½å•Šã€‚&lt;br&gt; å¦‚æœä½ è¦é€‰æ‹©å­—ä½“ï¼Œæ¯”å¦‚ç”¨å¾®è½¯é›…é»‘ï¼Œé‚£å°±&lt;code&gt;unvcode.font = &#39;msyh.ttc&#39;&lt;/code&gt;ï¼Œé¡ºä¾¿ä¸€æï¼Œæˆ‘å‘ç°&lt;code&gt;YuGothM.ttc&lt;/code&gt;çš„æ•ˆæœæ˜¯æœ€å¥½çš„â€¦â€¦&lt;/p&gt; &#xA;&lt;h2&gt;å®‰è£…&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install unvcode&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ç„¶ååœ¨ä»£ç é‡Œ&lt;code&gt;import unvcode&lt;/code&gt;å°±è¡Œäº†ï¼Œå°±æ˜¯è¿™ä¹ˆç®€å•ï¼&lt;/p&gt; &#xA;&lt;h2&gt;ç»“æŸ&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœä½ è§‰å¾—å¹¼å¥³Codeå¯¹ä½ çš„å·¥ä½œæˆ–å­¦ä¹ æœ‰æ‰€å¸®åŠ©ï¼Œæ¬¢è¿ç»™ä½œè€…é€ä¸€äº›å¹¼å¥³è¿‡æ¥ã€‚&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>open-mmlab/mmdetection</title>
    <updated>2022-07-21T01:35:07Z</updated>
    <id>tag:github.com,2022-07-21:/open-mmlab/mmdetection</id>
    <link href="https://github.com/open-mmlab/mmdetection" rel="alternate"></link>
    <summary type="html">&lt;p&gt;OpenMMLab Detection Toolbox and Benchmark&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/resources/mmdet-logo.png&#34; width=&#34;600&#34;&gt; &#xA; &lt;div&gt;&#xA;  &amp;nbsp;&#xA; &lt;/div&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;b&gt;&lt;font size=&#34;5&#34;&gt;OpenMMLab website&lt;/font&gt;&lt;/b&gt; &#xA;  &lt;sup&gt; &lt;a href=&#34;https://openmmlab.com&#34;&gt; &lt;i&gt;&lt;font size=&#34;4&#34;&gt;HOT&lt;/font&gt;&lt;/i&gt; &lt;/a&gt; &lt;/sup&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &#xA;  &lt;b&gt;&lt;font size=&#34;5&#34;&gt;OpenMMLab platform&lt;/font&gt;&lt;/b&gt; &#xA;  &lt;sup&gt; &lt;a href=&#34;https://platform.openmmlab.com&#34;&gt; &lt;i&gt;&lt;font size=&#34;4&#34;&gt;TRY IT OUT&lt;/font&gt;&lt;/i&gt; &lt;/a&gt; &lt;/sup&gt; &#xA; &lt;/div&gt; &#xA; &lt;div&gt;&#xA;  &amp;nbsp;&#xA; &lt;/div&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://pypi.org/project/mmdet&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/mmdet&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://mmdetection.readthedocs.io/en/latest/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-latest-blue&#34; alt=&#34;docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmdetection/actions&#34;&gt;&lt;img src=&#34;https://github.com/open-mmlab/mmdetection/workflows/build/badge.svg?sanitize=true&#34; alt=&#34;badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/open-mmlab/mmdetection&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/open-mmlab/mmdetection/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmdetection/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/open-mmlab/mmdetection.svg?sanitize=true&#34; alt=&#34;license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmdetection/issues&#34;&gt;&lt;img src=&#34;https://isitmaintained.com/badge/open/open-mmlab/mmdetection.svg?sanitize=true&#34; alt=&#34;open issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmdetection/issues&#34;&gt;&lt;img src=&#34;https://isitmaintained.com/badge/resolution/open-mmlab/mmdetection.svg?sanitize=true&#34; alt=&#34;issue resolution&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://mmdetection.readthedocs.io/en/stable/&#34;&gt;ğŸ“˜Documentation&lt;/a&gt; | &lt;a href=&#34;https://mmdetection.readthedocs.io/en/stable/get_started.html&#34;&gt;ğŸ› ï¸Installation&lt;/a&gt; | &lt;a href=&#34;https://mmdetection.readthedocs.io/en/stable/model_zoo.html&#34;&gt;ğŸ‘€Model Zoo&lt;/a&gt; | &lt;a href=&#34;https://mmdetection.readthedocs.io/en/stable/changelog.html&#34;&gt;ğŸ†•Update News&lt;/a&gt; | &lt;a href=&#34;https://github.com/open-mmlab/mmdetection/projects&#34;&gt;ğŸš€Ongoing Projects&lt;/a&gt; | &lt;a href=&#34;https://github.com/open-mmlab/mmdetection/issues/new/choose&#34;&gt;ğŸ¤”Reporting Issues&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/README_zh-CN.md&#34;&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;MMDetection is an open source object detection toolbox based on PyTorch. It is a part of the &lt;a href=&#34;https://openmmlab.com/&#34;&gt;OpenMMLab&lt;/a&gt; project.&lt;/p&gt; &#xA;&lt;p&gt;The master branch works with &lt;strong&gt;PyTorch 1.5+&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/12907710/137271636-56ba1cd2-b110-4812-8221-b4c120320aa9.png&#34;&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;Major features&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Modular Design&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;We decompose the detection framework into different components and one can easily construct a customized object detection framework by combining different modules.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Support of multiple frameworks out of box&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The toolbox directly supports popular and contemporary detection frameworks, &lt;em&gt;e.g.&lt;/em&gt; Faster RCNN, Mask RCNN, RetinaNet, etc.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;High efficiency&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;All basic bbox and mask operations run on GPUs. The training speed is faster than or comparable to other codebases, including &lt;a href=&#34;https://github.com/facebookresearch/detectron2&#34;&gt;Detectron2&lt;/a&gt;, &lt;a href=&#34;https://github.com/facebookresearch/maskrcnn-benchmark&#34;&gt;maskrcnn-benchmark&lt;/a&gt; and &lt;a href=&#34;https://github.com/TuSimple/simpledet&#34;&gt;SimpleDet&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;State of the art&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The toolbox stems from the codebase developed by the &lt;em&gt;MMDet&lt;/em&gt; team, who won &lt;a href=&#34;http://cocodataset.org/#detection-leaderboard&#34;&gt;COCO Detection Challenge&lt;/a&gt; in 2018, and we keep pushing it forward.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;Apart from MMDetection, we also released a library &lt;a href=&#34;https://github.com/open-mmlab/mmcv&#34;&gt;mmcv&lt;/a&gt; for computer vision research, which is heavily depended on by this toolbox.&lt;/p&gt; &#xA;&lt;h2&gt;What&#39;s New&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;2.25.0&lt;/strong&gt; was released in 1/6/2022:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Support dedicated &lt;code&gt;MMDetWandbHook&lt;/code&gt; hook&lt;/li&gt; &#xA; &lt;li&gt;Support &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/convnext&#34;&gt;ConvNeXt&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/ddod&#34;&gt;DDOD&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/solov2&#34;&gt;SOLOv2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Support &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/mask2former&#34;&gt;Mask2Former&lt;/a&gt; for instance segmentation&lt;/li&gt; &#xA; &lt;li&gt;Rename &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/mask2former&#34;&gt;config files of Mask2Former&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/changelog.md&#34;&gt;changelog.md&lt;/a&gt; for details and release history.&lt;/p&gt; &#xA;&lt;p&gt;For compatibility changes between different versions of MMDetection, please refer to &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/compatibility.md&#34;&gt;compatibility.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/get_started.md/#Installation&#34;&gt;Installation&lt;/a&gt; for installation instructions.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/get_started.md&#34;&gt;get_started.md&lt;/a&gt; for the basic usage of MMDetection. We provide &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/demo/MMDet_Tutorial.ipynb&#34;&gt;colab tutorial&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/demo/MMDet_InstanceSeg_Tutorial.ipynb&#34;&gt;instance segmentation colab tutorial&lt;/a&gt;, and other tutorials for:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/1_exist_data_model.md&#34;&gt;with existing dataset&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/2_new_data_model.md&#34;&gt;with new dataset&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/3_exist_data_new_model.md&#34;&gt;with existing dataset_new_model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/tutorials/config.md&#34;&gt;learn about configs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/tutorials/customize_dataset.md&#34;&gt;customize_datasets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/tutorials/data_pipeline.md&#34;&gt;customize data pipelines&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/tutorials/customize_models.md&#34;&gt;customize_models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/tutorials/customize_runtime.md&#34;&gt;customize runtime settings&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/tutorials/customize_losses.md&#34;&gt;customize_losses&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/tutorials/finetune.md&#34;&gt;finetuning models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/tutorials/pytorch2onnx.md&#34;&gt;export a model to ONNX&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/tutorials/onnx2tensorrt.md&#34;&gt;export ONNX to TRT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/tutorials/init_cfg.md&#34;&gt;weight initialization&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/tutorials/how_to.md&#34;&gt;how to xxx&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Overview of Benchmark and Model Zoo&lt;/h2&gt; &#xA;&lt;p&gt;Results and models are available in the &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/model_zoo.md&#34;&gt;model zoo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;b&gt;Architectures&lt;/b&gt; &#xA;&lt;/div&gt; &#xA;&lt;table align=&#34;center&#34;&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr align=&#34;center&#34; valign=&#34;bottom&#34;&gt; &#xA;   &lt;td&gt; &lt;b&gt;Object Detection&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Instance Segmentation&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Panoptic Segmentation&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Other&lt;/b&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr valign=&#34;top&#34;&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/fast_rcnn&#34;&gt;Fast R-CNN (ICCV&#39;2015)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/faster_rcnn&#34;&gt;Faster R-CNN (NeurIPS&#39;2015)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/rpn&#34;&gt;RPN (NeurIPS&#39;2015)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/ssd&#34;&gt;SSD (ECCV&#39;2016)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/retinanet&#34;&gt;RetinaNet (ICCV&#39;2017)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/cascade_rcnn&#34;&gt;Cascade R-CNN (CVPR&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/yolo&#34;&gt;YOLOv3 (ArXiv&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/cornernet&#34;&gt;CornerNet (ECCV&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/grid_rcnn&#34;&gt;Grid R-CNN (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/guided_anchoring&#34;&gt;Guided Anchoring (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/fsaf&#34;&gt;FSAF (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/centernet&#34;&gt;CenterNet (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/libra_rcnn&#34;&gt;Libra R-CNN (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/tridentnet&#34;&gt;TridentNet (ICCV&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/fcos&#34;&gt;FCOS (ICCV&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/reppoints&#34;&gt;RepPoints (ICCV&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/free_anchor&#34;&gt;FreeAnchor (NeurIPS&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/cascade_rpn&#34;&gt;CascadeRPN (NeurIPS&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/foveabox&#34;&gt;Foveabox (TIP&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/double_heads&#34;&gt;Double-Head R-CNN (CVPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/atss&#34;&gt;ATSS (CVPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/nas_fcos&#34;&gt;NAS-FCOS (CVPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/centripetalnet&#34;&gt;CentripetalNet (CVPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/autoassign&#34;&gt;AutoAssign (ArXiv&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/sabl&#34;&gt;Side-Aware Boundary Localization (ECCV&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/dynamic_rcnn&#34;&gt;Dynamic R-CNN (ECCV&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/detr&#34;&gt;DETR (ECCV&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/paa&#34;&gt;PAA (ECCV&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/vfnet&#34;&gt;VarifocalNet (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/sparse_rcnn&#34;&gt;Sparse R-CNN (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/yolof&#34;&gt;YOLOF (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/yolox&#34;&gt;YOLOX (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/deformable_detr&#34;&gt;Deformable DETR (ICLR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/tood&#34;&gt;TOOD (ICCV&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/ddod&#34;&gt;DDOD (ACM MM&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/mask_rcnn&#34;&gt;Mask R-CNN (ICCV&#39;2017)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/cascade_rcnn&#34;&gt;Cascade Mask R-CNN (CVPR&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/ms_rcnn&#34;&gt;Mask Scoring R-CNN (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/htc&#34;&gt;Hybrid Task Cascade (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/yolact&#34;&gt;YOLACT (ICCV&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/instaboost&#34;&gt;InstaBoost (ICCV&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/solo&#34;&gt;SOLO (ECCV&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/point_rend&#34;&gt;PointRend (CVPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/detectors&#34;&gt;DetectoRS (ArXiv&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/solov2&#34;&gt;SOLOv2 (NeurIPS&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/scnet&#34;&gt;SCNet (AAAI&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/queryinst&#34;&gt;QueryInst (ICCV&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/mask2former&#34;&gt;Mask2Former (ArXiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/panoptic_fpn&#34;&gt;Panoptic FPN (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/maskformer&#34;&gt;MaskFormer (NeurIPS&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/mask2former&#34;&gt;Mask2Former (ArXiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt;  &lt;li&gt;&lt;b&gt;Contrastive Learning&lt;/b&gt;&lt;/li&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;ul&gt; &#xA;      &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/selfsup_pretrain&#34;&gt;SwAV (NeurIPS&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/selfsup_pretrain&#34;&gt;MoCo (CVPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/selfsup_pretrain&#34;&gt;MoCov2 (ArXiv&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;/ul&gt; &#xA;    &lt;/ul&gt;  &lt;li&gt;&lt;b&gt;Distillation&lt;/b&gt;&lt;/li&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;ul&gt; &#xA;      &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/ld&#34;&gt;Localization Distillation (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/lad&#34;&gt;Label Assignment Distillation (WACV&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;/ul&gt; &#xA;    &lt;/ul&gt;  &lt;/td&gt; &#xA;  &lt;/tr&gt;   &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;b&gt;Components&lt;/b&gt; &#xA;&lt;/div&gt; &#xA;&lt;table align=&#34;center&#34;&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr align=&#34;center&#34; valign=&#34;bottom&#34;&gt; &#xA;   &lt;td&gt; &lt;b&gt;Backbones&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Necks&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Loss&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Common&lt;/b&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr valign=&#34;top&#34;&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;VGG (ICLR&#39;2015)&lt;/li&gt; &#xA;     &lt;li&gt;ResNet (CVPR&#39;2016)&lt;/li&gt; &#xA;     &lt;li&gt;ResNeXt (CVPR&#39;2017)&lt;/li&gt; &#xA;     &lt;li&gt;MobileNetV2 (CVPR&#39;2018)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/hrnet&#34;&gt;HRNet (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/empirical_attention&#34;&gt;Generalized Attention (ICCV&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/gcnet&#34;&gt;GCNet (ICCVW&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/res2net&#34;&gt;Res2Net (TPAMI&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/regnet&#34;&gt;RegNet (CVPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/resnest&#34;&gt;ResNeSt (ArXiv&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/pvt&#34;&gt;PVT (ICCV&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/swin&#34;&gt;Swin (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/pvt&#34;&gt;PVTv2 (ArXiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/resnet_strikes_back&#34;&gt;ResNet strikes back (ArXiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/efficientnet&#34;&gt;EfficientNet (ArXiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/convnext&#34;&gt;ConvNeXt (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/pafpn&#34;&gt;PAFPN (CVPR&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/nas_fpn&#34;&gt;NAS-FPN (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/carafe&#34;&gt;CARAFE (ICCV&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/fpg&#34;&gt;FPG (ArXiv&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/groie&#34;&gt;GRoIE (ICPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/dyhead&#34;&gt;DyHead (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/ghm&#34;&gt;GHM (AAAI&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/gfl&#34;&gt;Generalized Focal Loss (NeurIPS&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/seesaw_loss&#34;&gt;Seasaw Loss (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/faster_rcnn/faster_rcnn_r50_fpn_ohem_1x_coco.py&#34;&gt;OHEM (CVPR&#39;2016)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/gn&#34;&gt;Group Normalization (ECCV&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/dcn&#34;&gt;DCN (ICCV&#39;2017)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/dcnv2&#34;&gt;DCNv2 (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/gn+ws&#34;&gt;Weight Standardization (ArXiv&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/pisa&#34;&gt;Prime Sample Attention (CVPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/strong_baselines&#34;&gt;Strong Baselines (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/resnet_strikes_back&#34;&gt;Resnet strikes back (ArXiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt;   &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Some other methods are also supported in &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/projects.md&#34;&gt;projects using MMDetection&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/docs/en/faq.md&#34;&gt;FAQ&lt;/a&gt; for frequently asked questions.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We appreciate all contributions to improve MMDetection. Ongoing projects can be found in out &lt;a href=&#34;https://github.com/open-mmlab/mmdetection/projects&#34;&gt;GitHub Projects&lt;/a&gt;. Welcome community users to participate in these projects. Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/.github/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for the contributing guideline.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;MMDetection is an open source project that is contributed by researchers and engineers from various colleges and companies. We appreciate all the contributors who implement their methods or add new features, as well as users who give valuable feedbacks. We wish that the toolbox and benchmark could serve the growing research community by providing a flexible toolkit to reimplement existing methods and develop their own new detectors.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you use this toolbox or benchmark in your research, please cite this project.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{mmdetection,&#xA;  title   = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark},&#xA;  author  = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and&#xA;             Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and&#xA;             Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and&#xA;             Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and&#xA;             Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong&#xA;             and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},&#xA;  journal= {arXiv preprint arXiv:1906.07155},&#xA;  year={2019}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is released under the &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmdetection/master/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Projects in OpenMMLab&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmcv&#34;&gt;MMCV&lt;/a&gt;: OpenMMLab foundational library for computer vision.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mim&#34;&gt;MIM&lt;/a&gt;: MIM installs OpenMMLab packages.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmclassification&#34;&gt;MMClassification&lt;/a&gt;: OpenMMLab image classification toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmdetection&#34;&gt;MMDetection&lt;/a&gt;: OpenMMLab detection toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmdetection3d&#34;&gt;MMDetection3D&lt;/a&gt;: OpenMMLab&#39;s next-generation platform for general 3D object detection.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmrotate&#34;&gt;MMRotate&lt;/a&gt;: OpenMMLab rotated object detection toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmsegmentation&#34;&gt;MMSegmentation&lt;/a&gt;: OpenMMLab semantic segmentation toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmocr&#34;&gt;MMOCR&lt;/a&gt;: OpenMMLab text detection, recognition, and understanding toolbox.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmpose&#34;&gt;MMPose&lt;/a&gt;: OpenMMLab pose estimation toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmhuman3d&#34;&gt;MMHuman3D&lt;/a&gt;: OpenMMLab 3D human parametric model toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmselfsup&#34;&gt;MMSelfSup&lt;/a&gt;: OpenMMLab self-supervised learning toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmrazor&#34;&gt;MMRazor&lt;/a&gt;: OpenMMLab model compression toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmfewshot&#34;&gt;MMFewShot&lt;/a&gt;: OpenMMLab fewshot learning toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmaction2&#34;&gt;MMAction2&lt;/a&gt;: OpenMMLab&#39;s next-generation action understanding toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmtracking&#34;&gt;MMTracking&lt;/a&gt;: OpenMMLab video perception toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmflow&#34;&gt;MMFlow&lt;/a&gt;: OpenMMLab optical flow toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmediting&#34;&gt;MMEditing&lt;/a&gt;: OpenMMLab image and video editing toolbox.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmgeneration&#34;&gt;MMGeneration&lt;/a&gt;: OpenMMLab image and video generative models toolbox.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmdeploy&#34;&gt;MMDeploy&lt;/a&gt;: OpenMMLab model deployment framework.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>