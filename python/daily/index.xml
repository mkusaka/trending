<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-02-02T01:36:49Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>oumi-ai/oumi</title>
    <updated>2025-02-02T01:36:49Z</updated>
    <id>tag:github.com,2025-02-02:/oumi-ai/oumi</id>
    <link href="https://github.com/oumi-ai/oumi" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Everything you need to build state-of-the-art foundation models, end-to-end.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/docs/_static/logo/header_logo.png&#34; alt=&#34;# Oumi: Open Universal Machine Intelligence&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://oumi.ai/docs/en/latest/index.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Documentation-oumi-blue.svg?sanitize=true&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://oumi.ai/blog&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Blog-oumi-blue.svg?sanitize=true&#34; alt=&#34;Blog&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/oumi&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1286348126797430814?label=Discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://badge.fury.io/py/oumi&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/oumi.svg?sanitize=true&#34; alt=&#34;PyPI version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/Apache-2.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/oumi-ai/oumi/actions/workflows/pretest.yaml&#34;&gt;&lt;img src=&#34;https://github.com/oumi-ai/oumi/actions/workflows/pretest.yaml/badge.svg?branch=main&#34; alt=&#34;Tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/oumi-ai/oumi/actions/workflows/gpu_tests.yaml&#34;&gt;&lt;img src=&#34;https://github.com/oumi-ai/oumi/actions/workflows/gpu_tests.yaml/badge.svg?branch=main&#34; alt=&#34;GPU Tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/oumi-ai/oumi&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/oumi-ai/oumi&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/psf/black&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true&#34; alt=&#34;Code style: black&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pre-commit/pre-commit&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&#34; alt=&#34;pre-commit&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://oumi.ai&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/About-oumi-blue.svg?sanitize=true&#34; alt=&#34;About&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Everything you need to build state-of-the-art foundation models, end-to-end.&lt;/h3&gt; &#xA;&lt;p&gt;Oumi is a fully open-source platform that streamlines the entire lifecycle of foundation models - from data preparation and training to evaluation and deployment. Whether you&#39;re developing on a laptop, launching large scale experiments on a cluster, or deploying models in production, Oumi provides the tools and workflows you need.&lt;/p&gt; &#xA;&lt;p&gt;With Oumi, you can:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üöÄ Train and fine-tune models from 10M to 405B parameters using state-of-the-art techniques (SFT, LoRA, QLoRA, DPO, and more)&lt;/li&gt; &#xA; &lt;li&gt;ü§ñ Work with both text and multimodal models (Llama, Qwen, Phi, and others)&lt;/li&gt; &#xA; &lt;li&gt;üîÑ Synthesize and curate training data with LLM judges&lt;/li&gt; &#xA; &lt;li&gt;‚ö°Ô∏è Deploy models efficiently with popular inference engines (vLLM, SGLang)&lt;/li&gt; &#xA; &lt;li&gt;üìä Evaluate models comprehensively across standard benchmarks&lt;/li&gt; &#xA; &lt;li&gt;üåé Run anywhere - from laptops to clusters to clouds (AWS, Azure, GCP, Lambda, and more)&lt;/li&gt; &#xA; &lt;li&gt;üîå Integrate with both open models and commercial APIs (OpenAI, Anthropic, Vertex AI, Together, Parasail, ...)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All with one consistent API, production-grade reliability, and all the flexibility you need for research.&lt;/p&gt; &#xA;&lt;p&gt;Learn more at &lt;a href=&#34;https://oumi.ai/docs&#34;&gt;oumi.ai&lt;/a&gt;, or jump right in with the &lt;a href=&#34;https://oumi.ai/docs/en/latest/get_started/quickstart.html&#34;&gt;quickstart guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Notebook&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Try in Colab&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Goal&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;üéØ Getting Started: A Tour&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi%20-%20A%20Tour.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Quick tour of core features: training, evaluation, inference, and job management&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;üîß Model Finetuning Guide&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi%20-%20Finetuning%20Tutorial.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;End-to-end guide to LoRA tuning with data prep, training, and evaluation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;üìö Model Distillation&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi%20-%20Distill%20a%20Large%20Model.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Guide to distilling large models into smaller, efficient ones&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;üìã Model Evaluation&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi%20-%20Evaluation%20with%20Oumi.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Comprehensive model evaluation using Oumi&#39;s evaluation framework&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;‚òÅÔ∏è Remote Training&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi%20-%20Running%20Jobs%20Remotely.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Launch and monitor training jobs on cloud (AWS, Azure, GCP, Lambda, etc.) platforms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;üìà LLM-as-a-Judge&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi%20-%20Oumi%20Judge.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Filter and curate training data with built-in judges&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;üîÑ vLLM Inference Engine&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi%20-%20Using%20vLLM%20Engine%20for%20Inference.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Fast inference at scale with the vLLM engine&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;üîß Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;Installing oumi in your environment is straightforward:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Install the package (CPU &amp;amp; NPU only)&#xA;pip install oumi  # For local development &amp;amp; testing&#xA;&#xA;# OR, with GPU support (Requires Nvidia or AMD GPU)&#xA;pip install oumi[gpu]  # For GPU training&#xA;&#xA;# To get the latest version, install from the source&#xA;pip install git+https://github.com/oumi-ai/oumi.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more advanced installation options, see the &lt;a href=&#34;https://oumi.ai/docs/en/latest/get_started/installation.html&#34;&gt;installation guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Oumi CLI&lt;/h3&gt; &#xA;&lt;p&gt;You can quickly use the &lt;code&gt;oumi&lt;/code&gt; command to train, evaluate, and infer models using one of the existing &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes&#34;&gt;recipes&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Training&#xA;oumi train -c configs/recipes/smollm/sft/135m/quickstart_train.yaml&#xA;&#xA;# Evaluation&#xA;oumi evaluate -c configs/recipes/smollm/evaluation/135m/quickstart_eval.yaml&#xA;&#xA;# Inference&#xA;oumi infer -c configs/recipes/smollm/inference/135m_infer.yaml --interactive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more advanced options, see the &lt;a href=&#34;https://oumi.ai/docs/en/latest/user_guides/train/train.html&#34;&gt;training&lt;/a&gt;, &lt;a href=&#34;https://oumi.ai/docs/en/latest/user_guides/evaluate/evaluate.html&#34;&gt;evaluation&lt;/a&gt;, &lt;a href=&#34;https://oumi.ai/docs/en/latest/user_guides/infer/infer.html&#34;&gt;inference&lt;/a&gt;, and &lt;a href=&#34;https://oumi.ai/docs/en/latest/user_guides/judge/judge.html&#34;&gt;llm-as-a-judge&lt;/a&gt; guides.&lt;/p&gt; &#xA;&lt;h3&gt;Running Jobs Remotely&lt;/h3&gt; &#xA;&lt;p&gt;You can run jobs remotely on cloud platforms (AWS, Azure, GCP, Lambda, etc.) using the &lt;code&gt;oumi launch&lt;/code&gt; command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# GCP&#xA;oumi launch up -c configs/recipes/smollm/sft/135m/quickstart_gcp_job.yaml&#xA;&#xA;# AWS&#xA;oumi launch up -c configs/recipes/smollm/sft/135m/quickstart_aws_job.yaml&#xA;&#xA;# Azure&#xA;oumi launch up -c configs/recipes/smollm/sft/135m/quickstart_azure_job.yaml&#xA;&#xA;# Lambda&#xA;oumi launch up -c configs/recipes/smollm/sft/135m/quickstart_lambda_job.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Oumi is in &lt;ins&gt;beta&lt;/ins&gt; and under active development. The core features are stable, but some advanced features might change as the platform improves.&lt;/p&gt; &#xA;&lt;h2&gt;üíª Why use Oumi?&lt;/h2&gt; &#xA;&lt;p&gt;If you need a comprehensive platform for training, evaluating, or deploying models, Oumi is a great choice.&lt;/p&gt; &#xA;&lt;p&gt;Here are some of the key features that make Oumi stand out:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üîß &lt;strong&gt;Zero Boilerplate&lt;/strong&gt;: Get started in minutes with ready-to-use recipes for popular models and workflows. No need to write training loops or data pipelines.&lt;/li&gt; &#xA; &lt;li&gt;üè¢ &lt;strong&gt;Enterprise-Grade&lt;/strong&gt;: Built and validated by teams training models at scale&lt;/li&gt; &#xA; &lt;li&gt;üéØ &lt;strong&gt;Research Ready&lt;/strong&gt;: Perfect for ML research with easily reproducible experiments, and flexible interfaces for customizing each component.&lt;/li&gt; &#xA; &lt;li&gt;üåê &lt;strong&gt;Broad Model Support&lt;/strong&gt;: Works with most popular model architectures - from tiny models to the largest ones, text-only to multimodal.&lt;/li&gt; &#xA; &lt;li&gt;üöÄ &lt;strong&gt;SOTA Performance&lt;/strong&gt;: Native support for distributed training techniques (FSDP, DDP) and optimized inference engines (vLLM, SGLang).&lt;/li&gt; &#xA; &lt;li&gt;ü§ù &lt;strong&gt;Community First&lt;/strong&gt;: 100% open source with an active community. No vendor lock-in, no strings attached.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìö Examples &amp;amp; Recipes&lt;/h2&gt; &#xA;&lt;p&gt;Explore the growing collection of ready-to-use configurations for state-of-the-art models and training workflows:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; These configurations are not an exhaustive list of what&#39;s supported, simply examples to get you started. You can find a more exhaustive list of supported &lt;a href=&#34;https://oumi.ai/docs/en/latest/resources/models/supported_models.html&#34;&gt;models&lt;/a&gt;, and datasets (&lt;a href=&#34;https://oumi.ai/docs/en/latest/resources/datasets/sft_datasets.html&#34;&gt;supervised fine-tuning&lt;/a&gt;, &lt;a href=&#34;https://oumi.ai/docs/en/latest/resources/datasets/pretraining_datasets.html&#34;&gt;pre-training&lt;/a&gt;, &lt;a href=&#34;https://oumi.ai/docs/en/latest/resources/datasets/preference_datasets.html&#34;&gt;preference tuning&lt;/a&gt;, and &lt;a href=&#34;https://oumi.ai/docs/en/latest/resources/datasets/vl_sft_datasets.html&#34;&gt;vision-language finetuning&lt;/a&gt;) in the oumi documentation.&lt;/p&gt; &#xA;&lt;h3&gt;üêã DeepSeek R1 Family&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Example Configurations&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DeepSeek R1 671B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/inference/671b_together_infer.yaml&#34;&gt;Inference (Together AI)&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Distilled Llama 8B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/sft/distill_llama_8b/full_train.yaml&#34;&gt;FFT&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/sft/distill_llama_8b/lora_train.yaml&#34;&gt;LoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/sft/distill_llama_8b/qlora_train.yaml&#34;&gt;QLoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/inference/distill_llama_8b_infer.yaml&#34;&gt;Inference&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/evaluation/distill_llama_8b/eval.yaml&#34;&gt;Evaluation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Distilled Llama 70B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/sft/distill_llama_70b/full_train.yaml&#34;&gt;FFT&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/sft/distill_llama_70b/lora_train.yaml&#34;&gt;LoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/sft/distill_llama_70b/qlora_train.yaml&#34;&gt;QLoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/inference/distill_llama_70b_infer.yaml&#34;&gt;Inference&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/evaluation/distill_llama_70b/eval.yaml&#34;&gt;Evaluation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Distilled Qwen 1.5B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/sft/distill_qwen_1_5b/full_train.yaml&#34;&gt;FFT&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/sft/distill_qwen_1_5b/lora_train.yaml&#34;&gt;LoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/inference/distill_qwen_1_5b_infer.yaml&#34;&gt;Inference&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/evaluation/distill_qwen_1_5b/eval.yaml&#34;&gt;Evaluation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Distilled Qwen 32B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/sft/distill_qwen_32b/lora_train.yaml&#34;&gt;LoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/inference/distill_qwen_32b_infer.yaml&#34;&gt;Inference&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/deepseek_r1/evaluation/distill_qwen_32b/eval.yaml&#34;&gt;Evaluation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;ü¶ô Llama Family&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Example Configurations&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 3.1 8B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/sft/8b_full/train.yaml&#34;&gt;FFT&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/sft/8b_lora/train.yaml&#34;&gt;LoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/sft/8b_qlora/train.yaml&#34;&gt;QLoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/pretraining/8b/train.yaml&#34;&gt;Pre-training&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/inference/8b_rvllm_infer.yaml&#34;&gt;Inference (vLLM)&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/inference/8b_infer.yaml&#34;&gt;Inference&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/evaluation/8b_eval.yaml&#34;&gt;Evaluation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 3.1 70B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/sft/70b_full/train.yaml&#34;&gt;FFT&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/sft/70b_lora/train.yaml&#34;&gt;LoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/sft/70b_qlora/train.yaml&#34;&gt;QLoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/inference/70b_infer.yaml&#34;&gt;Inference&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/evaluation/70b_eval.yaml&#34;&gt;Evaluation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 3.1 405B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/sft/405b_full/train.yaml&#34;&gt;FFT&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/sft/405b_lora/train.yaml&#34;&gt;LoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_1/sft/405b_qlora/train.yaml&#34;&gt;QLoRA&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 3.2 1B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_2/sft/1b_full/train.yaml&#34;&gt;FFT&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_2/sft/1b_lora/train.yaml&#34;&gt;LoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_2/sft/1b_qlora/train.yaml&#34;&gt;QLoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_2/inference/1b_vllm_infer.yaml&#34;&gt;Inference (vLLM)&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_2/inference/1b_sglang_infer.yaml&#34;&gt;Inference (SGLang)&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_2/inference/1b_infer.yaml&#34;&gt;Inference&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_2/evaluation/1b_eval.yaml&#34;&gt;Evaluation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 3.2 3B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_2/sft/3b_full/train.yaml&#34;&gt;FFT&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_2/sft/3b_lora/train.yaml&#34;&gt;LoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_2/sft/3b_qlora/train.yaml&#34;&gt;QLoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_2/inference/3b_vllm_infer.yaml&#34;&gt;Inference (vLLM)&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_2/inference/3b_sglang_infer.yaml&#34;&gt;Inference (SGLang)&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_2/inference/3b_infer.yaml&#34;&gt;Inference&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_2/evaluation/3b_eval.yaml&#34;&gt;Evaluation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 3.3 70B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_3/sft/70b_full/train.yaml&#34;&gt;FFT&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_3/sft/70b_lora/train.yaml&#34;&gt;LoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_3/sft/70b_qlora/train.yaml&#34;&gt;QLoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_3/inference/70b_vllm_infer.yaml&#34;&gt;Inference (vLLM)&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_3/inference/70b_infer.yaml&#34;&gt;Inference&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/llama3_3/evaluation/70b_eval.yaml&#34;&gt;Evaluation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 3.2 Vision 11B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/llama3_2_vision/sft/11b_full/train.yaml&#34;&gt;SFT&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/llama3_2_vision/inference/11b_rvllm_infer.yaml&#34;&gt;Inference (vLLM)&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/llama3_2_vision/inference/11b_sglang_infer.yaml&#34;&gt;Inference (SGLang)&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/llama3_2_vision/evaluation/11b_eval.yaml&#34;&gt;Evaluation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;üé® Vision Models&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Example Configurations&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama 3.2 Vision 11B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/llama3_2_vision/sft/11b_full/train.yaml&#34;&gt;SFT&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/llama3_2_vision/sft/11b_lora/train.yaml&#34;&gt;LoRA&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/llama3_2_vision/inference/11b_rvllm_infer.yaml&#34;&gt;Inference (vLLM)&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/llama3_2_vision/inference/11b_sglang_infer.yaml&#34;&gt;Inference (SGLang)&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/llama3_2_vision/evaluation/11b_eval.yaml&#34;&gt;Evaluation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaVA 7B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/llava_7b/sft/train.yaml&#34;&gt;SFT&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/llava_7b/inference/vllm_infer.yaml&#34;&gt;Inference (vLLM)&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/llava_7b/inference/infer.yaml&#34;&gt;Inference&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi3 Vision 4.2B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/phi3/sft/train.yaml&#34;&gt;SFT&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/phi3/inference/vllm_infer.yaml&#34;&gt;Inference (vLLM)&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Qwen2-VL 2B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/qwen2_vl_2b/sft/train.yaml&#34;&gt;SFT&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/qwen2_vl_2b/inference/vllm_infer.yaml&#34;&gt;Inference (vLLM)&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/qwen2_vl_2b/inference/sglang_infer.yaml&#34;&gt;Inference (SGLang)&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/qwen2_vl_2b/inference/infer.yaml&#34;&gt;Inference&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/qwen2_vl_2b/evaluation/eval.yaml&#34;&gt;Evaluation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SmolVLM-Instruct 2B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes/vision/smolvlm/sft/gcp_job.yaml&#34;&gt;SFT&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;üîç Even more options&lt;/h3&gt; &#xA;&lt;p&gt;This section lists all the language models that can be used with Oumi. Thanks to the integration with the &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;ü§ó Transformers&lt;/a&gt; library, you can easily use any of these models for training, evaluation, or inference.&lt;/p&gt; &#xA;&lt;p&gt;Models prefixed with a checkmark (‚úÖ) have been thoroughly tested and validated by the Oumi community, with ready-to-use recipes available in the &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/configs/recipes&#34;&gt;configs/recipes&lt;/a&gt; directory.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;üìã Click to see more supported models&lt;/summary&gt; &#xA; &lt;h4&gt;Instruct Models&lt;/h4&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Size&lt;/th&gt; &#xA;    &lt;th&gt;Paper&lt;/th&gt; &#xA;    &lt;th&gt;HF Hub&lt;/th&gt; &#xA;    &lt;th&gt;License&lt;/th&gt; &#xA;    &lt;th&gt;Open [^1]&lt;/th&gt; &#xA;    &lt;th&gt;Recommended Parameters&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ SmolLM-Instruct&lt;/td&gt; &#xA;    &lt;td&gt;135M/360M/1.7B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/blog/smollm&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/HuggingFaceTB/SmolLM-135M-Instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Apache 2.0&lt;/td&gt; &#xA;    &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ DeepSeek R1 Family&lt;/td&gt; &#xA;    &lt;td&gt;1.5B/8B/32B/70B/671B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://api-docs.deepseek.com/news/news250120&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/deepseek-ai/DeepSeek-R1&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;MIT&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ Llama 3.1 Instruct&lt;/td&gt; &#xA;    &lt;td&gt;8B/70B/405B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2407.21783&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-3.1-70b-instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://llama.meta.com/llama3/license/&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ Llama 3.2 Instruct&lt;/td&gt; &#xA;    &lt;td&gt;1B/3B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2407.21783&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-3.2-3b-instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://llama.meta.com/llama3/license/&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ Llama 3.3 Instruct&lt;/td&gt; &#xA;    &lt;td&gt;70B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2407.21783&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-3.3-70b-instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://llama.meta.com/llama3/license/&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ Phi-3.5-Instruct&lt;/td&gt; &#xA;    &lt;td&gt;4B/14B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2404.14219&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/microsoft/Phi-3.5-mini-instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/microsoft/Phi-3-mini-4k-instruct/blob/main/LICENSE&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Qwen2.5-Instruct&lt;/td&gt; &#xA;    &lt;td&gt;0.5B-70B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.16609&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/Qwen/Qwen2.5-7B-Instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/QwenLM/Qwen/raw/main/LICENSE&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;OLMo 2 Instruct&lt;/td&gt; &#xA;    &lt;td&gt;7B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2402.00838&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/allenai/OLMo-2-1124-7B&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Apache 2.0&lt;/td&gt; &#xA;    &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;MPT-Instruct&lt;/td&gt; &#xA;    &lt;td&gt;7B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.mosaicml.com/blog/mpt-7b&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/mosaicml/mpt-7b-instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Apache 2.0&lt;/td&gt; &#xA;    &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Command R&lt;/td&gt; &#xA;    &lt;td&gt;35B/104B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://cohere.com/blog/command-r7b&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/CohereForAI/c4ai-command-r-plus&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://cohere.com/c4ai-cc-by-nc-license&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Granite-3.1-Instruct&lt;/td&gt; &#xA;    &lt;td&gt;2B/8B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ibm-granite/granite-3.0-language-models/raw/main/paper.pdf&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/ibm-granite/granite-3.1-8b-instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Apache 2.0&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Gemma 2 Instruct&lt;/td&gt; &#xA;    &lt;td&gt;2B/9B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://ai.google.dev/gemma&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/google/gemma-2-2b-it&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://ai.google.dev/gemma/terms&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;DBRX-Instruct&lt;/td&gt; &#xA;    &lt;td&gt;130B MoE&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/databricks/dbrx-instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Apache 2.0&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Falcon-Instruct&lt;/td&gt; &#xA;    &lt;td&gt;7B/40B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.01116&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tiiuae/falcon-7b-instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Apache 2.0&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h4&gt;Vision-Language Models&lt;/h4&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Size&lt;/th&gt; &#xA;    &lt;th&gt;Paper&lt;/th&gt; &#xA;    &lt;th&gt;HF Hub&lt;/th&gt; &#xA;    &lt;th&gt;License&lt;/th&gt; &#xA;    &lt;th&gt;Open&lt;/th&gt; &#xA;    &lt;th&gt;Recommended Parameters&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ Llama 3.2 Vision&lt;/td&gt; &#xA;    &lt;td&gt;11B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2407.21783&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-3.2-11b-vision&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://llama.meta.com/llama3/license/&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ LLaVA-1.5&lt;/td&gt; &#xA;    &lt;td&gt;7B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.03744&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/llava-hf/llava-1.5-7b-hf&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://ai.meta.com/llama/license&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ Phi-3 Vision&lt;/td&gt; &#xA;    &lt;td&gt;4.2B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2404.14219&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/microsoft/Phi-3-vision-128k-instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/microsoft/Phi-3-mini-4k-instruct/blob/main/LICENSE&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ BLIP-2&lt;/td&gt; &#xA;    &lt;td&gt;3.6B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.12597&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/Salesforce/blip2-opt-2.7b&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;MIT&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ Qwen2-VL&lt;/td&gt; &#xA;    &lt;td&gt;2B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://qwenlm.github.io/blog/qwen2-vl/&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/QwenLM/Qwen/raw/main/LICENSE&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ SmolVLM-Instruct&lt;/td&gt; &#xA;    &lt;td&gt;2B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/blog/smolvlm&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/HuggingFaceTB/SmolVLM-Instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Apache 2.0&lt;/td&gt; &#xA;    &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h4&gt;Base Models&lt;/h4&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Size&lt;/th&gt; &#xA;    &lt;th&gt;Paper&lt;/th&gt; &#xA;    &lt;th&gt;HF Hub&lt;/th&gt; &#xA;    &lt;th&gt;License&lt;/th&gt; &#xA;    &lt;th&gt;Open&lt;/th&gt; &#xA;    &lt;th&gt;Recommended Parameters&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ SmolLM2&lt;/td&gt; &#xA;    &lt;td&gt;135M/360M/1.7B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/blog/smollm&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/HuggingFaceTB/SmolLM2-135M&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Apache 2.0&lt;/td&gt; &#xA;    &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ Llama 3.2&lt;/td&gt; &#xA;    &lt;td&gt;1B/3B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2407.21783&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-3.2-3b&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://llama.meta.com/llama3/license/&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ Llama 3.1&lt;/td&gt; &#xA;    &lt;td&gt;8B/70B/405B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2407.21783&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-3.1-70b&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://llama.meta.com/llama3/license/&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ GPT-2&lt;/td&gt; &#xA;    &lt;td&gt;124M-1.5B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.14165&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/gpt2&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;MIT&lt;/td&gt; &#xA;    &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;DeepSeek V2&lt;/td&gt; &#xA;    &lt;td&gt;7B/13B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.deepseek.com/blogs/deepseek-v2&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/deepseek-ai/deepseek-llm-7b-v2&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/deepseek-ai/DeepSeek-LLM/raw/main/LICENSE-MODEL&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Gemma2&lt;/td&gt; &#xA;    &lt;td&gt;2B/9B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://ai.google.dev/gemma&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/google/gemma2-7b&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://ai.google.dev/gemma/terms&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;GPT-J&lt;/td&gt; &#xA;    &lt;td&gt;6B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.eleuther.ai/artifacts/gpt-j&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/EleutherAI/gpt-j-6b&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Apache 2.0&lt;/td&gt; &#xA;    &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;GPT-NeoX&lt;/td&gt; &#xA;    &lt;td&gt;20B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.06745&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/EleutherAI/gpt-neox-20b&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Apache 2.0&lt;/td&gt; &#xA;    &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Mistral&lt;/td&gt; &#xA;    &lt;td&gt;7B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.06825&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/mistralai/Mistral-7B-v0.1&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Apache 2.0&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Mixtral&lt;/td&gt; &#xA;    &lt;td&gt;8x7B/8x22B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://mistral.ai/news/mixtral-of-experts/&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/mistralai/Mixtral-8x7B-v0.1&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Apache 2.0&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;MPT&lt;/td&gt; &#xA;    &lt;td&gt;7B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.mosaicml.com/blog/mpt-7b&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/mosaicml/mpt-7b&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Apache 2.0&lt;/td&gt; &#xA;    &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;OLMo&lt;/td&gt; &#xA;    &lt;td&gt;1B/7B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2402.00838&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/allenai/OLMo-7B-hf&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Apache 2.0&lt;/td&gt; &#xA;    &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h4&gt;Reasoning Models&lt;/h4&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Size&lt;/th&gt; &#xA;    &lt;th&gt;Paper&lt;/th&gt; &#xA;    &lt;th&gt;HF Hub&lt;/th&gt; &#xA;    &lt;th&gt;License&lt;/th&gt; &#xA;    &lt;th&gt;Open&lt;/th&gt; &#xA;    &lt;th&gt;Recommended Parameters&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Qwen QwQ&lt;/td&gt; &#xA;    &lt;td&gt;32B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://qwenlm.github.io/blog/qwq-32b-preview/&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/Qwen/QwQ-32B-Preview&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/QwenLM/Qwen/raw/main/LICENSE&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h4&gt;Code Models&lt;/h4&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Size&lt;/th&gt; &#xA;    &lt;th&gt;Paper&lt;/th&gt; &#xA;    &lt;th&gt;HF Hub&lt;/th&gt; &#xA;    &lt;th&gt;License&lt;/th&gt; &#xA;    &lt;th&gt;Open&lt;/th&gt; &#xA;    &lt;th&gt;Recommended Parameters&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚úÖ Qwen2.5 Coder&lt;/td&gt; &#xA;    &lt;td&gt;0.5B-32B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://qwenlm.github.io/blog/qwen2.5/&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/QwenLM/Qwen/raw/main/LICENSE&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;DeepSeek Coder&lt;/td&gt; &#xA;    &lt;td&gt;1.3B-33B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2401.02954&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/deepseek-ai/deepseek-coder-7b-instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/deepseek-ai/DeepSeek-LLM/raw/main/LICENSE-MODEL&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;StarCoder 2&lt;/td&gt; &#xA;    &lt;td&gt;3B/7B/15B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2402.19173&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/bigcode/starcoder2-15b&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h4&gt;Math Models&lt;/h4&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Size&lt;/th&gt; &#xA;    &lt;th&gt;Paper&lt;/th&gt; &#xA;    &lt;th&gt;HF Hub&lt;/th&gt; &#xA;    &lt;th&gt;License&lt;/th&gt; &#xA;    &lt;th&gt;Open&lt;/th&gt; &#xA;    &lt;th&gt;Recommended Parameters&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;DeepSeek Math&lt;/td&gt; &#xA;    &lt;td&gt;7B&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2401.02954&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://huggingface.co/deepseek-ai/deepseek-math-7b-instruct&#34;&gt;Hub&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/deepseek-ai/DeepSeek-LLM/raw/main/LICENSE-MODEL&#34;&gt;License&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚ùå&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;üìñ Documentation&lt;/h2&gt; &#xA;&lt;p&gt;To learn more about all the platform&#39;s capabilities, see the &lt;a href=&#34;https://oumi.ai/docs&#34;&gt;Oumi documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;ü§ù Join the Community!&lt;/h2&gt; &#xA;&lt;p&gt;Oumi is a community-first effort. Whether you are a developer, a researcher, or a non-technical user, all contributions are very welcome!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To contribute to the &lt;code&gt;oumi&lt;/code&gt; repository, please check the &lt;a href=&#34;https://github.com/oumi-ai/oumi/raw/main/CONTRIBUTING.md&#34;&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; for guidance on how to contribute to send your first Pull Request.&lt;/li&gt; &#xA; &lt;li&gt;Make sure to join our &lt;a href=&#34;https://discord.gg/oumi&#34;&gt;Discord community&lt;/a&gt; to get help, share your experiences, and contribute to the project!&lt;/li&gt; &#xA; &lt;li&gt;If you are interested in joining one of the community&#39;s open-science efforts, check out our &lt;a href=&#34;https://oumi.ai/community&#34;&gt;open collaboration&lt;/a&gt; page.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üôè Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;Oumi makes use of &lt;a href=&#34;https://oumi.ai/docs/en/latest/about/acknowledgements.html&#34;&gt;several libraries&lt;/a&gt; and tools from the open-source community. We would like to acknowledge and deeply thank the contributors of these projects! ‚ú® üåü üí´&lt;/p&gt; &#xA;&lt;h2&gt;üìù Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find Oumi useful in your research, please consider citing it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@software{oumi2025,&#xA;  author = {Oumi Community},&#xA;  title = {Oumi: an Open, End-to-end Platform for Building Large Foundation Models},&#xA;  month = {January},&#xA;  year = {2025},&#xA;  url = {https://github.com/oumi-ai/oumi}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üìú License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the Apache License 2.0. See the &lt;a href=&#34;https://raw.githubusercontent.com/oumi-ai/oumi/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; &#xA;&lt;p&gt;[^1]: Open models are defined as models with fully open weights, training code, and data, and a permissive license. See &lt;a href=&#34;https://opensource.org/ai&#34;&gt;Open Source Definitions&lt;/a&gt; for more information.&lt;/p&gt;</summary>
  </entry>
</feed>