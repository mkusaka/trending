<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-07-03T01:33:34Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>pydata/xarray</title>
    <updated>2024-07-03T01:33:34Z</updated>
    <id>tag:github.com,2024-07-03:/pydata/xarray</id>
    <link href="https://github.com/pydata/xarray" rel="alternate"></link>
    <summary type="html">&lt;p&gt;N-D labeled arrays and datasets in Python&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;xarray: N-D labeled arrays and datasets&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/pydata/xarray/actions?query=workflow%3ACI&#34;&gt;&lt;img src=&#34;https://github.com/pydata/xarray/workflows/CI/badge.svg?branch=main&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/pydata/xarray&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/pydata/xarray/branch/main/graph/badge.svg?flag=unittests&#34; alt=&#34;Code coverage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.xarray.dev/&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/xray/badge/?version=latest&#34; alt=&#34;Docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pandas.pydata.org/speed/xarray/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/benchmarked%20by-asv-green.svg?style=flat&#34; alt=&#34;Benchmarked with asv&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/xarray/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/xarray.svg?sanitize=true&#34; alt=&#34;Available on pypi&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/python/black&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true&#34; alt=&#34;Formatted with black&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://mypy-lang.org/&#34;&gt;&lt;img src=&#34;http://www.mypy-lang.org/static/mypy_badge.svg?sanitize=true&#34; alt=&#34;Checked with mypy&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.5281/zenodo.11183201&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/DOI/10.5281/zenodo.11183201.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://mybinder.org/v2/gh/pydata/xarray/main?urlpath=lab/tree/doc/examples/weather-data.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/launch-binder-579ACA.svg?logo=data:image/png;base64,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&#34; alt=&#34;Examples on binder&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/xarray_dev&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/xarray_dev?style=social&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;xarray&lt;/strong&gt; (pronounced &#34;ex-array&#34;, formerly known as &lt;strong&gt;xray&lt;/strong&gt;) is an open source project and Python package that makes working with labelled multi-dimensional arrays simple, efficient, and fun!&lt;/p&gt; &#xA;&lt;p&gt;Xarray introduces labels in the form of dimensions, coordinates and attributes on top of raw &lt;a href=&#34;https://www.numpy.org&#34;&gt;NumPy&lt;/a&gt;-like arrays, which allows for a more intuitive, more concise, and less error-prone developer experience. The package includes a large and growing library of domain-agnostic functions for advanced analytics and visualization with these data structures.&lt;/p&gt; &#xA;&lt;p&gt;Xarray was inspired by and borrows heavily from &lt;a href=&#34;https://pandas.pydata.org&#34;&gt;pandas&lt;/a&gt;, the popular data analysis package focused on labelled tabular data. It is particularly tailored to working with &lt;a href=&#34;https://www.unidata.ucar.edu/software/netcdf&#34;&gt;netCDF&lt;/a&gt; files, which were the source of xarray&#39;s data model, and integrates tightly with &lt;a href=&#34;https://dask.org&#34;&gt;dask&lt;/a&gt; for parallel computing.&lt;/p&gt; &#xA;&lt;h2&gt;Why xarray?&lt;/h2&gt; &#xA;&lt;p&gt;Multi-dimensional (a.k.a. N-dimensional, ND) arrays (sometimes called &#34;tensors&#34;) are an essential part of computational science. They are encountered in a wide range of fields, including physics, astronomy, geoscience, bioinformatics, engineering, finance, and deep learning. In Python, &lt;a href=&#34;https://www.numpy.org&#34;&gt;NumPy&lt;/a&gt; provides the fundamental data structure and API for working with raw ND arrays. However, real-world datasets are usually more than just raw numbers; they have labels which encode information about how the array values map to locations in space, time, etc.&lt;/p&gt; &#xA;&lt;p&gt;Xarray doesn&#39;t just keep track of labels on arrays -- it uses them to provide a powerful and concise interface. For example:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Apply operations over dimensions by name: &lt;code&gt;x.sum(&#39;time&#39;)&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Select values by label instead of integer location: &lt;code&gt;x.loc[&#39;2014-01-01&#39;]&lt;/code&gt; or &lt;code&gt;x.sel(time=&#39;2014-01-01&#39;)&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Mathematical operations (e.g., &lt;code&gt;x - y&lt;/code&gt;) vectorize across multiple dimensions (array broadcasting) based on dimension names, not shape.&lt;/li&gt; &#xA; &lt;li&gt;Flexible split-apply-combine operations with groupby: &lt;code&gt;x.groupby(&#39;time.dayofyear&#39;).mean()&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Database like alignment based on coordinate labels that smoothly handles missing values: &lt;code&gt;x, y = xr.align(x, y, join=&#39;outer&#39;)&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Keep track of arbitrary metadata in the form of a Python dictionary: &lt;code&gt;x.attrs&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Learn more about xarray in its official documentation at &lt;a href=&#34;https://docs.xarray.dev/&#34;&gt;https://docs.xarray.dev/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Try out an &lt;a href=&#34;https://mybinder.org/v2/gh/pydata/xarray/main?urlpath=lab/tree/doc/examples/weather-data.ipynb&#34;&gt;interactive Jupyter notebook&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;You can find information about contributing to xarray at our &lt;a href=&#34;https://docs.xarray.dev/en/stable/contributing.html&#34;&gt;Contributing page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Get in touch&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ask usage questions (&#34;How do I?&#34;) on &lt;a href=&#34;https://github.com/pydata/xarray/discussions&#34;&gt;GitHub Discussions&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Report bugs, suggest features or view the source code &lt;a href=&#34;https://github.com/pydata/xarray&#34;&gt;on GitHub&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;For less well defined questions or ideas, or to announce other projects of interest to xarray users, use the &lt;a href=&#34;https://groups.google.com/forum/#!forum/xarray&#34;&gt;mailing list&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;NumFOCUS&lt;/h2&gt; &#xA;&lt;img src=&#34;https://numfocus.org/wp-content/uploads/2017/07/NumFocus_LRG.png&#34; width=&#34;200&#34; href=&#34;https://numfocus.org/&#34;&gt; &#xA;&lt;p&gt;Xarray is a fiscally sponsored project of &lt;a href=&#34;https://numfocus.org&#34;&gt;NumFOCUS&lt;/a&gt;, a nonprofit dedicated to supporting the open source scientific computing community. If you like Xarray and want to support our mission, please consider making a &lt;a href=&#34;https://numfocus.salsalabs.org/donate-to-xarray/&#34;&gt;donation&lt;/a&gt; to support our efforts.&lt;/p&gt; &#xA;&lt;h2&gt;History&lt;/h2&gt; &#xA;&lt;p&gt;Xarray is an evolution of an internal tool developed at &lt;a href=&#34;http://climate.com/&#34;&gt;The Climate Corporation&lt;/a&gt;. It was originally written by Climate Corp researchers Stephan Hoyer, Alex Kleeman and Eugene Brevdo and was released as open source in May 2014. The project was renamed from &#34;xray&#34; in January 2016. Xarray became a fiscally sponsored project of &lt;a href=&#34;https://numfocus.org&#34;&gt;NumFOCUS&lt;/a&gt; in August 2018.&lt;/p&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;p&gt;Thanks to our many contributors!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/pydata/xarray/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=pydata/xarray&#34; alt=&#34;Contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright 2014-2023, xarray Developers&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &#34;AS IS&#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; &#xA;&lt;p&gt;Xarray bundles portions of pandas, NumPy and Seaborn, all of which are available under a &#34;3-clause BSD&#34; license:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;pandas: &lt;code&gt;setup.py&lt;/code&gt;, &lt;code&gt;xarray/util/print_versions.py&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;NumPy: &lt;code&gt;xarray/core/npcompat.py&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Seaborn: &lt;code&gt;_determine_cmap_params&lt;/code&gt; in &lt;code&gt;xarray/core/plot/utils.py&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Xarray also bundles portions of CPython, which is available under the &#34;Python Software Foundation License&#34; in &lt;code&gt;xarray/core/pycompat.py&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Xarray uses icons from the icomoon package (free version), which is available under the &#34;CC BY 4.0&#34; license.&lt;/p&gt; &#xA;&lt;p&gt;The full text of these licenses are included in the licenses directory.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>stanford-futuredata/ColBERT</title>
    <updated>2024-07-03T01:33:34Z</updated>
    <id>tag:github.com,2024-07-03:/stanford-futuredata/ColBERT</id>
    <link href="https://github.com/stanford-futuredata/ColBERT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ColBERT: state-of-the-art neural search (SIGIR&#39;20, TACL&#39;21, NeurIPS&#39;21, NAACL&#39;22, CIKM&#39;22, ACL&#39;23, EMNLP&#39;23)&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/stanford-futuredata/ColBERT/main/docs/images/colbertofficial.png&#34; width=&#34;430px&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;/p&gt;&#xA;&lt;h1&gt;ColBERT (v2)&lt;/h1&gt; &#xA;&lt;h3&gt;ColBERT is a &lt;em&gt;fast&lt;/em&gt; and &lt;em&gt;accurate&lt;/em&gt; retrieval model, enabling scalable BERT-based search over large text collections in tens of milliseconds.&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/stanford-futuredata/ColBERT/blob/main/docs/intro2new.ipynb&#34;&gt;&lt;img align=&#34;center&#34; src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/stanford-futuredata/ColBERT/main/docs/images/ColBERT-Framework-MaxSim-W370px.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;b&gt;Figure 1:&lt;/b&gt; ColBERT&#39;s late interaction, efficiently scoring the fine-grained similarity between a queries and a passage. &lt;/p&gt; &#xA;&lt;p&gt;As Figure 1 illustrates, ColBERT relies on fine-grained &lt;strong&gt;contextual late interaction&lt;/strong&gt;: it encodes each passage into a &lt;strong&gt;matrix&lt;/strong&gt; of token-level embeddings (shown above in blue). Then at search time, it embeds every query into another matrix (shown in green) and efficiently finds passages that contextually match the query using scalable vector-similarity (&lt;code&gt;MaxSim&lt;/code&gt;) operators.&lt;/p&gt; &#xA;&lt;p&gt;These rich interactions allow ColBERT to surpass the quality of &lt;em&gt;single-vector&lt;/em&gt; representation models, while scaling efficiently to large corpora. You can read more in our papers:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2004.12832&#34;&gt;&lt;strong&gt;ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT&lt;/strong&gt;&lt;/a&gt; (SIGIR&#39;20).&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.00814&#34;&gt;&lt;strong&gt;Relevance-guided Supervision for OpenQA with ColBERT&lt;/strong&gt;&lt;/a&gt; (TACL&#39;21).&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2101.00436&#34;&gt;&lt;strong&gt;Baleen: Robust Multi-Hop Reasoning at Scale via Condensed Retrieval&lt;/strong&gt;&lt;/a&gt; (NeurIPS&#39;21).&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2112.01488&#34;&gt;&lt;strong&gt;ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction&lt;/strong&gt;&lt;/a&gt; (NAACL&#39;22).&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2205.09707&#34;&gt;&lt;strong&gt;PLAID: An Efficient Engine for Late Interaction Retrieval&lt;/strong&gt;&lt;/a&gt; (CIKM&#39;22).&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.01340&#34;&gt;&lt;strong&gt;Moving Beyond Downstream Task Accuracy for Information Retrieval Benchmarking&lt;/strong&gt;&lt;/a&gt; (ACL&#39;23 Findings).&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.00807&#34;&gt;&lt;strong&gt;UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers&lt;/strong&gt;&lt;/a&gt; (EMNLP&#39;23).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ðŸš¨ &lt;strong&gt;Announcements&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;(1/28/24) One of the easiest ways to use ColBERT in applications nowadays is the semi-official, fast-growing &lt;a href=&#34;https://github.com/bclavie/ragatouille&#34;&gt;RAGatouille&lt;/a&gt; library.&lt;/li&gt; &#xA; &lt;li&gt;(1/29/23) We have merged a new index updater feature and support for additional Hugging Face models! These are in beta so please give us feedback as you try them out.&lt;/li&gt; &#xA; &lt;li&gt;(1/24/23) If you&#39;re looking for the &lt;strong&gt;DSPy&lt;/strong&gt; framework for composing retrievers like ColBERTv2 and LLMs, it&#39;s at: &lt;a href=&#34;https://github.com/stanfordnlp/dspy&#34;&gt;https://github.com/stanfordnlp/dspy&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ColBERTv1&lt;/h2&gt; &#xA;&lt;p&gt;The ColBERTv1 code from the SIGIR&#39;20 paper is in the &lt;a href=&#34;https://github.com/stanford-futuredata/ColBERT/tree/colbertv1&#34;&gt;&lt;code&gt;colbertv1&lt;/code&gt; branch&lt;/a&gt;. See &lt;a href=&#34;https://raw.githubusercontent.com/stanford-futuredata/ColBERT/main/#branches&#34;&gt;here&lt;/a&gt; for more information on other branches.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;(Update: nowadays you can typically do &lt;code&gt;pip install colbert-ai[torch,faiss-gpu]&lt;/code&gt; to get things up and running, but if you face issues conda is always more reliable for &lt;code&gt;faiss&lt;/code&gt; and &lt;code&gt;torch&lt;/code&gt;.)&lt;/p&gt; &#xA;&lt;p&gt;ColBERT requires Python 3.7+ and Pytorch 1.9+ and uses the &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;Hugging Face Transformers&lt;/a&gt; library.&lt;/p&gt; &#xA;&lt;p&gt;We strongly recommend creating a conda environment using the commands below. (If you don&#39;t have conda, follow the official &lt;a href=&#34;https://docs.anaconda.com/anaconda/install/linux/#installation&#34;&gt;conda installation guide&lt;/a&gt;.)&lt;/p&gt; &#xA;&lt;p&gt;We have also included a new environment file specifically for CPU-only environments (&lt;code&gt;conda_env_cpu.yml&lt;/code&gt;), but note that if you are testing CPU execution on a machine that includes GPUs you might need to specify &lt;code&gt;CUDA_VISIBLE_DEVICES=&#34;&#34;&lt;/code&gt; as part of your command. Note that a GPU is required for training and indexing.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda env create -f conda_env[_cpu].yml&#xA;conda activate colbert&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you face any problems, please &lt;a href=&#34;https://github.com/stanford-futuredata/ColBERT/issues&#34;&gt;open a new issue&lt;/a&gt; and we&#39;ll help you promptly!&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;Using ColBERT on a dataset typically involves the following steps.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Step 0: Preprocess your collection.&lt;/strong&gt; At its simplest, ColBERT works with tab-separated (TSV) files: a file (e.g., &lt;code&gt;collection.tsv&lt;/code&gt;) will contain all passages and another (e.g., &lt;code&gt;queries.tsv&lt;/code&gt;) will contain a set of queries for searching the collection.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Step 1: Download the &lt;a href=&#34;https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz&#34;&gt;pre-trained ColBERTv2 checkpoint&lt;/a&gt;.&lt;/strong&gt; This checkpoint has been trained on the MS MARCO Passage Ranking task. You can also &lt;em&gt;optionally&lt;/em&gt; &lt;a href=&#34;https://raw.githubusercontent.com/stanford-futuredata/ColBERT/main/#training&#34;&gt;train your own ColBERT model&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Step 2: Index your collection.&lt;/strong&gt; Once you have a trained ColBERT model, you need to &lt;a href=&#34;https://raw.githubusercontent.com/stanford-futuredata/ColBERT/main/#indexing&#34;&gt;index your collection&lt;/a&gt; to permit fast retrieval. This step encodes all passages into matrices, stores them on disk, and builds data structures for efficient search.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Step 3: Search the collection with your queries.&lt;/strong&gt; Given the model and index, you can &lt;a href=&#34;https://raw.githubusercontent.com/stanford-futuredata/ColBERT/main/#retrieval&#34;&gt;issue queries over the collection&lt;/a&gt; to retrieve the top-k passages for each query.&lt;/p&gt; &#xA;&lt;p&gt;Below, we illustrate these steps via an example run on the MS MARCO Passage Ranking task.&lt;/p&gt; &#xA;&lt;h2&gt;API Usage Notebook&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;NEW&lt;/strong&gt;: We have an experimental notebook on &lt;a href=&#34;https://colab.research.google.com/github/stanford-futuredata/ColBERT/blob/main/docs/intro2new.ipynb&#34;&gt;Google Colab&lt;/a&gt; that you can use with free GPUs. Indexing 10,000 on the free Colab T4 GPU takes six minutes.&lt;/p&gt; &#xA;&lt;p&gt;This Jupyter notebook &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/stanford-futuredata/ColBERT/main/docs/intro.ipynb&#34;&gt;docs/intro.ipynb notebook&lt;/a&gt;&lt;/strong&gt; illustrates using the key features of ColBERT with the new Python API.&lt;/p&gt; &#xA;&lt;p&gt;It includes how to download the ColBERTv2 model checkpoint trained on MS MARCO Passage Ranking and how to download our new LoTTE benchmark.&lt;/p&gt; &#xA;&lt;h2&gt;Data&lt;/h2&gt; &#xA;&lt;p&gt;This repository works directly with a simple &lt;strong&gt;tab-separated file&lt;/strong&gt; format to store queries, passages, and top-k ranked lists.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Queries: each line is &lt;code&gt;qid \t query text&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Collection: each line is &lt;code&gt;pid \t passage text&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Top-k Ranking: each line is &lt;code&gt;qid \t pid \t rank&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This works directly with the data format of the &lt;a href=&#34;https://github.com/microsoft/MSMARCO-Passage-Ranking&#34;&gt;MS MARCO Passage Ranking&lt;/a&gt; dataset. You will need the training triples (&lt;code&gt;triples.train.small.tar.gz&lt;/code&gt;), the official top-1000 ranked lists for the dev set queries (&lt;code&gt;top1000.dev&lt;/code&gt;), and the dev set relevant passages (&lt;code&gt;qrels.dev.small.tsv&lt;/code&gt;). For indexing the full collection, you will also need the list of passages (&lt;code&gt;collection.tar.gz&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;h2&gt;Indexing&lt;/h2&gt; &#xA;&lt;p&gt;For fast retrieval, indexing precomputes the ColBERT representations of passages.&lt;/p&gt; &#xA;&lt;p&gt;Example usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from colbert.infra import Run, RunConfig, ColBERTConfig&#xA;from colbert import Indexer&#xA;&#xA;if __name__==&#39;__main__&#39;:&#xA;    with Run().context(RunConfig(nranks=1, experiment=&#34;msmarco&#34;)):&#xA;&#xA;        config = ColBERTConfig(&#xA;            nbits=2,&#xA;            root=&#34;/path/to/experiments&#34;,&#xA;        )&#xA;        indexer = Indexer(checkpoint=&#34;/path/to/checkpoint&#34;, config=config)&#xA;        indexer.index(name=&#34;msmarco.nbits=2&#34;, collection=&#34;/path/to/MSMARCO/collection.tsv&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Retrieval&lt;/h2&gt; &#xA;&lt;p&gt;We typically recommend that you use ColBERT for &lt;strong&gt;end-to-end&lt;/strong&gt; retrieval, where it directly finds its top-k passages from the full collection:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from colbert.data import Queries&#xA;from colbert.infra import Run, RunConfig, ColBERTConfig&#xA;from colbert import Searcher&#xA;&#xA;if __name__==&#39;__main__&#39;:&#xA;    with Run().context(RunConfig(nranks=1, experiment=&#34;msmarco&#34;)):&#xA;&#xA;        config = ColBERTConfig(&#xA;            root=&#34;/path/to/experiments&#34;,&#xA;        )&#xA;        searcher = Searcher(index=&#34;msmarco.nbits=2&#34;, config=config)&#xA;        queries = Queries(&#34;/path/to/MSMARCO/queries.dev.small.tsv&#34;)&#xA;        ranking = searcher.search_all(queries, k=100)&#xA;        ranking.save(&#34;msmarco.nbits=2.ranking.tsv&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can optionally specify the &lt;code&gt;ncells&lt;/code&gt;, &lt;code&gt;centroid_score_threshold&lt;/code&gt;, and &lt;code&gt;ndocs&lt;/code&gt; search hyperparameters to trade off between speed and result quality. Defaults for different values of &lt;code&gt;k&lt;/code&gt; are listed in colbert/searcher.py.&lt;/p&gt; &#xA;&lt;p&gt;We can evaluate the MSMARCO rankings using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m utility.evaluate.msmarco_passages --ranking &#34;/path/to/msmarco.nbits=2.ranking.tsv&#34; --qrels &#34;/path/to/MSMARCO/qrels.dev.small.tsv&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Basic Training (ColBERTv1-style)&lt;/h2&gt; &#xA;&lt;p&gt;We provide a &lt;a href=&#34;https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz&#34;&gt;pre-trained model checkpoint&lt;/a&gt;, but we also detail how to train from scratch here. Note that this example demonstrates the ColBERTv1 style of training, but the provided checkpoint was trained with ColBERTv2.&lt;/p&gt; &#xA;&lt;p&gt;Training requires a JSONL triples file with a &lt;code&gt;[qid, pid+, pid-]&lt;/code&gt; list per line. The query IDs and passage IDs correspond to the specified &lt;code&gt;queries.tsv&lt;/code&gt; and &lt;code&gt;collection.tsv&lt;/code&gt; files respectively.&lt;/p&gt; &#xA;&lt;p&gt;Example usage (training on 4 GPUs):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from colbert.infra import Run, RunConfig, ColBERTConfig&#xA;from colbert import Trainer&#xA;&#xA;if __name__==&#39;__main__&#39;:&#xA;    with Run().context(RunConfig(nranks=4, experiment=&#34;msmarco&#34;)):&#xA;&#xA;        config = ColBERTConfig(&#xA;            bsize=32,&#xA;            root=&#34;/path/to/experiments&#34;,&#xA;        )&#xA;        trainer = Trainer(&#xA;            triples=&#34;/path/to/MSMARCO/triples.train.small.tsv&#34;,&#xA;            queries=&#34;/path/to/MSMARCO/queries.train.small.tsv&#34;,&#xA;            collection=&#34;/path/to/MSMARCO/collection.tsv&#34;,&#xA;            config=config,&#xA;        )&#xA;&#xA;        checkpoint_path = trainer.train()&#xA;&#xA;        print(f&#34;Saved checkpoint to {checkpoint_path}...&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Advanced Training (ColBERTv2-style)&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from colbert.infra.run import Run&#xA;from colbert.infra.config import ColBERTConfig, RunConfig&#xA;from colbert import Trainer&#xA;&#xA;&#xA;def train():&#xA;    # use 4 gpus (e.g. four A100s, but you can use fewer by changing nway,accumsteps,bsize).&#xA;    with Run().context(RunConfig(nranks=4)):&#xA;        triples = &#39;/path/to/examples.64.json&#39;  # `wget https://huggingface.co/colbert-ir/colbertv2.0_msmarco_64way/resolve/main/examples.json?download=true` (26GB)&#xA;        queries = &#39;/path/to/MSMARCO/queries.train.tsv&#39;&#xA;        collection = &#39;/path/to/MSMARCO/collection.tsv&#39;&#xA;&#xA;        config = ColBERTConfig(bsize=32, lr=1e-05, warmup=20_000, doc_maxlen=180, dim=128, attend_to_mask_tokens=False, nway=64, accumsteps=1, similarity=&#39;cosine&#39;, use_ib_negatives=True)&#xA;        trainer = Trainer(triples=triples, queries=queries, collection=collection, config=config)&#xA;&#xA;        trainer.train(checkpoint=&#39;colbert-ir/colbertv1.9&#39;)  # or start from scratch, like `bert-base-uncased`&#xA;&#xA;&#xA;if __name__ == &#39;__main__&#39;:&#xA;    train()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running a lightweight ColBERTv2 server&lt;/h2&gt; &#xA;&lt;p&gt;We provide a script to run a lightweight server which serves k (upto 100) results in ranked order for a given search query, in JSON format. This script can be used to power DSP programs.&lt;/p&gt; &#xA;&lt;p&gt;To run the server, update the environment variables &lt;code&gt;INDEX_ROOT&lt;/code&gt; and &lt;code&gt;INDEX_NAME&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file to point to the appropriate ColBERT index. The run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python server.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A sample query:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;http://localhost:8893/api/search?query=Who won the 2022 FIFA world cup&amp;amp;k=25&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Branches&lt;/h2&gt; &#xA;&lt;h3&gt;Supported branches&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/stanford-futuredata/ColBERT/tree/main&#34;&gt;&lt;code&gt;main&lt;/code&gt;&lt;/a&gt;: Stable branch with ColBERTv2 + PLAID.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/stanford-futuredata/ColBERT/tree/colbertv1&#34;&gt;&lt;code&gt;colbertv1&lt;/code&gt;&lt;/a&gt;: Legacy branch for ColBERTv1.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Deprecated branches&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/stanford-futuredata/ColBERT/tree/new_api&#34;&gt;&lt;code&gt;new_api&lt;/code&gt;&lt;/a&gt;: Base ColBERTv2 implementation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/stanford-futuredata/ColBERT/tree/cpu_inference&#34;&gt;&lt;code&gt;cpu_inference&lt;/code&gt;&lt;/a&gt;: ColBERTv2 implementation with CPU search support.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/stanford-futuredata/ColBERT/tree/fast_search&#34;&gt;&lt;code&gt;fast_search&lt;/code&gt;&lt;/a&gt;: ColBERTv2 implementation with PLAID.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/stanford-futuredata/ColBERT/tree/binarization&#34;&gt;&lt;code&gt;binarization&lt;/code&gt;&lt;/a&gt;: ColBERT with a baseline binarization-based compression strategy (as opposed to ColBERTv2&#39;s residual compression, which we found to be more robust).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;p&gt;ColBERT logo designed by Chuyi Zhang.&lt;/p&gt;</summary>
  </entry>
</feed>