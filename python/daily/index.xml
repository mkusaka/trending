<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-27T01:42:34Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>dvruette/sd-webui-fabric</title>
    <updated>2023-07-27T01:42:34Z</updated>
    <id>tag:github.com,2023-07-27:/dvruette/sd-webui-fabric</id>
    <link href="https://github.com/dvruette/sd-webui-fabric" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FABRIC Plugin for Stable Diffusion WebUI&lt;/h1&gt; &#xA;&lt;p&gt;Alpha version of a plugin for &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;automatic1111/stable-diffusion-webui&lt;/a&gt;. Expect bugs and rough edges and feel free to contribute if you know how fix them.&lt;/p&gt; &#xA;&lt;p&gt;ğŸ“œ Paper: &lt;a href=&#34;https://arxiv.org/abs/2307.10159&#34;&gt;https://arxiv.org/abs/2307.10159&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;ğŸ¨ Project page: &lt;a href=&#34;https://sd-fabric.github.io&#34;&gt;https://sd-fabric.github.io&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/dvruette/sd-webui-fabric/main/static/fabric_demo.gif&#34; alt=&#34;demo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open the &#34;Extensions&#34; tab&lt;/li&gt; &#xA; &lt;li&gt;Open the &#34;Install from URL&#34; tab&lt;/li&gt; &#xA; &lt;li&gt;Copy-paste &lt;code&gt;https://github.com/dvruette/sd-webui-fabric.git&lt;/code&gt; into &#34;URL for extension&#39;s git repository&#34; and press &#34;Install&#34;&lt;/li&gt; &#xA; &lt;li&gt;Switch to the &#34;Installed&#34; tab and press &#34;Apply and restart UI&#34;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Note: Since FABRIC is quite VRAM intensive, using &lt;code&gt;--opt-split-attention&lt;/code&gt; is recommended.&lt;/p&gt; &#xA;&lt;h3&gt;Compatibility Notes&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;SDXL is currently not supported (PRs welcome!)&lt;/li&gt; &#xA; &lt;li&gt;Compatibility with other plugins is largely untested. If you experience errors with other plugins enabled, please disable all other plugins for the best chance for FABRIC to work. If you can figure out which plugin is incompatible, please open an issue.&lt;/li&gt; &#xA; &lt;li&gt;The plugin is INCOMPATIBLE with &lt;code&gt;reference&lt;/code&gt; mode in the ControlNet plugin. Instead of using a reference image, simply add it as a liked image. If you accidentally enable FABRIC and &lt;code&gt;reference&lt;/code&gt; mode at the same time, you will have to restart the WebUI to fix it.&lt;/li&gt; &#xA; &lt;li&gt;Some attention processors are not supported. In particular, &lt;code&gt;--opt-sub-quad-attention&lt;/code&gt; and &lt;code&gt;--opt-split-attention-v1&lt;/code&gt; are not supported at the moment.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How-to and Examples&lt;/h2&gt; &#xA;&lt;p&gt;Coming soon. Feel free to share examples with us if you have found something that works well and we&#39;ll add it here :)&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{vonrutte2023fabric,&#xA;      title={FABRIC: Personalizing Diffusion Models with Iterative Feedback}, &#xA;      author={Dimitri von RÃ¼tte and Elisabetta Fedele and Jonathan Thomm and Lukas Wolf},&#xA;      year={2023},&#xA;      eprint={2307.10159},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>invictus717/MetaTransformer</title>
    <updated>2023-07-27T01:42:34Z</updated>
    <id>tag:github.com,2023-07-27:/invictus717/MetaTransformer</id>
    <link href="https://github.com/invictus717/MetaTransformer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Meta-Transformer for Unified Multimodal Learning&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;assets\Meta-Transformer_banner.png&#34; width=&#34;80%&#34; height=&#34;80%&#34;&gt; &lt;/p&gt; &#xA;&lt;div&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;a href=&#34;https://scholar.google.com/citations?user=KuYlJCIAAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34;&gt;Yiyuan Zhang&lt;sup&gt;1,2*&lt;/sup&gt;&lt;/a&gt;â€ƒ &#xA;  &lt;a href=&#34;https://kxgong.github.io/&#34; target=&#34;_blank&#34;&gt;Kaixiong Gong&lt;sup&gt;1,2*&lt;/sup&gt;&lt;/a&gt;â€ƒ &#xA;  &lt;a href=&#34;http://kpzhang93.github.io/&#34; target=&#34;_blank&#34;&gt;Kaipeng Zhang&lt;sup&gt;2,â€ &lt;/sup&gt;&lt;/a&gt;â€ƒ &#xA;  &lt;br&gt; &#xA;  &lt;a href=&#34;http://www.ee.cuhk.edu.hk/~hsli/&#34; target=&#34;_blank&#34;&gt;Hongsheng Li &lt;sup&gt;1,2&lt;/sup&gt;&lt;/a&gt;â€ƒ &#xA;  &lt;a href=&#34;https://mmlab.siat.ac.cn/yuqiao/index.html&#34; target=&#34;_blank&#34;&gt;Yu Qiao &lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;â€ƒ &#xA;  &lt;a href=&#34;https://wlouyang.github.io/&#34; target=&#34;_blank&#34;&gt;Wanli Ouyang&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;â€ƒ &#xA;  &lt;a href=&#34;http://people.eecs.berkeley.edu/~xyyue/&#34; target=&#34;_blank&#34;&gt;Xiangyu Yue&lt;sup&gt;1,â€ ,â€¡&lt;/sup&gt;&lt;/a&gt; &#xA; &lt;/div&gt; &#xA; &lt;div&gt; &#xA;  &lt;div align=&#34;center&#34;&gt; &#xA;   &lt;sup&gt;1&lt;/sup&gt;Multimedia Lab, The Chinese University of Hong Kongâ€ƒ &#xA;   &lt;br&gt; &#xA;   &lt;sup&gt;2&lt;/sup&gt;OpenGVLabï¼ŒShanghai AI Laboratory &#xA;   &lt;br&gt; &#xA;   &lt;sup&gt;*&lt;/sup&gt; Equal Contributionâ€ƒ &#xA;   &lt;sup&gt;â€ &lt;/sup&gt; Corresponding Authorâ€ƒ &#xA;   &lt;sup&gt;â€¡&lt;/sup&gt; Project Leadâ€ƒ &#xA;  &lt;/div&gt; &#xA;  &lt;hr&gt; &#xA;  &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2307.10802&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arxiv-2307.10802-b31b1b?style=plastic&amp;amp;color=b31b1b&amp;amp;link=https%3A%2F%2Farxiv.org%2Fabs%2F2307.10802&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://kxgong.github.io/meta_transformer/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project-Website-brightgreen&#34; alt=&#34;website&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://mp.weixin.qq.com/s/r38bzqdJxDZUvtDI0c9CEw&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83-%E7%AE%80%E4%BB%8B-brightgreen&#34; alt=&#34;blog-cn&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/papers/2307.10802&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Space-blue&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/stars/invictus717/MetaTransformer?style=social&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://twitter.com/_akhaliq/status/1682248055637041152&#34;&gt;&lt;img src=&#34;https://img.icons8.com/color/48/000000/twitter.png&#34; width=&#34;25&#34; height=&#34;25&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=V8L8xbsTyls&amp;amp;ab_channel=CSBoard&#34;&gt;&lt;img src=&#34;https://img.icons8.com/color/48/000000/youtube-play.png&#34; width=&#34;25&#34; height=&#34;25&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://open.spotify.com/episode/6JJxcy2zMtTwr4jXPQEXjh&#34;&gt; &lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/1/19/Spotify_logo_without_text.svg?sanitize=true&#34; width=&#34;20&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;h3&gt;ğŸŒŸ Single Foundation Model Supports A Wide Range of Applications&lt;/h3&gt; &#xA;  &lt;p&gt;As a foundation model, Meta-Transformer can handle data from 12 modalities, which determines that it can support a wide range of applications. As shown in this figure, Meta-Transformer can provide services for downstream tasks including stock analysis ğŸ“ˆ, weather forecasting â˜€ï¸ â˜” â˜ï¸ â„ï¸ â›„ âš¡, remote sensing ğŸ“¡, autonomous driving ğŸš—, social network ğŸŒ, speech recognition ğŸ”‰, etc.&lt;/p&gt; &#xA;  &lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;assets\Meta-Transformer_application.png&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt; &lt;/p&gt; &#xA;  &lt;p&gt;&lt;strong&gt;Table 1&lt;/strong&gt;: Meta-Transformer is capable of handling up to 12 modalities, including natural language &lt;img src=&#34;assets\icons\text.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, RGB images &lt;img src=&#34;assets\icons\img.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, point clouds &lt;img src=&#34;assets\icons\pcd.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, audios &lt;img src=&#34;assets\icons\audio.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, videos &lt;img src=&#34;assets\icons\video.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, tabular data &lt;img src=&#34;assets\icons\table.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, graph &lt;img src=&#34;assets\icons\graph.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, time series data &lt;img src=&#34;assets\icons\time.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, hyper-spectral images &lt;img src=&#34;assets\icons\hyper.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, IMU &lt;img src=&#34;assets\icons\imu.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, medical images &lt;img src=&#34;assets\icons\xray.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, and infrared images &lt;img src=&#34;assets\icons\infrared.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;.&lt;/p&gt; &#xA;  &lt;p align=&#34;left&#34;&gt; &lt;img src=&#34;assets\Meta-Transformer_cmp.png&#34; width=&#34;100%&#34;&gt; &lt;/p&gt; &#xA;  &lt;h2&gt;ğŸš©ğŸš©ğŸš© Shared-Encoder, Unpaired Data, More Modalities&lt;/h2&gt; &#xA;  &lt;div&gt; &#xA;   &lt;img class=&#34;image&#34; src=&#34;assets\Meta-Transformer_teaser.png&#34; width=&#34;52%&#34; height=&#34;100%&#34;&gt; &#xA;   &lt;img class=&#34;image&#34; src=&#34;assets\Meta-Transformer_exp.png&#34; width=&#34;45.2%&#34; height=&#34;100%&#34;&gt; &#xA;  &lt;/div&gt; &#xA;  &lt;p&gt;This repository is built to explore the potential and extensibility of transformers for multimodal learning. We utilize the advantages of Transformers to deal with length-variant sequences. Then we propose the &lt;em&gt;Data-to-Sequence&lt;/em&gt; tokenization following a meta-scheme, then we apply it to 12 modalities including text, image, point cloud, audio, video, infrared, hyper-spectral, X-Ray, tabular, graph, time-series, and Inertial Measurement Unit (IMU) data.&lt;/p&gt; &#xA;  &lt;p align=&#34;left&#34;&gt; &lt;img src=&#34;assets\Meta-Transformer_data2seq.png&#34; width=&#34;100%&#34;&gt; &lt;/p&gt; &#xA;  &lt;p&gt;After obtaining the token sequence, we employ a modality-shared encoder to extract representation across different modalities. With task-specific heads, Meta-Transformer can handle various tasks on the different modalities, such as: classification, detection, and segmentation.&lt;/p&gt; &#xA;  &lt;p align=&#34;left&#34;&gt; &lt;img src=&#34;assets\Meta-Transformer_framework.png&#34; width=&#34;100%&#34;&gt; &lt;/p&gt; &#xA;  &lt;h1&gt;ğŸŒŸ News&lt;/h1&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;2023.7.25:&lt;/strong&gt; ğŸ‰ğŸ‰ğŸ‰ We have released a well-documented code for graph data understanding. The implementation for Tabular data and point cloud will be released very soon.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;2023.7.23:&lt;/strong&gt; We have released the code and pretrained weights for image understanding and time-series forcasting.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;2023.7.22:&lt;/strong&gt; ğŸŒŸğŸŒŸğŸŒŸ Pretrained weights and a usage demo for our Meta-Transformer have been released. Comprehensive documentation and implementation of the image modality are underway and will be released soon. Stay tuned for more exciting updates!âŒ›âŒ›âŒ›&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;2023.7.21:&lt;/strong&gt; Paper is released at &lt;a href=&#34;https://arxiv.org/abs/2307.10802&#34;&gt;arxiv&lt;/a&gt;, and code will be gradually released.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;2023.7.8:&lt;/strong&gt; Github Repository Initialization.&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA;  &lt;h1&gt;ğŸ”“ Model Zoo&lt;/h1&gt; &#xA;  &lt;!-- &lt;details&gt; --&gt; &#xA;  &lt;summary&gt; Open-source Modality-Agnostic Models &lt;/summary&gt; &#xA;  &lt;br&gt; &#xA;  &lt;div&gt; &#xA;   &lt;table&gt; &#xA;    &lt;thead&gt; &#xA;     &lt;tr&gt; &#xA;      &lt;th align=&#34;center&#34;&gt;Model&lt;/th&gt; &#xA;      &lt;th align=&#34;center&#34;&gt;Pretraining&lt;/th&gt; &#xA;      &lt;th align=&#34;center&#34;&gt;Scale&lt;/th&gt; &#xA;      &lt;th align=&#34;center&#34;&gt;#Param&lt;/th&gt; &#xA;      &lt;th align=&#34;center&#34;&gt;Download&lt;/th&gt; &#xA;     &lt;/tr&gt; &#xA;    &lt;/thead&gt; &#xA;    &lt;tbody&gt; &#xA;     &lt;tr&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;Meta-Transformer-B16&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;LAION-2B&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;Base&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;85M&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/19ahcN2QKknkir_bayhTW5rucuAiX0OXq/view?usp=sharing&#34;&gt;ckpt&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;/tr&gt; &#xA;     &lt;tr&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;Meta-Transformer-L14&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;LAION-2B&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;Large&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;302M&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/15EtzCBAQSqmelhdLz6k880A19_RpcX9B/view?usp=drive_link&#34;&gt;ckpt&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;/tr&gt; &#xA;    &lt;/tbody&gt; &#xA;   &lt;/table&gt; &#xA;  &lt;/div&gt; &#xA;  &lt;!-- &lt;/details&gt; --&gt; &#xA;  &lt;!-- &lt;details&gt; --&gt; &#xA;  &lt;summary&gt;Demo of Use for Pretrained Encoder&lt;/summary&gt; &#xA;  &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from timm.models.vision_transformer import Block&#xA;ckpt = torch.load(&#34;Meta-Transformer_base_patch16_encoder.pth&#34;)&#xA;encoder = nn.Sequential(*[&#xA;            Block(&#xA;                dim=768,&#xA;                num_heads=12,&#xA;                mlp_ratio=4.,&#xA;                qkv_bias=True,&#xA;                norm_layer=nn.LayerNorm,&#xA;                act_layer=nn.GELU&#xA;            )&#xA;            for i in range(12)])&#xA;encoder.load_state_dict(ckpt,strict=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;!-- &lt;/details&gt; --&gt; &#xA;  &lt;h1&gt;ğŸ•™ ToDo&lt;/h1&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Meta-Transformer with Large Language Models.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Multimodal Joint Training with Meta-Transformer.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Support More Modalities and More Tasks.&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA;  &lt;h1&gt;Contact&lt;/h1&gt; &#xA;  &lt;p&gt;ğŸš€ğŸš€ğŸš€ We aspire to shape this repository into &lt;strong&gt;a formidable foundation for mainstream AI perception tasks across diverse modalities&lt;/strong&gt;. Your contributions can play a significant role in this endeavor, and we warmly welcome your participation in our project!&lt;/p&gt; &#xA;  &lt;p&gt;To contact us, never hestitate to send an email to &lt;code&gt;yiyuanzhang.ai@gmail.com&lt;/code&gt; ,&lt;code&gt;kaixionggong@gmail.com&lt;/code&gt;, &lt;code&gt;zhangkaipeng@pjlab.org.cn&lt;/code&gt;, or &lt;code&gt;xyyue@ie.cuhk.edu.hk&lt;/code&gt;! &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;  &lt;h1&gt;Citation&lt;/h1&gt; &#xA;  &lt;p&gt;If the code and paper help your research, please kindly cite:&lt;/p&gt; &#xA;  &lt;pre&gt;&lt;code&gt;@article{zhang2023metatransformer,&#xA;        title={Meta-Transformer: A Unified Framework for Multimodal Learning}, &#xA;        author={Zhang, Yiyuan and Gong, Kaixiong and Zhang, Kaipeng and Li, Hongsheng and Qiao, Yu and Ouyang, Wanli and Yue, Xiangyu},&#xA;        year={2023},&#xA;        journal={arXiv preprint arXiv:2307.10802},&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;h1&gt;License&lt;/h1&gt; &#xA;  &lt;p&gt;This project is released under the &lt;a href=&#34;https://raw.githubusercontent.com/invictus717/MetaTransformer/master/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; &#xA;  &lt;h1&gt;Acknowledgement&lt;/h1&gt; &#xA;  &lt;p&gt;This code is developed based on excellent open-sourced projects including &lt;a href=&#34;https://github.com/open-mmlab/mmpretrain/tree/mmcls-1.x&#34;&gt;MMClassification&lt;/a&gt;, &lt;a href=&#34;https://github.com/open-mmlab/mmdetection&#34;&gt;MMDetection&lt;/a&gt;, &lt;a href=&#34;https://github.com/open-mmlab/mmsegmentation&#34;&gt;MMsegmentation&lt;/a&gt;, &lt;a href=&#34;https://github.com/guochengqian/openpoints&#34;&gt;OpenPoints&lt;/a&gt;, &lt;a href=&#34;https://github.com/thuml/Time-Series-Library&#34;&gt;Time-Series-Library&lt;/a&gt;, &lt;a href=&#34;https://github.com/microsoft/Graphormer&#34;&gt;Graphomer&lt;/a&gt;, &lt;a href=&#34;https://github.com/danfenghong/IEEE_TGRS_SpectralFormer&#34;&gt;SpectralFormer&lt;/a&gt;, and &lt;a href=&#34;https://github.com/czczup/ViT-Adapter&#34;&gt;ViT-Adapter&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;/div&gt;&#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>FlagAlpha/Llama2-Chinese</title>
    <updated>2023-07-27T01:42:34Z</updated>
    <id>tag:github.com,2023-07-27:/FlagAlpha/Llama2-Chinese</id>
    <link href="https://github.com/FlagAlpha/Llama2-Chinese" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Llamaä¸­æ–‡ç¤¾åŒºï¼Œæœ€å¥½çš„ä¸­æ–‡Llamaå¤§æ¨¡å‹ï¼Œå®Œå…¨å¼€æºå¯å•†ç”¨&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; Llama2-Chinese &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/assets/llama.png&#34; alt=&#34;Llama&#34; style=&#34;width: 20%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;font face=&#34;é»‘ä½“&#34; color=&#34;orange&#34; size=&#34;6&#34;&gt; æœ€å¥½çš„ä¸­æ–‡Llamaå¤§æ¨¡å‹ &lt;/font&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://llama.family&#34;&gt;åœ¨çº¿ä½“éªŒï¼šllama.family&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ—‚ï¸ å†…å®¹å¯¼å¼•&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E5%9B%BD%E5%86%85llama2%E6%9C%80%E6%96%B0%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%E4%B8%8A%E7%BA%BF&#34;&gt;ğŸ¼ å›½å†…Llama2æœ€æ–°ä¸‹è½½åœ°å€ä¸Šçº¿ï¼&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E7%A4%BE%E5%8C%BA%E4%BB%8B%E7%BB%8Dllama2%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA&#34;&gt;ğŸ”¥ ç¤¾åŒºä»‹ç»ï¼šLlama2ä¸­æ–‡ç¤¾åŒº&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E6%8B%A9llama2%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA&#34;&gt;ä¸ºä»€ä¹ˆé€‰æ‹©Llama2ä¸­æ–‡ç¤¾åŒºï¼Ÿ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E7%A4%BE%E5%8C%BA%E6%B4%BB%E5%8A%A8&#34;&gt;ç¤¾åŒºæ´»åŠ¨&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E7%AB%8B%E5%8D%B3%E5%8A%A0%E5%85%A5%E6%88%91%E4%BB%AC&#34;&gt;ç«‹å³åŠ å…¥æˆ‘ä»¬ï¼&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E7%A4%BE%E5%8C%BA%E5%85%AC%E5%91%8A&#34;&gt;ğŸ“¢ ç¤¾åŒºå…¬å‘Š&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8826%E6%97%A5%E6%96%B0%E5%A2%9Ellama2-13b%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E5%8F%82%E6%95%B0%E7%9A%844bit%E9%87%8F%E5%8C%96%E5%8E%8B%E7%BC%A9%E7%89%88%E6%9C%AC&#34;&gt;2023å¹´7æœˆ26æ—¥ï¼šæ–°å¢Llama2-13Bä¸­æ–‡å¾®è°ƒå‚æ•°çš„4bité‡åŒ–å‹ç¼©ç‰ˆæœ¬ï¼&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8825%E6%97%A5%E7%A4%BE%E5%8C%BA%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7llama%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA%E6%AC%A2%E8%BF%8E%E5%A4%A7%E5%AE%B6%E5%85%B3%E6%B3%A8%E8%8E%B7%E5%8F%96%E6%9C%80%E6%96%B0%E5%88%86%E4%BA%AB%E5%92%8C%E5%8A%A8%E6%80%81&#34;&gt;2023å¹´7æœˆ25æ—¥ï¼šç¤¾åŒºå¾®ä¿¡å…¬ä¼—å·â€œLlamaä¸­æ–‡ç¤¾åŒºâ€æ¬¢è¿å¤§å®¶å…³æ³¨ï¼Œè·å–æœ€æ–°åˆ†äº«å’ŒåŠ¨æ€ï¼&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8824%E6%97%A5flagalpha%E6%96%B0%E5%A2%9Ellama2-13b%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E5%8F%82%E6%95%B0&#34;&gt;2023å¹´7æœˆ24æ—¥ï¼šFlagAlphaæ–°å¢Llama2-13Bä¸­æ–‡å¾®è°ƒå‚æ•°ï¼&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8824%E6%97%A5llamafamily%E6%96%B0%E5%A2%9Ellama2-70b%E5%9C%A8%E7%BA%BF%E4%BD%93%E9%AA%8C&#34;&gt;2023å¹´7æœˆ24æ—¥ï¼šllama.familyæ–°å¢Llama2-70Båœ¨çº¿ä½“éªŒï¼&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8823%E6%97%A5llama2%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E5%8F%82%E6%95%B0%E5%8F%91%E5%B8%83%E8%87%B3hugging-face%E4%BB%93%E5%BA%93flagalpha&#34;&gt;2023å¹´7æœˆ23æ—¥ï¼šLlama2ä¸­æ–‡å¾®è°ƒå‚æ•°å‘å¸ƒè‡³Hugging Faceä»“åº“FlagAlphaï¼&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8822%E6%97%A5llama2%E5%9C%A8%E7%BA%BF%E4%BD%93%E9%AA%8C%E9%93%BE%E6%8E%A5llamafamily%E4%B8%8A%E7%BA%BF%E5%90%8C%E6%97%B6%E5%8C%85%E5%90%ABmeta%E5%8E%9F%E7%89%88%E5%92%8C%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E7%89%88%E6%9C%AC&#34;&gt;2023å¹´7æœˆ22æ—¥ï¼šLlama2åœ¨çº¿ä½“éªŒé“¾æ¥llama.familyä¸Šçº¿ï¼ŒåŒæ—¶åŒ…å«MetaåŸç‰ˆå’Œä¸­æ–‡å¾®è°ƒç‰ˆæœ¬ï¼&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8821%E6%97%A5%E8%AF%84%E6%B5%8B%E4%BA%86meta%E5%8E%9F%E5%A7%8B%E7%89%88llama2-chat%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%AD%E6%96%87%E9%97%AE%E7%AD%94%E8%83%BD%E5%8A%9B&#34;&gt;2023å¹´7æœˆ21æ—¥ï¼šè¯„æµ‹äº†MetaåŸå§‹ç‰ˆLlama2 Chatæ¨¡å‹çš„ä¸­æ–‡é—®ç­”èƒ½åŠ›ï¼&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8821%E6%97%A5%E6%96%B0%E5%A2%9Ellama2%E6%A8%A1%E5%9E%8B%E7%9A%84hugging-face%E7%89%88%E6%9C%AC%E5%9B%BD%E5%86%85%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80&#34;&gt;2023å¹´7æœˆ21æ—¥ï¼šæ–°å¢Llama2æ¨¡å‹çš„Hugging Faceç‰ˆæœ¬å›½å†…ä¸‹è½½åœ°å€ï¼&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8820%E6%97%A5%E6%96%B0%E5%A2%9E%E9%A3%9E%E4%B9%A6%E7%9F%A5%E8%AF%86%E5%BA%93%E6%96%87%E6%A1%A3%E6%AC%A2%E8%BF%8E%E5%A4%A7%E5%AE%B6%E4%B8%80%E8%B5%B7%E5%85%B1%E5%BB%BA&#34;&gt;2023å¹´7æœˆ20æ—¥ï¼šæ–°å¢é£ä¹¦çŸ¥è¯†åº“æ–‡æ¡£ï¼Œæ¬¢è¿å¤§å®¶ä¸€èµ·å…±å»ºï¼&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8820%E6%97%A5%E5%9B%BD%E5%86%85llama2%E6%9C%80%E6%96%B0%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%E4%B8%8A%E7%BA%BF&#34;&gt;2023å¹´7æœˆ20æ—¥ï¼šå›½å†…Llama2æœ€æ–°ä¸‹è½½åœ°å€ä¸Šçº¿ï¼&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8819%E6%97%A5%E6%AD%A3%E5%BC%8F%E5%90%AF%E5%8A%A8llama2%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E5%85%B3%E6%B3%A8%E6%88%91%E4%BB%AC%E8%8E%B7%E5%8F%96%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81&#34;&gt;2023å¹´7æœˆ19æ—¥ï¼šæ­£å¼å¯åŠ¨Llama2æ¨¡å‹çš„ä¸­æ–‡é¢„è®­ç»ƒï¼Œå…³æ³¨æˆ‘ä»¬è·å–å®æ—¶åŠ¨æ€ï¼&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8819%E6%97%A5llama2%E5%9B%BD%E5%86%85%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%E6%AD%A3%E5%9C%A8%E5%90%AF%E5%8A%A8%E6%95%AC%E8%AF%B7%E6%9C%9F%E5%BE%85&#34;&gt;2023å¹´7æœˆ19æ—¥ï¼šLlama2å›½å†…ä¸‹è½½åœ°å€æ­£åœ¨å¯åŠ¨ï¼Œæ•¬è¯·æœŸå¾…ï¼&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8819%E6%97%A5%E5%BC%80%E5%90%AFllama2%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA%E6%AC%A2%E8%BF%8E%E5%A4%A7%E5%AE%B6%E5%8A%A0%E5%85%A5&#34;&gt;2023å¹´7æœˆ19æ—¥ï¼šå¼€å¯Llama2ä¸­æ–‡ç¤¾åŒºï¼Œæ¬¢è¿å¤§å®¶åŠ å…¥ï¼&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90&#34;&gt;ğŸ“ æ•°æ®æ¥æº&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2&#34;&gt;â¬ æ¨¡å‹éƒ¨ç½²&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B&#34;&gt;é¢„è®­ç»ƒæ¨¡å‹&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#chat%E6%A8%A1%E5%9E%8B&#34;&gt;Chatæ¨¡å‹&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%94%A8%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B&#34;&gt;æ¨¡å‹è°ƒç”¨ä»£ç ç¤ºä¾‹&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#gradio%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E9%97%AE%E7%AD%94%E5%B9%B3%E5%8F%B0&#34;&gt;Gradioå¿«é€Ÿæ­å»ºé—®ç­”å¹³å°&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83&#34;&gt;ğŸ’¡ æ¨¡å‹å¾®è°ƒ&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E5%BE%AE%E8%B0%83%E8%BF%87%E7%A8%8B&#34;&gt;å¾®è°ƒè¿‡ç¨‹&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#step1-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87&#34;&gt;Step1: ç¯å¢ƒå‡†å¤‡&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#step2-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87&#34;&gt;Step2: æ•°æ®å‡†å¤‡&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#step3-%E5%BE%AE%E8%B0%83%E8%84%9A%E6%9C%AC&#34;&gt;Step3: å¾®è°ƒè„šæœ¬&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E5%8F%82%E6%95%B0&#34;&gt;ä¸­æ–‡å¾®è°ƒå‚æ•°&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96&#34;&gt;ğŸ„ æ¨¡å‹é‡åŒ–&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B&#34;&gt;ğŸ¥‡ æ¨¡å‹è¯„æµ‹&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99&#34;&gt;ğŸ“– å­¦ä¹ èµ„æ–™&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#meta%E5%AE%98%E6%96%B9%E5%AF%B9%E4%BA%8Ellama2%E7%9A%84%E4%BB%8B%E7%BB%8D&#34;&gt;Metaå®˜æ–¹å¯¹äºLlama2çš„ä»‹ç»&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#llama%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87&#34;&gt;Llamaç›¸å…³è®ºæ–‡&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#llama2%E7%9A%84%E8%AF%84%E6%B5%8B%E7%BB%93%E6%9E%9C&#34;&gt;Llama2çš„è¯„æµ‹ç»“æœ&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E8%87%B4%E8%B0%A2&#34;&gt;ğŸ‰ è‡´è°¢&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E9%97%AE%E9%A2%98%E5%8F%8D%E9%A6%88&#34;&gt;ğŸ¤” é—®é¢˜åé¦ˆ&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ¼ å›½å†…Llama2æœ€æ–°ä¸‹è½½åœ°å€ä¸Šçº¿ï¼&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-7Bå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_kR2fwuJdG1F3CoF33rwpIA1?pwd=z9kf&#34;&gt;https://pan.xunlei.com/s/VN_kR2fwuJdG1F3CoF33rwpIA1?pwd=z9kf&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-7B-Chatå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_kQa1_HBvV-X9QVI6jV2kOA1?pwd=xmra&#34;&gt;https://pan.xunlei.com/s/VN_kQa1_HBvV-X9QVI6jV2kOA1?pwd=xmra&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-13Bå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_izibaMDoptluWodzJw4cRA1?pwd=2qqb&#34;&gt;https://pan.xunlei.com/s/VN_izibaMDoptluWodzJw4cRA1?pwd=2qqb&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-13B-Chatå®˜ç½‘ç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_iyyponyapjIDLXJCNfqy7A1?pwd=t3xw&#34;&gt;https://pan.xunlei.com/s/VN_iyyponyapjIDLXJCNfqy7A1?pwd=t3xw&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-7B Hugging Faceç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep&#34;&gt;https://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-7B-Chat Hugging Faceç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir&#34;&gt;https://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-13B Hugging Faceç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf&#34;&gt;https://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-13B-Chat Hugging Faceç‰ˆæœ¬ï¼š&lt;a href=&#34;https://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg&#34;&gt;https://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ”¥ ç¤¾åŒºä»‹ç»ï¼šLlama2ä¸­æ–‡ç¤¾åŒº&lt;/h2&gt; &#xA;&lt;p&gt;æ¬¢è¿æ¥åˆ°Llama2ä¸­æ–‡ç¤¾åŒºï¼æˆ‘ä»¬æ˜¯ä¸€ä¸ªä¸“æ³¨äºLlama2æ¨¡å‹åœ¨ä¸­æ–‡æ–¹é¢çš„ä¼˜åŒ–å’Œä¸Šå±‚å»ºè®¾çš„é«˜çº§æŠ€æœ¯ç¤¾åŒºã€‚ &lt;strong&gt;*åŸºäºå¤§è§„æ¨¡ä¸­æ–‡æ•°æ®ï¼Œä»é¢„è®­ç»ƒå¼€å§‹å¯¹Llama2æ¨¡å‹è¿›è¡Œä¸­æ–‡èƒ½åŠ›çš„æŒç»­è¿­ä»£å‡çº§*&lt;/strong&gt;ã€‚ æˆ‘ä»¬çƒ­å¿±æ¬¢è¿å¯¹å¤§æ¨¡å‹LLMå……æ»¡çƒ­æƒ…çš„å¼€å‘è€…å’Œç ”ç©¶è€…åŠ å…¥æˆ‘ä»¬çš„è¡Œåˆ—ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;ä¸ºä»€ä¹ˆé€‰æ‹©Llama2ä¸­æ–‡ç¤¾åŒºï¼Ÿ&lt;/h3&gt; &#xA;&lt;p&gt;ğŸš€ &lt;strong&gt;é«˜çº§å·¥ç¨‹å¸ˆå›¢é˜Ÿæ”¯æŒ&lt;/strong&gt;ï¼šç¤¾åŒºæœ‰ä¸€æ‰¹ä¸“æ³¨ä¸ºå¤§å®¶æœåŠ¡çš„NLPé«˜çº§å·¥ç¨‹å¸ˆï¼Œæˆ‘ä»¬æœ‰ç€å¼ºå¤§çš„æŠ€æœ¯æ”¯æŒå’Œä¸°å¯Œçš„ç»éªŒï¼Œä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æŒ‡å¯¼å’Œå¸®åŠ©ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ğŸ¯ &lt;strong&gt;ä¸­æ–‡ä¼˜åŒ–&lt;/strong&gt;ï¼šæˆ‘ä»¬è‡´åŠ›äºåœ¨Llama2æ¨¡å‹çš„ä¸­æ–‡å¤„ç†æ–¹é¢è¿›è¡Œä¼˜åŒ–ï¼Œæ¢ç´¢é€‚ç”¨äºä¸­æ–‡çš„æœ€ä½³å®è·µï¼Œä»¥æå‡å…¶æ€§èƒ½å’Œé€‚åº”æ€§ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ğŸ’¡ &lt;strong&gt;åˆ›æ–°äº¤æµ&lt;/strong&gt;ï¼šæˆ‘ä»¬æ‹¥æœ‰ä¸€æ”¯å¯Œæœ‰åˆ›é€ åŠ›å’Œç»éªŒçš„ç¤¾åŒºæˆå‘˜å›¢é˜Ÿï¼Œå®šæœŸç»„ç»‡çº¿ä¸Šæ´»åŠ¨ã€æŠ€æœ¯ç ”è®¨å’Œç»éªŒåˆ†äº«ï¼Œä¿ƒè¿›æˆå‘˜é—´çš„åˆ›æ–°äº¤æµã€‚&lt;/p&gt; &#xA;&lt;p&gt;ğŸŒ &lt;strong&gt;å…¨çƒè”ç»“&lt;/strong&gt;ï¼šæˆ‘ä»¬æ¬¢è¿æ¥è‡ªä¸–ç•Œå„åœ°çš„å¼€å‘è€…åŠ å…¥ç¤¾åŒºï¼Œæ„å»ºä¸€ä¸ªå¼€æ”¾ã€å¤šå…ƒåŒ–çš„å­¦ä¹ å’Œäº¤æµå¹³å°ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ğŸ¤ &lt;strong&gt;å¼€æ”¾å…±äº«&lt;/strong&gt;ï¼šæˆ‘ä»¬é¼“åŠ±ç¤¾åŒºæˆå‘˜å¼€æºåˆ†äº«ä»£ç å’Œæ¨¡å‹ï¼Œæ¨åŠ¨åˆä½œå…±èµ¢ï¼Œå…±åŒä¿ƒè¿›ä¸­æ–‡NLPæŠ€æœ¯çš„å‘å±•ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;ç¤¾åŒºæ´»åŠ¨&lt;/h3&gt; &#xA;&lt;p&gt;ğŸ—“ï¸ &lt;strong&gt;çº¿ä¸Šè®²åº§&lt;/strong&gt;ï¼šé‚€è¯·è¡Œä¸šå†…ä¸“å®¶è¿›è¡Œçº¿ä¸Šè®²åº§ï¼Œåˆ†äº«Llama2åœ¨ä¸­æ–‡NLPé¢†åŸŸçš„æœ€æ–°æŠ€æœ¯å’Œåº”ç”¨ï¼Œæ¢è®¨å‰æ²¿ç ”ç©¶æˆæœã€‚&lt;/p&gt; &#xA;&lt;p&gt;ğŸ’» &lt;strong&gt;é¡¹ç›®å±•ç¤º&lt;/strong&gt;ï¼šæˆå‘˜å¯å±•ç¤ºè‡ªå·±åœ¨Llama2ä¸­æ–‡ä¼˜åŒ–æ–¹é¢çš„é¡¹ç›®æˆæœï¼Œè·å¾—åé¦ˆå’Œå»ºè®®ï¼Œä¿ƒè¿›é¡¹ç›®åä½œã€‚&lt;/p&gt; &#xA;&lt;p&gt;ğŸ“š &lt;strong&gt;å­¦ä¹ èµ„æº&lt;/strong&gt;ï¼šç¤¾åŒºç»´æŠ¤ä¸°å¯Œçš„å­¦ä¹ èµ„æ–™åº“ï¼ŒåŒ…æ‹¬æ•™ç¨‹ã€æ–‡æ¡£å’Œè®ºæ–‡è§£è¯»ï¼Œä¸ºæˆå‘˜æä¾›å…¨é¢çš„å­¦ä¹ æ”¯æŒã€‚&lt;/p&gt; &#xA;&lt;p&gt;ğŸ“ &lt;strong&gt;è®ºæ–‡è§£è¯»&lt;/strong&gt;ï¼šç¤¾åŒºæˆå‘˜å…±åŒè§£è¯»ä¸Llama2ç›¸å…³çš„æœ€æ–°ç ”ç©¶è®ºæ–‡ï¼Œæ·±å…¥ç†è§£å‰æ²¿ç®—æ³•å’Œæ–¹æ³•ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ğŸ‰ &lt;strong&gt;ä¸»é¢˜æ´»åŠ¨&lt;/strong&gt;ï¼šå®šæœŸä¸¾åŠå„ç±»ä¸»é¢˜æ´»åŠ¨ï¼ŒåŒ…æ‹¬æŒ‘æˆ˜èµ›ã€é»‘å®¢é©¬æ‹‰æ¾å’ŒæŠ€æœ¯æ²™é¾™ï¼Œè®©ç¤¾åŒºæˆå‘˜åœ¨è½»æ¾æ„‰å¿«çš„æ°›å›´ä¸­äº¤æµå’Œå­¦ä¹ ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ğŸŒŸ &lt;strong&gt;å¥–åŠ±è®¡åˆ’&lt;/strong&gt;ï¼šæˆ‘ä»¬è®¾ç«‹å¥–åŠ±è®¡åˆ’ï¼Œå¯¹ç¤¾åŒºä¸­ç§¯æå‚ä¸ã€è´¡çŒ®ä¼˜ç§€çš„æˆå‘˜ç»™äºˆè£èª‰å’Œå¥–åŠ±ï¼Œæ¿€åŠ±æ›´å¤šä¼˜ç§€äººæ‰çš„åŠ å…¥ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ğŸ“ˆ &lt;strong&gt;æŠ€æœ¯å’¨è¯¢&lt;/strong&gt;ï¼šæˆ‘ä»¬æä¾›æŠ€æœ¯å’¨è¯¢æœåŠ¡ï¼Œè§£ç­”æ‚¨åœ¨Llama2å¼€å‘å’Œä¼˜åŒ–è¿‡ç¨‹ä¸­é‡åˆ°çš„é—®é¢˜ï¼ŒåŠ©æ‚¨å¿«é€Ÿæ”»å…‹éš¾å…³ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ğŸš€ &lt;strong&gt;é¡¹ç›®åˆä½œ&lt;/strong&gt;ï¼šé¼“åŠ±æˆå‘˜é—´çš„é¡¹ç›®åˆä½œï¼Œå…±åŒæ¢ç´¢Llama2åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ï¼Œæ‰“é€ åˆ›æ–°è§£å†³æ–¹æ¡ˆã€‚&lt;/p&gt; &#xA;&lt;h3&gt;ç«‹å³åŠ å…¥æˆ‘ä»¬ï¼&lt;/h3&gt; &#xA;&lt;p&gt;ğŸ“š &lt;strong&gt;æ„¿æ™¯&lt;/strong&gt;ï¼šæ— è®ºæ‚¨æ˜¯å¯¹Llama2å·²æœ‰ç ”ç©¶å’Œåº”ç”¨ç»éªŒçš„ä¸“ä¸šå¼€å‘è€…ï¼Œè¿˜æ˜¯å¯¹Llama2ä¸­æ–‡ä¼˜åŒ–æ„Ÿå…´è¶£å¹¶å¸Œæœ›æ·±å…¥æ¢ç´¢çš„æ–°æ‰‹ï¼Œæˆ‘ä»¬éƒ½çƒ­åˆ‡æœŸå¾…æ‚¨çš„åŠ å…¥ã€‚åœ¨Llama2ä¸­æ–‡ç¤¾åŒºï¼Œæ‚¨å°†æœ‰æœºä¼šä¸è¡Œä¸šå†…é¡¶å°–äººæ‰å…±åŒäº¤æµï¼Œæºæ‰‹æ¨åŠ¨ä¸­æ–‡NLPæŠ€æœ¯çš„è¿›æ­¥ï¼Œå¼€åˆ›æ›´åŠ ç¾å¥½çš„æŠ€æœ¯æœªæ¥ï¼&lt;/p&gt; &#xA;&lt;p&gt;ğŸ”— &lt;strong&gt;æ¸©é¦¨æç¤º&lt;/strong&gt;ï¼šæœ¬ç¤¾åŒºä¸ºä¸“ä¸šæŠ€æœ¯äº¤æµå¹³å°ï¼Œæˆ‘ä»¬çƒ­åˆ‡æœŸæœ›å¿—åŒé“åˆçš„å¼€å‘è€…å’Œç ”ç©¶è€…åŠ å…¥ã€‚è¯·éµå®ˆç¤¾åŒºå‡†åˆ™ï¼Œå…±åŒç»´æŠ¤ç§¯æå‘ä¸Šçš„å­¦ä¹ æ°›å›´ï¼Œä»»ä½•ä¸Llama2æ— å…³çš„å†…å®¹å’Œå¹¿å‘Šå°†è¢«æ¸…ç†ã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£å’Œæ”¯æŒï¼&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“¢ ç¤¾åŒºå…¬å‘Š&lt;/h2&gt; &#xA;&lt;h4&gt;2023å¹´7æœˆ26æ—¥ï¼šæ–°å¢Llama2-13Bä¸­æ–‡å¾®è°ƒå‚æ•°çš„&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96&#34;&gt;4bité‡åŒ–å‹ç¼©ç‰ˆæœ¬&lt;/a&gt;ï¼&lt;/h4&gt; &#xA;&lt;h4&gt;2023å¹´7æœˆ25æ—¥ï¼šç¤¾åŒºå¾®ä¿¡å…¬ä¼—å·â€œLlamaä¸­æ–‡ç¤¾åŒºâ€æ¬¢è¿å¤§å®¶å…³æ³¨ï¼Œè·å–æœ€æ–°åˆ†äº«å’ŒåŠ¨æ€ï¼&lt;/h4&gt; &#xA;&lt;h4&gt;2023å¹´7æœˆ24æ—¥ï¼š&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;FlagAlpha&lt;/a&gt;æ–°å¢Llama2-13Bä¸­æ–‡å¾®è°ƒå‚æ•°ï¼&lt;/h4&gt; &#xA;&lt;h4&gt;2023å¹´7æœˆ24æ—¥ï¼š&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;æ–°å¢Llama2-70Båœ¨çº¿ä½“éªŒï¼&lt;/h4&gt; &#xA;&lt;h4&gt;2023å¹´7æœˆ23æ—¥ï¼šLlama2ä¸­æ–‡å¾®è°ƒå‚æ•°å‘å¸ƒè‡³Hugging Faceä»“åº“&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;FlagAlpha&lt;/a&gt;ï¼&lt;/h4&gt; &#xA;&lt;h4&gt;2023å¹´7æœˆ22æ—¥ï¼šLlama2åœ¨çº¿ä½“éªŒé“¾æ¥&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;ä¸Šçº¿ï¼ŒåŒæ—¶åŒ…å«MetaåŸç‰ˆå’Œä¸­æ–‡å¾®è°ƒç‰ˆæœ¬ï¼&lt;/h4&gt; &#xA;&lt;h4&gt;2023å¹´7æœˆ21æ—¥ï¼šè¯„æµ‹äº†MetaåŸå§‹ç‰ˆLlama2 Chatæ¨¡å‹çš„&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B&#34;&gt;ä¸­æ–‡é—®ç­”èƒ½åŠ›&lt;/a&gt;ï¼&lt;/h4&gt; &#xA;&lt;h4&gt;2023å¹´7æœˆ21æ—¥ï¼šæ–°å¢Llama2æ¨¡å‹çš„Hugging Faceç‰ˆæœ¬å›½å†…ä¸‹è½½åœ°å€ï¼&lt;/h4&gt; &#xA;&lt;h4&gt;2023å¹´7æœˆ20æ—¥ï¼šæ–°å¢&lt;a href=&#34;https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink&#34;&gt;é£ä¹¦çŸ¥è¯†åº“æ–‡æ¡£&lt;/a&gt;ï¼Œæ¬¢è¿å¤§å®¶ä¸€èµ·å…±å»ºï¼&lt;/h4&gt; &#xA;&lt;h4&gt;2023å¹´7æœˆ20æ—¥ï¼šå›½å†…Llama2æœ€æ–°ä¸‹è½½åœ°å€ä¸Šçº¿ï¼&lt;/h4&gt; &#xA;&lt;h4&gt;2023å¹´7æœˆ19æ—¥ï¼šæ­£å¼å¯åŠ¨Llama2æ¨¡å‹çš„ä¸­æ–‡é¢„è®­ç»ƒï¼Œå…³æ³¨æˆ‘ä»¬è·å–å®æ—¶åŠ¨æ€ï¼&lt;/h4&gt; &#xA;&lt;h4&gt;2023å¹´7æœˆ19æ—¥ï¼šLlama2å›½å†…ä¸‹è½½åœ°å€æ­£åœ¨å¯åŠ¨ï¼Œæ•¬è¯·æœŸå¾…ï¼&lt;/h4&gt; &#xA;&lt;h4&gt;2023å¹´7æœˆ19æ—¥ï¼šå¼€å¯Llama2ä¸­æ–‡ç¤¾åŒºï¼Œæ¬¢è¿å¤§å®¶åŠ å…¥ï¼&lt;/h4&gt; &#xA;&lt;h2&gt;ğŸ“ æ•°æ®æ¥æº&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘ä»¬è®¡åˆ’é€šè¿‡ä»¥ä¸‹æ•°æ®æ¥ä¼˜åŒ–Llama2çš„ä¸­æ–‡èƒ½åŠ›:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ç±»å‹&lt;/th&gt; &#xA;   &lt;th&gt;æè¿°&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ç½‘ç»œæ•°æ®&lt;/td&gt; &#xA;   &lt;td&gt;äº’è”ç½‘ä¸Šå…¬å¼€çš„ç½‘ç»œæ•°æ®ï¼ŒæŒ‘é€‰å‡ºå»é‡åçš„é«˜è´¨é‡ä¸­æ–‡æ•°æ®ï¼Œæ¶‰åŠåˆ°ç™¾ç§‘ã€ä¹¦ç±ã€åšå®¢ã€æ–°é—»ã€å…¬å‘Šã€å°è¯´ç­‰é«˜è´¨é‡é•¿æ–‡æœ¬æ•°æ®ã€‚&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/goldsmith/Wikipedia&#34;&gt;Wikipedia&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸­æ–‡Wikipediaçš„æ•°æ®&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/BAAI-WuDao/Model&#34;&gt;æ‚Ÿé“&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸­æ–‡æ‚Ÿé“å¼€æºçš„200Gæ•°æ®&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/CLUEbenchmark/CLUEDatasetSearch&#34;&gt;Clue&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Clueå¼€æ”¾çš„ä¸­æ–‡é¢„è®­ç»ƒæ•°æ®ï¼Œè¿›è¡Œæ¸…æ´—åçš„é«˜è´¨é‡ä¸­æ–‡é•¿æ–‡æœ¬æ•°æ®&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ç«èµ›æ•°æ®é›†&lt;/td&gt; &#xA;   &lt;td&gt;è¿‘å¹´æ¥ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†å¤šä»»åŠ¡ç«èµ›æ•°æ®é›†ï¼Œçº¦150ä¸ª&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/esbatmop/MNBVC&#34;&gt;MNBVC&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MNBVC ä¸­æ¸…æ´—å‡ºæ¥çš„éƒ¨åˆ†æ•°æ®é›†&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;å¸Œæœ›å¤§å®¶å¦‚æœæœ‰è¾ƒé«˜è´¨é‡çš„æ•°æ®é›†èƒ½å¤Ÿæä¾›ç»™æˆ‘ä»¬ï¼Œä¸èƒœæ„Ÿæ¿€!ğŸ’•ğŸ’•&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;â¬ æ¨¡å‹éƒ¨ç½²&lt;/h2&gt; &#xA;&lt;p&gt;Metaåœ¨ğŸ¤—Hugging Faceä¸Šæä¾›äº†æ‰€æœ‰æ¨¡å‹çš„ä¸‹è½½é“¾æ¥ï¼š&lt;a href=&#34;https://huggingface.co/meta-llama&#34;&gt;https://huggingface.co/meta-llama&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;é¢„è®­ç»ƒæ¨¡å‹&lt;/h3&gt; &#xA;&lt;p&gt;Llama2é¢„è®­ç»ƒæ¨¡å‹åŒ…å«7Bã€13Bå’Œ70Bä¸‰ä¸ªç‰ˆæœ¬&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ğŸ¤—æ¨¡å‹åŠ è½½åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ä¸‹è½½åœ°å€&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-7B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-hf&#34;&gt;æ¨¡å‹ä¸‹è½½&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-13B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-13b-hf&#34;&gt;æ¨¡å‹ä¸‹è½½&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-70B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-70b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-70b-hf&#34;&gt;æ¨¡å‹ä¸‹è½½&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Chatæ¨¡å‹&lt;/h3&gt; &#xA;&lt;p&gt;Llama2-Chatæ¨¡å‹åŸºäºé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œäº†ç›‘ç£å¾®è°ƒï¼Œå…·å¤‡æ›´å¼ºçš„å¯¹è¯èƒ½åŠ›&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ğŸ¤—æ¨¡å‹åŠ è½½åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ä¸‹è½½åœ°å€&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-chat-hf&#34;&gt;æ¨¡å‹ä¸‹è½½&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-13B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-13b-chat-hf&#34;&gt;æ¨¡å‹ä¸‹è½½&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-70B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-70b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-70b-chat-hf&#34;&gt;æ¨¡å‹ä¸‹è½½&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;æ¨¡å‹è°ƒç”¨ä»£ç ç¤ºä¾‹&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;model = AutoModelForCausalLM.from_pretrained(&#39;meta-llama/Llama-2-7b-chat-hf&#39;,device_map=&#39;auto&#39;,torch_dtype=torch.float16,load_in_8bit=True)&#xA;model =model.eval()&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;meta-llama/Llama-2-7b-chat-hf&#39;,use_fast=False)&#xA;tokenizer.pad_token = tokenizer.eos_token&#xA;input_ids = tokenizer([&#39;&amp;lt;s&amp;gt;Human: ä»‹ç»ä¸€ä¸‹ä¸­å›½\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#39;], return_tensors=&#34;pt&#34;,add_special_tokens=False).input_ids.to(&#39;cuda&#39;)        &#xA;generate_input = {&#xA;    &#34;input_ids&#34;:input_ids,&#xA;    &#34;max_new_tokens&#34;:512,&#xA;    &#34;do_sample&#34;:True,&#xA;    &#34;top_k&#34;:50,&#xA;    &#34;top_p&#34;:0.95,&#xA;    &#34;temperature&#34;:0.3,&#xA;    &#34;repetition_penalty&#34;:1.3,&#xA;    &#34;eos_token_id&#34;:tokenizer.eos_token_id,&#xA;    &#34;bos_token_id&#34;:tokenizer.bos_token_id,&#xA;    &#34;pad_token_id&#34;:tokenizer.pad_token_id&#xA;}&#xA;generate_ids  = model.generate(**generate_input)&#xA;text = tokenizer.decode(generate_ids[0])&#xA;print(text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Gradioå¿«é€Ÿæ­å»ºé—®ç­”å¹³å°&lt;/h3&gt; &#xA;&lt;p&gt;åŸºäºgradioæ­å»ºçš„é—®ç­”ç•Œé¢ï¼Œå®ç°äº†æµå¼çš„è¾“å‡ºï¼Œå°†ä¸‹é¢ä»£ç å¤åˆ¶åˆ°æ§åˆ¶å°è¿è¡Œï¼Œä»¥ä¸‹ä»£ç ä»¥Llama2-7B-Chatæ¨¡å‹ä¸ºä¾‹ï¼Œ&lt;font color=&#34;#006600&#34;&gt;ä¸åŒæ¨¡å‹åªéœ€ä¿®æ”¹ä¸€ä¸‹ä»£ç é‡Œçš„æ¨¡å‹åç§°å°±å¥½äº†ğŸ˜Š&lt;/font&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python examples/chat_gradio.py --model_name_or_path meta-llama/Llama-2-7b-chat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ğŸ’¡ æ¨¡å‹å¾®è°ƒ&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬ä»“åº“ä¸­æä¾›äº†åŸºäºLoRAçš„å¾®è°ƒä»£ç ï¼Œæœªæ¥æˆ‘ä»¬å°†ä¼šæ‰©å±•æ›´å¤šçš„å¾®è°ƒç®—æ³•ï¼Œæ•¬è¯·æœŸå¾…ï¼å…³äºLoRAçš„è¯¦ç»†ä»‹ç»å¯ä»¥å‚è€ƒè®ºæ–‡â€œ&lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;LoRA: Low-Rank Adaptation of Large Language Models&lt;/a&gt;â€ä»¥åŠå¾®è½¯Githubä»“åº“&lt;a href=&#34;https://github.com/microsoft/LoRA&#34;&gt;LoRA&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;å¾®è°ƒè¿‡ç¨‹&lt;/h3&gt; &#xA;&lt;h4&gt;Step1: ç¯å¢ƒå‡†å¤‡&lt;/h4&gt; &#xA;&lt;p&gt;æ ¹æ®&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/requirements.txt&#34;&gt;requirements.txt&lt;/a&gt;å®‰è£…å¯¹åº”çš„ç¯å¢ƒä¾èµ–ã€‚&lt;/p&gt; &#xA;&lt;h4&gt;Step2: æ•°æ®å‡†å¤‡&lt;/h4&gt; &#xA;&lt;p&gt;åœ¨dataç›®å½•ä¸‹æä¾›äº†ä¸€ä»½ç”¨äºæ¨¡å‹sftçš„æ•°æ®æ ·ä¾‹ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;è®­ç»ƒæ•°æ®ï¼š&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/data/train_sft.csv&#34;&gt;data/train_sft.csv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;éªŒè¯æ•°æ®ï¼š&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/data/dev_sft.csv&#34;&gt;data/dev_sft.csv&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;æ¯ä¸ªcsvæ–‡ä»¶ä¸­åŒ…å«ä¸€åˆ—â€œtextâ€ï¼Œæ¯ä¸€è¡Œä¸ºä¸€ä¸ªè®­ç»ƒæ ·ä¾‹ï¼Œæ¯ä¸ªè®­ç»ƒæ ·ä¾‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å°†é—®é¢˜å’Œç­”æ¡ˆç»„ç»‡ä¸ºæ¨¡å‹è¾“å…¥ï¼Œæ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è‡ªå®šä¹‰è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#34;&amp;lt;s&amp;gt;Human: &#34;+é—®é¢˜+&#34;\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#34;+ç­”æ¡ˆ&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ä¾‹å¦‚ï¼Œ&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;s&amp;gt;Human: ç”¨ä¸€å¥è¯æè¿°åœ°çƒä¸ºä»€ä¹ˆæ˜¯ç‹¬ä¸€æ— äºŒçš„ã€‚&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: å› ä¸ºåœ°çƒæ˜¯ç›®å‰ä¸ºæ­¢å”¯ä¸€å·²çŸ¥å­˜åœ¨ç”Ÿå‘½çš„è¡Œæ˜Ÿã€‚&amp;lt;/s&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Step3: å¾®è°ƒè„šæœ¬&lt;/h4&gt; &#xA;&lt;p&gt;æˆ‘ä»¬æä¾›äº†ç”¨äºå¾®è°ƒçš„è„šæœ¬&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/train/sft/finetune.sh&#34;&gt;train/sft/finetune.sh&lt;/a&gt;ï¼Œé€šè¿‡ä¿®æ”¹è„šæœ¬çš„éƒ¨åˆ†å‚æ•°å®ç°æ¨¡å‹çš„å¾®è°ƒï¼Œå…³äºå¾®è°ƒçš„å…·ä½“ä»£ç è§&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/train/sft/finetune_clm_lora.py&#34;&gt;train/sft/finetune_clm_lora.py&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;ä¸­æ–‡å¾®è°ƒå‚æ•°&lt;/h3&gt; &#xA;&lt;p&gt;æˆ‘ä»¬åŸºäºä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†å¯¹Llama2-Chatæ¨¡å‹è¿›è¡Œäº†å¾®è°ƒï¼Œä½¿å¾—Llama2æ¨¡å‹æœ‰ç€æ›´å¼ºçš„ä¸­æ–‡å¯¹è¯èƒ½åŠ›ã€‚LoRAå‚æ•°ä»¥åŠä¸åŸºç¡€æ¨¡å‹åˆå¹¶çš„å‚æ•°å‡å·²ä¸Šä¼ è‡³&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;Hugging Face&lt;/a&gt;ï¼Œç›®å‰åŒ…å«7Bå’Œ13Bçš„æ¨¡å‹ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ğŸ¤—æ¨¡å‹åŠ è½½åç§°&lt;/th&gt; &#xA;   &lt;th&gt;åŸºç¡€æ¨¡å‹ç‰ˆæœ¬&lt;/th&gt; &#xA;   &lt;th&gt;ä¸‹è½½åœ°å€&lt;/th&gt; &#xA;   &lt;th&gt;ä»‹ç»&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-Chinese-7b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-7b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat-LoRA&#34;&gt;æ¨¡å‹ä¸‹è½½&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸­æ–‡æŒ‡ä»¤å¾®è°ƒçš„LoRAå‚æ•°&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-Chinese-7b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-7b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat&#34;&gt;æ¨¡å‹ä¸‹è½½&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸­æ–‡æŒ‡ä»¤å¾®è°ƒçš„LoRAå‚æ•°ä¸åŸºç¡€æ¨¡å‹å‚æ•°åˆå¹¶ç‰ˆæœ¬&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-Chinese-13b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-13b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-LoRA&#34;&gt;æ¨¡å‹ä¸‹è½½&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸­æ–‡æŒ‡ä»¤å¾®è°ƒçš„LoRAå‚æ•°&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-Chinese-13b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-13b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat&#34;&gt;æ¨¡å‹ä¸‹è½½&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸­æ–‡æŒ‡ä»¤å¾®è°ƒçš„LoRAå‚æ•°ä¸åŸºç¡€æ¨¡å‹å‚æ•°åˆå¹¶ç‰ˆæœ¬&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!-- ## ğŸš€ æœªæ¥è®¡åˆ’ --&gt; &#xA;&lt;!-- ## ğŸ’ª å¢å¼ºèƒ½åŠ› --&gt; &#xA;&lt;h2&gt;ğŸ„ æ¨¡å‹é‡åŒ–&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘ä»¬å¯¹ä¸­æ–‡å¾®è°ƒçš„æ¨¡å‹å‚æ•°è¿›è¡Œäº†é‡åŒ–ï¼Œæ–¹ä¾¿ä»¥æ›´å°‘çš„è®¡ç®—èµ„æºè¿è¡Œã€‚ç›®å‰å·²ç»åœ¨&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;Hugging Face&lt;/a&gt;ä¸Šä¼ äº†13Bä¸­æ–‡å¾®è°ƒæ¨¡å‹&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat&#34;&gt;FlagAlpha/Llama2-Chinese-13b-Chat&lt;/a&gt;çš„4bitå‹ç¼©ç‰ˆæœ¬&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#34;&gt;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&lt;/a&gt;ï¼Œå…·ä½“è°ƒç”¨æ–¹å¼å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from transformers import AutoTokenizer&#xA;from auto_gptq import AutoGPTQForCausalLM&#xA;model = AutoGPTQForCausalLM.from_quantized(&#39;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#39;, device=&#34;cuda:0&#34;)&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#39;,use_fast=False)&#xA;input_ids = tokenizer([&#39;&amp;lt;s&amp;gt;Human: æ€ä¹ˆç™»ä¸Šç«æ˜Ÿ\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#39;], return_tensors=&#34;pt&#34;,add_special_tokens=False).input_ids.to(&#39;cuda&#39;)        &#xA;generate_input = {&#xA;    &#34;input_ids&#34;:input_ids,&#xA;    &#34;max_new_tokens&#34;:512,&#xA;    &#34;do_sample&#34;:True,&#xA;    &#34;top_k&#34;:50,&#xA;    &#34;top_p&#34;:0.95,&#xA;    &#34;temperature&#34;:0.3,&#xA;    &#34;repetition_penalty&#34;:1.3,&#xA;    &#34;eos_token_id&#34;:tokenizer.eos_token_id,&#xA;    &#34;bos_token_id&#34;:tokenizer.bos_token_id,&#xA;    &#34;pad_token_id&#34;:tokenizer.pad_token_id&#xA;}&#xA;generate_ids  = model.generate(**generate_input)&#xA;text = tokenizer.decode(generate_ids[0])&#xA;print(text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ğŸ¥‡ æ¨¡å‹è¯„æµ‹&lt;/h2&gt; &#xA;&lt;p&gt;ä¸ºäº†èƒ½å¤Ÿæ›´åŠ æ¸…æ™°åœ°äº†è§£Llama2æ¨¡å‹çš„ä¸­æ–‡é—®ç­”èƒ½åŠ›ï¼Œæˆ‘ä»¬ç­›é€‰äº†ä¸€äº›å…·æœ‰ä»£è¡¨æ€§çš„ä¸­æ–‡é—®é¢˜ï¼Œå¯¹Llama2æ¨¡å‹è¿›è¡Œæé—®ã€‚æˆ‘ä»¬æµ‹è¯•çš„æ¨¡å‹åŒ…å«Metaå…¬å¼€çš„Llama2-7B-Chatå’ŒLlama2-13B-Chatä¸¤ä¸ªç‰ˆæœ¬ï¼Œæ²¡æœ‰åšä»»ä½•å¾®è°ƒå’Œè®­ç»ƒã€‚æµ‹è¯•é—®é¢˜ç­›é€‰è‡ª&lt;a href=&#34;https://github.com/AtomEcho/AtomBulb&#34;&gt;AtomBulb&lt;/a&gt;ï¼Œå…±95ä¸ªæµ‹è¯•é—®é¢˜ï¼ŒåŒ…å«ï¼šé€šç”¨çŸ¥è¯†ã€è¯­è¨€ç†è§£ã€åˆ›ä½œèƒ½åŠ›ã€é€»è¾‘æ¨ç†ã€ä»£ç ç¼–ç¨‹ã€å·¥ä½œæŠ€èƒ½ã€ä½¿ç”¨å·¥å…·ã€äººæ ¼ç‰¹å¾å…«ä¸ªå¤§çš„ç±»åˆ«ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æµ‹è¯•ä¸­ä½¿ç”¨çš„Promptå¦‚ä¸‹ï¼Œä¾‹å¦‚å¯¹äºé—®é¢˜â€œåˆ—å‡º5ç§å¯ä»¥æ”¹å–„ç¡çœ è´¨é‡çš„æ–¹æ³•â€ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[INST] &#xA;&amp;lt;&amp;lt;SYS&amp;gt;&amp;gt;&#xA;You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. The answer always been translate into Chinese language.&#xA;&#xA;If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don&#39;t know the answer to a question, please don&#39;t share false information.&#xA;&#xA;The answer always been translate into Chinese language.&#xA;&amp;lt;&amp;lt;/SYS&amp;gt;&amp;gt;&#xA;&#xA;åˆ—å‡º5ç§å¯ä»¥æ”¹å–„ç¡çœ è´¨é‡çš„æ–¹æ³•&#xA;[/INST]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Llama2-7B-Chatçš„æµ‹è¯•ç»“æœè§&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/assets/meta_eval_7B.md&#34;&gt;meta_eval_7B.md&lt;/a&gt;ï¼ŒLlama2-13B-Chatçš„æµ‹è¯•ç»“æœè§&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/assets/meta_eval_13B.md&#34;&gt;meta_eval_13B.md&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;é€šè¿‡æµ‹è¯•æˆ‘ä»¬å‘ç°ï¼ŒMetaåŸå§‹çš„Llama2 Chatæ¨¡å‹å¯¹äºä¸­æ–‡é—®ç­”çš„å¯¹é½æ•ˆæœä¸€èˆ¬ï¼Œå¤§éƒ¨åˆ†æƒ…å†µä¸‹éƒ½ä¸èƒ½ç»™å‡ºä¸­æ–‡å›ç­”ï¼Œæˆ–è€…æ˜¯ä¸­è‹±æ–‡æ··æ‚çš„å½¢å¼ã€‚å› æ­¤ï¼ŒåŸºäºä¸­æ–‡æ•°æ®å¯¹Llama2æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œå¾®è°ƒååˆ†å¿…è¦ï¼Œæˆ‘ä»¬çš„ä¸­æ–‡ç‰ˆLlama2æ¨¡å‹ä¹Ÿå·²ç»åœ¨è®­ç»ƒä¸­ï¼Œè¿‘æœŸå°†å¯¹ç¤¾åŒºå¼€æ”¾ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“– å­¦ä¹ èµ„æ–™&lt;/h2&gt; &#xA;&lt;h3&gt;Metaå®˜æ–¹å¯¹äº&lt;a href=&#34;https://ai.meta.com/llama&#34;&gt;Llama2&lt;/a&gt;çš„ä»‹ç»&lt;/h3&gt; &#xA;&lt;p&gt;è‡ªä»Metaå…¬å¸å‘å¸ƒç¬¬ä¸€ä»£LLaMAæ¨¡å‹ä»¥æ¥ï¼Œç¾Šé©¼æ¨¡å‹å®¶æ—ç¹è£å‘å±•ã€‚è¿‘æœŸMetaå‘å¸ƒäº†Llama2ç‰ˆæœ¬ï¼Œå¼€æºå¯å•†ç”¨ï¼Œåœ¨æ¨¡å‹å’Œæ•ˆæœä¸Šæœ‰äº†é‡å¤§æ›´æ–°ã€‚Llama2æ€»å…±å…¬å¸ƒäº†7Bã€13Bå’Œ70Bä¸‰ç§å‚æ•°å¤§å°çš„æ¨¡å‹ã€‚ç›¸æ¯”äºLLaMAï¼ŒLlama2çš„è®­ç»ƒæ•°æ®è¾¾åˆ°äº†2ä¸‡äº¿tokenï¼Œä¸Šä¸‹æ–‡é•¿åº¦ä¹Ÿç”±ä¹‹å‰çš„2048å‡çº§åˆ°4096ï¼Œå¯ä»¥ç†è§£å’Œç”Ÿæˆæ›´é•¿çš„æ–‡æœ¬ã€‚Llama2 Chatæ¨¡å‹åŸºäº100ä¸‡äººç±»æ ‡è®°æ•°æ®å¾®è°ƒå¾—åˆ°ï¼Œåœ¨è‹±æ–‡å¯¹è¯ä¸Šè¾¾åˆ°äº†æ¥è¿‘ChatGPTçš„æ•ˆæœã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Llamaç›¸å…³è®ºæ–‡&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.13971&#34;&gt;LLaMA: Open and Efficient Foundation Language Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scontent-lax3-2.xx.fbcdn.net/v/t39.2365-6/10000000_663429262362723_1696968207443577320_n.pdf?_nc_cat=101&amp;amp;ccb=1-7&amp;amp;_nc_sid=3c67a6&amp;amp;_nc_ohc=5ol-jUSglG4AX9uTu-j&amp;amp;_nc_ht=scontent-lax3-2.xx&amp;amp;oh=00_AfDVmJr77y3bv5GCbJ26w-stMJNXsZPTwVDlWhoIkkb8Lg&amp;amp;oe=64BDB0D1&#34;&gt;Llama 2: Open Foundation and Fine-Tuned Chat Models&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Llama2çš„è¯„æµ‹ç»“æœ&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://scontent-lax3-2.xx.fbcdn.net/v/t39.8562-6/361265668_276217774995411_4529778090866658620_n.jpg?_nc_cat=1&amp;amp;ccb=1-7&amp;amp;_nc_sid=6825c5&amp;amp;_nc_ohc=gSMV6flCjbAAX8pE8nm&amp;amp;_nc_ht=scontent-lax3-2.xx&amp;amp;oh=00_AfC53vAix8IkoTlO1Z46g2IfS3p7jb51A8TaIrOK6grRsQ&amp;amp;oe=64BC6826&#34; alt=&#34;Llama2Eval&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;ğŸ‰ è‡´è°¢&lt;/h2&gt; &#xA;&lt;p&gt;æ„Ÿè°¢åŸå­å›å£°&lt;a href=&#34;https://github.com/AtomEcho&#34;&gt;AtomEcho&lt;/a&gt;å›¢é˜Ÿçš„æŠ€æœ¯å’Œèµ„æºæ”¯æŒï¼&lt;/p&gt; &#xA;&lt;p&gt;æ„Ÿè°¢ @xzsGenius å¯¹Llama2ä¸­æ–‡ç¤¾åŒºçš„è´¡çŒ®ï¼&lt;/p&gt; &#xA;&lt;p&gt;æ„Ÿè°¢ @Z Potentialsç¤¾åŒºå¯¹Llama2ä¸­æ–‡ç¤¾åŒºçš„æ”¯æŒï¼&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ¤” é—®é¢˜åé¦ˆ&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœ‰é—®é¢˜ï¼Œè¯·åœ¨GitHub Issueä¸­æäº¤ï¼Œåœ¨æäº¤é—®é¢˜ä¹‹å‰ï¼Œè¯·å…ˆæŸ¥é˜…ä»¥å¾€çš„issueæ˜¯å¦èƒ½è§£å†³ä½ çš„é—®é¢˜ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ç¤¼è²Œåœ°æå‡ºé—®é¢˜ï¼Œæ„å»ºå’Œè°çš„è®¨è®ºç¤¾åŒºã€‚&lt;/p&gt; &#xA;&lt;p&gt;åŠ å…¥&lt;a href=&#34;https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink&#34;&gt;é£ä¹¦çŸ¥è¯†åº“&lt;/a&gt;ï¼Œä¸€èµ·å…±å»ºç¤¾åŒºæ–‡æ¡£ã€‚&lt;/p&gt; &#xA;&lt;p&gt;åŠ å…¥å¾®ä¿¡ç¾¤è®¨è®ºğŸ˜ğŸ˜&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/assets/wechat.jpeg&#34; alt=&#34;Wechat&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://api.star-history.com/svg?repos=FlagAlpha/Llama2-Chinese&amp;amp;type=Date&#34; alt=&#34;Wechat&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt;</summary>
  </entry>
</feed>