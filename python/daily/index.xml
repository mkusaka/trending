<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-07-31T01:26:39Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>alexta69/metube</title>
    <updated>2024-07-31T01:26:39Z</updated>
    <id>tag:github.com,2024-07-31:/alexta69/metube</id>
    <link href="https://github.com/alexta69/metube" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Self-hosted YouTube downloader (web UI for youtube-dl / yt-dlp)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MeTube&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;em&gt;NOTE:&lt;/em&gt;&lt;/strong&gt; 32-bit ARM builds have been retired (a full year after &lt;a href=&#34;https://www.linuxserver.io/blog/a-farewell-to-arm-hf&#34;&gt;other major players&lt;/a&gt;), as new Node versions don&#39;t support them, and continued security updates and dependencies require new Node versions. Please migrate to a 64-bit OS to continue receiving MeTube upgrades.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/alexta69/metube/actions/workflows/main.yml/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt; &lt;img src=&#34;https://img.shields.io/docker/pulls/alexta69/metube.svg?sanitize=true&#34; alt=&#34;Docker Pulls&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Web GUI for youtube-dl (using the &lt;a href=&#34;https://github.com/yt-dlp/yt-dlp&#34;&gt;yt-dlp&lt;/a&gt; fork) with playlist support. Allows you to download videos from YouTube and &lt;a href=&#34;https://github.com/yt-dlp/yt-dlp/raw/master/supportedsites.md&#34;&gt;dozens of other sites&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/alexta69/metube/raw/master/screenshot.gif&#34; alt=&#34;screenshot1&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Run using Docker&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d -p 8081:8081 -v /path/to/downloads:/downloads ghcr.io/alexta69/metube&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Run using docker-compose&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;version: &#34;3&#34;&#xA;services:&#xA;  metube:&#xA;    image: ghcr.io/alexta69/metube&#xA;    container_name: metube&#xA;    restart: unless-stopped&#xA;    ports:&#xA;      - &#34;8081:8081&#34;&#xA;    volumes:&#xA;      - /path/to/downloads:/downloads&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Configuration via environment variables&lt;/h2&gt; &#xA;&lt;p&gt;Certain values can be set via environment variables, using the &lt;code&gt;-e&lt;/code&gt; parameter on the docker command line, or the &lt;code&gt;environment:&lt;/code&gt; section in docker-compose.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;UID&lt;/strong&gt;: user under which MeTube will run. Defaults to &lt;code&gt;1000&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;GID&lt;/strong&gt;: group under which MeTube will run. Defaults to &lt;code&gt;1000&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;UMASK&lt;/strong&gt;: umask value used by MeTube. Defaults to &lt;code&gt;022&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;DEFAULT_THEME&lt;/strong&gt;: default theme to use for the ui, can be set to &lt;code&gt;light&lt;/code&gt;, &lt;code&gt;dark&lt;/code&gt; or &lt;code&gt;auto&lt;/code&gt;. Defaults to &lt;code&gt;auto&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;DOWNLOAD_DIR&lt;/strong&gt;: path to where the downloads will be saved. Defaults to &lt;code&gt;/downloads&lt;/code&gt; in the docker image, and &lt;code&gt;.&lt;/code&gt; otherwise.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;AUDIO_DOWNLOAD_DIR&lt;/strong&gt;: path to where audio-only downloads will be saved, if you wish to separate them from the video downloads. Defaults to the value of &lt;code&gt;DOWNLOAD_DIR&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;DOWNLOAD_DIRS_INDEXABLE&lt;/strong&gt;: if &lt;code&gt;true&lt;/code&gt;, the download dirs (&lt;strong&gt;DOWNLOAD_DIR&lt;/strong&gt; and &lt;strong&gt;AUDIO_DOWNLOAD_DIR&lt;/strong&gt;) are indexable on the webserver. Defaults to &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CUSTOM_DIRS&lt;/strong&gt;: whether to enable downloading videos into custom directories within the &lt;strong&gt;DOWNLOAD_DIR&lt;/strong&gt; (or &lt;strong&gt;AUDIO_DOWNLOAD_DIR&lt;/strong&gt;). When enabled, a drop-down appears next to the Add button to specify the download directory. Defaults to &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CREATE_CUSTOM_DIRS&lt;/strong&gt;: whether to support automatically creating directories within the &lt;strong&gt;DOWNLOAD_DIR&lt;/strong&gt; (or &lt;strong&gt;AUDIO_DOWNLOAD_DIR&lt;/strong&gt;) if they do not exist. When enabled, the download directory selector becomes supports free-text input, and the specified directory will be created recursively. Defaults to &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;STATE_DIR&lt;/strong&gt;: path to where the queue persistence files will be saved. Defaults to &lt;code&gt;/downloads/.metube&lt;/code&gt; in the docker image, and &lt;code&gt;.&lt;/code&gt; otherwise.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;TEMP_DIR&lt;/strong&gt;: path where intermediary download files will be saved. Defaults to &lt;code&gt;/downloads&lt;/code&gt; in the docker image, and &lt;code&gt;.&lt;/code&gt; otherwise. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Set this to an SSD or RAM filesystem (e.g., &lt;code&gt;tmpfs&lt;/code&gt;) for better performance&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: Using a RAM filesystem may prevent downloads from being resumed&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;DELETE_FILE_ON_TRASHCAN&lt;/strong&gt;: if &lt;code&gt;true&lt;/code&gt;, downloaded files are deleted on the server, when they are trashed from the &#34;Completed&#34; section of the UI. Defaults to &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;URL_PREFIX&lt;/strong&gt;: base path for the web server (for use when hosting behind a reverse proxy). Defaults to &lt;code&gt;/&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;PUBLIC_HOST_URL&lt;/strong&gt;: base URL for the download links shown in the UI for completed files. By default MeTube serves them under its own URL. If your download directory is accessible on another URL and you want the download links to be based there, use this variable to set it.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;PUBLIC_HOST_AUDIO_URL&lt;/strong&gt;: same as PUBLIC_HOST_URL but for audio downloads.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;OUTPUT_TEMPLATE&lt;/strong&gt;: the template for the filenames of the downloaded videos, formatted according to &lt;a href=&#34;https://github.com/yt-dlp/yt-dlp/raw/master/README.md#output-template&#34;&gt;this spec&lt;/a&gt;. Defaults to &lt;code&gt;%(title)s.%(ext)s&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;OUTPUT_TEMPLATE_CHAPTER&lt;/strong&gt;: the template for the filenames of the downloaded videos, when split into chapters via postprocessors. Defaults to &lt;code&gt;%(title)s - %(section_number)s %(section_title)s.%(ext)s&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;YTDL_OPTIONS&lt;/strong&gt;: Additional options to pass to youtube-dl, in JSON format. &lt;a href=&#34;https://github.com/yt-dlp/yt-dlp/raw/master/yt_dlp/YoutubeDL.py#L183&#34;&gt;See available options here&lt;/a&gt;. They roughly correspond to command-line options, though some do not have exact equivalents here, for example &lt;code&gt;--recode-video&lt;/code&gt; has to be specified via &lt;code&gt;postprocessors&lt;/code&gt;. Also note that dashes are replaced with underscores.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;YTDL_OPTIONS_FILE&lt;/strong&gt;: A path to a JSON file that will be loaded and used for populating &lt;code&gt;YTDL_OPTIONS&lt;/code&gt; above. Please note that if both &lt;code&gt;YTDL_OPTIONS_FILE&lt;/code&gt; and &lt;code&gt;YTDL_OPTIONS&lt;/code&gt; are specified, the options in &lt;code&gt;YTDL_OPTIONS&lt;/code&gt; take precedence.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following example value for &lt;code&gt;YTDL_OPTIONS&lt;/code&gt; embeds English subtitles and chapter markers (for videos that have them), and also changes the permissions on the downloaded video and sets the file modification timestamp to the date of when it was downloaded:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;    environment:&#xA;      - &#39;YTDL_OPTIONS={&#34;writesubtitles&#34;:true,&#34;subtitleslangs&#34;:[&#34;en&#34;,&#34;-live_chat&#34;],&#34;updatetime&#34;:false,&#34;postprocessors&#34;:[{&#34;key&#34;:&#34;Exec&#34;,&#34;exec_cmd&#34;:&#34;chmod 0664&#34;,&#34;when&#34;:&#34;after_move&#34;},{&#34;key&#34;:&#34;FFmpegEmbedSubtitle&#34;,&#34;already_have_subtitle&#34;:false},{&#34;key&#34;:&#34;FFmpegMetadata&#34;,&#34;add_chapters&#34;:true}]}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The following example value for &lt;code&gt;OUTPUT_TEMPLATE&lt;/code&gt; sets:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;playlist name and author, if present&lt;/li&gt; &#xA; &lt;li&gt;playlist number and count, if present (zero-padded, if needed)&lt;/li&gt; &#xA; &lt;li&gt;video author, title and release date in YYYY-MM-DD format, falling back to &lt;em&gt;UNKNOWN_...&lt;/em&gt; if missing&lt;/li&gt; &#xA; &lt;li&gt;sanitises everything for valid UNIX filename&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;    environment:&#xA;      - &#39;OUTPUT_TEMPLATE=%(playlist_title&amp;amp;Playlist |)S%(playlist_title|)S%(playlist_uploader&amp;amp; by |)S%(playlist_uploader|)S%(playlist_autonumber&amp;amp; - |)S%(playlist_autonumber|)S%(playlist_count&amp;amp; of |)S%(playlist_count|)S%(playlist_autonumber&amp;amp; - |)S%(uploader,creator|UNKNOWN_AUTHOR)S - %(title|UNKNOWN_TITLE)S - %(release_date&amp;gt;%Y-%m-%d,upload_date&amp;gt;%Y-%m-%d|UNKNOWN_DATE)S.%(ext)s&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Using browser cookies&lt;/h2&gt; &#xA;&lt;p&gt;In case you need to use your browser&#39;s cookies with MeTube, for example to download restricted or private videos:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Add the following to your docker-compose.yml:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;    volumes:&#xA;      - /path/to/cookies:/cookies&#xA;    environment:&#xA;      - YTDL_OPTIONS={&#34;cookiefile&#34;:&#34;/cookies/cookies.txt&#34;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install in your browser an extension to extract cookies: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://addons.mozilla.org/en-US/firefox/addon/export-cookies-txt/&#34;&gt;Firefox&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://chrome.google.com/webstore/detail/get-cookiestxt-locally/cclelndahbckbenkjhflpdbgdldlbecc&#34;&gt;Chrome&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Extract the cookies you need with the extension and rename the file &lt;code&gt;cookies.txt&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Drop the file in the folder you configured in the docker-compose.yml above&lt;/li&gt; &#xA; &lt;li&gt;Restart the container&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Browser extensions&lt;/h2&gt; &#xA;&lt;p&gt;Browser extensions allow right-clicking videos and sending them directly to MeTube. Please note that if you&#39;re on an HTTPS page, your MeTube instance must be behind an HTTPS reverse proxy (see below) for the extensions to work.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Chrome:&lt;/strong&gt; contributed by &lt;a href=&#34;https://github.com/rpsl&#34;&gt;Rpsl&lt;/a&gt;. You can install it from &lt;a href=&#34;https://chrome.google.com/webstore/detail/metube-downloader/fbmkmdnlhacefjljljlbhkodfmfkijdh&#34;&gt;Google Chrome Webstore&lt;/a&gt; or use developer mode and install &lt;a href=&#34;https://github.com/Rpsl/metube-browser-extension&#34;&gt;from sources&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Firefox:&lt;/strong&gt; contributed by &lt;a href=&#34;https://github.com/nanocortex&#34;&gt;nanocortex&lt;/a&gt;. You can install it from &lt;a href=&#34;https://addons.mozilla.org/en-US/firefox/addon/metube-downloader&#34;&gt;Firefox Addons&lt;/a&gt; or get sources from &lt;a href=&#34;https://github.com/nanocortex/metube-firefox-addon&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;iOS Shortcut&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/rithask&#34;&gt;rithask&lt;/a&gt; has created an iOS shortcut to send the URL to MeTube from Safari. Initially, you&#39;ll need to enter the server address and port, but after that, it will be saved and you can just run the shortcut from the share menu in Safari. The address should include the protocol (http/https) and the port, if it&#39;s not the default 80/443. For example: &lt;code&gt;https://metube.example.com&lt;/code&gt; or &lt;code&gt;http://192.168.1.1:8081&lt;/code&gt;. The shortcut can be found &lt;a href=&#34;https://www.icloud.com/shortcuts/f1548df15b734418a77a709103bc1dd5&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;iOS Compatibility&lt;/h2&gt; &#xA;&lt;p&gt;iOS has strict requirements for video files, requiring h264 or h265 video codec and aac audio codec in MP4 container. This can sometimes be a lower quality than the best quality available. To accommodate iOS requirements, when downloading a MP4 format you can choose &#34;Best (iOS)&#34; to get the best quality formats as compatible as possible with iOS requirements.&lt;/p&gt; &#xA;&lt;h2&gt;Bookmarklet&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/kushfest&#34;&gt;kushfest&lt;/a&gt; has created a Chrome bookmarklet for sending the currently open webpage to MeTube. Please note that if you&#39;re on an HTTPS page, your MeTube instance must be behind an HTTPS reverse proxy (see below) for the bookmarklet to work.&lt;/p&gt; &#xA;&lt;p&gt;GitHub doesn&#39;t allow embedding JavaScript as a link, so the bookmarklet has to be created manually by copying the following code to a new bookmark you create on your bookmarks bar. Change the hostname in the URL below to point to your MeTube instance.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;javascript:!function(){xhr=new XMLHttpRequest();xhr.open(&#34;POST&#34;,&#34;https://metube.domain.com/add&#34;);xhr.withCredentials=true;xhr.send(JSON.stringify({&#34;url&#34;:document.location.href,&#34;quality&#34;:&#34;best&#34;}));xhr.onload=function(){if(xhr.status==200){alert(&#34;Sent to metube!&#34;)}else{alert(&#34;Send to metube failed. Check the javascript console for clues.&#34;)}}}();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/shoonya75&#34;&gt;shoonya75&lt;/a&gt; has contributed a Firefox version:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;javascript:(function(){xhr=new XMLHttpRequest();xhr.open(&#34;POST&#34;,&#34;https://metube.domain.com/add&#34;);xhr.send(JSON.stringify({&#34;url&#34;:document.location.href,&#34;quality&#34;:&#34;best&#34;}));xhr.onload=function(){if(xhr.status==200){alert(&#34;Sent to metube!&#34;)}else{alert(&#34;Send to metube failed. Check the javascript console for clues.&#34;)}}})();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The above bookmarklets use &lt;code&gt;alert()&lt;/code&gt; as a success/failure notification. The following will show a toast message instead:&lt;/p&gt; &#xA;&lt;p&gt;Chrome:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;javascript:!function(){function notify(msg) {var sc = document.scrollingElement.scrollTop; var text = document.createElement(&#39;span&#39;);text.innerHTML=msg;var ts = text.style;ts.all = &#39;revert&#39;;ts.color = &#39;#000&#39;;ts.fontFamily = &#39;Verdana, sans-serif&#39;;ts.fontSize = &#39;15px&#39;;ts.backgroundColor = &#39;white&#39;;ts.padding = &#39;15px&#39;;ts.border = &#39;1px solid gainsboro&#39;;ts.boxShadow = &#39;3px 3px 10px&#39;;ts.zIndex = &#39;100&#39;;document.body.appendChild(text);ts.position = &#39;absolute&#39;; ts.top = 50 + sc + &#39;px&#39;; ts.left = (window.innerWidth / 2)-(text.offsetWidth / 2) + &#39;px&#39;; setTimeout(function () { text.style.visibility = &#34;hidden&#34;; }, 1500);}xhr=new XMLHttpRequest();xhr.open(&#34;POST&#34;,&#34;https://metube.domain.com/add&#34;);xhr.send(JSON.stringify({&#34;url&#34;:document.location.href,&#34;quality&#34;:&#34;best&#34;}));xhr.onload=function() { if(xhr.status==200){notify(&#34;Sent to metube!&#34;)}else {notify(&#34;Send to metube failed. Check the javascript console for clues.&#34;)}}}();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Firefox:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;javascript:(function(){function notify(msg) {var sc = document.scrollingElement.scrollTop; var text = document.createElement(&#39;span&#39;);text.innerHTML=msg;var ts = text.style;ts.all = &#39;revert&#39;;ts.color = &#39;#000&#39;;ts.fontFamily = &#39;Verdana, sans-serif&#39;;ts.fontSize = &#39;15px&#39;;ts.backgroundColor = &#39;white&#39;;ts.padding = &#39;15px&#39;;ts.border = &#39;1px solid gainsboro&#39;;ts.boxShadow = &#39;3px 3px 10px&#39;;ts.zIndex = &#39;100&#39;;document.body.appendChild(text);ts.position = &#39;absolute&#39;; ts.top = 50 + sc + &#39;px&#39;; ts.left = (window.innerWidth / 2)-(text.offsetWidth / 2) + &#39;px&#39;; setTimeout(function () { text.style.visibility = &#34;hidden&#34;; }, 1500);}xhr=new XMLHttpRequest();xhr.open(&#34;POST&#34;,&#34;https://metube.domain.com/add&#34;);xhr.send(JSON.stringify({&#34;url&#34;:document.location.href,&#34;quality&#34;:&#34;best&#34;}));xhr.onload=function() { if(xhr.status==200){notify(&#34;Sent to metube!&#34;)}else {notify(&#34;Send to metube failed. Check the javascript console for clues.&#34;)}}})();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running behind a reverse proxy&lt;/h2&gt; &#xA;&lt;p&gt;It&#39;s advisable to run MeTube behind a reverse proxy, if authentication and/or HTTPS support are required.&lt;/p&gt; &#xA;&lt;p&gt;When running behind a reverse proxy which remaps the URL (i.e. serves MeTube under a subdirectory and not under root), don&#39;t forget to set the URL_PREFIX environment variable to the correct value.&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re using the &lt;a href=&#34;https://docs.linuxserver.io/general/swag&#34;&gt;linuxserver/swag&lt;/a&gt; image for your reverse proxying needs (which I can heartily recommend), it already includes ready snippets for proxying MeTube both in &lt;a href=&#34;https://github.com/linuxserver/reverse-proxy-confs/raw/master/metube.subfolder.conf.sample&#34;&gt;subfolder&lt;/a&gt; and &lt;a href=&#34;https://github.com/linuxserver/reverse-proxy-confs/raw/master/metube.subdomain.conf.sample&#34;&gt;subdomain&lt;/a&gt; modes under the &lt;code&gt;nginx/proxy-confs&lt;/code&gt; directory in the configuration volume. It also includes Authelia which can be used for authentication.&lt;/p&gt; &#xA;&lt;h3&gt;NGINX&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;location /metube/ {&#xA;        proxy_pass http://metube:8081;&#xA;        proxy_http_version 1.1;&#xA;        proxy_set_header Upgrade $http_upgrade;&#xA;        proxy_set_header Connection &#34;upgrade&#34;;&#xA;        proxy_set_header Host $host;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: the extra &lt;code&gt;proxy_set_header&lt;/code&gt; directives are there to make WebSocket work.&lt;/p&gt; &#xA;&lt;h3&gt;Apache&lt;/h3&gt; &#xA;&lt;p&gt;Contributed by &lt;a href=&#34;https://github.com/PIE-yt&#34;&gt;PIE-yt&lt;/a&gt;. Source &lt;a href=&#34;https://gist.github.com/PIE-yt/29e7116588379032427f5bd446b2cac4&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-apache&#34;&gt;# For putting in your Apache sites site.conf&#xA;# Serves MeTube under a /metube/ subdir (http://yourdomain.com/metube/)&#xA;&amp;lt;Location /metube/&amp;gt;&#xA;    ProxyPass http://localhost:8081/ retry=0 timeout=30&#xA;    ProxyPassReverse http://localhost:8081/&#xA;&amp;lt;/Location&amp;gt;&#xA;&#xA;&amp;lt;Location /metube/socket.io&amp;gt;&#xA;    RewriteEngine On&#xA;    RewriteCond %{QUERY_STRING} transport=websocket    [NC]&#xA;    RewriteRule /(.*) ws://localhost:8081/socket.io/$1 [P,L]&#xA;    ProxyPass http://localhost:8081/socket.io retry=0 timeout=30&#xA;    ProxyPassReverse http://localhost:8081/socket.io&#xA;&amp;lt;/Location&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Caddy&lt;/h3&gt; &#xA;&lt;p&gt;The following example Caddyfile gets a reverse proxy going behind &lt;a href=&#34;https://caddyserver.com&#34;&gt;caddy&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-caddyfile&#34;&gt;example.com {&#xA;  route /metube/* {&#xA;    uri strip_prefix metube&#xA;    reverse_proxy metube:8081&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Updating yt-dlp&lt;/h2&gt; &#xA;&lt;p&gt;The engine which powers the actual video downloads in MeTube is &lt;a href=&#34;https://github.com/yt-dlp/yt-dlp&#34;&gt;yt-dlp&lt;/a&gt;. Since video sites regularly change their layouts, frequent updates of yt-dlp are required to keep up.&lt;/p&gt; &#xA;&lt;p&gt;There&#39;s an automatic nightly build of MeTube which looks for a new version of yt-dlp, and if one exists, the build pulls it and publishes an updated docker image. Therefore, in order to keep up with the changes, it&#39;s recommended that you update your MeTube container regularly with the latest image.&lt;/p&gt; &#xA;&lt;p&gt;I recommend installing and setting up &lt;a href=&#34;https://github.com/containrrr/watchtower&#34;&gt;watchtower&lt;/a&gt; for this purpose.&lt;/p&gt; &#xA;&lt;h2&gt;Troubleshooting and submitting issues&lt;/h2&gt; &#xA;&lt;p&gt;Before asking a question or submitting an issue for MeTube, please remember that MeTube is only a UI for &lt;a href=&#34;https://github.com/yt-dlp/yt-dlp&#34;&gt;yt-dlp&lt;/a&gt;. Any issues you might be experiencing with authentication to video websites, postprocessing, permissions, other &lt;code&gt;YTDL_OPTIONS&lt;/code&gt; configurations which seem not to work, or anything else that concerns the workings of the underlying yt-dlp library, need not be opened on the MeTube project. In order to debug and troubleshoot them, it&#39;s advised to try using the yt-dlp binary directly first, bypassing the UI, and once that is working, importing the options that worked for you into &lt;code&gt;YTDL_OPTIONS&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In order to test with the yt-dlp command directly, you can either download it and run it locally, or for a better simulation of its actual conditions, you can run it within the MeTube container itself. Assuming your MeTube container is called &lt;code&gt;metube&lt;/code&gt;, run the following on your Docker host to get a shell inside the container:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec -ti metube sh&#xA;cd /downloads&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once there, you can use the yt-dlp command freely.&lt;/p&gt; &#xA;&lt;h2&gt;Building and running locally&lt;/h2&gt; &#xA;&lt;p&gt;Make sure you have node.js and Python 3.11 installed.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd metube/ui&#xA;# install Angular and build the UI&#xA;npm install&#xA;node_modules/.bin/ng build&#xA;# install python dependencies&#xA;cd ..&#xA;pip3 install pipenv&#xA;pipenv install&#xA;# run&#xA;pipenv run python3 app/main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A Docker image can be built locally (it will build the UI too):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker build -t metube .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Development notes&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The above works on Windows and macOS as well as Linux.&lt;/li&gt; &#xA; &lt;li&gt;If you&#39;re running the server in VSCode, your downloads will go to your user&#39;s Downloads folder (this is configured via the environment in .vscode/launch.json).&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>TDAmeritrade/stumpy</title>
    <updated>2024-07-31T01:26:39Z</updated>
    <id>tag:github.com,2024-07-31:/TDAmeritrade/stumpy</id>
    <link href="https://github.com/TDAmeritrade/stumpy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;STUMPY is a powerful and scalable Python library for modern time series analysis&lt;/p&gt;&lt;hr&gt;&lt;p&gt;|PyPI Version| |Conda Forge Version| |PyPI Downloads| |License| |Test Status| |Code Coverage|&lt;/p&gt; &#xA;&lt;p&gt;|RTD Status| |Binder| |JOSS| |NumFOCUS| |FOSSA|&lt;/p&gt; &#xA;&lt;p&gt;.. |PyPI Version| image:: &lt;a href=&#34;https://img.shields.io/pypi/v/stumpy.svg&#34;&gt;https://img.shields.io/pypi/v/stumpy.svg&lt;/a&gt; :target: &lt;a href=&#34;https://pypi.org/project/stumpy/&#34;&gt;https://pypi.org/project/stumpy/&lt;/a&gt; :alt: PyPI Version .. |Conda Forge Version| image:: &lt;a href=&#34;https://anaconda.org/conda-forge/stumpy/badges/version.svg&#34;&gt;https://anaconda.org/conda-forge/stumpy/badges/version.svg&lt;/a&gt; :target: &lt;a href=&#34;https://anaconda.org/conda-forge/stumpy&#34;&gt;https://anaconda.org/conda-forge/stumpy&lt;/a&gt; :alt: Conda-Forge Version .. |PyPI Downloads| image:: &lt;a href=&#34;https://static.pepy.tech/badge/stumpy/month&#34;&gt;https://static.pepy.tech/badge/stumpy/month&lt;/a&gt; :target: &lt;a href=&#34;https://pepy.tech/project/stumpy&#34;&gt;https://pepy.tech/project/stumpy&lt;/a&gt; :alt: PyPI Downloads .. |License| image:: &lt;a href=&#34;https://img.shields.io/pypi/l/stumpy.svg&#34;&gt;https://img.shields.io/pypi/l/stumpy.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/TDAmeritrade/stumpy/raw/master/LICENSE.txt&#34;&gt;https://github.com/TDAmeritrade/stumpy/blob/master/LICENSE.txt&lt;/a&gt; :alt: License .. |Test Status| image:: &lt;a href=&#34;https://github.com/TDAmeritrade/stumpy/workflows/Tests/badge.svg&#34;&gt;https://github.com/TDAmeritrade/stumpy/workflows/Tests/badge.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/TDAmeritrade/stumpy/actions?query=workflow%3ATests+branch%3Amain&#34;&gt;https://github.com/TDAmeritrade/stumpy/actions?query=workflow%3ATests+branch%3Amain&lt;/a&gt; :alt: Test Status .. |Code Coverage| image:: &lt;a href=&#34;https://codecov.io/gh/TDAmeritrade/stumpy/branch/master/graph/badge.svg&#34;&gt;https://codecov.io/gh/TDAmeritrade/stumpy/branch/master/graph/badge.svg&lt;/a&gt; :target: &lt;a href=&#34;https://codecov.io/gh/TDAmeritrade/stumpy&#34;&gt;https://codecov.io/gh/TDAmeritrade/stumpy&lt;/a&gt; :alt: Code Coverage .. |RTD Status| image:: &lt;a href=&#34;https://readthedocs.org/projects/stumpy/badge/?version=latest&#34;&gt;https://readthedocs.org/projects/stumpy/badge/?version=latest&lt;/a&gt; :target: &lt;a href=&#34;https://stumpy.readthedocs.io/&#34;&gt;https://stumpy.readthedocs.io/&lt;/a&gt; :alt: ReadTheDocs Status .. |Binder| image:: &lt;a href=&#34;https://mybinder.org/badge_logo.svg&#34;&gt;https://mybinder.org/badge_logo.svg&lt;/a&gt; :target: &lt;a href=&#34;https://mybinder.org/v2/gh/TDAmeritrade/stumpy/main?filepath=notebooks&#34;&gt;https://mybinder.org/v2/gh/TDAmeritrade/stumpy/main?filepath=notebooks&lt;/a&gt; :alt: Binder .. |JOSS| image:: &lt;a href=&#34;http://joss.theoj.org/papers/10.21105/joss.01504/status.svg&#34;&gt;http://joss.theoj.org/papers/10.21105/joss.01504/status.svg&lt;/a&gt; :target: &lt;a href=&#34;https://doi.org/10.21105/joss.01504&#34;&gt;https://doi.org/10.21105/joss.01504&lt;/a&gt; :alt: JOSS .. |DOI| image:: &lt;a href=&#34;https://zenodo.org/badge/184809315.svg&#34;&gt;https://zenodo.org/badge/184809315.svg&lt;/a&gt; :target: &lt;a href=&#34;https://zenodo.org/badge/latestdoi/184809315&#34;&gt;https://zenodo.org/badge/latestdoi/184809315&lt;/a&gt; :alt: DOI .. |NumFOCUS| image:: &lt;a href=&#34;https://img.shields.io/badge/NumFOCUS-Affiliated%20Project-orange.svg?style=flat&amp;amp;colorA=E1523D&amp;amp;colorB=007D8A&#34;&gt;https://img.shields.io/badge/NumFOCUS-Affiliated%20Project-orange.svg?style=flat&amp;amp;colorA=E1523D&amp;amp;colorB=007D8A&lt;/a&gt; :target: &lt;a href=&#34;https://numfocus.org/sponsored-projects/affiliated-projects&#34;&gt;https://numfocus.org/sponsored-projects/affiliated-projects&lt;/a&gt; :alt: NumFOCUS Affiliated Project .. |FOSSA| image:: &lt;a href=&#34;https://app.fossa.com/api/projects/custom%2B9056%2Fgithub.com%2FTDAmeritrade%2Fstumpy.svg?type=shield&#34;&gt;https://app.fossa.com/api/projects/custom%2B9056%2Fgithub.com%2FTDAmeritrade%2Fstumpy.svg?type=shield&lt;/a&gt; :target: &lt;a href=&#34;https://app.fossa.io/projects/custom%2B9056%2Fgithub.com%2FTDAmeritrade%2Fstumpy?ref=badge_shield&#34;&gt;https://app.fossa.io/projects/custom%2B9056%2Fgithub.com%2FTDAmeritrade%2Fstumpy?ref=badge_shield&lt;/a&gt; :alt: FOSSA .. |Twitter| image:: &lt;a href=&#34;https://img.shields.io/twitter/follow/stumpy_dev.svg?style=social&#34;&gt;https://img.shields.io/twitter/follow/stumpy_dev.svg?style=social&lt;/a&gt; :target: &lt;a href=&#34;https://twitter.com/stumpy_dev&#34;&gt;https://twitter.com/stumpy_dev&lt;/a&gt; :alt: Twitter&lt;/p&gt; &#xA;&lt;p&gt;|&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://raw.githubusercontent.com/TDAmeritrade/stumpy/master/docs/images/stumpy_logo_small.png&#34;&gt;https://raw.githubusercontent.com/TDAmeritrade/stumpy/master/docs/images/stumpy_logo_small.png&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/TDAmeritrade/stumpy&#34;&gt;https://github.com/TDAmeritrade/stumpy&lt;/a&gt; :alt: STUMPY Logo&lt;/p&gt; &#xA;&lt;h1&gt;====== STUMPY&lt;/h1&gt; &#xA;&lt;p&gt;STUMPY is a powerful and scalable Python library that efficiently computes something called the &lt;code&gt;matrix profile &amp;lt;https://stumpy.readthedocs.io/en/latest/Tutorial_The_Matrix_Profile.html&amp;gt;&lt;/code&gt;__, which is just an academic way of saying &#34;for every (green) subsequence within your time series, automatically identify its corresponding nearest-neighbor (grey)&#34;:&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://github.com/TDAmeritrade/stumpy/raw/main/docs/images/stumpy_demo.gif?raw=true&#34;&gt;https://github.com/TDAmeritrade/stumpy/blob/main/docs/images/stumpy_demo.gif?raw=true&lt;/a&gt; :alt: STUMPY Animated GIF&lt;/p&gt; &#xA;&lt;p&gt;What&#39;s important is that once you&#39;ve computed your matrix profile (middle panel above) it can then be used for a variety of time series data mining tasks such as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;pattern/motif (approximately repeated subsequences within a longer time series) discovery&lt;/li&gt; &#xA; &lt;li&gt;anomaly/novelty (discord) discovery&lt;/li&gt; &#xA; &lt;li&gt;shapelet discovery&lt;/li&gt; &#xA; &lt;li&gt;semantic segmentation&lt;/li&gt; &#xA; &lt;li&gt;streaming (on-line) data&lt;/li&gt; &#xA; &lt;li&gt;fast approximate matrix profiles&lt;/li&gt; &#xA; &lt;li&gt;time series chains (temporally ordered set of subsequence patterns)&lt;/li&gt; &#xA; &lt;li&gt;snippets for summarizing long time series&lt;/li&gt; &#xA; &lt;li&gt;pan matrix profiles for selecting the best subsequence window size(s)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;and more ... &amp;lt;https://www.cs.ucr.edu/~eamonn/100_Time_Series_Data_Mining_Questions__with_Answers.pdf&amp;gt;&lt;/code&gt;__&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Whether you are an academic, data scientist, software developer, or time series enthusiast, STUMPY is straightforward to install and our goal is to allow you to get to your time series insights faster. See &lt;code&gt;documentation &amp;lt;https://stumpy.readthedocs.io/en/latest/&amp;gt;&lt;/code&gt;__ for more information.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;How to use STUMPY&lt;/h2&gt; &#xA;&lt;p&gt;Please see our &lt;code&gt;API documentation &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html&amp;gt;&lt;/code&gt;__ for a complete list of available functions and see our informative &lt;code&gt;tutorials &amp;lt;https://stumpy.readthedocs.io/en/latest/tutorials.html&amp;gt;&lt;/code&gt;__ for more comprehensive example use cases. Below, you will find code snippets that quickly demonstrate how to use STUMPY.&lt;/p&gt; &#xA;&lt;p&gt;Typical usage (1-dimensional time series data) with &lt;code&gt;STUMP &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.stump&amp;gt;&lt;/code&gt;__:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: python&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import stumpy&#xA;import numpy as np&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    your_time_series = np.random.rand(10000)&#xA;    window_size = 50  # Approximately, how many data points might be found in a pattern &#xA;&#xA;    matrix_profile = stumpy.stump(your_time_series, m=window_size)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Distributed usage for 1-dimensional time series data with Dask Distributed via &lt;code&gt;STUMPED &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.stumped&amp;gt;&lt;/code&gt;__:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: python&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import stumpy&#xA;import numpy as np&#xA;from dask.distributed import Client&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    with Client() as dask_client:&#xA;        your_time_series = np.random.rand(10000)&#xA;        window_size = 50  # Approximately, how many data points might be found in a pattern &#xA;&#xA;        matrix_profile = stumpy.stumped(dask_client, your_time_series, m=window_size)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;GPU usage for 1-dimensional time series data with &lt;code&gt;GPU-STUMP &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.gpu_stump&amp;gt;&lt;/code&gt;__:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: python&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import stumpy&#xA;import numpy as np&#xA;from numba import cuda&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    your_time_series = np.random.rand(10000)&#xA;    window_size = 50  # Approximately, how many data points might be found in a pattern&#xA;    all_gpu_devices = [device.id for device in cuda.list_devices()]  # Get a list of all available GPU devices&#xA;&#xA;    matrix_profile = stumpy.gpu_stump(your_time_series, m=window_size, device_id=all_gpu_devices)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Multi-dimensional time series data with &lt;code&gt;MSTUMP &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.mstump&amp;gt;&lt;/code&gt;__:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: python&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import stumpy&#xA;import numpy as np&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    your_time_series = np.random.rand(3, 1000)  # Each row represents data from a different dimension while each column represents data from the same dimension&#xA;    window_size = 50  # Approximately, how many data points might be found in a pattern&#xA;&#xA;    matrix_profile, matrix_profile_indices = stumpy.mstump(your_time_series, m=window_size)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Distributed multi-dimensional time series data analysis with Dask Distributed &lt;code&gt;MSTUMPED &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.mstumped&amp;gt;&lt;/code&gt;__:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: python&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import stumpy&#xA;import numpy as np&#xA;from dask.distributed import Client&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    with Client() as dask_client:&#xA;        your_time_series = np.random.rand(3, 1000)   # Each row represents data from a different dimension while each column represents data from the same dimension&#xA;        window_size = 50  # Approximately, how many data points might be found in a pattern&#xA;&#xA;        matrix_profile, matrix_profile_indices = stumpy.mstumped(dask_client, your_time_series, m=window_size)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Time Series Chains with &lt;code&gt;Anchored Time Series Chains (ATSC) &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.atsc&amp;gt;&lt;/code&gt;__:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: python&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import stumpy&#xA;import numpy as np&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    your_time_series = np.random.rand(10000)&#xA;    window_size = 50  # Approximately, how many data points might be found in a pattern &#xA;    &#xA;    matrix_profile = stumpy.stump(your_time_series, m=window_size)&#xA;&#xA;    left_matrix_profile_index = matrix_profile[:, 2]&#xA;    right_matrix_profile_index = matrix_profile[:, 3]&#xA;    idx = 10  # Subsequence index for which to retrieve the anchored time series chain for&#xA;&#xA;    anchored_chain = stumpy.atsc(left_matrix_profile_index, right_matrix_profile_index, idx)&#xA;&#xA;    all_chain_set, longest_unanchored_chain = stumpy.allc(left_matrix_profile_index, right_matrix_profile_index)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Semantic Segmentation with &lt;code&gt;Fast Low-cost Unipotent Semantic Segmentation (FLUSS) &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.fluss&amp;gt;&lt;/code&gt;__:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: python&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import stumpy&#xA;import numpy as np&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    your_time_series = np.random.rand(10000)&#xA;    window_size = 50  # Approximately, how many data points might be found in a pattern&#xA;&#xA;    matrix_profile = stumpy.stump(your_time_series, m=window_size)&#xA;&#xA;    subseq_len = 50&#xA;    correct_arc_curve, regime_locations = stumpy.fluss(matrix_profile[:, 1], &#xA;                                                    L=subseq_len, &#xA;                                                    n_regimes=2, &#xA;                                                    excl_factor=1&#xA;                                                    )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;p&gt;Supported Python and NumPy versions are determined according to the &lt;code&gt;NEP 29 deprecation policy &amp;lt;https://numpy.org/neps/nep-0029-deprecation_policy.html&amp;gt;&lt;/code&gt;__.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;NumPy &amp;lt;http://www.numpy.org/&amp;gt;&lt;/code&gt;__&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Numba &amp;lt;http://numba.pydata.org/&amp;gt;&lt;/code&gt;__&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;SciPy &amp;lt;https://www.scipy.org/&amp;gt;&lt;/code&gt;__&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Where to get it&lt;/h2&gt; &#xA;&lt;p&gt;Conda install (preferred):&lt;/p&gt; &#xA;&lt;p&gt;.. code:: bash&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda install -c conda-forge stumpy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;PyPI install, presuming you have numpy, scipy, and numba installed:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: bash&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m pip install stumpy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To install stumpy from source, see the instructions in the &lt;code&gt;documentation &amp;lt;https://stumpy.readthedocs.io/en/latest/install.html&amp;gt;&lt;/code&gt;__.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;In order to fully understand and appreciate the underlying algorithms and applications, it is imperative that you read the original publications_. For a more detailed example of how to use STUMPY please consult the latest &lt;code&gt;documentation &amp;lt;https://stumpy.readthedocs.io/en/latest/&amp;gt;&lt;/code&gt;__ or explore our &lt;code&gt;hands-on tutorials &amp;lt;https://stumpy.readthedocs.io/en/latest/tutorials.html&amp;gt;&lt;/code&gt;__.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Performance&lt;/h2&gt; &#xA;&lt;p&gt;We tested the performance of computing the exact matrix profile using the Numba JIT compiled version of the code on randomly generated time series data with various lengths (i.e., &lt;code&gt;np.random.rand(n)&lt;/code&gt;) along with different &lt;code&gt;CPU and GPU hardware resources &amp;lt;hardware_&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://raw.githubusercontent.com/TDAmeritrade/stumpy/master/docs/images/performance.png&#34;&gt;https://raw.githubusercontent.com/TDAmeritrade/stumpy/master/docs/images/performance.png&lt;/a&gt; :alt: STUMPY Performance Plot&lt;/p&gt; &#xA;&lt;p&gt;The raw results are displayed in the table below as Hours:Minutes:Seconds.Milliseconds and with a constant window size of &lt;code&gt;m = 50&lt;/code&gt;. Note that these reported runtimes include the time that it takes to move the data from the host to all of the GPU device(s). You may need to scroll to the right side of the table in order to see all of the runtimes.&lt;/p&gt; &#xA;&lt;p&gt;+----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | i | n = 2\ :sup:&lt;code&gt;i&lt;/code&gt; | GPU-STOMP | STUMP.2 | STUMP.16 | STUMPED.128 | STUMPED.256 | GPU-STUMP.1 | GPU-STUMP.2 | GPU-STUMP.DGX1 | GPU-STUMP.DGX2 | +==========+===================+==============+=============+=============+=============+=============+=============+=============+================+================+ | 6 | 64 | 00:00:10.00 | 00:00:00.00 | 00:00:00.00 | 00:00:05.77 | 00:00:06.08 | 00:00:00.03 | 00:00:01.63 | NaN | NaN | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 7 | 128 | 00:00:10.00 | 00:00:00.00 | 00:00:00.00 | 00:00:05.93 | 00:00:07.29 | 00:00:00.04 | 00:00:01.66 | NaN | NaN | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 8 | 256 | 00:00:10.00 | 00:00:00.00 | 00:00:00.01 | 00:00:05.95 | 00:00:07.59 | 00:00:00.08 | 00:00:01.69 | 00:00:06.68 | 00:00:25.68 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 9 | 512 | 00:00:10.00 | 00:00:00.00 | 00:00:00.02 | 00:00:05.97 | 00:00:07.47 | 00:00:00.13 | 00:00:01.66 | 00:00:06.59 | 00:00:27.66 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 10 | 1024 | 00:00:10.00 | 00:00:00.02 | 00:00:00.04 | 00:00:05.69 | 00:00:07.64 | 00:00:00.24 | 00:00:01.72 | 00:00:06.70 | 00:00:30.49 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 11 | 2048 | NaN | 00:00:00.05 | 00:00:00.09 | 00:00:05.60 | 00:00:07.83 | 00:00:00.53 | 00:00:01.88 | 00:00:06.87 | 00:00:31.09 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 12 | 4096 | NaN | 00:00:00.22 | 00:00:00.19 | 00:00:06.26 | 00:00:07.90 | 00:00:01.04 | 00:00:02.19 | 00:00:06.91 | 00:00:33.93 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 13 | 8192 | NaN | 00:00:00.50 | 00:00:00.41 | 00:00:06.29 | 00:00:07.73 | 00:00:01.97 | 00:00:02.49 | 00:00:06.61 | 00:00:33.81 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 14 | 16384 | NaN | 00:00:01.79 | 00:00:00.99 | 00:00:06.24 | 00:00:08.18 | 00:00:03.69 | 00:00:03.29 | 00:00:07.36 | 00:00:35.23 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 15 | 32768 | NaN | 00:00:06.17 | 00:00:02.39 | 00:00:06.48 | 00:00:08.29 | 00:00:07.45 | 00:00:04.93 | 00:00:07.02 | 00:00:36.09 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 16 | 65536 | NaN | 00:00:22.94 | 00:00:06.42 | 00:00:07.33 | 00:00:09.01 | 00:00:14.89 | 00:00:08.12 | 00:00:08.10 | 00:00:36.54 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 17 | 131072 | 00:00:10.00 | 00:01:29.27 | 00:00:19.52 | 00:00:09.75 | 00:00:10.53 | 00:00:29.97 | 00:00:15.42 | 00:00:09.45 | 00:00:37.33 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 18 | 262144 | 00:00:18.00 | 00:05:56.50 | 00:01:08.44 | 00:00:33.38 | 00:00:24.07 | 00:00:59.62 | 00:00:27.41 | 00:00:13.18 | 00:00:39.30 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 19 | 524288 | 00:00:46.00 | 00:25:34.58 | 00:03:56.82 | 00:01:35.27 | 00:03:43.66 | 00:01:56.67 | 00:00:54.05 | 00:00:19.65 | 00:00:41.45 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 20 | 1048576 | 00:02:30.00 | 01:51:13.43 | 00:19:54.75 | 00:04:37.15 | 00:03:01.16 | 00:05:06.48 | 00:02:24.73 | 00:00:32.95 | 00:00:46.14 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 21 | 2097152 | 00:09:15.00 | 09:25:47.64 | 03:05:07.64 | 00:13:36.51 | 00:08:47.47 | 00:20:27.94 | 00:09:41.43 | 00:01:06.51 | 00:01:02.67 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 22 | 4194304 | NaN | 36:12:23.74 | 10:37:51.21 | 00:55:44.43 | 00:32:06.70 | 01:21:12.33 | 00:38:30.86 | 00:04:03.26 | 00:02:23.47 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 23 | 8388608 | NaN | 143:16:09.94| 38:42:51.42 | 03:33:30.53 | 02:00:49.37 | 05:11:44.45 | 02:33:14.60 | 00:15:46.26 | 00:08:03.76 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 24 | 16777216 | NaN | NaN | NaN | 14:39:11.99 | 07:13:47.12 | 20:43:03.80 | 09:48:43.42 | 01:00:24.06 | 00:29:07.84 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | NaN | 17729800 | 09:16:12.00 | NaN | NaN | 15:31:31.75 | 07:18:42.54 | 23:09:22.43 | 10:54:08.64 | 01:07:35.39 | 00:32:51.55 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 25 | 33554432 | NaN | NaN | NaN | 56:03:46.81 | 26:27:41.29 | 83:29:21.06 | 39:17:43.82 | 03:59:32.79 | 01:54:56.52 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 26 | 67108864 | NaN | NaN | NaN | 211:17:37.60| 106:40:17.17| 328:58:04.68| 157:18:30.50| 15:42:15.94 | 07:18:52.91 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | NaN | 100000000 | 291:07:12.00 | NaN | NaN | NaN | 234:51:35.39| NaN | NaN | 35:03:44.61 | 16:22:40.81 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+ | 27 | 134217728 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | 64:41:55.09 | 29:13:48.12 | +----------+-------------------+--------------+-------------+-------------+-------------+-------------+-------------+-------------+----------------+----------------+&lt;/p&gt; &#xA;&lt;p&gt;^^^^^^^^^^^^^^^^^^ Hardware Resources ^^^^^^^^^^^^^^^^^^&lt;/p&gt; &#xA;&lt;p&gt;.. _hardware:&lt;/p&gt; &#xA;&lt;p&gt;GPU-STOMP: These results are reproduced from the original &lt;code&gt;Matrix Profile II &amp;lt;https://ieeexplore.ieee.org/abstract/document/7837898&amp;gt;&lt;/code&gt;__ paper - NVIDIA Tesla K80 (contains 2 GPUs) and serves as the performance benchmark to compare against.&lt;/p&gt; &#xA;&lt;p&gt;STUMP.2: &lt;code&gt;stumpy.stump &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.stump&amp;gt;&lt;/code&gt;__ executed with 2 CPUs in Total - 2x Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz processors parallelized with Numba on a single server without Dask.&lt;/p&gt; &#xA;&lt;p&gt;STUMP.16: &lt;code&gt;stumpy.stump &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.stump&amp;gt;&lt;/code&gt;__ executed with 16 CPUs in Total - 16x Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz processors parallelized with Numba on a single server without Dask.&lt;/p&gt; &#xA;&lt;p&gt;STUMPED.128: &lt;code&gt;stumpy.stumped &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.stumped&amp;gt;&lt;/code&gt;__ executed with 128 CPUs in Total - 8x Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz processors x 16 servers, parallelized with Numba, and distributed with Dask Distributed.&lt;/p&gt; &#xA;&lt;p&gt;STUMPED.256: &lt;code&gt;stumpy.stumped &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.stumped&amp;gt;&lt;/code&gt;__ executed with 256 CPUs in Total - 8x Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz processors x 32 servers, parallelized with Numba, and distributed with Dask Distributed.&lt;/p&gt; &#xA;&lt;p&gt;GPU-STUMP.1: &lt;code&gt;stumpy.gpu_stump &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.gpu_stump&amp;gt;&lt;/code&gt;__ executed with 1x NVIDIA GeForce GTX 1080 Ti GPU, 512 threads per block, 200W power limit, compiled to CUDA with Numba, and parallelized with Python multiprocessing&lt;/p&gt; &#xA;&lt;p&gt;GPU-STUMP.2: &lt;code&gt;stumpy.gpu_stump &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.gpu_stump&amp;gt;&lt;/code&gt;__ executed with 2x NVIDIA GeForce GTX 1080 Ti GPU, 512 threads per block, 200W power limit, compiled to CUDA with Numba, and parallelized with Python multiprocessing&lt;/p&gt; &#xA;&lt;p&gt;GPU-STUMP.DGX1: &lt;code&gt;stumpy.gpu_stump &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.gpu_stump&amp;gt;&lt;/code&gt;__ executed with 8x NVIDIA Tesla V100, 512 threads per block, compiled to CUDA with Numba, and parallelized with Python multiprocessing&lt;/p&gt; &#xA;&lt;p&gt;GPU-STUMP.DGX2: &lt;code&gt;stumpy.gpu_stump &amp;lt;https://stumpy.readthedocs.io/en/latest/api.html#stumpy.gpu_stump&amp;gt;&lt;/code&gt;__ executed with 16x NVIDIA Tesla V100, 512 threads per block, compiled to CUDA with Numba, and parallelized with Python multiprocessing&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Running Tests&lt;/h2&gt; &#xA;&lt;p&gt;Tests are written in the &lt;code&gt;tests&lt;/code&gt; directory and processed using &lt;code&gt;PyTest &amp;lt;https://docs.pytest.org/en/latest/&amp;gt;&lt;/code&gt;__ and requires &lt;code&gt;coverage.py&lt;/code&gt; for code coverage analysis. Tests can be executed with:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: bash&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./test.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Python Version&lt;/h2&gt; &#xA;&lt;p&gt;STUMPY supports &lt;code&gt;Python 3.8+ &amp;lt;https://python3statement.org/&amp;gt;&lt;/code&gt;__ and, due to the use of unicode variable names/identifiers, is not compatible with Python 2.x. Given the small dependencies, STUMPY may work on older versions of Python but this is beyond the scope of our support and we strongly recommend that you upgrade to the most recent version of Python.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Getting Help&lt;/h2&gt; &#xA;&lt;p&gt;First, please check the &lt;code&gt;discussions &amp;lt;https://github.com/TDAmeritrade/stumpy/discussions&amp;gt;&lt;/code&gt;__ and &lt;code&gt;issues &amp;lt;https://github.com/TDAmeritrade/stumpy/issues?utf8=%E2%9C%93&amp;amp;q=&amp;gt;&lt;/code&gt;__ on Github to see if your question has already been answered there. If no solution is available there feel free to open a new discussion or issue and the authors will attempt to respond in a reasonably timely fashion.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome &lt;code&gt;contributions &amp;lt;https://github.com/TDAmeritrade/stumpy/blob/master/CONTRIBUTING.md&amp;gt;&lt;/code&gt;__ in any form! Assistance with documentation, particularly expanding tutorials, is always welcome. To contribute please &lt;code&gt;fork the project &amp;lt;https://github.com/TDAmeritrade/stumpy/fork&amp;gt;&lt;/code&gt;__, make your changes, and submit a pull request. We will do our best to work through any issues with you and get your code merged into the main branch.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Citing&lt;/h2&gt; &#xA;&lt;p&gt;If you have used this codebase in a scientific publication and wish to cite it, please use the &lt;code&gt;Journal of Open Source Software article &amp;lt;http://joss.theoj.org/papers/10.21105/joss.01504&amp;gt;&lt;/code&gt;__.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;S.M. Law, (2019). *STUMPY: A Powerful and Scalable Python Library for Time Series Data Mining*. Journal of Open Source Software, 4(39), 1504.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;.. code:: bibtex&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{law2019stumpy,&#xA;  author  = {Law, Sean M.},&#xA;  title   = {{STUMPY: A Powerful and Scalable Python Library for Time Series Data Mining}},&#xA;  journal = {{The Journal of Open Source Software}},&#xA;  volume  = {4},&#xA;  number  = {39},&#xA;  pages   = {1504},&#xA;  year    = {2019}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;p&gt;.. _publications:&lt;/p&gt; &#xA;&lt;p&gt;Yeh, Chin-Chia Michael, et al. (2016) Matrix Profile I: All Pairs Similarity Joins for Time Series: A Unifying View that Includes Motifs, Discords, and Shapelets. ICDM:1317-1322. &lt;code&gt;Link &amp;lt;https://ieeexplore.ieee.org/abstract/document/7837992&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;p&gt;Zhu, Yan, et al. (2016) Matrix Profile II: Exploiting a Novel Algorithm and GPUs to Break the One Hundred Million Barrier for Time Series Motifs and Joins. ICDM:739-748. &lt;code&gt;Link &amp;lt;https://ieeexplore.ieee.org/abstract/document/7837898&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;p&gt;Yeh, Chin-Chia Michael, et al. (2017) Matrix Profile VI: Meaningful Multidimensional Motif Discovery. ICDM:565-574. &lt;code&gt;Link &amp;lt;https://ieeexplore.ieee.org/abstract/document/8215529&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;p&gt;Zhu, Yan, et al. (2017) Matrix Profile VII: Time Series Chains: A New Primitive for Time Series Data Mining. ICDM:695-704. &lt;code&gt;Link &amp;lt;https://ieeexplore.ieee.org/abstract/document/8215542&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;p&gt;Gharghabi, Shaghayegh, et al. (2017) Matrix Profile VIII: Domain Agnostic Online Semantic Segmentation at Superhuman Performance Levels. ICDM:117-126. &lt;code&gt;Link &amp;lt;https://ieeexplore.ieee.org/abstract/document/8215484&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;p&gt;Zhu, Yan, et al. (2017) Exploiting a Novel Algorithm and GPUs to Break the Ten Quadrillion Pairwise Comparisons Barrier for Time Series Motifs and Joins. KAIS:203-236. &lt;code&gt;Link &amp;lt;https://link.springer.com/article/10.1007%2Fs10115-017-1138-x&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;p&gt;Zhu, Yan, et al. (2018) Matrix Profile XI: SCRIMP++: Time Series Motif Discovery at Interactive Speeds. ICDM:837-846. &lt;code&gt;Link &amp;lt;https://ieeexplore.ieee.org/abstract/document/8594908&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;p&gt;Yeh, Chin-Chia Michael, et al. (2018) Time Series Joins, Motifs, Discords and Shapelets: a Unifying View that Exploits the Matrix Profile. Data Min Knowl Disc:83-123. &lt;code&gt;Link &amp;lt;https://link.springer.com/article/10.1007/s10618-017-0519-9&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;p&gt;Gharghabi, Shaghayegh, et al. (2018) &#34;Matrix Profile XII: MPdist: A Novel Time Series Distance Measure to Allow Data Mining in More Challenging Scenarios.&#34; ICDM:965-970. &lt;code&gt;Link &amp;lt;https://ieeexplore.ieee.org/abstract/document/8594928&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;p&gt;Zimmerman, Zachary, et al. (2019) Matrix Profile XIV: Scaling Time Series Motif Discovery with GPUs to Break a Quintillion Pairwise Comparisons a Day and Beyond. SoCC &#39;19:74-86. &lt;code&gt;Link &amp;lt;https://dl.acm.org/doi/10.1145/3357223.3362721&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;p&gt;Akbarinia, Reza, and Betrand Cloez. (2019) Efficient Matrix Profile Computation Using Different Distance Functions. arXiv:1901.05708. &lt;code&gt;Link &amp;lt;https://arxiv.org/abs/1901.05708&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;p&gt;Kamgar, Kaveh, et al. (2019) Matrix Profile XV: Exploiting Time Series Consensus Motifs to Find Structure in Time Series Sets. ICDM:1156-1161. &lt;code&gt;Link &amp;lt;https://ieeexplore.ieee.org/abstract/document/8970797&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;License &amp;amp; Trademark&lt;/h2&gt; &#xA;&lt;p&gt;| STUMPY | Copyright 2019 TD Ameritrade. Released under the terms of the 3-Clause BSD license. | STUMPY is a trademark of TD Ameritrade IP Company, Inc. All rights reserved.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>healthchecks/healthchecks</title>
    <updated>2024-07-31T01:26:39Z</updated>
    <id>tag:github.com,2024-07-31:/healthchecks/healthchecks</id>
    <link href="https://github.com/healthchecks/healthchecks" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Open-source cron job and background task monitoring service, written in Python &amp; Django&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Healthchecks&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/healthchecks/healthchecks/actions/workflows/tests.yml&#34;&gt;&lt;img src=&#34;https://github.com/healthchecks/healthchecks/actions/workflows/tests.yml/badge.svg?sanitize=true&#34; alt=&#34;Tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://coveralls.io/github/healthchecks/healthchecks?branch=master&#34;&gt;&lt;img src=&#34;https://coveralls.io/repos/healthchecks/healthchecks/badge.svg?branch=master&amp;amp;service=github&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Healthchecks is a cron job monitoring service. It listens for HTTP requests and email messages (&#34;pings&#34;) from your cron jobs and scheduled tasks (&#34;checks&#34;). When a ping does not arrive on time, Healthchecks sends out alerts.&lt;/p&gt; &#xA;&lt;p&gt;Healthchecks comes with a web dashboard, API, 25+ integrations for delivering notifications, monthly email reports, WebAuthn 2FA support, team management features: projects, team members, read-only access.&lt;/p&gt; &#xA;&lt;p&gt;The building blocks are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.10+&lt;/li&gt; &#xA; &lt;li&gt;Django 5&lt;/li&gt; &#xA; &lt;li&gt;PostgreSQL or MySQL&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Healthchecks is licensed under the BSD 3-clause license.&lt;/p&gt; &#xA;&lt;p&gt;Healthchecks is available as a hosted service at &lt;a href=&#34;https://healthchecks.io/&#34;&gt;https://healthchecks.io/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;A &lt;a href=&#34;https://github.com/healthchecks/healthchecks/tree/master/docker&#34;&gt;Dockerfile&lt;/a&gt; and &lt;a href=&#34;https://hub.docker.com/r/healthchecks/healthchecks&#34;&gt;pre-built Docker images&lt;/a&gt; are available.&lt;/p&gt; &#xA;&lt;p&gt;Screenshots:&lt;/p&gt; &#xA;&lt;p&gt;The &#34;My Checks&#34; screen. Shows the status of all your cron jobs in a live-updating dashboard.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/healthchecks/healthchecks/master/static/img/my_checks.png?raw=true&#34; alt=&#34;Screenshot of My Checks page&#34; title=&#34;My Checks Page&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Each check has configurable Period and Grace Time parameters. Period is the expected time between pings. Grace Time specifies how long to wait before sending out alerts when a job is running late.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/healthchecks/healthchecks/master/static/img/period_grace.png?raw=true&#34; alt=&#34;Screenshot of Period/Grace dialog&#34; title=&#34;Period/Grace Dialog&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Alternatively, you can define the expected schedules using a cron expressions. Healthchecks uses the &lt;a href=&#34;https://github.com/cuu508/cronsim&#34;&gt;cronsim&lt;/a&gt; library to parse and evaluate cron expressions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/healthchecks/healthchecks/master/static/img/cron.png?raw=true&#34; alt=&#34;Screenshot of Cron dialog&#34; title=&#34;Cron Dialog&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Check details page, with a live-updating event log.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/healthchecks/healthchecks/master/static/img/check_details.png?raw=true&#34; alt=&#34;Screenshot of Check Details page&#34; title=&#34;Check Details Page&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Healthchecks provides status badges with public but hard-to-guess URLs. You can use them in your READMEs, dashboards, or status pages.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/healthchecks/healthchecks/master/static/img/badges.png?raw=true&#34; alt=&#34;Screenshot of Badges page&#34; title=&#34;Status Badges&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Setting Up for Development&lt;/h2&gt; &#xA;&lt;p&gt;To set up Healthchecks development environment:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Install dependencies (Debian/Ubuntu):&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo apt update&#xA;sudo apt install -y gcc python3-dev python3-venv libpq-dev libcurl4-openssl-dev libssl-dev&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Prepare directory for project code and virtualenv. Feel free to use a different location:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mkdir -p ~/webapps&#xA;cd ~/webapps&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Prepare virtual environment (with virtualenv you get pip, we&#39;ll use it soon to install requirements):&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python3 -m venv hc-venv&#xA;source hc-venv/bin/activate&#xA;pip3 install wheel # make sure wheel is installed in the venv&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Check out project code:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/healthchecks/healthchecks.git&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install requirements (Django, ...) into virtualenv:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install -r healthchecks/requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;macOS only - pycurl needs to be reinstalled using the following method (assumes OpenSSL was installed using brew):&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;export PYCURL_VERSION=`cat requirements.txt | grep pycurl | cut -d &#39;=&#39; -f3`&#xA;export OPENSSL_LOCATION=`brew --prefix openssl`&#xA;export PYCURL_SSL_LIBRARY=openssl&#xA;export LDFLAGS=-L$OPENSSL_LOCATION/lib&#xA;export CPPFLAGS=-I$OPENSSL_LOCATION/include&#xA;pip uninstall -y pycurl&#xA;pip install pycurl==$PYCURL_VERSION --compile --no-cache-dir&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create database tables and a superuser account:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd ~/webapps/healthchecks&#xA;./manage.py migrate&#xA;./manage.py createsuperuser&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;With the default configuration, Healthchecks stores data in a SQLite file &lt;code&gt;hc.sqlite&lt;/code&gt; in the checkout directory (&lt;code&gt;~/webapps/healthchecks&lt;/code&gt;).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run tests:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./manage.py test&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run development server:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./manage.py runserver&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The site should now be running at &lt;code&gt;http://localhost:8000&lt;/code&gt;. To access Django administration site, log in as a superuser, then visit &lt;code&gt;http://localhost:8000/admin/&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;Healthchecks reads configuration from environment variables.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://healthchecks.io/docs/self_hosted_configuration/&#34;&gt;Full list of configuration parameters&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Accessing Administration Panel&lt;/h2&gt; &#xA;&lt;p&gt;Healthchecks comes with Django&#39;s administration panel where you can manually view and modify user accounts, projects, checks, integrations etc. To access it,&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;if you haven&#39;t already, create a superuser account: &lt;code&gt;./manage.py createsuperuser&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;log into the site using superuser credentials&lt;/li&gt; &#xA; &lt;li&gt;in the top navigation, &#34;Account&#34; dropdown, select &#34;Site Administration&#34;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Sending Emails&lt;/h2&gt; &#xA;&lt;p&gt;Healthchecks must be able to send email messages, so it can send out login links and alerts to users. Specify your SMTP credentials using the following environment variables:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Implicit TLS (&lt;em&gt;recommended&lt;/em&gt;):&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;DEFAULT_FROM_EMAIL = &#34;valid-sender-address@example.org&#34;&#xA;EMAIL_HOST = &#34;your-smtp-server-here.com&#34;&#xA;EMAIL_PORT = 465&#xA;EMAIL_HOST_USER = &#34;smtp-username&#34;&#xA;EMAIL_HOST_PASSWORD = &#34;smtp-password&#34;&#xA;EMAIL_USE_TLS = False&#xA;EMAIL_USE_SSL = True&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Port 465 should be the preferred method according to &lt;a href=&#34;https://tools.ietf.org/html/rfc8314#section-3.3&#34;&gt;RFC8314 Section 3.3: Implicit TLS for SMTP Submission&lt;/a&gt;. Be sure to use a TLS certificate and not an SSL one.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Explicit TLS:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;DEFAULT_FROM_EMAIL = &#34;valid-sender-address@example.org&#34;&#xA;EMAIL_HOST = &#34;your-smtp-server-here.com&#34;&#xA;EMAIL_PORT = 587&#xA;EMAIL_HOST_USER = &#34;smtp-username&#34;&#xA;EMAIL_HOST_PASSWORD = &#34;smtp-password&#34;&#xA;EMAIL_USE_TLS = True&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For more information, have a look at Django documentation, &lt;a href=&#34;https://docs.djangoproject.com/en/4.2/topics/email/&#34;&gt;Sending Email&lt;/a&gt; section.&lt;/p&gt; &#xA;&lt;h2&gt;Receiving Emails&lt;/h2&gt; &#xA;&lt;p&gt;Healthchecks comes with a &lt;code&gt;smtpd&lt;/code&gt; management command, which starts up a SMTP listener service. With the command running, you can ping your checks by sending email messages to &lt;code&gt;your-uuid-here@my-monitoring-project.com&lt;/code&gt; email addresses.&lt;/p&gt; &#xA;&lt;p&gt;Start the SMTP listener on port 2525:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./manage.py smtpd --port 2525&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Send a test email:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl --url &#39;smtp://127.0.0.1:2525&#39; \&#xA;    --mail-from &#39;foo@example.org&#39; \&#xA;    --mail-rcpt &#39;11111111-1111-1111-1111-111111111111@my-monitoring-project.com&#39; \&#xA;    -F &#39;=&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Sending Alerts and Reports&lt;/h2&gt; &#xA;&lt;p&gt;Healthchecks comes with a &lt;code&gt;sendalerts&lt;/code&gt; management command, which continuously polls database for any checks changing state, and sends out notifications as needed. Within an activated virtualenv, you can manually run the &lt;code&gt;sendalerts&lt;/code&gt; command like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./manage.py sendalerts&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In a production setup, you will want to run this command from a process manager like systemd or &lt;a href=&#34;http://supervisord.org/&#34;&gt;supervisor&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Healthchecks also comes with a &lt;code&gt;sendreports&lt;/code&gt; management command which sends out monthly reports, weekly reports, and the daily or hourly reminders.&lt;/p&gt; &#xA;&lt;p&gt;Run &lt;code&gt;sendreports&lt;/code&gt; without arguments to run any due reports and reminders and then exit:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./manage.py sendreports&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run it with the &lt;code&gt;--loop&lt;/code&gt; argument to make it run continuously:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./manage.py sendreports --loop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Database Cleanup&lt;/h2&gt; &#xA;&lt;p&gt;Healthchecks deletes old entries from &lt;code&gt;api_ping&lt;/code&gt; and &lt;code&gt;api_notification&lt;/code&gt; tables automatically. By default, Healthchecks keeps the 100 most recent pings for every check. You can set the limit higher to keep a longer history: go to the Administration Panel, look up user&#39;s &lt;strong&gt;Profile&lt;/strong&gt; and modify its &#34;Ping log limit&#34; field.&lt;/p&gt; &#xA;&lt;p&gt;For each check, Healthchecks removes notifications that are older than the oldest stored ping for same check.&lt;/p&gt; &#xA;&lt;p&gt;Healthchecks also provides management commands for cleaning up &lt;code&gt;auth_user&lt;/code&gt;, &lt;code&gt;api_tokenbucket&lt;/code&gt; and &lt;code&gt;api_flip&lt;/code&gt; tables.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Remove user accounts that match either of these conditions:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Account was created more than 6 months ago, and user has never logged in. These can happen when user enters invalid email address when signing up.&lt;/li&gt; &#xA;   &lt;li&gt;Last login was more than 6 months ago, and the account has no checks. Assume the user doesn&#39;t intend to use the account any more and would probably &lt;em&gt;want&lt;/em&gt; it removed.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./manage.py pruneusers&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Remove old records from the &lt;code&gt;api_tokenbucket&lt;/code&gt; table. The TokenBucket model is used for rate-limiting login attempts and similar operations. Any records older than one day can be safely removed.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./manage.py prunetokenbucket&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Remove old records from the &lt;code&gt;api_flip&lt;/code&gt; table. The Flip objects are used to track status changes of checks, and to calculate downtime statistics month by month. Flip objects from more than 3 months ago are not used and can be safely removed.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./manage.py pruneflips&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Remove old objects from external object storage. When an user removes a check, removes a project, or closes their account, Healthchecks does not remove the associated objects from the external object storage on the fly. Instead, you should run &lt;code&gt;pruneobjects&lt;/code&gt; occasionally (for example, once a month). This command first takes an inventory of all checks in the database, and then iterates over top-level keys in the object storage bucket, and deletes any that don&#39;t also exist in the database.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./manage.py pruneobjects&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When you first try these commands on your data, it is a good idea to test them on a copy of your database, not on the live database right away. In a production setup, you should also have regular, automated database backups set up.&lt;/p&gt; &#xA;&lt;h2&gt;Two-factor Authentication&lt;/h2&gt; &#xA;&lt;p&gt;Healthchecks optionally supports two-factor authentication using the WebAuthn standard. To enable WebAuthn support, set the &lt;code&gt;RP_ID&lt;/code&gt; (relying party identifier ) setting to a non-null value. Set its value to your site&#39;s domain without scheme and without port. For example, if your site runs on &lt;code&gt;https://my-hc.example.org&lt;/code&gt;, set &lt;code&gt;RP_ID&lt;/code&gt; to &lt;code&gt;my-hc.example.org&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Note that WebAuthn requires HTTPS, even if running on localhost. To test WebAuthn locally with a self-signed certificate, you can use the &lt;code&gt;runsslserver&lt;/code&gt; command from the &lt;code&gt;django-sslserver&lt;/code&gt; package.&lt;/p&gt; &#xA;&lt;h2&gt;External Authentication&lt;/h2&gt; &#xA;&lt;p&gt;Healthchecks supports external authentication by means of HTTP headers set by reverse proxies or the WSGI server. This allows you to integrate it into your existing authentication system (e.g., LDAP or OAuth) via an authenticating proxy. When this option is enabled, &lt;strong&gt;healthchecks will trust the header&#39;s value implicitly&lt;/strong&gt;, so it is &lt;strong&gt;very important&lt;/strong&gt; to ensure that attackers cannot set the value themselves (and thus impersonate any user). How to do this varies by your chosen proxy, but generally involves configuring it to strip out headers that normalize to the same name as the chosen identity header.&lt;/p&gt; &#xA;&lt;p&gt;To enable this feature, set the &lt;code&gt;REMOTE_USER_HEADER&lt;/code&gt; value to a header you wish to authenticate with. HTTP headers will be prefixed with &lt;code&gt;HTTP_&lt;/code&gt; and have any dashes converted to underscores. Headers without that prefix can be set by the WSGI server itself only, which is more secure.&lt;/p&gt; &#xA;&lt;p&gt;When &lt;code&gt;REMOTE_USER_HEADER&lt;/code&gt; is set, Healthchecks will:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;assume the header contains user&#39;s email address&lt;/li&gt; &#xA; &lt;li&gt;look up and automatically log in the user with a matching email address&lt;/li&gt; &#xA; &lt;li&gt;automatically create an user account if it does not exist&lt;/li&gt; &#xA; &lt;li&gt;disable the default authentication methods (login link to email, password)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;External Object Storage&lt;/h2&gt; &#xA;&lt;p&gt;Healthchecks can optionally store large ping bodies in S3-compatible object storage. To enable this feature, you will need to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;ensure you have the &lt;a href=&#34;https://docs.min.io/docs/python-client-quickstart-guide.html&#34;&gt;MinIO Python library&lt;/a&gt; installed:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install minio&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;configure the credentials for accessing object storage: &lt;code&gt;S3_ACCESS_KEY&lt;/code&gt;, &lt;code&gt;S3_SECRET_KEY&lt;/code&gt;, &lt;code&gt;S3_ENDPOINT&lt;/code&gt;, &lt;code&gt;S3_REGION&lt;/code&gt; and &lt;code&gt;S3_BUCKET&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Healthchecks will use external object storage for storing any request bodies that exceed 100 bytes. If the size of a request body is 100 bytes or below, Healthchecks will still store it in the database.&lt;/p&gt; &#xA;&lt;p&gt;Healthchecks automatically removes old stored ping bodies from object storage while uploading new data. However, Healthchecks does not automatically clean up data when you delete checks, projects or entire user accounts. Use the &lt;code&gt;pruneobjects&lt;/code&gt; management command to remove data for checks that don&#39;t exist any more.&lt;/p&gt; &#xA;&lt;p&gt;When external object storage is not enabled (the credentials for accessing object storage are not set), Healthchecks stores all ping bodies in the database. If you enable external object storage, Healthchecks will still be able to access the ping bodies already stored in the database. You don&#39;t need to migrate them to the object storage. On the other hand, if you later decide to disable external object storage, Healthchecks will not have access to the externally stored ping bodies any more. And there is currently no script or management command for migrating ping bodies from external object storage back to the database.&lt;/p&gt; &#xA;&lt;h2&gt;Integrations&lt;/h2&gt; &#xA;&lt;h3&gt;Slack&lt;/h3&gt; &#xA;&lt;p&gt;Healthchecks supports two Slack integration setup flows: legacy and app-based.&lt;/p&gt; &#xA;&lt;p&gt;The legacy flow does not require additional configuration and is used by default. In this flow the user creates an incoming webhook URL on the Slack side, and pastes the webhook URL in a form on the Healthchecks side.&lt;/p&gt; &#xA;&lt;p&gt;In the app-based flow the user clicks an &#34;Add to Slack&#34; button in Healthchecks, and gets transferred to a Slack-hosted dialog where they select the channel to post notifications to. This flow uses OAuth2 behind the scenes. To enable this flow, you will need to set up a Slack OAuth2 app:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a new Slack app on &lt;a href=&#34;https://api.slack.com/apps/&#34;&gt;https://api.slack.com/apps/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Add at least one scope in the permissions section to be able to deploy the app in your workspace (By example &lt;code&gt;incoming-webhook&lt;/code&gt; for the &lt;code&gt;Bot Token Scopes&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Add a &lt;em&gt;redirect url&lt;/em&gt; in the format &lt;code&gt;SITE_ROOT/integrations/add_slack_btn/&lt;/code&gt;. For example, if your SITE_ROOT is &lt;code&gt;https://my-hc.example.org&lt;/code&gt; then the redirect URL would be &lt;code&gt;https://my-hc.example.org/integrations/add_slack_btn/&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Look up your Slack app for the Client ID and Client Secret. Put them in &lt;code&gt;SLACK_CLIENT_ID&lt;/code&gt; and &lt;code&gt;SLACK_CLIENT_SECRET&lt;/code&gt; environment variables. Once these variables are set, Healthchecks will switch from using the legacy flow to using the app-based flow.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The legacy and app-based flows only affect the user experience during the initial setup of Slack integrations. The contents of notifications posted to Slack are the same regardless of the setup flow used.&lt;/p&gt; &#xA;&lt;h3&gt;Discord&lt;/h3&gt; &#xA;&lt;p&gt;To enable Discord integration, you will need to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;register a new application on &lt;a href=&#34;https://discord.com/developers/applications/me&#34;&gt;https://discord.com/developers/applications/me&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;add a redirect URI to your Discord application. The URI format is &lt;code&gt;SITE_ROOT/integrations/add_discord/&lt;/code&gt;. For example, if you are running a development server on &lt;code&gt;localhost:8000&lt;/code&gt; then the redirect URI would be &lt;code&gt;http://localhost:8000/integrations/add_discord/&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Look up your Discord app&#39;s Client ID and Client Secret. Put them in &lt;code&gt;DISCORD_CLIENT_ID&lt;/code&gt; and &lt;code&gt;DISCORD_CLIENT_SECRET&lt;/code&gt; environment variables.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Pushover&lt;/h3&gt; &#xA;&lt;p&gt;Pushover integration works by creating an application on Pushover.net which is then subscribed to by Healthchecks users. The registration workflow is as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;On Healthchecks, the user adds a &#34;Pushover&#34; integration to a project&lt;/li&gt; &#xA; &lt;li&gt;Healthchecks redirects user&#39;s browser to a Pushover.net subscription page&lt;/li&gt; &#xA; &lt;li&gt;User approves adding the Healthchecks subscription to their Pushover account&lt;/li&gt; &#xA; &lt;li&gt;Pushover.net HTTP redirects back to Healthchecks with a subscription token&lt;/li&gt; &#xA; &lt;li&gt;Healthchecks saves the subscription token and uses it for sending Pushover notifications&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To enable the Pushover integration, you will need to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Register a new application on Pushover via &lt;a href=&#34;https://pushover.net/apps/build&#34;&gt;https://pushover.net/apps/build&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Within the Pushover &#39;application&#39; configuration, enable subscriptions. Make sure the subscription type is set to &#34;URL&#34;. Also make sure the redirect URL is configured to point back to the root of the Healthchecks instance (e.g., &lt;code&gt;http://healthchecks.example.com/&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Put the Pushover application API Token and the Pushover subscription URL in &lt;code&gt;PUSHOVER_API_TOKEN&lt;/code&gt; and &lt;code&gt;PUSHOVER_SUBSCRIPTION_URL&lt;/code&gt; environment variables. The Pushover subscription URL should look similar to &lt;code&gt;https://pushover.net/subscribe/yourAppName-randomAlphaNumericData&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Signal&lt;/h3&gt; &#xA;&lt;p&gt;Healthchecks uses &lt;a href=&#34;https://github.com/AsamK/signal-cli&#34;&gt;signal-cli&lt;/a&gt; to send Signal notifications. Healthcecks interacts with signal-cli over UNIX or TCP socket. Healthchecks requires signal-cli version 0.11.2 or later.&lt;/p&gt; &#xA;&lt;p&gt;To enable the Signal integration via UNIX socket:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Set up and configure signal-cli to expose JSON RPC on an UNIX socket (&lt;a href=&#34;https://github.com/AsamK/signal-cli/wiki/JSON-RPC-service&#34;&gt;instructions&lt;/a&gt;). Example: &lt;code&gt;signal-cli -a +xxxxxx daemon --socket /tmp/signal-cli-socket&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Put the socket&#39;s location in the &lt;code&gt;SIGNAL_CLI_SOCKET&lt;/code&gt; environment variable.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To enable the Signal integration via TCP socket:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Set up and configure signal-cli to expose JSON RPC on a TCP socket. Example: &lt;code&gt;signal-cli -a +xxxxxx daemon --tcp 127.0.0.1:7583&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Put the socket&#39;s hostname and port in the &lt;code&gt;SIGNAL_CLI_SOCKET&lt;/code&gt; environment variable using &#34;hostname:port&#34; syntax, example: &lt;code&gt;127.0.0.1:7583&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Telegram&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Create a Telegram bot by talking to the &lt;a href=&#34;https://core.telegram.org/bots#6-botfather&#34;&gt;BotFather&lt;/a&gt;. Set the bot&#39;s name, description, user picture, and add a &#34;/start&#34; command. To avoid user confusion, please do not use the Healthchecks.io logo as your bot&#39;s user picture, use your own logo.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;After creating the bot you will have the bot&#39;s name and token. Put them in &lt;code&gt;TELEGRAM_BOT_NAME&lt;/code&gt; and &lt;code&gt;TELEGRAM_TOKEN&lt;/code&gt; environment variables.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run &lt;code&gt;settelegramwebhook&lt;/code&gt; management command. This command tells Telegram where to forward channel messages by invoking Telegram&#39;s &lt;a href=&#34;https://core.telegram.org/bots/api#setwebhook&#34;&gt;setWebhook&lt;/a&gt; API call:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./manage.py settelegramwebhook&#xA;Done, Telegram&#39;s webhook set to: https://my-monitoring-project.com/integrations/telegram/bot/&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For this to work, your &lt;code&gt;SITE_ROOT&lt;/code&gt; must be correct and must use the &#34;https://&#34; scheme.&lt;/p&gt; &#xA;&lt;h3&gt;Apprise&lt;/h3&gt; &#xA;&lt;p&gt;To enable Apprise integration, you will need to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;ensure you have apprise installed in your local environment:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install apprise&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;enable the apprise functionality by setting the &lt;code&gt;APPRISE_ENABLED&lt;/code&gt; environment variable.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Shell Commands&lt;/h3&gt; &#xA;&lt;p&gt;The &#34;Shell Commands&#34; integration runs user-defined local shell commands when checks go up or down. This integration is disabled by default, and can be enabled by setting the &lt;code&gt;SHELL_ENABLED&lt;/code&gt; environment variable to &lt;code&gt;True&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Note: be careful when using &#34;Shell Commands&#34; integration, and only enable it when you fully trust the users of your Healthchecks instance. The commands will be executed by the &lt;code&gt;manage.py sendalerts&lt;/code&gt; process, and will run with the same system permissions as the &lt;code&gt;sendalerts&lt;/code&gt; process.&lt;/p&gt; &#xA;&lt;h3&gt;Matrix&lt;/h3&gt; &#xA;&lt;p&gt;To enable the Matrix integration you will need to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Register a bot user (for posting notifications) in your preferred homeserver.&lt;/li&gt; &#xA; &lt;li&gt;Use the &lt;a href=&#34;https://www.matrix.org/docs/guides/client-server-api#login&#34;&gt;Login API call&lt;/a&gt; to retrieve bot user&#39;s access token. You can run it as shown in the documentation, using curl in command shell.&lt;/li&gt; &#xA; &lt;li&gt;Set the &lt;code&gt;MATRIX_&lt;/code&gt; environment variables. Example:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;MATRIX_HOMESERVER=https://matrix.org&#xA;MATRIX_USER_ID=@mychecks:matrix.org&#xA;MATRIX_ACCESS_TOKEN=[a long string of characters returned by the login call]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;PagerDuty Simple Install Flow&lt;/h3&gt; &#xA;&lt;p&gt;To enable PagerDuty &lt;a href=&#34;https://developer.pagerduty.com/docs/app-integration-development/events-integration/&#34;&gt;Simple Install Flow&lt;/a&gt;,&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Register a PagerDuty app at &lt;a href=&#34;https://pagerduty.com/&#34;&gt;PagerDuty&lt;/a&gt;  Developer Mode  My Apps&lt;/li&gt; &#xA; &lt;li&gt;In the newly created app, add the &#34;Events Integration&#34; functionality&lt;/li&gt; &#xA; &lt;li&gt;Specify a Redirect URL: &lt;code&gt;https://your-domain.com/integrations/add_pagerduty/&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Copy the displayed app_id value (PXXXXX) and put it in the &lt;code&gt;PD_APP_ID&lt;/code&gt; environment variable&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Running in Production&lt;/h2&gt; &#xA;&lt;p&gt;Here is a non-exhaustive list of pointers and things to check before launching a Healthchecks instance in production.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Environment variables, settings.py and local_settings.py. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.djangoproject.com/en/4.2/ref/settings/#debug&#34;&gt;DEBUG&lt;/a&gt;. Make sure it is set to &lt;code&gt;False&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.djangoproject.com/en/4.2/ref/settings/#allowed-hosts&#34;&gt;ALLOWED_HOSTS&lt;/a&gt;. Make sure it contains the correct domain name you want to use.&lt;/li&gt; &#xA;   &lt;li&gt;Server Errors. When DEBUG=False, Django will not show detailed error pages, and will not print exception tracebacks to standard output. To receive exception tracebacks in email, review and edit the &lt;a href=&#34;https://docs.djangoproject.com/en/4.2/ref/settings/#admins&#34;&gt;ADMINS&lt;/a&gt; and &lt;a href=&#34;https://docs.djangoproject.com/en/4.2/ref/settings/#server-email&#34;&gt;SERVER_EMAIL&lt;/a&gt; settings. Consider setting up exception logging with &lt;a href=&#34;https://sentry.io/for/django/&#34;&gt;Sentry&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Management commands that need to be run during each deployment. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;manage.py compress&lt;/code&gt;  creates combined JS and CSS bundles and places them in the &lt;code&gt;static-collected&lt;/code&gt; directory.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;manage.py collectstatic&lt;/code&gt;  collects static files in the &lt;code&gt;static-collected&lt;/code&gt; directory.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;manage.py migrate&lt;/code&gt;  applies any pending database schema changes and data migrations.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Processes that need to be running constantly. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;manage.py runserver&lt;/code&gt; is intended for development only. &lt;strong&gt;Do not use it in production&lt;/strong&gt;, instead consider using &lt;a href=&#34;https://uwsgi-docs.readthedocs.io/en/latest/&#34;&gt;uWSGI&lt;/a&gt; or &lt;a href=&#34;https://gunicorn.org/&#34;&gt;gunicorn&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;manage.py sendalerts&lt;/code&gt; is the process that monitors checks and sends out monitoring alerts. It must be always running, it must be started on reboot, and it must be restarted if it itself crashes. On modern linux systems, a good option is to &lt;a href=&#34;https://github.com/healthchecks/healthchecks/issues/273#issuecomment-520560304&#34;&gt;define a systemd service&lt;/a&gt; for it.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Static files. Healthchecks serves static files on its own, no configuration required. It uses the &lt;a href=&#34;http://whitenoise.evans.io/en/stable/index.html&#34;&gt;Whitenoise library&lt;/a&gt; for this.&lt;/li&gt; &#xA; &lt;li&gt;General &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Make sure the database is secured well and is getting backed up regularly&lt;/li&gt; &#xA;   &lt;li&gt;Make sure the TLS certificates are secured well and are getting refreshed regularly&lt;/li&gt; &#xA;   &lt;li&gt;Have monitoring in place to be sure the Healthchecks instance itself is operational (is accepting pings, is sending out alerts, is not running out of resources).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Docker Image&lt;/h2&gt; &#xA;&lt;p&gt;Healthchecks provides a reference Dockerfile and prebuilt Docker images for every release. The Dockerfile lives in the &lt;a href=&#34;https://github.com/healthchecks/healthchecks/tree/master/docker&#34;&gt;/docker/&lt;/a&gt; directory, and Docker images for amd64, arm/v7 and arm64 architectures are available &lt;a href=&#34;https://hub.docker.com/r/healthchecks/healthchecks&#34;&gt;on Docker Hub&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The Docker images:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use uWSGI as the web server. uWSGI is configured to perform database migrations on startup, and to run &lt;code&gt;sendalerts&lt;/code&gt;, &lt;code&gt;sendreports&lt;/code&gt;, and &lt;code&gt;smtpd&lt;/code&gt; in the background. You do not need to run them separately.&lt;/li&gt; &#xA; &lt;li&gt;Ship with both PostgreSQL and MySQL database drivers.&lt;/li&gt; &#xA; &lt;li&gt;Serve static files using the whitenoise library.&lt;/li&gt; &#xA; &lt;li&gt;Have the apprise library preinstalled.&lt;/li&gt; &#xA; &lt;li&gt;Do &lt;em&gt;not&lt;/em&gt; handle TLS termination. In a production setup, you will want to put the Healthchecks container behind a reverse proxy or load balancer that handles TLS termination.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>