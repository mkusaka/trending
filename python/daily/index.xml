<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-09-04T01:39:10Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>sympy/sympy</title>
    <updated>2022-09-04T01:39:10Z</updated>
    <id>tag:github.com,2022-09-04:/sympy/sympy</id>
    <link href="https://github.com/sympy/sympy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A computer algebra system written in pure Python&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SymPy&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pypi.python.org/pypi/sympy&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/sympy.svg?sanitize=true&#34; alt=&#34;pypi version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.org/sympy/sympy&#34;&gt;&lt;img src=&#34;https://secure.travis-ci.org/sympy/sympy.svg?branch=master&#34; alt=&#34;Build status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/sympy/sympy?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/Join%20Chat.svg?sanitize=true&#34; alt=&#34;Join the chat at https://gitter.im/sympy/sympy&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://zenodo.org/badge/latestdoi/18918/sympy/sympy&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/18918/sympy/sympy.svg?sanitize=true&#34; alt=&#34;Zenodo Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/sympy&#34;&gt;&lt;img src=&#34;https://pepy.tech/badge/sympy/month&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/sympy/sympy/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/issue_tracking-github-blue.svg?sanitize=true&#34; alt=&#34;GitHub Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://git-scm.com/book/en/v2/GitHub-Contributing-to-a-Project&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PR-Welcome-%23FF8300.svg?&#34; alt=&#34;Git Tutorial&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://numfocus.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&amp;amp;colorA=E1523D&amp;amp;colorB=007D8A&#34; alt=&#34;Powered by NumFocus&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/sympy/sympy/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/commits-since/sympy/sympy/latest.svg?longCache=true&amp;amp;style=flat-square&amp;amp;logo=git&amp;amp;logoColor=fff&#34; alt=&#34;Commits since last release&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://sympy.org/&#34;&gt;&lt;img src=&#34;https://github.com/sympy/sympy/raw/master/banner.svg?sanitize=true&#34; alt=&#34;SymPy Banner&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/sympy/sympy/master/AUTHORS&#34;&gt;AUTHORS&lt;/a&gt; file for the list of authors.&lt;/p&gt; &#xA;&lt;p&gt;And many more people helped on the SymPy mailing list, reported bugs, helped organize SymPy&#39;s participation in the Google Summer of Code, the Google Highly Open Participation Contest, Google Code-In, wrote and blogged about SymPy...&lt;/p&gt; &#xA;&lt;p&gt;License: New BSD License (see the &lt;a href=&#34;https://raw.githubusercontent.com/sympy/sympy/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details) covers all files in the sympy repository unless stated otherwise.&lt;/p&gt; &#xA;&lt;p&gt;Our mailing list is at &lt;a href=&#34;https://groups.google.com/forum/?fromgroups#!forum/sympy&#34;&gt;https://groups.google.com/forum/?fromgroups#!forum/sympy&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We have a community chat at &lt;a href=&#34;https://gitter.im/sympy/sympy&#34;&gt;Gitter&lt;/a&gt;. Feel free to ask us anything there. We have a very welcoming and helpful community.&lt;/p&gt; &#xA;&lt;h2&gt;Download&lt;/h2&gt; &#xA;&lt;p&gt;The recommended installation method is through Anaconda, &lt;a href=&#34;https://www.anaconda.com/download/&#34;&gt;https://www.anaconda.com/download/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can also get the latest version of SymPy from &lt;a href=&#34;https://pypi.python.org/pypi/sympy/&#34;&gt;https://pypi.python.org/pypi/sympy/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;To get the git version do&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/sympy/sympy.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For other options (tarballs, debs, etc.), see &lt;a href=&#34;https://docs.sympy.org/dev/install.html&#34;&gt;https://docs.sympy.org/dev/install.html&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation and Usage&lt;/h2&gt; &#xA;&lt;p&gt;For in-depth instructions on installation and building the documentation, see the &lt;a href=&#34;https://docs.sympy.org/dev/documentation-style-guide.html&#34;&gt;SymPy Documentation Style Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Everything is at:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.sympy.org/&#34;&gt;https://docs.sympy.org/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can generate everything at the above site in your local copy of SymPy by:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd doc&#xA;$ make html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then the docs will be in &lt;span class=&#34;title-ref&#34;&gt;_build/html&lt;/span&gt;. If you don&#39;t want to read that, here is a short usage:&lt;/p&gt; &#xA;&lt;p&gt;From this directory, start Python and:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from sympy import Symbol, cos&#xA;&amp;gt;&amp;gt;&amp;gt; x = Symbol(&#39;x&#39;)&#xA;&amp;gt;&amp;gt;&amp;gt; e = 1/cos(x)&#xA;&amp;gt;&amp;gt;&amp;gt; print(e.series(x, 0, 10))&#xA;1 + x**2/2 + 5*x**4/24 + 61*x**6/720 + 277*x**8/8064 + O(x**10)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;SymPy also comes with a console that is a simple wrapper around the classic python console (or IPython when available) that loads the SymPy namespace and executes some common commands for you.&lt;/p&gt; &#xA;&lt;p&gt;To start it, issue:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ bin/isympy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;from this directory, if SymPy is not installed or simply:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ isympy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;if SymPy is installed.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;SymPy has a hard dependency on the &lt;a href=&#34;http://mpmath.org/&#34;&gt;mpmath&lt;/a&gt; library (version &amp;gt;= 0.19). You should install it first, please refer to the mpmath installation guide:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/fredrik-johansson/mpmath#1-download--installation&#34;&gt;https://github.com/fredrik-johansson/mpmath#1-download--installation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;To install SymPy using PyPI, run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pip install sympy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To install SymPy using Anaconda, run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ conda install -c anaconda sympy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To install SymPy from GitHub source, first clone SymPy using &lt;code&gt;git&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/sympy/sympy.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, in the &lt;code&gt;sympy&lt;/code&gt; repository that you cloned, simply run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python setup.py install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://docs.sympy.org/dev/install.html&#34;&gt;https://docs.sympy.org/dev/install.html&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions from anyone, even if you are new to open source. Please read our &lt;a href=&#34;https://github.com/sympy/sympy/wiki/Introduction-to-contributing&#34;&gt;Introduction to Contributing&lt;/a&gt; page and the &lt;a href=&#34;https://docs.sympy.org/dev/documentation-style-guide.html&#34;&gt;SymPy Documentation Style Guide&lt;/a&gt;. If you are new and looking for some way to contribute, a good place to start is to look at the issues tagged &lt;a href=&#34;https://github.com/sympy/sympy/issues?q=is%3Aopen+is%3Aissue+label%3A%22Easy+to+Fix%22&#34;&gt;Easy to Fix&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Please note that all participants in this project are expected to follow our Code of Conduct. By participating in this project you agree to abide by its terms. See &lt;a href=&#34;https://raw.githubusercontent.com/sympy/sympy/master/CODE_OF_CONDUCT.md&#34;&gt;CODE_OF_CONDUCT.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Tests&lt;/h2&gt; &#xA;&lt;p&gt;To execute all tests, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$./setup.py test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;in the current directory.&lt;/p&gt; &#xA;&lt;p&gt;For the more fine-grained running of tests or doctests, use &lt;code&gt;bin/test&lt;/code&gt; or respectively &lt;code&gt;bin/doctest&lt;/code&gt;. The master branch is automatically tested by Travis CI.&lt;/p&gt; &#xA;&lt;p&gt;To test pull requests, use &lt;a href=&#34;https://github.com/sympy/sympy-bot&#34;&gt;sympy-bot&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Regenerate Experimental &lt;span class=&#34;title-ref&#34;&gt;LaTeX&lt;/span&gt; Parser/Lexer&lt;/h2&gt; &#xA;&lt;p&gt;The parser and lexer were generated with the &lt;a href=&#34;http://antlr4.org&#34;&gt;ANTLR4&lt;/a&gt; toolchain in &lt;code&gt;sympy/parsing/latex/_antlr&lt;/code&gt; and checked into the repo. Presently, most users should not need to regenerate these files, but if you plan to work on this feature, you will need the &lt;code&gt;antlr4&lt;/code&gt; command-line tool (and you must ensure that it is in your &lt;code&gt;PATH&lt;/code&gt;). One way to get it is:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ conda install -c conda-forge antlr=4.10.1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, follow the instructions on the ANTLR website and download the &lt;code&gt;antlr-4.10.1-complete.jar&lt;/code&gt;. Then export the &lt;code&gt;CLASSPATH&lt;/code&gt; as instructed and instead of creating &lt;code&gt;antlr4&lt;/code&gt; as an alias, make it an executable file with the following contents:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash&#xA;java -jar /usr/local/lib/antlr-4.10.1-complete.jar &#34;$@&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After making changes to &lt;code&gt;sympy/parsing/latex/LaTeX.g4&lt;/code&gt;, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./setup.py antlr&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Clean&lt;/h2&gt; &#xA;&lt;p&gt;To clean everything (thus getting the same tree as in the repository):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./setup.py clean&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also clean things with git using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clean -Xdf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;which will clear everything ignored by &lt;code&gt;.gitignore&lt;/code&gt;, and:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clean -df&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to clear all untracked files. You can revert the most recent changes in git with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git reset --hard&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;WARNING: The above commands will all clear changes you may have made, and you will lose them forever. Be sure to check things with &lt;code&gt;git status&lt;/code&gt;, &lt;code&gt;git diff&lt;/code&gt;, &lt;code&gt;git clean -Xn&lt;/code&gt;, and &lt;code&gt;git clean -n&lt;/code&gt; before doing any of those.&lt;/p&gt; &#xA;&lt;h2&gt;Bugs&lt;/h2&gt; &#xA;&lt;p&gt;Our issue tracker is at &lt;a href=&#34;https://github.com/sympy/sympy/issues&#34;&gt;https://github.com/sympy/sympy/issues&lt;/a&gt;. Please report any bugs that you find. Or, even better, fork the repository on GitHub and create a pull request. We welcome all changes, big or small, and we will help you make the pull request if you are new to git (just ask on our mailing list or Gitter Channel). If you further have any queries, you can find answers on Stack Overflow using the &lt;a href=&#34;https://stackoverflow.com/questions/tagged/sympy&#34;&gt;sympy&lt;/a&gt; tag.&lt;/p&gt; &#xA;&lt;h2&gt;Brief History&lt;/h2&gt; &#xA;&lt;p&gt;SymPy was started by Ond≈ôej ƒåert√≠k in 2005, he wrote some code during the summer, then he wrote some more code during summer 2006. In February 2007, Fabian Pedregosa joined the project and helped fix many things, contributed documentation, and made it alive again. 5 students (Mateusz Paprocki, Brian Jorgensen, Jason Gedge, Robert Schwarz, and Chris Wu) improved SymPy incredibly during summer 2007 as part of the Google Summer of Code. Pearu Peterson joined the development during the summer 2007 and he has made SymPy much more competitive by rewriting the core from scratch, which has made it from 10x to 100x faster. Jurjen N.E. Bos has contributed pretty-printing and other patches. Fredrik Johansson has written mpmath and contributed a lot of patches.&lt;/p&gt; &#xA;&lt;p&gt;SymPy has participated in every Google Summer of Code since 2007. You can see &lt;a href=&#34;https://github.com/sympy/sympy/wiki#google-summer-of-code&#34;&gt;https://github.com/sympy/sympy/wiki#google-summer-of-code&lt;/a&gt; for full details. Each year has improved SymPy by bounds. Most of SymPy&#39;s development has come from Google Summer of Code students.&lt;/p&gt; &#xA;&lt;p&gt;In 2011, Ond≈ôej ƒåert√≠k stepped down as lead developer, with Aaron Meurer, who also started as a Google Summer of Code student, taking his place. Ond≈ôej ƒåert√≠k is still active in the community but is too busy with work and family to play a lead development role.&lt;/p&gt; &#xA;&lt;p&gt;Since then, a lot more people have joined the development and some people have also left. You can see the full list in doc/src/aboutus.rst, or online at:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.sympy.org/dev/aboutus.html#sympy-development-team&#34;&gt;https://docs.sympy.org/dev/aboutus.html#sympy-development-team&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The git history goes back to 2007 when development moved from svn to hg. To see the history before that point, look at &lt;a href=&#34;https://github.com/sympy/sympy-old&#34;&gt;https://github.com/sympy/sympy-old&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can use git to see the biggest developers. The command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git shortlog -ns&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;will show each developer, sorted by commits to the project. The command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git shortlog -ns --since=&#34;1 year&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;will show the top developers from the last year.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;To cite SymPy in publications use&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Meurer A, Smith CP, Paprocki M, ƒåert√≠k O, Kirpichev SB, Rocklin M, Kumar A, Ivanov S, Moore JK, Singh S, Rathnayake T, Vig S, Granger BE, Muller RP, Bonazzi F, Gupta H, Vats S, Johansson F, Pedregosa F, Curry MJ, Terrel AR, Rouƒçka ≈†, Saboo A, Fernando I, Kulal S, Cimrman R, Scopatz A. (2017) SymPy: symbolic computing in Python. &lt;em&gt;PeerJ Computer Science&lt;/em&gt; 3:e103 &lt;a href=&#34;https://doi.org/10.7717/peerj-cs.103&#34;&gt;https://doi.org/10.7717/peerj-cs.103&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;A BibTeX entry for LaTeX users is&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{10.7717/peerj-cs.103,&#xA; title = {SymPy: symbolic computing in Python},&#xA; author = {Meurer, Aaron and Smith, Christopher P. and Paprocki, Mateusz and \v{C}ert\&#39;{i}k, Ond\v{r}ej and Kirpichev, Sergey B. and Rocklin, Matthew and Kumar, Amit and Ivanov, Sergiu and Moore, Jason K. and Singh, Sartaj and Rathnayake, Thilina and Vig, Sean and Granger, Brian E. and Muller, Richard P. and Bonazzi, Francesco and Gupta, Harsh and Vats, Shivam and Johansson, Fredrik and Pedregosa, Fabian and Curry, Matthew J. and Terrel, Andy R. and Rou\v{c}ka, \v{S}t\v{e}p\&#39;{a}n and Saboo, Ashutosh and Fernando, Isuru and Kulal, Sumith and Cimrman, Robert and Scopatz, Anthony},&#xA; year = 2017,&#xA; month = Jan,&#xA; keywords = {Python, Computer algebra system, Symbolics},&#xA; abstract = {&#xA;            SymPy is an open-source computer algebra system written in pure Python. It is built with a focus on extensibility and ease of use, through both interactive and programmatic applications. These characteristics have led SymPy to become a popular symbolic library for the scientific Python ecosystem. This paper presents the architecture of SymPy, a description of its features, and a discussion of select submodules. The supplementary material provides additional examples and further outlines details of the architecture and features of SymPy.&#xA;         },&#xA; volume = 3,&#xA; pages = {e103},&#xA; journal = {PeerJ Computer Science},&#xA; issn = {2376-5992},&#xA; url = {https://doi.org/10.7717/peerj-cs.103},&#xA; doi = {10.7717/peerj-cs.103}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;SymPy is BSD licensed, so you are free to use it whatever you like, be it academic, commercial, creating forks or derivatives, as long as you copy the BSD statement if you redistribute it (see the LICENSE file for details). That said, although not required by the SymPy license, if it is convenient for you, please cite SymPy when using it in your work and also consider contributing all your changes back, so that we can incorporate it and all of us will benefit in the end.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ljvmiranda921/prodigy-pdf-custom-recipe</title>
    <updated>2022-09-04T01:39:10Z</updated>
    <id>tag:github.com,2022-09-04:/ljvmiranda921/prodigy-pdf-custom-recipe</id>
    <link href="https://github.com/ljvmiranda921/prodigy-pdf-custom-recipe" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Custom recipe and utilities for document processing&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ü™ê spaCy Project: Prodigy recipes for document processing and layout understanding&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains recipes on how to use &lt;a href=&#34;https://prodi.gy&#34;&gt;Prodigy&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co&#34;&gt;Hugging Face&lt;/a&gt; for annotating, training, and reviewing document layout datasets. We&#39;ll be finetuning a &lt;a href=&#34;https://arxiv.org/abs/2204.08387&#34;&gt;LayoutLMv3&lt;/a&gt; model using &lt;a href=&#34;https://guillaumejaume.github.io/FUNSD/&#34;&gt;FUNSD&lt;/a&gt;, a dataset of noisy scanned documents.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ljvmiranda921/prodigy-pdf-custom-recipe/master/docs/prodigy_annotation.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This also serves as an illustration of how to design document processing solutions. I attempted to generalize this approach into a framework, which you can read more &lt;a href=&#34;https://ljvmiranda921.github.io/notebook/2022/06/19/document-processing-framework/&#34;&gt;from my blog.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ljvmiranda921/prodigy-pdf-custom-recipe/master/docs/design_principles.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üìã project.yml&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/ljvmiranda921/prodigy-pdf-custom-recipe/master/project.yml&#34;&gt;&lt;code&gt;project.yml&lt;/code&gt;&lt;/a&gt; defines the data assets required by the project, as well as the available commands and workflows. For details, see the &lt;a href=&#34;https://spacy.io/usage/projects&#34;&gt;spaCy projects documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;‚èØ Commands&lt;/h3&gt; &#xA;&lt;p&gt;The following commands are defined by the project. They can be executed using &lt;a href=&#34;https://spacy.io/api/cli#project-run&#34;&gt;&lt;code&gt;spacy project run [name]&lt;/code&gt;&lt;/a&gt;. Commands are only re-run if their inputs have changed.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Command&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;install&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Install dependencies&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;hydrate-db&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Hydrate the Prodigy database with annotated data from FUNSD&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;review&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Review hydrated annotations&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;train&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Train FUNSD model&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;qa&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Perform QA for the test dataset using a trained model&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;clean-db&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Drop all generated Prodigy datasets&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;clean-files&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Clean all intermediary files&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;‚è≠ Workflows&lt;/h3&gt; &#xA;&lt;p&gt;The following workflows are defined by the project. They can be executed using &lt;a href=&#34;https://spacy.io/api/cli#project-run&#34;&gt;&lt;code&gt;spacy project run [name]&lt;/code&gt;&lt;/a&gt; and will run the specified commands in order. Commands are only re-run if their inputs have changed.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Workflow&lt;/th&gt; &#xA;   &lt;th&gt;Steps&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;all&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;install&lt;/code&gt; ‚Üí &lt;code&gt;hydrate-db&lt;/code&gt; ‚Üí &lt;code&gt;train&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;clean-all&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;clean-db&lt;/code&gt; ‚Üí &lt;code&gt;clean-files&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;üóÇ Assets&lt;/h3&gt; &#xA;&lt;p&gt;The following assets are defined by the project. They can be fetched by running &lt;a href=&#34;https://spacy.io/api/cli#project-assets&#34;&gt;&lt;code&gt;spacy project assets&lt;/code&gt;&lt;/a&gt; in the project directory.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;File&lt;/th&gt; &#xA;   &lt;th&gt;Source&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;assets/funsd.zip&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;URL&lt;/td&gt; &#xA;   &lt;td&gt;FUNSD dataset - noisy scanned documents for layout understanding&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!-- SPACY PROJECT: AUTO-GENERATED DOCS END (do not remove) --&gt;</summary>
  </entry>
  <entry>
    <title>alibaba/EasyCV</title>
    <updated>2022-09-04T01:39:10Z</updated>
    <id>tag:github.com,2022-09-04:/alibaba/EasyCV</id>
    <link href="https://github.com/alibaba/EasyCV" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An all-in-one toolkit for computer vision&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://pypi.org/project/pai-easycv/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/pai-easycv&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://easy-cv.readthedocs.io/en/latest/&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/easy-cv/badge/?version=latest&#34; alt=&#34;Documentation Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmdetection/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/alibaba/EasyCV.svg?sanitize=true&#34; alt=&#34;license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/alibaba/EasyCV/issues&#34;&gt;&lt;img src=&#34;https://isitmaintained.com/badge/open/alibaba/EasyCV.svg?sanitize=true&#34; alt=&#34;open issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/alibaba/EasyCV/pull/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-pr/alibaba/EasyCV.svg?sanitize=true&#34; alt=&#34;GitHub pull-requests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/alibaba/EasyCV/commit/&#34;&gt;&lt;img src=&#34;https://badgen.net/github/last-commit/alibaba/EasyCV&#34; alt=&#34;GitHub latest commit&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;!-- [![GitHub contributors](https://img.shields.io/github/contributors/alibaba/EasyCV.svg)](https://GitHub.com/alibaba/EasyCV/graphs/contributors/) --&gt; &#xA; &lt;!-- [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com) --&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;EasyCV&lt;/h1&gt; &#xA;&lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/README_zh-CN.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;EasyCV is an all-in-one computer vision toolbox based on PyTorch, mainly focuses on self-supervised learning, transformer based models, and major CV tasks including image classification, metric-learning, object detection, pose estimation and so on.&lt;/p&gt; &#xA;&lt;h3&gt;Major features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;SOTA SSL Algorithms&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;EasyCV provides state-of-the-art algorithms in self-supervised learning based on contrastive learning such as SimCLR, MoCO V2, Swav, DINO and also MAE based on masked image modeling. We also provide standard benchmarking tools for ssl model evaluation.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Vision Transformers&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;EasyCV aims to provide an easy way to use the off-the-shelf SOTA transformer models trained either using supervised learning or self-supervised learning, such as ViT, Swin Transformer and DETR Series. More models will be added in the future. In addition, we support all the pretrained models from &lt;a href=&#34;https://github.com/rwightman/pytorch-image-models&#34;&gt;timm&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Functionality &amp;amp; Extensibility&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;In addition to SSL, EasyCV also supports image classification, object detection, metric learning, and more areas will be supported in the future. Although covering different areas, EasyCV decomposes the framework into different components such as dataset, model and running hook, making it easy to add new components and combining it with existing modules.&lt;/p&gt; &lt;p&gt;EasyCV provides simple and comprehensive interface for inference. Additionally, all models are supported on &lt;a href=&#34;https://help.aliyun.com/document_detail/113696.html&#34;&gt;PAI-EAS&lt;/a&gt;, which can be easily deployed as online service and support automatic scaling and service monitoring.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Efficiency&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;EasyCV supports multi-gpu and multi worker training. EasyCV uses &lt;a href=&#34;https://github.com/NVIDIA/DALI&#34;&gt;DALI&lt;/a&gt; to accelerate data io and preprocessing process, and uses &lt;a href=&#34;https://github.com/alibaba/EasyCV/tree/master/docs/source/tutorials/torchacc.md&#34;&gt;TorchAccelerator&lt;/a&gt; and fp16 to accelerate training process. For inference optimization, EasyCV exports model using jit script, which can be optimized by &lt;a href=&#34;https://help.aliyun.com/document_detail/205134.html&#34;&gt;PAI-Blade&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What&#39;s New&lt;/h2&gt; &#xA;&lt;p&gt;[üî• Latest News] We have released our YOLOX-PAI that achieves SOTA results within 40~50 mAP (less than 1ms). And we also provide a convenient and fast export/predictor api for end2end object detection. To get a quick start of YOLOX-PAI, click &lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/tutorials/yolox.md&#34;&gt;here&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;31/08/2022 EasyCV v0.6.0 was released. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Release YOLOX-PAI which achieves SOTA results within 40~50 mAP (less than 1ms)&lt;/li&gt; &#xA;   &lt;li&gt;Add detection algo DINO which achieves 58.5 mAP on COCO&lt;/li&gt; &#xA;   &lt;li&gt;Add mask2former algo&lt;/li&gt; &#xA;   &lt;li&gt;Releases imagenet1k, imagenet22k, coco, lvis, voc2012 data with BaiduDisk to accelerate downloading&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/change_log.md&#34;&gt;change_log.md&lt;/a&gt; for more details and history.&lt;/p&gt; &#xA;&lt;h2&gt;Technical Articles&lt;/h2&gt; &#xA;&lt;p&gt;We have a series of technical articles on the functionalities of EasyCV.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/505219993&#34;&gt;EasyCVÂºÄÊ∫êÔΩúÂºÄÁÆ±Âç≥Áî®ÁöÑËßÜËßâËá™ÁõëÁù£+TransformerÁÆóÊ≥ïÂ∫ì&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/515859470&#34;&gt;MAEËá™ÁõëÁù£ÁÆóÊ≥ï‰ªãÁªçÂíåÂü∫‰∫éEasyCVÁöÑÂ§çÁé∞&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/528733299&#34;&gt;Âü∫‰∫éEasyCVÂ§çÁé∞ViTDetÔºöÂçïÂ±ÇÁâπÂæÅË∂ÖË∂äFPN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/543129581&#34;&gt;Âü∫‰∫éEasyCVÂ§çÁé∞DETRÂíåDAB-DETRÔºåObject QueryÁöÑÊ≠£Á°ÆÊâìÂºÄÊñπÂºè&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to the installation section in &lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/quick_start.md&#34;&gt;quick_start.md&lt;/a&gt; for installation.&lt;/p&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/quick_start.md&#34;&gt;quick_start.md&lt;/a&gt; for quick start. We also provides tutorials for more usages.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/tutorials/ssl.md&#34;&gt;self-supervised learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/tutorials/cls.md&#34;&gt;image classification&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/tutorials/yolox.md&#34;&gt;object detection with yolox-pai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/tutorials/compression.md&#34;&gt;model compression with yolox&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/tutorials/metric_learning.md&#34;&gt;metric learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/tutorials/torchacc.md&#34;&gt;torchacc&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;notebook&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/tutorials/EasyCV%E5%9B%BE%E5%83%8F%E8%87%AA%E7%9B%91%E7%9D%A3%E8%AE%AD%E7%BB%83-MAE.ipynb&#34;&gt;self-supervised learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/tutorials/EasyCV%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BBresnet50.ipynb&#34;&gt;image classification&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/tutorials/EasyCV%E5%9B%BE%E5%83%8F%E6%A3%80%E6%B5%8BYoloX.ipynb&#34;&gt;object detection with yolox-pai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/tutorials/EasyCV%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0resnet50.ipynb&#34;&gt;metric learning&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Model Zoo&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;b&gt;Architectures&lt;/b&gt; &#xA;&lt;/div&gt; &#xA;&lt;table align=&#34;center&#34;&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr align=&#34;center&#34;&gt; &#xA;   &lt;td&gt; &lt;b&gt;Self-Supervised Learning&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Image Classification&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Object Detection&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Segmentation&lt;/b&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr valign=&#34;top&#34;&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/selfsup/byol&#34;&gt;BYOL (NeurIPS&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/selfsup/dino&#34;&gt;DINO (ICCV&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/selfsup/mixco&#34;&gt;MiXCo (NeurIPS&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/selfsup/moby&#34;&gt;MoBY (ArXiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/selfsup/mocov2&#34;&gt;MoCov2 (ArXiv&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/selfsup/simclr&#34;&gt;SimCLR (ICML&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/selfsup/swav&#34;&gt;SwAV (NeurIPS&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/selfsup/mae&#34;&gt;MAE (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/selfsup/fast_convmae&#34;&gt;FastConvMAE (ArXiv&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/resnet&#34;&gt;ResNet (CVPR&#39;2016)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/resnext&#34;&gt;ResNeXt (CVPR&#39;2017)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/hrnet&#34;&gt;HRNet (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/vit&#34;&gt;ViT (ICLR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/swint&#34;&gt;SwinT (ICCV&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/efficientformer&#34;&gt;EfficientFormer (ArXiv&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/deit&#34;&gt;DeiT (ICML&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/xcit&#34;&gt;XCiT (ArXiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/tnt&#34;&gt;TNT (NeurIPS&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/convit&#34;&gt;ConViT (ArXiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/cait&#34;&gt;CaiT (ICCV&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/levit&#34;&gt;LeViT (ICCV&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/convnext&#34;&gt;ConvNeXt (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/resmlp&#34;&gt;ResMLP (ArXiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/coat&#34;&gt;CoaT (ICCV&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/convmixer&#34;&gt;ConvMixer (ICLR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/mlp-mixer&#34;&gt;MLP-Mixer (ArXiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/nest&#34;&gt;NesT (AAAI&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/pit&#34;&gt;PiT (ArXiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/twins&#34;&gt;Twins (NeurIPS&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/classification/imagenet/timm/shuffle_transformer&#34;&gt;Shuffle Transformer (ArXiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/detection/fcos&#34;&gt;FCOS (ICCV&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/detection/yolox&#34;&gt;YOLOX (ArXiv&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/detection/yolox&#34;&gt;YOLOX-PAI (ArXiv&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/detection/detr&#34;&gt;DETR (ECCV&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/detection/dab_detr&#34;&gt;DAB-DETR (ICLR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/detection/dab_detr&#34;&gt;DN-DETR (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/detection/dino&#34;&gt;DINO (ArXiv&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt;  &lt;li&gt;&lt;b&gt;Instance Segmentation&lt;/b&gt;&lt;/li&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;ul&gt; &#xA;      &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/detection/mask_rcnn&#34;&gt;Mask R-CNN (ICCV&#39;2017)&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/detection/vitdet&#34;&gt;ViTDet (ArXiv&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/segmentation/mask2former&#34;&gt;Mask2Former (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;/ul&gt; &#xA;    &lt;/ul&gt;  &lt;li&gt;&lt;b&gt;Sementic Segmentation&lt;/b&gt;&lt;/li&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;ul&gt; &#xA;      &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/segmentation/fcn&#34;&gt;FCN (CVPR&#39;2015)&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/segmentation/upernet&#34;&gt;UperNet (ECCV&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;/ul&gt; &#xA;    &lt;/ul&gt;  &lt;li&gt;&lt;b&gt;Panoptic Segmentation&lt;/b&gt;&lt;/li&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;ul&gt; &#xA;      &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/configs/segmentation/mask2former&#34;&gt;Mask2Former (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;/ul&gt; &#xA;    &lt;/ul&gt;  &lt;/td&gt; &#xA;  &lt;/tr&gt;   &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Please refer to the following model zoo for more details.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/model_zoo_ssl.md&#34;&gt;self-supervised learning model zoo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/model_zoo_cls.md&#34;&gt;classification model zoo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/model_zoo_det.md&#34;&gt;detection model zoo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/model_zoo_seg.md&#34;&gt;segmentation model zoo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Data Hub&lt;/h2&gt; &#xA;&lt;p&gt;EasyCV have collected dataset info for different senarios, making it easy for users to fintune or evaluate models in EasyCV modelzoo.&lt;/p&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/docs/source/data_hub.md&#34;&gt;data_hub.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/LICENSE&#34;&gt;Apache License (Version 2.0)&lt;/a&gt;. This toolkit also contains various third-party components and some code modified from other repos under other open source licenses. See the &lt;a href=&#34;https://raw.githubusercontent.com/alibaba/EasyCV/master/NOTICE&#34;&gt;NOTICE&lt;/a&gt; file for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;This repo is currently maintained by PAI-CV team, you can contact us by&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Dingding group number: 41783266&lt;/li&gt; &#xA; &lt;li&gt;Email: &lt;a href=&#34;mailto:easycv@list.alibaba-inc.com&#34;&gt;easycv@list.alibaba-inc.com&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Enterprise Service&lt;/h3&gt; &#xA;&lt;p&gt;If you need EasyCV enterprise service support, or purchase cloud product services, you can contact us by DingDing Group.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/4771825/165244727-b5d69628-97a6-4e2a-a23f-0c38a8d29341.jpg&#34; alt=&#34;dingding_qrcode&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>