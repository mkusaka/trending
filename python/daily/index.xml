<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-13T01:41:03Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>paulpierre/RasaGPT</title>
    <updated>2023-05-13T01:41:03Z</updated>
    <id>tag:github.com,2023-05-13:/paulpierre/RasaGPT</id>
    <link href="https://github.com/paulpierre/RasaGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üí¨ RasaGPT is the first headless LLM chatbot platform built on top of Rasa and Langchain. Built w/ Rasa, FastAPI, Langchain, LlamaIndex, SQLModel, pgvector, ngrok, telegram&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://github.com/paulpierre/RasaGPT/raw/main/github/rasagpt-banner.png?raw=true&#34; alt=&#34;RasaGPT Logo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üè† Overview&lt;/h1&gt; &#xA;&lt;p&gt;üí¨ RasaGPT is the first headless LLM chatbot platform built on top of &lt;a href=&#34;https://github.com/RasaHQ/rasa&#34;&gt;Rasa&lt;/a&gt; and &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;Langchain&lt;/a&gt;. It is boilerplate and a reference implementation of Rasa and Telegram utilizing an LLM library like Langchain for indexing, retrieval and context injection.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üìö Resources: &lt;a href=&#34;https://rasagpt.dev&#34;&gt;https://rasagpt.dev&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üßë‚Äçüíª Github: &lt;a href=&#34;https://github.com/paulpierre/RasaGPT&#34;&gt;https://github.com/paulpierre/RasaGPT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üßô Author: &lt;a href=&#34;https://twitter.com/paulpierre&#34;&gt;@paulpierre&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/GAPnQ0qf1-E&#34;&gt;&lt;img src=&#34;https://github.com/paulpierre/RasaGPT/raw/main/github/rasagpt-video-title-screen.png?raw=true&#34; alt=&#34;RasaGPT Youtube Video&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üí¨ What is Rasa?&lt;/h1&gt; &#xA;&lt;p&gt;In their own words:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;üí¨ Rasa is an open source (Python) machine learning framework to automate text- and voice-based conversations: NLU, dialogue management, connect to Slack, Facebook, and more - Create chatbots and voice assistants&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;In my words: &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://rasa.com/&#34;&gt;Rasa&lt;/a&gt; is a very popular (dare I say de facto?) and easy-enough to use chatbot framework with built in NLU ML pipelines that are obsolete and a conceptual starting point for a reimagined chatbot framework in a world of LLMs.&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üíÅ‚Äç‚ôÄÔ∏è Why RasaGPT?&lt;/h1&gt; &#xA;&lt;p&gt;RasaGPT works out of the box. A lot of the implementing headaches were sorted out so you don‚Äôt have to, including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Creating your own proprietary bot end-point using FastAPI, document upload and ‚Äútraining‚Äù &#39;pipeline included&lt;/li&gt; &#xA; &lt;li&gt;How to integrate Langchain/LlamaIndex and Rasa&lt;/li&gt; &#xA; &lt;li&gt;Library conflicts with LLM libraries and passing metadata&lt;/li&gt; &#xA; &lt;li&gt;Dockerized &lt;a href=&#34;https://github.com/khalo-sa/rasa-apple-silicon&#34;&gt;support on MacOS&lt;/a&gt; for running Rasa&lt;/li&gt; &#xA; &lt;li&gt;Reverse proxy with chatbots &lt;a href=&#34;https://ngrok.com/docs/ngrok-agent/&#34;&gt;via ngrok&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Implementing pgvector with your own custom schema instead of using Langchain‚Äôs highly opinionated &lt;a href=&#34;https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pgvector.html&#34;&gt;PGVector class&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Adding multi-tenancy (Rasa &lt;a href=&#34;https://forum.rasa.com/t/multi-tenancy-in-rasa-core/2382&#34;&gt;doesn&#39;t natively support this&lt;/a&gt;), sessions and metadata between Rasa and your own backend / application&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The backstory is familiar. A friend came to me with a problem. I scoured Google and Github for a decent reference implementation of LLM‚Äôs integrated with Rasa but came up empty-handed. I figured this to be a great opportunity to satiate my curiosity and 2 days later I had a proof of concept, and a week later this is what I came up with.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Caveat emptor:&lt;/strong&gt; This is far from production code and rife with prompt injection and general security vulnerabilities. I just hope someone finds this useful üòä&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;strong&gt;‚ú®&lt;/strong&gt;&amp;nbsp;Quick start&lt;/h1&gt; &#xA;&lt;p&gt;Getting started is easy, just make sure you meet the dependencies below.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è ** ATTENTION NON-MACOS USERS: ** If you are using Linux or Windows, you will need to change the image name from &lt;code&gt;khalosa/rasa-aarch64:3.5.2&lt;/code&gt; to &lt;code&gt;rasa/rasa:latest&lt;/code&gt; in &lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/0463274ee3174580f2099501e0f8c58238987f9b/docker-compose.yml#L64&#34;&gt;docker-compose.yml on line #64&lt;/a&gt; and in &lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/0463274ee3174580f2099501e0f8c58238987f9b/app/rasa/actions/Dockerfile#L1&#34;&gt;the actions Dockerfile on line #1 here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Get the code&#xA;git clone https://github.com/paulpierre/RasaGPT.git&#xA;cd RasaGPT&#xA;&#xA;## Setup the .env file&#xA;cp .env-example .env&#xA;&#xA;# Edit your .env file and add all the necessary credentials&#xA;make install&#xA;&#xA;# Type &#34;make&#34; to see more options&#xA;make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üî•&amp;nbsp;Features&lt;/h1&gt; &#xA;&lt;h2&gt;Full Application and API&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;LLM ‚Äúlearns‚Äù on an arbitrary corpus of data using Langchain&lt;/li&gt; &#xA; &lt;li&gt;Upload documents and ‚Äútrain‚Äù all via &lt;a href=&#34;https://fastapi.tiangolo.com/&#34;&gt;FastAPI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Document versioning and automatic ‚Äúre-training‚Äù implemented on upload&lt;/li&gt; &#xA; &lt;li&gt;Customize your own async end-points and database models via &lt;a href=&#34;https://fastapi.tiangolo.com/&#34;&gt;FastAPI&lt;/a&gt; and &lt;a href=&#34;https://sqlmodel.tiangolo.com/&#34;&gt;SQLModel&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Bot determines whether human handoff is necessary&lt;/li&gt; &#xA; &lt;li&gt;Bot generates tags based on user questions and response automatically&lt;/li&gt; &#xA; &lt;li&gt;Full API documentation via &lt;a href=&#34;https://github.com/swagger-api/swagger-ui&#34;&gt;Swagger&lt;/a&gt; and &lt;a href=&#34;https://redocly.github.io/redoc/&#34;&gt;Redoc&lt;/a&gt; included&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pgadmin-org/pgadmin4&#34;&gt;PGAdmin&lt;/a&gt; included so you can browser your database&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/paulpierre/RasaGPT/main/ngrok.com/docs&#34;&gt;Ngrok&lt;/a&gt; end-points are automatically generated for you on startup so your bot can always be accessed via &lt;code&gt;https://t.me/yourbotname&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Embedding similarity search built into Postgres via &lt;a href=&#34;https://github.com/pgvector/pgvector&#34;&gt;pgvector&lt;/a&gt; and Postgres functions&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/tree/main/app/api/data/training_data&#34;&gt;Dummy data included&lt;/a&gt; for you to test and experiment&lt;/li&gt; &#xA; &lt;li&gt;Unlimited use cases from help desk, customer support, quiz, e-learning, dungeon and dragons, and more &lt;br&gt;&lt;br&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Rasa integration&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Built on top of &lt;a href=&#34;https://rasa.com/docs/rasa/&#34;&gt;Rasa&lt;/a&gt;, the open source gold-standard for chat platforms&lt;/li&gt; &#xA; &lt;li&gt;Supports MacOS M1/M2 via Docker (canonical Rasa image &lt;a href=&#34;https://github.com/khalo-sa/rasa-apple-silicon&#34;&gt;lacks MacOS arch. support&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Supports Telegram, easily integrate Slack, Whatsapp, Line, SMS, etc.&lt;/li&gt; &#xA; &lt;li&gt;Setup complex dialog pipelines using NLU models form Huggingface like BERT or libraries/frameworks like Keras, Tensorflow with OpenAI GPT as fallback &lt;br&gt;&lt;br&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Flexibility&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Extend agentic, memory, etc. capabilities with Langchain&lt;/li&gt; &#xA; &lt;li&gt;Schema supports multi-tenancy, sessions, data storage&lt;/li&gt; &#xA; &lt;li&gt;Customize agent personalities&lt;/li&gt; &#xA; &lt;li&gt;Saves all of chat history and creating embeddings from all interactions future-proofing your retrieval strategy&lt;/li&gt; &#xA; &lt;li&gt;Automatically generate embeddings from knowledge base corpus and client feedback&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üßë‚Äçüíª&amp;nbsp;Installing&lt;/h1&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.9&lt;/li&gt; &#xA; &lt;li&gt;Docker &amp;amp; Docker compose (&lt;a href=&#34;https://www.docker.com/products/docker-desktop/&#34;&gt;Docker desktop MacOS&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Open AI&amp;nbsp;&lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;API key&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Telegram&amp;nbsp;&lt;a href=&#34;https://core.telegram.org/bots#how-do-i-create-a-bot&#34;&gt;bot credentials&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Ngrok&amp;nbsp;&lt;a href=&#34;https://dashboard.ngrok.com/tunnels/authtokens&#34;&gt;auth token&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Make (&lt;a href=&#34;https://formulae.brew.sh/formula/make&#34;&gt;MacOS&lt;/a&gt;/&lt;a href=&#34;https://stackoverflow.com/questions/32127524/how-to-install-and-use-make-in-windows&#34;&gt;Windows&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;SQLModel&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/paulpierre/RasaGPT.git&#xA;cd RasaGPT&#xA;cp .env-example .env&#xA;&#xA;# Edit your .env file and all the credentials&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;At any point feel free to just type in &lt;code&gt;make&lt;/code&gt; and it will display the list of options, mostly useful for debugging:&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/paulpierre/RasaGPT/raw/main/github/makefile-1.png?raw=true&#34; alt=&#34;Makefile main&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Docker-compose&lt;/h2&gt; &#xA;&lt;p&gt;The easiest way to get started is using the &lt;code&gt;Makefile&lt;/code&gt; in the root directory. It will install and run all the services for RasaGPT in the correct order.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make install&#xA;&#xA;# This will automatically install and run RasaGPT&#xA;# After installation, to run again you can simply run&#xA;&#xA;make run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Local Python Environment&lt;/h2&gt; &#xA;&lt;p&gt;This is useful if you wish to focus on developing on top of the API, a separate &lt;code&gt;Makefile&lt;/code&gt; was made for this. This will create a local virtual environment for you.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Assuming you are already in the RasaGPT directory&#xA;cd app/api&#xA;make install&#xA;&#xA;# This will automatically install and run RasaGPT&#xA;# After installation, to run again you can simply run&#xA;&#xA;make run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Similarly, enter &lt;code&gt;make&lt;/code&gt; to see a full list of commands&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/paulpierre/RasaGPT/raw/main/github/makefile-2.png?raw=true&#34; alt=&#34;Makefile API&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Installation process&lt;/h2&gt; &#xA;&lt;p&gt;Installation should be automated should look like this:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/paulpierre/RasaGPT/raw/main/github/cli_install.png?raw=true&#34; alt=&#34;Installation&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;üëâ&amp;nbsp;Full installation log:&amp;nbsp;&lt;a href=&#34;https://app.warp.dev/block/vflua6Eue29EPk8EVvW8Kd&#34;&gt;https://app.warp.dev/block/vflua6Eue29EPk8EVvW8Kd&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;The installation process for Docker takes the following steps at a high level&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Check to make sure you have &lt;code&gt;.env&lt;/code&gt; available&lt;/li&gt; &#xA; &lt;li&gt;Database is initialized with &lt;a href=&#34;https://github.com/pgvector/pgvector&#34;&gt;&lt;code&gt;pgvector&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Database models create the database schema&lt;/li&gt; &#xA; &lt;li&gt;Trains the Rasa model so it is ready to run&lt;/li&gt; &#xA; &lt;li&gt;Sets up ngrok with Rasa so Telegram has a webhook back to your API server&lt;/li&gt; &#xA; &lt;li&gt;Sets up the Rasa actions server so Rasa can talk to the RasaGPT API&lt;/li&gt; &#xA; &lt;li&gt;Database is populated with dummy data via &lt;code&gt;seed.py&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;‚òëÔ∏è&amp;nbsp;Next steps&lt;/h1&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üí¨&amp;nbsp;Start chatting&lt;/h2&gt; &#xA;&lt;p&gt;You can start chatting with your bot by visiting üëâ &lt;a href=&#34;https://t.me/yourbotsname&#34;&gt;https://t.me/yourbotsname&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/paulpierre/RasaGPT/raw/main/github/telegram.png?raw=true&#34; alt=&#34;Telegram&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üëÄ&amp;nbsp;View logs&lt;/h2&gt; &#xA;&lt;p&gt;You can view all of the log by visiting üëâ &lt;a href=&#34;https://localhost:9999/&#34;&gt;https://localhost:9999/&lt;/a&gt; which will displaying real-time logs of all the docker containers&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/paulpierre/RasaGPT/raw/main/github/container_logs.png?raw=true&#34; alt=&#34;Dozzle&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üìñ&amp;nbsp;API documentation&lt;/h2&gt; &#xA;&lt;p&gt;View the API endpoint docs by visiting üëâ &lt;a href=&#34;https://localhost:8888/docs&#34;&gt;https://localhost:8888/docs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;In this page you can create and update entities, as well as upload documents to the knowledge base.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/paulpierre/RasaGPT/raw/main/github/api.png?raw=true&#34; alt=&#34;Swagger Docs&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;‚úèÔ∏è&amp;nbsp;Examples&lt;/h1&gt; &#xA;&lt;p&gt;The bot is just a proof-of-concept and has not been optimized for retrieval. It currently uses 1000 character length chunking for indexing and basic euclidean distance for retrieval and quality is hit or miss.&lt;/p&gt; &#xA;&lt;p&gt;You can view example hits and misses with the bot in the &lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/RESULTS.md&#34;&gt;RESULTS.MD&lt;/a&gt; file. Overall I estimate index optimization and LLM configuration changes can increase output quality by more than 70%.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;üëâ&amp;nbsp;Click to see the &lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/RESULTS.md&#34;&gt;Q&amp;amp;A results of the demo data in&amp;nbsp;RESULTS.MD&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üíª&amp;nbsp;API Architecture and Usage&lt;/h1&gt; &#xA;&lt;p&gt;The REST API is straight forward, please visit the documentation üëâ&amp;nbsp;&lt;a href=&#34;http://localhost:8888/docs&#34;&gt;http://localhost:8888/docs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The entities below have basic CRUD operations and return JSON&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Organization&lt;/h2&gt; &#xA;&lt;p&gt;This can be thought of as a company that is your client in a SaaS / multi-tenant world. By default a list of dummy organizations have been provided&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/paulpierre/RasaGPT/raw/main/github/orgs.png?raw=true&#34; alt=&#34;Screenshot 2023-05-05 at 8.45.28 AM.png&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[&#xA;  {&#xA;    &#34;id&#34;: 1,&#xA;    &#34;uuid&#34;: &#34;d2a642e6-c81a-4a43-83e2-22cee3562452&#34;,&#xA;    &#34;display_name&#34;: &#34;Pepe Corp.&#34;,&#xA;    &#34;namespace&#34;: &#34;pepe&#34;,&#xA;    &#34;bot_url&#34;: null,&#xA;    &#34;created_at&#34;: &#34;2023-05-05T10:42:45.933976&#34;,&#xA;    &#34;updated_at&#34;: &#34;2023-05-05T10:42:45.933979&#34;&#xA;  },&#xA;  {&#xA;    &#34;id&#34;: 2,&#xA;    &#34;uuid&#34;: &#34;7d574f88-6c0b-4c1f-9368-367956b0e90f&#34;,&#xA;    &#34;display_name&#34;: &#34;Umbrella Corp&#34;,&#xA;    &#34;namespace&#34;: &#34;acme&#34;,&#xA;    &#34;bot_url&#34;: null,&#xA;    &#34;created_at&#34;: &#34;2023-05-05T10:43:03.555484&#34;,&#xA;    &#34;updated_at&#34;: &#34;2023-05-05T10:43:03.555488&#34;&#xA;  },&#xA;  {&#xA;    &#34;id&#34;: 3,&#xA;    &#34;uuid&#34;: &#34;65105a15-2ef0-4898-ac7a-8eafee0b283d&#34;,&#xA;    &#34;display_name&#34;: &#34;Cyberdine Systems&#34;,&#xA;    &#34;namespace&#34;: &#34;cyberdine&#34;,&#xA;    &#34;bot_url&#34;: null,&#xA;    &#34;created_at&#34;: &#34;2023-05-05T10:43:04.175424&#34;,&#xA;    &#34;updated_at&#34;: &#34;2023-05-05T10:43:04.175428&#34;&#xA;  },&#xA;  {&#xA;    &#34;id&#34;: 4,&#xA;    &#34;uuid&#34;: &#34;b7fb966d-7845-4581-a537-818da62645b5&#34;,&#xA;    &#34;display_name&#34;: &#34;Bluth Companies&#34;,&#xA;    &#34;namespace&#34;: &#34;bluth&#34;,&#xA;    &#34;bot_url&#34;: null,&#xA;    &#34;created_at&#34;: &#34;2023-05-05T10:43:04.697801&#34;,&#xA;    &#34;updated_at&#34;: &#34;2023-05-05T10:43:04.697804&#34;&#xA;  },&#xA;  {&#xA;    &#34;id&#34;: 5,&#xA;    &#34;uuid&#34;: &#34;9283d017-b24b-4ecd-bf35-808b45e258cf&#34;,&#xA;    &#34;display_name&#34;: &#34;Evil Corp&#34;,&#xA;    &#34;namespace&#34;: &#34;evil&#34;,&#xA;    &#34;bot_url&#34;: null,&#xA;    &#34;created_at&#34;: &#34;2023-05-05T10:43:05.102546&#34;,&#xA;    &#34;updated_at&#34;: &#34;2023-05-05T10:43:05.102549&#34;&#xA;  }&#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Project&lt;/h3&gt; &#xA;&lt;p&gt;This can be thought of as a product that belongs to a company. You can view the list of projects that belong to an organizations like so:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/paulpierre/RasaGPT/raw/main/github/org-projects.png?raw=true&#34; alt=&#34;org-projects.png&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[&#xA;  {&#xA;    &#34;id&#34;: 1,&#xA;    &#34;documents&#34;: [&#xA;      {&#xA;        &#34;id&#34;: 1,&#xA;        &#34;uuid&#34;: &#34;92604623-e37c-4935-bf08-0e9efa8b62f7&#34;,&#xA;        &#34;display_name&#34;: &#34;project-pepetamine.md&#34;,&#xA;        &#34;node_count&#34;: 3&#xA;      }&#xA;    ],&#xA;    &#34;document_count&#34;: 1,&#xA;    &#34;uuid&#34;: &#34;44a4b60b-9280-4b21-a676-00612be9aa87&#34;,&#xA;    &#34;display_name&#34;: &#34;Pepetamine&#34;,&#xA;    &#34;created_at&#34;: &#34;2023-05-05T10:42:46.060930&#34;,&#xA;    &#34;updated_at&#34;: &#34;2023-05-05T10:42:46.060934&#34;&#xA;  },&#xA;  {&#xA;    &#34;id&#34;: 2,&#xA;    &#34;documents&#34;: [&#xA;      {&#xA;        &#34;id&#34;: 2,&#xA;        &#34;uuid&#34;: &#34;b408595a-3426-4011-9b9b-8e260b244f74&#34;,&#xA;        &#34;display_name&#34;: &#34;project-frogonil.md&#34;,&#xA;        &#34;node_count&#34;: 3&#xA;      }&#xA;    ],&#xA;    &#34;document_count&#34;: 1,&#xA;    &#34;uuid&#34;: &#34;5ba6b812-de37-451d-83a3-8ccccadabd69&#34;,&#xA;    &#34;display_name&#34;: &#34;Frogonil&#34;,&#xA;    &#34;created_at&#34;: &#34;2023-05-05T10:42:48.043936&#34;,&#xA;    &#34;updated_at&#34;: &#34;2023-05-05T10:42:48.043940&#34;&#xA;  },&#xA;  {&#xA;    &#34;id&#34;: 3,&#xA;    &#34;documents&#34;: [&#xA;      {&#xA;        &#34;id&#34;: 3,&#xA;        &#34;uuid&#34;: &#34;b99d373a-3317-4699-a89e-90897ba00db6&#34;,&#xA;        &#34;display_name&#34;: &#34;project-kekzal.md&#34;,&#xA;        &#34;node_count&#34;: 3&#xA;      }&#xA;    ],&#xA;    &#34;document_count&#34;: 1,&#xA;    &#34;uuid&#34;: &#34;1be4360c-f06e-4494-bf20-e7c73a56f003&#34;,&#xA;    &#34;display_name&#34;: &#34;Kekzal&#34;,&#xA;    &#34;created_at&#34;: &#34;2023-05-05T10:42:49.092675&#34;,&#xA;    &#34;updated_at&#34;: &#34;2023-05-05T10:42:49.092678&#34;&#xA;  },&#xA;  {&#xA;    &#34;id&#34;: 4,&#xA;    &#34;documents&#34;: [&#xA;      {&#xA;        &#34;id&#34;: 4,&#xA;        &#34;uuid&#34;: &#34;94da307b-5993-4ddd-a852-3d8c12f95f3f&#34;,&#xA;        &#34;display_name&#34;: &#34;project-memetrex.md&#34;,&#xA;        &#34;node_count&#34;: 3&#xA;      }&#xA;    ],&#xA;    &#34;document_count&#34;: 1,&#xA;    &#34;uuid&#34;: &#34;1fd7e772-365c-451b-a7eb-4d529b0927f0&#34;,&#xA;    &#34;display_name&#34;: &#34;Memetrex&#34;,&#xA;    &#34;created_at&#34;: &#34;2023-05-05T10:42:50.184817&#34;,&#xA;    &#34;updated_at&#34;: &#34;2023-05-05T10:42:50.184821&#34;&#xA;  },&#xA;  {&#xA;    &#34;id&#34;: 5,&#xA;    &#34;documents&#34;: [&#xA;      {&#xA;        &#34;id&#34;: 5,&#xA;        &#34;uuid&#34;: &#34;6deff180-3e3e-4b09-ae5a-6502d031914a&#34;,&#xA;        &#34;display_name&#34;: &#34;project-pepetrak.md&#34;,&#xA;        &#34;node_count&#34;: 4&#xA;      }&#xA;    ],&#xA;    &#34;document_count&#34;: 1,&#xA;    &#34;uuid&#34;: &#34;a389eb58-b504-48b4-9bc3-d3c93d2fbeaa&#34;,&#xA;    &#34;display_name&#34;: &#34;PepeTrak&#34;,&#xA;    &#34;created_at&#34;: &#34;2023-05-05T10:42:51.293352&#34;,&#xA;    &#34;updated_at&#34;: &#34;2023-05-05T10:42:51.293355&#34;&#xA;  },&#xA;  {&#xA;    &#34;id&#34;: 6,&#xA;    &#34;documents&#34;: [&#xA;      {&#xA;        &#34;id&#34;: 6,&#xA;        &#34;uuid&#34;: &#34;2e3c2155-cafa-4c6b-b7cc-02bb5156715b&#34;,&#xA;        &#34;display_name&#34;: &#34;project-memegen.md&#34;,&#xA;        &#34;node_count&#34;: 5&#xA;      }&#xA;    ],&#xA;    &#34;document_count&#34;: 1,&#xA;    &#34;uuid&#34;: &#34;cec4154f-5d73-41a5-a764-eaf62fc3db2c&#34;,&#xA;    &#34;display_name&#34;: &#34;MemeGen&#34;,&#xA;    &#34;created_at&#34;: &#34;2023-05-05T10:42:52.562037&#34;,&#xA;    &#34;updated_at&#34;: &#34;2023-05-05T10:42:52.562040&#34;&#xA;  },&#xA;  {&#xA;    &#34;id&#34;: 7,&#xA;    &#34;documents&#34;: [&#xA;      {&#xA;        &#34;id&#34;: 7,&#xA;        &#34;uuid&#34;: &#34;baabcb6f-e14c-4d59-a019-ce29973b9f5c&#34;,&#xA;        &#34;display_name&#34;: &#34;project-neurokek.md&#34;,&#xA;        &#34;node_count&#34;: 5&#xA;      }&#xA;    ],&#xA;    &#34;document_count&#34;: 1,&#xA;    &#34;uuid&#34;: &#34;4a1a0542-e314-4ae7-9961-720c2d092f04&#34;,&#xA;    &#34;display_name&#34;: &#34;Neuro-kek&#34;,&#xA;    &#34;created_at&#34;: &#34;2023-05-05T10:42:53.689537&#34;,&#xA;    &#34;updated_at&#34;: &#34;2023-05-05T10:42:53.689539&#34;&#xA;  },&#xA;  {&#xA;    &#34;id&#34;: 8,&#xA;    &#34;documents&#34;: [&#xA;      {&#xA;        &#34;id&#34;: 8,&#xA;        &#34;uuid&#34;: &#34;5be007ec-5c89-4bc4-8bfd-448a3659c03c&#34;,&#xA;        &#34;display_name&#34;: &#34;org-about_the_company.md&#34;,&#xA;        &#34;node_count&#34;: 5&#xA;      },&#xA;      {&#xA;        &#34;id&#34;: 9,&#xA;        &#34;uuid&#34;: &#34;c2b3fb39-18c0-4f3e-9c21-749b86942cba&#34;,&#xA;        &#34;display_name&#34;: &#34;org-board_of_directors.md&#34;,&#xA;        &#34;node_count&#34;: 3&#xA;      },&#xA;      {&#xA;        &#34;id&#34;: 10,&#xA;        &#34;uuid&#34;: &#34;41aa81a9-13a9-4527-a439-c2ac0215593f&#34;,&#xA;        &#34;display_name&#34;: &#34;org-company_story.md&#34;,&#xA;        &#34;node_count&#34;: 4&#xA;      },&#xA;      {&#xA;        &#34;id&#34;: 11,&#xA;        &#34;uuid&#34;: &#34;91c59eb8-8c05-4f1f-b09d-fcd9b44b5a20&#34;,&#xA;        &#34;display_name&#34;: &#34;org-corporate_philosophy.md&#34;,&#xA;        &#34;node_count&#34;: 4&#xA;      },&#xA;      {&#xA;        &#34;id&#34;: 12,&#xA;        &#34;uuid&#34;: &#34;631fc3a9-7f5f-4415-8283-78ff582be483&#34;,&#xA;        &#34;display_name&#34;: &#34;org-customer_support.md&#34;,&#xA;        &#34;node_count&#34;: 3&#xA;      },&#xA;      {&#xA;        &#34;id&#34;: 13,&#xA;        &#34;uuid&#34;: &#34;d4c3d3db-6f24-433e-b2aa-52a70a0af976&#34;,&#xA;        &#34;display_name&#34;: &#34;org-earnings_fy2023.md&#34;,&#xA;        &#34;node_count&#34;: 5&#xA;      },&#xA;      {&#xA;        &#34;id&#34;: 14,&#xA;        &#34;uuid&#34;: &#34;08dd478b-414b-46c4-95c0-4d96e2089e90&#34;,&#xA;        &#34;display_name&#34;: &#34;org-management_team.md&#34;,&#xA;        &#34;node_count&#34;: 3&#xA;      }&#xA;    ],&#xA;    &#34;document_count&#34;: 7,&#xA;    &#34;uuid&#34;: &#34;1d2849b4-2715-4dcf-aa68-090a221942ba&#34;,&#xA;    &#34;display_name&#34;: &#34;Pepe Corp. (company)&#34;,&#xA;    &#34;created_at&#34;: &#34;2023-05-05T10:42:55.258902&#34;,&#xA;    &#34;updated_at&#34;: &#34;2023-05-05T10:42:55.258904&#34;&#xA;  }&#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Document&lt;/h2&gt; &#xA;&lt;p&gt;This can be thought of as an artifact related to a product, like an FAQ page or a PDF with financial statement earnings. You can view all the Documents associated with an Organization‚Äôs Project like so:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/paulpierre/RasaGPT/raw/main/github/documents.png?raw=true&#34; alt=&#34;documents.png&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;{&#xA;  &#34;id&#34;: 1,&#xA;  &#34;uuid&#34;: &#34;44a4b60b-9280-4b21-a676-00612be9aa87&#34;,&#xA;  &#34;organization&#34;: {&#xA;    &#34;id&#34;: 1,&#xA;    &#34;uuid&#34;: &#34;d2a642e6-c81a-4a43-83e2-22cee3562452&#34;,&#xA;    &#34;display_name&#34;: &#34;Pepe Corp.&#34;,&#xA;    &#34;bot_url&#34;: null,&#xA;    &#34;status&#34;: 2,&#xA;    &#34;created_at&#34;: &#34;2023-05-05T10:42:45.933976&#34;,&#xA;    &#34;updated_at&#34;: &#34;2023-05-05T10:42:45.933979&#34;,&#xA;    &#34;namespace&#34;: &#34;pepe&#34;&#xA;  },&#xA;  &#34;document_count&#34;: 1,&#xA;  &#34;documents&#34;: [&#xA;    {&#xA;      &#34;id&#34;: 1,&#xA;      &#34;uuid&#34;: &#34;92604623-e37c-4935-bf08-0e9efa8b62f7&#34;,&#xA;      &#34;organization_id&#34;: 1,&#xA;      &#34;project_id&#34;: 1,&#xA;      &#34;display_name&#34;: &#34;project-pepetamine.md&#34;,&#xA;      &#34;url&#34;: &#34;&#34;,&#xA;      &#34;data&#34;: &#34;# Pepetamine\n\nProduct Name: Pepetamine\n\nPurpose: Increases cognitive focus just like the Limitless movie\n\n**How to Use**\n\nPepetamine is available in the form of rare Pepe-coated tablets. The recommended dosage is one tablet per day, taken orally with a glass of water, preferably while browsing your favorite meme forum for maximum cognitive enhancement. For optimal results, take Pepetamine 30 minutes before engaging in mentally demanding tasks, such as decoding ancient Pepe hieroglyphics or creating your next viral meme masterpiece.\n\n**Side Effects**\n\nSome potential side effects of Pepetamine may include:\n\n1. Uncontrollable laughter and a sudden appreciation for dank memes\n2. An inexplicable desire to collect rare Pepes\n3. Enhanced meme creation skills, potentially leading to internet fame\n4. Temporary green skin pigmentation, resembling the legendary Pepe himself\n5. Spontaneously speaking in \&#34;feels good man\&#34; language\n\nWhile most side effects are generally harmless, consult your memologist if side effects persist or become bothersome.\n\n**Precautions**\n\nBefore taking Pepetamine, please consider the following precautions:\n\n1. Do not use Pepetamine if you have a known allergy to rare Pepes or dank memes.\n2. Pepetamine may not be suitable for individuals with a history of humor deficiency or meme intolerance.\n3. Exercise caution when driving or operating heavy machinery, as Pepetamine may cause sudden fits of laughter or intense meme ideation.\n\n**Interactions**\n\nPepetamine may interact with other substances, including:\n\n1. Normie supplements: Combining Pepetamine with normie supplements may result in meme conflicts and a decreased sense of humor.\n2. Caffeine: The combination of Pepetamine and caffeine may cause an overload of energy, resulting in hyperactive meme creation and potential internet overload.\n\nConsult your memologist if you are taking any other medications or substances to ensure compatibility with Pepetamine.\n\n**Overdose**\n\nIn case of an overdose, symptoms may include:\n\n1. Uncontrollable meme creation\n2. Delusions of grandeur as the ultimate meme lord\n3. Time warps into the world of Pepe\n\nIf you suspect an overdose, contact your local meme emergency service or visit the nearest meme treatment facility. Remember, the key to enjoying Pepetamine is to use it responsibly, and always keep in mind the wise words of our legendary Pepe: \&#34;Feels good man.\&#34;&#34;,&#xA;      &#34;hash&#34;: &#34;fdee6da2b5441080dd78e7850d3d2e1403bae71b9e0526b9dcae4c0782d95a78&#34;,&#xA;      &#34;version&#34;: 1,&#xA;      &#34;status&#34;: 2,&#xA;      &#34;created_at&#34;: &#34;2023-05-05T10:42:46.755428&#34;,&#xA;      &#34;updated_at&#34;: &#34;2023-05-05T10:42:46.755431&#34;&#xA;    }&#xA;  ],&#xA;  &#34;display_name&#34;: &#34;Pepetamine&#34;,&#xA;  &#34;created_at&#34;: &#34;2023-05-05T10:42:46.060930&#34;,&#xA;  &#34;updated_at&#34;: &#34;2023-05-05T10:42:46.060934&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Node&lt;/h2&gt; &#xA;&lt;p&gt;Although this is not exposed in the API, a node is a chunk of a document which embeddings get generated for. Nodes are used for retrieval search as well as context injection. A node belongs to a document.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;User&lt;/h2&gt; &#xA;&lt;p&gt;A user represents the person talking to a bot. Users do not necessarily belong to an org or product, but this relationship is captured in ChatSession below.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;ChatSession&lt;/h2&gt; &#xA;&lt;p&gt;Not exposed via API, but this represent a question and answer between the User and a bot. Each of these objects can be flexibly identified by a &lt;code&gt;session_id&lt;/code&gt; which gets automatically generated. Chat Sessions contain rich metadata that can be used for training and optimization. ChatSessions via the &lt;code&gt;/chat&lt;/code&gt; endpoint ARE in fact associated with organization (for multi-tenant security purposes)&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;strong&gt;üìö&amp;nbsp;How it works&lt;/strong&gt;&lt;/h1&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Rasa&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Rasa handles integration with the communication channel, in this case Telegram. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;It specifically handles submitting the target webhook user feedback should go through. In our case it is our FastAPI server via &lt;code&gt;/webhooks/{channel}/webhook&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Rasa has two components, the core&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/tree/main/app/rasa&#34;&gt;Rasa app&lt;/a&gt;&amp;nbsp;and an Rasa&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/tree/main/app/rasa/actions&#34;&gt;actions server&lt;/a&gt;&amp;nbsp;that runs separately&lt;/li&gt; &#xA; &lt;li&gt;Rasa must be configured (done already) via a few yaml files: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/rasa/config.yml&#34;&gt;config.yml&lt;/a&gt;&amp;nbsp;- contains NLU pipeline and policy configuration. What matters is setting the&amp;nbsp;&lt;code&gt;FallbackClassifier&lt;/code&gt;&amp;nbsp;threshold&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/rasa/credentials.yml&#34;&gt;credentials.yml&lt;/a&gt;&amp;nbsp;- contains the path to our webhook and Telegram credentials. This will get updated by the helper service&amp;nbsp;&lt;code&gt;rasa-credentials&lt;/code&gt;&amp;nbsp;via&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/rasa-credentials/main.py&#34;&gt;app/rasa-credentials/main.py&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/rasa/domain.yml&#34;&gt;domain.yml&lt;/a&gt;&amp;nbsp;- This contains the chat entrypoint logic configuration like intent and the action to take against the intent. Here we add the&amp;nbsp;&lt;code&gt;action_gpt_fallback&lt;/code&gt;&amp;nbsp;action which will trigger our&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/tree/main/app/rasa/actions&#34;&gt;actions server&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/rasa/endpoints.yml&#34;&gt;endpoints.yml&lt;/a&gt;&amp;nbsp;- This is where we set our custom action end-point for Rasa to trigger our fallback&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/rasa/data/nlu.yml&#34;&gt;nlu.yml&lt;/a&gt;&amp;nbsp;- this is where we set our intent&amp;nbsp;&lt;code&gt;out_of_scope&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/rasa/data/rules.yml&#34;&gt;rules.yml&lt;/a&gt;&amp;nbsp;- we set a rule for this intent that it should trigger the action&amp;nbsp;&lt;code&gt;action_gpt_fallback&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/rasa/actions/actions.py&#34;&gt;actions.py&lt;/a&gt;&amp;nbsp;- this is where we define and express our action via the&amp;nbsp;&lt;code&gt;ActionGPTFallback&lt;/code&gt;&amp;nbsp;class. The method&amp;nbsp;&lt;code&gt;name&lt;/code&gt;&amp;nbsp;returns the action we defined for our intent above&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Rasa&#39;s NLU models must be trained which can be done via CLI with&amp;nbsp;&lt;code&gt;rasa train&lt;/code&gt;&amp;nbsp;. This is done automatically for you when you run&amp;nbsp;&lt;code&gt;make install&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Rasa&#39;s core must be ran via&amp;nbsp;&lt;code&gt;rasa run&lt;/code&gt;&amp;nbsp;after training&lt;/li&gt; &#xA; &lt;li&gt;Rasa&#39;s action server must be ran separately with&amp;nbsp;&lt;code&gt;rasa run actions&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Telegram&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Rasa automatically updates the Telegram Bot API with your callback webhook from&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/rasa/credentials.yml&#34;&gt;credentials.yml&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;By default this is static. Since we are running on our local machine, we leverage&amp;nbsp;&lt;a href=&#34;https://ngrok.com/&#34;&gt;Ngrok&lt;/a&gt;&amp;nbsp;to generate a publically accessible URL and reverse tunnel into our docker container&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;rasa-credentials&lt;/code&gt;&amp;nbsp;service takes care of this process for you. Ngrok runs as a service, once it is ready&amp;nbsp;&lt;code&gt;rasa-credentials&lt;/code&gt;&amp;nbsp;calls the local ngrok API to retrieve the tunnel URL and updates the&amp;nbsp;&lt;code&gt;credentials.yml&lt;/code&gt;&amp;nbsp;file and restarts Rasa for you&lt;/li&gt; &#xA; &lt;li&gt;The webhook Telegram will send messages to will be our FastAPI server. Why this instead of Rasa? Because we want flexibility to capture metadata which Rasa makes a PITA and centralizing to the API server is ideal&lt;/li&gt; &#xA; &lt;li&gt;The FastAPI server forwards this to the Rasa webhook&lt;/li&gt; &#xA; &lt;li&gt;Rasa will then determine what action to take based on the user intent. Since the intents have been nerfed for this demo, it will go to the fallback action running in &lt;code&gt;actions.py&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;The custom action will capture the metadata and forward the response from FastAPI to the user&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;PGVector&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;pgvector&lt;/code&gt;&amp;nbsp;is a plugin for Postgres and automatically installed enabling your to store and calculate vector data types. We have our own implementation because the Langchain PGVector class is not flexible to adapt to our schema and we want flexibility.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;By default in postgres, any files in the container&#39;s path&amp;nbsp;&lt;code&gt;/docker-entry-initdb.d&lt;/code&gt;&amp;nbsp;get run if the database has not been initialized. In the&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/db/Dockerfile&#34;&gt;postgres Dockerfile&lt;/a&gt;&amp;nbsp;we copy&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/db/create_db.sh&#34;&gt;&lt;code&gt;create_db.sh&lt;/code&gt;&amp;nbsp;which creates&lt;/a&gt;&amp;nbsp;the db and user for our database&lt;/li&gt; &#xA; &lt;li&gt;In the&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/dca9be4cd6fe4c9daaff1564267cdb5327a384a5/Makefile#L64&#34;&gt;&lt;code&gt;models&lt;/code&gt;&amp;nbsp;command&lt;/a&gt;&amp;nbsp;in the&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/Makefile&#34;&gt;Makefile&lt;/a&gt;, we run the&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/api/models.py&#34;&gt;models.py&lt;/a&gt;&amp;nbsp;in the API container which creates the tables from the models.&lt;/li&gt; &#xA; &lt;li&gt;The&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/dca9be4cd6fe4c9daaff1564267cdb5327a384a5/app/api/models.py#L266&#34;&gt;&lt;code&gt;enable_vector&lt;/code&gt;&amp;nbsp;method&lt;/a&gt;&amp;nbsp;enables the pgvector extension in the database&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Langchain&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The training data gets loaded in the database&lt;/li&gt; &#xA; &lt;li&gt;The data is indexed&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/dca9be4cd6fe4c9daaff1564267cdb5327a384a5/app/api/main.py#L49&#34;&gt;if the index doesn&#39;t exist&lt;/a&gt;&amp;nbsp;and&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/api/index.json&#34;&gt;stored in a file named&amp;nbsp;&lt;code&gt;index.json&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;LlamaIndex uses a basic&amp;nbsp;&lt;code&gt;GPTSimpleVectorIndex&lt;/code&gt;&amp;nbsp;to find the relevant data and&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/dca9be4cd6fe4c9daaff1564267cdb5327a384a5/app/api/main.py#L66&#34;&gt;injects it into a prompt&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Guard rails via prompts are used to keep the conversation focused&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Bot flow&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The user will chat in Telegram and the message will be filtered for&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/rasa/data/nlu.yml&#34;&gt;existing intents&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;If it detects there is no intent match but instead matches the&amp;nbsp;&lt;code&gt;out_of_scope&lt;/code&gt;,&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/rasa/data/rules.yml&#34;&gt;based on rules.yml&lt;/a&gt;&amp;nbsp;it will trigger the&amp;nbsp;&lt;code&gt;action_gpt_fallback&lt;/code&gt;&amp;nbsp;action&lt;/li&gt; &#xA; &lt;li&gt;The&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/rasa/actions/actions.py&#34;&gt;&lt;code&gt;ActionGPTFallback&lt;/code&gt;&amp;nbsp;function&lt;/a&gt;&amp;nbsp;will then call the&amp;nbsp;&lt;a href=&#34;https://github.com/paulpierre/RasaGPT/raw/main/app/api/main.py&#34;&gt;FastAPI API server&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;the API using LlamaIndex will find the relevant indexed content and inject it into a prompt to send to OpenAI for inference&lt;/li&gt; &#xA; &lt;li&gt;The prompt contains conversational guardrails including: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Requests data be returned in JSON&lt;/li&gt; &#xA;   &lt;li&gt;Create categorical tags based on what the user&#39;s question&lt;/li&gt; &#xA;   &lt;li&gt;Return a boolean if the conversation should be escalated to a human (if there is no context match)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üìù&amp;nbsp;TODO&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Write tests üòÖ&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Implement LlamaIndex optimizations&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Implement chat history&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Implement &lt;a href=&#34;https://medium.com/@jerryjliu98/unifying-llm-powered-qa-techniques-with-routing-abstractions-438e2499a0d0&#34;&gt;Query Routers Abstractions&lt;/a&gt; to understand which search strategy to use (one-shot vs few-shot)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Explore other indexing methods like Tree indexes, Keyword indexes&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add chat history for immediate recall and context setting&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add a secondary adversarial agent (&lt;a href=&#34;https://simonwillison.net/2023/Apr/25/dual-llm-pattern/&#34;&gt;Dual pattern model&lt;/a&gt;) with the following potential functionalities: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Determine if the question has been answered and if not, re-optimize search strategy&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Ensure prompt injection is not occurring&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Increase baseline similarity search by exploring: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Regularly generate ‚Äúfake‚Äù document embeddings based on historical queries and link to actual documents via &lt;a href=&#34;https://wfhbrian.com/revolutionizing-search-how-hypothetical-document-embeddings-hyde-can-save-time-and-increase-productivity/&#34;&gt;HyDE pattern&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Regularly generate ‚Äúfake‚Äù user queries based on documents and link to actual document so user input search and ‚Äúfake‚Äù queries can match better&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üîç&amp;nbsp;Troubleshooting&lt;/h1&gt; &#xA;&lt;p&gt;In general, check your docker container logs by simply going to üëâ&amp;nbsp;&lt;a href=&#34;http://localhost:9999/&#34;&gt;http://localhost:9999/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Ngrok issues&lt;/h2&gt; &#xA;&lt;p&gt;Always check that your webhooks with ngrok and Telegram match. Simply do this by&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -sS &#34;https://api.telegram.org/bot&amp;lt;your-bot-secret-token&amp;gt;/getWebhookInfo&#34; | json_pp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;.. should return this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;{&#xA;    &#34;ok&#34;: true,&#xA;    &#34;result&#34;: {&#xA;        &#34;url&#34;: &#34;https://b280-04-115-40-112.ngrok-free.app/webhooks/telegram/webhook&#34;,&#xA;        &#34;has_custom_certificate&#34;: false,&#xA;        &#34;pending_update_count&#34;: 0,&#xA;        &#34;max_connections&#34;: 40,&#xA;        &#34;ip_address&#34;: &#34;1.2.3.4&#34;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;.. which should match the URL in your &lt;code&gt;credentials.yml&lt;/code&gt; file or visit the Ngrok admin UI üëâ&amp;nbsp;&lt;a href=&#34;http://localhost:4040/status&#34;&gt;http://localhost:4040/status&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/paulpierre/RasaGPT/raw/main/github/ngrok-admin.png?raw=true&#34; alt=&#34;ngrok-admin.png&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Looks like it is a match. If not, restart everything by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make restart&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üí™&amp;nbsp;Contributing / Issues&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Pull requests welcome&lt;/li&gt; &#xA; &lt;li&gt;Please submit issues via Github, I will do my best to resolve them&lt;/li&gt; &#xA; &lt;li&gt;If you want to get in touch, feel free to hmu on twitter via &lt;a href=&#34;https://twitter.com/paulpierre&#34;&gt;&lt;code&gt;@paulpierre&lt;/code&gt;&lt;/a&gt;`&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://camo.githubusercontent.com/bcb43227c1e90a1d27996eb75ac794bbf20d1355b36d0e9eaa71c71ad4dd2a56/68747470733a2f2f6d65646961342e67697068792e636f6d2f6d656469612f313149537762674378457a4d79592f67697068792e6769663f6369643d65636630356534376664703164727a72766178733175787532666269376f72316e68626f6d39326d30346436306e786b2665703d76315f676966735f72656c61746564267269643d67697068792e6769662663743d67&#34; alt=&#34;thumbsup&#34;&gt; &lt;br&gt; Congratulations, all your base are belong to us! kthxbye&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üìú&amp;nbsp;Open source license&lt;/h1&gt; &#xA;&lt;p&gt;Copyright (c) 2023 Paul Pierre. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>kemomi/daimai</title>
    <updated>2023-05-13T01:41:03Z</updated>
    <id>tag:github.com,2023-05-13:/kemomi/daimai</id>
    <link href="https://github.com/kemomi/daimai" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Â§ßÈ∫¶ÁΩëÊºîÂî±‰ºöÊä¢Á•®ËÑöÊú¨&lt;/p&gt;&lt;hr&gt;&lt;h3&gt;Êõ¥Êñ∞&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/kemomi/daimai/raw/main/O1CN01QtSzD62GdSE1msrJp_!!2251059038.jpg&#34; alt=&#34;logo&#34;&gt;&#xA; &lt;br&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;ÊèêÂâçÂáÜÂ§á&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.6.3&lt;/li&gt; &#xA; &lt;li&gt;Chromedriver.exe&lt;/li&gt; &#xA; &lt;li&gt;Chrome ÊµèËßàÂô®ÂÆâË£ÖÂ•ΩÂêéÈúÄÂ∞Üchromedriver.exeÊîæÁΩÆ‰∫éChromeÊµèËßàÂô®ÁõÆÂΩï‰∏ã&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;pip install selenium requests lxml&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ÂèÇÊï∞ËÆæÁΩÆ&lt;/h3&gt; &#xA;&lt;p&gt;Âú®&lt;code&gt;config.json&lt;/code&gt;‰∏≠ËæìÂÖ•Áõ∏Â∫îÈÖçÁΩÆ‰ø°ÊÅØÔºåÂÖ∑‰ΩìËØ¥ÊòéÂ¶Ç‰∏ãÔºö&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;date&lt;/code&gt;: Êó•ÊúüÈÄâÊã©&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;sess&lt;/code&gt;: Âú∫Ê¨°‰ºòÂÖàÁ∫ßÂàóË°®&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;price&lt;/code&gt;: Á•®‰ª∑‰ºòÂÖàÁ∫ßÔºåÂ¶ÇÊú¨‰æã‰∏≠ÂÖ±Êúâ‰∏âÊ°£Á•®‰ª∑ÔºåÊ†πÊçÆ‰∏ãË°®ÔºåÂàô‰ºòÂÖàÈÄâÊã©1ÔºåÂÜçÈÄâÊã©3Ôºõ‰πüÂèØ‰ª•‰ªÖËÆæÁΩÆ1‰∏™„ÄÇ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;real_name&lt;/code&gt;: [1,2], ÂÆûÂêçËÄÖÂ∫èÂè∑ÔºåÊ†πÊçÆÂ∫èÂè∑ÂÖ±ÈÄâÊã©‰∏§‰ΩçÂÆûÂêçËÄÖÔºåÊ†πÊçÆÂ∫èÂè∑Ôºå‰πüÂèØ‰ªÖÈÄâÊã©‰∏Ä‰Ωç&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;pre&gt;&lt;code&gt;#ÈÄâÊã©‰∏Ä‰ΩçÊàñÊòØÂ§ö‰ΩçÊ†πÊçÆË¥≠Á•®ÈúÄÁü•Ë¶ÅÊ±Ç:Ëã•Êó†ÈúÄÂÆûÂêçÂà∂‰ø°ÊÅØÂàô‰∏çÈúÄË¶ÅÂ°´ÂÜô;Ëã•‰∏Ä‰∏™ËÆ¢Âçï‰ªÖÈúÄÊèê‰æõ‰∏Ä‰ΩçË¥≠Á•®‰∫∫‰ø°ÊÅØÂàôÈÄâÊã©‰∏Ä‰Ωç;Ëã•‰∏ÄÂº†Èó®Á•®ÂØπÂ∫î‰∏Ä‰ΩçË¥≠Á•®‰∫∫‰ø°ÊÅØÂàôÈÄâÊã©Â§ö‰Ωç„ÄÇ&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;driver_path&lt;/code&gt;:ÊµèËßàÂô®È©±Âä®Âú∞ÂùÄ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;nick_name&lt;/code&gt;: Áî®Êà∑Âú®Â§ßÈ∫¶ÁΩëÁöÑÊòµÁß∞ÔºåÁî®‰∫éÈ™åËØÅÁôªÂΩïÊòØÂê¶ÊàêÂäü&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;ticket_num&lt;/code&gt;: Ë¥≠‰π∞Á•®Êï∞&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;damai_url&lt;/code&gt;: &lt;a href=&#34;https://www.damai.cn&#34;&gt;https://www.damai.cn&lt;/a&gt;, Â§ßÈ∫¶ÁΩëÂÆòÁΩëÁΩëÂùÄ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;target_url&lt;/code&gt;: &lt;a href=&#34;https://detail.damai.cn/item.htm?id=607865020360&#34;&gt;https://detail.damai.cn/item.htm?id=607865020360&lt;/a&gt; ÁõÆÊ†áÔºå‰æãÂ¶ÇÔºö&lt;a href=&#34;https://detail.damai.cn/item.htm?id=607865020360&#34;&gt;Âë®Êù∞‰º¶2023ÂòâÂπ¥Âçé‰∏ñÁïåÂ∑°ÂõûÊºîÂî±‰ºö--Êµ∑Âè£Á´ô&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ÈÉ®ÂàÜÈó®Á•®ÈúÄË¶ÅÈÄâÊã©ÂüéÂ∏ÇÔºåÂè™ÈúÄÈÄâÊã©Áõ∏Â∫îÂüéÂ∏ÇÂêéÂ∞ÜÂÖ∂ÁΩëÂùÄÂ§çÂà∂Âà∞config.jsonÊñá‰ª∂ÁöÑ&lt;code&gt;target_url&lt;/code&gt;ÂèÇÊï∞„ÄÇ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Ê†πÊçÆÈúÄË¶ÅÈÄâÊã©ÁöÑÂú∫Ê¨°ÂíåÁ•®‰ª∑ÂàÜÂà´‰øÆÊîπconfig.jsonÊñá‰ª∂‰∏≠ÁöÑ&lt;code&gt;sess&lt;/code&gt;Âíå&lt;code&gt;price&lt;/code&gt;ÂèÇÊï∞„ÄÇ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Êü•ÁúãË¥≠Á•®È°ªÁü•‰∏≠ÂÆûÂêçÂà∂‰∏ÄÊ†èÔºåËã•Êó†ÈúÄÂÆûÂêçÂà∂Âàôconfig.jsonÊñá‰ª∂‰∏≠ÁöÑ&lt;code&gt;real_name&lt;/code&gt;ÂèÇÊï∞‰∏çÈúÄË¶ÅÂ°´ÂÜôÔºàÂç≥‰∏∫[]ÔºâÔºõËã•ÊØèÁ¨îËÆ¢ÂçïÂè™ÈúÄ‰∏Ä‰∏™ËØÅ‰ª∂Âè∑Âàô&lt;code&gt;real_name&lt;/code&gt;ÂèÇÊï∞Âè™ÈúÄÈÄâÊã©‰∏Ä‰∏™ÔºõËã•ÊØèÂº†Èó®Á•®ÈúÄË¶Å‰∏Ä‰∏™ËØÅ‰ª∂Âè∑ÔºåÂàôreal_nameÂèÇÊï∞Ê†πÊçÆÈúÄË¥≠Á•®Êï∞ÈáèËøõË°åÁõ∏Â∫îÊ∑ªÂä†„ÄÇ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Ëã•ÊòØÈ¶ñÊ¨°ÁôªÂΩïÔºåÊ†πÊçÆÁªàÁ´ØËæìÂá∫ÁöÑÊèêÁ§∫Ôºå‰æùÊ¨°ÁÇπÂáªÁôªÂΩï„ÄÅÊâ´Á†ÅÁôªÂΩïÔºå‰ª£Á†ÅÂ∞ÜËá™Âä®‰øùÂ≠òcookieÊñá‰ª∂Ôºàcookie.pklÔºâ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;‰ΩøÁî®ÂâçËØ∑Â∞ÜÂæÖÊä¢Á•®ËÄÖÁöÑÂßìÂêç„ÄÅÊâãÊú∫„ÄÅÂú∞ÂùÄËÆæ‰∏∫ÈªòËÆ§„ÄÇ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ÈÖçÁΩÆÂÆåÊàêÂêéÊâßË°å&lt;code&gt;python damai_ticket.py&lt;/code&gt;Âç≥ÂèØ,Ê≥®ÊÑèËßÇÂØüÊéßÂà∂Âè∞ËæìÂá∫„ÄÇ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Êú¨‰ª£Á†Å‰∏∫‰øùËØÅÊä¢Á•®È°∫Âà©ÔºåËÆæÁΩÆÂæ™ÁéØÁõ¥Âà∞Êä¢Á•®ÊàêÂäüÊâçÈÄÄÂá∫Âæ™ÁéØÔºåËã•‰∏≠ÈÄîÈúÄË¶ÅÈÄÄÂá∫Á®ãÂ∫èËØ∑Áõ¥Êé•ÁªàÊ≠¢Á®ãÂ∫è„ÄÇ&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ÁÉ≠Èó®ÊºîÂî±‰ºö‰ø°ÊÅØ&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://detail.damai.cn/item.htm?spm=a2oeg.search_category.searchtxt.ditem_0.f4294d15c5tGAZ&amp;amp;id=611160757855&#34;&gt;Âë®Êù∞‰º¶ÊºîÂî±‰ºö-Â§©Ê¥•&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://detail.damai.cn/item.htm?id=607865020360&#34;&gt;Âë®Êù∞‰º¶ÊºîÂî±‰ºö-Êµ∑Âè£&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://detail.damai.cn/item.htm?id=704967827554&#34;&gt;Âë®Êù∞‰º¶ÊºîÂî±‰ºö-ÂëºÂíåÊµ©Áâπ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://detail.damai.cn/item.htm?id=704762591363&#34;&gt;Âë®Êù∞‰º¶ÊºîÂî±‰ºö-Â§™Âéü&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>IBM/Dromedary</title>
    <updated>2023-05-13T01:41:03Z</updated>
    <id>tag:github.com,2023-05-13:/IBM/Dromedary</id>
    <link href="https://github.com/IBM/Dromedary" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Dromedary: towards helpful, ethical and reliable LLMs.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/IBM/Dromedary/main/assets/images/dromedary_logo_with_text.svg?sanitize=true&#34; alt=&#34;Dromedary Logo&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;!-- # Dromedary --&gt; &#xA; &lt;h2&gt;Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision&lt;/h2&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/Dromedary/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Code%20License-GPL_3.0-green.svg?sanitize=true&#34; alt=&#34;Code License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/IBM/Dromedary/main/DATA_LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg?sanitize=true&#34; alt=&#34;Data License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;Dromedary is an open-source self-aligned language model trained with minimal human supervision. For comprehensive details and insights, we kindly direct you to our &lt;a href=&#34;https://github.com/IBM/Dromedary&#34;&gt;project page&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2305.03047&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/IBM/Dromedary/main/assets/images/self_align_pipeline.png&#34; alt=&#34;Dromedary Pipeline&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;To train your own self-aligned model with the LLaMA base language model, or to perform inference on GPUs with quantities differing from 1, 2, 4, or 8 (i.e., any power of 2), you should install our customized &lt;a href=&#34;https://raw.githubusercontent.com/IBM/Dromedary/main/llama_dromedary&#34;&gt;&lt;code&gt;llama_dromedary&lt;/code&gt;&lt;/a&gt; package.&lt;/p&gt; &#xA;&lt;p&gt;In a conda env with pytorch / cuda available, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd llama_dromedary&#xA;pip install -r requirements.txt&#xA;pip install -e .&#xA;cd ..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Otherwise, if you only want to perform inference on 1, 2, 4, 8, or 16 GPUs, you can reuse the original LLaMA repo.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/facebookresearch/llama.git&#xA;cd llama&#xA;pip install -r requirements.txt&#xA;pip install -e .&#xA;cd ..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In addition, you should at least install the packages required for inference:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd inference&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Model Weights&lt;/h2&gt; &#xA;&lt;p&gt;We release Dromedary weights as delta weights to comply with the LLaMA model license. You can add our delta to the original LLaMA weights to obtain the Dromedary weights. Instructions:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Get the original LLaMA weights in the Hugging Face format by following the instructions &lt;a href=&#34;https://huggingface.co/docs/transformers/main/model_doc/llama&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Download the LoRA delta weights from our Hugging Face &lt;a href=&#34;https://huggingface.co/zhiqings/dromedary-65b-lora-delta-v0&#34;&gt;model hub&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Follow our &lt;a href=&#34;https://raw.githubusercontent.com/IBM/Dromedary/main/inference&#34;&gt;inference guide&lt;/a&gt; to see how to deploy Dromedary/LLaMA on your own machine with &lt;a href=&#34;https://github.com/facebookresearch/fairscale/tree/main/fairscale/nn/model_parallel&#34;&gt;model parallel&lt;/a&gt; (which should be significantly faster than Hugging Face&#39;s default pipeline parallel when using multiple GPUs).&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;p&gt;We provide a &lt;a href=&#34;https://raw.githubusercontent.com/IBM/Dromedary/main/inference&#34;&gt;chatbot demo&lt;/a&gt; for Dromedary.&lt;/p&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;We provide the full &lt;a href=&#34;https://raw.githubusercontent.com/IBM/Dromedary/main/training&#34;&gt;training pipeline&lt;/a&gt; of Dromedary for reproduction.&lt;/p&gt; &#xA;&lt;h2&gt;Prompts&lt;/h2&gt; &#xA;&lt;p&gt;All the human annotations used in this project can be found &lt;a href=&#34;https://raw.githubusercontent.com/IBM/Dromedary/main/prompts&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;TODOs&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add the requirements.txt for the training pipeline.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add the evaluation code for TruthfulQA and HHH Eval.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Release Dromedary delta weights at Hugging Face model hub.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add support for Hugging Face native pipeline in the released model hub.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Release the synthetic training data of Dromedary.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add support for stream inference in the chatbot demo.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Fix the Hugging Face datasets/accelerate bug of fine-tuning in distributed setting.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Citation&lt;/h3&gt; &#xA;&lt;p&gt;Please cite the following paper if you use the data or code in this repo.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{sun2023principledriven,&#xA;      title={Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision},&#xA;      author={Zhiqing Sun and Yikang Shen and Qinhong Zhou and Hongxin Zhang and Zhenfang Chen and David Cox and Yiming Yang and Chuang Gan},&#xA;      year={2023},&#xA;      eprint={2305.03047},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.LG}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Acknowledgements&lt;/h3&gt; &#xA;&lt;p&gt;We thank Yizhong Wang for providing the code for the parse analysis plot. We also thank &lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;Meta LLaMA team&lt;/a&gt;, &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Standford Alpaca team&lt;/a&gt;, &lt;a href=&#34;https://github.com/lm-sys/FastChat&#34;&gt;Vicuna team&lt;/a&gt;, &lt;a href=&#34;https://github.com/tloen/alpaca-lora&#34;&gt;Alpaca-LoRA&lt;/a&gt;, and &lt;a href=&#34;https://github.com/huggingface/peft&#34;&gt;Hugging Face PEFT&lt;/a&gt; for their open-source efforts in democratizing large language models.&lt;/p&gt;</summary>
  </entry>
</feed>