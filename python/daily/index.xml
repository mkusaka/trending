<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-15T01:37:36Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>disler/multi-agent-postgres-data-analytics</title>
    <updated>2023-11-15T01:37:36Z</updated>
    <id>tag:github.com,2023-11-15:/disler/multi-agent-postgres-data-analytics</id>
    <link href="https://github.com/disler/multi-agent-postgres-data-analytics" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The way we interact with our data is changing.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Multi-Agent Postgres Data Analytics&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;The way we interact with our data is changing.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/multi-agent-coding.png&#34; alt=&#34;Multi-Agent Postgres Data Analytics&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üí¨ Read This First üí¨&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;This repo is an &lt;strong&gt;&lt;em&gt;experiment&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;learning tool&lt;/em&gt;&lt;/strong&gt; for building multi-agent systems.&lt;/p&gt; &#xA; &lt;p&gt;It is &lt;strong&gt;ONE&lt;/strong&gt; of &lt;strong&gt;MANY&lt;/strong&gt; steps toward building fully autonomous, &lt;em&gt;agentic software&lt;/em&gt;.&lt;/p&gt; &#xA; &lt;p&gt;It is &lt;strong&gt;NOT&lt;/strong&gt; a framework, or library, or shortcut.&lt;/p&gt; &#xA; &lt;p&gt;It &lt;strong&gt;IS&lt;/strong&gt; a &lt;strong&gt;&lt;em&gt;stepping stone&lt;/em&gt;&lt;/strong&gt; to help you internalize concepts, patterns and building blocks for your own multi-agent systems and applications.&lt;/p&gt; &#xA; &lt;p&gt;Code only tells a story at a moment in time. I highly recommend you watch the &lt;a href=&#34;https://www.youtube.com/playlist?list=PLS_o2ayVCKvDzj2YxeFqMq9UbR1PkPEh0&#34;&gt;video series&lt;/a&gt; to see the &lt;strong&gt;how and the why&lt;/strong&gt; behind the structure of this experimental codebase.&lt;/p&gt; &#xA; &lt;p&gt;In the series we build this from scratch and dive deep into complexities, principles, patterns and ideas surrounding multi-agent software. The video order is linked below, mapping branches to videos.&lt;/p&gt; &#xA; &lt;p&gt;This repo will not be maintained or updated beyond the lifespan of the series. It is a snapshot in time of the code we built in the video series and is meant only to be a reference for you on your journey to building your own multi-agent systems, &lt;strong&gt;&lt;em&gt;nothing more&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA; &lt;p&gt;When we complete the series will we freeze the codebase. We will then use it as a reference for experiments, products, and videos.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;üíª Multi-Agent Postgres Data Analytics Tool üíª&lt;/h2&gt; &#xA;&lt;p&gt;This is a multi-agent system that allows you to ask questions about your postgres database in natural language.&lt;/p&gt; &#xA;&lt;p&gt;The codebase is powered by GPT-4, Assistance API, AutoGen, Postgres, and Guidance.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s the first of many multi-agent applications that utilize LLMs (large language models) to enable reasoning and decision making with reduced need for explicit rules or logic.&lt;/p&gt; &#xA;&lt;h2&gt;üíª Setup üíª&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Read the codebase first&lt;/strong&gt;. Remember, this is an experiment and learning tool. It&#39;s not meant to be a framework or library.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;git branch -a&lt;/code&gt; to view all branches. Each branch is a video in the series. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;git checkout &amp;lt;branch-name&amp;gt;&lt;/code&gt; you want to view.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;poetry install&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;cp .env.sample .env&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Fill out &lt;code&gt;.env&lt;/code&gt; with your postgres url and openai api key&lt;/li&gt; &#xA; &lt;li&gt;Run a prompt against your database &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;poetry run start --prompt &#34;&amp;lt;ask your agent a question about your postgres database&amp;gt;&#34;&lt;/code&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Start with something simple to get a feel for it and then build up to more complex questions.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üõ†Ô∏è Core Tech Stack üõ†Ô∏è&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openai.com/&#34;&gt;OpenAI&lt;/a&gt; - GPT-4, GPT-4 Turbo, Assistance API&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://microsoft.github.io/autogen/&#34;&gt;AutoGen&lt;/a&gt; - Multi-Agent Framework&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/&#34;&gt;Postgres&lt;/a&gt; - Database&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/guidance-ai/guidance&#34;&gt;Guidance&lt;/a&gt; - Structured LLM Responses&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aider.chat/&#34;&gt;Aider&lt;/a&gt; - AI Pair Programming&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://python-poetry.org/&#34;&gt;Poetry&lt;/a&gt; - Package Manager&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.python.org/downloads/release/python-3100/&#34;&gt;Python ^3.10&lt;/a&gt; - Programming Language&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üîµ Multi-Agent Patterns &amp;amp; Terminology üîµ&lt;/h2&gt; &#xA;&lt;p&gt;Throughout the codebase we built up several existing and new patterns and terminology you&#39;ve likely seen in some shape or form. Here&#39;s a quick overview of the most important ones.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Agent&lt;/strong&gt; - An agent is LLM powered tool with a single purpose that can be assigned a function and/or prompt.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi-Agent Team&lt;/strong&gt; - A collection of agents that exchange messages and work together to accomplish a goal.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Conversations&lt;/strong&gt; - The exchange of messages between a multi-agent team.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Conversation Flows&lt;/strong&gt; - The way agents communicate with each other. How you&#39;re agents communicate completely changes the way your application works. The conversation flow dictates which agent speaks, the order in which they speak, who they speak to and what they say.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Orchestrator&lt;/strong&gt; - Manages a single agent team, their conversations and their output. Orchestrators contain different types of conversation flows.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Instruments&lt;/strong&gt; - Instruments are the tools agents can use. Think of it like a front-end store. It contains state and functions that both agents and orchestrators can utilize throughout the lifecycle of the application. Agents and Orchestrators can consume and manipulate the state of instruments although typically, only agents update state.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Decision Agents&lt;/strong&gt; - Agents that respond with concrete decisions which can dictate the flow of your applications. To build complex agentic systems you need agents to have the ability to make concrete decisions that then drive the flow of your application.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Structured vs Unstructured Agents&lt;/strong&gt; - Structured agents are agents that respond with structured data. Unstructured agents are agents that respond with unstructured data. Structured agents are typically decision agents.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üì∫ Video Series - Learn By Watching üì∫&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://youtu.be/jmDMusirPKA&#34;&gt;Part 1 - Prompt Engineering an ENTIRE codebase: Postgres Data Analytics Al Agent&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Branch: &lt;a href=&#34;https://github.com/disler/multi-agent-postgres-data-analytics/tree/v1-prompt-engineering-an-entire-codebase&#34;&gt;v1-prompt-engineering-an-entire-codebase&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Video: &lt;a href=&#34;https://youtu.be/jmDMusirPKA&#34;&gt;https://youtu.be/jmDMusirPKA&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/1-prompt-engineering-postgres-ai-data-analytics-agent.png&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://youtu.be/JjVvYDPVrAQ&#34;&gt;Part 2 - One Prompt is NOT enough: Using AutoGen to code a Multi-Agent Postgres AI Tool&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Branch: &lt;a href=&#34;https://github.com/disler/multi-agent-postgres-data-analytics/tree/v2-using-autogen-to-build-our-multi-agent-tool&#34;&gt;v2-using-autogen-to-build-our-multi-agent-tool&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Video: &lt;a href=&#34;https://youtu.be/JjVvYDPVrAQ&#34;&gt;https://youtu.be/JjVvYDPVrAQ&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/2-using-autogen-to-build-our-multi-agent-postgres-data-analytics-tool.png&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://youtu.be/4o8tymMQ5GM&#34;&gt;Part 3 - Make AutoGen Consistent: CONTROL your LLM agents for ACCURATE Postgres Al Data Analytics&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Branch: &lt;a href=&#34;https://github.com/disler/multi-agent-postgres-data-analytics/tree/v3-make-autogen-consistent-control-your-llm&#34;&gt;v3-make-autogen-consistent-control-your-llm&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Video: &lt;a href=&#34;https://youtu.be/4o8tymMQ5GM&#34;&gt;https://youtu.be/4o8tymMQ5GM&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/3-make-autogen-consistent-to-build-our-multi-agent-postgres-data-analytics-tool.png&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://youtu.be/CKo-czvxFkY&#34;&gt;Part 4 - AutoGen Token Tactics: FIRING AI Agents, USELESS Vector Embeddings, GPT-4 Memory Tricks&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Branch: &lt;a href=&#34;https://github.com/disler/multi-agent-postgres-data-analytics/tree/v4-autogen-token-tactics-firing-ai-agents&#34;&gt;v4-autogen-token-tactics-firing-ai-agents&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Video: &lt;a href=&#34;https://youtu.be/CKo-czvxFkY&#34;&gt;https://youtu.be/CKo-czvxFkY&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/4-autogen-token-tactics-managing-llm-memory-and-costs-multi-agent-postgres-ai-data-analytics.png&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://youtu.be/UA6IVMDPuC8&#34;&gt;Part 5 - AutoGen SPYWARE: Coding Systems for SUCCESSFUL AI Agents (Postgres Data Analytics)&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Branch: &lt;a href=&#34;https://github.com/disler/multi-agent-postgres-data-analytics/tree/v5-autogen-spyware-coding-systems-for-successful-ai&#34;&gt;v5-autogen-spyware-coding-systems-for-successful-ai&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Video: &lt;a href=&#34;https://youtu.be/UA6IVMDPuC8&#34;&gt;https://youtu.be/UA6IVMDPuC8&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/5-autogen-spyware-for-ai-agents-postgres-data-analytics-tool-ai.png&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://youtu.be/XGCWyfA3rgQ&#34;&gt;Part 6 - Using AUTOGEN &amp;amp; GUIDANCE to code LLM Control Flow &amp;amp; JSON Agents (No Prompt Engineering)&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Branch: &lt;a href=&#34;https://github.com/disler/multi-agent-postgres-data-analytics/tree/v6-control-flow-and-structured-response&#34;&gt;v6-control-flow-and-structured-response&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Video: &lt;a href=&#34;https://youtu.be/XGCWyfA3rgQ&#34;&gt;https://youtu.be/XGCWyfA3rgQ&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/6-autogen-and-guidance-for-autonomous-control-flow.png&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://youtu.be/KwcrjP3vuy0&#34;&gt;Part 7 - OpenAI Macro &amp;amp; Micro Strategy: Master Assistants API, Threads, Messages, and Runs&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Branch: &lt;a href=&#34;https://github.com/disler/multi-agent-postgres-data-analytics/tree/v7-turbo4-assistants-threads-messages&#34;&gt;v7-turbo4-assistants-threads-messages&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Video: &lt;a href=&#34;https://youtu.be/KwcrjP3vuy0&#34;&gt;https://youtu.be/KwcrjP3vuy0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/7-turbo4-assistants-threads-messages.png&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/#&#34;&gt;Part 8 - UNRELEASED&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/#&#34;&gt;Part 9 - UNRELEASED&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/#&#34;&gt;Part 10 - UNRELEASED&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;üß† Major Learnings Throughout the Series üß†&lt;/h1&gt; &#xA;&lt;h2&gt;üí° Why are multi-agent applications important?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;They&#39;re important because they allows us to create a more accurate model of the world.&lt;/li&gt; &#xA; &lt;li&gt;We become orchestrators enabling less engineering level and more product level work.&lt;/li&gt; &#xA; &lt;li&gt;They enable reasoning and decision making in a way that is more human like than ever before.&lt;/li&gt; &#xA; &lt;li&gt;We can build systems that make decisions as we would while operating alongside us.&lt;/li&gt; &#xA; &lt;li&gt;We can solve problems that previously required a dedicated hire or an entire team to solve.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;‚úÖ Multi-Agent Systems: The Good&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Can assign functions &amp;amp; prompts to specific agents, enabling specialization yielding better results.&lt;/li&gt; &#xA; &lt;li&gt;Agents can reflect on results to provide feedback thus improving the results.&lt;/li&gt; &#xA; &lt;li&gt;Can role play real organizational structures, existing and new.&lt;/li&gt; &#xA; &lt;li&gt;Ecosystem is evolving rapidly. New tools and frameworks are being built every day.&lt;/li&gt; &#xA; &lt;li&gt;Upside potential is ridiculously massive. We&#39;re talking asymmetric ROI, max &lt;a href=&#34;https://www.navalmanack.com/almanack-of-naval-ravikant/find-a-position-of-leverage&#34;&gt;leverage&lt;/a&gt;, &lt;a href=&#34;http://www.paulgraham.com/superlinear.html&#34;&gt;superlinear&lt;/a&gt; upside. The more agentic build blocks you have the more powerful your engineering and product potential becomes.&lt;/li&gt; &#xA; &lt;li&gt;Multi-agent engineering is probably the most important thing happening in software right now (2023-2024).&lt;/li&gt; &#xA; &lt;li&gt;The road to agentic software is clear. Solve small problems, create reusable building blocks, and then combine them to solve bigger problems.&lt;/li&gt; &#xA; &lt;li&gt;GPT-4 can support multi-agent systems without a doubt. It is the best model by light-years and drives incredible reasoning readily available at your fingertips.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;‚ùå Multi-Agent Systems: The Bad&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;It&#39;s an art to get the roles and the function of your agent right. How many do you need? What are they? How do you know?&lt;/li&gt; &#xA; &lt;li&gt;Can get expensive in testing and scales with # of agents. The more agents the more expensive each query is.&lt;/li&gt; &#xA; &lt;li&gt;Can be difficult to debug why a multi-agent system is not working as expected due to the non-deterministic nature of LLMs.&lt;/li&gt; &#xA; &lt;li&gt;Memory management is a major issue. The context window is forcing a lot of weird, intricate code to manage memory.&lt;/li&gt; &#xA; &lt;li&gt;Too much noise and hype in the AI Agent ecosystem. Lot&#39;s of clickbait hype with little follow through value. Hard to find good resources.&lt;/li&gt; &#xA; &lt;li&gt;Very few are engineers are publicly building multi-agent systems. Most are toy examples or ripping from example codebases.&lt;/li&gt; &#xA; &lt;li&gt;OpenAI is inadvertently killing startups with every new release. Risky to commit to building LLM powered applications.&lt;/li&gt; &#xA; &lt;li&gt;At the current price, we cannot run a fully agentic system that runs 24/7 or even for an hour on GPT-4 without burning thousands per day. The price must come down WITHOUT sacrificing quality (looking at you open source models).&lt;/li&gt; &#xA; &lt;li&gt;It&#39;s tricky to know when to write explicit code vs prompt engineer vs build a multi-agent team. This is a new skill that will take time to master.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üß† 2024 Multi-agent / LLM / Agentic Predictions üß†&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;stay tuned for predictions&lt;/p&gt; &#xA;&lt;/blockquote&gt;</summary>
  </entry>
  <entry>
    <title>eriklindernoren/ML-From-Scratch</title>
    <updated>2023-11-15T01:37:36Z</updated>
    <id>tag:github.com,2023-11-15:/eriklindernoren/ML-From-Scratch</id>
    <link href="https://github.com/eriklindernoren/ML-From-Scratch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Machine Learning From Scratch. Bare bones NumPy implementations of machine learning models and algorithms with a focus on accessibility. Aims to cover everything from linear regression to deep learning.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Machine Learning From Scratch&lt;/h1&gt; &#xA;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;p&gt;Python implementations of some of the fundamental Machine Learning models and algorithms from scratch.&lt;/p&gt; &#xA;&lt;p&gt;The purpose of this project is not to produce as optimized and computationally efficient algorithms as possible but rather to present the inner workings of them in a transparent and accessible way.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#machine-learning-from-scratch&#34;&gt;Machine Learning From Scratch&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#about&#34;&gt;About&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#table-of-contents&#34;&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#examples&#34;&gt;Examples&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#polynomial-regression&#34;&gt;Polynomial Regression&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#classification-with-cnn&#34;&gt;Classification With CNN&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#density-based-clustering&#34;&gt;Density-Based Clustering&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#generating-handwritten-digits&#34;&gt;Generating Handwritten Digits&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#deep-reinforcement-learning&#34;&gt;Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#image-reconstruction-with-rbm&#34;&gt;Image Reconstruction With RBM&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#evolutionary-evolved-neural-network&#34;&gt;Evolutionary Evolved Neural Network&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#genetic-algorithm&#34;&gt;Genetic Algorithm&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#association-analysis&#34;&gt;Association Analysis&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#implementations&#34;&gt;Implementations&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#supervised-learning&#34;&gt;Supervised Learning&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#unsupervised-learning&#34;&gt;Unsupervised Learning&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#reinforcement-learning&#34;&gt;Reinforcement Learning&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#deep-learning&#34;&gt;Deep Learning&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/#contact&#34;&gt;Contact&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/eriklindernoren/ML-From-Scratch&#xA;$ cd ML-From-Scratch&#xA;$ python setup.py install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;h3&gt;Polynomial Regression&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/polynomial_regression.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;http://eriklindernoren.se/images/p_reg.gif&#34; width=&#34;640&#34; \&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; Figure: Training progress of a regularized polynomial regression model fitting &lt;br&gt; temperature data measured in Link√∂ping, Sweden 2016. &lt;/p&gt; &#xA;&lt;h3&gt;Classification With CNN&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/convolutional_neural_network.py&#xA;&#xA;+---------+&#xA;| ConvNet |&#xA;+---------+&#xA;Input Shape: (1, 8, 8)&#xA;+----------------------+------------+--------------+&#xA;| Layer Type           | Parameters | Output Shape |&#xA;+----------------------+------------+--------------+&#xA;| Conv2D               | 160        | (16, 8, 8)   |&#xA;| Activation (ReLU)    | 0          | (16, 8, 8)   |&#xA;| Dropout              | 0          | (16, 8, 8)   |&#xA;| BatchNormalization   | 2048       | (16, 8, 8)   |&#xA;| Conv2D               | 4640       | (32, 8, 8)   |&#xA;| Activation (ReLU)    | 0          | (32, 8, 8)   |&#xA;| Dropout              | 0          | (32, 8, 8)   |&#xA;| BatchNormalization   | 4096       | (32, 8, 8)   |&#xA;| Flatten              | 0          | (2048,)      |&#xA;| Dense                | 524544     | (256,)       |&#xA;| Activation (ReLU)    | 0          | (256,)       |&#xA;| Dropout              | 0          | (256,)       |&#xA;| BatchNormalization   | 512        | (256,)       |&#xA;| Dense                | 2570       | (10,)        |&#xA;| Activation (Softmax) | 0          | (10,)        |&#xA;+----------------------+------------+--------------+&#xA;Total Parameters: 538570&#xA;&#xA;Training: 100% [------------------------------------------------------------------------] Time: 0:01:55&#xA;Accuracy: 0.987465181058&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;http://eriklindernoren.se/images/mlfs_cnn1.png&#34; width=&#34;640&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; Figure: Classification of the digit dataset using CNN. &lt;/p&gt; &#xA;&lt;h3&gt;Density-Based Clustering&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/dbscan.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;http://eriklindernoren.se/images/mlfs_dbscan.png&#34; width=&#34;640&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; Figure: Clustering of the moons dataset using DBSCAN. &lt;/p&gt; &#xA;&lt;h3&gt;Generating Handwritten Digits&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/unsupervised_learning/generative_adversarial_network.py&#xA;&#xA;+-----------+&#xA;| Generator |&#xA;+-----------+&#xA;Input Shape: (100,)&#xA;+------------------------+------------+--------------+&#xA;| Layer Type             | Parameters | Output Shape |&#xA;+------------------------+------------+--------------+&#xA;| Dense                  | 25856      | (256,)       |&#xA;| Activation (LeakyReLU) | 0          | (256,)       |&#xA;| BatchNormalization     | 512        | (256,)       |&#xA;| Dense                  | 131584     | (512,)       |&#xA;| Activation (LeakyReLU) | 0          | (512,)       |&#xA;| BatchNormalization     | 1024       | (512,)       |&#xA;| Dense                  | 525312     | (1024,)      |&#xA;| Activation (LeakyReLU) | 0          | (1024,)      |&#xA;| BatchNormalization     | 2048       | (1024,)      |&#xA;| Dense                  | 803600     | (784,)       |&#xA;| Activation (TanH)      | 0          | (784,)       |&#xA;+------------------------+------------+--------------+&#xA;Total Parameters: 1489936&#xA;&#xA;+---------------+&#xA;| Discriminator |&#xA;+---------------+&#xA;Input Shape: (784,)&#xA;+------------------------+------------+--------------+&#xA;| Layer Type             | Parameters | Output Shape |&#xA;+------------------------+------------+--------------+&#xA;| Dense                  | 401920     | (512,)       |&#xA;| Activation (LeakyReLU) | 0          | (512,)       |&#xA;| Dropout                | 0          | (512,)       |&#xA;| Dense                  | 131328     | (256,)       |&#xA;| Activation (LeakyReLU) | 0          | (256,)       |&#xA;| Dropout                | 0          | (256,)       |&#xA;| Dense                  | 514        | (2,)         |&#xA;| Activation (Softmax)   | 0          | (2,)         |&#xA;+------------------------+------------+--------------+&#xA;Total Parameters: 533762&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;http://eriklindernoren.se/images/gan_mnist5.gif&#34; width=&#34;640&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; Figure: Training progress of a Generative Adversarial Network generating &lt;br&gt; handwritten digits. &lt;/p&gt; &#xA;&lt;h3&gt;Deep Reinforcement Learning&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/deep_q_network.py&#xA;&#xA;+----------------+&#xA;| Deep Q-Network |&#xA;+----------------+&#xA;Input Shape: (4,)&#xA;+-------------------+------------+--------------+&#xA;| Layer Type        | Parameters | Output Shape |&#xA;+-------------------+------------+--------------+&#xA;| Dense             | 320        | (64,)        |&#xA;| Activation (ReLU) | 0          | (64,)        |&#xA;| Dense             | 130        | (2,)         |&#xA;+-------------------+------------+--------------+&#xA;Total Parameters: 450&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;http://eriklindernoren.se/images/mlfs_dql1.gif&#34; width=&#34;640&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; Figure: Deep Q-Network solution to the CartPole-v1 environment in OpenAI gym. &lt;/p&gt; &#xA;&lt;h3&gt;Image Reconstruction With RBM&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/restricted_boltzmann_machine.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;http://eriklindernoren.se/images/rbm_digits1.gif&#34; width=&#34;640&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; Figure: Shows how the network gets better during training at reconstructing &lt;br&gt; the digit 2 in the MNIST dataset. &lt;/p&gt; &#xA;&lt;h3&gt;Evolutionary Evolved Neural Network&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/neuroevolution.py&#xA;&#xA;+---------------+&#xA;| Model Summary |&#xA;+---------------+&#xA;Input Shape: (64,)&#xA;+----------------------+------------+--------------+&#xA;| Layer Type           | Parameters | Output Shape |&#xA;+----------------------+------------+--------------+&#xA;| Dense                | 1040       | (16,)        |&#xA;| Activation (ReLU)    | 0          | (16,)        |&#xA;| Dense                | 170        | (10,)        |&#xA;| Activation (Softmax) | 0          | (10,)        |&#xA;+----------------------+------------+--------------+&#xA;Total Parameters: 1210&#xA;&#xA;Population Size: 100&#xA;Generations: 3000&#xA;Mutation Rate: 0.01&#xA;&#xA;[0 Best Individual - Fitness: 3.08301, Accuracy: 10.5%]&#xA;[1 Best Individual - Fitness: 3.08746, Accuracy: 12.0%]&#xA;...&#xA;[2999 Best Individual - Fitness: 94.08513, Accuracy: 98.5%]&#xA;Test set accuracy: 96.7%&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;http://eriklindernoren.se/images/evo_nn4.png&#34; width=&#34;640&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; Figure: Classification of the digit dataset by a neural network which has&lt;br&gt; been evolutionary evolved. &lt;/p&gt; &#xA;&lt;h3&gt;Genetic Algorithm&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/genetic_algorithm.py&#xA;&#xA;+--------+&#xA;|   GA   |&#xA;+--------+&#xA;Description: Implementation of a Genetic Algorithm which aims to produce&#xA;the user specified target string. This implementation calculates each&#xA;candidate&#39;s fitness based on the alphabetical distance between the candidate&#xA;and the target. A candidate is selected as a parent with probabilities proportional&#xA;to the candidate&#39;s fitness. Reproduction is implemented as a single-point&#xA;crossover between pairs of parents. Mutation is done by randomly assigning&#xA;new characters with uniform probability.&#xA;&#xA;Parameters&#xA;----------&#xA;Target String: &#39;Genetic Algorithm&#39;&#xA;Population Size: 100&#xA;Mutation Rate: 0.05&#xA;&#xA;[0 Closest Candidate: &#39;CJqlJguPlqzvpoJmb&#39;, Fitness: 0.00]&#xA;[1 Closest Candidate: &#39;MCxZxdr nlfiwwGEk&#39;, Fitness: 0.01]&#xA;[2 Closest Candidate: &#39;MCxZxdm nlfiwwGcx&#39;, Fitness: 0.01]&#xA;[3 Closest Candidate: &#39;SmdsAklMHn kBIwKn&#39;, Fitness: 0.01]&#xA;[4 Closest Candidate: &#39;  lotneaJOasWfu Z&#39;, Fitness: 0.01]&#xA;...&#xA;[292 Closest Candidate: &#39;GeneticaAlgorithm&#39;, Fitness: 1.00]&#xA;[293 Closest Candidate: &#39;GeneticaAlgorithm&#39;, Fitness: 1.00]&#xA;[294 Answer: &#39;Genetic Algorithm&#39;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Association Analysis&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python mlfromscratch/examples/apriori.py&#xA;+-------------+&#xA;|   Apriori   |&#xA;+-------------+&#xA;Minimum Support: 0.25&#xA;Minimum Confidence: 0.8&#xA;Transactions:&#xA;    [1, 2, 3, 4]&#xA;    [1, 2, 4]&#xA;    [1, 2]&#xA;    [2, 3, 4]&#xA;    [2, 3]&#xA;    [3, 4]&#xA;    [2, 4]&#xA;Frequent Itemsets:&#xA;    [1, 2, 3, 4, [1, 2], [1, 4], [2, 3], [2, 4], [3, 4], [1, 2, 4], [2, 3, 4]]&#xA;Rules:&#xA;    1 -&amp;gt; 2 (support: 0.43, confidence: 1.0)&#xA;    4 -&amp;gt; 2 (support: 0.57, confidence: 0.8)&#xA;    [1, 4] -&amp;gt; 2 (support: 0.29, confidence: 1.0)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Implementations&lt;/h2&gt; &#xA;&lt;h3&gt;Supervised Learning&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/adaboost.py&#34;&gt;Adaboost&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/bayesian_regression.py&#34;&gt;Bayesian Regression&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/decision_tree.py&#34;&gt;Decision Tree&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/regression.py&#34;&gt;Elastic Net&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/gradient_boosting.py&#34;&gt;Gradient Boosting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/k_nearest_neighbors.py&#34;&gt;K Nearest Neighbors&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/regression.py&#34;&gt;Lasso Regression&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/linear_discriminant_analysis.py&#34;&gt;Linear Discriminant Analysis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/regression.py&#34;&gt;Linear Regression&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/logistic_regression.py&#34;&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/multi_class_lda.py&#34;&gt;Multi-class Linear Discriminant Analysis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/multilayer_perceptron.py&#34;&gt;Multilayer Perceptron&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/naive_bayes.py&#34;&gt;Naive Bayes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/neuroevolution.py&#34;&gt;Neuroevolution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/particle_swarm_optimization.py&#34;&gt;Particle Swarm Optimization of Neural Network&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/perceptron.py&#34;&gt;Perceptron&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/regression.py&#34;&gt;Polynomial Regression&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/random_forest.py&#34;&gt;Random Forest&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/regression.py&#34;&gt;Ridge Regression&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/support_vector_machine.py&#34;&gt;Support Vector Machine&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/supervised_learning/xgboost.py&#34;&gt;XGBoost&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Unsupervised Learning&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/apriori.py&#34;&gt;Apriori&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/autoencoder.py&#34;&gt;Autoencoder&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/dbscan.py&#34;&gt;DBSCAN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/fp_growth.py&#34;&gt;FP-Growth&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py&#34;&gt;Gaussian Mixture Model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/generative_adversarial_network.py&#34;&gt;Generative Adversarial Network&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/genetic_algorithm.py&#34;&gt;Genetic Algorithm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/k_means.py&#34;&gt;K-Means&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py&#34;&gt;Partitioning Around Medoids&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/principal_component_analysis.py&#34;&gt;Principal Component Analysis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py&#34;&gt;Restricted Boltzmann Machine&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Reinforcement Learning&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/reinforcement_learning/deep_q_network.py&#34;&gt;Deep Q-Network&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Deep Learning&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/deep_learning/neural_network.py&#34;&gt;Neural Network&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/deep_learning/layers.py&#34;&gt;Layers&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Activation Layer&lt;/li&gt; &#xA;   &lt;li&gt;Average Pooling Layer&lt;/li&gt; &#xA;   &lt;li&gt;Batch Normalization Layer&lt;/li&gt; &#xA;   &lt;li&gt;Constant Padding Layer&lt;/li&gt; &#xA;   &lt;li&gt;Convolutional Layer&lt;/li&gt; &#xA;   &lt;li&gt;Dropout Layer&lt;/li&gt; &#xA;   &lt;li&gt;Flatten Layer&lt;/li&gt; &#xA;   &lt;li&gt;Fully-Connected (Dense) Layer&lt;/li&gt; &#xA;   &lt;li&gt;Fully-Connected RNN Layer&lt;/li&gt; &#xA;   &lt;li&gt;Max Pooling Layer&lt;/li&gt; &#xA;   &lt;li&gt;Reshape Layer&lt;/li&gt; &#xA;   &lt;li&gt;Up Sampling Layer&lt;/li&gt; &#xA;   &lt;li&gt;Zero Padding Layer&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Model Types &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/examples/convolutional_neural_network.py&#34;&gt;Convolutional Neural Network&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/examples/multilayer_perceptron.py&#34;&gt;Multilayer Perceptron&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eriklindernoren/ML-From-Scratch/master/mlfromscratch/examples/recurrent_neural_network.py&#34;&gt;Recurrent Neural Network&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;If there&#39;s some implementation you would like to see here or if you&#39;re just feeling social, feel free to &lt;a href=&#34;mailto:eriklindernoren@gmail.com&#34;&gt;email&lt;/a&gt; me or connect with me on &lt;a href=&#34;https://www.linkedin.com/in/eriklindernoren/&#34;&gt;LinkedIn&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>hiyouga/LLaMA-Factory</title>
    <updated>2023-11-15T01:37:36Z</updated>
    <id>tag:github.com,2023-11-15:/hiyouga/LLaMA-Factory</id>
    <link href="https://github.com/hiyouga/LLaMA-Factory" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Easy-to-use LLM fine-tuning framework (LLaMA, BLOOM, Mistral, Baichuan, Qwen, ChatGLM)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LLaMA Factory: Training and Evaluating Large Language Models with Minimal Effort&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/hiyouga/LLaMA-Factory/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/hiyouga/LLaMA-Factory?style=social&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/hiyouga/LLaMA-Factory&#34; alt=&#34;GitHub Code License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/hiyouga/LLaMA-Factory/commits/main&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/last-commit/hiyouga/LLaMA-Factory&#34; alt=&#34;GitHub last commit&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/llmtuner/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/llmtuner&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/llmtuner/&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/badge/llmtuner&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/hiyouga/LLaMA-Factory/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-blue&#34; alt=&#34;GitHub pull request&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/c2EPEt5NU&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/c2EPEt5NU?compact=true&amp;amp;style=flat&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;üëã Join our &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/wechat.jpg&#34;&gt;WeChat&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;[ English | &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/README_zh.md&#34;&gt;‰∏≠Êñá&lt;/a&gt; ]&lt;/p&gt; &#xA;&lt;h2&gt;LLaMA Board: A One-stop Web UI for Getting Started with LLaMA Factory&lt;/h2&gt; &#xA;&lt;p&gt;Launch &lt;strong&gt;LLaMA Board&lt;/strong&gt; via &lt;code&gt;CUDA_VISIBLE_DEVICES=0 python src/train_web.py&lt;/code&gt;. (multiple GPUs are not supported yet)&lt;/p&gt; &#xA;&lt;p&gt;Here is an example of altering the self-cognition of an instruction-tuned language model within 10 minutes on a single GPU.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/hiyouga/LLaMA-Factory/assets/16256802/6ba60acc-e2e2-4bec-b846-2d88920d5ba1&#34;&gt;https://github.com/hiyouga/LLaMA-Factory/assets/16256802/6ba60acc-e2e2-4bec-b846-2d88920d5ba1&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Changelog&lt;/h2&gt; &#xA;&lt;p&gt;[23/10/21] We supported &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.05914&#34;&gt;NEFTune&lt;/a&gt;&lt;/strong&gt; trick for fine-tuning. Try &lt;code&gt;--neft_alpha&lt;/code&gt; argument to activate NEFTune, e.g., &lt;code&gt;--neft_alpha 5&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;[23/09/27] We supported &lt;strong&gt;$S^2$-Attn&lt;/strong&gt; proposed by &lt;a href=&#34;https://github.com/dvlab-research/LongLoRA&#34;&gt;LongLoRA&lt;/a&gt; for the LLaMA models. Try &lt;code&gt;--shift_attn&lt;/code&gt; argument to enable shift short attention.&lt;/p&gt; &#xA;&lt;p&gt;[23/09/23] We integrated MMLU, C-Eval and CMMLU benchmarks in this repo. See &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#evaluation&#34;&gt;this example&lt;/a&gt; to evaluate your models.&lt;/p&gt; &#xA;&lt;p&gt;[23/09/10] We supported using &lt;strong&gt;&lt;a href=&#34;https://github.com/Dao-AILab/flash-attention&#34;&gt;FlashAttention-2&lt;/a&gt;&lt;/strong&gt; for the LLaMA models. Try &lt;code&gt;--flash_attn&lt;/code&gt; argument to enable FlashAttention-2 if you are using RTX4090, A100 or H100 GPUs.&lt;/p&gt; &#xA;&lt;p&gt;[23/08/12] We supported &lt;strong&gt;RoPE scaling&lt;/strong&gt; to extend the context length of the LLaMA models. Try &lt;code&gt;--rope_scaling linear&lt;/code&gt; argument in training and &lt;code&gt;--rope_scaling dynamic&lt;/code&gt; argument at inference to extrapolate the position embeddings.&lt;/p&gt; &#xA;&lt;p&gt;[23/08/11] We supported &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.18290&#34;&gt;DPO training&lt;/a&gt;&lt;/strong&gt; for instruction-tuned models. See &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#dpo-training&#34;&gt;this example&lt;/a&gt; to train your models.&lt;/p&gt; &#xA;&lt;p&gt;[23/07/31] We supported &lt;strong&gt;dataset streaming&lt;/strong&gt;. Try &lt;code&gt;--streaming&lt;/code&gt; and &lt;code&gt;--max_steps 10000&lt;/code&gt; arguments to load your dataset in streaming mode.&lt;/p&gt; &#xA;&lt;p&gt;[23/07/29] We released two instruction-tuned 13B models at Hugging Face. See these Hugging Face Repos (&lt;a href=&#34;https://huggingface.co/hiyouga/Llama-2-Chinese-13b-chat&#34;&gt;LLaMA-2&lt;/a&gt; / &lt;a href=&#34;https://huggingface.co/hiyouga/Baichuan-13B-sft&#34;&gt;Baichuan&lt;/a&gt;) for details.&lt;/p&gt; &#xA;&lt;p&gt;[23/07/18] We developed an &lt;strong&gt;all-in-one Web UI&lt;/strong&gt; for training, evaluation and inference. Try &lt;code&gt;train_web.py&lt;/code&gt; to fine-tune models in your Web browser. Thank &lt;a href=&#34;https://github.com/KanadeSiina&#34;&gt;@KanadeSiina&lt;/a&gt; and &lt;a href=&#34;https://github.com/codemayq&#34;&gt;@codemayq&lt;/a&gt; for their efforts in the development.&lt;/p&gt; &#xA;&lt;p&gt;[23/07/09] We released &lt;strong&gt;&lt;a href=&#34;https://github.com/hiyouga/FastEdit&#34;&gt;FastEdit&lt;/a&gt;&lt;/strong&gt; ‚ö°ü©π, an easy-to-use package for editing the factual knowledge of large language models efficiently. Please follow &lt;a href=&#34;https://github.com/hiyouga/FastEdit&#34;&gt;FastEdit&lt;/a&gt; if you are interested.&lt;/p&gt; &#xA;&lt;p&gt;[23/06/29] We provided a &lt;strong&gt;reproducible example&lt;/strong&gt; of training a chat model using instruction-following datasets, see &lt;a href=&#34;https://huggingface.co/hiyouga/Baichuan-7B-sft&#34;&gt;Baichuan-7B-sft&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;p&gt;[23/06/22] We aligned the &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/src/api_demo.py&#34;&gt;demo API&lt;/a&gt; with the &lt;a href=&#34;https://platform.openai.com/docs/api-reference/chat&#34;&gt;OpenAI&#39;s&lt;/a&gt; format where you can insert the fine-tuned model in &lt;strong&gt;arbitrary ChatGPT-based applications&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;[23/06/03] We supported quantized training and inference (aka &lt;strong&gt;&lt;a href=&#34;https://github.com/artidoro/qlora&#34;&gt;QLoRA&lt;/a&gt;&lt;/strong&gt;). Try &lt;code&gt;--quantization_bit 4/8&lt;/code&gt; argument to work with quantized models.&lt;/p&gt; &#xA;&lt;h2&gt;Supported Models&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Model size&lt;/th&gt; &#xA;   &lt;th&gt;Default module&lt;/th&gt; &#xA;   &lt;th&gt;Template&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/baichuan-inc/Baichuan-13B&#34;&gt;Baichuan&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;7B/13B&lt;/td&gt; &#xA;   &lt;td&gt;W_pack&lt;/td&gt; &#xA;   &lt;td&gt;baichuan&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/baichuan-inc/Baichuan2&#34;&gt;Baichuan2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;7B/13B&lt;/td&gt; &#xA;   &lt;td&gt;W_pack&lt;/td&gt; &#xA;   &lt;td&gt;baichuan2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/bigscience/bloom&#34;&gt;BLOOM&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;560M/1.1B/1.7B/3B/7.1B/176B&lt;/td&gt; &#xA;   &lt;td&gt;query_key_value&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/bigscience/bloomz&#34;&gt;BLOOMZ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;560M/1.1B/1.7B/3B/7.1B/176B&lt;/td&gt; &#xA;   &lt;td&gt;query_key_value&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/THUDM/ChatGLM3&#34;&gt;ChatGLM3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;6B&lt;/td&gt; &#xA;   &lt;td&gt;query_key_value&lt;/td&gt; &#xA;   &lt;td&gt;chatglm3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/tiiuae/falcon-7b&#34;&gt;Falcon&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;7B/40B/180B&lt;/td&gt; &#xA;   &lt;td&gt;query_key_value&lt;/td&gt; &#xA;   &lt;td&gt;falcon&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/InternLM/InternLM&#34;&gt;InternLM&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;7B/20B&lt;/td&gt; &#xA;   &lt;td&gt;q_proj,v_proj&lt;/td&gt; &#xA;   &lt;td&gt;intern&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;LLaMA&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;7B/13B/33B/65B&lt;/td&gt; &#xA;   &lt;td&gt;q_proj,v_proj&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama&#34;&gt;LLaMA-2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;7B/13B/70B&lt;/td&gt; &#xA;   &lt;td&gt;q_proj,v_proj&lt;/td&gt; &#xA;   &lt;td&gt;llama2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/mistralai&#34;&gt;Mistral&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;q_proj,v_proj&lt;/td&gt; &#xA;   &lt;td&gt;mistral&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/microsoft/phi-1_5&#34;&gt;Phi-1.5&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.3B&lt;/td&gt; &#xA;   &lt;td&gt;Wqkv&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/QwenLM/Qwen&#34;&gt;Qwen&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;7B/14B&lt;/td&gt; &#xA;   &lt;td&gt;c_attn&lt;/td&gt; &#xA;   &lt;td&gt;qwen&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/xverse-ai&#34;&gt;XVERSE&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;7B/13B/65B&lt;/td&gt; &#xA;   &lt;td&gt;q_proj,v_proj&lt;/td&gt; &#xA;   &lt;td&gt;xverse&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] &lt;strong&gt;Default module&lt;/strong&gt; is used for the &lt;code&gt;--lora_target&lt;/code&gt; argument, you can use &lt;code&gt;--lora_target all&lt;/code&gt; to specify all the available modules.&lt;/p&gt; &#xA; &lt;p&gt;For the &#34;base&#34; models, the &lt;code&gt;--template&lt;/code&gt; argument can be chosen from &lt;code&gt;default&lt;/code&gt;, &lt;code&gt;alpaca&lt;/code&gt;, &lt;code&gt;vicuna&lt;/code&gt; etc. But make sure to use the &lt;strong&gt;corresponding template&lt;/strong&gt; for the &#34;chat&#34; models.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/src/llmtuner/extras/template.py&#34;&gt;template.py&lt;/a&gt; for a full list of models we supported.&lt;/p&gt; &#xA;&lt;h2&gt;Supported Training Approaches&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Approach&lt;/th&gt; &#xA;   &lt;th&gt;Full-parameter&lt;/th&gt; &#xA;   &lt;th&gt;Partial-parameter&lt;/th&gt; &#xA;   &lt;th&gt;LoRA&lt;/th&gt; &#xA;   &lt;th&gt;QLoRA&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Pre-Training&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Supervised Fine-Tuning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Reward Modeling&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PPO Training&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DPO Training&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] Use &lt;code&gt;--quantization_bit 4/8&lt;/code&gt; argument to enable QLoRA.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Provided Datasets&lt;/h2&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Pre-training datasets&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/data/wiki_demo.txt&#34;&gt;Wiki Demo (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/tiiuae/falcon-refinedweb&#34;&gt;RefinedWeb (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2&#34;&gt;RedPajama V2 (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/olm/olm-wikipedia-20221220&#34;&gt;Wikipedia (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered&#34;&gt;Wikipedia (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/EleutherAI/pile&#34;&gt;Pile (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/Skywork/SkyPile-150B&#34;&gt;SkyPile (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/bigcode/the-stack&#34;&gt;The Stack (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/bigcode/starcoderdata&#34;&gt;StarCoder (en)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Supervised fine-tuning datasets&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca&#34;&gt;Stanford Alpaca (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM&#34;&gt;GPT-4 Generated Data (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/data/self_cognition.json&#34;&gt;Self-cognition (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/OpenAssistant/oasst1&#34;&gt;Open Assistant (multilingual)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/QingyiSi/Alpaca-CoT/tree/main/Chinese-instruction-collection&#34;&gt;ShareGPT (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/JosephusCheung/GuanacoDataset&#34;&gt;Guanaco Dataset (multilingual)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/train_2M_CN&#34;&gt;BELLE 2M (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/train_1M_CN&#34;&gt;BELLE 1M (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/train_0.5M_CN&#34;&gt;BELLE 0.5M (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M&#34;&gt;BELLE Dialogue 0.4M (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/school_math_0.25M&#34;&gt;BELLE School Math 0.25M (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M&#34;&gt;BELLE Multiturn Chat 0.8M (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/thunlp/UltraChat&#34;&gt;UltraChat (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/GAIR/lima&#34;&gt;LIMA (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/garage-bAInd/Open-Platypus&#34;&gt;OpenPlatypus (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k&#34;&gt;CodeAlpaca 20k (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/QingyiSi/Alpaca-CoT&#34;&gt;Alpaca CoT (multilingual)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/TIGER-Lab/MathInstruct&#34;&gt;MathInstruct (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M&#34;&gt;Firefly 1.1M (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/suolyer/webqa&#34;&gt;Web QA (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/zxbsmk/webnovel_cn&#34;&gt;WebNovel (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/HasturOfficial/adgen&#34;&gt;Ad Gen (zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/totally-not-an-llm/sharegpt-hyperfiltered-3k&#34;&gt;ShareGPT Hyperfiltered (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/shibing624/sharegpt_gpt4&#34;&gt;ShareGPT4 (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k&#34;&gt;UltraChat 200k (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/THUDM/AgentInstruct&#34;&gt;AgentInstruct (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/lmsys/lmsys-chat-1m&#34;&gt;LMSYS Chat 1M (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k&#34;&gt;Evol Instruct V2 (en)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Preference datasets&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/Anthropic/hh-rlhf&#34;&gt;HH-RLHF (en)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/OpenAssistant/oasst1&#34;&gt;Open Assistant (multilingual)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM&#34;&gt;GPT-4 Generated Data (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/data/README.md&#34;&gt;data/README.md&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;p&gt;Some datasets require confirmation before using them, so we recommend logging in with your Hugging Face account using these commands.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install --upgrade huggingface_hub&#xA;huggingface-cli login&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Requirement&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.8+ and PyTorch 1.13.1+&lt;/li&gt; &#xA; &lt;li&gt;ü§óTransformers, Datasets, Accelerate, PEFT and TRL&lt;/li&gt; &#xA; &lt;li&gt;sentencepiece, protobuf and tiktoken&lt;/li&gt; &#xA; &lt;li&gt;jieba, rouge-chinese and nltk (used at evaluation and predict)&lt;/li&gt; &#xA; &lt;li&gt;gradio and matplotlib (used in web UI)&lt;/li&gt; &#xA; &lt;li&gt;uvicorn, fastapi and sse-starlette (used in API)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;And &lt;strong&gt;powerful GPUs&lt;/strong&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Data Preparation (optional)&lt;/h3&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/data/README.md&#34;&gt;data/README.md&lt;/a&gt; for checking the details about the format of dataset files. You can either use a single &lt;code&gt;.json&lt;/code&gt; file or a &lt;a href=&#34;https://huggingface.co/docs/datasets/dataset_script&#34;&gt;dataset loading script&lt;/a&gt; with multiple files to create a custom dataset.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] Please update &lt;code&gt;data/dataset_info.json&lt;/code&gt; to use your custom dataset. About the format of this file, please refer to &lt;code&gt;data/README.md&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Dependence Installation (optional)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/hiyouga/LLaMA-Factory.git&#xA;conda create -n llama_factory python=3.10&#xA;conda activate llama_factory&#xA;cd LLaMA-Factory&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to enable the quantized LoRA (QLoRA) on the Windows platform, you will be required to install a pre-built version of &lt;code&gt;bitsandbytes&lt;/code&gt; library, which supports CUDA 11.1 to 12.1.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.39.1-py3-none-win_amd64.whl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Train on a single GPU&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT] If you want to train models on multiple GPUs, please refer to &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#distributed-training&#34;&gt;Distributed Training&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;Pre-Training&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \&#xA;    --stage pt \&#xA;    --model_name_or_path path_to_llama_model \&#xA;    --do_train \&#xA;    --dataset wiki_demo \&#xA;    --finetuning_type lora \&#xA;    --lora_target q_proj,v_proj \&#xA;    --output_dir path_to_pt_checkpoint \&#xA;    --overwrite_cache \&#xA;    --per_device_train_batch_size 4 \&#xA;    --gradient_accumulation_steps 4 \&#xA;    --lr_scheduler_type cosine \&#xA;    --logging_steps 10 \&#xA;    --save_steps 1000 \&#xA;    --learning_rate 5e-5 \&#xA;    --num_train_epochs 3.0 \&#xA;    --plot_loss \&#xA;    --fp16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Supervised Fine-Tuning&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \&#xA;    --stage sft \&#xA;    --model_name_or_path path_to_llama_model \&#xA;    --do_train \&#xA;    --dataset alpaca_gpt4_en \&#xA;    --template default \&#xA;    --finetuning_type lora \&#xA;    --lora_target q_proj,v_proj \&#xA;    --output_dir path_to_sft_checkpoint \&#xA;    --overwrite_cache \&#xA;    --per_device_train_batch_size 4 \&#xA;    --gradient_accumulation_steps 4 \&#xA;    --lr_scheduler_type cosine \&#xA;    --logging_steps 10 \&#xA;    --save_steps 1000 \&#xA;    --learning_rate 5e-5 \&#xA;    --num_train_epochs 3.0 \&#xA;    --plot_loss \&#xA;    --fp16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Reward Modeling&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \&#xA;    --stage rm \&#xA;    --model_name_or_path path_to_llama_model \&#xA;    --do_train \&#xA;    --dataset comparison_gpt4_en \&#xA;    --template default \&#xA;    --finetuning_type lora \&#xA;    --lora_target q_proj,v_proj \&#xA;    --resume_lora_training False \&#xA;    --checkpoint_dir path_to_sft_checkpoint \&#xA;    --output_dir path_to_rm_checkpoint \&#xA;    --per_device_train_batch_size 2 \&#xA;    --gradient_accumulation_steps 4 \&#xA;    --lr_scheduler_type cosine \&#xA;    --logging_steps 10 \&#xA;    --save_steps 1000 \&#xA;    --learning_rate 1e-6 \&#xA;    --num_train_epochs 1.0 \&#xA;    --plot_loss \&#xA;    --fp16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;PPO Training&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \&#xA;    --stage ppo \&#xA;    --model_name_or_path path_to_llama_model \&#xA;    --do_train \&#xA;    --dataset alpaca_gpt4_en \&#xA;    --template default \&#xA;    --finetuning_type lora \&#xA;    --lora_target q_proj,v_proj \&#xA;    --resume_lora_training False \&#xA;    --checkpoint_dir path_to_sft_checkpoint \&#xA;    --reward_model path_to_rm_checkpoint \&#xA;    --output_dir path_to_ppo_checkpoint \&#xA;    --per_device_train_batch_size 2 \&#xA;    --gradient_accumulation_steps 4 \&#xA;    --lr_scheduler_type cosine \&#xA;    --logging_steps 10 \&#xA;    --save_steps 1000 \&#xA;    --learning_rate 1e-5 \&#xA;    --num_train_epochs 1.0 \&#xA;    --plot_loss \&#xA;    --fp16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;DPO Training&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \&#xA;    --stage dpo \&#xA;    --model_name_or_path path_to_llama_model \&#xA;    --do_train \&#xA;    --dataset comparison_gpt4_en \&#xA;    --template default \&#xA;    --finetuning_type lora \&#xA;    --lora_target q_proj,v_proj \&#xA;    --resume_lora_training False \&#xA;    --checkpoint_dir path_to_sft_checkpoint \&#xA;    --output_dir path_to_dpo_checkpoint \&#xA;    --per_device_train_batch_size 2 \&#xA;    --gradient_accumulation_steps 4 \&#xA;    --lr_scheduler_type cosine \&#xA;    --logging_steps 10 \&#xA;    --save_steps 1000 \&#xA;    --learning_rate 1e-5 \&#xA;    --num_train_epochs 1.0 \&#xA;    --plot_loss \&#xA;    --fp16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Distributed Training&lt;/h3&gt; &#xA;&lt;h4&gt;Use Huggingface Accelerate&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;accelerate config # configure the environment&#xA;accelerate launch src/train_bash.py # arguments (same as above)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Example config for LoRA training&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;compute_environment: LOCAL_MACHINE&#xA;distributed_type: MULTI_GPU&#xA;downcast_bf16: &#39;no&#39;&#xA;gpu_ids: all&#xA;machine_rank: 0&#xA;main_training_function: main&#xA;mixed_precision: fp16&#xA;num_machines: 1&#xA;num_processes: 4&#xA;rdzv_backend: static&#xA;same_network: true&#xA;tpu_env: []&#xA;tpu_use_cluster: false&#xA;tpu_use_sudo: false&#xA;use_cpu: false&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h4&gt;Use DeepSpeed&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;deepspeed --num_gpus 8 --master_port=9901 src/train_bash.py \&#xA;    --deepspeed ds_config.json \&#xA;    ... # arguments (same as above)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Example config for full-parameter training with DeepSpeed ZeRO-2&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;train_batch_size&#34;: &#34;auto&#34;,&#xA;  &#34;train_micro_batch_size_per_gpu&#34;: &#34;auto&#34;,&#xA;  &#34;gradient_accumulation_steps&#34;: &#34;auto&#34;,&#xA;  &#34;gradient_clipping&#34;: &#34;auto&#34;,&#xA;  &#34;zero_allow_untested_optimizer&#34;: true,&#xA;  &#34;fp16&#34;: {&#xA;    &#34;enabled&#34;: &#34;auto&#34;,&#xA;    &#34;loss_scale&#34;: 0,&#xA;    &#34;initial_scale_power&#34;: 16,&#xA;    &#34;loss_scale_window&#34;: 1000,&#xA;    &#34;hysteresis&#34;: 2,&#xA;    &#34;min_loss_scale&#34;: 1&#xA;  },  &#xA;  &#34;zero_optimization&#34;: {&#xA;    &#34;stage&#34;: 2,&#xA;    &#34;allgather_partitions&#34;: true,&#xA;    &#34;allgather_bucket_size&#34;: 5e8,&#xA;    &#34;reduce_scatter&#34;: true,&#xA;    &#34;reduce_bucket_size&#34;: 5e8,&#xA;    &#34;overlap_comm&#34;: false,&#xA;    &#34;contiguous_gradients&#34;: true&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Export model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python src/export_model.py \&#xA;    --model_name_or_path path_to_llama_model \&#xA;    --template default \&#xA;    --finetuning_type lora \&#xA;    --checkpoint_dir path_to_checkpoint \&#xA;    --export_dir path_to_export&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;API Demo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python src/api_demo.py \&#xA;    --model_name_or_path path_to_llama_model \&#xA;    --template default \&#xA;    --finetuning_type lora \&#xA;    --checkpoint_dir path_to_checkpoint&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] Visit &lt;code&gt;http://localhost:8000/docs&lt;/code&gt; for API documentation.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;CLI Demo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python src/cli_demo.py \&#xA;    --model_name_or_path path_to_llama_model \&#xA;    --template default \&#xA;    --finetuning_type lora \&#xA;    --checkpoint_dir path_to_checkpoint&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Web Demo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python src/web_demo.py \&#xA;    --model_name_or_path path_to_llama_model \&#xA;    --template default \&#xA;    --finetuning_type lora \&#xA;    --checkpoint_dir path_to_checkpoint&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Evaluation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/evaluate.py \&#xA;    --model_name_or_path path_to_llama_model \&#xA;    --finetuning_type lora \&#xA;    --checkpoint_dir path_to_checkpoint \&#xA;    --template vanilla \&#xA;    --task mmlu \&#xA;    --split test \&#xA;    --lang en \&#xA;    --n_shot 5 \&#xA;    --batch_size 4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Predict&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \&#xA;    --stage sft \&#xA;    --model_name_or_path path_to_llama_model \&#xA;    --do_predict \&#xA;    --dataset alpaca_gpt4_en \&#xA;    --template default \&#xA;    --finetuning_type lora \&#xA;    --checkpoint_dir path_to_checkpoint \&#xA;    --output_dir path_to_predict_result \&#xA;    --per_device_eval_batch_size 8 \&#xA;    --max_samples 100 \&#xA;    --predict_with_generate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] We recommend using &lt;code&gt;--per_device_eval_batch_size=1&lt;/code&gt; and &lt;code&gt;--max_target_length 128&lt;/code&gt; at 4/8-bit predict.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Projects using LLaMA Factory&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/Yu-Yang-Li/StarWhisper&#34;&gt;StarWhisper&lt;/a&gt;&lt;/strong&gt;: A large language model for Astronomy, based on ChatGLM2-6B and Qwen-14B.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/FudanDISC/DISC-LawLLM&#34;&gt;DISC-LawLLM&lt;/a&gt;&lt;/strong&gt;: A large language model specialized in Chinese legal domain, based on Baichuan-13B, is capable of retrieving and reasoning on legal knowledge.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/thomas-yanxin/Sunsimiao&#34;&gt;Sunsimiao&lt;/a&gt;&lt;/strong&gt;: A large language model specialized in Chinese medical domain, based on Baichuan-7B and ChatGLM-6B.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/WangRongsheng/CareGPT&#34;&gt;CareGPT&lt;/a&gt;&lt;/strong&gt;: A series of large language models for Chinese medical domain, based on LLaMA2-7B and Baichuan-13B.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This repository is licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE&#34;&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Please follow the model licenses to use the corresponding model weights: &lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan-13B-Base/resolve/main/Community%20License%20for%20Baichuan-13B%20Model.pdf&#34;&gt;Baichuan&lt;/a&gt; / &lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat/resolve/main/Community%20License%20for%20Baichuan2%20Model.pdf&#34;&gt;Baichuan2&lt;/a&gt; / &lt;a href=&#34;https://huggingface.co/spaces/bigscience/license&#34;&gt;BLOOM&lt;/a&gt; / &lt;a href=&#34;https://github.com/THUDM/ChatGLM3/raw/main/MODEL_LICENSE&#34;&gt;ChatGLM3&lt;/a&gt; / &lt;a href=&#34;https://huggingface.co/tiiuae/falcon-180B/blob/main/LICENSE.txt&#34;&gt;Falcon&lt;/a&gt; / &lt;a href=&#34;https://github.com/InternLM/InternLM#license&#34;&gt;InternLM&lt;/a&gt; / &lt;a href=&#34;https://github.com/facebookresearch/llama/raw/main/MODEL_CARD.md&#34;&gt;LLaMA&lt;/a&gt; / &lt;a href=&#34;https://ai.meta.com/llama/license/&#34;&gt;LLaMA-2&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE&#34;&gt;Mistral&lt;/a&gt; / &lt;a href=&#34;https://huggingface.co/microsoft/phi-1_5/resolve/main/Research%20License.docx&#34;&gt;Phi-1.5&lt;/a&gt; / &lt;a href=&#34;https://github.com/QwenLM/Qwen/raw/main/LICENSE&#34;&gt;Qwen&lt;/a&gt; / &lt;a href=&#34;https://github.com/xverse-ai/XVERSE-13B/raw/main/MODEL_LICENSE.pdf&#34;&gt;XVERSE&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If this work is helpful, please kindly cite as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@Misc{llama-factory,&#xA;  title = {LLaMA Factory},&#xA;  author = {hiyouga},&#xA;  howpublished = {\url{https://github.com/hiyouga/LLaMA-Factory}},&#xA;  year = {2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;This repo benefits from &lt;a href=&#34;https://github.com/huggingface/peft&#34;&gt;PEFT&lt;/a&gt;, &lt;a href=&#34;https://github.com/artidoro/qlora&#34;&gt;QLoRA&lt;/a&gt; and &lt;a href=&#34;https://github.com/lm-sys/FastChat&#34;&gt;FastChat&lt;/a&gt;. Thanks for their wonderful works.&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=hiyouga/LLaMA-Factory&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>