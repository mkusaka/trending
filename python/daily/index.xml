<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-26T01:36:11Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>facebookresearch/diplomacy_cicero</title>
    <updated>2022-11-26T01:36:11Z</updated>
    <id>tag:github.com,2022-11-26:/facebookresearch/diplomacy_cicero</id>
    <link href="https://github.com/facebookresearch/diplomacy_cicero" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Code for Cicero, an AI agent that plays the game of Diplomacy with open-domain natural language negotiation.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Diplomacy Cicero and Diplodocus&lt;/h1&gt; &#xA;&lt;p&gt;This code contains checkpoints and training code the following papers:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.science.org/doi/10.1126/science.ade9097&#34;&gt;&#34;Human-Level Play in the Game of Diplomacy by Combining Language Models with Strategic Reasoning&#34;&lt;/a&gt; published in Science, November 2022.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.05492&#34;&gt;&#34;Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning&#34;&lt;/a&gt; in review at ICLR 2023.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Code&lt;/h3&gt; &#xA;&lt;p&gt;A very brief orientation:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Most of the language modeling and generation code is in &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/parlai_diplomacy&#34;&gt;parlai_diplomacy&lt;/a&gt;, and leverages the &lt;a href=&#34;https://github.com/facebookresearch/ParlAI&#34;&gt;ParlAI framework&lt;/a&gt; for running and finetuning the language models involved.&lt;/li&gt; &#xA; &lt;li&gt;Within the &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/fairdiplomacy/agents&#34;&gt;agents&lt;/a&gt; directory, the central logic for Cicero&#39;s strategic planning lives &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/fairdiplomacy/agents/br_corr_bilateral_search.py&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/fairdiplomacy/agents/bqre1p_agent.py&#34;&gt;here&lt;/a&gt;. The latter also contains the core logic for Diplodocus&#39;s strategic planning. &#34;bqre1p&#34; was the internal dev name for DiL-piKL, and &#34;br_corr_bilateral&#34; the internal dev name for Cicero&#39;s bilateral and correlated planning components.&lt;/li&gt; &#xA; &lt;li&gt;The dialogue-free model architectures for RL are &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/fairdiplomacy/models/base_strategy_model/base_strategy_model.py&#34;&gt;here&lt;/a&gt;, and the bulk of the training logic lives &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/fairdiplomacy/models/base_strategy_model/train_sl.py&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The RL training code for both Cicero and Diplodocus is &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/fairdiplomacy/selfplay&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/conf&#34;&gt;conf&lt;/a&gt; directory contains various configs for Cicero, Diplodocus, benchmark agents, and training configs for RL.&lt;/li&gt; &#xA; &lt;li&gt;A separately licensed subfolder of this repo &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/fairdiplomacy_external&#34;&gt;here&lt;/a&gt; contains some utilities for visually rendering games, or connecting agents to be run online.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Game info&lt;/h3&gt; &#xA;&lt;p&gt;Diplomacy is a strategic board game set in 1914 Europe. The board is divided into fifty-six land regions and nineteen sea regions. Forty-two of the land regions are divided among the seven Great Powers of the game: Austria-Hungary, England, France, Germany, Italy, Russia, and Turkey. The remaining fourteen land regions are neutral at the start of the game.&lt;/p&gt; &#xA;&lt;p&gt;Each power controls some regions and some units. The number of the units controlled depends on the number of the controlled key regions called Supply Centers (SCs). Simply put, more SCs means more units. The goal of the game is to control more than half of all SCs by moving units into these regions and convincing other players to support you.&lt;/p&gt; &#xA;&lt;p&gt;You can find the full rules &lt;a href=&#34;https://en.wikibooks.org/wiki/Diplomacy/Rules&#34;&gt;here&lt;/a&gt;. To get the game&#39;s spirit, watch &lt;a href=&#34;https://www.youtube.com/c/diplostrats&#34;&gt;some&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/playlist?list=PLmbDtCxqXA5CyFoBmB5dJHHOHeLQ0Nd-Y&#34;&gt;games&lt;/a&gt; with comments. You can play the game online on &lt;a href=&#34;https://webdiplomacy.net/&#34;&gt;webDiplomacy&lt;/a&gt; either against bots or humans.&lt;/p&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Clone the repo with submodules:&#xA;git clone --recursive git@github.com:facebookresearch/diplomacy_cicero.git diplomacy_cicero&#xA;cd diplomacy_cicero&#xA;&#xA;# Apt installs&#xA;apt-get install -y wget bzip2 ca-certificates curl git build-essential clang-format-8 git wget cmake build-essential autoconf libtool pkg-config libgoogle-glog-dev&#xA;&#xA;# Install conda&#xA;wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-4.7.10-Linux-x86_64.sh -O ~/miniconda.sh&#xA;/bin/bash ~/miniconda.sh -b&#xA;&#xA;# Create conda env&#xA;conda create --yes -n diplomacy_cicero python=3.7&#xA;conda activate diplomacy_cicero&#xA;&#xA;# Install pytorch, pybind11&#xA;conda install --yes pytorch=1.7.1 torchvision cudatoolkit=11.0 -c pytorch&#xA;conda install --yes pybind11&#xA;&#xA;# Install go for boringssl in grpc&#xA;# We have some hacky patching code for protobuf that is not guaranteed&#xA;# to work on versions other than this.&#xA;conda install --yes go protobuf=3.19.1&#xA;&#xA;# Install python requirements&#xA;pip install -r requirements.txt&#xA;&#xA;# Local pip installs&#xA;pip install -e ./thirdparty/github/fairinternal/postman/nest/&#xA;# NOTE: Postman here links against pytorch for tensors, for this to work you may&#xA;# need to separately have installed cuda 11 on your own.&#xA;pip install -e ./thirdparty/github/fairinternal/postman/postman/&#xA;pip install -e . -vv&#xA;&#xA;# Make&#xA;make&#xA;&#xA;# Run unit tests&#xA;make test_fast&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After each pull it&#39;s recommended to run &lt;code&gt;make&lt;/code&gt; to re-compile internal C++ and protobuf code.&lt;/p&gt; &#xA;&lt;h3&gt;Downloading model files&lt;/h3&gt; &#xA;&lt;p&gt;Please email &lt;a href=&#34;mailto:diplomacyteam@meta.com&#34;&gt;diplomacyteam@meta.com&lt;/a&gt; to request the password. Then run &lt;code&gt;bash bin/download_model_files.sh &amp;lt;PASSWORD&amp;gt;&lt;/code&gt;. This will download and decrypt all relevant model files into &lt;code&gt;./models&lt;/code&gt;. This might take awhile.&lt;/p&gt; &#xA;&lt;h3&gt;Accessing Cicero&#39;s experiment games&lt;/h3&gt; &#xA;&lt;p&gt;JSON data for games that Cicero played in are located in &lt;code&gt;data/cicero_redacted_games&lt;/code&gt;. Only conversations with players who have consented to having their dialogue released are included. Please refer to the (separately-licensed) &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/(fairdiplomacy_external)&#34;&gt;fairdiplomacy_external&lt;/a&gt; subdirectory for details on HTML visualizations.&lt;/p&gt; &#xA;&lt;h3&gt;Getting started&lt;/h3&gt; &#xA;&lt;p&gt;The front-end for most tasks is &lt;code&gt;run.py&lt;/code&gt;, which can run various tasks specified by a protobuf config. The config schema can be found at &lt;code&gt;conf/conf.proto&lt;/code&gt;, and example configs for different tasks can be found in the &lt;code&gt;conf&lt;/code&gt; folder. This can be used for most tasks (except training parlai models): training no-press models, comparing agents, profiling things, launching an agent on webdip, etc.&lt;/p&gt; &#xA;&lt;p&gt;The config specification framework, called HeyHi, &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/heyhi/README.md&#34;&gt;is explained here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;A core abstraction is an &lt;code&gt;Agent&lt;/code&gt;, which is specified by an &lt;code&gt;Agent&lt;/code&gt; config whose schema lives in &lt;code&gt;conf/agents.proto&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Simulating games between agents&lt;/h3&gt; &#xA;&lt;p&gt;To simulate 1v6 games between a pair of agents, you can run the &lt;code&gt;compare_agents&lt;/code&gt; task. For example, to play one Cicero agent as Turkey against six full-press imitation agents, you can run&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;python run.py --adhoc --cfg conf/c01_ag_cmp/cmp.prototxt Iagent_one=agents/bqre1p_parlai_20220819_cicero_2.prototxt Iagent_six=agents/ablations/cicero_imitation_only.prototxt power_one=TURKEY&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you don&#39;t have sufficient memory to load two agents, you can load a single agent in self-play with the &lt;code&gt;use_shard_agent=1&lt;/code&gt; flag:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;python run.py --adhoc --cfg conf/c01_ag_cmp/cmp.prototxt Iagent_one=agents/bqre1p_parlai_20220819_cicero_2.prototxt use_shared_agent=1 power_one=TURKEY&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Training models in RL&lt;/h3&gt; &#xA;&lt;p&gt;To run the training for Cicero and/or Diplodocus:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python run.py â€”adhoc â€”cfg conf/c04_exploit/research_20221001_paper_cicero.prototxt launcher.slurm.num_gpus=256&#xA;&#xA;python run.py â€”adhoc â€”cfg conf/c04_exploit/research_20221001_paper_diplodocus_high.prototxt launcher.slurm.num_gpus=256&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The above training commands are designed for running on an appropriately configured Slurm cluster with a fast cross-machine shared filesystem. One can also instead pass &lt;code&gt;launcher.local.use_local=true&lt;/code&gt; to run them on locally, e.g. on an individual 8-GPU-or-more GPU machine but training may be very slow.&lt;/p&gt; &#xA;&lt;h3&gt;Other tasks&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/fairdiplomacy_external&#34;&gt;here&lt;/a&gt; for some separately-licensed code for rendering game jsons with HTML, as well as connecting agents to run on &lt;a href=&#34;https://webdiplomacy.net&#34;&gt;webdiplomacy.net&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Supervised training of baseline models&lt;/h3&gt; &#xA;&lt;p&gt;Supervised training and/or behavioral cloning for various dialogue-conditional models as well as pre-RL baseline dialogue-free models involves some of the scripts in &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/parlai_diplomacy&#34;&gt;parlai_diplomacy&lt;/a&gt; via the ParlAI framework, and on the dialogue-free side, some of the configs &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/conf/c02_sup_train&#34;&gt;conf/c02_sup_train&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/fairdiplomacy/models/base_strategy_model/train_sl.py&#34;&gt;train_sl.py&lt;/a&gt;. However the dataset of human games and/or dialogue is NOT available here, so the relevant code and configs are likely to be of limited use. They are provided here mostly as documentation for posterity.&lt;/p&gt; &#xA;&lt;p&gt;However, as mentioned above pre-trained models are available, and with sufficient compute power, re-running the RL on top of these pre-trained models is also possible without any exteral game data.&lt;/p&gt; &#xA;&lt;h3&gt;Pre-commit hooks&lt;/h3&gt; &#xA;&lt;p&gt;Run &lt;code&gt;pre-commit install&lt;/code&gt; to install pre-commit hooks that will auto-format python code before commiting it.&lt;/p&gt; &#xA;&lt;p&gt;Or you can do this manually. Use &lt;a href=&#34;https://github.com/psf/black&#34;&gt;black&lt;/a&gt; auto-formatter to format all python code. For protobufs use &lt;code&gt;clang-format-8 conf/*.proto -i&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Tests&lt;/h3&gt; &#xA;&lt;p&gt;To run tests locally run &lt;code&gt;make test&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We have 2 level of tests: fast, unit tests (run with &lt;code&gt;make test_fast&lt;/code&gt;) and slow, integration tests (run with &lt;code&gt;make test_integration&lt;/code&gt;). The latter aims to use the same entry point as users do, i.e., &lt;code&gt;run.py&lt;/code&gt; for the HeyHi part and &lt;code&gt;diplom&lt;/code&gt; for the ParlAi.&lt;/p&gt; &#xA;&lt;p&gt;We use &lt;code&gt;pytest&lt;/code&gt; to run and discover tests. Some useful &lt;a href=&#34;https://docs.pytest.org/en/stable/&#34;&gt;pytest&lt;/a&gt; commands.&lt;/p&gt; &#xA;&lt;p&gt;To run all tests in your current directory, simply run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pytest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run tests from a specific file, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pytest &amp;lt;filepath&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To use name-based filtering to run tests, use the flag &lt;code&gt;-k&lt;/code&gt;. For example, to only run tests with &lt;code&gt;parlai&lt;/code&gt; in the name, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pytest -k parlai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For verbose testing logs, use &lt;code&gt;-v&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pytest -v -k parlai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To print the output from a test or set of tests, use &lt;code&gt;-s&lt;/code&gt;; this also allows you to set breakpoints:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pytest -s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To view the durations of all tests, run with the flag &lt;code&gt;--durations=0&lt;/code&gt;, e.g.:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pytest --durations=0 unit_tests/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The following license, which is also available &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/LICENSE.md&#34;&gt;here&lt;/a&gt;, covers the content in this repo &lt;em&gt;except&lt;/em&gt; for the &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/diplomacy_cicero/release_orphan/fairdiplomacy_external&#34;&gt;fairdiplomacy_external&lt;/a&gt; directory. The content of fairdiplomacy_external is separately licenced under a version of the AGPL, see the license file within that directory for details.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(covers this repo except for the fairdiplomacy_external directory)&#xA;MIT License&#xA;&#xA;Copyright (c) Meta, Inc. and its affiliates.&#xA;&#xA;Permission is hereby granted, free of charge, to any person obtaining a copy&#xA;of this software and associated documentation files (the &#34;Software&#34;), to deal&#xA;in the Software without restriction, including without limitation the rights&#xA;to use, copy, modify, merge, publish, distribute, sublicense, and/or sell&#xA;copies of the Software, and to permit persons to whom the Software is&#xA;furnished to do so, subject to the following conditions:&#xA;&#xA;The above copyright notice and this permission notice shall be included in all&#xA;copies or substantial portions of the Software.&#xA;&#xA;THE SOFTWARE IS PROVIDED &#34;AS IS&#34;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR&#xA;IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,&#xA;FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE&#xA;AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER&#xA;LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,&#xA;OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE&#xA;SOFTWARE.&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>PaddlePaddle/PaddleSlim</title>
    <updated>2022-11-26T01:36:11Z</updated>
    <id>tag:github.com,2022-11-26:/PaddlePaddle/PaddleSlim</id>
    <link href="https://github.com/PaddlePaddle/PaddleSlim" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PaddleSlim is an open-source library for deep model compression and architecture search.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;h1 align=&#34;center&#34;&gt;PaddleSlim&lt;/h1&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-dfd.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/PaddlePaddle/Paddle?color=ffa&#34;&gt;&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.6.2+-aff.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/PaddlePaddle/PaddleSlim?color=9ea&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/PaddleSlim/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/PaddleSlim?color=9cf&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/PaddlePaddle/PaddleSlim?color=9cc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/PaddlePaddle/PaddleSlim?color=ccf&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;PaddleSlimæ˜¯ä¸€ä¸ªä¸“æ³¨äºæ·±åº¦å­¦ä¹ æ¨¡å‹å‹ç¼©çš„å·¥å…·åº“ï¼Œæä¾›&lt;strong&gt;ä½æ¯”ç‰¹é‡åŒ–ã€çŸ¥è¯†è’¸é¦ã€ç¨€ç–åŒ–å’Œæ¨¡å‹ç»“æ„æœç´¢&lt;/strong&gt;ç­‰æ¨¡å‹å‹ç¼©ç­–ç•¥ï¼Œå¸®åŠ©å¼€å‘è€…å¿«é€Ÿå®ç°æ¨¡å‹çš„å°å‹åŒ–ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;äº§å“åŠ¨æ€&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;ğŸ”¥ &lt;strong&gt;2022.08.16ï¼š&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/example/auto_compression&#34;&gt;è‡ªåŠ¨åŒ–å‹ç¼©&lt;/a&gt;åŠŸèƒ½å‡çº§&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;æ”¯æŒç›´æ¥åŠ è½½ONNXæ¨¡å‹å’ŒPaddleæ¨¡å‹å¯¼å‡ºè‡³ONNX&lt;/li&gt; &#xA;   &lt;li&gt;å‘å¸ƒ&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/raw/develop/docs/zh_cn/tutorials/quant/AnalysisQuant.md&#34;&gt;é‡åŒ–åˆ†æå·¥å…·&lt;/a&gt;ï¼Œå‘å¸ƒ&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/example/post_training_quantization/pytorch_yolo_series/&#34;&gt;YOLOç³»åˆ—ç¦»çº¿é‡åŒ–å·¥å…·&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;æ›´æ–°&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/example/auto_compression/pytorch_yolo_series&#34;&gt;YOLO-Seriesè‡ªåŠ¨åŒ–å‹ç¼©æ¨¡å‹åº“&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA;  &lt;table&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th align=&#34;left&#34;&gt;æ¨¡å‹&lt;/th&gt; &#xA;     &lt;th align=&#34;left&#34;&gt;Base mAP&lt;sup&gt;val&lt;br&gt;0.5:0.95&lt;/sup&gt;&lt;/th&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;ACTé‡åŒ–mAP&lt;sup&gt;val&lt;br&gt;0.5:0.95&lt;/sup&gt;&lt;/th&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;æ¨¡å‹ä½“ç§¯å‹ç¼©æ¯”&lt;/th&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;é¢„æµ‹æ—¶å»¶&lt;sup&gt;&lt;small&gt;FP32&lt;/small&gt;&lt;sup&gt;&lt;br&gt;&lt;sup&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/th&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;é¢„æµ‹æ—¶å»¶&lt;sup&gt;&lt;small&gt;INT8&lt;/small&gt;&lt;sup&gt;&lt;br&gt;&lt;sup&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/th&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;é¢„æµ‹åŠ é€Ÿæ¯”&lt;/th&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/thead&gt; &#xA;   &lt;tbody&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;PPYOLOE-s&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;43.1&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;42.6&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;3.9å€&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;6.51ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;2.12ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;3.1å€&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;YOLOv5s&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;37.4&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;36.9&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;3.8å€&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;5.95ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;1.87ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;3.2å€&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;YOLOv6s&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;42.4&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;41.3&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;3.9å€&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;9.06ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;1.83ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;5.0å€&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;YOLOv7&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;51.1&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;50.9&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;3.9å€&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;26.84ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;4.55ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;5.9å€&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;YOLOv7-Tiny&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;37.3&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;37.0&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;3.9å€&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;5.06ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;1.68ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;3.0å€&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ğŸ”¥ &lt;strong&gt;2022.07.01: å‘å¸ƒ&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/releases/tag/v2.3.0&#34;&gt;v2.3.0ç‰ˆæœ¬&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;å‘å¸ƒ&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/example/auto_compression&#34;&gt;è‡ªåŠ¨åŒ–å‹ç¼©åŠŸèƒ½&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;æ”¯æŒä»£ç æ— æ„ŸçŸ¥å‹ç¼©ï¼šå¼€å‘è€…åªéœ€æä¾›æ¨ç†æ¨¡å‹æ–‡ä»¶å’Œæ•°æ®ï¼Œæ—¢å¯è¿›è¡Œç¦»çº¿é‡åŒ–ï¼ˆPTQï¼‰ã€é‡åŒ–è®­ç»ƒï¼ˆQATï¼‰ã€ç¨€ç–è®­ç»ƒç­‰å‹ç¼©ä»»åŠ¡ã€‚&lt;/li&gt; &#xA;     &lt;li&gt;æ”¯æŒè‡ªåŠ¨ç­–ç•¥é€‰æ‹©ï¼Œæ ¹æ®ä»»åŠ¡ç‰¹ç‚¹å’Œéƒ¨ç½²ç¯å¢ƒç‰¹æ€§ï¼šè‡ªåŠ¨æœç´¢åˆé€‚çš„ç¦»çº¿é‡åŒ–æ–¹æ³•,è‡ªåŠ¨æœç´¢æœ€ä½³çš„å‹ç¼©ç­–ç•¥ç»„åˆæ–¹å¼ã€‚&lt;/li&gt; &#xA;     &lt;li&gt;å‘å¸ƒ&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/example/auto_compression/nlp&#34;&gt;è‡ªç„¶è¯­è¨€å¤„ç†&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/example/auto_compression/semantic_segmentation&#34;&gt;å›¾åƒè¯­ä¹‰åˆ†å‰²&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/example/auto_compression/detection&#34;&gt;å›¾åƒç›®æ ‡æ£€æµ‹&lt;/a&gt;ä¸‰ä¸ªæ–¹å‘çš„è‡ªåŠ¨åŒ–å‹ç¼©ç¤ºä¾‹ã€‚&lt;/li&gt; &#xA;     &lt;li&gt;å‘å¸ƒ&lt;code&gt;X2Paddle&lt;/code&gt;æ¨¡å‹è‡ªåŠ¨åŒ–å‹ç¼©æ–¹æ¡ˆ:&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/example/auto_compression/pytorch_yolo_series&#34;&gt;YOLOv5&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/example/auto_compression/pytorch_yolo_series&#34;&gt;YOLOv6&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/example/auto_compression/pytorch_yolo_series&#34;&gt;YOLOv7&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/example/auto_compression/pytorch_huggingface&#34;&gt;HuggingFace&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/example/auto_compression/tensorflow_mobilenet&#34;&gt;MobileNet&lt;/a&gt;ã€‚&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;å‡çº§é‡åŒ–åŠŸèƒ½ &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;ç»Ÿä¸€é‡åŒ–æ¨¡å‹æ ¼å¼ï¼›ç¦»çº¿é‡åŒ–æ”¯æŒwhile opï¼›ä¿®å¤BERTå¤§æ¨¡å‹é‡åŒ–è®­ç»ƒè¿‡æ…¢çš„é—®é¢˜ã€‚&lt;/li&gt; &#xA;     &lt;li&gt;æ–°å¢7ç§&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/tutorials/quant/post_training_quantization.md&#34;&gt;ç¦»çº¿é‡åŒ–æ–¹æ³•&lt;/a&gt;, åŒ…æ‹¬HIST, AVG, EMD, Bias Correction, AdaRoundç­‰ã€‚&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;æ”¯æŒåŠç»“æ„åŒ–ç¨€ç–è®­ç»ƒ&lt;/li&gt; &#xA;   &lt;li&gt;æ–°å¢å»¶æ—¶é¢„ä¼°å·¥å…· &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;æ”¯æŒå¯¹ç¨€ç–åŒ–æ¨¡å‹ã€ä½æ¯”ç‰¹é‡åŒ–æ¨¡å‹çš„æ€§èƒ½é¢„ä¼°ï¼›æ”¯æŒé¢„ä¼°æŒ‡å®šæ¨¡å‹åœ¨ç‰¹å®šéƒ¨ç½²ç¯å¢ƒä¸‹ (ARM CPU + Paddle Lite) çš„æ¨ç†æ€§èƒ½ï¼›æä¾› SD625ã€SD710ã€RK3288 èŠ¯ç‰‡ + Paddle Lite çš„é¢„ä¼°æ¥å£ã€‚&lt;/li&gt; &#xA;     &lt;li&gt;æä¾›éƒ¨ç½²ç¯å¢ƒè‡ªåŠ¨æ‰©å±•å·¥å…·ï¼Œå¯ä»¥è‡ªåŠ¨å¢åŠ åœ¨æ›´å¤š ARM CPU è®¾å¤‡ä¸Šçš„é¢„ä¼°å·¥å…·ã€‚&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;å†å²æ›´æ–°&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;2021.11.15: å‘å¸ƒv2.2.0ç‰ˆæœ¬&lt;/strong&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;æ”¯æŒåŠ¨æ€å›¾ç¦»çº¿é‡åŒ–åŠŸèƒ½.&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;2021.5.20: å‘å¸ƒV2.1.0ç‰ˆæœ¬&lt;/strong&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;æ‰©å±•ç¦»çº¿é‡åŒ–æ–¹æ³•&lt;/li&gt; &#xA;    &lt;li&gt;æ–°å¢éç»“æ„åŒ–ç¨€ç–&lt;/li&gt; &#xA;    &lt;li&gt;å¢å¼ºå‰ªæåŠŸèƒ½&lt;/li&gt; &#xA;    &lt;li&gt;ä¿®å¤OFAåŠŸèƒ½è‹¥å¹²bug&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;æ›´å¤šä¿¡æ¯è¯·å‚è€ƒï¼š&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/releases&#34;&gt;release note&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;åŸºç¡€å‹ç¼©åŠŸèƒ½æ¦‚è§ˆ&lt;/h2&gt; &#xA;&lt;p&gt;PaddleSlimæ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼Œä¹Ÿæ”¯æŒè‡ªå®šä¹‰é‡åŒ–ã€è£å‰ªç­‰åŠŸèƒ½ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr align=&#34;center&#34; valign=&#34;bottom&#34;&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/raw/release/2.0.0/docs/zh_cn/tutorials/quant/overview.md&#34;&gt;Quantization&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/raw/release/2.0.0/docs/zh_cn/tutorials/pruning/overview.md&#34;&gt;Pruning&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/raw/release/2.0.0/docs/zh_cn/tutorials/nas/overview.md&#34;&gt;NAS&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/tree/release/2.0.0/docs/zh_cn/tutorials&#34;&gt;Distilling&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr valign=&#34;top&#34;&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#%E5%9C%A8%E7%BA%BF%E9%87%8F%E5%8C%96%E8%AE%AD%E7%BB%83qat&#34;&gt;QAT&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#pact&#34;&gt;PACT&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#%E9%9D%99%E6%80%81%E7%A6%BB%E7%BA%BF%E9%87%8F%E5%8C%96ptq-static&#34;&gt;PTQ Static&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#%E5%8A%A8%E6%80%81%E7%A6%BB%E7%BA%BF%E9%87%8F%E5%8C%96ptq-dynamic&#34;&gt;PTQ Dynamic&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#embedding%E9%87%8F%E5%8C%96&#34;&gt;Embedding Quant&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#%E6%95%8F%E6%84%9F%E5%BA%A6%E5%89%AA%E6%9E%9D&#34;&gt;SensitivityPruner&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#fpgm&#34;&gt;FPGMFilterPruner&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#l1norm&#34;&gt;L1NormFilterPruner&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#l2norm&#34;&gt;**L2NormFilterPruner&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#slimfilter&#34;&gt;*SlimFilterPruner&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#optslimfilter&#34;&gt;*OptSlimFilterPruner&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#sanas&#34;&gt;*Simulate Anneal based NAS&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#rlnas&#34;&gt;*Reinforcement Learning based NAS&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#darts&#34;&gt;**DARTS&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#pc-darts&#34;&gt;**PC-DARTS&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#once-for-all&#34;&gt;**Once-for-All&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#hardware-aware-search&#34;&gt;*Hardware-aware Search&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#fsp&#34;&gt;*FSP&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#dml&#34;&gt;*DML&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/overview.md#dk&#34;&gt;*DK&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;æ³¨ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;*è¡¨ç¤ºä»…æ”¯æŒé™æ€å›¾ï¼Œ**è¡¨ç¤ºä»…æ”¯æŒåŠ¨æ€å›¾&lt;/li&gt; &#xA; &lt;li&gt;æ•æ„Ÿåº¦è£å‰ªæŒ‡çš„æ˜¯é€šè¿‡å„ä¸ªå±‚çš„æ•æ„Ÿåº¦åˆ†ææ¥ç¡®å®šå„ä¸ªå·ç§¯å±‚çš„å‰ªè£ç‡ï¼Œéœ€è¦å’Œå…¶ä»–è£å‰ªæ–¹æ³•é…åˆä½¿ç”¨ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;å¤šåœºæ™¯æ•ˆæœå±•ç¤º&lt;/h3&gt; &#xA;&lt;p&gt;PaddleSlimåœ¨å…¸å‹è§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸Šåšäº†æ¨¡å‹å‹ç¼©ï¼Œå¹¶ä¸”æµ‹è¯•äº†Nvidia GPUã€ARMç­‰è®¾å¤‡ä¸Šçš„åŠ é€Ÿæƒ…å†µï¼Œè¿™é‡Œå±•ç¤ºéƒ¨åˆ†æ¨¡å‹çš„å‹ç¼©æ•ˆæœï¼Œè¯¦ç»†æ–¹æ¡ˆå¯ä»¥å‚è€ƒä¸‹é¢CVå’ŒNLPæ¨¡å‹å‹ç¼©æ–¹æ¡ˆ:&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/images/benchmark.png&#34; height=&#34;185&#34; width=&#34;849&#34; hspace=&#34;10&#34;&gt; &lt;br&gt; &lt;strong&gt;è¡¨1: éƒ¨åˆ†åœºæ™¯æ¨¡å‹å‹ç¼©åŠ é€Ÿæƒ…å†µ&lt;/strong&gt; &lt;/p&gt; &#xA;&lt;p&gt;æ³¨:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;YOLOv3: åœ¨ç§»åŠ¨ç«¯SD855ä¸ŠåŠ é€Ÿ3.55å€ã€‚&lt;/li&gt; &#xA; &lt;li&gt;PP-OCR: ä½“ç§¯ç”±8.9Må‡å°‘åˆ°2.9M, åœ¨SD855ä¸ŠåŠ é€Ÿ1.27å€ã€‚&lt;/li&gt; &#xA; &lt;li&gt;BERT: æ¨¡å‹å‚æ•°ç”±110Må‡å°‘åˆ°80Mï¼Œç²¾åº¦æå‡çš„æƒ…å†µä¸‹ï¼ŒTesla T4 GPU FP16è®¡ç®—åŠ é€Ÿ1.47å€ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;è‡ªåŠ¨å‹ç¼©æ•ˆæœå±•ç¤º&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;800&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/7534971/168805367-f9d1299d-93e3-44d0-84da-870217edeb54.png&#34;&gt; &lt;br&gt; &lt;strong&gt;è¡¨3: è‡ªåŠ¨å‹ç¼©æ•ˆæœ&lt;/strong&gt; &lt;/p&gt; &#xA;&lt;h3&gt;ç¦»çº¿é‡åŒ–æ•ˆæœå¯¹æ¯”&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;750&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/7534971/169042883-9ca281ce-19be-4525-a3d2-c54cea4a2cbd.png&#34;&gt; &lt;br&gt; &lt;strong&gt;è¡¨2: å¤šç§ç¦»çº¿é‡åŒ–æ–¹æ³•æ•ˆæœå¯¹æ¯”&lt;/strong&gt; &lt;/p&gt; &#xA;&lt;h2&gt;æ–‡æ¡£æ•™ç¨‹&lt;/h2&gt; &#xA;&lt;h2&gt;ç‰ˆæœ¬å¯¹é½&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;PaddleSlim&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;PaddlePaddle&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;PaddleLite&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.0.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&amp;lt;=1.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.1.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.2.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.0Beta/RC&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.0.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.1.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.1.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.1.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.1.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&amp;gt;=2.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.3.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2.3.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&amp;gt;=2.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;å®‰è£…&lt;/h2&gt; &#xA;&lt;p&gt;å®‰è£…æœ€æ–°ç‰ˆæœ¬ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install paddleslim -i https://pypi.tuna.tsinghua.edu.cn/simple&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å®‰è£…æŒ‡å®šç‰ˆæœ¬ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install paddleslim==2.3.0 -i https://pypi.tuna.tsinghua.edu.cn/simple&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å®‰è£…developç‰ˆæœ¬ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/PaddlePaddle/PaddleSlim.git &amp;amp; cd PaddleSlim&#xA;python setup.py install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;éªŒè¯å®‰è£…&lt;/h3&gt; &#xA;&lt;p&gt;å®‰è£…å®Œæˆåæ‚¨å¯ä»¥ä½¿ç”¨ python æˆ– python3 è¿›å…¥ python è§£é‡Šå™¨ï¼Œè¾“å…¥import paddleslim, æ²¡æœ‰æŠ¥é”™åˆ™è¯´æ˜å®‰è£…æˆåŠŸã€‚&lt;/p&gt; &#xA;&lt;h3&gt;å¿«é€Ÿå¼€å§‹&lt;/h3&gt; &#xA;&lt;p&gt;å¿«é€Ÿå¼€å§‹æ•™ç¨‹æ˜¯èƒ½åŸºäºCIFAR10æ•°æ®é›†å¿«é€Ÿè¿è¡Œèµ·æ¥çš„ç®€å•ç¤ºä¾‹ï¼Œè‹¥æ‚¨æ˜¯Paddleå®˜æ–¹æ¨¡å‹å¥—ä»¶ç”¨æˆ·ï¼Œè¯·ç›´æ¥ä½¿ç”¨ä¸‹æ–¹çš„CVæ¨¡å‹å‹ç¼©æˆ–è€…NLPæ¨¡å‹å‹ç¼©ä¸­æ•™ç¨‹ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸ”¥ &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/example/auto_compression&#34;&gt;è‡ªåŠ¨å‹ç¼©&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/quick_start/static/quant_aware_tutorial.md&#34;&gt;é‡åŒ–è®­ç»ƒ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/quick_start/static/quant_post_static_tutorial.md&#34;&gt;ç¦»çº¿é‡åŒ–&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/quick_start/static/pruning_tutorial.md&#34;&gt;ç»“æ„åŒ–å‰ªæ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/quick_start/static/distillation_tutorial.md&#34;&gt;è’¸é¦&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/quick_start/static/nas_tutorial.md&#34;&gt;NAS&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;æ›´å¤šæ•™ç¨‹&lt;/h3&gt; &#xA;&lt;p&gt;è¿›é˜¶æ•™ç¨‹è¯¦ç»†ä»‹ç»äº†æ¯ä¸€æ­¥çš„æµç¨‹ï¼Œå¸®åŠ©æ‚¨æŠŠç›¸åº”æ–¹æ³•è¿ç§»åˆ°æ‚¨è‡ªå·±çš„æ¨¡å‹ä¸Šã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;é€šé“å‰ªè£&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/tutorials/pruning/overview.md&#34;&gt;å››ç§å‰ªè£ç­–ç•¥æ•ˆæœå¯¹æ¯”ä¸åº”ç”¨æ–¹æ³•&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/tutorials/pruning/overview.md#l1normfilterpruner&#34;&gt;L1NormFilterPruner&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/tutorials/pruning/overview.md#fpgmfilterpruner&#34;&gt;FPGMFilterPruner&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/tutorials/pruning/overview.md#slimfilterpruner&#34;&gt;SlimFilterFilterPruner&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/tutorials/pruning/overview.md#optslimfilterpruner&#34;&gt;OptSlimFilterPruner&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;è‡ªå®šä¹‰å‰ªè£ç­–ç•¥ï¼š&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/tutorials/pruning/dygraph/self_defined_filter_pruning.md&#34;&gt;åŠ¨æ€å›¾&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ä½æ¯”ç‰¹é‡åŒ–&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/tutorials/quant/overview.md&#34;&gt;ä¸‰ç§é‡åŒ–æ–¹æ³•ä»‹ç»ä¸åº”ç”¨&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/quick_start/static/quant_aware_tutorial.md&#34;&gt;é‡åŒ–è®­ç»ƒ&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/tutorials/quant/static/quant_post_tutorial.md&#34;&gt;ç¦»çº¿é‡åŒ–&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/tutorials/quant/post_training_quantization.md&#34;&gt;ç¦»çº¿é‡åŒ–æ–¹æ³•è§£æ&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/tutorials/quant/static/embedding_quant_tutorial.md&#34;&gt;embeddingé‡åŒ–&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;NAS&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/tutorials/nas/overview.md&#34;&gt;å››ç§NASç­–ç•¥ä»‹ç»å’Œåº”ç”¨&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/tutorials/nas/dygraph/nas_ofa.md&#34;&gt;Once-For-All&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/tutorials/nas/static/sanas_darts_space.md&#34;&gt;SANAS&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/tree/release/2.0.0/demo/nas#rlnas%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%90%9C%E7%B4%A2%E7%A4%BA%E4%BE%8B&#34;&gt;RLNAS&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/demo/darts/README.md&#34;&gt;DARTS&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;è’¸é¦&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/demo/distillation&#34;&gt;çŸ¥è¯†è’¸é¦ç¤ºä¾‹&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;æ¨ç†éƒ¨ç½²&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/demo/mkldnn_quant/README.md&#34;&gt;Intel CPUé‡åŒ–éƒ¨ç½²&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/demo/quant/deploy/TensorRT/README.md&#34;&gt;Nvidia GPUé‡åŒ–éƒ¨ç½²&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/deploy/deploy_cls_model_on_mobile_device.md&#34;&gt;PaddleLiteé‡åŒ–éƒ¨ç½²&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;CVæ¨¡å‹å‹ç¼©&lt;/h3&gt; &#xA;&lt;p&gt;æœ¬ç³»åˆ—æ•™ç¨‹å‡åŸºäºPaddleå®˜æ–¹çš„æ¨¡å‹å¥—ä»¶ä¸­æ¨¡å‹è¿›è¡Œå‹ç¼©ï¼Œè‹¥æ‚¨ä¸æ˜¯æ¨¡å‹å¥—ä»¶ç”¨æˆ·ï¼Œæ›´æ¨èä½¿ç”¨å¿«é€Ÿæ•™ç¨‹å’Œè¿›é˜¶æ•™ç¨‹ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;æ£€æµ‹æ¨¡å‹å‹ç¼©&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;å‹ç¼©æ–¹æ¡ˆ&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/cv/detection/static/yolov3_slim.md&#34;&gt;PPDetection-YOLOv3 å‹ç¼©æ–¹æ¡ˆ&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;æ–¹æ³•åº”ç”¨-é™æ€å›¾&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/cv/detection/static/paddledetection_slim_distillation_tutorial.md&#34;&gt;è’¸é¦&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/cv/detection/static/paddledetection_slim_quantization_tutorial.md&#34;&gt;é‡åŒ–è®­ç»ƒ&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/cv/detection/static/paddledetection_slim_nas_tutorial.md&#34;&gt;æ¨¡å‹ç»“æ„æœç´¢&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/cv/detection/static/paddledetection_slim_pruing_tutorial.md&#34;&gt;å‰ªæ&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/cv/detection/static/paddledetection_slim_prune_dist_tutorial.md&#34;&gt;å‰ªæä¸è’¸é¦çš„ç»“åˆä½¿ç”¨&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/cv/detection/static/paddledetection_slim_sensitivy_tutorial.md&#34;&gt;å·ç§¯å±‚æ•æ„Ÿåº¦åˆ†æ&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;æ–¹æ³•åº”ç”¨-åŠ¨æ€å›¾&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.0-rc/dygraph/configs/slim#%E5%89%AA%E8%A3%81&#34;&gt;å‰ªæ&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.0-rc/dygraph/configs/slim#%E9%87%8F%E5%8C%96&#34;&gt;é‡åŒ–è®­ç»ƒ&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;åˆ†å‰²æ¨¡å‹å‹ç¼©&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;å‹ç¼©æ–¹æ¡ˆ&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;æ–¹æ³•åº”ç”¨-é™æ€å›¾&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSeg/tree/release/v0.8.0/slim/distillation&#34;&gt;è’¸é¦&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSeg/tree/release/v0.8.0/slim/quantization&#34;&gt;é‡åŒ–è®­ç»ƒ&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSeg/tree/release/v0.8.0/slim/nas&#34;&gt;æ¨¡å‹ç»“æ„æœç´¢&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSeg/tree/release/v0.8.0/slim/prune&#34;&gt;å‰ªæ&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;æ–¹æ³•åº”ç”¨-åŠ¨æ€å›¾&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSeg/tree/develop/slim#%E6%A8%A1%E5%9E%8B%E8%A3%81%E5%89%AA&#34;&gt;å‰ªæ&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSeg/tree/develop/slim#%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96&#34;&gt;é‡åŒ–è®­ç»ƒ&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;OCRæ¨¡å‹å‹ç¼©&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;å‹ç¼©æ–¹æ¡ˆ&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/cv/ocr/static/3.5M_slim.md&#34;&gt;3.5Mæ¨¡å‹å‹ç¼©æ–¹æ¡ˆ&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;æ–¹æ³•åº”ç”¨-é™æ€å›¾&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleOCR/tree/release/1.1/deploy/slim/quantization&#34;&gt;é‡åŒ–è®­ç»ƒ&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleOCR/tree/release/1.1/deploy/slim/prune&#34;&gt;å‰ªæ&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;æ–¹æ³•åº”ç”¨-åŠ¨æ€å›¾&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleOCR/tree/develop/deploy/slim/prune&#34;&gt;å‰ªæ&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleOCR/tree/develop/deploy/slim/quantization&#34;&gt;é‡åŒ–è®­ç»ƒ&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;NLPæ¨¡å‹å‹ç¼©&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/nlp/paddlenlp_slim_ofa_tutorial.md&#34;&gt;PaddleNLP-BERT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/nlp/ernie_slim_ofa_tutorial.md&#34;&gt;ERNIE-ERNIE&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;APIæ–‡æ¡£&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/dygraph&#34;&gt;åŠ¨æ€å›¾&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/api_cn/static&#34;&gt;é™æ€å›¾&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/zh_cn/FAQ/quantization_FAQ.md&#34;&gt;FAQ&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h4&gt;1. é‡åŒ–è®­ç»ƒæˆ–è€…ç¦»çº¿é‡åŒ–åçš„æ¨¡å‹ä½“ç§¯ä¸ºä»€ä¹ˆæ²¡æœ‰å˜å°ï¼Ÿ&lt;/h4&gt; &#xA;&lt;p&gt;ç­”ï¼šè¿™æ˜¯å› ä¸ºé‡åŒ–åä¿å­˜çš„å‚æ•°æ˜¯è™½ç„¶æ˜¯int8èŒƒå›´ï¼Œä½†æ˜¯ç±»å‹æ˜¯floatã€‚è¿™æ˜¯å› ä¸ºPaddleè®­ç»ƒå‰å‘é»˜è®¤çš„Kernelä¸æ”¯æŒINT8 Kernelå®ç°ï¼Œåªæœ‰Paddle Inference TensorRTçš„æ¨ç†æ‰æ”¯æŒé‡åŒ–æ¨ç†åŠ é€Ÿã€‚ä¸ºäº†æ–¹ä¾¿é‡åŒ–åéªŒè¯é‡åŒ–ç²¾åº¦ï¼Œä½¿ç”¨Paddleè®­ç»ƒå‰å‘èƒ½åŠ è½½æ­¤æ¨¡å‹ï¼Œé»˜è®¤ä¿å­˜çš„Float32ç±»å‹æƒé‡ï¼Œä½“ç§¯æ²¡æœ‰å‘ç”Ÿå˜æ¢ã€‚&lt;/p&gt; &#xA;&lt;h4&gt;2. macOS + Python3.9ç¯å¢ƒæˆ–è€…Windowsç¯å¢ƒä¸‹, å®‰è£…å‡ºé”™, &#34;command &#39;swig&#39; failed&#34;&lt;/h4&gt; &#xA;&lt;p&gt;ç­”: è¯·å‚è€ƒ&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/issues/1258&#34;&gt;https://github.com/PaddlePaddle/PaddleSlim/issues/1258&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;è®¸å¯è¯ä¹¦&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬é¡¹ç›®çš„å‘å¸ƒå—&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/raw/develop/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;è®¸å¯è®¤è¯ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;è´¡çŒ®ä»£ç &lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘ä»¬éå¸¸æ¬¢è¿ä½ å¯ä»¥ä¸ºPaddleSlimæä¾›ä»£ç ï¼Œä¹Ÿååˆ†æ„Ÿè°¢ä½ çš„åé¦ˆã€‚&lt;/p&gt; &#xA;&lt;h2&gt;&lt;img title=&#34;&#34; src=&#34;https://user-images.githubusercontent.com/48054808/157800467-2a9946ad-30d1-49a9-b9db-ba33413d9c90.png&#34; alt=&#34;&#34; width=&#34;20&#34;&gt; æŠ€æœ¯äº¤æµ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;å¦‚æœä½ å‘ç°ä»»ä½•PaddleSlimå­˜åœ¨çš„é—®é¢˜æˆ–è€…æ˜¯å»ºè®®, æ¬¢è¿é€šè¿‡&lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSlim/issues&#34;&gt;GitHub Issues&lt;/a&gt;ç»™æˆ‘ä»¬æissuesã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;æ¬¢è¿åŠ å…¥PaddleSlim å¾®ä¿¡æŠ€æœ¯äº¤æµç¾¤&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/54695910/199486336-11d661a7-6cbd-47b1-823c-3e4ac38bb7d5.jpg&#34; width=&#34;225&#34; height=&#34;225&#34;&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>facebookresearch/xformers</title>
    <updated>2022-11-26T01:36:11Z</updated>
    <id>tag:github.com,2022-11-26:/facebookresearch/xformers</id>
    <link href="https://github.com/facebookresearch/xformers" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Hackable and optimized Transformers building blocks, supporting a composable construction.&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/docs/assets/logo.png&#34; width=&#34;800&#34;&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://anaconda.org/xformers/xformers/badges/installer/conda.svg?sanitize=true&#34; alt=&#34;Install with conda&#34;&gt; &lt;img src=&#34;https://anaconda.org/xformers/xformers/badges/downloads.svg?sanitize=true&#34; alt=&#34;Downloads&#34;&gt; &lt;img src=&#34;https://anaconda.org/xformers/xformers/badges/license.svg?sanitize=true&#34; alt=&#34;License&#34;&gt; &lt;a href=&#34;https://colab.research.google.com/github/facebookresearch/xformers/blob/main/docs/source/xformers_mingpt.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt; &lt;br&gt;&#xA; &lt;!--&#xA;![PyPI](https://img.shields.io/pypi/v/xformers)&#xA;![PyPI - License](https://img.shields.io/pypi/l/xformers)&#xA;[![Documentation Status](https://github.com/facebookresearch/xformers/actions/workflows/gh-pages.yml/badge.svg)](https://github.com/facebookresearch/xformers/actions/workflows/gh-pages.yml/badge.svg)&#xA;--&gt; &lt;a href=&#34;https://app.circleci.com/pipelines/github/facebookresearch/xformers/&#34;&gt;&lt;img src=&#34;https://circleci.com/gh/facebookresearch/xformers.svg?style=shield&#34; alt=&#34;CircleCI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/facebookresearch/xformers&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/facebookresearch/xformers/branch/main/graph/badge.svg?token=PKGKDR4JQM&#34; alt=&#34;Codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/psf/black&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true&#34; alt=&#34;black&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/CONTRIBUTING.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?sanitize=true&#34; alt=&#34;PRs welcome&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!--&#xA;[![Downloads](https://pepy.tech/badge/xformers)](https://pepy.tech/project/xformers)&#xA;--&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;xFormers - Toolbox to Accelerate Research on Transformers&lt;/h2&gt; &#xA;&lt;p&gt;xFormers is:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Customizable building blocks&lt;/strong&gt;: Independant/customizable building blocks that can be used without boilerplate code. The components are domain-agnostic and xFormers is used by researchers in vision, NLP and more.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Research first&lt;/strong&gt;: xFormers contains bleeding-edge components, that are not yet available in mainstream libraries like pytorch.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Built with efficiency in mind&lt;/strong&gt;: Because speed of iteration matters, components are as fast and memory-efficient as possible. xFormers contains its own CUDA kernels, but dispatches to other libraries when relevant.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installing xFormers&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;(RECOMMENDED) Using binaries&lt;/strong&gt;: We provide binaries for Linux and recent PyTorch versions. After you have &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;installed pytorch in conda&lt;/a&gt;, install xFormers with conda:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda install xformers -c xformers/label/dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;From source&lt;/strong&gt;: Alternatively, if no binaries are available (for instance for windows), you can also install from source:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# (Optional) Makes the build much faster&#xA;pip install ninja&#xA;# Set TORCH_CUDA_ARCH_LIST if running and building on different GPU types&#xA;pip install -v -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers&#xA;# (this can take dozens of minutes)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;pip wheels&lt;/strong&gt;: There is no updated package available on pip, please install from conda or from source&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Results&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Memory-efficient MHA&lt;/strong&gt; &lt;img src=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/docs/plots/mha/mha_vit.png&#34; alt=&#34;Benchmarks for ViTS&#34;&gt; &lt;em&gt;Setup: A100 on f16, measured total time for a forward+backward pass&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Note that this is exact attention, not an approximation, just by calling &lt;a href=&#34;https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention&#34;&gt;&lt;code&gt;xformers.ops.memory_efficient_attention&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;More benchmarks&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;xFormers provides many components, and more benchmarks are available in &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/BENCHMARKS.md&#34;&gt;BENCHMARKS.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;(Optional) Testing the installation&lt;/h3&gt; &#xA;&lt;p&gt;This command will provide information on an xFormers installation, and what kernels are built/available:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python -m xformers.info&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Using xFormers&lt;/h2&gt; &#xA;&lt;h3&gt;Transformers key concepts&lt;/h3&gt; &#xA;&lt;p&gt;Let&#39;s start from a classical overview of the Transformer architecture (illustration from Lin et al,, &#34;A Survey of Transformers&#34;)&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/docs/assets/Transformer_arch_Lin_et_al.png&#34; width=&#34;600&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;You&#39;ll find the key repository boundaries in this illustration: a Transformer is generally made of a collection of attention mechanisms, embeddings to encode some positional information, feed-forward blocks and a residual path (typically referred to as pre- or post- layer norm). These boundaries do not work for all models, but we found in practice that given some accomodations it could capture most of the state of the art.&lt;/p&gt; &#xA;&lt;p&gt;Models are thus not implemented in monolithic files, which are typically complicated to handle and modify. Most of the concepts present in the above illustration correspond to an abstraction level, and when variants are present for a given sub-block it should always be possible to select any of them. You can focus on a given encapsulation level and modify it as needed.&lt;/p&gt; &#xA;&lt;h3&gt;Repo map&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;â”œâ”€â”€ ops                         # Functional operators&#xA;    â”” ...&#xA;â”œâ”€â”€ components                  # Parts zoo, any of which can be used directly&#xA;â”‚   â”œâ”€â”€ attention&#xA;â”‚   â”‚    â”” ...                  # all the supported attentions&#xA;â”‚   â”œâ”€â”€ feedforward             #&#xA;â”‚   â”‚    â”” ...                  # all the supported feedforwards&#xA;â”‚   â”œâ”€â”€ positional_embedding    #&#xA;â”‚   â”‚    â”” ...                  # all the supported positional embeddings&#xA;â”‚   â”œâ”€â”€ activations.py          #&#xA;â”‚   â””â”€â”€ multi_head_dispatch.py  # (optional) multihead wrap&#xA;|&#xA;â”œâ”€â”€ benchmarks&#xA;â”‚     â”” ...                     # A lot of benchmarks that you can use to test some parts&#xA;â””â”€â”€ triton&#xA;      â”” ...                     # (optional) all the triton parts, requires triton + CUDA gpu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt; Attention mechanisms&lt;/summary&gt;&#xA; &lt;p&gt; &lt;/p&gt;&#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/attention/scaled_dot_product.py&#34;&gt;Scaled dot product&lt;/a&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34;&gt;Attention is all you need, Vaswani et al., 2017&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/attention/scaled_dot_product.py&#34;&gt;Sparse&lt;/a&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;whenever a sparse enough mask is passed&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/attention/blocksparse.py&#34;&gt;BlockSparse&lt;/a&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;em&gt;courtesy of &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/www.triton-lang.org&#34;&gt;Triton&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/attention/linformer.py&#34;&gt;Linformer&lt;/a&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://arxiv.org/abs/2006.04768&#34;&gt;Linformer, self-attention with linear complexity, Wang et al., 2020&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/attention/nystrom.py&#34;&gt;Nystrom&lt;/a&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://arxiv.org/abs/2102.03902&#34;&gt;NystrÃ¶mformer: A NystrÃ¶m-Based Algorithm for Approximating Self-Attention, Xiong et al., 2021&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/attention/local.py&#34;&gt;Local&lt;/a&gt;. Notably used in (and many others)&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://arxiv.org/abs/2004.05150&#34;&gt;Longformer: The Long-Document Transformer, Beltagy et al., 2020&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.14062&#34;&gt;BigBird, Transformer for longer sequences, Zaheer et al., 2020&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/attention/favor.py&#34;&gt;Favor/Performer&lt;/a&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://arxiv.org/abs/2009.14794v1&#34;&gt;Rethinking Attention with Performers, Choromanski et al., 2020&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/attention/ortho.py&#34;&gt;Orthoformer&lt;/a&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.05392&#34;&gt;Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers, Patrick et al., 2021&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/attention/random.py&#34;&gt;Random&lt;/a&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;See BigBird, Longformers,..&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/attention/global_tokens.py&#34;&gt;Global&lt;/a&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;See BigBird, Longformers,..&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/attention/fourier_mix.py&#34;&gt;FourierMix&lt;/a&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://arxiv.org/abs/2105.03824v1&#34;&gt;FNet: Mixing Tokens with Fourier Transforms, Lee-Thorp et al.&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/attention/compositional.py&#34;&gt;CompositionalAttention&lt;/a&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://arxiv.org/pdf/2110.09419v1.pdf&#34;&gt;Compositional Attention: Disentangling search and retrieval, S. Mittal et al.&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/attention/pooling.py&#34;&gt;2D Pooling&lt;/a&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://arxiv.org/pdf/2111.11418v1.pdf&#34;&gt;Metaformer is actually what you need for vision, Yu et al.&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/attention/visual.py&#34;&gt;Visual Attention&lt;/a&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://arxiv.org/pdf/2202.09741.pdf&#34;&gt;&lt;code&gt;Visual Attention Network&lt;/code&gt;_, Guo et al&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;... add a new one &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/CONTRIBUTING.md&#34;&gt;see Contribution.md&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;&lt;/p&gt;&#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Feed forward mechanisms &lt;/summary&gt;&#xA; &lt;p&gt; &lt;/p&gt;&#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/feedforward/mlp.py&#34;&gt;MLP&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/feedforward/fused_mlp.py&#34;&gt;Fused&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/feedforward/mixture_of_experts.py&#34;&gt;Mixture of Experts&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/feedforward/conv_mlp.py&#34;&gt;Conv2DFeedforward&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;&lt;/p&gt;&#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Positional embedding &lt;/summary&gt;&#xA; &lt;p&gt; &lt;/p&gt;&#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/positional_embedding/sine.py&#34;&gt;Sine&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/positional_embedding/vocab.py&#34;&gt;Vocabulary&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/positional_embedding/rotary.py&#34;&gt;Rotary&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/components/simplicial_embedding.py&#34;&gt;Simplicial&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;&lt;/p&gt;&#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Residual paths &lt;/summary&gt;&#xA; &lt;p&gt; &lt;/p&gt;&#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2002.04745v1.pdf&#34;&gt;Pre&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2002.04745v1.pdf&#34;&gt;Post&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2203.00555v1.pdf&#34;&gt;DeepNorm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;&lt;/p&gt;&#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Initializations &lt;/summary&gt;&#xA; &lt;p&gt; This is completely optional, and will only occur when generating full models through xFormers, not when picking parts individually. &lt;/p&gt;&#xA; &lt;p&gt;There are basically two initialization mechanisms exposed, but the user is free to initialize weights as he/she sees fit after the fact.&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Parts can expose a &lt;code&gt;init_weights()&lt;/code&gt; method, which define sane defaults&lt;/li&gt; &#xA;  &lt;li&gt;xFormers supports &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/factory/weight_init.py&#34;&gt;specific init schemes&lt;/a&gt; which &lt;em&gt;can take precedence&lt;/em&gt; over the init_weights()&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;If the second code path is being used (construct model through the model factory), we check that all the weights have been initialized, and possibly error out if it&#39;s not the case (if you set &lt;code&gt;xformers.factory.weight_init.__assert_if_not_initialized = True&lt;/code&gt;)&lt;/p&gt; &#xA; &lt;p&gt;Supported initialization schemes are:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1910.05895&#34;&gt;Small init&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/rwightman/pytorch-image-models/raw/master/timm/models/vision_transformer.py&#34;&gt;Timm defaults&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/google-research/vision_transformer&#34;&gt;ViT defaults&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/moco-v3&#34;&gt;Moco v3 defaults&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;One way to specify the init scheme is to set the &lt;code&gt;config.weight_init&lt;/code&gt; field to the matching enum value. This could easily be extended, feel free to submit a PR !&lt;/p&gt; &#xA; &lt;p&gt;&lt;/p&gt;&#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Key Features&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Many attention mechanisms, interchangeables&lt;/li&gt; &#xA; &lt;li&gt;Optimized building blocks, beyond PyTorch primitives &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Memory-efficient exact attention - up to 10x faster&lt;/li&gt; &#xA;   &lt;li&gt;sparse attention&lt;/li&gt; &#xA;   &lt;li&gt;block-sparse attention&lt;/li&gt; &#xA;   &lt;li&gt;fused softmax&lt;/li&gt; &#xA;   &lt;li&gt;fused linear layer&lt;/li&gt; &#xA;   &lt;li&gt;fused layer norm&lt;/li&gt; &#xA;   &lt;li&gt;fused dropout(activation(x+bias))&lt;/li&gt; &#xA;   &lt;li&gt;fused SwiGLU&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;Benchmarking and testing tools &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/BENCHMARKS.md&#34;&gt;micro benchnmarks&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;transformer block benchmark&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/xformers/benchmarks/LRA/README.md&#34;&gt;LRA&lt;/a&gt;, with SLURM support&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;Programatic and sweep friendly layer and model construction &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Compatible with hierarchical Transformers, like Swin or Metaformer&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;Hackable &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Not using monolithic CUDA kernels, composable building blocks&lt;/li&gt; &#xA;   &lt;li&gt;Using &lt;a href=&#34;https://triton-lang.org/&#34;&gt;Triton&lt;/a&gt; for some optimized parts, explicit, pythonic and user-accessible&lt;/li&gt; &#xA;   &lt;li&gt;Native support for SquaredReLU (on top of ReLU, LeakyReLU, GeLU, ..), extensible activations&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Install troubleshooting&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;NVCC and the current CUDA runtime match. Depending on your setup, you may be able to change the CUDA runtime with &lt;code&gt;module unload cuda; module load cuda/xx.x&lt;/code&gt;, possibly also &lt;code&gt;nvcc&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;the version of GCC that you&#39;re using matches the current NVCC capabilities&lt;/li&gt; &#xA; &lt;li&gt;the &lt;code&gt;TORCH_CUDA_ARCH_LIST&lt;/code&gt; env variable is set to the architures that you want to support. A suggested setup (slow to build but comprehensive) is &lt;code&gt;export TORCH_CUDA_ARCH_LIST=&#34;6.0;6.1;6.2;7.0;7.2;7.5;8.0;8.6&#34;&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;If the build from source OOMs, it&#39;s possible to reduce the parallelism of ninja with &lt;code&gt;MAX_JOBS&lt;/code&gt; (eg &lt;code&gt;MAX_JOBS=2&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;If you encounter &lt;a href=&#34;https://github.com/facebookresearch/xformers/issues/390#issuecomment-1315020700&#34;&gt;&lt;code&gt;UnsatisfiableError&lt;/code&gt;&lt;/a&gt; when installing with conda, make sure you have pytorch installed in your conda environment, and that your setup (pytorch version, cuda version, python version, OS) match &lt;a href=&#34;https://anaconda.org/xformers/xformers/files&#34;&gt;an existing binary for xFormers&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;License&lt;/h3&gt; &#xA;&lt;p&gt;xFormers has a BSD-style license, as found in the &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/xformers/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt; &#xA;&lt;h2&gt;Citing xFormers&lt;/h2&gt; &#xA;&lt;p&gt;If you use xFormers in your publication, please cite it by using the following BibTeX entry.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@Misc{xFormers2022,&#xA;  author =       {Benjamin Lefaudeux and Francisco Massa and Diana Liskovich and Wenhan Xiong and Vittorio Caggiano and Sean Naren and Min Xu and Jieru Hu and Marta Tintore and Susan Zhang and Patrick Labatut and Daniel Haziza},&#xA;  title =        {xFormers: A modular and hackable Transformer modelling library},&#xA;  howpublished = {\url{https://github.com/facebookresearch/xformers}},&#xA;  year =         {2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;The following repositories are used in xFormers, either in close to original form or as an inspiration:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/google-research/sputnik&#34;&gt;Sputnik&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hgyhungry/ge-spmm&#34;&gt;GE-SpMM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/triton&#34;&gt;Triton&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lucidrains/reformer-pytorch&#34;&gt;LucidRain Reformer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/RobinBruegger/RevTorch&#34;&gt;RevTorch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mlpen/Nystromformer&#34;&gt;Nystromformer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/fairscale/&#34;&gt;FairScale&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rwightman/pytorch-image-models&#34;&gt;Pytorch Image Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nvidia/cutlass&#34;&gt;CUTLASS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/HazyResearch/flash-attention&#34;&gt;Flash-Attention&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>