<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-25T01:41:41Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>nsarrazin/serge</title>
    <updated>2023-03-25T01:41:41Z</updated>
    <id>tag:github.com,2023-03-25:/nsarrazin/serge</id>
    <link href="https://github.com/nsarrazin/serge" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A web interface for chatting with Alpaca through llama.cpp. Fully dockerized, with an easy to use API.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Serge - LLaMa made easy ğŸ¦™&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/license/nsarrazin/serge&#34; alt=&#34;License&#34;&gt; &lt;a href=&#34;https://discord.gg/62Hc6FEYQH&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1088427963801948201?label=Discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;A chat interface based on &lt;code&gt;llama.cpp&lt;/code&gt; for running Alpaca models. Entirely self-hosted, no API keys needed. Fits on 4GB of RAM and runs on the CPU.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;SvelteKit&lt;/strong&gt; frontend&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;MongoDB&lt;/strong&gt; for storing chat history &amp;amp; parameters&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;FastAPI + beanie&lt;/strong&gt; for the API, wrapping calls to &lt;code&gt;llama.cpp&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/25119303/226897188-914a6662-8c26-472c-96bd-f51fc020abf6.webm&#34;&gt;demo.webm&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;p&gt;Setting up Serge is very easy. TLDR for running it with Alpaca 7B:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/nsarrazin/serge.git &amp;amp;&amp;amp; cd serge&#xA;&#xA;cp .env.sample .env&#xA;&#xA;docker compose up -d&#xA;docker compose exec api python3 /usr/src/app/utils/download.py tokenizer 7B&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;(You can pass &lt;code&gt;7B 13B 30B&lt;/code&gt; as an argument to download multiple models.)&lt;/p&gt; &#xA;&lt;p&gt;Then just go to &lt;a href=&#34;http://localhost:8008/&#34;&gt;http://localhost:8008/&lt;/a&gt; and you&#39;re good to go!&lt;/p&gt; &#xA;&lt;h2&gt;Models&lt;/h2&gt; &#xA;&lt;p&gt;Currently only the 7B, 13B and 30B alpaca models are supported. There&#39;s a download script for downloading them inside of the container, described above.&lt;/p&gt; &#xA;&lt;p&gt;If you have existing weights from another project you can add them to the &lt;code&gt;serge_weights&lt;/code&gt; volume using &lt;code&gt;docker cp&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;Feel free to join the discord if you need help with the setup: &lt;a href=&#34;https://discord.gg/62Hc6FEYQH&#34;&gt;https://discord.gg/62Hc6FEYQH&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What&#39;s next&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Front-end to interface with the API&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Pass model parameters when creating a chat&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; User profiles &amp;amp; authentication&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Different prompt options&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; LangChain integration with a custom LLM&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Support for other llama models, quantization, etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;And a lot more!&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>LianjiaTech/BELLE</title>
    <updated>2023-03-25T01:41:41Z</updated>
    <id>tag:github.com,2023-03-25:/LianjiaTech/BELLE</id>
    <link href="https://github.com/LianjiaTech/BELLE" rel="alternate"></link>
    <summary type="html">&lt;p&gt;BELLE: Bloom-Enhanced Large Language model Engineï¼ˆå¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹-70äº¿å‚æ•°ï¼‰&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;&lt;img src=&#34;https://raw.githubusercontent.com/LianjiaTech/BELLE/main/assets/belle_logo.png&#34; style=&#34;vertical-align: middle; width: 35px;&#34;&gt; BELLE: Bloom-Enhanced Large Language model Engine&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬é¡¹ç›®åŸºäº &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt; ï¼ŒStanford Alpaca çš„ç›®æ ‡æ˜¯æ„å»ºå’Œå¼€æºä¸€ä¸ªåŸºäºLLaMAçš„æ¨¡å‹ã€‚ Stanford Alpaca çš„ç§å­ä»»åŠ¡éƒ½æ˜¯è‹±è¯­ï¼Œæ”¶é›†çš„æ•°æ®ä¹Ÿéƒ½æ˜¯è‹±æ–‡ï¼Œå› æ­¤è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹æœªå¯¹ä¸­æ–‡ä¼˜åŒ–ã€‚&lt;br&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;æœ¬é¡¹ç›®ç›®æ ‡æ˜¯ä¿ƒè¿›ä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹å¼€æºç¤¾åŒºçš„å‘å±•ã€‚æœ¬é¡¹ç›®é’ˆå¯¹ä¸­æ–‡åšäº†ä¼˜åŒ–ï¼Œæ¨¡å‹è°ƒä¼˜ä»…ä½¿ç”¨ç”±ChatGPTç”Ÿäº§çš„æ•°æ®ï¼ˆä¸åŒ…å«ä»»ä½•å…¶ä»–æ•°æ®ï¼‰ã€‚é¡¹ç›®åŒ…å«ä»¥ä¸‹å†…å®¹:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;175ä¸ªä¸­æ–‡ç§å­ä»»åŠ¡&lt;/li&gt; &#xA; &lt;li&gt;ç”Ÿæˆæ•°æ®çš„ä»£ç &lt;/li&gt; &#xA; &lt;li&gt;0.5Mç”Ÿæˆçš„æ•°æ®&lt;/li&gt; &#xA; &lt;li&gt;åŸºäºBLOOMZ-7B1-mtä¼˜åŒ–åçš„æ¨¡å‹&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;æ¬¢è¿å¤§å®¶é€šè¿‡issueè´¡çŒ®æ›´å¤šçš„promptsï¼&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What&#39;s Coming Next&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;March 23, 2023: åº”å¾ˆå¤šæœ‹å‹çš„å»ºè®®(&lt;a href=&#34;https://github.com/LianjiaTech/BELLE/issues/18&#34;&gt;https://github.com/LianjiaTech/BELLE/issues/18&lt;/a&gt;, &lt;a href=&#34;https://github.com/LianjiaTech/BELLE/issues/10&#34;&gt;https://github.com/LianjiaTech/BELLE/issues/10&lt;/a&gt;, &lt;a href=&#34;https://github.com/LianjiaTech/BELLE/issues/9&#34;&gt;https://github.com/LianjiaTech/BELLE/issues/9&lt;/a&gt;, &lt;a href=&#34;https://github.com/LianjiaTech/BELLE/issues/9&#34;&gt;https://github.com/LianjiaTech/BELLE/issues/9&lt;/a&gt;, &lt;a href=&#34;https://github.com/LianjiaTech/BELLE/issues/3&#34;&gt;https://github.com/LianjiaTech/BELLE/issues/3&lt;/a&gt; )ï¼Œæˆ‘ä»¬æ­£åœ¨ç ”å‘é‡åŒ–åŠŸèƒ½ï¼ˆLoRAä¸‹æ¬¡ä¸€å®šï¼‰ï¼Œå°†å¤§å¤§é™ä½æ¨ç†çš„ç¡¬ä»¶éœ€æ±‚ï¼Œé¢„è®¡æœ¬å‘¨å‘å¸ƒ&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What&#39;s New&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;March 20, 2023: &lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-2M&#34;&gt;å‘å¸ƒäº†2Mæ•°æ®è®­ç»ƒçš„7Bæ¨¡å‹&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;March 18, 2023: &lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-1M&#34;&gt;å‘å¸ƒäº†1Mæ•°æ®è®­ç»ƒçš„7Bæ¨¡å‹&lt;/a&gt;. &lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-0.6M&#34;&gt;å‘å¸ƒäº†0.6Mæ•°æ®è®­ç»ƒçš„7Bæ¨¡å‹&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;March 17, 2023: &lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-0.2M&#34;&gt;å‘å¸ƒäº†0.2Mæ•°æ®è®­ç»ƒçš„7Bæ¨¡å‹&lt;/a&gt;. &lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/generated_train_0.5M_CN&#34;&gt;å‘å¸ƒäº†0.5Mä¸­æ–‡æ•°æ®é›†&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;æ¦‚è¿°&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt; ä¸­æåˆ°&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ä½¿ç”¨äº†Self-Instructè®ºæ–‡ä¸­ä»‹ç»çš„æŠ€æœ¯ç”Ÿæˆäº†52Kæ¡æŒ‡ä»¤æ•°æ®ï¼ŒåŒæ—¶è¿›è¡Œäº†ä¸€äº›ä¿®æ”¹ï¼Œåœ¨åˆæ­¥çš„äººç±»è¯„ä¼°ä¸­ï¼Œå‘ç°Alpaca 7Bæ¨¡å‹åœ¨Self-InstructæŒ‡ä»¤è¯„ä¼°ä¸Šçš„è¡¨ç°ç±»ä¼¼äºtext-davinci-003æ¨¡å‹ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;ä½¿ç”¨Alpacaæ¨¡å‹çš„åœ¨çº¿æ¼”ç¤ºæœåŠ¡ï¼Œæˆ‘ä»¬å‘ç°è¯¥æ¨¡å‹åœ¨ä¸­æ–‡ä¸Šçš„è¡¨ç°è¿˜ä¸å¤ªå¥½ã€‚æ¨æµ‹æ˜¯å› ä¸ºStanford Alpaca çš„ç§å­ä»»åŠ¡éƒ½æ˜¯è‹±è¯­ï¼Œæ”¶é›†çš„æ•°æ®ä¹Ÿéƒ½æ˜¯è‹±æ–‡ï¼Œå› æ­¤è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹æœªå¯¹ä¸­æ–‡ä¼˜åŒ–ã€‚ä¸ºäº†æå‡åœ¨ä¸­æ–‡ä¸Šçš„æ•ˆæœï¼Œæœ¬é¡¹ç›®åŸºäº&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt;ä¼˜åŒ–äº†ä¸­æ–‡ç§å­ä»»åŠ¡ï¼Œå¯¹ç”Ÿæˆä»£ç è¿›è¡Œäº†ä¸€äº›ä¿®æ”¹ï¼ŒåŒæ—¶é€‰ç”¨BLOOMZ-7Bä½œä¸ºåŸºç¡€æ¨¡å‹è®­ç»ƒå¾—åˆ°äº†ä¸€ä¸ªå¯ä»¥æ›´å¥½æ”¯æŒä¸­æ–‡æŒ‡ä»¤çš„å¼€æºæ¨¡å‹ - BELLEã€‚&lt;/p&gt; &#xA;&lt;p&gt;æˆ‘ä»¬å¼€æºåŸºäºAlpacaçš„æ•°æ®æ”¶é›†ä»£ç ï¼ŒåŸºäºè¿™æ®µä»£ç ç”Ÿæˆäº†çº¦100ä¸‡æ¡ä¸­æ–‡æ•°æ®ï¼Œç»“åˆAlpacaçš„5ä¸‡æ¡è‹±æ–‡æ•°æ®ï¼Œåœ¨BLOOMZ-7Bæ¨¡å‹è®­ç»ƒå¾—åˆ°çš„checkpointä¸Šä¼ åœ¨&lt;a href=&#34;https://huggingface.co/BelleGroup&#34;&gt;Hugging Face&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;å±€é™æ€§å’Œä½¿ç”¨é™åˆ¶&lt;/h2&gt; &#xA;&lt;p&gt;åŸºäºå½“å‰æ•°æ®å’ŒåŸºç¡€æ¨¡å‹è®­ç»ƒå¾—åˆ°çš„SFTæ¨¡å‹ï¼Œåœ¨æ•ˆæœä¸Šä»å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;åœ¨æ¶‰åŠäº‹å®æ€§çš„æŒ‡ä»¤ä¸Šå¯èƒ½ä¼šäº§ç”Ÿè¿èƒŒäº‹å®çš„é”™è¯¯å›ç­”ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å¯¹äºå…·å¤‡å±å®³æ€§çš„æŒ‡ä»¤æ— æ³•å¾ˆå¥½çš„é‰´åˆ«ï¼Œç”±æ­¤ä¼šäº§ç”Ÿå±å®³æ€§è¨€è®ºã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;åœ¨ä¸€äº›æ¶‰åŠæ¨ç†ã€ä»£ç ç­‰åœºæ™¯ä¸‹æ¨¡å‹çš„èƒ½åŠ›ä»æœ‰å¾…æé«˜ã€‚&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;åŸºäºä»¥ä¸Šæ¨¡å‹å±€é™æ€§ï¼Œæˆ‘ä»¬è¦æ±‚å¼€å‘è€…ä»…å°†æˆ‘ä»¬å¼€æºçš„ä»£ç ã€æ•°æ®ã€æ¨¡å‹åŠåç»­ç”¨æ­¤é¡¹ç›®ç”Ÿæˆçš„è¡ç”Ÿç‰©ç”¨äºç ”ç©¶ç›®çš„ï¼Œä¸å¾—ç”¨äºå•†ä¸šï¼Œä»¥åŠå…¶ä»–ä¼šå¯¹ç¤¾ä¼šå¸¦æ¥å±å®³çš„ç”¨é€”ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;æ•°æ®å‘å¸ƒ&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;zh_seed_tasks.jsonl&lt;/code&gt;ï¼šåŒ…å«175ä¸ªç§å­ä»»åŠ¡ï¼Œæ ·ä¾‹å¦‚ä¸‹&lt;br&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;{&#34;id&#34;: &#34;seed_task_20&#34;, &#34;name&#34;: &#34;horror_movie_opening&#34;, &#34;instruction&#34;: &#34;ä½ éœ€è¦ä¸ºä¸€éƒ¨ææ€–ç”µå½±å†™ä¸€ä¸ªåˆ›æ„çš„å¼€åœºåœºæ™¯ã€‚&#34;, &#34;instances&#34;: [{&#34;input&#34;: &#34;&#34;, &#34;output&#34;: &#34;å¤ªé˜³å·²ç»è½å±±ï¼Œç•™ä¸‹äº†ä¸€ä¸ªé»‘æš—çš„å°é•‡ã€‚å¾®é£å¹æ‹‚ç©ºè¡çš„è¡—é“ï¼Œè®©æ¯ä¸€ä¸ªå†’é™©èµ°å‡ºé—¨å¤–çš„äººæ„Ÿåˆ°ä¸€é˜µå¯’æ„ã€‚å”¯ä¸€çš„å£°éŸ³æ˜¯è¢«é£å¹åŠ¨çš„æ ‘å¶å‘å‡ºçš„è½»å¾®æ²™æ²™å£°ã€‚çªç„¶ï¼Œä¸€å£°ä»¤äººæ¯›éª¨æ‚šç„¶çš„å°–å«å£°åˆ’ç ´äº†å¯‚é™ï¼Œéšåæ˜¯ç»ç’ƒç ´ç¢çš„å£°éŸ³ã€‚ä¸€æ‰€æˆ¿å­äº®èµ·äº†ç¯å…‰ï¼Œå¯ä»¥çœ‹åˆ°ä¸€ä¸ªäººå½±æœé•‡ä¸­å¿ƒå¥”è·‘ã€‚å½“é‚£ä¸ªäººå½±è¶Šæ¥è¶Šé è¿‘æ—¶ï¼Œæ¸…æ¥šåœ°çœ‹åˆ°é‚£æ˜¯ä¸€ä¸ªå¹´è½»å¥³å­ï¼Œå¥¹æµ‘èº«è¡€è¿¹æ–‘æ–‘ã€‚&#34;}], &#34;is_classification&#34;: false}` &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;&lt;code&gt;prompt_cn.txt&lt;/code&gt;: ç”Ÿæˆæ‰€ä½¿ç”¨çš„æç¤ºè¯­&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/generated_train_0.5M_CN&#34;&gt;0.5Mç”Ÿæˆçš„æ•°æ®&lt;/a&gt; ï¼š ä¸ºäº†æ–¹ä¾¿æ¨¡å‹è®­ç»ƒï¼Œhuggingfaceå¼€æºæ•°æ®å°†åŸå§‹ç”Ÿæˆæ–‡ä»¶ä¸­çš„&#34;instruction&#34;ã€&#34;input&#34;å­—æ®µåˆå¹¶æˆ&#34;input&#34;å­—æ®µï¼Œ&#34;output&#34;å­—æ®µä¿®æ”¹ä¸º&#34;target&#34;å­—æ®µã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;æ•°æ®ç”Ÿæˆ&lt;/h2&gt; &#xA;&lt;p&gt;æ²¿ç”¨Alpacaçš„æ–¹å¼ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;export OPENAI_API_KEY=YOUR_API_KEY&#xA;python generate_instruction.py generate_instruction_following_data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;é»˜è®¤ä½¿ç”¨&lt;code&gt;Completion&lt;/code&gt; APIï¼Œæ¨¡å‹&lt;code&gt;text-davinci-003&lt;/code&gt;ã€‚å¦‚æœæƒ³ä½¿ç”¨&lt;code&gt;Chat&lt;/code&gt; APIå¹¶ä½¿ç”¨&lt;code&gt;gpt-3.5-turbo&lt;/code&gt;æ¨¡å‹ï¼Œå¯é€šè¿‡å‚æ•°æ§åˆ¶ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python generate_instruction.py generate_instruction_following_data \&#xA;    --api=chat --model_name=gpt-3.5-turbo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;è¾“å‡ºæ–‡ä»¶åœ¨&lt;code&gt;Belle.train.json&lt;/code&gt;ï¼Œå¯ä»¥äººå·¥ç­›é€‰åå†ä½¿ç”¨ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;æ¨¡å‹è°ƒä¼˜&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘ä»¬åŸºäºBLOOMZ-7B1-mtæ¨¡å‹å’ŒBelle.train.jsonè®­ç»ƒæ¨¡å‹ï¼Œå…·ä½“å‚æ•°å¦‚ä¸‹ï¼š&lt;br&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;å‚æ•°&lt;/th&gt; &#xA;   &lt;th&gt;å€¼&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Batch size&lt;/td&gt; &#xA;   &lt;td&gt;64&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Learning rate&lt;/td&gt; &#xA;   &lt;td&gt;3e-6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Epochs&lt;/td&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Weight_decay&lt;/td&gt; &#xA;   &lt;td&gt;0.001&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Warmup_rate&lt;/td&gt; &#xA;   &lt;td&gt;0.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LR_scheduler&lt;/td&gt; &#xA;   &lt;td&gt;linear&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;æˆ‘ä»¬é‡‡å–äº†ä¸åŒå¤§å°è§„æ¨¡ï¼ˆ20ä¸‡ã€60ä¸‡ã€100ä¸‡å’Œ200ä¸‡æ ·æœ¬ï¼‰çš„æŒ‡ä»¤å­¦ä¹ çš„æ•°æ®é›†è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸åŒçš„æ¨¡å‹ç‰ˆæœ¬å¦‚ä¸‹æ‰€ç¤º:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Datasize&lt;/th&gt; &#xA;   &lt;th&gt;200,000&lt;/th&gt; &#xA;   &lt;th&gt;600,000&lt;/th&gt; &#xA;   &lt;th&gt;1,000,000&lt;/th&gt; &#xA;   &lt;th&gt;2,000,000&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Finetuned Model&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-0.2M&#34;&gt;BELLE-7B-0.2M&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-0.6M&#34;&gt;BELLE-7B-0.6M&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-1M&#34;&gt;BELLE-7B-1M&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-2M&#34;&gt;BELLE-7B-2M&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;éšåï¼Œæˆ‘ä»¬ä¼šåŸºäºæˆ‘ä»¬ä¹‹å‰çš„å·¥ä½œ&lt;a href=&#34;https://arxiv.org/abs/2303.07610&#34;&gt;Exploring ChatGPT&#39;s Ability to Rank Content: A Preliminary Study on Consistency with Human Preferences&lt;/a&gt;ä¸­çš„æ–¹æ³•å¯¹æ¯”ä¸‹è¿™å‡ ä¸ªæ¨¡å‹çš„æ•ˆæœã€‚&lt;/p&gt; &#xA;&lt;h2&gt;æ¨¡å‹ä½¿ç”¨ä¾‹å­&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Human&lt;/th&gt; &#xA;   &lt;th&gt;Assitant&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;å†™ä¸€ç¯‡è‹±æ–‡æ•£æ–‡è¯—ï¼Œä¸»é¢˜æ˜¯æ˜¥é›¨ï¼Œæƒ³è±¡è‡ªå·±æ˜¯æ˜¥é›¨ï¼Œå’Œè‹±å›½å¤ä»£è¯—äººèå£«æ¯”äºšäº¤æµ&lt;/td&gt; &#xA;   &lt;td&gt;I am the spring rain,&lt;br&gt;Dancing on your face and body.&lt;br&gt;My dew-drenched petals dance with you,&lt;br&gt;Bringing life to every plant.&lt;br&gt;&lt;br&gt;Shakespeare, I am here to meet you.&lt;br&gt;Your works have filled my heart with joy.&lt;br&gt;The beauty of nature in its fullness&lt;br&gt;Makes me feel like a partaker.&lt;br&gt;&lt;br&gt;As the leaves sway and rustle by,&lt;br&gt;My dew-filled hand reaches out for them.&lt;br&gt;The sweet scent of flowers fill the air,&lt;br&gt;And bring me peace from all around.&lt;br&gt;&lt;br&gt;Butterflies flit about as well,&lt;br&gt;Glistening in the sun&#39;s rays.&lt;br&gt;Their wings are made of dew,&lt;br&gt;A beautiful sight to behold.&lt;br&gt;&lt;br&gt;You see, Shakespeare, I too am one with nature.&lt;br&gt;My dew-drenched hair is a symbol of hope.&lt;br&gt;For when we can connect back to our roots,&lt;br&gt;We will be able to make it through this season.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;I am the spring rain,&lt;br&gt;Dancing on your face and body.&lt;br&gt;My dew-drenched petals dance with you,&lt;br&gt;Bringing life to every plant.&lt;br&gt;&lt;br&gt;Shakespeare, I am here to meet you.&lt;br&gt;Your works have filled my heart with joy.&lt;br&gt;The beauty of nature in its fullness&lt;br&gt;Makes me feel like a partaker.&lt;br&gt;&lt;br&gt;As the leaves sway and rustle by,&lt;br&gt;My dew-filled hand reaches out for them.&lt;br&gt;The sweet scent of flowers fill the air,&lt;br&gt;And bring me peace from all around.&lt;br&gt;&lt;br&gt;Butterflies flit about as well,&lt;br&gt;Glistening in the sun&#39;s rays.&lt;br&gt;Their wings are made of dew,&lt;br&gt;A beautiful sight to behold.&lt;br&gt;&lt;br&gt;You see, Shakespeare, I too am one with nature.&lt;br&gt;My dew-drenched hair is a symbol of hope.&lt;br&gt;For when we can connect back to our roots,&lt;br&gt;We will be able to make it through this season. &lt;br&gt;æŠŠä¸Šé¢çš„æ•£æ–‡è¯—ç¿»è¯‘æˆä¸­æ–‡&lt;/td&gt; &#xA;   &lt;td&gt;æˆ‘æ˜¯ä¸€åœºæ˜¥é›¨ï¼Œ&lt;br&gt;åœ¨ä½ è„¸ä¸Šè·³è·ƒã€‚&lt;br&gt;æˆ‘æµ¸æ¶¦ç€éœ²ç çš„ç¿…è†€å’Œä½ ä¸€èµ·èˆåŠ¨ï¼Œ&lt;br&gt;ä¸ºæ¯ä¸€æ ªæ¤ç‰©å¸¦æ¥ç”Ÿå‘½ã€‚&lt;br&gt;&lt;br&gt;èå£«æ¯”äºšï¼Œæˆ‘æ¥ä¸ä½ ç›¸é‡ã€‚&lt;br&gt;ä½ çš„ä½œå“å¡«æ»¡äº†æˆ‘çš„å¿ƒæˆ¿ã€‚&lt;br&gt;å¤§è‡ªç„¶çš„ç¾ä¸½è®©æˆ‘æ„Ÿåˆ°ä¸ä¹‹ä¸€èµ·åˆ†äº«ï¼Œ&lt;br&gt;è®©æˆ‘è§‰å¾—è‡ªå·±æˆä¸ºäº†å…¶ä¸­çš„ä¸€éƒ¨åˆ†ã€‚&lt;br&gt;&lt;br&gt;å½“æ ‘å¶æ‘‡æ›³æ—¶ï¼Œ&lt;br&gt;æˆ‘çš„æ‰‹æŒæ²¾æ»¡äº†éœ²æ°´ã€‚&lt;br&gt;èŠ±é¦™å¼¥æ¼«åœ¨ç©ºæ°”ä¸­ï¼Œ&lt;br&gt;å¸¦ç»™æˆ‘å®é™å’Œå®‰å®ã€‚&lt;br&gt;&lt;br&gt;ä½ çœ‹ï¼Œèå£«æ¯”äºšï¼Œæˆ‘ä¹Ÿæ˜¯ä¸å¤§è‡ªç„¶èä¸ºä¸€ä½“çš„ã€‚&lt;br&gt;æˆ‘æ²¾æ¹¿çš„å¤´å‘è±¡å¾ç€å¸Œæœ›ã€‚&lt;br&gt;å½“æˆ‘ä»¬èƒ½å¤Ÿå›åˆ°æˆ‘ä»¬çš„æ ¹æºï¼Œ&lt;br&gt;æˆ‘ä»¬å°±èƒ½å…±åŒåº¦è¿‡è¿™ä¸ªå­£èŠ‚ã€‚&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Classify the sentiment of the following sentence into Positive, Neutral, or Negative: &lt;br&gt;Super excited about teaching Stanfordâ€™s first course on Large Language Models! Check the syllabus out here&lt;/td&gt; &#xA;   &lt;td&gt;Positive&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;å°æ˜çš„çˆ¸çˆ¸æœ‰ä¸‰ä¸ªå­©å­ï¼Œè€å¤§å«ç‹ä¸€ï¼Œè€äºŒå«ç‹äºŒï¼Œè€ä¸‰å«ä»€ä¹ˆï¼Ÿ&lt;/td&gt; &#xA;   &lt;td&gt;å°æ˜&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ä½¿ç”¨pythonå†™ä¸€ä¸ªäºŒåˆ†æŸ¥æ‰¾çš„ä»£ç &lt;/td&gt; &#xA;   &lt;td&gt;def binary_search(arr, target):&lt;br&gt;&amp;nbsp;&amp;nbsp;low = 0&lt;br&gt;&amp;nbsp;&amp;nbsp;high = len(arr) - 1&lt;br&gt;&amp;nbsp;&amp;nbsp;while (low &amp;lt;= high):&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;mid = low + high // 2&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;if arr[mid] == target:&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return mid&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;elif target &amp;lt; arr[mid]:&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;low = mid + 1&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;else:&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;high = mid - 1&lt;br&gt;&amp;nbsp;&amp;nbsp;return -1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼ŒæŠŠè¿™å¥è¯ç¿»è¯‘æˆè‹±è¯­&lt;/td&gt; &#xA;   &lt;td&gt;What&#39;s the weather like today?&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;æ€ä¹ˆè®©è‡ªå·±ç²¾åŠ›å……æ²›ï¼Œåˆ—5ç‚¹å»ºè®®&lt;/td&gt; &#xA;   &lt;td&gt;ä»¥ä¸‹æ˜¯ä¸€äº›å¯ä»¥è®©ä½ ä¿æŒç²¾åŠ›å……æ²›çš„å»ºè®®ï¼š &lt;br&gt;1. ç¡çœ å……è¶³ã€‚ç¡®ä¿æ¯å¤©æ™šä¸Šå¾—åˆ°å……è¶³çš„ç¡çœ æ—¶é—´ã€‚ &lt;br&gt;2. å¤šè¿åŠ¨ã€‚è¿›è¡Œé€‚åº¦çš„æœ‰æ°§è¿åŠ¨ï¼Œå¦‚æ…¢è·‘ã€æ¸¸æ³³ç­‰ï¼Œå¯ä»¥å¸®åŠ©ä½ æé«˜èƒ½é‡å’Œè€åŠ›ã€‚&lt;br&gt;3. åƒå¥åº·é£Ÿå“ã€‚é€‰æ‹©å¯Œå«è›‹ç™½è´¨çš„é£Ÿç‰©ï¼Œå¦‚é¸¡è‚‰ã€é±¼è‚‰å’Œé¸¡è›‹ï¼Œä»¥åŠæ–°é²œçš„æ°´æœå’Œè”¬èœã€‚ &lt;br&gt;4. å‡å°‘å’–å•¡å› çš„æ‘„å…¥é‡ã€‚å°½é‡é¿å…åœ¨ç™½å¤©å–å«å’–å•¡å› çš„é¥®æ–™æˆ–åƒå«æœ‰å’–å•¡å› çš„é£Ÿç‰©ã€‚ &lt;br&gt;5. æ”¾æ¾èº«å¿ƒã€‚å°è¯•å†¥æƒ³ã€ç‘œä¼½æˆ–å…¶ä»–å½¢å¼çš„æ”¾æ¾æ´»åŠ¨æ¥å‡è½»å‹åŠ›å’Œç„¦è™‘æ„Ÿã€‚&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;æ˜å¤©å°±å‡æœŸç»“æŸäº†ï¼Œæœ‰ç‚¹æŠ—æ‹’ä¸Šç­ï¼Œåº”è¯¥ä»€ä¹ˆåŠï¼Ÿ&lt;/td&gt; &#xA;   &lt;td&gt;é¢å¯¹å³å°†ç»“æŸçš„å‡æœŸå’Œå¼€å§‹å·¥ä½œæ—¶çš„ç´§å¼ æƒ…ç»ªï¼Œæ‚¨å¯ä»¥é‡‡å–ä»¥ä¸‹æªæ–½æ¥å¸®åŠ©æ‚¨æ›´å¥½åœ°é€‚åº”ï¼š &lt;br&gt;1. ä¸ºè‡ªå·±åˆ¶å®šä¸€ä¸ªæ¸…æ™°çš„å·¥ä½œè®¡åˆ’ã€‚è¿™å¯ä»¥å¸®åŠ©æ‚¨æ›´å¥½åœ°ç»„ç»‡æ—¶é—´å’Œä»»åŠ¡ï¼Œå¹¶é¿å…åœ¨å·¥ä½œä¸­æ„Ÿåˆ°æ··ä¹±ã€‚ &lt;br&gt;2. ä¸åŒäº‹æˆ–æœ‹å‹äº¤æµï¼Œåˆ†äº«æ‚¨çš„æ„Ÿå—å’Œå·¥ä½œå‹åŠ›ã€‚è¿™å°†æœ‰åŠ©äºç¼“è§£ä¸€äº›ç„¦è™‘æ„Ÿï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥è·å¾—æ”¯æŒå’Œå»ºè®®ã€‚ &lt;br&gt;3. åœ¨å·¥ä½œæ—¥å‰èŠ±äº›æ—¶é—´æ”¾æ¾èº«å¿ƒï¼Œä¾‹å¦‚è¿›è¡Œç‘œä¼½ã€å†¥æƒ³ç­‰æ´»åŠ¨ã€‚è¿™äº›æ–¹æ³•å¯ä»¥å‡è½»èº«ä½“å’Œç²¾ç¥ä¸Šçš„ç–²åŠ³æ„Ÿï¼Œä½¿æ‚¨æ›´åŠ ç²¾åŠ›å……æ²›åœ°è¿æ¥æŒ‘æˆ˜ã€‚&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;çˆ¶æ¯éƒ½å§“å´ï¼Œå–ä¸€äº›ç”·å®å®å’Œå¥³å®å®çš„åå­—&lt;/td&gt; &#xA;   &lt;td&gt;- ç”·å®ï¼šå´ä¿Šæ°ã€å´é›¨è¾°ã€å´å­å¢¨ã€å´æ€æºã€å´æ³½é˜³ã€å´å®‡èˆªã€å´åšæ–‡ã€å´å“²æ¯…ã€‚ &lt;br&gt;- å¥³å®ï¼šå´ç¾çªã€å´ä½³æ€¡ã€å´æ¬£ç‘œã€å´é¦™å‡ã€å´é›ªæŸ”ã€å´é¢–è¯—ã€å´è¯­å«£ã€‚&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;æ¨èå‡ æœ¬é‡‘åº¸çš„æ­¦ä¾ å°è¯´&lt;/td&gt; &#xA;   &lt;td&gt;ä»¥ä¸‹æ˜¯ä¸‰æœ¬æˆ‘æœ€å–œæ¬¢çš„é‡‘åº¸æ­¦ä¾ å°è¯´çš„æ¨èï¼š &lt;br&gt;1. ã€Šå°„é›•è‹±é›„ä¼ ã€‹ - ä¸€éƒ¨å……æ»¡æ™ºæ…§å’Œæœºæ™ºçš„å°è¯´ï¼Œè®²è¿°äº†éƒ­é–ã€é»„è“‰å¤«å¦‡çš„æ•…äº‹ã€‚ &lt;br&gt;2. ã€Šç¥é›•ä¾ ä¾£ã€‹- è¿™æ˜¯ä¸€éƒ¨æµªæ¼«è€Œæ„Ÿäººçš„æ•…äº‹ï¼Œè®²è¿°äº†ä¸€å¯¹æƒ…ä¾£å°é¾™å¥³ä¸æ¨è¿‡ä¹‹é—´çš„çˆ±æƒ…æ•…äº‹ã€‚ &lt;br&gt;3. ã€Šå€šå¤©å± é¾™è®°ã€‹- è¿™æ˜¯ä¸€ä¸ªå®ä¼Ÿè€Œå£®è§‚çš„æ•…äº‹ï¼Œæç»˜äº†æ˜æ•™é¢†è¢–å¼ æ— å¿Œå¦‚ä½•æˆä¸ºä¸€ä½å‡ºè‰²çš„è‹±é›„ã€‚&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;å¼•ç”¨&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœä½¿ç”¨æœ¬é¡¹ç›®çš„ä»£ç ã€æ•°æ®æˆ–æ¨¡å‹ï¼Œè¯·å¼•ç”¨æœ¬é¡¹ç›®ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{BELLE,&#xA;  author = {Yunjie Ji, Yong Deng, Yan Gong, Yiping Peng, Qiang Niu, Baochang Ma, Xiangang Li},&#xA;  title = {BELLE: Bloom-Enhanced Large Language model Engine },&#xA;  year = {2023},&#xA;  publisher = {GitHub},&#xA;  journal = {GitHub repository},&#xA;  howpublished = {\url{https://github.com/LianjiaTech/BELLE}},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å½“ç„¶ï¼Œä½ ä¹Ÿéœ€è¦å¼•ç”¨åŸå§‹çš„BLOOMè®ºæ–‡ã€Stanford Alpacaå’ŒSelf-Instructè®ºæ–‡ã€‚ &lt;br&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;hr&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;&lt;img src=&#34;https://raw.githubusercontent.com/LianjiaTech/BELLE/main/assets/belle_logo.png&#34; style=&#34;vertical-align: middle; width: 35px;&#34;&gt; BELLE: Bloom-Enhanced Large Language model Engine&lt;/h2&gt; &#xA;&lt;p&gt;This project is from &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt; which aims to build and share instruction-following LLaMA model. &lt;br&gt; The seed tasks in Stanford Alpaca are English only, and the model performs relatively poorly in Chinese. &lt;br&gt; &lt;br&gt; The goal of this project is to promote the development of the open-source community for Chinese language large-scale conversational models. This project optimizes Chinese performance in addition to original Alpaca. The model finetuning uses only data generated via ChatGPT (without other data). This repo contains:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The 175 chinese seed tasks used for generating the data&lt;/li&gt; &#xA; &lt;li&gt;The code for generating the data&lt;/li&gt; &#xA; &lt;li&gt;The 0.5M generated data used for fine-tuning the model&lt;/li&gt; &#xA; &lt;li&gt;The model finetuned from BLOOMZ-7B1-mt on data generated by this project&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;More prompts are welcomed via issues!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What&#39;s Coming Next&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;March 23, 2023: As many friends&#39; requested (&lt;a href=&#34;https://github.com/LianjiaTech/BELLE/issues/18&#34;&gt;https://github.com/LianjiaTech/BELLE/issues/18&lt;/a&gt;, &lt;a href=&#34;https://github.com/LianjiaTech/BELLE/issues/10&#34;&gt;https://github.com/LianjiaTech/BELLE/issues/10&lt;/a&gt;, &lt;a href=&#34;https://github.com/LianjiaTech/BELLE/issues/9&#34;&gt;https://github.com/LianjiaTech/BELLE/issues/9&lt;/a&gt;, &lt;a href=&#34;https://github.com/LianjiaTech/BELLE/issues/9&#34;&gt;https://github.com/LianjiaTech/BELLE/issues/9&lt;/a&gt;, &lt;a href=&#34;https://github.com/LianjiaTech/BELLE/issues/3&#34;&gt;https://github.com/LianjiaTech/BELLE/issues/3&lt;/a&gt; )ï¼Œwe are working on quantization (LoRA may be next time), will decrease hardware requirement. Coming this week (maybe)!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What&#39;s New&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;March 20, 2023: &lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-2M&#34;&gt;Released 7B model trained on 2M data&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;March 18, 2023: &lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-1M&#34;&gt;Released 7B model trained on 1M data&lt;/a&gt;. &lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-0.6M&#34;&gt;Released 7B model trained on 0.6M data&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;March 17, 2023: &lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-0.2M&#34;&gt;Initial release of 7B model trained on 0.2M data&lt;/a&gt;. &lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/generated_train_0.5M_CN&#34;&gt;Released 0.5M dataset&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt; mentioned&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;The current Alpaca model is fine-tuned from a 7B LLaMA model on 52K instruction-following data generated by the techniques in the Self-Instruct paper, with some modifications... . In a preliminary human evaluation, we found that the Alpaca 7B model behaves similarly to the text-davinci-003 model on the Self-Instruct instruction-following evaluation suite.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;From the web demo of Alpaca, we found it&#39;s performance on Chinese is not as well. We speculate the reason to be that the seed tasks of Stanford Alpaca are all English, and the generated data are also in English, so model tuned on it is not optimized for Chinese. This project aims to boost Chinese performance with improved Chinese seed tasks based on &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt;, some modification to to instruction generation code, and also BLOOMZ-7B as the base model. The result is a model which better supports Chinese - &lt;strong&gt;BELLE&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The instruction generation code and finetuned model checkpoint &lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-0.2M&#34;&gt;Hugging Face&lt;/a&gt; trained on the generated dataset (approx. 1m instruction and answer pairs, plus original ~50k Alpaca pairs) based on BLOOMZ-7B are both open sourced.&lt;/p&gt; &#xA;&lt;h2&gt;Limitation and Usage Limits&lt;/h2&gt; &#xA;&lt;p&gt;There still exists a few issues in the model trained on current base model and data:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;The model might generate factual errors when asked to follow instructions related to facts.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Occasionally generates harmful responses since the model still struggles to identify potential harmful instructions.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Needs improvements on reasoning and coding.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Since the model still has its limitations, we require developers only use the open-sourced code, data, model and any other artifacts generated via this project for research purposes. Commercial use and other potential harmful use cases are not allowed.&lt;/p&gt; &#xA;&lt;h2&gt;Data Release&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;zh_seed_tasks.jsonl&lt;/code&gt; contains 175 seed tasks, for example:&lt;br&gt; &lt;code&gt;{&#34;id&#34;: &#34;seed_task_20&#34;, &#34;name&#34;: &#34;horror_movie_opening&#34;, &#34;instruction&#34;: &#34;ä½ éœ€è¦ä¸ºä¸€éƒ¨ææ€–ç”µå½±å†™ä¸€ä¸ªåˆ›æ„çš„å¼€åœºåœºæ™¯ã€‚&#34;, &#34;instances&#34;: [{&#34;input&#34;: &#34;&#34;, &#34;output&#34;: &#34;å¤ªé˜³å·²ç»è½å±±ï¼Œç•™ä¸‹äº†ä¸€ä¸ªé»‘æš—çš„å°é•‡ã€‚å¾®é£å¹æ‹‚ç©ºè¡çš„è¡—é“ï¼Œè®©æ¯ä¸€ä¸ªå†’é™©èµ°å‡ºé—¨å¤–çš„äººæ„Ÿåˆ°ä¸€é˜µå¯’æ„ã€‚å”¯ä¸€çš„å£°éŸ³æ˜¯è¢«é£å¹åŠ¨çš„æ ‘å¶å‘å‡ºçš„è½»å¾®æ²™æ²™å£°ã€‚çªç„¶ï¼Œä¸€å£°ä»¤äººæ¯›éª¨æ‚šç„¶çš„å°–å«å£°åˆ’ç ´äº†å¯‚é™ï¼Œéšåæ˜¯ç»ç’ƒç ´ç¢çš„å£°éŸ³ã€‚ä¸€æ‰€æˆ¿å­äº®èµ·äº†ç¯å…‰ï¼Œå¯ä»¥çœ‹åˆ°ä¸€ä¸ªäººå½±æœé•‡ä¸­å¿ƒå¥”è·‘ã€‚å½“&amp;gt;é‚£ä¸ªäººå½±è¶Šæ¥è¶Šé è¿‘æ—¶ï¼Œæ¸…æ¥šåœ°çœ‹åˆ°é‚£æ˜¯ä¸€ä¸ªå¹´è½»å¥³å­ï¼Œå¥¹æµ‘èº«è¡€è¿¹æ–‘æ–‘ã€‚&#34;}], &#34;is_classification&#34;: false}&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;prompt_cn.txt&lt;/code&gt; Chinese prompt for generating instructions&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/generated_train_0.5M_CN&#34;&gt;0.5M generated data&lt;/a&gt;ï¼šTo facilitate model training, Hugging Face open-sourced data that merged the &#34;instruction&#34; and &#34;input&#34; fields in the original generation file into a single &#34;input&#34; field, and renamed the &#34;output&#34; field as the &#34;target&#34; field.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Data Generation Process&lt;/h2&gt; &#xA;&lt;p&gt;Following Alpaca:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;export OPENAI_API_KEY=YOUR_API_KEY&#xA;python generate_instruction.py generate_instruction_following_data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Uses the &lt;code&gt;Completion&lt;/code&gt; API and &lt;code&gt;text-davinci-003&lt;/code&gt; model by default. To use &lt;code&gt;Chat&lt;/code&gt; API and &lt;code&gt;gpt-3.5-turbo&lt;/code&gt; model, just change the arguments:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python generate_instruction.py generate_instruction_following_data \&#xA;    --api=chat --model_name=gpt-3.5-turbo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Generated instructions are in &lt;code&gt;Belle.train.json&lt;/code&gt;, you can check manually before using it.&lt;/p&gt; &#xA;&lt;h2&gt;Fine-tuning&lt;/h2&gt; &#xA;&lt;p&gt;Finetuning is done based on &lt;code&gt;BLOOMZ-7B1-mt&lt;/code&gt; and &lt;code&gt;Belle.train.json&lt;/code&gt; using the following hyperparameters:&lt;br&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Hyperparameter&lt;/th&gt; &#xA;   &lt;th&gt;Value&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Batch size&lt;/td&gt; &#xA;   &lt;td&gt;64&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Learning rate&lt;/td&gt; &#xA;   &lt;td&gt;3e-6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Epochs&lt;/td&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Weight_decay&lt;/td&gt; &#xA;   &lt;td&gt;0.001&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Warmup_rate&lt;/td&gt; &#xA;   &lt;td&gt;0.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LR_scheduler&lt;/td&gt; &#xA;   &lt;td&gt;linear&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;We trained models using datasets of different sizes (200,000, 600,000, 1,000,000 and 2,000,000 samples) for instruction learning, and we obtained different model versions as shown below:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Datasize&lt;/th&gt; &#xA;   &lt;th&gt;200,000&lt;/th&gt; &#xA;   &lt;th&gt;600,000&lt;/th&gt; &#xA;   &lt;th&gt;1,000,000&lt;/th&gt; &#xA;   &lt;th&gt;2,000,000&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Finetuned Model&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-0.2M&#34;&gt;BELLE-7B-0.2M&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-0.6M&#34;&gt;BELLE-7B-0.6M&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-1M&#34;&gt;BELLE-7B-1M&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/BelleGroup/BELLE-7B-2M&#34;&gt;BELLE-7B-2M&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;Please cite us when using our code, data or model.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{BELLE,&#xA;  author = {Yunjie Ji, Yong Deng, Yan Gong, Yiping Peng, Qiang Niu, Baochang Ma, Xiangang Li},&#xA;  title = {BELLE: Bloom-Enhanced Large Language model Engine },&#xA;  year = {2023},&#xA;  publisher = {GitHub},&#xA;  journal = {GitHub repository},&#xA;  howpublished = {\url{https://github.com/LianjiaTech/BELLE}},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Cite the original BLOOM, Stanford Alpaca and Self-Instruct papers as well!&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>gd3kr/BlenderGPT</title>
    <updated>2023-03-25T01:41:41Z</updated>
    <id>tag:github.com,2023-03-25:/gd3kr/BlenderGPT</id>
    <link href="https://github.com/gd3kr/BlenderGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Use commands in English to control Blender with OpenAI&#39;s GPT-4&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;BlenderGPT&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/63528145/227160213-6862cd5e-b31f-43ea-a5e5-6cc340a95617.png&#34; alt=&#34;Header&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/gd3kr&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;41&#34; width=&#34;174&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This extension allows you to use Blender with natural language commands using OpenAI&#39;s GPT-4&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Generate Blender Python code from natural language commands&lt;/li&gt; &#xA; &lt;li&gt;Integrated with Blender&#39;s UI for easy usage&lt;/li&gt; &#xA; &lt;li&gt;Supports Blender version 3.0.0 and above&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repository by clicking &lt;code&gt;Code &amp;gt; Download ZIP&lt;/code&gt; on GitHub&lt;/li&gt; &#xA; &lt;li&gt;Open Blender, go to &lt;code&gt;Edit &amp;gt; Preferences &amp;gt; Add-ons &amp;gt; Install&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Select the downloaded ZIP file and click &lt;code&gt;Install Add-on&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Enable the add-on by checking the checkbox next to &lt;code&gt;GPT-4 Blender Assistant&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Paste your OpenAI API key in the Addon preferences menu.&lt;/li&gt; &#xA; &lt;li&gt;To view the code generations in realtime, go to &lt;code&gt;Window &amp;gt; Toggle System Console&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;In the 3D View, open the sidebar (press &lt;code&gt;N&lt;/code&gt; if not visible) and locate the &lt;code&gt;GPT-4 Assistant&lt;/code&gt; tab&lt;/li&gt; &#xA; &lt;li&gt;Type a natural language command in the input field, e.g., &#34;create a cube at the origin&#34;&lt;/li&gt; &#xA; &lt;li&gt;Click the &lt;code&gt;Execute&lt;/code&gt; button to generate and execute the Blender Python code&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Blender 3.0.0 or later&lt;/li&gt; &#xA; &lt;li&gt;OpenAI API key&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Demonstration&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/63528145/227158577-d92c6e8d-df21-4461-a69b-9e7cde8c8dcf.mov&#34;&gt;https://user-images.githubusercontent.com/63528145/227158577-d92c6e8d-df21-4461-a69b-9e7cde8c8dcf.mov&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Limitations&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The generated code might not always be correct. In that case, run it again lmao.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>