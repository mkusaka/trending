<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-08T01:44:09Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>WPeace-HcH/WPeChatGPT</title>
    <updated>2023-03-08T01:44:09Z</updated>
    <id>tag:github.com,2023-03-08:/WPeace-HcH/WPeChatGPT</id>
    <link href="https://github.com/WPeace-HcH/WPeChatGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A plugin for IDA that can help to analyze binary file and it uses OpenAI&#39;s ChatGPT training API.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;WPeChatGPT&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;A plugin for IDA&lt;/strong&gt; that can help to analyze binary file, it based on Gepetto which uses OpenAI&#39;s davinci-003 model.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å½“å‰ &lt;em&gt;WPeChatGPT&lt;/em&gt; æ”¯æŒçš„&lt;strong&gt;åŠŸèƒ½&lt;/strong&gt;åŒ…æ‹¬ï¼š&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;åˆ†æå‡½æ•°çš„ä½¿ç”¨ç¯å¢ƒã€é¢„æœŸç›®çš„ã€å‡½æ•°åŠŸèƒ½ã€‚&lt;/li&gt; &#xA;   &lt;li&gt;é‡å‘½åå‡½æ•°çš„å˜é‡ã€‚&lt;/li&gt; &#xA;   &lt;li&gt;å°è¯•ç”¨ python3 å¯¹å‡½æ•°è¿›è¡Œè¿˜åŸï¼Œæ­¤åŠŸèƒ½ä¸»è¦æ˜¯é’ˆå¯¹è¾ƒå°å—çš„å‡½æ•°ï¼ˆå¦‚ä¸€ä¸ªå¼‚æˆ–è§£å¯†å‡½æ•°ï¼‰ã€‚&lt;/li&gt; &#xA;   &lt;li&gt;åœ¨å½“å‰å‡½æ•°ä¸­æŸ¥æ‰¾æ˜¯å¦å­˜åœ¨æ¼æ´ã€‚&lt;/li&gt; &#xA;   &lt;li&gt;å°è¯•ç”¨ python å¯¹æ¼æ´å‡½æ•°ç”Ÿæˆå¯¹åº”çš„ EXPã€‚&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;WPeChatGPT&lt;/em&gt; æ’ä»¶ä½¿ç”¨çš„æ˜¯ OpenAI åŸºäºGPTè®­ç»ƒçš„ &lt;strong&gt;text-davinci-003&lt;/strong&gt; æ¨¡å‹ã€‚&lt;br&gt; &lt;em&gt;v2.0&lt;/em&gt; ç‰ˆæœ¬åä½¿ç”¨ OpenAI æœ€æ–°çš„ &lt;strong&gt;gpt-3.5-turbo&lt;/strong&gt; æ¨¡å‹ï¼ˆThe same as &lt;strong&gt;ChatGPT&lt;/strong&gt;ï¼‰ã€‚&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;ChatGPT çš„åˆ†æç»“æœ&lt;strong&gt;ä»…ä¾›å‚è€ƒ&lt;/strong&gt;ï¼Œä¸ç„¶æˆ‘ä»¬è¿™äº›åˆ†æå¸ˆå°±å½“åœºå¤±ä¸šäº†ã€‚XD&lt;/p&gt; &#xA;&lt;h2&gt;æ›´æ–°å†å²&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Version&lt;/th&gt; &#xA;   &lt;th&gt;Date&lt;/th&gt; &#xA;   &lt;th&gt;Comment&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.0&lt;/td&gt; &#xA;   &lt;td&gt;2023-02-28&lt;/td&gt; &#xA;   &lt;td&gt;Based on Gepetto.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.1&lt;/td&gt; &#xA;   &lt;td&gt;2023-03-02&lt;/td&gt; &#xA;   &lt;td&gt;1. åˆ é™¤åˆ†æåŠ è§£å¯†çš„åŠŸèƒ½ã€‚&lt;br&gt;2. å¢åŠ  python è¿˜åŸå‡½æ•°çš„åŠŸèƒ½ã€‚&lt;br&gt;3. ä¿®æ”¹äº†ä¸€äº›ç»†èŠ‚ã€‚&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1.2&lt;/td&gt; &#xA;   &lt;td&gt;2023-03-03&lt;/td&gt; &#xA;   &lt;td&gt;1. å¢åŠ æŸ¥æ‰¾å‡½æ•°ä¸­äºŒè¿›åˆ¶æ¼æ´çš„åŠŸèƒ½ã€‚&lt;br&gt;2. å¢åŠ å°è¯•è‡ªåŠ¨ç”Ÿæˆå¯¹åº” EXP çš„åŠŸèƒ½ã€‚&lt;br&gt;3. ä¿®æ”¹äº†ä¸€äº›ç»†èŠ‚ã€‚&lt;br&gt;ï¼ˆç”±äºOpenAIæœåŠ¡å™¨å¡é¡¿åŸå› æœªæµ‹è¯•ä¸Šä¼ ï¼‰&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.0&lt;/td&gt; &#xA;   &lt;td&gt;2023-03-06&lt;/td&gt; &#xA;   &lt;td&gt;1. å®Œæˆæµ‹è¯• &lt;em&gt;v1.2&lt;/em&gt; ç‰ˆæœ¬æ¼æ´ç›¸å…³åŠŸèƒ½ã€‚&lt;br&gt;2. æ”¹ç”¨ OpenAI æœ€æ–°å‘å¸ƒçš„ &lt;strong&gt;gpt-3.5-turbo&lt;/strong&gt; æ¨¡å‹ã€‚&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.1&lt;/td&gt; &#xA;   &lt;td&gt;2023-03-07&lt;/td&gt; &#xA;   &lt;td&gt;Fix API problem about timed out.ï¼ˆè¯¦è§èŠ‚&lt;em&gt;&lt;strong&gt;å…³äº OpenAI-API æŠ¥é”™&lt;/strong&gt;&lt;/em&gt;ï¼‰&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;å®‰è£…&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;è¿è¡Œå¦‚ä¸‹å‘½ä»¤å®‰è£…æ‰€éœ€åŒ…ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r ./requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;ä¿®æ”¹è„šæœ¬ &lt;code&gt;WPeChatGPT.py&lt;/code&gt; æ·»åŠ  API key åˆ°å˜é‡ &lt;em&gt;&lt;strong&gt;openai.api_key&lt;/strong&gt;&lt;/em&gt;ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å¤åˆ¶è„šæœ¬æ–‡ä»¶ &lt;code&gt;WPeChatGPT.py&lt;/code&gt; åˆ° IDA çš„ plugins æ–‡ä»¶å¤¹, æœ€åé‡å¯ IDA åå³å¯ä½¿ç”¨ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;! NOTE&lt;/code&gt;&lt;/strong&gt;ï¼šéœ€è¦æŠŠ &lt;strong&gt;IDA çš„ç¯å¢ƒ&lt;/strong&gt;è®¾ç½®ä¸º &lt;strong&gt;python3&lt;/strong&gt;ï¼ŒWPeChatGPT &lt;em&gt;2.0&lt;/em&gt; ç‰ˆæœ¬åéœ€è¦ä½¿ç”¨&lt;strong&gt;æœ€æ–°çš„ OpenAI Python åŒ…&lt;/strong&gt;ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ä½¿ç”¨æ–¹æ³•&lt;/h2&gt; &#xA;&lt;p&gt;æ”¯æŒåœ¨ IDA ä¸­ä½¿ç”¨&lt;strong&gt;å³é”®ã€èœå•æ æˆ–å¿«æ·é”®&lt;/strong&gt;ä»»ä¸€ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;å¿«æ·é”®ï¼š&lt;br&gt; &lt;code&gt;å‡½æ•°åˆ†æ = &#34;Ctrl-Alt-G&#34;&lt;/code&gt;&lt;br&gt; &lt;code&gt;é‡å‘½åå‡½æ•°å˜é‡ = &#34;Ctrl-Alt-R&#34;&lt;/code&gt;&lt;br&gt; &lt;code&gt;äºŒè¿›åˆ¶æ¼æ´æŸ¥æ‰¾ = &#34;Ctrl-Alt-E&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ä¼ªä»£ç çª—å£å³é”®ï¼š&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;â€ƒâ€ƒ&lt;img src=&#34;https://github.com/WPeace-HcH/WPeChatGPT/raw/main/IMG/menuInPseudocode.png&#34; width=&#34;788&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;èœå•æ ï¼šEdit $\Rightarrow$ WPeChatGPT&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;â€ƒâ€ƒ&lt;img src=&#34;https://github.com/WPeace-HcH/WPeChatGPT/raw/main/IMG/menuInEdit.png&#34; width=&#34;360&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ç¤ºä¾‹&lt;/h2&gt; &#xA;&lt;p&gt;ä½¿ç”¨æ–¹å¼ï¼š&lt;/p&gt; &#xA;&lt;p&gt;â€ƒâ€ƒ&lt;img src=&#34;https://github.com/WPeace-HcH/WPeChatGPT/raw/main/IMG/useExample.gif&#34; width=&#34;790&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;å‡½æ•°åˆ†ææ•ˆæœå±•ç¤ºï¼š&lt;/p&gt; &#xA;&lt;p&gt;â€ƒâ€ƒ&lt;img src=&#34;https://github.com/WPeace-HcH/WPeChatGPT/raw/main/IMG/resultExample.gif&#34; width=&#34;790&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;äºŒè¿›åˆ¶æ¼æ´æŸ¥æ‰¾æ•ˆæœå±•ç¤ºï¼š&lt;/p&gt; &#xA;&lt;p&gt;â€ƒâ€ƒ&lt;img src=&#34;https://github.com/WPeace-HcH/WPeChatGPT/raw/main/IMG/vulnExample.gif&#34; width=&#34;790&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;å…³äº OpenAI-API æŠ¥é”™&lt;/h2&gt; &#xA;&lt;p&gt;â€ƒâ€ƒä» 2023.3.2 å¼€å§‹æˆ‘ç»å¸¸é‡åˆ° API æŠ¥é”™ï¼Œå¼€å§‹ä»¥ä¸ºæ˜¯æœåŠ¡å™¨ä¸ç¨³å®šçš„é—®é¢˜ï¼ˆå› ä¸ºåœ¨æˆ‘è¿™é‡Œæ—¶å¥½æ—¶åï¼‰ï¼Œä½†æ˜¯ç”±äºæœ‰å¤ªå¤šåé¦ˆè¯´éƒ½é‡åˆ°äº†ç›¸å…³é”™è¯¯ï¼Œæ‰€ä»¥æˆ‘å…ˆå»äº† OpenAI æŸ¥çœ‹ API Status ä¹‹åå‘ç°å…¶è¿è¡Œæƒ…å†µè‰¯å¥½ï¼Œå› æ­¤å‘ç°å¯èƒ½å¹¶ä¸æ˜¯æˆ‘æ‰€æƒ³çš„æœåŠ¡å™¨é—®é¢˜ï¼Œäºæ˜¯è¿›è¡Œäº†ç›¸å…³é—®é¢˜çš„æœç´¢åŠè°ƒè¯•ï¼Œä»¥ä¸‹æ˜¯æˆ‘å¯¹ OpenAI API è¿æ¥é—®é¢˜çš„å¤„ç†æ–¹æ³•ï¼š&lt;/p&gt; &#xA;&lt;p&gt;â€ƒâ€ƒé¦–å…ˆå‰æï¼Œæ’ä»¶å·²ç»åœ¨&lt;strong&gt;ç§‘å­¦ä¸Šç½‘&lt;/strong&gt;çš„æ¡ä»¶ä¸‹è¿è¡Œã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;åœ¨ç§‘å­¦ä¸Šç½‘çš„æ¡ä»¶ä¸‹ï¼Œå¦‚æœå‘ç°æ’ä»¶å¤šæ¬¡å°è¯•éƒ½æ— æ³•æ­£å¸¸è¿æ¥ APIï¼Œé‚£ä¹ˆéœ€è¦æŸ¥è¯¢ä¸€ä¸‹ python çš„ urllib3 ç‰ˆæœ¬ï¼ˆ1.26 ç‰ˆæœ¬å­˜åœ¨ä»£ç†é—®é¢˜ï¼‰ã€‚ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;å¯ä»¥ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤å¯¹ urllib3 è¿›è¡Œå›é€€ä¿®å¤ï¼š&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code&gt;pip uninstall urllib3&#xA;pip install urllib3==1.25.11&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;å¦‚æœ urllib3 ç‰ˆæœ¬æ²¡é”™æˆ–é‡è£… 1.25 ç‰ˆæœ¬è¿˜æ˜¯å­˜åœ¨ API è®¿é—®é—®é¢˜çš„è¯ï¼Œé‚£ä¹ˆè¯·ä¸‹è½½æœ€æ–°ç‰ˆæœ¬ï¼Œå¯¹æ’ä»¶æŒ‡å®šä»£ç†ï¼š &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;å°†ä¸‹é¢ä¸‰è¡Œä»£ç å–æ¶ˆæ³¨é‡Šï¼Œç„¶åæŠŠä»£ç†åœ°å€åŠç«¯å£ä¿¡æ¯å¡«å…¥ &lt;em&gt;&lt;strong&gt;proxies&lt;/strong&gt;&lt;/em&gt; å˜é‡å³å¯ï¼š&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code&gt;#print(&#34;WPeChatGPT has appointed the proxy.&#34;)&#xA;#proxies = {&#39;http&#39;: &#34;http://127.0.0.1:7890&#34;, &#39;https&#39;: &#34;http://127.0.0.1:7890&#34;}&#xA;#openai.proxy = proxies&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;è”ç³»æˆ‘&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœä½¿ç”¨æ’ä»¶æ—¶é‡åˆ°é—®é¢˜æˆ–æœ‰ä»»ä½•ç–‘é—®ï¼Œæ¬¢è¿ç•™è¨€æˆ–å‘é€é‚®ä»¶è”ç³»æˆ‘ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;The project is based on &lt;em&gt;Gepetto&lt;/em&gt; and inspired by it, you can visit &lt;a href=&#34;https://github.com/JusticeRage/Gepetto&#34;&gt;https://github.com/JusticeRage/Gepetto&lt;/a&gt; to learn about the original method.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>QiuChenly/QQFlacMusicDownloader</title>
    <updated>2023-03-08T01:44:09Z</updated>
    <id>tag:github.com,2023-03-08:/QiuChenly/QQFlacMusicDownloader</id>
    <link href="https://github.com/QiuChenly/QQFlacMusicDownloader" rel="alternate"></link>
    <summary type="html">&lt;p&gt;[ç§‹åŸè½å¶] QQ éŸ³ä¹æºæ— æŸæ­Œæ›²ä¸‹è½½&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;é¡¹ç›®ä»‹ç»&lt;/h1&gt; &#xA;&lt;p&gt;Create &amp;amp; Design By QiuChenly.&lt;/p&gt; &#xA;&lt;p&gt;è¿™æ˜¯ä¸€ä¸ªæ‰¹é‡ä¸‹è½½ QQ éŸ³ä¹/é…·æˆ‘éŸ³ä¹/ç½‘æ˜“äº‘ä¼šå‘˜æ— æŸéŸ³è´¨æ­Œæ›²çš„è„šæœ¬,æŠ€æœ¯å«é‡å¹¶ä¸æ˜¯å¾ˆå¤§,ä»…ä¾›å‚è€ƒã€‚&lt;/p&gt; &#xA;&lt;p&gt;æç¤ºï¼šç”±äºQQéŸ³ä¹æ¥å£è®¿é—®é¢‘ç‡é™åˆ¶ æœ‰æ—¶å€™æ­Œæ›²è·å–ä¸åˆ° å¤šåˆ·æ–°å‡ æ¬¡å°±å¥½äº†&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;å‰ç«¯æŠ€æœ¯: Vue3+TS+Pinia+ElementUI Plus&#xA;&#xA;åç«¯æŠ€æœ¯: Python3.9 + Flask + Concurrencyåç¨‹&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;ä½¿ç”¨æ–¹æ³•&lt;/h1&gt; &#xA;&lt;h3&gt;å¦‚æœä½ éœ€è¦ç”Ÿæˆ requirements.txt æ–‡ä»¶&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install pipreqs # å®‰è£…&#xA;pipreqs ./ --encoding=utf8 --force # åœ¨æ–‡ä»¶å¤¹ä¸­æ‰§è¡Œ&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;1. å®‰è£…ç¯å¢ƒ&lt;/h3&gt; &#xA;&lt;p&gt;é¦–å…ˆå®‰è£…æœ€æ–°çš„ python3 åˆ°ä½ çš„æ“ä½œç³»ç»Ÿé‡Œã€‚&lt;/p&gt; &#xA;&lt;p&gt;ä»¥ä¸‹æ‰€æœ‰æ“ä½œçš†é»˜è®¤å‡è®¾å½“å‰ç›®å½•åœ¨(Windows) D:/Downloads/QQFlacDownloader/ æˆ–è€…(Unix/Linux) ~/Download/QQFlacDownloader/&lt;/p&gt; &#xA;&lt;p&gt;å¦‚æœå®‰è£…ä¾èµ–åŒ…å‡ºç° 404 é”™è¯¯æˆ–è€…å¤ªæ…¢ï¼Œå¯ä»¥ç”¨ä¸‹é¢çš„ä»£ç åˆ‡æ¢åˆ°æ¸…åå¤§å­¦æœåŠ¡å™¨å®‰è£…ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# è®¾ç½®pythonçš„ä¾èµ–å®‰è£…é•œåƒæœåŠ¡å™¨ä¸ºæ¸…åå¤§å­¦æœåŠ¡å™¨&#xA;# &#xA;pip3 config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip3 install -r requirements.txt # å®‰è£…è½¯ä»¶ä¾èµ–å¿…é¡»åŒ…&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. è¿›å…¥è½¯ä»¶åŒ…ç›®å½•ä¸‹å¯åŠ¨è½¯ä»¶&lt;/h3&gt; &#xA;&lt;p&gt;ç»ˆç«¯/æ§åˆ¶å° è¿›å…¥åˆ°æœ¬æ–‡ä»¶æ‰€åœ¨çš„ç›®å½• æ‰§è¡Œä»¥ä¸‹æŒ‡ä»¤:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 MainServer.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å¯åŠ¨ååº”è¯¥èƒ½çœ‹åˆ°è¿™äº›ä¿¡æ¯ï¼Œå³è¡¨ç¤ºä½ å¯åŠ¨æˆåŠŸã€‚ &lt;img src=&#34;https://raw.githubusercontent.com/QiuChenly/QQFlacMusicDownloader/main/img_1.png&#34; alt=&#34;img_1.png&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;ç„¶ågoogle chromeä¹‹ç±»çš„æµè§ˆå™¨æ‰“å¼€&lt;a href=&#34;http://127.0.0.1:8899&#34;&gt;http://127.0.0.1:8899&lt;/a&gt;å³å¯æ‰“å¼€æ–°ä¸–ç•Œ&lt;/p&gt; &#xA;&lt;h1&gt;æ–°ç‰¹æ€§&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;åŠŸèƒ½&lt;/th&gt; &#xA;   &lt;th&gt;çŠ¶æ€&lt;/th&gt; &#xA;   &lt;th&gt;é™„åŠ è¯´æ˜&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ç½‘æ˜“äº‘ä¼šå‘˜æ­Œæ›²è§£æä¸‹è½½&lt;/td&gt; &#xA;   &lt;td&gt;å·²å®Œæˆ&lt;/td&gt; &#xA;   &lt;td&gt;ç‰ˆæƒé—®é¢˜ç°è‰²æ­Œæ›²æ²¡æœ‰CDNèµ„æºç¼“å­˜ æ— æ³•ä¸‹è½½&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;é…·æˆ‘éŸ³ä¹æ— æŸéŸ³è´¨ä¸‹è½½&lt;/td&gt; &#xA;   &lt;td&gt;å·²å®Œæˆ&lt;/td&gt; &#xA;   &lt;td&gt;éƒ¨åˆ†æ²¡æœ‰flacéŸ³è´¨ç‰ˆæœ¬çš„æ­Œæ›²å¯èƒ½æ— æ³•ä¸‹è½½&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;QQéŸ³ä¹æ— æŸä¼šå‘˜/é«˜è§£æåº¦æ— æŸä¸‹è½½&lt;/td&gt; &#xA;   &lt;td&gt;å·²å®Œæˆ&lt;/td&gt; &#xA;   &lt;td&gt;ç¬¬ä¸‰æ–¹æœåŠ¡å™¨å¥½åƒå·²ç»æŒ‚äº† ä¼°è®¡è¿™ä¸ªæœåŠ¡å™¨qqè¢«å°äº† æš‚æ—¶ç”¨ä¸äº† æœç´¢ä¸åˆ°æ­Œæ›²çš„è¯å¤šæœç´¢å‡ æ¬¡æˆ–è€…æ¢é…·æˆ‘æ¥å£&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;åŸºäºwebçš„å‹å¥½ç•Œé¢å‡ºæ¥å•¦&lt;/p&gt; &#xA;&lt;h2&gt;&lt;img src=&#34;https://raw.githubusercontent.com/QiuChenly/QQFlacMusicDownloader/main/md/media/img_2.png&#34; alt=&#34;img_2.png&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/QiuChenly/QQFlacMusicDownloader/main/md/media/img_3.png&#34; alt=&#34;img_3.png&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/QiuChenly/QQFlacMusicDownloader/main/md/media/img_1.png&#34; alt=&#34;img_1.png&#34;&gt;&lt;/h2&gt; &#xA;&lt;h1&gt;å£°æ˜&lt;/h1&gt; &#xA;&lt;p&gt;æœ¬ä»£ç  GPLV3 æˆæƒä½¿ç”¨ï¼Œç¦æ­¢å•†ä¸šç”¨é€”ï¼Œä»…ä¾›ç ”ç©¶å­¦ä¹  python æŠ€æœ¯ä½¿ç”¨ï¼Œä¸å¾—ä½¿ç”¨æœ¬ä»£ç è¿›è¡Œä»»ä½•å½¢å¼çš„ç‰Ÿåˆ©/è´©å–/ä¼ æ’­ï¼Œç¦æ­¢åœ¨ qq ç¾¤ä¼ æ’­ï¼Œæœ¬é¡¹ç›®ä»…ä¾›ä¸ªäººç§ä¸‹ç ”ç©¶å­¦ä¹ ä½¿ç”¨ï¼Œè¯·æ”¯æŒ QQ æ­£ç‰ˆéŸ³ä¹ï¼&lt;/p&gt; &#xA;&lt;p&gt;ä¸‹è½½çš„éŸ³ä¹æ–‡ä»¶åœ¨è¯•å¬åè¯·åœ¨ 24 å°æ—¶å†…åˆ é™¤ï¼Œè°¢è°¢ï¼ ä»…é™åœ¨ä¸­å›½å¤§é™†çš„å®ªæ³•è®¸å¯æƒ…å†µä¸‹ä½¿ç”¨ï¼Œç”¨æˆ·é€ æˆçš„ä¸€åˆ‡æ³•å¾‹è´£ä»»ä¸åæœéƒ½ç”±æ‚¨è‡ªå·±ç‹¬è‡ªæ‰¿æ‹…ï¼Œä½œè€…æ¦‚ä¸è´Ÿè´£ï¼&lt;/p&gt; &#xA;&lt;p&gt;æœ¬é¡¹ç›®ä»…é™ç ”ç©¶äº¤æµå­¦ä¹ ä½¿ç”¨ã€‚&lt;/p&gt; &#xA;&lt;h1&gt;å…¶ä»–èµ„æ–™&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/QiuChenly/QQFlacMusicDownloader/main/md/README.md&#34;&gt;æ—©æœŸæ¥å£ QMD Apkçš„é€†å‘è¿‡ç¨‹&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>gligen/GLIGEN</title>
    <updated>2023-03-08T01:44:09Z</updated>
    <id>tag:github.com,2023-03-08:/gligen/GLIGEN</id>
    <link href="https://github.com/gligen/GLIGEN" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Open-Set Grounded Text-to-Image Generation&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GLIGEN: Open-Set Grounded Text-to-Image Generation (CVPR 2023)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://yuheng-li.github.io/&#34;&gt;Yuheng Li&lt;/a&gt;, &lt;a href=&#34;https://hliu.cc&#34;&gt;Haotian Liu&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.ca/citations?user=HDiw-TsAAAAJ&amp;amp;hl=en/&#34;&gt;Qingyang Wu&lt;/a&gt;, &lt;a href=&#34;https://pages.cs.wisc.edu/~fmu/&#34;&gt;Fangzhou Mu&lt;/a&gt;, &lt;a href=&#34;https://jwyang.github.io/&#34;&gt;Jianwei Yang&lt;/a&gt;, &lt;a href=&#34;https://www.microsoft.com/en-us/research/people/jfgao/&#34;&gt;Jianfeng Gao&lt;/a&gt;, &lt;a href=&#34;https://chunyuan.li/&#34;&gt;Chunyuan Li*&lt;/a&gt;, &lt;a href=&#34;https://pages.cs.wisc.edu/~yongjaelee/&#34;&gt;Yong Jae Lee*&lt;/a&gt; (*Co-senior authors)&lt;/p&gt; &#xA;&lt;p&gt;[&lt;a href=&#34;https://gligen.github.io/&#34;&gt;Project Page&lt;/a&gt;] [&lt;a href=&#34;https://arxiv.org/abs/2301.07093&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/spaces/gligen/demo&#34;&gt;Demo&lt;/a&gt;] [&lt;a href=&#34;https://youtu.be/-MCkU7IAGKs&#34;&gt;YouTube Video&lt;/a&gt;] &lt;img src=&#34;https://raw.githubusercontent.com/gligen/GLIGEN/master/figures/concept.gif&#34; alt=&#34;Teaser figure&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/-MCkU7IAGKs&#34;&gt;&lt;img src=&#34;https://github.com/gligen/GLIGEN/raw/master/figures/teaser_v4.png&#34; alt=&#34;IMAGE ALT TEXT HERE&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Go beyond text prompt with GLIGEN: enable new capabilities on frozen text-to-image generation models to ground on various prompts, including box, keypoints and images.&lt;/li&gt; &#xA; &lt;li&gt;GLIGENâ€™s zero-shot performance on COCO and LVIS outperforms that of existing supervised layout-to-image baselines by a large margin.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;span&gt;ğŸ”¥&lt;/span&gt; News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.03.05]&lt;/strong&gt; Gradio demo code is released at &lt;a href=&#34;https://github.com/gligen/GLIGEN/tree/master/demo&#34;&gt;&lt;code&gt;GLIGEN/demo&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.03.03]&lt;/strong&gt; Code base and checkpoints are released.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.02.28]&lt;/strong&gt; Paper is accepted to CVPR 2023.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.01.17]&lt;/strong&gt; GLIGEN paper and demo is released.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;We provide &lt;a href=&#34;https://raw.githubusercontent.com/gligen/GLIGEN/master/env_docker/Dockerfile&#34;&gt;dockerfile&lt;/a&gt; to setup environment.&lt;/p&gt; &#xA;&lt;h2&gt;Download GLIGEN models&lt;/h2&gt; &#xA;&lt;p&gt;We provide five checkpoints for different use scenarios. All models here are based on SD-V-1.4.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Mode&lt;/th&gt; &#xA;   &lt;th&gt;Modality&lt;/th&gt; &#xA;   &lt;th&gt;Download&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Generation&lt;/td&gt; &#xA;   &lt;td&gt;Box+Text&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/gligen/gligen-generation-text-box/blob/main/diffusion_pytorch_model.bin&#34;&gt;HF Hub&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Generation&lt;/td&gt; &#xA;   &lt;td&gt;Box+Text+Image&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/gligen/gligen-generation-text-image-box/blob/main/diffusion_pytorch_model.bin&#34;&gt;HF Hub&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Generation&lt;/td&gt; &#xA;   &lt;td&gt;Keypoint&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/gligen/gligen-generation-keypoint/blob/main/diffusion_pytorch_model.bin&#34;&gt;HF Hub&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Inpainting&lt;/td&gt; &#xA;   &lt;td&gt;Box+Text&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/gligen/gligen-inpainting-text-box/blob/main/diffusion_pytorch_model.bin&#34;&gt;HF Hub&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Inpainting&lt;/td&gt; &#xA;   &lt;td&gt;Box+Text+Image&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/gligen/gligen-inpainting-text-image-box/blob/main/diffusion_pytorch_model.bin&#34;&gt;HF Hub&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Inference: Generate images with GLIGEN&lt;/h2&gt; &#xA;&lt;p&gt;We provide one script to generate images using provided checkpoints. First download models and put them in &lt;code&gt;gligen_checkpoints&lt;/code&gt;. Then run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python gligen_inference.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example samples for each checkpoint will be saved in &lt;code&gt;generation_samples&lt;/code&gt;. One can check &lt;code&gt;gligen_inference.py&lt;/code&gt; for more details about interface.&lt;/p&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;h3&gt;Grounded generation training&lt;/h3&gt; &#xA;&lt;p&gt;One need to first prepare data for different grounding modality conditions. Refer &lt;a href=&#34;https://raw.githubusercontent.com/gligen/GLIGEN/master/DATA/README.MD&#34;&gt;data&lt;/a&gt; for the data we used for different GLIGEN models. Once data is ready, the following command is used to train GLIGEN. (We support multi-GPUs training)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ptyhon main.py --name=your_experiment_name  --yaml_file=path_to_your_yaml_config&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;--yaml_file&lt;/code&gt; is the most important argument and below we will use one example to explain key components so that one can be familiar with our code and know how to customize training on their own grounding modalities. The other args are self-explanatory by their names. The experiment will be saved in &lt;code&gt;OUTPUT_ROOT/name&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;One can refer &lt;code&gt;configs/flicker_text.yaml&lt;/code&gt; as one example. One can see that there are 5 components defining this yaml: &lt;strong&gt;diffusion&lt;/strong&gt;, &lt;strong&gt;model&lt;/strong&gt;, &lt;strong&gt;autoencoder&lt;/strong&gt;, &lt;strong&gt;text_encoder&lt;/strong&gt;, &lt;strong&gt;train_dataset_names&lt;/strong&gt; and &lt;strong&gt;grounding_tokenizer_input&lt;/strong&gt;. Typecially, &lt;strong&gt;diffusion&lt;/strong&gt;, &lt;strong&gt;autoencoder&lt;/strong&gt; and &lt;strong&gt;text_encoder&lt;/strong&gt; should not be changed as they are defined by Stable Diffusion. One should pay attention to following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Within &lt;strong&gt;model&lt;/strong&gt; we add new argument &lt;strong&gt;grounding_tokenizer&lt;/strong&gt; which defines a network producing grounding tokens. This network will be instantized in the model. One can refer to &lt;code&gt;ldm/modules/diffusionmodules/grounding_net_example.py&lt;/code&gt; for more details about defining this network.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;grounding_tokenizer_input&lt;/strong&gt; will define a network taking in batch data from dataloader and produce input for the grounding_tokenizer. In other words, it is an intermediante class between dataloader and grounding_tokenizer. One can refer &lt;code&gt;grounding_input/__init__.py&lt;/code&gt; for details about defining this class.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;train_dataset_names&lt;/strong&gt; should be listing a serial of names of datasets (all datasets will be concatenated internally, thus it is useful to combine datasets for training). Each dataset name should be first registered in &lt;code&gt;dataset/catalog.py&lt;/code&gt;. We have listed all dataset we used; if one needs to train GLIGEN on their own modality dataset, please don&#39;t forget first list its name there.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Grounded inpainting training&lt;/h3&gt; &#xA;&lt;p&gt;GLIGEN also supports inpainting training. The following command can be used:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ptyhon main.py --name=your_experiment_name  --yaml_file=path_to_your_yaml_config --inpaint_mode=True  --ckpt=path_to_an_adapted_model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Typecially, we first train GLIGEN on generation task (e.g., text grounded generation) and this model has 4 channels for input conv (latent space of Stable Diffusion), then we modify the saved checkpoint to 9 channels with addition 5 channels initilized with 0. This continue training can lead to faster convergence and better results. path_to_an_adapted_model refers to this modified checkpoint, &lt;code&gt;convert_ckpt.py&lt;/code&gt; can be used for modifying checkpoint. &lt;strong&gt;NOTE:&lt;/strong&gt; yaml file is the same for generation and inpainting training, one only need to change &lt;code&gt;--inpaint_mode&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{li2023gligen,&#xA;  title={GLIGEN: Open-Set Grounded Text-to-Image Generation},&#xA;  author={Li, Yuheng and Liu, Haotian and Wu, Qingyang and Mu, Fangzhou and Yang, Jianwei and Gao, Jianfeng and Li, Chunyuan and Lee, Yong Jae},&#xA;  journal={CVPR},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;The original GLIGEN was partly implemented and trained during an internship at Microsoft. This repo re-implements GLIGEN in PyTorch with university GPUs after the internship. Despite the minor implementation differences, this repo aims to reproduce the results and observations in the paper for research purposes.&lt;/p&gt;</summary>
  </entry>
</feed>