<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-08-09T01:32:45Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>statsmodels/statsmodels</title>
    <updated>2024-08-09T01:32:45Z</updated>
    <id>tag:github.com,2024-08-09:/statsmodels/statsmodels</id>
    <link href="https://github.com/statsmodels/statsmodels" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Statsmodels: statistical modeling and econometrics in Python&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. image:: docs/source/images/statsmodels-logo-v2-horizontal.svg :alt: Statsmodels logo&lt;/p&gt; &#xA;&lt;p&gt;|PyPI Version| |Conda Version| |License| |Azure CI Build Status| |Codecov Coverage| |Coveralls Coverage| |PyPI downloads| |Conda downloads|&lt;/p&gt; &#xA;&lt;h1&gt;About statsmodels&lt;/h1&gt; &#xA;&lt;p&gt;statsmodels is a Python package that provides a complement to scipy for statistical computations including descriptive statistics and estimation and inference for statistical models.&lt;/p&gt; &#xA;&lt;h1&gt;Documentation&lt;/h1&gt; &#xA;&lt;p&gt;The documentation for the latest release is at&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.statsmodels.org/stable/&#34;&gt;https://www.statsmodels.org/stable/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The documentation for the development version is at&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.statsmodels.org/dev/&#34;&gt;https://www.statsmodels.org/dev/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Recent improvements are highlighted in the release notes&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.statsmodels.org/stable/release/&#34;&gt;https://www.statsmodels.org/stable/release/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Backups of documentation are available at &lt;a href=&#34;https://statsmodels.github.io/stable/&#34;&gt;https://statsmodels.github.io/stable/&lt;/a&gt; and &lt;a href=&#34;https://statsmodels.github.io/dev/&#34;&gt;https://statsmodels.github.io/dev/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Main Features&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Linear regression models:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Ordinary least squares&lt;/li&gt; &#xA;   &lt;li&gt;Generalized least squares&lt;/li&gt; &#xA;   &lt;li&gt;Weighted least squares&lt;/li&gt; &#xA;   &lt;li&gt;Least squares with autoregressive errors&lt;/li&gt; &#xA;   &lt;li&gt;Quantile regression&lt;/li&gt; &#xA;   &lt;li&gt;Recursive least squares&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Mixed Linear Model with mixed effects and variance components&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;GLM: Generalized linear models with support for all of the one-parameter exponential family distributions&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Bayesian Mixed GLM for Binomial and Poisson&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;GEE: Generalized Estimating Equations for one-way clustered or longitudinal data&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Discrete models:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Logit and Probit&lt;/li&gt; &#xA;   &lt;li&gt;Multinomial logit (MNLogit)&lt;/li&gt; &#xA;   &lt;li&gt;Poisson and Generalized Poisson regression&lt;/li&gt; &#xA;   &lt;li&gt;Negative Binomial regression&lt;/li&gt; &#xA;   &lt;li&gt;Zero-Inflated Count models&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;RLM: Robust linear models with support for several M-estimators.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Time Series Analysis: models for time series analysis&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Complete StateSpace modeling framework&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Seasonal ARIMA and ARIMAX models&lt;/li&gt; &#xA;     &lt;li&gt;VARMA and VARMAX models&lt;/li&gt; &#xA;     &lt;li&gt;Dynamic Factor models&lt;/li&gt; &#xA;     &lt;li&gt;Unobserved Component models&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Markov switching models (MSAR), also known as Hidden Markov Models (HMM)&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Univariate time series analysis: AR, ARIMA&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Vector autoregressive models, VAR and structural VAR&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Vector error correction model, VECM&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;exponential smoothing, Holt-Winters&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Hypothesis tests for time series: unit root, cointegration and others&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Descriptive statistics and process models for time series analysis&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Survival analysis:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Proportional hazards regression (Cox models)&lt;/li&gt; &#xA;   &lt;li&gt;Survivor function estimation (Kaplan-Meier)&lt;/li&gt; &#xA;   &lt;li&gt;Cumulative incidence function estimation&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Multivariate:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Principal Component Analysis with missing data&lt;/li&gt; &#xA;   &lt;li&gt;Factor Analysis with rotation&lt;/li&gt; &#xA;   &lt;li&gt;MANOVA&lt;/li&gt; &#xA;   &lt;li&gt;Canonical Correlation&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Nonparametric statistics: Univariate and multivariate kernel density estimators&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Datasets: Datasets used for examples and in testing&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Statistics: a wide range of statistical tests&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;diagnostics and specification tests&lt;/li&gt; &#xA;   &lt;li&gt;goodness-of-fit and normality tests&lt;/li&gt; &#xA;   &lt;li&gt;functions for multiple testing&lt;/li&gt; &#xA;   &lt;li&gt;various additional statistical tests&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Imputation with MICE, regression on order statistic and Gaussian imputation&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Mediation analysis&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Graphics includes plot functions for visual analysis of data and model results&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;I/O&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Tools for reading Stata .dta files, but pandas has a more recent version&lt;/li&gt; &#xA;   &lt;li&gt;Table output to ascii, latex, and html&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Miscellaneous models&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Sandbox: statsmodels contains a sandbox folder with code in various stages of development and testing which is not considered &#34;production ready&#34;. This covers among others&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Generalized method of moments (GMM) estimators&lt;/li&gt; &#xA;   &lt;li&gt;Kernel regression&lt;/li&gt; &#xA;   &lt;li&gt;Various extensions to scipy.stats.distributions&lt;/li&gt; &#xA;   &lt;li&gt;Panel data models&lt;/li&gt; &#xA;   &lt;li&gt;Information theoretic measures&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;How to get it&lt;/h1&gt; &#xA;&lt;p&gt;The main branch on GitHub is the most up to date code&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.github.com/statsmodels/statsmodels&#34;&gt;https://www.github.com/statsmodels/statsmodels&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Source download of release tags are available on GitHub&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/statsmodels/statsmodels/tags&#34;&gt;https://github.com/statsmodels/statsmodels/tags&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Binaries and source distributions are available from PyPi&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pypi.org/project/statsmodels/&#34;&gt;https://pypi.org/project/statsmodels/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Binaries can be installed in Anaconda&lt;/p&gt; &#xA;&lt;p&gt;conda install statsmodels&lt;/p&gt; &#xA;&lt;h1&gt;Getting the latest code&lt;/h1&gt; &#xA;&lt;p&gt;Installing the most recent nightly wheel&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;The most recent nightly wheel can be installed using pip.&#xA;&#xA;.. code:: bash&#xA;&#xA;   python -m pip install -i https://pypi.anaconda.org/scientific-python-nightly-wheels/simple statsmodels --upgrade --use-deprecated=legacy-resolver&#xA;&#xA;Installing from sources&#xA;~~~~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;See INSTALL.txt for requirements or see the documentation&#xA;&#xA;https://statsmodels.github.io/dev/install.html&#xA;&#xA;Contributing&#xA;============&#xA;Contributions in any form are welcome, including:&#xA;&#xA;* Documentation improvements&#xA;* Additional tests&#xA;* New features to existing models&#xA;* New models&#xA;&#xA;https://www.statsmodels.org/stable/dev/test_notes&#xA;&#xA;for instructions on installing statsmodels in *editable* mode.&#xA;&#xA;License&#xA;=======&#xA;&#xA;Modified BSD (3-clause)&#xA;&#xA;Discussion and Development&#xA;==========================&#xA;&#xA;Discussions take place on the mailing list&#xA;&#xA;https://groups.google.com/group/pystatsmodels&#xA;&#xA;and in the issue tracker. We are very interested in feedback&#xA;about usability and suggestions for improvements.&#xA;&#xA;Bug Reports&#xA;===========&#xA;&#xA;Bug reports can be submitted to the issue tracker at&#xA;&#xA;https://github.com/statsmodels/statsmodels/issues&#xA;&#xA;.. |Azure CI Build Status| image:: https://dev.azure.com/statsmodels/statsmodels-testing/_apis/build/status/statsmodels.statsmodels?branchName=main&#xA;   :target: https://dev.azure.com/statsmodels/statsmodels-testing/_build/latest?definitionId=1&amp;amp;branchName=main&#xA;.. |Codecov Coverage| image:: https://codecov.io/gh/statsmodels/statsmodels/branch/main/graph/badge.svg&#xA;   :target: https://codecov.io/gh/statsmodels/statsmodels&#xA;.. |Coveralls Coverage| image:: https://coveralls.io/repos/github/statsmodels/statsmodels/badge.svg?branch=main&#xA;   :target: https://coveralls.io/github/statsmodels/statsmodels?branch=main&#xA;.. |PyPI downloads| image:: https://img.shields.io/pypi/dm/statsmodels?label=PyPI%20Downloads&#xA;   :alt: PyPI - Downloads&#xA;   :target: https://pypi.org/project/statsmodels/&#xA;.. |Conda downloads| image:: https://img.shields.io/conda/dn/conda-forge/statsmodels.svg?label=Conda%20downloads&#xA;   :target: https://anaconda.org/conda-forge/statsmodels/&#xA;.. |PyPI Version| image:: https://img.shields.io/pypi/v/statsmodels.svg&#xA;   :target: https://pypi.org/project/statsmodels/&#xA;.. |Conda Version| image:: https://anaconda.org/conda-forge/statsmodels/badges/version.svg&#xA;   :target: https://anaconda.org/conda-forge/statsmodels/&#xA;.. |License| image:: https://img.shields.io/pypi/l/statsmodels.svg&#xA;   :target: https://github.com/statsmodels/statsmodels/blob/main/LICENSE.txt&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>jorhelp/Ingram</title>
    <updated>2024-08-09T01:32:45Z</updated>
    <id>tag:github.com,2024-08-09:/jorhelp/Ingram</id>
    <link href="https://github.com/jorhelp/Ingram" rel="alternate"></link>
    <summary type="html">&lt;p&gt;网络摄像头漏洞扫描工具 | Webcam vulnerability scanning tool&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img alt=&#34;Ingram&#34; src=&#34;https://github.com/jorhelp/imgs/raw/master/Ingram/logo.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;!-- icons --&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img alt=&#34;Platform&#34; src=&#34;https://img.shields.io/badge/platform-Linux%2520%7C%2520Mac-blue.svg?sanitize=true&#34;&gt; &#xA; &lt;img alt=&#34;Python Version&#34; src=&#34;https://img.shields.io/badge/python-3.8-yellow.svg?sanitize=true&#34;&gt; &#xA; &lt;img alt=&#34;GitHub&#34; src=&#34;https://img.shields.io/github/license/jorhelp/Ingram&#34;&gt; &#xA; &lt;img alt=&#34;Github Checks&#34; src=&#34;https://img.shields.io/github/checks-status/jorhelp/Ingram/master&#34;&gt; &#xA; &lt;img alt=&#34;GitHub Last Commit (master)&#34; src=&#34;https://img.shields.io/github/last-commit/jorhelp/Ingram/master&#34;&gt; &#xA; &lt;img alt=&#34;Languages Count&#34; src=&#34;https://img.shields.io/github/languages/count/jorhelp/Ingram?style=social&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;简体中文 | &lt;a href=&#34;https://github.com/jorhelp/Ingram/raw/master/README.en.md&#34;&gt;English&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;简介&lt;/h2&gt; &#xA;&lt;p&gt;主要针对网络摄像头的漏洞扫描框架，目前已集成海康、大华、宇视、dlink等常见设备&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img alt=&#34;run&#34; src=&#34;https://github.com/jorhelp/imgs/raw/master/Ingram/run_time.gif&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;安装&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;请在 Linux 或 Mac 系统使用，确保安装了3.8及以上版本的Python，尽量不要使用3.11，因为对许多包的兼容不是很好&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;克隆该仓库:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/jorhelp/Ingram.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;进入项目目录，创建一个虚拟环境，并激活该环境：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd Ingram&#xA;pip3 install virtualenv&#xA;python3 -m virtualenv venv&#xA;source venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;安装依赖:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip3 install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;至此安装完毕！&lt;/p&gt; &#xA;&lt;h2&gt;运行&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;由于是在虚拟环境中配置，所以，每次运行之前，请先激活虚拟环境：&lt;code&gt;source venv/bin/activate&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;你需要准备一个目标文件，比如 targets.txt，里面保存着你要扫描的 IP 地址，每行一个目标，具体格式如下：&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# 你可以使用井号(#)来进行注释&#xA;&#xA;# 单个的 IP 地址&#xA;192.168.0.1&#xA;&#xA;# IP 地址以及要扫描的端口&#xA;192.168.0.2:80&#xA;&#xA;# 带 &#39;/&#39; 的IP段&#xA;192.168.0.0/16&#xA;&#xA;# 带 &#39;-&#39; 的IP段&#xA;192.168.0.0-192.168.255.255&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;有了目标文件之后就可直接运行:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 run_ingram.py -i 你要扫描的文件 -o 输出文件夹&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;端口： 如果target.txt文件中指定了目标的端口，比如: 192.168.6.6:8000，那么会扫描该目标的8000端口&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;否则的话，默认只扫描常见端口(定义在 &lt;code&gt;Ingram/config.py&lt;/code&gt; 中)，若要批量扫描其他端口，需自行指定，例如：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 run_ingram.py -i 你要扫描的文件 -o 输出文件夹 -p 80 81 8000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;默认并发数目为 300，可以根据机器配置及网速通过 &lt;code&gt;-t&lt;/code&gt; 参数来自行调控：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 run_ingram.py -i 你要扫描的文件 -o 输出文件夹 -t 500&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;支持中断恢复，不过并不会实时记录当前运行状态，而是间隔一定时间，所以并不能准确恢复到上次的运行状态。如果扫描因为网络或异常而中断，可以通过重复执行上次的扫描命令来继续扫描&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;所有参数：&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;optional arguments:&#xA;  -h, --help            show this help message and exit&#xA;  -i IN_FILE, --in_file IN_FILE&#xA;                        the targets will be scan&#xA;  -o OUT_DIR, --out_dir OUT_DIR&#xA;                        the dir where results will be saved&#xA;  -p PORTS [PORTS ...], --ports PORTS [PORTS ...]&#xA;                        the port(s) to detect&#xA;  -t TH_NUM, --th_num TH_NUM&#xA;                        the processes num&#xA;  -T TIMEOUT, --timeout TIMEOUT&#xA;                        requests timeout&#xA;  -D, --disable_snapshot&#xA;                        disable snapshot&#xA;  --debug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;端口扫描器&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;我们可以利用强大的端口扫描器来获取活动主机，进而缩小 Ingram 的扫描范围，提高运行速度，具体做法是将端口扫描器的结果文件整理成 &lt;code&gt;ip:port&lt;/code&gt; 的格式，并作为 Ingram 的输入&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;这里以 masscan 为例简单演示一下（masscan 的详细用法这里不再赘述），首先用 masscan 扫描 80 或 8000-8008 端口存活的主机：&lt;code&gt;masscan -p80,8000-8008 -iL 目标文件 -oL 结果文件 --rate 8000&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;masscan 运行完之后，将结果文件整理一下：&lt;code&gt;grep &#39;open&#39; 结果文件 | awk &#39;{printf&#34;%s:%s\n&#34;, $4, $3}&#39; &amp;gt; targets.txt&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;之后对这些主机进行扫描：&lt;code&gt;python run_ingram.py -i targets.txt -o out&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;del&gt;微信提醒&lt;/del&gt;(已移除)&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;(&lt;strong&gt;可选&lt;/strong&gt;) 扫描时间可能会很长，如果你想让程序扫描结束的时候通过微信发送一条提醒的话，你需要按照 &lt;a href=&#34;https://wxpusher.zjiecode.com/docs/&#34;&gt;wxpusher&lt;/a&gt; 的指示来获取你的专属 &lt;em&gt;UID&lt;/em&gt; 和 &lt;em&gt;APP_TOKEN&lt;/em&gt;，并将其写入 &lt;code&gt;run_ingram.py&lt;/code&gt;:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# wechat&#xA;config.set_val(&#39;WXUID&#39;, &#39;这里写uid&#39;)&#xA;config.set_val(&#39;WXTOKEN&#39;, &#39;这里写token&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;结果&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;.&#xA;├── not_vulnerable.csv&#xA;├── results.csv&#xA;├── snapshots&#xA;└── log.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;results.csv&lt;/code&gt; 里保存了完整的结果, 格式为: &lt;code&gt;ip,端口,设备类型,用户名,密码,漏洞条目&lt;/code&gt;:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img alt=&#34;Ingram&#34; src=&#34;https://github.com/jorhelp/imgs/raw/master/Ingram/results.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;not_vulnerable.csv&lt;/code&gt; 中保存的是没有暴露的设备&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;snapshots&lt;/code&gt; 中保存了部分设备的快照:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img alt=&#34;Ingram&#34; src=&#34;https://github.com/jorhelp/imgs/raw/master/Ingram/snapshots.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;&lt;del&gt;实时预览&lt;/del&gt; (由于部分原因已移除)&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;del&gt;可以直接通过浏览器登录来预览&lt;/del&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;del&gt;如果想批量查看，我们提供了一个脚本 &lt;code&gt;show/show_rtsp/show_all.py&lt;/code&gt;，不过它还有一些问题:&lt;/del&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img alt=&#34;Ingram&#34; src=&#34;https://github.com/jorhelp/imgs/raw/master/Ingram/show_rtsp.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;免责声明&lt;/h2&gt; &#xA;&lt;p&gt;本工具仅供安全测试，严禁用于非法用途，后果与本团队无关&lt;/p&gt; &#xA;&lt;h2&gt;鸣谢 &amp;amp; 引用&lt;/h2&gt; &#xA;&lt;p&gt;Thanks to &lt;a href=&#34;https://github.com/Aiminsun/CVE-2021-36260&#34;&gt;Aiminsun&lt;/a&gt; for CVE-2021-36260&lt;br&gt; Thanks to &lt;a href=&#34;https://github.com/chrisjd20/hikvision_CVE-2017-7921_auth_bypass_config_decryptor&#34;&gt;chrisjd20&lt;/a&gt; for hidvision config file decryptor&lt;br&gt; Thanks to &lt;a href=&#34;https://github.com/mcw0/DahuaConsole&#34;&gt;mcw0&lt;/a&gt; for DahuaConsole&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>pytorch/rl</title>
    <updated>2024-08-09T01:32:45Z</updated>
    <id>tag:github.com,2024-08-09:/pytorch/rl</id>
    <link href="https://github.com/pytorch/rl" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A modular, primitive-first, python-first PyTorch library for Reinforcement Learning.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/pytorch/rl/actions/workflows/test-linux.yml&#34;&gt;&lt;img src=&#34;https://github.com/pytorch/rl/actions/workflows/test-linux.yml/badge.svg?sanitize=true&#34; alt=&#34;Unit-tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pytorch.org/rl/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Documentation-blue.svg?sanitize=true&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pytorch.github.io/rl/dev/bench/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Benchmarks-blue.svg?sanitize=true&#34; alt=&#34;Benchmarks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/pytorch/rl&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/pytorch/rl/branch/main/graph/badge.svg?token=HcpK1ILV6r&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/torchrl1&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/torchrl1?style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/torchrl.svg?sanitize=true&#34; alt=&#34;Python version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true&#34; alt=&#34;GitHub license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/torchrl&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/torchrl&#34; alt=&#34;pypi version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/torchrl-nightly&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/torchrl-nightly?label=nightly&#34; alt=&#34;pypi nightly version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/torchrl&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/personalized-badge/torchrl?period=total&amp;amp;units=international_system&amp;amp;left_color=blue&amp;amp;right_color=orange&amp;amp;left_text=Downloads&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/torchrl-nightly&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/personalized-badge/torchrl-nightly?period=total&amp;amp;units=international_system&amp;amp;left_color=blue&amp;amp;right_color=orange&amp;amp;left_text=Downloads%20(nightly)&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/cZs26Qq3Dd&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/cZs26Qq3Dd&#34; alt=&#34;Discord Shield&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;TorchRL&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/pytorch/rl/main/docs/source/_static/img/icon.png&#34; width=&#34;200&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pytorch/rl/main/#documentation-and-knowledge-base&#34;&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/rl/main/#writing-simplified-and-portable-rl-codebase-with-tensordict&#34;&gt;&lt;strong&gt;TensorDict&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/rl/main/#features&#34;&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/rl/main/#examples-tutorials-and-demos&#34;&gt;&lt;strong&gt;Examples, tutorials and demos&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/rl/main/#citation&#34;&gt;&lt;strong&gt;Citation&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/rl/main/#installation&#34;&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/rl/main/#asking-a-question&#34;&gt;&lt;strong&gt;Asking a question&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/rl/main/#contributing&#34;&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TorchRL&lt;/strong&gt; is an open-source Reinforcement Learning (RL) library for PyTorch.&lt;/p&gt; &#xA;&lt;h2&gt;Key features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🐍 &lt;strong&gt;Python-first&lt;/strong&gt;: Designed with Python as the primary language for ease of use and flexibility&lt;/li&gt; &#xA; &lt;li&gt;⏱️ &lt;strong&gt;Efficient&lt;/strong&gt;: Optimized for performance to support demanding RL research applications&lt;/li&gt; &#xA; &lt;li&gt;🧮 &lt;strong&gt;Modular, customizable, extensible&lt;/strong&gt;: Highly modular architecture allows for easy swapping, transformation, or creation of new components&lt;/li&gt; &#xA; &lt;li&gt;📚 &lt;strong&gt;Documented&lt;/strong&gt;: Thorough documentation ensures that users can quickly understand and utilize the library&lt;/li&gt; &#xA; &lt;li&gt;✅ &lt;strong&gt;Tested&lt;/strong&gt;: Rigorously tested to ensure reliability and stability&lt;/li&gt; &#xA; &lt;li&gt;⚙️ &lt;strong&gt;Reusable functionals&lt;/strong&gt;: Provides a set of highly reusable functions for cost functions, returns, and data processing&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Design Principles&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🔥 &lt;strong&gt;Aligns with PyTorch ecosystem&lt;/strong&gt;: Follows the structure and conventions of popular PyTorch libraries (e.g., dataset pillar, transforms, models, data utilities)&lt;/li&gt; &#xA; &lt;li&gt;➖ Minimal dependencies: Only requires Python standard library, NumPy, and PyTorch; optional dependencies for common environment libraries (e.g., OpenAI Gym) and datasets (D4RL, OpenX...)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Read the &lt;a href=&#34;https://arxiv.org/abs/2306.00577&#34;&gt;full paper&lt;/a&gt; for a more curated description of the library.&lt;/p&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;p&gt;Check our &lt;a href=&#34;https://pytorch.org/rl/stable/index.html#getting-started&#34;&gt;Getting Started tutorials&lt;/a&gt; for quickly ramp up with the basic features of the library!&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/pytorch/rl/main/docs/ppo.png&#34; width=&#34;800&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Documentation and knowledge base&lt;/h2&gt; &#xA;&lt;p&gt;The TorchRL documentation can be found &lt;a href=&#34;https://pytorch.org/rl&#34;&gt;here&lt;/a&gt;. It contains tutorials and the API reference.&lt;/p&gt; &#xA;&lt;p&gt;TorchRL also provides a RL knowledge base to help you debug your code, or simply learn the basics of RL. Check it out &lt;a href=&#34;https://pytorch.org/rl/stable/reference/knowledge_base.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We have some introductory videos for you to get to know the library better, check them out:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.talkrl.com/episodes/vincent-moens-on-torchrl&#34;&gt;TalkRL podcast&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/cIKMhZoykEE&#34;&gt;TorchRL intro at PyTorch day 2022&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/live/myEfUoYrbts?feature=share&#34;&gt;PyTorch 2.0 Q&amp;amp;A: TorchRL&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Spotlight publications&lt;/h2&gt; &#xA;&lt;p&gt;TorchRL being domain-agnostic, you can use it across many different fields. Here are a few examples:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pubs.acs.org/doi/10.1021/acs.jcim.4c00895&#34;&gt;ACEGEN&lt;/a&gt;: Reinforcement Learning of Generative Chemical Agents for Drug Discovery&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jmlr.org/papers/v25/23-1612.html&#34;&gt;BenchMARL&lt;/a&gt;: Benchmarking Multi-Agent Reinforcement Learning&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2406.17490&#34;&gt;BricksRL&lt;/a&gt;: A Platform for Democratizing Robotics and Reinforcement Learning Research and Education with LEGO&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/10409589&#34;&gt;OmniDrones&lt;/a&gt;: An Efficient and Flexible Platform for Reinforcement Learning in Drone Control&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.17100&#34;&gt;RL4CO&lt;/a&gt;: an Extensive Reinforcement Learning for Combinatorial Optimization Benchmark&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://proceedings.neurips.cc/paper_files/paper/2023/file/8a84a4341c375b8441b36836bb343d4e-Paper-Datasets_and_Benchmarks.pdf&#34;&gt;Robohive&lt;/a&gt;: A unified framework for robot learning&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Writing simplified and portable RL codebase with &lt;code&gt;TensorDict&lt;/code&gt;&lt;/h2&gt; &#xA;&lt;p&gt;RL algorithms are very heterogeneous, and it can be hard to recycle a codebase across settings (e.g. from online to offline, from state-based to pixel-based learning). TorchRL solves this problem through &lt;a href=&#34;https://github.com/pytorch/tensordict/&#34;&gt;&lt;code&gt;TensorDict&lt;/code&gt;&lt;/a&gt;, a convenient data structure&lt;sup&gt;(1)&lt;/sup&gt; that can be used to streamline one&#39;s RL codebase. With this tool, one can write a &lt;em&gt;complete PPO training script in less than 100 lines of code&lt;/em&gt;!&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Code&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from tensordict.nn import TensorDictModule&#xA;from tensordict.nn.distributions import NormalParamExtractor&#xA;from torch import nn&#xA;&#xA;from torchrl.collectors import SyncDataCollector&#xA;from torchrl.data.replay_buffers import TensorDictReplayBuffer, \&#xA;    LazyTensorStorage, SamplerWithoutReplacement&#xA;from torchrl.envs.libs.gym import GymEnv&#xA;from torchrl.modules import ProbabilisticActor, ValueOperator, TanhNormal&#xA;from torchrl.objectives import ClipPPOLoss&#xA;from torchrl.objectives.value import GAE&#xA;&#xA;env = GymEnv(&#34;Pendulum-v1&#34;)&#xA;model = TensorDictModule(&#xA;    nn.Sequential(&#xA;        nn.Linear(3, 128), nn.Tanh(),&#xA;        nn.Linear(128, 128), nn.Tanh(),&#xA;        nn.Linear(128, 128), nn.Tanh(),&#xA;        nn.Linear(128, 2),&#xA;        NormalParamExtractor()&#xA;    ),&#xA;    in_keys=[&#34;observation&#34;],&#xA;    out_keys=[&#34;loc&#34;, &#34;scale&#34;]&#xA;)&#xA;critic = ValueOperator(&#xA;    nn.Sequential(&#xA;        nn.Linear(3, 128), nn.Tanh(),&#xA;        nn.Linear(128, 128), nn.Tanh(),&#xA;        nn.Linear(128, 128), nn.Tanh(),&#xA;        nn.Linear(128, 1),&#xA;    ),&#xA;    in_keys=[&#34;observation&#34;],&#xA;)&#xA;actor = ProbabilisticActor(&#xA;    model,&#xA;    in_keys=[&#34;loc&#34;, &#34;scale&#34;],&#xA;    distribution_class=TanhNormal,&#xA;    distribution_kwargs={&#34;min&#34;: -1.0, &#34;max&#34;: 1.0},&#xA;    return_log_prob=True&#xA;    )&#xA;buffer = TensorDictReplayBuffer(&#xA;    LazyTensorStorage(1000),&#xA;    SamplerWithoutReplacement()&#xA;    )&#xA;collector = SyncDataCollector(&#xA;    env,&#xA;    actor,&#xA;    frames_per_batch=1000,&#xA;    total_frames=1_000_000&#xA;    )&#xA;loss_fn = ClipPPOLoss(actor, critic, gamma=0.99)&#xA;optim = torch.optim.Adam(loss_fn.parameters(), lr=2e-4)&#xA;adv_fn = GAE(value_network=critic, gamma=0.99, lmbda=0.95, average_gae=True)&#xA;for data in collector:  # collect data&#xA;    for epoch in range(10):&#xA;        adv_fn(data)  # compute advantage&#xA;        buffer.extend(data.view(-1))&#xA;        for i in range(20):  # consume data&#xA;            sample = buffer.sample(50)  # mini-batch&#xA;            loss_vals = loss_fn(sample)&#xA;            loss_val = sum(&#xA;                value for key, value in loss_vals.items() if&#xA;                key.startswith(&#34;loss&#34;)&#xA;                )&#xA;            loss_val.backward()&#xA;            optim.step()&#xA;            optim.zero_grad()&#xA;    print(f&#34;avg reward: {data[&#39;next&#39;, &#39;reward&#39;].mean().item(): 4.4f}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;Here is an example of how the &lt;a href=&#34;https://pytorch.org/rl/stable/reference/envs.html&#34;&gt;environment API&lt;/a&gt; relies on tensordict to carry data from one function to another during a rollout execution: &lt;img src=&#34;https://github.com/pytorch/rl/raw/main/docs/source/_static/img/rollout.gif&#34; alt=&#34;Alt Text&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;TensorDict&lt;/code&gt; makes it easy to re-use pieces of code across environments, models and algorithms.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Code&lt;/summary&gt; &#xA; &lt;p&gt;For instance, here&#39;s how to code a rollout in TorchRL:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;- obs, done = env.reset()&#xA;+ tensordict = env.reset()&#xA;policy = SafeModule(&#xA;    model,&#xA;    in_keys=[&#34;observation_pixels&#34;, &#34;observation_vector&#34;],&#xA;    out_keys=[&#34;action&#34;],&#xA;)&#xA;out = []&#xA;for i in range(n_steps):&#xA;-     action, log_prob = policy(obs)&#xA;-     next_obs, reward, done, info = env.step(action)&#xA;-     out.append((obs, next_obs, action, log_prob, reward, done))&#xA;-     obs = next_obs&#xA;+     tensordict = policy(tensordict)&#xA;+     tensordict = env.step(tensordict)&#xA;+     out.append(tensordict)&#xA;+     tensordict = step_mdp(tensordict)  # renames next_observation_* keys to observation_*&#xA;- obs, next_obs, action, log_prob, reward, done = [torch.stack(vals, 0) for vals in zip(*out)]&#xA;+ out = torch.stack(out, 0)  # TensorDict supports multiple tensor operations&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;Using this, TorchRL abstracts away the input / output signatures of the modules, env, collectors, replay buffers and losses of the library, allowing all primitives to be easily recycled across settings.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Code&lt;/summary&gt; &#xA; &lt;p&gt;Here&#39;s another example of an off-policy training loop in TorchRL (assuming that a data collector, a replay buffer, a loss and an optimizer have been instantiated):&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;- for i, (obs, next_obs, action, hidden_state, reward, done) in enumerate(collector):&#xA;+ for i, tensordict in enumerate(collector):&#xA;-     replay_buffer.add((obs, next_obs, action, log_prob, reward, done))&#xA;+     replay_buffer.add(tensordict)&#xA;    for j in range(num_optim_steps):&#xA;-         obs, next_obs, action, hidden_state, reward, done = replay_buffer.sample(batch_size)&#xA;-         loss = loss_fn(obs, next_obs, action, hidden_state, reward, done)&#xA;+         tensordict = replay_buffer.sample(batch_size)&#xA;+         loss = loss_fn(tensordict)&#xA;        loss.backward()&#xA;        optim.step()&#xA;        optim.zero_grad()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;This training loop can be re-used across algorithms as it makes a minimal number of assumptions about the structure of the data.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;TensorDict supports multiple tensor operations on its device and shape (the shape of TensorDict, or its batch size, is the common arbitrary N first dimensions of all its contained tensors):&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Code&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# stack and cat&#xA;tensordict = torch.stack(list_of_tensordicts, 0)&#xA;tensordict = torch.cat(list_of_tensordicts, 0)&#xA;# reshape&#xA;tensordict = tensordict.view(-1)&#xA;tensordict = tensordict.permute(0, 2, 1)&#xA;tensordict = tensordict.unsqueeze(-1)&#xA;tensordict = tensordict.squeeze(-1)&#xA;# indexing&#xA;tensordict = tensordict[:2]&#xA;tensordict[:, 2] = sub_tensordict&#xA;# device and memory location&#xA;tensordict.cuda()&#xA;tensordict.to(&#34;cuda:1&#34;)&#xA;tensordict.share_memory_()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;TensorDict comes with a dedicated &lt;a href=&#34;https://pytorch.github.io/tensordict/reference/nn.html&#34;&gt;&lt;code&gt;tensordict.nn&lt;/code&gt;&lt;/a&gt; module that contains everything you might need to write your model with it. And it is &lt;code&gt;functorch&lt;/code&gt; and &lt;code&gt;torch.compile&lt;/code&gt; compatible!&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Code&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)&#xA;+ td_module = SafeModule(transformer_model, in_keys=[&#34;src&#34;, &#34;tgt&#34;], out_keys=[&#34;out&#34;])&#xA;src = torch.rand((10, 32, 512))&#xA;tgt = torch.rand((20, 32, 512))&#xA;+ tensordict = TensorDict({&#34;src&#34;: src, &#34;tgt&#34;: tgt}, batch_size=[20, 32])&#xA;- out = transformer_model(src, tgt)&#xA;+ td_module(tensordict)&#xA;+ out = tensordict[&#34;out&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;The &lt;code&gt;TensorDictSequential&lt;/code&gt; class allows to branch sequences of &lt;code&gt;nn.Module&lt;/code&gt; instances in a highly modular way. For instance, here is an implementation of a transformer using the encoder and decoder blocks:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;encoder_module = TransformerEncoder(...)&#xA;encoder = TensorDictSequential(encoder_module, in_keys=[&#34;src&#34;, &#34;src_mask&#34;], out_keys=[&#34;memory&#34;])&#xA;decoder_module = TransformerDecoder(...)&#xA;decoder = TensorDictModule(decoder_module, in_keys=[&#34;tgt&#34;, &#34;memory&#34;], out_keys=[&#34;output&#34;])&#xA;transformer = TensorDictSequential(encoder, decoder)&#xA;assert transformer.in_keys == [&#34;src&#34;, &#34;src_mask&#34;, &#34;tgt&#34;]&#xA;assert transformer.out_keys == [&#34;memory&#34;, &#34;output&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;code&gt;TensorDictSequential&lt;/code&gt; allows to isolate subgraphs by querying a set of desired input / output keys:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;transformer.select_subsequence(out_keys=[&#34;memory&#34;])  # returns the encoder&#xA;transformer.select_subsequence(in_keys=[&#34;tgt&#34;, &#34;memory&#34;])  # returns the decoder&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;Check &lt;a href=&#34;https://pytorch.github.io/tensordict/&#34;&gt;TensorDict tutorials&lt;/a&gt; to learn more!&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;A common &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/torchrl/envs&#34;&gt;interface for environments&lt;/a&gt; which supports common libraries (OpenAI gym, deepmind control lab, etc.)&lt;sup&gt;(1)&lt;/sup&gt; and state-less execution (e.g. Model-based environments). The &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/torchrl/envs/batched_envs.py&#34;&gt;batched environments&lt;/a&gt; containers allow parallel execution&lt;sup&gt;(2)&lt;/sup&gt;. A common PyTorch-first class of &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/torchrl/data/tensor_specs.py&#34;&gt;tensor-specification class&lt;/a&gt; is also provided. TorchRL&#39;s environments API is simple but stringent and specific. Check the &lt;a href=&#34;https://pytorch.org/rl/stable/reference/envs.html&#34;&gt;documentation&lt;/a&gt; and &lt;a href=&#34;https://pytorch.org/rl/stable/tutorials/pendulum.html&#34;&gt;tutorial&lt;/a&gt; to learn more!&lt;/p&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Code&lt;/summary&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;env_make = lambda: GymEnv(&#34;Pendulum-v1&#34;, from_pixels=True)&#xA;env_parallel = ParallelEnv(4, env_make)  # creates 4 envs in parallel&#xA;tensordict = env_parallel.rollout(max_steps=20, policy=None)  # random rollout (no policy given)&#xA;assert tensordict.shape == [4, 20]  # 4 envs, 20 steps rollout&#xA;env_parallel.action_spec.is_in(tensordict[&#34;action&#34;])  # spec check returns True&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;multiprocess and distributed &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/torchrl/collectors/collectors.py&#34;&gt;data collectors&lt;/a&gt;&lt;sup&gt;(2)&lt;/sup&gt; that work synchronously or asynchronously. Through the use of TensorDict, TorchRL&#39;s training loops are made very similar to regular training loops in supervised learning (although the &#34;dataloader&#34; -- read data collector -- is modified on-the-fly):&lt;/p&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Code&lt;/summary&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;env_make = lambda: GymEnv(&#34;Pendulum-v1&#34;, from_pixels=True)&#xA;collector = MultiaSyncDataCollector(&#xA;    [env_make, env_make],&#xA;    policy=policy,&#xA;    devices=[&#34;cuda:0&#34;, &#34;cuda:0&#34;],&#xA;    total_frames=10000,&#xA;    frames_per_batch=50,&#xA;    ...&#xA;)&#xA;for i, tensordict_data in enumerate(collector):&#xA;    loss = loss_module(tensordict_data)&#xA;    loss.backward()&#xA;    optim.step()&#xA;    optim.zero_grad()&#xA;    collector.update_policy_weights_()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;/details&gt; &lt;p&gt;Check our &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/examples/distributed/collectors&#34;&gt;distributed collector examples&lt;/a&gt; to learn more about ultra-fast data collection with TorchRL.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;efficient&lt;sup&gt;(2)&lt;/sup&gt; and generic&lt;sup&gt;(1)&lt;/sup&gt; &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/torchrl/data/replay_buffers/replay_buffers.py&#34;&gt;replay buffers&lt;/a&gt; with modularized storage:&lt;/p&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Code&lt;/summary&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;storage = LazyMemmapStorage(  # memory-mapped (physical) storage&#xA;    cfg.buffer_size,&#xA;    scratch_dir=&#34;/tmp/&#34;&#xA;)&#xA;buffer = TensorDictPrioritizedReplayBuffer(&#xA;    alpha=0.7,&#xA;    beta=0.5,&#xA;    collate_fn=lambda x: x,&#xA;    pin_memory=device != torch.device(&#34;cpu&#34;),&#xA;    prefetch=10,  # multi-threaded sampling&#xA;    storage=storage&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;/details&gt; &lt;p&gt;Replay buffers are also offered as wrappers around common datasets for &lt;em&gt;offline RL&lt;/em&gt;:&lt;/p&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Code&lt;/summary&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from torchrl.data.replay_buffers import SamplerWithoutReplacement&#xA;from torchrl.data.datasets.d4rl import D4RLExperienceReplay&#xA;data = D4RLExperienceReplay(&#xA;    &#34;maze2d-open-v0&#34;,&#xA;    split_trajs=True,&#xA;    batch_size=128,&#xA;    sampler=SamplerWithoutReplacement(drop_last=True),&#xA;)&#xA;for sample in data:  # or alternatively sample = data.sample()&#xA;    fun(sample)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;cross-library &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/torchrl/envs/transforms/transforms.py&#34;&gt;environment transforms&lt;/a&gt;&lt;sup&gt;(1)&lt;/sup&gt;, executed on device and in a vectorized fashion&lt;sup&gt;(2)&lt;/sup&gt;, which process and prepare the data coming out of the environments to be used by the agent:&lt;/p&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Code&lt;/summary&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;env_make = lambda: GymEnv(&#34;Pendulum-v1&#34;, from_pixels=True)&#xA;env_base = ParallelEnv(4, env_make, device=&#34;cuda:0&#34;)  # creates 4 envs in parallel&#xA;env = TransformedEnv(&#xA;    env_base,&#xA;    Compose(&#xA;        ToTensorImage(),&#xA;        ObservationNorm(loc=0.5, scale=1.0)),  # executes the transforms once and on device&#xA;)&#xA;tensordict = env.reset()&#xA;assert tensordict.device == torch.device(&#34;cuda:0&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;Other transforms include: reward scaling (&lt;code&gt;RewardScaling&lt;/code&gt;), shape operations (concatenation of tensors, unsqueezing etc.), concatenation of successive operations (&lt;code&gt;CatFrames&lt;/code&gt;), resizing (&lt;code&gt;Resize&lt;/code&gt;) and many more.&lt;/p&gt; &#xA;   &lt;p&gt;Unlike other libraries, the transforms are stacked as a list (and not wrapped in each other), which makes it easy to add and remove them at will:&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;env.insert_transform(0, NoopResetEnv())  # inserts the NoopResetEnv transform at the index 0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;p&gt;Nevertheless, transforms can access and execute operations on the parent environment:&lt;/p&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;transform = env.transform[1]  # gathers the second transform of the list&#xA;parent_env = transform.parent  # returns the base environment of the second transform, i.e. the base env + the first transform&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;various tools for distributed learning (e.g. &lt;a href=&#34;https://github.com/pytorch/tensordict/raw/main/tensordict/memmap.py&#34;&gt;memory mapped tensors&lt;/a&gt;)&lt;sup&gt;(2)&lt;/sup&gt;;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;various &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/torchrl/modules/models/&#34;&gt;architectures&lt;/a&gt; and models (e.g. &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/torchrl/modules/tensordict_module/actors.py&#34;&gt;actor-critic&lt;/a&gt;)&lt;sup&gt;(1)&lt;/sup&gt;:&lt;/p&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Code&lt;/summary&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# create an nn.Module&#xA;common_module = ConvNet(&#xA;    bias_last_layer=True,&#xA;    depth=None,&#xA;    num_cells=[32, 64, 64],&#xA;    kernel_sizes=[8, 4, 3],&#xA;    strides=[4, 2, 1],&#xA;)&#xA;# Wrap it in a SafeModule, indicating what key to read in and where to&#xA;# write out the output&#xA;common_module = SafeModule(&#xA;    common_module,&#xA;    in_keys=[&#34;pixels&#34;],&#xA;    out_keys=[&#34;hidden&#34;],&#xA;)&#xA;# Wrap the policy module in NormalParamsWrapper, such that the output&#xA;# tensor is split in loc and scale, and scale is mapped onto a positive space&#xA;policy_module = SafeModule(&#xA;    NormalParamsWrapper(&#xA;        MLP(num_cells=[64, 64], out_features=32, activation=nn.ELU)&#xA;    ),&#xA;    in_keys=[&#34;hidden&#34;],&#xA;    out_keys=[&#34;loc&#34;, &#34;scale&#34;],&#xA;)&#xA;# Use a SafeProbabilisticTensorDictSequential to combine the SafeModule with a&#xA;# SafeProbabilisticModule, indicating how to build the&#xA;# torch.distribution.Distribution object and what to do with it&#xA;policy_module = SafeProbabilisticTensorDictSequential(  # stochastic policy&#xA;    policy_module,&#xA;    SafeProbabilisticModule(&#xA;        in_keys=[&#34;loc&#34;, &#34;scale&#34;],&#xA;        out_keys=&#34;action&#34;,&#xA;        distribution_class=TanhNormal,&#xA;    ),&#xA;)&#xA;value_module = MLP(&#xA;    num_cells=[64, 64],&#xA;    out_features=1,&#xA;    activation=nn.ELU,&#xA;)&#xA;# Wrap the policy and value funciton in a common module&#xA;actor_value = ActorValueOperator(common_module, policy_module, value_module)&#xA;# standalone policy from this&#xA;standalone_policy = actor_value.get_policy_operator()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;exploration &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/torchrl/modules/tensordict_module/exploration.py&#34;&gt;wrappers&lt;/a&gt; and &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/torchrl/modules/models/exploration.py&#34;&gt;modules&lt;/a&gt; to easily swap between exploration and exploitation&lt;sup&gt;(1)&lt;/sup&gt;:&lt;/p&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Code&lt;/summary&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;policy_explore = EGreedyWrapper(policy)&#xA;with set_exploration_type(ExplorationType.RANDOM):&#xA;    tensordict = policy_explore(tensordict)  # will use eps-greedy&#xA;with set_exploration_type(ExplorationType.DETERMINISTIC):&#xA;    tensordict = policy_explore(tensordict)  # will not use eps-greedy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;A series of efficient &lt;a href=&#34;https://github.com/pytorch/rl/tree/main/torchrl/objectives&#34;&gt;loss modules&lt;/a&gt; and highly vectorized &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/torchrl/objectives/value/functional.py&#34;&gt;functional return and advantage&lt;/a&gt; computation.&lt;/p&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Code&lt;/summary&gt; &#xA;   &lt;h3&gt;Loss modules&lt;/h3&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from torchrl.objectives import DQNLoss&#xA;loss_module = DQNLoss(value_network=value_network, gamma=0.99)&#xA;tensordict = replay_buffer.sample(batch_size)&#xA;loss = loss_module(tensordict)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;   &lt;h3&gt;Advantage computation&lt;/h3&gt; &#xA;   &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from torchrl.objectives.value.functional import vec_td_lambda_return_estimate&#xA;advantage = vec_td_lambda_return_estimate(gamma, lmbda, next_state_value, reward, done, terminated)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;a generic &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/torchrl/trainers/trainers.py&#34;&gt;trainer class&lt;/a&gt;&lt;sup&gt;(1)&lt;/sup&gt; that executes the aforementioned training loop. Through a hooking mechanism, it also supports any logging or data transformation operation at any given time.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;various &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/torchrl/trainers/helpers/models.py&#34;&gt;recipes&lt;/a&gt; to build models that correspond to the environment being deployed.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you feel a feature is missing from the library, please submit an issue! If you would like to contribute to new features, check our &lt;a href=&#34;https://github.com/pytorch/rl/issues/509&#34;&gt;call for contributions&lt;/a&gt; and our &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/CONTRIBUTING.md&#34;&gt;contribution&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;h2&gt;Examples, tutorials and demos&lt;/h2&gt; &#xA;&lt;p&gt;A series of &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/examples/&#34;&gt;examples&lt;/a&gt; are provided with an illustrative purpose:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/rl/raw/main/sota-implementations/dqn&#34;&gt;DQN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/rl/raw/main/sota-implementations/ddpg/ddpg.py&#34;&gt;DDPG&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/rl/raw/main/sota-implementations/iql/iql_offline.py&#34;&gt;IQL&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/rl/raw/main/sota-implementations/cql/cql_offline.py&#34;&gt;CQL&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/rl/raw/main/sota-implementations/td3/td3.py&#34;&gt;TD3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/rl/raw/main/sota-implementations/td3+bc/td3+bc.py&#34;&gt;TD3+BC&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/rl/raw/main/examples/a2c_old/a2c.py&#34;&gt;A2C&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/rl/raw/main/sota-implementations/ppo/ppo.py&#34;&gt;PPO&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/rl/raw/main/sota-implementations/sac/sac.py&#34;&gt;SAC&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/rl/raw/main/sota-implementations/redq/redq.py&#34;&gt;REDQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/rl/raw/main/sota-implementations/dreamer/dreamer.py&#34;&gt;Dreamer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/rl/raw/main/sota-implementations/decision_transformer&#34;&gt;Decision Transformers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/rl/raw/main/examples/rlhf&#34;&gt;RLHF&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;and many more to come!&lt;/p&gt; &#xA;&lt;p&gt;Check the &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/sota-implementations/&#34;&gt;examples&lt;/a&gt; directory for more details about handling the various configuration settings.&lt;/p&gt; &#xA;&lt;p&gt;We also provide &lt;a href=&#34;https://pytorch.org/rl/stable#tutorials&#34;&gt;tutorials and demos&lt;/a&gt; that give a sense of what the library can do.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;re using TorchRL, please refer to this BibTeX entry to cite this work:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{bou2023torchrl,&#xA;      title={TorchRL: A data-driven decision-making library for PyTorch}, &#xA;      author={Albert Bou and Matteo Bettini and Sebastian Dittert and Vikash Kumar and Shagun Sodhani and Xiaomeng Yang and Gianni De Fabritiis and Vincent Moens},&#xA;      year={2023},&#xA;      eprint={2306.00577},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.LG}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Create a conda environment where the packages will be installed.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda create --name torch_rl python=3.9&#xA;conda activate torch_rl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;PyTorch&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Depending on the use of functorch that you want to make, you may want to install the latest (nightly) PyTorch release or the latest stable version of PyTorch. See &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;here&lt;/a&gt; for a detailed list of commands, including &lt;code&gt;pip3&lt;/code&gt; or other special installation instructions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Torchrl&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can install the &lt;strong&gt;latest stable release&lt;/strong&gt; by using&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip3 install torchrl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This should work on linux, Windows 10 and OsX (Intel or Silicon chips). On certain Windows machines (Windows 11), one should install the library locally (see below).&lt;/p&gt; &#xA;&lt;p&gt;The &lt;strong&gt;nightly build&lt;/strong&gt; can be installed via&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip3 install torchrl-nightly&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;which we currently only ship for Linux and OsX (Intel) machines. Importantly, the nightly builds require the nightly builds of PyTorch too.&lt;/p&gt; &#xA;&lt;p&gt;To install extra dependencies, call&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip3 install &#34;torchrl[atari,dm_control,gym_continuous,rendering,tests,utils,marl,checkpointing]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or a subset of these.&lt;/p&gt; &#xA;&lt;p&gt;One may also desire to install the library locally. Three main reasons can motivate this:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;the nightly/stable release isn&#39;t available for one&#39;s platform (eg, Windows 11, nightlies for Apple Silicon etc.);&lt;/li&gt; &#xA; &lt;li&gt;contributing to the code;&lt;/li&gt; &#xA; &lt;li&gt;install torchrl with a previous version of PyTorch (any version &amp;gt;= 2.0) (note that this should also be doable via a regular install followed by a downgrade to a previous pytorch version -- but the C++ binaries will not be available so some feature will not work,&lt;br&gt; such as prioritized replay buffers and the like.)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To install the library locally, start by cloning the repo:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/pytorch/rl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and don&#39;t forget to check out the branch or tag you want to use for the build:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git checkout v0.4.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Go to the directory where you have cloned the torchrl repo and install it (after installing &lt;code&gt;ninja&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd /path/to/torchrl/&#xA;pip3 install ninja -U&#xA;python setup.py develop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;One can also build the wheels to distribute to co-workers using&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python setup.py bdist_wheel&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Your wheels will be stored there &lt;code&gt;./dist/torchrl&amp;lt;name&amp;gt;.whl&lt;/code&gt; and installable via&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install torchrl&amp;lt;name&amp;gt;.whl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: Unfortunately, &lt;code&gt;pip3 install -e .&lt;/code&gt; does not currently work. Contributions to help fix this are welcome!&lt;/p&gt; &#xA;&lt;p&gt;On M1 machines, this should work out-of-the-box with the nightly build of PyTorch. If the generation of this artifact in MacOs M1 doesn&#39;t work correctly or in the execution the message &lt;code&gt;(mach-o file, but is an incompatible architecture (have &#39;x86_64&#39;, need &#39;arm64e&#39;))&lt;/code&gt; appears, then try&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ARCHFLAGS=&#34;-arch arm64&#34; python setup.py develop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run a quick sanity check, leave that directory (e.g. by executing &lt;code&gt;cd ~/&lt;/code&gt;) and try to import the library.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -c &#34;import torchrl&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This should not return any warning or error.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Optional dependencies&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;The following libraries can be installed depending on the usage one wants to make of torchrl:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# diverse&#xA;pip3 install tqdm tensorboard &#34;hydra-core&amp;gt;=1.1&#34; hydra-submitit-launcher&#xA;&#xA;# rendering&#xA;pip3 install moviepy&#xA;&#xA;# deepmind control suite&#xA;pip3 install dm_control&#xA;&#xA;# gym, atari games&#xA;pip3 install &#34;gym[atari]&#34; &#34;gym[accept-rom-license]&#34; pygame&#xA;&#xA;# tests&#xA;pip3 install pytest pyyaml pytest-instafail&#xA;&#xA;# tensorboard&#xA;pip3 install tensorboard&#xA;&#xA;# wandb&#xA;pip3 install wandb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;If a &lt;code&gt;ModuleNotFoundError: No module named ‘torchrl._torchrl&lt;/code&gt; errors occurs (or a warning indicating that the C++ binaries could not be loaded), it means that the C++ extensions were not installed or not found.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;One common reason might be that you are trying to import torchrl from within the git repo location. The following code snippet should return an error if torchrl has not been installed in &lt;code&gt;develop&lt;/code&gt; mode: &lt;pre&gt;&lt;code&gt;cd ~/path/to/rl/repo&#xA;python -c &#39;from torchrl.envs.libs.gym import GymEnv&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; If this is the case, consider executing torchrl from another location.&lt;/li&gt; &#xA; &lt;li&gt;If you&#39;re not importing torchrl from within its repo location, it could be caused by a problem during the local installation. Check the log after the &lt;code&gt;python setup.py develop&lt;/code&gt;. One common cause is a g++/C++ version discrepancy and/or a problem with the &lt;code&gt;ninja&lt;/code&gt; library.&lt;/li&gt; &#xA; &lt;li&gt;If the problem persists, feel free to open an issue on the topic in the repo, we&#39;ll make our best to help!&lt;/li&gt; &#xA; &lt;li&gt;On &lt;strong&gt;MacOs&lt;/strong&gt;, we recommend installing XCode first. With Apple Silicon M1 chips, make sure you are using the arm64-built python (e.g. &lt;a href=&#34;https://betterprogramming.pub/how-to-install-pytorch-on-apple-m1-series-512b3ad9bc6&#34;&gt;here&lt;/a&gt;). Running the following lines of code &lt;pre&gt;&lt;code&gt;wget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py&#xA;python collect_env.py&#xA;&lt;/code&gt;&lt;/pre&gt; should display &lt;pre&gt;&lt;code&gt;OS: macOS *** (arm64)&#xA;&lt;/code&gt;&lt;/pre&gt; and not &lt;pre&gt;&lt;code&gt;OS: macOS **** (x86_64)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Versioning issues can cause error message of the type &lt;code&gt;undefined symbol&lt;/code&gt; and such. For these, refer to the &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/knowledge_base/VERSIONING_ISSUES.md&#34;&gt;versioning issues document&lt;/a&gt; for a complete explanation and proposed workarounds.&lt;/p&gt; &#xA;&lt;h2&gt;Asking a question&lt;/h2&gt; &#xA;&lt;p&gt;If you spot a bug in the library, please raise an issue in this repo.&lt;/p&gt; &#xA;&lt;p&gt;If you have a more generic question regarding RL in PyTorch, post it on the &lt;a href=&#34;https://discuss.pytorch.org/c/reinforcement-learning/6&#34;&gt;PyTorch forum&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Internal collaborations to torchrl are welcome! Feel free to fork, submit issues and PRs. You can checkout the detailed contribution guide &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/CONTRIBUTING.md&#34;&gt;here&lt;/a&gt;. As mentioned above, a list of open contributions can be found in &lt;a href=&#34;https://github.com/pytorch/rl/issues/509&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Contributors are recommended to install &lt;a href=&#34;https://pre-commit.com/&#34;&gt;pre-commit hooks&lt;/a&gt; (using &lt;code&gt;pre-commit install&lt;/code&gt;). pre-commit will check for linting related issues when the code is committed locally. You can disable th check by appending &lt;code&gt;-n&lt;/code&gt; to your commit command: &lt;code&gt;git commit -m &amp;lt;commit message&amp;gt; -n&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This library is released as a PyTorch beta feature. BC-breaking changes are likely to happen but they will be introduced with a deprecation warranty after a few release cycles.&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;TorchRL is licensed under the MIT License. See &lt;a href=&#34;https://github.com/pytorch/rl/raw/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;</summary>
  </entry>
</feed>