<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-27T01:42:34Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>dvruette/sd-webui-fabric</title>
    <updated>2023-07-27T01:42:34Z</updated>
    <id>tag:github.com,2023-07-27:/dvruette/sd-webui-fabric</id>
    <link href="https://github.com/dvruette/sd-webui-fabric" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FABRIC Plugin for Stable Diffusion WebUI&lt;/h1&gt; &#xA;&lt;p&gt;Alpha version of a plugin for &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;automatic1111/stable-diffusion-webui&lt;/a&gt;. Expect bugs and rough edges and feel free to contribute if you know how fix them.&lt;/p&gt; &#xA;&lt;p&gt;üìú Paper: &lt;a href=&#34;https://arxiv.org/abs/2307.10159&#34;&gt;https://arxiv.org/abs/2307.10159&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;üé® Project page: &lt;a href=&#34;https://sd-fabric.github.io&#34;&gt;https://sd-fabric.github.io&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/dvruette/sd-webui-fabric/main/static/fabric_demo.gif&#34; alt=&#34;demo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open the &#34;Extensions&#34; tab&lt;/li&gt; &#xA; &lt;li&gt;Open the &#34;Install from URL&#34; tab&lt;/li&gt; &#xA; &lt;li&gt;Copy-paste &lt;code&gt;https://github.com/dvruette/sd-webui-fabric.git&lt;/code&gt; into &#34;URL for extension&#39;s git repository&#34; and press &#34;Install&#34;&lt;/li&gt; &#xA; &lt;li&gt;Switch to the &#34;Installed&#34; tab and press &#34;Apply and restart UI&#34;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Note: Since FABRIC is quite VRAM intensive, using &lt;code&gt;--opt-split-attention&lt;/code&gt; is recommended.&lt;/p&gt; &#xA;&lt;h3&gt;Compatibility Notes&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;SDXL is currently not supported (PRs welcome!)&lt;/li&gt; &#xA; &lt;li&gt;Compatibility with other plugins is largely untested. If you experience errors with other plugins enabled, please disable all other plugins for the best chance for FABRIC to work. If you can figure out which plugin is incompatible, please open an issue.&lt;/li&gt; &#xA; &lt;li&gt;The plugin is INCOMPATIBLE with &lt;code&gt;reference&lt;/code&gt; mode in the ControlNet plugin. Instead of using a reference image, simply add it as a liked image. If you accidentally enable FABRIC and &lt;code&gt;reference&lt;/code&gt; mode at the same time, you will have to restart the WebUI to fix it.&lt;/li&gt; &#xA; &lt;li&gt;Some attention processors are not supported. In particular, &lt;code&gt;--opt-sub-quad-attention&lt;/code&gt; and &lt;code&gt;--opt-split-attention-v1&lt;/code&gt; are not supported at the moment.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How-to and Examples&lt;/h2&gt; &#xA;&lt;p&gt;Coming soon. Feel free to share examples with us if you have found something that works well and we&#39;ll add it here :)&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{vonrutte2023fabric,&#xA;      title={FABRIC: Personalizing Diffusion Models with Iterative Feedback}, &#xA;      author={Dimitri von R√ºtte and Elisabetta Fedele and Jonathan Thomm and Lukas Wolf},&#xA;      year={2023},&#xA;      eprint={2307.10159},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>invictus717/MetaTransformer</title>
    <updated>2023-07-27T01:42:34Z</updated>
    <id>tag:github.com,2023-07-27:/invictus717/MetaTransformer</id>
    <link href="https://github.com/invictus717/MetaTransformer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Meta-Transformer for Unified Multimodal Learning&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;assets\Meta-Transformer_banner.png&#34; width=&#34;80%&#34; height=&#34;80%&#34;&gt; &lt;/p&gt; &#xA;&lt;div&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;a href=&#34;https://scholar.google.com/citations?user=KuYlJCIAAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34;&gt;Yiyuan Zhang&lt;sup&gt;1,2*&lt;/sup&gt;&lt;/a&gt;‚ÄÉ &#xA;  &lt;a href=&#34;https://kxgong.github.io/&#34; target=&#34;_blank&#34;&gt;Kaixiong Gong&lt;sup&gt;1,2*&lt;/sup&gt;&lt;/a&gt;‚ÄÉ &#xA;  &lt;a href=&#34;http://kpzhang93.github.io/&#34; target=&#34;_blank&#34;&gt;Kaipeng Zhang&lt;sup&gt;2,‚Ä†&lt;/sup&gt;&lt;/a&gt;‚ÄÉ &#xA;  &lt;br&gt; &#xA;  &lt;a href=&#34;http://www.ee.cuhk.edu.hk/~hsli/&#34; target=&#34;_blank&#34;&gt;Hongsheng Li &lt;sup&gt;1,2&lt;/sup&gt;&lt;/a&gt;‚ÄÉ &#xA;  &lt;a href=&#34;https://mmlab.siat.ac.cn/yuqiao/index.html&#34; target=&#34;_blank&#34;&gt;Yu Qiao &lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;‚ÄÉ &#xA;  &lt;a href=&#34;https://wlouyang.github.io/&#34; target=&#34;_blank&#34;&gt;Wanli Ouyang&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;‚ÄÉ &#xA;  &lt;a href=&#34;http://people.eecs.berkeley.edu/~xyyue/&#34; target=&#34;_blank&#34;&gt;Xiangyu Yue&lt;sup&gt;1,‚Ä†,‚Ä°&lt;/sup&gt;&lt;/a&gt; &#xA; &lt;/div&gt; &#xA; &lt;div&gt; &#xA;  &lt;div align=&#34;center&#34;&gt; &#xA;   &lt;sup&gt;1&lt;/sup&gt;Multimedia Lab, The Chinese University of Hong Kong‚ÄÉ &#xA;   &lt;br&gt; &#xA;   &lt;sup&gt;2&lt;/sup&gt;OpenGVLabÔºåShanghai AI Laboratory &#xA;   &lt;br&gt; &#xA;   &lt;sup&gt;*&lt;/sup&gt; Equal Contribution‚ÄÉ &#xA;   &lt;sup&gt;‚Ä†&lt;/sup&gt; Corresponding Author‚ÄÉ &#xA;   &lt;sup&gt;‚Ä°&lt;/sup&gt; Project Lead‚ÄÉ &#xA;  &lt;/div&gt; &#xA;  &lt;hr&gt; &#xA;  &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2307.10802&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arxiv-2307.10802-b31b1b?style=plastic&amp;amp;color=b31b1b&amp;amp;link=https%3A%2F%2Farxiv.org%2Fabs%2F2307.10802&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://kxgong.github.io/meta_transformer/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project-Website-brightgreen&#34; alt=&#34;website&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://mp.weixin.qq.com/s/r38bzqdJxDZUvtDI0c9CEw&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83-%E7%AE%80%E4%BB%8B-brightgreen&#34; alt=&#34;blog-cn&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/papers/2307.10802&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Space-blue&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/stars/invictus717/MetaTransformer?style=social&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://twitter.com/_akhaliq/status/1682248055637041152&#34;&gt;&lt;img src=&#34;https://img.icons8.com/color/48/000000/twitter.png&#34; width=&#34;25&#34; height=&#34;25&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=V8L8xbsTyls&amp;amp;ab_channel=CSBoard&#34;&gt;&lt;img src=&#34;https://img.icons8.com/color/48/000000/youtube-play.png&#34; width=&#34;25&#34; height=&#34;25&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://open.spotify.com/episode/6JJxcy2zMtTwr4jXPQEXjh&#34;&gt; &lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/1/19/Spotify_logo_without_text.svg?sanitize=true&#34; width=&#34;20&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;h3&gt;üåü Single Foundation Model Supports A Wide Range of Applications&lt;/h3&gt; &#xA;  &lt;p&gt;As a foundation model, Meta-Transformer can handle data from 12 modalities, which determines that it can support a wide range of applications. As shown in this figure, Meta-Transformer can provide services for downstream tasks including stock analysis üìà, weather forecasting ‚òÄÔ∏è ‚òî ‚òÅÔ∏è ‚ùÑÔ∏è ‚õÑ ‚ö°, remote sensing üì°, autonomous driving üöó, social network üåç, speech recognition üîâ, etc.&lt;/p&gt; &#xA;  &lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;assets\Meta-Transformer_application.png&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt; &lt;/p&gt; &#xA;  &lt;p&gt;&lt;strong&gt;Table 1&lt;/strong&gt;: Meta-Transformer is capable of handling up to 12 modalities, including natural language &lt;img src=&#34;assets\icons\text.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, RGB images &lt;img src=&#34;assets\icons\img.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, point clouds &lt;img src=&#34;assets\icons\pcd.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, audios &lt;img src=&#34;assets\icons\audio.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, videos &lt;img src=&#34;assets\icons\video.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, tabular data &lt;img src=&#34;assets\icons\table.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, graph &lt;img src=&#34;assets\icons\graph.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, time series data &lt;img src=&#34;assets\icons\time.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, hyper-spectral images &lt;img src=&#34;assets\icons\hyper.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, IMU &lt;img src=&#34;assets\icons\imu.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, medical images &lt;img src=&#34;assets\icons\xray.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;, and infrared images &lt;img src=&#34;assets\icons\infrared.jpg&#34; width=&#34;15&#34; height=&#34;15&#34;&gt;.&lt;/p&gt; &#xA;  &lt;p align=&#34;left&#34;&gt; &lt;img src=&#34;assets\Meta-Transformer_cmp.png&#34; width=&#34;100%&#34;&gt; &lt;/p&gt; &#xA;  &lt;h2&gt;üö©üö©üö© Shared-Encoder, Unpaired Data, More Modalities&lt;/h2&gt; &#xA;  &lt;div&gt; &#xA;   &lt;img class=&#34;image&#34; src=&#34;assets\Meta-Transformer_teaser.png&#34; width=&#34;52%&#34; height=&#34;100%&#34;&gt; &#xA;   &lt;img class=&#34;image&#34; src=&#34;assets\Meta-Transformer_exp.png&#34; width=&#34;45.2%&#34; height=&#34;100%&#34;&gt; &#xA;  &lt;/div&gt; &#xA;  &lt;p&gt;This repository is built to explore the potential and extensibility of transformers for multimodal learning. We utilize the advantages of Transformers to deal with length-variant sequences. Then we propose the &lt;em&gt;Data-to-Sequence&lt;/em&gt; tokenization following a meta-scheme, then we apply it to 12 modalities including text, image, point cloud, audio, video, infrared, hyper-spectral, X-Ray, tabular, graph, time-series, and Inertial Measurement Unit (IMU) data.&lt;/p&gt; &#xA;  &lt;p align=&#34;left&#34;&gt; &lt;img src=&#34;assets\Meta-Transformer_data2seq.png&#34; width=&#34;100%&#34;&gt; &lt;/p&gt; &#xA;  &lt;p&gt;After obtaining the token sequence, we employ a modality-shared encoder to extract representation across different modalities. With task-specific heads, Meta-Transformer can handle various tasks on the different modalities, such as: classification, detection, and segmentation.&lt;/p&gt; &#xA;  &lt;p align=&#34;left&#34;&gt; &lt;img src=&#34;assets\Meta-Transformer_framework.png&#34; width=&#34;100%&#34;&gt; &lt;/p&gt; &#xA;  &lt;h1&gt;üåü News&lt;/h1&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;2023.7.25:&lt;/strong&gt; üéâüéâüéâ We have released a well-documented code for graph data understanding. The implementation for Tabular data and point cloud will be released very soon.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;2023.7.23:&lt;/strong&gt; We have released the code and pretrained weights for image understanding and time-series forcasting.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;2023.7.22:&lt;/strong&gt; üåüüåüüåü Pretrained weights and a usage demo for our Meta-Transformer have been released. Comprehensive documentation and implementation of the image modality are underway and will be released soon. Stay tuned for more exciting updates!‚åõ‚åõ‚åõ&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;2023.7.21:&lt;/strong&gt; Paper is released at &lt;a href=&#34;https://arxiv.org/abs/2307.10802&#34;&gt;arxiv&lt;/a&gt;, and code will be gradually released.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;2023.7.8:&lt;/strong&gt; Github Repository Initialization.&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA;  &lt;h1&gt;üîì Model Zoo&lt;/h1&gt; &#xA;  &lt;!-- &lt;details&gt; --&gt; &#xA;  &lt;summary&gt; Open-source Modality-Agnostic Models &lt;/summary&gt; &#xA;  &lt;br&gt; &#xA;  &lt;div&gt; &#xA;   &lt;table&gt; &#xA;    &lt;thead&gt; &#xA;     &lt;tr&gt; &#xA;      &lt;th align=&#34;center&#34;&gt;Model&lt;/th&gt; &#xA;      &lt;th align=&#34;center&#34;&gt;Pretraining&lt;/th&gt; &#xA;      &lt;th align=&#34;center&#34;&gt;Scale&lt;/th&gt; &#xA;      &lt;th align=&#34;center&#34;&gt;#Param&lt;/th&gt; &#xA;      &lt;th align=&#34;center&#34;&gt;Download&lt;/th&gt; &#xA;     &lt;/tr&gt; &#xA;    &lt;/thead&gt; &#xA;    &lt;tbody&gt; &#xA;     &lt;tr&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;Meta-Transformer-B16&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;LAION-2B&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;Base&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;85M&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/19ahcN2QKknkir_bayhTW5rucuAiX0OXq/view?usp=sharing&#34;&gt;ckpt&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;/tr&gt; &#xA;     &lt;tr&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;Meta-Transformer-L14&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;LAION-2B&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;Large&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;302M&lt;/td&gt; &#xA;      &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/15EtzCBAQSqmelhdLz6k880A19_RpcX9B/view?usp=drive_link&#34;&gt;ckpt&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;/tr&gt; &#xA;    &lt;/tbody&gt; &#xA;   &lt;/table&gt; &#xA;  &lt;/div&gt; &#xA;  &lt;!-- &lt;/details&gt; --&gt; &#xA;  &lt;!-- &lt;details&gt; --&gt; &#xA;  &lt;summary&gt;Demo of Use for Pretrained Encoder&lt;/summary&gt; &#xA;  &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from timm.models.vision_transformer import Block&#xA;ckpt = torch.load(&#34;Meta-Transformer_base_patch16_encoder.pth&#34;)&#xA;encoder = nn.Sequential(*[&#xA;            Block(&#xA;                dim=768,&#xA;                num_heads=12,&#xA;                mlp_ratio=4.,&#xA;                qkv_bias=True,&#xA;                norm_layer=nn.LayerNorm,&#xA;                act_layer=nn.GELU&#xA;            )&#xA;            for i in range(12)])&#xA;encoder.load_state_dict(ckpt,strict=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;!-- &lt;/details&gt; --&gt; &#xA;  &lt;h1&gt;üïô ToDo&lt;/h1&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Meta-Transformer with Large Language Models.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Multimodal Joint Training with Meta-Transformer.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Support More Modalities and More Tasks.&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA;  &lt;h1&gt;Contact&lt;/h1&gt; &#xA;  &lt;p&gt;üöÄüöÄüöÄ We aspire to shape this repository into &lt;strong&gt;a formidable foundation for mainstream AI perception tasks across diverse modalities&lt;/strong&gt;. Your contributions can play a significant role in this endeavor, and we warmly welcome your participation in our project!&lt;/p&gt; &#xA;  &lt;p&gt;To contact us, never hestitate to send an email to &lt;code&gt;yiyuanzhang.ai@gmail.com&lt;/code&gt; ,&lt;code&gt;kaixionggong@gmail.com&lt;/code&gt;, &lt;code&gt;zhangkaipeng@pjlab.org.cn&lt;/code&gt;, or &lt;code&gt;xyyue@ie.cuhk.edu.hk&lt;/code&gt;! &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;  &lt;h1&gt;Citation&lt;/h1&gt; &#xA;  &lt;p&gt;If the code and paper help your research, please kindly cite:&lt;/p&gt; &#xA;  &lt;pre&gt;&lt;code&gt;@article{zhang2023metatransformer,&#xA;        title={Meta-Transformer: A Unified Framework for Multimodal Learning}, &#xA;        author={Zhang, Yiyuan and Gong, Kaixiong and Zhang, Kaipeng and Li, Hongsheng and Qiao, Yu and Ouyang, Wanli and Yue, Xiangyu},&#xA;        year={2023},&#xA;        journal={arXiv preprint arXiv:2307.10802},&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;h1&gt;License&lt;/h1&gt; &#xA;  &lt;p&gt;This project is released under the &lt;a href=&#34;https://raw.githubusercontent.com/invictus717/MetaTransformer/master/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; &#xA;  &lt;h1&gt;Acknowledgement&lt;/h1&gt; &#xA;  &lt;p&gt;This code is developed based on excellent open-sourced projects including &lt;a href=&#34;https://github.com/open-mmlab/mmpretrain/tree/mmcls-1.x&#34;&gt;MMClassification&lt;/a&gt;, &lt;a href=&#34;https://github.com/open-mmlab/mmdetection&#34;&gt;MMDetection&lt;/a&gt;, &lt;a href=&#34;https://github.com/open-mmlab/mmsegmentation&#34;&gt;MMsegmentation&lt;/a&gt;, &lt;a href=&#34;https://github.com/guochengqian/openpoints&#34;&gt;OpenPoints&lt;/a&gt;, &lt;a href=&#34;https://github.com/thuml/Time-Series-Library&#34;&gt;Time-Series-Library&lt;/a&gt;, &lt;a href=&#34;https://github.com/microsoft/Graphormer&#34;&gt;Graphomer&lt;/a&gt;, &lt;a href=&#34;https://github.com/danfenghong/IEEE_TGRS_SpectralFormer&#34;&gt;SpectralFormer&lt;/a&gt;, and &lt;a href=&#34;https://github.com/czczup/ViT-Adapter&#34;&gt;ViT-Adapter&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;/div&gt;&#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>FlagAlpha/Llama2-Chinese</title>
    <updated>2023-07-27T01:42:34Z</updated>
    <id>tag:github.com,2023-07-27:/FlagAlpha/Llama2-Chinese</id>
    <link href="https://github.com/FlagAlpha/Llama2-Chinese" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Llama‰∏≠ÊñáÁ§æÂå∫ÔºåÊúÄÂ•ΩÁöÑ‰∏≠ÊñáLlamaÂ§ßÊ®°ÂûãÔºåÂÆåÂÖ®ÂºÄÊ∫êÂèØÂïÜÁî®&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; Llama2-Chinese &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/assets/llama.png&#34; alt=&#34;Llama&#34; style=&#34;width: 20%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;font face=&#34;Èªë‰Ωì&#34; color=&#34;orange&#34; size=&#34;6&#34;&gt; ÊúÄÂ•ΩÁöÑ‰∏≠ÊñáLlamaÂ§ßÊ®°Âûã &lt;/font&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://llama.family&#34;&gt;Âú®Á∫ø‰ΩìÈ™åÔºöllama.family&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üóÇÔ∏è ÂÜÖÂÆπÂØºÂºï&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E5%9B%BD%E5%86%85llama2%E6%9C%80%E6%96%B0%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%E4%B8%8A%E7%BA%BF&#34;&gt;üêº ÂõΩÂÜÖLlama2ÊúÄÊñ∞‰∏ãËΩΩÂú∞ÂùÄ‰∏äÁ∫øÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E7%A4%BE%E5%8C%BA%E4%BB%8B%E7%BB%8Dllama2%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA&#34;&gt;üî• Á§æÂå∫‰ªãÁªçÔºöLlama2‰∏≠ÊñáÁ§æÂå∫&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E6%8B%A9llama2%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA&#34;&gt;‰∏∫‰ªÄ‰πàÈÄâÊã©Llama2‰∏≠ÊñáÁ§æÂå∫Ôºü&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E7%A4%BE%E5%8C%BA%E6%B4%BB%E5%8A%A8&#34;&gt;Á§æÂå∫Ê¥ªÂä®&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E7%AB%8B%E5%8D%B3%E5%8A%A0%E5%85%A5%E6%88%91%E4%BB%AC&#34;&gt;Á´ãÂç≥Âä†ÂÖ•Êàë‰ª¨ÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E7%A4%BE%E5%8C%BA%E5%85%AC%E5%91%8A&#34;&gt;üì¢ Á§æÂå∫ÂÖ¨Âëä&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8826%E6%97%A5%E6%96%B0%E5%A2%9Ellama2-13b%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E5%8F%82%E6%95%B0%E7%9A%844bit%E9%87%8F%E5%8C%96%E5%8E%8B%E7%BC%A9%E7%89%88%E6%9C%AC&#34;&gt;2023Âπ¥7Êúà26Êó•ÔºöÊñ∞Â¢ûLlama2-13B‰∏≠ÊñáÂæÆË∞ÉÂèÇÊï∞ÁöÑ4bitÈáèÂåñÂéãÁº©ÁâàÊú¨ÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8825%E6%97%A5%E7%A4%BE%E5%8C%BA%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7llama%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA%E6%AC%A2%E8%BF%8E%E5%A4%A7%E5%AE%B6%E5%85%B3%E6%B3%A8%E8%8E%B7%E5%8F%96%E6%9C%80%E6%96%B0%E5%88%86%E4%BA%AB%E5%92%8C%E5%8A%A8%E6%80%81&#34;&gt;2023Âπ¥7Êúà25Êó•ÔºöÁ§æÂå∫ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑‚ÄúLlama‰∏≠ÊñáÁ§æÂå∫‚ÄùÊ¨¢ËøéÂ§ßÂÆ∂ÂÖ≥Ê≥®ÔºåËé∑ÂèñÊúÄÊñ∞ÂàÜ‰∫´ÂíåÂä®ÊÄÅÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8824%E6%97%A5flagalpha%E6%96%B0%E5%A2%9Ellama2-13b%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E5%8F%82%E6%95%B0&#34;&gt;2023Âπ¥7Êúà24Êó•ÔºöFlagAlphaÊñ∞Â¢ûLlama2-13B‰∏≠ÊñáÂæÆË∞ÉÂèÇÊï∞ÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8824%E6%97%A5llamafamily%E6%96%B0%E5%A2%9Ellama2-70b%E5%9C%A8%E7%BA%BF%E4%BD%93%E9%AA%8C&#34;&gt;2023Âπ¥7Êúà24Êó•Ôºöllama.familyÊñ∞Â¢ûLlama2-70BÂú®Á∫ø‰ΩìÈ™åÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8823%E6%97%A5llama2%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E5%8F%82%E6%95%B0%E5%8F%91%E5%B8%83%E8%87%B3hugging-face%E4%BB%93%E5%BA%93flagalpha&#34;&gt;2023Âπ¥7Êúà23Êó•ÔºöLlama2‰∏≠ÊñáÂæÆË∞ÉÂèÇÊï∞ÂèëÂ∏ÉËá≥Hugging Face‰ªìÂ∫ìFlagAlphaÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8822%E6%97%A5llama2%E5%9C%A8%E7%BA%BF%E4%BD%93%E9%AA%8C%E9%93%BE%E6%8E%A5llamafamily%E4%B8%8A%E7%BA%BF%E5%90%8C%E6%97%B6%E5%8C%85%E5%90%ABmeta%E5%8E%9F%E7%89%88%E5%92%8C%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E7%89%88%E6%9C%AC&#34;&gt;2023Âπ¥7Êúà22Êó•ÔºöLlama2Âú®Á∫ø‰ΩìÈ™åÈìæÊé•llama.family‰∏äÁ∫øÔºåÂêåÊó∂ÂåÖÂê´MetaÂéüÁâàÂíå‰∏≠ÊñáÂæÆË∞ÉÁâàÊú¨ÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8821%E6%97%A5%E8%AF%84%E6%B5%8B%E4%BA%86meta%E5%8E%9F%E5%A7%8B%E7%89%88llama2-chat%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%AD%E6%96%87%E9%97%AE%E7%AD%94%E8%83%BD%E5%8A%9B&#34;&gt;2023Âπ¥7Êúà21Êó•ÔºöËØÑÊµã‰∫ÜMetaÂéüÂßãÁâàLlama2 ChatÊ®°ÂûãÁöÑ‰∏≠ÊñáÈóÆÁ≠îËÉΩÂäõÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8821%E6%97%A5%E6%96%B0%E5%A2%9Ellama2%E6%A8%A1%E5%9E%8B%E7%9A%84hugging-face%E7%89%88%E6%9C%AC%E5%9B%BD%E5%86%85%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80&#34;&gt;2023Âπ¥7Êúà21Êó•ÔºöÊñ∞Â¢ûLlama2Ê®°ÂûãÁöÑHugging FaceÁâàÊú¨ÂõΩÂÜÖ‰∏ãËΩΩÂú∞ÂùÄÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8820%E6%97%A5%E6%96%B0%E5%A2%9E%E9%A3%9E%E4%B9%A6%E7%9F%A5%E8%AF%86%E5%BA%93%E6%96%87%E6%A1%A3%E6%AC%A2%E8%BF%8E%E5%A4%A7%E5%AE%B6%E4%B8%80%E8%B5%B7%E5%85%B1%E5%BB%BA&#34;&gt;2023Âπ¥7Êúà20Êó•ÔºöÊñ∞Â¢ûÈ£û‰π¶Áü•ËØÜÂ∫ìÊñáÊ°£ÔºåÊ¨¢ËøéÂ§ßÂÆ∂‰∏ÄËµ∑ÂÖ±Âª∫ÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8820%E6%97%A5%E5%9B%BD%E5%86%85llama2%E6%9C%80%E6%96%B0%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%E4%B8%8A%E7%BA%BF&#34;&gt;2023Âπ¥7Êúà20Êó•ÔºöÂõΩÂÜÖLlama2ÊúÄÊñ∞‰∏ãËΩΩÂú∞ÂùÄ‰∏äÁ∫øÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8819%E6%97%A5%E6%AD%A3%E5%BC%8F%E5%90%AF%E5%8A%A8llama2%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E5%85%B3%E6%B3%A8%E6%88%91%E4%BB%AC%E8%8E%B7%E5%8F%96%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81&#34;&gt;2023Âπ¥7Êúà19Êó•ÔºöÊ≠£ÂºèÂêØÂä®Llama2Ê®°ÂûãÁöÑ‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉÔºåÂÖ≥Ê≥®Êàë‰ª¨Ëé∑ÂèñÂÆûÊó∂Âä®ÊÄÅÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8819%E6%97%A5llama2%E5%9B%BD%E5%86%85%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%E6%AD%A3%E5%9C%A8%E5%90%AF%E5%8A%A8%E6%95%AC%E8%AF%B7%E6%9C%9F%E5%BE%85&#34;&gt;2023Âπ¥7Êúà19Êó•ÔºöLlama2ÂõΩÂÜÖ‰∏ãËΩΩÂú∞ÂùÄÊ≠£Âú®ÂêØÂä®ÔºåÊï¨ËØ∑ÊúüÂæÖÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8819%E6%97%A5%E5%BC%80%E5%90%AFllama2%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA%E6%AC%A2%E8%BF%8E%E5%A4%A7%E5%AE%B6%E5%8A%A0%E5%85%A5&#34;&gt;2023Âπ¥7Êúà19Êó•ÔºöÂºÄÂêØLlama2‰∏≠ÊñáÁ§æÂå∫ÔºåÊ¨¢ËøéÂ§ßÂÆ∂Âä†ÂÖ•ÔºÅ&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90&#34;&gt;üìù Êï∞ÊçÆÊù•Ê∫ê&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2&#34;&gt;‚è¨ Ê®°ÂûãÈÉ®ÁΩ≤&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B&#34;&gt;È¢ÑËÆ≠ÁªÉÊ®°Âûã&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#chat%E6%A8%A1%E5%9E%8B&#34;&gt;ChatÊ®°Âûã&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%94%A8%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B&#34;&gt;Ê®°ÂûãË∞ÉÁî®‰ª£Á†ÅÁ§∫‰æã&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#gradio%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E9%97%AE%E7%AD%94%E5%B9%B3%E5%8F%B0&#34;&gt;GradioÂø´ÈÄüÊê≠Âª∫ÈóÆÁ≠îÂπ≥Âè∞&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83&#34;&gt;üí° Ê®°ÂûãÂæÆË∞É&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E5%BE%AE%E8%B0%83%E8%BF%87%E7%A8%8B&#34;&gt;ÂæÆË∞ÉËøáÁ®ã&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#step1-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87&#34;&gt;Step1: ÁéØÂ¢ÉÂáÜÂ§á&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#step2-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87&#34;&gt;Step2: Êï∞ÊçÆÂáÜÂ§á&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#step3-%E5%BE%AE%E8%B0%83%E8%84%9A%E6%9C%AC&#34;&gt;Step3: ÂæÆË∞ÉËÑöÊú¨&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E5%8F%82%E6%95%B0&#34;&gt;‰∏≠ÊñáÂæÆË∞ÉÂèÇÊï∞&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96&#34;&gt;üçÑ Ê®°ÂûãÈáèÂåñ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B&#34;&gt;ü•á Ê®°ÂûãËØÑÊµã&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99&#34;&gt;üìñ Â≠¶‰π†ËµÑÊñô&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#meta%E5%AE%98%E6%96%B9%E5%AF%B9%E4%BA%8Ellama2%E7%9A%84%E4%BB%8B%E7%BB%8D&#34;&gt;MetaÂÆòÊñπÂØπ‰∫éLlama2ÁöÑ‰ªãÁªç&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#llama%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87&#34;&gt;LlamaÁõ∏ÂÖ≥ËÆ∫Êñá&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#llama2%E7%9A%84%E8%AF%84%E6%B5%8B%E7%BB%93%E6%9E%9C&#34;&gt;Llama2ÁöÑËØÑÊµãÁªìÊûú&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E8%87%B4%E8%B0%A2&#34;&gt;üéâ Ëá¥Ë∞¢&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E9%97%AE%E9%A2%98%E5%8F%8D%E9%A6%88&#34;&gt;ü§î ÈóÆÈ¢òÂèçÈ¶à&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üêº ÂõΩÂÜÖLlama2ÊúÄÊñ∞‰∏ãËΩΩÂú∞ÂùÄ‰∏äÁ∫øÔºÅ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-7BÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_kR2fwuJdG1F3CoF33rwpIA1?pwd=z9kf&#34;&gt;https://pan.xunlei.com/s/VN_kR2fwuJdG1F3CoF33rwpIA1?pwd=z9kf&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-7B-ChatÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_kQa1_HBvV-X9QVI6jV2kOA1?pwd=xmra&#34;&gt;https://pan.xunlei.com/s/VN_kQa1_HBvV-X9QVI6jV2kOA1?pwd=xmra&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-13BÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_izibaMDoptluWodzJw4cRA1?pwd=2qqb&#34;&gt;https://pan.xunlei.com/s/VN_izibaMDoptluWodzJw4cRA1?pwd=2qqb&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-13B-ChatÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_iyyponyapjIDLXJCNfqy7A1?pwd=t3xw&#34;&gt;https://pan.xunlei.com/s/VN_iyyponyapjIDLXJCNfqy7A1?pwd=t3xw&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-7B Hugging FaceÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep&#34;&gt;https://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-7B-Chat Hugging FaceÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir&#34;&gt;https://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-13B Hugging FaceÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf&#34;&gt;https://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-13B-Chat Hugging FaceÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg&#34;&gt;https://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üî• Á§æÂå∫‰ªãÁªçÔºöLlama2‰∏≠ÊñáÁ§æÂå∫&lt;/h2&gt; &#xA;&lt;p&gt;Ê¨¢ËøéÊù•Âà∞Llama2‰∏≠ÊñáÁ§æÂå∫ÔºÅÊàë‰ª¨ÊòØ‰∏Ä‰∏™‰∏ìÊ≥®‰∫éLlama2Ê®°ÂûãÂú®‰∏≠ÊñáÊñπÈù¢ÁöÑ‰ºòÂåñÂíå‰∏äÂ±ÇÂª∫ËÆæÁöÑÈ´òÁ∫ßÊäÄÊúØÁ§æÂå∫„ÄÇ &lt;strong&gt;*Âü∫‰∫éÂ§ßËßÑÊ®°‰∏≠ÊñáÊï∞ÊçÆÔºå‰ªéÈ¢ÑËÆ≠ÁªÉÂºÄÂßãÂØπLlama2Ê®°ÂûãËøõË°å‰∏≠ÊñáËÉΩÂäõÁöÑÊåÅÁª≠Ëø≠‰ª£ÂçáÁ∫ß*&lt;/strong&gt;„ÄÇ Êàë‰ª¨ÁÉ≠Âø±Ê¨¢ËøéÂØπÂ§ßÊ®°ÂûãLLMÂÖÖÊª°ÁÉ≠ÊÉÖÁöÑÂºÄÂèëËÄÖÂíåÁ†îÁ©∂ËÄÖÂä†ÂÖ•Êàë‰ª¨ÁöÑË°åÂàó„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;‰∏∫‰ªÄ‰πàÈÄâÊã©Llama2‰∏≠ÊñáÁ§æÂå∫Ôºü&lt;/h3&gt; &#xA;&lt;p&gt;üöÄ &lt;strong&gt;È´òÁ∫ßÂ∑•Á®ãÂ∏àÂõ¢ÈòüÊîØÊåÅ&lt;/strong&gt;ÔºöÁ§æÂå∫Êúâ‰∏ÄÊâπ‰∏ìÊ≥®‰∏∫Â§ßÂÆ∂ÊúçÂä°ÁöÑNLPÈ´òÁ∫ßÂ∑•Á®ãÂ∏àÔºåÊàë‰ª¨ÊúâÁùÄÂº∫Â§ßÁöÑÊäÄÊúØÊîØÊåÅÂíå‰∏∞ÂØåÁöÑÁªèÈ™åÔºå‰∏∫ÊÇ®Êèê‰æõ‰∏ì‰∏öÁöÑÊåáÂØºÂíåÂ∏ÆÂä©„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;üéØ &lt;strong&gt;‰∏≠Êñá‰ºòÂåñ&lt;/strong&gt;ÔºöÊàë‰ª¨Ëá¥Âäõ‰∫éÂú®Llama2Ê®°ÂûãÁöÑ‰∏≠ÊñáÂ§ÑÁêÜÊñπÈù¢ËøõË°å‰ºòÂåñÔºåÊé¢Á¥¢ÈÄÇÁî®‰∫é‰∏≠ÊñáÁöÑÊúÄ‰Ω≥ÂÆûË∑µÔºå‰ª•ÊèêÂçáÂÖ∂ÊÄßËÉΩÂíåÈÄÇÂ∫îÊÄß„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;üí° &lt;strong&gt;ÂàõÊñ∞‰∫§ÊµÅ&lt;/strong&gt;ÔºöÊàë‰ª¨Êã•Êúâ‰∏ÄÊîØÂØåÊúâÂàõÈÄ†ÂäõÂíåÁªèÈ™åÁöÑÁ§æÂå∫ÊàêÂëòÂõ¢ÈòüÔºåÂÆöÊúüÁªÑÁªáÁ∫ø‰∏äÊ¥ªÂä®„ÄÅÊäÄÊúØÁ†îËÆ®ÂíåÁªèÈ™åÂàÜ‰∫´Ôºå‰øÉËøõÊàêÂëòÈó¥ÁöÑÂàõÊñ∞‰∫§ÊµÅ„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;üåê &lt;strong&gt;ÂÖ®ÁêÉËÅîÁªì&lt;/strong&gt;ÔºöÊàë‰ª¨Ê¨¢ËøéÊù•Ëá™‰∏ñÁïåÂêÑÂú∞ÁöÑÂºÄÂèëËÄÖÂä†ÂÖ•Á§æÂå∫ÔºåÊûÑÂª∫‰∏Ä‰∏™ÂºÄÊîæ„ÄÅÂ§öÂÖÉÂåñÁöÑÂ≠¶‰π†Âíå‰∫§ÊµÅÂπ≥Âè∞„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;ü§ù &lt;strong&gt;ÂºÄÊîæÂÖ±‰∫´&lt;/strong&gt;ÔºöÊàë‰ª¨ÈºìÂä±Á§æÂå∫ÊàêÂëòÂºÄÊ∫êÂàÜ‰∫´‰ª£Á†ÅÂíåÊ®°ÂûãÔºåÊé®Âä®Âêà‰ΩúÂÖ±Ëµ¢ÔºåÂÖ±Âêå‰øÉËøõ‰∏≠ÊñáNLPÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;Á§æÂå∫Ê¥ªÂä®&lt;/h3&gt; &#xA;&lt;p&gt;üóìÔ∏è &lt;strong&gt;Á∫ø‰∏äËÆ≤Â∫ß&lt;/strong&gt;ÔºöÈÇÄËØ∑Ë°å‰∏öÂÜÖ‰∏ìÂÆ∂ËøõË°åÁ∫ø‰∏äËÆ≤Â∫ßÔºåÂàÜ‰∫´Llama2Âú®‰∏≠ÊñáNLPÈ¢ÜÂüüÁöÑÊúÄÊñ∞ÊäÄÊúØÂíåÂ∫îÁî®ÔºåÊé¢ËÆ®ÂâçÊ≤øÁ†îÁ©∂ÊàêÊûú„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;üíª &lt;strong&gt;È°πÁõÆÂ±ïÁ§∫&lt;/strong&gt;ÔºöÊàêÂëòÂèØÂ±ïÁ§∫Ëá™Â∑±Âú®Llama2‰∏≠Êñá‰ºòÂåñÊñπÈù¢ÁöÑÈ°πÁõÆÊàêÊûúÔºåËé∑ÂæóÂèçÈ¶àÂíåÂª∫ËÆÆÔºå‰øÉËøõÈ°πÁõÆÂçè‰Ωú„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;üìö &lt;strong&gt;Â≠¶‰π†ËµÑÊ∫ê&lt;/strong&gt;ÔºöÁ§æÂå∫Áª¥Êä§‰∏∞ÂØåÁöÑÂ≠¶‰π†ËµÑÊñôÂ∫ìÔºåÂåÖÊã¨ÊïôÁ®ã„ÄÅÊñáÊ°£ÂíåËÆ∫ÊñáËß£ËØªÔºå‰∏∫ÊàêÂëòÊèê‰æõÂÖ®Èù¢ÁöÑÂ≠¶‰π†ÊîØÊåÅ„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;üìù &lt;strong&gt;ËÆ∫ÊñáËß£ËØª&lt;/strong&gt;ÔºöÁ§æÂå∫ÊàêÂëòÂÖ±ÂêåËß£ËØª‰∏éLlama2Áõ∏ÂÖ≥ÁöÑÊúÄÊñ∞Á†îÁ©∂ËÆ∫ÊñáÔºåÊ∑±ÂÖ•ÁêÜËß£ÂâçÊ≤øÁÆóÊ≥ïÂíåÊñπÊ≥ï„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;üéâ &lt;strong&gt;‰∏ªÈ¢òÊ¥ªÂä®&lt;/strong&gt;ÔºöÂÆöÊúü‰∏æÂäûÂêÑÁ±ª‰∏ªÈ¢òÊ¥ªÂä®ÔºåÂåÖÊã¨ÊåëÊàòËµõ„ÄÅÈªëÂÆ¢È©¨ÊãâÊùæÂíåÊäÄÊúØÊ≤ôÈæôÔºåËÆ©Á§æÂå∫ÊàêÂëòÂú®ËΩªÊùæÊÑâÂø´ÁöÑÊ∞õÂõ¥‰∏≠‰∫§ÊµÅÂíåÂ≠¶‰π†„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;üåü &lt;strong&gt;Â•ñÂä±ËÆ°Âàí&lt;/strong&gt;ÔºöÊàë‰ª¨ËÆæÁ´ãÂ•ñÂä±ËÆ°ÂàíÔºåÂØπÁ§æÂå∫‰∏≠ÁßØÊûÅÂèÇ‰∏é„ÄÅË¥°ÁåÆ‰ºòÁßÄÁöÑÊàêÂëòÁªô‰∫àËç£Ë™âÂíåÂ•ñÂä±ÔºåÊøÄÂä±Êõ¥Â§ö‰ºòÁßÄ‰∫∫ÊâçÁöÑÂä†ÂÖ•„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;üìà &lt;strong&gt;ÊäÄÊúØÂí®ËØ¢&lt;/strong&gt;ÔºöÊàë‰ª¨Êèê‰æõÊäÄÊúØÂí®ËØ¢ÊúçÂä°ÔºåËß£Á≠îÊÇ®Âú®Llama2ÂºÄÂèëÂíå‰ºòÂåñËøáÁ®ã‰∏≠ÈÅáÂà∞ÁöÑÈóÆÈ¢òÔºåÂä©ÊÇ®Âø´ÈÄüÊîªÂÖãÈöæÂÖ≥„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;üöÄ &lt;strong&gt;È°πÁõÆÂêà‰Ωú&lt;/strong&gt;ÔºöÈºìÂä±ÊàêÂëòÈó¥ÁöÑÈ°πÁõÆÂêà‰ΩúÔºåÂÖ±ÂêåÊé¢Á¥¢Llama2Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊΩúÂäõÔºåÊâìÈÄ†ÂàõÊñ∞Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;Á´ãÂç≥Âä†ÂÖ•Êàë‰ª¨ÔºÅ&lt;/h3&gt; &#xA;&lt;p&gt;üìö &lt;strong&gt;ÊÑøÊôØ&lt;/strong&gt;ÔºöÊó†ËÆ∫ÊÇ®ÊòØÂØπLlama2Â∑≤ÊúâÁ†îÁ©∂ÂíåÂ∫îÁî®ÁªèÈ™åÁöÑ‰∏ì‰∏öÂºÄÂèëËÄÖÔºåËøòÊòØÂØπLlama2‰∏≠Êñá‰ºòÂåñÊÑüÂÖ¥Ë∂£Âπ∂Â∏åÊúõÊ∑±ÂÖ•Êé¢Á¥¢ÁöÑÊñ∞ÊâãÔºåÊàë‰ª¨ÈÉΩÁÉ≠ÂàáÊúüÂæÖÊÇ®ÁöÑÂä†ÂÖ•„ÄÇÂú®Llama2‰∏≠ÊñáÁ§æÂå∫ÔºåÊÇ®Â∞ÜÊúâÊú∫‰ºö‰∏éË°å‰∏öÂÜÖÈ°∂Â∞ñ‰∫∫ÊâçÂÖ±Âêå‰∫§ÊµÅÔºåÊê∫ÊâãÊé®Âä®‰∏≠ÊñáNLPÊäÄÊúØÁöÑËøõÊ≠•ÔºåÂºÄÂàõÊõ¥Âä†ÁæéÂ•ΩÁöÑÊäÄÊúØÊú™Êù•ÔºÅ&lt;/p&gt; &#xA;&lt;p&gt;üîó &lt;strong&gt;Ê∏©È¶®ÊèêÁ§∫&lt;/strong&gt;ÔºöÊú¨Á§æÂå∫‰∏∫‰∏ì‰∏öÊäÄÊúØ‰∫§ÊµÅÂπ≥Âè∞ÔºåÊàë‰ª¨ÁÉ≠ÂàáÊúüÊúõÂøóÂêåÈÅìÂêàÁöÑÂºÄÂèëËÄÖÂíåÁ†îÁ©∂ËÄÖÂä†ÂÖ•„ÄÇËØ∑ÈÅµÂÆàÁ§æÂå∫ÂáÜÂàôÔºåÂÖ±ÂêåÁª¥Êä§ÁßØÊûÅÂêë‰∏äÁöÑÂ≠¶‰π†Ê∞õÂõ¥Ôºå‰ªª‰Ωï‰∏éLlama2Êó†ÂÖ≥ÁöÑÂÜÖÂÆπÂíåÂπøÂëäÂ∞ÜË¢´Ê∏ÖÁêÜ„ÄÇÊÑüË∞¢ÊÇ®ÁöÑÁêÜËß£ÂíåÊîØÊåÅÔºÅ&lt;/p&gt; &#xA;&lt;h2&gt;üì¢ Á§æÂå∫ÂÖ¨Âëä&lt;/h2&gt; &#xA;&lt;h4&gt;2023Âπ¥7Êúà26Êó•ÔºöÊñ∞Â¢ûLlama2-13B‰∏≠ÊñáÂæÆË∞ÉÂèÇÊï∞ÁöÑ&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96&#34;&gt;4bitÈáèÂåñÂéãÁº©ÁâàÊú¨&lt;/a&gt;ÔºÅ&lt;/h4&gt; &#xA;&lt;h4&gt;2023Âπ¥7Êúà25Êó•ÔºöÁ§æÂå∫ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑‚ÄúLlama‰∏≠ÊñáÁ§æÂå∫‚ÄùÊ¨¢ËøéÂ§ßÂÆ∂ÂÖ≥Ê≥®ÔºåËé∑ÂèñÊúÄÊñ∞ÂàÜ‰∫´ÂíåÂä®ÊÄÅÔºÅ&lt;/h4&gt; &#xA;&lt;h4&gt;2023Âπ¥7Êúà24Êó•Ôºö&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;FlagAlpha&lt;/a&gt;Êñ∞Â¢ûLlama2-13B‰∏≠ÊñáÂæÆË∞ÉÂèÇÊï∞ÔºÅ&lt;/h4&gt; &#xA;&lt;h4&gt;2023Âπ¥7Êúà24Êó•Ôºö&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;Êñ∞Â¢ûLlama2-70BÂú®Á∫ø‰ΩìÈ™åÔºÅ&lt;/h4&gt; &#xA;&lt;h4&gt;2023Âπ¥7Êúà23Êó•ÔºöLlama2‰∏≠ÊñáÂæÆË∞ÉÂèÇÊï∞ÂèëÂ∏ÉËá≥Hugging Face‰ªìÂ∫ì&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;FlagAlpha&lt;/a&gt;ÔºÅ&lt;/h4&gt; &#xA;&lt;h4&gt;2023Âπ¥7Êúà22Êó•ÔºöLlama2Âú®Á∫ø‰ΩìÈ™åÈìæÊé•&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;‰∏äÁ∫øÔºåÂêåÊó∂ÂåÖÂê´MetaÂéüÁâàÂíå‰∏≠ÊñáÂæÆË∞ÉÁâàÊú¨ÔºÅ&lt;/h4&gt; &#xA;&lt;h4&gt;2023Âπ¥7Êúà21Êó•ÔºöËØÑÊµã‰∫ÜMetaÂéüÂßãÁâàLlama2 ChatÊ®°ÂûãÁöÑ&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B&#34;&gt;‰∏≠ÊñáÈóÆÁ≠îËÉΩÂäõ&lt;/a&gt;ÔºÅ&lt;/h4&gt; &#xA;&lt;h4&gt;2023Âπ¥7Êúà21Êó•ÔºöÊñ∞Â¢ûLlama2Ê®°ÂûãÁöÑHugging FaceÁâàÊú¨ÂõΩÂÜÖ‰∏ãËΩΩÂú∞ÂùÄÔºÅ&lt;/h4&gt; &#xA;&lt;h4&gt;2023Âπ¥7Êúà20Êó•ÔºöÊñ∞Â¢û&lt;a href=&#34;https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink&#34;&gt;È£û‰π¶Áü•ËØÜÂ∫ìÊñáÊ°£&lt;/a&gt;ÔºåÊ¨¢ËøéÂ§ßÂÆ∂‰∏ÄËµ∑ÂÖ±Âª∫ÔºÅ&lt;/h4&gt; &#xA;&lt;h4&gt;2023Âπ¥7Êúà20Êó•ÔºöÂõΩÂÜÖLlama2ÊúÄÊñ∞‰∏ãËΩΩÂú∞ÂùÄ‰∏äÁ∫øÔºÅ&lt;/h4&gt; &#xA;&lt;h4&gt;2023Âπ¥7Êúà19Êó•ÔºöÊ≠£ÂºèÂêØÂä®Llama2Ê®°ÂûãÁöÑ‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉÔºåÂÖ≥Ê≥®Êàë‰ª¨Ëé∑ÂèñÂÆûÊó∂Âä®ÊÄÅÔºÅ&lt;/h4&gt; &#xA;&lt;h4&gt;2023Âπ¥7Êúà19Êó•ÔºöLlama2ÂõΩÂÜÖ‰∏ãËΩΩÂú∞ÂùÄÊ≠£Âú®ÂêØÂä®ÔºåÊï¨ËØ∑ÊúüÂæÖÔºÅ&lt;/h4&gt; &#xA;&lt;h4&gt;2023Âπ¥7Êúà19Êó•ÔºöÂºÄÂêØLlama2‰∏≠ÊñáÁ§æÂå∫ÔºåÊ¨¢ËøéÂ§ßÂÆ∂Âä†ÂÖ•ÔºÅ&lt;/h4&gt; &#xA;&lt;h2&gt;üìù Êï∞ÊçÆÊù•Ê∫ê&lt;/h2&gt; &#xA;&lt;p&gt;Êàë‰ª¨ËÆ°ÂàíÈÄöËøá‰ª•‰∏ãÊï∞ÊçÆÊù•‰ºòÂåñLlama2ÁöÑ‰∏≠ÊñáËÉΩÂäõ:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Á±ªÂûã&lt;/th&gt; &#xA;   &lt;th&gt;ÊèèËø∞&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ÁΩëÁªúÊï∞ÊçÆ&lt;/td&gt; &#xA;   &lt;td&gt;‰∫íËÅîÁΩë‰∏äÂÖ¨ÂºÄÁöÑÁΩëÁªúÊï∞ÊçÆÔºåÊåëÈÄâÂá∫ÂéªÈáçÂêéÁöÑÈ´òË¥®Èáè‰∏≠ÊñáÊï∞ÊçÆÔºåÊ∂âÂèäÂà∞ÁôæÁßë„ÄÅ‰π¶Á±ç„ÄÅÂçöÂÆ¢„ÄÅÊñ∞Èóª„ÄÅÂÖ¨Âëä„ÄÅÂ∞èËØ¥Á≠âÈ´òË¥®ÈáèÈïøÊñáÊú¨Êï∞ÊçÆ„ÄÇ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/goldsmith/Wikipedia&#34;&gt;Wikipedia&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‰∏≠ÊñáWikipediaÁöÑÊï∞ÊçÆ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/BAAI-WuDao/Model&#34;&gt;ÊÇüÈÅì&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‰∏≠ÊñáÊÇüÈÅìÂºÄÊ∫êÁöÑ200GÊï∞ÊçÆ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/CLUEbenchmark/CLUEDatasetSearch&#34;&gt;Clue&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ClueÂºÄÊîæÁöÑ‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÔºåËøõË°åÊ∏ÖÊ¥óÂêéÁöÑÈ´òË¥®Èáè‰∏≠ÊñáÈïøÊñáÊú¨Êï∞ÊçÆ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Á´ûËµõÊï∞ÊçÆÈõÜ&lt;/td&gt; &#xA;   &lt;td&gt;ËøëÂπ¥Êù•‰∏≠ÊñáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ§ö‰ªªÂä°Á´ûËµõÊï∞ÊçÆÈõÜÔºåÁ∫¶150‰∏™&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/esbatmop/MNBVC&#34;&gt;MNBVC&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MNBVC ‰∏≠Ê∏ÖÊ¥óÂá∫Êù•ÁöÑÈÉ®ÂàÜÊï∞ÊçÆÈõÜ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Â∏åÊúõÂ§ßÂÆ∂Â¶ÇÊûúÊúâËæÉÈ´òË¥®ÈáèÁöÑÊï∞ÊçÆÈõÜËÉΩÂ§üÊèê‰æõÁªôÊàë‰ª¨Ôºå‰∏çËÉúÊÑüÊøÄ!üíïüíï&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;‚è¨ Ê®°ÂûãÈÉ®ÁΩ≤&lt;/h2&gt; &#xA;&lt;p&gt;MetaÂú®ü§óHugging Face‰∏äÊèê‰æõ‰∫ÜÊâÄÊúâÊ®°ÂûãÁöÑ‰∏ãËΩΩÈìæÊé•Ôºö&lt;a href=&#34;https://huggingface.co/meta-llama&#34;&gt;https://huggingface.co/meta-llama&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;È¢ÑËÆ≠ÁªÉÊ®°Âûã&lt;/h3&gt; &#xA;&lt;p&gt;Llama2È¢ÑËÆ≠ÁªÉÊ®°ÂûãÂåÖÂê´7B„ÄÅ13BÂíå70B‰∏â‰∏™ÁâàÊú¨&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Ê®°ÂûãÂêçÁß∞&lt;/th&gt; &#xA;   &lt;th&gt;ü§óÊ®°ÂûãÂä†ËΩΩÂêçÁß∞&lt;/th&gt; &#xA;   &lt;th&gt;‰∏ãËΩΩÂú∞ÂùÄ&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-7B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-hf&#34;&gt;Ê®°Âûã‰∏ãËΩΩ&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-13B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-13b-hf&#34;&gt;Ê®°Âûã‰∏ãËΩΩ&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-70B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-70b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-70b-hf&#34;&gt;Ê®°Âûã‰∏ãËΩΩ&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;ChatÊ®°Âûã&lt;/h3&gt; &#xA;&lt;p&gt;Llama2-ChatÊ®°ÂûãÂü∫‰∫éÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°å‰∫ÜÁõëÁù£ÂæÆË∞ÉÔºåÂÖ∑Â§áÊõ¥Âº∫ÁöÑÂØπËØùËÉΩÂäõ&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Ê®°ÂûãÂêçÁß∞&lt;/th&gt; &#xA;   &lt;th&gt;ü§óÊ®°ÂûãÂä†ËΩΩÂêçÁß∞&lt;/th&gt; &#xA;   &lt;th&gt;‰∏ãËΩΩÂú∞ÂùÄ&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-chat-hf&#34;&gt;Ê®°Âûã‰∏ãËΩΩ&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-13B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-13b-chat-hf&#34;&gt;Ê®°Âûã‰∏ãËΩΩ&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-70B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-70b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-70b-chat-hf&#34;&gt;Ê®°Âûã‰∏ãËΩΩ&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Ê®°ÂûãË∞ÉÁî®‰ª£Á†ÅÁ§∫‰æã&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;model = AutoModelForCausalLM.from_pretrained(&#39;meta-llama/Llama-2-7b-chat-hf&#39;,device_map=&#39;auto&#39;,torch_dtype=torch.float16,load_in_8bit=True)&#xA;model =model.eval()&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;meta-llama/Llama-2-7b-chat-hf&#39;,use_fast=False)&#xA;tokenizer.pad_token = tokenizer.eos_token&#xA;input_ids = tokenizer([&#39;&amp;lt;s&amp;gt;Human: ‰ªãÁªç‰∏Ä‰∏ã‰∏≠ÂõΩ\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#39;], return_tensors=&#34;pt&#34;,add_special_tokens=False).input_ids.to(&#39;cuda&#39;)        &#xA;generate_input = {&#xA;    &#34;input_ids&#34;:input_ids,&#xA;    &#34;max_new_tokens&#34;:512,&#xA;    &#34;do_sample&#34;:True,&#xA;    &#34;top_k&#34;:50,&#xA;    &#34;top_p&#34;:0.95,&#xA;    &#34;temperature&#34;:0.3,&#xA;    &#34;repetition_penalty&#34;:1.3,&#xA;    &#34;eos_token_id&#34;:tokenizer.eos_token_id,&#xA;    &#34;bos_token_id&#34;:tokenizer.bos_token_id,&#xA;    &#34;pad_token_id&#34;:tokenizer.pad_token_id&#xA;}&#xA;generate_ids  = model.generate(**generate_input)&#xA;text = tokenizer.decode(generate_ids[0])&#xA;print(text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;GradioÂø´ÈÄüÊê≠Âª∫ÈóÆÁ≠îÂπ≥Âè∞&lt;/h3&gt; &#xA;&lt;p&gt;Âü∫‰∫égradioÊê≠Âª∫ÁöÑÈóÆÁ≠îÁïåÈù¢ÔºåÂÆûÁé∞‰∫ÜÊµÅÂºèÁöÑËæìÂá∫ÔºåÂ∞Ü‰∏ãÈù¢‰ª£Á†ÅÂ§çÂà∂Âà∞ÊéßÂà∂Âè∞ËøêË°åÔºå‰ª•‰∏ã‰ª£Á†Å‰ª•Llama2-7B-ChatÊ®°Âûã‰∏∫‰æãÔºå&lt;font color=&#34;#006600&#34;&gt;‰∏çÂêåÊ®°ÂûãÂè™ÈúÄ‰øÆÊîπ‰∏Ä‰∏ã‰ª£Á†ÅÈáåÁöÑÊ®°ÂûãÂêçÁß∞Â∞±Â•Ω‰∫Üüòä&lt;/font&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python examples/chat_gradio.py --model_name_or_path meta-llama/Llama-2-7b-chat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üí° Ê®°ÂûãÂæÆË∞É&lt;/h2&gt; &#xA;&lt;p&gt;Êú¨‰ªìÂ∫ì‰∏≠Êèê‰æõ‰∫ÜÂü∫‰∫éLoRAÁöÑÂæÆË∞É‰ª£Á†ÅÔºåÊú™Êù•Êàë‰ª¨Â∞Ü‰ºöÊâ©Â±ïÊõ¥Â§öÁöÑÂæÆË∞ÉÁÆóÊ≥ïÔºåÊï¨ËØ∑ÊúüÂæÖÔºÅÂÖ≥‰∫éLoRAÁöÑËØ¶ÁªÜ‰ªãÁªçÂèØ‰ª•ÂèÇËÄÉËÆ∫Êñá‚Äú&lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;LoRA: Low-Rank Adaptation of Large Language Models&lt;/a&gt;‚Äù‰ª•ÂèäÂæÆËΩØGithub‰ªìÂ∫ì&lt;a href=&#34;https://github.com/microsoft/LoRA&#34;&gt;LoRA&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;ÂæÆË∞ÉËøáÁ®ã&lt;/h3&gt; &#xA;&lt;h4&gt;Step1: ÁéØÂ¢ÉÂáÜÂ§á&lt;/h4&gt; &#xA;&lt;p&gt;Ê†πÊçÆ&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/requirements.txt&#34;&gt;requirements.txt&lt;/a&gt;ÂÆâË£ÖÂØπÂ∫îÁöÑÁéØÂ¢É‰æùËµñ„ÄÇ&lt;/p&gt; &#xA;&lt;h4&gt;Step2: Êï∞ÊçÆÂáÜÂ§á&lt;/h4&gt; &#xA;&lt;p&gt;Âú®dataÁõÆÂΩï‰∏ãÊèê‰æõ‰∫Ü‰∏Ä‰ªΩÁî®‰∫éÊ®°ÂûãsftÁöÑÊï∞ÊçÆÊ†∑‰æãÔºö&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ËÆ≠ÁªÉÊï∞ÊçÆÔºö&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/data/train_sft.csv&#34;&gt;data/train_sft.csv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;È™åËØÅÊï∞ÊçÆÔºö&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/data/dev_sft.csv&#34;&gt;data/dev_sft.csv&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;ÊØè‰∏™csvÊñá‰ª∂‰∏≠ÂåÖÂê´‰∏ÄÂàó‚Äútext‚ÄùÔºåÊØè‰∏ÄË°å‰∏∫‰∏Ä‰∏™ËÆ≠ÁªÉÊ†∑‰æãÔºåÊØè‰∏™ËÆ≠ÁªÉÊ†∑‰æãÊåâÁÖß‰ª•‰∏ãÊ†ºÂºèÂ∞ÜÈóÆÈ¢òÂíåÁ≠îÊ°àÁªÑÁªá‰∏∫Ê®°ÂûãËæìÂÖ•ÔºåÊÇ®ÂèØ‰ª•ÊåâÁÖß‰ª•‰∏ãÊ†ºÂºèËá™ÂÆö‰πâËÆ≠ÁªÉÂíåÈ™åËØÅÊï∞ÊçÆÈõÜÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#34;&amp;lt;s&amp;gt;Human: &#34;+ÈóÆÈ¢ò+&#34;\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#34;+Á≠îÊ°à&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;‰æãÂ¶ÇÔºå&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;s&amp;gt;Human: Áî®‰∏ÄÂè•ËØùÊèèËø∞Âú∞ÁêÉ‰∏∫‰ªÄ‰πàÊòØÁã¨‰∏ÄÊó†‰∫åÁöÑ„ÄÇ&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: Âõ†‰∏∫Âú∞ÁêÉÊòØÁõÆÂâç‰∏∫Ê≠¢ÂîØ‰∏ÄÂ∑≤Áü•Â≠òÂú®ÁîüÂëΩÁöÑË°åÊòü„ÄÇ&amp;lt;/s&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Step3: ÂæÆË∞ÉËÑöÊú¨&lt;/h4&gt; &#xA;&lt;p&gt;Êàë‰ª¨Êèê‰æõ‰∫ÜÁî®‰∫éÂæÆË∞ÉÁöÑËÑöÊú¨&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/train/sft/finetune.sh&#34;&gt;train/sft/finetune.sh&lt;/a&gt;ÔºåÈÄöËøá‰øÆÊîπËÑöÊú¨ÁöÑÈÉ®ÂàÜÂèÇÊï∞ÂÆûÁé∞Ê®°ÂûãÁöÑÂæÆË∞ÉÔºåÂÖ≥‰∫éÂæÆË∞ÉÁöÑÂÖ∑‰Ωì‰ª£Á†ÅËßÅ&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/train/sft/finetune_clm_lora.py&#34;&gt;train/sft/finetune_clm_lora.py&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;‰∏≠ÊñáÂæÆË∞ÉÂèÇÊï∞&lt;/h3&gt; &#xA;&lt;p&gt;Êàë‰ª¨Âü∫‰∫é‰∏≠ÊñáÊåá‰ª§Êï∞ÊçÆÈõÜÂØπLlama2-ChatÊ®°ÂûãËøõË°å‰∫ÜÂæÆË∞ÉÔºå‰ΩøÂæóLlama2Ê®°ÂûãÊúâÁùÄÊõ¥Âº∫ÁöÑ‰∏≠ÊñáÂØπËØùËÉΩÂäõ„ÄÇLoRAÂèÇÊï∞‰ª•Âèä‰∏éÂü∫Á°ÄÊ®°ÂûãÂêàÂπ∂ÁöÑÂèÇÊï∞ÂùáÂ∑≤‰∏ä‰º†Ëá≥&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;Hugging Face&lt;/a&gt;ÔºåÁõÆÂâçÂåÖÂê´7BÂíå13BÁöÑÊ®°Âûã„ÄÇ&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Ê®°ÂûãÂêçÁß∞&lt;/th&gt; &#xA;   &lt;th&gt;ü§óÊ®°ÂûãÂä†ËΩΩÂêçÁß∞&lt;/th&gt; &#xA;   &lt;th&gt;Âü∫Á°ÄÊ®°ÂûãÁâàÊú¨&lt;/th&gt; &#xA;   &lt;th&gt;‰∏ãËΩΩÂú∞ÂùÄ&lt;/th&gt; &#xA;   &lt;th&gt;‰ªãÁªç&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-Chinese-7b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-7b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat-LoRA&#34;&gt;Ê®°Âûã‰∏ãËΩΩ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‰∏≠ÊñáÊåá‰ª§ÂæÆË∞ÉÁöÑLoRAÂèÇÊï∞&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-Chinese-7b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-7b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat&#34;&gt;Ê®°Âûã‰∏ãËΩΩ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‰∏≠ÊñáÊåá‰ª§ÂæÆË∞ÉÁöÑLoRAÂèÇÊï∞‰∏éÂü∫Á°ÄÊ®°ÂûãÂèÇÊï∞ÂêàÂπ∂ÁâàÊú¨&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-Chinese-13b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-13b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-LoRA&#34;&gt;Ê®°Âûã‰∏ãËΩΩ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‰∏≠ÊñáÊåá‰ª§ÂæÆË∞ÉÁöÑLoRAÂèÇÊï∞&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-Chinese-13b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-13b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat&#34;&gt;Ê®°Âûã‰∏ãËΩΩ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‰∏≠ÊñáÊåá‰ª§ÂæÆË∞ÉÁöÑLoRAÂèÇÊï∞‰∏éÂü∫Á°ÄÊ®°ÂûãÂèÇÊï∞ÂêàÂπ∂ÁâàÊú¨&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!-- ## üöÄ Êú™Êù•ËÆ°Âàí --&gt; &#xA;&lt;!-- ## üí™ Â¢ûÂº∫ËÉΩÂäõ --&gt; &#xA;&lt;h2&gt;üçÑ Ê®°ÂûãÈáèÂåñ&lt;/h2&gt; &#xA;&lt;p&gt;Êàë‰ª¨ÂØπ‰∏≠ÊñáÂæÆË∞ÉÁöÑÊ®°ÂûãÂèÇÊï∞ËøõË°å‰∫ÜÈáèÂåñÔºåÊñπ‰æø‰ª•Êõ¥Â∞ëÁöÑËÆ°ÁÆóËµÑÊ∫êËøêË°å„ÄÇÁõÆÂâçÂ∑≤ÁªèÂú®&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;Hugging Face&lt;/a&gt;‰∏ä‰º†‰∫Ü13B‰∏≠ÊñáÂæÆË∞ÉÊ®°Âûã&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat&#34;&gt;FlagAlpha/Llama2-Chinese-13b-Chat&lt;/a&gt;ÁöÑ4bitÂéãÁº©ÁâàÊú¨&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#34;&gt;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&lt;/a&gt;ÔºåÂÖ∑‰ΩìË∞ÉÁî®ÊñπÂºèÂ¶Ç‰∏ãÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from transformers import AutoTokenizer&#xA;from auto_gptq import AutoGPTQForCausalLM&#xA;model = AutoGPTQForCausalLM.from_quantized(&#39;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#39;, device=&#34;cuda:0&#34;)&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#39;,use_fast=False)&#xA;input_ids = tokenizer([&#39;&amp;lt;s&amp;gt;Human: ÊÄé‰πàÁôª‰∏äÁÅ´Êòü\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#39;], return_tensors=&#34;pt&#34;,add_special_tokens=False).input_ids.to(&#39;cuda&#39;)        &#xA;generate_input = {&#xA;    &#34;input_ids&#34;:input_ids,&#xA;    &#34;max_new_tokens&#34;:512,&#xA;    &#34;do_sample&#34;:True,&#xA;    &#34;top_k&#34;:50,&#xA;    &#34;top_p&#34;:0.95,&#xA;    &#34;temperature&#34;:0.3,&#xA;    &#34;repetition_penalty&#34;:1.3,&#xA;    &#34;eos_token_id&#34;:tokenizer.eos_token_id,&#xA;    &#34;bos_token_id&#34;:tokenizer.bos_token_id,&#xA;    &#34;pad_token_id&#34;:tokenizer.pad_token_id&#xA;}&#xA;generate_ids  = model.generate(**generate_input)&#xA;text = tokenizer.decode(generate_ids[0])&#xA;print(text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ü•á Ê®°ÂûãËØÑÊµã&lt;/h2&gt; &#xA;&lt;p&gt;‰∏∫‰∫ÜËÉΩÂ§üÊõ¥Âä†Ê∏ÖÊô∞Âú∞‰∫ÜËß£Llama2Ê®°ÂûãÁöÑ‰∏≠ÊñáÈóÆÁ≠îËÉΩÂäõÔºåÊàë‰ª¨Á≠õÈÄâ‰∫Ü‰∏Ä‰∫õÂÖ∑Êúâ‰ª£Ë°®ÊÄßÁöÑ‰∏≠ÊñáÈóÆÈ¢òÔºåÂØπLlama2Ê®°ÂûãËøõË°åÊèêÈóÆ„ÄÇÊàë‰ª¨ÊµãËØïÁöÑÊ®°ÂûãÂåÖÂê´MetaÂÖ¨ÂºÄÁöÑLlama2-7B-ChatÂíåLlama2-13B-Chat‰∏§‰∏™ÁâàÊú¨ÔºåÊ≤°ÊúâÂÅö‰ªª‰ΩïÂæÆË∞ÉÂíåËÆ≠ÁªÉ„ÄÇÊµãËØïÈóÆÈ¢òÁ≠õÈÄâËá™&lt;a href=&#34;https://github.com/AtomEcho/AtomBulb&#34;&gt;AtomBulb&lt;/a&gt;ÔºåÂÖ±95‰∏™ÊµãËØïÈóÆÈ¢òÔºåÂåÖÂê´ÔºöÈÄöÁî®Áü•ËØÜ„ÄÅËØ≠Ë®ÄÁêÜËß£„ÄÅÂàõ‰ΩúËÉΩÂäõ„ÄÅÈÄªËæëÊé®ÁêÜ„ÄÅ‰ª£Á†ÅÁºñÁ®ã„ÄÅÂ∑•‰ΩúÊäÄËÉΩ„ÄÅ‰ΩøÁî®Â∑•ÂÖ∑„ÄÅ‰∫∫Ê†ºÁâπÂæÅÂÖ´‰∏™Â§ßÁöÑÁ±ªÂà´„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;ÊµãËØï‰∏≠‰ΩøÁî®ÁöÑPromptÂ¶Ç‰∏ãÔºå‰æãÂ¶ÇÂØπ‰∫éÈóÆÈ¢ò‚ÄúÂàóÂá∫5ÁßçÂèØ‰ª•ÊîπÂñÑÁù°Áú†Ë¥®ÈáèÁöÑÊñπÊ≥ï‚ÄùÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[INST] &#xA;&amp;lt;&amp;lt;SYS&amp;gt;&amp;gt;&#xA;You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. The answer always been translate into Chinese language.&#xA;&#xA;If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don&#39;t know the answer to a question, please don&#39;t share false information.&#xA;&#xA;The answer always been translate into Chinese language.&#xA;&amp;lt;&amp;lt;/SYS&amp;gt;&amp;gt;&#xA;&#xA;ÂàóÂá∫5ÁßçÂèØ‰ª•ÊîπÂñÑÁù°Áú†Ë¥®ÈáèÁöÑÊñπÊ≥ï&#xA;[/INST]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Llama2-7B-ChatÁöÑÊµãËØïÁªìÊûúËßÅ&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/assets/meta_eval_7B.md&#34;&gt;meta_eval_7B.md&lt;/a&gt;ÔºåLlama2-13B-ChatÁöÑÊµãËØïÁªìÊûúËßÅ&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/assets/meta_eval_13B.md&#34;&gt;meta_eval_13B.md&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;ÈÄöËøáÊµãËØïÊàë‰ª¨ÂèëÁé∞ÔºåMetaÂéüÂßãÁöÑLlama2 ChatÊ®°ÂûãÂØπ‰∫é‰∏≠ÊñáÈóÆÁ≠îÁöÑÂØπÈΩêÊïàÊûú‰∏ÄËà¨ÔºåÂ§ßÈÉ®ÂàÜÊÉÖÂÜµ‰∏ãÈÉΩ‰∏çËÉΩÁªôÂá∫‰∏≠ÊñáÂõûÁ≠îÔºåÊàñËÄÖÊòØ‰∏≠Ëã±ÊñáÊ∑∑ÊùÇÁöÑÂΩ¢Âºè„ÄÇÂõ†Ê≠§ÔºåÂü∫‰∫é‰∏≠ÊñáÊï∞ÊçÆÂØπLlama2Ê®°ÂûãËøõË°åËÆ≠ÁªÉÂíåÂæÆË∞ÉÂçÅÂàÜÂøÖË¶ÅÔºåÊàë‰ª¨ÁöÑ‰∏≠ÊñáÁâàLlama2Ê®°Âûã‰πüÂ∑≤ÁªèÂú®ËÆ≠ÁªÉ‰∏≠ÔºåËøëÊúüÂ∞ÜÂØπÁ§æÂå∫ÂºÄÊîæ„ÄÇ&lt;/p&gt; &#xA;&lt;h2&gt;üìñ Â≠¶‰π†ËµÑÊñô&lt;/h2&gt; &#xA;&lt;h3&gt;MetaÂÆòÊñπÂØπ‰∫é&lt;a href=&#34;https://ai.meta.com/llama&#34;&gt;Llama2&lt;/a&gt;ÁöÑ‰ªãÁªç&lt;/h3&gt; &#xA;&lt;p&gt;Ëá™‰ªéMetaÂÖ¨Âè∏ÂèëÂ∏ÉÁ¨¨‰∏Ä‰ª£LLaMAÊ®°Âûã‰ª•Êù•ÔºåÁæäÈ©ºÊ®°ÂûãÂÆ∂ÊóèÁπÅËç£ÂèëÂ±ï„ÄÇËøëÊúüMetaÂèëÂ∏É‰∫ÜLlama2ÁâàÊú¨ÔºåÂºÄÊ∫êÂèØÂïÜÁî®ÔºåÂú®Ê®°ÂûãÂíåÊïàÊûú‰∏äÊúâ‰∫ÜÈáçÂ§ßÊõ¥Êñ∞„ÄÇLlama2ÊÄªÂÖ±ÂÖ¨Â∏É‰∫Ü7B„ÄÅ13BÂíå70B‰∏âÁßçÂèÇÊï∞Â§ßÂ∞èÁöÑÊ®°Âûã„ÄÇÁõ∏ÊØî‰∫éLLaMAÔºåLlama2ÁöÑËÆ≠ÁªÉÊï∞ÊçÆËææÂà∞‰∫Ü2‰∏á‰∫øtokenÔºå‰∏ä‰∏ãÊñáÈïøÂ∫¶‰πüÁî±‰πãÂâçÁöÑ2048ÂçáÁ∫ßÂà∞4096ÔºåÂèØ‰ª•ÁêÜËß£ÂíåÁîüÊàêÊõ¥ÈïøÁöÑÊñáÊú¨„ÄÇLlama2 ChatÊ®°ÂûãÂü∫‰∫é100‰∏á‰∫∫Á±ªÊ†áËÆ∞Êï∞ÊçÆÂæÆË∞ÉÂæóÂà∞ÔºåÂú®Ëã±ÊñáÂØπËØù‰∏äËææÂà∞‰∫ÜÊé•ËøëChatGPTÁöÑÊïàÊûú„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;LlamaÁõ∏ÂÖ≥ËÆ∫Êñá&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.13971&#34;&gt;LLaMA: Open and Efficient Foundation Language Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scontent-lax3-2.xx.fbcdn.net/v/t39.2365-6/10000000_663429262362723_1696968207443577320_n.pdf?_nc_cat=101&amp;amp;ccb=1-7&amp;amp;_nc_sid=3c67a6&amp;amp;_nc_ohc=5ol-jUSglG4AX9uTu-j&amp;amp;_nc_ht=scontent-lax3-2.xx&amp;amp;oh=00_AfDVmJr77y3bv5GCbJ26w-stMJNXsZPTwVDlWhoIkkb8Lg&amp;amp;oe=64BDB0D1&#34;&gt;Llama 2: Open Foundation and Fine-Tuned Chat Models&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Llama2ÁöÑËØÑÊµãÁªìÊûú&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://scontent-lax3-2.xx.fbcdn.net/v/t39.8562-6/361265668_276217774995411_4529778090866658620_n.jpg?_nc_cat=1&amp;amp;ccb=1-7&amp;amp;_nc_sid=6825c5&amp;amp;_nc_ohc=gSMV6flCjbAAX8pE8nm&amp;amp;_nc_ht=scontent-lax3-2.xx&amp;amp;oh=00_AfC53vAix8IkoTlO1Z46g2IfS3p7jb51A8TaIrOK6grRsQ&amp;amp;oe=64BC6826&#34; alt=&#34;Llama2Eval&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;üéâ Ëá¥Ë∞¢&lt;/h2&gt; &#xA;&lt;p&gt;ÊÑüË∞¢ÂéüÂ≠êÂõûÂ£∞&lt;a href=&#34;https://github.com/AtomEcho&#34;&gt;AtomEcho&lt;/a&gt;Âõ¢ÈòüÁöÑÊäÄÊúØÂíåËµÑÊ∫êÊîØÊåÅÔºÅ&lt;/p&gt; &#xA;&lt;p&gt;ÊÑüË∞¢ @xzsGenius ÂØπLlama2‰∏≠ÊñáÁ§æÂå∫ÁöÑË¥°ÁåÆÔºÅ&lt;/p&gt; &#xA;&lt;p&gt;ÊÑüË∞¢ @Z PotentialsÁ§æÂå∫ÂØπLlama2‰∏≠ÊñáÁ§æÂå∫ÁöÑÊîØÊåÅÔºÅ&lt;/p&gt; &#xA;&lt;h2&gt;ü§î ÈóÆÈ¢òÂèçÈ¶à&lt;/h2&gt; &#xA;&lt;p&gt;Â¶ÇÊúâÈóÆÈ¢òÔºåËØ∑Âú®GitHub Issue‰∏≠Êèê‰∫§ÔºåÂú®Êèê‰∫§ÈóÆÈ¢ò‰πãÂâçÔºåËØ∑ÂÖàÊü•ÈòÖ‰ª•ÂæÄÁöÑissueÊòØÂê¶ËÉΩËß£ÂÜ≥‰Ω†ÁöÑÈóÆÈ¢ò„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Á§ºË≤åÂú∞ÊèêÂá∫ÈóÆÈ¢òÔºåÊûÑÂª∫ÂíåË∞êÁöÑËÆ®ËÆ∫Á§æÂå∫„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Âä†ÂÖ•&lt;a href=&#34;https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink&#34;&gt;È£û‰π¶Áü•ËØÜÂ∫ì&lt;/a&gt;Ôºå‰∏ÄËµ∑ÂÖ±Âª∫Á§æÂå∫ÊñáÊ°£„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Âä†ÂÖ•ÂæÆ‰ø°Áæ§ËÆ®ËÆ∫üòçüòç&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/assets/wechat.jpeg&#34; alt=&#34;Wechat&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://api.star-history.com/svg?repos=FlagAlpha/Llama2-Chinese&amp;amp;type=Date&#34; alt=&#34;Wechat&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt;</summary>
  </entry>
</feed>