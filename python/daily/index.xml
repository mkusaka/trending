<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-03T01:35:00Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>jhao104/proxy_pool</title>
    <updated>2024-03-03T01:35:00Z</updated>
    <id>tag:github.com,2024-03-03:/jhao104/proxy_pool</id>
    <link href="https://github.com/jhao104/proxy_pool" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Python ProxyPool for web spider&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ProxyPool 爬虫代理IP池&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.org/jhao104/proxy_pool&#34;&gt;&lt;img src=&#34;https://travis-ci.org/jhao104/proxy_pool.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://www.spiderpy.cn/blog/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Powered%20by-@j_hao104-green.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/jhao104/proxy_pool/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/packagist/l/doctrine/orm.svg?sanitize=true&#34; alt=&#34;Packagist&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/jhao104/proxy_pool/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/jhao104/proxy_pool.svg?sanitize=true&#34; alt=&#34;GitHub contributors&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/jhao104/proxy_pool&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/language-Python-green.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;______                        ______             _&#xA;| ___ \_                      | ___ \           | |&#xA;| |_/ / \__ __   __  _ __   _ | |_/ /___   ___  | |&#xA;|  __/|  _// _ \ \ \/ /| | | ||  __// _ \ / _ \ | |&#xA;| |   | | | (_) | &amp;gt;  &amp;lt; \ |_| || |  | (_) | (_) || |___&#xA;\_|   |_|  \___/ /_/\_\ \__  |\_|   \___/ \___/ \_____\&#xA;                       __ / /&#xA;                      /___ /&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ProxyPool&lt;/h3&gt; &#xA;&lt;p&gt;爬虫代理IP池项目,主要功能为定时采集网上发布的免费代理验证入库，定时验证入库的代理保证代理的可用性，提供API和CLI两种使用方式。同时你也可以扩展代理源以增加代理池IP的质量和数量。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;文档: &lt;a href=&#34;https://proxy-pool.readthedocs.io/zh/latest/&#34;&gt;document&lt;/a&gt; &lt;a href=&#34;https://proxy-pool.readthedocs.io/zh/latest/?badge=latest&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/proxy-pool/badge/?version=latest&#34; alt=&#34;Documentation Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;支持版本: &lt;a href=&#34;https://docs.python.org/2.7/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-2.7-green.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.python.org/3.5/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-3.5-blue.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.python.org/3.6/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-3.6-blue.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.python.org/3.7/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-3.7-blue.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.python.org/3.8/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-3.8-blue.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.python.org/3.9/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-3.9-blue.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.python.org/3.10/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-3.10-blue.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.python.org/3.11/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-3.11-blue.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;测试地址: &lt;a href=&#34;http://demo.spiderpy.cn&#34;&gt;http://demo.spiderpy.cn&lt;/a&gt; (勿压谢谢)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;付费代理推荐: &lt;a href=&#34;https://get.brightdata.com/github_jh&#34;&gt;luminati-china&lt;/a&gt;. 国外的亮数据BrightData（以前叫luminati）被认为是代理市场领导者，覆盖全球的7200万IP，大部分是真人住宅IP，成功率扛扛的。付费套餐多种，需要高质量代理IP的可以注册后联系中文客服，开通后赠送5美金余额和教程指引(PS:用不明白的同学可以参考这个&lt;a href=&#34;https://www.cnblogs.com/jhao/p/15611785.html&#34;&gt;使用教程&lt;/a&gt;)。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;运行项目&lt;/h3&gt; &#xA;&lt;h5&gt;下载代码:&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;git clone&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone git@github.com:jhao104/proxy_pool.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;releases&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;https://github.com/jhao104/proxy_pool/releases 下载对应zip文件&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;安装依赖:&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;更新配置:&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# setting.py 为项目配置文件&#xA;&#xA;# 配置API服务&#xA;&#xA;HOST = &#34;0.0.0.0&#34;               # IP&#xA;PORT = 5000                    # 监听端口&#xA;&#xA;&#xA;# 配置数据库&#xA;&#xA;DB_CONN = &#39;redis://:pwd@127.0.0.1:8888/0&#39;&#xA;&#xA;&#xA;# 配置 ProxyFetcher&#xA;&#xA;PROXY_FETCHER = [&#xA;    &#34;freeProxy01&#34;,      # 这里是启用的代理抓取方法名，所有fetch方法位于fetcher/proxyFetcher.py&#xA;    &#34;freeProxy02&#34;,&#xA;    # ....&#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;启动项目:&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 如果已经具备运行条件, 可用通过proxyPool.py启动。&#xA;# 程序分为: schedule 调度程序 和 server Api服务&#xA;&#xA;# 启动调度程序&#xA;python proxyPool.py schedule&#xA;&#xA;# 启动webApi服务&#xA;python proxyPool.py server&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Docker Image&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker pull jhao104/proxy_pool&#xA;&#xA;docker run --env DB_CONN=redis://:password@ip:port/0 -p 5010:5010 jhao104/proxy_pool:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;docker-compose&lt;/h3&gt; &#xA;&lt;p&gt;项目目录下运行:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;使用&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Api&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;启动web服务后, 默认配置下会开启 &lt;a href=&#34;http://127.0.0.1:5010&#34;&gt;http://127.0.0.1:5010&lt;/a&gt; 的api接口服务:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;api&lt;/th&gt; &#xA;   &lt;th&gt;method&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;params&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;   &lt;td&gt;GET&lt;/td&gt; &#xA;   &lt;td&gt;api介绍&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;/get&lt;/td&gt; &#xA;   &lt;td&gt;GET&lt;/td&gt; &#xA;   &lt;td&gt;随机获取一个代理&lt;/td&gt; &#xA;   &lt;td&gt;可选参数: &lt;code&gt;?type=https&lt;/code&gt; 过滤支持https的代理&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;/pop&lt;/td&gt; &#xA;   &lt;td&gt;GET&lt;/td&gt; &#xA;   &lt;td&gt;获取并删除一个代理&lt;/td&gt; &#xA;   &lt;td&gt;可选参数: &lt;code&gt;?type=https&lt;/code&gt; 过滤支持https的代理&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;/all&lt;/td&gt; &#xA;   &lt;td&gt;GET&lt;/td&gt; &#xA;   &lt;td&gt;获取所有代理&lt;/td&gt; &#xA;   &lt;td&gt;可选参数: &lt;code&gt;?type=https&lt;/code&gt; 过滤支持https的代理&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;/count&lt;/td&gt; &#xA;   &lt;td&gt;GET&lt;/td&gt; &#xA;   &lt;td&gt;查看代理数量&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;/delete&lt;/td&gt; &#xA;   &lt;td&gt;GET&lt;/td&gt; &#xA;   &lt;td&gt;删除代理&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;?proxy=host:ip&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;爬虫使用&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;　　如果要在爬虫代码中使用的话， 可以将此api封装成函数直接使用，例如：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import requests&#xA;&#xA;def get_proxy():&#xA;    return requests.get(&#34;http://127.0.0.1:5010/get/&#34;).json()&#xA;&#xA;def delete_proxy(proxy):&#xA;    requests.get(&#34;http://127.0.0.1:5010/delete/?proxy={}&#34;.format(proxy))&#xA;&#xA;# your spider code&#xA;&#xA;def getHtml():&#xA;    # ....&#xA;    retry_count = 5&#xA;    proxy = get_proxy().get(&#34;proxy&#34;)&#xA;    while retry_count &amp;gt; 0:&#xA;        try:&#xA;            html = requests.get(&#39;http://www.example.com&#39;, proxies={&#34;http&#34;: &#34;http://{}&#34;.format(proxy)})&#xA;            # 使用代理访问&#xA;            return html&#xA;        except Exception:&#xA;            retry_count -= 1&#xA;    # 删除代理池中代理&#xA;    delete_proxy(proxy)&#xA;    return None&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;扩展代理&lt;/h3&gt; &#xA;&lt;p&gt;　　项目默认包含几个免费的代理获取源，但是免费的毕竟质量有限，所以如果直接运行可能拿到的代理质量不理想。所以，提供了代理获取的扩展方法。&lt;/p&gt; &#xA;&lt;p&gt;　　添加一个新的代理源方法如下:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;1、首先在&lt;a href=&#34;https://github.com/jhao104/proxy_pool/raw/1a3666283806a22ef287fba1a8efab7b94e94bac/fetcher/proxyFetcher.py#L21&#34;&gt;ProxyFetcher&lt;/a&gt;类中添加自定义的获取代理的静态方法， 该方法需要以生成器(yield)形式返回&lt;code&gt;host:ip&lt;/code&gt;格式的代理，例如:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#xA;class ProxyFetcher(object):&#xA;    # ....&#xA;&#xA;    # 自定义代理源获取方法&#xA;    @staticmethod&#xA;    def freeProxyCustom1():  # 命名不和已有重复即可&#xA;&#xA;        # 通过某网站或者某接口或某数据库获取代理&#xA;        # 假设你已经拿到了一个代理列表&#xA;        proxies = [&#34;x.x.x.x:3128&#34;, &#34;x.x.x.x:80&#34;]&#xA;        for proxy in proxies:&#xA;            yield proxy&#xA;        # 确保每个proxy都是 host:ip正确的格式返回&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2、添加好方法后，修改&lt;a href=&#34;https://github.com/jhao104/proxy_pool/raw/1a3666283806a22ef287fba1a8efab7b94e94bac/setting.py#L47&#34;&gt;setting.py&lt;/a&gt;文件中的&lt;code&gt;PROXY_FETCHER&lt;/code&gt;项：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;　　在&lt;code&gt;PROXY_FETCHER&lt;/code&gt;下添加自定义方法的名字:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;PROXY_FETCHER = [&#xA;    &#34;freeProxy01&#34;,    &#xA;    &#34;freeProxy02&#34;,&#xA;    # ....&#xA;    &#34;freeProxyCustom1&#34;  #  # 确保名字和你添加方法名字一致&#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;　　&lt;code&gt;schedule&lt;/code&gt; 进程会每隔一段时间抓取一次代理，下次抓取时会自动识别调用你定义的方法。&lt;/p&gt; &#xA;&lt;h3&gt;免费代理源&lt;/h3&gt; &#xA;&lt;p&gt;目前实现的采集免费代理网站有(排名不分先后, 下面仅是对其发布的免费代理情况, 付费代理测评可以参考&lt;a href=&#34;https://zhuanlan.zhihu.com/p/33576641&#34;&gt;这里&lt;/a&gt;):&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;代理名称&lt;/th&gt; &#xA;   &lt;th&gt;状态&lt;/th&gt; &#xA;   &lt;th&gt;更新速度&lt;/th&gt; &#xA;   &lt;th&gt;可用率&lt;/th&gt; &#xA;   &lt;th&gt;地址&lt;/th&gt; &#xA;   &lt;th&gt;代码&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;站大爷&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;★&lt;/td&gt; &#xA;   &lt;td&gt;**&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.zdaye.com/&#34;&gt;地址&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jhao104/proxy_pool/master/fetcher/proxyFetcher.py#L28&#34;&gt;&lt;code&gt;freeProxy01&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;66代理&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;★&lt;/td&gt; &#xA;   &lt;td&gt;*&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.66ip.cn/&#34;&gt;地址&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jhao104/proxy_pool/master/fetcher/proxyFetcher.py#L50&#34;&gt;&lt;code&gt;freeProxy02&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;开心代理&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;★&lt;/td&gt; &#xA;   &lt;td&gt;*&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.kxdaili.com/&#34;&gt;地址&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jhao104/proxy_pool/master/fetcher/proxyFetcher.py#L63&#34;&gt;&lt;code&gt;freeProxy03&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FreeProxyList&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;★&lt;/td&gt; &#xA;   &lt;td&gt;*&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.freeproxylists.net/zh/&#34;&gt;地址&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jhao104/proxy_pool/master/fetcher/proxyFetcher.py#L74&#34;&gt;&lt;code&gt;freeProxy04&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;快代理&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;★&lt;/td&gt; &#xA;   &lt;td&gt;*&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.kuaidaili.com/&#34;&gt;地址&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jhao104/proxy_pool/master/fetcher/proxyFetcher.py#L92&#34;&gt;&lt;code&gt;freeProxy05&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;冰凌代理&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;★★★&lt;/td&gt; &#xA;   &lt;td&gt;*&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.binglx.cn/&#34;&gt;地址&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jhao104/proxy_pool/master/fetcher/proxyFetcher.py#L111&#34;&gt;&lt;code&gt;freeProxy06&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;云代理&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;★&lt;/td&gt; &#xA;   &lt;td&gt;*&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.ip3366.net/&#34;&gt;地址&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jhao104/proxy_pool/master/fetcher/proxyFetcher.py#L123&#34;&gt;&lt;code&gt;freeProxy07&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;小幻代理&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;★★&lt;/td&gt; &#xA;   &lt;td&gt;*&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ip.ihuan.me/&#34;&gt;地址&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jhao104/proxy_pool/master/fetcher/proxyFetcher.py#L133&#34;&gt;&lt;code&gt;freeProxy08&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;免费代理库&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;☆&lt;/td&gt; &#xA;   &lt;td&gt;*&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://ip.jiangxianli.com/&#34;&gt;地址&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jhao104/proxy_pool/master/fetcher/proxyFetcher.py#L143&#34;&gt;&lt;code&gt;freeProxy09&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;89代理&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;☆&lt;/td&gt; &#xA;   &lt;td&gt;*&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.89ip.cn/&#34;&gt;地址&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jhao104/proxy_pool/master/fetcher/proxyFetcher.py#L154&#34;&gt;&lt;code&gt;freeProxy10&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;稻壳代理&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;★★&lt;/td&gt; &#xA;   &lt;td&gt;***&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.docip.ne&#34;&gt;地址&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jhao104/proxy_pool/master/fetcher/proxyFetcher.py#L164&#34;&gt;&lt;code&gt;freeProxy11&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;如果还有其他好的免费代理网站, 可以在提交在&lt;a href=&#34;https://github.com/jhao104/proxy_pool/issues/71&#34;&gt;issues&lt;/a&gt;, 下次更新时会考虑在项目中支持。&lt;/p&gt; &#xA;&lt;h3&gt;问题反馈&lt;/h3&gt; &#xA;&lt;p&gt;　　任何问题欢迎在&lt;a href=&#34;https://github.com/jhao104/proxy_pool/issues&#34;&gt;Issues&lt;/a&gt; 中反馈，同时也可以到我的&lt;a href=&#34;http://www.spiderpy.cn/blog/message&#34;&gt;博客&lt;/a&gt;中留言。&lt;/p&gt; &#xA;&lt;p&gt;　　你的反馈会让此项目变得更加完美。&lt;/p&gt; &#xA;&lt;h3&gt;贡献代码&lt;/h3&gt; &#xA;&lt;p&gt;　　本项目仅作为基本的通用的代理池架构，不接收特有功能(当然,不限于特别好的idea)。&lt;/p&gt; &#xA;&lt;p&gt;　　本项目依然不够完善，如果发现bug或有新的功能添加，请在&lt;a href=&#34;https://github.com/jhao104/proxy_pool/issues&#34;&gt;Issues&lt;/a&gt;中提交bug(或新功能)描述，我会尽力改进，使她更加完美。&lt;/p&gt; &#xA;&lt;p&gt;　　这里感谢以下contributor的无私奉献：&lt;/p&gt; &#xA;&lt;p&gt;　　&lt;a href=&#34;https://github.com/kangnwh&#34;&gt;@kangnwh&lt;/a&gt; | &lt;a href=&#34;https://github.com/bobobo80&#34;&gt;@bobobo80&lt;/a&gt; | &lt;a href=&#34;https://github.com/halleywj&#34;&gt;@halleywj&lt;/a&gt; | &lt;a href=&#34;https://github.com/newlyedward&#34;&gt;@newlyedward&lt;/a&gt; | &lt;a href=&#34;https://github.com/wang-ye&#34;&gt;@wang-ye&lt;/a&gt; | &lt;a href=&#34;https://github.com/gladmo&#34;&gt;@gladmo&lt;/a&gt; | &lt;a href=&#34;https://github.com/bernieyangmh&#34;&gt;@bernieyangmh&lt;/a&gt; | &lt;a href=&#34;https://github.com/PythonYXY&#34;&gt;@PythonYXY&lt;/a&gt; | &lt;a href=&#34;https://github.com/zuijiawoniu&#34;&gt;@zuijiawoniu&lt;/a&gt; | &lt;a href=&#34;https://github.com/netAir&#34;&gt;@netAir&lt;/a&gt; | &lt;a href=&#34;https://github.com/scil&#34;&gt;@scil&lt;/a&gt; | &lt;a href=&#34;https://github.com/tangrela&#34;&gt;@tangrela&lt;/a&gt; | &lt;a href=&#34;https://github.com/highroom&#34;&gt;@highroom&lt;/a&gt; | &lt;a href=&#34;https://github.com/luocaodan&#34;&gt;@luocaodan&lt;/a&gt; | &lt;a href=&#34;https://github.com/vc5&#34;&gt;@vc5&lt;/a&gt; | &lt;a href=&#34;https://github.com/1again&#34;&gt;@1again&lt;/a&gt; | &lt;a href=&#34;https://github.com/obaiyan&#34;&gt;@obaiyan&lt;/a&gt; | &lt;a href=&#34;https://github.com/zsbh&#34;&gt;@zsbh&lt;/a&gt; | &lt;a href=&#34;https://github.com/jiannanya&#34;&gt;@jiannanya&lt;/a&gt; | &lt;a href=&#34;https://github.com/Jerry12228&#34;&gt;@Jerry12228&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Release Notes&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/jhao104/proxy_pool/raw/master/docs/changelog.rst&#34;&gt;changelog&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>maszhongming/Multi-LoRA-Composition</title>
    <updated>2024-03-03T01:35:00Z</updated>
    <id>tag:github.com,2024-03-03:/maszhongming/Multi-LoRA-Composition</id>
    <link href="https://github.com/maszhongming/Multi-LoRA-Composition" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Repository for the Paper &#34;Multi-LoRA Composition for Image Generation&#34;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://raw.githubusercontent.com/maszhongming/Multi-LoRA-Composition/main/images/tangram.png&#34; alt=&#34;title&#34; width=&#34;4%&#34;&gt; Multi-LoRA Composition for Image Generation&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://maszhongming.github.io/Multi-LoRA-Composition/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/🌐-Website-red&#34; height=&#34;25&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2402.16843&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/📝-Paper-blue&#34; height=&#34;25&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://drive.google.com/file/d/1SuwRgV1LtEud8dfjftnw-zxBMgzSCwIT/view?usp=sharing&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/🎨-ComposLoRA-green&#34; height=&#34;25&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;🖋 &lt;strong&gt;Authors:&lt;/strong&gt; &lt;a href=&#34;https://maszhongming.github.io/&#34;&gt;Ming Zhong&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=S6OFEFEAAAAJ&amp;amp;hl=en&#34;&gt;Yelong Shen&lt;/a&gt;, &lt;a href=&#34;https://www.microsoft.com/en-us/research/people/shuowa/&#34;&gt;Shuohang Wang&lt;/a&gt;, &lt;a href=&#34;https://adamlu123.github.io/&#34;&gt;Yadong Lu&lt;/a&gt;, &lt;a href=&#34;https://yzjiao.github.io/&#34;&gt;Yizhu Jiao&lt;/a&gt;, &lt;a href=&#34;https://ozyyshr.github.io/&#34;&gt;Siru Ouyang&lt;/a&gt;, &lt;a href=&#34;https://plusross.github.io/&#34;&gt;Donghan Yu&lt;/a&gt;, &lt;a href=&#34;https://hanj.cs.illinois.edu/&#34;&gt;Jiawei Han&lt;/a&gt;, &lt;a href=&#34;https://www.microsoft.com/en-us/research/people/wzchen/&#34;&gt;Weizhu Chen&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;📜 Overview&lt;/h2&gt; &#xA;&lt;p&gt;Low-Rank Adaptation (LoRA) is extensively utilized in text-to-image models for the accurate rendition of specific elements like distinct characters or unique styles in generated images.&lt;/p&gt; &#xA;&lt;p&gt;Our project presents two training-free methods: &lt;strong&gt;LoRA Switch&lt;/strong&gt; and &lt;strong&gt;LoRA Composite&lt;/strong&gt; for integrating any number of elements in an image through multi-LoRA composition.&lt;/p&gt; &#xA;&lt;p&gt;The figure below illustrates differences between the traditional LoRA Merge approach and our newly proposed techniques:&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/maszhongming/Multi-LoRA-Composition/main/images/intro_fig.png&#34; width=&#34;100%&#34; alt=&#34;intro_case&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;🚀 Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Setting Up the Environment&lt;/h3&gt; &#xA;&lt;p&gt;To begin, set up your environment with the necessary packages:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create --name multi-lora python=3.10&#xA;conda activate multi-lora&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Downloading Pre-trained LoRAs&lt;/h3&gt; &#xA;&lt;p&gt;Our &lt;strong&gt;ComposLoRA&lt;/strong&gt; testbed collects 22 pre-trained LoRAs, spanning characters, clothing, styles, backgrounds, and objects. Download &lt;code&gt;ComposLoRA.zip&lt;/code&gt; from &lt;a href=&#34;https://drive.google.com/file/d/1SuwRgV1LtEud8dfjftnw-zxBMgzSCwIT/view?usp=sharing&#34;&gt;this link&lt;/a&gt;, put it in the &lt;a href=&#34;https://raw.githubusercontent.com/maszhongming/Multi-LoRA-Composition/main/models&#34;&gt;models&lt;/a&gt; folder, and unzip it.&lt;/p&gt; &#xA;&lt;h2&gt;🖼️ Image Generation with Multi-LoRA Composition&lt;/h2&gt; &#xA;&lt;p&gt;To compose multiple LoRAs using different methods during image generation, follow these steps:&lt;/p&gt; &#xA;&lt;p&gt;First, load the base model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from diffusers import DiffusionPipeline&#xA;&#xA;pipeline = DiffusionPipeline.from_pretrained(&#xA;    &#39;SG161222/Realistic_Vision_V5.1_noVAE&#39;,&#xA;    custom_pipeline=&#34;MingZhong/StableDiffusionPipeline-with-LoRA-C&#34;,&#xA;    use_safetensors=True&#xA;).to(&#34;cuda&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This model from Hugging Face is selected for realistic-style image generation. Additionally, our custom pipeline integrates the LoRA composite method into the standard Stable Diffusion pipeline.&lt;/p&gt; &#xA;&lt;p&gt;Next, choose a character LoRA and a clothing LoRA from ComposLoRA for composition:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Load LoRAs&#xA;lora_path = &#39;models/lora/reality&#39;&#xA;pipeline.load_lora_weights(lora_path, weight_name=&#34;character_2.safetensors&#34;, adapter_name=&#34;character&#34;)&#xA;pipeline.load_lora_weights(lora_path, weight_name=&#34;clothing_2.safetensors&#34;, adapter_name=&#34;clothing&#34;)&#xA;&#xA;# List of LoRAs to be composed&#xA;cur_loras = [&#34;character&#34;, &#34;clothing&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Select a composition method. &#34;switch&#34; and &#34;composite&#34; are our new proposals, offering alternatives to the traditional &#34;merge&#34; method:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from callbacks import make_callback&#xA;&#xA;method = &#39;switch&#39;&#xA;&#xA;# Initialize based on the selected composition method&#xA;if method == &#34;merge&#34;:&#xA;    pipeline.set_adapters(cur_loras)&#xA;    switch_callback = None&#xA;elif method == &#34;switch&#34;:&#xA;    pipeline.set_adapters([cur_loras[0]])&#xA;    switch_callback = make_callback(switch_step=args.switch_step, loras=cur_loras)&#xA;else:&#xA;    pipeline.set_adapters(cur_loras)&#xA;    switch_callback = None&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, set your prompt and generate the image:.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Set the prompts for image generation&#xA;prompt = &#34;RAW photo, subject, 8k uhd, dslr, high quality, Fujifilm XT3, half-length portrait from knees up, scarlett, short red hair, blue eyes, school uniform, white shirt, red tie, blue pleated microskirt&#34;&#xA;negative_prompt = &#34;extra heads, nsfw, deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime, text, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck&#34;&#xA;&#xA;# Generate and save the image&#xA;generator = torch.maunal_seed(11)&#xA;image = pipeline(&#xA;    prompt=prompt, &#xA;    negative_prompt=negative_prompt,&#xA;    height=1024,&#xA;    width=768,&#xA;    num_inference_steps=100,&#xA;    guidance_scale=7,&#xA;    generator=generator,&#xA;    cross_attention_kwargs={&#34;scale&#34;: 0.8},&#xA;    callback_on_step_end=switch_callback,&#xA;    lora_composite=True if method == &#34;composite&#34; else False&#xA;).images[0]&#xA;image.save(&#39;example.png&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Refer to &lt;code&gt;example.py&lt;/code&gt; for the full code, and adjust the following command to see results from different composition methods:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python example.py --method switch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Images generated by each of the three methods are showcased below:&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/maszhongming/Multi-LoRA-Composition/main/images/merge_example.png&#34; alt=&#34;merge_example&#34; width=&#34;25%&#34; style=&#34;margin-right: 10px;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/maszhongming/Multi-LoRA-Composition/main/images/switch_example.png&#34; alt=&#34;switch_example&#34; width=&#34;25%&#34; style=&#34;margin-right: 10px;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/maszhongming/Multi-LoRA-Composition/main/images/composite_example.png&#34; alt=&#34;composite_example&#34; width=&#34;25%&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;🎨 Experiments on ComposLoRA&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;ComposLoRA&lt;/strong&gt; features 22 LoRAs and 480 different composition sets, allowing for the generation of images with any composition of 2-5 LoRAs, including at least one character LoRA.&lt;/p&gt; &#xA;&lt;h3&gt;Image Generation&lt;/h3&gt; &#xA;&lt;p&gt;To generate anime-style images incorporating 2 LoRAs using LoRA Composite method, use the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export CUDA_VISIBLE_DEVICES=0&#xA;&#xA;python compose_lora.py \&#xA;    --method composite \&#xA;    --compos_num 2 \&#xA;    --save_path output \&#xA;    --lora_scale 0.8 \&#xA;    --image_style anime \&#xA;    --denoise_steps 200 \&#xA;    --cfg_scale 10 \&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Adjust the parameters in &lt;code&gt;compos_reality.sh&lt;/code&gt; and &lt;code&gt;compose_anime.sh&lt;/code&gt; for different compositions.&lt;/p&gt; &#xA;&lt;h3&gt;Comparative Evaluation with GPT-4V&lt;/h3&gt; &#xA;&lt;p&gt;For comparative evaluation on composition efficacy and image quality, we use GPT-4V. Set your OpenAI API key first:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export OPENAI_API_KEY=&#39;your_openai_api_key_here&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, compare the composite and merge methods with this command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python evaluate.py \&#xA;    --base_method merge \&#xA;    --comp_method composite \&#xA;    --compos_num 2 \&#xA;    --image_style anime \&#xA;    --image_path output \&#xA;    --save_path eval_result \&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Modify &lt;code&gt;eval.sh&lt;/code&gt; for comparative evaluation under different conditions. Note the position bias of GPT-4V as mentioned in our paper, making it essential to input images in both orders and average the scores for a fair final assessment.&lt;/p&gt; &#xA;&lt;h2&gt;Human Evaluation&lt;/h2&gt; &#xA;&lt;p&gt;We also conduct human evaluations on 120 generated images to assess composition and image quality from a human perspective. These evaluations offer additional insights into the performance of our Multi-LoRA Composition methods and metrics. For detailed information on the evaluation process and results, please visit the &lt;a href=&#34;https://raw.githubusercontent.com/maszhongming/Multi-LoRA-Composition/main/human_eval&#34;&gt;human_eval&lt;/a&gt; folder.&lt;/p&gt; &#xA;&lt;h2&gt;📚 Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find this work useful, please kindly cite our paper:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{zhong2024multi,&#xA;    title={Multi-LoRA Composition for Image Generation},&#xA;    author={Zhong, Ming and Shen, Yelong and Wang, Shuohang and Lu, Yadong and Jiao, Yizhu and Ouyang, Siru and Yu, Donghan and Han, Jiawei and Chen, Weizhu},&#xA;    journal={arXiv preprint arXiv:2402.16843},&#xA;    year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>kijai/ComfyUI-SUPIR</title>
    <updated>2024-03-03T01:35:00Z</updated>
    <id>tag:github.com,2024-03-03:/kijai/ComfyUI-SUPIR</id>
    <link href="https://github.com/kijai/ComfyUI-SUPIR" rel="alternate"></link>
    <summary type="html">&lt;p&gt;SUPIR upscaling wrapper for ComfyUI&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ComfyUI SUPIR upscaler wrapper node&lt;/h1&gt; &#xA;&lt;h2&gt;WORK IN PROGRESS&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/kijai/ComfyUI-SUPIR/assets/40791699/887898d3-afe5-45d1-be08-50f6620b70eb&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Installing&lt;/h1&gt; &#xA;&lt;p&gt;Either manager and install from git, or clone this repo to custom_nodes and run:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;or if you use portable (run this in ComfyUI_windows_portable -folder):&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;python_embeded\python.exe -m pip install -r ComfyUI\custom_nodes\ComfyUI-SUPIR\requirements.txt&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Additionally &lt;code&gt;xformers&lt;/code&gt; seems to currently be necessary, a safe way (often problem on Windows) to install/update it is with:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;pip install -U xformers --no-dependencies&lt;/code&gt; (for portable &lt;code&gt;python_embeded\python.exe -m pip install -U xformers --no-dependencies&lt;/code&gt; )&lt;/p&gt; &#xA;&lt;p&gt;Get the SUPIR model(s) from the original links below, they are loaded from the normal &lt;code&gt;ComfyUI/models/checkpoints&lt;/code&gt; -folder In addition you need an SDXL model, they are loaded from the same folder.&lt;/p&gt; &#xA;&lt;p&gt;I have not included llava in this, but you can input any captions to the node and thus use anything you want to generate them, or just don&#39;t, seems to work great even without.&lt;/p&gt; &#xA;&lt;p&gt;Memory requirements are directly related to the input image resolution, the &#34;scale_by&#34; in the node simply scales the input, you can leave it at 1.0 and size your input with any other node as well. In my testing I was able to run 512x512 to 1024x1024 with a 10GB 3080 GPU, and other tests on 24GB GPU to up 3072x3072. System RAM requirements are also hefty, don&#39;t know numbers but I would guess under 32GB is going to have issues, tested with 64GB.&lt;/p&gt; &#xA;&lt;p&gt;Mirror for the models: &lt;a href=&#34;https://huggingface.co/camenduru/SUPIR/tree/main&#34;&gt;https://huggingface.co/camenduru/SUPIR/tree/main&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;WARNING: currently downloads 10GB clip model as I didn&#39;t figure out a way to use existing ones yet&lt;/h2&gt; &#xA;&lt;h1&gt;Tests&lt;/h1&gt; &#xA;&lt;p&gt;Video upscale test (currently the node does frames one by one from input batch):&lt;/p&gt; &#xA;&lt;p&gt;Original: &lt;a href=&#34;https://github.com/kijai/ComfyUI-SUPIR/assets/40791699/33621520-a429-4155-aa3a-ac5cd15bda56&#34;&gt;https://github.com/kijai/ComfyUI-SUPIR/assets/40791699/33621520-a429-4155-aa3a-ac5cd15bda56&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Upscaled 3x: &lt;a href=&#34;https://github.com/kijai/ComfyUI-SUPIR/assets/40791699/d6c60e0a-11c3-496d-82c6-a724758a131a&#34;&gt;https://github.com/kijai/ComfyUI-SUPIR/assets/40791699/d6c60e0a-11c3-496d-82c6-a724758a131a&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Image upscale from 3x from 512p: &lt;a href=&#34;https://github.com/kijai/ComfyUI-SUPIR/assets/40791699/545ddce4-8324-45cb-a545-6d1f527d8750&#34;&gt;https://github.com/kijai/ComfyUI-SUPIR/assets/40791699/545ddce4-8324-45cb-a545-6d1f527d8750&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Original repo: &lt;a href=&#34;https://github.com/Fanghua-Yu/SUPIR&#34;&gt;https://github.com/Fanghua-Yu/SUPIR&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Models we provided:&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;SUPIR-v0Q&lt;/code&gt;: &lt;a href=&#34;https://pan.baidu.com/s/1lnefCZhBTeDWijqbj1jIyw?pwd=pjq6&#34;&gt;Baidu Netdisk&lt;/a&gt;, &lt;a href=&#34;https://drive.google.com/drive/folders/1yELzm5SvAi9e7kPcO_jPp2XkTs4vK6aR?usp=sharing&#34;&gt;Google Drive&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Default training settings with paper. High generalization and high image quality in most cases.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;SUPIR-v0F&lt;/code&gt;: &lt;a href=&#34;https://pan.baidu.com/s/1AECN8NjiVuE3hvO8o-Ua6A?pwd=k2uz&#34;&gt;Baidu Netdisk&lt;/a&gt;, &lt;a href=&#34;https://drive.google.com/drive/folders/1yELzm5SvAi9e7kPcO_jPp2XkTs4vK6aR?usp=sharing&#34;&gt;Google Drive&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Training with light degradation settings. Stage1 encoder of &lt;code&gt;SUPIR-v0F&lt;/code&gt; remains more details when facing light degradations.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;BibTeX&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{yu2024scaling,&#xA;  title={Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild}, &#xA;  author={Fanghua Yu and Jinjin Gu and Zheyuan Li and Jinfan Hu and Xiangtao Kong and Xintao Wang and Jingwen He and Yu Qiao and Chao Dong},&#xA;  year={2024},&#xA;  eprint={2401.13627},&#xA;  archivePrefix={arXiv},&#xA;  primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;📧 Contact&lt;/h2&gt; &#xA;&lt;p&gt;If you have any question, please email &lt;code&gt;fanghuayu96@gmail.com&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Non-Commercial Use Only Declaration&lt;/h2&gt; &#xA;&lt;p&gt;The SUPIR (&#34;Software&#34;) is made available for use, reproduction, and distribution strictly for non-commercial purposes. For the purposes of this declaration, &#34;non-commercial&#34; is defined as not primarily intended for or directed towards commercial advantage or monetary compensation.&lt;/p&gt; &#xA;&lt;p&gt;By using, reproducing, or distributing the Software, you agree to abide by this restriction and not to use the Software for any commercial purposes without obtaining prior written permission from Dr. Jinjin Gu.&lt;/p&gt; &#xA;&lt;p&gt;This declaration does not in any way limit the rights under any open source license that may apply to the Software; it solely adds a condition that the Software shall not be used for commercial purposes.&lt;/p&gt; &#xA;&lt;p&gt;IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.&lt;/p&gt; &#xA;&lt;p&gt;For inquiries or to obtain permission for commercial use, please contact Dr. Jinjin Gu (&lt;a href=&#34;mailto:hellojasongt@gmail.com&#34;&gt;hellojasongt@gmail.com&lt;/a&gt;).&lt;/p&gt;</summary>
  </entry>
</feed>