<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-02-04T01:37:35Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Blaizzy/mlx-vlm</title>
    <updated>2025-02-04T01:37:35Z</updated>
    <id>tag:github.com,2025-02-04:/Blaizzy/mlx-vlm</id>
    <link href="https://github.com/Blaizzy/mlx-vlm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;MLX-VLM is a package for inference and fine-tuning of Vision Language Models (VLMs) on your Mac using MLX.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MLX-VLM&lt;/h1&gt; &#xA;&lt;p&gt;MLX-VLM is a package for inference and fine-tuning of Vision Language Models (VLMs) on your Mac using MLX.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#usage&#34;&gt;Usage&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#command-line-interface-cli&#34;&gt;Command Line Interface (CLI)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#chat-ui-with-gradio&#34;&gt;Chat UI with Gradio&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#python-script&#34;&gt;Python Script&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#multi-image-chat-support&#34;&gt;Multi-Image Chat Support&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#supported-models&#34;&gt;Supported Models&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#usage-examples&#34;&gt;Usage Examples&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#fine-tuning&#34;&gt;Fine-tuning&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;The easiest way to get started is to install the &lt;code&gt;mlx-vlm&lt;/code&gt; package using pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install mlx-vlm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Command Line Interface (CLI)&lt;/h3&gt; &#xA;&lt;p&gt;Generate output from a model using the CLI:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python -m mlx_vlm.generate --model mlx-community/Qwen2-VL-2B-Instruct-4bit --max-tokens 100 --temp 0.0 --image http://images.cocodataset.org/val2017/000000039769.jpg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Chat UI with Gradio&lt;/h3&gt; &#xA;&lt;p&gt;Launch a chat interface using Gradio:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python -m mlx_vlm.chat_ui --model mlx-community/Qwen2-VL-2B-Instruct-4bit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Python Script&lt;/h3&gt; &#xA;&lt;p&gt;Here&#39;s an example of how to use MLX-VLM in a Python script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import mlx.core as mx&#xA;from mlx_vlm import load, generate&#xA;from mlx_vlm.prompt_utils import apply_chat_template&#xA;from mlx_vlm.utils import load_config&#xA;&#xA;# Load the model&#xA;model_path = &#34;mlx-community/Qwen2-VL-2B-Instruct-4bit&#34;&#xA;model, processor = load(model_path)&#xA;config = load_config(model_path)&#xA;&#xA;# Prepare input&#xA;image = [&#34;http://images.cocodataset.org/val2017/000000039769.jpg&#34;]&#xA;prompt = &#34;Describe this image.&#34;&#xA;&#xA;# Apply chat template&#xA;formatted_prompt = apply_chat_template(&#xA;    processor, config, prompt, num_images=len(image)&#xA;)&#xA;&#xA;# Generate output&#xA;output = generate(model, processor, formatted_prompt, image, verbose=False)&#xA;print(output)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Multi-Image Chat Support&lt;/h2&gt; &#xA;&lt;p&gt;MLX-VLM supports analyzing multiple images simultaneously with select models. This feature enables more complex visual reasoning tasks and comprehensive analysis across multiple images in a single conversation.&lt;/p&gt; &#xA;&lt;h3&gt;Supported Models&lt;/h3&gt; &#xA;&lt;p&gt;The following models support multi-image chat:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Idefics 2&lt;/li&gt; &#xA; &lt;li&gt;LLaVA (Interleave)&lt;/li&gt; &#xA; &lt;li&gt;Qwen2-VL&lt;/li&gt; &#xA; &lt;li&gt;Phi3-Vision&lt;/li&gt; &#xA; &lt;li&gt;Pixtral&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Usage Examples&lt;/h3&gt; &#xA;&lt;h4&gt;Python Script&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mlx_vlm import load, generate&#xA;from mlx_vlm.prompt_utils import apply_chat_template&#xA;from mlx_vlm.utils import load_config&#xA;&#xA;model_path = &#34;mlx-community/Qwen2-VL-2B-Instruct-4bit&#34;&#xA;model, processor = load(model_path)&#xA;config = load_config(model_path)&#xA;&#xA;images = [&#34;path/to/image1.jpg&#34;, &#34;path/to/image2.jpg&#34;]&#xA;prompt = &#34;Compare these two images.&#34;&#xA;&#xA;formatted_prompt = apply_chat_template(&#xA;    processor, config, prompt, num_images=len(images)&#xA;)&#xA;&#xA;output = generate(model, processor, formatted_prompt, images, verbose=False)&#xA;print(output)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Command Line&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python -m mlx_vlm.generate --model mlx-community/Qwen2-VL-2B-Instruct-4bit --max-tokens 100 --prompt &#34;Compare these images&#34; --image path/to/image1.jpg path/to/image2.jpg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Video Understanding&lt;/h2&gt; &#xA;&lt;p&gt;MLX-VLM also supports video analysis such as captioning, summarization, and more, with select models.&lt;/p&gt; &#xA;&lt;h3&gt;Supported Models&lt;/h3&gt; &#xA;&lt;p&gt;The following models support video chat:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Qwen2-VL&lt;/li&gt; &#xA; &lt;li&gt;Qwen2.5-VL&lt;/li&gt; &#xA; &lt;li&gt;Idefics3&lt;/li&gt; &#xA; &lt;li&gt;LLaVA&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;With more coming soon.&lt;/p&gt; &#xA;&lt;h3&gt;Usage Examples&lt;/h3&gt; &#xA;&lt;h4&gt;Command Line&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python -m mlx_vlm.video_generate --model mlx-community/Qwen2-VL-2B-Instruct-4bit --max-tokens 100 --prompt &#34;Describe this video&#34; --video path/to/video.mp4 --max-pixels 224 224 --fps 1.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;These examples demonstrate how to use multiple images with MLX-VLM for more complex visual reasoning tasks.&lt;/p&gt; &#xA;&lt;h1&gt;Fine-tuning&lt;/h1&gt; &#xA;&lt;p&gt;MLX-VLM supports fine-tuning models with LoRA and QLoRA.&lt;/p&gt; &#xA;&lt;h2&gt;LoRA &amp;amp; QLoRA&lt;/h2&gt; &#xA;&lt;p&gt;To learn more about LoRA, please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/mlx_vlm/LORA.MD&#34;&gt;LoRA.md&lt;/a&gt; file.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Soulter/AstrBot</title>
    <updated>2025-02-04T01:37:35Z</updated>
    <id>tag:github.com,2025-02-04:/Soulter/AstrBot</id>
    <link href="https://github.com/Soulter/AstrBot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;âœ¨æ˜“ä¸Šæ‰‹çš„å¤šå¹³å° LLM èŠå¤©æœºå™¨äººåŠå¼€å‘æ¡†æ¶âœ¨ã€‚æ”¯æŒ QQã€QQé¢‘é“ã€Telegramã€å¾®ä¿¡å¹³å°(Gewechat)ã€å†…ç½® Web Chatï¼ŒOpenAI GPTã€DeepSeekã€Ollamaã€Llamaã€GLMã€Geminiã€OneAPIã€LLMTunerï¼Œæ”¯æŒ LLM Agent æ’ä»¶å¼€å‘ï¼Œå¯è§†åŒ–é¢æ¿ã€‚ä¸€é”®éƒ¨ç½²ã€‚æ”¯æŒ Dify å·¥ä½œæµã€ä»£ç æ‰§è¡Œå™¨ã€Whisper è¯­éŸ³è½¬æ–‡å­—ã€‚&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/07649e07-3b8e-4feb-9aa9-bf13af4f3476&#34; alt=&#34;logo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;em&gt;âœ¨ æ˜“ä¸Šæ‰‹çš„å¤šå¹³å° LLM èŠå¤©æœºå™¨äººåŠå¼€å‘æ¡†æ¶ âœ¨&lt;/em&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/Soulter/AstrBot/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/Soulter/AstrBot&#34; alt=&#34;GitHub release (latest by date)&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/python-3.10+-blue.svg?sanitize=true&#34; alt=&#34;python&#34;&gt; &lt;a href=&#34;https://hub.docker.com/r/soulter/astrbot&#34;&gt;&lt;img alt=&#34;Docker pull&#34; src=&#34;https://img.shields.io/docker/pulls/soulter/astrbot.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;img alt=&#34;Static Badge&#34; src=&#34;https://img.shields.io/badge/QQ%E7%BE%A4-322154837-purple&#34;&gt; &lt;a href=&#34;https://wakatime.com/badge/user/915e5316-99c6-4563-a483-ef186cf000c9/project/018e705a-a1a7-409a-a849-3013485e6c8e&#34;&gt;&lt;img src=&#34;https://wakatime.com/badge/user/915e5316-99c6-4563-a483-ef186cf000c9/project/018e705a-a1a7-409a-a849-3013485e6c8e.svg?sanitize=true&#34; alt=&#34;wakatime&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.soulter.top%2Fastrbot%2Fstats&amp;amp;query=v&amp;amp;label=7%E6%97%A5%E6%B6%88%E6%81%AF%E4%B8%8A%E8%A1%8C%E9%87%8F&amp;amp;cacheSeconds=3600&#34; alt=&#34;Dynamic JSON Badge&#34;&gt; &lt;a href=&#34;https://codecov.io/gh/Soulter/AstrBot&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/Soulter/AstrBot/graph/badge.svg?token=FF3P5967B8&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://astrbot.app/&#34;&gt;æŸ¥çœ‹æ–‡æ¡£&lt;/a&gt; ï½œ &lt;a href=&#34;https://github.com/Soulter/AstrBot/issues&#34;&gt;é—®é¢˜æäº¤&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;AstrBot æ˜¯ä¸€ä¸ªæ¾è€¦åˆã€å¼‚æ­¥ã€æ”¯æŒå¤šæ¶ˆæ¯å¹³å°éƒ¨ç½²ã€å…·æœ‰æ˜“ç”¨çš„æ’ä»¶ç³»ç»Ÿå’Œå®Œå–„çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥å…¥åŠŸèƒ½çš„èŠå¤©æœºå™¨äººåŠå¼€å‘æ¡†æ¶ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;âœ¨ ä¸»è¦åŠŸèƒ½&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;å¤§è¯­è¨€æ¨¡å‹å¯¹è¯&lt;/strong&gt;ã€‚æ”¯æŒå„ç§å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬ OpenAI APIã€Google Geminiã€Llamaã€Deepseekã€ChatGLM ç­‰ï¼Œæ”¯æŒæ¥å…¥æœ¬åœ°éƒ¨ç½²çš„å¤§æ¨¡å‹ï¼Œé€šè¿‡ Ollamaã€LLMTunerã€‚å…·æœ‰å¤šè½®å¯¹è¯ã€äººæ ¼æƒ…å¢ƒã€å¤šæ¨¡æ€èƒ½åŠ›ï¼Œæ”¯æŒå›¾ç‰‡ç†è§£ã€è¯­éŸ³è½¬æ–‡å­—ï¼ˆWhisperï¼‰ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;å¤šæ¶ˆæ¯å¹³å°æ¥å…¥&lt;/strong&gt;ã€‚æ”¯æŒæ¥å…¥ QQï¼ˆOneBotï¼‰ã€QQ é¢‘é“ã€å¾®ä¿¡ï¼ˆGewechatã€VChatï¼‰ã€Telegramã€‚åç»­å°†æ”¯æŒé’‰é’‰ã€é£ä¹¦ã€Discordã€WhatsAppã€å°çˆ±éŸ³å“ã€‚æ”¯æŒé€Ÿç‡é™åˆ¶ã€ç™½åå•ã€å…³é”®è¯è¿‡æ»¤ã€ç™¾åº¦å†…å®¹å®¡æ ¸ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Agent&lt;/strong&gt;ã€‚åŸç”Ÿæ”¯æŒéƒ¨åˆ† Agent èƒ½åŠ›ï¼Œå¦‚ä»£ç æ‰§è¡Œå™¨ã€è‡ªç„¶è¯­è¨€å¾…åŠã€ç½‘é¡µæœç´¢ã€‚å¯¹æ¥ &lt;a href=&#34;https://astrbot.app/others/dify.html&#34;&gt;Dify å¹³å°&lt;/a&gt;ï¼Œä¾¿æ·æ¥å…¥ Dify æ™ºèƒ½åŠ©æ‰‹ã€çŸ¥è¯†åº“å’Œ Dify å·¥ä½œæµã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;æ’ä»¶æ‰©å±•&lt;/strong&gt;ã€‚æ·±åº¦ä¼˜åŒ–çš„æ’ä»¶æœºåˆ¶ï¼Œæ”¯æŒ&lt;a href=&#34;https://astrbot.app/dev/plugin.html&#34;&gt;å¼€å‘æ’ä»¶&lt;/a&gt;æ‰©å±•åŠŸèƒ½ï¼Œæç®€å¼€å‘ã€‚å·²æ”¯æŒå®‰è£…å¤šä¸ªæ’ä»¶ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;å¯è§†åŒ–ç®¡ç†é¢æ¿&lt;/strong&gt;ã€‚æ”¯æŒå¯è§†åŒ–ä¿®æ”¹é…ç½®ã€æ’ä»¶ç®¡ç†ã€æ—¥å¿—æŸ¥çœ‹ç­‰åŠŸèƒ½ï¼Œé™ä½é…ç½®éš¾åº¦ã€‚é›†æˆ WebChatï¼Œå¯åœ¨é¢æ¿ä¸Šä¸å¤§æ¨¡å‹å¯¹è¯ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;é«˜ç¨³å®šæ€§ã€é«˜æ¨¡å—åŒ–&lt;/strong&gt;ã€‚åŸºäºäº‹ä»¶æ€»çº¿å’Œæµæ°´çº¿çš„æ¶æ„è®¾è®¡ï¼Œé«˜åº¦æ¨¡å—åŒ–ï¼Œä½è€¦åˆã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] ç®¡ç†é¢æ¿åœ¨çº¿ä½“éªŒ Demo: &lt;a href=&#34;https://demo.astrbot.app/&#34;&gt;https://demo.astrbot.app/&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;ç”¨æˆ·å: &lt;code&gt;astrbot&lt;/code&gt;, å¯†ç : &lt;code&gt;astrbot&lt;/code&gt;ã€‚æœªé…ç½® LLMï¼Œæ— æ³•åœ¨èŠå¤©é¡µä½¿ç”¨å¤§æ¨¡å‹ã€‚ï¼ˆä¸è¦å†ä¿®æ”¹ demo çš„ç™»å½•å¯†ç äº† ğŸ˜­ï¼‰&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;âœ¨ ä½¿ç”¨æ–¹å¼&lt;/h2&gt; &#xA;&lt;h4&gt;Docker éƒ¨ç½²&lt;/h4&gt; &#xA;&lt;p&gt;è¯·å‚é˜…å®˜æ–¹æ–‡æ¡£ &lt;a href=&#34;https://astrbot.app/deploy/astrbot/docker.html#%E4%BD%BF%E7%94%A8-docker-%E9%83%A8%E7%BD%B2-astrbot&#34;&gt;ä½¿ç”¨ Docker éƒ¨ç½² AstrBot&lt;/a&gt; ã€‚&lt;/p&gt; &#xA;&lt;h4&gt;Windows ä¸€é”®å®‰è£…å™¨éƒ¨ç½²&lt;/h4&gt; &#xA;&lt;p&gt;éœ€è¦ç”µè„‘ä¸Šå®‰è£…æœ‰ Pythonï¼ˆ&amp;gt;3.10ï¼‰ã€‚è¯·å‚é˜…å®˜æ–¹æ–‡æ¡£ &lt;a href=&#34;https://astrbot.app/deploy/astrbot/windows.html&#34;&gt;ä½¿ç”¨ Windows ä¸€é”®å®‰è£…å™¨éƒ¨ç½² AstrBot&lt;/a&gt; ã€‚&lt;/p&gt; &#xA;&lt;h4&gt;Replit éƒ¨ç½²&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://repl.it/github/Soulter/AstrBot&#34;&gt;&lt;img src=&#34;https://repl.it/badge/github/Soulter/AstrBot&#34; alt=&#34;Run on Repl.it&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;CasaOS éƒ¨ç½²&lt;/h4&gt; &#xA;&lt;p&gt;ç¤¾åŒºè´¡çŒ®çš„éƒ¨ç½²æ–¹å¼ã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¯·å‚é˜…å®˜æ–¹æ–‡æ¡£ &lt;a href=&#34;https://astrbot.app/deploy/astrbot/casaos.html&#34;&gt;é€šè¿‡æºç éƒ¨ç½² AstrBot&lt;/a&gt; ã€‚&lt;/p&gt; &#xA;&lt;h4&gt;æ‰‹åŠ¨éƒ¨ç½²&lt;/h4&gt; &#xA;&lt;p&gt;è¯·å‚é˜…å®˜æ–¹æ–‡æ¡£ &lt;a href=&#34;https://astrbot.app/deploy/astrbot/cli.html&#34;&gt;é€šè¿‡æºç éƒ¨ç½² AstrBot&lt;/a&gt; ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;âš¡ æ¶ˆæ¯å¹³å°æ”¯æŒæƒ…å†µ&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;å¹³å°&lt;/th&gt; &#xA;   &lt;th&gt;æ”¯æŒæ€§&lt;/th&gt; &#xA;   &lt;th&gt;è¯¦æƒ…&lt;/th&gt; &#xA;   &lt;th&gt;æ¶ˆæ¯ç±»å‹&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;QQ(å®˜æ–¹æœºå™¨äººæ¥å£)&lt;/td&gt; &#xA;   &lt;td&gt;âœ”&lt;/td&gt; &#xA;   &lt;td&gt;ç§èŠã€ç¾¤èŠï¼ŒQQ é¢‘é“ç§èŠã€ç¾¤èŠ&lt;/td&gt; &#xA;   &lt;td&gt;æ–‡å­—ã€å›¾ç‰‡&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;QQ(OneBot)&lt;/td&gt; &#xA;   &lt;td&gt;âœ”&lt;/td&gt; &#xA;   &lt;td&gt;ç§èŠã€ç¾¤èŠ&lt;/td&gt; &#xA;   &lt;td&gt;æ–‡å­—ã€å›¾ç‰‡ã€è¯­éŸ³&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;å¾®ä¿¡(ä¸ªäººå·)&lt;/td&gt; &#xA;   &lt;td&gt;âœ”&lt;/td&gt; &#xA;   &lt;td&gt;å¾®ä¿¡ä¸ªäººå·ç§èŠã€ç¾¤èŠ&lt;/td&gt; &#xA;   &lt;td&gt;æ–‡å­—ã€å›¾ç‰‡ã€è¯­éŸ³&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Soulter/astrbot_plugin_telegram&#34;&gt;Telegram&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;âœ”&lt;/td&gt; &#xA;   &lt;td&gt;ç§èŠã€ç¾¤èŠ&lt;/td&gt; &#xA;   &lt;td&gt;æ–‡å­—ã€å›¾ç‰‡&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;å¾®ä¿¡(ä¼ä¸šå¾®ä¿¡)&lt;/td&gt; &#xA;   &lt;td&gt;ğŸš§&lt;/td&gt; &#xA;   &lt;td&gt;è®¡åˆ’å†…&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;å¾®ä¿¡å¯¹è¯å¼€æ”¾å¹³å°&lt;/td&gt; &#xA;   &lt;td&gt;ğŸš§&lt;/td&gt; &#xA;   &lt;td&gt;è®¡åˆ’å†…&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;é£ä¹¦&lt;/td&gt; &#xA;   &lt;td&gt;ğŸš§&lt;/td&gt; &#xA;   &lt;td&gt;è®¡åˆ’å†…&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Discord&lt;/td&gt; &#xA;   &lt;td&gt;ğŸš§&lt;/td&gt; &#xA;   &lt;td&gt;è®¡åˆ’å†…&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;WhatsApp&lt;/td&gt; &#xA;   &lt;td&gt;ğŸš§&lt;/td&gt; &#xA;   &lt;td&gt;è®¡åˆ’å†…&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;å°çˆ±éŸ³å“&lt;/td&gt; &#xA;   &lt;td&gt;ğŸš§&lt;/td&gt; &#xA;   &lt;td&gt;è®¡åˆ’å†…&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;ğŸ¦Œ æ¥ä¸‹æ¥çš„è·¯çº¿å›¾&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] æ¬¢è¿åœ¨ Issue æå‡ºæ›´å¤šå»ºè®® &amp;lt;3&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; å®Œå–„å¹¶ä¿è¯ç›®å‰æ‰€æœ‰å¹³å°é€‚é…å™¨çš„åŠŸèƒ½ä¸€è‡´æ€§&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; ä¼˜åŒ–æ’ä»¶æ¥å£&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; é»˜è®¤æ”¯æŒæ›´å¤š TTS æœåŠ¡ï¼Œå¦‚ GPT-Sovits&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; å®Œå–„â€œèŠå¤©å¢å¼ºâ€éƒ¨åˆ†ï¼Œæ”¯æŒæŒä¹…åŒ–è®°å¿†&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; è§„åˆ’ i18n&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;â¤ï¸ è´¡çŒ®&lt;/h2&gt; &#xA;&lt;p&gt;æ¬¢è¿ä»»ä½• Issues/Pull Requestsï¼åªéœ€è¦å°†ä½ çš„æ›´æ”¹æäº¤åˆ°æ­¤é¡¹ç›® ï¼š)&lt;/p&gt; &#xA;&lt;p&gt;å¯¹äºæ–°åŠŸèƒ½çš„æ·»åŠ ï¼Œè¯·å…ˆé€šè¿‡ Issue è®¨è®ºã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ğŸŒŸ æ”¯æŒ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Star è¿™ä¸ªé¡¹ç›®ï¼&lt;/li&gt; &#xA; &lt;li&gt;åœ¨&lt;a href=&#34;https://afdian.com/a/soulter&#34;&gt;çˆ±å‘ç”µ&lt;/a&gt;æ”¯æŒæˆ‘ï¼&lt;/li&gt; &#xA; &lt;li&gt;åœ¨&lt;a href=&#34;https://drive.soulter.top/f/pYfA/d903f4fa49a496fda3f16d2be9e023b5.png&#34;&gt;å¾®ä¿¡&lt;/a&gt;æ”¯æŒæˆ‘~&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;âœ¨ Demo&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] ä»£ç æ‰§è¡Œå™¨çš„æ–‡ä»¶è¾“å…¥/è¾“å‡ºç›®å‰ä»…æµ‹è¯•äº† Napcat(QQ), Lagrange(QQ)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/4ee688d9-467d-45c8-99d6-368f9a8a92d8&#34; width=&#34;600&#34;&gt; &#xA; &lt;p&gt;&lt;em&gt;âœ¨åŸºäº Docker çš„æ²™ç®±åŒ–ä»£ç æ‰§è¡Œå™¨ï¼ˆBeta æµ‹è¯•ä¸­ï¼‰âœ¨&lt;/em&gt;&lt;/p&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/0378f407-6079-4f64-ae4c-e97ab20611d2&#34; height=&#34;500&#34;&gt; &#xA; &lt;p&gt;&lt;em&gt;âœ¨ å¤šæ¨¡æ€ã€ç½‘é¡µæœç´¢ã€é•¿æ–‡æœ¬è½¬å›¾ç‰‡ï¼ˆå¯é…ç½®ï¼‰ âœ¨&lt;/em&gt;&lt;/p&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/8ec12797-e70f-460a-959e-48eca39ca2bb&#34; height=&#34;100&#34;&gt; &#xA; &lt;p&gt;&lt;em&gt;âœ¨ è‡ªç„¶è¯­è¨€å¾…åŠäº‹é¡¹ âœ¨&lt;/em&gt;&lt;/p&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/e137a9e1-340a-4bf2-bb2b-771132780735&#34; height=&#34;150&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/480f5e82-cf6a-4955-a869-0d73137aa6e1&#34; height=&#34;150&#34;&gt; &#xA; &lt;p&gt;&lt;em&gt;âœ¨ æ’ä»¶ç³»ç»Ÿâ€”â€”éƒ¨åˆ†æ’ä»¶å±•ç¤º âœ¨&lt;/em&gt;&lt;/p&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/592a8630-14c7-4e06-b496-9c0386e4f36c&#34; width=&#34;600&#34;&gt; &#xA; &lt;p&gt;&lt;em&gt;âœ¨ ç®¡ç†é¢æ¿ âœ¨&lt;/em&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://drive.soulter.top/f/vlsA/ezgif-5-fb044b2542.gif&#34; alt=&#34;webchat&#34;&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;em&gt;âœ¨ å†…ç½® Web Chatï¼Œåœ¨çº¿ä¸æœºå™¨äººäº¤äº’ âœ¨&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;â­ Star History&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨çš„ç”Ÿæ´» / å·¥ä½œäº§ç”Ÿäº†å¸®åŠ©ï¼Œæˆ–è€…æ‚¨å…³æ³¨æœ¬é¡¹ç›®çš„æœªæ¥å‘å±•ï¼Œè¯·ç»™é¡¹ç›® Starï¼Œè¿™æ˜¯æˆ‘ç»´æŠ¤è¿™ä¸ªå¼€æºé¡¹ç›®çš„åŠ¨åŠ› &amp;lt;3&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://star-history.com/#soulter/astrbot&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=soulter/astrbot&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Sponsors&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://api.gitsponsors.com/api/badge/link?p=XEpbdGxlitw/RbcwiTX93UMzNK/jgDYC8NiSzamIPMoKvG2lBFmyXhSS/b0hFoWlBBMX2L5X5CxTDsUdyvcIEHTOfnkXz47UNOZvMwyt5CzbYpq0SEzsSV1OJF1cCo90qC/ZyYKYOWedal3MhZ3ikw==&#34;&gt;&lt;img src=&#34;https://api.gitsponsors.com/api/badge/img?id=575865240&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The project is protected under the &lt;code&gt;AGPL-v3&lt;/code&gt; opensource license.&lt;/li&gt; &#xA; &lt;li&gt;The deployment of WeChat (personal account) utilizes &lt;a href=&#34;https://github.com/Devo919/Gewechat&#34;&gt;Gewechat&lt;/a&gt; service. AstrBot only guarantees connectivity with Gewechat and recommends using a WeChat account that is not frequently used. In the event of account risk control, the author of this project shall not bear any responsibility.&lt;/li&gt; &#xA; &lt;li&gt;Please ensure compliance with local laws and regulations when using this project.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;!-- ## âœ¨ ATRI [Beta æµ‹è¯•]&#xA;&#xA;è¯¥åŠŸèƒ½ä½œä¸ºæ’ä»¶è½½å…¥ã€‚æ’ä»¶ä»“åº“åœ°å€ï¼š[astrbot_plugin_atri](https://github.com/Soulter/astrbot_plugin_atri)&#xA;&#xA;1. åŸºäºã€ŠATRI ~ My Dear Momentsã€‹ä¸»è§’ ATRI è§’è‰²å°è¯ä½œä¸ºå¾®è°ƒæ•°æ®é›†çš„ `Qwen1.5-7B-Chat Lora` å¾®è°ƒæ¨¡å‹ã€‚&#xA;2. é•¿æœŸè®°å¿†&#xA;3. è¡¨æƒ…åŒ…ç†è§£ä¸å›å¤&#xA;4. TTS&#xA;    --&gt; &#xA;&lt;p&gt;&lt;em&gt;ç§ã¯ã€é«˜æ€§èƒ½ã§ã™ã‹ã‚‰!&lt;/em&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>agno-agi/agno</title>
    <updated>2025-02-04T01:37:35Z</updated>
    <id>tag:github.com,2025-02-04:/agno-agi/agno</id>
    <link href="https://github.com/agno-agi/agno" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Agno is a lightweight framework for building multi-modal Agents&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34; id=&#34;top&#34;&gt; &#xA; &lt;a href=&#34;https://docs.agno.com&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;.assets/logo-dark.svg&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;.assets/logo-light.svg&#34;&gt; &#xA;   &lt;img src=&#34;https://raw.githubusercontent.com/agno-agi/agno/main/.assets/logo-light.svg?sanitize=true&#34; alt=&#34;Agno&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://docs.agno.com&#34;&gt;ğŸ“š Documentation&lt;/a&gt; &amp;nbsp;|&amp;nbsp; &#xA; &lt;a href=&#34;https://docs.agno.com/examples/introduction&#34;&gt;ğŸ’¡ Examples&lt;/a&gt; &amp;nbsp;|&amp;nbsp; &#xA; &lt;a href=&#34;https://github.com/agno-agi/agno/stargazers&#34;&gt;ğŸŒŸ Star Us&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.agno.com&#34;&gt;Agno&lt;/a&gt; is a lightweight framework for building multi-modal Agents.&lt;/p&gt; &#xA;&lt;h2&gt;Simple, Fast, and Agnostic&lt;/h2&gt; &#xA;&lt;p&gt;Agno is designed with three core principles:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Simplicity&lt;/strong&gt;: No graphs, chains, or convoluted patterns â€” just pure python.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Uncompromising Performance&lt;/strong&gt;: Blazing fast agents with a minimal memory footprint.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Truly Agnostic&lt;/strong&gt;: Any model, any provider, any modality. Future-proof agents.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Key features&lt;/h2&gt; &#xA;&lt;p&gt;Here&#39;s why you should build Agents with Agno:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Lightning Fast&lt;/strong&gt;: Agent creation is 6000x faster than LangGraph (see &lt;a href=&#34;https://raw.githubusercontent.com/agno-agi/agno/main/#performance&#34;&gt;performance&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Model Agnostic&lt;/strong&gt;: Use any model, any provider, no lock-in.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi Modal&lt;/strong&gt;: Native support for text, image, audio and video.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi Agent&lt;/strong&gt;: Delegate tasks across a team of specialized agents.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Memory Management&lt;/strong&gt;: Store user sessions and agent state in a database.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Knowledge Stores&lt;/strong&gt;: Use vector databases for Agentic RAG or dynamic few-shot.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Structured Outputs&lt;/strong&gt;: Make Agents respond with structured data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Monitoring&lt;/strong&gt;: Track agent sessions and performance in real-time on &lt;a href=&#34;https://app.agno.com&#34;&gt;agno.com&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install -U agno&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;What are Agents?&lt;/h2&gt; &#xA;&lt;p&gt;Agents are autonomous programs that use language models to achieve tasks. They solve problems by running tools, accessing knowledge and memory to improve responses.&lt;/p&gt; &#xA;&lt;p&gt;Instead of a rigid binary definition, let&#39;s think of Agents in terms of agency and autonomy.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Level 0&lt;/strong&gt;: Agents with no tools (basic inference tasks).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Level 1&lt;/strong&gt;: Agents with tools for autonomous task execution.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Level 2&lt;/strong&gt;: Agents with knowledge, combining memory and reasoning.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Level 3&lt;/strong&gt;: Teams of agents collaborating on complex workflows.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Example - Basic Agent&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from agno.agent import Agent&#xA;from agno.models.openai import OpenAIChat&#xA;&#xA;agent = Agent(&#xA;    model=OpenAIChat(id=&#34;gpt-4o&#34;),&#xA;    description=&#34;You are an enthusiastic news reporter with a flair for storytelling!&#34;,&#xA;    markdown=True&#xA;)&#xA;agent.print_response(&#34;Tell me about a breaking news story from New York.&#34;, stream=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run the agent, install dependencies and export your &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install agno openai&#xA;&#xA;export OPENAI_API_KEY=sk-xxxx&#xA;&#xA;python basic_agent.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/agno-agi/agno/main/cookbook/getting_started/01_basic_agent.py&#34;&gt;View this example in the cookbook&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Example - Agent with tools&lt;/h2&gt; &#xA;&lt;p&gt;This basic agent will obviously make up a story, lets give it a tool to search the web.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from agno.agent import Agent&#xA;from agno.models.openai import OpenAIChat&#xA;from agno.tools.duckduckgo import DuckDuckGoTools&#xA;&#xA;agent = Agent(&#xA;    model=OpenAIChat(id=&#34;gpt-4o&#34;),&#xA;    description=&#34;You are an enthusiastic news reporter with a flair for storytelling!&#34;,&#xA;    tools=[DuckDuckGoTools()],&#xA;    show_tool_calls=True,&#xA;    markdown=True&#xA;)&#xA;agent.print_response(&#34;Tell me about a breaking news story from New York.&#34;, stream=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install dependencies and run the Agent:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install duckduckgo-search&#xA;&#xA;python agent_with_tools.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now you should see a much more relevant result.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/agno-agi/agno/main/cookbook/getting_started/02_agent_with_tools.py&#34;&gt;View this example in the cookbook&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Example - Agent with knowledge&lt;/h2&gt; &#xA;&lt;p&gt;Agents can store knowledge in a vector database and use it for RAG or dynamic few-shot learning.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Agno agents use Agentic RAG&lt;/strong&gt; by default, which means they will search their knowledge base for the specific information they need to achieve their task.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from agno.agent import Agent&#xA;from agno.models.openai import OpenAIChat&#xA;from agno.embedder.openai import OpenAIEmbedder&#xA;from agno.tools.duckduckgo import DuckDuckGoTools&#xA;from agno.knowledge.pdf_url import PDFUrlKnowledgeBase&#xA;from agno.vectordb.lancedb import LanceDb, SearchType&#xA;&#xA;agent = Agent(&#xA;    model=OpenAIChat(id=&#34;gpt-4o&#34;),&#xA;    description=&#34;You are a Thai cuisine expert!&#34;,&#xA;    instructions=[&#xA;        &#34;Search your knowledge base for Thai recipes.&#34;,&#xA;        &#34;If the question is better suited for the web, search the web to fill in gaps.&#34;,&#xA;        &#34;Prefer the information in your knowledge base over the web results.&#34;&#xA;    ],&#xA;    knowledge=PDFUrlKnowledgeBase(&#xA;        urls=[&#34;https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf&#34;],&#xA;        vector_db=LanceDb(&#xA;            uri=&#34;tmp/lancedb&#34;,&#xA;            table_name=&#34;recipes&#34;,&#xA;            search_type=SearchType.hybrid,&#xA;            embedder=OpenAIEmbedder(id=&#34;text-embedding-3-small&#34;),&#xA;        ),&#xA;    ),&#xA;    tools=[DuckDuckGoTools()],&#xA;    show_tool_calls=True,&#xA;    markdown=True&#xA;)&#xA;&#xA;# Comment out after the knowledge base is loaded&#xA;if agent.knowledge is not None:&#xA;    agent.knowledge.load()&#xA;&#xA;agent.print_response(&#34;How do I make chicken and galangal in coconut milk soup&#34;, stream=True)&#xA;agent.print_response(&#34;What is the history of Thai curry?&#34;, stream=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install dependencies and run the Agent:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install lancedb tantivy pypdf duckduckgo-search&#xA;&#xA;python agent_with_knowledge.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/agno-agi/agno/main/cookbook/getting_started/03_agent_with_knowledge.py&#34;&gt;View this example in the cookbook&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Example - Multi Agent Teams&lt;/h2&gt; &#xA;&lt;p&gt;Agents work best when they have a singular purpose, a narrow scope and a small number of tools. When the number of tools grows beyond what the language model can handle or the tools belong to different categories, use a team of agents to spread the load.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from agno.agent import Agent&#xA;from agno.models.openai import OpenAIChat&#xA;from agno.tools.duckduckgo import DuckDuckGoTools&#xA;from agno.tools.yfinance import YFinanceTools&#xA;&#xA;web_agent = Agent(&#xA;    name=&#34;Web Agent&#34;,&#xA;    role=&#34;Search the web for information&#34;,&#xA;    model=OpenAIChat(id=&#34;gpt-4o&#34;),&#xA;    tools=[DuckDuckGoTools()],&#xA;    instructions=&#34;Always include sources&#34;,&#xA;    show_tool_calls=True,&#xA;    markdown=True,&#xA;)&#xA;&#xA;finance_agent = Agent(&#xA;    name=&#34;Finance Agent&#34;,&#xA;    role=&#34;Get financial data&#34;,&#xA;    model=OpenAIChat(id=&#34;gpt-4o&#34;),&#xA;    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)],&#xA;    instructions=&#34;Use tables to display data&#34;,&#xA;    show_tool_calls=True,&#xA;    markdown=True,&#xA;)&#xA;&#xA;agent_team = Agent(&#xA;    team=[web_agent, finance_agent],&#xA;    model=OpenAIChat(id=&#34;gpt-4o&#34;),&#xA;    instructions=[&#34;Always include sources&#34;, &#34;Use tables to display data&#34;],&#xA;    show_tool_calls=True,&#xA;    markdown=True,&#xA;)&#xA;&#xA;agent_team.print_response(&#34;What&#39;s the market outlook and financial performance of AI semiconductor companies?&#34;, stream=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install dependencies and run the Agent team:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install duckduckgo-search yfinance&#xA;&#xA;python agent_team.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/agno-agi/agno/main/cookbook/getting_started/05_agent_team.py&#34;&gt;View this example in the cookbook&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Performance&lt;/h2&gt; &#xA;&lt;p&gt;Agno is designed for high performance agentic systems:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Agent instantiation: &amp;lt;5Î¼s on average (5000x faster than LangGraph).&lt;/li&gt; &#xA; &lt;li&gt;Memory footprint: &amp;lt;0.01Mib on average (50x less memory than LangGraph).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Tested on an Apple M4 Mackbook Pro.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;While an Agent&#39;s performance is bottlenecked by inference, we must do everything possible to minimize execution time, reduce memory usage, and parallelize tool calls. These numbers are may seem minimal, but they add up even at medium scale.&lt;/p&gt; &#xA;&lt;h3&gt;Instantiation time&lt;/h3&gt; &#xA;&lt;p&gt;Let&#39;s measure the time it takes for an Agent with 1 tool to start up. We&#39;ll run the evaluation 1000 times to get a baseline measurement.&lt;/p&gt; &#xA;&lt;p&gt;You should run the evaluation yourself on your own machine, please, do not take these results at face value.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Setup virtual environment&#xA;./scripts/perf_setup.sh&#xA;source .venvs/perfenv/bin/activate&#xA;# OR Install dependencies manually&#xA;# pip install openai agno langgraph langchain_openai&#xA;&#xA;# Agno&#xA;python evals/performance/instantiation_with_tool.py&#xA;&#xA;# LangGraph&#xA;python evals/performance/other/langgraph_instantiation.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The following evaluation is run on an Apple M4 Mackbook Pro, but we&#39;ll soon be moving this to a Github actions runner for consistency.&lt;/p&gt; &#xA;&lt;p&gt;LangGraph is on the right, &lt;strong&gt;we start it first to give it a head start&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Agno is on the left, notice how it finishes before LangGraph gets 1/2 way through the runtime measurement, and hasn&#39;t even started the memory measurement. That&#39;s how fast Agno is.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/ba466d45-75dd-45ac-917b-0a56c5742e23&#34;&gt;https://github.com/user-attachments/assets/ba466d45-75dd-45ac-917b-0a56c5742e23&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Dividing the average time of a Langgraph Agent by the average time of an Agno Agent:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;0.020526s / 0.000002s ~ 10,263&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In this particular run, &lt;strong&gt;Agno Agent instantiation is roughly 10,000 times faster than Langgraph Agent instantiation&lt;/strong&gt;. Sure, the runtime will be dominated by inference, but these numbers add up as the number of Agents grows.&lt;/p&gt; &#xA;&lt;p&gt;The numbers continue to favor Agno as the number of tools grow, and we all memory and knowledge stores.&lt;/p&gt; &#xA;&lt;h3&gt;Memory usage&lt;/h3&gt; &#xA;&lt;p&gt;To measure memory usage, we use the &lt;code&gt;tracemalloc&lt;/code&gt; library. We first calculate a baseline memory usage by running an empty function, then run the Agent 1000x times and calculate the difference. This gives a (reasonably) isolated measurement of the memory usage of the Agent.&lt;/p&gt; &#xA;&lt;p&gt;We recommend running the evaluation yourself on your own machine, and digging into the code to see how it works. If we&#39;ve made a mistake, please let us know.&lt;/p&gt; &#xA;&lt;p&gt;Dividing the average memory usage of a Langgraph Agent by the average memory usage of an Agno Agent:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;0.137273/0.002528 ~ 54.3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Langgraph Agents use ~50x more memory than Agno Agents&lt;/strong&gt;. In our opinion, memory usage is a much more important metric than instantiation time. As we start running thousands of Agents in production, these numbers directly start affecting the cost of running the Agents.&lt;/p&gt; &#xA;&lt;h3&gt;Conclusion&lt;/h3&gt; &#xA;&lt;p&gt;Agno agents are designed for high-performance and while we do share some benchmarks against other frameworks, we should be mindful that accuracy and reliability are more important than speed.&lt;/p&gt; &#xA;&lt;p&gt;We&#39;ll be publishing accuracy and reliability benchmarks running on Github actions in the coming weeks. Given that each framework is different and we won&#39;t be able to tune their performance like we do with Agno, for future benchmarks we&#39;ll only be comparing against ourselves.&lt;/p&gt; &#xA;&lt;h2&gt;Cursor Setup&lt;/h2&gt; &#xA;&lt;p&gt;When building Agno agents, using the Agno docs as a documentation source in Cursor is a great way to speed up your development.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;In Cursor, go to the settings or preferences section.&lt;/li&gt; &#xA; &lt;li&gt;Find the section to manage documentation sources.&lt;/li&gt; &#xA; &lt;li&gt;Add &lt;code&gt;https://docs.agno.com&lt;/code&gt; to the list of documentation URLs.&lt;/li&gt; &#xA; &lt;li&gt;Save the changes.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Now, Cursor will have access to the Agno documentation.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation, Community &amp;amp; More examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Docs: &lt;a href=&#34;https://docs.agno.com&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;docs.agno.com&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Getting Started Examples: &lt;a href=&#34;https://github.com/agno-agi/agno/tree/main/cookbook/getting_started&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Getting Started Cookbook&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;All Examples: &lt;a href=&#34;https://github.com/agno-agi/agno/tree/main/cookbook&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Cookbook&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Community forum: &lt;a href=&#34;https://community.agno.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;community.agno.com&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Chat: &lt;a href=&#34;https://discord.gg/4MtYHHrgA8&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;discord&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributions&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions, read our &lt;a href=&#34;https://github.com/agno-agi/agno/raw/main/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt; to get started.&lt;/p&gt; &#xA;&lt;h2&gt;Telemetry&lt;/h2&gt; &#xA;&lt;p&gt;Agno logs which model an agent used so we can prioritize updates to the most popular providers. You can disable this by setting &lt;code&gt;AGNO_TELEMETRY=false&lt;/code&gt; in your environment.&lt;/p&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/agno-agi/agno/main/#top&#34;&gt;â¬†ï¸ Back to Top&lt;/a&gt; &lt;/p&gt;</summary>
  </entry>
</feed>