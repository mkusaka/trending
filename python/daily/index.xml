<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-06T01:41:47Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>bmaltais/kohya_ss</title>
    <updated>2023-02-06T01:41:47Z</updated>
    <id>tag:github.com,2023-02-06:/bmaltais/kohya_ss</id>
    <link href="https://github.com/bmaltais/kohya_ss" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kohya&#39;s GUI&lt;/h1&gt; &#xA;&lt;p&gt;This repository repository is providing a Windows focussed Gradio GUI for kohya&#39;s Stable Diffusion trainers found here: &lt;a href=&#34;https://github.com/kohya-ss/sd-scripts&#34;&gt;https://github.com/kohya-ss/sd-scripts&lt;/a&gt;. The GUI allow you to set the training parameters and generate and run the required CLI command to train the model.&lt;/p&gt; &#xA;&lt;p&gt;If you run on Linux and would like to use the GUI there is now a port of it as a docker container. You can find the project here: &lt;a href=&#34;https://github.com/P2Enjoy/kohya_ss-docker&#34;&gt;https://github.com/P2Enjoy/kohya_ss-docker&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Tutorials&lt;/h2&gt; &#xA;&lt;p&gt;How to create a LoRA part 1, dataset preparation:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=N4_-fB62Hwk&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/N4_-fB62Hwk/0.jpg&#34; alt=&#34;IMAGE ALT TEXT HERE&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;How to create a LoRA part 2, training the model:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=k5imq01uvUY&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/k5imq01uvUY/0.jpg&#34; alt=&#34;IMAGE ALT TEXT HERE&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Required Dependencies&lt;/h2&gt; &#xA;&lt;p&gt;Python 3.10.6+ and Git:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install Python 3.10 using &lt;a href=&#34;https://www.python.org/ftp/python/3.10.9/python-3.10.9-amd64.exe&#34;&gt;https://www.python.org/ftp/python/3.10.9/python-3.10.9-amd64.exe&lt;/a&gt; (make sure to tick the box to add Python to the environment path)&lt;/li&gt; &#xA; &lt;li&gt;git: &lt;a href=&#34;https://git-scm.com/download/win&#34;&gt;https://git-scm.com/download/win&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Visual Studio 2015, 2017, 2019, and 2022 redistributable: &lt;a href=&#34;https://aka.ms/vs/17/release/vc_redist.x64.exe&#34;&gt;https://aka.ms/vs/17/release/vc_redist.x64.exe&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Give unrestricted script access to powershell so venv can work:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Open an administrator powershell window&lt;/li&gt; &#xA; &lt;li&gt;Type &lt;code&gt;Set-ExecutionPolicy Unrestricted&lt;/code&gt; and answer A&lt;/li&gt; &#xA; &lt;li&gt;Close admin powershell window&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Open a regular user Powershell terminal and type the following inside:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;git clone https://github.com/bmaltais/kohya_ss.git&#xA;cd kohya_ss&#xA;&#xA;python -m venv venv&#xA;.\venv\Scripts\activate&#xA;&#xA;pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116&#xA;pip install --use-pep517 --upgrade -r requirements.txt&#xA;pip install -U -I --no-deps https://github.com/C43H66N12O12S2/stable-diffusion-webui/releases/download/f/xformers-0.0.14.dev0-cp310-cp310-win_amd64.whl&#xA;&#xA;cp .\bitsandbytes_windows\*.dll .\venv\Lib\site-packages\bitsandbytes\&#xA;cp .\bitsandbytes_windows\cextension.py .\venv\Lib\site-packages\bitsandbytes\cextension.py&#xA;cp .\bitsandbytes_windows\main.py .\venv\Lib\site-packages\bitsandbytes\cuda_setup\main.py&#xA;&#xA;accelerate config&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Optional: CUDNN 8.6&lt;/h3&gt; &#xA;&lt;p&gt;This step is optional but can improve the learning speed for NVidia 30X0/40X0 owners... It allows larger training batch size and faster training speed&lt;/p&gt; &#xA;&lt;p&gt;Due to the filesize I can&#39;t host the DLLs needed for CUDNN 8.6 on Github, I strongly advise you download them for a speed boost in sample generation (almost 50% on 4090) you can download them from here: &lt;a href=&#34;https://b1.thefileditch.ch/mwxKTEtelILoIbMbruuM.zip&#34;&gt;https://b1.thefileditch.ch/mwxKTEtelILoIbMbruuM.zip&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;To install simply unzip the directory and place the &lt;code&gt;cudnn_windows&lt;/code&gt; folder in the root of the kohya_ss repo.&lt;/p&gt; &#xA;&lt;p&gt;Run the following command to install:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;.\venv\Scripts\activate&#xA;python .\tools\cudann_1.8_install.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Upgrade&lt;/h2&gt; &#xA;&lt;p&gt;When a new release comes out you can upgrade your repo with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;cd kohya_ss&#xA;git pull&#xA;.\venv\Scripts\activate&#xA;pip install --use-pep517 --upgrade -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once the commands have completed successfully you should be ready to use the new version.&lt;/p&gt; &#xA;&lt;h2&gt;Launching the GUI&lt;/h2&gt; &#xA;&lt;p&gt;To run the GUI you simply use this command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;.\gui.ps1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or you can alsi do:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;.\venv\Scripts\activate&#xA;python.exe .\kohya_gui.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Dreambooth&lt;/h2&gt; &#xA;&lt;p&gt;You can find the dreambooth solution spercific &lt;a href=&#34;https://raw.githubusercontent.com/bmaltais/kohya_ss/master/train_db_README.md&#34;&gt;Dreambooth README&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Finetune&lt;/h2&gt; &#xA;&lt;p&gt;You can find the finetune solution spercific &lt;a href=&#34;https://raw.githubusercontent.com/bmaltais/kohya_ss/master/fine_tune_README.md&#34;&gt;Finetune README&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Train Network&lt;/h2&gt; &#xA;&lt;p&gt;You can find the train network solution spercific &lt;a href=&#34;https://raw.githubusercontent.com/bmaltais/kohya_ss/master/train_network_README.md&#34;&gt;Train network README&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;LoRA&lt;/h2&gt; &#xA;&lt;p&gt;Training a LoRA currently use the &lt;code&gt;train_network.py&lt;/code&gt; python code. You can create LoRA network by using the all-in-one &lt;code&gt;gui.cmd&lt;/code&gt; or by running the dedicated LoRA training GUI with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;.\venv\Scripts\activate&#xA;python lora_gui.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once you have created the LoRA network you can generate images via auto1111 by installing the extension found here: &lt;a href=&#34;https://github.com/kohya-ss/sd-webui-additional-networks&#34;&gt;https://github.com/kohya-ss/sd-webui-additional-networks&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Troubleshooting&lt;/h2&gt; &#xA;&lt;h3&gt;Page file limit&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;if get X error relating to &lt;code&gt;page file&lt;/code&gt;, increase page file size limit in Windows&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;No module called tkinter&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Re-install python 3.10.x on your system: &lt;a href=&#34;https://www.python.org/ftp/python/3.10.9/python-3.10.9-amd64.exe&#34;&gt;https://www.python.org/ftp/python/3.10.9/python-3.10.9-amd64.exe&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;FileNotFoundError&lt;/h3&gt; &#xA;&lt;p&gt;This is usually related to an installation issue. Make sure you do not have python modules installed locally that could conflict with the ones installed in the venv:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open a new powershell terminal and make sure no venv is active.&lt;/li&gt; &#xA; &lt;li&gt;Run the following commands&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip freeze &amp;gt; uninstall.txt&#xA;pip uninstall -r uninstall.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then redo the installation instruction within the kohya_ss venv.&lt;/p&gt; &#xA;&lt;h2&gt;Change history&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2023/02/04 (v20.6.1) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;--persistent_data_loader_workers&lt;/code&gt; option is added to &lt;code&gt;fine_tune.py&lt;/code&gt;, &lt;code&gt;train_db.py&lt;/code&gt; and &lt;code&gt;train_network.py&lt;/code&gt;. This option may significantly reduce the waiting time between epochs. Thanks to hitomi!&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--debug_dataset&lt;/code&gt; option is now working on non-Windows environment. Thanks to tsukimiya!&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;networks/resize_lora.py&lt;/code&gt; script is added. This can approximate the higher-rank (dim) LoRA model by a lower-rank LoRA model, e.g. 128 by 4. Thanks to mgz-dev! &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;code&gt;--help&lt;/code&gt; option shows usage.&lt;/li&gt; &#xA;     &lt;li&gt;Currently the metadata is not copied. This will be fixed in the near future.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;2023/02/03 (v20.6.0) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Increase max LoRA rank (dim) size to 1024.&lt;/li&gt; &#xA;   &lt;li&gt;Update finetune preprocessing scripts. &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;code&gt;.bmp&lt;/code&gt; and &lt;code&gt;.jpeg&lt;/code&gt; are supported. Thanks to breakcore2 and p1atdev!&lt;/li&gt; &#xA;     &lt;li&gt;The default weights of &lt;code&gt;tag_images_by_wd14_tagger.py&lt;/code&gt; is now &lt;code&gt;SmilingWolf/wd-v1-4-convnext-tagger-v2&lt;/code&gt;. You can specify another model id from &lt;code&gt;SmilingWolf&lt;/code&gt; by &lt;code&gt;--repo_id&lt;/code&gt; option. Thanks to SmilingWolf for the great work.&lt;/li&gt; &#xA;     &lt;li&gt;To change the weight, remove &lt;code&gt;wd14_tagger_model&lt;/code&gt; folder, and run the script again.&lt;/li&gt; &#xA;     &lt;li&gt;&lt;code&gt;--max_data_loader_n_workers&lt;/code&gt; option is added to each script. This option uses the DataLoader for data loading to speed up loading, 20%~30% faster.&lt;/li&gt; &#xA;     &lt;li&gt;Please specify 2 or 4, depends on the number of CPU cores.&lt;/li&gt; &#xA;     &lt;li&gt;&lt;code&gt;--recursive&lt;/code&gt; option is added to &lt;code&gt;merge_dd_tags_to_metadata.py&lt;/code&gt; and &lt;code&gt;merge_captions_to_metadata.py&lt;/code&gt;, only works with &lt;code&gt;--full_path&lt;/code&gt;.&lt;/li&gt; &#xA;     &lt;li&gt;&lt;code&gt;make_captions_by_git.py&lt;/code&gt; is added. It uses &lt;a href=&#34;https://huggingface.co/microsoft/git-large-textcaps&#34;&gt;GIT microsoft/git-large-textcaps&lt;/a&gt; for captioning.&lt;/li&gt; &#xA;     &lt;li&gt;&lt;code&gt;requirements.txt&lt;/code&gt; is updated. If you use this script, &lt;a href=&#34;https://github.com/kohya-ss/sd-scripts#upgrade&#34;&gt;please update the libraries&lt;/a&gt;.&lt;/li&gt; &#xA;     &lt;li&gt;Usage is almost the same as &lt;code&gt;make_captions.py&lt;/code&gt;, but batch size should be smaller.&lt;/li&gt; &#xA;     &lt;li&gt;&lt;code&gt;--remove_words&lt;/code&gt; option removes as much text as possible (such as &lt;code&gt;the word &#34;XXXX&#34; on it&lt;/code&gt;).&lt;/li&gt; &#xA;     &lt;li&gt;&lt;code&gt;--skip_existing&lt;/code&gt; option is added to &lt;code&gt;prepare_buckets_latents.py&lt;/code&gt;. Images with existing npz files are ignored by this option.&lt;/li&gt; &#xA;     &lt;li&gt;&lt;code&gt;clean_captions_and_tags.py&lt;/code&gt; is updated to remove duplicated or conflicting tags, e.g. &lt;code&gt;shirt&lt;/code&gt; is removed when &lt;code&gt;white shirt&lt;/code&gt; exists. if &lt;code&gt;black hair&lt;/code&gt; is with &lt;code&gt;red hair&lt;/code&gt;, both are removed.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Tag frequency is added to the metadata in &lt;code&gt;train_network.py&lt;/code&gt;. Thanks to space-nuko! &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;strong&gt;All tags and number of occurrences of the tag are recorded.&lt;/strong&gt; If you do not want it, disable metadata storing with &lt;code&gt;--no_metadata&lt;/code&gt; option.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;2023/01/30 (v20.5.2): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add &lt;code&gt;--lr_scheduler_num_cycles&lt;/code&gt; and &lt;code&gt;--lr_scheduler_power&lt;/code&gt; options for &lt;code&gt;train_network.py&lt;/code&gt; for cosine_with_restarts and polynomial learning rate schedulers. Thanks to mgz-dev!&lt;/li&gt; &#xA;   &lt;li&gt;Fixed U-Net &lt;code&gt;sample_size&lt;/code&gt; parameter to &lt;code&gt;64&lt;/code&gt; when converting from SD to Diffusers format, in &lt;code&gt;convert_diffusers20_original_sd.py&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;2023/01/27 (v20.5.1): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fix issue: &lt;a href=&#34;https://github.com/bmaltais/kohya_ss/issues/70&#34;&gt;https://github.com/bmaltais/kohya_ss/issues/70&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Fix issue &lt;a href=&#34;https://github.com/bmaltais/kohya_ss/issues/71&#34;&gt;https://github.com/bmaltais/kohya_ss/issues/71&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;2023/01/26 (v20.5.0): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add new &lt;code&gt;Dreambooth TI&lt;/code&gt; tab for training of Textual Inversion embeddings&lt;/li&gt; &#xA;   &lt;li&gt;Add Textual Inversion training. Documentation is &lt;a href=&#34;https://raw.githubusercontent.com/bmaltais/kohya_ss/master/train_ti_README-ja.md&#34;&gt;here&lt;/a&gt; (in Japanese.)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;2023/01/22 (v20.4.1): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add new tool to verify LoRA weights produced by the trainer. Can be found under &#34;Dreambooth LoRA/Tools/Verify LoRA&#34;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;2023/01/22 (v20.4.0): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add support for &lt;code&gt;network_alpha&lt;/code&gt; under the Training tab and support for &lt;code&gt;--training_comment&lt;/code&gt; under the Folders tab.&lt;/li&gt; &#xA;   &lt;li&gt;Add &lt;code&gt;--network_alpha&lt;/code&gt; option to specify &lt;code&gt;alpha&lt;/code&gt; value to prevent underflows for stable training. Thanks to CCRcmcpe! &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Details of the issue are described in &lt;a href=&#34;https://github.com/kohya-ss/sd-webui-additional-networks/issues/49&#34;&gt;https://github.com/kohya-ss/sd-webui-additional-networks/issues/49&lt;/a&gt; .&lt;/li&gt; &#xA;     &lt;li&gt;The default value is &lt;code&gt;1&lt;/code&gt;, scale &lt;code&gt;1 / rank (or dimension)&lt;/code&gt;. Set same value as &lt;code&gt;network_dim&lt;/code&gt; for same behavior to old version.&lt;/li&gt; &#xA;     &lt;li&gt;LoRA with a large dimension (rank) seems to require a higher learning rate with &lt;code&gt;alpha=1&lt;/code&gt; (e.g. 1e-3 for 128-dim, still investigating).　&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;For generating images in Web UI, &lt;strong&gt;the latest version of the extension &lt;code&gt;sd-webui-additional-networks&lt;/code&gt; (v0.3.0 or later) is required for the models trained with this release or later.&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Add logging for the learning rate for U-Net and Text Encoder independently, and for running average epoch loss. Thanks to mgz-dev!&lt;/li&gt; &#xA;   &lt;li&gt;Add more metadata such as dataset/reg image dirs, session ID, output name etc... See &lt;a href=&#34;https://github.com/kohya-ss/sd-scripts/pull/77&#34;&gt;https://github.com/kohya-ss/sd-scripts/pull/77&lt;/a&gt; for details. Thanks to space-nuko! &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;strong&gt;Now the metadata includes the folder name (the basename of the folder contains image files, not fullpath).&lt;/strong&gt; If you do not want it, disable metadata storing with &lt;code&gt;--no_metadata&lt;/code&gt; option.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Add &lt;code&gt;--training_comment&lt;/code&gt; option. You can specify an arbitrary string and refer to it by the extension.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;It seems that the Stable Diffusion web UI now supports image generation using the LoRA model learned in this repository.&lt;/p&gt; &#xA;&lt;p&gt;Note: At this time, it appears that models learned with version 0.4.0 are not supported. If you want to use the generation function of the web UI, please continue to use version 0.3.2. Also, it seems that LoRA models for SD2.x are not supported.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2023/01/16 (v20.3.0): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fix a part of LoRA modules are not trained when &lt;code&gt;gradient_checkpointing&lt;/code&gt; is enabled.&lt;/li&gt; &#xA;   &lt;li&gt;Add &lt;code&gt;--save_last_n_epochs_state&lt;/code&gt; option. You can specify how many state folders to keep, apart from how many models to keep. Thanks to shirayu!&lt;/li&gt; &#xA;   &lt;li&gt;Fix Text Encoder training stops at &lt;code&gt;max_train_steps&lt;/code&gt; even if &lt;code&gt;max_train_epochs&lt;/code&gt; is set in `train_db.py``.&lt;/li&gt; &#xA;   &lt;li&gt;Added script to check LoRA weights. You can check weights by &lt;code&gt;python networks\check_lora_weights.py &amp;lt;model file&amp;gt;&lt;/code&gt;. If some modules are not trained, the value is &lt;code&gt;0.0&lt;/code&gt; like following. &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;code&gt;lora_te_text_model_encoder_layers_11_*&lt;/code&gt; is not trained with &lt;code&gt;clip_skip=2&lt;/code&gt;, so &lt;code&gt;0.0&lt;/code&gt; is okay for these modules.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;example result of &lt;code&gt;check_lora_weights.py&lt;/code&gt;, Text Encoder and a part of U-Net are not trained:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;number of LoRA-up modules: 264&#xA;lora_te_text_model_encoder_layers_0_mlp_fc1.lora_up.weight,0.0&#xA;lora_te_text_model_encoder_layers_0_mlp_fc2.lora_up.weight,0.0&#xA;lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_up.weight,0.0&#xA;:&#xA;lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight,0.0&#xA;lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight,0.0&#xA;lora_unet_mid_block_attentions_0_proj_in.lora_up.weight,0.003503334941342473&#xA;lora_unet_mid_block_attentions_0_proj_out.lora_up.weight,0.004308608360588551&#xA;:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;all modules are trained:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;number of LoRA-up modules: 264&#xA;lora_te_text_model_encoder_layers_0_mlp_fc1.lora_up.weight,0.0028684409335255623&#xA;lora_te_text_model_encoder_layers_0_mlp_fc2.lora_up.weight,0.0029794853180646896&#xA;lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_up.weight,0.002507600700482726&#xA;lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_up.weight,0.002639499492943287&#xA;:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/01/16 (v20.2.1):&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Merging latest code update from kohya&lt;/li&gt; &#xA;   &lt;li&gt;Added &lt;code&gt;--max_train_epochs&lt;/code&gt; and &lt;code&gt;--max_data_loader_n_workers&lt;/code&gt; option for each training script.&lt;/li&gt; &#xA;   &lt;li&gt;If you specify the number of training epochs with &lt;code&gt;--max_train_epochs&lt;/code&gt;, the number of steps is calculated from the number of epochs automatically.&lt;/li&gt; &#xA;   &lt;li&gt;You can set the number of workers for DataLoader with &lt;code&gt;--max_data_loader_n_workers&lt;/code&gt;, default is 8. The lower number may reduce the main memory usage and the time between epochs, but may cause slower dataloading (training).&lt;/li&gt; &#xA;   &lt;li&gt;Fix loading some VAE or .safetensors as VAE is failed for &lt;code&gt;--vae&lt;/code&gt; option. Thanks to Fannovel16!&lt;/li&gt; &#xA;   &lt;li&gt;Add negative prompt scaling for &lt;code&gt;gen_img_diffusers.py&lt;/code&gt; You can set another conditioning scale to the negative prompt with &lt;code&gt;--negative_scale&lt;/code&gt; option, and &lt;code&gt;--nl&lt;/code&gt; option for the prompt. Thanks to laksjdjf!&lt;/li&gt; &#xA;   &lt;li&gt;Refactoring of GUI code and fixing mismatch... and possibly introducing bugs...&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/01/11 (v20.2.0):&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add support for max token lenght&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/01/10 (v20.1.1):&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fix issue with LoRA config loading&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/01/10 (v20.1):&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add support for &lt;code&gt;--output_name&lt;/code&gt; to trainers&lt;/li&gt; &#xA;   &lt;li&gt;Refactor code for easier maintenance&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/01/10 (v20.0):&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Update code base to match latest kohys_ss code upgrade in &lt;a href=&#34;https://github.com/kohya-ss/sd-scripts&#34;&gt;https://github.com/kohya-ss/sd-scripts&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/01/09 (v19.4.3):&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add vae support to dreambooth GUI&lt;/li&gt; &#xA;   &lt;li&gt;Add gradient_checkpointing, gradient_accumulation_steps, mem_eff_attn, shuffle_caption to finetune GUI&lt;/li&gt; &#xA;   &lt;li&gt;Add gradient_accumulation_steps, mem_eff_attn to dreambooth lora gui&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/01/08 (v19.4.2):&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add find/replace option to Basic Caption utility&lt;/li&gt; &#xA;   &lt;li&gt;Add resume training and save_state option to finetune UI&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/01/06 (v19.4.1):&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Emergency fix for new version of gradio causing issues with drop down menus. Please run &lt;code&gt;pip install -U -r requirements.txt&lt;/code&gt; to fix the issue after pulling this repo.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/01/06 (v19.4):&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add new Utility to Extract a LoRA from a finetuned model&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/01/06 (v19.3.1):&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Emergency fix for dreambooth_ui no longer working, sorry&lt;/li&gt; &#xA;   &lt;li&gt;Add LoRA network merge too GUI. Run &lt;code&gt;pip install -U -r requirements.txt&lt;/code&gt; after pulling this new release.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/01/05 (v19.3):&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Add support for &lt;code&gt;--clip_skip&lt;/code&gt; option&lt;/li&gt; &#xA;   &lt;li&gt;Add missing &lt;code&gt;detect_face_rotate.py&lt;/code&gt; to tools folder&lt;/li&gt; &#xA;   &lt;li&gt;Add &lt;code&gt;gui.cmd&lt;/code&gt; for easy start of GUI&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/01/02 (v19.2) update:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Finetune, add xformers, 8bit adam, min bucket, max bucket, batch size and flip augmentation support for dataset preparation&lt;/li&gt; &#xA;   &lt;li&gt;Finetune, add &#34;Dataset preparation&#34; tab to group task specific options&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/01/01 (v19.2) update:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;add support for color and flip augmentation to &#34;Dreambooth LoRA&#34;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023/01/01 (v19.1) update:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;merge kohys_ss upstream code updates&lt;/li&gt; &#xA;   &lt;li&gt;rework Dreambooth LoRA GUI&lt;/li&gt; &#xA;   &lt;li&gt;fix bug where LoRA network weights were not loaded to properly resume training&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2022/12/30 (v19) update:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;support for LoRA network training in kohya_gui.py.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2022/12/23 (v18.8) update:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fix for conversion tool issue when the source was an sd1.x diffuser model&lt;/li&gt; &#xA;   &lt;li&gt;Other minor code and GUI fix&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2022/12/22 (v18.7) update:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Merge dreambooth and finetune is a common GUI&lt;/li&gt; &#xA;   &lt;li&gt;General bug fixes and code improvements&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2022/12/21 (v18.6.1) update:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;fix issue with dataset balancing when the number of detected images in the folder is 0&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2022/12/21 (v18.6) update:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;add optional GUI authentication support via: &lt;code&gt;python fine_tune.py --username=&amp;lt;name&amp;gt; --password=&amp;lt;password&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>LeagueOfPoro/CapsuleFarmerEvolved</title>
    <updated>2023-02-06T01:41:47Z</updated>
    <id>tag:github.com,2023-02-06:/LeagueOfPoro/CapsuleFarmerEvolved</id>
    <link href="https://github.com/LeagueOfPoro/CapsuleFarmerEvolved" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Automatically drops from lolesports.com and farm Esports Capsules&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Capsule Farmer Evolved&lt;/h1&gt; &#xA;&lt;p&gt;Are you tired of watching professional League of Legends games? Do you watch only for the drops? This is a revolution in the farming of League of Legends Esports capsules!&lt;/p&gt; &#xA;&lt;p&gt;This is a successor to the old &lt;a href=&#34;https://github.com/LeagueOfPoro/EsportsCapsuleFarmer&#34;&gt;EsportsCapsuleFarmer&lt;/a&gt; which relied on a web browser to watch videos. &lt;em&gt;Capsule Farmer Evolved&lt;/em&gt; simulates traffic to lolesports.com servers and tricks it into thinking the account is watching a stream. This approach drastically lowers the hardware requirements.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://lolesports.com/article/lol-esports-2022-season-rewards-and-drops-update!/blt4ae38b4643f45741&#34;&gt;Learn more about the esports drops directly from Riot games.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Watch every live match&lt;/li&gt; &#xA; &lt;li&gt;Show how many drops each account received during the program run&lt;/li&gt; &#xA; &lt;li&gt;Very lightweight - no external browser needed&lt;/li&gt; &#xA; &lt;li&gt;Simple GUI&lt;/li&gt; &#xA; &lt;li&gt;2FA (experimental) - programs prompts for the code on startup&lt;/li&gt; &#xA; &lt;li&gt;ARM supported (Raspberry Pi)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Discord&lt;/h3&gt; &#xA;&lt;p&gt;Share your drops or just come hangout to League of Poro&#39;s Discord server: &lt;a href=&#34;https://discord.gg/c2Qs9Y83hh&#34;&gt;https://discord.gg/c2Qs9Y83hh&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download and run the latest CapsuleFarmerEvolved.zip from &lt;a href=&#34;https://github.com/LeagueOfPoro/CapsuleFarmerEvolved/releases/latest&#34;&gt;Releases tab&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Extract the archive&lt;/li&gt; &#xA; &lt;li&gt;Edit the configuration file &lt;code&gt;config.yaml&lt;/code&gt; with a text editor (e.g. Notepad) - see &lt;a href=&#34;https://raw.githubusercontent.com/LeagueOfPoro/CapsuleFarmerEvolved/master/#configuration&#34;&gt;Configuration&lt;/a&gt; for details&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;CapsuleFarmer.exe&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;There&#39;s a &lt;a href=&#34;https://github.com/LeagueOfPoro/CapsuleFarmerEvolved/wiki/Quickstart-guide&#34;&gt;Quickstart guide&lt;/a&gt; if you have issues&lt;/p&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;Fill out your username and password in &lt;code&gt;config.yaml&lt;/code&gt;. Name of the account groups is not important but I recommend entering something recognizable to better detect problems with the account.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;accounts:&#xA;  accountname:&#xA;    username: &#34;username&#34;&#xA;    password: &#34;password&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can add as many accounts as you want. &lt;em&gt;(But be reasonable)&lt;/em&gt; Example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;accounts:&#xA;  accountname:&#xA;    username: &#34;username&#34;&#xA;    password: &#34;password&#34;&#xA;  changethistowhatever:&#xA;    username: &#34;Riot Poro&#34;&#xA;    password: &#34;1234&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In case of problem, enable debugging mode to increase verbosity of the log: &lt;code&gt;debug: True&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can select a non-default configuration file, see &lt;a href=&#34;https://raw.githubusercontent.com/LeagueOfPoro/CapsuleFarmerEvolved/master/#cli&#34;&gt;CLI&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;capsulefarmerevolved.exe --config secret.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Notes&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;I recommend disabling 2FA on accounts using the bot. It will be way more stable, and it won&#39;t ask you for a code in the middle of a random night.&lt;/li&gt; &#xA; &lt;li&gt;Not every account receives every drop. That is normal, and it would happen even if you watched it on the web. &lt;img src=&#34;https://user-images.githubusercontent.com/95635582/215994461-4f613b76-0e96-4b1a-b138-f1caa748df65.png&#34; alt=&#34;image&#34;&gt;&lt;/li&gt; &#xA; &lt;li&gt;Regularly check if the &#34;Heartbeat&#34; happened within the last few minutes. If not, restart the program.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;CLI&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;usage: CapsuleFarmerEvolved.exe [-h] [-c CONFIGPATH]&#xA;&#xA;Farm Esports Capsules by watching all matches on lolesports.com.&#xA;&#xA;options:&#xA;  -h, --help            show this help message and exit&#xA;  -c CONFIGPATH, --config CONFIGPATH&#xA;                        Path to a custom config file&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Installation (advanced)&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisities&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python &amp;gt;= 3.10.1 (version 3.9 should work as well but is not officially supported)&lt;/li&gt; &#xA; &lt;li&gt;pipenv (&lt;code&gt;pip install pipenv&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Step by step&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repo - &lt;code&gt;git clone https://github.com/LeagueOfPoro/CapsuleFarmerEvolved.git&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Move to the directory - &lt;code&gt;cd CapsuleFarmerEvolved&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Install the Python virtual environment - &lt;code&gt;pipenv install&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Edit the configuration file&lt;/li&gt; &#xA; &lt;li&gt;Run the tool - &lt;code&gt;pipenv run python ./main.py&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Update&lt;/h3&gt; &#xA;&lt;p&gt;In the CapsuleFarmerEvolved, run &lt;code&gt;git pull&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Create EXE&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;pipenv install --dev&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;pipenv run pyinstaller -F --icon=poro.ico ./main.py --collect-all charset_normalizer -n CapsuleFarmerEvolved&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Docker&lt;/h2&gt; &#xA;&lt;p&gt;Pre-built image:&lt;/p&gt; &#xA;&lt;p&gt;Edit the &lt;code&gt;/path/to/config.yaml&lt;/code&gt; to absolute path to your configuration file and run the container in the background:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run -it --rm --restart unless-stopped --name CapsuleFarmer -d -v /path/to/config.yaml:/config/config.yaml  leagueofporo/capsulefarmer:master&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to build the image locally:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repo and move to it&#39;s direcotry&lt;/li&gt; &#xA; &lt;li&gt;Build the image: &lt;code&gt;docker build -t capsulefarmerevolved .&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Edit the &lt;code&gt;/path/to/config.yaml&lt;/code&gt; to absolute path to your configuration file and run the container in the background:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-docker&#34;&gt;docker run -it --rm --restart unless-stopped -d -v /path/to/config.yaml:/config/config.yaml  capsulefarmerevolved&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Support my work&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/channel/UCwgpdTScSd788qILhLnyyyw?sub_confirmation=1&#34;&gt;Subscribe to my channel on YouTube&lt;/a&gt; or even&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/channel/UCwgpdTScSd788qILhLnyyyw/join&#34; target=&#34;_blank&#34;&gt;&lt;img height=&#34;35&#34; style=&#34;border:0px;height:46px;&#34; src=&#34;https://share.leagueofporo.com/yt_member.png&#34; border=&#34;0&#34; alt=&#34;Become a channel member on YouTube&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;a href=&#34;https://www.youtube.com/channel/UCwgpdTScSd788qILhLnyyyw/join&#34; target=&#34;_blank&#34;&gt; &lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>zhayujie/chatgpt-on-wechat</title>
    <updated>2023-02-06T01:41:47Z</updated>
    <id>tag:github.com,2023-02-06:/zhayujie/chatgpt-on-wechat</id>
    <link href="https://github.com/zhayujie/chatgpt-on-wechat" rel="alternate"></link>
    <summary type="html">&lt;p&gt;使用ChatGPT搭建微信聊天机器人，基于OpenAI API和itchat实现。Wechat robot based on ChatGPT, which using OpenAI api and itchat library.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;简介&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ChatGPT近期以强大的对话和信息整合能力风靡全网，可以写代码、改论文、讲故事，几乎无所不能，这让人不禁有个大胆的想法，能否用他的对话模型把我们的微信打造成一个智能机器人，可以在与好友对话中给出意想不到的回应，而且再也不用担心女朋友影响我们 &lt;del&gt;打游戏&lt;/del&gt; 工作了。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;基于ChatGPT的微信聊天机器人，通过 &lt;a href=&#34;https://github.com/openai/openai-quickstart-python&#34;&gt;OpenAI&lt;/a&gt; 接口生成对话内容，使用 &lt;a href=&#34;https://github.com/littlecodersh/ItChat&#34;&gt;itchat&lt;/a&gt; 实现微信消息的接收和自动回复。已实现的特性如下：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;文本对话：&lt;/strong&gt; 接收私聊及群组中的微信消息，使用ChatGPT生成回复内容，完成自动回复&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;规则定制化：&lt;/strong&gt; 支持私聊中按指定规则触发自动回复，支持对群组设置自动回复白名单&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;多账号：&lt;/strong&gt; 支持多微信账号同时运行&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;图片生成：&lt;/strong&gt; 支持根据描述生成图片，并自动发送至个人聊天或群聊&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;上下文记忆&lt;/strong&gt;：支持多轮对话记忆，且为每个好友维护独立的上下会话&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;更新日志&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;2022.02.05：&lt;/strong&gt; 在openai官方接口方案中 (GPT-3模型) 实现上下文对话&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;2022.12.19：&lt;/strong&gt; 引入 &lt;a href=&#34;https://github.com/why2lyj/ItChat-UOS&#34;&gt;itchat-uos&lt;/a&gt; 替换 itchat，解决由于不能登录网页微信而无法使用的问题，且解决Python3.9的兼容问题&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;2022.12.18：&lt;/strong&gt; 支持根据描述生成图片并发送，openai版本需大于0.25.0&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;2022.12.17：&lt;/strong&gt; 原来的方案是从 &lt;a href=&#34;https://chat.openai.com/chat&#34;&gt;ChatGPT页面&lt;/a&gt; 获取session_token，使用 &lt;a href=&#34;https://github.com/acheong08/ChatGPT&#34;&gt;revChatGPT&lt;/a&gt; 直接访问web接口，但随着ChatGPT接入Cloudflare人机验证，这一方案难以在服务器顺利运行。 所以目前使用的方案是调用 OpenAI 官方提供的 &lt;a href=&#34;https://beta.openai.com/docs/api-reference/introduction&#34;&gt;API&lt;/a&gt;，回复质量上基本接近于ChatGPT的内容，劣势是暂不支持有上下文记忆的对话，优势是稳定性和响应速度较好。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;使用效果&lt;/h1&gt; &#xA;&lt;h3&gt;个人聊天&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zhayujie/chatgpt-on-wechat/master/docs/images/single-chat-sample.jpg&#34; alt=&#34;single-chat-sample.jpg&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;群组聊天&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zhayujie/chatgpt-on-wechat/master/docs/images/group-chat-sample.jpg&#34; alt=&#34;group-chat-sample.jpg&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;图片生成&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zhayujie/chatgpt-on-wechat/master/docs/images/image-create-sample.jpg&#34; alt=&#34;group-chat-sample.jpg&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;快速开始&lt;/h1&gt; &#xA;&lt;h2&gt;准备&lt;/h2&gt; &#xA;&lt;h3&gt;1. OpenAI账号注册&lt;/h3&gt; &#xA;&lt;p&gt;前往 &lt;a href=&#34;https://beta.openai.com/signup&#34;&gt;OpenAI注册页面&lt;/a&gt; 创建账号，参考这篇 &lt;a href=&#34;https://www.cnblogs.com/damugua/p/16969508.html&#34;&gt;教程&lt;/a&gt; 可以通过虚拟手机号来接收验证码。创建完账号则前往 &lt;a href=&#34;https://beta.openai.com/account/api-keys&#34;&gt;API管理页面&lt;/a&gt; 创建一个 API Key 并保存下来，后面需要在项目中配置这个key。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;项目中使用的对话模型是 davinci，计费方式是每1k字 (包含请求和回复) 消耗 $0.02，图片生成是每张消耗 $0.016，账号创建有免费的 $18 额度，使用完可以更换邮箱重新注册。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;2.运行环境&lt;/h3&gt; &#xA;&lt;p&gt;支持 Linux、MacOS、Windows 系统（可在Linux服务器上长期运行)，同时需安装 &lt;code&gt;Python&lt;/code&gt;。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;建议Python版本在 3.7.1~3.9.X 之间，3.10及以上版本在 MacOS 可用，其他系统上不确定能否正常运行。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;1.克隆项目代码：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/zhayujie/chatgpt-on-wechat&#xA;cd chatgpt-on-wechat/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;2.安装所需核心依赖：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip3 install itchat-uos==1.5.0.dev0&#xA;pip3 install --upgrade openai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;注：&lt;code&gt;itchat-uos&lt;/code&gt;使用指定版本1.5.0.dev0，&lt;code&gt;openai&lt;/code&gt;使用最新版本，需高于0.25.0。&lt;/p&gt; &#xA;&lt;h2&gt;配置&lt;/h2&gt; &#xA;&lt;p&gt;配置文件的模板在根目录的&lt;code&gt;config-template.json&lt;/code&gt;中，需复制该模板创建最终生效的 &lt;code&gt;config.json&lt;/code&gt; 文件：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp config-template.json config.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;然后在&lt;code&gt;config.json&lt;/code&gt;中填入配置，以下是对默认配置的说明，可根据需要进行自定义修改：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# config.json文件内容示例&#xA;{ &#xA;  &#34;open_ai_api_key&#34;: &#34;YOUR API KEY&#34;                           # 填入上面创建的 OpenAI API KEY&#xA;  &#34;single_chat_prefix&#34;: [&#34;bot&#34;, &#34;@bot&#34;],                      # 私聊时文本需要包含该前缀才能触发机器人回复&#xA;  &#34;single_chat_reply_prefix&#34;: &#34;[bot] &#34;,                       # 私聊时自动回复的前缀，用于区分真人&#xA;  &#34;group_chat_prefix&#34;: [&#34;@bot&#34;],                              # 群聊时包含该前缀则会触发机器人回复&#xA;  &#34;group_name_white_list&#34;: [&#34;ChatGPT测试群&#34;, &#34;ChatGPT测试群2&#34;], # 开启自动回复的群名称列表&#xA;  &#34;image_create_prefix&#34;: [&#34;画&#34;, &#34;看&#34;, &#34;找&#34;],                   # 开启图片回复的前缀&#xA;  &#34;conversation_max_tokens&#34;: 1000,                            # 支持上下文记忆的最多字符数&#xA;  &#34;character_desc&#34;: &#34;你是ChatGPT, 一个由OpenAI训练的大型语言模型, 你乐于回答人们的各种问题。&#34;  # 人格描述&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;配置说明：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;1.个人聊天&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;个人聊天中，需要以 &#34;bot&#34;或&#34;@bot&#34; 为开头的内容触发机器人，对应配置项 &lt;code&gt;single_chat_prefix&lt;/code&gt; (如果不需要以前缀触发可以填写 &lt;code&gt;&#34;single_chat_prefix&#34;: [&#34;&#34;]&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;机器人回复的内容会以 &#34;[bot] &#34; 作为前缀， 以区分真人，对应的配置项为 &lt;code&gt;single_chat_reply_prefix&lt;/code&gt; (如果不需要前缀可以填写 &lt;code&gt;&#34;single_chat_reply_prefix&#34;: &#34;&#34;&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;2.群组聊天&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;群组聊天中，群名称需配置在 &lt;code&gt;group_name_white_list &lt;/code&gt; 中才能开启群聊自动回复。如果想对所有群聊生效，可以直接填写 &lt;code&gt;&#34;group_name_white_list&#34;: &#34;ALL_GROUP&#34;&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;默认只要被人 @ 就会触发机器人自动回复；另外群聊天中只要检测到以 &#34;@bot&#34; 开头的内容，同样会自动回复（方便自己触发），这对应配置项 &lt;code&gt;group_chat_prefix&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;可选配置: &lt;code&gt;group_name_keyword_white_list&lt;/code&gt;配置项支持模糊匹配群名称，&lt;code&gt;group_chat_keyword&lt;/code&gt;配置项则支持模糊匹配群消息内容，用法与上述两个配置项相同。（Contributed by &lt;a href=&#34;https://github.com/evolay&#34;&gt;evolay&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;3.其他配置&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;对于图像生成，在满足个人或群组触发条件外，还需要额外的关键词前缀来触发，对应配置 &lt;code&gt;image_create_prefix &lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;关于OpenAI对话及图片接口的参数配置（内容自由度、回复字数限制、图片大小等），可以参考 &lt;a href=&#34;https://beta.openai.com/docs/api-reference/completions&#34;&gt;对话接口&lt;/a&gt; 和 &lt;a href=&#34;https://beta.openai.com/docs/api-reference/completions&#34;&gt;图像接口&lt;/a&gt; 文档直接在 &lt;a href=&#34;https://github.com/zhayujie/chatgpt-on-wechat/raw/master/bot/openai/open_ai_bot.py&#34;&gt;代码&lt;/a&gt; &lt;code&gt;bot/openai/open_ai_bot.py&lt;/code&gt; 中进行调整。&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;conversation_max_tokens&lt;/code&gt;：表示能够记忆的上下文最大字数（一问一答为一组对话，如果累积的对话字数超出限制，就会优先移除最早的一组对话）&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;character_desc&lt;/code&gt; 配置中保存着你对机器人说的一段话，他会记住这段话并作为他的设定，你可以为他定制任何人格 (关于会话上下文的更多内容参考该 &lt;a href=&#34;https://github.com/zhayujie/chatgpt-on-wechat/issues/43&#34;&gt;issue&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;运行&lt;/h2&gt; &#xA;&lt;p&gt;1.如果是开发机 &lt;strong&gt;本地运行&lt;/strong&gt;，直接在项目根目录下执行：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;终端输出二维码后，使用微信进行扫码，当输出 &#34;Start auto replying&#34; 时表示自动回复程序已经成功运行了（注意：用于登录的微信需要在支付处已完成实名认证）。扫码登录后，就可以在微信手机端通过配置的关键词触发自动回复了。&lt;/p&gt; &#xA;&lt;p&gt;2.如果是 &lt;strong&gt;服务器部署&lt;/strong&gt;，则使用nohup命令在后台运行：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;touch nohup.out                                   # 首次运行需要新建日志文件                     &#xA;nohup python3 app.py &amp;amp; tail -f nohup.out          # 在后台运行程序并通过日志输出二维码&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;扫码登录后程序即可运行于服务器后台，此时可通过 &lt;code&gt;ctrl+c&lt;/code&gt; 关闭日志，不会影响后台程序的运行。使用 &lt;code&gt;ps -ef | grep app.py | grep -v grep&lt;/code&gt; 命令可查看运行于后台的进程，如果想要重新启动程序可以先 &lt;code&gt;kill&lt;/code&gt; 掉对应的进程。日志关闭后如果想要再次打开只需输入&amp;nbsp;&lt;code&gt;tail -f nohup.out&lt;/code&gt;。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;注：如果 扫码后手机提示登录验证需要等待5s，而终端的二维码再次刷新并提示 &lt;code&gt;Log in time out, reloading QR code&lt;/code&gt;，此时需参考此 &lt;a href=&#34;https://github.com/zhayujie/chatgpt-on-wechat/issues/8&#34;&gt;issue&lt;/a&gt; 修改一行代码即可解决。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;常见问题&lt;/h2&gt; &#xA;&lt;p&gt;FAQs： &lt;a href=&#34;https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs&#34;&gt;https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;联系&lt;/h2&gt; &#xA;&lt;p&gt;欢迎提交PR、Issues，以及Star支持一下。程序运行遇到问题优先查看 &lt;a href=&#34;https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs&#34;&gt;常见问题列表&lt;/a&gt; ，其次前往 &lt;a href=&#34;https://github.com/zhayujie/chatgpt-on-wechat/issues&#34;&gt;Issues&lt;/a&gt; 中搜索，没有相似问题则创建Issue，一段时间内无回复可加微信 eijuyahz 交流。&lt;/p&gt;</summary>
  </entry>
</feed>