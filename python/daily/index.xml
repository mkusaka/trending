<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-05-21T01:34:29Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>beeware/toga</title>
    <updated>2025-05-21T01:34:29Z</updated>
    <id>tag:github.com,2025-05-21:/beeware/toga</id>
    <link href="https://github.com/beeware/toga" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Python native, OS native GUI toolkit.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. |logo| image:: &lt;a href=&#34;https://beeware.org/project/toga/toga.png&#34;&gt;https://beeware.org/project/toga/toga.png&lt;/a&gt; :width: 72px :target: &lt;a href=&#34;https://beeware.org/toga&#34;&gt;https://beeware.org/toga&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. |pyversions| image:: &lt;a href=&#34;https://img.shields.io/pypi/pyversions/toga.svg&#34;&gt;https://img.shields.io/pypi/pyversions/toga.svg&lt;/a&gt; :target: &lt;a href=&#34;https://pypi.python.org/pypi/toga&#34;&gt;https://pypi.python.org/pypi/toga&lt;/a&gt; :alt: Python Versions&lt;/p&gt; &#xA;&lt;p&gt;.. |version| image:: &lt;a href=&#34;https://img.shields.io/pypi/v/toga.svg&#34;&gt;https://img.shields.io/pypi/v/toga.svg&lt;/a&gt; :target: &lt;a href=&#34;https://pypi.python.org/pypi/toga&#34;&gt;https://pypi.python.org/pypi/toga&lt;/a&gt; :alt: Project version&lt;/p&gt; &#xA;&lt;p&gt;.. |license| image:: &lt;a href=&#34;https://img.shields.io/pypi/l/toga.svg&#34;&gt;https://img.shields.io/pypi/l/toga.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/beeware/toga/raw/main/LICENSE&#34;&gt;https://github.com/beeware/toga/blob/main/LICENSE&lt;/a&gt; :alt: BSD-3-Clause License&lt;/p&gt; &#xA;&lt;p&gt;.. |maturity| image:: &lt;a href=&#34;https://img.shields.io/pypi/status/toga.svg&#34;&gt;https://img.shields.io/pypi/status/toga.svg&lt;/a&gt; :target: &lt;a href=&#34;https://pypi.python.org/pypi/toga&#34;&gt;https://pypi.python.org/pypi/toga&lt;/a&gt; :alt: Project status&lt;/p&gt; &#xA;&lt;p&gt;.. |ci| image:: &lt;a href=&#34;https://github.com/beeware/toga/workflows/CI/badge.svg?branch=main&#34;&gt;https://github.com/beeware/toga/workflows/CI/badge.svg?branch=main&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/beeware/toga/actions&#34;&gt;https://github.com/beeware/toga/actions&lt;/a&gt; :alt: Build Status&lt;/p&gt; &#xA;&lt;p&gt;.. |social| image:: &lt;a href=&#34;https://img.shields.io/discord/836455665257021440?label=Discord%20Chat&amp;amp;logo=discord&amp;amp;style=plastic&#34;&gt;https://img.shields.io/discord/836455665257021440?label=Discord%20Chat&amp;amp;logo=discord&amp;amp;style=plastic&lt;/a&gt; :target: &lt;a href=&#34;https://beeware.org/bee/chat/&#34;&gt;https://beeware.org/bee/chat/&lt;/a&gt; :alt: Discord server&lt;/p&gt; &#xA;&lt;p&gt;|logo|&lt;/p&gt; &#xA;&lt;h1&gt;Toga&lt;/h1&gt; &#xA;&lt;p&gt;|pyversions| |license| |version| |maturity| |ci| |social|&lt;/p&gt; &#xA;&lt;p&gt;A Python native, OS native GUI toolkit.&lt;/p&gt; &#xA;&lt;h2&gt;Minimum requirements&lt;/h2&gt; &#xA;&lt;p&gt;Each backend has specific requirements and pre-requisites. See the &lt;code&gt;platform documentation &amp;lt;https://toga.readthedocs.io/en/latest/reference/platforms/&amp;gt;&lt;/code&gt;__ for details.&lt;/p&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;To get a demonstration of the capabilities of Toga, run the following::&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pip install toga-demo&#xA;$ toga-demo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will pop up a GUI window with some sample widgets.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Documentation for Toga can be found on &lt;code&gt;Read The Docs&lt;/code&gt;_.&lt;/p&gt; &#xA;&lt;p&gt;.. _Read The Docs: &lt;a href=&#34;https://toga.readthedocs.io&#34;&gt;https://toga.readthedocs.io&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Financial support&lt;/h2&gt; &#xA;&lt;p&gt;The BeeWare project would not be possible without the generous support of our financial members:&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://beeware.org/community/members/anaconda/anaconda-large.png&#34;&gt;https://beeware.org/community/members/anaconda/anaconda-large.png&lt;/a&gt; :target: &lt;a href=&#34;https://anaconda.com/&#34;&gt;https://anaconda.com/&lt;/a&gt; :alt: Anaconda logo&lt;/p&gt; &#xA;&lt;p&gt;Anaconda Inc. - Advancing AI through open source.&lt;/p&gt; &#xA;&lt;p&gt;Plus individual contributions from &lt;code&gt;users like you &amp;lt;https://beeware.org/community/members/&amp;gt;&lt;/code&gt;__. If you find Toga, or other BeeWare tools useful, please consider becoming a financial member.&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;Toga is part of the &lt;code&gt;BeeWare suite&lt;/code&gt;_. You can talk to the community through:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;@beeware@fosstodon.org on Mastodon&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Discord&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;The Toga &lt;code&gt;Github Discussions forum&lt;/code&gt;_&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We foster a welcoming and respectful community as described in our &lt;code&gt;BeeWare Community Code of Conduct&lt;/code&gt;_.&lt;/p&gt; &#xA;&lt;p&gt;.. _BeeWare suite: &lt;a href=&#34;https://beeware.org&#34;&gt;https://beeware.org&lt;/a&gt; .. _@&lt;a href=&#34;mailto:beeware@fosstodon.org&#34;&gt;beeware@fosstodon.org&lt;/a&gt; on Mastodon: &lt;a href=&#34;https://fosstodon.org/@beeware&#34;&gt;https://fosstodon.org/@beeware&lt;/a&gt; .. _Discord: &lt;a href=&#34;https://beeware.org/bee/chat/&#34;&gt;https://beeware.org/bee/chat/&lt;/a&gt; .. _Github Discussions forum: &lt;a href=&#34;https://github.com/beeware/toga/discussions&#34;&gt;https://github.com/beeware/toga/discussions&lt;/a&gt; .. _BeeWare Community Code of Conduct: &lt;a href=&#34;https://beeware.org/community/behavior/&#34;&gt;https://beeware.org/community/behavior/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;If you experience problems with Toga, &lt;code&gt;log them on GitHub &amp;lt;https://github.com/beeware/toga/issues&amp;gt;&lt;/code&gt;__.&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;d like to contribute to Toga development, our &lt;code&gt;contribution guide &amp;lt;https://toga.readthedocs.io/en/latest/how-to/contribute/index.html&amp;gt;&lt;/code&gt;__ details how to set up a development environment, and other requirements we have as part of our contribution process.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>bilibili/Index-anisora</title>
    <updated>2025-05-21T01:34:29Z</updated>
    <id>tag:github.com,2025-05-21:/bilibili/Index-anisora</id>
    <link href="https://github.com/bilibili/Index-anisora" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/index_icon.png&#34; width=&#34;250&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; üñ•Ô∏è &lt;a href=&#34;https://github.com/bilibili/Index-anisora/tree/main&#34;&gt;GitHub&lt;/a&gt; &amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ü§ó &lt;a href=&#34;https://huggingface.co/IndexTeam/Index-anisora&#34;&gt;Hugging Face&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ü§ñ &lt;a href=&#34;https://www.modelscope.cn/organization/bilibili-index&#34;&gt;Model Scope&lt;/a&gt;&amp;nbsp;&amp;nbsp; | üìë &lt;a href=&#34;http://arxiv.org/abs/2412.10255&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/ArXiv-2412.10255-red&#34;&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp; ÔΩú üìë &lt;a href=&#34;http://arxiv.org/abs/2504.10044&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/ArXiv-2504.10044-red&#34;&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;English&lt;/strong&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/README_CN.md&#34;&gt;&lt;strong&gt;‰∏≠ÊñáÁÆÄ‰Ωì&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://arxiv.org/abs/2412.10255&#34;&gt;&lt;strong&gt;Index-AniSora:The Ultimate Open-Source Anime Video Generation Model&lt;/strong&gt;&lt;/a&gt; &#xA; &lt;be&gt;&lt;/be&gt;&lt;/p&gt; &#xA;&lt;p&gt;This Project presenting Bilibili&#39;s gift to the anime world - Index-AniSora, the most powerful open-source animated video generation model. It enables one-click creation of video shots across diverse anime styles including series episodes, Chinese original animations, manga adaptations, VTuber content, anime PVs, mad-style parodies(È¨ºÁïúÂä®Áîª), and more! Powered by our IJCAI&#39;25-accepted work &lt;a href=&#34;http://arxiv.org/abs/2412.10255&#34;&gt;AniSora: Exploring the Frontiers of Animation Video Generation in the Sora Era &lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Video Demos&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;video src=&#34;https://github.com/user-attachments/assets/4351fc5e-f7fd-456b-807e-82fdcb321de2&#34; controls width=&#34;60%&#34; poster=&#34;&#34;&gt;&lt;/video&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;üì£ Updates&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;2025/05/12&lt;/code&gt; üî•üî•Everything we build is open-source. Check Out Now!!!&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;2025/05/10&lt;/code&gt; üî•Our paper is accepted by IJCAI25. Camera Ready Version is updated.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;2024/12/19&lt;/code&gt; We submitted our paper on arXiv and released our project with evaluation benchmark.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Project Guide&lt;/h2&gt; &#xA;&lt;h3&gt;AniSoraV1.0&lt;/h3&gt; &#xA;&lt;p&gt;Find in üìÅ &lt;code&gt;anisoraV1_infer&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Trained on the CogVideoX-5B foundation model, with full training and inference code released.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Localized region guidance for video control&lt;/li&gt; &#xA; &lt;li&gt;Temporal guidance (first/last frame guidance, keyframe interpolation, multi-frame guidance)&lt;/li&gt; &#xA; &lt;li&gt;Full training and inference code release. Find in üìÅ &lt;code&gt;anisoraV1_train_npu&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Cost-effective deployment on RTX 4090&lt;/li&gt; &#xA; &lt;li&gt;Covers 80% of application scenarios&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;AniSoraV2.0&lt;/h3&gt; &#xA;&lt;p&gt;Find in üìÅ &lt;code&gt;anisoraV2_gpu&lt;/code&gt;, &lt;code&gt;anisoraV2_npu&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Powered by the enhanced Wan2.1-14B foundation model for superior stability.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Distillation-accelerated inference without quality compromise, faster and cheaper&lt;/li&gt; &#xA; &lt;li&gt;Full training/inference code release&lt;/li&gt; &#xA; &lt;li&gt;Native support Huawei Ascend 910B NPUs (entirely trained on domestic chips) üìÅ &lt;code&gt;anisoraV2_npu&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;High quality video shots generation, covers 90% of application scenarios&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ecosystem Tools&lt;/h3&gt; &#xA;&lt;p&gt;Find in üìÅ &lt;code&gt;data_pipeline&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;End-to-end dataset pipeline for rapid training data expansion.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Animate data cleaning pipeline.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Anime-optimized Benchmark System&lt;/h3&gt; &#xA;&lt;p&gt;Find in üìÅ &lt;code&gt;reward&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Specialized evaluation models and scoring algorithms for anime video generation, includes reward models suitable for reinforcement learning and benchmarking.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Tailored evaluation framework for animation generation&lt;/li&gt; &#xA; &lt;li&gt;Standard test dataset aligned with ACG aesthetics&lt;/li&gt; &#xA; &lt;li&gt;Human Preference Alignment&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The benchmark dataset contains 948 animation video clips are collected and labeled with different actions. Each label contains 10-30 video clips. The corresponding text prompt is generated by Qwen-VL2 at first, then is corrected manually to guarantee the text-video alignment. Fill the form and send PDF format to &lt;a href=&#34;mailto:yangsiqian@bilibili.com&#34;&gt;yangsiqian@bilibili.com&lt;/a&gt; or &lt;a href=&#34;mailto:xubaohan@bilibili.com&#34;&gt;xubaohan@bilibili.com&lt;/a&gt; (links provided after agreeing with Bilibili)&lt;/p&gt; &#xA;&lt;h3&gt;AniSoraV1.0_RL&lt;/h3&gt; &#xA;&lt;p&gt;Find in üìÅ &lt;code&gt;anisora_rl&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;The first RLHF framework for anime video generation.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;RL-optimized AniSoraV1.0 for enhanced anime-style output&lt;/li&gt; &#xA; &lt;li&gt;Methodology detailed in our preprint: &lt;a href=&#34;http://arxiv.org/abs/2504.10044&#34;&gt; Aligning Anime Video Generation with Human Feedback &lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìë Todo List&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;AniSoraV2.0 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Support 14B version, is excepted before the end of May.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;AniSora Dataset &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;High quality training set open apply&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Anisora Benchmark &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Update latest SOTA models performance&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Provide more video demos on AniSora benchmark.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;üí° Abstract&lt;/h2&gt; &#xA;&lt;p&gt;Animation has gained significant interest in the recent film and TV industry. Despite the success of advanced video generation models like Sora, Kling, and CogVideoX in generating natural videos, they lack the same effectiveness in handling animation videos. Evaluating animation video generation is also a great challenge due to its unique artist styles, violating the laws of physics and exaggerated motions. In this paper, we present a comprehensive system, &lt;strong&gt;AniSora&lt;/strong&gt;, designed for animation video generation, which includes a data processing pipeline, a controllable generation model, and an evaluation dataset. Supported by the data processing pipeline with over 10M high-quality data, the generation model incorporates a spatiotemporal mask module to facilitate key animation production functions such as image-to-video generation, frame interpolation, and localized image-guided animation. We also collect an evaluation benchmark of 948 various animation videos, the evaluation on VBench and human double-blind test demonstrates consistency in character and motion, achieving state-of-the-art results in animation video generation.&lt;/p&gt; &#xA;&lt;h2&gt;üñ•Ô∏è Method&lt;/h2&gt; &#xA;&lt;p&gt;The overview of Index-anisora is shown as follows.&lt;/p&gt; &#xA;&lt;picture&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/framework.png&#34; width=&#34;800&#34;&gt; &#xA;&lt;/picture&gt; &#xA;&lt;p&gt;Features:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;We develop a comprehensive video processing system that significantly enhances preprocessing for video generation.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;We propose a unified framework designed for animation video generation with a spatiotemporal mask module, enabling tasks such as image-to-video generation, frame interpolation, and localized image-guided animation.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;We release a benchmark dataset specifically for evaluating animation video generation.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;üéûÔ∏è Showcases&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Image-generated videos in different artistic styles:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;prmopt&lt;/th&gt; &#xA;   &lt;th&gt;image&lt;/th&gt; &#xA;   &lt;th&gt;Video&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;The figures in the picture are sitting in a forward moving car waving to the rear, their hair swaying from side to side in the wind&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/000000(225).png&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/000000(225).gif&#34; alt=&#34;Demo&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;The scene shows two figures in red wedding clothes holding a red rope as they walk off into the distance&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/000000(223).png&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/000000(223).gif&#34; alt=&#34;Demo&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;The yellow-haired figure reaches out to touch the head of the kneeling figure, and the kneeling figure&#39;s body rises and falls as he gasps for breath.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/000000(232).png&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/000000(232).gif&#34; alt=&#34;Demo&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;In the frame, a person sprints forward at high speed, their motion appearing slightly blurred from the velocity.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/image_1.jpg&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/image_1_vid.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;In the frame, the character raises their arm, with gaseous currents visibly flowing along its surface.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/image_2.jpg&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/image_2_vid.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;The old man&#39;s gaze locks onto the gemstone, his right hand subtly adjusting the magnifying glass as his lips move‚Äîas if it holds the key to unraveling some ancient knowledge or secret.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/image_3.jpg&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/image_3_vid.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;The man on the left presses his lips tightly together, his face etched with fury and resolve. Every line of his expression radiates both profound frustration and unshakable conviction. Meanwhile, the other man&#39;s jaw hangs open‚Äîpoised as if to erupt into a shout or impassioned declaration.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/image_4.jpg&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/image_4_vid.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;The scene depicts an exploding rock, erupting in blinding light as shattered fragments blast outward in all directions.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/image_5.jpg&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/image_5_vid.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Temporal Control:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;prmopt&lt;/th&gt; &#xA;   &lt;th&gt;first frame&lt;/th&gt; &#xA;   &lt;th&gt;mid frame&lt;/th&gt; &#xA;   &lt;th&gt;last frame&lt;/th&gt; &#xA;   &lt;th&gt;Video&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;In this video we see a scene from the animated film Beauty and the Beast with Belle and the Beast. Belle, with long blonde hair, is standing in a room with large windows, looking out the window and talking to it. She is wearing a purple dress with a purple top...&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/cartoon_films_ren_wu_shuo_hua_34_firstmidlast_first.png&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/cartoon_films_ren_wu_shuo_hua_34_firstmidlast_mid.png&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/cartoon_films_ren_wu_shuo_hua_34_firstmidlast_last.png&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/cartoon_films_ren_wu_shuo_hua_34_firstmidlast.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;In this video, a young woman with long blonde hair can be seen looking out from behind a car door at night. The car is parked under a starry sky with a full moon illuminating the scene. The woman appears to be in a state of worry, as evidenced by her facial expression and the way she grips the car door.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/motion_comics_tui_la_5_firstlast_first.png&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/motion_comics_tui_la_5_firstlast_last.jpeg&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/motion_comics_tui_la_5_firstlast.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;A cartoon cat is the central figure in this video, which appears to be in a state of mischief or curiosity. The cat&#39;s eyes are closed and its mouth is open, suggesting a moment of surprise or anticipation...&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/motion_comics_zhi_dong_xi_2_last.jpeg&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/motion_comics_zhi_dong_xi_2_last.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Spatial Control:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;prmopt&lt;/th&gt; &#xA;   &lt;th&gt;first frame&lt;/th&gt; &#xA;   &lt;th&gt;motion mask&lt;/th&gt; &#xA;   &lt;th&gt;Video(with motion mask visualization)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;In this vibrant underwater scene from the animated film Finding Nemo, Marlin and Nemo, two clownfish, talk near a large purple piece of coral...&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/132.png&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/132_mask.png&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/132.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Same as above&lt;/td&gt; &#xA;   &lt;td&gt;Same as above&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/133_mask.png&#34; width=&#34;800&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/133.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;font-size:18px;&#34;&gt; More videos are available in: &lt;a href=&#34;https://pwz4yo5eenw.feishu.cn/docx/XN9YdiOwCoqJuexLdCpcakSlnkg&#34;&gt;Video Gallery AniSoraV1.0&lt;/a&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üìë Evaluation&lt;/h2&gt; &#xA;&lt;p&gt;Evaluation results on Vbench:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Motion Smoothness&lt;/th&gt; &#xA;   &lt;th&gt;Motion Score&lt;/th&gt; &#xA;   &lt;th&gt;Aesthetic Quality&lt;/th&gt; &#xA;   &lt;th&gt;Imaging Quality&lt;/th&gt; &#xA;   &lt;th&gt;I2V Subject&lt;/th&gt; &#xA;   &lt;th&gt;I2V Background&lt;/th&gt; &#xA;   &lt;th&gt;Overall Consistency&lt;/th&gt; &#xA;   &lt;th&gt;Subject Consistency&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Opensora-Plan(V1.3)&lt;/td&gt; &#xA;   &lt;td&gt;99.13&lt;/td&gt; &#xA;   &lt;td&gt;76.45&lt;/td&gt; &#xA;   &lt;td&gt;53.21&lt;/td&gt; &#xA;   &lt;td&gt;65.11&lt;/td&gt; &#xA;   &lt;td&gt;93.53&lt;/td&gt; &#xA;   &lt;td&gt;94.71&lt;/td&gt; &#xA;   &lt;td&gt;21.67&lt;/td&gt; &#xA;   &lt;td&gt;88.86&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Opensora(V1.2)&lt;/td&gt; &#xA;   &lt;td&gt;98.78&lt;/td&gt; &#xA;   &lt;td&gt;73.62&lt;/td&gt; &#xA;   &lt;td&gt;54.30&lt;/td&gt; &#xA;   &lt;td&gt;68.44&lt;/td&gt; &#xA;   &lt;td&gt;93.15&lt;/td&gt; &#xA;   &lt;td&gt;91.09&lt;/td&gt; &#xA;   &lt;td&gt;22.68&lt;/td&gt; &#xA;   &lt;td&gt;87.71&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vidu&lt;/td&gt; &#xA;   &lt;td&gt;97.71&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;77.51&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;53.68&lt;/td&gt; &#xA;   &lt;td&gt;69.23&lt;/td&gt; &#xA;   &lt;td&gt;92.25&lt;/td&gt; &#xA;   &lt;td&gt;93.06&lt;/td&gt; &#xA;   &lt;td&gt;20.87&lt;/td&gt; &#xA;   &lt;td&gt;88.27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Covideo(5B-V1)&lt;/td&gt; &#xA;   &lt;td&gt;97.67&lt;/td&gt; &#xA;   &lt;td&gt;71.47&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;54.87&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;68.16&lt;/td&gt; &#xA;   &lt;td&gt;90.68&lt;/td&gt; &#xA;   &lt;td&gt;91.79&lt;/td&gt; &#xA;   &lt;td&gt;21.87&lt;/td&gt; &#xA;   &lt;td&gt;90.29&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MiniMax&lt;/td&gt; &#xA;   &lt;td&gt;99.20&lt;/td&gt; &#xA;   &lt;td&gt;66.53&lt;/td&gt; &#xA;   &lt;td&gt;54.56&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;71.67&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;95.95&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;95.42&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;21.82&lt;/td&gt; &#xA;   &lt;td&gt;93.62&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;AniSora&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;99.34&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;45.59&lt;/td&gt; &#xA;   &lt;td&gt;54.31&lt;/td&gt; &#xA;   &lt;td&gt;70.58&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;97.52&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;95.04&lt;/td&gt; &#xA;   &lt;td&gt;21.15&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;96.99&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AniSora-K&lt;/td&gt; &#xA;   &lt;td&gt;99.12&lt;/td&gt; &#xA;   &lt;td&gt;59.49&lt;/td&gt; &#xA;   &lt;td&gt;53.76&lt;/td&gt; &#xA;   &lt;td&gt;68.68&lt;/td&gt; &#xA;   &lt;td&gt;95.13&lt;/td&gt; &#xA;   &lt;td&gt;93.36&lt;/td&gt; &#xA;   &lt;td&gt;21.13&lt;/td&gt; &#xA;   &lt;td&gt;94.61&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AniSora-I&lt;/td&gt; &#xA;   &lt;td&gt;99.31&lt;/td&gt; &#xA;   &lt;td&gt;54.96&lt;/td&gt; &#xA;   &lt;td&gt;54.67&lt;/td&gt; &#xA;   &lt;td&gt;68.98&lt;/td&gt; &#xA;   &lt;td&gt;94.16&lt;/td&gt; &#xA;   &lt;td&gt;92.38&lt;/td&gt; &#xA;   &lt;td&gt;20.47&lt;/td&gt; &#xA;   &lt;td&gt;95.75&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GT&lt;/td&gt; &#xA;   &lt;td&gt;98.72&lt;/td&gt; &#xA;   &lt;td&gt;56.05&lt;/td&gt; &#xA;   &lt;td&gt;52.70&lt;/td&gt; &#xA;   &lt;td&gt;70.50&lt;/td&gt; &#xA;   &lt;td&gt;96.02&lt;/td&gt; &#xA;   &lt;td&gt;95.03&lt;/td&gt; &#xA;   &lt;td&gt;21.29&lt;/td&gt; &#xA;   &lt;td&gt;94.37&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Evaluation results on AniSora-Benchmark:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Human Evaluation&lt;/th&gt; &#xA;   &lt;th&gt;Visual Smooth&lt;/th&gt; &#xA;   &lt;th&gt;Visual Motion&lt;/th&gt; &#xA;   &lt;th&gt;Visual Appeal&lt;/th&gt; &#xA;   &lt;th&gt;Text-Video Consistency&lt;/th&gt; &#xA;   &lt;th&gt;Image-Video Consistency&lt;/th&gt; &#xA;   &lt;th&gt;Character Consistency&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vidu-1.5&lt;/td&gt; &#xA;   &lt;td&gt;60.98&lt;/td&gt; &#xA;   &lt;td&gt;55.37&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;78.95&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;50.68&lt;/td&gt; &#xA;   &lt;td&gt;60.71&lt;/td&gt; &#xA;   &lt;td&gt;66.85&lt;/td&gt; &#xA;   &lt;td&gt;82.57&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Opensora-V1.2&lt;/td&gt; &#xA;   &lt;td&gt;41.10&lt;/td&gt; &#xA;   &lt;td&gt;22.28&lt;/td&gt; &#xA;   &lt;td&gt;74.90&lt;/td&gt; &#xA;   &lt;td&gt;22.62&lt;/td&gt; &#xA;   &lt;td&gt;52.19&lt;/td&gt; &#xA;   &lt;td&gt;55.67&lt;/td&gt; &#xA;   &lt;td&gt;74.76&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Opensora-Plan-V1.3&lt;/td&gt; &#xA;   &lt;td&gt;46.14&lt;/td&gt; &#xA;   &lt;td&gt;35.08&lt;/td&gt; &#xA;   &lt;td&gt;77.47&lt;/td&gt; &#xA;   &lt;td&gt;36.14&lt;/td&gt; &#xA;   &lt;td&gt;56.19&lt;/td&gt; &#xA;   &lt;td&gt;59.42&lt;/td&gt; &#xA;   &lt;td&gt;81.19&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CogVideoX-5B-V1&lt;/td&gt; &#xA;   &lt;td&gt;53.29&lt;/td&gt; &#xA;   &lt;td&gt;39.91&lt;/td&gt; &#xA;   &lt;td&gt;73.07&lt;/td&gt; &#xA;   &lt;td&gt;39.59&lt;/td&gt; &#xA;   &lt;td&gt;67.98&lt;/td&gt; &#xA;   &lt;td&gt;65.49&lt;/td&gt; &#xA;   &lt;td&gt;83.07&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MiniMax-I2V01&lt;/td&gt; &#xA;   &lt;td&gt;69.63&lt;/td&gt; &#xA;   &lt;td&gt;69.38&lt;/td&gt; &#xA;   &lt;td&gt;68.05&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;70.34&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;76.14&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;78.74&lt;/td&gt; &#xA;   &lt;td&gt;89.47&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;AniSora (Ours)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;70.13&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;71.47&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;47.94&lt;/td&gt; &#xA;   &lt;td&gt;64.44&lt;/td&gt; &#xA;   &lt;td&gt;72.92&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;81.54&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;94.54&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AniSora (Interpolated Avg)&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;70.78&lt;/td&gt; &#xA;   &lt;td&gt;53.02&lt;/td&gt; &#xA;   &lt;td&gt;64.41&lt;/td&gt; &#xA;   &lt;td&gt;73.56&lt;/td&gt; &#xA;   &lt;td&gt;80.62&lt;/td&gt; &#xA;   &lt;td&gt;91.59&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AniSora (KeyFrame Interp)&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;70.03&lt;/td&gt; &#xA;   &lt;td&gt;58.10&lt;/td&gt; &#xA;   &lt;td&gt;64.57&lt;/td&gt; &#xA;   &lt;td&gt;74.57&lt;/td&gt; &#xA;   &lt;td&gt;80.78&lt;/td&gt; &#xA;   &lt;td&gt;91.98&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AniSora (KeyFrame Interp)&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;70.03&lt;/td&gt; &#xA;   &lt;td&gt;58.10&lt;/td&gt; &#xA;   &lt;td&gt;64.57&lt;/td&gt; &#xA;   &lt;td&gt;74.57&lt;/td&gt; &#xA;   &lt;td&gt;80.78&lt;/td&gt; &#xA;   &lt;td&gt;91.98&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GT&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;92.20&lt;/td&gt; &#xA;   &lt;td&gt;58.27&lt;/td&gt; &#xA;   &lt;td&gt;89.72&lt;/td&gt; &#xA;   &lt;td&gt;92.51&lt;/td&gt; &#xA;   &lt;td&gt;94.69&lt;/td&gt; &#xA;   &lt;td&gt;95.08&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;AniSora for our I2V results.&lt;/p&gt; &#xA;&lt;p&gt;AniSora-K for the key frame interpolation results.&lt;/p&gt; &#xA;&lt;p&gt;AniSora-I for the average results of frame interpolation conditions, including key frame, last frame, mid frame results.&lt;/p&gt; &#xA;&lt;h2&gt;üê≥ Benchmark Dataset&lt;/h2&gt; &#xA;&lt;p&gt;The benchmark dataset contains 948 animation video clips are collected and labeled with different actions. Each label contains 10-30 video clips. The corresponding text prompt is generated by Qwen-VL2 at first, then is corrected manually to guarantee the text-video alignment.&lt;/p&gt; &#xA;&lt;p&gt;Fill the &lt;a href=&#34;https://raw.githubusercontent.com/bilibili/Index-anisora/main/assets/anisora_benchmark_agreement_form.doc&#34;&gt;form&lt;/a&gt; and send PDF format to &lt;a href=&#34;mailto:yangsiqian@bilibili.com&#34;&gt;yangsiqian@bilibili.com&lt;/a&gt; or &lt;a href=&#34;mailto:xubaohan@bilibili.com&#34;&gt;xubaohan@bilibili.com&lt;/a&gt; (links provided after agreeing with Bilibili)&lt;/p&gt; &#xA;&lt;h2&gt;ü§ó Acknowledgments&lt;/h2&gt; &#xA;&lt;p&gt;We would like to express our sincere thanks to the &lt;a href=&#34;https://github.com/THUDM/CogVideo&#34;&gt;CogVideoX&lt;/a&gt;„ÄÅ&lt;a href=&#34;https://github.com/Wan-Video/Wan2.1&#34;&gt;Wan2.1&lt;/a&gt;„ÄÅ&lt;a href=&#34;https://github.com/Vchitect/FasterCache&#34;&gt;FasterCache&lt;/a&gt; and &lt;a href=&#34;https://github.com/bebebe666/OptimalSteps&#34;&gt;OSS&lt;/a&gt; for their valuable work.&lt;/p&gt; &#xA;&lt;h2&gt;üìö Citation&lt;/h2&gt; &#xA;&lt;p&gt;üåü If you find our work helpful, please leave us a star and cite our paper.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{jiang2024anisora,&#xA;  title={AniSora: Exploring the Frontiers of Animation Video Generation in the Sora Era},&#xA;  author={Yudong Jiang, Baohan Xu, Siqian Yang, Mingyu Yin, Jing Liu, Chao Xu, Siqi Wang, Yidi Wu, Bingwen Zhu, Xinwen Zhang, Xingyu Zheng,Jixuan Xu, Yue Zhang, Jinlong Hou and Huyang Sun},&#xA;  journal={arXiv preprint arXiv:2412.10255},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>