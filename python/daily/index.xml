<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-25T01:42:15Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>CHNZYX/CentOS-LLVM-Fork</title>
    <updated>2023-05-25T01:42:15Z</updated>
    <id>tag:github.com,2023-05-25:/CHNZYX/CentOS-LLVM-Fork</id>
    <link href="https://github.com/CHNZYX/CentOS-LLVM-Fork" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;ÊÄé‰πàÂÜôÂïäÔºå‰∏ç‰ºöÂïäQAQ&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>kyegomez/tree-of-thoughts</title>
    <updated>2023-05-25T01:42:15Z</updated>
    <id>tag:github.com,2023-05-25:/kyegomez/tree-of-thoughts</id>
    <link href="https://github.com/kyegomez/tree-of-thoughts" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Plug in and Play Implementation of Tree of Thoughts: Deliberate Problem Solving with Large Language Models that Elevates Model Reasoning by atleast 70%&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tree of Thoughts üå≥üå≤üå¥üåøüçÉ&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kyegomez/tree-of-thoughts/main/tree-of-thoughts.jpeg&#34; alt=&#34;tree of thoughts banner&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2305.10601.pdf&#34;&gt;Paper link&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Tree of Thoughts (ToT) is an all-new powerful and flexible algorithm that advances model reasoning by a whopping 70%. This is an plug in and play verision, connect your own models and enjoy superintelligence!&lt;/p&gt; &#xA;&lt;p&gt;Share this repository by clicking on the following buttons üòä&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/intent/tweet?text=Check%20out%20this%20amazing%20project%20on%20improving%20AI%20reasoning%20-%20Tree%20of%20Thoughts!%20https://github.com/kyegomez/tree-of-thoughts&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url?style=social&amp;amp;url=https%3A%2F%2Fgithub.com%2Fkyegomez%2Ftree-of-thoughts&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fgithub.com%2Fkyegomez%2Ftree-of-thoughts&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Share-LinkedIn-blue?style=social&amp;amp;logo=linkedin&#34; alt=&#34;LinkedIn&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Join Agora, Creators United&lt;/h1&gt; &#xA;&lt;p&gt;This implementation of Tree of Thoughts is brought to you by Agora, Agora advances Humanity with open source SOTA Multi-Modality AI research! We plan on combating Humanity&#39;s grandest root problems like food insecurity, planetary insecurity, and disease, and hopefully death itself.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/qUtxnK2NMf&#34;&gt;Join our Discord and contribute to this project&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;p&gt;Clone this repository with &lt;code&gt;git clone https://github.com/kyegomez/tree-of-thoughts&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;or:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;pip install tree-of-thoughts &lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Navigate to the repository folder: &lt;code&gt; cd tree-of-thoughts&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;pip install openai&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Create a Python script (e.g., example.py) and import the necessary classes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from tree_of_thoughts.treeofthoughts import OpenAILanguageModel, CustomLanguageModel, TreeofThoughts, OptimizedOpenAILanguageModel, OptimizedTreeofThoughts&#xA;&#xA;use_v2 = False&#xA;api_key=&#34;&#34;&#xA;api_base= &#34;&#34; # leave it blank if you simply use default openai api url&#xA;&#xA;if not use_v2:&#xA;    #v1&#xA;    model = OpenAILanguageModel(api_key=api_key, api_base=api_base # api_model=&#34;gpt4&#34; # for higher performance base model is not smart&#xA;    ) &#xA;else:&#xA;    #v2 parallel execution, caching, adaptive temperature&#xA;    model = OptimizedOpenAILanguageModel(api_key=api_key, api_base=api_base, # api_model=&#34;gpt4&#34; # for higher performance base model is not smart&#xA;    )&#xA;&#xA;#choose search algorithm(&#39;BFS&#39; or &#39;DFS&#39;)&#xA;search_algorithm = &#34;BFS&#34;&#xA;&#xA;#cot or propose&#xA;strategy=&#34;cot&#34;&#xA;&#xA;# value or vote&#xA;evaluation_strategy = &#34;value&#34;&#xA;&#xA;if not use_v2:&#xA;    #create an instance of the tree of thoughts class v1&#xA;    tree_of_thoughts = TreeofThoughts(model, search_algorithm)&#xA;else:&#xA;    #or v2 -&amp;gt; dynamic beam width -&amp;lt; adjust the beam width [b] dynamically based on the search depth quality of the generated thoughts&#xA;    tree_of_thoughts= OptimizedTreeofThoughts(model, search_algorithm)&#xA;&#xA;input_problem = &#34;use 4 numbers and basic arithmetic operations (+-*/) to obtain 24&#34;&#xA;    &#xA;k = 5&#xA;T = 3&#xA;b = 5&#xA;vth = 0.5&#xA;timeout = 10&#xA;confidence = 1.0 #cmodel is confident on performance&#xA;max_iterations = 40 #tree branh nodes &#xA;convergence_threshold = 0.01&#xA;convergence_count = 5&#xA;&#xA;&#xA;&#xA;&#xA;solution = tree_of_thoughts.solve(input_problem, k, T, b, vth, timeout, confidence_threshold=confidence, max_iterations=max_iterations, convergence_threshold=convergence_threshold, convergence_count=convergence_count)&#xA;    &#xA;&#xA;#use the solution in your production environment&#xA;print(f&#39;solution {solution}&#39;)&#xA;&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or Integrate your own custom language model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#xA;class CustomLanguageModel(AbstractLanguageModel):&#xA;    def __init__(self, model):&#xA;        self.model = model&#xA;&#xA;    def generate_thoughts(self, state, k):&#xA;        #implement the thought generation logic using self.model&#xA;        pass&#xA;&#xA;    def evaluate_states(self, states):&#xA;        #implement state evaluation logic using self.model&#xA;        pass&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the example script&lt;/p&gt; &#xA;&lt;h2&gt;üåü Features:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;General problem-solving framework for language models&lt;/li&gt; &#xA; &lt;li&gt;Supports both breadth-first search (BFS) and depth-first search (DFS) algorithms&lt;/li&gt; &#xA; &lt;li&gt;Easy integration with popular language models like OpenAI and Hugging Face&lt;/li&gt; &#xA; &lt;li&gt;Extensible and adaptable to different problem properties and resource constraints&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Algorithmic Pseudocode&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Define the thought decomposition based on the problem properties.&lt;/li&gt; &#xA; &lt;li&gt;Create a thought generator function G(pŒ∏, s, k) with two strategies: a. Sample i.i.d. thoughts from a CoT prompt. b. Propose thoughts sequentially using a &#34;propose prompt&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Create a state evaluator function V(pŒ∏, S) with two strategies: a. Value each state independently. b. Vote across states.&lt;/li&gt; &#xA; &lt;li&gt;Choose a search algorithm (BFS or DFS) based on the tree structure.&lt;/li&gt; &#xA; &lt;li&gt;Implement the chosen search algorithm.&lt;/li&gt; &#xA; &lt;li&gt;Execute the chosen search algorithm with the input problem, thought generator, state evaluator, and other required parameters.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Tree of Thoughts Class&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class TreeofThoughts:&#xA;    &#xA;    def __init__(self, model, search_algorithm):&#xA;        self.model = model&#xA;        self.search_algorithm = search_algorithm&#xA;&#xA;    def solve(self, x, k, T, b, vth):&#xA;        if self.search_algorithm == &#39;BFS&#39;:&#xA;            return self.tot_bfs(x, k, T, b)&#xA;        elif self.search_algorithm == &#39;DFS&#39;:&#xA;            return self.tot_dfs(x, k, T, vth)&#xA;        else:&#xA;            raise ValueError(&#34;Invalid search algorithm. Choose &#39;BFS&#39; or &#39;DFS&#39;.&#34;)&#xA;&#xA;    def tot_bfs(self, x, k, T, b):&#xA;        S0 = {x}&#xA;        for t in range(1, T + 1):&#xA;            S0_t = {(*s, z) for s in S0 for z in self.model.generate_thoughts(s, k)}&#xA;            Vt = self.model.evaluate_states(S0_t)&#xA;            St = sorted(S0_t, key=lambda s: Vt[s], reverse=True)[:b]&#xA;            S0 = set(St)&#xA;        return self.model.generate_thoughts(max(St, key=lambda s: Vt[s]), 1)&#xA;&#xA;    def tot_dfs(self, x, k, T, vth):&#xA;        output = []&#xA;&#xA;        def dfs(s, t):&#xA;            if t &amp;gt; T:&#xA;                output.append(self.model.generate_thoughts(s, 1))&#xA;                return&#xA;            for s_prime in sorted(self.model.generate_thoughts(s, k)):&#xA;                if self.model.evaluate_states({s_prime})[s_prime] &amp;gt; vth:&#xA;                    dfs((*s, s_prime), t + 1)&#xA;&#xA;        dfs(x, 1)&#xA;        return output&#xA;    &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage Examples&lt;/h2&gt; &#xA;&lt;h3&gt;OpenAI API&lt;/h3&gt; &#xA;&lt;p&gt;To use Tree of Thoughts with OpenAI&#39;s API, create a custom model class that inherits from &lt;code&gt;AbstractLanguageModel&lt;/code&gt; and implements the required methods using OpenAI&#39;s API. Then, create an instance of the &lt;code&gt;TreeOfThoughts&lt;/code&gt; class with the custom model and the desired search algorithm (&#39;BFS&#39; or &#39;DFS&#39;).&lt;/p&gt; &#xA;&lt;h3&gt;Hugging Face Transformers&lt;/h3&gt; &#xA;&lt;p&gt;To use Tree of Thoughts with Hugging Face Transformers, create a custom model class that inherits from &lt;code&gt;AbstractLanguageModel&lt;/code&gt; and implements the required methods using Hugging Face Transformers. Then, create an instance of the &lt;code&gt;TreeOfThoughts&lt;/code&gt; class with the custom model and the desired search algorithm (&#39;BFS&#39; or &#39;DFS&#39;).&lt;/p&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;This algorithm is still infant yet it&#39;s potential remains unimaginable, let&#39;s advance the reasoning of AI&#39;s together under this banner.&lt;/p&gt; &#xA;&lt;h1&gt;Share With Your Network&lt;/h1&gt; &#xA;&lt;p&gt;You can easily share this repository by clicking on the following buttons:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/intent/tweet?text=Check%20out%20this%20amazing%20project%20on%20improving%20AI%20reasoning%20-%20Tree%20of%20Thoughts!%20https://github.com/kyegomez/tree-of-thoughts&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url?style=social&amp;amp;url=https%3A%2F%2Fgithub.com%2Fkyegomez%2Ftree-of-thoughts&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fgithub.com%2Fkyegomez%2Ftree-of-thoughts&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Share-LinkedIn-blue?style=social&amp;amp;logo=linkedin&#34; alt=&#34;LinkedIn&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;For Instagram, while it doesn&#39;t directly support sharing of web links, you can share the screenshot of our project and the link in your caption or bio. You can download the project screenshot by clicking the image below:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/kyegomez/tree-of-thoughts/raw/main/tree-of-thoughts.jpeg&#34;&gt;&lt;img src=&#34;https://github.com/kyegomez/tree-of-thoughts/raw/main/tree-of-thoughts.jpeg&#34; alt=&#34;Tree of Thoughts&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;We greatly appreciate any help in spreading the word about our project. Thank you for your support!&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;p&gt;now: Generate suite of evaluations used in the paper testing AI agents with other reasoning methods like COT and self consistency and run them in parallel to conduct evaluation experiments.&lt;/p&gt; &#xA;&lt;p&gt;Implement a more sophisticated prompt engineering strategy to guide the model&#39;s reasoning process more effectively.&lt;/p&gt; &#xA;&lt;p&gt;Make TreeofThoughts class completely customizable with a config yml file with params like chatbot: type: &#34;openai&#34; max_context_length: 8000 include_chat_history_in_query: false openai: model: &amp;lt;model_name&amp;gt; api_key: &amp;lt;your_open_ai_api_key&amp;gt;&lt;/p&gt; &#xA;&lt;p&gt;Script that generates an dataset based on a topic input, -&amp;gt; set of questions are asked, then multiple trees of thoughts are run concurrently to generate the decision making rich dataset&lt;/p&gt; &#xA;&lt;p&gt;Introduce a reinforcement learning, distillment, and finetuning scripts to finely tune the model based on feedback from the Tree of Thoughts algorithm.&lt;/p&gt; &#xA;&lt;p&gt;Integrate heuristics that autonomously determine the search algorithm based on indicators&lt;/p&gt; &#xA;&lt;p&gt;Integrate heuristics that autonomously determine the strategy cos or propose&lt;/p&gt; &#xA;&lt;p&gt;Integrate heuristics that autonomously set the input params:&lt;/p&gt; &#xA;&lt;p&gt;k = T = b = vth =&lt;/p&gt; &#xA;&lt;p&gt;multi-modality tree of thoughts&lt;/p&gt; &#xA;&lt;p&gt;multi-modality forest of thoughts&lt;/p&gt; &#xA;&lt;p&gt;multi-modality world of thoughts&lt;/p&gt; &#xA;&lt;h3&gt;Multi-Modality Tree of Thoughts üåêüå≥&lt;/h3&gt; &#xA;&lt;p&gt;The next big advancement for the Tree of Thoughts algorithm is to extend it to multi-modality, enabling it to handle not only text but also images, audio, and other data types. This will bring us closer to multi-modal superintelligence.&lt;/p&gt; &#xA;&lt;h4&gt;Actionable Steps&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Research and identify suitable multi-modal pre-trained models that can handle various data types (e.g., text, images, audio).&lt;/li&gt; &#xA; &lt;li&gt;Adapt the thought decomposition, thought generator, and state evaluator functions to handle multi-modal data.&lt;/li&gt; &#xA; &lt;li&gt;Develop a method for combining different modalities in the search tree, allowing the algorithm to reason across different data types.&lt;/li&gt; &#xA; &lt;li&gt;Implement and test the multi-modal Tree of Thoughts algorithm with various problems and datasets.&lt;/li&gt; &#xA; &lt;li&gt;Optimize the algorithm for performance and resource usage, ensuring it scales well with large multi-modal datasets.&lt;/li&gt; &#xA; &lt;li&gt;Publish the results and gather feedback from the community to further improve the multi-modal Tree of Thoughts algorithm.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Join us on this exciting journey to advance the Tree of Thoughts algorithm to multi-modality superintelligence! üöÄ&lt;/p&gt; &#xA;&lt;h1&gt;The Compiler&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/kyegomez/the-compiler&#34;&gt;Utilizing Tree of Thoughts for optimal program synthesis&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/kyegomez/the-compiler/raw/main/the-compiler.png&#34; alt=&#34;the compiler banner&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Welcome to &lt;em&gt;The Compiler&lt;/em&gt;, a novel child project under the Tree of Thoughts (ToT) paradigm. This project is crafted with the intent of making autonomous programming not just a reality, but an effortless task for you.&lt;/p&gt; &#xA;&lt;p&gt;In essence, &lt;em&gt;The Compiler&lt;/em&gt; allows you to &#34;grow&#34; any program you can dream of. By providing a high-level specification of the product you would like, you can sit back and let &lt;em&gt;The Compiler&lt;/em&gt; do the heavy lifting.&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;The Compiler&lt;/em&gt; leverages the ToT framework and large language models (LLMs) to handle the programming process, from abstract specifications to a working program.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s a basic breakdown of the workflow:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Input&lt;/strong&gt;: You provide an abstract specification for the product you would like.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Unit Tests Generation&lt;/strong&gt;: We use an LLM on ToT to produce a suite of unit tests for the code.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Run ToT&lt;/strong&gt;: We run the Tree of Thoughts LLM on the given specification, using the generated unit tests as the evaluation score.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Output&lt;/strong&gt;: Ready to use program!&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Architecture&lt;/h2&gt; &#xA;&lt;p&gt;The Compiler, leveraging the Tree of Thoughts paradigm, consists of several primary components, including the Specification Parser, Thought Decomposer, Thought Generator, State Evaluator, and the Search Algorithm.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Specification Parser&lt;/strong&gt;: This interprets your high-level input specifications and translates them into a format that the Thought Decomposer can understand and work with.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Thought Decomposer&lt;/strong&gt;: This component breaks down the programming problem into manageable &#34;thoughts&#34; or steps.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Thought Generator&lt;/strong&gt;: It generates potential thoughts or steps from the current state using two strategies, either sampling thoughts independently or proposing thoughts sequentially.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;State Evaluator&lt;/strong&gt;: It evaluates the progress of different states towards solving the programming problem, acting as a heuristic for the Search Algorithm.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Search Algorithm&lt;/strong&gt;: This module determines which states to keep exploring and in which order. It employs either Breadth-First Search (BFS) or Depth-First Search (DFS), depending on the nature of the problem.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Share The Compiler&lt;/h2&gt; &#xA;&lt;p&gt;If you find this project exciting and think others might benefit from it, feel free to share it. Use the buttons below to share it on various social media platforms:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://twitter.com/share?text=Check%20out%20The%20Compiler%20project%20on%20GitHub!%20It%20allows%20you%20to%20autonomously%20create%20programs%20using%20abstract%20specifications.&amp;amp;url=https://github.com/kyegomez/the-compiler&#34;&gt;Share on Twitter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.linkedin.com/shareArticle?mini=true&amp;amp;url=https://github.com/kyegomez/the-compiler&amp;amp;title=The%20Compiler%20Project&amp;amp;summary=This%20project%20is%20a%20revolution%20in%20autonomous%20programming!%20Check%20it%20out%20on%20GitHub.&#34;&gt;Share on LinkedIn&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.facebook.com/sharer.php?u=https://github.com/kyegomez/the-compiler&#34;&gt;Share on Facebook&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Let&#39;s revolutionize the world of programming together with &lt;em&gt;The Compiler&lt;/em&gt;!&lt;/p&gt; &#xA;&lt;h1&gt;Acknowledgements&lt;/h1&gt; &#xA;&lt;p&gt;Thanks to: Shunyu Yao Princeton University, Dian Yu Google DeepMind, Jeffrey Zhao, Google DeepMind, Izhak Shafran Google DeepMind, Thomas L. Griffiths, Princeton University, Yuan Cao Google DeepMind, Karthik Narasimha, Princeton University for sharing this amazing work with the world!&lt;/p&gt; &#xA;&lt;p&gt;And, thanks to Phil Wang or Lucidrains for inspiring me to devote myself to open source AI Research&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/i-Code</title>
    <updated>2023-05-25T01:42:15Z</updated>
    <id>tag:github.com,2023-05-25:/microsoft/i-Code</id>
    <link href="https://github.com/microsoft/i-Code" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Project i-Code&lt;/h1&gt; &#xA;&lt;p&gt;The ambition of the i-Code project is to build integrative and composable multimodal Artificial Intelligence. The &#34;i&#34; stands for integrative multimodal learning.&lt;/p&gt; &#xA;&lt;h2&gt;Multimodal Foundation Models&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/i-Code/tree/main/i-Code-V1&#34;&gt;i-Code V1&lt;/a&gt;: i-Code: An Integrative and Composable Multimodal Learning Framework. AAAI 2023, &lt;a href=&#34;https://arxiv.org/abs/2205.01818&#34;&gt;paper link&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/i-Code/tree/main/i-Code-V2&#34;&gt;i-Code V2&lt;/a&gt;: i-Code V2: An Autoregressive Generation Framework over Vision, Language, and Speech Data. &lt;a href=&#34;https://arxiv.org/abs/2305.12311&#34;&gt;Paper link&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/i-Code/tree/main/i-Code-V3&#34;&gt;i-Code V3 (CoDi)&lt;/a&gt;: Any-to-Any Generation via Composable Diffusion, &lt;a href=&#34;https://arxiv.org/abs/2305.11846&#34;&gt;paper link&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/i-Code/tree/main/i-Code-Studio&#34;&gt;i-Code Studio&lt;/a&gt;: A Configurable and Composable Framework for Integrative AI, &lt;a href=&#34;https://arxiv.org/abs/2305.13738&#34;&gt;paper link&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Multimodal Document Intelligence&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/i-Code/tree/main/i-Code-Doc&#34;&gt;i-Code Doc (UDOP)&lt;/a&gt;: Unifying Vision, Text, and Layout for Universal Document Processing. CVPR 2023 Highlight, &lt;a href=&#34;https://arxiv.org/abs/2212.02623&#34;&gt;paper link&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&#34;https://cla.opensource.microsoft.com&#34;&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h2&gt;Trademarks&lt;/h2&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt;</summary>
  </entry>
</feed>