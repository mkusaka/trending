<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-10-21T01:33:31Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>spesmilo/electrum</title>
    <updated>2024-10-21T01:33:31Z</updated>
    <id>tag:github.com,2024-10-21:/spesmilo/electrum</id>
    <link href="https://github.com/spesmilo/electrum" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Electrum Bitcoin Wallet&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Electrum - Lightweight Bitcoin client&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;Licence: MIT Licence&#xA;Author: Thomas Voegtlin&#xA;Language: Python (&amp;gt;= 3.8)&#xA;Homepage: https://electrum.org/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cirrus-ci.com/github/spesmilo/electrum&#34;&gt;&lt;img src=&#34;https://api.cirrus-ci.com/github/spesmilo/electrum.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://coveralls.io/github/spesmilo/electrum?branch=master&#34;&gt;&lt;img src=&#34;https://coveralls.io/repos/github/spesmilo/electrum/badge.svg?branch=master&#34; alt=&#34;Test coverage statistics&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://crowdin.com/project/electrum&#34;&gt;&lt;img src=&#34;https://d322cqt584bo4o.cloudfront.net/electrum/localized.svg?sanitize=true&#34; alt=&#34;Help translate Electrum online&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;(If you&#39;ve come here looking to simply run Electrum, &lt;a href=&#34;https://electrum.org/#download&#34;&gt;you may download it here&lt;/a&gt;.)&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Electrum itself is pure Python, and so are most of the required dependencies, but not everything. The following sections describe how to run from source, but here is a TL;DR:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get install libsecp256k1-dev&#xA;$ ELECTRUM_ECC_DONT_COMPILE=1 python3 -m pip install --user &#34;.[gui,crypto]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Not pure-python dependencies&lt;/h3&gt; &#xA;&lt;h4&gt;Qt GUI&lt;/h4&gt; &#xA;&lt;p&gt;If you want to use the Qt interface, install the Qt dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get install python3-pyqt6&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;libsecp256k1&lt;/h4&gt; &#xA;&lt;p&gt;For elliptic curve operations, &lt;a href=&#34;https://github.com/bitcoin-core/secp256k1&#34;&gt;libsecp256k1&lt;/a&gt; is a required dependency.&lt;/p&gt; &#xA;&lt;p&gt;If you &#34;pip install&#34; Electrum, by default libsecp will get compiled locally, as part of the &lt;code&gt;electrum-ecc&lt;/code&gt; dependency. This can be opted-out of, by setting the &lt;code&gt;ELECTRUM_ECC_DONT_COMPILE=1&lt;/code&gt; environment variable. For the compilation to work, besides a C compiler, you need at least:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get install automake libtool&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you opt out of the compilation, you need to provide libsecp in another way, e.g.:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get install libsecp256k1-dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;cryptography&lt;/h4&gt; &#xA;&lt;p&gt;Due to the need for fast symmetric ciphers, &lt;a href=&#34;https://github.com/pyca/cryptography&#34;&gt;cryptography&lt;/a&gt; is required. Install from your package manager (or from pip):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get install python3-cryptography&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;hardware-wallet support&lt;/h4&gt; &#xA;&lt;p&gt;If you would like hardware wallet support, &lt;a href=&#34;https://github.com/spesmilo/electrum-docs/raw/master/hardware-linux.rst&#34;&gt;see this&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Running from tar.gz&lt;/h3&gt; &#xA;&lt;p&gt;If you downloaded the official package (tar.gz), you can run Electrum from its root directory without installing it on your system; all the pure python dependencies are included in the &#39;packages&#39; directory. To run Electrum from its root directory, just do:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./run_electrum&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also install Electrum on your system, by running this command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get install python3-setuptools python3-pip&#xA;$ python3 -m pip install --user .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will download and install the Python dependencies used by Electrum instead of using the &#39;packages&#39; directory. It will also place an executable named &lt;code&gt;electrum&lt;/code&gt; in &lt;code&gt;~/.local/bin&lt;/code&gt;, so make sure that is on your &lt;code&gt;PATH&lt;/code&gt; variable.&lt;/p&gt; &#xA;&lt;h3&gt;Development version (git clone)&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;(For OS-specific instructions, see &lt;a href=&#34;https://raw.githubusercontent.com/spesmilo/electrum/master/contrib/build-wine/README_windows.md&#34;&gt;here for Windows&lt;/a&gt;, and &lt;a href=&#34;https://raw.githubusercontent.com/spesmilo/electrum/master/contrib/osx/README_macos.md&#34;&gt;for macOS&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Check out the code from GitHub:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/spesmilo/electrum.git&#xA;$ cd electrum&#xA;$ git submodule update --init&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run install (this should install dependencies):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python3 -m pip install --user -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create translations (optional):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get install python3-requests gettext qttools5-dev-tools&#xA;$ ./contrib/pull_locale&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, to start Electrum:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ./run_electrum&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run tests&lt;/h3&gt; &#xA;&lt;p&gt;Run unit tests with &lt;code&gt;pytest&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pytest tests -v&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run a single file, specify it directly like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pytest tests/test_bitcoin.py -v&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Creating Binaries&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/spesmilo/electrum/master/contrib/build-linux/sdist/README.md&#34;&gt;Linux (tarball)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/spesmilo/electrum/master/contrib/build-linux/appimage/README.md&#34;&gt;Linux (AppImage)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/spesmilo/electrum/master/contrib/osx/README.md&#34;&gt;macOS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/spesmilo/electrum/master/contrib/build-wine/README.md&#34;&gt;Windows&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/spesmilo/electrum/master/contrib/android/Readme.md&#34;&gt;Android&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Any help testing the software, reporting or fixing bugs, reviewing pull requests and recent changes, writing tests, or helping with outstanding issues is very welcome. Implementing new features, or improving/refactoring the codebase, is of course also welcome, but to avoid wasted effort, especially for larger changes, we encourage discussing these on the issue tracker or IRC first.&lt;/p&gt; &#xA;&lt;p&gt;Besides &lt;a href=&#34;https://github.com/spesmilo/electrum&#34;&gt;GitHub&lt;/a&gt;, most communication about Electrum development happens on IRC, in the &lt;code&gt;#electrum&lt;/code&gt; channel on Libera Chat. The easiest way to participate on IRC is with the web client, &lt;a href=&#34;https://web.libera.chat/#electrum&#34;&gt;web.libera.chat&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>qxresearch/qxresearch-event-1</title>
    <updated>2024-10-21T01:33:31Z</updated>
    <id>tag:github.com,2024-10-21:/qxresearch/qxresearch-event-1</id>
    <link href="https://github.com/qxresearch/qxresearch-event-1" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Python hands on tutorial with 50+ Python Application (10 lines of code) By @xiaowuc2&lt;/p&gt;&lt;hr&gt;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://qxresearch.github.io/qxresearch-event-1&#34;&gt; &lt;img src=&#34;https://github.com/xiaowuc2/ChatGPT-Python-Applications/raw/main/resource/10lines3.gif&#34; alt=&#34;Logo&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;Welcome to our GitHub repository featuring 50+ Python applications with only 10 lines of code! In this repository, you&#39;ll find a wide range of topics such as Machine Learning, Deep Learning, GUI, Computer Vision, and API development. Each application is designed to be simple and concise, making it easy to understand and modify. Whether you&#39;re a beginner or an experienced developer, these applications are perfect for learning and experimenting with Python. So dive in, explore, and have fun!&lt;/p&gt; &#xA;&lt;p&gt;Additionally, we understand that sometimes code can be complex, which is why we&#39;ve created video explanations for each project available on our YouTube channel. With these resources at your disposal, you can quickly gain a deep understanding of the code and easily customize it to suit your needs. Subscribe to the YouTube channel &lt;a href=&#34;https://www.youtube.com/@qxresearch/&#34;&gt;@qxresearch&lt;/a&gt; to receive updates on new projects! Which also enables you to join a community of like-minded Python enthusiasts and stay connected with a passionate group of learners and experts.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; About Us : &lt;a href=&#34;https://www.qxresearch.org&#34;&gt; @qxresearch &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;qxresearch AI is a research lab focused on Machine Learning, Deep Learning, and Computer Vision. Our team aspires to make discoveries that hold a broad impact, and at the core of our approach lies the sharing of our findings in the field. Our researchers regularly publish in academic journals, release projects as open source on GitHub, and apply these findings in practical applications.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;We are looking for passionate new PhD students, Postdocs, and Master students to join the team!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Follow us on &lt;a href=&#34;https://linkedin.com/company/qxresearch&#34;&gt;LinkedIn&lt;/a&gt; for timely updates regarding new opportunities.&lt;/li&gt; &#xA; &lt;li&gt;Kindly email us your research interests and proposal for consideration.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;‚úîÔ∏è If you think this repository has helped you learn something new you can give a star ‚≠ê &#xA;‚ùå If not, point out &#39;why&#39; and spam the issue section üö© &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Python Application&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üìº &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/Voice%20Recorder&#34;&gt;Voice Recorder&lt;/a&gt; : Simple voice recorder with custom time limit&lt;/li&gt; &#xA; &lt;li&gt;üîë &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/Password%20Protech%20PDF&#34;&gt;Password Protect PDF&lt;/a&gt; : Protect a pdf with custom password&lt;/li&gt; &#xA; &lt;li&gt;üóè &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/Merge%20Multiple%20PDF&#34;&gt;Merge Multiple PDF&lt;/a&gt; : Merge multiple pdfs with python scripting&lt;/li&gt; &#xA; &lt;li&gt;üîî &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/Windows%20Notification&#34;&gt;Windows Notification&lt;/a&gt; : Custom windows notification maker&lt;/li&gt; &#xA; &lt;li&gt;üé¨ &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/Audio%20Visualization%20Tool&#34;&gt;Audio Visualization Tool&lt;/a&gt; : Awesome audio visualization tool!&lt;/li&gt; &#xA; &lt;li&gt;üìü &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/Random%20Password%20Generator&#34;&gt;Random Password Generator&lt;/a&gt; : Random secured password generator app&lt;/li&gt; &#xA; &lt;li&gt;üé∂ &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/Extract%20mp3%20from%20mp4&#34;&gt;Extract mp3 from mp4&lt;/a&gt; : Extract audio from video with parsing&lt;/li&gt; &#xA; &lt;li&gt;üîó &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/Link%20Shortener%20and%20Extractor&#34;&gt;Link Shortener and Extractor&lt;/a&gt; : URL shortener and Extractor from terminal&lt;/li&gt; &#xA; &lt;li&gt;üîã &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/Terminal%20Tricks&#34;&gt;Terminal Tricks&lt;/a&gt; : Cool terminal tricks #scripting&lt;/li&gt; &#xA; &lt;li&gt;üéÇ &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/Birthday%20Reminder&#34;&gt;Birthday Reminder&lt;/a&gt; : Birthday reminder for lazy coders&lt;/li&gt; &#xA; &lt;li&gt;üìª &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/audiobook&#34;&gt;Audiobook&lt;/a&gt; : Audiobook creator from text file&lt;/li&gt; &#xA; &lt;li&gt;‚è∞ &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/Alarm&#34;&gt;Alarm&lt;/a&gt; : Friendly alarm for programmers to take a break&lt;/li&gt; &#xA; &lt;li&gt;‚è±Ô∏è &lt;a href=&#34;https://github.com/xiaowuc2/Schedule-YouTube-video-Python/raw/master/python%20code.py&#34;&gt;Schedule YouTube Video&lt;/a&gt; : Python script will play a youtube video at scheduled time&lt;/li&gt; &#xA; &lt;li&gt;üìÜ &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/Calendar&#34;&gt;Calendar&lt;/a&gt; : A tkinter(GUI toolkit) based calendar app&lt;/li&gt; &#xA; &lt;li&gt;‚úèÔ∏è &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/Paint&#34;&gt;Paint&lt;/a&gt; : A tkinter(GUI toolkit) based interactive paint clone&lt;/li&gt; &#xA; &lt;li&gt;üíª &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/ScreenShot&#34;&gt;Screenshot taker&lt;/a&gt; : A tkinter based screenshot app with clickable button&lt;/li&gt; &#xA; &lt;li&gt;üìñ &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/Search%20Engine&#34;&gt;Wikipedia Search Engine&lt;/a&gt; : Wekipedia API integrated tkinter based search engine&lt;/li&gt; &#xA; &lt;li&gt;üõ†Ô∏è &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/tree/master/Applications/CSPRNG&#34;&gt;Cryptographically Secured Random Number Generator&lt;/a&gt; : Building a CSRNG from scratch&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Machine Learning Applications&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;chatGPT&lt;/code&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚úíÔ∏è &lt;a href=&#34;https://github.com/xiaowuc2/ChatGPT-Python-Applications/tree/main/email-automation&#34;&gt;email-automation&lt;/a&gt; : Tool to automate automate news briefing and blogging from custom senders (mail)&lt;/li&gt; &#xA; &lt;li&gt;‚≠ê &lt;a href=&#34;https://github.com/xiaowuc2/ChatGPT-Python-Applications/tree/main/chatbot&#34;&gt;custom-chatbot&lt;/a&gt; : ask chatbot to do custom work on the bases of the task (eg. scriptwriter)&lt;/li&gt; &#xA; &lt;li&gt;üìü &lt;a href=&#34;https://github.com/xiaowuc2/ChatGPT-Python-Applications/tree/main/whisper-speech-text&#34;&gt;whisper-speech-text&lt;/a&gt; : OpenAI&#39;s another API to convert text from audio&lt;/li&gt; &#xA; &lt;li&gt;‚öôÔ∏è &lt;a href=&#34;https://github.com/xiaowuc2/ChatGPT-Python-Applications/tree/main/finetuned-gpt&#34;&gt;finetuned-gpt&lt;/a&gt; : Train chatGPT on your custom data &amp;amp; ask queries from that data&lt;/li&gt; &#xA; &lt;li&gt;üí† &lt;a href=&#34;https://github.com/xiaowuc2/ChatGPT-Python-Applications/tree/main/voice-assistant&#34;&gt;voice-assistant&lt;/a&gt; : Voice assistant based on ChatGPT and WhisperAPI (Audio input &amp;amp; output)&lt;/li&gt; &#xA; &lt;li&gt;üêª &lt;a href=&#34;https://github.com/xiaowuc2/ChatGPT-Python-Applications/tree/main/web-scraping-summarizer&#34;&gt;web-scraping-summarizer&lt;/a&gt; : This tool scrapes a given website and summarizes the main context&lt;/li&gt; &#xA; &lt;li&gt;‚åö &lt;a href=&#34;https://raw.githubusercontent.com/xiaowuc2/ChatGPT-Python-Applications/main/resource/git4.png&#34;&gt;your-prespective&lt;/a&gt; : You can train ChatGPT to perceive things the way you do, and it will imitate you!&lt;/li&gt; &#xA; &lt;li&gt;üìñ &lt;a href=&#34;https://raw.githubusercontent.com/xiaowuc2/ChatGPT-Python-Applications/main/resource/git4.png&#34;&gt;bhagavad-gita-gpt&lt;/a&gt; : A religious book which contains all the answers to find our purpose and to live it fully&lt;/li&gt; &#xA; &lt;li&gt;üèú &lt;a href=&#34;https://github.com/xiaowuc2/ChatGPT-Python-Applications/raw/main/vector-database/Vector_Databse.ipynb&#34;&gt;vector-databse&lt;/a&gt; : This is how you can send big text files to chatgpt and avoid the token limits&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Setup&lt;/h3&gt; &#xA;&lt;p&gt;Refer to this &lt;a href=&#34;https://youtu.be/beEBeQw5tpc&#34;&gt;setup video&lt;/a&gt; to install the dependencies and generate API keys and incorporate them with our applications. I&#39;ve articulated the steps in text format here :&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Install the dependencies following these steps :&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Star this repository (top right corner)&lt;/li&gt; &#xA;   &lt;li&gt;&amp;lt;&amp;gt;Code &amp;gt; Download ZIP &amp;gt; Open cmd/terminal in that location&lt;/li&gt; &#xA;   &lt;li&gt;Run this command : &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Replace API keys in &lt;code&gt;yml&lt;/code&gt; files&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;* The setup for different projects might not be the same. Please refer to the individual setup guides given for each project.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Contributing&lt;/h3&gt; &#xA;&lt;p&gt;Any kind of contributions to &lt;code&gt;qxresearch-event-1&lt;/code&gt; are welcome. Contributions are what make the open source community such an amazing place to learn, inspire, and create.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/fork&#34;&gt;&lt;strong&gt;Fork&lt;/strong&gt;&lt;/a&gt; the Project&lt;/li&gt; &#xA; &lt;li&gt;Create your Feature Branch&lt;/li&gt; &#xA; &lt;li&gt;Commit your Changes&lt;/li&gt; &#xA; &lt;li&gt;Push to the Branch&lt;/li&gt; &#xA; &lt;li&gt;Open a &lt;a href=&#34;https://github.com/qxresearch/qxresearch-event-1/pulls&#34;&gt;&lt;strong&gt;Pull Request&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Do you want to join @qxresearch and contribute to new projects?&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fill up this &lt;a href=&#34;https://forms.gle/tqR8Pa6j27CHaorT6&#34;&gt;Form&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Subscribe to support : &lt;a href=&#34;https://www.youtube.com/qxresearch&#34;&gt;@qxresearch&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;a href=&#34;https://trackgit.com&#34;&gt; &lt;img src=&#34;https://us-central1-trackgit-analytics.cloudfunctions.net/token/ping/lggxrc0abm2i1s2ok85l&#34; alt=&#34;trackgit-views&#34;&gt; &lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>wandb/wandb</title>
    <updated>2024-10-21T01:33:31Z</updated>
    <id>tag:github.com,2024-10-21:/wandb/wandb</id>
    <link href="https://github.com/wandb/wandb" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The AI developer platform. Use Weights &amp; Biases to train and fine-tune models, and manage models from experimentation to production.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/wandb/wandb/main/assets/logo-dark.svg#gh-dark-mode-only&#34; width=&#34;600&#34; alt=&#34;Weights &amp;amp; Biases&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/wandb/wandb/main/assets/logo-light.svg#gh-light-mode-only&#34; width=&#34;600&#34; alt=&#34;Weights &amp;amp; Biases&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://pypi.python.org/pypi/wandb&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/wandb&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://anaconda.org/conda-forge/wandb&#34;&gt;&lt;img src=&#34;https://img.shields.io/conda/vn/conda-forge/wandb&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://circleci.com/gh/wandb/wandb&#34;&gt;&lt;img src=&#34;https://img.shields.io/circleci/build/github/wandb/wandb/main&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/wandb/wandb&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/gh/wandb/wandb&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_%26_Biases.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;Use W&amp;amp;B to build better models faster. Track and visualize all the pieces of your machine learning pipeline, from datasets to production machine learning models. Get started with W&amp;amp;B today, &lt;a href=&#34;https://wandb.com?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=readme&#34;&gt;sign up for a W&amp;amp;B account!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Building an LLM app? Track, debug, evaluate, and monitor LLM apps with &lt;a href=&#34;https://wandb.github.io/weave?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=readme&#34;&gt;Weave&lt;/a&gt;, our new suite of tools for GenAI.&lt;/p&gt; &#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt; &#xA;&lt;h1&gt;Documentation&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a target=&#34;_blank&#34; href=&#34;https://docs.wandb.ai/guides/track?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=readme&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;./assets/Product_Icons_dark_background/experiments-dark.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;./assets/Product_Icons_light/experiments-light.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;img alt=&#34;Weights and Biases Experiments&#34; src=&#34;&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &lt;a target=&#34;_blank&#34; href=&#34;https://docs.wandb.ai/guides/reports?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=readme&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;./assets/Product_Icons_dark_background/reports-dark.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;./assets/Product_Icons_light/reports-light.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;img alt=&#34;Weights and Biases Reports&#34; src=&#34;&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &lt;a target=&#34;_blank&#34; href=&#34;https://docs.wandb.ai/guides/artifacts?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=readme&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;./assets/Product_Icons_dark_background/artifacts-dark.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;./assets/Product_Icons_light/artifacts-light.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;img alt=&#34;Weights and Biases Artifacts&#34; src=&#34;&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &lt;a target=&#34;_blank&#34; href=&#34;https://docs.wandb.ai/guides/tables?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=readme&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;./assets/Product_Icons_dark_background/tables-dark.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;./assets/Product_Icons_light/tables-light.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;img alt=&#34;Weights and Biases Tables&#34; src=&#34;&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &lt;a target=&#34;_blank&#34; href=&#34;https://docs.wandb.ai/guides/sweeps?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=readme&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;./assets/Product_Icons_dark_background/sweeps-dark.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;./assets/Product_Icons_light/sweeps-light.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;img alt=&#34;Weights and Biases Sweeps&#34; src=&#34;&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &lt;a target=&#34;_blank&#34; href=&#34;https://docs.wandb.ai/guides/launch?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=readme&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;./assets/Product_Icons_dark_background/launch-dark.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;./assets/Product_Icons_light/launch-light.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;img alt=&#34;Weights and Biases Launch&#34; src=&#34;&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &lt;a target=&#34;_blank&#34; href=&#34;https://docs.wandb.ai/guides/model_registry?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=readme&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;./assets/Product_Icons_dark_background/model-registry-dark.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;./assets/Product_Icons_light/model-registry-light.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;img alt=&#34;Weights and Biases Model Management&#34; src=&#34;&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &lt;a target=&#34;_blank&#34; href=&#34;https://docs.wandb.ai/guides/artifacts/project-scoped-automations?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=readme&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;./assets/Product_Icons_dark_background/automations-dark.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;./assets/Product_Icons_light/automations-light.svg&#34; width=&#34;14.0%&#34;&gt; &#xA;   &lt;img alt=&#34;Weights and Biases Prompts&#34; src=&#34;&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt;&lt;/p&gt;&#xA;&lt;a target=&#34;_blank&#34; href=&#34;https://docs.wandb.ai/guides/artifacts/project-scoped-automations?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=readme&#34;&gt; &lt;/a&gt;&#xA;&lt;p&gt;&lt;a target=&#34;_blank&#34; href=&#34;https://docs.wandb.ai/guides/artifacts/project-scoped-automations?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=readme&#34;&gt;See the &lt;/a&gt;&lt;a href=&#34;https://docs.wandb.ai/?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=documentation&#34;&gt;W&amp;amp;B Developer Guide&lt;/a&gt; and &lt;a href=&#34;https://docs.wandb.ai/ref?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=documentation&#34;&gt;API Reference Guide&lt;/a&gt; for a full technical description of the W&amp;amp;B platform.&lt;/p&gt; &#xA;&lt;h1&gt;Quickstart&lt;/h1&gt; &#xA;&lt;p&gt;Get started with W&amp;amp;B in four steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;First, sign up for a &lt;a href=&#34;https://wandb.ai/login?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=quickstart&#34;&gt;W&amp;amp;B account&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Second, install&amp;nbsp;the W&amp;amp;B SDK with &lt;a href=&#34;https://pip.pypa.io/en/stable/&#34;&gt;pip&lt;/a&gt;. Navigate to your terminal and type the following command:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install wandb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Third, log into W&amp;amp;B:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;wandb.login()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Use the example code snippet below as a template to integrate W&amp;amp;B to your Python script:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import wandb&#xA;&#xA;# Start a W&amp;amp;B Run with wandb.init&#xA;run = wandb.init(project=&#34;my_first_project&#34;)&#xA;&#xA;# Save model inputs and hyperparameters in a wandb.config object&#xA;config = run.config&#xA;config.learning_rate = 0.01&#xA;&#xA;# Model training code here ...&#xA;&#xA;# Log metrics over time to visualize performance with wandb.log&#xA;for i in range(10):&#xA;    run.log({&#34;loss&#34;: ...})&#xA;&#xA;# Mark the run as finished, and finish uploading all data&#xA;run.finish()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That&#39;s it! Navigate to the W&amp;amp;B App to view a dashboard of your first W&amp;amp;B Experiment. Use the W&amp;amp;B App to compare multiple experiments in a unified place, dive into the results of a single run, and much more!&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/wandb/wandb/main/assets/wandb_demo_experiments.gif&#34; width=&#34;100%&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; Example W&amp;amp;B Dashboard that shows Runs from an Experiment. &lt;/p&gt; &#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt; &#xA;&lt;h1&gt;Integrations&lt;/h1&gt; &#xA;&lt;p&gt;Use your favorite framework with W&amp;amp;B. W&amp;amp;B integrations make it fast and easy to set up experiment tracking and data versioning inside existing projects. For more information on how to integrate W&amp;amp;B with the framework of your choice, see the &lt;a href=&#34;https://docs.wandb.ai/guides/integrations&#34;&gt;Integrations chapter&lt;/a&gt; in the W&amp;amp;B Developer Guide.&lt;/p&gt; &#xA;&lt;!-- &lt;p align=&#39;center&#39;&gt;&#xA;&lt;img src=&#34;./assets/integrations.png&#34; width=&#34;100%&#34; /&gt;&#xA;&lt;/p&gt; --&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;üî• PyTorch&lt;/summary&gt; &#xA; &lt;p&gt;Call &lt;code&gt;.watch&lt;/code&gt; and pass in your PyTorch model to automatically log gradients and store the network topology. Next, use &lt;code&gt;.log&lt;/code&gt; to track other metrics. The following example demonstrates an example of how to do this:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import wandb&#xA;&#xA;# 1. Start a new run&#xA;run = wandb.init(project=&#34;gpt4&#34;)&#xA;&#xA;# 2. Save model inputs and hyperparameters&#xA;config = run.config&#xA;config.dropout = 0.01&#xA;&#xA;# 3. Log gradients and model parameters&#xA;run.watch(model)&#xA;for batch_idx, (data, target) in enumerate(train_loader):&#xA;    ...&#xA;    if batch_idx % args.log_interval == 0:&#xA;        # 4. Log metrics to visualize performance&#xA;        run.log({&#34;loss&#34;: loss})&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Run an example &lt;a href=&#34;http://wandb.me/pytorch-colab&#34;&gt;Google Colab Notebook&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt;Read the &lt;a href=&#34;https://docs.wandb.com/guides/integrations/pytorch?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=integrations&#34;&gt;Developer Guide&lt;/a&gt; for technical details on how to integrate PyTorch with W&amp;amp;B.&lt;/li&gt; &#xA;  &lt;li&gt;Explore &lt;a href=&#34;https://app.wandb.ai/wandb/getting-started/reports/Pytorch--VmlldzoyMTEwNzM?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=integrations&#34;&gt;W&amp;amp;B Reports&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;üåä TensorFlow/Keras&lt;/summary&gt; Use W&amp;amp;B Callbacks to automatically save metrics to W&amp;amp;B when you call `model.fit` during training. &#xA; &lt;p&gt;The following code example demonstrates how your script might look like when you integrate W&amp;amp;B with Keras:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# This script needs these libraries to be installed:&#xA;#   tensorflow, numpy&#xA;&#xA;import wandb&#xA;from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint&#xA;&#xA;import random&#xA;import numpy as np&#xA;import tensorflow as tf&#xA;&#xA;&#xA;# Start a run, tracking hyperparameters&#xA;run = wandb.init(&#xA;    # set the wandb project where this run will be logged&#xA;    project=&#34;my-awesome-project&#34;,&#xA;    # track hyperparameters and run metadata with wandb.config&#xA;    config={&#xA;        &#34;layer_1&#34;: 512,&#xA;        &#34;activation_1&#34;: &#34;relu&#34;,&#xA;        &#34;dropout&#34;: random.uniform(0.01, 0.80),&#xA;        &#34;layer_2&#34;: 10,&#xA;        &#34;activation_2&#34;: &#34;softmax&#34;,&#xA;        &#34;optimizer&#34;: &#34;sgd&#34;,&#xA;        &#34;loss&#34;: &#34;sparse_categorical_crossentropy&#34;,&#xA;        &#34;metric&#34;: &#34;accuracy&#34;,&#xA;        &#34;epoch&#34;: 8,&#xA;        &#34;batch_size&#34;: 256,&#xA;    },&#xA;)&#xA;&#xA;# [optional] use wandb.config as your config&#xA;config = run.config&#xA;&#xA;# get the data&#xA;mnist = tf.keras.datasets.mnist&#xA;(x_train, y_train), (x_test, y_test) = mnist.load_data()&#xA;x_train, x_test = x_train / 255.0, x_test / 255.0&#xA;x_train, y_train = x_train[::5], y_train[::5]&#xA;x_test, y_test = x_test[::20], y_test[::20]&#xA;labels = [str(digit) for digit in range(np.max(y_train) + 1)]&#xA;&#xA;# build a model&#xA;model = tf.keras.models.Sequential(&#xA;    [&#xA;        tf.keras.layers.Flatten(input_shape=(28, 28)),&#xA;        tf.keras.layers.Dense(config.layer_1, activation=config.activation_1),&#xA;        tf.keras.layers.Dropout(config.dropout),&#xA;        tf.keras.layers.Dense(config.layer_2, activation=config.activation_2),&#xA;    ]&#xA;)&#xA;&#xA;# compile the model&#xA;model.compile(optimizer=config.optimizer, loss=config.loss, metrics=[config.metric])&#xA;&#xA;# WandbMetricsLogger will log train and validation metrics to wandb&#xA;# WandbModelCheckpoint will upload model checkpoints to wandb&#xA;history = model.fit(&#xA;    x=x_train,&#xA;    y=y_train,&#xA;    epochs=config.epoch,&#xA;    batch_size=config.batch_size,&#xA;    validation_data=(x_test, y_test),&#xA;    callbacks=[&#xA;        WandbMetricsLogger(log_freq=5),&#xA;        WandbModelCheckpoint(&#34;models&#34;),&#xA;    ],&#xA;)&#xA;&#xA;# [optional] finish the wandb run, necessary in notebooks&#xA;run.finish()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;Get started integrating your Keras model with W&amp;amp;B today:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Run an example &lt;a href=&#34;https://wandb.me/intro-keras?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=integrations&#34;&gt;Google Colab Notebook&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Read the &lt;a href=&#34;https://docs.wandb.com/guides/integrations/keras?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=integrations&#34;&gt;Developer Guide&lt;/a&gt; for technical details on how to integrate Keras with W&amp;amp;B.&lt;/li&gt; &#xA;  &lt;li&gt;Explore &lt;a href=&#34;https://app.wandb.ai/wandb/getting-started/reports/Keras--VmlldzoyMTEwNjQ?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=integrations&#34;&gt;W&amp;amp;B Reports&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;ü§ó Hugging Face Transformers&lt;/summary&gt; &#xA; &lt;p&gt;Pass &lt;code&gt;wandb&lt;/code&gt; to the &lt;code&gt;report_to&lt;/code&gt; argument when you run a script using a Hugging Face Trainer. W&amp;amp;B will automatically log losses, evaluation metrics, model topology, and gradients.&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The environment you run your script in must have &lt;code&gt;wandb&lt;/code&gt; installed.&lt;/p&gt; &#xA; &lt;p&gt;The following example demonstrates how to integrate W&amp;amp;B with Hugging Face:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# This script needs these libraries to be installed:&#xA;#   numpy, transformers, datasets&#xA;&#xA;import wandb&#xA;&#xA;import os&#xA;import numpy as np&#xA;from datasets import load_dataset&#xA;from transformers import TrainingArguments, Trainer&#xA;from transformers import AutoTokenizer, AutoModelForSequenceClassification&#xA;&#xA;&#xA;def tokenize_function(examples):&#xA;    return tokenizer(examples[&#34;text&#34;], padding=&#34;max_length&#34;, truncation=True)&#xA;&#xA;&#xA;def compute_metrics(eval_pred):&#xA;    logits, labels = eval_pred&#xA;    predictions = np.argmax(logits, axis=-1)&#xA;    return {&#34;accuracy&#34;: np.mean(predictions == labels)}&#xA;&#xA;&#xA;# download prepare the data&#xA;dataset = load_dataset(&#34;yelp_review_full&#34;)&#xA;tokenizer = AutoTokenizer.from_pretrained(&#34;distilbert-base-uncased&#34;)&#xA;&#xA;small_train_dataset = dataset[&#34;train&#34;].shuffle(seed=42).select(range(1000))&#xA;small_eval_dataset = dataset[&#34;test&#34;].shuffle(seed=42).select(range(300))&#xA;&#xA;small_train_dataset = small_train_dataset.map(tokenize_function, batched=True)&#xA;small_eval_dataset = small_train_dataset.map(tokenize_function, batched=True)&#xA;&#xA;# download the model&#xA;model = AutoModelForSequenceClassification.from_pretrained(&#xA;    &#34;distilbert-base-uncased&#34;, num_labels=5&#xA;)&#xA;&#xA;# set the wandb project where this run will be logged&#xA;os.environ[&#34;WANDB_PROJECT&#34;] = &#34;my-awesome-project&#34;&#xA;&#xA;# save your trained model checkpoint to wandb&#xA;os.environ[&#34;WANDB_LOG_MODEL&#34;] = &#34;true&#34;&#xA;&#xA;# turn off watch to log faster&#xA;os.environ[&#34;WANDB_WATCH&#34;] = &#34;false&#34;&#xA;&#xA;# pass &#34;wandb&#34; to the `report_to` parameter to turn on wandb logging&#xA;training_args = TrainingArguments(&#xA;    output_dir=&#34;models&#34;,&#xA;    report_to=&#34;wandb&#34;,&#xA;    logging_steps=5,&#xA;    per_device_train_batch_size=32,&#xA;    per_device_eval_batch_size=32,&#xA;    evaluation_strategy=&#34;steps&#34;,&#xA;    eval_steps=20,&#xA;    max_steps=100,&#xA;    save_steps=100,&#xA;)&#xA;&#xA;# define the trainer and start training&#xA;trainer = Trainer(&#xA;    model=model,&#xA;    args=training_args,&#xA;    train_dataset=small_train_dataset,&#xA;    eval_dataset=small_eval_dataset,&#xA;    compute_metrics=compute_metrics,&#xA;)&#xA;trainer.train()&#xA;&#xA;# [optional] finish the wandb run, necessary in notebooks&#xA;wandb.finish()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Run an example &lt;a href=&#34;http://wandb.me/hf?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=integrations&#34;&gt;Google Colab Notebook&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt;Read the &lt;a href=&#34;https://docs.wandb.com/guides/integrations/huggingface?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=integrations&#34;&gt;Developer Guide&lt;/a&gt; for technical details on how to integrate Hugging Face with W&amp;amp;B.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;‚ö°Ô∏è PyTorch Lightning&lt;/summary&gt; &#xA; &lt;p&gt;Build scalable, structured, high-performance PyTorch models with Lightning and log them with W&amp;amp;B.&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# This script needs these libraries to be installed:&#xA;#   torch, torchvision, pytorch_lightning&#xA;&#xA;import wandb&#xA;&#xA;import os&#xA;from torch import optim, nn, utils&#xA;from torchvision.datasets import MNIST&#xA;from torchvision.transforms import ToTensor&#xA;&#xA;import pytorch_lightning as pl&#xA;from pytorch_lightning.loggers import WandbLogger&#xA;&#xA;&#xA;class LitAutoEncoder(pl.LightningModule):&#xA;    def __init__(self, lr=1e-3, inp_size=28, optimizer=&#34;Adam&#34;):&#xA;        super().__init__()&#xA;&#xA;        self.encoder = nn.Sequential(&#xA;            nn.Linear(inp_size * inp_size, 64), nn.ReLU(), nn.Linear(64, 3)&#xA;        )&#xA;        self.decoder = nn.Sequential(&#xA;            nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, inp_size * inp_size)&#xA;        )&#xA;        self.lr = lr&#xA;&#xA;        # save hyperparameters to self.hparamsm auto-logged by wandb&#xA;        self.save_hyperparameters()&#xA;&#xA;    def training_step(self, batch, batch_idx):&#xA;        x, y = batch&#xA;        x = x.view(x.size(0), -1)&#xA;        z = self.encoder(x)&#xA;        x_hat = self.decoder(z)&#xA;        loss = nn.functional.mse_loss(x_hat, x)&#xA;&#xA;        # log metrics to wandb&#xA;        self.log(&#34;train_loss&#34;, loss)&#xA;        return loss&#xA;&#xA;    def configure_optimizers(self):&#xA;        optimizer = optim.Adam(self.parameters(), lr=self.lr)&#xA;        return optimizer&#xA;&#xA;&#xA;# init the autoencoder&#xA;autoencoder = LitAutoEncoder(lr=1e-3, inp_size=28)&#xA;&#xA;# setup data&#xA;batch_size = 32&#xA;dataset = MNIST(os.getcwd(), download=True, transform=ToTensor())&#xA;train_loader = utils.data.DataLoader(dataset, shuffle=True)&#xA;&#xA;# initialise the wandb logger and name your wandb project&#xA;wandb_logger = WandbLogger(project=&#34;my-awesome-project&#34;)&#xA;&#xA;# add your batch size to the wandb config&#xA;wandb_logger.experiment.config[&#34;batch_size&#34;] = batch_size&#xA;&#xA;# pass wandb_logger to the Trainer&#xA;trainer = pl.Trainer(limit_train_batches=750, max_epochs=5, logger=wandb_logger)&#xA;&#xA;# train the model&#xA;trainer.fit(model=autoencoder, train_dataloaders=train_loader)&#xA;&#xA;# [optional] finish the wandb run, necessary in notebooks&#xA;wandb.finish()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Run an example &lt;a href=&#34;http://wandb.me/lightning?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=integrations&#34;&gt;Google Colab Notebook&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt;Read the &lt;a href=&#34;https://docs.wandb.ai/guides/integrations/lightning?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=integrations&#34;&gt;Developer Guide&lt;/a&gt; for technical details on how to integrate PyTorch Lightning with W&amp;amp;B.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;üí® XGBoost&lt;/summary&gt; Use W&amp;amp;B Callbacks to automatically save metrics to W&amp;amp;B when you call `model.fit` during training. &#xA; &lt;p&gt;The following code example demonstrates how your script might look like when you integrate W&amp;amp;B with XGBoost:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# This script needs these libraries to be installed:&#xA;#   numpy, xgboost&#xA;&#xA;import wandb&#xA;from wandb.xgboost import WandbCallback&#xA;&#xA;import numpy as np&#xA;import xgboost as xgb&#xA;&#xA;&#xA;# setup parameters for xgboost&#xA;param = {&#xA;    &#34;objective&#34;: &#34;multi:softmax&#34;,&#xA;    &#34;eta&#34;: 0.1,&#xA;    &#34;max_depth&#34;: 6,&#xA;    &#34;nthread&#34;: 4,&#xA;    &#34;num_class&#34;: 6,&#xA;}&#xA;&#xA;# start a new wandb run to track this script&#xA;run = wandb.init(&#xA;    # set the wandb project where this run will be logged&#xA;    project=&#34;my-awesome-project&#34;,&#xA;    # track hyperparameters and run metadata&#xA;    config=param,&#xA;)&#xA;&#xA;# download data from wandb Artifacts and prep data&#xA;run.use_artifact(&#34;wandb/intro/dermatology_data:v0&#34;, type=&#34;dataset&#34;).download(&#34;.&#34;)&#xA;data = np.loadtxt(&#xA;    &#34;./dermatology.data&#34;,&#xA;    delimiter=&#34;,&#34;,&#xA;    converters={33: lambda x: int(x == &#34;?&#34;), 34: lambda x: int(x) - 1},&#xA;)&#xA;sz = data.shape&#xA;&#xA;train = data[: int(sz[0] * 0.7), :]&#xA;test = data[int(sz[0] * 0.7) :, :]&#xA;&#xA;train_X = train[:, :33]&#xA;train_Y = train[:, 34]&#xA;&#xA;test_X = test[:, :33]&#xA;test_Y = test[:, 34]&#xA;&#xA;xg_train = xgb.DMatrix(train_X, label=train_Y)&#xA;xg_test = xgb.DMatrix(test_X, label=test_Y)&#xA;watchlist = [(xg_train, &#34;train&#34;), (xg_test, &#34;test&#34;)]&#xA;&#xA;# add another config to the wandb run&#xA;num_round = 5&#xA;run.config[&#34;num_round&#34;] = 5&#xA;run.config[&#34;data_shape&#34;] = sz&#xA;&#xA;# pass WandbCallback to the booster to log its configs and metrics&#xA;bst = xgb.train(&#xA;    param, xg_train, num_round, evals=watchlist, callbacks=[WandbCallback()]&#xA;)&#xA;&#xA;# get prediction&#xA;pred = bst.predict(xg_test)&#xA;error_rate = np.sum(pred != test_Y) / test_Y.shape[0]&#xA;&#xA;# log your test metric to wandb&#xA;run.summary[&#34;Error Rate&#34;] = error_rate&#xA;&#xA;# [optional] finish the wandb run, necessary in notebooks&#xA;run.finish()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Run an example &lt;a href=&#34;https://wandb.me/xgboost?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=integrations&#34;&gt;Google Colab Notebook&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt;Read the &lt;a href=&#34;https://docs.wandb.ai/guides/integrations/xgboost?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=integrations&#34;&gt;Developer Guide&lt;/a&gt; for technical details on how to integrate XGBoost with W&amp;amp;B.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;üßÆ Sci-Kit Learn&lt;/summary&gt; Use wandb to visualize and compare your scikit-learn models&#39; performance: &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# This script needs these libraries to be installed:&#xA;#   numpy, sklearn&#xA;&#xA;import wandb&#xA;from wandb.sklearn import plot_precision_recall, plot_feature_importances&#xA;from wandb.sklearn import plot_class_proportions, plot_learning_curve, plot_roc&#xA;&#xA;import numpy as np&#xA;from sklearn import datasets&#xA;from sklearn.ensemble import RandomForestClassifier&#xA;from sklearn.model_selection import train_test_split&#xA;&#xA;&#xA;# load and process data&#xA;wbcd = datasets.load_breast_cancer()&#xA;feature_names = wbcd.feature_names&#xA;labels = wbcd.target_names&#xA;&#xA;test_size = 0.2&#xA;X_train, X_test, y_train, y_test = train_test_split(&#xA;    wbcd.data, wbcd.target, test_size=test_size&#xA;)&#xA;&#xA;# train model&#xA;model = RandomForestClassifier()&#xA;model.fit(X_train, y_train)&#xA;model_params = model.get_params()&#xA;&#xA;# get predictions&#xA;y_pred = model.predict(X_test)&#xA;y_probas = model.predict_proba(X_test)&#xA;importances = model.feature_importances_&#xA;indices = np.argsort(importances)[::-1]&#xA;&#xA;# start a new wandb run and add your model hyperparameters&#xA;run = wandb.init(project=&#34;my-awesome-project&#34;, config=model_params)&#xA;&#xA;# Add additional configs to wandb&#xA;run.config.update(&#xA;    {&#xA;        &#34;test_size&#34;: test_size,&#xA;        &#34;train_len&#34;: len(X_train),&#xA;        &#34;test_len&#34;: len(X_test),&#xA;    }&#xA;)&#xA;&#xA;# log additional visualisations to wandb&#xA;plot_class_proportions(y_train, y_test, labels)&#xA;plot_learning_curve(model, X_train, y_train)&#xA;plot_roc(y_test, y_probas, labels)&#xA;plot_precision_recall(y_test, y_probas, labels)&#xA;plot_feature_importances(model)&#xA;&#xA;# [optional] finish the wandb run, necessary in notebooks&#xA;run.finish()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Run an example &lt;a href=&#34;https://wandb.me/scikit-colab?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=integrations&#34;&gt;Google Colab Notebook&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt;Read the &lt;a href=&#34;https://docs.wandb.ai/guides/integrations/scikit?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=integrations&#34;&gt;Developer Guide&lt;/a&gt; for technical details on how to integrate Scikit-Learn with W&amp;amp;B.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt; &#xA;&lt;h1&gt;W&amp;amp;B Hosting Options&lt;/h1&gt; &#xA;&lt;p&gt;Weights &amp;amp; Biases is available in the cloud or installed on your private infrastructure. Set up a W&amp;amp;B Server in a production environment in one of three ways:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.wandb.ai/guides/hosting/hosting-options/self-managed#on-prem-private-cloud?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=hosting&#34;&gt;Production Cloud&lt;/a&gt;: Set up a production deployment on a private cloud in just a few steps using terraform scripts provided by W&amp;amp;B.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.wandb.ai/guides/hosting/hosting-options/wb-managed#dedicated-cloud?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=hosting&#34;&gt;Dedicated Cloud&lt;/a&gt;: A managed, dedicated deployment on W&amp;amp;B&#39;s single-tenant infrastructure in your choice of cloud region.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.wandb.ai/guides/hosting/how-to-guides/bare-metal?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=hosting&#34;&gt;On-Prem/Bare Metal&lt;/a&gt;: W&amp;amp;B supports setting up a production server on most bare metal servers in your on-premise data centers. Quickly get started by running &lt;code&gt;wandb server&lt;/code&gt; to easily start hosting W&amp;amp;B on your local infrastructure.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://docs.wandb.ai/guides/hosting?utm_source=github&amp;amp;utm_medium=code&amp;amp;utm_campaign=wandb&amp;amp;utm_content=hosting&#34;&gt;Hosting documentation&lt;/a&gt; in the W&amp;amp;B Developer Guide for more information.&lt;/p&gt; &#xA;&lt;!-- &amp;nbsp;&#xA;&#xA;# Tutorials&#xA;&#xA;Explore example Colab Notebooks at [wandb/examples GitHub repository](https://github.com/wandb/examples/tree/master/colabs). Here are some of our favorites:&#xA;&#xA;[INSERT] --&gt; &#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt; &#xA;&lt;h1&gt;Contribution guidelines&lt;/h1&gt; &#xA;&lt;p&gt;Weights &amp;amp; Biases ‚ù§Ô∏è open source, and we welcome contributions from the community! See the &lt;a href=&#34;https://github.com/wandb/wandb/raw/main/CONTRIBUTING.md&#34;&gt;Contribution guide&lt;/a&gt; for more information on the development workflow and the internals of the wandb library. For wandb bugs and feature requests, visit &lt;a href=&#34;https://github.com/wandb/wandb/issues&#34;&gt;GitHub Issues&lt;/a&gt; or contact &lt;a href=&#34;mailto:support@wandb.com&#34;&gt;support@wandb.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt; &#xA;&lt;h1&gt;W&amp;amp;B Community&lt;/h1&gt; &#xA;&lt;p&gt;Be a part of the growing W&amp;amp;B Community and interact with the W&amp;amp;B team in our &lt;a href=&#34;https://wandb.me/discord&#34;&gt;Discord&lt;/a&gt;. Stay connected with the latest ML updates and tutorials with &lt;a href=&#34;https://wandb.ai/fully-connected&#34;&gt;W&amp;amp;B Fully Connected&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/wandb/wandb/raw/main/LICENSE&#34;&gt;MIT License&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>