<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-04T01:34:11Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>naver/dust3r</title>
    <updated>2024-03-04T01:34:11Z</updated>
    <id>tag:github.com,2024-03-04:/naver/dust3r</id>
    <link href="https://github.com/naver/dust3r" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DUSt3R&lt;/h1&gt; &#xA;&lt;p&gt;Official implementation of &lt;code&gt;DUSt3R: Geometric 3D Vision Made Easy&lt;/code&gt;&lt;br&gt; [&lt;a href=&#34;https://dust3r.europe.naverlabs.com/&#34;&gt;Project page&lt;/a&gt;], [&lt;a href=&#34;https://arxiv.org/abs/2312.14132&#34;&gt;DUSt3R arxiv&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/naver/dust3r/main/assets/pipeline1.jpg&#34; alt=&#34;Example of reconstruction from two images&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/naver/dust3r/main/assets/dust3r_archi.jpg&#34; alt=&#34;High level overview of DUSt3R capabilities&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{wang2023dust3r,&#xA;      title={DUSt3R: Geometric 3D Vision Made Easy}, &#xA;      author={Shuzhe Wang and Vincent Leroy and Yohann Cabon and Boris Chidlovskii and Jerome Revaud},&#xA;      year={2023},&#xA;      eprint={2312.14132},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#dust3r&#34;&gt;DUSt3R&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#table-of-contents&#34;&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#get-started&#34;&gt;Get Started&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#checkpoints&#34;&gt;Checkpoints&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#interactive-demo&#34;&gt;Interactive demo&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#usage&#34;&gt;Usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#training&#34;&gt;Training&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#demo&#34;&gt;Demo&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#our-hyperparameters&#34;&gt;Our Hyperparameters&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The code is distributed under the CC BY-NC-SA 4.0 License. See &lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Copyright (C) 2024-present Naver Corporation. All rights reserved.&#xA;# Licensed under CC BY-NC-SA 4.0 (non-commercial use only).&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone DUSt3R&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone --recursive https://github.com/naver/dust3r&#xA;cd dust3r&#xA;# if you have already cloned dust3r:&#xA;# git submodule update --init --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Create the environment, here we show an example using conda.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n dust3r python=3.11 cmake=3.14.0&#xA;conda activate dust3r &#xA;conda install pytorch torchvision pytorch-cuda=12.1 -c pytorch -c nvidia  # use the correct version of cuda for your system&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Optional, compile the cuda kernels for RoPE (as in CroCo v2)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# DUST3R relies on RoPE positional embeddings for which you can compile some cuda kernels for faster runtime.&#xA;cd croco/models/curope/&#xA;python setup.py build_ext --inplace&#xA;cd ../../../&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Download pre-trained model&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p checkpoints/&#xA;wget https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth -P checkpoints/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Checkpoints&lt;/h3&gt; &#xA;&lt;p&gt;We provide several pre-trained models:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Modelname&lt;/th&gt; &#xA;   &lt;th&gt;Training resolutions&lt;/th&gt; &#xA;   &lt;th&gt;Head&lt;/th&gt; &#xA;   &lt;th&gt;Encoder&lt;/th&gt; &#xA;   &lt;th&gt;Decoder&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_224_linear.pth&#34;&gt;&lt;code&gt;DUSt3R_ViTLarge_BaseDecoder_224_linear.pth&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;224x224&lt;/td&gt; &#xA;   &lt;td&gt;Linear&lt;/td&gt; &#xA;   &lt;td&gt;ViT-L&lt;/td&gt; &#xA;   &lt;td&gt;ViT-B&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_linear.pth&#34;&gt;&lt;code&gt;DUSt3R_ViTLarge_BaseDecoder_512_linear.pth&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;512x384, 512x336, 512x288, 512x256, 512x160&lt;/td&gt; &#xA;   &lt;td&gt;Linear&lt;/td&gt; &#xA;   &lt;td&gt;ViT-L&lt;/td&gt; &#xA;   &lt;td&gt;ViT-B&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth&#34;&gt;&lt;code&gt;DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;512x384, 512x336, 512x288, 512x256, 512x160&lt;/td&gt; &#xA;   &lt;td&gt;DPT&lt;/td&gt; &#xA;   &lt;td&gt;ViT-L&lt;/td&gt; &#xA;   &lt;td&gt;ViT-B&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;You can check the hyperparameters we used to train these models in the &lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#our-hyperparameters&#34;&gt;section: Our Hyperparameters&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Interactive demo&lt;/h3&gt; &#xA;&lt;p&gt;In this demo, you should be able run DUSt3R on your machine to reconstruct a scene.&lt;br&gt; First select images that depicts the same scene.&lt;/p&gt; &#xA;&lt;p&gt;You can adjust the global alignment schedule and its number of iterations.&lt;br&gt; Note: if you selected one or two images, the global alignment procedure will be skipped (mode=GlobalAlignerMode.PairViewer)&lt;br&gt; Hit &#34;Run&#34; and wait.&lt;br&gt; When the global alignment ends, the reconstruction appears.&lt;br&gt; Use the slider &#34;min_conf_thr&#34; to show or remove low confidence areas.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 demo.py --weights checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth&#xA;&#xA;# Use --image_size to select the correct resolution for your checkpoint. 512 (default) or 224&#xA;# Use --local_network to make it accessible on the local network, or --server_name to specify the url manually&#xA;# Use --server_port to change the port, by default it will search for an available port starting at 7860&#xA;# Use --device to use a different device, by default it&#39;s &#34;cuda&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/naver/dust3r/main/assets/demo.jpg&#34; alt=&#34;demo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from dust3r.inference import inference, load_model&#xA;from dust3r.utils.image import load_images&#xA;from dust3r.image_pairs import make_pairs&#xA;from dust3r.cloud_opt import global_aligner, GlobalAlignerMode&#xA;&#xA;if __name__ == &#39;__main__&#39;:&#xA;    model_path = &#34;checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth&#34;&#xA;    device = &#39;cuda&#39;&#xA;    batch_size = 1&#xA;    schedule = &#39;cosine&#39;&#xA;    lr = 0.01&#xA;    niter = 300&#xA;&#xA;    model = load_model(model_path, device)&#xA;    # load_images can take a list of images or a directory&#xA;    images = load_images([&#39;croco/assets/Chateau1.png&#39;, &#39;croco/assets/Chateau2.png&#39;], size=512)&#xA;    pairs = make_pairs(images, scene_graph=&#39;complete&#39;, prefilter=None, symmetrize=True)&#xA;    output = inference(pairs, model, device, batch_size=batch_size)&#xA;&#xA;    # at this stage, you have the raw dust3r predictions&#xA;    view1, pred1 = output[&#39;view1&#39;], output[&#39;pred1&#39;]&#xA;    view2, pred2 = output[&#39;view2&#39;], output[&#39;pred2&#39;]&#xA;    # here, view1, pred1, view2, pred2 are dicts of lists of len(2)&#xA;    #  -&amp;gt; because we symmetrize we have (im1, im2) and (im2, im1) pairs&#xA;    # in each view you have:&#xA;    # an integer image identifier: view1[&#39;idx&#39;] and view2[&#39;idx&#39;]&#xA;    # the img: view1[&#39;img&#39;] and view2[&#39;img&#39;]&#xA;    # the image shape: view1[&#39;true_shape&#39;] and view2[&#39;true_shape&#39;]&#xA;    # an instance string output by the dataloader: view1[&#39;instance&#39;] and view2[&#39;instance&#39;]&#xA;    # pred1 and pred2 contains the confidence values: pred1[&#39;conf&#39;] and pred2[&#39;conf&#39;]&#xA;    # pred1 contains 3D points for view1[&#39;img&#39;] in view1[&#39;img&#39;] space: pred1[&#39;pts3d&#39;]&#xA;    # pred2 contains 3D points for view2[&#39;img&#39;] in view1[&#39;img&#39;] space: pred2[&#39;pts3d_in_other_view&#39;]&#xA;&#xA;    # next we&#39;ll use the global_aligner to align the predictions&#xA;    # depending on your task, you may be fine with the raw output and not need it&#xA;    # with only two input images, you could use GlobalAlignerMode.PairViewer: it would just convert the output&#xA;    # if using GlobalAlignerMode.PairViewer, no need to run compute_global_alignment&#xA;    scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PointCloudOptimizer)&#xA;    loss = scene.compute_global_alignment(init=&#34;mst&#34;, niter=niter, schedule=schedule, lr=lr)&#xA;&#xA;    # retrieve useful values from scene:&#xA;    imgs = scene.imgs&#xA;    focals = scene.get_focals()&#xA;    poses = scene.get_im_poses()&#xA;    pts3d = scene.get_pts3d()&#xA;    confidence_masks = scene.get_masks()&#xA;&#xA;    # visualize reconstruction&#xA;    scene.show()&#xA;&#xA;    # find 2D-2D matches between the two images&#xA;    from dust3r.utils.geometry import find_reciprocal_matches, xy_grid&#xA;    pts2d_list, pts3d_list = [], []&#xA;    for i in range(2):&#xA;        conf_i = confidence_masks[i].cpu().numpy()&#xA;        pts2d_list.append(xy_grid(*imgs[i].shape[:2][::-1])[conf_i])  # imgs[i].shape[:2] = (H, W)&#xA;        pts3d_list.append(pts3d[i].detach().cpu().numpy()[conf_i])&#xA;    reciprocal_in_P2, nn2_in_P1, num_matches = find_reciprocal_matches(*pts3d_list)&#xA;    print(f&#39;found {num_matches} matches&#39;)&#xA;    matches_im1 = pts2d_list[1][reciprocal_in_P2]&#xA;    matches_im0 = pts2d_list[0][nn2_in_P1][reciprocal_in_P2]&#xA;&#xA;    # visualize a few matches&#xA;    import numpy as np&#xA;    from matplotlib import pyplot as pl&#xA;    n_viz = 10&#xA;    match_idx_to_viz = np.round(np.linspace(0, num_matches-1, n_viz)).astype(int)&#xA;    viz_matches_im0, viz_matches_im1 = matches_im0[match_idx_to_viz], matches_im1[match_idx_to_viz]&#xA;&#xA;    H0, W0, H1, W1 = *imgs[0].shape[:2], *imgs[1].shape[:2]&#xA;    img0 = np.pad(imgs[0], ((0, max(H1 - H0, 0)), (0, 0), (0, 0)), &#39;constant&#39;, constant_values=0)&#xA;    img1 = np.pad(imgs[1], ((0, max(H0 - H1, 0)), (0, 0), (0, 0)), &#39;constant&#39;, constant_values=0)&#xA;    img = np.concatenate((img0, img1), axis=1)&#xA;    pl.figure()&#xA;    pl.imshow(img)&#xA;    cmap = pl.get_cmap(&#39;jet&#39;)&#xA;    for i in range(n_viz):&#xA;        (x0, y0), (x1, y1) = viz_matches_im0[i].T, viz_matches_im1[i].T&#xA;        pl.plot([x0, x1 + W0], [y0, y1], &#39;-+&#39;, color=cmap(i / (n_viz - 1)), scalex=False, scaley=False)&#xA;    pl.show(block=True)&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/naver/dust3r/main/assets/matching.jpg&#34; alt=&#34;matching example on croco pair&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;In this section, we present propose a short demonstration to get started with training DUSt3R. At the moment, we didn&#39;t release the training datasets, so we&#39;re going to download and prepare a subset of &lt;a href=&#34;https://github.com/facebookresearch/co3d&#34;&gt;CO3Dv2&lt;/a&gt; - &lt;a href=&#34;https://github.com/facebookresearch/co3d/raw/main/LICENSE&#34;&gt;Creative Commons Attribution-NonCommercial 4.0 International&lt;/a&gt; and launch the training code on it. The demo model will be trained for a few epochs on a very small dataset. It will not be very good.&lt;/p&gt; &#xA;&lt;h3&gt;Demo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&#xA;# download and prepare the co3d subset&#xA;mkdir -p data/co3d_subset&#xA;cd data/co3d_subset&#xA;git clone https://github.com/facebookresearch/co3d&#xA;cd co3d&#xA;python3 ./co3d/download_dataset.py --download_folder ../ --single_sequence_subset&#xA;rm ../*.zip&#xA;cd ../../..&#xA;&#xA;python3 datasets_preprocess/preprocess_co3d.py --co3d_dir data/co3d_subset --output_dir data/co3d_subset_processed  --single_sequence_subset&#xA;&#xA;# download the pretrained croco v2 checkpoint&#xA;mkdir -p checkpoints/&#xA;wget https://download.europe.naverlabs.com/ComputerVision/CroCo/CroCo_V2_ViTLarge_BaseDecoder.pth -P checkpoints/&#xA;&#xA;# the training of dust3r is done in 3 steps.&#xA;# for this example we&#39;ll do fewer epochs, for the actual hyperparameters we used in the paper, see the next section: &#34;Our Hyperparameters&#34;&#xA;# step 1 - train dust3r for 224 resolution&#xA;torchrun --nproc_per_node=4 train.py \&#xA;    --train_dataset &#34;1000 @ Co3d(split=&#39;train&#39;, ROOT=&#39;data/co3d_subset_processed&#39;, aug_crop=16, mask_bg=&#39;rand&#39;, resolution=224, transform=ColorJitter)&#34; \&#xA;    --test_dataset &#34;100 @ Co3d(split=&#39;test&#39;, ROOT=&#39;data/co3d_subset_processed&#39;, resolution=224, seed=777)&#34; \&#xA;    --model &#34;AsymmetricCroCo3DStereo(pos_embed=&#39;RoPE100&#39;, img_size=(224, 224), head_type=&#39;linear&#39;, output_mode=&#39;pts3d&#39;, depth_mode=(&#39;exp&#39;, -inf, inf), conf_mode=(&#39;exp&#39;, 1, inf), enc_embed_dim=1024, enc_depth=24, enc_num_heads=16, dec_embed_dim=768, dec_depth=12, dec_num_heads=12)&#34; \&#xA;    --train_criterion &#34;ConfLoss(Regr3D(L21, norm_mode=&#39;avg_dis&#39;), alpha=0.2)&#34; \&#xA;    --test_criterion &#34;Regr3D_ScaleShiftInv(L21, gt_scale=True)&#34; \&#xA;    --pretrained checkpoints/CroCo_V2_ViTLarge_BaseDecoder.pth \&#xA;    --lr 0.0001 --min_lr 1e-06 --warmup_epochs 1 --epochs 10 --batch_size 16 --accum_iter 1 \&#xA;    --save_freq 1 --keep_freq 5 --eval_freq 1 \&#xA;    --output_dir checkpoints/dust3r_demo_224&#x9;  &#xA;&#xA;# step 2 - train dust3r for 512 resolution&#xA;torchrun --nproc_per_node=4 train.py \&#xA;    --train_dataset &#34;1000 @ Co3d(split=&#39;train&#39;, ROOT=&#39;data/co3d_subset_processed&#39;, aug_crop=16, mask_bg=&#39;rand&#39;, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter)&#34; \&#xA;    --test_dataset=&#34;100 @ Co3d(split=&#39;test&#39;, ROOT=&#39;data/co3d_subset_processed&#39;, resolution=(512,384), seed=777)&#34; \&#xA;    --model=&#34;AsymmetricCroCo3DStereo(pos_embed=&#39;RoPE100&#39;, patch_embed_cls=&#39;ManyAR_PatchEmbed&#39;, img_size=(512, 512), head_type=&#39;linear&#39;, output_mode=&#39;pts3d&#39;, depth_mode=(&#39;exp&#39;, -inf, inf), conf_mode=(&#39;exp&#39;, 1, inf), enc_embed_dim=1024, enc_depth=24, enc_num_heads=16, dec_embed_dim=768, dec_depth=12, dec_num_heads=12)&#34; \&#xA;    --train_criterion &#34;ConfLoss(Regr3D(L21, norm_mode=&#39;avg_dis&#39;), alpha=0.2)&#34; \&#xA;    --test_criterion &#34;Regr3D_ScaleShiftInv(L21, gt_scale=True)&#34; \&#xA;    --pretrained=&#39;checkpoints/dust3r_demo_224/checkpoint-best.pth&#39; \&#xA;    --lr=0.0001 --min_lr=1e-06 --warmup_epochs 1 --epochs 10 --batch_size 4 --accum_iter 4 \&#xA;    --save_freq 1 --keep_freq 5 --eval_freq 1 \&#xA;    --output_dir checkpoints/dust3r_demo_512&#xA;&#xA;# step 3 - train dust3r for 512 resolution with dpt&#xA;torchrun --nproc_per_node=4 train.py \&#xA;    --train_dataset &#34;1000 @ Co3d(split=&#39;train&#39;, ROOT=&#39;data/co3d_subset_processed&#39;, aug_crop=16, mask_bg=&#39;rand&#39;, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter)&#34; \&#xA;    --test_dataset=&#34;100 @ Co3d(split=&#39;test&#39;, ROOT=&#39;data/co3d_subset_processed&#39;, resolution=(512,384), seed=777)&#34; \&#xA;    --model=&#34;AsymmetricCroCo3DStereo(pos_embed=&#39;RoPE100&#39;, patch_embed_cls=&#39;ManyAR_PatchEmbed&#39;, img_size=(512, 512), head_type=&#39;dpt&#39;, output_mode=&#39;pts3d&#39;, depth_mode=(&#39;exp&#39;, -inf, inf), conf_mode=(&#39;exp&#39;, 1, inf), enc_embed_dim=1024, enc_depth=24, enc_num_heads=16, dec_embed_dim=768, dec_depth=12, dec_num_heads=12)&#34; \&#xA;    --train_criterion &#34;ConfLoss(Regr3D(L21, norm_mode=&#39;avg_dis&#39;), alpha=0.2)&#34; \&#xA;    --test_criterion &#34;Regr3D_ScaleShiftInv(L21, gt_scale=True)&#34; \&#xA;    --pretrained=&#39;checkpoints/dust3r_demo_512/checkpoint-best.pth&#39; \&#xA;    --lr=0.0001 --min_lr=1e-06 --warmup_epochs 1 --epochs 10 --batch_size 2 --accum_iter 8 \&#xA;    --save_freq 1 --keep_freq 5 --eval_freq 1 \&#xA;    --output_dir checkpoints/dust3r_demo_512dpt&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Our Hyperparameters&lt;/h3&gt; &#xA;&lt;p&gt;We didn&#39;t release the training datasets, but here are the commands we used for training our models:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# NOTE: ROOT path omitted for datasets&#xA;# 224 linear&#xA;torchrun --nproc_per_node 4 train.py \&#xA;    --train_dataset=&#34; + 100_000 @ Habitat512(1_000_000, split=&#39;train&#39;, aug_crop=16, resolution=224, transform=ColorJitter) + 100_000 @ BlendedMVS(split=&#39;train&#39;, aug_crop=16, resolution=224, transform=ColorJitter) + 100_000 @ MegaDepthDense(split=&#39;train&#39;, aug_crop=16, resolution=224, transform=ColorJitter) + 100_000 @ ARKitScenes(aug_crop=256, resolution=224, transform=ColorJitter) + 100_000 @ Co3d_v3(split=&#39;train&#39;, aug_crop=16, mask_bg=&#39;rand&#39;, resolution=224, transform=ColorJitter) + 100_000 @ StaticThings3D(aug_crop=256, mask_bg=&#39;rand&#39;, resolution=224, transform=ColorJitter) + 100_000 @ ScanNetpp(split=&#39;train&#39;, aug_crop=256, resolution=224, transform=ColorJitter) + 100_000 @ Waymo(aug_crop=128, resolution=224, transform=ColorJitter) &#34; \&#xA;    --test_dataset=&#34; Habitat512(1_000, split=&#39;val&#39;, resolution=224, seed=777) + 1_000 @ BlendedMVS(split=&#39;val&#39;, resolution=224, seed=777) + 1_000 @ MegaDepthDense(split=&#39;val&#39;, resolution=224, seed=777) + 1_000 @ Co3d_v3(split=&#39;test&#39;, mask_bg=&#39;rand&#39;, resolution=224, seed=777) &#34; \&#xA;    --train_criterion=&#34;ConfLoss(Regr3D(L21, norm_mode=&#39;avg_dis&#39;), alpha=0.2)&#34; \&#xA;    --test_criterion=&#39;Regr3D_ScaleShiftInv(L21, gt_scale=True)&#39; \&#xA;    --model=&#34;AsymmetricCroCo3DStereo(pos_embed=&#39;RoPE100&#39;, img_size=(224, 224), head_type=&#39;linear&#39;, output_mode=&#39;pts3d&#39;, depth_mode=(&#39;exp&#39;, -inf, inf), conf_mode=(&#39;exp&#39;, 1, inf), enc_embed_dim=1024, enc_depth=24, enc_num_heads=16, dec_embed_dim=768, dec_depth=12, dec_num_heads=12)&#34; \&#xA;    --pretrained=&#34;checkpoints/CroCo_V2_ViTLarge_BaseDecoder.pth&#34; \&#xA;    --lr=0.0001 --min_lr=1e-06 --warmup_epochs=10 --epochs=100 --batch_size=16 --accum_iter=1 \&#xA;    --save_freq=5 --keep_freq=10 --eval_freq=1 \&#xA;    --output_dir=&#39;checkpoints/dust3r_224&#39;&#xA;&#xA;# 512 linear&#xA;torchrun --nproc_per_node 8 train.py \&#xA;    --train_dataset=&#34; + 10_000 @ Habitat512(1_000_000, split=&#39;train&#39;, aug_crop=16, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ BlendedMVS(split=&#39;train&#39;, aug_crop=16, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ MegaDepthDense(split=&#39;train&#39;, aug_crop=16, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ ARKitScenes(aug_crop=256, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ Co3d_v3(split=&#39;train&#39;, aug_crop=16, mask_bg=&#39;rand&#39;, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ StaticThings3D(aug_crop=256, mask_bg=&#39;rand&#39;, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ ScanNetpp(split=&#39;train&#39;, aug_crop=256, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ Waymo(aug_crop=128, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) &#34; \&#xA;    --test_dataset=&#34; Habitat512(1_000, split=&#39;val&#39;, resolution=(512,384), seed=777) + 1_000 @ BlendedMVS(split=&#39;val&#39;, resolution=(512,384), seed=777) + 1_000 @ MegaDepthDense(split=&#39;val&#39;, resolution=(512,336), seed=777) + 1_000 @ Co3d_v3(split=&#39;test&#39;, resolution=(512,384), seed=777) &#34; \&#xA;    --train_criterion=&#34;ConfLoss(Regr3D(L21, norm_mode=&#39;avg_dis&#39;), alpha=0.2)&#34; \&#xA;    --test_criterion=&#39;Regr3D_ScaleShiftInv(L21, gt_scale=True)&#39; \&#xA;    --model=&#34;AsymmetricCroCo3DStereo(pos_embed=&#39;RoPE100&#39;, patch_embed_cls=&#39;ManyAR_PatchEmbed&#39;, img_size=(512, 512), head_type=&#39;linear&#39;, output_mode=&#39;pts3d&#39;, depth_mode=(&#39;exp&#39;, -inf, inf), conf_mode=(&#39;exp&#39;, 1, inf), enc_embed_dim=1024, enc_depth=24, enc_num_heads=16, dec_embed_dim=768, dec_depth=12, dec_num_heads=12)&#34; \&#xA;    --pretrained=&#39;checkpoints/dust3r_224/checkpoint-best.pth&#39; \&#xA;    --lr=0.0001 --min_lr=1e-06 --warmup_epochs=20 --epochs=200 --batch_size=4 --accum_iter=2 \&#xA;    --save_freq=10 --keep_freq=10 --eval_freq=1 --print_freq=10 \&#xA;    --output_dir=&#39;checkpoints/dust3r_512&#39;&#xA;&#xA;# 512 dpt&#xA;torchrun --nproc_per_node 8 train.py \&#xA;    --train_dataset=&#34; + 10_000 @ Habitat512(1_000_000, split=&#39;train&#39;, aug_crop=16, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ BlendedMVS(split=&#39;train&#39;, aug_crop=16, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ MegaDepthDense(split=&#39;train&#39;, aug_crop=16, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ ARKitScenes(aug_crop=256, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ Co3d_v3(split=&#39;train&#39;, aug_crop=16, mask_bg=&#39;rand&#39;, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ StaticThings3D(aug_crop=256, mask_bg=&#39;rand&#39;, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ ScanNetpp(split=&#39;train&#39;, aug_crop=256, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ Waymo(aug_crop=128, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) &#34; \&#xA;    --test_dataset=&#34; Habitat512(1_000, split=&#39;val&#39;, resolution=(512,384), seed=777) + 1_000 @ BlendedMVS(split=&#39;val&#39;, resolution=(512,384), seed=777) + 1_000 @ MegaDepthDense(split=&#39;val&#39;, resolution=(512,336), seed=777) + 1_000 @ Co3d_v3(split=&#39;test&#39;, resolution=(512,384), seed=777) &#34; \&#xA;    --train_criterion=&#34;ConfLoss(Regr3D(L21, norm_mode=&#39;avg_dis&#39;), alpha=0.2)&#34; \&#xA;    --test_criterion=&#39;Regr3D_ScaleShiftInv(L21, gt_scale=True)&#39; \&#xA;    --model=&#34;AsymmetricCroCo3DStereo(pos_embed=&#39;RoPE100&#39;, patch_embed_cls=&#39;ManyAR_PatchEmbed&#39;, img_size=(512, 512), head_type=&#39;dpt&#39;, output_mode=&#39;pts3d&#39;, depth_mode=(&#39;exp&#39;, -inf, inf), conf_mode=(&#39;exp&#39;, 1, inf), enc_embed_dim=1024, enc_depth=24, enc_num_heads=16, dec_embed_dim=768, dec_depth=12, dec_num_heads=12)&#34; \&#xA;    --pretrained=&#39;checkpoints/dust3r_512/checkpoint-best.pth&#39; \&#xA;    --lr=0.0001 --min_lr=1e-06 --warmup_epochs=15 --epochs=90 --batch_size=2 --accum_iter=4 \&#xA;    --save_freq=5 --keep_freq=10 --eval_freq=1 --print_freq=10 \&#xA;    --output_dir=&#39;checkpoints/dust3r_512dpt&#39;&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>pydantic/FastUI</title>
    <updated>2024-03-04T01:34:11Z</updated>
    <id>tag:github.com,2024-03-04:/pydantic/FastUI</id>
    <link href="https://github.com/pydantic/FastUI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Build better UIs faster.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FastUI&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/pydantic/FastUI/actions?query=event%3Apush+branch%3Amain+workflow%3ACI&#34;&gt;&lt;img src=&#34;https://github.com/pydantic/FastUI/actions/workflows/ci.yml/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/fastui&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/fastui.svg?sanitize=true&#34; alt=&#34;pypi&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pydantic/FastUI&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/fastui.svg?sanitize=true&#34; alt=&#34;versions&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pydantic/FastUI/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/pydantic/FastUI.svg?sanitize=true&#34; alt=&#34;license&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please note:&lt;/strong&gt; FastUI is still an active work in progress, do not expect it to be complete.&lt;/p&gt; &#xA;&lt;h2&gt;The Principle (short version)&lt;/h2&gt; &#xA;&lt;p&gt;You can see a simple demo of an application built with FastUI &lt;a href=&#34;https://fastui-demo.onrender.com&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;FastUI is a new way to build web application user interfaces defined by declarative Python code.&lt;/p&gt; &#xA;&lt;p&gt;This means:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;If you&#39;re a Python developer&lt;/strong&gt; â€” you can build responsive web applications using React without writing a single line of JavaScript, or touching &lt;code&gt;npm&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;If you&#39;re a frontend developer&lt;/strong&gt; â€” you can concentrate on building magical components that are truly reusable, no copy-pasting components for each view.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;For everyone&lt;/strong&gt; â€” a true separation of concerns, the backend defines the entire application; while the frontend is free to implement just the user interface&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;At its heart, FastUI is a set of matching &lt;a href=&#34;https://docs.pydantic.dev&#34;&gt;Pydantic&lt;/a&gt; models and TypeScript interfaces that allow you to define a user interface. This interface is validated at build time by TypeScript and pyright/mypy and at runtime by Pydantic.&lt;/p&gt; &#xA;&lt;h2&gt;The Practice â€” Usage&lt;/h2&gt; &#xA;&lt;p&gt;FastUI is made up of 4 things:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pypi.python.org/pypi/fastui&#34;&gt;&lt;code&gt;fastui&lt;/code&gt; PyPI package&lt;/a&gt; â€” Pydantic models for UI components, and some utilities. While it works well with &lt;a href=&#34;https://fastapi.tiangolo.com&#34;&gt;FastAPI&lt;/a&gt; it doesn&#39;t depend on FastAPI, and most of it could be used with any python web framework.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.npmjs.com/package/@pydantic/fastui&#34;&gt;&lt;code&gt;@pydantic/fastui&lt;/code&gt; npm package&lt;/a&gt; â€” a React TypeScript package that lets you reuse the machinery and types of FastUI while implementing your own components&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.npmjs.com/package/@pydantic/fastui-bootstrap&#34;&gt;&lt;code&gt;@pydantic/fastui-bootstrap&lt;/code&gt; npm package&lt;/a&gt; â€” implementation/customisation of all FastUI components using &lt;a href=&#34;https://getbootstrap.com&#34;&gt;Bootstrap&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jsdelivr.com/package/npm/@pydantic/fastui-prebuilt&#34;&gt;&lt;code&gt;@pydantic/fastui-prebuilt&lt;/code&gt; npm package&lt;/a&gt; (available on &lt;a href=&#34;https://www.jsdelivr.com/package/npm/@pydantic/fastui-prebuilt&#34;&gt;jsdelivr.com CDN&lt;/a&gt;) providing a pre-built version of the FastUI React app so you can use it without installing any npm packages or building anything yourself. The Python package provides a simple HTML page to serve this app.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Here&#39;s a simple but complete FastAPI application that uses FastUI to show some user profiles:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from datetime import date&#xA;&#xA;from fastapi import FastAPI, HTTPException&#xA;from fastapi.responses import HTMLResponse&#xA;from fastui import FastUI, AnyComponent, prebuilt_html, components as c&#xA;from fastui.components.display import DisplayMode, DisplayLookup&#xA;from fastui.events import GoToEvent, BackEvent&#xA;from pydantic import BaseModel, Field&#xA;&#xA;app = FastAPI()&#xA;&#xA;&#xA;class User(BaseModel):&#xA;    id: int&#xA;    name: str&#xA;    dob: date = Field(title=&#39;Date of Birth&#39;)&#xA;&#xA;&#xA;# define some users&#xA;users = [&#xA;    User(id=1, name=&#39;John&#39;, dob=date(1990, 1, 1)),&#xA;    User(id=2, name=&#39;Jack&#39;, dob=date(1991, 1, 1)),&#xA;    User(id=3, name=&#39;Jill&#39;, dob=date(1992, 1, 1)),&#xA;    User(id=4, name=&#39;Jane&#39;, dob=date(1993, 1, 1)),&#xA;]&#xA;&#xA;&#xA;@app.get(&#34;/api/&#34;, response_model=FastUI, response_model_exclude_none=True)&#xA;def users_table() -&amp;gt; list[AnyComponent]:&#xA;    &#34;&#34;&#34;&#xA;    Show a table of four users, `/api` is the endpoint the frontend will connect to&#xA;    when a user visits `/` to fetch components to render.&#xA;    &#34;&#34;&#34;&#xA;    return [&#xA;        c.Page(  # Page provides a basic container for components&#xA;            components=[&#xA;                c.Heading(text=&#39;Users&#39;, level=2),  # renders `&amp;lt;h2&amp;gt;Users&amp;lt;/h2&amp;gt;`&#xA;                c.Table(&#xA;                    data=users,&#xA;                    # define two columns for the table&#xA;                    columns=[&#xA;                        # the first is the users, name rendered as a link to their profile&#xA;                        DisplayLookup(field=&#39;name&#39;, on_click=GoToEvent(url=&#39;/user/{id}/&#39;)),&#xA;                        # the second is the date of birth, rendered as a date&#xA;                        DisplayLookup(field=&#39;dob&#39;, mode=DisplayMode.date),&#xA;                    ],&#xA;                ),&#xA;            ]&#xA;        ),&#xA;    ]&#xA;&#xA;&#xA;@app.get(&#34;/api/user/{user_id}/&#34;, response_model=FastUI, response_model_exclude_none=True)&#xA;def user_profile(user_id: int) -&amp;gt; list[AnyComponent]:&#xA;    &#34;&#34;&#34;&#xA;    User profile page, the frontend will fetch this when the user visits `/user/{id}/`.&#xA;    &#34;&#34;&#34;&#xA;    try:&#xA;        user = next(u for u in users if u.id == user_id)&#xA;    except StopIteration:&#xA;        raise HTTPException(status_code=404, detail=&#34;User not found&#34;)&#xA;    return [&#xA;        c.Page(&#xA;            components=[&#xA;                c.Heading(text=user.name, level=2),&#xA;                c.Link(components=[c.Text(text=&#39;Back&#39;)], on_click=BackEvent()),&#xA;                c.Details(data=user),&#xA;            ]&#xA;        ),&#xA;    ]&#xA;&#xA;&#xA;@app.get(&#39;/{path:path}&#39;)&#xA;async def html_landing() -&amp;gt; HTMLResponse:&#xA;    &#34;&#34;&#34;Simple HTML page which serves the React app, comes last as it matches all paths.&#34;&#34;&#34;&#xA;    return HTMLResponse(prebuilt_html(title=&#39;FastUI Demo&#39;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Which renders like this:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pydantic/FastUI/main/screenshot.png&#34; alt=&#34;screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Of course, that&#39;s a very simple application, the &lt;a href=&#34;https://fastui-demo.onrender.com&#34;&gt;full demo&lt;/a&gt; is more complete.&lt;/p&gt; &#xA;&lt;h3&gt;Components&lt;/h3&gt; &#xA;&lt;p&gt;FastUI already defines a rich set of components.&lt;/p&gt; &#xA;&lt;p&gt;All components are listed in the &lt;a href=&#34;https://fastui-demo.onrender.com&#34;&gt;demo app&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;The Principle (long version)&lt;/h2&gt; &#xA;&lt;p&gt;FastUI is an implementation of the RESTful principle; but not as it&#39;s usually understood, instead I mean the principle defined in the original &lt;a href=&#34;https://ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm&#34;&gt;PhD dissertation&lt;/a&gt; by Roy Fielding, and excellently summarised in &lt;a href=&#34;https://htmx.org/essays/how-did-rest-come-to-mean-the-opposite-of-rest/&#34;&gt;this essay on htmx.org&lt;/a&gt; (HTMX people, I&#39;m sorry to use your article to promote React which I know you despise ğŸ™).&lt;/p&gt; &#xA;&lt;p&gt;The RESTful principle as described in the HTMX article is that the frontend doesn&#39;t need to (and shouldn&#39;t) know anything about the application you&#39;re building. Instead, it should just provide all the components you need to construct the interface, the backend can then tell the frontend what to do.&lt;/p&gt; &#xA;&lt;p&gt;Think of your frontend as a puppet, and the backend as the hand within it â€” the puppet doesn&#39;t need to know what to say, that&#39;s kind of the point.&lt;/p&gt; &#xA;&lt;p&gt;Building an application this way has a number of significant advantages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You only need to write code in one place to build a new feature â€” add a new view, change the behavior of an existing view or alter the URL structure&lt;/li&gt; &#xA; &lt;li&gt;Deploying the front and backend can be completely decoupled, provided the frontend knows how to render all the components the backend is going to ask it to use, you&#39;re good to go&lt;/li&gt; &#xA; &lt;li&gt;You should be able to reuse a rich set of opensource components, they should end up being better tested and more reliable than anything you could build yourself, this is possible because the components need no context about how they&#39;re going to be used (note: since FastUI is brand new, this isn&#39;t true yet, hopefully we get there)&lt;/li&gt; &#xA; &lt;li&gt;We can use Pydantic, TypeScript and JSON Schema to provide guarantees that the two sides are communicating with an agreed schema&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In the abstract, FastUI is like the opposite of GraphQL but with the same goal â€” GraphQL lets frontend developers extend an application without any new backend development; FastUI lets backend developers extend an application without any new frontend development.&lt;/p&gt; &#xA;&lt;h3&gt;Beyond Python and React&lt;/h3&gt; &#xA;&lt;p&gt;Of course, this principle shouldn&#39;t be limited to Python and React applications â€” provided we use the same set of agreed schemas and encoding to communicate, we should be able to use any frontend and backend that implements the schema. Interchangeably.&lt;/p&gt; &#xA;&lt;p&gt;This could mean:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Implementing a web frontend using another JS framework like Vue â€” lots of work, limited value IMHO&lt;/li&gt; &#xA; &lt;li&gt;Implementing a web frontend using an edge server, so the browser just sees HTML â€” lots of work but very valuable&lt;/li&gt; &#xA; &lt;li&gt;Implementing frontends for other platforms like mobile or IOT â€” lots of work, no idea if it&#39;s actually a good idea?&lt;/li&gt; &#xA; &lt;li&gt;Implementing the component models in another language like Rust or Go â€” since there&#39;s actually not that much code in the backend, so this would be a relatively small and mechanical task&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>liguodongiot/llm-action</title>
    <updated>2024-03-04T01:34:11Z</updated>
    <id>tag:github.com,2024-03-04:/liguodongiot/llm-action</id>
    <link href="https://github.com/liguodongiot/llm-action" rel="alternate"></link>
    <summary type="html">&lt;p&gt;æœ¬é¡¹ç›®æ—¨åœ¨åˆ†äº«å¤§æ¨¡å‹ç›¸å…³æŠ€æœ¯åŸç†ä»¥åŠå®æˆ˜ç»éªŒã€‚&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/liguodongiot/llm-action/raw/main/pic/llm-action-v3.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt; &lt;a href=&#34;https://github.com/liguodongiot/llm-action/stargazers&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/liguodongiot/llm-action?style=social&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/pic/wx.jpg&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/åƒæœå†»ä¸åæœå†»çš®-1AAD19.svg?style=plastic&amp;amp;logo=wechat&amp;amp;logoColor=white&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://www.zhihu.com/people/liguodong-iot&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/åƒæœå†»ä¸åæœå†»çš®-0079FF.svg?style=plastic&amp;amp;logo=zhihu&amp;amp;logoColor=white&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://juejin.cn/user/3642056016410728&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/æ˜é‡‘-åƒæœå†»ä¸åæœå†»çš®-000099.svg?style=plastic&amp;amp;logo=juejin&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://liguodong.blog.csdn.net/&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/CSDN-åƒæœå†»ä¸åæœå†»çš®-6B238E.svg&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;ç›®å½•&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸ”¥ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E8%AE%AD%E7%BB%83&#34;&gt;LLMè®­ç»ƒ&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ğŸ« &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E8%AE%AD%E7%BB%83%E5%AE%9E%E6%88%98&#34;&gt;LLMè®­ç»ƒå®æˆ˜&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;ğŸ¼ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86&#34;&gt;LLMå‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;ğŸ° &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%BE%AE%E8%B0%83%E5%AE%9E%E6%88%98&#34;&gt;LLMå‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å®æˆ˜&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;ğŸ˜ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E5%B9%B6%E8%A1%8C%E6%8A%80%E6%9C%AF&#34;&gt;LLMåˆ†å¸ƒå¼è®­ç»ƒå¹¶è¡ŒæŠ€æœ¯&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;ğŸŒ‹ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E5%88%86%E5%B8%83%E5%BC%8Fai%E6%A1%86%E6%9E%B6&#34;&gt;åˆ†å¸ƒå¼AIæ¡†æ¶&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;ğŸ“¡ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1&#34;&gt;åˆ†å¸ƒå¼è®­ç»ƒç½‘ç»œé€šä¿¡&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ğŸ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E6%8E%A8%E7%90%86&#34;&gt;LLMæ¨ç†&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ğŸš€ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6&#34;&gt;LLMæ¨ç†æ¡†æ¶&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;âœˆï¸ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF&#34;&gt;LLMæ¨ç†ä¼˜åŒ–æŠ€æœ¯&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;â™»ï¸ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%8E%8B%E7%BC%A9&#34;&gt;LLMå‹ç¼©&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ğŸ“ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E9%87%8F%E5%8C%96&#34;&gt;LLMé‡åŒ–&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;ğŸ”° &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%89%AA%E6%9E%9D&#34;&gt;LLMå‰ªæ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;ğŸ’¹ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F&#34;&gt;LLMçŸ¥è¯†è’¸é¦&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;â™‘ï¸ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E4%BD%8E%E7%A7%A9%E5%88%86%E8%A7%A3&#34;&gt;ä½ç§©åˆ†è§£&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;â™ï¸ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E7%AE%97%E6%B3%95%E6%9E%B6%E6%9E%84&#34;&gt;LLMç®—æ³•æ¶æ„&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;ğŸ§©&lt;/span&gt; &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91&#34;&gt;LLMåº”ç”¨å¼€å‘&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ğŸ€„ï¸ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%9B%BD%E4%BA%A7%E5%8C%96%E9%80%82%E9%85%8D&#34;&gt;LLMå›½äº§åŒ–é€‚é…&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¯ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#ai%E7%BC%96%E8%AF%91%E5%99%A8&#34;&gt;AIç¼–è¯‘å™¨&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”˜ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#ai%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD&#34;&gt;AIåŸºç¡€è®¾æ–½&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ğŸ’Ÿ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llmops&#34;&gt;LLMOps&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ğŸ„ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E7%94%9F%E6%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF&#34;&gt;LLMç”Ÿæ€ç›¸å…³æŠ€æœ¯&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¨ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E5%8F%8A%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7&#34;&gt;æœåŠ¡å™¨åŸºç¡€ç¯å¢ƒå®‰è£…åŠå¸¸ç”¨å·¥å…·&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ğŸ’¬ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#llm%E5%AD%A6%E4%B9%A0%E4%BA%A4%E6%B5%81%E7%BE%A4&#34;&gt;LLMå­¦ä¹ äº¤æµç¾¤&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ğŸ‘¥ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7&#34;&gt;å¾®ä¿¡å…¬ä¼—å·&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;â­ï¸ &lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#star-history&#34;&gt;Star History&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LLMè®­ç»ƒ&lt;/h2&gt; &#xA;&lt;h3&gt;LLMè®­ç»ƒå®æˆ˜&lt;/h3&gt; &#xA;&lt;p&gt;ä¸‹é¢æ±‡æ€»äº†æˆ‘åœ¨å¤§æ¨¡å‹å®è·µä¸­è®­ç»ƒç›¸å…³çš„æ‰€æœ‰æ•™ç¨‹ã€‚ä»6Båˆ°65Bï¼Œä»å…¨é‡å¾®è°ƒåˆ°é«˜æ•ˆå¾®è°ƒï¼ˆLoRAï¼ŒQLoRAï¼ŒP-Tuning v2ï¼‰ï¼Œå†åˆ°RLHFï¼ˆåŸºäºäººå·¥åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼‰ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;LLM&lt;/th&gt; &#xA;   &lt;th&gt;é¢„è®­ç»ƒ/SFT/RLHF...&lt;/th&gt; &#xA;   &lt;th&gt;å‚æ•°&lt;/th&gt; &#xA;   &lt;th&gt;æ•™ç¨‹&lt;/th&gt; &#xA;   &lt;th&gt;ä»£ç &lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;full fine-turning&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/618321077&#34;&gt;ä»0åˆ°1å¤ç°æ–¯å¦ç¦ç¾Šé©¼ï¼ˆStanford Alpaca 7Bï¼‰&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/alpaca&#34;&gt;é…å¥—ä»£ç &lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Alpaca(LLaMA)&lt;/td&gt; &#xA;   &lt;td&gt;LoRA&lt;/td&gt; &#xA;   &lt;td&gt;7B~65B&lt;/td&gt; &#xA;   &lt;td&gt;1.&lt;a href=&#34;https://zhuanlan.zhihu.com/p/619426866&#34;&gt;è¶³å¤ŸæƒŠè‰³ï¼Œä½¿ç”¨Alpaca-LoraåŸºäºLLaMA(7B)äºŒååˆ†é’Ÿå®Œæˆå¾®è°ƒï¼Œæ•ˆæœæ¯”è‚©æ–¯å¦ç¦ç¾Šé©¼&lt;/a&gt;&lt;br&gt;2. &lt;a href=&#34;https://zhuanlan.zhihu.com/p/632492604&#34;&gt;ä½¿ç”¨ LoRA æŠ€æœ¯å¯¹ LLaMA 65B å¤§æ¨¡å‹è¿›è¡Œå¾®è°ƒåŠæ¨ç†&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/alpaca-lora&#34;&gt;é…å¥—ä»£ç &lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BELLE(LLaMA/Bloom)&lt;/td&gt; &#xA;   &lt;td&gt;full fine-turning&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;1.&lt;a href=&#34;https://zhuanlan.zhihu.com/p/618876472&#34;&gt;åŸºäºLLaMA-7B/Bloomz-7B1-mtå¤ç°å¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹BELLEåŠGPTQé‡åŒ–&lt;/a&gt; &lt;br&gt; 2. &lt;a href=&#34;https://zhuanlan.zhihu.com/p/621128368&#34;&gt;BELLE(LLaMA-7B/Bloomz-7B1-mt)å¤§æ¨¡å‹ä½¿ç”¨GPTQé‡åŒ–åæ¨ç†æ€§èƒ½æµ‹è¯•&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM&lt;/td&gt; &#xA;   &lt;td&gt;LoRA&lt;/td&gt; &#xA;   &lt;td&gt;6B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/621793987&#34;&gt;ä»0åˆ°1åŸºäºChatGLM-6Bä½¿ç”¨LoRAè¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/chatglm-lora&#34;&gt;é…å¥—ä»£ç &lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM&lt;/td&gt; &#xA;   &lt;td&gt;full fine-turning/P-Tuning v2&lt;/td&gt; &#xA;   &lt;td&gt;6B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/622351059&#34;&gt;ä½¿ç”¨DeepSpeed/P-Tuning v2å¯¹ChatGLM-6Bè¿›è¡Œå¾®è°ƒ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/chatglm&#34;&gt;é…å¥—ä»£ç &lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vicuna(LLaMA)&lt;/td&gt; &#xA;   &lt;td&gt;full fine-turning&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/624012908&#34;&gt;å¤§æ¨¡å‹ä¹Ÿå†…å·ï¼ŒVicunaè®­ç»ƒåŠæ¨ç†æŒ‡å—ï¼Œæ•ˆæœç¢¾å‹æ–¯å¦ç¦ç¾Šé©¼&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OPT&lt;/td&gt; &#xA;   &lt;td&gt;RLHF&lt;/td&gt; &#xA;   &lt;td&gt;0.1B~66B&lt;/td&gt; &#xA;   &lt;td&gt;1.&lt;a href=&#34;https://zhuanlan.zhihu.com/p/626159553&#34;&gt;ä¸€é”®å¼ RLHF è®­ç»ƒ DeepSpeed Chatï¼ˆä¸€ï¼‰ï¼šç†è®ºç¯‡&lt;/a&gt;&amp;nbsp;&lt;br&gt; 2. &lt;a href=&#34;https://zhuanlan.zhihu.com/p/626214655&#34;&gt;ä¸€é”®å¼ RLHF è®­ç»ƒ DeepSpeed Chatï¼ˆäºŒï¼‰ï¼šå®è·µç¯‡&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/deepspeedchat&#34;&gt;é…å¥—ä»£ç &lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MiniGPT-4(LLaMA)&lt;/td&gt; &#xA;   &lt;td&gt;full fine-turning&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/627671257&#34;&gt;å¤§æ€å™¨ï¼Œå¤šæ¨¡æ€å¤§æ¨¡å‹MiniGPT-4å…¥å‘æŒ‡å—&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese-LLaMA-Alpaca(LLaMA)&lt;/td&gt; &#xA;   &lt;td&gt;LoRAï¼ˆé¢„è®­ç»ƒ+å¾®è°ƒï¼‰&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/631360711&#34;&gt;ä¸­æ–‡LLaMA&amp;amp;Alpacaå¤§è¯­è¨€æ¨¡å‹è¯è¡¨æ‰©å……+é¢„è®­ç»ƒ+æŒ‡ä»¤ç²¾è°ƒ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/chinese-llama-alpaca&#34;&gt;é…å¥—ä»£ç &lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA&lt;/td&gt; &#xA;   &lt;td&gt;QLoRA&lt;/td&gt; &#xA;   &lt;td&gt;7B/65B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/636644164&#34;&gt;é«˜æ•ˆå¾®è°ƒæŠ€æœ¯QLoRAå®æˆ˜ï¼ŒåŸºäºLLaMA-65Bå¾®è°ƒä»…éœ€48Gæ˜¾å­˜ï¼ŒçœŸé¦™&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/qlora&#34;&gt;é…å¥—ä»£ç &lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E7%9B%AE%E5%BD%95&#34;&gt;â¬† ä¸€é”®è¿”å›ç›®å½•&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;LLMå¾®è°ƒæŠ€æœ¯åŸç†&lt;/h3&gt; &#xA;&lt;p&gt;å¯¹äºæ™®é€šå¤§ä¼—æ¥è¯´ï¼Œè¿›è¡Œå¤§æ¨¡å‹çš„é¢„è®­ç»ƒæˆ–è€…å…¨é‡å¾®è°ƒé¥ä¸å¯åŠã€‚ç”±æ­¤ï¼Œå‚¬ç”Ÿäº†å„ç§å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯ï¼Œè®©ç§‘ç ”äººå‘˜æˆ–è€…æ™®é€šå¼€å‘è€…æœ‰æœºä¼šå°è¯•å¾®è°ƒå¤§æ¨¡å‹ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å› æ­¤ï¼Œè¯¥æŠ€æœ¯å€¼å¾—æˆ‘ä»¬è¿›è¡Œæ·±å…¥åˆ†æå…¶èƒŒåçš„æœºç†ï¼Œæœ¬ç³»åˆ—å¤§ä½“åˆ†ä¸ƒç¯‡æ–‡ç« è¿›è¡Œè®²è§£ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/635152813&#34;&gt;å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆä¸€ï¼‰-èƒŒæ™¯ã€å‚æ•°é«˜æ•ˆå¾®è°ƒç®€ä»‹&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/635686756&#34;&gt;å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆäºŒï¼‰-BitFitã€Prefix Tuningã€Prompt Tuning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/635848732&#34;&gt;å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆä¸‰ï¼‰-P-Tuningã€P-Tuning v2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/636038478&#34;&gt;å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆå››ï¼‰-Adapter TuningåŠå…¶å˜ä½“&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/636215898&#34;&gt;å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆäº”ï¼‰-LoRAã€AdaLoRAã€QLoRA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/636362246&#34;&gt;å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆå…­ï¼‰-MAM Adapterã€UniPELT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/649755252&#34;&gt;å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆä¸ƒï¼‰-æœ€ä½³å®è·µã€æ€»ç»“&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;LLMå¾®è°ƒå®æˆ˜&lt;/h3&gt; &#xA;&lt;p&gt;ä¸‹é¢ç»™å¤§å®¶åˆ†äº«&lt;strong&gt;å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å®æˆ˜&lt;/strong&gt;ï¼Œè¯¥ç³»åˆ—ä¸»è¦é’ˆå¯¹ HuggingFace PEFT æ¡†æ¶æ”¯æŒçš„ä¸€äº›é«˜æ•ˆå¾®è°ƒæŠ€æœ¯è¿›è¡Œè®²è§£ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;æ•™ç¨‹&lt;/th&gt; &#xA;   &lt;th&gt;ä»£ç &lt;/th&gt; &#xA;   &lt;th&gt;æ¡†æ¶&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/651744834&#34;&gt;å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å®æˆ˜ï¼ˆä¸€ï¼‰-PEFTæ¦‚è¿°åŠç¯å¢ƒæ­å»º&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;HuggingFace PEFT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/646748939&#34;&gt;å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å®æˆ˜ï¼ˆäºŒï¼‰-Prompt Tuning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/peft/clm/peft_prompt_tuning_clm.ipynb&#34;&gt;é…å¥—ä»£ç &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HuggingFace PEFT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/646876256&#34;&gt;å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å®æˆ˜ï¼ˆä¸‰ï¼‰-P-Tuning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/peft/clm/peft_p_tuning_clm.ipynb&#34;&gt;é…å¥—ä»£ç &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HuggingFace PEFT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/648156780&#34;&gt;å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å®æˆ˜ï¼ˆå››ï¼‰-Prefix Tuning / P-Tuning v2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/peft/clm/peft_p_tuning_v2_clm.ipynb&#34;&gt;é…å¥—ä»£ç &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HuggingFace PEFT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/649315197&#34;&gt;å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å®æˆ˜ï¼ˆäº”ï¼‰-LoRA&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/peft/clm/peft_lora_clm.ipynb&#34;&gt;é…å¥—ä»£ç &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HuggingFace PEFT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/649707359&#34;&gt;å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å®æˆ˜ï¼ˆå…­ï¼‰-IA3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/peft/clm/peft_ia3_clm.ipynb&#34;&gt;é…å¥—ä»£ç &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HuggingFace PEFT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/670048482&#34;&gt;å¤§æ¨¡å‹å¾®è°ƒå®æˆ˜ï¼ˆä¸ƒï¼‰-åŸºäºLoRAå¾®è°ƒå¤šæ¨¡æ€å¤§æ¨¡å‹&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/peft/multimodal/blip2_lora_int8_fine_tune.py&#34;&gt;é…å¥—ä»£ç &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;HuggingFace PEFT&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/670116171&#34;&gt;å¤§æ¨¡å‹å¾®è°ƒå®æˆ˜ï¼ˆå…«ï¼‰-ä½¿ç”¨INT8/FP4/NF4å¾®è°ƒå¤§æ¨¡å‹&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/train/peft/multimodal/finetune_bloom_bnb_peft.ipynb&#34;&gt;é…å¥—ä»£ç &lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;PEFTã€bitsandbytes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E7%9B%AE%E5%BD%95&#34;&gt;â¬† ä¸€é”®è¿”å›ç›®å½•&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/docs/llm-base/distribution-parallelism&#34;&gt;LLMåˆ†å¸ƒå¼è®­ç»ƒå¹¶è¡ŒæŠ€æœ¯&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;è¿‘å¹´æ¥ï¼Œéšç€Transformerã€MOEæ¶æ„çš„æå‡ºï¼Œä½¿å¾—æ·±åº¦å­¦ä¹ æ¨¡å‹è½»æ¾çªç ´ä¸Šä¸‡äº¿è§„æ¨¡å‚æ•°ï¼Œä¼ ç»Ÿçš„å•æœºå•å¡æ¨¡å¼å·²ç»æ— æ³•æ»¡è¶³è¶…å¤§æ¨¡å‹è¿›è¡Œè®­ç»ƒçš„è¦æ±‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦åŸºäºå•æœºå¤šå¡ã€ç”šè‡³æ˜¯å¤šæœºå¤šå¡è¿›è¡Œåˆ†å¸ƒå¼å¤§æ¨¡å‹çš„è®­ç»ƒã€‚&lt;/p&gt; &#xA;&lt;p&gt;è€Œåˆ©ç”¨AIé›†ç¾¤ï¼Œä½¿æ·±åº¦å­¦ä¹ ç®—æ³•æ›´å¥½åœ°ä»å¤§é‡æ•°æ®ä¸­é«˜æ•ˆåœ°è®­ç»ƒå‡ºæ€§èƒ½ä¼˜è‰¯çš„å¤§æ¨¡å‹æ˜¯åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ çš„é¦–è¦ç›®æ ‡ã€‚ä¸ºäº†å®ç°è¯¥ç›®æ ‡ï¼Œä¸€èˆ¬éœ€è¦æ ¹æ®ç¡¬ä»¶èµ„æºä¸æ•°æ®/æ¨¡å‹è§„æ¨¡çš„åŒ¹é…æƒ…å†µï¼Œè€ƒè™‘å¯¹è®¡ç®—ä»»åŠ¡ã€è®­ç»ƒæ•°æ®å’Œæ¨¡å‹è¿›è¡Œåˆ’åˆ†ï¼Œä»è€Œè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒã€‚å› æ­¤ï¼Œåˆ†å¸ƒå¼è®­ç»ƒç›¸å…³æŠ€æœ¯å€¼å¾—æˆ‘ä»¬è¿›è¡Œæ·±å…¥åˆ†æå…¶èƒŒåçš„æœºç†ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ä¸‹é¢ä¸»è¦å¯¹å¤§æ¨¡å‹è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒçš„å¹¶è¡ŒæŠ€æœ¯è¿›è¡Œè®²è§£ï¼Œæœ¬ç³»åˆ—å¤§ä½“åˆ†ä¹ç¯‡æ–‡ç« è¿›è¡Œè®²è§£ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/598714869&#34;&gt;å¤§æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒå¹¶è¡ŒæŠ€æœ¯ï¼ˆä¸€ï¼‰-æ¦‚è¿°&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/650002268&#34;&gt;å¤§æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒå¹¶è¡ŒæŠ€æœ¯ï¼ˆäºŒï¼‰-æ•°æ®å¹¶è¡Œ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/653860567&#34;&gt;å¤§æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒå¹¶è¡ŒæŠ€æœ¯ï¼ˆä¸‰ï¼‰-æµæ°´çº¿å¹¶è¡Œ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/657921100&#34;&gt;å¤§æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒå¹¶è¡ŒæŠ€æœ¯ï¼ˆå››ï¼‰-å¼ é‡å¹¶è¡Œ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/659792351&#34;&gt;å¤§æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒå¹¶è¡ŒæŠ€æœ¯ï¼ˆäº”ï¼‰-åºåˆ—å¹¶è¡Œ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/661279318&#34;&gt;å¤§æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒå¹¶è¡ŒæŠ€æœ¯ï¼ˆå…­ï¼‰-å¤šç»´æ··åˆå¹¶è¡Œ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/662517647&#34;&gt;å¤§æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒå¹¶è¡ŒæŠ€æœ¯ï¼ˆä¸ƒï¼‰-è‡ªåŠ¨å¹¶è¡Œ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/662518387&#34;&gt;å¤§æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒå¹¶è¡ŒæŠ€æœ¯ï¼ˆå…«ï¼‰-MOEå¹¶è¡Œ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7290740395913969705&#34;&gt;å¤§æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒå¹¶è¡ŒæŠ€æœ¯ï¼ˆä¹ï¼‰-æ€»ç»“&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E7%9B%AE%E5%BD%95&#34;&gt;â¬† ä¸€é”®è¿”å›ç›®å½•&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;åˆ†å¸ƒå¼AIæ¡†æ¶&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/pytorch/&#34;&gt;PyTorch&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;PyTorch å•æœºå¤šå¡è®­ç»ƒ&lt;/li&gt; &#xA;   &lt;li&gt;PyTorch å¤šæœºå¤šå¡è®­ç»ƒ&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/megatron&#34;&gt;Megatron-LM&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Megatron-LM å•æœºå¤šå¡è®­ç»ƒ&lt;/li&gt; &#xA;   &lt;li&gt;Megatron-LM å¤šæœºå¤šå¡è®­ç»ƒ&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7259682893648724029&#34;&gt;åŸºäºMegatron-LMä»0åˆ°1å®ŒæˆGPT2æ¨¡å‹é¢„è®­ç»ƒã€æ¨¡å‹è¯„ä¼°åŠæ¨ç†&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/deepspeed&#34;&gt;DeepSpeed&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;DeepSpeed å•æœºå¤šå¡è®­ç»ƒ&lt;/li&gt; &#xA;   &lt;li&gt;DeepSpeed å¤šæœºå¤šå¡è®­ç»ƒ&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/train/megatron-deepspeed&#34;&gt;Megatron-DeepSpeed&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;åŸºäº Megatron-DeepSpeed ä» 0 åˆ°1 å®Œæˆ LLaMA é¢„è®­ç»ƒ&lt;/li&gt; &#xA;   &lt;li&gt;åŸºäº Megatron-DeepSpeed ä» 0 åˆ°1 å®Œæˆ Bloom é¢„è®­ç»ƒ&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;åˆ†å¸ƒå¼è®­ç»ƒç½‘ç»œé€šä¿¡&lt;/h3&gt; &#xA;&lt;p&gt;TODO&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E7%9B%AE%E5%BD%95&#34;&gt;â¬† ä¸€é”®è¿”å›ç›®å½•&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/inference&#34;&gt;LLMæ¨ç†&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;LLMæ¨ç†æ¡†æ¶&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/625415776/answer/3243562246&#34;&gt;å¤§æ¨¡å‹æ¨ç†æ¡†æ¶æ¦‚è¿°&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/626008090&#34;&gt;å¤§æ¨¡å‹çš„å¥½ä¼™ä¼´ï¼Œæµ…ææ¨ç†åŠ é€Ÿå¼•æ“FasterTransformer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/629336492&#34;&gt;æ¨¡å‹æ¨ç†æœåŠ¡åŒ–æ¡†æ¶Tritonä¿å§†å¼æ•™ç¨‹ï¼ˆä¸€ï¼‰ï¼šå¿«é€Ÿå…¥é—¨&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/634143650&#34;&gt;æ¨¡å‹æ¨ç†æœåŠ¡åŒ–æ¡†æ¶Tritonä¿å§†å¼æ•™ç¨‹ï¼ˆäºŒï¼‰ï¼šæ¶æ„è§£æ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/634444666&#34;&gt;æ¨¡å‹æ¨ç†æœåŠ¡åŒ–æ¡†æ¶Tritonä¿å§†å¼æ•™ç¨‹ï¼ˆä¸‰ï¼‰ï¼šå¼€å‘å®è·µ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/666849728&#34;&gt;TensorRT-LLMä¿å§†çº§æ•™ç¨‹ï¼ˆä¸€ï¼‰-å¿«é€Ÿå…¥é—¨&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/667572720&#34;&gt;TensorRT-LLMä¿å§†çº§æ•™ç¨‹ï¼ˆäºŒï¼‰-å¼€å‘å®è·µ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;TensorRT-LLMä¿å§†çº§æ•™ç¨‹ï¼ˆä¸‰ï¼‰-åŸºäºTritonå®Œæˆæ¨¡å‹æœåŠ¡åŒ–&lt;/li&gt; &#xA; &lt;li&gt;TensorRT-LLMä¿å§†çº§æ•™ç¨‹ï¼ˆå››ï¼‰-æ–°æ¨¡å‹é€‚é…&lt;/li&gt; &#xA; &lt;li&gt;TensorRT&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;LLMæ¨ç†ä¼˜åŒ–æŠ€æœ¯&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;LLMæ¨ç†ä¼˜åŒ–æŠ€æœ¯æ¦‚è¿°&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;PageAttention&lt;/li&gt; &#xA; &lt;li&gt;FlashAttention&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LLMå‹ç¼©&lt;/h2&gt; &#xA;&lt;p&gt;è¿‘å¹´æ¥ï¼Œéšç€Transformerã€MOEæ¶æ„çš„æå‡ºï¼Œä½¿å¾—æ·±åº¦å­¦ä¹ æ¨¡å‹è½»æ¾çªç ´ä¸Šä¸‡äº¿è§„æ¨¡å‚æ•°ï¼Œä»è€Œå¯¼è‡´æ¨¡å‹å˜å¾—è¶Šæ¥è¶Šå¤§ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸€äº›å¤§æ¨¡å‹å‹ç¼©æŠ€æœ¯æ¥é™ä½æ¨¡å‹éƒ¨ç½²çš„æˆæœ¬ï¼Œå¹¶æå‡æ¨¡å‹çš„æ¨ç†æ€§èƒ½ã€‚ æ¨¡å‹å‹ç¼©ä¸»è¦åˆ†ä¸ºå¦‚ä¸‹å‡ ç±»ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;å‰ªæï¼ˆPruningï¼‰&lt;/li&gt; &#xA; &lt;li&gt;çŸ¥è¯†è’¸é¦ï¼ˆKnowledge Distillationï¼‰&lt;/li&gt; &#xA; &lt;li&gt;é‡åŒ–&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/model-compression/quantization&#34;&gt;LLMé‡åŒ–&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;æœ¬ç³»åˆ—å°†é’ˆå¯¹ä¸€äº›å¸¸è§å¤§æ¨¡å‹é‡åŒ–æ–¹æ¡ˆï¼ˆGPTQã€LLM.int8()ã€SmoothQuantã€AWQç­‰ï¼‰è¿›è¡Œè®²è¿°ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/627484732/answer/3261671478&#34;&gt;å¤§æ¨¡å‹é‡åŒ–æ¦‚è¿°&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼š &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/647589650&#34;&gt;å¤§æ¨¡å‹é‡åŒ–æ„ŸçŸ¥è®­ç»ƒæŠ€æœ¯åŸç†ï¼šLLM-QAT&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;&#34;&gt;å¤§æ¨¡å‹é‡åŒ–æ„ŸçŸ¥å¾®è°ƒæŠ€æœ¯åŸç†ï¼šQLoRA&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;PEQA&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;è®­ç»ƒåé‡åŒ–ï¼š &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/680212402&#34;&gt;å¤§æ¨¡å‹é‡åŒ–æŠ€æœ¯åŸç†ï¼šGPTQã€LLM.int8()&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/576376372/answer/3388402085&#34;&gt;å¤§æ¨¡å‹é‡åŒ–æŠ€æœ¯åŸç†ï¼šSmoothQuant&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/681578090&#34;&gt;å¤§æ¨¡å‹é‡åŒ–æŠ€æœ¯åŸç†ï¼šAWQã€AutoAWQ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/682871823&#34;&gt;å¤§æ¨¡å‹é‡åŒ–æŠ€æœ¯åŸç†ï¼šSpQR&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/683813769&#34;&gt;å¤§æ¨¡å‹é‡åŒ–æŠ€æœ¯åŸç†ï¼šZeroQuantç³»åˆ—&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;å¤§æ¨¡å‹é‡åŒ–æŠ€æœ¯åŸç†ï¼šæ€»ç»“&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;LLMå‰ªæ&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;ç»“æ„åŒ–å‰ªæ&lt;/strong&gt;ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;LLM-Pruner&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;éç»“æ„åŒ–å‰ªæ&lt;/strong&gt;ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;SparseGPT&lt;/li&gt; &#xA; &lt;li&gt;LoRAPrune&lt;/li&gt; &#xA; &lt;li&gt;Wanda&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;LLMçŸ¥è¯†è’¸é¦&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/625415893/answer/3243565375&#34;&gt;å¤§æ¨¡å‹çŸ¥è¯†è’¸é¦æ¦‚è¿°&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Standard KD&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;p&gt;ä½¿å­¦ç”Ÿæ¨¡å‹å­¦ä¹ æ•™å¸ˆæ¨¡å‹(LLM)æ‰€æ‹¥æœ‰çš„å¸¸è§çŸ¥è¯†ï¼Œå¦‚è¾“å‡ºåˆ†å¸ƒå’Œç‰¹å¾ä¿¡æ¯ï¼Œè¿™ç§æ–¹æ³•ç±»ä¼¼äºä¼ ç»Ÿçš„KDã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;MINILLM&lt;/li&gt; &#xA; &lt;li&gt;GKD&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;EA-based KD&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;p&gt;ä¸ä»…ä»…æ˜¯å°†LLMçš„å¸¸è§çŸ¥è¯†è½¬ç§»åˆ°å­¦ç”Ÿæ¨¡å‹ä¸­ï¼Œè¿˜æ¶µç›–äº†è’¸é¦å®ƒä»¬ç‹¬ç‰¹çš„æ¶Œç°èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼ŒEA-based KDåˆåˆ†ä¸ºäº†ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ã€æ€ç»´é“¾ï¼ˆCoTï¼‰å’ŒæŒ‡ä»¤è·Ÿéšï¼ˆIFï¼‰ã€‚&lt;/p&gt; &#xA;&lt;p&gt;In-Context Learningï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;In-Context Learning distillation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Chain-of-Thoughtï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;MT-COT&lt;/li&gt; &#xA; &lt;li&gt;Fine-tune-CoT&lt;/li&gt; &#xA; &lt;li&gt;DISCO&lt;/li&gt; &#xA; &lt;li&gt;SCOTT&lt;/li&gt; &#xA; &lt;li&gt;SOCRATIC CoT&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Instruction Followingï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lion&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ä½ç§©åˆ†è§£&lt;/h3&gt; &#xA;&lt;p&gt;ä½ç§©åˆ†è§£æ—¨åœ¨é€šè¿‡å°†ç»™å®šçš„æƒé‡çŸ©é˜µåˆ†è§£æˆä¸¤ä¸ªæˆ–å¤šä¸ªè¾ƒå°ç»´åº¦çš„çŸ©é˜µï¼Œä»è€Œå¯¹å…¶è¿›è¡Œè¿‘ä¼¼ã€‚ä½ç§©åˆ†è§£èƒŒåçš„æ ¸å¿ƒæ€æƒ³æ˜¯æ‰¾åˆ°ä¸€ä¸ªå¤§çš„æƒé‡çŸ©é˜µWçš„åˆ†è§£ï¼Œå¾—åˆ°ä¸¤ä¸ªçŸ©é˜µUå’ŒVï¼Œä½¿å¾—Wâ‰ˆU Vï¼Œå…¶ä¸­Uæ˜¯ä¸€ä¸ªmÃ—kçŸ©é˜µï¼ŒVæ˜¯ä¸€ä¸ªkÃ—nçŸ©é˜µï¼Œå…¶ä¸­kè¿œå°äºmå’Œnã€‚Uå’ŒVçš„ä¹˜ç§¯è¿‘ä¼¼äºåŸå§‹çš„æƒé‡çŸ©é˜µï¼Œä»è€Œå¤§å¹…å‡å°‘äº†å‚æ•°æ•°é‡å’Œè®¡ç®—å¼€é”€ã€‚&lt;/p&gt; &#xA;&lt;p&gt;åœ¨LLMç ”ç©¶çš„æ¨¡å‹å‹ç¼©é¢†åŸŸï¼Œç ”ç©¶äººå‘˜é€šå¸¸å°†å¤šç§æŠ€æœ¯ä¸ä½ç§©åˆ†è§£ç›¸ç»“åˆï¼ŒåŒ…æ‹¬ä¿®å‰ªã€é‡åŒ–ç­‰ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ZeroQuant-FPï¼ˆä½ç§©åˆ†è§£+é‡åŒ–ï¼‰&lt;/li&gt; &#xA; &lt;li&gt;LoRAPruneï¼ˆä½ç§©åˆ†è§£+å‰ªæï¼‰&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/docs/llm-base/ai-algo&#34;&gt;LLMç®—æ³•æ¶æ„&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/600016134&#34;&gt;å¤§æ¨¡å‹ç®—æ³•æ¼”è¿›&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ChatGLM / ChatGLM2 / ChatGLM3 å¤§æ¨¡å‹è§£æ&lt;/li&gt; &#xA; &lt;li&gt;Bloom å¤§æ¨¡å‹è§£æ&lt;/li&gt; &#xA; &lt;li&gt;LLaMA / LLaMA2 å¤§æ¨¡å‹è§£æ&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/606757218/answer/3075464500&#34;&gt;ç™¾å·æ™ºèƒ½å¼€æºå¤§æ¨¡å‹baichuan-7BæŠ€æœ¯å‰–æ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/611507751/answer/3114988669&#34;&gt;ç™¾å·æ™ºèƒ½å¼€æºå¤§æ¨¡å‹baichuan-13BæŠ€æœ¯å‰–æ&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LLMåº”ç”¨å¼€å‘&lt;/h2&gt; &#xA;&lt;p&gt;å¤§æ¨¡å‹æ˜¯åŸºåº§ï¼Œè¦æƒ³è®©å…¶å˜æˆä¸€æ¬¾äº§å“ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸€äº›å…¶ä»–ç›¸å…³çš„æŠ€æœ¯ï¼Œæ¯”å¦‚ï¼šå‘é‡æ•°æ®åº“ï¼ˆPineconeã€Milvusã€Vespaã€Weaviateï¼‰ï¼ŒLangChainç­‰ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/476025527&#34;&gt;äº‘åŸç”Ÿå‘é‡æ•°æ®åº“Milvusï¼ˆä¸€ï¼‰-ç®€è¿°ã€ç³»ç»Ÿæ¶æ„åŠåº”ç”¨åœºæ™¯&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/477231485&#34;&gt;äº‘åŸç”Ÿå‘é‡æ•°æ®åº“Milvusï¼ˆäºŒï¼‰-æ•°æ®ä¸ç´¢å¼•çš„å¤„ç†æµç¨‹ã€ç´¢å¼•ç±»å‹åŠSchema&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/651921120&#34;&gt;å…³äºå¤§æ¨¡å‹é©±åŠ¨çš„AIæ™ºèƒ½ä½“Agentçš„ä¸€äº›æ€è€ƒ&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/docs/llm_localization&#34;&gt;LLMå›½äº§åŒ–é€‚é…&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;éšç€ ChatGPT çš„ç°è±¡çº§èµ°çº¢ï¼Œå¼•é¢†äº†AIå¤§æ¨¡å‹æ—¶ä»£çš„å˜é©ï¼Œä»è€Œå¯¼è‡´ AI ç®—åŠ›æ—¥ç›Šç´§ç¼ºã€‚ä¸æ­¤åŒæ—¶ï¼Œä¸­ç¾è´¸æ˜“æˆ˜ä»¥åŠç¾å›½å¯¹åè¿›è¡ŒAIèŠ¯ç‰‡ç›¸å…³çš„åˆ¶è£å¯¼è‡´ AI ç®—åŠ›çš„å›½äº§åŒ–é€‚é…åŠ¿åœ¨å¿…è¡Œã€‚æœ¬ç³»åˆ—å°†å¯¹ä¸€äº›å›½äº§åŒ– AI åŠ é€Ÿå¡è¿›è¡Œè®²è§£ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/637918406&#34;&gt;å¤§æ¨¡å‹å›½äº§åŒ–é€‚é…1-åä¸ºæ˜‡è…¾AIå…¨æ ˆè½¯ç¡¬ä»¶å¹³å°æ€»ç»“&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/650730807&#34;&gt;å¤§æ¨¡å‹å›½äº§åŒ–é€‚é…2-åŸºäºæ˜‡è…¾910ä½¿ç”¨ChatGLM-6Bè¿›è¡Œæ¨¡å‹æ¨ç†&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/651324599&#34;&gt;å¤§æ¨¡å‹å›½äº§åŒ–é€‚é…3-åŸºäºæ˜‡è…¾910ä½¿ç”¨ChatGLM-6Bè¿›è¡Œæ¨¡å‹è®­ç»ƒ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/655902796&#34;&gt;å¤§æ¨¡å‹å›½äº§åŒ–é€‚é…4-åŸºäºæ˜‡è…¾910ä½¿ç”¨LLaMA-13Bè¿›è¡Œå¤šæœºå¤šå¡è®­ç»ƒ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7291513759470960679&#34;&gt;å¤§æ¨¡å‹å›½äº§åŒ–é€‚é…5-ç™¾åº¦é£æµ†PaddleNLPå¤§è¯­è¨€æ¨¡å‹å·¥å…·é“¾æ€»ç»“&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/677799157&#34;&gt;å¤§æ¨¡å‹å›½äº§åŒ–é€‚é…6-åŸºäºæ˜‡è…¾910Bå¿«é€ŸéªŒè¯ChatGLM3-6B/BaiChuan2-7Bæ¨¡å‹æ¨ç†&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E7%9B%AE%E5%BD%95&#34;&gt;â¬† ä¸€é”®è¿”å›ç›®å½•&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/ai-compiler&#34;&gt;AIç¼–è¯‘å™¨&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;AIç¼–è¯‘å™¨æ˜¯æŒ‡å°†æœºå™¨å­¦ä¹ ç®—æ³•ä»å¼€å‘é˜¶æ®µï¼Œé€šè¿‡å˜æ¢å’Œä¼˜åŒ–ç®—æ³•ï¼Œä½¿å…¶å˜æˆéƒ¨ç½²çŠ¶æ€ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/669347560&#34;&gt;AIç¼–è¯‘å™¨æŠ€æœ¯å‰–æï¼ˆä¸€ï¼‰-æ¦‚è¿°&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/671477784&#34;&gt;AIç¼–è¯‘å™¨æŠ€æœ¯å‰–æï¼ˆäºŒï¼‰-ä¼ ç»Ÿç¼–è¯‘å™¨&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/676723324&#34;&gt;AIç¼–è¯‘å™¨æŠ€æœ¯å‰–æï¼ˆä¸‰ï¼‰-æ ‘æ¨¡å‹ç¼–è¯‘å·¥å…· Treelite è¯¦è§£&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;AIç¼–è¯‘å™¨æŠ€æœ¯å‰–æï¼ˆå››ï¼‰-ç¼–è¯‘å™¨å‰ç«¯&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;AIç¼–è¯‘å™¨æŠ€æœ¯å‰–æï¼ˆäº”ï¼‰-ç¼–è¯‘å™¨åç«¯&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;AIç¼–è¯‘å™¨æŠ€æœ¯å‰–æï¼ˆå…­ï¼‰-ä¸»æµç¼–è¯‘æ¡†æ¶&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;AIç¼–è¯‘å™¨æŠ€æœ¯å‰–æï¼ˆä¸ƒï¼‰-æ·±åº¦å­¦ä¹ æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/672584013&#34;&gt;lleavesï¼šä½¿ç”¨ LLVM ç¼–è¯‘æ¢¯åº¦æå‡å†³ç­–æ ‘å°†é¢„æµ‹é€Ÿåº¦æå‡10+å€&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;æ¡†æ¶ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;MLIR&lt;/li&gt; &#xA; &lt;li&gt;XLA&lt;/li&gt; &#xA; &lt;li&gt;TVM&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;AIåŸºç¡€è®¾æ–½&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7311604023184162835&#34;&gt;AI é›†ç¾¤åŸºç¡€è®¾æ–½ NVMe SSD è¯¦è§£&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/673903240&#34;&gt;AI é›†ç¾¤åŸºç¡€è®¾æ–½ InfiniBand è¯¦è§£&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;å¤§æ¨¡å‹è®­ç»ƒåŸºç¡€è®¾æ–½ï¼šç®—åŠ›ç¯‡&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;AIåŠ é€Ÿå¡&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/667686665&#34;&gt;AIèŠ¯ç‰‡æŠ€æœ¯åŸç†å‰–æï¼ˆä¸€ï¼‰ï¼šå›½å†…å¤–AIèŠ¯ç‰‡æ¦‚è¿°&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;AIèŠ¯ç‰‡æŠ€æœ¯åŸç†å‰–æï¼ˆäºŒï¼‰ï¼šè‹±ä¼Ÿè¾¾GPU&lt;/li&gt; &#xA; &lt;li&gt;AIèŠ¯ç‰‡æŠ€æœ¯åŸç†å‰–æï¼ˆä¸‰ï¼‰ï¼šè°·æ­ŒTPU&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;AIé›†ç¾¤&lt;/h3&gt; &#xA;&lt;p&gt;å¾…æ›´æ–°...&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/tree/main/docs/llm-base/network-communication&#34;&gt;AIé›†ç¾¤ç½‘ç»œé€šä¿¡&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;å¾…æ›´æ–°...&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;åˆ†å¸ƒå¼è®­ç»ƒç½‘ç»œé€šè®¯åŸè¯­&lt;/li&gt; &#xA; &lt;li&gt;AI é›†ç¾¤é€šä¿¡è½¯ç¡¬ä»¶&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LLMOps&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/676389726&#34;&gt;åœ¨ Kubernetes ä¸Šéƒ¨ç½²æœºå™¨å­¦ä¹ æ¨¡å‹çš„æŒ‡å—&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7320513026188099619&#34;&gt;ä½¿ç”¨ Kubernetes éƒ¨ç½²æœºå™¨å­¦ä¹ æ¨¡å‹çš„ä¼˜åŠ¿&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LLMç”Ÿæ€ç›¸å…³æŠ€æœ¯&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/630696264&#34;&gt;å¤§æ¨¡å‹è¯è¡¨æ‰©å……å¿…å¤‡å·¥å…·SentencePiece&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/601594836/answer/3032763174&#34;&gt;å¤§æ¨¡å‹å®è·µæ€»ç»“&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/604393963/answer/3061358152&#34;&gt;ChatGLM å’Œ ChatGPT çš„æŠ€æœ¯åŒºåˆ«åœ¨å“ªé‡Œï¼Ÿ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/602504880/answer/3041965998&#34;&gt;ç°åœ¨ä¸ºä»€ä¹ˆé‚£ä¹ˆå¤šäººä»¥æ¸…åå¤§å­¦çš„ChatGLM-6Bä¸ºåŸºåº§è¿›è¡Œè¯•éªŒï¼Ÿ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/616600181/answer/3195333332&#34;&gt;ä¸ºä»€ä¹ˆå¾ˆå¤šæ–°å‘å¸ƒçš„å¤§æ¨¡å‹é»˜è®¤ä½¿ç”¨BF16è€Œä¸æ˜¯FP16ï¼Ÿ&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E7%9B%AE%E5%BD%95&#34;&gt;â¬† ä¸€é”®è¿”å›ç›®å½•&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;æœåŠ¡å™¨åŸºç¡€ç¯å¢ƒå®‰è£…åŠå¸¸ç”¨å·¥å…·&lt;/h2&gt; &#xA;&lt;p&gt;åŸºç¡€ç¯å¢ƒå®‰è£…ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/docs/llm-base/a800-env-install.md&#34;&gt;è‹±ä¼Ÿè¾¾A800åŠ é€Ÿå¡å¸¸è§è½¯ä»¶åŒ…å®‰è£…å‘½ä»¤&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/docs/llm-base/h800-env-install.md&#34;&gt;è‹±ä¼Ÿè¾¾H800åŠ é€Ÿå¡å¸¸è§è½¯ä»¶åŒ…å®‰è£…å‘½ä»¤&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/docs/llm_localization/ascend910-env-install.md&#34;&gt;æ˜‡è…¾910åŠ é€Ÿå¡å¸¸è§è½¯ä»¶åŒ…å®‰è£…å‘½ä»¤&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;å¸¸ç”¨å·¥å…·ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/6992742028605915150&#34;&gt;Linux å¸¸è§å‘½ä»¤å¤§å…¨&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7089093437223338015&#34;&gt;Conda å¸¸ç”¨å‘½ä»¤å¤§å…¨&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/6999405667261874183&#34;&gt;Poetry å¸¸ç”¨å‘½ä»¤å¤§å…¨&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7016238524286861325&#34;&gt;Docker å¸¸ç”¨å‘½ä»¤å¤§å…¨&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7016595442062327844&#34;&gt;Docker Dockerfile æŒ‡ä»¤å¤§å…¨&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/7031201391553019911&#34;&gt;Kubernetes å¸¸ç”¨å‘½ä»¤å¤§å…¨&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liguodongiot/llm-action/raw/main/docs/llm-base/dcgmi.md&#34;&gt;é›†ç¾¤ç¯å¢ƒ GPU ç®¡ç†å’Œç›‘æ§å·¥å…· DCGM å¸¸ç”¨å‘½ä»¤å¤§å…¨&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LLMå­¦ä¹ äº¤æµç¾¤&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘åˆ›å»ºäº†å¤§æ¨¡å‹å­¦ä¹ äº¤æµç¾¤ï¼Œä¾›å¤§å®¶ä¸€èµ·å­¦ä¹ äº¤æµå¤§æ¨¡å‹ç›¸å…³çš„æœ€æ–°æŠ€æœ¯ï¼Œç›®å‰å·²æœ‰5ä¸ªç¾¤ï¼Œæ¯ä¸ªç¾¤éƒ½æœ‰ä¸Šç™¾äººçš„è§„æ¨¡ï¼Œ&lt;strong&gt;å¯åŠ æˆ‘å¾®ä¿¡è¿›ç¾¤&lt;/strong&gt;ï¼ˆåŠ å¾®ä¿¡è¯·å¤‡æ³¨æ¥æ„ï¼Œå¦‚ï¼šè¿›å¤§æ¨¡å‹å­¦ä¹ äº¤æµç¾¤+GitHubï¼‰ã€‚&lt;strong&gt;ä¸€å®šè¦å¤‡æ³¨å“Ÿï¼Œå¦åˆ™ä¸äºˆé€šè¿‡&lt;/strong&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;PSï¼š&lt;strong&gt;æˆéƒ½æœ‰ä¸ªæœ¬åœ°å¤§æ¨¡å‹äº¤æµç¾¤ï¼Œæƒ³è¿›å¯ä»¥å¦å¤–å•ç‹¬å¤‡æ³¨ä¸‹ã€‚&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/liguodongiot/llm-action/raw/main/pic/wx.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;å¾®ä¿¡å…¬ä¼—å·&lt;/h2&gt; &#xA;&lt;p&gt;å¾®ä¿¡å…¬ä¼—å·ï¼š&lt;strong&gt;åƒæœå†»ä¸åæœå†»çš®&lt;/strong&gt;ï¼Œè¯¥å…¬ä¼—å·ä¸»è¦åˆ†äº«AIå·¥ç¨‹åŒ–ï¼ˆå¤§æ¨¡å‹ã€MLOpsç­‰ï¼‰ç›¸å…³å®è·µç»éªŒï¼Œå…è´¹ç”µå­ä¹¦ç±ã€è®ºæ–‡ç­‰ã€‚&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/liguodongiot/llm-action/raw/main/pic/wx-gzh.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/liguodongiot/llm-action/main/#%E7%9B%AE%E5%BD%95&#34;&gt;â¬† ä¸€é”®è¿”å›ç›®å½•&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#liguodongiot/llm-action&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=liguodongiot/llm-action&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>