<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-17T01:43:15Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>system76/virgo</title>
    <updated>2023-07-17T01:43:15Z</updated>
    <id>tag:github.com,2023-07-17:/system76/virgo</id>
    <link href="https://github.com/system76/virgo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;System76 Virgo Laptop Project&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;System76 Virgo Laptop Project&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the KiCad electrical design of the System76 Virgo laptop.&lt;/p&gt; &#xA;&lt;h2&gt;LICENSE&lt;/h2&gt; &#xA;&lt;p&gt;Hardware design files produced by System76 are licensed &lt;a href=&#34;https://raw.githubusercontent.com/system76/virgo/main/LICENSE-HARDWARE&#34;&gt;CERN-OHL-S-2.0&lt;/a&gt;. This license is recommended for open hardware by a number of organizations, and can be seen as the hardware equivalent of using the GPLv3 license on software.&lt;/p&gt; &#xA;&lt;p&gt;Software source files produced by System76 are licensed &lt;a href=&#34;https://raw.githubusercontent.com/system76/virgo/main/LICENSE-SOFTWARE&#34;&gt;GPL-3.0-only&lt;/a&gt;. To disambiguate the licensing, these files will also have an SPDX identifier.&lt;/p&gt; &#xA;&lt;p&gt;Third party files of varying licenses, compatible with redistribution, will be included in the third-party folder, with a note of their proper license.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>baaivision/Emu</title>
    <updated>2023-07-17T01:43:15Z</updated>
    <id>tag:github.com,2023-07-17:/baaivision/Emu</id>
    <link href="https://github.com/baaivision/Emu" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Emu: An Open Multimodal Generalist&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;Emu: An Open Multimodal Generalist &lt;/h1&gt;&#xA; &lt;h3&gt;&lt;a href=&#34;https://arxiv.org/abs/2307.05222&#34;&gt;Generative Pretraining in Multimodality&lt;/a&gt;&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/Quan-Sun&#34;&gt;Quan Sun&lt;/a&gt;&lt;sup&gt;1*&lt;/sup&gt;, &lt;a href=&#34;https://yqy2001.github.io&#34;&gt;Qiying Yu&lt;/a&gt;&lt;sup&gt;2,1*&lt;/sup&gt;, &lt;a href=&#34;&#34;&gt;Yufeng Cui&lt;/a&gt;&lt;sup&gt;1*&lt;/sup&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=VsJ39HMAAAAJ&#34;&gt;Fan Zhang&lt;/a&gt;&lt;sup&gt;1*&lt;/sup&gt;, &lt;a href=&#34;https://github.com/zhangxiaosong18&#34;&gt;Xiaosong Zhang&lt;/a&gt;&lt;sup&gt;1*&lt;/sup&gt;, &lt;a href=&#34;&#34;&gt;Yueze Wang&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;, &lt;a href=&#34;https://hongcheng-gao.github.io/&#34;&gt;Hongcheng Gao&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;,&lt;br&gt;&lt;a href=&#34;https://air.tsinghua.edu.cn/en/info/1046/1194.htm&#34;&gt;Jingjing Liu&lt;/a&gt;&lt;sup&gt;2&lt;/sup&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=knvEK4AAAAAJ&amp;amp;hl=en&#34;&gt;Tiejun Huang&lt;/a&gt;&lt;sup&gt;1,3&lt;/sup&gt;, &lt;a href=&#34;https://www.xloong.wang/&#34;&gt;Xinlong Wang&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; &lt;a href=&#34;https://www.baai.ac.cn/english.html&#34;&gt;BAAI&lt;/a&gt;, &lt;sup&gt;2&lt;/sup&gt; &lt;a href=&#34;https://air.tsinghua.edu.cn&#34;&gt;THU&lt;/a&gt;, &lt;sup&gt;3&lt;/sup&gt; &lt;a href=&#34;https://english.pku.edu.cn/&#34;&gt;PKU&lt;/a&gt; &lt;br&gt;&lt;sup&gt;*&lt;/sup&gt; Equal Contribution&lt;/p&gt; &#xA; &lt;p&gt;| &lt;a href=&#34;https://arxiv.org/abs/2307.05222&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://emu.ssi.plus/&#34;&gt;Demo&lt;/a&gt; |&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;strong&gt;Emu is a multimodal generalist that can seamlessly generate images and texts in multimodal context&lt;/strong&gt;. &lt;strong&gt;Emu&lt;/strong&gt; is trained with a unified autoregressive objective, &lt;em&gt;i.e.&lt;/em&gt;, predict-the-next-element, including both visual embeddings and textual tokens. Trained under this objective, &lt;strong&gt;Emu&lt;/strong&gt; can serve as a generalist interface for both image-to-text and text-to-image tasks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/baaivision/Emu/main/assets/Emu.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Generalist Interface&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Emu&lt;/strong&gt; serves as a generalist interface capable of diverse multimodal tasks, such as image captioning, image/video question answering, and text-to-image generation, together with new abilities like in-context text and image generation, and image blending:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/baaivision/Emu/main/assets/generalist.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;Clone this repository and install required packages:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/baaivision/Emu&#xA;cd Emu&#xA;&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Model Weights&lt;/h2&gt; &#xA;&lt;p&gt;We release the pretrained and instruction-tuned weights of &lt;strong&gt;Emu&lt;/strong&gt;. Our weights are subject to LLaMA&#39;s &lt;a href=&#34;https://github.com/facebookresearch/llama/raw/main/LICENSE&#34;&gt;license&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model name&lt;/th&gt; &#xA;   &lt;th&gt;Weight&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Emu&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/BAAI/Emu/blob/main/Emu-pretrain.pt&#34;&gt;ü§ó HF link&lt;/a&gt; (27GB)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Emu-I&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/BAAI/Emu/blob/main/Emu-instruct.pt&#34;&gt;ü§ó HF link&lt;/a&gt; (27GB)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;p&gt;At present, we provide inference code that can process interleaved image-text as input, and output text.&lt;/p&gt; &#xA;&lt;p&gt;For instruction-tuned model, we provide examples for image captioning, visual question answering, and interleaved multi-image understanding:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python inference.py --instruct --ckpt-path $Instruct_CKPT_PATH&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For pretrained model, we provide an example for in-context learning:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python inference.py --ckpt-path $Pretrain_CKPT_PATH&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Schedule&lt;/h2&gt; &#xA;&lt;p&gt;We are committed to open-sourcing all Emu related materials, including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; The weights of &lt;strong&gt;Emu&lt;/strong&gt; and &lt;strong&gt;Emu-I&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Inference example for interleaved image-text as input, text as output&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Video inference example&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Weights of image decoder &amp;amp; image generation/blending example&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; YT-Storyboard-1B pretraining data&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Pretraining code&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Instruction tuning code&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Evaluation code&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We hope to foster the growth of our community through open-sourcing and promoting collaborationüë¨. Let&#39;s step towards multimodal intelligence togetherüçª.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;We thank the great work from &lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;LLaMA&lt;/a&gt;, &lt;a href=&#34;https://github.com/salesforce/LAVIS&#34;&gt;BLIP-2&lt;/a&gt;, &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt;, and &lt;a href=&#34;https://github.com/lm-sys/FastChat&#34;&gt;FastChat&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find Emu useful for your research and applications, please consider starring this repository and citing:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{Emu,&#xA;  title={Generative Pretraining in Multimodality},&#xA;  author={Sun, Quan and Yu, Qiying and Cui, Yufeng and Zhang, Fan and Zhang, Xiaosong and Wang, Yueze and Gao, Hongcheng and Liu, Jingjing and Huang, Tiejun and Wang, Xinlong},&#xA;  publisher={arXiv preprint arXiv:2307.05222},&#xA;  year={2023},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Misc&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/baaivision/Emu/stargazers&#34;&gt;&lt;img src=&#34;https://reporoster.com/stars/baaivision/Emu&#34; alt=&#34;Stargazers repo roster for @baaivision/Emu&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/baaivision/Emu/network/members&#34;&gt;&lt;img src=&#34;https://reporoster.com/forks/baaivision/Emu&#34; alt=&#34;Forkers repo roster for @baaivision/Emu&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://star-history.com/#baaivision/Emu&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=baaivision/Emu&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>filip-michalsky/SalesGPT</title>
    <updated>2023-07-17T01:43:15Z</updated>
    <id>tag:github.com,2023-07-17:/filip-michalsky/SalesGPT</id>
    <link href="https://github.com/filip-michalsky/SalesGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Context-aware AI Sales Agent to automate sales outreach.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;span&gt;ü§ñ&lt;/span&gt; SalesGPT - Your Context-Aware AI Sales Assistant&lt;/h1&gt; &#xA;&lt;p&gt;This repo demonstrates an implementation of a &lt;strong&gt;context-aware&lt;/strong&gt; AI Sales Assistant using LLMs.&lt;/p&gt; &#xA;&lt;p&gt;SalesGPT is context-aware, which means it can understand what section of a sales conversation it is in and act accordingly. Morever, SalesGPT has access to tools, such as your own pre-defined product knowledge base, significantly reducing hallucinations!&lt;/p&gt; &#xA;&lt;p&gt;We leverage the &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;&lt;code&gt;langchain&lt;/code&gt;&lt;/a&gt; library in this implementation, specifically &lt;a href=&#34;https://langchain-langchain.vercel.app/docs/modules/agents/how_to/custom_agent_with_tool_retrieval&#34;&gt;Custom Agent Configuration&lt;/a&gt; and are inspired by &lt;a href=&#34;https://github.com/yoheinakajima/babyagi&#34;&gt;BabyAGI&lt;/a&gt; architecture.&lt;/p&gt; &#xA;&lt;h2&gt;Our Vision: Build the Best Open-Source Autonomous Sales Agent&lt;/h2&gt; &#xA;&lt;p&gt;We are building SalesGPT to power your best Autonomous Sales Agents. Hence, we would love to learn more about use cases you are building towards which will fuel SalesGPT development roadmap.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;If you want us to build better towards your needs, please fill out our 45 seconds &lt;a href=&#34;https://5b7mfhwiany.typeform.com/to/xmJbWIjG&#34;&gt;SalesGPT Use Case Survey&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;If you looking for help building your Autonomous Sales Agents&lt;/h3&gt; &#xA;&lt;p&gt;I am currently open to freelancing opps - please contact me through &lt;a href=&#34;https://odysseypartners.ai?utm_source=SalesGPT&#34;&gt;my website&lt;/a&gt; if you think I can help you.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;üî¥&lt;/span&gt; Latest News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Sales Agent can now take advantage of &lt;strong&gt;tools&lt;/strong&gt;, such as look up products in a product catalog!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Demo: SalesGPT Outbound Prospecting: A New Way to Sell? ü§î&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/filip-michalsky/SalesGPT/assets/31483888/2b13ba28-4e07-41dc-a8bf-4084d25247ca&#34;&gt;https://github.com/filip-michalsky/SalesGPT/assets/31483888/2b13ba28-4e07-41dc-a8bf-4084d25247ca&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os&#xA;from salesgpt.agents import SalesGPT&#xA;from langchain.chat_models import ChatOpenAI&#xA;&#xA;os.environ[&#39;OPENAI_API_KEY&#39;] = &#39;sk-xxx&#39; # fill me in&#xA;&#xA;llm = ChatOpenAI(temperature=0.4)&#xA;                            &#xA;sales_agent = SalesGPT.from_llm(llm, use_tools=True, verbose=False,&#xA;                            product_catalog = &#34;examples/sample_product_catalog.txt&#34;,&#xA;                            salesperson_name=&#34;Ted Lasso&#34;,&#xA;                            salesperson_role=&#34;Sales Representative&#34;,&#xA;                            company_name=&#34;Sleep Haven&#34;,&#xA;                            company_business=&#39;&#39;&#39;Sleep Haven &#xA;                            is a premium mattress company that provides&#xA;                            customers with the most comfortable and&#xA;                            supportive sleeping experience possible. &#xA;                            We offer a range of high-quality mattresses,&#xA;                            pillows, and bedding accessories &#xA;                            that are designed to meet the unique &#xA;                            needs of our customers.&#39;&#39;&#39;&#xA;                            )&#xA;sales_agent.seed_agent()&#xA;sales_agent.determine_conversation_stage() # optional for demonstration, built into the prompt&#xA;&#xA;# agent &#xA;sales_agent.step()&#xA;&#xA;# user&#xA;user_input = input(&#39;Your response: &#39;) # Yea, sure&#xA;sales_agent.human_step(user_input)&#xA;&#xA;# agent&#xA;sales_agent.determine_conversation_stage() # optional for demonstration, built into the prompt&#xA;sales_agent.step()&#xA;&#xA;# user&#xA;user_input = input(&#39;Your response: &#39;) # What pricing do you have for your mattresses?&#xA;sales_agent.human_step(user_input)&#xA;&#xA;# agent&#xA;sales_agent.determine_conversation_stage() # optional for demonstration, built into the prompt&#xA;sales_agent.step()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Conversation Stage: Introduction: Start the conversation by introducing yourself and your company.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Thought: Do I need to use a tool? No &lt;br&gt; Ted Lasso: Hello, my name is Ted Lasso and I&#39;m calling on behalf of Sleep Haven. We are a premium mattress company that provides customers with the most comfortable and supportive sleeping experience possible. I was wondering if you would be interested in learning more about our products and how they can improve your sleep?&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;User: Yea, sure&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Conversation Stage: Value proposition: Briefly explain how your product/service can benefit the prospect.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Thought: Do I need to use a tool? No &lt;br&gt; Ted Lasso: Great to hear that! Our mattresses are specially designed to contour to your body shape, providing the perfect level of support and comfort for a better night&#39;s sleep. Plus, they&#39;re made with high-quality materials that are built to last. Would you like to hear more about our different mattress options?&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;User: What pricing do you have for your mattresses?&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Thought: Do I need to use a tool? Yes --&amp;gt; AI Agent uses tools here.&lt;br&gt; Action: ProductSearch&lt;br&gt; ActionInput pricing for mattresses&lt;br&gt; Observation: Sleep Haven offers three mattresses: the Classic Harmony Spring Mattress for $1,299, the Plush Serenity Bamboo Mattress for $2,599, and the Luxury Cloud-Comfort Memory Foam Mattress for $999. The sizes available vary by mattress.&lt;br&gt; Ted Lasso: Sleep Haven offers three mattresses at different price points. The Classic Harmony Spring Mattress is priced at $1,299, the Plush Serenity Bamboo Mattress is priced at $2,599, and the Luxury Cloud-Comfort Memory Foam Mattress is priced at $999. The prices may vary depending on the size you choose. Would you like more information about the specific sizes and features of each mattress?&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Product Knowledge Base&lt;/h2&gt; &#xA;&lt;p&gt;The AI Sales Agent has access to tools, such as your internal Product Knowledge base. This allows the agent to only talk about your own products and significantly reduces hallucinations.&lt;/p&gt; &#xA;&lt;h2&gt;Understanding Context&lt;/h2&gt; &#xA;&lt;p&gt;The AI Sales Agent understands the conversation stage (you can define your own stages fitting your needs):&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Introduction: Start the conversation by introducing yourself and your company.&lt;/li&gt; &#xA; &lt;li&gt;Qualification: Qualify the prospect by confirming if they are the right person to talk to regarding your product/service.&lt;/li&gt; &#xA; &lt;li&gt;Value proposition: Briefly explain how your product/service can benefit the prospect.&lt;/li&gt; &#xA; &lt;li&gt;Needs analysis: Ask open-ended questions to uncover the prospect&#39;s needs and pain points.&lt;/li&gt; &#xA; &lt;li&gt;Solution presentation: Based on the prospect&#39;s needs, present your product/service as the solution that can address their pain points.&lt;/li&gt; &#xA; &lt;li&gt;Objection handling: Address any objections that the prospect may have regarding your product/service.&lt;/li&gt; &#xA; &lt;li&gt;Close: Ask for the sale by proposing a next step.&lt;/li&gt; &#xA; &lt;li&gt;End Conversation: The user does not want to continue the conversation, so end the call.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;As such, this agent can have a natural sales conversation with a prospect and behaves based on the conversation stage. Hence, this notebook demonstrates how we can use AI to automate sales development representatives activites, such as outbound sales calls.&lt;/p&gt; &#xA;&lt;h2&gt;Architecture&lt;/h2&gt; &#xA;&lt;img src=&#34;https://singularity-assets-public.s3.amazonaws.com/new_flow.png&#34; width=&#34;800&#34; height=&#34;440&#34;&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Make sure your have a python 3.10+ and run:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Create &lt;code&gt;.env&lt;/code&gt; file and put your Open AI Key there by specifying a line:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;OPENAI_API_KEY=sk-xxx&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Install with pip&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;pip install salesgpt&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Try it out&lt;/h2&gt; &#xA;&lt;p&gt;To get a feel for a conversation with the AI Sales agent, you can run:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;python run.py --verbose True --config examples/example_agent_setup.json&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;from your terminal.&lt;/p&gt; &#xA;&lt;h2&gt;Contact Us&lt;/h2&gt; &#xA;&lt;p&gt;For questions, you can &lt;a href=&#34;mailto:filipmichalsky@gmail.com&#34;&gt;contact the repo author&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Follow me at &lt;a href=&#34;https://twitter.com/FilipMichalsky&#34;&gt;@FilipMichalsky&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;SalesGPT Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Add the ability of Sales Agent to interact with AI plugins on your website (.well-known/ai-plugin.json)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;What tools should the agent have? (e.g., the ability to search the internet)&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;del&gt;- Add the ability to stop generation when user interupts the agent&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;- Add a vectorstore to incorporate a real product knowledge base vs. the LLM making it up.&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;- Knowledge base for products/services a Sales Agent can offer (so that LLM does not make it up)&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;- Convert LLM Chains (linear workflow) to an Agent (decides what to do based on user&#39;s input)&lt;/del&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are highly encouraged! Please fork and submit a PR.&lt;/p&gt;</summary>
  </entry>
</feed>