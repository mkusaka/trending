<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-23T01:35:06Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>loganmarchione/homelab-svg-assets</title>
    <updated>2022-12-23T01:35:06Z</updated>
    <id>tag:github.com,2022-12-23:/loganmarchione/homelab-svg-assets</id>
    <link href="https://github.com/loganmarchione/homelab-svg-assets" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Full-color SVG icons of homelab-related software, products, and brands&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;homelab-svg-assets&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/loganmarchione/homelab-svg-assets/tree/main/assets&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/directory-file-count/loganmarchione/homelab-svg-assets/assets?extension=svg&amp;amp;label=Total%20Icons&amp;amp;type=file&#34; alt=&#34;Total Icons&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/loganmarchione/homelab-svg-assets&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/repo-size/loganmarchione/homelab-svg-assets??label=Repo%20Size&#34; alt=&#34;Repo Size&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/loganmarchione/homelab-svg-assets/actions/workflows/main.yml&#34;&gt;&lt;img src=&#34;https://github.com/loganmarchione/homelab-svg-assets/actions/workflows/main.yml/badge.svg?sanitize=true&#34; alt=&#34;Python_Lint&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/loganmarchione/homelab-svg-assets/tags&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/tag/loganmarchione/homelab-svg-assets?color=green&amp;amp;logo=github&amp;amp;label=Latest%20GitHub%20Tag&amp;amp;sort=semver&#34; alt=&#34;Latest GitHub Tag&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://packagist.org/packages/loganmarchione/homelab-svg-assets&#34;&gt;&lt;img src=&#34;https://img.shields.io/packagist/v/loganmarchione/homelab-svg-assets?color=green&amp;amp;logo=packagist&amp;amp;logoColor=white&amp;amp;label=Latest%20Packagist%20Version&#34; alt=&#34;Latest Packagist Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.npmjs.com/package/@loganmarchione/homelab-svg-assets&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/@loganmarchione/homelab-svg-assets?color=green&amp;amp;logo=npm&amp;amp;label=Latest%20NPM%20Version&#34; alt=&#34;Latest NPM Version&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Over 350 full-color SVG icons of homelab-related software, products, and brands in a normalized size.&lt;/p&gt; &#xA;&lt;h1&gt;Table of Contents&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/#table-of-contents&#34;&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/#usage&#34;&gt;Usage&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/#general-usage&#34;&gt;General usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/#diagramsnet-usage&#34;&gt;Diagrams.net usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/#cdn-usage&#34;&gt;CDN usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/#php-usage&#34;&gt;PHP usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/#npm-usage&#34;&gt;NPM usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/#hugo-usage&#34;&gt;Hugo usage&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/#legal&#34;&gt;Legal&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/#other-icon-sets&#34;&gt;Other icon sets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/#todo&#34;&gt;TODO&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;p&gt;‚ö†Ô∏è All users should read the &lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/DISCLAIMER.md&#34;&gt;disclaimer&lt;/a&gt; before using this project. ‚ö†Ô∏è&lt;/p&gt; &#xA;&lt;h2&gt;General usage&lt;/h2&gt; &#xA;&lt;p&gt;Icons as SVGs are available in the &lt;a href=&#34;https://github.com/loganmarchione/homelab-svg-assets/tree/main/assets&#34;&gt;assets&lt;/a&gt; directory. See &lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/ICONS.md&#34;&gt;ICONS.md&lt;/a&gt; for a preview of all icons.&lt;/p&gt; &#xA;&lt;h2&gt;Diagrams.net usage&lt;/h2&gt; &#xA;&lt;p&gt;In a &lt;a href=&#34;https://app.diagrams.net/&#34;&gt;Diagrams.net&lt;/a&gt; project, go to &lt;code&gt;File--&amp;gt;Open Library from--&amp;gt;URL&lt;/code&gt; and paste in the URL below (it will take a second to load)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/homelab-svg-assets.xml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also start brand new project with the library built-in to the URL by using &lt;a href=&#34;https://app.diagrams.net/?clibs=Uhttps%3A%2F%2Fraw.githubusercontent.com%2Floganmarchione%2Fhomelab-svg-assets%2Fmain%2Fhomelab-svg-assets.xml&#34;&gt;this link&lt;/a&gt; (also below)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;https://app.diagrams.net/?clibs=Uhttps%3A%2F%2Fraw.githubusercontent.com%2Floganmarchione%2Fhomelab-svg-assets%2Fmain%2Fhomelab-svg-assets.xml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you self-host Diagrams.net (it is available as a &lt;a href=&#34;https://hub.docker.com/r/jgraph/drawio&#34;&gt;Docker container&lt;/a&gt;), you can replace the domain with your custom domain&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;https://drawio.yourdomain.com/?clibs=Uhttps%3A%2F%2Fraw.githubusercontent.com%2Floganmarchione%2Fhomelab-svg-assets%2Fmain%2Fhomelab-svg-assets.xml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;CDN usage&lt;/h2&gt; &#xA;&lt;p&gt;Icons are available via &lt;a href=&#34;https://www.jsdelivr.com/package/npm/@loganmarchione/homelab-svg-assets&#34;&gt;jsDelivr&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Replace the icon name as needed. You can also replace &lt;code&gt;latest&lt;/code&gt; with a specific version.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;img height=&#34;48&#34; width=&#34;48&#34; src=&#34;https://cdn.jsdelivr.net/npm/@loganmarchione/homelab-svg-assets@latest/assets/linux.svg&#34;/&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;PHP usage&lt;/h2&gt; &#xA;&lt;p&gt;Icons are available in PHP as a package on &lt;a href=&#34;https://packagist.org/packages/loganmarchione/homelab-svg-assets&#34;&gt;Packagist&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Run &lt;code&gt;composer require loganmarchione/homelab-svg-assets&lt;/code&gt;, or add the package to your &lt;code&gt;composer.json&lt;/code&gt; file (below)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;{&#xA;    &#34;require&#34;: {&#xA;        &#34;loganmarchione/homelab-svg-assets&#34;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Icons will be available at &lt;code&gt;./vendor/loganmarchione/homelab-svg-assets/assets/linux.svg&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;NPM usage&lt;/h2&gt; &#xA;&lt;p&gt;Icons are available as a package on &lt;a href=&#34;https://www.npmjs.com/package/@loganmarchione/homelab-svg-assets&#34;&gt;NPM&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Run &lt;code&gt;npm install @loganmarchione/homelab-svg-assets&lt;/code&gt;, or add the package to your &lt;code&gt;package.json&lt;/code&gt; file (below)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;{&#xA;  &#34;dependencies&#34;: {&#xA;    &#34;@loganmarchione/homelab-svg-assets&#34;: &#34;*&#34;&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Icons will be available at &lt;code&gt;./node_modules/@loganmarchione/homelab-svg-assets/assets/linux.svg&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Hugo usage&lt;/h2&gt; &#xA;&lt;p&gt;There is a &lt;a href=&#34;https://github.com/loganmarchione/homelab-svg-assets/raw/main/go.mod&#34;&gt;go.mod&lt;/a&gt; file, so this icon pack can be used as a &lt;a href=&#34;https://gohugo.io/hugo-modules/&#34;&gt;Hugo module&lt;/a&gt;. You need to be using at least Hugo &lt;a href=&#34;https://gohugo.io/news/0.56.0-relnotes/&#34;&gt;0.56.0&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In your Hugo site directory, initialize your site as a module:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;hugo mod init foo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In your &lt;code&gt;config.yaml&lt;/code&gt; (adjust for &lt;code&gt;.json&lt;/code&gt; or &lt;code&gt;.toml&lt;/code&gt; configuration files), add the section below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;module:&#xA;  imports:&#xA;    - path: github.com/loganmarchione/homelab-svg-assets&#xA;      mounts:&#xA;        - source: assets&#xA;          target: assets/svg/homelab-svg-assets&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Download the module:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;hugo mod get -u&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create a shortcode in the location below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;layouts/shortcodes/homelab.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Copy/paste the following code into the shortcode (you can apply custom CSS using the class &lt;code&gt;blah&lt;/code&gt; in the example):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;{{/*Get the parameters */}}&#xA;{{ $path := (.Get &#34;src&#34;) }}&#xA;&#xA;{{/* Concat to create the correct path */}}&#xA;{{- $icon := resources.Get (print &#34;svg/homelab-svg-assets/&#34; $path &#34;.svg&#34; ) -}}&#xA;&#xA;&amp;lt;span class=&#34;blah&#34;&amp;gt;{{- $icon.Content | safeHTML -}}&amp;lt;/span&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, in your markdown files, you can reference the icon:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;{{&amp;lt; homelab src=&#34;linux&#34; &amp;gt;}}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Legal&lt;/h1&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/DISCLAIMER.md&#34;&gt;DISCLAIMER.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Other icon sets&lt;/h1&gt; &#xA;&lt;p&gt;It would be remiss of me if I did not mention other great icons sets&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://simpleicons.org/&#34;&gt;Simple Icons&lt;/a&gt; - Monochromatic SVG icons for popular brands&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://icons.getbootstrap.com/&#34;&gt;Bootstrap Icons&lt;/a&gt; - Mostly generic icons, but some brand icons&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fontawesome.com/icons&#34;&gt;Font Awesome&lt;/a&gt; - Mix of generic and brand icons&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://devicon.dev/&#34;&gt;Devicon&lt;/a&gt; - Icons representing programming languages, designing &amp;amp; development tools&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;TODO&lt;/h1&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/loganmarchione/homelab-svg-assets/main/TODO.md&#34;&gt;TODO.md&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>openai/point-e</title>
    <updated>2022-12-23T01:35:06Z</updated>
    <id>tag:github.com,2022-12-23:/openai/point-e</id>
    <link href="https://github.com/openai/point-e" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Point cloud diffusion for 3D model synthesis&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Point¬∑E&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/openai/point-e/main/point_e/examples/paper_banner.gif&#34; alt=&#34;Animation of four 3D point clouds rotating&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is the official code and model release for &lt;a href=&#34;https://arxiv.org/abs/2212.08751&#34;&gt;Point-E: A System for Generating 3D Point Clouds from Complex Prompts&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;p&gt;Install with &lt;code&gt;pip install -e .&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To get started with examples, see the following notebooks:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/point-e/main/point_e/examples/image2pointcloud.ipynb&#34;&gt;image2pointcloud.ipynb&lt;/a&gt; - sample a point cloud, conditioned on some example synthetic view images.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/point-e/main/point_e/examples/text2pointcloud.ipynb&#34;&gt;text2pointcloud.ipynb&lt;/a&gt; - use our small, worse quality pure text-to-3D model to produce 3D point clouds directly from text descriptions. This model&#39;s capabilities are limited, but it does understand some simple categories and colors.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/point-e/main/point_e/examples/pointcloud2mesh.ipynb&#34;&gt;pointcloud2mesh.ipynb&lt;/a&gt; - try our SDF regression model for producing meshes from point clouds.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For our P-FID and P-IS evaluation scripts, see:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/point-e/main/point_e/evals/scripts/evaluate_pfid.py&#34;&gt;evaluate_pfid.py&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/point-e/main/point_e/evals/scripts/evaluate_pis.py&#34;&gt;evaluate_pis.py&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For our Blender rendering code, see &lt;a href=&#34;https://raw.githubusercontent.com/openai/point-e/main/point_e/evals/scripts/blender_script.py&#34;&gt;blender_script.py&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Samples&lt;/h1&gt; &#xA;&lt;p&gt;You can download the seed images and point clouds corresponding to the paper banner images &lt;a href=&#34;https://openaipublic.azureedge.net/main/point-e/banner_pcs.zip&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can download the seed images used for COCO CLIP R-Precision evaluations &lt;a href=&#34;https://openaipublic.azureedge.net/main/point-e/coco_images.zip&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ldkong1205/RoboDepth</title>
    <updated>2022-12-23T01:35:06Z</updated>
    <id>tag:github.com,2022-12-23:/ldkong1205/RoboDepth</id>
    <link href="https://github.com/ldkong1205/RoboDepth" rel="alternate"></link>
    <summary type="html">&lt;p&gt;RoboDepth: Robust Out-of-Distribution Depth Estimation under Common Corruptions&lt;/p&gt;&lt;hr&gt;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/docs/figs/logo.png&#34; align=&#34;center&#34; width=&#34;32%&#34;&gt; &lt;/p&gt;&#xA;&lt;h3 align=&#34;center&#34;&gt;&lt;strong&gt;RoboDepth: Robust Out-of-Distribution Depth Estimation under Common Corruptions&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://scholar.google.com/citations?user=-j1j7TkAAAAJ&#34;&gt;Lingdong Kong&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;&amp;nbsp; &lt;a href=&#34;https://github.com/Daniel-xsy&#34;&gt;Shaoyuan Xie&lt;/a&gt;&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp; &lt;a href=&#34;https://scholar.google.com/citations?user=UyooQDYAAAAJ&#34;&gt;Hanjiang Hu&lt;/a&gt;&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp; &lt;a href=&#34;https://scholar.google.com/citations?user=9I7uKooAAAAJ&#34;&gt;Benoit Cottereau&lt;/a&gt;&lt;sup&gt;4&lt;/sup&gt;&amp;nbsp; &lt;a href=&#34;&#34;&gt;Lai Xing Ng&lt;/a&gt;&lt;sup&gt;5&lt;/sup&gt;&amp;nbsp; &lt;a href=&#34;https://scholar.google.com/citations?user=nFP2ldkAAAAJ&#34;&gt;Wei Tsang Ooi&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;&amp;nbsp; &lt;br&gt; &lt;sup&gt;1&lt;/sup&gt;National University of Singapore&amp;nbsp;&amp;nbsp; &lt;sup&gt;2&lt;/sup&gt;Huazhong Univerisity of Science and Technology&lt;br&gt; &lt;sup&gt;3&lt;/sup&gt;Carnegie Mellon University&amp;nbsp;&amp;nbsp; &lt;sup&gt;4&lt;/sup&gt;CNRS&amp;nbsp;&amp;nbsp; &lt;sup&gt;5&lt;/sup&gt;A*STAR &lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Paper-%F0%9F%93%83-blue&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://ldkong.com/RoboDepth&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Project-%F0%9F%94%97-lightblue&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/ldkong/RoboDepth&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Demo-%F0%9F%8E%AC-pink&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/592479725&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/%E4%B8%AD%E8%AF%91%E7%89%88-%F0%9F%90%BC-red&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;RoboDepth&lt;/strong&gt; is a comprehensive evaluation benchmark designed for probing the &lt;strong&gt;robustness&lt;/strong&gt; of monocular and stereo depth estimation algorithms. It includes &lt;strong&gt;18 common corruption&lt;/strong&gt; types, ranging from weather and lighting conditions, sensor failure and movement, and noises during data processing.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/docs/figs/taxonomy.png&#34; align=&#34;center&#34; width=&#34;95%&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Updates&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2022.11] - We are organizing the &lt;a href=&#34;https://robodepth.github.io/&#34;&gt;1st RoboDepth Competition&lt;/a&gt; at &lt;a href=&#34;https://www.icra2023.org/&#34;&gt;ICRA 2023&lt;/a&gt;. Join the challenge today! &lt;span&gt;üôã&lt;/span&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2022.11] - &lt;code&gt;KITTI-C&lt;/code&gt; is ready to be downloaded! See &lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/docs/DATA_PREPARE.md&#34;&gt;here&lt;/a&gt; for more details.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Outline&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/#data-preparation&#34;&gt;Data Preparation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/#getting-started&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/#model-zoo&#34;&gt;Model Zoo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/#create-corruption-sets&#34;&gt;Create Corruption Sets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/#todo-list&#34;&gt;TODO List&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/#citation&#34;&gt;Citation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/#acknowledgements&#34;&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/docs/INSTALL.md&#34;&gt;INSTALL.md&lt;/a&gt; for the installation details.&lt;/p&gt; &#xA;&lt;h2&gt;Data Preparation&lt;/h2&gt; &#xA;&lt;h3&gt;RoboDepth Benchmark&lt;/h3&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/docs/DATA_PREPARE.md&#34;&gt;DATA_PREPARE.md&lt;/a&gt; for the details to prepare the &lt;a href=&#34;http://www.cvlibs.net/datasets/kitti/raw_data.php&#34;&gt;KITTI&lt;/a&gt;, &lt;a href=&#34;&#34;&gt;KITTI-C&lt;/a&gt;, &lt;a href=&#34;&#34;&gt;Cityscapes&lt;/a&gt;, and &lt;a href=&#34;&#34;&gt;NYUDepth2&lt;/a&gt; datasets.&lt;/p&gt; &#xA;&lt;h3&gt;RoboDepth Competition @ ICRA 2023&lt;/h3&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/competition/COMPETITION.md&#34;&gt;COMPETITION.md&lt;/a&gt; for the details to prepare the training and evaluation data associated with the &lt;a href=&#34;https://robodepth.github.io/&#34;&gt;1st RoboDepth Competition&lt;/a&gt; at &lt;a href=&#34;https://www.icra2023.org/&#34;&gt;ICRA 2023&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/docs/GET_STARTED.md&#34;&gt;GET_STARTED.md&lt;/a&gt; to learn more usage about this codebase.&lt;/p&gt; &#xA;&lt;h2&gt;Model Zoo&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;span&gt;üöò&lt;/span&gt; - Outdoor Depth Estimation&lt;/h3&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;&amp;nbsp;&lt;b&gt;Self-Supervised Depth Estimation&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;blockquote&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;[x] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/1806.01260&#34;&gt;MonoDepth2&lt;/a&gt;, ICCV 2019.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/nianticlabs/monodepth2&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[x] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/1909.09051&#34;&gt;DepthHints&lt;/a&gt;, ICCV 2019.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/nianticlabs/depth-hints&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[x] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/1908.11112&#34;&gt;MaskOcc&lt;/a&gt;, arXiv 2019.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/schelv/monodepth2&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[x] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2004.05560&#34;&gt;DNet&lt;/a&gt;, IROS 2020.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/TJ-IPLab/DNet&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[x] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2112.13047&#34;&gt;CADepth&lt;/a&gt;, 3DV 2021.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/kamiLight/CADepth-master&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2110.08192&#34;&gt;TC-Depth&lt;/a&gt;, 3DV 2021.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/DaoyiG/TC-Depth&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[x] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2012.07356&#34;&gt;HR-Depth&lt;/a&gt;, AAAI 2021.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/shawLyu/HR-Depth&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2102.02629&#34;&gt;Insta-DM&lt;/a&gt;, AAAI 2021.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/SeokjuLee/Insta-DM&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[x] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/pdf/2110.09482.pdf&#34;&gt;DIFFNet&lt;/a&gt;, BMVC 2021.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/brandleyzhou/DIFFNet&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[x] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2104.14540&#34;&gt;ManyDepth&lt;/a&gt;, CVPR 2021.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/nianticlabs/manydepth&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2109.12484&#34;&gt;EPCDepth&lt;/a&gt;, ICCV 2021.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/prstrive/EPCDepth&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[x] &lt;strong&gt;&lt;a href=&#34;http://arxiv.org/abs/2108.08829&#34;&gt;FSRE-Depth&lt;/a&gt;, ICCV 2021.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/hyBlue/FSRE-Depth&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.07616&#34;&gt;DepthFormer&lt;/a&gt;, CVPR 2022.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/TRI-ML/vidar&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2207.04680&#34;&gt;DynaDepth&lt;/a&gt;, ECCV 2022.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/SenZHANG-GitHub/ekf-imu-depth&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.15174&#34;&gt;DynamicDepth&lt;/a&gt;, ECCV 2022.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/AutoAILab/DynamicDepth&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2207.11984&#34;&gt;RA-Depth&lt;/a&gt;, ECCV 2022.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/hmhemu/RA-Depth&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2206.03799&#34;&gt;Dyna-DM&lt;/a&gt;, arXiv 2022.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/kieran514/dyna-dm&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.00411&#34;&gt;TriDepth&lt;/a&gt;, WACV 2023.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/xingyuuchen/tri-depth&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.05479&#34;&gt;FreqAwareDepth&lt;/a&gt;, WACV 2023.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/xingyuuchen/freq-aware-depth&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA; &lt;/blockquote&gt; &#xA;&lt;/details&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;&amp;nbsp;&lt;b&gt;Fully-Supervised Depth Estimation&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;blockquote&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2011.14141&#34;&gt;AdaBins&lt;/a&gt;, CVPR 2021.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/zhyever/Monocular-Depth-Estimation-Toolbox/tree/main/configs/adabins&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.01502&#34;&gt;NeWCRFs&lt;/a&gt;, CVPR 2022.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/aliyun/NeWCRFs&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.14211&#34;&gt;DepthFormer&lt;/a&gt;, arXiv 2022.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/zhyever/Monocular-Depth-Estimation-Toolbox/tree/main/configs/depthformer&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2201.07436&#34;&gt;GLPDepth&lt;/a&gt;, arXiv 2022.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/vinvino02/GLPDepth&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA; &lt;/blockquote&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;&lt;span&gt;üè†&lt;/span&gt; - Indoor Depth Estimation&lt;/h3&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;&amp;nbsp;&lt;b&gt;Self-Supervised Depth Estimation&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;blockquote&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;[ ] Coming soon.&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA; &lt;/blockquote&gt; &#xA;&lt;/details&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;&amp;nbsp;&lt;b&gt;Fully-Supervised Depth Estimation&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;blockquote&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2011.14141&#34;&gt;AdaBins&lt;/a&gt;, CVPR 2021.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/zhyever/Monocular-Depth-Estimation-Toolbox/tree/main/configs/adabins&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.01502&#34;&gt;NeWCRFs&lt;/a&gt;, CVPR 2022.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/aliyun/NeWCRFs&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.02091&#34;&gt;P3Depth&lt;/a&gt;, CVPR 2022.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/SysCV/P3Depth&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.14211&#34;&gt;DepthFormer&lt;/a&gt;, arXiv 2022.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/zhyever/Monocular-Depth-Estimation-Toolbox/tree/main/configs/depthformer&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[ ] &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2201.07436&#34;&gt;GLPDepth&lt;/a&gt;, arXiv 2022.&lt;/strong&gt; &lt;sup&gt;&lt;a href=&#34;https://github.com/vinvino02/GLPDepth&#34;&gt;&lt;strong&gt;&lt;code&gt;[Code]&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA; &lt;/blockquote&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;&lt;span&gt;ü§ñ&lt;/span&gt; - RoboDepth Benchmark&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/docs/figs/benchmark.png&#34; align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/docs/MODEL_ZOO.md&#34;&gt;MODEL_ZOO.md&lt;/a&gt; for the detailed benchmarking results and to access the pretrained weights.&lt;/p&gt; &#xA;&lt;h2&gt;Create Corruption Sets&lt;/h2&gt; &#xA;&lt;p&gt;You can manage to create your own &#34;RoboDepth&#34; corrpution sets! Follow the instructions listed in &lt;a href=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/docs/CREATE.md&#34;&gt;CREATE.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;TODO List&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Initial release. üöÄ&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add scripts for creating common corruptions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add download link of KITTI-C.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add competition data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add evaluation scripts on corruption sets.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find this work helpful, please kindly consider citing our paper:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@ARTICLE{kong2022robodepth,&#xA;  title={RoboDepth: Robust Out-of-Distribution Depth Estimation under Common Corruptions},&#xA;  author={Kong, Lingdong and Xie, Shaoyuan and Hu, Hanjiang and Cottereau, Benoit and Ng, Lai Xing and Ooi, Wei Tsang},&#xA;  journal={arXiv preprint arXiv:2212.xxxxx}, &#xA;  year={2022},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;&lt;img alt=&#34;Creative Commons License&#34; style=&#34;border-width:0&#34; src=&#34;https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png&#34;&gt;&lt;/a&gt; &lt;br&gt; This work is under the &lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;This project is supported by &lt;a href=&#34;https://descartes.cnrsatcreate.cnrs.fr/&#34;&gt;DesCartes&lt;/a&gt;, a &lt;a href=&#34;https://www.cnrsatcreate.cnrs.fr/&#34;&gt;CNRS@CREATE&lt;/a&gt; program on Intelligent Modeling for Decision-Making in Critical Urban Systems.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ldkong1205/RoboDepth/main/docs/figs/ack.png&#34; align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;/p&gt;</summary>
  </entry>
</feed>