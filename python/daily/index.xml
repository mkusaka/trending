<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-06-06T01:34:41Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>HKUDS/AutoAgent</title>
    <updated>2025-06-06T01:34:41Z</updated>
    <id>tag:github.com,2025-06-06:/HKUDS/AutoAgent</id>
    <link href="https://github.com/HKUDS/AutoAgent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&#34;AutoAgent: Fully-Automated and Zero-Code LLM Agent Framework&#34;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name=&#34;readme-top&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/AutoAgent_logo.svg?sanitize=true&#34; alt=&#34;Logo&#34; width=&#34;200&#34;&gt; &#xA; &lt;h1 align=&#34;center&#34;&gt;AutoAgent: Fully-Automated &amp;amp; Zero-Code&lt;br&gt; LLM Agent Framework &lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://autoagent-ai.github.io&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&amp;amp;color=FFE165&amp;amp;logo=homepage&amp;amp;logoColor=white&#34; alt=&#34;Credits&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://join.slack.com/t/metachain-workspace/shared_invite/zt-2zibtmutw-v7xOJObBf9jE2w3x7nctFQ&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Slack-Join%20Us-red?logo=slack&amp;amp;logoColor=white&amp;amp;style=for-the-badge&#34; alt=&#34;Join our Slack community&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://discord.gg/jQJdXyDB&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Discord-Join%20Us-purple?logo=discord&amp;amp;logoColor=white&amp;amp;style=for-the-badge&#34; alt=&#34;Join our Discord community&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/HKUDS/AutoAgent/raw/main/assets/autoagent-wechat.jpg&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Wechat-Join%20Us-green?logo=wechat&amp;amp;logoColor=white&amp;amp;style=for-the-badge&#34; alt=&#34;Join our Wechat community&#34;&gt;&lt;/a&gt; &#xA; &lt;br&gt; &#xA; &lt;a href=&#34;https://autoagent-ai.github.io/docs&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Documentation-000?logo=googledocs&amp;amp;logoColor=FFE165&amp;amp;style=for-the-badge&#34; alt=&#34;Check out the documentation&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://arxiv.org/abs/2502.05957&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Paper%20on%20Arxiv-000?logoColor=FFE165&amp;amp;logo=arxiv&amp;amp;style=for-the-badge&#34; alt=&#34;Paper&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://gaia-benchmark-leaderboard.hf.space/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GAIA%20Benchmark-000?logoColor=FFE165&amp;amp;logo=huggingface&amp;amp;style=for-the-badge&#34; alt=&#34;Evaluation Benchmark Score&#34;&gt;&lt;/a&gt; &#xA; &lt;hr&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Welcome to AutoAgent! AutoAgent is a &lt;strong&gt;Fully-Automated&lt;/strong&gt; and highly &lt;strong&gt;Self-Developing&lt;/strong&gt; framework that enables users to create and deploy LLM agents through &lt;strong&gt;Natural Language Alone&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;✨Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;🏆 Top Performers on the GAIA Benchmark &lt;br&gt;AutoAgent has secured top rankings among open-sourced methods, delivering comparable performance to &lt;strong&gt;OpenAI&#39;s Deep Research&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;📚 Agentic-RAG with Native Self-Managing Vector Database &lt;br&gt;AutoAgent equipped with a native self-managing vector database, outperforms industry-leading solutions like &lt;strong&gt;LangChain&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;✨ Agent and Workflow Create with Ease &lt;br&gt;AutoAgent leverages natural language to effortlessly build ready-to-use &lt;strong&gt;tools&lt;/strong&gt;, &lt;strong&gt;agents&lt;/strong&gt; and &lt;strong&gt;workflows&lt;/strong&gt; - no coding required.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;🌐 Universal LLM Support &lt;br&gt;AutoAgent seamlessly integrates with &lt;strong&gt;A Wide Range&lt;/strong&gt; of LLMs (e.g., OpenAI, Anthropic, Deepseek, vLLM, Grok, Huggingface ...)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;🔀 Flexible Interaction &lt;br&gt;Benefit from support for both &lt;strong&gt;function-calling&lt;/strong&gt; and &lt;strong&gt;ReAct&lt;/strong&gt; interaction modes.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;🤖 Dynamic, Extensible, Lightweight &lt;br&gt;AutoAgent is your &lt;strong&gt;Personal AI Assistant&lt;/strong&gt;, designed to be dynamic, extensible, customized, and lightweight.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;🚀 Unlock the Future of LLM Agents. Try 🔥AutoAgent🔥 Now!&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;!-- &lt;img src=&#34;./assets/AutoAgentnew-intro.pdf&#34; alt=&#34;Logo&#34; width=&#34;100%&#34;&gt; --&gt; &#xA; &lt;figure&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/autoagent-intro.svg?sanitize=true&#34; alt=&#34;Logo&#34; style=&#34;max-width: 100%; height: auto;&#34;&gt; &#xA;  &lt;figcaption&gt;&#xA;   &lt;em&gt;Quick Overview of AutoAgent.&lt;/em&gt;&#xA;  &lt;/figcaption&gt; &#xA; &lt;/figure&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;🔥 News&lt;/h2&gt; &#xA;&lt;div class=&#34;scrollable&#34;&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;[2025, Feb 17]&lt;/strong&gt;: &amp;nbsp;🎉🎉We&#39;ve updated and released AutoAgent v0.2.0 (formerly known as MetaChain). Detailed changes include: 1) fix the bug of different LLM providers from issues; 2) add automatic installation of AutoAgent in the container environment according to issues; 3) add more easy-to-use commands for the CLI mode. 4) Rename the project to AutoAgent for better understanding.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;[2025, Feb 10]&lt;/strong&gt;: &amp;nbsp;🎉🎉We&#39;ve released &lt;b&gt;MetaChain!&lt;/b&gt;, including framework, evaluation codes and CLI mode! Check our &lt;a href=&#34;https://arxiv.org/abs/2502.05957&#34;&gt;paper&lt;/a&gt; for more details.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/div&gt; &#xA;&lt;span id=&#34;table-of-contents&#34;&gt;&lt;/span&gt; &#xA;&lt;h2&gt;📑 Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#features&#34;&gt;✨ Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#news&#34;&gt;🔥 News&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#how-to-use&#34;&gt;🔍 How to Use AutoAgent&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#user-mode&#34;&gt;1. &lt;code&gt;user mode&lt;/code&gt; (SOTA 🏆 Open Deep Research)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#agent-editor&#34;&gt;2. &lt;code&gt;agent editor&lt;/code&gt; (Agent Creation without Workflow)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#workflow-editor&#34;&gt;3. &lt;code&gt;workflow editor&lt;/code&gt; (Agent Creation with Workflow)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#quick-start&#34;&gt;⚡ Quick Start&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#api-keys-setup&#34;&gt;API Keys Setup&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#start-with-cli-mode&#34;&gt;Start with CLI Mode&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#todo&#34;&gt;☑️ Todo List&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#reproduce&#34;&gt;🔬 How To Reproduce the Results in the Paper&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#documentation&#34;&gt;📖 Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#community&#34;&gt;🤝 Join the Community&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#acknowledgements&#34;&gt;🙏 Acknowledgements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/#cite&#34;&gt;🌟 Cite&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;span id=&#34;how-to-use&#34;&gt;&lt;/span&gt; &#xA;&lt;h2&gt;🔍 How to Use AutoAgent&lt;/h2&gt; &#xA;&lt;span id=&#34;user-mode&#34;&gt;&lt;/span&gt; &#xA;&lt;h3&gt;1. &lt;code&gt;user mode&lt;/code&gt; (SOTA 🏆 Open Deep Research)&lt;/h3&gt; &#xA;&lt;p&gt;AutoAgent have an out-of-the-box multi-agent system, which you could choose &lt;code&gt;user mode&lt;/code&gt; in the start page to use it. This multi-agent system is a general AI assistant, having the same functionality with &lt;strong&gt;OpenAI&#39;s Deep Research&lt;/strong&gt; and the comparable performance with it in &lt;a href=&#34;https://gaia-benchmark-leaderboard.hf.space/&#34;&gt;GAIA&lt;/a&gt; benchmark.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🚀 &lt;strong&gt;High Performance&lt;/strong&gt;: Matches Deep Research using Claude 3.5 rather than OpenAI&#39;s o3 model.&lt;/li&gt; &#xA; &lt;li&gt;🔄 &lt;strong&gt;Model Flexibility&lt;/strong&gt;: Compatible with any LLM (including Deepseek-R1, Grok, Gemini, etc.)&lt;/li&gt; &#xA; &lt;li&gt;💰 &lt;strong&gt;Cost-Effective&lt;/strong&gt;: Open-source alternative to Deep Research&#39;s $200/month subscription&lt;/li&gt; &#xA; &lt;li&gt;🎯 &lt;strong&gt;User-Friendly&lt;/strong&gt;: Easy-to-deploy CLI interface for seamless interaction&lt;/li&gt; &#xA; &lt;li&gt;📁 &lt;strong&gt;File Support&lt;/strong&gt;: Handles file uploads for enhanced data interaction&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;video width=&#34;80%&#34; controls&gt; &#xA;  &lt;source src=&#34;./assets/video_v1_compressed.mp4&#34; type=&#34;video/mp4&#34;&gt; &#xA; &lt;/video&gt; &#xA; &lt;p&gt;&lt;em&gt;🎥 Deep Research (aka User Mode)&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;span id=&#34;agent-editor&#34;&gt;&lt;/span&gt; &#xA;&lt;h3&gt;2. &lt;code&gt;agent editor&lt;/code&gt; (Agent Creation without Workflow)&lt;/h3&gt; &#xA;&lt;p&gt;The most distinctive feature of AutoAgent is its natural language customization capability. Unlike other agent frameworks, AutoAgent allows you to create tools, agents, and workflows using natural language alone. Simply choose &lt;code&gt;agent editor&lt;/code&gt; or &lt;code&gt;workflow editor&lt;/code&gt; mode to start your journey of building agents through conversations.&lt;/p&gt; &#xA;&lt;p&gt;You can use &lt;code&gt;agent editor&lt;/code&gt; as shown in the following figure.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr align=&#34;center&#34;&gt; &#xA;   &lt;td width=&#34;33%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/1-requirement.png&#34; alt=&#34;requirement&#34; width=&#34;100%&#34;&gt; &lt;br&gt; &lt;em&gt;Input what kind of agent you want to create.&lt;/em&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;33%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/2-profiling.png&#34; alt=&#34;profiling&#34; width=&#34;100%&#34;&gt; &lt;br&gt; &lt;em&gt;Automated agent profiling.&lt;/em&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;33%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/3-profiles.png&#34; alt=&#34;profiles&#34; width=&#34;100%&#34;&gt; &lt;br&gt; &lt;em&gt;Output the agent profiles.&lt;/em&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr align=&#34;center&#34;&gt; &#xA;   &lt;td width=&#34;33%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/4-tools.png&#34; alt=&#34;tools&#34; width=&#34;100%&#34;&gt; &lt;br&gt; &lt;em&gt;Create the desired tools.&lt;/em&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;33%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/5-task.png&#34; alt=&#34;task&#34; width=&#34;100%&#34;&gt; &lt;br&gt; &lt;em&gt;Input what do you want to complete with the agent. (Optional)&lt;/em&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;33%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/agent_editor/6-output-next.png&#34; alt=&#34;output&#34; width=&#34;100%&#34;&gt; &lt;br&gt; &lt;em&gt;Create the desired agent(s) and go to the next step.&lt;/em&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;span id=&#34;workflow-editor&#34;&gt;&lt;/span&gt; &#xA;&lt;h3&gt;3. &lt;code&gt;workflow editor&lt;/code&gt; (Agent Creation with Workflow)&lt;/h3&gt; &#xA;&lt;p&gt;You can also create the agent workflows using natural language description with the &lt;code&gt;workflow editor&lt;/code&gt; mode, as shown in the following figure. (Tips: this mode does not support tool creation temporarily.)&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr align=&#34;center&#34;&gt; &#xA;   &lt;td width=&#34;33%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/1-requirement.png&#34; alt=&#34;requirement&#34; width=&#34;100%&#34;&gt; &lt;br&gt; &lt;em&gt;Input what kind of workflow you want to create.&lt;/em&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;33%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/2-profiling.png&#34; alt=&#34;profiling&#34; width=&#34;100%&#34;&gt; &lt;br&gt; &lt;em&gt;Automated workflow profiling.&lt;/em&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;33%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/3-profiles.png&#34; alt=&#34;profiles&#34; width=&#34;100%&#34;&gt; &lt;br&gt; &lt;em&gt;Output the workflow profiles.&lt;/em&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr align=&#34;center&#34;&gt; &#xA;   &lt;td width=&#34;33%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/4-task.png&#34; alt=&#34;task&#34; width=&#34;66%&#34;&gt; &lt;br&gt; &lt;em&gt;Input what do you want to complete with the workflow. (Optional)&lt;/em&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;33%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/workflow_editor/5-output-next.png&#34; alt=&#34;output&#34; width=&#34;66%&#34;&gt; &lt;br&gt; &lt;em&gt;Create the desired workflow(s) and go to the next step.&lt;/em&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;span id=&#34;quick-start&#34;&gt;&lt;/span&gt; &#xA;&lt;h2&gt;⚡ Quick Start&lt;/h2&gt; &#xA;&lt;span id=&#34;installation&#34;&gt;&lt;/span&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;h4&gt;AutoAgent Installation&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/HKUDS/AutoAgent.git&#xA;cd AutoAgent&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Docker Installation&lt;/h4&gt; &#xA;&lt;p&gt;We use Docker to containerize the agent-interactive environment. So please install &lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt; first. You don&#39;t need to manually pull the pre-built image, because we have let Auto-Deep-Research &lt;strong&gt;automatically pull the pre-built image based on your architecture of your machine&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;span id=&#34;api-keys-setup&#34;&gt;&lt;/span&gt; &#xA;&lt;h3&gt;API Keys Setup&lt;/h3&gt; &#xA;&lt;p&gt;Create an environment variable file, just like &lt;code&gt;.env.template&lt;/code&gt;, and set the API keys for the LLMs you want to use. Not every LLM API Key is required, use what you need.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Required Github Tokens of your own&#xA;GITHUB_AI_TOKEN=&#xA;&#xA;# Optional API Keys&#xA;OPENAI_API_KEY=&#xA;DEEPSEEK_API_KEY=&#xA;ANTHROPIC_API_KEY=&#xA;GEMINI_API_KEY=&#xA;HUGGINGFACE_API_KEY=&#xA;GROQ_API_KEY=&#xA;XAI_API_KEY=&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;span id=&#34;start-with-cli-mode&#34;&gt;&lt;/span&gt; &#xA;&lt;h3&gt;Start with CLI Mode&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[🚨 &lt;strong&gt;News&lt;/strong&gt;: ] We have updated a more easy-to-use command to start the CLI mode and fix the bug of different LLM providers from issues. You can follow the following steps to start the CLI mode with different LLM providers with much less configuration.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;Command Options:&lt;/h4&gt; &#xA;&lt;p&gt;You can run &lt;code&gt;auto main&lt;/code&gt; to start full part of AutoAgent, including &lt;code&gt;user mode&lt;/code&gt;, &lt;code&gt;agent editor&lt;/code&gt; and &lt;code&gt;workflow editor&lt;/code&gt;. Btw, you can also run &lt;code&gt;auto deep-research&lt;/code&gt; to start more lightweight &lt;code&gt;user mode&lt;/code&gt;, just like the &lt;a href=&#34;https://github.com/HKUDS/Auto-Deep-Research&#34;&gt;Auto-Deep-Research&lt;/a&gt; project. Some configuration of this command is shown below.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--container_name&lt;/code&gt;: Name of the Docker container (default: &#39;deepresearch&#39;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--port&lt;/code&gt;: Port for the container (default: 12346)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;COMPLETION_MODEL&lt;/code&gt;: Specify the LLM model to use, you should follow the name of &lt;a href=&#34;https://github.com/BerriAI/litellm&#34;&gt;Litellm&lt;/a&gt; to set the model name. (Default: &lt;code&gt;claude-3-5-sonnet-20241022&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;DEBUG&lt;/code&gt;: Enable debug mode for detailed logs (default: False)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;API_BASE_URL&lt;/code&gt;: The base URL for the LLM provider (default: None)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;FN_CALL&lt;/code&gt;: Enable function calling (default: None). Most of time, you could ignore this option because we have already set the default value based on the model name.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;git_clone&lt;/code&gt;: Clone the AutoAgent repository to the local environment (only support with the &lt;code&gt;auto main&lt;/code&gt; command, default: True)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;test_pull_name&lt;/code&gt;: The name of the test pull. (only support with the &lt;code&gt;auto main&lt;/code&gt; command, default: &#39;autoagent_mirror&#39;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;More details about &lt;code&gt;git_clone&lt;/code&gt; and &lt;code&gt;test_pull_name&lt;/code&gt;]&lt;/h4&gt; &#xA;&lt;p&gt;In the &lt;code&gt;agent editor&lt;/code&gt; and &lt;code&gt;workflow editor&lt;/code&gt; mode, we should clone a mirror of the AutoAgent repository to the local agent-interactive environment and let our &lt;strong&gt;AutoAgent&lt;/strong&gt; automatically update the AutoAgent itself, such as creating new tools, agents and workflows. So if you want to use the &lt;code&gt;agent editor&lt;/code&gt; and &lt;code&gt;workflow editor&lt;/code&gt; mode, you should set the &lt;code&gt;git_clone&lt;/code&gt; to True and set the &lt;code&gt;test_pull_name&lt;/code&gt; to &#39;autoagent_mirror&#39; or other branches.&lt;/p&gt; &#xA;&lt;h4&gt;&lt;code&gt;auto main&lt;/code&gt; with different LLM Providers&lt;/h4&gt; &#xA;&lt;p&gt;Then I will show you how to use the full part of AutoAgent with the &lt;code&gt;auto main&lt;/code&gt; command and different LLM providers. If you want to use the &lt;code&gt;auto deep-research&lt;/code&gt; command, you can refer to the &lt;a href=&#34;https://github.com/HKUDS/Auto-Deep-Research&#34;&gt;Auto-Deep-Research&lt;/a&gt; project for more details.&lt;/p&gt; &#xA;&lt;h5&gt;Anthropic&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;set the &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ANTHROPIC_API_KEY=your_anthropic_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;auto main # default model is claude-3-5-sonnet-20241022&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;OpenAI&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;set the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;OPENAI_API_KEY=your_openai_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;COMPLETION_MODEL=gpt-4o auto main&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Mistral&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;set the &lt;code&gt;MISTRAL_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;MISTRAL_API_KEY=your_mistral_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;COMPLETION_MODEL=mistral/mistral-large-2407 auto main&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Gemini - Google AI Studio&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;set the &lt;code&gt;GEMINI_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;GEMINI_API_KEY=your_gemini_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;COMPLETION_MODEL=gemini/gemini-2.0-flash auto main&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Huggingface&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;set the &lt;code&gt;HUGGINGFACE_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;HUGGINGFACE_API_KEY=your_huggingface_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;COMPLETION_MODEL=huggingface/meta-llama/Llama-3.3-70B-Instruct auto main&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Groq&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;set the &lt;code&gt;GROQ_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;GROQ_API_KEY=your_groq_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;COMPLETION_MODEL=groq/deepseek-r1-distill-llama-70b auto main&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;OpenAI-Compatible Endpoints (e.g., Grok)&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;set the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;OPENAI_API_KEY=your_api_key_for_openai_compatible_endpoints&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;COMPLETION_MODEL=openai/grok-2-latest API_BASE_URL=https://api.x.ai/v1 auto main&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;OpenRouter (e.g., DeepSeek-R1)&lt;/h5&gt; &#xA;&lt;p&gt;We recommend using OpenRouter as LLM provider of DeepSeek-R1 temporarily. Because official API of DeepSeek-R1 can not be used efficiently.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;set the &lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;OPENROUTER_API_KEY=your_openrouter_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;COMPLETION_MODEL=openrouter/deepseek/deepseek-r1 auto main&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;DeepSeek&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;set the &lt;code&gt;DEEPSEEK_API_KEY&lt;/code&gt; in the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;DEEPSEEK_API_KEY=your_deepseek_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;run the following command to start Auto-Deep-Research.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;COMPLETION_MODEL=deepseek/deepseek-chat auto main&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After the CLI mode is started, you can see the start page of AutoAgent:&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;!-- &lt;img src=&#34;./assets/AutoAgentnew-intro.pdf&#34; alt=&#34;Logo&#34; width=&#34;100%&#34;&gt; --&gt; &#xA; &lt;figure&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/cover.png&#34; alt=&#34;Logo&#34; style=&#34;max-width: 100%; height: auto;&#34;&gt; &#xA;  &lt;figcaption&gt;&#xA;   &lt;em&gt;Start Page of AutoAgent.&lt;/em&gt;&#xA;  &lt;/figcaption&gt; &#xA; &lt;/figure&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Tips&lt;/h3&gt; &#xA;&lt;h4&gt;Import browser cookies to browser environment&lt;/h4&gt; &#xA;&lt;p&gt;You can import the browser cookies to the browser environment to let the agent better access some specific websites. For more details, please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/AutoAgent/environment/cookie_json/README.md&#34;&gt;cookies&lt;/a&gt; folder.&lt;/p&gt; &#xA;&lt;h4&gt;Add your own API keys for third-party Tool Platforms&lt;/h4&gt; &#xA;&lt;p&gt;If you want to create tools from the third-party tool platforms, such as RapidAPI, you should subscribe tools from the platform and add your own API keys by running &lt;a href=&#34;https://raw.githubusercontent.com/HKUDS/AutoAgent/main/process_tool_docs.py&#34;&gt;process_tool_docs.py&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python process_tool_docs.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;More features coming soon! 🚀 &lt;strong&gt;Web GUI interface&lt;/strong&gt; under development.&lt;/p&gt; &#xA;&lt;span id=&#34;todo&#34;&gt;&lt;/span&gt; &#xA;&lt;h2&gt;☑️ Todo List&lt;/h2&gt; &#xA;&lt;p&gt;AutoAgent is continuously evolving! Here&#39;s what&#39;s coming:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;📊 &lt;strong&gt;More Benchmarks&lt;/strong&gt;: Expanding evaluations to &lt;strong&gt;SWE-bench&lt;/strong&gt;, &lt;strong&gt;WebArena&lt;/strong&gt;, and more&lt;/li&gt; &#xA; &lt;li&gt;🖥️ &lt;strong&gt;GUI Agent&lt;/strong&gt;: Supporting &lt;em&gt;Computer-Use&lt;/em&gt; agents with GUI interaction&lt;/li&gt; &#xA; &lt;li&gt;🔧 &lt;strong&gt;Tool Platforms&lt;/strong&gt;: Integration with more platforms like &lt;strong&gt;Composio&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;🏗️ &lt;strong&gt;Code Sandboxes&lt;/strong&gt;: Supporting additional environments like &lt;strong&gt;E2B&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;🎨 &lt;strong&gt;Web Interface&lt;/strong&gt;: Developing comprehensive GUI for better user experience&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Have ideas or suggestions? Feel free to open an issue! Stay tuned for more exciting updates! 🚀&lt;/p&gt; &#xA;&lt;span id=&#34;reproduce&#34;&gt;&lt;/span&gt; &#xA;&lt;h2&gt;🔬 How To Reproduce the Results in the Paper&lt;/h2&gt; &#xA;&lt;h3&gt;GAIA Benchmark&lt;/h3&gt; &#xA;&lt;p&gt;For the GAIA benchmark, you can run the following command to run the inference.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd path/to/AutoAgent &amp;amp;&amp;amp; sh evaluation/gaia/scripts/run_infer.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For the evaluation, you can run the following command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd path/to/AutoAgent &amp;amp;&amp;amp; python evaluation/gaia/get_score.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Agentic-RAG&lt;/h3&gt; &#xA;&lt;p&gt;For the Agentic-RAG task, you can run the following command to run the inference.&lt;/p&gt; &#xA;&lt;p&gt;Step1. Turn to &lt;a href=&#34;https://huggingface.co/datasets/yixuantt/MultiHopRAG&#34;&gt;this page&lt;/a&gt; and download it. Save them to your datapath.&lt;/p&gt; &#xA;&lt;p&gt;Step2. Run the following command to run the inference.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd path/to/AutoAgent &amp;amp;&amp;amp; sh evaluation/multihoprag/scripts/run_rag.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Step3. The result will be saved in the &lt;code&gt;evaluation/multihoprag/result.json&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;span id=&#34;documentation&#34;&gt;&lt;/span&gt; &#xA;&lt;h2&gt;📖 Documentation&lt;/h2&gt; &#xA;&lt;p&gt;A more detailed documentation is coming soon 🚀, and we will update in the &lt;a href=&#34;https://AutoAgent-ai.github.io/docs&#34;&gt;Documentation&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;span id=&#34;community&#34;&gt;&lt;/span&gt; &#xA;&lt;h2&gt;🤝 Join the Community&lt;/h2&gt; &#xA;&lt;p&gt;We want to build a community for AutoAgent, and we welcome everyone to join us. You can join our community by:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://join.slack.com/t/AutoAgent-workspace/shared_invite/zt-2zibtmutw-v7xOJObBf9jE2w3x7nctFQ&#34;&gt;Join our Slack workspace&lt;/a&gt; - Here we talk about research, architecture, and future development.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.gg/z68KRvwB&#34;&gt;Join our Discord server&lt;/a&gt; - This is a community-run server for general discussion, questions, and feedback.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/HKUDS/AutoAgent/issues&#34;&gt;Read or post Github Issues&lt;/a&gt; - Check out the issues we&#39;re working on, or add your own ideas.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;span id=&#34;acknowledgements&#34;&gt;&lt;/span&gt; &#xA;&lt;h2&gt;Misc&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/HKUDS/AutoAgent/stargazers&#34;&gt;&lt;img src=&#34;https://reporoster.com/stars/HKUDS/AutoAgent&#34; alt=&#34;Stargazers repo roster for @HKUDS/AutoAgent&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/HKUDS/AutoAgent/network/members&#34;&gt;&lt;img src=&#34;https://reporoster.com/forks/HKUDS/AutoAgent&#34; alt=&#34;Forkers repo roster for @HKUDS/AutoAgent&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://star-history.com/#HKUDS/AutoAgent&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=HKUDS/AutoAgent&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;🙏 Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;Rome wasn&#39;t built in a day. AutoAgent stands on the shoulders of giants, and we are deeply grateful for the outstanding work that came before us. Our framework architecture draws inspiration from &lt;a href=&#34;https://github.com/openai/swarm&#34;&gt;OpenAI Swarm&lt;/a&gt;, while our user mode&#39;s three-agent design benefits from &lt;a href=&#34;https://github.com/microsoft/autogen/tree/main/python/packages/autogen-magentic-one&#34;&gt;Magentic-one&lt;/a&gt;&#39;s insights. We&#39;ve also learned from &lt;a href=&#34;https://github.com/All-Hands-AI/OpenHands&#34;&gt;OpenHands&lt;/a&gt; for documentation structure and many other excellent projects for agent-environment interaction design, among others. We express our sincere gratitude and respect to all these pioneering works that have been instrumental in shaping AutoAgent.&lt;/p&gt; &#xA;&lt;span id=&#34;cite&#34;&gt;&lt;/span&gt; &#xA;&lt;h2&gt;🌟 Cite&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-tex&#34;&gt;@misc{AutoAgent,&#xA;      title={{AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents}},&#xA;      author={Jiabin Tang, Tianyu Fan, Chao Huang},&#xA;      year={2025},&#xA;      eprint={202502.05957},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.AI},&#xA;      url={https://arxiv.org/abs/2502.05957},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>topoteretes/cognee</title>
    <updated>2025-06-06T01:34:41Z</updated>
    <id>tag:github.com,2025-06-06:/topoteretes/cognee</id>
    <link href="https://github.com/topoteretes/cognee" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Memory for AI Agents in 5 lines of code&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/topoteretes/cognee&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/dev/assets/cognee-logo-transparent.png&#34; alt=&#34;Cognee Logo&#34; height=&#34;60&#34;&gt; &lt;/a&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;cognee - Memory for AI Agents in 5 lines of code&lt;/p&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=1bezuvLwJmw&amp;amp;t=2s&#34;&gt;Demo&lt;/a&gt; . &lt;a href=&#34;https://cognee.ai&#34;&gt;Learn more&lt;/a&gt; · &lt;a href=&#34;https://discord.gg/NQPKmU5CCg&#34;&gt;Join Discord&lt;/a&gt; · &lt;a href=&#34;https://www.reddit.com/r/AIMemory/&#34;&gt;Join r/AIMemory&lt;/a&gt; &lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://GitHub.com/topoteretes/cognee/network/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/topoteretes/cognee.svg?style=social&amp;amp;label=Fork&amp;amp;maxAge=2592000&#34; alt=&#34;GitHub forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/topoteretes/cognee/stargazers/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/topoteretes/cognee.svg?style=social&amp;amp;label=Star&amp;amp;maxAge=2592000&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/topoteretes/cognee/commit/&#34;&gt;&lt;img src=&#34;https://badgen.net/github/commits/topoteretes/cognee&#34; alt=&#34;GitHub commits&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/topoteretes/cognee/tags/&#34;&gt;&lt;img src=&#34;https://badgen.net/github/tag/topoteretes/cognee&#34; alt=&#34;Github tag&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/cognee&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/badge/cognee&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/topoteretes/cognee/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/topoteretes/cognee/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000&#34; alt=&#34;Contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.producthunt.com/posts/cognee?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-cognee&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=946346&amp;amp;theme=light&amp;amp;period=daily&amp;amp;t=1744472480704&#34; alt=&#34;cognee - Memory for AI Agents  in 5 lines of code | Product Hunt&#34; style=&#34;width: 250px; height: 54px;&#34; width=&#34;250&#34; height=&#34;54&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;Build dynamic memory for Agents and replace RAG using scalable, modular ECL (Extract, Cognify, Load) pipelines.&lt;/p&gt; &#xA; &lt;p&gt;More on &lt;a href=&#34;https://docs.cognee.ai/use-cases&#34;&gt;use-cases&lt;/a&gt; and &lt;a href=&#34;https://github.com/topoteretes/cognee/tree/main/evals&#34;&gt;evals&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p align=&#34;center&#34;&gt; 🌐 Available Languages : &lt;a href=&#34;https://raw.githubusercontent.com/topoteretes/cognee/main/assets/community/README.pt.md&#34;&gt;🇵🇹 Português&lt;/a&gt; · &lt;a href=&#34;https://raw.githubusercontent.com/topoteretes/cognee/main/assets/community/README.zh.md&#34;&gt;🇨🇳 [中文]&lt;/a&gt; · &lt;a href=&#34;https://raw.githubusercontent.com/topoteretes/cognee/main/assets/community/README.ru.md&#34;&gt;🇷🇺 Русский&lt;/a&gt; &lt;/p&gt; &#xA; &lt;div style=&#34;text-align: center&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/main/assets/cognee_benefits.png&#34; alt=&#34;Why cognee?&#34; width=&#34;50%&#34;&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Interconnect and retrieve your past conversations, documents, images and audio transcriptions&lt;/li&gt; &#xA; &lt;li&gt;Replaces RAG systems and reduces developer effort, and cost.&lt;/li&gt; &#xA; &lt;li&gt;Load data to graph and vector databases using only Pydantic&lt;/li&gt; &#xA; &lt;li&gt;Manipulate your data while ingesting from 30+ data sources&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;p&gt;Get started quickly with a Google Colab &lt;a href=&#34;https://colab.research.google.com/drive/1jHbWVypDgCLwjE71GSXhRL3YxYhCZzG1?usp=sharing&#34;&gt;notebook&lt;/a&gt; , &lt;a href=&#34;https://deepnote.com/workspace/cognee-382213d0-0444-4c89-8265-13770e333c02/project/cognee-demo-78ffacb9-5832-4611-bb1a-560386068b30/notebook/Notebook-1-75b24cda566d4c24ab348f7150792601?utm_source=share-modal&amp;amp;utm_medium=product-shared-content&amp;amp;utm_campaign=notebook&amp;amp;utm_content=78ffacb9-5832-4611-bb1a-560386068b30&#34;&gt;Deepnote notebook&lt;/a&gt; or &lt;a href=&#34;https://github.com/topoteretes/cognee-starter&#34;&gt;starter repo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Your contributions are at the core of making this a true open source project. Any contributions you make are &lt;strong&gt;greatly appreciated&lt;/strong&gt;. See &lt;a href=&#34;https://raw.githubusercontent.com/topoteretes/cognee/main/CONTRIBUTING.md&#34;&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;📦 Installation&lt;/h2&gt; &#xA;&lt;p&gt;You can install Cognee using either &lt;strong&gt;pip&lt;/strong&gt;, &lt;strong&gt;poetry&lt;/strong&gt;, &lt;strong&gt;uv&lt;/strong&gt; or any other python package manager. Cognee supports Python 3.8 to 3.12&lt;/p&gt; &#xA;&lt;h3&gt;With pip&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install cognee&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Local Cognee installation&lt;/h2&gt; &#xA;&lt;p&gt;You can install the local Cognee repo using &lt;strong&gt;pip&lt;/strong&gt;, &lt;strong&gt;poetry&lt;/strong&gt; and &lt;strong&gt;uv&lt;/strong&gt;. For local pip installation please make sure your pip version is above version 21.3.&lt;/p&gt; &#xA;&lt;h3&gt;with UV with all optional dependencies&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uv sync --all-extras&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;💻 Basic Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Setup&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;import os&#xA;os.environ[&#34;LLM_API_KEY&#34;] = &#34;YOUR OPENAI_API_KEY&#34;&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also set the variables by creating .env file, using our &lt;a href=&#34;https://github.com/topoteretes/cognee/raw/main/.env.template&#34;&gt;template.&lt;/a&gt; To use different LLM providers, for more info check out our &lt;a href=&#34;https://docs.cognee.ai&#34;&gt;documentation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Simple example&lt;/h3&gt; &#xA;&lt;p&gt;This script will run the default pipeline:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import cognee&#xA;import asyncio&#xA;&#xA;&#xA;async def main():&#xA;    # Add text to cognee&#xA;    await cognee.add(&#34;Natural language processing (NLP) is an interdisciplinary subfield of computer science and information retrieval.&#34;)&#xA;&#xA;    # Generate the knowledge graph&#xA;    await cognee.cognify()&#xA;&#xA;    # Query the knowledge graph&#xA;    results = await cognee.search(&#34;Tell me about NLP&#34;)&#xA;&#xA;    # Display the results&#xA;    for result in results:&#xA;        print(result)&#xA;&#xA;&#xA;if __name__ == &#39;__main__&#39;:&#xA;    asyncio.run(main())&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  Natural Language Processing (NLP) is a cross-disciplinary and interdisciplinary field that involves computer science and information retrieval. It focuses on the interaction between computers and human language, enabling machines to understand and process natural language.&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Our paper is out! &lt;a href=&#34;https://arxiv.org/abs/2505.24478&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Read here&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;div style=&#34;text-align: center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/topoteretes/cognee/main/assets/cognee-paper.png&#34; alt=&#34;cognee paper&#34; width=&#34;100%&#34;&gt; &#xA;&lt;/div&gt;  &#xA;&lt;h2&gt;Cognee UI&lt;/h2&gt; &#xA;&lt;p&gt;You can also cognify your files and query using cognee UI.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/topoteretes/cognee/main/assets/cognee-ui-2.webp&#34; width=&#34;100%&#34; alt=&#34;Cognee UI 2&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Try cognee UI out locally &lt;a href=&#34;https://docs.cognee.ai/how-to-guides/cognee-ui&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Understand our architecture&lt;/h2&gt; &#xA;&lt;div style=&#34;text-align: center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/topoteretes/cognee/main/assets/cognee_diagram.png&#34; alt=&#34;cognee concept diagram&#34; width=&#34;100%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Demos&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;What is AI memory:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/8b2a0050-5ec4-424c-b417-8269971503f0&#34;&gt;Learn about cognee&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Simple GraphRAG demo&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/d80b0776-4eb9-4b8e-aa22-3691e2d44b8f&#34;&gt;Simple GraphRAG demo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;cognee with Ollama&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/8621d3e8-ecb8-4860-afb2-5594f2ee17db&#34;&gt;cognee with local models&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;We are committed to making open source an enjoyable and respectful experience for our community. See &lt;a href=&#34;https://github.com/topoteretes/cognee/raw/main/CODE_OF_CONDUCT.md&#34;&gt;&lt;code&gt;CODE_OF_CONDUCT&lt;/code&gt;&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;💫 Contributors&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/topoteretes/cognee/graphs/contributors&#34;&gt; &lt;img alt=&#34;contributors&#34; src=&#34;https://contrib.rocks/image?repo=topoteretes/cognee&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#topoteretes/cognee&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=topoteretes/cognee&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>LMCache/LMCache</title>
    <updated>2025-06-06T01:34:41Z</updated>
    <id>tag:github.com,2025-06-06:/LMCache/LMCache</id>
    <link href="https://github.com/LMCache/LMCache" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Redis for LLMs&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/a0809748-3cb1-4732-9c5a-acfa90cc72d1&#34; width=&#34;720&#34; alt=&#34;lmcache logo&#34;&gt;  &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://deepwiki.com/LMCache/LMCache&#34;&gt; &lt;img src=&#34;https://deepwiki.com/badge.svg?sanitize=true&#34; alt=&#34;Ask DeepWiki&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://docs.lmcache.ai/&#34;&gt; &lt;img alt=&#34;Documentation&#34; src=&#34;https://img.shields.io/badge/docs-blue?logo=readthedocs&amp;amp;logoColor=f0f8ff&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://join.slack.com/t/lmcacheworkspace/shared_invite/zt-2viziwhue-5Amprc9k5hcIdXT7XevTaQ&#34;&gt; &lt;img alt=&#34;Join Slack&#34; src=&#34;https://img.shields.io/badge/LMCache-Join%20Slack-blue?logo=slack&#34;&gt; &lt;/a&gt; &lt;img alt=&#34;GitHub commit activity&#34; src=&#34;https://img.shields.io/github/commit-activity/w/LMCache/LMCache&#34;&gt; &lt;img alt=&#34;PyPI - Downloads&#34; src=&#34;https://img.shields.io/pypi/dm/LMCache&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UC58zMz55n70rtf1Ak2PULJA&#34;&gt; &lt;img alt=&#34;YouTube Channel Views&#34; src=&#34;https://img.shields.io/youtube/channel/views/UC58zMz55n70rtf1Ak2PULJA&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt; Redis for LLMs - Infinite and Ultra-Fast &lt;/h3&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;LMCache is an &lt;strong&gt;LLM&lt;/strong&gt; serving engine extension to &lt;strong&gt;reduce TTFT&lt;/strong&gt; and &lt;strong&gt;increase throughput&lt;/strong&gt;, especially under long-context scenarios. By storing the KV caches of reusable texts across various locations, including (GPU, CPU DRAM, Local Disk), LMCache reuses the KV caches of &lt;strong&gt;&lt;em&gt;any&lt;/em&gt;&lt;/strong&gt; reused text (not necessarily prefix) in &lt;strong&gt;&lt;em&gt;any&lt;/em&gt;&lt;/strong&gt; serving engine instance. Thus, LMCache saves precious GPU cycles and reduces user response delay.&lt;/p&gt; &#xA;&lt;p&gt;By combining LMCache with vLLM, LMCache achieves 3-10x delay savings and GPU cycle reduction in many LLM use cases, including multi-round QA and RAG.&lt;/p&gt; &#xA;&lt;p&gt;Try LMCache with pre-built vllm docker images &lt;a href=&#34;https://docs.lmcache.ai/developer_guide/docker_file.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;🚀 Performance snapshot&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/7db9510f-0104-4fb3-9976-8ad5d7fafe26&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;💻 Installation and Quickstart&lt;/h1&gt; &#xA;&lt;p&gt;Please refer to our detailed documentation for &lt;a href=&#34;https://docs.lmcache.ai/getting_started/installation.html#install-from-source-v1&#34;&gt;LMCache V1&lt;/a&gt; and &lt;a href=&#34;https://docs.lmcache.ai/getting_started/installation.html#install-from-source-v0&#34;&gt;LMCache V0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Interested in Connecting?&lt;/h1&gt; &#xA;&lt;p&gt;Fill out the interest form or &lt;a href=&#34;https://raw.githubusercontent.com/LMCache/LMCache/dev/contact@lmcache.ai&#34;&gt;drop an email&lt;/a&gt;, and our team will reach out to you! &lt;a href=&#34;https://forms.gle/mQfQDUXbKfp2St1z7&#34;&gt;Google Form&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;🛣️ News and Milestones&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; LMCache V1 with vLLM integration with following features is live 🔥 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;High performance CPU KVCache offloading&lt;/li&gt; &#xA;   &lt;li&gt;Disaggregated prefill&lt;/li&gt; &#xA;   &lt;li&gt;P2P KVCache sharing&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; LMCache is supported in the &lt;a href=&#34;https://github.com/vllm-project/production-stack/tree/main&#34;&gt;vLLM production stack ecosystem&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; User and developer documentation&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Stable support for non-prefix KV caches&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Support installation through pip install and integrate with latest vLLM&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; First release of LMCache&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;📖 Blogs and documentations&lt;/h1&gt; &#xA;&lt;p&gt;Our latest &lt;a href=&#34;https://lmcache.github.io&#34;&gt;blog posts&lt;/a&gt; and the &lt;a href=&#34;https://docs.lmcache.ai/&#34;&gt;documentation&lt;/a&gt; pages are available online&lt;/p&gt; &#xA;&lt;h1&gt;Community meeting&lt;/h1&gt; &#xA;&lt;p&gt;The community meeting for LMCache is hosted weekly. Meeting Details:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Tuesdays at 9:00 AM PT – &lt;a href=&#34;https://drive.google.com/file/d/15Xz8-LtpBQ5QgR7KrorOOyfuohCFQmwn/view?usp=drive_link&#34;&gt;Add to Calendar&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Tuesdays at 6:30 PM PT – &lt;a href=&#34;https://drive.google.com/file/d/1WMZNFXV24kWzprDjvO-jQ7mOY7whqEdG/view?usp=drive_link&#34;&gt;Add to Calendar&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Meetings &lt;strong&gt;alternate weekly&lt;/strong&gt; between the two times. All are welcome to join!&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome and value any contributions and collaborations. Please check out &lt;a href=&#34;https://raw.githubusercontent.com/LMCache/LMCache/dev/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for how to get involved.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you use LMCache for your research, please cite our papers:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{liu2024cachegen,&#xA;  title={Cachegen: Kv cache compression and streaming for fast large language model serving},&#xA;  author={Liu, Yuhan and Li, Hanchen and Cheng, Yihua and Ray, Siddhant and Huang, Yuyang and Zhang, Qizheng and Du, Kuntai and Yao, Jiayi and Lu, Shan and Ananthanarayanan, Ganesh and others},&#xA;  booktitle={Proceedings of the ACM SIGCOMM 2024 Conference},&#xA;  pages={38--56},&#xA;  year={2024}&#xA;}&#xA;&#xA;@article{cheng2024large,&#xA;  title={Do Large Language Models Need a Content Delivery Network?},&#xA;  author={Cheng, Yihua and Du, Kuntai and Yao, Jiayi and Jiang, Junchen},&#xA;  journal={arXiv preprint arXiv:2409.13761},&#xA;  year={2024}&#xA;}&#xA;&#xA;@article{yao2024cacheblend,&#xA;  title={CacheBlend: Fast Large Language Model Serving with Cached Knowledge Fusion},&#xA;  author={Yao, Jiayi and Li, Hanchen and Liu, Yuhan and Ray, Siddhant and Cheng, Yihua and Zhang, Qizheng and Du, Kuntai and Lu, Shan and Jiang, Junchen},&#xA;  journal={arXiv preprint arXiv:2405.16444},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under Apache License 2.0. See the &lt;a href=&#34;https://raw.githubusercontent.com/LMCache/LMCache/dev/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</summary>
  </entry>
</feed>