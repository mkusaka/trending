<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-23T01:31:59Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>shamhi/TapSwapBot</title>
    <updated>2024-05-23T01:31:59Z</updated>
    <id>tag:github.com,2024-05-23:/shamhi/TapSwapBot</id>
    <link href="https://github.com/shamhi/TapSwapBot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Bot that mines coins in Tapswap&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://t.me/sho6ot&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Telegram-%40Me-orange&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/shamhi/TapSwapBot/main/.github/images/demo.png&#34; alt=&#34;img1&#34;&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;üá™üá≥ README in english available &lt;a href=&#34;https://raw.githubusercontent.com/shamhi/TapSwapBot/main/README-EN.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;–ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;–ü—Ä–∏–≤—è–∑–∫–∞ –ø—Ä–æ–∫—Å–∏ –∫ —Å–µ—Å—Å–∏–∏&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;–ê–≤—Ç–æ-–ø–æ–∫—É–ø–∫–∞ –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –º–æ–Ω–µ—Ç (tap, energy, charge)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;–†–∞–Ω–¥–æ–º–Ω–æ–µ –≤—Ä–µ–º—è —Å–Ω–∞ –º–µ–∂–¥—É –∫–ª–∏–∫–∞–º–∏&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;–†–∞–Ω–¥–æ–º–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–∫–æ–≤ –∑–∞ –∑–∞–ø—Ä–æ—Å&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;–ü–æ–¥–¥–µ—Ä–∂–∫–∞ tdata / pyrogram .session / telethon .session&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/shamhi/TapSwapBot/raw/main/.env-example&#34;&gt;–ù–∞—Å—Ç—Ä–æ–π–∫–∏&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;–ù–∞—Å—Ç—Ä–æ–π–∫–∞&lt;/th&gt; &#xA;   &lt;th&gt;–û–ø–∏—Å–∞–Ω–∏–µ&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;API_ID / API_HASH&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–î–∞–Ω–Ω—ã–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã, —Å –∫–æ—Ç–æ—Ä–æ–π –∑–∞–ø—É—Å–∫–∞—Ç—å —Å–µ—Å—Å–∏—é Telegram (—Å—Ç–æ–∫ - Android)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;MIN_AVAILABLE_ENERGY&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ—Å—Ç—É–ø–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–∏, –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –∫–æ—Ç–æ—Ä–æ–π –±—É–¥–µ—Ç –∑–∞–¥–µ—Ä–∂–∫–∞ (–Ω–∞–ø—Ä. 100)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;SLEEP_BY_MIN_ENERGY&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–ó–∞–¥–µ—Ä–∂–∫–∞ –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–Ω–∞–ø—Ä. 200)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;ADD_TAPS_ON_TURBO&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–°–∫–æ–ª—å–∫–æ —Ç–∞–ø–æ–≤ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–æ –ø—Ä–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ç—É—Ä–±–æ (–Ω–∞–ø—Ä. 2500)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;AUTO_UPGRADE_TAP&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–£–ª—É—á—à–∞—Ç—å –ª–∏ —Ç–∞–ø (True / False)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;MAX_TAP_LEVEL&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –ø—Ä–æ–∫–∞—á–∫–∏ —Ç–∞–ø–∞ (–¥–æ 20)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;AUTO_UPGRADE_ENERGY&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–£–ª—É—á—à–∞—Ç—å –ª–∏ —ç–Ω–µ—Ä–≥–∏—é (True / False)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;MAX_ENERGY_LEVEL&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –ø—Ä–æ–∫–∞—á–∫–∏ —ç–Ω–µ—Ä–≥–∏–∏ (–¥–æ 20)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;AUTO_UPGRADE_CHARGE&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–£–ª—É—á—à–∞—Ç—å –ª–∏ –∑–∞—Ä—è–¥ —ç–Ω–µ—Ä–≥–∏–∏ (True / False)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;MAX_CHARGE_LEVEL&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –ø—Ä–æ–∫–∞—á–∫–∏ –∑–∞—Ä—è–¥–∞ —ç–Ω–µ—Ä–≥–∏–∏ (–¥–æ 5)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;APPLY_DAILY_ENERGY&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π –±—É—Å—Ç —ç–Ω–µ—Ä–≥–∏–∏ (True / False)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;APPLY_DAILY_TURBO&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π –±—É—Å—Ç —Ç—É—Ä–±–æ (True / False)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;RANDOM_CLICKS_COUNT&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–†–∞–Ω–¥–æ–º–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–∞–ø–æ–≤ (–Ω–∞–ø—Ä. 50,200)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;SLEEP_BETWEEN_TAP&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–†–∞–Ω–¥–æ–º–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Ç–∞–ø–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–Ω–∞–ø—Ä. 10,25)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;USE_PROXY_FROM_FILE&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å-–ª–∏ –ø—Ä–æ–∫—Å–∏ –∏–∑ —Ñ–∞–π–ª–∞ &lt;code&gt;bot/config/proxies.txt&lt;/code&gt; (True / False)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;–£—Å—Ç–∞–Ω–æ–≤–∫–∞&lt;/h2&gt; &#xA;&lt;p&gt;–í—ã –º–æ–∂–µ—Ç–µ —Å–∫–∞—á–∞—Ç—å &lt;a href=&#34;https://github.com/shamhi/TapSwapBot&#34;&gt;&lt;strong&gt;–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π&lt;/strong&gt;&lt;/a&gt; –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –Ω–∞ –≤–∞—à—É —Å–∏—Å—Ç–µ–º—É –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–æ–π –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;~ &amp;gt;&amp;gt;&amp;gt; git clone https://github.com/shamhi/TapSwapBot.git &#xA;~ &amp;gt;&amp;gt;&amp;gt; cd TapSwapBot&#xA;&#xA;# –ï—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ Telethon —Å–µ—Å—Å–∏–∏, —Ç–æ –∫–ª–æ–Ω–∏—Ä—É–π—Ç–µ –≤–µ—Ç–∫—É &#34;converter&#34;&#xA;~ &amp;gt;&amp;gt;&amp;gt; git clone https://github.com/shamhi/TapSwapBot.git -b converter&#xA;~ &amp;gt;&amp;gt;&amp;gt; cd TapSwapBot&#xA;&#xA;# Linux&#xA;~/TapSwapBot &amp;gt;&amp;gt;&amp;gt; python3 -m venv venv&#xA;~/TapSwapBot &amp;gt;&amp;gt;&amp;gt; source venv/bin/activate&#xA;~/TapSwapBot &amp;gt;&amp;gt;&amp;gt; pip3 install -r requirements.txt&#xA;~/TapSwapBot &amp;gt;&amp;gt;&amp;gt; cp .env-example .env&#xA;~/TapSwapBot &amp;gt;&amp;gt;&amp;gt; nano .env  # –ó–¥–µ—Å—å –≤—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–Ω—ã —É–∫–∞–∑–∞—Ç—å –≤–∞—à–∏ API_ID –∏ API_HASH , –æ—Å—Ç–∞–ª—å–Ω–æ–µ –±–µ—Ä–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é&#xA;~/TapSwapBot &amp;gt;&amp;gt;&amp;gt; python3 main.py&#xA;&#xA;# Windows&#xA;~/TapSwapBot &amp;gt;&amp;gt;&amp;gt; python -m venv venv&#xA;~/TapSwapBot &amp;gt;&amp;gt;&amp;gt; venv\Scripts\activate&#xA;~/TapSwapBot &amp;gt;&amp;gt;&amp;gt; pip install -r requirements.txt&#xA;~/TapSwapBot &amp;gt;&amp;gt;&amp;gt; copy .env-example .env&#xA;~/TapSwapBot &amp;gt;&amp;gt;&amp;gt; # –£–∫–∞–∑—ã–≤–∞–µ—Ç–µ –≤–∞—à–∏ API_ID –∏ API_HASH, –æ—Å—Ç–∞–ª—å–Ω–æ–µ –±–µ—Ä–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é&#xA;~/TapSwapBot &amp;gt;&amp;gt;&amp;gt; python main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;–¢–∞–∫–∂–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;~/TapSwapBot &amp;gt;&amp;gt;&amp;gt; python3 main.py --action (1/2/3)&#xA;# –ò–ª–∏&#xA;~/TapSwapBot &amp;gt;&amp;gt;&amp;gt; python3 main.py -a (1/2/3)&#xA;&#xA;# 1 - –°–æ–∑–¥–∞–µ—Ç —Å–µ—Å—Å–∏—é&#xA;# 2 - –ó–∞–ø—É—Å–∫–∞–µ—Ç –∫–ª–∏–∫–µ—Ä&#xA;# 3 - –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ Telegram&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>THUDM/CogVLM2</title>
    <updated>2024-05-23T01:31:59Z</updated>
    <id>tag:github.com,2024-05-23:/THUDM/CogVLM2</id>
    <link href="https://github.com/THUDM/CogVLM2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GPT4V-level open-source multi-modal model based on Llama3-8B&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CogVLM2&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/CogVLM2/main/README_zh.md&#34;&gt;‰∏≠ÊñáÁâàREADME&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/THUDM/CogVLM2/main/resources/logo.svg?sanitize=true&#34; width=&#34;40%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; üëã Join our &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/CogVLM2/main/resources/WECHAT.md&#34; target=&#34;_blank&#34;&gt;Wechat&lt;/a&gt; ¬∑ üí°Try it &lt;a href=&#34;http://36.103.203.44:7861/&#34; target=&#34;_blank&#34;&gt;Online&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; üìçExperience the larger-scale CogVLM model (GLM-4V) on the &lt;a href=&#34;https://open.bigmodel.cn/dev/api#super-humanoid&#34;&gt;ZhipuAI Open Platform&lt;/a&gt;. &lt;/p&gt; &#xA;&lt;p&gt;We launch a new generation of &lt;strong&gt;CogVLM2&lt;/strong&gt; series of models and open source two models based on &lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct&#34;&gt;Meta-Llama-3-8B-Instruct&lt;/a&gt;. Compared with the previous generation of CogVLM open source models, the CogVLM2 series of open source models have the following improvements:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Significant improvements in many benchmarks such as &lt;code&gt;TextVQA&lt;/code&gt;, &lt;code&gt;DocVQA&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Support &lt;strong&gt;8K&lt;/strong&gt; content length.&lt;/li&gt; &#xA; &lt;li&gt;Support image resolution up to &lt;strong&gt;1344 * 1344&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Provide an open source model version that supports both &lt;strong&gt;Chinese and English&lt;/strong&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You can see the details of the &lt;strong&gt;CogVLM2&lt;/strong&gt; family of open source models in the table below:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model name&lt;/th&gt; &#xA;   &lt;th&gt;cogvlm2-llama3-chat-19B&lt;/th&gt; &#xA;   &lt;th&gt;cogvlm2-llama3-chinese-chat-19B&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Base Model&lt;/td&gt; &#xA;   &lt;td&gt;Meta-Llama-3-8B-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;Meta-Llama-3-8B-Instruct&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Language&lt;/td&gt; &#xA;   &lt;td&gt;English&lt;/td&gt; &#xA;   &lt;td&gt;Chinese, English&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Model size&lt;/td&gt; &#xA;   &lt;td&gt;19B&lt;/td&gt; &#xA;   &lt;td&gt;19B&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Task&lt;/td&gt; &#xA;   &lt;td&gt;Image understanding, dialogue model&lt;/td&gt; &#xA;   &lt;td&gt;Image understanding, dialogue model&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Model link&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/THUDM/cogvlm2-llama3-chat-19B&#34;&gt;ü§ó Huggingface&lt;/a&gt; &lt;a href=&#34;https://modelscope.cn/models/ZhipuAI/cogvlm2-llama3-chat-19B/&#34;&gt;ü§ñ ModelScope&lt;/a&gt; &lt;a href=&#34;https://wisemodel.cn/models/ZhipuAI/cogvlm2-llama3-chat-19B/&#34;&gt;üí´ Wise Model&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/THUDM/cogvlm2-llama3-chinese-chat-19B&#34;&gt;ü§ó Huggingface&lt;/a&gt; &lt;a href=&#34;https://modelscope.cn/models/ZhipuAI/cogvlm2-llama3-chinese-chat-19B/&#34;&gt;ü§ñ ModelScope&lt;/a&gt; &lt;a href=&#34;https://wisemodel.cn/models/ZhipuAI/cogvlm2-llama3-chinese-chat-19B/&#34;&gt; üí´ Wise Model&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Demo Page&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://36.103.203.44:7861/&#34;&gt;üìô Official Demo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://36.103.203.44:7861/&#34;&gt;üìô Official Demo&lt;/a&gt; &lt;a href=&#34;https://modelscope.cn/studios/ZhipuAI/Cogvlm2-llama3-chinese-chat-Demo/summary&#34;&gt;ü§ñ ModelScope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Int4 model&lt;/td&gt; &#xA;   &lt;td&gt;Not yet launched&lt;/td&gt; &#xA;   &lt;td&gt;Not yet launched&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Text length&lt;/td&gt; &#xA;   &lt;td&gt;8K&lt;/td&gt; &#xA;   &lt;td&gt;8K&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Image resolution&lt;/td&gt; &#xA;   &lt;td&gt;1344 * 1344&lt;/td&gt; &#xA;   &lt;td&gt;1344 * 1344&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Benchmark&lt;/h2&gt; &#xA;&lt;p&gt;Our open source models have achieved good results in many lists compared to the previous generation of CogVLM open source models. Its excellent performance can compete with some non-open source models, as shown in the table below:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Open Source&lt;/th&gt; &#xA;   &lt;th&gt;LLM Size&lt;/th&gt; &#xA;   &lt;th&gt;TextVQA&lt;/th&gt; &#xA;   &lt;th&gt;DocVQA&lt;/th&gt; &#xA;   &lt;th&gt;ChartQA&lt;/th&gt; &#xA;   &lt;th&gt;OCRbench&lt;/th&gt; &#xA;   &lt;th&gt;MMMU&lt;/th&gt; &#xA;   &lt;th&gt;MMVet&lt;/th&gt; &#xA;   &lt;th&gt;MMBench&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CogVLM1.1&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;69.7&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;68.3&lt;/td&gt; &#xA;   &lt;td&gt;590&lt;/td&gt; &#xA;   &lt;td&gt;37.3&lt;/td&gt; &#xA;   &lt;td&gt;52.0&lt;/td&gt; &#xA;   &lt;td&gt;65.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaVA-1.5&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;13B&lt;/td&gt; &#xA;   &lt;td&gt;61.3&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;337&lt;/td&gt; &#xA;   &lt;td&gt;37.0&lt;/td&gt; &#xA;   &lt;td&gt;35.4&lt;/td&gt; &#xA;   &lt;td&gt;67.7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mini-Gemini&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;34B&lt;/td&gt; &#xA;   &lt;td&gt;74.1&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;48.0&lt;/td&gt; &#xA;   &lt;td&gt;59.3&lt;/td&gt; &#xA;   &lt;td&gt;80.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaVA-NeXT-LLaMA3&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;8B&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;78.2&lt;/td&gt; &#xA;   &lt;td&gt;69.5&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;41.7&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;72.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaVA-NeXT-110B&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;110B&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;85.7&lt;/td&gt; &#xA;   &lt;td&gt;79.7&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;49.1&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;80.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;InternVL-1.5&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;20B&lt;/td&gt; &#xA;   &lt;td&gt;80.6&lt;/td&gt; &#xA;   &lt;td&gt;90.9&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;83.8&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;720&lt;/td&gt; &#xA;   &lt;td&gt;46.8&lt;/td&gt; &#xA;   &lt;td&gt;55.4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;82.3&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;QwenVL-Plus&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;78.9&lt;/td&gt; &#xA;   &lt;td&gt;91.4&lt;/td&gt; &#xA;   &lt;td&gt;78.1&lt;/td&gt; &#xA;   &lt;td&gt;726&lt;/td&gt; &#xA;   &lt;td&gt;51.4&lt;/td&gt; &#xA;   &lt;td&gt;55.7&lt;/td&gt; &#xA;   &lt;td&gt;67.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Claude3-Opus&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;89.3&lt;/td&gt; &#xA;   &lt;td&gt;80.8&lt;/td&gt; &#xA;   &lt;td&gt;694&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;59.4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;51.7&lt;/td&gt; &#xA;   &lt;td&gt;63.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gemini Pro 1.5&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;73.5&lt;/td&gt; &#xA;   &lt;td&gt;86.5&lt;/td&gt; &#xA;   &lt;td&gt;81.3&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;58.5&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPT-4V&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;78.0&lt;/td&gt; &#xA;   &lt;td&gt;88.4&lt;/td&gt; &#xA;   &lt;td&gt;78.5&lt;/td&gt; &#xA;   &lt;td&gt;656&lt;/td&gt; &#xA;   &lt;td&gt;56.8&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;67.7&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;75.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;CogVLM2-LLaMA3&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;8B&lt;/td&gt; &#xA;   &lt;td&gt;84.2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;92.3&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;81.0&lt;/td&gt; &#xA;   &lt;td&gt;756&lt;/td&gt; &#xA;   &lt;td&gt;44.3&lt;/td&gt; &#xA;   &lt;td&gt;60.4&lt;/td&gt; &#xA;   &lt;td&gt;80.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;CogVLM2-LLaMA3-Chinese&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;8B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;85.0&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;88.4&lt;/td&gt; &#xA;   &lt;td&gt;74.7&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;780&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;42.8&lt;/td&gt; &#xA;   &lt;td&gt;60.5&lt;/td&gt; &#xA;   &lt;td&gt;78.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;All reviews were obtained without using any external OCR tools (&#34;pixel only&#34;).&lt;/p&gt; &#xA;&lt;h2&gt;Project structure&lt;/h2&gt; &#xA;&lt;p&gt;This open source repos will help developers to quickly get started with the basic calling methods of the CogVLM2 open source model, fine-tuning examples, OpenAI API format calling examples, etc. The specific project structure is as follows, you can click to enter the corresponding tutorial link:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/CogVLM2/main/basic_demo/README.md&#34;&gt;basic_demo&lt;/a&gt; - Basic calling methods include model inference calling methods such as CLI, WebUI and OpenAI API. If you are using the CogVLM2 open source model for the first time, we recommend you start here.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/CogVLM2/main/finetune_demo/README.md&#34;&gt;finetune_demo&lt;/a&gt; - Fine-tuning examples, including examples of fine-tuning language models.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This model is released under the CogVLM2 &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/CogVLM2/main/MODEL_LICENSE&#34;&gt;CogVLM2 LICENSE&lt;/a&gt;. For models built with Meta Llama 3, please also adhere to the &lt;a href=&#34;https://llama.meta.com/llama3/license/&#34;&gt;LLAMA3_LICENSE&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find our work helpful, please consider citing the following papers&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{wang2023cogvlm,&#xA;      title={CogVLM: Visual Expert for Pretrained Language Models}, &#xA;      author={Weihan Wang and Qingsong Lv and Wenmeng Yu and Wenyi Hong and Ji Qi and Yan Wang and Junhui Ji and Zhuoyi Yang and Lei Zhao and Xixuan Song and Jiazheng Xu and Bin Xu and Juanzi Li and Yuxiao Dong and Ming Ding and Jie Tang},&#xA;      year={2023},&#xA;      eprint={2311.03079},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>Codium-ai/cover-agent</title>
    <updated>2024-05-23T01:31:59Z</updated>
    <id>tag:github.com,2024-05-23:/Codium-ai/cover-agent</id>
    <link href="https://github.com/Codium-ai/cover-agent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;CodiumAI Cover-Agent: An AI-Powered Tool for Automated Test Generation and Code Coverage Enhancement! üíªü§ñüß™üêû&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://www.codium.ai/images/cover-agent/cover-agent-dark.png&#34; width=&#34;330&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;https://www.codium.ai/images/cover-agent/cover-agent-light.png&#34; width=&#34;330&#34;&gt; &#xA;   &lt;img src=&#34;https://www.codium.ai/images/cover-agent/cover-agent-light.png&#34; alt=&#34;logo&#34; width=&#34;330&#34;&gt; &#xA;  &lt;/picture&gt; &#xA;  &lt;br&gt; CodiumAI Cover Agent aims to help efficiently increasing code coverage, by automatically generating qualified tests to enhance existing test suites &#xA; &lt;/div&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/Codium-ai/cover-agent/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-AGPL_3.0-blue.svg?sanitize=true&#34; alt=&#34;GitHub license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/cYsvFJJbdM&#34;&gt;&lt;img src=&#34;https://badgen.net/badge/icon/discord?icon=discord&amp;amp;label&amp;amp;color=purple&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/codiumai&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/codiumai&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Codium-ai/cover-agent/commits/main&#34;&gt; &lt;img alt=&#34;GitHub&#34; src=&#34;https://img.shields.io/github/last-commit/Codium-ai/cover-agent/main?style=for-the-badge&#34; height=&#34;20&#34;&gt; &lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Codium-ai/cover-agent/main/#news-and-updates&#34;&gt;News and Updates&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Codium-ai/cover-agent/main/#overview&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Codium-ai/cover-agent/main/#installation-and-usage&#34;&gt;Installation and Usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Codium-ai/cover-agent/main/#development&#34;&gt;Development&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Codium-ai/cover-agent/main/#roadmap&#34;&gt;Roadmap&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;News and Updates&lt;/h2&gt; &#xA;&lt;h3&gt;2024-05-09:&lt;/h3&gt; &#xA;&lt;h4&gt;This repository includes the first known implementation of TestGen-LLM, described in the paper &lt;a href=&#34;https://arxiv.org/abs/2402.09171&#34;&gt;Automated Unit Test Improvement using Large Language Models at Meta&lt;/a&gt;.&lt;/h4&gt; &#xA;&lt;h1&gt;Cover-Agent&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to Cover-Agent. This focused project utilizes Generative AI to automate and enhance the generation of tests (currently mostly unit tests), aiming to streamline development workflows. Cover-Agent can run via a terminal, and is planned to be integrated into popular CI platforms. &lt;a href=&#34;https://youtu.be/fIYkSEJ4eqE?feature=shared&#34;&gt;&lt;img src=&#34;https://www.codium.ai/wp-content/uploads/2024/05/CodiumAI-CoverAgent-v240519-small-loop.gif&#34; alt=&#34;Test generation xxx&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;We invite the community to collaborate and help extend the capabilities of Cover Agent, continuing its development as a cutting-edge solution in the automated unit test generation domain. We also wish to inspire researchers to leverage this open-source tool to explore new test-generation techniques.&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;This tool is part of a broader suite of utilities designed to automate the creation of unit tests for software projects. Utilizing advanced Generative AI models, it aims to simplify and expedite the testing process, ensuring high-quality software development. The system comprises several components:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Test Runner:&lt;/strong&gt; Executes the command or scripts to run the test suite and generate code coverage reports.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Coverage Parser:&lt;/strong&gt; Validates that code coverage increases as tests are added, ensuring that new tests contribute to the overall test effectiveness.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Prompt Builder:&lt;/strong&gt; Gathers necessary data from the codebase and constructs the prompt to be passed to the Large Language Model (LLM).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;AI Caller:&lt;/strong&gt; Interacts with the LLM to generate tests based on the prompt provided.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Installation and Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;p&gt;Before you begin, make sure you have the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt; set in your environment variables, which is required for calling the OpenAI API.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If running directly from the repository you will also need:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python installed on your system.&lt;/li&gt; &#xA; &lt;li&gt;Poetry installed for managing Python package dependencies. Installation instructions for Poetry can be found at &lt;a href=&#34;https://python-poetry.org/docs/&#34;&gt;https://python-poetry.org/docs/&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Standalone Runtime&lt;/h3&gt; &#xA;&lt;p&gt;The Cover Agent can be installed as a Python Pip package or run as a standalone executable.&lt;/p&gt; &#xA;&lt;h4&gt;Python Pip&lt;/h4&gt; &#xA;&lt;p&gt;To install the Python Pip package directly via GitHub run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install git+https://github.com/Codium-ai/cover-agent.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Binary&lt;/h4&gt; &#xA;&lt;p&gt;The binary can be run without any Python environment installed on your system (e.g. within a Docker container that does not contain Python). You can download the release for your system by navigating to the project&#39;s &lt;a href=&#34;https://github.com/Codium-ai/cover-agent/releases&#34;&gt;release page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Repository Setup&lt;/h3&gt; &#xA;&lt;p&gt;Run the following command to install all the dependencies and run the project from source:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;poetry install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running the Code&lt;/h3&gt; &#xA;&lt;p&gt;After downloading the executable or installing the Pip package you can run the Cover Agent to generate and validate unit tests. Execute it from the command line by using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cover-agent \&#xA;  --source-file-path &#34;&amp;lt;path_to_source_file&amp;gt;&#34; \&#xA;  --test-file-path &#34;&amp;lt;path_to_test_file&amp;gt;&#34; \&#xA;  --code-coverage-report-path &#34;&amp;lt;path_to_coverage_report&amp;gt;&#34; \&#xA;  --test-command &#34;&amp;lt;test_command_to_run&amp;gt;&#34; \&#xA;  --test-command-dir &#34;&amp;lt;directory_to_run_test_command&amp;gt;&#34; \&#xA;  --coverage-type &#34;&amp;lt;type_of_coverage_report&amp;gt;&#34; \&#xA;  --desired-coverage &amp;lt;desired_coverage_between_0_and_100&amp;gt; \&#xA;  --max-iterations &amp;lt;max_number_of_llm_iterations&amp;gt; \&#xA;  --included-files &#34;&amp;lt;optional_list_of_files_to_include&amp;gt;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can use the example projects within this repository to run this code as a test.&lt;/p&gt; &#xA;&lt;p&gt;Follow the steps in the README.md file located in the &lt;code&gt;templated_tests/python_fastapi/&lt;/code&gt; directory, then return to the root of the repository and run the following command to add tests to the &lt;strong&gt;python fastapi&lt;/strong&gt; example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cover-agent \&#xA;  --source-file-path &#34;templated_tests/python_fastapi/app.py&#34; \&#xA;  --test-file-path &#34;templated_tests/python_fastapi/test_app.py&#34; \&#xA;  --code-coverage-report-path &#34;templated_tests/python_fastapi/coverage.xml&#34; \&#xA;  --test-command &#34;pytest --cov=. --cov-report=xml --cov-report=term&#34; \&#xA;  --test-command-dir &#34;templated_tests/python_fastapi&#34; \&#xA;  --coverage-type &#34;cobertura&#34; \&#xA;  --desired-coverage 70 \&#xA;  --max-iterations 10&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For an example using &lt;strong&gt;go&lt;/strong&gt; &lt;code&gt;cd&lt;/code&gt; into &lt;code&gt;templated_tests/go_webservice&lt;/code&gt;, set up the project following the &lt;code&gt;README.md&lt;/code&gt;. To work with coverage reporting, you need to install &lt;code&gt;gocov&lt;/code&gt; and &lt;code&gt;gocov-xml&lt;/code&gt;. Run the following commands to install these tools:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;go install github.com/axw/gocov/gocov@v1.1.0&#xA;go install github.com/AlekSi/gocov-xml@v1.1.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and then run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cover-agent \&#xA;  --source-file-path &#34;app.go&#34; \&#xA;  --test-file-path &#34;app_test.go&#34; \&#xA;  --code-coverage-report-path &#34;coverage.xml&#34; \&#xA;  --test-command &#34;go test -coverprofile=coverage.out &amp;amp;&amp;amp; gocov convert coverage.out | gocov-xml &amp;gt; coverage.xml&#34; \&#xA;  --test-command-dir $(pwd) \&#xA;  --coverage-type &#34;cobertura&#34; \&#xA;  --desired-coverage 70 \&#xA;  --max-iterations 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Try and add more tests to this project by running this command at the root of this repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;poetry run cover-agent \&#xA;  --source-file-path &#34;cover_agent/main.py&#34; \&#xA;  --test-file-path &#34;tests/test_main.py&#34; \&#xA;  --code-coverage-report-path &#34;coverage.xml&#34; \&#xA;  --test-command &#34;poetry run pytest --junitxml=testLog.xml --cov=templated_tests --cov=cover_agent --cov-report=xml --cov-report=term --log-cli-level=INFO&#34; \&#xA;  --coverage-type &#34;cobertura&#34; \&#xA;  --desired-coverage 70 \&#xA;  --max-iterations 1 \&#xA;  --model &#34;gpt-4o&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: If you are using Poetry then use the &lt;code&gt;poetry run cover-agent&lt;/code&gt; command instead of the &lt;code&gt;cover-agent&lt;/code&gt; run command.&lt;/p&gt; &#xA;&lt;h3&gt;Outputs&lt;/h3&gt; &#xA;&lt;p&gt;A few debug files will be outputted locally within the repository (that are part of the &lt;code&gt;.gitignore&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;generated_prompt.md&lt;/code&gt;: The full prompt that is sent to the LLM&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;run.log&lt;/code&gt;: A copy of the logger that gets dumped to your &lt;code&gt;stdout&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;test_results.html&lt;/code&gt;: A results table that contains the following for each generated test: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Test status&lt;/li&gt; &#xA;   &lt;li&gt;Failure reason (if applicable)&lt;/li&gt; &#xA;   &lt;li&gt;Exit code,&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;stderr&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;stdout&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Generated test&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Using other LLMs&lt;/h3&gt; &#xA;&lt;p&gt;This project uses LiteLLM to communicate with OpenAI and other hosted LLMs (supporting 100+ LLMs to date). To use a different model other than the OpenAI default you&#39;ll need to:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Export any environment variables needed by the supported LLM &lt;a href=&#34;https://litellm.vercel.app/docs/proxy/quick_start#supported-llms&#34;&gt;following the LiteLLM instructions&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Call the name of the model using the &lt;code&gt;--model&lt;/code&gt; option when calling Cover Agent.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For example (as found in the &lt;a href=&#34;https://litellm.vercel.app/docs/proxy/quick_start#supported-llms&#34;&gt;LiteLLM Quick Start guide&lt;/a&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export VERTEX_PROJECT=&#34;hardy-project&#34;&#xA;export VERTEX_LOCATION=&#34;us-west&#34;&#xA;&#xA;cover-agent \&#xA;  ...&#xA;  --model &#34;vertex_ai/gemini-pro&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;p&gt;This section discusses the development of this project.&lt;/p&gt; &#xA;&lt;h3&gt;Versioning&lt;/h3&gt; &#xA;&lt;p&gt;Before merging to main make sure to manually increment the version number in &lt;code&gt;cover_agent/version.txt&lt;/code&gt; at the root of the repository.&lt;/p&gt; &#xA;&lt;h3&gt;Running Tests&lt;/h3&gt; &#xA;&lt;p&gt;Set up your development environment by running the &lt;code&gt;poetry install&lt;/code&gt; command as you did above.&lt;/p&gt; &#xA;&lt;p&gt;Note: for older versions of Poetry you may need to include the &lt;code&gt;--dev&lt;/code&gt; option to install Dev dependencies.&lt;/p&gt; &#xA;&lt;p&gt;After setting up your environment run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;poetry run pytest --junitxml=testLog.xml --cov=templated_tests --cov=cover_agent --cov-report=xml --cov-report=term --log-cli-level=INFO&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will also generate all logs and output reports that are generated in &lt;code&gt;.github/workflows/ci_pipeline.yml&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;p&gt;Below is the roadmap of planned features, with the current implementation status:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Automatically generates unit tests for your software projects, utilizing advanced AI models to ensure comprehensive test coverage and quality assurance. (similar to Meta) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Being able to generate tests for different programming languages&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Being able to deal with a large variety of testing scenarios&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Generate a behavior analysis for the code under test, and generate tests accordingly&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Check test flakiness, e.g. by running 5 times as suggested by TestGen-LLM&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Cover more test generation pains &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Generate new tests that are focused on the PR changeset&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Run over an entire repo/code-base and attempt to enhance all existing test suites&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Improve usability &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Connectors for GitHub Actions, Jenkins, CircleCI, Travis CI, and more&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Integrate into databases, APIs, OpenTelemetry and other sources of data to extract relevant i/o for the test generation&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add a setting file&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;CodiumAI&lt;/h2&gt; &#xA;&lt;p&gt;CodiumAI&#39;s mission is to enable busy dev teams to increase and maintain their code integrity. We offer various tools, including &#34;Pro&#34; versions of our open-source tools, which are meant to handle enterprise-level code complexity and are multi-repo codebase aware.&lt;/p&gt;</summary>
  </entry>
</feed>