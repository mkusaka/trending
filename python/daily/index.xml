<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-27T01:43:09Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>lvwerra/trl</title>
    <updated>2023-01-27T01:43:09Z</updated>
    <id>tag:github.com,2023-01-27:/lvwerra/trl</id>
    <link href="https://github.com/lvwerra/trl" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Train transformer language models with reinforcement learning.&lt;/p&gt;&lt;hr&gt;&lt;div style=&#34;text-align: center&#34;&gt; &#xA; &lt;img src=&#34;https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/trl_banner_dark.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;TRL - Transformer Reinforcement Learning&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Train transformer language models with reinforcement learning.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;What is it?&lt;/h2&gt; &#xA;&lt;p&gt;With &lt;code&gt;trl&lt;/code&gt; you can train transformer language models with Proximal Policy Optimization (PPO). The library is built on top of the &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;&lt;code&gt;transformers&lt;/code&gt;&lt;/a&gt; library by ðŸ¤— Hugging Face. Therefore, pre-trained language models can be directly loaded via &lt;code&gt;transformers&lt;/code&gt;. At this point most of decoder architectures and encoder-decoder architectures are supported.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Highlights:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;PPOTrainer&lt;/code&gt;: A PPO trainer for language models that just needs (query, response, reward) triplets to optimise the language model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;AutoModelForCausalLMWithValueHead&lt;/code&gt; &amp;amp; &lt;code&gt;AutoModelForSeq2SeqLMWithValueHead&lt;/code&gt;: A transformer model with an additional scalar output for each token which can be used as a value function in reinforcement learning.&lt;/li&gt; &#xA; &lt;li&gt;Example: Train GPT2 to generate positive movie reviews with a BERT sentiment classifier.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How it works&lt;/h2&gt; &#xA;&lt;p&gt;Fine-tuning a language model via PPO consists of roughly three steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Rollout&lt;/strong&gt;: The language model generates a response or continuation based on query which could be the start of a sentence.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Evaluation&lt;/strong&gt;: The query and response are evaluated with a function, model, human feedback or some combination of them. The important thing is that this process should yield a scalar value for each query/response pair.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Optimization&lt;/strong&gt;: This is the most complex part. In the optimisation step the query/response pairs are used to calculate the log-probabilities of the tokens in the sequences. This is done with the model that is trained and and a reference model, which is usually the pre-trained model before fine-tuning. The KL-divergence between the two outputs is used as an additional reward signal to make sure the generated responses don&#39;t deviate to far from the reference language model. The active language model is then trained with PPO.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;This process is illustrated in the sketch below:&lt;/p&gt; &#xA;&lt;div style=&#34;text-align: center&#34;&gt; &#xA; &lt;img src=&#34;https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/trl_overview.png&#34; width=&#34;800&#34;&gt; &#xA; &lt;p style=&#34;text-align: center;&#34;&gt; &lt;b&gt;Figure:&lt;/b&gt; Sketch of the workflow. &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Python package&lt;/h3&gt; &#xA;&lt;p&gt;Install the library with pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install trl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;From source&lt;/h3&gt; &#xA;&lt;p&gt;If you want to run the examples in the repository a few additional libraries are required. Clone the repository and install it with pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/lvwerra/trl.git&#xA;cd trl/&#xA;pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;How to use&lt;/h2&gt; &#xA;&lt;h3&gt;Example&lt;/h3&gt; &#xA;&lt;p&gt;This is a basic example on how to use the library. Based on a query the language model creates a response which is then evaluated. The evaluation could be a human in the loop or another model&#39;s output.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# imports&#xA;import torch&#xA;from transformers import AutoTokenizer&#xA;from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model&#xA;from trl.core import respond_to_batch&#xA;&#xA;# get models&#xA;model = AutoModelForCausalLMWithValueHead.from_pretrained(&#39;gpt2&#39;)&#xA;model_ref = create_reference_model(model)&#xA;&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;gpt2&#39;)&#xA;&#xA;# initialize trainer&#xA;ppo_config = PPOConfig(&#xA;    batch_size=1,&#xA;    forward_batch_size=1&#xA;)&#xA;&#xA;# encode a query&#xA;query_txt = &#34;This morning I went to the &#34;&#xA;query_tensor = tokenizer.encode(query_txt, return_tensors=&#34;pt&#34;)&#xA;&#xA;# get model response&#xA;response_tensor  = respond_to_batch(model_ref, query_tensor)&#xA;&#xA;# create a ppo trainer&#xA;ppo_trainer = PPOTrainer(ppo_config, model, model_ref, tokenizer)&#xA;&#xA;# define a reward for response&#xA;# (this could be any reward such as human feedback or output from another model)&#xA;reward = [torch.tensor(1.0)]&#xA;&#xA;# train model for one step with ppo&#xA;train_stats = ppo_trainer.step([query_tensor[0]], [response_tensor[0]], reward)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Advanced example: IMDB sentiment&lt;/h3&gt; &#xA;&lt;p&gt;For a detailed example check out the example python script &lt;code&gt;examples/scripts/ppo-sentiment.py&lt;/code&gt;, where GPT2 is fine-tuned to generate positive movie reviews. An few examples from the language models before and after optimisation are given below:&lt;/p&gt; &#xA;&lt;div style=&#34;text-align: center&#34;&gt; &#xA; &lt;img src=&#34;https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/table_imdb_preview.png&#34; width=&#34;800&#34;&gt; &#xA; &lt;p style=&#34;text-align: center;&#34;&gt; &lt;b&gt;Figure:&lt;/b&gt; A few review continuations before and after optimisation. &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;h3&gt;Proximal Policy Optimisation&lt;/h3&gt; &#xA;&lt;p&gt;The PPO implementation largely follows the structure introduced in the paper &lt;strong&gt;&#34;Fine-Tuning Language Models from Human Preferences&#34;&lt;/strong&gt; by D. Ziegler et al. [&lt;a href=&#34;https://arxiv.org/pdf/1909.08593.pdf&#34;&gt;paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/openai/lm-human-preferences&#34;&gt;code&lt;/a&gt;].&lt;/p&gt; &#xA;&lt;h3&gt;Language models&lt;/h3&gt; &#xA;&lt;p&gt;The language models utilize the &lt;code&gt;transformers&lt;/code&gt; library by ðŸ¤— Hugging Face.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>readthedocs/readthedocs.org</title>
    <updated>2023-01-27T01:43:09Z</updated>
    <id>tag:github.com,2023-01-27:/readthedocs/readthedocs.org</id>
    <link href="https://github.com/readthedocs/readthedocs.org" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The source code that powers readthedocs.org&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Welcome to Read the Docs&lt;/h1&gt; &#xA;&lt;p&gt;|build-status| |docs| |coverage|&lt;/p&gt; &#xA;&lt;h2&gt;Purpose&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;Read the Docs&lt;/code&gt;_ hosts documentation for the open source community. It supports Sphinx_ docs written with reStructuredText_, and can pull from your Subversion_, Bazaar_, Git_, and Mercurial_ repositories. Then we build documentation and host it for you. Think of it as &lt;em&gt;Continuous Documentation&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;.. _Read the docs: &lt;a href=&#34;https://readthedocs.org/&#34;&gt;https://readthedocs.org/&lt;/a&gt; .. _Sphinx: &lt;a href=&#34;http://www.sphinx-doc.org/&#34;&gt;http://www.sphinx-doc.org/&lt;/a&gt; .. _reStructuredText: &lt;a href=&#34;http://www.sphinx-doc.org/en/master/usage/restructuredtext/basics.html&#34;&gt;http://www.sphinx-doc.org/en/master/usage/restructuredtext/basics.html&lt;/a&gt; .. _Subversion: &lt;a href=&#34;http://subversion.tigris.org/&#34;&gt;http://subversion.tigris.org/&lt;/a&gt; .. _Bazaar: &lt;a href=&#34;http://bazaar.canonical.com/&#34;&gt;http://bazaar.canonical.com/&lt;/a&gt; .. _Git: &lt;a href=&#34;http://git-scm.com/&#34;&gt;http://git-scm.com/&lt;/a&gt; .. _Mercurial: &lt;a href=&#34;https://www.mercurial-scm.org/&#34;&gt;https://www.mercurial-scm.org/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Documentation for RTD&lt;/h2&gt; &#xA;&lt;p&gt;You will find complete documentation for setting up your project at &lt;code&gt;the Read the Docs site&lt;/code&gt;_.&lt;/p&gt; &#xA;&lt;p&gt;.. _the Read the Docs site: &lt;a href=&#34;https://docs.readthedocs.io/&#34;&gt;https://docs.readthedocs.io/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Get in touch&lt;/h2&gt; &#xA;&lt;p&gt;You can find information about getting in touch with Read the Docs at our &lt;code&gt;Contribution page &amp;lt;https://docs.readthedocs.io/en/latest/contribute.html#get-in-touch&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;You can find information about contributing to Read the Docs at our &lt;code&gt;Contribution page &amp;lt;https://docs.readthedocs.io/en/latest/contribute.html&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &#xA;&lt;h2&gt;Quickstart for GitHub-Hosted Projects&lt;/h2&gt; &#xA;&lt;p&gt;By the end of this quickstart, you will have a new project automatically updated when you push to GitHub.&lt;/p&gt; &#xA;&lt;p&gt;#. Create an account on &lt;code&gt;Read the Docs&lt;/code&gt;_. You will get an email verifying your email address which you should accept within 7 days.&lt;/p&gt; &#xA;&lt;p&gt;#. Log in and click on &#34;Import a Project&#34;.&lt;/p&gt; &#xA;&lt;p&gt;#. Click &#34;Connect to GitHub&#34; in order to connect your account&#39;s repositories to GitHub.&lt;/p&gt; &#xA;&lt;p&gt;#. When prompted on GitHub, give access to your account.&lt;/p&gt; &#xA;&lt;p&gt;#. Click &#34;Import a Repository&#34; and select any desired repository.&lt;/p&gt; &#xA;&lt;p&gt;#. Change any information if desired and click &#34;Next&#34;.&lt;/p&gt; &#xA;&lt;p&gt;#. All done. Commit away and your project will auto-update.&lt;/p&gt; &#xA;&lt;p&gt;.. |build-status| image:: &lt;a href=&#34;https://circleci.com/gh/readthedocs/readthedocs.org.svg?style=svg&#34;&gt;https://circleci.com/gh/readthedocs/readthedocs.org.svg?style=svg&lt;/a&gt; :alt: build status :target: &lt;a href=&#34;https://circleci.com/gh/readthedocs/readthedocs.org&#34;&gt;https://circleci.com/gh/readthedocs/readthedocs.org&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. |docs| image:: &lt;a href=&#34;https://readthedocs.org/projects/docs/badge/?version=latest&#34;&gt;https://readthedocs.org/projects/docs/badge/?version=latest&lt;/a&gt; :alt: Documentation Status :scale: 100% :target: &lt;a href=&#34;https://docs.readthedocs.io/en/latest/?badge=latest&#34;&gt;https://docs.readthedocs.io/en/latest/?badge=latest&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. |coverage| image:: &lt;a href=&#34;https://codecov.io/gh/readthedocs/readthedocs.org/branch/main/graph/badge.svg&#34;&gt;https://codecov.io/gh/readthedocs/readthedocs.org/branch/main/graph/badge.svg&lt;/a&gt; :alt: Test coverage :scale: 100% :target: &lt;a href=&#34;https://codecov.io/gh/readthedocs/readthedocs.org&#34;&gt;https://codecov.io/gh/readthedocs/readthedocs.org&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;MIT&lt;/code&gt;_ Â© 2010 Read the Docs, Inc. &amp;amp; contributors&lt;/p&gt; &#xA;&lt;p&gt;.. _MIT: LICENSE&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>PRBonn/kiss-icp</title>
    <updated>2023-01-27T01:43:09Z</updated>
    <id>tag:github.com,2023-01-27:/PRBonn/kiss-icp</id>
    <link href="https://github.com/PRBonn/kiss-icp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;KISS-ICP: In Defense of Point-to-Point ICP â€“ Simple, Accurate, and Robust Registration If Done in the Right Way https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/vizzo2023ral.pdf&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;KISS-ICP: In Defense of Point-to-Point ICP â€“ Simple, Accurate, and Robust Registration If Done the Right Way&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/ubuntu-333333?style=flat&amp;amp;logo=ubuntu&#34; alt=&#34;ubuntu&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/windows-333333?style=flat&amp;amp;logo=windows&amp;amp;logocolor=blue&#34; alt=&#34;windows&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/-macos-333333?style=flat&amp;amp;logo=apple&#34; alt=&#34;macos&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/21349875/211829074-474bec08-0129-4e34-85e7-62265e44a7de.png&#34; alt=&#34;overview&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Point cloud maps (blue) generated online by our proposed odometry pipeline on different datasets with the same set of parameters. We depict the latest scan in yellow. The scans are recorded using different sensors with different point densities, different orientations, and different shooting patterns. The automotive example stems from the MulRan dataset. The drone of the Voxgraph dataset and the segway robot used in the NCLT dataset show a high acceleration motion profile. The handheld mechanical LiDAR of LOAM Livox has a completely different shooting pattern than the commonly used rotating mechanical LiDAR.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ðŸ“° NEWS!!! ðŸ“° ROS API&lt;/h2&gt; &#xA;&lt;p&gt;It was never this easy, just git clone this repo into your catkin workspace and build it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd ~/catkin_ws/ &amp;amp;&amp;amp; git clone https://github.com/PRBonn/kiss-icp &amp;amp;&amp;amp; catkin build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more detailed instructions on the ROS wrapper, please visit &lt;a href=&#34;https://raw.githubusercontent.com/PRBonn/kiss-icp/main/src/cpp/kiss_icp_ros/ros1/README.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;ROS Video Example&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/21349875/214578180-b1d2431c-8fff-440e-aa6e-99a1d85989b5.mp4&#34;&gt;https://user-images.githubusercontent.com/21349875/214578180-b1d2431c-8fff-440e-aa6e-99a1d85989b5.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Install Python API&lt;/h2&gt; &#xA;&lt;p&gt;We released a python-package supported on &lt;img src=&#34;https://img.shields.io/badge/-macos-333333?style=flat&amp;amp;logo=apple&#34; alt=&#34;macos&#34;&gt;, &lt;img src=&#34;https://img.shields.io/badge/windows-333333?style=flat&amp;amp;logo=windows&amp;amp;logocolor=blue&#34; alt=&#34;windows&#34;&gt;, and &lt;img src=&#34;https://img.shields.io/badge/ubuntu-333333?style=flat&amp;amp;logo=ubuntu&#34; alt=&#34;ubuntu&#34;&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To get started, just run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install kiss-icp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you also want to install all the &lt;em&gt;(optional)&lt;/em&gt; dependencies, like Open3D for running the visualizer:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install &#34;kiss-icp[all]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, follow the instructions on how to run the system by typing:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;kiss_icp_pipeline --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This should print the following help message: &lt;img src=&#34;https://user-images.githubusercontent.com/21349875/193282970-25a400aa-ebcd-487a-b839-faa04eeca5b9.png&#34; alt=&#34;out&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Install Python API (developer mode)&lt;/h3&gt; &#xA;&lt;p&gt;If you plan to modify the code then you need to setup the dev dependencies, luckilly, the only real requirements are a modern C++ compiler and the &lt;code&gt;pip&lt;/code&gt; package manager, nothing else!, in Ubuntu-based sytems this can be done with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo apt install g++ python3-pip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After that you can clone the code and install the python api:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/PRBonn/kiss-icp.git&#xA;cd kiss-icp&#xA;pip install --verbose .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Install Python API (expert mode)&lt;/h3&gt; &#xA;&lt;p&gt;If you want to have more controll over the build, you should then install &lt;code&gt;cmake&lt;/code&gt;, ,&lt;code&gt;ninja&lt;/code&gt;, &lt;code&gt;tbb&lt;/code&gt;, &lt;code&gt;Eigen&lt;/code&gt;, and &lt;code&gt;pybind11&lt;/code&gt; as extra dependencies in your system, the ubuntu-way of doing this is:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo apt install build-essential libeigen3-dev libtbb-dev pybind11-dev ninja-build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Teaser Video&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/38326482/189950820-030fd9e4-406b-4d14-8171-43b134344223.mp4&#34;&gt;https://user-images.githubusercontent.com/38326482/189950820-030fd9e4-406b-4d14-8171-43b134344223.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Authors&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ignacio Vizzo&lt;/li&gt; &#xA; &lt;li&gt;Tiziano Guadagnino&lt;/li&gt; &#xA; &lt;li&gt;Benedikt Mersch&lt;/li&gt; &#xA; &lt;li&gt;Louis Wiesmann&lt;/li&gt; &#xA; &lt;li&gt;Jens Behley&lt;/li&gt; &#xA; &lt;li&gt;Cyrill Stachniss&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you use this library for any academic work, please cite our original &lt;a href=&#34;https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/vizzo2023ral.pdf&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{vizzo2023ral,&#xA;  author    = {Vizzo, Ignacio and Guadagnino, Tiziano and Mersch, Benedikt and Wiesmann, Louis and Behley, Jens and Stachniss, Cyrill},&#xA;  title     = {{KISS-ICP: In Defense of Point-to-Point ICP -- Simple, Accurate, and Robust Registration If Done the Right Way}},&#xA;  journal   = {IEEE Robotics and Automation Letters (RA-L)},&#xA;  pages     = {1-8},&#xA;  doi       = {10.1109/LRA.2023.3236571},&#xA;  volume    = {8},&#xA;  number    = {2},&#xA;  year      = {2023},&#xA;  codeurl   = {https://github.com/PRBonn/kiss-icp},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#PRBonn/kiss-icp&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=PRBonn/kiss-icp&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>