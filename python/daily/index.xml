<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-10-22T01:40:24Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>tairov/llama2.mojo</title>
    <updated>2023-10-22T01:40:24Z</updated>
    <id>tag:github.com,2023-10-22:/tairov/llama2.mojo</id>
    <link href="https://github.com/tairov/llama2.mojo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Inference Llama 2 in one file of pure ğŸ”¥&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;llama2.ğŸ”¥&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/tairov/llama2.mojo/master/assets/llama2.mojo-demo.gif&#34; width=&#34;700&#34; alt=&#34;llama2.mojo logo&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Have you ever wanted to inference a baby Llama 2 model in pure Mojo? No? Well, now you can!&lt;/p&gt; &#xA;&lt;p&gt;supported version: &lt;a href=&#34;https://docs.modular.com/mojo/changelog.html#v0.4.0-2023-10-05&#34;&gt;Mojo 0.4.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;With the release of &lt;a href=&#34;https://www.modular.com/blog/mojo-its-finally-here&#34;&gt;Mojo&lt;/a&gt;, I was inspired to take my Python port of &lt;a href=&#34;https://github.com/tairov/llama2.py&#34;&gt;llama2.py&lt;/a&gt; and transition it to Mojo. The result? A version that leverages Mojo&#39;s SIMD &amp;amp; vectorization primitives, boosting the Python performance by nearly 250x. Impressively, the Mojo version now outperforms the original &lt;code&gt;llama2.c&lt;/code&gt; compiled in &lt;code&gt;runfast&lt;/code&gt; mode out of the box by 15-20%. This showcases the potential of hardware-level optimizations through Mojo&#39;s advanced features. I think this also can help us to see how far can we go with the original &lt;code&gt;llama2.c&lt;/code&gt; hardware optimizations.&lt;/p&gt; &#xA;&lt;h2&gt;performance&lt;/h2&gt; &#xA;&lt;p&gt;Since there were some debates was this comparison legit or not I did some research and found that in &lt;code&gt;runfast&lt;/code&gt; mode &lt;code&gt;llama2.c&lt;/code&gt; includes multiple optimizations like aggressive vectorization, which makes comparison fair with Mojo SIMD vectorization.&lt;/p&gt; &#xA;&lt;p&gt;UPD. further improvements of &lt;code&gt;llama2.mojo&lt;/code&gt; parallelization make it working slightly better or the same as C on different models.&lt;/p&gt; &#xA;&lt;h2&gt;supported models&lt;/h2&gt; &#xA;&lt;p&gt;At the moment, the following models were successfully executed via &lt;code&gt;llama2.mojo&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories 260K, 15M, 110M&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Tinyllama-1.1B-Chat-v0.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;extensive benchmark on Apple M1 Max&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://engiware.com/benchmark/llama2-ports-extensive-benchmarks-mac-m1-max.html&#34;&gt;mojo vs 6 programming languages&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;benchmark (updated)&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/karpathy/llama2.c&#34;&gt;llama2.c&lt;/a&gt; (OMP/parallelized)&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;llama2.mojo&lt;/strong&gt; (parallelized)&lt;/th&gt; &#xA;   &lt;th&gt;llama2.mojo (naive matmul)&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/tairov/llama2.py&#34;&gt;llama2.py&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories15M.bin&lt;/td&gt; &#xA;   &lt;td&gt;435 tok/s&lt;/td&gt; &#xA;   &lt;td&gt;440 tok/s&lt;/td&gt; &#xA;   &lt;td&gt;67.26 tok/s&lt;/td&gt; &#xA;   &lt;td&gt;1.3 tok/s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;stories110M.bin&lt;/td&gt; &#xA;   &lt;td&gt;64 tok/s&lt;/td&gt; &#xA;   &lt;td&gt;63 tok/s&lt;/td&gt; &#xA;   &lt;td&gt;9.20 tok/s&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TinyLlama-1.1B&lt;/td&gt; &#xA;   &lt;td&gt;7.25 tok/s&lt;/td&gt; &#xA;   &lt;td&gt;7.25 tok/s&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;OS/HW specs&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;OS:         Ubuntu 20.04&#xA;CPU(s):     6&#xA;Model name: Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz&#xA;CPU MHz:    3191.998&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;Make sure you have installed and &lt;a href=&#34;https://docs.modular.com/mojo/manual/get-started/index.html&#34;&gt;configured mojo on your environment&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Or you can use &lt;a href=&#34;https://playground.modular.com/&#34;&gt;mojo playground&lt;/a&gt; to run this model.&lt;/p&gt; &#xA;&lt;h2&gt;try the ğŸ”¥ magic&lt;/h2&gt; &#xA;&lt;p&gt;HuggingFace - &lt;a href=&#34;https://huggingface.co/spaces/radames/Gradio-llama2.mojo&#34;&gt;https://huggingface.co/spaces/radames/Gradio-llama2.mojo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;feel the ğŸ”¥ magic&lt;/h2&gt; &#xA;&lt;p&gt;First, navigate to the folder when you keep your projects and clone this repository to this folder:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/tairov/llama2.mojo.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, open the repository folder:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd llama2.mojo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now, let&#39;s download the model&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, just run the Mojo&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mojo llama2.mojo stories15M.bin -s 100 -n 256 -t 0.5 -i &#34;Mojo is a language&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;example output&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;num hardware threads:  6&#xA;SIMD vector width:  16&#xA;checkpoint size:  60816028 [ 57 MB ]&#xA;n layers:  6&#xA;vocab size:  32000&#xA;Mojo is a language that people like to talk. Hephones are very different from other people. He has a big book with many pictures and words. He likes to look at the pictures and learn new things.&#xA;One day, Mojo was playing with his friends in the park. They were running and laughing and having fun. Mojo told them about his book and his friends. They listened and looked at the pictures. Then, they saw a picture of a big, scary monster. They were very scared and ran away.&#xA;Mojo was sad that his book was gone. He told his friends about the monster and they all felt very sad. Mojo&#39;s friends tried to make him feel better, but nothing worked. Mojo never learned his language again.&#xA;achieved tok/s:  440.21739130434781&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;running via Docker&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker build --build-arg AUTH_KEY=&amp;lt;your-modular-auth-key&amp;gt; -t llama2.mojo .&#xA;docker run -it llama2.mojo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;With Gradio UI:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# uncomment the last line in Dockerfile CMD [&#34;python&#34;, &#34;gradio_app.py&#34;]&#xA;docker run -it -p 0.0.0.0:7860:7860 llama2.mojo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;citing llama2.ğŸ”¥&lt;/h2&gt; &#xA;&lt;p&gt;If you use or discuss llama2.mojo in your academic research, please cite the project to help spread awareness:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{llama2.mojo,&#xA;  author = {Aydyn Tairov}, &#xA;  title = {Inference Llama2 in one file of pure Mojo},&#xA;  year = {2023},&#xA;  month = {09},&#xA;  howpublished = {\url{https://github.com/tairov/llama2.mojo}},&#xA;  note = {Llama2 Mojo, MIT License}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We kindly request that you include a link to the GitHub repository in published papers. This will allow interested readers to easily find the latest updates and extensions to the project.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;llama2.mojo&lt;/code&gt; aims to encourage academic research on efficient implementations of transformer architectures, the &lt;code&gt;llama&lt;/code&gt; model, and applications of the &lt;code&gt;mojo&lt;/code&gt; programming language. Citing the project helps growth of the knowledge community around these topics. We appreciate your support through referencing &lt;code&gt;llama2.mojo&lt;/code&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;play with Tinyllama-1.1B-Chat-v0.2&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://github.com/jzhang38/TinyLlama&#34;&gt;TinyLlama&lt;/a&gt; is a 1.1B Llama model trained on 3 trillion tokens. This compactness allows it to cater to a multitude of applications demanding a restricted computation and memory footprint. This is also the reason why we select it as the first model to support.&lt;/p&gt; &#xA;&lt;p&gt;First, navigate to the folder when you keep your projects and clone this repository to this folder:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/tairov/llama2.mojo.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, open the repository folder:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd llama2.mojo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now, let&#39;s download the model and the tokenizer&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wget https://huggingface.co/kirp/TinyLlama-1.1B-Chat-v0.2-bin/resolve/main/tok_tl-chat.bin&#xA;wget https://huggingface.co/kirp/TinyLlama-1.1B-Chat-v0.2-bin/resolve/main/tl-chat.bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, just run the Mojo&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mojo llama2.mojo tl-chat.bin \&#xA;    -z tok_tl-chat.bin \&#xA;    -n 256 -t 0 -s 100 -i &#34;&amp;lt;|im_start|&amp;gt;user\nGive me a python function to generate Fibonacci sequence&amp;lt;|im_end|&amp;gt;\n&amp;lt;|im_start|&amp;gt;assistant\n&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;example output&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;num hardware threads:  6&#xA;SIMD vector width:  16&#xA;checkpoint size:  4400767004 [ 4196 MB ]&#xA;n layers:  22&#xA;vocab size:  32003&#xA;&amp;lt;|im_start|&amp;gt;user&#xA;Give me a python function to generate Fibonacci sequence&amp;lt;|im_end|&amp;gt;&#xA;&amp;lt;|im_start|&amp;gt;assistant&#xA;Sure, here&#39;s a Python function that generates the Fibonacci sequence:&#xA;&#xA;def fibonacci(n):&#xA;    if n &amp;lt;= 0:&#xA;        return 0&#xA;    elif n == 1:&#xA;        return 1&#xA;    else:&#xA;        return fibonacci(n-1) + fibonacci(n-2)&#xA;&#xA;This function takes an integer n as a parameter and returns the next Fibonacci number. It uses a recursive approach to calculate the Fibonacci numbers, starting from 0 and working up. The function returns the value it found at the current level of the recursion, which can be either 0 or a Fibonacci number.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;license&lt;/h2&gt; &#xA;&lt;p&gt;MIT&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>moesnow/March7thAssistant</title>
    <updated>2023-10-22T01:40:24Z</updated>
    <id>tag:github.com,2023-10-22:/moesnow/March7thAssistant</id>
    <link href="https://github.com/moesnow/March7thAssistant" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ğŸ§Š å´©åï¼šæ˜Ÿç©¹é“é“ è‡ªåŠ¨æ—¥å¸¸ï½œæ¯æ—¥å®è®­ï½œæ¸…ä½“åŠ›ï½œé”„å¤§åœ°ï½œæ¨¡æ‹Ÿå®‡å®™ï½œå¿˜å´ä¹‹åº­ï½œå›¾å½¢ç•Œé¢ï½œæ¶ˆæ¯æ¨é€ï½œå¾ªç¯è¿è¡Œ&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/moesnow/March7thAssistant/main/assets/screenshot/March7th.png&#34;&gt; &lt;/p&gt; &#xA; &lt;h1&gt; ä¸‰æœˆä¸ƒå°åŠ©æ‰‹&lt;br&gt; March7thAssistant &lt;/h1&gt; &#xA; &lt;p&gt; &lt;img alt=&#34;&#34; src=&#34;https://img.shields.io/badge/platform-Windows-blue?style=flat-square&amp;amp;color=4096d8&#34;&gt; &lt;img alt=&#34;&#34; src=&#34;https://img.shields.io/github/last-commit/moesnow/March7thAssistant?style=flat-square&amp;amp;color=f18cb9&#34;&gt; &lt;img alt=&#34;&#34; src=&#34;https://img.shields.io/github/v/release/moesnow/March7thAssistant?style=flat-square&amp;amp;color=4096d8&#34;&gt; &lt;img alt=&#34;&#34; src=&#34;https://img.shields.io/github/downloads/moesnow/March7thAssistant/total?style=flat-square&amp;amp;color=f18cb9&#34;&gt; &lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;ç®€ä½“ä¸­æ–‡&lt;/strong&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/moesnow/March7thAssistant/main/README_TW.md&#34;&gt;ç¹é«”ä¸­æ–‡&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/moesnow/March7thAssistant/main/README_EN.md&#34;&gt;English&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;å¿«é€Ÿä¸Šæ‰‹ï¼Œè¯·è®¿é—®ï¼š&lt;a href=&#34;https://moesnow.github.io/March7thAssistant/#/assets/docs/Tutorial&#34;&gt;ä½¿ç”¨æ•™ç¨‹&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;é‡åˆ°é—®é¢˜ï¼Œè¯·åœ¨æé—®å‰æŸ¥çœ‹ï¼š&lt;a href=&#34;https://moesnow.github.io/March7thAssistant/#/assets/docs/FAQ&#34;&gt;FAQ&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;åŠŸèƒ½ç®€ä»‹&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;æ—¥å¸¸&lt;/strong&gt;ï¼šæ¸…ä½“åŠ›ã€æ¯æ—¥å®è®­ã€é¢†å¥–åŠ±ã€å§”æ‰˜ã€é”„å¤§åœ°&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;å‘¨å¸¸&lt;/strong&gt;ï¼šå†æˆ˜ä½™å“ã€æ¨¡æ‹Ÿå®‡å®™ã€å¿˜å´ä¹‹åº­&lt;/li&gt; &#xA; &lt;li&gt;æ¯æ—¥å®è®­ç­‰ä»»åŠ¡çš„å®Œæˆæƒ…å†µæ”¯æŒæ¶ˆæ¯æ¨é€&lt;/li&gt; &#xA; &lt;li&gt;å‡Œæ™¨å››ç‚¹æˆ–ä½“åŠ›æ¢å¤åˆ°æŒ‡å®šå€¼åè‡ªåŠ¨å¯åŠ¨&lt;/li&gt; &#xA; &lt;li&gt;ä»»åŠ¡å®Œæˆåå£°éŸ³æç¤ºã€è‡ªåŠ¨å…³é—­æ¸¸æˆæˆ–å…³æœº&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;å…¶ä¸­æ¨¡æ‹Ÿå®‡å®™è°ƒç”¨çš„ &lt;a href=&#34;https://github.com/CHNZYX/Auto_Simulated_Universe&#34;&gt;Auto_Simulated_Universe&lt;/a&gt; é¡¹ç›®ï¼Œé”„å¤§åœ°è°ƒç”¨çš„ &lt;a href=&#34;https://github.com/linruowuyin/Fhoe-Rail&#34;&gt;Fhoe-Rail&lt;/a&gt; é¡¹ç›®&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;è¯¦æƒ…è§ &lt;a href=&#34;https://raw.githubusercontent.com/moesnow/March7thAssistant/main/assets/config/config.example.yaml&#34;&gt;é…ç½®æ–‡ä»¶&lt;/a&gt; æˆ–å›¾å½¢ç•Œé¢è®¾ç½® ï½œğŸŒŸå–œæ¬¢å°±ç»™ä¸ªæ˜Ÿæ˜Ÿå§|ï½¥Ï‰ï½¥) ğŸŒŸï½œQQç¾¤ &lt;a href=&#34;https://qm.qq.com/q/9gFqUrUGVq&#34;&gt;855392201&lt;/a&gt; TGç¾¤ &lt;a href=&#34;https://t.me/+ZgH5zpvFS8o0NGI1&#34;&gt;ç‚¹å‡»è·³è½¬&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ç•Œé¢å±•ç¤º&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/moesnow/March7thAssistant/main/assets/screenshot/README.png&#34; alt=&#34;README&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;æ³¨æ„äº‹é¡¹&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;å¿…é¡»ä½¿ç”¨&lt;strong&gt;PCç«¯&lt;/strong&gt; &lt;code&gt;1920*1080&lt;/code&gt; åˆ†è¾¨ç‡çª—å£æˆ–å…¨å±è¿è¡Œæ¸¸æˆï¼ˆä¸æ”¯æŒHDRï¼‰&lt;/li&gt; &#xA; &lt;li&gt;æ¨¡æ‹Ÿå®‡å®™ç›¸å…³ &lt;a href=&#34;https://asu.stysqy.top/&#34;&gt;é¡¹ç›®æ–‡æ¡£&lt;/a&gt; &lt;a href=&#34;https://asu.stysqy.top/guide/qa.html&#34;&gt;Q&amp;amp;A&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;éœ€è¦åå°è¿è¡Œæˆ–å¤šæ˜¾ç¤ºå™¨å¯ä»¥å°è¯• &lt;a href=&#34;https://asu.stysqy.top/guide/bs.html&#34;&gt;è¿œç¨‹æœ¬åœ°å¤šç”¨æˆ·æ¡Œé¢&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;é‡åˆ°é”™è¯¯è¯·åœ¨ &lt;a href=&#34;https://github.com/moesnow/March7thAssistant/issues&#34;&gt;Issue&lt;/a&gt; åé¦ˆï¼Œæé—®è®¨è®ºå¯ä»¥åœ¨ &lt;a href=&#34;https://github.com/moesnow/March7thAssistant/discussions&#34;&gt;Discussions&lt;/a&gt; ï¼Œç¾¤èŠéšç¼˜çœ‹ï¼Œæ¬¢è¿ &lt;a href=&#34;https://github.com/moesnow/March7thAssistant/pulls&#34;&gt;PR&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ä¸‹è½½å®‰è£…&lt;/h2&gt; &#xA;&lt;p&gt;å‰å¾€ &lt;a href=&#34;https://github.com/moesnow/March7thAssistant/releases/latest&#34;&gt;Releases&lt;/a&gt; ä¸‹è½½åè§£å‹åŒå‡»ä¸‰æœˆä¸ƒå›¾æ ‡çš„ &lt;code&gt;March7th Launcher.exe&lt;/code&gt; æ‰“å¼€å›¾å½¢ç•Œé¢&lt;/p&gt; &#xA;&lt;p&gt;å¦‚æœéœ€è¦ä½¿ç”¨ &lt;strong&gt;ä»»åŠ¡è®¡åˆ’ç¨‹åº&lt;/strong&gt; å®šæ—¶è¿è¡Œæˆ–ç›´æ¥æ‰§è¡Œ &lt;strong&gt;å®Œæ•´è¿è¡Œ&lt;/strong&gt;ï¼Œå¯ä»¥ä½¿ç”¨ç»ˆç«¯å›¾æ ‡çš„ &lt;code&gt;March7th Assistant.exe&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;æ£€æµ‹æ›´æ–°å¯ä»¥ç‚¹å‡»å›¾å½¢ç•Œé¢è®¾ç½®æœ€åº•ä¸‹çš„æŒ‰é’®ï¼Œæˆ–åŒå‡» &lt;code&gt;Update.exe&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;æºç è¿è¡Œ&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœä½ æ˜¯å®Œå…¨ä¸æ‡‚çš„å°ç™½ï¼Œè¯·é€šè¿‡ä¸Šé¢çš„æ–¹å¼ä¸‹è½½å®‰è£…ï¼Œä¸ç”¨å¾€ä¸‹çœ‹äº†ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;git clone https://github.com/moesnow/March7thAssistant&#xA;cd March7thAssistant&#xA;pip install -r requirements.txt&#xA;python app.py&#xA;python main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;å¼€å‘ç›¸å…³&lt;/summary&gt; &#xA; &lt;p&gt;è·å– crop å‚æ•°è¡¨ç¤ºçš„è£å‰ªåæ ‡å¯ä»¥é€šè¿‡å›¾å½¢ç•Œé¢è®¾ç½®å†…çš„æ•è·æˆªå›¾åŠŸèƒ½&lt;/p&gt; &#xA; &lt;p&gt;python main.py åé¢æ”¯æŒå‚æ•° fight/universe/forgottenhall ç­‰&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;å¦‚æœå–œæ¬¢æœ¬é¡¹ç›®ï¼Œå¯ä»¥å¾®ä¿¡èµèµé€ä½œè€…ä¸€æ¯å’–å•¡â˜•&lt;/p&gt; &#xA;&lt;p&gt;æ‚¨çš„æ”¯æŒå°±æ˜¯ä½œè€…å¼€å‘å’Œç»´æŠ¤é¡¹ç›®çš„åŠ¨åŠ›ğŸš€&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/moesnow/March7thAssistant/main/assets/screenshot/sponsor.jpg&#34; alt=&#34;sponsor&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ç›¸å…³é¡¹ç›®&lt;/h2&gt; &#xA;&lt;p&gt;March7thAssistant ç¦»ä¸å¼€ä»¥ä¸‹å¼€æºé¡¹ç›®çš„å¸®åŠ©ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;æ¨¡æ‹Ÿå®‡å®™è‡ªåŠ¨åŒ– &lt;a href=&#34;https://github.com/CHNZYX/Auto_Simulated_Universe&#34;&gt;https://github.com/CHNZYX/Auto_Simulated_Universe&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;é”„å¤§åœ°è‡ªåŠ¨åŒ– &lt;a href=&#34;https://github.com/linruowuyin/Fhoe-Rail&#34;&gt;https://github.com/linruowuyin/Fhoe-Rail&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;OCRæ–‡å­—è¯†åˆ« &lt;a href=&#34;https://github.com/hiroi-sora/PaddleOCR-json&#34;&gt;https://github.com/hiroi-sora/PaddleOCR-json&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å›¾å½¢ç•Œé¢ç»„ä»¶åº“ &lt;a href=&#34;https://github.com/zhiyiYo/PyQt-Fluent-Widgets&#34;&gt;https://github.com/zhiyiYo/PyQt-Fluent-Widgets&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/moesnow/March7thAssistant/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=moesnow/March7thAssistant&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;Stargazers over time&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://starchart.cc/moesnow/March7thAssistant&#34;&gt;&lt;img src=&#34;https://starchart.cc/moesnow/March7thAssistant.svg?sanitize=true&#34; alt=&#34;Star History&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Planetary-Computers/autotab-starter</title>
    <updated>2023-10-22T01:40:24Z</updated>
    <id>tag:github.com,2023-10-22:/Planetary-Computers/autotab-starter</id>
    <link href="https://github.com/Planetary-Computers/autotab-starter" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Build browser agents for real world tasks&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;autotab&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to autotab! autotab makes it easy to create auditable browser automations using AI. Go from a point &amp;amp; click demonstration in the browser to live code for those actions in seconds.&lt;/p&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;It usually takes 5-10 minutes to get everything set up (including gathering passwords and installing dependencies). You must have the Chrome browser installed, and we recommend setting up a Python virtual environment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/Planetary-Computers/autotab-starter.git&#xA;cd autotab-starter&#xA;# Recommended: Setup a Python virtual environment&#xA;make install&#xA;brew install --cask chromedriver&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Configuration&lt;/h3&gt; &#xA;&lt;p&gt;Configure your credentials: Create a &lt;code&gt;.autotab.yaml&lt;/code&gt; file following the example in &lt;code&gt;.example.autotab.yaml&lt;/code&gt;. (~3 minutes)&lt;/p&gt; &#xA;&lt;h3&gt;Run&lt;/h3&gt; &#xA;&lt;p&gt;Run &lt;code&gt;autotab record&lt;/code&gt; to open a new browser window where you can start recording your actions.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Recording an automation&lt;/h3&gt; &#xA;&lt;p&gt;To record a new automation, run &lt;code&gt;autotab record&lt;/code&gt;. You can optionally add a &lt;code&gt;--agent &amp;lt;agent_name&amp;gt;&lt;/code&gt; argument. This will launch a Chrome session controlled by Selenium and then log you in to Google and open the autotab extension in the sidepanel.&lt;/p&gt; &#xA;&lt;p&gt;If the sidepanel does not open, type &lt;code&gt;Command - Shift - Y&lt;/code&gt; to open the sidepanel.&lt;/p&gt; &#xA;&lt;p&gt;Once the sidepanel is open, you can use record mode to record clicks and typing (&lt;code&gt;Command - E&lt;/code&gt;) or select mode (&lt;code&gt;Command I&lt;/code&gt;) to select an element to be hovered, copied to clipboard or to inject text into.&lt;/p&gt; &#xA;&lt;p&gt;At the end of recording make sure to copy all the code. autotab will have created a &lt;code&gt;&amp;lt;agent_name&amp;gt;.py&lt;/code&gt; file in the &lt;code&gt;agents/&lt;/code&gt; folder with boilerplate code. Paste the code in there, format it and then your agent is ready to run!&lt;/p&gt; &#xA;&lt;h3&gt;Running an automation&lt;/h3&gt; &#xA;&lt;p&gt;To play an automation you&#39;ve already created, run &lt;code&gt;autotab play --agent &amp;lt;agent_name&amp;gt;&lt;/code&gt;. Leaving out &lt;code&gt;--agent &amp;lt;agent_name&amp;gt;&lt;/code&gt; has it default to run &lt;code&gt;agents/agent.py&lt;/code&gt;. This just runs the Python script, so you can set debug as you would any other Python script. Often times interactions fail if the Chrome window running the automation isn&#39;t focused. We are working on a headless version that runs in the cloud which we hope to release soon to address this.&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;See the quickstart above (Steps 1 and 2).&lt;/p&gt; &#xA;&lt;p&gt;Running &lt;code&gt;make install&lt;/code&gt; installs all the dependencies as well as the local package which enables the &lt;code&gt;autotab record&lt;/code&gt; and &lt;code&gt;autotab play&lt;/code&gt; commands.&lt;/p&gt; &#xA;&lt;h3&gt;Secrets&lt;/h3&gt; &#xA;&lt;p&gt;Create a &lt;code&gt;.autotab.yaml&lt;/code&gt; file in the root folder and populate it with the variables listed in the &lt;code&gt;.example.autotab.yaml&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;p&gt;The first time an agent logs into Google, it may require 2FA depending on your settings. The script will store the relevant cookies to avoid 2FA in subsequent runs. Please note that these cookies are stored in a google_cookies.json file, which should be handled with care as it contains sensitive information (we store only the logged-out cookies, so even if someone gets those cookies they still need your password to gain access).&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This repository is provided as-is, with no guarantees. Before using any code, please review it thoroughly. If considering a scraper, familiarize yourself with the target website&#39;s guidelines and Terms of Service. Avoid any unauthorized or illegal activities. We hold no responsibility for any potential issues or outcomes.&lt;/p&gt;</summary>
  </entry>
</feed>