<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-10-23T01:37:53Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>iam-veeramalla/python-for-devops</title>
    <updated>2023-10-23T01:37:53Z</updated>
    <id>tag:github.com,2023-10-23:/iam-veeramalla/python-for-devops</id>
    <link href="https://github.com/iam-veeramalla/python-for-devops" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Learn Python from DevOps Engineer point of you.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Python Zero to Hero for DevOps Engineers&lt;/h1&gt; &#xA;&lt;img width=&#34;1141&#34; alt=&#34;Screenshot 2023-10-12 at 9 57 40 PM&#34; src=&#34;https://github.com/iam-veeramalla/python-for-devops/assets/43399466/d70f5fe2-0ba3-449d-b41f-413a38fc4584&#34;&gt; &#xA;&lt;h2&gt;Day 1: Introduction to Python, Installation, and Configuration&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Introduction to Python and its role in DevOps.&lt;/li&gt; &#xA; &lt;li&gt;Installing Python and setting up a development environment.&lt;/li&gt; &#xA; &lt;li&gt;Writing your first Python program.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 2: Intro to Datatypes, Working with Strings and Numbers&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;String data type in Python.&lt;/li&gt; &#xA; &lt;li&gt;String manipulation and formatting.&lt;/li&gt; &#xA; &lt;li&gt;Regular expressions for text processing.&lt;/li&gt; &#xA; &lt;li&gt;Numeric data types in Python (int, float).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 3: Keywords and Variables&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Understanding variables in Python.&lt;/li&gt; &#xA; &lt;li&gt;Variable scope and lifetime.&lt;/li&gt; &#xA; &lt;li&gt;Variable naming conventions and best practices.&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Using variables to store and manipulate configuration data in a DevOps context.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 4: Functions, Modules and Packages&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;What are differences between function, modules and packages ?&lt;/li&gt; &#xA; &lt;li&gt;How to import a package ?&lt;/li&gt; &#xA; &lt;li&gt;What are Python workspaces ?&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 5: Environment Variables and Command Line Arguments&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Reading and writing environment variables in Python.&lt;/li&gt; &#xA; &lt;li&gt;Using the os and dotenv modules.&lt;/li&gt; &#xA; &lt;li&gt;Securing sensitive information in environment variables.&lt;/li&gt; &#xA; &lt;li&gt;Handling command line arguments in Python.&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Developing a Python script that accepts command line arguments to customize DevOps automation tasks.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 6: Operators&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Introduction to operators in Python.&lt;/li&gt; &#xA; &lt;li&gt;Arithmetic, comparison, and logical operators.&lt;/li&gt; &#xA; &lt;li&gt;Bitwise and assignment operators.&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Using operators to perform calculations and comparisons in a DevOps script.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 7: Conditional Handling using if, elif and else&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Conditional statements (if, elif, else).&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Automating a server shutdown if it&#39;s running out of disk space.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 8: Working with Lists (Part 1)&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Understanding lists and list data structure.&lt;/li&gt; &#xA; &lt;li&gt;List manipulation and common list operations.&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Writing a script to manage a list of user accounts in a DevOps environment.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 9: Loops&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Loops in Python (for and while).&lt;/li&gt; &#xA; &lt;li&gt;Loop control statements (break, continue).&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Automating a log file analysis with a loop to find errors.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 10: Working with Lists (Part 2)&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;List comprehensions.&lt;/li&gt; &#xA; &lt;li&gt;Nested lists and advanced list operations.&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Parsing a complex configuration file with nested lists.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 11: Working with Dictionaries and Sets&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Dictionaries and key-value pairs.&lt;/li&gt; &#xA; &lt;li&gt;Sets and set operations.&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Managing a dictionary of server configurations and optimizing retrieval.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 12: Functions and Modules&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Introduction to functions in Python.&lt;/li&gt; &#xA; &lt;li&gt;Writing functions and function parameters.&lt;/li&gt; &#xA; &lt;li&gt;Return values and modular code.&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Creating a function to automate server status checks.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 13: Functions and Modules (Part 2)&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Advanced function topics (recursion, lambda functions).&lt;/li&gt; &#xA; &lt;li&gt;Function libraries and built-in functions.&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Developing a library of custom functions for DevOps automation.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 14: Python Libraries for DevOps (Part 1)&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Introduction to external libraries like Paramiko, Fabric, and Boto3.&lt;/li&gt; &#xA; &lt;li&gt;Automating SSH connections with Paramiko.&lt;/li&gt; &#xA; &lt;li&gt;Running commands on remote servers.&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Using Paramiko to create a secure remote backup solution.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 15: Python Libraries for DevOps (Part 2)&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Using Fabric for remote task automation.&lt;/li&gt; &#xA; &lt;li&gt;AWS automation with Boto3.&lt;/li&gt; &#xA; &lt;li&gt;Managing EC2 instances, S3 buckets, and more.&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Creating a Fabric script for deploying applications to remote servers.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 16: Working with RESTful APIs&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Introduction to RESTful APIs.&lt;/li&gt; &#xA; &lt;li&gt;Making HTTP requests using Python.&lt;/li&gt; &#xA; &lt;li&gt;Parsing JSON responses and error handling.&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Developing a script to monitor RESTful API endpoints for your DevOps tools.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 17: Data Serialization and Configuration Files&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Serializing and deserializing data (JSON, YAML).&lt;/li&gt; &#xA; &lt;li&gt;Managing configuration data.&lt;/li&gt; &#xA; &lt;li&gt;DevOps use cases for configuration files.&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Building a configuration manager to handle application settings in JSON format.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 18: Automation with Cron Jobs&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Scheduling automated tasks using cron.&lt;/li&gt; &#xA; &lt;li&gt;Creating Python scripts for scheduled automation.&lt;/li&gt; &#xA; &lt;li&gt;Handling periodic tasks and reports.&lt;/li&gt; &#xA; &lt;li&gt;Practice exercises and examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Example: Using cron and Python to schedule regular backups of your data.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Day 19: Python Interview Questions &amp;amp; Answers&lt;/h2&gt;</summary>
  </entry>
  <entry>
    <title>WisdomShell/codeshell</title>
    <updated>2023-10-23T01:37:53Z</updated>
    <id>tag:github.com,2023-10-23:/WisdomShell/codeshell</id>
    <link href="https://github.com/WisdomShell/codeshell" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A series of code large language models developed by PKU-KCL&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://cdn-uploads.huggingface.co/production/uploads/6489a27bd0b2fd1f3297e5ca/3LQsqRzluBhBN2DipN6Ox.png&#34; width=&#34;400&#34;&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; ğŸ¤— &lt;a href=&#34;https://huggingface.co/WisdomShell/CodeShell&#34; target=&#34;_blank&#34;&gt;Hugging Face&lt;/a&gt; â€¢ ğŸŒ &lt;a href=&#34;http://se.pku.edu.cn/kcl/&#34; target=&#34;_blank&#34;&gt;PKU-KCL&lt;/a&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/WisdomShell/codeshell/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/modelscope/modelscope.svg?sanitize=true&#34; alt=&#34;license&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h4 align=&#34;center&#34;&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/WisdomShell/codeshell/raw/main/README.md&#34;&gt;&lt;b&gt;ä¸­æ–‡&lt;/b&gt;&lt;/a&gt;|&lt;a href=&#34;https://github.com/WisdomShell/codeshell/raw/main/README_EN.md&#34;&gt;English&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;CodeShellæ˜¯&lt;a href=&#34;http://se.pku.edu.cn/kcl/&#34;&gt;åŒ—äº¬å¤§å­¦çŸ¥è¯†è®¡ç®—å®éªŒå®¤&lt;/a&gt;è”åˆå››å·å¤©åºœé“¶è¡ŒAIå›¢é˜Ÿç ”å‘çš„å¤šè¯­è¨€ä»£ç å¤§æ¨¡å‹åŸºåº§ã€‚CodeShellå…·æœ‰70äº¿å‚æ•°ï¼Œåœ¨äº”åƒäº¿Tokensè¿›è¡Œäº†è®­ç»ƒï¼Œä¸Šä¸‹æ–‡çª—å£é•¿åº¦ä¸º8192ã€‚åœ¨æƒå¨çš„ä»£ç è¯„ä¼°Benchmarkï¼ˆHumanEvalä¸MBPPï¼‰ä¸Šï¼ŒCodeShellå–å¾—åŒç­‰è§„æ¨¡æœ€å¥½çš„æ€§èƒ½ã€‚ä¸æ­¤åŒæ—¶ï¼Œæˆ‘ä»¬æä¾›äº†ä¸CodeShellé…å¥—çš„éƒ¨ç½²æ–¹æ¡ˆä¸IDEæ’ä»¶ï¼Œè¯·å‚è€ƒä»£ç åº“&lt;a href=&#34;https://github.com/WisdomShell/codeshell&#34;&gt;CodeShell&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æœ¬æ¬¡å¼€æºçš„æ¨¡å‹å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/WisdomShell/CodeShell&#34; target=&#34;_blank&#34;&gt;&lt;b&gt;CodeShell Base&lt;/b&gt;&lt;/a&gt;ï¼šCodelShellåº•åº§æ¨¡å‹ï¼Œå…·æœ‰å¼ºå¤§çš„ä»£ç åŸºç¡€èƒ½åŠ›ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/WisdomShell/CodeShell-Chat&#34; target=&#34;_blank&#34;&gt;&lt;b&gt;CodeShell Chat&lt;/b&gt;&lt;/a&gt;ï¼šCodelShellå¯¹è¯æ¨¡å‹ï¼Œåœ¨ä»£ç é—®ç­”ã€ä»£ç è¡¥å…¨ç­‰ä¸‹æ¸¸ä»»åŠ¡é‡æ€§èƒ½ä¼˜å¼‚ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/WisdomShell/CodeShell-Chat-int4&#34; target=&#34;_blank&#34;&gt;&lt;b&gt;CodeShell Chat 4bit&lt;/b&gt;&lt;/a&gt;ï¼šCodelShellå¯¹è¯æ¨¡å‹4bité‡åŒ–ç‰ˆæœ¬ï¼Œåœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„å‰æä¸‹å†…å­˜æ¶ˆè€—æ›´å°ï¼Œé€Ÿåº¦æ›´å¿«ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/WisdomShell/llama_cpp_for_codeshell&#34; target=&#34;_blank&#34;&gt;&lt;b&gt;CodeShell CPP&lt;/b&gt;&lt;/a&gt;ï¼šCodelShellå¯¹è¯æ¨¡å‹CPPç‰ˆæœ¬ï¼Œæ”¯æŒå¼€å‘è€…åœ¨æ²¡æœ‰GPUçš„ä¸ªäººç”µè„‘ä¸­ä½¿ç”¨ã€‚æ³¨æ„ï¼ŒCPPç‰ˆæœ¬åŒæ ·æ”¯æŒé‡åŒ–æ“ä½œï¼Œç”¨æˆ·å¯ä»¥åœ¨æœ€å°å†…å­˜ä¸º8Gçš„ä¸ªäººç”µè„‘ä¸­è¿è¡ŒCodeShellã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Main Characteristics of CodeShell&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;å¼ºå¤§çš„æ€§èƒ½&lt;/strong&gt;ï¼šCodelShellåœ¨HumanEvalå’ŒMBPPä¸Šè¾¾åˆ°äº†7Bä»£ç åŸºåº§å¤§æ¨¡å‹çš„æœ€ä¼˜æ€§èƒ½&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;å®Œæ•´çš„ä½“ç³»&lt;/strong&gt;ï¼šé™¤äº†ä»£ç å¤§æ¨¡å‹ï¼ŒåŒæ—¶å¼€æºIDEï¼ˆVS Codeä¸JetBrainsï¼‰æ’ä»¶ï¼Œå½¢æˆå¼€æºçš„å…¨æ ˆæŠ€æœ¯ä½“ç³»&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;è½»é‡åŒ–éƒ¨ç½²&lt;/strong&gt;ï¼šæ”¯æŒæœ¬åœ°C++éƒ¨ç½²ï¼Œæä¾›è½»é‡å¿«é€Ÿçš„æœ¬åœ°åŒ–è½¯ä»¶å¼€å‘åŠ©æ‰‹è§£å†³æ–¹æ¡ˆ&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;å…¨é¢çš„è¯„æµ‹&lt;/strong&gt;ï¼šæä¾›æ”¯æŒå®Œæ•´é¡¹ç›®ä¸Šä¸‹æ–‡ã€è¦†ç›–ä»£ç ç”Ÿæˆã€ä»£ç ç¼ºé™·æ£€æµ‹ä¸ä¿®å¤ã€æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆç­‰å¸¸è§è½¯ä»¶å¼€å‘æ´»åŠ¨çš„å¤šä»»åŠ¡è¯„æµ‹ä½“ç³»ï¼ˆå³å°†å¼€æºï¼‰&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;é«˜æ•ˆçš„è®­ç»ƒ&lt;/strong&gt;ï¼šåŸºäºé«˜æ•ˆçš„æ•°æ®æ²»ç†ä½“ç³»ï¼ŒCodeShellåœ¨å®Œå…¨å†·å¯åŠ¨æƒ…å†µä¸‹ï¼Œåªè®­ç»ƒäº†äº”åƒäº¿Tokenå³è·å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Performance&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘ä»¬é€‰å–äº†ç›®å‰æœ€æµè¡Œçš„ä¸¤ä¸ªä»£ç è¯„æµ‹æ•°æ®é›†ï¼ˆHumanEvalä¸MBPPï¼‰å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œä¸ç›®å‰æœ€å…ˆè¿›çš„ä¸¤ä¸ª7bä»£ç å¤§æ¨¡å‹CodeLllamaä¸Starcoderç›¸æ¯”ï¼ŒCodeshell å–å¾—äº†æœ€ä¼˜çš„æˆç»©ã€‚å…·ä½“è¯„æµ‹ç»“æœå¦‚ä¸‹ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ä»»åŠ¡&lt;/th&gt; &#xA;   &lt;th&gt;CodeShell-7b&lt;/th&gt; &#xA;   &lt;th&gt;CodeLlama-7b&lt;/th&gt; &#xA;   &lt;th&gt;Starcoder-7b&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;humaneval&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;34.32&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;29.44&lt;/td&gt; &#xA;   &lt;td&gt;27.80&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mbpp&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;38.65&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;37.60&lt;/td&gt; &#xA;   &lt;td&gt;34.16&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;multiple-js&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;33.17&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;31.30&lt;/td&gt; &#xA;   &lt;td&gt;27.02&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;multiple-java&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;30.43&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;29.24&lt;/td&gt; &#xA;   &lt;td&gt;24.30&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;multiple-cpp&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;28.21&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;27.33&lt;/td&gt; &#xA;   &lt;td&gt;23.04&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;multiple-swift&lt;/td&gt; &#xA;   &lt;td&gt;24.30&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;25.32&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;15.70&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;multiple-php&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;30.87&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;25.96&lt;/td&gt; &#xA;   &lt;td&gt;22.11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;multiple-d&lt;/td&gt; &#xA;   &lt;td&gt;8.85&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;11.60&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;8.08&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;multiple-jl&lt;/td&gt; &#xA;   &lt;td&gt;22.08&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;25.28&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;22.96&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;multiple-lua&lt;/td&gt; &#xA;   &lt;td&gt;22.39&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;30.50&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;22.92&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;multiple-r&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;20.52&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;18.57&lt;/td&gt; &#xA;   &lt;td&gt;14.29&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;multiple-rkt&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;17.20&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;12.55&lt;/td&gt; &#xA;   &lt;td&gt;10.43&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;multiple-rs&lt;/td&gt; &#xA;   &lt;td&gt;24.55&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;25.90&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;22.82&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;python 3.8 and above&lt;/li&gt; &#xA; &lt;li&gt;pytorch 2.0 and above are recommended&lt;/li&gt; &#xA; &lt;li&gt;transformers 4.32 and above&lt;/li&gt; &#xA; &lt;li&gt;CUDA 11.8 and above are recommended (this is for GPU users, flash-attention users, etc.)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;CodeShellç³»åˆ—æ¨¡å‹å·²ç»ä¸Šä¼ è‡³ &lt;a href=&#34;https://huggingface.co/WisdomShell/CodeShell&#34; target=&#34;_blank&#34;&gt;Hugging Face&lt;/a&gt;ï¼Œå¼€å‘è€…å¯ä»¥é€šè¿‡Transformerså¿«é€Ÿè°ƒç”¨CodeShellå’ŒCodeShell-Chatã€‚&lt;/p&gt; &#xA;&lt;p&gt;åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿å·²ç»æ­£ç¡®è®¾ç½®äº†ç¯å¢ƒï¼Œå¹¶å®‰è£…äº†å¿…è¦çš„ä»£ç åŒ…ï¼Œä»¥åŠæ»¡è¶³ä¸Šä¸€å°èŠ‚çš„ç¯å¢ƒè¦æ±‚ã€‚ä½ å¯ä»¥é€šè¿‡ä¸‹åˆ—ä»£ç å¿«é€Ÿå®‰è£…ç›¸å…³ä¾èµ–ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æ¥ä¸‹æ¥ä½ å¯ä»¥é€šè¿‡Transformersä½¿ç”¨CodeShellã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Code Generation&lt;/h3&gt; &#xA;&lt;p&gt;å¼€å‘è€…å¯ä»¥ä½¿ç”¨CodeShellå¿«é€Ÿç”Ÿæˆä»£ç ï¼ŒåŠ é€Ÿå¼€å‘æ•ˆç‡ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from transformers import AutoModelForCausalLM, AutoTokenizer&#xA;&#xA;device = &#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;&#xA;tokenizer = AutoTokenizer.from_pretrained(&#34;WisdomShell/CodeShell-7B&#34;)&#xA;model = AutoModelForCausalLM.from_pretrained(&#34;WisdomShell/CodeShell-7B&#34;, trust_remote_code=True, torch_dtype=torch.bfloat16).to(device)&#xA;inputs = tokenizer(&#39;def merge_sort():&#39;, return_tensors=&#39;pt&#39;).to(device)&#xA;outputs = model.generate(**inputs)&#xA;print(tokenizer.decode(outputs[0]))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fill in the Moddle&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;CodeShell æ”¯æŒFill-in-the-Middleæ¨¡å¼ï¼Œä»è€Œæ›´å¥½çš„æ”¯æŒè½¯ä»¶å¼€å‘è¿‡ç¨‹ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;input_text = &#34;&amp;lt;fim_prefix&amp;gt;def print_hello_world():\n    &amp;lt;fim_suffix&amp;gt;\n    print(&#39;Hello world!&#39;)&amp;lt;fim_middle&amp;gt;&#34;&#xA;inputs = tokenizer(input_text, return_tensors=&#39;pt&#39;).to(device)&#xA;outputs = model.generate(**inputs)&#xA;print(tokenizer.decode(outputs[0]))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ä»£ç é—®ç­”&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;CodeShellåŒæ—¶å¼€æºäº†ä»£ç åŠ©æ‰‹æ¨¡å‹CodeShell-7B-Chatï¼Œå¼€å‘è€…å¯ä»¥é€šè¿‡ä¸‹åˆ—ä»£ç ä¸æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModelForCausalLM.from_pretrained(&#39;WisdomShell/CodeShell-7B-Chat&#39;, trust_remote_code=True, torch_dtype=torch.bfloat16).to(device)&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;WisdomShell/CodeShell-7B-Chat&#39;)&#xA;&#xA;history = []&#xA;query = &#39;ä½ æ˜¯è°?&#39;&#xA;response = model.chat(query, history, tokenizer)&#xA;print(response)&#xA;history.append((query, response))&#xA;&#xA;query = &#39;ç”¨Pythonå†™ä¸€ä¸ªHTTP server&#39;&#xA;response = model.chat(query, history, tokenizer)&#xA;print(response)&#xA;history.append((query, response))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å¼€å‘è€…ä¹Ÿå¯ä»¥é€šè¿‡VS Codeä¸JetBrainsæ’ä»¶ä¸CodeShell-7B-Chatäº¤äº’ï¼Œè¯¦æƒ…è¯·å‚&lt;a href=&#34;https://github.com/WisdomShell/codeshell-vscode&#34;&gt;VSCodeæ’ä»¶ä»“åº“&lt;/a&gt;ä¸&lt;a href=&#34;https://github.com/WisdomShell/codeshell-intellij&#34;&gt;IntelliJæ’ä»¶ä»“åº“&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Model Quantization&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;CodeShell æ”¯æŒ4 bit/8 bité‡åŒ–ï¼Œ4 bité‡åŒ–åï¼Œå ç”¨æ˜¾å­˜å¤§å°çº¦6Gï¼Œç”¨æˆ·å¯ä»¥åœ¨æ˜¾å­˜è¾ƒå°çš„GPUä¸Šä½¿ç”¨CodeShellã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModelForCausalLM.from_pretrained(&#39;WisdomShell/CodeShell-7B-Chat-int4&#39;, trust_remote_code=True).to(device)&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;WisdomShell/CodeShell-7B-Chat-int4&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;CodeShell in c/c++&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;ç”±äºå¤§éƒ¨åˆ†ä¸ªäººç”µè„‘æ²¡æœ‰GPUï¼ŒCodeShellæä¾›äº†C/C++ç‰ˆæœ¬çš„æ¨ç†æ”¯æŒï¼Œå¼€å‘è€…å¯ä»¥æ ¹æ®æœ¬åœ°ç¯å¢ƒè¿›è¡Œç¼–è¯‘ä¸ä½¿ç”¨ï¼Œè¯¦è§&lt;a href=&#34;https://github.com/WisdomShell/llama_cpp_for_codeshell&#34;&gt;CodeShell C/C++æœ¬åœ°åŒ–ç‰ˆ&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘ä»¬æä¾›äº†Web-UIã€å‘½ä»¤è¡Œã€APIã€IDEå››ç§å½¢å¼çš„Demoã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Web UI&lt;/h3&gt; &#xA;&lt;p&gt;å¼€å‘è€…é€šè¿‡ä¸‹åˆ—å‘½ä»¤å¯åŠ¨WebæœåŠ¡ï¼ŒæœåŠ¡å¯åŠ¨åï¼Œå¯ä»¥é€šè¿‡&lt;code&gt;https://127.0.0.1:8000&lt;/code&gt;è¿›è¡Œè®¿é—®ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python demos/web_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;CLI Demo&lt;/h3&gt; &#xA;&lt;p&gt;æˆ‘ä»¬ä¹Ÿæä¾›äº†å‘½ä»¤è¡Œäº¤äº’çš„Demoç‰ˆæœ¬ï¼Œå¼€å‘è€…å¯ä»¥é€šè¿‡ä¸‹åˆ—å‘½ä»¤è¿è¡Œã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python demos/cli_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;API&lt;/h3&gt; &#xA;&lt;p&gt;CodeShellä¹Ÿæä¾›äº†åŸºäºOpenAI APIçš„éƒ¨ç½²æ–¹æ³•ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python demos/openai_api.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å¯åŠ¨åå³å¯é€šè¿‡HTTPè¯·æ±‚ä¸CodeShelläº¤äº’ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl http://127.0.0.1:8000/v1/chat/completions \&#xA;  -H &#34;Content-Type: application/json&#34; \&#xA;  -d &#39;{&#xA;    &#34;model&#34;: &#34;CodeShell-7B-Chat&#34;,&#xA;    &#34;messages&#34;: [&#xA;      {&#xA;        &#34;role&#34;: &#34;user&#34;,&#xA;        &#34;content&#34;: &#34;ä½ å¥½&#34;&#xA;      }&#xA;    ]&#xA;  }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;IDE&lt;/h3&gt; &#xA;&lt;p&gt;CodeShellæœ€åæä¾›äº†çº¿ä¸ŠIDEï¼Œå¼€å‘è€…å¯ä»¥é€šè¿‡IDEè¿›è¡Œä»£ç è¡¥å…¨ã€ä»£ç é—®ç­”ç­‰æ“ä½œã€‚åŒæ—¶ï¼ŒIDEæ’ä»¶ä¹ŸåŒæ—¶å‘å¸ƒï¼Œå¼€å‘è€…å¯ä»¥è‡ªè¡Œåœ¨æœ¬åœ°è¿›è¡Œå®‰è£…ä½¿ç”¨ã€‚æ’ä»¶ç›¸å…³é—®é¢˜æ¬¢è¿åœ¨&lt;a href=&#34;https://github.com/WisdomShell/codeshell-vscode&#34;&gt;VSCodeæ’ä»¶ä»“åº“&lt;/a&gt;ä¸&lt;a href=&#34;https://github.com/WisdomShell/codeshell-intellij&#34;&gt;IntelliJæ’ä»¶ä»“åº“&lt;/a&gt;ä¸­è®¨è®ºã€‚&lt;/p&gt; &#xA;&lt;h2&gt;Model Details&lt;/h2&gt; &#xA;&lt;p&gt;Code Shellä½¿ç”¨GPT-2ä½œä¸ºåŸºç¡€æ¶æ„ï¼Œé‡‡ç”¨Grouped-Query Attentionã€RoPEç›¸å¯¹ä½ç½®ç¼–ç ç­‰æŠ€æœ¯ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Hyper-parameter&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Hyper-parameter&lt;/th&gt; &#xA;   &lt;th&gt;Value&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;n_layer&lt;/td&gt; &#xA;   &lt;td&gt;42&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;n_embd&lt;/td&gt; &#xA;   &lt;td&gt;4096&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;n_inner&lt;/td&gt; &#xA;   &lt;td&gt;16384&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;n_head&lt;/td&gt; &#xA;   &lt;td&gt;32&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;num_query_groups&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;seq-length&lt;/td&gt; &#xA;   &lt;td&gt;8192&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;vocab_size&lt;/td&gt; &#xA;   &lt;td&gt;70144&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Data&lt;/h3&gt; &#xA;&lt;p&gt;CodeShellåŸºäºè‡ªå·±çˆ¬å–çš„Githubæ•°æ®ã€Big Codeå¼€æºçš„Stackå’ŒStarCoderæ•°æ®é›†ã€ä»¥åŠå°‘é‡é«˜è´¨é‡çš„ä¸­è‹±æ–‡æ•°æ®è¿›è¡Œè®­ç»ƒã€‚åœ¨åŸå§‹æ•°æ®é›†çš„åŸºç¡€ä¸Šï¼ŒCodeShellé‡‡ç”¨åŸºäºMinihashå¯¹æ•°æ®å»é‡ï¼ŒåŸºäºKenLMä»¥åŠé«˜è´¨é‡æ•°æ®ç­›é€‰æ¨¡å‹å¯¹æ•°æ®è¿›è¡Œäº†è¿‡æ»¤ä¸ç­›é€‰ï¼Œæœ€ç»ˆå¾—åˆ°é«˜è´¨é‡çš„é¢„è®­ç»ƒæ•°æ®é›†ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Tokenizer&lt;/h3&gt; &#xA;&lt;p&gt;CodeShellåŸºäºStarcoderè¯è¡¨è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå»é™¤äº†ä½¿ç”¨é¢‘ç‡è¾ƒä½çš„è¯è¯­ï¼Œå¹¶æ·»åŠ äº†éƒ¨åˆ†ä¸­æ–‡è¯è¡¨ï¼Œæ˜¾è‘—æå‡äº†ä¸­æ–‡çš„å‹ç¼©ç‡ï¼Œä¸ºChatç‰ˆæœ¬çš„è®­ç»ƒæä¾›äº†åŸºç¡€ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Tokenizer&lt;/th&gt; &#xA;   &lt;th&gt;Size&lt;/th&gt; &#xA;   &lt;th&gt;Chinese&lt;/th&gt; &#xA;   &lt;th&gt;English&lt;/th&gt; &#xA;   &lt;th&gt;Code&lt;/th&gt; &#xA;   &lt;th&gt;Total&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Starcoder&lt;/td&gt; &#xA;   &lt;td&gt;49152&lt;/td&gt; &#xA;   &lt;td&gt;1.22&lt;/td&gt; &#xA;   &lt;td&gt;3.47&lt;/td&gt; &#xA;   &lt;td&gt;3.30&lt;/td&gt; &#xA;   &lt;td&gt;2.66&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CodeShell&lt;/td&gt; &#xA;   &lt;td&gt;70020&lt;/td&gt; &#xA;   &lt;td&gt;1.50&lt;/td&gt; &#xA;   &lt;td&gt;3.47&lt;/td&gt; &#xA;   &lt;td&gt;3.30&lt;/td&gt; &#xA;   &lt;td&gt;2.95&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;ç¤¾åŒºä½¿ç”¨CodeShellæ¨¡å‹éœ€è¦éµå¾ªã€ŠCodeShellæ¨¡å‹è®¸å¯åè®®ã€‹åŠApache 2.0è®¸å¯åè®®ã€‚CodeShellæ¨¡å‹å…è®¸ç”¨äºå•†ä¸šç”¨é€”ï¼Œä½†å¦‚æœæ‚¨è®¡åˆ’å°†CodeShellæ¨¡å‹æˆ–å…¶æ´¾ç”Ÿäº§å“ç”¨äºå•†ä¸šç”¨é€”ï¼Œéœ€è¦æ‚¨ç¡®è®¤ä¸»ä½“ç¬¦åˆä»¥ä¸‹æ¡ä»¶ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;å…³è”æ–¹çš„æœåŠ¡æˆ–äº§å“çš„æ¯æ—¥å¹³å‡æ´»è·ƒç”¨æˆ·æ•°ï¼ˆDAUï¼‰ä¸èƒ½è¶…è¿‡100ä¸‡ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å…³è”æ–¹ä¸å¾—æ˜¯è½¯ä»¶æœåŠ¡æä¾›å•†æˆ–äº‘æœåŠ¡æä¾›å•†ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å…³è”æ–¹ä¸å­˜åœ¨å°†è·å¾—æˆäºˆçš„å•†ä¸šè®¸å¯ï¼Œåœ¨æœªç»è®¸å¯çš„å‰æä¸‹å°†å…¶å†æˆæƒç»™å…¶ä»–ç¬¬ä¸‰æ–¹çš„å¯èƒ½æ€§ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;åœ¨æ»¡è¶³ä¸Šè¿°æ¡ä»¶çš„å‰æä¸‹ï¼Œæ‚¨éœ€è¦é€šè¿‡å‘&lt;a href=&#34;mailto:codeshell.opensource@gmail.com&#34;&gt;codeshell.opensource@gmail.com&lt;/a&gt;å‘é€ç”µå­é‚®ä»¶æäº¤ç”³è¯·ã€‚ç»å®¡æ ¸é€šè¿‡åï¼Œå°†æˆäºˆæ‚¨ä¸€ä¸ªå…¨çƒçš„ã€éæ’ä»–çš„ã€ä¸å¯è½¬è®©çš„ã€ä¸å¯å†æˆæƒçš„å•†ä¸šç‰ˆæƒè®¸å¯ã€‚&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>OpenTalker/video-retalking</title>
    <updated>2023-10-23T01:37:53Z</updated>
    <id>tag:github.com,2023-10-23:/OpenTalker/video-retalking</id>
    <link href="https://github.com/OpenTalker/video-retalking" rel="alternate"></link>
    <summary type="html">&lt;p&gt;[SIGGRAPH Asia 2022] VideoReTalking: Audio-based Lip Synchronization for Talking Head Video Editing In the Wild&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h2&gt;VideoReTalking &lt;br&gt; &lt;span style=&#34;font-size:12px&#34;&gt;Audio-based Lip Synchronization for Talking Head Video Editing In the Wild&lt;/span&gt; &lt;/h2&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.14758&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/ArXiv-2211.14758-red&#34;&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&#34;https://vinthony.github.io/video-retalking/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project-Page-Green&#34;&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&#34;https://colab.research.google.com/github/vinthony/video-retalking/blob/main/quick_demo.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;div&gt; &#xA;  &lt;a target=&#34;_blank&#34;&gt;Kun Cheng &lt;sup&gt;*,1,2&lt;/sup&gt; &lt;/a&gt;â€ƒ &#xA;  &lt;a href=&#34;https://vinthony.github.io/&#34; target=&#34;_blank&#34;&gt;Xiaodong Cun &lt;sup&gt;*,2&lt;/sup&gt;&lt;/a&gt;â€ƒ &#xA;  &lt;a href=&#34;https://yzhang2016.github.io/yongnorriszhang.github.io/&#34; target=&#34;_blank&#34;&gt;Yong Zhang &lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;â€ƒ &#xA;  &lt;a href=&#34;https://menghanxia.github.io/&#34; target=&#34;_blank&#34;&gt;Menghan Xia &lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;â€ƒ &#xA;  &lt;a href=&#34;https://feiiyin.github.io/&#34; target=&#34;_blank&#34;&gt;Fei Yin &lt;sup&gt;2,3&lt;/sup&gt;&lt;/a&gt;â€ƒ&#xA;  &lt;br&gt; &#xA;  &lt;a href=&#34;https://web.xidian.edu.cn/mrzhu/en/index.html&#34; target=&#34;_blank&#34;&gt;Mingrui Zhu &lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;â€ƒ &#xA;  &lt;a href=&#34;https://xuanwangvc.github.io/&#34; target=&#34;_blank&#34;&gt;Xuan Wang &lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;â€ƒ &#xA;  &lt;a href=&#34;https://juewang725.github.io/&#34; target=&#34;_blank&#34;&gt;Jue Wang &lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;â€ƒ &#xA;  &lt;a href=&#34;https://web.xidian.edu.cn/nnwang/en/index.html&#34; target=&#34;_blank&#34;&gt;Nannan Wang &lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt; &#xA;  &lt;sup&gt;1&lt;/sup&gt; Xidian University â€ƒ &#xA;  &lt;sup&gt;2&lt;/sup&gt; Tencent AI Lab â€ƒ &#xA;  &lt;sup&gt;3&lt;/sup&gt; Tsinghua University &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;i&gt;&lt;strong&gt;&lt;a href=&#34;https://sa2022.siggraph.org/&#34; target=&#34;_blank&#34;&gt;SIGGRAPH Asia 2022 Conference Track&lt;/a&gt;&lt;/strong&gt;&lt;/i&gt; &#xA; &lt;br&gt; &#xA; &lt;br&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/OpenTalker/video-retalking/main/docs/static/images/teaser.png?raw=true&#34; width=&#34;768px&#34;&gt; &#xA; &lt;div align=&#34;justify&#34;&gt;&#xA;   We present VideoReTalking, a new system to edit the faces of a real-world talking head video according to input audio, producing a high-quality and lip-syncing output video even with a different emotion. Our system disentangles this objective into three sequential tasks: (1) face video generation with a canonical expression; (2) audio-driven lip-sync; and (3) face enhancement for improving photo-realism. Given a talking-head video, we first modify the expression of each frame according to the same expression template using the expression editing network, resulting in a video with the canonical expression. This video, together with the given audio, is then fed into the lip-sync network to generate a lip-syncing video. Finally, we improve the photo-realism of the synthesized faces through an identity-aware face enhancement network and post-processing. We use learning-based approaches for all three steps and all our modules can be tackled in a sequential pipeline without any user intervention.&#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt; &lt;img alt=&#34;pipeline&#34; src=&#34;https://raw.githubusercontent.com/OpenTalker/video-retalking/main/docs/static/images/pipeline.png?raw=true&#34; width=&#34;768px&#34;&gt;&lt;br&gt; &lt;em align=&#34;center&#34;&gt;Pipeline&lt;/em&gt; &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Results in the Wild ï¼ˆcontains audioï¼‰&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/4397546/224310754-665eb2dd-aadc-47dc-b1f9-2029a937b20a.mp4&#34;&gt;https://user-images.githubusercontent.com/4397546/224310754-665eb2dd-aadc-47dc-b1f9-2029a937b20a.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Environment&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/vinthony/video-retalking.git&#xA;cd video-retalking&#xA;conda create -n video_retalking python=3.8&#xA;conda activate video_retalking&#xA;&#xA;conda install ffmpeg&#xA;&#xA;# Please follow the instructions from https://pytorch.org/get-started/previous-versions/&#xA;# This installation command only works on CUDA 11.1&#xA;pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html&#xA;&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quick Inference&lt;/h2&gt; &#xA;&lt;h4&gt;Pretrained Models&lt;/h4&gt; &#xA;&lt;p&gt;Please download our &lt;a href=&#34;https://drive.google.com/drive/folders/18rhjMpxK8LVVxf7PI6XwOidt8Vouv_H0?usp=share_link&#34;&gt;pre-trained models&lt;/a&gt; and put them in &lt;code&gt;./checkpoints&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;!-- We also provide some [example videos and audio](https://drive.google.com/drive/folders/14OwbNGDCAMPPdY-l_xO1axpUjkPxI9Dv?usp=share_link). Please put them in `./examples`. --&gt; &#xA;&lt;h4&gt;Inference&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 inference.py \&#xA;  --face examples/face/1.mp4 \&#xA;  --audio examples/audio/1.wav \&#xA;  --outfile results/1_1.mp4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This script includes data preprocessing steps. You can test any talking face videos without manual alignment. But it is worth noting that DNet cannot handle extreme poses.&lt;/p&gt; &#xA;&lt;p&gt;You can also control the expression by adding the following parameters:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;--exp_img&lt;/code&gt;: Pre-defined expression template. The default is &#34;neutral&#34;. You can choose &#34;smile&#34; or an image path.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;--up_face&lt;/code&gt;: You can choose &#34;surprise&#34; or &#34;angry&#34; to modify the expression of upper face with &lt;a href=&#34;https://github.com/donydchen/ganimation_replicate&#34;&gt;GANimation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find our work useful in your research, please consider citing:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{cheng2022videoretalking,&#xA;        title={VideoReTalking: Audio-based Lip Synchronization for Talking Head Video Editing In the Wild}, &#xA;        author={Kun Cheng and Xiaodong Cun and Yong Zhang and Menghan Xia and Fei Yin and Mingrui Zhu and Xuan Wang and Jue Wang and Nannan Wang},&#xA;        year={2022},&#xA;        eprint={2211.14758},&#xA;        archivePrefix={arXiv},&#xA;        primaryClass={cs.CV}&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;Thanks to &lt;a href=&#34;https://github.com/Rudrabha/Wav2Lip&#34;&gt;Wav2Lip&lt;/a&gt;, &lt;a href=&#34;https://github.com/RenYurui/PIRender&#34;&gt;PIRenderer&lt;/a&gt;, &lt;a href=&#34;https://github.com/TencentARC/GFPGAN&#34;&gt;GFP-GAN&lt;/a&gt;, &lt;a href=&#34;https://github.com/yangxy/GPEN&#34;&gt;GPEN&lt;/a&gt;, &lt;a href=&#34;https://github.com/donydchen/ganimation_replicate&#34;&gt;ganimation_replicate&lt;/a&gt;, &lt;a href=&#34;https://github.com/rotemtzaban/STIT&#34;&gt;STIT&lt;/a&gt; for sharing their code.&lt;/p&gt; &#xA;&lt;h2&gt;Related Work&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/FeiiYin/StyleHEAT&#34;&gt;StyleHEAT: One-Shot High-Resolution Editable Talking Face Generation via Pre-trained StyleGAN (ECCV 2022)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Doubiiu/CodeTalker&#34;&gt;CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior (CVPR 2023)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Winfredy/SadTalker&#34;&gt;SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation (CVPR 2023)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Carlyx/DPE&#34;&gt;DPE: Disentanglement of Pose and Expression for General Video Portrait Editing (CVPR 2023)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/FeiiYin/SPI/&#34;&gt;3D GAN Inversion with Facial Symmetry Prior (CVPR 2023)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mael-zys/T2M-GPT&#34;&gt;T2M-GPT: Generating Human Motion from Textual Descriptions with Discrete Representations (CVPR 2023)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This is not an official product of Tencent.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;1. Please carefully read and comply with the open-source license applicable to this code before using it. &#xA;2. Please carefully read and comply with the intellectual property declaration applicable to this code before using it.&#xA;3. This open-source code runs completely offline and does not collect any personal information or other data. If you use this code to provide services to end-users and collect related data, please take necessary compliance measures according to applicable laws and regulations (such as publishing privacy policies, adopting necessary data security strategies, etc.). If the collected data involves personal information, user consent must be obtained (if applicable). Any legal liabilities arising from this are unrelated to Tencent.&#xA;4. Without Tencent&#39;s written permission, you are not authorized to use the names or logos legally owned by Tencent, such as &#34;Tencent.&#34; Otherwise, you may be liable for legal responsibilities.&#xA;5. This open-source code does not have the ability to directly provide services to end-users. If you need to use this code for further model training or demos, as part of your product to provide services to end-users, or for similar use, please comply with applicable laws and regulations for your product or service. Any legal liabilities arising from this are unrelated to Tencent.&#xA;6. It is prohibited to use this open-source code for activities that harm the legitimate rights and interests of others (including but not limited to fraud, deception, infringement of others&#39; portrait rights, reputation rights, etc.), or other behaviors that violate applicable laws and regulations or go against social ethics and good customs (including providing incorrect or false information, spreading pornographic, terrorist, and violent information, etc.). Otherwise, you may be liable for legal responsibilities.&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>