<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-23T01:42:20Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>mymusise/ChatGLM-Tuning</title>
    <updated>2023-03-23T01:42:20Z</updated>
    <id>tag:github.com,2023-03-23:/mymusise/ChatGLM-Tuning</id>
    <link href="https://github.com/mymusise/ChatGLM-Tuning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;一种平价的chatgpt实现方案, 基于ChatGLM-6B + LoRA&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGLM-Tuning&lt;/h1&gt; &#xA;&lt;p&gt;一种平价的chatgpt实现方案，基于清华的 &lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34;&gt;ChatGLM-6B&lt;/a&gt; + LoRA 进行finetune.&lt;/p&gt; &#xA;&lt;p&gt;数据集: &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;alpaca&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;有colab的同学可以直接在colab上尝试： &lt;a href=&#34;https://colab.research.google.com/github/mymusise/ChatGLM-Tuning/blob/master/examples/finetune.ipynb&#34;&gt; &lt;img alt=&#34;Build&#34; src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34;&gt; &lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;S1 Finetune&lt;/h2&gt; &#xA;&lt;h3&gt;准备&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;显卡: 显存 &amp;gt;= 16G (最好24G或者以上)&lt;/li&gt; &#xA; &lt;li&gt;环境：&lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;python&amp;gt;=3.8&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;cuda&amp;gt;=11.6, cupti, cuDNN, TensorRT等深度学习环境&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;pip3 install -r requirements.txt&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;数据预处理&lt;/h3&gt; &#xA;&lt;p&gt;转化alpaca数据集为jsonl&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python cover_alpaca2jsonl.py \&#xA;    --data_path data/alpaca_data.json \&#xA;    --save_path data/alpaca_data.jsonl \&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;tokenization&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python tokenize_dataset_rows.py \&#xA;    --jsonl_path data/alpaca_data.jsonl \&#xA;    --save_path data/alpaca \&#xA;    --max_seq_length 320&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--jsonl_path&lt;/code&gt; 微调的数据路径, 格式jsonl, 对每行的[&#39;context&#39;]和[&#39;target&#39;]字段进行encode&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--save_path&lt;/code&gt; 输出路径&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--max_seq_length&lt;/code&gt; 样本的最大长度&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;训练&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python finetune.py \&#xA;    --dataset_path data/alpaca \&#xA;    --lora_rank 8 \&#xA;    --per_device_train_batch_size 2 \&#xA;    --gradient_accumulation_steps 1 \&#xA;    --max_steps 52000 \&#xA;    --save_steps 1000 \&#xA;    --save_total_limit 2 \&#xA;    --learning_rate 2e-5 \&#xA;    --fp16 \&#xA;    --remove_unused_columns false \&#xA;    --logging_steps 50 \&#xA;    --output_dir output&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;推理&lt;/h3&gt; &#xA;&lt;p&gt;参考 &lt;a href=&#34;https://raw.githubusercontent.com/mymusise/ChatGLM-Tuning/master/infer.ipynb&#34;&gt;infer.ipynb&lt;/a&gt;&lt;/p&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;Finetune前后对比&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt;利用Alpaca数据集合对ChatGLM-6B Finetune后，在Alpaca数据集上表现得更好:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;code&gt;Answer:&lt;/code&gt; 是模型的输出&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;#### Answer:&lt;/code&gt; 是原答案 &lt;img src=&#34;https://user-images.githubusercontent.com/6883957/226977555-c00c796f-4fdb-4613-810a-8b9a6068bb1b.jpeg&#34; alt=&#34;&#34;&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;S2. Reward Model&lt;/h2&gt; &#xA;&lt;h2&gt;S3. PPO&lt;/h2&gt; &#xA;&lt;h1&gt;TODO:&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;del&gt;bs &amp;gt; 1 support&lt;/del&gt;&lt;/li&gt; &#xA; &lt;li&gt;使用中文数据&lt;/li&gt; &#xA; &lt;li&gt;加入RLHF&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>hwchase17/langchain-hub</title>
    <updated>2023-03-23T01:42:20Z</updated>
    <id>tag:github.com,2023-03-23:/hwchase17/langchain-hub</id>
    <link href="https://github.com/hwchase17/langchain-hub" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LangChainHub&lt;/h1&gt; &#xA;&lt;p&gt;[Warning: very beta, may change drastically]&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://forms.gle/aAhZ6nEUybdzVbYq6&#34;&gt;Google Form&lt;/a&gt; for submitting new prompts.&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;Taking inspiration from Hugging Face Hub, LangChainHub is collection of all artifacts useful for working with LangChain primitives such as prompts, chains and agents. The goal of this repository is to be a central resource for sharing and discovering high quality prompts, chains and agents that combine together to form complex LLM applications.&lt;/p&gt; &#xA;&lt;p&gt;We are starting off the hub with a collection of prompts, and we look forward to the LangChain community adding to this collection. We hope to expand to chains and agents shortly.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Since we are using GitHub to organize this Hub, adding artifacts can best be done in one of three ways:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create a fork and then open a PR against the repo.&lt;/li&gt; &#xA; &lt;li&gt;Create an issue on the repo with details of the artifact you would like to add.&lt;/li&gt; &#xA; &lt;li&gt;Add an artifact with the appropriate Google form: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://forms.gle/aAhZ6nEUybdzVbYq6&#34;&gt;Prompts&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Each of the different types of artifacts (listed below) will have different instructions on how to upload them. Please refer to the appropriate documentation to do so.&lt;/p&gt; &#xA;&lt;h2&gt;📖 Prompts&lt;/h2&gt; &#xA;&lt;p&gt;At a high level, prompts are organized by use case inside the &lt;code&gt;prompts&lt;/code&gt; directory. To load a prompt in LangChain, you should use the following code snippet:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from langchain.prompts import load_prompt&#xA;&#xA;prompt = load_prompt(&#39;lc://prompts/path/to/file.json&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In addition to prompt files themselves, each sub-directory also contains a README explaining how best to use that prompt in the appropriate LangChain chain.&lt;/p&gt; &#xA;&lt;p&gt;For more detailed information on how prompts are organized in the Hub, and how best to upload one, please see the documentation &lt;a href=&#34;https://raw.githubusercontent.com/hwchase17/langchain-hub/master/prompts/README.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;🔗 Chains&lt;/h2&gt; &#xA;&lt;p&gt;At a high level, chains are organized by use case inside the &lt;code&gt;chains&lt;/code&gt; directory. To load a chain in LangChain, you should use the following code snippet:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from langchain.chains import load_chain&#xA;&#xA;chain = load_chain(&#39;lc://chains/path/to/file.json&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In addition to chain files themselves, each sub-directory also contains a README explaining what that chain contains.&lt;/p&gt; &#xA;&lt;p&gt;For more detailed information on how chains are organized in the Hub, and how best to upload one, please see the documentation &lt;a href=&#34;https://raw.githubusercontent.com/hwchase17/langchain-hub/master/chains/README.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;🤖 Agents&lt;/h2&gt; &#xA;&lt;p&gt;At a high level, chains are organized by use case inside the &lt;code&gt;chains&lt;/code&gt; directory. To load a chain in LangChain, you should use the following code snippet:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from langchain.agents import initialize_agent&#xA;&#xA;llm = ...&#xA;tools = ...&#xA;&#xA;agent = initialize_agent(tools, llm, agent=&#34;lc://agents/self-ask-with-search/agent.json&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In addition to agent files themselves, each sub-directory also contains a README explaining what that agent contains.&lt;/p&gt; &#xA;&lt;p&gt;For more detailed information on how agents are organized in the Hub, and how best to upload one, please see the documentation &lt;a href=&#34;https://raw.githubusercontent.com/hwchase17/langchain-hub/master/agents/README.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;👷 Agent Executors&lt;/h2&gt; &#xA;&lt;p&gt;Coming soon!&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>GerevAI/gerev</title>
    <updated>2023-03-23T01:42:20Z</updated>
    <id>tag:github.com,2023-03-23:/GerevAI/gerev</id>
    <link href="https://github.com/GerevAI/gerev" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🧠 ChatGPT search engine for your organization. 🔎&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GerevAI/gerev/main/images/api.gif&#34; alt=&#34;first image&#34;&gt; &lt;strong&gt;Find any conversation, doc, or internal page in seconds&lt;/strong&gt; ⏲️⚡️&lt;br&gt; &lt;strong&gt;Join 100+&lt;/strong&gt; devs by hosting your own gerev instance, become a &lt;strong&gt;hero&lt;/strong&gt; within your org! 💪&lt;/p&gt; &#xA;&lt;h2&gt;Join Discord for early access code!&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://discordapp.com/api/guilds/1060085859497549844/widget.png?style=shield&#34; alt=&#34;Discord Shield&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/aMRRcmhAdW&#34;&gt;Join here!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Search focused on devs&lt;/h1&gt; &#xA;&lt;p&gt;Devs are the best early adopters, they adopt technology early and aid in spreading it to their non-technical peers. That&#39;s why gerev is focused on making a product dev&#39;s adore and love ❤️&lt;/p&gt; &#xA;&lt;h2&gt;Made for devs 👨‍💻&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;For finding internal pages &lt;em&gt;fast&lt;/em&gt; ⚡️&lt;/strong&gt; &lt;img src=&#34;https://raw.githubusercontent.com/GerevAI/gerev/main/images/product-example.png&#34; alt=&#34;second image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Troubleshoot Issues 🐛&lt;/strong&gt; &lt;img src=&#34;https://raw.githubusercontent.com/GerevAI/gerev/main/images/sql-card.png&#34; alt=&#34;fourth image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;For finding code snippets and code examples 🧑‍💻&lt;/strong&gt;&lt;br&gt; Coming Soon... &lt;img src=&#34;https://raw.githubusercontent.com/GerevAI/gerev/main/images/CodeCard.png&#34; alt=&#34;third image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Integrations&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Slack&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Confluence&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Google Drive (Docs, .docx, .pptx)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Confluence Cloud - by &lt;a href=&#34;https://github.com/bryan-pakulski&#34;&gt;@bryan-pakulski&lt;/a&gt; &lt;span&gt;🙏&lt;/span&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Bookstack - by &lt;a href=&#34;https://github.com/flifloo&#34;&gt;@flifloo&lt;/a&gt; &lt;span&gt;🙏&lt;/span&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; RocketChat (in PR)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Gitlab Issues (In PR)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Notion (In Progress...)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Microsoft Teams&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Sharepoint&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;span&gt;🙏&lt;/span&gt; - by the community&lt;/p&gt; &#xA;&lt;h2&gt;Natural Langauge&lt;/h2&gt; &#xA;&lt;p&gt;Enables searching using natural language. such as &lt;code&gt;&#34;How to do X&#34;&lt;/code&gt;, &lt;code&gt;&#34;how to connect to Y&#34;&lt;/code&gt;, &lt;code&gt;&#34;Do we support Z&#34;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install &lt;em&gt;Nvidia for docker&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;Run docker&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Nvidia for docker&lt;/h2&gt; &#xA;&lt;p&gt;Install nvidia container toolkit on the host machine.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \&#xA;   &amp;amp;&amp;amp; curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - \&#xA;   &amp;amp;&amp;amp; curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list&#xA;   &#xA;sudo apt-get update&#xA;&#xA;sudo apt-get install -y nvidia-docker2&#xA;&#xA;sudo systemctl restart docker&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Run docker&lt;/h2&gt; &#xA;&lt;p&gt;Then run the docker container like so:&lt;/p&gt; &#xA;&lt;h3&gt;Nvidia hardware&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --gpus all -p 80:80 -v ~/.gerev/storage:/opt/storage gerev/gerev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;CPU only (no GPU)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run -p 80:80 -v ~/.gerev/storage:/opt/storage gerev/gerev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Run from source&lt;/h2&gt; &#xA;&lt;p&gt;See CONTRIBUTING.md&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;gerev is also popular with some big names. 😉&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GerevAI/gerev/main/images/bill.png&#34; alt=&#34;first image&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>