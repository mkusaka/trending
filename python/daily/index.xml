<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-07-10T01:38:47Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Xpra-org/xpra</title>
    <updated>2024-07-10T01:38:47Z</updated>
    <id>tag:github.com,2024-07-10:/Xpra-org/xpra</id>
    <link href="https://github.com/Xpra-org/xpra" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Persistent remote applications for X11; screen sharing for X11, MacOS and MSWindows.&lt;/p&gt;&lt;hr&gt;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/#about&#34;&gt;About&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/#usage&#34;&gt;Usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/#documentation&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/#help&#34;&gt;Help&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;About&lt;/h1&gt; &#xA;&lt;p&gt;Xpra is known as &lt;em&gt;&#34;screen for X&#34;&lt;/em&gt; : its &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Usage/Seamless.md&#34;&gt;seamless mode&lt;/a&gt; allows you to run X11 programs, usually on a remote host, direct their display to your local machine, and then to disconnect from these programs and reconnect from the same or another machine(s), without losing any state. Effectively giving you remote access to individual graphical applications. It can also be used to &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Usage/Shadow.md&#34;&gt;access existing desktop sessions&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Usage/Desktop.md&#34;&gt;start remote desktop sessions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Xpra is &lt;em&gt;open-source&lt;/em&gt; (&lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/COPYING&#34;&gt;GPLv2+&lt;/a&gt;) with clients available for &lt;a href=&#34;https://github.com/Xpra-org/xpra/wiki/Platforms&#34;&gt;many supported platforms&lt;/a&gt; and the server includes a built-in &lt;a href=&#34;https://github.com/Xpra-org/xpra-html5&#34;&gt;HTML5 client&lt;/a&gt;. Xpra is usable over a wide variety of &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Network/README.md&#34;&gt;network protocols&lt;/a&gt; and does its best to adapt to any network conditions.&lt;/p&gt; &#xA;&lt;p&gt;Xpra forwards and synchronizes many extra desktop features which allows remote applications to integrate transparently into the client&#39;s desktop environment: &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Features/Audio.md&#34;&gt;audio input and output&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Features/Printing.md&#34;&gt;printers&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Features/Clipboard.md&#34;&gt;clipboard&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Features/System-Tray.md&#34;&gt;system trays&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Features/Notifications.md&#34;&gt;notifications&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Features/Webcam.md&#34;&gt;webcams&lt;/a&gt;, etc&lt;/p&gt; &#xA;&lt;p&gt;It can also &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Features/File-Transfers.md&#34;&gt;open documents and URLs remotely&lt;/a&gt;, display &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Features/Image-Depth.md&#34;&gt;high bit depth content&lt;/a&gt;, and it will try honour the &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Features/DPI.md&#34;&gt;display&#39;s DPI&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s what a seamless session with two windows (an &lt;code&gt;xterm&lt;/code&gt; and &lt;code&gt;glxspheres&lt;/code&gt;) looks like when attached from an MS Windows 11 desktop client: &lt;img src=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/images/screenshots/win11-glxspheres.png&#34; alt=&#34;Windows11-client&#34;&gt; (the windows may look like native windows, but they are running on a remote Linux server)&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;h2&gt;Official stable downloads&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Microsoft Windows: &lt;a href=&#34;https://xpra.org/dists/windows/Xpra-x86_64_Setup.exe&#34;&gt;EXE&lt;/a&gt;, &lt;a href=&#34;https://xpra.org/dists/windows/Xpra.zip&#34;&gt;ZIP&lt;/a&gt;, &lt;a href=&#34;https://xpra.org/dists/windows/Xpra-x86_64.msi&#34;&gt;MSI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;MacOS &lt;code&gt;x86_64&lt;/code&gt; &lt;a href=&#34;https://xpra.org/dists/MacOS/x86_64/Xpra.dmg&#34;&gt;DMG&lt;/a&gt; / &lt;a href=&#34;https://xpra.org/dists/MacOS%3E/x86_64/Xpra.pkg&#34;&gt;PKG&lt;/a&gt;, &lt;code&gt;arm64&lt;/code&gt; &lt;a href=&#34;https://xpra.org/dists/MacOS/arm64/Xpra.dmg&#34;&gt;DMG&lt;/a&gt; / &lt;a href=&#34;https://xpra.org/dists/MacOS/arm64/Xpra.pkg&#34;&gt;PKG&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Linux: &lt;a href=&#34;https://github.com/Xpra-org/xpra/wiki/Download#-for-rpm-distributions&#34;&gt;RPM&lt;/a&gt;, &lt;a href=&#34;https://github.com/Xpra-org/xpra/wiki/Download#-for-debian-based-distributions&#34;&gt;DEB&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All the packages are signed. There are also &lt;a href=&#34;https://xpra.org/beta&#34;&gt;beta builds&lt;/a&gt; available. For more information, see &lt;a href=&#34;https://github.com/Xpra-org/xpra/wiki/Download&#34;&gt;xpra downloads&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Build from source&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/Xpra-org/xpra; cd xpra&#xA;python3 ./setup.py install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more details, see &lt;a href=&#34;https://github.com/Xpra-org/xpra/tree/master/docs/Build&#34;&gt;building from source&lt;/a&gt;. To contribute to the project, please try to use pull-requests and follow our &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/CODE_OF_CONDUCT.md&#34;&gt;code of conduct&lt;/a&gt;. Unit test status: &lt;a href=&#34;https://github.com/Xpra-org/xpra/actions/workflows/test.yml&#34;&gt;&lt;img src=&#34;https://github.com/Xpra-org/xpra/actions/workflows/test.yml/badge.svg?sanitize=true&#34; alt=&#34;xpra&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;h2&gt;Initial requirements&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;xpra&lt;/code&gt; must be installed on the client and the host.&lt;/p&gt; &#xA;&lt;p&gt;You can use the &lt;a href=&#34;https://github.com/Xpra-org/xpra-html5&#34;&gt;html5 client&lt;/a&gt; in which case xpra is only required on the host.&lt;/p&gt; &#xA;&lt;h2&gt;Seamless Mode&lt;/h2&gt; &#xA;&lt;p&gt;Run &lt;code&gt;xterm&lt;/code&gt; on a remote host, display and iteract with it locally (from the client machine):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;xpra start ssh://USER@HOST/ --start=xterm&#xA;# hint: xterm must be installed on the HOST.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more examples, see &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Usage/README.md&#34;&gt;usage&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Shadow&lt;/h2&gt; &#xA;&lt;p&gt;View an existing desktop session running on a remote host:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;xpra shadow ssh://USER@HOST/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Network Access&lt;/h2&gt; &#xA;&lt;p&gt;Xpra servers can support &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Network/README.md&#34;&gt;many different types of connections&lt;/a&gt; using a single TCP port: &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Network/SSL.md&#34;&gt;SSL&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Network/SSH.md&#34;&gt;SSH&lt;/a&gt;, (secure) http / websockets, RFB, etc..&lt;br&gt; Connections can be secured using &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Network/Encryption.md&#34;&gt;encryption&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Usage/Authentication.md&#34;&gt;many authentication modules&lt;/a&gt;.&lt;br&gt; Sessions can be automatically announced on LANs using &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Network/Multicast-DNS.md&#34;&gt;multicast DNS&lt;/a&gt; so that clients can connect more easily using a GUI (ie: &lt;code&gt;xpra mdns-gui&lt;/code&gt;).&lt;br&gt; Its flexible &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs/Usage/Proxy-Server.md&#34;&gt;proxy server&lt;/a&gt; can be used as a relay or front end for multiple server sessions.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Documentation&lt;/h1&gt; &#xA;&lt;p&gt;There is extensive documentation &lt;a href=&#34;https://raw.githubusercontent.com/Xpra-org/xpra/master/docs&#34;&gt;right here&lt;/a&gt; for the current development version. This documentation is also included with each release.&lt;/p&gt; &#xA;&lt;p&gt;For more generic version-agnostic information, checkout &lt;a href=&#34;https://github.com/Xpra-org/xpra/wiki&#34;&gt;the wiki&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Help&lt;/h1&gt; &#xA;&lt;p&gt;Make sure to check the &lt;a href=&#34;https://github.com/Xpra-org/xpra/raw/master/docs/FAQ.md&#34;&gt;FAQ&lt;/a&gt;, your question may already be answered there. You can ask your questions on the &lt;a href=&#34;https://github.com/orgs/Xpra-org/discussions&#34;&gt;github discussions&lt;/a&gt;, or on the IRC channel &lt;code&gt;#xpra&lt;/code&gt; on &lt;a href=&#34;https://libera.chat&#34;&gt;&lt;code&gt;libera.chat&lt;/code&gt;&lt;/a&gt; or &lt;a href=&#34;https://discord.gg/2mtC6cDv6Q&#34;&gt;using discord&lt;/a&gt;. If you have hit a bug (sorry about that!), please see &lt;a href=&#34;https://github.com/Xpra-org/xpra/wiki/Reporting-Bugs&#34;&gt;reporting bugs&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>modelscope/agentscope</title>
    <updated>2024-07-10T01:38:47Z</updated>
    <id>tag:github.com,2024-07-10:/modelscope/agentscope</id>
    <link href="https://github.com/modelscope/agentscope" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Start building LLM-empowered multi-agent applications in an easier way.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;English | &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/README_ZH.md&#34;&gt;&lt;strong&gt;‰∏≠Êñá&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;AgentScope&lt;/h1&gt; &#xA;&lt;h1 align=&#34;left&#34;&gt; &lt;img src=&#34;https://img.alicdn.com/imgextra/i2/O1CN01cdjhVE1wwt5Auv7bY_!!6000000006373-0-tps-1792-1024.jpg&#34; width=&#34;600&#34; alt=&#34;agentscope-logo&#34;&gt; &lt;/h1&gt; &#xA;&lt;p&gt;Start building LLM-empowered multi-agent applications in an easier way.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2402.14034&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/cs.MA-2402.14034-B31C1C?logo=arxiv&amp;amp;logoColor=B31C1C&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/agentscope/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.9+-blue&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/agentscope/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/pypi-v0.0.6a2-blue?logo=pypi&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://modelscope.github.io/agentscope/#welcome-to-agentscope-tutorial-hub&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Docs-English%7C%E4%B8%AD%E6%96%87-blue?logo=markdown&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://modelscope.github.io/agentscope/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Docs-API_Reference-blue?logo=markdown&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://modelscope.cn/studios?name=agentscope&amp;amp;page=1&amp;amp;sort=latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/ModelScope-Demos-4e29ff.svg?logo=data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjI0IDEyMS4zMyIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxwYXRoIGQ9Im0wIDQ3Ljg0aDI1LjY1djI1LjY1aC0yNS42NXoiIGZpbGw9IiM2MjRhZmYiIC8+Cgk8cGF0aCBkPSJtOTkuMTQgNzMuNDloMjUuNjV2MjUuNjVoLTI1LjY1eiIgZmlsbD0iIzYyNGFmZiIgLz4KCTxwYXRoIGQ9Im0xNzYuMDkgOTkuMTRoLTI1LjY1djIyLjE5aDQ3Ljg0di00Ny44NGgtMjIuMTl6IiBmaWxsPSIjNjI0YWZmIiAvPgoJPHBhdGggZD0ibTEyNC43OSA0Ny44NGgyNS42NXYyNS42NWgtMjUuNjV6IiBmaWxsPSIjMzZjZmQxIiAvPgoJPHBhdGggZD0ibTAgMjIuMTloMjUuNjV2MjUuNjVoLTI1LjY1eiIgZmlsbD0iIzM2Y2ZkMSIgLz4KCTxwYXRoIGQ9Im0xOTguMjggNDcuODRoMjUuNjV2MjUuNjVoLTI1LjY1eiIgZmlsbD0iIzYyNGFmZiIgLz4KCTxwYXRoIGQ9Im0xOTguMjggMjIuMTloMjUuNjV2MjUuNjVoLTI1LjY1eiIgZmlsbD0iIzM2Y2ZkMSIgLz4KCTxwYXRoIGQ9Im0xNTAuNDQgMHYyMi4xOWgyNS42NXYyNS42NWgyMi4xOXYtNDcuODR6IiBmaWxsPSIjNjI0YWZmIiAvPgoJPHBhdGggZD0ibTczLjQ5IDQ3Ljg0aDI1LjY1djI1LjY1aC0yNS42NXoiIGZpbGw9IiMzNmNmZDEiIC8+Cgk8cGF0aCBkPSJtNDcuODQgMjIuMTloMjUuNjV2LTIyLjE5aC00Ny44NHY0Ny44NGgyMi4xOXoiIGZpbGw9IiM2MjRhZmYiIC8+Cgk8cGF0aCBkPSJtNDcuODQgNzMuNDloLTIyLjE5djQ3Ljg0aDQ3Ljg0di0yMi4xOWgtMjUuNjV6IiBmaWxsPSIjNjI0YWZmIiAvPgo8L3N2Zz4K&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/modelscope/agentscope/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache--2.0-black&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://modelscope.github.io/agentscope/tutorial/contribute.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Contribute-Welcome-green&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you find our work helpful, please kindly cite &lt;a href=&#34;https://arxiv.org/abs/2402.14034&#34;&gt;our paper&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Welcome to join our community on&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://discord.gg/eYMpfnkG8h&#34;&gt;Discord&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;DingTalk&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://gw.alicdn.com/imgextra/i1/O1CN01hhD1mu1Dd3BWVUvxN_!!6000000000238-2-tps-400-400.png&#34; width=&#34;100&#34; height=&#34;100&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://img.alicdn.com/imgextra/i2/O1CN01tuJ5971OmAqNg9cOw_!!6000000001747-0-tps-444-460.jpg&#34; width=&#34;100&#34; height=&#34;100&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;img src=&#34;https://img.alicdn.com/imgextra/i3/O1CN01SFL0Gu26nrQBFKXFR_!!6000000007707-2-tps-500-500.png&#34; alt=&#34;new&#34; width=&#34;30&#34; height=&#34;30&#34;&gt;&lt;strong&gt;[2024-06-14]&lt;/strong&gt; A new prompt tuning module is available in AgentScope to help developers generate and optimize the agents&#39; system prompts! Refer to our &lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/209-prompt_opt.html&#34;&gt;tutorial&lt;/a&gt; for more details!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;img src=&#34;https://img.alicdn.com/imgextra/i3/O1CN01SFL0Gu26nrQBFKXFR_!!6000000007707-2-tps-500-500.png&#34; alt=&#34;new&#34; width=&#34;30&#34; height=&#34;30&#34;&gt;&lt;strong&gt;[2024-06-11]&lt;/strong&gt; The RAG functionality is available for agents in &lt;strong&gt;AgentScope&lt;/strong&gt; now! &lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/210-rag.html&#34;&gt;&lt;strong&gt;A quick introduction to RAG in AgentScope&lt;/strong&gt;&lt;/a&gt; can help you equip your agent with external knowledge!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;img src=&#34;https://img.alicdn.com/imgextra/i3/O1CN01SFL0Gu26nrQBFKXFR_!!6000000007707-2-tps-500-500.png&#34; alt=&#34;new&#34; width=&#34;30&#34; height=&#34;30&#34;&gt;&lt;strong&gt;[2024-06-09]&lt;/strong&gt; We release &lt;strong&gt;AgentScope&lt;/strong&gt; v0.0.5 now! In this new version, &lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/209-gui.html&#34;&gt;&lt;strong&gt;AgentScope Workstation&lt;/strong&gt;&lt;/a&gt; (the online version is running on &lt;a href=&#34;https://agentscope.io&#34;&gt;agentscope.io&lt;/a&gt;) is open-sourced with the refactored &lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/209-gui.html&#34;&gt;&lt;strong&gt;AgentScope Studio&lt;/strong&gt;&lt;/a&gt;!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5 align=&#34;center&#34;&gt; &lt;img src=&#34;https://img.alicdn.com/imgextra/i1/O1CN01RXAVVn1zUtjXVvuqS_!!6000000006718-1-tps-3116-1852.gif&#34; width=&#34;600&#34; alt=&#34;agentscope-logo&#34;&gt; &lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;img src=&#34;https://img.alicdn.com/imgextra/i3/O1CN01SFL0Gu26nrQBFKXFR_!!6000000007707-2-tps-500-500.png&#34; alt=&#34;new&#34; width=&#34;30&#34; height=&#34;30&#34;&gt;&lt;strong&gt;[2024-05-24]&lt;/strong&gt; We are pleased to announce that features related to the &lt;strong&gt;AgentScope Workstation&lt;/strong&gt; will soon be open-sourced! The online website services are temporarily offline. The online website service will be upgraded and back online shortly. Stay tuned...&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;img src=&#34;https://img.alicdn.com/imgextra/i3/O1CN01SFL0Gu26nrQBFKXFR_!!6000000007707-2-tps-500-500.png&#34; alt=&#34;new&#34; width=&#34;30&#34; height=&#34;30&#34;&gt;&lt;strong&gt;[2024-05-15]&lt;/strong&gt; A new &lt;strong&gt;Parser Module&lt;/strong&gt; for &lt;strong&gt;formatted response&lt;/strong&gt; is added in AgentScope! Refer to our &lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-parser.html&#34;&gt;tutorial&lt;/a&gt; for more details. The &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/agents/dict_dialog_agent.py&#34;&gt;&lt;code&gt;DictDialogAgent&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://github.com/modelscope/agentscope/tree/main/examples/game_werewolf&#34;&gt;werewolf game&lt;/a&gt; example are updated simultaneously.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/qbc2016/AgentScope/assets/22984042/22d45aee-3470-4923-850f-348a5b0faaa7&#34;&gt;https://github.com/qbc2016/AgentScope/assets/22984042/22d45aee-3470-4923-850f-348a5b0faaa7&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;img src=&#34;https://img.alicdn.com/imgextra/i3/O1CN01SFL0Gu26nrQBFKXFR_!!6000000007707-2-tps-500-500.png&#34; alt=&#34;new&#34; width=&#34;30&#34; height=&#34;30&#34;&gt;&lt;strong&gt;[2024-05-14]&lt;/strong&gt; Dear AgentScope users, we are conducting a survey on &lt;strong&gt;AgentScope Workstation &amp;amp; Copilot&lt;/strong&gt; user experience. We currently need your valuable feedback to help us improve the experience of AgentScope&#39;s Drag &amp;amp; Drop multi-agent application development and Copilot. Your feedback is valuable and the survey will take about 3~5 minutes. Please click &lt;a href=&#34;https://survey.aliyun.com/apps/zhiliao/vgpTppn22&#34;&gt;URL&lt;/a&gt; to participate in questionnaire surveys. Thank you very much for your support and contribution!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;img src=&#34;https://img.alicdn.com/imgextra/i3/O1CN01SFL0Gu26nrQBFKXFR_!!6000000007707-2-tps-500-500.png&#34; alt=&#34;new&#34; width=&#34;30&#34; height=&#34;30&#34;&gt;&lt;strong&gt;[2024-05-14]&lt;/strong&gt; AgentScope supports &lt;strong&gt;gpt-4o&lt;/strong&gt; as well as other OpenAI vision models now! Try gpt-4o with its &lt;a href=&#34;https://raw.githubusercontent.com/modelscope/agentscope/main/examples/model_configs_template/openai_chat_template.json&#34;&gt;model configuration&lt;/a&gt; and new example &lt;a href=&#34;https://raw.githubusercontent.com/modelscope/agentscope/main/examples/conversation_with_gpt-4o&#34;&gt;Conversation with gpt-4o&lt;/a&gt;!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;[2024-04-30]&lt;/strong&gt; We release &lt;strong&gt;AgentScope&lt;/strong&gt; v0.0.4 now!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;[2024-04-27]&lt;/strong&gt; &lt;a href=&#34;https://agentscope.aliyun.com/&#34;&gt;AgentScope Workstation&lt;/a&gt; is now online! You are welcome to try building your multi-agent application simply with our &lt;em&gt;drag-and-drop platform&lt;/em&gt; and ask our &lt;em&gt;copilot&lt;/em&gt; questions about AgentScope!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;[2024-04-19]&lt;/strong&gt; AgentScope supports Llama3 now! We provide &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_llama3&#34;&gt;scripts&lt;/a&gt; and example &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_llama3&#34;&gt;model configuration&lt;/a&gt; for quick set-up. Feel free to try llama3 in our examples!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;[2024-04-06]&lt;/strong&gt; We release &lt;strong&gt;AgentScope&lt;/strong&gt; v0.0.3 now!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;[2024-04-06]&lt;/strong&gt; New examples &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/game_gomoku&#34;&gt;Gomoku&lt;/a&gt;, &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/conversation_with_react_agent&#34;&gt;Conversation with ReAct Agent&lt;/a&gt;, &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/conversation_with_RAG_agents&#34;&gt;Conversation with RAG Agent&lt;/a&gt; and &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/distributed_parallel_optimization&#34;&gt;Distributed Parallel Optimization&lt;/a&gt; are available now!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;[2024-03-19]&lt;/strong&gt; We release &lt;strong&gt;AgentScope&lt;/strong&gt; v0.0.2 now! In this new version, AgentScope supports &lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#supported-models&#34;&gt;ollama&lt;/a&gt;(A local CPU inference engine), &lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#supported-models&#34;&gt;DashScope&lt;/a&gt; and Google &lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#supported-models&#34;&gt;Gemini&lt;/a&gt; APIs.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;[2024-03-19]&lt;/strong&gt; New examples &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/conversation_with_mentions&#34;&gt;&#34;Autonomous Conversation with Mentions&#34;&lt;/a&gt; and &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/conversation_with_langchain&#34;&gt;&#34;Basic Conversation with LangChain library&#34;&lt;/a&gt; are available now!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;[2024-03-19]&lt;/strong&gt; The &lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/index.html&#34;&gt;Chinese tutorial&lt;/a&gt; of AgentScope is online now!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;[2024-02-27]&lt;/strong&gt; We release &lt;strong&gt;AgentScope v0.0.1&lt;/strong&gt; now, which is also available in &lt;a href=&#34;https://pypi.org/project/agentscope/&#34;&gt;PyPI&lt;/a&gt;!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;[2024-02-14]&lt;/strong&gt; We release our paper &#34;AgentScope: A Flexible yet Robust Multi-Agent Platform&#34; in &lt;a href=&#34;https://arxiv.org/abs/2402.14034&#34;&gt;arXiv&lt;/a&gt; now!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;What&#39;s AgentScope?&lt;/h2&gt; &#xA;&lt;p&gt;AgentScope is an innovative multi-agent platform designed to empower developers to build multi-agent applications with large-scale models. It features three high-level capabilities:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;ü§ù &lt;strong&gt;Easy-to-Use&lt;/strong&gt;: Designed for developers, with &lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/204-service.html#&#34;&gt;fruitful components&lt;/a&gt;, &lt;a href=&#34;https://modelscope.github.io/agentscope/en/index.html&#34;&gt;comprehensive documentation&lt;/a&gt;, and broad compatibility. Besides, &lt;a href=&#34;https://agentscope.aliyun.com/&#34;&gt;AgentScope Workstation&lt;/a&gt; provides a &lt;em&gt;drag-and-drop programming platform&lt;/em&gt; and a &lt;em&gt;copilot&lt;/em&gt; for beginners of AgentScope!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;‚úÖ &lt;strong&gt;High Robustness&lt;/strong&gt;: Supporting customized fault-tolerance controls and retry mechanisms to enhance application stability.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üöÄ &lt;strong&gt;Actor-Based Distribution&lt;/strong&gt;: Building distributed multi-agent applications in a centralized programming manner for streamlined development.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Supported Model Libraries&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;AgentScope provides a list of &lt;code&gt;ModelWrapper&lt;/code&gt; to support both local model services and third-party model APIs.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;API&lt;/th&gt; &#xA;   &lt;th&gt;Task&lt;/th&gt; &#xA;   &lt;th&gt;Model Wrapper&lt;/th&gt; &#xA;   &lt;th&gt;Configuration&lt;/th&gt; &#xA;   &lt;th&gt;Some Supported Models&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OpenAI API&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/openai_model.py&#34;&gt;&lt;code&gt;OpenAIChatWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#openai-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/openai_chat_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;gpt-4o, gpt-4, gpt-3.5-turbo, ...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Embedding&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/openai_model.py&#34;&gt;&lt;code&gt;OpenAIEmbeddingWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#openai-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/openai_embedding_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;text-embedding-ada-002, ...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;DALL¬∑E&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/openai_model.py&#34;&gt;&lt;code&gt;OpenAIDALLEWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#openai-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/openai_dall_e_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;dall-e-2, dall-e-3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DashScope API&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/dashscope_model.py&#34;&gt;&lt;code&gt;DashScopeChatWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#dashscope-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/dashscope_chat_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;qwen-plus, qwen-max, ...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Image Synthesis&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/dashscope_model.py&#34;&gt;&lt;code&gt;DashScopeImageSynthesisWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#dashscope-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/dashscope_image_synthesis_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;wanx-v1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Text Embedding&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/dashscope_model.py&#34;&gt;&lt;code&gt;DashScopeTextEmbeddingWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#dashscope-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/dashscope_text_embedding_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;text-embedding-v1, text-embedding-v2, ...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Multimodal&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/dashscope_model.py&#34;&gt;&lt;code&gt;DashScopeMultiModalWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#dashscope-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/dashscope_multimodal_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;qwen-vl-max, qwen-vl-chat-v1, qwen-audio-chat&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gemini API&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/gemini_model.py&#34;&gt;&lt;code&gt;GeminiChatWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#gemini-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/gemini_chat_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;gemini-pro, ...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Embedding&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/gemini_model.py&#34;&gt;&lt;code&gt;GeminiEmbeddingWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#gemini-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/gemini_embedding_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;models/embedding-001, ...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ZhipuAI API&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/zhipu_model.py&#34;&gt;&lt;code&gt;ZhipuAIChatWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#zhipu-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/zhipu_chat_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;glm-4, ...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Embedding&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/zhipu_model.py&#34;&gt;&lt;code&gt;ZhipuAIEmbeddingWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#zhipu-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/zhipu_embedding_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;embedding-2, ...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ollama&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/ollama_model.py&#34;&gt;&lt;code&gt;OllamaChatWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#ollama-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/ollama_chat_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;llama3, llama2, Mistral, ...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Embedding&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/ollama_model.py&#34;&gt;&lt;code&gt;OllamaEmbeddingWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#ollama-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/ollama_embedding_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;llama2, Mistral, ...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Generation&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/ollama_model.py&#34;&gt;&lt;code&gt;OllamaGenerationWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#ollama-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/ollama_generate_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;llama2, Mistral, ...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LiteLLM API&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/litellm_model.py&#34;&gt;&lt;code&gt;LiteLLMChatWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#litellm-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/litellm_chat_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.litellm.ai/docs/&#34;&gt;models supported by litellm&lt;/a&gt;...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Post Request based API&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/src/agentscope/models/post_model.py&#34;&gt;&lt;code&gt;PostAPIModelWrapper&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/203-model.html#post-request-api&#34;&gt;guidance&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_configs_template/postapi_model_config_template.json&#34;&gt;template&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Supported Local Model Deployment&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;AgentScope enables developers to rapidly deploy local model services using the following libraries.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/scripts/README.md#ollama&#34;&gt;ollama (CPU inference)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/scripts/README.md#with-transformers-library&#34;&gt;Flask + Transformers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/scripts/README.md#with-modelscope-library&#34;&gt;Flask + ModelScope&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/scripts/README.md#fastchat&#34;&gt;FastChat&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/scripts/README.md#vllm&#34;&gt;vllm&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Supported Services&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Web Search&lt;/li&gt; &#xA; &lt;li&gt;Data Query&lt;/li&gt; &#xA; &lt;li&gt;Retrieval&lt;/li&gt; &#xA; &lt;li&gt;Code Execution&lt;/li&gt; &#xA; &lt;li&gt;File Operation&lt;/li&gt; &#xA; &lt;li&gt;Text Processing&lt;/li&gt; &#xA; &lt;li&gt;Multi Modality&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example Applications&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Model&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;img src=&#34;https://img.alicdn.com/imgextra/i3/O1CN01SFL0Gu26nrQBFKXFR_!!6000000007707-2-tps-500-500.png&#34; alt=&#34;new&#34; width=&#34;30&#34; height=&#34;30&#34;&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/model_llama3&#34;&gt;Using Llama3 in AgentScope&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Conversation&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/conversation_basic&#34;&gt;Basic Conversation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/conversation_with_mentions&#34;&gt;Autonomous Conversation with Mentions&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/conversation_self_organizing&#34;&gt;Self-Organizing Conversation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/conversation_with_langchain&#34;&gt;Basic Conversation with LangChain library&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/conversation_with_react_agent&#34;&gt;Conversation with ReAct Agent&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/conversation_nl2sql/&#34;&gt;Conversation in Natural Language to Query SQL&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/conversation_with_RAG_agents&#34;&gt;Conversation with RAG Agent&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;img src=&#34;https://img.alicdn.com/imgextra/i3/O1CN01SFL0Gu26nrQBFKXFR_!!6000000007707-2-tps-500-500.png&#34; alt=&#34;new&#34; width=&#34;30&#34; height=&#34;30&#34;&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/conversation_with_gpt-4o&#34;&gt;Conversation with gpt-4o&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;img src=&#34;https://img.alicdn.com/imgextra/i3/O1CN01SFL0Gu26nrQBFKXFR_!!6000000007707-2-tps-500-500.png&#34; alt=&#34;new&#34; width=&#34;30&#34; height=&#34;30&#34;&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/conversation_with_swe-agent/&#34;&gt;Conversation with Software Engineering Agent&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;img src=&#34;https://img.alicdn.com/imgextra/i3/O1CN01SFL0Gu26nrQBFKXFR_!!6000000007707-2-tps-500-500.png&#34; alt=&#34;new&#34; width=&#34;30&#34; height=&#34;30&#34;&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/conversation_with_customized_services/&#34;&gt;Conversation with Customized Services&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Game&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/game_gomoku&#34;&gt;Gomoku&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/game_werewolf&#34;&gt;Werewolf&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Distribution&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/distributed_conversation&#34;&gt;Distributed Conversation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/distributed_debate&#34;&gt;Distributed Debate&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/distributed_parallel_optimization&#34;&gt;Distributed Parallel Optimization&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/agentscope/raw/main/examples/distributed_simulation&#34;&gt;Distributed Large Scale Simulation&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;More models, services and examples are coming soon!&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;AgentScope requires &lt;strong&gt;Python 3.9&lt;/strong&gt; or higher.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note: This project is currently in active development, it&#39;s recommended to install AgentScope from source.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;From source&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install AgentScope in editable mode:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Pull the source code from GitHub&#xA;git clone https://github.com/modelscope/agentscope.git&#xA;&#xA;# Install the package in editable mode&#xA;cd agentscope&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To build distributed multi-agent applications:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# On windows&#xA;pip install -e .[distribute]&#xA;# On mac&#xA;pip install -e .\[distribute\]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Using pip&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install AgentScope from pip:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install agentscope --pre&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;h3&gt;Configuration&lt;/h3&gt; &#xA;&lt;p&gt;In AgentScope, the model deployment and invocation are decoupled by &lt;code&gt;ModelWrapper&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To use these model wrappers, you need to prepare a model config file as follows.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model_config = {&#xA;    # The identifies of your config and used model wrapper&#xA;    &#34;config_name&#34;: &#34;{your_config_name}&#34;,          # The name to identify the config&#xA;    &#34;model_type&#34;: &#34;{model_type}&#34;,                 # The type to identify the model wrapper&#xA;&#xA;    # Detailed parameters into initialize the model wrapper&#xA;    # ...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Taking OpenAI Chat API as an example, the model configuration is as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;openai_model_config = {&#xA;    &#34;config_name&#34;: &#34;my_openai_config&#34;,             # The name to identify the config&#xA;    &#34;model_type&#34;: &#34;openai_chat&#34;,                   # The type to identify the model wrapper&#xA;&#xA;    # Detailed parameters into initialize the model wrapper&#xA;    &#34;model_name&#34;: &#34;gpt-4&#34;,                         # The used model in openai API, e.g. gpt-4, gpt-3.5-turbo, etc.&#xA;    &#34;api_key&#34;: &#34;xxx&#34;,                              # The API key for OpenAI API. If not set, env&#xA;                                                   # variable OPENAI_API_KEY will be used.&#xA;    &#34;organization&#34;: &#34;xxx&#34;,                         # The organization for OpenAI API. If not set, env&#xA;                                                   # variable OPENAI_ORGANIZATION will be used.&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;More details about how to set up local model services and prepare model configurations is in our &lt;a href=&#34;https://modelscope.github.io/agentscope/index.html#welcome-to-agentscope-tutorial-hub&#34;&gt;tutorial&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Create Agents&lt;/h3&gt; &#xA;&lt;p&gt;Create built-in user and assistant agents as follows.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from agentscope.agents import DialogAgent, UserAgent&#xA;import agentscope&#xA;&#xA;# Load model configs&#xA;agentscope.init(model_configs=&#34;./model_configs.json&#34;)&#xA;&#xA;# Create a dialog agent and a user agent&#xA;dialog_agent = DialogAgent(name=&#34;assistant&#34;,&#xA;                           model_config_name=&#34;my_openai_config&#34;)&#xA;user_agent = UserAgent()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Construct Conversation&lt;/h3&gt; &#xA;&lt;p&gt;In AgentScope, &lt;strong&gt;message&lt;/strong&gt; is the bridge among agents, which is a &lt;strong&gt;dict&lt;/strong&gt; that contains two necessary fields &lt;code&gt;name&lt;/code&gt; and &lt;code&gt;content&lt;/code&gt; and an optional field &lt;code&gt;url&lt;/code&gt; to local files (image, video or audio) or website.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from agentscope.message import Msg&#xA;&#xA;x = Msg(name=&#34;Alice&#34;, content=&#34;Hi!&#34;)&#xA;x = Msg(&#34;Bob&#34;, &#34;What about this picture I took?&#34;, url=&#34;/path/to/picture.jpg&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Start a conversation between two agents (e.g. dialog_agent and user_agent) with the following code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x = None&#xA;while True:&#xA;    x = dialog_agent(x)&#xA;    x = user_agent(x)&#xA;    if x.content == &#34;exit&#34;:  # user input &#34;exit&#34; to exit the conversation_basic&#xA;        break&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;AgentScope Studio&lt;/h3&gt; &#xA;&lt;p&gt;AgentScope provides an easy-to-use runtime user interface capable of displaying multimodal output on the front end, including text, images, audio and video.&lt;/p&gt; &#xA;&lt;p&gt;Refer to our &lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/209-gui.html&#34;&gt;tutorial&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h5 align=&#34;center&#34;&gt; &lt;img src=&#34;https://img.alicdn.com/imgextra/i4/O1CN015kjnkd1xdwJoNxqLZ_!!6000000006467-0-tps-3452-1984.jpg&#34; width=&#34;600&#34; alt=&#34;agentscope-logo&#34;&gt; &lt;/h5&gt; &#xA;&lt;h2&gt;Tutorial&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/101-agentscope.html&#34;&gt;About AgentScope&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/102-installation.html&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/103-example.html&#34;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/203-model.html&#34;&gt;Model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/206-prompt.html&#34;&gt;Prompt Engineering&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/201-agent.html&#34;&gt;Agent&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/205-memory.html&#34;&gt;Memory&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/203-parser.html&#34;&gt;Response Parser&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/204-service.html&#34;&gt;Tool&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/202-pipeline.html&#34;&gt;Pipeline and MsgHub&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/208-distribute.html&#34;&gt;Distribution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/209-gui.html&#34;&gt;AgentScope Studio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/105-logging.html&#34;&gt;Logging&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/207-monitor.html&#34;&gt;Monitor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.github.io/agentscope/zh_CN/tutorial/104-usecase.html&#34;&gt;Example: Werewolf Game&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;AgentScope is released under Apache License 2.0.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are always welcomed!&lt;/p&gt; &#xA;&lt;p&gt;We provide a developer version with additional pre-commit hooks to perform checks compared to the official version:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# For windows&#xA;pip install -e .[dev]&#xA;# For mac&#xA;pip install -e .\[dev\]&#xA;&#xA;# Install pre-commit hooks&#xA;pre-commit install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please refer to our &lt;a href=&#34;https://modelscope.github.io/agentscope/en/tutorial/302-contribute.html&#34;&gt;Contribution Guide&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;p&gt;If you find our work helpful for your research or application, please cite &lt;a href=&#34;https://arxiv.org/abs/2402.14034&#34;&gt;our paper&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{agentscope,&#xA;  author  = {Dawei Gao and&#xA;             Zitao Li and&#xA;             Xuchen Pan and&#xA;             Weirui Kuang and&#xA;             Zhijian Ma and&#xA;             Bingchen Qian and&#xA;             Fei Wei and&#xA;             Wenhao Zhang and&#xA;             Yuexiang Xie and&#xA;             Daoyuan Chen and&#xA;             Liuyi Yao and&#xA;             Hongyi Peng and&#xA;             Zeyu Zhang and&#xA;             Lin Zhu and&#xA;             Chen Cheng and&#xA;             Hongzhu Shi and&#xA;             Yaliang Li and&#xA;             Bolin Ding and&#xA;             Jingren Zhou},&#xA;  title   = {AgentScope: A Flexible yet Robust Multi-Agent Platform},&#xA;  journal = {CoRR},&#xA;  volume  = {abs/2402.14034},&#xA;  year    = {2024},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>langchain-ai/langgraph</title>
    <updated>2024-07-10T01:38:47Z</updated>
    <id>tag:github.com,2024-07-10:/langchain-ai/langgraph</id>
    <link href="https://github.com/langchain-ai/langgraph" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Build resilient language agents as graphs.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ü¶úüï∏Ô∏èLangGraph&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/langgraph&#34; alt=&#34;Version&#34;&gt; &lt;a href=&#34;https://pepy.tech/project/langgraph&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/badge/langgraph/month&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/langchain-ai/langgraph/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-raw/langchain-ai/langgraph&#34; alt=&#34;Open Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.com/channels/1038097195422978059/1170024642245832774&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/6adMQxSpJS?compact=true&amp;amp;style=flat&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://langchain-ai.github.io/langgraph/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-latest-blue&#34; alt=&#34;Docs&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;‚ö° Building language agents as graphs ‚ö°&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] Looking for the JS version? Click &lt;a href=&#34;https://github.com/langchain-ai/langgraphjs&#34;&gt;here&lt;/a&gt; (&lt;a href=&#34;https://langchain-ai.github.io/langgraphjs/&#34;&gt;JS docs&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] Looking to deploy your LangGraph application? &lt;a href=&#34;https://www.langchain.com/langgraph-cloud-beta&#34;&gt;Join the waitlist&lt;/a&gt; for &lt;a href=&#34;https://langchain-ai.github.io/langgraph/cloud/&#34;&gt;LangGraph Cloud&lt;/a&gt;, our managed service for deploying and hosting LangGraph applications.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://langchain-ai.github.io/langgraph/&#34;&gt;LangGraph&lt;/a&gt; is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures, differentiating it from DAG-based solutions. As a very low-level framework, it provides fine-grained control over both the flow and state of your application, crucial for creating reliable agents. Additionally, LangGraph includes built-in persistence, enabling advanced human-in-the-loop and memory features.&lt;/p&gt; &#xA;&lt;p&gt;LangGraph is inspired by &lt;a href=&#34;https://research.google/pubs/pub37252/&#34;&gt;Pregel&lt;/a&gt; and &lt;a href=&#34;https://beam.apache.org/&#34;&gt;Apache Beam&lt;/a&gt;. The public interface draws inspiration from &lt;a href=&#34;https://networkx.org/documentation/latest/&#34;&gt;NetworkX&lt;/a&gt;. LangGraph is built by LangChain Inc, the creators of LangChain, but can be used without LangChain.&lt;/p&gt; &#xA;&lt;h3&gt;Key Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Cycles and Branching&lt;/strong&gt;: Implement loops and conditionals in your apps.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Persistence&lt;/strong&gt;: Automatically save state after each step in the graph. Pause and resume the graph execution at any point to support error recovery, human-in-the-loop workflows, time travel and more.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Human-in-the-Loop&lt;/strong&gt;: Interrupt graph execution to approve or edit next action planned by the agent.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Streaming Support&lt;/strong&gt;: Stream outputs as they are produced by each node (including token streaming).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Integration with LangChain&lt;/strong&gt;: LangGraph integrates seamlessly with &lt;a href=&#34;https://github.com/langchain-ai/langchain/&#34;&gt;LangChain&lt;/a&gt; and &lt;a href=&#34;https://docs.smith.langchain.com/&#34;&gt;LangSmith&lt;/a&gt; (but does not require them).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install -U langgraph&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;One of the central concepts of LangGraph is state. Each graph execution creates a state that is passed between nodes in the graph as they execute, and each node updates this internal state with its return value after it executes. The way that the graph updates its internal state is defined by either the type of graph chosen or a custom function.&lt;/p&gt; &#xA;&lt;p&gt;Let&#39;s take a look at a simple example of an agent that can use a search tool.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install langchain-anthropic&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export ANTHROPIC_API_KEY=sk-...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Optionally, we can set up &lt;a href=&#34;https://docs.smith.langchain.com/&#34;&gt;LangSmith&lt;/a&gt; for best-in-class observability.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export LANGSMITH_TRACING=true&#xA;export LANGSMITH_API_KEY=lsv2_sk_...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from typing import Annotated, Literal, TypedDict&#xA;&#xA;from langchain_core.messages import HumanMessage&#xA;from langchain_anthropic import ChatAnthropic&#xA;from langchain_core.tools import tool&#xA;from langgraph.checkpoint import MemorySaver&#xA;from langgraph.graph import END, StateGraph, MessagesState&#xA;from langgraph.prebuilt import ToolNode&#xA;&#xA;&#xA;# Define the tools for the agent to use&#xA;@tool&#xA;def search(query: str):&#xA;    &#34;&#34;&#34;Call to surf the web.&#34;&#34;&#34;&#xA;    # This is a placeholder, but don&#39;t tell the LLM that...&#xA;    if &#34;sf&#34; in query.lower() or &#34;san francisco&#34; in query.lower():&#xA;        return [&#34;It&#39;s 60 degrees and foggy.&#34;]&#xA;    return [&#34;It&#39;s 90 degrees and sunny.&#34;]&#xA;&#xA;&#xA;tools = [search]&#xA;&#xA;tool_node = ToolNode(tools)&#xA;&#xA;model = ChatAnthropic(model=&#34;claude-3-5-sonnet-20240620&#34;, temperature=0).bind_tools(tools)&#xA;&#xA;# Define the function that determines whether to continue or not&#xA;def should_continue(state: MessagesState) -&amp;gt; Literal[&#34;tools&#34;, END]:&#xA;    messages = state[&#39;messages&#39;]&#xA;    last_message = messages[-1]&#xA;    # If the LLM makes a tool call, then we route to the &#34;tools&#34; node&#xA;    if last_message.tool_calls:&#xA;        return &#34;tools&#34;&#xA;    # Otherwise, we stop (reply to the user)&#xA;    return END&#xA;&#xA;&#xA;# Define the function that calls the model&#xA;def call_model(state: MessagesState):&#xA;    messages = state[&#39;messages&#39;]&#xA;    response = model.invoke(messages)&#xA;    # We return a list, because this will get added to the existing list&#xA;    return {&#34;messages&#34;: [response]}&#xA;&#xA;&#xA;# Define a new graph&#xA;workflow = StateGraph(MessagesState)&#xA;&#xA;# Define the two nodes we will cycle between&#xA;workflow.add_node(&#34;agent&#34;, call_model)&#xA;workflow.add_node(&#34;tools&#34;, tool_node)&#xA;&#xA;# Set the entrypoint as `agent`&#xA;# This means that this node is the first one called&#xA;workflow.set_entry_point(&#34;agent&#34;)&#xA;&#xA;# We now add a conditional edge&#xA;workflow.add_conditional_edges(&#xA;    # First, we define the start node. We use `agent`.&#xA;    # This means these are the edges taken after the `agent` node is called.&#xA;    &#34;agent&#34;,&#xA;    # Next, we pass in the function that will determine which node is called next.&#xA;    should_continue,&#xA;)&#xA;&#xA;# We now add a normal edge from `tools` to `agent`.&#xA;# This means that after `tools` is called, `agent` node is called next.&#xA;workflow.add_edge(&#34;tools&#34;, &#39;agent&#39;)&#xA;&#xA;# Initialize memory to persist state between graph runs&#xA;checkpointer = MemorySaver()&#xA;&#xA;# Finally, we compile it!&#xA;# This compiles it into a LangChain Runnable,&#xA;# meaning you can use it as you would any other runnable.&#xA;# Note that we&#39;re (optionally) passing the memory when compiling the graph&#xA;app = workflow.compile(checkpointer=checkpointer)&#xA;&#xA;# Use the Runnable&#xA;final_state = app.invoke(&#xA;    {&#34;messages&#34;: [HumanMessage(content=&#34;what is the weather in sf&#34;)]},&#xA;    config={&#34;configurable&#34;: {&#34;thread_id&#34;: 42}}&#xA;)&#xA;final_state[&#34;messages&#34;][-1].content&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#34;Based on the search results, I can tell you that the current weather in San Francisco is:\n\nTemperature: 60 degrees Fahrenheit\nConditions: Foggy\n\nSan Francisco is known for its microclimates and frequent fog, especially during the summer months. The temperature of 60¬∞F (about 15.5¬∞C) is quite typical for the city, which tends to have mild temperatures year-round. The fog, often referred to as &#34;Karl the Fog&#34; by locals, is a characteristic feature of San Francisco\&#39;s weather, particularly in the mornings and evenings.\n\nIs there anything else you\&#39;d like to know about the weather in San Francisco or any other location?&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now when we pass the same &lt;code&gt;&#34;thread_id&#34;&lt;/code&gt;, the conversation context is retained via the saved state (i.e. stored list of messages)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;final_state = app.invoke(&#xA;    {&#34;messages&#34;: [HumanMessage(content=&#34;what about ny&#34;)]},&#xA;    config={&#34;configurable&#34;: {&#34;thread_id&#34;: 42}}&#xA;)&#xA;final_state[&#34;messages&#34;][-1].content&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#34;Based on the search results, I can tell you that the current weather in New York City is:\n\nTemperature: 90 degrees Fahrenheit (approximately 32.2 degrees Celsius)\nConditions: Sunny\n\nThis weather is quite different from what we just saw in San Francisco. New York is experiencing much warmer temperatures right now. Here are a few points to note:\n\n1. The temperature of 90¬∞F is quite hot, typical of summer weather in New York City.\n2. The sunny conditions suggest clear skies, which is great for outdoor activities but also means it might feel even hotter due to direct sunlight.\n3. This kind of weather in New York often comes with high humidity, which can make it feel even warmer than the actual temperature suggests.\n\nIt&#39;s interesting to see the stark contrast between San Francisco&#39;s mild, foggy weather and New York&#39;s hot, sunny conditions. This difference illustrates how varied weather can be across different parts of the United States, even on the same day.\n\nIs there anything else you&#39;d like to know about the weather in New York or any other location?&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step-by-step Breakdown&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Initialize the model and tools.&lt;/summary&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;we use &lt;code&gt;ChatAnthropic&lt;/code&gt; as our LLM. &lt;strong&gt;NOTE:&lt;/strong&gt; we need make sure the model knows that it has these tools available to call. We can do this by converting the LangChain tools into the format for OpenAI tool calling using the &lt;code&gt;.bind_tools()&lt;/code&gt; method.&lt;/li&gt; &#xA;    &lt;li&gt;we define the tools we want to use - a search tool in our case. It is really easy to create your own tools - see documentation here on how to do that &lt;a href=&#34;https://python.langchain.com/docs/modules/agents/tools/custom_tools&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;/ul&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Initialize graph with state.&lt;/summary&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;we initialize graph (&lt;code&gt;StateGraph&lt;/code&gt;) by passing state schema (in our case &lt;code&gt;MessagesState&lt;/code&gt;)&lt;/li&gt; &#xA;    &lt;li&gt;&lt;code&gt;MessagesState&lt;/code&gt; is a prebuilt state schema that has one attribute -- a list of LangChain &lt;code&gt;Message&lt;/code&gt; objects, as well as logic for merging the updates from each node into the state&lt;/li&gt; &#xA;   &lt;/ul&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Define graph nodes.&lt;/summary&gt; &#xA;   &lt;p&gt;There are two main nodes we need:&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;The &lt;code&gt;agent&lt;/code&gt; node: responsible for deciding what (if any) actions to take.&lt;/li&gt; &#xA;    &lt;li&gt;The &lt;code&gt;tools&lt;/code&gt; node that invokes tools: if the agent decides to take an action, this node will then execute that action.&lt;/li&gt; &#xA;   &lt;/ul&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Define entry point and graph edges.&lt;/summary&gt; &#xA;   &lt;p&gt;First, we need to set the entry point for graph execution - &lt;code&gt;agent&lt;/code&gt; node.&lt;/p&gt; &#xA;   &lt;p&gt;Then we define one normal and one conditional edge. Conditional edge means that the destination depends on the contents of the graph&#39;s state (&lt;code&gt;MessageState&lt;/code&gt;). In our case, the destination is not known until the agent (LLM) decides.&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Conditional edge: after the agent is called, we should either: &#xA;     &lt;ul&gt; &#xA;      &lt;li&gt;a. Run tools if the agent said to take an action, OR&lt;/li&gt; &#xA;      &lt;li&gt;b. Finish (respond to the user) if the agent did not ask to run tools&lt;/li&gt; &#xA;     &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;li&gt;Normal edge: after the tools are invoked, the graph should always return to the agent to decide what to do next&lt;/li&gt; &#xA;   &lt;/ul&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Compile the graph.&lt;/summary&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;When we compile the graph, we turn it into a LangChain &lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts/#runnable-interface&#34;&gt;Runnable&lt;/a&gt;, which automatically enables calling &lt;code&gt;.invoke()&lt;/code&gt;, &lt;code&gt;.stream()&lt;/code&gt; and &lt;code&gt;.batch()&lt;/code&gt; with your inputs&lt;/li&gt; &#xA;    &lt;li&gt;We can also optionally pass checkpointer object for persisting state between graph runs, and enabling memory, human-in-the-loop workflows, time travel and more. In our case we use &lt;code&gt;MemorySaver&lt;/code&gt; - a simple in-memory checkpointer&lt;/li&gt; &#xA;   &lt;/ul&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;Execute the graph.&lt;/summary&gt; &#xA;   &lt;ol&gt; &#xA;    &lt;li&gt; &lt;p&gt;LangGraph adds the input message to the internal state, then passes the state to the entrypoint node, &lt;code&gt;&#34;agent&#34;&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;li&gt; &lt;p&gt;The &lt;code&gt;&#34;agent&#34;&lt;/code&gt; node executes, invoking the chat model.&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;li&gt; &lt;p&gt;The chat model returns an &lt;code&gt;AIMessage&lt;/code&gt;. LangGraph adds this to the state.&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;li&gt; &lt;p&gt;Graph cycles the following steps until there are no more &lt;code&gt;tool_calls&lt;/code&gt; on &lt;code&gt;AIMessage&lt;/code&gt;:&lt;/p&gt; &#xA;     &lt;ul&gt; &#xA;      &lt;li&gt;If &lt;code&gt;AIMessage&lt;/code&gt; has &lt;code&gt;tool_calls&lt;/code&gt;, &lt;code&gt;&#34;tools&#34;&lt;/code&gt; node executes&lt;/li&gt; &#xA;      &lt;li&gt;The &lt;code&gt;&#34;agent&#34;&lt;/code&gt; node executes again and returns &lt;code&gt;AIMessage&lt;/code&gt;&lt;/li&gt; &#xA;     &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;li&gt; &lt;p&gt;Execution progresses to the special &lt;code&gt;END&lt;/code&gt; value and outputs the final state. And as a result, we get a list of all our chat messages as output.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;/ol&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://langchain-ai.github.io/langgraph/tutorials/&#34;&gt;Tutorials&lt;/a&gt;: Learn to build with LangGraph through guided examples.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://langchain-ai.github.io/langgraph/how-tos/&#34;&gt;How-to Guides&lt;/a&gt;: Accomplish specific things within LangGraph, from streaming, to adding memory &amp;amp; persistence, to common design patterns (branching, subgraphs, etc.), these are the place to go if you want to copy and run a specific code snippet.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://langchain-ai.github.io/langgraph/concepts/&#34;&gt;Conceptual Guides&lt;/a&gt;: In-depth explanations of the key concepts and principles behind LangGraph, such as nodes, edges, state and more.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://langchain-ai.github.io/langgraph/reference/graphs/&#34;&gt;API Reference&lt;/a&gt;: Review important classes and methods, simple examples of how to use the graph and checkpointing APIs, higher-level prebuilt components and more.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://langchain-ai.github.io/langgraph/cloud/&#34;&gt;Cloud (beta)&lt;/a&gt;: With one click, deploy LangGraph applications to LangGraph Cloud.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;For more information on how to contribute, see &lt;a href=&#34;https://github.com/langchain-ai/langgraph/raw/main/CONTRIBUTING.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>