<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-03T01:37:37Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>OctoPrint/OctoPrint</title>
    <updated>2023-01-03T01:37:37Z</updated>
    <id>tag:github.com,2023-01-03:/OctoPrint/OctoPrint</id>
    <link href="https://github.com/OctoPrint/OctoPrint" rel="alternate"></link>
    <summary type="html">&lt;p&gt;OctoPrint is the snappy web interface for your 3D printer!&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://octoprint.org/assets/img/logo.png&#34; alt=&#34;OctoPrint&#39;s logo&#34;&gt;&lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt;OctoPrint&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/v/release/OctoPrint/OctoPrint?logo=github&amp;amp;logoColor=white&#34; alt=&#34;GitHub release&#34;&gt; &lt;img src=&#34;https://img.shields.io/pypi/v/OctoPrint?logo=python&amp;amp;logoColor=white&#34; alt=&#34;PyPI&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/OctoPrint/OctoPrint/build.yml?branch=master&#34; alt=&#34;Build status&#34;&gt; &lt;a href=&#34;https://community.octoprint.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/discourse/users?label=forum&amp;amp;logo=discourse&amp;amp;logoColor=white&amp;amp;server=https%3A%2F%2Fcommunity.octoprint.org&#34; alt=&#34;Community Forum&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.octoprint.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/704958479194128507?label=discord&amp;amp;logo=discord&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://octoprint.org/conduct/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg?sanitize=true&#34; alt=&#34;Contributor Covenant&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/psf/black&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true&#34; alt=&#34;Code style: black&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/prettier/prettier&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square&#34; alt=&#34;Code style: prettier&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pycqa.github.io/isort/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%20imports-isort-%231674b1&#34; alt=&#34;Imports: isort&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pre-commit/pre-commit&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&amp;amp;logoColor=white&#34; alt=&#34;pre-commit&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;OctoPrint provides a snappy web interface for controlling consumer 3D printers. It is Free Software and released under the &lt;a href=&#34;https://www.gnu.org/licenses/agpl-3.0.html&#34;&gt;GNU Affero General Public License V3&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Its website can be found at &lt;a href=&#34;https://octoprint.org/?utm_source=github&amp;amp;utm_medium=readme&#34;&gt;octoprint.org&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The community forum is available at &lt;a href=&#34;https://community.octoprint.org/?utm_source=github&amp;amp;utm_medium=readme&#34;&gt;community.octoprint.org&lt;/a&gt;. It also serves as central knowledge base.&lt;/p&gt; &#xA;&lt;p&gt;An invite to the Discord server can be found at &lt;a href=&#34;https://discord.octoprint.org&#34;&gt;discord.octoprint.org&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The FAQ can be accessed by following &lt;a href=&#34;https://faq.octoprint.org/?utm_source=github&amp;amp;utm_medium=readme&#34;&gt;faq.octoprint.org&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The documentation is located at &lt;a href=&#34;https://docs.octoprint.org&#34;&gt;docs.octoprint.org&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The official plugin repository can be reached at &lt;a href=&#34;https://plugins.octoprint.org/?utm_source=github&amp;amp;utm_medium=readme&#34;&gt;plugins.octoprint.org&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;OctoPrint&#39;s development wouldn&#39;t be possible without the &lt;a href=&#34;https://octoprint.org/support-octoprint/?utm_source=github&amp;amp;utm_medium=readme&#34;&gt;financial support by its community&lt;/a&gt;. If you enjoy OctoPrint, please consider becoming a regular supporter!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://octoprint.org/assets/img/screenshot-readme.png&#34; alt=&#34;Screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;You are currently looking at the source code repository of OctoPrint. If you already installed it (e.g. by using the Raspberry Pi targeted distribution &lt;a href=&#34;https://github.com/guysoft/OctoPi&#34;&gt;OctoPi&lt;/a&gt;) and only want to find out how to use it, &lt;a href=&#34;https://docs.octoprint.org/&#34;&gt;the documentation&lt;/a&gt; might be of more interest for you. You might also want to subscribe to join &lt;a href=&#34;https://community.octoprint.org&#34;&gt;the community forum at community.octoprint.org&lt;/a&gt; where there are other active users who might be able to help you with any questions you might have.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions of all kinds are welcome, not only in the form of code but also with regards to the &lt;a href=&#34;https://docs.octoprint.org/&#34;&gt;official documentation&lt;/a&gt;, debugging help in the &lt;a href=&#34;https://github.com/OctoPrint/OctoPrint/issues&#34;&gt;bug tracker&lt;/a&gt;, support of other users on &lt;a href=&#34;https://community.octoprint.org&#34;&gt;the community forum at community.octoprint.org&lt;/a&gt; or &lt;a href=&#34;https://discord.octoprint.org&#34;&gt;the official discord at discord.octoprint.org&lt;/a&gt; and also &lt;a href=&#34;https://octoprint.org/support-octoprint/?utm_source=github&amp;amp;utm_medium=readme&#34;&gt;financially&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you think something is bad about OctoPrint or its documentation the way it is, please help in any way to make it better instead of just complaining about it -- this is an Open Source Project after all :)&lt;/p&gt; &#xA;&lt;p&gt;For information about how to go about submitting bug reports or pull requests, please see the project&#39;s &lt;a href=&#34;https://github.com/OctoPrint/OctoPrint/raw/master/CONTRIBUTING.md&#34;&gt;Contribution Guidelines&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Installation instructions for installing from source for different operating systems can be found &lt;a href=&#34;https://community.octoprint.org/tags/c/support/guides/15/setup&#34;&gt;on the forum&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you want to run OctoPrint on a Raspberry Pi, you really should take a look at &lt;a href=&#34;https://github.com/guysoft/OctoPi&#34;&gt;OctoPi&lt;/a&gt; which is a custom SD card image that includes OctoPrint plus dependencies.&lt;/p&gt; &#xA;&lt;p&gt;The generic steps that should basically be done regardless of operating system and runtime environment are the following (as &lt;em&gt;regular user&lt;/em&gt;, please keep your hands &lt;em&gt;off&lt;/em&gt; of the &lt;code&gt;sudo&lt;/code&gt; command here!) - this assumes you already have Python 3.7+, pip and virtualenv and their dependencies set up on your system:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create a user-owned virtual environment therein: &lt;code&gt;virtualenv venv&lt;/code&gt;. If you want to specify a specific python to use instead of whatever version your system defaults to, you can also explicitly require that via the &lt;code&gt;--python&lt;/code&gt; parameter, e.g. &lt;code&gt;virtualenv --python=python3 venv&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Install OctoPrint &lt;em&gt;into that virtual environment&lt;/em&gt;: &lt;code&gt;./venv/bin/pip install OctoPrint&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You may then start the OctoPrint server via &lt;code&gt;/path/to/OctoPrint/venv/bin/octoprint&lt;/code&gt;, see &lt;a href=&#34;https://raw.githubusercontent.com/OctoPrint/OctoPrint/master/#usage&#34;&gt;Usage&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;p&gt;After installation, please make sure you follow the first-run wizard and set up access control as necessary.&lt;/p&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;p&gt;OctoPrint depends on a few python modules to do its job. Those are automatically installed when installing OctoPrint via &lt;code&gt;pip&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;OctoPrint currently supports Python 3.7, 3.8, 3.9 and 3.10.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Running the pip install via&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install OctoPrint&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;installs the &lt;code&gt;octoprint&lt;/code&gt; script in your Python installation&#39;s scripts folder (which, depending on whether you installed OctoPrint globally or into a virtual env, will be in your &lt;code&gt;PATH&lt;/code&gt; or not). The following usage examples assume that the &lt;code&gt;octoprint&lt;/code&gt; script is on your &lt;code&gt;PATH&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can start the server via&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;octoprint serve&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default it binds to all interfaces on port 5000 (so pointing your browser to &lt;code&gt;http://127.0.0.1:5000&lt;/code&gt; will do the trick). If you want to change that, use the additional command line parameters &lt;code&gt;host&lt;/code&gt; and &lt;code&gt;port&lt;/code&gt;, which accept the host ip to bind to and the numeric port number respectively. If for example you want the server to only listen on the local interface on port 8080, the command line would be&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;octoprint serve --host=127.0.0.1 --port=8080&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, the host and port on which to bind can be defined via the config file.&lt;/p&gt; &#xA;&lt;p&gt;If you want to run OctoPrint as a daemon (only supported on Linux), use&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;octoprint daemon {start|stop|restart} [--pid PIDFILE]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you do not supply a custom pidfile location via &lt;code&gt;--pid PIDFILE&lt;/code&gt;, it will be created at &lt;code&gt;/tmp/octoprint.pid&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can also specify the config file or the base directory (for basing off the &lt;code&gt;uploads&lt;/code&gt;, &lt;code&gt;timelapse&lt;/code&gt; and &lt;code&gt;logs&lt;/code&gt; folders), e.g.:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;octoprint serve --config /path/to/another/config.yaml --basedir /path/to/my/basedir&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To start OctoPrint in safe mode - which disables all third party plugins that do not come bundled with OctoPrint - use the &lt;code&gt;--safe&lt;/code&gt; flag:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;octoprint serve --safe&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;code&gt;octoprint --help&lt;/code&gt; for more information on the available command line parameters.&lt;/p&gt; &#xA;&lt;p&gt;OctoPrint also ships with a &lt;code&gt;run&lt;/code&gt; script in its source directory. You can invoke it to start the server. It takes the same command line arguments as the &lt;code&gt;octoprint&lt;/code&gt; script.&lt;/p&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;If not specified via the command line, the config file &lt;code&gt;config.yaml&lt;/code&gt; for OctoPrint is expected in the settings folder, which is located at &lt;code&gt;~/.octoprint&lt;/code&gt; on Linux, at &lt;code&gt;%APPDATA%/OctoPrint&lt;/code&gt; on Windows and at &lt;code&gt;~/Library/Application Support/OctoPrint&lt;/code&gt; on MacOS.&lt;/p&gt; &#xA;&lt;p&gt;A comprehensive overview of all available configuration settings can be found &lt;a href=&#34;https://docs.octoprint.org/en/master/configuration/config_yaml.html&#34;&gt;in the docs&lt;/a&gt;. Please note that the most commonly used configuration settings can also easily be edited from OctoPrint&#39;s settings dialog.&lt;/p&gt; &#xA;&lt;h2&gt;Special Thanks&lt;/h2&gt; &#xA;&lt;p&gt;Cross-browser testing services are kindly provided by &lt;a href=&#34;https://www.browserstack.com/&#34;&gt;BrowserStack&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Profiling is done with the help of &lt;a href=&#34;https://www.pyvmmonitor.com&#34;&gt;PyVmMonitor&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Error tracking is powered and sponsored by &lt;a href=&#34;https://sentry.io&#34;&gt;Sentry&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>JonasGeiping/cramming</title>
    <updated>2023-01-03T01:37:37Z</updated>
    <id>tag:github.com,2023-01-03:/JonasGeiping/cramming</id>
    <link href="https://github.com/JonasGeiping/cramming" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Cramming the training of a (BERT-type) language model into limited compute.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Cramming Language Model (Pretraining)&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains code to replicate our research described in &#34;Cramming: Training a Language Model on a Single GPU in One Day&#34;. We experiment with language model pretraining a BERT-type model with limited compute, wondering &#34;how bad can it really be&#34;?&lt;/p&gt; &#xA;&lt;p&gt;You can find our paper here: &lt;a href=&#34;https://arxiv.org/abs/2212.14034&#34;&gt;https://arxiv.org/abs/2212.14034&lt;/a&gt;, and the abstract below:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Recent trends in language modeling have focused on increasing performance through scaling, and have resulted in an environment where training language models is out of reach for most researchers and practitioners. While most in the community are asking how to push the limits of extreme computation, we ask the opposite question:&lt;br&gt; How far can we get with a single GPU in just one day?&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;We investigate the downstream performance achievable with a transformer-based language model trained completely from scratch with masked language modeling for a &lt;em&gt;single&lt;/em&gt; day on a &lt;em&gt;single consumer&lt;/em&gt; GPU. Aside from re-analyzing nearly all components of the pretraining pipeline for this scenario and providing a modified pipeline with performance close to BERT, we investigate why scaling down is hard, and which modifications actually improve performance in this scenario. We provide evidence that even in this constrained setting, performance closely follows scaling laws observed in large-compute settings. Through the lens of scaling laws, we categorize a range of recent improvements to training and architecture and discuss their merit and practical applicability (or lack thereof) for the limited compute setting.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;The Rules for Cramming&lt;/h2&gt; &#xA;&lt;p&gt;Setting:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A transformer-based language model of arbitrary size is trained with masked-language modeling, completely from scratch.&lt;/li&gt; &#xA; &lt;li&gt;Existing pretrained models cannot be included in any part of the pipeline.&lt;/li&gt; &#xA; &lt;li&gt;Any raw text (excluding downstream data) can be included for training. This means that one can achieve speedups by making judicious choices about how and when to sample data, provided the sampling mechanism does not require a pre-trained model.&lt;/li&gt; &#xA; &lt;li&gt;The downloading and pre-processing of raw data is exempted from the total compute budget. Pre-processing may include CPU-based tokenizer construction, tokenization, and filtering, but cannot include representation learning (e.g. pre-training a word embedding is not allowed, unless it is counted towards the final runtime).&lt;/li&gt; &#xA; &lt;li&gt;Training proceeds on a single GPU for 24 hours.&lt;/li&gt; &#xA; &lt;li&gt;Downstream performance is evaluated on GLUE (&lt;a href=&#34;https://gluebenchmark.com/&#34;&gt;https://gluebenchmark.com/&lt;/a&gt;). Downstream finetuning on GLUE is limited to brief training with only the training data of the downstream task (we consider 5 epochs or less) and needs to work with hyperparameters set globally for all GLUE tasks. Downstream finetuning is excluded from the total compute budget.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;How to run the code&lt;/h1&gt; &#xA;&lt;h2&gt;Requirements:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;PyTorch: &lt;code&gt;torch&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;huggingface: &lt;code&gt;transformers&lt;/code&gt;, &lt;code&gt;tokenizers&lt;/code&gt;, &lt;code&gt;datasets&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;hydra-core&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;[OPTIONAL]&lt;code&gt;deepspeed&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;[OPTIONAL] &lt;code&gt;flash-attention&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;psutil&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;einops&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;[OPTIONAL] For The-Pile data, install &lt;code&gt;zstandard&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Just clone for now, and install packages as described&lt;/li&gt; &#xA; &lt;li&gt;[Optional] Follow the instructions at &lt;a href=&#34;https://pre-commit.com/&#34;&gt;https://pre-commit.com/&lt;/a&gt; to install the pre-commit hooks.&lt;/li&gt; &#xA; &lt;li&gt;[Optional] For deduplication, first install rust &lt;code&gt;curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh &lt;/code&gt;, then &lt;code&gt;git clone https://github.com/google-research/deduplicate-text-datasets/tree/dev-v1&lt;/code&gt; and then run &lt;code&gt;cargo install --target-dir ../cramming/dedup&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;[Optional] For FlashAttention, install package as instructed at &lt;a href=&#34;https://github.com/HazyResearch/flash-attention&#34;&gt;https://github.com/HazyResearch/flash-attention&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;General Usage&lt;/h2&gt; &#xA;&lt;p&gt;Use the &lt;code&gt;pretrain.py&lt;/code&gt; script to pretrain with limited compute. This repository uses hydra (&lt;a href=&#34;https://hydra.cc/docs/intro/&#34;&gt;https://hydra.cc/docs/intro/&lt;/a&gt;), so all fields in &lt;code&gt;cramming/config&lt;/code&gt; can be modified on the command line. For example, the &lt;code&gt;budget&lt;/code&gt; can be modified by providing &lt;code&gt;budget=48&lt;/code&gt; as additional argument, or the learning rate can be modified via &lt;code&gt;train.optim.lr=1e-4&lt;/code&gt;. Check out the configuration folder to see all arguments.&lt;/p&gt; &#xA;&lt;p&gt;Your first step should be to verify the installed packages. To do so, you can run &lt;code&gt;python pretrain.py dryrun=True&lt;/code&gt;, which will run the default sanity check for a single iteration. From there, you can enable additional functionality. For example, modify the architecture, e.g. &lt;code&gt;arch=bert-original&lt;/code&gt; and training setup &lt;code&gt;train=bert-original&lt;/code&gt;. To really train a language model, you need to switch away from the sanity check dataset to at least &lt;code&gt;data=bookcorpus-wikipedia&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Data Handling&lt;/h3&gt; &#xA;&lt;p&gt;The data sources from &lt;code&gt;data.sources&lt;/code&gt; will be read, normalized and pretokenized before training starts and cached into a database. Subsequent calls with the same configuration will reused this database of tokenized sequences. By default, a new tokenizer will also be constructed and saved during this process. Important data options are &lt;code&gt;data.max_entries_in_raw_dataset&lt;/code&gt;, which defines how much &lt;em&gt;raw&lt;/em&gt; data will be loaded. For example, for a large data source such as C4, only a subset of raw data will be downloaded. Then, &lt;code&gt;max_seq_in_tokenized_dataset&lt;/code&gt; bottlenecks how many &lt;em&gt;processed&lt;/em&gt; sequences will be stored in the database. This number should be larger than the number of sequences expected to be read within the budget.&lt;/p&gt; &#xA;&lt;p&gt;Additional Notes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A simple trick to run dataset preprocessing only is to run &lt;code&gt;python pretrain.py data=... dryrun=True&lt;/code&gt;, which dry-runs the training, but runs the full data preprocessing. Later runs can then re-use the cached data.&lt;/li&gt; &#xA; &lt;li&gt;Dataset preprocessing is heavily parallelized. This might be a problem for your RAM. If this happens, reduce &lt;code&gt;impl.threads&lt;/code&gt;. Especially the deduplication code does require substantial amounts of RAM.&lt;/li&gt; &#xA; &lt;li&gt;I would run first experiments with &lt;code&gt;bookcorpus-wikipedia&lt;/code&gt; only, which preprocesses comparatively quickly and only then look into the full processed and filtered C4.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Evaluation&lt;/h3&gt; &#xA;&lt;p&gt;To evaluate pretrained models on GLUE (or some GLUE tasks), use &lt;code&gt;eval.py&lt;/code&gt;. This script searches for saved models in the base directory. Given the name of a previous run, this script will, by default, retrieve the latest checkpoint saved with this name, and then run evaluations.&lt;/p&gt; &#xA;&lt;h3&gt;WandB&lt;/h3&gt; &#xA;&lt;p&gt;You can log runs to your weights&amp;amp;biases account. To do so, simply modify &lt;code&gt;wandb.entity&lt;/code&gt; and &lt;code&gt;wandb.project&lt;/code&gt; on the command line or at &lt;code&gt;cramming/config/wandb/default.yaml&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Replicate the final recipe&lt;/h2&gt; &#xA;&lt;p&gt;To replicate the final recipe discussed in the paper, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python pretrain.py name=amp_b4096_c5_o3_final arch=bert-c5 train=bert-o3 train.batch_size=4096 data=c4-subset-processed&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to pretrain and&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python eval.py eval=GLUE_sane name=amp_b4096_c5_o3_final eval.checkpoint=latest impl.microbatch_size=16 impl.shuffle_in_dataloader=True&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to evaluate the model. The recipe called &#34;crammed BERT&#34; in the paper corresponds to the architecture called &lt;code&gt;bert-c5&lt;/code&gt; trained with training setup &lt;code&gt;bert-o3&lt;/code&gt; on data &lt;code&gt;c4-subset-processed&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Additional Recipes&lt;/h2&gt; &#xA;&lt;p&gt;Pretraining: Single GPU:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python pretrain.py name=bert data=bookcorpus-wikipedia arch=bert-original train=bert-original&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Multi-GPU:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;torchrun --nproc_per_node=4 --standalone pretrain.py name=bert4gpu  data=bookcorpus-wikipedia arch=bert-original train=bert-original&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Eval a huggingface checkpoint:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python eval.py dryrun=True eval=rte name=bert-finetuning eval.checkpoint=hf://bert-base-uncased&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Sanity check for distributed code on CPU:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;torchrun --nproc_per_node=4 --standalone  pretrain.py name=speedtest1 dryrun=True data=sanity-check-2  impl.backend=gloo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Additional examples for recipes can be found in the &lt;code&gt;/scripts&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;h1&gt;Todos:&lt;/h1&gt; &#xA;&lt;p&gt;The following options are currently broken/limited/work-in-progress. Use these at your own discretion, or open a pull-request with a fix.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The-Pile needs to be downloaded in its entirety to be used, but the code could be updated to stream, just like C4.&lt;/li&gt; &#xA; &lt;li&gt;Data Preprocessing is wasteful in terms of RAM.&lt;/li&gt; &#xA; &lt;li&gt;Token Dropping is simplistic, a more involved version could be better.&lt;/li&gt; &#xA; &lt;li&gt;Code currently uses the &#34;old&#34; &lt;code&gt;jit.script&lt;/code&gt; fusion, should move toward new &lt;code&gt;torch.compile&lt;/code&gt; implementation at some point. The current &lt;code&gt;inductor&lt;/code&gt; hook is also non-functional.&lt;/li&gt; &#xA; &lt;li&gt;Shampoo (see discussion at &lt;a href=&#34;https://twitter.com/_arohan_/status/1608577721818546176?s=20&#34;&gt;https://twitter.com/_arohan_/status/1608577721818546176?s=20&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Causal Attention [I broke this shortly before release, if you want to re-test CA, you&#39;d have to fix it first]&lt;/li&gt; &#xA; &lt;li&gt;LAWA&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Contact&lt;/h1&gt; &#xA;&lt;p&gt;Please, feel free to contact us with any questions, or open an issue on Github.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ashemery/exploitation-course</title>
    <updated>2023-01-03T01:37:37Z</updated>
    <id>tag:github.com,2023-01-03:/ashemery/exploitation-course</id>
    <link href="https://github.com/ashemery/exploitation-course" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Offensive Software Exploitation Course&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Offensive Software Exploitation (OSE) Course&lt;/h1&gt; &#xA;&lt;p&gt;This repository is for the Offensive Software Exploitation Course I am teaching at Champlain College and currently doing it for free online (check the YouTube channel for the recordings). Most of the slidenotes I used, are already shared on &lt;a href=&#34;http://opensecuritytraining.info/HTID.html&#34;&gt;HTID Course&lt;/a&gt;, but the labs were fully created by myself. I used publically available resources and software to explain each of the weakneses covered, so there is nothing here that you cannot find online.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;OFFENSIVE SECURITY &amp;amp; REVERSE ENGINEERING (FULL COURSE)&lt;/h3&gt; &#xA;&lt;p&gt;This is the whole course that was covered at Champlain College during Spring 20/21, yes during the COVID-19 pandemic! Unfortunately I was not able to cover all the modules due to time limitation, but other than that I had a great semester with my students and enjoyed teaching this course to them. Big thank you to each one of them, who all graduated now. The course could be found here &lt;a href=&#34;https://github.com/ashemery/exploitation-course/tree/master/course/2021&#34;&gt;OSRE&lt;/a&gt;. The videos on my YouTube channel walk through most of them.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Vulnerable Software&lt;/h3&gt; &#xA;&lt;p&gt;The vulnerable software I used are also online and can be found at &lt;a href=&#34;https://www.exploit-db.com/&#34;&gt;Exploit-db&lt;/a&gt;. I also used Stephen Bradshaw&#39;s &lt;a href=&#34;https://github.com/stephenbradshaw/vulnserver&#34;&gt;VulnServer&lt;/a&gt;, plus maybe some other simple code that I prepared. Please check each lab for the software used in that specific lab and from where to download it.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Tool(s) Required&lt;/h3&gt; &#xA;&lt;p&gt;All of the tools used are free and could be downloaded from the URLs below.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Immunity Debugger: &lt;a href=&#34;https://www.immunityinc.com/products/debugger/&#34;&gt;download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Kali Linux: &lt;a href=&#34;https://www.kali.org/&#34;&gt;download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CFF Explorer: &lt;a href=&#34;https://ntcore.com/?page_id=388&#34;&gt;download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;PE-bear: &lt;a href=&#34;https://github.com/hasherezade/pe-bear-releases&#34;&gt;download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Ghidra: &lt;a href=&#34;https://ghidra-sre.org/&#34;&gt;download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;IDA Pro: &lt;a href=&#34;https://www.hex-rays.com/products/ida/&#34;&gt;download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;x64dbg: &lt;a href=&#34;https://x64dbg.com/#start&#34;&gt;download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Microsoft SysInternals Suite: &lt;a href=&#34;https://docs.microsoft.com/en-us/sysinternals/&#34;&gt;download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CAPA by FireEye FLARE Team: &lt;a href=&#34;https://github.com/fireeye/capa&#34;&gt;download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;NetCat: &lt;a href=&#34;https://joncraton.org/blog/46/netcat-for-windows/&#34;&gt;download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Others!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Target(s) Used&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download a Windows 10 VM from Microsoft VMs (currently using Version 1809 Build 17763.1339) &lt;a href=&#34;https://developer.microsoft.com/en-us/microsoft-edge/tools/vms/&#34;&gt;here&lt;/a&gt;. This will be used for most of the labs, except for the EggHunter lab, I used a Windows 7 VM, also from Microsoft VMs (currently offline so check archive.org).&lt;/li&gt; &#xA; &lt;li&gt;All the targeted software is Intel/AMD 32-bit unless otherwise instructed.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Table of Contents:&lt;/h3&gt; &#xA;&lt;p&gt;The topics that will be covered in this course are:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The Basics (PE Format, DLLs, etc)&lt;/li&gt; &#xA; &lt;li&gt;Bug Hunting and Fuzzing&lt;/li&gt; &#xA; &lt;li&gt;Intro. to Memory Corruption and Buffer Overflows&lt;/li&gt; &#xA; &lt;li&gt;Metasploit&lt;/li&gt; &#xA; &lt;li&gt;Mitigation Techniques&lt;/li&gt; &#xA; &lt;li&gt;SEH and Jumping Strategies&lt;/li&gt; &#xA; &lt;li&gt;Egghunter&lt;/li&gt; &#xA; &lt;li&gt;Retrurn Oriented Programming (ROP)&lt;/li&gt; &#xA; &lt;li&gt;Post Exploitation&lt;/li&gt; &#xA; &lt;li&gt;Manual Code Injection&lt;/li&gt; &#xA; &lt;li&gt;Intro. to Assembly x86 and x64 (please check update #3 for this part)&lt;/li&gt; &#xA; &lt;li&gt;Reverse Engineering (please check update #3 for this part)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Video Recordings:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Arabic version: &lt;a href=&#34;https://www.youtube.com/playlist?list=PLCS2zI95IiNyo5AhbVIL2hVX7zhuSkOkz&#34;&gt;Playlist&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;English version: &lt;a href=&#34;https://www.youtube.com/playlist?list=PLCS2zI95IiNybAAQ0HL88YzwRpLXje5y6&#34;&gt;Playlist&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Useful Resources:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The number one resource is the Corelan Team&#39;s blog, &lt;a href=&#34;https://www.corelan.be/&#34;&gt;Corelan Team&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Introductory Intel x86, &lt;a href=&#34;https://opensecuritytraining.info/IntroX86.html&#34;&gt;OpenSecurityTraining&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Update(s):&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[1] &lt;del&gt;On Aug. 6th, 2020 both &lt;a href=&#34;https://www.elearnsecurity.com/&#34;&gt;eLearnSecurity&lt;/a&gt; and &lt;a href=&#34;https://www.ine.com/&#34;&gt;INE&lt;/a&gt; decided to sponsor the English version of the course and therefore will be recording an English version too.&lt;/del&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2] Nov. 10th, 2020: will sponsor it myself, since I left working for eLearnSecurity.&lt;/li&gt; &#xA; &lt;li&gt;[3] Nov. 30th, 2020: this course will be taught next semester (Spring 2021) at Champlain College, with a slight difference, the Reverse Engineering section.&lt;/li&gt; &#xA; &lt;li&gt;[4] Jul. 1st, 2021: publishing the whole course that was covered at Champlain College during Spring 20/21, yes during the COVID-19 pandemic!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Credits:&lt;/h3&gt; &#xA;&lt;p&gt;Thanks to everyone who shared their work online, without them this course would not have happened!&lt;/p&gt;</summary>
  </entry>
</feed>