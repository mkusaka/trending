<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-10-30T01:34:14Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>reflex-dev/reflex</title>
    <updated>2023-10-30T01:34:14Z</updated>
    <id>tag:github.com,2023-10-30:/reflex-dev/reflex</id>
    <link href="https://github.com/reflex-dev/reflex" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ğŸ•¸ Web apps in pure Python ğŸ&lt;/p&gt;&lt;hr&gt;&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;+ Searching for Pynecone? You are in the right repo. Pynecone has been renamed to Reflex. +&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/reflex_dark.svg#gh-light-mode-only&#34; alt=&#34;Reflex Logo&#34; width=&#34;300px&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/reflex_light.svg#gh-dark-mode-only&#34; alt=&#34;Reflex Logo&#34; width=&#34;300px&#34;&gt; &#xA; &lt;hr&gt; &#xA; &lt;h3&gt;&lt;strong&gt;âœ¨ Performant, customizable web apps in pure Python. Deploy in seconds. âœ¨&lt;/strong&gt;&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://badge.fury.io/py/reflex&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/reflex.svg?sanitize=true&#34; alt=&#34;PyPI version&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://github.com/pynecone-io/pynecone/actions/workflows/integration.yml/badge.svg?sanitize=true&#34; alt=&#34;tests&#34;&gt; &lt;img src=&#34;https://img.shields.io/pypi/pyversions/reflex.svg?sanitize=true&#34; alt=&#34;versions&#34;&gt; &lt;a href=&#34;https://reflex.dev/docs/getting-started/introduction&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Documentation%20-Introduction%20-%20%23007ec6&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/T5WSbC2YtQ&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1029853095527727165?color=%237289da&amp;amp;label=Discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/reflex-dev/reflex/raw/main/README.md&#34;&gt;English&lt;/a&gt; | &lt;a href=&#34;https://github.com/reflex-dev/reflex/raw/main/docs/zh/zh_cn/README.md&#34;&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; | &lt;a href=&#34;https://github.com/reflex-dev/reflex/raw/main/docs/zh/zh_tw/README.md&#34;&gt;ç¹é«”ä¸­æ–‡&lt;/a&gt; | &lt;a href=&#34;https://github.com/reflex-dev/reflex/raw/main/docs/tr/README.md&#34;&gt;TÃ¼rkÃ§e&lt;/a&gt; | &lt;a href=&#34;https://github.com/reflex-dev/reflex/raw/main/docs/in/README.md&#34;&gt;à¤¹à¤¿à¤‚à¤¦à¥€&lt;/a&gt; | &lt;a href=&#34;https://github.com/reflex-dev/reflex/raw/main/docs/pt/pt_br/README.md&#34;&gt;PortuguÃªs (Brasil)&lt;/a&gt; | &lt;a href=&#34;https://github.com/reflex-dev/reflex/raw/main/docs/it/README.md&#34;&gt;Italiano&lt;/a&gt; | &lt;a href=&#34;https://github.com/reflex-dev/reflex/raw/main/docs/kr/README.md&#34;&gt;í•œêµ­ì–´&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h2&gt;âš™ï¸ Installation&lt;/h2&gt; &#xA;&lt;p&gt;Open a terminal and run (Requires Python 3.8+):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install reflex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ğŸ¥³ Create your first app&lt;/h2&gt; &#xA;&lt;p&gt;Installing &lt;code&gt;reflex&lt;/code&gt; also installs the &lt;code&gt;reflex&lt;/code&gt; command line tool.&lt;/p&gt; &#xA;&lt;p&gt;Test that the install was successful by creating a new project. (Replace &lt;code&gt;my_app_name&lt;/code&gt; with your project name):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir my_app_name&#xA;cd my_app_name&#xA;reflex init&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command initializes a template app in your new directory.&lt;/p&gt; &#xA;&lt;p&gt;You can run this app in development mode:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;reflex run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You should see your app running at &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Now you can modify the source code in &lt;code&gt;my_app_name/my_app_name.py&lt;/code&gt;. Reflex has fast refreshes so you can see your changes instantly when you save your code.&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ«§ Example App&lt;/h2&gt; &#xA;&lt;p&gt;Let&#39;s go over an example: creating an image generation UI around DALLÂ·E. For simplicity, we just call the OpenAI API, but you could replace this with an ML model run locally.&lt;/p&gt; &#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/dalle.gif&#34; alt=&#34;A frontend wrapper for DALLÂ·E, shown in the process of generating an image.&#34; width=&#34;550&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt; &#xA;&lt;p&gt;Here is the complete code to create this. This is all done in one Python file!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import reflex as rx&#xA;import openai&#xA;&#xA;openai.api_key = &#34;YOUR_API_KEY&#34;&#xA;&#xA;class State(rx.State):&#xA;    &#34;&#34;&#34;The app state.&#34;&#34;&#34;&#xA;    prompt = &#34;&#34;&#xA;    image_url = &#34;&#34;&#xA;    processing = False&#xA;    complete = False&#xA;&#xA;    def get_image(self):&#xA;        &#34;&#34;&#34;Get the image from the prompt.&#34;&#34;&#34;&#xA;        if self.prompt == &#34;&#34;:&#xA;            return rx.window_alert(&#34;Prompt Empty&#34;)&#xA;&#xA;        self.processing, self.complete = True, False&#xA;        yield&#xA;        response = openai.Image.create(prompt=self.prompt, n=1, size=&#34;1024x1024&#34;)&#xA;        self.image_url = response[&#34;data&#34;][0][&#34;url&#34;]&#xA;        self.processing, self.complete = False, True&#xA;        &#xA;&#xA;def index():&#xA;    return rx.center(&#xA;        rx.vstack(&#xA;            rx.heading(&#34;DALLÂ·E&#34;),&#xA;            rx.input(placeholder=&#34;Enter a prompt&#34;, on_blur=State.set_prompt),&#xA;            rx.button(&#xA;                &#34;Generate Image&#34;,&#xA;                on_click=State.get_image,&#xA;                is_loading=State.processing,&#xA;                width=&#34;100%&#34;,&#xA;            ),&#xA;            rx.cond(&#xA;                State.complete,&#xA;                     rx.image(&#xA;                         src=State.image_url,&#xA;                         height=&#34;25em&#34;,&#xA;                         width=&#34;25em&#34;,&#xA;                    )&#xA;            ),&#xA;            padding=&#34;2em&#34;,&#xA;            shadow=&#34;lg&#34;,&#xA;            border_radius=&#34;lg&#34;,&#xA;        ),&#xA;        width=&#34;100%&#34;,&#xA;        height=&#34;100vh&#34;,&#xA;    )&#xA;&#xA;# Add state and page to the app.&#xA;app = rx.App()&#xA;app.add_page(index, title=&#34;reflex:DALLÂ·E&#34;)&#xA;app.compile()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Let&#39;s break this down.&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Reflex UI&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Let&#39;s start with the UI.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def index():&#xA;    return rx.center(&#xA;        ...&#xA;    )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This &lt;code&gt;index&lt;/code&gt; function defines the frontend of the app.&lt;/p&gt; &#xA;&lt;p&gt;We use different components such as &lt;code&gt;center&lt;/code&gt;, &lt;code&gt;vstack&lt;/code&gt;, &lt;code&gt;input&lt;/code&gt;, and &lt;code&gt;button&lt;/code&gt; to build the frontend. Components can be nested within each other to create complex layouts. And you can use keyword args to style them with the full power of CSS.&lt;/p&gt; &#xA;&lt;p&gt;Reflex comes with &lt;a href=&#34;https://reflex.dev/docs/library&#34;&gt;60+ built-in components&lt;/a&gt; to help you get started. We are actively adding more components, and it&#39;s easy to &lt;a href=&#34;https://reflex.dev/docs/advanced-guide/wrapping-react&#34;&gt;create your own components&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;State&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Reflex represents your UI as a function of your state.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class State(rx.State):&#xA;    &#34;&#34;&#34;The app state.&#34;&#34;&#34;&#xA;    prompt = &#34;&#34;&#xA;    image_url = &#34;&#34;&#xA;    processing = False&#xA;    complete = False&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The state defines all the variables (called vars) in an app that can change and the functions that change them.&lt;/p&gt; &#xA;&lt;p&gt;Here the state is comprised of a &lt;code&gt;prompt&lt;/code&gt; and &lt;code&gt;image_url&lt;/code&gt;. There are also the booleans &lt;code&gt;processing&lt;/code&gt; and &lt;code&gt;complete&lt;/code&gt; to indicate when to show the circular progress and image.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Event Handlers&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def get_image(self):&#xA;    &#34;&#34;&#34;Get the image from the prompt.&#34;&#34;&#34;&#xA;    if self.prompt == &#34;&#34;:&#xA;        return rx.window_alert(&#34;Prompt Empty&#34;)&#xA;&#xA;    self.processing, self.complete = True, False&#xA;    yield&#xA;    response = openai.Image.create(prompt=self.prompt, n=1, size=&#34;1024x1024&#34;)&#xA;    self.image_url = response[&#34;data&#34;][0][&#34;url&#34;]&#xA;    self.processing, self.complete = False, True&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Within the state, we define functions called event handlers that change the state vars. Event handlers are the way that we can modify the state in Reflex. They can be called in response to user actions, such as clicking a button or typing in a text box. These actions are called events.&lt;/p&gt; &#xA;&lt;p&gt;Our DALLÂ·E. app has an event handler, &lt;code&gt;get_image&lt;/code&gt; to which get this image from the OpenAI API. Using &lt;code&gt;yield&lt;/code&gt; in the middle of an event handler will cause the UI to update. Otherwise the UI will update at the end of the event handler.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Routing&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Finally, we define our app.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;app = rx.App()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We add a page from the root of the app to the index component. We also add a title that will show up in the page preview/browser tab.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;app.add_page(index, title=&#34;DALL-E&#34;)&#xA;app.compile()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can create a multi-page app by adding more pages.&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“‘ Resources&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;ğŸ“‘ &lt;a href=&#34;https://reflex.dev/docs/getting-started/introduction&#34;&gt;Docs&lt;/a&gt; &amp;nbsp; | &amp;nbsp; ğŸ—ï¸ &lt;a href=&#34;https://reflex.dev/blog&#34;&gt;Blog&lt;/a&gt; &amp;nbsp; | &amp;nbsp; ğŸ“± &lt;a href=&#34;https://reflex.dev/docs/library&#34;&gt;Component Library&lt;/a&gt; &amp;nbsp; | &amp;nbsp; ğŸ–¼ï¸ &lt;a href=&#34;https://reflex.dev/docs/gallery&#34;&gt;Gallery&lt;/a&gt; &amp;nbsp; | &amp;nbsp; ğŸ›¸ &lt;a href=&#34;https://reflex.dev/docs/hosting/deploy&#34;&gt;Deployment&lt;/a&gt; &amp;nbsp;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;âœ… Status&lt;/h2&gt; &#xA;&lt;p&gt;Reflex launched in December 2022 with the name Pynecone.&lt;/p&gt; &#xA;&lt;p&gt;As of July 2023, we are in the &lt;strong&gt;Public Beta&lt;/strong&gt; stage.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;span&gt;âœ…&lt;/span&gt; &lt;strong&gt;Public Alpha&lt;/strong&gt;: Anyone can install and use Reflex. There may be issues, but we are working to resolve them actively.&lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;ğŸ”¶&lt;/span&gt; &lt;strong&gt;Public Beta&lt;/strong&gt;: Stable enough for non-enterprise use-cases.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Public Hosting Beta&lt;/strong&gt;: &lt;em&gt;Optionally&lt;/em&gt;, deploy and host your apps on Reflex!&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Public&lt;/strong&gt;: Reflex is production ready.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Reflex has new releases and features coming every week! Make sure to &lt;span&gt;â­&lt;/span&gt; star and &lt;span&gt;ğŸ‘€&lt;/span&gt; watch this repository to stay up to date.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions of any size! Below are some good ways to get started in the Reflex community.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Join Our Discord&lt;/strong&gt;: Our &lt;a href=&#34;https://discord.gg/T5WSbC2YtQ&#34;&gt;Discord&lt;/a&gt; is the best place to get help on your Reflex project and to discuss how you can contribute.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;GitHub Discussions&lt;/strong&gt;: A great way to talk about features you want added or things that are confusing/need clarification.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: These are an excellent way to report bugs. Additionally, you can try and solve an existing issue and submit a PR.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We are actively looking for contributors, no matter your skill level or experience.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Reflex is open-source and licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/reflex-dev/reflex/main/LICENSE&#34;&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>THUDM/ChatGLM3</title>
    <updated>2023-10-30T01:34:14Z</updated>
    <id>tag:github.com,2023-10-30:/THUDM/ChatGLM3</id>
    <link href="https://github.com/THUDM/ChatGLM3" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ChatGLM3 series: Open Bilingual Chat LLMs | å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGLM3&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; ğŸ¤— &lt;a href=&#34;https://huggingface.co/THUDM/chatglm3-6b&#34; target=&#34;_blank&#34;&gt;HF Repo&lt;/a&gt; â€¢ ğŸ¤– &lt;a href=&#34;https://modelscope.cn/models/ZhipuAI/chatglm3-6b&#34; target=&#34;_blank&#34;&gt;ModelScope&lt;/a&gt; â€¢ ğŸ¦ &lt;a href=&#34;https://twitter.com/thukeg&#34; target=&#34;_blank&#34;&gt;Twitter&lt;/a&gt; â€¢ ğŸ“ƒ &lt;a href=&#34;https://arxiv.org/abs/2103.10360&#34; target=&#34;_blank&#34;&gt;[GLM@ACL 22]&lt;/a&gt; &lt;a href=&#34;https://github.com/THUDM/GLM&#34; target=&#34;_blank&#34;&gt;[GitHub]&lt;/a&gt; â€¢ ğŸ“ƒ &lt;a href=&#34;https://arxiv.org/abs/2210.02414&#34; target=&#34;_blank&#34;&gt;[GLM-130B@ICLR 23]&lt;/a&gt; &lt;a href=&#34;https://github.com/THUDM/GLM-130B&#34; target=&#34;_blank&#34;&gt;[GitHub]&lt;/a&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ &lt;a href=&#34;https://join.slack.com/t/chatglm/shared_invite/zt-25ti5uohv-A_hs~am_D3Q8XPZMpj7wwQ&#34; target=&#34;_blank&#34;&gt;Slack&lt;/a&gt; å’Œ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM3/main/resources/WECHAT.md&#34; target=&#34;_blank&#34;&gt;WeChat&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; ğŸ“åœ¨ &lt;a href=&#34;https://www.chatglm.cn&#34;&gt;chatglm.cn&lt;/a&gt; ä½“éªŒæ›´å¤§è§„æ¨¡çš„ ChatGLM æ¨¡å‹ã€‚ &lt;/p&gt; &#xA;&lt;h2&gt;ä»‹ç»&lt;/h2&gt; &#xA;&lt;p&gt;ChatGLM3 æ˜¯æ™ºè°±AIå’Œæ¸…åå¤§å­¦ KEG å®éªŒå®¤è”åˆå‘å¸ƒçš„æ–°ä¸€ä»£å¯¹è¯é¢„è®­ç»ƒæ¨¡å‹ã€‚ChatGLM3-6B æ˜¯ ChatGLM3 ç³»åˆ—ä¸­çš„å¼€æºæ¨¡å‹ï¼Œåœ¨ä¿ç•™äº†å‰ä¸¤ä»£æ¨¡å‹å¯¹è¯æµç•…ã€éƒ¨ç½²é—¨æ§›ä½ç­‰ä¼—å¤šä¼˜ç§€ç‰¹æ€§çš„åŸºç¡€ä¸Šï¼ŒChatGLM3-6B å¼•å…¥äº†å¦‚ä¸‹ç‰¹æ€§ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;æ›´å¼ºå¤§çš„åŸºç¡€æ¨¡å‹ï¼š&lt;/strong&gt; ChatGLM3-6B çš„åŸºç¡€æ¨¡å‹ ChatGLM3-6B-Base é‡‡ç”¨äº†æ›´å¤šæ ·çš„è®­ç»ƒæ•°æ®ã€æ›´å……åˆ†çš„è®­ç»ƒæ­¥æ•°å’Œæ›´åˆç†çš„è®­ç»ƒç­–ç•¥ã€‚åœ¨è¯­ä¹‰ã€æ•°å­¦ã€æ¨ç†ã€ä»£ç ã€çŸ¥è¯†ç­‰ä¸åŒè§’åº¦çš„æ•°æ®é›†ä¸Šæµ‹è¯„æ˜¾ç¤ºï¼Œ&lt;strong&gt;ChatGLM3-6B-Base å…·æœ‰åœ¨ 10B ä»¥ä¸‹çš„åŸºç¡€æ¨¡å‹ä¸­æœ€å¼ºçš„æ€§èƒ½&lt;/strong&gt;ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;æ›´å®Œæ•´çš„åŠŸèƒ½æ”¯æŒï¼š&lt;/strong&gt; ChatGLM3-6B é‡‡ç”¨äº†å…¨æ–°è®¾è®¡çš„ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM3/main/PROMPT.md&#34;&gt;Prompt æ ¼å¼&lt;/a&gt;ï¼Œé™¤æ­£å¸¸çš„å¤šè½®å¯¹è¯å¤–ã€‚åŒæ—¶åŸç”Ÿæ”¯æŒ&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM3/main/tool_using/README.md&#34;&gt;å·¥å…·è°ƒç”¨&lt;/a&gt;ï¼ˆFunction Callï¼‰ã€ä»£ç æ‰§è¡Œï¼ˆCode Interpreterï¼‰å’Œ Agent ä»»åŠ¡ç­‰å¤æ‚åœºæ™¯ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;æ›´å…¨é¢çš„å¼€æºåºåˆ—ï¼š&lt;/strong&gt; é™¤äº†å¯¹è¯æ¨¡å‹ &lt;a href=&#34;https://huggingface.co/THUDM/chatglm3-6b&#34;&gt;ChatGLM3-6B&lt;/a&gt; å¤–ï¼Œè¿˜å¼€æºäº†åŸºç¡€æ¨¡å‹ &lt;a href=&#34;https://huggingface.co/THUDM/chatglm3-6b-base&#34;&gt;ChatGLM3-6B-Base&lt;/a&gt;ã€é•¿æ–‡æœ¬å¯¹è¯æ¨¡å‹ &lt;a href=&#34;https://huggingface.co/THUDM/chatglm3-6b-32k&#34;&gt;ChatGLM3-6B-32K&lt;/a&gt;ã€‚ä»¥ä¸Šæ‰€æœ‰æƒé‡å¯¹å­¦æœ¯ç ”ç©¶&lt;strong&gt;å®Œå…¨å¼€æ”¾&lt;/strong&gt;ï¼Œåœ¨å¡«å†™&lt;a href=&#34;https://open.bigmodel.cn/mla/form&#34;&gt;é—®å·&lt;/a&gt;è¿›è¡Œç™»è®°å&lt;strong&gt;äº¦å…è®¸å…è´¹å•†ä¸šä½¿ç”¨&lt;/strong&gt;ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;ChatGLM3 å¼€æºæ¨¡å‹æ—¨åœ¨ä¸å¼€æºç¤¾åŒºä¸€èµ·æ¨åŠ¨å¤§æ¨¡å‹æŠ€æœ¯å‘å±•ï¼Œæ³è¯·å¼€å‘è€…å’Œå¤§å®¶éµå®ˆ&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM3/main/MODEL_LICENSE&#34;&gt;å¼€æºåè®®&lt;/a&gt;ï¼Œå‹¿å°†å¼€æºæ¨¡å‹å’Œä»£ç åŠåŸºäºå¼€æºé¡¹ç›®äº§ç”Ÿçš„è¡ç”Ÿç‰©ç”¨äºä»»ä½•å¯èƒ½ç»™å›½å®¶å’Œç¤¾ä¼šå¸¦æ¥å±å®³çš„ç”¨é€”ä»¥åŠç”¨äºä»»ä½•æœªç»è¿‡å®‰å…¨è¯„ä¼°å’Œå¤‡æ¡ˆçš„æœåŠ¡ã€‚ç›®å‰ï¼Œæœ¬é¡¹ç›®å›¢é˜ŸæœªåŸºäº &lt;strong&gt;ChatGLM3 å¼€æºæ¨¡å‹&lt;/strong&gt;å¼€å‘ä»»ä½•åº”ç”¨ï¼ŒåŒ…æ‹¬ç½‘é¡µç«¯ã€å®‰å“ã€è‹¹æœ iOS åŠ Windows App ç­‰åº”ç”¨ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å°½ç®¡æ¨¡å‹åœ¨è®­ç»ƒçš„å„ä¸ªé˜¶æ®µéƒ½å°½åŠ›ç¡®ä¿æ•°æ®çš„åˆè§„æ€§å’Œå‡†ç¡®æ€§ï¼Œä½†ç”±äº ChatGLM3-6B æ¨¡å‹è§„æ¨¡è¾ƒå°ï¼Œä¸”æ¨¡å‹å—æ¦‚ç‡éšæœºæ€§å› ç´ å½±å“ï¼Œæ— æ³•ä¿è¯è¾“å‡ºå†…å®¹çš„å‡†ç¡®ã€‚åŒæ—¶æ¨¡å‹çš„è¾“å‡ºå®¹æ˜“è¢«ç”¨æˆ·çš„è¾“å…¥è¯¯å¯¼ã€‚&lt;strong&gt;æœ¬é¡¹ç›®ä¸æ‰¿æ‹…å¼€æºæ¨¡å‹å’Œä»£ç å¯¼è‡´çš„æ•°æ®å®‰å…¨ã€èˆ†æƒ…é£é™©æˆ–å‘ç”Ÿä»»ä½•æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­ã€ä¸å½“åˆ©ç”¨è€Œäº§ç”Ÿçš„é£é™©å’Œè´£ä»»ã€‚&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;æ¨¡å‹åˆ—è¡¨&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Seq Length&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Download&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ChatGLM3-6B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8k&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/THUDM/chatglm3-6b&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://modelscope.cn/models/ZhipuAI/chatglm3-6b&#34;&gt;ModelScope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ChatGLM3-6B-Base&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8k&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/THUDM/chatglm3-6b-base&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://modelscope.cn/models/ZhipuAI/chatglm3-6b-base&#34;&gt;ModelScope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ChatGLM3-6B-32K&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32k&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/THUDM/chatglm3-6b-32k&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://modelscope.cn/models/ZhipuAI/chatglm3-6b-32k&#34;&gt;ModelScope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;è¯„æµ‹ç»“æœ&lt;/h2&gt; &#xA;&lt;h3&gt;å…¸å‹ä»»åŠ¡&lt;/h3&gt; &#xA;&lt;p&gt;æˆ‘ä»¬é€‰å–äº† 8 ä¸ªä¸­è‹±æ–‡å…¸å‹æ•°æ®é›†ï¼Œåœ¨ ChatGLM3-6B (base) ç‰ˆæœ¬ä¸Šè¿›è¡Œäº†æ€§èƒ½æµ‹è¯•ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;GSM8K&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MATH&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;BBH&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MMLU&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;C-Eval&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;CMMLU&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MBPP&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;AGIEval&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B-Base&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Best Baseline&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;60.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;63.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;62.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM3-6B-Base&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;72.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;25.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;66.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;69.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;67.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;53.7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Best Baseline æŒ‡çš„æ˜¯æ¨¡å‹å‚æ•°åœ¨ 10B ä»¥ä¸‹ã€åœ¨å¯¹åº”æ•°æ®é›†ä¸Šè¡¨ç°æœ€å¥½çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä¸åŒ…æ‹¬åªé’ˆå¯¹æŸä¸€é¡¹ä»»åŠ¡è®­ç»ƒè€Œæœªä¿æŒé€šç”¨èƒ½åŠ›çš„æ¨¡å‹ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;å¯¹ ChatGLM3-6B-Base çš„æµ‹è¯•ä¸­ï¼ŒBBH é‡‡ç”¨ 3-shot æµ‹è¯•ï¼Œéœ€è¦æ¨ç†çš„ GSM8Kã€MATH é‡‡ç”¨ 0-shot CoT æµ‹è¯•ï¼ŒMBPP é‡‡ç”¨ 0-shot ç”Ÿæˆåè¿è¡Œæµ‹ä¾‹è®¡ç®— Pass@1 ï¼Œå…¶ä»–é€‰æ‹©é¢˜ç±»å‹æ•°æ®é›†å‡é‡‡ç”¨ 0-shot æµ‹è¯•ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;æˆ‘ä»¬åœ¨å¤šä¸ªé•¿æ–‡æœ¬åº”ç”¨åœºæ™¯ä¸‹å¯¹ ChatGLM3-6B-32K è¿›è¡Œäº†äººå·¥è¯„ä¼°æµ‹è¯•ã€‚ä¸äºŒä»£æ¨¡å‹ç›¸æ¯”ï¼Œå…¶æ•ˆæœå¹³å‡æå‡äº†è¶…è¿‡ 50%ã€‚åœ¨è®ºæ–‡é˜…è¯»ã€æ–‡æ¡£æ‘˜è¦å’Œè´¢æŠ¥åˆ†æç­‰åº”ç”¨ä¸­ï¼Œè¿™ç§æå‡å°¤ä¸ºæ˜¾è‘—ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜åœ¨ LongBench è¯„æµ‹é›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œäº†æµ‹è¯•ï¼Œå…·ä½“ç»“æœå¦‚ä¸‹è¡¨æ‰€ç¤º&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;å¹³å‡&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Summary&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Single-Doc QA&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Multi-Doc QA&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Code&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Few-shot&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Synthetic&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B-32K&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;41.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;37.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM3-6B-32K&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;56.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;65&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;ä½¿ç”¨æ–¹å¼&lt;/h2&gt; &#xA;&lt;h3&gt;ç¯å¢ƒå®‰è£…&lt;/h3&gt; &#xA;&lt;p&gt;é¦–å…ˆéœ€è¦ä¸‹è½½æœ¬ä»“åº“ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/THUDM/ChatGLM3&#xA;cd ChatGLM3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ç„¶åä½¿ç”¨ pip å®‰è£…ä¾èµ–ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å…¶ä¸­ &lt;code&gt;transformers&lt;/code&gt; åº“ç‰ˆæœ¬æ¨èä¸º &lt;code&gt;4.30.2&lt;/code&gt;ï¼Œ&lt;code&gt;torch&lt;/code&gt; æ¨èä½¿ç”¨ 2.0 åŠä»¥ä¸Šçš„ç‰ˆæœ¬ï¼Œä»¥è·å¾—æœ€ä½³çš„æ¨ç†æ€§èƒ½ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;ç»¼åˆ Demo&lt;/h3&gt; &#xA;&lt;p&gt;æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªé›†æˆä»¥ä¸‹ä¸‰ç§åŠŸèƒ½çš„ç»¼åˆ Demoï¼Œè¿è¡Œæ–¹æ³•è¯·å‚è€ƒ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM3/main/composite_demo/README.md&#34;&gt;ç»¼åˆ Demo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Chat: å¯¹è¯æ¨¡å¼ï¼Œåœ¨æ­¤æ¨¡å¼ä¸‹å¯ä»¥ä¸æ¨¡å‹è¿›è¡Œå¯¹è¯ã€‚&lt;/li&gt; &#xA; &lt;li&gt;Tool: å·¥å…·æ¨¡å¼ï¼Œæ¨¡å‹é™¤äº†å¯¹è¯å¤–ï¼Œè¿˜å¯ä»¥é€šè¿‡å·¥å…·è¿›è¡Œå…¶ä»–æ“ä½œã€‚ &lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM3/main/resources/tool.png&#34; alt=&#34;tool&#34;&gt;&lt;/li&gt; &#xA; &lt;li&gt;Code Interpreter: ä»£ç è§£é‡Šå™¨æ¨¡å¼ï¼Œæ¨¡å‹å¯ä»¥åœ¨ä¸€ä¸ª Jupyter ç¯å¢ƒä¸­æ‰§è¡Œä»£ç å¹¶è·å–ç»“æœï¼Œä»¥å®Œæˆå¤æ‚ä»»åŠ¡ã€‚ &lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM3/main/resources/heart.png&#34; alt=&#34;code&#34;&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ä»£ç è°ƒç”¨&lt;/h3&gt; &#xA;&lt;p&gt;å¯ä»¥é€šè¿‡å¦‚ä¸‹ä»£ç è°ƒç”¨ ChatGLM æ¨¡å‹æ¥ç”Ÿæˆå¯¹è¯ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from transformers import AutoTokenizer, AutoModel&#xA;&amp;gt;&amp;gt;&amp;gt; tokenizer = AutoTokenizer.from_pretrained(&#34;THUDM/chatglm3-6b&#34;, trust_remote_code=True)&#xA;&amp;gt;&amp;gt;&amp;gt; model = AutoModel.from_pretrained(&#34;THUDM/chatglm3-6b&#34;, trust_remote_code=True, device=&#39;cuda&#39;)&#xA;&amp;gt;&amp;gt;&amp;gt; model = model.eval()&#xA;&amp;gt;&amp;gt;&amp;gt; response, history = model.chat(tokenizer, &#34;ä½ å¥½&#34;, history=[])&#xA;&amp;gt;&amp;gt;&amp;gt; print(response)&#xA;ä½ å¥½ğŸ‘‹!æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM3-6B,å¾ˆé«˜å…´è§åˆ°ä½ ,æ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚&#xA;&amp;gt;&amp;gt;&amp;gt; response, history = model.chat(tokenizer, &#34;æ™šä¸Šç¡ä¸ç€åº”è¯¥æ€ä¹ˆåŠ&#34;, history=history)&#xA;&amp;gt;&amp;gt;&amp;gt; print(response)&#xA;æ™šä¸Šç¡ä¸ç€å¯èƒ½ä¼šè®©ä½ æ„Ÿåˆ°ç„¦è™‘æˆ–ä¸èˆ’æœ,ä½†ä»¥ä¸‹æ˜¯ä¸€äº›å¯ä»¥å¸®åŠ©ä½ å…¥ç¡çš„æ–¹æ³•:&#xA;&#xA;1. åˆ¶å®šè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨:ä¿æŒè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨å¯ä»¥å¸®åŠ©ä½ å»ºç«‹å¥åº·çš„ç¡çœ ä¹ æƒ¯,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚å°½é‡åœ¨æ¯å¤©çš„ç›¸åŒæ—¶é—´ä¸ŠåºŠ,å¹¶åœ¨åŒä¸€æ—¶é—´èµ·åºŠã€‚&#xA;2. åˆ›é€ ä¸€ä¸ªèˆ’é€‚çš„ç¡çœ ç¯å¢ƒ:ç¡®ä¿ç¡çœ ç¯å¢ƒèˆ’é€‚,å®‰é™,é»‘æš—ä¸”æ¸©åº¦é€‚å®œã€‚å¯ä»¥ä½¿ç”¨èˆ’é€‚çš„åºŠä¸Šç”¨å“,å¹¶ä¿æŒæˆ¿é—´é€šé£ã€‚&#xA;3. æ”¾æ¾èº«å¿ƒ:åœ¨ç¡å‰åšäº›æ”¾æ¾çš„æ´»åŠ¨,ä¾‹å¦‚æ³¡ä¸ªçƒ­æ°´æ¾¡,å¬äº›è½»æŸ”çš„éŸ³ä¹,é˜…è¯»ä¸€äº›æœ‰è¶£çš„ä¹¦ç±ç­‰,æœ‰åŠ©äºç¼“è§£ç´§å¼ å’Œç„¦è™‘,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚&#xA;4. é¿å…é¥®ç”¨å«æœ‰å’–å•¡å› çš„é¥®æ–™:å’–å•¡å› æ˜¯ä¸€ç§åˆºæ¿€æ€§ç‰©è´¨,ä¼šå½±å“ä½ çš„ç¡çœ è´¨é‡ã€‚å°½é‡é¿å…åœ¨ç¡å‰é¥®ç”¨å«æœ‰å’–å•¡å› çš„é¥®æ–™,ä¾‹å¦‚å’–å•¡,èŒ¶å’Œå¯ä¹ã€‚&#xA;5. é¿å…åœ¨åºŠä¸Šåšä¸ç¡çœ æ— å…³çš„äº‹æƒ…:åœ¨åºŠä¸Šåšäº›ä¸ç¡çœ æ— å…³çš„äº‹æƒ…,ä¾‹å¦‚çœ‹ç”µå½±,ç©æ¸¸æˆæˆ–å·¥ä½œç­‰,å¯èƒ½ä¼šå¹²æ‰°ä½ çš„ç¡çœ ã€‚&#xA;6. å°è¯•å‘¼å¸æŠ€å·§:æ·±å‘¼å¸æ˜¯ä¸€ç§æ”¾æ¾æŠ€å·§,å¯ä»¥å¸®åŠ©ä½ ç¼“è§£ç´§å¼ å’Œç„¦è™‘,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚è¯•ç€æ…¢æ…¢å¸æ°”,ä¿æŒå‡ ç§’é’Ÿ,ç„¶åç¼“æ…¢å‘¼æ°”ã€‚&#xA;&#xA;å¦‚æœè¿™äº›æ–¹æ³•æ— æ³•å¸®åŠ©ä½ å…¥ç¡,ä½ å¯ä»¥è€ƒè™‘å’¨è¯¢åŒ»ç”Ÿæˆ–ç¡çœ ä¸“å®¶,å¯»æ±‚è¿›ä¸€æ­¥çš„å»ºè®®ã€‚&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;ä»æœ¬åœ°åŠ è½½æ¨¡å‹&lt;/h4&gt; &#xA;&lt;p&gt;ä»¥ä¸Šä»£ç ä¼šç”± &lt;code&gt;transformers&lt;/code&gt; è‡ªåŠ¨ä¸‹è½½æ¨¡å‹å®ç°å’Œå‚æ•°ã€‚å®Œæ•´çš„æ¨¡å‹å®ç°åœ¨ &lt;a href=&#34;https://huggingface.co/THUDM/chatglm3-6b&#34;&gt;Hugging Face Hub&lt;/a&gt;ã€‚å¦‚æœä½ çš„ç½‘ç»œç¯å¢ƒè¾ƒå·®ï¼Œä¸‹è½½æ¨¡å‹å‚æ•°å¯èƒ½ä¼šèŠ±è´¹è¾ƒé•¿æ—¶é—´ç”šè‡³å¤±è´¥ã€‚æ­¤æ—¶å¯ä»¥å…ˆå°†æ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°ï¼Œç„¶åä»æœ¬åœ°åŠ è½½ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ä» Hugging Face Hub ä¸‹è½½æ¨¡å‹éœ€è¦å…ˆ&lt;a href=&#34;https://docs.github.com/zh/repositories/working-with-files/managing-large-files/installing-git-large-file-storage&#34;&gt;å®‰è£…Git LFS&lt;/a&gt;ï¼Œç„¶åè¿è¡Œ&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;git clone https://huggingface.co/THUDM/chatglm3-6b&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å¦‚æœä»ä½ ä» HuggingFace ä¸‹è½½æ¯”è¾ƒæ…¢ï¼Œä¹Ÿå¯ä»¥ä» &lt;a href=&#34;https://modelscope.cn/models/ZhipuAI/chatglm3-6b&#34;&gt;ModelScope&lt;/a&gt; ä¸­ä¸‹è½½ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;ç½‘é¡µç‰ˆå¯¹è¯ Demo&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM3/main/resources/web-demo.gif&#34; alt=&#34;web-demo&#34;&gt; å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¯åŠ¨åŸºäº Gradio çš„ç½‘é¡µç‰ˆ demoï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python web_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM3/main/resources/web-demo2.png&#34; alt=&#34;web-demo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¯åŠ¨åŸºäº Streamlit çš„ç½‘é¡µç‰ˆ demoï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;streamlit run web_demo2.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ç½‘é¡µç‰ˆ demo ä¼šè¿è¡Œä¸€ä¸ª Web Serverï¼Œå¹¶è¾“å‡ºåœ°å€ã€‚åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€è¾“å‡ºçš„åœ°å€å³å¯ä½¿ç”¨ã€‚ ç»æµ‹è¯•ï¼ŒåŸºäº Streamlit çš„ç½‘é¡µç‰ˆ Demo ä¼šæ›´æµç•…ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;å‘½ä»¤è¡Œå¯¹è¯ Demo&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM3/main/resources/cli-demo.png&#34; alt=&#34;cli-demo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;è¿è¡Œä»“åº“ä¸­ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM3/main/cli_demo.py&#34;&gt;cli_demo.py&lt;/a&gt;ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python cli_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ç¨‹åºä¼šåœ¨å‘½ä»¤è¡Œä¸­è¿›è¡Œäº¤äº’å¼çš„å¯¹è¯ï¼Œåœ¨å‘½ä»¤è¡Œä¸­è¾“å…¥æŒ‡ç¤ºå¹¶å›è½¦å³å¯ç”Ÿæˆå›å¤ï¼Œè¾“å…¥ &lt;code&gt;clear&lt;/code&gt; å¯ä»¥æ¸…ç©ºå¯¹è¯å†å²ï¼Œè¾“å…¥ &lt;code&gt;stop&lt;/code&gt; ç»ˆæ­¢ç¨‹åºã€‚&lt;/p&gt; &#xA;&lt;h3&gt;API éƒ¨ç½²&lt;/h3&gt; &#xA;&lt;p&gt;æ„Ÿè°¢ &lt;a href=&#34;https://github.com/xusenlinzy&#34;&gt;@xusenlinzy&lt;/a&gt; å®ç°äº† OpenAI æ ¼å¼çš„æµå¼ API éƒ¨ç½²ï¼Œå¯ä»¥ä½œä¸ºä»»æ„åŸºäº ChatGPT çš„åº”ç”¨çš„åç«¯ï¼Œæ¯”å¦‚ &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web&#34;&gt;ChatGPT-Next-Web&lt;/a&gt;ã€‚å¯ä»¥é€šè¿‡è¿è¡Œä»“åº“ä¸­çš„&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM3/main/openai_api.py&#34;&gt;openai_api.py&lt;/a&gt; è¿›è¡Œéƒ¨ç½²ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python openai_api.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;è¿›è¡Œ API è°ƒç”¨çš„ç¤ºä¾‹ä»£ç ä¸º&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import openai&#xA;if __name__ == &#34;__main__&#34;:&#xA;    openai.api_base = &#34;http://localhost:8000/v1&#34;&#xA;    openai.api_key = &#34;none&#34;&#xA;    for chunk in openai.ChatCompletion.create(&#xA;        model=&#34;chatglm3-6b&#34;,&#xA;        messages=[&#xA;            {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;ä½ å¥½&#34;}&#xA;        ],&#xA;        stream=True&#xA;    ):&#xA;        if hasattr(chunk.choices[0].delta, &#34;content&#34;):&#xA;            print(chunk.choices[0].delta.content, end=&#34;&#34;, flush=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;å·¥å…·è°ƒç”¨&lt;/h3&gt; &#xA;&lt;p&gt;å…³äºå·¥å…·è°ƒç”¨çš„æ–¹æ³•è¯·å‚è€ƒ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM3/main/tool_using/README.md&#34;&gt;å·¥å…·è°ƒç”¨&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ä½æˆæœ¬éƒ¨ç½²&lt;/h2&gt; &#xA;&lt;p&gt;è¯·è§ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM3/main/DEPLOYMENT.md&#34;&gt;DEPLOYMENT.md&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;å¼•ç”¨&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œæœ‰å¸®åŠ©çš„è¯ï¼Œè¯·è€ƒè™‘å¼•ç”¨ä¸‹åˆ—è®ºæ–‡ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{zeng2022glm,&#xA;  title={Glm-130b: An open bilingual pre-trained model},&#xA;  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},&#xA;  journal={arXiv preprint arXiv:2210.02414},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{du2022glm,&#xA;  title={GLM: General Language Model Pretraining with Autoregressive Blank Infilling},&#xA;  author={Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},&#xA;  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},&#xA;  pages={320--335},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>huggingface/alignment-handbook</title>
    <updated>2023-10-30T01:34:14Z</updated>
    <id>tag:github.com,2023-10-30:/huggingface/alignment-handbook</id>
    <link href="https://github.com/huggingface/alignment-handbook" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Robust recipes for to align language models with human and AI preferences&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Alignment Handbook&lt;/h1&gt; &#xA;&lt;p&gt;Robust recipes to align language models with human and AI preferences.&lt;/p&gt; &#xA;&lt;h2&gt;What is this?&lt;/h2&gt; &#xA;&lt;p&gt;Just one year ago, chatbots were out of fashion and most people hadn&#39;t heard about techniques like Reinforcement Learning from Human Feedback (RLHF) to align language models with human preferences. Then, OpenAI broke the internet with ChatGPT and Meta followed suit by releasing the Llama series of language models which enabled the ML community to build their very own capable chatbots. This has led to a rich ecosystem of datasets and models that have mostly focused on teaching language models to follow instructions through supervised fine-tuning (SFT).&lt;/p&gt; &#xA;&lt;p&gt;However, we know from the &lt;a href=&#34;https://huggingface.co/papers/2203.02155&#34;&gt;InstructGPT&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/papers/2307.09288&#34;&gt;Llama2&lt;/a&gt; papers that significant gains in helpfulness and safety can be had by augmenting SFT with human (or AI) preferences. At the same time, aligning language models to a set of preferences is a fairly novel idea and there are few public resources available on how to train these models, what data to collect, and what metrics to measure for best downstream performance.&lt;/p&gt; &#xA;&lt;p&gt;The Alignment Handbook aims to fill that gap by providing the community with a series of robust training recipes that span the whole pipeline.&lt;/p&gt; &#xA;&lt;h2&gt;Links ğŸ”—&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/collections/HuggingFaceH4/zephyr-7b-6538c6d6d5ddd1cbb1744a66&#34;&gt;Zephyr 7B models, datasets, and demos&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;p&gt;The initial release of the handbook will focus on the following techniques:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Supervised fine-tuning:&lt;/strong&gt; teach language models to follow instructions and tips on how to collect and curate your own training dataset.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Reward modeling:&lt;/strong&gt; teach language models to distinguish model responses according to human or AI preferences.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Rejection sampling:&lt;/strong&gt; a simple, but powerful technique to boost the performance of your SFT model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Direct preference optimisation (DPO):&lt;/strong&gt; a powerful and promising alternative to PPO.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;p&gt;To run the code in this project, first create a Python virtual environment using e.g. Conda:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda create -n handbook python=3.10 &amp;amp;&amp;amp; conda activate handbook&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, install PyTorch v2.1.0. Since this hardware-dependent, we direct you to the &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;PyTorch Installation Page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Once PyTorch is installed, you can install the remaining package dependencies as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, log into your Hugging Face account as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;huggingface-cli login&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, install Git LFS so that you can push models to the Hugging Face Hub:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install git-lfs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find the content of this repo useful in your work, please cite it as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{alignment_handbook2023,&#xA;  author = {Lewis Tunstall and Edward Beeching and Nathan Lambert and Nazneen Rajani and Alexander M. Rush and Thomas Wolf},&#xA;  title = {The Alignment Handbook},&#xA;  year = {2023},&#xA;  publisher = {GitHub},&#xA;  journal = {GitHub repository},&#xA;  howpublished = {\url{https://github.com/huggingface/alignment-handbook}}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>