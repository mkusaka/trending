<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-01-21T01:48:02Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>enoch3712/ExtractThinker</title>
    <updated>2025-01-21T01:48:02Z</updated>
    <id>tag:github.com,2025-01-21:/enoch3712/ExtractThinker</id>
    <link href="https://github.com/enoch3712/ExtractThinker" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ExtractThinker is a Document Intelligence library for LLMs, offering ORM-style interaction for flexible and powerful document workflows.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/enoch3712/Open-DocLLM/assets/9283394/41d9d151-acb5-44da-9c10-0058f76c2512&#34; alt=&#34;Extract Thinker Logo&#34; width=&#34;200&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img alt=&#34;Python Version&#34; src=&#34;https://img.shields.io/badge/Python-3.9%2B-blue.svg?sanitize=true&#34;&gt; &lt;a href=&#34;https://medium.com/@enoch3712&#34;&gt; &lt;img alt=&#34;Medium&#34; src=&#34;https://img.shields.io/badge/Medium-12100E?style=flat&amp;amp;logo=medium&amp;amp;logoColor=white&#34;&gt; &lt;/a&gt; &lt;img alt=&#34;GitHub Last Commit&#34; src=&#34;https://img.shields.io/github/last-commit/enoch3712/Open-DocLLM&#34;&gt; &lt;img alt=&#34;Github License&#34; src=&#34;https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;ExtractThinker&lt;/h1&gt; &#xA;&lt;p&gt;ExtractThinker is a flexible document intelligence tool that leverages Large Language Models (LLMs) to extract and classify structured data from documents, functioning like an ORM for seamless document processing workflows.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TL;DR Document Intelligence for LLMs&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Flexible Document Loaders&lt;/strong&gt;: Support for multiple document loaders, including Tesseract OCR, Azure Form Recognizer, AWS Textract, Google Document AI, and more.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Customizable Contracts&lt;/strong&gt;: Define custom extraction contracts using Pydantic models for precise data extraction.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Advanced Classification&lt;/strong&gt;: Classify documents or document sections using custom classifications and strategies.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Asynchronous Processing&lt;/strong&gt;: Utilize asynchronous processing for efficient handling of large documents.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi-format Support&lt;/strong&gt;: Seamlessly work with various document formats like PDFs, images, spreadsheets, and more.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ORM-style Interaction&lt;/strong&gt;: Interact with documents and LLMs in an ORM-like fashion for intuitive development.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Splitting Strategies&lt;/strong&gt;: Implement lazy or eager splitting strategies to process documents page by page or as a whole.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Integration with LLMs&lt;/strong&gt;: Easily integrate with different LLM providers like OpenAI, Anthropic, Cohere, and more.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Community-driven Development&lt;/strong&gt;: Inspired by the LangChain ecosystem with a focus on intelligent document processing. &lt;img src=&#34;https://github.com/user-attachments/assets/844b425c-0bb7-4abc-9d08-96e4a736d096&#34; alt=&#34;image&#34;&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üì¶ Installation&lt;/h2&gt; &#xA;&lt;p&gt;Install ExtractThinker using pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install extract_thinker&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üõ†Ô∏è Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Basic Extraction Example&lt;/h3&gt; &#xA;&lt;p&gt;Here&#39;s a quick example to get you started with ExtractThinker. This example demonstrates how to load a document using PyPdf and extract specific fields defined in a contract.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os&#xA;from dotenv import load_dotenv&#xA;from extract_thinker import Extractor, DocumentLoaderPyPdf, Contract&#xA;&#xA;load_dotenv()&#xA;&#xA;class InvoiceContract(Contract):&#xA;    invoice_number: str&#xA;    invoice_date: str&#xA;&#xA;# Set the path to your Tesseract executable&#xA;test_file_path = os.path.join(&#34;path_to_your_files&#34;, &#34;invoice.pdf&#34;)&#xA;&#xA;# Initialize the extractor&#xA;extractor = Extractor()&#xA;extractor.load_document_loader(DocumentLoaderPyPdf())&#xA;extractor.load_llm(&#34;gpt-4o-mini&#34;)  # or any other supported model&#xA;&#xA;# Extract data from the document&#xA;result = extractor.extract(test_file_path, InvoiceContract)&#xA;&#xA;print(&#34;Invoice Number:&#34;, result.invoice_number)&#xA;print(&#34;Invoice Date:&#34;, result.invoice_date)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Classification Example&lt;/h3&gt; &#xA;&lt;p&gt;ExtractThinker allows you to classify documents or parts of documents using custom classifications:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os&#xA;from dotenv import load_dotenv&#xA;from extract_thinker import (&#xA;    Extractor, Classification, Process, ClassificationStrategy,&#xA;    DocumentLoaderPyPdf, Contract&#xA;)&#xA;&#xA;load_dotenv()&#xA;&#xA;class InvoiceContract(Contract):&#xA;    invoice_number: str&#xA;    invoice_date: str&#xA;&#xA;class DriverLicenseContract(Contract):&#xA;    name: str&#xA;    license_number: str&#xA;&#xA;# Initialize the extractor and load the document loader&#xA;extractor = Extractor()&#xA;extractor.load_document_loader(DocumentLoaderPyPdf())&#xA;extractor.load_llm(&#34;gpt-4o-mini&#34;)&#xA;&#xA;# Define classifications&#xA;classifications = [&#xA;    Classification(&#xA;        name=&#34;Invoice&#34;,&#xA;        description=&#34;An invoice document&#34;,&#xA;        contract=InvoiceContract,&#xA;        extractor=extractor,&#xA;    ),&#xA;    Classification(&#xA;        name=&#34;Driver License&#34;,&#xA;        description=&#34;A driver&#39;s license document&#34;,&#xA;        contract=DriverLicenseContract,&#xA;        extractor=extractor,&#xA;    ),&#xA;]&#xA;&#xA;# Classify the document directly using the extractor&#xA;result = extractor.classify(&#xA;    &#34;path_to_your_document.pdf&#34;,  # Can be a file path or IO stream&#xA;    classifications,&#xA;    image=True  # Set to True for image-based classification&#xA;)&#xA;&#xA;# The result will be a ClassificationResponse object with &#39;name&#39; and &#39;confidence&#39; fields&#xA;print(f&#34;Document classified as: {result.name}&#34;)&#xA;print(f&#34;Confidence level: {result.confidence}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Splitting Files Example&lt;/h3&gt; &#xA;&lt;p&gt;ExtractThinker allows you to split and process documents using different strategies. Here&#39;s how you can split a document and extract data based on classifications.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os&#xA;from dotenv import load_dotenv&#xA;from extract_thinker import (&#xA;    Extractor,&#xA;    Process,&#xA;    Classification,&#xA;    ImageSplitter,&#xA;    DocumentLoaderTesseract,&#xA;    Contract,&#xA;    SplittingStrategy,&#xA;)&#xA;&#xA;load_dotenv()&#xA;&#xA;class DriverLicenseContract(Contract):&#xA;    name: str&#xA;    license_number: str&#xA;&#xA;class InvoiceContract(Contract):&#xA;    invoice_number: str&#xA;    invoice_date: str&#xA;&#xA;# Initialize the extractor and load the document loader&#xA;extractor = Extractor()&#xA;extractor.load_document_loader(DocumentLoaderPyPdf())&#xA;extractor.load_llm(&#34;gpt-4o-mini&#34;)&#xA;&#xA;# Define classifications&#xA;classifications = [&#xA;    Classification(&#xA;        name=&#34;Driver License&#34;,&#xA;        description=&#34;A driver&#39;s license document&#34;,&#xA;        contract=DriverLicenseContract,&#xA;        extractor=extractor,&#xA;    ),&#xA;    Classification(&#xA;        name=&#34;Invoice&#34;,&#xA;        description=&#34;An invoice document&#34;,&#xA;        contract=InvoiceContract,&#xA;        extractor=extractor,&#xA;    ),&#xA;]&#xA;&#xA;# Initialize the process and load the splitter&#xA;process = Process()&#xA;process.load_document_loader(DocumentLoaderPyPdf())&#xA;process.load_splitter(ImageSplitter(model=&#34;gpt-4o-mini&#34;))&#xA;&#xA;# Load and process the document&#xA;path_to_document = &#34;path_to_your_multipage_document.pdf&#34;&#xA;split_content = (&#xA;    process.load_file(path_to_document)&#xA;    .split(classifications, strategy=SplittingStrategy.LAZY)&#xA;    .extract()&#xA;)&#xA;&#xA;# Process the extracted content as needed&#xA;for item in split_content:&#xA;    if isinstance(item, InvoiceContract):&#xA;        print(&#34;Extracted Invoice:&#34;)&#xA;        print(&#34;Invoice Number:&#34;, item.invoice_number)&#xA;        print(&#34;Invoice Date:&#34;, item.invoice_date)&#xA;    elif isinstance(item, DriverLicenseContract):&#xA;        print(&#34;Extracted Driver License:&#34;)&#xA;        print(&#34;Name:&#34;, item.name)&#xA;        print(&#34;License Number:&#34;, item.license_number)&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Batch Processing Example&lt;/h3&gt; &#xA;&lt;p&gt;You can also perform batch processing of documents:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from extract_thinker import Extractor, Contract&#xA;&#xA;class ReceiptContract(Contract):&#xA;    store_name: str&#xA;    total_amount: float&#xA;&#xA;extractor = Extractor()&#xA;extractor.load_llm(&#34;gpt-4o-mini&#34;)&#xA;&#xA;# List of file paths or streams&#xA;document = &#34;receipt1.jpg&#34;&#xA;&#xA;batch_job = extractor.extract_batch(&#xA;    source=document,&#xA;    response_model=ReceiptContract,&#xA;    vision=True,&#xA;)&#xA;&#xA;# Monitor the batch job status&#xA;print(&#34;Batch Job Status:&#34;, await batch_job.get_status())&#xA;&#xA;# Retrieve results once processing is complete&#xA;results = await batch_job.get_result()&#xA;for result in results.parsed_results:&#xA;    print(&#34;Store Name:&#34;, result.store_name)&#xA;    print(&#34;Total Amount:&#34;, result.total_amount)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Local LLM Integration Example&lt;/h3&gt; &#xA;&lt;p&gt;ExtractThinker supports custom LLM integrations. Here&#39;s how you can use a custom LLM:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from extract_thinker import Extractor, LLM, DocumentLoaderTesseract, Contract&#xA;&#xA;class InvoiceContract(Contract):&#xA;    invoice_number: str&#xA;    invoice_date: str&#xA;&#xA;# Initialize the extractor&#xA;extractor = Extractor()&#xA;extractor.load_document_loader(DocumentLoaderTesseract(os.getenv(&#34;TESSERACT_PATH&#34;)))&#xA;&#xA;# Load a custom LLM (e.g., Ollama)&#xA;llm = LLM(&#39;ollama/phi3&#39;, api_base=&#39;http://localhost:11434&#39;)&#xA;extractor.load_llm(llm)&#xA;&#xA;# Extract data&#xA;result = extractor.extract(&#34;invoice.png&#34;, InvoiceContract)&#xA;print(&#34;Invoice Number:&#34;, result.invoice_number)&#xA;print(&#34;Invoice Date:&#34;, result.invoice_date)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üìö Documentation and Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Examples&lt;/strong&gt;: Check out the examples directory for Jupyter notebooks and scripts demonstrating various use cases.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Medium Articles&lt;/strong&gt;: Read articles about ExtractThinker on the author&#39;s Medium page.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Test Suite&lt;/strong&gt;: Explore the test suite in the tests/ directory for more advanced usage examples and test cases.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üß© Integration with LLM Providers&lt;/h2&gt; &#xA;&lt;p&gt;ExtractThinker supports integration with multiple LLM providers:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;: Use models like gpt-3.5-turbo, gpt-4, etc.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Anthropic&lt;/strong&gt;: Integrate with Claude models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Cohere&lt;/strong&gt;: Utilize Cohere&#39;s language models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Azure OpenAI&lt;/strong&gt;: Connect with Azure&#39;s OpenAI services.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Local Models&lt;/strong&gt;: Ollama compatible models.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;‚öôÔ∏è How It Works&lt;/h2&gt; &#xA;&lt;p&gt;ExtractThinker uses a modular architecture inspired by the LangChain ecosystem:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Document Loaders&lt;/strong&gt;: Responsible for loading and preprocessing documents from various sources and formats.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Extractors&lt;/strong&gt;: Orchestrate the interaction between the document loaders and LLMs to extract structured data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Splitters&lt;/strong&gt;: Implement strategies to split documents into manageable chunks for processing.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Contracts&lt;/strong&gt;: Define the expected structure of the extracted data using Pydantic models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Classifications&lt;/strong&gt;: Classify documents or document sections to apply appropriate extraction contracts.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Processes&lt;/strong&gt;: Manage the workflow of loading, classifying, splitting, and extracting data from documents.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/b12ba937-20a8-47da-a778-c126bc1748b3&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üìù Why Use ExtractThinker?&lt;/h2&gt; &#xA;&lt;p&gt;While general frameworks like LangChain offer a broad range of functionalities, ExtractThinker is specialized for Intelligent Document Processing (IDP). It simplifies the complexities associated with IDP by providing:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Specialized Components&lt;/strong&gt;: Tailored tools for document loading, splitting, and extraction.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;High Accuracy with LLMs&lt;/strong&gt;: Leverages the power of LLMs to improve the accuracy of data extraction and classification.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Ease of Use&lt;/strong&gt;: Intuitive APIs and ORM-style interactions reduce the learning curve.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Community Support&lt;/strong&gt;: Active development and support from the community.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions from the community! To contribute:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Fork the repository&lt;/li&gt; &#xA; &lt;li&gt;Create a new branch for your feature or bugfix&lt;/li&gt; &#xA; &lt;li&gt;Write tests for your changes&lt;/li&gt; &#xA; &lt;li&gt;Run tests to ensure everything is working correctly&lt;/li&gt; &#xA; &lt;li&gt;Submit a pull request with a description of your changes&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;üåü Community and Support&lt;/h2&gt; &#xA;&lt;p&gt;Stay updated and connect with the community:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/towards-artificial-intelligence/scaling-document-extraction-with-o1-gpt4o-and-mini-extractthinker-8f3340b4e69c&#34;&gt;Scaling Document Extraction with o1, GPT-4o &amp;amp; Mini&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/gitconnected/claude-3-5-the-king-of-document-intelligence-f57bea1d209d?sk=124c5abb30c0e7f04313c5e20e79c2d1&#34;&gt;Claude 3.5 ‚Äî The King of Document Intelligence&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/gitconnected/classification-tree-for-llms-32b69015c5e0?sk=8a258cf74fe3483e68ab164e6b3aaf4c&#34;&gt;Classification Tree for LLMs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/gitconnected/advanced-document-classification-with-llms-8801eaee3c58?sk=f5a22ee72022eb70e112e3e2d1608e79&#34;&gt;Advanced Document Classification with LLMs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/towards-artificial-intelligence/phi-3-and-azure-pdf-data-extraction-extractthinker-cb490a095adb?sk=7be7e625b8f9932768442f87dd0ebcec&#34;&gt;Phi-3 and Azure: PDF Data Extraction | ExtractThinker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/towards-artificial-intelligence/extractthinker-ai-document-intelligence-with-llms-72cbce1890ef&#34;&gt;ExtractThinker: Document Intelligence for LLMs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìÑ License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the Apache License 2.0. See the LICENSE file for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;For any questions or issues, please open an issue on the GitHub repository or reach out via email.&lt;/p&gt;</summary>
  </entry>
</feed>