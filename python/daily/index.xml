<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-25T01:35:59Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>0xJs/RedTeaming_CheatSheet</title>
    <updated>2022-11-25T01:35:59Z</updated>
    <id>tag:github.com,2022-11-25:/0xJs/RedTeaming_CheatSheet</id>
    <link href="https://github.com/0xJs/RedTeaming_CheatSheet" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Pentesting cheatsheet with all the commands I learned during my learning journey. Will try to to keep it up-to-date.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RedTeaming_CheatSheet&lt;/h1&gt; &#xA;&lt;p&gt;Pentesting / RedTeaming cheatsheet with all the commands and techniques I learned during my learning journey. Will keep it up to date. If you have any recommendations for courses or links or have any questions feel free to dm me on discord. 0xjs#9027&lt;/p&gt; &#xA;&lt;h2&gt;Index&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/#General&#34;&gt;General&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/payloads.md&#34;&gt;Payloads&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/OSINT.md&#34;&gt;Open Source Intelligence&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/python_dependancies.md&#34;&gt;Python Dependancies&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/infrastructure/readme.md&#34;&gt;Infrastructure&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/infrastructure/bufferoverflow.md&#34;&gt;Buffer overflow&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/infrastructure/enumeration.md&#34;&gt;Enumeration&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/infrastructure/exploitation.md&#34;&gt;Exploitation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/infrastructure/privesc_windows.md&#34;&gt;Privilege Escalation Windows&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/infrastructure/privesc_linux.md&#34;&gt;Privilege Escalation Linux&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/infrastructure/post_exploitation.md&#34;&gt;Post Exploitation&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/windows-ad/readme.md&#34;&gt;Windows AD&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/windows-ad/Local-Privilege-Escalation.md&#34;&gt;Local privilege escalation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/windows-ad/Domain-Enumeration.md&#34;&gt;Domain Enumeration&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/windows-ad/Lateral-Movement.md&#34;&gt;Lateral Movement&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/windows-ad/PowerShell-Evasion.md&#34;&gt;Powershell Evasion&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/windows-ad/Domain-Privilege-Escalation.md&#34;&gt;Domain privilege escalation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/windows-ad/Domain-Persistence.md&#34;&gt;Domain Persistence&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cloud/readme.md&#34;&gt;Cloud&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cloud/recon.md&#34;&gt;Recon \ OSINT&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cloud/initial-access-attacks.md&#34;&gt;Initial access attacks&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cloud/readme.md&#34;&gt;Cloud services&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cloud/azure/readme.md&#34;&gt;Azure&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cloud/aws/readme.md&#34;&gt;Amazon Web Services&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cloud/gcb/readme.md&#34;&gt;Google Cloud Platform&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;C2 Frameworks&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cobalt-strike.md&#34;&gt;Cobalt Strike&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/covenant.md&#34;&gt;Covenant&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/metasploit.md&#34;&gt;Metasploit&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Sources&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Cloud: CARTP from Pentester Academy and breaching the cloud from antisyphon.&lt;/li&gt; &#xA; &lt;li&gt;Windows: CRTP, CRTE from Pentester Academy, ECPTX from eLearnSecurity and CRTO from RastaMouse.&lt;/li&gt; &#xA; &lt;li&gt;Infra: PNPT and Tiberius privesc courses&lt;/li&gt; &#xA; &lt;li&gt;OSINT: PNPT Course&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>baaivision/EVA</title>
    <updated>2022-11-25T01:35:59Z</updated>
    <id>tag:github.com,2022-11-25:/baaivision/EVA</id>
    <link href="https://github.com/baaivision/EVA" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Exploring the Limits of Masked Visual Representation Learning at Scale (https://arxiv.org/abs/2211.07636)&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;EVA: An Open Billion-Scale Vision Foundation Model &lt;/h1&gt; &#xA; &lt;h3&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.07636&#34;&gt;EVA: Exploring the Limits of Masked Visual Representation Learning at Scale&lt;/a&gt;&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://bit.ly/YuxinFang_GoogleScholar&#34;&gt;Yuxin Fang&lt;/a&gt;&lt;sup&gt;2,1&lt;/sup&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=1ks0R04AAAAJ&amp;amp;hl&#34;&gt;Wen Wang&lt;/a&gt;&lt;sup&gt;3,1&lt;/sup&gt;, &lt;a href=&#34;https://binhuixie.github.io/&#34;&gt;Binhui Xie&lt;/a&gt;&lt;sup&gt;4,1&lt;/sup&gt;, &lt;a href=&#34;https://github.com/Quan-Sun&#34;&gt;Quan Sun&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=-eJHVt8AAAAJ&amp;amp;hl=en&#34;&gt;Ledell Wu&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;, &lt;a href=&#34;https://xinggangw.info/&#34;&gt;Xinggang Wang&lt;/a&gt;&lt;sup&gt;2&lt;/sup&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=knvEK4AAAAAJ&amp;amp;hl=en&#34;&gt;Tiejun Huang&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;, &lt;a href=&#34;https://www.xloong.wang/&#34;&gt;Xinlong Wang&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;, &lt;a href=&#34;http://yue-cao.me/&#34;&gt;Yue Cao&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;a href=&#34;https://www.baai.ac.cn/english.html&#34;&gt;BAAI&lt;/a&gt;, &lt;sup&gt;2&lt;/sup&gt;&lt;a href=&#34;http://english.hust.edu.cn/&#34;&gt;HUST&lt;/a&gt;, &lt;sup&gt;3&lt;/sup&gt;&lt;a href=&#34;https://www.zju.edu.cn/english/&#34;&gt;ZJU&lt;/a&gt;, &lt;sup&gt;4&lt;/sup&gt;&lt;a href=&#34;https://english.bit.edu.cn/&#34;&gt;BIT&lt;/a&gt;&lt;/p&gt; &#xA; &lt;!-- [![Paper](http://img.shields.io/badge/paper-arxiv.2211.07636-B31B1B.svg)](https://arxiv.org/abs/2211.07636) --&gt; &#xA; &lt;!-- ArXiv Preprint ([arXiv 2211.07636](https://arxiv.org/abs/2211.07636)) --&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://paperswithcode.com/sota/instance-segmentation-on-coco?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/instance-segmentation-on-coco&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/instance-segmentation-on-coco-minival?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/instance-segmentation-on-coco-minival&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/instance-segmentation-on-lvis-v1-0-val?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/instance-segmentation-on-lvis-v1-0-val&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/object-detection-on-lvis-v1-0-val?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/object-detection-on-lvis-v1-0-val&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/object-detection-on-coco?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/object-detection-on-coco&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/object-detection-on-coco-minival?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/object-detection-on-coco-minival&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/semantic-segmentation-on-ade20k?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/semantic-segmentation-on-ade20k&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/action-classification-on-kinetics-700?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/action-classification-on-kinetics-700&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/action-classification-on-kinetics-400?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/action-classification-on-kinetics-400&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/action-classification-on-kinetics-600?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/action-classification-on-kinetics-600&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;We launch &lt;strong&gt;EVA&lt;/strong&gt;, a vision-centric foundation model to &lt;strong&gt;E&lt;/strong&gt;xplore the limits of &lt;strong&gt;V&lt;/strong&gt;isual representation at sc&lt;strong&gt;A&lt;/strong&gt;le using only publicly accessible data and academic resources. &lt;strong&gt;EVA&lt;/strong&gt; is a vanilla ViT pre-trained to reconstruct the masked out image-text aligned vision features (&lt;em&gt;i.e.&lt;/em&gt;, CLIP features) conditioned on visible image patches. Via this pretext task, we can efficiently scale up EVA to one billion parameters, and sets new records on a broad range of representative vision downstream tasks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;EVA is the first open-sourced billion-scale vision foundation model that achieves state-of-the-art performance on a broad range of downstream tasks.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;strong&gt;All the code &amp;amp; 16x state-of-the-art billion-scale models that are open-sourced!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Nov 22, 2022&lt;/code&gt;: release code &amp;amp; model of &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/det/README.md&#34;&gt;object detection and instance segmentation&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Nov 21, 2022&lt;/code&gt;: release code &amp;amp; model of &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/video/README.md&#34;&gt;video classification&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/seg/README.md&#34;&gt;semantic segmentation&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/clip/README.md&#34;&gt;EVA-CLIP&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Nov 20, 2022&lt;/code&gt;: release code &amp;amp; model of &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/eva/README.md&#34;&gt;pre-training and image classification&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Nov 18, 2022&lt;/code&gt;: release wandb &lt;a href=&#34;https://wandb.ai/baaivision/eva-clip/reports/ViT-g-14--VmlldzoyOTkwMDYy&#34;&gt;log &amp;amp; statistics&lt;/a&gt; of 1.1B EVA-CLIP training.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;span id=&#34;eva_performance_summary&#34;&gt;&lt;/span&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Catalog&lt;/h2&gt; &#xA;&lt;p&gt;All EVA model checkpoints (16 in total) are now available at &lt;a href=&#34;https://huggingface.co/BAAI/EVA/tree/main&#34;&gt;ğŸ¤— Hugging Face Models&lt;/a&gt;. Try them out!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/eva&#34;&gt;Pre-training&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/eva&#34;&gt;Image Classification&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/video&#34;&gt;Video Classification&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/det&#34;&gt;Object Detection &amp;amp; Instance Segmentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/seg&#34;&gt;Semantic Segmentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/clip&#34;&gt;CLIP&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Summary of EVA&#39;s performance&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;strong&gt;image &amp;amp; video classification&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;table border=&#34;1&#34; width=&#34;100%&#34;&gt; &#xA;  &lt;tbody&gt;&#xA;   &lt;tr align=&#34;center&#34;&gt; &#xA;    &lt;th&gt; &lt;/th&gt;&#xA;    &lt;th&gt; &lt;/th&gt;&#xA;    &lt;th colspan=&#34;3&#34;&gt;image classification&lt;/th&gt;&#xA;    &lt;th colspan=&#34;3&#34;&gt;video classification&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr align=&#34;center&#34;&gt; &#xA;    &lt;th&gt;model&lt;/th&gt;&#xA;    &lt;th&gt;#param.&lt;/th&gt;&#xA;    &lt;th&gt;IN-1K&lt;/th&gt;&#xA;    &lt;th&gt;IN-1K, zero-shot&lt;/th&gt;&#xA;    &lt;th&gt;12 avg. zero-shot&lt;/th&gt;&#xA;    &lt;th&gt;K400&lt;/th&gt;&#xA;    &lt;th&gt;K600&lt;/th&gt;&#xA;    &lt;th&gt;K700&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr align=&#34;center&#34;&gt; &#xA;    &lt;th&gt;EVA&lt;/th&gt;&#xA;    &lt;th&gt;1.0B&lt;/th&gt;&#xA;    &lt;th&gt;&lt;a href=&#34;https://github.com/baaivision/EVA/raw/master/logs/cls/ft_1k_cls_sz560_89p7.txt&#34;&gt;89.7&lt;/a&gt;&lt;/th&gt;&#xA;    &lt;th&gt;&lt;a href=&#34;https://wandb.ai/baaivision/eva-clip/reports/ViT-g-14--VmlldzoyOTkwMDYy&#34;&gt;78.5&lt;/a&gt;&lt;/th&gt;&#xA;    &lt;th&gt;72.5+&lt;/th&gt;&#xA;    &lt;th&gt;89.7&lt;/th&gt;&#xA;    &lt;th&gt;89.8&lt;/th&gt;&#xA;    &lt;th&gt;82.9&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt;&#xA; &lt;/table&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;strong&gt;object detection &amp;amp; segmentation&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;table border=&#34;1&#34; width=&#34;200%&#34;&gt; &#xA;  &lt;tbody&gt;&#xA;   &lt;tr align=&#34;center&#34;&gt; &#xA;    &lt;th&gt; &lt;/th&gt;&#xA;    &lt;th&gt; &lt;/th&gt;&#xA;    &lt;th colspan=&#34;4&#34;&gt;COCO det &amp;amp; ins seg&lt;/th&gt;&#xA;    &lt;th colspan=&#34;2&#34;&gt;LVIS det &amp;amp; ins seg&lt;/th&gt;&#xA;    &lt;th colspan=&#34;2&#34;&gt;sem seg&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr align=&#34;center&#34;&gt; &#xA;    &lt;th&gt;model&lt;/th&gt;&#xA;    &lt;th&gt;#param.&lt;/th&gt;&#xA;    &lt;th&gt;det (test)&lt;/th&gt;&#xA;    &lt;th&gt;det (val)&lt;/th&gt;&#xA;    &lt;th&gt;seg (test)&lt;/th&gt;&#xA;    &lt;th&gt;seg (val)&lt;/th&gt;&#xA;    &lt;th&gt;det&lt;/th&gt;&#xA;    &lt;th&gt;seg&lt;/th&gt;&#xA;    &lt;th&gt;COCO-Stuff&lt;/th&gt;&#xA;    &lt;th&gt;ADE20K&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr align=&#34;center&#34;&gt; &#xA;    &lt;th&gt;EVA&lt;/th&gt;&#xA;    &lt;th&gt;1.0B&lt;/th&gt;&#xA;    &lt;th&gt;&lt;a href=&#34;https://codalab.lisn.upsaclay.fr/competitions/7384#results&#34;&gt;64.7&lt;/a&gt;&lt;/th&gt;&#xA;    &lt;th&gt;64.5&lt;/th&gt;&#xA;    &lt;th&gt;&lt;a href=&#34;https://codalab.lisn.upsaclay.fr/competitions/7383#results&#34;&gt;55.5&lt;/a&gt;&lt;/th&gt;&#xA;    &lt;th&gt;55.0&lt;/th&gt;&#xA;    &lt;th&gt;62.2&lt;/th&gt;&#xA;    &lt;th&gt;55.0&lt;/th&gt;&#xA;    &lt;th&gt;&lt;a href=&#34;https://github.com/baaivision/EVA/raw/master/logs/sem_seg/ft_cocstuff164k_sem_seg_ss_53p4.txt&#34;&gt;53.4&lt;/a&gt;&lt;/th&gt;&#xA;    &lt;th&gt;&lt;a href=&#34;https://github.com/baaivision/EVA/raw/master/logs/sem_seg/ft_ade20k_sem_seg_ms_62p3.txt&#34;&gt;62.3&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt;&#xA; &lt;/table&gt; &#xA; &lt;br&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find our work helpful, please &lt;strong&gt;starğŸŒŸ&lt;/strong&gt; this repo and &lt;strong&gt;citeğŸ“‘&lt;/strong&gt; our paper. Thanks for your support!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{EVA,&#xA;  title={EVA: Exploring the Limits of Masked Visual Representation Learning at Scale},&#xA;  author={Fang, Yuxin and Wang, Wen and Xie, Binhui and Sun, Quan and Wu, Ledell and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},&#xA;  journal={arXiv preprint arXiv:2211.07636},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The content of this project itself is licensed under &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;For help and issues associated with EVA, or reporting a bug, please open a &lt;a href=&#34;https://github.com/baaivision/EVA/issues/new&#34;&gt;GitHub Issue&lt;/a&gt;. Let&#39;s build a better &amp;amp; stronger EVA together :)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;We are hiring&lt;/strong&gt; at all levels at BAAI Vision Team, including full-time researchers, engineers and interns. If you are interested in working with us on &lt;strong&gt;foundation model, self-supervised learning and multimodal learning&lt;/strong&gt;, please contact&amp;nbsp;&lt;a href=&#34;http://yue-cao.me/&#34;&gt;Yue Cao&lt;/a&gt; (&lt;code&gt;caoyue@baai.ac.cn&lt;/code&gt;) and &lt;a href=&#34;https://www.xloong.wang/&#34;&gt;Xinlong Wang&lt;/a&gt; (&lt;code&gt;wangxinlong@baai.ac.cn&lt;/code&gt;).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;â†³ Stargazers&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/baaivision/EVA/stargazers&#34;&gt;&lt;img src=&#34;https://reporoster.com/stars/baaivision/EVA&#34; alt=&#34;Stargazers repo roster for @baaivision/EVA&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;â†³ Forkers&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/baaivision/EVA/network/members&#34;&gt;&lt;img src=&#34;https://reporoster.com/forks/baaivision/EVA&#34; alt=&#34;Forkers repo roster for @baaivision/EVA&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>biancangming/wtv</title>
    <updated>2022-11-25T01:35:59Z</updated>
    <id>tag:github.com,2022-11-25:/biancangming/wtv</id>
    <link href="https://github.com/biancangming/wtv" rel="alternate"></link>
    <summary type="html">&lt;p&gt;è§£å†³ç”µè„‘ã€æ‰‹æœºçœ‹ç”µè§†ç›´æ’­çš„è‹¦æ¼ï¼Œæ”¶é›†å„ç§ç›´æ’­æºï¼Œç”µè§†ç›´æ’­ç½‘ç«™&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; &#xA; &lt;p&gt;QQç¾¤å…è´¹å¼€æ”¾ä¸­....&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://qm.qq.com/cgi-bin/qm/qr?k=xdOuWd8gz2OHO5zY_jvjwzwj-fb_7O2I&amp;amp;jump_from=webapi&#34;&gt;ç‚¹å‡»é“¾æ¥åŠ å…¥ç¾¤èŠã€wtväº¤æµç¾¤ã€‘ï¼Œç­‰çº§ä½äºä¸€ä¸ªå¤ªé˜³è°¢ç»å…¥å†…&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;é•¿æœŸæ›´æ–°ï¼Œå»ºè®®æ”¶è—æœ¬é¡µé¢ï¼Œèµ„æºæ¥æºç½‘ç»œï¼Œå¯ç”¨æ€§æœªé€ä¸€éªŒè¯ï¼Œå°½å¯èƒ½ä¿è¯å¤§å¤šèµ„æºå¯ç”¨ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;æœ€æ–°IPTVç›´æ’­æºm3u8ä¸‹è½½ï¼Œç”µè§†ç›´æ’­ç½‘ç«™æ¨èï¼ŒåŸåˆ™ä¸Šä»¥ä¸­æ–‡é¢‘é“ä¸ºä¸»&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/biancangming/wtv/wiki/%E6%9C%80%E6%96%B0IPTV%E7%9B%B4%E6%92%AD%E6%BA%90m3u8%E4%B8%8B%E8%BD%BD%EF%BC%8C%E7%94%B5%E8%A7%86%E7%9B%B4%E6%92%AD%E7%BD%91%E7%AB%99%E6%8E%A8%E8%8D%90&#34;&gt;https://github.com/biancangming/wtv/wiki/æœ€æ–°IPTVç›´æ’­æºm3u8ä¸‹è½½ï¼Œç”µè§†ç›´æ’­ç½‘ç«™æ¨è&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;wtv-tools wtvå·¥å…·ç®±&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/biancangming/wtv/issues/8&#34;&gt;https://github.com/biancangming/wtv/issues/8&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;æ­£ç‰ˆçœ‹TVç½‘ç«™åˆé›†&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/biancangming/wtv/wiki/TV%E7%9B%B4%E6%92%AD%E7%BD%91%E7%AB%99%E5%90%88%E9%9B%86&#34;&gt;https://github.com/biancangming/wtv/wiki/TVç›´æ’­ç½‘ç«™åˆé›†&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;github ç›¸å…³é¡¹ç›®æ¨è&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;åŒ—äº¬è”é€šIPTVé¢‘é“åˆ—è¡¨ &lt;a href=&#34;https://github.com/qwerttvv/Beijing-IPTV&#34;&gt;https://github.com/qwerttvv/Beijing-IPTV&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ç§»åŠ¨ç›´æ’­æºæ±‡æ€» &lt;a href=&#34;https://github.com/SPX372928/MyIPTV&#34;&gt;https://github.com/SPX372928/MyIPTV&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;10086IPTV &lt;a href=&#34;https://github.com/sheng007/10086-IPTV&#34;&gt;https://github.com/sheng007/10086-IPTV&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ä¸–ç•ŒIPTVåº“, å†…å®¹å…¨ï¼š &lt;a href=&#34;https://github.com/iptv-org/iptv&#34;&gt;https://github.com/iptv-org/iptv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;IPTVM3U, &lt;a href=&#34;https://github.com/Sphinxroot/IPTVM3U&#34;&gt;https://github.com/Sphinxroot/IPTVM3U&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[ä¸€é”®ç®¡ç†iptvè„šæœ¬] &lt;a href=&#34;https://github.com/woniuzfb/iptv&#34;&gt;https://github.com/woniuzfb/iptv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[iptv-pro.github.io] &lt;a href=&#34;https://github.com/iptv-pro/iptv-pro.github.io&#34;&gt;https://github.com/iptv-pro/iptv-pro.github.io&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;PCç›´æ’­æºè½¯ä»¶æ¨è&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;potplayer(å½±éŸ³æ’­æ”¾æ”¯æŒæµåª’ä½“) &lt;a href=&#34;https://daumpotplayer.com/download/&#34;&gt;https://daumpotplayer.com/download/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;vlcï¼ˆä¸“ä¸šæµåª’ä½“è½¯ä»¶ï¼‰ &lt;a href=&#34;https://www.videolan.org/vlc/&#34;&gt;https://www.videolan.org/vlc/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;é»‘é¸Ÿæ’­æ”¾å™¨ï¼ˆæ°‘é—´ï¼Œè‡ªå¸¦æºï¼‰ &lt;a href=&#34;https://guihet.com/blackbird-player.html&#34;&gt;https://guihet.com/blackbird-player.html&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;m3u æ‰¹é‡æ£€æµ‹è„šæœ¬&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/biancangming/wtv/tree/master/m3uMaker&#34;&gt;https://github.com/biancangming/wtv/tree/master/m3uMaker&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;æœ‰å…´è¶£å…³æ³¨æˆ‘çš„å¾®ä¿¡å…¬ä¼—å·ï¼Œä¸€ä¸ªæ©™å­pro&lt;/h1&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/42108047/173232153-a4a60817-cba0-4f0a-8ccb-f26e197314f9.jpg&#34; width=&#34;200&#34; height=&#34;200&#34; alt=&#34;ä¸€ä¸ªæ©™å­pro&#34;&gt;</summary>
  </entry>
</feed>