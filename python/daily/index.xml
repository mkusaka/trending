<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-09-13T01:37:25Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>codefuse-ai/MFTCoder</title>
    <updated>2023-09-13T01:37:25Z</updated>
    <id>tag:github.com,2023-09-13:/codefuse-ai/MFTCoder</id>
    <link href="https://github.com/codefuse-ai/MFTCoder" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CodeFuse-MFTCoder: Multitask Fine-Tuned Code LLMs&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/codefuse-ai/MFTCoder/main/assets/codefuse_logo_blue.png&#34; width=&#34;100%&#34;&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt; &lt;a href=&#34;https://github.com/codefuse-ai/MFTCoder&#34;&gt; &lt;img alt=&#34;stars&#34; src=&#34;https://img.shields.io/github/stars/codefuse-ai/MFTCoder?style=social&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/codefuse-ai/MFTCoder&#34;&gt; &lt;img alt=&#34;forks&#34; src=&#34;https://img.shields.io/github/forks/codefuse-ai/MFTCoder?style=social&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/codefuse-ai/MFTCoder/LICENCE&#34;&gt; &lt;img alt=&#34;License: MIT&#34; src=&#34;https://badgen.net/badge/license/apache2.0/blue&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/codefuse-ai/MFTCoder/issues&#34;&gt; &lt;img alt=&#34;Open Issues&#34; src=&#34;https://img.shields.io/github/issues-raw/codefuse-ai/MFTCoder&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/codefuse-ai/MFTCoder/main/README_cn.md&#34;&gt;[‰∏≠Êñá]&lt;/a&gt; [&lt;strong&gt;English&lt;/strong&gt;]&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/codefuse-ai/MFTCoder/main/#News&#34;&gt;News&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/codefuse-ai/MFTCoder/main/#Articles&#34;&gt;Articles&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/codefuse-ai/MFTCoder/main/#Introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/codefuse-ai/MFTCoder/main/#Requirements&#34;&gt;Requirements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/codefuse-ai/MFTCoder/main/#Training&#34;&gt;Training&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/codefuse-ai/MFTCoder/main/#Models&#34;&gt;Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/codefuse-ai/MFTCoder/main/#Datasets&#34;&gt;Datasets&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;p&gt;üî•üî•üî• [2023/09/07]We released &lt;strong&gt;CodeFuse-CodeLlama-34B&lt;/strong&gt;, which achieves the &lt;strong&gt;74.4% Python Pass@1&lt;/strong&gt; (greedy decoding) and surpasses GPT4 (2023/03/15) and ChatGPT-3.5 on the &lt;a href=&#34;https://github.com/openai/human-eval&#34;&gt;HumanEval Benchmarks&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;üî• [2023/08/26]We released MFTCoder which supports finetuning Code Llama, Llama, Llama2, StarCoder, ChatGLM2, CodeGeeX2, Qwen, and GPT-NeoX models with LoRA/QLoRA.&lt;/p&gt; &#xA;&lt;h3&gt;HumanEval Performance&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;HumanEval(Pass@1)&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Date&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;CodeFuse-CodeLlama-34B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;74.4%&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2023/09&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;WizardCoder-Python-34B-V1.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;73.2%&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2023/08&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;GPT-4(zero-shot)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;67.0%&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2023/03&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;PanGu-Coder2 15B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;61.6%&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2023/08&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;CodeLlama-34b-Python&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;53.7%&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2023/08&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;CodeLlama-34b&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;48.8%&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2023/08&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;GPT-3.5(zero-shot)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;48.1%&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2022/11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;OctoCoder&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.2%&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2023/08&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;StarCoder-15B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.6%&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2023/05&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;LLaMA 2 70B(zero-shot)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.9%&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2023/07&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Articles&lt;/h2&gt; &#xA;&lt;p&gt;TBA&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;CodeFuse-MFTCoder&lt;/strong&gt; is an open-source project of CodeFuse for multitasking Code-LLMs(large language model for code tasks), which includes models, datasets, training codebases and inference guides. In MFTCoder, we released two codebases for finetuning Large Language Models:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;mft_peft_hf&lt;/code&gt; is based on the HuggingFace Accelerate and deepspeed framework.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;mft_atorch&lt;/code&gt; is based on the &lt;a href=&#34;https://github.com/intelligent-machine-learning/dlrover&#34;&gt;ATorch frameworks&lt;/a&gt;, which is a fast distributed training framework of LLM.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The aim of this project is to foster collaboration and share advancements in large language models, particularly within the domain of code development.&lt;/p&gt; &#xA;&lt;h3&gt;Frameworks&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/codefuse-ai/MFTCoder/main/assets/img.png&#34; alt=&#34;img.png&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Highlights&lt;/h3&gt; &#xA;&lt;p&gt;&lt;span&gt;‚úÖ&lt;/span&gt; &lt;strong&gt;Multi-task&lt;/strong&gt;: Train models on multiple tasks while maintaining a balance between them. The models can even generalize to new, previously unseen tasks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;‚úÖ&lt;/span&gt; &lt;strong&gt;Multi-model&lt;/strong&gt;: It integrates state-of-the-art open-source models such as gpt-neox, llama, llama-2, baichuan, Qwen, chatglm2, and more. (These finetuned models will be released in the near future.)&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;‚úÖ&lt;/span&gt; &lt;strong&gt;Multi-framework&lt;/strong&gt;: It provides support for both HuggingFace Accelerate (with deepspeed) and &lt;a href=&#34;https://github.com/intelligent-machine-learning/dlrover&#34;&gt;ATorch&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;‚úÖ&lt;/span&gt; &lt;strong&gt;Efficient fine-tuning&lt;/strong&gt;: It supports LoRA and QLoRA, enabling fine-tuning of large models with minimal resources. The training speed meets the demands of almost all fine-tuning scenarios.&lt;/p&gt; &#xA;&lt;p&gt;The main components of this project include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Support for both SFT (Supervised FineTuning) and MFT (Multi-task FineTuning). The current MFTCoder achieves data balance among multiple tasks, and future releases will achieve a balance between task difficulty and convergence speed during training.&lt;/li&gt; &#xA; &lt;li&gt;Support for QLoRA instruction fine-tuning, as well as LoRA fine-tuning.&lt;/li&gt; &#xA; &lt;li&gt;Support for most mainstream open-source large models, particularly those relevant to Code-LLMs, such as Code-LLaMA, Starcoder, Codegeex2, Qwen, GPT-Neox, and more.&lt;/li&gt; &#xA; &lt;li&gt;Support for weight merging between the LoRA adaptor and base models, simplifying the inference process.&lt;/li&gt; &#xA; &lt;li&gt;Release of 2 high-quality code-related instruction fine-tuning datasets: &lt;a href=&#34;https://huggingface.co/datasets/codefuse-ai/Evol-instruction-66k&#34;&gt;Evol-instruction-66k&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/datasets/codefuse-ai/CodeExercise-Python-27k&#34;&gt;CodeExercise-Python-27k&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Release of 2 models: &lt;a href=&#34;https://huggingface.co/codefuse-ai/CodeFuse-13B&#34;&gt;CodeFuse-13B&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/codefuse-ai/CodeFuse-CodeLlama-34B&#34;&gt;CodeFuse-CodeLlama-34B&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;To begin, ensure that you have successfully installed CUDA (version &amp;gt;= 11.4, preferably 11.7) along with the necessary drivers. Additionally, make sure you have installed torch (version 2.0.1).&lt;/p&gt; &#xA;&lt;p&gt;Next, we have provided an init_env.sh script to simplify the installation of required packages. Execute the following command to run the script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sh init_env.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you require flash attention, please refer to the following link for installation instructions: &lt;a href=&#34;https://github.com/Dao-AILab/flash-attention&#34;&gt;https://github.com/Dao-AILab/flash-attention&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;üöÄ &lt;a href=&#34;https://raw.githubusercontent.com/codefuse-ai/MFTCoder/main/mft_peft_hf/README.md&#34;&gt;Huggingface accelerate + deepspeed Codebase for MFT(Multi-task Finetuning)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;üöÄ &lt;a href=&#34;https://raw.githubusercontent.com/codefuse-ai/MFTCoder/main/mft_atorch/README.md&#34;&gt;Atorch Codebase for MFT(Multi-task Finetuning)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Models&lt;/h2&gt; &#xA;&lt;p&gt;We are excited to release the following two CodeLLMs trained by MFTCoder, now available on Hugging Face:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Base Model&lt;/th&gt; &#xA;   &lt;th&gt;Num of examples trained&lt;/th&gt; &#xA;   &lt;th&gt;Batch Size&lt;/th&gt; &#xA;   &lt;th&gt;Seq Length&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/codefuse-ai/CodeFuse-CodeLlama-34B&#34;&gt;üî•üî•üî• CodeFuse-CodeLlama-34B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-34b-Python&lt;/td&gt; &#xA;   &lt;td&gt;600k&lt;/td&gt; &#xA;   &lt;td&gt;80&lt;/td&gt; &#xA;   &lt;td&gt;4096&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/codefuse-ai/CodeFuse-13B&#34;&gt;üî• CodeFuse-13B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CodeFuse-13B&lt;/td&gt; &#xA;   &lt;td&gt;66k&lt;/td&gt; &#xA;   &lt;td&gt;64&lt;/td&gt; &#xA;   &lt;td&gt;4096&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Datasets&lt;/h2&gt; &#xA;&lt;p&gt;We are also pleased to release two code-related instruction datasets, meticulously selected from a range of datasets to facilitate multitask training. Moving forward, we are committed to releasing additional instruction datasets covering various code-related tasks.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Introduction&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/codefuse-ai/Evol-instruction-66k&#34;&gt;‚≠ê Evol-instruction-66k&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Based on open-evol-instruction-80k, filter out low-quality, repeated, and similar instructions to HumanEval, thus get high-quality code instruction dataset.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/codefuse-ai/CodeExercise-Python-27k&#34;&gt;‚≠ê CodeExercise-Python-27k&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;python code exercise instruction dataset generated by chatgpt&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
  <entry>
    <title>intelligent-machine-learning/dlrover</title>
    <updated>2023-09-13T01:37:25Z</updated>
    <id>tag:github.com,2023-09-13:/intelligent-machine-learning/dlrover</id>
    <link href="https://github.com/intelligent-machine-learning/dlrover" rel="alternate"></link>
    <summary type="html">&lt;p&gt;DLRover: An Automatic Distributed Deep Learning System&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DLRover&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/figures/dlrover_logo.png&#34; alt=&#34;Editor&#34; width=&#34;350&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div id=&#34;top&#34; align=&#34;center&#34;&gt;&#xA;  DLRover: An Automatic Distributed Deep Learning System &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/intelligent-machine-learning/easydl/actions/workflows/main.yml&#34;&gt;&lt;img src=&#34;https://github.com/intelligent-machine-learning/easydl/actions/workflows/main.yml/badge.svg?sanitize=true&#34; alt=&#34;Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/intelligent-machine-learning/dlrover&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/intelligent-machine-learning/dlrover/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;Code Coverage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/dlrover/&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/dlrover.svg?sanitize=true&#34; alt=&#34;PyPI Status Badge&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;DLRover makes the distributed training of large AI models easy, stable, fast and green. It can automatically train the Deep Learning model on the distributed cluster. It helps model developers to focus on model arichtecture, without taking care of any engineering stuff, say, hardware acceleration, distributed running, etc. Now, it provides automated operation and maintenance for deep learning training jobs on K8s/Ray. Major features as&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fault-Tolerance&lt;/strong&gt;, single node failover without restarting the entire job.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Auto-Scaling&lt;/strong&gt;, Automatically scale up/down resources at both node level and CPU/memory level.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Dynamic data sharding&lt;/strong&gt;, dynamic dispatch training data to each worker instead of dividing equally, faster worker more data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Automatic Resource Optimization&lt;/strong&gt;, Automatically optimize the job resource to improve the training performance and resources utilization.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Latest News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2023/08] &lt;a href=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/blogs/stabilize_llm_training_cn.md&#34;&gt;DLRover improves the stability of pre-trained model training over thousands of GPUs.&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2023/04] &lt;a href=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/blogs/deeprec_autoscale_cn.md&#34;&gt;DLRover auto-scales nodes of a DeepRec distributed training job.&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why DLRover?&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://www.bilibili.com/video/BV1Nk4y1N7fx/?vd_source=603516da01339dc75fb908e1cce180c7&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/figures/dlrover-cover.jpg&#34; width=&#34;700&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Fault Tolerance to Improve the Stability of Job&lt;/h3&gt; &#xA;&lt;p&gt;DLRover can restore the training when the process fails without stopping the training job. The actions to restore training in DLRover are:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Diagnose the failure reason.&lt;/li&gt; &#xA; &lt;li&gt;Restart the process not the node due to software errors.&lt;/li&gt; &#xA; &lt;li&gt;Restart the failed nodes due to hardward errors.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;Fault Tolerance of PyTorch Distributed Training&lt;/h4&gt; &#xA;&lt;p&gt;DLRover supports fault tolerance of the process failure and the node failure to restore trainig. Compared with restarting a new job, DLRover can reduce the overhead to schedule all Pods, pull image and install packages on all nodes.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Step to restore training&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Failure without DLRover&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Node failure with DLRover&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Process failure with DLRover&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Restore action&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Restart Job&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Restart failed nodes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Restart training process&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Schedule node, pull image and install packages&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;All nodes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Only new nodes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Node health check&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;All nodes execute a simple allgtather task&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;All nodes execute a allgtather simple task&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Build communication world&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Start training process&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Restore checkpoint&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Fault Tolerance of TensorFlow PS Distributed Training&lt;/h4&gt; &#xA;&lt;p&gt;DLRover can recover failed parameter servers and workers to resume training. Compared with manual restarting jobs, DLRover can reduce the overhead to restore the training.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Step to restore training&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Failure without DLRover&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;PS failure with DLRover&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Worker failure with DLRover&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Restore action&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Restart Job&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Restart failed PS&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Restart failed workers&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Schedule node, pull image and install packages&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;All nodes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Only new PS&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Only new workers&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Start session&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;all nodes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;all nodes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Only new workers&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Initialize Graph&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Only new workers&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Restore checkpoint&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Yes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;No&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;What&#39;s more, DLRover also can automatic diagnose the reason of failure. For example, the OOM is the common error due to user&#39;s insufficient memory configuration. DLRover can automatically launch a Pod with more memory to recover the OOM node. In AntGroup, DLRover manages hundreds of DL training jobs every day on the customized Kubernetes cluster in AntGroup. Except for the failed job resulting from code errors, the rate of completed jobs raise 89% with tf-operator in KubeFlow to 95%. Other unrecoverable failure reasons of a job are data error, NaN loss of the model, network breakdown, and so on.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/figures/job-complete-rate.png&#34; alt=&#34;Editor&#34; width=&#34;600&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;No Resource Configuration to Submit a Job&lt;/h3&gt; &#xA;&lt;p&gt;Compared with Training Job (e.g., TensorFlow, PyTorch etc) in Kubeflow, Users can submit a distributed training job without any resource configuration.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/figures/dlrover_vs_tfjob.jpg&#34; alt=&#34;Editor&#34; width=&#34;600&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Auto-Scaling to Improve Training Performance&lt;/h3&gt; &#xA;&lt;p&gt;DLRover automatically scales up/down resources (for parameter servers or workers) at the runtime of a training job. By monitoring the workload of nodes and throughput, DLRover can diagnose the bottleneck of the resource configuration. The common bottleneck contains node straggler, the unbalanced workload of PS, insufficient CPU cores of nodes, and the insufficient number of nodes. DLRover can improve the training performance by dynamic resource adjustment.&lt;/p&gt; &#xA;&lt;p&gt;We use the dataset of &lt;a href=&#34;https://www.kaggle.com/c/criteo-display-ad-challenge&#34;&gt;Kaggle CRITEO&lt;/a&gt; to train Wide&amp;amp;Deep and xDeepFM with 10 epoches on a K8s cluster. DLRover can mitigate straggler to improve the training throughput and shorten the job competion time (JCT).&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/figures/exp-jct-deepctr.png&#34; alt=&#34;Editor&#34; width=&#34;600&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Auto-Scaling to Improve Resource Utilization&lt;/h3&gt; &#xA;&lt;p&gt;Different model training requires different resources. Users prefer to configure their jobs with over-provision resources to avoid any potential risk from insufficient resources. This usually ends up in huge resource waste. DLRover Auto-Scaling can allocate resources by the demand of model training to reduce the waste of resources.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/figures/daily-job-resource-util.png&#34; alt=&#34;Editor&#34; width=&#34;1000&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Dynamic Data Sharding For Elasticity and Fault-tolerance&lt;/h3&gt; &#xA;&lt;p&gt;Dynamic data sharding splits the dataset into many small shards and each shard only contains a few batches of training samples. The worker will get a shard only when it using up samples of the last one. With the dynaic sharding, DLRover can&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;recover the shard if the worker fails before using up samples of the shard.&lt;/li&gt; &#xA; &lt;li&gt;mitigate the worker straggler by assigning more shards to the fast worker.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Integration to Offline and Online Deep Learning&lt;/h3&gt; &#xA;&lt;p&gt;With the data source transparency provided by dynamic data sharding, DLRover can be integrated with offline training which consumes batch data, and also supports online learning with real-time streaming data. (fed with a message queue like RocketMQ/Kafka/Pulsar/..., or executed as a training sink node inside Flink/Spark/Ray/...)&lt;/p&gt; &#xA;&lt;p&gt;By practice, DLRover is an ideal component to build an end-to-end industrial online learning system, &lt;a href=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/tutorial/estimator.md&#34;&gt;estimator.md&lt;/a&gt; provides a detailed example implemented with &lt;code&gt;tf.estimator.Estimator&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;How to Use DLRover to Train Your Models?&lt;/h2&gt; &#xA;&lt;p&gt;Firstly, the user need to deploy the DLRover elasticjob controller in a kubernetes cluster by followding the &lt;a href=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/deployment/controller.md&#34;&gt;tutorial&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Train a PyTorch Model&lt;/h3&gt; &#xA;&lt;p&gt;Only by 2 steps, the user can use DLRover to run the training script which &lt;code&gt;torchrun&lt;/code&gt; or &lt;code&gt;torch.distributed.run&lt;/code&gt; can run.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install dlrover[torch] in the training image with the command&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install dlrover[torch]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use &lt;code&gt;dlrover-run&lt;/code&gt; to run the training script.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;dlrover-run&#xA;    --nnodes=$NUM_NODES&#xA;    --nproc_per_node=$$NUM_TRAINERS&#xA;    train_scripts.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Set the image and command in an ElasticJob yaml file to submit a job. We can refer to the example &lt;a href=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/examples/pytorch/mnist/ddp_elastic_job.yaml&#34;&gt;torch_mnist_job.yaml&lt;/a&gt; to make an ElasticJob yaml.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Train a TensorFlow Model&lt;/h3&gt; &#xA;&lt;p&gt;We can use DLRover to train a TensorFlow by the following steps:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use TensorFlow estimator to develop the TensorFlow model.&lt;/li&gt; &#xA; &lt;li&gt;Define the input of &lt;code&gt;tf.dataset&lt;/code&gt; in a training configuration of DLRover.&lt;/li&gt; &#xA; &lt;li&gt;Define your reader to read samples from the dataset file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We can refer to the &lt;a href=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/tutorial/estimator.md&#34;&gt;estimator.md&lt;/a&gt; to train a model with DLRover.&lt;/p&gt; &#xA;&lt;h2&gt;What&#39;s Next?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fine-grained automatic distributed training for GPU Synchronous jobs &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;hybrid-parallel mode&lt;/li&gt; &#xA;   &lt;li&gt;adapted hyper parameters adjustment with dynamic resources&lt;/li&gt; &#xA;   &lt;li&gt;more strategies for Fine-grained scenarioes&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Full stack solution for Online Deep Learning&lt;/li&gt; &#xA; &lt;li&gt;High performance extension library for Tensorflow/Pytorch to speed up training&lt;/li&gt; &#xA; &lt;li&gt;...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/developer_guide.md&#34;&gt;DEVELOPMENT&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/tutorial/tf_ps_on_cloud.md&#34;&gt;Train a TensorFlow Estimator on Kubernetes&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/tutorial/torch_on_cloud.md&#34;&gt;Train a PyTorch Model on Kubernetes&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/intelligent-machine-learning/dlrover/master/docs/tutorial/torch_ddp_nanogpt.md&#34;&gt;Train a GPT Model on Kubernetes&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>