<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-07-24T01:35:00Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>sinaatalay/rendercv</title>
    <updated>2024-07-24T01:35:00Z</updated>
    <id>tag:github.com,2024-07-24:/sinaatalay/rendercv</id>
    <link href="https://github.com/sinaatalay/rendercv" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A LaTeX CV/Resume Framework&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;RenderCV&lt;/h1&gt; &#xA; &lt;p&gt;&lt;em&gt;A&lt;/em&gt; $\LaTeX$ &lt;em&gt;CV/Resume Framework&lt;/em&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/sinaatalay/rendercv/actions/workflows/test.yaml&#34;&gt;&lt;img src=&#34;https://github.com/sinaatalay/rendercv/actions/workflows/test.yaml/badge.svg?branch=main&#34; alt=&#34;test&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://coverage-badge.samuelcolvin.workers.dev/redirect/sinaatalay/rendercv&#34;&gt;&lt;img src=&#34;https://coverage-badge.samuelcolvin.workers.dev/sinaatalay/rendercv.svg?sanitize=true&#34; alt=&#34;coverage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.rendercv.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-mkdocs-rgb(0%2C79%2C144)&#34; alt=&#34;docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/rendercv&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/rendercv?label=PyPI%20version&amp;amp;color=rgb(0%2C79%2C144)&#34; alt=&#34;pypi-version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypistats.org/packages/rendercv&#34;&gt;&lt;img src=&#34;https://img.shields.io/pepy/dt/rendercv?label=PyPI%20downloads&amp;amp;color=rgb(0%2C%2079%2C%20144)&#34; alt=&#34;pypi-downloads&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;RenderCV allows you to create a high-quality CV as a PDF from a YAML input file. It supports Markdown syntax and gives you complete control over the $\LaTeX$ code.&lt;/p&gt; &#xA;&lt;p&gt;The primary motivation behind RenderCV is to provide a concrete framework that allows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Version controlling a CV&#39;s content and design separately and in an organized manner.&lt;/li&gt; &#xA; &lt;li&gt;Building an automated pipeline that updates the final output (PDF, $\LaTeX$, Markdown, HTML, and PNGs) whenever the content is modified.&lt;/li&gt; &#xA; &lt;li&gt;Making the CV&#39;s design uniform and nicely structured without room for human errors.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;RenderCV offers built-in $\LaTeX$ and Markdown templates ready to produce high-quality CVs. However, the templates are entirely arbitrary and can easily be updated to leverage RenderCV&#39;s capabilities with custom CV themes.&lt;/p&gt; &#xA;&lt;p&gt;RenderCV takes a YAML file that looks like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;cv:&#xA;  name: John Doe&#xA;  location: Your Location&#xA;  email: youremail@yourdomain.com&#xA;  sections:&#xA;    this_is_a_section_title:&#xA;      - This is a type of entry, TextEntry‚Äîjust a plain string.&#xA;      - You may have as many entries as you want under a section.&#xA;      - RenderCV offers a variety of entry types such as TextEntry,&#xA;        BulletEntry, EducationEntry, ExperienceEntry, NormalEntry,&#xA;        OneLineEntry, PublicationEntry.&#xA;      - Each entry type has its own set of attributes and different&#xA;        looks.&#xA;    my_education_section:&#xA;      - institution: Boƒüazi√ßi University&#xA;        area: Mechanical Engineering&#xA;        degree: BS&#xA;        start_date: 2024-09&#xA;        end_date: 2029-05&#xA;        highlights:&#xA;          - &#39;GPA: 3.9/4.0 ([Transcript](https://example.com))&#39;&#xA;          - &#39;**Coursework:** Structural Analysis, Thermodynamics,&#xA;            Heat Transfer&#39;&#xA;    experience:&#xA;      ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, it produces one of these PDFs with its corresponding $\LaTeX$ code, Markdown file, HTML file, and images as PNGs. Each of these is an example of one of 4 built-in themes of RenderCV. Click on the images below to preview PDF files.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/sinaatalay/rendercv/raw/main/examples/John_Doe_ClassicTheme_CV.pdf&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sinaatalay/rendercv/main/docs/assets/images/classic.png&#34; alt=&#34;Classic Theme Example of RenderCV&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/sinaatalay/rendercv/raw/main/examples/John_Doe_Sb2novTheme_CV.pdf&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sinaatalay/rendercv/main/docs/assets/images/sb2nov.png&#34; alt=&#34;Sb2nov Theme Example of RenderCV&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/sinaatalay/rendercv/raw/main/examples/John_Doe_ModerncvTheme_CV.pdf&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sinaatalay/rendercv/main/docs/assets/images/moderncv.png&#34; alt=&#34;Moderncv Theme Example of RenderCV&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/sinaatalay/rendercv/raw/main/examples/John_Doe_EngineeringresumesTheme_CV.pdf&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sinaatalay/rendercv/main/docs/assets/images/engineeringresumes.png&#34; alt=&#34;Engineeringresumes Theme Example of RenderCV&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The contents of the HTML file can be pasted into Grammarly or any word processor for spelling and grammar checking.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sinaatalay/rendercv/main/docs/assets/images/grammarly.gif&#34; alt=&#34;Grammarly for RenderCV&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;It also validates the input file. If there are any problems, it tells users where the problems are and how they can fix them.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sinaatalay/rendercv/main/docs/assets/images/cli.gif&#34; alt=&#34;CLI of RenderCV&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;RenderCV comes with a JSON Schema so that the YAML input file can be filled out interactively.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sinaatalay/rendercv/main/docs/assets/images/schema.gif&#34; alt=&#34;JSON Schema of RenderCV&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start Guide&lt;/h2&gt; &#xA;&lt;p&gt;Either use &lt;a href=&#34;https://github.com/sinaatalay/rendercv-pipeline&#34;&gt;rendercv-pipeline&lt;/a&gt; or follow the steps below.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install&amp;nbsp;&lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;Python&lt;/a&gt;&amp;nbsp;(3.10 or newer).&lt;/li&gt; &#xA; &lt;li&gt;Run the command below in a terminal to install RenderCV. &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install rendercv&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Run the command below to generate starting input files. &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;rendercv new &#34;Full Name&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Edit the contents of&amp;nbsp;&lt;code&gt;Full_Name_CV.yaml&lt;/code&gt;&amp;nbsp;in your favorite editor (&lt;em&gt;tip: use an editor that supports JSON Schemas&lt;/em&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Run the command below to generate your&amp;nbsp;CV. &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;rendercv render Full_Name_CV.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.rendercv.com/user_guide/&#34;&gt;Here&lt;/a&gt;, you can find a comprehensive user guide that covers the YAML input file structure and command-line interface (CLI) in greater detail.&lt;/p&gt; &#xA;&lt;h2&gt;Motivation&lt;/h2&gt; &#xA;&lt;p&gt;Writing the content of a CV and designing a CV are separate issues that should be treated separately. RenderCV attempts to provide this separation. This approach encourages users to concentrate on the content without getting distracted by the appearance of their CV and vice versa.&lt;/p&gt; &#xA;&lt;p&gt;RenderCV also provides a set of utilities that automate most of the manual work involved in the CV updating process. After updating a single sentence or date in the YAML input file written in pure English, RenderCV will:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Re-create your $\LaTeX$ file,&lt;/li&gt; &#xA; &lt;li&gt;Render a new PDF file,&lt;/li&gt; &#xA; &lt;li&gt;Create a new Markdown file,&lt;/li&gt; &#xA; &lt;li&gt;Create a new HTML document, and&lt;/li&gt; &#xA; &lt;li&gt;Create images of each page of the PDF file as PNGs.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Why use RenderCV instead of $\LaTeX$? I can version-control $\LaTeX$ code too!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;RenderCV is not a replacement for $\LaTeX$. It is a set of utilities designed to create and manage $\LaTeX$ CVs. If you&#39;re currently using $\LaTeX$ to create your CV, you should try RenderCV. Using your existing $\LaTeX$ themes in RenderCV is very easy.&lt;/p&gt; &#xA;&lt;p&gt;Advantages of RenderCV over using pure $\LaTeX$:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;RenderCV will separate the content of your CV from your $\LaTeX$ code. They will sit in independent files, and RenderCV will use both to generate your CV.&lt;/li&gt; &#xA; &lt;li&gt;You will be able to version-control your $\LaTeX$ code and content separately.&lt;/li&gt; &#xA; &lt;li&gt;Updating your content in a YAML file is easier than updating a complex $\LaTeX$ file.&lt;/li&gt; &#xA; &lt;li&gt;A pure $\LaTeX$ CV will have many code duplications because a CV is a document with a list of sections that contain a list of entries. RenderCV has only one $\LaTeX$ code for each entry type, duplicated automatically based on the YAML input file.&lt;/li&gt; &#xA; &lt;li&gt;Spell-checking is not very straightforward in $\LaTeX$ documents.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rendercv.com/user_guide&#34;&gt;User Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rendercv.com/developer_guide&#34;&gt;Developer Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rendercv.com/reference&#34;&gt;Overview of Source Code&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.rendercv.com/changelog&#34;&gt;Changelog&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;All contributions to RenderCV are welcome! To get started, please read &lt;a href=&#34;https://docs.rendercv.com/developer_guide&#34;&gt;the developer guide&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>neuml/txtai</title>
    <updated>2024-07-24T01:35:00Z</updated>
    <id>tag:github.com,2024-07-24:/neuml/txtai</id>
    <link href="https://github.com/neuml/txtai" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üí° All-in-one open-source embeddings database for semantic search, LLM orchestration and language model workflows&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/logo.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;b&gt;All-in-one embeddings database&lt;/b&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/neuml/txtai/releases&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/release/neuml/txtai.svg?style=flat&amp;amp;color=success&#34; alt=&#34;Version&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/neuml/txtai&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/last-commit/neuml/txtai.svg?style=flat&amp;amp;color=blue&#34; alt=&#34;GitHub last commit&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/neuml/txtai/issues&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/issues/neuml/txtai.svg?style=flat&amp;amp;color=success&#34; alt=&#34;GitHub issues&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://join.slack.com/t/txtai/shared_invite/zt-1cagya4yf-DQeuZbd~aMwH5pckBU4vPg&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/slack-join-blue?style=flat&amp;amp;logo=slack&amp;amp;logocolor=white&#34; alt=&#34;Join Slack&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/neuml/txtai/actions?query=workflow%3Abuild&#34;&gt; &lt;img src=&#34;https://github.com/neuml/txtai/workflows/build/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://coveralls.io/github/neuml/txtai?branch=master&#34;&gt; &lt;img src=&#34;https://img.shields.io/coverallsCoverage/github/neuml/txtai&#34; alt=&#34;Coverage Status&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;txtai is an all-in-one embeddings database for semantic search, LLM orchestration and language model workflows.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/architecture.png#gh-light-mode-only&#34; alt=&#34;architecture&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/architecture-dark.png#gh-dark-mode-only&#34; alt=&#34;architecture&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Embeddings databases are a union of vector indexes (sparse and dense), graph networks and relational databases. This enables vector search with SQL, topic modeling, retrieval augmented generation (RAG) and more.&lt;/p&gt; &#xA;&lt;p&gt;Embeddings databases can stand on their own and/or serve as a powerful knowledge source for large language model (LLM) prompts.&lt;/p&gt; &#xA;&lt;p&gt;Summary of txtai features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üîé Vector search with SQL, object storage, topic modeling, graph analysis and multimodal indexing&lt;/li&gt; &#xA; &lt;li&gt;üìÑ Create embeddings for text, documents, audio, images and video&lt;/li&gt; &#xA; &lt;li&gt;üí° Pipelines powered by language models that run LLM prompts, question-answering, labeling, transcription, translation, summarization and more&lt;/li&gt; &#xA; &lt;li&gt;‚Ü™Ô∏èÔ∏è Workflows to join pipelines together and aggregate business logic. txtai processes can be simple microservices or multi-model workflows.&lt;/li&gt; &#xA; &lt;li&gt;‚öôÔ∏è Build with Python or YAML. API bindings available for &lt;a href=&#34;https://github.com/neuml/txtai.js&#34;&gt;JavaScript&lt;/a&gt;, &lt;a href=&#34;https://github.com/neuml/txtai.java&#34;&gt;Java&lt;/a&gt;, &lt;a href=&#34;https://github.com/neuml/txtai.rs&#34;&gt;Rust&lt;/a&gt; and &lt;a href=&#34;https://github.com/neuml/txtai.go&#34;&gt;Go&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;‚òÅÔ∏è Run local or scale out with container orchestration&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;txtai is built with Python 3.8+, &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;Hugging Face Transformers&lt;/a&gt;, &lt;a href=&#34;https://github.com/UKPLab/sentence-transformers&#34;&gt;Sentence Transformers&lt;/a&gt; and &lt;a href=&#34;https://github.com/tiangolo/fastapi&#34;&gt;FastAPI&lt;/a&gt;. txtai is open-source under an Apache 2.0 license.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Interested in an easy and secure way to run hosted txtai applications? Then join the &lt;a href=&#34;https://txtai.cloud&#34;&gt;txtai.cloud&lt;/a&gt; preview to learn more.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Why txtai?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/why.png#gh-light-mode-only&#34; alt=&#34;why&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/why-dark.png#gh-dark-mode-only&#34; alt=&#34;why&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;New vector databases, LLM frameworks and everything in between are sprouting up daily. Why build with txtai?&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Up and running in minutes with &lt;a href=&#34;https://neuml.github.io/txtai/install/&#34;&gt;pip&lt;/a&gt; or &lt;a href=&#34;https://neuml.github.io/txtai/cloud/&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Get started in a couple lines&#xA;import txtai&#xA;&#xA;embeddings = txtai.Embeddings()&#xA;embeddings.index([&#34;Correct&#34;, &#34;Not what we hoped&#34;])&#xA;embeddings.search(&#34;positive&#34;, 1)&#xA;#[(0, 0.29862046241760254)]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Built-in API makes it easy to develop applications using your programming language of choice&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# app.yml&#xA;embeddings:&#xA;    path: sentence-transformers/all-MiniLM-L6-v2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CONFIG=app.yml uvicorn &#34;txtai.api:app&#34;&#xA;curl -X GET &#34;http://localhost:8000/search?query=positive&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run local - no need to ship data off to disparate remote services&lt;/li&gt; &#xA; &lt;li&gt;Work with micromodels all the way up to large language models (LLMs)&lt;/li&gt; &#xA; &lt;li&gt;Low footprint - install additional dependencies and scale up when needed&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://neuml.github.io/txtai/examples&#34;&gt;Learn by example&lt;/a&gt; - notebooks cover all available functionality&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Use Cases&lt;/h2&gt; &#xA;&lt;p&gt;The following sections introduce common txtai use cases. A comprehensive set of over 50 &lt;a href=&#34;https://neuml.github.io/txtai/examples&#34;&gt;example notebooks and applications&lt;/a&gt; are also available.&lt;/p&gt; &#xA;&lt;h3&gt;Semantic Search&lt;/h3&gt; &#xA;&lt;p&gt;Build semantic/similarity/vector/neural search applications.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/demo.gif&#34; alt=&#34;demo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Traditional search systems use keywords to find data. Semantic search has an understanding of natural language and identifies results that have the same meaning, not necessarily the same keywords.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/search.png#gh-light-mode-only&#34; alt=&#34;search&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/search-dark.png#gh-dark-mode-only&#34; alt=&#34;search&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Get started with the following examples.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Notebook&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/01_Introducing_txtai.ipynb&#34;&gt;Introducing txtai&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=SIezMnVdmMs&#34;&gt;‚ñ∂Ô∏è&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Overview of the functionality provided by txtai&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/01_Introducing_txtai.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/13_Similarity_search_with_images.ipynb&#34;&gt;Similarity search with images&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Embed images and text into the same space for search&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/13_Similarity_search_with_images.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/34_Build_a_QA_database.ipynb&#34;&gt;Build a QA database&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Question matching with semantic search&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/34_Build_a_QA_database.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/38_Introducing_the_Semantic_Graph.ipynb&#34;&gt;Semantic Graphs&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Explore topics, data connectivity and run network analysis&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/38_Introducing_the_Semantic_Graph.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;LLM Orchestration&lt;/h3&gt; &#xA;&lt;p&gt;LLM chains, retrieval augmented generation (RAG), chat with your data, pipelines and workflows that interface with large language models (LLMs).&lt;/p&gt; &#xA;&lt;h4&gt;Chains&lt;/h4&gt; &#xA;&lt;p&gt;Integrate LLM chains (known as workflows in txtai), multiple LLM agents and self-critique.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/llm.png&#34; alt=&#34;llm&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;See below to learn more.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Notebook&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/44_Prompt_templates_and_task_chains.ipynb&#34;&gt;Prompt templates and task chains&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Build model prompts and connect tasks together with workflows&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/44_Prompt_templates_and_task_chains.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/53_Integrate_LLM_Frameworks.ipynb&#34;&gt;Integrate LLM frameworks&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Integrate llama.cpp, LiteLLM and custom generation frameworks&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/53_Integrate_LLM_Frameworks.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/57_Build_knowledge_graphs_with_LLM_driven_entity_extraction.ipynb&#34;&gt;Build knowledge graphs with LLMs&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Build knowledge graphs with LLM-driven entity extraction&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/57_Build_knowledge_graphs_with_LLM_driven_entity_extraction.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Retrieval augmented generation&lt;/h4&gt; &#xA;&lt;p&gt;Retrieval augmented generation (RAG) reduces the risk of LLM hallucinations by constraining the output with a knowledge base as context. RAG is commonly used to &#34;chat with your data&#34;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/rag.png#gh-light-mode-only&#34; alt=&#34;rag&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/rag-dark.png#gh-dark-mode-only&#34; alt=&#34;rag&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;A novel feature of txtai is that it can provide both an answer and source citation.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Notebook&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/52_Build_RAG_pipelines_with_txtai.ipynb&#34;&gt;Build RAG pipelines with txtai&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Guide on retrieval augmented generation including how to create citations&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/52_Build_RAG_pipelines_with_txtai.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/63_How_RAG_with_txtai_works.ipynb&#34;&gt;How RAG with txtai works&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Create RAG processes, API services and Docker instances&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/63_How_RAG_with_txtai_works.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/58_Advanced_RAG_with_graph_path_traversal.ipynb&#34;&gt;Advanced RAG with graph path traversal&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Graph path traversal to collect complex sets of data for advanced RAG&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/58_Advanced_RAG_with_graph_path_traversal.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/60_Advanced_RAG_with_guided_generation.ipynb&#34;&gt;Advanced RAG with guided generation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Retrieval Augmented and Guided Generation&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/60_Advanced_RAG_with_guided_generation.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Language Model Workflows&lt;/h3&gt; &#xA;&lt;p&gt;Language model workflows, also known as semantic workflows, connect language models together to build intelligent applications.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/flows.png#gh-light-mode-only&#34; alt=&#34;flows&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/flows-dark.png#gh-dark-mode-only&#34; alt=&#34;flows&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;While LLMs are powerful, there are plenty of smaller, more specialized models that work better and faster for specific tasks. This includes models for extractive question-answering, automatic summarization, text-to-speech, transcription and translation.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Notebook&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/14_Run_pipeline_workflows.ipynb&#34;&gt;Run pipeline workflows&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=UBMPDCn1gEU&#34;&gt;‚ñ∂Ô∏è&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Simple yet powerful constructs to efficiently process data&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/14_Run_pipeline_workflows.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/09_Building_abstractive_text_summaries.ipynb&#34;&gt;Building abstractive text summaries&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Run abstractive text summarization&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/09_Building_abstractive_text_summaries.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/11_Transcribe_audio_to_text.ipynb&#34;&gt;Transcribe audio to text&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Convert audio files to text&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/11_Transcribe_audio_to_text.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtai/raw/master/examples/12_Translate_text_between_languages.ipynb&#34;&gt;Translate text between languages&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Streamline machine translation and language detection&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/neuml/txtai/blob/master/examples/12_Translate_text_between_languages.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/install.png#gh-light-mode-only&#34; alt=&#34;install&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/install-dark.png#gh-dark-mode-only&#34; alt=&#34;install&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The easiest way to install is via pip and PyPI&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install txtai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Python 3.8+ is supported. Using a Python &lt;a href=&#34;https://docs.python.org/3/library/venv.html&#34;&gt;virtual environment&lt;/a&gt; is recommended.&lt;/p&gt; &#xA;&lt;p&gt;See the detailed &lt;a href=&#34;https://neuml.github.io/txtai/install&#34;&gt;install instructions&lt;/a&gt; for more information covering &lt;a href=&#34;https://neuml.github.io/txtai/install/#optional-dependencies&#34;&gt;optional dependencies&lt;/a&gt;, &lt;a href=&#34;https://neuml.github.io/txtai/install/#environment-specific-prerequisites&#34;&gt;environment specific prerequisites&lt;/a&gt;, &lt;a href=&#34;https://neuml.github.io/txtai/install/#install-from-source&#34;&gt;installing from source&lt;/a&gt;, &lt;a href=&#34;https://neuml.github.io/txtai/install/#conda&#34;&gt;conda support&lt;/a&gt; and how to &lt;a href=&#34;https://neuml.github.io/txtai/cloud&#34;&gt;run with containers&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Model guide&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/models.png&#34; alt=&#34;models&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;See the table below for the current recommended models. These models all allow commercial use and offer a blend of speed and performance.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Component&lt;/th&gt; &#xA;   &lt;th&gt;Model(s)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://neuml.github.io/txtai/embeddings&#34;&gt;Embeddings&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://hf.co/sentence-transformers/all-MiniLM-L6-v2&#34;&gt;all-MiniLM-L6-v2&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://neuml.github.io/txtai/pipeline/image/caption&#34;&gt;Image Captions&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://hf.co/Salesforce/blip-image-captioning-base&#34;&gt;BLIP&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://neuml.github.io/txtai/pipeline/text/labels&#34;&gt;Labels - Zero Shot&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://hf.co/facebook/bart-large&#34;&gt;BART-Large-MNLI&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://neuml.github.io/txtai/pipeline/text/labels&#34;&gt;Labels - Fixed&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Fine-tune with &lt;a href=&#34;https://neuml.github.io/txtai/pipeline/train/trainer&#34;&gt;training pipeline&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://neuml.github.io/txtai/pipeline/text/llm&#34;&gt;Large Language Model (LLM)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://hf.co/Open-Orca/Mistral-7B-OpenOrca&#34;&gt;Mistral 7B OpenOrca&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://neuml.github.io/txtai/pipeline/text/summary&#34;&gt;Summarization&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://hf.co/sshleifer/distilbart-cnn-12-6&#34;&gt;DistilBART&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://neuml.github.io/txtai/pipeline/audio/texttospeech&#34;&gt;Text-to-Speech&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://hf.co/NeuML/ljspeech-jets-onnx&#34;&gt;ESPnet JETS&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://neuml.github.io/txtai/pipeline/audio/transcription&#34;&gt;Transcription&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://hf.co/openai/whisper-base&#34;&gt;Whisper&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://neuml.github.io/txtai/pipeline/text/translation&#34;&gt;Translation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://hf.co/Helsinki-NLP&#34;&gt;OPUS Model Series&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Models can be loaded as either a path from the Hugging Face Hub or a local directory. Model paths are optional, defaults are loaded when not specified. For tasks with no recommended model, txtai uses the default models as shown in the Hugging Face Tasks guide.&lt;/p&gt; &#xA;&lt;p&gt;See the following links to learn more.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hf.co/tasks&#34;&gt;Hugging Face Tasks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hf.co/models&#34;&gt;Hugging Face Model Hub&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hf.co/spaces/mteb/leaderboard&#34;&gt;MTEB Leaderboard&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://chat.lmsys.org/?leaderboard&#34;&gt;LMSYS LLM Leaderboard&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hf.co/spaces/HuggingFaceH4/open_llm_leaderboard&#34;&gt;Open LLM Leaderboard&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Powered by txtai&lt;/h2&gt; &#xA;&lt;p&gt;The following applications are powered by txtai.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/apps.jpg&#34; alt=&#34;apps&#34;&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Application&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/txtchat&#34;&gt;txtchat&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Retrieval Augmented Generation (RAG) powered search&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/paperai&#34;&gt;paperai&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Semantic search and workflows for medical/scientific papers&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/codequestion&#34;&gt;codequestion&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Semantic search for developers&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/neuml/tldrstory&#34;&gt;tldrstory&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Semantic search for headlines and story text&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;In addition to this list, there are also many other &lt;a href=&#34;https://github.com/neuml/txtai/network/dependents&#34;&gt;open-source projects&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/scholar?q=txtai&amp;amp;hl=en&amp;amp;as_ylo=2022&#34;&gt;published research&lt;/a&gt; and closed proprietary/commercial projects that have built on txtai in production.&lt;/p&gt; &#xA;&lt;h2&gt;Further Reading&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/further.png#gh-light-mode-only&#34; alt=&#34;further&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/neuml/txtai/master/docs/images/further-ghdark.png#gh-dark-mode-only&#34; alt=&#34;further&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/neuml/introducing-txtai-the-all-in-one-embeddings-database-c721f4ff91ad&#34;&gt;Introducing txtai, the all-in-one embeddings database&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://neuml.hashnode.dev/series/txtai-tutorial&#34;&gt;Tutorial series on Hashnode&lt;/a&gt; | &lt;a href=&#34;https://dev.to/neuml/tutorial-series-on-txtai-ibg&#34;&gt;dev.to&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/neuml/whats-new-in-txtai-7-0-855ad6a55440&#34;&gt;What&#39;s new in txtai 7.0&lt;/a&gt; | &lt;a href=&#34;https://medium.com/neuml/whats-new-in-txtai-6-0-7d93eeedf804&#34;&gt;6.0&lt;/a&gt; | &lt;a href=&#34;https://medium.com/neuml/whats-new-in-txtai-5-0-e5c75a13b101&#34;&gt;5.0&lt;/a&gt; | &lt;a href=&#34;https://medium.com/neuml/whats-new-in-txtai-4-0-bbc3a65c3d1c&#34;&gt;4.0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/neuml/getting-started-with-semantic-search-a9fd9d8a48cf&#34;&gt;Getting started with semantic search&lt;/a&gt; | &lt;a href=&#34;https://medium.com/neuml/getting-started-with-semantic-workflows-2fefda6165d9&#34;&gt;workflows&lt;/a&gt; | &lt;a href=&#34;https://medium.com/neuml/getting-started-with-rag-9a0cca75f748&#34;&gt;rag&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/neuml/running-at-scale-with-txtai-71196cdd99f9&#34;&gt;Running txtai at scale&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/neuml/vector-search-rag-landscape-a-review-with-txtai-a7f37ad0e187&#34;&gt;Vector search &amp;amp; RAG Landscape: A review with txtai&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://neuml.github.io/txtai&#34;&gt;Full documentation on txtai&lt;/a&gt; including configuration settings for embeddings, pipelines, workflows, API and a FAQ with common questions/issues is available.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;For those who would like to contribute to txtai, please see &lt;a href=&#34;https://github.com/neuml/.github/raw/master/CONTRIBUTING.md&#34;&gt;this guide&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>