<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-05T01:43:33Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>binary-husky/gpt_academic</title>
    <updated>2023-07-05T01:43:33Z</updated>
    <id>tag:github.com,2023-07-05:/binary-husky/gpt_academic</id>
    <link href="https://github.com/binary-husky/gpt_academic" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ä¸ºChatGPT/GLMæä¾›å›¾å½¢äº¤äº’ç•Œé¢ï¼Œç‰¹åˆ«ä¼˜åŒ–è®ºæ–‡é˜…è¯»/æ¶¦è‰²/å†™ä½œä½“éªŒï¼Œæ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒè‡ªå®šä¹‰å¿«æ·æŒ‰é’®&amp;å‡½æ•°æ’ä»¶ï¼Œæ”¯æŒPythonå’ŒC++ç­‰é¡¹ç›®å‰–æ&amp;è‡ªè¯‘è§£åŠŸèƒ½ï¼ŒPDF/LaTexè®ºæ–‡ç¿»è¯‘&amp;æ€»ç»“åŠŸèƒ½ï¼Œæ”¯æŒå¹¶è¡Œé—®è¯¢å¤šç§LLMæ¨¡å‹ï¼Œæ”¯æŒæ¸…åchatglmç­‰æœ¬åœ°æ¨¡å‹ã€‚å…¼å®¹å¤æ—¦MOSS, llama, rwkv, ç›˜å¤, newbing, claudeç­‰&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;2023.5.27 å¯¹Gradioä¾èµ–è¿›è¡Œäº†è°ƒæ•´ï¼ŒForkå¹¶è§£å†³äº†å®˜æ–¹Gradioçš„è‹¥å¹²Bugsã€‚è¯·åŠæ—¶&lt;strong&gt;æ›´æ–°ä»£ç &lt;/strong&gt;å¹¶é‡æ–°æ›´æ–°pipä¾èµ–ã€‚å®‰è£…ä¾èµ–æ—¶ï¼Œè¯·ä¸¥æ ¼é€‰æ‹©&lt;code&gt;requirements.txt&lt;/code&gt;ä¸­&lt;strong&gt;æŒ‡å®šçš„ç‰ˆæœ¬&lt;/strong&gt;ï¼š&lt;/p&gt; &#xA; &lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;&lt;img src=&#34;https://raw.githubusercontent.com/binary-husky/gpt_academic/master/docs/logo.png&#34; width=&#34;40&#34;&gt; GPT å­¦æœ¯ä¼˜åŒ– (GPT Academic)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;å¦‚æœå–œæ¬¢è¿™ä¸ªé¡¹ç›®ï¼Œè¯·ç»™å®ƒä¸€ä¸ªStarï¼›å¦‚æœä½ å‘æ˜äº†æ›´å¥½ç”¨çš„å¿«æ·é”®æˆ–å‡½æ•°æ’ä»¶ï¼Œæ¬¢è¿å‘pull requests&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you like this project, please give it a Star. If you&#39;ve come up with more useful academic shortcuts or functional plugins, feel free to open an issue or pull request. We also have a README in &lt;a href=&#34;https://raw.githubusercontent.com/binary-husky/gpt_academic/master/docs/README_EN.md&#34;&gt;English|&lt;/a&gt;&lt;a href=&#34;https://raw.githubusercontent.com/binary-husky/gpt_academic/master/docs/README_JP.md&#34;&gt;æ—¥æœ¬èª|&lt;/a&gt;&lt;a href=&#34;https://github.com/mldljyh/ko_gpt_academic&#34;&gt;í•œêµ­ì–´|&lt;/a&gt;&lt;a href=&#34;https://raw.githubusercontent.com/binary-husky/gpt_academic/master/docs/README_RS.md&#34;&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹|&lt;/a&gt;&lt;a href=&#34;https://raw.githubusercontent.com/binary-husky/gpt_academic/master/docs/README_FR.md&#34;&gt;FranÃ§ais&lt;/a&gt; translated by this project itself. To translate this project to arbitary language with GPT, read and run &lt;a href=&#34;https://raw.githubusercontent.com/binary-husky/gpt_academic/master/multi_language.py&#34;&gt;&lt;code&gt;multi_language.py&lt;/code&gt;&lt;/a&gt; (experimental).&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;1.è¯·æ³¨æ„åªæœ‰&lt;strong&gt;çº¢é¢œè‰²&lt;/strong&gt;æ ‡è¯†çš„å‡½æ•°æ’ä»¶ï¼ˆæŒ‰é’®ï¼‰æ‰æ”¯æŒè¯»å–æ–‡ä»¶ï¼Œéƒ¨åˆ†æ’ä»¶ä½äºæ’ä»¶åŒºçš„&lt;strong&gt;ä¸‹æ‹‰èœå•&lt;/strong&gt;ä¸­ã€‚å¦å¤–æˆ‘ä»¬ä»¥&lt;strong&gt;æœ€é«˜ä¼˜å…ˆçº§&lt;/strong&gt;æ¬¢è¿å’Œå¤„ç†ä»»ä½•æ–°æ’ä»¶çš„PRï¼&lt;/p&gt; &#xA; &lt;p&gt;2.æœ¬é¡¹ç›®ä¸­æ¯ä¸ªæ–‡ä»¶çš„åŠŸèƒ½éƒ½åœ¨è‡ªè¯‘è§£&lt;a href=&#34;https://github.com/binary-husky/gpt_academic/wiki/chatgpt-academic%E9%A1%B9%E7%9B%AE%E8%87%AA%E8%AF%91%E8%A7%A3%E6%8A%A5%E5%91%8A&#34;&gt;&lt;code&gt;self_analysis.md&lt;/code&gt;&lt;/a&gt;è¯¦ç»†è¯´æ˜ã€‚éšç€ç‰ˆæœ¬çš„è¿­ä»£ï¼Œæ‚¨ä¹Ÿå¯ä»¥éšæ—¶è‡ªè¡Œç‚¹å‡»ç›¸å…³å‡½æ•°æ’ä»¶ï¼Œè°ƒç”¨GPTé‡æ–°ç”Ÿæˆé¡¹ç›®çš„è‡ªæˆ‘è§£ææŠ¥å‘Šã€‚å¸¸è§é—®é¢˜æ±‡æ€»åœ¨&lt;a href=&#34;https://github.com/binary-husky/gpt_academic/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98&#34;&gt;&lt;code&gt;wiki&lt;/code&gt;&lt;/a&gt;å½“ä¸­ã€‚&lt;a href=&#34;https://raw.githubusercontent.com/binary-husky/gpt_academic/master/#installation&#34;&gt;å®‰è£…æ–¹æ³•&lt;/a&gt;ã€‚&lt;/p&gt; &#xA; &lt;p&gt;3.æœ¬é¡¹ç›®å…¼å®¹å¹¶é¼“åŠ±å°è¯•å›½äº§å¤§è¯­è¨€æ¨¡å‹chatglmå’ŒRWKV, ç›˜å¤ç­‰ç­‰ã€‚æ”¯æŒå¤šä¸ªapi-keyå…±å­˜ï¼Œå¯åœ¨é…ç½®æ–‡ä»¶ä¸­å¡«å†™å¦‚&lt;code&gt;API_KEY=&#34;openai-key1,openai-key2,api2d-key3&#34;&lt;/code&gt;ã€‚éœ€è¦ä¸´æ—¶æ›´æ¢&lt;code&gt;API_KEY&lt;/code&gt;æ—¶ï¼Œåœ¨è¾“å…¥åŒºè¾“å…¥ä¸´æ—¶çš„&lt;code&gt;API_KEY&lt;/code&gt;ç„¶åå›è½¦é”®æäº¤åå³å¯ç”Ÿæ•ˆã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;åŠŸèƒ½&lt;/th&gt; &#xA;    &lt;th&gt;æè¿°&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;ä¸€é”®æ¶¦è‰²&lt;/td&gt; &#xA;    &lt;td&gt;æ”¯æŒä¸€é”®æ¶¦è‰²ã€ä¸€é”®æŸ¥æ‰¾è®ºæ–‡è¯­æ³•é”™è¯¯&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;ä¸€é”®ä¸­è‹±äº’è¯‘&lt;/td&gt; &#xA;    &lt;td&gt;ä¸€é”®ä¸­è‹±äº’è¯‘&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;ä¸€é”®ä»£ç è§£é‡Š&lt;/td&gt; &#xA;    &lt;td&gt;æ˜¾ç¤ºä»£ç ã€è§£é‡Šä»£ç ã€ç”Ÿæˆä»£ç ã€ç»™ä»£ç åŠ æ³¨é‡Š&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV14s4y1E7jN&#34;&gt;è‡ªå®šä¹‰å¿«æ·é”®&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;æ”¯æŒè‡ªå®šä¹‰å¿«æ·é”®&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;æ¨¡å—åŒ–è®¾è®¡&lt;/td&gt; &#xA;    &lt;td&gt;æ”¯æŒè‡ªå®šä¹‰å¼ºå¤§çš„&lt;a href=&#34;https://github.com/binary-husky/gpt_academic/tree/master/crazy_functions&#34;&gt;å‡½æ•°æ’ä»¶&lt;/a&gt;ï¼Œæ’ä»¶æ”¯æŒ&lt;a href=&#34;https://github.com/binary-husky/gpt_academic/wiki/%E5%87%BD%E6%95%B0%E6%8F%92%E4%BB%B6%E6%8C%87%E5%8D%97&#34;&gt;çƒ­æ›´æ–°&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1cj411A7VW&#34;&gt;è‡ªæˆ‘ç¨‹åºå‰–æ&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;[å‡½æ•°æ’ä»¶] &lt;a href=&#34;https://github.com/binary-husky/gpt_academic/wiki/chatgpt-academic%E9%A1%B9%E7%9B%AE%E8%87%AA%E8%AF%91%E8%A7%A3%E6%8A%A5%E5%91%8A&#34;&gt;ä¸€é”®è¯»æ‡‚&lt;/a&gt;æœ¬é¡¹ç›®çš„æºä»£ç &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1cj411A7VW&#34;&gt;ç¨‹åºå‰–æ&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;[å‡½æ•°æ’ä»¶] ä¸€é”®å¯ä»¥å‰–æå…¶ä»–Python/C/C++/Java/Lua/...é¡¹ç›®æ ‘&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;è¯»è®ºæ–‡ã€&lt;a href=&#34;https://www.bilibili.com/video/BV1KT411x7Wn&#34;&gt;ç¿»è¯‘&lt;/a&gt;è®ºæ–‡&lt;/td&gt; &#xA;    &lt;td&gt;[å‡½æ•°æ’ä»¶] ä¸€é”®è§£è¯»latex/pdfè®ºæ–‡å…¨æ–‡å¹¶ç”Ÿæˆæ‘˜è¦&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Latexå…¨æ–‡&lt;a href=&#34;https://www.bilibili.com/video/BV1nk4y1Y7Js/&#34;&gt;ç¿»è¯‘&lt;/a&gt;ã€&lt;a href=&#34;https://www.bilibili.com/video/BV1FT411H7c5/&#34;&gt;æ¶¦è‰²&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;[å‡½æ•°æ’ä»¶] ä¸€é”®ç¿»è¯‘æˆ–æ¶¦è‰²latexè®ºæ–‡&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;æ‰¹é‡æ³¨é‡Šç”Ÿæˆ&lt;/td&gt; &#xA;    &lt;td&gt;[å‡½æ•°æ’ä»¶] ä¸€é”®æ‰¹é‡ç”Ÿæˆå‡½æ•°æ³¨é‡Š&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Markdown&lt;a href=&#34;https://www.bilibili.com/video/BV1yo4y157jV/&#34;&gt;ä¸­è‹±äº’è¯‘&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;[å‡½æ•°æ’ä»¶] çœ‹åˆ°ä¸Šé¢5ç§è¯­è¨€çš„&lt;a href=&#34;https://github.com/binary-husky/gpt_academic/raw/master/docs/README_EN.md&#34;&gt;README&lt;/a&gt;äº†å—ï¼Ÿ&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;chatåˆ†ææŠ¥å‘Šç”Ÿæˆ&lt;/td&gt; &#xA;    &lt;td&gt;[å‡½æ•°æ’ä»¶] è¿è¡Œåè‡ªåŠ¨ç”Ÿæˆæ€»ç»“æ±‡æŠ¥&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1KT411x7Wn&#34;&gt;PDFè®ºæ–‡å…¨æ–‡ç¿»è¯‘åŠŸèƒ½&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;[å‡½æ•°æ’ä»¶] PDFè®ºæ–‡æå–é¢˜ç›®&amp;amp;æ‘˜è¦+ç¿»è¯‘å…¨æ–‡ï¼ˆå¤šçº¿ç¨‹ï¼‰&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1LM4y1279X&#34;&gt;Arxivå°åŠ©æ‰‹&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;[å‡½æ•°æ’ä»¶] è¾“å…¥arxivæ–‡ç« urlå³å¯ä¸€é”®ç¿»è¯‘æ‘˜è¦+ä¸‹è½½PDF&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV19L411U7ia&#34;&gt;è°·æ­Œå­¦æœ¯ç»Ÿåˆå°åŠ©æ‰‹&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;[å‡½æ•°æ’ä»¶] ç»™å®šä»»æ„è°·æ­Œå­¦æœ¯æœç´¢é¡µé¢URLï¼Œè®©gptå¸®ä½ &lt;a href=&#34;https://www.bilibili.com/video/BV1GP411U7Az/&#34;&gt;å†™relatedworks&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;äº’è”ç½‘ä¿¡æ¯èšåˆ+GPT&lt;/td&gt; &#xA;    &lt;td&gt;[å‡½æ•°æ’ä»¶] ä¸€é”®&lt;a href=&#34;https://www.bilibili.com/video/BV1om4y127ck&#34;&gt;è®©GPTå…ˆä»äº’è”ç½‘è·å–ä¿¡æ¯&lt;/a&gt;ï¼Œå†å›ç­”é—®é¢˜ï¼Œè®©ä¿¡æ¯æ°¸ä¸è¿‡æ—¶&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;â­Arxivè®ºæ–‡ç²¾ç»†ç¿»è¯‘&lt;/td&gt; &#xA;    &lt;td&gt;[å‡½æ•°æ’ä»¶] ä¸€é”®&lt;a href=&#34;https://www.bilibili.com/video/BV1dz4y1v77A/&#34;&gt;ä»¥è¶…é«˜è´¨é‡ç¿»è¯‘arxivè®ºæ–‡&lt;/a&gt;ï¼Œè¿„ä»Šä¸ºæ­¢æœ€å¥½çš„è®ºæ–‡ç¿»è¯‘å·¥å…·â­&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;å…¬å¼/å›¾ç‰‡/è¡¨æ ¼æ˜¾ç¤º&lt;/td&gt; &#xA;    &lt;td&gt;å¯ä»¥åŒæ—¶æ˜¾ç¤ºå…¬å¼çš„&lt;a href=&#34;https://user-images.githubusercontent.com/96192199/230598842-1d7fcddd-815d-40ee-af60-baf488a199df.png&#34;&gt;texå½¢å¼å’Œæ¸²æŸ“å½¢å¼&lt;/a&gt;ï¼Œæ”¯æŒå…¬å¼ã€ä»£ç é«˜äº®&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;å¤šçº¿ç¨‹å‡½æ•°æ’ä»¶æ”¯æŒ&lt;/td&gt; &#xA;    &lt;td&gt;æ”¯æŒå¤šçº¿è°ƒç”¨chatgptï¼Œä¸€é”®å¤„ç†&lt;a href=&#34;https://www.bilibili.com/video/BV1FT411H7c5/&#34;&gt;æµ·é‡æ–‡æœ¬&lt;/a&gt;æˆ–ç¨‹åº&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;å¯åŠ¨æš—è‰²gradio&lt;a href=&#34;https://github.com/binary-husky/gpt_academic/issues/173&#34;&gt;ä¸»é¢˜&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;åœ¨æµè§ˆå™¨urlåé¢æ·»åŠ &lt;code&gt;/?__theme=dark&lt;/code&gt;å¯ä»¥åˆ‡æ¢darkä¸»é¢˜&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1wT411p7yf&#34;&gt;å¤šLLMæ¨¡å‹&lt;/a&gt;æ”¯æŒ&lt;/td&gt; &#xA;    &lt;td&gt;åŒæ—¶è¢«GPT3.5ã€GPT4ã€&lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34;&gt;æ¸…åChatGLM&lt;/a&gt;ã€&lt;a href=&#34;https://github.com/OpenLMLab/MOSS&#34;&gt;å¤æ—¦MOSS&lt;/a&gt;åŒæ—¶ä¼ºå€™çš„æ„Ÿè§‰ä¸€å®šä¼šå¾ˆä¸é”™å§ï¼Ÿ&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;æ›´å¤šLLMæ¨¡å‹æ¥å…¥ï¼Œæ”¯æŒ&lt;a href=&#34;https://huggingface.co/spaces/qingxu98/gpt-academic&#34;&gt;huggingfaceéƒ¨ç½²&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;åŠ å…¥Newbingæ¥å£(æ–°å¿…åº”)ï¼Œå¼•å…¥æ¸…å&lt;a href=&#34;https://github.com/Jittor/JittorLLMs&#34;&gt;Jittorllms&lt;/a&gt;æ”¯æŒ&lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;LLaMA&lt;/a&gt;ï¼Œ&lt;a href=&#34;https://github.com/BlinkDL/ChatRWKV&#34;&gt;RWKV&lt;/a&gt;å’Œ&lt;a href=&#34;https://openi.org.cn/pangu/&#34;&gt;ç›˜å¤Î±&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;æ›´å¤šæ–°åŠŸèƒ½å±•ç¤º(å›¾åƒç”Ÿæˆç­‰) â€¦â€¦&lt;/td&gt; &#xA;    &lt;td&gt;è§æœ¬æ–‡æ¡£ç»“å°¾å¤„ â€¦â€¦&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æ–°ç•Œé¢ï¼ˆä¿®æ”¹&lt;code&gt;config.py&lt;/code&gt;ä¸­çš„LAYOUTé€‰é¡¹å³å¯å®ç°â€œå·¦å³å¸ƒå±€â€å’Œâ€œä¸Šä¸‹å¸ƒå±€â€çš„åˆ‡æ¢ï¼‰&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/230361456-61078362-a966-4eb5-b49e-3c62ef18b860.gif&#34; width=&#34;700&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æ‰€æœ‰æŒ‰é’®éƒ½é€šè¿‡è¯»å–functional.pyåŠ¨æ€ç”Ÿæˆï¼Œå¯éšæ„åŠ è‡ªå®šä¹‰åŠŸèƒ½ï¼Œè§£æ”¾ç²˜è´´æ¿&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/231975334-b4788e91-4887-412f-8b43-2b9c5f41d248.gif&#34; width=&#34;700&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æ¶¦è‰²/çº é”™&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/231980294-f374bdcb-3309-4560-b424-38ef39f04ebd.gif&#34; width=&#34;700&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;å¦‚æœè¾“å‡ºåŒ…å«å…¬å¼ï¼Œä¼šåŒæ—¶ä»¥texå½¢å¼å’Œæ¸²æŸ“å½¢å¼æ˜¾ç¤ºï¼Œæ–¹ä¾¿å¤åˆ¶å’Œé˜…è¯»&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/230598842-1d7fcddd-815d-40ee-af60-baf488a199df.png&#34; width=&#34;700&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æ‡’å¾—çœ‹é¡¹ç›®ä»£ç ï¼Ÿæ•´ä¸ªå·¥ç¨‹ç›´æ¥ç»™chatgptç‚«å˜´é‡Œ&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/226935232-6b6a73ce-8900-4aee-93f9-733c7e6fef53.png&#34; width=&#34;700&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;å¤šç§å¤§è¯­è¨€æ¨¡å‹æ··åˆè°ƒç”¨ï¼ˆChatGLM + OpenAI-GPT3.5 + &lt;a href=&#34;https://api2d.com/&#34;&gt;API2D&lt;/a&gt;-GPT4ï¼‰&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/232537274-deca0563-7aa6-4b5d-94a2-b7c453c47794.png&#34; width=&#34;700&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;h2&gt;å®‰è£…-æ–¹æ³•1ï¼šç›´æ¥è¿è¡Œ (Windows, Linux or MacOS)&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ä¸‹è½½é¡¹ç›®&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/binary-husky/gpt_academic.git&#xA;cd gpt_academic&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;é…ç½®API_KEY&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;åœ¨&lt;code&gt;config.py&lt;/code&gt;ä¸­ï¼Œé…ç½®API KEYç­‰è®¾ç½®ï¼Œ&lt;a href=&#34;https://github.com/binary-husky/gpt_academic/issues/1&#34;&gt;ç‚¹å‡»æŸ¥çœ‹ç‰¹æ®Šç½‘ç»œç¯å¢ƒè®¾ç½®æ–¹æ³•&lt;/a&gt; ã€‚&lt;/p&gt; &#xA;&lt;p&gt;(P.S. ç¨‹åºè¿è¡Œæ—¶ä¼šä¼˜å…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨åä¸º&lt;code&gt;config_private.py&lt;/code&gt;çš„ç§å¯†é…ç½®æ–‡ä»¶ï¼Œå¹¶ç”¨å…¶ä¸­çš„é…ç½®è¦†ç›–&lt;code&gt;config.py&lt;/code&gt;çš„åŒåé…ç½®ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨èƒ½ç†è§£æˆ‘ä»¬çš„é…ç½®è¯»å–é€»è¾‘ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‚¨åœ¨&lt;code&gt;config.py&lt;/code&gt;æ—è¾¹åˆ›å»ºä¸€ä¸ªåä¸º&lt;code&gt;config_private.py&lt;/code&gt;çš„æ–°é…ç½®æ–‡ä»¶ï¼Œå¹¶æŠŠ&lt;code&gt;config.py&lt;/code&gt;ä¸­çš„é…ç½®è½¬ç§»ï¼ˆå¤åˆ¶ï¼‰åˆ°&lt;code&gt;config_private.py&lt;/code&gt;ä¸­ã€‚&lt;code&gt;config_private.py&lt;/code&gt;ä¸å—gitç®¡æ§ï¼Œå¯ä»¥è®©æ‚¨çš„éšç§ä¿¡æ¯æ›´åŠ å®‰å…¨ã€‚P.S.é¡¹ç›®åŒæ ·æ”¯æŒé€šè¿‡&lt;code&gt;ç¯å¢ƒå˜é‡&lt;/code&gt;é…ç½®å¤§å¤šæ•°é€‰é¡¹ï¼Œç¯å¢ƒå˜é‡çš„ä¹¦å†™æ ¼å¼å‚è€ƒ&lt;code&gt;docker-compose&lt;/code&gt;æ–‡ä»¶ã€‚è¯»å–ä¼˜å…ˆçº§: &lt;code&gt;ç¯å¢ƒå˜é‡&lt;/code&gt; &amp;gt; &lt;code&gt;config_private.py&lt;/code&gt; &amp;gt; &lt;code&gt;config.py&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;å®‰è£…ä¾èµ–&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# ï¼ˆé€‰æ‹©I: å¦‚ç†Ÿæ‚‰pythonï¼‰ï¼ˆpythonç‰ˆæœ¬3.9ä»¥ä¸Šï¼Œè¶Šæ–°è¶Šå¥½ï¼‰ï¼Œå¤‡æ³¨ï¼šä½¿ç”¨å®˜æ–¹pipæºæˆ–è€…é˜¿é‡Œpipæº,ä¸´æ—¶æ¢æºæ–¹æ³•ï¼špython -m pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/&#xA;python -m pip install -r requirements.txt&#xA;&#xA;# ï¼ˆé€‰æ‹©II: å¦‚ä¸ç†Ÿæ‚‰pythonï¼‰ä½¿ç”¨anacondaï¼Œæ­¥éª¤ä¹Ÿæ˜¯ç±»ä¼¼çš„ (https://www.bilibili.com/video/BV1rc411W7Dr)ï¼š&#xA;conda create -n gptac_venv python=3.11    # åˆ›å»ºanacondaç¯å¢ƒ&#xA;conda activate gptac_venv                 # æ¿€æ´»anacondaç¯å¢ƒ&#xA;python -m pip install -r requirements.txt # è¿™ä¸ªæ­¥éª¤å’Œpipå®‰è£…ä¸€æ ·çš„æ­¥éª¤&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;å¦‚æœéœ€è¦æ”¯æŒæ¸…åChatGLM/å¤æ—¦MOSSä½œä¸ºåç«¯ï¼Œè¯·ç‚¹å‡»å±•å¼€æ­¤å¤„&lt;/summary&gt; &#xA; &lt;p&gt; &lt;/p&gt;&#xA; &lt;p&gt;ã€å¯é€‰æ­¥éª¤ã€‘å¦‚æœéœ€è¦æ”¯æŒæ¸…åChatGLM/å¤æ—¦MOSSä½œä¸ºåç«¯ï¼Œéœ€è¦é¢å¤–å®‰è£…æ›´å¤šä¾èµ–ï¼ˆå‰ææ¡ä»¶ï¼šç†Ÿæ‚‰Python + ç”¨è¿‡Pytorch + ç”µè„‘é…ç½®å¤Ÿå¼ºï¼‰ï¼š&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# ã€å¯é€‰æ­¥éª¤Iã€‘æ”¯æŒæ¸…åChatGLMã€‚æ¸…åChatGLMå¤‡æ³¨ï¼šå¦‚æœé‡åˆ°&#34;Call ChatGLM fail ä¸èƒ½æ­£å¸¸åŠ è½½ChatGLMçš„å‚æ•°&#34; é”™è¯¯ï¼Œå‚è€ƒå¦‚ä¸‹ï¼š 1ï¼šä»¥ä¸Šé»˜è®¤å®‰è£…çš„ä¸ºtorch+cpuç‰ˆï¼Œä½¿ç”¨cudaéœ€è¦å¸è½½torché‡æ–°å®‰è£…torch+cudaï¼› 2ï¼šå¦‚å› æœ¬æœºé…ç½®ä¸å¤Ÿæ— æ³•åŠ è½½æ¨¡å‹ï¼Œå¯ä»¥ä¿®æ”¹request_llm/bridge_chatglm.pyä¸­çš„æ¨¡å‹ç²¾åº¦, å°† AutoTokenizer.from_pretrained(&#34;THUDM/chatglm-6b&#34;, trust_remote_code=True) éƒ½ä¿®æ”¹ä¸º AutoTokenizer.from_pretrained(&#34;THUDM/chatglm-6b-int4&#34;, trust_remote_code=True)&#xA;python -m pip install -r request_llm/requirements_chatglm.txt  &#xA;&#xA;# ã€å¯é€‰æ­¥éª¤IIã€‘æ”¯æŒå¤æ—¦MOSS&#xA;python -m pip install -r request_llm/requirements_moss.txt&#xA;git clone https://github.com/OpenLMLab/MOSS.git request_llm/moss  # æ³¨æ„æ‰§è¡Œæ­¤è¡Œä»£ç æ—¶ï¼Œå¿…é¡»å¤„äºé¡¹ç›®æ ¹è·¯å¾„&#xA;&#xA;# ã€å¯é€‰æ­¥éª¤IIIã€‘ç¡®ä¿config.pyé…ç½®æ–‡ä»¶çš„AVAIL_LLM_MODELSåŒ…å«äº†æœŸæœ›çš„æ¨¡å‹ï¼Œç›®å‰æ”¯æŒçš„å…¨éƒ¨æ¨¡å‹å¦‚ä¸‹(jittorllmsç³»åˆ—ç›®å‰ä»…æ”¯æŒdockeræ–¹æ¡ˆ)ï¼š&#xA;AVAIL_LLM_MODELS = [&#34;gpt-3.5-turbo&#34;, &#34;api2d-gpt-3.5-turbo&#34;, &#34;gpt-4&#34;, &#34;api2d-gpt-4&#34;, &#34;chatglm&#34;, &#34;newbing&#34;, &#34;moss&#34;] # + [&#34;jittorllms_rwkv&#34;, &#34;jittorllms_pangualpha&#34;, &#34;jittorllms_llama&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;è¿è¡Œ&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;å®‰è£…-æ–¹æ³•2ï¼šä½¿ç”¨Docker&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ä»…ChatGPTï¼ˆæ¨èå¤§å¤šæ•°äººé€‰æ‹©ï¼Œç­‰ä»·äºdocker-composeæ–¹æ¡ˆ1ï¼‰&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/binary-husky/gpt_academic.git  # ä¸‹è½½é¡¹ç›®&#xA;cd gpt_academic                                 # è¿›å…¥è·¯å¾„&#xA;nano config.py                                      # ç”¨ä»»æ„æ–‡æœ¬ç¼–è¾‘å™¨ç¼–è¾‘config.py, é…ç½® â€œProxyâ€ï¼Œ â€œAPI_KEYâ€ ä»¥åŠ â€œWEB_PORTâ€ (ä¾‹å¦‚50923) ç­‰&#xA;docker build -t gpt-academic .                      # å®‰è£…&#xA;&#xA;#ï¼ˆæœ€åä¸€æ­¥-é€‰æ‹©1ï¼‰åœ¨Linuxç¯å¢ƒä¸‹ï¼Œç”¨`--net=host`æ›´æ–¹ä¾¿å¿«æ·&#xA;docker run --rm -it --net=host gpt-academic&#xA;#ï¼ˆæœ€åä¸€æ­¥-é€‰æ‹©2ï¼‰åœ¨macOS/windowsç¯å¢ƒä¸‹ï¼Œåªèƒ½ç”¨-pé€‰é¡¹å°†å®¹å™¨ä¸Šçš„ç«¯å£(ä¾‹å¦‚50923)æš´éœ²ç»™ä¸»æœºä¸Šçš„ç«¯å£&#xA;docker run --rm -it -e WEB_PORT=50923 -p 50923:50923 gpt-academic&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;P.S. å¦‚æœéœ€è¦ä¾èµ–Latexçš„æ’ä»¶åŠŸèƒ½ï¼Œè¯·è§Wikiã€‚å¦å¤–ï¼Œæ‚¨ä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨docker-composeè·å–LatexåŠŸèƒ½ï¼ˆä¿®æ”¹docker-compose.ymlï¼Œä¿ç•™æ–¹æ¡ˆ4å¹¶åˆ é™¤å…¶ä»–æ–¹æ¡ˆï¼‰ã€‚&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;ChatGPT + ChatGLM + MOSSï¼ˆéœ€è¦ç†Ÿæ‚‰Dockerï¼‰&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# ä¿®æ”¹docker-compose.ymlï¼Œä¿ç•™æ–¹æ¡ˆ2å¹¶åˆ é™¤å…¶ä»–æ–¹æ¡ˆã€‚ä¿®æ”¹docker-compose.ymlä¸­æ–¹æ¡ˆ2çš„é…ç½®ï¼Œå‚è€ƒå…¶ä¸­æ³¨é‡Šå³å¯&#xA;docker-compose up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;ChatGPT + LLAMA + ç›˜å¤ + RWKVï¼ˆéœ€è¦ç†Ÿæ‚‰Dockerï¼‰&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# ä¿®æ”¹docker-compose.ymlï¼Œä¿ç•™æ–¹æ¡ˆ3å¹¶åˆ é™¤å…¶ä»–æ–¹æ¡ˆã€‚ä¿®æ”¹docker-compose.ymlä¸­æ–¹æ¡ˆ3çš„é…ç½®ï¼Œå‚è€ƒå…¶ä¸­æ³¨é‡Šå³å¯&#xA;docker-compose up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;å®‰è£…-æ–¹æ³•3ï¼šå…¶ä»–éƒ¨ç½²å§¿åŠ¿&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;ä¸€é”®è¿è¡Œè„šæœ¬ã€‚ å®Œå…¨ä¸ç†Ÿæ‚‰pythonç¯å¢ƒçš„Windowsç”¨æˆ·å¯ä»¥ä¸‹è½½&lt;a href=&#34;https://github.com/binary-husky/gpt_academic/releases&#34;&gt;Release&lt;/a&gt;ä¸­å‘å¸ƒçš„ä¸€é”®è¿è¡Œè„šæœ¬å®‰è£…æ— æœ¬åœ°æ¨¡å‹çš„ç‰ˆæœ¬ã€‚ è„šæœ¬çš„è´¡çŒ®æ¥æºæ˜¯&lt;a href=&#34;https://github.com/oobabooga/one-click-installers&#34;&gt;oobabooga&lt;/a&gt;ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ä½¿ç”¨docker-composeè¿è¡Œã€‚ è¯·é˜…è¯»docker-compose.ymlåï¼ŒæŒ‰ç…§å…¶ä¸­çš„æç¤ºæ“ä½œå³å¯&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å¦‚ä½•ä½¿ç”¨åä»£URL æŒ‰ç…§&lt;code&gt;config.py&lt;/code&gt;ä¸­çš„è¯´æ˜é…ç½®API_URL_REDIRECTå³å¯ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å¾®è½¯äº‘AzureAPI æŒ‰ç…§&lt;code&gt;config.py&lt;/code&gt;ä¸­çš„è¯´æ˜é…ç½®å³å¯ï¼ˆAZURE_ENDPOINTç­‰å››ä¸ªé…ç½®ï¼‰&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;è¿œç¨‹äº‘æœåŠ¡å™¨éƒ¨ç½²ï¼ˆéœ€è¦äº‘æœåŠ¡å™¨çŸ¥è¯†ä¸ç»éªŒï¼‰ã€‚ è¯·è®¿é—®&lt;a href=&#34;https://github.com/binary-husky/gpt_academic/wiki/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9C%E7%A8%8B%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97&#34;&gt;éƒ¨ç½²wiki-1&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ä½¿ç”¨WSL2ï¼ˆWindows Subsystem for Linux å­ç³»ç»Ÿï¼‰ã€‚ è¯·è®¿é—®&lt;a href=&#34;https://github.com/binary-husky/gpt_academic/wiki/%E4%BD%BF%E7%94%A8WSL2%EF%BC%88Windows-Subsystem-for-Linux-%E5%AD%90%E7%B3%BB%E7%BB%9F%EF%BC%89%E9%83%A8%E7%BD%B2&#34;&gt;éƒ¨ç½²wiki-2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å¦‚ä½•åœ¨äºŒçº§ç½‘å€ï¼ˆå¦‚&lt;code&gt;http://localhost/subpath&lt;/code&gt;ï¼‰ä¸‹è¿è¡Œã€‚ è¯·è®¿é—®&lt;a href=&#34;https://raw.githubusercontent.com/binary-husky/gpt_academic/master/docs/WithFastapi.md&#34;&gt;FastAPIè¿è¡Œè¯´æ˜&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Advanced Usage&lt;/h1&gt; &#xA;&lt;h2&gt;è‡ªå®šä¹‰æ–°çš„ä¾¿æ·æŒ‰é’® / è‡ªå®šä¹‰å‡½æ•°æ’ä»¶&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;è‡ªå®šä¹‰æ–°çš„ä¾¿æ·æŒ‰é’®ï¼ˆå­¦æœ¯å¿«æ·é”®ï¼‰ ä»»æ„æ–‡æœ¬ç¼–è¾‘å™¨æ‰“å¼€&lt;code&gt;core_functional.py&lt;/code&gt;ï¼Œæ·»åŠ æ¡ç›®å¦‚ä¸‹ï¼Œç„¶åé‡å¯ç¨‹åºå³å¯ã€‚ï¼ˆå¦‚æœæŒ‰é’®å·²ç»æ·»åŠ æˆåŠŸå¹¶å¯è§ï¼Œé‚£ä¹ˆå‰ç¼€ã€åç¼€éƒ½æ”¯æŒçƒ­ä¿®æ”¹ï¼Œæ— éœ€é‡å¯ç¨‹åºå³å¯ç”Ÿæ•ˆã€‚ï¼‰ ä¾‹å¦‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#34;è¶…çº§è‹±è¯‘ä¸­&#34;: {&#xA;    # å‰ç¼€ï¼Œä¼šè¢«åŠ åœ¨ä½ çš„è¾“å…¥ä¹‹å‰ã€‚ä¾‹å¦‚ï¼Œç”¨æ¥æè¿°ä½ çš„è¦æ±‚ï¼Œä¾‹å¦‚ç¿»è¯‘ã€è§£é‡Šä»£ç ã€æ¶¦è‰²ç­‰ç­‰&#xA;    &#34;Prefix&#34;: &#34;è¯·ç¿»è¯‘æŠŠä¸‹é¢ä¸€æ®µå†…å®¹æˆä¸­æ–‡ï¼Œç„¶åç”¨ä¸€ä¸ªmarkdownè¡¨æ ¼é€ä¸€è§£é‡Šæ–‡ä¸­å‡ºç°çš„ä¸“æœ‰åè¯ï¼š\n\n&#34;, &#xA;    &#xA;    # åç¼€ï¼Œä¼šè¢«åŠ åœ¨ä½ çš„è¾“å…¥ä¹‹åã€‚ä¾‹å¦‚ï¼Œé…åˆå‰ç¼€å¯ä»¥æŠŠä½ çš„è¾“å…¥å†…å®¹ç”¨å¼•å·åœˆèµ·æ¥ã€‚&#xA;    &#34;Suffix&#34;: &#34;&#34;,&#xA;},&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/226899272-477c2134-ed71-4326-810c-29891fe4a508.png&#34; width=&#34;500&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;è‡ªå®šä¹‰å‡½æ•°æ’ä»¶&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;ç¼–å†™å¼ºå¤§çš„å‡½æ•°æ’ä»¶æ¥æ‰§è¡Œä»»ä½•ä½ æƒ³å¾—åˆ°çš„å’Œæƒ³ä¸åˆ°çš„ä»»åŠ¡ã€‚ æœ¬é¡¹ç›®çš„æ’ä»¶ç¼–å†™ã€è°ƒè¯•éš¾åº¦å¾ˆä½ï¼Œåªè¦æ‚¨å…·å¤‡ä¸€å®šçš„pythonåŸºç¡€çŸ¥è¯†ï¼Œå°±å¯ä»¥ä»¿ç…§æˆ‘ä»¬æä¾›çš„æ¨¡æ¿å®ç°è‡ªå·±çš„æ’ä»¶åŠŸèƒ½ã€‚ è¯¦æƒ…è¯·å‚è€ƒ&lt;a href=&#34;https://github.com/binary-husky/gpt_academic/wiki/%E5%87%BD%E6%95%B0%E6%8F%92%E4%BB%B6%E6%8C%87%E5%8D%97&#34;&gt;å‡½æ•°æ’ä»¶æŒ‡å—&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Latest Update&lt;/h1&gt; &#xA;&lt;h2&gt;æ–°åŠŸèƒ½åŠ¨æ€&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;å¯¹è¯ä¿å­˜åŠŸèƒ½ã€‚åœ¨å‡½æ•°æ’ä»¶åŒºè°ƒç”¨ &lt;code&gt;ä¿å­˜å½“å‰çš„å¯¹è¯&lt;/code&gt; å³å¯å°†å½“å‰å¯¹è¯ä¿å­˜ä¸ºå¯è¯»+å¯å¤åŸçš„htmlæ–‡ä»¶ï¼Œ å¦å¤–åœ¨å‡½æ•°æ’ä»¶åŒºï¼ˆä¸‹æ‹‰èœå•ï¼‰è°ƒç”¨ &lt;code&gt;è½½å…¥å¯¹è¯å†å²å­˜æ¡£&lt;/code&gt; ï¼Œå³å¯è¿˜åŸä¹‹å‰çš„ä¼šè¯ã€‚ Tipï¼šä¸æŒ‡å®šæ–‡ä»¶ç›´æ¥ç‚¹å‡» &lt;code&gt;è½½å…¥å¯¹è¯å†å²å­˜æ¡£&lt;/code&gt; å¯ä»¥æŸ¥çœ‹å†å²htmlå­˜æ¡£ç¼“å­˜ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/235222390-24a9acc0-680f-49f5-bc81-2f3161f1e049.png&#34; width=&#34;500&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;â­Latex/Arxivè®ºæ–‡ç¿»è¯‘åŠŸèƒ½â­&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/binary-husky/gpt_academic/assets/96192199/002a1a75-ace0-4e6a-94e2-ec1406a746f1&#34; height=&#34;250&#34;&gt; ===&amp;gt; &#xA; &lt;img src=&#34;https://github.com/binary-husky/gpt_academic/assets/96192199/9fdcc391-f823-464f-9322-f8719677043b&#34; height=&#34;250&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;ç”ŸæˆæŠ¥å‘Šã€‚å¤§éƒ¨åˆ†æ’ä»¶éƒ½ä¼šåœ¨æ‰§è¡Œç»“æŸåï¼Œç”Ÿæˆå·¥ä½œæŠ¥å‘Š&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/227503770-fe29ce2c-53fd-47b0-b0ff-93805f0c2ff4.png&#34; height=&#34;250&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/227504617-7a497bb3-0a2a-4b50-9a8a-95ae60ea7afd.png&#34; height=&#34;250&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;æ¨¡å—åŒ–åŠŸèƒ½è®¾è®¡ï¼Œç®€å•çš„æ¥å£å´èƒ½æ”¯æŒå¼ºå¤§çš„åŠŸèƒ½&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/229288270-093643c1-0018-487a-81e6-1d7809b6e90f.png&#34; height=&#34;400&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/227504931-19955f78-45cd-4d1c-adac-e71e50957915.png&#34; height=&#34;400&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;è¯‘è§£å…¶ä»–å¼€æºé¡¹ç›®&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/226935232-6b6a73ce-8900-4aee-93f9-733c7e6fef53.png&#34; height=&#34;250&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/226969067-968a27c1-1b9c-486b-8b81-ab2de8d3f88a.png&#34; height=&#34;250&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;è£…é¥°&lt;a href=&#34;https://github.com/fghrsh/live2d_demo&#34;&gt;live2d&lt;/a&gt;çš„å°åŠŸèƒ½ï¼ˆé»˜è®¤å…³é—­ï¼Œéœ€è¦ä¿®æ”¹&lt;code&gt;config.py&lt;/code&gt;ï¼‰&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/236432361-67739153-73e8-43fe-8111-b61296edabd9.png&#34; width=&#34;500&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ol start=&#34;7&#34;&gt; &#xA; &lt;li&gt;æ–°å¢MOSSå¤§è¯­è¨€æ¨¡å‹æ”¯æŒ&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/96192199/236639178-92836f37-13af-4fdd-984d-b4450fe30336.png&#34; width=&#34;500&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ol start=&#34;8&#34;&gt; &#xA; &lt;li&gt;OpenAIå›¾åƒç”Ÿæˆ&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/binary-husky/gpt_academic/assets/96192199/bc7ab234-ad90-48a0-8d62-f703d9e74665&#34; width=&#34;500&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ol start=&#34;9&#34;&gt; &#xA; &lt;li&gt;OpenAIéŸ³é¢‘è§£æä¸æ€»ç»“&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/binary-husky/gpt_academic/assets/96192199/709ccf95-3aee-498a-934a-e1c22d3d5d5b&#34; width=&#34;500&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ol start=&#34;10&#34;&gt; &#xA; &lt;li&gt;Latexå…¨æ–‡æ ¡å¯¹çº é”™&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/binary-husky/gpt_academic/assets/96192199/651ccd98-02c9-4464-91e1-77a6b7d1b033&#34; height=&#34;200&#34;&gt; ===&amp;gt; &#xA; &lt;img src=&#34;https://github.com/binary-husky/gpt_academic/assets/96192199/476f66d9-7716-4537-b5c1-735372c25adb&#34; height=&#34;200&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;ç‰ˆæœ¬:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;version 3.5(Todo): ä½¿ç”¨è‡ªç„¶è¯­è¨€è°ƒç”¨æœ¬é¡¹ç›®çš„æ‰€æœ‰å‡½æ•°æ’ä»¶ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰&lt;/li&gt; &#xA; &lt;li&gt;version 3.4: +arxivè®ºæ–‡ç¿»è¯‘ã€latexè®ºæ–‡æ‰¹æ”¹åŠŸèƒ½&lt;/li&gt; &#xA; &lt;li&gt;version 3.3: +äº’è”ç½‘ä¿¡æ¯ç»¼åˆåŠŸèƒ½&lt;/li&gt; &#xA; &lt;li&gt;version 3.2: å‡½æ•°æ’ä»¶æ”¯æŒæ›´å¤šå‚æ•°æ¥å£ (ä¿å­˜å¯¹è¯åŠŸèƒ½, è§£è¯»ä»»æ„è¯­è¨€ä»£ç +åŒæ—¶è¯¢é—®ä»»æ„çš„LLMç»„åˆ)&lt;/li&gt; &#xA; &lt;li&gt;version 3.1: æ”¯æŒåŒæ—¶é—®è¯¢å¤šä¸ªgptæ¨¡å‹ï¼æ”¯æŒapi2dï¼Œæ”¯æŒå¤šä¸ªapikeyè´Ÿè½½å‡è¡¡&lt;/li&gt; &#xA; &lt;li&gt;version 3.0: å¯¹chatglmå’Œå…¶ä»–å°å‹llmçš„æ”¯æŒ&lt;/li&gt; &#xA; &lt;li&gt;version 2.6: é‡æ„äº†æ’ä»¶ç»“æ„ï¼Œæé«˜äº†äº¤äº’æ€§ï¼ŒåŠ å…¥æ›´å¤šæ’ä»¶&lt;/li&gt; &#xA; &lt;li&gt;version 2.5: è‡ªæ›´æ–°ï¼Œè§£å†³æ€»ç»“å¤§å·¥ç¨‹æºä»£ç æ—¶æ–‡æœ¬è¿‡é•¿ã€tokenæº¢å‡ºçš„é—®é¢˜&lt;/li&gt; &#xA; &lt;li&gt;version 2.4: (1)æ–°å¢PDFå…¨æ–‡ç¿»è¯‘åŠŸèƒ½; (2)æ–°å¢è¾“å…¥åŒºåˆ‡æ¢ä½ç½®çš„åŠŸèƒ½; (3)æ–°å¢å‚ç›´å¸ƒå±€é€‰é¡¹; (4)å¤šçº¿ç¨‹å‡½æ•°æ’ä»¶ä¼˜åŒ–ã€‚&lt;/li&gt; &#xA; &lt;li&gt;version 2.3: å¢å¼ºå¤šçº¿ç¨‹äº¤äº’æ€§&lt;/li&gt; &#xA; &lt;li&gt;version 2.2: å‡½æ•°æ’ä»¶æ”¯æŒçƒ­é‡è½½&lt;/li&gt; &#xA; &lt;li&gt;version 2.1: å¯æŠ˜å å¼å¸ƒå±€&lt;/li&gt; &#xA; &lt;li&gt;version 2.0: å¼•å…¥æ¨¡å—åŒ–å‡½æ•°æ’ä»¶&lt;/li&gt; &#xA; &lt;li&gt;version 1.0: åŸºç¡€åŠŸèƒ½&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;gpt_academicå¼€å‘è€…QQç¾¤-2ï¼š610599535&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;å·²çŸ¥é—®é¢˜ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;æŸäº›æµè§ˆå™¨ç¿»è¯‘æ’ä»¶å¹²æ‰°æ­¤è½¯ä»¶å‰ç«¯çš„è¿è¡Œ&lt;/li&gt; &#xA;   &lt;li&gt;å®˜æ–¹Gradioç›®å‰æœ‰å¾ˆå¤šå…¼å®¹æ€§Bugï¼Œè¯·åŠ¡å¿…ä½¿ç”¨&lt;code&gt;requirement.txt&lt;/code&gt;å®‰è£…Gradio&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;å‚è€ƒä¸å­¦ä¹ &lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;ä»£ç ä¸­å‚è€ƒäº†å¾ˆå¤šå…¶ä»–ä¼˜ç§€é¡¹ç›®ä¸­çš„è®¾è®¡ï¼Œé¡ºåºä¸åˆ†å…ˆåï¼š&#xA;&#xA;# æ¸…åChatGLM-6B:&#xA;https://github.com/THUDM/ChatGLM-6B&#xA;&#xA;# æ¸…åJittorLLMs:&#xA;https://github.com/Jittor/JittorLLMs&#xA;&#xA;# ChatPaper:&#xA;https://github.com/kaixindelele/ChatPaper&#xA;&#xA;# Edge-GPT:&#xA;https://github.com/acheong08/EdgeGPT&#xA;&#xA;# ChuanhuChatGPT:&#xA;https://github.com/GaiZhenbiao/ChuanhuChatGPT&#xA;&#xA;# Oobabooga one-click installer:&#xA;https://github.com/oobabooga/one-click-installers&#xA;&#xA;# Moreï¼š&#xA;https://github.com/gradio-app/gradio&#xA;https://github.com/fghrsh/live2d_demo&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>langchain-ai/streamlit-agent</title>
    <updated>2023-07-05T01:43:33Z</updated>
    <id>tag:github.com,2023-07-05:/langchain-ai/streamlit-agent</id>
    <link href="https://github.com/langchain-ai/streamlit-agent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Reference implementations of several LangChain agents as Streamlit apps&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ğŸ¦œï¸ğŸ”— LangChain ğŸ¤ Streamlit agent examples&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://codespaces.new/langchain-ai/streamlit-agent?quickstart=1&#34;&gt;&lt;img src=&#34;https://github.com/codespaces/badge.svg?sanitize=true&#34; alt=&#34;Open in GitHub Codespaces&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repository contains reference implementations of various LangChain agents as Streamlit apps including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;basic_streaming.py&lt;/code&gt;: How to do streaming with a simple app using &lt;code&gt;langchain.chat_models.ChatOpenAI&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;mrkl_demo.py&lt;/code&gt;: An agent that replicates the &lt;a href=&#34;https://python.langchain.com/docs/modules/agents/how_to/mrkl&#34;&gt;MRKL demo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;minimal_agent.py&lt;/code&gt;: A minimal agent with search (requires setting &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; env to run)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;search_and_chat.py&lt;/code&gt;: A search-enabled chatbot that remembers chat history&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Apps feature LangChain ğŸ¤ Streamlit integrations such as the &lt;a href=&#34;https://python.langchain.com/docs/modules/callbacks/integrations/streamlit&#34;&gt;Callback integration&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;This project uses &lt;a href=&#34;https://python-poetry.org/&#34;&gt;Poetry&lt;/a&gt; for dependency management.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Create Python environment&#xA;$ poetry install&#xA;&#xA;# Install git pre-commit hooks&#xA;$ poetry shell&#xA;$ pre-commit install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Run mrkl_demo.py or another app the same way&#xA;$ streamlit run streamlit_agent/mrkl_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We plan to add more agent examples over time - PRs welcome&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Chat QA over docs&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; SQL agent&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>PlayVoice/so-vits-svc-5.0</title>
    <updated>2023-07-05T01:43:33Z</updated>
    <id>tag:github.com,2023-07-05:/PlayVoice/so-vits-svc-5.0</id>
    <link href="https://github.com/PlayVoice/so-vits-svc-5.0" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Core Engine of Singing Voice Conversion &amp; Singing Voice Clone&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt; Variational Inference with adversarial learning for end-to-end Singing Voice Conversion based on VITS &lt;/h1&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/spaces/maxmax20160403/sovits5.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/drive/1PY1E4bDAeHbAD4r99D_oYXB46fG8nIA5?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt; &lt;img alt=&#34;GitHub Repo stars&#34; src=&#34;https://img.shields.io/github/stars/PlayVoice/so-vits-svc-5.0&#34;&gt; &lt;img alt=&#34;GitHub forks&#34; src=&#34;https://img.shields.io/github/forks/PlayVoice/so-vits-svc-5.0&#34;&gt; &lt;img alt=&#34;GitHub issues&#34; src=&#34;https://img.shields.io/github/issues/PlayVoice/so-vits-svc-5.0&#34;&gt; &lt;img alt=&#34;GitHub&#34; src=&#34;https://img.shields.io/github/license/PlayVoice/so-vits-svc-5.0&#34;&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PlayVoice/so-vits-svc-5.0/bigvgan-mix-v2/README_ZH.md&#34;&gt;ä¸­æ–‡æ–‡æ¡£&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;This project is target for: beginners in deep learning, the basic operation of Python and PyTorch is the prerequisite for using this project;&lt;/li&gt; &#xA; &lt;li&gt;This project aims to help deep learning beginners get rid of boring pure theoretical learning, and master the basic knowledge of deep learning by combining it with practice;&lt;/li&gt; &#xA; &lt;li&gt;This project does not support real-time voice change; (support needs to replace whisper)&lt;/li&gt; &#xA; &lt;li&gt;This project will not develop one-click packages for other purposesï¼›&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/PlayVoice/so-vits-svc-5.0/assets/16432329/3854b281-8f97-4016-875b-6eb663c92466&#34; alt=&#34;vits-5.0-frame&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;6G memory GPU can be used to trained&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;support for multiple speakers&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;create unique speakers through speaker mixing&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;even with light accompaniment can also be converted&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;F0 can be edited using Excel&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Model properties&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Feature&lt;/th&gt; &#xA;   &lt;th&gt;From&lt;/th&gt; &#xA;   &lt;th&gt;Status&lt;/th&gt; &#xA;   &lt;th&gt;Function&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;whisper&lt;/td&gt; &#xA;   &lt;td&gt;OpenAI&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;strong noise immunity&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;bigvgan&lt;/td&gt; &#xA;   &lt;td&gt;NVIDA&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;alias and snake&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;natural speech&lt;/td&gt; &#xA;   &lt;td&gt;Microsoft&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;reduce mispronunciation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;neural source-filter&lt;/td&gt; &#xA;   &lt;td&gt;NII&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;solve the problem of audio F0 discontinuity&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;speaker encoder&lt;/td&gt; &#xA;   &lt;td&gt;Google&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;Timbre Encoding and Clustering&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GRL for speaker&lt;/td&gt; &#xA;   &lt;td&gt;Ubisoft&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;Preventing Encoder Leakage Timbre&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;one shot vits&lt;/td&gt; &#xA;   &lt;td&gt;Samsung&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;Voice Clone&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SCLN&lt;/td&gt; &#xA;   &lt;td&gt;Microsoft&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;Improve Clone&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PPG perturbation&lt;/td&gt; &#xA;   &lt;td&gt;this project&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;Improved noise immunity and de-timbre&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HuBERT perturbation&lt;/td&gt; &#xA;   &lt;td&gt;this project&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;Improved noise immunity and de-timbre&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;VAE perturbation&lt;/td&gt; &#xA;   &lt;td&gt;this project&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;Improve sound quality&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;due to the use of data perturbation, it takes longer to train than other projects.&lt;/p&gt; &#xA;&lt;h2&gt;Dataset preparation&lt;/h2&gt; &#xA;&lt;p&gt;Necessary pre-processing:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;1 accompaniment separation, &lt;a href=&#34;https://github.com/Anjok07/ultimatevocalremovergui&#34;&gt;UVR&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;2 cut audio, less than 30 seconds for whisper, &lt;a href=&#34;https://github.com/flutydeer/audio-slicer&#34;&gt;slicer&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;then put the dataset into the dataset_raw directory according to the following file structure&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dataset_raw&#xA;â”œâ”€â”€â”€speaker0&#xA;â”‚   â”œâ”€â”€â”€000001.wav&#xA;â”‚   â”œâ”€â”€â”€...&#xA;â”‚   â””â”€â”€â”€000xxx.wav&#xA;â””â”€â”€â”€speaker1&#xA;    â”œâ”€â”€â”€000001.wav&#xA;    â”œâ”€â”€â”€...&#xA;    â””â”€â”€â”€000xxx.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Install dependencies&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;1 software dependency&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;apt update &amp;amp;&amp;amp; sudo apt install ffmpeg&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;pip install -r requirements.txt&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2 download the Timbre Encoder: &lt;a href=&#34;https://drive.google.com/drive/folders/15oeBYf6Qn1edONkVLXe82MzdIi3O_9m3&#34;&gt;Speaker-Encoder by @mueller91&lt;/a&gt;, put &lt;code&gt;best_model.pth.tar&lt;/code&gt; into &lt;code&gt;speaker_pretrain/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;3 download whisper model &lt;a href=&#34;https://openaipublic.azureedge.net/main/whisper/models/81f7c96c852ee8fc832187b0132e569d6c3065a3252ed18e56effd0b6a73e524/large-v2.pt&#34;&gt;whisper-large-v2&lt;/a&gt;, Make sure to download &lt;code&gt;large-v2.pt&lt;/code&gt;ï¼Œput it into &lt;code&gt;whisper_pretrain/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;4 whisper is built-in, do not install it additionally, it will conflict and report an error&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;5 download &lt;a href=&#34;https://github.com/bshall/hubert/releases/tag/v0.1&#34;&gt;hubert_soft model&lt;/a&gt;ï¼Œput &lt;code&gt;hubert-soft-0d54a1f4.pt&lt;/code&gt; into &lt;code&gt;hubert_pretrain/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Data preprocessing&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;1ï¼Œ re-sampling&lt;/p&gt; &lt;p&gt;generate audio with a sampling rate of 16000Hzï¼š./data_svc/waves-16k&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python prepare/preprocess_a.py -w ./dataset_raw -o ./data_svc/waves-16k -s 16000&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;p&gt;generate audio with a sampling rate of 32000Hzï¼š./data_svc/waves-32k&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python prepare/preprocess_a.py -w ./dataset_raw -o ./data_svc/waves-32k -s 32000&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2ï¼Œ use 16K audio to extract pitchï¼š&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python prepare/preprocess_crepe.py -w data_svc/waves-16k/ -p data_svc/pitch&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;3ï¼Œ use 16K audio to extract ppg&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python prepare/preprocess_ppg.py -w data_svc/waves-16k/ -p data_svc/whisper&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;4ï¼Œ use 16K audio to extract hubert&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python prepare/preprocess_hubert.py -w data_svc/waves-16k/ -v data_svc/hubert&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;5ï¼Œ use 16k audio to extract timbre code&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python prepare/preprocess_speaker.py data_svc/waves-16k/ data_svc/speaker&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;6ï¼Œ extract the average value of the timbre code for inference; it can also replace a single audio timbre in generating the training index, and use it as the unified timbre of the speaker for training&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python prepare/preprocess_speaker_ave.py data_svc/speaker/ data_svc/singer&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;7ï¼Œ use 32k audio to extract the linear spectrum&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python prepare/preprocess_spec.py -w data_svc/waves-32k/ -s data_svc/specs&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;8ï¼Œ use 32k audio to generate training index&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python prepare/preprocess_train.py&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;9ï¼Œ training file debugging&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python prepare/preprocess_zzz.py&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;data_svc/&#xA;â””â”€â”€ waves-16k&#xA;â”‚    â””â”€â”€ speaker0&#xA;â”‚    â”‚      â”œâ”€â”€ 000001.wav&#xA;â”‚    â”‚      â””â”€â”€ 000xxx.wav&#xA;â”‚    â””â”€â”€ speaker1&#xA;â”‚           â”œâ”€â”€ 000001.wav&#xA;â”‚           â””â”€â”€ 000xxx.wav&#xA;â””â”€â”€ waves-32k&#xA;â”‚    â””â”€â”€ speaker0&#xA;â”‚    â”‚      â”œâ”€â”€ 000001.wav&#xA;â”‚    â”‚      â””â”€â”€ 000xxx.wav&#xA;â”‚    â””â”€â”€ speaker1&#xA;â”‚           â”œâ”€â”€ 000001.wav&#xA;â”‚           â””â”€â”€ 000xxx.wav&#xA;â””â”€â”€ pitch&#xA;â”‚    â””â”€â”€ speaker0&#xA;â”‚    â”‚      â”œâ”€â”€ 000001.pit.npy&#xA;â”‚    â”‚      â””â”€â”€ 000xxx.pit.npy&#xA;â”‚    â””â”€â”€ speaker1&#xA;â”‚           â”œâ”€â”€ 000001.pit.npy&#xA;â”‚           â””â”€â”€ 000xxx.pit.npy&#xA;â””â”€â”€ hubert&#xA;â”‚    â””â”€â”€ speaker0&#xA;â”‚    â”‚      â”œâ”€â”€ 000001.vec.npy&#xA;â”‚    â”‚      â””â”€â”€ 000xxx.vec.npy&#xA;â”‚    â””â”€â”€ speaker1&#xA;â”‚           â”œâ”€â”€ 000001.vec.npy&#xA;â”‚           â””â”€â”€ 000xxx.vec.npy&#xA;â””â”€â”€ whisper&#xA;â”‚    â””â”€â”€ speaker0&#xA;â”‚    â”‚      â”œâ”€â”€ 000001.ppg.npy&#xA;â”‚    â”‚      â””â”€â”€ 000xxx.ppg.npy&#xA;â”‚    â””â”€â”€ speaker1&#xA;â”‚           â”œâ”€â”€ 000001.ppg.npy&#xA;â”‚           â””â”€â”€ 000xxx.ppg.npy&#xA;â””â”€â”€ speaker&#xA;â”‚    â””â”€â”€ speaker0&#xA;â”‚    â”‚      â”œâ”€â”€ 000001.spk.npy&#xA;â”‚    â”‚      â””â”€â”€ 000xxx.spk.npy&#xA;â”‚    â””â”€â”€ speaker1&#xA;â”‚           â”œâ”€â”€ 000001.spk.npy&#xA;â”‚           â””â”€â”€ 000xxx.spk.npy&#xA;â””â”€â”€ singer&#xA;    â”œâ”€â”€ speaker0.spk.npy&#xA;    â””â”€â”€ speaker1.spk.npy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Train&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;1ï¼Œ if fine-tuning based on the pre-trained model, you need to download the pre-trained model: &lt;a href=&#34;https://github.com/PlayVoice/so-vits-svc-5.0/releases/tag/bigvgan_release&#34;&gt;sovits5.0_bigvgan_mix_v2.pth&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;set pretrain: &#34;./sovits5.0_bigvgan_mix_v2.pth&#34; in configs/base.yamlï¼Œand adjust the learning rate appropriately, eg 5e-5&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2ï¼Œ start training&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python svc_trainer.py -c configs/base.yaml -n sovits5.0&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;3ï¼Œ resume training&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python svc_trainer.py -c configs/base.yaml -n sovits5.0 -p chkpt/sovits5.0/***.pth&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;4ï¼Œ view log&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;tensorboard --logdir logs/&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/PlayVoice/so-vits-svc-5.0/assets/16432329/1628e775-5888-4eac-b173-a28dca978faa&#34; alt=&#34;sovits5 0_base&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;1ï¼Œ export inference model: text encoder, Flow network, Decoder network&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python svc_export.py --config configs/base.yaml --checkpoint_path chkpt/sovits5.0/***.pt&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2ï¼Œ use whisper to extract content encoding, without using one-click reasoning, in order to reduce GPU memory usage&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python whisper/inference.py -w test.wav -p test.ppg.npy&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;3ï¼Œ use hubert to extract content vector, without using one-click reasoning, in order to reduce GPU memory usage&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python hubert/inference.py -w test.wav -v test.vec.npy&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;4ï¼Œ extract the F0 parameter to the csv text format, open the csv file in Excel, and manually modify the wrong F0 according to Audition or SonicVisualiser&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python pitch/inference.py -w test.wav -p test.csv&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;5ï¼Œspecify parameters and infer&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;python svc_inference.py --config configs/base.yaml --model sovits5.0.pth --spk ./configs/singers/singer0001.npy --wave test.wav --ppg test.ppg.npy --vec test.vec.npy --pit test.csv&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;p&gt;when --ppg is specified, when the same audio is reasoned multiple times, it can avoid repeated extraction of audio content codes; if it is not specified, it will be automatically extracted;&lt;/p&gt; &lt;p&gt;when --vec is specified, when the same audio is reasoned multiple times, it can avoid repeated extraction of audio content codes; if it is not specified, it will be automatically extracted;&lt;/p&gt; &lt;p&gt;when --pit is specified, the manually tuned F0 parameter can be loaded; if not specified, it will be automatically extracted;&lt;/p&gt; &lt;p&gt;generate files in the current directory:svc_out.wav&lt;/p&gt; &#xA;  &lt;table&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th&gt;args&lt;/th&gt; &#xA;     &lt;th&gt;--config&lt;/th&gt; &#xA;     &lt;th&gt;--model&lt;/th&gt; &#xA;     &lt;th&gt;--spk&lt;/th&gt; &#xA;     &lt;th&gt;--wave&lt;/th&gt; &#xA;     &lt;th&gt;--ppg&lt;/th&gt; &#xA;     &lt;th&gt;--vec&lt;/th&gt; &#xA;     &lt;th&gt;--pit&lt;/th&gt; &#xA;     &lt;th&gt;--shift&lt;/th&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/thead&gt; &#xA;   &lt;tbody&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;name&lt;/td&gt; &#xA;     &lt;td&gt;config path&lt;/td&gt; &#xA;     &lt;td&gt;model path&lt;/td&gt; &#xA;     &lt;td&gt;speaker&lt;/td&gt; &#xA;     &lt;td&gt;wave input&lt;/td&gt; &#xA;     &lt;td&gt;wave ppg&lt;/td&gt; &#xA;     &lt;td&gt;wave hubert&lt;/td&gt; &#xA;     &lt;td&gt;wave pitch&lt;/td&gt; &#xA;     &lt;td&gt;pitch shift&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Creat singer&lt;/h2&gt; &#xA;&lt;p&gt;named by pure coincidenceï¼šaverage -&amp;gt; ave -&amp;gt; evaï¼Œeve(eva) represents conception and reproduction&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;python svc_eva.py&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;eva_conf = {&#xA;    &#39;./configs/singers/singer0022.npy&#39;: 0,&#xA;    &#39;./configs/singers/singer0030.npy&#39;: 0,&#xA;    &#39;./configs/singers/singer0047.npy&#39;: 0.5,&#xA;    &#39;./configs/singers/singer0051.npy&#39;: 0.5,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;the generated singer file isï¼ševa.spk.npy&lt;/p&gt; &#xA;&lt;h2&gt;Data set&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;URL&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;KiSing&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://shijt.site/index.php/2021/05/16/kising-the-first-open-source-mandarin-singing-voice-synthesis-corpus/&#34;&gt;http://shijt.site/index.php/2021/05/16/kising-the-first-open-source-mandarin-singing-voice-synthesis-corpus/&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PopCS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/MoonInTheRiver/DiffSinger/raw/master/resources/apply_form.md&#34;&gt;https://github.com/MoonInTheRiver/DiffSinger/blob/master/resources/apply_form.md&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;opencpop&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://wenet.org.cn/opencpop/download/&#34;&gt;https://wenet.org.cn/opencpop/download/&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Multi-Singer&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Multi-Singer/Multi-Singer.github.io&#34;&gt;https://github.com/Multi-Singer/Multi-Singer.github.io&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;M4Singer&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/M4Singer/M4Singer/raw/master/apply_form.md&#34;&gt;https://github.com/M4Singer/M4Singer/blob/master/apply_form.md&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CSD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://zenodo.org/record/4785016#.YxqrTbaOMU4&#34;&gt;https://zenodo.org/record/4785016#.YxqrTbaOMU4&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;KSS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/datasets/bryanpark/korean-single-speaker-speech-dataset&#34;&gt;https://www.kaggle.com/datasets/bryanpark/korean-single-speaker-speech-dataset&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;JVS MuSic&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://sites.google.com/site/shinnosuketakamichi/research-topics/jvs_music&#34;&gt;https://sites.google.com/site/shinnosuketakamichi/research-topics/jvs_music&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PJS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://sites.google.com/site/shinnosuketakamichi/research-topics/pjs_corpus&#34;&gt;https://sites.google.com/site/shinnosuketakamichi/research-topics/pjs_corpus&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;JUST Song&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://sites.google.com/site/shinnosuketakamichi/publication/jsut-song&#34;&gt;https://sites.google.com/site/shinnosuketakamichi/publication/jsut-song&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MUSDB18&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://sigsep.github.io/datasets/musdb.html#musdb18-compressed-stems&#34;&gt;https://sigsep.github.io/datasets/musdb.html#musdb18-compressed-stems&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DSD100&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://sigsep.github.io/datasets/dsd100.html&#34;&gt;https://sigsep.github.io/datasets/dsd100.html&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Aishell-3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://www.aishelltech.com/aishell_3&#34;&gt;http://www.aishelltech.com/aishell_3&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;VCTK&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://datashare.ed.ac.uk/handle/10283/2651&#34;&gt;https://datashare.ed.ac.uk/handle/10283/2651&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Code sources and references&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/facebookresearch/speech-resynthesis&#34;&gt;https://github.com/facebookresearch/speech-resynthesis&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2104.00355&#34;&gt;paper&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/jaywalnut310/vits&#34;&gt;https://github.com/jaywalnut310/vits&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2106.06103&#34;&gt;paper&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/openai/whisper/&#34;&gt;https://github.com/openai/whisper/&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2212.04356&#34;&gt;paper&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/NVIDIA/BigVGAN&#34;&gt;https://github.com/NVIDIA/BigVGAN&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2206.04658&#34;&gt;paper&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/mindslab-ai/univnet&#34;&gt;https://github.com/mindslab-ai/univnet&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2106.07889&#34;&gt;paper&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts/tree/master/project/01-nsf&#34;&gt;https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts/tree/master/project/01-nsf&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/brentspell/hifi-gan-bwe&#34;&gt;https://github.com/brentspell/hifi-gan-bwe&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/mozilla/TTS&#34;&gt;https://github.com/mozilla/TTS&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/bshall/soft-vc&#34;&gt;https://github.com/bshall/soft-vc&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/maxrmorrison/torchcrepe&#34;&gt;https://github.com/maxrmorrison/torchcrepe&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/OlaWod/FreeVC&#34;&gt;https://github.com/OlaWod/FreeVC&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2210.15418&#34;&gt;paper&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/hcy71o/SNAC&#34;&gt;SNAC : Speaker-normalized Affine Coupling Layer in Flow-based Architecture for Zero-Shot Multi-Speaker Text-to-Speech&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.00585&#34;&gt;Adapter-Based Extension of Multi-Speaker Text-to-Speech Model for New Speakers&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2103.00993.pdf&#34;&gt;AdaSpeech: Adaptive Text to Speech for Custom Voice&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ubisoft/ubisoft-laforge-daft-exprt&#34;&gt;Cross-Speaker Prosody Transfer on Any Text for Expressive Speech Synthesis&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.05401&#34;&gt;Learn to Sing by Listening: Building Controllable Virtual Singer by Unsupervised Learning from Voice Recordings&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2305.09167.pdf&#34;&gt;Adversarial Speaker Disentanglement Using Unannotated External Data for Self-supervised Representation Based Voice Conversion&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2202.01252&#34;&gt;Speaker normalization (GRL) for self-supervised speech emotion recognition&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Method of Preventing Timbre Leakage Based on Data Perturbation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/auspicious3000/contentvec/raw/main/contentvec/data/audio/audio_utils_1.py&#34;&gt;https://github.com/auspicious3000/contentvec/blob/main/contentvec/data/audio/audio_utils_1.py&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/revsic/torch-nansy/raw/main/utils/augment/praat.py&#34;&gt;https://github.com/revsic/torch-nansy/blob/main/utils/augment/praat.py&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/revsic/torch-nansy/raw/main/utils/augment/peq.py&#34;&gt;https://github.com/revsic/torch-nansy/blob/main/utils/augment/peq.py&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/biggytruck/SpeechSplit2/raw/main/utils.py&#34;&gt;https://github.com/biggytruck/SpeechSplit2/blob/main/utils.py&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/OlaWod/FreeVC/raw/main/preprocess_sr.py&#34;&gt;https://github.com/OlaWod/FreeVC/blob/main/preprocess_sr.py&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/PlayVoice/so-vits-svc/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=PlayVoice/so-vits-svc&#34;&gt; &lt;/a&gt;</summary>
  </entry>
</feed>