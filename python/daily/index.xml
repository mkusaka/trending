<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-08-15T01:39:05Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>martinvigo/email2phonenumber</title>
    <updated>2025-08-15T01:39:05Z</updated>
    <id>tag:github.com,2025-08-15:/martinvigo/email2phonenumber</id>
    <link href="https://github.com/martinvigo/email2phonenumber" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A OSINT tool to obtain a target&#39;s phone number just by having his email address&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;email2phonenumber&lt;/h1&gt; &#xA;&lt;p&gt;email2phonenumber is an OSINT tool that allows you to obtain a target&#39;s phone number just by having his email address.&lt;/p&gt; &#xA;&lt;p&gt;For full details check: &lt;a href=&#34;https://www.martinvigo.com/email2phonenumber&#34;&gt;https://www.martinvigo.com/email2phonenumber&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Demo: &lt;a href=&#34;https://www.youtube.com/watch?v=dfvqhDUn81s&#34;&gt;https://www.youtube.com/watch?v=dfvqhDUn81s&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;IMPORTANT:&lt;/strong&gt;&lt;/em&gt; *email2phonenumber is a proof-of-concept tool I wrote during my research on new OSINT methodologies to obtain a target&#39;s phone number. The supported services (Ebay, Lastpass, Amazon and Twitter) have long added protections to protect from these type of scraping like having to receive a code over email first or simply adding captchas. There are of course many other sites that are still leaking phone number digits but I am focused on other research projects. Feel free to submit pull request if you want to add support for new sites.&lt;/p&gt; &#xA;&lt;p&gt;Please check out my newer tool &#34;&lt;a href=&#34;https://www.martinvigo.com/tools/phonerator/&#34;&gt;Phonerator&lt;/a&gt;&#34;, which is maintained and focuses on the novel aspect of this research, generating valid phone numbers. &lt;a href=&#34;https://www.martinvigo.com/phonerator-an-advanced-valid-phone-number-generator/&#34;&gt;See more details&lt;/a&gt;. There is also a small OSINT challenge in there... ;)&lt;/p&gt; &#xA;&lt;h2&gt;Basic info&lt;/h2&gt; &#xA;&lt;p&gt;This tool helps automate discovering someone&#39;s phone number by abusing password reset design weaknesses and publicly available data. It supports 3 main functions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&#34;scrape&#34; - scrapes websites for phone number digits by initiating password reset using the target&#39;s email address&lt;/li&gt; &#xA; &lt;li&gt;&#34;generate&#34; - creates a list of valid phone numbers based on the country&#39;s Phone Numbering Plan publicly available information&lt;/li&gt; &#xA; &lt;li&gt;&#34;bruteforce&#34; - iterates over a list of phone numbers and initiates password reset on different websites to obtain associated masked emails and correlate it to the victim&#39;s one&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;email2phonenumber was developed on Python 3.x&lt;/p&gt; &#xA;&lt;p&gt;You will need couple 3rd party libraries: BeautifulSoup and requests. These can be easily installed with pip&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip3 install beautifulsoup4 requests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Scrape websites for phone number digits&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 email2phonenumber.py scrape -e target@email.com&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Generate a dictionary of valid phone numbers based on a phone number mask&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 email2phonenumber.py generate -m 555XXX1234 -o /tmp/dic.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Find target&#39;s phone number by resetting passwords on websites that do not alert the target using a phone number mask and proxies to avoid captchas and other abuse protections&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 email2phonenumber.py bruteforce -m 555XXX1234 -e target@email.com -p /tmp/proxies.txt -q&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Demo video&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=dfvqhDUn81s&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/dfvqhDUn81s/0.jpg&#34; alt=&#34;email2phonenumber demo video&#34; /&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Tool presentation at BSides Las Vegas 2019&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=1zssBR85vDA&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/1zssBR85vDA/0.jpg&#34; alt=&#34;Tool presentation at Bsides Las Vegas 2019&#34; /&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Authors&lt;/h2&gt; &#xA;&lt;p&gt;Martin Vigo - @martin_vigo - &lt;a href=&#34;https://www.martinvigo.com&#34;&gt;martinvigo.com&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>oop7/YTSage</title>
    <updated>2025-08-15T01:39:05Z</updated>
    <id>tag:github.com,2025-08-15:/oop7/YTSage</id>
    <link href="https://github.com/oop7/YTSage" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Modern YouTube downloader with a clean PySide6 interface. Download videos in any quality, extract audio, fetch subtitles, sponserBlock, and view video metadata. Built with yt-dlp for reliable performance.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;üé• YTSage&lt;/h1&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/f95f7bfb-8591-4d32-b795-68e61efd670c&#34; width=&#34;800&#34; alt=&#34;YTSage Interface&#34; /&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://badge.fury.io/py/ytsage&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/ytsage?color=dc2626&amp;amp;style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&#34; alt=&#34;PyPI version&#34; /&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-374151?style=for-the-badge&amp;amp;logo=opensource&amp;amp;logoColor=white&#34; alt=&#34;License: MIT&#34; /&gt;&lt;/a&gt; &lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.7+-1f2937?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&#34; alt=&#34;Python 3.7+&#34; /&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/ytsage&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/ytsage?color=4b5563&amp;amp;style=for-the-badge&amp;amp;logo=download&amp;amp;logoColor=white&#34; alt=&#34;Downloads&#34; /&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/oop7/YTSage/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/oop7/YTSage?color=dc2626&amp;amp;style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white&#34; alt=&#34;GitHub Stars&#34; /&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;A modern YouTube downloader with a clean PySide6 interface.&lt;/strong&gt;&lt;br /&gt; Download videos in any quality, extract audio, fetch subtitles, and more.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/oop7/YTSage/main/#installation&#34;&gt;Installation&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oop7/YTSage/main/#features&#34;&gt;Features&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oop7/YTSage/main/#usage&#34;&gt;Usage&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oop7/YTSage/main/#screenshots&#34;&gt;Screenshots&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/oop7/YTSage/main/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr /&gt; &#xA;&lt;p&gt;&lt;a id=&#34;features&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;‚ú® Features&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Core Features&lt;/th&gt; &#xA;    &lt;th&gt;Advanced Features&lt;/th&gt; &#xA;    &lt;th&gt;Extra Features&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;üé• Format Table&lt;/td&gt; &#xA;    &lt;td&gt;üö´ SponsorBlock Integration&lt;/td&gt; &#xA;    &lt;td&gt;üíæ Save Download Path&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;üéµ Audio Extraction&lt;/td&gt; &#xA;    &lt;td&gt;üìù Multi-Subtitle Select &amp;amp; Merge&lt;/td&gt; &#xA;    &lt;td&gt;üîÑ Auto-Update yt-dlp&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;‚ú® Simple UI&lt;/td&gt; &#xA;    &lt;td&gt;üíæ Save Description&lt;/td&gt; &#xA;    &lt;td&gt;üõ†Ô∏è FFmpeg/yt-dlp Detection&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;üìã Playlist Support&lt;/td&gt; &#xA;    &lt;td&gt;üñºÔ∏è Save thumbnail&lt;/td&gt; &#xA;    &lt;td&gt;‚öôÔ∏è Custom Commands&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;üñºÔ∏è Playlist Selector&lt;/td&gt; &#xA;    &lt;td&gt;üöÄ Speed Limiter&lt;/td&gt; &#xA;    &lt;td&gt;üç™ Login with Cookies&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;‚úÇÔ∏è Trim Video Sections&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;a id=&#34;installation&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Quick Install (Recommended)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install ytsage&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Run the application&#xA;ytsage&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;üì¶ Other Installation Methods&lt;/h3&gt; &#xA;&lt;h3&gt;Pre-built Executables&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ü™ü Windows: &lt;code&gt;YTSage.exe&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;ü™ü Windows: &lt;code&gt;YTSage-ffmpeg.exe&lt;/code&gt; (Includes FFmpeg)&lt;/li&gt; &#xA; &lt;li&gt;üêß Linux: &lt;code&gt;YTSage_{version}_amd64.deb&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;üêß Linux: &lt;code&gt;YTSage-x86_64.AppImage&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;üçé macOS: &lt;code&gt;YTSage-macOS-app.zip&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;üçé macOS: &lt;code&gt;YTSage-{version}.dmg&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;üõ†Ô∏è Manual Installation from Source&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Clone repository&#xA;git clone https://github.com/oop7/YTSage.git&#xA;&#xA;# Navigate to directory&#xA;cd YTSage&#xA;&#xA;# Install dependencies&#xA;pip install -r requirements.txt&#xA;&#xA;# Run application&#xA;python main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;a id=&#34;screenshots&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üì∏ Screenshots&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;tbody&gt;&#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/f95f7bfb-8591-4d32-b795-68e61efd670c&#34; alt=&#34;Main Interface&#34; width=&#34;400&#34; /&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/f7b3ebab-3054-4c77-8109-c899a8b10047&#34; alt=&#34;Playlist Download&#34; width=&#34;400&#34; /&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;em&gt;Main Interface&lt;/em&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;em&gt;Playlist Download&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/a80d2ae2-0031-4ed0-bee4-93293634c62a&#34; alt=&#34;Audio Format Selection with Save Thumbnail&#34; width=&#34;400&#34; /&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/5236e3cc-8a8d-4d85-a660-782a740ef9af&#34; alt=&#34;Subtitle Options merged with Remove Sponsor Segments&#34; width=&#34;400&#34; /&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;em&gt;Audio Format&lt;/em&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;em&gt;Subtitle Options&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt;&#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;a id=&#34;usage&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üìñ Usage&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;üéØ Basic Usage&lt;/summary&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Launch YTSage&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Paste YouTube URL&lt;/strong&gt; (or use &#34;Paste URL&#34; button)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Click &#34;Analyze&#34;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Select Format:&lt;/strong&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;code&gt;Video&lt;/code&gt; for video downloads&lt;/li&gt; &#xA;    &lt;li&gt;&lt;code&gt;Audio Only&lt;/code&gt; for audio extraction&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Choose Options:&lt;/strong&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Enable subtitles &amp;amp; select language&lt;/li&gt; &#xA;    &lt;li&gt;Enable subtitle merge&lt;/li&gt; &#xA;    &lt;li&gt;Save thumbnail&lt;/li&gt; &#xA;    &lt;li&gt;Remove sponsor segments&lt;/li&gt; &#xA;    &lt;li&gt;Save description&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Select Output Directory&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Click &#34;Download&#34;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;üìã Playlist Download&lt;/summary&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Paste Playlist URL&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Click &#34;Analyze&#34;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Select videos from the playlist selector (optional, defaults to all)&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Choose desired format/quality&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Click &#34;Download&#34;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;blockquote&gt; &#xA;  &lt;p&gt;üí° The application automatically handles the download queue&lt;/p&gt; &#xA; &lt;/blockquote&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;üß∞ Advanced Options&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Quality Selection:&lt;/strong&gt; Choose the highest resolution for best quality&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Subtitle Options:&lt;/strong&gt; Filter languages and embed into video&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Custom Commands:&lt;/strong&gt; Access advanced yt-dlp features&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Save Description:&lt;/strong&gt; Save the description of the video&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Save Thumbnail:&lt;/strong&gt; Save the thumbnail of the video&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Remove Sponsor Segments:&lt;/strong&gt; Remove sponsor segments from the video&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Speed Limiter:&lt;/strong&gt; Limit the download speed&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Login with Cookies:&lt;/strong&gt; Login to YouTube using cookies to access private content&lt;br /&gt; How to use it: &#xA;   &lt;ol&gt; &#xA;    &lt;li&gt;Extract cookies from your browser using an extension like &lt;a href=&#34;https://github.com/moustachauve/cookie-editor?tab=readme-ov-file&#34;&gt;cookie-editor&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;Copy the cookies in Netscape format&lt;/li&gt; &#xA;    &lt;li&gt;Create a file named &lt;code&gt;cookies.txt&lt;/code&gt; and paste the cookies into it&lt;/li&gt; &#xA;    &lt;li&gt;Select the &lt;code&gt;cookies.txt&lt;/code&gt; file in the app&lt;/li&gt; &#xA;   &lt;/ol&gt; &lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Save Download Path:&lt;/strong&gt; Save the download path&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Update yt-dlp:&lt;/strong&gt; Update yt-dlp&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;FFmpeg/yt-dlp Detection:&lt;/strong&gt; Automatically detect FFmpeg/yt-dlp&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Custom Commands:&lt;/strong&gt; Access advanced yt-dlp features&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Trim Video:&lt;/strong&gt; Download only specific parts of a video by specifying time ranges (HH:MM:SS format)&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;üõ†Ô∏è Troubleshooting&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Format table not displaying:&lt;/strong&gt; Update yt-dlp to the latest version&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Download fails:&lt;/strong&gt; Check your internet connection and ensure the video is available&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Audio extraction issues:&lt;/strong&gt; Verify FFmpeg is properly installed&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;üß© Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Python:&lt;/strong&gt; 3.7 or higher&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;GUI Framework:&lt;/strong&gt; PySide6&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Download Engine:&lt;/strong&gt; yt-dlp&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Media Processing:&lt;/strong&gt; FFmpeg&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Additional Libraries:&lt;/strong&gt; Pillow, requests, packaging, markdown, pygame&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;contributing&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üë• Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions! Here&#39;s how you can help:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;üç¥ Fork the repository&lt;/li&gt; &#xA; &lt;li&gt;üåø Create your feature branch: &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git checkout -b feature/AmazingFeature&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;üíæ Commit your changes: &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git commit -m &#39;Add some AmazingFeature&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;üì§ Push to the branch: &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git push origin feature/AmazingFeature&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;üîÑ Open a Pull Request&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;üìä Star History&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://star-history.com/#oop7/YTSage&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=oop7/YTSage&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34; /&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;üìú License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href=&#34;https://raw.githubusercontent.com/oop7/YTSage/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; &#xA;&lt;h2&gt;üôè Acknowledgments&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Technology&lt;/th&gt; &#xA;    &lt;th&gt;Purpose&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/yt-dlp/yt-dlp&#34;&gt;yt-dlp&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Download Engine&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://wiki.qt.io/Qt_for_Python&#34;&gt;PySide6&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;GUI Framework&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://ffmpeg.org/&#34;&gt;FFmpeg&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Media Processing&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://python-pillow.org/&#34;&gt;Pillow&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Image Processing&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://requests.readthedocs.io/&#34;&gt;requests&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;HTTP Requests&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://packaging.python.org/&#34;&gt;packaging&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Packaging&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://python-markdown.github.io/&#34;&gt;markdown&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Markdown Processing&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.pygame.org/&#34;&gt;pygame&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Audio Playback&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://pixabay.com/sound-effects/new-notification-09-352705/&#34;&gt;New Notification 09 by Universfield&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Notification Sound&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;‚ö†Ô∏è Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This tool is for personal use only. Please respect YouTube&#39;s terms of service and content creators&#39; rights.&lt;/p&gt; &#xA;&lt;hr /&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;Made with ‚ù§Ô∏è by &lt;a href=&#34;https://github.com/oop7&#34;&gt;oop7&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>datalab-to/marker</title>
    <updated>2025-08-15T01:39:05Z</updated>
    <id>tag:github.com,2025-08-15:/datalab-to/marker</id>
    <link href="https://github.com/datalab-to/marker" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Convert PDF to markdown + JSON quickly with high accuracy&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Marker&lt;/h1&gt; &#xA;&lt;p&gt;Marker converts documents to markdown, JSON, chunks, and HTML quickly and accurately.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Converts PDF, image, PPTX, DOCX, XLSX, HTML, EPUB files in all languages&lt;/li&gt; &#xA; &lt;li&gt;Formats tables, forms, equations, inline math, links, references, and code blocks&lt;/li&gt; &#xA; &lt;li&gt;Extracts and saves images&lt;/li&gt; &#xA; &lt;li&gt;Removes headers/footers/other artifacts&lt;/li&gt; &#xA; &lt;li&gt;Extensible with your own formatting and logic&lt;/li&gt; &#xA; &lt;li&gt;Does structured extraction, given a JSON schema (beta)&lt;/li&gt; &#xA; &lt;li&gt;Optionally boost accuracy with LLMs (and your own prompt)&lt;/li&gt; &#xA; &lt;li&gt;Works on GPU, CPU, or MPS&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Performance&lt;/h2&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/datalab-to/marker/master/data/images/overall.png&#34; width=&#34;800px&#34; /&gt; &#xA;&lt;p&gt;Marker benchmarks favorably compared to cloud services like Llamaparse and Mathpix, as well as other open source tools.&lt;/p&gt; &#xA;&lt;p&gt;The above results are running single PDF pages serially. Marker is significantly faster when running in batch mode, with a projected throughput of 25 pages/second on an H100.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/datalab-to/marker/master/#benchmarks&#34;&gt;below&lt;/a&gt; for detailed speed and accuracy benchmarks, and instructions on how to run your own benchmarks.&lt;/p&gt; &#xA;&lt;h2&gt;Hybrid Mode&lt;/h2&gt; &#xA;&lt;p&gt;For the highest accuracy, pass the &lt;code&gt;--use_llm&lt;/code&gt; flag to use an LLM alongside marker. This will do things like merge tables across pages, handle inline math, format tables properly, and extract values from forms. It can use any gemini or ollama model. By default, it uses &lt;code&gt;gemini-2.0-flash&lt;/code&gt;. See &lt;a href=&#34;https://raw.githubusercontent.com/datalab-to/marker/master/#llm-services&#34;&gt;below&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;p&gt;Here is a table benchmark comparing marker, gemini flash alone, and marker with use_llm:&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/datalab-to/marker/master/data/images/table.png&#34; width=&#34;400px&#34; /&gt; &#xA;&lt;p&gt;As you can see, the use_llm mode offers higher accuracy than marker or gemini alone.&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;PDF&lt;/th&gt; &#xA;   &lt;th&gt;File type&lt;/th&gt; &#xA;   &lt;th&gt;Markdown&lt;/th&gt; &#xA;   &lt;th&gt;JSON&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://greenteapress.com/thinkpython/thinkpython.pdf&#34;&gt;Think Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Textbook&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/VikParuchuri/marker/raw/master/data/examples/markdown/thinkpython/thinkpython.md&#34;&gt;View&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/VikParuchuri/marker/raw/master/data/examples/json/thinkpython.json&#34;&gt;View&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/2101.03961.pdf&#34;&gt;Switch Transformers&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;arXiv paper&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/VikParuchuri/marker/raw/master/data/examples/markdown/switch_transformers/switch_trans.md&#34;&gt;View&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/VikParuchuri/marker/raw/master/data/examples/json/switch_trans.json&#34;&gt;View&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/1804.07821.pdf&#34;&gt;Multi-column CNN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;arXiv paper&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/VikParuchuri/marker/raw/master/data/examples/markdown/multicolcnn/multicolcnn.md&#34;&gt;View&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/VikParuchuri/marker/raw/master/data/examples/json/multicolcnn.json&#34;&gt;View&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Commercial usage&lt;/h1&gt; &#xA;&lt;p&gt;I want marker to be as widely accessible as possible, while still funding my development/training costs. Research and personal usage is always okay, but there are some restrictions on commercial usage.&lt;/p&gt; &#xA;&lt;p&gt;The weights for the models are licensed &lt;code&gt;cc-by-nc-sa-4.0&lt;/code&gt;, but I will waive that for any organization under $2M USD in gross revenue in the most recent 12-month period AND under $2M in lifetime VC/angel funding raised. You also must not be competitive with the &lt;a href=&#34;https://www.datalab.to/&#34;&gt;Datalab API&lt;/a&gt;. If you want to remove the GPL license requirements (dual-license) and/or use the weights commercially over the revenue limit, check out the options &lt;a href=&#34;https://www.datalab.to&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Hosted API&lt;/h1&gt; &#xA;&lt;p&gt;There&#39;s a hosted API for marker available &lt;a href=&#34;https://www.datalab.to/&#34;&gt;here&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Supports PDF, image, PPT, PPTX, DOC, DOCX, XLS, XLSX, HTML, EPUB files&lt;/li&gt; &#xA; &lt;li&gt;1/4th the price of leading cloud-based competitors&lt;/li&gt; &#xA; &lt;li&gt;Fast - ~15s for a 250 page PDF&lt;/li&gt; &#xA; &lt;li&gt;Supports LLM mode&lt;/li&gt; &#xA; &lt;li&gt;High uptime (99.99%)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Community&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg//KuZwXNGnfH&#34;&gt;Discord&lt;/a&gt; is where we discuss future development.&lt;/p&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;p&gt;You&#39;ll need python 3.10+ and &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;PyTorch&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Install with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install marker-pdf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to use marker on documents other than PDFs, you will need to install additional dependencies with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install marker-pdf[full]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;p&gt;First, some configuration:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Your torch device will be automatically detected, but you can override this. For example, &lt;code&gt;TORCH_DEVICE=cuda&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Some PDFs, even digital ones, have bad text in them. Set &lt;code&gt;--force_ocr&lt;/code&gt; to force OCR on all lines, or the &lt;code&gt;strip_existing_ocr&lt;/code&gt; to keep all digital text, and strip out any existing OCR text.&lt;/li&gt; &#xA; &lt;li&gt;If you care about inline math, set &lt;code&gt;force_ocr&lt;/code&gt; to convert inline math to LaTeX.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Interactive App&lt;/h2&gt; &#xA;&lt;p&gt;I&#39;ve included a streamlit app that lets you interactively try marker with some basic options. Run it with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install streamlit streamlit-ace&#xA;marker_gui&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Convert a single file&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;marker_single /path/to/file.pdf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can pass in PDFs or images.&lt;/p&gt; &#xA;&lt;p&gt;Options:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--page_range TEXT&lt;/code&gt;: Specify which pages to process. Accepts comma-separated page numbers and ranges. Example: &lt;code&gt;--page_range &#34;0,5-10,20&#34;&lt;/code&gt; will process pages 0, 5 through 10, and page 20.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--output_format [markdown|json|html|chunks]&lt;/code&gt;: Specify the format for the output results.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--output_dir PATH&lt;/code&gt;: Directory where output files will be saved. Defaults to the value specified in settings.OUTPUT_DIR.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--paginate_output&lt;/code&gt;: Paginates the output, using &lt;code&gt;\n\n{PAGE_NUMBER}&lt;/code&gt; followed by &lt;code&gt;-&lt;/code&gt; * 48, then &lt;code&gt;\n\n&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--use_llm&lt;/code&gt;: Uses an LLM to improve accuracy. You will need to configure the LLM backend - see &lt;a href=&#34;https://raw.githubusercontent.com/datalab-to/marker/master/#llm-services&#34;&gt;below&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--force_ocr&lt;/code&gt;: Force OCR processing on the entire document, even for pages that might contain extractable text. This will also format inline math properly.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--block_correction_prompt&lt;/code&gt;: if LLM mode is active, an optional prompt that will be used to correct the output of marker. This is useful for custom formatting or logic that you want to apply to the output.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--strip_existing_ocr&lt;/code&gt;: Remove all existing OCR text in the document and re-OCR with surya.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--redo_inline_math&lt;/code&gt;: If you want the absolute highest quality inline math conversion, use this along with &lt;code&gt;--use_llm&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--disable_image_extraction&lt;/code&gt;: Don&#39;t extract images from the PDF. If you also specify &lt;code&gt;--use_llm&lt;/code&gt;, then images will be replaced with a description.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--debug&lt;/code&gt;: Enable debug mode for additional logging and diagnostic information.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--processors TEXT&lt;/code&gt;: Override the default processors by providing their full module paths, separated by commas. Example: &lt;code&gt;--processors &#34;module1.processor1,module2.processor2&#34;&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--config_json PATH&lt;/code&gt;: Path to a JSON configuration file containing additional settings.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;config --help&lt;/code&gt;: List all available builders, processors, and converters, and their associated configuration. These values can be used to build a JSON configuration file for additional tweaking of marker defaults.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--converter_cls&lt;/code&gt;: One of &lt;code&gt;marker.converters.pdf.PdfConverter&lt;/code&gt; (default) or &lt;code&gt;marker.converters.table.TableConverter&lt;/code&gt;. The &lt;code&gt;PdfConverter&lt;/code&gt; will convert the whole PDF, the &lt;code&gt;TableConverter&lt;/code&gt; will only extract and convert tables.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--llm_service&lt;/code&gt;: Which llm service to use if &lt;code&gt;--use_llm&lt;/code&gt; is passed. This defaults to &lt;code&gt;marker.services.gemini.GoogleGeminiService&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--help&lt;/code&gt;: see all of the flags that can be passed into marker. (it supports many more options then are listed above)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The list of supported languages for surya OCR is &lt;a href=&#34;https://github.com/VikParuchuri/surya/raw/master/surya/recognition/languages.py&#34;&gt;here&lt;/a&gt;. If you don&#39;t need OCR, marker can work with any language.&lt;/p&gt; &#xA;&lt;h2&gt;Convert multiple files&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;marker /path/to/input/folder&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;marker&lt;/code&gt; supports all the same options from &lt;code&gt;marker_single&lt;/code&gt; above.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--workers&lt;/code&gt; is the number of conversion workers to run simultaneously. This is automatically set by default, but you can increase it to increase throughput, at the cost of more CPU/GPU usage. Marker will use 5GB of VRAM per worker at the peak, and 3.5GB average.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Convert multiple files on multiple GPUs&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;NUM_DEVICES=4 NUM_WORKERS=15 marker_chunk_convert ../pdf_in ../md_out&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;NUM_DEVICES&lt;/code&gt; is the number of GPUs to use. Should be &lt;code&gt;2&lt;/code&gt; or greater.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;NUM_WORKERS&lt;/code&gt; is the number of parallel processes to run on each GPU.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Use from python&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;code&gt;PdfConverter&lt;/code&gt; class at &lt;code&gt;marker/converters/pdf.py&lt;/code&gt; function for additional arguments that can be passed.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from marker.converters.pdf import PdfConverter&#xA;from marker.models import create_model_dict&#xA;from marker.output import text_from_rendered&#xA;&#xA;converter = PdfConverter(&#xA;    artifact_dict=create_model_dict(),&#xA;)&#xA;rendered = converter(&#34;FILEPATH&#34;)&#xA;text, _, images = text_from_rendered(rendered)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;rendered&lt;/code&gt; will be a pydantic basemodel with different properties depending on the output type requested. With markdown output (default), you&#39;ll have the properties &lt;code&gt;markdown&lt;/code&gt;, &lt;code&gt;metadata&lt;/code&gt;, and &lt;code&gt;images&lt;/code&gt;. For json output, you&#39;ll have &lt;code&gt;children&lt;/code&gt;, &lt;code&gt;block_type&lt;/code&gt;, and &lt;code&gt;metadata&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Custom configuration&lt;/h3&gt; &#xA;&lt;p&gt;You can pass configuration using the &lt;code&gt;ConfigParser&lt;/code&gt;. To see all available options, do &lt;code&gt;marker_single --help&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from marker.converters.pdf import PdfConverter&#xA;from marker.models import create_model_dict&#xA;from marker.config.parser import ConfigParser&#xA;&#xA;config = {&#xA;    &#34;output_format&#34;: &#34;json&#34;,&#xA;    &#34;ADDITIONAL_KEY&#34;: &#34;VALUE&#34;&#xA;}&#xA;config_parser = ConfigParser(config)&#xA;&#xA;converter = PdfConverter(&#xA;    config=config_parser.generate_config_dict(),&#xA;    artifact_dict=create_model_dict(),&#xA;    processor_list=config_parser.get_processors(),&#xA;    renderer=config_parser.get_renderer(),&#xA;    llm_service=config_parser.get_llm_service()&#xA;)&#xA;rendered = converter(&#34;FILEPATH&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Extract blocks&lt;/h3&gt; &#xA;&lt;p&gt;Each document consists of one or more pages. Pages contain blocks, which can themselves contain other blocks. It&#39;s possible to programmatically manipulate these blocks.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s an example of extracting all forms from a document:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from marker.converters.pdf import PdfConverter&#xA;from marker.models import create_model_dict&#xA;from marker.schema import BlockTypes&#xA;&#xA;converter = PdfConverter(&#xA;    artifact_dict=create_model_dict(),&#xA;)&#xA;document = converter.build_document(&#34;FILEPATH&#34;)&#xA;forms = document.contained_blocks((BlockTypes.Form,))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Look at the processors for more examples of extracting and manipulating blocks.&lt;/p&gt; &#xA;&lt;h2&gt;Other converters&lt;/h2&gt; &#xA;&lt;p&gt;You can also use other converters that define different conversion pipelines:&lt;/p&gt; &#xA;&lt;h3&gt;Extract tables&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;TableConverter&lt;/code&gt; will only convert and extract tables:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from marker.converters.table import TableConverter&#xA;from marker.models import create_model_dict&#xA;from marker.output import text_from_rendered&#xA;&#xA;converter = TableConverter(&#xA;    artifact_dict=create_model_dict(),&#xA;)&#xA;rendered = converter(&#34;FILEPATH&#34;)&#xA;text, _, images = text_from_rendered(rendered)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This takes all the same configuration as the PdfConverter. You can specify the configuration &lt;code&gt;force_layout_block=Table&lt;/code&gt; to avoid layout detection and instead assume every page is a table. Set &lt;code&gt;output_format=json&lt;/code&gt; to also get cell bounding boxes.&lt;/p&gt; &#xA;&lt;p&gt;You can also run this via the CLI with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;marker_single FILENAME --use_llm --force_layout_block Table --converter_cls marker.converters.table.TableConverter --output_format json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;OCR Only&lt;/h3&gt; &#xA;&lt;p&gt;If you only want to run OCR, you can also do that through the &lt;code&gt;OCRConverter&lt;/code&gt;. Set &lt;code&gt;--keep_chars&lt;/code&gt; to keep individual characters and bounding boxes.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from marker.converters.ocr import OCRConverter&#xA;from marker.models import create_model_dict&#xA;&#xA;converter = OCRConverter(&#xA;    artifact_dict=create_model_dict(),&#xA;)&#xA;rendered = converter(&#34;FILEPATH&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This takes all the same configuration as the PdfConverter.&lt;/p&gt; &#xA;&lt;p&gt;You can also run this via the CLI with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;marker_single FILENAME --converter_cls marker.converters.ocr.OCRConverter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Structured Extraction (beta)&lt;/h3&gt; &#xA;&lt;p&gt;You can run structured extraction via the &lt;code&gt;ExtractionConverter&lt;/code&gt;. This requires an llm service to be setup first (see &lt;a href=&#34;https://raw.githubusercontent.com/datalab-to/marker/master/#llm-services&#34;&gt;here&lt;/a&gt; for details). You&#39;ll get a JSON output with the extracted values.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from marker.converters.extraction import ExtractionConverter&#xA;from marker.models import create_model_dict&#xA;from marker.config.parser import ConfigParser&#xA;from pydantic import BaseModel&#xA;&#xA;class Links(BaseModel):&#xA;    links: list[str]&#xA;    &#xA;schema = Links.model_json_schema()&#xA;config_parser = ConfigParser({&#xA;    &#34;page_schema&#34;: schema&#xA;})&#xA;&#xA;converter = ExtractionConverter(&#xA;    artifact_dict=create_model_dict(),&#xA;    config=config_parser.generate_config_dict(),&#xA;    llm_service=config_parser.get_llm_service(),&#xA;)&#xA;rendered = converter(&#34;FILEPATH&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Rendered will have an &lt;code&gt;original_markdown&lt;/code&gt; field. If you pass this back in next time you run the converter, as the &lt;code&gt;existing_markdown&lt;/code&gt; config key, you can skip re-parsing the document.&lt;/p&gt; &#xA;&lt;h1&gt;Output Formats&lt;/h1&gt; &#xA;&lt;h2&gt;Markdown&lt;/h2&gt; &#xA;&lt;p&gt;Markdown output will include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;image links (images will be saved in the same folder)&lt;/li&gt; &#xA; &lt;li&gt;formatted tables&lt;/li&gt; &#xA; &lt;li&gt;embedded LaTeX equations (fenced with &lt;code&gt;$$&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Code is fenced with triple backticks&lt;/li&gt; &#xA; &lt;li&gt;Superscripts for footnotes&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;HTML&lt;/h2&gt; &#xA;&lt;p&gt;HTML output is similar to markdown output:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Images are included via &lt;code&gt;img&lt;/code&gt; tags&lt;/li&gt; &#xA; &lt;li&gt;equations are fenced with &lt;code&gt;&amp;lt;math&amp;gt;&lt;/code&gt; tags&lt;/li&gt; &#xA; &lt;li&gt;code is in &lt;code&gt;pre&lt;/code&gt; tags&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;JSON&lt;/h2&gt; &#xA;&lt;p&gt;JSON output will be organized in a tree-like structure, with the leaf nodes being blocks. Examples of leaf nodes are a single list item, a paragraph of text, or an image.&lt;/p&gt; &#xA;&lt;p&gt;The output will be a list, with each list item representing a page. Each page is considered a block in the internal marker schema. There are different types of blocks to represent different elements.&lt;/p&gt; &#xA;&lt;p&gt;Pages have the keys:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;id&lt;/code&gt; - unique id for the block.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;block_type&lt;/code&gt; - the type of block. The possible block types can be seen in &lt;code&gt;marker/schema/__init__.py&lt;/code&gt;. As of this writing, they are [&#34;Line&#34;, &#34;Span&#34;, &#34;FigureGroup&#34;, &#34;TableGroup&#34;, &#34;ListGroup&#34;, &#34;PictureGroup&#34;, &#34;Page&#34;, &#34;Caption&#34;, &#34;Code&#34;, &#34;Figure&#34;, &#34;Footnote&#34;, &#34;Form&#34;, &#34;Equation&#34;, &#34;Handwriting&#34;, &#34;TextInlineMath&#34;, &#34;ListItem&#34;, &#34;PageFooter&#34;, &#34;PageHeader&#34;, &#34;Picture&#34;, &#34;SectionHeader&#34;, &#34;Table&#34;, &#34;Text&#34;, &#34;TableOfContents&#34;, &#34;Document&#34;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;html&lt;/code&gt; - the HTML for the page. Note that this will have recursive references to children. The &lt;code&gt;content-ref&lt;/code&gt; tags must be replaced with the child content if you want the full html. You can see an example of this at &lt;code&gt;marker/output.py:json_to_html&lt;/code&gt;. That function will take in a single block from the json output, and turn it into HTML.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;polygon&lt;/code&gt; - the 4-corner polygon of the page, in (x1,y1), (x2,y2), (x3, y3), (x4, y4) format. (x1,y1) is the top left, and coordinates go clockwise.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;children&lt;/code&gt; - the child blocks.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The child blocks have two additional keys:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;section_hierarchy&lt;/code&gt; - indicates the sections that the block is part of. &lt;code&gt;1&lt;/code&gt; indicates an h1 tag, &lt;code&gt;2&lt;/code&gt; an h2, and so on.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;images&lt;/code&gt; - base64 encoded images. The key will be the block id, and the data will be the encoded image.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note that child blocks of pages can have their own children as well (a tree structure).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;      &#34;id&#34;: &#34;/page/10/Page/366&#34;,&#xA;      &#34;block_type&#34;: &#34;Page&#34;,&#xA;      &#34;html&#34;: &#34;&amp;lt;content-ref src=&#39;/page/10/SectionHeader/0&#39;&amp;gt;&amp;lt;/content-ref&amp;gt;&amp;lt;content-ref src=&#39;/page/10/SectionHeader/1&#39;&amp;gt;&amp;lt;/content-ref&amp;gt;&amp;lt;content-ref src=&#39;/page/10/Text/2&#39;&amp;gt;&amp;lt;/content-ref&amp;gt;&amp;lt;content-ref src=&#39;/page/10/Text/3&#39;&amp;gt;&amp;lt;/content-ref&amp;gt;&amp;lt;content-ref src=&#39;/page/10/Figure/4&#39;&amp;gt;&amp;lt;/content-ref&amp;gt;&amp;lt;content-ref src=&#39;/page/10/SectionHeader/5&#39;&amp;gt;&amp;lt;/content-ref&amp;gt;&amp;lt;content-ref src=&#39;/page/10/SectionHeader/6&#39;&amp;gt;&amp;lt;/content-ref&amp;gt;&amp;lt;content-ref src=&#39;/page/10/TextInlineMath/7&#39;&amp;gt;&amp;lt;/content-ref&amp;gt;&amp;lt;content-ref src=&#39;/page/10/TextInlineMath/8&#39;&amp;gt;&amp;lt;/content-ref&amp;gt;&amp;lt;content-ref src=&#39;/page/10/Table/9&#39;&amp;gt;&amp;lt;/content-ref&amp;gt;&amp;lt;content-ref src=&#39;/page/10/SectionHeader/10&#39;&amp;gt;&amp;lt;/content-ref&amp;gt;&amp;lt;content-ref src=&#39;/page/10/Text/11&#39;&amp;gt;&amp;lt;/content-ref&amp;gt;&#34;,&#xA;      &#34;polygon&#34;: [[0.0, 0.0], [612.0, 0.0], [612.0, 792.0], [0.0, 792.0]],&#xA;      &#34;children&#34;: [&#xA;        {&#xA;          &#34;id&#34;: &#34;/page/10/SectionHeader/0&#34;,&#xA;          &#34;block_type&#34;: &#34;SectionHeader&#34;,&#xA;          &#34;html&#34;: &#34;&amp;lt;h1&amp;gt;Supplementary Material for &amp;lt;i&amp;gt;Subspace Adversarial Training&amp;lt;/i&amp;gt; &amp;lt;/h1&amp;gt;&#34;,&#xA;          &#34;polygon&#34;: [&#xA;            [217.845703125, 80.630859375], [374.73046875, 80.630859375],&#xA;            [374.73046875, 107.0],&#xA;            [217.845703125, 107.0]&#xA;          ],&#xA;          &#34;children&#34;: null,&#xA;          &#34;section_hierarchy&#34;: {&#xA;            &#34;1&#34;: &#34;/page/10/SectionHeader/1&#34;&#xA;          },&#xA;          &#34;images&#34;: {}&#xA;        },&#xA;        ...&#xA;        ]&#xA;    }&#xA;&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Chunks&lt;/h2&gt; &#xA;&lt;p&gt;Chunks format is similar to JSON, but flattens everything into a single list instead of a tree. Only the top level blocks from each page show up. It also has the full HTML of each block inside, so you don&#39;t need to crawl the tree to reconstruct it. This enable flexible and easy chunking for RAG.&lt;/p&gt; &#xA;&lt;h2&gt;Metadata&lt;/h2&gt; &#xA;&lt;p&gt;All output formats will return a metadata dictionary, with the following fields:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;    &#34;table_of_contents&#34;: [&#xA;      {&#xA;        &#34;title&#34;: &#34;Introduction&#34;,&#xA;        &#34;heading_level&#34;: 1,&#xA;        &#34;page_id&#34;: 0,&#xA;        &#34;polygon&#34;: [...]&#xA;      }&#xA;    ], // computed PDF table of contents&#xA;    &#34;page_stats&#34;: [&#xA;      {&#xA;        &#34;page_id&#34;:  0, &#xA;        &#34;text_extraction_method&#34;: &#34;pdftext&#34;,&#xA;        &#34;block_counts&#34;: [(&#34;Span&#34;, 200), ...]&#xA;      },&#xA;      ...&#xA;    ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;LLM Services&lt;/h1&gt; &#xA;&lt;p&gt;When running with the &lt;code&gt;--use_llm&lt;/code&gt; flag, you have a choice of services you can use:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Gemini&lt;/code&gt; - this will use the Gemini developer API by default. You&#39;ll need to pass &lt;code&gt;--gemini_api_key&lt;/code&gt; to configuration.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Google Vertex&lt;/code&gt; - this will use vertex, which can be more reliable. You&#39;ll need to pass &lt;code&gt;--vertex_project_id&lt;/code&gt;. To use it, set &lt;code&gt;--llm_service=marker.services.vertex.GoogleVertexService&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Ollama&lt;/code&gt; - this will use local models. You can configure &lt;code&gt;--ollama_base_url&lt;/code&gt; and &lt;code&gt;--ollama_model&lt;/code&gt;. To use it, set &lt;code&gt;--llm_service=marker.services.ollama.OllamaService&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Claude&lt;/code&gt; - this will use the anthropic API. You can configure &lt;code&gt;--claude_api_key&lt;/code&gt;, and &lt;code&gt;--claude_model_name&lt;/code&gt;. To use it, set &lt;code&gt;--llm_service=marker.services.claude.ClaudeService&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;OpenAI&lt;/code&gt; - this supports any openai-like endpoint. You can configure &lt;code&gt;--openai_api_key&lt;/code&gt;, &lt;code&gt;--openai_model&lt;/code&gt;, and &lt;code&gt;--openai_base_url&lt;/code&gt;. To use it, set &lt;code&gt;--llm_service=marker.services.openai.OpenAIService&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Azure OpenAI&lt;/code&gt; - this uses the Azure OpenAI service. You can configure &lt;code&gt;--azure_endpoint&lt;/code&gt;, &lt;code&gt;--azure_api_key&lt;/code&gt;, and &lt;code&gt;--deployment_name&lt;/code&gt;. To use it, set &lt;code&gt;--llm_service=marker.services.azure_openai.AzureOpenAIService&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;These services may have additional optional configuration as well - you can see it by viewing the classes.&lt;/p&gt; &#xA;&lt;h1&gt;Internals&lt;/h1&gt; &#xA;&lt;p&gt;Marker is easy to extend. The core units of marker are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Providers&lt;/code&gt;, at &lt;code&gt;marker/providers&lt;/code&gt;. These provide information from a source file, like a PDF.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Builders&lt;/code&gt;, at &lt;code&gt;marker/builders&lt;/code&gt;. These generate the initial document blocks and fill in text, using info from the providers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Processors&lt;/code&gt;, at &lt;code&gt;marker/processors&lt;/code&gt;. These process specific blocks, for example the table formatter is a processor.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Renderers&lt;/code&gt;, at &lt;code&gt;marker/renderers&lt;/code&gt;. These use the blocks to render output.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Schema&lt;/code&gt;, at &lt;code&gt;marker/schema&lt;/code&gt;. The classes for all the block types.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Converters&lt;/code&gt;, at &lt;code&gt;marker/converters&lt;/code&gt;. They run the whole end to end pipeline.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To customize processing behavior, override the &lt;code&gt;processors&lt;/code&gt;. To add new output formats, write a new &lt;code&gt;renderer&lt;/code&gt;. For additional input formats, write a new &lt;code&gt;provider.&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Processors and renderers can be directly passed into the base &lt;code&gt;PDFConverter&lt;/code&gt;, so you can specify your own custom processing easily.&lt;/p&gt; &#xA;&lt;h2&gt;API server&lt;/h2&gt; &#xA;&lt;p&gt;There is a very simple API server you can run like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install -U uvicorn fastapi python-multipart&#xA;marker_server --port 8001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will start a fastapi server that you can access at &lt;code&gt;localhost:8001&lt;/code&gt;. You can go to &lt;code&gt;localhost:8001/docs&lt;/code&gt; to see the endpoint options.&lt;/p&gt; &#xA;&lt;p&gt;You can send requests like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import requests&#xA;import json&#xA;&#xA;post_data = {&#xA;    &#39;filepath&#39;: &#39;FILEPATH&#39;,&#xA;    # Add other params here&#xA;}&#xA;&#xA;requests.post(&#34;http://localhost:8001/marker&#34;, data=json.dumps(post_data)).json()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that this is not a very robust API, and is only intended for small-scale use. If you want to use this server, but want a more robust conversion option, you can use the hosted &lt;a href=&#34;https://www.datalab.to/plans&#34;&gt;Datalab API&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Troubleshooting&lt;/h1&gt; &#xA;&lt;p&gt;There are some settings that you may find useful if things aren&#39;t working the way you expect:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you have issues with accuracy, try setting &lt;code&gt;--use_llm&lt;/code&gt; to use an LLM to improve quality. You must set &lt;code&gt;GOOGLE_API_KEY&lt;/code&gt; to a Gemini API key for this to work.&lt;/li&gt; &#xA; &lt;li&gt;Make sure to set &lt;code&gt;force_ocr&lt;/code&gt; if you see garbled text - this will re-OCR the document.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;TORCH_DEVICE&lt;/code&gt; - set this to force marker to use a given torch device for inference.&lt;/li&gt; &#xA; &lt;li&gt;If you&#39;re getting out of memory errors, decrease worker count. You can also try splitting up long PDFs into multiple files.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Debugging&lt;/h2&gt; &#xA;&lt;p&gt;Pass the &lt;code&gt;debug&lt;/code&gt; option to activate debug mode. This will save images of each page with detected layout and text, as well as output a json file with additional bounding box information.&lt;/p&gt; &#xA;&lt;h1&gt;Benchmarks&lt;/h1&gt; &#xA;&lt;h2&gt;Overall PDF Conversion&lt;/h2&gt; &#xA;&lt;p&gt;We created a &lt;a href=&#34;https://huggingface.co/datasets/datalab-to/marker_benchmark&#34;&gt;benchmark set&lt;/a&gt; by extracting single PDF pages from common crawl. We scored based on a heuristic that aligns text with ground truth text segments, and an LLM as a judge scoring method.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Avg Time&lt;/th&gt; &#xA;   &lt;th&gt;Heuristic Score&lt;/th&gt; &#xA;   &lt;th&gt;LLM Score&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;marker&lt;/td&gt; &#xA;   &lt;td&gt;2.83837&lt;/td&gt; &#xA;   &lt;td&gt;95.6709&lt;/td&gt; &#xA;   &lt;td&gt;4.23916&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llamaparse&lt;/td&gt; &#xA;   &lt;td&gt;23.348&lt;/td&gt; &#xA;   &lt;td&gt;84.2442&lt;/td&gt; &#xA;   &lt;td&gt;3.97619&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mathpix&lt;/td&gt; &#xA;   &lt;td&gt;6.36223&lt;/td&gt; &#xA;   &lt;td&gt;86.4281&lt;/td&gt; &#xA;   &lt;td&gt;4.15626&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;docling&lt;/td&gt; &#xA;   &lt;td&gt;3.69949&lt;/td&gt; &#xA;   &lt;td&gt;86.7073&lt;/td&gt; &#xA;   &lt;td&gt;3.70429&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Benchmarks were run on an H100 for markjer and docling - llamaparse and mathpix used their cloud services. We can also look at it by document type:&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/datalab-to/marker/master/data/images/per_doc.png&#34; width=&#34;1000px&#34; /&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Document Type&lt;/th&gt; &#xA;   &lt;th&gt;Marker heuristic&lt;/th&gt; &#xA;   &lt;th&gt;Marker LLM&lt;/th&gt; &#xA;   &lt;th&gt;Llamaparse Heuristic&lt;/th&gt; &#xA;   &lt;th&gt;Llamaparse LLM&lt;/th&gt; &#xA;   &lt;th&gt;Mathpix Heuristic&lt;/th&gt; &#xA;   &lt;th&gt;Mathpix LLM&lt;/th&gt; &#xA;   &lt;th&gt;Docling Heuristic&lt;/th&gt; &#xA;   &lt;th&gt;Docling LLM&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Scientific paper&lt;/td&gt; &#xA;   &lt;td&gt;96.6737&lt;/td&gt; &#xA;   &lt;td&gt;4.34899&lt;/td&gt; &#xA;   &lt;td&gt;87.1651&lt;/td&gt; &#xA;   &lt;td&gt;3.96421&lt;/td&gt; &#xA;   &lt;td&gt;91.2267&lt;/td&gt; &#xA;   &lt;td&gt;4.46861&lt;/td&gt; &#xA;   &lt;td&gt;92.135&lt;/td&gt; &#xA;   &lt;td&gt;3.72422&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Book page&lt;/td&gt; &#xA;   &lt;td&gt;97.1846&lt;/td&gt; &#xA;   &lt;td&gt;4.16168&lt;/td&gt; &#xA;   &lt;td&gt;90.9532&lt;/td&gt; &#xA;   &lt;td&gt;4.07186&lt;/td&gt; &#xA;   &lt;td&gt;93.8886&lt;/td&gt; &#xA;   &lt;td&gt;4.35329&lt;/td&gt; &#xA;   &lt;td&gt;90.0556&lt;/td&gt; &#xA;   &lt;td&gt;3.64671&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Other&lt;/td&gt; &#xA;   &lt;td&gt;95.1632&lt;/td&gt; &#xA;   &lt;td&gt;4.25076&lt;/td&gt; &#xA;   &lt;td&gt;81.1385&lt;/td&gt; &#xA;   &lt;td&gt;4.01835&lt;/td&gt; &#xA;   &lt;td&gt;79.6231&lt;/td&gt; &#xA;   &lt;td&gt;4.00306&lt;/td&gt; &#xA;   &lt;td&gt;83.8223&lt;/td&gt; &#xA;   &lt;td&gt;3.76147&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Form&lt;/td&gt; &#xA;   &lt;td&gt;88.0147&lt;/td&gt; &#xA;   &lt;td&gt;3.84663&lt;/td&gt; &#xA;   &lt;td&gt;66.3081&lt;/td&gt; &#xA;   &lt;td&gt;3.68712&lt;/td&gt; &#xA;   &lt;td&gt;64.7512&lt;/td&gt; &#xA;   &lt;td&gt;3.33129&lt;/td&gt; &#xA;   &lt;td&gt;68.3857&lt;/td&gt; &#xA;   &lt;td&gt;3.40491&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Presentation&lt;/td&gt; &#xA;   &lt;td&gt;95.1562&lt;/td&gt; &#xA;   &lt;td&gt;4.13669&lt;/td&gt; &#xA;   &lt;td&gt;81.2261&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;83.6737&lt;/td&gt; &#xA;   &lt;td&gt;3.95683&lt;/td&gt; &#xA;   &lt;td&gt;84.8405&lt;/td&gt; &#xA;   &lt;td&gt;3.86331&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Financial document&lt;/td&gt; &#xA;   &lt;td&gt;95.3697&lt;/td&gt; &#xA;   &lt;td&gt;4.39106&lt;/td&gt; &#xA;   &lt;td&gt;82.5812&lt;/td&gt; &#xA;   &lt;td&gt;4.16111&lt;/td&gt; &#xA;   &lt;td&gt;81.3115&lt;/td&gt; &#xA;   &lt;td&gt;4.05556&lt;/td&gt; &#xA;   &lt;td&gt;86.3882&lt;/td&gt; &#xA;   &lt;td&gt;3.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Letter&lt;/td&gt; &#xA;   &lt;td&gt;98.4021&lt;/td&gt; &#xA;   &lt;td&gt;4.5&lt;/td&gt; &#xA;   &lt;td&gt;93.4477&lt;/td&gt; &#xA;   &lt;td&gt;4.28125&lt;/td&gt; &#xA;   &lt;td&gt;96.0383&lt;/td&gt; &#xA;   &lt;td&gt;4.45312&lt;/td&gt; &#xA;   &lt;td&gt;92.0952&lt;/td&gt; &#xA;   &lt;td&gt;4.09375&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Engineering document&lt;/td&gt; &#xA;   &lt;td&gt;93.9244&lt;/td&gt; &#xA;   &lt;td&gt;4.04412&lt;/td&gt; &#xA;   &lt;td&gt;77.4854&lt;/td&gt; &#xA;   &lt;td&gt;3.72059&lt;/td&gt; &#xA;   &lt;td&gt;80.3319&lt;/td&gt; &#xA;   &lt;td&gt;3.88235&lt;/td&gt; &#xA;   &lt;td&gt;79.6807&lt;/td&gt; &#xA;   &lt;td&gt;3.42647&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Legal document&lt;/td&gt; &#xA;   &lt;td&gt;96.689&lt;/td&gt; &#xA;   &lt;td&gt;4.27759&lt;/td&gt; &#xA;   &lt;td&gt;86.9769&lt;/td&gt; &#xA;   &lt;td&gt;3.87584&lt;/td&gt; &#xA;   &lt;td&gt;91.601&lt;/td&gt; &#xA;   &lt;td&gt;4.20805&lt;/td&gt; &#xA;   &lt;td&gt;87.8383&lt;/td&gt; &#xA;   &lt;td&gt;3.65552&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Newspaper page&lt;/td&gt; &#xA;   &lt;td&gt;98.8733&lt;/td&gt; &#xA;   &lt;td&gt;4.25806&lt;/td&gt; &#xA;   &lt;td&gt;84.7492&lt;/td&gt; &#xA;   &lt;td&gt;3.90323&lt;/td&gt; &#xA;   &lt;td&gt;96.9963&lt;/td&gt; &#xA;   &lt;td&gt;4.45161&lt;/td&gt; &#xA;   &lt;td&gt;92.6496&lt;/td&gt; &#xA;   &lt;td&gt;3.51613&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Magazine page&lt;/td&gt; &#xA;   &lt;td&gt;98.2145&lt;/td&gt; &#xA;   &lt;td&gt;4.38776&lt;/td&gt; &#xA;   &lt;td&gt;87.2902&lt;/td&gt; &#xA;   &lt;td&gt;3.97959&lt;/td&gt; &#xA;   &lt;td&gt;93.5934&lt;/td&gt; &#xA;   &lt;td&gt;4.16327&lt;/td&gt; &#xA;   &lt;td&gt;93.0892&lt;/td&gt; &#xA;   &lt;td&gt;4.02041&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Throughput&lt;/h2&gt; &#xA;&lt;p&gt;We benchmarked throughput using a &lt;a href=&#34;https://www.greenteapress.com/thinkpython/thinkpython.pdf&#34;&gt;single long PDF&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Time per page&lt;/th&gt; &#xA;   &lt;th&gt;Time per document&lt;/th&gt; &#xA;   &lt;th&gt;VRAM used&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;marker&lt;/td&gt; &#xA;   &lt;td&gt;0.18&lt;/td&gt; &#xA;   &lt;td&gt;43.42&lt;/td&gt; &#xA;   &lt;td&gt;3.17GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The projected throughput is 122 pages per second on an H100 - we can run 22 individual processes given the VRAM used.&lt;/p&gt; &#xA;&lt;h2&gt;Table Conversion&lt;/h2&gt; &#xA;&lt;p&gt;Marker can extract tables from PDFs using &lt;code&gt;marker.converters.table.TableConverter&lt;/code&gt;. The table extraction performance is measured by comparing the extracted HTML representation of tables against the original HTML representations using the test split of &lt;a href=&#34;https://developer.ibm.com/exchanges/data/all/fintabnet/&#34;&gt;FinTabNet&lt;/a&gt;. The HTML representations are compared using a tree edit distance based metric to judge both structure and content. Marker detects and identifies the structure of all tables in a PDF page and achieves these scores:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Avg score&lt;/th&gt; &#xA;   &lt;th&gt;Total tables&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;marker&lt;/td&gt; &#xA;   &lt;td&gt;0.816&lt;/td&gt; &#xA;   &lt;td&gt;99&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;marker w/use_llm&lt;/td&gt; &#xA;   &lt;td&gt;0.907&lt;/td&gt; &#xA;   &lt;td&gt;99&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;gemini&lt;/td&gt; &#xA;   &lt;td&gt;0.829&lt;/td&gt; &#xA;   &lt;td&gt;99&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The &lt;code&gt;--use_llm&lt;/code&gt; flag can significantly improve table recognition performance, as you can see.&lt;/p&gt; &#xA;&lt;p&gt;We filter out tables that we cannot align with the ground truth, since fintabnet and our layout model have slightly different detection methods (this results in some tables being split/merged).&lt;/p&gt; &#xA;&lt;h2&gt;Running your own benchmarks&lt;/h2&gt; &#xA;&lt;p&gt;You can benchmark the performance of marker on your machine. Install marker manually with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/VikParuchuri/marker.git&#xA;poetry install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Overall PDF Conversion&lt;/h3&gt; &#xA;&lt;p&gt;Download the benchmark data &lt;a href=&#34;https://drive.google.com/file/d/1ZSeWDo2g1y0BRLT7KnbmytV2bjWARWba/view?usp=sharing&#34;&gt;here&lt;/a&gt; and unzip. Then run the overall benchmark like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python benchmarks/overall.py --methods marker --scores heuristic,llm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Options:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--use_llm&lt;/code&gt; use an llm to improve the marker results.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--max_rows&lt;/code&gt; how many rows to process for the benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--methods&lt;/code&gt; can be &lt;code&gt;llamaparse&lt;/code&gt;, &lt;code&gt;mathpix&lt;/code&gt;, &lt;code&gt;docling&lt;/code&gt;, &lt;code&gt;marker&lt;/code&gt;. Comma separated.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--scores&lt;/code&gt; which scoring functions to use, can be &lt;code&gt;llm&lt;/code&gt;, &lt;code&gt;heuristic&lt;/code&gt;. Comma separated.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Table Conversion&lt;/h3&gt; &#xA;&lt;p&gt;The processed FinTabNet dataset is hosted &lt;a href=&#34;https://huggingface.co/datasets/datalab-to/fintabnet-test&#34;&gt;here&lt;/a&gt; and is automatically downloaded. Run the benchmark with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python benchmarks/table/table.py --max_rows 100&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Options:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--use_llm&lt;/code&gt; uses an llm with marker to improve accuracy.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--use_gemini&lt;/code&gt; also benchmarks gemini 2.0 flash.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;How it works&lt;/h1&gt; &#xA;&lt;p&gt;Marker is a pipeline of deep learning models:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Extract text, OCR if necessary (heuristics, &lt;a href=&#34;https://github.com/VikParuchuri/surya&#34;&gt;surya&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Detect page layout and find reading order (&lt;a href=&#34;https://github.com/VikParuchuri/surya&#34;&gt;surya&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Clean and format each block (heuristics, &lt;a href=&#34;https://github.com/VikParuchuri/texify&#34;&gt;texify&lt;/a&gt;, &lt;a href=&#34;https://github.com/VikParuchuri/surya&#34;&gt;surya&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Optionally use an LLM to improve quality&lt;/li&gt; &#xA; &lt;li&gt;Combine blocks and postprocess complete text&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;It only uses models where necessary, which improves speed and accuracy.&lt;/p&gt; &#xA;&lt;h1&gt;Limitations&lt;/h1&gt; &#xA;&lt;p&gt;PDF is a tricky format, so marker will not always work perfectly. Here are some known limitations that are on the roadmap to address:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Very complex layouts, with nested tables and forms, may not work&lt;/li&gt; &#xA; &lt;li&gt;Forms may not be rendered well&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note: Passing the &lt;code&gt;--use_llm&lt;/code&gt; and &lt;code&gt;--force_ocr&lt;/code&gt; flags will mostly solve these issues.&lt;/p&gt;</summary>
  </entry>
</feed>