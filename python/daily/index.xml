<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-06T01:37:20Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>altryne/chatGPT-telegram-bot</title>
    <updated>2022-12-06T01:37:20Z</updated>
    <id>tag:github.com,2022-12-06:/altryne/chatGPT-telegram-bot</id>
    <link href="https://github.com/altryne/chatGPT-telegram-bot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This is a very early attempt at having chatGPT work within a telegram bot&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGPT Telegram Bot - @altryne&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/altryne/status/1598822052760195072&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/463317/205404516-56ea908e-dd31-4c53-acb7-15f9f6ed379f.gif&#34; alt=&#34;CleanShot 2022-12-02 at 16 08 27&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is a Telegram bot that lets you chat with the &lt;a href=&#34;https://github.com/openai/gpt-3&#34;&gt;chatGPT&lt;/a&gt; language model using your local browser. The bot uses Playwright to run chatGPT in Chromium, and can parse code and text, as well as send messages. It also includes a &lt;code&gt;/draw&lt;/code&gt; command that allows you to generate pictures using stable diffusion. More features are coming soon.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Chat with chatGPT from your Telegram on the go&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;code&gt;/draw&lt;/code&gt; pictures using stable diffusion (version 0.0.2)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;code&gt;/browse&lt;/code&gt; give chatGPT access to Google (version 0.0.3)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to Install&lt;/h2&gt; &#xA;&lt;h3&gt;Step 1: Install Python and Miniconda&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Go to the &lt;a href=&#34;https://docs.conda.io/en/latest/miniconda.html&#34;&gt;Miniconda download page&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Click on the appropriate installer for your operating system.&lt;/li&gt; &#xA; &lt;li&gt;Follow the prompts to complete the installation.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Step 2: Create a conda environment&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open a terminal or command prompt.&lt;/li&gt; &#xA; &lt;li&gt;Navigate to the directory where you want to create the environment.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;conda env create -f environment.yml&lt;/code&gt; to create the environment.&lt;/li&gt; &#xA; &lt;li&gt;Activate the newly created environment &lt;code&gt;conda activate chat&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Step 3: Install Playwright&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open a terminal or command prompt.&lt;/li&gt; &#xA; &lt;li&gt;Navigate to the directory where you installed Miniconda.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;playwright install&lt;/code&gt; to download the necessary Chromium software.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;playwright install-deps&lt;/code&gt; to download the necessary dependencies&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Step 4: Set up your Telegram bot&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Set up your Telegram bot token and user ID in the &lt;code&gt;.env&lt;/code&gt; file. See &lt;a href=&#34;https://core.telegram.org/bots/tutorial#obtain-your-bot-token&#34;&gt;these instructions&lt;/a&gt; for more information on how to do this.&lt;/li&gt; &#xA; &lt;li&gt;Edit the &lt;code&gt;.env.example&lt;/code&gt; file, rename it to &lt;code&gt;.env&lt;/code&gt;, and place your values in the appropriate fields.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Step 5: Set up your API keys&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Copy the &lt;code&gt;.env.example&lt;/code&gt; file and rename the copy to &lt;code&gt;.env&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;To use the &lt;code&gt;/draw&lt;/code&gt; command, you will need to obtain an API key for stable diffusion. To do this, go to &lt;a href=&#34;https://beta.dreamstudio.ai/membership?tab=home&#34;&gt;Dream Studio Beta&lt;/a&gt; and sign up for a free membership.&lt;/li&gt; &#xA; &lt;li&gt;SERP_API_KEY is optional. If you want to use the &lt;code&gt;/browse&lt;/code&gt; command, you will need to obtain an API key for SERP. To do this, go to &lt;a href=&#34;https://serpapi.com/&#34;&gt;SERP API&lt;/a&gt; and sign up for a free account.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Step 5: Run the server&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open a terminal or command prompt.&lt;/li&gt; &#xA; &lt;li&gt;Navigate to the directory where you installed the ChatGPT Telegram bot.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;python server.py&lt;/code&gt; to start the server.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Step 6: Chat with your bot in Telegram&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open the Telegram app on your device.&lt;/li&gt; &#xA; &lt;li&gt;Find your bot in the list of contacts (you should have already created it with @botfather).&lt;/li&gt; &#xA; &lt;li&gt;Start chatting with your bot.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Creator &lt;a href=&#34;https://twitter.com/altryne/status/1598902799625961472&#34;&gt;@Altryne&lt;/a&gt; on Twitter&lt;/li&gt; &#xA; &lt;li&gt;Based on &lt;a href=&#34;https://github.com/danielgross/whatsapp-gpt&#34;&gt;Daniel Gross&#39;s whatsapp gpt&lt;/a&gt; package.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>acheong08/ChatGPT</title>
    <updated>2022-12-06T01:37:20Z</updated>
    <id>tag:github.com,2022-12-06:/acheong08/ChatGPT</id>
    <link href="https://github.com/acheong08/ChatGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lightweight package for interacting with ChatGPT&#39;s API by OpenAI. Uses reverse engineered official API.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGPT&lt;/h1&gt; &#xA;&lt;p&gt;Reverse Engineered ChatGPT by OpenAI. Extensible for chatbots etc.&lt;/p&gt; &#xA;&lt;h1&gt;Disclaimer&lt;/h1&gt; &#xA;&lt;p&gt;This is not an official OpenAI product. This is a personal project and is not affiliated with OpenAI in any way. Don&#39;t sue me&lt;/p&gt; &#xA;&lt;h3&gt;This is a library and not intended for direct CLI use&lt;/h3&gt; &#xA;&lt;p&gt;The CLI functionality is for demo and testing only.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/rawandahmad698&#34;&gt;@rawandahmad698&lt;/a&gt; has a much better CLI tool at&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/rawandahmad698/PyChatGPT&#34;&gt;PyChatGPT&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Urgent help needed&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Writing tests&lt;/li&gt; &#xA; &lt;li&gt;More verbose error handling&lt;/li&gt; &#xA; &lt;li&gt;Decrecate bs4 in favor of pure requests&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Wiki is now open to all contributors&lt;/h3&gt; &#xA;&lt;h1&gt;Features&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/36258159/205534498-acc59484-c4b4-487d-89a7-d7b884af709b.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;No moderation&lt;/li&gt; &#xA; &lt;li&gt;Programmable&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Setup&lt;/h1&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;pip3 install revChatGPT --upgrade&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Email and password authentication&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;    &#34;email&#34;: &#34;&amp;lt;YOUR_EMAIL&amp;gt;&#34;,&#xA;    &#34;password&#34;: &#34;&amp;lt;YOUR_PASSWORD&amp;gt;&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Save this in &lt;code&gt;config.json&lt;/code&gt; in current working directory&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Legacy authentication or if using Google Auth&lt;/summary&gt; Go to https://chat.openai.com/chat and log in or sign up &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Open console with &lt;code&gt;F12&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Open &lt;code&gt;Application&lt;/code&gt; tab &amp;gt; Cookies &lt;img src=&#34;https://user-images.githubusercontent.com/36258159/205494773-32ef651a-994d-435a-9f76-a26699935dac.png&#34; alt=&#34;image&#34;&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Copy the value for &lt;code&gt;__Secure-next-auth.session-token&lt;/code&gt; and paste it into &lt;code&gt;config.json.example&lt;/code&gt; under &lt;code&gt;session_token&lt;/code&gt;. You do not need to fill out &lt;code&gt;Authorization&lt;/code&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/36258159/205495076-664a8113-eda5-4d1e-84d3-6fad3614cfd8.png&#34; alt=&#34;image&#34;&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Save the modified file to &lt;code&gt;config.json&lt;/code&gt; (In the current working directory)&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA;&lt;/details&gt; &#xA;&lt;h1&gt;Running&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt; $ python3 -m revChatGPT            &#xA;&#xA;    ChatGPT - A command-line interface to OpenAI&#39;s ChatGPT (https://chat.openai.com/chat)&#xA;    Repo: github.com/acheong08/ChatGPT&#xA;    Arguments: Use --stream to enable data streaming. (Doesn&#39;t work on MacOS)&#xA;    &#xA;Type &#39;!help&#39; to show commands&#xA;Press enter twice to submit your question.&#xA;&#xA;You: !help&#xA;&#xA;&#xA;                !help - Show this message&#xA;                !reset - Forget the current conversation&#xA;                !refresh - Refresh the session authentication&#xA;                !exit - Exit the program&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Refresh every so often in case the token expires.&lt;/p&gt; &#xA;&lt;h1&gt;Development:&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;pip3 install revChatGPT --upgrade&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from revChatGPT.revChatGPT import Chatbot&#xA;import json&#xA;&#xA;# Get your config in JSON&#xA;config = {&#xA;    &#34;email&#34;: &#34;&amp;lt;YOUR_EMAIL&amp;gt;&#34;,&#xA;    &#34;password&#34;: &#34;&amp;lt;YOUR_PASSWORD&amp;gt;&#34;&#xA;}&#xA;&#xA;chatbot = Chatbot(config, conversation_id=None)&#xA;chatbot.reset_chat() # Forgets conversation&#xA;chatbot.refresh_session() # Uses the session_token to get a new bearer token&#xA;resp = chatbot.get_chat_response(prompt, output=&#34;text&#34;) # Sends a request to the API and returns the response by OpenAI&#xA;resp[&#39;message&#39;] # The message sent by the response&#xA;resp[&#39;conversation_id&#39;] # The current conversation id&#xA;resp[&#39;parent_id&#39;] # The ID of the response&#xA;&#xA; # This returns a stream of text (live update)&#xA;resp = chatbot.get_chat_response(prompt, output=&#34;stream&#34;) &#xA;for line in resp: # You have to loop through the response stream&#xA;        print(line[&#39;message&#39;]) # Same format as text return type&#xA;        ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This can be imported to projects for bots and much more. You can have multiple independent conversations by keeping track of the conversation_id.&lt;/p&gt; &#xA;&lt;h1&gt;Awesome ChatGPT&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/stars/acheong08/lists/awesome-chatgpt&#34;&gt;My list&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you have a cool project you want added to the list, open an issue.&lt;/p&gt; &#xA;&lt;h1&gt;Star History&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#acheong08/ChatGPT&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=acheong08/ChatGPT&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>openai/baselines</title>
    <updated>2022-12-06T01:37:20Z</updated>
    <id>tag:github.com,2022-12-06:/openai/baselines</id>
    <link href="https://github.com/openai/baselines" rel="alternate"></link>
    <summary type="html">&lt;p&gt;OpenAI Baselines: high-quality implementations of reinforcement learning algorithms&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;strong&gt;Status:&lt;/strong&gt; Maintenance (expect bug fixes and minor updates)&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/openai/baselines/master/data/logo.jpg&#34; width=&#34;25%&#34; align=&#34;right&#34;&gt; &lt;a href=&#34;https://travis-ci.org/openai/baselines&#34;&gt;&lt;img src=&#34;https://travis-ci.org/openai/baselines.svg?branch=master&#34; alt=&#34;Build status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Baselines&lt;/h1&gt; &#xA;&lt;p&gt;OpenAI Baselines is a set of high-quality implementations of reinforcement learning algorithms.&lt;/p&gt; &#xA;&lt;p&gt;These algorithms will make it easier for the research community to replicate, refine, and identify new ideas, and will create good baselines to build research on top of. Our DQN implementation and its variants are roughly on par with the scores in published papers. We expect they will be used as a base around which new ideas can be added, and as a tool for comparing a new approach against existing ones.&lt;/p&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;Baselines requires python3 (&amp;gt;=3.5) with the development headers. You&#39;ll also need system packages CMake, OpenMPI and zlib. Those can be installed as follows&lt;/p&gt; &#xA;&lt;h3&gt;Ubuntu&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install cmake libopenmpi-dev python3-dev zlib1g-dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Mac OS X&lt;/h3&gt; &#xA;&lt;p&gt;Installation of system packages on Mac requires &lt;a href=&#34;https://brew.sh&#34;&gt;Homebrew&lt;/a&gt;. With Homebrew installed, run the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install cmake openmpi&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Virtual environment&lt;/h2&gt; &#xA;&lt;p&gt;From the general python package sanity perspective, it is a good idea to use virtual environments (virtualenvs) to make sure packages from different projects do not interfere with each other. You can install virtualenv (which is itself a pip package) via&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install virtualenv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Virtualenvs are essentially folders that have copies of python executable and all python packages. To create a virtualenv called venv with python3, one runs&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;virtualenv /path/to/venv --python=python3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To activate a virtualenv:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;. /path/to/venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;More thorough tutorial on virtualenvs and options can be found &lt;a href=&#34;https://virtualenv.pypa.io/en/stable/&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Tensorflow versions&lt;/h2&gt; &#xA;&lt;p&gt;The master branch supports Tensorflow from version 1.4 to 1.14. For Tensorflow 2.0 support, please use tf2 branch.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Clone the repo and cd into it:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/openai/baselines.git&#xA;cd baselines&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you don&#39;t have TensorFlow installed already, install your favourite flavor of TensorFlow. In most cases, you may use&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install tensorflow-gpu==1.14 # if you have a CUDA-compatible gpu and proper drivers&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;or&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install tensorflow==1.14&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;to install Tensorflow 1.14, which is the latest version of Tensorflow supported by the master branch. Refer to &lt;a href=&#34;https://www.tensorflow.org/install/&#34;&gt;TensorFlow installation guide&lt;/a&gt; for more details.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install baselines package&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;MuJoCo&lt;/h3&gt; &#xA;&lt;p&gt;Some of the baselines examples use &lt;a href=&#34;http://www.mujoco.org&#34;&gt;MuJoCo&lt;/a&gt; (multi-joint dynamics in contact) physics simulator, which is proprietary and requires binaries and a license (temporary 30-day license can be obtained from &lt;a href=&#34;http://www.mujoco.org&#34;&gt;www.mujoco.org&lt;/a&gt;). Instructions on setting up MuJoCo can be found &lt;a href=&#34;https://github.com/openai/mujoco-py&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Testing the installation&lt;/h2&gt; &#xA;&lt;p&gt;All unit tests in baselines can be run using pytest runner:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install pytest&#xA;pytest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Training models&lt;/h2&gt; &#xA;&lt;p&gt;Most of the algorithms in baselines repo are used as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m baselines.run --alg=&amp;lt;name of the algorithm&amp;gt; --env=&amp;lt;environment_id&amp;gt; [additional arguments]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Example 1. PPO with MuJoCo Humanoid&lt;/h3&gt; &#xA;&lt;p&gt;For instance, to train a fully-connected network controlling MuJoCo humanoid using PPO2 for 20M timesteps&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m baselines.run --alg=ppo2 --env=Humanoid-v2 --network=mlp --num_timesteps=2e7&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that for mujoco environments fully-connected network is default, so we can omit &lt;code&gt;--network=mlp&lt;/code&gt; The hyperparameters for both network and the learning algorithm can be controlled via the command line, for instance:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m baselines.run --alg=ppo2 --env=Humanoid-v2 --network=mlp --num_timesteps=2e7 --ent_coef=0.1 --num_hidden=32 --num_layers=3 --value_network=copy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;will set entropy coefficient to 0.1, and construct fully connected network with 3 layers with 32 hidden units in each, and create a separate network for value function estimation (so that its parameters are not shared with the policy network, but the structure is the same)&lt;/p&gt; &#xA;&lt;p&gt;See docstrings in &lt;a href=&#34;https://raw.githubusercontent.com/openai/baselines/master/baselines/common/models.py&#34;&gt;common/models.py&lt;/a&gt; for description of network parameters for each type of model, and docstring for &lt;a href=&#34;https://raw.githubusercontent.com/openai/baselines/master/baselines/ppo2/ppo2.py#L152&#34;&gt;baselines/ppo2/ppo2.py/learn()&lt;/a&gt; for the description of the ppo2 hyperparameters.&lt;/p&gt; &#xA;&lt;h3&gt;Example 2. DQN on Atari&lt;/h3&gt; &#xA;&lt;p&gt;DQN with Atari is at this point a classics of benchmarks. To run the baselines implementation of DQN on Atari Pong:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m baselines.run --alg=deepq --env=PongNoFrameskip-v4 --num_timesteps=1e6&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Saving, loading and visualizing models&lt;/h2&gt; &#xA;&lt;h3&gt;Saving and loading the model&lt;/h3&gt; &#xA;&lt;p&gt;The algorithms serialization API is not properly unified yet; however, there is a simple method to save / restore trained models. &lt;code&gt;--save_path&lt;/code&gt; and &lt;code&gt;--load_path&lt;/code&gt; command-line option loads the tensorflow state from a given path before training, and saves it after the training, respectively. Let&#39;s imagine you&#39;d like to train ppo2 on Atari Pong, save the model and then later visualize what has it learnt.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v4 --num_timesteps=2e7 --save_path=~/models/pong_20M_ppo2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This should get to the mean reward per episode about 20. To load and visualize the model, we&#39;ll do the following - load the model, train it for 0 steps, and then visualize:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v4 --num_timesteps=0 --load_path=~/models/pong_20M_ppo2 --play&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;NOTE:&lt;/em&gt; Mujoco environments require normalization to work properly, so we wrap them with VecNormalize wrapper. Currently, to ensure the models are saved with normalization (so that trained models can be restored and run without further training) the normalization coefficients are saved as tensorflow variables. This can decrease the performance somewhat, so if you require high-throughput steps with Mujoco and do not need saving/restoring the models, it may make sense to use numpy normalization instead. To do that, set &#39;use_tf=False` in &lt;a href=&#34;https://raw.githubusercontent.com/openai/baselines/master/baselines/run.py#L116&#34;&gt;baselines/run.py&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Logging and vizualizing learning curves and other training metrics&lt;/h3&gt; &#xA;&lt;p&gt;By default, all summary data, including progress, standard output, is saved to a unique directory in a temp folder, specified by a call to Python&#39;s &lt;a href=&#34;https://docs.python.org/3/library/tempfile.html#tempfile.gettempdir&#34;&gt;tempfile.gettempdir()&lt;/a&gt;. The directory can be changed with the &lt;code&gt;--log_path&lt;/code&gt; command-line option.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v4 --num_timesteps=2e7 --save_path=~/models/pong_20M_ppo2 --log_path=~/logs/Pong/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;NOTE:&lt;/em&gt; Please be aware that the logger will overwrite files of the same name in an existing directory, thus it&#39;s recommended that folder names be given a unique timestamp to prevent overwritten logs.&lt;/p&gt; &#xA;&lt;p&gt;Another way the temp directory can be changed is through the use of the &lt;code&gt;$OPENAI_LOGDIR&lt;/code&gt; environment variable.&lt;/p&gt; &#xA;&lt;p&gt;For examples on how to load and display the training data, see &lt;a href=&#34;https://raw.githubusercontent.com/openai/baselines/master/docs/viz/viz.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Subpackages&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/baselines/master/baselines/a2c&#34;&gt;A2C&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/baselines/master/baselines/acer&#34;&gt;ACER&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/baselines/master/baselines/acktr&#34;&gt;ACKTR&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/baselines/master/baselines/ddpg&#34;&gt;DDPG&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/baselines/master/baselines/deepq&#34;&gt;DQN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/baselines/master/baselines/gail&#34;&gt;GAIL&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/baselines/master/baselines/her&#34;&gt;HER&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/baselines/master/baselines/ppo1&#34;&gt;PPO1&lt;/a&gt; (obsolete version, left here temporarily)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/baselines/master/baselines/ppo2&#34;&gt;PPO2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/baselines/master/baselines/trpo_mpi&#34;&gt;TRPO&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Benchmarks&lt;/h2&gt; &#xA;&lt;p&gt;Results of benchmarks on Mujoco (1M timesteps) and Atari (10M timesteps) are available &lt;a href=&#34;https://htmlpreview.github.com/?https://github.com/openai/baselines/raw/master/benchmarks_mujoco1M.htm&#34;&gt;here for Mujoco&lt;/a&gt; and &lt;a href=&#34;https://htmlpreview.github.com/?https://github.com/openai/baselines/raw/master/benchmarks_atari10M.htm&#34;&gt;here for Atari&lt;/a&gt; respectively. Note that these results may be not on the latest version of the code, particular commit hash with which results were obtained is specified on the benchmarks page.&lt;/p&gt; &#xA;&lt;p&gt;To cite this repository in publications:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{baselines,&#xA;  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},&#xA;  title = {OpenAI Baselines},&#xA;  year = {2017},&#xA;  publisher = {GitHub},&#xA;  journal = {GitHub repository},&#xA;  howpublished = {\url{https://github.com/openai/baselines}},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>