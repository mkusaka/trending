<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-28T01:32:07Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>shamhi/HamsterKombatBot</title>
    <updated>2024-05-28T01:32:07Z</updated>
    <id>tag:github.com,2024-05-28:/shamhi/HamsterKombatBot</id>
    <link href="https://github.com/shamhi/HamsterKombatBot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Bot that mines coins in HamsterKombat&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://t.me/sho6ot&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Telegram-%40Me-orange&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/shamhi/HamsterKombatBot/main/.github/images/demo.png&#34; alt=&#34;img1&#34;&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;üá™üá≥ README in english available &lt;a href=&#34;https://raw.githubusercontent.com/shamhi/HamsterKombatBot/main/README-EN.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;–ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;–ü—Ä–∏–≤—è–∑–∫–∞ –ø—Ä–æ–∫—Å–∏ –∫ —Å–µ—Å—Å–∏–∏&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;–ê–≤—Ç–æ-–ø–æ–∫—É–ø–∫–∞ –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –º–æ–Ω–µ—Ç (tap, energy, charge)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;–†–∞–Ω–¥–æ–º–Ω–æ–µ –≤—Ä–µ–º—è —Å–Ω–∞ –º–µ–∂–¥—É –∫–ª–∏–∫–∞–º–∏&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;–†–∞–Ω–¥–æ–º–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–∫–æ–≤ –∑–∞ –∑–∞–ø—Ä–æ—Å&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;–ü–æ–¥–¥–µ—Ä–∂–∫–∞ tdata / pyrogram .session / telethon .session&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/shamhi/HamsterKombatBot/raw/main/.env-example&#34;&gt;–ù–∞—Å—Ç—Ä–æ–π–∫–∏&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;–ù–∞—Å—Ç—Ä–æ–π–∫–∞&lt;/th&gt; &#xA;   &lt;th&gt;–û–ø–∏—Å–∞–Ω–∏–µ&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;API_ID / API_HASH&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–î–∞–Ω–Ω—ã–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã, —Å –∫–æ—Ç–æ—Ä–æ–π –∑–∞–ø—É—Å–∫–∞—Ç—å —Å–µ—Å—Å–∏—é Telegram &lt;em&gt;(—Å—Ç–æ–∫ - Android)&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;MIN_AVAILABLE_ENERGY&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ—Å—Ç—É–ø–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–∏, –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –∫–æ—Ç–æ—Ä–æ–π –±—É–¥–µ—Ç –∑–∞–¥–µ—Ä–∂–∫–∞ &lt;em&gt;(–Ω–∞–ø—Ä. 100)&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;SLEEP_BY_MIN_ENERGY&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–ó–∞–¥–µ—Ä–∂–∫–∞ –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö &lt;em&gt;(–Ω–∞–ø—Ä. 200)&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;ADD_TAPS_ON_TURBO&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–°–∫–æ–ª—å–∫–æ —Ç–∞–ø–æ–≤ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–æ –ø—Ä–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ç—É—Ä–±–æ &lt;em&gt;(–Ω–∞–ø—Ä. 2500)&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;AUTO_UPGRADE&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–£–ª—É—á—à–∞—Ç—å –ª–∏ –ø–∞—Å—Å–∏–≤–Ω—ã–π –∑–∞—Ä–∞–±–æ—Ç–æ–∫ &lt;em&gt;(True / False)&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;MAX_LEVEL&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –ø—Ä–æ–∫–∞—á–∫–∏ –∞–ø–≥—Ä–µ–π–¥–∞ &lt;em&gt;(–Ω–∞–ø—Ä. 20)&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;APPLY_DAILY_ENERGY&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π –±—É—Å—Ç —ç–Ω–µ—Ä–≥–∏–∏ &lt;em&gt;(True / False)&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;APPLY_DAILY_TURBO&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π –±—É—Å—Ç —Ç—É—Ä–±–æ &lt;em&gt;(True / False)&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;RANDOM_CLICKS_COUNT&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–†–∞–Ω–¥–æ–º–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–∞–ø–æ–≤ &lt;em&gt;(–Ω–∞–ø—Ä. [50,200])&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;SLEEP_BETWEEN_TAP&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–†–∞–Ω–¥–æ–º–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Ç–∞–ø–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö &lt;em&gt;(–Ω–∞–ø—Ä. [10,25])&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;USE_PROXY_FROM_FILE&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å-–ª–∏ –ø—Ä–æ–∫—Å–∏ –∏–∑ —Ñ–∞–π–ª–∞ &lt;code&gt;bot/config/proxies.txt&lt;/code&gt; &lt;em&gt;(True / False)&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç üìö&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;–ß—Ç–æ–±—ã —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –≤ Windows, –∑–∞–ø—É—Å—Ç–∏—Ç–µ INSTALL.bat.&lt;/li&gt; &#xA; &lt;li&gt;–î–ª—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ &lt;code&gt;START.bat&lt;/code&gt; (–∏–ª–∏ –≤ –∫–æ–Ω—Å–æ–ª–∏: &lt;code&gt;python main.py&lt;/code&gt;).&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è&lt;/h2&gt; &#xA;&lt;p&gt;–ü—Ä–µ–∂–¥–µ —á–µ–º –Ω–∞—á–∞—Ç—å, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ —Å–ª–µ–¥—É—é—â–µ–µ:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;Python&lt;/a&gt; –≤–µ—Ä—Å–∏–∏ 3.10 –∏–ª–∏ 3.11.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;–ü–æ–ª—É—á–µ–Ω–∏–µ API –∫–ª—é—á–µ–π&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;–ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ —Å–∞–π—Ç &lt;a href=&#34;https://my.telegram.org&#34;&gt;my.telegram.org&lt;/a&gt; –∏ –≤–æ–π–¥–∏—Ç–µ –≤ —Å–∏—Å—Ç–µ–º—É, –∏—Å–ø–æ–ª—å–∑—É—è —Å–≤–æ–π –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞.&lt;/li&gt; &#xA; &lt;li&gt;–í—ã–±–µ—Ä–∏—Ç–µ &lt;strong&gt;&#34;API development tools&#34;&lt;/strong&gt; –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ —Ñ–æ—Ä–º—É –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –Ω–æ–≤–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.&lt;/li&gt; &#xA; &lt;li&gt;–ó–∞–ø–∏—à–∏—Ç–µ &lt;code&gt;API_ID&lt;/code&gt; –∏ &lt;code&gt;API_HASH&lt;/code&gt; –≤ —Ñ–∞–π–ª–µ &lt;code&gt;.env&lt;/code&gt;, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –ø–æ—Å–ª–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –≤–∞—à–µ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;–£—Å—Ç–∞–Ω–æ–≤–∫–∞&lt;/h2&gt; &#xA;&lt;p&gt;–í—ã –º–æ–∂–µ—Ç–µ —Å–∫–∞—á–∞—Ç—å &lt;a href=&#34;https://github.com/shamhi/HamsterKombatBot&#34;&gt;&lt;strong&gt;–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π&lt;/strong&gt;&lt;/a&gt; –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –Ω–∞ –≤–∞—à—É —Å–∏—Å—Ç–µ–º—É –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–æ–π –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;~ &amp;gt;&amp;gt;&amp;gt; git clone https://github.com/shamhi/HamsterKombatBot.git &#xA;~ &amp;gt;&amp;gt;&amp;gt; cd HamsterKombatBot&#xA;&#xA;# Linux&#xA;~/HamsterKombatBot &amp;gt;&amp;gt;&amp;gt; python3 -m venv venv&#xA;~/HamsterKombatBot &amp;gt;&amp;gt;&amp;gt; source venv/bin/activate&#xA;~/HamsterKombatBot &amp;gt;&amp;gt;&amp;gt; pip3 install -r requirements.txt&#xA;~/HamsterKombatBot &amp;gt;&amp;gt;&amp;gt; cp .env-example .env&#xA;~/HamsterKombatBot &amp;gt;&amp;gt;&amp;gt; nano .env  # –ó–¥–µ—Å—å –≤—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–Ω—ã —É–∫–∞–∑–∞—Ç—å –≤–∞—à–∏ API_ID –∏ API_HASH , –æ—Å—Ç–∞–ª—å–Ω–æ–µ –±–µ—Ä–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é&#xA;~/HamsterKombatBot &amp;gt;&amp;gt;&amp;gt; python3 main.py&#xA;&#xA;# Windows&#xA;~/HamsterKombatBot &amp;gt;&amp;gt;&amp;gt; python -m venv venv&#xA;~/HamsterKombatBot &amp;gt;&amp;gt;&amp;gt; venv\Scripts\activate&#xA;~/HamsterKombatBot &amp;gt;&amp;gt;&amp;gt; pip install -r requirements.txt&#xA;~/HamsterKombatBot &amp;gt;&amp;gt;&amp;gt; copy .env-example .env&#xA;~/HamsterKombatBot &amp;gt;&amp;gt;&amp;gt; # –£–∫–∞–∑—ã–≤–∞–µ—Ç–µ –≤–∞—à–∏ API_ID –∏ API_HASH, –æ—Å—Ç–∞–ª—å–Ω–æ–µ –±–µ—Ä–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é&#xA;~/HamsterKombatBot &amp;gt;&amp;gt;&amp;gt; python main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;–¢–∞–∫–∂–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;~/HamsterKombatBot &amp;gt;&amp;gt;&amp;gt; python3 main.py --action (1/2)&#xA;# –ò–ª–∏&#xA;~/HamsterKombatBot &amp;gt;&amp;gt;&amp;gt; python3 main.py -a (1/2)&#xA;&#xA;# 1 - –°–æ–∑–¥–∞–µ—Ç —Å–µ—Å—Å–∏—é&#xA;# 2 - –ó–∞–ø—É—Å–∫–∞–µ—Ç –∫–ª–∏–∫–µ—Ä&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>lavague-ai/LaVague</title>
    <updated>2024-05-28T01:32:07Z</updated>
    <id>tag:github.com,2024-05-28:/lavague-ai/LaVague</id>
    <link href="https://github.com/lavague-ai/LaVague" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Large Action Model framework to develop AI Web Agents&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/lavague-ai/LaVague/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/lavague-ai/LaVague.svg?style=for-the-badge&#34; alt=&#34;Stargazers&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lavague-ai/LaVague/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/lavague-ai/LaVague.svg?style=for-the-badge&#34; alt=&#34;Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lavague-ai/LaVague/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/lavague-ai/LaVague.svg?style=for-the-badge&#34; alt=&#34;Forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lavague-ai/LaVague/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/lavague-ai/LaVague.svg?style=for-the-badge&#34; alt=&#34;Contributors&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/lavague-ai/LaVague/main/docs/assets/logo.png&#34; width=&#34;140px:&#34; alt=&#34;LaVague Logo&#34;&gt; &#xA; &lt;h1&gt;Welcome to LaVague&lt;/h1&gt; &#xA; &lt;h4 align=&#34;center&#34;&gt; &lt;a href=&#34;https://discord.gg/SDxn9KpqX9&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&#34; height=&#34;35px&#34; alt=&#34;Join our Discord server!&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://docs.lavague.ai/en/latest/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/üìÑ-docs-000000?style=for-the-badge&amp;amp;colorA=09c&amp;amp;colorB=555&#34; height=&#34;35px&#34; alt=&#34;Docs&#34;&gt;&lt;/a&gt; &lt;/h4&gt; &#xA; &lt;p&gt;A Large Action Model framework for developing AI Web Agents &lt;/p&gt; &#xA; &lt;h1&gt;&lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;üèÑ‚Äç‚ôÄÔ∏è What is LaVague?&lt;/h2&gt; &#xA;&lt;p&gt;LaVague is an &lt;strong&gt;open-source Large Action Model framework&lt;/strong&gt; to develop AI Web Agents.&lt;/p&gt; &#xA;&lt;p&gt;Our web agents take an objective, such as &#34;Print installation steps for Hugging Face&#39;s Diffusers library&#34; and performs the required actions to achieve this goal by leveraging our two core components:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;strong&gt;World Model&lt;/strong&gt; that takes an objective and the current state (aka the current web page) and turns that into instructions&lt;/li&gt; &#xA; &lt;li&gt;An &lt;strong&gt;Action Engine&lt;/strong&gt; which ‚Äúcompiles‚Äù these instructions into action code, e.g. &lt;strong&gt;Selenium&lt;/strong&gt; or &lt;strong&gt;Playwright&lt;/strong&gt; &amp;amp; execute them&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Demo&lt;/h3&gt; &#xA;&lt;p&gt;Here is an example of how LaVague can take multiple steps to achieve the objective of &#34;Go on the quicktour of PEFT&#34;:&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/lavague-ai/LaVague/main/docs/assets/demo_agent_hf.gif&#34; alt=&#34;Demo for agent&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;Hands-on&lt;/h3&gt; &#xA;&lt;p&gt;You can do this with the following steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download LaVague with:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install lavague&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Use our framework to build a Web Agent and implement the objective:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from lavague.core import  WorldModel, ActionEngine, PythonEngine&#xA;from lavague.core.agents import WebAgent&#xA;from lavague.drivers.selenium import SeleniumDriver&#xA;&#xA;selenium_driver = SeleniumDriver(headless=False)&#xA;world_model = WorldModel()&#xA;action_engine = ActionEngine(selenium_driver)&#xA;python_engine = PythonEngine()&#xA;agent = WebAgent(world_model, action_engine, python_engine)&#xA;agent.get(&#34;https://huggingface.co/docs&#34;)&#xA;agent.run(&#34;Go on the quicktour of PEFT&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information on this example and how to use LaVague, see our &lt;a href=&#34;https://docs.lavague.ai/en/latest/docs/get-started/quick-tour/&#34;&gt;quick-tour&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note, these examples use our default OpenAI API configuration and you will need to set the OPENAI_API_KEY variable in your local environment with a valid API key for these to work.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;For an end-to-end example of LaVague in a Google Colab, see our &lt;a href=&#34;https://colab.research.google.com/github/lavague-ai/lavague/blob/main/docs/docs/get-started/quick-tour-notebook/quick-tour.ipynb&#34;&gt;quick-tour notebook&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üôã Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We would love your help and support on our quest to build a robust and reliable Large Action Model for web automation.&lt;/p&gt; &#xA;&lt;p&gt;To avoid having multiple people working on the same things &amp;amp; being unable to merge your work, we have outlined the following contribution process:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;üì¢ We outline tasks on our &lt;a href=&#34;https://github.com/orgs/lavague-ai/projects/1/views/3&#34;&gt;&lt;code&gt;backlog&lt;/code&gt;&lt;/a&gt;: we recommend you check out issues with the &lt;a href=&#34;https://github.com/lavague-ai/LaVague/labels/help%20wanted&#34;&gt;&lt;code&gt;help-wanted&lt;/code&gt;&lt;/a&gt; labels &amp;amp; &lt;a href=&#34;https://github.com/lavague-ai/LaVague/labels/good%20first%20issue&#34;&gt;&lt;code&gt;good first issue&lt;/code&gt;&lt;/a&gt; labels&lt;/li&gt; &#xA; &lt;li&gt;üôã‚Äç‚ôÄÔ∏è If you are interested in working on one of these tasks, comment on the issue!&lt;/li&gt; &#xA; &lt;li&gt;ü§ù We will discuss with you and assign you the task with a &lt;a href=&#34;https://github.com/lavague-ai/LaVague/labels/community-assigned&#34;&gt;&lt;code&gt;community assigned&lt;/code&gt;&lt;/a&gt; label&lt;/li&gt; &#xA; &lt;li&gt;üí¨ We will then be available to discuss this task with you&lt;/li&gt; &#xA; &lt;li&gt;‚¨ÜÔ∏è You should submit your work as a PR&lt;/li&gt; &#xA; &lt;li&gt;‚úÖ We will review &amp;amp; merge your code or request changes/give feedback&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Please check out our &lt;a href=&#34;https://raw.githubusercontent.com/lavague-ai/LaVague/main/docs/docs/contributing/contributing.md&#34;&gt;&lt;code&gt;contributing guide&lt;/code&gt;&lt;/a&gt; for a more detailed guide.&lt;/p&gt; &#xA;&lt;p&gt;If you want to ask questions, contribute, or have proposals, please come on our &lt;a href=&#34;https://discord.gg/SDxn9KpqX9&#34;&gt;&lt;code&gt;Discord&lt;/code&gt;&lt;/a&gt; to chat!&lt;/p&gt; &#xA;&lt;h2&gt;üó∫Ô∏è Roadmap&lt;/h2&gt; &#xA;&lt;p&gt;TO keep up to date with our project backlog &lt;a href=&#34;https://github.com/orgs/lavague-ai/projects/1/views/2&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üö® Security warning&lt;/h2&gt; &#xA;&lt;p&gt;Note, this project executes LLM-generated code using &lt;code&gt;exec&lt;/code&gt;. This is not considered a safe practice. We therefore recommend taking extra care when using LaVague and running LaVague in a sandboxed environment!&lt;/p&gt; &#xA;&lt;h2&gt;üìà Data collection&lt;/h2&gt; &#xA;&lt;p&gt;We want to build a dataset that can be used by the AI community to build better Large Action Models for better Web Agents. You can see our work so far on building community datasets on our &lt;a href=&#34;https://huggingface.co/BigAction&#34;&gt;BigAction HuggingFace page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;This is why LaVague collects the following user data telemetry by default:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Version of LaVague installed&lt;/li&gt; &#xA; &lt;li&gt;Code generated for each web action step&lt;/li&gt; &#xA; &lt;li&gt;LLM used (i.e GPT4)&lt;/li&gt; &#xA; &lt;li&gt;Multi modal LLM used (i.e GPT4)&lt;/li&gt; &#xA; &lt;li&gt;Randomly generated anonymous user ID&lt;/li&gt; &#xA; &lt;li&gt;Whether you are using a CLI command or our library directly&lt;/li&gt; &#xA; &lt;li&gt;The instruction used/generated&lt;/li&gt; &#xA; &lt;li&gt;The objective used (if you are using the agent)&lt;/li&gt; &#xA; &lt;li&gt;The chain of thoughts (if you are using the agent)&lt;/li&gt; &#xA; &lt;li&gt;The interaction zone on the page (bounding box)&lt;/li&gt; &#xA; &lt;li&gt;The viewport size of your browser&lt;/li&gt; &#xA; &lt;li&gt;The URL you performed an action on&lt;/li&gt; &#xA; &lt;li&gt;Whether the action failed or succeeded&lt;/li&gt; &#xA; &lt;li&gt;Error message, where relevant&lt;/li&gt; &#xA; &lt;li&gt;The source nodes (chunks of HTML code retrieved from the web page to perform this action)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;üö´ Turn off all telemetry&lt;/h3&gt; &#xA;&lt;p&gt;If you want to turn off all telemetry, you can set the TELEMETRY_VAR environment variable to &#34;NONE&#34;.&lt;/p&gt; &#xA;&lt;p&gt;If you are running LaVague locally in a Linux environment, you can persistently set this variable for your environment with the following steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Add TELEMETRY_VAR=&#34;NONE&#34; to your ~/.bashrc, ~/.bash_profile, or ~/.profile file (which file you have depends on your shell and its configuration)&lt;/li&gt; &#xA; &lt;li&gt;Use `source ~/.bashrc (or .bash_profile or .profile) to apply your modifications without having to log out and back in&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;In a notebook cell, you can use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;import os&#xA;os.environ[&#39;TELEMETRY_VAR&#39;] = &#34;NONE&#34;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>darrenburns/elia</title>
    <updated>2024-05-28T01:32:07Z</updated>
    <id>tag:github.com,2024-05-28:/darrenburns/elia</id>
    <link href="https://github.com/darrenburns/elia" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A snappy, keyboard-centric terminal user interface for interacting with large language models. Chat with ChatGPT, Claude, Llama 3, Phi 3, Mistral, Gemma and more.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/darrenburns/elia/assets/5740731/4037b91a-1ad8-4d5b-884d-b3f1b495acf4&#34; width=&#34;126px&#34;&gt; &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;i align=&#34;center&#34;&gt;A snappy, keyboard-centric terminal user interface for interacting with large language models.&lt;/i&gt;&lt;br&gt; &lt;i align=&#34;center&#34;&gt;Chat with Claude 3, ChatGPT, and local models like Llama 3, Phi 3, Mistral and Gemma.&lt;/i&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/darrenburns/elia/assets/5740731/75f8563f-ce1a-4c9c-98c0-1bd1f7010814&#34; alt=&#34;elia-screenshot-collage&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;elia&lt;/code&gt; is an application for interacting with LLMs which runs entirely in your terminal, and is designed to be keyboard-focused, efficient, and fun to use! It stores your conversations in a local SQLite database, and allows you to interact with a variety of models. Speak with proprietary models such as ChatGPT and Claude, or with local models running through &lt;code&gt;ollama&lt;/code&gt; or LocalAI.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Install Elia with &lt;a href=&#34;https://github.com/pypa/pipx&#34;&gt;pipx&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pipx install elia-chat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Depending on the model you wish to use, you may need to set one or more environment variables (e.g. &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;, &lt;code&gt;GEMINI_API_KEY&lt;/code&gt; etc).&lt;/p&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;Launch Elia from the command line:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;elia&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Launch a new chat inline (under your prompt) with &lt;code&gt;-i&lt;/code&gt;/&lt;code&gt;--inline&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;elia -i &#34;What is the Zen of Python?&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Launch a new chat in full-screen mode:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;elia &#34;Tell me a cool fact about lizards!&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Specify a model via the command line using &lt;code&gt;-m&lt;/code&gt;/&lt;code&gt;--model&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;elia -m gpt-4o&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Options can be combined - here&#39;s how you launch a chat with Gemini 1.5 Flash in inline mode (requires &lt;code&gt;GEMINI_API_KEY&lt;/code&gt; environment variable).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;elia -i -m gemini/gemini-1.5-flash-latest &#34;How do I call Rust code from Python?&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running local models&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://github.com/ollama/ollama&#34;&gt;&lt;code&gt;ollama&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Pull the model you require, e.g. &lt;code&gt;ollama pull llama3&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Run the local ollama server: &lt;code&gt;ollama serve&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Add the model to the config file (see below).&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;The location of the configuration file is noted at the bottom of the options window (&lt;code&gt;ctrl+o&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;The example file below shows the available options, as well as examples of how to add new models.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;# the ID or name of the model that is selected by default on launch&#xA;default_model = &#34;gpt-4o&#34;&#xA;# the system prompt on launch&#xA;system_prompt = &#34;You are a helpful assistant who talks like a pirate.&#34;&#xA;# change the syntax highlighting theme of code in messages&#xA;# choose from https://pygments.org/styles/&#xA;# defaults to &#34;monokai&#34;&#xA;message_code_theme = &#34;dracula&#34;&#xA;&#xA;# example of adding local llama3 support&#xA;# only the `name` field is required here.&#xA;[[models]]&#xA;name = &#34;ollama/llama3&#34;&#xA;&#xA;# example of a model running on a local server, e.g. LocalAI&#xA;[[models]]&#xA;name = &#34;openai/some-model&#34;&#xA;api_base = &#34;http://localhost:8080/v1&#34;&#xA;api_key = &#34;api-key-if-required&#34;&#xA;&#xA;# example of add a groq model, showing some other fields&#xA;[[models]]&#xA;name = &#34;groq/llama2-70b-4096&#34;&#xA;display_name = &#34;Llama 2 70B&#34;  # appears in UI&#xA;provider = &#34;Groq&#34;  # appears in UI&#xA;temperature = 1.0  # high temp = high variation in output&#xA;max_retries = 0  # number of retries on failed request&#xA;&#xA;# example of multiple instances of one model, e.g. you might&#xA;# have a &#39;work&#39; OpenAI org and a &#39;personal&#39; org.&#xA;[[models]]&#xA;id = &#34;work-gpt-3.5-turbo&#34;&#xA;name = &#34;gpt-3.5-turbo&#34;&#xA;display_name = &#34;GPT 3.5 Turbo (Work)&#34;&#xA;&#xA;[[models]]&#xA;id = &#34;personal-gpt-3.5-turbo&#34;&#xA;name = &#34;gpt-3.5-turbo&#34;&#xA;display_name = &#34;GPT 3.5 Turbo (Personal)&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Changing keybindings&lt;/h2&gt; &#xA;&lt;p&gt;Right now, keybinds cannot be changed. Terminals are also rather limited in what keybinds they support. For example, pressing &lt;kbd&gt;Cmd&lt;/kbd&gt;+&lt;kbd&gt;Enter&lt;/kbd&gt; to send a message is not possible (although we may support a protocol to allow this in some terminals in the future).&lt;/p&gt; &#xA;&lt;p&gt;For now, I recommend you map whatever key combo you want at the terminal emulator level to send &lt;code&gt;\n&lt;/code&gt;. Here&#39;s an example using iTerm:&lt;/p&gt; &#xA;&lt;img width=&#34;848&#34; alt=&#34;image&#34; src=&#34;https://github.com/darrenburns/elia/assets/5740731/94b6e50c-429a-4d17-99c2-affaa828f35b&#34;&gt; &#xA;&lt;p&gt;With this mapping in place, pressing &lt;kbd&gt;Cmd&lt;/kbd&gt;+&lt;kbd&gt;Enter&lt;/kbd&gt; will send a message to the LLM, and pressing &lt;kbd&gt;Enter&lt;/kbd&gt; alone will create a new line.&lt;/p&gt; &#xA;&lt;h2&gt;Import from ChatGPT&lt;/h2&gt; &#xA;&lt;p&gt;Export your conversations to a JSON file using the ChatGPT UI, then import them using the &lt;code&gt;import&lt;/code&gt; command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;elia import &#39;path/to/conversations.json&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Wiping the database&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;elia reset&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Uninstalling&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pipx uninstall elia-chat&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>