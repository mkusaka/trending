<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-04-11T01:35:03Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>blasty/JiaTansSSHAgent</title>
    <updated>2024-04-11T01:35:03Z</updated>
    <id>tag:github.com,2024-04-11:/blasty/JiaTansSSHAgent</id>
    <link href="https://github.com/blasty/JiaTansSSHAgent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Jia Tan&#39;s SSH Agent&lt;/h1&gt; &#xA;&lt;p&gt;Simple SSH Agent that implements some of the XZ sshd backdoor functionality.&lt;/p&gt; &#xA;&lt;p&gt;For those who want to more easily explore the backdoor using a typical SSH client.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/blasty/JiaTansSSHAgent/master/assets/demo.png&#34; alt=&#34;demo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Generate your own ed448 private key &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;openssl genpkey -algorithm ED448 -outform PEM -out privkey.pem&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Patch your liblzma.so with the ed448 pubkey &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;python3 scripts/patch_liblzma.py privkey.pem liblzma.so liblzma_patched.so&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Patch your SSH client to skip verification of the certificate: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Look for this section in openssh&#39;s &lt;code&gt;sshkey.c&lt;/code&gt; and commment it out:&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;if ((ret = sshkey_verify(key-&amp;gt;cert-&amp;gt;signature_key, sig, slen,&#xA;           sshbuf_ptr(key-&amp;gt;cert-&amp;gt;certblob), signed_len, NULL, 0, NULL)) != 0)&#xA;{&#xA;&#x9;goto out;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;python3 -m virtualenv venv &amp;amp;&amp;amp; . venv/bin/activate &amp;amp;&amp;amp; pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;python3 agent.py /tmp/agent ./privkey.pem&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;SSH_AUTH_SOCK=/tmp/agent ./ssh root@localhost&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;log in with any password :)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;-- blasty &lt;code&gt;&amp;lt;peter@haxx.in&amp;gt;&lt;/code&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Filimoa/open-parse</title>
    <updated>2024-04-11T01:35:03Z</updated>
    <id>tag:github.com,2024-04-11:/Filimoa/open-parse</id>
    <link href="https://github.com/Filimoa/open-parse" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Improved file parsing for LLM‚Äôs&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://sergey-filimonov.nyc3.digitaloceanspaces.com/open-parse/open-parse-with-text-tp-logo.webp&#34; width=&#34;350&#34;&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;strong&gt;Easily chunk complex documents the same way a human would.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Chunking documents is a challenging task that underpins any RAG system. High quality results are critical to a sucessful AI application, yet most open-source libraries are limited in their ability to handle complex documents.&lt;/p&gt; &#xA;&lt;p&gt;Open Parse is designed to fill this gap by providing a flexible, easy-to-use library capable of visually discerning document layouts and chunking them effectively.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;How is this different from other layout parsers?&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;h4&gt;‚úÇÔ∏è Text Splitting&lt;/h4&gt; &#xA; &lt;p&gt;Text splitting converts a file to raw text and &lt;a href=&#34;https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/token_text_splitter/&#34;&gt;slices it up&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;You lose the ability to easily overlay the chunk on the original pdf&lt;/li&gt; &#xA;  &lt;li&gt;You ignore the underlying semantic structure of the file - headings, sections, bullets represent valuable information.&lt;/li&gt; &#xA;  &lt;li&gt;No support for tables, images or markdown.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;ü§ñ ML Layout Parsers&lt;/h4&gt; &#xA; &lt;p&gt;There&#39;s some of fantastic libraries like &lt;a href=&#34;https://github.com/Layout-Parser/layout-parser&#34;&gt;layout-parser&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;While they can identify various elements like text blocks, images, and tables, but they are not built to group related content effectively.&lt;/li&gt; &#xA;  &lt;li&gt;They strictly focus on layout parsing - you will need to add another model to extract markdown from the images, parse tables, group nodes, etc.&lt;/li&gt; &#xA;  &lt;li&gt;We&#39;ve found performance to be sub-optimal on many documents while also being computationally heavy.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;üíº Commercial Solutions&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Typically priced at ‚âà $10 / 1k pages. See &lt;a href=&#34;https://cloud.google.com/document-ai&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;https://aws.amazon.com/textract/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://www.reducto.ai/&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt;Requires sharing your data with a vendor&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Highlights&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Visually-Driven:&lt;/strong&gt; Open-Parse visually analyzes documents for superior LLM input, going beyond naive text splitting.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚úçÔ∏è Markdown Support:&lt;/strong&gt; Basic markdown support for parsing headings, bold and italics.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìä High-Precision Table Support:&lt;/strong&gt; Extract tables into clean Markdown formats with accuracy that surpasses traditional tools.&lt;/p&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;&lt;i&gt;Examples&lt;/i&gt;&lt;/summary&gt; The following examples were parsed with unitable. &#xA;   &lt;br&gt; &#xA;   &lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://sergey-filimonov.nyc3.digitaloceanspaces.com/open-parse/unitable-parsing-sample.webp&#34; width=&#34;650&#34;&gt; &lt;/p&gt; &#xA;   &lt;br&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;üõ†Ô∏è Extensible:&lt;/strong&gt; Easily implement your own post-processing steps.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;üí°Intuitive:&lt;/strong&gt; Great editor support. Completion everywhere. Less time debugging.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;üéØ Easy:&lt;/strong&gt; Designed to be easy to use and learn. Less time reading docs.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://sergey-filimonov.nyc3.digitaloceanspaces.com/open-parse/marked-up-doc-2.webp&#34; width=&#34;250&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;h4&gt;Basic Example&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import openparse&#xA;&#xA;basic_doc_path = &#34;./sample-docs/mobile-home-manual.pdf&#34;&#xA;parser = openparse.DocumentParser()&#xA;parsed_basic_doc = parser.parse(basic_doc_path)&#xA;&#xA;for node in parsed_basic_doc.nodes:&#xA;    print(node)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;üìì Try the sample notebook&lt;/strong&gt; &lt;a href=&#34;https://colab.research.google.com/drive/1Z5B5gsnmhFKEFL-5yYIcoox7-jQao8Ep?usp=sharing&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Semantic Processing Example&lt;/h4&gt; &#xA;&lt;p&gt;Chunking documents is fundamentally about grouping similar semantic nodes together. By embedding the text of each node, we can then cluster them together based on their similarity.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from openparse import processing, DocumentParser&#xA;&#xA;semantic_pipeline = processing.SemanticIngestionPipeline(&#xA;    openai_api_key=OPEN_AI_KEY,&#xA;    model=&#34;text-embedding-3-large&#34;,&#xA;    min_tokens=64,&#xA;    max_tokens=1024,&#xA;)&#xA;parser = DocumentParser(&#xA;    processing_pipeline=semantic_pipeline,&#xA;)&#xA;parsed_content = parser.parse(basic_doc_path)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;üìì Sample notebook&lt;/strong&gt; &lt;a href=&#34;https://github.com/Filimoa/open-parse/raw/main/src/cookbooks/semantic_processing.ipynb&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Serializing Results&lt;/h4&gt; &#xA;&lt;p&gt;Uses pydantic under the hood so you can serialize results with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;parsed_content.dict()&#xA;&#xA;# or to convert to a valid json dict&#xA;parsed_content.json()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;Python 3.8+&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dealing with PDF&#39;s:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pdfminer/pdfminer.six&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;pdfminer.six&lt;/a&gt; Fully open source.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Extracting Tables:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pymupdf/PyMuPDF&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;PyMuPDF&lt;/a&gt; has some table detection functionality. Please see their &lt;a href=&#34;https://mupdf.com/licensing/index.html#commercial&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;license&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/microsoft/table-transformer-detection&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;Table Transformer&lt;/a&gt; is a deep learning approach.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/poloclub/unitable&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;unitable&lt;/a&gt; is another transformers based approach with &lt;strong&gt;state-of-the-art&lt;/strong&gt; performance.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h4&gt;1. Core Library&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;pip install openparse&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Enabling OCR Support&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;p&gt;PyMuPDF will already contain all the logic to support OCR functions. But it additionally does need Tesseract‚Äôs language support data, so installation of Tesseract-OCR is still required.&lt;/p&gt; &#xA;&lt;p&gt;The language support folder location must be communicated either via storing it in the environment variable &#34;TESSDATA_PREFIX&#34;, or as a parameter in the applicable functions.&lt;/p&gt; &#xA;&lt;p&gt;So for a working OCR functionality, make sure to complete this checklist:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Install Tesseract.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Locate Tesseract‚Äôs language support folder. Typically you will find it here:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Windows: &lt;code&gt;C:/Program Files/Tesseract-OCR/tessdata&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Unix systems: &lt;code&gt;/usr/share/tesseract-ocr/5/tessdata&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Set the environment variable TESSDATA_PREFIX&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Windows: &lt;code&gt;setx TESSDATA_PREFIX &#34;C:/Program Files/Tesseract-OCR/tessdata&#34;&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Unix systems: &lt;code&gt;declare -x TESSDATA_PREFIX= /usr/share/tesseract-ocr/5/tessdata&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;em&gt;On Windows systems, this must happen outside Python ‚Äì before starting your script. Just manipulating os.environ will not work!&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h4&gt;2. ML Table Detection (Optional)&lt;/h4&gt; &#xA;&lt;p&gt;This repository provides an optional feature to parse content from tables using a variety of deep learning models.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;pip install &#34;openparse[ml]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then download the model weights with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;openparse-download&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can run the parsing with the following.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;parser = openparse.DocumentParser(&#xA;        table_args={&#xA;            &#34;parsing_algorithm&#34;: &#34;unitable&#34;,&#xA;            &#34;min_table_confidence&#34;: 0.8,&#xA;        },&#xA;)&#xA;parsed_nodes = parser.parse(pdf_path)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note we currently use &lt;a href=&#34;https://github.com/microsoft/table-transformer&#34;&gt;table-transformers&lt;/a&gt; for all table detection and we find its performance to be subpar. This negatively affects the downstream results of unitable. If you&#39;re aware of a better model please open an Issue - the unitable team mentioned they might add this soon too.&lt;/p&gt; &#xA;&lt;h2&gt;Cookbooks&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Filimoa/open-parse/tree/main/src/cookbooks&#34;&gt;https://github.com/Filimoa/open-parse/tree/main/src/cookbooks&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://filimoa.github.io/open-parse/&#34;&gt;https://filimoa.github.io/open-parse/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Sponsors&lt;/h2&gt; &#xA;&lt;!-- sponsors --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.data.threesigma.ai/filings-ai&#34; target=&#34;_blank&#34; title=&#34;Three Sigma: AI for insurance filings.&#34;&gt;&lt;img src=&#34;https://sergey-filimonov.nyc3.digitaloceanspaces.com/open-parse/marketing/three-sigma-wide.png&#34; width=&#34;250&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- /sponsors --&gt; &#xA;&lt;p&gt;Does your use case need something special? Reach &lt;a href=&#34;https://www.linkedin.com/in/sergey-osu/&#34;&gt;out&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>LlamaFamily/Llama-Chinese</title>
    <updated>2024-04-11T01:35:03Z</updated>
    <id>tag:github.com,2024-04-11:/LlamaFamily/Llama-Chinese</id>
    <link href="https://github.com/LlamaFamily/Llama-Chinese" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Llama‰∏≠ÊñáÁ§æÂå∫ÔºåÊúÄÂ•ΩÁöÑ‰∏≠ÊñáLlamaÂ§ßÊ®°ÂûãÔºåÂÆåÂÖ®ÂºÄÊ∫êÂèØÂïÜÁî®&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;left&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/README_EN.md&#34;&gt;English&lt;/a&gt; ÔΩú ‰∏≠Êñá &lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt; Llama-Chinese &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/llama.png&#34; alt=&#34;Llama&#34; style=&#34;width: 20%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;font face=&#34;Èªë‰Ωì&#34; color=&#34;orange&#34; size=&#34;6&#34;&gt; ÊúÄÂ•ΩÁöÑ‰∏≠ÊñáLlamaÂ§ßÊ®°Âûã &lt;/font&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://llama.family&#34;&gt;Âú®Á∫ø‰ΩìÈ™åÔºöllama.family&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B-Chat&#34;&gt;Âü∫‰∫éLlama2ÁöÑÂºÄÊ∫ê‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉÂ§ßÊ®°ÂûãAtom-7B&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üóÇÔ∏è ÂÜÖÂÆπÂØºÂºï&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E7%A4%BE%E5%8C%BA%E4%BB%8B%E7%BB%8Dllama%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA&#34;&gt;üî• Á§æÂå∫‰ªãÁªçÔºöLlama‰∏≠ÊñáÁ§æÂå∫&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E7%A4%BE%E5%8C%BA%E5%85%AC%E5%91%8A&#34;&gt;üì¢ Á§æÂå∫ÂÖ¨Âëä&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E5%9B%BD%E5%86%85llama2%E6%9C%80%E6%96%B0%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80&#34;&gt;üêº ÂõΩÂÜÖLlama2ÊúÄÊñ∞‰∏ãËΩΩÂú∞ÂùÄ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-atom%E5%A4%A7%E6%A8%A1%E5%9E%8B&#34;&gt;üîµ AtomÂ§ßÊ®°Âûã&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%A4%A7%E8%A7%84%E6%A8%A1%E7%9A%84%E4%B8%AD%E6%96%87%E6%95%B0%E6%8D%AE%E9%A2%84%E8%AE%AD%E7%BB%83&#34;&gt;Â§ßËßÑÊ®°ÁöÑ‰∏≠ÊñáÊï∞ÊçÆÈ¢ÑËÆ≠ÁªÉ&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E6%9B%B4%E9%AB%98%E6%95%88%E7%9A%84%E4%B8%AD%E6%96%87%E8%AF%8D%E8%A1%A8&#34;&gt;Êõ¥È´òÊïàÁöÑ‰∏≠ÊñáËØçË°®&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E8%87%AA%E9%80%82%E5%BA%94%E4%B8%8A%E4%B8%8B%E6%96%87%E6%89%A9%E5%B1%95&#34;&gt;Ëá™ÈÄÇÂ∫î‰∏ä‰∏ãÊñáÊâ©Â±ï&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E4%B8%AD%E6%96%87%E6%95%B0%E6%8D%AE&#34;&gt;üìù ‰∏≠ÊñáÊï∞ÊçÆ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2&#34;&gt;‚è¨ Ê®°ÂûãÈÉ®ÁΩ≤&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD&#34;&gt;Ê®°Âûã‰∏ãËΩΩ&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#meta%E5%AE%98%E6%96%B9llama2%E6%A8%A1%E5%9E%8B&#34;&gt;MetaÂÆòÊñπLlama2Ê®°Âûã&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%9F%BA%E4%BA%8Ellama2%E7%9A%84%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B&#34;&gt;Âü∫‰∫éLlama2ÁöÑ‰∏≠ÊñáÂæÆË∞ÉÊ®°Âûã&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%9F%BA%E4%BA%8Ellama2%E7%9A%84%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8Batom&#34;&gt;Âü∫‰∫éLlama2ÁöÑ‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãAtom&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%94%A8%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B&#34;&gt;Ê®°ÂûãË∞ÉÁî®‰ª£Á†ÅÁ§∫‰æã&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#fastapi%E6%8E%A5%E5%8F%A3%E6%90%AD%E5%BB%BA&#34;&gt;FastAPIÊé•Âè£Êê≠Âª∫&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#gradio%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E9%97%AE%E7%AD%94%E5%B9%B3%E5%8F%B0&#34;&gt;GradioÂø´ÈÄüÊê≠Âª∫ÈóÆÁ≠îÂπ≥Âè∞&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#docker%E9%83%A8%E7%BD%B2%E9%97%AE%E7%AD%94%E6%8E%A5%E5%8F%A3&#34;&gt;DockerÈÉ®ÁΩ≤ÈóÆÁ≠îÊé•Âè£&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83&#34;&gt;ü§ñ Ê®°ÂûãÈ¢ÑËÆ≠ÁªÉ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83&#34;&gt;üí° Ê®°ÂûãÂæÆË∞É&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#step1-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87&#34;&gt;Step1: ÁéØÂ¢ÉÂáÜÂ§á&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#step2-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87&#34;&gt;Step2: Êï∞ÊçÆÂáÜÂ§á&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#step3-%E5%BE%AE%E8%B0%83%E8%84%9A%E6%9C%AC&#34;&gt;Step3: ÂæÆË∞ÉËÑöÊú¨&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#lora%E5%BE%AE%E8%B0%83&#34;&gt;LoRAÂæÆË∞É&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%85%A8%E9%87%8F%E5%8F%82%E6%95%B0%E5%BE%AE%E8%B0%83&#34;&gt;ÂÖ®ÈáèÂèÇÊï∞ÂæÆË∞É&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#step4-%E5%8A%A0%E8%BD%BD%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B&#34;&gt;Step4: Âä†ËΩΩÂæÆË∞ÉÊ®°Âûã&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#lora%E5%BE%AE%E8%B0%83-1&#34;&gt;LoRAÂæÆË∞É&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%85%A8%E9%87%8F%E5%8F%82%E6%95%B0%E5%BE%AE%E8%B0%83-1&#34;&gt;ÂÖ®ÈáèÂèÇÊï∞ÂæÆË∞É&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96&#34;&gt;üçÑ Ê®°ÂûãÈáèÂåñ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F&#34;&gt;üöÄ Êé®ÁêÜÂä†ÈÄü&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#TensorRT-LLM&#34;&gt;TensorRT-LLM&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#vllm&#34;&gt;vLLM&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#jittorllms&#34;&gt;JittorLLMs&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#lmdeploy&#34;&gt;lmdeploy&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B&#34;&gt;ü•á Ê®°ÂûãËØÑÊµã&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E5%A4%96%E5%BB%B6%E8%83%BD%E5%8A%9B&#34;&gt;üí™ Â§ñÂª∂ËÉΩÂäõ&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#langchain&#34;&gt;LangChain&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E4%BB%A3%E7%A0%81%E6%A8%A1%E5%9E%8B&#34;&gt;üêû ‰ª£Á†ÅÊ®°Âûã&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99&#34;&gt;üìñ Â≠¶‰π†ËµÑÊñô&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#meta%E5%AE%98%E6%96%B9%E5%AF%B9%E4%BA%8Ellama2%E7%9A%84%E4%BB%8B%E7%BB%8D&#34;&gt;MetaÂÆòÊñπÂØπ‰∫éLlama2ÁöÑ‰ªãÁªç&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87&#34;&gt;LlamaÁõ∏ÂÖ≥ËÆ∫Êñá&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#llama2%E7%9A%84%E8%AF%84%E6%B5%8B%E7%BB%93%E6%9E%9C&#34;&gt;Llama2ÁöÑËØÑÊµãÁªìÊûú&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E8%87%B4%E8%B0%A2&#34;&gt;üéâ Ëá¥Ë∞¢&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E9%97%AE%E9%A2%98%E5%8F%8D%E9%A6%88&#34;&gt;ü§î ÈóÆÈ¢òÂèçÈ¶à&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üî• Á§æÂå∫‰ªãÁªçÔºöLlama‰∏≠ÊñáÁ§æÂå∫&lt;/h2&gt; &#xA;&lt;p&gt;Ê¨¢ËøéÊù•Âà∞Llama‰∏≠ÊñáÁ§æÂå∫ÔºÅÊàë‰ª¨ÊòØ‰∏Ä‰∏™‰∏ìÊ≥®‰∫éLlamaÊ®°ÂûãÂú®‰∏≠ÊñáÊñπÈù¢ÁöÑ‰ºòÂåñÂíå‰∏äÂ±ÇÂª∫ËÆæÁöÑÈ´òÁ∫ßÊäÄÊúØÁ§æÂå∫„ÄÇ &lt;strong&gt;*Âü∫‰∫éÂ§ßËßÑÊ®°‰∏≠ÊñáÊï∞ÊçÆÔºå‰ªéÈ¢ÑËÆ≠ÁªÉÂºÄÂßãÂØπLlama2Ê®°ÂûãËøõË°å‰∏≠ÊñáËÉΩÂäõÁöÑÊåÅÁª≠Ëø≠‰ª£ÂçáÁ∫ß*&lt;/strong&gt;„ÄÇ Êàë‰ª¨ÁÉ≠Âø±Ê¨¢ËøéÂØπÂ§ßÊ®°ÂûãLLMÂÖÖÊª°ÁÉ≠ÊÉÖÁöÑÂºÄÂèëËÄÖÂíåÁ†îÁ©∂ËÄÖÂä†ÂÖ•Êàë‰ª¨ÁöÑË°åÂàó„ÄÇ&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;h3&gt;‰∏∫‰ªÄ‰πàÈÄâÊã©Llama2‰∏≠ÊñáÁ§æÂå∫Ôºü&lt;/h3&gt; &#xA; &lt;p&gt;üöÄ &lt;strong&gt;È´òÁ∫ßÂ∑•Á®ãÂ∏àÂõ¢ÈòüÊîØÊåÅ&lt;/strong&gt;ÔºöÁ§æÂå∫Êúâ‰∏ÄÊâπ‰∏ìÊ≥®‰∏∫Â§ßÂÆ∂ÊúçÂä°ÁöÑNLPÈ´òÁ∫ßÂ∑•Á®ãÂ∏àÔºåÊàë‰ª¨ÊúâÁùÄÂº∫Â§ßÁöÑÊäÄÊúØÊîØÊåÅÂíå‰∏∞ÂØåÁöÑÁªèÈ™åÔºå‰∏∫ÊÇ®Êèê‰æõ‰∏ì‰∏öÁöÑÊåáÂØºÂíåÂ∏ÆÂä©„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;üéØ &lt;strong&gt;‰∏≠Êñá‰ºòÂåñ&lt;/strong&gt;ÔºöÊàë‰ª¨Ëá¥Âäõ‰∫éÂú®Llama2Ê®°ÂûãÁöÑ‰∏≠ÊñáÂ§ÑÁêÜÊñπÈù¢ËøõË°å‰ºòÂåñÔºåÊé¢Á¥¢ÈÄÇÁî®‰∫é‰∏≠ÊñáÁöÑÊúÄ‰Ω≥ÂÆûË∑µÔºå‰ª•ÊèêÂçáÂÖ∂ÊÄßËÉΩÂíåÈÄÇÂ∫îÊÄß„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;üí° &lt;strong&gt;ÂàõÊñ∞‰∫§ÊµÅ&lt;/strong&gt;ÔºöÊàë‰ª¨Êã•Êúâ‰∏ÄÊîØÂØåÊúâÂàõÈÄ†ÂäõÂíåÁªèÈ™åÁöÑÁ§æÂå∫ÊàêÂëòÂõ¢ÈòüÔºåÂÆöÊúüÁªÑÁªáÁ∫ø‰∏äÊ¥ªÂä®„ÄÅÊäÄÊúØÁ†îËÆ®ÂíåÁªèÈ™åÂàÜ‰∫´Ôºå‰øÉËøõÊàêÂëòÈó¥ÁöÑÂàõÊñ∞‰∫§ÊµÅ„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;üåê &lt;strong&gt;ÂÖ®ÁêÉËÅîÁªì&lt;/strong&gt;ÔºöÊàë‰ª¨Ê¨¢ËøéÊù•Ëá™‰∏ñÁïåÂêÑÂú∞ÁöÑÂºÄÂèëËÄÖÂä†ÂÖ•Á§æÂå∫ÔºåÊûÑÂª∫‰∏Ä‰∏™ÂºÄÊîæ„ÄÅÂ§öÂÖÉÂåñÁöÑÂ≠¶‰π†Âíå‰∫§ÊµÅÂπ≥Âè∞„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;ü§ù &lt;strong&gt;ÂºÄÊîæÂÖ±‰∫´&lt;/strong&gt;ÔºöÊàë‰ª¨ÈºìÂä±Á§æÂå∫ÊàêÂëòÂºÄÊ∫êÂàÜ‰∫´‰ª£Á†ÅÂíåÊ®°ÂûãÔºåÊé®Âä®Âêà‰ΩúÂÖ±Ëµ¢ÔºåÂÖ±Âêå‰øÉËøõ‰∏≠ÊñáNLPÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ&lt;/p&gt; &#xA; &lt;h3&gt;Á§æÂå∫Ê¥ªÂä®&lt;/h3&gt; &#xA; &lt;p&gt;üóìÔ∏è &lt;strong&gt;Á∫ø‰∏äËÆ≤Â∫ß&lt;/strong&gt;ÔºöÈÇÄËØ∑Ë°å‰∏öÂÜÖ‰∏ìÂÆ∂ËøõË°åÁ∫ø‰∏äËÆ≤Â∫ßÔºåÂàÜ‰∫´Llama2Âú®‰∏≠ÊñáNLPÈ¢ÜÂüüÁöÑÊúÄÊñ∞ÊäÄÊúØÂíåÂ∫îÁî®ÔºåÊé¢ËÆ®ÂâçÊ≤øÁ†îÁ©∂ÊàêÊûú„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;üíª &lt;strong&gt;È°πÁõÆÂ±ïÁ§∫&lt;/strong&gt;ÔºöÊàêÂëòÂèØÂ±ïÁ§∫Ëá™Â∑±Âú®Llama2‰∏≠Êñá‰ºòÂåñÊñπÈù¢ÁöÑÈ°πÁõÆÊàêÊûúÔºåËé∑ÂæóÂèçÈ¶àÂíåÂª∫ËÆÆÔºå‰øÉËøõÈ°πÁõÆÂçè‰Ωú„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;üìö &lt;strong&gt;Â≠¶‰π†ËµÑÊ∫ê&lt;/strong&gt;ÔºöÁ§æÂå∫Áª¥Êä§‰∏∞ÂØåÁöÑÂ≠¶‰π†ËµÑÊñôÂ∫ìÔºåÂåÖÊã¨ÊïôÁ®ã„ÄÅÊñáÊ°£ÂíåËÆ∫ÊñáËß£ËØªÔºå‰∏∫ÊàêÂëòÊèê‰æõÂÖ®Èù¢ÁöÑÂ≠¶‰π†ÊîØÊåÅ„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;üìù &lt;strong&gt;ËÆ∫ÊñáËß£ËØª&lt;/strong&gt;ÔºöÁ§æÂå∫ÊàêÂëòÂÖ±ÂêåËß£ËØª‰∏éLlama2Áõ∏ÂÖ≥ÁöÑÊúÄÊñ∞Á†îÁ©∂ËÆ∫ÊñáÔºåÊ∑±ÂÖ•ÁêÜËß£ÂâçÊ≤øÁÆóÊ≥ïÂíåÊñπÊ≥ï„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;üéâ &lt;strong&gt;‰∏ªÈ¢òÊ¥ªÂä®&lt;/strong&gt;ÔºöÂÆöÊúü‰∏æÂäûÂêÑÁ±ª‰∏ªÈ¢òÊ¥ªÂä®ÔºåÂåÖÊã¨ÊåëÊàòËµõ„ÄÅÈªëÂÆ¢È©¨ÊãâÊùæÂíåÊäÄÊúØÊ≤ôÈæôÔºåËÆ©Á§æÂå∫ÊàêÂëòÂú®ËΩªÊùæÊÑâÂø´ÁöÑÊ∞õÂõ¥‰∏≠‰∫§ÊµÅÂíåÂ≠¶‰π†„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;üåü &lt;strong&gt;Â•ñÂä±ËÆ°Âàí&lt;/strong&gt;ÔºöÊàë‰ª¨ËÆæÁ´ãÂ•ñÂä±ËÆ°ÂàíÔºåÂØπÁ§æÂå∫‰∏≠ÁßØÊûÅÂèÇ‰∏é„ÄÅË¥°ÁåÆ‰ºòÁßÄÁöÑÊàêÂëòÁªô‰∫àËç£Ë™âÂíåÂ•ñÂä±ÔºåÊøÄÂä±Êõ¥Â§ö‰ºòÁßÄ‰∫∫ÊâçÁöÑÂä†ÂÖ•„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;üìà &lt;strong&gt;ÊäÄÊúØÂí®ËØ¢&lt;/strong&gt;ÔºöÊàë‰ª¨Êèê‰æõÊäÄÊúØÂí®ËØ¢ÊúçÂä°ÔºåËß£Á≠îÊÇ®Âú®Llama2ÂºÄÂèëÂíå‰ºòÂåñËøáÁ®ã‰∏≠ÈÅáÂà∞ÁöÑÈóÆÈ¢òÔºåÂä©ÊÇ®Âø´ÈÄüÊîªÂÖãÈöæÂÖ≥„ÄÇ&lt;/p&gt; &#xA; &lt;p&gt;üöÄ &lt;strong&gt;È°πÁõÆÂêà‰Ωú&lt;/strong&gt;ÔºöÈºìÂä±ÊàêÂëòÈó¥ÁöÑÈ°πÁõÆÂêà‰ΩúÔºåÂÖ±ÂêåÊé¢Á¥¢Llama2Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊΩúÂäõÔºåÊâìÈÄ†ÂàõÊñ∞Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ&lt;/p&gt; &#xA; &lt;h3&gt;Á´ãÂç≥Âä†ÂÖ•Êàë‰ª¨ÔºÅ&lt;/h3&gt; &#xA; &lt;p&gt;üìö &lt;strong&gt;ÊÑøÊôØ&lt;/strong&gt;ÔºöÊó†ËÆ∫ÊÇ®ÊòØÂØπLlama2Â∑≤ÊúâÁ†îÁ©∂ÂíåÂ∫îÁî®ÁªèÈ™åÁöÑ‰∏ì‰∏öÂºÄÂèëËÄÖÔºåËøòÊòØÂØπLlama2‰∏≠Êñá‰ºòÂåñÊÑüÂÖ¥Ë∂£Âπ∂Â∏åÊúõÊ∑±ÂÖ•Êé¢Á¥¢ÁöÑÊñ∞ÊâãÔºåÊàë‰ª¨ÈÉΩÁÉ≠ÂàáÊúüÂæÖÊÇ®ÁöÑÂä†ÂÖ•„ÄÇÂú®Llama2‰∏≠ÊñáÁ§æÂå∫ÔºåÊÇ®Â∞ÜÊúâÊú∫‰ºö‰∏éË°å‰∏öÂÜÖÈ°∂Â∞ñ‰∫∫ÊâçÂÖ±Âêå‰∫§ÊµÅÔºåÊê∫ÊâãÊé®Âä®‰∏≠ÊñáNLPÊäÄÊúØÁöÑËøõÊ≠•ÔºåÂºÄÂàõÊõ¥Âä†ÁæéÂ•ΩÁöÑÊäÄÊúØÊú™Êù•ÔºÅ&lt;/p&gt; &#xA; &lt;p&gt;üîó &lt;strong&gt;Ê∏©È¶®ÊèêÁ§∫&lt;/strong&gt;ÔºöÊú¨Á§æÂå∫‰∏∫‰∏ì‰∏öÊäÄÊúØ‰∫§ÊµÅÂπ≥Âè∞ÔºåÊàë‰ª¨ÁÉ≠ÂàáÊúüÊúõÂøóÂêåÈÅìÂêàÁöÑÂºÄÂèëËÄÖÂíåÁ†îÁ©∂ËÄÖÂä†ÂÖ•„ÄÇËØ∑ÈÅµÂÆàÁ§æÂå∫ÂáÜÂàôÔºåÂÖ±ÂêåÁª¥Êä§ÁßØÊûÅÂêë‰∏äÁöÑÂ≠¶‰π†Ê∞õÂõ¥Ôºå‰ªª‰Ωï‰∏éLlama2Êó†ÂÖ≥ÁöÑÂÜÖÂÆπÂíåÂπøÂëäÂ∞ÜË¢´Ê∏ÖÁêÜ„ÄÇÊÑüË∞¢ÊÇ®ÁöÑÁêÜËß£ÂíåÊîØÊåÅÔºÅ&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;üì¢ Á§æÂå∫ÂÖ¨Âëä&lt;/h2&gt; &#xA;&lt;p&gt;„ÄêÊúÄÊñ∞„Äë2024Âπ¥03Êúà08Êó•ÔºöÂºÄÊîæ‰∫ÜÂÖçË¥πAPI‰æõÂ§ßÂÆ∂‰ΩøÁî®ÔºåÂåÖÂê´ÔºàAtom-1B,7B,13B 3Áßç‰∏≠ÊñáÂ§ßÊ®°ÂûãÔºâ&lt;a href=&#34;https://llama.family/docs/chat-completion-v1&#34;&gt;API‰ΩøÁî®ÈìæÊé•&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;„ÄêÊúÄÊñ∞„Äë2023Âπ¥10Êúà8Êó•ÔºöÊñ∞Â¢ûÊ∏ÖÂçéÂ§ßÂ≠¶JittorLLMsÁöÑÊé®ÁêÜÂä†ÈÄüÂäüËÉΩ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#jittorllms&#34;&gt;JittorLLMs&lt;/a&gt;ÔºÅ&lt;/p&gt; &#xA;&lt;p&gt;„ÄêÊúÄÊñ∞„Äë2023Âπ¥9Êúà12Êó•ÔºöÊõ¥Êñ∞È¢ÑËÆ≠ÁªÉÁâàÊú¨&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B&#34;&gt;Atom-7B&lt;/a&gt;ÂíåÂØπËØùÁâàÊú¨&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B-Chat&#34;&gt;Atom-7B-Chat&lt;/a&gt;Ê®°ÂûãÂèÇÊï∞ÔºåÊúÄÊñ∞ÁöÑ‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÈáè‰∏∫100B tokenÔºåËÆ≠ÁªÉËøõÁ®ãËßÅ&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;ÔºÅ&lt;/p&gt; &#xA;&lt;p&gt;„ÄêÊúÄÊñ∞„Äë2023Âπ¥9Êúà2Êó•ÔºöÊñ∞Â¢ûÊ®°Âûã&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83&#34;&gt;È¢ÑËÆ≠ÁªÉ‰ª£Á†Å&lt;/a&gt;Âíå&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83&#34;&gt;ÂÖ®ÈáèÂèÇÊï∞ÂæÆË∞É‰ª£Á†Å&lt;/a&gt;ÔºÅ&lt;/p&gt; &#xA;&lt;p&gt;„ÄêÊúÄÊñ∞„Äë2023Âπ¥8Êúà28Êó•ÔºöÂèëÂ∏ÉÂü∫‰∫éLlama2ËøõË°å‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉÁöÑÂºÄÊ∫êÂ§ßÊ®°Âûã&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B&#34;&gt;Atom-7B&lt;/a&gt;ÔºåÂπ∂Â∞ÜÊåÅÁª≠Êõ¥Êñ∞ÔºåËØ¶ÊÉÖÂèÇËÄÉ&lt;a href=&#34;https://mp.weixin.qq.com/s/Bdx0JTVh1kgPn5ydYxIkEw&#34;&gt;Á§æÂå∫ÂÖ¨‰ºóÂè∑ÊñáÁ´†&lt;/a&gt;ÔºÅ&lt;/p&gt; &#xA;&lt;p&gt;„ÄêÊúÄÊñ∞„Äë2023Âπ¥8Êúà26Êó•ÔºöÊèê‰æõ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#fastapi%E6%8E%A5%E5%8F%A3%E6%90%AD%E5%BB%BA&#34;&gt;FastAPI&lt;/a&gt;Êé•Âè£Êê≠Âª∫ËÑöÊú¨ÔºÅ&lt;/p&gt; &#xA;&lt;p&gt;„ÄêÊúÄÊñ∞„Äë2023Âπ¥8Êúà26Êó•ÔºöÊèê‰æõÂ∞ÜMetaÂéüÂßãÊ®°ÂûãÂèÇÊï∞ËΩ¨Êç¢‰∏∫ÂÖºÂÆπHugging FaceÁöÑ&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/scripts/convert2hf/README.md&#34;&gt;Ê†ºÂºèËΩ¨ÂåñËÑöÊú¨&lt;/a&gt;ÔºÅ&lt;/p&gt; &#xA;&lt;p&gt;„ÄêÊúÄÊñ∞„Äë2023Âπ¥8Êúà26Êó•ÔºöÊñ∞Â¢û&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E4%BB%A3%E7%A0%81%E6%A8%A1%E5%9E%8B&#34;&gt;Code Llama&lt;/a&gt;Ê®°ÂûãÔºÅ&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥8Êúà15Êó•ÔºöÊñ∞Â¢û&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%8A%A0%E8%BD%BD%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B&#34;&gt;PEFTÂä†ËΩΩÂæÆË∞ÉÊ®°ÂûãÂèÇÊï∞&lt;/a&gt;ÁöÑ‰ª£Á†ÅÁ§∫‰æãÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥8Êúà14Êó•Ôºö&lt;a href=&#34;https://llama.family&#34;&gt;Â§ßÊ®°ÂûãÊï∞ÊçÆÂÖ±‰∫´ËÆ≠ÁªÉÂπ≥Âè∞&lt;/a&gt;‰∏äÁ∫øÔºåÊ≤°ÊúâÁÆóÂäõ‰πüËÉΩÂèÇ‰∏éÂ§ßÊ®°ÂûãËÆ≠ÁªÉÔºåÁ§æÂå∫ÊØè‰ΩçÊàêÂëòË¥°ÁåÆÁöÑÊï∞ÊçÆÈÉΩÂ∞ÜÂÜ≥ÂÆöÊ®°ÂûãËÉΩÂäõÁöÑÊú™Êù•Ëµ∞ÂêëÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥8Êúà3Êó•ÔºöÊñ∞Â¢ûFasterTransformerÂíåvLLMÁöÑGPU&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F&#34;&gt;Êé®ÁêÜÂä†ÈÄü&lt;/a&gt;ÊîØÊåÅÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà31Êó•Ôºö„ÄêÈáçÁ£Ö„ÄëÂõΩÂÜÖÈ¶ñ‰∏™ÁúüÊ≠£ÊÑè‰πâ‰∏äÁöÑLlama2‰∏≠ÊñáÂ§ßÊ®°ÂûãÂèëÂ∏ÉÔºÅËØ¶ÊÉÖÂèÇËßÅ&lt;a href=&#34;https://mp.weixin.qq.com/s/lExUU7z_MvgJ7tzQPF8tUQ&#34;&gt;Á§æÂå∫ÂÖ¨‰ºóÂè∑ÊñáÁ´†&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà28Êó•ÔºöÈÄöËøá&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#docker%E9%83%A8%E7%BD%B2%E9%97%AE%E7%AD%94%E6%8E%A5%E5%8F%A3&#34;&gt;DockerÈÉ®ÁΩ≤&lt;/a&gt;ÈóÆÁ≠îÊé•Âè£ÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà27Êó•ÔºöÊñ∞Â¢û&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#langchain&#34;&gt;LangChain&lt;/a&gt;ÊîØÊåÅÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà26Êó•ÔºöÊñ∞Â¢ûLlama2-13B‰∏≠ÊñáÂæÆË∞ÉÂèÇÊï∞ÁöÑ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96&#34;&gt;4bitÈáèÂåñÂéãÁº©ÁâàÊú¨&lt;/a&gt;ÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà25Êó•ÔºöÁ§æÂå∫ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑‚ÄúLlama‰∏≠ÊñáÁ§æÂå∫‚ÄùÊ¨¢ËøéÂ§ßÂÆ∂ÂÖ≥Ê≥®ÔºåËé∑ÂèñÊúÄÊñ∞ÂàÜ‰∫´ÂíåÂä®ÊÄÅÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà24Êó•Ôºö&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;FlagAlpha&lt;/a&gt;Êñ∞Â¢ûLlama2-13B‰∏≠ÊñáÂæÆË∞ÉÂèÇÊï∞ÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà24Êó•Ôºö&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;Êñ∞Â¢ûLlama2-70BÂú®Á∫ø‰ΩìÈ™åÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà23Êó•ÔºöLlama2‰∏≠ÊñáÂæÆË∞ÉÂèÇÊï∞ÂèëÂ∏ÉËá≥Hugging Face‰ªìÂ∫ì&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;FlagAlpha&lt;/a&gt;ÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà22Êó•ÔºöLlama2Âú®Á∫ø‰ΩìÈ™åÈìæÊé•&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;‰∏äÁ∫øÔºåÂêåÊó∂ÂåÖÂê´MetaÂéüÁâàÂíå‰∏≠ÊñáÂæÆË∞ÉÁâàÊú¨ÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà21Êó•ÔºöËØÑÊµã‰∫ÜMetaÂéüÂßãÁâàLlama2 ChatÊ®°ÂûãÁöÑ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B&#34;&gt;‰∏≠ÊñáÈóÆÁ≠îËÉΩÂäõ&lt;/a&gt;ÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà21Êó•ÔºöÊñ∞Â¢ûLlama2Ê®°ÂûãÁöÑHugging FaceÁâàÊú¨ÂõΩÂÜÖ‰∏ãËΩΩÂú∞ÂùÄÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà20Êó•ÔºöÊñ∞Â¢û&lt;a href=&#34;https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink&#34;&gt;È£û‰π¶Áü•ËØÜÂ∫ìÊñáÊ°£&lt;/a&gt;ÔºåÊ¨¢ËøéÂ§ßÂÆ∂‰∏ÄËµ∑ÂÖ±Âª∫ÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà20Êó•ÔºöÂõΩÂÜÖLlama2ÊúÄÊñ∞‰∏ãËΩΩÂú∞ÂùÄ‰∏äÁ∫øÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà19Êó•ÔºöÊ≠£ÂºèÂêØÂä®Llama2Ê®°ÂûãÁöÑ‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉÔºåÂÖ≥Ê≥®Êàë‰ª¨Ëé∑ÂèñÂÆûÊó∂Âä®ÊÄÅÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà19Êó•ÔºöLlama2ÂõΩÂÜÖ‰∏ãËΩΩÂú∞ÂùÄÊ≠£Âú®ÂêØÂä®ÔºåÊï¨ËØ∑ÊúüÂæÖÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;2023Âπ¥7Êúà19Êó•ÔºöÂºÄÂêØLlama2‰∏≠ÊñáÁ§æÂå∫ÔºåÊ¨¢ËøéÂ§ßÂÆ∂Âä†ÂÖ•ÔºÅ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;üêº ÂõΩÂÜÖLlama2ÊúÄÊñ∞‰∏ãËΩΩÂú∞ÂùÄ&lt;/h2&gt; &#xA;&lt;p&gt;Êú¨‰ªìÂ∫ì‰∏≠ÁöÑ‰ª£Á†ÅÁ§∫‰æã‰∏ªË¶ÅÊòØÂü∫‰∫éHugging FaceÁâàÊú¨ÂèÇÊï∞ËøõË°åË∞ÉÁî®ÔºåÊàë‰ª¨Êèê‰æõ‰∫ÜËÑöÊú¨Â∞ÜMetaÂÆòÁΩëÂèëÂ∏ÉÁöÑÊ®°ÂûãÂèÇÊï∞ËΩ¨Êç¢‰∏∫Hugging FaceÊîØÊåÅÁöÑÊ†ºÂºèÔºåÂèØ‰ª•Áõ¥Êé•ÈÄöËøátransformersÂ∫ìËøõË°åÂä†ËΩΩÔºö&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/scripts/convert2hf/README.md&#34;&gt;ÂèÇÊï∞Ê†ºÂºèËΩ¨Âåñ&lt;/a&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-7BÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_kR2fwuJdG1F3CoF33rwpIA1?pwd=z9kf&#34;&gt;https://pan.xunlei.com/s/VN_kR2fwuJdG1F3CoF33rwpIA1?pwd=z9kf&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-7B-ChatÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_kQa1_HBvV-X9QVI6jV2kOA1?pwd=xmra&#34;&gt;https://pan.xunlei.com/s/VN_kQa1_HBvV-X9QVI6jV2kOA1?pwd=xmra&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-13BÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_izibaMDoptluWodzJw4cRA1?pwd=2qqb&#34;&gt;https://pan.xunlei.com/s/VN_izibaMDoptluWodzJw4cRA1?pwd=2qqb&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-13B-ChatÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_iyyponyapjIDLXJCNfqy7A1?pwd=t3xw&#34;&gt;https://pan.xunlei.com/s/VN_iyyponyapjIDLXJCNfqy7A1?pwd=t3xw&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-7B Hugging FaceÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep&#34;&gt;https://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-7B-Chat Hugging FaceÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir&#34;&gt;https://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-13B Hugging FaceÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf&#34;&gt;https://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-13B-Chat Hugging FaceÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg&#34;&gt;https://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Llama2-70B-Chat Hugging FaceÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.xunlei.com/s/VNa_vCGzCy3h3N7oeFXs2W1hA1?pwd=uhxh#&#34;&gt;https://pan.xunlei.com/s/VNa_vCGzCy3h3N7oeFXs2W1hA1?pwd=uhxh#&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;CodeLlama-7bÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.baidu.com/s/1cIPzdNywWLvQI7_2QanOEQ?pwd=zfwi&#34;&gt;https://pan.baidu.com/s/1cIPzdNywWLvQI7_2QanOEQ?pwd=zfwi&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;CodeLlama-7b-PythonÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.baidu.com/s/1liY8klGoDagYbpw-g-oFag?pwd=i952&#34;&gt;https://pan.baidu.com/s/1liY8klGoDagYbpw-g-oFag?pwd=i952&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;CodeLlama-7b-InstructÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.baidu.com/s/108o9_DT2E_vfSGtOnDCQVw?pwd=zkt9&#34;&gt;https://pan.baidu.com/s/108o9_DT2E_vfSGtOnDCQVw?pwd=zkt9&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;CodeLlama-13bÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.baidu.com/s/1lLaeHv0XEBv0iiZzI1dpnw?pwd=qn99&#34;&gt;https://pan.baidu.com/s/1lLaeHv0XEBv0iiZzI1dpnw?pwd=qn99&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;CodeLlama-13b-PythonÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.baidu.com/s/1OLVfvZS_oqL3oqMKwsI87w?pwd=a78k&#34;&gt;https://pan.baidu.com/s/1OLVfvZS_oqL3oqMKwsI87w?pwd=a78k&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;CodeLlama-13b-InstructÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.baidu.com/s/1HyxJl4w8wElgkZRh2ATrXQ?pwd=seg6&#34;&gt;https://pan.baidu.com/s/1HyxJl4w8wElgkZRh2ATrXQ?pwd=seg6&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;CodeLlama-34bÂÆòÁΩëÁâàÊú¨Ôºö&lt;a href=&#34;https://pan.baidu.com/s/1vEw0pFgIkctPUN4_5_6pIQ?pwd=q8eu&#34;&gt;https://pan.baidu.com/s/1vEw0pFgIkctPUN4_5_6pIQ?pwd=q8eu&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;üîµ AtomÂ§ßÊ®°Âûã&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;ÂéüÂ≠êÂ§ßÊ®°ÂûãAtom&lt;/strong&gt;Áî±Llama‰∏≠ÊñáÁ§æÂå∫ÂíåÂéüÂ≠êÂõûÂ£∞ËÅîÂêàÊâìÈÄ†ÔºåÂú®‰∏≠ÊñáÂ§ßÊ®°ÂûãËØÑÊµãÊ¶úÂçïC-Eval‰∏≠‰ΩçÂ±ÖÂâçÂçÅÔºà8Êúà21Êó•ËØÑÊµãÊèê‰∫§Êó∂Èó¥Ôºâ„ÄÇ&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/ceval.jpg&#34; alt=&#34;ceval&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;AtomÁ≥ªÂàóÊ®°ÂûãÂåÖÂê´Atom-7BÂíåAtom-13BÔºåÂü∫‰∫éLlama2ÂÅö‰∫Ü‰∏≠ÊñáËÉΩÂäõÁöÑÊåÅÁª≠‰ºòÂåñ„ÄÇAtom-7BÂíåAtom-7B-ChatÁõÆÂâçÂ∑≤ÂÆåÂÖ®ÂºÄÊ∫êÔºåÊîØÊåÅÂïÜÁî®ÔºåÂèØÂú®&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;Hugging Face&lt;/a&gt;‰ªìÂ∫ìËé∑ÂèñÊ®°ÂûãÔºåËØ¶ÊÉÖËßÅ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%9F%BA%E4%BA%8Ellama2%E7%9A%84%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8Batom&#34;&gt;Atom-7B‰∏ãËΩΩ&lt;/a&gt;„ÄÇAtomÂ§ßÊ®°ÂûãÈíàÂØπ‰∏≠ÊñáÂÅö‰∫Ü‰ª•‰∏ã‰ºòÂåñÔºö&lt;/p&gt; &#xA;&lt;h3&gt;Â§ßËßÑÊ®°ÁöÑ‰∏≠ÊñáÊï∞ÊçÆÈ¢ÑËÆ≠ÁªÉ&lt;/h3&gt; &#xA;&lt;p&gt;ÂéüÂ≠êÂ§ßÊ®°ÂûãAtomÂú®Llama2ÁöÑÂü∫Á°Ä‰∏äÔºåÈááÁî®Â§ßËßÑÊ®°ÁöÑ‰∏≠ÊñáÊï∞ÊçÆËøõË°åÊåÅÁª≠È¢ÑËÆ≠ÁªÉÔºåÂåÖÂê´ÁôæÁßë„ÄÅ‰π¶Á±ç„ÄÅÂçöÂÆ¢„ÄÅÊñ∞Èóª„ÄÅÂÖ¨Âëä„ÄÅÂ∞èËØ¥„ÄÅÈáëËûçÊï∞ÊçÆ„ÄÅÊ≥ïÂæãÊï∞ÊçÆ„ÄÅÂåªÁñóÊï∞ÊçÆ„ÄÅ‰ª£Á†ÅÊï∞ÊçÆ„ÄÅ‰∏ì‰∏öËÆ∫ÊñáÊï∞ÊçÆ„ÄÅ‰∏≠ÊñáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁ´ûËµõÊï∞ÊçÆÈõÜÁ≠âÔºåËØ¶ËßÅ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90&#34;&gt;üìù Êï∞ÊçÆÊù•Ê∫ê&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;ÂêåÊó∂ÂØπÂ∫ûÂ§ßÁöÑÊï∞ÊçÆËøõË°å‰∫ÜËøáÊª§„ÄÅÊâìÂàÜ„ÄÅÂéªÈáçÔºåÁ≠õÈÄâÂá∫Ë∂ÖËøá1T tokenÁöÑÈ´òË¥®Èáè‰∏≠ÊñáÊï∞ÊçÆÔºåÊåÅÁª≠‰∏çÊñ≠Âä†ÂÖ•ËÆ≠ÁªÉËø≠‰ª£‰∏≠„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;Êõ¥È´òÊïàÁöÑ‰∏≠ÊñáËØçË°®&lt;/h3&gt; &#xA;&lt;p&gt;‰∏∫‰∫ÜÊèêÈ´ò‰∏≠ÊñáÊñáÊú¨Â§ÑÁêÜÁöÑÊïàÁéáÔºåÊàë‰ª¨ÈíàÂØπLlama2Ê®°ÂûãÁöÑËØçË°®ËøõË°å‰∫ÜÊ∑±Â∫¶‰ºòÂåñ„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨Âü∫‰∫éÊï∞ÁôæGÁöÑ‰∏≠ÊñáÊñáÊú¨ÔºåÂú®ËØ•Ê®°ÂûãËØçË°®ÁöÑÂü∫Á°Ä‰∏äÊâ©Â±ïËØçÂ∫ìËá≥65,000‰∏™ÂçïËØç„ÄÇÁªèËøáÊµãËØïÔºåÊàë‰ª¨ÁöÑÊîπËøõ‰ΩøÂæó‰∏≠ÊñáÁºñÁ†Å/Ëß£Á†ÅÈÄüÂ∫¶ÊèêÈ´ò‰∫ÜÁ∫¶350ÔºÖ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËøòÊâ©Â§ß‰∫Ü‰∏≠ÊñáÂ≠óÁ¨¶ÈõÜÁöÑË¶ÜÁõñËåÉÂõ¥ÔºåÂåÖÊã¨ÊâÄÊúâemojiÁ¨¶Âè∑üòä„ÄÇËøô‰ΩøÂæóÁîüÊàêÂ∏¶ÊúâË°®ÊÉÖÁ¨¶Âè∑ÁöÑÊñáÁ´†Êõ¥Âä†È´òÊïà„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;Ëá™ÈÄÇÂ∫î‰∏ä‰∏ãÊñáÊâ©Â±ï&lt;/h3&gt; &#xA;&lt;p&gt;AtomÂ§ßÊ®°ÂûãÈªòËÆ§ÊîØÊåÅ4K‰∏ä‰∏ãÊñáÔºåÂà©Áî®‰ΩçÁΩÆÊèíÂÄºPIÂíåNeural Tangent Kernel ÔºàNTKÔºâÊñπÊ≥ïÔºåÁªèËøáÂæÆË∞ÉÂèØ‰ª•Â∞Ü‰∏ä‰∏ãÊñáÈïøÂ∫¶Êâ©Â¢ûÂà∞32K„ÄÇ&lt;/p&gt; &#xA;&lt;h2&gt;üìù ‰∏≠ÊñáÊï∞ÊçÆ&lt;/h2&gt; &#xA;&lt;p&gt;Êàë‰ª¨ÈÄöËøá‰ª•‰∏ãÊï∞ÊçÆÊù•‰ºòÂåñLlama2ÁöÑ‰∏≠ÊñáËÉΩÂäõ:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Á±ªÂûã&lt;/th&gt; &#xA;   &lt;th&gt;ÊèèËø∞&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ÁΩëÁªúÊï∞ÊçÆ&lt;/td&gt; &#xA;   &lt;td&gt;‰∫íËÅîÁΩë‰∏äÂÖ¨ÂºÄÁöÑÁΩëÁªúÊï∞ÊçÆÔºåÊåëÈÄâÂá∫ÂéªÈáçÂêéÁöÑÈ´òË¥®Èáè‰∏≠ÊñáÊï∞ÊçÆÔºåÊ∂âÂèäÂà∞ÁôæÁßë„ÄÅ‰π¶Á±ç„ÄÅÂçöÂÆ¢„ÄÅÊñ∞Èóª„ÄÅÂÖ¨Âëä„ÄÅÂ∞èËØ¥Á≠âÈ´òË¥®ÈáèÈïøÊñáÊú¨Êï∞ÊçÆ„ÄÇ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/goldsmith/Wikipedia&#34;&gt;Wikipedia&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‰∏≠ÊñáWikipediaÁöÑÊï∞ÊçÆ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/BAAI-WuDao/Model&#34;&gt;ÊÇüÈÅì&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‰∏≠ÊñáÊÇüÈÅìÂºÄÊ∫êÁöÑ200GÊï∞ÊçÆ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/CLUEbenchmark/CLUEDatasetSearch&#34;&gt;Clue&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ClueÂºÄÊîæÁöÑ‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÔºåËøõË°åÊ∏ÖÊ¥óÂêéÁöÑÈ´òË¥®Èáè‰∏≠ÊñáÈïøÊñáÊú¨Êï∞ÊçÆ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Á´ûËµõÊï∞ÊçÆÈõÜ&lt;/td&gt; &#xA;   &lt;td&gt;ËøëÂπ¥Êù•‰∏≠ÊñáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ§ö‰ªªÂä°Á´ûËµõÊï∞ÊçÆÈõÜÔºåÁ∫¶150‰∏™&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/esbatmop/MNBVC&#34;&gt;MNBVC&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MNBVC ‰∏≠Ê∏ÖÊ¥óÂá∫Êù•ÁöÑÈÉ®ÂàÜÊï∞ÊçÆÈõÜ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Â∏åÊúõÂ§ßÂÆ∂Â¶ÇÊûúÊúâËæÉÈ´òË¥®ÈáèÁöÑÊï∞ÊçÆÈõÜËÉΩÂ§üÊèê‰æõÁªôÊàë‰ª¨Ôºå‰∏çËÉúÊÑüÊøÄ!üíïüíï&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;‚è¨ Ê®°ÂûãÈÉ®ÁΩ≤&lt;/h2&gt; &#xA;&lt;p&gt;MetaÂú®ü§óHugging Face‰∏äÊèê‰æõ‰∫ÜÊâÄÊúâÊ®°ÂûãÁöÑ‰∏ãËΩΩÈìæÊé•Ôºö&lt;a href=&#34;https://huggingface.co/meta-llama&#34;&gt;https://huggingface.co/meta-llama&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Llama‰∏≠ÊñáÁ§æÂå∫ÁöÑ‰∏≠ÊñáÊ®°Âûã‰∏ãËΩΩÈìæÊé•Ôºö&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;https://huggingface.co/FlagAlpha&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Ê®°Âûã‰∏ãËΩΩ&lt;/h3&gt; &#xA;&lt;h4&gt;MetaÂÆòÊñπLlama2Ê®°Âûã&lt;/h4&gt; &#xA;&lt;p&gt;Llama2È¢ÑËÆ≠ÁªÉÊ®°ÂûãÂåÖÂê´7B„ÄÅ13BÂíå70B‰∏â‰∏™ÁâàÊú¨„ÄÇLlama2-ChatÊ®°ÂûãÂü∫‰∫éÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°å‰∫ÜÁõëÁù£ÂæÆË∞ÉÔºåÂÖ∑Â§áÊõ¥Âº∫ÁöÑÂØπËØùËÉΩÂäõ„ÄÇ&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Á±ªÂà´&lt;/th&gt; &#xA;   &lt;th&gt;Ê®°ÂûãÂêçÁß∞&lt;/th&gt; &#xA;   &lt;th&gt;ü§óÊ®°ÂûãÂä†ËΩΩÂêçÁß∞&lt;/th&gt; &#xA;   &lt;th&gt;‰∏ãËΩΩÂú∞ÂùÄ&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;È¢ÑËÆ≠ÁªÉ&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-7B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep&#34;&gt;ËøÖÈõ∑ÁΩëÁõò&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;È¢ÑËÆ≠ÁªÉ&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-13B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-13b-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf&#34;&gt;ËøÖÈõ∑ÁΩëÁõò&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;È¢ÑËÆ≠ÁªÉ&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-70B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-70b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-70b-hf&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-chat-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir&#34;&gt;ËøÖÈõ∑ÁΩëÁõò&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-13B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-13b-chat-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg&#34;&gt;ËøÖÈõ∑ÁΩëÁõò&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-70B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-70b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-70b-chat-hf&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://pan.xunlei.com/s/VNa_vCGzCy3h3N7oeFXs2W1hA1?pwd=uhxh#&#34;&gt;ËøÖÈõ∑ÁΩëÁõò&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Âü∫‰∫éLlama2ÁöÑ‰∏≠ÊñáÂæÆË∞ÉÊ®°Âûã&lt;/h4&gt; &#xA;&lt;p&gt;Êàë‰ª¨Âü∫‰∫é‰∏≠ÊñáÊåá‰ª§Êï∞ÊçÆÈõÜÂØπLlama2-ChatÊ®°ÂûãËøõË°å‰∫ÜÂæÆË∞ÉÔºå‰ΩøÂæóLlama2Ê®°ÂûãÊúâÁùÄÊõ¥Âº∫ÁöÑ‰∏≠ÊñáÂØπËØùËÉΩÂäõ„ÄÇLoRAÂèÇÊï∞‰ª•Âèä‰∏éÂü∫Á°ÄÊ®°ÂûãÂêàÂπ∂ÁöÑÂèÇÊï∞ÂùáÂ∑≤‰∏ä‰º†Ëá≥&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;Hugging Face&lt;/a&gt;ÔºåÁõÆÂâçÂåÖÂê´7BÂíå13BÁöÑÊ®°Âûã„ÄÇ&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Á±ªÂà´&lt;/th&gt; &#xA;   &lt;th&gt;Ê®°ÂûãÂêçÁß∞&lt;/th&gt; &#xA;   &lt;th&gt;ü§óÊ®°ÂûãÂä†ËΩΩÂêçÁß∞&lt;/th&gt; &#xA;   &lt;th&gt;Âü∫Á°ÄÊ®°ÂûãÁâàÊú¨&lt;/th&gt; &#xA;   &lt;th&gt;‰∏ãËΩΩÂú∞ÂùÄ&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ÂêàÂπ∂ÂèÇÊï∞&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-Chinese-7b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-7b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ÂêàÂπ∂ÂèÇÊï∞&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-Chinese-13b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-13b-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRAÂèÇÊï∞&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-Chinese-7b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-7b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat-LoRA&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRAÂèÇÊï∞&lt;/td&gt; &#xA;   &lt;td&gt;Llama2-Chinese-13b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Llama2-Chinese-13b-Chat-LoRA&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-LoRA&#34;&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Âü∫‰∫éLlama2ÁöÑ‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãAtom&lt;/h4&gt; &#xA;&lt;p&gt;Á§æÂå∫Êèê‰æõÈ¢ÑËÆ≠ÁªÉÁâàÊú¨Atom-7BÂíåÂü∫‰∫éAtom-7BËøõË°åÂØπËØùÂæÆË∞ÉÁöÑÊ®°ÂûãÂèÇÊï∞‰æõÂºÄÊîæ‰∏ãËΩΩÔºåÊ®°ÂûãÂèÇÊï∞‰ºöÊåÅÁª≠‰∏çÊñ≠Êõ¥Êñ∞ÔºåÂÖ≥‰∫éÊ®°ÂûãÁöÑËøõÂ±ïËØ¶ËßÅÁ§æÂå∫ÂÆòÁΩë&lt;a href=&#34;https://llama.family&#34;&gt;llama.family&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Á±ªÂà´&lt;/th&gt; &#xA;   &lt;th&gt;Ê®°ÂûãÂêçÁß∞&lt;/th&gt; &#xA;   &lt;th&gt;ü§óÊ®°ÂûãÂä†ËΩΩÂêçÁß∞&lt;/th&gt; &#xA;   &lt;th&gt;‰∏ãËΩΩÂú∞ÂùÄ&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;È¢ÑËÆ≠ÁªÉ&lt;/td&gt; &#xA;   &lt;td&gt;Atom-7B&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Atom-7B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://modelscope.cn/models/FlagAlpha/Atom-7B&#34;&gt;ModelScope&lt;/a&gt; | &lt;a href=&#34;https://wisemodel.cn/models/FlagAlpha/Atom-7B&#34;&gt;WiseModel&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;Atom-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;FlagAlpha/Atom-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/FlagAlpha/Atom-7B-Chat&#34;&gt;HuggingFace&lt;/a&gt; | &lt;a href=&#34;https://modelscope.cn/models/FlagAlpha/Atom-7B-Chat&#34;&gt;ModelScope&lt;/a&gt; | &lt;a href=&#34;https://wisemodel.cn/models/FlagAlpha/Atom-7B-Chat&#34;&gt;WiseModel&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Ê®°ÂûãË∞ÉÁî®‰ª£Á†ÅÁ§∫‰æã&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;device_map = &#34;cuda:0&#34; if torch.cuda.is_available() else &#34;auto&#34;&#xA;model = AutoModelForCausalLM.from_pretrained(&#39;FlagAlpha/Atom-7B-Chat&#39;,device_map=device_map,torch_dtype=torch.float16,load_in_8bit=True,trust_remote_code=True,use_flash_attention_2=True)&#xA;model =model.eval()&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;FlagAlpha/Atom-7B-Chat&#39;,use_fast=False)&#xA;tokenizer.pad_token = tokenizer.eos_token&#xA;input_ids = tokenizer([&#39;&amp;lt;s&amp;gt;Human: ‰ªãÁªç‰∏Ä‰∏ã‰∏≠ÂõΩ\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#39;], return_tensors=&#34;pt&#34;,add_special_tokens=False).input_ids&#xA;if torch.cuda.is_available():&#xA;  input_ids = input_ids.to(&#39;cuda&#39;)&#xA;generate_input = {&#xA;    &#34;input_ids&#34;:input_ids,&#xA;    &#34;max_new_tokens&#34;:512,&#xA;    &#34;do_sample&#34;:True,&#xA;    &#34;top_k&#34;:50,&#xA;    &#34;top_p&#34;:0.95,&#xA;    &#34;temperature&#34;:0.3,&#xA;    &#34;repetition_penalty&#34;:1.3,&#xA;    &#34;eos_token_id&#34;:tokenizer.eos_token_id,&#xA;    &#34;bos_token_id&#34;:tokenizer.bos_token_id,&#xA;    &#34;pad_token_id&#34;:tokenizer.pad_token_id&#xA;}&#xA;generate_ids  = model.generate(**generate_input)&#xA;text = tokenizer.decode(generate_ids[0])&#xA;print(text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;FastAPIÊé•Âè£Êê≠Âª∫&lt;/h3&gt; &#xA;&lt;p&gt;‰∏∫‰∫ÜÊñπ‰æøÈÄöËøáAPIÊñπÂºèË∞ÉÁî®Ê®°ÂûãÔºåÊàë‰ª¨Êèê‰æõ‰∫ÜËÑöÊú¨Áî®Êù•Âø´ÈÄüÊê≠Âª∫&lt;a href=&#34;https://github.com/tiangolo/fastapi&#34;&gt;FastAPI&lt;/a&gt;Êé•Âè£ÔºåÁõ∏ÂÖ≥ÊµãËØï‰ª£Á†Å‰∏éAPIÂèÇÊï∞ËÆæÁΩÆËßÅ&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/scripts/api/README.md&#34;&gt;API Ë∞ÉÁî®&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;GradioÂø´ÈÄüÊê≠Âª∫ÈóÆÁ≠îÂπ≥Âè∞&lt;/h3&gt; &#xA;&lt;p&gt;Âü∫‰∫égradioÊê≠Âª∫ÁöÑÈóÆÁ≠îÁïåÈù¢ÔºåÂÆûÁé∞‰∫ÜÊµÅÂºèÁöÑËæìÂá∫ÔºåÂ∞Ü‰∏ãÈù¢‰ª£Á†ÅÂ§çÂà∂Âà∞ÊéßÂà∂Âè∞ËøêË°åÔºå‰ª•‰∏ã‰ª£Á†Å‰ª•Atom-7BÊ®°Âûã‰∏∫‰æãÔºå&lt;font color=&#34;#006600&#34;&gt;‰∏çÂêåÊ®°ÂûãÂè™ÈúÄ‰øÆÊîπ‰∏Ä‰∏ã‰ª£Á†ÅÈáåÁöÑÊ®°ÂûãÂêçÁß∞Â∞±Â•Ω‰∫Üüòä&lt;/font&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python examples/chat_gradio.py --model_name_or_path FlagAlpha/Atom-7B-Chat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;DockerÈÉ®ÁΩ≤ÈóÆÁ≠îÊé•Âè£&lt;/h3&gt; &#xA;&lt;p&gt;ËØ¶ÊÉÖÂèÇËßÅÔºö&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/docs/chat_gradio_guide.md&#34;&gt;DockerÈÉ®ÁΩ≤&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Á¨¨‰∏ÄÊ≠•ÔºöÂáÜÂ§ádockerÈïúÂÉèÔºåÈÄöËøádockerÂÆπÂô®ÂêØÂä®&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/examples/chat_gradio.py&#34;&gt;chat_gradio.py&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/LlamaFamily/Llama-Chinese.git&#xA;&#xA;cd Llama-Chinese&#xA;&#xA;docker build -f docker/Dockerfile -t flagalpha/llama2-chinese:gradio .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Á¨¨‰∫åÊ≠•ÔºöÈÄöËøádocker-composeÂêØÂä®chat_gradio&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd Llama-Chinese/docker&#xA;docker-compose up -d --build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ü§ñ Ê®°ÂûãÈ¢ÑËÆ≠ÁªÉ&lt;/h2&gt; &#xA;&lt;p&gt;ËôΩÁÑ∂Llama2ÁöÑÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÁõ∏ÂØπ‰∫éÁ¨¨‰∏Ä‰ª£LLaMAÊâ©Â§ß‰∫Ü‰∏ÄÂÄçÔºå‰ΩÜÊòØ‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÁöÑÊØî‰æã‰æùÁÑ∂ÈùûÂ∏∏Â∞ëÔºå‰ªÖÂç†0.13%ÔºåËøô‰πüÂØºËá¥‰∫ÜÂéüÂßãLlama2ÁöÑ‰∏≠ÊñáËÉΩÂäõËæÉÂº±„ÄÇ‰∏∫‰∫ÜËÉΩÂ§üÊèêÂçáÊ®°ÂûãÁöÑ‰∏≠ÊñáËÉΩÂäõÔºåÂèØ‰ª•ÈááÁî®ÂæÆË∞ÉÂíåÈ¢ÑËÆ≠ÁªÉ‰∏§ÁßçË∑ØÂæÑÔºåÂÖ∂‰∏≠Ôºö&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;ÂæÆË∞ÉÈúÄË¶ÅÁöÑÁÆóÂäõËµÑÊ∫êÂ∞ëÔºåËÉΩÂ§üÂø´ÈÄüÂÆûÁé∞‰∏Ä‰∏™‰∏≠ÊñáLlamaÁöÑÈõèÂΩ¢„ÄÇ‰ΩÜÁº∫ÁÇπ‰πüÊòæËÄåÊòìËßÅÔºåÂè™ËÉΩÊøÄÂèëÂü∫Â∫ßÊ®°ÂûãÂ∑≤ÊúâÁöÑ‰∏≠ÊñáËÉΩÂäõÔºåÁî±‰∫éLlama2ÁöÑ‰∏≠ÊñáËÆ≠ÁªÉÊï∞ÊçÆÊú¨Ë∫´ËæÉÂ∞ëÔºåÊâÄ‰ª•ËÉΩÂ§üÊøÄÂèëÁöÑËÉΩÂäõ‰πüÊúâÈôêÔºåÊ≤ªÊ†á‰∏çÊ≤ªÊú¨„ÄÇ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Âü∫‰∫éÂ§ßËßÑÊ®°‰∏≠ÊñáËØ≠ÊñôËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåÊàêÊú¨È´òÔºå‰∏ç‰ªÖÈúÄË¶ÅÂ§ßËßÑÊ®°È´òË¥®ÈáèÁöÑ‰∏≠ÊñáÊï∞ÊçÆÔºå‰πüÈúÄË¶ÅÂ§ßËßÑÊ®°ÁöÑÁÆóÂäõËµÑÊ∫ê„ÄÇ‰ΩÜÊòØ‰ºòÁÇπ‰πüÊòæËÄåÊòìËßÅÔºåÂ∞±ÊòØËÉΩ‰ªéÊ®°ÂûãÂ∫ïÂ±Ç‰ºòÂåñ‰∏≠ÊñáËÉΩÂäõÔºåÁúüÊ≠£ËææÂà∞Ê≤ªÊú¨ÁöÑÊïàÊûúÔºå‰ªéÂÜÖÊ†∏‰∏∫Â§ßÊ®°ÂûãÊ≥®ÂÖ•Âº∫Â§ßÁöÑ‰∏≠ÊñáËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Êàë‰ª¨‰∏∫Á§æÂå∫Êèê‰æõ‰∫ÜLlamaÊ®°ÂûãÁöÑÈ¢ÑËÆ≠ÁªÉ‰ª£Á†ÅÔºå‰ª•Âèä&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/tree/main/data&#34;&gt;‰∏≠ÊñáÊµãËØïËØ≠Êñô&lt;/a&gt;ÔºåÊõ¥Â§öÊï∞ÊçÆÂèØ‰ª•ÂèÇËÄÉ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E4%B8%AD%E6%96%87%E6%95%B0%E6%8D%AE&#34;&gt;‰∏≠ÊñáËØ≠Êñô&lt;/a&gt;„ÄÇÂÖ∑‰Ωì‰ª£Á†ÅÂíåÈÖçÁΩÆÂ¶Ç‰∏ãÔºö&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ê®°ÂûãÈ¢ÑËÆ≠ÁªÉËÑöÊú¨Ôºö&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/pretrain.sh&#34;&gt;train/pretrain/pretrain.sh&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;È¢ÑËÆ≠ÁªÉÂÆûÁé∞‰ª£Á†ÅÔºö&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/pretrain_clm.py&#34;&gt;train/pretrain/pretrain_clm.py&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/DeepSpeed&#34;&gt;DeepSpeed&lt;/a&gt;Âä†ÈÄüÔºö &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ÂØπ‰∫éÂçïÂç°ËÆ≠ÁªÉÔºåÂèØ‰ª•ÈááÁî®ZeRO-2ÁöÑÊñπÂºèÔºåÂèÇÊï∞ÈÖçÁΩÆËßÅ &lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/ds_config_zero2.json&#34;&gt;train/pretrain/ds_config_zero2.json&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;ÂØπ‰∫éÂ§öÂç°ËÆ≠ÁªÉÔºåÂèØ‰ª•ÈááÁî®ZeRO-3ÁöÑÊñπÂºèÔºåÂèÇÊï∞ÈÖçÁΩÆËßÅ &lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/ds_config_zero3.json&#34;&gt;train/pretrain/ds_config_zero3.json&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ËÆ≠ÁªÉÊïàÊûúÂ∫¶ÈáèÊåáÊ†áÔºö&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/pretrain/accuracy.py&#34;&gt;train/pretrain/accuracy.py&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üí° Ê®°ÂûãÂæÆË∞É&lt;/h2&gt; &#xA;&lt;p&gt;Êú¨‰ªìÂ∫ì‰∏≠ÂêåÊó∂Êèê‰æõ‰∫ÜLoRAÂæÆË∞ÉÂíåÂÖ®ÈáèÂèÇÊï∞ÂæÆË∞É‰ª£Á†ÅÔºåÂÖ≥‰∫éLoRAÁöÑËØ¶ÁªÜ‰ªãÁªçÂèØ‰ª•ÂèÇËÄÉËÆ∫Êñá‚Äú&lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;LoRA: Low-Rank Adaptation of Large Language Models&lt;/a&gt;‚Äù‰ª•ÂèäÂæÆËΩØGithub‰ªìÂ∫ì&lt;a href=&#34;https://github.com/microsoft/LoRA&#34;&gt;LoRA&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;Step1: ÁéØÂ¢ÉÂáÜÂ§á&lt;/h3&gt; &#xA;&lt;p&gt;Ê†πÊçÆ&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/requirements.txt&#34;&gt;requirements.txt&lt;/a&gt;ÂÆâË£ÖÂØπÂ∫îÁöÑÁéØÂ¢É‰æùËµñ„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;Step2: Êï∞ÊçÆÂáÜÂ§á&lt;/h3&gt; &#xA;&lt;p&gt;Âú®dataÁõÆÂΩï‰∏ãÊèê‰æõ‰∫Ü‰∏Ä‰ªΩÁî®‰∫éÊ®°ÂûãsftÁöÑÊï∞ÊçÆÊ†∑‰æãÔºö&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ËÆ≠ÁªÉÊï∞ÊçÆÔºö&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/data/train_sft.csv&#34;&gt;data/train_sft.csv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;È™åËØÅÊï∞ÊçÆÔºö&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/data/dev_sft.csv&#34;&gt;data/dev_sft.csv&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;ÊØè‰∏™csvÊñá‰ª∂‰∏≠ÂåÖÂê´‰∏ÄÂàó‚Äútext‚ÄùÔºåÊØè‰∏ÄË°å‰∏∫‰∏Ä‰∏™ËÆ≠ÁªÉÊ†∑‰æãÔºåÊØè‰∏™ËÆ≠ÁªÉÊ†∑‰æãÊåâÁÖß‰ª•‰∏ãÊ†ºÂºèÂ∞ÜÈóÆÈ¢òÂíåÁ≠îÊ°àÁªÑÁªá‰∏∫Ê®°ÂûãËæìÂÖ•ÔºåÊÇ®ÂèØ‰ª•ÊåâÁÖß‰ª•‰∏ãÊ†ºÂºèËá™ÂÆö‰πâËÆ≠ÁªÉÂíåÈ™åËØÅÊï∞ÊçÆÈõÜÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#34;&amp;lt;s&amp;gt;Human: &#34;+ÈóÆÈ¢ò+&#34;\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#34;+Á≠îÊ°à&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;‰æãÂ¶ÇÔºå&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;s&amp;gt;Human: Áî®‰∏ÄÂè•ËØùÊèèËø∞Âú∞ÁêÉ‰∏∫‰ªÄ‰πàÊòØÁã¨‰∏ÄÊó†‰∫åÁöÑ„ÄÇ&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: Âõ†‰∏∫Âú∞ÁêÉÊòØÁõÆÂâç‰∏∫Ê≠¢ÂîØ‰∏ÄÂ∑≤Áü•Â≠òÂú®ÁîüÂëΩÁöÑË°åÊòü„ÄÇ&amp;lt;/s&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step3: ÂæÆË∞ÉËÑöÊú¨&lt;/h3&gt; &#xA;&lt;h4&gt;LoRAÂæÆË∞É&lt;/h4&gt; &#xA;&lt;p&gt;LoRAÂæÆË∞ÉËÑöÊú¨ËßÅÔºö&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/sft/finetune_lora.sh&#34;&gt;train/sft/finetune_lora.sh&lt;/a&gt;ÔºåÂÖ≥‰∫éLoRAÂæÆË∞ÉÁöÑÂÖ∑‰ΩìÂÆûÁé∞‰ª£Á†ÅËßÅ&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/sft/finetune_clm_lora.py&#34;&gt;train/sft/finetune_clm_lora.py&lt;/a&gt;ÔºåÂçïÊú∫Â§öÂç°ÁöÑÂæÆË∞ÉÂèØ‰ª•ÈÄöËøá‰øÆÊîπËÑöÊú¨‰∏≠ÁöÑ&lt;code&gt;--include localhost:0&lt;/code&gt;Êù•ÂÆûÁé∞„ÄÇ&lt;/p&gt; &#xA;&lt;h4&gt;ÂÖ®ÈáèÂèÇÊï∞ÂæÆË∞É&lt;/h4&gt; &#xA;&lt;p&gt;ÂÖ®ÈáèÂèÇÊï∞ÂæÆË∞ÉËÑöÊú¨ËßÅÔºö&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/sft/finetune.sh&#34;&gt;train/sft/finetune.sh&lt;/a&gt;ÔºåÂÖ≥‰∫éÂÖ®ÈáèÂèÇÊï∞ÂæÆË∞ÉÁöÑÂÖ∑‰ΩìÂÆûÁé∞‰ª£Á†ÅËßÅ&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/train/sft/finetune_clm.py&#34;&gt;train/sft/finetune_clm.py&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;Step4: Âä†ËΩΩÂæÆË∞ÉÊ®°Âûã&lt;/h3&gt; &#xA;&lt;h4&gt;LoRAÂæÆË∞É&lt;/h4&gt; &#xA;&lt;p&gt;Âü∫‰∫éLoRAÂæÆË∞ÉÁöÑÊ®°ÂûãÂèÇÊï∞ËßÅÔºö&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E5%9F%BA%E4%BA%8Ellama2%E7%9A%84%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B&#34;&gt;Âü∫‰∫éLlama2ÁöÑ‰∏≠ÊñáÂæÆË∞ÉÊ®°Âûã&lt;/a&gt;ÔºåLoRAÂèÇÊï∞ÈúÄË¶ÅÂíåÂü∫Á°ÄÊ®°ÂûãÂèÇÊï∞ÁªìÂêà‰ΩøÁî®„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;ÈÄöËøá&lt;a href=&#34;https://github.com/huggingface/peft&#34;&gt;PEFT&lt;/a&gt;Âä†ËΩΩÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÂèÇÊï∞ÂíåÂæÆË∞ÉÊ®°ÂûãÂèÇÊï∞Ôºå‰ª•‰∏ãÁ§∫‰æã‰ª£Á†Å‰∏≠Ôºåbase_model_name_or_path‰∏∫È¢ÑËÆ≠ÁªÉÊ®°ÂûãÂèÇÊï∞‰øùÂ≠òË∑ØÂæÑÔºåfinetune_model_path‰∏∫ÂæÆË∞ÉÊ®°ÂûãÂèÇÊï∞‰øùÂ≠òË∑ØÂæÑ„ÄÇ&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;from peft import PeftModel,PeftConfig&#xA;# ‰æãÂ¶Ç: finetune_model_path=&#39;FlagAlpha/Llama2-Chinese-7b-Chat-LoRA&#39;&#xA;finetune_model_path=&#39;&#39;  &#xA;config = PeftConfig.from_pretrained(finetune_model_path)&#xA;# ‰æãÂ¶Ç: base_model_name_or_path=&#39;meta-llama/Llama-2-7b-chat&#39;&#xA;tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path,use_fast=False)&#xA;tokenizer.pad_token = tokenizer.eos_token&#xA;device_map = &#34;cuda:0&#34; if torch.cuda.is_available() else &#34;auto&#34;&#xA;model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,device_map=device_map,torch_dtype=torch.float16,load_in_8bit=True,trust_remote_code=True,use_flash_attention_2=True)&#xA;model = PeftModel.from_pretrained(model, finetune_model_path, device_map={&#34;&#34;: 0})&#xA;model =model.eval()&#xA;input_ids = tokenizer([&#39;&amp;lt;s&amp;gt;Human: ‰ªãÁªç‰∏Ä‰∏ãÂåó‰∫¨\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#39;], return_tensors=&#34;pt&#34;,add_special_tokens=False).input_ids&#xA;if torch.cuda.is_available():&#xA;  input_ids = input_ids.to(&#39;cuda&#39;)&#xA;generate_input = {&#xA;    &#34;input_ids&#34;:input_ids,&#xA;    &#34;max_new_tokens&#34;:512,&#xA;    &#34;do_sample&#34;:True,&#xA;    &#34;top_k&#34;:50,&#xA;    &#34;top_p&#34;:0.95,&#xA;    &#34;temperature&#34;:0.3,&#xA;    &#34;repetition_penalty&#34;:1.3,&#xA;    &#34;eos_token_id&#34;:tokenizer.eos_token_id,&#xA;    &#34;bos_token_id&#34;:tokenizer.bos_token_id,&#xA;    &#34;pad_token_id&#34;:tokenizer.pad_token_id&#xA;}&#xA;generate_ids  = model.generate(**generate_input)&#xA;text = tokenizer.decode(generate_ids[0])&#xA;print(text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;ÂÖ®ÈáèÂèÇÊï∞ÂæÆË∞É&lt;/h4&gt; &#xA;&lt;p&gt;ÂØπ‰∫éÂÖ®ÈáèÂèÇÊï∞ÂæÆË∞ÉÁöÑÊ®°ÂûãÔºåË∞ÉÁî®ÊñπÂºèÂêå&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%94%A8%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B&#34;&gt;Ê®°ÂûãË∞ÉÁî®‰ª£Á†ÅÁ§∫‰æã&lt;/a&gt;ÔºåÂè™ÈúÄË¶Å‰øÆÊîπÂÖ∂‰∏≠ÁöÑÊ®°ÂûãÂêçÁß∞ÊàñËÄÖ‰øùÂ≠òË∑ØÂæÑÂç≥ÂèØ„ÄÇ&lt;/p&gt; &#xA;&lt;!-- ## üöÄ Êú™Êù•ËÆ°Âàí --&gt; &#xA;&lt;h2&gt;üçÑ Ê®°ÂûãÈáèÂåñ&lt;/h2&gt; &#xA;&lt;p&gt;Êàë‰ª¨ÂØπ‰∏≠ÊñáÂæÆË∞ÉÁöÑÊ®°ÂûãÂèÇÊï∞ËøõË°å‰∫ÜÈáèÂåñÔºåÊñπ‰æø‰ª•Êõ¥Â∞ëÁöÑËÆ°ÁÆóËµÑÊ∫êËøêË°å„ÄÇÁõÆÂâçÂ∑≤ÁªèÂú®&lt;a href=&#34;https://huggingface.co/FlagAlpha&#34;&gt;Hugging Face&lt;/a&gt;‰∏ä‰º†‰∫Ü13B‰∏≠ÊñáÂæÆË∞ÉÊ®°Âûã&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat&#34;&gt;FlagAlpha/Llama2-Chinese-13b-Chat&lt;/a&gt;ÁöÑ4bitÂéãÁº©ÁâàÊú¨&lt;a href=&#34;https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#34;&gt;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&lt;/a&gt;ÔºåÂÖ∑‰ΩìË∞ÉÁî®ÊñπÂºèÂ¶Ç‰∏ãÔºö&lt;/p&gt; &#xA;&lt;p&gt;ÁéØÂ¢ÉÂáÜÂ§áÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install git+https://github.com/PanQiWei/AutoGPTQ.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoTokenizer&#xA;from auto_gptq import AutoGPTQForCausalLM&#xA;model = AutoGPTQForCausalLM.from_quantized(&#39;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#39;, device=&#34;cuda:0&#34;)&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;FlagAlpha/Llama2-Chinese-13b-Chat-4bit&#39;,use_fast=False)&#xA;input_ids = tokenizer([&#39;&amp;lt;s&amp;gt;Human: ÊÄé‰πàÁôª‰∏äÁÅ´Êòü\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#39;], return_tensors=&#34;pt&#34;,add_special_tokens=False).input_ids.to(&#39;cuda&#39;)        &#xA;generate_input = {&#xA;    &#34;input_ids&#34;:input_ids,&#xA;    &#34;max_new_tokens&#34;:512,&#xA;    &#34;do_sample&#34;:True,&#xA;    &#34;top_k&#34;:50,&#xA;    &#34;top_p&#34;:0.95,&#xA;    &#34;temperature&#34;:0.3,&#xA;    &#34;repetition_penalty&#34;:1.3,&#xA;    &#34;eos_token_id&#34;:tokenizer.eos_token_id,&#xA;    &#34;bos_token_id&#34;:tokenizer.bos_token_id,&#xA;    &#34;pad_token_id&#34;:tokenizer.pad_token_id&#xA;}&#xA;generate_ids  = model.generate(**generate_input)&#xA;text = tokenizer.decode(generate_ids[0])&#xA;print(text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üöÄ Êé®ÁêÜÂä†ÈÄü&lt;/h2&gt; &#xA;&lt;p&gt;ÈöèÁùÄÂ§ßÊ®°ÂûãÂèÇÊï∞ËßÑÊ®°ÁöÑ‰∏çÊñ≠Â¢ûÈïøÔºåÂú®ÊúâÈôêÁöÑÁÆóÂäõËµÑÊ∫ê‰∏ãÔºåÊèêÂçáÊ®°ÂûãÁöÑÊé®ÁêÜÈÄüÂ∫¶ÈÄêÊ∏êÂèò‰∏∫‰∏Ä‰∏™ÈáçË¶ÅÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇÂ∏∏Áî®ÁöÑÊé®ÁêÜÂä†ÈÄüÊ°ÜÊû∂ÂåÖÂê´ lmdeploy„ÄÅFasterTransformer„ÄÅvLLMÂíåJittorLLMs Á≠â„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;TensorRT-LLM&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/NVIDIA/TensorRT-LLM/tree/main&#34;&gt;TensorRT-LLM&lt;/a&gt;Áî±NVIDIAÂºÄÂèëÔºåÈ´òÊÄßËÉΩÊé®ÁêÜÊ°ÜÊû∂&lt;/p&gt; &#xA;&lt;p&gt;ËØ¶ÁªÜÁöÑÊé®ÁêÜÊñáÊ°£ËßÅÔºö&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/tree/main/inference-speed/GPU/TensorRT-LLM_example&#34;&gt;inference-speed/GPU/TensorRT-LLM_example&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;vLLM&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/vllm-project/vllm&#34;&gt;vLLM&lt;/a&gt;Áî±Âä†Â∑ûÂ§ßÂ≠¶‰ºØÂÖãÂà©ÂàÜÊ†°ÂºÄÂèëÔºåÊ†∏ÂøÉÊäÄÊúØÊòØPageAttentionÔºåÂêûÂêêÈáèÊØîHuggingFace TransformersÈ´òÂá∫24ÂÄç„ÄÇÁõ∏ËæÉ‰∏éFasterTrainsformerÔºåvLLMÊõ¥Âä†ÁöÑÁÆÄÂçïÊòìÁî®Ôºå‰∏çÈúÄË¶ÅÈ¢ùÂ§ñËøõË°åÊ®°ÂûãÁöÑËΩ¨Êç¢ÔºåÊîØÊåÅfp16Êé®ÁêÜ„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;ËØ¶ÁªÜÁöÑÊé®ÁêÜÊñáÊ°£ËßÅÔºö&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/inference-speed/GPU/vllm_example/README.md&#34;&gt;inference-speed/GPU/vllm_example&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;JittorLLMs&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Jittor/JittorLLMs&#34;&gt;JittorLLMs&lt;/a&gt;Áî±ÈùûÂçÅÁßëÊäÄÈ¢ÜË°îÔºå‰∏éÊ∏ÖÂçéÂ§ßÂ≠¶ÂèØËßÜÂ™í‰ΩìÁ†îÁ©∂‰∏≠ÂøÉÂêà‰ΩúÁ†îÂèëÔºåÈÄöËøáÂä®ÊÄÅswapÊú∫Âà∂Â§ßÂπÖÈôç‰ΩéÁ°¨‰ª∂ÈÖçÁΩÆË¶ÅÊ±ÇÔºàÂáèÂ∞ë80%Ôºâ,Âπ∂‰∏îJittorÊ°ÜÊû∂ÈÄöËøáÈõ∂Êã∑Ë¥ùÊäÄÊúØÔºåÂ§ßÊ®°ÂûãÂä†ËΩΩÁõ∏ÊØîPytorchÂºÄÈîÄÈôç‰Ωé40%ÔºåÂêåÊó∂ÔºåÈÄöËøáÂÖÉÁÆóÂ≠êËá™Âä®ÁºñËØë‰ºòÂåñÔºåËÆ°ÁÆóÊÄßËÉΩÊèêÂçá20%‰ª•‰∏ä„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;ËØ¶ÁªÜÁöÑÊé®ÁêÜÊñáÊ°£ËßÅÔºö&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/inference-speed/GPU/JittorLLMs_example/README.md&#34;&gt;inference-speed/GPU/JittorLLMs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;lmdeploy&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/InternLM/lmdeploy/&#34;&gt;lmdeploy&lt;/a&gt; Áî±‰∏äÊµ∑‰∫∫Â∑•Êô∫ËÉΩÂÆûÈ™åÂÆ§ÂºÄÂèëÔºåÊé®ÁêÜ‰ΩøÁî® C++/CUDAÔºåÂØπÂ§ñÊèê‰æõ python/gRPC/http Êé•Âè£Âíå WebUI ÁïåÈù¢ÔºåÊîØÊåÅ tensor parallel ÂàÜÂ∏ÉÂºèÊé®ÁêÜ„ÄÅÊîØÊåÅ fp16/weight int4/kv cache int8 ÈáèÂåñ„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;ËØ¶ÁªÜÁöÑÊé®ÁêÜÊñáÊ°£ËßÅÔºö&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/tree/main/inference-speed/GPU/lmdeploy_example&#34;&gt;inference-speed/GPU/lmdeploy_example&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ü•á Ê®°ÂûãËØÑÊµã&lt;/h2&gt; &#xA;&lt;p&gt;‰∏∫‰∫ÜËÉΩÂ§üÊõ¥Âä†Ê∏ÖÊô∞Âú∞‰∫ÜËß£Llama2Ê®°ÂûãÁöÑ‰∏≠ÊñáÈóÆÁ≠îËÉΩÂäõÔºåÊàë‰ª¨Á≠õÈÄâ‰∫Ü‰∏Ä‰∫õÂÖ∑Êúâ‰ª£Ë°®ÊÄßÁöÑ‰∏≠ÊñáÈóÆÈ¢òÔºåÂØπLlama2Ê®°ÂûãËøõË°åÊèêÈóÆ„ÄÇÊàë‰ª¨ÊµãËØïÁöÑÊ®°ÂûãÂåÖÂê´MetaÂÖ¨ÂºÄÁöÑLlama2-7B-ChatÂíåLlama2-13B-Chat‰∏§‰∏™ÁâàÊú¨ÔºåÊ≤°ÊúâÂÅö‰ªª‰ΩïÂæÆË∞ÉÂíåËÆ≠ÁªÉ„ÄÇÊµãËØïÈóÆÈ¢òÁ≠õÈÄâËá™&lt;a href=&#34;https://github.com/AtomEcho/AtomBulb&#34;&gt;AtomBulb&lt;/a&gt;ÔºåÂÖ±95‰∏™ÊµãËØïÈóÆÈ¢òÔºåÂåÖÂê´ÔºöÈÄöÁî®Áü•ËØÜ„ÄÅËØ≠Ë®ÄÁêÜËß£„ÄÅÂàõ‰ΩúËÉΩÂäõ„ÄÅÈÄªËæëÊé®ÁêÜ„ÄÅ‰ª£Á†ÅÁºñÁ®ã„ÄÅÂ∑•‰ΩúÊäÄËÉΩ„ÄÅ‰ΩøÁî®Â∑•ÂÖ∑„ÄÅ‰∫∫Ê†ºÁâπÂæÅÂÖ´‰∏™Â§ßÁöÑÁ±ªÂà´„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;ÊµãËØï‰∏≠‰ΩøÁî®ÁöÑPromptÂ¶Ç‰∏ãÔºå‰æãÂ¶ÇÂØπ‰∫éÈóÆÈ¢ò‚ÄúÂàóÂá∫5ÁßçÂèØ‰ª•ÊîπÂñÑÁù°Áú†Ë¥®ÈáèÁöÑÊñπÊ≥ï‚ÄùÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[INST] &#xA;&amp;lt;&amp;lt;SYS&amp;gt;&amp;gt;&#xA;You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. The answer always been translate into Chinese language.&#xA;&#xA;If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don&#39;t know the answer to a question, please don&#39;t share false information.&#xA;&#xA;The answer always been translate into Chinese language.&#xA;&amp;lt;&amp;lt;/SYS&amp;gt;&amp;gt;&#xA;&#xA;ÂàóÂá∫5ÁßçÂèØ‰ª•ÊîπÂñÑÁù°Áú†Ë¥®ÈáèÁöÑÊñπÊ≥ï&#xA;[/INST]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Llama2-7B-ChatÁöÑÊµãËØïÁªìÊûúËßÅ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/meta_eval_7B.md&#34;&gt;meta_eval_7B.md&lt;/a&gt;ÔºåLlama2-13B-ChatÁöÑÊµãËØïÁªìÊûúËßÅ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/meta_eval_13B.md&#34;&gt;meta_eval_13B.md&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;ÈÄöËøáÊµãËØïÊàë‰ª¨ÂèëÁé∞ÔºåMetaÂéüÂßãÁöÑLlama2 ChatÊ®°ÂûãÂØπ‰∫é‰∏≠ÊñáÈóÆÁ≠îÁöÑÂØπÈΩêÊïàÊûú‰∏ÄËà¨ÔºåÂ§ßÈÉ®ÂàÜÊÉÖÂÜµ‰∏ãÈÉΩ‰∏çËÉΩÁªôÂá∫‰∏≠ÊñáÂõûÁ≠îÔºåÊàñËÄÖÊòØ‰∏≠Ëã±ÊñáÊ∑∑ÊùÇÁöÑÂΩ¢Âºè„ÄÇÂõ†Ê≠§ÔºåÂü∫‰∫é‰∏≠ÊñáÊï∞ÊçÆÂØπLlama2Ê®°ÂûãËøõË°åËÆ≠ÁªÉÂíåÂæÆË∞ÉÂçÅÂàÜÂøÖË¶ÅÔºåÊàë‰ª¨ÁöÑ‰∏≠ÊñáÁâàLlama2Ê®°Âûã‰πüÂ∑≤ÁªèÂú®ËÆ≠ÁªÉ‰∏≠ÔºåËøëÊúüÂ∞ÜÂØπÁ§æÂå∫ÂºÄÊîæ„ÄÇ&lt;/p&gt; &#xA;&lt;h2&gt;üí™ Â§ñÂª∂ËÉΩÂäõ&lt;/h2&gt; &#xA;&lt;p&gt;Èô§‰∫ÜÊåÅÁª≠Â¢ûÂº∫Â§ßÊ®°ÂûãÂÜÖÂú®ÁöÑÁü•ËØÜÂÇ®Â§á„ÄÅÈÄöÁî®ÁêÜËß£„ÄÅÈÄªËæëÊé®ÁêÜÂíåÊÉ≥Ë±°ËÉΩÂäõÁ≠âÔºåÊú™Êù•ÔºåÊàë‰ª¨‰πü‰ºö‰∏çÊñ≠‰∏∞ÂØåÂ§ßÊ®°ÂûãÁöÑÂ§ñÂª∂ËÉΩÂäõÔºå‰æãÂ¶ÇÁü•ËØÜÂ∫ìÊ£ÄÁ¥¢„ÄÅËÆ°ÁÆóÂ∑•ÂÖ∑„ÄÅWolframAlpha„ÄÅÊìç‰ΩúËΩØ‰ª∂Á≠â„ÄÇ Êàë‰ª¨È¶ñÂÖàÈõÜÊàê‰∫ÜLangChainÊ°ÜÊû∂ÔºåÂèØ‰ª•Êõ¥Êñπ‰æøÂú∞Âü∫‰∫éLlama2ÂºÄÂèëÊñáÊ°£Ê£ÄÁ¥¢„ÄÅÈóÆÁ≠îÊú∫Âô®‰∫∫ÂíåÊô∫ËÉΩ‰ΩìÂ∫îÁî®Á≠âÔºåÂÖ≥‰∫éLangChainÁöÑÊõ¥Â§ö‰ªãÁªçÂèÇËßÅ&lt;a href=&#34;https://github.com/langchain-ai/langchain&#34;&gt;LangChain&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;LangChain&lt;/h3&gt; &#xA;&lt;p&gt;ÈíàÂØπLangChainÊ°ÜÊû∂Â∞ÅË£ÖÁöÑLlama2 LLMÁ±ªËßÅ&lt;a href=&#34;https://github.com/LlamaFamily/Llama-Chinese/raw/main/examples/llama2_for_langchain.py&#34;&gt;examples/llama2_for_langchain.py&lt;/a&gt;ÔºåÁÆÄÂçïÁöÑË∞ÉÁî®‰ª£Á†ÅÁ§∫‰æãÂ¶Ç‰∏ãÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from llama2_for_langchain import Llama2&#xA;&#xA;# ËøôÈáå‰ª•Ë∞ÉÁî®FlagAlpha/Atom-7B-Chat‰∏∫‰æã&#xA;llm = Llama2(model_name_or_path=&#39;FlagAlpha/Atom-7B-Chat&#39;)&#xA;&#xA;while True:&#xA;    human_input = input(&#34;Human: &#34;)&#xA;    response = llm(human_input)&#xA;    print(f&#34;Llama2: {response}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üêû ‰ª£Á†ÅÊ®°Âûã&lt;/h2&gt; &#xA;&lt;p&gt;MetaÂÆòÊñπÂú®2023Âπ¥8Êúà24Êó•ÂèëÂ∏É‰∫ÜCode LlamaÔºåÂü∫‰∫é‰ª£Á†ÅÊï∞ÊçÆÂØπLlama2ËøõË°å‰∫ÜÂæÆË∞ÉÔºåÊèê‰æõ‰∏â‰∏™‰∏çÂêåÂäüËÉΩÁöÑÁâàÊú¨ÔºöÂü∫Á°ÄÊ®°ÂûãÔºàCode LlamaÔºâ„ÄÅPython‰∏ìÁî®Ê®°ÂûãÔºàCode Llama - PythonÔºâÂíåÊåá‰ª§Ë∑üÈöèÊ®°ÂûãÔºàCode Llama - InstructÔºâÔºåÂåÖÂê´7B„ÄÅ13B„ÄÅ34B‰∏âÁßç‰∏çÂêåÂèÇÊï∞ËßÑÊ®°„ÄÇ‰∏çÂêåÊ®°ÂûãËÉΩÂäõÂå∫Âà´Â¶Ç‰∏ãË°®ÊâÄÁ§∫Ôºö&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Ê®°ÂûãÁ±ªÂà´&lt;/th&gt; &#xA;   &lt;th&gt;Ê®°ÂûãÂêçÁß∞&lt;/th&gt; &#xA;   &lt;th&gt;‰ª£Á†ÅÁª≠ÂÜô&lt;/th&gt; &#xA;   &lt;th&gt;‰ª£Á†ÅÂ°´ÂÖÖ&lt;/th&gt; &#xA;   &lt;th&gt;Êåá‰ª§ÁºñÁ®ã&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Code Llama&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-7b&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-13b&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-34b&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Code Llama - Python&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-7b-Python&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-13b-Python&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-34b-Python&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Code Llama - Instruct&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-7b-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-13b-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CodeLlama-34b-Instruct&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚ùå&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Êàë‰ª¨Êèê‰æõ‰∫ÜCode LlamaÁöÑ&lt;a href=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/#-%E5%9B%BD%E5%86%85Llama2%E6%9C%80%E6%96%B0%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80&#34;&gt;ÂõΩÂÜÖ‰∏ãËΩΩÈìæÊé•&lt;/a&gt;‰ª•ÂèäÂú®Á∫ø‰ΩìÈ™åÂú∞ÂùÄ&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;ÔºåÂÖ≥‰∫éCode LlamaÁöÑËØ¶ÁªÜ‰ø°ÊÅØÂèØ‰ª•ÂèÇËÄÉÂÆòÊñπGithub‰ªìÂ∫ì&lt;a href=&#34;https://github.com/facebookresearch/codellama&#34;&gt;codellama&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h2&gt;üìñ Â≠¶‰π†ËµÑÊñô&lt;/h2&gt; &#xA;&lt;h3&gt;MetaÂÆòÊñπÂØπ‰∫é&lt;a href=&#34;https://ai.meta.com/llama&#34;&gt;Llama2&lt;/a&gt;ÁöÑ‰ªãÁªç&lt;/h3&gt; &#xA;&lt;p&gt;Ëá™‰ªéMetaÂÖ¨Âè∏ÂèëÂ∏ÉÁ¨¨‰∏Ä‰ª£LLaMAÊ®°Âûã‰ª•Êù•ÔºåÁæäÈ©ºÊ®°ÂûãÂÆ∂ÊóèÁπÅËç£ÂèëÂ±ï„ÄÇËøëÊúüMetaÂèëÂ∏É‰∫ÜLlama2ÁâàÊú¨ÔºåÂºÄÊ∫êÂèØÂïÜÁî®ÔºåÂú®Ê®°ÂûãÂíåÊïàÊûú‰∏äÊúâ‰∫ÜÈáçÂ§ßÊõ¥Êñ∞„ÄÇLlama2ÊÄªÂÖ±ÂÖ¨Â∏É‰∫Ü7B„ÄÅ13BÂíå70B‰∏âÁßçÂèÇÊï∞Â§ßÂ∞èÁöÑÊ®°Âûã„ÄÇÁõ∏ÊØî‰∫éLLaMAÔºåLlama2ÁöÑËÆ≠ÁªÉÊï∞ÊçÆËææÂà∞‰∫Ü2‰∏á‰∫øtokenÔºå‰∏ä‰∏ãÊñáÈïøÂ∫¶‰πüÁî±‰πãÂâçÁöÑ2048ÂçáÁ∫ßÂà∞4096ÔºåÂèØ‰ª•ÁêÜËß£ÂíåÁîüÊàêÊõ¥ÈïøÁöÑÊñáÊú¨„ÄÇLlama2 ChatÊ®°ÂûãÂü∫‰∫é100‰∏á‰∫∫Á±ªÊ†áËÆ∞Êï∞ÊçÆÂæÆË∞ÉÂæóÂà∞ÔºåÂú®Ëã±ÊñáÂØπËØù‰∏äËææÂà∞‰∫ÜÊé•ËøëChatGPTÁöÑÊïàÊûú„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;LlamaÁõ∏ÂÖ≥ËÆ∫Êñá&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.13971&#34;&gt;LLaMA: Open and Efficient Foundation Language Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2307.09288&#34;&gt;Llama 2: Open Foundation and Fine-Tuned Chat Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/&#34;&gt;Code Llama: Open Foundation Models for Code&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Llama2ÁöÑËØÑÊµãÁªìÊûú&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/llama_eval.jpeg&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;üéâ Ëá¥Ë∞¢&lt;/h2&gt; &#xA;&lt;p&gt;ÊÑüË∞¢ÂéüÂ≠êÂõûÂ£∞&lt;a href=&#34;https://github.com/AtomEcho&#34;&gt;AtomEcho&lt;/a&gt;Âõ¢ÈòüÁöÑÊäÄÊúØÂíåËµÑÊ∫êÊîØÊåÅÔºÅ&lt;/p&gt; &#xA;&lt;p&gt;ÊÑüË∞¢ËäØÊ†º&lt;a href=&#34;https://coremesh.net&#34;&gt;Coremesh&lt;/a&gt;Âõ¢ÈòüÁöÑÊäÄÊúØÂíåËµÑÊ∫êÊîØÊåÅÔºÅ&lt;/p&gt; &#xA;&lt;p&gt;ÊÑüË∞¢ @xzsGenius ÂØπLlama2‰∏≠ÊñáÁ§æÂå∫ÁöÑË¥°ÁåÆÔºÅ&lt;/p&gt; &#xA;&lt;p&gt;ÊÑüË∞¢ @Z PotentialsÁ§æÂå∫ÂØπLlama2‰∏≠ÊñáÁ§æÂå∫ÁöÑÊîØÊåÅÔºÅ&lt;/p&gt; &#xA;&lt;h2&gt;ü§î ÈóÆÈ¢òÂèçÈ¶à&lt;/h2&gt; &#xA;&lt;p&gt;Â¶ÇÊúâÈóÆÈ¢òÔºåËØ∑Âú®GitHub Issue‰∏≠Êèê‰∫§ÔºåÂú®Êèê‰∫§ÈóÆÈ¢ò‰πãÂâçÔºåËØ∑ÂÖàÊü•ÈòÖ‰ª•ÂæÄÁöÑissueÊòØÂê¶ËÉΩËß£ÂÜ≥‰Ω†ÁöÑÈóÆÈ¢ò„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Á§ºË≤åÂú∞ÊèêÂá∫ÈóÆÈ¢òÔºåÊûÑÂª∫ÂíåË∞êÁöÑËÆ®ËÆ∫Á§æÂå∫„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Âä†ÂÖ•&lt;a href=&#34;https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink&#34;&gt;È£û‰π¶Áü•ËØÜÂ∫ì&lt;/a&gt;Ôºå‰∏ÄËµ∑ÂÖ±Âª∫Á§æÂå∫ÊñáÊ°£„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Âä†ÂÖ•ÂæÆ‰ø°Áæ§ËÆ®ËÆ∫üòçüòç&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LlamaFamily/Llama-Chinese/main/assets/wechat.jpeg&#34; alt=&#34;Wechat&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://api.star-history.com/svg?repos=LlamaFamily/Llama-Chinese&amp;amp;type=Date&#34; alt=&#34;Wechat&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt;</summary>
  </entry>
</feed>