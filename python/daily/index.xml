<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-24T01:42:57Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>michaelshumshum/r-placer</title>
    <updated>2023-07-24T01:42:57Z</updated>
    <id>tag:github.com,2023-07-24:/michaelshumshum/r-placer</id>
    <link href="https://github.com/michaelshumshum/r-placer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;bot for 2022 r/place&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;r-placer&lt;/h1&gt; &#xA;&lt;p&gt;bot for &lt;del&gt;2022&lt;/del&gt; 2023 r/place&lt;/p&gt; &#xA;&lt;p&gt;unarchived if anybody wants to help work on this. i am not sure if it works. my main developer account was banned, so you must provide your own API key.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;del&gt;place has ended.&lt;/del&gt; thanks to everyone who participated and to those who used my bot!&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/michaelshumshum/r-placer/master/place.jpg&#34; alt=&#34;place.png&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;what&lt;/h2&gt; &#xA;&lt;p&gt;(maybe) working r/place bot that takes an input image, location, and account login to draw to the r/place canvas. relatively neat compared to &lt;a href=&#34;https://github.com/rdeepak2002/reddit-place-script-2022&#34;&gt;this one&lt;/a&gt; as coding style is more OOP. though, could still need some touching up.&lt;/p&gt; &#xA;&lt;p&gt;supports multiple accounts. automatically determines which canvas to add to. just use coordinates.&lt;/p&gt; &#xA;&lt;h2&gt;contributing&lt;/h2&gt; &#xA;&lt;p&gt;please&lt;/p&gt; &#xA;&lt;h2&gt;requirements&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;setup&lt;/h2&gt; &#xA;&lt;p&gt;create a new file called &lt;code&gt;accounts.csv&lt;/code&gt; which contains the data for the accounts you want to use. each row should formatted like &lt;code&gt;email username password&lt;/code&gt;, where spaces are delimiters. email is optional, so you can put filler information there if needed.&lt;/p&gt; &#xA;&lt;p&gt;adjust configuration in &lt;code&gt;config.json&lt;/code&gt;. i have included the information for my apps and the developer account for it. feel free to use it as well or change it to your own apps. the apps are necessary for the accounts to receive their access token. more apps = more accounts. you must also adjust the &lt;code&gt;main-dev-account&lt;/code&gt; to the information of the account you used to create the app.&lt;/p&gt; &#xA;&lt;h3&gt;tor&lt;/h3&gt; &#xA;&lt;p&gt;included is a &lt;code&gt;torrc&lt;/code&gt; file that is required. you must also have the &lt;code&gt;tor&lt;/code&gt; binary installed on your machine. on linux and mac, you can use homebrew: &lt;code&gt;brew install tor&lt;/code&gt;. once installed, go to &lt;code&gt;/usr/local/etc/tor/&lt;/code&gt; and put the &lt;code&gt;torrc&lt;/code&gt; file in there. making a sym-link is also valid. finally, run &lt;code&gt;brew services start tor&lt;/code&gt;. windows installation is more complicated and i don&#39;t have a windows machine to try it out.&lt;/p&gt; &#xA;&lt;h2&gt;usage&lt;/h2&gt; &#xA;&lt;p&gt;run &lt;code&gt;python main.py &amp;lt;image path&amp;gt; &amp;lt;x-coord&amp;gt; &amp;lt;y-coord&amp;gt;&lt;/code&gt;, where the image path is the image you want to draw, and x-coord/y-coord represent the location you want the image to be drawn.&lt;/p&gt; &#xA;&lt;h3&gt;account maker&lt;/h3&gt; &#xA;&lt;p&gt;simple selenium script that automatically creates a reddit account. 90% can solve the captcha, though some human intervention might be needed occasionally. sends account data to a specified google sheet using gspread. makes one account at a time as reddit limits you to 1 account per ip every 10 minutes. to make more, use a vpn for every iteration. my focus wasn&#39;t on the account maker that much, so it isn&#39;t as refined. if you want to adjust anything, look into the &lt;code&gt;sheets.py&lt;/code&gt; and &lt;code&gt;account_maker.py&lt;/code&gt; files. for anybody else, refer to &lt;a href=&#34;https://docs.gspread.org/en/latest/&#34;&gt;the gspread page&lt;/a&gt; to see how to setup gspread. there is a paramter in the config that identifies the email for the accounts.&lt;/p&gt; &#xA;&lt;h2&gt;notes&lt;/h2&gt; &#xA;&lt;p&gt;make sure to verify all the emails for all your accounts and interact with it a little. for me, i join a random subreddit, which has really made the accounts immune so far. that seems to be primary factor in getting accounts banned. though, still not guaranteed it doesn&#39;t get banned.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>tinygrad/tinygrad</title>
    <updated>2023-07-24T01:42:57Z</updated>
    <id>tag:github.com,2023-07-24:/tinygrad/tinygrad</id>
    <link href="https://github.com/tinygrad/tinygrad" rel="alternate"></link>
    <summary type="html">&lt;p&gt;You like pytorch? You like micrograd? You love tinygrad! ❤️&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://tinygrad.org&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/logo.png&#34; alt=&#34;logo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;tinygrad: For something between &lt;a href=&#34;https://github.com/pytorch/pytorch&#34;&gt;PyTorch&lt;/a&gt; and &lt;a href=&#34;https://github.com/karpathy/micrograd&#34;&gt;karpathy/micrograd&lt;/a&gt;. Maintained by &lt;a href=&#34;https://tinygrad.org&#34;&gt;tiny corp&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;h3&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/tinygrad/tinygrad&#34;&gt;Homepage&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs&#34;&gt;Documentation&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/examples&#34;&gt;Examples&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/showcase.md&#34;&gt;Showcase&lt;/a&gt; | &lt;a href=&#34;https://discord.gg/ZjZadyC7PK&#34;&gt;Discord&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/tinygrad/tinygrad/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/tinygrad/tinygrad&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/tinygrad/tinygrad/actions/workflows/test.yml&#34;&gt;&lt;img src=&#34;https://github.com/tinygrad/tinygrad/actions/workflows/test.yml/badge.svg?sanitize=true&#34; alt=&#34;Unit Tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/ZjZadyC7PK&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1068976834382925865&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/tinygrad/tinygrad&#34;&gt;&lt;img src=&#34;https://img.shields.io/tokei/lines/github/tinygrad/tinygrad&#34; alt=&#34;Lines of code&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;This may not be the best deep learning framework, but it is a deep learning framework.&lt;/p&gt; &#xA;&lt;p&gt;Due to its extreme simplicity, it aims to be the easiest framework to add new accelerators to, with support for both inference and training. If XLA is CISC, tinygrad is RISC.&lt;/p&gt; &#xA;&lt;p&gt;tinygrad is still alpha software, but we &lt;a href=&#34;https://geohot.github.io/blog/jekyll/update/2023/05/24/the-tiny-corp-raised-5M.html&#34;&gt;raised some money&lt;/a&gt; to make it good. Someday, we will tape out chips.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;h3&gt;LLaMA and Stable Diffusion&lt;/h3&gt; &#xA;&lt;p&gt;tinygrad can run &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/showcase.md#llama&#34;&gt;LLaMA&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/showcase.md#stable-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h3&gt;Laziness&lt;/h3&gt; &#xA;&lt;p&gt;Try a matmul. See how, despite the style, it is fused into one kernel with the power of laziness.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;DEBUG=3 python3 -c &#34;from tinygrad.tensor import Tensor;&#xA;N = 1024; a, b = Tensor.rand(N, N), Tensor.rand(N, N);&#xA;c = (a.reshape(N, 1, N) * b.permute(1,0).reshape(1, N, N)).sum(axis=2);&#xA;print((c.numpy() - (a.numpy() @ b.numpy())).mean())&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And we can change &lt;code&gt;DEBUG&lt;/code&gt; to &lt;code&gt;4&lt;/code&gt; to see the generated code.&lt;/p&gt; &#xA;&lt;h3&gt;Neural networks&lt;/h3&gt; &#xA;&lt;p&gt;As it turns out, 90% of what you need for neural networks are a decent autograd/tensor library. Throw in an optimizer, a data loader, and some compute, and you have all you need.&lt;/p&gt; &#xA;&lt;h4&gt;Neural network example (from test/models/test_mnist.py)&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from tinygrad.tensor import Tensor&#xA;import tinygrad.nn.optim as optim&#xA;&#xA;class TinyBobNet:&#xA;  def __init__(self):&#xA;    self.l1 = Tensor.uniform(784, 128)&#xA;    self.l2 = Tensor.uniform(128, 10)&#xA;&#xA;  def forward(self, x):&#xA;    return x.dot(self.l1).relu().dot(self.l2).log_softmax()&#xA;&#xA;model = TinyBobNet()&#xA;optim = optim.SGD([model.l1, model.l2], lr=0.001)&#xA;&#xA;# ... complete data loader here&#xA;&#xA;out = model.forward(x)&#xA;loss = out.mul(y).mean()&#xA;optim.zero_grad()&#xA;loss.backward()&#xA;optim.step()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Accelerators&lt;/h2&gt; &#xA;&lt;p&gt;tinygrad already supports numerous accelerators, including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; CPU&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; GPU (OpenCL)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; C Code (Clang)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; LLVM&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; METAL&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; CUDA&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Triton&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; PyTorch&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;And it is easy to add more! Your accelerator of choice only needs to support a total of 26 (optionally 27) low level ops. More information can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/adding_new_accelerators.md&#34;&gt;documentation for adding new accelerators&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;The current recommended way to install tinygrad is from source.&lt;/p&gt; &#xA;&lt;h3&gt;From source&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/tinygrad/tinygrad.git&#xA;cd tinygrad&#xA;python3 -m pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Don&#39;t forget the &lt;code&gt;.&lt;/code&gt; at the end!&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Documentation along with a quick start guide can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs&#34;&gt;docs/&lt;/a&gt; directory.&lt;/p&gt; &#xA;&lt;h3&gt;Quick example comparing to PyTorch&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from tinygrad.tensor import Tensor&#xA;&#xA;x = Tensor.eye(3, requires_grad=True)&#xA;y = Tensor([[2.0,0,-2.0]], requires_grad=True)&#xA;z = y.matmul(x).sum()&#xA;z.backward()&#xA;&#xA;print(x.grad.numpy())  # dz/dx&#xA;print(y.grad.numpy())  # dz/dy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The same thing but in PyTorch:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import torch&#xA;&#xA;x = torch.eye(3, requires_grad=True)&#xA;y = torch.tensor([[2.0,0,-2.0]], requires_grad=True)&#xA;z = y.matmul(x).sum()&#xA;z.backward()&#xA;&#xA;print(x.grad.numpy())  # dz/dx&#xA;print(y.grad.numpy())  # dz/dy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;There has been a lot of interest in tinygrad lately. Here are some basic guidelines for contributing:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Bug fixes are the best and always welcome! Like &lt;a href=&#34;https://github.com/tinygrad/tinygrad/pull/421/files&#34;&gt;this one&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;If you don&#39;t understand the code you are changing, don&#39;t change it!&lt;/li&gt; &#xA; &lt;li&gt;All code golf PRs will be closed, but &lt;a href=&#34;https://github.com/tinygrad/tinygrad/pull/372/files&#34;&gt;conceptual cleanups&lt;/a&gt; are great.&lt;/li&gt; &#xA; &lt;li&gt;Features are welcome. Though if you are adding a feature, you need to include tests.&lt;/li&gt; &#xA; &lt;li&gt;Improving test coverage is great, with reliable non-brittle tests.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Additional guidelines can be found in &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Running tests&lt;/h3&gt; &#xA;&lt;p&gt;For more examples on how to run the full test suite please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/tinygrad/tinygrad/master/.github/workflows/test.yml&#34;&gt;CI workflow&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Some examples:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python3 -m pip install -e &#39;.[testing]&#39;&#xA;python3 -m pytest&#xA;python3 -m pytest -v -k TestTrain&#xA;python3 ./test/models/test_train.py TestTrain.test_efficientnet&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>michael-wzhu/Chinese-LlaMA2</title>
    <updated>2023-07-24T01:42:57Z</updated>
    <id>tag:github.com,2023-07-24:/michael-wzhu/Chinese-LlaMA2</id>
    <link href="https://github.com/michael-wzhu/Chinese-LlaMA2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Repo for adapting Meta LlaMA2 in Chinese! META最新发布的LlaMA2的汉化版！ （完全开源可商用）&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Chinese-LlaMA2&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/michael-wzhu/Chinese-LlaMA2/main/assets/chinese-llama2-banner.png&#34; width=&#34;600&#34;&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img alt=&#34;GitHub&#34; src=&#34;https://img.shields.io/github/license/ymcui/Chinese-LLaMA-Alpaca.svg?color=blue&amp;amp;style=flat-square&#34;&gt; &lt;img alt=&#34;GitHub top language&#34; src=&#34;https://img.shields.io/github/languages/top/ymcui/Chinese-LLaMA-Alpaca&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;就在不久前，Meta最新开源了Llama 2模型，完全可商用，看来Meta势必要与OpenAI (ClosedAI) 硬刚到底。虽然Llama 2对原版的LlaMA模型做了升级，但是其仍然对中文没有太好的支持，需要在中文上做定制化。所以我们决定在次开展Llama 2的中文汉化工作：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;⏳&lt;a href=&#34;https://huggingface.co/michaelwzhu/Chinese-LlaMA2-7B&#34;&gt;Chinese-LlaMA2&lt;/a&gt;: 对Llama 2进行中文预训练； &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;第一步：先在42G中文预料上进行训练；后续将会加大训练规模&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;⏳&lt;a href=&#34;https://huggingface.co/michaelwzhu/Chinese-LlaMA2-7B-chat&#34;&gt;Chinese-LlaMA2-chat&lt;/a&gt;: 对&lt;a href=&#34;https://huggingface.co/michaelwzhu/Chinese-LlaMA2-7B&#34;&gt;Chinese-LlaMA2&lt;/a&gt;进行指令微调和多轮对话微调，以适应各种应用场景和多轮对话交互。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;同时我们也考虑更为快速的中文适配方案：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;⏳Chinese-LlaMA2-sft-v0: 采用现有的开源中文指令微调或者是对话数据，对LlaMA-2进行直接微调 (将于近期开源)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;注意，为了遵循相应的许可，我们将不会发布完整的模型权重，只发布LoRA权重，其与Meta的LlaMA2权重合并即可形成Chinese-LlaMA2模型。&lt;/p&gt; &#xA;&lt;p&gt;同时，我们将会围绕Chinese-LlaMA2打造各种垂直领域模型：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;⏳&lt;a href=&#34;https://huggingface.co/michaelwzhu/Chinese-LlaMA2-7B-chatmed&#34;&gt;Chinese-LlaMA2-chatmed&lt;/a&gt;: Chinese-LlaMA2医学领域大模型，支持多轮在线问诊；&lt;/li&gt; &#xA; &lt;li&gt;⏳&lt;a href=&#34;https://huggingface.co/michaelwzhu/Chinese-LlaMA2-7B-tcm&#34;&gt;Chinese-LlaMA2-tcm&lt;/a&gt;: Chinese-LlaMA2中医药大模型，专注于中医药细分领域，赋能中医药传承&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;更新&lt;/h2&gt; &#xA;&lt;p&gt;2023/07/20 采用开源中文指令数据对LlaMA-2-7B进行微调(不扩充词表/扩充词表); 采用vllm对模型进行serving&lt;/p&gt; &#xA;&lt;p&gt;2023/07/19 启动LlaMA-2中文大模型；&lt;/p&gt; &#xA;&lt;h2&gt;快速上手&lt;/h2&gt; &#xA;&lt;h3&gt;获得llama-2权重&lt;/h3&gt; &#xA;&lt;p&gt;现在LlaMA-2权重需要在Meta指定的官方网站申请，具体说明见&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-70b-hf&#34;&gt;LlaMA-的hf页面&lt;/a&gt;。当你没有通过申请时，在这个网页上看到的是一个申请表，你需要根据他的说明进行申请，申请通过后就可以看到权重文件了。&lt;/p&gt; &#xA;&lt;p&gt;下载模型权重，运行：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;src/further_ft/download_checkpoints.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;指令微调&lt;/h3&gt; &#xA;&lt;p&gt;对LlaMA-2进行指令微调(不扩充词表/扩充词表)，也就是现在常见的SFT，见&lt;a href=&#34;https://raw.githubusercontent.com/michael-wzhu/Chinese-LlaMA2/main/src/sft/SFT-README.md&#34;&gt;SFT-README.md&lt;/a&gt;;&lt;/p&gt; &#xA;&lt;h3&gt;扩充词表和扩展embedding层&lt;/h3&gt; &#xA;&lt;p&gt;我们现在采用的方案是：使用&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca&#34;&gt;Chinese-LLaMA&lt;/a&gt;的词表，该词表是对llama原始词表的扩充，将词汇量从32000扩展到49953大小。同时LlaMA-2模型会进行embedding层的resize，即采用随机初始化的参数扩展embedding层和lm_head层。&lt;/p&gt; &#xA;&lt;p&gt;在一些我们关注的垂直领域，我们后续也会自己训一个sentencepiece模型来更新llama-2的词表。&lt;/p&gt; &#xA;&lt;h3&gt;继续预训练&lt;/h3&gt; &#xA;&lt;p&gt;由于扩展词表后，LlaMA-2的embedding层和lm_head层会有随机初始化的参数，所以我们需要采用大规模的预训练学习中文语料的知识。继续预训练运行以下命令(数据，模型的路径，卡数等需要自行配置)：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=&#34;2,3&#34; ./src/further_ft/run_train.sh&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;评测交流与技术交流&lt;/h2&gt; &#xA;&lt;p&gt;PromptCBLUE与大模型技术交流微信交流群二维码（截止至7月23日有效）：&lt;/p&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/michael-wzhu/Chinese-LlaMA2/main/assets/wechat_qrcode.jpg&#34; width=&#34;300&#34;&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;h2&gt;团队介绍&lt;/h2&gt; &#xA;&lt;p&gt;本项目由华东师范大学计算机科学与技术学院智能知识管理与服务团队完成，团队指导老师为王晓玲教授。&lt;/p&gt;</summary>
  </entry>
</feed>