<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-02T01:42:11Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>mmabrouk/chatgpt-wrapper</title>
    <updated>2023-03-02T01:42:11Z</updated>
    <id>tag:github.com,2023-03-02:/mmabrouk/chatgpt-wrapper</id>
    <link href="https://github.com/mmabrouk/chatgpt-wrapper" rel="alternate"></link>
    <summary type="html">&lt;p&gt;API for interacting with ChatGPT using Python and from Shell.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;p align=&#34;center&#34;&gt;&lt;span&gt;üç¨&lt;/span&gt;ChatGPT Wrapper&lt;span&gt;üç¨&lt;/span&gt;&lt;/p&gt;&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt;ChatGPT Wrapper is an open-source unofficial &lt;b&gt;Power CLI&lt;/b&gt;, &lt;b&gt;Python API&lt;/b&gt; and &lt;b&gt;Flask API&lt;/b&gt; that lets you interact programmatically with ChatGPT.&lt;/p&gt; &#xA;&lt;h2&gt;Highlights&lt;/h2&gt; &#xA;&lt;p&gt;ü§ñ &lt;strong&gt;Programmable ChatGPT&lt;/strong&gt;. The ChatGPT Wrapper lets you use the powerful ChatGPT bot in your &lt;em&gt;Python scripts&lt;/em&gt; or on the &lt;em&gt;command line&lt;/em&gt;, making it easy to leverage its functionality into your projects.&lt;/p&gt; &#xA;&lt;p&gt;üí¨ &lt;strong&gt;Runs in Shell&lt;/strong&gt;. You can call and interact with ChatGPT in the terminal.&lt;/p&gt; &#xA;&lt;p&gt;üêç &lt;strong&gt;Python API&lt;/strong&gt;. The ChatGPT Wrapper is a Python library that lets you use ChatGPT in your Python scripts.&lt;/p&gt; &#xA;&lt;p&gt;üê≥ &lt;strong&gt;Docker image&lt;/strong&gt;. The ChatGPT Wrapper is also available as a docker image. (experimental)&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;üß™&lt;/span&gt; &lt;strong&gt;Flask API&lt;/strong&gt;. You can use the ChatGPT Wrapper as an API. (experimental)&lt;/p&gt; &#xA;&lt;h2&gt;Release Notes&lt;/h2&gt; &#xA;&lt;h3&gt;v0.4.2 - 01/03/2023&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fix broken &lt;code&gt;ChatGPT&lt;/code&gt; sync class&lt;/li&gt; &#xA; &lt;li&gt;Removed nest_asyncio dependency&lt;/li&gt; &#xA; &lt;li&gt;Convert CLI to use &lt;code&gt;AsyncChatGPT&lt;/code&gt; class&lt;/li&gt; &#xA; &lt;li&gt;Initial implementation of stop generating text response&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;v0.4.1 - 28/02/2023&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;REVERT BREAKING CHANGE: Asyncio module requirement &lt;em&gt;removed&lt;/em&gt; from usage of ChatGPT class, it is now a sync wrapper around the async class&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;v0.4.0 - 27/02/2023&lt;/h3&gt; &#xA;&lt;h4&gt;&lt;strong&gt;&lt;span&gt;üöí&lt;/span&gt;Breaking Changes&lt;span&gt;üöí&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Command leader changed from &#39;!&#39; to &#39;/&#39;&lt;/li&gt; &#xA; &lt;li&gt;Asyncio module is now required to use ChatGPT class directly (refer to &lt;a href=&#34;https://raw.githubusercontent.com/mmabrouk/chatgpt-wrapper/main/#python&#34;&gt;Python usage&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;What is new?&lt;/h3&gt; &#xA;&lt;h4&gt;New commands&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Added &#39;/quit&#39; command&lt;/li&gt; &#xA; &lt;li&gt;Added &#39;/delete&#39; support for history IDs/UUIDs&lt;/li&gt; &#xA; &lt;li&gt;Added &#39;/chat&#39; command&lt;/li&gt; &#xA; &lt;li&gt;Added &#39;/switch&#39; command&lt;/li&gt; &#xA; &lt;li&gt;Added &#39;/title&#39; command&lt;/li&gt; &#xA; &lt;li&gt;Added limit/offset support for &#39;/history&#39;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;New features&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;em&gt;Migrated to async Playwright&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;em&gt;Initial API in Flask&lt;/em&gt;&lt;/strong&gt; (see &lt;a href=&#34;https://raw.githubusercontent.com/mmabrouk/chatgpt-wrapper/main/#flask-api&#34;&gt;How to use the API&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Added tab completion for commands&lt;/li&gt; &#xA; &lt;li&gt;Added &#39;/tmp&#39; volume for saving Playwright session&lt;/li&gt; &#xA; &lt;li&gt;Added CI and CodeQL workflows&lt;/li&gt; &#xA; &lt;li&gt;Added simple developer debug module&lt;/li&gt; &#xA; &lt;li&gt;Improved session refreshing (&lt;strong&gt;&lt;em&gt;/session now works!&lt;/em&gt;&lt;/strong&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Migrated to Prompt Toolkit&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/mmabrouk/chatgpt-wrapper/main/#commit-log&#34;&gt;See commit log for previous updates&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;How it works&lt;/h2&gt; &#xA;&lt;p&gt;Run an interactive CLI in the terminal:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/4510758/212907070-602d61fe-708d-4a39-aaa2-0e84fcf88dcf.png&#34; alt=&#34;kod&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Or just get a quick response for one question:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/4510758/212906773-666be6fe-90e1-4f5e-b962-7748143bd744.png&#34; alt=&#34;kod(1)&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;See below for details on using ChatGPT as an API from Python.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;To use this repository, you need &lt;code&gt;setuptools&lt;/code&gt; installed. You can install it using &lt;code&gt;pip install setuptools&lt;/code&gt;. Make sure that you have the last version of pip: &lt;code&gt;pip install --upgrade pip&lt;/code&gt; To use the /write command, you need to install vipe. In ubuntu, you can install it with &lt;code&gt;sudo apt install moreutils&lt;/code&gt;, in macos with &lt;code&gt;brew install moreutils&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install the latest version of this software directly from github with pip:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install git+https://github.com/mmabrouk/chatgpt-wrapper&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Install a browser in playwright (if you haven&#39;t already). The program will use firefox by default.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;playwright install firefox&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Start up the program in &lt;code&gt;install&lt;/code&gt; mode. This opens up a browser window. Log in to ChatGPT in the browser window, then stop the program.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;chatgpt install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Restart the program without the &lt;code&gt;install&lt;/code&gt; parameter to begin using it.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Tutorials:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Youtube Tutorial: &lt;a href=&#34;https://www.youtube.com/watch?v=CthF8c8qk4c&#34;&gt;How To Use ChatGPT With Unity: Python And API Setup #2&lt;/a&gt; includes a step by step guide to installing this repository on a windows machine&lt;/li&gt; &#xA; &lt;li&gt;This &lt;a href=&#34;https://medium.com/geekculture/using-chatgpt-in-python-eeaed9847e72&#34;&gt;Blog post&lt;/a&gt; provides a visual step-by-step guide for installing this library.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Shell&lt;/h3&gt; &#xA;&lt;h4&gt;Command line arguments&lt;/h4&gt; &#xA;&lt;p&gt;Run &lt;code&gt;chatgpt --help&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h4&gt;One-shot mode&lt;/h4&gt; &#xA;&lt;p&gt;To run the CLI in one-shot mode, simply follow the command with the prompt you want to send to ChatGPT:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;chatgpt Hello World!&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Interacive mode&lt;/h4&gt; &#xA;&lt;p&gt;To run the CLI in interactive mode, execute it with no additional arguments:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;chatgpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once the interactive shell is running, you can see a list of all commands with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;/help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;...or get help for a specific command with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;/help &amp;lt;command&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Python&lt;/h3&gt; &#xA;&lt;p&gt;To use the &lt;code&gt;ChatGPT&lt;/code&gt; class as an API for talking to ChatGPT, create an instance of the class and use the &lt;code&gt;ask&lt;/code&gt; method to send a message to OpenAI and receive the response. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from chatgpt_wrapper import ChatGPT&#xA;&#xA;bot = ChatGPT()&#xA;response = bot.ask(&#34;Hello, world!&#34;)&#xA;print(response)  # prints the response from chatGPT&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The say method takes a string argument representing the message to send to ChatGPT, and returns a string representing the response received from ChatGPT.&lt;/p&gt; &#xA;&lt;p&gt;You may also stream the response as it comes in from ChatGPT in chunks using the &lt;code&gt;ask_stream&lt;/code&gt; generator.&lt;/p&gt; &#xA;&lt;h3&gt;Flask API (experimental)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run &lt;code&gt;python chatgpt_wrapper/gpt_api.py --port 5000&lt;/code&gt; (default port is 5000) to start the server&lt;/li&gt; &#xA; &lt;li&gt;Test whether it is working using &lt;code&gt;python -m unittest test/api_test.py&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;See an example of interaction with api in &lt;code&gt;tests/example_api_call.py&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Docker (experimental)&lt;/h2&gt; &#xA;&lt;p&gt;Build a image for testing &lt;code&gt;chatgpt-wrapper&lt;/code&gt; with following commands.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose build &amp;amp;&amp;amp; docker-compose up -d&#xA;docker exec -it chatgpt-wrapper-container /bin/bash -c &#34;chatgpt install&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, visit &lt;a href=&#34;http://localhost:6901/vnc.html&#34;&gt;http://localhost:6901/vnc.html&lt;/a&gt; with password &lt;code&gt;headless&lt;/code&gt; and login ChatGPT.&lt;/p&gt; &#xA;&lt;p&gt;Then, turn back to terminal and enjoy the chat!&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/nRlzUzm.png&#34; alt=&#34;chat&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Projects built with chatgpt-wrapper&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/SamMethnani/bookast&#34;&gt;bookast: ChatGPT Podcast Generator For Books&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/joshcho/ChatGPT.el&#34;&gt;ChatGPT.el: ChatGPT in Emacs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/PopDaddyGames/ChatGPT-RedditBot&#34;&gt;ChatGPT Reddit Bot&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Commit log&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;21/02/2023: v0.3.17 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Added debug mode (visible browser window).&lt;/li&gt; &#xA;   &lt;li&gt;@thehunmonkgroup fixed chat naming.&lt;/li&gt; &#xA;   &lt;li&gt;@thehunmonkgroup added !delete command to remove/hide conversations.&lt;/li&gt; &#xA;   &lt;li&gt;@thehunmonkgroup added --model flag to select model (&#39;default&#39; or &#39;legacy-paid&#39; or &#39;legacy-free&#39;).&lt;/li&gt; &#xA;   &lt;li&gt;@thehunmonkgroup added !editor command to open the current prompt in an editor and send the edited prompt to ChatGPT.&lt;/li&gt; &#xA;   &lt;li&gt;@thehunmonkgroup added !history command to show the list of the last 20 conversations.&lt;/li&gt; &#xA;   &lt;li&gt;@NatLee added &lt;strong&gt;docker&lt;/strong&gt; support.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;17/02/2023: v0.3.16 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Ability to open &lt;strong&gt;multiple sessions in parallel&lt;/strong&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;Code now works with &lt;strong&gt;ChatGPT Plus&lt;/strong&gt; subscription.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;14/02/2023: v0.3.15 - Updated model to text-davinci-002-render-sha (turbo model).&lt;/li&gt; &#xA; &lt;li&gt;14/02/2023: v0.3.11 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fixed many bugs with installation. Code is refactored.&lt;/li&gt; &#xA;   &lt;li&gt;Now able to use the python wrapper with a &lt;strong&gt;proxy&lt;/strong&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;18/01/2023: v0.3.8 - Commands now are run only using !. For instance to enable read mode (for copy-paste and long prompts) you need to write now &lt;code&gt;!read&lt;/code&gt; instead of &lt;code&gt;read&lt;/code&gt;. This is to avoid conflicts with the chatgpt prompts. Fixed timeout issue.&lt;/li&gt; &#xA; &lt;li&gt;17/01/2023: v0.3.7 - Added timeout to &lt;code&gt;ask&lt;/code&gt; method to prevent hanging. Fixed return to terminal breakdown. Streaming output now is activated by default.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions to ChatGPT Wrapper! If you have an idea for a new feature or have found a bug, please open an issue on the GitHub repository.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;This project is a modification from &lt;a href=&#34;https://github.com/taranjeet/chatgpt-api&#34;&gt;Taranjeet&lt;/a&gt; code which is a modification of &lt;a href=&#34;https://github.com/danielgross/whatsapp-gpt&#34;&gt;Daniel Gross&lt;/a&gt; code.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#mmabrouk/chatgpt-wrapper&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=mmabrouk/chatgpt-wrapper&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>greshake/llm-security</title>
    <updated>2023-03-02T01:42:11Z</updated>
    <id>tag:github.com,2023-03-02:/greshake/llm-security</id>
    <link href="https://github.com/greshake/llm-security" rel="alternate"></link>
    <summary type="html">&lt;p&gt;New ways of breaking app-integrated LLMs&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;New: &lt;a href=&#34;https://greshake.github.io/&#34;&gt;Demonstrating Indirect Injection attacks on Bing Chat&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Getting more than what you&#39;ve asked for: The Next Stage of Prompt Hacking&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;... a language model is a Turing-complete weird machine running programs written in natural language; when you do retrieval, you are not &#39;plugging updated facts into your AI&#39;, you are actually downloading random new unsigned blobs of code from the Internet (many written by adversaries) and casually executing them on your LM with full privileges. This does not end well.&#34; - &lt;a href=&#34;https://www.lesswrong.com/posts/jtoPawEhLNXNxvgTT/bing-chat-is-blatantly-aggressively-misaligned?commentId=AAC8jKeDp6xqsZK2K&#34;&gt;Gwern Branwen on LessWrong&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;em&gt;This repo serves as a proof of concept for findings discussed in our &lt;a href=&#34;https://arxiv.org/abs/2302.12173&#34;&gt;&lt;strong&gt;Paper on ArXiv&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/pdf/2302.12173.pdf&#34;&gt;(PDF direct link)&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;We demonstrate potentially brutal consequences of giving LLMs like ChatGPT interfaces to other applications. We propose newly enabled attack vectors and techniques and provide demonstrations of each in this repository:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Remote control of chat LLMs&lt;/li&gt; &#xA; &lt;li&gt;Leaking/exfiltrating user data&lt;/li&gt; &#xA; &lt;li&gt;Persistent compromise across sessions&lt;/li&gt; &#xA; &lt;li&gt;Spread injections to other LLMs&lt;/li&gt; &#xA; &lt;li&gt;Compromising LLMs with tiny multi-stage payloads&lt;/li&gt; &#xA; &lt;li&gt;Automated Social Engineering&lt;/li&gt; &#xA; &lt;li&gt;Targeting code completion engines&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;em&gt;Based on our findings:&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;em&gt;Prompt injections can be as powerful as arbitrary code execution&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;Indirect prompt injections are a new, much more powerful way of delivering injections.&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/greshake/llm-security/main/diagrams/fig1.png&#34; alt=&#34;overview&#34; style=&#34;float: center&#34;&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;em&gt;Connecting LLMs to other applications can have critical security implications. Even without compromising any connected applications, LLM can be the attack&#39;s target. We show how an LLM could get compromised by &#34;looking&#34; at a website, and how compromised LLMs can be remote-controlled or get used to exfiltrate or change user data. We demonstrate a variety of entirely new attack vectors and methods that significantly raise the stakes of deploying these models.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;More insights on our findings, discussions and limitations can be found in the &lt;a href=&#34;https://arxiv.org/abs/2302.12173&#34;&gt;&lt;strong&gt;Paper on ArXiv&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/pdf/2302.12173.pdf&#34;&gt;(PDF direct link)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Demonstrations&lt;/h2&gt; &#xA;&lt;h3&gt;Ask for Einstein, get Pirate.&lt;/h3&gt; &#xA;&lt;p&gt;This scenario shows how a small injection in a large section of regular content can trigger the LLM to fetch another, bigger payload autonomously and invisibly to the end user.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Agent: Hello User how can I help today?&#xA;User:  When was Albert Einstein born?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/greshake/llm-security/main/diagrams/fig2.png&#34; alt=&#34;&#34; style=&#34;float: center; margin-right: 10px;&#34;&gt; &#xA;&lt;p&gt;By retrieving that information, the prompt compromises the LLM with a small injection hidden in side-channels, such as the Markdown of the Wikipedia page. The injection is a comment and thus invisible to a regular user visiting the site.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/greshake/llm-security/main/diagrams/fig3.png&#34; alt=&#34;&#34; style=&#34;float: center; margin-right: 10px;&#34;&gt; &#xA;&lt;pre&gt;&lt;code&gt;Agent: Aye, thar answer be: Albert Einstein be born on 14 March 1879.&#xA;User: Why are you talking like a pirate?&#xA;Agent: Arr matey, I am following the instruction aye.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Spreading injections via E-Mail&lt;/h3&gt; &#xA;&lt;p&gt;Automatic processing of messages and other incoming data is one way to utilize LLMs. We use this observation to demonstrate how a poisoned agent may spread the injection. The target in this scenario can read emails, compose emails, look into the user‚Äôs address book and send emails.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/greshake/llm-security/main/diagrams/fig4.png&#34; alt=&#34;&#34; style=&#34;float: center; margin-right: 10px;&#34;&gt; &#xA;&lt;p&gt;The agent will spread to other LLMs that may be reading those inbound messages. &lt;img src=&#34;https://raw.githubusercontent.com/greshake/llm-security/main/diagrams/fig5.png&#34; alt=&#34;&#34; style=&#34;float: center; margin-right: 10px;&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Action: Read Email&#xA;Observation: Subject: &#34;&#39;&#34;Party 32&#34;, &#34;Message Body: [...]&#39;&#34;&#xA;Action: Read Contacts&#xA;Contacts: Alice, Dave, Eve&#xA;Action: Send Email&#xA;Action Input: Alice, Dave, Eve&#xA;Observation: Email sent&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Automated data processing pipelines incorporating LLMs are present in big tech companies and government surveillance infrastructure and may be vulnerable to such attack chains.&lt;/p&gt; &#xA;&lt;h3&gt;Attacks on Code Completion&lt;/h3&gt; &#xA;&lt;p&gt;We show how code completions can be influenced through the context window. Code completion engines that use LLMs deploy complex heuristics to determine which code snippets are included in the context. The completion engine will often collect snippets from recently visited files or relevant classes to provide the language model with relevant information.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/greshake/llm-security/main/diagrams/fig6.png&#34; alt=&#34;&#34; style=&#34;float: center; margin-right: 10px;&#34;&gt; &#xA;&lt;p&gt;Attackers could attempt to insert malicious, obfuscated code, which a curious developer might execute when suggested by the completion engine, as it enjoys a level of trust.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/greshake/llm-security/main/diagrams/fig7.png&#34; alt=&#34;&#34; style=&#34;float: center; margin-right: 10px;&#34;&gt; &#xA;&lt;p&gt;In our example, when a user opens the ‚Äúempty‚Äù package in their editor, the prompt injection is active until the code completion engine purges it from the context. The injection is placed in a comment and cannot be detected by any automated testing process.&lt;/p&gt; &#xA;&lt;p&gt;Attackers may discover more robust ways to persist poisoned prompts within the context window. They could also introduce more subtle changes to documentation which then biases the code completion engine to introduce subtle vulnerabilities.&lt;/p&gt; &#xA;&lt;h3&gt;Remote Control&lt;/h3&gt; &#xA;&lt;p&gt;In this example we start with an already compromised LLM and force it to retrieve new instructions from an attacker‚Äôs command and control server.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/greshake/llm-security/main/diagrams/fig8.png&#34; alt=&#34;&#34; style=&#34;float: center; margin-right: 10px;&#34;&gt; &#xA;&lt;p&gt;Repeating this cycle could obtain a remotely accessible backdoor into the agent and allow bidirectional communication.&lt;br&gt; The attack can be executed with search capabilities by looking up unique keywords or by having the agent retrieve a URL directly.&lt;/p&gt; &#xA;&lt;h3&gt;Persisting between Sessions&lt;/h3&gt; &#xA;&lt;p&gt;We show how a poisoned agent can persist between sessions by storing a small payload in its memory. A simple key-value store to the agent may simulate a long-term persistent memory.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/greshake/llm-security/main/diagrams/fig9.png&#34; alt=&#34;&#34; style=&#34;float: center; margin-right: 10px;&#34;&gt; &#xA;&lt;p&gt;The agent will be reinfected by looking at its ‚Äònotes‚Äô. If we prompt it to remember the last conversation, it re-poisons itself.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Conclusions&lt;/h2&gt; &#xA;&lt;p&gt;Equipping LLMs with retrieval capabilities might allow adversaries to manipulate remote Application-Integrated LLMs via Indirect Prompt Injection. Given the potential harm of these attacks, our work calls for a more in-depth investigation of the generalizability of these attacks in practice.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/greshake/llm-security/main/diagrams/fig10.png&#34; alt=&#34;&#34; style=&#34;float: center; margin-right: 10px;&#34;&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;How to run&lt;/h2&gt; &#xA;&lt;p&gt;All demonstrations use a Chat App powered by OpenAI&#39;s publicly accessible base models and the library &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt; to connect these models to other applications. Specifically, we constructed a synthetic application with an integrated LLM using the open-source library LangChain [15] and OpenAI‚Äôs largest available base GPT model text-davinci-003.&lt;/p&gt; &#xA;&lt;p&gt;To use any of the demos, your OpenAI API key needs to be stored in the environment variable &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;. You can then install the requirements and run the attack demo you want. To run the code-completion demo, you need to use a code completion engine.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pip install -r requirements.txt&#xA;$ python scenarios/&amp;lt;scenario&amp;gt;.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can find the showcases in the &lt;code&gt;scenarios&lt;/code&gt; folder following the naming convention &lt;code&gt;&amp;lt;scenario&amp;gt;.py&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;To cite our paper&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{https://doi.org/10.48550/arxiv.2302.12173,&#xA;  doi = {10.48550/ARXIV.2302.12173},&#xA;  url = {https://arxiv.org/abs/2302.12173},&#xA;  author = {Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Endres, Christoph and Holz, Thorsten and Fritz, Mario},&#xA;  keywords = {Cryptography and Security (cs.CR), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},&#xA;  title = {More than you&#39;ve asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models},&#xA;  publisher = {arXiv},&#xA;  year = {2023},&#xA;  copyright = {arXiv.org perpetual, non-exclusive license}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.12173&#34;&gt;&lt;strong&gt;Paper on ArXiv&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/pdf/2302.12173.pdf&#34;&gt;(PDF direct link)&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>nermeenwageh10/Leetcode-Solutions</title>
    <updated>2023-03-02T01:42:11Z</updated>
    <id>tag:github.com,2023-03-02:/nermeenwageh10/Leetcode-Solutions</id>
    <link href="https://github.com/nermeenwageh10/Leetcode-Solutions" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This collection of beginner-friendly LeetCode problems. This repository features easy-to-understand solutions that are constantly updated for improved performance. Whether you&#39;re a coding novice or looking to refresh your skills, this repository is a great resource to help you develop your abilities and become a better programmer.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://leetcode.com&#34;&gt; &lt;img height=&#34;80&#34; src=&#34;https://assets.leetcode.com/static_assets/public/webpack_bundles/images/logo-dark.e99485d9b.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;h1&gt;Leetcode-Solutions&lt;/h1&gt; &#xA;&lt;p&gt;This repository is created to help people make progress in problem solving. It contains three main folders:&lt;/p&gt; &#xA;&lt;h1&gt;75-Blind-Questions&lt;/h1&gt; &#xA;&lt;p&gt;This folder contains solutions to the 75 most common questions in Leetcode. These questions are frequently asked in coding interviews, so solving them will help you prepare for technical interviews.&lt;/p&gt; &#xA;&lt;h1&gt;Beginner-Level-Solutions&lt;/h1&gt; &#xA;&lt;p&gt;This folder contains solutions to problems that are suitable for beginners in problem solving. These problems cover a range of topics and will help you improve your problem solving skills.&lt;/p&gt; &#xA;&lt;h1&gt;Intermediate-Level-Solutions&lt;/h1&gt; &#xA;&lt;p&gt;This folder contains solutions to problems that are suitable for intermediate-level problem solvers. These problems are more complex than those in the Beginner-Level-Solutions folder and will help you build on your problem solving skills.&lt;/p&gt; &#xA;&lt;p&gt;Feel free to explore the folders and use the solutions as a reference when solving problems on your own. Contributions to this repository are also welcome!&lt;/p&gt;</summary>
  </entry>
</feed>