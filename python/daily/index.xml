<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-12T01:43:57Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>pydantic/bump-pydantic</title>
    <updated>2023-07-12T01:43:57Z</updated>
    <id>tag:github.com,2023-07-12:/pydantic/bump-pydantic</id>
    <link href="https://github.com/pydantic/bump-pydantic" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Convert Pydantic from V1 to V2 ‚ôª&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Bump Pydantic ‚ôªÔ∏è&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pypi.org/project/bump-pydantic&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/bump-pydantic.svg?sanitize=true&#34; alt=&#34;PyPI - Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/bump-pydantic&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/bump-pydantic.svg?sanitize=true&#34; alt=&#34;PyPI - Python Version&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Bump Pydantic is a tool to help you migrate your code from Pydantic V1 to V2.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; If you find bugs, please report them on the &lt;a href=&#34;https://github.com/pydantic/bump-pydantic/issues/new&#34;&gt;issue tracker&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Table of contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#bump-pydantic-%EF%B8%8F&#34;&gt;Bump Pydantic ‚ôªÔ∏è&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#table-of-contents&#34;&gt;Table of contents&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#usage&#34;&gt;Usage&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#check-diff-before-applying-changes&#34;&gt;Check diff before applying changes&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#apply-changes&#34;&gt;Apply changes&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#rules&#34;&gt;Rules&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#bp001-add-default-none-to-optionalt-uniont-none-and-any-fields&#34;&gt;BP001: Add default &lt;code&gt;None&lt;/code&gt; to &lt;code&gt;Optional[T]&lt;/code&gt;, &lt;code&gt;Union[T, None]&lt;/code&gt; and &lt;code&gt;Any&lt;/code&gt; fields&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#bp002-replace-config-class-by-model_config-attribute&#34;&gt;BP002: Replace &lt;code&gt;Config&lt;/code&gt; class by &lt;code&gt;model_config&lt;/code&gt; attribute&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#bp003-replace-field-old-parameters-to-new-ones&#34;&gt;BP003: Replace &lt;code&gt;Field&lt;/code&gt; old parameters to new ones&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#bp004-replace-imports&#34;&gt;BP004: Replace imports&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#bp005-replace-genericmodel-by-basemodel&#34;&gt;BP005: Replace &lt;code&gt;GenericModel&lt;/code&gt; by &lt;code&gt;BaseModel&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#bp006-replace-__root__-by-rootmodel&#34;&gt;BP006: Replace &lt;code&gt;__root__&lt;/code&gt; by &lt;code&gt;RootModel&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#bp007-replace-decorators&#34;&gt;BP007: Replace decorators&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pydantic/bump-pydantic/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;The installation is as simple as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install bump-pydantic&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;bump-pydantic&lt;/code&gt; is a CLI tool, hence you can use it from your terminal.&lt;/p&gt; &#xA;&lt;p&gt;To see the available options, you can run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bump-pydantic --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Check diff before applying changes&lt;/h3&gt; &#xA;&lt;p&gt;To check the diff before applying the changes, you can run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bump-pydantic --diff &amp;lt;package&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Apply changes&lt;/h3&gt; &#xA;&lt;p&gt;To apply the changes, you can run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bump-pydantic &amp;lt;package&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Rules&lt;/h2&gt; &#xA;&lt;p&gt;You can find below the list of rules that are applied by &lt;code&gt;bump-pydantic&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s also possible to disable rules by using the &lt;code&gt;--disable&lt;/code&gt; option.&lt;/p&gt; &#xA;&lt;h3&gt;BP001: Add default &lt;code&gt;None&lt;/code&gt; to &lt;code&gt;Optional[T]&lt;/code&gt;, &lt;code&gt;Union[T, None]&lt;/code&gt; and &lt;code&gt;Any&lt;/code&gt; fields&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚úÖ Add default &lt;code&gt;None&lt;/code&gt; to &lt;code&gt;Optional[T]&lt;/code&gt; fields.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following code will be transformed:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;class User(BaseModel):&#xA;    name: Optional[str]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Into:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;class User(BaseModel):&#xA;    name: Optional[str] = None&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;BP002: Replace &lt;code&gt;Config&lt;/code&gt; class by &lt;code&gt;model_config&lt;/code&gt; attribute&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚úÖ Replace &lt;code&gt;Config&lt;/code&gt; class by &lt;code&gt;model_config = ConfigDict()&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;‚úÖ Rename old &lt;code&gt;Config&lt;/code&gt; attributes to new &lt;code&gt;model_config&lt;/code&gt; attributes.&lt;/li&gt; &#xA; &lt;li&gt;‚úÖ Add a TODO comment in case the transformation can&#39;t be done automatically.&lt;/li&gt; &#xA; &lt;li&gt;‚úÖ Replace &lt;code&gt;Extra&lt;/code&gt; enum by string values.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following code will be transformed:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from pydantic import BaseModel, Extra&#xA;&#xA;&#xA;class User(BaseModel):&#xA;    name: str&#xA;&#xA;    class Config:&#xA;        extra = Extra.forbid&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Into:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from pydantic import ConfigDict, BaseModel&#xA;&#xA;&#xA;class User(BaseModel):&#xA;    name: str&#xA;&#xA;    model_config = ConfigDict(extra=&#34;forbid&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;BP003: Replace &lt;code&gt;Field&lt;/code&gt; old parameters to new ones&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚úÖ Replace &lt;code&gt;Field&lt;/code&gt; old parameters to new ones.&lt;/li&gt; &#xA; &lt;li&gt;‚úÖ Replace &lt;code&gt;field: Enum = Field(Enum.VALUE, const=True)&lt;/code&gt; by &lt;code&gt;field: Literal[Enum.VALUE] = Enum.VALUE&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following code will be transformed:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from typing import List&#xA;&#xA;from pydantic import BaseModel, Field&#xA;&#xA;&#xA;class User(BaseModel):&#xA;    name: List[str] = Field(..., min_items=1)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Into:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from typing import List&#xA;&#xA;from pydantic import BaseModel, Field&#xA;&#xA;&#xA;class User(BaseModel):&#xA;    name: List[str] = Field(..., min_length=1)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;BP004: Replace imports&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚úÖ Replace &lt;code&gt;BaseSettings&lt;/code&gt; from &lt;code&gt;pydantic&lt;/code&gt; to &lt;code&gt;pydantic_settings&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;‚úÖ Replace &lt;code&gt;Color&lt;/code&gt; and &lt;code&gt;PaymentCardNumber&lt;/code&gt; from &lt;code&gt;pydantic&lt;/code&gt; to &lt;code&gt;pydantic_extra_types&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;BP005: Replace &lt;code&gt;GenericModel&lt;/code&gt; by &lt;code&gt;BaseModel&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚úÖ Replace &lt;code&gt;GenericModel&lt;/code&gt; by &lt;code&gt;BaseModel&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following code will be transformed:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from typing import Generic, TypeVar&#xA;from pydantic.generics import GenericModel&#xA;&#xA;T = TypeVar(&#39;T&#39;)&#xA;&#xA;class User(GenericModel, Generic[T]):&#xA;    name: str&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Into:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from typing import Generic, TypeVar&#xA;&#xA;T = TypeVar(&#39;T&#39;)&#xA;&#xA;class User(BaseModel, Generic[T]):&#xA;    name: str&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;BP006: Replace &lt;code&gt;__root__&lt;/code&gt; by &lt;code&gt;RootModel&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚úÖ Replace &lt;code&gt;__root__&lt;/code&gt; by &lt;code&gt;RootModel&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following code will be transformed:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from typing import List&#xA;&#xA;from pydantic import BaseModel&#xA;&#xA;class User(BaseModel):&#xA;    age: int&#xA;    name: str&#xA;&#xA;class Users(BaseModel):&#xA;    __root__ = List[User]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Into:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from typing import List&#xA;&#xA;from pydantic import RootModel&#xA;&#xA;class User(BaseModel):&#xA;    age: int&#xA;    name: str&#xA;&#xA;class Users(RootModel[List[User]]):&#xA;    pass&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;BP007: Replace decorators&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚úÖ Replace &lt;code&gt;@validator&lt;/code&gt; by &lt;code&gt;@field_validator&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;‚úÖ Replace &lt;code&gt;@root_validator&lt;/code&gt; by &lt;code&gt;@model_validator&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following code will be transformed:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from pydantic import BaseModel, validator, root_validator&#xA;&#xA;&#xA;class User(BaseModel):&#xA;    name: str&#xA;&#xA;    @validator(&#39;name&#39;, pre=True)&#xA;    def validate_name(cls, v):&#xA;        return v&#xA;&#xA;    @root_validator(pre=True)&#xA;    def validate_root(cls, values):&#xA;        return values&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Into:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from pydantic import BaseModel, field_validator, model_validator&#xA;&#xA;&#xA;class User(BaseModel):&#xA;    name: str&#xA;&#xA;    @field_validator(&#39;name&#39;, mode=&#39;before&#39;)&#xA;    def validate_name(cls, v):&#xA;        return v&#xA;&#xA;    @model_validator(mode=&#39;before&#39;)&#xA;    def validate_root(cls, values):&#xA;        return values&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!--&#xA;### BP008: Replace `pydantic.parse_obj_as` by `pydantic.TypeAdapter`&#xA;&#xA;- ‚úÖ Replace `pydantic.parse_obj_as(T, obj)` to `pydantic.TypeAdapter(T).validate_python(obj)`.&#xA;&#xA;&#xA;The following code will be transformed:&#xA;&#xA;```py&#xA;from typing import List&#xA;&#xA;from pydantic import BaseModel, parse_obj_as&#xA;&#xA;&#xA;class User(BaseModel):&#xA;    name: str&#xA;&#xA;&#xA;class Users(BaseModel):&#xA;    users: List[User]&#xA;&#xA;&#xA;users = parse_obj_as(Users, {&#39;users&#39;: [{&#39;name&#39;: &#39;John&#39;}]})&#xA;```&#xA;&#xA;Into:&#xA;&#xA;```py&#xA;from typing import List&#xA;&#xA;from pydantic import BaseModel, TypeAdapter&#xA;&#xA;&#xA;class User(BaseModel):&#xA;    name: str&#xA;&#xA;&#xA;class Users(BaseModel):&#xA;    users: List[User]&#xA;&#xA;&#xA;users = TypeAdapter(Users).validate_python({&#39;users&#39;: [{&#39;name&#39;: &#39;John&#39;}]})&#xA;```&#xA;--&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the terms of the MIT license.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>lifeisboringsoprogramming/sd-webui-xldemo-txt2img</title>
    <updated>2023-07-12T01:43:57Z</updated>
    <id>tag:github.com,2023-07-12:/lifeisboringsoprogramming/sd-webui-xldemo-txt2img</id>
    <link href="https://github.com/lifeisboringsoprogramming/sd-webui-xldemo-txt2img" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Stable Diffusion XL 0.9 Demo webui extension&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stable Diffusion XL 0.9 txt2img webui extension&lt;/h1&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/lifeisboringsoprogramming/sd-webui-xldemo-txt2img/main/images/webui.png&#34;&gt; &#xA;&lt;p&gt;A custom extension for &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;AUTOMATIC1111/stable-diffusion-webui&lt;/a&gt; that demo the SDXL 0.9 txt2img features&lt;/p&gt; &#xA;&lt;h1&gt;Tested environment&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GPU: RTX 3060 12G VRAM&lt;/li&gt; &#xA; &lt;li&gt;OS: Ubuntu&lt;/li&gt; &#xA; &lt;li&gt;Automatic1111 WebUI version: v1.4.0&lt;/li&gt; &#xA; &lt;li&gt;python: 3.10.9&lt;/li&gt; &#xA; &lt;li&gt;torch: 2.0.1+cu118&lt;/li&gt; &#xA; &lt;li&gt;xformers: 0.0.20&lt;/li&gt; &#xA; &lt;li&gt;gradio: 3.32.0&lt;/li&gt; &#xA; &lt;li&gt;checkpoint: 20af92d769&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Overview&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;This project allows users to do txt2img using the SDXL 0.9 base checkpoint&lt;/li&gt; &#xA; &lt;li&gt;Refine image using SDXL 0.9 refiner checkpoint&lt;/li&gt; &#xA; &lt;li&gt;Setting sampling steps&lt;/li&gt; &#xA; &lt;li&gt;Setting image width and height&lt;/li&gt; &#xA; &lt;li&gt;Setting batch size&lt;/li&gt; &#xA; &lt;li&gt;Setting CFG Scale&lt;/li&gt; &#xA; &lt;li&gt;Setting seed&lt;/li&gt; &#xA; &lt;li&gt;Reuse seed&lt;/li&gt; &#xA; &lt;li&gt;Use refiner&lt;/li&gt; &#xA; &lt;li&gt;Setting refiner strength&lt;/li&gt; &#xA; &lt;li&gt;Send to img2img&lt;/li&gt; &#xA; &lt;li&gt;Send to inpaint&lt;/li&gt; &#xA; &lt;li&gt;Send to extras&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Tutorial&lt;/h1&gt; &#xA;&lt;p&gt;There is a video to show how to use the extension&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=iF4w7gFDaYM&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/iF4w7gFDaYM/sddefault.jpg&#34; alt=&#34;Introducing Stable Diffusion XL 0.9 txt2img AUTOMATIC1111 webui extension&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Stable Diffusion extension&lt;/h1&gt; &#xA;&lt;p&gt;This project can be run as a stable Diffusion extension inside the Stable Diffusion WebUI.&lt;/p&gt; &#xA;&lt;h2&gt;Installation for stable Diffusion extension&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Copy and paste &lt;code&gt;https://github.com/lifeisboringsoprogramming/sd-webui-xldemo-txt2img.git&lt;/code&gt; to URL for extension&#39;s git repository&lt;/li&gt; &#xA; &lt;li&gt;Press Install button&lt;/li&gt; &#xA; &lt;li&gt;Apply and restart UI when finished installing&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/lifeisboringsoprogramming/sd-webui-xldemo-txt2img/main/images/webui-install.png&#34;&gt; &#xA;&lt;h1&gt;Limitations&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;this extension does not work with other extension like control net&lt;/li&gt; &#xA; &lt;li&gt;this extension does not work with LoRA, textual inversion embeddings, etc&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;YouTube Channel&lt;/h1&gt; &#xA;&lt;p&gt;Please subscribe to my YouTube channel, thank you very much.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://bit.ly/3odzTKX&#34;&gt;https://bit.ly/3odzTKX&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Patreon&lt;/h1&gt; &#xA;&lt;p&gt;‚òïÔ∏è Please consider to support me in Patreon üçª&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.patreon.com/lifeisboringsoprogramming&#34;&gt;https://www.patreon.com/lifeisboringsoprogramming&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>pyg-team/pytorch_geometric</title>
    <updated>2023-07-12T01:43:57Z</updated>
    <id>tag:github.com,2023-07-12:/pyg-team/pytorch_geometric</id>
    <link href="https://github.com/pyg-team/pytorch_geometric" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Graph Neural Network Library for PyTorch&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;150&#34; src=&#34;https://raw.githubusercontent.com/pyg-team/pyg_sphinx_theme/master/pyg_sphinx_theme/static/img/pyg_logo_text.svg?sanitize=true&#34;&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pypi.python.org/pypi/torch-geometric&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/torch-geometric.svg?sanitize=true&#34; alt=&#34;PyPI Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/actions/workflows/testing.yml&#34;&gt;&lt;img src=&#34;https://github.com/pyg-team/pytorch_geometric/actions/workflows/testing.yml/badge.svg?sanitize=true&#34; alt=&#34;Testing Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/actions/workflows/linting.yml&#34;&gt;&lt;img src=&#34;https://github.com/pyg-team/pytorch_geometric/actions/workflows/linting.yml/badge.svg?sanitize=true&#34; alt=&#34;Linting Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/pytorch-geometric/badge/?version=latest&#34; alt=&#34;Docs Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/.github/CONTRIBUTING.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat&#34; alt=&#34;Contributing&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://data.pyg.org/slack.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/slack-pyg-brightgreen&#34; alt=&#34;Slack&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io&#34;&gt;Documentation&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/1903.02428&#34;&gt;Paper&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/get_started/colabs.html&#34;&gt;Colab Notebooks and Video Tutorials&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/external/resources.html&#34;&gt;External Resources&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href=&#34;https://github.com/snap-stanford/ogb/tree/master/examples&#34;&gt;OGB Examples&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PyG&lt;/strong&gt; &lt;em&gt;(PyTorch Geometric)&lt;/em&gt; is a library built upon &lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt; to easily write and train Graph Neural Networks (GNNs) for a wide range of applications related to structured data.&lt;/p&gt; &#xA;&lt;p&gt;It consists of various methods for deep learning on graphs and other irregular structures, also known as &lt;em&gt;&lt;a href=&#34;http://geometricdeeplearning.com/&#34;&gt;geometric deep learning&lt;/a&gt;&lt;/em&gt;, from a variety of published papers. In addition, it consists of easy-to-use mini-batch loaders for operating on many small and single giant graphs, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/tree/master/examples/multi_gpu&#34;&gt;multi GPU-support&lt;/a&gt;, &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/tutorial/compile.html&#34;&gt;&lt;code&gt;torch.compile&lt;/code&gt;&lt;/a&gt; support, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/datapipe.py&#34;&gt;&lt;code&gt;DataPipe&lt;/code&gt;&lt;/a&gt; support, a large number of common benchmark datasets (based on simple interfaces to create your own), the &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/advanced/graphgym.html&#34;&gt;GraphGym&lt;/a&gt; experiment manager, and helpful transforms, both for learning on arbitrary graphs as well as on 3D meshes or point clouds.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://data.pyg.org/slack.html&#34;&gt;Click here to join our Slack community!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://medium.com/stanford-cs224w&#34;&gt;&lt;img style=&#34;max-width=: 941px&#34; src=&#34;https://data.pyg.org/img/cs224w_tutorials.png&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pyg-team/pytorch_geometric/master/#library-highlights&#34;&gt;Library Highlights&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pyg-team/pytorch_geometric/master/#quick-tour-for-new-users&#34;&gt;Quick Tour for New Users&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pyg-team/pytorch_geometric/master/#architecture-overview&#34;&gt;Architecture Overview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pyg-team/pytorch_geometric/master/#implemented-gnn-models&#34;&gt;Implemented GNN Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/pyg-team/pytorch_geometric/master/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Library Highlights&lt;/h2&gt; &#xA;&lt;p&gt;Whether you are a machine learning researcher or first-time user of machine learning toolkits, here are some reasons to try out PyG for machine learning on graph-structured data.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Easy-to-use and unified API&lt;/strong&gt;: All it takes is 10-20 lines of code to get started with training a GNN model (see the next section for a &lt;a href=&#34;https://raw.githubusercontent.com/pyg-team/pytorch_geometric/master/#quick-tour-for-new-users&#34;&gt;quick tour&lt;/a&gt;). PyG is &lt;em&gt;PyTorch-on-the-rocks&lt;/em&gt;: It utilizes a tensor-centric API and keeps design principles close to vanilla PyTorch. If you are already familiar with PyTorch, utilizing PyG is straightforward.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Comprehensive and well-maintained GNN models&lt;/strong&gt;: Most of the state-of-the-art Graph Neural Network architectures have been implemented by library developers or authors of research papers and are ready to be applied.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Great flexibility&lt;/strong&gt;: Existing PyG models can easily be extended for conducting your own research with GNNs. Making modifications to existing models or creating new architectures is simple, thanks to its easy-to-use message passing API, and a variety of operators and utility functions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Large-scale real-world GNN models&lt;/strong&gt;: We focus on the need of GNN applications in challenging real-world scenarios, and support learning on diverse types of graphs, including but not limited to: scalable GNNs for graphs with millions of nodes; dynamic GNNs for node predictions over time; heterogeneous GNNs with multiple node types and edge types.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;GraphGym integration&lt;/strong&gt;: GraphGym lets users easily reproduce GNN experiments, is able to launch and analyze thousands of different GNN configurations, and is customizable by registering new modules to a GNN learning pipeline.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quick Tour for New Users&lt;/h2&gt; &#xA;&lt;p&gt;In this quick tour, we highlight the ease of creating and training a GNN model with only a few lines of code.&lt;/p&gt; &#xA;&lt;h3&gt;Train your own GNN model&lt;/h3&gt; &#xA;&lt;p&gt;In the first glimpse of PyG, we implement the training of a GNN for classifying papers in a citation graph. For this, we load the &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.Planetoid.html&#34;&gt;Cora&lt;/a&gt; dataset, and create a simple 2-layer GCN model using the pre-defined &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html&#34;&gt;&lt;code&gt;GCNConv&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from torch import Tensor&#xA;from torch_geometric.nn import GCNConv&#xA;from torch_geometric.datasets import Planetoid&#xA;&#xA;dataset = Planetoid(root=&#39;.&#39;, name=&#39;Cora&#39;)&#xA;&#xA;class GCN(torch.nn.Module):&#xA;    def __init__(self, in_channels, hidden_channels, out_channels):&#xA;        super().__init__()&#xA;        self.conv1 = GCNConv(in_channels, hidden_channels)&#xA;        self.conv2 = GCNConv(hidden_channels, out_channels)&#xA;&#xA;    def forward(self, x: Tensor, edge_index: Tensor) -&amp;gt; Tensor:&#xA;        # x: Node feature matrix of shape [num_nodes, in_channels]&#xA;        # edge_index: Graph connectivity matrix of shape [2, num_edges]&#xA;        x = self.conv1(x, edge_index).relu()&#xA;        x = self.conv2(x, edge_index)&#xA;        return x&#xA;&#xA;model = GCN(dataset.num_features, 16, dataset.num_classes)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;We can now optimize the model in a training loop, similar to the &lt;a href=&#34;https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#full-implementation&#34;&gt;standard PyTorch training procedure&lt;/a&gt;.&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch.nn.functional as F&#xA;&#xA;data = dataset[0]&#xA;optimizer = torch.optim.Adam(model.parameters(), lr=0.01)&#xA;&#xA;for epoch in range(200):&#xA;    pred = model(data.x, data.edge_index)&#xA;    loss = F.cross_entropy(pred[data.train_mask], data.y[data.train_mask])&#xA;&#xA;    # Backpropagation&#xA;    optimizer.zero_grad()&#xA;    loss.backward()&#xA;    optimizer.step()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;More information about evaluating final model performance can be found in the corresponding &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/gcn.py&#34;&gt;example&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Create your own GNN layer&lt;/h3&gt; &#xA;&lt;p&gt;In addition to the easy application of existing GNNs, PyG makes it simple to implement custom Graph Neural Networks (see &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_gnn.html&#34;&gt;here&lt;/a&gt; for the accompanying tutorial). For example, this is all it takes to implement the &lt;a href=&#34;https://arxiv.org/abs/1801.07829&#34;&gt;edge convolutional layer&lt;/a&gt; from Wang &lt;em&gt;et al.&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;p&gt;$$x_i^{\prime} ~ = ~ \max_{j \in \mathcal{N}(i)} ~ \textrm{MLP}_{\theta} \left( [ ~ x_i, ~ x_j - x_i ~ ] \right)$$&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from torch import Tensor&#xA;from torch.nn import Sequential, Linear, ReLU&#xA;from torch_geometric.nn import MessagePassing&#xA;&#xA;class EdgeConv(MessagePassing):&#xA;    def __init__(self, in_channels, out_channels):&#xA;        super().__init__(aggr=&#34;max&#34;)  # &#34;Max&#34; aggregation.&#xA;        self.mlp = Sequential(&#xA;            Linear(2 * in_channels, out_channels),&#xA;            ReLU(),&#xA;            Linear(out_channels, out_channels),&#xA;        )&#xA;&#xA;    def forward(self, x: Tensor, edge_index: Tensor) -&amp;gt; Tensor:&#xA;        # x: Node feature matrix of shape [num_nodes, in_channels]&#xA;        # edge_index: Graph connectivity matrix of shape [2, num_edges]&#xA;        return self.propagate(edge_index, x=x)  # shape [num_nodes, out_channels]&#xA;&#xA;    def message(self, x_j: Tensor, x_i: Tensor) -&amp;gt; Tensor:&#xA;        # x_j: Source node features of shape [num_edges, in_channels]&#xA;        # x_i: Target node features of shape [num_edges, in_channels]&#xA;        edge_features = torch.cat([x_i, x_j - x_i], dim=-1)&#xA;        return self.mlp(edge_features)  # shape [num_edges, out_channels]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Manage experiments with GraphGym&lt;/h3&gt; &#xA;&lt;p&gt;GraphGym allows you to manage and launch GNN experiments, using a highly modularized pipeline (see &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/advanced/graphgym.html&#34;&gt;here&lt;/a&gt; for the accompanying tutorial).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/pyg-team/pytorch_geometric.git&#xA;cd pytorch_geometric/graphgym&#xA;bash run_single.sh  # run a single GNN experiment (node/edge/graph-level)&#xA;bash run_batch.sh   # run a batch of GNN experiments, using differnt GNN designs/datasets/tasks&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Users are highly encouraged to check out the &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest&#34;&gt;documentation&lt;/a&gt;, which contains additional tutorials on the essential functionalities of PyG, including data handling, creation of datasets and a full list of implemented methods, transforms, and datasets. For a quick start, check out our &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/tree/master/examples&#34;&gt;examples&lt;/a&gt; in &lt;code&gt;examples/&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Architecture Overview&lt;/h2&gt; &#xA;&lt;p&gt;PyG provides a multi-layer framework that enables users to build Graph Neural Network solutions on both low and high levels. It comprises of the following components:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The PyG &lt;strong&gt;engine&lt;/strong&gt; utilizes the powerful PyTorch deep learning framework with full &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/tutorial/compile.html&#34;&gt;&lt;code&gt;torch.compile&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/advanced/jit.html&#34;&gt;TorchScript&lt;/a&gt; support, as well as additions of efficient CPU/CUDA libraries for operating on sparse data, &lt;em&gt;e.g.&lt;/em&gt;, &lt;a href=&#34;https://github.com/pyg-team/pyg-lib&#34;&gt;&lt;code&gt;pyg-lib&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The PyG &lt;strong&gt;storage&lt;/strong&gt; handles data processing, transformation and loading pipelines. It is capable of handling and processing large-scale graph datasets, and provides effective solutions for heterogeneous graphs. It further provides a variety of sampling solutions, which enable training of GNNs on large-scale graphs.&lt;/li&gt; &#xA; &lt;li&gt;The PyG &lt;strong&gt;operators&lt;/strong&gt; bundle essential functionalities for implementing Graph Neural Networks. PyG supports important GNN building blocks that can be combined and applied to various parts of a GNN model, ensuring rich flexibility of GNN design.&lt;/li&gt; &#xA; &lt;li&gt;Finally, PyG provides an abundant set of GNN &lt;strong&gt;models&lt;/strong&gt;, and examples that showcase GNN models on standard graph benchmarks. Thanks to its flexibility, users can easily build and modify custom GNN models to fit their specific needs.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;100%&#34; src=&#34;https://raw.githubusercontent.com/pyg-team/pytorch_geometric/master/docs/source/_figures/architecture.svg?sanitize=true&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Implemented GNN Models&lt;/h2&gt; &#xA;&lt;p&gt;We list currently supported PyG models, layers and operators according to category:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GNN layers:&lt;/strong&gt; All Graph Neural Network layers are implemented via the &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MessagePassing.html&#34;&gt;&lt;code&gt;nn.MessagePassing&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt; interface. A GNN layer specifies how to perform message passing, &lt;em&gt;i.e.&lt;/em&gt; by designing different message, aggregation and update functions as defined &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_gnn.html&#34;&gt;here&lt;/a&gt;. These GNN layers can be stacked together to create Graph Neural Network models.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html&#34;&gt;GCNConv&lt;/a&gt;&lt;/strong&gt; from Kipf and Welling: &lt;a href=&#34;https://arxiv.org/abs/1609.02907&#34;&gt;Semi-Supervised Classification with Graph Convolutional Networks&lt;/a&gt; (ICLR 2017) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/gcn.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ChebConv.html&#34;&gt;ChebConv&lt;/a&gt;&lt;/strong&gt; from Defferrard &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1606.09375&#34;&gt;Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering&lt;/a&gt; (NIPS 2016) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/gcn.py#L36-L37&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GATConv.html&#34;&gt;GATConv&lt;/a&gt;&lt;/strong&gt; from Veliƒçkoviƒá &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1710.10903&#34;&gt;Graph Attention Networks&lt;/a&gt; (ICLR 2018) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/gat.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;Expand to see all implemented GNN layers...&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCN2Conv.html&#34;&gt;GCN2Conv&lt;/a&gt;&lt;/strong&gt; from Chen &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2007.02133&#34;&gt;Simple and Deep Graph Convolutional Networks&lt;/a&gt; (ICML 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/gcn2_cora.py&#34;&gt;&lt;strong&gt;Example1&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/gcn2_ppi.py&#34;&gt;&lt;strong&gt;Example2&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SplineConv.html&#34;&gt;SplineConv&lt;/a&gt;&lt;/strong&gt; from Fey &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1711.08920&#34;&gt;SplineCNN: Fast Geometric Deep Learning with Continuous B-Spline Kernels&lt;/a&gt; (CVPR 2018) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/cora.py&#34;&gt;&lt;strong&gt;Example1&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/faust.py&#34;&gt;&lt;strong&gt;Example2&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.NNConv.html&#34;&gt;NNConv&lt;/a&gt;&lt;/strong&gt; from Gilmer &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1704.01212&#34;&gt;Neural Message Passing for Quantum Chemistry&lt;/a&gt; (ICML 2017) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/qm9_nn_conv.py&#34;&gt;&lt;strong&gt;Example1&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/mnist_nn_conv.py&#34;&gt;&lt;strong&gt;Example2&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.CGConv.html&#34;&gt;CGConv&lt;/a&gt;&lt;/strong&gt; from Xie and Grossman: &lt;a href=&#34;https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.120.145301&#34;&gt;Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties&lt;/a&gt; (Physical Review Letters 120, 2018)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ECConv.html&#34;&gt;ECConv&lt;/a&gt;&lt;/strong&gt; from Simonovsky and Komodakis: &lt;a href=&#34;https://arxiv.org/abs/1704.02901&#34;&gt;Edge-Conditioned Convolution on Graphs&lt;/a&gt; (CVPR 2017)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.EGConv.html&#34;&gt;EGConv&lt;/a&gt;&lt;/strong&gt; from Tailor &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2104.01481&#34;&gt;Adaptive Filters and Aggregator Fusion for Efficient Graph Convolutions&lt;/a&gt; (GNNSys 2021) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/egc.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GATv2Conv.html&#34;&gt;GATv2Conv&lt;/a&gt;&lt;/strong&gt; from Brody &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2105.14491&#34;&gt;How Attentive are Graph Attention Networks?&lt;/a&gt; (ICLR 2022)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.TransformerConv.html&#34;&gt;TransformerConv&lt;/a&gt;&lt;/strong&gt; from Shi &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2009.03509&#34;&gt;Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification&lt;/a&gt; (CoRR 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/unimp_arxiv.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SAGEConv.html&#34;&gt;SAGEConv&lt;/a&gt;&lt;/strong&gt; from Hamilton &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1706.02216&#34;&gt;Inductive Representation Learning on Large Graphs&lt;/a&gt; (NIPS 2017) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/reddit.py&#34;&gt;&lt;strong&gt;Example1&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/ogbn_products_sage.py&#34;&gt;&lt;strong&gt;Example2&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/graph_sage_unsup.py&#34;&gt;&lt;strong&gt;Example3&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/graph_sage_unsup_ppi.py&#34;&gt;&lt;strong&gt;Example4&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GraphConv.html&#34;&gt;GraphConv&lt;/a&gt;&lt;/strong&gt; from, &lt;em&gt;e.g.&lt;/em&gt;, Morris &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1810.02244&#34;&gt;Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks&lt;/a&gt; (AAAI 2019)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GatedGraphConv.html&#34;&gt;GatedGraphConv&lt;/a&gt;&lt;/strong&gt; from Li &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1511.05493&#34;&gt;Gated Graph Sequence Neural Networks&lt;/a&gt; (ICLR 2016)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ResGatedGraphConv.html&#34;&gt;ResGatedGraphConv&lt;/a&gt;&lt;/strong&gt; from Bresson and Laurent: &lt;a href=&#34;https://arxiv.org/abs/1711.07553&#34;&gt;Residual Gated Graph ConvNets&lt;/a&gt; (CoRR 2017)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GINConv.html&#34;&gt;GINConv&lt;/a&gt;&lt;/strong&gt; from Xu &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1810.00826&#34;&gt;How Powerful are Graph Neural Networks?&lt;/a&gt; (ICLR 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/mutag_gin.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GINEConv.html&#34;&gt;GINEConv&lt;/a&gt;&lt;/strong&gt; from Hu &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1905.12265&#34;&gt;Strategies for Pre-training Graph Neural Networks&lt;/a&gt; (ICLR 2020)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ARMAConv.html&#34;&gt;ARMAConv&lt;/a&gt;&lt;/strong&gt; from Bianchi &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1901.01343&#34;&gt;Graph Neural Networks with Convolutional ARMA Filters&lt;/a&gt; (CoRR 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/arma.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SGConv.html&#34;&gt;SGConv&lt;/a&gt;&lt;/strong&gt; from Wu &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1902.07153&#34;&gt;Simplifying Graph Convolutional Networks&lt;/a&gt; (CoRR 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/sgc.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.APPNP.html&#34;&gt;APPNP&lt;/a&gt;&lt;/strong&gt; from Klicpera &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1810.05997&#34;&gt;Predict then Propagate: Graph Neural Networks meet Personalized PageRank&lt;/a&gt; (ICLR 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/benchmark/citation/appnp.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MFConv.html&#34;&gt;MFConv&lt;/a&gt;&lt;/strong&gt; from Duvenaud &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1509.09292&#34;&gt;Convolutional Networks on Graphs for Learning Molecular Fingerprints&lt;/a&gt; (NIPS 2015)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.AGNNConv.html&#34;&gt;AGNNConv&lt;/a&gt;&lt;/strong&gt; from Thekumparampil &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1803.03735&#34;&gt;Attention-based Graph Neural Network for Semi-Supervised Learning&lt;/a&gt; (CoRR 2017) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/agnn.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.TAGConv.html&#34;&gt;TAGConv&lt;/a&gt;&lt;/strong&gt; from Du &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1710.10370&#34;&gt;Topology Adaptive Graph Convolutional Networks&lt;/a&gt; (CoRR 2017) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/tagcn.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.PNAConv.html&#34;&gt;PNAConv&lt;/a&gt;&lt;/strong&gt; from Corso &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2004.05718&#34;&gt;Principal Neighbourhood Aggregation for Graph Nets&lt;/a&gt; (CoRR 2020) [&lt;strong&gt;&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/pna.py&#34;&gt;Example&lt;/a&gt;&lt;/strong&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.FAConv.html&#34;&gt;FAConv&lt;/a&gt;&lt;/strong&gt; from Bo &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2101.00797&#34;&gt;Beyond Low-Frequency Information in Graph Convolutional Networks&lt;/a&gt; (AAAI 2021)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.nn.conv.PDNConv.html&#34;&gt;PDNConv&lt;/a&gt;&lt;/strong&gt; from Rozemberczki &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2010.12878&#34;&gt;Pathfinder Discovery Networks for Neural Message Passing&lt;/a&gt; (WWW 2021)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.RGCNConv.html&#34;&gt;RGCNConv&lt;/a&gt;&lt;/strong&gt; from Schlichtkrull &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1703.06103&#34;&gt;Modeling Relational Data with Graph Convolutional Networks&lt;/a&gt; (ESWC 2018) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/rgcn.py&#34;&gt;&lt;strong&gt;Example1&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/rgcn_link_pred.py&#34;&gt;&lt;strong&gt;Example2&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.RGATConv.html&#34;&gt;RGATConv&lt;/a&gt;&lt;/strong&gt; from Busbridge &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1904.05811&#34;&gt;Relational Graph Attention Networks&lt;/a&gt; (CoRR 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/rgat.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.FiLMConv.html&#34;&gt;FiLMConv&lt;/a&gt;&lt;/strong&gt; from Brockschmidt: &lt;a href=&#34;https://arxiv.org/abs/1906.12192&#34;&gt;GNN-FiLM: Graph Neural Networks with Feature-wise Linear Modulation&lt;/a&gt; (ICML 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/film.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SignedConv.html&#34;&gt;SignedConv&lt;/a&gt;&lt;/strong&gt; from Derr &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1808.06354&#34;&gt;Signed Graph Convolutional Network&lt;/a&gt; (ICDM 2018) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/signed_gcn.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.DNAConv.html&#34;&gt;DNAConv&lt;/a&gt;&lt;/strong&gt; from Fey: &lt;a href=&#34;https://arxiv.org/abs/1904.04849&#34;&gt;Just Jump: Dynamic Neighborhood Aggregation in Graph Neural Networks&lt;/a&gt; (ICLR-W 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/dna.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.PANConv.html&#34;&gt;PANConv&lt;/a&gt;&lt;/strong&gt; from Ma &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2006.16811&#34;&gt;Path Integral Based Convolution and Pooling for Graph Neural Networks&lt;/a&gt; (NeurIPS 2020)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.PointNetConv.html&#34;&gt;PointNetConv&lt;/a&gt;&lt;/strong&gt; (including &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.fps.html&#34;&gt;Iterative Farthest Point Sampling&lt;/a&gt;&lt;/strong&gt;, dynamic graph generation based on &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.knn_graph.html&#34;&gt;nearest neighbor&lt;/a&gt;&lt;/strong&gt; or &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.radius_graph.html&#34;&gt;maximum distance&lt;/a&gt;&lt;/strong&gt;, and &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.unpool.knn_interpolate.html&#34;&gt;k-NN interpolation&lt;/a&gt;&lt;/strong&gt; for upsampling) from Qi &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1612.00593&#34;&gt;PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation&lt;/a&gt; (CVPR 2017) and &lt;a href=&#34;https://arxiv.org/abs/1706.02413&#34;&gt;PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space&lt;/a&gt; (NIPS 2017) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/pointnet2_classification.py&#34;&gt;&lt;strong&gt;Example1&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/pointnet2_segmentation.py&#34;&gt;&lt;strong&gt;Example2&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.EdgeConv.html&#34;&gt;EdgeConv&lt;/a&gt;&lt;/strong&gt; from Wang &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1801.07829&#34;&gt;Dynamic Graph CNN for Learning on Point Clouds&lt;/a&gt; (CoRR, 2018) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/dgcnn_classification.py&#34;&gt;&lt;strong&gt;Example1&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/dgcnn_segmentation.py&#34;&gt;&lt;strong&gt;Example2&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.XConv.html&#34;&gt;XConv&lt;/a&gt;&lt;/strong&gt; from Li &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1801.07791&#34;&gt;PointCNN: Convolution On X-Transformed Points&lt;/a&gt; (NeurIPS 2018) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/benchmark/points/point_cnn.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.PPFConv.html&#34;&gt;PPFConv&lt;/a&gt;&lt;/strong&gt; from Deng &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1802.02669&#34;&gt;PPFNet: Global Context Aware Local Features for Robust 3D Point Matching&lt;/a&gt; (CVPR 2018)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GMMConv.html&#34;&gt;GMMConv&lt;/a&gt;&lt;/strong&gt; from Monti &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1611.08402&#34;&gt;Geometric Deep Learning on Graphs and Manifolds using Mixture Model CNNs&lt;/a&gt; (CVPR 2017)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.FeaStConv.html&#34;&gt;FeaStConv&lt;/a&gt;&lt;/strong&gt; from Verma &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1706.05206&#34;&gt;FeaStNet: Feature-Steered Graph Convolutions for 3D Shape Analysis&lt;/a&gt; (CVPR 2018)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.PointTransformerConv.html&#34;&gt;PointTransformerConv&lt;/a&gt;&lt;/strong&gt; from Zhao &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2012.09164&#34;&gt;Point Transformer&lt;/a&gt; (2020)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.HypergraphConv.html&#34;&gt;HypergraphConv&lt;/a&gt;&lt;/strong&gt; from Bai &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1901.08150&#34;&gt;Hypergraph Convolution and Hypergraph Attention&lt;/a&gt; (CoRR 2019)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GravNetConv.html&#34;&gt;GravNetConv&lt;/a&gt;&lt;/strong&gt; from Qasim &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1902.07987&#34;&gt;Learning Representations of Irregular Particle-detector Geometry with Distance-weighted Graph Networks&lt;/a&gt; (European Physics Journal C, 2019)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SuperGATConv.html&#34;&gt;SuperGAT&lt;/a&gt;&lt;/strong&gt; from Kim and Oh: &lt;a href=&#34;https://openreview.net/forum?id=Wi5KUNlqWty&#34;&gt;How To Find Your Friendly Neighborhood: Graph Attention Design With Self-Supervision&lt;/a&gt; (ICLR 2021) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/super_gat.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.HGTConv.html&#34;&gt;HGTConv&lt;/a&gt;&lt;/strong&gt; from Hu &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2003.01332&#34;&gt;Heterogeneous Graph Transformer&lt;/a&gt; (WWW 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/hetero/hgt_dblp.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.HEATonv.html&#34;&gt;HEATConv&lt;/a&gt;&lt;/strong&gt; from Mo &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2106.07161&#34;&gt;Heterogeneous Edge-Enhanced Graph Attention Network For Multi-Agent Trajectory Prediction&lt;/a&gt; (CoRR 2021)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SSGConv.html&#34;&gt;SSGConv&lt;/a&gt;&lt;/strong&gt; from Zhu &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://openreview.net/forum?id=CYO5T-YjWZV&#34;&gt;Simple Spectral Graph Convolution&lt;/a&gt; (ICLR 2021)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.FusedGATConv.html&#34;&gt;FusedGATConv&lt;/a&gt;&lt;/strong&gt; from Zhang &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://proceedings.mlsys.org/paper/2022/file/9a1158154dfa42caddbd0694a4e9bdc8-Paper.pdf&#34;&gt;Understanding GNN Computational Graph: A Coordinated Computation, IO, and Memory Perspective&lt;/a&gt; (MLSys 2022)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GPSConv.html&#34;&gt;GPSConv&lt;/a&gt;&lt;/strong&gt; from Ramp√°≈°ek &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2205.12454&#34;&gt;Recipe for a General, Powerful, Scalable Graph Transformer&lt;/a&gt; (NeurIPS 2022) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/graph_gps.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pooling layers:&lt;/strong&gt; Graph pooling layers combine the vectorial representations of a set of nodes in a graph (or a subgraph) into a single vector representation that summarizes its properties of nodes. It is commonly applied to graph-level tasks, which require combining node features into a single graph representation.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.TopKPooling.html&#34;&gt;Top-K Pooling&lt;/a&gt;&lt;/strong&gt; from Gao and Ji: &lt;a href=&#34;https://arxiv.org/abs/1905.05178&#34;&gt;Graph U-Nets&lt;/a&gt; (ICML 2019), Cangea &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1811.01287&#34;&gt;Towards Sparse Hierarchical Graph Classifiers&lt;/a&gt; (NeurIPS-W 2018) and Knyazev &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1905.02850&#34;&gt;Understanding Attention and Generalization in Graph Neural Networks&lt;/a&gt; (ICLR-W 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/proteins_topk_pool.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.dense_diff_pool.html&#34;&gt;DiffPool&lt;/a&gt;&lt;/strong&gt; from Ying &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1806.08804&#34;&gt;Hierarchical Graph Representation Learning with Differentiable Pooling&lt;/a&gt; (NeurIPS 2018) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/proteins_diff_pool.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;Expand to see all implemented pooling layers...&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.AttentionalAggregation.html&#34;&gt;Attentional Aggregation&lt;/a&gt;&lt;/strong&gt; from Li &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1904.12787&#34;&gt;Graph Matching Networks for Learning the Similarity of Graph Structured Objects&lt;/a&gt; (ICML 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/benchmark/kernel/global_attention.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.Set2Set.html&#34;&gt;Set2Set&lt;/a&gt;&lt;/strong&gt; from Vinyals &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1511.06391&#34;&gt;Order Matters: Sequence to Sequence for Sets&lt;/a&gt; (ICLR 2016) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/benchmark/kernel/set2set.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.SortAggregation.html&#34;&gt;Sort Aggregation&lt;/a&gt;&lt;/strong&gt; from Zhang &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://www.cse.wustl.edu/~muhan/papers/AAAI_2018_DGCNN.pdf&#34;&gt;An End-to-End Deep Learning Architecture for Graph Classification&lt;/a&gt; (AAAI 2018) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/benchmark/kernel/sort_pool.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.dense_mincut_pool.html&#34;&gt;MinCut Pooling&lt;/a&gt;&lt;/strong&gt; from Bianchi &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1907.00481&#34;&gt;Spectral Clustering with Graph Neural Networks for Graph Pooling&lt;/a&gt; (ICML 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/proteins_mincut_pool.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.DMoNPooling.html&#34;&gt;DMoN Pooling&lt;/a&gt;&lt;/strong&gt; from Tsitsulin &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2006.16904&#34;&gt;Graph Clustering with Graph Neural Networks&lt;/a&gt; (CoRR 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/proteins_dmon_pool.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.graclus.html&#34;&gt;Graclus Pooling&lt;/a&gt;&lt;/strong&gt; from Dhillon &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;http://www.cs.utexas.edu/users/inderjit/public_papers/multilevel_pami.pdf&#34;&gt;Weighted Graph Cuts without Eigenvectors: A Multilevel Approach&lt;/a&gt; (PAMI 2007) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/mnist_graclus.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.voxel_grid.html&#34;&gt;Voxel Grid Pooling&lt;/a&gt;&lt;/strong&gt; from, &lt;em&gt;e.g.&lt;/em&gt;, Simonovsky and Komodakis: &lt;a href=&#34;https://arxiv.org/abs/1704.02901&#34;&gt;Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs&lt;/a&gt; (CVPR 2017) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/mnist_voxel_grid.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.SAGPooling.html&#34;&gt;SAG Pooling&lt;/a&gt;&lt;/strong&gt; from Lee &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1904.08082&#34;&gt;Self-Attention Graph Pooling&lt;/a&gt; (ICML 2019) and Knyazev &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1905.02850&#34;&gt;Understanding Attention and Generalization in Graph Neural Networks&lt;/a&gt; (ICLR-W 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/benchmark/kernel/sag_pool.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.EdgePooling.html&#34;&gt;Edge Pooling&lt;/a&gt;&lt;/strong&gt; from Diehl &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://graphreason.github.io/papers/17.pdf&#34;&gt;Towards Graph Pooling by Edge Contraction&lt;/a&gt; (ICML-W 2019) and Diehl: &lt;a href=&#34;https://arxiv.org/abs/1905.10990&#34;&gt;Edge Contraction Pooling for Graph Neural Networks&lt;/a&gt; (CoRR 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/benchmark/kernel/edge_pool.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.ASAPooling.html&#34;&gt;ASAPooling&lt;/a&gt;&lt;/strong&gt; from Ranjan &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1911.07979&#34;&gt;ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical Graph Representations&lt;/a&gt; (AAAI 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/benchmark/kernel/asap.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.PANPooling.html&#34;&gt;PANPooling&lt;/a&gt;&lt;/strong&gt; from Ma &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2006.16811&#34;&gt;Path Integral Based Convolution and Pooling for Graph Neural Networks&lt;/a&gt; (NeurIPS 2020)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.MemPooling.html&#34;&gt;MemPooling&lt;/a&gt;&lt;/strong&gt; from Khasahmadi &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2002.09518&#34;&gt;Memory-Based Graph Networks&lt;/a&gt; (ICLR 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/mem_pool.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.GraphMultisetTransformer.html&#34;&gt;Graph Multiset Transformer&lt;/a&gt;&lt;/strong&gt; from Baek &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2102.11533&#34;&gt;Accurate Learning of Graph Representations with Graph Multiset Pooling&lt;/a&gt; (ICLR 2021) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/proteins_gmt.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.EquilibriumAggregation.html&#34;&gt;Equilibrium Aggregation&lt;/a&gt;&lt;/strong&gt; from Bartunov &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2202.12795&#34;&gt;&lt;/a&gt; (UAI 2022) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/equilibrium_median.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;strong&gt;GNN models:&lt;/strong&gt; Our supported GNN models incorporate multiple message passing layers, and users can directly use these pre-defined models to make predictions on graphs. Unlike simple stacking of GNN layers, these models could involve pre-processing, additional learnable parameters, skip connections, graph coarsening, etc.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.SchNet.html&#34;&gt;SchNet&lt;/a&gt;&lt;/strong&gt; from Sch√ºtt &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1706.08566&#34;&gt;SchNet: A Continuous-filter Convolutional Neural Network for Modeling Quantum Interactions&lt;/a&gt; (NIPS 2017) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/qm9_pretrained_schnet.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.DimeNet.html&#34;&gt;DimeNet&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.DimeNetPlusPlus.html&#34;&gt;DimeNetPlusPlus&lt;/a&gt;&lt;/strong&gt; from Klicpera &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2003.03123&#34;&gt;Directional Message Passing for Molecular Graphs&lt;/a&gt; (ICLR 2020) and &lt;a href=&#34;https://arxiv.org/abs/2011.14115&#34;&gt;Fast and Uncertainty-Aware Directional Message Passing for Non-Equilibrium Molecules&lt;/a&gt; (NeurIPS-W 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/qm9_pretrained_dimenet.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.Node2Vec.html&#34;&gt;Node2Vec&lt;/a&gt;&lt;/strong&gt; from Grover and Leskovec: &lt;a href=&#34;https://arxiv.org/abs/1607.00653&#34;&gt;node2vec: Scalable Feature Learning for Networks&lt;/a&gt; (KDD 2016) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/node2vec.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.DeepGraphInfomax.html&#34;&gt;Deep Graph Infomax&lt;/a&gt;&lt;/strong&gt; from Veliƒçkoviƒá &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1809.10341&#34;&gt;Deep Graph Infomax&lt;/a&gt; (ICLR 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/infomax_transductive.py&#34;&gt;&lt;strong&gt;Example1&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/infomax_inductive.py&#34;&gt;&lt;strong&gt;Example2&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Deep Multiplex Graph Infomax&lt;/strong&gt; from Park &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1911.06750&#34;&gt;Unsupervised Attributed Multiplex Network Embedding&lt;/a&gt; (AAAI 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/hetero/dmgi_unsup.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.MaskLabel.html&#34;&gt;Masked Label Prediction&lt;/a&gt;&lt;/strong&gt; from Shi &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2009.03509&#34;&gt;Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification&lt;/a&gt; (CoRR 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/unimp_arxiv.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.PMLP.html&#34;&gt;PMLP&lt;/a&gt;&lt;/strong&gt; from Yang &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2212.09034&#34;&gt;Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs&lt;/a&gt; (ICLR 2023)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;Expand to see all implemented GNN models...&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.JumpingKnowledge.html&#34;&gt;Jumping Knowledge&lt;/a&gt;&lt;/strong&gt; from Xu &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1806.03536&#34;&gt;Representation Learning on Graphs with Jumping Knowledge Networks&lt;/a&gt; (ICML 2018) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/benchmark/kernel/gin.py#L54-L106&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;A &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.MetaLayer.html&#34;&gt;MetaLayer&lt;/a&gt;&lt;/strong&gt; for building any kind of graph network similar to the &lt;a href=&#34;https://github.com/deepmind/graph_nets&#34;&gt;TensorFlow Graph Nets library&lt;/a&gt; from Battaglia &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1806.01261&#34;&gt;Relational Inductive Biases, Deep Learning, and Graph Networks&lt;/a&gt; (CoRR 2018)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.MetaPath2Vec.html&#34;&gt;MetaPath2Vec&lt;/a&gt;&lt;/strong&gt; from Dong &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://ericdongyx.github.io/papers/KDD17-dong-chawla-swami-metapath2vec.pdf&#34;&gt;metapath2vec: Scalable Representation Learning for Heterogeneous Networks&lt;/a&gt; (KDD 2017) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/hetero/metapath2vec.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;All variants of &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GAE.html&#34;&gt;Graph Autoencoders&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.VGAE.html&#34;&gt;Variational Autoencoders&lt;/a&gt;&lt;/strong&gt; from: &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1611.07308&#34;&gt;Variational Graph Auto-Encoders&lt;/a&gt; from Kipf and Welling (NIPS-W 2016) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/autoencoder.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1802.04407&#34;&gt;Adversarially Regularized Graph Autoencoder for Graph Embedding&lt;/a&gt; from Pan &lt;em&gt;et al.&lt;/em&gt; (IJCAI 2018) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/argva_node_clustering.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2001.07614&#34;&gt;Simple and Effective Graph Autoencoders with One-Hop Linear Models&lt;/a&gt; from Salha &lt;em&gt;et al.&lt;/em&gt; (ECML 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/autoencoder.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/seal_link_pred.py&#34;&gt;SEAL&lt;/a&gt;&lt;/strong&gt; from Zhang and Chen: &lt;a href=&#34;https://arxiv.org/pdf/1802.09691.pdf&#34;&gt;Link Prediction Based on Graph Neural Networks&lt;/a&gt; (NeurIPS 2018) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/seal_link_pred.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.RENet.html&#34;&gt;RENet&lt;/a&gt;&lt;/strong&gt; from Jin &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1904.05530&#34;&gt;Recurrent Event Network for Reasoning over Temporal Knowledge Graphs&lt;/a&gt; (ICLR-W 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/renet.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GraphUNet.html&#34;&gt;GraphUNet&lt;/a&gt;&lt;/strong&gt; from Gao and Ji: &lt;a href=&#34;https://arxiv.org/abs/1905.05178&#34;&gt;Graph U-Nets&lt;/a&gt; (ICML 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/graph_unet.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.AttentiveFP.html&#34;&gt;AttentiveFP&lt;/a&gt;&lt;/strong&gt; from Xiong &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959&#34;&gt;Pushing the Boundaries of Molecular Representation for Drug Discovery with the Graph Attention Mechanism&lt;/a&gt; (J. Med. Chem. 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/attentive_fp.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.DeepGCNLayer.html&#34;&gt;DeepGCN&lt;/a&gt;&lt;/strong&gt; and the &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GENConv.html&#34;&gt;GENConv&lt;/a&gt;&lt;/strong&gt; from Li &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1904.03751&#34;&gt;DeepGCNs: Can GCNs Go as Deep as CNNs?&lt;/a&gt; (ICCV 2019) and &lt;a href=&#34;https://arxiv.org/abs/2006.07739&#34;&gt;DeeperGCN: All You Need to Train Deeper GCNs&lt;/a&gt; (CoRR 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/ogbn_proteins_deepgcn.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.RECT_L.html&#34;&gt;RECT&lt;/a&gt;&lt;/strong&gt; from Wang &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://ieeexplore.ieee.org/document/8979355&#34;&gt;Network Embedding with Completely-imbalanced Labels&lt;/a&gt; (TKDE 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/rect.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.explain.algorithm.GNNExplainer.html&#34;&gt;GNNExplainer&lt;/a&gt;&lt;/strong&gt; from Ying &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1903.03894&#34;&gt;GNNExplainer: Generating Explanations for Graph Neural Networks&lt;/a&gt; (NeurIPS 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/explain/gnn_explainer.py&#34;&gt;&lt;strong&gt;Example1&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/explain/gnn_explainer_ba_shapes.py&#34;&gt;&lt;strong&gt;Example2&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/explain/gnn_explainer_link_pred.py&#34;&gt;&lt;strong&gt;Example3&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Graph-less Neural Networks&lt;/strong&gt; from Zhang &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2110.08727&#34;&gt;Graph-less Neural Networks: Teaching Old MLPs New Tricks via Distillation&lt;/a&gt; (CoRR 2021) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/glnn.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.LINKX.html&#34;&gt;LINKX&lt;/a&gt;&lt;/strong&gt; from Lim &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2110.14446&#34;&gt;Large Scale Learning on Non-Homophilous Graphs: New Benchmarks and Strong Simple Methods&lt;/a&gt; (NeurIPS 2021) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/linkx.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GroupAddRev.html&#34;&gt;RevGNN&lt;/a&gt;&lt;/strong&gt; from Li &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2106.07476&#34;&gt;Training Graph Neural with 1000 Layers&lt;/a&gt; (ICML 2021) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/rev_gnn.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.TransE.html&#34;&gt;TransE&lt;/a&gt;&lt;/strong&gt; from Bordes &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf&#34;&gt;Translating Embeddings for Modeling Multi-Relational Data&lt;/a&gt; (NIPS 2013) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/kge_fb15k_237.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.ComplEx.html&#34;&gt;ComplEx&lt;/a&gt;&lt;/strong&gt; from Trouillon &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1606.06357&#34;&gt;Complex Embeddings for Simple Link Prediction&lt;/a&gt; (ICML 2016) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/kge_fb15k_237.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.DistMult.html&#34;&gt;DistMult&lt;/a&gt;&lt;/strong&gt; from Yang &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1412.6575&#34;&gt;Embedding Entities and Relations for Learning and Inference in Knowledge Bases&lt;/a&gt; (ICLR 2015) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/kge_fb15k_237.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.RotatE.html&#34;&gt;RotatE&lt;/a&gt;&lt;/strong&gt; from Sun &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1902.10197&#34;&gt;RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space&lt;/a&gt; (ICLR 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/kge_fb15k_237.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;strong&gt;GNN operators and utilities:&lt;/strong&gt; PyG comes with a rich set of neural network operators that are commonly used in many GNN models. They follow an extensible design: It is easy to apply these operators and graph utilities to existing GNN layers and models to further enhance model performance.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.dropout_edge&#34;&gt;DropEdge&lt;/a&gt;&lt;/strong&gt; from Rong &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://openreview.net/forum?id=Hkx1qkrKPr&#34;&gt;DropEdge: Towards Deep Graph Convolutional Networks on Node Classification&lt;/a&gt; (ICLR 2020)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.dropout_node&#34;&gt;DropNode&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.mask_feature&#34;&gt;MaskFeature&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.add_random_edge&#34;&gt;AddRandomEdge&lt;/a&gt;&lt;/strong&gt; from You &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2010.13902&#34;&gt;Graph Contrastive Learning with Augmentations&lt;/a&gt; (NeurIPS 2020)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.dropout_path&#34;&gt;DropPath&lt;/a&gt;&lt;/strong&gt; from Li &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2205.10053&#34;&gt;MaskGAE: Masked Graph Modeling Meets Graph Autoencoders&lt;/a&gt; (arXiv 2022)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.shuffle_node&#34;&gt;ShuffleNode&lt;/a&gt;&lt;/strong&gt; from Veliƒçkoviƒá &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1809.10341&#34;&gt;Deep Graph Infomax&lt;/a&gt; (ICLR 2019)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.GraphNorm.html&#34;&gt;GraphNorm&lt;/a&gt;&lt;/strong&gt; from Cai &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://proceedings.mlr.press/v139/cai21e.html&#34;&gt;GraphNorm: A Principled Approach to Accelerating Graph Neural Network Training&lt;/a&gt; (ICML 2021)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.GDC.html&#34;&gt;GDC&lt;/a&gt;&lt;/strong&gt; from Klicpera &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1911.05485&#34;&gt;Diffusion Improves Graph Learning&lt;/a&gt; (NeurIPS 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/gcn.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;Expand to see all implemented GNN operators and utilities...&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.GraphSizeNorm.html&#34;&gt;GraphSizeNorm&lt;/a&gt;&lt;/strong&gt; from Dwivedi &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2003.00982&#34;&gt;Benchmarking Graph Neural Networks&lt;/a&gt; (CoRR 2020)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.PairNorm.html&#34;&gt;PairNorm&lt;/a&gt;&lt;/strong&gt; from Zhao and Akoglu: &lt;a href=&#34;https://arxiv.org/abs/1909.12223&#34;&gt;PairNorm: Tackling Oversmoothing in GNNs&lt;/a&gt; (ICLR 2020)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.MeanSubtractionNorm.html&#34;&gt;MeanSubtractionNorm&lt;/a&gt;&lt;/strong&gt; from Yang &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2003.13663&#34;&gt;Revisiting &#34;Over-smoothing&#34; in Deep GCNs&lt;/a&gt; (CoRR 2020)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.DiffGroupNorm.html&#34;&gt;DiffGroupNorm&lt;/a&gt;&lt;/strong&gt; from Zhou &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2006.06972&#34;&gt;Towards Deeper Graph Neural Networks with Differentiable Group Normalization&lt;/a&gt; (NeurIPS 2020)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.tree_decomposition&#34;&gt;Tree Decomposition&lt;/a&gt;&lt;/strong&gt; from Jin &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1802.04364&#34;&gt;Junction Tree Variational Autoencoder for Molecular Graph Generation&lt;/a&gt; (ICML 2018)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.TGNMemory.html&#34;&gt;TGN&lt;/a&gt;&lt;/strong&gt; from Rossi &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2006.10637&#34;&gt;Temporal Graph Networks for Deep Learning on Dynamic Graphs&lt;/a&gt; (GRL+ 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/tgn.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.WLConv.html&#34;&gt;Weisfeiler Lehman Operator&lt;/a&gt;&lt;/strong&gt; from Weisfeiler and Lehman: &lt;a href=&#34;https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf&#34;&gt;A Reduction of a Graph to a Canonical Form and an Algebra Arising During this Reduction&lt;/a&gt; (Nauchno-Technicheskaya Informatsia 1968) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/wl_kernel.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.WLConvContinuous.html&#34;&gt;Continuous Weisfeiler Lehman Operator&lt;/a&gt;&lt;/strong&gt; from Togninalli &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1906.01277&#34;&gt;Wasserstein Weisfeiler-Lehman Graph Kernels&lt;/a&gt; (NeurIPS 2019)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.LabelPropagation.html&#34;&gt;Label Propagation&lt;/a&gt;&lt;/strong&gt; from Zhu and Ghahramani: &lt;a href=&#34;http://mlg.eng.cam.ac.uk/zoubin/papers/CMU-CALD-02-107.pdf&#34;&gt;Learning from Labeled and Unlabeled Data with Label Propagation&lt;/a&gt; (CMU-CALD 2002) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/label_prop.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.transforms.LocalDegreeProfile&#34;&gt;Local Degree Profile&lt;/a&gt;&lt;/strong&gt; from Cai and Wang: &lt;a href=&#34;https://arxiv.org/abs/1811.03508&#34;&gt;A Simple yet Effective Baseline for Non-attribute Graph Classification&lt;/a&gt; (CoRR 2018)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.CorrectAndSmooth.html&#34;&gt;CorrectAndSmooth&lt;/a&gt;&lt;/strong&gt; from Huang &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2010.13993&#34;&gt;Combining Label Propagation And Simple Models Out-performs Graph Neural Networks&lt;/a&gt; (CoRR 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/correct_and_smooth.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.functional.gini.html&#34;&gt;Gini&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.functional.bro.html&#34;&gt;BRO&lt;/a&gt;&lt;/strong&gt; regularization from Henderson &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2105.04854&#34;&gt;Improving Molecular Graph Neural Network Explainability with Orthonormalization and Induced Sparsity&lt;/a&gt; (ICML 2021)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.transforms.RootedEgoNets&#34;&gt;RootedEgoNets&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.transforms.RootedRWSubgraph&#34;&gt;RootedRWSubgraph&lt;/a&gt;&lt;/strong&gt; from Zhao &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2110.03753&#34;&gt;From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness&lt;/a&gt; (ICLR 2022)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.transforms.FeaturePropagation&#34;&gt;FeaturePropagation&lt;/a&gt;&lt;/strong&gt; from Rossi &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2111.12128&#34;&gt;On the Unreasonable Effectiveness of Feature Propagation in Learning on Graphs with Missing Node Features&lt;/a&gt; (CoRR 2021)&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;strong&gt;Scalable GNNs:&lt;/strong&gt; PyG supports the implementation of Graph Neural Networks that can scale to large-scale graphs. Such application is challenging since the entire graph, its associated features and the GNN parameters cannot fit into GPU memory. Many state-of-the-art scalability approaches tackle this challenge by sampling neighborhoods for mini-batch training, graph clustering and partitioning, or by using simplified GNN models. These approaches have been implemented in PyG, and can benefit from the above GNN layers, operators and models.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.NeighborLoader&#34;&gt;NeighborLoader&lt;/a&gt;&lt;/strong&gt; from Hamilton &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1706.02216&#34;&gt;Inductive Representation Learning on Large Graphs&lt;/a&gt; (NIPS 2017) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/reddit.py&#34;&gt;&lt;strong&gt;Example1&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/ogbn_products_sage.py&#34;&gt;&lt;strong&gt;Example2&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/ogbn_products_gat.py&#34;&gt;&lt;strong&gt;Example3&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/hetero/to_hetero_mag.py&#34;&gt;&lt;strong&gt;Example4&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.ClusterLoader&#34;&gt;ClusterGCN&lt;/a&gt;&lt;/strong&gt; from Chiang &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1905.07953&#34;&gt;Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks&lt;/a&gt; (KDD 2019) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/cluster_gcn_reddit.py&#34;&gt;&lt;strong&gt;Example1&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/cluster_gcn_ppi.py&#34;&gt;&lt;strong&gt;Example2&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.GraphSAINTSampler&#34;&gt;GraphSAINT&lt;/a&gt;&lt;/strong&gt; from Zeng &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/1907.04931&#34;&gt;GraphSAINT: Graph Sampling Based Inductive Learning Method&lt;/a&gt; (ICLR 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/graph_saint.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;Expand to see all implemented scalable GNNs...&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.ShaDowKHopSampler&#34;&gt;ShaDow&lt;/a&gt;&lt;/strong&gt; from Zeng &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2201.07858&#34;&gt;Decoupling the Depth and Scope of Graph Neural Networks&lt;/a&gt; (NeurIPS 2021) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/shadow.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.SIGN.html&#34;&gt;SIGN&lt;/a&gt;&lt;/strong&gt; from Rossi &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2004.11198&#34;&gt;SIGN: Scalable Inception Graph Neural Networks&lt;/a&gt; (CoRR 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/sign.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.loader.HGTLoader.html&#34;&gt;HGTLoader&lt;/a&gt;&lt;/strong&gt; from Hu &lt;em&gt;et al.&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2003.01332&#34;&gt;Heterogeneous Graph Transformer&lt;/a&gt; (WWW 2020) [&lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/raw/master/examples/hetero/to_hetero_mag.py&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;PyG is available for Python 3.7 to Python 3.11.&lt;/p&gt; &#xA;&lt;h3&gt;Anaconda&lt;/h3&gt; &#xA;&lt;p&gt;You can now install PyG via &lt;a href=&#34;https://anaconda.org/pyg/pyg&#34;&gt;Anaconda&lt;/a&gt; for all major OS/PyTorch/CUDA combinations ü§ó If you have not yet installed PyTorch, install it via &lt;code&gt;conda&lt;/code&gt; as described in the &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;official PyTorch documentation&lt;/a&gt;. Given that you have PyTorch installed (&lt;code&gt;&amp;gt;=1.8.0&lt;/code&gt;), simply run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda install pyg -c pyg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;PyPi&lt;/h3&gt; &#xA;&lt;p&gt;From &lt;strong&gt;PyG 2.3&lt;/strong&gt; onwards, you can install and use PyG &lt;strong&gt;without any external library&lt;/strong&gt; required except for PyTorch. For this, simply run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install torch_geometric&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;PyG 2.3 requires that at least PyTorch 1.12 is installed.&lt;/p&gt; &#xA;&lt;h3&gt;Additional Libraries&lt;/h3&gt; &#xA;&lt;p&gt;If you want to utilize the full set of features from PyG, there exists several additional libraries you may want to install:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/pyg-team/pyg-lib&#34;&gt;&lt;code&gt;pyg-lib&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;: Heterogeneous GNN operators and graph sampling routines&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/rusty1s/pytorch_scatter&#34;&gt;&lt;code&gt;torch-scatter&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;: Accelerated and efficient sparse reductions&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/rusty1s/pytorch_sparse&#34;&gt;&lt;code&gt;torch-sparse&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;: &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/advanced/sparse_tensor.html&#34;&gt;&lt;code&gt;SparseTensor&lt;/code&gt;&lt;/a&gt; support&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/rusty1s/pytorch_cluster&#34;&gt;&lt;code&gt;torch-cluster&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;: Graph clustering routines&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/rusty1s/pytorch_spline_conv&#34;&gt;&lt;code&gt;torch-spline-conv&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;: &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SplineConv.html&#34;&gt;&lt;code&gt;SplineConv&lt;/code&gt;&lt;/a&gt; support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;These packages come with their own CPU and GPU kernel implementations based on the &lt;a href=&#34;https://github.com/pytorch/extension-cpp&#34;&gt;PyTorch C++/CUDA/hip(ROCm) extension interface&lt;/a&gt;. For a basic usage of PyG, these dependencies are &lt;strong&gt;fully optional&lt;/strong&gt;. We recommend to start with a minimal installation, and install additional dependencies once you start to actually need them.&lt;/p&gt; &#xA;&lt;p&gt;For ease of installation of these extensions, we provide &lt;code&gt;pip&lt;/code&gt; wheels for all major OS/PyTorch/CUDA combinations, see &lt;a href=&#34;https://data.pyg.org/whl&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;PyTorch 2.0&lt;/h4&gt; &#xA;&lt;p&gt;To install the binaries for PyTorch 2.0.0, simply run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+${CUDA}.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;${CUDA}&lt;/code&gt; should be replaced by either &lt;code&gt;cpu&lt;/code&gt;, &lt;code&gt;cu117&lt;/code&gt;, or &lt;code&gt;cu118&lt;/code&gt; depending on your PyTorch installation.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;code&gt;cpu&lt;/code&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;code&gt;cu117&lt;/code&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;code&gt;cu118&lt;/code&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Linux&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;macOS&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;PyTorch 1.13&lt;/h4&gt; &#xA;&lt;p&gt;To install the binaries for PyTorch 1.13.0, simply run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-1.13.0+${CUDA}.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;${CUDA}&lt;/code&gt; should be replaced by either &lt;code&gt;cpu&lt;/code&gt;, &lt;code&gt;cu116&lt;/code&gt;, or &lt;code&gt;cu117&lt;/code&gt; depending on your PyTorch installation.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;code&gt;cpu&lt;/code&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;code&gt;cu116&lt;/code&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;code&gt;cu117&lt;/code&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Linux&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;macOS&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Binaries of older versions are also provided for PyTorch 1.4.0, PyTorch 1.5.0, PyTorch 1.6.0, PyTorch 1.7.0/1.7.1, PyTorch 1.8.0/1.8.1, PyTorch 1.9.0, PyTorch 1.10.0/1.10.1/1.10.2, PyTorch 1.11.0 and PyTorch 1.12.0/1.12.1 (following the same procedure). &lt;strong&gt;For older versions, you might need to explicitly specify the latest supported version number&lt;/strong&gt; or install via &lt;code&gt;pip install --no-index&lt;/code&gt; in order to prevent a manual installation from source. You can look up the latest supported version number &lt;a href=&#34;https://data.pyg.org/whl&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Nightly and Master&lt;/h3&gt; &#xA;&lt;p&gt;In case you want to experiment with the latest PyG features which are not fully released yet, either install the &lt;strong&gt;nightly version&lt;/strong&gt; of PyG via&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install pyg-nightly&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or install PyG &lt;strong&gt;from master&lt;/strong&gt; via&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install git+https://github.com/pyg-team/pytorch_geometric.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ROCm Wheels&lt;/h3&gt; &#xA;&lt;p&gt;The external &lt;a href=&#34;https://github.com/Looong01/pyg-rocm-build&#34;&gt;&lt;code&gt;pyg-rocm-build&lt;/code&gt; repository&lt;/a&gt; provides wheels and detailed instructions on how to install PyG for ROCm. If you have any questions about it, please open an issue &lt;a href=&#34;https://github.com/Looong01/pyg-rocm-build/issues&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Cite&lt;/h2&gt; &#xA;&lt;p&gt;Please cite &lt;a href=&#34;https://arxiv.org/abs/1903.02428&#34;&gt;our paper&lt;/a&gt; (and the respective papers of the methods used) if you use this code in your own work:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{Fey/Lenssen/2019,&#xA;  title={Fast Graph Representation Learning with {PyTorch Geometric}},&#xA;  author={Fey, Matthias and Lenssen, Jan E.},&#xA;  booktitle={ICLR Workshop on Representation Learning on Graphs and Manifolds},&#xA;  year={2019},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Feel free to &lt;a href=&#34;mailto:matthias.fey@tu-dortmund.de&#34;&gt;email us&lt;/a&gt; if you wish your work to be listed in the &lt;a href=&#34;https://pytorch-geometric.readthedocs.io/en/latest/external/resources.html&#34;&gt;external resources&lt;/a&gt;. If you notice anything unexpected, please open an &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/issues&#34;&gt;issue&lt;/a&gt; and let us know. If you have any questions or are missing a specific feature, feel free &lt;a href=&#34;https://github.com/pyg-team/pytorch_geometric/discussions&#34;&gt;to discuss them with us&lt;/a&gt;. We are motivated to constantly make PyG even better.&lt;/p&gt;</summary>
  </entry>
</feed>