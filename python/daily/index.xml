<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-08-22T01:38:11Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>facefusion/facefusion</title>
    <updated>2023-08-22T01:38:11Z</updated>
    <id>tag:github.com,2023-08-22:/facefusion/facefusion</id>
    <link href="https://github.com/facefusion/facefusion" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Next generation face swapper and enhancer&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FaceFusion&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Next generation face swapper and enhancer.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/facefusion/facefusion/actions?query=workflow:ci&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/facefusion/facefusion/ci.yml.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/license-MIT-green&#34; alt=&#34;License&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Preview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/facefusion/facefusion/master/.github/preview.png?sanitize=true&#34; alt=&#34;Preview&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Be aware, the installation needs technical skills and is not for beginners. Please do not open platform and installation related issues on GitHub. We have a very helpful &lt;a href=&#34;https://join.facefusion.io&#34;&gt;Discord&lt;/a&gt; community that will guide you to install FaceFusion.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.facefusion.io/installation/basic&#34;&gt;Basic&lt;/a&gt; - It is more likely to work on your computer, but will be quite slow&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.facefusion.io/installation/acceleration&#34;&gt;Acceleration&lt;/a&gt; - Unleash the full potential of your CPU and GPU&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Start the program with arguments:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python run.py [options]&#xA;&#xA;-h, --help                                                                                       show this help message and exit&#xA;-s SOURCE_PATH, --source SOURCE_PATH                                                             select a source image&#xA;-t TARGET_PATH, --target TARGET_PATH                                                             select a target image or video&#xA;-o OUTPUT_PATH, --output OUTPUT_PATH                                                             specify the output file or directory&#xA;--frame-processors FRAME_PROCESSORS [FRAME_PROCESSORS ...]                                       choose from the available frame processors (choices: face_enhancer, face_swapper, frame_enhancer, ...)&#xA;--ui-layouts UI_LAYOUTS [UI_LAYOUTS ...]                                                         choose from the available ui layouts (choices: benchmark, default, ...)&#xA;--keep-fps                                                                                       preserve the frames per second (fps) of the target&#xA;--keep-temp                                                                                      retain temporary frames after processing&#xA;--skip-audio                                                                                     omit audio from the target&#xA;--face-recognition {reference,many}                                                              specify the method for face recognition&#xA;--face-analyser-direction {left-right,right-left,top-bottom,bottom-top,small-large,large-small}  specify the direction used for face analysis&#xA;--face-analyser-age {child,teen,adult,senior}                                                    specify the age used for face analysis&#xA;--face-analyser-gender {male,female}                                                             specify the gender used for face analysis&#xA;--reference-face-position REFERENCE_FACE_POSITION                                                specify the position of the reference face&#xA;--reference-face-distance REFERENCE_FACE_DISTANCE                                                specify the distance between the reference face and the target face&#xA;--reference-frame-number REFERENCE_FRAME_NUMBER                                                  specify the number of the reference frame&#xA;--trim-frame-start TRIM_FRAME_START                                                              specify the start frame for extraction&#xA;--trim-frame-end TRIM_FRAME_END                                                                  specify the end frame for extraction&#xA;--temp-frame-format {jpg,png}                                                                    specify the image format used for frame extraction&#xA;--temp-frame-quality [0-100]                                                                     specify the image quality used for frame extraction&#xA;--output-video-encoder {libx264,libx265,libvpx-vp9,h264_nvenc,hevc_nvenc}                        specify the encoder used for the output video&#xA;--output-video-quality [0-100]                                                                   specify the quality used for the output video&#xA;--max-memory MAX_MEMORY                                                                          specify the maximum amount of ram to be used (in gb)&#xA;--execution-providers {cpu} [{cpu} ...]                                                          choose from the available execution providers (choices: cpu, ...)&#xA;--execution-thread-count EXECUTION_THREAD_COUNT                                                  specify the number of execution threads&#xA;--execution-queue-count EXECUTION_QUEUE_COUNT                                                    specify the number of execution queries&#xA;-v, --version                                                                                    show program&#39;s version number and exit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Using the &lt;code&gt;-s/--source&lt;/code&gt;, &lt;code&gt;-t/--target&lt;/code&gt; and &lt;code&gt;-o/--output&lt;/code&gt; argument will run the program in headless mode.&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This software is meant to be a productive contribution to the rapidly growing AI-generated media industry. It will help artists with tasks such as animating a custom character or using the character as a model for clothing etc.&lt;/p&gt; &#xA;&lt;p&gt;The developers of this software are aware of its possible unethical applications and are committed to take preventative measures against them. It has a built-in check which prevents the program from working on inappropriate media including but not limited to nudity, graphic content, sensitive material such as war footage etc. We will continue to develop this project in the positive direction while adhering to law and ethics. This project may be shut down or include watermarks on the output if requested by law.&lt;/p&gt; &#xA;&lt;p&gt;Users of this software are expected to use this software responsibly while abiding the local law. If face of a real person is being used, users are suggested to get consent from the concerned person and clearly mention that it is a deepfake when posting content online. Developers of this software will not be responsible for actions of end-users.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Read the &lt;a href=&#34;https://docs.facefusion.io&#34;&gt;documentation&lt;/a&gt; for a deep dive.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>KianBrose/smtp_mail_bot_server</title>
    <updated>2023-08-22T01:38:11Z</updated>
    <id>tag:github.com,2023-08-22:/KianBrose/smtp_mail_bot_server</id>
    <link href="https://github.com/KianBrose/smtp_mail_bot_server" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A repository for automating incoming mail messages&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Custom domain SMTP mail bot server&lt;/h1&gt; &#xA;&lt;p&gt;Long name isn&#39;t it, it&#39;s basically just a program meant to be able to read email contents from one of your custom domains/websites so that you can automate something with it, like a verification bot or something idk up to you&lt;/p&gt; &#xA;&lt;h2&gt;Why&lt;/h2&gt; &#xA;&lt;p&gt;Long story short, refferal type giveaways were pissing me off since they&#39;re unfair to people with few friends when compared to influencers that abuse the refferal system, so a modified version of this was used to&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://www.youtube.com/KianBrose&#34;&gt;Full video about this project available here&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;I made a video about this, you should watch it &lt;a href=&#34;https://www.youtube.com/KianBrose&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Read mail from a custom domain&lt;/li&gt; &#xA; &lt;li&gt;Fully self hosted, no rate limits, payments or restrictions&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Deployment&lt;/h2&gt; &#xA;&lt;p&gt;To use this you need to buy a domain. Then add the following DNS records:&lt;/p&gt; &#xA;&lt;p&gt;I&#39;ll assume that you are running this with&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Public ip: 210.210.210.210 (You can find yours here &lt;a href=&#34;https://4.ident.me/&#34;&gt;https://4.ident.me/&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Localhost ip: 192.168.0.10 (Open a console and write &lt;code&gt;ip a&lt;/code&gt; or &lt;code&gt;ifconfig&lt;/code&gt; on mac/linux, and &lt;code&gt;ipconfig&lt;/code&gt; on windows. It starts with 192.168 and is naer your public ip)&lt;/li&gt; &#xA; &lt;li&gt;Domain: example.com&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;DNS records&lt;/h3&gt; &#xA;&lt;p&gt;Add the following DNS records on your registrar, I recommend &lt;a href=&#34;https://cloudflare.com/&#34;&gt;cloudflare&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Type: A&#xA;Name: example.com&#xA;Content/Value: 210.210.210.210&#xA;TTL: Automatic&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Type: MX&#xA;Name: example.com&#xA;Content/Value: example.com&#xA;Priority: 10&#xA;TTL: Automatic&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Port forwarding&lt;/h3&gt; &#xA;&lt;p&gt;On whatever computer you are running you will have to make sure your router is port forwarded for the port 25 and routes its traffic to the private ip of where the code will run. If it will run on 192.168.0.10, port forward 192.168.0.10 port 25. If you don&#39;t know how to do it your ISP might be blocking you or your router is just bad, there are tons of guides online, even on my channel.&lt;/p&gt; &#xA;&lt;h3&gt;Code changes&lt;/h3&gt; &#xA;&lt;p&gt;In the &lt;code&gt;handle_RCPT&lt;/code&gt; function, change the domain &lt;code&gt;kianbrose.com&lt;/code&gt; to &lt;code&gt;example.com&lt;/code&gt; (obviously yours in there)&lt;/p&gt; &#xA;&lt;p&gt;At the bottom of the script, change the &lt;code&gt;hostname=&#39;192.168.x.x&#39;&lt;/code&gt; set it to your own private ipv4&lt;/p&gt; &#xA;&lt;h2&gt;Running&lt;/h2&gt; &#xA;&lt;p&gt;It will probably complain if you don&#39;t use sudo permissions, run as admin on windows or on mac/linux &lt;code&gt;sudo python main.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Authors&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/KianBrose&#34;&gt;KianBrose (YouTube)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>dot-agent/openagent</title>
    <updated>2023-08-22T01:38:11Z</updated>
    <id>tag:github.com,2023-08-22:/dot-agent/openagent</id>
    <link href="https://github.com/dot-agent/openagent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Microservices approach to AGI. Modular components for AI apps or AGI agents. (... and solving some wicked LLM problems like ⚡ 2X faster LLaMA 2)&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Smilies/Grinning%20Face.png&#34; alt=&#34;Grinning Face&#34; width=&#34;50&#34; height=&#34;50&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Smilies/Robot.png&#34; alt=&#34;Robot&#34; width=&#34;175&#34; height=&#34;175&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Hey there, Friend! This project is still in the &#34;just for friends&#34; stage. If you want to see what we&#39;re messing with and have some thoughts, take a look at the code. Would love your thoughts or contributions .&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h1 id=&#34;-why-we-started-dotagent-&#34;&gt;&lt;strong&gt;Why we started dotagent?&lt;/strong&gt;&lt;/h1&gt; &#xA;&lt;p&gt;We have a dream: Open and democratic AGI , free from blackbox censorship and control imposed by private corporations under the disguise of alignment. We once had this with the web but lost this liberty to the corporate giants of the mobile era, whose duopoly has imposed a fixed 30% tax on all developers.&lt;/p&gt; &#xA;&lt;p&gt;Our moonshot : A network of domain specific AI agents , collaborating so seamlessly that it feels like AGI. Contribute to democratizing the LAST technological frontier.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/dotagent-ai/openagent/raw/911fa336d5c5647ccbd45471f6bc5c2f22d1f45d/assets/divider.gif&#34; alt=&#34;-----------------------------------------------------&#34;&gt;&lt;/p&gt; &#xA;&lt;h1 id=&#34;what-is-openagent-&#34;&gt;What is OpenAgent ?&lt;/h1&gt; &#xA;&lt;p&gt;OpenAgent is a library of modular components and an orchestration framework. Inspired by a microservices approach, it gives developers all the components they need to build robust, stable &amp;amp; reliable AI applications and experimental autonomous agents.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/dot-agent/openagent/main/assets/openagent_features.png&#34; alt=&#34;-----------------------------------------------------&#34;&gt;&lt;/p&gt; &#xA;&lt;h2 id=&#34;modularity&#34;&gt; 🧱 Modularity&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Multiplatform:&lt;/strong&gt;&lt;/em&gt; Agents do not have to run on a single location or machine. Different components can run across various platforms, including the cloud, personal computers, or mobile devices.&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Extensible:&lt;/strong&gt;&lt;/em&gt; If you know how to do something in Python or plain English, you can integrate it with OpenAgent.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2 id=&#34;guardrails&#34;&gt; 🚧 Guardrails&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Set clear boundaries:&lt;/strong&gt;&lt;/em&gt; Users can precisely outline what their agent can and cannot do. This safeguard guarantees that the agent remains a dynamic, self-improving system without overstepping defined boundaries.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2 id=&#34;greater-control-with-structured-outputs&#34;&gt;🏗️ Greater control with Structured outputs&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;&lt;strong&gt;More Effective Than Chaining or Prompting:&lt;/strong&gt;&lt;/em&gt; The prompt compiler unlocks the next level of prompt engineering, providing far greater control over LLMs than few-shot prompting or traditional chaining methods.&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Superpowers to Prompt Engineers:&lt;/strong&gt;&lt;/em&gt; It gives full power of prompt engineering, aligning with how LLMs actually process text. This understanding enables you to precisely control the output, defining the exact response structure and instructing LLMs on how to generate responses.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2 id=&#34;powerful-prompt-compiler&#34;&gt;🏭 Powerful Prompt Compiler&lt;/h2&gt; &#xA;&lt;p&gt;The philosophy is to handle more processing at compile time and maintain better session with LLMs.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Pre-compiling prompts:&lt;/strong&gt;&lt;/em&gt; By handling basic prompt processing at compile time, unnecessary redundant LLM processing are eliminated.&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Session state with LLM:&lt;/strong&gt;&lt;/em&gt; Maintaining state with LLMs and reusing KV caches can eliminate many redundant generations and significantly speed up the process for longer and more complex prompts. &lt;em&gt;(only for opensource models)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Optimized tokens:&lt;/strong&gt;&lt;/em&gt; Compiler can transform many output tokens into prompt token batches, which are cheaper and faster. The structure of the template can dynamically guide the probabilities of subsequent tokens, ensuring alignment with the template and optimized tokenization . &lt;em&gt;&lt;strong&gt;(only for opensource models)&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;&lt;strong&gt;&lt;strong&gt;Speculative sampling (WIP):&lt;/strong&gt;&lt;/strong&gt;&lt;/em&gt; You can enhance token generation speed in a large language model by using a smaller model as an assistant. The method relies on an algorithm that generates multiple tokens per transformer call using a faster draft model. This can lead to upto 3x speedup in token generation .&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2 id=&#34;-containerized-scalable-&#34;&gt;&lt;strong&gt;📦 Containerized &amp;amp; Scalable&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;.🤖 &lt;em&gt;&lt;strong&gt;files :&lt;/strong&gt;&lt;/em&gt; Agents can be effortlessly exported into a simple .agent or .🤖 file, allowing them to run in any environment.&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Agentbox (optional):&lt;/strong&gt;&lt;/em&gt; Agents should be able to optimize computing resources inside a sandbox. You can use Agentbox locally or on a cloud with a simple API, with cloud agentbox offering additional control and safety.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/dotagent-ai/openagent/raw/911fa336d5c5647ccbd45471f6bc5c2f22d1f45d/assets/divider.gif&#34; alt=&#34;-----------------------------------------------------&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Step 1: Install Poetry&lt;/h3&gt; &#xA;&lt;p&gt;Poetry is used for dependency management in this project. Please note that Poetry has some compatibility issues with Conda.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;pip install poetry&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Step 2: Lock the Dependencies&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;poetry lock&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Step 3: Install the Dependencies&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;poetry install&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Common Errors&lt;/h2&gt; &#xA;&lt;h3&gt;SQLite3 Version Error&lt;/h3&gt; &#xA;&lt;p&gt;If you encounter an error like:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Your system has an unsupported version of sqlite3. Chroma requires sqlite3 &amp;gt;= 3.35.0.&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is a very common issue with Chroma DB. You can find instructions to resolve this in the &lt;a href=&#34;https://docs.trychroma.com/troubleshooting#sqlite&#34;&gt;Chroma DB tutorial&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Code for a full-stack chat app, complete with UI.&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import openagent.compiler as compiler&#xA;from openagent.compiler._program import Log&#xA;from openagent import memory&#xA;import chainlit as ui&#xA;from dotenv import load_dotenv&#xA;load_dotenv()&#xA;&#xA;@ui.on_chat_start&#xA;def start_chat():&#xA;   compiler.llm = compiler.llms.OpenAI(model=&#34;gpt-3.5-turbo&#34;)&#xA;&#xA;&#xA;class ChatLog(Log):&#xA;   def append(self, entry):&#xA;       super().append(entry)&#xA;       print(entry)&#xA;       is_end = entry[&#34;type&#34;] == &#34;end&#34;&#xA;       is_assistant = entry[&#34;name&#34;] == &#34;assistant&#34;&#xA;       if is_end and is_assistant:&#xA;           ui.run_sync(ui.Message(content=entry[&#34;new_prefix&#34;]).send())&#xA;&#xA;&#xA;memory = memory.SimpleMemory()&#xA;&#xA;@ui.on_message&#xA;async def main(message: str):&#xA;   program = compiler(&#xA;       &#34;&#34;&#34;&#xA;       {{#system~}}&#xA;       You are a helpful assistant&#xA;       {{~/system}}&#xA;&#xA;       {{~#geneach &#39;conversation&#39; stop=False}}&#xA;       {{#user~}}&#xA;       {{set &#39;this.user_text&#39; (await &#39;user_text&#39;)  hidden=False}}&#xA;       {{~/user}}&#xA;&#xA;       {{#assistant~}}&#xA;       {{gen &#39;this.ai_text&#39; temperature=0 max_tokens=300}}&#xA;       {{~/assistant}}&#xA;       {{~/geneach}}&#34;&#34;&#34;, memory = memory&#xA;   )&#xA;&#xA;   program(user_text=message, log=ChatLog())&#xA;&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The UI will look something like this: &lt;img src=&#34;https://raw.githubusercontent.com/dot-agent/openagent/main/assets/chatapp.png&#34; alt=&#34;-----------------------------------------------------&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt;</summary>
  </entry>
</feed>