<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-05-31T01:34:41Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>coleam00/local-ai-packaged</title>
    <updated>2025-05-31T01:34:41Z</updated>
    <id>tag:github.com,2025-05-31:/coleam00/local-ai-packaged</id>
    <link href="https://github.com/coleam00/local-ai-packaged" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Run all your local AI together in one package - Ollama, Supabase, n8n, Open WebUI, and more!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Self-hosted AI Package&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Self-hosted AI Package&lt;/strong&gt; is an open, docker compose template that quickly bootstraps a fully featured Local AI and Low Code development environment including Ollama for your local LLMs, Open WebUI for an interface to chat with your N8N agents, and Supabase for your database, vector store, and authentication.&lt;/p&gt; &#xA;&lt;p&gt;This is Cole&#39;s version with a couple of improvements and the addition of Supabase, Open WebUI, Flowise, Neo4j, Langfuse, SearXNG, and Caddy! Also, the local RAG AI Agent workflows from the video will be automatically in your n8n instance if you use this setup instead of the base one provided by n8n!&lt;/p&gt; &#xA;&lt;h2&gt;Important Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://thinktank.ottomator.ai/c/local-ai/18&#34;&gt;Local AI community&lt;/a&gt; forum over in the oTTomator Think Tank&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/users/coleam00/projects/2/views/1&#34;&gt;GitHub Kanban board&lt;/a&gt; for feature implementation and bug squashing.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/n8n-io/self-hosted-ai-starter-kit&#34;&gt;Original Local AI Starter Kit&lt;/a&gt; by the n8n team&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Download my N8N + OpenWebUI integration &lt;a href=&#34;https://openwebui.com/f/coleam/n8n_pipe/&#34;&gt;directly on the Open WebUI site.&lt;/a&gt; (more instructions below)&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/n8n-io/self-hosted-ai-starter-kit/main/assets/n8n-demo.gif&#34; alt=&#34;n8n.io - Screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Curated by &lt;a href=&#34;https://github.com/n8n-io&#34;&gt;https://github.com/n8n-io&lt;/a&gt; and &lt;a href=&#34;https://github.com/coleam00&#34;&gt;https://github.com/coleam00&lt;/a&gt;, it combines the self-hosted n8n platform with a curated list of compatible AI products and components to quickly get started with building self-hosted AI workflows.&lt;/p&gt; &#xA;&lt;h3&gt;What’s included&lt;/h3&gt; &#xA;&lt;p&gt;✅ &lt;a href=&#34;https://n8n.io/&#34;&gt;&lt;strong&gt;Self-hosted n8n&lt;/strong&gt;&lt;/a&gt; - Low-code platform with over 400 integrations and advanced AI components&lt;/p&gt; &#xA;&lt;p&gt;✅ &lt;a href=&#34;https://supabase.com/&#34;&gt;&lt;strong&gt;Supabase&lt;/strong&gt;&lt;/a&gt; - Open source database as a service - most widely used database for AI agents&lt;/p&gt; &#xA;&lt;p&gt;✅ &lt;a href=&#34;https://ollama.com/&#34;&gt;&lt;strong&gt;Ollama&lt;/strong&gt;&lt;/a&gt; - Cross-platform LLM platform to install and run the latest local LLMs&lt;/p&gt; &#xA;&lt;p&gt;✅ &lt;a href=&#34;https://openwebui.com/&#34;&gt;&lt;strong&gt;Open WebUI&lt;/strong&gt;&lt;/a&gt; - ChatGPT-like interface to privately interact with your local models and N8N agents&lt;/p&gt; &#xA;&lt;p&gt;✅ &lt;a href=&#34;https://flowiseai.com/&#34;&gt;&lt;strong&gt;Flowise&lt;/strong&gt;&lt;/a&gt; - No/low code AI agent builder that pairs very well with n8n&lt;/p&gt; &#xA;&lt;p&gt;✅ &lt;a href=&#34;https://qdrant.tech/&#34;&gt;&lt;strong&gt;Qdrant&lt;/strong&gt;&lt;/a&gt; - Open source, high performance vector store with an comprehensive API. Even though you can use Supabase for RAG, this was kept unlike Postgres since it&#39;s faster than Supabase so sometimes is the better option.&lt;/p&gt; &#xA;&lt;p&gt;✅ &lt;a href=&#34;https://neo4j.com/&#34;&gt;&lt;strong&gt;Neo4j&lt;/strong&gt;&lt;/a&gt; - Knowledge graph engine that powers tools like GraphRAG, LightRAG, and Graphiti&lt;/p&gt; &#xA;&lt;p&gt;✅ &lt;a href=&#34;https://searxng.org/&#34;&gt;&lt;strong&gt;SearXNG&lt;/strong&gt;&lt;/a&gt; - Open source, free internet metasearch engine which aggregates results from up to 229 search services. Users are neither tracked nor profiled, hence the fit with the local AI package.&lt;/p&gt; &#xA;&lt;p&gt;✅ &lt;a href=&#34;https://caddyserver.com/&#34;&gt;&lt;strong&gt;Caddy&lt;/strong&gt;&lt;/a&gt; - Managed HTTPS/TLS for custom domains&lt;/p&gt; &#xA;&lt;p&gt;✅ &lt;a href=&#34;https://langfuse.com/&#34;&gt;&lt;strong&gt;Langfuse&lt;/strong&gt;&lt;/a&gt; - Open source LLM engineering platform for agent observability&lt;/p&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;Before you begin, make sure you have the following software installed:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;Python&lt;/a&gt; - Required to run the setup script&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://desktop.github.com/&#34;&gt;Git/GitHub Desktop&lt;/a&gt; - For easy repository management&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.docker.com/products/docker-desktop/&#34;&gt;Docker/Docker Desktop&lt;/a&gt; - Required to run all services&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Clone the repository and navigate to the project directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/coleam00/local-ai-packaged.git&#xA;cd local-ai-packaged&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Before running the services, you need to set up your environment variables for Supabase following their &lt;a href=&#34;https://supabase.com/docs/guides/self-hosting/docker#securing-your-services&#34;&gt;self-hosting guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Make a copy of &lt;code&gt;.env.example&lt;/code&gt; and rename it to &lt;code&gt;.env&lt;/code&gt; in the root directory of the project&lt;/li&gt; &#xA; &lt;li&gt;Set the following required environment variables: &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;############&#xA;# N8N Configuration&#xA;############&#xA;N8N_ENCRYPTION_KEY=&#xA;N8N_USER_MANAGEMENT_JWT_SECRET=&#xA;&#xA;############&#xA;# Supabase Secrets&#xA;############&#xA;POSTGRES_PASSWORD=&#xA;JWT_SECRET=&#xA;ANON_KEY=&#xA;SERVICE_ROLE_KEY=&#xA;DASHBOARD_USERNAME=&#xA;DASHBOARD_PASSWORD=&#xA;POOLER_TENANT_ID=&#xA;&#xA;############&#xA;# Neo4j Secrets&#xA;############   &#xA;NEO4J_AUTH=&#xA;&#xA;############&#xA;# Langfuse credentials&#xA;############&#xA;&#xA;CLICKHOUSE_PASSWORD=&#xA;MINIO_ROOT_PASSWORD=&#xA;LANGFUSE_SALT=&#xA;NEXTAUTH_SECRET=&#xA;ENCRYPTION_KEY=  &#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT] Make sure to generate secure random values for all secrets. Never use the example values in production.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Set the following environment variables if deploying to production, otherwise leave commented: &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;############&#xA;# Caddy Config&#xA;############&#xA;&#xA;N8N_HOSTNAME=n8n.yourdomain.com&#xA;WEBUI_HOSTNAME=:openwebui.yourdomain.com&#xA;FLOWISE_HOSTNAME=:flowise.yourdomain.com&#xA;SUPABASE_HOSTNAME=:supabase.yourdomain.com&#xA;OLLAMA_HOSTNAME=:ollama.yourdomain.com&#xA;SEARXNG_HOSTNAME=searxng.yourdomain.com&#xA;NEO4J_HOSTNAME=neo4j.yourdomain.com&#xA;LETSENCRYPT_EMAIL=your-email-address&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;The project includes a &lt;code&gt;start_services.py&lt;/code&gt; script that handles starting both the Supabase and local AI services. The script accepts a &lt;code&gt;--profile&lt;/code&gt; flag to specify which GPU configuration to use.&lt;/p&gt; &#xA;&lt;h3&gt;For Nvidia GPU users&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python start_services.py --profile gpu-nvidia&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] If you have not used your Nvidia GPU with Docker before, please follow the &lt;a href=&#34;https://github.com/ollama/ollama/raw/main/docs/docker.md&#34;&gt;Ollama Docker instructions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;For AMD GPU users on Linux&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python start_services.py --profile gpu-amd&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;For Mac / Apple Silicon users&lt;/h3&gt; &#xA;&lt;p&gt;If you&#39;re using a Mac with an M1 or newer processor, you can&#39;t expose your GPU to the Docker instance, unfortunately. There are two options in this case:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Run the starter kit fully on CPU:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python start_services.py --profile cpu&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run Ollama on your Mac for faster inference, and connect to that from the n8n instance:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python start_services.py --profile none&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you want to run Ollama on your mac, check the &lt;a href=&#34;https://ollama.com/&#34;&gt;Ollama homepage&lt;/a&gt; for installation instructions.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;For Mac users running OLLAMA locally&lt;/h4&gt; &#xA;&lt;p&gt;If you&#39;re running OLLAMA locally on your Mac (not in Docker), you need to modify the OLLAMA_HOST environment variable in the n8n service configuration. Update the x-n8n section in your Docker Compose file as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;x-n8n: &amp;amp;service-n8n&#xA;  # ... other configurations ...&#xA;  environment:&#xA;    # ... other environment variables ...&#xA;    - OLLAMA_HOST=host.docker.internal:11434&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Additionally, after you see &#34;Editor is now accessible via: &lt;a href=&#34;http://localhost:5678/&#34;&gt;http://localhost:5678/&lt;/a&gt;&#34;:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Head to &lt;a href=&#34;http://localhost:5678/home/credentials&#34;&gt;http://localhost:5678/home/credentials&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Click on &#34;Local Ollama service&#34;&lt;/li&gt; &#xA; &lt;li&gt;Change the base URL to &#34;&lt;a href=&#34;http://host.docker.internal:11434/&#34;&gt;http://host.docker.internal:11434/&lt;/a&gt;&#34;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;For everyone else&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python start_services.py --profile cpu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Deploying to the Cloud&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites for the below steps&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Linux machine (preferably Unbuntu) with Nano, Git, and Docker installed&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Extra steps&lt;/h3&gt; &#xA;&lt;p&gt;Before running the above commands to pull the repo and install everything:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Run the commands as root to open up the necessary ports:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ufw enable&lt;/li&gt; &#xA;   &lt;li&gt;ufw allow 8000 &amp;amp;&amp;amp; ufw allow 3000 &amp;amp;&amp;amp; ufw allow 5678 &amp;amp;&amp;amp; ufw allow 3002 &amp;amp;&amp;amp; ufw allow 80 &amp;amp;&amp;amp; ufw allow 443&lt;/li&gt; &#xA;   &lt;li&gt;ufw allow 3001 (if you want to expose Flowise, you will have to set up the &lt;a href=&#34;https://docs.flowiseai.com/configuration/environment-variables&#34;&gt;environment variables&lt;/a&gt; to enable authentication)&lt;/li&gt; &#xA;   &lt;li&gt;ufw allow 8080 (if you want to expose SearXNG)&lt;/li&gt; &#xA;   &lt;li&gt;ufw allow 11434 (if you want to expose Ollama)&lt;/li&gt; &#xA;   &lt;li&gt;ufw reload&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Set up A records for your DNS provider to point your subdomains you&#39;ll set up in the .env file for Caddy to the IP address of your cloud instance.&lt;/p&gt; &lt;p&gt;For example, A record to point n8n to [cloud instance IP] for n8n.yourdomain.com&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;⚡️ Quick start and usage&lt;/h2&gt; &#xA;&lt;p&gt;The main component of the self-hosted AI starter kit is a docker compose file pre-configured with network and disk so there isn’t much else you need to install. After completing the installation steps above, follow the steps below to get started.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Open &lt;a href=&#34;http://localhost:5678/&#34;&gt;http://localhost:5678/&lt;/a&gt; in your browser to set up n8n. You’ll only have to do this once. You are NOT creating an account with n8n in the setup here, it is only a local account for your instance!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open the included workflow: &lt;a href=&#34;http://localhost:5678/workflow/vTN9y2dLXqTiDfPT&#34;&gt;http://localhost:5678/workflow/vTN9y2dLXqTiDfPT&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create credentials for every service:&lt;/p&gt; &lt;p&gt;Ollama URL: &lt;a href=&#34;http://ollama:11434&#34;&gt;http://ollama:11434&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Postgres (through Supabase): use DB, username, and password from .env. IMPORTANT: Host is &#39;db&#39; Since that is the name of the service running Supabase&lt;/p&gt; &lt;p&gt;Qdrant URL: &lt;a href=&#34;http://qdrant:6333&#34;&gt;http://qdrant:6333&lt;/a&gt; (API key can be whatever since this is running locally)&lt;/p&gt; &lt;p&gt;Google Drive: Follow &lt;a href=&#34;https://docs.n8n.io/integrations/builtin/credentials/google/&#34;&gt;this guide from n8n&lt;/a&gt;. Don&#39;t use localhost for the redirect URI, just use another domain you have, it will still work! Alternatively, you can set up &lt;a href=&#34;https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.localfiletrigger/&#34;&gt;local file triggers&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Select &lt;strong&gt;Test workflow&lt;/strong&gt; to start running the workflow.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If this is the first time you’re running the workflow, you may need to wait until Ollama finishes downloading Llama3.1. You can inspect the docker console logs to check on the progress.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Make sure to toggle the workflow as active and copy the &#34;Production&#34; webhook URL!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open &lt;a href=&#34;http://localhost:3000/&#34;&gt;http://localhost:3000/&lt;/a&gt; in your browser to set up Open WebUI. You’ll only have to do this once. You are NOT creating an account with Open WebUI in the setup here, it is only a local account for your instance!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Go to Workspace -&amp;gt; Functions -&amp;gt; Add Function -&amp;gt; Give name + description then paste in the code from &lt;code&gt;n8n_pipe.py&lt;/code&gt;&lt;/p&gt; &lt;p&gt;The function is also &lt;a href=&#34;https://openwebui.com/f/coleam/n8n_pipe/&#34;&gt;published here on Open WebUI&#39;s site&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Click on the gear icon and set the n8n_url to the production URL for the webhook you copied in a previous step.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Toggle the function on and now it will be available in your model dropdown in the top left!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;To open n8n at any time, visit &lt;a href=&#34;http://localhost:5678/&#34;&gt;http://localhost:5678/&lt;/a&gt; in your browser. To open Open WebUI at any time, visit &lt;a href=&#34;http://localhost:3000/&#34;&gt;http://localhost:3000/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;With your n8n instance, you’ll have access to over 400 integrations and a suite of basic and advanced AI nodes such as &lt;a href=&#34;https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/&#34;&gt;AI Agent&lt;/a&gt;, &lt;a href=&#34;https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.text-classifier/&#34;&gt;Text classifier&lt;/a&gt;, and &lt;a href=&#34;https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.information-extractor/&#34;&gt;Information Extractor&lt;/a&gt; nodes. To keep everything local, just remember to use the Ollama node for your language model and Qdrant as your vector store.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] This starter kit is designed to help you get started with self-hosted AI workflows. While it’s not fully optimized for production environments, it combines robust components that work well together for proof-of-concept projects. You can customize it to meet your specific needs&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Upgrading&lt;/h2&gt; &#xA;&lt;p&gt;To update all containers to their latest versions (n8n, Open WebUI, etc.), run these commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Stop all services&#xA;docker compose -p localai -f docker-compose.yml --profile &amp;lt;your-profile&amp;gt; down&#xA;&#xA;# Pull latest versions of all containers&#xA;docker compose -p localai -f docker-compose.yml --profile &amp;lt;your-profile&amp;gt; pull&#xA;&#xA;# Start services again with your desired profile&#xA;python start_services.py --profile &amp;lt;your-profile&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Replace &lt;code&gt;&amp;lt;your-profile&amp;gt;&lt;/code&gt; with one of: &lt;code&gt;cpu&lt;/code&gt;, &lt;code&gt;gpu-nvidia&lt;/code&gt;, &lt;code&gt;gpu-amd&lt;/code&gt;, or &lt;code&gt;none&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Note: The &lt;code&gt;start_services.py&lt;/code&gt; script itself does not update containers - it only restarts them or pulls them if you are downloading these containers for the first time. To get the latest versions, you must explicitly run the commands above.&lt;/p&gt; &#xA;&lt;h2&gt;Troubleshooting&lt;/h2&gt; &#xA;&lt;p&gt;Here are solutions to common issues you might encounter:&lt;/p&gt; &#xA;&lt;h3&gt;Supabase Issues&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Supabase Pooler Restarting&lt;/strong&gt;: If the supabase-pooler container keeps restarting itself, follow the instructions in &lt;a href=&#34;https://github.com/supabase/supabase/issues/30210#issuecomment-2456955578&#34;&gt;this GitHub issue&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Supabase Analytics Startup Failure&lt;/strong&gt;: If the supabase-analytics container fails to start after changing your Postgres password, delete the folder &lt;code&gt;supabase/docker/volumes/db/data&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;If using Docker Desktop&lt;/strong&gt;: Go into the Docker settings and make sure &#34;Expose daemon on tcp://localhost:2375 without TLS&#34; is turned on&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Supabase Service Unavailable&lt;/strong&gt; - Make sure you don&#39;t have an &#34;@&#34; character in your Postgres password! If the connection to the kong container is working (the container logs say it is receiving requests from n8n) but n8n says it cannot connect, this is generally the problem from what the community has shared. Other characters might not be allowed too, the @ symbol is just the one I know for sure!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;GPU Support Issues&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Windows GPU Support&lt;/strong&gt;: If you&#39;re having trouble running Ollama with GPU support on Windows with Docker Desktop:&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Open Docker Desktop settings&lt;/li&gt; &#xA;   &lt;li&gt;Enable WSL 2 backend&lt;/li&gt; &#xA;   &lt;li&gt;See the &lt;a href=&#34;https://docs.docker.com/desktop/features/gpu/&#34;&gt;Docker GPU documentation&lt;/a&gt; for more details&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Linux GPU Support&lt;/strong&gt;: If you&#39;re having trouble running Ollama with GPU support on Linux, follow the &lt;a href=&#34;https://github.com/ollama/ollama/raw/main/docs/docker.md&#34;&gt;Ollama Docker instructions&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;👓 Recommended reading&lt;/h2&gt; &#xA;&lt;p&gt;n8n is full of useful content for getting started quickly with its AI concepts and nodes. If you run into an issue, go to &lt;a href=&#34;https://raw.githubusercontent.com/coleam00/local-ai-packaged/main/#support&#34;&gt;support&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.n8n.io/ai-agents/&#34;&gt;AI agents for developers: from theory to practice with n8n&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.n8n.io/advanced-ai/intro-tutorial/&#34;&gt;Tutorial: Build an AI workflow in n8n&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.n8n.io/advanced-ai/langchain/langchain-n8n/&#34;&gt;Langchain Concepts in n8n&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.n8n.io/advanced-ai/examples/agent-chain-comparison/&#34;&gt;Demonstration of key differences between agents and chains&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.n8n.io/advanced-ai/examples/understand-vector-databases/&#34;&gt;What are vector databases?&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🎥 Video walkthrough&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/pOsO40HSbOo&#34;&gt;Cole&#39;s Guide to the Local AI Starter Kit&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🛍️ More AI templates&lt;/h2&gt; &#xA;&lt;p&gt;For more AI workflow ideas, visit the &lt;a href=&#34;https://n8n.io/workflows/?categories=AI&#34;&gt;&lt;strong&gt;official n8n AI template gallery&lt;/strong&gt;&lt;/a&gt;. From each workflow, select the &lt;strong&gt;Use workflow&lt;/strong&gt; button to automatically import the workflow into your local n8n instance.&lt;/p&gt; &#xA;&lt;h3&gt;Learn AI key concepts&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://n8n.io/workflows/1954-ai-agent-chat/&#34;&gt;AI Agent Chat&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://n8n.io/workflows/2026-ai-chat-with-any-data-source-using-the-n8n-workflow-tool/&#34;&gt;AI chat with any data source (using the n8n workflow too)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://n8n.io/workflows/2098-chat-with-openai-assistant-by-adding-a-memory/&#34;&gt;Chat with OpenAI Assistant (by adding a memory)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://n8n.io/workflows/1980-use-an-open-source-llm-via-huggingface/&#34;&gt;Use an open-source LLM (via HuggingFace)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://n8n.io/workflows/2165-chat-with-pdf-docs-using-ai-quoting-sources/&#34;&gt;Chat with PDF docs using AI (quoting sources)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://n8n.io/workflows/2006-ai-agent-that-can-scrape-webpages/&#34;&gt;AI agent that can scrape webpages&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Local AI templates&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://n8n.io/workflows/2341-build-a-tax-code-assistant-with-qdrant-mistralai-and-openai/&#34;&gt;Tax Code Assistant&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://n8n.io/workflows/2339-breakdown-documents-into-study-notes-using-templating-mistralai-and-qdrant/&#34;&gt;Breakdown Documents into Study Notes with MistralAI and Qdrant&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://n8n.io/workflows/2335-build-a-financial-documents-assistant-using-qdrant-and-mistralai/&#34;&gt;Financial Documents Assistant using Qdrant and&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;http://mistral.ai/&#34;&gt;&amp;nbsp;Mistral.ai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://n8n.io/workflows/2333-recipe-recommendations-with-qdrant-and-mistral/&#34;&gt;Recipe Recommendations with Qdrant and Mistral&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Tips &amp;amp; tricks&lt;/h2&gt; &#xA;&lt;h3&gt;Accessing local files&lt;/h3&gt; &#xA;&lt;p&gt;The self-hosted AI starter kit will create a shared folder (by default, located in the same directory) which is mounted to the n8n container and allows n8n to access files on disk. This folder within the n8n container is located at &lt;code&gt;/data/shared&lt;/code&gt; -- this is the path you’ll need to use in nodes that interact with the local filesystem.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Nodes that interact with the local filesystem&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.filesreadwrite/&#34;&gt;Read/Write Files from Disk&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.localfiletrigger/&#34;&gt;Local File Trigger&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executecommand/&#34;&gt;Execute Command&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;📜&amp;nbsp;License&lt;/h2&gt; &#xA;&lt;p&gt;This project (originally created by the n8n team, link at the top of the README) is licensed under the Apache License 2.0 - see the &lt;a href=&#34;https://raw.githubusercontent.com/coleam00/local-ai-packaged/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ok-oldking/ok-wuthering-waves</title>
    <updated>2025-05-31T01:34:41Z</updated>
    <id>tag:github.com,2025-05-31:/ok-oldking/ok-wuthering-waves</id>
    <link href="https://github.com/ok-oldking/ok-wuthering-waves" rel="alternate"></link>
    <summary type="html">&lt;p&gt;鸣潮 后台自动战斗 自动刷声骸 一键日常 Automation for Wuthering Waves&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1 align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ok-oldking/ok-wuthering-waves/master/icon.png&#34; width=&#34;200&#34;&gt; &lt;br&gt; ok-ww &lt;/h1&gt; &#xA; &lt;h3&gt;&lt;i&gt;基于图像识别的鸣潮自动化, 使用windows接口模拟用户点击, 无读取游戏内存或侵入修改游戏文件/数据.&lt;/i&gt;&lt;/h3&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/platfrom-Windows-blue?color=blue&#34; alt=&#34;Static Badge&#34;&gt; &lt;a href=&#34;https://github.com/ok-oldking/ok-wuthering-waves/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/ok-oldking/ok-wuthering-waves&#34; alt=&#34;GitHub release (with filter)&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ok-oldking/ok-wuthering-waves/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/downloads/ok-oldking/ok-wuthering-waves/total&#34; alt=&#34;GitHub all releases&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/vVyCatEBgA&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/296598043787132928?color=5865f2&amp;amp;label=%20Discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ok-oldking/ok-wuthering-waves/master/README_en.md&#34;&gt;English Readme&lt;/a&gt; | 中文说明&lt;/h3&gt; &#xA;&lt;p&gt;演示和教程 &lt;a href=&#34;https://youtu.be/h6P1KWjdnB4&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&amp;amp;logo=YouTube&amp;amp;logoColor=white&#34; alt=&#34;YouTube&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;免责声明&lt;/h1&gt; &#xA;&lt;p&gt;本软件是一个外部工具，旨在自动化鸣潮的游戏玩法。它仅通过现有用户界面与游戏交互，并遵守相关法律法规。该软件包旨在简化用户与游戏的交互，不会破坏游戏平衡或提供不公平优势，也不会修改任何游戏文件或代码。&lt;/p&gt; &#xA;&lt;p&gt;本软件开源、免费，仅供个人学习交流使用，仅限于个人游戏账号，不得用于任何商业或营利性目的。开发者团队拥有本项目的最终解释权。使用本软件产生的所有问题与本项目及开发者团队无关。若您发现商家使用本软件进行代练并收费，这是商家的个人行为，本软件不授权用于代练服务，产生的问题及后果与本软件无关。本软件不授权任何人进行售卖，售卖的软件可能被加入恶意代码，导致游戏账号或电脑资料被盗，与本软件无关。&lt;/p&gt; &#xA;&lt;p&gt;请注意，根据库洛的《鸣潮》公平运营声明:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;严禁利用任何第三方工具破坏游戏体验。&#xA;我们将严厉打击使用外挂、加速器、作弊软件、宏脚本等违规工具的行为，这些行为包括但不限于自动挂机、技能加速、无敌模式、瞬移、修改游戏数据等操作。&#xA;一经查证，我们将视违规情况和次数，采取包括但不限于扣除违规收益、冻结或永久封禁游戏账号等措施。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;使用方法:下载绿色版7z压缩包(250M左右), 解压后双击ok-ww.exe&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ok-oldking/ok-wuthering-waves/releases&#34;&gt;GitHub下载&lt;/a&gt;, 免费网页直链, 不要点击下载Source Code, 点击下载7z压缩包&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mirrorchyan.com/zh/projects?rid=okww&#34;&gt;Mirror酱下载渠道&lt;/a&gt;, 国内网页直链, 下载需要购买CD-KEY, 已有Mirror酱CD-KEY可免费下载&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pan.quark.cn/s/a1052cec4d13&#34;&gt;夸克网盘&lt;/a&gt;, 免费, 但需要注册并下载夸克网盘客户端&lt;/li&gt; &#xA; &lt;li&gt;加入QQ频道后, 讨论组下载 &lt;a href=&#34;https://pd.qq.com/s/djmm6l44y&#34;&gt;https://pd.qq.com/s/djmm6l44y&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;有多强?&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;4K分辨率流畅运行,支持所有16:9分辨率,1600x900以上, 1280x720不支持是因为鸣潮bug, 它的1280x720并不是1280x720. 部分功能也可以在21:9等宽屏分辨率运行&lt;/li&gt; &#xA; &lt;li&gt;可后台运行,可窗口化,可全屏,屏幕缩放比例无要求&lt;/li&gt; &#xA; &lt;li&gt;全角色自动识别，无需配置出招表，一键运行&lt;/li&gt; &#xA; &lt;li&gt;后台自动静音游戏&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;出现问题请检查&lt;/h3&gt; &#xA;&lt;p&gt;有问题点这里, 挨个检查再提问:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;解压问题:&lt;/strong&gt; 将压缩包解压到仅包含英文字符的目录中。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;杀毒软件干扰:&lt;/strong&gt; 将下载和解压目录添加到您的杀毒软件/Windows Defender 白名单中。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;显示设置:&lt;/strong&gt; 关闭显卡滤镜和锐化。使用默认游戏亮度并禁用在游戏上显示FPS(如小飞机)。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;自定义按键绑定:&lt;/strong&gt; 如没有使用默认按键，请在APP设置中设置, 不在设置里的按键不支持。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;版本过旧:&lt;/strong&gt; 确保您使用的是最新版本的 OK-GI。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;性能:&lt;/strong&gt; 在游戏中保持稳定的 60 FPS，如果需要，降低分辨率。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;游戏断线&lt;/strong&gt; 如果经常发现断开服务器链接的问题, 可以先打开游戏5分钟再开始玩, 或者断开后不要退出游戏, 重新登陆&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;进一步帮助:&lt;/strong&gt; 如果问题仍然存在，请提交错误报告。&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Python 源码运行&lt;/h3&gt; &#xA;&lt;p&gt;仅支持Python 3.12&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;#CPU版本, 使用openvino&#xA;pip install -r requirements.txt --upgrade #install python dependencies, 更新代码后可能需要重新运行&#xA;python main.py # run the release version&#xA;python main_debug.py # run the debug version&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;#GPU版本, 使用onnxruntime-directml加速, 推荐大显存显卡使用, 可以大约降低50%的CPU和内存消耗&#xA;pip install -r requirements-direct-ml.txt --upgrade #install python dependencies, 更新代码后可能需要重新运行&#xA;python main_direct_ml.py # run the release version&#xA;python main_direct_ml_debug.py # run the debug version&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;命令行参数&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;ok-ww.exe -t 1 -e&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;-t 或 --task 代表启动后自动执行第几个任务, 1就是第一个, 一条龙任务&lt;/li&gt; &#xA; &lt;li&gt;-e 或 --exit 加上代表如果执行完任务之后自动退出&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;加入我们&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;由于基于&lt;a href=&#34;https://github.com/ok-oldking/ok-script&#34;&gt;ok-script&lt;/a&gt;开发，项目代码仅有3000行（Python），简单易维护&lt;/li&gt; &#xA; &lt;li&gt;鸣潮水群 970523295 进群答案:老王同学OK&lt;/li&gt; &#xA; &lt;li&gt;群都满了 加QQ频道 &lt;a href=&#34;https://pd.qq.com/s/djmm6l44y&#34;&gt;https://pd.qq.com/s/djmm6l44y&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;有兴趣开发的请加开发者群926858895&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;相关项目&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ok-oldking/ok-genshin-impact&#34;&gt;ok-genshin-impact&lt;/a&gt; 原神自动化,一键日常,后台剧情 ( 可后台,支持全游戏语言,支持全16: 9分辨率)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ok-oldking/ok-gf2&#34;&gt;ok-gf2&lt;/a&gt; 少前2追放自动化,一键日常,竞技场,兵棋推演,尘烟 (支持PC版后台)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;赞助商(Sponsors)&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;EXE签名: Free code signing provided by &lt;a href=&#34;https://signpath.io/&#34;&gt;SignPath.io&lt;/a&gt;, certificate by &lt;a href=&#34;https://signpath.org/&#34;&gt;SignPath Foundation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;致谢&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/lazydog28/mc_auto_boss&#34;&gt;https://github.com/lazydog28/mc_auto_boss&lt;/a&gt; 后台点击代码&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>GoogleCloudPlatform/agent-starter-pack</title>
    <updated>2025-05-31T01:34:41Z</updated>
    <id>tag:github.com,2025-05-31:/GoogleCloudPlatform/agent-starter-pack</id>
    <link href="https://github.com/GoogleCloudPlatform/agent-starter-pack" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A collection of production-ready Generative AI Agent templates built for Google Cloud. It accelerates development by providing a holistic, production-ready solution, addressing common challenges (Deployment &amp; Operations, Evaluation, Customization, Observability) in building and deploying GenAI agents.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;🚀 Agent Starter Pack&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/agent-starter-pack?color=blue&#34; alt=&#34;Version&#34;&gt; &lt;a href=&#34;https://youtu.be/jHt-ZVD660g&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/1--Minute%20Overview-gray&#34; alt=&#34;1-Minute Video Overview&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://googlecloudplatform.github.io/agent-starter-pack/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Documentation-gray&#34; alt=&#34;Docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://studio.firebase.google.com/new?template=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fagent-starter-pack%2Ftree%2Fmain%2Fsrc%2Fresources%2Fidx&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://cdn.firebasestudio.dev/btn/try_light_20.svg&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;https://cdn.firebasestudio.dev/btn/try_dark_20.svg&#34;&gt; &#xA;   &lt;img height=&#34;20&#34; alt=&#34;Try in Firebase Studio&#34; src=&#34;https://cdn.firebasestudio.dev/btn/try_blue_20.svg?sanitize=true&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &lt;a href=&#34;https://shell.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https%3A%2F%2Fgithub.com%2Feliasecchig%2Fasp-open-in-cloud-shell&amp;amp;cloudshell_print=open-in-cs&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Launch-in_Cloud_Shell-white&#34; alt=&#34;Launch in Cloud Shell&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/stars/GoogleCloudPlatform/agent-starter-pack?color=yellow&#34; alt=&#34;Stars&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;agent-starter-pack&lt;/code&gt; is a collection of production-ready Generative AI Agent templates built for Google Cloud. &lt;br&gt; It accelerates development by providing a holistic, production-ready solution, addressing common challenges (Deployment &amp;amp; Operations, Evaluation, Customization, Observability) in building and deploying GenAI agents.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;⚡️ Launch&lt;/th&gt; &#xA;   &lt;th&gt;🧪 Experiment&lt;/th&gt; &#xA;   &lt;th&gt;✅ Deploy&lt;/th&gt; &#xA;   &lt;th&gt;🛠️ Customize&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/agents/&#34;&gt;Pre-built agent templates&lt;/a&gt; (ReAct, RAG, multi-agent, Live API).&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-overview&#34;&gt;Vertex AI evaluation&lt;/a&gt; and an interactive playground.&lt;/td&gt; &#xA;   &lt;td&gt;Production-ready infra with &lt;a href=&#34;https://googlecloudplatform.github.io/agent-starter-pack/guide/observability&#34;&gt;monitoring, observability&lt;/a&gt;, and &lt;a href=&#34;https://googlecloudplatform.github.io/agent-starter-pack/guide/deployment&#34;&gt;CI/CD&lt;/a&gt; on &lt;a href=&#34;https://cloud.google.com/run&#34;&gt;Cloud Run&lt;/a&gt; or &lt;a href=&#34;https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview&#34;&gt;Agent Engine&lt;/a&gt;.&lt;/td&gt; &#xA;   &lt;td&gt;Extend and customize templates according to your needs.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;⚡ Get Started in 1 Minute&lt;/h2&gt; &#xA;&lt;p&gt;Ready to build your AI agent? Simply run this command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Create and activate a Python virtual environment&#xA;python -m venv .venv &amp;amp;&amp;amp; source .venv/bin/activate&#xA;&#xA;# Install the agent starter pack&#xA;pip install agent-starter-pack&#xA;&#xA;# Create a new agent project&#xA;agent-starter-pack create my-awesome-agent&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;That&#39;s it!&lt;/strong&gt; You now have a fully functional agent project—complete with backend, frontend, and deployment infrastructure—ready for you to explore and customize. See &lt;a href=&#34;https://googlecloudplatform.github.io/agent-starter-pack/guide/installation&#34;&gt;Installation Guide&lt;/a&gt; for more options, or try with zero setup in &lt;a href=&#34;https://studio.firebase.google.com/new?template=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fagent-starter-pack%2Ftree%2Fmain%2Fsrc%2Fresources%2Fidx&#34;&gt;Firebase Studio&lt;/a&gt; or &lt;a href=&#34;https://shell.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https%3A%2F%2Fgithub.com%2Feliasecchig%2Fasp-open-in-cloud-shell&amp;amp;cloudshell_print=open-in-cs&#34;&gt;Cloud Shell&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;🆕 The starter pack offers full support for Agent Engine, a new fully managed solution to deploy agents. Simply run this command to get started:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;agent-starter-pack create my-agent -d agent_engine -a adk_base&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;See the &lt;a href=&#34;https://googlecloudplatform.github.io/agent-starter-pack/cli/create&#34;&gt;full list of options&lt;/a&gt; for details.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🤖 Agents&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Agent Name&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;adk_base&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A base ReAct agent implemented using Google&#39;s &lt;a href=&#34;https://github.com/google/adk-python&#34;&gt;Agent Development Kit&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;agentic_rag&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A RAG agent for document retrieval and Q&amp;amp;A. Supporting &lt;a href=&#34;https://cloud.google.com/generative-ai-app-builder/docs/enterprise-search-introduction&#34;&gt;Vertex AI Search&lt;/a&gt; and &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/vector-search/overview&#34;&gt;Vector Search&lt;/a&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;langgraph_base_react&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;An agent implementing a base ReAct agent using LangGraph&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;crewai_coding_crew&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A multi-agent system implemented with CrewAI created to support coding activities&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;live_api&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A real-time multimodal RAG agent powered by Gemini, supporting audio/video/text chat with vector DB-backed responses&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;More agents are on the way!&lt;/strong&gt; We are continuously expanding our &lt;a href=&#34;https://googlecloudplatform.github.io/agent-starter-pack/agents/overview&#34;&gt;agent library&lt;/a&gt;. Have a specific agent type in mind? &lt;a href=&#34;https://github.com/GoogleCloudPlatform/agent-starter-pack/issues/new?labels=enhancement&#34;&gt;Raise an issue as a feature request!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;🔍 ADK Samples&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Looking to explore more ADK examples? Check out the &lt;a href=&#34;https://github.com/google/adk-samples&#34;&gt;ADK Samples Repository&lt;/a&gt; for additional examples and use cases demonstrating ADK&#39;s capabilities.&lt;/p&gt; &#xA;&lt;h4&gt;Extra Features&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;agent-starter-pack&lt;/code&gt; offers two key features to accelerate and simplify the development of your agent:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;🔄 &lt;a href=&#34;https://googlecloudplatform.github.io/agent-starter-pack/cli/setup_cicd&#34;&gt;CI/CD Automation (Experimental)&lt;/a&gt;&lt;/strong&gt; - One command to set up a complete GitHub + Cloud Build pipeline for all environments&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;📥 &lt;a href=&#34;https://googlecloudplatform.github.io/agent-starter-pack/guide/data-ingestion&#34;&gt;Data Pipeline for RAG with Terraform/CI-CD&lt;/a&gt;&lt;/strong&gt; - Seamlessly integrate a data pipeline to process embeddings for RAG into your agent system. Supporting &lt;a href=&#34;https://cloud.google.com/generative-ai-app-builder/docs/enterprise-search-introduction&#34;&gt;Vertex AI Search&lt;/a&gt; and &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/vector-search/overview&#34;&gt;Vector Search&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;High-Level Architecture&lt;/h2&gt; &#xA;&lt;p&gt;This starter pack covers all aspects of Agent development, from prototyping and evaluation to deployment and monitoring.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/images/ags_high_level_architecture.png&#34; alt=&#34;High Level Architecture&#34; title=&#34;Architecture&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;🔧 Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.10+&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cloud.google.com/sdk/docs/install&#34;&gt;Google Cloud SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.hashicorp.com/terraform/downloads&#34;&gt;Terraform&lt;/a&gt; (for deployment)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;📚 Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Visit our &lt;a href=&#34;https://googlecloudplatform.github.io/agent-starter-pack/&#34;&gt;documentation site&lt;/a&gt; for comprehensive guides and references!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://googlecloudplatform.github.io/agent-starter-pack/guide/getting-started&#34;&gt;Getting Started Guide&lt;/a&gt; - First steps with agent-starter-pack&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://googlecloudplatform.github.io/agent-starter-pack/guide/installation&#34;&gt;Installation Guide&lt;/a&gt; - Setting up your environment&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://googlecloudplatform.github.io/agent-starter-pack/guide/deployment&#34;&gt;Deployment Guide&lt;/a&gt; - Taking your agent to production&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://googlecloudplatform.github.io/agent-starter-pack/agents/overview&#34;&gt;Agent Templates Overview&lt;/a&gt; - Explore available agent patterns&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://googlecloudplatform.github.io/agent-starter-pack/cli/&#34;&gt;CLI Reference&lt;/a&gt; - Command-line tool documentation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Video Walkthrough:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=9zqwym-N3lg&#34;&gt;Exploring the Agent Starter Pack&lt;/a&gt;&lt;/strong&gt;: A comprehensive tutorial demonstrating how to rapidly deploy AI Agents using the Agent Starter Pack, covering architecture, templates, and step-by-step deployment.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.youtube.com/live/eZ-8UQ_t4YM?feature=shared&amp;amp;t=2791&#34;&gt;6-minute introduction&lt;/a&gt;&lt;/strong&gt; (April 2024): Explaining the Agent Starter Pack and demonstrating its key features. Part of the Kaggle GenAI intensive course.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=yIRIT_EtALs&amp;amp;t=235s&#34;&gt;120-minute livestream demo&lt;/a&gt;&lt;/strong&gt; (March 6, 2025): Watch us build 3 Agents in under 30 minutes using the &lt;code&gt;agent-starter-pack&lt;/code&gt;!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Looking for more examples and resources for Generative AI on Google Cloud? Check out the &lt;a href=&#34;https://github.com/GoogleCloudPlatform/generative-ai&#34;&gt;GoogleCloudPlatform/generative-ai&lt;/a&gt; repository for notebooks, code samples, and more!&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are welcome! See the &lt;a href=&#34;https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/CONTRIBUTING.md&#34;&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Feedback&lt;/h2&gt; &#xA;&lt;p&gt;We value your input! Your feedback helps us improve this starter pack and make it more useful for the community.&lt;/p&gt; &#xA;&lt;h3&gt;Getting Help&lt;/h3&gt; &#xA;&lt;p&gt;If you encounter any issues or have specific suggestions, please first consider &lt;a href=&#34;https://github.com/GoogleCloudPlatform/generative-ai/issues&#34;&gt;raising an issue&lt;/a&gt; on our GitHub repository.&lt;/p&gt; &#xA;&lt;h3&gt;Share Your Experience&lt;/h3&gt; &#xA;&lt;p&gt;For other types of feedback, or if you&#39;d like to share a positive experience or success story using this starter pack, we&#39;d love to hear from you! You can reach out to us at &lt;a href=&#34;mailto:agent-starter-pack@google.com&#34;&gt;&lt;/a&gt;&lt;a href=&#34;mailto:agent-starter-pack@google.com&#34;&gt;agent-starter-pack@google.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Thank you for your contributions!&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This repository is for demonstrative purposes only and is not an officially supported Google product.&lt;/p&gt; &#xA;&lt;h2&gt;Terms of Service&lt;/h2&gt; &#xA;&lt;p&gt;The agent-starter-pack templating CLI and the templates in this starter pack leverage Google Cloud APIs. When you use this starter pack, you&#39;ll be deploying resources in your own Google Cloud project and will be responsible for those resources. Please review the &lt;a href=&#34;https://cloud.google.com/terms/service-terms&#34;&gt;Google Cloud Service Terms&lt;/a&gt; for details on the terms of service associated with these APIs.&lt;/p&gt;</summary>
  </entry>
</feed>