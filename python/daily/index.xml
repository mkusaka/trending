<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-09-05T01:41:29Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Gabattal/Scripts-LeagueOfLegends</title>
    <updated>2022-09-05T01:41:29Z</updated>
    <id>tag:github.com,2022-09-05:/Gabattal/Scripts-LeagueOfLegends</id>
    <link href="https://github.com/Gabattal/Scripts-LeagueOfLegends" rel="alternate"></link>
    <summary type="html">&lt;p&gt;When I have a script idea, whether it is stupid or brilliant, I develop it and I push it there :D&lt;/p&gt;&lt;hr&gt;&lt;h3&gt;scripts&lt;/h3&gt; &#xA;&lt;p&gt;When I have a script idea, whether it is stupid or brilliant, I develop it and push it there :D&lt;/p&gt; &#xA;&lt;h1&gt;Auto-Chat&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The Auto-Chat allows you to autoype a prewritten sentence each time you die or make a kill. (this is the moment to create elaborate flame)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Auto-Champ-Select&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The Auto-Champ-Select allows you to auto accept the match, pick and ban for you. Once the game started, an alert (a music) is launched so you don&#39;t have to pay attention.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Since I am developing several scripts in this repository, you can find a detailed readme in each project&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>fundamentalvision/Deformable-DETR</title>
    <updated>2022-09-05T01:41:29Z</updated>
    <id>tag:github.com,2022-09-05:/fundamentalvision/Deformable-DETR</id>
    <link href="https://github.com/fundamentalvision/Deformable-DETR" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Deformable DETR: Deformable Transformers for End-to-End Object Detection.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Deformable DETR&lt;/h1&gt; &#xA;&lt;p&gt;By &lt;a href=&#34;https://scholar.google.com/citations?user=02RXI00AAAAJ&#34;&gt;Xizhou Zhu&lt;/a&gt;, &lt;a href=&#34;https://www.weijiesu.com/&#34;&gt;Weijie Su&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/in/lewei-lu-94015977/&#34;&gt;Lewei Lu&lt;/a&gt;, &lt;a href=&#34;http://staff.ustc.edu.cn/~binli/&#34;&gt;Bin Li&lt;/a&gt;, &lt;a href=&#34;http://www.ee.cuhk.edu.hk/~xgwang/&#34;&gt;Xiaogang Wang&lt;/a&gt;, &lt;a href=&#34;https://jifengdai.org/&#34;&gt;Jifeng Dai&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;This repository is an official implementation of the paper &lt;a href=&#34;https://arxiv.org/abs/2010.04159&#34;&gt;Deformable DETR: Deformable Transformers for End-to-End Object Detection&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;TL; DR.&lt;/strong&gt; Deformable DETR is an efficient and fast-converging end-to-end object detector. It mitigates the high complexity and slow convergence issues of DETR via a novel sampling-based efficient attention mechanism.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/fundamentalvision/Deformable-DETR/main/figs/illustration.png&#34; alt=&#34;deformable_detr&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/fundamentalvision/Deformable-DETR/main/figs/convergence.png&#34; alt=&#34;deformable_detr&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Abstract.&lt;/strong&gt; DETR has been recently proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance. However, it suffers from slow convergence and limited feature spatial resolution, due to the limitation of Transformer attention modules in processing image feature maps. To mitigate these issues, we proposed Deformable DETR, whose attention modules only attend to a small set of key sampling points around a reference. Deformable DETR can achieve better performance than DETR (especially on small objects) with 10× less training epochs. Extensive experiments on the COCO benchmark demonstrate the effectiveness of our approach.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is released under the &lt;a href=&#34;https://raw.githubusercontent.com/fundamentalvision/Deformable-DETR/main/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Changelog&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/fundamentalvision/Deformable-DETR/main/docs/changelog.md&#34;&gt;changelog.md&lt;/a&gt; for detailed logs of major changes.&lt;/p&gt; &#xA;&lt;h2&gt;Citing Deformable DETR&lt;/h2&gt; &#xA;&lt;p&gt;If you find Deformable DETR useful in your research, please consider citing:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{zhu2020deformable,&#xA;  title={Deformable DETR: Deformable Transformers for End-to-End Object Detection},&#xA;  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},&#xA;  journal={arXiv preprint arXiv:2010.04159},&#xA;  year={2020}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Main Results&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;sub&gt;&lt;sub&gt;Method&lt;/sub&gt;&lt;/sub&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;sub&gt;&lt;sub&gt;Epochs&lt;/sub&gt;&lt;/sub&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;sub&gt;&lt;sub&gt;AP&lt;/sub&gt;&lt;/sub&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;sub&gt;&lt;sub&gt;AP&lt;sub&gt;S&lt;/sub&gt;&lt;/sub&gt;&lt;/sub&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;sub&gt;&lt;sub&gt;AP&lt;sub&gt;M&lt;/sub&gt;&lt;/sub&gt;&lt;/sub&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;sub&gt;&lt;sub&gt;AP&lt;sub&gt;L&lt;/sub&gt;&lt;/sub&gt;&lt;/sub&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;sub&gt;&lt;sub&gt;params&lt;br&gt;(M)&lt;/sub&gt;&lt;/sub&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;sub&gt;&lt;sub&gt;FLOPs&lt;br&gt;(G)&lt;/sub&gt;&lt;/sub&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;sub&gt;&lt;sub&gt;Total&lt;br&gt;Train&lt;br&gt;Time&lt;br&gt;(GPU&lt;br&gt;hours)&lt;/sub&gt;&lt;/sub&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;sub&gt;&lt;sub&gt;Train&lt;br&gt;Speed&lt;br&gt;(GPU&lt;br&gt;hours&lt;br&gt;/epoch)&lt;/sub&gt;&lt;/sub&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;sub&gt;&lt;sub&gt;Infer&lt;br&gt;Speed&lt;br&gt;(FPS)&lt;/sub&gt;&lt;/sub&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;sub&gt;&lt;sub&gt;Batch&lt;br&gt;Infer&lt;br&gt;Speed&lt;br&gt;(FPS)&lt;/sub&gt;&lt;/sub&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;sub&gt;&lt;sub&gt;URL&lt;/sub&gt;&lt;/sub&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;sub&gt;&lt;sub&gt;Faster R-CNN + FPN&lt;/sub&gt;&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;109&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;42.0&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;26.6&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;45.4&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;53.4&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;42&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;180&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;380&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;3.5&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;25.6&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;28.0&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;-&lt;/sub&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;sub&gt;&lt;sub&gt;DETR&lt;/sub&gt;&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;500&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;42.0&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;20.5&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;45.8&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;61.1&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;41&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;86&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;2000&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;4.0&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;27.0&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;38.3&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;-&lt;/sub&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;sub&gt;&lt;sub&gt;DETR-DC5&lt;/sub&gt;&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;500&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;43.3&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;22.5&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;47.3&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;61.1&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;41&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;187&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;7000&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;14.0&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;11.4&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;12.4&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;-&lt;/sub&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;sub&gt;&lt;sub&gt;DETR-DC5&lt;/sub&gt;&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;50&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;35.3&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;15.2&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;37.5&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;53.6&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;41&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;187&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;700&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;14.0&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;11.4&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;12.4&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;-&lt;/sub&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;sub&gt;&lt;sub&gt;DETR-DC5+&lt;/sub&gt;&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;50&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;36.2&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;16.3&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;39.2&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;53.9&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;41&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;187&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;700&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;14.0&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;11.4&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;12.4&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;-&lt;/sub&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;sub&gt;&lt;sub&gt;Deformable DETR&lt;br&gt;(single scale)&lt;/sub&gt;&lt;/sub&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;50&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;39.4&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;20.6&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;43.0&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;55.5&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;34&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;78&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;160&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;3.2&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;27.0&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;42.4&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;&lt;a href=&#34;https://raw.githubusercontent.com/fundamentalvision/Deformable-DETR/main/configs/r50_deformable_detr_single_scale.sh&#34;&gt;config&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/1n3ZnZ-UAqmTUR4AZoM4qQntIDn6qCZx4/view?usp=sharing&#34;&gt;log&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/1WEjQ9_FgfI5sw5OZZ4ix-OKk-IJ_-SDU/view?usp=sharing&#34;&gt;model&lt;/a&gt;&lt;/sub&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;sub&gt;&lt;sub&gt;Deformable DETR&lt;br&gt;(single scale, DC5)&lt;/sub&gt;&lt;/sub&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;50&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;41.5&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;24.1&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;45.3&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;56.0&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;34&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;128&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;215&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;4.3&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;22.1&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;29.4&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;&lt;a href=&#34;https://raw.githubusercontent.com/fundamentalvision/Deformable-DETR/main/configs/r50_deformable_detr_single_scale_dc5.sh&#34;&gt;config&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/1-UfTp2q4GIkJjsaMRIkQxa5k5vn8_n-B/view?usp=sharing&#34;&gt;log&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/1m_TgMjzH7D44fbA-c_jiBZ-xf-odxGdk/view?usp=sharing&#34;&gt;model&lt;/a&gt;&lt;/sub&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;sub&gt;&lt;sub&gt;Deformable DETR&lt;/sub&gt;&lt;/sub&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;50&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;44.5&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;27.1&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;47.6&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;59.6&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;40&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;173&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;325&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;6.5&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;15.0&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;19.4&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;&lt;a href=&#34;https://raw.githubusercontent.com/fundamentalvision/Deformable-DETR/main/configs/r50_deformable_detr.sh&#34;&gt;config&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/18YSLshFjc_erOLfFC-hHu4MX4iyz1Dqr/view?usp=sharing&#34;&gt;log&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/1nDWZWHuRwtwGden77NLM9JoWe-YisJnA/view?usp=sharing&#34;&gt;model&lt;/a&gt;&lt;/sub&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;sub&gt;&lt;sub&gt;+ iterative bounding box refinement&lt;/sub&gt;&lt;/sub&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;50&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;46.2&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;28.3&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;49.2&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;61.5&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;41&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;173&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;325&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;6.5&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;15.0&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;19.4&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;&lt;a href=&#34;https://raw.githubusercontent.com/fundamentalvision/Deformable-DETR/main/configs/r50_deformable_detr_plus_iterative_bbox_refinement.sh&#34;&gt;config&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/1DFNloITi1SFBWjYzvVEAI75ndwmGM1Uj/view?usp=sharing&#34;&gt;log&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/1JYKyRYzUH7uo9eVfDaVCiaIGZb5YTCuI/view?usp=sharing&#34;&gt;model&lt;/a&gt;&lt;/sub&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;sub&gt;&lt;sub&gt;++ two-stage Deformable DETR&lt;/sub&gt;&lt;/sub&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;50&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;46.9&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;29.6&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;50.1&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;61.6&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;41&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;173&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;340&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;6.8&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;sub&gt;14.5&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;18.8&lt;/sub&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;sub&gt;&lt;a href=&#34;https://raw.githubusercontent.com/fundamentalvision/Deformable-DETR/main/configs/r50_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage.sh&#34;&gt;config&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/1ozi0wbv5-Sc5TbWt1jAuXco72vEfEtbY/view?usp=sharing&#34;&gt;log&lt;/a&gt; &lt;br&gt;&lt;a href=&#34;https://drive.google.com/file/d/15I03A7hNTpwuLNdfuEmW9_taZMNVssEp/view?usp=sharing&#34;&gt;model&lt;/a&gt;&lt;/sub&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;All models of Deformable DETR are trained with total batch size of 32.&lt;/li&gt; &#xA; &lt;li&gt;Training and inference speed are measured on NVIDIA Tesla V100 GPU.&lt;/li&gt; &#xA; &lt;li&gt;&#34;Deformable DETR (single scale)&#34; means only using res5 feature map (of stride 32) as input feature maps for Deformable Transformer Encoder.&lt;/li&gt; &#xA; &lt;li&gt;&#34;DC5&#34; means removing the stride in C5 stage of ResNet and add a dilation of 2 instead.&lt;/li&gt; &#xA; &lt;li&gt;&#34;DETR-DC5+&#34; indicates DETR-DC5 with some modifications, including using Focal Loss for bounding box classification and increasing number of object queries to 300.&lt;/li&gt; &#xA; &lt;li&gt;&#34;Batch Infer Speed&#34; refer to inference with batch size = 4 to maximize GPU utilization.&lt;/li&gt; &#xA; &lt;li&gt;The original implementation is based on our internal codebase. There are slight differences in the final accuracy and running time due to the plenty details in platform switch.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Linux, CUDA&amp;gt;=9.2, GCC&amp;gt;=5.4&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Python&amp;gt;=3.7&lt;/p&gt; &lt;p&gt;We recommend you to use Anaconda to create a conda environment:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n deformable_detr python=3.7 pip&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then, activate the environment:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda activate deformable_detr&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;PyTorch&amp;gt;=1.5.1, torchvision&amp;gt;=0.6.1 (following instructions &lt;a href=&#34;https://pytorch.org/&#34;&gt;here&lt;/a&gt;)&lt;/p&gt; &lt;p&gt;For example, if your CUDA version is 9.2, you could install pytorch and torchvision as following:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda install pytorch=1.5.1 torchvision=0.6.1 cudatoolkit=9.2 -c pytorch&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Other requirements&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Compiling CUDA operators&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ./models/ops&#xA;sh ./make.sh&#xA;# unit test (should see all checking is True)&#xA;python test.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Dataset preparation&lt;/h3&gt; &#xA;&lt;p&gt;Please download &lt;a href=&#34;https://cocodataset.org/&#34;&gt;COCO 2017 dataset&lt;/a&gt; and organize them as following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;code_root/&#xA;└── data/&#xA;    └── coco/&#xA;        ├── train2017/&#xA;        ├── val2017/&#xA;        └── annotations/&#xA;        &#x9;├── instances_train2017.json&#xA;        &#x9;└── instances_val2017.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Training&lt;/h3&gt; &#xA;&lt;h4&gt;Training on single node&lt;/h4&gt; &#xA;&lt;p&gt;For example, the command for training Deformable DETR on 8 GPUs is as following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;GPUS_PER_NODE=8 ./tools/run_dist_launch.sh 8 ./configs/r50_deformable_detr.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Training on multiple nodes&lt;/h4&gt; &#xA;&lt;p&gt;For example, the command for training Deformable DETR on 2 nodes of each with 8 GPUs is as following:&lt;/p&gt; &#xA;&lt;p&gt;On node 1:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;MASTER_ADDR=&amp;lt;IP address of node 1&amp;gt; NODE_RANK=0 GPUS_PER_NODE=8 ./tools/run_dist_launch.sh 16 ./configs/r50_deformable_detr.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On node 2:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;MASTER_ADDR=&amp;lt;IP address of node 1&amp;gt; NODE_RANK=1 GPUS_PER_NODE=8 ./tools/run_dist_launch.sh 16 ./configs/r50_deformable_detr.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Training on slurm cluster&lt;/h4&gt; &#xA;&lt;p&gt;If you are using slurm cluster, you can simply run the following command to train on 1 node with 8 GPUs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;GPUS_PER_NODE=8 ./tools/run_dist_slurm.sh &amp;lt;partition&amp;gt; deformable_detr 8 configs/r50_deformable_detr.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or 2 nodes of each with 8 GPUs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;GPUS_PER_NODE=8 ./tools/run_dist_slurm.sh &amp;lt;partition&amp;gt; deformable_detr 16 configs/r50_deformable_detr.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Some tips to speed-up training&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If your file system is slow to read images, you may consider enabling &#39;--cache_mode&#39; option to load whole dataset into memory at the beginning of training.&lt;/li&gt; &#xA; &lt;li&gt;You may increase the batch size to maximize the GPU utilization, according to GPU memory of yours, e.g., set &#39;--batch_size 3&#39; or &#39;--batch_size 4&#39;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Evaluation&lt;/h3&gt; &#xA;&lt;p&gt;You can get the config file and pretrained model of Deformable DETR (the link is in &#34;Main Results&#34; session), then run following command to evaluate it on COCO 2017 validation set:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;lt;path to config file&amp;gt; --resume &amp;lt;path to pre-trained model&amp;gt; --eval&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also run distributed evaluation by using &lt;code&gt;./tools/run_dist_launch.sh&lt;/code&gt; or &lt;code&gt;./tools/run_dist_slurm.sh&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>vnpy/vnpy</title>
    <updated>2022-09-05T01:41:29Z</updated>
    <id>tag:github.com,2022-09-05:/vnpy/vnpy</id>
    <link href="https://github.com/vnpy/vnpy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;基于Python的开源量化交易平台开发框架&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;VeighNa - By Traders, For Traders.&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://vnpy.oss-cn-shanghai.aliyuncs.com/veighna-logo.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;💬 Want to read this in &lt;strong&gt;english&lt;/strong&gt; ? Go &lt;a href=&#34;https://raw.githubusercontent.com/vnpy/vnpy/master/README_ENG.md&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/version-3.3.0-blueviolet.svg?sanitize=true&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/platform-windows|linux|macos-yellow.svg&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/python-3.7|3.8|3.9|3.10-blue.svg&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/workflow/status/vnpy/vnpy/Python%20application/master&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/vnpy/vnpy.svg?color=orange&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;VeighNa是一套基于Python的开源量化交易系统开发框架，在开源社区持续不断的贡献下一步步成长为多功能量化交易平台，自发布以来已经积累了众多来自金融机构或相关领域的用户，包括私募基金、证券公司、期货公司等。&lt;/p&gt; &#xA;&lt;p&gt;🎓🎓🎓 &lt;strong&gt;2022年VeighNa线下小班特训营报名进行中！目前已经确定的场次包括《VeighNa套利价差交易》和《VeighNa源码深入解析》，两天10小时的课程内容结合后续3个月的助教辅导，帮助学员在量化实践中深入掌握相关的知识体系。报名方法请扫描下方二维码关注后，回复关键词【小班】即可：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://vnpy.oss-cn-shanghai.aliyuncs.com/vnpy_qr.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;在使用VeighNa进行二次开发（策略、模块等）的过程中有任何疑问，请查看&lt;a href=&#34;https://www.vnpy.com/docs/cn/index.html&#34;&gt;&lt;strong&gt;VeighNa项目文档&lt;/strong&gt;&lt;/a&gt;，如果无法解决请前往&lt;a href=&#34;https://www.vnpy.com/forum/&#34;&gt;&lt;strong&gt;官方社区论坛&lt;/strong&gt;&lt;/a&gt;的【提问求助】板块寻求帮助，也欢迎在【经验分享】板块分享你的使用心得！&lt;/p&gt; &#xA;&lt;p&gt;针对VeighNa的金融机构用户，创建了一个专门的【VeighNa机构用户群】（QQ群号：676499931），主要分享机构应用方面相关的问题，如：银行间市场接入、资管O32系统、分布式部署等内容。请注意本群只对金融机构用户开放，加群时请注明：姓名-机构-部门。&lt;/p&gt; &#xA;&lt;h2&gt;功能特点&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;多功能量化交易平台（trader），整合了多种交易接口，并针对具体策略算法和功能开发提供了简洁易用的API，用于快速构建交易员所需的量化交易应用。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;覆盖国内外所拥有的下述交易品种的交易接口（gateway）：&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;国内市场&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt; &lt;p&gt;CTP（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_ctp&#34;&gt;ctp&lt;/a&gt;）：国内期货、期权&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;CTP Mini（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_mini&#34;&gt;mini&lt;/a&gt;）：国内期货、期权&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;CTP证券（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_sopt&#34;&gt;sopt&lt;/a&gt;）：ETF期权&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;飞马（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_femas&#34;&gt;femas&lt;/a&gt;）：国内期货&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;恒生UFT（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_uft&#34;&gt;uft&lt;/a&gt;）：国内期货、ETF期权&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;易盛（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_esunny&#34;&gt;esunny&lt;/a&gt;）：国内期货、黄金TD&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;顶点飞创（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_sec&#34;&gt;sec&lt;/a&gt;）：ETF期权&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;顶点HTS（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_hts&#34;&gt;hts&lt;/a&gt;）：ETF期权&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;南华NHTD（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_nhtd&#34;&gt;nhtd&lt;/a&gt;）：国内期货、ETF期权&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;中泰XTP（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_xtp&#34;&gt;xtp&lt;/a&gt;）：国内证券（A股）、ETF期权&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;华鑫奇点（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_tora&#34;&gt;tora&lt;/a&gt;）：国内证券（A股）、ETF期权&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;国泰君安（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_hft&#34;&gt;hft&lt;/a&gt;）：国内证券（A股、两融）&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;东证OST（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_ost&#34;&gt;ost&lt;/a&gt;）：国内证券（A股）&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;飞鼠（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_sgit&#34;&gt;sgit&lt;/a&gt;）：黄金TD、国内期货&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;金仕达黄金（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_ksgold&#34;&gt;ksgold&lt;/a&gt;）：黄金TD&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;融航（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_rohon&#34;&gt;rohon&lt;/a&gt;）：期货资管&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;中汇亿达（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_comstar&#34;&gt;comstar&lt;/a&gt;）：银行间市场&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;掘金（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_gm&#34;&gt;gm&lt;/a&gt;）：国内证券（仿真）&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;恒生云UF（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_uf&#34;&gt;uf&lt;/a&gt;）：国内证券（仿真）&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;TTS（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_tts&#34;&gt;tts&lt;/a&gt;）：国内期货（仿真）&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;火象（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_hx&#34;&gt;hx&lt;/a&gt;）：国内期货（仿真）&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;海外市场&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt; &lt;p&gt;Interactive Brokers（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_ib&#34;&gt;ib&lt;/a&gt;）：海外证券、期货、期权、贵金属等&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;易盛9.0外盘（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_tap&#34;&gt;tap&lt;/a&gt;）：海外期货&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;直达期货（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_da&#34;&gt;da&lt;/a&gt;）：海外期货&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;特殊应用&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;RPC服务（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_rpcservice&#34;&gt;rpc&lt;/a&gt;）：跨进程通讯接口，用于分布式架构&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;覆盖下述各类量化策略的交易应用（app）：&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_ctastrategy&#34;&gt;cta_strategy&lt;/a&gt;：CTA策略引擎模块，在保持易用性的同时，允许用户针对CTA类策略运行过程中委托的报撤行为进行细粒度控制（降低交易滑点、实现高频策略）&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_ctabacktester&#34;&gt;cta_backtester&lt;/a&gt;：CTA策略回测模块，无需使用Jupyter Notebook，直接使用图形界面进行策略回测分析、参数优化等相关工作&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_spreadtrading&#34;&gt;spread_trading&lt;/a&gt;：价差交易模块，支持自定义价差，实时计算价差行情和持仓，支持价差算法交易以及自动价差策略两种模式&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_optionmaster&#34;&gt;option_master&lt;/a&gt;：期权交易模块，针对国内期权市场设计，支持多种期权定价模型、隐含波动率曲面计算、希腊值风险跟踪等功能&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_portfoliostrategy&#34;&gt;portfolio_strategy&lt;/a&gt;：组合策略模块，面向同时交易多合约的量化策略（Alpha、期权套利等），提供历史数据回测和实盘自动交易功能&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_algotrading&#34;&gt;algo_trading&lt;/a&gt;：算法交易模块，提供多种常用的智能交易算法：TWAP、Sniper、Iceberg、BestLimit等&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_scripttrader&#34;&gt;script_trader&lt;/a&gt;：脚本策略模块，面向多标的类量化策略和计算任务设计，同时也可以在命令行中实现REPL指令形式的交易，不支持回测功能&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_paperaccount&#34;&gt;paper_account&lt;/a&gt;：本地仿真模块，纯本地化实现的仿真模拟交易功能，基于交易接口获取的实时行情进行委托撮合，提供委托成交推送以及持仓记录&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_chartwizard&#34;&gt;chart_wizard&lt;/a&gt;：K线图表模块，基于RQData数据服务（期货）或者交易接口获取历史数据，并结合Tick推送显示实时行情变化&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_portfoliomanager&#34;&gt;portfolio_manager&lt;/a&gt;：交易组合管理模块，以独立的策略交易组合（子账户）为基础，提供委托成交记录管理、交易仓位自动跟踪以及每日盈亏实时统计功能&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_rpcservice&#34;&gt;rpc_service&lt;/a&gt;：RPC服务模块，允许将某一进程启动为服务端，作为统一的行情和交易路由通道，允许多客户端同时连接，实现多进程分布式系统&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_datamanager&#34;&gt;data_manager&lt;/a&gt;：历史数据管理模块，通过树形目录查看数据库中已有的数据概况，选择任意时间段数据查看字段细节，支持CSV文件的数据导入和导出&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_datarecorder&#34;&gt;data_recorder&lt;/a&gt;：行情记录模块，基于图形界面进行配置，根据需求实时录制Tick或者K线行情到数据库中，用于策略回测或者实盘初始化&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_excelrtd&#34;&gt;excel_rtd&lt;/a&gt;：Excel RTD（Real Time Data）实时数据服务，基于pyxll模块实现在Excel中获取各类数据（行情、合约、持仓等）的实时推送更新&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_riskmanager&#34;&gt;risk_manager&lt;/a&gt;：风险管理模块，提供包括交易流控、下单数量、活动委托、撤单总数等规则的统计和限制，有效实现前端风控功能&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.github.com/vnpy/vnpy_webtrader&#34;&gt;web_trader&lt;/a&gt;：Web服务模块，针对B-S架构需求设计，实现了提供主动函数调用（REST）和被动数据推送（Websocket）的Web服务器&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Python交易API接口封装（api），提供上述交易接口的底层对接实现。&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;REST Client（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_rest&#34;&gt;rest&lt;/a&gt;）：基于协程异步IO的高性能REST API客户端，采用事件消息循环的编程模型，支持高并发实时交易请求发送&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Websocket Client（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_websocket&#34;&gt;websocket&lt;/a&gt;）：基于协程异步IO的高性能Websocket API客户端，支持和REST Client共用事件循环并发运行&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;简洁易用的事件驱动引擎（event），作为事件驱动型交易程序的核心。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;对接各类数据库的适配器接口（database）：&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;SQL类&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt; &lt;p&gt;SQLite（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_sqlite&#34;&gt;sqlite&lt;/a&gt;）：轻量级单文件数据库，无需安装和配置数据服务程序，VeighNa的默认选项，适合入门新手用户&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;MySQL（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_mysql&#34;&gt;mysql&lt;/a&gt;）：主流的开源关系型数据库，文档资料极为丰富，且可替换其他NewSQL兼容实现（如TiDB）&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;PostgreSQL（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_postgresql&#34;&gt;postgresql&lt;/a&gt;）：特性更为丰富的开源关系型数据库，支持通过扩展插件来新增功能，只推荐熟手使用&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;NoSQL类&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt; &lt;p&gt;DolphinDB（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_dolphindb&#34;&gt;dolphindb&lt;/a&gt;）：一款高性能分布式时序数据库，适用于对速度要求极高的低延时或实时性任务&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;Arctic（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_arctic&#34;&gt;arctic&lt;/a&gt;）：高性能金融时序数据库，采用了分块化储存、LZ4压缩等性能优化方案，以实现时序数据的高效读写&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;TDengine（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_taos&#34;&gt;taos&lt;/a&gt;）：分布式、高性能、支持SQL的时序数据库，带有内建的缓存、流式计算、数据订阅等系统功能，能大幅减少研发和运维的复杂度&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;TimescaleDB（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_timescaledb&#34;&gt;timescaledb&lt;/a&gt;）：基于PostgreSQL开发的一款时序数据库，以插件化扩展的形式安装，支持自动按空间和时间对数据进行分区&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;MongoDB（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_mongodb&#34;&gt;mongodb&lt;/a&gt;）：基于分布式文件储存（bson格式）的文档式数据库，内置的热数据内存缓存提供更快读写速度&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;InfluxDB（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_influxdb&#34;&gt;influxdb&lt;/a&gt;）：针对TimeSeries Data专门设计的时序数据库，列式数据储存提供极高的读写效率和外围分析应用&lt;/p&gt; &lt;/li&gt; &#xA;     &lt;li&gt; &lt;p&gt;LevelDB（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_leveldb&#34;&gt;leveldb&lt;/a&gt;）：由Google推出的高性能Key/Value数据库，基于LSM算法实现进程内存储引擎，支持数十亿级别的海量数据&lt;/p&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;对接下述各类数据服务的适配器接口（datafeed）：&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;米筐RQData（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_rqdata&#34;&gt;rqdata&lt;/a&gt;）：股票、期货、期权、基金、债券、黄金TD&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;恒生UData（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_udata&#34;&gt;udata&lt;/a&gt;）：股票、期货、期权&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;TuShare（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_tushare&#34;&gt;tushare&lt;/a&gt;）：股票、期货、期权、基金&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;万得Wind（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_wind&#34;&gt;wind&lt;/a&gt;）：股票、期货、基金、债券&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;天软Tinysoft（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_tinysoft&#34;&gt;tinysoft&lt;/a&gt;）：股票、期货、基金、债券&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;同花顺iFinD（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_ifind&#34;&gt;ifind&lt;/a&gt;）：股票、期货、基金、债券&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;天勤TQSDK（&lt;a href=&#34;https://www.github.com/vnpy/vnpy_tqsdk&#34;&gt;tqsdk&lt;/a&gt;）：期货&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;跨进程通讯标准组件（rpc），用于实现分布式部署的复杂交易系统。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Python高性能K线图表（chart），支持大数据量图表显示以及实时数据更新功能。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;http://www.vnpy.com/forum&#34;&gt;社区论坛&lt;/a&gt;和&lt;a href=&#34;http://zhuanlan.zhihu.com/vn-py&#34;&gt;知乎专栏&lt;/a&gt;，内容包括VeighNa项目的开发教程和Python在量化交易领域的应用研究等内容。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;官方交流群262656087（QQ），管理严格（定期清除长期潜水的成员），入群费将捐赠给VeighNa社区基金。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;注：以上关于功能特点的说明为根据说明文档发布时情况罗列，后续可能存在更新或调整。若功能描述同实际存在出入，欢迎通过Issue联系进行调整。&lt;/p&gt; &#xA;&lt;h2&gt;环境准备&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;推荐使用VeighNa团队为量化交易专门打造的Python发行版&lt;a href=&#34;https://download.vnpy.com/veighna_studio-3.3.0.exe&#34;&gt;VeighNa Studio-3.3.0&lt;/a&gt;，集成内置了VeighNa框架以及VeighNa Station量化管理平台，无需手动安装&lt;/li&gt; &#xA; &lt;li&gt;支持的系统版本：Windows 10以上 / Windows Server 2016以上 / Ubuntu 20.04 LTS以上&lt;/li&gt; &#xA; &lt;li&gt;支持的Python版本：Python 3.7/ 3.8 / 3.9 / 3.10 64位（&lt;strong&gt;推荐使用Python 3.10&lt;/strong&gt;）&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;安装步骤&lt;/h2&gt; &#xA;&lt;p&gt;在&lt;a href=&#34;https://github.com/vnpy/vnpy/releases&#34;&gt;这里&lt;/a&gt;下载Release发布版本，解压后运行以下命令安装：&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;install.bat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Ubuntu&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;bash install.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Macos&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;bash install_osx.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;注意：setup.cfg中列举了VeighNa框架安装所需的依赖库，requirements.txt中给出了这些依赖库的推荐安装版本。&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;使用指南&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;在&lt;a href=&#34;http://www.simnow.com.cn/&#34;&gt;SimNow&lt;/a&gt;注册CTP仿真账号，并在&lt;a href=&#34;http://www.simnow.com.cn/product.action&#34;&gt;该页面&lt;/a&gt;获取经纪商代码以及交易行情服务器地址。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;在&lt;a href=&#34;https://www.vnpy.com/forum/&#34;&gt;VeighNa社区论坛&lt;/a&gt;注册获得VeighNa Station账号密码（论坛账号密码即是）&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;启动VeighNa Station（安装VeighNa Studio后会在桌面自动创建快捷方式），输入上一步的账号密码登录&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;点击底部的&lt;strong&gt;VeighNa Trader&lt;/strong&gt;按钮，开始你的交易！！！&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;注意：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;在VeighNa Trader的运行过程中请勿关闭VeighNa Station（会自动退出）&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;脚本运行&lt;/h2&gt; &#xA;&lt;p&gt;除了基于VeighNa Station的图形化启动方式外，也可以在任意目录下创建run.py，写入以下示例代码：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;from vnpy.event import EventEngine&#xA;from vnpy.trader.engine import MainEngine&#xA;from vnpy.trader.ui import MainWindow, create_qapp&#xA;&#xA;from vnpy_ctp import CtpGateway&#xA;from vnpy_ctastrategy import CtaStrategyApp&#xA;from vnpy_ctabacktester import CtaBacktesterApp&#xA;&#xA;&#xA;def main():&#xA;    &#34;&#34;&#34;Start VeighNa Trader&#34;&#34;&#34;&#xA;    qapp = create_qapp()&#xA;&#xA;    event_engine = EventEngine()&#xA;    main_engine = MainEngine(event_engine)&#xA;    &#xA;    main_engine.add_gateway(CtpGateway)&#xA;    main_engine.add_app(CtaStrategyApp)&#xA;    main_engine.add_app(CtaBacktesterApp)&#xA;&#xA;    main_window = MainWindow(main_engine, event_engine)&#xA;    main_window.showMaximized()&#xA;&#xA;    qapp.exec()&#xA;&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    main()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;在该目录下打开CMD（按住Shift-&amp;gt;点击鼠标右键-&amp;gt;在此处打开命令窗口/PowerShell）后运行下列命令启动VeighNa Trader：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python run.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;贡献代码&lt;/h2&gt; &#xA;&lt;p&gt;VeighNa使用Github托管其源代码，如果希望贡献代码请使用github的PR（Pull Request）的流程:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/vnpy/vnpy/issues/new&#34;&gt;创建 Issue&lt;/a&gt; - 对于较大的改动（如新功能，大型重构等）建议先开issue讨论一下，较小的improvement（如文档改进，bugfix等）直接发PR即可&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Fork &lt;a href=&#34;https://github.com/vnpy/vnpy&#34;&gt;VeighNa&lt;/a&gt; - 点击右上角&lt;strong&gt;Fork&lt;/strong&gt;按钮&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Clone你自己的fork: &lt;code&gt;git clone https://github.com/$userid/vnpy.git&lt;/code&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;如果你的fork已经过时，需要手动sync：&lt;a href=&#34;https://help.github.com/articles/syncing-a-fork/&#34;&gt;同步方法&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;从&lt;strong&gt;dev&lt;/strong&gt;创建你自己的feature branch: &lt;code&gt;git checkout -b $my_feature_branch dev&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;在$my_feature_branch上修改并将修改push到你的fork上&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;创建从你的fork的$my_feature_branch分支到主项目的&lt;strong&gt;dev&lt;/strong&gt;分支的[Pull Request] - &lt;a href=&#34;https://github.com/vnpy/vnpy/compare?expand=1&#34;&gt;在此&lt;/a&gt;点击&lt;strong&gt;compare across forks&lt;/strong&gt;，选择需要的fork和branch创建PR&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;等待review, 需要继续改进，或者被Merge!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;在提交代码的时候，请遵守以下规则，以提高代码质量：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;使用&lt;a href=&#34;https://pypi.org/project/flake8/&#34;&gt;flake8&lt;/a&gt;检查你的代码，确保没有error和warning。在项目根目录下运行&lt;code&gt;flake8&lt;/code&gt;即可。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;其他内容&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vnpy/vnpy/raw/dev/.github/SUPPORT.md&#34;&gt;获取帮助&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vnpy/vnpy/raw/dev/.github/CODE_OF_CONDUCT.md&#34;&gt;社区行为准则&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vnpy/vnpy/raw/dev/.github/ISSUE_TEMPLATE.md&#34;&gt;Issue模板&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vnpy/vnpy/raw/dev/.github/PULL_REQUEST_TEMPLATE.md&#34;&gt;PR模板&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;版权说明&lt;/h2&gt; &#xA;&lt;p&gt;MIT&lt;/p&gt;</summary>
  </entry>
</feed>