<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-22T01:32:59Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>lanqian528/chat2api</title>
    <updated>2024-05-22T01:32:59Z</updated>
    <id>tag:github.com,2024-05-22:/lanqian528/chat2api</id>
    <link href="https://github.com/lanqian528/chat2api" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A service that can convert ChatGPT on the web to OpenAI API format.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CHAT2API&lt;/h1&gt; &#xA;&lt;p&gt;🤖 一个简单的ChatGPT TO API代理&lt;/p&gt; &#xA;&lt;p&gt;🌟 无需账号即可使用免费、无限的 &lt;code&gt;GPT-3.5&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;💥 支持AccessToken使用账号，支持 &lt;code&gt;GPT-4&lt;/code&gt;、&lt;code&gt;GPT-4o&lt;/code&gt;、 &lt;code&gt;GPTs&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;🔍 回复格式与真实api完全一致，适配几乎所有客户端&lt;/p&gt; &#xA;&lt;h2&gt;交流群&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://t.me/chat2api&#34;&gt;https://t.me/chat2api&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;要提问请先阅读完仓库文档，尤其是常见问题部分&lt;/p&gt; &#xA;&lt;p&gt;提问时请提供：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;启动日志截图 (敏感信息打码，包括 &lt;code&gt;环境变量&lt;/code&gt; 和 &lt;code&gt;版本号&lt;/code&gt;)，&lt;/li&gt; &#xA; &lt;li&gt;报错的日志信息 (敏感信息打码)，&lt;/li&gt; &#xA; &lt;li&gt;接口返回的 &lt;code&gt;状态码&lt;/code&gt; 和 &lt;code&gt;响应体&lt;/code&gt;，&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;功能&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;已完成&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;[x] 流式、非流式传输&lt;/li&gt; &#xA;  &lt;li&gt;[x] 免登录 GPT3.5 对话&lt;/li&gt; &#xA;  &lt;li&gt;[x] GPT-3.5 对话 (传入模型名不包含gpt-4，则默认使用gpt-3.5，也就是text-davinci-002-render-sha)&lt;/li&gt; &#xA;  &lt;li&gt;[x] GPT-4 对话 (传入模型名包含: gpt-4，gpt-4o，gpt-4-moblie 即可使用对应模型， 需传入AccessToken)&lt;/li&gt; &#xA;  &lt;li&gt;[x] GPT-4 画图、代码、联网&lt;/li&gt; &#xA;  &lt;li&gt;[x] 支持GPTs (传入模型名：gpt-4-gizmo-g-*)&lt;/li&gt; &#xA;  &lt;li&gt;[x] 上传图片、文件 (格式为API对应格式，支持url和base64)&lt;/li&gt; &#xA;  &lt;li&gt;[x] WebUI (&lt;a href=&#34;http://127.0.0.1:5005&#34;&gt;http://127.0.0.1:5005&lt;/a&gt;, 不支持登录使用)&lt;/li&gt; &#xA;  &lt;li&gt;[x] 可作为网关使用，可多机分布部署&lt;/li&gt; &#xA;  &lt;li&gt;[x] 多账号轮询，同时支持AccessToken和RefreshToken&lt;/li&gt; &#xA;  &lt;li&gt;[x] Tokens 管理，支持上传、清除&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;TODO&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;[ ] 暂无，欢迎提 issue&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Tokens 管理&lt;/h2&gt; &#xA;&lt;p&gt;首先配置环境变量 &lt;code&gt;AUTHORIZATION&lt;/code&gt;，然后运行程序&lt;/p&gt; &#xA;&lt;p&gt;访问 &lt;code&gt;/tokens&lt;/code&gt; 或者 &lt;code&gt;/api_prefix/tokens&lt;/code&gt; 可以查看现有 Tokens 数量，也可以上传新的 Tokens ，或者清空 Tokens&lt;/p&gt; &#xA;&lt;p&gt;请求时传入 &lt;code&gt;AUTHORIZATION&lt;/code&gt; 中你配置的值即可多账号轮询， &lt;code&gt;AUTHORIZATION&lt;/code&gt; 可以配置多个值，用英文逗号分隔&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lanqian528/chat2api/main/docs/tokens.png&#34; alt=&#34;tokens.png&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;环境变量&lt;/h2&gt; &#xA;&lt;p&gt;每个环境变量都有默认值，如果不懂环境变量的含义，请不要设置，更不要传空值&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# 安全相关&#xA;API_PREFIX=your_prefix                               // API前缀密码，不设置容易被人访问，设置后需请求 /your_prefix/v1/chat/completions&#xA;AUTHORIZATION=sk-xxxxxxxx,sk-yyyyyyyy                // 先到 /tokens 上传ac或rt，请求时传入 AUTHORIZATION 可多账号轮询&#xA;&#xA;# 请求相关&#xA;CHATGPT_BASE_URL=https://chatgpt.com                 // ChatGPT网关地址，设置后会改变请求的网站，多个网关用逗号分隔&#xA;PROXY_URL=your_first_proxy, your_second_proxy        // 代理url，多个代理用逗号分隔&#xA;ARKOSE_TOKEN_URL=https://arkose.example.com/token    // 获取Arkose token的地址，上文有提供说明&#xA;&#xA;# 功能相关&#xA;HISTORY_DISABLED=true                                // 是否不保存聊天记录并返回 conversation_id，true为不保存且不返回&#xA;POW_DIFFICULTY=000032                                // 要解决的工作量证明难度，字符串越小，计算时间越长，建议000032&#xA;RETRY_TIMES=3                                        // 出错重试次数&#xA;ENABLE_GATEWAY=true                                  // 是否启用网关模式(WEBUI)，true为启用&#xA;CONVERSATION_ONLY=false                              // 使用的网关支持在服务端处理pow和arkose时可以开启，开启则直接使用对话接口&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;部署&lt;/h2&gt; &#xA;&lt;h3&gt;zeabur部署&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zeabur.com/templates/6HEGIZ?referralCode=LanQian528&#34;&gt;&lt;img src=&#34;https://zeabur.com/button.svg?sanitize=true&#34; alt=&#34;Deploy on Zeabur&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;直接部署&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/LanQian528/chat2api&#xA;cd chat2api&#xA;pip install -r requirements.txt&#xA;python app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Docker部署&lt;/h3&gt; &#xA;&lt;p&gt;您需要安装Docker和Docker Compose。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d \&#xA;  --name chat2api \&#xA;  -p 5005:5005 \&#xA;  lanqian528/chat2api:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;(推荐，可用 PLUS 账号) Docker Compose部署&lt;/h3&gt; &#xA;&lt;p&gt;创建一个新的目录，例如chat2api，并进入该目录：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir chat2api&#xA;cd chat2api&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;在此目录中下载库中的docker-compose.yml文件：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wget https://raw.githubusercontent.com/LanQian528/chat2api/main/docker-compose.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;修改docker-compose.yml文件中的环境变量，保存后：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;使用&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;在网页使用, 直接访问以下地址, 仅支持使用免登 GPT3.5:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;http://127.0.0.1:5005&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;使用 API , 支持传入 AccessToken 或 RefreshToken, 可用 GPT-4, GPT-4o, GPTs:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl --location &#39;http://127.0.0.1:5005/v1/chat/completions&#39; \&#xA;--header &#39;Content-Type: application/json&#39; \&#xA;--header &#39;Authorization: Bearer {{OpenAI APIKEY}}&#39; \&#xA;--data &#39;{&#xA;     &#34;model&#34;: &#34;gpt-3.5-turbo&#34;,&#xA;     &#34;messages&#34;: [{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Say this is a test!&#34;}],&#xA;     &#34;stream&#34;: true&#xA;   }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;将你账号的 &lt;code&gt;AccessToken&lt;/code&gt; 或 &lt;code&gt;RefreshToken&lt;/code&gt; 当作 &lt;code&gt;OpenAI APIKEY&lt;/code&gt; 传入&lt;/p&gt; &#xA;&lt;p&gt;如果设置了 &lt;code&gt;AUTHORIZATION&lt;/code&gt; 环境变量，可以将设置的值当作 &lt;code&gt;OpenAI APIKEY&lt;/code&gt; 传入进行多 Tokens 轮询&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;code&gt;AccessToken&lt;/code&gt; 获取: chatgpt官网登录后，再打开 &lt;a href=&#34;https://chatgpt.com/api/auth/session&#34;&gt;https://chatgpt.com/api/auth/session&lt;/a&gt; 获取 &lt;code&gt;accessToken&lt;/code&gt; 这个值&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;RefreshToken&lt;/code&gt; 获取: 此处不提供获取方法。&lt;/li&gt; &#xA;  &lt;li&gt;免登录 gpt3.5 无需传入 Token&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;ArkoseToken&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;h4&gt;目前支持外部服务提供 ArkoseToken&lt;/h4&gt; &#xA; &lt;h4&gt;推荐使用 docker-compose 方式部署, 已内置 Arkose 服务&lt;/h4&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;设置环境变量ARKOSE_TOKEN_URL&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;在需要&lt;code&gt;ArkoseToken&lt;/code&gt;的时候，&lt;code&gt;chat2api&lt;/code&gt;会向&lt;code&gt;ARKOSE_TOKEN_URL&lt;/code&gt;发送&lt;code&gt;POST&lt;/code&gt;请求&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;请按照以下格式提供外部服务：&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;请求体：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-request&#34;&gt;{&#34;blob&#34;: &#34;rFYaxQNEApDlx/Db.KyrE79pAAFBs70CYtbM4pMNUsc7jIkLGdiDs7vziHRGe78bqWXDo0AYyq2A10qIlcTt89lBYXJqCbONC/nD8C199pEZ/c9ocVKKtM27jZQ7fyOpWd9p5qjKeXT4xEGBFpoE3Re1DwdQeijYp7VMJQyw7RYN+IDB1QEx3aKSO6aTI+ivnhw9ztfn/p1SkvAyyOhur/ArF08WQ+rXQpxpttaSQlzMsIwlYbuUUuYE2f9JrQaYG7qip1DKvju111P6wTNy4QVlMXG32VrzaOWh4nmQ0lOcZ1DmN6u2aeJZotffHV2zOOQAqqnParidTbN+qFre2t77ZwBuGKGqLyT8LeOp02GdFwcyw0kkeX+L7vwYAzBpjA5ky0r0X+i8HpzWt8QCyWzEW9kHn9LLCTwg2MOumzjb66Ad4WDe+C1bAcOKuEyXiYh+a1cWZAOdzEuxEg90yCfI7DZR94BsoDR85gEC/Og88i098u5HV7hZZEOQ6J8fmi68FSyPkN7oLCmBsZCMAZqzapNP/MkeIMExrdw7Jf/PtMrZN4bwM56mWfyIJf5h/zXu8PUajVwE9Pj/M5VtB0spZg49JNeHExosVCAB0C0JW+T8vEIwoqiY4pRQ0lbMHTQZFpU2xURTgcgh+m6g1SEYR1FY3de1XnzfiTQq1RTNJPydj5xpt6r6okr8yIJdRhmVXlQI+pS7vi3+Lls2hnpr7L+l1mcUIMPZNBCs3AUFJNpp6SwQjZkPvKggg1p+uS6PdvKRizM9O9+FKc103AhuSia8KTrvU8tWhBhCzIHCD4LNfnkjuBWSdbDttva4AEXUoPuKkQCWaBzq4lQPUIHFOM9HmNe738vVkNdAuOYffxDNegcpIxLVgZGfbgLQ=&#34;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;响应体：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-response&#34;&gt;{&#34;token&#34;: &#34;45017c7bb17115f36.7290869304|r=ap-southeast-1|meta=3|metabgclr=transparent|metaiconclr=%23757575|guitextcolor=%23000000|pk=0A1D34FC-659D-4E23-B17B-694DCFCF6A6C|at=40|sup=1|rid=3|ag=101|cdn_url=https%3A%2F%2Ftcr9i.openai.com%2Fcdn%2Ffc|lurl=https%3A%2F%2Faudio-ap-southeast-1.arkoselabs.com|surl=https%3A%2F%2Ftcr9i.openai.com|smurl=https%3A%2F%2Ftcr9i.openai.com%2Fcdn%2Ffc%2Fassets%2Fstyle-manager&#34;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;常见问题&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;错误代码： &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;code&gt;401&lt;/code&gt;：当前IP不支持免登录，请尝试更换IP地址，或者在环境变量 &lt;code&gt;PROXY_URL&lt;/code&gt; 中设置代理，或者你的身份验证失败。&lt;/li&gt; &#xA;    &lt;li&gt;&lt;code&gt;403&lt;/code&gt;：请在日志中查看具体报错信息&lt;/li&gt; &#xA;    &lt;li&gt;&lt;code&gt;429&lt;/code&gt;：当前IP请求1小时内请求超过限制，请稍后再试，或更换ip。&lt;/li&gt; &#xA;    &lt;li&gt;&lt;code&gt;500&lt;/code&gt;：服务器内部错误，请求失败。&lt;/li&gt; &#xA;    &lt;li&gt;&lt;code&gt;502&lt;/code&gt;：服务器网关错误，或网络不可用，请尝试更换网络环境。&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;已知情况： &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;日本IP很多不支持免登，免登3.5建议使用美国IP&lt;/li&gt; &#xA;    &lt;li&gt;99%的账号都支持免费 &lt;code&gt;GPT-4o&lt;/code&gt; ，但根据IP地区开启，目前日本和新加坡IP已知开启概率较大&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;环境变量 &lt;code&gt;AUTHORIZATION&lt;/code&gt; 是什么？ &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;是一个自己给chat2api设置的一个身份验证，设置后才可使用已保存的 Tokens 轮询，请求时当作 &lt;code&gt;APIKEY&lt;/code&gt; 传入&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;AccessToken 如何获取？ &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;chatgpt官网登录后，再打开 &lt;a href=&#34;https://chatgpt.com/api/auth/session&#34;&gt;https://chatgpt.com/api/auth/session&lt;/a&gt; 获取 &lt;code&gt;accessToken&lt;/code&gt; 这个值&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;PLUS账号报错&lt;code&gt;403&lt;/code&gt;？ &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;PLUS账号需要配置 &lt;code&gt;ArkoseToken&lt;/code&gt;，请根据上文进行配置&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;ArkoseToken 是什么，怎么获取？ &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;请参考上文的说明，更多请参考 &lt;a href=&#34;https://www.arkoselabs.com/&#34;&gt;https://www.arkoselabs.com/&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;赞助商&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://capsolver.com/?utm_source=github&amp;amp;utm_medium=github_banner&amp;amp;utm_campaign=chat2api&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lanqian528/chat2api/main/docs/capsolver.jpg&#34; alt=&#34;Capsolver&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MIT License&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>alexfazio/viral-clips-crew</title>
    <updated>2024-05-22T01:32:59Z</updated>
    <id>tag:github.com,2024-05-22:/alexfazio/viral-clips-crew</id>
    <link href="https://github.com/alexfazio/viral-clips-crew" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Your CrewAI Powered Video Editing Assistant&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;viral-clips-crew (prototype)&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/alexfazio/viral-clips-crew/assets/34505954/c69da629-06eb-4279-a5cb-0d8d7fc1dfee&#34; width=&#34;600px&#34; height=&#34;auto&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;Your &lt;a href=&#34;https://github.com/joaomdmoura/crewAI&#34;&gt;CrewAI&lt;/a&gt; Powered Video Editing Assistant&lt;/h1&gt; &#xA;&lt;p&gt;Are you a social media content curator? Skip the tedious editing process and get polished video highlights in minutes. &lt;code&gt;viral-clips-crew&lt;/code&gt; watches and listens to long-form content, extracting the most striking and potentially viral segments, ready for publication on social media.&lt;/p&gt; &#xA;&lt;h2&gt;Content Repurposing Made Easy&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;viral-clips-crew&lt;/code&gt; helps you repackage your valuable content in new and engaging ways to capture attention on social media and drive traffic back to the original long-form piece. Whether you&#39;re looking to refresh your own content or recycle content from other creators, this tool streamlines the process, making content repurposing effortless and efficient.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;This project requires:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.7+&lt;/li&gt; &#xA; &lt;li&gt;CrewAI&lt;/li&gt; &#xA; &lt;li&gt;OpenAI API key / Google Gemini API key&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All required Python libraries are listed in &lt;code&gt;pyproject.toml&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repository to your local machine:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/alexfazio/viral-clips-crew.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Install Poetry to automatically manage project dependencies:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install poetry&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Install the required Python packages using Poetry:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;poetry install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Open &lt;code&gt;.env&lt;/code&gt; and insert your OpenAI API key.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Here&#39;s the revised description:&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;After setting up, drag your desired clip into the &lt;code&gt;input_files&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Gemini can process videos up to 1 hour in length. If you are using the OpenAI API, please ensure that the clip is less than 15 minutes in length. The current LLM context windows are approximately 15 minutes.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Run &lt;code&gt;viral-clips-crew&lt;/code&gt; using Poetry with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;poetry run python app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will kickstart the process from beginning to completion.&lt;/p&gt; &#xA;&lt;p&gt;Final output will be in the &lt;code&gt;subtitler_output&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;If you like this project and want to support it, please consider leaving a star. Every contribution helps keep the project running. Thank you!&lt;/p&gt; &#xA;&lt;h2&gt;Note&lt;/h2&gt; &#xA;&lt;p&gt;The code for &lt;code&gt;viral-clips-crew&lt;/code&gt; is intended for demonstrative purposes and is not meant for production use. The API keys are hardcoded and need to be replaced with your own. Always ensure your keys are kept secure.&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;Thanks to &lt;a href=&#34;https://x.com/Cyb3rCh1ck3n&#34;&gt;Rip&amp;amp;Tear&lt;/a&gt; for his support on the early prototype build.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the terms of the MIT license.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://x.com/alxfazio/status/1791863931931078719&#34;&gt;&lt;img src=&#34;https://i.imgur.com/TBD2bvj.png&#34; alt=&#34;Watch the video&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>HumanSignal/labelImg</title>
    <updated>2024-05-22T01:32:59Z</updated>
    <id>tag:github.com,2024-05-22:/HumanSignal/labelImg</id>
    <link href="https://github.com/HumanSignal/labelImg" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LabelImg is now part of the Label Studio community. The popular image annotation tool created by Tzutalin is no longer actively being developed, but you can check out Label Studio, the open source data labeling tool for images, text, hypertext, audio, video and time-series data.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. image:: /readme/images/labelimg.png :target: &lt;a href=&#34;https://github.com/heartexlabs/label-studio&#34;&gt;https://github.com/heartexlabs/label-studio&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Label Studio is a modern, multi-modal data annotation tool&lt;/h1&gt; &#xA;&lt;p&gt;LabelImg, the popular image annotation tool created by Tzutalin with the help of dozens contributors, is no longer actively being developed and has become part of the Label Studio community. Check out &lt;code&gt;Label Studio &amp;lt;https://github.com/heartexlabs/label-studio&amp;gt;&lt;/code&gt;&lt;strong&gt;, the most flexible open source data labeling tool for images, text, hypertext, audio, video and time-series data. &lt;code&gt;Install &amp;lt;https://labelstud.io/guide/install.html&amp;gt;&lt;/code&gt;&lt;/strong&gt; Label Studio and join the &lt;code&gt;slack community &amp;lt;https://label-studio.slack.com/&amp;gt;&lt;/code&gt;__ to get started.&lt;/p&gt; &#xA;&lt;p&gt;.. image:: /readme/images/label-studio-1-6-player-screenshot.png :target: &lt;a href=&#34;https://github.com/heartexlabs/label-studio&#34;&gt;https://github.com/heartexlabs/label-studio&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;About LabelImg&lt;/h1&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/pypi/v/labelimg.svg&#34;&gt;https://img.shields.io/pypi/v/labelimg.svg&lt;/a&gt; :target: &lt;a href=&#34;https://pypi.python.org/pypi/labelimg&#34;&gt;https://pypi.python.org/pypi/labelimg&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/github/workflow/status/tzutalin/labelImg/Package?style=for-the-badge&#34;&gt;https://img.shields.io/github/workflow/status/tzutalin/labelImg/Package?style=for-the-badge&lt;/a&gt; :alt: GitHub Workflow Status&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/badge/lang-en-blue.svg&#34;&gt;https://img.shields.io/badge/lang-en-blue.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/tzutalin/labelImg&#34;&gt;https://github.com/tzutalin/labelImg&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/badge/lang-zh-green.svg&#34;&gt;https://img.shields.io/badge/lang-zh-green.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/tzutalin/labelImg/raw/master/readme/README.zh.rst&#34;&gt;https://github.com/tzutalin/labelImg/blob/master/readme/README.zh.rst&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/badge/lang-jp-green.svg&#34;&gt;https://img.shields.io/badge/lang-jp-green.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/tzutalin/labelImg/raw/master/readme/README.jp.rst&#34;&gt;https://github.com/tzutalin/labelImg/blob/master/readme/README.jp.rst&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;LabelImg is a graphical image annotation tool.&lt;/p&gt; &#xA;&lt;p&gt;It is written in Python and uses Qt for its graphical interface.&lt;/p&gt; &#xA;&lt;p&gt;Annotations are saved as XML files in PASCAL VOC format, the format used by &lt;code&gt;ImageNet &amp;lt;http://www.image-net.org/&amp;gt;&lt;/code&gt;__. Besides, it also supports YOLO and CreateML formats.&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://raw.githubusercontent.com/tzutalin/labelImg/master/demo/demo3.jpg&#34;&gt;https://raw.githubusercontent.com/tzutalin/labelImg/master/demo/demo3.jpg&lt;/a&gt; :alt: Demo Image&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://raw.githubusercontent.com/tzutalin/labelImg/master/demo/demo.jpg&#34;&gt;https://raw.githubusercontent.com/tzutalin/labelImg/master/demo/demo.jpg&lt;/a&gt; :alt: Demo Image&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Watch a demo video &amp;lt;https://youtu.be/p0nR2YsCY_U&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Get from PyPI but only python3.0 or above&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;This is the simplest (one-command) install method on modern Linux distributions such as Ubuntu and Fedora.&#xA;&#xA;.. code:: shell&#xA;&#xA;    pip3 install labelImg&#xA;    labelImg&#xA;    labelImg [IMAGE_PATH] [PRE-DEFINED CLASS FILE]&#xA;&#xA;&#xA;Build from source&#xA;~~~~~~~~~~~~~~~~~&#xA;&#xA;Linux/Ubuntu/Mac requires at least `Python&#xA;2.6 &amp;lt;https://www.python.org/getit/&amp;gt;`__ and has been tested with `PyQt&#xA;4.8 &amp;lt;https://www.riverbankcomputing.com/software/pyqt/intro&amp;gt;`__. However, `Python&#xA;3 or above &amp;lt;https://www.python.org/getit/&amp;gt;`__ and  `PyQt5 &amp;lt;https://pypi.org/project/PyQt5/&amp;gt;`__ are strongly recommended.&#xA;&#xA;&#xA;Ubuntu Linux&#xA;^^^^^^^^^^^^&#xA;&#xA;Python 3 + Qt5&#xA;&#xA;.. code:: shell&#xA;&#xA;    sudo apt-get install pyqt5-dev-tools&#xA;    sudo pip3 install -r requirements/requirements-linux-python3.txt&#xA;    make qt5py3&#xA;    python3 labelImg.py&#xA;    python3 labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]&#xA;&#xA;macOS&#xA;^^^^^&#xA;&#xA;Python 3 + Qt5&#xA;&#xA;.. code:: shell&#xA;&#xA;    brew install qt  # Install qt-5.x.x by Homebrew&#xA;    brew install libxml2&#xA;&#xA;    or using pip&#xA;&#xA;    pip3 install pyqt5 lxml # Install qt and lxml by pip&#xA;&#xA;    make qt5py3&#xA;    python3 labelImg.py&#xA;    python3 labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]&#xA;&#xA;&#xA;Python 3 Virtualenv (Recommended)&#xA;&#xA;Virtualenv can avoid a lot of the QT / Python version issues&#xA;&#xA;.. code:: shell&#xA;&#xA;    brew install python3&#xA;    pip3 install pipenv&#xA;    pipenv run pip install pyqt5==5.15.2 lxml&#xA;    pipenv run make qt5py3&#xA;    pipenv run python3 labelImg.py&#xA;    [Optional] rm -rf build dist; pipenv run python setup.py py2app -A;mv &#34;dist/labelImg.app&#34; /Applications&#xA;&#xA;Note: The Last command gives you a nice .app file with a new SVG Icon in your /Applications folder. You can consider using the script: build-tools/build-for-macos.sh&#xA;&#xA;&#xA;Windows&#xA;^^^^^^^&#xA;&#xA;Install `Python &amp;lt;https://www.python.org/downloads/windows/&amp;gt;`__,&#xA;`PyQt5 &amp;lt;https://www.riverbankcomputing.com/software/pyqt/download5&amp;gt;`__&#xA;and `install lxml &amp;lt;http://lxml.de/installation.html&amp;gt;`__.&#xA;&#xA;Open cmd and go to the `labelImg &amp;lt;#labelimg&amp;gt;`__ directory&#xA;&#xA;.. code:: shell&#xA;&#xA;    pyrcc4 -o libs/resources.py resources.qrc&#xA;    For pyqt5, pyrcc5 -o libs/resources.py resources.qrc&#xA;&#xA;    python labelImg.py&#xA;    python labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]&#xA;&#xA;If you want to package it into a separate EXE file&#xA;&#xA;.. code:: shell&#xA;&#xA;    Install pyinstaller and execute:&#xA;&#xA;    pip install pyinstaller&#xA;    pyinstaller --hidden-import=pyqt5 --hidden-import=lxml -F -n &#34;labelImg&#34; -c labelImg.py -p ./libs -p ./&#xA;&#xA;Windows + Anaconda&#xA;^^^^^^^^^^^^^^^^^^&#xA;&#xA;Download and install `Anaconda &amp;lt;https://www.anaconda.com/download/#download&amp;gt;`__ (Python 3+)&#xA;&#xA;Open the Anaconda Prompt and go to the `labelImg &amp;lt;#labelimg&amp;gt;`__ directory&#xA;&#xA;.. code:: shell&#xA;&#xA;    conda install pyqt=5&#xA;    conda install -c anaconda lxml&#xA;    pyrcc5 -o libs/resources.py resources.qrc&#xA;    python labelImg.py&#xA;    python labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]&#xA;&#xA;Use Docker&#xA;~~~~~~~~~~~~~~~~~&#xA;.. code:: shell&#xA;&#xA;    docker run -it \&#xA;    --user $(id -u) \&#xA;    -e DISPLAY=unix$DISPLAY \&#xA;    --workdir=$(pwd) \&#xA;    --volume=&#34;/home/$USER:/home/$USER&#34; \&#xA;    --volume=&#34;/etc/group:/etc/group:ro&#34; \&#xA;    --volume=&#34;/etc/passwd:/etc/passwd:ro&#34; \&#xA;    --volume=&#34;/etc/shadow:/etc/shadow:ro&#34; \&#xA;    --volume=&#34;/etc/sudoers.d:/etc/sudoers.d:ro&#34; \&#xA;    -v /tmp/.X11-unix:/tmp/.X11-unix \&#xA;    tzutalin/py2qt4&#xA;&#xA;    make qt4py2;./labelImg.py&#xA;&#xA;You can pull the image which has all of the installed and required dependencies. `Watch a demo video &amp;lt;https://youtu.be/nw1GexJzbCI&amp;gt;`__&#xA;&#xA;&#xA;Usage&#xA;-----&#xA;&#xA;Steps (PascalVOC)&#xA;~~~~~~~~~~~~~~~~~&#xA;&#xA;1. Build and launch using the instructions above.&#xA;2. Click &#39;Change default saved annotation folder&#39; in Menu/File&#xA;3. Click &#39;Open Dir&#39;&#xA;4. Click &#39;Create RectBox&#39;&#xA;5. Click and release left mouse to select a region to annotate the rect&#xA;   box&#xA;6. You can use right mouse to drag the rect box to copy or move it&#xA;&#xA;The annotation will be saved to the folder you specify.&#xA;&#xA;You can refer to the below hotkeys to speed up your workflow.&#xA;&#xA;Steps (YOLO)&#xA;~~~~~~~~~~~~&#xA;&#xA;1. In ``data/predefined_classes.txt`` define the list of classes that will be used for your training.&#xA;&#xA;2. Build and launch using the instructions above.&#xA;&#xA;3. Right below &#34;Save&#34; button in the toolbar, click &#34;PascalVOC&#34; button to switch to YOLO format.&#xA;&#xA;4. You may use Open/OpenDIR to process single or multiple images. When finished with a single image, click save.&#xA;&#xA;A txt file of YOLO format will be saved in the same folder as your image with same name. A file named &#34;classes.txt&#34; is saved to that folder too. &#34;classes.txt&#34; defines the list of class names that your YOLO label refers to.&#xA;&#xA;Note:&#xA;&#xA;- Your label list shall not change in the middle of processing a list of images. When you save an image, classes.txt will also get updated, while previous annotations will not be updated.&#xA;&#xA;- You shouldn&#39;t use &#34;default class&#34; function when saving to YOLO format, it will not be referred.&#xA;&#xA;- When saving as YOLO format, &#34;difficult&#34; flag is discarded.&#xA;&#xA;Create pre-defined classes&#xA;~~~~~~~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;You can edit the&#xA;`data/predefined\_classes.txt &amp;lt;https://github.com/tzutalin/labelImg/blob/master/data/predefined_classes.txt&amp;gt;`__&#xA;to load pre-defined classes&#xA;&#xA;Annotation visualization&#xA;~~~~~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;1. Copy the existing lables file to same folder with the images. The labels file name must be same with image file name.&#xA;&#xA;2. Click File and choose &#39;Open Dir&#39; then Open the image folder.&#xA;&#xA;3. Select image in File List, it will appear the bounding box and label for all objects in that image.&#xA;&#xA;(Choose Display Labels mode in View to show/hide lablels)&#xA;&#xA;&#xA;Hotkeys&#xA;~~~~~~~&#xA;&#xA;+--------------------+--------------------------------------------+&#xA;| Ctrl + u           | Load all of the images from a directory    |&#xA;+--------------------+--------------------------------------------+&#xA;| Ctrl + r           | Change the default annotation target dir   |&#xA;+--------------------+--------------------------------------------+&#xA;| Ctrl + s           | Save                                       |&#xA;+--------------------+--------------------------------------------+&#xA;| Ctrl + d           | Copy the current label and rect box        |&#xA;+--------------------+--------------------------------------------+&#xA;| Ctrl + Shift + d   | Delete the current image                   |&#xA;+--------------------+--------------------------------------------+&#xA;| Space              | Flag the current image as verified         |&#xA;+--------------------+--------------------------------------------+&#xA;| w                  | Create a rect box                          |&#xA;+--------------------+--------------------------------------------+&#xA;| d                  | Next image                                 |&#xA;+--------------------+--------------------------------------------+&#xA;| a                  | Previous image                             |&#xA;+--------------------+--------------------------------------------+&#xA;| del                | Delete the selected rect box               |&#xA;+--------------------+--------------------------------------------+&#xA;| Ctrl++             | Zoom in                                    |&#xA;+--------------------+--------------------------------------------+&#xA;| Ctrl--             | Zoom out                                   |&#xA;+--------------------+--------------------------------------------+&#xA;| ↑→↓←               | Keyboard arrows to move selected rect box  |&#xA;+--------------------+--------------------------------------------+&#xA;&#xA;**Verify Image:**&#xA;&#xA;When pressing space, the user can flag the image as verified, a green background will appear.&#xA;This is used when creating a dataset automatically, the user can then through all the pictures and flag them instead of annotate them.&#xA;&#xA;**Difficult:**&#xA;&#xA;The difficult field is set to 1 indicates that the object has been annotated as &#34;difficult&#34;, for example, an object which is clearly visible but difficult to recognize without substantial use of context.&#xA;According to your deep neural network implementation, you can include or exclude difficult objects during training.&#xA;&#xA;How to reset the settings&#xA;~~~~~~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;In case there are issues with loading the classes, you can either:&#xA;&#xA;1. From the top menu of the labelimg click on Menu/File/Reset All&#xA;2. Remove the `.labelImgSettings.pkl` from your home directory. In Linux and Mac you can do:&#xA;    `rm ~/.labelImgSettings.pkl`&#xA;&#xA;&#xA;How to contribute&#xA;~~~~~~~~~~~~~~~~~&#xA;&#xA;Send a pull request&#xA;&#xA;License&#xA;~~~~~~~&#xA;`Free software: MIT license &amp;lt;https://github.com/tzutalin/labelImg/blob/master/LICENSE&amp;gt;`_&#xA;&#xA;Citation: Tzutalin. LabelImg. Git code (2015). https://github.com/tzutalin/labelImg&#xA;&#xA;Related and additional tools&#xA;~~~~~~~~~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;1. `Label Studio &amp;lt;https://github.com/heartexlabs/label-studio&amp;gt;`__ to label images, text, audio, video and time-series data for machine learning and AI&#xA;2. `ImageNet Utils &amp;lt;https://github.com/tzutalin/ImageNet_Utils&amp;gt;`__ to&#xA;   download image, create a label text for machine learning, etc&#xA;3. `Use Docker to run labelImg &amp;lt;https://hub.docker.com/r/tzutalin/py2qt4&amp;gt;`__&#xA;4. `Generating the PASCAL VOC TFRecord files &amp;lt;https://github.com/tensorflow/models/blob/4f32535fe7040bb1e429ad0e3c948a492a89482d/research/object_detection/g3doc/preparing_inputs.md#generating-the-pascal-voc-tfrecord-files&amp;gt;`__&#xA;5. `App Icon based on Icon by Nick Roach (GPL) &amp;lt;https://www.elegantthemes.com/&amp;gt;`__&#xA;6. `Setup python development in vscode &amp;lt;https://tzutalin.blogspot.com/2019/04/set-up-visual-studio-code-for-python-in.html&amp;gt;`__&#xA;7. `The link of this project on iHub platform &amp;lt;https://code.ihub.org.cn/projects/260/repository/labelImg&amp;gt;`__&#xA;8. `Convert annotation files to CSV format or format for Google Cloud AutoML &amp;lt;https://github.com/tzutalin/labelImg/tree/master/tools&amp;gt;`__&#xA;&#xA;&#xA;&#xA;Stargazers over time&#xA;~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;.. image:: https://starchart.cc/tzutalin/labelImg.svg&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>