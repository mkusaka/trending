<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-02T01:33:33Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>adamian98/pulse</title>
    <updated>2022-08-02T01:33:33Z</updated>
    <id>tag:github.com,2022-08-02:/adamian98/pulse</id>
    <link href="https://github.com/adamian98/pulse" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models&lt;/h1&gt; &#xA;&lt;p&gt;Code accompanying CVPR&#39;20 paper of the same title. Paper link: &lt;a href=&#34;https://arxiv.org/pdf/2003.03808.pdf&#34;&gt;https://arxiv.org/pdf/2003.03808.pdf&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;NOTE&lt;/h2&gt; &#xA;&lt;p&gt;We have noticed a lot of concern that PULSE will be used to identify individuals whose faces have been blurred out. We want to emphasize that this is impossible - &lt;strong&gt;PULSE makes imaginary faces of people who do not exist, which should not be confused for real people.&lt;/strong&gt; It will &lt;strong&gt;not&lt;/strong&gt; help identify or reconstruct the original image.&lt;/p&gt; &#xA;&lt;p&gt;We also want to address concerns of bias in PULSE. &lt;strong&gt;We have now included a new section in the &lt;a href=&#34;https://arxiv.org/pdf/2003.03808.pdf&#34;&gt;paper&lt;/a&gt; and an accompanying model card directly addressing this bias.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/adamian98/pulse/master/readme_resources/014.jpeg&#34; alt=&#34;Transformation Preview&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/adamian98/pulse/master/readme_resources/034.jpeg&#34; alt=&#34;Transformation Preview&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/adamian98/pulse/master/readme_resources/094.jpeg&#34; alt=&#34;Transformation Preview&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Table of Contents&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/adamian98/pulse/master/#pulse-self-supervised-photo-upsampling-via-latent-space-exploration-of-generative-models&#34;&gt;PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/adamian98/pulse/master/#table-of-contents&#34;&gt;Table of Contents&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/adamian98/pulse/master/#what-does-it-do&#34;&gt;What does it do?&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/adamian98/pulse/master/#usage&#34;&gt;Usage&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/adamian98/pulse/master/#prereqs&#34;&gt;Prereqs&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/adamian98/pulse/master/#data&#34;&gt;Data&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/adamian98/pulse/master/#applying-pulse&#34;&gt;Applying PULSE&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What does it do?&lt;/h2&gt; &#xA;&lt;p&gt;Given a low-resolution input image, PULSE searches the outputs of a generative model (here, &lt;a href=&#34;https://github.com/NVlabs/stylegan&#34;&gt;StyleGAN&lt;/a&gt;) for high-resolution images that are perceptually realistic and downscale correctly.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/adamian98/pulse/master/readme_resources/transformation.gif&#34; alt=&#34;Transformation Preview&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;The main file of interest for applying PULSE is &lt;code&gt;run.py&lt;/code&gt;. A full list of arguments with descriptions can be found in that file; here we describe those relevant to getting started.&lt;/p&gt; &#xA;&lt;h3&gt;Prereqs&lt;/h3&gt; &#xA;&lt;p&gt;You will need to install cmake first (required for dlib, which is used for face alignment). Currently the code only works with CUDA installed (and therefore requires an appropriate GPU) and has been tested on Linux and Windows. For the full set of required Python packages, create a Conda environment from the provided YAML, e.g.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda create -f pulse.yml &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or (Anaconda on Windows):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda env create -n pulse -f pulse.yml&#xA;conda activate pulse&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In some environments (e.g. on Windows), you may have to edit the pulse.yml to remove the version specific hash on each dependency and remove any dependency that still throws an error after running &lt;code&gt;conda env create...&lt;/code&gt; (such as readline)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dependencies&#xA;  - blas=1.0=mkl&#xA;  ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dependencies&#xA;  - blas=1.0&#xA; ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, you will need an internet connection the first time you run the code as it will automatically download the relevant pretrained model from Google Drive (if it has already been downloaded, it will use the local copy). In the event that the public Google Drive is out of capacity, add the files to your own Google Drive instead; get the share URL and replace the ID in the &lt;a href=&#34;https://drive.google.com/uc?=ID&#34;&gt;https://drive.google.com/uc?=ID&lt;/a&gt; links in &lt;code&gt;align_face.py&lt;/code&gt; and &lt;code&gt;PULSE.py&lt;/code&gt; with the new file ids from the share URL given by your own Drive file.&lt;/p&gt; &#xA;&lt;h3&gt;Data&lt;/h3&gt; &#xA;&lt;p&gt;By default, input data for &lt;code&gt;run.py&lt;/code&gt; should be placed in &lt;code&gt;./input/&lt;/code&gt; (though this can be modified). However, this assumes faces have already been aligned and downscaled. If you have data that is not already in this form, place it in &lt;code&gt;realpics&lt;/code&gt; and run &lt;code&gt;align_face.py&lt;/code&gt; which will automatically do this for you. (Again, all directories can be changed by command line arguments if more convenient.) You will at this stage pic a downscaling factor.&lt;/p&gt; &#xA;&lt;p&gt;Note that if your data begins at a low resolution already, downscaling it further will retain very little information. In this case, you may wish to bicubically upsample (usually, to 1024x1024) and allow &lt;code&gt;align_face.py&lt;/code&gt; to downscale for you.&lt;/p&gt; &#xA;&lt;h3&gt;Applying PULSE&lt;/h3&gt; &#xA;&lt;p&gt;Once your data is appropriately formatted, all you need to do is&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python run.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Enjoy!&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>city-super/BungeeNeRF</title>
    <updated>2022-08-02T01:33:33Z</updated>
    <id>tag:github.com,2022-08-02:/city-super/BungeeNeRF</id>
    <link href="https://github.com/city-super/BungeeNeRF" rel="alternate"></link>
    <summary type="html">&lt;p&gt;[ECCV22] BungeeNeRF: Progressive Neural Radiance Field for Extreme Multi-scale Scene Rendering&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;BungeeNeRF&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the code release for &lt;a href=&#34;https://city-super.github.io/citynerf/img/BungeeNeRF_ECCV22.pdf&#34;&gt;BungeeNeRF: Progressive Neural Radiance Field for Extreme Multi-scale Scene Rendering&lt;/a&gt;, aka &lt;a href=&#34;https://city-super.github.io/citynerf/&#34;&gt;CityNeRF&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/city-super/BungeeNeRF/main/imgs/training_mechanism.png&#34; alt=&#34;scheme&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Abstract&lt;/h2&gt; &#xA;&lt;p&gt;Neural Radiance Field (NeRF) has achieved outstanding performance in modeling 3D objects and controlled scenes, usually under a single scale. In this work, we focus on multi-scale cases where large changes in imagery are observed at drastically different scales. This scenario vastly exists in real-world 3D environments, such as city scenes, with views ranging from satellite level that captures the overview of a city, to ground level imagery showing complex details of an architecture; and can also be commonly identified in landscape and delicate minecraft 3D models. The wide span of viewing positions within these scenes yields multi-scale renderings with very different levels of detail, which poses great challenges to neural radiance field and biases it towards compromised results. To address these issues, we introduce BungeeNeRF, a progressive neural radiance field that achieves level-of-detail rendering across drastically varied scales. Starting from fitting distant views with a shallow base block, as training progresses, new blocks are appended to accommodate the emerging details in the increasingly closer views. The strategy progressively activates high-frequency channels in NeRF‚Äôs positional encoding inputs and successively unfold more complex details as the training proceeds. We demonstrate the superiority of BungeeNeRF in modeling diverse multi-scale scenes with drastically varying views on multiple data sources (city models, synthetic, and drone captured data) and its support for high-quality rendering in different levels of detail.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;We recommend using &lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&gt;Anaconda&lt;/a&gt; to set up the environment. Run the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/city-super/BungeeNeRF.git; cd BungeeNeRF&#xA;conda create --name bungee python=3.7; conda activate bungee&#xA;conda install pip; pip install --upgrade pip&#xA;pip install -r requirements.txt&#xA;mkdir data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Data&lt;/h2&gt; &#xA;&lt;p&gt;Two pre-processed data can be download from: &lt;a href=&#34;https://drive.google.com/drive/folders/1ybq-BuRH0EEpcp5OZT9xEMi-Px1pdx4D?usp=sharing&#34;&gt;Google Drive&lt;/a&gt;. Unzip &lt;code&gt;multiscale_google_56Leonard.zip&lt;/code&gt; and &lt;code&gt;multiscale_google_Transamerica.zip&lt;/code&gt; to &lt;code&gt;data&lt;/code&gt; dir. These two folders contain rendered images and processed camera poses. We also offer two .eps files that can be loaded into &lt;a href=&#34;https://earth.google.com/studio/&#34;&gt;Google Earth Studio&lt;/a&gt;. You can adjust camera trajectory and render the most updated views for yourself. The appearance of cities are always updated in GES :). We recommend reading &lt;a href=&#34;https://earth.google.com/studio/docs/advanced-features/3d-camera-export/&#34;&gt;3D Camera Export&lt;/a&gt; and &lt;a href=&#34;https://www.google.com/earth/studio/faq/&#34;&gt;FAQs&lt;/a&gt; for camera configuration and permitted usages.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/city-super/BungeeNeRF/main/imgs/panel.png&#34; alt=&#34;panel&#34;&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; Exported 3D tracking data (.json) format &lt;/summary&gt; {&#34;name&#34;: xxxx, &#34;width&#34;: xxxx, &#34;height&#34;: xxxx, &#34;numFrames&#34;: xxxx, &#34;durationSeconds&#34;: 56.3, &#34;cameraFrames&#34;: [ { &#34;position&#34;: { &#34;x&#34;: xxx, &#34;y&#34;: xxx, &#34;z&#34;: xxx }, &#34;rotation&#34;: { &#34;x&#34;: xxx, &#34;y&#34;: xxx, &#34;z&#34;: xxx }, &#34;coordinate&#34;: { &#34;latitude&#34;: xx, &#34;longitude&#34;: xx, &#34;altitude&#34;: xxx }, &#34;fovVertical&#34;: xx }, ... ], &#34;trackPoints&#34;: []} &#xA;&lt;/details&gt; &#xA;&lt;p&gt;Some notes on processing camera poses exported from Google Earth Studio:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Scale it such that the whole scene is within a period (e.g. [-pi, pi]) to be effectively represented by the positional encoding.&lt;/li&gt; &#xA; &lt;li&gt;To get the rotation matrix, use the &#34;rotation&#34; entry in the exported .json file and consider applying x&#39;=-x, y&#39;=180-y, z&#39;=180+z to get Euler angles.&lt;/li&gt; &#xA; &lt;li&gt;H, W, Focal can be directly read from the exported .json file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Feel free to contact authors if you have any question about the data.&lt;/p&gt; &#xA;&lt;h2&gt;Running&lt;/h2&gt; &#xA;&lt;p&gt;To run experiments, use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python run_bungee.py --config configs/EXP_CONFIG_FILE&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The training starts from the furthest scale, with &lt;code&gt;cur_stage=0&lt;/code&gt;. After an ideal amount of training you can switch to the next training stage by specifying &lt;code&gt;cur_stage=1&lt;/code&gt;, which will include one finer scale into the training set; and start training from a previous stage checkpoint specified with &lt;code&gt;--ft_path&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python run_bungee.py --config configs/EXP_CONFIG_FILE --cur_stage 1 --ft_path PREV_CKPT_PATH&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Rendering&lt;/h2&gt; &#xA;&lt;p&gt;To render views, use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python run_bungee.py --config configs/EXP_CONFIG_FILE --render_test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{xiangli2022bungeenerf,&#xA;    title={BungeeNeRF: Progressive Neural Radiance Field for Extreme Multi-scale Scene Rendering},&#xA;    author={Xiangli, Yuanbo and Xu, Linning and Pan, Xingang, and Zhao, Nanxuan and Rao, Anyi and Theobalt, Christian and Dai, Bo and Lin, Dahua},&#xA;    booktitle = {The European Conference on Computer Vision (ECCV)}, &#xA;    year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>jina-ai/discoart</title>
    <updated>2022-08-02T01:33:33Z</updated>
    <id>tag:github.com,2022-08-02:/jina-ai/discoart</id>
    <link href="https://github.com/jina-ai/discoart" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Create Disco Diffusion artworks in one line&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/.github/banner.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;b&gt;Create compelling Disco Diffusion artworks in one line&lt;/b&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://pypi.org/project/discoart/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/discoart?style=flat-square&amp;amp;label=Release&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/repository/docker/jinaai/discoart&#34;&gt;&lt;img alt=&#34;Docker Cloud Build Status&#34; src=&#34;https://img.shields.io/docker/cloud/build/jinaai/discoart?logo=docker&amp;amp;logoColor=white&amp;amp;style=flat-square&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://slack.jina.ai&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Slack-3.1k-blueviolet?logo=slack&amp;amp;logoColor=white&amp;amp;style=flat-square&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/jina-ai/discoart/blob/main/discoart.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Open-in%20Colab-brightgreen?logo=google-colab&amp;amp;style=flat-square&#34; alt=&#34;Open in Google Colab&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;DiscoArt is an elegant way of creating compelling Disco Diffusion&lt;sup&gt;&lt;a href=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/#example-application&#34;&gt;[*]&lt;/a&gt;&lt;/sup&gt; artworks for generative artists, AI enthusiasts and hard-core developers. DiscoArt has a modern &amp;amp; professional API with a beautiful codebase, ensuring high usability and maintainability. It introduces handy features such as result recovery and persistence, gRPC/HTTP serving w/o TLS, post-analysis, easing the integration to larger cross-modal or multi-modal applications.&lt;/p&gt; &#xA;&lt;p&gt;&lt;sub&gt;&lt;sup&gt;&lt;a id=&#34;example-application&#34;&gt;[*]&lt;/a&gt; Disco Diffusion is a Google Colab Notebook that leverages CLIP-Guided Diffusion to allow one to create compelling and beautiful images from text prompts. &lt;/sup&gt;&lt;/sub&gt;&lt;/p&gt; &#xA;&lt;p&gt;üíØ &lt;strong&gt;Best-in-class&lt;/strong&gt;: industry-level engineering, top-notch code quality, lean dependencies, small RAM/VRAM footprint; important bug fixes, feature improvements &lt;a href=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/FEATURES.md&#34;&gt;vs. the original DD5.6&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;üëº &lt;strong&gt;Available to all&lt;/strong&gt;: smooth install for &lt;em&gt;self-hosting&lt;/em&gt;, Google Colab &lt;em&gt;free tier&lt;/em&gt;, non-GUI (IPython) environment, and CLI! No brainfuck, no dependency hell, no stackoverflow.&lt;/p&gt; &#xA;&lt;p&gt;üé® &lt;strong&gt;Focus on create not code&lt;/strong&gt;: one-liner &lt;code&gt;create()&lt;/code&gt; with a Pythonic interface, autocompletion in IDE, and powerful features. Fetch real-time results anywhere anytime, no more worry on session outrage on Google Colab. Set initial state easily for more efficient parameter exploration.&lt;/p&gt; &#xA;&lt;p&gt;üè≠ &lt;strong&gt;Ready for integration &amp;amp; production&lt;/strong&gt;: built on top of &lt;a href=&#34;https://github.com/jina-ai/docarray&#34;&gt;DocArray&lt;/a&gt; data structure, enjoy smooth integration with &lt;a href=&#34;https://github.com/jina-ai/jina&#34;&gt;Jina&lt;/a&gt;, &lt;a href=&#34;https://github.com/jina-ai/clip-as-service&#34;&gt;CLIP-as-service&lt;/a&gt; and other cross-/multi-modal applications.&lt;/p&gt; &#xA;&lt;p&gt;‚òÅÔ∏è &lt;a href=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/#serving&#34;&gt;&lt;strong&gt;As-a-service&lt;/strong&gt;&lt;/a&gt;: simply &lt;code&gt;python -m discoart serve&lt;/code&gt;, DiscoArt is now a high-performance low-latency service supports gRPC/HTTP/websockets and TLS. Scaling up/down is one-line; Cloud-native features e.g. Kubernetes, Prometheus and Grafana is one-line. &lt;a href=&#34;https://github.com/jina-ai/jina&#34;&gt;Unbelievable simple thanks to Jina&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://twitter.com/hxiao/status/1542967938369687552?s=20&amp;amp;t=DO27EKNMADzv4WjHLQiPFA&#34;&gt;Gallery with prompts&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Do you see the &lt;code&gt;discoart-id&lt;/code&gt; in each tweet? To get the config &amp;amp; prompts, simply:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from discoart import show_config&#xA;&#xA;show_config(&#39;discoart-id&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;Python 3.7+ and CUDA-enabled PyTorch is required.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install discoart&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This applies to both &lt;em&gt;self-hosting&lt;/em&gt;, &lt;em&gt;Google Colab&lt;/em&gt;, system integration, non-GUI environments.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Self-hosted Jupyter&lt;/strong&gt;: to run a Jupyter Notebook on your own GPU machine, the easiest way is to &lt;a href=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/#run-in-docker&#34;&gt;use our prebuilt Docker image&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Use it from CLI&lt;/strong&gt;: &lt;a href=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/#cli&#34;&gt;&lt;code&gt;python -m discoart create&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;python -m discoart config&lt;/code&gt; are CLI commands.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Use it as a service&lt;/strong&gt;: &lt;a href=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/#serving&#34;&gt;&lt;code&gt;python -m discoart serve&lt;/code&gt;&lt;/a&gt; allows one to run it as gRPC/HTTP/websockets service.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/jina-ai/discoart/blob/main/discoart.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Open-in%20Colab-brightgreen?logo=google-colab&amp;amp;style=flat-square&#34; alt=&#34;Open in Google Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Create artworks&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from discoart import create&#xA;&#xA;da = create()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That&#39;s it! It will create with the &lt;a href=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/discoart/resources/default.yml&#34;&gt;default text prompts and parameters&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/.github/create-demo.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Set prompts and parameters&lt;/h3&gt; &#xA;&lt;p&gt;Supported parameters are &lt;a href=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/discoart/resources/default.yml&#34;&gt;listed here&lt;/a&gt;. You can specify them in &lt;code&gt;create()&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from discoart import create&#xA;&#xA;da = create(&#xA;    text_prompts=&#39;A painting of sea cliffs in a tumultuous storm, Trending on ArtStation.&#39;,&#xA;    init_image=&#39;https://d2vyhzeko0lke5.cloudfront.net/2f4f6dfa5a05e078469ebe57e77b72f0.png&#39;,&#xA;    skip_steps=100,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/.github/parameter-demo.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;In case you forgot a parameter, just lookup the cheatsheet at anytime:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from discoart import cheatsheet&#xA;&#xA;cheatsheet()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The difference on the parameters between DiscoArt and DD5.6 &lt;a href=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/FEATURES.md&#34;&gt;is explained here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Visualize results&lt;/h3&gt; &#xA;&lt;p&gt;Final results and intermediate results are created under the current working directory, i.e.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;./{name-docarray}/{i}-done.png&#xA;./{name-docarray}/{i}-step-{j}.png&#xA;./{name-docarray}/{i}-progress.png&#xA;./{name-docarray}/{i}-progress.gif&#xA;./{name-docarray}/da.protobuf.lz4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/.github/result-persist.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;where:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;name-docarray&lt;/code&gt; is the name of the run, you can specify it otherwise it is a random name.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;i-*&lt;/code&gt; is up to the value of &lt;code&gt;n_batches&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;*-done-*&lt;/code&gt; is the final image on done.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;*-step-*&lt;/code&gt; is the intermediate image at certain step, updated in real-time.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;*-progress.png&lt;/code&gt; is the sprite image of all intermediate results so far, updated in real-time.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;*-progress.gif&lt;/code&gt; is the animated gif of all intermediate results so far, updated in real-time.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;da.protobuf.lz4&lt;/code&gt; is the compressed protobuf of all intermediate results so far, updated in real-time.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The save frequency is controlled by &lt;code&gt;save_rate&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Moreover, &lt;code&gt;create()&lt;/code&gt; returns &lt;code&gt;da&lt;/code&gt;, a &lt;a href=&#34;https://docarray.jina.ai/fundamentals/documentarray/&#34;&gt;DocumentArray&lt;/a&gt;-type object. It contains the following information:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;All arguments passed to &lt;code&gt;create()&lt;/code&gt; function, including seed, text prompts and model parameters.&lt;/li&gt; &#xA; &lt;li&gt;4 generated image and its intermediate steps&#39; images, where &lt;code&gt;4&lt;/code&gt; is determined by &lt;code&gt;n_batches&lt;/code&gt; and is the default value.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This allows you to further post-process, analyze, export the results with powerful DocArray API.&lt;/p&gt; &#xA;&lt;p&gt;Images are stored as Data URI in &lt;code&gt;.uri&lt;/code&gt;, to save the first image as a local file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;da[0].save_uri_to_file(&#39;discoart-result.png&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To save all final images:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for idx, d in enumerate(da):&#xA;    d.save_uri_to_file(f&#39;discoart-result-{idx}.png&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also display all four final images in a grid:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;da.plot_image_sprites(skip_empty=True, show_index=True, keep_aspect_ratio=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/.github/all-results.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Or display them one by one:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for d in da:&#xA;    d.display()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or take one particular run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;da[0].display()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/.github/display.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Visualize intermediate steps&lt;/h3&gt; &#xA;&lt;p&gt;You can also zoom into a run (say the first run) and check out intermediate steps:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;da[0].chunks.plot_image_sprites(&#xA;    skip_empty=True, show_index=True, keep_aspect_ratio=True&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/.github/chunks.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can &lt;code&gt;.display()&lt;/code&gt; the chunks one by one, or save one via &lt;code&gt;.save_uri_to_file()&lt;/code&gt;, or save all intermediate steps as a GIF:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;da[0].chunks.save_gif(&#xA;    &#39;lighthouse.gif&#39;, show_index=True, inline_display=True, size_ratio=0.5&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/.github/lighthouse.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Note that &amp;gt;=0.7.14, a 20FPS gif is generated which includes all intermedidate steps.&lt;/p&gt; &#xA;&lt;h3&gt;Show/save/load configs&lt;/h3&gt; &#xA;&lt;p&gt;To show the config of a Document/DocumentArray,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from discoart import show_config&#xA;&#xA;show_config(da)  # show the config of the first run&#xA;show_config(da[3])  # show the config of the fourth run&#xA;show_config(&#xA;    &#39;discoart-06030a0198843332edc554ffebfbf288&#39;&#xA;)  # show the config of the run with a known DocArray ID&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To save the config of a Document/DocumentArray,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from discoart import save_config&#xA;&#xA;save_config(da, &#39;my.yml&#39;)  # save the config of the first run&#xA;save_config(da[3], &#39;my.yml&#39;)  # save the config of the fourth run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run &lt;code&gt;create&lt;/code&gt; from a YAML config of Document/DocumentArray,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from discoart import create, load_config&#xA;&#xA;config = load_config(&#39;my.yml&#39;)&#xA;create(**config)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also export the config as an SVG image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from discoart.config import save_config_svg&#xA;&#xA;save_config_svg(da)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/.github/discoart-3205998582.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;One can also generate runnable Python code directly from the config:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from discoart.config import export_python&#xA;&#xA;export_python(da)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Pull results anywhere anytime&lt;/h3&gt; &#xA;&lt;p&gt;If you are a free-tier Google Colab user, one annoy thing is the lost of sessions from time to time. Or sometimes you just early stop the run as the first image is not good enough, and a keyboard interrupt will prevent &lt;code&gt;.create()&lt;/code&gt; to return any result. Either case, you can easily recover the results by pulling the last session ID.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Find the session ID. It appears on top of the image. &lt;img src=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/.github/session-id.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Pull the result via that ID &lt;strong&gt;on any machine at any time&lt;/strong&gt;, not necessarily on Google Colab:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from docarray import DocumentArray&#xA;&#xA;da = DocumentArray.pull(&#39;discoart-3205998582&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Reuse a Document as initial state&lt;/h3&gt; &#xA;&lt;p&gt;Consider a Document as a self-contained data with config and image, one can use it as the initial state for the future run. Its &lt;code&gt;.tags&lt;/code&gt; will be used as the initial parameters; &lt;code&gt;.uri&lt;/code&gt; if presented will be used as the initial image.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from discoart import create&#xA;from docarray import DocumentArray&#xA;&#xA;da = DocumentArray.pull(&#39;discoart-3205998582&#39;)&#xA;&#xA;create(&#xA;    init_document=da[0],&#xA;    cut_ic_pow=0.5,&#xA;    tv_scale=600,&#xA;    cut_overview=&#39;[12]*1000&#39;,&#xA;    cut_innercut=&#39;[12]*1000&#39;,&#xA;    use_secondary_model=False,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you just want to initialize from a known DocArray ID, then simply:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from discoart import create&#xA;&#xA;create(init_document=&#39;discoart-3205998582&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Environment variables&lt;/h3&gt; &#xA;&lt;p&gt;You can set environment variables to control the meta-behavior of DiscoArt. The environment variables must be set before importing DiscoArt, either in Bash or in Python via &lt;code&gt;os.environ&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;DISCOART_LOG_LEVEL=&#39;DEBUG&#39; # more verbose logs&#xA;DISCOART_OPTOUT_CLOUD_BACKUP=&#39;1&#39; # opt-out from cloud backup&#xA;DISCOART_DISABLE_IPYTHON=&#39;1&#39; # disable ipython dependency&#xA;DISCOART_DISABLE_RESULT_SUMMARY=&#39;1&#39; # disable result summary after the run ends&#xA;DISCOART_DEFAULT_PARAMETERS_YAML=&#39;path/to/your-default.yml&#39; # use a custom default parameters file&#xA;DISCOART_CUT_SCHEDULES_YAML=&#39;path/to/your-schedules.yml&#39; # use a custom cut schedules file&#xA;DISCOART_MODELS_YAML=&#39;path/to/your-models.yml&#39; # use a custom list of models file&#xA;DISCOART_OUTPUT_DIR=&#39;path/to/your-output-dir&#39; # use a custom output directory for all images and results&#xA;DISCOART_CACHE_DIR=&#39;path/to/your-cache-dir&#39; # use a custom cache directory for models and downloads&#xA;DISCOART_DISABLE_REMOTE_MODELS=&#39;1&#39; # disable the listing of diffusion models on Github, remote diffusion models allows user to use latest models without updating the codebase.&#xA;DISCOART_REMOTE_MODELS_URL=&#39;https://yourdomain/models.yml&#39; # use a custom remote URL for fetching models list&#xA;DISCOART_DISABLE_CHECK_MODEL_SHA=&#39;1&#39; # disable checking local model SHA matches the remote model SHA&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;CLI&lt;/h2&gt; &#xA;&lt;p&gt;DiscoArt provides two commands &lt;code&gt;create&lt;/code&gt; and &lt;code&gt;config&lt;/code&gt; that allows you to run DiscoArt from CLI.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m discoart create my.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;which creates artworks from the YAML config file &lt;code&gt;my.yml&lt;/code&gt;. You can also do:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat config.yml | python -m discoart create&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;So how can I have my own &lt;code&gt;my.yml&lt;/code&gt; and what does it look like? That&#39;s the second command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m discoart config my.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;which forks the &lt;a href=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/discoart/resources/default.yml&#34;&gt;default YAML config&lt;/a&gt; and export them to &lt;code&gt;my.yml&lt;/code&gt;. Now you can modify it and run it with &lt;code&gt;python -m discoart create&lt;/code&gt; command.&lt;/p&gt; &#xA;&lt;p&gt;If no output path is specified, then &lt;code&gt;python -m discoart config&lt;/code&gt; will print the default config to stdout.&lt;/p&gt; &#xA;&lt;p&gt;To get help on a command, add &lt;code&gt;--help&lt;/code&gt; at the end, e.g.:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m discoart create --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;usage: python -m discoart create [-h] [YAML_CONFIG_FILE]&#xA;&#xA;positional arguments:&#xA;  YAML_CONFIG_FILE  The YAML config file to use, default is stdin.&#xA;&#xA;optional arguments:&#xA;  -h, --help        show this help message and exit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Serving&lt;/h2&gt; &#xA;&lt;p&gt;Serving DiscoArt is super easy. Simply run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m discoart serve&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You shall see:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/.github/serving.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Now send request to the server via curl/Javascript, e.g.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl \&#xA;-X POST http://0.0.0.0:51001/post \&#xA;-H &#39;Content-Type: application/json&#39; \&#xA;-d &#39;{&#34;execEndpoint&#34;:&#34;/create&#34;, &#34;parameters&#34;: {&#34;text_prompts&#34;: [&#34;A beautiful painting of a singular lighthouse&#34;, &#34;yellow color scheme&#34;]}}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That&#39;s it.&lt;/p&gt; &#xA;&lt;p&gt;You can of course pass all parameters that accepted by &lt;code&gt;create()&lt;/code&gt; function in the JSON.&lt;/p&gt; &#xA;&lt;h3&gt;Polling intermediate results&lt;/h3&gt; &#xA;&lt;p&gt;We already know that &lt;code&gt;create&lt;/code&gt; function is slow even on GPU it could take 10 minutes to finish an artwork. This means the after sending the above request, the client will have to wait 10 minutes for the response. There is nothing wrong with this behavior given that everything runs synchronously. However, in practice, client may expect a progress or intermediate results in the middle instead of waiting for the end.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;/result&lt;/code&gt; endpoint is designed for this purpose. It will return the intermediate results as soon as they are available. All you need is to specify &lt;code&gt;name_docarray&lt;/code&gt; in the request parameters as you specified in &lt;code&gt;/create&lt;/code&gt; endpoint. Here is an example:&lt;/p&gt; &#xA;&lt;p&gt;Let&#39;s create &lt;code&gt;mydisco-123&lt;/code&gt; by sending the following request to &lt;code&gt;/create&lt;/code&gt; endpoint:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl \&#xA;-X POST http://0.0.0.0:51001/post \&#xA;-H &#39;Content-Type: application/json&#39; \&#xA;-d &#39;{&#34;execEndpoint&#34;:&#34;/create&#34;, &#34;parameters&#34;: {&#34;name_docarray&#34;: &#34;mydisco-123&#34;, &#34;text_prompts&#34;: [&#34;A beautiful painting of a singular lighthouse&#34;, &#34;yellow color scheme&#34;]}}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now that the above request is being processed on the server, you can periodically check &lt;code&gt;mydisco-123&lt;/code&gt; progress by sending the following request to &lt;code&gt;/result&lt;/code&gt; endpoint:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl \&#xA;-X POST http://0.0.0.0:51001/post \&#xA;-H &#39;Content-Type: application/json&#39; \&#xA;-d &#39;{&#34;execEndpoint&#34;:&#34;/result&#34;, &#34;parameters&#34;: {&#34;name_docarray&#34;: &#34;mydisco-123&#34;}}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A JSON will be returned with up-to-date progress, with image as DataURI, loss, steps etc. &lt;a href=&#34;https://docarray.jina.ai/fundamentals/fastapi-support/#json-schema&#34;&gt;The JSON Schema of Document/DocumentArray is described here.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Note, &lt;code&gt;/result&lt;/code&gt; won&#39;t be blocked by &lt;code&gt;/create&lt;/code&gt; thanks to the smart routing of Jina Gateway. To learn/play more about those endpoints, you can check ReDoc or the Swagger UI embedded in the server.&lt;/p&gt; &#xA;&lt;h3&gt;Skip &amp;amp; Cancel&lt;/h3&gt; &#xA;&lt;p&gt;Send to &lt;code&gt;/skip&lt;/code&gt;, to skip the current run and move to the next run as defined in &lt;code&gt;n_batches&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl \&#xA;-X POST http://0.0.0.0:51001/post \&#xA;-H &#39;Content-Type: application/json&#39; \&#xA;-d &#39;{&#34;execEndpoint&#34;:&#34;/skip&#34;}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Send to &lt;code&gt;/stop&lt;/code&gt;, to stop the current run cancel all runs &lt;code&gt;n_batches&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl \&#xA;-X POST http://0.0.0.0:51001/post \&#xA;-H &#39;Content-Type: application/json&#39; \&#xA;-d &#39;{&#34;execEndpoint&#34;:&#34;/stop&#34;}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Unblocking &lt;code&gt;/create&lt;/code&gt; request&lt;/h3&gt; &#xA;&lt;p&gt;It is possible to have an unblocked &lt;code&gt;/create&lt;/code&gt; endpoint: the client request to &lt;code&gt;/create&lt;/code&gt; will be &lt;strong&gt;immediately&lt;/strong&gt; returned, without waiting for the results to be finished. You now have to fully rely on &lt;code&gt;/result&lt;/code&gt; to poll the result.&lt;/p&gt; &#xA;&lt;p&gt;To enable this feature:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Copy-paste the &lt;a href=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/discoart/resources/flow.yml&#34;&gt;default &lt;code&gt;flow.yml&lt;/code&gt; file&lt;/a&gt; to &lt;code&gt;myflow.yml&lt;/code&gt;;&lt;/li&gt; &#xA; &lt;li&gt;Change &lt;code&gt;floating: false&lt;/code&gt; to &lt;code&gt;floating: true&lt;/code&gt; under &lt;code&gt;discoart&lt;/code&gt; executor section;&lt;/li&gt; &#xA; &lt;li&gt;Run the following command: &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m discoart serve myflow.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Beware that the request velocity is now under &lt;strong&gt;your control&lt;/strong&gt;. That is, if the client sends 10 &lt;code&gt;/create&lt;/code&gt; requests in a second, then the server will start 10 &lt;code&gt;create()&lt;/code&gt; in parallel! This can easily lead to OOM. Hence, the suggestion is only enabling this feature if you are sure that the client is not sending too many requests, e.g. you control the client request rate; or you are using DiscoArt behind a BFF (backend for frontend).&lt;/p&gt; &#xA;&lt;h3&gt;Scaling out&lt;/h3&gt; &#xA;&lt;p&gt;If you have multiple GPUs and you want to run multiple DiscoArt instances in parallel by leveraging GPUs in a time-multiplexed fashion, you can copy-paste the &lt;a href=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/discoart/resources/flow.yml&#34;&gt;default &lt;code&gt;flow.yml&lt;/code&gt; file&lt;/a&gt; and modify it as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;jtype: Flow&#xA;with:&#xA;  protocol: http&#xA;  monitoring: true&#xA;  port: 51001&#xA;  port_monitoring: 51002  # prometheus monitoring port&#xA;  env:&#xA;    JINA_LOG_LEVEL: debug&#xA;    DISCOART_DISABLE_IPYTHON: 1&#xA;    DISCOART_DISABLE_RESULT_SUMMARY: 1&#xA;executors:&#xA;  - name: discoart&#xA;    uses: DiscoArtExecutor&#xA;    env:&#xA;      CUDA_VISIBLE_DEVICES: RR0:3  # change this if you have multiple GPU&#xA;    replicas: 3  # change this if you have larger VRAM&#xA;  - name: poller&#xA;    uses: ResultPoller&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here &lt;code&gt;replicas: 3&lt;/code&gt; says spawning three DiscoArt instances, &lt;code&gt;CUDA_VISIBLE_DEVICES: RR0:3&lt;/code&gt; makes sure they use the first three GPUs in a round-robin fashion.&lt;/p&gt; &#xA;&lt;p&gt;Name it as &lt;code&gt;myflow.yml&lt;/code&gt; and then run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m discoart serve myflow.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Customization&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/jina-ai/jina&#34;&gt;Thanks to Jina&lt;/a&gt;, there are tons of things you can customize! You can change the port number; change protocol to gRPC/Websockets; add TLS encryption; enable/disable Prometheus monitoring; you can also export it to Kubernetes deployment bundle simply via:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;jina export kubernetes myflow.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more features and YAML configs, &lt;a href=&#34;https://docs.jina.ai&#34;&gt;please check out Jina docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Use gRPC gateway&lt;/h3&gt; &#xA;&lt;p&gt;To switch from HTTP to gRPC gateway is simple:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;jtype: Flow&#xA;with:&#xA;  protocol: grpc&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and then restart the server.&lt;/p&gt; &#xA;&lt;p&gt;There are multiple advantages of using gRPC gateway:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Much faster and smaller network overhead.&lt;/li&gt; &#xA; &lt;li&gt;Feature-rich, like compression, status monitoring, etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In general, if you are using the DiscoArt server behind a BFF (backend for frontend), or your DiscoArt server does &lt;strong&gt;not&lt;/strong&gt; directly serve HTTP traffic from end-users, then you should use gRPC protocol.&lt;/p&gt; &#xA;&lt;p&gt;To communicate with a gRPC DiscoArt server, one can use a Jina Client:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# !pip install jina&#xA;from jina import Client&#xA;&#xA;c = Client(host=&#39;grpc://0.0.0.0:51001&#39;)&#xA;&#xA;da = c.post(&#xA;    &#39;/create&#39;,&#xA;    parameters={&#xA;        &#39;name_docarray&#39;: &#39;mydisco-123&#39;,&#xA;        &#39;text_prompts&#39;: [&#xA;            &#39;A beautiful painting of a singular lighthouse&#39;,&#xA;            &#39;yellow color scheme&#39;,&#xA;        ],&#xA;    },&#xA;)&#xA;&#xA;# check intermediate results&#xA;da = c.post(&#39;/result&#39;, parameters={&#39;name_docarray&#39;: &#39;mydisco-123&#39;})&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To use an existing Document/DocumentArray as init Document for &lt;code&gt;create&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from jina import Client&#xA;&#xA;c = Client(host=&#39;grpc://0.0.0.0:51001&#39;)&#xA;&#xA;old_da = create(...)&#xA;&#xA;da = c.post(&#xA;    &#39;/create&#39;,&#xA;    old_da,  # this can be a DocumentArray or a single Document&#xA;    parameters={&#xA;        &#39;width_height&#39;: [1024, 768],&#xA;    },&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This equals to run &lt;code&gt;create(init_document=old_da, width_height=[1024, 768])&lt;/code&gt; on the server. Note:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;follow-up parameters have higher priorities than the parameters in &lt;code&gt;init_document&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;if &lt;code&gt;init_document&lt;/code&gt; is a DocumentArray, then the first Document in the array will be used as the init Document.&lt;/li&gt; &#xA; &lt;li&gt;there is no need to do any serialization before sending, Jina automatically handles it.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Hosting on Google Colab&lt;/h3&gt; &#xA;&lt;p&gt;Though not recommended, it is also possible to use Google Colab to host DiscoArt server. Please check out the following tutorials:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.jina.ai/how-to/google-colab/&#34;&gt;https://docs.jina.ai/how-to/google-colab/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://clip-as-service.jina.ai/hosting/colab/&#34;&gt;https://clip-as-service.jina.ai/hosting/colab/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Run in Docker&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/repository/docker/jinaai/discoart&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/image-size/jinaai/discoart/latest?logo=docker&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;Docker Image Size (tag)&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;We provide a prebuilt Docker image for running DiscoArt out of the box. To update Docker image to latest version:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker pull jinaai/discoart:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Use Jupyter notebook&lt;/h3&gt; &#xA;&lt;p&gt;The default entrypoint is starting a Jupyter notebook&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# docker build . -t jinaai/discoart  # if you want to build yourself&#xA;docker run -p 51000:8888 -v $(pwd):/home/jovyan/ -v $HOME/.cache:/root/.cache --gpus all jinaai/discoart&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now you can visit &lt;code&gt;http://127.0.0.1:51000&lt;/code&gt; to access the notebook&lt;/p&gt; &#xA;&lt;h3&gt;Use as a service&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# docker build . -t jinaai/discoart  # if you want to build yourself&#xA;docker run --entrypoint &#34;python&#34; -p 51001:51001 -v $(pwd):/home/jovyan/ -v $HOME/.cache:/root/.cache --gpus all jinaai/discoart -m discoart serve&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Your DiscoArt server is now running at &lt;code&gt;http://127.0.0.1:51001&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Release cycle&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/repository/docker/jinaai/discoart&#34;&gt;Docker images are built on every release&lt;/a&gt;, so one can lock it to a specific version, say &lt;code&gt;0.5.1&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -p 51000:8888 -v $(pwd):/home/jovyan/ -v $HOME/.cache:/root/.cache --gpus all jinaai/discoart:0.5.1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;What&#39;s next?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/jina-ai/discoart/blob/main/discoart.ipynb&#34;&gt;Next is create&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;üòé &lt;strong&gt;If you are already a DD user&lt;/strong&gt;: you are ready to go! There is no extra learning, DiscoArt respects the same parameter semantics as DD5.6. So just unleash your creativity! &lt;a href=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/FEATURES.md&#34;&gt;Read more about their differences here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can always do &lt;code&gt;from discoart import cheatsheet; cheatsheet()&lt;/code&gt; to check all new/modified parameters.&lt;/p&gt; &#xA;&lt;p&gt;üë∂ &lt;strong&gt;If you are a &lt;a href=&#34;https://github.com/jina-ai/dalle-flow/&#34;&gt;DALL¬∑E Flow&lt;/a&gt; or new user&lt;/strong&gt;: you may want to take step by step, as Disco Diffusion works in a very different way than DALL¬∑E. It is much more advanced and powerful: e.g. Disco Diffusion can take weighted &amp;amp; structured text prompts; it can initialize from a image with controlled noise; and there are way more parameters one can tweak. Impatient prompt like &lt;code&gt;&#34;armchair avocado&#34;&lt;/code&gt; will give you nothing but confusion and frustration. I highly recommend you to check out the following resources before trying your own prompt:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/document/d/1l8s7uS2dGqjztYSjPpzlmXLjl5PM3IGkRWI3IiCuK7g/mobilebasic&#34;&gt;Zippy&#39;s Disco Diffusion Cheatsheet v0.3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/document/d/1ORymHm0Te18qKiHnhcdgGp-WSt8ZkLZvow3raiu2DVU/edit#&#34;&gt;EZ Charts - Diffusion Parameter Studies&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://weirdwonderfulai.art/resources/disco-diffusion-70-plus-artist-studies/&#34;&gt;Disco Diffusion 70+ Artist Studies&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sweet-hall-e72.notion.site/A-Traveler-s-Guide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f#e122e748b86e4fc0ad6a7a50e46d6e10&#34;&gt;A Traveler‚Äôs Guide to the Latent Space&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://coar.notion.site/Disco-Diffusion-Illustrated-Settings-cd4badf06e08440c99d8a93d4cd39f51&#34;&gt;Disco Diffusion Illustrated Settings&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://coar.notion.site/coar/Coar-s-Disco-Diffusion-Guide-3d86d652c15d4ca986325e808bde06aa#8a3c6e9e4b6847afa56106eacb6f1f79&#34;&gt;Coar‚Äôs Disco Diffusion Guide&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- start support-pitch --&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Join our &lt;a href=&#34;https://slack.jina.ai&#34;&gt;Slack community&lt;/a&gt; and chat with other community members about ideas.&lt;/li&gt; &#xA; &lt;li&gt;Join our &lt;a href=&#34;https://youtube.com/playlist?list=PL3UBBWOUVhFYRUa_gpYYKBqEAkO4sxmne&#34;&gt;Engineering All Hands&lt;/a&gt; meet-up to discuss your use case and learn Jina&#39;s new features. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;When?&lt;/strong&gt; The second Tuesday of every month&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Where?&lt;/strong&gt; Zoom (&lt;a href=&#34;https://calendar.google.com/calendar/embed?src=c_1t5ogfp2d45v8fit981j08mcm4%40group.calendar.google.com&amp;amp;ctz=Europe%2FBerlin&#34;&gt;see our public events calendar&lt;/a&gt;/&lt;a href=&#34;https://calendar.google.com/calendar/ical/c_1t5ogfp2d45v8fit981j08mcm4%40group.calendar.google.com/public/basic.ics&#34;&gt;.ical&lt;/a&gt;) and &lt;a href=&#34;https://youtube.com/c/jina-ai&#34;&gt;live stream on YouTube&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Subscribe to the latest video tutorials on our &lt;a href=&#34;https://youtube.com/c/jina-ai&#34;&gt;YouTube channel&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Join Us&lt;/h2&gt; &#xA;&lt;p&gt;DiscoArt is backed by &lt;a href=&#34;https://jina.ai&#34;&gt;Jina AI&lt;/a&gt; and licensed under &lt;a href=&#34;https://raw.githubusercontent.com/jina-ai/discoart/main/LICENSE&#34;&gt;MIT License&lt;/a&gt;. &lt;a href=&#34;https://jobs.jina.ai&#34;&gt;We are actively hiring&lt;/a&gt; AI engineers, solution engineers to build the next neural search ecosystem in open-source.&lt;/p&gt; &#xA;&lt;!-- end support-pitch --&gt;</summary>
  </entry>
</feed>