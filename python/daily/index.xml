<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-10-21T01:36:12Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>JingShing/NovelAI-4chan-lowvram-ver</title>
    <updated>2022-10-21T01:36:12Z</updated>
    <id>tag:github.com,2022-10-21:/JingShing/NovelAI-4chan-lowvram-ver</id>
    <link href="https://github.com/JingShing/NovelAI-4chan-lowvram-ver" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A low vram ver for installing novelai 4chan leaked ver.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/JingShing/NovelAI-4chan-lowvram-ver/main/README_TCH.md&#34;&gt;ç¹é«”ä¸­æ–‡&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Warning&lt;/h1&gt; &#xA;&lt;p&gt;This still need 6g or more vram to run. If your gpu isn&#39;t powerful enough you may use the &lt;a href=&#34;https://github.com/JingShing/novelai-colab-ver/tree/main/4chan_ver&#34;&gt;colab ver&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;NovelAI-4chan-lowvram-ver&lt;/h1&gt; &#xA;&lt;p&gt;A low vram ver for installing novelai 4chan leaked ver.&lt;/p&gt; &#xA;&lt;h2&gt;How you get the low vram ver AI&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://drive.google.com/file/d/1ydm2JRJf8w9G0_KBWLJNQ7Yj3KCIN1XL/view?usp=sharing&#34;&gt;google cloud&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mega.nz/file/OBMF0D6Q#HGmNIB8ZmRJVZ2mWJ5aN2cm4iatdxV7Oqej0GfOHI-o&#34;&gt;Mega&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;It has all module you need and it can run faster and need less vram than original 4chan ver. You can use 1660 or 3060 to run this AI. It only takes 6g vram to run.&lt;/p&gt; &#xA;&lt;h2&gt;Original efficiency&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JingShing/NovelAI-4chan-lowvram-ver/main/low-vram-pic/or.png&#34; alt=&#34;or&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Low vram version efficiency&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JingShing/NovelAI-4chan-lowvram-ver/main/low-vram-pic/new.png&#34; alt=&#34;new&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>PaddlePaddle/PaddleSpeech</title>
    <updated>2022-10-21T01:36:12Z</updated>
    <id>tag:github.com,2022-10-21:/PaddlePaddle/PaddleSpeech</id>
    <link href="https://github.com/PaddlePaddle/PaddleSpeech" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Easy-to-use Speech Toolkit including SOTA/Streaming ASR with punctuation, influential TTS with text frontend, Speaker Verification System, End-to-End Speech Translation and Keyword Spotting. Won NAACL2022 Best Demo Award.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/README_cn.md&#34;&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt;|English)&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/images/PaddleSpeech_logo.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-red.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/PaddlePaddle/PaddleSpeech?color=ffa&#34;&gt;&lt;/a&gt; &lt;a href=&#34;support os&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.7+-aff.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/PaddlePaddle/PaddleSpeech?color=9ea&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/commits&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/commit-activity/m/PaddlePaddle/PaddleSpeech?color=3af&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/PaddlePaddle/PaddleSpeech?color=9cc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/PaddlePaddle/PaddleSpeech?color=ccf&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/=https://pypi.org/project/paddlespeech/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/PaddleSpeech&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/=https://pypi.org/project/paddlespeech/&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/badge/paddlespeech&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h4&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#quick-start&#34;&gt; Quick Start &lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#documents&#34;&gt; Documents &lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#model-list&#34;&gt; Models List &lt;/a&gt; | &lt;a href=&#34;https://aistudio.baidu.com/aistudio/course/introduce/25130&#34;&gt; AIStudio Courses &lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/abs/2205.12007&#34;&gt; NAACL2022 Best Demo Award Paper &lt;/a&gt; | &lt;a href=&#34;https://gitee.com/paddlepaddle/PaddleSpeech&#34;&gt; Gitee &lt;/a&gt; &lt;/h4&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;PaddleSpeech&lt;/strong&gt; is an open-source toolkit on &lt;a href=&#34;https://github.com/PaddlePaddle/Paddle&#34;&gt;PaddlePaddle&lt;/a&gt; platform for a variety of critical tasks in speech and audio, with the state-of-art and influential models.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PaddleSpeech&lt;/strong&gt; won the &lt;a href=&#34;https://2022.naacl.org/blog/best-demo-award/&#34;&gt;NAACL2022 Best Demo Award&lt;/a&gt;, please check out our paper on &lt;a href=&#34;https://arxiv.org/abs/2205.12007&#34;&gt;Arxiv&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h5&gt;Speech Recognition&lt;/h5&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table style=&#34;width:100%&#34;&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt; Input Audio &lt;/th&gt; &#xA;    &lt;th width=&#34;550&#34;&gt; Recognition Result &lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://paddlespeech.bj.bcebos.com/PaddleAudio/en.wav&#34; rel=&#34;nofollow&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/images/audio_icon.png&#34; width=&#34;200 style=&#34; max-width: 100%;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;/td&gt; &#xA;    &lt;td&gt;I knocked at the door on the ancient side of the building.&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://paddlespeech.bj.bcebos.com/PaddleAudio/zh.wav&#34; rel=&#34;nofollow&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/images/audio_icon.png&#34; width=&#34;200&#34; style=&#34;max-width: 100%;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;/td&gt; &#xA;    &lt;td&gt;æˆ‘è®¤ä¸ºè·‘æ­¥æœ€é‡è¦çš„å°±æ˜¯ç»™æˆ‘å¸¦æ¥äº†èº«ä½“å¥åº·ã€‚&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;h5&gt;Speech Translation (English to Chinese)&lt;/h5&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table style=&#34;width:100%&#34;&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt; Input Audio &lt;/th&gt; &#xA;    &lt;th width=&#34;550&#34;&gt; Translations Result &lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://paddlespeech.bj.bcebos.com/PaddleAudio/en.wav&#34; rel=&#34;nofollow&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/images/audio_icon.png&#34; width=&#34;200 style=&#34; max-width: 100%;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;/td&gt; &#xA;    &lt;td&gt;æˆ‘ åœ¨ è¿™æ ‹ å»ºç­‘ çš„ å¤è€ é—¨ä¸Š æ•²é—¨ã€‚&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;h5&gt;Text-to-Speech&lt;/h5&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table style=&#34;width:100%&#34;&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th width=&#34;550&#34;&gt; Input Text&lt;/th&gt; &#xA;    &lt;th&gt;Synthetic Audio&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Life was like a box of chocolates, you never know what you&#39;re gonna get.&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/tacotron2_ljspeech_waveflow_samples_0.2/sentence_1.wav&#34; rel=&#34;nofollow&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/images/audio_icon.png&#34; width=&#34;200&#34; style=&#34;max-width: 100%;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;æ—©ä¸Šå¥½ï¼Œä»Šå¤©æ˜¯2020/10/29ï¼Œæœ€ä½æ¸©åº¦æ˜¯-3Â°Cã€‚&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/parakeet_espnet_fs2_pwg_demo/tn_g2p/parakeet/001.wav&#34; rel=&#34;nofollow&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/images/audio_icon.png&#34; width=&#34;200&#34; style=&#34;max-width: 100%;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;å­£å§¬å¯‚ï¼Œé›†é¸¡ï¼Œé¸¡å³æ£˜é¸¡ã€‚æ£˜é¸¡é¥¥å½ï¼Œå­£å§¬åŠç®•ç¨·æµé¸¡ã€‚é¸¡æ—¢æµï¼Œè·»å§¬ç¬ˆï¼Œå­£å§¬å¿Œï¼Œæ€¥å’­é¸¡ï¼Œé¸¡æ€¥ï¼Œç»§åœ¾å‡ ï¼Œå­£å§¬æ€¥ï¼Œå³ç±ç®•å‡»é¸¡ï¼Œç®•ç–¾å‡»å‡ ä¼ï¼Œä¼å³é½‘ï¼Œé¸¡å½é›†å‡ åŸºï¼Œå­£å§¬æ€¥æå±å‡»é¸¡ï¼Œé¸¡æ—¢æ®›ï¼Œå­£å§¬æ¿€ï¼Œå³è®°ã€Šå­£å§¬å‡»é¸¡è®°ã€‹ã€‚&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/jijiji.wav&#34; rel=&#34;nofollow&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/images/audio_icon.png&#34; width=&#34;200&#34; style=&#34;max-width: 100%;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;For more synthesized audios, please refer to &lt;a href=&#34;https://paddlespeech.readthedocs.io/en/latest/tts/demo.html&#34;&gt;PaddleSpeech Text-to-Speech samples&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h5&gt;Punctuation Restoration&lt;/h5&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table style=&#34;width:100%&#34;&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th width=&#34;390&#34;&gt; Input Text &lt;/th&gt; &#xA;    &lt;th width=&#34;390&#34;&gt; Output Text &lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;ä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šä½ ä¸‹åˆæœ‰ç©ºå—æˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­&lt;/td&gt; &#xA;    &lt;td&gt;ä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šï¼ä½ ä¸‹åˆæœ‰ç©ºå—ï¼Ÿæˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­ã€‚&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;Features&lt;/h3&gt; &#xA;&lt;p&gt;Via the easy-to-use, efficient, flexible and scalable implementation, our vision is to empower both industrial application and academic research, including training, inference &amp;amp; testing modules, and deployment process. To be more specific, this toolkit features at:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸ“¦ &lt;strong&gt;Ease of Use&lt;/strong&gt;: low barriers to install, &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#quick-start&#34;&gt;CLI&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#quick-start-server&#34;&gt;Server&lt;/a&gt;, and &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#quick-start-streaming-server&#34;&gt;Streaming Server&lt;/a&gt; is available to quick-start your journey.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ† &lt;strong&gt;Align to the State-of-the-Art&lt;/strong&gt;: we provide high-speed and ultra-lightweight models, and also cutting-edge technology.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ† &lt;strong&gt;Streaming ASR and TTS System&lt;/strong&gt;: we provide production ready streaming asr and streaming tts system.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ’¯ &lt;strong&gt;Rule-based Chinese frontend&lt;/strong&gt;: our frontend contains Text Normalization and Grapheme-to-Phoneme (G2P, including Polyphone and Tone Sandhi). Moreover, we use self-defined linguistic rules to adapt Chinese context.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ“¦ &lt;strong&gt;Varieties of Functions that Vitalize both Industrial and Academia&lt;/strong&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ğŸ›ï¸ &lt;em&gt;Implementation of critical audio tasks&lt;/em&gt;: this toolkit contains audio functions like Automatic Speech Recognition, Text-to-Speech Synthesis, Speaker Verfication, KeyWord Spotting, Audio Classification, and Speech Translation, etc.&lt;/li&gt; &#xA;   &lt;li&gt;ğŸ”¬ &lt;em&gt;Integration of mainstream models and datasets&lt;/em&gt;: the toolkit implements modules that participate in the whole pipeline of the speech tasks, and uses mainstream datasets like LibriSpeech, LJSpeech, AIShell, CSMSC, etc. See also &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#model-list&#34;&gt;model list&lt;/a&gt; for more details.&lt;/li&gt; &#xA;   &lt;li&gt;ğŸ§© &lt;em&gt;Cascaded models application&lt;/em&gt;: as an extension of the typical traditional audio tasks, we combine the workflows of the aforementioned tasks with other fields like Natural language processing (NLP) and Computer Vision (CV).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Recent Update&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸ‘‘ 2022.10.11: Add &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/librispeech/asr3&#34;&gt;Wav2vec2ASR&lt;/a&gt;, wav2vec2.0 fine-tuning for ASR on LibriSpeech.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ 2022.09.26: Add Voice Cloning, TTS finetune, and ERNIE-SAT in &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/speech_web&#34;&gt;PaddleSpeech Web Demo&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;âš¡ 2022.09.09: Add AISHELL-3 Voice Cloning &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/vc2&#34;&gt;example&lt;/a&gt; with ECAPA-TDNN speaker encoder.&lt;/li&gt; &#xA; &lt;li&gt;âš¡ 2022.08.25: Release TTS &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/other/tts_finetune/tts3&#34;&gt;finetune&lt;/a&gt; example.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ 2022.08.22: Add ERNIE-SAT models: &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/vctk/ernie_sat&#34;&gt;ERNIE-SAT-vctk&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/ernie_sat&#34;&gt;ERNIE-SAT-aishell3&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3_vctk/ernie_sat&#34;&gt;ERNIE-SAT-zh_en&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ 2022.08.15: Add &lt;a href=&#34;https://github.com/GitYCC/g2pW&#34;&gt;g2pW&lt;/a&gt; into TTS Chinese Text Frontend.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ 2022.08.09: Release &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/zh_en_tts/tts3&#34;&gt;Chinese English mixed TTS&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;âš¡ 2022.08.03: Add ONNXRuntime infer for TTS CLI.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ‰ 2022.07.18: Release VITS: &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/vits&#34;&gt;VITS-csmsc&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/vits&#34;&gt;VITS-aishell3&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/vits-vc&#34;&gt;VITS-VC&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ‰ 2022.06.22: All TTS models support ONNX format.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ€ 2022.06.17: Add &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/speech_web&#34;&gt;PaddleSpeech Web Demo&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ‘‘ 2022.05.13: Release &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/asr/PPASR.md&#34;&gt;PP-ASR&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/tts/PPTTS.md&#34;&gt;PP-TTS&lt;/a&gt;ã€&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/vpr/PPVPR.md&#34;&gt;PP-VPR&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ‘ğŸ» 2022.05.06: &lt;code&gt;PaddleSpeech Streaming Server&lt;/code&gt; is available for &lt;code&gt;Streaming ASR&lt;/code&gt; with &lt;code&gt;Punctuation Restoration&lt;/code&gt; and &lt;code&gt;Token Timestamp&lt;/code&gt; and &lt;code&gt;Text-to-Speech&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ‘ğŸ» 2022.05.06: &lt;code&gt;PaddleSpeech Server&lt;/code&gt; is available for &lt;code&gt;Audio Classification&lt;/code&gt;, &lt;code&gt;Automatic Speech Recognition&lt;/code&gt; and &lt;code&gt;Text-to-Speech&lt;/code&gt;, &lt;code&gt;Speaker Verification&lt;/code&gt; and &lt;code&gt;Punctuation Restoration&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ‘ğŸ» 2022.03.28: &lt;code&gt;PaddleSpeech CLI&lt;/code&gt; is available for &lt;code&gt;Speaker Verification&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;ğŸ¤— 2021.12.14: &lt;a href=&#34;https://huggingface.co/spaces/KPatrick/PaddleSpeechASR&#34;&gt;ASR&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/spaces/KPatrick/PaddleSpeechTTS&#34;&gt;TTS&lt;/a&gt; Demos on Hugging Face Spaces are available!&lt;/li&gt; &#xA; &lt;li&gt;ğŸ‘ğŸ» 2021.12.10: &lt;code&gt;PaddleSpeech CLI&lt;/code&gt; is available for &lt;code&gt;Audio Classification&lt;/code&gt;, &lt;code&gt;Automatic Speech Recognition&lt;/code&gt;, &lt;code&gt;Speech Translation (English to Chinese)&lt;/code&gt; and &lt;code&gt;Text-to-Speech&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Community&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Scan the QR code below with your Wechat, you can access to official technical exchange group and get the bonus ( more than 20GB learning materials, such as papers, codes and videos ) and the live link of the lessons. Look forward to your participation.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/30135920/196351517-19dece6b-d6ea-448e-a341-d6bfe5712ec1.jpg&#34; width=&#34;200&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;We strongly recommend our users to install PaddleSpeech in &lt;strong&gt;Linux&lt;/strong&gt; with &lt;em&gt;python&amp;gt;=3.7&lt;/em&gt; and &lt;em&gt;paddlepaddle&amp;gt;=2.4rc&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Dependency Introduction&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;gcc &amp;gt;= 4.8.5&lt;/li&gt; &#xA; &lt;li&gt;paddlepaddle &amp;gt;= 2.4rc&lt;/li&gt; &#xA; &lt;li&gt;python &amp;gt;= 3.7&lt;/li&gt; &#xA; &lt;li&gt;OS support: Linux(recommend), Windows, Mac OSX&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;PaddleSpeech depends on paddlepaddle. For installation, please refer to the official website of &lt;a href=&#34;https://www.paddlepaddle.org.cn/en&#34;&gt;paddlepaddle&lt;/a&gt; and choose according to your own machine. Here is an example of the cpu version.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install paddlepaddle -i https://mirror.baidu.com/pypi/simple&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also specify the version of paddlepaddle or install the develop version.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# install 2.3.1 version. Note, 2.3.1 is just an example, please follow the minimum dependency of paddlepaddle for your selection&#xA;pip install paddlepaddle==2.3.1 -i https://mirror.baidu.com/pypi/simple&#xA;# install develop version&#xA;pip install paddlepaddle==0.0.0 -f https://www.paddlepaddle.org.cn/whl/linux/cpu-mkl/develop.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There are two quick installation methods for PaddleSpeech, one is pip installation, and the other is source code compilation (recommended).&lt;/p&gt; &#xA;&lt;h3&gt;pip install&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install pytest-runner&#xA;pip install paddlespeech&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;source code compilation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/PaddlePaddle/PaddleSpeech.git&#xA;cd PaddleSpeech&#xA;pip install pytest-runner&#xA;pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more installation problems, such as conda environment, librosa-dependent, gcc problems, kaldi installation, etc., you can refer to this &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/install.md&#34;&gt;installation document&lt;/a&gt;. If you encounter problems during installation, you can leave a message on &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/issues/2150&#34;&gt;#2150&lt;/a&gt; and find related problems&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;quickstart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;Developers can have a try of our models with &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/paddlespeech/cli/README.md&#34;&gt;PaddleSpeech Command Line&lt;/a&gt; or Python. Change &lt;code&gt;--input&lt;/code&gt; to test your own audio/text and support 16k wav format audio.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;You can also quickly experience it in AI Studio ğŸ‘‰ğŸ» &lt;a href=&#34;https://aistudio.baidu.com/aistudio/projectdetail/4353348?sUid=2470186&amp;amp;shared=1&amp;amp;ts=1660876445786&#34;&gt;PaddleSpeech API Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Test audio sample download&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;wget -c https://paddlespeech.bj.bcebos.com/PaddleAudio/zh.wav&#xA;wget -c https://paddlespeech.bj.bcebos.com/PaddleAudio/en.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Automatic Speech Recognition&lt;/h3&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;â€ƒï¼ˆClick to expandï¼‰Open Source Speech Recognition&lt;/summary&gt; &#xA; &lt;p&gt;&lt;strong&gt;command line experience&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech asr --lang zh --input zh.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;strong&gt;Python API experience&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from paddlespeech.cli.asr.infer import ASRExecutor&#xA;&amp;gt;&amp;gt;&amp;gt; asr = ASRExecutor()&#xA;&amp;gt;&amp;gt;&amp;gt; result = asr(audio_file=&#34;zh.wav&#34;)&#xA;&amp;gt;&amp;gt;&amp;gt; print(result)&#xA;æˆ‘è®¤ä¸ºè·‘æ­¥æœ€é‡è¦çš„å°±æ˜¯ç»™æˆ‘å¸¦æ¥äº†èº«ä½“å¥åº·&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Text-to-Speech&lt;/h3&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;â€ƒOpen Source Speech Synthesis&lt;/summary&gt; &#xA; &lt;p&gt;Output 24k sample rate wav format audio&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;command line experience&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech tts --input &#34;ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ç™¾åº¦é£æ¡¨æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼&#34; --output output.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;strong&gt;Python API experience&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from paddlespeech.cli.tts.infer import TTSExecutor&#xA;&amp;gt;&amp;gt;&amp;gt; tts = TTSExecutor()&#xA;&amp;gt;&amp;gt;&amp;gt; tts(text=&#34;ä»Šå¤©å¤©æ°”ååˆ†ä¸é”™ã€‚&#34;, output=&#34;output.wav&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;You can experience in &lt;a href=&#34;https://huggingface.co/spaces&#34;&gt;Huggingface Spaces&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/KPatrick/PaddleSpeechTTS&#34;&gt;TTS Demo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Audio Classification&lt;/h3&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;â€ƒAn open-domain sound classification tool&lt;/summary&gt; &#xA; &lt;p&gt;Sound classification model based on 527 categories of AudioSet dataset&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;command line experience&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech cls --input zh.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;strong&gt;Python API experience&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from paddlespeech.cli.cls.infer import CLSExecutor&#xA;&amp;gt;&amp;gt;&amp;gt; cls = CLSExecutor()&#xA;&amp;gt;&amp;gt;&amp;gt; result = cls(audio_file=&#34;zh.wav&#34;)&#xA;&amp;gt;&amp;gt;&amp;gt; print(result)&#xA;Speech 0.9027186632156372&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Voiceprint Extraction&lt;/h3&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;â€ƒIndustrial-grade voiceprint extraction tool&lt;/summary&gt; &#xA; &lt;p&gt;&lt;strong&gt;command line experience&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech vector --task spk --input zh.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;strong&gt;Python API experience&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from paddlespeech.cli.vector import VectorExecutor&#xA;&amp;gt;&amp;gt;&amp;gt; vec = VectorExecutor()&#xA;&amp;gt;&amp;gt;&amp;gt; result = vec(audio_file=&#34;zh.wav&#34;)&#xA;&amp;gt;&amp;gt;&amp;gt; print(result) # 187ç»´å‘é‡&#xA;[ -0.19083306   9.474295   -14.122263    -2.0916545    0.04848729&#xA;   4.9295826    1.4780062    0.3733844   10.695862     3.2697146&#xA;  -4.48199     -0.6617882   -9.170393   -11.1568775   -1.2358263 ...]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Punctuation Restoration&lt;/h3&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;â€ƒQuick recovery of text punctuation, works with ASR models&lt;/summary&gt; &#xA; &lt;p&gt;&lt;strong&gt;command line experience&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech text --task punc --input ä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šä½ ä¸‹åˆæœ‰ç©ºå—æˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;strong&gt;Python API experience&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from paddlespeech.cli.text.infer import TextExecutor&#xA;&amp;gt;&amp;gt;&amp;gt; text_punc = TextExecutor()&#xA;&amp;gt;&amp;gt;&amp;gt; result = text_punc(text=&#34;ä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šä½ ä¸‹åˆæœ‰ç©ºå—æˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­&#34;)&#xA;ä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šï¼ä½ ä¸‹åˆæœ‰ç©ºå—ï¼Ÿæˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­ã€‚&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Speech Translation&lt;/h3&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;â€ƒEnd-to-end English to Chinese Speech Translation Tool&lt;/summary&gt; &#xA; &lt;p&gt;Use pre-compiled kaldi related tools, only support experience in Ubuntu system&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;command line experience&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech st --input en.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;strong&gt;Python API experience&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from paddlespeech.cli.st.infer import STExecutor&#xA;&amp;gt;&amp;gt;&amp;gt; st = STExecutor()&#xA;&amp;gt;&amp;gt;&amp;gt; result = st(audio_file=&#34;en.wav&#34;)&#xA;[&#39;æˆ‘ åœ¨ è¿™æ ‹ å»ºç­‘ çš„ å¤è€ é—¨ä¸Š æ•²é—¨ ã€‚&#39;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;a name=&#34;quickstartserver&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start Server&lt;/h2&gt; &#xA;&lt;p&gt;Developers can have a try of our speech server with &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/paddlespeech/server/README.md&#34;&gt;PaddleSpeech Server Command Line&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;You can try it quickly in AI Studio (recommend): &lt;a href=&#34;https://aistudio.baidu.com/aistudio/projectdetail/4354592?sUid=2470186&amp;amp;shared=1&amp;amp;ts=1660877827034&#34;&gt;SpeechServer&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Start server&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech_server start --config_file ./demos/speech_server/conf/application.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Access Speech Recognition Services&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech_client asr --server_ip 127.0.0.1 --port 8090 --input input_16k.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Access Text to Speech Services&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech_client tts --server_ip 127.0.0.1 --port 8090 --input &#34;æ‚¨å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ç™¾åº¦é£æ¡¨è¯­éŸ³åˆæˆæœåŠ¡ã€‚&#34; --output output.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Access Audio Classification Services&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;paddlespeech_client cls --server_ip 127.0.0.1 --port 8090 --input input.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information about server command lines, please see: &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/speech_server&#34;&gt;speech server demos&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;quickstartstreamingserver&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start Streaming Server&lt;/h2&gt; &#xA;&lt;p&gt;Developers can have a try of &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/streaming_asr_server/README.md&#34;&gt;streaming asr&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/streaming_tts_server/README.md&#34;&gt;streaming tts&lt;/a&gt; server.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Start Streaming Speech Recognition Server&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;paddlespeech_server start --config_file ./demos/streaming_asr_server/conf/application.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Access Streaming Speech Recognition Services&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;paddlespeech_client asr_online --server_ip 127.0.0.1 --port 8090 --input input_16k.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Start Streaming Text to Speech Server&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;paddlespeech_server start --config_file ./demos/streaming_tts_server/conf/tts_online_application.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Access Streaming Text to Speech Services&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;paddlespeech_client tts_online --server_ip 127.0.0.1 --port 8092 --protocol http --input &#34;æ‚¨å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ç™¾åº¦é£æ¡¨è¯­éŸ³åˆæˆæœåŠ¡ã€‚&#34; --output output.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information please see: &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/streaming_asr_server/README.md&#34;&gt;streaming asr&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/streaming_tts_server/README.md&#34;&gt;streaming tts&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;ModelList&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Model List&lt;/h2&gt; &#xA;&lt;p&gt;PaddleSpeech supports a series of most popular models. They are summarized in &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/released_model.md&#34;&gt;released models&lt;/a&gt; and attached with available pretrained models.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;SpeechToText&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Speech-to-Text&lt;/strong&gt; contains &lt;em&gt;Acoustic Model&lt;/em&gt;, &lt;em&gt;Language Model&lt;/em&gt;, and &lt;em&gt;Speech Translation&lt;/em&gt;, with the following details:&lt;/p&gt; &#xA;&lt;table style=&#34;width:100%&#34;&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Speech-to-Text Module Type&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Model Type&lt;/th&gt; &#xA;   &lt;th&gt;Example&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;4&#34;&gt;Speech Recogination&lt;/td&gt; &#xA;   &lt;td rowspan=&#34;2&#34;&gt;Aishell&lt;/td&gt; &#xA;   &lt;td&gt;DeepSpeech2 RNN + Conv based Models&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell/asr0&#34;&gt;deepspeech2-aishell&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Transformer based Attention Models &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell/asr1&#34;&gt;u2.transformer.conformer-aishell&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; Librispeech&lt;/td&gt; &#xA;   &lt;td&gt;Transformer based Attention Models &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/librispeech/asr0&#34;&gt;deepspeech2-librispeech&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/librispeech/asr1&#34;&gt;transformer.conformer.u2-librispeech&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/librispeech/asr2&#34;&gt;transformer.conformer.u2-kaldi-librispeech&lt;/a&gt; &lt;/td&gt;  &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TIMIT&lt;/td&gt; &#xA;   &lt;td&gt;Unified Streaming &amp;amp; Non-streaming Two-pass&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/timit/asr1&#34;&gt; u2-timit&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Alignment&lt;/td&gt; &#xA;   &lt;td&gt;THCHS30&lt;/td&gt; &#xA;   &lt;td&gt;MFA&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/.examples/thchs30/align0&#34;&gt;mfa-thchs30&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;1&#34;&gt;Language Model&lt;/td&gt; &#xA;   &lt;td colspan=&#34;2&#34;&gt;Ngram Language Model&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/other/ngram_lm&#34;&gt;kenlm&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;2&#34;&gt;Speech Translation (English to Chinese)&lt;/td&gt; &#xA;   &lt;td rowspan=&#34;2&#34;&gt;TED En-Zh&lt;/td&gt; &#xA;   &lt;td&gt;Transformer + ASR MTL&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ted_en_zh/st0&#34;&gt;transformer-ted&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FAT + Transformer + ASR MTL&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ted_en_zh/st1&#34;&gt;fat-st-ted&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a name=&#34;TextToSpeech&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Text-to-Speech&lt;/strong&gt; in PaddleSpeech mainly contains three modules: &lt;em&gt;Text Frontend&lt;/em&gt;, &lt;em&gt;Acoustic Model&lt;/em&gt; and &lt;em&gt;Vocoder&lt;/em&gt;. Acoustic Model and Vocoder models are listed as follow:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt; Text-to-Speech Module Type &lt;/th&gt; &#xA;   &lt;th&gt; Model Type &lt;/th&gt; &#xA;   &lt;th&gt; Dataset &lt;/th&gt; &#xA;   &lt;th&gt; Example &lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; Text Frontend &lt;/td&gt; &#xA;   &lt;td colspan=&#34;2&#34;&gt; â€ƒ &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/other/tn&#34;&gt;tn&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/other/g2p&#34;&gt;g2p&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;5&#34;&gt;Acoustic Model&lt;/td&gt; &#xA;   &lt;td&gt;Tacotron2&lt;/td&gt; &#xA;   &lt;td&gt;LJSpeech / CSMSC&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ljspeech/tts0&#34;&gt;tacotron2-ljspeech&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/tts0&#34;&gt;tacotron2-csmsc&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Transformer TTS&lt;/td&gt; &#xA;   &lt;td&gt;LJSpeech&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ljspeech/tts1&#34;&gt;transformer-ljspeech&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SpeedySpeech&lt;/td&gt; &#xA;   &lt;td&gt;CSMSC&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/tts2&#34;&gt;speedyspeech-csmsc&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FastSpeech2&lt;/td&gt; &#xA;   &lt;td&gt;LJSpeech / VCTK / CSMSC / AISHELL-3 / ZH_EN / finetune&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ljspeech/tts3&#34;&gt;fastspeech2-ljspeech&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/vctk/tts3&#34;&gt;fastspeech2-vctk&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/tts3&#34;&gt;fastspeech2-csmsc&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/tts3&#34;&gt;fastspeech2-aishell3&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/zh_en_tts/tts3&#34;&gt;fastspeech2-zh_en&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/other/tts_finetune/tts3&#34;&gt;fastspeech2-finetune&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ERNIE-SAT&lt;/td&gt; &#xA;   &lt;td&gt;VCTK / AISHELL-3 / ZH_EN&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/vctk/ernie_sat&#34;&gt;ERNIE-SAT-vctk&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/ernie_sat&#34;&gt;ERNIE-SAT-aishell3&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3_vctk/ernie_sat&#34;&gt;ERNIE-SAT-zh_en&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;6&#34;&gt;Vocoder&lt;/td&gt; &#xA;   &lt;td&gt;WaveFlow&lt;/td&gt; &#xA;   &lt;td&gt;LJSpeech&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ljspeech/voc0&#34;&gt;waveflow-ljspeech&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Parallel WaveGAN&lt;/td&gt; &#xA;   &lt;td&gt;LJSpeech / VCTK / CSMSC / AISHELL-3&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ljspeech/voc1&#34;&gt;PWGAN-ljspeech&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/vctk/voc1&#34;&gt;PWGAN-vctk&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/voc1&#34;&gt;PWGAN-csmsc&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/voc1&#34;&gt;PWGAN-aishell3&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Multi Band MelGAN&lt;/td&gt; &#xA;   &lt;td&gt;CSMSC&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/voc3&#34;&gt;Multi Band MelGAN-csmsc&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Style MelGAN&lt;/td&gt; &#xA;   &lt;td&gt;CSMSC&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/voc4&#34;&gt;Style MelGAN-csmsc&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HiFiGAN&lt;/td&gt; &#xA;   &lt;td&gt;LJSpeech / VCTK / CSMSC / AISHELL-3&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ljspeech/voc5&#34;&gt;HiFiGAN-ljspeech&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/vctk/voc5&#34;&gt;HiFiGAN-vctk&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/voc5&#34;&gt;HiFiGAN-csmsc&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/voc5&#34;&gt;HiFiGAN-aishell3&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;WaveRNN&lt;/td&gt; &#xA;   &lt;td&gt;CSMSC&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/voc6&#34;&gt;WaveRNN-csmsc&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;5&#34;&gt;Voice Cloning&lt;/td&gt; &#xA;   &lt;td&gt;GE2E&lt;/td&gt; &#xA;   &lt;td&gt;Librispeech, etc.&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/other/ge2e&#34;&gt;GE2E&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SV2TTS (GE2E + Tacotron2)&lt;/td&gt; &#xA;   &lt;td&gt;AISHELL-3&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/vc0&#34;&gt;VC0&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SV2TTS (GE2E + FastSpeech2)&lt;/td&gt; &#xA;   &lt;td&gt;AISHELL-3&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/vc1&#34;&gt;VC1&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SV2TTS (ECAPA-TDNN + FastSpeech2)&lt;/td&gt; &#xA;   &lt;td&gt;AISHELL-3&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/vc2&#34;&gt;VC2&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GE2E + VITS&lt;/td&gt; &#xA;   &lt;td&gt;AISHELL-3&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/vits-vc&#34;&gt;VITS-VC&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;3&#34;&gt;End-to-End&lt;/td&gt; &#xA;   &lt;td&gt;VITS&lt;/td&gt; &#xA;   &lt;td&gt;CSMSC / AISHELL-3&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/csmsc/vits&#34;&gt;VITS-csmsc&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/vits&#34;&gt;VITS-aishell3&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a name=&#34;AudioClassification&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Audio Classification&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table style=&#34;width:100%&#34;&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt; Task &lt;/th&gt; &#xA;   &lt;th&gt; Dataset &lt;/th&gt; &#xA;   &lt;th&gt; Model Type &lt;/th&gt; &#xA;   &lt;th&gt; Example &lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Audio Classification&lt;/td&gt; &#xA;   &lt;td&gt;ESC-50&lt;/td&gt; &#xA;   &lt;td&gt;PANN&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/esc50/cls0&#34;&gt;pann-esc50&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a name=&#34;SpeakerVerification&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Speaker Verification&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table style=&#34;width:100%&#34;&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt; Task &lt;/th&gt; &#xA;   &lt;th&gt; Dataset &lt;/th&gt; &#xA;   &lt;th&gt; Model Type &lt;/th&gt; &#xA;   &lt;th&gt; Example &lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Speaker Verification&lt;/td&gt; &#xA;   &lt;td&gt;VoxCeleb1/2&lt;/td&gt; &#xA;   &lt;td&gt;ECAPA-TDNN&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/voxceleb/sv0&#34;&gt;ecapa-tdnn-voxceleb12&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a name=&#34;SpeakerDiarization&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Speaker Diarization&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table style=&#34;width:100%&#34;&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt; Task &lt;/th&gt; &#xA;   &lt;th&gt; Dataset &lt;/th&gt; &#xA;   &lt;th&gt; Model Type &lt;/th&gt; &#xA;   &lt;th&gt; Example &lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Speaker Diarization&lt;/td&gt; &#xA;   &lt;td&gt;AMI&lt;/td&gt; &#xA;   &lt;td&gt;ECAPA-TDNN + AHC / SC&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/ami/sd0&#34;&gt;ecapa-tdnn-ami&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a name=&#34;PunctuationRestoration&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Punctuation Restoration&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table style=&#34;width:100%&#34;&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt; Task &lt;/th&gt; &#xA;   &lt;th&gt; Dataset &lt;/th&gt; &#xA;   &lt;th&gt; Model Type &lt;/th&gt; &#xA;   &lt;th&gt; Example &lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Punctuation Restoration&lt;/td&gt; &#xA;   &lt;td&gt;IWLST2012_zh&lt;/td&gt; &#xA;   &lt;td&gt;Ernie Linear&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/iwslt2012/punc0&#34;&gt;iwslt2012-punc0&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Documents&lt;/h2&gt; &#xA;&lt;p&gt;Normally, &lt;a href=&#34;https://paperswithcode.com/area/speech&#34;&gt;Speech SoTA&lt;/a&gt;, &lt;a href=&#34;https://paperswithcode.com/area/audio&#34;&gt;Audio SoTA&lt;/a&gt; and &lt;a href=&#34;https://paperswithcode.com/area/music&#34;&gt;Music SoTA&lt;/a&gt; give you an overview of the hot academic topics in the related area. To focus on the tasks in PaddleSpeech, you will find the following guidelines are helpful to grasp the core ideas.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/install.md&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#quickstart&#34;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/README.md&#34;&gt;Some Demos&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Tutorials &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/asr/quick_start.md&#34;&gt;Automatic Speech Recognition&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/asr/models_introduction.md&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/asr/data_preparation.md&#34;&gt;Data Preparation&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/asr/ngram_lm.md&#34;&gt;Ngram LM&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/tts/quick_start.md&#34;&gt;Text-to-Speech&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/tts/models_introduction.md&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/tts/advanced_usage.md&#34;&gt;Advanced Usage&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/tts/zh_text_frontend.md&#34;&gt;Chinese Rule Based Text Frontend&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://paddlespeech.readthedocs.io/en/latest/tts/demo.html&#34;&gt;Test Audio Samples&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Speaker Verification &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/audio_searching/README.md&#34;&gt;Audio Searching&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/speaker_verification/README.md&#34;&gt;Speaker Verification&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/audio_tagging/README.md&#34;&gt;Audio Classification&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/speech_translation/README.md&#34;&gt;Speech Translation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/demos/speech_server/README.md&#34;&gt;Speech Server&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/released_model.md&#34;&gt;Released Models&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#SpeechToText&#34;&gt;Speech-to-Text&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#TextToSpeech&#34;&gt;Text-to-Speech&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#AudioClassification&#34;&gt;Audio Classification&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#SpeakerVerification&#34;&gt;Speaker Verification&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#SpeakerDiarization&#34;&gt;Speaker Diarization&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#PunctuationRestoration&#34;&gt;Punctuation Restoration&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#Community&#34;&gt;Community&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#contribution&#34;&gt;Welcome to contribute&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/#License&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The Text-to-Speech module is originally called &lt;a href=&#34;https://github.com/PaddlePaddle/Parakeet&#34;&gt;Parakeet&lt;/a&gt;, and now merged with this repository. If you are interested in academic research about this task, please see &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/docs/source/tts#overview&#34;&gt;TTS research overview&lt;/a&gt;. Also, &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/raw/develop/docs/source/tts/models_introduction.md&#34;&gt;this document&lt;/a&gt; is a good guideline for the pipeline components.&lt;/p&gt; &#xA;&lt;h2&gt;â­ Examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/JiehangXie/PaddleBoBo&#34;&gt;PaddleBoBo&lt;/a&gt;: Use PaddleSpeech TTS to generate virtual human voice.&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA; &lt;a href=&#34;https://www.bilibili.com/video/BV1cL411V71o?share_source=copy_web&#34;&gt;&lt;img src=&#34;https://ai-studio-static-online.cdn.bcebos.com/06fd746ab32042f398fb6f33f873e6869e846fe63c214596ae37860fe8103720&#34; width=&#34;500px&#34;&gt;&lt;/a&gt;&#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://paddlespeech.readthedocs.io/en/latest/demo_video.html&#34;&gt;PaddleSpeech Demo Video&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/jerryuhoo/VTuberTalk&#34;&gt;VTuberTalk&lt;/a&gt;: Use PaddleSpeech TTS and ASR to clone voice from videos.&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/jerryuhoo/VTuberTalk/main/gui/gui.png&#34; width=&#34;500px&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;To cite PaddleSpeech for research, please use the following format.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-tex&#34;&gt;@inproceedings{zhang2022paddlespeech,&#xA;    title = {PaddleSpeech: An Easy-to-Use All-in-One Speech Toolkit},&#xA;    author = {Hui Zhang, Tian Yuan, Junkun Chen, Xintong Li, Renjie Zheng, Yuxin Huang, Xiaojie Chen, Enlei Gong, Zeyu Chen, Xiaoguang Hu, dianhai yu, Yanjun Ma, Liang Huang},&#xA;    booktitle = {Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations},&#xA;    year = {2022},&#xA;    publisher = {Association for Computational Linguistics},&#xA;}&#xA;&#xA;@inproceedings{zheng2021fused,&#xA;  title={Fused acoustic and text encoding for multimodal bilingual pretraining and speech translation},&#xA;  author={Zheng, Renjie and Chen, Junkun and Ma, Mingbo and Huang, Liang},&#xA;  booktitle={International Conference on Machine Learning},&#xA;  pages={12736--12746},&#xA;  year={2021},&#xA;  organization={PMLR}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a name=&#34;contribution&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contribute to PaddleSpeech&lt;/h2&gt; &#xA;&lt;p&gt;You are warmly welcome to submit questions in &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/discussions&#34;&gt;discussions&lt;/a&gt; and bug reports in &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleSpeech/issues&#34;&gt;issues&lt;/a&gt;! Also, we highly appreciate if you are willing to contribute to this project!&lt;/p&gt; &#xA;&lt;h3&gt;Contributors&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/zh794390558&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/3038472?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Jackwaterveg&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/87408988?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/yt605155624&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/24568452?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Honei&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/11361692?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/KPatr1ck&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/22954146?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/kuke&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/3064195?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lym0302&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/34430015?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/SmileGoat&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/56786796?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/xinghai-sun&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/7038341?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pkuyym&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/5782283?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/LittleChenCc&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/10339970?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/qingen&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/3139179?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/D-DanielYang&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/23690325?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Mingxue-Xu&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/92848346?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/745165806&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/20623194?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/jerryuhoo&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/24245709?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/WilliamZhang06&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/97937340?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/chrisxu2016&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/18379485?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/iftaken&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/30135920?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lfchener&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/6771821?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/BarryKCL&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/48039828?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/mmglove&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/38800877?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/gongel&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/24390500?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/luotao1&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/6836917?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/wanghaoshuang&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/7534971?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/kslz&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/54951765?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/JiehangXie&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/51190264?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/david-95&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/15189190?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/THUzyt21&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/91456992?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/buchongyu2&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/29157444?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/iclementine&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/16222986?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/phecda-xu&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/46859427?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/freeliuzc&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/23568094?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ZeyuChen&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/1371212?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ccrrong&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/101700995?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/AK391&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/81195143?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/qingqing01&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/7845005?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/0x45f&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/23097963?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/vpegasus&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/22723154?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ericxk&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/4719594?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Betterman-qs&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/61459181?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/sneaxiy&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/32832641?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Doubledongli&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/20540661?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/apps/dependabot&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/in/29110?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/kvinwang&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/6442159?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/chenkui164&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/34813030?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/PaddleZhang&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/97284124?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/billishyahao&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/96406262?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/BrightXiaoHan&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/25839309?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/jiqiren11&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/82639260?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ryanrussell&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/523300?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/GT-ZhangAcer&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/46156734?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/tensor-tang&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/21351065?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/hysunflower&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/52739577?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/oyjxer&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/16233945?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/JamesLim-sy&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/61349199?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/limpidezza&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/71760778?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/windstamp&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/34057289?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/AshishKarel&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/58069375?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/chesterkuo&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/6285069?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/YDX-2147483647&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/73375426?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/AdamBear&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/2288870?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/wwhu&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/6081200?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lispc&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/2833376?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/harisankarh&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/1307053?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/pengzhendong&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/10704539?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Jackiexiao&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/18050469?s=60&amp;amp;v=4&#34; width=&#34;75&#34; height=&#34;75&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/HighCWu&#34;&gt;HighCWu&lt;/a&gt; for adding &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/vits&#34;&gt;VITS-aishell3&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/examples/aishell3/vits-vc&#34;&gt;VITS-VC&lt;/a&gt; examples.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/david-95&#34;&gt;david-95&lt;/a&gt; improved TTS, fixed multi-punctuation bug, and contributed to multiple program and data.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/BarryKCL&#34;&gt;BarryKCL&lt;/a&gt; improved TTS Chinses frontend based on &lt;a href=&#34;https://github.com/GitYCC/g2pW&#34;&gt;G2PW&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/yeyupiaoling&#34;&gt;yeyupiaoling&lt;/a&gt;/&lt;a href=&#34;https://github.com/yeyupiaoling/PPASR&#34;&gt;PPASR&lt;/a&gt;/&lt;a href=&#34;https://github.com/yeyupiaoling/PaddlePaddle-DeepSpeech&#34;&gt;PaddlePaddle-DeepSpeech&lt;/a&gt;/&lt;a href=&#34;https://github.com/yeyupiaoling/VoiceprintRecognition-PaddlePaddle&#34;&gt;VoiceprintRecognition-PaddlePaddle&lt;/a&gt;/&lt;a href=&#34;https://github.com/yeyupiaoling/AudioClassification-PaddlePaddle&#34;&gt;AudioClassification-PaddlePaddle&lt;/a&gt; for years of attention, constructive advice and great help.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/mymagicpower&#34;&gt;mymagicpower&lt;/a&gt; for the Java implementation of ASR upon &lt;a href=&#34;https://github.com/mymagicpower/AIAS/tree/main/3_audio_sdks/asr_sdk&#34;&gt;short&lt;/a&gt; and &lt;a href=&#34;https://github.com/mymagicpower/AIAS/tree/main/3_audio_sdks/asr_long_audio_sdk&#34;&gt;long&lt;/a&gt; audio files.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/JiehangXie&#34;&gt;JiehangXie&lt;/a&gt;/&lt;a href=&#34;https://github.com/JiehangXie/PaddleBoBo&#34;&gt;PaddleBoBo&lt;/a&gt; for developing Virtual Uploader(VUP)/Virtual YouTuber(VTuber) with PaddleSpeech TTS function.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/745165806&#34;&gt;745165806&lt;/a&gt;/&lt;a href=&#34;https://github.com/745165806/PaddleSpeechTask&#34;&gt;PaddleSpeechTask&lt;/a&gt; for contributing Punctuation Restoration model.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/745165806&#34;&gt;kslz&lt;/a&gt; for supplementary Chinese documents.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/awmmmm&#34;&gt;awmmmm&lt;/a&gt; for contributing fastspeech2 aishell3 conformer pretrained model.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/phecda-xu&#34;&gt;phecda-xu&lt;/a&gt;/&lt;a href=&#34;https://github.com/phecda-xu/PaddleDubbing&#34;&gt;PaddleDubbing&lt;/a&gt; for developing a dubbing tool with GUI based on PaddleSpeech TTS model.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/jerryuhoo&#34;&gt;jerryuhoo&lt;/a&gt;/&lt;a href=&#34;https://github.com/jerryuhoo/VTuberTalk&#34;&gt;VTuberTalk&lt;/a&gt; for developing a GUI tool based on PaddleSpeech TTS and code for making datasets from videos based on PaddleSpeech ASR.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/vpegasus&#34;&gt;vpegasus&lt;/a&gt;/&lt;a href=&#34;https://github.com/vpegasus/xuesebot&#34;&gt;xuesebot&lt;/a&gt; for developing a rasa chatbot,which is able to speak and listen thanks to PaddleSpeech.&lt;/li&gt; &#xA; &lt;li&gt;Many thanks to &lt;a href=&#34;https://github.com/chenkui164&#34;&gt;chenkui164&lt;/a&gt;/&lt;a href=&#34;https://github.com/chenkui164/FastASR&#34;&gt;FastASR&lt;/a&gt; for the C++ inference implementation of PaddleSpeech ASR.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Besides, PaddleSpeech depends on a lot of open source repositories. See &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/docs/source/reference.md&#34;&gt;references&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;PaddleSpeech is provided under the &lt;a href=&#34;https://raw.githubusercontent.com/PaddlePaddle/PaddleSpeech/develop/LICENSE&#34;&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>tiangolo/full-stack-fastapi-postgresql</title>
    <updated>2022-10-21T01:36:12Z</updated>
    <id>tag:github.com,2022-10-21:/tiangolo/full-stack-fastapi-postgresql</id>
    <link href="https://github.com/tiangolo/full-stack-fastapi-postgresql" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Full stack, modern web application generator. Using FastAPI, PostgreSQL as database, Docker, automatic HTTPS and more.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Full Stack FastAPI and PostgreSQL - Base Project Generator&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.com/tiangolo/full-stack-fastapi-postgresql&#34;&gt;&lt;img src=&#34;https://travis-ci.com/tiangolo/full-stack-fastapi-postgresql.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Generate a backend and frontend stack using Python, including interactive API documentation.&lt;/p&gt; &#xA;&lt;h3&gt;Interactive API documentation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/tiangolo/full-stack-fastapi-postgresql/master/img/docs.png&#34; alt=&#34;API docs&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Alternative API documentation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/tiangolo/full-stack-fastapi-postgresql/master/img/redoc.png&#34; alt=&#34;API docs&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Dashboard Login&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/tiangolo/full-stack-fastapi-postgresql/master/img/login.png&#34; alt=&#34;API docs&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Dashboard - Create User&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/tiangolo/full-stack-fastapi-postgresql/master/img/dashboard.png&#34; alt=&#34;API docs&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Full &lt;strong&gt;Docker&lt;/strong&gt; integration (Docker based).&lt;/li&gt; &#xA; &lt;li&gt;Docker Swarm Mode deployment.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt; integration and optimization for local development.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Production ready&lt;/strong&gt; Python web server using Uvicorn and Gunicorn.&lt;/li&gt; &#xA; &lt;li&gt;Python &lt;a href=&#34;https://github.com/tiangolo/fastapi&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;FastAPI&lt;/strong&gt;&lt;/a&gt; backend: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt;: Very high performance, on par with &lt;strong&gt;NodeJS&lt;/strong&gt; and &lt;strong&gt;Go&lt;/strong&gt; (thanks to Starlette and Pydantic).&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Intuitive&lt;/strong&gt;: Great editor support. &lt;abbr title=&#34;also known as auto-complete, autocompletion, IntelliSense&#34;&gt;Completion&lt;/abbr&gt; everywhere. Less time debugging.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Easy&lt;/strong&gt;: Designed to be easy to use and learn. Less time reading docs.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Short&lt;/strong&gt;: Minimize code duplication. Multiple features from each parameter declaration.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Robust&lt;/strong&gt;: Get production-ready code. With automatic interactive documentation.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Standards-based&lt;/strong&gt;: Based on (and fully compatible with) the open standards for APIs: &lt;a href=&#34;https://github.com/OAI/OpenAPI-Specification&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;OpenAPI&lt;/a&gt; and &lt;a href=&#34;http://json-schema.org/&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;JSON Schema&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://fastapi.tiangolo.com/features/&#34; class=&#34;external-link&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Many other features&lt;/strong&gt;&lt;/a&gt; including automatic validation, serialization, interactive documentation, authentication with OAuth2 JWT tokens, etc.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Secure password&lt;/strong&gt; hashing by default.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;JWT token&lt;/strong&gt; authentication.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;SQLAlchemy&lt;/strong&gt; models (independent of Flask extensions, so they can be used with Celery workers directly).&lt;/li&gt; &#xA; &lt;li&gt;Basic starting models for users (modify and remove as you need).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Alembic&lt;/strong&gt; migrations.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CORS&lt;/strong&gt; (Cross Origin Resource Sharing).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Celery&lt;/strong&gt; worker that can import and use models and code from the rest of the backend selectively.&lt;/li&gt; &#xA; &lt;li&gt;REST backend tests based on &lt;strong&gt;Pytest&lt;/strong&gt;, integrated with Docker, so you can test the full API interaction, independent on the database. As it runs in Docker, it can build a new data store from scratch each time (so you can use ElasticSearch, MongoDB, CouchDB, or whatever you want, and just test that the API works).&lt;/li&gt; &#xA; &lt;li&gt;Easy Python integration with &lt;strong&gt;Jupyter Kernels&lt;/strong&gt; for remote or in-Docker development with extensions like Atom Hydrogen or Visual Studio Code Jupyter.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Vue&lt;/strong&gt; frontend: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Generated with Vue CLI.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;JWT Authentication&lt;/strong&gt; handling.&lt;/li&gt; &#xA;   &lt;li&gt;Login view.&lt;/li&gt; &#xA;   &lt;li&gt;After login, main dashboard view.&lt;/li&gt; &#xA;   &lt;li&gt;Main dashboard with user creation and edition.&lt;/li&gt; &#xA;   &lt;li&gt;Self user edition.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Vuex&lt;/strong&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Vue-router&lt;/strong&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Vuetify&lt;/strong&gt; for beautiful material design components.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;TypeScript&lt;/strong&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;Docker server based on &lt;strong&gt;Nginx&lt;/strong&gt; (configured to play nicely with Vue-router).&lt;/li&gt; &#xA;   &lt;li&gt;Docker multi-stage building, so you don&#39;t need to save or commit compiled code.&lt;/li&gt; &#xA;   &lt;li&gt;Frontend tests ran at build time (can be disabled too).&lt;/li&gt; &#xA;   &lt;li&gt;Made as modular as possible, so it works out of the box, but you can re-generate with Vue CLI or create it as you need, and re-use what you want.&lt;/li&gt; &#xA;   &lt;li&gt;It&#39;s also easy to remove it if you have an API-only app, check the instructions in the generated &lt;code&gt;README.md&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;PGAdmin&lt;/strong&gt; for PostgreSQL database, you can modify it to use PHPMyAdmin and MySQL easily.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Flower&lt;/strong&gt; for Celery jobs monitoring.&lt;/li&gt; &#xA; &lt;li&gt;Load balancing between frontend and backend with &lt;strong&gt;Traefik&lt;/strong&gt;, so you can have both under the same domain, separated by path, but served by different containers.&lt;/li&gt; &#xA; &lt;li&gt;Traefik integration, including Let&#39;s Encrypt &lt;strong&gt;HTTPS&lt;/strong&gt; certificates automatic generation.&lt;/li&gt; &#xA; &lt;li&gt;GitLab &lt;strong&gt;CI&lt;/strong&gt; (continuous integration), including frontend and backend testing.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to use it&lt;/h2&gt; &#xA;&lt;p&gt;Go to the directory where you want to create your project and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install cookiecutter&#xA;cookiecutter https://github.com/tiangolo/full-stack-fastapi-postgresql&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Generate passwords&lt;/h3&gt; &#xA;&lt;p&gt;You will be asked to provide passwords and secret keys for several components. Open another terminal and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;openssl rand -hex 32&#xA;# Outputs something like: 99d3b1f01aa639e4a76f4fc281fc834747a543720ba4c8a8648ba755aef9be7f&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Copy the contents and use that as password / secret key. And run that again to generate another secure key.&lt;/p&gt; &#xA;&lt;h3&gt;Input variables&lt;/h3&gt; &#xA;&lt;p&gt;The generator (cookiecutter) will ask you for some data, you might want to have at hand before generating the project.&lt;/p&gt; &#xA;&lt;p&gt;The input variables, with their default values (some auto generated) are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;project_name&lt;/code&gt;: The name of the project&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;project_slug&lt;/code&gt;: The development friendly name of the project. By default, based on the project name&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;domain_main&lt;/code&gt;: The domain in where to deploy the project for production (from the branch &lt;code&gt;production&lt;/code&gt;), used by the load balancer, backend, etc. By default, based on the project slug.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;domain_staging&lt;/code&gt;: The domain in where to deploy while staging (before production) (from the branch &lt;code&gt;master&lt;/code&gt;). By default, based on the main domain.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;docker_swarm_stack_name_main&lt;/code&gt;: The name of the stack while deploying to Docker in Swarm mode for production. By default, based on the domain.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;docker_swarm_stack_name_staging&lt;/code&gt;: The name of the stack while deploying to Docker in Swarm mode for staging. By default, based on the domain.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;secret_key&lt;/code&gt;: Backend server secret key. Use the method above to generate it.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;first_superuser&lt;/code&gt;: The first superuser generated, with it you will be able to create more users, etc. By default, based on the domain.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;first_superuser_password&lt;/code&gt;: First superuser password. Use the method above to generate it.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;backend_cors_origins&lt;/code&gt;: Origins (domains, more or less) that are enabled for CORS (Cross Origin Resource Sharing). This allows a frontend in one domain (e.g. &lt;code&gt;https://dashboard.example.com&lt;/code&gt;) to communicate with this backend, that could be living in another domain (e.g. &lt;code&gt;https://api.example.com&lt;/code&gt;). It can also be used to allow your local frontend (with a custom &lt;code&gt;hosts&lt;/code&gt; domain mapping, as described in the project&#39;s &lt;code&gt;README.md&lt;/code&gt;) that could be living in &lt;code&gt;http://dev.example.com:8080&lt;/code&gt; to communicate with the backend at &lt;code&gt;https://stag.example.com&lt;/code&gt;. Notice the &lt;code&gt;http&lt;/code&gt; vs &lt;code&gt;https&lt;/code&gt; and the &lt;code&gt;dev.&lt;/code&gt; prefix for local development vs the &#34;staging&#34; &lt;code&gt;stag.&lt;/code&gt; prefix. By default, it includes origins for production, staging and development, with ports commonly used during local development by several popular frontend frameworks (Vue with &lt;code&gt;:8080&lt;/code&gt;, React, Angular).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;smtp_port&lt;/code&gt;: Port to use to send emails via SMTP. By default &lt;code&gt;587&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;smtp_host&lt;/code&gt;: Host to use to send emails, it would be given by your email provider, like Mailgun, Sparkpost, etc.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;smtp_user&lt;/code&gt;: The user to use in the SMTP connection. The value will be given by your email provider.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;smtp_password&lt;/code&gt;: The password to be used in the SMTP connection. The value will be given by the email provider.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;smtp_emails_from_email&lt;/code&gt;: The email account to use as the sender in the notification emails, it would be something like &lt;code&gt;info@your-custom-domain.com&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;postgres_password&lt;/code&gt;: Postgres database password. Use the method above to generate it. (You could easily modify it to use MySQL, MariaDB, etc).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;pgadmin_default_user&lt;/code&gt;: PGAdmin default user, to log-in to the PGAdmin interface.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;pgadmin_default_user_password&lt;/code&gt;: PGAdmin default user password. Generate it with the method above.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;traefik_constraint_tag&lt;/code&gt;: The tag to be used by the internal Traefik load balancer (for example, to divide requests between backend and frontend) for production. Used to separate this stack from any other stack you might have. This should identify each stack in each environment (production, staging, etc).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;traefik_constraint_tag_staging&lt;/code&gt;: The Traefik tag to be used while on staging.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;traefik_public_constraint_tag&lt;/code&gt;: The tag that should be used by stack services that should communicate with the public.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;flower_auth&lt;/code&gt;: Basic HTTP authentication for flower, in the form&lt;code&gt;user:password&lt;/code&gt;. By default: &#34;&lt;code&gt;admin:changethis&lt;/code&gt;&#34;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;sentry_dsn&lt;/code&gt;: Key URL (DSN) of Sentry, for live error reporting. You can use the open source version or a free account. E.g.: &lt;code&gt;https://1234abcd:5678ef@sentry.example.com/30&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;docker_image_prefix&lt;/code&gt;: Prefix to use for Docker image names. If you are using GitLab Docker registry it would be based on your code repository. E.g.: &lt;code&gt;git.example.com/development-team/my-awesome-project/&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;docker_image_backend&lt;/code&gt;: Docker image name for the backend. By default, it will be based on your Docker image prefix, e.g.: &lt;code&gt;git.example.com/development-team/my-awesome-project/backend&lt;/code&gt;. And depending on your environment, a different tag will be appended ( &lt;code&gt;prod&lt;/code&gt;, &lt;code&gt;stag&lt;/code&gt;, &lt;code&gt;branch&lt;/code&gt; ). So, the final image names used will be like: &lt;code&gt;git.example.com/development-team/my-awesome-project/backend:prod&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;docker_image_celeryworker&lt;/code&gt;: Docker image for the celery worker. By default, based on your Docker image prefix.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;docker_image_frontend&lt;/code&gt;: Docker image for the frontend. By default, based on your Docker image prefix.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to deploy&lt;/h2&gt; &#xA;&lt;p&gt;This stack can be adjusted and used with several deployment options that are compatible with Docker Compose, but it is designed to be used in a cluster controlled with pure Docker in Swarm Mode with a Traefik main load balancer proxy handling automatic HTTPS certificates, using the ideas from &lt;a href=&#34;https://dockerswarm.rocks&#34; target=&#34;_blank&#34;&gt;DockerSwarm.rocks&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://dockerswarm.rocks&#34; target=&#34;_blank&#34;&gt;DockerSwarm.rocks&lt;/a&gt; to see how to deploy such a cluster in 20 minutes.&lt;/p&gt; &#xA;&lt;h2&gt;More details&lt;/h2&gt; &#xA;&lt;p&gt;After using this generator, your new project (the directory created) will contain an extensive &lt;code&gt;README.md&lt;/code&gt; with instructions for development, deployment, etc. You can pre-read &lt;a href=&#34;https://raw.githubusercontent.com/tiangolo/full-stack-fastapi-postgresql/master/%7B%7Bcookiecutter.project_slug%7D%7D/README.md&#34;&gt;the project &lt;code&gt;README.md&lt;/code&gt; template here too&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Sibling project generators&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Full Stack FastAPI Couchbase: &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-couchbase&#34;&gt;https://github.com/tiangolo/full-stack-fastapi-couchbase&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Release Notes&lt;/h2&gt; &#xA;&lt;h3&gt;Latest Changes&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Update issue-manager. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/211&#34;&gt;#211&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Add &lt;a href=&#34;https://github.com/sponsors/tiangolo&#34;&gt;GitHub Sponsors&lt;/a&gt; button. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/201&#34;&gt;#201&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Add consistent errors for env vars not set. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/200&#34;&gt;#200&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Upgrade Traefik to version 2, keeping in sync with DockerSwarm.rocks. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/199&#34;&gt;#199&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Add docs about reporting test coverage in HTML. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/161&#34;&gt;#161&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Run tests with &lt;code&gt;TestClient&lt;/code&gt;. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/160&#34;&gt;#160&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Refactor backend: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Simplify configs for tools and format to better support editor integration.&lt;/li&gt; &#xA;   &lt;li&gt;Add mypy configurations and plugins.&lt;/li&gt; &#xA;   &lt;li&gt;Add types to all the codebase.&lt;/li&gt; &#xA;   &lt;li&gt;Update types for SQLAlchemy models with plugin.&lt;/li&gt; &#xA;   &lt;li&gt;Update and refactor CRUD utils.&lt;/li&gt; &#xA;   &lt;li&gt;Refactor DB sessions to use dependencies with &lt;code&gt;yield&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;Refactor dependencies, security, CRUD, models, schemas, etc. To simplify code and improve autocompletion.&lt;/li&gt; &#xA;   &lt;li&gt;Change from PyJWT to Python-JOSE as it supports additional use cases.&lt;/li&gt; &#xA;   &lt;li&gt;Fix JWT tokens using user email/ID as the subject in &lt;code&gt;sub&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/158&#34;&gt;#158&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Add docs about removing the frontend, for an API-only app. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/156&#34;&gt;#156&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Simplify scripts and development, update docs and configs. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/155&#34;&gt;#155&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Simplify &lt;code&gt;docker-compose.*.yml&lt;/code&gt; files, refactor deployment to reduce config files. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/153&#34;&gt;#153&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Simplify env var files, merge to a single &lt;code&gt;.env&lt;/code&gt; file. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/151&#34;&gt;#151&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;0.5.0&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Make the Traefik public network a fixed default of &lt;code&gt;traefik-public&lt;/code&gt; as done in DockerSwarm.rocks, to simplify development and iteration of the project generator. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/150&#34;&gt;#150&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Update to PostgreSQL 12. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/148&#34;&gt;#148&lt;/a&gt;. by &lt;a href=&#34;https://github.com/RCheese&#34;&gt;@RCheese&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Use Poetry for package management. Initial PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/144&#34;&gt;#144&lt;/a&gt; by &lt;a href=&#34;https://github.com/RCheese&#34;&gt;@RCheese&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Fix Windows line endings for shell scripts after project generation with Cookiecutter hooks. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/149&#34;&gt;#149&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Upgrade Vue CLI to version 4. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/120&#34;&gt;#120&lt;/a&gt; by &lt;a href=&#34;https://github.com/br3ndonland&#34;&gt;@br3ndonland&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Remove duplicate &lt;code&gt;login&lt;/code&gt; tag. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/135&#34;&gt;#135&lt;/a&gt; by &lt;a href=&#34;https://github.com/Nonameentered&#34;&gt;@Nonameentered&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Fix showing email in dashboard when there&#39;s no user&#39;s full name. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/129&#34;&gt;#129&lt;/a&gt; by &lt;a href=&#34;https://github.com/rlonka&#34;&gt;@rlonka&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Format code with Black and Flake8. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/121&#34;&gt;#121&lt;/a&gt; by &lt;a href=&#34;https://github.com/br3ndonland&#34;&gt;@br3ndonland&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Simplify SQLAlchemy Base class. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/117&#34;&gt;#117&lt;/a&gt; by &lt;a href=&#34;https://github.com/airibarne&#34;&gt;@airibarne&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Update CRUD utils for users, handling password hashing. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/106&#34;&gt;#106&lt;/a&gt; by &lt;a href=&#34;https://github.com/mocsar&#34;&gt;@mocsar&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Use &lt;code&gt;.&lt;/code&gt; instead of &lt;code&gt;source&lt;/code&gt; for interoperability. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/98&#34;&gt;#98&lt;/a&gt; by &lt;a href=&#34;https://github.com/gucharbon&#34;&gt;@gucharbon&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Use Pydantic&#39;s &lt;code&gt;BaseSettings&lt;/code&gt; for settings/configs and env vars. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/87&#34;&gt;#87&lt;/a&gt; by &lt;a href=&#34;https://github.com/StephenBrown2&#34;&gt;@StephenBrown2&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Remove &lt;code&gt;package-lock.json&lt;/code&gt; to let everyone lock their own versions (depending on OS, etc).&lt;/li&gt; &#xA; &lt;li&gt;Simplify Traefik service labels PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/139&#34;&gt;#139&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Add email validation. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/40&#34;&gt;#40&lt;/a&gt; by &lt;a href=&#34;https://github.com/kedod&#34;&gt;@kedod&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Fix typo in README. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/83&#34;&gt;#83&lt;/a&gt; by &lt;a href=&#34;https://github.com/ashears&#34;&gt;@ashears&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Fix typo in README. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/80&#34;&gt;#80&lt;/a&gt; by &lt;a href=&#34;https://github.com/abjoker&#34;&gt;@abjoker&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Fix function name &lt;code&gt;read_item&lt;/code&gt; and response code. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/74&#34;&gt;#74&lt;/a&gt; by &lt;a href=&#34;https://github.com/jcaguirre89&#34;&gt;@jcaguirre89&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Fix typo in comment. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/70&#34;&gt;#70&lt;/a&gt; by &lt;a href=&#34;https://github.com/daniel-butler&#34;&gt;@daniel-butler&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Fix Flower Docker configuration. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/37&#34;&gt;#37&lt;/a&gt; by &lt;a href=&#34;https://github.com/dmontagu&#34;&gt;@dmontagu&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Add new CRUD utils based on DB and Pydantic models. Initial PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/23&#34;&gt;#23&lt;/a&gt; by &lt;a href=&#34;https://github.com/ebreton&#34;&gt;@ebreton&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Add normal user testing Pytest fixture. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/20&#34;&gt;#20&lt;/a&gt; by &lt;a href=&#34;https://github.com/ebreton&#34;&gt;@ebreton&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;0.4.0&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Fix security on resetting a password. Receive token as body, not query. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/34&#34;&gt;#34&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Fix security on resetting a password. Receive it as body, not query. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/33&#34;&gt;#33&lt;/a&gt; by &lt;a href=&#34;https://github.com/dmontagu&#34;&gt;@dmontagu&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Fix SQLAlchemy class lookup on initialization. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/29&#34;&gt;#29&lt;/a&gt; by &lt;a href=&#34;https://github.com/ebreton&#34;&gt;@ebreton&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Fix SQLAlchemy operation errors on database restart. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/32&#34;&gt;#32&lt;/a&gt; by &lt;a href=&#34;https://github.com/ebreton&#34;&gt;@ebreton&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Fix locations of scripts in generated README. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/19&#34;&gt;#19&lt;/a&gt; by &lt;a href=&#34;https://github.com/ebreton&#34;&gt;@ebreton&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Forward arguments from script to &lt;code&gt;pytest&lt;/code&gt; inside container. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/17&#34;&gt;#17&lt;/a&gt; by &lt;a href=&#34;https://github.com/ebreton&#34;&gt;@ebreton&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Update development scripts.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Read Alembic configs from env vars. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/9&#34; target=&#34;_blank&#34;&gt;#9&lt;/a&gt; by &lt;a href=&#34;https://github.com/ebreton&#34; target=&#34;_blank&#34;&gt;@ebreton&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create DB Item objects from all Pydantic model&#39;s fields.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Update Jupyter Lab installation and util script/environment variable for local development.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;0.3.0&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/14&#34; target=&#34;_blank&#34;&gt;#14&lt;/a&gt;:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Update CRUD utils to use types better.&lt;/li&gt; &#xA;   &lt;li&gt;Simplify Pydantic model names, from &lt;code&gt;UserInCreate&lt;/code&gt; to &lt;code&gt;UserCreate&lt;/code&gt;, etc.&lt;/li&gt; &#xA;   &lt;li&gt;Upgrade packages.&lt;/li&gt; &#xA;   &lt;li&gt;Add new generic &#34;Items&#34; models, crud utils, endpoints, and tests. To facilitate re-using them to create new functionality. As they are simple and generic (not like Users), it&#39;s easier to copy-paste and adapt them to each use case.&lt;/li&gt; &#xA;   &lt;li&gt;Update endpoints/&lt;em&gt;path operations&lt;/em&gt; to simplify code and use new utilities, prefix and tags in &lt;code&gt;include_router&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;Update testing utils.&lt;/li&gt; &#xA;   &lt;li&gt;Update linting rules, relax vulture to reduce false positives.&lt;/li&gt; &#xA;   &lt;li&gt;Update migrations to include new Items.&lt;/li&gt; &#xA;   &lt;li&gt;Update project README.md with tips about how to start with backend.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Upgrade Python to 3.7 as Celery is now compatible too. PR &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/10&#34; target=&#34;_blank&#34;&gt;#10&lt;/a&gt; by &lt;a href=&#34;https://github.com/ebreton&#34; target=&#34;_blank&#34;&gt;@ebreton&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;0.2.2&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fix frontend hijacking /docs in development. Using latest &lt;a href=&#34;https://github.com/tiangolo/node-frontend&#34;&gt;https://github.com/tiangolo/node-frontend&lt;/a&gt; with custom Nginx configs in frontend. &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/6&#34; target=&#34;_blank&#34;&gt;PR #6&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;0.2.1&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Fix documentation for &lt;em&gt;path operation&lt;/em&gt; to get user by ID. &lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/4&#34; target=&#34;_blank&#34;&gt;PR #4&lt;/a&gt; by &lt;a href=&#34;https://github.com/mpclarkson&#34; target=&#34;_blank&#34;&gt;@mpclarkson&lt;/a&gt; in FastAPI.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Set &lt;code&gt;/start-reload.sh&lt;/code&gt; as a command override for development by default.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Update generated README.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;0.2.0&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tiangolo/full-stack-fastapi-postgresql/pull/2&#34; target=&#34;_blank&#34;&gt;PR #2&lt;/a&gt;&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Simplify and update backend &lt;code&gt;Dockerfile&lt;/code&gt;s.&lt;/li&gt; &#xA; &lt;li&gt;Refactor and simplify backend code, improve naming, imports, modules and &#34;namespaces&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Improve and simplify Vuex integration with TypeScript accessors.&lt;/li&gt; &#xA; &lt;li&gt;Standardize frontend components layout, buttons order, etc.&lt;/li&gt; &#xA; &lt;li&gt;Add local development scripts (to develop this project generator itself).&lt;/li&gt; &#xA; &lt;li&gt;Add logs to startup modules to detect errors early.&lt;/li&gt; &#xA; &lt;li&gt;Improve FastAPI dependency utilities, to simplify and reduce code (to require a superuser).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;0.1.2&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fix path operation to update self-user, set parameters as body payload.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;0.1.1&lt;/h3&gt; &#xA;&lt;p&gt;Several bug fixes since initial publication, including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Order of path operations for users.&lt;/li&gt; &#xA; &lt;li&gt;Frontend sending login data in the correct format.&lt;/li&gt; &#xA; &lt;li&gt;Add &lt;a href=&#34;https://localhost&#34;&gt;https://localhost&lt;/a&gt; variants to CORS.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the terms of the MIT license.&lt;/p&gt;</summary>
  </entry>
</feed>