<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-01-15T01:39:23Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>microsoft/LLMLingua</title>
    <updated>2024-01-15T01:39:23Z</updated>
    <id>tag:github.com,2024-01-15:/microsoft/LLMLingua</id>
    <link href="https://github.com/microsoft/LLMLingua" rel="alternate"></link>
    <summary type="html">&lt;p&gt;To speed up LLMs&#39; inference and enhance LLM&#39;s perceive of key information, compress the prompt and KV-Cache, which achieves up to 20x compression with minimal performance loss.&lt;/p&gt;&lt;hr&gt;&lt;div style=&#34;display: flex; align-items: center;&#34;&gt; &#xA; &lt;div style=&#34;width: 100px; margin-right: 10px; height:auto;&#34; align=&#34;left&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/images/LLMLingua_logo.png&#34; alt=&#34;LLMLingua&#34; width=&#34;100&#34; align=&#34;left&#34;&gt; &#xA; &lt;/div&gt; &#xA; &lt;div style=&#34;flex-grow: 1;&#34; align=&#34;center&#34;&gt; &#xA;  &lt;h2 align=&#34;center&#34;&gt;(Long)LLMLingua: Enhancing Large Language Model Inference via Prompt Compression&lt;/h2&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; | &lt;a href=&#34;https://llmlingua.com/&#34;&gt;&lt;b&gt;Project Page&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/abs/2310.05736&#34;&gt;&lt;b&gt;LLMLingua Paper&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/abs/2310.06839&#34;&gt;&lt;b&gt;LongLLMLingua Paper&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/microsoft/LLMLingua&#34;&gt;&lt;b&gt;HF Space Demo&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/LLMLingua/assets/30883354/eb0ea70d-6d4c-4aa7-8977-61f94bb87438&#34;&gt;https://github.com/microsoft/LLMLingua/assets/30883354/eb0ea70d-6d4c-4aa7-8977-61f94bb87438&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ü§≥ Talk slides are available in &lt;a href=&#34;https://drive.google.com/file/d/1fzK3wOvy2boF7XzaYuq2bQ3jFeP1WMk3/view?usp=sharing&#34;&gt;AI Time Jan, 24&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;üñ• EMNLP&#39;23 slides are available in &lt;a href=&#34;https://drive.google.com/file/d/1GxQLAEN8bBB2yiEdQdW4UKoJzZc0es9t/view&#34;&gt;Session 5&lt;/a&gt; and &lt;a href=&#34;https://drive.google.com/file/d/1LJBUfJrKxbpdkwo13SgPOqugk-UjLVIF/view&#34;&gt;BoF-6&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;üìö Check out our new &lt;a href=&#34;https://medium.com/@iofu728/longllmlingua-bye-bye-to-middle-loss-and-save-on-your-rag-costs-via-prompt-compression-54b559b9ddf7&#34;&gt;blog post&lt;/a&gt; discussing RAG benefits and cost savings through prompt compression. See the script example &lt;a href=&#34;https://github.com/microsoft/LLMLingua/raw/main/examples/Retrieval.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;üéà Visit our &lt;a href=&#34;https://llmlingua.com/&#34;&gt;project page&lt;/a&gt; for real-world case studies in RAG, Online Meetings, CoT, and Code.&lt;/li&gt; &#xA; &lt;li&gt;üë®‚Äçü¶Ø Explore our &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/examples&#34;&gt;&#39;./examples&#39;&lt;/a&gt; directory for practical applications, including &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/examples/RAG.ipynb&#34;&gt;RAG&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/examples/OnlineMeeting.ipynb&#34;&gt;Online Meeting&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/examples/CoT.ipynb&#34;&gt;CoT&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/examples/Code.ipynb&#34;&gt;Code&lt;/a&gt;, and &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/examples/RAGLlamaIndex.ipynb&#34;&gt;RAG using LlamaIndex&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;üëæ LongLLMLingua is now part of the &lt;a href=&#34;https://github.com/run-llama/llama_index/raw/main/llama_index/indices/postprocessor/longllmlingua.py&#34;&gt;LlamaIndex pipeline&lt;/a&gt;, a widely-used RAG framework.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;TL;DR&lt;/h2&gt; &#xA;&lt;p&gt;LLMLingua utilizes a compact, well-trained language model (e.g., GPT2-small, LLaMA-7B) to identify and remove non-essential tokens in prompts. This approach enables efficient inference with large language models (LLMs), achieving up to 20x compression with minimal performance loss.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.05736&#34;&gt;LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models&lt;/a&gt; (EMNLP 2023)&lt;br&gt; &lt;em&gt;Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang and Lili Qiu&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;LongLLMLingua mitigates the &#39;lost in the middle&#39; issue in LLMs, enhancing long-context information processing. It reduces costs and boosts efficiency with prompt compression, improving RAG performance by up to 21.4% using only 1/4 of the tokens.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.06839&#34;&gt;LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression&lt;/a&gt; (Under Review)&lt;br&gt; &lt;em&gt;Huiqiang Jiang, Qianhui Wu, Xufang Luo, Dongsheng Li, Chin-Yew Lin, Yuqing Yang and Lili Qiu&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üé• Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/images/LLMLingua_motivation.png&#34; alt=&#34;Background&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ever encountered the token limit when asking ChatGPT to summarize lengthy texts?&lt;/li&gt; &#xA; &lt;li&gt;Frustrated with ChatGPT forgetting previous instructions after extensive fine-tuning?&lt;/li&gt; &#xA; &lt;li&gt;Experienced high costs using GPT3.5/4 API for experiments despite excellent results?&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;While Large Language Models like ChatGPT and GPT-4 excel in generalization and reasoning, they often face challenges like prompt length limits and prompt-based pricing schemes.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/images/motivation.png&#34; alt=&#34;Motivation for LLMLingua&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Now you can use &lt;strong&gt;LLMLingua&lt;/strong&gt; &amp;amp; &lt;strong&gt;LongLLMLingua&lt;/strong&gt;!&lt;/p&gt; &#xA;&lt;p&gt;These tools offer an efficient solution to compress prompts by up to &lt;strong&gt;20x&lt;/strong&gt;, enhancing the utility of LLMs.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üí∞ &lt;strong&gt;Cost Savings&lt;/strong&gt;: Reduces both prompt and generation lengths.&lt;/li&gt; &#xA; &lt;li&gt;üìù &lt;strong&gt;Extended Context Support&lt;/strong&gt;: Enhances support for longer contexts, mitigates the &#34;lost in the middle&#34; issue, and boosts overall performance.&lt;/li&gt; &#xA; &lt;li&gt;‚öñÔ∏è &lt;strong&gt;Robustness&lt;/strong&gt;: No additional training needed for LLMs.&lt;/li&gt; &#xA; &lt;li&gt;üïµÔ∏è &lt;strong&gt;Knowledge Retention&lt;/strong&gt;: Maintains original prompt information like ICL and reasoning.&lt;/li&gt; &#xA; &lt;li&gt;üìú &lt;strong&gt;KV-Cache Compression&lt;/strong&gt;: Accelerates inference process.&lt;/li&gt; &#xA; &lt;li&gt;ü™É &lt;strong&gt;Comprehensive Recovery&lt;/strong&gt;: GPT-4 can recover all key information from compressed prompts.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/images/LLMLingua.png&#34; alt=&#34;Framework of LLMLingua&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/images/LongLLMLingua.png&#34; alt=&#34;Framework of LongLLMLingua&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/images/LLMLingua_demo.png&#34; alt=&#34;Demo of LLMLingua&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;PS: This demo is based on the &lt;a href=&#34;https://github.com/feedox/alt-gpt&#34;&gt;alt-gpt&lt;/a&gt; project. Special thanks to @Livshitz for their valuable contribution.&lt;/p&gt; &#xA;&lt;p&gt;If you find this repo helpful, please cite the following papers:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{jiang-etal-2023-llmlingua,&#xA;    title = &#34;{LLML}ingua: Compressing Prompts for Accelerated Inference of Large Language Models&#34;,&#xA;    author = &#34;Huiqiang Jiang and Qianhui Wu and Chin-Yew Lin and Yuqing Yang and Lili Qiu&#34;,&#xA;    booktitle = &#34;Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing&#34;,&#xA;    month = dec,&#xA;    year = &#34;2023&#34;,&#xA;    publisher = &#34;Association for Computational Linguistics&#34;,&#xA;    url = &#34;https://aclanthology.org/2023.emnlp-main.825&#34;,&#xA;    doi = &#34;10.18653/v1/2023.emnlp-main.825&#34;,&#xA;    pages = &#34;13358--13376&#34;,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{jiang-etal-2023-longllmlingua,&#xA;    title = &#34;{L}ong{LLML}ingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression&#34;,&#xA;    author = &#34;Huiqiang Jiang and Qianhui Wu and and Xufang Luo and Dongsheng Li and Chin-Yew Lin and Yuqing Yang and Lili Qiu&#34;,&#xA;    url = &#34;https://arxiv.org/abs/2310.06839&#34;,&#xA;    journal = &#34;ArXiv preprint&#34;,&#xA;    volume = &#34;abs/2310.06839&#34;,&#xA;    year = &#34;2023&#34;,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üéØ Quick Start&lt;/h2&gt; &#xA;&lt;h4&gt;1. &lt;strong&gt;Installing (Long)LLMLingua:&lt;/strong&gt;&lt;/h4&gt; &#xA;&lt;p&gt;To get started with (Long)LLMLingua, simply install it using pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install llmlingua&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2. &lt;strong&gt;Using (Long)LLMLingua for Prompt Compression:&lt;/strong&gt;&lt;/h4&gt; &#xA;&lt;p&gt;With (Long)LLMLingua, you can easily compress your prompts. Here‚Äôs how you can do it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from llmlingua import PromptCompressor&#xA;&#xA;llm_lingua = PromptCompressor()&#xA;compressed_prompt = llm_lingua.compress_prompt(prompt, instruction=&#34;&#34;, question=&#34;&#34;, target_token=200)&#xA;&#xA;# &amp;gt; {&#39;compressed_prompt&#39;: &#39;Question: Sam bought a dozen boxes, each with 30 highlighter pens inside, for $10 each box. He reanged five of boxes into packages of sixlters each and sold them $3 per. He sold the rest theters separately at the of three pens $2. How much did make in total, dollars?\nLets think step step\nSam bought 1 boxes x00 oflters.\nHe bought 12 * 300ters in total\nSam then took 5 boxes 6ters0ters.\nHe sold these boxes for 5 *5\nAfterelling these  boxes there were 3030 highlighters remaining.\nThese form 330 / 3 = 110 groups of three pens.\nHe sold each of these groups for $2 each, so made 110 * 2 = $220 from them.\nIn total, then, he earned $220 + $15 = $235.\nSince his original cost was $120, he earned $235 - $120 = $115 in profit.\nThe answer is 115&#39;,&#xA;#  &#39;origin_tokens&#39;: 2365,&#xA;#  &#39;compressed_tokens&#39;: 211,&#xA;#  &#39;ratio&#39;: &#39;11.2x&#39;,&#xA;#  &#39;saving&#39;: &#39;, Saving $0.1 in GPT-4.&#39;}&#xA;&#xA;## Or use the quantation model, like TheBloke/Llama-2-7b-Chat-GPTQ, only need &amp;lt;8GB GPU memory.&#xA;## Before that, you need to pip install optimum auto-gptq&#xA;llm_lingua = PromptCompressor(&#34;TheBloke/Llama-2-7b-Chat-GPTQ&#34;, model_config={&#34;revision&#34;: &#34;main&#34;})&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;3. &lt;strong&gt;Learning More:&lt;/strong&gt;&lt;/h4&gt; &#xA;&lt;p&gt;To understand how to apply LLMLingua and LongLLMLingua in real-world scenarios like RAG, Online Meetings, CoT, and Code, please refer to our &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/examples&#34;&gt;&lt;strong&gt;examples&lt;/strong&gt;&lt;/a&gt;. For detailed guidance, the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/DOCUMENT.md&#34;&gt;&lt;strong&gt;documentation&lt;/strong&gt;&lt;/a&gt; provides extensive recommendations on effectively utilizing LLMLingua.&lt;/p&gt; &#xA;&lt;h2&gt;Frequently Asked Questions&lt;/h2&gt; &#xA;&lt;p&gt;For more insights and answers, visit our &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/LLMLingua/main/Transparency_FAQ.md&#34;&gt;FAQ section&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&#34;https://cla.opensource.microsoft.com&#34;&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h2&gt;Trademarks&lt;/h2&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>MooreThreads/Moore-AnimateAnyone</title>
    <updated>2024-01-15T01:39:23Z</updated>
    <id>tag:github.com,2024-01-15:/MooreThreads/Moore-AnimateAnyone</id>
    <link href="https://github.com/MooreThreads/Moore-AnimateAnyone" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ü§ó Introduction&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;update&lt;/strong&gt;Ôºöüî•üî•üî•We launch a HuggingFace Spaces demo of Moore-AnimateAnyone at &lt;a href=&#34;https://huggingface.co/spaces/xunsong/Moore-AnimateAnyone&#34;&gt;here&lt;/a&gt;!!&lt;/p&gt; &#xA;&lt;p&gt;This repository reproduces &lt;a href=&#34;https://github.com/HumanAIGC/AnimateAnyone&#34;&gt;AnimateAnyone&lt;/a&gt;. To align the results demonstrated by the original paper, we adopt various approaches and tricks, which may differ somewhat from the paper and another &lt;a href=&#34;https://github.com/guoqincode/Open-AnimateAnyone&#34;&gt;implementation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s worth noting that this is a very preliminary version, aiming for approximating the performance (roughly 80% under our test) showed in &lt;a href=&#34;https://github.com/HumanAIGC/AnimateAnyone&#34;&gt;AnimateAnyone&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We will continue to develop it, and also welcome feedbacks and ideas from the community. The enhanced version will also be launched on our &lt;a href=&#34;https://maliang.mthreads.com/&#34;&gt;MoBi MaLiang&lt;/a&gt; AIGC platform, running on our own full-featured GPU S4000 cloud computing platform.&lt;/p&gt; &#xA;&lt;h1&gt;üìù Release Plans&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Inference codes and pretrained weights&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Training scripts&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; The training code involves private data and packages. We will organize this portion of the code as soon as possible and then release it.&lt;/p&gt; &#xA;&lt;h1&gt;üéûÔ∏è Examples&lt;/h1&gt; &#xA;&lt;p&gt;Here are some results we generated, with the resolution of 512x768.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/MooreThreads/Moore-AnimateAnyone/assets/138439222/f0454f30-6726-4ad4-80a7-5b7a15619057&#34;&gt;https://github.com/MooreThreads/Moore-AnimateAnyone/assets/138439222/f0454f30-6726-4ad4-80a7-5b7a15619057&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/MooreThreads/Moore-AnimateAnyone/assets/138439222/337ff231-68a3-4760-a9f9-5113654acf48&#34;&gt;https://github.com/MooreThreads/Moore-AnimateAnyone/assets/138439222/337ff231-68a3-4760-a9f9-5113654acf48&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table class=&#34;center&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; style=&#34;border: none&#34;&gt; &#xA;    &lt;video controls autoplay loop src=&#34;https://github.com/MooreThreads/Moore-AnimateAnyone/assets/138439222/9c4d852e-0a99-4607-8d63-569a1f67a8d2&#34; muted=&#34;false&#34;&gt;&lt;/video&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; style=&#34;border: none&#34;&gt; &#xA;    &lt;video controls autoplay loop src=&#34;https://github.com/MooreThreads/Moore-AnimateAnyone/assets/138439222/722c6535-2901-4e23-9de9-501b22306ebd&#34; muted=&#34;false&#34;&gt;&lt;/video&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; style=&#34;border: none&#34;&gt; &#xA;    &lt;video controls autoplay loop src=&#34;https://github.com/MooreThreads/Moore-AnimateAnyone/assets/138439222/17b907cc-c97e-43cd-af18-b646393c8e8a&#34; muted=&#34;false&#34;&gt;&lt;/video&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; style=&#34;border: none&#34;&gt; &#xA;    &lt;video controls autoplay loop src=&#34;https://github.com/MooreThreads/Moore-AnimateAnyone/assets/138439222/86f2f6d2-df60-4333-b19b-4c5abcd5999d&#34; muted=&#34;false&#34;&gt;&lt;/video&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Limitation&lt;/strong&gt;: We observe following shortcomings in current version:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The background may occur some artifacts, when the reference image has a clean background&lt;/li&gt; &#xA; &lt;li&gt;Suboptimal results may arise when there is a scale mismatch between the reference image and keypoints. We have yet to implement preprocessing techniques as mentioned in the &lt;a href=&#34;https://arxiv.org/pdf/2311.17117.pdf&#34;&gt;paper&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Some flickering and jittering may occur when the motion sequence is subtle or the scene is static.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;These issues will be addressed and improved in the near future. We appreciate your anticipation!&lt;/p&gt; &#xA;&lt;h1&gt;‚öíÔ∏è Installation&lt;/h1&gt; &#xA;&lt;h2&gt;Build Environtment&lt;/h2&gt; &#xA;&lt;p&gt;We Recommend a python version &lt;code&gt;&amp;gt;=3.10&lt;/code&gt; and cuda version &lt;code&gt;=11.7&lt;/code&gt;. Then build environment as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# [Optional] Create a virtual env&#xA;python -m venv .venv&#xA;source .venv/bin/activate&#xA;# Install with pip:&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Download weights&lt;/h2&gt; &#xA;&lt;p&gt;Download our trained &lt;a href=&#34;https://huggingface.co/patrolli/AnimateAnyone/tree/main&#34;&gt;weights&lt;/a&gt;, which include four parts: &lt;code&gt;denoising_unet.pth&lt;/code&gt;, &lt;code&gt;reference_unet.pth&lt;/code&gt;, &lt;code&gt;pose_guider.pth&lt;/code&gt; and &lt;code&gt;motion_module.pth&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Download pretrained weight of based models and other components:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/runwayml/stable-diffusion-v1-5&#34;&gt;StableDiffusion V1.5&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/stabilityai/sd-vae-ft-mse&#34;&gt;sd-vae-ft-mse&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/lambdalabs/sd-image-variations-diffusers/tree/main/image_encoder&#34;&gt;image_encoder&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Download dwpose weights (&lt;code&gt;dw-ll_ucoco_384.onnx&lt;/code&gt;, &lt;code&gt;yolox_l.onnx&lt;/code&gt;) following &lt;a href=&#34;https://github.com/IDEA-Research/DWPose?tab=readme-ov-file#-dwpose-for-controlnet&#34;&gt;this&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Put these weights under a directory, like &lt;code&gt;./pretrained_weights&lt;/code&gt;, and orgnize them as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;./pretrained_weights/&#xA;|-- DWPose&#xA;|   |-- dw-ll_ucoco_384.onnx&#xA;|   `-- yolox_l.onnx&#xA;|-- image_encoder&#xA;|   |-- config.json&#xA;|   `-- pytorch_model.bin&#xA;|-- denoising_unet.pth&#xA;|-- motion_module.pth&#xA;|-- pose_guider.pth&#xA;|-- reference_unet.pth&#xA;|-- sd-vae-ft-mse&#xA;|   |-- config.json&#xA;|   |-- diffusion_pytorch_model.bin&#xA;|   `-- diffusion_pytorch_model.safetensors&#xA;`-- stable-diffusion-v1-5&#xA;    |-- feature_extractor&#xA;    |   `-- preprocessor_config.json&#xA;    |-- model_index.json&#xA;    |-- unet&#xA;    |   |-- config.json&#xA;    |   `-- diffusion_pytorch_model.bin&#xA;    `-- v1-inference.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: If you have installed some of the pretrained models, such as &lt;code&gt;StableDiffusion V1.5&lt;/code&gt;, you can specify their paths in the config file (e.g. &lt;code&gt;./config/prompts/animation.yaml&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;h1&gt;üöÄ Inference&lt;/h1&gt; &#xA;&lt;p&gt;Here is the cli command for running inference scripts:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m scripts.pose2vid --config ./configs/prompts/animation.yaml -W 512 -H 784 -L 64&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can refer the format of &lt;code&gt;animation.yaml&lt;/code&gt; to add your own reference images or pose videos. To convert the raw video into a pose video (keypoint sequence), you can run with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python tools/vid2pose.py --video_path /path/to/your/video.mp4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;üé® Gradio Demo&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;HuggingFace Demo&lt;/strong&gt;: We launch a quick preview demo of Moore-AnimateAnyone at &lt;a href=&#34;https://huggingface.co/spaces/xunsong/Moore-AnimateAnyone&#34;&gt;HuggingFace Spaces&lt;/a&gt;!! We appreciate the assistance provided by the HuggingFace team in setting up this demo.&lt;/p&gt; &#xA;&lt;p&gt;To reduce waiting time, we limit the size (width, height, and length) and inference steps when generating videos.&lt;/p&gt; &#xA;&lt;p&gt;If you have your own GPU resource (&amp;gt;= 16GB vram), you can run a local gradio app via following commands:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;python app.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üñåÔ∏è Try on Mobi MaLiang&lt;/h1&gt; &#xA;&lt;p&gt;We will launched this model on our &lt;a href=&#34;https://maliang.mthreads.com/&#34;&gt;MoBi MaLiang&lt;/a&gt; AIGC platform, running on our own full-featured GPU S4000 cloud computing platform. Mobi MaLiang has now integrated various AIGC applications and functionalities (e.g. text-to-image, controllable generation...). You can experience it by &lt;a href=&#34;https://maliang.mthreads.com/&#34;&gt;clicking this link&lt;/a&gt; or scanning the QR code bellow via WeChat!&lt;/p&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/MooreThreads/Moore-AnimateAnyone/master/assets/mini_program_maliang.png&#34; width=&#34;100&#xA;  &#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;‚öñÔ∏è Disclaimer&lt;/h1&gt; &#xA;&lt;p&gt;This project is intended for academic research, and we explicitly disclaim any responsibility for user-generated content. Users are solely liable for their actions while using the generative model. The project contributors have no legal affiliation with, nor accountability for, users&#39; behaviors. It is imperative to use the generative model responsibly, adhering to both ethical and legal standards.&lt;/p&gt; &#xA;&lt;h1&gt;üôèüèª Acknowledgements&lt;/h1&gt; &#xA;&lt;p&gt;We first thank the authors of &lt;a href=&#34;&#34;&gt;AnimateAnyone&lt;/a&gt;. Additionally, we would like to thank the contributors to the &lt;a href=&#34;https://github.com/magic-research/magic-animate&#34;&gt;majic-animate&lt;/a&gt;, &lt;a href=&#34;https://github.com/guoyww/AnimateDiff&#34;&gt;animatediff&lt;/a&gt; and &lt;a href=&#34;https://github.com/guoqincode/Open-AnimateAnyone&#34;&gt;Open-AnimateAnyone&lt;/a&gt; repositorities, for their open research and exploration. Furthermore, our repo incorporates some codes from &lt;a href=&#34;https://github.com/IDEA-Research/DWPose&#34;&gt;dwpose&lt;/a&gt; and &lt;a href=&#34;https://github.com/s9roll7/animatediff-cli-prompt-travel/&#34;&gt;animatediff-cli-prompt-travel&lt;/a&gt;, and we extend our thanks to them as well.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>TheCyb3rAlpha/BobTheSmuggler</title>
    <updated>2024-01-15T01:39:23Z</updated>
    <id>tag:github.com,2024-01-15:/TheCyb3rAlpha/BobTheSmuggler</id>
    <link href="https://github.com/TheCyb3rAlpha/BobTheSmuggler" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&#34;Bob the Smuggler&#34;: A tool that leverages HTML Smuggling Attack and allows you to create HTML files with embedded 7z/zip archives. The tool would compress your binary (EXE/DLL) into 7z/zip file format, then XOR encrypt the archive and then hides inside PNG/GIF image file format (Image Polyglots).&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;BobTheSmuggler&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/TheCyb3rAlpha/BobTheSmuggler/main/images/bob.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Update&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;Jan 15th, 2024 - &lt;strong&gt;Support for multi-file compression has been added&lt;/strong&gt;. If you have multiple files generated for your final payload (e.g., DLL-Sideloading files or multi-stage delivery files), you can now use the &#39;-i&#39; option to specify the directory path. If a directory path is provided, BobTheSmuggler will automatically archive all the files in that directory, XOR encrypt the archive, and embed it inside PNG/GIF.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Project Description&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;&#34;Bob the Smuggler&#34;&lt;/strong&gt; is a tool that leverages HTML Smuggling Attack and allows you to create HTML files with embedded 7z/zip archives. The tool would compress your binary (EXE/DLL) into 7z/zip file format, then XOR encrypt the archive and then hides inside PNG/GIF image file format (Image Polyglots). The JavaScript embedded within the HTML will download the PNG/GIF file and store it in the cache. Following this, the JavaScript will extract the data embedded in the PNG/GIF, assemble it, perform XOR decryption, and then store it as an in-memory blob.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://www.plantuml.com/plantuml/dpng/bP7BRzf04CRl_YkcbygSE5O2LQKonhIYJSGZoe7BuXt3IlkmPjSGyzTdRCSAIW0f5qlU-RxVFBw93u92PNJqBHpG81WHa9I8slSe6YqnHtL4I5ymhuBOQOIPua-SFgV3wM8n6BCeSQOaz1w-GsfpgilGYhOs_d4UdbK99nKEK0hlJuvaOr45n2rdveXRmazu_9yDW6Um4DVe1n70A3Kxb3qHPTTOsKRAw8rNTW-hW7jXtPv4UQYPZDhZPtZsPtQNoFKl4bTFsLqYrplhH-Dy_My1Zk21TwNRYAaYp8EkcTLQjfOzSs6bnixwHlJSnKfLS0ePMYGH4FwAerZbf3Y6nCac1jPoWe547fIp7DDlxz7iTDrdaLG-EDCDjqPJweQpyIX_NGtbiWKFUCtTRs_TJTiK2r7fqFg6VB0BRxzJGiZ_V18hzBkkkT2Ogyr3Twub2bb3uOYXMXsHQgxpK6KqOLHbz2i0&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This tool currently support the following payload Delivery Chains:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;.EXE/.DLL --&amp;gt; .7z/.Zip (Password Protected) --&amp;gt; .JS --&amp;gt; .HTML&lt;/li&gt; &#xA; &lt;li&gt;.EXE/.DLL --&amp;gt; .7z/.Zip (Password Protected) --&amp;gt; .JS --&amp;gt; .SVG --&amp;gt; .HTML&lt;/li&gt; &#xA; &lt;li&gt;.EXE/.DLL --&amp;gt; .7z/.Zip (Password Protected) --&amp;gt; .PNG/.GIF --&amp;gt; .JS --&amp;gt; .HTML&lt;/li&gt; &#xA; &lt;li&gt;.EXE/.DLL --&amp;gt; .7z/.Zip (Password Protected) --&amp;gt; .PNG/.GIF --&amp;gt; JS --&amp;gt; .SVG --&amp;gt; .HTML&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Stealthy File Concealment:&lt;/strong&gt; Embed any file type (EXE/DLL) securely within HTML pages, PNG, GIF, and SVG files, ensuring the data remains hidden in plain sight.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Versatile Embedding:&lt;/strong&gt; Offers the flexibility to embed files in various formats, catering to diverse needs and scenarios.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Advanced Obfuscation:&lt;/strong&gt; Utilizes sophisticated techniques to obfuscate the embedded data, further enhancing security and reducing detectability.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Custom Template Support:&lt;/strong&gt; Allows the use of custom HTML and SVG templates for embedding, providing personalized and context-specific concealment.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Intuitive Interface:&lt;/strong&gt; Features an easy-to-use command-line interface, making it accessible for both technical and non-technical users.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Visual Validation:&lt;/strong&gt; Includes visualization tools for PNG files, offering users a way to confirm the successful embedding of data.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Pre-requisites&lt;/h2&gt; &#xA;&lt;p&gt;Before running the tool, you need the following pre-requisites:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install python-magic py7zr pyminizip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; To install python-magic, you would need to install the libmagic library on your system. Follow this URL to install the libmagic library: &lt;a href=&#34;https://pypi.org/project/python-magic/&#34;&gt;https://pypi.org/project/python-magic/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Once the required libraries are installed, you can proceed with the installation of the tool using the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/TheCyb3rAlpha/BobTheSmuggler.git&#xA;cd BobTheSmuggler&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Once installed, you can use the tool by executing the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 BobTheSmuggler.py -h&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/TheCyb3rAlpha/BobTheSmuggler/main/images/usage.png&#34; alt=&#34;Usage&#34; title=&#34;usage&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;======================================================================&#xA;‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó&#xA;‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó    ‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù&#xA;‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù       ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó&#xA;‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó       ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù&#xA;‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù       ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó&#xA;‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù        ‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù&#xA;‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó&#xA;‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó&#xA;‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù&#xA;‚ïö‚ïê‚ïê‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó&#xA;‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïù ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë&#xA;‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù&#xA;======================================================================&#xA;&#xA;usage: BobTheSmuggler.py [-h] -i EXE_FILE [-p PASSWORD] -f OUTPUT_HTML -o OUTPUT_FILENAME -t {html,svg,png,gif} [-c {7z,zip}] [-u PNG_URL] [-png PNG_FILE] [-gif GIF_FILE] [-e CUSTOM_FILE] [-v]&#xA;&#xA;Hides EXE/DLL file inside an HTML/SVG file.&#xA;&#xA;optional arguments:&#xA;  -h, --help            show this help message and exit&#xA;  -i EXE_FILE           Path to the EXE/DLL file.&#xA;  -p PASSWORD           Password for compression.&#xA;  -f OUTPUT_HTML        HTML Smuggled file (.html)&#xA;  -o OUTPUT_FILENAME    Downloaded file name (Your payload is in this file.)&#xA;  -t {html,svg,png,gif} Type of embedded template.&#xA;  -c {7z,zip}           Compression format: 7z or zip (default: zip)&#xA;  -u PNG_URL            URL for the embedded PNG image.&#xA;  -png PNG_FILE         Path to the PNG file for embedding EXE/DLL.&#xA;  -gif GIF_FILE         Path to the GIF file for embedding EXE/DLL.&#xA;  -e CUSTOM_FILE        HTML file to clone as template.&#xA;  -v, --verbose         Enable verbose logging.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;If you want to compress SharpHound.exe into 7z format (password protected) and store it in a HTML file, you can use the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 BobTheSmuggler.py -i path/to/SharpHound.exe -p 123456 -c 7z -f SharpHound.html -o SharpHound.7z -t html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/TheCyb3rAlpha/BobTheSmuggler/main/images/bts_html.png&#34; alt=&#34;bts_html&#34; title=&#34;HTML Creation&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Embed payload inside PNG File:&lt;/h3&gt; &#xA;&lt;p&gt;To create an HTML file with the embedded payload hidden inside PNG file, you can use the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 BobTheSmuggler.py -i &amp;lt;Input_file_path&amp;gt; -p &amp;lt;password_to_encrypt&amp;gt; -f &amp;lt;output_HTML_filename&amp;gt; -o &amp;lt;Output 7z/zip filename stored inside HTML&amp;gt; -t png test.png&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/TheCyb3rAlpha/BobTheSmuggler/main/images/bts_png.png&#34; alt=&#34;bts_png&#34; title=&#34;PNG Creation&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Make sure you host the PNG/GIF files on a CDN. (Recommended: You should use the -u option to provide the CDN URL where you&#39;ll host the PNG/GIF file). For testing purpose, you can use the flask app (app.py) which would host banner.gif and banner.png on localhost:8000&lt;/p&gt; &#xA;&lt;p&gt;Similarly, you can use the following command to create an HTML file with the embedded payload hidden inside GIF file:&lt;/p&gt; &#xA;&lt;h3&gt;Embed payload inside GIF File:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 BobTheSmuggler.py -i &amp;lt;Input_file_path&amp;gt; -p &amp;lt;password_to_encrypt&amp;gt; -f &amp;lt;output_HTML_filename&amp;gt; -o &amp;lt;Output 7z/zip filename stored inside HTML&amp;gt; -t gif test.gif&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/TheCyb3rAlpha/BobTheSmuggler/main/images/bts_gif.png&#34; alt=&#34;bts_gif&#34; title=&#34;GIF Creation&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Once the final image (PNG/GIF) is generated, the size of the image will increase because it will contain your embedded file.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/TheCyb3rAlpha/BobTheSmuggler/main/images/bts_image.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;.EXE/.DLL --&amp;gt; .7z --&amp;gt; .PNG --&amp;gt; .SVG --&amp;gt; .HTML Chain:&lt;/h3&gt; &#xA;&lt;p&gt;A simple chain with a different approach. Your EXE/DLL gets compressed to .7z/.zip file, then it gets stored inside a PNG/GIF file. The PNG/GIF gets called by the JS inside the SVG file which is embedded inside HTML. Once the JS is called, it downloads PNG/ZIP file, extracts XOR&#39;d compressed data from the image chunks, decrypts the file and invokes the download functionality.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 BobTheSmuggler.py -i &amp;lt;Input_file_path&amp;gt; -p &amp;lt;password_to_encrypt&amp;gt; -f &amp;lt;output_HTML_filename&amp;gt; -o &amp;lt;Output 7z/zip filename stored inside HTML&amp;gt; -t svg -e &amp;lt;Custom_SVG_Template&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The Following Templates have been added to this project:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;OneDrive Download HTML Template (Used by BumbleBee malware delivery mechanism)&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Paypal Fake Invoice SVG Template (Used for callback phishing)&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/TheCyb3rAlpha/BobTheSmuggler/main/images/bts_templates.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This tool is intended solely for educational purposes. Users are advised to utilize it only in a manner that promotes learning and understanding. The author of this tool explicitly disclaims any liability for its use beyond educational contexts. Users choosing to employ this tool for purposes other than education do so at their own risk and responsibility, and the author shall not be held accountable for any consequences arising from such use.&lt;/p&gt;</summary>
  </entry>
</feed>