<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-02-11T01:36:24Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>browser-use/browser-use</title>
    <updated>2025-02-11T01:36:24Z</updated>
    <id>tag:github.com,2025-02-11:/browser-use/browser-use</id>
    <link href="https://github.com/browser-use/browser-use" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Make websites accessible for AI agents&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; &#xA; &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;./static/browser-use-dark.png&#34;&gt; &#xA; &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;./static/browser-use.png&#34;&gt; &#xA; &lt;img alt=&#34;Shows a black Browser Use Logo in light color mode and a white one in dark color mode.&#34; src=&#34;https://raw.githubusercontent.com/browser-use/browser-use/main/static/browser-use.png&#34; width=&#34;full&#34;&gt; &#xA;&lt;/picture&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt;Enable AI to control your browser ü§ñ&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/gregpr07/browser-use/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/gregpr07/browser-use?style=social&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://link.browser-use.com/discord&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1303749220842340412?color=7289DA&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.browser-use.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Documentation-%F0%9F%93%95-blue&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://cloud.browser-use.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Cloud-%E2%98%81%EF%B8%8F-blue&#34; alt=&#34;Cloud&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://x.com/gregpr07&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/Gregor?style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://x.com/mamagnus00&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/Magnus?style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.workweave.ai/reports/repository/org_T5Pvn3UBswTHIsN1dWS3voPg/881458615&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint?url=https%3A%2F%2Fapp.workweave.ai%2Fapi%2Frepository%2Fbadge%2Forg_T5Pvn3UBswTHIsN1dWS3voPg%2F881458615&amp;amp;labelColor=#EC6341&#34; alt=&#34;Weave Badge&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;üåê Browser-use is the easiest way to connect your AI agents with the browser.&lt;/p&gt; &#xA;&lt;p&gt;üí° See what others are building and share your projects in our &lt;a href=&#34;https://link.browser-use.com/discord&#34;&gt;Discord&lt;/a&gt; - we&#39;d love to see what you create!&lt;/p&gt; &#xA;&lt;p&gt;üå©Ô∏è Skip the setup - try our hosted version for instant browser automation! &lt;a href=&#34;https://cloud.browser-use.com&#34;&gt;Try it now&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Quick start&lt;/h1&gt; &#xA;&lt;p&gt;With pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install browser-use&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;install playwright:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;playwright install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Spin up your agent:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from langchain_openai import ChatOpenAI&#xA;from browser_use import Agent&#xA;import asyncio&#xA;from dotenv import load_dotenv&#xA;load_dotenv()&#xA;&#xA;async def main():&#xA;    agent = Agent(&#xA;        task=&#34;Go to Reddit, search for &#39;browser-use&#39;, click on the first post and return the first comment.&#34;,&#xA;        llm=ChatOpenAI(model=&#34;gpt-4o&#34;),&#xA;    )&#xA;    result = await agent.run()&#xA;    print(result)&#xA;&#xA;asyncio.run(main())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Add your API keys for the provider you want to use to your &lt;code&gt;.env&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;OPENAI_API_KEY=&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For other settings, models, and more, check out the &lt;a href=&#34;https://docs.browser-use.com&#34;&gt;documentation üìï&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Test with UI&lt;/h3&gt; &#xA;&lt;p&gt;You can test &lt;a href=&#34;https://github.com/browser-use/web-ui&#34;&gt;browser-use with a UI repository&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Or simply run the gradio example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;uv pip install gradio&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python examples/ui/gradio_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Demos&lt;/h1&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/browser-use/browser-use/raw/main/examples/use-cases/shopping.py&#34;&gt;Task&lt;/a&gt;: Add grocery items to cart, and checkout.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=L2Ya9PYNns8&#34;&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/d9359085-bde6-41d4-aa4e-6520d0221872&#34; alt=&#34;AI Did My Groceries&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;Prompt: Add my latest LinkedIn follower to my leads in Salesforce.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/1440affc-a552-442e-b702-d0d3b277b0ae&#34; alt=&#34;LinkedIn to Salesforce&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/browser-use/browser-use/raw/main/examples/use-cases/find_and_apply_to_jobs.py&#34;&gt;Prompt&lt;/a&gt;: Read my CV &amp;amp; find ML jobs, save them to a file, and then start applying for them in new tabs, if you need help, ask me.&#39;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/171fb4d6-0355-46f2-863e-edb04a828d04&#34;&gt;https://github.com/user-attachments/assets/171fb4d6-0355-46f2-863e-edb04a828d04&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/browser-use/browser-use/raw/main/examples/browser/real_browser.py&#34;&gt;Prompt&lt;/a&gt;: Write a letter in Google Docs to my Papa, thanking him for everything, and save the document as a PDF.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/242ade3e-15bc-41c2-988f-cbc5415a66aa&#34; alt=&#34;Letter to Papa&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/browser-use/browser-use/raw/main/examples/custom-functions/save_to_file_hugging_face.py&#34;&gt;Prompt&lt;/a&gt;: Look up models with a license of cc-by-sa-4.0 and sort by most likes on Hugging face, save top 5 to file.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/de73ee39-432c-4b97-b4e8-939fd7f323b3&#34;&gt;https://github.com/user-attachments/assets/de73ee39-432c-4b97-b4e8-939fd7f323b3&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;More examples&lt;/h2&gt; &#xA;&lt;p&gt;For more examples see the &lt;a href=&#34;https://raw.githubusercontent.com/browser-use/browser-use/main/examples&#34;&gt;examples&lt;/a&gt; folder or join the &lt;a href=&#34;https://link.browser-use.com/discord&#34;&gt;Discord&lt;/a&gt; and show off your project.&lt;/p&gt; &#xA;&lt;h1&gt;Vision&lt;/h1&gt; &#xA;&lt;p&gt;Tell your computer what to do, and it gets it done.&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Improve memory management&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Enhance planning capabilities&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Improve self-correction&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Fine-tune the model for better performance&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Create datasets for complex tasks&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Sandbox browser-use for specific websites&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Implement deterministic script rerun with LLM fallback&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Cloud-hosted version&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add stop/pause functionality&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Improve authentication handling&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Reduce token consumption&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Implement long-term memory&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Handle repetitive tasks reliably&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Third-party integrations (Slack, etc.)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Include more interactive elements&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Human-in-the-loop execution&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Benchmark various models against each other&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Let the user record a workflow and browser-use will execute it&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Improve the generated GIF quality&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Create various demos for tutorial execution, job application, QA testing, social media, etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We love contributions! Feel free to open issues for bugs or feature requests. To contribute to the docs, check out the &lt;code&gt;/docs&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;h2&gt;Local Setup&lt;/h2&gt; &#xA;&lt;p&gt;To learn more about the library, check out the &lt;a href=&#34;https://docs.browser-use.com/development/local-setup&#34;&gt;local setup üìï&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Cooperations&lt;/h2&gt; &#xA;&lt;p&gt;We are forming a commission to define best practices for UI/UX design for browser agents. Together, we&#39;re exploring how software redesign improves the performance of AI agents and gives these companies a competitive advantage by designing their existing software to be at the forefront of the agent age.&lt;/p&gt; &#xA;&lt;p&gt;Email &lt;a href=&#34;mailto:tbiddle@loop11.com?subject=I%20want%20to%20join%20the%20UI/UX%20commission%20for%20AI%20agents&amp;amp;body=Hi%20Toby%2C%0A%0AI%20found%20you%20in%20the%20browser-use%20GitHub%20README.%0A%0A&#34;&gt;Toby&lt;/a&gt; to apply for a seat on the committee.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you use Browser Use in your research or project, please cite:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@software{browser_use2024,&#xA;  author = {M√ºller, Magnus and ≈Ωuniƒç, Gregor},&#xA;  title = {Browser Use: Enable AI to control your browser},&#xA;  year = {2024},&#xA;  publisher = {GitHub},&#xA;  url = {https://github.com/browser-use/browser-use}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/402b2129-b6ac-44d3-a217-01aea3277dce&#34; width=&#34;400&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://x.com/gregpr07&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/Gregor?style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://x.com/mamagnus00&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/Magnus?style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA;  Made with ‚ù§Ô∏è in Zurich and San Francisco &#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>homarr-labs/dashboard-icons</title>
    <updated>2025-02-11T01:36:24Z</updated>
    <id>tag:github.com,2025-02-11:/homarr-labs/dashboard-icons</id>
    <link href="https://github.com/homarr-labs/dashboard-icons" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The best source for dashboard icons.&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; &#xA; &lt;p&gt;[!WARNING] The repository has been migrated from &lt;code&gt;walkxcode&lt;/code&gt; to &lt;code&gt;homarr-labs&lt;/code&gt;, because I do not have the capacity/time to keep maintaining it. The Homarr team will take over all management and maintenance, whilst keeping all functionality for you, the user, the same. The project will always be usable outside of Homarr itself and breaking changes will not be made. ^Bjorn&lt;/p&gt; &#xA; &lt;p&gt;The license and guidelines have changed, so please review them. If you want to help with maintenance, reach out to &lt;a href=&#34;mailto:homarr-labs@proton.me&#34;&gt;homarr-labs@proton.me&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.jsdelivr.com/package/gh/homarr-labs/dashboard-icons&#34;&gt;&lt;img src=&#34;https://img.shields.io/jsdelivr/gh/hy/homarr-labs/dashboard-icons?style=flat-square&amp;amp;color=%23A020F0&#34; alt=&#34;jsDelivr hits (GitHub)&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.jsdelivr.com/package/gh/walkxcode/dashboard-icons&#34;&gt;&lt;img src=&#34;https://img.shields.io/jsdelivr/gh/hy/walkxcode/dashboard-icons?style=flat-square&amp;amp;color=%23A020F0&#34; alt=&#34;jsDelivr hits (GitHub)&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Dashboard Icons&lt;/h2&gt; &#xA;&lt;p&gt;The best source for dashboard icons.&lt;br&gt; &lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/ICONS.md&#34;&gt;&lt;strong&gt;View icons ‚Üí&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/#dashboard-icons&#34;&gt;Dashboard Icons&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/#table-of-contents&#34;&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/#icon-requests&#34;&gt;Icon Requests&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/#supported-dashboards&#34;&gt;Supported Dashboards&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/#usage-and-details&#34;&gt;Usage and Details&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/#direct-links&#34;&gt;Direct Links&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/#base-url&#34;&gt;Base URL&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/#name&#34;&gt;Name&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/#formats&#34;&gt;Formats&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/#darklight-versions&#34;&gt;Dark/Light Versions&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/#downloading-icons&#34;&gt;Downloading Icons&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/#disclaimer&#34;&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Icon Requests&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;re looking to add a new icon, please read the &lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/CONTRIBUTING.md&#34;&gt;Contribution Guidelines&lt;/a&gt;. Afterwards, submit a Pull Request or open an issue.&lt;/p&gt; &#xA;&lt;h2&gt;Supported Dashboards&lt;/h2&gt; &#xA;&lt;p&gt;Several dashboards offer seamless integration with Dashboard Icons. Here are some of the most popular options:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ajnart/homarr&#34;&gt;Homarr&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gethomepage/homepage&#34;&gt;Homepage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Lissy93/dashy&#34;&gt;Dashy&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage and Details&lt;/h2&gt; &#xA;&lt;h3&gt;Direct Links&lt;/h3&gt; &#xA;&lt;p&gt;Icons can be used directly from either GitHub or jsDelivr (recommended). Links consist of three components, each described below:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Base URL&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Name&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Format&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;A complete link will look like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;https://&amp;lt;Base URL&amp;gt;/&amp;lt;Format&amp;gt;/&amp;lt;Name&amp;gt;.&amp;lt;Format&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For example, the icon URL for the WEBP version of Nextcloud Calendar would be:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;https://cdn.jsdelivr.net/gh/homarr-labs/dashboard-icons/webp/nextcloud-calendar.webp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Base URL&lt;/h4&gt; &#xA;&lt;p&gt;We recommend using jsDelivr, a free and fast CDN:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;https://cdn.jsdelivr.net/gh/homarr-labs/dashboard-icons&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Alternatively, you can use direct links to the repository:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/refs/heads/main&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Name&lt;/h4&gt; &#xA;&lt;p&gt;Icons are named using kebab case (lowercase words separated by hyphens). For example, &#34;Nextcloud Calendar&#34; becomes &lt;code&gt;nextcloud-calendar&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Formats&lt;/h4&gt; &#xA;&lt;p&gt;Icons are available in the following formats:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;SVG&lt;/li&gt; &#xA; &lt;li&gt;PNG&lt;/li&gt; &#xA; &lt;li&gt;WEBP&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All icons are generated from the SVG file as the base.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Read more about the specifics and standards of icons in the &lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/CONTRIBUTING.md&#34;&gt;Contribution Guidelines&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Dark/Light Versions&lt;/h3&gt; &#xA;&lt;p&gt;In some cases, an icon might have very light or dark colors, making it hard to see on certain backgrounds. In this situation, a &lt;code&gt;-light&lt;/code&gt; or &lt;code&gt;-dark&lt;/code&gt; version will be added to the end of the icon&#39;s name, with colors adjusted accordingly.&lt;/p&gt; &#xA;&lt;p&gt;For example, &#34;2fauth&#34; becomes &lt;code&gt;2fauth-light&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Read more about the specifics and standards of icons in the &lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/CONTRIBUTING.md&#34;&gt;Contribution Guidelines&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Downloading Icons&lt;/h3&gt; &#xA;&lt;p&gt;To download icons from the &lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/ICONS.md&#34;&gt;icons page&lt;/a&gt;, simply Right-click the icon link and select &#34;Save link as&#34;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: Visiting the icons page will load every icon in the repository. This may result in:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;High data usage.&lt;/li&gt; &#xA; &lt;li&gt;System slowdowns.&lt;/li&gt; &#xA; &lt;li&gt;Browser crashes on some devices.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you prefer not to load all icons at once, consider using the direct links or downloading icons individually.&lt;/p&gt; &#xA;&lt;p&gt;To download icons using the terminal, use &lt;code&gt;curl&lt;/code&gt; or &lt;code&gt;wget&lt;/code&gt;. Refer to &lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/#direct-links&#34;&gt;Direct Links&lt;/a&gt; for details on the link structure.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl -O https://&amp;lt;Base URL&amp;gt;/&amp;lt;Format&amp;gt;/&amp;lt;Name&amp;gt;.&amp;lt;Format&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;wget https://&amp;lt;Base URL&amp;gt;/&amp;lt;Format&amp;gt;/&amp;lt;Name&amp;gt;.&amp;lt;Format&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;Unless otherwise indicated, all images and assets in this repository, including product names, trademarks, and registered trademarks, are the property of their respective owners. These images and assets are used for identification purposes only, and their use does not imply endorsement.&lt;/p&gt; &#xA;&lt;p&gt;Read the &lt;a href=&#34;https://raw.githubusercontent.com/homarr-labs/dashboard-icons/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for more information about the project itself. For questions or concerns, contact us at &lt;a href=&#34;mailto:homarr-labs@proton.me&#34;&gt;homarr-labs@proton.me&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>SWivid/F5-TTS</title>
    <updated>2025-02-11T01:36:24Z</updated>
    <id>tag:github.com,2025-02-11:/SWivid/F5-TTS</id>
    <link href="https://github.com/SWivid/F5-TTS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official code for &#34;F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching&#34;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/SWivid/F5-TTS&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-3.10-brightgreen&#34; alt=&#34;python&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2410.06885&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2410.06885-b31b1b.svg?logo=arXiv&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://swivid.github.io/F5-TTS/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-Demo%20page-orange.svg?sanitize=true&#34; alt=&#34;demo&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/mrfakename/E2-F5-TTS&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97-Space%20demo-yellow&#34; alt=&#34;hfspace&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://modelscope.cn/studios/modelscope/E2-F5-TTS&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%96-Space%20demo-blue&#34; alt=&#34;msspace&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://x-lance.sjtu.edu.cn/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/X--LANCE-Lab-grey?labelColor=lightgrey&#34; alt=&#34;lab&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.pcl.ac.cn&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Peng%20Cheng-Lab-grey?labelColor=lightgrey&#34; alt=&#34;lab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- &lt;img src=&#34;https://github.com/user-attachments/assets/12d7749c-071a-427c-81bf-b87b91def670&#34; alt=&#34;Watermark&#34; style=&#34;width: 40px; height: auto&#34;&gt; --&gt; &#xA;&lt;p&gt;&lt;strong&gt;F5-TTS&lt;/strong&gt;: Diffusion Transformer with ConvNeXt V2, faster trained and inference.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;E2 TTS&lt;/strong&gt;: Flat-UNet Transformer, closest reproduction from &lt;a href=&#34;https://arxiv.org/abs/2406.18009&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Sway Sampling&lt;/strong&gt;: Inference-time flow step sampling strategy, greatly improves performance&lt;/p&gt; &#xA;&lt;h3&gt;Thanks to all the contributors !&lt;/h3&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;2024/10/08&lt;/strong&gt;: F5-TTS &amp;amp; E2 TTS base models on &lt;a href=&#34;https://huggingface.co/SWivid/F5-TTS&#34;&gt;ü§ó Hugging Face&lt;/a&gt;, &lt;a href=&#34;https://www.modelscope.cn/models/SWivid/F5-TTS_Emilia-ZH-EN&#34;&gt;ü§ñ Model Scope&lt;/a&gt;, &lt;a href=&#34;https://wisemodel.cn/models/SJTU_X-LANCE/F5-TTS_Emilia-ZH-EN&#34;&gt;üü£ Wisemodel&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Create a python 3.10 conda env (you could also use virtualenv)&#xA;conda create -n f5-tts python=3.10&#xA;conda activate f5-tts&#xA;&#xA;# NVIDIA GPU: install pytorch with your CUDA version, e.g.&#xA;pip install torch==2.3.0+cu118 torchaudio==2.3.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118&#xA;&#xA;# AMD GPU: install pytorch with your ROCm version, e.g. (Linux only)&#xA;pip install torch==2.5.1+rocm6.2 torchaudio==2.5.1+rocm6.2 --extra-index-url https://download.pytorch.org/whl/rocm6.2&#xA;&#xA;# Intel GPU: install pytorch with your XPU version, e.g.&#xA;# Intel¬Æ Deep Learning Essentials or Intel¬Æ oneAPI Base Toolkit must be installed&#xA;pip install --pre torch torchaudio --index-url https://download.pytorch.org/whl/nightly/xpu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then you can choose from a few options below:&lt;/p&gt; &#xA;&lt;h3&gt;1. As a pip package (if just for inference)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install git+https://github.com/SWivid/F5-TTS.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Local editable (if also do training, finetuning)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/SWivid/F5-TTS.git&#xA;cd F5-TTS&#xA;# git submodule update --init --recursive  # (optional, if need bigvgan)&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. Docker usage&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Build from Dockerfile&#xA;docker build -t f5tts:v1 .&#xA;&#xA;# Or pull from GitHub Container Registry&#xA;docker pull ghcr.io/swivid/f5-tts:main&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;h3&gt;1. Gradio App&lt;/h3&gt; &#xA;&lt;p&gt;Currently supported features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Basic TTS with Chunk Inference&lt;/li&gt; &#xA; &lt;li&gt;Multi-Style / Multi-Speaker Generation&lt;/li&gt; &#xA; &lt;li&gt;Voice Chat powered by Qwen2.5-3B-Instruct&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/SWivid/F5-TTS/main/src/f5_tts/infer/SHARED.md&#34;&gt;Custom inference with more language support&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Launch a Gradio app (web interface)&#xA;f5-tts_infer-gradio&#xA;&#xA;# Specify the port/host&#xA;f5-tts_infer-gradio --port 7860 --host 0.0.0.0&#xA;&#xA;# Launch a share link&#xA;f5-tts_infer-gradio --share&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. CLI Inference&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Run with flags&#xA;# Leave --ref_text &#34;&#34; will have ASR model transcribe (extra GPU memory usage)&#xA;f5-tts_infer-cli \&#xA;--model &#34;F5-TTS&#34; \&#xA;--ref_audio &#34;ref_audio.wav&#34; \&#xA;--ref_text &#34;The content, subtitle or transcription of reference audio.&#34; \&#xA;--gen_text &#34;Some text you want TTS model generate for you.&#34;&#xA;&#xA;# Run with default setting. src/f5_tts/infer/examples/basic/basic.toml&#xA;f5-tts_infer-cli&#xA;# Or with your own .toml file&#xA;f5-tts_infer-cli -c custom.toml&#xA;&#xA;# Multi voice. See src/f5_tts/infer/README.md&#xA;f5-tts_infer-cli -c src/f5_tts/infer/examples/multi/story.toml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. More instructions&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;In order to have better generation results, take a moment to read &lt;a href=&#34;https://raw.githubusercontent.com/SWivid/F5-TTS/main/src/f5_tts/infer&#34;&gt;detailed guidance&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://github.com/SWivid/F5-TTS/issues?q=is%3Aissue&#34;&gt;Issues&lt;/a&gt; are very useful, please try to find the solution by properly searching the keywords of problem encountered. If no answer found, then feel free to open an issue.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;h3&gt;1. Gradio App&lt;/h3&gt; &#xA;&lt;p&gt;Read &lt;a href=&#34;https://raw.githubusercontent.com/SWivid/F5-TTS/main/src/f5_tts/train&#34;&gt;training &amp;amp; finetuning guidance&lt;/a&gt; for more instructions.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Quick start with Gradio web interface&#xA;f5-tts_finetune-gradio&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/SWivid/F5-TTS/main/src/f5_tts/eval&#34;&gt;Evaluation&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;p&gt;Use pre-commit to ensure code quality (will run linters and formatters automatically)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install pre-commit&#xA;pre-commit install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When making a pull request, before each commit, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pre-commit run --all-files&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: Some model components have linting exceptions for E722 to accommodate tensor notation&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2406.18009&#34;&gt;E2-TTS&lt;/a&gt; brilliant work, simple and effective&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2407.05361&#34;&gt;Emilia&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2406.05763&#34;&gt;WenetSpeech4TTS&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/1904.02882&#34;&gt;LibriTTS&lt;/a&gt;, &lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34;&gt;LJSpeech&lt;/a&gt; valuable datasets&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lucidrains&#34;&gt;lucidrains&lt;/a&gt; initial CFM structure with also &lt;a href=&#34;https://github.com/bfs18&#34;&gt;bfs18&lt;/a&gt; for discussion&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2403.03206&#34;&gt;SD3&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://github.com/huggingface/diffusers&#34;&gt;Hugging Face diffusers&lt;/a&gt; DiT and MMDiT code structure&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rtqichen/torchdiffeq&#34;&gt;torchdiffeq&lt;/a&gt; as ODE solver, &lt;a href=&#34;https://huggingface.co/charactr/vocos-mel-24khz&#34;&gt;Vocos&lt;/a&gt; and &lt;a href=&#34;https://github.com/NVIDIA/BigVGAN&#34;&gt;BigVGAN&lt;/a&gt; as vocoder&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/FunASR&#34;&gt;FunASR&lt;/a&gt;, &lt;a href=&#34;https://github.com/SYSTRAN/faster-whisper&#34;&gt;faster-whisper&lt;/a&gt;, &lt;a href=&#34;https://github.com/microsoft/UniSpeech&#34;&gt;UniSpeech&lt;/a&gt;, &lt;a href=&#34;https://github.com/tarepan/SpeechMOS&#34;&gt;SpeechMOS&lt;/a&gt; for evaluation tools&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MahmoudAshraf97/ctc-forced-aligner&#34;&gt;ctc-forced-aligner&lt;/a&gt; for speech edit test&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://x.com/realmrfakename&#34;&gt;mrfakename&lt;/a&gt; huggingface space demo ~&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lucasnewman/f5-tts-mlx/tree/main&#34;&gt;f5-tts-mlx&lt;/a&gt; Implementation with MLX framework by &lt;a href=&#34;https://github.com/lucasnewman&#34;&gt;Lucas Newman&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/DakeQQ/F5-TTS-ONNX&#34;&gt;F5-TTS-ONNX&lt;/a&gt; ONNX Runtime version by &lt;a href=&#34;https://github.com/DakeQQ&#34;&gt;DakeQQ&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If our work and codebase is useful for you, please cite as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{chen-etal-2024-f5tts,&#xA;      title={F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching}, &#xA;      author={Yushen Chen and Zhikang Niu and Ziyang Ma and Keqi Deng and Chunhui Wang and Jian Zhao and Kai Yu and Xie Chen},&#xA;      journal={arXiv preprint arXiv:2410.06885},&#xA;      year={2024},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Our code is released under MIT License. The pre-trained models are licensed under the CC-BY-NC license due to the training data Emilia, which is an in-the-wild dataset. Sorry for any inconvenience this may cause.&lt;/p&gt;</summary>
  </entry>
</feed>