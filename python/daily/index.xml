<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-15T01:40:56Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Bing-su/adetailer</title>
    <updated>2023-05-15T01:40:56Z</updated>
    <id>tag:github.com,2023-05-15:/Bing-su/adetailer</id>
    <link href="https://github.com/Bing-su/adetailer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Auto detecting, masking and inpainting with detection model.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;!After Detailer&lt;/h1&gt; &#xA;&lt;p&gt;!After Detailer is a extension for stable diffusion webui, similar to Detection Detailer, except it uses ultralytics instead of the mmdet.&lt;/p&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;(from Mikubill/sd-webui-controlnet)&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open &#34;Extensions&#34; tab.&lt;/li&gt; &#xA; &lt;li&gt;Open &#34;Install from URL&#34; tab in the tab.&lt;/li&gt; &#xA; &lt;li&gt;Enter &lt;code&gt;https://github.com/Bing-su/adetailer.git&lt;/code&gt; to &#34;URL for extension&#39;s git repository&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Press &#34;Install&#34; button.&lt;/li&gt; &#xA; &lt;li&gt;Wait 5 seconds, and you will see the message &#34;Installed into stable-diffusion-webui\extensions\adetailer. Use Installed tab to restart&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Go to &#34;Installed&#34; tab, click &#34;Check for updates&#34;, and then click &#34;Apply and restart UI&#34;. (The next time you can also use this method to update extensions.)&lt;/li&gt; &#xA; &lt;li&gt;Completely restart A1111 webui including your terminal. (If you do not know what is a &#34;terminal&#34;, you can reboot your computer: turn your computer off and turn it on again.)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You &lt;strong&gt;DON&#39;T&lt;/strong&gt; need to download any model from huggingface.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;It&#39;s auto detecting, masking, and inpainting tool.&lt;/p&gt; &#xA;&lt;p&gt;So some options correspond to options on the inpaint tab.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/Bm7YLEA.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Other options:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Option&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ADetailer model&lt;/td&gt; &#xA;   &lt;td&gt;Determine what to detect.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&amp;nbsp;= disable&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ADetailer prompt,&amp;nbsp;negative prompt&lt;/td&gt; &#xA;   &lt;td&gt;Prompts and negative prompts to apply&lt;/td&gt; &#xA;   &lt;td&gt;If left blank, it will use the same as the input.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Detection model confidence threshold %&lt;/td&gt; &#xA;   &lt;td&gt;Only objects with a detection model confidence above this threshold are used for inpainting.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mask erosion (-) / dilation (+)&lt;/td&gt; &#xA;   &lt;td&gt;Enlarge or reduce the detected mask.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.opencv.org/4.7.0/db/df6/tutorial_erosion_dilatation.html&#34;&gt;opencv example&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mask x, y offset&lt;/td&gt; &#xA;   &lt;td&gt;Moves the mask horizontally and vertically by pixels.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;ControlNet Inpainting&lt;/h2&gt; &#xA;&lt;p&gt;You can use the ControlNet inpaint extension if you have ControlNet installed and a ControlNet inpaint model.&lt;/p&gt; &#xA;&lt;p&gt;On the ControlNet tab, select a ControlNet inpaint model and set the model weights.&lt;/p&gt; &#xA;&lt;h2&gt;Model&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Target&lt;/th&gt; &#xA;   &lt;th&gt;mAP 50&lt;/th&gt; &#xA;   &lt;th&gt;mAP 50-95&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;face_yolov8n.pt&lt;/td&gt; &#xA;   &lt;td&gt;2D / realistic face&lt;/td&gt; &#xA;   &lt;td&gt;0.660&lt;/td&gt; &#xA;   &lt;td&gt;0.366&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;face_yolov8s.pt&lt;/td&gt; &#xA;   &lt;td&gt;2D / realistic face&lt;/td&gt; &#xA;   &lt;td&gt;0.713&lt;/td&gt; &#xA;   &lt;td&gt;0.404&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mediapipe_face_full&lt;/td&gt; &#xA;   &lt;td&gt;realistic face&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mediapipe_face_short&lt;/td&gt; &#xA;   &lt;td&gt;realistic face&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;hand_yolov8n.pt&lt;/td&gt; &#xA;   &lt;td&gt;2D / realistic hand&lt;/td&gt; &#xA;   &lt;td&gt;0.767&lt;/td&gt; &#xA;   &lt;td&gt;0.505&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;person_yolov8n-seg.pt&lt;/td&gt; &#xA;   &lt;td&gt;2D / realistic person&lt;/td&gt; &#xA;   &lt;td&gt;0.782 (bbox)&lt;br&gt;0.761 (mask)&lt;/td&gt; &#xA;   &lt;td&gt;0.555 (bbox)&lt;br&gt;0.460 (mask)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;person_yolov8s-seg.pt&lt;/td&gt; &#xA;   &lt;td&gt;2D / realistic person&lt;/td&gt; &#xA;   &lt;td&gt;0.824 (bbox)&lt;br&gt;0.809 (mask)&lt;/td&gt; &#xA;   &lt;td&gt;0.605 (bbox)&lt;br&gt;0.508 (mask)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The yolo models can be found on huggingface &lt;a href=&#34;https://huggingface.co/Bingsu/adetailer&#34;&gt;Bingsu/adetailer&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;User Model&lt;/h3&gt; &#xA;&lt;p&gt;Put your &lt;a href=&#34;https://github.com/ultralytics/ultralytics&#34;&gt;ultralytics&lt;/a&gt; model in &lt;code&gt;webui/models/adetailer&lt;/code&gt;. The model name should end with &lt;code&gt;.pt&lt;/code&gt; or &lt;code&gt;.pth&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;It must be a bbox detection or segment model and use all label.&lt;/p&gt; &#xA;&lt;h3&gt;Dataset&lt;/h3&gt; &#xA;&lt;p&gt;Datasets used for training the yolo models are:&lt;/p&gt; &#xA;&lt;h4&gt;Face&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://universe.roboflow.com/my-workspace-mph8o/anime-face-createml&#34;&gt;Anime Face CreateML&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://universe.roboflow.com/0oooooo0/xml2txt-njqx1&#34;&gt;xml2txt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://universe.roboflow.com/sed-b8vkf/an-lfg5i&#34;&gt;AN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://shuoyang1213.me/WIDERFACE/index.html&#34;&gt;wider face&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Hand&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://universe.roboflow.com/1-yshhi/anhdet&#34;&gt;AnHDet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://universe.roboflow.com/catwithawand/hand-detection-fuao9&#34;&gt;hand-detection-fuao9&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Person&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cocodataset.org/#home&#34;&gt;coco2017&lt;/a&gt; (only person)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jerryli27/AniSeg&#34;&gt;AniSeg&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/skytnt/anime-segmentation&#34;&gt;skytnt/anime-segmentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/38RSxSO.png&#34; alt=&#34;image&#34;&gt; &lt;img src=&#34;https://i.imgur.com/2CYgjLx.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ko-fi.com/F1F1L7V2N&#34;&gt;&lt;img src=&#34;https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true&#34; alt=&#34;ko-fi&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Gioman101/FlipperAmiibo</title>
    <updated>2023-05-15T01:40:56Z</updated>
    <id>tag:github.com,2023-05-15:/Gioman101/FlipperAmiibo</id>
    <link href="https://github.com/Gioman101/FlipperAmiibo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Made to be used with Flipper just drag the folder into NFC&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FlipperAmiibo&lt;/h1&gt; &#xA;&lt;p&gt;A collection of FlipperZero NFC files that emulate Amiibo&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Gioman101/FlipperAmiibo/archive/refs/heads/main.zip&#34;&gt;Download&lt;/a&gt; this repository as an archive&lt;/li&gt; &#xA; &lt;li&gt;Extract the archive into the &lt;code&gt;nfc&lt;/code&gt; directory on your Flipper&#39;s SD card.&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>openai/plugins-quickstart</title>
    <updated>2023-05-15T01:40:56Z</updated>
    <id>tag:github.com,2023-05-15:/openai/plugins-quickstart</id>
    <link href="https://github.com/openai/plugins-quickstart" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Get a ChatGPT plugin up and running in under 5 minutes!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGPT plugins quickstart&lt;/h1&gt; &#xA;&lt;p&gt;Get a todo list ChatGPT plugin up and running in under 5 minutes using Python. If you do not already have plugin developer access, please &lt;a href=&#34;https://openai.com/waitlist/plugins&#34;&gt;join the waitlist&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;To install the required packages for this plugin, run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run the plugin, enter the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once the local server is running:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Navigate to &lt;a href=&#34;https://chat.openai.com&#34;&gt;https://chat.openai.com&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;In the Model drop down, select &#34;Plugins&#34; (note, if you don&#39;t see it there, you don&#39;t have access yet).&lt;/li&gt; &#xA; &lt;li&gt;Select &#34;Plugin store&#34;&lt;/li&gt; &#xA; &lt;li&gt;Select &#34;Develop your own plugin&#34;&lt;/li&gt; &#xA; &lt;li&gt;Enter in &lt;code&gt;localhost:5003&lt;/code&gt; since this is the URL the server is running on locally, then select &#34;Find manifest file&#34;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The plugin should now be installed and enabled! You can start with a question like &#34;What is on my todo list&#34; and then try adding something to it as well!&lt;/p&gt; &#xA;&lt;h2&gt;Getting help&lt;/h2&gt; &#xA;&lt;p&gt;If you run into issues or have questions building a plugin, please join our &lt;a href=&#34;https://community.openai.com/c/chat-plugins/20&#34;&gt;Developer community forum&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>