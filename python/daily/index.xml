<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-10-26T01:38:04Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>TheLastBen/fast-stable-diffusion</title>
    <updated>2022-10-26T01:38:04Z</updated>
    <id>tag:github.com,2022-10-26:/TheLastBen/fast-stable-diffusion</id>
    <link href="https://github.com/TheLastBen/fast-stable-diffusion" rel="alternate"></link>
    <summary type="html">&lt;p&gt;fast-stable-diffusion, +25-50% speed increase + memory efficient + DreamBooth&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;fast-stable-diffusion colabs, +25-50% speed increase + memory efficient + DreamBooth&lt;/h1&gt; &#xA;&lt;p&gt;2 Colab adaptations for both hlky and AUTOMATIC1111 Webuis of stable diffusion, implementing the optimization suggested by &lt;a href=&#34;https://github.com/MatthieuTPHR&#34;&gt;https://github.com/MatthieuTPHR&lt;/a&gt; : &lt;a href=&#34;https://github.com/huggingface/diffusers/pull/532&#34;&gt;https://github.com/huggingface/diffusers/pull/532&lt;/a&gt;, using the MemoryEfficientAttention implementation from xformers (cc. @fmassa, @danthe3rd, @blefaudeux) to both speedup the cross-attention speed and decrease its GPU memory requirements.&lt;/p&gt; &#xA;&lt;p&gt;All you have to do is enter your huggingface token only once and you&#39;re all set, the colabs will install the repos and the models inside Gdrive, so the loading will be fast everytime you use it, enjoy !!&lt;/p&gt; &#xA;&lt;center&gt;&#xA; &lt;b&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;AUTOMATIC1111 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;HLKY &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; Relaxed mode &lt;br&gt; &lt;a href=&#34;https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast_stable_diffusion_AUTOMATIC1111.ipynb&#34;&gt; &lt;img src=&#34;https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/1.jpg&#34;&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast_stable_diffusion_hlky.ipynb&#34;&gt; &lt;img src=&#34;https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/2.jpg&#34;&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&#34;https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast_stable_diffusion_relaxed.ipynb&#34;&gt; &lt;img src=&#34;https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/3.jpg&#34;&gt;&lt;/a&gt;&lt;/b&gt; &#xA; &lt;p&gt;If you encounter any issue or you want to update to latest webui version, remove the folder &#34;sd&#34; or &#34;stable-diffusion-webui&#34; from your GDrive (and GDrive trash) and rerun the colab.&lt;/p&gt; &#xA; &lt;h1&gt;fast-dreambooth colab, simple and easy to use&lt;/h1&gt; &#xA; &lt;p&gt;Train your model using this easy simple and fast colab, all you have to do is enter you huggingface token once, and it will cache all the files in GDrive, including the trained model and you will be able to use it directly from the colab, make sure you use high quality reference pictures for the training. Thanks to &lt;a href=&#34;https://github.com/jachiam&#34;&gt;https://github.com/jachiam&lt;/a&gt; for his diffusers to CKPT &lt;a href=&#34;https://gist.github.com/jachiam/8a5c0b607e38fcc585168b90c686eb05&#34;&gt;script&lt;/a&gt;, the trained models now can now be used in SD WEBUI from AUTOMATIC1111 and hlky and others.&lt;/p&gt; &#xA; &lt;p&gt;&lt;b&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;DreamBooth&lt;br&gt;&lt;/b&gt;&lt;/p&gt;&#xA; &lt;b&gt; &lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb&#34;&gt; &lt;img src=&#34;https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/4.jpg&#34;&gt;&lt;/a&gt; &lt;/p&gt; &lt;/b&gt;&#xA;&lt;/center&gt;</summary>
  </entry>
  <entry>
    <title>Fizzadar/pyinfra</title>
    <updated>2022-10-26T01:38:04Z</updated>
    <id>tag:github.com,2022-10-26:/Fizzadar/pyinfra</id>
    <link href="https://github.com/Fizzadar/pyinfra" rel="alternate"></link>
    <summary type="html">&lt;p&gt;pyinfra automates infrastructure super fast at massive scale. It can be used for ad-hoc command execution, service deployment, configuration management and more.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://pyinfra.com&#34;&gt; &lt;img src=&#34;https://pyinfra.com/static/logo_readme.png&#34; alt=&#34;pyinfra&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;em&gt;pyinfra automates infrastructure super fast at massive scale&lt;/em&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://pypi.python.org/pypi/pyinfra&#34;&gt;&lt;img alt=&#34;PyPI version&#34; src=&#34;https://img.shields.io/pypi/v/pyinfra?color=blue&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/pyinfra&#34;&gt;&lt;img alt=&#34;PyPi downloads&#34; src=&#34;https://pepy.tech/badge/pyinfra&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.pyinfra.com&#34;&gt;&lt;img alt=&#34;Docs status&#34; src=&#34;https://img.shields.io/github/workflow/status/Fizzadar/pyinfra/Generate%20&amp;amp;%20Deploy%20Docs/master?label=docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Fizzadar/pyinfra/actions?query=workflow%3A%22Execute+tests%22&#34;&gt;&lt;img alt=&#34;Execute tests status&#34; src=&#34;https://img.shields.io/github/workflow/status/Fizzadar/pyinfra/Execute%20tests/master?label=tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/Fizzadar/pyinfra&#34;&gt;&lt;img alt=&#34;Codecov Coverage&#34; src=&#34;https://img.shields.io/codecov/c/gh/Fizzadar/pyinfra&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Fizzadar/pyinfra/raw/2.x/LICENSE.md&#34;&gt;&lt;img alt=&#34;MIT Licensed&#34; src=&#34;https://img.shields.io/pypi/l/pyinfra&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://docs.pyinfra.com&#34;&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://docs.pyinfra.com/page/getting-started.html&#34;&gt;&lt;strong&gt;Getting Started&lt;/strong&gt;&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://docs.pyinfra.com/page/examples.html&#34;&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://docs.pyinfra.com/page/support.html&#34;&gt;&lt;strong&gt;Help &amp;amp; Support&lt;/strong&gt;&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://docs.pyinfra.com/page/contributing.html&#34;&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;pyinfra automates/provisions/manages/deploys infrastructure. It can be used for ad-hoc command execution, service deployment, configuration management and more. Design features include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üöÄ &lt;strong&gt;Super fast&lt;/strong&gt; execution over thousands of hosts with predictable performance.&lt;/li&gt; &#xA; &lt;li&gt;üö® &lt;strong&gt;Instant debugging&lt;/strong&gt; with stdout &amp;amp; stderr output on error or as required (&lt;code&gt;-v&lt;/code&gt;|&lt;code&gt;-vv&lt;/code&gt;|&lt;code&gt;-vvv&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;üì¶ &lt;strong&gt;Extendable&lt;/strong&gt; with &lt;em&gt;any&lt;/em&gt; Python package as configured &amp;amp; written in standard Python.&lt;/li&gt; &#xA; &lt;li&gt;üíª &lt;strong&gt;Agentless execution&lt;/strong&gt; against SSH/Docker/subprocess/winrm hosts.&lt;/li&gt; &#xA; &lt;li&gt;‚ùóÔ∏è &lt;strong&gt;Two stage process&lt;/strong&gt; that enables &lt;code&gt;--dry&lt;/code&gt; runs before executing any changes.&lt;/li&gt; &#xA; &lt;li&gt;üîå &lt;strong&gt;Integrated&lt;/strong&gt; with Docker, Vagrant/Mech &amp;amp; Ansible out of the box.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When you run pyinfra you&#39;ll see something like (&lt;a href=&#34;https://pyinfra.com/static/example_deploy.png&#34;&gt;non animated version&lt;/a&gt;):&lt;/p&gt; &#xA;&lt;img width=&#34;100%&#34; src=&#34;https://pyinfra.com/static/example_deploy.gif&#34;&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;Install pyinfra with &lt;a href=&#34;https://pipxproject.github.io/pipx/&#34;&gt;&lt;code&gt;pipx&lt;/code&gt;&lt;/a&gt; (recommended) or &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pipx install pyinfra&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now you can execute commands on hosts via SSH:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pyinfra my-server.net exec -- echo &#34;hello world&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or execute in Docker, on the local machine, and other &lt;a href=&#34;https://docs.pyinfra.com/page/connectors.html&#34;&gt;connectors&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pyinfra @docker/ubuntu exec -- echo &#34;Hello world&#34;&#xA;pyinfra @local exec -- echo &#34;Hello world&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;As well as executing commands you can define state using &lt;a href=&#34;https://docs.pyinfra.com/page/operations.html&#34;&gt;operations&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# Install iftop apt package if not present&#xA;pyinfra @docker/ubuntu apt.packages iftop update=true _sudo=true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Which can then be saved as a Python file like &lt;code&gt;deploy.py&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from pyinfra.operations import apt&#xA;&#xA;apt.packages(&#xA;    name=&#34;Ensure iftop is installed&#34;,&#xA;    packages=[&#39;iftop&#39;],&#xA;    update=True,&#xA;    _sudo=True,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The hosts can also be saved in a file, for example &lt;code&gt;inventory.py&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;targets = [&#34;@docker/ubuntu&#34;, &#34;my-test-server.net&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And executed together:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pyinfra inventory.py deploy.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now you know the building blocks of pyinfra! By combining inventory, operations and Python code you can deploy anything.&lt;/p&gt; &#xA;&lt;p&gt;See the more detailed &lt;a href=&#34;https://docs.pyinfra.com/page/getting-started.html&#34;&gt;getting started&lt;/a&gt; or &lt;a href=&#34;https://docs.pyinfra.com/page/using-operations.html&#34;&gt;using operations&lt;/a&gt; guides. See how to use &lt;a href=&#34;https://docs.pyinfra.com/page/inventory-data.html&#34;&gt;inventory &amp;amp; data&lt;/a&gt;, &lt;a href=&#34;https://docs.pyinfra.com/page/arguments.html&#34;&gt;global arguments&lt;/a&gt; and &lt;a href=&#34;https://docs.pyinfra.com/page/cli.html&#34;&gt;the CLI&lt;/a&gt; or check out the &lt;a href=&#34;https://docs.pyinfra.com/page/examples.html&#34;&gt;documented examples&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>automl/TabPFN</title>
    <updated>2022-10-26T01:38:04Z</updated>
    <id>tag:github.com,2022-10-26:/automl/TabPFN</id>
    <link href="https://github.com/automl/TabPFN" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official implementation of the TabPFN and the tabpfn package.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TabPFN&lt;/h1&gt; &#xA;&lt;p&gt;The TabPFN is a neural network that learned to do tabular data prediction. This is the original CUDA-supporting pytorch impelementation.&lt;/p&gt; &#xA;&lt;p&gt;We created a &lt;a href=&#34;https://colab.research.google.com/drive/194mCs6SEPEW6C0rcP7xWzcEtt1RBc8jJ&#34;&gt;Colab&lt;/a&gt;, that lets you play with our scikit-learn interface.&lt;/p&gt; &#xA;&lt;p&gt;We also created two demos. One to experiment with the TabPFNs predictions (&lt;a href=&#34;https://huggingface.co/spaces/TabPFN/TabPFNPrediction&#34;&gt;https://huggingface.co/spaces/TabPFN/TabPFNPrediction&lt;/a&gt;) and one to check cross- validation ROC AUC scores on new datasets (&lt;a href=&#34;https://huggingface.co/spaces/TabPFN/TabPFNEvaluation&#34;&gt;https://huggingface.co/spaces/TabPFN/TabPFNEvaluation&lt;/a&gt;). Both of them run on a weak CPU, thus it can require a little bit of time. Both demos are based on a scikit-learn interface that makes using the TabPFN as easy as a scikit-learn SVM.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install tabpfn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to evaluate our baselines, too, please install with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install tabpfn[baselines]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run the autogluon and autosklearn baseline please create a separate environment and install autosklearn / autogluon==0.4.0, installation in the same environment as our other baselines is not possible.&lt;/p&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;p&gt;A simple usage of our sklearn interface is:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.metrics import accuracy_score&#xA;from sklearn.datasets import load_breast_cancer&#xA;from sklearn.model_selection import train_test_split&#xA;&#xA;from tabpfn.scripts.transformer_prediction_interface import TabPFNClassifier&#xA;&#xA;X, y = load_breast_cancer(return_X_y=True)&#xA;X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)&#xA;&#xA;# N_ensemble_configurations controls the number of model predictions that are ensembled with feature and class rotations (See our work for details).&#xA;# When N_ensemble_configurations &amp;gt; #features * #classes, no further averaging is applied.&#xA;&#xA;classifier = TabPFNClassifier(device=&#39;cpu&#39;, N_ensemble_configurations=32)&#xA;&#xA;# By setting normalize_with_test to True, input normalization is applied across train + test set (weak transductive setting). [default = False]&#xA;classifier.fit(X_train, y_train, normalize_with_test=False)&#xA;y_eval, p_eval = classifier.predict(X_test, return_winning_probability=True)&#xA;&#xA;print(&#39;Accuracy&#39;, accuracy_score(y_test, y_eval))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Our Paper&lt;/h3&gt; &#xA;&lt;p&gt;Read our &lt;a href=&#34;https://arxiv.org/abs/2207.01848&#34;&gt;paper&lt;/a&gt; for more information about the setup (or contact us ‚ò∫Ô∏è). If you use our method, please cite us using&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{tabpfn,&#xA;  doi = {10.48550/ARXIV.2207.01848},&#xA;  url = {https://arxiv.org/abs/2207.01848},&#xA;  author = {Hollmann, Noah and M√ºller, Samuel and Eggensperger, Katharina and Hutter, Frank},&#xA;  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},&#xA;  title = {TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second},&#xA;  publisher = {arXiv},&#xA;  year = {2022},&#xA;  copyright = {arXiv.org perpetual, non-exclusive license}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>