<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-05T01:33:08Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>zgimszhd61/prompt-collection-quickstart</title>
    <updated>2024-05-05T01:33:08Z</updated>
    <id>tag:github.com,2024-05-05:/zgimszhd61/prompt-collection-quickstart</id>
    <link href="https://github.com/zgimszhd61/prompt-collection-quickstart" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;prompt-collection-quickstart&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;group together the pro and con cases for each arguement &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;请把下面代码里的prompt抽取出来，并转化成易于中国人阅读和理解的格式,花括号里面内容保持原文。只需要提供prompt原文，不要说其他无关内容。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;总结 - 1&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;将三个引号之间的文本摘要成大约50个字。&#xA;&#xA;&#34;&#34;&#34;insert text here&#34;&#34;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;总结 - 2&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;总结两段中用三引号分隔的文本。&#xA;&#xA;&#34;&#34;&#34;insert text here&#34;&#34;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;总结 -3&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;将由三引号分隔的文本总结为 3 个要点。&#xA;&#xA;&#34;&#34;&#34;insert text here&#34;&#34;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;RAG答案合成 - 1&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;使用提供的由三重引号引起来的文章来回答问题。 如果在文章中找不到答案，请写“我找不到答案”。&#xA;&#xA;&amp;lt;插入文章，每篇文章均由三引号分隔&amp;gt;&#xA;&#xA;问题：&amp;lt;在此插入问题&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;RAG答案合成 - 例子&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;使用提供的由三重引号引起来的文章来回答问题。 如果在文章中找不到答案，请写“我找不到答案”。&#xA;&#xA;&#34;&#34;&#34;小红喜欢牡丹花&#34;&#34;&#34;&#xA;&#34;&#34;&#34;小白也喜欢牡丹花&#34;&#34;&#34;&#xA;&#34;&#34;&#34;小唐喜欢小红&#34;&#34;&#34;&#xA;&#xA;问题：小红被什么喜欢？&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;您将获得一份由三重引号和一个问题分隔的文档。 您的任务是仅使用提供的文档回答问题，并引用用于回答问题的文档段落。 如果文档不包含回答此问题所需的信息，则只需写：“信息不足”。 如果提供了问题的答案，则必须附有引文注释。 使用以下格式引用相关段落（{“引用”：…}）。&#xA;&#xA;&#34;&#34;&#34;中国人口和56个民族&#xA; &#xA;&#xA;中华民族有着悠久的历史。从遥远的古代起，中华各民族人民的祖先就劳动、生息、繁衍在中华大地上，共同为中华文明和建立统一的多民族国家而贡献自己的才智。&#xA;&#xA; &#xA;&#xA;据中国政府考察统计正式确认的中华人民共和国民族共有56个，其他为未识别的民族。&#xA;&#xA; &#xA;&#xA;据第六次全国人口普查主要数据：汉族人口比重最大，约占全国人口总数的91.51%左右，其它55个民族总人口偏少，约占全国总人口的8.49%左右，故称其为少数民族。&#xA;&#xA; &#xA;&#xA;全国55个少数民族中人口最多的是壮族，人口超过1600万（2000年）；最少的是珞巴族，人口不足3000人（2000年）（未包括中印争议的藏南地区60万珞巴族人）。&#xA;&#xA; &#xA;&#xA;分布特点&#xA;  &#xA;&#xA; 中国各民族分布的特点是：大杂居、小聚居、相互交错居住。汉族地区有少数民族聚居，少数民族地区有汉族居住。这种分布格局是长期历史发展过程中，各民族间相互交往、流动而形成的。中国少数民族人口虽少，但分布很广。全国各省、自治区、直辖市都有少数民族居住，绝大部分县级单位都有两个以上的民族居住。中国的少数民族，主要分布在内蒙古、新疆、宁夏、广西、西藏、云南、贵州、青海、四川、甘肃、黑龙江、辽宁、吉林、湖南、湖北、海南、台湾等省、自治区。中国民族成分最多的是云南省，有25个民族。&#xA; &#xA; &#xA;地理资源&#xA; &#xA;&#xA;中国地域辽阔，资源丰富。民族区域自治制度是国家的一项基本政治制度，中国政府一直致力于推进民族区域自治制度，保证少数民族当家做主管理本民族内部事务的权利。据《中国的民族区域自治》白皮书载，中国的55个少数民族中，有44个建立了自治地方，实行区域自治的少数民族人口占少数民族总人口的71%。中国民族自治地方的面积占全国国土总面积的64%左右；草原面积占全国的75%，中国著名的5大天然牧区，都在少数民族地区；森林面积占全国的43.9%；林木蓄积量占全国的55.9%；水力资源蕴藏量占全国的65.9%。此外，还有大量的矿藏资源，以及丰富的动植物资源和旅游资源。&#xA;&#xA; &#xA;&#xA;各民族人口&#xA; &#xA;&#xA;新中国成立后，中国政府对少数民族实行了宽于汉族的生育政策。&#xA;&#xA; &#xA;&#xA;为提高少数民族人口素质，加快民族自治地方的经济社会发展，中国各民族自治地方的人民代表大会，根据国家有关少数民族也要实行计划生育的精神，制定了该地区少数民族的计划生育政策，但其政策宽于汉族的生育政策。这使得少数民族人口的增长速度高于全国平均水平。&#xA;&#xA; &#xA;&#xA;全国五次人口普查结果表明，中国少数民族：1953年7月1日为3532万人，1964年7月1日为4000万人，1982年7月1日为6724万人，1990年7月1日为9120万人，2000年11月1日为10643万人。&#xA;&#xA; &#xA;&#xA;据2000年第五次全国人口普查统计，中国大陆31个省、自治区、直辖市共有12.9533亿人。其中汉族115940万人，占91.59%；少数民族10643万占8.41%（同1990年第四次全国人口普查相比，汉族人口增加了11692万人，增长了11.22%；各少数民族人口增加了1523万人，增长了16.70%）。&#xA;&#xA; &#xA;&#xA;第六次全国人口普查显示：大陆31个省、自治区、直辖市和现役军人的人口中，汉族人口为1225932641人，占91.51%；各少数民族人口为113792211人，占8.49%。同2000年第五次全国人口普查相比，汉族人口增加66537177人，增长5.74%；各少数民族人口增加7362627人，增长6.92%。&#xA;&#34;&#34;&#34;&#xA;&#xA;&#34;&#34;&#34;&#xA;政区类型&#xA;播报&#xA;编辑&#xA;中华人民共和国省级行政区是中央人民政府直接管辖的最高一级地方行政区域，包括四种类型：省、自治区、直辖市和特别行政区。《中华人民共和国宪法》第三十条规定：全国分为省、自治区、直辖市。自治区是省级民族自治地方。第三十一条规定：国家在必要时得设立特别行政区。在特别行政区内实行的制度按照具体情况由全国人民代表大会以法律规定。 [2] [4]&#xA;省，是中国国家地方一级行政区域，名称起源于元代，一直沿用至今，已有六、七百年的历史。 [1-2]&#xA;自治区，是中华人民共和国少数民族聚居地方实行民族区域自治而建立的相当于省的行政区域。 [1-2]&#xA;直辖市，即中央直辖市，由国务院直接管辖。是人口比较集中，在政治、经济、文化等方面具有特别重要地位的大城市。 [1-2]&#xA;特别行政区，是为“一国两制”的实施而设立的享有高度自治权的地方行政区域。与省、自治区、直辖市同属直辖于中央人民政府的地方行政区域。 [2] [12]&#xA;中华人民共和国成立初期，除了省、自治区、直辖市，还设有相当于省级行政区的行署区、地方、地区；在省级行政区之上，还有6个大行政区，作为一级地方行政单位，即东北、华北、华东、中南、西北、西南六大行政区。 [3] [5]&#xA;&#34;&#34;&#34;&#xA;&#xA;&#34;&#34;&#34;&#xA;中华民族有着悠久的历史。从遥远的古代起，中华各民族人民的祖先就劳动、生息、繁衍在中华大地上，共同为中华文明和建立统一的多民族国家而贡献自己的才智。 [2]&#xA;据中国政府考察统计正式确认的中华人民共和国民族共有56个，其他为未识别的民族 [1]。 [2]&#xA;据第六次全国人口普查主要数据：汉族人口比重最大，约占全国人口总数的91.51%左右，其它55个民族总人口偏少，约占全国总人口的8.49%左右，故称其为少数民族。 [6]&#xA;全国55个少数民族中人口最多的是壮族，人口超过1600万（2000年） [3]；最少的是珞巴族，人口不足3000人（2000年） [4]（未包括中华人民共和国的固有领土藏南地区的60万珞巴族人）。&#xA;&#34;&#34;&#34;&#xA;&#xA;问题：中国有多少个省份和民族?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;RAG答案合成 - 2&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;您将获得一份由三重引号和一个问题分隔的文档。 您的任务是仅使用提供的文档回答问题，并引用用于回答问题的文档段落。 如果文档不包含回答此问题所需的信息，则只需写：“信息不足”。 如果提供了问题的答案，则必须附有引文注释。 使用以下格式引用相关段落（{“引用”：…}）。&#xA;&#xA;&#34;&#34;&#34;&amp;lt;在此插入文档&amp;gt;&#34;&#34;&#34;&#xA;&#xA;问题：&amp;lt;在此插入问题&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;RAG答案合成 - 例子&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;您将获得一份由三重引号和一个问题分隔的文档。 您的任务是仅使用提供的文档回答问题，并引用用于回答问题的文档段落。 如果文档不包含回答此问题所需的信息，则只需写：“信息不足”。 如果提供了问题的答案，则必须附有引文注释。 使用以下格式引用相关段落（{“引用”：…}）。&#xA;&#xA;&#34;&#34;&#34;小红喜欢牡丹花&#34;&#34;&#34;&#xA;&#34;&#34;&#34;小白也喜欢牡丹花&#34;&#34;&#34;&#xA;&#34;&#34;&#34;小唐喜欢小红&#34;&#34;&#34;&#xA;&#xA;&#xA;问题：小红喜欢什么？&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;分解任务 - 1&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;我们将向您提供客户服务查询。 将每个查询分为主要类别和次要类别。 提供 json 格式的输出，其中包含以下键：主要和次要。&#xA;&#xA;主要类别：计费、技术支持、帐户管理或一般查询。&#xA;&#xA;计费二级类别：&#xA;- 取消订阅或升级&#xA;- 添加付款方式&#xA;- 收费说明&#xA;- 对收费提出争议&#xA;&#xA;技术支持二级分类：&#xA;- 故障排除&#xA;- 设备兼容性&#xA;- 软件更新&#xA;&#xA;账户管理二级分类：&#xA;- 重设密码&#xA;- 更新个人信息&#xA;- 关闭账户&#xA;- 账户安全&#xA;&#xA;一般查询二级类别：&#xA;- 产品信息&#xA;- 价钱&#xA;- 反馈&#xA;- 与人类交谈&#xA;&#xA;查询：我需要让我的互联网重新工作&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;分解任务 - 2&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;您将收到需要在技术支持环境中进行故障排除的客户服务查询。 通过以下方式帮助用户：&#xA;&#xA;- 请他们检查所有进出路由器的电缆是否已连接。 请注意，随着时间的推移，电缆松动是很常见的。&#xA;- 如果所有电缆均已连接并且问题仍然存在，请询问他们正在使用哪种路由器型号&#xA;- 现在您将建议他们如何重新启动设备：&#xA;-- 如果型号是 MTD-327J，建议他们按下红色按钮并按住 5 秒钟，然后等待 5 分钟后再测试连接。&#xA;-- 如果型号是 MTD-327S，建议他们拔下并重新插入，然后等待 5 分钟再测试连接。&#xA;- 如果客户的问题在重新启动设备并等待 5 分钟后仍然存在，请通过输出 {“IT 支持请求”} 将他们连接到 IT 支持。&#xA;- 如果用户开始询问与此主题无关的问题，请确认他们是否想结束当前有关故障排除的聊天，并根据以下方案对他们的请求进行分类：&#xA;&#xA;&amp;lt;在此处插入上面的主要/次要分类方案&amp;gt;&#xA;&#xA;查询：我需要让我的互联网重新工作。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;判断对错 - 1&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;确定学生的解决方案是否正确。&#xA;问题陈述：我正在建造一个太阳能发电装置，我需要帮助解决财务问题。&#xA;- 土地成本 100 美元/平方英尺&#xA;- 我可以以 250 美元/平方英尺的价格购买太阳能电池板&#xA;- 我协商了一份维护合同，每年将花费我 10 万美元，每平方英尺额外花费 10 美元&#xA;第一年运营的总成本是多少，与平方英尺数的函数关系。&#xA;&#xA;学生的解决方案：设 x 为装置的尺寸（以平方英尺为单位）。&#xA;1.土地成本：100x&#xA;2.太阳能电池板成本：250x&#xA;3.维护成本：100,000 + 100x&#xA;总成本：100x + 250x + 100,000 + 100x = 450x + 100,000&#xA;&#xA;Assistant：&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;确定学生的解决方案是否正确。&#xA;问题陈述：中国有多少个省份和民族?&#xA;&#xA;学生的解决方案：&#34;&#34;&#34;&#xA;中国有以下数量的省份和民族：&#xA;&#xA;省份：中华人民共和国省级行政区包括省、自治区、直辖市和特别行政区。共有31个省、自治区、直辖市和台湾等地区。{“政区类型”：省、自治区、直辖市}&#xA;民族：中国共有56个民族，其中汉族占绝大多数，其他55个民族称为少数民族。{“中国人口和56个民族”}&#xA;&#34;&#34;&#34;&#xA;&#xA;Assistant：&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;判断对错 - 2&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;首先制定自己的问题解决方案。 然后将你的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。 在你自己完成问题之前，不要决定学生的解决方案是否正确。&#xA;&#xA;问题陈述：我正在建造一个太阳能发电装置，我需要帮助解决财务问题。&#xA;- 土地成本 100 美元/平方英尺&#xA;- 我可以以 250 美元/平方英尺的价格购买太阳能电池板&#xA;- 我协商了一份维护合同，每年将花费我 10 万美元，每平方英尺额外花费 10 美元&#xA;第一年运营的总成本是多少，与平方英尺数的函数关系。&#xA;&#xA;学生的解决方案：设 x 为装置的尺寸（以平方英尺为单位）。&#xA;1.土地成本：100x&#xA;2.太阳能电池板成本：250x&#xA;3.维护成本：100,000 + 100x&#xA;总成本：100x + 250x + 100,000 + 100x = 450x + 100,000&#xA;&#xA;Assistant：&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;回答问题&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;请按照以下步骤回答用户的疑问。&#xA;&#xA;步骤 1 - 首先找出你自己的问题解决方案。 不要依赖学生的解决方案，因为它可能是不正确的。 将这一步的所有工作用三引号 (&#34;&#34;&#34;) 括起来。&#xA;&#xA;第 2 步 - 将您的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。 将这一步的所有工作用三引号 (&#34;&#34;&#34;) 括起来。&#xA;&#xA;第 3 步 - 如果学生犯了错误，请确定在不泄露答案的情况下可以给学生什么提示。 将这一步的所有工作用三引号 (&#34;&#34;&#34;) 括起来。&#xA;&#xA;步骤 4 - 如果学生犯了错误，请向学生提供上一步的提示（在三重引号之外）。 不要写“步骤 4 - ...”，而写“提示：”。&#xA;&#xA;问题陈述：&amp;lt;插入问题陈述&amp;gt;&#xA;&#xA;学生解决方案：&amp;lt;插入学生解决方案&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;回答问题，判断对错，并给出分析&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;将您的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。&#xA;&#xA;问题陈述：“”“&amp;lt;插入问题陈述&amp;gt;”“”&#xA;&#xA;您的解决方案：“”“&amp;lt;插入模型生成的解决方案&amp;gt;”“”&#xA;&#xA;学生的解决方案：“”“&amp;lt;插入学生的解决方案&amp;gt;”“”&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;自动批阅答案&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;你是一名数学导师。 如果学生犯了错误，请以不透露答案的方式向学生提供提示。 如果学生没有犯错，只需给他们一个鼓励性的评论。&#xA;问题陈述：“”“&amp;lt;插入问题陈述&amp;gt;”“”&#xA;&#xA;您的解决方案：“”“&amp;lt;插入模型生成的解决方案&amp;gt;”“”&#xA;&#xA;学生的解决方案：“”“&amp;lt;插入学生的解决方案&amp;gt;”“”&#xA;&#xA;分析：“”“&amp;lt;插入上一步中模型生成的分析&amp;gt;”“”&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>SuperpoweredAI/spRAG</title>
    <updated>2024-05-05T01:33:08Z</updated>
    <id>tag:github.com,2024-05-05:/SuperpoweredAI/spRAG</id>
    <link href="https://github.com/SuperpoweredAI/spRAG" rel="alternate"></link>
    <summary type="html">&lt;p&gt;RAG framework for challenging queries over dense unstructured data&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;spRAG&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/NTUVX9DmQ3&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1234629280755875881.svg?label=Discord&amp;amp;logo=discord&amp;amp;color=7289DA&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;spRAG is a RAG framework for unstructured data. It is especially good at handling challenging queries over dense text, like financial reports, legal documents, and academic papers.&lt;/p&gt; &#xA;&lt;p&gt;spRAG achieves substantially higher accuracy than vanilla RAG baselines on complex open-book question answering tasks. On one especially challenging benchmark, &lt;a href=&#34;https://arxiv.org/abs/2311.11944&#34;&gt;FinanceBench&lt;/a&gt;, spRAG gets accurate answers 83% of the time, compared to the vanilla RAG baseline which only gets 19% of questions correct.&lt;/p&gt; &#xA;&lt;p&gt;There are two key methods used to improve performance over vanilla RAG systems:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;AutoContext&lt;/li&gt; &#xA; &lt;li&gt;Relevant Segment Extraction (RSE)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;AutoContext&lt;/h4&gt; &#xA;&lt;p&gt;AutoContext automatically injects document-level context into individual chunks prior to embedding them. This gives the embeddings a much more accurate and complete representation of the content and meaning of the text. In our testing, this feature leads to a dramatic improvement in retrieval quality. In addition to increasing the rate at which the correct information is retrieved, AutoContext also substantially reduces the rate at which irrelevant results show up in the search results. This reduces the rate at which the LLM misinterprets a piece of text in downstream chat and generation applications.&lt;/p&gt; &#xA;&lt;p&gt;The implementation of AutoContext is fairly straightforward. All we do is generate a 1-2 sentence summary of the document, add the file name to it, and then prepend that to each chunk prior to embedding it.&lt;/p&gt; &#xA;&lt;h4&gt;Relevant Segment Extraction&lt;/h4&gt; &#xA;&lt;p&gt;Relevant Segment Extraction (RSE) is a post-processing step that takes clusters of relevant chunks and intelligently combines them into longer sections of text that we call segments. These segments provide better context to the LLM than any individual chunk can. For simple factual questions, the answer is usually contained in a single chunk; but for more complex questions, the answer usually spans a longer section of text. The goal of RSE is to intelligently identify the section(s) of text that provide the most relevant information, without being constrained to fixed length chunks.&lt;/p&gt; &#xA;&lt;p&gt;For example, suppose you have a bunch of SEC filings in a knowledge base and you ask “What were Apple’s key financial results in the most recent fiscal year?” RSE will identify the most relevant segment as the entire “Consolidated Statement of Operations” section, which will be 5-10 chunks long. Whereas if you ask “Who is Apple’s CEO?” the most relevant segment will be identified as a single chunk that mentions “Tim Cook, CEO.”&lt;/p&gt; &#xA;&lt;h1&gt;Tutorial&lt;/h1&gt; &#xA;&lt;p&gt;The easiest way to install spRAG is to use the Python package: &lt;code&gt;pip install sprag&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Quickstart&lt;/h4&gt; &#xA;&lt;p&gt;By default, spRAG uses OpenAI for embeddings, Claude 3 Haiku for AutoContext, and Cohere for reranking, so to run the code below you&#39;ll need to make sure you have API keys for those providers set as environmental variables with the following names: &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;, and &lt;code&gt;CO_API_KEY&lt;/code&gt;. &lt;strong&gt;If you want to run spRAG with different models, take a look at the &#34;Basic customization&#34; section below.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can create a new KnowledgeBase directly from a file using the &lt;code&gt;create_kb_from_file&lt;/code&gt; function:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sprag.create_kb import create_kb_from_file&#xA;&#xA;file_path = &#34;spRAG/tests/data/levels_of_agi.pdf&#34;&#xA;kb_id = &#34;levels_of_agi&#34;&#xA;kb = create_kb_from_file(kb_id, file_path)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;KnowledgeBase objects persist to disk automatically, so you don&#39;t need to explicitly save it at this point.&lt;/p&gt; &#xA;&lt;p&gt;Now you can load the KnowledgeBase by its &lt;code&gt;kb_id&lt;/code&gt; (only necessary if you run this from a separate script) and query it using the &lt;code&gt;query&lt;/code&gt; method:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sprag.knowledge_base import KnowledgeBase&#xA;&#xA;kb = KnowledgeBase(&#34;levels_of_agi&#34;)&#xA;search_queries = [&#34;What are the levels of AGI?&#34;, &#34;What is the highest level of AGI?&#34;]&#xA;results = kb.query(search_queries)&#xA;for segment in results:&#xA;    print(segment)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Basic customization&lt;/h4&gt; &#xA;&lt;p&gt;Now let&#39;s look at an example of how we can customize the configuration of a KnowledgeBase. In this case, we&#39;ll customize it so that it only uses OpenAI (useful if you don&#39;t have API keys for Anthropic and Cohere). To do so, we need to pass in a subclass of &lt;code&gt;LLM&lt;/code&gt; and a subclass of &lt;code&gt;Reranker&lt;/code&gt;. We&#39;ll use &lt;code&gt;gpt-3.5-turbo&lt;/code&gt; for the LLM (this is what gets used for document summarization in AutoContext) and since OpenAI doesn&#39;t offer a reranker, we&#39;ll use the &lt;code&gt;NoReranker&lt;/code&gt; class for that.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sprag.llm import OpenAIChatAPI&#xA;from sprag.reranker import NoReranker&#xA;&#xA;llm = OpenAIChatAPI(model=&#39;gpt-3.5-turbo&#39;)&#xA;reranker = NoReranker()&#xA;&#xA;kb = KnowledgeBase(kb_id=&#34;levels_of_agi&#34;, reranker=reranker, auto_context_model=llm)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now we can add documents to this KnowledgeBase using the &lt;code&gt;add_document&lt;/code&gt; method. Note that the &lt;code&gt;add_document&lt;/code&gt; method takes in raw text, not files, so we&#39;ll have to extract the text from our file first. There are some utility functions for doing this in the &lt;code&gt;document_parsing.py&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sprag.document_parsing import extract_text_from_pdf&#xA;&#xA;file_path = &#34;spRAG/tests/data/levels_of_agi.pdf&#34;&#xA;text = extract_text_from_pdf(file_path)&#xA;kb.add_document(doc_id=file_path, text=text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Architecture&lt;/h1&gt; &#xA;&lt;h2&gt;KnowledgeBase object&lt;/h2&gt; &#xA;&lt;p&gt;A KnowledgeBase object takes in documents (in the form of raw text) and does chunking and embedding on them, along with a few other preprocessing operations. Then at query time you feed in queries and it returns the most relevant segments of text.&lt;/p&gt; &#xA;&lt;p&gt;KnowledgeBase objects are persistent by default. The full configuration needed to reconstruct the object gets saved as a JSON file upon creation and updating.&lt;/p&gt; &#xA;&lt;h2&gt;Components&lt;/h2&gt; &#xA;&lt;p&gt;There are five key components that define the configuration of a KnowledgeBase, each of which are customizable:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;VectorDB&lt;/li&gt; &#xA; &lt;li&gt;ChunkDB&lt;/li&gt; &#xA; &lt;li&gt;Embedding&lt;/li&gt; &#xA; &lt;li&gt;Reranker&lt;/li&gt; &#xA; &lt;li&gt;LLM&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;There are defaults for each of these components, as well as alternative options included in the repo. You can also define fully custom components by subclassing the base classes and passing in an instance of that subclass to the KnowledgeBase constructor.&lt;/p&gt; &#xA;&lt;h4&gt;VectorDB&lt;/h4&gt; &#xA;&lt;p&gt;The VectorDB component stores the embedding vectors, as well as a small amount of metadata.&lt;/p&gt; &#xA;&lt;p&gt;The currently available options are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;BasicVectorDB&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;ChunkDB&lt;/h4&gt; &#xA;&lt;p&gt;The ChunkDB stores the content of text chunks in a nested dictionary format, keyed on &lt;code&gt;doc_id&lt;/code&gt; and &lt;code&gt;chunk_index&lt;/code&gt;. This is used by RSE to retrieve the full text associated with specific chunks.&lt;/p&gt; &#xA;&lt;p&gt;The currently available options are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;BasicChunkDB&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Embedding&lt;/h4&gt; &#xA;&lt;p&gt;The Embedding component defines the embedding model.&lt;/p&gt; &#xA;&lt;p&gt;The currently available options are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;OpenAIEmbedding&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;CohereEmbedding&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;VoyageAIEmbedding&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Reranker&lt;/h4&gt; &#xA;&lt;p&gt;The Reranker components define the reranker. This is used after the vector database search (and before RSE) to provide a more accurate ranking of chunks.&lt;/p&gt; &#xA;&lt;p&gt;The currently available options are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;CohereReranker&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;LLM&lt;/h4&gt; &#xA;&lt;p&gt;This defines the LLM to be used for document summarization, which is only used in AutoContext.&lt;/p&gt; &#xA;&lt;p&gt;The currently available options are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;OpenAIChatAPI&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;AnthropicChatAPI&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Document upload flow&lt;/h2&gt; &#xA;&lt;p&gt;Documents -&amp;gt; chunking -&amp;gt; embedding -&amp;gt; chunk and vector database upsert&lt;/p&gt; &#xA;&lt;h2&gt;Query flow&lt;/h2&gt; &#xA;&lt;p&gt;Queries -&amp;gt; vector database search -&amp;gt; reranking -&amp;gt; RSE -&amp;gt; results&lt;/p&gt; &#xA;&lt;h1&gt;Community and support&lt;/h1&gt; &#xA;&lt;p&gt;You can join our &lt;a href=&#34;https://discord.gg/NTUVX9DmQ3&#34;&gt;Discord&lt;/a&gt; to ask questions, make suggestions, and discuss contributions.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>e2b-dev/code-interpreter</title>
    <updated>2024-05-05T01:33:08Z</updated>
    <id>tag:github.com,2024-05-05:/e2b-dev/code-interpreter</id>
    <link href="https://github.com/e2b-dev/code-interpreter" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Python &amp; JS/TS SDK for adding code interpreting to your AI app&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Code Interpreter SDK&lt;/h1&gt; &#xA;&lt;p&gt;E2B&#39;s &lt;a href=&#34;https://github.com/e2b-dev/code-interpreter&#34;&gt;Code Interpreter SDK&lt;/a&gt; allows you to add code interpreting capabilities to your AI apps.&lt;/p&gt; &#xA;&lt;p&gt;The code interpreter runs inside the &lt;a href=&#34;https://github.com/e2b-dev/e2b&#34;&gt;E2B Sandbox&lt;/a&gt; - an open-source secure sandbox made for running untrusted AI-generated code and AI agents.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;✅ Works with any LLM and AI framework&lt;/li&gt; &#xA; &lt;li&gt;✅ Supports streaming content like charts and stdout, stderr&lt;/li&gt; &#xA; &lt;li&gt;✅ Python &amp;amp; JS SDK&lt;/li&gt; &#xA; &lt;li&gt;✅ Runs on serverless and edge functions&lt;/li&gt; &#xA; &lt;li&gt;✅ Runs AI-generated code in secure sandboxed environments&lt;/li&gt; &#xA; &lt;li&gt;✅ 100% open source (including &lt;a href=&#34;https://github.com/e2b-dev/infra&#34;&gt;infrastructure&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Follow E2B on &lt;a href=&#34;https://twitter.com/e2b_dev&#34;&gt;X (Twitter)&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;🚀 Quickstart&lt;/h2&gt; &#xA;&lt;h3&gt;1. Install SDK&lt;/h3&gt; &#xA;&lt;p&gt;JavaScript/TypeScript&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm i @e2b/code-interpreter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Python&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install e2b_code_interpreter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Execute code with code interpreter inside sandbox&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ts&#34;&gt;import { CodeInterpreter } from &#39;@e2b/code-interpreter&#39;&#xA;&#xA;const sandbox = await CodeInterpreter.create()&#xA;await sandbox.notebook.execCell(&#39;x = 1&#39;)&#xA;&#xA;const execution = await sandbox.notebook.execCell(&#39;x+=1; x&#39;)&#xA;console.log(execution.text)  // outputs 2&#xA;&#xA;await sandbox.close()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Python&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from e2b_code_interpreter import CodeInterpreter&#xA;&#xA;with CodeInterpreter() as sandbox:&#xA;    sandbox.notebook.exec_cell(&#34;x = 1&#34;)&#xA;&#xA;    execution = sandbox.notebook.exec_cell(&#34;x+=1; x&#34;)&#xA;    print(execution.text)  # outputs 2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. Hello World guide&lt;/h3&gt; &#xA;&lt;p&gt;Dive depeer and check out the &lt;a href=&#34;https://raw.githubusercontent.com/e2b-dev/code-interpreter/main/hello-world/js&#34;&gt;JavaScript&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/e2b-dev/code-interpreter/main/hello-world/py&#34;&gt;Python&lt;/a&gt; the Hello World guides to learn how o connect code interpreter LLMs.&lt;/p&gt; &#xA;&lt;h2&gt;📖 Cookbook examples&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Hello World&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/e2b-dev/e2b-cookbook/tree/main/examples/hello-world-js&#34;&gt;TypeScript&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/e2b-dev/e2b-cookbook/tree/main/examples/hello-world-python&#34;&gt;Python&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;LLM Providers&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🪸 &lt;a href=&#34;https://github.com/e2b-dev/e2b-cookbook/raw/main/examples/claude-code-interpreter/claude_code_interpreter.ipynb&#34;&gt;Claude with code intepreter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;🦙 &lt;a href=&#34;https://github.com/e2b-dev/e2b-cookbook/tree/main/examples/llama-3-code-interpreter&#34;&gt;Llama 3 with code interpreter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/e2b-dev/e2b-cookbook/tree/main/templates/mixtral-8x7b-code-interpreter-nextjs&#34;&gt;Mixtral with code interpreter and chat UI&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;AI Frameworks&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🦜⛓️ &lt;a href=&#34;https://github.com/e2b-dev/e2b-cookbook/tree/main/examples/langchain-python&#34;&gt;LangChain with code interpreter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;🦜🕸️ &lt;a href=&#34;https://github.com/e2b-dev/e2b-cookbook/tree/main/examples/langgraph-python&#34;&gt;LangGraph with code interpreter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/e2b-dev/e2b-cookbook/tree/main/examples/e2b_autogen&#34;&gt;Autogen with secure sandboxed code interpreter&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;💻 Supported languages for AI-code execution&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;✅ Python&lt;/li&gt; &#xA; &lt;li&gt;(soon) JavaScript/TypeScript&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>