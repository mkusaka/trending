<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-27T01:41:19Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>microsoft/Olive</title>
    <updated>2023-05-27T01:41:19Z</updated>
    <id>tag:github.com,2023-05-27:/microsoft/Olive</id>
    <link href="https://github.com/microsoft/Olive" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Olive is an easy-to-use hardware-aware model optimization tool that composes industry-leading techniques across model compression, optimization, and compilation.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Olive&lt;/h1&gt; &#xA;&lt;p&gt;Olive is an easy-to-use hardware-aware model optimization tool that composes industry-leading techniques across model compression, optimization, and compilation. Given a model and targeted hardware, Olive composes the best suitable optimization techniques to output the most efficient model(s) for inferencing on cloud or edge, while taking a set of constraints such as accuracy and latency into consideration.&lt;/p&gt; &#xA;&lt;p&gt;Since every ML accelerator vendor implements their own acceleration tool chains to make the most of their hardware, hardware-aware optimizations are fragmented. With Olive, we can:&lt;/p&gt; &#xA;&lt;p&gt;Reduce engineering effort for optimizing models for cloud and edge: Developers are required to learn and utilize multiple hardware vendor-specific toolchains in order to prepare and optimize their trained model for deployment. Olive aims to simplify the experience by aggregating and automating optimization techniques for the desired hardware targets.&lt;/p&gt; &#xA;&lt;p&gt;Build up a unified optimization framework: Given that no single optimization technique serves all scenarios well, Olive enables an extensible framework that allows industry to easily plugin their optimization innovations. Olive can efficiently compose and tune integrated techniques for offering a ready-to-use E2E optimization solution.&lt;/p&gt; &#xA;&lt;h2&gt;Get Started and Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Documentation: &lt;a href=&#34;https://microsoft.github.io/Olive&#34;&gt;https://microsoft.github.io/Olive&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Examples: &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/Olive/main/examples&#34;&gt;examples&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;We recommend installing Olive in a &lt;a href=&#34;https://docs.python.org/3/library/venv.html&#34;&gt;virtual environment&lt;/a&gt; or a &lt;a href=&#34;https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html&#34;&gt;conda environment&lt;/a&gt;. Olive is installed using pip.&lt;/p&gt; &#xA;&lt;p&gt;Create a virtual/conda environment with the desired version of Python and activate it.&lt;/p&gt; &#xA;&lt;p&gt;You will need to install a build of &lt;a href=&#34;https://onnxruntime.ai&#34;&gt;&lt;strong&gt;onnxruntime&lt;/strong&gt;&lt;/a&gt;. You can install the desired build separately but public versions of onnxruntime can also be installed as extra dependencies during Olive installation.&lt;/p&gt; &#xA;&lt;h3&gt;Install with pip&lt;/h3&gt; &#xA;&lt;p&gt;Olive is available for installation from PyPI.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install olive-ai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;With onnxruntime (Default CPU):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install olive-ai[cpu]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;With onnxruntime-gpu:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install olive-ai[gpu]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;With onnxruntime-directml:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install olive-ai[directml]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Optional Dependencies&lt;/h3&gt; &#xA;&lt;p&gt;Olive has optional dependencies that can be installed to enable additional features. These dependencies can be installed as extras:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;azureml&lt;/strong&gt;: To enable AzureML integration. Packages: &lt;code&gt;azure-ai-ml, azure-identity&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;docker&lt;/strong&gt;: To enable docker integration. Packages: &lt;code&gt;docker&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;openvino&lt;/strong&gt;: To use OpenVINO related passes. Packages: &lt;code&gt;openvino==2022.3.0, openvino-dev[tensorflow,onnx]==2022.3.0&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Weâ€™d love to embrace your contribution to Olive. Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/Olive/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Formatting&lt;/h3&gt; &#xA;&lt;p&gt;Olive uses pre-commit hooks to check and format code. To install the pre-commit hooks, run the following commands from the root of the repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# install pre-commit and other dev requirements&#xA;python -m pip install pre-commit&#xA;# install the git hook scripts&#xA;pre-commit install&#xA;# for the first time, run on all files&#xA;pre-commit run --all-files&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Everytime you make a git commit, the hooks will automatically point out issues in code for changed files and fix them if possible.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright (c) Microsoft Corporation. All rights reserved.&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/Olive/main/LICENSE&#34;&gt;MIT&lt;/a&gt; License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>homanp/superagent</title>
    <updated>2023-05-27T01:41:19Z</updated>
    <id>tag:github.com,2023-05-27:/homanp/superagent</id>
    <link href="https://github.com/homanp/superagent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ðŸ¥· SuperAgent - Deploy LLM Agents to production&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SuperAgent ðŸ¥·&lt;/h1&gt; &#xA;&lt;p&gt; &lt;img alt=&#34;GitHub Contributors&#34; src=&#34;https://img.shields.io/github/contributors/homanp/superagent&#34;&gt; &lt;img alt=&#34;GitHub Last Commit&#34; src=&#34;https://img.shields.io/github/last-commit/homanp/superagent&#34;&gt; &lt;img alt=&#34;&#34; src=&#34;https://img.shields.io/github/repo-size/homanp/superagent&#34;&gt; &lt;img alt=&#34;GitHub Issues&#34; src=&#34;https://img.shields.io/github/issues/homanp/superagent&#34;&gt; &lt;img alt=&#34;GitHub Pull Requests&#34; src=&#34;https://img.shields.io/github/issues-pr/homanp/superagent&#34;&gt; &lt;img alt=&#34;Github License&#34; src=&#34;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&#34;&gt; &lt;img alt=&#34;Discord&#34; src=&#34;https://img.shields.io/discord/1110910277110743103?label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=plastic&amp;amp;color=d7b023)%5D(https://discord.gg/e8j7mgjDUK&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;SuperAgent is a powerful tool that simplifies the configuration and deployment of LLM (Large Language Model) Agents to production. It provides a range of features and functionalities to make it easier for developers to build, manage and deploy AI agents to production including features such as built in memory and document retrieval via vector dbs.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Checkout the &lt;a href=&#34;https://docs.superagent.sh/&#34;&gt;full documentation here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;p&gt;Here&#39;s an overview of the roadmap for SuperAgent:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Bring your own DB:&lt;/strong&gt; SuperAgent allows you to use your own database to store agent-related data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Authentication:&lt;/strong&gt; Authentication mechanisms are implemented to secure the SuperAgent application.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;ChatGPT clone:&lt;/strong&gt; SuperAgent supports chatGPT-like conversational AI.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Built-in memory:&lt;/strong&gt; SuperAgent has a built-in memory to give context and history to the LLM.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;REST API:&lt;/strong&gt; All functionality is exposed by a REST API.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Support for multiple LLMs:&lt;/strong&gt; SuperAgent supports multiple Language Models, allowing you to choose the most suitable one for your needs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Streaming support:&lt;/strong&gt; SuperAgent supports streaming conversations for real-time communication.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Built-in vectorstore:&lt;/strong&gt; SuperAgent includes a built-in vector store for efficient vector-based search and retrieval.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Built-in document retrieval:&lt;/strong&gt; SuperAgent offers document retrieval capabilities.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Q&amp;amp;A Agents:&lt;/strong&gt; SuperAgent supports the creation of Q&amp;amp;A agents for question answering over documents.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Prompt management:&lt;/strong&gt; SuperAgent includes features for managing and configuring prompts for the agents.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;Tools:&lt;/strong&gt; SuperAgent will include a wide variety of tools that enable the LLM to access the outside world.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;ReAct Agents with Tools:&lt;/strong&gt; SuperAgent enables the creation of reactive agents with the help of provided tools.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;Plan-solve Agents with Tools:&lt;/strong&gt; SuperAgent supports the creation of plan-solve agents with the help of provided tools.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;Bring your own LLM:&lt;/strong&gt; SuperAgent allows you to bring your own Language Model to use with the platform.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;Usage quotas and tracking:&lt;/strong&gt; SuperAgent provides usage quotas and tracking mechanisms for better resource management.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;Python SDK:&lt;/strong&gt; SuperAgent offers a Python Software Development Kit (SDK) for easier integration and development.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;Javascript SDK:&lt;/strong&gt; SuperAgent provides a Javascript SDK for developers who prefer using Javascript.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;NodeJS SDK:&lt;/strong&gt; SuperAgent provides a NodeJS SDK for developers who prefer using Node.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;SuperAgent CLI:&lt;/strong&gt; SuperAgent includes a command-line interface (CLI) for managing and deploying agents.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;One-click deploy (GCP, Amazon, DigitalOcean):&lt;/strong&gt; SuperAgent aims to provide a one-click deploy feature for popular cloud platforms like GCP, Amazon, and DigitalOcean.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Stack&lt;/h2&gt; &#xA;&lt;p&gt;SuperAgent is built on the following technologies and frameworks:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fastapi.tiangolo.com/&#34;&gt;FastAPI&lt;/a&gt;: A modern, fast (high-performance) web framework for building APIs with Python.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://supabase.com/&#34;&gt;Supabase&lt;/a&gt;: An open-source alternative to Firebase that provides a suite of tools for building scalable applications.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://python.langchain.com/en/latest/&#34;&gt;LangChain&lt;/a&gt;: A Python library for natural language processing and understanding.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.prisma.io/&#34;&gt;Prisma&lt;/a&gt;: A modern database toolkit that simplifies database access and management.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pinecone.io/&#34;&gt;Pinecone&lt;/a&gt;: A vector database that enables fast similarity search and retrieval.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To get started with SuperAgent, follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Clone the SuperAgent repository into a public GitHub repository or fork it from &lt;a href=&#34;https://github.com/homanp/superagent/fork&#34;&gt;https://github.com/homanp/superagent/fork&lt;/a&gt;. If you plan to distribute the code, keep the source code public.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/homanp/superagent.git&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To run the script, simply execute it using:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bash setup.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Deployment&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cloud.digitalocean.com/apps/new?repo=https://github.com/homanp/superagent/tree/main&#34;&gt;&lt;img src=&#34;https://www.deploytodo.com/do-btn-blue.svg?sanitize=true&#34; alt=&#34;Deploy to DO&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributions&lt;/h2&gt; &#xA;&lt;p&gt;SuperAgent is an open-source project, and contributions are welcome. If you would like to contribute, you can create new features, fix bugs, or improve the infrastructure. Please refer to the &lt;a href=&#34;https://github.com/homanp/superagent/raw/main/.github/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; file in the repository for more information on how to contribute.&lt;/p&gt; &#xA;&lt;p&gt;We appreciate your contributions and aim to make it easy for anyone to create and run LLM Agents in production using SuperAgent.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>YBYBZhang/ControlVideo</title>
    <updated>2023-05-27T01:41:19Z</updated>
    <id>tag:github.com,2023-05-27:/YBYBZhang/ControlVideo</id>
    <link href="https://github.com/YBYBZhang/ControlVideo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official pytorch implementation of &#34;ControlVideo: Training-free Controllable Text-to-Video Generation&#34;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ControlVideo&lt;/h1&gt; &#xA;&lt;p&gt;Official pytorch implementation of &#34;ControlVideo: Training-free Controllable Text-to-Video Generation&#34;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.13077&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2305.13077-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://visitor-badge.laobi.icu/badge?page_id=YBYBZhang/ControlVideo&#34; alt=&#34;visitors&#34;&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/overview.png&#34; width=&#34;1080px&#34;&gt; &lt;br&gt; &lt;em&gt;ControlVideo adapts ControlNet to the video counterpart without any finetuning, aiming to directly inherit its high-quality and consistent generation &lt;/em&gt; &lt;/p&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[05/25/2023] Code &lt;a href=&#34;https://github.com/YBYBZhang/ControlVideo/&#34;&gt;ControlVideo&lt;/a&gt; released!&lt;/li&gt; &#xA; &lt;li&gt;[05/23/2023] Paper &lt;a href=&#34;https://arxiv.org/abs/2305.13077&#34;&gt;ControlVideo&lt;/a&gt; released!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;h3&gt;1. Download Weights&lt;/h3&gt; &#xA;&lt;p&gt;All pre-trained weights are downloaded to &lt;code&gt;checkpoints/&lt;/code&gt; directory, including the pre-trained weights of &lt;a href=&#34;https://huggingface.co/runwayml/stable-diffusion-v1-5&#34;&gt;Stable Diffusion v1.5&lt;/a&gt;, ControlNet conditioned on &lt;a href=&#34;https://huggingface.co/lllyasviel/sd-controlnet-canny&#34;&gt;canny edges&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/lllyasviel/sd-controlnet-depth&#34;&gt;depth maps&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/lllyasviel/sd-controlnet-openpose&#34;&gt;human poses&lt;/a&gt;. The &lt;code&gt;flownet.pkl&lt;/code&gt; is the weights of &lt;a href=&#34;https://github.com/megvii-research/ECCV2022-RIFE&#34;&gt;RIFE&lt;/a&gt;. The final file tree likes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-none&#34;&gt;checkpoints&#xA;â”œâ”€â”€ stable-diffusion-v1-5&#xA;â”œâ”€â”€ sd-controlnet-canny&#xA;â”œâ”€â”€ sd-controlnet-depth&#xA;â”œâ”€â”€ sd-controlnet-openpose&#xA;â”œâ”€â”€ flownet.pkl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Requirements&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda create -n controlvideo python=3.10&#xA;conda activate controlvideo&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;xformers&lt;/code&gt; is recommended to save memory and running time.&lt;/p&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;p&gt;To perform text-to-video generation, just run this command in &lt;code&gt;inference.sh&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python inference.py \&#xA;    --prompt &#34;A striking mallard floats effortlessly on the sparkling pond.&#34; \&#xA;    --condition &#34;depth&#34; \&#xA;    --video_path &#34;data/mallard-water.mp4&#34; \&#xA;    --output_path &#34;outputs/&#34; \&#xA;    --video_length 15 \&#xA;    --smoother_steps 19 20 \&#xA;    # --is_long_video&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;--video_length&lt;/code&gt; is the length of synthesized video, &lt;code&gt;--condition&lt;/code&gt; represents the type of structure sequence, &lt;code&gt;--smoother_steps&lt;/code&gt; determines at which timesteps to perform smoothing, and &lt;code&gt;--is_long_video&lt;/code&gt; denotes whether to enable efficient long-video synthesis.&lt;/p&gt; &#xA;&lt;h2&gt;Visualizations&lt;/h2&gt; &#xA;&lt;h3&gt;ControlVideo on depth maps&lt;/h3&gt; &#xA;&lt;table class=&#34;center&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/depth/A_charming_flamingo_gracefully_wanders_in_the_calm_and_serene_water,_its_delicate_neck_curving_into_an_elegant_shape..gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/depth/A_striking_mallard_floats_effortlessly_on_the_sparkling_pond..gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/depth/A_gigantic_yellow_jeep_slowly_turns_on_a_wide,_smooth_road_in_the_city..gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&#34;A charming flamingo gracefully wanders in the calm and serene water, its delicate neck curving into an elegant shape.&#34;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&#34;A striking mallard floats effortlessly on the sparkling pond.&#34;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&#34;A gigantic yellow jeep slowly turns on a wide, smooth road in the city.&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/depth/A_sleek_boat_glides_effortlessly_through_the_shimmering_river,_van_gogh_style..gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/depth/A_majestic_sailing_boat_cruises_along_the_vast,_azure_sea..gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/depth/A_contented_cow_ambles_across_the_dewy,_verdant_pasture..gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&#34;A sleek boat glides effortlessly through the shimmering river, van gogh style.&#34;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&#34;A majestic sailing boat cruises along the vast, azure sea.&#34;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&#34;A contented cow ambles across the dewy, verdant pasture.&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;ControlVideo on canny edges&lt;/h3&gt; &#xA;&lt;table class=&#34;center&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/canny/A_young_man_riding_a_sleek,_black_motorbike_through_the_winding_mountain_roads..gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/canny/A_white_swan_moving_on_the_lake,_cartoon_style..gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/canny/A_dusty_old_jeep_was_making_its_way_down_the_winding_forest_road,_creaking_and_groaning_with_each_bump_and_turn..gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&#34;A young man riding a sleek, black motorbike through the winding mountain roads.&#34;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&#34;A white swan movingon the lake, cartoon style.&#34;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&#34;A dusty old jeep was making its way down the winding forest road, creaking and groaning with each bump and turn.&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/canny/A_shiny_red_jeep_smoothly_turns_on_a_narrow,_winding_road_in_the_mountains..gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/canny/A_majestic_camel_gracefully_strides_across_the_scorching_desert_sands..gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/canny/A_fit_man_is_leisurely_hiking_through_a_lush_and_verdant_forest..gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&#34;A shiny red jeep smoothly turns on a narrow, winding road in the mountains.&#34;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&#34;A majestic camel gracefully strides across the scorching desert sands.&#34;&lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34; align=&#34;center&#34;&gt;&#34;A fit man is leisurely hiking through a lush and verdant forest.&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;ControlVideo on human poses&lt;/h3&gt; &#xA;&lt;table class=&#34;center&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;25%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/pose/James_bond_moonwalk_on_the_beach,_animation_style.gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;25%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/pose/Goku_in_a_mountain_range,_surreal_style..gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;25%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/pose/Hulk_is_jumping_on_the_street,_cartoon_style.gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;25%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/pose/A_robot_dances_on_a_road,_animation_style.gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;25%&#34; align=&#34;center&#34;&gt;&#34;James bond moonwalk on the beach, animation style.&#34;&lt;/td&gt; &#xA;   &lt;td width=&#34;25%&#34; align=&#34;center&#34;&gt;&#34;Goku in a mountain range, surreal style.&#34;&lt;/td&gt; &#xA;   &lt;td width=&#34;25%&#34; align=&#34;center&#34;&gt;&#34;Hulk is jumping on the street, cartoon style.&#34;&lt;/td&gt; &#xA;   &lt;td width=&#34;25%&#34; align=&#34;center&#34;&gt;&#34;A robot dances on a road, animation style.&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt;&#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Long video generation&lt;/h3&gt; &#xA;&lt;table class=&#34;center&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;60%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/long/A_steamship_on_the_ocean,_at_sunset,_sketch_style.gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;40%&#34; align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/YBYBZhang/ControlVideo/master/assets/long/Hulk_is_dancing_on_the_beach,_cartoon_style.gif&#34; raw=&#34;true&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;60%&#34; align=&#34;center&#34;&gt;&#34;A steamship on the ocean, at sunset, sketch style.&#34;&lt;/td&gt; &#xA;   &lt;td width=&#34;40%&#34; align=&#34;center&#34;&gt;&#34;Hulk is dancing on the beach, cartoon style.&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you make use of our work, please cite our paper.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{zhang2023controlvideo,&#xA;  title={ControlVideo: Training-free Controllable Text-to-Video Generation},&#xA;  author={Zhang, Yabo and Wei, Yuxiang and Jiang, Dongsheng and Zhang, Xiaopeng and Zuo, Wangmeng and Tian, Qi},&#xA;  journal={arXiv preprint arXiv:2305.13077},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;This work repository borrows heavily from &lt;a href=&#34;https://github.com/huggingface/diffusers&#34;&gt;Diffusers&lt;/a&gt;, &lt;a href=&#34;https://github.com/lllyasviel/ControlNet&#34;&gt;ControlNet&lt;/a&gt;, &lt;a href=&#34;https://github.com/showlab/Tune-A-Video&#34;&gt;Tune-A-Video&lt;/a&gt;, and &lt;a href=&#34;https://github.com/megvii-research/ECCV2022-RIFE&#34;&gt;RIFE&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;There are also many interesting works on video generation: &lt;a href=&#34;https://github.com/showlab/Tune-A-Video&#34;&gt;Tune-A-Video&lt;/a&gt;, &lt;a href=&#34;https://github.com/Picsart-AI-Research/Text2Video-Zero&#34;&gt;Text2Video-Zero&lt;/a&gt;, &lt;a href=&#34;https://github.com/mayuelala/FollowYourPose&#34;&gt;Follow-Your-Pose&lt;/a&gt;, &lt;a href=&#34;https://github.com/Weifeng-Chen/control-a-video&#34;&gt;Control-A-Video&lt;/a&gt;, et al.&lt;/p&gt;</summary>
  </entry>
</feed>