<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-19T01:41:48Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>shyamsn97/mario-gpt</title>
    <updated>2023-02-19T01:41:48Z</updated>
    <id>tag:github.com,2023-02-19:/shyamsn97/mario-gpt</id>
    <link href="https://github.com/shyamsn97/mario-gpt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Generating Mario Levels with GPT2. Code for the paper &#34;MarioGPT: Open-Ended Text2Level Generation through Large Language Models&#34; https://arxiv.org/abs/2302.05981&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;MarioGPT: Open-Ended Text2Level Generation through Large Language Models&lt;/h1&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.05981&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/paper-arxiv.2302.05981-B31B1B.svg?sanitize=true&#34; alt=&#34;Paper&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/mario-gpt&#34;&gt;&lt;img src=&#34;https://badgen.net/pypi/v/mario-gpt/&#34; alt=&#34;PyPi version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/multimodalart/mariogpt&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%20HuggingFace%20-Demo-blue.svg?sanitize=true&#34; alt=&#34;HuggingFace Spaces&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/drive/16KR9idJUim6RAiyPASoQAaC768AvOGxP?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/shyamsn97/mario-gpt/main/#interacting-with-levels&#34;&gt;Playing Generated Level&lt;/a&gt;&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Generated Level&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/shyamsn97/mario-gpt/main/static/example_interactive.gif&#34; alt=&#34;alt text&#34;&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/shyamsn97/mario-gpt/main/static/test_level.png&#34; alt=&#34;alt text&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;How does it work?&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Architecture&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Example Prompt Generations&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/shyamsn97/mario-gpt/main/static/architecture.png&#34; alt=&#34;alt text&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/shyamsn97/mario-gpt/main/static/prompt-samples.png&#34; alt=&#34;alt text&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;MarioGPT is a finetuned GPT2 model (specifically, &lt;a href=&#34;https://huggingface.co/distilgpt2&#34;&gt;distilgpt2&lt;/a&gt;), that is trained on a subset Super Mario Bros and Super Mario Bros: The Lost Levels levels, provided by &lt;a href=&#34;https://github.com/TheVGLC/TheVGLC&#34;&gt;The Video Game Level Corpus&lt;/a&gt;. MarioGPT is able to generate levels, guided by a simple text prompt. This generation is not perfect, but we believe this is a great first step more controllable and diverse level / environment generation.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;python3.8+&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;from pypi&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install mario-gpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or from source&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:shyamsn97/mario-gpt.git&#xA;python setup.py install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Generating Levels&lt;/h2&gt; &#xA;&lt;p&gt;Since our models are built off of the amazing &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;transformers&lt;/a&gt; library, we host our model in &lt;a href=&#34;https://huggingface.co/shyamsn97/Mario-GPT2-700-context-length&#34;&gt;https://huggingface.co/shyamsn97/Mario-GPT2-700-context-length&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This code snippet is the minimal code you need to generate a mario level!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mario_gpt import MarioLM, SampleOutput&#xA;&#xA;# pretrained_model = shyamsn97/Mario-GPT2-700-context-length&#xA;&#xA;mario_lm = MarioLM()&#xA;&#xA;# use cuda to speed stuff up&#xA;# import torch&#xA;# device = torch.device(&#39;cuda&#39;)&#xA;# mario_lm = mario_lm.to(device)&#xA;&#xA;prompts = [&#34;many pipes, many enemies, some blocks, high elevation&#34;]&#xA;&#xA;# generate level of size 1400, pump temperature up to ~2.4 for more stochastic but playable levels&#xA;generated_level = mario_lm.sample(&#xA;    prompts=prompts,&#xA;    num_steps=1400,&#xA;    temperature=2.0,&#xA;    use_tqdm=True&#xA;)&#xA;&#xA;# show string list&#xA;generated_level.level&#xA;&#xA;# show PIL image&#xA;generated_level.img&#xA;&#xA;# save image&#xA;generated_level.img.save(&#34;generated_level.png&#34;)&#xA;&#xA;# save text level to file&#xA;generated_level.save(&#34;generated_level.txt&#34;)&#xA;&#xA;# play in interactive&#xA;generated_level.play()&#xA;&#xA;# run Astar agent&#xA;generated_level.run_astar()&#xA;&#xA;# load from text file&#xA;loaded_level = SampleOutput.load(&#34;generated_level.txt&#34;)&#xA;&#xA;# play from loaded (should be the same level that we generated)&#xA;loaded_level.play()&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/shyamsn97/mario-gpt/main/notebooks/Sampling.ipynb&#34;&gt;notebook&lt;/a&gt; for a more in depth tutorial to generate levels&lt;/h5&gt; &#xA;&lt;h2&gt;Interacting with Levels&lt;/h2&gt; &#xA;&lt;p&gt;Right now there are two ways to interact with generated levels:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/spaces/multimodalart/mariogpt&#34;&gt;Huggingface demo&lt;/a&gt; -- Thanks to the amazing work by &lt;a href=&#34;https://github.com/multimodalart&#34;&gt;multimodalart&lt;/a&gt;, you can generate and play levels interactively in the browser! In addition, gpus are provided so you don&#39;t have to own one yourself.&lt;/li&gt; &#xA; &lt;li&gt;Using the &lt;a href=&#34;https://raw.githubusercontent.com/shyamsn97/mario-gpt/main/mario_gpt/simulator/simulator.py&#34;&gt;play and astar methods&lt;/a&gt;. These require you to have java installed on your computer (Java 8+ tested). For interactive, use the &lt;code&gt;play()&lt;/code&gt; method and for astar use the &lt;code&gt;run_astar&lt;/code&gt; method. Example:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mario_gpt import MarioLM&#xA;&#xA;mario_lm = MarioLM()&#xA;&#xA;prompts = [&#34;many pipes, many enemies, some blocks, high elevation&#34;]&#xA;&#xA;generated_level = mario_lm.sample(&#xA;    prompts=prompts,&#xA;    num_steps=1400,&#xA;    temperature=2.0,&#xA;    use_tqdm=True&#xA;)&#xA;&#xA;# play in interactive&#xA;generated_level.play()&#xA;&#xA;# run Astar agent&#xA;generated_level.run_astar()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Future Plans&lt;/h2&gt; &#xA;&lt;p&gt;Here&#39;s a list of some stuff that will be added to the codebase!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Basic inference code&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add MarioBert Model&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add Interactive simulator&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Inpainting functionality from paper&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Open-ended level generation code&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Training code from paper&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Different generation methods (eg. constrained beam search, etc.)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Authors&lt;/h2&gt; &#xA;&lt;p&gt;Shyam Sudhakaran &lt;a href=&#34;mailto:shyamsnair@protonmail.com&#34;&gt;shyamsnair@protonmail.com&lt;/a&gt;, &lt;a href=&#34;https://github.com/shyamsn97&#34;&gt;https://github.com/shyamsn97&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Miguel Gonz√°lez-Duque &lt;a href=&#34;mailto:migd@itu.dk&#34;&gt;migd@itu.dk&lt;/a&gt;, &lt;a href=&#34;https://github.com/miguelgondu&#34;&gt;https://github.com/miguelgondu&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Claire Glanois &lt;a href=&#34;mailto:clgl@itu.dk&#34;&gt;clgl@itu.dk&lt;/a&gt;, &lt;a href=&#34;https://github.com/claireaoi&#34;&gt;https://github.com/claireaoi&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Matthias Freiberger &lt;a href=&#34;mailto:matfr@itu.dk&#34;&gt;matfr@itu.dk&lt;/a&gt;, &lt;a href=&#34;https://github.com/matfrei&#34;&gt;https://github.com/matfrei&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Elias Najarro &lt;a href=&#34;mailto:enaj@itu.dk&#34;&gt;enaj@itu.dk&lt;/a&gt;, &lt;a href=&#34;https://github.com/enajx&#34;&gt;https://github.com/enajx&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Sebastian Risi &lt;a href=&#34;mailto:sebr@itu.dk&#34;&gt;sebr@itu.dk&lt;/a&gt;, &lt;a href=&#34;https://github.com/sebastianrisi&#34;&gt;https://github.com/sebastianrisi&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you use the code for academic or commecial use, please cite the associated paper:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{https://doi.org/10.48550/arxiv.2302.05981,&#xA;  doi = {10.48550/ARXIV.2302.05981},&#xA;  &#xA;  url = {https://arxiv.org/abs/2302.05981},&#xA;  &#xA;  author = {Sudhakaran, Shyam and Gonz√°lez-Duque, Miguel and Glanois, Claire and Freiberger, Matthias and Najarro, Elias and Risi, Sebastian},&#xA;  &#xA;  keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},&#xA;  &#xA;  title = {MarioGPT: Open-Ended Text2Level Generation through Large Language Models},&#xA;  &#xA;  publisher = {arXiv},&#xA;  &#xA;  year = {2023},&#xA;  &#xA;  copyright = {arXiv.org perpetual, non-exclusive license}&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>mukulpatnaik/researchgpt</title>
    <updated>2023-02-19T01:41:48Z</updated>
    <id>tag:github.com,2023-02-19:/mukulpatnaik/researchgpt</id>
    <link href="https://github.com/mukulpatnaik/researchgpt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An open-source LLM based research assistant that allows you to have a conversation with a research paper&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ResearchGPT&lt;/h1&gt; &#xA;&lt;p&gt;This is a flask app provides an interface to enable a conversation with a research paper. You can enter a link to a pdf hosted online or upload your own pdf. The app will then extract the text from the pdf, create embeddings from the text and use them with the openai api to generate a response to a question you ask. It will also return a source for the part of the text it used to generate the response and the page number.&lt;/p&gt; &#xA;&lt;p&gt;Edit: the demo has been temporarily taken down due to high costs of maintainance and calling the openai API. Cuurrently working on a way for the user to use their own API key.&lt;/p&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/36257370/218764852-32b79201-4767-4684-980a-73aa81e7d72a.mp4&#34;&gt;https://user-images.githubusercontent.com/36257370/218764852-32b79201-4767-4684-980a-73aa81e7d72a.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/mukulpatnaik/researchgpt.git&#xA;cd researchgpt&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;You need to have an openai api key and set it as the environment variable &#39;OPENAI_API_KEY&#39;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main-local.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Google Cloud Deployment&lt;/h2&gt; &#xA;&lt;p&gt;Follow the instructions here: &lt;a href=&#34;https://cloud.google.com/appengine/docs/standard/python3/building-app/deploying-web-service&#34;&gt;https://cloud.google.com/appengine/docs/standard/python3/building-app/deploying-web-service&lt;/a&gt; Once you have the app.yaml file set up with your openai key and also have gcloud cli set up, you can deploy with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcloud app deploy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To stream logs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcloud app logs tail&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>Guiflayrom/yolnp</title>
    <updated>2023-02-19T01:41:48Z</updated>
    <id>tag:github.com,2023-02-19:/Guiflayrom/yolnp</id>
    <link href="https://github.com/Guiflayrom/yolnp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Yolnp is a project based in YOLO to detect plates&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;YOLNP - You Only Look Number Plates&lt;/h1&gt; &#xA;&lt;p&gt;Buy me a coffee :D -&amp;gt; &lt;a href=&#34;https://www.buymeacoffee.com/guiflayrom&#34;&gt;https://www.buymeacoffee.com/guiflayrom&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;YOLNP - You Only Look Number Plates - It is a full stack project created, idealized, designed, codified by the owner of this repository. YOLNP was my first project since I decided to create my Github account. It was started in 2020, when I was 15 years old, and finally finished it now at my 18 years old, so I have a fondness for everything it has been through, and now it&#39;s time to leave it opensource ;)&lt;/p&gt; &#xA;&lt;p&gt;YOLNP was developed with the intention of being useful for personal surveillance and data science for physical companies that are located on highways.&lt;/p&gt; &#xA;&lt;h1&gt;Screens&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/YhQN8ST.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Dashboard&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Guiflayrom/yolnp/raw/master/resource/dashboard.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;All Plates Detected&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Guiflayrom/yolnp/raw/master/resource/all_plates.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Alerts Configuration&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Guiflayrom/yolnp/raw/master/resource/alerts_page.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Real Time&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Guiflayrom/yolnp/raw/master/resource/real_time.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Functionalities&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Process local videos and rtsp streams&lt;/li&gt; &#xA; &lt;li&gt;Start and stop the ALPR through requests located in a flask server&lt;/li&gt; &#xA; &lt;li&gt;Share a stream of image that is being processed&lt;/li&gt; &#xA; &lt;li&gt;Detect plates in your personal alerts list&lt;/li&gt; &#xA; &lt;li&gt;Check recurrenting plates&lt;/li&gt; &#xA; &lt;li&gt;View the plate picture when detected&lt;/li&gt; &#xA; &lt;li&gt;Run ALPR in Threading system&lt;/li&gt; &#xA; &lt;li&gt;Calculate median duration of plate in recorded videos&lt;/li&gt; &#xA; &lt;li&gt;Alert stealed cars by consulting (deprecated)&lt;/li&gt; &#xA; &lt;li&gt;Estimate median price of cars (deprecated)&lt;/li&gt; &#xA; &lt;li&gt;Get origin city of plate (deprecated)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Technologies&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;CVA -&amp;gt;&lt;/strong&gt; PaddleOCR, Tensorflow, Keras, OpenCV, Flask, Numpy...&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;SERVER -&amp;gt;&lt;/strong&gt; DRF, JWT, CORS..&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;CLIENT -&amp;gt;&lt;/strong&gt; Nuxt.js, Axios, Vuex, Vuex-Localstorage...&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>