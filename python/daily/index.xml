<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-04T01:43:11Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>AnTi-anti/damai_ticket</title>
    <updated>2023-03-04T01:43:11Z</updated>
    <id>tag:github.com,2023-03-04:/AnTi-anti/damai_ticket</id>
    <link href="https://github.com/AnTi-anti/damai_ticket" rel="alternate"></link>
    <summary type="html">&lt;p&gt;大麦网抢票脚本&lt;/p&gt;&lt;hr&gt;&lt;h3&gt;提前准备&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.6.3&lt;/li&gt; &#xA; &lt;li&gt;Chromedriver.exe&lt;/li&gt; &#xA; &lt;li&gt;Chrome 浏览器安装好后需将chromedriver.exe放置于Chrome浏览器目录下&lt;/li&gt; &#xA; &lt;li&gt;pip install selenium requests lxml&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;参数设置&lt;/h3&gt; &#xA;&lt;p&gt;在&lt;code&gt;config.json&lt;/code&gt;中输入相应配置信息，具体说明如下：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;date&lt;/code&gt;: 日期选择&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;sess&lt;/code&gt;: 场次优先级列表，如本例中共有三个场次，根据下表，则优先选择1，再选择2，最后选择3；也可以仅设置1个。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;price&lt;/code&gt;: 票价优先级，如本例中共有三档票价，根据下表，则优先选择1，再选择3；也可以仅设置1个。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;real_name&lt;/code&gt;: [1,2], 实名者序号，如本例中根据序号共选择两位实名者，根据序号，也可仅选择一位&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;选择一位或是多位根据购票需知要求，&lt;/li&gt; &#xA;   &lt;li&gt;若无需实名制信息则不需要填写，&lt;/li&gt; &#xA;   &lt;li&gt;若一个订单仅需提供一位购票人信息则选择一位，&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;若一张门票对应一位购票人信息则选择多位）。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;nick_name&lt;/code&gt;: 用户在大麦网的昵称，用于验证登录是否成功&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;ticket_num&lt;/code&gt;: 购买票数&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;damai_url&lt;/code&gt;: &lt;a href=&#34;https://www.damai.cn&#34;&gt;https://www.damai.cn&lt;/a&gt;, 大麦网官网网址&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;target_url&lt;/code&gt;: &lt;a href=&#34;https://detail.damai.cn/item.htm?id=599834886497&#34;&gt;https://detail.damai.cn/item.htm?id=599834886497&lt;/a&gt; 目标购票网址&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;部分门票需要选择城市，只需选择相应城市后将其网址复制到config.json文件的target_url参数即可。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;根据需要选择的场次和票价分别修改config.json文件中的sess和price参数。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;查看购票须知中实名制一栏，若无需实名制则config.json文件中的real_name参数不需要填写（即为[]）；若每笔订单只需一个证件号则real_name参数只需选择一个；若每张门票需要一个证件号，则real_name参数根据需购票数量进行相应添加。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;若是首次登录，根据终端输出的提示，依次点击登录、扫码登录，代码将自动保存cookie文件（cookie.pkl）&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;使用前请将待抢票者的姓名、手机、地址设为默认。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;配置完成后执行python damai_ticket.py即可,注意观察控制台输出。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;本代码为保证抢票顺利，设置循环直到抢票成功才退出循环，若中途需要退出程序请直接终止程序。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;更新&lt;/h3&gt; &#xA;&lt;p&gt;以下内容在博客：&lt;a href=&#34;https://blog.csdn.net/weixin_35770067/category_10688081.html&#34;&gt;https://blog.csdn.net/weixin_35770067/category_10688081.html&lt;/a&gt; 付费专栏进行更新&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2023.02.27：秀动解决本地时间和服务器时间不同步的bug&lt;/li&gt; &#xA; &lt;li&gt;2023.02.26：针对观演人选择与否进行代码优化&lt;/li&gt; &#xA; &lt;li&gt;2023.02.13: 大麦网支持捡漏&lt;/li&gt; &#xA; &lt;li&gt;2022.09.13：微店bug完善,大麦抢票采用接口重新开发中&lt;/li&gt; &#xA; &lt;li&gt;2022.08.30: 微店增加定时抢购和多账号抢购&lt;/li&gt; &#xA; &lt;li&gt;2022.08.09: 微店增加request接口写法，高成功率&lt;/li&gt; &#xA; &lt;li&gt;2022.08.04: 秀动、大麦增加QQ邮箱通知并修复已知bug&lt;/li&gt; &#xA; &lt;li&gt;2022.08.02: 微店支持选购多张票，增加方糖通知&lt;/li&gt; &#xA; &lt;li&gt;2022.07.27: 更新大麦滑块验证，自动识别&lt;/li&gt; &#xA; &lt;li&gt;2022.07.20：增加微店下单模块&lt;/li&gt; &#xA; &lt;li&gt;2022.07.17：增加微店抢票模块&lt;/li&gt; &#xA; &lt;li&gt;2022.07.10：增加下单页面验证码自动识别模块&lt;/li&gt; &#xA; &lt;li&gt;2022.04.20 更新正在现场抢票&lt;/li&gt; &#xA; &lt;li&gt;2022.03.13：修复抢票选座功能&lt;/li&gt; &#xA; &lt;li&gt;2022.01.28：更新秀动抢票&lt;/li&gt; &#xA; &lt;li&gt;2022.01.22：增加支持自动选座功能&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;订阅CSDN文章后有问题，可以添加我的联系方式&lt;/p&gt; &#xA;&lt;p&gt;感谢&lt;a href=&#34;https://github.com/ouyangjunfei?tab=repositories&#34;&gt;Fly1nDutchman&lt;/a&gt;在其他购票页面发现的问题，经过验证，我已经合并代码，特再次进行说明，表示感谢。&lt;/p&gt; &#xA;&lt;p&gt;修复1：支持关闭实名制遮罩&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;测试地址：&lt;a href=&#34;https://detail.damai.cn/item.htm?&amp;amp;id=662062693636&#34;&gt;https://detail.damai.cn/item.htm?&amp;amp;id=662062693636&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;500&#34; src=&#34;https://user-images.githubusercontent.com/37463338/145715661-56e0a495-2809-461e-beb2-7030fbe8e748.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;修复2：特惠场次有票但无法被选中的问题&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;测试地址： &lt;a href=&#34;https://detail.damai.cn/item.htm?id=659519464426&#34;&gt;https://detail.damai.cn/item.htm?id=659519464426&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;修复3：支持日期选择&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;500&#34; src=&#34;https://user-images.githubusercontent.com/37463338/145716541-e74a3624-7ebf-45c0-ae64-c30e2211af9e.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;热门演唱会信息&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://detail.damai.cn/item.htm?spm=a2oeg.search_category.0.0.57344206jb38CA&amp;amp;id=658630460380&amp;amp;clicktitle=%E8%96%9B%E4%B9%8B%E8%B0%A6%E2%80%9C%E5%A4%A9%E5%A4%96%E6%9D%A5%E7%89%A9%E2%80%9D%E5%B7%A1%E5%9B%9E%E6%BC%94%E5%94%B1%E4%BC%9A-%E5%B9%BF%E5%B7%9E%E7%AB%99&#34;&gt;薛之谦演唱会&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://detail.damai.cn/item.htm?spm=a2oeg.search_category.0.0.7e141ffaOOsGL3&amp;amp;id=660857675535&amp;amp;clicktitle=%E6%9D%8E%E8%8D%A3%E6%B5%A9%E2%80%9C%E9%BA%BB%E9%9B%80%E2%80%9D%E5%B7%A1%E5%9B%9E%E6%BC%94%E5%94%B1%E4%BC%9A%20%E5%B9%BF%E5%B7%9E%E7%AB%99&#34;&gt;李荣浩广州演唱会&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://detail.damai.cn/item.htm?spm=a2oeg.search_category.0.0.310919488fszNB&amp;amp;id=662432820667&amp;amp;clicktitle=%E4%BF%9D%E5%88%A9%C2%B7%E5%A4%AE%E5%8D%8E%E2%80%9C%E7%A5%9E%E5%B7%9E%E4%B9%9D%E5%9F%8E%EF%BC%8C%E5%85%B1%E4%BA%AB%E6%98%8E%E5%A4%A9%E2%80%9D2021%E6%BC%94%E5%87%BA%E8%A1%8C%E5%8A%A8%20%E5%A4%AE%E5%8D%8E%E7%89%88%E3%80%8A%E5%A6%82%E6%A2%A6%E4%B9%8B%E6%A2%A6%E3%80%8B&#34;&gt;北京保利·央华“神州九城，共享明天”2021演出行动 央华版 如梦之梦&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://m.damai.cn/damai/detail/item.html?itemId=607865020360&amp;amp;sqm=dianying.h5.unknown.value&amp;amp;spm=a2o71.project.0.i1&#34;&gt;周杰伦演唱会&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://detail.damai.cn/item.htm?id=704046634773&#34;&gt;张杰演唱会&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>LlmKira/Openaibot</title>
    <updated>2023-03-04T01:43:11Z</updated>
    <id>tag:github.com,2023-03-04:/LlmKira/Openaibot</id>
    <link href="https://github.com/LlmKira/Openaibot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Gpt-3.5-turbo/ChatGPT Chatbot/Voice Assistant | 📱Cross-Platform | 🦾 Async | 🗣 Good Contextual Support | 🌻 sh &amp; docker Deployment| 🔌API Server Provided| 🎤 Azure/Vits for Voice Chatting |🌎 Real-time Information Searching| 📷Multi-modal/Image Understanding | 💐Self-maintained LLM Framework&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;&lt;img src=&#34;https://raw.githubusercontent.com/LLMKira/Docs/main/docs/cover.png&#34; alt=&#34;cover&#34;&gt;&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img alt=&#34;License&#34; src=&#34;https://img.shields.io/badge/LICENSE-AGPL-ff69b4&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Python-3.8|9|10|11-green&#34; alt=&#34;Python&#34;&gt; &lt;a href=&#34;https://afdian.net/a/Suki1077&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Buyme-milk-DB94A2&#34; alt=&#34;SPONSOR&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.fossa.com/projects/git%2Bgithub.com%2Fsudoskys%2FOpenaibot?ref=badge_small&#34; alt=&#34;FOSSA Status&#34;&gt;&lt;img src=&#34;https://app.fossa.com/api/projects/git%2Bgithub.com%2Fsudoskys%2FOpenaibot.svg?type=small&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;OpenaiBot&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/LlmKira/Openaibot/raw/main/README_ZH.md&#34;&gt;中文&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;全平台，多模态(语音/图片)理解，自维护套件，实时信息支持&lt;/p&gt; &#xA;&lt;p&gt;If you don&#39;t have the instant messaging platform you need or you want to develop a new application, you are welcome to contribute to this repository. You can develop a new Controller by using &lt;code&gt;Event.py&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We use the self-maintained llm framework &lt;a href=&#34;https://github.com/LLMKira/llm-kira&#34;&gt;llm-kira&lt;/a&gt; to implement the conversation client.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please submit an issue/discussion if you have a deployment issue rather than emailing me&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🥽 Feature&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Async&lt;/li&gt; &#xA; &lt;li&gt;Support for rate limiting&lt;/li&gt; &#xA; &lt;li&gt;Support for private chats, group chats&lt;/li&gt; &#xA; &lt;li&gt;Support for black and white list system&lt;/li&gt; &#xA; &lt;li&gt;Support for usage management, persona, custom words style 🤖&lt;/li&gt; &#xA; &lt;li&gt;Memory pool guarantees 1000 rounds of contextual memory 💾&lt;/li&gt; &#xA; &lt;li&gt;Multi-platform, universal use, also supports local voice assistant 🗣️&lt;/li&gt; &#xA; &lt;li&gt;Multiple Api key polling pools for easy management and overflow pop-ups 📊&lt;/li&gt; &#xA; &lt;li&gt;Active search for content to reply to and support for Sticker replies 😊&lt;/li&gt; &#xA; &lt;li&gt;Universal interface for multi-platform support, theoretically allows access to any chat platform 🌐&lt;/li&gt; &#xA; &lt;li&gt;Content security removable components, also supports official Api content filtering 🔒&lt;/li&gt; &#xA; &lt;li&gt;Real-time web indexing support, universal crawler (supports UrlQueryHtml url?q={}) 🕸️&lt;/li&gt; &#xA; &lt;li&gt;Multimodal interaction support, image Blip comprehension support, voice recognition 👂 , sticker support 😎&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🪜 Deploy It&lt;/h2&gt; &#xA;&lt;h3&gt;🔨 Check&lt;/h3&gt; &#xA;&lt;p&gt;Make sure your server has 1GB of RAM and 10GB of free storage.&lt;/p&gt; &#xA;&lt;p&gt;For Arm architecture servers: &lt;code&gt;curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh&lt;/code&gt; (The setup.sh can now automatically install rust.)&lt;/p&gt; &#xA;&lt;h3&gt;📦 Deploy/Renew&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -LO https://raw.githubusercontent.com/LLMKira/Openaibot/main/setup.sh &amp;amp;&amp;amp; sh setup.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For Chinese users&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -LO https://raw.kgithub.com/LLMKira/Openaibot/main/setup.sh &amp;amp;&amp;amp; sh setup.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or &lt;a href=&#34;https://llmkira.github.io/Docs/guide/getting-started#docker&#34;&gt;Docker Deploy&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;🍽 Configure&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;set Redis&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;apt-get install redis&#xA;systemctl enable redis.service --now&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;edit bot config&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cp Config/app_exp.toml Config/app.toml&#xA;&#xA;nano Config/app.toml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;# Comment out which part you don&#39;t want to start&#xA;# 注释你不需要的部分&#xA;&#xA;# QQ Bot&#xA;[Controller.QQ]&#xA;master = [114, 514] # QQ number&#xA;account = 0  # Bot s QQ number&#xA;http_host = &#39;http://localhost:8080&#39;   # Mirai http Server&#xA;ws_host = &#39;http://localhost:8080&#39;   # Mirai Websocket Server&#xA;verify_key = &#34;&#34;&#xA;trigger = false # Proactive response when appropriate&#xA;INTRO = &#34;POWER BY OPENAI&#34;  # Suffixes for replies&#xA;ABOUT = &#34;Created by github.com/LLMKira/Openaibot&#34; # /about&#xA;WHITE = &#34;Group NOT in WHITE list&#34; # Whitelist/Blacklist tips&#xA;# Proxy set, but does not proxy openai api, only bot&#xA;proxy = { status = false, url = &#34;http://127.0.0.1:7890&#34; }&#xA;&#xA;# Telegram Bot&#xA;[Controller.Telegram]&#xA;master = [114, 514] # User Id @JsonDumpBot&#xA;botToken = &#39;&#39; # Bot Token @botfather&#xA;trigger = false&#xA;INTRO = &#34;POWER BY OPENAI&#34;&#xA;ABOUT = &#34;Created by github.com/LLMKira/Openaibot&#34;&#xA;WHITE = &#34;Group NOT in WHITE list&#34;&#xA;# 设置的代理，只代理 bot  openai api-&amp;gt;service.json &#xA;proxy = { status = false, url = &#34;http://127.0.0.1:7890&#34; }&#xA;&#xA;# 基础对话事件服务器，Web支持或者音箱用&amp;amp;Use by Voice Assistant&#xA;[Controller.BaseServer]&#xA;host = &#34;127.0.0.1&#34;&#xA;port = 9559&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want configure the backend or openai proxy. Please Check &lt;a href=&#34;https://llmkira.github.io/Docs/guide/service&#34;&gt;Deploy Docs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;🪶 App Token&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Telegram&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://t.me/BotFather&#34;&gt;Telegram BotToken Request&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Make sure &lt;em&gt;the bot is a group admin&lt;/em&gt; or &lt;em&gt;privacy mode is turned off&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;QQ&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://graiax.cn/before/install_mirai.html&#34;&gt;Configuring the QQ bot&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;🌻 Run Bot&lt;/h3&gt; &#xA;&lt;p&gt;Our robots can be started in multiple processes.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;apt install npm&#xA;npm install pm2@latest -g&#xA;# or&#xA;yarn global add pm2&#xA;&#xA;# test bot&#xA;python3 main.py&#xA;&#xA;# run bot&#xA;pm2 start pm2.json&#xA;&#xA;&#xA;pm2 status&#xA;&#xA;# stop bot&#xA;pm2 stop pm2.json&#xA;pm2 stop xx(id)&#xA;pm2 restart x(id)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once configured, send a message and use the &lt;code&gt;/add_white_user&lt;/code&gt; command to add your platform ID returned by the bot to the whitelist and you will be able to talk. Or use &lt;code&gt;/close_group_white_mode&lt;/code&gt; to turn off the bot&#39;s &lt;em&gt;group whitelist&lt;/em&gt; mode.&lt;/p&gt; &#xA;&lt;h3&gt;🎤 Or Run Voice Assistant&lt;/h3&gt; &#xA;&lt;p&gt;In addition to the robot, we also have a voice assistant.&lt;/p&gt; &#xA;&lt;p&gt;Voice Assistant is a web-dependent voice assistant that you can easily run on small devices through Azure or Openai&#39;s recognition services.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run BaseEvent Server&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;# 基础对话事件服务器，Web支持或者音箱用&#xA;[Controller.BaseServer]&#xA;port = 9559&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run Vits Server&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/LlmKira/MoeGoe&#34;&gt;https://github.com/LlmKira/MoeGoe&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run Assistant&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd Assistant&#xA;cat install.md&#xA;pip3 install -r requirements.txt&#xA;python3 clinet.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;🥕 Add Api Key&lt;/h3&gt; &#xA;&lt;p&gt;Use &lt;code&gt;/add_api_key&lt;/code&gt; Command add &lt;a href=&#34;https://beta.openai.com/account/api-keys&#34;&gt;OpenaiKey&lt;/a&gt; to &lt;code&gt;Config/api_keys.json&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;🫧 About ID&lt;/h3&gt; &#xA;&lt;p&gt;You&#39;ll be wondering about our multi-platform ID system. This is how we store your ID in our json/database: &lt;code&gt;real_id&lt;/code&gt; + &lt;code&gt;suffix&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;toml&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Use your real ID in &lt;code&gt;app.toml&lt;/code&gt;, which is the whitelist prompt without the suffix.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;json/command&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When using the user/group authorization command, you need to follow the real ID with the corresponding suffix ID.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Controller&lt;/th&gt; &#xA;   &lt;th&gt;suffix_id&lt;/th&gt; &#xA;   &lt;th&gt;desc&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;QQ&lt;/td&gt; &#xA;   &lt;td&gt;101&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Telegram&lt;/td&gt; &#xA;   &lt;td&gt;100&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Api&lt;/td&gt; &#xA;   &lt;td&gt;103&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;🥪 About Models&lt;/h3&gt; &#xA;&lt;h4&gt;ChatGpt&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;models&lt;/th&gt; &#xA;   &lt;th&gt;token limit&lt;/th&gt; &#xA;   &lt;th&gt;cost&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;gpt-3.5-turbo&lt;/td&gt; &#xA;   &lt;td&gt;4095&lt;/td&gt; &#xA;   &lt;td&gt;optimized for chat at 1/10th the cost of text-davinci-003.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;gpt-3.5-turbo-0301&lt;/td&gt; &#xA;   &lt;td&gt;4095&lt;/td&gt; &#xA;   &lt;td&gt;optimized for chat at 1/10th the cost of text-davinci-003.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;GPT3&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;models&lt;/th&gt; &#xA;   &lt;th&gt;token limit&lt;/th&gt; &#xA;   &lt;th&gt;cost&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;code-davinci-002&lt;/td&gt; &#xA;   &lt;td&gt;8000&lt;/td&gt; &#xA;   &lt;td&gt;During this initial limited beta period, Codex usage is free.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;code-cushman-001&lt;/td&gt; &#xA;   &lt;td&gt;2048&lt;/td&gt; &#xA;   &lt;td&gt;During this initial limited beta period, Codex usage is free.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;text-davinci-003&lt;/td&gt; &#xA;   &lt;td&gt;4000&lt;/td&gt; &#xA;   &lt;td&gt;$0.0200 /1K tokens&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;text-curie-001&lt;/td&gt; &#xA;   &lt;td&gt;2048&lt;/td&gt; &#xA;   &lt;td&gt;$0.0020 /1K tokens&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;text-babbage-001&lt;/td&gt; &#xA;   &lt;td&gt;2048&lt;/td&gt; &#xA;   &lt;td&gt;$0.0005 /1K tokens&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;text-ada-001&lt;/td&gt; &#xA;   &lt;td&gt;2048&lt;/td&gt; &#xA;   &lt;td&gt;$0.0004 /1K tokens&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;🌽 &lt;code&gt;/Config&lt;/code&gt; File&lt;/h3&gt; &#xA;&lt;p&gt;Our &lt;code&gt;llm-kira&lt;/code&gt; dependency library is stored in the current package directory when there is no Redis support.&lt;/p&gt; &#xA;&lt;p&gt;The application itself is stored in Redis for robustness, except for &lt;code&gt;api_keys.json&lt;/code&gt;, &lt;code&gt;service.json&lt;/code&gt; and &lt;code&gt;assistants.json&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you have &lt;code&gt;config.json&lt;/code&gt;, the application will automatically initialise this file. And you can update the configuration to this file using the &lt;code&gt;/config&lt;/code&gt; command.&lt;/p&gt; &#xA;&lt;h3&gt;🎸 Command&lt;/h3&gt; &#xA;&lt;p&gt;Due to lack of maintainers, some commands only work on some platforms.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;chat - talk&#xA;write - continue writing&#xA;forgetme - reset memory&#xA;remind - Scene setting cancel overwrite with short text&#xA;voice - voice support&#xA;style - set the preferred word&#xA;&#xA;trigger - Admin initiates unsolicited responses&#xA;trace - Admin activates automatic tracking of associated channels&#xA;cross - whether the Admin starts a cross-response&#xA;silent - Admin starts silent error reporting&#xA;&#xA;auto_adjust - automatic optimizer&#xA;set_user_cold - set user cooldown&#xA;set_group_cold - set group cooldown&#xA;set_token_limit - set output limit length&#xA;set_input_limit - set input limit length&#xA;see_api_key - Several Api keys now&#xA;del_api_key - Delete Api key&#xA;add_api_key - add Api key&#xA;config - get/backup hot configuration file&#xA;set_per_user_limit - set normal user limit&#xA;set_per_hour_limit - set user hour limit&#xA;promote_user_limit - Promote user limit&#xA;reset_user_usage - Reset user usage&#xA;add_block_group - block group&#xA;del_block_group - Unblock group&#xA;add_block_user - block user&#xA;del_block_user - Unblock user&#xA;add_white_group - add whitelist group&#xA;add_white_user - add whitelist user&#xA;del_white_group - delist whitelist group&#xA;del_white_user - remove whitelist user&#xA;update_detect - update sensitive words&#xA;open_user_white_mode - open user whitelist&#xA;open_group_white_mode - open group whitelist&#xA;close_user_white_mode - close user whitelist&#xA;close_group_white_mode - close group whitelist&#xA;open - open the robot&#xA;close - close the robot&#xA;change_head - set head switch&#xA;change_style - set the style switch&#xA;help - help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;🧀 More Docs&lt;/h3&gt; &#xA;&lt;p&gt;Details On &lt;a href=&#34;https://llmkira.github.io/Docs/en/guide/getting-started&#34;&gt;Deploy Guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Network Plugins/Proxy Settings/Custom Model Names/Speech Services/Picture Understanding/Censor Configuration Please see &lt;a href=&#34;https://llmkira.github.io/Docs/guide/service&#34;&gt;Service Configuration Guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;详细接口/服务配置/自定义 请查看文档 &lt;a href=&#34;https://llmkira.github.io/Docs/guide/getting-started&#34;&gt;Deploy Guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;贴纸设置/代理设置/切换其他模型/语音服务/图片理解/审查配置 请查看 &lt;a href=&#34;https://llmkira.github.io/Docs/guide/service&#34;&gt;服务配置&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🤗 Join Our Community&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/LLMKira/Openaibot/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=LLMKira/Openaibot&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;❤ Thanks&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/TelechaBot/BaseBot&#34;&gt;QuickDev&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/LLMKira/llm-kira&#34;&gt;LLM Kira&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/murray-z/text_analysis_tools&#34;&gt;text_analysis_tools&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CjangCjengh/MoeGoe&#34;&gt;MoeGoe Voice&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/deedy5&#34;&gt;duckduckgo_search&lt;/a&gt; @deedy5&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🍞 Other similar projects&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ChatGPT Mirai Bot is a QQ bot based on the ChatGPT Web Side Api&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/lss233/chatgpt-mirai-qq-bot&#34;&gt;https://github.com/lss233/chatgpt-mirai-qq-bot&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;📃 License&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;This project open source and available under&#xA;the [AGPL License](https://github.com/LLMKira/Openaibot/blob/main/LICENSE).&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/LlmKira/Openaibot/raw/main/CLAUSE.md&#34;&gt;CLAUSE&lt;/a&gt; 说明了如何授权，声明，附加条款等内容。&lt;/p&gt; &#xA;&lt;h3&gt;Fossa&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://app.fossa.com/projects/git%2Bgithub.com%2Fsudoskys%2FOpenaibot?ref=badge_large&#34;&gt;&lt;img src=&#34;https://app.fossa.com/api/projects/git%2Bgithub.com%2Fsudoskys%2FOpenaibot.svg?type=large&#34; alt=&#34;FOSSA Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;You wouldn&#39;t believe it, but Ai also wrote part of this Readme&lt;/p&gt; &#xA;&lt;/blockquote&gt;</summary>
  </entry>
  <entry>
    <title>openai/tiktoken</title>
    <updated>2023-03-04T01:43:11Z</updated>
    <id>tag:github.com,2023-03-04:/openai/tiktoken</id>
    <link href="https://github.com/openai/tiktoken" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;⏳ tiktoken&lt;/h1&gt; &#xA;&lt;p&gt;tiktoken is a fast &lt;a href=&#34;https://en.wikipedia.org/wiki/Byte_pair_encoding&#34;&gt;BPE&lt;/a&gt; tokeniser for use with OpenAI&#39;s models.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import tiktoken&#xA;enc = tiktoken.get_encoding(&#34;gpt2&#34;)&#xA;assert enc.decode(enc.encode(&#34;hello world&#34;)) == &#34;hello world&#34;&#xA;&#xA;# To get the tokeniser corresponding to a specific model in the OpenAI API:&#xA;enc = tiktoken.encoding_for_model(&#34;text-davinci-003&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The open source version of &lt;code&gt;tiktoken&lt;/code&gt; can be installed from PyPI:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install tiktoken&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The tokeniser API is documented in &lt;code&gt;tiktoken/core.py&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Example code using &lt;code&gt;tiktoken&lt;/code&gt; can be found in the &lt;a href=&#34;https://github.com/openai/openai-cookbook/raw/main/examples/How_to_count_tokens_with_tiktoken.ipynb&#34;&gt;OpenAI Cookbook&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Performance&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;tiktoken&lt;/code&gt; is between 3-6x faster than a comparable open source tokeniser:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/openai/tiktoken/main/perf.svg?sanitize=true&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Performance measured on 1GB of text using the GPT-2 tokeniser, using &lt;code&gt;GPT2TokenizerFast&lt;/code&gt; from &lt;code&gt;tokenizers==0.13.2&lt;/code&gt;, &lt;code&gt;transformers==4.24.0&lt;/code&gt; and &lt;code&gt;tiktoken==0.2.0&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Getting help&lt;/h2&gt; &#xA;&lt;p&gt;Please post questions in the &lt;a href=&#34;https://github.com/openai/tiktoken/issues&#34;&gt;issue tracker&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you work at OpenAI, make sure to check the internal documentation or feel free to contact @shantanu.&lt;/p&gt; &#xA;&lt;h2&gt;Extending tiktoken&lt;/h2&gt; &#xA;&lt;p&gt;You may wish to extend &lt;code&gt;tiktoken&lt;/code&gt; to support new encodings. There are two ways to do this.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Create your &lt;code&gt;Encoding&lt;/code&gt; object exactly the way you want and simply pass it around.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cl100k_base = tiktoken.get_encoding(&#34;cl100k_base&#34;)&#xA;&#xA;# In production, load the arguments directly instead of accessing private attributes&#xA;# See openai_public.py for examples of arguments for specific encodings&#xA;enc = tiktoken.Encoding(&#xA;    # If you&#39;re changing the set of special tokens, make sure to use a different name&#xA;    # It should be clear from the name what behaviour to expect.&#xA;    name=&#34;cl100k_im&#34;,&#xA;    pat_str=cl100k_base._pat_str,&#xA;    mergeable_ranks=cl100k_base._mergeable_ranks,&#xA;    special_tokens={&#xA;        **cl100k_base._special_tokens,&#xA;        &#34;&amp;lt;|im_start|&amp;gt;&#34;: 100264,&#xA;        &#34;&amp;lt;|im_end|&amp;gt;&#34;: 100265,&#xA;    }&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Use the &lt;code&gt;tiktoken_ext&lt;/code&gt; plugin mechanism to register your &lt;code&gt;Encoding&lt;/code&gt; objects with &lt;code&gt;tiktoken&lt;/code&gt;.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is only useful if you need &lt;code&gt;tiktoken.get_encoding&lt;/code&gt; to find your encoding, otherwise prefer option 1.&lt;/p&gt; &#xA;&lt;p&gt;To do this, you&#39;ll need to create a namespace package under &lt;code&gt;tiktoken_ext&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Layout your project like this, making sure to omit the &lt;code&gt;tiktoken_ext/__init__.py&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;my_tiktoken_extension&#xA;├── tiktoken_ext&#xA;│&amp;nbsp;&amp;nbsp; └── my_encodings.py&#xA;└── setup.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;my_encodings.py&lt;/code&gt; should be a module that contains a variable named &lt;code&gt;ENCODING_CONSTRUCTORS&lt;/code&gt;. This is a dictionary from an encoding name to a function that takes no arguments and returns arguments that can be passed to &lt;code&gt;tiktoken.Encoding&lt;/code&gt; to construct that encoding. For an example, see &lt;code&gt;tiktoken_ext/openai_public.py&lt;/code&gt;. For precise details, see &lt;code&gt;tiktoken/registry.py&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Your &lt;code&gt;setup.py&lt;/code&gt; should look something like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from setuptools import setup, find_namespace_packages&#xA;&#xA;setup(&#xA;    name=&#34;my_tiktoken_extension&#34;,&#xA;    packages=find_namespace_packages(include=[&#39;tiktoken_ext*&#39;]),&#xA;    install_requires=[&#34;tiktoken&#34;],&#xA;    ...&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then simply &lt;code&gt;pip install ./my_tiktoken_extension&lt;/code&gt; and you should be able to use your custom encodings! Make sure &lt;strong&gt;not&lt;/strong&gt; to use an editable install.&lt;/p&gt;</summary>
  </entry>
</feed>