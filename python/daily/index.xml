<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-19T01:37:39Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Wilson-ZheLin/Streamline-Analyst</title>
    <updated>2024-02-19T01:37:39Z</updated>
    <id>tag:github.com,2024-02-19:/Wilson-ZheLin/Streamline-Analyst</id>
    <link href="https://github.com/Wilson-ZheLin/Streamline-Analyst" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An AI agent powered by LLMs that streamlines the entire process of data analysis. üöÄ&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Streamline Analyst: A Data Analysis AI Agent&lt;/h1&gt; &#xA;&lt;p&gt;Streamline Analyst ü™Ñ is a cutting-edge, open-source application powered by Large Language Models (LLMs) designed to revolutionize data analysis. This &lt;strong&gt;Data Analysis Agent&lt;/strong&gt; effortlessly automates all the tasks such as data cleaning, preprocessing, and even complex operations like identifying target objects, partitioning test sets, and selecting the best-fit models based on your data. With Streamline Analyst, results visualization and evaluation become seamless.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s how it simplifies your workflow: just &lt;strong&gt;select your data file&lt;/strong&gt;, &lt;strong&gt;pick an analysis mode&lt;/strong&gt;, and &lt;strong&gt;hit start&lt;/strong&gt;. Streamline Analyst aims to expedite the data analysis process, making it accessible to all, regardless of their expertise in data analysis. It&#39;s built to empower users to process data and achieve high-quality visualizations with unparalleled efficiencyüöÄ, and to execute high-performance modeling with the best strategiesüîÆ.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Try Our Live Demo Here&lt;/strong&gt;: &lt;a href=&#34;https://streamline.streamlit.app&#34;&gt;Streamline Analyst&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Your data&#39;s privacy and security are paramount; rest assured, uploaded data and API Keys are strictly for one-time use and are neither saved nor shared.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Wilson-ZheLin/Streamline-Analyst/assets/145169519/4167b04c-0853-4703-87a4-6c2994e30f9e&#34; alt=&#34;Screenshot 2024-02-12 at 16 01 01&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Looking ahead, we plan to enhance Streamline Analyst with advanced features like &lt;em&gt;&lt;strong&gt;Natural Language Processing (NLP)&lt;/strong&gt;&lt;/em&gt;, &lt;em&gt;&lt;strong&gt;neural networks&lt;/strong&gt;&lt;/em&gt;, and &lt;em&gt;&lt;strong&gt;object detection (utilizing YOLO)&lt;/strong&gt;&lt;/em&gt;, broadening its capabilities to meet more diverse data analysis needs.&lt;/p&gt; &#xA;&lt;h2&gt;Current Version Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Target Variable Identification&lt;/strong&gt;: LLMs adeptly pinpoint the target variable&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Null Value Management&lt;/strong&gt;: Choose from a variety of strategies such as mean, median, mode filling, interpolation, or introducing new categories for handling missing data, all recommended by LLMs&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Data Encoding Tactics&lt;/strong&gt;: Automated suggestions and completions for the best encoding methods, including one-hot, integer mapping, and label encoding&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Dimensionality Reduction with PCA&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Duplicate Entity Resolution&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Data Transformation and Normalization&lt;/strong&gt;: Utilize Box-Cox transformation and normalization techniques to improve data distribution and scalability&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Balancing Target Variable Entities&lt;/strong&gt;: LLM-recommended methods like random over-sampling, SMOTE, and ADASYN help balance data sets, crucial for unbiased model training&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Data Set Proportion Adjustment&lt;/strong&gt;: LLM determines the proportion of the data set (can also be adjusted manually)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Model Selection and Training&lt;/strong&gt;: Based on your data, LLMs recommend and initiate training with the most suitable models&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Cluster Number Recommendation&lt;/strong&gt;: Leveraging the Elbow Rule and Silhouette Coefficient for optimal cluster numbers, with the flexibility of real-time adjustments&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All processed data and models are made available for download, offering a comprehensive, user-friendly data analysis toolkit.&lt;/p&gt; &#xA;&lt;h3&gt;Modeling and Results Visualization:&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Wilson-ZheLin/Streamline-Analyst/assets/145169519/423da7be-63f1-491d-9ebe-6a788c440c40&#34; alt=&#34;Screenshot 2024-02-12 at 16 10 35&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Automated Workflow Interface:&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Wilson-ZheLin/Streamline-Analyst/assets/145169519/9d04d5f2-4f2a-44eb-ab8b-c07c8c0c5a53&#34; alt=&#34;Screenshot 2024-02-12 at 16 20 19&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Supported Modeling tasks:&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Classification Models&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Clustering Models&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Regression Models&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Logistic regression&lt;/td&gt; &#xA;   &lt;td&gt;K-means clustering&lt;/td&gt; &#xA;   &lt;td&gt;Linear regression&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Random forest&lt;/td&gt; &#xA;   &lt;td&gt;DBSCAN&lt;/td&gt; &#xA;   &lt;td&gt;Ridge regression&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Support vector machine&lt;/td&gt; &#xA;   &lt;td&gt;Gaussian mixture model&lt;/td&gt; &#xA;   &lt;td&gt;Lasso regression&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gradient boosting machine&lt;/td&gt; &#xA;   &lt;td&gt;Hierarchical clustering&lt;/td&gt; &#xA;   &lt;td&gt;Elastic net regression&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gaussian Naive Bayes&lt;/td&gt; &#xA;   &lt;td&gt;Spectral clustering&lt;/td&gt; &#xA;   &lt;td&gt;Random forest regression&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AdaBoost&lt;/td&gt; &#xA;   &lt;td&gt;etc.&lt;/td&gt; &#xA;   &lt;td&gt;Gradient boosting regression&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;XGBoost&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;etc.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Real-time calculation of model indicators and result visualization:&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Classification Metrics &amp;amp; Plots&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Clustering Metrics &amp;amp; Plots&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Regression Metrics &amp;amp; Plots&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Model score&lt;/td&gt; &#xA;   &lt;td&gt;Silhouette score&lt;/td&gt; &#xA;   &lt;td&gt;R-squared score&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Confusion matrix&lt;/td&gt; &#xA;   &lt;td&gt;Calinski-Harabasz score&lt;/td&gt; &#xA;   &lt;td&gt;Mean square error (MSE)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AUC&lt;/td&gt; &#xA;   &lt;td&gt;Davies-Bouldin score&lt;/td&gt; &#xA;   &lt;td&gt;Root mean square error (RMSE)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;F1 score&lt;/td&gt; &#xA;   &lt;td&gt;Cluster scatter plot&lt;/td&gt; &#xA;   &lt;td&gt;Absolute error (MAE)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ROC plot&lt;/td&gt; &#xA;   &lt;td&gt;etc.&lt;/td&gt; &#xA;   &lt;td&gt;Residual plot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;etc.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Predicted value vs actual value plot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Quantile-Quantile plot&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Visual Analysis Toolkit:&lt;/h3&gt; &#xA;&lt;p&gt;Streamline Analyst ü™Ñ offers an array of intuitive visual tools for enhanced data insight, &lt;strong&gt;without the need for an API Key&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Single Attribute Visualization&lt;/strong&gt;: Insightful views into individual data aspects&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi-Attribute Visualization&lt;/strong&gt;: Comprehensive analysis of variable interrelations&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Three-Dimensional Plotting&lt;/strong&gt;: Advanced 3D representations for complex data relationships&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Word Clouds&lt;/strong&gt;: Key themes and concepts highlighted through word frequency&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;World Heat Maps&lt;/strong&gt;: Geographic trends and distributions made visually accessible&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Demo link available at&lt;/strong&gt;: &lt;a href=&#34;https://streamline.streamlit.app&#34;&gt;Streamline Analyst&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Wilson-ZheLin/Streamline-Analyst/assets/145169519/56884ea5-1426-4126-b210-e7e529a34c4a&#34;&gt;https://github.com/Wilson-ZheLin/Streamline-Analyst/assets/145169519/56884ea5-1426-4126-b210-e7e529a34c4a&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Local Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;p&gt;To run &lt;code&gt;app.py&lt;/code&gt;, you&#39;ll need:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;Python 3.11.5&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openai.com/blog/openai-api&#34;&gt;OpenAI API Key&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;OpenAI: Note that the free quota does not support GPT-4&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install the required packages&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Run &lt;code&gt;app.py&lt;/code&gt; on your local machine&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;streamlit run app.py&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>xaitax/CVE-2024-21413-Microsoft-Outlook-Remote-Code-Execution-Vulnerability</title>
    <updated>2024-02-19T01:37:39Z</updated>
    <id>tag:github.com,2024-02-19:/xaitax/CVE-2024-21413-Microsoft-Outlook-Remote-Code-Execution-Vulnerability</id>
    <link href="https://github.com/xaitax/CVE-2024-21413-Microsoft-Outlook-Remote-Code-Execution-Vulnerability" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Microsoft-Outlook-Remote-Code-Execution-Vulnerability&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CVE-2024-21413 | Microsoft Outlook Remote Code Execution Vulnerability PoC&lt;/h1&gt; &#xA;&lt;h2&gt;üìú Description&lt;/h2&gt; &#xA;&lt;p&gt;This script presents a proof of concept (PoC) for CVE-2024-21413, a significant security vulnerability discovered in Microsoft Outlook with a CVSS of 9.8. Termed the #MonikerLink bug, this vulnerability has far-reaching implications, including the potential leakage of local NTLM information and the possibility of remote code execution. Moreover, it highlights an attack vector that could bypass Office Protected View, thereby extending its threat to other Office applications.&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Usage&lt;/h2&gt; &#xA;&lt;p&gt;Use this tool responsibly and ensure you have authorization from the target system&#39;s owner. This script requires SMTP authentication to send an email, bypassing SPF, DKIM, and DMARC checks, which helps in simulating a real-world attack scenario more effectively.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python CVE-2024-21413.py --server &#34;&amp;lt;SMTP server&amp;gt;&#34; --port &amp;lt;SMTP port&amp;gt; --username &#34;&amp;lt;SMTP username&amp;gt;&#34; --password &#34;&amp;lt;SMTP password&amp;gt;&#34; --sender &#34;&amp;lt;sender email&amp;gt;&#34; --recipient &#34;&amp;lt;recipient email&amp;gt;&#34; --url &#34;&amp;lt;link URL&amp;gt;&#34; --subject &#34;&amp;lt;email subject&amp;gt;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--server&lt;/code&gt;: SMTP server hostname or IP.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--port&lt;/code&gt;: SMTP server port.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--username&lt;/code&gt;: SMTP server username for authentication.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--password&lt;/code&gt;: SMTP server password for authentication.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--sender&lt;/code&gt;: Sender email address.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--recipient&lt;/code&gt;: Recipient email address.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--url&lt;/code&gt;: Malicious path to include in the email.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--subject&lt;/code&gt;: Email subject.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Initial Sending&lt;/h3&gt; &#xA;&lt;img width=&#34;730&#34; alt=&#34;image&#34; src=&#34;https://github.com/xaitax/CVE-2024-21413-Microsoft-Outlook-Remote-Code-Execution-Vulnerability/assets/5014849/5b68f853-e278-48cc-98fa-f560509d7d44&#34;&gt; &#xA;&lt;h3&gt;Display in Outlook (no warnings, no Protected view)&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/xaitax/CVE-2024-21413-Microsoft-Outlook-Remote-Code-Execution-Vulnerability/assets/5014849/914110cb-ee5d-432a-bac5-c8243015658a&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Wireshark capture including NTLM credentials (you can also run impacket, alternatively)&lt;/h3&gt; &#xA;&lt;img width=&#34;604&#34; alt=&#34;image&#34; src=&#34;https://github.com/xaitax/CVE-2024-21413-Microsoft-Outlook-Remote-Code-Execution-Vulnerability/assets/5014849/89edf325-9a16-4977-be3a-4e9064bb003f&#34;&gt; &#xA;&lt;h2&gt;üßê Why SMTP Authentication?&lt;/h2&gt; &#xA;&lt;p&gt;SMTP authentication is crucial for this demonstration to ensure the email sent bypasses common email validation checks such as SPF (Sender Policy Framework), DKIM (DomainKeys Identified Mail), and DMARC (Domain-based Message Authentication, Reporting, and Conformance). These security measures are designed to detect and prevent email spoofing, where attackers send emails from a forged address. By using authenticated SMTP, the demonstration closely mimics how a sophisticated attacker might circumvent these protections, making the testing environment more realistic and highlighting the importance of comprehensive email security practices.&lt;/p&gt; &#xA;&lt;h2&gt;üìÜ Changelog&lt;/h2&gt; &#xA;&lt;h3&gt;[18. February 2024] - Initial Release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Managed &amp;amp; confirmed Microsoft Outlook Remote Code Execution (RCE) but won&#39;t publish details (yet).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;[16. February 2024] - Initial Release&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Initial release showcasing the exploit for CVE-2024-21413.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Remote Code Execution (RCE)&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/xaitax/CVE-2024-21413-Microsoft-Outlook-Remote-Code-Execution-Vulnerability/assets/5014849/cd0dbae7-aaec-4532-9114-b58239fe5775&#34; alt=&#34;CVE-2024-21413-RCE&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;No details will be published (as of now).&lt;/p&gt; &#xA;&lt;h2&gt;Research&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://research.checkpoint.com/2024/the-risks-of-the-monikerlink-bug-in-microsoft-outlook-and-the-big-picture/&#34;&gt;Checkpoint&lt;/a&gt; has done all the amazing research.&lt;/p&gt; &#xA;&lt;h2&gt;üìå Author&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Alexander Hagenah&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://primepage.de&#34;&gt;Website&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/xaitax&#34;&gt;Twitter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/alexhagenah/&#34;&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;‚ö†Ô∏è Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This tool is intended for educational and ethical testing purposes only. Unauthorized scanning, testing, or exploiting of systems is illegal and unethical. Ensure you have explicit, authorized permission to engage in any testing or exploitation activities against target systems.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>facebookresearch/DiT</title>
    <updated>2024-02-19T01:37:39Z</updated>
    <id>tag:github.com,2024-02-19:/facebookresearch/DiT</id>
    <link href="https://github.com/facebookresearch/DiT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official PyTorch Implementation of &#34;Scalable Diffusion Models with Transformers&#34;&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Scalable Diffusion Models with Transformers (DiT)&lt;br&gt;&lt;sub&gt;Official PyTorch Implementation&lt;/sub&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;http://arxiv.org/abs/2212.09748&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://www.wpeebles.com/DiT&#34;&gt;Project Page&lt;/a&gt; | Run DiT-XL/2 &lt;a href=&#34;https://huggingface.co/spaces/wpeebles/DiT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://colab.research.google.com/github/facebookresearch/DiT/blob/main/run_DiT.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://replicate.com/arielreplicate/scalable_diffusion_with_transformers&#34;&gt;&lt;img src=&#34;https://replicate.com/arielreplicate/scalable_diffusion_with_transformers/badge&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/facebookresearch/DiT/main/visuals/sample_grid_0.png&#34; alt=&#34;DiT samples&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repo contains PyTorch model definitions, pre-trained weights and training/sampling code for our paper exploring diffusion models with transformers (DiTs). You can find more visualizations on our &lt;a href=&#34;https://www.wpeebles.com/DiT&#34;&gt;project page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.wpeebles.com/DiT&#34;&gt;&lt;strong&gt;Scalable Diffusion Models with Transformers&lt;/strong&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://www.wpeebles.com&#34;&gt;William Peebles&lt;/a&gt;, &lt;a href=&#34;https://www.sainingxie.com&#34;&gt;Saining Xie&lt;/a&gt; &lt;br&gt;UC Berkeley, New York University&lt;br&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;We train latent diffusion models, replacing the commonly-used U-Net backbone with a transformer that operates on latent patches. We analyze the scalability of our Diffusion Transformers (DiTs) through the lens of forward pass complexity as measured by Gflops. We find that DiTs with higher Gflops---through increased transformer depth/width or increased number of input tokens---consistently have lower FID. In addition to good scalability properties, our DiT-XL/2 models outperform all prior diffusion models on the class-conditional ImageNet 512√ó512 and 256√ó256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter.&lt;/p&gt; &#xA;&lt;p&gt;This repository contains:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ü™ê A simple PyTorch &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DiT/main/models.py&#34;&gt;implementation&lt;/a&gt; of DiT&lt;/li&gt; &#xA; &lt;li&gt;‚ö°Ô∏è Pre-trained class-conditional DiT models trained on ImageNet (512x512 and 256x256)&lt;/li&gt; &#xA; &lt;li&gt;üí• A self-contained &lt;a href=&#34;https://huggingface.co/spaces/wpeebles/DiT&#34;&gt;Hugging Face Space&lt;/a&gt; and &lt;a href=&#34;http://colab.research.google.com/github/facebookresearch/DiT/blob/main/run_DiT.ipynb&#34;&gt;Colab notebook&lt;/a&gt; for running pre-trained DiT-XL/2 models&lt;/li&gt; &#xA; &lt;li&gt;üõ∏ A DiT &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DiT/main/train.py&#34;&gt;training script&lt;/a&gt; using PyTorch DDP&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;An implementation of DiT directly in Hugging Face &lt;code&gt;diffusers&lt;/code&gt; can also be found &lt;a href=&#34;https://github.com/huggingface/diffusers/raw/main/docs/source/en/api/pipelines/dit.mdx&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;First, download and set up the repo:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/facebookresearch/DiT.git&#xA;cd DiT&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We provide an &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DiT/main/environment.yml&#34;&gt;&lt;code&gt;environment.yml&lt;/code&gt;&lt;/a&gt; file that can be used to create a Conda environment. If you only want to run pre-trained models locally on CPU, you can remove the &lt;code&gt;cudatoolkit&lt;/code&gt; and &lt;code&gt;pytorch-cuda&lt;/code&gt; requirements from the file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda env create -f environment.yml&#xA;conda activate DiT&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Sampling &lt;a href=&#34;https://huggingface.co/spaces/wpeebles/DiT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://colab.research.google.com/github/facebookresearch/DiT/blob/main/run_DiT.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/facebookresearch/DiT/main/visuals/sample_grid_1.png&#34; alt=&#34;More DiT samples&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pre-trained DiT checkpoints.&lt;/strong&gt; You can sample from our pre-trained DiT models with &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DiT/main/sample.py&#34;&gt;&lt;code&gt;sample.py&lt;/code&gt;&lt;/a&gt;. Weights for our pre-trained DiT model will be automatically downloaded depending on the model you use. The script has various arguments to switch between the 256x256 and 512x512 models, adjust sampling steps, change the classifier-free guidance scale, etc. For example, to sample from our 512x512 DiT-XL/2 model, you can use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python sample.py --image-size 512 --seed 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For convenience, our pre-trained DiT models can be downloaded directly here as well:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;DiT Model&lt;/th&gt; &#xA;   &lt;th&gt;Image Resolution&lt;/th&gt; &#xA;   &lt;th&gt;FID-50K&lt;/th&gt; &#xA;   &lt;th&gt;Inception Score&lt;/th&gt; &#xA;   &lt;th&gt;Gflops&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://dl.fbaipublicfiles.com/DiT/models/DiT-XL-2-256x256.pt&#34;&gt;XL/2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;256x256&lt;/td&gt; &#xA;   &lt;td&gt;2.27&lt;/td&gt; &#xA;   &lt;td&gt;278.24&lt;/td&gt; &#xA;   &lt;td&gt;119&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://dl.fbaipublicfiles.com/DiT/models/DiT-XL-2-512x512.pt&#34;&gt;XL/2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;512x512&lt;/td&gt; &#xA;   &lt;td&gt;3.04&lt;/td&gt; &#xA;   &lt;td&gt;240.82&lt;/td&gt; &#xA;   &lt;td&gt;525&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Custom DiT checkpoints.&lt;/strong&gt; If you&#39;ve trained a new DiT model with &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DiT/main/train.py&#34;&gt;&lt;code&gt;train.py&lt;/code&gt;&lt;/a&gt; (see &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DiT/main/#training-dit&#34;&gt;below&lt;/a&gt;), you can add the &lt;code&gt;--ckpt&lt;/code&gt; argument to use your own checkpoint instead. For example, to sample from the EMA weights of a custom 256x256 DiT-L/4 model, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python sample.py --model DiT-L/4 --image-size 256 --ckpt /path/to/model.pt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Training DiT&lt;/h2&gt; &#xA;&lt;p&gt;We provide a training script for DiT in &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DiT/main/train.py&#34;&gt;&lt;code&gt;train.py&lt;/code&gt;&lt;/a&gt;. This script can be used to train class-conditional DiT models, but it can be easily modified to support other types of conditioning. To launch DiT-XL/2 (256x256) training with &lt;code&gt;N&lt;/code&gt; GPUs on one node:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;torchrun --nnodes=1 --nproc_per_node=N train.py --model DiT-XL/2 --data-path /path/to/imagenet/train&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;PyTorch Training Results&lt;/h3&gt; &#xA;&lt;p&gt;We&#39;ve trained DiT-XL/2 and DiT-B/4 models from scratch with the PyTorch training script to verify that it reproduces the original JAX results up to several hundred thousand training iterations. Across our experiments, the PyTorch-trained models give similar (and sometimes slightly better) results compared to the JAX-trained models up to reasonable random variation. Some data points:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;DiT Model&lt;/th&gt; &#xA;   &lt;th&gt;Train Steps&lt;/th&gt; &#xA;   &lt;th&gt;FID-50K&lt;br&gt; (JAX Training)&lt;/th&gt; &#xA;   &lt;th&gt;FID-50K&lt;br&gt; (PyTorch Training)&lt;/th&gt; &#xA;   &lt;th&gt;PyTorch Global Training Seed&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;XL/2&lt;/td&gt; &#xA;   &lt;td&gt;400K&lt;/td&gt; &#xA;   &lt;td&gt;19.5&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;18.1&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;42&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;B/4&lt;/td&gt; &#xA;   &lt;td&gt;400K&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;68.4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;68.9&lt;/td&gt; &#xA;   &lt;td&gt;42&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;B/4&lt;/td&gt; &#xA;   &lt;td&gt;400K&lt;/td&gt; &#xA;   &lt;td&gt;68.4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;68.3&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;100&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;These models were trained at 256x256 resolution; we used 8x A100s to train XL/2 and 4x A100s to train B/4. Note that FID here is computed with 250 DDPM sampling steps, with the &lt;code&gt;mse&lt;/code&gt; VAE decoder and without guidance (&lt;code&gt;cfg-scale=1&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TF32 Note (important for A100 users).&lt;/strong&gt; When we ran the above tests, TF32 matmuls were disabled per PyTorch&#39;s defaults. We&#39;ve enabled them at the top of &lt;code&gt;train.py&lt;/code&gt; and &lt;code&gt;sample.py&lt;/code&gt; because it makes training and sampling way way way faster on A100s (and should for other Ampere GPUs too), but note that the use of TF32 may lead to some differences compared to the above results.&lt;/p&gt; &#xA;&lt;h3&gt;Enhancements&lt;/h3&gt; &#xA;&lt;p&gt;Training (and sampling) could likely be sped-up significantly by:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; using &lt;a href=&#34;https://github.com/HazyResearch/flash-attention&#34;&gt;Flash Attention&lt;/a&gt; in the DiT model&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; using &lt;code&gt;torch.compile&lt;/code&gt; in PyTorch 2.0&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Basic features that would be nice to add:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Monitor FID and other metrics&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Generate and save samples from the EMA model periodically&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Resume training from a checkpoint&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; AMP/bfloat16 support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;üî• Feature Update&lt;/strong&gt; Check out this repository at &lt;a href=&#34;https://github.com/chuanyangjin/fast-DiT&#34;&gt;https://github.com/chuanyangjin/fast-DiT&lt;/a&gt; to preview a selection of training speed acceleration and memory saving features including gradient checkpointing, mixed precision training and pre-extrated VAE features. With these advancements, we have achieved a training speed of 0.84 steps/sec for DiT-XL/2 using just a single A100 GPU.&lt;/p&gt; &#xA;&lt;h2&gt;Evaluation (FID, Inception Score, etc.)&lt;/h2&gt; &#xA;&lt;p&gt;We include a &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DiT/main/sample_ddp.py&#34;&gt;&lt;code&gt;sample_ddp.py&lt;/code&gt;&lt;/a&gt; script which samples a large number of images from a DiT model in parallel. This script generates a folder of samples as well as a &lt;code&gt;.npz&lt;/code&gt; file which can be directly used with &lt;a href=&#34;https://github.com/openai/guided-diffusion/tree/main/evaluations&#34;&gt;ADM&#39;s TensorFlow evaluation suite&lt;/a&gt; to compute FID, Inception Score and other metrics. For example, to sample 50K images from our pre-trained DiT-XL/2 model over &lt;code&gt;N&lt;/code&gt; GPUs, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;torchrun --nnodes=1 --nproc_per_node=N sample_ddp.py --model DiT-XL/2 --num-fid-samples 50000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There are several additional options; see &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DiT/main/sample_ddp.py&#34;&gt;&lt;code&gt;sample_ddp.py&lt;/code&gt;&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;h2&gt;Differences from JAX&lt;/h2&gt; &#xA;&lt;p&gt;Our models were originally trained in JAX on TPUs. The weights in this repo are ported directly from the JAX models. There may be minor differences in results stemming from sampling with different floating point precisions. We re-evaluated our ported PyTorch weights at FP32, and they actually perform marginally better than sampling in JAX (2.21 FID versus 2.27 in the paper).&lt;/p&gt; &#xA;&lt;h2&gt;BibTeX&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{Peebles2022DiT,&#xA;  title={Scalable Diffusion Models with Transformers},&#xA;  author={William Peebles and Saining Xie},&#xA;  year={2022},&#xA;  journal={arXiv preprint arXiv:2212.09748},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;p&gt;We thank Kaiming He, Ronghang Hu, Alexander Berg, Shoubhik Debnath, Tim Brooks, Ilija Radosavovic and Tete Xiao for helpful discussions. William Peebles is supported by the NSF Graduate Research Fellowship.&lt;/p&gt; &#xA;&lt;p&gt;This codebase borrows from OpenAI&#39;s diffusion repos, most notably &lt;a href=&#34;https://github.com/openai/guided-diffusion&#34;&gt;ADM&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The code and model weights are licensed under CC-BY-NC. See &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DiT/main/LICENSE.txt&#34;&gt;&lt;code&gt;LICENSE.txt&lt;/code&gt;&lt;/a&gt; for details.&lt;/p&gt;</summary>
  </entry>
</feed>