<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-24T01:43:09Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>MoonInTheRiver/DiffSinger</title>
    <updated>2023-01-24T01:43:09Z</updated>
    <id>tag:github.com,2023-01-24:/MoonInTheRiver/DiffSinger</id>
    <link href="https://github.com/MoonInTheRiver/DiffSinger" rel="alternate"></link>
    <summary type="html">&lt;p&gt;DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism (SVS &amp; TTS); AAAI 2022; Official code&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2105.02446&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-Paper-%3CCOLOR%3E.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/MoonInTheRiver/DiffSinger&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/MoonInTheRiver/DiffSinger?style=social&#34; alt=&#34;GitHub Stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/MoonInTheRiver/DiffSinger/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/downloads/MoonInTheRiver/DiffSinger/total.svg?sanitize=true&#34; alt=&#34;downloads&#34;&gt;&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/NATSpeech/DiffSpeech&#34;&gt;Interactive🤗 TTS&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/Silentlin/DiffSinger&#34;&gt;Interactive🤗 SVS&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repository is the official PyTorch implementation of our AAAI-2022 &lt;a href=&#34;https://arxiv.org/abs/2105.02446&#34;&gt;paper&lt;/a&gt;, in which we propose DiffSinger (for Singing-Voice-Synthesis) and DiffSpeech (for Text-to-Speech).&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;🎉&lt;/span&gt; &lt;span&gt;🎉&lt;/span&gt; &lt;span&gt;🎉&lt;/span&gt; &lt;strong&gt;Updates&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Sep.11, 2022: &lt;span&gt;🔌&lt;/span&gt; &lt;a href=&#34;https://raw.githubusercontent.com/MoonInTheRiver/DiffSinger/master/docs/README-SVS-opencpop-pndm.md&#34;&gt;DiffSinger-PN&lt;/a&gt;. Add plug-in &lt;a href=&#34;https://arxiv.org/abs/2202.09778&#34;&gt;PNDM&lt;/a&gt;, ICLR 2022 in our laboratory, to accelerate DiffSinger freely.&lt;/li&gt; &#xA; &lt;li&gt;Jul.27, 2022: Update documents for &lt;a href=&#34;https://raw.githubusercontent.com/MoonInTheRiver/DiffSinger/master/docs/README-SVS.md&#34;&gt;SVS&lt;/a&gt;. Add easy inference &lt;a href=&#34;https://raw.githubusercontent.com/MoonInTheRiver/DiffSinger/master/docs/README-SVS-opencpop-cascade.md#4-inference-from-raw-inputs&#34;&gt;A&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://raw.githubusercontent.com/MoonInTheRiver/DiffSinger/master/docs/README-SVS-opencpop-e2e.md#4-inference-from-raw-inputs&#34;&gt;B&lt;/a&gt;; Add Interactive SVS running on &lt;a href=&#34;https://huggingface.co/spaces/Silentlin/DiffSinger&#34;&gt;HuggingFace🤗 SVS&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Mar.2, 2022: MIDI-B-version.&lt;/li&gt; &#xA; &lt;li&gt;Mar.1, 2022: &lt;a href=&#34;https://github.com/MoonInTheRiver/NeuralSVB&#34;&gt;NeuralSVB&lt;/a&gt;, for singing voice beautifying, has been released.&lt;/li&gt; &#xA; &lt;li&gt;Feb.13, 2022: &lt;a href=&#34;https://github.com/NATSpeech/NATSpeech&#34;&gt;NATSpeech&lt;/a&gt;, the improved code framework, which contains the implementations of DiffSpeech and our NeurIPS-2021 work &lt;a href=&#34;https://openreview.net/forum?id=xmJsuh8xlq&#34;&gt;PortaSpeech&lt;/a&gt; has been released.&lt;/li&gt; &#xA; &lt;li&gt;Jan.29, 2022: support MIDI-A-version SVS.&lt;/li&gt; &#xA; &lt;li&gt;Jan.13, 2022: support SVS, release PopCS dataset.&lt;/li&gt; &#xA; &lt;li&gt;Dec.19, 2021: support TTS. &lt;a href=&#34;https://huggingface.co/spaces/NATSpeech/DiffSpeech&#34;&gt;HuggingFace🤗 TTS&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;span&gt;🚀&lt;/span&gt; &lt;strong&gt;News&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Feb.24, 2022: Our new work, NeuralSVB was accepted by ACL-2022 &lt;a href=&#34;https://arxiv.org/abs/2202.13277&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-Paper-%3CCOLOR%3E.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;. &lt;a href=&#34;https://neuralsvb.github.io&#34;&gt;Demo Page&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Dec.01, 2021: DiffSinger was accepted by AAAI-2022.&lt;/li&gt; &#xA; &lt;li&gt;Sep.29, 2021: Our recent work &lt;code&gt;PortaSpeech: Portable and High-Quality Generative Text-to-Speech&lt;/code&gt; was accepted by NeurIPS-2021 &lt;a href=&#34;https://arxiv.org/abs/2109.15166&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-Paper-%3CCOLOR%3E.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt; .&lt;/li&gt; &#xA; &lt;li&gt;May.06, 2021: We submitted DiffSinger to Arxiv &lt;a href=&#34;https://arxiv.org/abs/2105.02446&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-Paper-%3CCOLOR%3E.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Environments&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;conda create -n your_env_name python=3.8&#xA;source activate your_env_name &#xA;pip install -r requirements_2080.txt   (GPU 2080Ti, CUDA 10.2)&#xA;or pip install -r requirements_3090.txt   (GPU 3090, CUDA 11.4)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Documents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MoonInTheRiver/DiffSinger/master/docs/README-TTS.md&#34;&gt;Run DiffSpeech (TTS version)&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MoonInTheRiver/DiffSinger/master/docs/README-SVS.md&#34;&gt;Run DiffSinger (SVS version)&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Mel Pipeline&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Pitch Input&lt;/th&gt; &#xA;   &lt;th&gt;F0 Prediction&lt;/th&gt; &#xA;   &lt;th&gt;Acceleration Method&lt;/th&gt; &#xA;   &lt;th&gt;Vocoder&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MoonInTheRiver/DiffSinger/master/docs/README-TTS.md&#34;&gt;DiffSpeech (Text-&amp;gt;F0, Text+F0-&amp;gt;Mel, Mel-&amp;gt;Wav)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34;&gt;Ljspeech&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;   &lt;td&gt;Explicit&lt;/td&gt; &#xA;   &lt;td&gt;Shallow Diffusion&lt;/td&gt; &#xA;   &lt;td&gt;NSF-HiFiGAN&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MoonInTheRiver/DiffSinger/master/docs/README-SVS-popcs.md&#34;&gt;DiffSinger (Lyric+F0-&amp;gt;Mel, Mel-&amp;gt;Wav)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/MoonInTheRiver/DiffSinger&#34;&gt;PopCS&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Ground-Truth F0&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;   &lt;td&gt;Shallow Diffusion&lt;/td&gt; &#xA;   &lt;td&gt;NSF-HiFiGAN&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MoonInTheRiver/DiffSinger/master/docs/README-SVS-opencpop-cascade.md&#34;&gt;DiffSinger (Lyric+MIDI-&amp;gt;F0, Lyric+F0-&amp;gt;Mel, Mel-&amp;gt;Wav)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://wenet.org.cn/opencpop/&#34;&gt;OpenCpop&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MIDI&lt;/td&gt; &#xA;   &lt;td&gt;Explicit&lt;/td&gt; &#xA;   &lt;td&gt;Shallow Diffusion&lt;/td&gt; &#xA;   &lt;td&gt;NSF-HiFiGAN&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MoonInTheRiver/DiffSinger/master/docs/README-SVS-opencpop-cascade.md&#34;&gt;FFT-Singer (Lyric+MIDI-&amp;gt;F0, Lyric+F0-&amp;gt;Mel, Mel-&amp;gt;Wav)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://wenet.org.cn/opencpop/&#34;&gt;OpenCpop&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MIDI&lt;/td&gt; &#xA;   &lt;td&gt;Explicit&lt;/td&gt; &#xA;   &lt;td&gt;Invalid&lt;/td&gt; &#xA;   &lt;td&gt;NSF-HiFiGAN&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MoonInTheRiver/DiffSinger/master/docs/README-SVS-opencpop-e2e.md&#34;&gt;DiffSinger (Lyric+MIDI-&amp;gt;Mel, Mel-&amp;gt;Wav)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://wenet.org.cn/opencpop/&#34;&gt;OpenCpop&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MIDI&lt;/td&gt; &#xA;   &lt;td&gt;Implicit&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;   &lt;td&gt;Pitch-Extractor + NSF-HiFiGAN&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MoonInTheRiver/DiffSinger/master/docs/README-SVS-opencpop-pndm.md&#34;&gt;DiffSinger+PNDM (Lyric+MIDI-&amp;gt;Mel, Mel-&amp;gt;Wav)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://wenet.org.cn/opencpop/&#34;&gt;OpenCpop&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MIDI&lt;/td&gt; &#xA;   &lt;td&gt;Implicit&lt;/td&gt; &#xA;   &lt;td&gt;PLMS&lt;/td&gt; &#xA;   &lt;td&gt;Pitch-Extractor + NSF-HiFiGAN&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Tensorboard&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;tensorboard --logdir_spec exp_name&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;table style=&#34;width:100%&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/MoonInTheRiver/DiffSinger/master/resources/tfb.png&#34; alt=&#34;Tensorboard&#34; height=&#34;250&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Audio Demos&lt;/h2&gt; &#xA;&lt;p&gt;Old audio samples can be found in our &lt;a href=&#34;https://diffsinger.github.io/&#34;&gt;demo page&lt;/a&gt;. Audio samples generated by this repository are listed here:&lt;/p&gt; &#xA;&lt;h3&gt;TTS audio samples&lt;/h3&gt; &#xA;&lt;p&gt;Speech samples (test set of LJSpeech) can be found in &lt;a href=&#34;https://github.com/MoonInTheRiver/DiffSinger/raw/master/resources/demos_1213&#34;&gt;resources/demos_1213&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;SVS audio samples&lt;/h3&gt; &#xA;&lt;p&gt;Singing samples (test set of PopCS) can be found in &lt;a href=&#34;https://github.com/MoonInTheRiver/DiffSinger/raw/master/resources/demos_0112&#34;&gt;resources/demos_0112&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{liu2021diffsinger,&#xA;  title={Diffsinger: Singing voice synthesis via shallow diffusion mechanism},&#xA;  author={Liu, Jinglin and Li, Chengxi and Ren, Yi and Chen, Feiyang and Liu, Peng and Zhao, Zhou},&#xA;  journal={arXiv preprint arXiv:2105.02446},&#xA;  volume={2},&#xA;  year={2021}}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;Our codes are based on the following repos:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lucidrains/denoising-diffusion-pytorch&#34;&gt;denoising-diffusion-pytorch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/PyTorchLightning/pytorch-lightning&#34;&gt;PyTorch Lightning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kan-bayashi/ParallelWaveGAN&#34;&gt;ParallelWaveGAN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jik876/hifi-gan&#34;&gt;HifiGAN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/espnet/espnet&#34;&gt;espnet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lmnt-com/diffwave&#34;&gt;DiffWave&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Also thanks &lt;a href=&#34;https://github.com/keonlee9420/DiffSinger&#34;&gt;Keon Lee&lt;/a&gt; for fast implementation of our work.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>daveshap/LongtermChatExternalSources</title>
    <updated>2023-01-24T01:43:09Z</updated>
    <id>tag:github.com,2023-01-24:/daveshap/LongtermChatExternalSources</id>
    <link href="https://github.com/daveshap/LongtermChatExternalSources" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GPT-3 chatbot with long-term memory and external sources&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LongtermChatExternalSources&lt;/h1&gt; &#xA;&lt;p&gt;GPT-3 chatbot with long-term memory and external sources&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>hacs/integration</title>
    <updated>2023-01-24T01:43:09Z</updated>
    <id>tag:github.com,2023-01-24:/hacs/integration</id>
    <link href="https://github.com/hacs/integration" rel="alternate"></link>
    <summary type="html">&lt;p&gt;HACS gives you a powerful UI to handle downloads of all your custom needs.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;HACS (Home Assistant Community Store)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;Manage (Install, track, upgrade) and discover custom elements for Home Assistant directly from the UI.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hacs/documentation/master/static/img/demo.gif&#34; alt=&#34;gif&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What?&lt;/h2&gt; &#xA;&lt;p&gt;HACS is a integration that gives the user a powerful UI to handle downloads of custom needs.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Highlights of what HACS can do:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Help you discover new custom elements.&lt;/li&gt; &#xA; &lt;li&gt;Help you download new custom elements.&lt;/li&gt; &#xA; &lt;li&gt;Help you keep track of your custom elements. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Manage(download/update/remove)&lt;/li&gt; &#xA;   &lt;li&gt;Shortcuts to repositories/issue tracker&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Useful links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hacs.xyz/&#34;&gt;General documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hacs.xyz/docs/configuration/basic&#34;&gt;Configuration&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hacs.xyz/docs/faq&#34;&gt;FAQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hacs&#34;&gt;GitHub&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.gg/apgchf8&#34;&gt;Discord&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sponsors/ludeeus&#34;&gt;Become a GitHub sponsor? ❤️&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://buymeacoffee.com/ludeeus&#34;&gt;BuyMe&lt;del&gt;Coffee&lt;/del&gt;Beer? 🍺🙈&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Issues&lt;/h2&gt; &#xA;&lt;p&gt;&lt;del&gt;If&lt;/del&gt; When you experience issues/bugs with this the best way to report them is to open an issue in &lt;strong&gt;this&lt;/strong&gt; repo.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hacs.xyz/docs/issues&#34;&gt;Issue link&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>