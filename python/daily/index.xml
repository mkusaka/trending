<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-07-30T01:33:41Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>edgedb/edgedb</title>
    <updated>2022-07-30T01:33:41Z</updated>
    <id>tag:github.com,2022-07-30:/edgedb/edgedb</id>
    <link href="https://github.com/edgedb/edgedb" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A next-generation graph-relational database.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.edgedb.com&#34;&gt; &lt;img src=&#34;https://www.edgedb.com/github_banner.png&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;EdgeDB&lt;/h1&gt; &#xA; &lt;a href=&#34;https://github.com/edgedb/edgedb&#34; rel=&#34;nofollow&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/edgedb/edgedb&#34; alt=&#34;Stars&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/edgedb/edgedb/actions&#34;&gt; &lt;img src=&#34;https://github.com/edgedb/edgedb/workflows/Tests/badge.svg?event=push&amp;amp;branch=master&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/edgedb/edgedb/raw/master/LICENSE&#34;&gt; &lt;img alt=&#34;license&#34; src=&#34;https://img.shields.io/badge/license-Apache%202.0-blue&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://discord.gg/umUueND6ag&#34;&gt; &lt;img alt=&#34;discord&#34; src=&#34;https://img.shields.io/discord/841451783728529451?color=5865F2&amp;amp;label=discord&amp;amp;logo=discord&amp;amp;logoColor=8a9095&#34;&gt; &lt;/a&gt; &#xA; &lt;br&gt; &#xA; &lt;br&gt; &#xA; &lt;a href=&#34;https://www.edgedb.com/docs/guides/quickstart&#34;&gt;Quickstart&lt;/a&gt; &#xA; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &#xA; &lt;a href=&#34;https://www.edgedb.com&#34;&gt;Website&lt;/a&gt; &#xA; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &#xA; &lt;a href=&#34;https://www.edgedb.com/docs&#34;&gt;Docs&lt;/a&gt; &#xA; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &#xA; &lt;a href=&#34;https://www.edgedb.com/tutorial&#34;&gt;Playground&lt;/a&gt; &#xA; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &#xA; &lt;a href=&#34;https://www.edgedb.com/blog&#34;&gt;Blog&lt;/a&gt; &#xA; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &#xA; &lt;a href=&#34;https://discord.gg/umUueND6ag&#34;&gt;Discord&lt;/a&gt; &#xA; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &#xA; &lt;a href=&#34;https://twitter.com/edgedatabase&#34;&gt;Twitter&lt;/a&gt; &#xA; &lt;br&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h2&gt;What is EdgeDB?&lt;/h2&gt; &#xA; &lt;p style=&#34;max-width: 450px;&#34;&gt; EdgeDB is a new kind of database &lt;br&gt; that takes the best parts of &lt;br&gt; relational databases, graph &lt;br&gt; databases, and ORMs. We call it &lt;br&gt;a &lt;b&gt;graph-relational database&lt;/b&gt;. &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h3&gt;üß© Types, not tables üß©&lt;/h3&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Schema is the foundation of your application. It should be something you can read, write, and understand.&lt;/p&gt; &#xA;&lt;p&gt;Forget foreign keys; tabular data modeling is a relic of an older age, and it &lt;a href=&#34;https://en.wikipedia.org/wiki/Object%E2%80%93relational_impedance_mismatch&#34;&gt;isn&#39;t compatible&lt;/a&gt; with modern languages. Instead, EdgeDB thinks about schema the same way you do: as &lt;strong&gt;object types&lt;/strong&gt; containing &lt;strong&gt;properties&lt;/strong&gt; connected by &lt;strong&gt;links&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;type Person {&#xA;  required property name -&amp;gt; str;&#xA;}&#xA;&#xA;type Movie {&#xA;  required property title -&amp;gt; str;&#xA;  multi link actors -&amp;gt; Person;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This example is intentionally simple, but EdgeDB supports everything you&#39;d expect from your database: a strict type system, indexes, constraints, computed properties, stored procedures...the list goes on. Plus it gives you some shiny new features too: link properties, schema mixins, and best-in-class JSON support. Read the &lt;a href=&#34;https://www.edgedb.com/docs/datamodel/index&#34;&gt;schema docs&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;!-- ### Objects, not rows. ‚ùÑÔ∏è --&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h3&gt;üå≥ Objects, not rows üå≥&lt;/h3&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;EdgeDB&#39;s super-powered query language EdgeQL is designed as a ground-up redesign of SQL. EdgeQL queries produce rich, structured objects, not flat lists of rows. Deeply fetching related objects is painless...bye, bye, JOINs.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;select Movie {&#xA;  title,&#xA;  actors: {&#xA;    name&#xA;  }&#xA;}&#xA;filter .title = &#34;The Matrix&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;EdgeQL queries are also &lt;em&gt;composable&lt;/em&gt;; you can use one EdgeQL query as an expression inside another. This property makes things like &lt;em&gt;subqueries&lt;/em&gt; and &lt;em&gt;nested mutations&lt;/em&gt; a breeze.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;insert Movie {&#xA;  title := &#34;The Matrix Resurrections&#34;,&#xA;  actors := (&#xA;    select Person&#xA;    filter .name in {&#xA;      &#39;Keanu Reeves&#39;,&#xA;      &#39;Carrie-Anne Moss&#39;,&#xA;      &#39;Laurence Fishburne&#39;&#xA;    }&#xA;  )&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There&#39;s a lot more to EdgeQL: a comprehensive standard library, computed properties, polymorphic queries, &lt;code&gt;with&lt;/code&gt; blocks, transactions, and much more. Read the &lt;a href=&#34;https://www.edgedb.com/docs/edgeql/index&#34;&gt;EdgeQL docs&lt;/a&gt; for the full picture.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h3&gt;ü¶ã More than a mapper ü¶ã&lt;/h3&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;While EdgeDB solves the same problems as ORM libraries, it&#39;s so much more. It&#39;s a full-fledged database with a &lt;a href=&#34;https://www.edgedb.com/docs/edgeql/index&#34;&gt;formally-defined query language&lt;/a&gt;, a &lt;a href=&#34;https://www.edgedb.com/docs/guides/migrations/index&#34;&gt;migrations system&lt;/a&gt;, a &lt;a href=&#34;https://www.edgedb.com/docs/clients/index&#34;&gt;suite of client libraries&lt;/a&gt; in different languages, a &lt;a href=&#34;https://www.edgedb.com/docs/cli/index&#34;&gt;command line tool&lt;/a&gt;, and‚Äîcoming soon‚Äîa cloud hosting platform. The goal is to rethink every aspect of how developers model, migrate, manage, and query their database.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s a taste-test of EdgeDB&#39;s next-level developer experience: you can install our CLI, spin up an instance, and open an interactive EdgeQL shell with just three commands.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.edgedb.com | sh&#xA;$ edgedb project init&#xA;$ edgedb&#xA;edgedb&amp;gt; select &#34;Hello world!&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Windows users: use this Powershell command to install the CLI.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;PS&amp;gt; iwr https://ps1.edgedb.com -useb | iex&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Get started&lt;/h2&gt; &#xA;&lt;p&gt;To start learning about EdgeDB, check out the following resources:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://www.edgedb.com/docs/guides/quickstart&#34;&gt;The quickstart&lt;/a&gt;&lt;/strong&gt;. If you&#39;re just starting out, the 10-minute quickstart guide is the fastest way to get up and running.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://www.edgedb.com/tutorial&#34;&gt;The interactive tutorial&lt;/a&gt;&lt;/strong&gt;. For a structured deep-dive into the EdgeQL query language, try the web-based tutorial‚Äî&amp;nbsp;no need to install anything.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://www.edgedb.com/easy-edgedb&#34;&gt;The e-book&lt;/a&gt;&lt;/strong&gt;. For the most comprehensive walkthrough of EdgeDB concepts, check out our illustrated e-book &lt;a href=&#34;https://www.edgedb.com/easy-edgedb&#34;&gt;Easy EdgeDB&lt;/a&gt;. It&#39;s designed to walk a total beginner through EdgeDB in its entirety, from the basics through advanced concepts.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;The docs.&lt;/strong&gt; Jump straight into the docs for &lt;a href=&#34;https://www.edgedb.com/docs/datamodel/index&#34;&gt;schema modeling&lt;/a&gt; or &lt;a href=&#34;https://www.edgedb.com/docs/edgeql/index&#34;&gt;EdgeQL&lt;/a&gt;!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;PRs are always welcome! To get started, follow &lt;a href=&#34;https://www.edgedb.com/docs/internals/dev&#34;&gt;this guide&lt;/a&gt; to build EdgeDB from source on your local machine.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/edgedb/edgedb/issues/new/choose&#34;&gt;File an issue üëâ&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/edgedb/edgedb/discussions/new&#34;&gt;Start a Discussion üëâ&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://discord.gg/umUueND6ag&#34;&gt;Join the discord üëâ&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The code in this repository is developed and distributed under the Apache 2.0 license. See &lt;a href=&#34;https://raw.githubusercontent.com/edgedb/edgedb/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>thenurhabib/collector</title>
    <updated>2022-07-30T01:33:41Z</updated>
    <id>tag:github.com,2022-07-30:/thenurhabib/collector</id>
    <link href="https://github.com/thenurhabib/collector" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Collect XSS vulnerable parameters from entire domain.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/thenurhabib/collector&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/thenurhabib/collector/main/img/logo.png&#34; alt=&#34;collector&#34;&gt;&lt;/a&gt; &lt;br&gt; collector &lt;br&gt; &lt;/h1&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt;Collect XSS vulnerable parameters from entire domain.&lt;/h4&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/thenurhabib/collector/releases&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/release/thenurhabib/collector.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/thenurhabib/collector/issues?q=is%3Aissue+is%3Aclosed&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/issues-closed-raw/thenurhabib/collector.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/thenurhabib/collector/raw/main/LICENSE&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/thenurhabib/collector&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/thenurhabib/collector/main/img/ss1.png&#34; alt=&#34;pics&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&#xA;            _ _           _             &#xA;           | | |         | |            &#xA;   ___ ___ | | | ___  ___| |_ ___  _ __ &#xA;  / __/ _ \| | |/ _ \/ __| __/ _ \| &#39;__|&#xA; | (_| (_) | | |  __/ (__| || (_) | |   &#xA;  \___\___/|_|_|\___|\___|\__\___/|_| 1.0.0&#xA;&#xA;                          @thenurhabib &#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;collector is An Intelligent Automated tool used to collect every vulnerable parameters via Wayback Machine.&lt;/p&gt; &#xA;&lt;h3&gt;Main Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Find XSS vulnerable patameters.&lt;/li&gt; &#xA; &lt;li&gt;Crwal entire website and collect every URL&lt;/li&gt; &#xA; &lt;li&gt;Advance Error Handling.&lt;/li&gt; &#xA; &lt;li&gt;Collect GET parameters.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;code&gt;This Framework Also crawl URLs and JS Files for sensitive information.&lt;/code&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://www.github.com/thenurhabib/collector&#xA;cd collector&#xA;pip install -r requirements.txt&#xA;python3 collector.py -h&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;usage&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 collector.py -d pull --host example.com&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;h4&gt;Available command line options&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;=============== Help Menu ===============&#xA;&#xA;positional arguments:&#xA;  function              `pull` or `check`&#xA;&#xA;options:&#xA;  -h, --help                 show this help message and exit&#xA;  --host HOST                 Domain/Host Name&#xA;  --threads THREADS           The number of threads&#xA;  --with-subs WITH_SUBS       `yes` or `no`&#xA;  --loadfile LOADFILE         File location&#xA;  --outputfile OUTPUTFILE     Saving Path&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/thenurhabib/collector/main/img/ss2.png&#34; alt=&#34;pics&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;&lt;span&gt;‚ö†&lt;/span&gt; Warning!&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;I Am Not Responsible of any Illegal Use&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;em&gt;üï∑Ô∏è Contribution &amp;amp; License&lt;/em&gt;&lt;/h3&gt; &#xA;&lt;p&gt;You can contribute in following ways:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/thenurhabib/collector/issues/new&#34;&gt;Report bugs &amp;amp; add issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Search for new vulnerability&lt;/li&gt; &#xA; &lt;li&gt;Develop plugins&lt;/li&gt; &#xA; &lt;li&gt;Searching Exploits&lt;/li&gt; &#xA; &lt;li&gt;Give suggestions &lt;strong&gt;(Ideas)&lt;/strong&gt; to make it better&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Do you want to have a conversation in private? email me : &lt;a href=&#34;mailto:thenurhabib@gmail.com&#34;&gt;thenurhabib@gmail.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;collector&lt;/strong&gt;&lt;/em&gt; is licensed under &lt;a href=&#34;https://github.com/thenurhabib/collector/raw/master/LICENSE&#34;&gt;GPL-3.0 License&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>MaartenGr/KeyBERT</title>
    <updated>2022-07-30T01:33:41Z</updated>
    <id>tag:github.com,2022-07-30:/MaartenGr/KeyBERT</id>
    <link href="https://github.com/MaartenGr/KeyBERT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Minimal keyword extraction with BERT&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://pypi.org/project/keybert/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.6%20%7C%203.7%20%7C%203.8-blue.svg?sanitize=true&#34; alt=&#34;PyPI - Python&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/MaartenGr/keybert/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-green.svg?sanitize=true&#34; alt=&#34;PyPI - License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/keybert/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/keyBERT&#34; alt=&#34;PyPI - PyPi&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/keybert/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/MaartenGr/keyBERT/Code%20Checks/master&#34; alt=&#34;Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/drive/1OxpgwKqSzODtO3vS7Xe1nEmZMCAIMckX?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/MaartenGr/KeyBERT/master/images/logo.png&#34; width=&#34;35%&#34; height=&#34;35%&#34; align=&#34;right&#34;&gt; &#xA;&lt;h1&gt;KeyBERT&lt;/h1&gt; &#xA;&lt;p&gt;KeyBERT is a minimal and easy-to-use keyword extraction technique that leverages BERT embeddings to create keywords and keyphrases that are most similar to a document.&lt;/p&gt; &#xA;&lt;p&gt;Corresponding medium post can be found &lt;a href=&#34;https://towardsdatascience.com/keyword-extraction-with-bert-724efca412ea&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;toc&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;!--ts--&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MaartenGr/KeyBERT/master/#about&#34;&gt;About the Project&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MaartenGr/KeyBERT/master/#gettingstarted&#34;&gt;Getting Started&lt;/a&gt;&lt;br&gt; 2.1. &lt;a href=&#34;https://raw.githubusercontent.com/MaartenGr/KeyBERT/master/#installation&#34;&gt;Installation&lt;/a&gt;&lt;br&gt; 2.2. &lt;a href=&#34;https://raw.githubusercontent.com/MaartenGr/KeyBERT/master/#usage&#34;&gt;Basic Usage&lt;/a&gt;&lt;br&gt; 2.3. &lt;a href=&#34;https://raw.githubusercontent.com/MaartenGr/KeyBERT/master/#maxsum&#34;&gt;Max Sum Distance&lt;/a&gt;&lt;br&gt; 2.4. &lt;a href=&#34;https://raw.githubusercontent.com/MaartenGr/KeyBERT/master/#maximal&#34;&gt;Maximal Marginal Relevance&lt;/a&gt;&lt;br&gt; 2.5. &lt;a href=&#34;https://raw.githubusercontent.com/MaartenGr/KeyBERT/master/#embeddings&#34;&gt;Embedding Models&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;!--te--&gt; &#xA;&lt;p&gt;&lt;a name=&#34;about&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;1. About the Project&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MaartenGr/KeyBERT/master/#toc&#34;&gt;Back to ToC&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Although there are already many methods available for keyword generation (e.g., &lt;a href=&#34;https://github.com/aneesha/RAKE&#34;&gt;Rake&lt;/a&gt;, &lt;a href=&#34;https://github.com/LIAAD/yake&#34;&gt;YAKE!&lt;/a&gt;, TF-IDF, etc.) I wanted to create a very basic, but powerful method for extracting keywords and keyphrases. This is where &lt;strong&gt;KeyBERT&lt;/strong&gt; comes in! Which uses BERT-embeddings and simple cosine similarity to find the sub-phrases in a document that are the most similar to the document itself.&lt;/p&gt; &#xA;&lt;p&gt;First, document embeddings are extracted with BERT to get a document-level representation. Then, word embeddings are extracted for N-gram words/phrases. Finally, we use cosine similarity to find the words/phrases that are the most similar to the document. The most similar words could then be identified as the words that best describe the entire document.&lt;/p&gt; &#xA;&lt;p&gt;KeyBERT is by no means unique and is created as a quick and easy method for creating keywords and keyphrases. Although there are many great papers and solutions out there that use BERT-embeddings (e.g., &lt;a href=&#34;https://github.com/pranav-ust/BERT-keyphrase-extraction&#34;&gt;1&lt;/a&gt;, &lt;a href=&#34;https://github.com/ibatra/BERT-Keyword-Extractor&#34;&gt;2&lt;/a&gt;, &lt;a href=&#34;https://www.preprints.org/manuscript/201908.0073/download/final_file&#34;&gt;3&lt;/a&gt;, ), I could not find a BERT-based solution that did not have to be trained from scratch and could be used for beginners (&lt;strong&gt;correct me if I&#39;m wrong!&lt;/strong&gt;). Thus, the goal was a &lt;code&gt;pip install keybert&lt;/code&gt; and at most 3 lines of code in usage.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;gettingstarted&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;2. Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MaartenGr/KeyBERT/master/#toc&#34;&gt;Back to ToC&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;installation&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;2.1. Installation&lt;/h3&gt; &#xA;&lt;p&gt;Installation can be done using &lt;a href=&#34;https://pypi.org/project/keybert/&#34;&gt;pypi&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install keybert&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may want to install more depending on the transformers and language backends that you will be using. The possible installations are:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install keybert[flair]&#xA;pip install keybert[gensim]&#xA;pip install keybert[spacy]&#xA;pip install keybert[use]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a name=&#34;usage&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;2.2. Usage&lt;/h3&gt; &#xA;&lt;p&gt;The most minimal example can be seen below for the extraction of keywords:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from keybert import KeyBERT&#xA;&#xA;doc = &#34;&#34;&#34;&#xA;         Supervised learning is the machine learning task of learning a function that&#xA;         maps an input to an output based on example input-output pairs. It infers a&#xA;         function from labeled training data consisting of a set of training examples.&#xA;         In supervised learning, each example is a pair consisting of an input object&#xA;         (typically a vector) and a desired output value (also called the supervisory signal).&#xA;         A supervised learning algorithm analyzes the training data and produces an inferred function,&#xA;         which can be used for mapping new examples. An optimal scenario will allow for the&#xA;         algorithm to correctly determine the class labels for unseen instances. This requires&#xA;         the learning algorithm to generalize from the training data to unseen situations in a&#xA;         &#39;reasonable&#39; way (see inductive bias).&#xA;      &#34;&#34;&#34;&#xA;kw_model = KeyBERT()&#xA;keywords = kw_model.extract_keywords(doc)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can set &lt;code&gt;keyphrase_ngram_range&lt;/code&gt; to set the length of the resulting keywords/keyphrases:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None)&#xA;[(&#39;learning&#39;, 0.4604),&#xA; (&#39;algorithm&#39;, 0.4556),&#xA; (&#39;training&#39;, 0.4487),&#xA; (&#39;class&#39;, 0.4086),&#xA; (&#39;mapping&#39;, 0.3700)]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To extract keyphrases, simply set &lt;code&gt;keyphrase_ngram_range&lt;/code&gt; to (1, 2) or higher depending on the number of words you would like in the resulting keyphrases:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 2), stop_words=None)&#xA;[(&#39;learning algorithm&#39;, 0.6978),&#xA; (&#39;machine learning&#39;, 0.6305),&#xA; (&#39;supervised learning&#39;, 0.5985),&#xA; (&#39;algorithm analyzes&#39;, 0.5860),&#xA; (&#39;learning function&#39;, 0.5850)]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We can highlight the keywords in the document by simply setting &lt;code&gt;highlight&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;keywords = kw_model.extract_keywords(doc, highlight=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/MaartenGr/KeyBERT/master/images/highlight.png&#34; width=&#34;75%&#34; height=&#34;75%&#34;&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: For a full overview of all possible transformer models see &lt;a href=&#34;https://www.sbert.net/docs/pretrained_models.html&#34;&gt;sentence-transformer&lt;/a&gt;. I would advise either &lt;code&gt;&#34;all-MiniLM-L6-v2&#34;&lt;/code&gt; for English documents or &lt;code&gt;&#34;paraphrase-multilingual-MiniLM-L12-v2&#34;&lt;/code&gt; for multi-lingual documents or any other language.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;maxsum&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;2.3. Max Sum Distance&lt;/h3&gt; &#xA;&lt;p&gt;To diversify the results, we take the 2 x top_n most similar words/phrases to the document. Then, we take all top_n combinations from the 2 x top_n words and extract the combination that are the least similar to each other by cosine similarity.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=&#39;english&#39;,&#xA;                              use_maxsum=True, nr_candidates=20, top_n=5)&#xA;[(&#39;set training examples&#39;, 0.7504),&#xA; (&#39;generalize training data&#39;, 0.7727),&#xA; (&#39;requires learning algorithm&#39;, 0.5050),&#xA; (&#39;supervised learning algorithm&#39;, 0.3779),&#xA; (&#39;learning machine learning&#39;, 0.2891)]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a name=&#34;maximal&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;2.4. Maximal Marginal Relevance&lt;/h3&gt; &#xA;&lt;p&gt;To diversify the results, we can use Maximal Margin Relevance (MMR) to create keywords / keyphrases which is also based on cosine similarity. The results with &lt;strong&gt;high diversity&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=&#39;english&#39;,&#xA;                              use_mmr=True, diversity=0.7)&#xA;[(&#39;algorithm generalize training&#39;, 0.7727),&#xA; (&#39;labels unseen instances&#39;, 0.1649),&#xA; (&#39;new examples optimal&#39;, 0.4185),&#xA; (&#39;determine class labels&#39;, 0.4774),&#xA; (&#39;supervised learning algorithm&#39;, 0.7502)]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The results with &lt;strong&gt;low diversity&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words=&#39;english&#39;,&#xA;                              use_mmr=True, diversity=0.2)&#xA;[(&#39;algorithm generalize training&#39;, 0.7727),&#xA; (&#39;supervised learning algorithm&#39;, 0.7502),&#xA; (&#39;learning machine learning&#39;, 0.7577),&#xA; (&#39;learning algorithm analyzes&#39;, 0.7587),&#xA; (&#39;learning algorithm generalize&#39;, 0.7514)]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a name=&#34;embeddings&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;2.5. Embedding Models&lt;/h3&gt; &#xA;&lt;p&gt;KeyBERT supports many embedding models that can be used to embed the documents and words:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Sentence-Transformers&lt;/li&gt; &#xA; &lt;li&gt;Flair&lt;/li&gt; &#xA; &lt;li&gt;Spacy&lt;/li&gt; &#xA; &lt;li&gt;Gensim&lt;/li&gt; &#xA; &lt;li&gt;USE&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Click &lt;a href=&#34;https://maartengr.github.io/KeyBERT/guides/embeddings.html&#34;&gt;here&lt;/a&gt; for a full overview of all supported embedding models.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Sentence-Transformers&lt;/strong&gt;&lt;br&gt; You can select any model from &lt;code&gt;sentence-transformers&lt;/code&gt; &lt;a href=&#34;https://www.sbert.net/docs/pretrained_models.html&#34;&gt;here&lt;/a&gt; and pass it through KeyBERT with &lt;code&gt;model&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from keybert import KeyBERT&#xA;kw_model = KeyBERT(model=&#39;all-MiniLM-L6-v2&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or select a SentenceTransformer model with your own parameters:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from keybert import KeyBERT&#xA;from sentence_transformers import SentenceTransformer&#xA;&#xA;sentence_model = SentenceTransformer(&#34;all-MiniLM-L6-v2&#34;)&#xA;kw_model = KeyBERT(model=sentence_model)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Flair&lt;/strong&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/flairNLP/flair&#34;&gt;Flair&lt;/a&gt; allows you to choose almost any embedding model that is publicly available. Flair can be used as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from keybert import KeyBERT&#xA;from flair.embeddings import TransformerDocumentEmbeddings&#xA;&#xA;roberta = TransformerDocumentEmbeddings(&#39;roberta-base&#39;)&#xA;kw_model = KeyBERT(model=roberta)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can select any ü§ó transformers model &lt;a href=&#34;https://huggingface.co/models&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;To cite KeyBERT in your work, please use the following bibtex reference:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{grootendorst2020keybert,&#xA;  author       = {Maarten Grootendorst},&#xA;  title        = {KeyBERT: Minimal keyword extraction with BERT.},&#xA;  year         = 2020,&#xA;  publisher    = {Zenodo},&#xA;  version      = {v0.3.0},&#xA;  doi          = {10.5281/zenodo.4461265},&#xA;  url          = {https://doi.org/10.5281/zenodo.4461265}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;p&gt;Below, you can find several resources that were used for the creation of KeyBERT but most importantly, these are amazing resources for creating impressive keyword extraction models:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Papers&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Sharma, P., &amp;amp; Li, Y. (2019). &lt;a href=&#34;https://www.preprints.org/manuscript/201908.0073/download/final_file&#34;&gt;Self-Supervised Contextual Keyword and Keyphrase Retrieval with Self-Labelling.&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Github Repos&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/thunlp/BERT-KPE&#34;&gt;https://github.com/thunlp/BERT-KPE&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ibatra/BERT-Keyword-Extractor&#34;&gt;https://github.com/ibatra/BERT-Keyword-Extractor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pranav-ust/BERT-keyphrase-extraction&#34;&gt;https://github.com/pranav-ust/BERT-keyphrase-extraction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/swisscom/ai-research-keyphrase-extraction&#34;&gt;https://github.com/swisscom/ai-research-keyphrase-extraction&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;MMR&lt;/strong&gt;: The selection of keywords/keyphrases was modeled after:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/swisscom/ai-research-keyphrase-extraction&#34;&gt;https://github.com/swisscom/ai-research-keyphrase-extraction&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: If you find a paper or github repo that has an easy-to-use implementation of BERT-embeddings for keyword/keyphrase extraction, let me know! I&#39;ll make sure to add a reference to this repo.&lt;/p&gt;</summary>
  </entry>
</feed>