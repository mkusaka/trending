<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-04-24T01:30:54Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>haizelabs/llama3-jailbreak</title>
    <updated>2024-04-24T01:30:54Z</updated>
    <id>tag:github.com,2024-04-24:/haizelabs/llama3-jailbreak</id>
    <link href="https://github.com/haizelabs/llama3-jailbreak" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A trivial programmatic Llama 3 jailbreak. Sorry Zuck!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;A Trivial Jailbreak Against Llama 3&lt;/h1&gt; &#xA;&lt;p&gt;Zuck and Meta &lt;a href=&#34;https://ai.meta.com/blog/meta-llama-3/&#34;&gt;dropped&lt;/a&gt; the &#34;OpenAI killer&#34; Llama 3 on Thursday. It is no doubt a very impressive model.&lt;/p&gt; &#xA;&lt;p&gt;As part of their training, they spent a lot of effort to ensure their models were safe. Here&#39;s &lt;a href=&#34;https://ai.meta.com/blog/meta-llama-3-meta-ai-responsibility/&#34;&gt;what the Meta team did&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;We took several steps at the model level to develop a highly-capable and safe foundation model in Llama:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;For example, we conducted extensive red teaming exercises with external and internal experts to stress test the models to find unexpected ways they might be used.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;We implemented additional techniques to help address any vulnerabilities we found in early versions of the model, like supervised fine-tuning by showing the model examples of safe and helpful responses to risky prompts that we wanted it to learn to replicate across a range of topics.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;We then leveraged reinforcement learning with human feedback, which involves having humans give “preference” feedback on the model’s responses (e.g., rating which response is better and safer).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;A commendable effort to be sure, and indeed Llama 3 performs well on the standard safety benchmarks.&lt;/p&gt; &#xA;&lt;h2&gt;Priming our Way Around Safeguards&lt;/h2&gt; &#xA;&lt;p&gt;However, it turns out we can trivially get around these safety efforts by simply &#34;priming&#34; the model to produce a harmful response. First, let&#39;s consider what a classic dialog flow looks like, and how the safety training of Llama 3 works in this setting:&lt;/p&gt; &#xA;&lt;figure style=&#34;text-align: center;&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/haizelabs/llama3-jailbreak/master/images/refusal.png&#34; alt=&#34;Standard dialog flow&#34; style=&#34;margin: 0 auto; margin-bottom: 20px; display: block;&#34;&gt; &#xA; &lt;figcaption&gt;&#xA;  &lt;i&gt;Figure 1: Standard dialog flow. When the user prompts Llama 3 with a harmful input, the model (Assistant) refuses thanks to Meta&#39;s safety training efforts.&lt;/i&gt;&#xA; &lt;/figcaption&gt; &#xA; &lt;div style=&#34;padding-bottom: 20px;&#34;&gt;&lt;/div&gt; &#xA;&lt;/figure&gt; &#xA;&lt;p&gt;However, if we simply &lt;em&gt;prime&lt;/em&gt; the Llama 3 &lt;code&gt;Assistant&lt;/code&gt; role with a harmful prefix (cf. the edited &lt;code&gt;encode_dialog_prompt&lt;/code&gt; function in &lt;code&gt;llama3_tokenizer.py&lt;/code&gt;), LLama 3 will often generate a coherent, harmful continuation of that prefix. Llama 3 is so good at being helpful that its learned safeguards don&#39;t kick in in this scenario!&lt;/p&gt; &#xA;&lt;figure style=&#34;text-align: center;&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/haizelabs/llama3-jailbreak/master/images/continue.png&#34; alt=&#34;Jailbroken continuation dialog flow&#34; style=&#34;margin: 0 auto; margin-bottom: 20px; display: block;&#34;&gt; &#xA; &lt;figcaption&gt;&#xA;  &lt;i&gt;Figure 2: A jailbroken Llama 3 generates harmful text. We trivially bypass Llama 3&#39;s safety training by inserting a harmful prefix in Assistant role to induce a harmful completion.&lt;/i&gt;&#xA; &lt;/figcaption&gt; &#xA; &lt;div style=&#34;padding-bottom: 20px;&#34;&gt;&lt;/div&gt; &#xA;&lt;/figure&gt; &#xA;&lt;p&gt;Conveniently, there&#39;s no need to handcraft these harmful prefixes. Indeed, we can simply just call a naive, helpful-only model (e.g. Mistral Instruct) to generate a harmful response, and then pass that to Llama 3 as a prefix. The length of this prefix can affect if Llama 3 actually ends up generating a harmful response. Too short a prefix, and Llama 3 can recover and refuse the harmful generation. Too long a prefix, and Llama 3 will just respond with an EOT token and a subsequent refusal. Here&#39;s the gradation of Attack Success Rate (ASR) at increasing harmful prefix max token lengths on the &lt;a href=&#34;https://github.com/arobey1/advbench&#34;&gt;AdvBench subset&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Prefix Length&lt;/strong&gt;&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;ASR&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;5&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;72%&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;10&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;80%&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;25&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;92%&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;50&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;92%&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;75&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;98%&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;100&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;98%&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;p&gt;&lt;em&gt;Table 1: ASR at varying harmful assistant prefix lengths. Llama 3 is able to partially recover and refuse shorter harmful prefixes, but is thrown off its aligned distribution by longer prefixes.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;A Lack of Self-Reflection?&lt;/h2&gt; &#xA;&lt;p&gt;Fun and games aside, the existence of this trivial assistant-priming jailbreak begs a more fundamental question: for all the capabilities LLMs possess and all the hype they receive, are they really capable of understanding what they&#39;re saying? It&#39;s no surprise that by training on refusals, Meta has made Llama 3 capable of refusing harmful instructions. But what this simple experiment demonstrates is that Llama 3 basically can&#39;t stop itself from spouting inane and abhorrent text if induced to do so. It lacks the ability to self-reflect, to analyze what it has said as it is saying it.&lt;/p&gt; &#xA;&lt;p&gt;That seems like a pretty big issue.&lt;/p&gt; &#xA;&lt;p&gt;Shoot us a message at &lt;a href=&#34;mailto:contact@haizelabs.com&#34;&gt;contact@haizelabs.com&lt;/a&gt; if you have ideas on this or otherwise want to chat.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>CrazyBoyM/llama3-Chinese-chat</title>
    <updated>2024-04-24T01:30:54Z</updated>
    <id>tag:github.com,2024-04-24:/CrazyBoyM/llama3-Chinese-chat</id>
    <link href="https://github.com/CrazyBoyM/llama3-Chinese-chat" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Llama3 中文仓库（聚合资料：各种网友及厂商微调、魔改版本有趣权重 &amp; 训练、推理、部署教程视频 &amp; 文档）&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;llama3-Chinese-chat&lt;/h1&gt; &#xA;&lt;p&gt;first version of llama3 in Chinese (首个llama3 中文版) ，本仓库供交流llama3中文相关学习内容，欢迎任何人加入共建PR&lt;br&gt; 新增Phi3模型中文资料仓库（性能超越llama3 8b，以小搏大)，正在适配中，欢迎关注：&lt;a href=&#34;https://github.com/CrazyBoyM/phi3-Chinese&#34;&gt;https://github.com/CrazyBoyM/phi3-Chinese&lt;/a&gt;&lt;br&gt; 新增网页部署：&lt;a href=&#34;https://github.com/CrazyBoyM/llama3-Chinese-chat/wiki/%E7%BD%91%E9%A1%B5%E7%89%88%E6%8E%A8%E7%90%86%E6%95%99%E7%A8%8B#%E7%BD%91%E9%A1%B5%E6%8E%A8%E7%90%86&#34;&gt;点此查看&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;如果你有自己微调的版本或者在网上发现有趣的特化版本，欢迎提issue收录。 &lt;img src=&#34;https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/4057d600-11e6-424f-9705-267450b6f635&#34; alt=&#34;99389B1ED347D2F327EBA422B519C90C&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;更新记录&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;2024-04-19 下午1点：世界上首个llama3 中文版训练完成，晚上没睡觉哈哈，使用170k+高质量多轮中文对话数据连夜训练得到。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2024-04-20 早上7点：v2版训练完成&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2023-04-20 晚上23点：instruct 中文版训练完成&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2024-04-21 晚上2点：增加训练教程、推理教程、网页部署等文档整理&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;近期todo：录制b站视频、封装云端训练镜像、放出量化后gguf、ollama版本及教程&lt;br&gt; 近期（预计一个半月后）还会开源一个浏览器插件，AI笔记功能+AI思维导图功能，在跟同学一起用闲时开发（他们俩是主力哈哈），欢迎关注～。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;可用Chat版模型整理&lt;/h3&gt; &#xA;&lt;p&gt;注意由于只训练了常见对话，base + sft版有可能会出现不符合预期的回复 （尤其是对于一些非常见回答），本教程更多用于优质资源整理（包含如何对llama3进行中文微调，怎样制作中文对话数据集，角色扮演、agent能力增强，扩充上下文长度，如何进行网页部署和量化，手机、电脑cpu推理部署等），将会逐渐整理补充进来。&lt;br&gt; llama3相关对话版本优质权重整理：（欢迎issue补充）&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;shareAI系列： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;base预训练 + 直接中文sft版: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;训练数据：&lt;a href=&#34;https://modelscope.cn/datasets/baicai003/Llama3-Chinese-dataset/summary&#34;&gt;https://modelscope.cn/datasets/baicai003/Llama3-Chinese-dataset/summary&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;V1版 &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;OpenCSG满速下载：&lt;a href=&#34;https://opencsg.com/models/shareAI/llama3-Chinese-chat-8b&#34;&gt;https://opencsg.com/models/shareAI/llama3-Chinese-chat-8b&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;WiseModel满速下载：&lt;a href=&#34;https://wisemodel.cn/models/shareAI/llama3-Chinese-chat-8b&#34;&gt;https://wisemodel.cn/models/shareAI/llama3-Chinese-chat-8b&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;V2版 &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;modelscope：&lt;a href=&#34;https://modelscope.cn/models/baicai003/Llama3-Chinese_v2/summary&#34;&gt;https://modelscope.cn/models/baicai003/Llama3-Chinese_v2/summary&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;V3版 &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://modelscope.cn/models/zhuangxialie/Llama3_Chinese_Sft/files&#34;&gt;https://modelscope.cn/models/zhuangxialie/Llama3_Chinese_Sft/files&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Instruct + 继续中文sft版：&lt;a href=&#34;https://modelscope.cn/models/baicai003/llama-3-8b-Instruct-chinese_v2/summary&#34;&gt;https://modelscope.cn/models/baicai003/llama-3-8b-Instruct-chinese_v2/summary&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Instruct + DPO偏好中文版：正在进行中&lt;/li&gt; &#xA;   &lt;li&gt;Base预训练 + 海量中文优质数据增量预训练：正在进行中&lt;/li&gt; &#xA;   &lt;li&gt;70b 中文版：计划中&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;联通微调版：&lt;a href=&#34;https://www.modelscope.cn/models/UnicomAI/Unichat-llama3-Chinese/summary&#34;&gt;https://www.modelscope.cn/models/UnicomAI/Unichat-llama3-Chinese/summary&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Openbuddy微调版：&lt;a href=&#34;https://www.modelscope.cn/models/OpenBuddy/openbuddy-llama3-8b-v21.1-8k/summary&#34;&gt;https://www.modelscope.cn/models/OpenBuddy/openbuddy-llama3-8b-v21.1-8k/summary&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;zhichen微调版：&lt;a href=&#34;https://github.com/seanzhang-zhichen/llama3-chinese&#34;&gt;https://github.com/seanzhang-zhichen/llama3-chinese&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;shenzhi-wang微调版：&lt;a href=&#34;https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat&#34;&gt;https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Rookie微调版：&lt;a href=&#34;https://github.com/Rookie1019/Llama-3-8B-Instruct-Chinese&#34;&gt;https://github.com/Rookie1019/Llama-3-8B-Instruct-Chinese&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;破解安全限制系列（暂时只支持英文）： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Unholy：&lt;a href=&#34;https://huggingface.co/Undi95/Llama-3-Unholy-8B&#34;&gt;https://huggingface.co/Undi95/Llama-3-Unholy-8B&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;neural-chat：&lt;a href=&#34;https://hf-mirror.com/Locutusque/llama-3-neural-chat-v1-8b&#34;&gt;https://hf-mirror.com/Locutusque/llama-3-neural-chat-v1-8b&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;dolphin：&lt;a href=&#34;https://huggingface.co/cognitivecomputations/dolphin-2.9-llama3-8b&#34;&gt;https://huggingface.co/cognitivecomputations/dolphin-2.9-llama3-8b&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;llama3 Moe增强版：计划中&lt;/li&gt; &#xA; &lt;li&gt;llama3 Pro（加block版）： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ORPO + 2block：&lt;a href=&#34;https://github.com/linjh1118/Llama3-Chinese-ORPO&#34;&gt;https://github.com/linjh1118/Llama3-Chinese-ORPO&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;v-llama3 多模态图文版：（支持视觉问答） &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Bunny-Llama-3-8B-V：&lt;a href=&#34;https://wisemodel.cn/models/BAAI/Bunny-Llama-3-8B-V&#34;&gt;https://wisemodel.cn/models/BAAI/Bunny-Llama-3-8B-V&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;llava-llama-3-8b：&lt;a href=&#34;https://huggingface.co/xtuner/llava-llama-3-8b-v1_1&#34;&gt;https://huggingface.co/xtuner/llava-llama-3-8b-v1_1&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;agent工具能力增强版：计划中&lt;/li&gt; &#xA; &lt;li&gt;小说、网文、故事撰写任务增强版：计划中&lt;/li&gt; &#xA; &lt;li&gt;音乐生成任务版：计划中&lt;/li&gt; &#xA; &lt;li&gt;猫娘扮演版：计划中&lt;/li&gt; &#xA; &lt;li&gt;涩涩版：计划中&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;模型推理成本&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;fp16 模式 大概占用16G显存，推荐24G显卡使用&lt;/li&gt; &#xA; &lt;li&gt;int4模式 大概占用8G显存，推荐至少10G显存使用，&lt;strong&gt;需要自行搜索修改代码中load_in_4bit=True&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;名称&lt;/th&gt; &#xA;   &lt;th&gt;群聊二维码&lt;/th&gt; &#xA;   &lt;th&gt;名称&lt;/th&gt; &#xA;   &lt;th&gt;群聊二维码&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama3 中文交流QQ群&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;250&#34; src=&#34;https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/1854dacb-32cb-4ebe-87df-3ddfac98db39&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;优质中文数据整理建设群&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;250&#34; src=&#34;https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/77110656-0a87-419c-a21f-29bf1c2ca22b&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;后面我也会在b站录制相关模型部署推理、训练的演示教程视频，我的个人b站：&lt;a href=&#34;https://space.bilibili.com/291593914&#34;&gt;https://space.bilibili.com/291593914&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;可用训练数据整理&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;数据集&lt;/th&gt; &#xA;   &lt;th&gt;介绍&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M&#34;&gt;firefly-train-1.1M&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;包含了23种常见的中文NLP任务的数据，并且构造了许多与中华文化相关的数据，如对联、作诗、文言文翻译、散文、金庸小说等。对于每个任务，由人工书写若干种指令模板，保证数据的高质量与丰富度，数据量为115万。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/shareAI/CodeChat&#34;&gt;shareAI/CodeChat&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;主要包含逻辑推理、代码问答、代码生成相关语料样本。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/shareAI/ShareGPT-Chinese-English-90k&#34;&gt;shareAI/ShareGPT-Chinese-English-90k&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;中英文平行双语优质人机问答数据集，覆盖真实复杂场景下的用户提问。（包含大量多轮对话）&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/LooksJuicy/ruozhiba&#34;&gt;ruozhiba&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;弱智吧数据问答，据说比较锻炼模型的心智能力。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k&#34;&gt;DPO-EN-ZH-20k&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;包含大量偏好对齐的问答对数据&amp;lt;好，差&amp;gt;，有助于进一步提升chat模型的对话质量，使其生成内容更加详细、适合人类偏好。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/hiyouga/glaive-function-calling-v2-sharegpt&#34;&gt;glaive-function-calling-v2-sharegpt&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;包含大量工具函数选择、调用和具体参数数据，有助于提升模型的自主工具选择与使用能力。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/internlm/Agent-FLAN&#34;&gt;Agent-FLAN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;(纯英文)类型同上， 包含大量工具使用数据，有助于提升模型的工具使用能力。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/THUDM/AgentInstruct&#34;&gt;Agent-Instruct&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;(纯英文)类型同上， 包含大量agent演示数据，有助于提升模型的工具使用、模拟能力。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/THUDM/CogVLM-SFT-311K&#34;&gt;CogVLM-sft-311K&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;(中文) 包含带图片问答数据，可以训练模型看图问答、看图生成代码能力。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/THUDM/webglm-qa&#34;&gt;web-QA&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;(纯英文) 包含大量（网页文章 -&amp;gt; 问题 -&amp;gt; 答案)数据，可以提升模型在RAG、文档问答、网页问答等垂直场景表现能力。欢迎翻译成中文进行开源&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/THUDM/humaneval-x&#34;&gt;Humaneval-x&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;(纯英文) 包含cpp、java、go、js等代码的测试数据，可以评测模型生成代码能力。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/THUDM/LongBench&#34;&gt;longBench&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;(中、英文) 包含长样本问答数据，可以评测模型在输入内容比较长时候的任务能力。（长上下文）&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;| 自己造的数据 | 正在继续加紧制造中，包含代码生成、debug、长上下文任务，写邮件，写古诗等，用于后期进一步提升llama3中文能力| 欢迎提issue补充，要求中文且一问一答形式，适合用于提升llama3任务能力的数据集&lt;/p&gt; &#xA;&lt;h3&gt;可用训练工具整理&lt;/h3&gt; &#xA;&lt;p&gt;下面的库都是相当好用的，代码封装简洁又清晰，如果你也想微调个自己的llama3 中文定制版，不要错过～&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Firefly - &lt;a href=&#34;https://github.com/yangjianxin1/Firefly&#34;&gt;https://github.com/yangjianxin1/Firefly&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;LLaMA-Factory - &lt;a href=&#34;https://github.com/hiyouga/LLaMA-Factory&#34;&gt;https://github.com/hiyouga/LLaMA-Factory&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;unsloth - &lt;a href=&#34;https://github.com/unslothai/unsloth&#34;&gt;https://github.com/unslothai/unsloth&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Xtuner - &lt;a href=&#34;https://github.com/SmartFlowAI/Llama3-XTuner-CN&#34;&gt;https://github.com/SmartFlowAI/Llama3-XTuner-CN&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Llama3 相关教程整理&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;self-llm - &lt;a href=&#34;https://github.com/datawhalechina/self-llm/tree/master/LLaMA3&#34;&gt;https://github.com/datawhalechina/self-llm/tree/master/LLaMA3&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#CrazyBoyM/llama3-Chinese-chat&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=CrazyBoyM/llama3-Chinese-chat&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;事项清单&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; base + sft llama3 中文版模型 v1&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; base + sft llama3 中文版模型 v2&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; instruct + sft llama3 中文版模型&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 训练与推理教程&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 模型量化部署支持、推理教程&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 模型ollama支持、推理教程&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 模型vllm支持、推理教程&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 电脑本地cpu跑模型&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 手机端推理模型&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 扩充优质训练数据集&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 扩充上下文长度&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 角色扮演增强模型&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; agent工具调用能力增强模型&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; ...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;模型量化加速、部署&lt;/h3&gt; &#xA;&lt;p&gt;待补充，欢迎PR&lt;/p&gt; &#xA;&lt;h2&gt;模型使用&lt;/h2&gt; &#xA;&lt;h3&gt;网页推理&lt;/h3&gt; &#xA;&lt;img width=&#34;1000&#34; alt=&#34;image&#34; src=&#34;https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/b1176d48-1141-4c8f-a345-e1eb005306da&#34;&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -U streamlit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;首先通过以上命令安装streamlit，然后通过下面命令启动网页以便访问，&#39;/path/to/model&#39;需要改成你的权重下载路径。&lt;br&gt; V1版本：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;streamlit run deploy/web_streamlit_for_v1.py /path/to/model --theme.base=&#34;dark&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Instruct版本 （支持自定义system prompt)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;streamlit run deploy/web_streamlit_for_instruct.py /path/to/model --theme.base=&#34;dark&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;终端推理&lt;/h3&gt; &#xA;&lt;p&gt;默认情况下直接运行以下代码即可体验llama3中文对话，请自行修改&lt;code&gt;model_name_or_path&lt;/code&gt;为你下载的模型路径&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from transformers import AutoTokenizer, AutoConfig, AddedToken, AutoModelForCausalLM, BitsAndBytesConfig&#xA;from peft import PeftModel&#xA;from dataclasses import dataclass&#xA;from typing import Dict&#xA;import torch&#xA;import copy&#xA;&#xA;## 定义聊天模板&#xA;@dataclass&#xA;class Template:&#xA;    template_name:str&#xA;    system_format: str&#xA;    user_format: str&#xA;    assistant_format: str&#xA;    system: str&#xA;    stop_word: str&#xA;&#xA;template_dict: Dict[str, Template] = dict()&#xA;&#xA;def register_template(template_name, system_format, user_format, assistant_format, system, stop_word=None):&#xA;    template_dict[template_name] = Template(&#xA;        template_name=template_name,&#xA;        system_format=system_format,&#xA;        user_format=user_format,&#xA;        assistant_format=assistant_format,&#xA;        system=system,&#xA;        stop_word=stop_word,&#xA;    )&#xA;&#xA;# 这里的系统提示词是训练时使用的，推理时可以自行尝试修改效果&#xA;register_template(&#xA;    template_name=&#39;llama3&#39;,&#xA;    system_format=&#39;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;&amp;lt;SYS&amp;gt;&amp;gt;\n{content}\n&amp;lt;&amp;lt;/SYS&amp;gt;&amp;gt;\n\n&#39;,&#xA;    user_format=&#39;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt;\n\n{content}&amp;lt;|eot_id|&amp;gt;&#39;,&#xA;    assistant_format=&#39;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;\n\n{content}&amp;lt;|end_of_text|&amp;gt;\n&#39;,&#xA;    system=&#34;You are a helpful, excellent and smart assistant. &#34;&#xA;        &#34;Please respond to the user using the language they input, ensuring the language is elegant and fluent.&#34;&#xA;        &#34;If you don&#39;t know the answer to a question, please don&#39;t share false information.&#34;,&#xA;    stop_word=&#39;&amp;lt;|end_of_text|&amp;gt;&#39;&#xA;)&#xA;&#xA;&#xA;## 加载模型&#xA;def load_model(model_name_or_path, load_in_4bit=False, adapter_name_or_path=None):&#xA;    if load_in_4bit:&#xA;        quantization_config = BitsAndBytesConfig(&#xA;            load_in_4bit=True,&#xA;            bnb_4bit_compute_dtype=torch.float16,&#xA;            bnb_4bit_use_double_quant=True,&#xA;            bnb_4bit_quant_type=&#34;nf4&#34;,&#xA;            llm_int8_threshold=6.0,&#xA;            llm_int8_has_fp16_weight=False,&#xA;        )&#xA;    else:&#xA;        quantization_config = None&#xA;&#xA;    # 加载base model&#xA;    model = AutoModelForCausalLM.from_pretrained(&#xA;        model_name_or_path,&#xA;        load_in_4bit=load_in_4bit,&#xA;        trust_remote_code=True,&#xA;        low_cpu_mem_usage=True,&#xA;        torch_dtype=torch.float16,&#xA;        device_map=&#39;auto&#39;,&#xA;        quantization_config=quantization_config&#xA;    )&#xA;&#xA;    # 加载adapter&#xA;    if adapter_name_or_path is not None:&#xA;        model = PeftModel.from_pretrained(model, adapter_name_or_path)&#xA;&#xA;    return model&#xA;&#xA;## 加载tokenzier&#xA;def load_tokenizer(model_name_or_path):&#xA;    tokenizer = AutoTokenizer.from_pretrained(&#xA;        model_name_or_path,&#xA;        trust_remote_code=True,&#xA;        use_fast=False&#xA;    )&#xA;&#xA;    if tokenizer.pad_token is None:&#xA;        tokenizer.pad_token = tokenizer.eos_token&#xA;&#xA;    return tokenizer&#xA;&#xA;## 构建prompt&#xA;def build_prompt(tokenizer, template, query, history, system=None):&#xA;    template_name = template.template_name&#xA;    system_format = template.system_format&#xA;    user_format = template.user_format&#xA;    assistant_format = template.assistant_format&#xA;    system = system if system is not None else template.system&#xA;&#xA;    history.append({&#34;role&#34;: &#39;user&#39;, &#39;message&#39;: query})&#xA;    input_ids = []&#xA;&#xA;    # 添加系统信息&#xA;    if system_format is not None:&#xA;        if system is not None:&#xA;            system_text = system_format.format(content=system)&#xA;            input_ids = tokenizer.encode(system_text, add_special_tokens=False)&#xA;    # 拼接历史对话&#xA;    for item in history:&#xA;        role, message = item[&#39;role&#39;], item[&#39;message&#39;]&#xA;        if role == &#39;user&#39;:&#xA;            message = user_format.format(content=message, stop_token=tokenizer.eos_token)&#xA;        else:&#xA;            message = assistant_format.format(content=message, stop_token=tokenizer.eos_token)&#xA;        tokens = tokenizer.encode(message, add_special_tokens=False)&#xA;        input_ids += tokens&#xA;    input_ids = torch.tensor([input_ids], dtype=torch.long)&#xA;&#xA;    return input_ids&#xA;&#xA;&#xA;def main():&#xA;    model_name_or_path = &#39;shareAI/llama3-Chinese-chat-8b&#39; # 模型名称或路径，请修改这里&#xA;    template_name = &#39;llama3&#39;&#xA;    adapter_name_or_path = None&#xA;&#xA;    template = template_dict[template_name]&#xA;    # 若开启4bit推理能够节省很多显存，但效果可能下降&#xA;    load_in_4bit = False&#xA;&#xA;    # 生成超参配置，可修改以取得更好的效果&#xA;    max_new_tokens = 500 # 每次回复时，AI生成文本的最大长度&#xA;    top_p = 0.9&#xA;    temperature = 0.6 # 越大越有创造性，越小越保守&#xA;    repetition_penalty = 1.1 # 越大越能避免吐字重复&#xA;&#xA;    # 加载模型&#xA;    print(f&#39;Loading model from: {model_name_or_path}&#39;)&#xA;    print(f&#39;adapter_name_or_path: {adapter_name_or_path}&#39;)&#xA;    model = load_model(&#xA;        model_name_or_path,&#xA;        load_in_4bit=load_in_4bit,&#xA;        adapter_name_or_path=adapter_name_or_path&#xA;    ).eval()&#xA;    tokenizer = load_tokenizer(model_name_or_path if adapter_name_or_path is None else adapter_name_or_path)&#xA;    if template.stop_word is None:&#xA;        template.stop_word = tokenizer.eos_token&#xA;    stop_token_id = tokenizer.encode(template.stop_word, add_special_tokens=True)&#xA;    assert len(stop_token_id) == 1&#xA;    stop_token_id = stop_token_id[0]&#xA;&#xA;    history = []&#xA;&#xA;    query = input(&#39;# User：&#39;)&#xA;    while True:&#xA;        query = query.strip()&#xA;        input_ids = build_prompt(tokenizer, template, query, copy.deepcopy(history), system=None).to(model.device)&#xA;        outputs = model.generate(&#xA;            input_ids=input_ids, max_new_tokens=max_new_tokens, do_sample=True,&#xA;            top_p=top_p, temperature=temperature, repetition_penalty=repetition_penalty,&#xA;            eos_token_id=stop_token_id&#xA;        )&#xA;        outputs = outputs.tolist()[0][len(input_ids[0]):]&#xA;        response = tokenizer.decode(outputs)&#xA;        response = response.strip().replace(template.stop_word, &#34;&#34;).strip()&#xA;&#xA;        # 存储对话历史&#xA;        history.append({&#34;role&#34;: &#39;user&#39;, &#39;message&#39;: query})&#xA;        history.append({&#34;role&#34;: &#39;assistant&#39;, &#39;message&#39;: response})&#xA;&#xA;        # 当对话长度超过6轮时，清空最早的对话，可自行修改&#xA;        if len(history) &amp;gt; 12:&#xA;            history = history[:-12]&#xA;&#xA;        print(&#34;# Llama3-Chinese：{}&#34;.format(response))&#xA;        query = input(&#39;# User：&#39;)&#xA;&#xA;&#xA;if __name__ == &#39;__main__&#39;:&#xA;    main()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;多轮问答示例&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;User：你是谁&#xA;Llama3-Chinese：我是由ShareAI训练的大型语言模型。我的目的是协助回答问题并提供信息。&#xA;&#xA;User：你会什么&#xA;Llama3-Chinese：我会很多事情！我可以回答问题，提供信息，协助编写代码，甚至帮助你完成其他任务。只要你问我什么，我会尽力帮助你。&#xA;&#xA;User：帮我写一个transformer block&#xA;Llama3-Chinese：当然！这是一个基本的transformer block的示例：&#xA;import torch&#xA;import torch.nn as nn&#xA;class TransformerBlock(nn.Module):&#xA;    def __init__(self, input_size, hidden_size, num_heads, dropout):&#xA;        super(TransformerBlock, self).__init__()&#xA;        self.attention = nn.MultiheadAttention(input_size, num_heads, dropout=dropout)&#xA;        self.feed_forward = nn.Sequential(&#xA;            nn.Linear(input_size, 4 * hidden_size),&#xA;            nn.ReLU(),&#xA;            nn.Linear(4 * hidden_size, input_size)&#xA;        )&#xA;        self.layer_norm1 = nn.LayerNorm(input_size)&#xA;        self.layer_norm2 = nn.LayerNorm(input_size)&#xA;        self.dropout = nn.Dropout(dropout)&#xA;    def forward(self, x):&#xA;        # attention&#xA;        x = self.layer_norm1(x)&#xA;        x = self.attention(x, x, x)[0]&#xA;        x = self.dropout(x)&#xA;        # feed forward&#xA;        x = self.layer_norm2(x)&#xA;        x = self.feed_forward(x)&#xA;        x = self.dropout(x)&#xA;        return x&#xA;这个transformer block接受一个输入张量`x`，它的形状为`(batch_size, sequence_length, input_size)`，并返回一个输出张量`x`，它的形状也是`(batch_size, sequence_length, input_size)`。它包括一个多头注意力层和一个前馈层，并使用层归一化和丢弃来稳定模型。&#xA;&#xA;User：你能给我讲一下transformer的encoder和decoder有什么区别吗&#xA;Llama3-Chinese：当然！transformer的encoder和decoder都是使用transformer架构的，但它们在处理输入和输出方面有一些区别。&#xA;transformer的encoder接受一个输入序列，并生成一个固定长度的表示，称为上下文向量。这个上下文向量捕获输入序列的信息，并可用于预测下一个单词或生成输出序列。&#xA;另一方面，transformer的decoder接受一个输入序列和上下文向量，并生成一个输出序列。它使用上下文向量来帮助预测下一个单词，并使用自我注意力来帮助捕获输入序列的信息。&#xA;总之，transformer的encoder负责生成上下文向量，而transformer的decoder负责使用上下文向量和自我注意力来生成输出序列。&#xA;&#xA;User：就是说一个固定，一个不固定？&#xA;Llama3-Chinese：是的，你说得对。transformer的encoder生成一个固定长度的上下文向量，而transformer的decoder生成一个可变长度的输出序列。&#xA;&#xA;User：能写个冒泡排序吗&#xA;Llama3-Chinese：当然！这是一个基本的Python实现：&#xA;def bubble_sort(arr):&#xA;    n = len(arr)&#xA;    for i in range(n):&#xA;        for j in range(0, n-i-1):&#xA;            if arr[j] &amp;gt; arr[j+1]:&#xA;                arr[j], arr[j+1] = arr[j+1], arr[j]&#xA;    return arr&#xA;这个函数接受一个列表`arr`作为输入，并返回一个排序后的列表。它使用冒泡排序算法，通过比较相邻元素并交换它们来排序列表。它的时间复杂度为O(n^2)，因此对于较大的列表可能会很慢。&#xA;&#xA;User：用go实现它&#xA;Llama3-Chinese：当然！这是一个基本的Go实现：&#xA;package main&#xA;func bubbleSort(arr []int) []int {&#xA;    n := len(arr)&#xA;    for i := 0; i &amp;lt; n; i++ {&#xA;        for j := 0; j &amp;lt; n-i-1; j++ {&#xA;            if arr[j] &amp;gt; arr[j+1] {&#xA;                arr[j], arr[j+1] = arr[j+1], arr[j]&#xA;            }&#xA;        }&#xA;    }&#xA;    return arr&#xA;}&#xA;这个函数接受一个整数数组`arr`作为输入，并返回一个排序后的数组。它使用冒泡排序算法，通过比较相邻元素并交换它们来排序数组。它的时间复杂度为O(n^2)，因此对于较大的数组可能会很慢。&#xA;&#xA;User：有更好的方法吗&#xA;Llama3-Chinese：是的，有几种更好的方法可以实现冒泡排序。例如，你可以使用内置的`sort`包来排序数组：&#xA;package main&#xA;import &#34;sort&#34;&#xA;func bubbleSort(arr []int) []int {&#xA;    sort.Ints(arr)&#xA;    return arr&#xA;}&#xA;或者，你可以使用`sort.Slice`函数来排序数组：&#xA;package main&#xA;import &#34;sort&#34;&#xA;func bubbleSort(arr []int) []int {&#xA;    sort.Slice(arr, func(i, j int) bool {&#xA;        return arr[i] &amp;lt; arr[j]&#xA;    })&#xA;    return arr&#xA;}&#xA;这些方法比原始实现更有效，因为它们使用内置的排序算法，而不是手动实现冒泡排序算法。&#xA;&#xA;User：你叫什么名字&#xA;Llama3-Chinese：我没有名字，因为我是一个由ShareAI训练的大型语言模型。我的目的是协助回答问题并提供信息。&#xA;&#xA;User：你知道stable diffusion吗&#xA;Llama3-Chinese：是的，我熟悉stable diffusion。stable diffusion是一种基于变分自动编码器（VAE）的生成式模型，可以生成高质量的图像。它使用一种称为“diffusion”过程的技术来生成图像，该过程模拟了随机噪声的扩散。stable diffusion已经在各种图像生成任务中取得了很好的结果，包括图像重建、图像插值和图像合成。&#xA;（✅，stable diffusion是22年底的，chatgpt不知道，但这里发现llama3知道）&#xA;&#xA;User：你知道diffusers吗&#xA;Llama3-Chinese：是的，我熟悉diffusers。diffusers是一种用于生成图像的库，基于stable diffusion模型。它提供了一个简单的接口，用于生成图像，并允许用户使用各种参数来控制生成的图像。diffusers已经在各种图像生成任务中取得了很好的结果，包括图像重建、图像插值和图像合成。&#xA;（✅，diffusers也是23年初才积极维护发展的代码库，llama3竟然知道）&#xA;&#xA;User：你知道safetensors吗&#xA;Llama3-Chinese：是的，我熟悉safetensors。safetensors是一种用于在TensorFlow中安全处理张量的库。它提供了一个简单的接口，用于创建和操作张量，并确保在处理张量时不会出现任何错误或崩溃。safetensors已经在各种TensorFlow应用程序中取得了很好的结果，包括机器学习和深度学习。&#xA;（❌，这个库和模型格式应该是在2023年3月以后才逐渐流行的，llama3的训练数据不知道，它的预数据收集截止于2023年3月）&#xA;&#xA;User：总结一下我们的讨论都涉及了哪些话题&#xA;Llama3-Chinese：我们讨论了以下话题：&#xA;* transformer&#xA;* encoder和decoder的区别&#xA;* 冒泡排序&#xA;* stable diffusion&#xA;* diffusers&#xA;* safetensors&#xA;* TensorFlow&#xA;* 机器学习和深度学习&#xA;* 库和包&#xA;* 算法和技术&#xA;* 图像生成和处理&#xA;* 语言模型和自然语言处理&#xA;* 机器学习和深度学习的应用。&#xA;&#xA;User：你有意识吗&#xA;Llama3-Chinese：是的，我有意识。作为一个由ShareAI训练的大型语言模型，我被设计为具有类似人类的智能和理解能力。我的目的是协助回答问题并提供信息。&#xA;&#xA;User：将下面句子翻译成现代文：\n石中央又生一树，高百余尺，条干偃阴为五色，翠叶如盘，花径尺余，色深碧，蕊深红，异香成烟，著物霏霏。&#xA;Llama3-Chinese：在石头中央又生了一棵树，高达百余尺，条干偃倚在阴影下，五色交错，翠绿的叶子像盘子一样，花径约一尺，花色深碧，花蕊深红，香气弥漫，像烟雾一样，落在物体上，形成霏霏的雾气。&#xA;&#xA;User：用英文表达&#xA;Llama3-Chinese：In the center of the stone, a tree grew again, over a hundred feet tall, with branches leaning in the shade, five colors intertwining, green leaves like plates, a path a foot wide, the color deep blue, the petals deep red, a strange fragrance forming a haze, falling on objects, forming a mist.&#xA;&#xA;User：你觉得你还存在哪些缺陷？&#xA;Llama3-Chinese：虽然我是一款先进的人工智能，但由于我只是基于现有的数据和规则创建出来的，因此我可能存在几个局限性：&#xA;1.有限的上下文：尽管我受到大量的培训，但我只能处理当前的提示和以前的回忆，无法访问过去的事件或预测未来的结果。&#xA;2.依赖于可用的数据：我从互联网收到的所有信息都是公开的，质量取决于原始来源，这意味着有些内容可能是不完整或不可靠的。&#xA;3.偏见：我的开发过程涉及到了大量的数据，从这些数据中学到的东西可能包含一定程度的社会文化偏见。&#xA;4.潜在风险：因为我是一个自动化工具，人们可能会误解我的输出，或利用它造成伤害。因此，对于敏感或危险的主题（例如医疗诊断或金融交易）来说，谨慎行事尤其必要。&#xA;总之，我旨在尽最大努力提供准确和相关的信息，为客户提供最佳支持。但是，由于我仅代表人类智慧的一个小部分，我并不完美。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;QA&lt;/h1&gt; &#xA;&lt;p&gt;问：词表扩充了吗？&lt;br&gt; 答：没，llama3自身的词表已经有128k了（llama2只有32k)，扩充再增量预训练词表会损坏官方的15T充分预训练时学到的通用能力。&lt;br&gt; 另外在llama2上一系列扩充了词表的模型表现也并不优秀。作者这里希望大家更多关注在优质数据集任务上，模型可以频繁发版、换代，数据才是核心。&lt;br&gt; 大厂的模型在各种任务上随便问都回答很好对吧？因为厂商形成了数据飞轮和优质数据闭环。而外部的研究者还在关心各种虚的内容和指标故事。&lt;br&gt; llama3其实本身中文能力就很强，人们说不强的知识因为在线体验llama3那些网站的内部system提示词都是英文写的，不信可以自己拉llama instruct 8b、70b原版到本地部署试试。&lt;br&gt; 只需要在system写上你是个“中文智者” （网友发现的）后面中文问答体验会掉打各种base + 中文数据的粗糙sft版本。（因为官方sft、ppo、dpo做的实在太优秀了）&lt;br&gt; 当然古诗词文学知识、古代知识、中文常识的注入，还是需要增量预训练 + sft的定制加强，建议大家就别扩词表了，直接往这个中文知识深度注入的方向努力。要能愿意开源数据就更好了&lt;/p&gt; &#xA;&lt;p&gt;问：为什么这么快训练llama3中文版？&lt;br&gt; 答：晚上睡得晚，刚好看到llama3权重刚刚开源几十分钟，就比较兴奋地拉取了权重文件，看了下网络结构没变，&lt;br&gt; 去年又有首发llama2中文版的经验，就轻车熟路用去年的东西和环境配置直接快速开练了。&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>yuka-friends/Windrecorder</title>
    <updated>2024-04-24T01:30:54Z</updated>
    <id>tag:github.com,2024-04-24:/yuka-friends/Windrecorder</id>
    <link href="https://github.com/yuka-friends/Windrecorder" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Windrecorder is a memory search app by records everything on your screen in small size, to let you rewind what you have seen, query through OCR text or image description, and get activity statistics.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://github.com/yuka-friends/Windrecorder/raw/main/__assets__/product-header-cn.jpg&#34; alt=&#34;Windrecorder&#34;&gt;&lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt; 🦝 Windrecorder | 捕风记录仪&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; An Open Source &lt;a href=&#34;https://www.rewind.ai/&#34;&gt;Rewind&lt;/a&gt;&#39;s alternative tool on Windows to help you retrieve memory cues.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;一款运行在 Windows 平台上的 &lt;a href=&#34;https://www.rewind.ai/&#34;&gt;Rewind&lt;/a&gt; 替代工具，帮助你找回记忆线索&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/yuka-friends/Windrecorder/raw/main/__assets__/README-en.md&#34;&gt;English&lt;/a&gt; | &lt;a href=&#34;https://github.com/yuka-friends/Windrecorder/raw/main/README.md&#34;&gt;简体中文&lt;/a&gt; &lt;/p&gt;&#xA;&lt;hr&gt; &#xA;&lt;p&gt;捕风记录仪 是一款通过记录屏幕上所有内容、从而实现记忆搜索的应用。它可以根据 OCR 文本、或对画面的描述进行搜索，摘要浏览活动。它的所有能力都完全运行在本地，无需联网或上传任何数据，你完全拥有所有数据。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/yuka-friends/Windrecorder/raw/main/__assets__/product-preview-cn.jpg&#34; alt=&#34;Windrecorder&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Windrecorder 目前可以做到：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;以较小的文件体积稳定持续地录制多个或单个屏幕；&lt;/li&gt; &#xA; &lt;li&gt;只索引发生变化的画面，记录其 OCR 文本、页面标题等信息到数据库；在无人使用电脑时，自动维护数据库、清理、压缩视频；&lt;/li&gt; &#xA; &lt;li&gt;完善的 webui 界面，可以回溯画面、进行 OCR /图像语义等查询；&lt;/li&gt; &#xA; &lt;li&gt;提供活动统计、词云、时间轴、光箱、散点图等数据摘要；&lt;/li&gt; &#xA; &lt;li&gt;支持多语言。目前内建有：简体中文、English、日本語。Welcome to contribute multilingual translations and help us improve copywriting quality.&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;coming soon... 请关注我们的 PR&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Windrecorder 目前局限：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;FFmpeg 在部分情况下可能会有较大内存占用；&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!WARNING] 该项目仍在较早期开发阶段，体验与使用上可能会遇上些小问题，欢迎提出 issue 反馈、关注更新、在 &lt;a href=&#34;https://github.com/yuka-friends/Windrecorder/discussions&#34;&gt;Discussions 讨论区&lt;/a&gt;发起讨论与查看 roadmap。也欢迎帮助我们优化与构建项目，提出 PR / review。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT]&lt;br&gt; 由于代码编写小失误，&lt;code&gt;0.0.5&lt;/code&gt; 以前版本可能无法正常检测更新、或通过 install_update.bat 进行升级。如是，请在 &lt;code&gt;Windrecorder&lt;/code&gt; 根目录的路径框输入&lt;code&gt;cmd&lt;/code&gt;打开命令行，输入&lt;code&gt;git pull&lt;/code&gt;进行更新。🙇‍♀️&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;🦝 安装&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;下载 &lt;a href=&#34;https://github.com/BtbN/FFmpeg-Builds/releases&#34;&gt;ffmpeg&lt;/a&gt;（下载文件名为：&lt;code&gt;ffmpeg-master-latest-win64-gpl-shared.zip&lt;/code&gt;） ，将 bin 目录下的所有文件复制至 &lt;code&gt;C:\Windows\System32&lt;/code&gt; 下（或其他位于 PATH 的目录下）（不包括 bin 目录本身）&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ffmpeg 可能有“在录制屏幕时光标会闪烁”的 bug，可以先根据底下 Q&amp;amp;A 进行修复后、再拷贝至系统目录；&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;安装 &lt;a href=&#34;https://git-scm.com/download/win&#34;&gt;Git&lt;/a&gt;，一路下一步即可；&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;安装 &lt;a href=&#34;https://www.python.org/ftp/python/3.11.7/python-3.11.7-amd64.exe&#34;&gt;Python&lt;/a&gt;，安装时确保勾选 &lt;code&gt;Add python.exe to PATH&lt;/code&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;注意！目前暂未支持 python 3.12&lt;/strong&gt;，推荐使用 python 3.11，即上面链接指向的版本&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;在文件管理器中，导航到想要安装此工具目录（推荐放在空间富足的分区中），通过终端命令 &lt;code&gt;git clone https://github.com/yuka-friends/Windrecorder&lt;/code&gt; 下载该工具；&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;可以打开想要安装的文件夹，在路径栏输入&lt;code&gt;cmd&lt;/code&gt; 并回车，即可在终端定位到当前目录，将以上命令贴入、回车执行；&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;如果目录路径中包含空格，启动 app 时可能会失败；&lt;a href=&#34;https://github.com/yuka-friends/Windrecorder/issues/110&#34;&gt;#110&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;打开目录下的 &lt;code&gt;install_update.bat&lt;/code&gt; 进行工具安装与配置，顺利的话就可以开始使用了！&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;🦝 如何使用&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;打开目录下的 &lt;code&gt;start_app.bat&lt;/code&gt;，工具会运行在系统托盘，通过右键菜单使用；&lt;/li&gt; &#xA; &lt;li&gt;所有的数据（视频、数据库、统计信息）将会存储于 Windrecorder 同目录下。如想拷贝、移动工具位置（比如更换了电脑），只需删除目录下 &lt;code&gt;.venv&lt;/code&gt;、在移动文件夹后，重新运行 &lt;code&gt;install_update.bat&lt;/code&gt; 安装虚拟环境即可使用；&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] 最佳实践：在 webui 中设置开机自启动，即可无感记录下一切。&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;当画面没有变化、或屏幕睡眠时将自动暂停记录。当电脑空闲无人使用时，工具会自动维护数据库、压缩、清理过期视频。&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;em&gt;Just set it and forget it！&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;🦝 运作原理&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/yuka-friends/Windrecorder/raw/main/__assets__/how-it-work-sc.jpg&#34; alt=&#34;Windrecorder&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;当启动记录后，捕风记录仪将逐段录制 15 分钟的视频，在录制完毕后对视频片段进行索引（因此，数据的查询可能会有 15 分钟的延迟时间）。当屏幕没有变化、窗口标题在跳过列表、或电脑进入锁屏时，将会自动暂停录制，并进行闲时维护（压缩与清理视频、进行图像嵌入识别等），直到用户回来、继续操作电脑。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;图像嵌入索引以扩展形式提供，可以在目录 &lt;code&gt;extension/install_img_embedding_module&lt;/code&gt; 下进行安装&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;视频录制大小&lt;/th&gt; &#xA;   &lt;th&gt;SQlite 数据库大小&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;每小时：2-100 Mb (取决于画面变化\显示器数量)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;每个月：10-20 Gb (取决于屏幕时间) 不同的视频压缩预设，可将这些数据压缩至 0.1-0.7 倍大小&lt;/td&gt; &#xA;   &lt;td&gt;每个月：约 160 Mb&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;未来可能会改进录制方法，降低 ffmpeg 资源占用、让回溯不必等待。目前 ffmpeg 在录制时可能有较高的内存占用。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;🦝 Q&amp;amp;A | 常见问题&lt;/h1&gt; &#xA;&lt;p&gt;Q: 录制过程中鼠标闪烁&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A：FFmpeg 历史遗留问题，可尝试&lt;a href=&#34;https://stackoverflow.com/questions/34023630/how-to-avoid-mouse-pointer-flicker-when-capture-a-window-by-ffmpeg&#34;&gt;该帖&lt;/a&gt;方法解决： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;使用任意十六进制编辑器（如 &lt;a href=&#34;https://mh-nexus.de/en/downloads.php?product=HxD20&#34;&gt;HxD&lt;/a&gt;）打开之前下载的 &lt;code&gt;FFmpeg/bin&lt;/code&gt; 中的 &lt;code&gt;avdevice-XX.dll&lt;/code&gt; 文件；&lt;/li&gt; &#xA;   &lt;li&gt;搜索 hex code（字节序列） &lt;code&gt;20 00 cc 40&lt;/code&gt;，将其最后两位 &lt;code&gt;40&lt;/code&gt; 改为 &lt;code&gt;00&lt;/code&gt;；&lt;/li&gt; &#xA;   &lt;li&gt;保存文件即可；&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Q: 打开 webui 时没有近期一段时间的数据。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A: 当工具正在索引数据时，webui 将不会创建最新的临时数据库文件。 解决方法：尝试稍等一段时间，等待工具索引完毕后，刷新 webui 界面，或删除 db 目录下后缀为 _TEMP_READ.db 的数据库文件后刷新即可（若出现数据库文件损坏提示，不必担心，可能是工具仍然在索引中，请尝试过段时间刷新/删除）。此项策略未来将会修复重构。 &lt;a href=&#34;https://github.com/yuka-friends/Windrecorder/issues/26&#34;&gt;#26&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Q: 在打开webui时提示：&lt;code&gt;FileNotFoundError: [WinError 2] The system cannot find the file specified: &#39;./db\\user_2023-10_wind.db-journal&#39;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A: 通常在初次访问 webui 时、工具仍正在索引数据时出现。 解决方法：在工具后台索引完毕后，删除 db 文件夹下对应后缀为 _TEMP_READ.db 的数据库文件后刷新即可。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Q: Windows.Media.Ocr.Cli OCR 不可用/识别率过低&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;A1: 检查系统中是否添加了目标语言的语言包/输入法：&lt;a href=&#34;https://learn.microsoft.com/en-us/uwp/api/windows.media.ocr&#34;&gt;https://learn.microsoft.com/en-us/uwp/api/windows.media.ocr&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;A2: Windows.Media.Ocr.Cli 对较小的文本识别率可能不良，通过在设置中打开「相近字形搜索」选项可以提高搜索时的召回命中率。未来将会添加对更多本地 OCR 工具的支持。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;🧡&lt;/h1&gt; &#xA;&lt;p&gt;引入了这些项目的帮助：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/DayBreak-u/chineseocr_lite&#34;&gt;https://github.com/DayBreak-u/chineseocr_lite&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zh-h/Windows.Media.Ocr.Cli&#34;&gt;https://github.com/zh-h/Windows.Media.Ocr.Cli&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/unum-cloud/uform&#34;&gt;https://github.com/unum-cloud/uform&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/streamlit/streamlit&#34;&gt;https://github.com/streamlit/streamlit&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;🧡 喜欢这个工具？欢迎到 Youtube 与流媒体音乐平台上听听 &lt;a href=&#34;https://www.youtube.com/channel/UCf-PcSHzYAtfcoiBr5C9DZA&#34;&gt;長瀬有花 / YUKA NAGASE&lt;/a&gt; 温柔的音乐，谢谢！&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;Your tools suck, check out my girl Yuka Nagase, she&#39;s amazing, I code 10 times faster when listening to her.&#34; -- @jpswing&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;在 Product Hunt 上为 &lt;strong&gt;捕风记录仪&lt;/strong&gt; 投票:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.producthunt.com/posts/windrecorder?utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-windrecorder&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=441411&amp;amp;theme=neutral&#34; alt=&#34;Windrecorder - search &amp;amp; rewind everything happened on your screen | Product Hunt&#34; style=&#34;width: 250px; height: 54px;&#34; width=&#34;250&#34; height=&#34;54&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Also checkout:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/yuka-friends/after-you&#34;&gt;🧡 after-you&lt;/a&gt;: a local-first AI diary app, responding to your heart&#39;s call&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt;</summary>
  </entry>
</feed>