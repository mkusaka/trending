<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-06-22T01:35:49Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>kijai/ComfyUI-WanVideoWrapper</title>
    <updated>2025-06-22T01:35:49Z</updated>
    <id>tag:github.com,2025-06-22:/kijai/ComfyUI-WanVideoWrapper</id>
    <link href="https://github.com/kijai/ComfyUI-WanVideoWrapper" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ComfyUI wrapper nodes for &lt;a href=&#34;https://github.com/Wan-Video/Wan2.1&#34;&gt;WanVideo&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;h1&gt;WORK IN PROGRESS&lt;/h1&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repo into &lt;code&gt;custom_nodes&lt;/code&gt; folder.&lt;/li&gt; &#xA; &lt;li&gt;Install dependencies: &lt;code&gt;pip install -r requirements.txt&lt;/code&gt; or if you use the portable install, run this in ComfyUI_windows_portable -folder:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;code&gt;python_embeded\python.exe -m pip install -r ComfyUI\custom_nodes\ComfyUI-WanVideoWrapper\requirements.txt&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Models&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://huggingface.co/Kijai/WanVideo_comfy/tree/main&#34;&gt;https://huggingface.co/Kijai/WanVideo_comfy/tree/main&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Text encoders to &lt;code&gt;ComfyUI/models/text_encoders&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Clip vision to &lt;code&gt;ComfyUI/models/clip_vision&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Transformer to &lt;code&gt;ComfyUI/models/diffusion_models&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Vae to &lt;code&gt;ComfyUI/models/vae&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can also use the native ComfyUI text encoding and clip vision loader with the wrapper instead of the original models:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/6a2fd9a5-8163-4c93-b362-92ef34dbd3a4&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Examples:&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/KwaiVGI/ReCamMaster&#34;&gt;ReCamMaster&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/c58a12c2-13ba-4af8-8041-e283dbef197e&#34;&gt;https://github.com/user-attachments/assets/c58a12c2-13ba-4af8-8041-e283dbef197e&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;TeaCache (with the old temporary WIP naive version, I2V):&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note that with the new version the threshold values should be 10x higher&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Range of 0.25-0.30 seems good when using the coefficients, start step can be 0, with more aggressive threshold values it may make sense to start later to avoid any potential step skips early on, that generally ruin the motion.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/504a9a50-3337-43d2-97b8-8e1661f29f46&#34;&gt;https://github.com/user-attachments/assets/504a9a50-3337-43d2-97b8-8e1661f29f46&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Context window test:&lt;/p&gt; &#xA;&lt;p&gt;1025 frames using window size of 81 frames, with 16 overlap. With the 1.3B T2V model this used under 5GB VRAM and took 10 minutes to gen on a 5090:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/89b393af-cf1b-49ae-aa29-23e57f65911e&#34;&gt;https://github.com/user-attachments/assets/89b393af-cf1b-49ae-aa29-23e57f65911e&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;This very first test was 512x512x81&lt;/p&gt; &#xA;&lt;p&gt;~16GB used with 20/40 blocks offloaded&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/fa6d0a4f-4a4d-4de5-84a4-877cc37b715f&#34;&gt;https://github.com/user-attachments/assets/fa6d0a4f-4a4d-4de5-84a4-877cc37b715f&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Vid2vid example:&lt;/p&gt; &#xA;&lt;p&gt;with 14B T2V model:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/ef228b8a-a13a-4327-8a1b-1eb343cf00d8&#34;&gt;https://github.com/user-attachments/assets/ef228b8a-a13a-4327-8a1b-1eb343cf00d8&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;with 1.3B T2V model&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/4f35ba84-da7a-4d5b-97ee-9641296f391e&#34;&gt;https://github.com/user-attachments/assets/4f35ba84-da7a-4d5b-97ee-9641296f391e&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>dottxt-ai/outlines</title>
    <updated>2025-06-22T01:35:49Z</updated>
    <id>tag:github.com,2025-06-22:/dottxt-ai/outlines</id>
    <link href="https://github.com/dottxt-ai/outlines" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Structured Text Generation&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34; style=&#34;margin-bottom: 1em;&#34;&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/docs/assets/images/logo-light-mode.svg#gh-light-mode-only&#34; alt=&#34;Outlines Logo&#34; width=&#34;300&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/docs/assets/images/logo-dark-mode.svg#gh-dark-mode-only&#34; alt=&#34;Outlines Logo&#34; width=&#34;300&#34;&gt;&lt;/p&gt; &#xA; &lt;p&gt;üóíÔ∏è &lt;em&gt;Structured outputs for LLMs&lt;/em&gt; üóíÔ∏è&lt;/p&gt; &#xA; &lt;p&gt;Made with ‚ù§üë∑Ô∏è by the team at &lt;a href=&#34;https://dottxt.co&#34;&gt;.txt&lt;/a&gt; &lt;br&gt;Trusted by NVIDIA, Cohere, HuggingFace, vLLM, etc.&lt;/p&gt; &#xA; &lt;!-- Project Badges --&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://pypi.org/project/outlines/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/outlines?style=flat-square&amp;amp;logoColor=white&amp;amp;color=ddb8ca&#34; alt=&#34;PyPI Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypistats.org/packages/outlines&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/outlines?color=A6B4A3&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/dottxt-ai/outlines/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/dottxt-ai/outlines?style=flat-square&amp;amp;logo=github&amp;amp;color=BD932F&amp;amp;logoColor=white&#34; alt=&#34;Stars&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;!-- Community Badges --&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://discord.gg/R9DSu34mGd&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1182316225284554793?color=ddb8ca&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://blog.dottxt.co/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/dottxt%20blog-a6b4a3&#34; alt=&#34;Blog&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://x.com/dottxtai&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/dottxtai?style=flat-square&amp;amp;logo=x&amp;amp;logoColor=white&amp;amp;color=bd932f&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Need a high-performance commercial solution for structured outputs? Email us at &lt;a href=&#34;mailto:contact@dottxt.co&#34;&gt;contact@dottxt.co&lt;/a&gt;, or &lt;a href=&#34;https://cal.com/team/dottxt/sales&#34;&gt;schedule a call&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#why-outlines&#34;&gt;Why Outlines?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#quickstart&#34;&gt;Quickstart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#real-world-examples&#34;&gt;Real-World Examples&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#customer-support-triage&#34;&gt;üôã‚Äç‚ôÇÔ∏è Customer Support Triage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#e-commerce-product-categorization&#34;&gt;üì¶ E-commerce Product Categorization&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#parse-event-details-with-incomplete-data&#34;&gt;üìä Parse Event Details with Incomplete Data&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#categorize-documents-into-predefined-types&#34;&gt;üóÇÔ∏è Categorize Documents into Predefined Types&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#schedule-a-meeting-with-function-calling&#34;&gt;üìÖ Schedule a Meeting with Function Calling&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#dynamically-generate-prompts-with-re-usable-templates&#34;&gt;üìù Dynamically Generate Prompts with Re-usable Templates&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#they-use-outlines&#34;&gt;They Use Outlines&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#model-integrations&#34;&gt;Model Integrations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#core-features&#34;&gt;Core Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#other-features&#34;&gt;Other Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#about-txt&#34;&gt;About .txt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/#community&#34;&gt;Community&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA; &lt;img src=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/docs/assets/images/install.png&#34; width=&#34;300&#34;&gt;&#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Why Outlines?&lt;/h2&gt; &#xA;&lt;p&gt;LLMs are powerful but their outputs are unpredictable. Most solutions attempt to fix bad outputs after generation using parsing, regex, or fragile code that breaks easily.&lt;/p&gt; &#xA;&lt;p&gt;Outlines guarantees structured outputs during generation ‚Äî directly from any LLM.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Works with any model&lt;/strong&gt; - Same code runs across OpenAI, Ollama, vLLM, and more&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Simple integration&lt;/strong&gt; - Just pass your desired output type: &lt;code&gt;model(prompt, output_type)&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Guaranteed valid structure&lt;/strong&gt; - No more parsing headaches or broken JSON&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Provider independence&lt;/strong&gt; - Switch models without changing code&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;The Outlines Philosophy&lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA; &lt;img src=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/docs/assets/images/use_philosophy.png&#34; width=&#34;300&#34;&gt;&#xA;&lt;/div&gt; &#xA;&lt;p&gt;Outlines follows a simple pattern that mirrors Python&#39;s own type system. Simply specify the desired output type, and Outlines will ensure your data matches that structure exactly:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For a yes/no response, use &lt;code&gt;Literal[&#34;Yes&#34;, &#34;No&#34;]&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;For numerical values, use &lt;code&gt;int&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;For complex objects, define a structure with a &lt;a href=&#34;https://docs.pydantic.dev/latest/&#34;&gt;Pydantic model&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;Getting started with outlines is simple:&lt;/p&gt; &#xA;&lt;h3&gt;1. Install outlines&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install outlines&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Connect to your preferred model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import outlines&#xA;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;&#xA;&#xA;MODEL_NAME = &#34;microsoft/Phi-3-mini-4k-instruct&#34;&#xA;model = outlines.from_transformers(&#xA;    AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=&#34;auto&#34;),&#xA;    AutoTokenizer.from_pretrained(MODEL_NAME)&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. Start with simple structured outputs&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from typing import Literal&#xA;from pydantic import BaseModel&#xA;&#xA;&#xA;# Simple classification&#xA;sentiment = model(&#xA;    &#34;Analyze: &#39;This product completely changed my life!&#39;&#34;,&#xA;    Literal[&#34;Positive&#34;, &#34;Negative&#34;, &#34;Neutral&#34;]&#xA;)&#xA;print(sentiment)  # &#34;Positive&#34;&#xA;&#xA;# Extract specific types&#xA;temperature = model(&#34;What&#39;s the boiling point of water in Celsius?&#34;, int)&#xA;print(temperature)  # 100&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;4. Create complex structures&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pydantic import BaseModel&#xA;from enum import Enum&#xA;&#xA;class Rating(Enum):&#xA;    poor = 1&#xA;    fair = 2&#xA;    good = 3&#xA;    excellent = 4&#xA;&#xA;class ProductReview(BaseModel):&#xA;    rating: Rating&#xA;    pros: list[str]&#xA;    cons: list[str]&#xA;    summary: str&#xA;&#xA;review = model(&#xA;    &#34;Review: The XPS 13 has great battery life and a stunning display, but it runs hot and the webcam is poor quality.&#34;,&#xA;    ProductReview,&#xA;    max_new_tokens=200,&#xA;)&#xA;&#xA;review = ProductReview.model_validate_json(review)&#xA;print(f&#34;Rating: {review.rating.name}&#34;)  # &#34;Rating: good&#34;&#xA;print(f&#34;Pros: {review.pros}&#34;)           # &#34;Pros: [&#39;great battery life&#39;, &#39;stunning display&#39;]&#34;&#xA;print(f&#34;Summary: {review.summary}&#34;)     # &#34;Summary: Good laptop with great display but thermal issues&#34;t(result)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Real-world examples&lt;/h2&gt; &#xA;&lt;p&gt;Here are production-ready examples showing how Outlines solves common problems:&lt;/p&gt; &#xA;&lt;details id=&#34;customer-support-triage&#34;&gt;&#xA; &lt;summary&gt;&lt;b&gt;üôã‚Äç‚ôÇÔ∏è Customer Support Triage&lt;/b&gt; &lt;br&gt;This example shows how to convert a free-form customer email into a structured service ticket. By parsing attributes like priority, category, and escalation flags, the code enables automated routing and handling of support issues. &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import outlines&#xA;from enum import Enum&#xA;from pydantic import BaseModel&#xA;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;from typing import List&#xA;&#xA;&#xA;MODEL_NAME = &#34;microsoft/Phi-3-mini-4k-instruct&#34;&#xA;model = outlines.from_transformers(&#xA;    AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=&#34;auto&#34;),&#xA;    AutoTokenizer.from_pretrained(MODEL_NAME)&#xA;)&#xA;&#xA;&#xA;def alert_manager(ticket):&#xA;    print(&#34;Alert!&#34;, ticket)&#xA;&#xA;&#xA;class TicketPriority(str, Enum):&#xA;    low = &#34;low&#34;&#xA;    medium = &#34;medium&#34;&#xA;    high = &#34;high&#34;&#xA;    urgent = &#34;urgent&#34;&#xA;&#xA;class ServiceTicket(BaseModel):&#xA;    priority: TicketPriority&#xA;    category: str&#xA;    requires_manager: bool&#xA;    summary: str&#xA;    action_items: List[str]&#xA;&#xA;&#xA;customer_email = &#34;&#34;&#34;&#xA;Subject: URGENT - Cannot access my account after payment&#xA;&#xA;I paid for the premium plan 3 hours ago and still can&#39;t access any features.&#xA;I&#39;ve tried logging out and back in multiple times. This is unacceptable as I&#xA;have a client presentation in an hour and need the analytics dashboard.&#xA;Please fix this immediately or refund my payment.&#xA;&#34;&#34;&#34;&#xA;&#xA;prompt = f&#34;&#34;&#34;&#xA;&amp;lt;|im_start|&amp;gt;user&#xA;Analyze this customer email:&#xA;&#xA;{customer_email}&#xA;&amp;lt;|im_end|&amp;gt;&#xA;&amp;lt;|im_start|&amp;gt;assistant&#xA;&#34;&#34;&#34;&#xA;&#xA;ticket = model(&#xA;    prompt,&#xA;    ServiceTicket,&#xA;    max_new_tokens=500&#xA;)&#xA;&#xA;# Use structured data to route the ticket&#xA;ticket = ServiceTicket.model_validate_json(ticket)&#xA;if ticket.priority == &#34;urgent&#34; or ticket.requires_manager:&#xA;    alert_manager(ticket)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details id=&#34;e-commerce-product-categorization&#34;&gt;&#xA; &lt;summary&gt;&lt;b&gt;üì¶ E-commerce product categorization&lt;/b&gt; &lt;br&gt;This use case demonstrates how outlines can transform product descriptions into structured categorization data (e.g., main category, sub-category, and attributes) to streamline tasks such as inventory management. Each product description is processed automatically, reducing manual categorization overhead. &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import outlines&#xA;from pydantic import BaseModel&#xA;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;from typing import List, Optional&#xA;&#xA;&#xA;MODEL_NAME = &#34;microsoft/Phi-3-mini-4k-instruct&#34;&#xA;model = outlines.from_transformers(&#xA;    AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=&#34;auto&#34;),&#xA;    AutoTokenizer.from_pretrained(MODEL_NAME)&#xA;)&#xA;&#xA;&#xA;def update_inventory(product, category, sub_category):&#xA;    print(f&#34;Updated {product.split(&#39;,&#39;)[0]} in category {category}/{sub_category}&#34;)&#xA;&#xA;&#xA;class ProductCategory(BaseModel):&#xA;    main_category: str&#xA;    sub_category: str&#xA;    attributes: List[str]&#xA;    brand_match: Optional[str]&#xA;&#xA;# Process product descriptions in batches&#xA;product_descriptions = [&#xA;    &#34;Apple iPhone 15 Pro Max 256GB Titanium, 6.7-inch Super Retina XDR display with ProMotion&#34;,&#xA;    &#34;Organic Cotton T-Shirt, Men&#39;s Medium, Navy Blue, 100% Sustainable Materials&#34;,&#xA;    &#34;KitchenAid Stand Mixer, 5 Quart, Red, 10-Speed Settings with Dough Hook Attachment&#34;&#xA;]&#xA;&#xA;template = outlines.Template.from_string(&#34;&#34;&#34;&#xA;&amp;lt;|im_start|&amp;gt;user&#xA;Categorize this product:&#xA;&#xA;{{ description }}&#xA;&amp;lt;|im_end|&amp;gt;&#xA;&amp;lt;|im_start|&amp;gt;assistant&#xA;&#34;&#34;&#34;)&#xA;&#xA;# Get structured categorization for all products&#xA;categories = model(&#xA;    [template(description=desc) for desc in product_descriptions],&#xA;    ProductCategory,&#xA;    max_new_tokens=200&#xA;)&#xA;&#xA;# Use categorization for inventory management&#xA;categories = [&#xA;    ProductCategory.model_validate_json(category) for category in categories&#xA;]&#xA;for product, category in zip(product_descriptions, categories):&#xA;    update_inventory(product, category.main_category, category.sub_category)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details id=&#34;parse-event-details-with-incomplete-data&#34;&gt;&#xA; &lt;summary&gt;&lt;b&gt;üìä Parse event details with incomplete data&lt;/b&gt; &lt;br&gt;This example uses outlines to parse event descriptions into structured information (like event name, date, location, type, and topics), even handling cases where the data is incomplete. It leverages union types to return either structured event data or a fallback ‚ÄúI don‚Äôt know‚Äù answer, ensuring robust extraction in varying scenarios. &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import outlines&#xA;from typing import Union, List, Literal&#xA;from pydantic import BaseModel&#xA;from enum import Enum&#xA;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;&#xA;&#xA;MODEL_NAME = &#34;microsoft/Phi-3-mini-4k-instruct&#34;&#xA;model = outlines.from_transformers(&#xA;    AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=&#34;auto&#34;),&#xA;    AutoTokenizer.from_pretrained(MODEL_NAME)&#xA;)&#xA;&#xA;class EventType(str, Enum):&#xA;    conference = &#34;conference&#34;&#xA;    webinar = &#34;webinar&#34;&#xA;    workshop = &#34;workshop&#34;&#xA;    meetup = &#34;meetup&#34;&#xA;    other = &#34;other&#34;&#xA;&#xA;&#xA;class EventInfo(BaseModel):&#xA;    &#34;&#34;&#34;Structured information about a tech event&#34;&#34;&#34;&#xA;    name: str&#xA;    date: str&#xA;    location: str&#xA;    event_type: EventType&#xA;    topics: List[str]&#xA;    registration_required: bool&#xA;&#xA;# Create a union type that can either be a structured EventInfo or &#34;I don&#39;t know&#34;&#xA;EventResponse = Union[EventInfo, Literal[&#34;I don&#39;t know&#34;]]&#xA;&#xA;# Sample event descriptions&#xA;event_descriptions = [&#xA;    # Complete information&#xA;    &#34;&#34;&#34;&#xA;    Join us for DevCon 2023, the premier developer conference happening on November 15-17, 2023&#xA;    at the San Francisco Convention Center. Topics include AI/ML, cloud infrastructure, and web3.&#xA;    Registration is required.&#xA;    &#34;&#34;&#34;,&#xA;&#xA;    # Insufficient information&#xA;    &#34;&#34;&#34;&#xA;    Tech event next week. More details coming soon!&#xA;    &#34;&#34;&#34;&#xA;]&#xA;&#xA;# Process events&#xA;results = []&#xA;for description in event_descriptions:&#xA;    prompt = f&#34;&#34;&#34;&#xA;&amp;lt;|im_start&amp;gt;system&#xA;You are a helpful assistant&#xA;&amp;lt;|im_end|&amp;gt;&#xA;&amp;lt;|im_start&amp;gt;user&#xA;Extract structured information about this tech event:&#xA;&#xA;{description}&#xA;&#xA;If there is enough information, return a JSON object with the following fields:&#xA;&#xA;- name: The name of the event&#xA;- date: The date where the event is taking place&#xA;- location: Where the event is taking place&#xA;- event_type: either &#39;conference&#39;, &#39;webinar&#39;, &#39;workshop&#39;, &#39;meetup&#39; or &#39;other&#39;&#xA;- topics: a list of topics of the conference&#xA;- registration_required: a boolean that indicates whether registration is required&#xA;&#xA;If the information available does not allow you to fill this JSON, and only then, answer &#39;I don&#39;t know&#39;.&#xA;&amp;lt;|im_end|&amp;gt;&#xA;&amp;lt;|im_start|&amp;gt;assistant&#xA;&#34;&#34;&#34;&#xA;    # Union type allows the model to return structured data or &#34;I don&#39;t know&#34;&#xA;    result = model(prompt, EventResponse, max_new_tokens=200)&#xA;    results.append(result)&#xA;&#xA;# Display results&#xA;for i, result in enumerate(results):&#xA;    print(f&#34;Event {i+1}:&#34;)&#xA;    if isinstance(result, str):&#xA;        print(f&#34;  {result}&#34;)&#xA;    else:&#xA;        # It&#39;s an EventInfo object&#xA;        print(f&#34;  Name: {result.name}&#34;)&#xA;        print(f&#34;  Type: {result.event_type}&#34;)&#xA;        print(f&#34;  Date: {result.date}&#34;)&#xA;        print(f&#34;  Topics: {&#39;, &#39;.join(result.topics)}&#34;)&#xA;    print()&#xA;&#xA;# Use structured data in downstream processing&#xA;structured_count = sum(1 for r in results if isinstance(r, EventInfo))&#xA;print(f&#34;Successfully extracted data for {structured_count} of {len(results)} events&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details id=&#34;categorize-documents-into-predefined-types&#34;&gt;&#xA; &lt;summary&gt;&lt;b&gt;üóÇÔ∏è Categorize documents into predefined types&lt;/b&gt; &lt;br&gt;In this case, outlines classifies documents into predefined categories (e.g., ‚ÄúFinancial Report,‚Äù ‚ÄúLegal Contract‚Äù) using a literal type specification. The resulting classifications are displayed in both a table format and through a category distribution summary, illustrating how structured outputs can simplify content management. &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import outlines&#xA;from typing import Literal, List&#xA;import pandas as pd&#xA;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;&#xA;&#xA;MODEL_NAME = &#34;microsoft/Phi-3-mini-4k-instruct&#34;&#xA;model = outlines.from_transformers(&#xA;    AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=&#34;auto&#34;),&#xA;    AutoTokenizer.from_pretrained(MODEL_NAME)&#xA;)&#xA;&#xA;&#xA;# Define classification categories using Literal&#xA;DocumentCategory = Literal[&#xA;    &#34;Financial Report&#34;,&#xA;    &#34;Legal Contract&#34;,&#xA;    &#34;Technical Documentation&#34;,&#xA;    &#34;Marketing Material&#34;,&#xA;    &#34;Personal Correspondence&#34;&#xA;]&#xA;&#xA;# Sample documents to classify&#xA;documents = [&#xA;    &#34;Q3 Financial Summary: Revenue increased by 15% year-over-year to $12.4M. EBITDA margin improved to 23% compared to 19% in Q3 last year. Operating expenses...&#34;,&#xA;&#xA;    &#34;This agreement is made between Party A and Party B, hereinafter referred to as &#39;the Parties&#39;, on this day of...&#34;,&#xA;&#xA;    &#34;The API accepts POST requests with JSON payloads. Required parameters include &#39;user_id&#39; and &#39;transaction_type&#39;. The endpoint returns a 200 status code on success.&#34;&#xA;]&#xA;&#xA;template = outlines.Template.from_string(&#34;&#34;&#34;&#xA;&amp;lt;|im_start|&amp;gt;user&#xA;Classify the following document into exactly one category among the following categories:&#xA;- Financial Report&#xA;- Legal Contract&#xA;- Technical Documentation&#xA;- Marketing Material&#xA;- Personal Correspondence&#xA;&#xA;Document:&#xA;{{ document }}&#xA;&amp;lt;|im_end|&amp;gt;&#xA;&amp;lt;|im_start|&amp;gt;assistant&#xA;&#34;&#34;&#34;)&#xA;&#xA;# Classify documents&#xA;def classify_documents(texts: List[str]) -&amp;gt; List[DocumentCategory]:&#xA;    results = []&#xA;&#xA;    for text in texts:&#xA;        prompt = template(document=text)&#xA;        # The model must return one of the predefined categories&#xA;        category = model(prompt, DocumentCategory, max_new_tokens=200)&#xA;        results.append(category)&#xA;&#xA;    return results&#xA;&#xA;# Perform classification&#xA;classifications = classify_documents(documents)&#xA;&#xA;# Create a simple results table&#xA;results_df = pd.DataFrame({&#xA;    &#34;Document&#34;: [doc[:50] + &#34;...&#34; for doc in documents],&#xA;    &#34;Classification&#34;: classifications&#xA;})&#xA;&#xA;print(results_df)&#xA;&#xA;# Count documents by category&#xA;category_counts = pd.Series(classifications).value_counts()&#xA;print(&#34;\nCategory Distribution:&#34;)&#xA;print(category_counts)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary id=&#34;schedule-a-meeting-with-function-calling&#34;&gt;&lt;b&gt;üìÖ Schedule a meeting from requests with Function Calling&lt;/b&gt; &lt;br&gt;This example demonstrates how outlines can interpret a natural language meeting request and translate it into a structured format matching a predefined function‚Äôs parameters. Once the meeting details are extracted (e.g., title, date, duration, attendees), they are used to automatically schedule the meeting. &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import outlines&#xA;import json&#xA;from typing import List, Optional&#xA;from datetime import date&#xA;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;&#xA;&#xA;MODEL_NAME = &#34;microsoft/phi-4&#34;&#xA;model = outlines.from_transformers(&#xA;    AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=&#34;auto&#34;),&#xA;    AutoTokenizer.from_pretrained(MODEL_NAME)&#xA;)&#xA;&#xA;&#xA;# Define a function with typed parameters&#xA;def schedule_meeting(&#xA;    title: str,&#xA;    date: date,&#xA;    duration_minutes: int,&#xA;    attendees: List[str],&#xA;    location: Optional[str] = None,&#xA;    agenda_items: Optional[List[str]] = None&#xA;):&#xA;    &#34;&#34;&#34;Schedule a meeting with the specified details&#34;&#34;&#34;&#xA;    # In a real app, this would create the meeting&#xA;    meeting = {&#xA;        &#34;title&#34;: title,&#xA;        &#34;date&#34;: date,&#xA;        &#34;duration_minutes&#34;: duration_minutes,&#xA;        &#34;attendees&#34;: attendees,&#xA;        &#34;location&#34;: location,&#xA;        &#34;agenda_items&#34;: agenda_items&#xA;    }&#xA;    return f&#34;Meeting &#39;{title}&#39; scheduled for {date} with {len(attendees)} attendees&#34;&#xA;&#xA;# Natural language request&#xA;user_request = &#34;&#34;&#34;&#xA;I need to set up a product roadmap review with the engineering team for next&#xA;Tuesday at 2pm. It should last 90 minutes. Please invite john@example.com,&#xA;sarah@example.com, and the product team at product@example.com.&#xA;&#34;&#34;&#34;&#xA;&#xA;# Outlines automatically infers the required structure from the function signature&#xA;prompt = f&#34;&#34;&#34;&#xA;&amp;lt;|im_start|&amp;gt;user&#xA;Extract the meeting details from this request:&#xA;&#xA;{user_request}&#xA;&amp;lt;|im_end|&amp;gt;&#xA;&amp;lt;|im_start|&amp;gt;assistant&#xA;&#34;&#34;&#34;&#xA;meeting_params = model(prompt, schedule_meeting, max_new_tokens=200)&#xA;&#xA;# The result is a dictionary matching the function parameters&#xA;meeting_params = json.loads(meeting_params)&#xA;print(meeting_params)&#xA;&#xA;# Call the function with the extracted parameters&#xA;result = schedule_meeting(**meeting_params)&#xA;print(result)&#xA;# &#34;Meeting &#39;Product Roadmap Review&#39; scheduled for 2023-10-17 with 3 attendees&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary id=&#34;dynamically-generate-prompts-with-re-usable-templates&#34;&gt;&lt;b&gt;üìù Dynamically generate prompts with re-usable templates&lt;/b&gt; &lt;br&gt;Using Jinja-based templates, this example shows how to generate dynamic prompts for tasks like sentiment analysis. It illustrates how to easily re-use and customize prompts‚Äîincluding few-shot learning strategies‚Äîfor different content types while ensuring the outputs remain structured. &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import outlines&#xA;from typing import List, Literal&#xA;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;&#xA;&#xA;MODEL_NAME = &#34;microsoft/phi-4&#34;&#xA;model = outlines.from_transformers(&#xA;    AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=&#34;auto&#34;),&#xA;    AutoTokenizer.from_pretrained(MODEL_NAME)&#xA;)&#xA;&#xA;&#xA;# 1. Create a reusable template with Jinja syntax&#xA;sentiment_template = outlines.Template.from_string(&#34;&#34;&#34;&#xA;&amp;lt;|im_start&amp;gt;user&#xA;Analyze the sentiment of the following {{ content_type }}:&#xA;&#xA;{{ text }}&#xA;&#xA;Provide your analysis as either &#34;Positive&#34;, &#34;Negative&#34;, or &#34;Neutral&#34;.&#xA;&amp;lt;|im_end&amp;gt;&#xA;&amp;lt;|im_start&amp;gt;assistant&#xA;&#34;&#34;&#34;)&#xA;&#xA;# 2. Generate prompts with different parameters&#xA;review = &#34;This restaurant exceeded all my expectations. Fantastic service!&#34;&#xA;prompt = sentiment_template(content_type=&#34;review&#34;, text=review)&#xA;&#xA;# 3. Use the templated prompt with structured generation&#xA;result = model(prompt, Literal[&#34;Positive&#34;, &#34;Negative&#34;, &#34;Neutral&#34;])&#xA;print(result)  # &#34;Positive&#34;&#xA;&#xA;# Templates can also be loaded from files&#xA;example_template = outlines.Template.from_file(&#34;templates/few_shot.txt&#34;)&#xA;&#xA;# Use with examples for few-shot learning&#xA;examples = [&#xA;    (&#34;The food was cold&#34;, &#34;Negative&#34;),&#xA;    (&#34;The staff was friendly&#34;, &#34;Positive&#34;)&#xA;]&#xA;few_shot_prompt = example_template(examples=examples, query=&#34;Service was slow&#34;)&#xA;print(few_shot_prompt)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;They use outlines&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/docs/assets/images/readme-light.png#gh-light-mode-only&#34; alt=&#34;Users Logo&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/docs/assets/images/readme-dark.png#gh-dark-mode-only&#34; alt=&#34;Users Logo&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Model Integrations&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model type&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Documentation&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Server Support&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;vLLM and Ollama&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://dottxt-ai.github.io/outlines/latest/features/models/&#34;&gt;Server Integrations ‚Üí&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Local Model Support&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;transformers and llama.cpp&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://dottxt-ai.github.io/outlines/latest/features/models/&#34;&gt;Model Integrations ‚Üí&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;API Support&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;OpenAI and Gemini&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://dottxt-ai.github.io/outlines/latest/features/models/&#34;&gt;API Integrations ‚Üí&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Core Features&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Feature&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Documentation&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Multiple Choices&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Constrain outputs to predefined options&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://dottxt-ai.github.io/outlines/latest/features/core/output_types/#multiple-choices&#34;&gt;Multiple Choices Guide ‚Üí&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Function Calls&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Infer structure from function signatures&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://dottxt-ai.github.io/outlines/latest/features/core/output_types/#json-schemas&#34;&gt;Function Guide ‚Üí&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;JSON/Pydantic&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Generate outputs matching JSON schemas&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://dottxt-ai.github.io/outlines/latest/features/core/output_types/#json-schemas&#34;&gt;JSON Guide ‚Üí&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Regular Expressions&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Generate text following a regex pattern&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://dottxt-ai.github.io/outlines/latest/features/core/output_types/#regex-patterns&#34;&gt;Regex Guide ‚Üí&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Grammars&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Enforce complex output structures&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://dottxt-ai.github.io/outlines/latest/features/core/output_types/#context-free-grammars&#34;&gt;Grammar Guide ‚Üí&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Other Features&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Feature&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Documentation&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Prompt templates&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Separate complex prompts from code&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://dottxt-ai.github.io/outlines/latest/features/utility/template/&#34;&gt;Template Guide ‚Üí&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Custome types&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Intuitive interface to build complex types&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://dottxt-ai.github.io/outlines/latest/features/core/output_types/#basic-python-types&#34;&gt;Python Types Guide ‚Üí&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Applications&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Encapsulate templates and types into functions&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://dottxt-ai.github.io/outlines/latest/features/utility/application/&#34;&gt;Application Guide ‚Üí&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;About .txt&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/docs/assets/images/dottxt-light.svg#gh-light-mode-only&#34; alt=&#34;dottxt logo&#34; width=&#34;100&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/dottxt-ai/outlines/main/docs/assets/images/dottxt-dark.svg#gh-dark-mode-only&#34; alt=&#34;dottxt logo&#34; width=&#34;100&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Outlines is developed and maintained by &lt;a href=&#34;https://dottxt.co&#34;&gt;.txt&lt;/a&gt;, a company dedicated to making LLMs more reliable for production applications.&lt;/p&gt; &#xA;&lt;p&gt;Our focus is on advancing structured generation technology through:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üß™ &lt;strong&gt;Cutting-edge Research&lt;/strong&gt;: We publish our findings on &lt;a href=&#34;http://blog.dottxt.co/performance-gsm8k.html&#34;&gt;structured generation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üöÄ &lt;strong&gt;Enterprise-grade solutions&lt;/strong&gt;: You can license &lt;a href=&#34;https://docs.dottxt.co&#34;&gt;our enterprise-grade libraries&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;üß© &lt;strong&gt;Open Source Collaboration&lt;/strong&gt;: We believe in building in public and contributing to the community&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Follow us on &lt;a href=&#34;https://twitter.com/dottxtai&#34;&gt;Twitter&lt;/a&gt; or check out our &lt;a href=&#34;https://blog.dottxt.co/&#34;&gt;blog&lt;/a&gt; to stay updated on our latest work in making LLMs more reliable.&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34; style=&#34;margin-bottom: 1em;&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/dottxt-ai/outlines/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/dottxt-ai/outlines?style=flat-square&amp;amp;logo=github&amp;amp;logoColor=white&amp;amp;color=ECEFF4&#34; alt=&#34;Contributors&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/dottxt-ai/outlines/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/dottxt-ai/outlines?style=flat-square&amp;amp;logo=github&amp;amp;color=BD932F&amp;amp;logoColor=white&#34; alt=&#34;Stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypistats.org/packages/outlines&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/outlines?color=A6B4A3&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/R9DSu34mGd&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1182316225284554793?color=ddb8ca&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;Discord badge&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üí° &lt;strong&gt;Have an idea?&lt;/strong&gt; Come chat with us on &lt;a href=&#34;https://discord.gg/R9DSu34mGd&#34;&gt;Discord&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üêû &lt;strong&gt;Found a bug?&lt;/strong&gt; Open an &lt;a href=&#34;https://github.com/dottxt-ai/outlines/issues&#34;&gt;issue&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üß© &lt;strong&gt;Want to contribute?&lt;/strong&gt; Consult our &lt;a href=&#34;https://dottxt-ai.github.io/outlines/latest/community/contribute/&#34;&gt;contribution guide&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Cite Outlines&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{willard2023efficient,&#xA;  title={Efficient Guided Generation for Large Language Models},&#xA;  author={Willard, Brandon T and Louf, R{\&#39;e}mi},&#xA;  journal={arXiv preprint arXiv:2307.09702},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>