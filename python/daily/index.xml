<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-12T01:35:27Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Zero6992/chatGPT-discord-bot</title>
    <updated>2022-12-12T01:35:27Z</updated>
    <id>tag:github.com,2022-12-12:/Zero6992/chatGPT-discord-bot</id>
    <link href="https://github.com/Zero6992/chatGPT-discord-bot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Integrate ChatGPT into your own discord bot&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;chatGPT-discord-bot&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;h3&gt;This is a project that provides you to build your own Discord bot using ChatGPT&lt;/h3&gt; &#xA; &lt;p&gt;⭐️ A star would be highly appreciated&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;/chat [message]&lt;/code&gt; Chat with ChatGPT!&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/private&lt;/code&gt; ChatGPT switch to private mode&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/public&lt;/code&gt; ChatGPT switch to public mode&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/reset&lt;/code&gt; ChatGPT conversation history will be erased&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Chat&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/206497774-47d960cd-1aeb-4fba-9af5-1f9d6ff41f00.gif&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Mode&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;public mode (default)&lt;/code&gt; the bot directly reply on the channel&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/206565977-d7c5d405-fdb4-4202-bbdd-715b7c8e8415.gif&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;private mode&lt;/code&gt; the bot&#39;s reply can only be seen by who use the command&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/206565873-b181e600-e793-4a94-a978-47f806b986da.gif&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Setup&lt;/h1&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;dependencies: Reverse Engineered ChatGPT by OpenAI &lt;a href=&#34;https://github.com/acheong08/ChatGPT&#34;&gt;here&lt;/a&gt; and discord.py&lt;/p&gt; &#xA;&lt;h2&gt;Step 1: Create a Discord bot&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Go to &lt;a href=&#34;https://discord.com/developers/applications&#34;&gt;https://discord.com/developers/applications&lt;/a&gt; create an application&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Build a Discord bot under the application&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Get the token from bot setting&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/205949161-4b508c6d-19a7-49b6-b8ed-7525ddbef430.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Store the token to &lt;code&gt;config.json&lt;/code&gt; under the &lt;code&gt;discord_bot_token&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/205949488-f3f2903d-7fb8-4be3-a703-2174535b3cd7.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Turn MESSAGE CONTENT INTENT &lt;code&gt;ON&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/205949323-4354bd7d-9bb9-4f4b-a87e-deb9933a89b5.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Invite your bot through OAuth2 URL Generator&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/205949600-0c7ddb40-7e82-47a0-b59a-b089f929d177.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Step 2: Email and password authentication&lt;/h2&gt; &#xA;&lt;p&gt;Save both in &lt;code&gt;config.json&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/205949713-8c0dbcca-9f63-4150-850d-bb21bac06158.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;If you are logging in with a Google or Microsoft account, please use the session token method below.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Step 2: Session token authentication&lt;/h2&gt; &#xA;&lt;p&gt;Go to &lt;a href=&#34;https://chat.openai.com/chat&#34;&gt;https://chat.openai.com/chat&lt;/a&gt; log in&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Open console with &lt;code&gt;F12&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open &lt;code&gt;Application&lt;/code&gt; tab &amp;gt; Cookies&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/36258159/205494773-32ef651a-994d-435a-9f76-a26699935dac.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Copy the value for &lt;code&gt;__Secure-next-auth.session-token&lt;/code&gt; and paste it into &lt;code&gt;config.json&lt;/code&gt; under &lt;code&gt;session_token&lt;/code&gt;. You do not need to fill out &lt;code&gt;email&lt;/code&gt; and &lt;code&gt;password&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/205950188-96ae9b35-539a-4246-857d-e97e9a0bf8fd.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Step 3: Run the bot&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open a terminal or command prompt&lt;/li&gt; &#xA; &lt;li&gt;Navigate to the directory where you installed the ChatGPT Discord bot&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;python3 main.py&lt;/code&gt; to start the bot&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Step 3: Run the bot with docker&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Build the Docker image &lt;code&gt;docker build -t chatgpt-discord-bot --platform linux/amd64 .&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run the Docker container &lt;code&gt;docker run --platform linux/amd64 -d chatgpt-discord-bot&lt;/code&gt;&lt;/p&gt; &lt;h3&gt;Stop the bot:&lt;/h3&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;docker ps&lt;/code&gt; to see the list of running services&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;docker stop &amp;lt;BOT CONTAINER ID&amp;gt;&lt;/code&gt; to stop the running bot&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Optional: Setup starting prompt&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A starting prompt would be invoked when the bot is first started or reset&lt;/li&gt; &#xA; &lt;li&gt;You can set it up by modifying the content in &lt;code&gt;starting-prompt.txt&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;All the text in the file will be fired as a prompt to the bot&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Have A Good Chat !&lt;/h3&gt;</summary>
  </entry>
  <entry>
    <title>lss233/chatgpt-mirai-qq-bot</title>
    <updated>2022-12-12T01:35:27Z</updated>
    <id>tag:github.com,2022-12-12:/lss233/chatgpt-mirai-qq-bot</id>
    <link href="https://github.com/lss233/chatgpt-mirai-qq-bot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;OpenAI ChatGPT for Mirai QQ Bot，QQ 聊天机器人！ 每个群组/好友单独一个 Conversation，文字转图片发送， Docker 快速部署，正/反向代理加速 (部分代码由 ChatGPT 生成）&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGPT Mirai QQ Bot&lt;/h1&gt; &#xA;&lt;p&gt;一款使用 OpenAI 的 ChatGPT 进行聊天的 QQ 机器人！&lt;/p&gt; &#xA;&lt;p&gt;基于&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/GraiaProject/Ariadne&#34;&gt;Ariadne&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/project-mirai/mirai-api-http&#34;&gt;mirai-http-api&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/acheong08/ChatGPT&#34;&gt;Reverse Engineered ChatGPT by OpenAI&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;支持：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 文字转图片发送&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 群聊回复引用&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 关键词触发回复&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 反向代理/正向代理&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 多种方式登录 OpenAI&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://jq.qq.com/?_wv=1027&amp;amp;k=3X55LqoY&#34;&gt;交流群&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lss233/chatgpt-mirai-qq-bot/master/.github/preview.png&#34; alt=&#34;Preview&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🔧 使用&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Linux: 通过 Docker Compose 部署 （自带 Mirai, 新人推荐)&lt;/summary&gt; &#xA; &lt;p&gt;我们使用 &lt;code&gt;docker-compose.yaml&lt;/code&gt; 整合了 &lt;a href=&#34;https://github.com/ttionya/mirai-http-docker&#34;&gt;ttionya/mirai-http&lt;/a&gt; 和本项目来实现快速部署。&lt;/p&gt; &#xA; &lt;p&gt;但是在部署过程中仍然需要一些步骤来进行配置。&lt;/p&gt; &#xA; &lt;p&gt;您可以尝试使用 &lt;a href=&#34;https://github.com/paradox8599&#34;&gt;@paradox8599&lt;/a&gt; 提供的简易部署脚本：&lt;a href=&#34;https://github.com/paradox8599/mirai-chatgpt-setup&#34;&gt;paradox8599/mirai-chatgpt-setup&lt;/a&gt; 进行较快地部署。&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;或者&lt;/strong&gt;移步至 &lt;a href=&#34;https://github.com/lss233/chatgpt-mirai-qq-bot/wiki/%E4%BD%BF%E7%94%A8-Docker-Compose-%E9%83%A8%E7%BD%B2%EF%BC%88Mirai---%E6%9C%AC%E9%A1%B9%E7%9B%AE%EF%BC%89&#34;&gt;Wiki&lt;/a&gt; 浏览手工配置的方案。&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Linux: 通过 Docker 部署 （适合已经有 Mirai 的用户)&lt;/summary&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt; &lt;p&gt;找个合适的位置，写你的 &lt;code&gt;config.json&lt;/code&gt;。&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;执行以下命令，启动 bot：&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 修改 /path/to/config.json 为你 config.json 的位置&#xA;docker run --name mirai-chatgpt-bot \&#xA;    -v /path/to/config.json:/app/config.json \&#xA;    --network host \&#xA;    lss233/chatgpt-mirai-qq-bot:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Windows: 快速部署包 (自带 Mirai，新人推荐）&lt;/summary&gt; &#xA; &lt;p&gt;我们为 Windows 用户制作了一个快速启动包，可以在 &lt;a href=&#34;https://github.com/lss233/chatgpt-mirai-qq-bot/releases&#34;&gt;Release&lt;/a&gt; 中找到。&lt;/p&gt; &#xA; &lt;p&gt;文件名为：&lt;code&gt;quickstart-windows-amd64.zip&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;手动部署&lt;/summary&gt; &#xA; &lt;p&gt;提示：你需要 Python &amp;gt;= 3.9 才能运行本项目&lt;/p&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt; &lt;p&gt;部署 Mirai ，安装 mirai-http-api 插件&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;下载本项目:&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/lss233/chatgpt-mirai-qq-bot&#xA;cd chatgpt-mirai-qq-bot&#xA;pip3 install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ol start=&#34;3&#34;&gt; &#xA;  &lt;li&gt; &lt;p&gt;重命名 &lt;code&gt;config.example.json&lt;/code&gt; 为 &lt;code&gt;config.json&lt;/code&gt;, 更改里面的配置.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;启动 bot.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 bot.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;⚙ 配置文件&lt;/h2&gt; &#xA;&lt;p&gt;你可以参考 &lt;code&gt;config.example.json&lt;/code&gt; 来写配置文件。&lt;/p&gt; &#xA;&lt;p&gt;配置文件主要包含 mirai-http-api 的连接信息和 OpenAI 的登录信息。&lt;/p&gt; &#xA;&lt;p&gt;OpenAI 注册教程： &lt;a href=&#34;https://www.cnblogs.com/mrjade/p/16968591.html&#34;&gt;https://www.cnblogs.com/mrjade/p/16968591.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;OpenAI 配置的信息可参考 &lt;a href=&#34;https://github.com/acheong08/ChatGPT/wiki/Setup&#34;&gt;这里&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;！！请注意！！ 不要把 &lt;code&gt;//&lt;/code&gt; 开头的注释也抄进去了！&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-jsonc&#34;&gt;{&#xA;    &#34;mirai&#34;: {&#xA;        &#34;qq&#34;: 123456, // 机器人的 QQ 账号&#xA;        &#34;api_key&#34;: &#34;&amp;lt;mirai-http-api 中的 verifyKey&amp;gt;&#34;,&#xA;        &#34;http_url&#34;: &#34;http://localhost:8080&#34;, // mirai-http-api 中的 http 回调地址&#xA;        &#34;ws_url&#34;: &#34;http://localhost:8080&#34; // mirai-http-api 中的 ws 回调地址&#xA;    },&#xA;    &#34;openai&#34;: {&#xA;        &#34;email&#34;: &#34;&amp;lt;YOUR_EMAIL&amp;gt;&#34;, // 你的 OpenAI 账号邮箱&#xA;        &#34;password&#34;: &#34;&amp;lt;YOUR_PASSWORD&amp;gt;&#34; // 你的 OpenAI 账号密码&#xA;    },&#xA;    &#34;text_to_image&#34;: { // 文字转图片&#xA;        &#34;font_size&#34;: 30, // 字体大小&#xA;        &#34;width&#34;: 700, // 图片宽度&#xA;        &#34;font_path&#34;: &#34;fonts/sarasa-mono-sc-regular.ttf&#34;, // 字体&#xA;        &#34;offset_x&#34;: 50, // 起始点 X&#xA;        &#34;offset_y&#34;: 50 // 起始点 Y&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;🚀 使用代理&lt;/h3&gt; &#xA;&lt;p&gt;如果你的网络访问 OpenAI 比较慢，或者你的 IP 被封锁了（需要验证码）， 可以通过配置代理的方式来连接到 OpenAI。&lt;/p&gt; &#xA;&lt;p&gt;代理有两种方式，分别为 反向代理 和 正向代理，你只需要配置其中一种方式即可。&lt;/p&gt; &#xA;&lt;h4&gt;反向代理&lt;/h4&gt; &#xA;&lt;p&gt;使用反向代理方式访问 OpenAI, 你需要准备一个可以访问到 &lt;code&gt;chat.openai.com&lt;/code&gt; 的代理网站。&lt;/p&gt; &#xA;&lt;p&gt;这可以通过 cf worker / nginx 反向代理 / vercel 等来实现，在此不作赘述。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;可以参考： &lt;a href=&#34;https://www.j000e.com/cloudflare/cfworkers_reverse_proxy.html&#34;&gt;https://www.j000e.com/cloudflare/cfworkers_reverse_proxy.html&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;你只需要代理 &lt;code&gt;chat.openai.com&lt;/code&gt; 这一个域名即可。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;在 &lt;code&gt;&#34;openai&#34;&lt;/code&gt; 中加入一条 &lt;code&gt;&#34;base_url&#34;: &amp;lt;你的反代URL&amp;gt;&lt;/code&gt; 即可。&lt;/p&gt; &#xA;&lt;p&gt;举个例子：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-jsonc&#34;&gt;    // 前面别的东西&#xA;    &#34;openai&#34;: {&#xA;        &#34;email&#34;: &#34;&amp;lt;YOUR_EMAIL&amp;gt;&#34;, // 你的 OpenAI 账号邮箱&#xA;        &#34;password&#34;: &#34;&amp;lt;YOUR_PASSWORD&amp;gt;&#34;, // 你的 OpenAI 账号密码&#xA;        &#34;base_url&#34;: &#34;https://chatgpt.proxy.lss233.com/&#34;&#xA;    },&#xA;    // 后面别的东西&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;之后，所有发往 &lt;code&gt;chat.openai.com&lt;/code&gt; 的请求都会通过 &lt;code&gt;base_url&lt;/code&gt; 中配置的地址发送。&lt;/p&gt; &#xA;&lt;h4&gt;正向代理&lt;/h4&gt; &#xA;&lt;p&gt;使用正向代理方式访问 OpenAI, 你需要在运行本项目的主机上有一个可以访问的 HTTTP/HTTPS 代理服务器。&lt;/p&gt; &#xA;&lt;p&gt;在 &lt;code&gt;&#34;openai&#34;&lt;/code&gt; 中加入一条 &lt;code&gt;&#34;proxy&#34;: &amp;lt;你的代理服务器地址&amp;gt;&lt;/code&gt; 即可。&lt;/p&gt; &#xA;&lt;p&gt;举个例子：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-jsonc&#34;&gt;    // 前面别的东西&#xA;    &#34;openai&#34;: {&#xA;        &#34;email&#34;: &#34;&amp;lt;YOUR_EMAIL&amp;gt;&#34;, // 你的 OpenAI 账号邮箱&#xA;        &#34;password&#34;: &#34;&amp;lt;YOUR_PASSWORD&amp;gt;&#34;, // 你的 OpenAI 账号密码&#xA;        &#34;proxy&#34;: &#34;http://localhost:1080&#34;&#xA;    },&#xA;    // 后面别的东西&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;OpenAI 登录不了&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;Captcha detect&lt;/code&gt;、 &lt;code&gt;State not found&lt;/code&gt; 等各种问题，都可以通过配置 &lt;code&gt;session_token&lt;/code&gt; 登录。&lt;/p&gt; &#xA;&lt;p&gt;举个例子：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-jsonc&#34;&gt;    // 前面别的东西&#xA;    &#34;openai&#34;: {&#xA;        &#34;session_token&#34;: &#34;一串ey开头的很长的东西...&#34;,&#xA;        &#34;proxy&#34;: &#34;http://localhost:1080&#34;&#xA;    },&#xA;    // 后面别的东西&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;请参考 &lt;a href=&#34;https://github.com/acheong08/ChatGPT/wiki/Setup&#34;&gt;这里&lt;/a&gt; 了解 &lt;code&gt;session_token&lt;/code&gt; 的获取方法。&lt;/p&gt; &#xA;&lt;p&gt;注： &lt;code&gt;session_token&lt;/code&gt; 具有时效性，如果长期出现错误的情况，请重新获取你的 &lt;code&gt;session_token&lt;/code&gt;。 &lt;a href=&#34;https://github.com/lss233/chatgpt-mirai-qq-bot/issues/29&#34;&gt;#29&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;📷 图片转文字&lt;/h2&gt; &#xA;&lt;p&gt;本项目会在向 QQ 群发送消息失败时，自动将消息转为图片发送。&lt;/p&gt; &#xA;&lt;p&gt;字体文件存放于 &lt;code&gt;fonts/&lt;/code&gt; 目录中。&lt;/p&gt; &#xA;&lt;p&gt;默认使用的字体是 &lt;a href=&#34;https://github.com/be5invis/Sarasa-Gothic&#34;&gt;更纱黑体&lt;/a&gt;。&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>VoltaML/voltaML-fast-stable-diffusion</title>
    <updated>2022-12-12T01:35:27Z</updated>
    <id>tag:github.com,2022-12-12:/VoltaML/voltaML-fast-stable-diffusion</id>
    <link href="https://github.com/VoltaML/voltaML-fast-stable-diffusion" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lightweight library to accelerate Stable-Diffusion, Dreambooth into fastest inference models with single line of code 🔥 🔥&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/107309002/203284627-fa180962-75b1-41dd-83a7-124b74a1fcdf.png&#34; alt=&#34;Screenshot from 2022-11-22 15-29-39&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;⚡voltaML-fast-stable-diffusion 🔥 🔥&lt;/h2&gt; &#xA;&lt;p&gt;Lightweight library to accelerate Stable-Diffusion, Dreambooth into fastest inference models with &lt;strong&gt;one single line of code&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://discord.gg/pY5SVyHmWm&#34;&gt; &lt;img src=&#34;https://dcbadge.vercel.app/api/server/pY5SVyHmWm&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;&lt;strong&gt;🔥&lt;a href=&#34;https://github.com/VoltaML/voltaML&#34;&gt;Accelerate Computer vision, NLP models etc.&lt;/a&gt; with voltaML. Upto 10X speed up in inference🔥&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;voltaML Docker Container 🐳&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/VoltaML/voltaML-fast-stable-diffusion.git&#xA;cd voltaML-fast-stable-diffusion&#xA;&#xA;sudo docker pull voltaml/volta_diffusion:v0.2 &#xA;&#xA;sudo docker run -it --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 -v $(pwd):/code --rm voltaml/volta_diffusion:v0.2 &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Own setup:&lt;/h3&gt; &#xA;&lt;p&gt;Requirements: Please refer to the requirements.txt file to set it up on your own environment.&lt;/p&gt; &#xA;&lt;p&gt;It is recommended to use our voltaml/volta_diffusion container or NVIDIA TensorRT container&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Hugging Face Login&lt;/h3&gt; &#xA;&lt;p&gt;Login into your Hugging Face account through the terminal&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;huggingface-cli login&#xA;Token: #enter your huggingface token&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Accelerate&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;bash optimize.sh --model=&#39;runwayml/stable-diffusion-v1-5&#39; # your model path/ hugging face name&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Inference&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;For TensorRT&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 volta_infer.py --backend=&#39;TRT&#39; --prompt=&#39;a gigantic robotic bipedal dinosaur, highly detailed, photorealistic, digital painting, artstation, concept art, sharp focus, illustration, art by greg rutkowski and alphonse mucha&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;For PyTorch&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 volta_infer.py --backend=&#39;PT&#39; --prompt=&#39;a gigantic robotic bipedal dinosaur, highly detailed, photorealistic, digital painting, artstation, concept art, sharp focus, illustration, art by greg rutkowski and alphonse mucha&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Benchmark&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 volta_infer.py --backend=&#39;TRT&#39; --benchmark&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The below benchmarks have been done for generating a 512x512 image, batch size 1 for 50 iterations.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;T4 (it/s)&lt;/th&gt; &#xA;   &lt;th&gt;A10 (it/s)&lt;/th&gt; &#xA;   &lt;th&gt;A100 (it/s)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PyTorch&lt;/td&gt; &#xA;   &lt;td&gt;4.3&lt;/td&gt; &#xA;   &lt;td&gt;8.8&lt;/td&gt; &#xA;   &lt;td&gt;15.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Flash attention xformers&lt;/td&gt; &#xA;   &lt;td&gt;5.5&lt;/td&gt; &#xA;   &lt;td&gt;15.6&lt;/td&gt; &#xA;   &lt;td&gt;27.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;VoltaML(TRT)&lt;/td&gt; &#xA;   &lt;td&gt;7.7&lt;/td&gt; &#xA;   &lt;td&gt;17.2&lt;/td&gt; &#xA;   &lt;td&gt;36.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/107309002/203910224-e4e89fe5-5929-4e5e-ac8d-4f126fc5c273.jpg&#34; alt=&#34;diffusion posts&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/107309002/203910230-f83eda45-eb85-48a2-b5c8-e4f3ec8c21dd.jpg&#34; alt=&#34;diffusion posts 1&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/107309002/203910233-79991ee4-24e1-4ac0-b0b2-d41543f75cef.jpg&#34; alt=&#34;diffusion posts 3&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/107309002/203910349-1168695b-816f-4d35-9fa7-7e0331816eeb.jpg&#34; alt=&#34;diffusion posts 4&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;To-Do:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Integrate Flash-attention&lt;/li&gt; &#xA; &lt;li&gt;Integrate AITemplate&lt;/li&gt; &#xA; &lt;li&gt;Try Flash-attention with TensorRT&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contribution:&lt;/h2&gt; &#xA;&lt;p&gt;We invite the open source community to contribute and help us better voltaML. Please check out our &lt;a href=&#34;https://github.com/VoltaML/voltaML-fast-stable-diffusion/raw/main/CONTRIBUTION.md&#34;&gt;contribution guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.photoroom.com/tech/stable-diffusion-25-percent-faster-and-save-seconds/&#34;&gt;https://www.photoroom.com/tech/stable-diffusion-25-percent-faster-and-save-seconds/&lt;/a&gt; &lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kamalkraj/stable-diffusion-tritonserver&#34;&gt;https://github.com/kamalkraj/stable-diffusion-tritonserver&lt;/a&gt; &lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/luohao123/gaintmodels&#34;&gt;https://github.com/luohao123/gaintmodels&lt;/a&gt; &lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/stochasticai/x-stable-diffusion&#34;&gt;https://github.com/stochasticai/x-stable-diffusion&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>