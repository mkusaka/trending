<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-10-10T01:39:48Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>relt-1/czeditor</title>
    <updated>2022-10-10T01:39:48Z</updated>
    <id>tag:github.com,2022-10-10:/relt-1/czeditor</id>
    <link href="https://github.com/relt-1/czeditor" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Fully functional Crazy Error Video editing software&lt;/p&gt; &#xA;&lt;p&gt;This application mainly targeted for old and lower hardware like core2 duo and pentium series. It&#39;s also compatible with the latest generation of hardware and CPUs.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s in alpha stage and currently supporting Windows XP and Windows 7 Errors.&lt;/p&gt; &#xA;&lt;p&gt;If you want to contribute, you can do just go to GitHub and fork the repo and start working on it.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>open-mmlab/mmcv</title>
    <updated>2022-10-10T01:39:48Z</updated>
    <id>tag:github.com,2022-10-10:/open-mmlab/mmcv</id>
    <link href="https://github.com/open-mmlab/mmcv" rel="alternate"></link>
    <summary type="html">&lt;p&gt;OpenMMLab Computer Vision Foundation&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/open-mmlab/mmcv/master/docs/en/mmcv-logo.png&#34; width=&#34;300&#34;&gt; &#xA; &lt;div&gt;&#xA;  &amp;nbsp;&#xA; &lt;/div&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;b&gt;&lt;font size=&#34;5&#34;&gt;OpenMMLab website&lt;/font&gt;&lt;/b&gt; &#xA;  &lt;sup&gt; &lt;a href=&#34;https://openmmlab.com&#34;&gt; &lt;i&gt;&lt;font size=&#34;4&#34;&gt;HOT&lt;/font&gt;&lt;/i&gt; &lt;/a&gt; &lt;/sup&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &#xA;  &lt;b&gt;&lt;font size=&#34;5&#34;&gt;OpenMMLab platform&lt;/font&gt;&lt;/b&gt; &#xA;  &lt;sup&gt; &lt;a href=&#34;https://platform.openmmlab.com&#34;&gt; &lt;i&gt;&lt;font size=&#34;4&#34;&gt;TRY IT OUT&lt;/font&gt;&lt;/i&gt; &lt;/a&gt; &lt;/sup&gt; &#xA; &lt;/div&gt; &#xA; &lt;div&gt;&#xA;  &amp;nbsp;&#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://mmcv.readthedocs.io/en/latest/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-latest-blue&#34; alt=&#34;docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/mmcv/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/mmcv&#34; alt=&#34;PyPI - Python Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/mmcv&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/mmcv&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmcv/actions&#34;&gt;&lt;img src=&#34;https://github.com/open-mmlab/mmcv/workflows/build/badge.svg?sanitize=true&#34; alt=&#34;badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/open-mmlab/mmcv&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/open-mmlab/mmcv/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmcv/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/open-mmlab/mmcv.svg?sanitize=true&#34; alt=&#34;license&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmcv/master/README_zh-CN.md&#34;&gt;简体中文&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;MMCV is a foundational library for computer vision research and supports many research projects as below:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mim&#34;&gt;MIM&lt;/a&gt;: MIM installs OpenMMLab packages.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmclassification&#34;&gt;MMClassification&lt;/a&gt;: OpenMMLab image classification toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmdetection&#34;&gt;MMDetection&lt;/a&gt;: OpenMMLab detection toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmdetection3d&#34;&gt;MMDetection3D&lt;/a&gt;: OpenMMLab&#39;s next-generation platform for general 3D object detection.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmrotate&#34;&gt;MMRotate&lt;/a&gt;: OpenMMLab rotated object detection toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmsegmentation&#34;&gt;MMSegmentation&lt;/a&gt;: OpenMMLab semantic segmentation toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmocr&#34;&gt;MMOCR&lt;/a&gt;: OpenMMLab text detection, recognition, and understanding toolbox.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmpose&#34;&gt;MMPose&lt;/a&gt;: OpenMMLab pose estimation toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmhuman3d&#34;&gt;MMHuman3D&lt;/a&gt;: OpenMMLab 3D human parametric model toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmselfsup&#34;&gt;MMSelfSup&lt;/a&gt;: OpenMMLab self-supervised learning toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmrazor&#34;&gt;MMRazor&lt;/a&gt;: OpenMMLab model compression toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmfewshot&#34;&gt;MMFewShot&lt;/a&gt;: OpenMMLab fewshot learning toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmaction2&#34;&gt;MMAction2&lt;/a&gt;: OpenMMLab&#39;s next-generation action understanding toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmtracking&#34;&gt;MMTracking&lt;/a&gt;: OpenMMLab video perception toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmflow&#34;&gt;MMFlow&lt;/a&gt;: OpenMMLab optical flow toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmediting&#34;&gt;MMEditing&lt;/a&gt;: OpenMMLab image and video editing toolbox.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmgeneration&#34;&gt;MMGeneration&lt;/a&gt;: OpenMMLab image and video generative models toolbox.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmdeploy&#34;&gt;MMDeploy&lt;/a&gt;: OpenMMLab model deployment framework.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;It provides the following functionalities.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Universal IO APIs&lt;/li&gt; &#xA; &lt;li&gt;Image/Video processing&lt;/li&gt; &#xA; &lt;li&gt;Image and annotation visualization&lt;/li&gt; &#xA; &lt;li&gt;Useful utilities (progress bar, timer, ...)&lt;/li&gt; &#xA; &lt;li&gt;PyTorch runner with hooking mechanism&lt;/li&gt; &#xA; &lt;li&gt;Various CNN architectures&lt;/li&gt; &#xA; &lt;li&gt;High-quality implementation of common CUDA ops&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;It supports the following systems.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Linux&lt;/li&gt; &#xA; &lt;li&gt;Windows&lt;/li&gt; &#xA; &lt;li&gt;macOS&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;http://mmcv.readthedocs.io/en/latest&#34;&gt;documentation&lt;/a&gt; for more features and usage.&lt;/p&gt; &#xA;&lt;p&gt;Note: MMCV requires Python 3.6+.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;There are two versions of MMCV:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;mmcv-full&lt;/strong&gt;: comprehensive, with full features and various CUDA ops out of box. It takes longer time to build.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;mmcv&lt;/strong&gt;: lite, without CUDA ops but all other features, similar to mmcv&amp;lt;1.0.0. It is useful when you do not need those CUDA ops.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Do not install both versions in the same environment, otherwise you may encounter errors like &lt;code&gt;ModuleNotFound&lt;/code&gt;. You need to uninstall one before installing the other. &lt;code&gt;Installing the full version is highly recommended if CUDA is available&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;a. Install the full version.&lt;/p&gt; &#xA;&lt;p&gt;Before installing mmcv-full, make sure that PyTorch has been successfully installed following the &lt;a href=&#34;https://pytorch.org/&#34;&gt;official guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We provide pre-built mmcv packages (recommended) with different PyTorch and CUDA versions to simplify the building for &lt;strong&gt;Linux and Windows systems&lt;/strong&gt;. In addition, you can run &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmcv/master/.dev_scripts/check_installation.py&#34;&gt;check_installation.py&lt;/a&gt; to check the installation of mmcv-full after running the installation commands.&lt;/p&gt; &#xA;&lt;p&gt;i. Install the latest version.&lt;/p&gt; &#xA;&lt;p&gt;The rule for installing the latest &lt;code&gt;mmcv-full&lt;/code&gt; is as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/{cu_version}/{torch_version}/index.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please replace &lt;code&gt;{cu_version}&lt;/code&gt; and &lt;code&gt;{torch_version}&lt;/code&gt; in the url to your desired one. For example, to install the latest &lt;code&gt;mmcv-full&lt;/code&gt; with &lt;code&gt;CUDA 11.1&lt;/code&gt; and &lt;code&gt;PyTorch 1.9.0&lt;/code&gt;, use the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: mmcv-full is only compiled on PyTorch 1.x.0 because the compatibility usually holds between 1.x.0 and 1.x.1. If your PyTorch version is 1.x.1, you can install mmcv-full compiled with PyTorch 1.x.0 and it usually works well. For example, if your PyTorch version is 1.8.1 and CUDA version is 11.1, you can use the following command to install mmcv-full.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more details, please refer the the following tables and delete &lt;code&gt;=={mmcv_version}&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;ii. Install a specified version.&lt;/p&gt; &#xA;&lt;p&gt;The rule for installing a specified &lt;code&gt;mmcv-full&lt;/code&gt; is as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/{cu_version}/{torch_version}/index.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;First of all, please refer to the Releases and replace &lt;code&gt;{mmcv_version}&lt;/code&gt; a specified one. e.g. &lt;code&gt;1.3.9&lt;/code&gt;. Then replace &lt;code&gt;{cu_version}&lt;/code&gt; and &lt;code&gt;{torch_version}&lt;/code&gt; in the url to your desired versions. For example, to install &lt;code&gt;mmcv-full==1.3.9&lt;/code&gt; with &lt;code&gt;CUDA 11.1&lt;/code&gt; and &lt;code&gt;PyTorch 1.9.0&lt;/code&gt;, use the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install mmcv-full==1.3.9 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more details, please refer the the following tables.&lt;/p&gt; &#xA;&lt;table class=&#34;docutils&#34;&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th width=&#34;80&#34;&gt; CUDA &lt;/th&gt; &#xA;   &lt;th valign=&#34;bottom&#34; align=&#34;left&#34; width=&#34;120&#34;&gt;torch 1.11&lt;/th&gt; &#xA;   &lt;th valign=&#34;bottom&#34; align=&#34;left&#34; width=&#34;120&#34;&gt;torch 1.10&lt;/th&gt; &#xA;   &lt;th valign=&#34;bottom&#34; align=&#34;left&#34; width=&#34;120&#34;&gt;torch 1.9&lt;/th&gt; &#xA;   &lt;th valign=&#34;bottom&#34; align=&#34;left&#34; width=&#34;120&#34;&gt;torch 1.8&lt;/th&gt; &#xA;   &lt;th valign=&#34;bottom&#34; align=&#34;left&#34; width=&#34;120&#34;&gt;torch 1.7&lt;/th&gt; &#xA;   &lt;th valign=&#34;bottom&#34; align=&#34;left&#34; width=&#34;120&#34;&gt;torch 1.6&lt;/th&gt; &#xA;   &lt;th valign=&#34;bottom&#34; align=&#34;left&#34; width=&#34;120&#34;&gt;torch 1.5&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;11.5&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu115/torch1.11.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;11.3&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.11.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.10.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;  &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;11.1&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;11.0&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu110/torch1.7.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;10.2&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu102/torch1.11.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu102/torch1.10.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu102/torch1.9.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu102/torch1.8.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu102/torch1.7.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu102/torch1.6.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt;pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu102/torch1.5.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;10.1&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt; pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.8.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt; pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.7.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt; pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.6.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt; pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.5.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;9.2&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt; pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu92/torch1.7.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt; pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu92/torch1.6.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt; pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cu92/torch1.5.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;cpu&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt; pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.11.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt; pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.10.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt; pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.9.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt; pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.8.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt; pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.7.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt; pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.6.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&#xA;    &lt;details&gt;&#xA;     &lt;summary&gt; install &lt;/summary&gt;&#xA;     &lt;pre&gt;&lt;code&gt; pip install mmcv-full=={mmcv_version} -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.5.0/index.html&lt;/code&gt;&lt;/pre&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The pre-built packages provided above do not include all versions of mmcv-full, you can click on the corresponding links to see the supported versions. For example, you can click &lt;a href=&#34;https://download.openmmlab.com/mmcv/dist/cu102/torch1.8.0/index.html&#34;&gt;cu102-torch1.8.0&lt;/a&gt; and you can see that &lt;code&gt;cu102-torch1.8.0&lt;/code&gt; only provides 1.3.0 and above versions of mmcv-full. In addition, We no longer provide &lt;code&gt;mmcv-full&lt;/code&gt; pre-built packages compiled with &lt;code&gt;PyTorch 1.3 &amp;amp; 1.4&lt;/code&gt; since v1.3.17. You can find previous versions that compiled with PyTorch 1.3 &amp;amp; 1.4 &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmcv/master/docs/en/get_started/previous_versions.md&#34;&gt;here&lt;/a&gt;. The compatibility is still ensured in our CI, but we will discard the support of PyTorch 1.3 &amp;amp; 1.4 next year.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: mmcv-full does not provide pre-built packages for &lt;code&gt;cu102-torch1.11&lt;/code&gt; and &lt;code&gt;cu92-torch*&lt;/code&gt; on Windows.&lt;/p&gt; &#xA;&lt;p&gt;Another way is to compile locally by running&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pip install mmcv-full&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that the local compiling may take up to 10 mins.&lt;/p&gt; &#xA;&lt;p&gt;b. Install the lite version.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pip install mmcv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;c. Install full version with custom operators for onnxruntime&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Check &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmcv/master/docs/en/deployment/onnxruntime_op.md&#34;&gt;here&lt;/a&gt; for detailed instruction.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you would like to build MMCV from source, please refer to the &lt;a href=&#34;https://mmcv.readthedocs.io/en/latest/get_started/build.html&#34;&gt;guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;p&gt;If you face some installation issues, CUDA related issues or RuntimeErrors, you may first refer to this &lt;a href=&#34;https://mmcv.readthedocs.io/en/latest/faq.html&#34;&gt;Frequently Asked Questions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find this project useful in your research, please consider cite:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-latex&#34;&gt;@misc{mmcv,&#xA;    title={{MMCV: OpenMMLab} Computer Vision Foundation},&#xA;    author={MMCV Contributors},&#xA;    howpublished = {\url{https://github.com/open-mmlab/mmcv}},&#xA;    year={2018}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We appreciate all contributions to improve MMCV. Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmcv/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for the contributing guideline.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MMCV is released under the Apache 2.0 license, while some specific operations in this library are with other licenses. Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmcv/master/LICENSES.md&#34;&gt;LICENSES.md&lt;/a&gt; for the careful check, if you are using our code for commercial matters.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>sczhou/CodeFormer</title>
    <updated>2022-10-10T01:39:48Z</updated>
    <id>tag:github.com,2022-10-10:/sczhou/CodeFormer</id>
    <link href="https://github.com/sczhou/CodeFormer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;[NeurIPS 2022] Towards Robust Blind Face Restoration with Codebook Lookup Transformer&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/CodeFormer_logo.png&#34; height=&#34;110&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Towards Robust Blind Face Restoration with Codebook Lookup Transformer (NeurIPS 2022)&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2206.11253&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://shangchenzhou.com/projects/CodeFormer/&#34;&gt;Project Page&lt;/a&gt; | &lt;a href=&#34;https://youtu.be/d3VDpkXlueI&#34;&gt;Video&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1m52PNveE4PBhYrecj34cnpEeiHcC5LTb?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;google colab logo&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/sczhou/CodeFormer&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Demo-%F0%9F%A4%97%20Hugging%20Face-blue&#34; alt=&#34;Hugging Face&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://replicate.com/sczhou/codeformer&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Demo-%F0%9F%9A%80%20Replicate-blue&#34; alt=&#34;Replicate&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://visitor-badge.laobi.icu/badge?page_id=sczhou/CodeFormer&#34; alt=&#34;visitors&#34;&gt;&lt;/p&gt; &#xA;&lt;!-- ![visitors](https://visitor-badge.glitch.me/badge?page_id=sczhou/CodeFormer) --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://shangchenzhou.com/&#34;&gt;Shangchen Zhou&lt;/a&gt;, &lt;a href=&#34;https://ckkelvinchan.github.io/&#34;&gt;Kelvin C.K. Chan&lt;/a&gt;, &lt;a href=&#34;https://li-chongyi.github.io/&#34;&gt;Chongyi Li&lt;/a&gt;, &lt;a href=&#34;https://www.mmlab-ntu.com/person/ccloy/&#34;&gt;Chen Change Loy&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;S-Lab, Nanyang Technological University&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/network.jpg&#34; width=&#34;800px&#34;&gt; &#xA;&lt;p&gt;&lt;span&gt;⭐&lt;/span&gt; If CodeFormer is helpful to your images or projects, please help star this repo. Thanks! &lt;span&gt;🤗&lt;/span&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;[&lt;font color=&#34;#d1585d&#34;&gt;News&lt;/font&gt;]&lt;/strong&gt;: &lt;span&gt;🐳&lt;/span&gt; &lt;em&gt;Due to copyright issues, we have to delay the release of the training code (expected by the end of this year). Please star and stay tuned for our future updates!&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Update&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.10.05&lt;/strong&gt;: Support video input &lt;code&gt;--input_path [YOUR_VIDOE.mp4]&lt;/code&gt;. Try it to enhance your videos! &lt;span&gt;🎬&lt;/span&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.09.14&lt;/strong&gt;: Integrated to &lt;span&gt;🤗&lt;/span&gt; &lt;a href=&#34;https://huggingface.co/spaces&#34;&gt;Hugging Face&lt;/a&gt;. Try out online demo! &lt;a href=&#34;https://huggingface.co/spaces/sczhou/CodeFormer&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Demo-%F0%9F%A4%97%20Hugging%20Face-blue&#34; alt=&#34;Hugging Face&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.09.09&lt;/strong&gt;: Integrated to &lt;span&gt;🚀&lt;/span&gt; &lt;a href=&#34;https://replicate.com/explore&#34;&gt;Replicate&lt;/a&gt;. Try out online demo! &lt;a href=&#34;https://replicate.com/sczhou/codeformer&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Demo-%F0%9F%9A%80%20Replicate-blue&#34; alt=&#34;Replicate&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.09.04&lt;/strong&gt;: Add face upsampling &lt;code&gt;--face_upsample&lt;/code&gt; for high-resolution AI-created face enhancement.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.08.23&lt;/strong&gt;: Some modifications on face detection and fusion for better AI-created face enhancement.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.08.07&lt;/strong&gt;: Integrate &lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN&#34;&gt;Real-ESRGAN&lt;/a&gt; to support background image enhancement.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.07.29&lt;/strong&gt;: Integrate new face detectors of &lt;code&gt;[&#39;RetinaFace&#39;(default), &#39;YOLOv5&#39;]&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.07.17&lt;/strong&gt;: Add Colab demo of CodeFormer. &lt;a href=&#34;https://colab.research.google.com/drive/1m52PNveE4PBhYrecj34cnpEeiHcC5LTb?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;google colab logo&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.07.16&lt;/strong&gt;: Release inference code for face restoration. &lt;span&gt;😊&lt;/span&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.06.21&lt;/strong&gt;: This repo is created.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;TODO&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add checkpoint for face inpainting&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add checkpoint for face colorization&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add training code and config files&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;del&gt;Add background image enhancement&lt;/del&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;&lt;span&gt;🐼&lt;/span&gt; Try Enhancing Old Photos / Fixing AI-arts&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://imgsli.com/MTI3NTE2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/imgsli_1.jpg&#34; height=&#34;226px&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://imgsli.com/MTI3NTE1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/imgsli_2.jpg&#34; height=&#34;226px&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://imgsli.com/MTI3NTIw&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/imgsli_3.jpg&#34; height=&#34;226px&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Face Restoration&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/restoration_result1.png&#34; width=&#34;400px&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/restoration_result2.png&#34; width=&#34;400px&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/restoration_result3.png&#34; width=&#34;400px&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/restoration_result4.png&#34; width=&#34;400px&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Face Color Enhancement and Restoration&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/color_enhancement_result1.png&#34; width=&#34;400px&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/color_enhancement_result2.png&#34; width=&#34;400px&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Face Inpainting&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/inpainting_result1.png&#34; width=&#34;400px&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/inpainting_result2.png&#34; width=&#34;400px&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Dependencies and Installation&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Pytorch &amp;gt;= 1.7.1&lt;/li&gt; &#xA; &lt;li&gt;CUDA &amp;gt;= 10.1&lt;/li&gt; &#xA; &lt;li&gt;Other required packages in &lt;code&gt;requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# git clone this repository&#xA;git clone https://github.com/sczhou/CodeFormer&#xA;cd CodeFormer&#xA;&#xA;# create new anaconda env&#xA;conda create -n codeformer python=3.8 -y&#xA;conda activate codeformer&#xA;&#xA;# install python dependencies&#xA;pip3 install -r requirements.txt&#xA;python basicsr/setup.py develop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- conda install -c conda-forge dlib --&gt; &#xA;&lt;h3&gt;Quick Inference&lt;/h3&gt; &#xA;&lt;h4&gt;Download Pre-trained Models:&lt;/h4&gt; &#xA;&lt;p&gt;Download the facelib pretrained models from [&lt;a href=&#34;https://drive.google.com/drive/folders/1b_3qwrzY_kTQh0-SnBoGBgOrJ_PLZSKm?usp=sharing&#34;&gt;Google Drive&lt;/a&gt; | &lt;a href=&#34;https://entuedu-my.sharepoint.com/:f:/g/personal/s200094_e_ntu_edu_sg/EvDxR7FcAbZMp_MA9ouq7aQB8XTppMb3-T0uGZ_2anI2mg?e=DXsJFo&#34;&gt;OneDrive&lt;/a&gt;] to the &lt;code&gt;weights/facelib&lt;/code&gt; folder. You can manually download the pretrained models OR download by runing the following command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/download_pretrained_models.py facelib&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Download the CodeFormer pretrained models from [&lt;a href=&#34;https://drive.google.com/drive/folders/1CNNByjHDFt0b95q54yMVp6Ifo5iuU6QS?usp=sharing&#34;&gt;Google Drive&lt;/a&gt; | &lt;a href=&#34;https://entuedu-my.sharepoint.com/:f:/g/personal/s200094_e_ntu_edu_sg/EoKFj4wo8cdIn2-TY2IV6CYBhZ0pIG4kUOeHdPR_A5nlbg?e=AO8UN9&#34;&gt;OneDrive&lt;/a&gt;] to the &lt;code&gt;weights/CodeFormer&lt;/code&gt; folder. You can manually download the pretrained models OR download by runing the following command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/download_pretrained_models.py CodeFormer&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Prepare Testing Data:&lt;/h4&gt; &#xA;&lt;p&gt;You can put the testing images in the &lt;code&gt;inputs/TestWhole&lt;/code&gt; folder. If you would like to test on cropped and aligned faces, you can put them in the &lt;code&gt;inputs/cropped_faces&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;h4&gt;Testing on Face Restoration:&lt;/h4&gt; &#xA;&lt;p&gt;[Note] If you want to compare CodeFormer in your paper, please run the following command indicating &lt;code&gt;--has_aligned&lt;/code&gt; (for cropped and aligned face), as the command for the whole image will involve a process of face-background fusion that may damage hair texture on the boundary, which leads to unfair comparison.&lt;/p&gt; &#xA;&lt;p&gt;🧑🏻 Face Restoration (cropped and aligned face)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# For cropped and aligned faces&#xA;python inference_codeformer.py -w 0.5 --has_aligned --input_path [input folder]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;span&gt;🖼&lt;/span&gt; Whole Image Enhancement&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# For whole image&#xA;# Add &#39;--bg_upsampler realesrgan&#39; to enhance the background regions with Real-ESRGAN&#xA;# Add &#39;--face_upsample&#39; to further upsample restorated face with Real-ESRGAN&#xA;python inference_codeformer.py -w 0.7 --input_path [image folder/image path]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;span&gt;🎬&lt;/span&gt; Video Enhancement&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# For video clips&#xA;# Set frame rate of saved video via &#39;--save_video_fps 24&#39;&#xA;python inference_codeformer.py --bg_upsampler realesrgan --face_upsample -w 1.0 --input_path [video path] --save_video_fps 24&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Fidelity weight &lt;em&gt;w&lt;/em&gt; lays in [0, 1]. Generally, smaller &lt;em&gt;w&lt;/em&gt; tends to produce a higher-quality result, while larger &lt;em&gt;w&lt;/em&gt; yields a higher-fidelity result.&lt;/p&gt; &#xA;&lt;p&gt;The results will be saved in the &lt;code&gt;results&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;h3&gt;Citation&lt;/h3&gt; &#xA;&lt;p&gt;If our work is useful for your research, please consider citing:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{zhou2022codeformer,&#xA;    author = {Zhou, Shangchen and Chan, Kelvin C.K. and Li, Chongyi and Loy, Chen Change},&#xA;    title = {Towards Robust Blind Face Restoration with Codebook Lookup TransFormer},&#xA;    booktitle = {NeurIPS},&#xA;    year = {2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;License&lt;/h3&gt; &#xA;&lt;p&gt;This project is licensed under &lt;a rel=&#34;license&#34; href=&#34;https://github.com/sczhou/CodeFormer/raw/master/LICENSE&#34;&gt;S-Lab License 1.0&lt;/a&gt;. Redistribution and use for non-commercial purposes should follow this license.&lt;/p&gt; &#xA;&lt;h3&gt;Acknowledgement&lt;/h3&gt; &#xA;&lt;p&gt;This project is based on &lt;a href=&#34;https://github.com/XPixelGroup/BasicSR&#34;&gt;BasicSR&lt;/a&gt;. Some codes are brought from &lt;a href=&#34;https://github.com/samb-t/unleashing-transformers&#34;&gt;Unleashing Transformers&lt;/a&gt;, &lt;a href=&#34;https://github.com/deepcam-cn/yolov5-face&#34;&gt;YOLOv5-face&lt;/a&gt;, and &lt;a href=&#34;https://github.com/xinntao/facexlib&#34;&gt;FaceXLib&lt;/a&gt;. We also adopt &lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN&#34;&gt;Real-ESRGAN&lt;/a&gt; to support background image enhancement. Thanks for their awesome works.&lt;/p&gt; &#xA;&lt;h3&gt;Contact&lt;/h3&gt; &#xA;&lt;p&gt;If you have any question, please feel free to reach me out at &lt;code&gt;shangchenzhou@gmail.com&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>