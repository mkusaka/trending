<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-09T01:35:13Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Doubiiu/DynamiCrafter</title>
    <updated>2024-02-09T01:35:13Z</updated>
    <id>tag:github.com,2024-02-09:/Doubiiu/DynamiCrafter</id>
    <link href="https://github.com/Doubiiu/DynamiCrafter" rel="alternate"></link>
    <summary type="html">&lt;p&gt;DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;&lt;em&gt;&lt;strong&gt;&lt;em&gt;&lt;strong&gt;DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;!-- ![](./assets/logo_long.png#gh-light-mode-only){: width=&#34;50%&#34;} --&gt; &#xA;&lt;!-- ![](./assets/logo_long_dark.png#gh-dark-mode-only=100x20) --&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/logo_long.png&#34; style=&#34;height:100px&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.12190&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2310.12190-b31b1b.svg?sanitize=true&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&#34;https://doubiiu.github.io/projects/DynamiCrafter/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project-Page-Green&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&#34;https://huggingface.co/spaces/Doubiiu/DynamiCrafter&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Demo-blue&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&#34;https://youtu.be/0NfmIsNAg-g&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Youtube-Video-b31b1b.svg?sanitize=true&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://openxlab.org.cn/apps/detail/JinboXING/DynamiCrafter&#34;&gt;&lt;img src=&#34;https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg?sanitize=true&#34; alt=&#34;Open in OpenXLab&#34;&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://replicate.com/camenduru/dynami-crafter-576x1024&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/replicate-Demo-blue&#34;&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://github.com/camenduru/DynamiCrafter-colab&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Colab-Demo-Green&#34;&gt;&lt;/a&gt;&amp;nbsp;&lt;a href=&#34;https://huggingface.co/papers/2310.12190&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Page-blue&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;a href=&#34;https://doubiiu.github.io/&#34;&gt;Jinbo Xing&lt;/a&gt;, &lt;a href=&#34;https://menghanxia.github.io&#34;&gt;Menghan Xia*&lt;/a&gt;, &lt;a href=&#34;https://yzhang2016.github.io&#34;&gt;Yong Zhang&lt;/a&gt;, &lt;a href=&#34;&#34;&gt;Haoxin Chen&lt;/a&gt;, &lt;a href=&#34;&#34;&gt;Wangbo Yu&lt;/a&gt;, &lt;br&gt;&lt;a href=&#34;https://github.com/hyliu&#34;&gt;Hanyuan Liu&lt;/a&gt;, &lt;a href=&#34;https://xinntao.github.io/&#34;&gt;Xintao Wang&lt;/a&gt;, &lt;a href=&#34;https://www.cse.cuhk.edu.hk/~ttwong/myself.html&#34;&gt;Tien-Tsin Wong*&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/citations?hl=en&amp;amp;user=4oXBp9UAAAAJ&amp;amp;view_op=list_works&amp;amp;sortby=pubdate&#34;&gt;Ying Shan&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt; &lt;br&gt;&lt;br&gt; (* corresponding authors)&lt;/p&gt; &#xA; &lt;p&gt;From CUHK and Tencent AI Lab.&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;🔆 Introduction&lt;/h2&gt; &#xA;&lt;h3&gt;🔥🔥 New Update Rolls Out for DynamiCrafter! Better Dynamic, Higher Resolution, and Stronger Coherence! &lt;br&gt;&lt;/h3&gt; &#xA;&lt;p&gt;🤗 DynamiCrafter can animate open-domain still images based on &lt;strong&gt;text prompt&lt;/strong&gt; by leveraging the pre-trained video diffusion priors. Please check our project page and paper for more information. &lt;br&gt; 😀 We will continue to improve the model&#39;s performance.&lt;/p&gt; &#xA;&lt;p&gt;👀 Seeking comparisons with &lt;a href=&#34;https://stability.ai/news/stable-video-diffusion-open-ai-video-model&#34;&gt;Stable Video Diffusion&lt;/a&gt; and &lt;a href=&#34;https://pika.art/&#34;&gt;PikaLabs&lt;/a&gt;? Click the image below. &lt;a href=&#34;https://www.youtube.com/watch?v=0NfmIsNAg-g&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/0NfmIsNAg-g/0.jpg&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;1.1. Showcases (576x1024)&lt;/h3&gt; &#xA;&lt;table class=&#34;center&#34;&gt; &#xA; &lt;!-- &lt;tr&gt;&#xA;    &lt;td colspan=&#34;1&#34;&gt;&#34;fireworks display&#34;&lt;/td&gt;&#xA;    &lt;td colspan=&#34;1&#34;&gt;&#34;a robot is walking through a destroyed city&#34;&lt;/td&gt;&#xA;  &lt;/tr&gt; --&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/showcase/firework03.gif&#34; width=&#34;340&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/showcase/robot01.gif&#34; width=&#34;340&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;!-- &lt;tr&gt;&#xA;    &lt;td colspan=&#34;1&#34;&gt;&#34;riding a bike under a bridge&#34;&lt;/td&gt;&#xA;    &lt;td colspan=&#34;1&#34;&gt;&#34;&#34;&lt;/td&gt;&#xA;  &lt;/tr&gt; --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/showcase/bike_chineseink.gif&#34; width=&#34;340&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/showcase/girl07.gif&#34; width=&#34;340&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;1.2. Showcases (320x512)&lt;/h3&gt; &#xA;&lt;table class=&#34;center&#34;&gt; &#xA; &lt;!-- &lt;tr&gt;&#xA;    &lt;td colspan=&#34;1&#34;&gt;&#34;fireworks display&#34;&lt;/td&gt;&#xA;    &lt;td colspan=&#34;1&#34;&gt;&#34;a robot is walking through a destroyed city&#34;&lt;/td&gt;&#xA;  &lt;/tr&gt; --&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/showcase/bloom2.gif&#34; width=&#34;340&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/showcase/train_anime02.gif&#34; width=&#34;340&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;!-- &lt;tr&gt;&#xA;    &lt;td colspan=&#34;1&#34;&gt;&#34;riding a bike under a bridge&#34;&lt;/td&gt;&#xA;    &lt;td colspan=&#34;1&#34;&gt;&#34;&#34;&lt;/td&gt;&#xA;  &lt;/tr&gt; --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/showcase/pour_honey.gif&#34; width=&#34;340&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/showcase/lighthouse.gif&#34; width=&#34;340&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;1.3. Showcases (256x256)&lt;/h3&gt; &#xA;&lt;table class=&#34;center&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td colspan=&#34;2&#34;&gt;&#34;bear playing guitar happily, snowing&#34;&lt;/td&gt; &#xA;   &lt;td colspan=&#34;2&#34;&gt;&#34;boy walking on the street&#34;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/showcase/guitar0.jpeg_00.png&#34; width=&#34;170&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/showcase/guitar0.gif&#34; width=&#34;170&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/showcase/walk0.png_00.png&#34; width=&#34;170&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/showcase/walk0.gif&#34; width=&#34;170&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;!-- &lt;tr&gt;&#xA;    &lt;td colspan=&#34;2&#34;&gt;&#34;two people dancing&#34;&lt;/td&gt;&#xA;    &lt;td colspan=&#34;2&#34;&gt;&#34;girl talking and blinking&#34;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/showcase/dance1.jpeg_00.png width=&#34;170&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/showcase/dance1.gif width=&#34;170&#34;&gt;&#xA;  &lt;/td&gt;&#xA;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/showcase/girl3.jpeg_00.png width=&#34;170&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/showcase/girl3.gif width=&#34;170&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;/tr&gt; --&gt; &#xA;  &lt;!-- &lt;tr&gt;&#xA;    &lt;td colspan=&#34;2&#34;&gt;&#34;zoom-in, a landscape, springtime&#34;&lt;/td&gt;&#xA;    &lt;td colspan=&#34;2&#34;&gt;&#34;A blonde woman rides on top of a moving &lt;br&gt;washing machine into the sunset.&#34;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/showcase/Upscaled_Aime_Tribolet_springtime_landscape_golden_hour_morning_pale_yel_e6946f8d-37c1-4ce8-bf62-6ba90d23bd93.mp4_00.png width=&#34;170&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/showcase/Upscaled_Aime_Tribolet_springtime_landscape_golden_hour_morning_pale_yel_e6946f8d-37c1-4ce8-bf62-6ba90d23bd93.gif width=&#34;170&#34;&gt;&#xA;  &lt;/td&gt;&#xA;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/showcase/Upscaled_Alex__State_Blonde_woman_riding_on_top_of_a_moving_washing_mach_c31acaa3-dd30-459f-a109-2d2eb4c00fe2.mp4_00.png width=&#34;170&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/showcase/Upscaled_Alex__State_Blonde_woman_riding_on_top_of_a_moving_washing_mach_c31acaa3-dd30-459f-a109-2d2eb4c00fe2.gif width=&#34;170&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;&#xA;  &lt;tr&gt;&#xA;    &lt;td colspan=&#34;2&#34;&gt;&#34;explode colorful smoke coming out&#34;&lt;/td&gt;&#xA;    &lt;td colspan=&#34;2&#34;&gt;&#34;a bird on the tree branch&#34;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/showcase/explode0.jpeg_00.png width=&#34;170&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/showcase/explode0.gif width=&#34;170&#34;&gt;&#xA;  &lt;/td&gt;&#xA;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/showcase/bird000.jpeg width=&#34;170&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/showcase/bird000.gif width=&#34;170&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;/tr&gt; --&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;2. Applications&lt;/h3&gt; &#xA;&lt;h4&gt;2.1 Storytelling video generation (see project page for more details)&lt;/h4&gt; &#xA;&lt;table class=&#34;center&#34;&gt; &#xA; &lt;!-- &lt;tr style=&#34;font-weight: bolder;text-align:center;&#34;&gt;&#xA;        &lt;td&gt;Input&lt;/td&gt;&#xA;        &lt;td&gt;Output&lt;/td&gt;&#xA;        &lt;td&gt;Input&lt;/td&gt;&#xA;        &lt;td&gt;Output&lt;/td&gt;&#xA;    &lt;/tr&gt; --&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td colspan=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/application/storytellingvideo.gif&#34; width=&#34;250&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h4&gt;2.2 Looping video generation&lt;/h4&gt; &#xA;&lt;table class=&#34;center&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/application/60.gif&#34; width=&#34;300&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/application/35.gif&#34; width=&#34;300&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/application/36.gif&#34; width=&#34;300&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;!-- &lt;tr&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/application/05.gif width=&#34;300&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/application/25.gif width=&#34;300&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/application/34.gif width=&#34;300&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;/tr&gt; --&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h4&gt;2.3 Generative frame interpolation&lt;/h4&gt; &#xA;&lt;table class=&#34;center&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr style=&#34;font-weight: bolder;text-align:center;&#34;&gt; &#xA;   &lt;td&gt;Input starting frame&lt;/td&gt; &#xA;   &lt;td&gt;Input ending frame&lt;/td&gt; &#xA;   &lt;td&gt;Generated video&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/application/gkxX0kb8mE8_input_start.png&#34; width=&#34;250&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/application/gkxX0kb8mE8_input_end.png&#34; width=&#34;250&#34;&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Doubiiu/DynamiCrafter/main/assets/application/gkxX0kb8mE8.gif&#34; width=&#34;250&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;!-- &lt;tr&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/application/YwHJYWvv_dM_input_start.png width=&#34;250&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/application/YwHJYWvv_dM_input_end.png width=&#34;250&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/application/YwHJYWvv_dM.gif width=&#34;250&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;&#xA;  &lt;tr&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/application/ypDLB52Ykk4_input_start.png width=&#34;250&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/application/ypDLB52Ykk4_input_end.png width=&#34;250&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;td&gt;&#xA;    &lt;img src=assets/application/ypDLB52Ykk4.gif width=&#34;250&#34;&gt;&#xA;  &lt;/td&gt;&#xA;  &lt;/tr&gt; --&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;📝 Changelog&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2024.02.05]&lt;/strong&gt;: 🔥🔥 Release high-resolution models (320x512 &amp;amp; 576x1024).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.12.02]&lt;/strong&gt;: Launch the local Gradio demo.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.11.29]&lt;/strong&gt;: Release the main model at a resolution of 256x256.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.11.27]&lt;/strong&gt;: Launch the project page and update the arXiv preprint.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;🧰 Models&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Resolution&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;GPU Mem. &amp;amp; Inference Time (A100)&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Checkpoint&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;DynamiCrafter1024&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;576x1024&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;18.3GB &amp;amp; 75s (&lt;code&gt;perframe_ae=True&lt;/code&gt;)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://huggingface.co/Doubiiu/DynamiCrafter_1024/blob/main/model.ckpt&#34;&gt;Hugging Face&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;DynamiCrafter512&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;320x512&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;12.8GB &amp;amp; 20s (&lt;code&gt;perframe_ae=True&lt;/code&gt;)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://huggingface.co/Doubiiu/DynamiCrafter_512/blob/main/model.ckpt&#34;&gt;Hugging Face&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;DynamiCrafter256&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;256x256&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;11.9GB &amp;amp; 10s (&lt;code&gt;perframe_ae=False&lt;/code&gt;)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://huggingface.co/Doubiiu/DynamiCrafter/blob/main/model.ckpt&#34;&gt;Hugging Face&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Currently, our DynamiCrafter can support generating videos of up to 16 frames with a resolution of 576x1024.&lt;/p&gt; &#xA;&lt;p&gt;GPU memory consumed on RTX 4090 reported by @noguchis in &lt;a href=&#34;https://x.com/noguchis/status/1754488826016432341?s=20&#34;&gt;Twitter&lt;/a&gt;: 18.3GB (576x1024), 12.8GB (320x512), 11.9GB (256x256).&lt;/p&gt; &#xA;&lt;!-- It takes approximately 10 seconds and requires a peak GPU memory of 20 GB to animate an image using a single NVIDIA A100 (40G) GPU. --&gt; &#xA;&lt;h2&gt;⚙️ Setup&lt;/h2&gt; &#xA;&lt;h3&gt;Install Environment via Anaconda (Recommended)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n dynamicrafter python=3.8.5&#xA;conda activate dynamicrafter&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;💫 Inference&lt;/h2&gt; &#xA;&lt;h3&gt;1. Command line&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download pretrained models via Hugging Face, and put the &lt;code&gt;model.ckpt&lt;/code&gt; with the required resolution in &lt;code&gt;checkpoints/dynamicrafter_[1024|512|256]_v1/model.ckpt&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Run the commands based on your devices and needs in terminal.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  # Run on a single GPU:&#xA;  # Select the model based on required resolutions: i.e., 1024|512|320:&#xA;  sh scripts/run.sh 1024&#xA;  # Run on multiple GPUs for parallel inference:&#xA;  sh scripts/run_mp.sh 1024&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Local Gradio demo&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download the pretrained models and put them in the corresponding directory according to the previous guidelines.&lt;/li&gt; &#xA; &lt;li&gt;Input the following commands in terminal (choose a model based on the required resolution: 1024, 512 or 256).&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  python gradio_app.py --res 1024&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;👨‍👩‍👧‍👦 Crafter Family&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/AILab-CVC/VideoCrafter&#34;&gt;VideoCrafter1&lt;/a&gt;: Framework for high-quality video generation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/YingqingHe/ScaleCrafter&#34;&gt;ScaleCrafter&lt;/a&gt;: Tuning-free method for high-resolution image/video generation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/AILab-CVC/TaleCrafter&#34;&gt;TaleCrafter&lt;/a&gt;: An interactive story visualization tool that supports multiple characters.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/arthur-qiu/LongerCrafter&#34;&gt;LongerCrafter&lt;/a&gt;: Tuning-free method for longer high-quality video generation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://doubiiu.github.io/projects/Make-Your-Video/&#34;&gt;MakeYourVideo, might be a Crafter:)&lt;/a&gt;: Video generation/editing with textual and structural guidance.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gongyeliu.github.io/StyleCrafter.github.io/&#34;&gt;StyleCrafter&lt;/a&gt;: Stylized-image-guided text-to-image and text-to-video generation.&lt;/p&gt; &#xA;&lt;h2&gt;😉 Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bib&#34;&gt;@article{xing2023dynamicrafter,&#xA;  title={DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors},&#xA;  author={Xing, Jinbo and Xia, Menghan and Zhang, Yong and Chen, Haoxin and Yu, Wangbo and Liu, Hanyuan and Wang, Xintao and Wong, Tien-Tsin and Shan, Ying},&#xA;  journal={arXiv preprint arXiv:2310.12190},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;🙏 Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;We would like to thank &lt;a href=&#34;https://twitter.com/_akhaliq?lang=en&#34;&gt;AK(@_akhaliq)&lt;/a&gt; for the help of setting up hugging face online demo, and &lt;a href=&#34;https://twitter.com/camenduru&#34;&gt;camenduru&lt;/a&gt; for providing the replicate &amp;amp; colab online demo.&lt;/p&gt; &#xA;&lt;h2&gt;📢 Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;We develop this repository for RESEARCH purposes, so it can only be used for personal/research/non-commercial purposes.&lt;/p&gt; &#xA;&lt;hr&gt;</summary>
  </entry>
  <entry>
    <title>AnythingInAnyScene/anything_in_anyscene</title>
    <updated>2024-02-09T01:35:13Z</updated>
    <id>tag:github.com,2024-02-09:/AnythingInAnyScene/anything_in_anyscene</id>
    <link href="https://github.com/AnythingInAnyScene/anything_in_anyscene" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h3&gt;Full code is coming soon...&lt;/h3&gt;</summary>
  </entry>
  <entry>
    <title>tsujuifu/pytorch_mgie</title>
    <updated>2024-02-09T01:35:13Z</updated>
    <id>tag:github.com,2024-02-09:/tsujuifu/pytorch_mgie</id>
    <link href="https://github.com/tsujuifu/pytorch_mgie" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Gradio demo of MGIE&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;🔥 Apple&#39;s official repo is open-sourced at &lt;a href=&#34;https://github.com/apple/ml-mgie&#34;&gt;ml-mgie&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h1&gt;[ICLR&#39;24] Guiding Instruction-based Image Editing via Multimodal Large Language Models&lt;/h1&gt; &#xA;&lt;p&gt;A &lt;strong&gt;Gradio demo&lt;/strong&gt; of &lt;a href=&#34;https://tsujuifu.github.io/pubs/iclr24_mgie.pdf&#34;&gt;MGIE&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://tsujuifu.github.io/pubs/iclr24_mgie.pdf&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://mllm-ie.github.io&#34;&gt;Project&lt;/a&gt; | &lt;a href=&#34;http://128.111.41.13:7122&#34;&gt;Demo 1&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/tsujuifu/ml-mgie&#34;&gt;Demo 2&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/tsujuifu/pytorch_mgie/main/_imgs/gradio.gif&#34; width=&#34;25%&#34;&gt; &#xA;&lt;h2&gt;Gradio Demo&lt;/h2&gt; &#xA;&lt;p&gt;Follow &lt;a href=&#34;https://github.com/apple/ml-mgie?tab=readme-ov-file#requirements&#34;&gt;Requirements&lt;/a&gt; to build env and put &lt;a href=&#34;https://github.com/tsujuifu/pytorch_mgie/raw/main/app.py&#34;&gt;app.py&lt;/a&gt; in ml-mgie&lt;/p&gt; &#xA;&lt;p&gt;Put official &lt;a href=&#34;https://drive.google.com/uc?id=1f_zD8UWRNsPV5ztrCmhxEC4o3cD0_zn7&#34;&gt;LLaVA-7B&lt;/a&gt; in &lt;a href=&#34;https://raw.githubusercontent.com/tsujuifu/pytorch_mgie/main/_ckpt&#34;&gt;_ckpt/LLaVA-7B-v1&lt;/a&gt; and download pre-trained &lt;a href=&#34;https://docs-assets.developer.apple.com/ml-research/models/mgie/mgie_7b.tar.gz&#34;&gt;ckpt&lt;/a&gt; (on IPr2Pr + MagicBrush) in &lt;a href=&#34;https://raw.githubusercontent.com/tsujuifu/pytorch_mgie/main/_ckpt&#34;&gt;_ckpt/mgie_7b&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gradio app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/tsujuifu/pytorch_mgie/main/_imgs/gradio.png&#34; width=&#34;100%&#34;&gt;</summary>
  </entry>
</feed>