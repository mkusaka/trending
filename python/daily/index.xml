<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-11T01:43:17Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>minimaxir/simpleaichat</title>
    <updated>2023-07-11T01:43:17Z</updated>
    <id>tag:github.com,2023-07-11:/minimaxir/simpleaichat</id>
    <link href="https://github.com/minimaxir/simpleaichat" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Python package for easily interfacing with chat apps, with robust features and minimal code complexity.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;simpleaichat&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;from simpleaichat import AIChat&#xA;&#xA;ai = AIChat(system=&#34;Write a fancy GitHub README based on the user-provided project name.&#34;)&#xA;ai(&#34;simpleaichat&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;simpleaichat is a Python package for easily interfacing with chat apps like ChatGPT and GPT-4 with robust features and minimal code complexity. This tool has many features optimized for working with ChatGPT as fast and as cheap as possible, but still much more capable of modern AI tricks than most implementations:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create and run chats with only a few lines of code!&lt;/li&gt; &#xA; &lt;li&gt;Optimized workflows which minimize the amount of tokens used, reducing costs and latency.&lt;/li&gt; &#xA; &lt;li&gt;Run multiple independent chats at once.&lt;/li&gt; &#xA; &lt;li&gt;Minimal codebase: no code dives to figure out what&#39;s going on under the hood needed!&lt;/li&gt; &#xA; &lt;li&gt;Chat streaming responses and the ability to use tools.&lt;/li&gt; &#xA; &lt;li&gt;Async support, including for streaming and tools.&lt;/li&gt; &#xA; &lt;li&gt;Ablity to create more complex yet clear workflows if needed, such as Agents. (Demo soon!)&lt;/li&gt; &#xA; &lt;li&gt;Coming soon: more chat model support (PaLM, Claude)!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Here&#39;s some fun, hackable examples on how simpleaichat works:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Creating a &lt;a href=&#34;https://raw.githubusercontent.com/minimaxir/simpleaichat/main/examples/notebooks/simpleaichat_coding.ipynb&#34;&gt;Python coding assistant&lt;/a&gt; without any unnecessary accompanying output, allowing 5x faster generation at 1/3rd the cost. (&lt;a href=&#34;https://colab.research.google.com/github/minimaxir/simpleaichat/blob/main/examples/notebooks/simpleaichat_coding.ipynb&#34;&gt;Colab&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Allowing simpleaichat to &lt;a href=&#34;https://raw.githubusercontent.com/minimaxir/simpleaichat/main/examples/notebooks/chatgpt_inline_tips.ipynb&#34;&gt;provide inline tips&lt;/a&gt; following ChatGPT usage guidelines. (&lt;a href=&#34;https://colab.research.google.com/github/minimaxir/simpleaichat/blob/main/examples/notebooks/chatgpt_inline_tips.ipynb&#34;&gt;Colab&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Async interface for &lt;a href=&#34;https://raw.githubusercontent.com/minimaxir/simpleaichat/main/examples/notebooks/simpleaichat_async.ipynb&#34;&gt;conducting many chats&lt;/a&gt; in the time it takes to receive one AI message. (&lt;a href=&#34;https://colab.research.google.com/github/minimaxir/simpleaichat/blob/main/examples/notebooks/simpleaichat_async.ipynb&#34;&gt;Colab&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Create your own Tabletop RPG (TTRPG) setting and campaign by using &lt;a href=&#34;https://raw.githubusercontent.com/minimaxir/simpleaichat/main/examples/notebooks/schema_ttrpg.ipynb&#34;&gt;advanced structured data models&lt;/a&gt;. (&lt;a href=&#34;https://colab.research.google.com/github/minimaxir/simpleaichat/blob/main/examples/notebooks/schema_ttrpg.ipynb&#34;&gt;Colab&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;simpleaichat can be installed &lt;a href=&#34;https://pypi.org/project/simpleaichat/&#34;&gt;from PyPI&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip3 install simpleaichat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quick, Fun Demo&lt;/h2&gt; &#xA;&lt;p&gt;You can demo chat-apps very quickly with simpleaichat! First, you will need to get an OpenAI API key, and then with one line of code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;from simpleaichat import AIChat&#xA;&#xA;AIChat(api_key=&#34;sk-...&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And with that, you&#39;ll be thrust directly into an interactive chat!&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/minimaxir/simpleaichat/main/docs/helloworld.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This AI chat will mimic the behavior of OpenAI&#39;s webapp, but on your local computer!&lt;/p&gt; &#xA;&lt;p&gt;You can also pass the API key by storing it in an &lt;code&gt;.env&lt;/code&gt; file with a &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; field in the working directory (recommended), or by setting the environment variable of &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; directly to the API key.&lt;/p&gt; &#xA;&lt;p&gt;But what about creating your own custom conversations? That&#39;s where things get fun. Just input whatever person, place or thing, fictional or nonfictional, that you want to chat with!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;AIChat(&#34;GLaDOS&#34;)  # assuming API key loaded via methods above&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/minimaxir/simpleaichat/main/docs/glados.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;But that&#39;s not all! You can customize exactly how they behave too with additional commands!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;AIChat(&#34;GLaDOS&#34;, &#34;Speak in the style of a Seinfeld monologue&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/minimaxir/simpleaichat/main/docs/gladoseinfeld.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;AIChat(&#34;Ronald McDonald&#34;, &#34;Speak using only emoji&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/minimaxir/simpleaichat/main/docs/clownemoji.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Need some socialization immediately? Once simpleaichat is installed, you can also start these chats directly from the command line!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;simpleaichat&#xA;simpleaichat &#34;GlaDOS&#34;&#xA;simpleaichat &#34;GLaDOS&#34; &#34;Speak in the style of a Seinfeld monologue&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Building AI-based Apps&lt;/h2&gt; &#xA;&lt;p&gt;The trick with working with new chat-based apps that wasn&#39;t readily available with earlier iterations of GPT-3 is the addition of the system prompt: a different class of prompt that guides the AI behavior throughout the entire conversation. In fact, the chat demos above are actually using &lt;a href=&#34;https://github.com/minimaxir/simpleaichat/raw/main/PROMPTS.md#interactive-chat&#34;&gt;system prompt tricks&lt;/a&gt; behind the scenes! OpenAI has also released an official guide for &lt;a href=&#34;https://platform.openai.com/docs/guides/gpt-best-practices&#34;&gt;system prompt best practices&lt;/a&gt; to building AI apps.&lt;/p&gt; &#xA;&lt;p&gt;For developers, you can instantiate a programmatic instance of &lt;code&gt;AIChat&lt;/code&gt; by explicitly specifying a system prompt, or by disabling the console.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;ai = AIChat(system=&#34;You are a helpful assistant.&#34;)&#xA;ai = AIChat(console=False)  # same as above&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also pass in a &lt;code&gt;model&lt;/code&gt; parameter, such as &lt;code&gt;model=&#34;gpt-4&#34;&lt;/code&gt; if you have access to GPT-4, or &lt;code&gt;model=&#34;gpt-3.5-turbo-16k&#34;&lt;/code&gt; for a larger-context-window ChatGPT.&lt;/p&gt; &#xA;&lt;p&gt;You can then feed the new &lt;code&gt;ai&lt;/code&gt; class with user input, and it will return and save the response from ChatGPT:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;response = ai(&#34;What is the capital of California?&#34;)&#xA;print(response)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;The capital of California is Sacramento.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, you can stream responses by token with a generator if the text generation itself is too slow:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;for chunk in ai.stream(&#34;What is the capital of California?&#34;, params={&#34;max_tokens&#34;: 5}):&#xA;    response_td = chunk[&#34;response&#34;]  # dict contains &#34;delta&#34; for the new token and &#34;response&#34;&#xA;    print(response_td)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;The&#xA;The capital&#xA;The capital of&#xA;The capital of California&#xA;The capital of California is&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Further calls to the &lt;code&gt;ai&lt;/code&gt; object will continue the chat, automatically incorporating previous information from the conversation.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;response = ai(&#34;When was it founded?&#34;)&#xA;print(response)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Sacramento was founded on February 27, 1850.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also save chat sessions (as CSV or JSON) and load them later. The API key is not saved so you will have to provide that when loading.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;ai.save_session()  # CSV, will only save messages&#xA;ai.save_session(format=&#34;json&#34;, minify=True)  # JSON&#xA;&#xA;ai.load_session(&#34;my.csv&#34;)&#xA;ai.load_session(&#34;my.json&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Functions&lt;/h3&gt; &#xA;&lt;p&gt;A large number of popular venture-capital-funded ChatGPT apps don&#39;t actually use the &#34;chat&#34; part of the model. Instead, they just use the system prompt/first user prompt as a form of natural language programming. You can emulate this behavior by passing a new system prompt when generating text, and not saving the resulting messages.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;AIChat&lt;/code&gt; class is a manager of chat &lt;em&gt;sessions&lt;/em&gt;, which means you can have multiple independent chats or functions happening! The examples above use a default session, but you can create new ones by specifying a &lt;code&gt;id&lt;/code&gt; when calling &lt;code&gt;ai&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;json = &#39;{&#34;title&#34;: &#34;An array of integers.&#34;, &#34;array&#34;: [-1, 0, 1]}&#39;&#xA;functions = [&#xA;             &#34;Format the user-provided JSON as YAML.&#34;,&#xA;             &#34;Write a limerick based on the user-provided JSON.&#34;,&#xA;             &#34;Translate the user-provided JSON from English to French.&#34;&#xA;            ]&#xA;params = {&#34;temperature&#34;: 0.0, &#34;max_tokens&#34;: 100}  # a temperature of 0.0 is deterministic&#xA;&#xA;# We namespace the function by `id` so it doesn&#39;t affect other chats.&#xA;# Settings set during session creation will apply to all generations from the session,&#xA;# but you can change them per-generation, as is the case with the `system` prompt here.&#xA;ai = AIChat(id=&#34;function&#34;, params=params, save_messages=False)&#xA;for function in functions:&#xA;    output = ai(json, id=&#34;function&#34;, system=function)&#xA;    print(output)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;title: &#34;An array of integers.&#34;&#xA;array:&#xA;  - -1&#xA;  - 0&#xA;  - 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;An array of integers so neat,&#xA;With values that can&#39;t be beat,&#xA;From negative to positive one,&#xA;It&#39;s a range that&#39;s quite fun,&#xA;This JSON is really quite sweet!&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;{&#34;titre&#34;: &#34;Un tableau d&#39;entiers.&#34;, &#34;tableau&#34;: [-1, 0, 1]}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Newer versions of ChatGPT also support &#34;&lt;a href=&#34;https://platform.openai.com/docs/guides/gpt/function-calling&#34;&gt;function calling&lt;/a&gt;&#34;, but the real benefit of that feature is the ability for ChatGPT to support structured input and/or output, which now opens up a wide variety of applications! simpleaichat streamlines the workflow to allow you to just pass an &lt;code&gt;input_schema&lt;/code&gt; and/or an &lt;code&gt;output_schema&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can construct a schema using a &lt;a href=&#34;https://docs.pydantic.dev/latest/&#34;&gt;pydantic&lt;/a&gt; BaseModel.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;from pydantic import BaseModel, Field&#xA;&#xA;ai = AIChat(&#xA;    console=False,&#xA;    save_messages=False,  # with schema I/O, messages are never saved&#xA;    model=&#34;gpt-3.5-turbo-0613&#34;,&#xA;    params={&#34;temperature&#34;: 0.0},&#xA;)&#xA;&#xA;class get_event_metadata(BaseModel):&#xA;    &#34;&#34;&#34;Event information&#34;&#34;&#34;&#xA;&#xA;    description: str = Field(description=&#34;Description of event&#34;)&#xA;    city: str = Field(description=&#34;City where event occured&#34;)&#xA;    year: int = Field(description=&#34;Year when event occured&#34;)&#xA;    month: str = Field(description=&#34;Month when event occured&#34;)&#xA;&#xA;# returns a dict, with keys ordered as in the schema&#xA;ai(&#34;First iPhone announcement&#34;, output_schema=get_event_metadata)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;{&#39;description&#39;: &#39;The first iPhone was announced by Apple Inc.&#39;,&#xA; &#39;city&#39;: &#39;San Francisco&#39;,&#xA; &#39;year&#39;: 2007,&#xA; &#39;month&#39;: &#39;January&#39;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/minimaxir/simpleaichat/main/examples/notebooks/schema_ttrpg.ipynb&#34;&gt;TTRPG Generator Notebook&lt;/a&gt; for a more elaborate demonstration of schema capabilities.&lt;/p&gt; &#xA;&lt;h3&gt;Tools&lt;/h3&gt; &#xA;&lt;p&gt;One of the most recent aspects of interacting with ChatGPT is the ability for the model to use &#34;tools.&#34; As popularized by &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt;, tools allow the model to decide when to use custom functions, which can extend beyond just the chat AI itself, for example retrieving recent information from the internet not present in the chat AI&#39;s training data. This workflow is analogous to ChatGPT Plugins.&lt;/p&gt; &#xA;&lt;p&gt;Parsing the model output to invoke tools typically requires a number of shennanigans, but simpleaichat uses &lt;a href=&#34;https://github.com/minimaxir/simpleaichat/raw/main/PROMPTS.md#tools&#34;&gt;a neat trick&lt;/a&gt; to make it fast and reliable! Additionally, the specified tools return a &lt;code&gt;context&lt;/code&gt; for ChatGPT to draw from for its final response, and tools you specify can return a dictionary which you can also populate with arbitrary metadata for debugging and postprocessing. Each generation returns a dictionary with the &lt;code&gt;response&lt;/code&gt; and the &lt;code&gt;tool&lt;/code&gt; function used, which can be used to set up workflows akin to &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt;-style Agents, e.g. recursively feed input to the model until it determines it does not need to use any more tools.&lt;/p&gt; &#xA;&lt;p&gt;You will need to specify functions with docstrings which provide hints for the AI to select them:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;from simpleaichat.utils import wikipedia_search, wikipedia_search_lookup&#xA;&#xA;# This uses the Wikipedia Search API.&#xA;# Results from it are nondeterministic, your mileage will vary.&#xA;def search(query):&#xA;    &#34;&#34;&#34;Search the internet.&#34;&#34;&#34;&#xA;    wiki_matches = wikipedia_search(query, n=3)&#xA;    return {&#34;context&#34;: &#34;, &#34;.join(wiki_matches), &#34;titles&#34;: wiki_matches}&#xA;&#xA;def lookup(query):&#xA;    &#34;&#34;&#34;Lookup more information about a topic.&#34;&#34;&#34;&#xA;    page = wikipedia_search_lookup(query, sentences=3)&#xA;    return page&#xA;&#xA;params = {&#34;temperature&#34;: 0.0, &#34;max_tokens&#34;: 100}&#xA;ai = AIChat(params=params, console=False)&#xA;&#xA;ai(&#34;San Francisco tourist attractions&#34;, tools=[search, lookup])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;{&#39;context&#39;: &#34;Fisherman&#39;s Wharf, San Francisco, Tourist attractions in the United States, Lombard Street (San Francisco)&#34;,&#xA; &#39;titles&#39;: [&#34;Fisherman&#39;s Wharf, San Francisco&#34;,&#xA;  &#39;Tourist attractions in the United States&#39;,&#xA;  &#39;Lombard Street (San Francisco)&#39;],&#xA; &#39;tool&#39;: &#39;search&#39;,&#xA; &#39;response&#39;: &#34;There are many popular tourist attractions in San Francisco, including Fisherman&#39;s Wharf and Lombard Street. Fisherman&#39;s Wharf is a bustling waterfront area known for its seafood restaurants, souvenir shops, and sea lion sightings. Lombard Street, on the other hand, is a famous winding street with eight hairpin turns that attract visitors from all over the world. Both of these attractions are must-sees for anyone visiting San Francisco.&#34;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;ai(&#34;Lombard Street?&#34;, tools=[search, lookup])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;{&#39;context&#39;: &#39;Lombard Street is an eastâ€“west street in San Francisco, California that is famous for a steep, one-block section with eight hairpin turns. Stretching from The Presidio east to The Embarcadero (with a gap on Telegraph Hill), most of the street\&#39;s western segment is a major thoroughfare designated as part of U.S. Route 101. The famous one-block section, claimed to be &#34;the crookedest street in the world&#34;, is located along the eastern segment in the Russian Hill neighborhood.&#39;,&#xA; &#39;tool&#39;: &#39;lookup&#39;,&#xA; &#39;response&#39;: &#39;Lombard Street is a famous street in San Francisco, California known for its steep, one-block section with eight hairpin turns. It stretches from The Presidio to The Embarcadero, with a gap on Telegraph Hill. The western segment of the street is a major thoroughfare designated as part of U.S. Route 101, while the famous one-block section, claimed to be &#34;the crookedest street in the world&#34;, is located along the eastern segment in the Russian Hill&#39;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py3&#34;&gt;ai(&#34;Thanks for your help!&#34;, tools=[search, lookup])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;{&#39;response&#39;: &#34;You&#39;re welcome! If you have any more questions or need further assistance, feel free to ask.&#34;,&#xA; &#39;tool&#39;: None}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Miscellaneous Notes&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Like &lt;a href=&#34;https://github.com/minimaxir/gpt-2-simple&#34;&gt;gpt-2-simple&lt;/a&gt; before it, the primary motivation behind releasing simpleaichat is to both democratize access to ChatGPT even more and also offer more transparency for non-engineers into how Chat AI-based apps work under the hood given the disproportionate amount of media misinformation about their capabilities. This is inspired by real-world experience from &lt;a href=&#34;https://tech.buzzfeed.com/the-right-tools-for-the-job-c05de96e949e&#34;&gt;my work with BuzzFeed&lt;/a&gt; in the domain, where after spending a long time working with the popular &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt;, a more-simple implementation was both much easier to maintain and resulted in much better generations. I began focusing development on simpleaichat after reading a &lt;a href=&#34;https://news.ycombinator.com/item?id=35820931&#34;&gt;Hacker News thread&lt;/a&gt; filled with many similar complaints, indicating value for an easier-to-use interface for modern AI tricks. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;simpleaichat very intentionally avoids coupling features with common use cases where possible (e.g. Tools) in order to avoid software lock-in due to the difficulty implementing anything not explicitly mentioned in the project&#39;s documentation. The philosophy behind simpleaichat is to provide good demos, and let the user&#39;s creativity and business needs take priority instead of having to fit a round peg into a square hole like with LangChain.&lt;/li&gt; &#xA;   &lt;li&gt;simpleaichat makes it easier to interface with Chat AIs, but it does not attempt to solve common technical and ethical problems inherent to large language models trained on the internet, including prompt injection and unintended plagiarism. The user should exercise good judgment when implementing simpleaichat. Use cases of simpleaichat which go against OpenAI&#39;s &lt;a href=&#34;https://openai.com/policies/usage-policies&#34;&gt;usage policies&lt;/a&gt; (including jailbreaking) will not be endorsed.&lt;/li&gt; &#xA;   &lt;li&gt;simpleaichat intentionally does not use the &#34;Agent&#34; logical metaphor for tool workflows because it&#39;s become an AI hype buzzword heavily divorced from its origins. If needed be, you can emulate the Agent workflow with a &lt;code&gt;while&lt;/code&gt; loop without much additional code, plus with the additional benefit of much more flexibility such as debugging.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;The session manager implements some sensible security defaults, such as using UUIDs as session ids by default, storing authentication information in a way to minimize unintentional leakage, and type enforcement via Pydantic. Your end-user application should still be aware of potential security issues, however.&lt;/li&gt; &#xA; &lt;li&gt;Although OpenAI&#39;s documentation says that system prompts are less effective than a user prompt constructed in a similar manner, in my experience it still does perform better for maintaining rules/a persona.&lt;/li&gt; &#xA; &lt;li&gt;Many examples of popular prompts use more conversational prompts, while the example prompts here use more consise and imperative prompts. This aspect of prompt engineering is still evolving, but in my experience commands do better with ChatGPT and with greater token efficieny. That&#39;s also why simpleaichat allows users to specify system prompts (and explicitly highlights what the default use) instead of relying on historical best practices.&lt;/li&gt; &#xA; &lt;li&gt;Token counts for async is not supported as OpenAI doesn&#39;t return token counts when streaming responses. In general, there may be some desync in token counts and usage for various use cases; I&#39;m working on categorizing them.&lt;/li&gt; &#xA; &lt;li&gt;Outside of the explicit examples, none of this README uses AI-generated text. The introduction code example is just a joke, but it was too good of a real-world use case!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;PaLM Chat (Bard) and Anthropic Claude support&lt;/li&gt; &#xA; &lt;li&gt;More fun/feature-filled CLI chat app based on Textual&lt;/li&gt; &#xA; &lt;li&gt;Simple example of using simpleaichat in a webapp&lt;/li&gt; &#xA; &lt;li&gt;Simple of example of using simpleaichat in a stateless manner (e.g. AWS Lambda functions)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Maintainer/Creator&lt;/h2&gt; &#xA;&lt;p&gt;Max Woolf (&lt;a href=&#34;https://minimaxir.com&#34;&gt;@minimaxir&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Max&#39;s open-source projects are supported by his &lt;a href=&#34;https://www.patreon.com/minimaxir&#34;&gt;Patreon&lt;/a&gt; and &lt;a href=&#34;https://github.com/sponsors/minimaxir&#34;&gt;GitHub Sponsors&lt;/a&gt;. If you found this project helpful, any monetary contributions to the Patreon are appreciated and will be put to good creative use.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MIT&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>lablab-ai/Google-VertexAI-FastAPI</title>
    <updated>2023-07-11T01:43:17Z</updated>
    <id>tag:github.com,2023-07-11:/lablab-ai/Google-VertexAI-FastAPI</id>
    <link href="https://github.com/lablab-ai/Google-VertexAI-FastAPI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Simple boilerplate to get started with Generative AI models from Google Vertex AI based on FastAPI&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Getting started with Vertex AI Generative AI&lt;/h1&gt; &#xA;&lt;h2&gt;Before you begin&lt;/h2&gt; &#xA;&lt;p&gt;This is a simple starter boilerplate that gives you a basic FastAPI setup with a few endpoints. It is meant to be used as a starting point for your own projects.&lt;/p&gt; &#xA;&lt;h3&gt;Clone and install dependencies&lt;/h3&gt; &#xA;&lt;p&gt;In your terminal, run the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:lablab-ai/Google-VertexAI-FastAPI.git&#xA;cd Google-VertexAI-FastAPI&#xA;cd app&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Update the project auth&lt;/h3&gt; &#xA;&lt;p&gt;In order to use the Vertex AI SDK, you will need to update the project auth using a serviceaccount&lt;/p&gt; &#xA;&lt;p&gt;In &lt;code&gt;app&lt;/code&gt;, folder create the file &lt;code&gt;service_account.json&lt;/code&gt; and paste the content of your service account json file. Create the file if you don&#39;t have it by runnung the following command in your terminal:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;touch service_account.json&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;In the file &lt;code&gt;service_account.json&lt;/code&gt; paste the content of your service account json file. It should look like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;{&#xA;    &#34;type&#34;: &#34;service_account&#34;,&#xA;    &#34;project_id&#34;: &#34;YOUR_PROJECT_ID&#34;,&#xA;    &#34;private_key_id&#34;: &#34;YOUR_PRIVATE_KEY_ID&#34;,&#xA;    &#34;private_key&#34;: &#34;YOUR_PRIVATE_KEY&#34;,&#xA;    &#34;client_email&#34;: &#34;YOUR_CLIENT_EMAIL&#34;,&#xA;    &#34;client_id&#34;: &#34;YOUR_CLIENT_ID&#34;,&#xA;    &#34;auth_uri&#34;: &#34;YOUR_AUTH_URI&#34;,&#xA;    &#34;token_uri&#34;: &#34;YOUR_TOKEN_URI&#34;,&#xA;    &#34;auth_provider_x509_cert_url&#34;: &#34;YOUR_AUTH_PROVIDER_X509_CERT_URL&#34;,&#xA;    &#34;client_x509_cert_url&#34;: &#34;YOUR_CLIENT_X509_CERT_URL&#34;,&#xA;    &#34;universe_domain&#34;: &#34;YOUR_UNIVERSE_DOMAIN&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can find your service account json file in the Vertex AI console under &lt;code&gt;Settings &amp;gt; Service account&lt;/code&gt; or you got it provided by lablab.ai (If you are part of the Google Vertex AI hackathon )&lt;/p&gt; &#xA;&lt;h3&gt;Start the server and test&lt;/h3&gt; &#xA;&lt;p&gt;Once you have installed the dependencies, you can start the server by running: &lt;code&gt;uvicorn main:app --reload --port 8080&lt;/code&gt; in the &lt;code&gt;app&lt;/code&gt; directory. When the server is running, you can test it by going to &lt;code&gt;http://localhost:8080/docs&lt;/code&gt; in your browser. You should see the Swagger UI where you can test the endpoints.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/lablab-ai/Google-VertexAI-FastAPI/assets/2171273/13df1172-0b77-43f3-85a0-0bf936bbd8db&#34; alt=&#34;image&#34;&gt; &lt;img src=&#34;https://github.com/lablab-ai/Google-VertexAI-FastAPI/assets/2171273/e69f7892-6945-4d85-987e-dbbc23e553bd&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Good luck! and don&#39;t forget to star this repo if you like it!&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Thank you&lt;/strong&gt; for reading! If you enjoyed this tutorial you can find more and continue reading &lt;a href=&#34;https://lablab.ai/t/&#34;&gt;on our tutorial page&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://lablab.ai&#34;&gt;&lt;img src=&#34;https://storage.googleapis.com/lablab-static-eu/images/github/lablab-banner.jpg&#34; alt=&#34;Artificial Intelligence Hackathons, tutorials and Boilerplates&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Join the LabLab Discord&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://discordapp.com/api/guilds/877056448956346408/widget.png?style=banner1&#34; alt=&#34;Discord Banner 1&#34;&gt;&lt;br&gt; On lablab discord, we discuss this repo and many other topics related to artificial intelligence! Checkout upcoming &lt;a href=&#34;https://lablab.ai&#34;&gt;Artificial Intelligence Hackathons&lt;/a&gt; Event&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://newnative.ai&#34;&gt;&lt;img src=&#34;https://storage.googleapis.com/lablab-static-eu/images/github/nn-group-loggos.jpg&#34; alt=&#34;Acclerating innovation through acceleration&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>khoj-ai/khoj</title>
    <updated>2023-07-11T01:43:17Z</updated>
    <id>tag:github.com,2023-07-11:/khoj-ai/khoj</id>
    <link href="https://github.com/khoj-ai/khoj" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An AI personal assistant for your digital brain&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/src/khoj/interface/web/assets/icons/khoj-logo-sideways.svg?sanitize=true&#34; width=&#34;330&#34; alt=&#34;Khoj Logo&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/khoj-ai/khoj/actions/workflows/test.yml&#34;&gt;&lt;img src=&#34;https://github.com/khoj-ai/khoj/actions/workflows/test.yml/badge.svg?sanitize=true&#34; alt=&#34;test&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/khoj-ai/khoj/pkgs/container/khoj&#34;&gt;&lt;img src=&#34;https://github.com/khoj-ai/khoj/actions/workflows/dockerize.yml/badge.svg?sanitize=true&#34; alt=&#34;dockerize&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/khoj-assistant/&#34;&gt;&lt;img src=&#34;https://github.com/khoj-ai/khoj/actions/workflows/pypi.yml/badge.svg?sanitize=true&#34; alt=&#34;pypi&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;An AI personal assistant for your digital brain&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Supported Plugins&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/khoj-ai/khoj/tree/master/src/interface/obsidian#readme&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Obsidian-%23483699.svg?style=for-the-badge&amp;amp;logo=obsidian&amp;amp;logoColor=white&#34; alt=&#34;Khoj on Obsidian&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/khoj-ai/khoj/tree/master/src/interface/emacs#readme&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Emacs-%237F5AB6.svg?&amp;amp;style=for-the-badge&amp;amp;logo=gnu-emacs&amp;amp;logoColor=white&#34; alt=&#34;Khoj on Emacs&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Demos&#34;&gt;Demos&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#khoj-in-obsidian&#34;&gt;Khoj in Obsidian&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#khoj-in-emacs-browser&#34;&gt;Khoj in Emacs, Browser&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Interfaces&#34;&gt;Interfaces&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Architecture&#34;&gt;Architecture&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Setup&#34;&gt;Setup&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#1-Install&#34;&gt;Install&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#2-Run&#34;&gt;Run&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#3-Configure&#34;&gt;Configure&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#4-install-interface-plugins&#34;&gt;Install Plugins&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Use&#34;&gt;Use&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Khoj-search&#34;&gt;Khoj Search&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Khoj-chat&#34;&gt;Khoj Chat&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Upgrade&#34;&gt;Upgrade&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#upgrade-khoj-server&#34;&gt;Khoj Server&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#upgrade-khoj-on-emacs&#34;&gt;Khoj.el&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#upgrade-khoj-on-obsidian&#34;&gt;Khoj Obsidian&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#uninstall&#34;&gt;Uninstall&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Troubleshoot&#34;&gt;Troubleshoot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#advanced-usage&#34;&gt;Advanced Usage&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#access-khoj-on-mobile&#34;&gt;Access Khoj on Mobile&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#use-openai-models-for-search&#34;&gt;Use OpenAI Models for Search&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#search-across-different-languages&#34;&gt;Search across Different Languages&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#bootstrap-khoj-search-for-offline-usage-later&#34;&gt;Boostrap Khoj Search for Offline Usage Later&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Miscellaneous&#34;&gt;Miscellaneous&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#set-your-openai-api-key-in-khoj&#34;&gt;Setup OpenAI API key in Khoj&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#gpt-api&#34;&gt;GPT API&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Performance&#34;&gt;Performance&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Query-performance&#34;&gt;Query Performance&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Indexing-performance&#34;&gt;Indexing Performance&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Miscellaneous-1&#34;&gt;Miscellaneous&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Development&#34;&gt;Development&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#visualize-codebase&#34;&gt;Visualize Codebase&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Setup&#34;&gt;Setup&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Using-Pip&#34;&gt;Using Pip&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Using-Docker&#34;&gt;Using Docker&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Using-Conda&#34;&gt;Using Conda&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Validate&#34;&gt;Validate&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Credits&#34;&gt;Credits&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Search&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Local&lt;/strong&gt;: Your personal data stays local. All search and indexing is done on your machine. &lt;em&gt;Unlike chat which requires access to GPT.&lt;/em&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Incremental&lt;/strong&gt;: Incremental search for a fast, search-as-you-type experience&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Chat&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Faster answers&lt;/strong&gt;: Find answers faster, smoother than search. No need to manually scan through your notes to find answers.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Iterative discovery&lt;/strong&gt;: Iteratively explore and (re-)discover your notes&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Assisted creativity&lt;/strong&gt;: Smoothly weave across answers retrieval and content generation&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;General&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Natural&lt;/strong&gt;: Advanced natural language understanding using Transformer based ML Models&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Pluggable&lt;/strong&gt;: Modular architecture makes it easy to plug in new data sources, frontends and ML models&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Multiple Sources&lt;/strong&gt;: Index your Org-mode and Markdown notes, PDF files, Github repositories, and Photos&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Multiple Interfaces&lt;/strong&gt;: Interact from your &lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/src/khoj/interface/web/index.html&#34;&gt;Web Browser&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/src/interface/emacs/khoj.el&#34;&gt;Emacs&lt;/a&gt; or &lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/src/interface/obsidian/&#34;&gt;Obsidian&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Demos&lt;/h2&gt; &#xA;&lt;h3&gt;Khoj in Obsidian&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/khoj-ai/khoj/assets/6413477/3e33d8ea-25bb-46c8-a3bf-c92f78d0f56b&#34;&gt;https://github.com/khoj-ai/khoj/assets/6413477/3e33d8ea-25bb-46c8-a3bf-c92f78d0f56b&lt;/a&gt;&lt;/p&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Description&lt;/summary&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Install Khoj via &lt;code&gt;pip&lt;/code&gt; and start Khoj backend in a terminal (Run &lt;code&gt;khoj&lt;/code&gt;) &lt;pre&gt;&lt;code&gt;python -m pip install khoj-assistant&#xA;khoj&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;li&gt;Install Khoj plugin via Community Plugins settings pane on Obsidian app &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Check the new Khoj plugin settings&lt;/li&gt; &#xA;    &lt;li&gt;Let Khoj backend index the markdown, pdf, Github markdown files in the current Vault&lt;/li&gt; &#xA;    &lt;li&gt;Open Khoj plugin on Obsidian via Search button on Left Pane&lt;/li&gt; &#xA;    &lt;li&gt;Search &#34;&lt;em&gt;Announce plugin to folks&lt;/em&gt;&#34; in the &lt;a href=&#34;https://marcus.se.net/obsidian-plugin-docs/&#34;&gt;Obsidian Plugin docs&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;Jump to the &lt;a href=&#34;https://marcus.se.net/obsidian-plugin-docs/publishing/submit-your-plugin&#34;&gt;search result&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;/ol&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Khoj in Emacs, Browser&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/6413477/184735169-92c78bf1-d827-4663-9087-a1ea194b8f4b.mp4&#34;&gt;https://user-images.githubusercontent.com/6413477/184735169-92c78bf1-d827-4663-9087-a1ea194b8f4b.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Description&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Install Khoj via pip&lt;/li&gt; &#xA;  &lt;li&gt;Start Khoj app&lt;/li&gt; &#xA;  &lt;li&gt;Add this readme and &lt;a href=&#34;https://github.com/khoj-ai/khoj/tree/master/src/interface/emacs&#34;&gt;khoj.el readme&lt;/a&gt; as org-mode for Khoj to index&lt;/li&gt; &#xA;  &lt;li&gt;Search &#34;&lt;em&gt;Setup editor&lt;/em&gt;&#34; on the Web and Emacs. Re-rank the results for better accuracy&lt;/li&gt; &#xA;  &lt;li&gt;Top result is what we are looking for, the &lt;a href=&#34;https://github.com/khoj-ai/khoj/tree/master/src/interface/emacs#2-Install-Khojel&#34;&gt;section to Install Khoj.el on Emacs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Analysis&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;The results do not have any words used in the query &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;em&gt;Based on the top result it seems the re-ranking model understands that Emacs is an editor?&lt;/em&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;The results incrementally update as the query is entered&lt;/li&gt; &#xA;  &lt;li&gt;The results are re-ranked, for better accuracy, once user hits enter&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Interfaces&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/khoj-ai/khoj/raw/master/docs/interfaces.png?&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Architecture&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/khoj-ai/khoj/raw/master/docs/khoj_architecture.png?&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;These are the general setup instructions for Khoj.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Make sure &lt;a href=&#34;https://realpython.com/installing-python/&#34;&gt;python&lt;/a&gt; and &lt;a href=&#34;https://pip.pypa.io/en/stable/installation/&#34;&gt;pip&lt;/a&gt; are installed on your machine&lt;/li&gt; &#xA; &lt;li&gt;Check the &lt;a href=&#34;https://github.com/khoj-ai/khoj/tree/master/src/interface/emacs#Setup&#34;&gt;Khoj.el Readme&lt;/a&gt; to setup Khoj with Emacs&lt;br&gt; Its simpler as it can skip the server &lt;em&gt;install&lt;/em&gt;, &lt;em&gt;run&lt;/em&gt; and &lt;em&gt;configure&lt;/em&gt; step below.&lt;/li&gt; &#xA; &lt;li&gt;Check the &lt;a href=&#34;https://github.com/khoj-ai/khoj/tree/master/src/interface/obsidian#Setup&#34;&gt;Khoj Obsidian Readme&lt;/a&gt; to setup Khoj with Obsidian&lt;br&gt; Its simpler as it can skip the &lt;em&gt;configure&lt;/em&gt; step below.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;1. Install&lt;/h3&gt; &#xA;&lt;p&gt;Run the following command in your terminal to install the Khoj backend.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;On Linux/MacOS&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m pip install khoj-assistant&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;On Windows&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;py -m pip install khoj-assistant&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2. Run&lt;/h3&gt; &#xA;&lt;p&gt;Run the following commmand from your terminal to start the Khoj backend and open Khoj in your browser.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;khoj --gui&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: To start Khoj automatically in the background use &lt;a href=&#34;https://www.windowscentral.com/how-create-automated-task-using-task-scheduler-windows-10&#34;&gt;Task scheduler&lt;/a&gt; on Windows or &lt;a href=&#34;https://en.wikipedia.org/wiki/Cron&#34;&gt;Cron&lt;/a&gt; on Mac, Linux (e.g with &lt;code&gt;@reboot khoj&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;h3&gt;3. Configure&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Set &lt;code&gt;File&lt;/code&gt;, &lt;code&gt;Folder&lt;/code&gt; and hit &lt;code&gt;Save&lt;/code&gt; in each Plugins you want to enable for Search on the Khoj config page&lt;/li&gt; &#xA; &lt;li&gt;Add your OpenAI API key to Chat Feature settings if you want to use Chat&lt;/li&gt; &#xA; &lt;li&gt;Click &lt;code&gt;Configure&lt;/code&gt; and wait. The app will download ML models and index the content for search and (optionally) chat&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;4. Install Interface Plugins&lt;/h3&gt; &#xA;&lt;p&gt;Khoj exposes a web interface to search, chat and configure by default.&lt;br&gt; The optional steps below allow using Khoj from within an existing application like Obsidian or Emacs.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Khoj Obsidian&lt;/strong&gt;:&lt;br&gt; &lt;a href=&#34;https://github.com/khoj-ai/khoj/tree/master/src/interface/obsidian#2-Setup-Plugin&#34;&gt;Install&lt;/a&gt; the Khoj Obsidian plugin&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Khoj Emacs&lt;/strong&gt;:&lt;br&gt; &lt;a href=&#34;https://github.com/khoj-ai/khoj/tree/master/src/interface/emacs#2-Install-Khojel&#34;&gt;Install&lt;/a&gt; khoj.el&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Use&lt;/h2&gt; &#xA;&lt;h3&gt;Khoj Search&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Khoj via Obsidian&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Click the &lt;em&gt;Khoj search&lt;/em&gt; icon ðŸ”Ž on the &lt;a href=&#34;https://help.obsidian.md/User+interface/Workspace/Ribbon&#34;&gt;Ribbon&lt;/a&gt; or Search for &lt;em&gt;Khoj: Search&lt;/em&gt; in the &lt;a href=&#34;https://help.obsidian.md/Plugins/Command+palette&#34;&gt;Command Palette&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Khoj via Emacs&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Run &lt;code&gt;M-x khoj &amp;lt;user-query&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Khoj via Web&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Open &lt;a href=&#34;http://localhost:8000/&#34;&gt;http://localhost:8000/&lt;/a&gt; directly&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Khoj via API&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;See the Khoj FastAPI &lt;a href=&#34;http://localhost:8000/docs&#34;&gt;Swagger Docs&lt;/a&gt;, &lt;a href=&#34;http://localhost:8000/redocs&#34;&gt;ReDocs&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Query Filters&lt;/summary&gt; &#xA; &lt;p&gt;Use structured query syntax to filter the natural language search results&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Word Filter&lt;/strong&gt;: Get entries that include/exclude a specified term &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Entries that contain term_to_include: &lt;code&gt;+&#34;term_to_include&#34;&lt;/code&gt;&lt;/li&gt; &#xA;    &lt;li&gt;Entries that contain term_to_exclude: &lt;code&gt;-&#34;term_to_exclude&#34;&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Date Filter&lt;/strong&gt;: Get entries containing dates in YYYY-MM-DD format from specified date (range) &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Entries from April 1st 1984: &lt;code&gt;dt:&#34;1984-04-01&#34;&lt;/code&gt;&lt;/li&gt; &#xA;    &lt;li&gt;Entries after March 31st 1984: &lt;code&gt;dt&amp;gt;=&#34;1984-04-01&#34;&lt;/code&gt;&lt;/li&gt; &#xA;    &lt;li&gt;Entries before April 2nd 1984 : &lt;code&gt;dt&amp;lt;=&#34;1984-04-01&#34;&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;File Filter&lt;/strong&gt;: Get entries from a specified file &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Entries from incoming.org file: &lt;code&gt;file:&#34;incoming.org&#34;&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;Combined Example &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;code&gt;what is the meaning of life? file:&#34;1984.org&#34; dt&amp;gt;=&#34;1984-01-01&#34; dt&amp;lt;=&#34;1985-01-01&#34; -&#34;big&#34; -&#34;brother&#34;&lt;/code&gt;&lt;/li&gt; &#xA;    &lt;li&gt;Adds all filters to the natural language query. It should return entries &#xA;     &lt;ul&gt; &#xA;      &lt;li&gt;from the file &lt;em&gt;1984.org&lt;/em&gt;&lt;/li&gt; &#xA;      &lt;li&gt;containing dates from the year &lt;em&gt;1984&lt;/em&gt;&lt;/li&gt; &#xA;      &lt;li&gt;excluding words &lt;em&gt;&#34;big&#34;&lt;/em&gt; and &lt;em&gt;&#34;brother&#34;&lt;/em&gt;&lt;/li&gt; &#xA;      &lt;li&gt;that best match the natural language query &lt;em&gt;&#34;what is the meaning of life?&#34;&lt;/em&gt;&lt;/li&gt; &#xA;     &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Khoj Chat&lt;/h3&gt; &#xA;&lt;h4&gt;Overview&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Creates a personal assistant for you to inquire and engage with your notes&lt;/li&gt; &#xA; &lt;li&gt;Uses &lt;a href=&#34;https://openai.com/blog/chatgpt&#34;&gt;ChatGPT&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#khoj-search&#34;&gt;Khoj search&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Supports multi-turn conversations with the relevant notes for context&lt;/li&gt; &#xA; &lt;li&gt;Shows reference notes used to generate a response&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;em&gt;Your query and top notes from khoj search will be sent to OpenAI for processing&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Setup&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#set-your-openai-api-key-in-khoj&#34;&gt;Setup your OpenAI API key in Khoj&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Use&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open &lt;a href=&#34;http://localhost:8000/chat&#34;&gt;/chat&lt;/a&gt;[^2]&lt;/li&gt; &#xA; &lt;li&gt;Type your queries and see response by Khoj from your notes&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;Demo&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/khoj-ai/khoj/raw/master/docs/khoj_chat_web_interface.png?&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Details&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Your query is used to retrieve the most relevant notes, if any, using Khoj search&lt;/li&gt; &#xA; &lt;li&gt;These notes, the last few messages and associated metadata is passed to ChatGPT along with your query for a response&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Upgrade&lt;/h2&gt; &#xA;&lt;h3&gt;Upgrade Khoj Server&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install --upgrade khoj-assistant&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;Note: To upgrade to the latest pre-release version of the khoj server run below command&lt;/em&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Maps to the latest commit on the master branch&#xA;pip install --upgrade --pre khoj-assistant&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Upgrade Khoj on Emacs&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use your Emacs Package Manager to Upgrade&lt;/li&gt; &#xA; &lt;li&gt;See &lt;a href=&#34;https://github.com/khoj-ai/khoj/tree/master/src/interface/emacs#Upgrade&#34;&gt;khoj.el readme&lt;/a&gt; for details&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Upgrade Khoj on Obsidian&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Upgrade via the Community plugins tab on the settings pane in the Obsidian app&lt;/li&gt; &#xA; &lt;li&gt;See the &lt;a href=&#34;https://github.com/khoj-ai/khoj/tree/master/src/interface/obsidian#2-Setup-Plugin&#34;&gt;khoj plugin readme&lt;/a&gt; for details&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Uninstall&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;(Optional) Hit &lt;code&gt;Ctrl-C&lt;/code&gt; in the terminal running the khoj server to stop it&lt;/li&gt; &#xA; &lt;li&gt;Delete the khoj directory in your home folder (i.e &lt;code&gt;~/.khoj&lt;/code&gt; on Linux, Mac or &lt;code&gt;C:\Users\&amp;lt;your-username&amp;gt;\.khoj&lt;/code&gt; on Windows)&lt;/li&gt; &#xA; &lt;li&gt;Uninstall the khoj server with &lt;code&gt;pip uninstall khoj-assistant&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;(Optional) Uninstall khoj.el or the khoj obsidian plugin in the standard way on Emacs, Obsidian&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Troubleshoot&lt;/h2&gt; &#xA;&lt;h4&gt;Install fails while building Tokenizer dependency&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Details&lt;/strong&gt;: &lt;code&gt;pip install khoj-assistant&lt;/code&gt; fails while building the &lt;code&gt;tokenizers&lt;/code&gt; dependency. Complains about Rust.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fix&lt;/strong&gt;: Install Rust to build the tokenizers package. For example on Mac run: &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;brew install rustup&#xA;rustup-init&#xA;source ~/.cargo/env&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Refer&lt;/strong&gt;: &lt;a href=&#34;https://github.com/khoj-ai/khoj/issues/82#issuecomment-1241890946&#34;&gt;Issue with Fix&lt;/a&gt; for more details&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Search starts giving wonky results&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fix&lt;/strong&gt;: Open &lt;a href=&#34;http://localhost:8000/api/update?force=true&#34;&gt;/api/update?force=true&lt;/a&gt;[^2] in browser to regenerate index from scratch&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;em&gt;This is a fix for when you percieve the search results have degraded. Not if you think they&#39;ve always given wonky results&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Khoj in Docker errors out with &#34;Killed&#34; in error message&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fix&lt;/strong&gt;: Increase RAM available to Docker Containers in Docker Settings&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Refer&lt;/strong&gt;: &lt;a href=&#34;https://stackoverflow.com/a/50770267&#34;&gt;StackOverflow Solution&lt;/a&gt;, &lt;a href=&#34;https://docs.docker.com/desktop/mac/#resources&#34;&gt;Configure Resources on Docker for Mac&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Khoj errors out complaining about Tensors mismatch or null&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Mitigation&lt;/strong&gt;: Disable &lt;code&gt;image&lt;/code&gt; search using the desktop GUI&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Advanced Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Access Khoj on Mobile&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#Setup&#34;&gt;Setup Khoj&lt;/a&gt; on your personal server. This can be any always-on machine, i.e an old computer, RaspberryPi(?) etc&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tailscale.com/kb/installation/&#34;&gt;Install&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/tailscale.com/&#34;&gt;Tailscale&lt;/a&gt; on your personal server and phone&lt;/li&gt; &#xA; &lt;li&gt;Open the Khoj web interface of the server from your phone browser.&lt;br&gt; It should be &lt;code&gt;http://tailscale-ip-of-server:8000&lt;/code&gt; or &lt;code&gt;http://name-of-server:8000&lt;/code&gt; if you&#39;ve setup &lt;a href=&#34;https://tailscale.com/kb/1081/magicdns/&#34;&gt;MagicDNS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Click the &lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps/Add_to_home_screen&#34;&gt;Add to Homescreen&lt;/a&gt; button&lt;/li&gt; &#xA; &lt;li&gt;Enjoy exploring your notes, documents and images from your phone!&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/khoj-ai/khoj/raw/master/docs/khoj_pwa_android.png?&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Use OpenAI Models for Search&lt;/h3&gt; &#xA;&lt;h4&gt;Setup&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Set &lt;code&gt;encoder-type&lt;/code&gt;, &lt;code&gt;encoder&lt;/code&gt; and &lt;code&gt;model-directory&lt;/code&gt; under &lt;code&gt;asymmetric&lt;/code&gt; and/or &lt;code&gt;symmetric&lt;/code&gt; &lt;code&gt;search-type&lt;/code&gt; in your &lt;code&gt;khoj.yml&lt;/code&gt;[^1]: &lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;   asymmetric:&#xA;-    encoder: &#34;sentence-transformers/multi-qa-MiniLM-L6-cos-v1&#34;&#xA;+    encoder: text-embedding-ada-002&#xA;+    encoder-type: khoj.utils.models.OpenAI&#xA;     cross-encoder: &#34;cross-encoder/ms-marco-MiniLM-L-6-v2&#34;&#xA;-    encoder-type: sentence_transformers.SentenceTransformer&#xA;-    model_directory: &#34;~/.khoj/search/asymmetric/&#34;&#xA;+    model-directory: null&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#set-your-openai-api-key-in-khoj&#34;&gt;Setup your OpenAI API key in Khoj&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Restart Khoj server to generate embeddings. It will take longer than with offline models.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;Warnings&lt;/h4&gt; &#xA;&lt;p&gt;This configuration &lt;em&gt;uses an online model&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;It will &lt;strong&gt;send all notes to OpenAI&lt;/strong&gt; to generate embeddings&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;All queries will be sent to OpenAI&lt;/strong&gt; when you search with Khoj&lt;/li&gt; &#xA; &lt;li&gt;You will be &lt;strong&gt;charged by OpenAI&lt;/strong&gt; based on the total tokens processed&lt;/li&gt; &#xA; &lt;li&gt;It &lt;em&gt;requires an active internet connection&lt;/em&gt; to search and index&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Search across Different Languages&lt;/h3&gt; &#xA;&lt;p&gt;To search for notes in multiple, different languages, you can use a &lt;a href=&#34;https://www.sbert.net/docs/pretrained_models.html#multi-lingual-models&#34;&gt;multi-lingual model&lt;/a&gt;.&lt;br&gt; For example, the &lt;a href=&#34;https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&#34;&gt;paraphrase-multilingual-MiniLM-L12-v2&lt;/a&gt; supports &lt;a href=&#34;https://www.sbert.net/docs/pretrained_models.html#:~:text=we%20used%20the%20following%2050%2B%20languages&#34;&gt;50+ languages&lt;/a&gt;, has good search quality and speed. To use it:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Manually update &lt;code&gt;search-type &amp;gt; asymmetric &amp;gt; encoder&lt;/code&gt; to &lt;code&gt;paraphrase-multilingual-MiniLM-L12-v2&lt;/code&gt; in your &lt;code&gt;~/.khoj/khoj.yml&lt;/code&gt; file for now. See diff of &lt;code&gt;khoj.yml&lt;/code&gt; below for illustration:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt; asymmetric:&#xA;- encoder: &#34;sentence-transformers/multi-qa-MiniLM-L6-cos-v1&#34;&#xA;+ encoder: &#34;paraphrase-multilingual-MiniLM-L12-v2&#34;&#xA;   cross-encoder: &#34;cross-encoder/ms-marco-MiniLM-L-6-v2&#34;&#xA;   model_directory: &#34;~/.khoj/search/asymmetric/&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Regenerate your content index. For example, by opening &lt;a href=&#34;http://localhost:8000/api/update?t=force&#34;&gt;&amp;lt;khoj-url&amp;gt;/api/update?t=force&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Bootstrap Khoj Search for Offline Usage later&lt;/h3&gt; &#xA;&lt;p&gt;You can bootstrap Khoj pre-emptively to run on machines that do not have internet access. An example use-case would be to run Khoj on an air-gapped machine. Note: &lt;em&gt;Only search can currently run in fully offline mode, not chat.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;With Internet &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Manually download the &lt;a href=&#34;https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1&#34;&gt;asymmetric text&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2&#34;&gt;symmetric text&lt;/a&gt;and &lt;a href=&#34;https://huggingface.co/sentence-transformers/clip-ViT-B-32&#34;&gt;image search&lt;/a&gt; models from HuggingFace&lt;/li&gt; &#xA;   &lt;li&gt;Pip install khoj (and dependencies) in an associated virtualenv. E.g &lt;code&gt;python -m venv .venv &amp;amp;&amp;amp; source .venv/bin/activate &amp;amp;&amp;amp; pip install khoj-assistant&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;Without Internet &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Copy each of the search models into their respective folders, &lt;code&gt;asymmetric&lt;/code&gt;, &lt;code&gt;symmetric&lt;/code&gt; and &lt;code&gt;image&lt;/code&gt; under the &lt;code&gt;~/.khoj/search/&lt;/code&gt; directory on the air-gapped machine&lt;/li&gt; &#xA;   &lt;li&gt;Copy the khoj virtual environment directory onto the air-gapped machine, activate the environment and start and khoj as normal. E.g &lt;code&gt;source .venv/bin/activate &amp;amp;&amp;amp; khoj&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Miscellaneous&lt;/h2&gt; &#xA;&lt;h3&gt;Set your OpenAI API key in Khoj&lt;/h3&gt; &#xA;&lt;p&gt;If you want, Khoj can be configured to use OpenAI for search and chat.&lt;br&gt; Add your OpenAI API to Khoj by using either of the two options below:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Open your &lt;a href=&#34;http://localhost:8000/config/processor/conversation&#34;&gt;Khoj settings&lt;/a&gt;, add your OpenAI API key, and click &lt;em&gt;Save&lt;/em&gt;. Then go to your &lt;a href=&#34;http://localhost:8000/config&#34;&gt;Khoj settings&lt;/a&gt; and click &lt;code&gt;Configure&lt;/code&gt;. This will refresh Khoj with your OpenAI API key.&lt;/li&gt; &#xA; &lt;li&gt;Set &lt;code&gt;openai-api-key&lt;/code&gt; field under &lt;code&gt;processor.conversation&lt;/code&gt; section in your &lt;code&gt;khoj.yml&lt;/code&gt;[^1] to your &lt;a href=&#34;https://beta.openai.com/account/api-keys&#34;&gt;OpenAI API key&lt;/a&gt; and restart khoj: &lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;processor:&#xA;  conversation:&#xA;-    openai-api-key: # &#34;YOUR_OPENAI_API_KEY&#34;&#xA;+    openai-api-key: sk-aaaaaaaaaaaaaaaaaaaaaaaahhhhhhhhhhhhhhhhhhhhhhhh&#xA;    model: &#34;text-davinci-003&#34;&#xA;    conversation-logfile: &#34;~/.khoj/processor/conversation/conversation_logs.json&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: &lt;em&gt;This will enable Khoj to send your query and note(s) to OpenAI for processing&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;GPT API&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;http://localhost:8000/api/chat&#34;&gt;chat&lt;/a&gt;, &lt;a href=&#34;http://localhost:8000/api/beta/answer&#34;&gt;answer&lt;/a&gt; and &lt;a href=&#34;http://localhost:8000/api/beta/search&#34;&gt;search&lt;/a&gt; API endpoints use &lt;a href=&#34;https://openai.com/api/&#34;&gt;OpenAI API&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;They are disabled by default&lt;/li&gt; &#xA; &lt;li&gt;To use them: &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/#set-your-openai-api-key-in-khoj&#34;&gt;Setup your OpenAI API key in Khoj&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Interact with them from the &lt;a href=&#34;http://locahost:8000/docs&#34;&gt;Khoj Swagger docs&lt;/a&gt;[^2]&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Index Github Repository for Search, Chat&lt;/h3&gt; &#xA;&lt;p&gt;The Khoj Github plugin can index issues, commit messages and markdown, org-mode and PDF files from any repositories you have access to. This allows you to chat or search with these repositories. Get answers, resolve issues or just explore a repo with the help of your AI personal assistant.&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://faq.khoj.dev&#34;&gt;Khoj FAQ&lt;/a&gt; for a demo of Khoj search and chat. It makes the Khoj github repo available for exploring.&lt;/p&gt; &#xA;&lt;p&gt;Note: &lt;em&gt;Khoj will ignore code files in the repository for now as the default AI model used works best with natural language text, not code.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Setup Khoj Github plugin&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Get a &lt;a href=&#34;https://docs.github.com/en/github/authenticating-to-github/keeping-your-account-and-data-secure/creating-a-personal-access-token&#34;&gt;pat token&lt;/a&gt; with &lt;code&gt;repo&lt;/code&gt; and &lt;code&gt;read:org&lt;/code&gt; scopes in the classic flow.&lt;/li&gt; &#xA; &lt;li&gt;Configure Khoj settings to include the &lt;code&gt;owner&lt;/code&gt; and &lt;code&gt;repo_name&lt;/code&gt;. The &lt;code&gt;owner&lt;/code&gt; will be the organization name if the repo is in an organization. The &lt;code&gt;repo_name&lt;/code&gt; will be the name of the repository. Optionally, you can also supply a branch name. If no branch name is supplied, the &lt;code&gt;master&lt;/code&gt; branch will be used.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Performance&lt;/h2&gt; &#xA;&lt;h3&gt;Query performance&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Semantic search using the bi-encoder is fairly fast at &amp;lt;50 ms&lt;/li&gt; &#xA; &lt;li&gt;Reranking using the cross-encoder is slower at &amp;lt;2s on 15 results. Tweak &lt;code&gt;top_k&lt;/code&gt; to tradeoff speed for accuracy of results&lt;/li&gt; &#xA; &lt;li&gt;Filters in query (e.g by file, word or date) usually add &amp;lt;20ms to query latency&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Indexing performance&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Indexing is more strongly impacted by the size of the source data&lt;/li&gt; &#xA; &lt;li&gt;Indexing 100K+ line corpus of notes takes about 10 minutes&lt;/li&gt; &#xA; &lt;li&gt;Indexing 4000+ images takes about 15 minutes and more than 8Gb of RAM&lt;/li&gt; &#xA; &lt;li&gt;Note: &lt;em&gt;It should only take this long on the first run&lt;/em&gt; as the index is incrementally updated&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Miscellaneous&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Testing done on a Mac M1 and a &amp;gt;100K line corpus of notes&lt;/li&gt; &#xA; &lt;li&gt;Search, indexing on a GPU has not been tested yet&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;h3&gt;Visualize Codebase&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://mango-dune-07a8b7110.1.azurestaticapps.net/?repo=debanjum%2Fkhoj&#34;&gt;Interactive Visualization&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/khoj-ai/khoj/raw/master/docs/khoj_codebase_visualization_0.2.1.png?&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Setup&lt;/h3&gt; &#xA;&lt;h4&gt;Using Pip&lt;/h4&gt; &#xA;&lt;h5&gt;1. Install&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Get Khoj Code&#xA;git clone https://github.com/khoj-ai/khoj &amp;amp;&amp;amp; cd khoj&#xA;&#xA;# Create, Activate Virtual Environment&#xA;python3 -m venv .venv &amp;amp;&amp;amp; source .venv/bin/activate&#xA;&#xA;# Install Khoj for Development&#xA;pip install -e .[dev]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;2. Run&lt;/h5&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Start Khoj &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;khoj -vv&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Configure Khoj &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Via the Settings UI&lt;/strong&gt;: Add files, directories to index the &lt;a href=&#34;http://localhost:8000/config&#34;&gt;Khoj settings&lt;/a&gt; UI once Khoj has started up. Once you&#39;ve saved all your settings, click &lt;code&gt;Configure&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Manually&lt;/strong&gt;: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Copy the &lt;code&gt;config/khoj_sample.yml&lt;/code&gt; to &lt;code&gt;~/.khoj/khoj.yml&lt;/code&gt;&lt;/li&gt; &#xA;     &lt;li&gt;Set &lt;code&gt;input-files&lt;/code&gt; or &lt;code&gt;input-filter&lt;/code&gt; in each relevant &lt;code&gt;content-type&lt;/code&gt; section of &lt;code&gt;~/.khoj/khoj.yml&lt;/code&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;Set &lt;code&gt;input-directories&lt;/code&gt; field in &lt;code&gt;image&lt;/code&gt; &lt;code&gt;content-type&lt;/code&gt; section&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;Delete &lt;code&gt;content-type&lt;/code&gt; and &lt;code&gt;processor&lt;/code&gt; sub-section(s) irrelevant for your use-case&lt;/li&gt; &#xA;     &lt;li&gt;Restart khoj&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Note: Wait after configuration for khoj to Load ML model, generate embeddings and expose API to query notes, images, documents etc specified in config YAML&lt;/p&gt; &#xA;&lt;h4&gt;Using Docker&lt;/h4&gt; &#xA;&lt;h5&gt;1. Clone&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/khoj-ai/khoj &amp;amp;&amp;amp; cd khoj&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;2. Configure&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Required&lt;/strong&gt;: Update &lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/docker-compose.yml&#34;&gt;docker-compose.yml&lt;/a&gt; to mount your images, (org-mode or markdown) notes, PDFs and Github repositories&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Optional&lt;/strong&gt;: Edit application configuration in &lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/config/khoj_docker.yml&#34;&gt;khoj_docker.yml&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;3. Run&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker-compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;Note: The first run will take time. Let it run, it&#39;s mostly not hung, just generating embeddings&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h5&gt;4. Upgrade&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker-compose build --pull&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Using Conda&lt;/h4&gt; &#xA;&lt;h5&gt;1. Install Dependencies&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html&#34;&gt;Install Conda&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;2. Install Khoj&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/khoj-ai/khoj &amp;amp;&amp;amp; cd khoj&#xA;conda env create -f config/environment.yml&#xA;conda activate khoj&#xA;python3 -m pip install pyqt6  # As conda does not support pyqt6 yet&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;3. Configure&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Copy the &lt;code&gt;config/khoj_sample.yml&lt;/code&gt; to &lt;code&gt;~/.khoj/khoj.yml&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Set &lt;code&gt;input-files&lt;/code&gt; or &lt;code&gt;input-filter&lt;/code&gt; in each relevant &lt;code&gt;content-type&lt;/code&gt; section of &lt;code&gt;~/.khoj/khoj.yml&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Set &lt;code&gt;input-directories&lt;/code&gt; field in &lt;code&gt;image&lt;/code&gt; &lt;code&gt;content-type&lt;/code&gt; section&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Delete &lt;code&gt;content-type&lt;/code&gt;, &lt;code&gt;processor&lt;/code&gt; sub-sections irrelevant for your use-case&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;4. Run&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python3 -m src.khoj.main -vv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Load ML model, generate embeddings and expose API to query notes, images, documents etc specified in config YAML&lt;/p&gt; &#xA;&lt;h5&gt;5. Upgrade&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd khoj&#xA;git pull origin master&#xA;conda deactivate khoj&#xA;conda env update -f config/environment.yml&#xA;conda activate khoj&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Validate&lt;/h3&gt; &#xA;&lt;h4&gt;Before Make Changes&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install Git Hooks for Validation &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pre-commit install -t pre-push -t pre-commit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This ensures standard code formatting fixes and other checks run automatically on every commit and push&lt;/li&gt; &#xA;   &lt;li&gt;Note 1: If &lt;a href=&#34;https://pre-commit.com/#intro&#34;&gt;pre-commit&lt;/a&gt; didn&#39;t already get installed, &lt;a href=&#34;https://pre-commit.com/#install&#34;&gt;install it&lt;/a&gt; via &lt;code&gt;pip install pre-commit&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Note 2: To run the pre-commit changes manually, use &lt;code&gt;pre-commit run --hook-stage manual --all&lt;/code&gt; before creating PR&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;Before Creating PR&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Run Tests. If you get an error complaining about a missing &lt;code&gt;fast_tokenizer_file&lt;/code&gt;, follow the solution &lt;a href=&#34;https://github.com/UKPLab/sentence-transformers/issues/1659&#34;&gt;in this Github issue&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pytest&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run MyPy to check types&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mypy --config-file pyproject.toml&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;After Creating PR&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Automated &lt;a href=&#34;https://raw.githubusercontent.com/khoj-ai/khoj/master/.github/workflows&#34;&gt;validation workflows&lt;/a&gt; run for every PR.&lt;/p&gt; &lt;p&gt;Ensure any issues seen by them our fixed&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Test the python packge created for a PR&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Download and extract the zipped &lt;code&gt;.whl&lt;/code&gt; artifact generated from the pypi workflow run for the PR.&lt;/li&gt; &#xA;   &lt;li&gt;Install (in your virtualenv) with &lt;code&gt;pip install /path/to/download*.whl&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Start and use the application to see if it works fine&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1&#34;&gt;Multi-QA MiniLM Model&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2&#34;&gt;All MiniLM Model&lt;/a&gt; for Text Search. See &lt;a href=&#34;https://www.sbert.net/examples/applications/retrieve_rerank/README.html&#34;&gt;SBert Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/CLIP&#34;&gt;OpenAI CLIP Model&lt;/a&gt; for Image Search. See &lt;a href=&#34;https://www.sbert.net/examples/applications/image-search/README.html&#34;&gt;SBert Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Charles Cave for &lt;a href=&#34;http://members.optusnet.com.au/~charles57/GTD/orgnode.html&#34;&gt;OrgNode Parser&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mooz.github.io/org-js/&#34;&gt;Org.js&lt;/a&gt; to render Org-mode results on the Web interface&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/markdown-it/markdown-it&#34;&gt;Markdown-it&lt;/a&gt; to render Markdown results on the Web interface&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;[^1]: Default Khoj config file @ &lt;code&gt;~/.khoj/khoj.yml&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;[^2]: Default Khoj url @ &lt;a href=&#34;http://localhost:8000&#34;&gt;http://localhost:8000&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>