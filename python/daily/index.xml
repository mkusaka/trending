<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-05T01:36:24Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>hisxo/ReconAIzer</title>
    <updated>2023-04-05T01:36:24Z</updated>
    <id>tag:github.com,2023-04-05:/hisxo/ReconAIzer</id>
    <link href="https://github.com/hisxo/ReconAIzer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Burp Suite extension to add OpenAI to Burp to help you with your Bug Bounty recon!&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/16657045/229288097-9ff8cda0-5159-4817-ab7f-371934cff65a.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;ReconAIzer&lt;/h1&gt; &#xA;&lt;p&gt;ReconAIzer is a powerful Jython extension for Burp Suite that leverages OpenAI to help bug bounty hunters optimize their recon process. This extension automates various tasks, making it easier and faster for security researchers to identify and exploit vulnerabilities.&lt;/p&gt; &#xA;&lt;p&gt;Once installed, ReconAIzer add a contextual menu and a dedicated tab to see the results:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/16657045/229282506-ea5bc46b-b4d9-4f1b-9ec1-5dcd987de0bc.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Burp Suite&lt;/li&gt; &#xA; &lt;li&gt;Jython Standalone Jar&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Follow these steps to install the ReconAIzer extension on Burp Suite:&lt;/p&gt; &#xA;&lt;h3&gt;Step 1: Download Jython&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download the latest Jython Standalone Jar from the official website: &lt;a href=&#34;https://www.jython.org/download&#34;&gt;https://www.jython.org/download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Save the Jython Standalone Jar file in a convenient location on your computer.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Step 2: Configure Jython in Burp Suite&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open Burp Suite.&lt;/li&gt; &#xA; &lt;li&gt;Go to the &#34;Extensions&#34; tab.&lt;/li&gt; &#xA; &lt;li&gt;Click on the &#34;Extensions settings&#34; sub-tab.&lt;/li&gt; &#xA; &lt;li&gt;Under &#34;Python Environment,&#34; click on the &#34;Select file...&#34; button next to &#34;Location of the Jython standalone JAR file.&#34;&lt;/li&gt; &#xA; &lt;li&gt;Browse to the location where you saved the Jython Standalone Jar file in Step 1 and select it.&lt;/li&gt; &#xA; &lt;li&gt;Wait for the &#34;Python Environment&#34; status to change to &#34;Jython (version x.x.x) successfully loaded,&#34; where x.x.x represents the Jython version.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Step 3: Download and Install ReconAIzer&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download the &lt;a href=&#34;https://github.com/hisxo/ReconAIzer/releases&#34;&gt;latest release of ReconAIzer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Open the file and go on line 103 to replace &lt;em&gt;&#34;[YOUR OPENAI API KEY]&#34;&lt;/em&gt; with your OpenAI API key&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;em&gt;Note: Your OpenAI API key can be found here: &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;https://platform.openai.com/account/api-keys&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Step 4: Download and Install ReconAIzer&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open Burp Suite&lt;/li&gt; &#xA; &lt;li&gt;Go back to the &#34;Extensions&#34; tab in Burp Suite.&lt;/li&gt; &#xA; &lt;li&gt;Click the &#34;Add&#34; button.&lt;/li&gt; &#xA; &lt;li&gt;In the &#34;Add extension&#34; dialog, select &#34;Python&#34; as the &#34;Extension type.&#34;&lt;/li&gt; &#xA; &lt;li&gt;Click on the &#34;Select file...&#34; button next to &#34;Extension file&#34; and browse to the location where you saved the &lt;code&gt;ReconAIzer.py&lt;/code&gt; file in Step 3.1. Select the file and click &#34;Open.&#34;&lt;/li&gt; &#xA; &lt;li&gt;Make sure the &#34;Load&#34; checkbox is selected and click the &#34;Next&#34; button.&lt;/li&gt; &#xA; &lt;li&gt;Wait for the extension to be loaded. You should see a message in the &#34;Output&#34; section stating that the ReconAIzer extension has been successfully loaded.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Congratulations! You have successfully installed the ReconAIzer extension in Burp Suite. You can now start using it to enhance your bug bounty hunting experience.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note: Feel free to suggest prompts improvements or anything you would like to see on ReconAIzer!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Happy bug hunting!&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/16657045/229282837-da0c0314-0882-4ef2-9203-018682330f76.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>WordAsImage/Word-As-Image</title>
    <updated>2023-04-05T01:36:24Z</updated>
    <id>tag:github.com,2023-04-05:/WordAsImage/Word-As-Image</id>
    <link href="https://github.com/WordAsImage/Word-As-Image" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Word-As-Image for Semantic Typography&lt;/h1&gt; &#xA;&lt;!-- [![arXiv](https://img.shields.io/badge/📃-arXiv%20-red.svg)](https://arxiv.org/abs/2303.01818) --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://wordasimage.github.io/Word-As-Image-Page/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%8C%90-Website%20-blue.svg?sanitize=true&#34; alt=&#34;webpage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/SemanticTypography/Word-As-Image&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97-Demo%20-yellow.svg?sanitize=true&#34; alt=&#34;Huggingface space&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=9D12a6RCQaw&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%93%BD%EF%B8%8F-Video%20-orchid.svg?sanitize=true&#34; alt=&#34;Youtube&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/WordAsImage/Word-As-Image/main/images/teaser.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt;&#xA;&lt;br&gt; A few examples of our &#xA;&lt;b&gt;W&lt;/b&gt;ord-&#xA;&lt;b&gt;A&lt;/b&gt;s-&#xA;&lt;b&gt;I&lt;/b&gt;mage illustrations in various fonts and for different textual concept. The semantically adjusted letters are created completely automatically using our method, and can then be used for further creative design as we illustrate here.&#xA;&lt;br&gt;&#xA;&lt;br&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;A word-as-image is a semantic typography technique where a word illustration presents a visualization of the meaning of the word, while also preserving its readability. We present a method to create word-as-image illustrations automatically. This task is highly challenging as it requires semantic understanding of the word and a creative idea of where and how to depict these semantics in a visually pleasing and legible manner. We rely on the remarkable ability of recent large pretrained language-vision models to distill textual concepts visually. We target simple, concise, black-and-white designs that convey the semantics clearly.We deliberately do not change the color or texture of the letters and do not use embellishments. Our method optimizes the outline of each letter to convey the desired concept, guided by a pretrained Stable Diffusion model. We incorporate additional loss terms to ensure the legibility of the text and the preservation of the style of the font. We show high quality and engaging results on numerous examples and compare to alternative techniques.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Description&lt;/h2&gt; &#xA;&lt;p&gt;Official implementation of Word-As-Image for Semantic Typography paper. &lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repo:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/WordAsImage/Word-As-Image.git&#xA;cd Word-As-Image&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Create a new conda environment and install the libraries:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create --name word python=3.8.15&#xA;conda activate word&#xA;pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113&#xA;conda install -y numpy scikit-image&#xA;conda install -y -c anaconda cmake&#xA;conda install -y -c conda-forge ffmpeg&#xA;pip install svgwrite svgpathtools cssutils numba torch-tools scikit-fmm easydict visdom freetype-py shapely&#xA;pip install opencv-python==4.5.4.60  &#xA;pip install kornia==0.6.8&#xA;pip install wandb&#xA;pip install shapely&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Install diffusers:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install diffusers==0.8&#xA;pip install transformers scipy ftfy accelerate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Install diffvg:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/BachiLi/diffvg.git&#xA;cd diffvg&#xA;git submodule update --init --recursive&#xA;python setup.py install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;Paste your HuggingFace &lt;a href=&#34;https://huggingface.co/settings/tokens&#34;&gt;access token&lt;/a&gt; for StableDiffusion in the TOKEN file.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Run Experiments&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda activate word&#xA;cd Word-As-Image&#xA;&#xA;# Please modify the parameters accordingly in the file and run:&#xA;bash run_word_as_image.sh&#xA;&#xA;# Or run :&#xA;python code/main.py --experiment &amp;lt;experiment&amp;gt; --semantic_concept &amp;lt;concept&amp;gt; --optimized_letter &amp;lt;letter&amp;gt; --seed &amp;lt;seed&amp;gt; --font &amp;lt;font_name&amp;gt; --use_wandb &amp;lt;0/1&amp;gt; --wandb_user &amp;lt;user name&amp;gt; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--semantic_concept&lt;/code&gt; : the semantic concept to insert&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--optimized_letter&lt;/code&gt; : one letter in the word to optimize&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--font&lt;/code&gt; : font name, the &lt;font name&gt;.ttf file should be located in code/data/fonts/&lt;/font&gt;&lt;/li&gt;&#xA; &lt;font name&gt; &lt;/font&gt;&#xA;&lt;/ul&gt;&#xA;&lt;font name&gt; &lt;p&gt;Optional arguments:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;code&gt;--word&lt;/code&gt; : The text to work on, default: the semantic concept&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;--config&lt;/code&gt; : Path to config file, default: code/config/base.yaml&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;--experiment&lt;/code&gt; : You can specify any experiment in the config file, default: conformal_0.5_dist_pixel_100_kernel201&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;--log_dir&lt;/code&gt; : Default: output folder&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;--prompt_suffix&lt;/code&gt; : Default: &#34;minimal flat 2d vector. lineal color. trending on artstation&#34;&lt;/li&gt; &#xA; &lt;/ul&gt; &lt;h3&gt;Examples&lt;/h3&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python code/main.py  --semantic_concept &#34;BUNNY&#34; --optimized_letter &#34;Y&#34; --font &#34;KaushanScript-Regular&#34; --seed 0&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;br&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/WordAsImage/Word-As-Image/main/images/KaushanScript-Regular_BUNNY_Y.svg?sanitize=true&#34; width=&#34;22%&#34;&gt; &#xA; &lt;/div&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python code/main.py  --semantic_concept &#34;LEAVES&#34; --word &#34;NATURE&#34; --optimized_letter &#34;T&#34; --font &#34;HobeauxRococeaux-Sherman&#34; --seed 0&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;br&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/WordAsImage/Word-As-Image/main/images/HobeauxRococeaux-Sherman_NATURE_T.svg?sanitize=true&#34; width=&#34;25%&#34;&gt; &#xA; &lt;/div&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Pay attention, as the arguments are case-sensitive, but it can handle both upper and lowercase letters depending on the input letters.&lt;/li&gt; &#xA; &lt;/ul&gt; &lt;h2&gt;Tips&lt;/h2&gt; &lt;p&gt;If the outcome does not meet your quality expectations, you could try the following options:&lt;/p&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Adjusting the weight 𝛼 of the L𝑎𝑐𝑎𝑝 loss, which preserves the letter&#39;s structure after deformation.&lt;/li&gt; &#xA;  &lt;li&gt;Modifying the 𝜎 parameter of the low-pass filter used in the L𝑡𝑜𝑛𝑒 loss, which limits the degree of deviation from the original letter.&lt;/li&gt; &#xA;  &lt;li&gt;Changing the number of control points, as this can influence the outputs.&lt;/li&gt; &#xA;  &lt;li&gt;Experimenting with different seeds, as each may produce slightly different results.&lt;/li&gt; &#xA;  &lt;li&gt;Changing the font type, as this can also result in various outputs.&lt;/li&gt; &#xA; &lt;/ol&gt; &lt;h2&gt;Acknowledgement&lt;/h2&gt; &lt;p&gt;Our implementation is based ob Stable Diffusion text-to-image model from Hugging Face&#39;s &lt;a href=&#34;https://github.com/huggingface/diffusers&#34;&gt;Diffusers&lt;/a&gt; library, combined with &lt;a href=&#34;https://github.com/BachiLi/diffvg&#34;&gt;Diffvg&lt;/a&gt;. The framework is built on &lt;a href=&#34;https://github.com/Picsart-AI-Research/LIVE-Layerwise-Image-Vectorization&#34;&gt;Live&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Licence&lt;/h2&gt; &lt;p&gt;This work is licensed under a &lt;a href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;.&lt;/p&gt; &lt;/font&gt;</summary>
  </entry>
  <entry>
    <title>kale5195/chilloutai</title>
    <updated>2023-04-05T01:36:24Z</updated>
    <id>tag:github.com,2023-04-05:/kale5195/chilloutai</id>
    <link href="https://github.com/kale5195/chilloutai" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AI 图片生成&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/kale5195/chilloutai/main/README-EN.md&#34;&gt;English&lt;/a&gt; | 简体中文 &lt;/p&gt; &#xA;&lt;p&gt;2023-04-04:&lt;/p&gt; &#xA;&lt;p&gt;你可以加入 &lt;a href=&#34;https://dub.sh/bot007&#34;&gt;slack channel&lt;/a&gt; 体验图片生成 + ChatGPT Bot&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;希望这个教程可以帮助你！如果想支持一下，可以使用 &lt;a href=&#34;https://runpod.io?ref=78g53ap2&#34;&gt;RunPod Referral link&lt;/a&gt; 这个链接注册&lt;/p&gt; &#xA;&lt;p&gt;教程已分成两部分：&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/kale5195/automatic-chillout/raw/main/serverless-zh.md&#34;&gt;如何在 RunPod Serverless 中运行 ChilloutMix 和 LORA&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/kale5195/automatic-chillout/raw/main/web-ui-zh.md&#34;&gt;如何在 RunPod WebUI 中运行 ChilloutMix 和 LORA&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h2&gt;Update&lt;/h2&gt; &#xA;&lt;p&gt;2.29: 新增&lt;a href=&#34;https://civitai.com/models/10415/guofeng3&#34;&gt;国风&lt;/a&gt;模型，并搭配了&lt;a href=&#34;https://civitai.com/models/12597/moxin&#34;&gt;墨心&lt;/a&gt;和疏可走马 LORA&lt;/p&gt; &#xA;&lt;p&gt;可参考教程二，直接使用这个 &lt;a href=&#34;https://runpod.io/gsc?template=svr4ufvg8c&amp;amp;ref=78g53ap2&#34;&gt;Template&lt;/a&gt; 链接部署&lt;/p&gt;</summary>
  </entry>
</feed>