<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-12-21T01:36:28Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>comet-ml/opik</title>
    <updated>2024-12-21T01:36:28Z</updated>
    <id>tag:github.com,2024-12-21:/comet-ml/opik</id>
    <link href="https://github.com/comet-ml/opik" rel="alternate"></link>
    <summary type="html">&lt;p&gt;From RAG chatbots to code assistants to complex agentic pipelines and beyond, build LLM systems that run better, faster, and cheaper with tracing, evaluations, and dashboards.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34; style=&#34;border-bottom: none&#34;&gt; &#xA; &lt;div&gt; &#xA;  &lt;a href=&#34;https://www.comet.com/site/products/opik/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=header_img&amp;amp;utm_campaign=opik&#34;&gt;&#xA;   &lt;picture&gt; &#xA;    &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;/apps/opik-documentation/documentation/static/img/logo-dark-mode.svg&#34;&gt; &#xA;    &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;/apps/opik-documentation/documentation/static/img/opik-logo.svg&#34;&gt; &#xA;    &lt;img alt=&#34;Comet Opik logo&#34; src=&#34;https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/static/img/opik-logo.svg?sanitize=true&#34; width=&#34;200&#34;&gt; &#xA;   &lt;/picture&gt;&lt;/a&gt; &#xA;  &lt;br&gt; Opik &#xA; &lt;/div&gt; Open source LLM evaluation framework&lt;br&gt; &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; From RAG chatbots to code assistants to complex agentic pipelines and beyond, build LLM systems that run better, faster, and cheaper with tracing, evaluations, and dashboards. &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://pypi.org/project/opik/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/opik&#34; alt=&#34;Python SDK&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/comet-ml/opik/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/comet-ml/opik&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/comet-ml/opik/actions/workflows/build_apps.yml&#34;&gt;&lt;img src=&#34;https://github.com/comet-ml/opik/actions/workflows/build_apps.yml/badge.svg?sanitize=true&#34; alt=&#34;Build&#34;&gt;&lt;/a&gt; &lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/opik_quickstart.ipynb&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA; &lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/opik_quickstart.ipynb&#34;&gt; &#xA;  &lt;!-- &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; alt=&#34;Open Quickstart In Colab&#34;/&gt; --&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.comet.com/site/products/opik/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=website_button&amp;amp;utm_campaign=opik&#34;&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://chat.comet.com&#34;&gt;&lt;b&gt;Slack community&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://x.com/Cometml&#34;&gt;&lt;b&gt;Twitter&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://www.comet.com/docs/opik/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=docs_button&amp;amp;utm_campaign=opik&#34;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/comet-ml/opik/main/readme-thumbnail.png&#34; alt=&#34;Opik thumbnail&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ What is Opik?&lt;/h2&gt; &#xA;&lt;p&gt;Opik is an open-source platform for evaluating, testing and monitoring LLM applications. Built by &lt;a href=&#34;https://www.comet.com?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=what_is_opik_link&amp;amp;utm_campaign=opik&#34;&gt;Comet&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;You can use Opik for:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Development:&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tracing:&lt;/strong&gt; Track all LLM calls and traces during development and production (&lt;a href=&#34;https://www.comet.com/docs/opik/quickstart/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=quickstart_link&amp;amp;utm_campaign=opik&#34;&gt;Quickstart&lt;/a&gt;, &lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/overview/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=integrations_link&amp;amp;utm_campaign=opik&#34;&gt;Integrations&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Annotations:&lt;/strong&gt; Annotate your LLM calls by logging feedback scores using the &lt;a href=&#34;https://www.comet.com/docs/opik/tracing/annotate_traces/#annotating-traces-and-spans-using-the-sdk?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=sdk_link&amp;amp;utm_campaign=opik&#34;&gt;Python SDK&lt;/a&gt; or the &lt;a href=&#34;https://www.comet.com/docs/opik/tracing/annotate_traces/#annotating-traces-through-the-ui?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=ui_link&amp;amp;utm_campaign=opik&#34;&gt;UI&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Evaluation&lt;/strong&gt;: Automate the evaluation process of your LLM application:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Datasets and Experiments&lt;/strong&gt;: Store test cases and run experiments (&lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/manage_datasets/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=datasets_link&amp;amp;utm_campaign=opik&#34;&gt;Datasets&lt;/a&gt;, &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/evaluate_your_llm/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=eval_link&amp;amp;utm_campaign=opik&#34;&gt;Evaluate your LLM Application&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;LLM as a judge metrics&lt;/strong&gt;: Use Opik&#39;s LLM as a judge metric for complex issues like &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/metrics/hallucination/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=hallucination_link&amp;amp;utm_campaign=opik&#34;&gt;hallucination detection&lt;/a&gt;, &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/metrics/moderation/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=moderation_link&amp;amp;utm_campaign=opik&#34;&gt;moderation&lt;/a&gt; and RAG evaluation (&lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/metrics/answer_relevance/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=alex_link&amp;amp;utm_campaign=opik&#34;&gt;Answer Relevance&lt;/a&gt;, &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/metrics/context_precision/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=context_link&amp;amp;utm_campaign=opik&#34;&gt;Context Precision&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;CI/CD integration&lt;/strong&gt;: Run evaluations as part of your CI/CD pipeline using our &lt;a href=&#34;https://www.comet.com/docs/opik/testing/pytest_integration/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=pytest_link&amp;amp;utm_campaign=opik&#34;&gt;PyTest integration&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Production Monitoring&lt;/strong&gt;:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Log all your production traces&lt;/strong&gt;: Opik has been designed to support high volumes of traces, making it easy to monitor your production applications.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Monitoring dashboards&lt;/strong&gt;: Review your feedback scores, trace count and tokens over time in the &lt;a href=&#34;https://www.comet.com/docs/opik/self-host/opik_dashboard/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=dashboard_link&amp;amp;utm_campaign=opik&#34;&gt;Opik Dashboard&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP]&lt;br&gt; If you are looking for features that Opik doesn&#39;t have today, please raise a new &lt;a href=&#34;https://github.com/comet-ml/opik/issues/new/choose&#34;&gt;Feature request&lt;/a&gt; üöÄ&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üõ†Ô∏è Installation&lt;/h2&gt; &#xA;&lt;p&gt;Opik is available as a fully open source local installation or using Comet.com as a hosted solution. The easiest way to get started with Opik is by creating a free Comet account at &lt;a href=&#34;https://www.comet.com/signup?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=install&amp;amp;utm_campaign=opik&#34;&gt;comet.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;d like to self-host Opik, you can do so by cloning the repository and starting the platform using Docker Compose:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Clone the Opik repository&#xA;git clone https://github.com/comet-ml/opik.git&#xA;&#xA;# Navigate to the opik/deployment/docker-compose directory&#xA;cd opik/deployment/docker-compose&#xA;&#xA;# Start the Opik platform&#xA;docker compose up --detach&#xA;&#xA;# You can now visit http://localhost:5173 on your browser!&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information about the different deployment options, please see our deployment guides:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Installation methods&lt;/th&gt; &#xA;   &lt;th&gt;Docs link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Local instance&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/self-host/local_deployment?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=self_host_link&amp;amp;utm_campaign=opik&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Local%20Deployments-%232496ED?style=flat&amp;amp;logo=docker&amp;amp;logoColor=white&#34; alt=&#34;Local Deployment&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Kubernetes&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/self-host/kubernetes/#kubernetes-installation?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=kubernetes_link&amp;amp;utm_campaign=opik&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Kubernetes-%23326ce5.svg?&amp;amp;logo=kubernetes&amp;amp;logoColor=white&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;üèÅ Get Started&lt;/h2&gt; &#xA;&lt;p&gt;To get started, you will need to first install the Python SDK:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install opik&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once the SDK is installed, you can configure it by running the &lt;code&gt;opik configure&lt;/code&gt; command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;opik configure&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will allow you to configure Opik locally by setting the correct local server address or if you&#39;re using the Cloud platform by setting the API Key&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP]&lt;br&gt; You can also call the &lt;code&gt;opik.configure(use_local=True)&lt;/code&gt; method from your Python code to configure the SDK to run on the local installation.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;You are now ready to start logging traces using the &lt;a href=&#34;https://www.comet.com/docs/opik/python-sdk-reference/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=sdk_link2&amp;amp;utm_campaign=opik&#34;&gt;Python SDK&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;üìù Logging Traces&lt;/h3&gt; &#xA;&lt;p&gt;The easiest way to get started is to use one of our integrations. Opik supports:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Integration&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Documentation&lt;/th&gt; &#xA;   &lt;th&gt;Try in Colab&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OpenAI&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all OpenAI LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/openai/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=openai_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/openai.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LiteLLM&lt;/td&gt; &#xA;   &lt;td&gt;Call any LLM model using the OpenAI format&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/comet-ml/opik/main/tracing/integrations/litellm.md&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/litellm.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LangChain&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all LangChain LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/langchain/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=langchain_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/langchain.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Haystack&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all Haystack calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/haystack/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=haystack_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/haystack.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Bedrock&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all Bedrock LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/bedrock?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=bedrock_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/bedrock.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Anthropic&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all Anthropic LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/anthropic?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=anthropic_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/anthropic.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gemini&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all Gemini LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/gemini?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=gemini_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/gemini.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Groq&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all Groq LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/groq?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=groq_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/groq.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LangGraph&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all LangGraph executions&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/langgraph/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=langchain_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/langgraph.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LlamaIndex&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all LlamaIndex LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/llama_index?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=llama_index_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/llama-index.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ollama&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all Ollama LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/ollama?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=ollama_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/ollama.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Predibase&lt;/td&gt; &#xA;   &lt;td&gt;Fine-tune and serve open-source Large Language Models&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/predibase?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=predibase_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/predibase.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ragas&lt;/td&gt; &#xA;   &lt;td&gt;Evaluation framework for your Retrieval Augmented Generation (RAG) pipelines&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/ragas?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=ragas_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/ragas.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;watsonx&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all watsonx LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/watsonx?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=watsonx_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/watsonx.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP]&lt;br&gt; If the framework you are using is not listed above, feel free to &lt;a href=&#34;https://github.com/comet-ml/opik/issues&#34;&gt;open an issue&lt;/a&gt; or submit a PR with the integration.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;If you are not using any of the frameworks above, you can also use the &lt;code&gt;track&lt;/code&gt; function decorator to &lt;a href=&#34;https://www.comet.com/docs/opik/tracing/log_traces/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=traces_link&amp;amp;utm_campaign=opik&#34;&gt;log traces&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import opik&#xA;&#xA;opik.configure(use_local=True) # Run locally&#xA;&#xA;@opik.track&#xA;def my_llm_function(user_question: str) -&amp;gt; str:&#xA;    # Your LLM code here&#xA;&#xA;    return &#34;Hello&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP]&lt;br&gt; The track decorator can be used in conjunction with any of our integrations and can also be used to track nested function calls.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;üßë‚Äç‚öñÔ∏è LLM as a Judge metrics&lt;/h3&gt; &#xA;&lt;p&gt;The Python Opik SDK includes a number of LLM as a judge metrics to help you evaluate your LLM application. Learn more about it in the &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/metrics/overview/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=metrics_2_link&amp;amp;utm_campaign=opik&#34;&gt;metrics documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To use them, simply import the relevant metric and use the &lt;code&gt;score&lt;/code&gt; function:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from opik.evaluation.metrics import Hallucination&#xA;&#xA;metric = Hallucination()&#xA;score = metric.score(&#xA;    input=&#34;What is the capital of France?&#34;,&#xA;    output=&#34;Paris&#34;,&#xA;    context=[&#34;France is a country in Europe.&#34;]&#xA;)&#xA;print(score)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Opik also includes a number of pre-built heuristic metrics as well as the ability to create your own. Learn more about it in the &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/metrics/overview?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=metrics_3_link&amp;amp;utm_campaign=opik&#34;&gt;metrics documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;üîç Evaluating your LLM Application&lt;/h3&gt; &#xA;&lt;p&gt;Opik allows you to evaluate your LLM application during development through &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/manage_datasets/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=datasets_2_link&amp;amp;utm_campaign=opik&#34;&gt;Datasets&lt;/a&gt; and &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/evaluate_your_llm/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=experiments_link&amp;amp;utm_campaign=opik&#34;&gt;Experiments&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can also run evaluations as part of your CI/CD pipeline using our &lt;a href=&#34;https://www.comet.com/docs/opik/testing/pytest_integration/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=pytest_2_link&amp;amp;utm_campaign=opik&#34;&gt;PyTest integration&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; &#xA;&lt;p&gt;There are many ways to contribute to Opik:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Submit &lt;a href=&#34;https://github.com/comet-ml/opik/issues&#34;&gt;bug reports&lt;/a&gt; and &lt;a href=&#34;https://github.com/comet-ml/opik/issues&#34;&gt;feature requests&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Review the documentation and submit &lt;a href=&#34;https://github.com/comet-ml/opik/pulls&#34;&gt;Pull Requests&lt;/a&gt; to improve it&lt;/li&gt; &#xA; &lt;li&gt;Speaking or writing about Opik and &lt;a href=&#34;https://chat.comet.com&#34;&gt;letting us know&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Upvoting &lt;a href=&#34;https://github.com/comet-ml/opik/issues?q=is%3Aissue+is%3Aopen+label%3A%22enhancement%22&#34;&gt;popular feature requests&lt;/a&gt; to show your support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To learn more about how to contribute to Opik, please see our &lt;a href=&#34;https://raw.githubusercontent.com/comet-ml/opik/main/CONTRIBUTING.md&#34;&gt;contributing guidelines&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>leggedrobotics/rsl_rl</title>
    <updated>2024-12-21T01:36:28Z</updated>
    <id>tag:github.com,2024-12-21:/leggedrobotics/rsl_rl</id>
    <link href="https://github.com/leggedrobotics/rsl_rl" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Fast and simple implementation of RL algorithms, designed to run fully on GPU.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RSL RL&lt;/h1&gt; &#xA;&lt;p&gt;Fast and simple implementation of RL algorithms, designed to run fully on GPU. This code is an evolution of &lt;code&gt;rl-pytorch&lt;/code&gt; provided with NVIDIA&#39;s Isaac GYM.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;span&gt;‚ö°&lt;/span&gt; The &lt;code&gt;algorithms&lt;/code&gt; branch supports additional algorithms (SAC, DDPG, DSAC, and more)!&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Only PPO is implemented for now. More algorithms will be added later. Contributions are welcome.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Maintainer&lt;/strong&gt;: David Hoeller and Nikita Rudin &lt;br&gt; &lt;strong&gt;Affiliation&lt;/strong&gt;: Robotic Systems Lab, ETH Zurich &amp;amp; NVIDIA &lt;br&gt; &lt;strong&gt;Contact&lt;/strong&gt;: &lt;a href=&#34;mailto:rudinn@ethz.ch&#34;&gt;rudinn@ethz.ch&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;Following are the instructions to setup the repository for your workspace:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/leggedrobotics/rsl_rl&#xA;cd rsl_rl&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The framework supports the following logging frameworks which can be configured through &lt;code&gt;logger&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Tensorboard: &lt;a href=&#34;https://www.tensorflow.org/tensorboard/&#34;&gt;https://www.tensorflow.org/tensorboard/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Weights &amp;amp; Biases: &lt;a href=&#34;https://wandb.ai/site&#34;&gt;https://wandb.ai/site&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Neptune: &lt;a href=&#34;https://docs.neptune.ai/&#34;&gt;https://docs.neptune.ai/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For a demo configuration of the PPO, please check: &lt;a href=&#34;https://raw.githubusercontent.com/leggedrobotics/rsl_rl/master/config/dummy_config.yaml&#34;&gt;dummy_config.yaml&lt;/a&gt; file.&lt;/p&gt; &#xA;&lt;h2&gt;Contribution Guidelines&lt;/h2&gt; &#xA;&lt;p&gt;For documentation, we adopt the &lt;a href=&#34;https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html&#34;&gt;Google Style Guide&lt;/a&gt; for docstrings. We use &lt;a href=&#34;https://www.sphinx-doc.org/en/master/&#34;&gt;Sphinx&lt;/a&gt; for generating the documentation. Please make sure that your code is well-documented and follows the guidelines.&lt;/p&gt; &#xA;&lt;p&gt;We use the following tools for maintaining code quality:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pre-commit.com/&#34;&gt;pre-commit&lt;/a&gt;: Runs a list of formatters and linters over the codebase.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://black.readthedocs.io/en/stable/&#34;&gt;black&lt;/a&gt;: The uncompromising code formatter.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://flake8.pycqa.org/en/latest/&#34;&gt;flake8&lt;/a&gt;: A wrapper around PyFlakes, pycodestyle, and McCabe complexity checker.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please check &lt;a href=&#34;https://pre-commit.com/#install&#34;&gt;here&lt;/a&gt; for instructions to set these up. To run over the entire repository, please execute the following command in the terminal:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# for installation (only once)&#xA;pre-commit install&#xA;# for running&#xA;pre-commit run --all-files&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Useful Links&lt;/h3&gt; &#xA;&lt;p&gt;Environment repositories using the framework:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Legged-Gym&lt;/code&gt; (built on top of NVIDIA Isaac Gym): &lt;a href=&#34;https://leggedrobotics.github.io/legged_gym/&#34;&gt;https://leggedrobotics.github.io/legged_gym/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Orbit&lt;/code&gt; (built on top of NVIDIA Isaac Sim): &lt;a href=&#34;https://isaac-orbit.github.io/&#34;&gt;https://isaac-orbit.github.io/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>onyx-dot-app/onyx</title>
    <updated>2024-12-21T01:36:28Z</updated>
    <id>tag:github.com,2024-12-21:/onyx-dot-app/onyx</id>
    <link href="https://github.com/onyx-dot-app/onyx" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Gen-AI Chat for Teams - Think ChatGPT if it had access to your team&#39;s unique knowledge.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name=&#34;readme-top&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.onyx.app/&#34;&gt; &lt;img width=&#34;50%&#34; src=&#34;https://github.com/onyx-dot-app/onyx/raw/logo/OnyxLogoCropped.jpg?raw=true)&#34;&gt;&lt;/a&gt; &lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt;Open Source Gen-AI + Enterprise Search.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://docs.onyx.app/&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/docs-view-blue&#34; alt=&#34;Documentation&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://join.slack.com/t/danswer/shared_invite/zt-1w76msxmd-HJHLe3KNFIAIzk_0dSOKaQ&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/slack-join-blue.svg?logo=slack&#34; alt=&#34;Slack&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://discord.gg/TDJ59cGV2X&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/discord-join-blue.svg?logo=discord&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/onyx-dot-app/onyx/raw/main/README.md&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/static/v1?label=license&amp;amp;message=MIT&amp;amp;color=blue&#34; alt=&#34;License&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.onyx.app/&#34;&gt;Onyx&lt;/a&gt;&lt;/strong&gt; (formerly Danswer) is the AI Assistant connected to your company&#39;s docs, apps, and people. Onyx provides a Chat interface and plugs into any LLM of your choice. Onyx can be deployed anywhere and for any scale - on a laptop, on-premise, or to cloud. Since you own the deployment, your user data and chats are fully in your own control. Onyx is dual Licensed with most of it under MIT license and designed to be modular and easily extensible. The system also comes fully ready for production usage with user authentication, role management (admin/basic users), chat persistence, and a UI for configuring AI Assistants.&lt;/p&gt; &#xA;&lt;p&gt;Onyx also serves as a Enterprise Search across all common workplace tools such as Slack, Google Drive, Confluence, etc. By combining LLMs and team specific knowledge, Onyx becomes a subject matter expert for the team. Imagine ChatGPT if it had access to your team&#39;s unique knowledge! It enables questions such as &#34;A customer wants feature X, is this already supported?&#34; or &#34;Where&#39;s the pull request for feature Y?&#34;&lt;/p&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;Onyx Web App:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/onyx-dot-app/onyx/assets/32520769/563be14c-9304-47b5-bf0a-9049c2b6f410&#34;&gt;https://github.com/onyx-dot-app/onyx/assets/32520769/563be14c-9304-47b5-bf0a-9049c2b6f410&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Or, plug Onyx into your existing Slack workflows (more integrations to come üòÅ):&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/onyx-dot-app/onyx/assets/25087905/3e19739b-d178-4371-9a38-011430bdec1b&#34;&gt;https://github.com/onyx-dot-app/onyx/assets/25087905/3e19739b-d178-4371-9a38-011430bdec1b&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;For more details on the Admin UI to manage connectors and users, check out our &lt;strong&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=geNzY1nbCnU&#34;&gt;Full Video Demo&lt;/a&gt;&lt;/strong&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Deployment&lt;/h2&gt; &#xA;&lt;p&gt;Onyx can easily be run locally (even on a laptop) or deployed on a virtual machine with a single &lt;code&gt;docker compose&lt;/code&gt; command. Checkout our &lt;a href=&#34;https://docs.onyx.app/quickstart&#34;&gt;docs&lt;/a&gt; to learn more.&lt;/p&gt; &#xA;&lt;p&gt;We also have built-in support for deployment on Kubernetes. Files for that can be found &lt;a href=&#34;https://github.com/onyx-dot-app/onyx/tree/main/deployment/kubernetes&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üíÉ Main Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Chat UI with the ability to select documents to chat with.&lt;/li&gt; &#xA; &lt;li&gt;Create custom AI Assistants with different prompts and backing knowledge sets.&lt;/li&gt; &#xA; &lt;li&gt;Connect Onyx with LLM of your choice (self-host for a fully airgapped solution).&lt;/li&gt; &#xA; &lt;li&gt;Document Search + AI Answers for natural language queries.&lt;/li&gt; &#xA; &lt;li&gt;Connectors to all common workplace tools like Google Drive, Confluence, Slack, etc.&lt;/li&gt; &#xA; &lt;li&gt;Slack integration to get answers and search results directly in Slack.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üöß Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Chat/Prompt sharing with specific teammates and user groups.&lt;/li&gt; &#xA; &lt;li&gt;Multimodal model support, chat with images, video etc.&lt;/li&gt; &#xA; &lt;li&gt;Choosing between LLMs and parameters during chat session.&lt;/li&gt; &#xA; &lt;li&gt;Tool calling and agent configurations options.&lt;/li&gt; &#xA; &lt;li&gt;Organizational understanding and ability to locate and suggest experts from your team.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Other Notable Benefits of Onyx&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;User Authentication with document level access management.&lt;/li&gt; &#xA; &lt;li&gt;Best in class Hybrid Search across all sources (BM-25 + prefix aware embedding models).&lt;/li&gt; &#xA; &lt;li&gt;Admin Dashboard to configure connectors, document-sets, access, etc.&lt;/li&gt; &#xA; &lt;li&gt;Custom deep learning models + learn from user feedback.&lt;/li&gt; &#xA; &lt;li&gt;Easy deployment and ability to host Onyx anywhere of your choosing.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üîå Connectors&lt;/h2&gt; &#xA;&lt;p&gt;Efficiently pulls the latest changes from:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Slack&lt;/li&gt; &#xA; &lt;li&gt;GitHub&lt;/li&gt; &#xA; &lt;li&gt;Google Drive&lt;/li&gt; &#xA; &lt;li&gt;Confluence&lt;/li&gt; &#xA; &lt;li&gt;Jira&lt;/li&gt; &#xA; &lt;li&gt;Zendesk&lt;/li&gt; &#xA; &lt;li&gt;Gmail&lt;/li&gt; &#xA; &lt;li&gt;Notion&lt;/li&gt; &#xA; &lt;li&gt;Gong&lt;/li&gt; &#xA; &lt;li&gt;Slab&lt;/li&gt; &#xA; &lt;li&gt;Linear&lt;/li&gt; &#xA; &lt;li&gt;Productboard&lt;/li&gt; &#xA; &lt;li&gt;Guru&lt;/li&gt; &#xA; &lt;li&gt;Bookstack&lt;/li&gt; &#xA; &lt;li&gt;Document360&lt;/li&gt; &#xA; &lt;li&gt;Sharepoint&lt;/li&gt; &#xA; &lt;li&gt;Hubspot&lt;/li&gt; &#xA; &lt;li&gt;Local Files&lt;/li&gt; &#xA; &lt;li&gt;Websites&lt;/li&gt; &#xA; &lt;li&gt;And more ...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìö Editions&lt;/h2&gt; &#xA;&lt;p&gt;There are two editions of Onyx:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Onyx Community Edition (CE) is available freely under the MIT Expat license. This version has ALL the core features discussed above. This is the version of Onyx you will get if you follow the Deployment guide above.&lt;/li&gt; &#xA; &lt;li&gt;Onyx Enterprise Edition (EE) includes extra features that are primarily useful for larger organizations. Specifically, this includes: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Single Sign-On (SSO), with support for both SAML and OIDC&lt;/li&gt; &#xA;   &lt;li&gt;Role-based access control&lt;/li&gt; &#xA;   &lt;li&gt;Document permission inheritance from connected sources&lt;/li&gt; &#xA;   &lt;li&gt;Usage analytics and query history accessible to admins&lt;/li&gt; &#xA;   &lt;li&gt;Whitelabeling&lt;/li&gt; &#xA;   &lt;li&gt;API key authentication&lt;/li&gt; &#xA;   &lt;li&gt;Encryption of secrets&lt;/li&gt; &#xA;   &lt;li&gt;Any many more! Checkout &lt;a href=&#34;https://www.onyx.app/&#34;&gt;our website&lt;/a&gt; for the latest.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To try the Onyx Enterprise Edition:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Checkout our &lt;a href=&#34;https://cloud.onyx.app/signup&#34;&gt;Cloud product&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;For self-hosting, contact us at &lt;a href=&#34;mailto:founders@onyx.app&#34;&gt;founders@onyx.app&lt;/a&gt; or book a call with us on our &lt;a href=&#34;https://cal.com/team/danswer/founders&#34;&gt;Cal&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;üí° Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Looking to contribute? Please check out the &lt;a href=&#34;https://raw.githubusercontent.com/onyx-dot-app/onyx/main/CONTRIBUTING.md&#34;&gt;Contribution Guide&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;‚≠êStar History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#onyx-dot-app/onyx&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=onyx-dot-app/onyx&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>