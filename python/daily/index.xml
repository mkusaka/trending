<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-08-29T01:38:35Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Zulko/moviepy</title>
    <updated>2023-08-29T01:38:35Z</updated>
    <id>tag:github.com,2023-08-29:/Zulko/moviepy</id>
    <link href="https://github.com/Zulko/moviepy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Video editing with Python&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MoviePy&lt;/h1&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://badge.fury.io/py/moviepy.svg&#34;&gt;https://badge.fury.io/py/moviepy.svg&lt;/a&gt; :target: PyPI_ :alt: MoviePy page on the Python Package Index .. image:: &lt;a href=&#34;https://img.shields.io/gitter/room/movie-py/gitter?color=46BC99&amp;amp;logo=gitter&#34;&gt;https://img.shields.io/gitter/room/movie-py/gitter?color=46BC99&amp;amp;logo=gitter&lt;/a&gt; :target: Gitter_ :alt: Discuss MoviePy on Gitter .. image:: &lt;a href=&#34;https://img.shields.io/github/actions/workflow/status/Zulko/moviepy/test_suite.yml?logo=github&#34;&gt;https://img.shields.io/github/actions/workflow/status/Zulko/moviepy/test_suite.yml?logo=github&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/Zulko/moviepy/actions/workflows/test_suite.yml&#34;&gt;https://github.com/Zulko/moviepy/actions/workflows/test_suite.yml&lt;/a&gt; :alt: Build status on gh-actions .. image:: &lt;a href=&#34;https://img.shields.io/coveralls/github/Zulko/moviepy/master?logo=coveralls&#34;&gt;https://img.shields.io/coveralls/github/Zulko/moviepy/master?logo=coveralls&lt;/a&gt; :target: &lt;a href=&#34;https://coveralls.io/github/Zulko/moviepy?branch=master&#34;&gt;https://coveralls.io/github/Zulko/moviepy?branch=master&lt;/a&gt; :alt: Code coverage from coveralls.io&lt;/p&gt; &#xA;&lt;p&gt;MoviePy (full documentation_) is a Python library for video editing: cutting, concatenations, title insertions, video compositing (a.k.a. non-linear editing), video processing, and creation of custom effects. See the gallery_ for some examples of use.&lt;/p&gt; &#xA;&lt;p&gt;MoviePy can read and write all the most common audio and video formats, including GIF, and runs on Windows/Mac/Linux, with Python 3.6+. Here it is in action in an IPython notebook:&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://raw.githubusercontent.com/Zulko/moviepy/master/docs/demo_preview.jpeg&#34;&gt;https://raw.githubusercontent.com/Zulko/moviepy/master/docs/demo_preview.jpeg&lt;/a&gt; :alt: [logo] :align: center&lt;/p&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;In this example we open a video file, select the subclip between t=50s and t=60s, add a title at the center of the screen, and write the result to a new file:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: python&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from moviepy import *&#xA;&#xA;video = VideoFileClip(&#34;myHolidays.mp4&#34;).subclip(50,60)&#xA;&#xA;# Make the text. Many more options are available.&#xA;txt_clip = ( TextClip(&#34;My Holidays 2013&#34;,fontsize=70,color=&#39;white&#39;)&#xA;             .with_position(&#39;center&#39;)&#xA;             .with_duration(10) )&#xA;&#xA;result = CompositeVideoClip([video, txt_clip]) # Overlay text on video&#xA;result.write_videofile(&#34;myHolidays_edited.webm&#34;,fps=25) # Many options...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; This example uses the new 2.x API, for MoviePy 1.0.3, currently on PyPI, see &lt;code&gt;this snippet &amp;lt;https://gist.github.com/Zulko/57e6e50debef1834fb9b60700b1b9f99&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &#xA;&lt;h2&gt;Maintainers wanted!&lt;/h2&gt; &#xA;&lt;p&gt;As there are more and more people seeking support (270 open issues as of Jan. 2021!) and all the MoviePy maintainers seem busy, we&#39;d love to hear about developers interested in giving a hand and solving some of the issues (especially the ones that affect you) or reviewing pull requests. Open an issue or contact us directly if you are interested. Thanks!&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;MoviePy depends on the Python modules NumPy_, Imageio_, Decorator_, and Proglog_, which will be automatically installed during MoviePy&#39;s installation. The software FFMPEG should be automatically downloaded/installed (by imageio) during your first use of MoviePy (installation will take a few seconds). If you want to use a specific version of FFMPEG, follow the instructions in &lt;code&gt;config_defaults.py&lt;/code&gt;. In case of trouble, provide feedback.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Installation by hand:&lt;/strong&gt; download the sources, either from PyPI_ or, if you want the development version, from GitHub_, unzip everything into one folder, open a terminal and type:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: bash&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ (sudo) python setup.py install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Installation with pip:&lt;/strong&gt; if you have &lt;code&gt;pip&lt;/code&gt; installed, just type this in a terminal:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: bash&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ (sudo) pip install moviepy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you have neither &lt;code&gt;setuptools&lt;/code&gt; nor &lt;code&gt;ez_setup&lt;/code&gt; installed, the command above will fail. In this case type this before installing:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: bash&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ (sudo) pip install setuptools&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Optional but useful dependencies&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;You can install ``moviepy`` with all dependencies via:&#xA;&#xA;.. code:: bash&#xA;&#xA;    $ (sudo) pip install moviepy[optional]&#xA;&#xA;ImageMagick_ is not strictly required, but needed if you want to incorporate texts. It can also be used as a backend for GIFs, though you can also create GIFs with MoviePy without ImageMagick.&#xA;&#xA;Once you have installed ImageMagick, MoviePy will try to autodetect the path to its executable. If it fails, you can still configure it by setting environment variables (see the documentation).&#xA;&#xA;PyGame_ is needed for video and sound previews (not relevant if you intend to work with MoviePy on a server but essential for advanced video editing by hand).&#xA;&#xA;For advanced image processing, you will need one or several of the following packages:&#xA;&#xA;- The Python Imaging Library (PIL) or, even better, its branch Pillow_.&#xA;- Scipy_ (for tracking, segmenting, etc.) can be used to resize video clips if PIL and OpenCV are not installed.&#xA;- `Scikit Image`_ may be needed for some advanced image manipulation.&#xA;- `OpenCV 2.4.6`_ or a more recent version (one that provides the package ``cv2``) may be needed for some advanced image manipulation.&#xA;- `Matplotlib`_&#xA;&#xA;For instance, using the method ``clip.resize`` requires that at least one of Scipy, PIL, Pillow or OpenCV is installed.&#xA;&#xA;&#xA;Documentation&#xA;-------------&#xA;&#xA;Building the documentation has additional dependencies that require installation.&#xA;&#xA;.. code:: bash&#xA;&#xA;    $ (sudo) pip install moviepy[doc]&#xA;&#xA;The documentation can be generated and viewed via:&#xA;&#xA;.. code:: bash&#xA;&#xA;    $ python setup.py build_docs&#xA;&#xA;You can pass additional arguments to the documentation build, such as clean build:&#xA;&#xA;.. code:: bash&#xA;&#xA;    $ python setup.py build_docs -E&#xA;&#xA;More information is available from the `Sphinx`_ documentation.&#xA;&#xA;New in 1.0.0: Progress bars and messages with Proglog&#xA;-------------------------------------------------------&#xA;&#xA;Non-backwards-compatible changes were introduced in 1.0.0 to&#xA;manage progress bars and messages using&#xA;`Proglog &amp;lt;https://github.com/Edinburgh-Genome-Foundry/Proglog&amp;gt;`_, which&#xA;enables to display nice progress bars in the console as well as in&#xA;a Jupyter notebook or any user interface, like a website.&#xA;&#xA;To display notebook friendly progress bars, first install IPyWidgets:&#xA;&#xA;.. code::&#xA;&#xA;    sudo pip install ipywidgets&#xA;    sudo jupyter nbextension enable --py --sys-prefix widgetsnbextension&#xA;&#xA;Then at the beginning of your notebook enter:&#xA;&#xA;.. code:: python&#xA;&#xA;    import proglog&#xA;    proglog.notebook()&#xA;&#xA;Have a look at the Proglog project page for more options.&#xA;&#xA;Contribute&#xA;----------&#xA;&#xA;MoviePy is open-source software originally written by Zulko_ and released under the MIT licence. The project is hosted on GitHub_, where everyone is welcome to contribute, ask for help or simply give feedback. Please read our `Contributing Guidelines`_ for more information about how to contribute!&#xA;&#xA;You can also discuss the project on Reddit_ or Gitter_. These are preferred over GitHub issues for usage questions and examples.&#xA;&#xA;&#xA;Maintainers&#xA;-----------&#xA;&#xA;- Zulko_ (owner)&#xA;- `@tburrows13`_&#xA;- `@mgaitan`_&#xA;- `@earney`_&#xA;- `@mbeacom`_&#xA;- `@overdrivr`_&#xA;- `@keikoro`_&#xA;- `@ryanfox`_&#xA;- `@mondeja`_&#xA;&#xA;&#xA;.. MoviePy links&#xA;.. _gallery: https://zulko.github.io/moviepy/gallery.html&#xA;.. _documentation: https://zulko.github.io/moviepy/&#xA;.. _`download MoviePy`: https://github.com/Zulko/moviepy&#xA;.. _`Label Wiki`: https://github.com/Zulko/moviepy/wiki/Label-Wiki&#xA;.. _Contributing Guidelines: https://github.com/Zulko/moviepy/blob/master/CONTRIBUTING.md&#xA;&#xA;.. Websites, Platforms&#xA;.. _Reddit: https://www.reddit.com/r/moviepy/&#xA;.. _PyPI: https://pypi.python.org/pypi/moviepy&#xA;.. _GitHub: https://github.com/Zulko/moviepy&#xA;.. _Gitter: https://gitter.im/movie-py/Lobby&#xA;&#xA;.. Software, Tools, Libraries&#xA;.. _Pillow: https://pillow.readthedocs.org/en/latest/&#xA;.. _Scipy: https://www.scipy.org/&#xA;.. _`OpenCV 2.4.6`: https://github.com/skvark/opencv-python&#xA;.. _Pygame: https://www.pygame.org/download.shtml&#xA;.. _Numpy: https://www.scipy.org/install.html&#xA;.. _imageio: https://imageio.github.io/&#xA;.. _`Scikit Image`: https://scikit-image.org/docs/stable/install.html&#xA;.. _Decorator: https://pypi.python.org/pypi/decorator&#xA;.. _proglog: https://github.com/Edinburgh-Genome-Foundry/Proglog&#xA;.. _ffmpeg: https://www.ffmpeg.org/download.html&#xA;.. _ImageMagick: https://www.imagemagick.org/script/index.php&#xA;.. _`Matplotlib`: https://matplotlib.org/&#xA;.. _`Sphinx`: https://www.sphinx-doc.org/en/master/setuptools.html&#xA;&#xA;.. People&#xA;.. _Zulko: https://github.com/Zulko&#xA;.. _`@mgaitan`: https://github.com/mgaitan&#xA;.. _`@tburrows13`: https://github.com/tburrows13&#xA;.. _`@earney`: https://github.com/earney&#xA;.. _`@mbeacom`: https://github.com/mbeacom&#xA;.. _`@overdrivr`: https://github.com/overdrivr&#xA;.. _`@keikoro`: https://github.com/keikoro&#xA;.. _`@ryanfox`: https://github.com/ryanfox&#xA;.. _`@mondeja`: https://github.com/mondeja&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>RadeonOpenCompute/ROCm</title>
    <updated>2023-08-29T01:38:35Z</updated>
    <id>tag:github.com,2023-08-29:/RadeonOpenCompute/ROCm</id>
    <link href="https://github.com/RadeonOpenCompute/ROCm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AMD ROCm™ Platform - GitHub Home&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AMD ROCm™ Platform&lt;/h1&gt; &#xA;&lt;p&gt;ROCm is an open-source stack, composed primarily of open-source software (OSS), designed for graphics processing unit (GPU) computation. ROCm consists of a collection of drivers, development tools, and APIs that enable GPU programming from low-level kernel to end-user applications.&lt;/p&gt; &#xA;&lt;p&gt;With ROCm, you can customize your GPU software to meet your specific needs. You can develop, collaborate, test, and deploy your applications in a free, open-source, integrated, and secure software ecosystem. ROCm is particularly well-suited to GPU-accelerated high-performance computing (HPC), artificial intelligence (AI), scientific computing, and computer aided design (CAD).&lt;/p&gt; &#xA;&lt;p&gt;ROCm is powered by AMD’s &lt;a href=&#34;https://github.com/ROCm-Developer-Tools/HIP&#34;&gt;Heterogeneous-computing Interface for Portability (HIP)&lt;/a&gt;, an OSS C++ GPU programming environment and its corresponding runtime. HIP allows ROCm developers to create portable applications on different platforms by deploying code on a range of platforms, from dedicated gaming GPUs to exascale HPC clusters.&lt;/p&gt; &#xA;&lt;p&gt;ROCm supports programming models, such as OpenMP and OpenCL, and includes all necessary OSS compilers, debuggers, and libraries. ROCm is fully integrated into machine learning (ML) frameworks, such as PyTorch and TensorFlow.&lt;/p&gt; &#xA;&lt;h2&gt;ROCm Documentation&lt;/h2&gt; &#xA;&lt;p&gt;The ROCm Documentation site is &lt;a href=&#34;https://rocm.docs.amd.com&#34;&gt;rocm.docs.amd.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Source code for the documentation is located in the docs folder of most repositories that are part of ROCm.&lt;/p&gt; &#xA;&lt;p&gt;This repository contains the manifest file for ROCm releases, changelogs, and release information. The file &lt;code&gt;default.xml&lt;/code&gt; contains information for all repositories and the associated commit used to build the current ROCm release.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;default.xml&lt;/code&gt; file uses the repo Manifest Format.&lt;/p&gt; &#xA;&lt;p&gt;The develop branch of this repository contains content for the next ROCm release.&lt;/p&gt; &#xA;&lt;h3&gt;How to build documentation via Sphinx&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd docs&#xA;&#xA;pip3 install -r sphinx/requirements.txt&#xA;&#xA;python3 -m sphinx -T -E -b html -d _build/doctrees -D language=en . _build/html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Older ROCm Releases&lt;/h2&gt; &#xA;&lt;p&gt;For release information for older ROCm releases, refer to &lt;a href=&#34;https://raw.githubusercontent.com/RadeonOpenCompute/ROCm/develop/CHANGELOG.md&#34;&gt;&lt;code&gt;CHANGELOG.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Pythagora-io/gpt-pilot</title>
    <updated>2023-08-29T01:38:35Z</updated>
    <id>tag:github.com,2023-08-29:/Pythagora-io/gpt-pilot</id>
    <link href="https://github.com/Pythagora-io/gpt-pilot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PoC for a scalable dev tool that writes entire apps from scratch while the developer oversees the implementation&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;🧑‍✈️ GPT PILOT&lt;/h1&gt; &#xA;&lt;h3&gt;GPT Pilot codes the entire app as you oversee the code being written&lt;/h3&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;This is a research project to see how can GPT-4 be utilized to generate fully working, production-ready, apps. &lt;strong&gt;The main idea is that AI can write most of the code for an app (maybe 95%) but for the rest 5%, a developer is and will be needed until we get full AGI&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;I&#39;ve broken down the idea behind GPT Pilot and how it works in the following blog posts:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://blog.pythagora.ai/2023/08/23/430/&#34;&gt;[Part 1/3] High-level concepts + GPT Pilot workflow until the coding part&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;em&gt;[Part 2/3] GPT Pilot coding workflow (COMING UP)&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;em&gt;[Part 3/3] Other important concepts and future plans (COMING UP)&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/#-examples&#34;&gt;👉 Examples of apps written by GPT Pilot 👈&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Pythagora-io/gpt-pilot/assets/10895136/0495631b-511e-451b-93d5-8a42acf22d3d&#34;&gt;https://github.com/Pythagora-io/gpt-pilot/assets/10895136/0495631b-511e-451b-93d5-8a42acf22d3d&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Main pillars of GPT Pilot:&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;For AI to create a fully working app, &lt;strong&gt;a developer needs to be involved&lt;/strong&gt; in the process of app creation. They need to be able to change the code at any moment and GPT Pilot needs to continue working with those changes (eg. add an API key or fix an issue if an AI gets stuck) &lt;br&gt;&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;The app needs to be written step by step as a developer would write it&lt;/strong&gt; - Let&#39;s say you want to create a simple app and you know everything you need to code and have the entire architecture in your head. Even then, you won&#39;t code it out entirely, then run it for the first time and debug all the issues at once. Rather, you will implement something simple, like add routes, run it, see how it works, and then move on to the next task. This way, you can debug issues as they arise. The same should be in the case when AI codes. It will make mistakes for sure so in order for it to have an easier time debugging issues and for the developer to understand what is happening, the AI shouldn&#39;t just spit out the entire codebase at once. Rather, the app should be developed step by step just like a developer would code it - eg. setup routes, add database connection, etc. &lt;br&gt;&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;The approach needs to be scalable&lt;/strong&gt; so that AI can create a production ready app &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Context rewinding&lt;/strong&gt; - for solving each development task, the context size of the first message to the LLM has to be relatively the same. For example, the context size of the first LLM message while implementing development task #5 has to be more or less the same as the first message while developing task #50. Because of this, the conversation needs to be rewound to the first message upon each task. &lt;a href=&#34;https://blogpythagora.files.wordpress.com/2023/08/pythagora-product-development-frame-3-1.jpg?w=1714&#34;&gt;See the diagram here&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Recursive conversations&lt;/strong&gt; are LLM conversations that are set up in a way that they can be used “recursively”. For example, if GPT Pilot detects an error, it needs to debug it but let’s say that, during the debugging process, another error happens. Then, GPT Pilot needs to stop debugging the first issue, fix the second one, and then get back to fixing the first issue. This is a very important concept that, I believe, needs to work to make AI build large and scalable apps by itself. It works by rewinding the context and explaining each error in the recursion separately. Once the deepest level error is fixed, we move up in the recursion and continue fixing that error. We do this until the entire recursion is completed.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;TDD (Test Driven Development)&lt;/strong&gt; - for GPT Pilot to be able to scale the codebase, it will need to be able to create new code without breaking previously written code. There is no better way to do this than working with TDD methodology. For each code that GPT Pilot writes, it needs to write tests that check if the code works as intended so that whenever new changes are made, all previous tests can be run.&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The idea is that AI won&#39;t be able to (at least in the near future) create apps from scratch without the developer being involved. That&#39;s why we created an interactive tool that generates code but also requires the developer to check each step so that they can understand what&#39;s going on and so that the AI can have a better overview of the entire codebase.&lt;/p&gt; &#xA;&lt;p&gt;Obviously, it still can&#39;t create any production-ready app but the general concept of how this could work is there.&lt;/p&gt; &#xA;&lt;h1&gt;🚦How to start using gpt-pilot?&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repo&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;cd gpt-pilot&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;python -m venv pilot-env&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;source pilot-env/bin/activate&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;cd pilot&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;mv .env.example .env&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Add your OpenAI API key and the database info to the &lt;code&gt;.env&lt;/code&gt; file&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;python main.py&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;After, this, you can just follow the instructions in the terminal.&lt;/p&gt; &#xA;&lt;p&gt;All generated code will be stored in the folder &lt;code&gt;workspace&lt;/code&gt; inside the folder named after the app name you enter upon starting the pilot. &lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;🧑‍💻️ Other arguments&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;continue working on an existing app&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py app_id=&amp;lt;ID_OF_THE_APP&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;continue working on an existing app from a specific step&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py app_id=&amp;lt;ID_OF_THE_APP&amp;gt; step=&amp;lt;STEP_FROM_CONST_COMMON&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;continue working on an existing app from a specific development step&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py app_id=&amp;lt;ID_OF_THE_APP&amp;gt; skip_until_dev_step=&amp;lt;DEV_STEP&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is basically the same as &lt;code&gt;step&lt;/code&gt; but during the actual development process. If you want to play around with gpt-pilot, this is likely the flag you will often use &lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;🔎 Examples&lt;/h1&gt; &#xA;&lt;p&gt;Here are a couple of example apps GPT Pilot created by itself:&lt;/p&gt; &#xA;&lt;h3&gt;Real-time chat app&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;💬 Prompt: &lt;code&gt;A simple chat app with real time communication&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;▶️ &lt;a href=&#34;https://youtu.be/bUj9DbMRYhA&#34;&gt;Video of the app creation process&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;💻️ &lt;a href=&#34;https://github.com/Pythagora-io/gpt-pilot-chat-app-demo&#34;&gt;GitHub repo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;img src=&#34;https://github.com/Pythagora-io/gpt-pilot/assets/10895136/85bc705c-be88-4ca1-9a3b-033700b97a22&#34; alt=&#34;gpt-pilot demo chat app&#34; width=&#34;500px&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;Markdown editor&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;💬 Prompt: &lt;code&gt;Build a simple markdown editor using HTML, CSS, and JavaScript. Allow users to input markdown text and display the formatted output in real-time.&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;▶️ &lt;a href=&#34;https://youtu.be/uZeA1iX9dgg&#34;&gt;Video of the app creation process&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;💻️ &lt;a href=&#34;https://github.com/Pythagora-io/gpt-pilot-demo-markdown-editor.git&#34;&gt;GitHub repo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;img src=&#34;https://github.com/Pythagora-io/gpt-pilot/assets/10895136/dbe1ccc3-b126-4df0-bddb-a524d6a386a8&#34; alt=&#34;gpt-pilot demo markdown editor&#34; width=&#34;500px&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;Timer app&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;💬 Prompt: &lt;code&gt;Create a simple timer app using HTML, CSS, and JavaScript that allows users to set a countdown timer and receive an alert when the time is up.&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;▶️ &lt;a href=&#34;https://youtu.be/CMN3W18zfiE&#34;&gt;Video of the app creation process&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;💻️ &lt;a href=&#34;https://github.com/Pythagora-io/gpt-pilot-timer-app-demo&#34;&gt;GitHub repo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;img src=&#34;https://github.com/Pythagora-io/gpt-pilot/assets/10895136/93bed40b-b769-4c8b-b16d-b80fb6fc73e0&#34; alt=&#34;gpt-pilot demo markdown editor&#34; width=&#34;500px&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;🏗 How GPT Pilot works?&lt;/h1&gt; &#xA;&lt;p&gt;Here are the steps GPT Pilot takes to create an app:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Pythagora-io/gpt-pilot/assets/10895136/d89ba1d4-1208-4b7f-b3d4-76e3ccea584e&#34; alt=&#34;GPT Pilot workflow&#34;&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;You enter the app name and the description&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Product Owner agent&lt;/strong&gt; asks a couple of questions to understand the requirements better&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Product Owner agent&lt;/strong&gt; writes user stories and asks you if they are all correct (this helps it create code later on)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Architect agent&lt;/strong&gt; writes up technologies that will be used for the app&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;DevOps agent&lt;/strong&gt; checks if all technologies are installed on the machine and installs them if they are not&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Tech Lead agent&lt;/strong&gt; writes up development tasks that Developer will need to implement. This is an important part because, for each step, Tech Lead needs to specify how the user (real world developer) can review if the task is done (eg. open localhost:3000 and do something)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Developer agent&lt;/strong&gt; takes each task and writes up what needs to be done to implement it. The description is in human readable form.&lt;/li&gt; &#xA; &lt;li&gt;Finally, &lt;strong&gt;Code Monkey agent&lt;/strong&gt; takes the Developer&#39;s description and the currently implement file and implements the changes into it. We realized this works much better than giving it to Developer right away to implement changes.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Pythagora-io/gpt-pilot/assets/10895136/54a8ec24-a2ea-43a6-a494-03139d4e43f5&#34; alt=&#34;GPT Pilot Coding Workflow&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;🕴How&#39;s GPT Pilot different from &lt;em&gt;Smol developer&lt;/em&gt; and &lt;em&gt;GPT engineer&lt;/em&gt;?&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Human developer is involved throughout the process&lt;/strong&gt; - I don&#39;t think that AI can&#39;t (at least in the near future) create apps without a developer being involved. Also, I think it&#39;s hard for a developer to get into a big codebase and try debugging it. That&#39;s why my idea was for AI to develop the app step by step where each step is reviewed by the developer. If you want to change some code yourself, you can just change it and GPT Pilot will continue developing on top of those changes. &lt;br&gt;&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Continuous development loops&lt;/strong&gt; - The goal behind this project was to see how we can create recursive conversations with GPT so that it can debug any issue and implement any feature. For example, after the app is generated, you can always add more instructions about what you want to implement or debug. I wanted to see if this can be so flexible that, regardless of the app&#39;s size, it can just iterate and build bigger and bigger apps &lt;br&gt;&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Auto debugging&lt;/strong&gt; - when it detects an error, it debugs it by itself. I still haven&#39;t implemented writing automated tests which should make this fully autonomous but for now, you can input the error that&#39;s happening (eg. within a UI) and GPT Pilot will debug it from there. The plan is to make it write automated tests in Cypress as well so that it can test it by itself and debug without the developer&#39;s explanation.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;🍻 Contributing&lt;/h1&gt; &#xA;&lt;p&gt;If you are interested in contributing to GPT Pilot, I would be more than happy to have you on board but also help you get started. Feel free to ping &lt;a href=&#34;mailto:zvonimir@pythagora.ai&#34;&gt;zvonimir@pythagora.ai&lt;/a&gt; and I&#39;ll help you get started.&lt;/p&gt; &#xA;&lt;h2&gt;🔬️ Research&lt;/h2&gt; &#xA;&lt;p&gt;Since this is a research project, there are many areas that need to be researched on both practical and theoretical levels. We&#39;re happy to hear how can the entire GPT Pilot concept be improved. For example, maybe it would work better if we structured functional requirements differently or maybe technical requirements need to be specified in a different way.&lt;/p&gt; &#xA;&lt;h2&gt;🖥 Development&lt;/h2&gt; &#xA;&lt;p&gt;Other than the research, GPT Pilot needs to be debugged to work in different scenarios. For example, we realized that the quality of the code generated is very sensitive to the size of the development task. When the task is too broad, the code has too many bugs that are hard to fix but when the development task is too narrow, GPT also seems to struggle in getting the task implemented into the existing code.&lt;/p&gt; &#xA;&lt;h1&gt;🔗 Connect with us&lt;/h1&gt; &#xA;&lt;p&gt;🌟 As an open source tool, it would mean the world to us if you starred the GPT-pilot repo 🌟&lt;/p&gt; &#xA;&lt;p&gt;💬 Join &lt;a href=&#34;https://discord.gg/FWnRZdCb&#34;&gt;the Discord server&lt;/a&gt; to get in touch. &lt;br&gt;&lt;br&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;</summary>
  </entry>
</feed>