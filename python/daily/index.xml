<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-01-20T01:38:43Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ZHO-ZHO-ZHO/ComfyUI-PhotoMaker</title>
    <updated>2024-01-20T01:38:43Z</updated>
    <id>tag:github.com,2024-01-20:/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker</id>
    <link href="https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Unofficial implementation of PhotoMaker for ComfyUI&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/15f9ebaf-b205-4cbd-928e-eca1a0cacb7f&#34; alt=&#34;PNSTYLE_23png&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;ComfyUI PhotoMaker&lt;/h1&gt; &#xA;&lt;p&gt;Unofficial implementation of &lt;a href=&#34;https://github.com/TencentARC/PhotoMaker&#34;&gt;PhotoMaker&lt;/a&gt; for ComfyUI&lt;/p&gt; &#xA;&lt;!--&#xA;![Dingtalk_20240117150313](https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/da664c2b-cb30-44e2-85ec-d6070fcfa8f0)&#xA;&#xA;&#xA;![Dingtalk_20240117161736](https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/07c924ab-3ee5-4919-87bc-ac49c28914f1)&#xA;---&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/0292bf55-21b7-4025-bc27-7e3e7ccc2af3&#34; alt=&#34;Dingtalk_20240118163802&#34;&gt;&lt;/p&gt; &#xA;&lt;!--&#xA;![Dingtalk_20240118163953](https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/9b8a665f-6c9c-441c-aa81-fc56423de89e)&#xA;---&gt; &#xA;&lt;p&gt;å•å¼ å‚è€ƒä¸å¤šå¼ å‚è€ƒçš„å¯¹æ¯”ï¼š&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/e7bccd61-7855-46c2-a6bc-31b34e742927&#34; alt=&#34;Dingtalk_20240117201650&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/6bbcfcf9-9027-4c6f-9be1-750971b7848c&#34; alt=&#34;Dingtalk_20240117201201&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;é¡¹ç›®ä»‹ç» | Info&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;æ¥è‡ªå¯¹&lt;a href=&#34;https://github.com/TencentARC/PhotoMaker&#34;&gt;PhotoMaker&lt;/a&gt;çš„éå®˜æ–¹å®ç°&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ç‰ˆæœ¬ï¼šV2.5 æ”¯æŒloraã€æ”¯æŒå¤šæ‰¹æ¬¡ã€æ”¯æŒé€šç”¨çš„styler&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!--&#xA;èŠ‚ç‚¹æ‹†åˆ† + æ”¯æŒæœ¬åœ°æ¨¡å‹ + æ”¯æŒè‡ªå®šä¹‰å°ºå¯¸ +æé€Ÿ3å€ + æ”¯æŒå¤šå›¾ç›´æ¥è¾“å…¥&#xA;---&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/d067fc21-3b51-44bc-b76e-9351a7f6966a&#34; alt=&#34;Dingtalk_20240119194547&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;è§†é¢‘æ¼”ç¤º&lt;/h2&gt; &#xA;&lt;!--&#xA;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/8718a70e-a5d7-463b-b36e-de1ffefad9ed&#xA;---&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/d58af6e7-d0f3-41ff-ab33-195cb6d66e9e&#34;&gt;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/d58af6e7-d0f3-41ff-ab33-195cb6d66e9e&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;èŠ‚ç‚¹è¯´æ˜ | Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;åŸºç¡€æ¨¡å‹åŠ è½½ | base model loader&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ğŸ“·Base Model Loader from hubğŸ¤—ï¼šæ”¯æŒä» huggingface hub è‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼Œè¾“å…¥æ¨¡å‹åç§°ï¼ˆå¦‚ï¼šSG161222/RealVisXL_V3.0ï¼‰å³å¯&lt;/li&gt; &#xA;   &lt;li&gt;ğŸ“·Base Model Loader locallyï¼šæ”¯æŒåŠ è½½æœ¬åœ°æ¨¡å‹ï¼ˆéœ€ SDXL ç³»åˆ—æ¨¡å‹ï¼‰&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;PhotoMaker Adapter æ¨¡å‹åŠ è½½ | PhotoMaker Adapter Loader&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ğŸ“·PhotoMaker Adapter Loader from hubğŸ¤—ï¼šæ”¯æŒä» huggingface hub è‡ªåŠ¨ä¸‹è½½æ¨¡å‹&lt;/li&gt; &#xA;   &lt;li&gt;ğŸ“·PhotoMaker Adapter Loader locallyï¼šæ”¯æŒåŠ è½½æœ¬åœ°æ¨¡å‹ï¼Œè¾“å…¥ photomaker-v1.bin æ¨¡å‹æ‰€åœ¨è·¯å¾„å³å¯&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;å‚è€ƒå›¾é¢„å¤„ç† | ğŸ“·Ref Image Preprocessing&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ç›´æ¥æ¨¡å¼ | Direct_inputï¼šæ¥å…¥å•/å¤šå¼ å›¾åƒï¼ˆéå¿…è¦é¡¹ï¼‰&lt;/li&gt; &#xA;   &lt;li&gt;è·¯å¾„æ¨¡å¼ | Path_inputï¼šè‡ªåŠ¨è¯»å–è·¯å¾„ä¸­çš„æ‰€æœ‰å›¾åƒ&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Loraæ¨¡å‹åŠ è½½ | ğŸ“·LoRALoader ğŸ†•&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;æ”¯æŒåŠ è½½æœ¬åœ° lora æ¨¡å‹&lt;/li&gt; &#xA;   &lt;li&gt;æ”¯æŒæƒé‡è°ƒèŠ‚&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;æç¤ºè¯ + é£æ ¼ | ğŸ“·Prompt_Styler ğŸ†•&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ä¸å„ç§æç¤ºè¯ï¼ˆæ–‡æœ¬ï¼‰è¾“å…¥ï¼ˆå¦‚è‚–åƒå¤§å¸ˆç­‰ï¼‰ã€stylerå…¼å®¹&lt;/li&gt; &#xA;   &lt;li&gt;promptã€negativeï¼šæ­£è´Ÿæç¤ºè¯&lt;/li&gt; &#xA;   &lt;li&gt;æ”¯æŒæƒé‡è°ƒèŠ‚&lt;/li&gt; &#xA;   &lt;li&gt;style_nameï¼šæ”¯æŒå®˜æ–¹æä¾›çš„10ç§é£æ ¼ &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;(No style)&lt;/li&gt; &#xA;     &lt;li&gt;Cinematic&lt;/li&gt; &#xA;     &lt;li&gt;Disney Charactor&lt;/li&gt; &#xA;     &lt;li&gt;Digital Art&lt;/li&gt; &#xA;     &lt;li&gt;Photographic (Default)&lt;/li&gt; &#xA;     &lt;li&gt;Fantasy art&lt;/li&gt; &#xA;     &lt;li&gt;Neonpunk&lt;/li&gt; &#xA;     &lt;li&gt;Enhance&lt;/li&gt; &#xA;     &lt;li&gt;Comic book&lt;/li&gt; &#xA;     &lt;li&gt;Lowpoly&lt;/li&gt; &#xA;     &lt;li&gt;Line art&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;PhotoMaker ç”Ÿæˆ | ğŸ“·PhotoMaker Generation ğŸ†•&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;pipeï¼šæ¥å…¥æ¨¡å‹&lt;/li&gt; &#xA;   &lt;li&gt;pil_imageï¼šæ¥å…¥é¢„å¤„ç†å›¾åƒ&lt;/li&gt; &#xA;   &lt;li&gt;positivetã€negativeï¼šæ­£è´Ÿæç¤ºè¯&lt;/li&gt; &#xA;   &lt;li&gt;batch_sizeï¼šç”Ÿæˆæ•°é‡&lt;/li&gt; &#xA;   &lt;li&gt;style_strength_ratioï¼šé£æ ¼æ··åˆå¼ºåº¦ï¼ˆé«˜äº30æŒ‰30è®¡ç®—ï¼‰&lt;/li&gt; &#xA;   &lt;li&gt;stepï¼šæ­¥æ•°ï¼Œå®˜æ–¹é»˜è®¤50æ­¥ï¼Œä½†æ¯•ç«Ÿæ˜¯åŸºäºSDXLæ¨¡å‹ï¼Œæˆ‘å®æµ‹ä¸‹æ¥30æ­¥è¶³å¤Ÿäº†&lt;/li&gt; &#xA;   &lt;li&gt;guidance_scaleï¼šæç¤ºè¯ç›¸å…³åº¦ï¼Œä¸€èˆ¬é»˜è®¤ä¸º5&lt;/li&gt; &#xA;   &lt;li&gt;widthã€heightï¼šå°ºå¯¸è®¾ç½®ï¼ˆéœ€1024ç»´åº¦ï¼‰&lt;/li&gt; &#xA;   &lt;li&gt;seedï¼šç§å­&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!--&#xA;- base_model_pathï¼šæ”¯æŒè¾“å…¥huggingfaceæ¨¡å‹åç§°è‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚ï¼šSG161222/RealVisXL_V3.0ï¼‰&#xA;- ref_images_pathï¼šæ”¯æŒæ‰¹é‡è¯»å–å‚è€ƒå›¾åƒï¼Œæ”¾å…¥æ–‡ä»¶å¤¹ä¸­å³å¯&#xA;- ptomptã€negativeï¼šæ­£è´Ÿæç¤ºè¯&#xA;- style_nameï¼šæ”¯æŒå®˜æ–¹æä¾›çš„10ç§é£æ ¼&#xA;    - (No style)&#xA;    - Cinematic&#xA;    - Disney Charactor&#xA;    - Digital Art&#xA;    - Photographic (Default)&#xA;    - Fantasy art&#xA;    - Neonpunk&#xA;    - Enhance&#xA;    - Comic book&#xA;    - Lowpoly&#xA;    - Line art &#xA;- style_strength_ratioï¼šé£æ ¼æ··åˆå¼ºåº¦ï¼ˆé«˜äº30æŒ‰30è®¡ç®—ï¼‰&#xA;- stepï¼šæ­¥æ•°ï¼Œå®˜æ–¹é»˜è®¤50æ­¥ï¼Œä½†æ¯•ç«Ÿæ˜¯åŸºäºSDXLæ¨¡å‹ï¼Œæˆ‘å®æµ‹ä¸‹æ¥30æ­¥è¶³å¤Ÿäº†&#xA;- guidance_scaleï¼šæç¤ºè¯ç›¸å…³åº¦ï¼Œä¸€èˆ¬é»˜è®¤ä¸º5&#xA;- seedï¼šç§å­&#xA;---&gt; &#xA;&lt;h2&gt;é£æ ¼ | Styles&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/dc675478-47a0-456d-946b-0cf781aa4c28&#34; alt=&#34;PNSTYLE_2&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;å®‰è£… | Install&lt;/h2&gt; &#xA;&lt;!--&#xA;- æ¨èä½¿ç”¨ç®¡ç†å™¨ ComfyUI Manager å®‰è£…&#xA;---&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æ‰‹åŠ¨å®‰è£…ï¼š &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;&lt;code&gt;cd custom_nodes&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;git clone https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker.git&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;cd custom_nodes/ComfyUI-PhotoMaker&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;é‡å¯ ComfyUI&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;å·¥ä½œæµ | Workflows&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/raw/main/PhotoMaker%20Workflows/PhotoMaker_lora_batch%E3%80%90Zho%E3%80%91.json&#34;&gt;V2.5 lora + batch&lt;/a&gt; ğŸ†•&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/b862b89f-1609-43d9-84a1-5f11a2d1ab2d&#34; alt=&#34;Dingtalk_20240119202403&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/raw/main/PhotoMaker%20Workflows/PhotoMaker_lora_portrait_styler%E3%80%90Zho%E3%80%91.json&#34;&gt;V2.5 portraitmaster + styler + lora&lt;/a&gt; ğŸ†•&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/38e01035-139e-4a89-8982-6f7168684045&#34; alt=&#34;Dingtalk_20240119201125&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/raw/main/PhotoMaker%20Workflows/PhotoMaker_locally%E3%80%90Zho%E3%80%91.json&#34;&gt;V2.0 æœ¬åœ°æ¨¡å‹ locally&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/bf6a55ae-767e-4aaf-9f75-6f752bb5b530&#34; alt=&#34;QQæˆªå›¾20240118163432&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/raw/main/PhotoMaker%20Workflows/PhotoMaker_fromhub%E3%80%90Zho%E3%80%91.json&#34;&gt;V2.0 è‡ªåŠ¨ä¸‹è½½ huggingface hub&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/f645c1b7-2548-45fc-b388-0ebe62e2724d&#34; alt=&#34;QQæˆªå›¾20240118163252&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;æ›´æ–°æ—¥å¿—&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;20240119&lt;/p&gt; &lt;p&gt;æ›´æ–°ä¸º V2.5ï¼šæ”¯æŒloraã€æ”¯æŒè‡ªå®šä¹‰ç”Ÿæˆæ•°é‡ã€æ”¯æŒé€šç”¨æç¤ºè¯è¾“å…¥ï¼ˆæ–‡æœ¬ï¼‰å¦‚ï¼šstylerã€portraitmaterç­‰&lt;/p&gt; &lt;p&gt;æ–°å¢ lora + batchã€portraitmaster + styler + lora ä¸¤ä¸ªå·¥ä½œæµ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;20240119&lt;/p&gt; &lt;p&gt;æ›´æ–°ä¸º V2.1ï¼šå‚è€ƒå›¾æ”¹ä¸ºç›´æ¥è¾“å…¥/è·¯å¾„è¾“å…¥ä¸¤ç§æ–°æ¨¡å¼ï¼Œå…¶ä¸­ç›´æ¥è¾“å…¥æ”¯æŒå¤šå›¾&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/78595f2c-7f87-477a-9896-007dd24fe8c9&#34; alt=&#34;Dingtalk_20240119022341&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;20240118&lt;/p&gt; &lt;p&gt;æ›´æ–°ä¸º V2.0ï¼šèŠ‚ç‚¹æ‹†åˆ† + æ”¯æŒæœ¬åœ°æ¨¡å‹ + æ”¯æŒè‡ªå®šä¹‰å°ºå¯¸ +æé€Ÿ3å€&lt;/p&gt; &lt;p&gt;æ–°å¢æœ¬åœ°ã€hubåŠ è½½å·¥ä½œæµ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;20240117&lt;/p&gt; &lt;p&gt;æ–°å¢å•å¼ å›¾è¾“å…¥ï¼Œå¹¶ç»™å‡ºå¯¹æ¯”å›¾&lt;/p&gt; &lt;p&gt;ä¿®å¤bugï¼Œåˆç‰ˆä¸Šçº¿&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;20240116&lt;/p&gt; &lt;p&gt;åˆ›å»ºé¡¹ç›®&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;é€Ÿåº¦å®æµ‹ | Speed&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;V2.0 æé€Ÿ 3 å€&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;A100 50æ­¥ 7s&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;&lt;img src=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/4ae13ffc-c770-4551-bcb2-ce0b0ddc1367&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;V1.5&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;A100 50æ­¥ 23s&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;&lt;img src=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/df6eacda-2640-425b-b5ca-1ab5a8a61a66&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;v100 50æ­¥ 90s&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;&lt;img src=&#34;https://github.com/ZHO-ZHO-ZHO/ComfyUI-PhotoMaker/assets/140084057/973b8b6b-9195-4044-b75d-bd833bd6421e&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Stars&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#ZHO-ZHO-ZHO/ComfyUI-PhotoMaker&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=ZHO-ZHO-ZHO/ComfyUI-PhotoMaker&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;æ„Ÿè°¢&lt;a href=&#34;https://twitter.com/eviljer&#34;&gt;@erLin&lt;/a&gt;å¯¹ComfyUI çš„å›¾åƒå¼ é‡ Shape (N, H, W, C)çš„æé†’ï¼Œå¸®åŠ©æˆ‘æˆåŠŸä¿®å¤äº†bugï¼&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/TencentARC/PhotoMaker&#34;&gt;PhotoMaker&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>msd0pe-1/cve-maker</title>
    <updated>2024-01-20T01:38:43Z</updated>
    <id>tag:github.com,2024-01-20:/msd0pe-1/cve-maker</id>
    <link href="https://github.com/msd0pe-1/cve-maker" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Tool to find CVEs and Exploits.&lt;/p&gt;&lt;hr&gt;&lt;a target=&#34;_blank&#34; href=&#34;https://img.shields.io/badge/platform-linux-%23309874?style=flat&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/platform-linux-%23309874?style=flat&#34;&gt; &lt;/a&gt; &#xA;&lt;a target=&#34;_blank&#34; href=&#34;https://img.shields.io/badge/version-2.5.1-%2325c2a0?style=flat&amp;amp;color=%2325c2a0&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/version-2.5.1-%2325c2a0?style=flat&amp;amp;color=%2325c2a0&#34;&gt; &lt;/a&gt; &#xA;&lt;a href=&#34;https://www.python.org/&#34; rel=&#34;nofollow&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/python-3.11.2-%23ab6cd6?style=flat&#34;&gt; &lt;/a&gt; &#xA;&lt;a href=&#34;https://github.com/msd0pe-1/cve-maker-master/raw/master/LICENSE&#34; rel=&#34;nofollow&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/license-GPLv3-%231ac0c6?style=flat&#34;&gt; &lt;/a&gt; &#xA;&lt;h1&gt;CVE-MAKER&lt;/h1&gt; &#xA;&lt;p&gt;Use this software &lt;strong&gt;only for legal purposes&lt;/strong&gt;.&lt;br&gt; I am in no way responsible for your actions.&lt;br&gt; Use python 3.11.2&lt;br&gt; &lt;strong&gt;Made by msd0pe&lt;/strong&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;DESCRIPTION&lt;/h2&gt; &#xA;&lt;p&gt;cve-maker is a hub for finding CVEs and exploits. It is based on the official NIST, ExploitDB and Github databases. The tool makes it quick and easy to search for CVEs and their associated exploits. It is able to detect exploit compilation options. It can also be used to list the latest critical vulnerabilities.&lt;/p&gt; &#xA;&lt;h2&gt;USAGE&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/msd0pe-1/cve-maker/assets/47142249/931e2ac2-948f-4f88-a22a-03f751bf7273&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;INSTALLATION&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;From PIP:&lt;/em&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;apt-get install python3 python3-pip python3-dev git libssl-dev libffi-dev build-essential curl&#xA;pip3 install --upgrade pip&#xA;pip3 install cve-maker&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;em&gt;Or download the project:&lt;/em&gt;&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;apt-get install python3 python3-pip python3-dev git libssl-dev libffi-dev build-essential virtualenv curl&#xA;git clone https://github.com/msd0pe-1/cve-maker/&#xA;cd cve-maker&#xA;virtualenv -p python3 venv&#xA;source venv/bin/activate&#xA;pip3 install --upgrade pip&#xA;pip3 install .&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;# Launch:&#xA;python3 -m cve-maker&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;CONTRIBUTING&lt;/h2&gt; &#xA;&lt;p&gt;This project is in active development. Feel free to suggest a new feature or open a pull request !&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>apple/ml-aim</title>
    <updated>2024-01-20T01:38:43Z</updated>
    <id>tag:github.com,2024-01-20:/apple/ml-aim</id>
    <link href="https://github.com/apple/ml-aim" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repository provides the code and model checkpoints of the research paper: Scalable Pre-training of Large Autoregressive Image Models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AIM: Autoregressive Image Models&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;Alaaeldin El-Nouby, Michal Klein, Shuangfei Zhai, Miguel Angel Bautista, Alexander Toshev, Vaishaal Shankar, Joshua M Susskind, and Armand Joulin&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2401.08541&#34;&gt;&lt;code&gt;Paper&lt;/code&gt;&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/apple/ml-aim/main/#citation&#34;&gt;&lt;code&gt;BibTex&lt;/code&gt;&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;This software project accompanies the research paper, &lt;a href=&#34;https://arxiv.org/abs/2401.08541&#34;&gt;Scalable Pre-training of Large Autoregressive Image Models&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We introduce &lt;strong&gt;AIM&lt;/strong&gt; a collection of vision models pre-trained with an autoregressive generative objective. We show that autoregressive pre-training of image features exhibits similar scaling properties to their textual counterpart (i.e. Large Language Models). Specifically, we highlight two findings:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;the model capacity can be trivially scaled to billions of parameters, and&lt;/li&gt; &#xA; &lt;li&gt;AIM effectively leverages large collections of uncurated image data.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Please install PyTorch using the official &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;installation instructions&lt;/a&gt;. Afterward, install the package as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commandline&#34;&gt;pip install git+https://git@github.com/apple/ml-aim.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We also offer &lt;a href=&#34;https://github.com/ml-explore/mlx&#34;&gt;MLX&lt;/a&gt; backend support for research and experimentation on Apple silicon. To enable MLX support, simply run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commandline&#34;&gt;pip install mlx&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Below we provide an example of usage in &lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from PIL import Image&#xA;&#xA;from aim.utils import load_pretrained&#xA;from aim.torch.data import val_transforms&#xA;&#xA;img = Image.open(...)&#xA;model = load_pretrained(&#34;aim-600M-2B-imgs&#34;, backend=&#34;torch&#34;)&#xA;transform = val_transforms()&#xA;&#xA;inp = transform(img).unsqueeze(0)&#xA;logits, features = model(inp)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;and in both &lt;a href=&#34;https://ml-explore.github.io/mlx/&#34;&gt;MLX&lt;/a&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from PIL import Image&#xA;import mlx.core as mx&#xA;&#xA;from aim.utils import load_pretrained&#xA;from aim.torch.data import val_transforms&#xA;&#xA;img = Image.open(...)&#xA;model = load_pretrained(&#34;aim-600M-2B-imgs&#34;, backend=&#34;mlx&#34;)&#xA;transform = val_transforms()&#xA;&#xA;inp = transform(img).unsqueeze(0)&#xA;inp = mx.array(inp.numpy())&#xA;logits, features = model(inp)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;and &lt;a href=&#34;https://jax.readthedocs.io/&#34;&gt;JAX&lt;/a&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from PIL import Image&#xA;import jax.numpy as jnp&#xA;&#xA;from aim.utils import load_pretrained&#xA;from aim.torch.data import val_transforms&#xA;&#xA;img = Image.open(...)&#xA;model, params = load_pretrained(&#34;aim-600M-2B-imgs&#34;, backend=&#34;jax&#34;)&#xA;transform = val_transforms()&#xA;&#xA;inp = transform(img).unsqueeze(0)&#xA;inp = jnp.array(inp)&#xA;(logits, features), _ = model.apply(params, inp, mutable=[&#39;batch_stats&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Pre-trained checkpoints&lt;/h2&gt; &#xA;&lt;p&gt;The pre-trained models can be accessed via &lt;a href=&#34;https://pytorch.org/hub/&#34;&gt;PyTorch Hub&lt;/a&gt; as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;&#xA;aim_600m = torch.hub.load(&#34;apple/ml-aim&#34;, &#34;aim_600M&#34;)&#xA;aim_1b   = torch.hub.load(&#34;apple/ml-aim&#34;, &#34;aim_1B&#34;)&#xA;aim_3b   = torch.hub.load(&#34;apple/ml-aim&#34;, &#34;aim_3B&#34;)&#xA;aim_7b   = torch.hub.load(&#34;apple/ml-aim&#34;, &#34;aim_7B&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or via &lt;a href=&#34;https://huggingface.co/docs/hub/&#34;&gt;HuggingFace Hub&lt;/a&gt; as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from aim.torch.models import AIMForImageClassification&#xA;&#xA;aim_600m = AIMForImageClassification.from_pretrained(&#34;apple/aim-600M&#34;)&#xA;aim_1b   = AIMForImageClassification.from_pretrained(&#34;apple/aim-1B&#34;)&#xA;aim_3b   = AIMForImageClassification.from_pretrained(&#34;apple/aim-3B&#34;)&#xA;aim_7b   = AIMForImageClassification.from_pretrained(&#34;apple/aim-7B&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Pre-trained backbones&lt;/h3&gt; &#xA;&lt;p&gt;The following table contains pre-trained backbones used in our paper.&lt;/p&gt; &#xA;&lt;table style=&#34;margin: auto&#34;&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;model&lt;/th&gt; &#xA;   &lt;th&gt;#params&lt;/th&gt; &#xA;   &lt;th&gt;attn (best layer)&lt;/th&gt; &#xA;   &lt;th&gt;backbone, SHA256&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AIM-0.6B&lt;/td&gt; &#xA;   &lt;td&gt;0.6B&lt;/td&gt; &#xA;   &lt;td&gt;79.4%&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/apple/AIM/resolve/main/aim_600m_2bimgs_attnprobe_backbone.pth&#34;&gt;link&lt;/a&gt;, 0d6f6b8f&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AIM-1B&lt;/td&gt; &#xA;   &lt;td&gt;1B&lt;/td&gt; &#xA;   &lt;td&gt;82.3%&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/apple/AIM/resolve/main/aim_1b_5bimgs_attnprobe_backbone.pth&#34;&gt;link&lt;/a&gt;, d254ecd3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AIM-3B&lt;/td&gt; &#xA;   &lt;td&gt;3B&lt;/td&gt; &#xA;   &lt;td&gt;83.3%&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/apple/AIM/resolve/main/aim_3b_5bimgs_attnprobe_backbone.pth&#34;&gt;link&lt;/a&gt;, 8475ce4e&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AIM-7B&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;84.0%&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/apple/AIM/resolve/main/aim_7b_5bimgs_attnprobe_backbone.pth&#34;&gt;link&lt;/a&gt;, 184ed94c&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Pre-trained attention heads&lt;/h3&gt; &#xA;&lt;p&gt;The table below contains the classification results on ImageNet-1k validation set.&lt;/p&gt; &#xA;&lt;table style=&#34;margin: auto&#34;&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th rowspan=&#34;2&#34;&gt;model&lt;/th&gt; &#xA;   &lt;th colspan=&#34;2&#34;&gt;top-1 IN-1k&lt;/th&gt; &#xA;   &lt;th colspan=&#34;2&#34;&gt;attention head, SHA256&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;last layer&lt;/th&gt; &#xA;   &lt;th&gt;best layer&lt;/th&gt; &#xA;   &lt;th&gt;last layer&lt;/th&gt; &#xA;   &lt;th&gt;best layer&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AIM-0.6B&lt;/td&gt; &#xA;   &lt;td&gt;78.5%&lt;/td&gt; &#xA;   &lt;td&gt;79.4%&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/apple/AIM/resolve/main/aim_600m_2bimgs_attnprobe_head_last_layers.pth&#34;&gt;link&lt;/a&gt;, 5ce5a341&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/apple/AIM/resolve/main/aim_600m_2bimgs_attnprobe_head_best_layers.pth&#34;&gt;link&lt;/a&gt;, ebd45c05&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AIM-1B&lt;/td&gt; &#xA;   &lt;td&gt;80.6%&lt;/td&gt; &#xA;   &lt;td&gt;82.3%&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/apple/AIM/resolve/main/aim_1b_5bimgs_attnprobe_head_last_layers.pth&#34;&gt;link&lt;/a&gt;, db3be2ad&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/apple/AIM/resolve/main/aim_1b_5bimgs_attnprobe_head_best_layers.pth&#34;&gt;link&lt;/a&gt;, f1ed7852&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AIM-3B&lt;/td&gt; &#xA;   &lt;td&gt;82.2%&lt;/td&gt; &#xA;   &lt;td&gt;83.3%&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/apple/AIM/resolve/main/aim_3b_5bimgs_attnprobe_head_last_layers.pth&#34;&gt;link&lt;/a&gt;, 5c057b30&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/apple/AIM/resolve/main/aim_3b_5bimgs_attnprobe_head_best_layers.pth&#34;&gt;link&lt;/a&gt;, ad380e16&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AIM-7B&lt;/td&gt; &#xA;   &lt;td&gt;82.4%&lt;/td&gt; &#xA;   &lt;td&gt;84.0%&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/apple/AIM/resolve/main/aim_7b_5bimgs_attnprobe_head_last_layers.pth&#34;&gt;link&lt;/a&gt;, 1e5c99ba&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/apple/AIM/resolve/main/aim_7b_5bimgs_attnprobe_head_best_layers.pth&#34;&gt;link&lt;/a&gt;, 73ecd732&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Reproducing the IN-1k classification results&lt;/h2&gt; &#xA;&lt;p&gt;The commands below reproduce the &lt;a href=&#34;https://raw.githubusercontent.com/apple/ml-aim/main/#pre-trained-attention-heads&#34;&gt;attention probe results&lt;/a&gt; on ImageNet-1k validation set. We run the evaluation using 1 node with 8 GPUs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commandline&#34;&gt;torchrun --standalone --nnodes=1 --nproc-per-node=8 main_attnprobe.py \&#xA;  --model=aim-7B \&#xA;  --batch-size=64 \&#xA;  --data-path=/path/to/imagenet \&#xA;  --probe-layers=best \&#xA;  --backbone-ckpt-path=/path/to/backbone_ckpt.pth \&#xA;  --head-ckpt-path=/path/to/head_ckpt.pth&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, we probe features from the intermediate 6 layers that provide the best performance. To change this, simply pass &lt;code&gt;--probe-layers=last&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find our work useful, please consider citing us as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{elnouby2024scalable,&#xA;      title={Scalable Pre-training of Large Autoregressive Image Models},&#xA;      author={Alaaeldin El-Nouby and Michal Klein and Shuangfei Zhai and Miguel Angel Bautista and Alexander Toshev and Vaishaal Shankar and Joshua M Susskind and Armand Joulin},&#xA;      year={2024},&#xA;      eprint={2401.08541},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>