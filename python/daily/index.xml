<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-03-14T01:37:25Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>microsoft/TRELLIS</title>
    <updated>2025-03-14T01:37:25Z</updated>
    <id>tag:github.com,2025-03-14:/microsoft/TRELLIS</id>
    <link href="https://github.com/microsoft/TRELLIS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official repo for paper &#34;Structured 3D Latents for Scalable and Versatile 3D Generation&#34; (CVPR&#39;25).&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/TRELLIS/main/assets/logo.webp&#34; width=&#34;100%&#34; align=&#34;center&#34;&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt;Structured 3D Latents&lt;br&gt;for Scalable and Versatile 3D Generation&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2412.01506&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-Paper-red?logo=arxiv&amp;amp;logoColor=white&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://trellis3d.github.io&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project_Page-Website-green?logo=googlechrome&amp;amp;logoColor=white&#34; alt=&#34;Project Page&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/JeffreyXiang/TRELLIS&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Live_Demo-blue&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/TRELLIS/main/assets/teaser.png&#34; width=&#34;100%&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;span style=&#34;font-size: 16px; font-weight: 600;&#34;&gt;T&lt;/span&gt;&lt;span style=&#34;font-size: 12px; font-weight: 700;&#34;&gt;RELLIS&lt;/span&gt; is a large 3D asset generation model. It takes in text or image prompts and generates high-quality 3D assets in various formats, such as Radiance Fields, 3D Gaussians, and meshes. The cornerstone of &lt;span style=&#34;font-size: 16px; font-weight: 600;&#34;&gt;T&lt;/span&gt;&lt;span style=&#34;font-size: 12px; font-weight: 700;&#34;&gt;RELLIS&lt;/span&gt; is a unified Structured LATent (&lt;span style=&#34;font-size: 16px; font-weight: 600;&#34;&gt;SL&lt;/span&gt;&lt;span style=&#34;font-size: 12px; font-weight: 700;&#34;&gt;AT&lt;/span&gt;) representation that allows decoding to different output formats and Rectified Flow Transformers tailored for &lt;span style=&#34;font-size: 16px; font-weight: 600;&#34;&gt;SL&lt;/span&gt;&lt;span style=&#34;font-size: 12px; font-weight: 700;&#34;&gt;AT&lt;/span&gt; as the powerful backbones. We provide large-scale pre-trained models with up to 2 billion parameters on a large 3D asset dataset of 500K diverse objects. &lt;span style=&#34;font-size: 16px; font-weight: 600;&#34;&gt;T&lt;/span&gt;&lt;span style=&#34;font-size: 12px; font-weight: 700;&#34;&gt;RELLIS&lt;/span&gt; significantly surpasses existing methods, including recent ones at similar scales, and showcases flexible output format selection and local 3D editing capabilities which were not offered by previous models.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Check out our &lt;a href=&#34;https://trellis3d.github.io&#34;&gt;Project Page&lt;/a&gt; for more videos and interactive demos!&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;!-- Features --&gt; &#xA;&lt;h2&gt;üåü Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;High Quality&lt;/strong&gt;: It produces diverse 3D assets at high quality with intricate shape and texture details.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Versatility&lt;/strong&gt;: It takes text or image prompts and can generate various final 3D representations including but not limited to &lt;em&gt;Radiance Fields&lt;/em&gt;, &lt;em&gt;3D Gaussians&lt;/em&gt;, and &lt;em&gt;meshes&lt;/em&gt;, accommodating diverse downstream requirements.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Flexible Editing&lt;/strong&gt;: It allows for easy editings of generated 3D assets, such as generating variants of the same object or local editing of the 3D asset.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- Updates --&gt; &#xA;&lt;h2&gt;‚è© Updates&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;12/26/2024&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Release &lt;a href=&#34;https://github.com/microsoft/TRELLIS#-dataset&#34;&gt;&lt;strong&gt;TRELLIS-500K&lt;/strong&gt;&lt;/a&gt; dataset and toolkits for data preparation.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;12/18/2024&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Implementation of multi-image conditioning for TRELLIS-image model. (&lt;a href=&#34;https://github.com/microsoft/TRELLIS/issues/7&#34;&gt;#7&lt;/a&gt;). This is based on tuning-free algorithm without training a specialized model, so it may not give the best results for all input images.&lt;/li&gt; &#xA; &lt;li&gt;Add Gaussian export in &lt;code&gt;app.py&lt;/code&gt; and &lt;code&gt;example.py&lt;/code&gt;. (&lt;a href=&#34;https://github.com/microsoft/TRELLIS/issues/40&#34;&gt;#40&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- TODO List --&gt; &#xA;&lt;h2&gt;üöß TODO List&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Release inference code and TRELLIS-image-large model&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Release dataset and dataset toolkits&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Release TRELLIS-text model series&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Release training code&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- Installation --&gt; &#xA;&lt;h2&gt;üì¶ Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;System&lt;/strong&gt;: The code is currently tested only on &lt;strong&gt;Linux&lt;/strong&gt;. For windows setup, you may refer to &lt;a href=&#34;https://github.com/microsoft/TRELLIS/issues/3&#34;&gt;#3&lt;/a&gt; (not fully tested).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Hardware&lt;/strong&gt;: An NVIDIA GPU with at least 16GB of memory is necessary. The code has been verified on NVIDIA A100 and A6000 GPUs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Software&lt;/strong&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The &lt;a href=&#34;https://developer.nvidia.com/cuda-toolkit-archive&#34;&gt;CUDA Toolkit&lt;/a&gt; is needed to compile certain submodules. The code has been tested with CUDA versions 11.8 and 12.2.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.anaconda.com/miniconda/install/#quick-command-line-install&#34;&gt;Conda&lt;/a&gt; is recommended for managing dependencies.&lt;/li&gt; &#xA;   &lt;li&gt;Python version 3.8 or higher is required.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation Steps&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Clone the repo:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone --recurse-submodules https://github.com/microsoft/TRELLIS.git&#xA;cd TRELLIS&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install the dependencies:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Before running the following command there are somethings to note:&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;By adding &lt;code&gt;--new-env&lt;/code&gt;, a new conda environment named &lt;code&gt;trellis&lt;/code&gt; will be created. If you want to use an existing conda environment, please remove this flag.&lt;/li&gt; &#xA;   &lt;li&gt;By default the &lt;code&gt;trellis&lt;/code&gt; environment will use pytorch 2.4.0 with CUDA 11.8. If you want to use a different version of CUDA (e.g., if you have CUDA Toolkit 12.2 installed and do not want to install another 11.8 version for submodule compilation), you can remove the &lt;code&gt;--new-env&lt;/code&gt; flag and manually install the required dependencies. Refer to &lt;a href=&#34;https://pytorch.org/get-started/previous-versions/&#34;&gt;PyTorch&lt;/a&gt; for the installation command.&lt;/li&gt; &#xA;   &lt;li&gt;If you have multiple CUDA Toolkit versions installed, &lt;code&gt;PATH&lt;/code&gt; should be set to the correct version before running the command. For example, if you have CUDA Toolkit 11.8 and 12.2 installed, you should run &lt;code&gt;export PATH=/usr/local/cuda-11.8/bin:$PATH&lt;/code&gt; before running the command.&lt;/li&gt; &#xA;   &lt;li&gt;By default, the code uses the &lt;code&gt;flash-attn&lt;/code&gt; backend for attention. For GPUs do not support &lt;code&gt;flash-attn&lt;/code&gt; (e.g., NVIDIA V100), you can remove the &lt;code&gt;--flash-attn&lt;/code&gt; flag to install &lt;code&gt;xformers&lt;/code&gt; only and set the &lt;code&gt;ATTN_BACKEND&lt;/code&gt; environment variable to &lt;code&gt;xformers&lt;/code&gt; before running the code. See the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/TRELLIS/main/#minimal-example&#34;&gt;Minimal Example&lt;/a&gt; for more details.&lt;/li&gt; &#xA;   &lt;li&gt;The installation may take a while due to the large number of dependencies. Please be patient. If you encounter any issues, you can try to install the dependencies one by one, specifying one flag at a time.&lt;/li&gt; &#xA;   &lt;li&gt;If you encounter any issues during the installation, feel free to open an issue or contact us.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;Create a new conda environment named &lt;code&gt;trellis&lt;/code&gt; and install the dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;. ./setup.sh --new-env --basic --xformers --flash-attn --diffoctreerast --spconv --mipgaussian --kaolin --nvdiffrast&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The detailed usage of &lt;code&gt;setup.sh&lt;/code&gt; can be found by running &lt;code&gt;. ./setup.sh --help&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;Usage: setup.sh [OPTIONS]&#xA;Options:&#xA;    -h, --help              Display this help message&#xA;    --new-env               Create a new conda environment&#xA;    --basic                 Install basic dependencies&#xA;    --xformers              Install xformers&#xA;    --flash-attn            Install flash-attn&#xA;    --diffoctreerast        Install diffoctreerast&#xA;    --vox2seq               Install vox2seq&#xA;    --spconv                Install spconv&#xA;    --mipgaussian           Install mip-splatting&#xA;    --kaolin                Install kaolin&#xA;    --nvdiffrast            Install nvdiffrast&#xA;    --demo                  Install all dependencies for demo&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;!-- Pretrained Models --&gt; &#xA;&lt;h2&gt;ü§ñ Pretrained Models&lt;/h2&gt; &#xA;&lt;p&gt;We provide the following pretrained models:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;#Params&lt;/th&gt; &#xA;   &lt;th&gt;Download&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TRELLIS-image-large&lt;/td&gt; &#xA;   &lt;td&gt;Large image-to-3D model&lt;/td&gt; &#xA;   &lt;td&gt;1.2B&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/JeffreyXiang/TRELLIS-image-large&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TRELLIS-text-base&lt;/td&gt; &#xA;   &lt;td&gt;Base text-to-3D model&lt;/td&gt; &#xA;   &lt;td&gt;342M&lt;/td&gt; &#xA;   &lt;td&gt;Coming Soon&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TRELLIS-text-large&lt;/td&gt; &#xA;   &lt;td&gt;Large text-to-3D model&lt;/td&gt; &#xA;   &lt;td&gt;1.1B&lt;/td&gt; &#xA;   &lt;td&gt;Coming Soon&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TRELLIS-text-xlarge&lt;/td&gt; &#xA;   &lt;td&gt;Extra-large text-to-3D model&lt;/td&gt; &#xA;   &lt;td&gt;2.0B&lt;/td&gt; &#xA;   &lt;td&gt;Coming Soon&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The models are hosted on Hugging Face. You can directly load the models with their repository names in the code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;TrellisImageTo3DPipeline.from_pretrained(&#34;JeffreyXiang/TRELLIS-image-large&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you prefer loading the model from local, you can download the model files from the links above and load the model with the folder path (folder structure should be maintained):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;TrellisImageTo3DPipeline.from_pretrained(&#34;/path/to/TRELLIS-image-large&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- Usage --&gt; &#xA;&lt;h2&gt;üí° Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Minimal Example&lt;/h3&gt; &#xA;&lt;p&gt;Here is an &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/TRELLIS/main/example.py&#34;&gt;example&lt;/a&gt; of how to use the pretrained models for 3D asset generation.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os&#xA;# os.environ[&#39;ATTN_BACKEND&#39;] = &#39;xformers&#39;   # Can be &#39;flash-attn&#39; or &#39;xformers&#39;, default is &#39;flash-attn&#39;&#xA;os.environ[&#39;SPCONV_ALGO&#39;] = &#39;native&#39;        # Can be &#39;native&#39; or &#39;auto&#39;, default is &#39;auto&#39;.&#xA;                                            # &#39;auto&#39; is faster but will do benchmarking at the beginning.&#xA;                                            # Recommended to set to &#39;native&#39; if run only once.&#xA;&#xA;import imageio&#xA;from PIL import Image&#xA;from trellis.pipelines import TrellisImageTo3DPipeline&#xA;from trellis.utils import render_utils, postprocessing_utils&#xA;&#xA;# Load a pipeline from a model folder or a Hugging Face model hub.&#xA;pipeline = TrellisImageTo3DPipeline.from_pretrained(&#34;JeffreyXiang/TRELLIS-image-large&#34;)&#xA;pipeline.cuda()&#xA;&#xA;# Load an image&#xA;image = Image.open(&#34;assets/example_image/T.png&#34;)&#xA;&#xA;# Run the pipeline&#xA;outputs = pipeline.run(&#xA;    image,&#xA;    seed=1,&#xA;    # Optional parameters&#xA;    # sparse_structure_sampler_params={&#xA;    #     &#34;steps&#34;: 12,&#xA;    #     &#34;cfg_strength&#34;: 7.5,&#xA;    # },&#xA;    # slat_sampler_params={&#xA;    #     &#34;steps&#34;: 12,&#xA;    #     &#34;cfg_strength&#34;: 3,&#xA;    # },&#xA;)&#xA;# outputs is a dictionary containing generated 3D assets in different formats:&#xA;# - outputs[&#39;gaussian&#39;]: a list of 3D Gaussians&#xA;# - outputs[&#39;radiance_field&#39;]: a list of radiance fields&#xA;# - outputs[&#39;mesh&#39;]: a list of meshes&#xA;&#xA;# Render the outputs&#xA;video = render_utils.render_video(outputs[&#39;gaussian&#39;][0])[&#39;color&#39;]&#xA;imageio.mimsave(&#34;sample_gs.mp4&#34;, video, fps=30)&#xA;video = render_utils.render_video(outputs[&#39;radiance_field&#39;][0])[&#39;color&#39;]&#xA;imageio.mimsave(&#34;sample_rf.mp4&#34;, video, fps=30)&#xA;video = render_utils.render_video(outputs[&#39;mesh&#39;][0])[&#39;normal&#39;]&#xA;imageio.mimsave(&#34;sample_mesh.mp4&#34;, video, fps=30)&#xA;&#xA;# GLB files can be extracted from the outputs&#xA;glb = postprocessing_utils.to_glb(&#xA;    outputs[&#39;gaussian&#39;][0],&#xA;    outputs[&#39;mesh&#39;][0],&#xA;    # Optional parameters&#xA;    simplify=0.95,          # Ratio of triangles to remove in the simplification process&#xA;    texture_size=1024,      # Size of the texture used for the GLB&#xA;)&#xA;glb.export(&#34;sample.glb&#34;)&#xA;&#xA;# Save Gaussians as PLY files&#xA;outputs[&#39;gaussian&#39;][0].save_ply(&#34;sample.ply&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After running the code, you will get the following files:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;sample_gs.mp4&lt;/code&gt;: a video showing the 3D Gaussian representation&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;sample_rf.mp4&lt;/code&gt;: a video showing the Radiance Field representation&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;sample_mesh.mp4&lt;/code&gt;: a video showing the mesh representation&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;sample.glb&lt;/code&gt;: a GLB file containing the extracted textured mesh&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;sample.ply&lt;/code&gt;: a PLY file containing the 3D Gaussian representation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Web Demo&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/TRELLIS/main/app.py&#34;&gt;app.py&lt;/a&gt; provides a simple web demo for 3D asset generation. Since this demo is based on &lt;a href=&#34;https://gradio.app/&#34;&gt;Gradio&lt;/a&gt;, additional dependencies are required:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;. ./setup.sh --demo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After installing the dependencies, you can run the demo with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, you can access the demo at the address shown in the terminal.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;The web demo is also available on &lt;a href=&#34;https://huggingface.co/spaces/JeffreyXiang/TRELLIS&#34;&gt;Hugging Face Spaces&lt;/a&gt;!&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;!-- Dataset --&gt; &#xA;&lt;h2&gt;üìö Dataset&lt;/h2&gt; &#xA;&lt;p&gt;We provide &lt;strong&gt;TRELLIS-500K&lt;/strong&gt;, a large-scale dataset containing 500K 3D assets curated from &lt;a href=&#34;https://objaverse.allenai.org/&#34;&gt;Objaverse(XL)&lt;/a&gt;, &lt;a href=&#34;https://amazon-berkeley-objects.s3.amazonaws.com/index.html&#34;&gt;ABO&lt;/a&gt;, &lt;a href=&#34;https://tianchi.aliyun.com/specials/promotion/alibaba-3d-future&#34;&gt;3D-FUTURE&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/datasets/hssd/hssd-models&#34;&gt;HSSD&lt;/a&gt;, and &lt;a href=&#34;https://github.com/rehg-lab/lowshot-shapebias/tree/main/toys4k&#34;&gt;Toys4k&lt;/a&gt;, filtered based on aesthetic scores. Please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/TRELLIS/main/DATASET.md&#34;&gt;dataset README&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;!-- License --&gt; &#xA;&lt;h2&gt;‚öñÔ∏è License&lt;/h2&gt; &#xA;&lt;p&gt;TRELLIS models and the majority of the code are licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/TRELLIS/main/LICENSE&#34;&gt;MIT License&lt;/a&gt;. The following submodules may have different licenses:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/JeffreyXiang/diffoctreerast&#34;&gt;&lt;strong&gt;diffoctreerast&lt;/strong&gt;&lt;/a&gt;: We developed a CUDA-based real-time differentiable octree renderer for rendering radiance fields as part of this project. This renderer is derived from the &lt;a href=&#34;https://github.com/graphdeco-inria/diff-gaussian-rasterization&#34;&gt;diff-gaussian-rasterization&lt;/a&gt; project and is available under the &lt;a href=&#34;https://github.com/JeffreyXiang/diffoctreerast/raw/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/MaxtirError/FlexiCubes&#34;&gt;&lt;strong&gt;Modified Flexicubes&lt;/strong&gt;&lt;/a&gt;: In this project, we used a modified version of &lt;a href=&#34;https://github.com/nv-tlabs/FlexiCubes&#34;&gt;Flexicubes&lt;/a&gt; to support vertex attributes. This modified version is licensed under the &lt;a href=&#34;https://github.com/nv-tlabs/FlexiCubes/raw/main/LICENSE.txt&#34;&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- Citation --&gt; &#xA;&lt;h2&gt;üìú Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find this work helpful, please consider citing our paper:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{xiang2024structured,&#xA;    title   = {Structured 3D Latents for Scalable and Versatile 3D Generation},&#xA;    author  = {Xiang, Jianfeng and Lv, Zelong and Xu, Sicheng and Deng, Yu and Wang, Ruicheng and Zhang, Bowen and Chen, Dong and Tong, Xin and Yang, Jiaolong},&#xA;    journal = {arXiv preprint arXiv:2412.01506},&#xA;    year    = {2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>