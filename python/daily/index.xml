<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-07-14T01:32:09Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>IDEACVR/DINO</title>
    <updated>2022-07-14T01:32:09Z</updated>
    <id>tag:github.com,2022-07-14:/IDEACVR/DINO</id>
    <link href="https://github.com/IDEACVR/DINO" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official implementation of the paper &#34;DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection&#34;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DINO &lt;img src=&#34;https://raw.githubusercontent.com/IDEACVR/DINO/main/figs/dinosaur.png&#34; width=&#34;30&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://paperswithcode.com/sota/object-detection-on-coco-minival?p=dino-detr-with-improved-denoising-anchor-1&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/dino-detr-with-improved-denoising-anchor-1/object-detection-on-coco-minival&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://paperswithcode.com/sota/object-detection-on-coco?p=dino-detr-with-improved-denoising-anchor-1&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/dino-detr-with-improved-denoising-anchor-1/object-detection-on-coco&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is the official implementation of the paper &#34;&lt;a href=&#34;https://arxiv.org/abs/2203.03605&#34;&gt;DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection&lt;/a&gt;&#34;. (DINO pronounced `da…™no ä&#39; as in dinosaur)&lt;/p&gt; &#xA;&lt;p&gt;Authors: &lt;a href=&#34;https://scholar.google.com/citations?user=B8hPxMQAAAAJ&amp;amp;hl=zh-CN&#34;&gt;Hao Zhang&lt;/a&gt;*, &lt;a href=&#34;https://fengli-ust.github.io/&#34;&gt;Feng Li&lt;/a&gt;*, &lt;a href=&#34;https://www.lsl.zone/&#34;&gt;Shilong Liu&lt;/a&gt;*, &lt;a href=&#34;https://www.leizhang.org/&#34;&gt;Lei Zhang&lt;/a&gt;, &lt;a href=&#34;https://www.suhangss.me/&#34;&gt;Hang Su&lt;/a&gt;, &lt;a href=&#34;https://ml.cs.tsinghua.edu.cn/~jun/index.shtml&#34;&gt;Jun Zhu&lt;/a&gt;, &lt;a href=&#34;https://www.cse.ust.hk/~ni/&#34;&gt;Lionel M. Ni&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com.hk/citations?user=9akH-n8AAAAJ&amp;amp;hl=en&#34;&gt;Heung-Yeung Shum&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;News&lt;/h1&gt; &#xA;&lt;p&gt;[2022/7/10]: We released the code and checkpoints with Resnet-50 backbone. &lt;br&gt; [2022/6/7]: We release a unified detection and segmentation model &lt;a href=&#34;https://arxiv.org/pdf/2206.02777.pdf&#34;&gt;Mask DINO&lt;/a&gt; that achieves the best results on all the three segmentation tasks (&lt;strong&gt;54.7&lt;/strong&gt; AP on &lt;a href=&#34;https://paperswithcode.com/sota/instance-segmentation-on-coco&#34;&gt;COCO instance leaderboard&lt;/a&gt;, &lt;strong&gt;59.5&lt;/strong&gt; PQ on &lt;a href=&#34;https://paperswithcode.com/sota/panoptic-segmentation-on-coco-test-dev&#34;&gt;COCO panoptic leaderboard&lt;/a&gt;, and &lt;strong&gt;60.8&lt;/strong&gt; mIoU on &lt;a href=&#34;https://paperswithcode.com/sota/semantic-segmentation-on-ade20k&#34;&gt;ADE20K semantic leaderboard&lt;/a&gt;)! Code will be available &lt;a href=&#34;https://github.com/IDEACVR/MaskDINO&#34;&gt;here&lt;/a&gt;. &lt;br&gt; [2022/5/28] Code for &lt;a href=&#34;https://arxiv.org/pdf/2203.01305.pdf&#34;&gt;DN-DETR&lt;/a&gt; is available &lt;a href=&#34;https://github.com/IDEA-opensource/DN-DETR&#34;&gt;here&lt;/a&gt;. &lt;br&gt; [2020/4/10]: Code for &lt;a href=&#34;https://arxiv.org/abs/2201.12329&#34;&gt;DAB-DETR&lt;/a&gt; is avaliable &lt;a href=&#34;https://github.com/SlongLiu/DAB-DETR&#34;&gt;here&lt;/a&gt;. &lt;br&gt; [2022/3/8]: We reach the SOTA on &lt;a href=&#34;https://paperswithcode.com/sota/object-detection-on-coco&#34;&gt;MS-COCO leader board&lt;/a&gt; with &lt;strong&gt;63.3AP&lt;/strong&gt;! &lt;br&gt; [2022/3/9]: We build a repo &lt;a href=&#34;https://github.com/IDEACVR/awesome-detection-transformer&#34;&gt;Awesome Detection Transformer&lt;/a&gt; to present papers about transformer for detection and segmenttion. Welcome to your attention!&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/IDEACVR/DINO/main/figs/sota.jpg&#34; alt=&#34;SOTA results&#34; title=&#34;results on MSCOCO&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Introduction&lt;/h1&gt; &#xA;&lt;p&gt;We present &lt;strong&gt;DINO&lt;/strong&gt; (&lt;strong&gt;D&lt;/strong&gt;ETR with &lt;strong&gt;I&lt;/strong&gt;mproved de&lt;strong&gt;N&lt;/strong&gt;oising anch&lt;strong&gt;O&lt;/strong&gt;r boxes) with:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;State-of-the-art &amp;amp; end-to-end&lt;/strong&gt;: DINO achieves &lt;strong&gt;63.2&lt;/strong&gt; AP on COCO Val and &lt;strong&gt;63.3&lt;/strong&gt; AP on COCO test-dev with more than ten times smaller model size and data size than previous best models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fast-converging&lt;/strong&gt;: With the ResNet-50 backbone, DINO with 5 scales achieves &lt;strong&gt;49.4&lt;/strong&gt; AP in 12 epochs and &lt;strong&gt;51.3&lt;/strong&gt; AP in 24 epochs. Our 4-scale model achieves similar performance and runs at 23 FPS.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Methods&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/IDEACVR/DINO/main/figs/framework.png&#34; alt=&#34;method&#34; title=&#34;model arch&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Model Zoo&lt;/h2&gt; &#xA;&lt;p&gt;We have put our model checkpoints here &lt;a href=&#34;https://drive.google.com/drive/folders/1qD5m1NmK0kjE5hh-G17XUX751WsEG-h_?usp=sharing&#34;&gt;[model zoo in Google Drive]&lt;/a&gt;&lt;a href=&#34;https://pan.baidu.com/s/1St5rvfgfPwpnPuf_Oe6DpQ&#34;&gt;[model zoo in ÁôæÂ∫¶ÁΩëÁõò]&lt;/a&gt;ÔºàÊèêÂèñÁ†Å&#34;DINO&#34;), where checkpoint{x}_{y}scale.pth denotes the checkpoint of y-scale model trained for x epochs.&lt;/p&gt; &#xA;&lt;h3&gt;12 epoch setting&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr style=&#34;text-align: right;&#34;&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;name&lt;/th&gt; &#xA;   &lt;th&gt;backbone&lt;/th&gt; &#xA;   &lt;th&gt;box AP&lt;/th&gt; &#xA;   &lt;th&gt;Checkpoint&lt;/th&gt; &#xA;   &lt;th&gt;Where in &lt;a href=&#34;https://arxiv.org/abs/2203.03605&#34;&gt;Our Paper&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;1&lt;/th&gt; &#xA;   &lt;td&gt;DINO-4scale&lt;/td&gt; &#xA;   &lt;td&gt;R50&lt;/td&gt; &#xA;   &lt;td&gt;49.0&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1qD5m1NmK0kjE5hh-G17XUX751WsEG-h_?usp=sharing&#34;&gt;Google Drive&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&#34;https://pan.baidu.com/s/1St5rvfgfPwpnPuf_Oe6DpQ&#34;&gt;BaiDu&lt;/a&gt;&amp;nbsp;&lt;/td&gt; &#xA;   &lt;td&gt;Table 1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;2&lt;/th&gt; &#xA;   &lt;td&gt;DINO-5scale&lt;/td&gt; &#xA;   &lt;td&gt;R50&lt;/td&gt; &#xA;   &lt;td&gt;49.4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1qD5m1NmK0kjE5hh-G17XUX751WsEG-h_?usp=sharing&#34;&gt;Google Drive&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&#34;https://pan.baidu.com/s/1St5rvfgfPwpnPuf_Oe6DpQ&#34;&gt;BaiDu&lt;/a&gt;&amp;nbsp;&lt;/td&gt; &#xA;   &lt;td&gt;Table 1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;24 epoch setting&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr style=&#34;text-align: right;&#34;&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;name&lt;/th&gt; &#xA;   &lt;th&gt;backbone&lt;/th&gt; &#xA;   &lt;th&gt;box AP&lt;/th&gt; &#xA;   &lt;th&gt;Checkpoint&lt;/th&gt; &#xA;   &lt;th&gt;Where in &lt;a href=&#34;https://arxiv.org/abs/2203.03605&#34;&gt;Our Paper&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;1&lt;/th&gt; &#xA;   &lt;td&gt;DINO-4scale&lt;/td&gt; &#xA;   &lt;td&gt;R50&lt;/td&gt; &#xA;   &lt;td&gt;50.4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1qD5m1NmK0kjE5hh-G17XUX751WsEG-h_?usp=sharing&#34;&gt;Google Drive&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&#34;https://pan.baidu.com/s/1St5rvfgfPwpnPuf_Oe6DpQ&#34;&gt;BaiDu&lt;/a&gt;&amp;nbsp;&lt;/td&gt; &#xA;   &lt;td&gt;Table 2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;2&lt;/th&gt; &#xA;   &lt;td&gt;DINO-5scale&lt;/td&gt; &#xA;   &lt;td&gt;R50&lt;/td&gt; &#xA;   &lt;td&gt;51.3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1qD5m1NmK0kjE5hh-G17XUX751WsEG-h_?usp=sharing&#34;&gt;Google Drive&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&#34;https://pan.baidu.com/s/1St5rvfgfPwpnPuf_Oe6DpQ&#34;&gt;BaiDu&lt;/a&gt;&amp;nbsp;&lt;/td&gt; &#xA;   &lt;td&gt;Table 2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;36 epoch setting&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr style=&#34;text-align: right;&#34;&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;name&lt;/th&gt; &#xA;   &lt;th&gt;backbone&lt;/th&gt; &#xA;   &lt;th&gt;box AP&lt;/th&gt; &#xA;   &lt;th&gt;Checkpoint&lt;/th&gt; &#xA;   &lt;th&gt;Where in &lt;a href=&#34;https://arxiv.org/abs/2203.03605&#34;&gt;Our Paper&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;1&lt;/th&gt; &#xA;   &lt;td&gt;DINO-4scale&lt;/td&gt; &#xA;   &lt;td&gt;R50&lt;/td&gt; &#xA;   &lt;td&gt;50.9&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1qD5m1NmK0kjE5hh-G17XUX751WsEG-h_?usp=sharing&#34;&gt;Google Drive&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&#34;https://pan.baidu.com/s/1St5rvfgfPwpnPuf_Oe6DpQ&#34;&gt;BaiDu&lt;/a&gt;&amp;nbsp;&lt;/td&gt; &#xA;   &lt;td&gt;Table 2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;2&lt;/th&gt; &#xA;   &lt;td&gt;DINO-5scale&lt;/td&gt; &#xA;   &lt;td&gt;R50&lt;/td&gt; &#xA;   &lt;td&gt;51.2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1qD5m1NmK0kjE5hh-G17XUX751WsEG-h_?usp=sharing&#34;&gt;Google Drive&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&#34;https://pan.baidu.com/s/1St5rvfgfPwpnPuf_Oe6DpQ&#34;&gt;BaiDu&lt;/a&gt;&amp;nbsp;&lt;/td&gt; &#xA;   &lt;td&gt;Table 2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;We use the environment same to DAB-DETR and DN-DETR to run DINO. If you have run DN-DETR or DAB-DETR, you can skip this step. We test our models under &lt;code&gt;python=3.7.3,pytorch=1.9.0,cuda=11.1&lt;/code&gt;. Other versions might be available as well.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repo&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git https://github.com/IDEACVR/DINO&#xA;cd DINO&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Install Pytorch and torchvision&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Follow the instruction on &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;https://pytorch.org/get-started/locally/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# an example:&#xA;conda install -c pytorch pytorch torchvision&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Install other needed packages&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Compiling CUDA operators&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd models/dino/ops&#xA;python setup.py build install&#xA;# unit test (should see all checking is True)&#xA;python test.py&#xA;cd ../../..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Data&lt;/h2&gt; &#xA;&lt;p&gt;Please download &lt;a href=&#34;https://cocodataset.org/&#34;&gt;COCO 2017&lt;/a&gt; dataset and organize them as following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;COCODIR/&#xA;  ‚îú‚îÄ‚îÄ train2017/&#xA;  ‚îú‚îÄ‚îÄ val2017/&#xA;  ‚îî‚îÄ‚îÄ annotations/&#xA;  &#x9;‚îú‚îÄ‚îÄ instances_train2017.json&#xA;  &#x9;‚îî‚îÄ‚îÄ instances_val2017.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Run&lt;/h2&gt; &#xA;&lt;p&gt;We use DINO 4-scale model trained for 12 epochs as an example to demonstrate how to evaluate and train our model.&lt;/p&gt; &#xA;&lt;h3&gt;Eval our pretrianed model&lt;/h3&gt; &#xA;&lt;p&gt;Download our DINO model checkpoint &#34;checkpoint0011_4scale.pth&#34; from &lt;a href=&#34;https://drive.google.com/drive/folders/1qD5m1NmK0kjE5hh-G17XUX751WsEG-h_?usp=sharing&#34;&gt;this link&lt;/a&gt; and perform the command below. You can expect to get the final AP about 49.0.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bash scripts/DINO_eval.sh /path/to/your/COCODIR /path/to/your/checkpoint&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Train the 4scale model for 12 epochs&lt;/h3&gt; &#xA;&lt;p&gt;You can also train our model on a single process:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bash scripts/DINO_train.sh /path/to/your/COCODIR&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Distributed Run&lt;/h3&gt; &#xA;&lt;p&gt;However, as the training is time consuming, we suggest to train the model on multi-device.&lt;/p&gt; &#xA;&lt;p&gt;If you plan to train the models on a cluster with Slurm, here is an example command for training:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# for DINO-4scale: 49.0&#xA;bash scripts/DINO_train_submitit.sh /path/to/your/COCODIR&#xA;&#xA;# for DINO-5scale: 49.4&#xA;bash scripts/DINO_train_submitit_5scale.sh /path/to/your/COCODIR&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Notes: The results are sensitive to the batch size. We use 16(2 images each GPU x 8 GPUs for DINO-4scale and 1 images each GPU x 16 GPUs for DINO-5scale) by default.&lt;/p&gt; &#xA;&lt;p&gt;Or run with multi-processes on a single node:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# for DINO-4scale: 49.0&#xA;bash scripts/DINO_train_dist.sh /path/to/your/COCODIR&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Links&lt;/h1&gt; &#xA;&lt;p&gt;Our model is based on &lt;a href=&#34;https://arxiv.org/abs/2201.12329&#34;&gt;DAB-DETR&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2203.01305&#34;&gt;DN-DETR&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt; &lt;font size=&#34;3&#34;&gt;&lt;b&gt;DN-DETR: Accelerate DETR Training by Introducing Query DeNoising.&lt;/b&gt;&lt;/font&gt; &lt;br&gt; &lt;font size=&#34;2&#34;&gt;Feng Li*, Hao Zhang*, Shilong Liu, Jian Guo, Lionel M. Ni, Lei Zhang.&lt;/font&gt; &lt;br&gt; &lt;font size=&#34;2&#34;&gt;IEEE Conference on Computer Vision and Pattern Recognition (&lt;b&gt;CVPR&lt;/b&gt;) 2022.&lt;/font&gt; &lt;br&gt; &lt;a href=&#34;https://arxiv.org/abs/2203.01305&#34;&gt;[paper]&lt;/a&gt; &lt;a href=&#34;https://github.com/FengLi-ust/DN-DETR&#34;&gt;[code]&lt;/a&gt; &lt;a href=&#34;https://www.zhihu.com/question/517340666/answer/2381304399&#34;&gt;[‰∏≠ÊñáËß£ËØª]&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt; &lt;font size=&#34;3&#34;&gt;&lt;b&gt;DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR.&lt;/b&gt;&lt;/font&gt; &lt;br&gt; &lt;font size=&#34;2&#34;&gt;Shilong Liu, Feng Li, Hao Zhang, Xiao Yang, Xianbiao Qi, Hang Su, Jun Zhu, Lei Zhang.&lt;/font&gt; &lt;br&gt; &lt;font size=&#34;2&#34;&gt;International Conference on Learning Representations (&lt;b&gt;ICLR&lt;/b&gt;) 2022.&lt;/font&gt; &lt;br&gt; &lt;a href=&#34;https://arxiv.org/abs/2201.12329&#34;&gt;[paper]&lt;/a&gt; &lt;a href=&#34;https://github.com/SlongLiu/DAB-DETR&#34;&gt;[code]&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;LICNESE&lt;/h2&gt; &#xA;&lt;p&gt;DINO is released under the Apache 2.0 license. Please see the &lt;a href=&#34;https://raw.githubusercontent.com/IDEACVR/DINO/main/LICNESE&#34;&gt;LICENSE&lt;/a&gt; file for more information.&lt;/p&gt; &#xA;&lt;p&gt;Copyright (c) IDEA. All rights reserved.&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;); you may not use these files except in compliance with the License. You may obtain a copy of the License at &lt;a href=&#34;http://www.apache.org/licenses/LICENSE-2.0&#34;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &#34;AS IS&#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; &#xA;&lt;h1&gt;Bibtex&lt;/h1&gt; &#xA;&lt;p&gt;If you find our work helpful for your research, please consider citing the following BibTeX entry.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{zhang2022dino,&#xA;      title={DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection}, &#xA;      author={Hao Zhang and Feng Li and Shilong Liu and Lei Zhang and Hang Su and Jun Zhu and Lionel M. Ni and Heung-Yeung Shum},&#xA;      year={2022},&#xA;      eprint={2203.03605},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>spack/spack</title>
    <updated>2022-07-14T01:32:09Z</updated>
    <id>tag:github.com,2022-07-14:/spack/spack</id>
    <link href="https://github.com/spack/spack" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A flexible package manager that supports multiple versions, configurations, platforms, and compilers.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg?sanitize=true&#34; width=&#34;64&#34; valign=&#34;middle&#34; alt=&#34;Spack&#34;&gt; Spack&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/spack/spack/actions&#34;&gt;&lt;img src=&#34;https://github.com/spack/spack/workflows/linux%20tests/badge.svg?sanitize=true&#34; alt=&#34;Unit Tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/spack/spack/actions/workflows/bootstrap.yml&#34;&gt;&lt;img src=&#34;https://github.com/spack/spack/actions/workflows/bootstrap.yml/badge.svg?sanitize=true&#34; alt=&#34;Bootstrapping&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/spack/spack/actions?query=workflow%3A%22macOS+builds+nightly%22&#34;&gt;&lt;img src=&#34;https://github.com/spack/spack/workflows/macOS%20builds%20nightly/badge.svg?branch=develop&#34; alt=&#34;macOS Builds (nightly)&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/spack/spack&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/spack/spack/branch/develop/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/spack/spack/actions/workflows/build-containers.yml&#34;&gt;&lt;img src=&#34;https://github.com/spack/spack/actions/workflows/build-containers.yml/badge.svg?sanitize=true&#34; alt=&#34;Containers&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://spack.readthedocs.io&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/spack/badge/?version=latest&#34; alt=&#34;Read the Docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://slack.spack.io&#34;&gt;&lt;img src=&#34;https://slack.spack.io/badge.svg?sanitize=true&#34; alt=&#34;Slack&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Spack is a multi-platform package manager that builds and installs multiple versions and configurations of software. It works on Linux, macOS, and many supercomputers. Spack is non-destructive: installing a new version of a package does not break existing installations, so many configurations of the same package can coexist.&lt;/p&gt; &#xA;&lt;p&gt;Spack offers a simple &#34;spec&#34; syntax that allows users to specify versions and configuration options. Package files are written in pure Python, and specs allow package authors to write a single script for many different builds of the same package. With Spack, you can build your software &lt;em&gt;all&lt;/em&gt; the ways you want to.&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://spack.readthedocs.io/en/latest/features.html&#34;&gt;Feature Overview&lt;/a&gt; for examples and highlights.&lt;/p&gt; &#xA;&lt;p&gt;To install spack and your first package, make sure you have Python. Then:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone -c feature.manyFiles=true https://github.com/spack/spack.git&#xA;$ cd spack/bin&#xA;$ ./spack install zlib&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://spack.readthedocs.io/&#34;&gt;&lt;strong&gt;Full documentation&lt;/strong&gt;&lt;/a&gt; is available, or run &lt;code&gt;spack help&lt;/code&gt; or &lt;code&gt;spack help --all&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For a cheat sheet on Spack syntax, run &lt;code&gt;spack help --spec&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Tutorial&lt;/h2&gt; &#xA;&lt;p&gt;We maintain a &lt;a href=&#34;https://spack.readthedocs.io/en/latest/tutorial.html&#34;&gt;&lt;strong&gt;hands-on tutorial&lt;/strong&gt;&lt;/a&gt;. It covers basic to advanced usage, packaging, developer features, and large HPC deployments. You can do all of the exercises on your own laptop using a Docker container.&lt;/p&gt; &#xA;&lt;p&gt;Feel free to use these materials to teach users at your organization about Spack.&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;Spack is an open source project. Questions, discussion, and contributions are welcome. Contributions can be anything from new packages to bugfixes, documentation, or even new core features.&lt;/p&gt; &#xA;&lt;p&gt;Resources:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Slack workspace&lt;/strong&gt;: &lt;a href=&#34;https://spackpm.slack.com&#34;&gt;spackpm.slack.com&lt;/a&gt;. To get an invitation, visit &lt;a href=&#34;https://slack.spack.io&#34;&gt;slack.spack.io&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Mailing list&lt;/strong&gt;: &lt;a href=&#34;https://groups.google.com/d/forum/spack&#34;&gt;groups.google.com/d/forum/spack&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Twitter&lt;/strong&gt;: &lt;a href=&#34;https://twitter.com/spackpm&#34;&gt;@spackpm&lt;/a&gt;. Be sure to &lt;code&gt;@mention&lt;/code&gt; us!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributing to Spack is relatively easy. Just send us a &lt;a href=&#34;https://help.github.com/articles/using-pull-requests/&#34;&gt;pull request&lt;/a&gt;. When you send your request, make &lt;code&gt;develop&lt;/code&gt; the destination branch on the &lt;a href=&#34;https://github.com/spack/spack&#34;&gt;Spack repository&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Your PR must pass Spack&#39;s unit tests and documentation tests, and must be &lt;a href=&#34;https://www.python.org/dev/peps/pep-0008/&#34;&gt;PEP 8&lt;/a&gt; compliant. We enforce these guidelines with our CI process. To run these tests locally, and for helpful tips on git, see our &lt;a href=&#34;https://spack.readthedocs.io/en/latest/contribution_guide.html&#34;&gt;Contribution Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Spack&#39;s &lt;code&gt;develop&lt;/code&gt; branch has the latest contributions. Pull requests should target &lt;code&gt;develop&lt;/code&gt;, and users who want the latest package versions, features, etc. can use &lt;code&gt;develop&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Releases&lt;/h2&gt; &#xA;&lt;p&gt;For multi-user site deployments or other use cases that need very stable software installations, we recommend using Spack&#39;s &lt;a href=&#34;https://github.com/spack/spack/releases&#34;&gt;stable releases&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Each Spack release series also has a corresponding branch, e.g. &lt;code&gt;releases/v0.14&lt;/code&gt; has &lt;code&gt;0.14.x&lt;/code&gt; versions of Spack, and &lt;code&gt;releases/v0.13&lt;/code&gt; has &lt;code&gt;0.13.x&lt;/code&gt; versions. We backport important bug fixes to these branches but we do not advance the package versions or make other changes that would change the way Spack concretizes dependencies within a release branch. So, you can base your Spack deployment on a release branch and &lt;code&gt;git pull&lt;/code&gt; to get fixes, without the package churn that comes with &lt;code&gt;develop&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The latest release is always available with the &lt;code&gt;releases/latest&lt;/code&gt; tag.&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://spack.readthedocs.io/en/latest/developer_guide.html#releases&#34;&gt;docs on releases&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;Please note that Spack has a &lt;a href=&#34;https://raw.githubusercontent.com/spack/spack/develop/.github/CODE_OF_CONDUCT.md&#34;&gt;&lt;strong&gt;Code of Conduct&lt;/strong&gt;&lt;/a&gt;. By participating in the Spack community, you agree to abide by its rules.&lt;/p&gt; &#xA;&lt;h2&gt;Authors&lt;/h2&gt; &#xA;&lt;p&gt;Many thanks go to Spack&#39;s &lt;a href=&#34;https://github.com/spack/spack/graphs/contributors&#34;&gt;contributors&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Spack was created by Todd Gamblin, &lt;a href=&#34;mailto:tgamblin@llnl.gov&#34;&gt;tgamblin@llnl.gov&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Citing Spack&lt;/h3&gt; &#xA;&lt;p&gt;If you are referencing Spack in a publication, please cite the following paper:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Todd Gamblin, Matthew P. LeGendre, Michael R. Collette, Gregory L. Lee, Adam Moody, Bronis R. de Supinski, and W. Scott Futral. &lt;a href=&#34;https://www.computer.org/csdl/proceedings/sc/2015/3723/00/2807623.pdf&#34;&gt;&lt;strong&gt;The Spack Package Manager: Bringing Order to HPC Software Chaos&lt;/strong&gt;&lt;/a&gt;. In &lt;em&gt;Supercomputing 2015 (SC‚Äô15)&lt;/em&gt;, Austin, Texas, November 15-20 2015. LLNL-CONF-669890.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;On GitHub, you can copy this citation in APA or BibTeX format via the &#34;Cite this repository&#34; button. Or, see the comments in &lt;code&gt;CITATION.cff&lt;/code&gt; for the raw BibTeX.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Spack is distributed under the terms of both the MIT license and the Apache License (Version 2.0). Users may choose either license, at their option.&lt;/p&gt; &#xA;&lt;p&gt;All new contributions must be made under both the MIT and Apache-2.0 licenses.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/spack/spack/raw/develop/LICENSE-MIT&#34;&gt;LICENSE-MIT&lt;/a&gt;, &lt;a href=&#34;https://github.com/spack/spack/raw/develop/LICENSE-APACHE&#34;&gt;LICENSE-APACHE&lt;/a&gt;, &lt;a href=&#34;https://github.com/spack/spack/raw/develop/COPYRIGHT&#34;&gt;COPYRIGHT&lt;/a&gt;, and &lt;a href=&#34;https://github.com/spack/spack/raw/develop/NOTICE&#34;&gt;NOTICE&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;p&gt;SPDX-License-Identifier: (Apache-2.0 OR MIT)&lt;/p&gt; &#xA;&lt;p&gt;LLNL-CODE-811652&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>MaartenGr/BERTopic</title>
    <updated>2022-07-14T01:32:09Z</updated>
    <id>tag:github.com,2022-07-14:/MaartenGr/BERTopic</id>
    <link href="https://github.com/MaartenGr/BERTopic" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Leveraging BERT and c-TF-IDF to create easily interpretable topics.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://pypi.org/project/bertopic/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-v3.7+-blue.svg?sanitize=true&#34; alt=&#34;PyPI - Python&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/bertopic/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/MaartenGr/BERTopic/Code%20Checks/master&#34; alt=&#34;Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://maartengr.github.io/BERTopic/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-Passing-green.svg?sanitize=true&#34; alt=&#34;docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/bertopic/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/BERTopic&#34; alt=&#34;PyPI - PyPi&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/MaartenGr/VLAC/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-green.svg?sanitize=true&#34; alt=&#34;PyPI - License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2203.05794&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2203.05794-%3CCOLOR%3E.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;BERTopic&lt;/h1&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/MaartenGr/BERTopic/master/images/logo.png&#34; width=&#34;35%&#34; height=&#34;35%&#34; align=&#34;right&#34;&gt; &#xA;&lt;p&gt;BERTopic is a topic modeling technique that leverages ü§ó transformers and c-TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions.&lt;/p&gt; &#xA;&lt;p&gt;BERTopic supports &lt;a href=&#34;https://maartengr.github.io/BERTopic/getting_started/guided/guided.html&#34;&gt;&lt;strong&gt;guided&lt;/strong&gt;&lt;/a&gt;, (semi-) &lt;a href=&#34;https://maartengr.github.io/BERTopic/getting_started/supervised/supervised.html&#34;&gt;&lt;strong&gt;supervised&lt;/strong&gt;&lt;/a&gt;, and &lt;a href=&#34;https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html&#34;&gt;&lt;strong&gt;dynamic&lt;/strong&gt;&lt;/a&gt; topic modeling. It even supports visualizations similar to LDAvis!&lt;/p&gt; &#xA;&lt;p&gt;Corresponding medium posts can be found &lt;a href=&#34;https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6?source=friends_link&amp;amp;sk=0b5a470c006d1842ad4c8a3057063a99&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://towardsdatascience.com/interactive-topic-modeling-with-bertopic-1ea55e7d73d8?sk=03c2168e9e74b6bda2a1f3ed953427e4&#34;&gt;here&lt;/a&gt;. For a more detailed overview, you can read the &lt;a href=&#34;https://arxiv.org/abs/2203.05794&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Installation, with sentence-transformers, can be done using &lt;a href=&#34;https://pypi.org/project/bertopic/&#34;&gt;pypi&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install bertopic&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may want to install more depending on the transformers and language backends that you will be using. The possible installations are:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install bertopic[flair]&#xA;pip install bertopic[gensim]&#xA;pip install bertopic[spacy]&#xA;pip install bertopic[use]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;For an in-depth overview of the features of BERTopic you can check the full documentation &lt;a href=&#34;https://maartengr.github.io/BERTopic/&#34;&gt;here&lt;/a&gt; or you can follow along with one of the examples below:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Topic Modeling with BERTopic&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1FieRA9fLdkQEGDIMYl0I3MCjSUKVF8C-?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;(Custom) Embedding Models in BERTopic&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/18arPPe50szvcCp_Y6xS56H2tY0m-RLqv?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Advanced Customization in BERTopic&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1ClTYut039t-LDtlcd-oQAdXWgcsSGTw9?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;(semi-)Supervised Topic Modeling with BERTopic&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1bxizKzv5vfxJEB29sntU__ZC7PBSIPaQ?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Dynamic Topic Modeling with Trump&#39;s Tweets&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1un8ooI-7ZNlRoK0maVkYhmNRl0XGK88f?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Topic Modeling arXiv Abstracts&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/maartengr/topic-modeling-arxiv-abstract-with-bertopic&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?style=for-the-badge&amp;amp;message=Kaggle&amp;amp;color=222222&amp;amp;logo=Kaggle&amp;amp;logoColor=20BEFF&amp;amp;label=&#34; alt=&#34;Kaggle&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;We start by extracting topics from the well-known 20 newsgroups dataset containing English documents:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bertopic import BERTopic&#xA;from sklearn.datasets import fetch_20newsgroups&#xA; &#xA;docs = fetch_20newsgroups(subset=&#39;all&#39;,  remove=(&#39;headers&#39;, &#39;footers&#39;, &#39;quotes&#39;))[&#39;data&#39;]&#xA;&#xA;topic_model = BERTopic()&#xA;topics, probs = topic_model.fit_transform(docs)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After generating topics and their probabilities, we can access the frequent topics that were generated:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; topic_model.get_topic_info()&#xA;&#xA;Topic&#x9;Count&#x9;Name&#xA;-1&#x9;4630&#x9;-1_can_your_will_any&#xA;0&#x9;693&#x9;49_windows_drive_dos_file&#xA;1&#x9;466&#x9;32_jesus_bible_christian_faith&#xA;2&#x9;441&#x9;2_space_launch_orbit_lunar&#xA;3&#x9;381&#x9;22_key_encryption_keys_encrypted&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;-1 refers to all outliers and should typically be ignored. Next, let&#39;s take a look at the most frequent topic that was generated, topic 0:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; topic_model.get_topic(0)&#xA;&#xA;[(&#39;windows&#39;, 0.006152228076250982),&#xA; (&#39;drive&#39;, 0.004982897610645755),&#xA; (&#39;dos&#39;, 0.004845038866360651),&#xA; (&#39;file&#39;, 0.004140142872194834),&#xA; (&#39;disk&#39;, 0.004131678774810884),&#xA; (&#39;mac&#39;, 0.003624848635985097),&#xA; (&#39;memory&#39;, 0.0034840976976789903),&#xA; (&#39;software&#39;, 0.0034415334250699077),&#xA; (&#39;email&#39;, 0.0034239554442333257),&#xA; (&#39;pc&#39;, 0.003047105930670237)]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Use &lt;code&gt;BERTopic(language=&#34;multilingual&#34;)&lt;/code&gt; to select a model that supports 50+ languages.&lt;/p&gt; &#xA;&lt;h2&gt;Visualize Topics&lt;/h2&gt; &#xA;&lt;p&gt;After having trained our BERTopic model, we can iteratively go through hundreds of topics to get a good understanding of the topics that were extracted. However, that takes quite some time and lacks a global representation. Instead, we can visualize the topics that were generated in a way very similar to &lt;a href=&#34;https://github.com/cpsievert/LDAvis&#34;&gt;LDAvis&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;topic_model.visualize_topics()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/MaartenGr/BERTopic/master/images/topic_visualization.gif&#34; width=&#34;60%&#34; height=&#34;60%&#34; align=&#34;center&#34;&gt; &#xA;&lt;p&gt;We can create an overview of the most frequent topics in a way that they are easily interpretable. Horizontal barcharts typically convey information rather well and allow for an intuitive representation of the topics:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;topic_model.visualize_barchart()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/MaartenGr/BERTopic/master/images/topics.png&#34; width=&#34;70%&#34; height=&#34;70%&#34; align=&#34;center&#34;&gt; &#xA;&lt;p&gt;Find all possible visualizations with interactive examples in the documentation &lt;a href=&#34;https://maartengr.github.io/BERTopic/getting_started/visualization/visualization.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Embedding Models&lt;/h2&gt; &#xA;&lt;p&gt;BERTopic supports many embedding models that can be used to embed the documents and words:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Sentence-Transformers&lt;/li&gt; &#xA; &lt;li&gt;Flair&lt;/li&gt; &#xA; &lt;li&gt;Spacy&lt;/li&gt; &#xA; &lt;li&gt;Gensim&lt;/li&gt; &#xA; &lt;li&gt;USE&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/UKPLab/sentence-transformers&#34;&gt;&lt;strong&gt;Sentence-Transformers&lt;/strong&gt;&lt;/a&gt; is typically used as it has shown great results embedding documents meant for semantic similarity. Simply select any from their documentation &lt;a href=&#34;https://www.sbert.net/docs/pretrained_models.html&#34;&gt;here&lt;/a&gt; and pass it to BERTopic:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;topic_model = BERTopic(embedding_model=&#34;all-MiniLM-L6-v2&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/flairNLP/flair&#34;&gt;&lt;strong&gt;Flair&lt;/strong&gt;&lt;/a&gt; allows you to choose almost any ü§ó transformers model. Simply select any from &lt;a href=&#34;https://huggingface.co/models&#34;&gt;here&lt;/a&gt; and pass it to BERTopic:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from flair.embeddings import TransformerDocumentEmbeddings&#xA;&#xA;roberta = TransformerDocumentEmbeddings(&#39;roberta-base&#39;)&#xA;topic_model = BERTopic(embedding_model=roberta)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Click &lt;a href=&#34;https://maartengr.github.io/BERTopic/getting_started/embeddings/embeddings.html&#34;&gt;here&lt;/a&gt; for a full overview of all supported embedding models.&lt;/p&gt; &#xA;&lt;h2&gt;Dynamic Topic Modeling&lt;/h2&gt; &#xA;&lt;p&gt;Dynamic topic modeling (DTM) is a collection of techniques aimed at analyzing the evolution of topics over time. These methods allow you to understand how a topic is represented over time. Here, we will be using all of Donald Trump&#39;s tweet to see how he talked over certain topics over time:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import re&#xA;import pandas as pd&#xA;&#xA;trump = pd.read_csv(&#39;https://drive.google.com/uc?export=download&amp;amp;id=1xRKHaP-QwACMydlDnyFPEaFdtskJuBa6&#39;)&#xA;trump.text = trump.apply(lambda row: re.sub(r&#34;http\S+&#34;, &#34;&#34;, row.text).lower(), 1)&#xA;trump.text = trump.apply(lambda row: &#34; &#34;.join(filter(lambda x:x[0]!=&#34;@&#34;, row.text.split())), 1)&#xA;trump.text = trump.apply(lambda row: &#34; &#34;.join(re.sub(&#34;[^a-zA-Z]+&#34;, &#34; &#34;, row.text).split()), 1)&#xA;trump = trump.loc[(trump.isRetweet == &#34;f&#34;) &amp;amp; (trump.text != &#34;&#34;), :]&#xA;timestamps = trump.date.to_list()&#xA;tweets = trump.text.to_list()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, we need to extract the global topic representations by simply creating and training a BERTopic model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;topic_model = BERTopic(verbose=True)&#xA;topics, probs = topic_model.fit_transform(tweets)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;From these topics, we are going to generate the topic representations at each timestamp for each topic. We do this by simply calling &lt;code&gt;topics_over_time&lt;/code&gt; and pass in his tweets, the corresponding timestamps, and the related topics:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;topics_over_time = topic_model.topics_over_time(tweets, topics, timestamps, nr_bins=20)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, we can visualize the topics by simply calling &lt;code&gt;visualize_topics_over_time()&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=6)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/MaartenGr/BERTopic/master/images/dtm.gif&#34; width=&#34;80%&#34; height=&#34;80%&#34; align=&#34;center&#34;&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;BERTopic has quite a number of functions that quickly can become overwhelming. To alleviate this issue, you will find an overview of all methods and a short description of its purpose.&lt;/p&gt; &#xA;&lt;h3&gt;Common&lt;/h3&gt; &#xA;&lt;p&gt;For quick access to common functions, here is an overview of BERTopic&#39;s main methods:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Code&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Fit the model&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.fit(docs)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Fit the model and predict documents&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.fit_transform(docs)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Predict new documents&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.transform([new_doc])&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Access single topic&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.get_topic(topic=12)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Access all topics&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.get_topics()&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Get topic freq&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.get_topic_freq()&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Get all topic information&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.get_topic_info()&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Get representative docs per topic&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.get_representative_docs()&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Update topic representation&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.update_topics(docs, topics, n_gram_range=(1, 3))&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Generate topic labels&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.generate_topic_labels()&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Set topic labels&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.set_topic_labels(my_custom_labels)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Merge topics&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.merge_topics(docs, topics, topics_to_merge)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Reduce nr of topics&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.reduce_topics(docs, topics, nr_topics=30)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Find topics&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.find_topics(&#34;vehicle&#34;)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Save model&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.save(&#34;my_model&#34;)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Load model&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;BERTopic.load(&#34;my_model&#34;)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Get parameters&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.get_params()&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Variations&lt;/h3&gt; &#xA;&lt;p&gt;There are many different use cases in which topic modeling can be used. As such, a number of variations of BERTopic have been developed such that one package can be used across across many use cases:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Code&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;(semi-) Supervised Topic Modeling&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.fit(docs, y=y)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Topic Modeling per Class&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.topics_per_class(docs, topics, classes)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Dynamic Topic Modeling&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.topics_over_time(docs, topics, timestamps)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Hierarchical Topic Modeling&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.hierarchical_topics(docs, topics)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Guided Topic Modeling&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;BERTopic(seed_topic_list=seed_topic_list)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Visualizations&lt;/h3&gt; &#xA;&lt;p&gt;Evaluating topic models can be rather difficult due to the somewhat subjective nature of evaluation. Visualizing different aspects of the topic model helps in understanding the model and makes it easier to tweak the model to your liking.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Code&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Visualize Topics&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.visualize_topics()&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Visualize Documents&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.visualize_documents()&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Visualize Document Hierarchy&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.visualize_hierarchical_documents()&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Visualize Topic Hierarchy&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.visualize_hierarchy()&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Visualize Topic Tree&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.get_topic_tree(hierarchical_topics)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Visualize Topic Terms&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.visualize_barchart()&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Visualize Topic Similarity&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.visualize_heatmap()&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Visualize Term Score Decline&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.visualize_term_rank()&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Visualize Topic Probability Distribution&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.visualize_distribution(probs[0])&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Visualize Topics over Time&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.visualize_topics_over_time(topics_over_time)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Visualize Topics per Class&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;.visualize_topics_per_class(topics_per_class)&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;To cite the &lt;a href=&#34;https://arxiv.org/abs/2203.05794&#34;&gt;BERTopic paper&lt;/a&gt;, please use the following bibtex reference:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtext&#34;&gt;@article{grootendorst2022bertopic,&#xA;  title={BERTopic: Neural topic modeling with a class-based TF-IDF procedure},&#xA;  author={Grootendorst, Maarten},&#xA;  journal={arXiv preprint arXiv:2203.05794},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>