<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-20T01:41:19Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>karpathy/ng-video-lecture</title>
    <updated>2023-01-20T01:41:19Z</updated>
    <id>tag:github.com,2023-01-20:/karpathy/ng-video-lecture</id>
    <link href="https://github.com/karpathy/ng-video-lecture" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;nanogpt-lecture&lt;/h1&gt; &#xA;&lt;p&gt;Code created in the &lt;a href=&#34;https://karpathy.ai/zero-to-hero.html&#34;&gt;Neural Networks: Zero To Hero&lt;/a&gt; video lecture series, specifically on the first lecture on nanoGPT. Publishing here as a Github repo so people can easily hack it, walk through the &lt;code&gt;git log&lt;/code&gt; history of it, etc.&lt;/p&gt; &#xA;&lt;h3&gt;License&lt;/h3&gt; &#xA;&lt;p&gt;MIT&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>cleanlab/cleanlab</title>
    <updated>2023-01-20T01:41:19Z</updated>
    <id>tag:github.com,2023-01-20:/cleanlab/cleanlab</id>
    <link href="https://github.com/cleanlab/cleanlab" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The standard data-centric AI package for data quality and machine learning with messy, real-world data and labels.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/cleanlab_logo_open_source_transparent_optimized_size.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;cleanlab automatically detects problems in a ML dataset. This data-centric AI package facilitates &lt;strong&gt;machine learning with messy, real-world data&lt;/strong&gt; by providing &lt;strong&gt;clean lab&lt;/strong&gt;els for robust training and flagging errors in your data.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#xA;# cleanlab works with **any classifier**. Yup, you can use sklearn/PyTorch/TensorFlow/XGBoost/etc.&#xA;cl = cleanlab.classification.CleanLearning(sklearn.YourFavoriteClassifier())&#xA;&#xA;# cleanlab finds data and label issues in **any dataset**... in ONE line of code!&#xA;label_issues = cl.find_label_issues(data, labels)&#xA;&#xA;# cleanlab trains a robust version of your model that works more reliably with noisy data.&#xA;cl.fit(data, labels)&#xA;&#xA;# cleanlab estimates the predictions you would have gotten if you had trained with *no* label issues.&#xA;cl.predict(test_data)&#xA;&#xA;# A true data-centric AI package, cleanlab quantifies class-level issues and overall data quality, for any dataset.&#xA;cleanlab.dataset.health_summary(labels, confident_joint=cl.confident_joint)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Get started with: &lt;a href=&#34;https://docs.cleanlab.ai/&#34;&gt;documentation&lt;/a&gt;, &lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/image.html&#34;&gt;tutorials&lt;/a&gt;, &lt;a href=&#34;https://github.com/cleanlab/examples&#34;&gt;examples&lt;/a&gt;, and &lt;a href=&#34;https://cleanlab.ai/blog/&#34;&gt;blogs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Learn to run cleanlab on your data in 5 minutes for classification with: &lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/image.html&#34;&gt;image&lt;/a&gt;, &lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/text.html&#34;&gt;text&lt;/a&gt;, &lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/audio.html&#34;&gt;audio&lt;/a&gt;, or &lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/tabular.html&#34;&gt;tabular&lt;/a&gt; data.&lt;/li&gt; &#xA; &lt;li&gt;Use cleanlab to automatically: &lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/indepth_overview.html&#34;&gt;find mislabeled data + train robust models&lt;/a&gt;, &lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/outliers.html&#34;&gt;detect outliers&lt;/a&gt;, &lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/multiannotator.html&#34;&gt;estimate consensus + annotator-quality for multi-annotator datasets&lt;/a&gt;, &lt;a href=&#34;https://github.com/cleanlab/examples/raw/master/active_learning_multiannotator/active_learning.ipynb&#34;&gt;suggest which data is best to (re)label next&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pypi.org/pypi/cleanlab/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/cleanlab.svg?sanitize=true&#34; alt=&#34;pypi&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/pypi/cleanlab/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/platform-noarch-lightgrey&#34; alt=&#34;os&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/pypi/cleanlab/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.7%2B-blue&#34; alt=&#34;py_versions&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/cleanlab/cleanlab/actions?query=workflow%3ACI&#34;&gt;&lt;img src=&#34;https://github.com/cleanlab/cleanlab/workflows/CI/badge.svg?sanitize=true&#34; alt=&#34;build_status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://app.codecov.io/gh/cleanlab/cleanlab&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/cleanlab/cleanlab/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;coverage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.cleanlab.ai/&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?logo=github&amp;amp;style=flat&amp;amp;color=pink&amp;amp;label=docs&amp;amp;message=cleanlab&#34; alt=&#34;docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://cleanlab.ai/slack&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?logo=slack&amp;amp;style=flat&amp;amp;color=white&amp;amp;label=slack&amp;amp;message=community&#34; alt=&#34;Slack Community&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/CleanlabAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/CleanlabAI?style=social&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://cleanlab.ai/studio/?utm_source=github&amp;amp;utm_medium=readme&amp;amp;utm_campaign=clostostudio&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cleanlab/assets/master/shields/cl-studio-shield.svg?sanitize=true&#34; alt=&#34;Cleanlab Studio&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;News! (2022) &lt;/b&gt; -- cleanlab made accessible for everybody, not just ML researchers (&lt;b&gt;click to learn more&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;p&gt; &lt;/p&gt;&#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;b&gt;Nov 2022 ðŸ“–&lt;/b&gt; cleanlab 2.2.0 released! Added better algorithms for: label issues in multi-label classification, data with some classes absent, and estimating the number of label errors in a dataset. &lt;/li&gt; &#xA;  &lt;li&gt; &lt;b&gt;Sep 2022 ðŸ“–&lt;/b&gt; cleanlab 2.1.0 released! Added support for: data labeled by multiple annotators in cleanlab.multiannotator, token classification with text data in cleanlab.token_classification, out-of-distribution detection in cleanlab.outlier, and CleanLearning with non-numpy-array data (e.g. pandas dataframes, tensorflow/pytorch datasets, etc) in cleanlab.classification.CleanLearning. &lt;/li&gt; &#xA;  &lt;li&gt; &lt;b&gt;April 2022 ðŸ“–&lt;/b&gt; cleanlab 2.0.0 released! Lays foundations for this library to grow into a general-purpose data-centric AI toolkit. &lt;/li&gt; &#xA;  &lt;li&gt; &lt;b&gt;March 2022 ðŸ“–&lt;/b&gt; Documentation migrated to new website: &lt;a href=&#34;https://docs.cleanlab.ai/&#34;&gt;docs.cleanlab.ai&lt;/a&gt; with quickstart tutorials for image/text/audio/tabular data.&lt;/li&gt; &#xA;  &lt;li&gt; &lt;b&gt;Feb 2022 ðŸ’»&lt;/b&gt; &lt;a href=&#34;https://docs.cleanlab.ai/master/migrating/migrate_v2.html&#34;&gt;APIs simplified&lt;/a&gt; to make cleanlab accessible for everybody, not just ML researchers &lt;/li&gt; &#xA;  &lt;li&gt; &lt;b&gt;Long-time cleanlab user?&lt;/b&gt; Here&#39;s &lt;a href=&#34;https://docs.cleanlab.ai/stable/migrating/migrate_v2.html&#34;&gt;how to migrate&lt;/a&gt; to cleanlab versions &amp;gt;= 2.0.0. &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;News! (2021) &lt;/b&gt; -- cleanlab finds pervasive label errors in the most common ML datasets (&lt;b&gt;click to learn more&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;p&gt; &lt;/p&gt;&#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;b&gt;Dec 2021 ðŸŽ‰&lt;/b&gt; NeurIPS published the &lt;a href=&#34;https://arxiv.org/abs/2103.14749&#34;&gt;label errors paper (Northcutt, Athalye, &amp;amp; Mueller, 2021)&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt; &lt;b&gt;Apr 2021 ðŸŽ‰&lt;/b&gt; Journal of AI Research published the &lt;a href=&#34;https://jair.org/index.php/jair/article/view/12125&#34;&gt;confident learning paper (Northcutt, Jiang, &amp;amp; Chuang, 2021)&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt; &lt;b&gt;Mar 2021 ðŸ˜²&lt;/b&gt; cleanlab used to find and fix label issues in 10 of the most common ML benchmark datasets, published in: &lt;a href=&#34;https://neurips.cc/Conferences/2021/ScheduleMultitrack?event=22763&#34;&gt;NeurIPS 2021&lt;/a&gt;. Along with &lt;a href=&#34;https://arxiv.org/abs/2103.14749&#34;&gt;the paper (Northcutt, Athalye, &amp;amp; Mueller, 2021)&lt;/a&gt;, the authors launched &lt;a href=&#34;https://labelerrors.com&#34;&gt;labelerrors.com&lt;/a&gt; where you can view the label issues in these datasets.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;News! (2020) &lt;/b&gt; -- cleanlab supports all OS, achieves state-of-the-art performance (&lt;b&gt;click to learn more&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;p&gt; &lt;/p&gt;&#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;b&gt;Dec 2020 ðŸŽ‰&lt;/b&gt; cleanlab supports NeurIPS workshop paper &lt;a href=&#34;https://securedata.lol/camera_ready/28.pdf&#34;&gt;(Northcutt, Athalye, &amp;amp; Lin, 2020)&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt; &lt;b&gt;Dec 2020 ðŸ¤–&lt;/b&gt; cleanlab supports &lt;a href=&#34;https://github.com/cleanlab/cleanlab/raw/master/cleanlab/classification.py#L215&#34;&gt;PU learning&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt; &lt;b&gt;Feb 2020 ðŸ¤–&lt;/b&gt; cleanlab now natively supports Mac, Linux, and Windows.&lt;/li&gt; &#xA;  &lt;li&gt; &lt;b&gt;Feb 2020 ðŸ¤–&lt;/b&gt; cleanlab now supports &lt;a href=&#34;https://github.com/cleanlab/cleanlab/raw/master/cleanlab/experimental/coteaching.py&#34;&gt;Co-Teaching&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/1804.06872&#34;&gt;(Han et al., 2018)&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;li&gt; &lt;b&gt;Jan 2020 ðŸŽ‰&lt;/b&gt; cleanlab achieves state-of-the-art on CIFAR-10 with noisy labels. Code to reproduce: &lt;a href=&#34;https://github.com/cleanlab/examples/tree/master/contrib/v1/cifar10&#34;&gt;examples/cifar10&lt;/a&gt;. This is a great place to see how to use cleanlab on real datasets (with predicted probabilities from trained model already precomputed for you).&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;Release notes for past versions are &lt;a href=&#34;https://github.com/cleanlab/cleanlab/releases&#34;&gt;here&lt;/a&gt;. Details behind updates are explained in our &lt;a href=&#34;https://cleanlab.ai/blog/&#34;&gt;blog&lt;/a&gt; and &lt;a href=&#34;https://cleanlab.ai/research/&#34;&gt;research papers&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;So fresh, so cleanlab&lt;/h2&gt; &#xA;&lt;p&gt;cleanlab &lt;strong&gt;clean&lt;/strong&gt;s your data&#39;s &lt;strong&gt;lab&lt;/strong&gt;els via state-of-the-art &lt;em&gt;confident learning&lt;/em&gt; algorithms, published in this &lt;a href=&#34;https://jair.org/index.php/jair/article/view/12125&#34;&gt;paper&lt;/a&gt; and &lt;a href=&#34;https://l7.curtisnorthcutt.com/confident-learning&#34;&gt;blog&lt;/a&gt;. See some of the datasets cleaned with cleanlab at &lt;a href=&#34;https://labelerrors.com&#34;&gt;labelerrors.com&lt;/a&gt;. This package helps you find data and label issues so you can train reliable ML models.&lt;/p&gt; &#xA;&lt;p&gt;cleanlab is:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;backed by theory&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;with &lt;a href=&#34;https://arxiv.org/abs/1911.00068&#34;&gt;provable guarantees&lt;/a&gt; of exact estimation of noise and label errors, even with imperfect models.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;fast&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Code is parallelized (&amp;lt; 1 second to find label issues in ImageNet with pre-computed predictions).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;easy-to-use&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Find label issues or train noise-robust models in one line of code (no hyperparameters by default).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;general&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Works with &lt;strong&gt;&lt;a href=&#34;https://labelerrors.com/&#34;&gt;any dataset&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;any model&lt;/strong&gt;, e.g., TensorFlow, PyTorch, sklearn, XGBoost, Huggingface, etc.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/label-errors-examples.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; Examples of incorrect given labels in various image datasets &lt;a href=&#34;https://l7.curtisnorthcutt.com/label-errors&#34;&gt;found and corrected&lt;/a&gt; using cleanlab. &lt;/p&gt; &#xA;&lt;h2&gt;Run cleanlab&lt;/h2&gt; &#xA;&lt;p&gt;cleanlab supports Linux, macOS, and Windows and runs on Python 3.7+.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Get started &lt;a href=&#34;https://docs.cleanlab.ai/&#34;&gt;here&lt;/a&gt;! Install via &lt;code&gt;pip&lt;/code&gt; or &lt;code&gt;conda&lt;/code&gt; as described &lt;a href=&#34;https://docs.cleanlab.ai/&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Developers who install the bleeding-edge from source should refer to &lt;a href=&#34;https://docs.cleanlab.ai/master/index.html&#34;&gt;this master branch documentation&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Use cleanlab with any model for most ML tasks&lt;/h2&gt; &#xA;&lt;p&gt;All features of cleanlab work with &lt;strong&gt;any dataset&lt;/strong&gt; and &lt;strong&gt;any model&lt;/strong&gt;. Yes, any model: scikit-learn, PyTorch, Tensorflow, Keras, JAX, HuggingFace, MXNet, XGBoost, etc. If you use a sklearn-compatible classifier, all cleanlab methods work out-of-the-box.&lt;/p&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt; Itâ€™s also easy to use your favorite non-sklearn-compatible model (&lt;b&gt;click to learn more&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;cleanlab can find label issues from any model&#39;s predicted class probabilities if you can produce them yourself.&lt;/p&gt; &#xA; &lt;p&gt;Some other cleanlab functionality requires your model to be sklearn-compatible. There&#39;s nothing you need to do if your model already has &lt;code&gt;.fit()&lt;/code&gt;, &lt;code&gt;.predict()&lt;/code&gt;, and &lt;code&gt;.predict_proba()&lt;/code&gt; methods. Otherwise, just wrap your custom model into a Python class that inherits the &lt;code&gt;sklearn.base.BaseEstimator&lt;/code&gt;:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.base import BaseEstimator&#xA;class YourFavoriteModel(BaseEstimator): # Inherits sklearn base classifier&#xA;    def __init__(self, ):&#xA;        pass  # ensure this re-initializes parameters for neural net models&#xA;    def fit(self, X, y, sample_weight=None):&#xA;        pass&#xA;    def predict(self, X):&#xA;        pass&#xA;    def predict_proba(self, X):&#xA;        pass&#xA;    def score(self, X, y, sample_weight=None):&#xA;        pass&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;This inheritance allows to apply a wide range of sklearn functionality like hyperparameter-optimization to your custom model. Now you can use your model with every method in cleanlab. Here&#39;s one example:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from cleanlab.classification import CleanLearning&#xA;cl = CleanLearning(clf=YourFavoriteModel())  # has all the same methods of YourFavoriteModel&#xA;cl.fit(train_data, train_labels_with_errors)&#xA;cl.predict(test_data)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;Want to see a working example? &lt;a href=&#34;https://github.com/cleanlab/cleanlab/raw/master/cleanlab/experimental/mnist_pytorch.py&#34;&gt;Hereâ€™s a compliant PyTorch MNIST CNN class&lt;/a&gt;&lt;/h4&gt; &#xA; &lt;p&gt;More details are provided in documentation of &lt;a href=&#34;https://docs.cleanlab.ai/stable/cleanlab/classification.html&#34;&gt;cleanlab.classification.CleanLearning&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;p&gt;Note, some libraries exist to give you sklearn-compatibility for free. For PyTorch, check out the &lt;a href=&#34;https://skorch.readthedocs.io/&#34;&gt;skorch&lt;/a&gt; Python library which will wrap your PyTorch model into a sklearn-compatible model (&lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/image.html&#34;&gt;example&lt;/a&gt;). For TensorFlow/Keras, check out &lt;a href=&#34;https://www.adriangb.com/scikeras/&#34;&gt;SciKeras&lt;/a&gt; (&lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/text.html&#34;&gt;example&lt;/a&gt;) or &lt;a href=&#34;https://docs.cleanlab.ai/stable/cleanlab/experimental/keras.html&#34;&gt;our own Keras wrapper&lt;/a&gt;. Many libraries also already offer a special scikit-learn API, for example: &lt;a href=&#34;https://xgboost.readthedocs.io/en/stable/python/python_api.html#module-xgboost.sklearn&#34;&gt;XGBoost&lt;/a&gt; or &lt;a href=&#34;https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html&#34;&gt;LightGBM&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;br&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;cleanlab is useful across a wide variety of Machine Learning tasks. Specific tasks this package offers dedicated functionality for include:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/indepth_overview.html&#34;&gt;Binary and multi-class classification&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html&#34;&gt;Multi-label classification&lt;/a&gt; (e.g. image/document tagging)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/token_classification.html&#34;&gt;Token classification&lt;/a&gt; (e.g. entity recognition in text)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/multiannotator.html&#34;&gt;Classification with data labeled by multiple annotators&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cleanlab/examples/raw/master/active_learning_multiannotator/active_learning.ipynb&#34;&gt;Active learning with multiple annotators&lt;/a&gt; (suggest which data to label or re-label to improve model most)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/outliers.html&#34;&gt;Out of distribution detection&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For many other ML tasks, cleanlab can still help you improve your dataset if appropriately applied.&lt;/p&gt; &#xA;&lt;h2&gt;Cool cleanlab applications&lt;/h2&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt; Reproducing results in &lt;a href=&#34;https://arxiv.org/abs/1911.00068&#34;&gt;Confident Learning paper&lt;/a&gt; (&lt;b&gt;click to learn more&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;For additional details, check out the: &lt;a href=&#34;https://github.com/cgnorthcutt/confidentlearning-reproduce&#34;&gt;confidentlearning-reproduce repository&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;h3&gt;State of the Art Learning with Noisy Labels in CIFAR&lt;/h3&gt; &#xA; &lt;p&gt;A step-by-step guide to reproduce these results is available &lt;a href=&#34;https://github.com/cleanlab/examples/tree/master/contrib/v1/cifar10&#34;&gt;here&lt;/a&gt;. This guide is also a good tutorial for using cleanlab on any large dataset. You&#39;ll need to &lt;code&gt;git clone&lt;/code&gt; &lt;a href=&#34;https://github.com/cgnorthcutt/confidentlearning-reproduce&#34;&gt;confidentlearning-reproduce&lt;/a&gt; which contains the data and files needed to reproduce the CIFAR-10 results.&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/cifar10_benchmarks.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA; &lt;p&gt;Comparison of confident learning (CL), as implemented in cleanlab, versus seven recent methods for learning with noisy labels in CIFAR-10. Highlighted cells show CL robustness to sparsity. The five CL methods estimate label issues, remove them, then train on the cleaned data using &lt;a href=&#34;https://github.com/cleanlab/cleanlab/raw/master/cleanlab/experimental/coteaching.py&#34;&gt;Co-Teaching&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;p&gt;Observe how cleanlab (i.e. the CL method) is robust to large sparsity in label noise whereas prior art tends to reduce in performance for increased sparsity, as shown by the red highlighted regions. This is important because real-world label noise is often sparse, e.g. a tiger is likely to be mislabeled as a lion, but not as most other classes like airplane, bathtub, and microwave.&lt;/p&gt; &#xA; &lt;h3&gt;Find label issues in ImageNet&lt;/h3&gt; &#xA; &lt;p&gt;Use cleanlab to identify ~100,000 label errors in the 2012 ILSVRC ImageNet training dataset: &lt;a href=&#34;https://github.com/cleanlab/examples/tree/master/contrib/v1/imagenet&#34;&gt;examples/imagenet&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/imagenet_train_label_errors_32.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA; &lt;p&gt;Label issues in ImageNet train set found via cleanlab. Label Errors are boxed in red. Ontological issues in green. Multi-label images in blue.&lt;/p&gt; &#xA; &lt;h3&gt;Find Label Errors in MNIST&lt;/h3&gt; &#xA; &lt;p&gt;Use cleanlab to identify ~50 label errors in the MNIST dataset: &lt;a href=&#34;https://github.com/cleanlab/examples/tree/master/contrib/v1/mnist&#34;&gt;examples/mnist&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/mnist_training_label_errors24_prune_by_noise_rate.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA; &lt;p&gt;Top 24 least-confident labels in the original MNIST &lt;strong&gt;train&lt;/strong&gt; dataset, algorithmically identified via cleanlab. Examples are ordered left-right, top-down by increasing self-confidence (predicted probability that the &lt;strong&gt;given&lt;/strong&gt; label is correct), denoted &lt;strong&gt;conf&lt;/strong&gt; in teal. The most-likely correct label (with largest predicted probability) is in green. Overt label errors highlighted in red.&lt;/p&gt; &#xA; &lt;br&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt; Learning with noisy labels across 4 data distributions and 9 classifiers (&lt;b&gt;click to learn more&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;cleanlab is a general tool that can learn with noisy labels regardless of dataset distribution or classifier type: &lt;a href=&#34;https://github.com/cleanlab/examples/raw/master/classifier_comparison/classifier_comparison.ipynb&#34;&gt;examples/classifier_comparison&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/demo_cleanlab_across_datasets_and_classifiers.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA; &lt;p&gt;Each sub-figure above depicts the decision boundary learned using &lt;a href=&#34;https://github.com/cleanlab/cleanlab/raw/master/cleanlab/classification.py#L141&#34;&gt;cleanlab.classification.CleanLearning&lt;/a&gt; in the presence of extreme (~35%) label errors (circled in green). Label noise is class-conditional (not uniformly random). Columns are organized by the classifier used, except the left-most column which depicts the ground-truth data distribution. Rows are organized by dataset.&lt;/p&gt; &#xA; &lt;p&gt;Each sub-figure depicts accuracy scores on a test set (with correct non-noisy labels) as decimal values:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;LEFT (in black): The classifier test accuracy trained with perfect labels (no label errors).&lt;/li&gt; &#xA;  &lt;li&gt;MIDDLE (in blue): The classifier test accuracy trained with noisy labels using cleanlab.&lt;/li&gt; &#xA;  &lt;li&gt;RIGHT (in white): The baseline classifier test accuracy trained with noisy labels.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;As an example, the table below is the noise matrix (noisy channel) *P(s | y) characterizing the label noise for the first dataset row in the figure. &lt;em&gt;s&lt;/em&gt; represents the observed noisy labels and &lt;em&gt;y&lt;/em&gt; represents the latent, true labels. The trace of this matrix is 2.6. A trace of 4 implies no label noise. A cell in this matrix is read like: &#34;Around 38% of true underlying &#39;3&#39; labels were randomly flipped to &#39;2&#39; labels in the observed dataset.&#34;&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;&lt;code&gt;p(labelï¸±y)&lt;/code&gt;&lt;/th&gt; &#xA;    &lt;th&gt;y=0&lt;/th&gt; &#xA;    &lt;th&gt;y=1&lt;/th&gt; &#xA;    &lt;th&gt;y=2&lt;/th&gt; &#xA;    &lt;th&gt;y=3&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;label=0&lt;/td&gt; &#xA;    &lt;td&gt;0.55&lt;/td&gt; &#xA;    &lt;td&gt;0.01&lt;/td&gt; &#xA;    &lt;td&gt;0.07&lt;/td&gt; &#xA;    &lt;td&gt;0.06&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;label=1&lt;/td&gt; &#xA;    &lt;td&gt;0.22&lt;/td&gt; &#xA;    &lt;td&gt;0.87&lt;/td&gt; &#xA;    &lt;td&gt;0.24&lt;/td&gt; &#xA;    &lt;td&gt;0.02&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;label=2&lt;/td&gt; &#xA;    &lt;td&gt;0.12&lt;/td&gt; &#xA;    &lt;td&gt;0.04&lt;/td&gt; &#xA;    &lt;td&gt;0.64&lt;/td&gt; &#xA;    &lt;td&gt;0.38&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;label=3&lt;/td&gt; &#xA;    &lt;td&gt;0.11&lt;/td&gt; &#xA;    &lt;td&gt;0.08&lt;/td&gt; &#xA;    &lt;td&gt;0.05&lt;/td&gt; &#xA;    &lt;td&gt;0.54&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;br&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt; ML research using cleanlab (&lt;b&gt;click to learn more&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;Researchers may find some components of this package useful for evaluating algorithms for ML with noisy labels. For additional details/notation, refer to &lt;a href=&#34;https://jair.org/index.php/jair/article/view/12125&#34;&gt;the Confident Learning paper&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;h3&gt;Methods to Standardize Research with Noisy Labels&lt;/h3&gt; &#xA; &lt;p&gt;cleanlab supports a number of functions to generate noise for benchmarking and standardization in research. This next example shows how to generate valid, class-conditional, uniformly random noisy channel matrices:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Generate a valid (necessary conditions for learnability are met) noise matrix for any trace &amp;gt; 1&#xA;from cleanlab.benchmarking.noise_generation import generate_noise_matrix_from_trace&#xA;noise_matrix=generate_noise_matrix_from_trace(&#xA;    K=number_of_classes,&#xA;    trace=float_value_greater_than_1_and_leq_K,&#xA;    py=prior_of_y_actual_labels_which_is_just_an_array_of_length_K,&#xA;    frac_zero_noise_rates=float_from_0_to_1_controlling_sparsity,&#xA;)&#xA;&#xA;# Check if a noise matrix is valid (necessary conditions for learnability are met)&#xA;from cleanlab.benchmarking.noise_generation import noise_matrix_is_valid&#xA;is_valid=noise_matrix_is_valid(&#xA;    noise_matrix,&#xA;    prior_of_y_which_is_just_an_array_of_length_K,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;For a given noise matrix, this example shows how to generate noisy labels. Methods can be seeded for reproducibility.&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Generate noisy labels using the noise_marix. Guarantees exact amount of noise in labels.&#xA;from cleanlab.benchmarking.noise_generation import generate_noisy_labels&#xA;s_noisy_labels = generate_noisy_labels(y_hidden_actual_labels, noise_matrix)&#xA;&#xA;# This package is a full of other useful methods for learning with noisy labels.&#xA;# The tutorial stops here, but you don&#39;t have to. Inspect method docstrings for full docs.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;br&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt; cleanlab for advanced users (&lt;b&gt;click to learn more&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;Many methods and their default parameters are not covered here. Check out the &lt;a href=&#34;https://docs.cleanlab.ai/master/&#34;&gt;documentation for the master branch version&lt;/a&gt; for the full suite of features supported by the cleanlab API.&lt;/p&gt; &#xA; &lt;h2&gt;Use any custom model&#39;s predicted probabilities to find label errors in 1 line of code&lt;/h2&gt; &#xA; &lt;p&gt;pred_probs (num_examples x num_classes matrix of predicted probabilities) should already be computed on your own, with any classifier. For best results, pred_probs should be obtained in a holdout/out-of-sample manner (e.g. via cross-validation).&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;cleanlab can do this for you via &lt;a href=&#34;https://docs.cleanlab.ai/master/cleanlab/count.html&#34;&gt;&lt;code&gt;cleanlab.count.estimate_cv_predicted_probabilities&lt;/code&gt;&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;Tutorial with more info: [&lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/pred_probs_cross_val.html&#34;&gt;here&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;li&gt;Examples how to compute pred_probs with: [&lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/image.html&#34;&gt;CNN image classifier (PyTorch)&lt;/a&gt;], [&lt;a href=&#34;https://docs.cleanlab.ai/stable/tutorials/text.html&#34;&gt;NN text classifier (TensorFlow)&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# label issues are ordered by likelihood of being an error. First index is most likely error.&#xA;from cleanlab.filter import find_label_issues&#xA;&#xA;ordered_label_issues = find_label_issues(  # One line of code!&#xA;    labels=numpy_array_of_noisy_labels,&#xA;    pred_probs=numpy_array_of_predicted_probabilities,&#xA;    return_indices_ranked_by=&#39;normalized_margin&#39;, # Orders label issues&#xA; )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;Pre-computed &lt;strong&gt;out-of-sample&lt;/strong&gt; predicted probabilities for CIFAR-10 train set are available: &lt;a href=&#34;https://github.com/cleanlab/examples/tree/master/contrib/v1/cifar10#pre-computed-psx-for-every-noise--sparsity-condition&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;h2&gt;Fully characterize label noise and uncertainty in your dataset.&lt;/h2&gt; &#xA; &lt;p&gt;&lt;em&gt;s&lt;/em&gt; denotes a random variable that represents the observed, noisy label and &lt;em&gt;y&lt;/em&gt; denotes a random variable representing the hidden, actual labels. Both &lt;em&gt;s&lt;/em&gt; and &lt;em&gt;y&lt;/em&gt; take any of the m classes as values. The cleanlab package supports different levels of granularity for computation depending on the needs of the user. Because of this, we support multiple alternatives, all no more than a few lines, to estimate these latent distribution arrays, enabling the user to reduce computation time by only computing what they need to compute, as seen in the examples below.&lt;/p&gt; &#xA; &lt;p&gt;Throughout these examples, youâ€™ll see a variable called &lt;em&gt;confident_joint&lt;/em&gt;. The confident joint is an m x m matrix (m is the number of classes) that counts, for every observed, noisy class, the number of examples that confidently belong to every latent, hidden class. It counts the number of examples that we are confident are labeled correctly or incorrectly for every pair of observed and unobserved classes. The confident joint is an unnormalized estimate of the complete-information latent joint distribution, &lt;em&gt;Ps,y&lt;/em&gt;.&lt;/p&gt; &#xA; &lt;p&gt;The label flipping rates are denoted &lt;em&gt;P(s | y)&lt;/em&gt;, the inverse rates are &lt;em&gt;P(y | s)&lt;/em&gt;, and the latent prior of the unobserved, true labels, &lt;em&gt;p(y)&lt;/em&gt;.&lt;/p&gt; &#xA; &lt;p&gt;Most of the methods in the &lt;strong&gt;cleanlab&lt;/strong&gt; package start by first estimating the &lt;em&gt;confident_joint&lt;/em&gt;. You can learn more about this in the &lt;a href=&#34;https://arxiv.org/abs/1911.00068&#34;&gt;confident learning paper&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;h3&gt;Option 1: Compute the confident joint and predicted probs first. Stop if thatâ€™s all you need.&lt;/h3&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from cleanlab.count import estimate_latent&#xA;from cleanlab.count import estimate_confident_joint_and_cv_pred_proba&#xA;&#xA;# Compute the confident joint and the n x m predicted probabilities matrix (pred_probs),&#xA;# for n examples, m classes. Stop here if all you need is the confident joint.&#xA;confident_joint, pred_probs = estimate_confident_joint_and_cv_pred_proba(&#xA;    X=X_train,&#xA;    labels=train_labels_with_errors,&#xA;    clf=logreg(), # default, you can use any classifier&#xA;)&#xA;&#xA;# Estimate latent distributions: p(y) as est_py, P(s|y) as est_nm, and P(y|s) as est_inv&#xA;est_py, est_nm, est_inv = estimate_latent(&#xA;    confident_joint,&#xA;    labels=train_labels_with_errors,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h3&gt;Option 2: Estimate the latent distribution matrices in a single line of code.&lt;/h3&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from cleanlab.count import estimate_py_noise_matrices_and_cv_pred_proba&#xA;est_py, est_nm, est_inv, confident_joint, pred_probs = estimate_py_noise_matrices_and_cv_pred_proba(&#xA;    X=X_train,&#xA;    labels=train_labels_with_errors,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h3&gt;Option 3: Skip computing the predicted probabilities if you already have them.&lt;/h3&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Already have pred_probs? (n x m matrix of predicted probabilities)&#xA;# For example, you might get them from a pre-trained model (like resnet on ImageNet)&#xA;# With the cleanlab package, you estimate directly with pred_probs.&#xA;from cleanlab.count import estimate_py_and_noise_matrices_from_probabilities&#xA;est_py, est_nm, est_inv, confident_joint = estimate_py_and_noise_matrices_from_probabilities(&#xA;    labels=train_labels_with_errors,&#xA;    pred_probs=pred_probs,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h2&gt;Completely characterize label noise in a dataset:&lt;/h2&gt; &#xA; &lt;p&gt;The joint probability distribution of noisy and true labels, &lt;em&gt;P(s,y)&lt;/em&gt;, completely characterizes label noise with a class-conditional &lt;em&gt;m x m&lt;/em&gt; matrix.&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from cleanlab.count import estimate_joint&#xA;joint = estimate_joint(&#xA;    labels=noisy_labels,&#xA;    pred_probs=probabilities,&#xA;    confident_joint=None,  # Provide if you have it already&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;br&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt; Positive-Unlabeled Learning (&lt;b&gt;click to learn more&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;Positive-Unlabeled (PU) learning (in which your data only contains a few positively labeled examples with the rest unlabeled) is just a special case of &lt;a href=&#34;https://github.com/cleanlab/cleanlab/raw/master/cleanlab/classification.py#L141&#34;&gt;CleanLearning&lt;/a&gt; when one of the classes has no error. &lt;code&gt;P&lt;/code&gt; stands for the positive class and &lt;strong&gt;is assumed to have zero label errors&lt;/strong&gt; and &lt;code&gt;U&lt;/code&gt; stands for unlabeled data, but in practice, we just assume the &lt;code&gt;U&lt;/code&gt; class is a noisy negative class that actually contains some positive examples. Thus, the goal of PU learning is to (1) estimate the proportion of negatively labeled examples that actually belong to the positive class (see&lt;code&gt;fraction\_noise\_in\_unlabeled\_class&lt;/code&gt; in the last example), (2) find the errors (see last example), and (3) train on clean data (see first example below). cleanlab does all three, taking into account that there are no label errors in whichever class you specify as positive.&lt;/p&gt; &#xA; &lt;p&gt;There are two ways to use cleanlab for PU learning. We&#39;ll look at each here.&lt;/p&gt; &#xA; &lt;p&gt;Method 1. If you are using the cleanlab classifier &lt;a href=&#34;https://github.com/cleanlab/cleanlab/raw/master/cleanlab/classification.py#L141&#34;&gt;CleanLearning()&lt;/a&gt;, and your dataset has exactly two classes (positive = 1, and negative = 0), PU learning is supported directly in cleanlab. You can perform PU learning like this:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from cleanlab.classification import CleanLearning&#xA;from sklearn.linear_model import LogisticRegression&#xA;# Wrap around any classifier. Yup, you can use sklearn/pyTorch/TensorFlow/FastText/etc.&#xA;pu_class = 0 # Should be 0 or 1. Label of class with NO ERRORS. (e.g., P class in PU)&#xA;cl = CleanLearning(clf=LogisticRegression(), pulearning=pu_class)&#xA;cl.fit(X=X_train_data, labels=train_noisy_labels)&#xA;# Estimate the predictions you would have gotten by training with *no* label errors.&#xA;predicted_test_labels = cl.predict(X_test)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;Method 2. However, you might be using a more complicated classifier that doesn&#39;t work well with &lt;a href=&#34;https://github.com/cleanlab/cleanlab/raw/master/cleanlab/classification.py#L141&#34;&gt;CleanLearning&lt;/a&gt; (see this example for CIFAR-10). Or you might have 3 or more classes. Here&#39;s how to use cleanlab for PU learning in this situation. To let cleanlab know which class has no error (in standard PU learning, this is the P class), you need to set the threshold for that class to 1 (1 means the probability that the labels of that class are correct is 1, i.e. that class has no error). Here&#39;s the code:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np&#xA;# K is the number of classes in your dataset&#xA;# pred_probs are the cross-validated predicted probabilities.&#xA;# s is the array/list/iterable of noisy labels&#xA;# pu_class is a 0-based integer for the class that has no label errors.&#xA;thresholds = np.asarray([np.mean(pred_probs[:, k][s == k]) for k in range(K)])&#xA;thresholds[pu_class] = 1.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;Now you can use cleanlab however you were before. Just be sure to pass in &lt;code&gt;thresholds&lt;/code&gt; as a parameter wherever it applies. For example:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Uncertainty quantification (characterize the label noise&#xA;# by estimating the joint distribution of noisy and true labels)&#xA;cj = compute_confident_joint(s, pred_probs, thresholds=thresholds, )&#xA;# Now the noise (cj) has been estimated taking into account that some class(es) have no error.&#xA;# We can use cj to find label errors like this:&#xA;indices_of_label_issues = find_label_issues(s, pred_probs, confident_joint=cj, )&#xA;&#xA;# In addition to label issues, cleanlab can find the fraction of noise in the unlabeled class.&#xA;# First we need the inv_noise_matrix which contains P(y|s) (proportion of mislabeling).&#xA;_, _, inv_noise_matrix = estimate_latent(confident_joint=cj, labels=s, )&#xA;# Because inv_noise_matrix contains P(y|s), p (y = anything | labels = pu_class) should be 0&#xA;# because the prob(true label is something else | example is in pu_class) is 0.&#xA;# What&#39;s more interesting is p(y = anything | s is not put_class), or in the binary case&#xA;# this translates to p(y = pu_class | s = 1 - pu_class) because pu_class is 0 or 1.&#xA;# So, to find the fraction_noise_in_unlabeled_class, for binary, you just compute:&#xA;fraction_noise_in_unlabeled_class = inv_noise_matrix[pu_class][1 - pu_class]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;Now that you have &lt;code&gt;indices_of_label_errors&lt;/code&gt;, you can remove those label issues and train on clean data (or only remove some of the label issues and iteratively use confident learning / cleanlab to improve results).&lt;/p&gt; &#xA; &lt;br&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;Many other practical applications are demonstrated in our &lt;a href=&#34;https://github.com/cleanlab/examples&#34;&gt;Example Notebooks&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Citation and related publications&lt;/h2&gt; &#xA;&lt;p&gt;cleanlab is based on peer-reviewed research. Here are relevant papers to cite if you use this package:&lt;/p&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;a href=&#34;https://arxiv.org/abs/1911.00068&#34;&gt;Confident Learning (JAIR &#39;21)&lt;/a&gt; (&lt;b&gt;click to show bibtex&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;@article{northcutt2021confidentlearning,&#xA;    title={Confident Learning: Estimating Uncertainty in Dataset Labels},&#xA;    author={Curtis G. Northcutt and Lu Jiang and Isaac L. Chuang},&#xA;    journal={Journal of Artificial Intelligence Research (JAIR)},&#xA;    volume={70},&#xA;    pages={1373--1411},&#xA;    year={2021}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;a href=&#34;https://arxiv.org/abs/1705.01936&#34;&gt;Rank Pruning (UAI &#39;17)&lt;/a&gt; (&lt;b&gt;click to show bibtex&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;@inproceedings{northcutt2017rankpruning,&#xA;    author={Northcutt, Curtis G. and Wu, Tailin and Chuang, Isaac L.},&#xA;    title={Learning with Confident Examples: Rank Pruning for Robust Classification with Noisy Labels},&#xA;    booktitle = {Proceedings of the Thirty-Third Conference on Uncertainty in Artificial Intelligence},&#xA;    series = {UAI&#39;17},&#xA;    year = {2017},&#xA;    location = {Sydney, Australia},&#xA;    numpages = {10},&#xA;    url = {http://auai.org/uai2017/proceedings/papers/35.pdf},&#xA;    publisher = {AUAI Press},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;a href=&#34;https://people.csail.mit.edu/jonasmueller/info/LabelQuality_icml.pdf&#34;&gt; Label Quality Scoring (ICML &#39;22)&lt;/a&gt; (&lt;b&gt;click to show bibtex&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;@inproceedings{kuan2022labelquality,&#xA;    title={Model-agnostic label quality scoring to detect real-world label errors},&#xA;    author={Kuan, Johnson and Mueller, Jonas},&#xA;    booktitle={ICML DataPerf Workshop},&#xA;    year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;a href=&#34;https://arxiv.org/abs/2207.03061&#34;&gt; Out-of-Distribution Detection (ICML &#39;22)&lt;/a&gt; (&lt;b&gt;click to show bibtex&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;@inproceedings{kuan2022ood,&#xA;    title={Back to the Basics: Revisiting Out-of-Distribution Detection Baselines},&#xA;    author={Kuan, Johnson and Mueller, Jonas},&#xA;    booktitle={ICML Workshop on Principles of Distribution Shift},&#xA;    year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.03920&#34;&gt; Token Classification Label Errors (NeurIPS &#39;22)&lt;/a&gt; (&lt;b&gt;click to show bibtex&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;@inproceedings{wang2022tokenerrors,&#xA;    title={Detecting label errors in token classification data},&#xA;    author={Wang, Wei-Chen and Mueller, Jonas},&#xA;    booktitle={NeurIPS Workshop on Interactive Learning for Natural Language Processing (InterNLP)},&#xA;    year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.06812&#34;&gt; CROWDLAB for data with multiple annotators (NeurIPS &#39;22)&lt;/a&gt; (&lt;b&gt;click to show bibtex&lt;/b&gt;) &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;@inproceedings{goh2022crowdlab,&#xA;    title={Utilizing supervised models to infer consensus labels and their quality from data with multiple annotators},&#xA;    author={Goh, Hui Wen and Tkachenko, Ulyana and Mueller, Jonas},&#xA;    booktitle={NeurIPS Human in the Loop Learning Workshop},&#xA;    year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;To understand/cite other cleanlab functionality not described above, check out our &lt;a href=&#34;https://cleanlab.ai/research/&#34;&gt;additional publications&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Other resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://cleanlab.ai/blog/&#34;&gt;Cleanlab Blog&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://l7.curtisnorthcutt.com/confident-learning&#34;&gt;Blog post: Introduction to Confident Learning&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.14749&#34;&gt;NeurIPS 2021 paper: Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://cleanlab.ai/studio/?utm_source=github&amp;amp;utm_medium=readme&amp;amp;utm_campaign=clostostudio&#34;&gt;Cleanlab Studio&lt;/a&gt;: No-code Data Improvement&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;While this open-source library &lt;strong&gt;finds&lt;/strong&gt; data issues, an interface is needed to efficiently &lt;strong&gt;fix&lt;/strong&gt; these issues in your dataset. &lt;a href=&#34;https://cleanlab.ai/studio/?utm_source=github&amp;amp;utm_medium=readme&amp;amp;utm_campaign=clostostudio&#34;&gt;Cleanlab Studio&lt;/a&gt; is a no-code platform to find and fix problems in real-world ML datasets. Studio automatically runs optimized versions of the algorithms from this open-source library on top of AutoML models fit to your data, and presents detected issues in a smart data editing interface. Think of it like a data cleaning assistant that helps you quickly improve the quality of your data (via AI/automation + streamlined UX).&lt;/p&gt; &#xA;&lt;h2&gt;Join our community&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;The best place to learn is &lt;a href=&#34;https://cleanlab.ai/slack&#34;&gt;our Slack community&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Have ideas for the future of cleanlab? How are you using cleanlab? &lt;a href=&#34;https://github.com/cleanlab/cleanlab/discussions&#34;&gt;Join the discussion&lt;/a&gt; and check out &lt;a href=&#34;https://github.com/cleanlab/cleanlab/projects&#34;&gt;our active/planned Projects and what we could use your help with&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Interested in contributing? See the &lt;a href=&#34;https://raw.githubusercontent.com/cleanlab/cleanlab/master/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt; and &lt;a href=&#34;https://github.com/cleanlab/cleanlab/wiki#ideas-for-contributing-to-cleanlab&#34;&gt;ideas on useful contributions&lt;/a&gt;. We welcome your help building a standard open-source library for data-centric AI!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Have code improvements for cleanlab? See the &lt;a href=&#34;https://raw.githubusercontent.com/cleanlab/cleanlab/master/DEVELOPMENT.md&#34;&gt;development guide&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Have an issue with cleanlab? &lt;a href=&#34;https://github.com/cleanlab/cleanlab/issues?q=is%3Aissue&#34;&gt;Search existing issues&lt;/a&gt; or &lt;a href=&#34;https://github.com/cleanlab/cleanlab/issues/new&#34;&gt;submit a new issue&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Need professional help with cleanlab? Join our &lt;a href=&#34;https://cleanlab.ai/slack&#34;&gt;#help Slack channel&lt;/a&gt; and message one of our core developers, Jonas Mueller, or schedule a meeting via email: &lt;a href=&#34;mailto:team@cleanlab.ai&#34;&gt;team@cleanlab.ai&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright (c) 2017-2023 Cleanlab Inc.&lt;/p&gt; &#xA;&lt;p&gt;cleanlab is free software: you can redistribute it and/or modify it under the terms of the GNU Affero General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.&lt;/p&gt; &#xA;&lt;p&gt;cleanlab is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/cleanlab/cleanlab/raw/master/LICENSE&#34;&gt;GNU Affero General Public LICENSE&lt;/a&gt; for details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>pdm-project/pdm</title>
    <updated>2023-01-20T01:41:19Z</updated>
    <id>tag:github.com,2023-01-20:/pdm-project/pdm</id>
    <link href="https://github.com/pdm-project/pdm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A modern Python package and dependency manager supporting the latest PEP standards&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;PDM&lt;/h1&gt; &#xA; &lt;p&gt;A modern Python package and dependency manager supporting the latest PEP standards. &lt;a href=&#34;https://raw.githubusercontent.com/pdm-project/pdm/main/README_zh.md&#34;&gt;ä¸­æ–‡ç‰ˆæœ¬è¯´æ˜Ž&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pdm-project/pdm/main/docs/docs/assets/logo_big.png&#34; alt=&#34;PDM logo&#34;&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://pdm.fming.dev&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Docs-mkdocs-blue?style=for-the-badge&#34; alt=&#34;Docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/pdm_project&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/pdm_project?label=get%20updates&amp;amp;logo=twitter&amp;amp;style=for-the-badge&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/Phn8smztpv&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/824472774965329931?label=discord&amp;amp;logo=discord&amp;amp;style=for-the-badge&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://github.com/pdm-project/pdm/workflows/Tests/badge.svg?sanitize=true&#34; alt=&#34;Github Actions&#34;&gt; &lt;a href=&#34;https://pypi.org/project/pdm&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/pdm?logo=python&amp;amp;logoColor=%23cccccc&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/pdm-project/pdm&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/pdm-project/pdm/branch/main/graph/badge.svg?token=erZTquL5n0&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://repology.org/project/pdm/versions&#34;&gt;&lt;img src=&#34;https://repology.org/badge/tiny-repos/pdm.svg?sanitize=true&#34; alt=&#34;Packaging status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/pdm&#34;&gt;&lt;img src=&#34;https://pepy.tech/badge/pdm/week&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pdm.fming.dev&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/pdm-managed-blueviolet&#34; alt=&#34;pdm-managed&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://trackgit.com&#34;&gt; &lt;img src=&#34;https://us-central1-trackgit-analytics.cloudfunctions.net/token/ping/l4eztudjnh9bfay668fl&#34; alt=&#34;trackgit-views&#34;&gt; &lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://asciinema.org/a/jnifN30pjfXbO9We2KqOdXEhB&#34;&gt;&lt;img src=&#34;https://asciinema.org/a/jnifN30pjfXbO9We2KqOdXEhB.svg?sanitize=true&#34; alt=&#34;asciicast&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;What is PDM?&lt;/h2&gt; &#xA;&lt;p&gt;PDM is meant to be a next generation Python package management tool. It was originally built for personal use. If you feel you are going well with &lt;code&gt;Pipenv&lt;/code&gt; or &lt;code&gt;Poetry&lt;/code&gt; and don&#39;t want to introduce another package manager, just stick to it. But if you are missing something that is not present in those tools, you can probably find some goodness in &lt;code&gt;pdm&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Highlights of features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Opt-in &lt;a href=&#34;https://www.python.org/dev/peps/pep-0582&#34;&gt;PEP 582&lt;/a&gt; support, no virtualenv involved at all.&lt;/li&gt; &#xA; &lt;li&gt;Simple and fast dependency resolver, mainly for large binary distributions.&lt;/li&gt; &#xA; &lt;li&gt;A &lt;a href=&#34;https://www.python.org/dev/peps/pep-0517&#34;&gt;PEP 517&lt;/a&gt; build backend.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.python.org/dev/peps/pep-0621&#34;&gt;PEP 621&lt;/a&gt; project metadata.&lt;/li&gt; &#xA; &lt;li&gt;Flexible and powerful plug-in system.&lt;/li&gt; &#xA; &lt;li&gt;Versatile user scripts.&lt;/li&gt; &#xA; &lt;li&gt;Opt-in centralized installation cache like &lt;a href=&#34;https://pnpm.io/motivation#saving-disk-space-and-boosting-installation-speed&#34;&gt;pnpm&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What is PEP 582?&lt;/h2&gt; &#xA;&lt;p&gt;The majority of Python packaging tools also act as virtualenv managers to gain the ability to isolate project environments. But things get tricky when it comes to nested venvs: One installs the virtualenv manager using a venv encapsulated Python, and create more venvs using the tool which is based on an encapsulated Python. One day a minor release of Python is released and one has to check all those venvs and upgrade them if required.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.python.org/dev/peps/pep-0582&#34;&gt;PEP 582&lt;/a&gt;, on the other hand, introduces a way to decouple the Python interpreter from project environments. It is a relatively new proposal and there are not many tools supporting it (one that does is &lt;a href=&#34;https://github.com/David-OConnor/pyflow&#34;&gt;pyflow&lt;/a&gt;, but it is written with Rust and thus can&#39;t get much help from the big Python community and for the same reason it can&#39;t act as a &lt;a href=&#34;https://www.python.org/dev/peps/pep-0517&#34;&gt;PEP 517&lt;/a&gt; backend).&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.python.org/dev/peps/pep-0582&#34;&gt;PEP 582&lt;/a&gt; proposes a project structure as below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;foo&#xA;    __pypackages__&#xA;        3.8&#xA;            lib&#xA;                bottle&#xA;    myscript.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There is a &lt;code&gt;__pypackages__&lt;/code&gt; directory in the project root to hold all dependent libraries, just like what &lt;code&gt;npm&lt;/code&gt; does. Read more about the specification &lt;a href=&#34;https://www.python.org/dev/peps/pep-0582/#specification&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;PDM requires python version 3.7 or higher.&lt;/p&gt; &#xA;&lt;h3&gt;Via Install Script&lt;/h3&gt; &#xA;&lt;p&gt;Like Pip, PDM provides an installation script that will install PDM into an isolated environment.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;For Linux/Mac&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -sSL https://raw.githubusercontent.com/pdm-project/pdm/main/install-pdm.py | python3 -&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;For Windows&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;(Invoke-WebRequest -Uri https://raw.githubusercontent.com/pdm-project/pdm/main/install-pdm.py -UseBasicParsing).Content | python -&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For security reasons, you should verify the checksum of &lt;code&gt;install-pdm.py&lt;/code&gt;. The sha256 checksum is: &lt;code&gt;ed83f61b7ad3c3fcace57fda31175ad861c4283aeea02ba13b6351a66c2cca60&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;The installer will install PDM into the user site and the location depends on the system:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;$HOME/.local/bin&lt;/code&gt; for Unix&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;%APPDATA%\Python\Scripts&lt;/code&gt; on Windows&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can pass additional options to the script to control how PDM is installed:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;usage: install-pdm.py [-h] [-v VERSION] [--prerelease] [--remove] [-p PATH] [-d DEP]&#xA;&#xA;optional arguments:&#xA;  -h, --help            show this help message and exit&#xA;  -v VERSION, --version VERSION | envvar: PDM_VERSION&#xA;                        Specify the version to be installed, or HEAD to install from the main branch&#xA;  --prerelease | envvar: PDM_PRERELEASE    Allow prereleases to be installed&#xA;  --remove | envvar: PDM_REMOVE            Remove the PDM installation&#xA;  -p PATH, --path PATH | envvar: PDM_HOME  Specify the location to install PDM&#xA;  -d DEP, --dep DEP | envvar: PDM_DEPS     Specify additional dependencies, can be given multiple times&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can either pass the options after the script or set the env var value.&lt;/p&gt; &#xA;&lt;h3&gt;Alternative Installation Methods&lt;/h3&gt; &#xA;&lt;p&gt;If you are on MacOS and using &lt;code&gt;homebrew&lt;/code&gt;, install it by:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install pdm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you are on Windows and using &lt;a href=&#34;https://scoop.sh/&#34;&gt;Scoop&lt;/a&gt;, install it by:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;scoop bucket add frostming https://github.com/frostming/scoop-frostming.git&#xA;scoop install pdm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Otherwise, it is recommended to install &lt;code&gt;pdm&lt;/code&gt; in an isolated environment with &lt;code&gt;pipx&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pipx install pdm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or you can install it under a user site:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install --user pdm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;With &lt;a href=&#34;https://asdf-vm.com/&#34;&gt;asdf-vm&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;asdf plugin add pdm&#xA;asdf install pdm latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Initialize a new PDM project&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pdm init&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Answer the questions following the guide, and a PDM project with a &lt;code&gt;pyproject.toml&lt;/code&gt; file will be ready to use.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Install dependencies&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pdm add requests flask&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can add multiple dependencies in the same command. After a while, check the &lt;code&gt;pdm.lock&lt;/code&gt; file to see what is locked for each package.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Run your script with &lt;a href=&#34;https://www.python.org/dev/peps/pep-0582&#34;&gt;PEP 582&lt;/a&gt; support&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;By default, PDM will create &lt;code&gt;.venv&lt;/code&gt; in the project root, when doing &lt;code&gt;pdm install&lt;/code&gt; on an existing project, as other package managers do. But you can make PEP 582 the default by &lt;code&gt;pdm config python.use_venv false&lt;/code&gt;. To enable the full power of PEP 582, do the following steps to make the Python interpreter use it.&lt;/p&gt; &#xA;&lt;p&gt;Suppose you have a script &lt;code&gt;app.py&lt;/code&gt; placed next to the &lt;code&gt;__pypackages__&lt;/code&gt; directory with the following content(taken from Flask&#39;s website):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from flask import Flask&#xA;app = Flask(__name__)&#xA;&#xA;@app.route(&#39;/&#39;)&#xA;def hello_world():&#xA;    return &#39;Hello World!&#39;&#xA;&#xA;if __name__ == &#39;__main__&#39;:&#xA;    app.run()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you are a Bash user, set the environment variable by &lt;code&gt;eval &#34;$(pdm --pep582)&#34;&lt;/code&gt;. Now you can run the app directly with your familiar &lt;strong&gt;Python interpreter&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ python /home/frostming/workspace/flask_app/app.py&#xA; * Serving Flask app &#34;app&#34; (lazy loading)&#xA; ...&#xA; * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Ta-da! You are running an app with its dependencies installed in an isolated place, while no virtualenv is involved.&lt;/p&gt; &#xA;&lt;p&gt;For Windows users, please refer to &lt;a href=&#34;https://pdm.fming.dev/latest/usage/pep582/#enable-pep-582-globally&#34;&gt;the doc&lt;/a&gt; about how to make it work, it also includes a simple explanation of how it works.&lt;/p&gt; &#xA;&lt;h2&gt;Badges&lt;/h2&gt; &#xA;&lt;p&gt;Tell people you are using PDM in your project by including the markdown code in README.md:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;[![pdm-managed](https://img.shields.io/badge/pdm-managed-blueviolet)](https://pdm.fming.dev)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pdm.fming.dev&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/pdm-managed-blueviolet&#34; alt=&#34;pdm-managed&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Packaging Status&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://repology.org/project/pdm/versions&#34;&gt;&lt;img src=&#34;https://repology.org/badge/vertical-allrepos/pdm.svg?sanitize=true&#34; alt=&#34;Packaging status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;PDM Eco-system&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/pdm-project/awesome-pdm&#34;&gt;Awesome PDM&lt;/a&gt; is a curated list of awesome PDM plugins and resources.&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;h3&gt;1. What is put in &lt;code&gt;__pypackages__&lt;/code&gt;?&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.python.org/dev/peps/pep-0582&#34;&gt;PEP 582&lt;/a&gt; is a draft proposal which still needs a lot of polishing. For instance, it doesn&#39;t mention how to manage CLI executables. PDM makes the decision to put &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;include&lt;/code&gt; together with &lt;code&gt;lib&lt;/code&gt; under &lt;code&gt;__pypackages__/X.Y&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;2. How do I run CLI scripts in the local package directory?&lt;/h3&gt; &#xA;&lt;p&gt;The recommended way is to prefix your command with &lt;code&gt;pdm run&lt;/code&gt;. It is also possible to run CLI scripts directly from the outside. PDM&#39;s installer has already injected the package path to the &lt;code&gt;sys.path&lt;/code&gt; in the entry script file.&lt;/p&gt; &#xA;&lt;h3&gt;3. What site-packages will be loaded when using PDM?&lt;/h3&gt; &#xA;&lt;p&gt;Packages in the local &lt;code&gt;__pypackages__&lt;/code&gt; directory will be loaded before the system-level &lt;code&gt;site-packages&lt;/code&gt; for isolation.&lt;/p&gt; &#xA;&lt;h3&gt;4. Can I relocate or move the &lt;code&gt;__pypackages__&lt;/code&gt; folder for deployment?&lt;/h3&gt; &#xA;&lt;p&gt;You&#39;d better not. The packages installed inside &lt;code&gt;__pypackages__&lt;/code&gt; are OS dependent. Instead, you should keep &lt;code&gt;pdm.lock&lt;/code&gt; in VCS and do &lt;code&gt;pdm sync&lt;/code&gt; on the target environment to deploy.&lt;/p&gt; &#xA;&lt;h2&gt;Sponsors&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://cdn.jsdelivr.net/gh/pdm-project/sponsors/sponsors.svg&#34;&gt; &lt;img src=&#34;https://cdn.jsdelivr.net/gh/pdm-project/sponsors/sponsors.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;This project is strongly inspired by &lt;a href=&#34;https://github.com/David-OConnor/pyflow&#34;&gt;pyflow&lt;/a&gt; and &lt;a href=&#34;https://github.com/python-poetry/poetry&#34;&gt;poetry&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is open sourced under MIT license, see the &lt;a href=&#34;https://raw.githubusercontent.com/pdm-project/pdm/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for more details.&lt;/p&gt;</summary>
  </entry>
</feed>