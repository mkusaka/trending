<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-02T01:43:09Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>saltstack/salt</title>
    <updated>2023-06-02T01:43:09Z</updated>
    <id>tag:github.com,2023-06-02:/saltstack/salt</id>
    <link href="https://github.com/saltstack/salt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Software to automate the management and configuration of any infrastructure or application at scale. Get access to the Salt software package repository here:&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/github/license/saltstack/salt&#34;&gt;https://img.shields.io/github/license/saltstack/salt&lt;/a&gt; :alt: Salt Project License: Apache v2.0 :target: &lt;a href=&#34;https://github.com/saltstack/salt/raw/master/LICENSE&#34;&gt;https://github.com/saltstack/salt/blob/master/LICENSE&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/pypi/dm/salt?label=pypi%20downloads&#34;&gt;https://img.shields.io/pypi/dm/salt?label=pypi%20downloads&lt;/a&gt; :alt: PyPi Package Downloads :target: &lt;a href=&#34;https://pypi.org/project/salt&#34;&gt;https://pypi.org/project/salt&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/lgtm/grade/python/github/saltstack/salt&#34;&gt;https://img.shields.io/lgtm/grade/python/github/saltstack/salt&lt;/a&gt; :alt: PyPi Package Downloads :target: &lt;a href=&#34;https://lgtm.com/projects/g/saltstack/salt/context:python&#34;&gt;https://lgtm.com/projects/g/saltstack/salt/context:python&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/badge/slack-@saltstackcommunity-blue.svg?logo=slack&#34;&gt;https://img.shields.io/badge/slack-@saltstackcommunity-blue.svg?logo=slack&lt;/a&gt; :alt: Salt Project Slack Community :target: &lt;a href=&#34;https://join.slack.com/t/saltstackcommunity/shared_invite/zt-3av8jjyf-oBQ2M0vhXOhJpNpRkPWBvg&#34;&gt;https://join.slack.com/t/saltstackcommunity/shared_invite/zt-3av8jjyf-oBQ2M0vhXOhJpNpRkPWBvg&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/twitch/status/saltprojectoss&#34;&gt;https://img.shields.io/twitch/status/saltprojectoss&lt;/a&gt; :alt: Salt Project Twitch Channel :target: &lt;a href=&#34;https://www.twitch.tv/saltprojectoss&#34;&gt;https://www.twitch.tv/saltprojectoss&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/reddit/subreddit-subscribers/saltstack?style=social&#34;&gt;https://img.shields.io/reddit/subreddit-subscribers/saltstack?style=social&lt;/a&gt; :alt: Salt Project subreddit :target: &lt;a href=&#34;https://www.reddit.com/r/saltstack/&#34;&gt;https://www.reddit.com/r/saltstack/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/twitter/follow/Salt_Project_OS?style=social&amp;amp;logo=twitter&#34;&gt;https://img.shields.io/twitter/follow/Salt_Project_OS?style=social&amp;amp;logo=twitter&lt;/a&gt; :alt: Follow SaltStack on Twitter :target: &lt;a href=&#34;https://twitter.com/intent/follow?screen_name=Salt_Project_OS&#34;&gt;https://twitter.com/intent/follow?screen_name=Salt_Project_OS&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. figure:: &lt;a href=&#34;https://gitlab.com/saltstack/open/salt-branding-guide/-/raw/master/logos/SaltProject_altlogo_teal.png?inline=true&#34;&gt;https://gitlab.com/saltstack/open/salt-branding-guide/-/raw/master/logos/SaltProject_altlogo_teal.png?inline=true&lt;/a&gt; :scale: 80 % :width: 1000px :height: 356px :align: center :alt: Salt Project Logo&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Latest Salt Documentation&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Open an issue&lt;/code&gt;_ (bug report, feature request, etc.)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;em&gt;Salt is the world&#39;s fastest, most intelligent and scalable automation&lt;/em&gt; &lt;em&gt;engine.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h1&gt;About Salt&lt;/h1&gt; &#xA;&lt;p&gt;Built on Python, Salt is an event-driven automation tool and framework to deploy, configure, and manage complex IT systems. Use Salt to automate common infrastructure administration tasks and ensure that all the components of your infrastructure are operating in a consistent desired state.&lt;/p&gt; &#xA;&lt;p&gt;Salt has many possible uses, including configuration management, which involves:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Managing operating system deployment and configuration.&lt;/li&gt; &#xA; &lt;li&gt;Installing and configuring software applications and services.&lt;/li&gt; &#xA; &lt;li&gt;Managing servers, virtual machines, containers, databases, web servers, network devices, and more.&lt;/li&gt; &#xA; &lt;li&gt;Ensuring consistent configuration and preventing configuration drift.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Salt is ideal for configuration management because it is pluggable, customizable, and plays well with many existing technologies. Salt enables you to deploy and manage applications that use any tech stack running on nearly any &lt;code&gt;operating system &amp;lt;https://docs.saltproject.io/salt/install-guide/en/latest/topics/salt-supported-operating-systems.html&amp;gt;&lt;/code&gt;_, including different types of network devices such as switches and routers from a variety of vendors.&lt;/p&gt; &#xA;&lt;p&gt;In addition to configuration management Salt can also:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Automate and orchestrate routine IT processes, such as common required tasks for scheduled server downtimes or upgrading operating systems or applications.&lt;/li&gt; &#xA; &lt;li&gt;Create self-aware, self-healing systems that can automatically respond to outages, common administration problems, or other important events.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;About our sponsors&lt;/h1&gt; &#xA;&lt;p&gt;Salt powers VMware&#39;s &lt;code&gt;vRealize Automation SaltStack Config&lt;/code&gt;_, and can be found under the hood of products from Juniper, Cisco, Cloudflare, Nutanix, SUSE, and Tieto, to name a few.&lt;/p&gt; &#xA;&lt;p&gt;The original sponsor of our community, SaltStack, was &lt;code&gt;acquired by VMware in 2020 &amp;lt;https://www.vmware.com/company/acquisitions/saltstack.html&amp;gt;&lt;/code&gt;_. The Salt Project remains an open source ecosystem that VMware supports and contributes to. VMware ensures the code integrity and quality of the Salt modules by acting as the official sponsor and manager of the Salt project. Many of the core Salt Project contributors are also VMware employees. This team carefully reviews and enhances the Salt modules to ensure speed, quality, and security.&lt;/p&gt; &#xA;&lt;h1&gt;Download and install Salt&lt;/h1&gt; &#xA;&lt;p&gt;Salt is tested and packaged to run on CentOS, Debian, RHEL, Ubuntu, MacOS, Windows, and more. Download Salt and get started now. See &lt;code&gt;supported operating systems &amp;lt;https://docs.saltproject.io/salt/install-guide/en/latest/topics/salt-supported-operating-systems.html&amp;gt;&lt;/code&gt;_ for more information.&lt;/p&gt; &#xA;&lt;p&gt;To download and install Salt, see:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;The Salt install guide &amp;lt;https://docs.saltproject.io/salt/install-guide/en/latest/index.html&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Salt Project repository &amp;lt;https://repo.saltproject.io/&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Technical support&lt;/h1&gt; &#xA;&lt;p&gt;Report bugs or problems using Salt by opening an issue: &lt;code&gt;&amp;lt;https://github.com/saltstack/salt/issues&amp;gt;&lt;/code&gt;_&lt;/p&gt; &#xA;&lt;p&gt;To join our community forum where you can exchange ideas, best practices, discuss technical support questions, and talk to project maintainers, join our Slack workspace: &lt;code&gt;Salt Project Community Slack&lt;/code&gt;_&lt;/p&gt; &#xA;&lt;h1&gt;Salt Project documentation&lt;/h1&gt; &#xA;&lt;p&gt;Installation instructions, tutorials, in-depth API and module documentation:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;The Salt install guide &amp;lt;https://docs.saltproject.io/salt/install-guide/en/latest/index.html&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;The Salt user guide &amp;lt;https://docs.saltproject.io/salt/user-guide/en/latest/&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Latest Salt documentation&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Salt&#39;s contributing guide &amp;lt;https://docs.saltproject.io/en/master/topics/development/contributing.html&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Security advisories&lt;/h1&gt; &#xA;&lt;p&gt;Keep an eye on the Salt Project &lt;code&gt;Security Announcements &amp;lt;https://saltproject.io/security-announcements/&amp;gt;&lt;/code&gt;_ landing page. Salt Project recommends subscribing to the &lt;code&gt;Salt Project Security RSS feed &amp;lt;https://saltproject.io/feed/?post_type=security&amp;gt;&lt;/code&gt;_ to receive notification when new information is available regarding security announcements.&lt;/p&gt; &#xA;&lt;p&gt;Other channels to receive security announcements include the &lt;code&gt;Salt Community mailing list &amp;lt;https://groups.google.com/forum/#!forum/salt-users&amp;gt;&lt;/code&gt;_ and the &lt;code&gt;Salt Project Community Slack&lt;/code&gt;_.&lt;/p&gt; &#xA;&lt;p&gt;Responsibly reporting security vulnerabilities ++++++++++++++++++++++++++++++++++++++++++++++ When reporting security vulnerabilities for Salt or other SaltStack projects, refer to the &lt;code&gt;SECURITY.md&lt;/code&gt;_ file found in this repository.&lt;/p&gt; &#xA;&lt;h1&gt;Join our community&lt;/h1&gt; &#xA;&lt;p&gt;Salt is built by the Salt Project community, which includes more than 3,000 contributors working in roles just like yours. This well-known and trusted community works together to improve the underlying technology and extend Salt by creating a variety of execution and state modules to accomplish the most common tasks or solve the most important problems that people in your role are likely to face.&lt;/p&gt; &#xA;&lt;p&gt;If you want to help extend Salt or solve a problem with Salt, you can join our community and contribute today.&lt;/p&gt; &#xA;&lt;p&gt;Please be sure to review our &lt;code&gt;Code of Conduct &amp;lt;https://github.com/saltstack/salt/blob/master/CODE_OF_CONDUCT.md&amp;gt;&lt;/code&gt;_. Also, check out some of our community resources including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Salt Project Community Wiki &amp;lt;https://github.com/saltstack/community/wiki&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Salt Project Community Slack&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Salt Project: IRC on LiberaChat &amp;lt;https://web.libera.chat/#salt&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Salt Project YouTube channel &amp;lt;https://www.youtube.com/channel/UCpveTIucFx9ljGelW63-BWg&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Salt Project Twitch channel &amp;lt;https://www.twitch.tv/saltprojectoss&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;There are lots of ways to get involved in our community. Every month, there are around a dozen opportunities to meet with other contributors and the Salt Core team and collaborate in real time. The best way to keep track is by subscribing to the &lt;strong&gt;Salt Project Community Events Calendar&lt;/strong&gt; on the main &lt;code&gt;&amp;lt;https://saltproject.io&amp;gt;&lt;/code&gt;_ website.&lt;/p&gt; &#xA;&lt;p&gt;If you have additional questions, email us at &lt;a href=&#34;mailto:saltproject@vmware.com&#34;&gt;saltproject@vmware.com&lt;/a&gt; or reach out directly to the Community Manager, Jimmy Chunga via Slack. We&#39;d be glad to have you join our community!&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;Salt is licensed under the Apache 2.0 license. Please see the &lt;code&gt;LICENSE file &amp;lt;https://github.com/saltstack/salt/blob/master/LICENSE&amp;gt;&lt;/code&gt;_ for the full text of the Apache license, followed by a full summary of the licensing used by external modules.&lt;/p&gt; &#xA;&lt;p&gt;A complete list of attributions and dependencies can be found here: &lt;code&gt;salt/DEPENDENCIES.md &amp;lt;https://github.com/saltstack/salt/blob/master/DEPENDENCIES.md&amp;gt;&lt;/code&gt;_&lt;/p&gt; &#xA;&lt;p&gt;.. _Salt Project Community Slack: &lt;a href=&#34;https://join.slack.com/t/saltstackcommunity/shared_invite/zt-3av8jjyf-oBQ2M0vhXOhJpNpRkPWBvg&#34;&gt;https://join.slack.com/t/saltstackcommunity/shared_invite/zt-3av8jjyf-oBQ2M0vhXOhJpNpRkPWBvg&lt;/a&gt; .. _vRealize Automation SaltStack Config: &lt;a href=&#34;https://www.vmware.com/products/vrealize-automation/saltstack-config.html&#34;&gt;https://www.vmware.com/products/vrealize-automation/saltstack-config.html&lt;/a&gt; .. _Latest Salt Documentation: &lt;a href=&#34;https://docs.saltproject.io/en/latest/&#34;&gt;https://docs.saltproject.io/en/latest/&lt;/a&gt; .. _Open an issue: &lt;a href=&#34;https://github.com/saltstack/salt/issues/new/choose&#34;&gt;https://github.com/saltstack/salt/issues/new/choose&lt;/a&gt; .. _SECURITY.md: &lt;a href=&#34;https://github.com/saltstack/salt/raw/master/SECURITY.md&#34;&gt;https://github.com/saltstack/salt/blob/master/SECURITY.md&lt;/a&gt; .. _Calendar html: &lt;a href=&#34;https://outlook.office365.com/owa/calendar/105f69bacd4541baa849529aed37eb2d@vmware.com/434ec2155b2b4cce90144c87f0dd03d56626754050155294962/calendar.html&#34;&gt;https://outlook.office365.com/owa/calendar/105f69bacd4541baa849529aed37eb2d@vmware.com/434ec2155b2b4cce90144c87f0dd03d56626754050155294962/calendar.html&lt;/a&gt; .. _Calendar ics: &lt;a href=&#34;https://outlook.office365.com/owa/calendar/105f69bacd4541baa849529aed37eb2d@vmware.com/434ec2155b2b4cce90144c87f0dd03d56626754050155294962/calendar.ics&#34;&gt;https://outlook.office365.com/owa/calendar/105f69bacd4541baa849529aed37eb2d@vmware.com/434ec2155b2b4cce90144c87f0dd03d56626754050155294962/calendar.ics&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>princeton-nlp/MeZO</title>
    <updated>2023-06-02T01:43:09Z</updated>
    <id>tag:github.com,2023-06-02:/princeton-nlp/MeZO</id>
    <link href="https://github.com/princeton-nlp/MeZO" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MeZO: Fine-Tuning Language Models with Just Forward Passes&lt;/h1&gt; &#xA;&lt;p&gt;This is the implementation for the paper &#34;Fine-Tuning Language Models with Just Forward Passes&#34;.&lt;/p&gt; &#xA;&lt;p&gt;We are still actively cleaning the code base. A better version of README is coming soon!&lt;/p&gt; &#xA;&lt;h2&gt;Outline&lt;/h2&gt; &#xA;&lt;p&gt;For reproducing RoBERTa-large experiments, please refer to the &lt;code&gt;medium_models&lt;/code&gt; folder. For OPT experiments, please refer to the &lt;code&gt;large_models&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{malladi2023mezo,&#xA;   title={Fine-Tuning Large Language Models with Just Forward Passes},&#xA;   author={Malladi, Sadhika and Gao, Tianyu and Nichani, Eshaan and Damian, Alex and Lee, Jason D and Chen, Danqi and Arora, Sanjeev},&#xA;   year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>OpenBMB/CPM-Bee</title>
    <updated>2023-06-02T01:43:09Z</updated>
    <id>tag:github.com,2023-06-02:/OpenBMB/CPM-Bee</id>
    <link href="https://github.com/OpenBMB/CPM-Bee" rel="alternate"></link>
    <summary type="html">&lt;p&gt;百亿参数的中英文双语基座大模型&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;CPM-Bee&lt;/h1&gt; &#xA; &lt;p&gt;&lt;strong&gt;百亿参数的开源中英文双语基座大模型&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;#模型&#34;&gt;模型&lt;/a&gt; • &lt;a href=&#34;#预训练&#34;&gt;OpenBMB体系&lt;/a&gt; • &lt;a href=&#34;#零样本评测&#34;&gt;性能表现&lt;/a&gt; • &lt;a href=&#34;#模型协议&#34;&gt;开源协议&lt;/a&gt; &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;✨ 模型介绍&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;CPM-Bee&lt;/strong&gt;是一个完全开源、允许商用的百亿参数中英文基座模型，也是&lt;a href=&#34;https://live.openbmb.org/&#34;&gt;&lt;strong&gt;CPM-Live&lt;/strong&gt;&lt;/a&gt;训练的第二个里程碑。它采用Transformer自回归架构（auto-regressive），在超万亿（trillion）高质量语料上进行预训练，拥有强大的基础能力。开发者和研究者可以在CPM-Bee基座模型的基础上在各类场景进行适配来以创建特定领域的应用模型。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;👐 开源可商用&lt;/strong&gt;：OpenBMB始终秉承“让大模型飞入千家万户”的开源精神，CPM-Bee基座模型将完全开源并且可商用，以推动大模型领域的发展。我们鼓励全球范围内的科研机构、企业和个人开发者在遵守&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/CPM-Bee/main/#%E6%A8%A1%E5%9E%8B%E5%8D%8F%E8%AE%AE&#34;&gt;开源许可协议&lt;/a&gt;的前提下，自由地在CPM-Bee基座模型上进行创新。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;💫 中英双语性能优异&lt;/strong&gt;： CPM-Bee基座模型在预训练语料上进行了严格的筛选和配比，同时在中英双语上具有亮眼表现，具体可参见&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/CPM-Bee/main/#%E9%9B%B6%E6%A0%B7%E6%9C%AC%E8%AF%84%E6%B5%8B&#34;&gt;评测任务和结果&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;📖 超大规模高质量语料&lt;/strong&gt;： CPM-Bee基座模型在超万亿语料进行训练，是开源社区内经过语料最多的模型之一。同时，我们对预训练语料进行了严格的筛选、清洗和后处理以确保质量。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;img src=&#34;https://i.imgloc.com/2023/05/21/V4nLS3.png&#34; width=&#34;20px&#34;&gt; OpenBMB大模型系统生态支持&lt;/strong&gt;： OpenBMB大模型系统在高性能预训练、适配、压缩、部署、工具开发了一系列工具，CPM-Bee基座模型将配套所有的工具脚本，高效支持开发者进行进阶使用。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔨 对话和工具使用能力&lt;/strong&gt;： 结合OpenBMB在指令微调和工具学习的探索，我们在CPM-Bee基座模型的基础上进行微调，训练出了具有强大对话和工具使用能力的实例模型，API和内测将于近期开放。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;em&gt;Read this in &lt;a href=&#34;https://github.com/OpenBMB/CPM-Bee/raw/main/README_en.md&#34;&gt;English&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;说明：CPM-Bee是一个&lt;strong&gt;基座&lt;/strong&gt;模型，即从零开始通过&lt;strong&gt;预训练&lt;/strong&gt;得来。我们鼓励用户在自己的场景和数据上&lt;strong&gt;适配/微调/对齐&lt;/strong&gt;后再进行使用。例如，&lt;a href=&#34;https://github.com/thunlp/WebCPM&#34;&gt;WebCPM&lt;/a&gt; 以CPM-Bee为基座，在人类网络检索的序列化数据上进行适配，获得了复杂问答和上网检索的能力。后续我们将会发布更多在CPM-Bee基座模型基础上适配的模型。&lt;/p&gt; &#xA;&lt;h2&gt;🚀 安装和使用&lt;/h2&gt; &#xA;&lt;p&gt;您需要克隆该仓库：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone -b main --single-branch https://github.com/OpenBMB/CPM-Bee.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;并确保您的环境符合要求：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;- python&amp;gt;=3.7&#xA;- torch&amp;gt;=1.10&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;我们建议使用Anaconda管理环境并从PyPI安装其他依赖项：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cd src&#xA;$ pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;模型&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/openbmb/cpm-bee-10b/tree/main&#34;&gt;&lt;strong&gt;模型权重下载链接&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;CPM-Bee的基座模型可以准确地进行语义理解，高效完成各类基础任务，包括：文字填空、文本生成、翻译、问答、评分预测、文本选择题等等。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;&#34;填空&#34;:{&#34;input&#34;: &#34;心理学领域的研究人员发现，做出重要决定的最好方法之一，比如选择一所大学或&amp;lt;mask_0&amp;gt;，都涉及到使用决策工作表。研究优化的心理学家将&amp;lt;mask_1&amp;gt;与理论理想决策进行比较，看看它们有多相似。工作表程序的支持者认为它会产生最优的，也就是说，最好的决策。虽然有&amp;lt;mask_2&amp;gt;可以接受，但它们在本质上都是相似的。&#34;,&#34;&amp;lt;ans&amp;gt;&#34;:{&#34;&amp;lt;mask_0&amp;gt;&#34;:&#34;&#34;,&#34;&amp;lt;mask_1&amp;gt;&#34;:&#34;&#34;,&#34;&amp;lt;mask_2&amp;gt;&#34;:&#34;&#34;}},&#xA;&#34;文本生成&#34;: {&#34;input&#34;: &#34;今天天气很好，我和妈妈一起去公园，&#34;, &#34;prompt&#34;: &#34;往后写约100字&#34;, &#34;&amp;lt;ans&amp;gt;&#34;: &#34;&#34;}&#xA;&#34;翻译&#34;: {&#34;input&#34;: &#34;北京是中国的首都&#34;, &#34;prompt&#34;: &#34;中翻英&#34;, &#34;&amp;lt;ans&amp;gt;&#34;: &#34;&#34;}&#xA;&#34;问答&#34;: {&#34;input&#34;: &#34;NGC 6231是一个位于天蝎座的疏散星团，天球座标为赤经16时54分，赤纬-41度48分，视觉观测大小约45角分，亮度约2.6视星等，距地球5900光年。NGC 6231年龄约为三百二十万年，是一个非常年轻的星团，星团内的最亮星是5等的天蝎座 ζ1星。用双筒望远镜或小型望远镜就能看到个别的行星。NGC 6231在1654年被意大利天文学家乔瓦尼·巴蒂斯特·霍迪尔纳（Giovanni Battista Hodierna）以Luminosae的名字首次纪录在星表中，但是未见记载于夏尔·梅西耶的天体列表和威廉·赫歇尔的深空天体目录。这个天体在1678年被爱德蒙·哈雷（I.7）、1745年被夏西亚科斯（Jean-Phillippe Loys de Cheseaux）（9）、1751年被尼可拉·路易·拉卡伊（II.13）分别再次独立发现。&#34;, &#34;question&#34;: &#34;NGC 6231的经纬度是多少？&#34;, &#34;&amp;lt;ans&amp;gt;&#34;: &#34;&#34;}&#xA;&#34;评分预测&#34;: {&#34;input&#34;:&#34;之前多次聚餐都选择这里，有各种大小的包房同时能容纳很多人，环境好有特色还有表演，整体聚餐氛围一下被带动起来。现在由于炭火改成了电烤羊，口感真的不如从前，不过其他菜品都还是不错，烤羊剩下的拆骨肉最后还能再加工一下椒盐的也很好吃。&#34;,&#34;question&#34;:&#34;评分是多少？(1-5)&#34;,&#34;&amp;lt;ans&amp;gt;&#34;:&#34;&#34;},&#xA;&#34;选择题&#34;: {&#34;input&#34;: &#34;父母都希望自己的孩子诚实、勇敢、有礼貌。要想让孩子成为这样的人，父母首先得从自己做起，要是连自己都做不到，又怎能要求孩子做到呢？&#34;, &#34;options&#34;: {&#34;&amp;lt;option_0&amp;gt;&#34;: &#34;少提要求&#34;, &#34;&amp;lt;option_1&amp;gt;&#34;: &#34;降低标准&#34;, &#34;&amp;lt;option_2&amp;gt;&#34;: &#34;自己先做好&#34;, &#34;&amp;lt;option_3&amp;gt;&#34;: &#34;让孩子拿主意&#34;}, &#34;question&#34;: &#34;教育孩子时，父母应该：&#34;, &#34;&amp;lt;ans&amp;gt;&#34;: &#34;&#34;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;img src=&#34;https://i.imgloc.com/2023/05/21/V4nLS3.png&#34; width=&#34;25px&#34;&gt; OpenBMB&lt;/h2&gt; &#xA;&lt;p&gt;基于OpenBMB的大模型系统生态，我们在训练CPM-Bee的过程中实现了全流程高效。同时提供了继续训练（基于BMTrain）、微调（基于OpenPrompt和OpenDelta）、工具使用（基于BMTools）、模型压缩（基于BMCook）、高效推理（基于BMInf）的全套脚本，可以协助开发者快速上手和使用CPM-Bee。&lt;/p&gt; &#xA;&lt;h3&gt;预训练&lt;/h3&gt; &#xA;&lt;p&gt;我们提供了基于&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/CPM-Bee/main/%5Bhttps://github.com/OpenBMB/BMTrain%5D(https://github.com/OpenBMB/BMTrain)&#34;&gt;BMTrain&lt;/a&gt;加速的预训练&lt;a href=&#34;https://github.com/OpenBMB/CPM-Bee/raw/main/src/pretrain_cpm_bee.py&#34;&gt;脚本&lt;/a&gt;，大幅提升预训练效率。&lt;/p&gt; &#xA;&lt;h3&gt;模型微调&lt;/h3&gt; &#xA;&lt;p&gt;基于&lt;a href=&#34;https://github.com/thunlp/OpenDelta&#34;&gt;OpenDelta&lt;/a&gt;，我们给出了两种微调方案：全参数微调和参数高效的增量微调，可以将CPM-Bee适配到各类下游场景中。&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;全参数微调：&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ torchrun --nnodes=1 --nproc_per_node=4 --rdzv_id=1 --rdzv_backend=c10d --rdzv_endpoint=localhost:12345 finetune_cpm_bee.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;增量微调：&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ torchrun --nnodes=1 --nproc_per_node=4 --rdzv_id=1 --rdzv_backend=c10d --rdzv_endpoint=localhost:12345 finetune_cpm_bee.py \&#xA;--use-delta \&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;任务流程 要在特定任务上微调模型，您应该准备数据集并按如下方式执行：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;调整数据格式。 您可以将分类问题集成到选择题的格式中。有关数据格式的更多信息，您可以查看&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/CPM-Bee/main/#%E6%A8%A1%E5%9E%8B&#34;&gt;CPM-Bee数据格式&lt;/a&gt;&lt;br&gt; 应当注意，由于我们选定&lt;code&gt;&amp;lt;...&amp;gt;&lt;/code&gt;作为特殊token的标记，可能与文本中的&lt;code&gt;&amp;lt;&lt;/code&gt;混淆，所以您应当对文本数据中的非特殊token的部分，做转义处理。例如，我们有如下数据 &lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#34;input&#34;: &#34;团队配合非常重要，如果不能做到&amp;lt;mask_0&amp;gt;，则可能会造成1+1&amp;lt;2的结果，所以，要更加注意&amp;lt;mask_1&amp;gt;&#34;, &#34;&amp;lt;ans&amp;gt;&#34;: {&#34;&amp;lt;mask_0&amp;gt;&#34;: &#34;&#34;, &#34;&amp;lt;mask_1&amp;gt;&#34;: &#34;&#34;}}&#xA;&lt;/code&gt;&lt;/pre&gt; 该数据中，&lt;code&gt;&amp;lt;mask_0&amp;gt;&lt;/code&gt;与&lt;code&gt;&amp;lt;mask_1&amp;gt;&lt;/code&gt;是特殊token，应保持不变，其余&lt;code&gt;&amp;lt;&lt;/code&gt;均替换为&lt;code&gt;&amp;lt;&amp;lt;&lt;/code&gt;，转义处理后的数据如下: &lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#34;input&#34;: &#34;团队配合非常重要，如果不能做到&amp;lt;mask_0&amp;gt;，则可能会造成1+1&amp;lt;&amp;lt;2的结果，所以，要更加注意&amp;lt;mask_1&amp;gt;&#34;, &#34;&amp;lt;ans&amp;gt;&#34;: {&#34;&amp;lt;mask_0&amp;gt;&#34;: &#34;&#34;, &#34;&amp;lt;mask_1&amp;gt;&#34;: &#34;&#34;}}&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;将数据集预处理为二进制文件。 要构建预处理数据集，您可以运行&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ python preprocess_dataset.py --input your/reformated/data/path --output_path your/binary/data/path --output_name data_name&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;预处理后，您将获得：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;|-- your/binary/data/path&#xA;    |-- folder1&#xA;    |    |-- data_name&#xA;    |    |-- meta.bin&#xA;    |-- folder2&#xA;         |-- data_name&#xA;         |-- meta.bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;微调CPM-Bee 要开始微调，您可以运行：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ bash scripts/finetune_cpm_bee.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;或者您可以直接通过torchrun运行finetune_cpm_bee.py。例如，您可以在具有4块GPU的服务器上对CPM-Bee进行增量微调，如下所示：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;torchrun --nnodes=1 --nproc_per_node=4 --rdzv_id=1 --rdzv_backend=c10d --rdzv_endpoint=localhost:12345 finetune_cpm_bee.py \&#xA;--model-config your/model/config/path \&#xA;--load your/model/checkpoint/path \&#xA;--dataset your/binary/data/path/folder1 \&#xA;--eval_dataset your/binary/data/path/folder2 \&#xA;--use-delta &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;模型压缩&lt;/h3&gt; &#xA;&lt;p&gt;基于&lt;a href=&#34;https://github.com/OpenBMB/BMCook&#34;&gt;BMCook&lt;/a&gt;，我们对原始的CPM-Bee基座模型进行压缩，提供了多种大小的CPM-Bee模型来适应各种不同的场景。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;模型&lt;/th&gt; &#xA;   &lt;th&gt;#Attn层&lt;/th&gt; &#xA;   &lt;th&gt;#FFN层&lt;/th&gt; &#xA;   &lt;th&gt;Attn隐状态维度&lt;/th&gt; &#xA;   &lt;th&gt;FFN隐状态维度&lt;/th&gt; &#xA;   &lt;th&gt;下载&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CPM-Bee-10B&lt;/td&gt; &#xA;   &lt;td&gt;48&lt;/td&gt; &#xA;   &lt;td&gt;48&lt;/td&gt; &#xA;   &lt;td&gt;4096&lt;/td&gt; &#xA;   &lt;td&gt;10240&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/cpm-bee-10b/tree/main&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CPM-Bee-5B&lt;/td&gt; &#xA;   &lt;td&gt;19&lt;/td&gt; &#xA;   &lt;td&gt;24&lt;/td&gt; &#xA;   &lt;td&gt;4096&lt;/td&gt; &#xA;   &lt;td&gt;10240&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/cpm-bee-5b/tree/main&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CPM-Bee-2B&lt;/td&gt; &#xA;   &lt;td&gt;19&lt;/td&gt; &#xA;   &lt;td&gt;24&lt;/td&gt; &#xA;   &lt;td&gt;2048&lt;/td&gt; &#xA;   &lt;td&gt;5120&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/cpm-bee-2b/tree/main&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CPM-Bee-1B&lt;/td&gt; &#xA;   &lt;td&gt;19&lt;/td&gt; &#xA;   &lt;td&gt;24&lt;/td&gt; &#xA;   &lt;td&gt;1280&lt;/td&gt; &#xA;   &lt;td&gt;1024&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/cpm-bee-1b/tree/main&#34;&gt;链接&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;模型部署&lt;/h3&gt; &#xA;&lt;p&gt;对于压缩后的CPM-Bee，普通的消费级显卡即可完成快速推理，不同大小的模型所占用的推理资源如下：&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;模型&lt;/th&gt; &#xA;   &lt;th&gt;推理内存占用&lt;/th&gt; &#xA;   &lt;th&gt;推荐硬件&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CPM-Bee-10B&lt;/td&gt; &#xA;   &lt;td&gt;20GB&lt;/td&gt; &#xA;   &lt;td&gt;RTX 3090（24 GB）&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CPM-Bee-5B&lt;/td&gt; &#xA;   &lt;td&gt;11 GB&lt;/td&gt; &#xA;   &lt;td&gt;RTX 3090（24 GB）&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CPM-Bee-2B&lt;/td&gt; &#xA;   &lt;td&gt;6.7 GB&lt;/td&gt; &#xA;   &lt;td&gt;GTX 1080（8 GB）&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CPM-Bee-1B&lt;/td&gt; &#xA;   &lt;td&gt;4.1 GB&lt;/td&gt; &#xA;   &lt;td&gt;GTX 1660（6 GB）&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;对于具体的推理任务，您可以编写自己的推理代码。这里我们举一个简单的文本生成示例。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from cpm_live.generation.bee import CPMBeeBeamSearch&#xA;from cpm_live.models import CPMBeeTorch, CPMBeeConfig&#xA;from cpm_live.tokenizers import CPMBeeTokenizer&#xA;from opendelta import LoraModel&#xA;import torch&#xA;&#xA;# prepare your input data.&#xA;data_list = [&#xA;    {&#34;input&#34;: &#34;今天天气是真的&#34;, &#34;prompt&#34;: &#34;往后写一句话&#34;, &#34;&amp;lt;ans&amp;gt;&#34;: &#34;&#34;},&#xA;    {&#34;input&#34;: &#34;北京市气象台提示，4月12日午后偏南风加大，阵风可达6级左右，南下的沙尘可能伴随回流北上进京，外出仍需注意&amp;lt;mask_0&amp;gt;，做好健康防护。天津市气象台也提示，受&amp;lt;mask_1&amp;gt;影响，我市4月12日有浮尘天气，PM10浓度&amp;lt;mask_2&amp;gt;。请注意关好门窗，老人儿童尽量减少户外活动，外出注意带好&amp;lt;mask_3&amp;gt;。” &#34;,&#34;&amp;lt;ans&amp;gt;&#34;:{&#34;&amp;lt;mask_0&amp;gt;&#34;:&#34;&#34;,&#34;&amp;lt;mask_1&amp;gt;&#34;:&#34;&#34;,&#34;&amp;lt;mask_2&amp;gt;&#34;:&#34;&#34;,&#34;&amp;lt;mask_3&amp;gt;&#34;:&#34;&#34;}},&#xA;]&#xA;&#xA;# load model&#xA;config = CPMBeeConfig.from_json_file(&#34;cpm-bee-5b.json&#34;)&#xA;ckpt_path = &#34;cpm-bee-5b-ckpt.pt&#34;&#xA;tokenizer = CPMBeeTokenizer()&#xA;model = CPMBeeTorch(config=config)&#xA;&#xA;# insert LoRA&#xA;# delta_model = LoraModel(backbone_model=model, modified_modules=[&#34;project_q&#34;, &#34;project_v&#34;], backend=&#34;hf&#34;)&#xA;# lora_ckpt_path = &#34;path/to/lora.pt&#34;&#xA;# model.load_state_dict(torch.load(lora_ckpt_path), strict=False)&#xA;&#xA;# load checkpoints&#xA;model.load_state_dict(torch.load(ckpt_path), strict=False)&#xA;model.cuda()&#xA;&#xA;# use beam search&#xA;beam_search = CPMBeeBeamSearch(&#xA;    model=model,&#xA;    tokenizer=tokenizer,&#xA;)&#xA;for data in data_list:&#xA;    inference_results = beam_search.generate([data], max_length=100, repetition_penalty=1.1)&#xA;    for res in inference_results:&#xA;        print(res)&#xA;# output:&#xA;# {&#39;input&#39;: &#39;今天天气是真的&#39;, &#39;prompt&#39;: &#39;往后写一句话&#39;, &#39;&amp;lt;ans&amp;gt;&#39;: {&#39;&amp;lt;mask&amp;gt;&#39;: &#39;好啊！&#39;}}&#xA;# {&#39;input&#39;: &#39;北京市气象台提示，4月12日午后偏南风加大，阵风可达6级左右，南下的沙尘可能伴随回流北上进京，外出仍需注意&amp;lt;mask_0&amp;gt;，做好健康防护。天津市气象台也提示，受&amp;lt;mask_1&amp;gt;影响，我市4月12日有浮尘天气，PM10浓度&amp;lt;mask_2&amp;gt;。请注意关好门窗，老人儿童尽量减少户外活动，外出注意带好&amp;lt;mask_3&amp;gt;。” &#39;, &#39;&amp;lt;ans&amp;gt;&#39;: {&#39;&amp;lt;mask_0&amp;gt;&#39;: &#39;防风&#39;, &#39;&amp;lt;mask_1&amp;gt;&#39;: &#39;沙尘天气&#39;, &#39;&amp;lt;mask_2&amp;gt;&#39;: &#39;较高&#39;, &#39;&amp;lt;mask_3&amp;gt;&#39;: &#39;口罩、护目镜等防护用品&#39;}}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;我们还将上面的代码集成到一个python文件&lt;code&gt;text_generation.py&lt;/code&gt;中，为了便于推断，可以直接运行该文件：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python text_generation.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;您可以设置不同的输入格式，以适应不同的推理任务。&lt;/p&gt; &#xA;&lt;h2&gt;💫 性能表现&lt;/h2&gt; &#xA;&lt;h3&gt;零样本评测&lt;/h3&gt; &#xA;&lt;p&gt;我们对CPM-Bee基座模型进行了全方位的中英文能力评测。 在中文的Zero-CLUE评测基准上，CPM-Bee可以大幅超越其他模型，位列中文大模型第一。在英文评测基准上，CPM-Bee也展现出了和开源模型LLaMA相当的效果。&lt;/p&gt; &#xA;&lt;h4&gt;ZeroCLUE中文评测&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Score&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;EPRSTMT&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;CSLDCP&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;TNEWSF&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;IFLYTEKF&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;OCNLIF&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;BUSTM&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;CHIDF&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;CSLF&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;CLUEWSCF&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;CPM-Bee&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;78.184&lt;/td&gt; &#xA;   &lt;td&gt;85.52&lt;/td&gt; &#xA;   &lt;td&gt;58.99&lt;/td&gt; &#xA;   &lt;td&gt;78.2&lt;/td&gt; &#xA;   &lt;td&gt;58.81&lt;/td&gt; &#xA;   &lt;td&gt;77.73&lt;/td&gt; &#xA;   &lt;td&gt;83.85&lt;/td&gt; &#xA;   &lt;td&gt;89.65&lt;/td&gt; &#xA;   &lt;td&gt;83.6&lt;/td&gt; &#xA;   &lt;td&gt;87.24&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Ctyun_Big_Model&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;76.217&lt;/td&gt; &#xA;   &lt;td&gt;87.25&lt;/td&gt; &#xA;   &lt;td&gt;48.02&lt;/td&gt; &#xA;   &lt;td&gt;77.13&lt;/td&gt; &#xA;   &lt;td&gt;59.62&lt;/td&gt; &#xA;   &lt;td&gt;75.5&lt;/td&gt; &#xA;   &lt;td&gt;90.05&lt;/td&gt; &#xA;   &lt;td&gt;84.6&lt;/td&gt; &#xA;   &lt;td&gt;82.9&lt;/td&gt; &#xA;   &lt;td&gt;81.72&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;PaddleNLP-UTC&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;70.547&lt;/td&gt; &#xA;   &lt;td&gt;85.92&lt;/td&gt; &#xA;   &lt;td&gt;58.92&lt;/td&gt; &#xA;   &lt;td&gt;68.27&lt;/td&gt; &#xA;   &lt;td&gt;40.15&lt;/td&gt; &#xA;   &lt;td&gt;74.79&lt;/td&gt; &#xA;   &lt;td&gt;76.7&lt;/td&gt; &#xA;   &lt;td&gt;82.75&lt;/td&gt; &#xA;   &lt;td&gt;70.6&lt;/td&gt; &#xA;   &lt;td&gt;74.48&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;二郎神-UnifiedMC&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;70.295&lt;/td&gt; &#xA;   &lt;td&gt;88.71&lt;/td&gt; &#xA;   &lt;td&gt;50.18&lt;/td&gt; &#xA;   &lt;td&gt;71.67&lt;/td&gt; &#xA;   &lt;td&gt;40.58&lt;/td&gt; &#xA;   &lt;td&gt;75.5&lt;/td&gt; &#xA;   &lt;td&gt;80.15&lt;/td&gt; &#xA;   &lt;td&gt;84.85&lt;/td&gt; &#xA;   &lt;td&gt;60.6&lt;/td&gt; &#xA;   &lt;td&gt;81.72&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;英文评测&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;BoolQ&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;PIQA&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;SIQA&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;HellaSwag&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;WinoGrande&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;ARC-e&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;ARC-c&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;OBQA&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;GPT-3&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;60.5&lt;/td&gt; &#xA;   &lt;td&gt;81&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;78.9&lt;/td&gt; &#xA;   &lt;td&gt;70.2&lt;/td&gt; &#xA;   &lt;td&gt;68.8&lt;/td&gt; &#xA;   &lt;td&gt;51.4&lt;/td&gt; &#xA;   &lt;td&gt;57.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Gopher&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;79.3&lt;/td&gt; &#xA;   &lt;td&gt;81.8&lt;/td&gt; &#xA;   &lt;td&gt;50.6&lt;/td&gt; &#xA;   &lt;td&gt;79.2&lt;/td&gt; &#xA;   &lt;td&gt;70.1&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Chinchilla&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;83.7&lt;/td&gt; &#xA;   &lt;td&gt;81.8&lt;/td&gt; &#xA;   &lt;td&gt;51.3&lt;/td&gt; &#xA;   &lt;td&gt;80.8&lt;/td&gt; &#xA;   &lt;td&gt;74.9&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;PaLM&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;84.8&lt;/td&gt; &#xA;   &lt;td&gt;80.5&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;79.7&lt;/td&gt; &#xA;   &lt;td&gt;77&lt;/td&gt; &#xA;   &lt;td&gt;75.2&lt;/td&gt; &#xA;   &lt;td&gt;52.5&lt;/td&gt; &#xA;   &lt;td&gt;50.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;LLaMA-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;66.13&lt;/td&gt; &#xA;   &lt;td&gt;76.5&lt;/td&gt; &#xA;   &lt;td&gt;79.8&lt;/td&gt; &#xA;   &lt;td&gt;48.9&lt;/td&gt; &#xA;   &lt;td&gt;76.1&lt;/td&gt; &#xA;   &lt;td&gt;70.1&lt;/td&gt; &#xA;   &lt;td&gt;72.8&lt;/td&gt; &#xA;   &lt;td&gt;47.6&lt;/td&gt; &#xA;   &lt;td&gt;57.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;LLaMA-13B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;68.08&lt;/td&gt; &#xA;   &lt;td&gt;78.1&lt;/td&gt; &#xA;   &lt;td&gt;80.1&lt;/td&gt; &#xA;   &lt;td&gt;50.4&lt;/td&gt; &#xA;   &lt;td&gt;79.2&lt;/td&gt; &#xA;   &lt;td&gt;73&lt;/td&gt; &#xA;   &lt;td&gt;74.8&lt;/td&gt; &#xA;   &lt;td&gt;52.7&lt;/td&gt; &#xA;   &lt;td&gt;56.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;CPM-Bee&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;67.80&lt;/td&gt; &#xA;   &lt;td&gt;78.69&lt;/td&gt; &#xA;   &lt;td&gt;77.58&lt;/td&gt; &#xA;   &lt;td&gt;61.11&lt;/td&gt; &#xA;   &lt;td&gt;78.89&lt;/td&gt; &#xA;   &lt;td&gt;61.88&lt;/td&gt; &#xA;   &lt;td&gt;66.88&lt;/td&gt; &#xA;   &lt;td&gt;54.18&lt;/td&gt; &#xA;   &lt;td&gt;63.20&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;CPM-Bee + Decoder Tuning&lt;/h3&gt; &#xA;&lt;p&gt;使用和OpenBMB和THUNLP联合自研的&lt;a href=&#34;https://arxiv.org/abs/2212.08408&#34;&gt;Decoder Tuning&lt;/a&gt;（将发表于ACL 2023）技术，可以仅仅使用API的情况下，不访问和修改模型参数即可大幅提高下游任务的性能。 实现代码&lt;a href=&#34;https://github.com/thunlp/DecT&#34;&gt;链接&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;样本数&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;SST2&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;IMDB&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Yelp&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;AGNews&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;DBpedia&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Yahoo&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;RTE&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;SNLI&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;MNLI-m&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;MNLI-mm&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;FewNERD&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Avg.&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;CPM-Bee&lt;/td&gt; &#xA;   &lt;td&gt;80.5&lt;/td&gt; &#xA;   &lt;td&gt;89.1&lt;/td&gt; &#xA;   &lt;td&gt;96.6&lt;/td&gt; &#xA;   &lt;td&gt;74.6&lt;/td&gt; &#xA;   &lt;td&gt;71.3&lt;/td&gt; &#xA;   &lt;td&gt;46.7&lt;/td&gt; &#xA;   &lt;td&gt;84.1&lt;/td&gt; &#xA;   &lt;td&gt;45.4&lt;/td&gt; &#xA;   &lt;td&gt;45.6&lt;/td&gt; &#xA;   &lt;td&gt;45.6&lt;/td&gt; &#xA;   &lt;td&gt;1.6&lt;/td&gt; &#xA;   &lt;td&gt;61.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;16&lt;/td&gt; &#xA;   &lt;td&gt;T5-3B&lt;/td&gt; &#xA;   &lt;td&gt;89.9&lt;/td&gt; &#xA;   &lt;td&gt;92.7&lt;/td&gt; &#xA;   &lt;td&gt;94.9&lt;/td&gt; &#xA;   &lt;td&gt;87.7&lt;/td&gt; &#xA;   &lt;td&gt;96.2&lt;/td&gt; &#xA;   &lt;td&gt;66.5&lt;/td&gt; &#xA;   &lt;td&gt;55.8&lt;/td&gt; &#xA;   &lt;td&gt;52.0&lt;/td&gt; &#xA;   &lt;td&gt;52.8&lt;/td&gt; &#xA;   &lt;td&gt;52.2&lt;/td&gt; &#xA;   &lt;td&gt;51.9&lt;/td&gt; &#xA;   &lt;td&gt;72.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;LLaMA-7B&lt;/td&gt; &#xA;   &lt;td&gt;85.1&lt;/td&gt; &#xA;   &lt;td&gt;90.5&lt;/td&gt; &#xA;   &lt;td&gt;92.8&lt;/td&gt; &#xA;   &lt;td&gt;71.4&lt;/td&gt; &#xA;   &lt;td&gt;89.8&lt;/td&gt; &#xA;   &lt;td&gt;45.1&lt;/td&gt; &#xA;   &lt;td&gt;49.1&lt;/td&gt; &#xA;   &lt;td&gt;35.2&lt;/td&gt; &#xA;   &lt;td&gt;36.3&lt;/td&gt; &#xA;   &lt;td&gt;36.2&lt;/td&gt; &#xA;   &lt;td&gt;54.6&lt;/td&gt; &#xA;   &lt;td&gt;62.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Vicuna-13B&lt;/td&gt; &#xA;   &lt;td&gt;82.1&lt;/td&gt; &#xA;   &lt;td&gt;88.8&lt;/td&gt; &#xA;   &lt;td&gt;95.6&lt;/td&gt; &#xA;   &lt;td&gt;86.4&lt;/td&gt; &#xA;   &lt;td&gt;74.4&lt;/td&gt; &#xA;   &lt;td&gt;55.3&lt;/td&gt; &#xA;   &lt;td&gt;62.5&lt;/td&gt; &#xA;   &lt;td&gt;61.4&lt;/td&gt; &#xA;   &lt;td&gt;54.3&lt;/td&gt; &#xA;   &lt;td&gt;48.6&lt;/td&gt; &#xA;   &lt;td&gt;52.1&lt;/td&gt; &#xA;   &lt;td&gt;69.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CPM-Bee&lt;/td&gt; &#xA;   &lt;td&gt;92.7&lt;/td&gt; &#xA;   &lt;td&gt;96.2&lt;/td&gt; &#xA;   &lt;td&gt;97.5&lt;/td&gt; &#xA;   &lt;td&gt;85.5&lt;/td&gt; &#xA;   &lt;td&gt;89.8&lt;/td&gt; &#xA;   &lt;td&gt;65.2&lt;/td&gt; &#xA;   &lt;td&gt;86.0&lt;/td&gt; &#xA;   &lt;td&gt;86.4&lt;/td&gt; &#xA;   &lt;td&gt;76.3&lt;/td&gt; &#xA;   &lt;td&gt;76.3&lt;/td&gt; &#xA;   &lt;td&gt;54.6&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;82.4&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;64&lt;/td&gt; &#xA;   &lt;td&gt;LLaMA-7B&lt;/td&gt; &#xA;   &lt;td&gt;87.5&lt;/td&gt; &#xA;   &lt;td&gt;85.7&lt;/td&gt; &#xA;   &lt;td&gt;96.9&lt;/td&gt; &#xA;   &lt;td&gt;75.4&lt;/td&gt; &#xA;   &lt;td&gt;93.5&lt;/td&gt; &#xA;   &lt;td&gt;47.4&lt;/td&gt; &#xA;   &lt;td&gt;51.4&lt;/td&gt; &#xA;   &lt;td&gt;39.4&lt;/td&gt; &#xA;   &lt;td&gt;36.2&lt;/td&gt; &#xA;   &lt;td&gt;38.4&lt;/td&gt; &#xA;   &lt;td&gt;59.8&lt;/td&gt; &#xA;   &lt;td&gt;64.7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Vicuna-13B&lt;/td&gt; &#xA;   &lt;td&gt;92.0&lt;/td&gt; &#xA;   &lt;td&gt;90.8&lt;/td&gt; &#xA;   &lt;td&gt;96.5&lt;/td&gt; &#xA;   &lt;td&gt;87.7&lt;/td&gt; &#xA;   &lt;td&gt;87.8&lt;/td&gt; &#xA;   &lt;td&gt;58.7&lt;/td&gt; &#xA;   &lt;td&gt;59.1&lt;/td&gt; &#xA;   &lt;td&gt;58.7&lt;/td&gt; &#xA;   &lt;td&gt;56.7&lt;/td&gt; &#xA;   &lt;td&gt;48.4&lt;/td&gt; &#xA;   &lt;td&gt;56.8&lt;/td&gt; &#xA;   &lt;td&gt;72.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CPM-Bee&lt;/td&gt; &#xA;   &lt;td&gt;94.3&lt;/td&gt; &#xA;   &lt;td&gt;96.5&lt;/td&gt; &#xA;   &lt;td&gt;98.3&lt;/td&gt; &#xA;   &lt;td&gt;88.5&lt;/td&gt; &#xA;   &lt;td&gt;93.5&lt;/td&gt; &#xA;   &lt;td&gt;68.7&lt;/td&gt; &#xA;   &lt;td&gt;87.1&lt;/td&gt; &#xA;   &lt;td&gt;88.9&lt;/td&gt; &#xA;   &lt;td&gt;78.0&lt;/td&gt; &#xA;   &lt;td&gt;79.0&lt;/td&gt; &#xA;   &lt;td&gt;59.8&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;84.8&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;256&lt;/td&gt; &#xA;   &lt;td&gt;LLaMA-7B&lt;/td&gt; &#xA;   &lt;td&gt;87.6&lt;/td&gt; &#xA;   &lt;td&gt;88.8&lt;/td&gt; &#xA;   &lt;td&gt;97.1&lt;/td&gt; &#xA;   &lt;td&gt;82.4&lt;/td&gt; &#xA;   &lt;td&gt;94.2&lt;/td&gt; &#xA;   &lt;td&gt;48.5&lt;/td&gt; &#xA;   &lt;td&gt;53.4&lt;/td&gt; &#xA;   &lt;td&gt;39.8&lt;/td&gt; &#xA;   &lt;td&gt;37.3&lt;/td&gt; &#xA;   &lt;td&gt;37.4&lt;/td&gt; &#xA;   &lt;td&gt;59.1&lt;/td&gt; &#xA;   &lt;td&gt;66.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Vicuna-13B&lt;/td&gt; &#xA;   &lt;td&gt;93.1&lt;/td&gt; &#xA;   &lt;td&gt;88.7&lt;/td&gt; &#xA;   &lt;td&gt;96.8&lt;/td&gt; &#xA;   &lt;td&gt;89.9&lt;/td&gt; &#xA;   &lt;td&gt;89.1&lt;/td&gt; &#xA;   &lt;td&gt;58.6&lt;/td&gt; &#xA;   &lt;td&gt;58.5&lt;/td&gt; &#xA;   &lt;td&gt;58.7&lt;/td&gt; &#xA;   &lt;td&gt;57.5&lt;/td&gt; &#xA;   &lt;td&gt;48.3&lt;/td&gt; &#xA;   &lt;td&gt;56.6&lt;/td&gt; &#xA;   &lt;td&gt;72.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CPM-Bee&lt;/td&gt; &#xA;   &lt;td&gt;94.5&lt;/td&gt; &#xA;   &lt;td&gt;96.7&lt;/td&gt; &#xA;   &lt;td&gt;98.4&lt;/td&gt; &#xA;   &lt;td&gt;89.7&lt;/td&gt; &#xA;   &lt;td&gt;94.2&lt;/td&gt; &#xA;   &lt;td&gt;69.9&lt;/td&gt; &#xA;   &lt;td&gt;87.7&lt;/td&gt; &#xA;   &lt;td&gt;89.4&lt;/td&gt; &#xA;   &lt;td&gt;81.7&lt;/td&gt; &#xA;   &lt;td&gt;80.6&lt;/td&gt; &#xA;   &lt;td&gt;59.1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;85.6&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;📃开源协议&lt;/h2&gt; &#xA;&lt;h4&gt;模型协议&lt;/h4&gt; &#xA;&lt;p&gt;CPM-Bee基座采用协议为&lt;a href=&#34;https://github.com/OpenBMB/General-Model-License/raw/main/%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE-%E6%9D%A5%E6%BA%90%E8%AF%B4%E6%98%8E-%E5%AE%A3%E4%BC%A0%E9%99%90%E5%88%B6-%E5%95%86%E4%B8%9A%E6%8E%88%E6%9D%83.md&#34;&gt;“通用模型许可协议-来源说明-宣传限制-商业授权”&lt;/a&gt;，本模型允许商用，如需将模型用于商业用途，请联系&lt;a href=&#34;mailto:cpm@modelbest.cn&#34;&gt;cpm@modelbest.cn&lt;/a&gt;来获取书面授权。&lt;/p&gt; &#xA;&lt;h4&gt;声明&lt;/h4&gt; &#xA;&lt;p&gt;作为一个语言模型，CPM-Bee通过学习大量的文本来生成内容，但它无法理解、表达个人观点或价值判断，它所输出的任何内容都不代表模型开发者的观点和立场。 因此用户在使用CPM-Bee生成的内容时，应自行负责对其进行评估和验证。&lt;/p&gt;</summary>
  </entry>
</feed>