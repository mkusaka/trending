<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-02-07T01:37:11Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>RockChinQ/LangBot</title>
    <updated>2025-02-07T01:37:11Z</updated>
    <id>tag:github.com,2025-02-07:/RockChinQ/LangBot</id>
    <link href="https://github.com/RockChinQ/LangBot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ğŸ˜ä¸°å¯Œç”Ÿæ€ã€ğŸ§©æ”¯æŒæ‰©å±•ã€ğŸ¦„å¤šæ¨¡æ€ - å¤§æ¨¡å‹åŸç”Ÿå³æ—¶é€šä¿¡æœºå™¨äººå¹³å° ğŸ¤– | é€‚é… QQ / å¾®ä¿¡ï¼ˆä¼ä¸šå¾®ä¿¡ã€ä¸ªäººå¾®ä¿¡ï¼‰/ é£ä¹¦ï¼ˆfeishuï¼‰/ Discord / OneBot ç­‰æ¶ˆæ¯å¹³å° | æ”¯æŒ OpenAI GPTã€ChatGPTã€DeepSeekã€Difyã€Claudeã€Geminiã€Ollamaã€LM Studioã€SiliconFlowã€Qwenã€Moonshotã€ChatGLM ç­‰ LLM çš„æœºå™¨äºº / Agent | LLM-based instant messaging bots platform, supports Discord, WeChat, Lark, QQ platform, OpenAI ChatGPT, DeepSeek.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://langbot.app&#34;&gt; &lt;img src=&#34;https://docs.langbot.app/social.png&#34; alt=&#34;LangBot&#34;&gt; &lt;/a&gt; &lt;/p&gt;&#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://trendshift.io/repositories/6187&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://trendshift.io/api/badge/repositories/6187&#34; alt=&#34;RockChinQ%2FQChatGPT | Trendshift&#34; style=&#34;width: 250px; height: 55px;&#34; width=&#34;250&#34; height=&#34;55&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://docs.langbot.app&#34;&gt;é¡¹ç›®ä¸»é¡µ&lt;/a&gt; ï½œ &lt;a href=&#34;https://docs.langbot.app/insight/intro.htmll&#34;&gt;åŠŸèƒ½ä»‹ç»&lt;/a&gt; ï½œ &lt;a href=&#34;https://docs.langbot.app/insight/guide.html&#34;&gt;éƒ¨ç½²æ–‡æ¡£&lt;/a&gt; ï½œ &lt;a href=&#34;https://docs.langbot.app/usage/faq.html&#34;&gt;å¸¸è§é—®é¢˜&lt;/a&gt; ï½œ &lt;a href=&#34;https://docs.langbot.app/plugin/plugin-intro.html&#34;&gt;æ’ä»¶ä»‹ç»&lt;/a&gt; ï½œ &lt;a href=&#34;https://github.com/RockChinQ/LangBot/issues/new?assignees=&amp;amp;labels=%E7%8B%AC%E7%AB%8B%E6%8F%92%E4%BB%B6&amp;amp;projects=&amp;amp;template=submit-plugin.yml&amp;amp;title=%5BPlugin%5D%3A+%E8%AF%B7%E6%B1%82%E7%99%BB%E8%AE%B0%E6%96%B0%E6%8F%92%E4%BB%B6&#34;&gt;æäº¤æ’ä»¶&lt;/a&gt;&lt;/p&gt; &#xA; &lt;div align=&#34;center&#34;&gt;&#xA;   ğŸ˜é«˜ç¨³å®šã€ğŸ§©æ”¯æŒæ‰©å±•ã€ğŸ¦„å¤šæ¨¡æ€ - å¤§æ¨¡å‹åŸç”Ÿå³æ—¶é€šä¿¡æœºå™¨äººå¹³å°ğŸ¤– &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://qm.qq.com/q/PF9OuQCCcM&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%E7%A4%BE%E5%8C%BAQQ%E7%BE%A4-1030838208-blue&#34; alt=&#34;QQ Group&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/RockChinQ/LangBot/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/RockChinQ/LangBot&#34; alt=&#34;GitHub release (latest by date)&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.qchatgpt.rockchin.top%2Fapi%2Fv2%2Fview%2Frealtime%2Fcount_query%3Fminute%3D10080&amp;amp;query=%24.data.count&amp;amp;label=%E4%BD%BF%E7%94%A8%E9%87%8F%EF%BC%887%E6%97%A5%EF%BC%89&#34; alt=&#34;Dynamic JSON Badge&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/python-3.10%20%7C%203.11%20%7C%203.12-blue.svg?sanitize=true&#34; alt=&#34;python&#34;&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/RockChinQ/LangBot/master/README.md&#34;&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; / &lt;a href=&#34;https://raw.githubusercontent.com/RockChinQ/LangBot/master/README_EN.md&#34;&gt;English&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;h2&gt;âœ¨ ç‰¹æ€§&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸ’¬ å¤§æ¨¡å‹å¯¹è¯ã€Agentï¼šæ”¯æŒå¤šç§å¤§æ¨¡å‹ï¼Œé€‚é…ç¾¤èŠå’Œç§èŠï¼›å…·æœ‰å¤šè½®å¯¹è¯ã€å·¥å…·è°ƒç”¨ã€å¤šæ¨¡æ€èƒ½åŠ›ï¼Œå¹¶æ·±åº¦é€‚é… &lt;a href=&#34;https://dify.ai&#34;&gt;Dify&lt;/a&gt;ã€‚ç›®å‰æ”¯æŒ QQã€QQé¢‘é“ã€ä¼ä¸šå¾®ä¿¡ã€é£ä¹¦ã€Discordã€ä¸ªäººå¾®ä¿¡ï¼Œåç»­è¿˜å°†æ”¯æŒ WhatsAppã€Telegram ç­‰å¹³å°ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸ› ï¸ é«˜ç¨³å®šæ€§ã€åŠŸèƒ½å®Œå¤‡ï¼šåŸç”Ÿæ”¯æŒè®¿é—®æ§åˆ¶ã€é™é€Ÿã€æ•æ„Ÿè¯è¿‡æ»¤ç­‰æœºåˆ¶ï¼›é…ç½®ç®€å•ï¼Œæ”¯æŒå¤šç§éƒ¨ç½²æ–¹å¼ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸ§© æ’ä»¶æ‰©å±•ã€æ´»è·ƒç¤¾åŒºï¼šæ”¯æŒäº‹ä»¶é©±åŠ¨ã€ç»„ä»¶æ‰©å±•ç­‰æ’ä»¶æœºåˆ¶ï¼›ä¸°å¯Œç”Ÿæ€ï¼Œç›®å‰å·²æœ‰æ•°åä¸ª&lt;a href=&#34;https://docs.langbot.app/plugin/plugin-intro.html&#34;&gt;æ’ä»¶&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ğŸ˜» [New] Web ç®¡ç†é¢æ¿ï¼šæ”¯æŒé€šè¿‡æµè§ˆå™¨ç®¡ç† LangBot å®ä¾‹ï¼Œå…·ä½“æ”¯æŒåŠŸèƒ½ï¼ŒæŸ¥çœ‹&lt;a href=&#34;https://docs.langbot.app/webui/intro.html&#34;&gt;æ–‡æ¡£&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ“¦ å¼€å§‹ä½¿ç”¨&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT]&lt;/p&gt; &#xA; &lt;p&gt;åœ¨æ‚¨å¼€å§‹ä»»ä½•æ–¹å¼éƒ¨ç½²ä¹‹å‰ï¼Œè¯·åŠ¡å¿…é˜…è¯»&lt;a href=&#34;https://docs.langbot.app/insight/guide.html&#34;&gt;æ–°æ‰‹æŒ‡å¼•&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;Docker Compose éƒ¨ç½²&lt;/h4&gt; &#xA;&lt;p&gt;é€‚åˆç†Ÿæ‚‰ Docker çš„ç”¨æˆ·ï¼ŒæŸ¥çœ‹æ–‡æ¡£&lt;a href=&#34;https://docs.langbot.app/deploy/langbot/docker.html&#34;&gt;Docker éƒ¨ç½²&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h4&gt;å®å¡”é¢æ¿éƒ¨ç½²&lt;/h4&gt; &#xA;&lt;p&gt;å·²ä¸Šæ¶å®å¡”é¢æ¿ï¼Œè‹¥æ‚¨å·²å®‰è£…å®å¡”é¢æ¿ï¼Œå¯ä»¥æ ¹æ®&lt;a href=&#34;https://docs.langbot.app/deploy/langbot/one-click/bt.html&#34;&gt;æ–‡æ¡£&lt;/a&gt;ä½¿ç”¨ã€‚&lt;/p&gt; &#xA;&lt;h4&gt;Zeabur äº‘éƒ¨ç½²&lt;/h4&gt; &#xA;&lt;p&gt;ç¤¾åŒºè´¡çŒ®çš„ Zeabur æ¨¡æ¿ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zeabur.com/zh-CN/templates/ZKTBDH&#34;&gt;&lt;img src=&#34;https://zeabur.com/button.svg?sanitize=true&#34; alt=&#34;Deploy on Zeabur&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Railway äº‘éƒ¨ç½²&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://railway.app/template/yRrAyL?referralCode=vogKPF&#34;&gt;&lt;img src=&#34;https://railway.com/button.svg?sanitize=true&#34; alt=&#34;Deploy on Railway&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;æ‰‹åŠ¨éƒ¨ç½²&lt;/h4&gt; &#xA;&lt;p&gt;ç›´æ¥ä½¿ç”¨å‘è¡Œç‰ˆè¿è¡Œï¼ŒæŸ¥çœ‹æ–‡æ¡£&lt;a href=&#34;https://docs.langbot.app/deploy/langbot/manual.html&#34;&gt;æ‰‹åŠ¨éƒ¨ç½²&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“¸ æ•ˆæœå±•ç¤º&lt;/h2&gt; &#xA;&lt;img alt=&#34;å›å¤æ•ˆæœï¼ˆå¸¦æœ‰è”ç½‘æ’ä»¶ï¼‰&#34; src=&#34;https://docs.langbot.app/QChatGPT-0516.png&#34; width=&#34;500px&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;WebUI Demo: &lt;a href=&#34;https://demo.langbot.dev/&#34;&gt;https://demo.langbot.dev/&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ç™»å½•ä¿¡æ¯ï¼šé‚®ç®±ï¼š&lt;code&gt;demo@langbot.app&lt;/code&gt; å¯†ç ï¼š&lt;code&gt;langbot123456&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;æ³¨æ„ï¼šä»…å±•ç¤ºwebuiæ•ˆæœï¼Œå…¬å¼€ç¯å¢ƒï¼Œè¯·ä¸è¦åœ¨å…¶ä¸­å¡«å…¥æ‚¨çš„ä»»ä½•æ•æ„Ÿä¿¡æ¯ã€‚&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ”Œ ç»„ä»¶å…¼å®¹æ€§&lt;/h2&gt; &#xA;&lt;h3&gt;æ¶ˆæ¯å¹³å°&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;å¹³å°&lt;/th&gt; &#xA;   &lt;th&gt;çŠ¶æ€&lt;/th&gt; &#xA;   &lt;th&gt;å¤‡æ³¨&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;QQ ä¸ªäººå·&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;QQ ä¸ªäººå·ç§èŠã€ç¾¤èŠ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;QQ å®˜æ–¹æœºå™¨äºº&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;QQ å®˜æ–¹æœºå™¨äººï¼Œæ”¯æŒé¢‘é“ã€ç§èŠã€ç¾¤èŠ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ä¼ä¸šå¾®ä¿¡&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;é£ä¹¦&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Discord&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ä¸ªäººå¾®ä¿¡&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;ä½¿ç”¨ &lt;a href=&#34;https://github.com/Devo919/Gewechat&#34;&gt;Gewechat&lt;/a&gt; æ¥å…¥&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Telegram&lt;/td&gt; &#xA;   &lt;td&gt;ğŸš§&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;WhatsApp&lt;/td&gt; &#xA;   &lt;td&gt;ğŸš§&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;é’‰é’‰&lt;/td&gt; &#xA;   &lt;td&gt;ğŸš§&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;ğŸš§: æ­£åœ¨å¼€å‘ä¸­&lt;/p&gt; &#xA;&lt;h3&gt;å¤§æ¨¡å‹&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;æ¨¡å‹&lt;/th&gt; &#xA;   &lt;th&gt;çŠ¶æ€&lt;/th&gt; &#xA;   &lt;th&gt;å¤‡æ³¨&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://platform.openai.com/&#34;&gt;OpenAI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;å¯æ¥å…¥ä»»ä½• OpenAI æ¥å£æ ¼å¼æ¨¡å‹&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.deepseek.com/&#34;&gt;DeepSeek&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.moonshot.cn/&#34;&gt;Moonshot&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.anthropic.com/&#34;&gt;Anthropic&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://x.ai/&#34;&gt;xAI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://open.bigmodel.cn/&#34;&gt;æ™ºè°±AI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://dify.ai&#34;&gt;Dify&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;LLMOps å¹³å°&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ollama.com/&#34;&gt;Ollama&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;æœ¬åœ°å¤§æ¨¡å‹è¿è¡Œå¹³å°&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://lmstudio.ai/&#34;&gt;LMStudio&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;æœ¬åœ°å¤§æ¨¡å‹è¿è¡Œå¹³å°&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ai.gitee.com/&#34;&gt;GiteeAI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;å¤§æ¨¡å‹æ¥å£èšåˆå¹³å°&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://siliconflow.cn/&#34;&gt;SiliconFlow&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;å¤§æ¨¡å‹èšåˆå¹³å°&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://bailian.console.aliyun.com/&#34;&gt;é˜¿é‡Œäº‘ç™¾ç‚¼&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;å¤§æ¨¡å‹èšåˆå¹³å°&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;ğŸ˜˜ ç¤¾åŒºè´¡çŒ®&lt;/h2&gt; &#xA;&lt;p&gt;LangBot ç¦»ä¸å¼€ä»¥ä¸‹è´¡çŒ®è€…å’Œç¤¾åŒºå†…æ‰€æœ‰äººçš„è´¡çŒ®ï¼Œæˆ‘ä»¬æ¬¢è¿ä»»ä½•å½¢å¼çš„è´¡çŒ®å’Œåé¦ˆã€‚&lt;/p&gt; &#xA;&lt;a href=&#34;https://github.com/RockChinQ/LangBot/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=RockChinQ/LangBot&#34;&gt; &lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Physical-Intelligence/openpi</title>
    <updated>2025-02-07T01:37:11Z</updated>
    <id>tag:github.com,2025-02-07:/Physical-Intelligence/openpi</id>
    <link href="https://github.com/Physical-Intelligence/openpi" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;openpi&lt;/h1&gt; &#xA;&lt;p&gt;openpi holds open-source models and packages for robotics, published by the &lt;a href=&#34;https://www.physicalintelligence.company/&#34;&gt;Physical Intelligence team&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Currently, this repo contains two types of models:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;the &lt;a href=&#34;https://www.physicalintelligence.company/blog/pi0&#34;&gt;Ï€â‚€ model&lt;/a&gt;, a flow-based diffusion vision-language-action model (VLA)&lt;/li&gt; &#xA; &lt;li&gt;the &lt;a href=&#34;https://www.physicalintelligence.company/research/fast&#34;&gt;Ï€â‚€-FAST model&lt;/a&gt;, an autoregressive VLA, based on the FAST action tokenizer.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For both models, we provide &lt;em&gt;base model&lt;/em&gt; checkpoints, pre-trained on 10k+ hours of robot data, and examples for using them out of the box or fine-tuning them to your own datasets.&lt;/p&gt; &#xA;&lt;p&gt;This is an experiment: $\pi_0$ was developed for our own robots, which differ from the widely used platforms such as &lt;a href=&#34;https://tonyzhaozh.github.io/aloha/&#34;&gt;ALOHA&lt;/a&gt; and &lt;a href=&#34;https://droid-dataset.github.io/&#34;&gt;DROID&lt;/a&gt;, and though we are optimistic that researchers and practitioners will be able to run creative new experiments adapting $\pi_0$ to their own platforms, we do not expect every such attempt to be successful. All this is to say: $\pi_0$ may or may not work for you, but you are welcome to try it and see!&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;To run the models in this repository, you will need an NVIDIA GPU with at least the following specifications. These estimations assume a single GPU, but you can also use multiple GPUs with model parallelism to reduce per-GPU memory requirements by configuring &lt;code&gt;fsdp_devices&lt;/code&gt; in the training config. Please also note that the current training script does not yet support multi-node training.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Mode&lt;/th&gt; &#xA;   &lt;th&gt;Memory Required&lt;/th&gt; &#xA;   &lt;th&gt;Example GPU&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Inference&lt;/td&gt; &#xA;   &lt;td&gt;&amp;gt; 8 GB&lt;/td&gt; &#xA;   &lt;td&gt;RTX 4090&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Fine-Tuning (LoRA)&lt;/td&gt; &#xA;   &lt;td&gt;&amp;gt; 22.5 GB&lt;/td&gt; &#xA;   &lt;td&gt;RTX 4090&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Fine-Tuning (Full)&lt;/td&gt; &#xA;   &lt;td&gt;&amp;gt; 70 GB&lt;/td&gt; &#xA;   &lt;td&gt;A100 (80GB) / H100&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The repo has been tested with Ubuntu 22.04, we do not currently support other operating systems.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;When cloning this repo, make sure to update submodules:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone --recurse-submodules git@github.com:Physical-Intelligence/openpi.git&#xA;&#xA;# Or if you already cloned the repo:&#xA;git submodule update --init --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We use &lt;a href=&#34;https://docs.astral.sh/uv/&#34;&gt;uv&lt;/a&gt; to manage Python dependencies. See the &lt;a href=&#34;https://docs.astral.sh/uv/getting-started/installation/&#34;&gt;uv installation instructions&lt;/a&gt; to set it up. Once uv is installed, run the following to set up the environment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;GIT_LFS_SKIP_SMUDGE=1 uv sync&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;NOTE: &lt;code&gt;GIT_LFS_SKIP_SMUDGE=1&lt;/code&gt; is needed to pull LeRobot as a dependency.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt;: As an alternative to uv installation, we provide instructions for installing openpi using Docker. If you encounter issues with your system setup, consider using Docker to simplify installation. See &lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/docs/docker.md&#34;&gt;Docker Setup&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Model Checkpoints&lt;/h2&gt; &#xA;&lt;h3&gt;Base Models&lt;/h3&gt; &#xA;&lt;p&gt;We provide multiple base VLA model checkpoints. These checkpoints have been pre-trained on 10k+ hours of robot data, and can be used for fine-tuning.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Use Case&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Checkpoint Path&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;$\pi_0$&lt;/td&gt; &#xA;   &lt;td&gt;Fine-Tuning&lt;/td&gt; &#xA;   &lt;td&gt;Base diffusion &lt;a href=&#34;https://www.physicalintelligence.company/blog/pi0&#34;&gt;Ï€â‚€ model&lt;/a&gt; for fine-tuning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;s3://openpi-assets/checkpoints/pi0_base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;$\pi_0$-FAST&lt;/td&gt; &#xA;   &lt;td&gt;Fine-Tuning&lt;/td&gt; &#xA;   &lt;td&gt;Base autoregressive &lt;a href=&#34;https://www.physicalintelligence.company/research/fast&#34;&gt;Ï€â‚€-FAST model&lt;/a&gt; for fine-tuning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;s3://openpi-assets/checkpoints/pi0_fast_base&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Fine-Tuned Models&lt;/h3&gt; &#xA;&lt;p&gt;We also provide &#34;expert&#34; checkpoints for various robot platforms and tasks. These models are fine-tuned from the base models above and intended to run directly on the target robot. These may or may not work on your particular robot. Since these checkpoints were fine-tuned on relatively small datasets collected with more widely available robots, such as ALOHA and the DROID Franka setup, they might not generalize to your particular setup, though we found some of these, especially the DROID checkpoint, to generalize quite broadly in practice.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Use Case&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Checkpoint Path&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;$\pi_0$-FAST-DROID&lt;/td&gt; &#xA;   &lt;td&gt;Inference&lt;/td&gt; &#xA;   &lt;td&gt;$\pi_0$-FAST model fine-tuned on the &lt;a href=&#34;https://droid-dataset.github.io/&#34;&gt;DROID dataset&lt;/a&gt;, can perform a wide range of simple table-top manipulation tasks 0-shot in new scenes on the DROID robot platform&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;s3://openpi-assets/checkpoints/pi0_fast_droid&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;$\pi_0$-DROID&lt;/td&gt; &#xA;   &lt;td&gt;Fine-Tuning&lt;/td&gt; &#xA;   &lt;td&gt;$\pi_0$ model fine-tuned on the &lt;a href=&#34;https://droid-dataset.github.io/&#34;&gt;DROID dataset&lt;/a&gt;, faster inference than $\pi_0$-FAST-DROID, but may not follow language commands as well&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;s3://openpi-assets/checkpoints/pi0_droid&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;$\pi_0$-ALOHA-towel&lt;/td&gt; &#xA;   &lt;td&gt;Inference&lt;/td&gt; &#xA;   &lt;td&gt;$\pi_0$ model fine-tuned on internal ALOHA data, can fold diverse towels 0-shot on &lt;a href=&#34;https://tonyzhaozh.github.io/aloha/&#34;&gt;ALOHA&lt;/a&gt; robot platforms&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;s3://openpi-assets/checkpoints/pi0_aloha_towel&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;$\pi_0$-ALOHA-tupperware&lt;/td&gt; &#xA;   &lt;td&gt;Inference&lt;/td&gt; &#xA;   &lt;td&gt;$\pi_0$ model fine-tuned on internal ALOHA data, can unpack food from a tupperware container&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;s3://openpi-assets/checkpoints/pi0_aloha_tupperware&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;$\pi_0$-ALOHA-pen-uncap&lt;/td&gt; &#xA;   &lt;td&gt;Inference&lt;/td&gt; &#xA;   &lt;td&gt;$\pi_0$ model fine-tuned on &lt;a href=&#34;https://dit-policy.github.io/&#34;&gt;public ALOHA data&lt;/a&gt;, can uncap a pen&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;s3://openpi-assets/checkpoints/pi0_aloha_pen_uncap&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;By default, checkpoints are automatically downloaded from &lt;code&gt;s3://openpi-assets&lt;/code&gt; and are cached in &lt;code&gt;~/.cache/openpi&lt;/code&gt; when needed. You can overwrite the download path by setting the &lt;code&gt;OPENPI_DATA_HOME&lt;/code&gt; environment variable.&lt;/p&gt; &#xA;&lt;h2&gt;Running Inference for a Pre-Trained Model&lt;/h2&gt; &#xA;&lt;p&gt;Our pre-trained model checkpoints can be run with a few lines of code (here our $\pi_0$-FAST-DROID model):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from openpi.training import config&#xA;from openpi.policies import policy_config&#xA;from openpi.shared import download&#xA;&#xA;config = config.get_config(&#34;pi0_fast_droid&#34;)&#xA;checkpoint_dir = download.maybe_download(&#34;s3://openpi-assets/checkpoints/pi0_fast_droid&#34;)&#xA;&#xA;# Create a trained policy.&#xA;policy = policy_config.create_trained_policy(config, checkpoint_dir)&#xA;&#xA;# Run inference on a dummy example.&#xA;example = {&#xA;    &#34;observation/exterior_image_1_left&#34;: ...,&#xA;    &#34;observation/wrist_image_left&#34;: ...,&#xA;    ...&#xA;    &#34;prompt&#34;: &#34;pick up the fork&#34;&#xA;}&#xA;action_chunk = policy.infer(example)[&#34;actions&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also test this out in the &lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/inference.ipynb&#34;&gt;example notebook&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We provide detailed step-by-step examples for running inference of our pre-trained checkpoints on &lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/droid/README.md&#34;&gt;DROID&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/aloha_real/README.md&#34;&gt;ALOHA&lt;/a&gt; robots.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Remote Inference&lt;/strong&gt;: We provide &lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/docs/remote_inference.md&#34;&gt;examples and code&lt;/a&gt; for running inference of our models &lt;strong&gt;remotely&lt;/strong&gt;: the model can run on a different server and stream actions to the robot via a websocket connection. This makes it easy to use more powerful GPUs off-robot and keep robot and policy environments separate.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Test inference without a robot&lt;/strong&gt;: We provide a &lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/simple_client/README.md&#34;&gt;script&lt;/a&gt; for testing inference without a robot. This script will generate a random observation and run inference with the model. See &lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/simple_client/README.md&#34;&gt;here&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Fine-Tuning Base Models on Your Own Data&lt;/h2&gt; &#xA;&lt;p&gt;We will fine-tune the $\pi_0$-FAST model on the &lt;a href=&#34;https://libero-project.github.io/datasets&#34;&gt;Libero dataset&lt;/a&gt; as a running example for how to fine-tune a base model on your own data. We will explain three steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Convert your data to a LeRobot dataset (which we use for training)&lt;/li&gt; &#xA; &lt;li&gt;Defining training configs and running training&lt;/li&gt; &#xA; &lt;li&gt;Spinning up a policy server and running inference&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;1. Convert your data to a LeRobot dataset&lt;/h3&gt; &#xA;&lt;p&gt;We provide a minimal example script for converting Libero data to a LeRobot dataset in &lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/libero/convert_libero_data_to_lerobot.py&#34;&gt;&lt;code&gt;examples/libero/convert_libero_data_to_lerobot.py&lt;/code&gt;&lt;/a&gt;. You can easily modify it to convert your own data! You can download the raw Libero dataset from &lt;a href=&#34;https://huggingface.co/datasets/openvla/modified_libero_rlds&#34;&gt;here&lt;/a&gt;, and run the script with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uv run examples/libero/convert_libero_data_to_lerobot.py --data_dir /path/to/your/libero/data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Defining training configs and running training&lt;/h3&gt; &#xA;&lt;p&gt;To fine-tune a base model on your own data, you need to define configs for data processing and training. We provide example configs with detailed comments for Libero below, which you can modify for your own dataset:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/policies/libero_policy.py&#34;&gt;&lt;code&gt;LiberoInputs&lt;/code&gt; and &lt;code&gt;LiberoOutputs&lt;/code&gt;&lt;/a&gt;: Defines the data mapping from the Libero environment to the model and vice versa. Will be used for both, training and inference.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/training/config.py&#34;&gt;&lt;code&gt;LeRobotLiberoDataConfig&lt;/code&gt;&lt;/a&gt;: Defines how to process raw Libero data from LeRobot dataset for training.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/training/config.py&#34;&gt;&lt;code&gt;TrainConfig&lt;/code&gt;&lt;/a&gt;: Defines fine-tuning hyperparameters, data config, and weight loader.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We provide example fine-tuning configs for both, &lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/training/config.py&#34;&gt;Ï€â‚€&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/training/config.py&#34;&gt;Ï€â‚€-FAST&lt;/a&gt; on Libero data.&lt;/p&gt; &#xA;&lt;p&gt;Before we can run training, we need to compute the normalization statistics for the training data. Run the script below with the name of your training config:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uv run scripts/compute_norm_stats.py --config-name pi0_fast_libero&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now we can kick off training with the following command (the &lt;code&gt;--overwrite&lt;/code&gt; flag is used to overwrite existing checkpoints if you rerun fine-tuning with the same config):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;XLA_PYTHON_CLIENT_MEM_FRACTION=0.9 uv run scripts/train.py pi0_fast_libero --exp-name=my_experiment --overwrite&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The command will log training progress to the console and save checkpoints to the &lt;code&gt;checkpoints&lt;/code&gt; directory. You can also monitor training progress on the Weights &amp;amp; Biases dashboard. For maximally using the GPU memory, set &lt;code&gt;XLA_PYTHON_CLIENT_MEM_FRACTION=0.9&lt;/code&gt; before running training -- this enables JAX to use up to 90% of the GPU memory (vs. the default of 75%).&lt;/p&gt; &#xA;&lt;h3&gt;3. Spinning up a policy server and running inference&lt;/h3&gt; &#xA;&lt;p&gt;Once training is complete, we can run inference by spinning up a policy server and then querying it from a Libero evaluation script. Launching a model server is easy (we use the checkpoint for iteration 20,000 for this example, modify as needed):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uv run scripts/serve_policy.py policy:checkpoint --policy.config=pi0_fast_libero --policy.dir=checkpoints/pi0_fast_libero/my_experiment/20000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will spin up a server that listens on port 8000 and waits for observations to be sent to it. We can then run the Libero evaluation script to query the server. For instructions how to install Libero and run the evaluation script, see the &lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/libero/README.md&#34;&gt;Libero README&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;More Examples&lt;/h3&gt; &#xA;&lt;p&gt;We provide more examples for how to fine-tune and run inference with our models on the ALOHA platform in the following READMEs:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/aloha_sim&#34;&gt;ALOHA Simulator&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/aloha_real&#34;&gt;ALOHA Real&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Troubleshooting&lt;/h2&gt; &#xA;&lt;p&gt;We will collect common issues and their solutions here. If you encounter an issue, please check here first. If you can&#39;t find a solution, please file an issue on the repo (see &lt;a href=&#34;https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/CONTRIBUTING.md&#34;&gt;here&lt;/a&gt; for guidelines).&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Issue&lt;/th&gt; &#xA;   &lt;th&gt;Resolution&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;uv sync&lt;/code&gt; fails with dependency conflicts&lt;/td&gt; &#xA;   &lt;td&gt;Try removing the virtual environment directory (&lt;code&gt;rm -rf .venv&lt;/code&gt;) and running &lt;code&gt;uv sync&lt;/code&gt; again. If issues persist, check that you have the latest version of &lt;code&gt;uv&lt;/code&gt; installed (&lt;code&gt;uv self update&lt;/code&gt;).&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Training runs out of GPU memory&lt;/td&gt; &#xA;   &lt;td&gt;Make sure you set &lt;code&gt;XLA_PYTHON_CLIENT_MEM_FRACTION=0.9&lt;/code&gt; before running training to allow JAX to use more GPU memory. You can also try reducing the batch size in your training config.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Policy server connection errors&lt;/td&gt; &#xA;   &lt;td&gt;Check that the server is running and listening on the expected port. Verify network connectivity and firewall settings between client and server.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Missing norm stats error when training&lt;/td&gt; &#xA;   &lt;td&gt;Run &lt;code&gt;scripts/compute_norm_stats.py&lt;/code&gt; with your config name before starting training.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Dataset download fails&lt;/td&gt; &#xA;   &lt;td&gt;Check your internet connection. If using &lt;code&gt;local_files_only=True&lt;/code&gt;, verify the dataset exists locally. For HuggingFace datasets, ensure you&#39;re logged in (&lt;code&gt;huggingface-cli login&lt;/code&gt;).&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CUDA/GPU errors&lt;/td&gt; &#xA;   &lt;td&gt;Verify NVIDIA drivers and CUDA toolkit are installed correctly. For Docker, ensure nvidia-container-toolkit is installed. Check GPU compatibility.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Import errors when running examples&lt;/td&gt; &#xA;   &lt;td&gt;Make sure you&#39;ve installed all dependencies with &lt;code&gt;uv sync&lt;/code&gt; and activated the virtual environment. Some examples may have additional requirements listed in their READMEs.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Action dimensions mismatch&lt;/td&gt; &#xA;   &lt;td&gt;Verify your data processing transforms match the expected input/output dimensions of your robot. Check the action space definitions in your policy classes.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
</feed>