<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-01-29T01:35:40Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Ucas-HaoranWei/Vary-toy</title>
    <updated>2024-01-29T01:35:40Z</updated>
    <id>tag:github.com,2024-01-29:/Ucas-HaoranWei/Vary-toy</id>
    <link href="https://github.com/Ucas-HaoranWei/Vary-toy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official code implementation of Vary-toy (Small Language Model Meets with Reinforced Vision Vocabulary)&lt;/p&gt;&lt;hr&gt;&lt;h3&gt;&lt;a href=&#34;&#34;&gt;Small Language Model Meets with Reinforced Vision Vocabulary&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;a href=&#34;https://varytoy.github.io/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project-Page-Green&#34;&gt;&lt;/a&gt; &#xA;&lt;a href=&#34;https://arxiv.org/abs/2401.12503&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Paper-PDF-orange&#34;&gt;&lt;/a&gt; &#xA;&lt;a href=&#34;https://vary.xiaomy.net/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/demo-blue&#34;&gt;&lt;/a&gt; &#xA;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/679447793&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/zhihu-yellow&#34;&gt;&lt;/a&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=J4naK0MAAAAJ&amp;amp;hl=en&#34;&gt;Haoran Wei*&lt;/a&gt;, Lingyu Kong*, Jinyue Chen, Liang Zhao, &lt;a href=&#34;https://joker316701882.github.io/&#34;&gt;Zheng Ge&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com.hk/citations?user=rWCQMNgAAAAJ&amp;amp;hl=zh-CN&amp;amp;oi=sra&#34;&gt;En Yu&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=MVZrGkYAAAAJ&amp;amp;hl=en&#34;&gt;Jianjian Sun&lt;/a&gt;, Chunrui Han, &lt;a href=&#34;https://scholar.google.com/citations?user=yuB-cfoAAAAJ&amp;amp;hl=en&#34;&gt;Xiangyu Zhang&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Ucas-HaoranWei/Vary-toy/main/assets/vary-toy-logo.jpg&#34; style=&#34;width: 200px&#34; align=&#34;center&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;&#34;&gt;The Young&#39;s First ``Large&#39;&#39; Vision Language Model&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Release&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2024/1/23] ðŸ”¥Eval codes will be available soon.&lt;/li&gt; &#xA; &lt;li&gt;[2024/1/23] ðŸ”¥ðŸ”¥ðŸ”¥You only need a single 1080Ti to experience all features of current LVLMs.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg?sanitize=true&#34; alt=&#34;Code License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca/raw/main/DATA_LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg?sanitize=true&#34; alt=&#34;Data License&#34;&gt;&lt;/a&gt; &lt;strong&gt;Usage and License Notices&lt;/strong&gt;: The data, code, and checkpoint are intended and licensed for research use only. They are also restricted to use that follow the license agreement of LLaMA, Vicuna, GPT-4, Qwen, and LLaVA.&lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ucas-HaoranWei/Vary-toy/main/#install&#34;&gt;Install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ucas-HaoranWei/Vary-toy/main/#vary-weights&#34;&gt;Vary-toy Weights&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ucas-HaoranWei/Vary-toy/main/#Demo&#34;&gt;Demo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Ucas-HaoranWei/Vary-toy/main/#train&#34;&gt;Train&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;Noteï¼šThe Vary-toy is based on Vary, if you install the &lt;a href=&#34;https://github.com/Ucas-HaoranWei/Vary&#34;&gt;Vary&lt;/a&gt;, you can skip some steps, e.g., 3.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repository and navigate to the Vary folder&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/Ucas-HaoranWei/Vary-toy.git&#xA;cd /path/to/vary&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Install Package&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;conda create -n vary python=3.10 -y&#xA;conda activate vary&#xA;pip install e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Install Flash-Attention&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install ninja&#xA;pip install flash-attn --no-build-isolation&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Vary Weights&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download the Vary-toy weights &lt;a href=&#34;https://huggingface.co/Haoran-megvii/Vary-toy&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Download the CLIP-VIT-L &lt;a href=&#34;https://huggingface.co/openai/clip-vit-large-patch14/&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Update the CLIP-VIT path in the codes (/cache/vit-large-patch14/) to your path.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;python vary/demo/run_qwen_vary.py  --model-name  /vary/model/path/ --image-file /an/image/file.png&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Train&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;deepspeed   Vary/train/train_qwen_vary.py  --deepspeed /Vary/zero_config/zero2.json&#xA;            --model_name_or_path /Vary-toy/path/&#xA;            --vision_tower /vit-large-patch14/path/&#xA;            --freeze_vision_tower True&#xA;            --freeze_lm_model False&#xA;            --vision_select_layer  -2&#xA;            --use_im_start_end True&#xA;            --bf16 True&#xA;            --per_device_eval_batch_size 4&#xA;            --gradient_accumulation_steps 1&#xA;            --evaluation_strategy &#34;no&#34;&#xA;            --save_strategy &#34;steps&#34;&#xA;            --save_steps 5000&#xA;            --save_total_limit 1&#xA;            --weight_decay 0.&#xA;            --warmup_ratio 0.03&#xA;            --lr_scheduler_type &#34;cosine&#34;&#xA;            --logging_steps 1 --tf32 True&#xA;            --model_max_length 4096&#xA;            --gradient_checkpointing True&#xA;            --dataloader_num_workers 4&#xA;            --report_to none&#xA;            --per_device_train_batch_size 4&#xA;            --num_train_epochs 1&#xA;            --learning_rate 5e-5&#xA;            --datasets  data_name1+data_name2+data_name3&#xA;            --output_dir /path/to/output/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We encourage you to extract the new vision vocabulary weights for your new base language model !!!&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions about the code or the paper, please email (&lt;code&gt;weihaoran18@mails.ucas.ac.cn&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;h2&gt;Discussion&lt;/h2&gt; &#xA;&lt;p&gt;Vary-toy is not a toy, and we have designed two excellent models based on it, one is Vary-document (specifically for document/pdf processing), and the other is Vary-plot for chart analysis. You can see their amazing performance here &lt;a href=&#34;https://github.com/Ucas-HaoranWei/Vary-family&#34;&gt;Vary-family&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find our work useful in your research, please consider citing Vary:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{wei2023vary,&#xA;  title={Vary: Scaling up the Vision Vocabulary for Large Vision-Language Models},&#xA;  author={Wei, Haoran and Kong, Lingyu and Chen, Jinyue and Zhao, Liang and Ge, Zheng and Yang, Jinrong and Sun, Jianjian and Han, Chunrui and Zhang, Xiangyu},&#xA;  journal={arXiv preprint arXiv:2312.06109},&#xA;  year={2023}&#xA;}&#xA;&#xA;@article{wei2024small,&#xA;  title={Small Language Model Meets with Reinforced Vision Vocabulary},&#xA;  author={Wei, Haoran and Kong, Lingyu and Chen, Jinyue and Zhao, Liang and Ge, Zheng and Yu, En and Sun, Jianjian and Han, Chunrui and Zhang, Xiangyu},&#xA;  journal={arXiv preprint arXiv:2401.12503},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>simonw/llm</title>
    <updated>2024-01-29T01:35:40Z</updated>
    <id>tag:github.com,2024-01-29:/simonw/llm</id>
    <link href="https://github.com/simonw/llm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Access large language models from the command-line&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LLM&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pypi.org/project/llm/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/llm.svg?sanitize=true&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://llm.datasette.io/&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/llm/badge/?version=latest&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://llm.datasette.io/en/stable/changelog.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/simonw/llm?include_prereleases&amp;amp;label=changelog&#34; alt=&#34;Changelog&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/simonw/llm/actions?query=workflow%3ATest&#34;&gt;&lt;img src=&#34;https://github.com/simonw/llm/workflows/Test/badge.svg?sanitize=true&#34; alt=&#34;Tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/simonw/llm/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202.0-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://datasette.io/discord-llm&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/823971286308356157?label=discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://formulae.brew.sh/formula/llm&#34;&gt;&lt;img src=&#34;https://img.shields.io/homebrew/installs/dy/llm?color=yellow&amp;amp;label=homebrew&amp;amp;logo=homebrew&#34; alt=&#34;Homebrew&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;A CLI utility and Python library for interacting with Large Language Models, both via remote APIs and models that can be installed and run on your own machine.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://llm.datasette.io/en/stable/usage.html#executing-a-prompt&#34;&gt;Run prompts from the command-line&lt;/a&gt;, &lt;a href=&#34;https://llm.datasette.io/en/stable/logging.html&#34;&gt;store the results in SQLite&lt;/a&gt;, &lt;a href=&#34;https://llm.datasette.io/en/stable/embeddings/index.html&#34;&gt;generate embeddings&lt;/a&gt; and more.&lt;/p&gt; &#xA;&lt;p&gt;Full documentation: &lt;strong&gt;&lt;a href=&#34;https://llm.datasette.io/&#34;&gt;llm.datasette.io&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Background on this project:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://simonwillison.net/2023/May/18/cli-tools-for-llms/&#34;&gt;llm, ttok and strip-tagsâ€”CLI tools for working with ChatGPT and other LLMs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://simonwillison.net/2023/Jul/12/llm/&#34;&gt;The LLM CLI tool now supports self-hosted language models via plugins&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://simonwillison.net/2023/Jul/18/accessing-llama-2/&#34;&gt;Accessing Llama 2 from the command-line with the llm-replicate plugin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://simonwillison.net/2023/Aug/1/llama-2-mac/&#34;&gt;Run Llama 2 on your own Mac using LLM and Homebrew&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://simonwillison.net/2023/Aug/3/weird-world-of-llms/&#34;&gt;Catching up on the weird world of LLMs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://simonwillison.net/2023/Sep/4/llm-embeddings/&#34;&gt;LLM now provides tools for working with embeddings&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://simonwillison.net/2023/Sep/12/llm-clip-and-chat/&#34;&gt;Build an image search engine with llm-clip, chat with models with llm chat&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://simonwillison.net/2023/Dec/18/mistral/&#34;&gt;Many options for running Mistral models in your terminal using LLM&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Install this tool using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install llm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or using &lt;a href=&#34;https://brew.sh/&#34;&gt;Homebrew&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install llm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://llm.datasette.io/en/stable/setup.html&#34;&gt;Detailed installation instructions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;p&gt;If you have an &lt;a href=&#34;https://platform.openai.com/api-keys&#34;&gt;OpenAI API key&lt;/a&gt; you can get started using the OpenAI models right away.&lt;/p&gt; &#xA;&lt;p&gt;As an alternative to OpenAI, you can &lt;a href=&#34;https://llm.datasette.io/en/stable/plugins/installing-plugins.html&#34;&gt;install plugins&lt;/a&gt; to access models by other providers, including models that can be installed and run on your own device.&lt;/p&gt; &#xA;&lt;p&gt;Save your OpenAI API key like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;llm keys set openai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will prompt you for your key like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Enter key: &amp;lt;paste here&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now that you&#39;ve saved a key you can run a prompt like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;llm &#34;Five cute names for a pet penguin&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;1. Waddles&#xA;2. Pebbles&#xA;3. Bubbles&#xA;4. Flappy&#xA;5. Chilly&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Read the &lt;a href=&#34;https://llm.datasette.io/en/stable/usage.html&#34;&gt;usage instructions&lt;/a&gt; for more.&lt;/p&gt; &#xA;&lt;h2&gt;Installing a model that runs on your own machine&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://llm.datasette.io/en/stable/plugins/index.html&#34;&gt;LLM plugins&lt;/a&gt; can add support for alternative models, including models that run on your own machine.&lt;/p&gt; &#xA;&lt;p&gt;To download and run Mistral 7B Instruct locally, you can install the &lt;a href=&#34;https://github.com/simonw/llm-gpt4all&#34;&gt;llm-gpt4all&lt;/a&gt; plugin:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;llm install llm-gpt4all&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then run this command to see which models it makes available:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;llm models&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;gpt4all: all-MiniLM-L6-v2-f16 - SBert, 43.76MB download, needs 1GB RAM&#xA;gpt4all: orca-mini-3b-gguf2-q4_0 - Mini Orca (Small), 1.84GB download, needs 4GB RAM&#xA;gpt4all: mistral-7b-instruct-v0 - Mistral Instruct, 3.83GB download, needs 8GB RAM&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Each model file will be downloaded once the first time you use it. Try Mistral out like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;llm -m mistral-7b-instruct-v0 &#39;difference between a pelican and a walrus&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also start a chat session with the model using the &lt;code&gt;llm chat&lt;/code&gt; command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;llm chat -m mistral-7b-instruct-v0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Chatting with mistral-7b-instruct-v0&#xA;Type &#39;exit&#39; or &#39;quit&#39; to exit&#xA;Type &#39;!multi&#39; to enter multiple lines, then &#39;!end&#39; to finish&#xA;&amp;gt; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Using a system prompt&lt;/h2&gt; &#xA;&lt;p&gt;You can use the &lt;code&gt;-s/--system&lt;/code&gt; option to set a system prompt, providing instructions for processing other input to the tool.&lt;/p&gt; &#xA;&lt;p&gt;To describe how the code a file works, try this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat mycode.py | llm -s &#34;Explain this code&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Help&lt;/h2&gt; &#xA;&lt;p&gt;For help, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;llm --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m llm --help&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>mealie-recipes/mealie</title>
    <updated>2024-01-29T01:35:40Z</updated>
    <id>tag:github.com,2024-01-29:/mealie-recipes/mealie</id>
    <link href="https://github.com/mealie-recipes/mealie" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Mealie is a self hosted recipe manager and meal planner with a RestAPI backend and a reactive frontend application built in Vue for a pleasant user experience for the whole family. Easily add recipes into your database by providing the url and mealie will automatically import the relevant data or add a family recipe with the UI editor&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://img.shields.io/github/v/release/mealie-recipes/mealie&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/mealie-recipes/mealie?style=flat-square&amp;amp;label=latest%20release&#34; alt=&#34;Latest Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/mealie-recipes/mealie/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/mealie-recipes/mealie.svg?style=flat-square&#34; alt=&#34;Contributors&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/mealie-recipes/mealie/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/mealie-recipes/mealie.svg?style=flat-square&#34; alt=&#34;Forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/mealie-recipes/mealie/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/mealie-recipes/mealie.svg?style=flat-square&#34; alt=&#34;Stargazers&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/mealie-recipes/mealie/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/mealie-recipes/mealie.svg?style=flat-square&#34; alt=&#34;Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/mealie-recipes/mealie/raw/mealie-next/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/mealie-recipes/mealie.svg?style=flat-square&#34; alt=&#34;AGPL License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://img.shields.io/docker/pulls/hkotel/mealie&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/hkotel/mealie&#34; alt=&#34;Docker Pulls&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- PROJECT LOGO --&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/mealie-recipes/mealie&#34;&gt; &#xA;  &lt;svg style=&#34;width:100px;height:100px&#34; viewbox=&#34;0 0 24 24&#34;&gt; &#xA;   &lt;path fill=&#34;currentColor&#34; d=&#34;M8.1,13.34L3.91,9.16C2.35,7.59 2.35,5.06 3.91,3.5L10.93,10.5L8.1,13.34M13.41,13L20.29,19.88L18.88,21.29L12,14.41L5.12,21.29L3.71,19.88L13.36,10.22L13.16,10C12.38,9.23 12.38,7.97 13.16,7.19L17.5,2.82L18.43,3.74L15.19,7L16.15,7.94L19.39,4.69L20.31,5.61L17.06,8.85L18,9.81L21.26,6.56L22.18,7.5L17.81,11.84C17.03,12.62 15.77,12.62 15,11.84L14.78,11.64L13.41,13Z&#34; /&gt; &#xA;  &lt;/svg&gt; &lt;/a&gt; &lt;/p&gt;&#xA;&lt;h3 align=&#34;center&#34;&gt;Mealie&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; A Place for All Your Recipes &lt;br&gt; &lt;a href=&#34;https://nightly.mealie.io&#34;&gt;&lt;strong&gt;Explore the docs Â»&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/mealie-recipes/mealie&#34;&gt; &lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://demo.mealie.io/&#34;&gt;View Demo&lt;/a&gt; Â· &lt;a href=&#34;https://github.com/mealie-recipes/mealie/issues&#34;&gt;Report Bug&lt;/a&gt; Â· &lt;a href=&#34;https://github.com/mealie-recipes/mealie/pkgs/container/mealie&#34;&gt;GitHub Container Registry&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.mealie.io&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mealie-recipes/mealie/mealie-next/docs/docs/assets/img/home_screenshot.png&#34; alt=&#34;Product Name Screen Shot&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;About The Project&lt;/h1&gt; &#xA;&lt;p&gt;Mealie is a self hosted recipe manager and meal planner with a RestAPI backend and a reactive frontend application built in Vue for a pleasant user experience for the whole family. Easily add recipes into your database by providing the URL and Mealie will automatically import the relevant data, or add a family recipe with the UI editor. Mealie also provides an API for interactions from 3rd party applications.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.gg/QuStdQGSGK&#34;&gt;Remember to join the Discord&lt;/a&gt;!&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nightly.mealie.io&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- CONTRIBUTING --&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are &lt;strong&gt;greatly appreciated&lt;/strong&gt;. If you&#39;re going to be working on the code-base, you&#39;ll want to use the nightly documentation to ensure you get the latest information.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;See the &lt;a href=&#34;https://nightly.mealie.io/contributors/developers-guide/code-contributions/&#34;&gt;Contributors Guide&lt;/a&gt; for help getting started.&lt;/li&gt; &#xA; &lt;li&gt;We use &lt;a href=&#34;https://code.visualstudio.com/docs/remote/containers&#34;&gt;VSCode Dev Containers&lt;/a&gt; to make it easy for contributors to get started!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you are not a coder, you can still contribute financially. Financial contributions help me prioritize working on this project over others and helps me know that there is a real demand for project development.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/haykot&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/v2/default-green.png&#34; alt=&#34;Buy Me A Coffee&#34; style=&#34;height: 30px !important;width: 107px !important;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Translations&lt;/h3&gt; &#xA;&lt;p&gt;Translations can be a great way for &lt;strong&gt;non-coders&lt;/strong&gt; to contribute to project. We use &lt;a href=&#34;https://crowdin.com/project/mealie&#34;&gt;Crowdin&lt;/a&gt; to allow several contributors to work on translating Mealie. You can simply help by voting for your preferred translations, or even by completely translating Mealie into a new language.&lt;/p&gt; &#xA;&lt;p&gt;For more information, check out the translation page on the &lt;a href=&#34;https://nightly.mealie.io/contributors/translating/&#34;&gt;contributor&#39;s guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;!-- LICENSE --&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Distributed under the AGPL License. See &lt;code&gt;LICENSE&lt;/code&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Sponsors&lt;/h2&gt; &#xA;&lt;p&gt;Huge thanks to all the sponsors of this project on &lt;a href=&#34;https://github.com/sponsors/hay-kot&#34;&gt;Github Sponsors&lt;/a&gt; and Buy Me a Coffee. Without you, this project would surely not be possible.&lt;/p&gt; &#xA;&lt;p&gt;Thanks to Linode for providing Hosting for the Demo, Beta, and Documentation sites! Another big thanks to JetBrains for providing their IDEs for development.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img height=&#34;100&#34; src=&#34;https://raw.githubusercontent.com/mealie-recipes/mealie/mealie-next/docs/docs/assets/img/sponsors-linode.svg?sanitize=true&#34;&gt; &#xA; &lt;img height=&#34;100&#34; src=&#34;https://raw.githubusercontent.com/mealie-recipes/mealie/mealie-next/docs/docs/assets/img/sponsors-jetbrains.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; &#xA;&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</summary>
  </entry>
</feed>