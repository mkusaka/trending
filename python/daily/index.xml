<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-02-04T01:37:35Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Blaizzy/mlx-vlm</title>
    <updated>2025-02-04T01:37:35Z</updated>
    <id>tag:github.com,2025-02-04:/Blaizzy/mlx-vlm</id>
    <link href="https://github.com/Blaizzy/mlx-vlm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;MLX-VLM is a package for inference and fine-tuning of Vision Language Models (VLMs) on your Mac using MLX.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MLX-VLM&lt;/h1&gt; &#xA;&lt;p&gt;MLX-VLM is a package for inference and fine-tuning of Vision Language Models (VLMs) on your Mac using MLX.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#usage&#34;&gt;Usage&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#command-line-interface-cli&#34;&gt;Command Line Interface (CLI)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#chat-ui-with-gradio&#34;&gt;Chat UI with Gradio&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#python-script&#34;&gt;Python Script&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#multi-image-chat-support&#34;&gt;Multi-Image Chat Support&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#supported-models&#34;&gt;Supported Models&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#usage-examples&#34;&gt;Usage Examples&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#fine-tuning&#34;&gt;Fine-tuning&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;The easiest way to get started is to install the &lt;code&gt;mlx-vlm&lt;/code&gt; package using pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install mlx-vlm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Command Line Interface (CLI)&lt;/h3&gt; &#xA;&lt;p&gt;Generate output from a model using the CLI:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python -m mlx_vlm.generate --model mlx-community/Qwen2-VL-2B-Instruct-4bit --max-tokens 100 --temp 0.0 --image http://images.cocodataset.org/val2017/000000039769.jpg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Chat UI with Gradio&lt;/h3&gt; &#xA;&lt;p&gt;Launch a chat interface using Gradio:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python -m mlx_vlm.chat_ui --model mlx-community/Qwen2-VL-2B-Instruct-4bit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Python Script&lt;/h3&gt; &#xA;&lt;p&gt;Here&#39;s an example of how to use MLX-VLM in a Python script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import mlx.core as mx&#xA;from mlx_vlm import load, generate&#xA;from mlx_vlm.prompt_utils import apply_chat_template&#xA;from mlx_vlm.utils import load_config&#xA;&#xA;# Load the model&#xA;model_path = &#34;mlx-community/Qwen2-VL-2B-Instruct-4bit&#34;&#xA;model, processor = load(model_path)&#xA;config = load_config(model_path)&#xA;&#xA;# Prepare input&#xA;image = [&#34;http://images.cocodataset.org/val2017/000000039769.jpg&#34;]&#xA;prompt = &#34;Describe this image.&#34;&#xA;&#xA;# Apply chat template&#xA;formatted_prompt = apply_chat_template(&#xA;    processor, config, prompt, num_images=len(image)&#xA;)&#xA;&#xA;# Generate output&#xA;output = generate(model, processor, formatted_prompt, image, verbose=False)&#xA;print(output)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Multi-Image Chat Support&lt;/h2&gt; &#xA;&lt;p&gt;MLX-VLM supports analyzing multiple images simultaneously with select models. This feature enables more complex visual reasoning tasks and comprehensive analysis across multiple images in a single conversation.&lt;/p&gt; &#xA;&lt;h3&gt;Supported Models&lt;/h3&gt; &#xA;&lt;p&gt;The following models support multi-image chat:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Idefics 2&lt;/li&gt; &#xA; &lt;li&gt;LLaVA (Interleave)&lt;/li&gt; &#xA; &lt;li&gt;Qwen2-VL&lt;/li&gt; &#xA; &lt;li&gt;Phi3-Vision&lt;/li&gt; &#xA; &lt;li&gt;Pixtral&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Usage Examples&lt;/h3&gt; &#xA;&lt;h4&gt;Python Script&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mlx_vlm import load, generate&#xA;from mlx_vlm.prompt_utils import apply_chat_template&#xA;from mlx_vlm.utils import load_config&#xA;&#xA;model_path = &#34;mlx-community/Qwen2-VL-2B-Instruct-4bit&#34;&#xA;model, processor = load(model_path)&#xA;config = load_config(model_path)&#xA;&#xA;images = [&#34;path/to/image1.jpg&#34;, &#34;path/to/image2.jpg&#34;]&#xA;prompt = &#34;Compare these two images.&#34;&#xA;&#xA;formatted_prompt = apply_chat_template(&#xA;    processor, config, prompt, num_images=len(images)&#xA;)&#xA;&#xA;output = generate(model, processor, formatted_prompt, images, verbose=False)&#xA;print(output)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Command Line&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python -m mlx_vlm.generate --model mlx-community/Qwen2-VL-2B-Instruct-4bit --max-tokens 100 --prompt &#34;Compare these images&#34; --image path/to/image1.jpg path/to/image2.jpg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Video Understanding&lt;/h2&gt; &#xA;&lt;p&gt;MLX-VLM also supports video analysis such as captioning, summarization, and more, with select models.&lt;/p&gt; &#xA;&lt;h3&gt;Supported Models&lt;/h3&gt; &#xA;&lt;p&gt;The following models support video chat:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Qwen2-VL&lt;/li&gt; &#xA; &lt;li&gt;Qwen2.5-VL&lt;/li&gt; &#xA; &lt;li&gt;Idefics3&lt;/li&gt; &#xA; &lt;li&gt;LLaVA&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;With more coming soon.&lt;/p&gt; &#xA;&lt;h3&gt;Usage Examples&lt;/h3&gt; &#xA;&lt;h4&gt;Command Line&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python -m mlx_vlm.video_generate --model mlx-community/Qwen2-VL-2B-Instruct-4bit --max-tokens 100 --prompt &#34;Describe this video&#34; --video path/to/video.mp4 --max-pixels 224 224 --fps 1.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;These examples demonstrate how to use multiple images with MLX-VLM for more complex visual reasoning tasks.&lt;/p&gt; &#xA;&lt;h1&gt;Fine-tuning&lt;/h1&gt; &#xA;&lt;p&gt;MLX-VLM supports fine-tuning models with LoRA and QLoRA.&lt;/p&gt; &#xA;&lt;h2&gt;LoRA &amp;amp; QLoRA&lt;/h2&gt; &#xA;&lt;p&gt;To learn more about LoRA, please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/mlx_vlm/LORA.MD&#34;&gt;LoRA.md&lt;/a&gt; file.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Soulter/AstrBot</title>
    <updated>2025-02-04T01:37:35Z</updated>
    <id>tag:github.com,2025-02-04:/Soulter/AstrBot</id>
    <link href="https://github.com/Soulter/AstrBot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;✨易上手的多平台 LLM 聊天机器人及开发框架✨。支持 QQ、QQ频道、Telegram、微信平台(Gewechat)、内置 Web Chat，OpenAI GPT、DeepSeek、Ollama、Llama、GLM、Gemini、OneAPI、LLMTuner，支持 LLM Agent 插件开发，可视化面板。一键部署。支持 Dify 工作流、代码执行器、Whisper 语音转文字。&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/07649e07-3b8e-4feb-9aa9-bf13af4f3476&#34; alt=&#34;logo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;em&gt;✨ 易上手的多平台 LLM 聊天机器人及开发框架 ✨&lt;/em&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/Soulter/AstrBot/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/Soulter/AstrBot&#34; alt=&#34;GitHub release (latest by date)&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/python-3.10+-blue.svg?sanitize=true&#34; alt=&#34;python&#34;&gt; &lt;a href=&#34;https://hub.docker.com/r/soulter/astrbot&#34;&gt;&lt;img alt=&#34;Docker pull&#34; src=&#34;https://img.shields.io/docker/pulls/soulter/astrbot.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;img alt=&#34;Static Badge&#34; src=&#34;https://img.shields.io/badge/QQ%E7%BE%A4-322154837-purple&#34;&gt; &lt;a href=&#34;https://wakatime.com/badge/user/915e5316-99c6-4563-a483-ef186cf000c9/project/018e705a-a1a7-409a-a849-3013485e6c8e&#34;&gt;&lt;img src=&#34;https://wakatime.com/badge/user/915e5316-99c6-4563-a483-ef186cf000c9/project/018e705a-a1a7-409a-a849-3013485e6c8e.svg?sanitize=true&#34; alt=&#34;wakatime&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.soulter.top%2Fastrbot%2Fstats&amp;amp;query=v&amp;amp;label=7%E6%97%A5%E6%B6%88%E6%81%AF%E4%B8%8A%E8%A1%8C%E9%87%8F&amp;amp;cacheSeconds=3600&#34; alt=&#34;Dynamic JSON Badge&#34;&gt; &lt;a href=&#34;https://codecov.io/gh/Soulter/AstrBot&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/Soulter/AstrBot/graph/badge.svg?token=FF3P5967B8&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://astrbot.app/&#34;&gt;查看文档&lt;/a&gt; ｜ &lt;a href=&#34;https://github.com/Soulter/AstrBot/issues&#34;&gt;问题提交&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;AstrBot 是一个松耦合、异步、支持多消息平台部署、具有易用的插件系统和完善的大语言模型（LLM）接入功能的聊天机器人及开发框架。&lt;/p&gt; &#xA;&lt;h2&gt;✨ 主要功能&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;大语言模型对话&lt;/strong&gt;。支持各种大语言模型，包括 OpenAI API、Google Gemini、Llama、Deepseek、ChatGLM 等，支持接入本地部署的大模型，通过 Ollama、LLMTuner。具有多轮对话、人格情境、多模态能力，支持图片理解、语音转文字（Whisper）。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;多消息平台接入&lt;/strong&gt;。支持接入 QQ（OneBot）、QQ 频道、微信（Gewechat、VChat）、Telegram。后续将支持钉钉、飞书、Discord、WhatsApp、小爱音响。支持速率限制、白名单、关键词过滤、百度内容审核。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Agent&lt;/strong&gt;。原生支持部分 Agent 能力，如代码执行器、自然语言待办、网页搜索。对接 &lt;a href=&#34;https://astrbot.app/others/dify.html&#34;&gt;Dify 平台&lt;/a&gt;，便捷接入 Dify 智能助手、知识库和 Dify 工作流。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;插件扩展&lt;/strong&gt;。深度优化的插件机制，支持&lt;a href=&#34;https://astrbot.app/dev/plugin.html&#34;&gt;开发插件&lt;/a&gt;扩展功能，极简开发。已支持安装多个插件。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;可视化管理面板&lt;/strong&gt;。支持可视化修改配置、插件管理、日志查看等功能，降低配置难度。集成 WebChat，可在面板上与大模型对话。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;高稳定性、高模块化&lt;/strong&gt;。基于事件总线和流水线的架构设计，高度模块化，低耦合。&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] 管理面板在线体验 Demo: &lt;a href=&#34;https://demo.astrbot.app/&#34;&gt;https://demo.astrbot.app/&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;用户名: &lt;code&gt;astrbot&lt;/code&gt;, 密码: &lt;code&gt;astrbot&lt;/code&gt;。未配置 LLM，无法在聊天页使用大模型。（不要再修改 demo 的登录密码了 😭）&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;✨ 使用方式&lt;/h2&gt; &#xA;&lt;h4&gt;Docker 部署&lt;/h4&gt; &#xA;&lt;p&gt;请参阅官方文档 &lt;a href=&#34;https://astrbot.app/deploy/astrbot/docker.html#%E4%BD%BF%E7%94%A8-docker-%E9%83%A8%E7%BD%B2-astrbot&#34;&gt;使用 Docker 部署 AstrBot&lt;/a&gt; 。&lt;/p&gt; &#xA;&lt;h4&gt;Windows 一键安装器部署&lt;/h4&gt; &#xA;&lt;p&gt;需要电脑上安装有 Python（&amp;gt;3.10）。请参阅官方文档 &lt;a href=&#34;https://astrbot.app/deploy/astrbot/windows.html&#34;&gt;使用 Windows 一键安装器部署 AstrBot&lt;/a&gt; 。&lt;/p&gt; &#xA;&lt;h4&gt;Replit 部署&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://repl.it/github/Soulter/AstrBot&#34;&gt;&lt;img src=&#34;https://repl.it/badge/github/Soulter/AstrBot&#34; alt=&#34;Run on Repl.it&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;CasaOS 部署&lt;/h4&gt; &#xA;&lt;p&gt;社区贡献的部署方式。&lt;/p&gt; &#xA;&lt;p&gt;请参阅官方文档 &lt;a href=&#34;https://astrbot.app/deploy/astrbot/casaos.html&#34;&gt;通过源码部署 AstrBot&lt;/a&gt; 。&lt;/p&gt; &#xA;&lt;h4&gt;手动部署&lt;/h4&gt; &#xA;&lt;p&gt;请参阅官方文档 &lt;a href=&#34;https://astrbot.app/deploy/astrbot/cli.html&#34;&gt;通过源码部署 AstrBot&lt;/a&gt; 。&lt;/p&gt; &#xA;&lt;h2&gt;⚡ 消息平台支持情况&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;平台&lt;/th&gt; &#xA;   &lt;th&gt;支持性&lt;/th&gt; &#xA;   &lt;th&gt;详情&lt;/th&gt; &#xA;   &lt;th&gt;消息类型&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;QQ(官方机器人接口)&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;私聊、群聊，QQ 频道私聊、群聊&lt;/td&gt; &#xA;   &lt;td&gt;文字、图片&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;QQ(OneBot)&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;私聊、群聊&lt;/td&gt; &#xA;   &lt;td&gt;文字、图片、语音&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;微信(个人号)&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;微信个人号私聊、群聊&lt;/td&gt; &#xA;   &lt;td&gt;文字、图片、语音&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Soulter/astrbot_plugin_telegram&#34;&gt;Telegram&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;✔&lt;/td&gt; &#xA;   &lt;td&gt;私聊、群聊&lt;/td&gt; &#xA;   &lt;td&gt;文字、图片&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;微信(企业微信)&lt;/td&gt; &#xA;   &lt;td&gt;🚧&lt;/td&gt; &#xA;   &lt;td&gt;计划内&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;微信对话开放平台&lt;/td&gt; &#xA;   &lt;td&gt;🚧&lt;/td&gt; &#xA;   &lt;td&gt;计划内&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;飞书&lt;/td&gt; &#xA;   &lt;td&gt;🚧&lt;/td&gt; &#xA;   &lt;td&gt;计划内&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Discord&lt;/td&gt; &#xA;   &lt;td&gt;🚧&lt;/td&gt; &#xA;   &lt;td&gt;计划内&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;WhatsApp&lt;/td&gt; &#xA;   &lt;td&gt;🚧&lt;/td&gt; &#xA;   &lt;td&gt;计划内&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;小爱音响&lt;/td&gt; &#xA;   &lt;td&gt;🚧&lt;/td&gt; &#xA;   &lt;td&gt;计划内&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;🦌 接下来的路线图&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] 欢迎在 Issue 提出更多建议 &amp;lt;3&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 完善并保证目前所有平台适配器的功能一致性&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 优化插件接口&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 默认支持更多 TTS 服务，如 GPT-Sovits&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 完善“聊天增强”部分，支持持久化记忆&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 规划 i18n&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;❤️ 贡献&lt;/h2&gt; &#xA;&lt;p&gt;欢迎任何 Issues/Pull Requests！只需要将你的更改提交到此项目 ：)&lt;/p&gt; &#xA;&lt;p&gt;对于新功能的添加，请先通过 Issue 讨论。&lt;/p&gt; &#xA;&lt;h2&gt;🌟 支持&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Star 这个项目！&lt;/li&gt; &#xA; &lt;li&gt;在&lt;a href=&#34;https://afdian.com/a/soulter&#34;&gt;爱发电&lt;/a&gt;支持我！&lt;/li&gt; &#xA; &lt;li&gt;在&lt;a href=&#34;https://drive.soulter.top/f/pYfA/d903f4fa49a496fda3f16d2be9e023b5.png&#34;&gt;微信&lt;/a&gt;支持我~&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;✨ Demo&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] 代码执行器的文件输入/输出目前仅测试了 Napcat(QQ), Lagrange(QQ)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/4ee688d9-467d-45c8-99d6-368f9a8a92d8&#34; width=&#34;600&#34;&gt; &#xA; &lt;p&gt;&lt;em&gt;✨基于 Docker 的沙箱化代码执行器（Beta 测试中）✨&lt;/em&gt;&lt;/p&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/0378f407-6079-4f64-ae4c-e97ab20611d2&#34; height=&#34;500&#34;&gt; &#xA; &lt;p&gt;&lt;em&gt;✨ 多模态、网页搜索、长文本转图片（可配置） ✨&lt;/em&gt;&lt;/p&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/8ec12797-e70f-460a-959e-48eca39ca2bb&#34; height=&#34;100&#34;&gt; &#xA; &lt;p&gt;&lt;em&gt;✨ 自然语言待办事项 ✨&lt;/em&gt;&lt;/p&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/e137a9e1-340a-4bf2-bb2b-771132780735&#34; height=&#34;150&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/480f5e82-cf6a-4955-a869-0d73137aa6e1&#34; height=&#34;150&#34;&gt; &#xA; &lt;p&gt;&lt;em&gt;✨ 插件系统——部分插件展示 ✨&lt;/em&gt;&lt;/p&gt; &#xA; &lt;img src=&#34;https://github.com/user-attachments/assets/592a8630-14c7-4e06-b496-9c0386e4f36c&#34; width=&#34;600&#34;&gt; &#xA; &lt;p&gt;&lt;em&gt;✨ 管理面板 ✨&lt;/em&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://drive.soulter.top/f/vlsA/ezgif-5-fb044b2542.gif&#34; alt=&#34;webchat&#34;&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;em&gt;✨ 内置 Web Chat，在线与机器人交互 ✨&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;⭐ Star History&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] 如果本项目对您的生活 / 工作产生了帮助，或者您关注本项目的未来发展，请给项目 Star，这是我维护这个开源项目的动力 &amp;lt;3&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://star-history.com/#soulter/astrbot&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=soulter/astrbot&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Sponsors&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://api.gitsponsors.com/api/badge/link?p=XEpbdGxlitw/RbcwiTX93UMzNK/jgDYC8NiSzamIPMoKvG2lBFmyXhSS/b0hFoWlBBMX2L5X5CxTDsUdyvcIEHTOfnkXz47UNOZvMwyt5CzbYpq0SEzsSV1OJF1cCo90qC/ZyYKYOWedal3MhZ3ikw==&#34;&gt;&lt;img src=&#34;https://api.gitsponsors.com/api/badge/img?id=575865240&#34; height=&#34;20&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The project is protected under the &lt;code&gt;AGPL-v3&lt;/code&gt; opensource license.&lt;/li&gt; &#xA; &lt;li&gt;The deployment of WeChat (personal account) utilizes &lt;a href=&#34;https://github.com/Devo919/Gewechat&#34;&gt;Gewechat&lt;/a&gt; service. AstrBot only guarantees connectivity with Gewechat and recommends using a WeChat account that is not frequently used. In the event of account risk control, the author of this project shall not bear any responsibility.&lt;/li&gt; &#xA; &lt;li&gt;Please ensure compliance with local laws and regulations when using this project.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;!-- ## ✨ ATRI [Beta 测试]&#xA;&#xA;该功能作为插件载入。插件仓库地址：[astrbot_plugin_atri](https://github.com/Soulter/astrbot_plugin_atri)&#xA;&#xA;1. 基于《ATRI ~ My Dear Moments》主角 ATRI 角色台词作为微调数据集的 `Qwen1.5-7B-Chat Lora` 微调模型。&#xA;2. 长期记忆&#xA;3. 表情包理解与回复&#xA;4. TTS&#xA;    --&gt; &#xA;&lt;p&gt;&lt;em&gt;私は、高性能ですから!&lt;/em&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>agno-agi/agno</title>
    <updated>2025-02-04T01:37:35Z</updated>
    <id>tag:github.com,2025-02-04:/agno-agi/agno</id>
    <link href="https://github.com/agno-agi/agno" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Agno is a lightweight framework for building multi-modal Agents&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34; id=&#34;top&#34;&gt; &#xA; &lt;a href=&#34;https://docs.agno.com&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;.assets/logo-dark.svg&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;.assets/logo-light.svg&#34;&gt; &#xA;   &lt;img src=&#34;https://raw.githubusercontent.com/agno-agi/agno/main/.assets/logo-light.svg?sanitize=true&#34; alt=&#34;Agno&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://docs.agno.com&#34;&gt;📚 Documentation&lt;/a&gt; &amp;nbsp;|&amp;nbsp; &#xA; &lt;a href=&#34;https://docs.agno.com/examples/introduction&#34;&gt;💡 Examples&lt;/a&gt; &amp;nbsp;|&amp;nbsp; &#xA; &lt;a href=&#34;https://github.com/agno-agi/agno/stargazers&#34;&gt;🌟 Star Us&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.agno.com&#34;&gt;Agno&lt;/a&gt; is a lightweight framework for building multi-modal Agents.&lt;/p&gt; &#xA;&lt;h2&gt;Simple, Fast, and Agnostic&lt;/h2&gt; &#xA;&lt;p&gt;Agno is designed with three core principles:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Simplicity&lt;/strong&gt;: No graphs, chains, or convoluted patterns — just pure python.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Uncompromising Performance&lt;/strong&gt;: Blazing fast agents with a minimal memory footprint.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Truly Agnostic&lt;/strong&gt;: Any model, any provider, any modality. Future-proof agents.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Key features&lt;/h2&gt; &#xA;&lt;p&gt;Here&#39;s why you should build Agents with Agno:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Lightning Fast&lt;/strong&gt;: Agent creation is 6000x faster than LangGraph (see &lt;a href=&#34;https://raw.githubusercontent.com/agno-agi/agno/main/#performance&#34;&gt;performance&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Model Agnostic&lt;/strong&gt;: Use any model, any provider, no lock-in.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi Modal&lt;/strong&gt;: Native support for text, image, audio and video.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi Agent&lt;/strong&gt;: Delegate tasks across a team of specialized agents.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Memory Management&lt;/strong&gt;: Store user sessions and agent state in a database.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Knowledge Stores&lt;/strong&gt;: Use vector databases for Agentic RAG or dynamic few-shot.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Structured Outputs&lt;/strong&gt;: Make Agents respond with structured data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Monitoring&lt;/strong&gt;: Track agent sessions and performance in real-time on &lt;a href=&#34;https://app.agno.com&#34;&gt;agno.com&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install -U agno&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;What are Agents?&lt;/h2&gt; &#xA;&lt;p&gt;Agents are autonomous programs that use language models to achieve tasks. They solve problems by running tools, accessing knowledge and memory to improve responses.&lt;/p&gt; &#xA;&lt;p&gt;Instead of a rigid binary definition, let&#39;s think of Agents in terms of agency and autonomy.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Level 0&lt;/strong&gt;: Agents with no tools (basic inference tasks).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Level 1&lt;/strong&gt;: Agents with tools for autonomous task execution.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Level 2&lt;/strong&gt;: Agents with knowledge, combining memory and reasoning.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Level 3&lt;/strong&gt;: Teams of agents collaborating on complex workflows.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Example - Basic Agent&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from agno.agent import Agent&#xA;from agno.models.openai import OpenAIChat&#xA;&#xA;agent = Agent(&#xA;    model=OpenAIChat(id=&#34;gpt-4o&#34;),&#xA;    description=&#34;You are an enthusiastic news reporter with a flair for storytelling!&#34;,&#xA;    markdown=True&#xA;)&#xA;agent.print_response(&#34;Tell me about a breaking news story from New York.&#34;, stream=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run the agent, install dependencies and export your &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install agno openai&#xA;&#xA;export OPENAI_API_KEY=sk-xxxx&#xA;&#xA;python basic_agent.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/agno-agi/agno/main/cookbook/getting_started/01_basic_agent.py&#34;&gt;View this example in the cookbook&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Example - Agent with tools&lt;/h2&gt; &#xA;&lt;p&gt;This basic agent will obviously make up a story, lets give it a tool to search the web.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from agno.agent import Agent&#xA;from agno.models.openai import OpenAIChat&#xA;from agno.tools.duckduckgo import DuckDuckGoTools&#xA;&#xA;agent = Agent(&#xA;    model=OpenAIChat(id=&#34;gpt-4o&#34;),&#xA;    description=&#34;You are an enthusiastic news reporter with a flair for storytelling!&#34;,&#xA;    tools=[DuckDuckGoTools()],&#xA;    show_tool_calls=True,&#xA;    markdown=True&#xA;)&#xA;agent.print_response(&#34;Tell me about a breaking news story from New York.&#34;, stream=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install dependencies and run the Agent:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install duckduckgo-search&#xA;&#xA;python agent_with_tools.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now you should see a much more relevant result.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/agno-agi/agno/main/cookbook/getting_started/02_agent_with_tools.py&#34;&gt;View this example in the cookbook&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Example - Agent with knowledge&lt;/h2&gt; &#xA;&lt;p&gt;Agents can store knowledge in a vector database and use it for RAG or dynamic few-shot learning.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Agno agents use Agentic RAG&lt;/strong&gt; by default, which means they will search their knowledge base for the specific information they need to achieve their task.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from agno.agent import Agent&#xA;from agno.models.openai import OpenAIChat&#xA;from agno.embedder.openai import OpenAIEmbedder&#xA;from agno.tools.duckduckgo import DuckDuckGoTools&#xA;from agno.knowledge.pdf_url import PDFUrlKnowledgeBase&#xA;from agno.vectordb.lancedb import LanceDb, SearchType&#xA;&#xA;agent = Agent(&#xA;    model=OpenAIChat(id=&#34;gpt-4o&#34;),&#xA;    description=&#34;You are a Thai cuisine expert!&#34;,&#xA;    instructions=[&#xA;        &#34;Search your knowledge base for Thai recipes.&#34;,&#xA;        &#34;If the question is better suited for the web, search the web to fill in gaps.&#34;,&#xA;        &#34;Prefer the information in your knowledge base over the web results.&#34;&#xA;    ],&#xA;    knowledge=PDFUrlKnowledgeBase(&#xA;        urls=[&#34;https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf&#34;],&#xA;        vector_db=LanceDb(&#xA;            uri=&#34;tmp/lancedb&#34;,&#xA;            table_name=&#34;recipes&#34;,&#xA;            search_type=SearchType.hybrid,&#xA;            embedder=OpenAIEmbedder(id=&#34;text-embedding-3-small&#34;),&#xA;        ),&#xA;    ),&#xA;    tools=[DuckDuckGoTools()],&#xA;    show_tool_calls=True,&#xA;    markdown=True&#xA;)&#xA;&#xA;# Comment out after the knowledge base is loaded&#xA;if agent.knowledge is not None:&#xA;    agent.knowledge.load()&#xA;&#xA;agent.print_response(&#34;How do I make chicken and galangal in coconut milk soup&#34;, stream=True)&#xA;agent.print_response(&#34;What is the history of Thai curry?&#34;, stream=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install dependencies and run the Agent:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install lancedb tantivy pypdf duckduckgo-search&#xA;&#xA;python agent_with_knowledge.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/agno-agi/agno/main/cookbook/getting_started/03_agent_with_knowledge.py&#34;&gt;View this example in the cookbook&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Example - Multi Agent Teams&lt;/h2&gt; &#xA;&lt;p&gt;Agents work best when they have a singular purpose, a narrow scope and a small number of tools. When the number of tools grows beyond what the language model can handle or the tools belong to different categories, use a team of agents to spread the load.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from agno.agent import Agent&#xA;from agno.models.openai import OpenAIChat&#xA;from agno.tools.duckduckgo import DuckDuckGoTools&#xA;from agno.tools.yfinance import YFinanceTools&#xA;&#xA;web_agent = Agent(&#xA;    name=&#34;Web Agent&#34;,&#xA;    role=&#34;Search the web for information&#34;,&#xA;    model=OpenAIChat(id=&#34;gpt-4o&#34;),&#xA;    tools=[DuckDuckGoTools()],&#xA;    instructions=&#34;Always include sources&#34;,&#xA;    show_tool_calls=True,&#xA;    markdown=True,&#xA;)&#xA;&#xA;finance_agent = Agent(&#xA;    name=&#34;Finance Agent&#34;,&#xA;    role=&#34;Get financial data&#34;,&#xA;    model=OpenAIChat(id=&#34;gpt-4o&#34;),&#xA;    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)],&#xA;    instructions=&#34;Use tables to display data&#34;,&#xA;    show_tool_calls=True,&#xA;    markdown=True,&#xA;)&#xA;&#xA;agent_team = Agent(&#xA;    team=[web_agent, finance_agent],&#xA;    model=OpenAIChat(id=&#34;gpt-4o&#34;),&#xA;    instructions=[&#34;Always include sources&#34;, &#34;Use tables to display data&#34;],&#xA;    show_tool_calls=True,&#xA;    markdown=True,&#xA;)&#xA;&#xA;agent_team.print_response(&#34;What&#39;s the market outlook and financial performance of AI semiconductor companies?&#34;, stream=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install dependencies and run the Agent team:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install duckduckgo-search yfinance&#xA;&#xA;python agent_team.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/agno-agi/agno/main/cookbook/getting_started/05_agent_team.py&#34;&gt;View this example in the cookbook&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Performance&lt;/h2&gt; &#xA;&lt;p&gt;Agno is designed for high performance agentic systems:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Agent instantiation: &amp;lt;5μs on average (5000x faster than LangGraph).&lt;/li&gt; &#xA; &lt;li&gt;Memory footprint: &amp;lt;0.01Mib on average (50x less memory than LangGraph).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Tested on an Apple M4 Mackbook Pro.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;While an Agent&#39;s performance is bottlenecked by inference, we must do everything possible to minimize execution time, reduce memory usage, and parallelize tool calls. These numbers are may seem minimal, but they add up even at medium scale.&lt;/p&gt; &#xA;&lt;h3&gt;Instantiation time&lt;/h3&gt; &#xA;&lt;p&gt;Let&#39;s measure the time it takes for an Agent with 1 tool to start up. We&#39;ll run the evaluation 1000 times to get a baseline measurement.&lt;/p&gt; &#xA;&lt;p&gt;You should run the evaluation yourself on your own machine, please, do not take these results at face value.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Setup virtual environment&#xA;./scripts/perf_setup.sh&#xA;source .venvs/perfenv/bin/activate&#xA;# OR Install dependencies manually&#xA;# pip install openai agno langgraph langchain_openai&#xA;&#xA;# Agno&#xA;python evals/performance/instantiation_with_tool.py&#xA;&#xA;# LangGraph&#xA;python evals/performance/other/langgraph_instantiation.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The following evaluation is run on an Apple M4 Mackbook Pro, but we&#39;ll soon be moving this to a Github actions runner for consistency.&lt;/p&gt; &#xA;&lt;p&gt;LangGraph is on the right, &lt;strong&gt;we start it first to give it a head start&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Agno is on the left, notice how it finishes before LangGraph gets 1/2 way through the runtime measurement, and hasn&#39;t even started the memory measurement. That&#39;s how fast Agno is.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/ba466d45-75dd-45ac-917b-0a56c5742e23&#34;&gt;https://github.com/user-attachments/assets/ba466d45-75dd-45ac-917b-0a56c5742e23&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Dividing the average time of a Langgraph Agent by the average time of an Agno Agent:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;0.020526s / 0.000002s ~ 10,263&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In this particular run, &lt;strong&gt;Agno Agent instantiation is roughly 10,000 times faster than Langgraph Agent instantiation&lt;/strong&gt;. Sure, the runtime will be dominated by inference, but these numbers add up as the number of Agents grows.&lt;/p&gt; &#xA;&lt;p&gt;The numbers continue to favor Agno as the number of tools grow, and we all memory and knowledge stores.&lt;/p&gt; &#xA;&lt;h3&gt;Memory usage&lt;/h3&gt; &#xA;&lt;p&gt;To measure memory usage, we use the &lt;code&gt;tracemalloc&lt;/code&gt; library. We first calculate a baseline memory usage by running an empty function, then run the Agent 1000x times and calculate the difference. This gives a (reasonably) isolated measurement of the memory usage of the Agent.&lt;/p&gt; &#xA;&lt;p&gt;We recommend running the evaluation yourself on your own machine, and digging into the code to see how it works. If we&#39;ve made a mistake, please let us know.&lt;/p&gt; &#xA;&lt;p&gt;Dividing the average memory usage of a Langgraph Agent by the average memory usage of an Agno Agent:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;0.137273/0.002528 ~ 54.3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Langgraph Agents use ~50x more memory than Agno Agents&lt;/strong&gt;. In our opinion, memory usage is a much more important metric than instantiation time. As we start running thousands of Agents in production, these numbers directly start affecting the cost of running the Agents.&lt;/p&gt; &#xA;&lt;h3&gt;Conclusion&lt;/h3&gt; &#xA;&lt;p&gt;Agno agents are designed for high-performance and while we do share some benchmarks against other frameworks, we should be mindful that accuracy and reliability are more important than speed.&lt;/p&gt; &#xA;&lt;p&gt;We&#39;ll be publishing accuracy and reliability benchmarks running on Github actions in the coming weeks. Given that each framework is different and we won&#39;t be able to tune their performance like we do with Agno, for future benchmarks we&#39;ll only be comparing against ourselves.&lt;/p&gt; &#xA;&lt;h2&gt;Cursor Setup&lt;/h2&gt; &#xA;&lt;p&gt;When building Agno agents, using the Agno docs as a documentation source in Cursor is a great way to speed up your development.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;In Cursor, go to the settings or preferences section.&lt;/li&gt; &#xA; &lt;li&gt;Find the section to manage documentation sources.&lt;/li&gt; &#xA; &lt;li&gt;Add &lt;code&gt;https://docs.agno.com&lt;/code&gt; to the list of documentation URLs.&lt;/li&gt; &#xA; &lt;li&gt;Save the changes.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Now, Cursor will have access to the Agno documentation.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation, Community &amp;amp; More examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Docs: &lt;a href=&#34;https://docs.agno.com&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;docs.agno.com&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Getting Started Examples: &lt;a href=&#34;https://github.com/agno-agi/agno/tree/main/cookbook/getting_started&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Getting Started Cookbook&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;All Examples: &lt;a href=&#34;https://github.com/agno-agi/agno/tree/main/cookbook&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Cookbook&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Community forum: &lt;a href=&#34;https://community.agno.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;community.agno.com&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Chat: &lt;a href=&#34;https://discord.gg/4MtYHHrgA8&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;discord&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributions&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions, read our &lt;a href=&#34;https://github.com/agno-agi/agno/raw/main/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt; to get started.&lt;/p&gt; &#xA;&lt;h2&gt;Telemetry&lt;/h2&gt; &#xA;&lt;p&gt;Agno logs which model an agent used so we can prioritize updates to the most popular providers. You can disable this by setting &lt;code&gt;AGNO_TELEMETRY=false&lt;/code&gt; in your environment.&lt;/p&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/agno-agi/agno/main/#top&#34;&gt;⬆️ Back to Top&lt;/a&gt; &lt;/p&gt;</summary>
  </entry>
</feed>