<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-10T01:41:23Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>SCUTlihaoyu/open-chat-video-editor</title>
    <updated>2023-05-10T01:41:23Z</updated>
    <id>tag:github.com,2023-05-10:/SCUTlihaoyu/open-chat-video-editor</id>
    <link href="https://github.com/SCUTlihaoyu/open-chat-video-editor" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Open source short video automatic generation tool&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Open Chat Video Editor&lt;/h1&gt; &#xA;&lt;h2&gt;简介&lt;/h2&gt; &#xA;&lt;p&gt;Open Chat Video Editor是开源的短视频生成和编辑工具，整体技术框架如下：&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/21036347/236475457-e6104baa-11c2-4fe9-88b3-f328114d0076.png&#34; alt=&#34;sys中文&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;TODO&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;windows、linux不同系统更方便的install指引&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;创建docker，方便大家一键使用&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;能够在线直接快速体验的url&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 在短视频文案数据上对文本模型finetune,支持更多的文案风格&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; finetune SD模型，提升图像和视频的生成效果&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;目前具有以下特点：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;1）&lt;strong&gt;一键生成可用的短视频&lt;/strong&gt;，包括：配音、背景音乐、字幕等。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2）算法和数据均基于开源项目，方便技术交流和学习&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;3）支持多种输入数据，方便对各种各样的数据，一键转短视频，目前支持：&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;短句转短视频&lt;/strong&gt;（Text2Video）: 根据输入的简短文字，生成短视频文案，并合成短视频&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;网页链接转短视频&lt;/strong&gt;（Url2Video）: 自动对网页的内容进行提取，生成视频文案，并生成短视频&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;strong&gt;长视频转短视频&lt;/strong&gt;（Long Video to Short Video）: 对输入的长视频进行分析和摘要，并生成短视频&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;4）涵盖&lt;strong&gt;生成模型&lt;/strong&gt;和&lt;strong&gt;多模态检索模型&lt;/strong&gt;等多种主流算法和模型，如: Chatgpt,Stable Diffusion,CLIP 等&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;文本生成上，支持：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; ChatGPT&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; BELLE&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Alpaca&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Dolly 等多种模型&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;视觉信息生成上，支持图像和视频两种模态，生成方式上，支持检索和生成两种模型，目前共有6种模式：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 图像检索&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 图像生成（stable diffusion）&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 先图像检索，再基于stable diffusion 进行图像生成&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 视频检索&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 视频生成（stable diffusion）&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 视频检索后，再基于stable diffusion 进行视频生成&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;结果展示&lt;/h2&gt; &#xA;&lt;h3&gt;1、短句转短视频（Text2Video）&lt;/h3&gt; &#xA;&lt;p&gt;界面如下: &lt;img src=&#34;https://user-images.githubusercontent.com/21036347/236427963-7e9a166b-c085-4af8-b691-5a67f3e865e5.png&#34; alt=&#34;text2video&#34;&gt; 以输入文案：【小孩子养宠物】为例，利用文本模型（如：chatgpt 等），可以自动生成一个较长的短视频文案：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[&#39;小孩子养宠物&#39;, &#39;可以更好地提升小孩子的责任感和独立感&#39;, &#39;但也要慎重的选择合适的宠物&#39;, &#39;因为只有经过一定的训练养成&#39;, &#39;它们才能够成长起来&#39;, &#39;一起玩耍和度过一段欢快的时光&#39;, &#39;宠物不仅能够陪伴小孩子渡过寂寞时光&#39;, &#39;还能培养小孩子处事冷静、自信以及情感交流和沟通能力&#39;, &#39;在养宠物的过程中&#39;, &#39;小孩子们可以唤醒和发掘他们被磨练出来的坚毅和耐力&#39;, &#39;能够亲身体验到勤勉 和坚持的重要性&#39;] &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;根据不同的视频生成模式，可以生成不同的视频，各个模式对比如下:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;1）图像检索&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/21036347/236428839-9c3c3a2d-6163-4577-82f5-5815772f294f.mp4&#34;&gt;https://user-images.githubusercontent.com/21036347/236428839-9c3c3a2d-6163-4577-82f5-5815772f294f.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;2）图像生成（stable diffusion）&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/21036347/236429111-b151f3b5-64d0-4572-8daa-29a78a3d1f3d.mp4&#34;&gt;https://user-images.githubusercontent.com/21036347/236429111-b151f3b5-64d0-4572-8daa-29a78a3d1f3d.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;3）先图像检索，再基于stable diffusion 进行图像生成&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/21036347/236429690-93ea7377-e233-4629-868f-ef953a4dfa4c.mp4&#34;&gt;https://user-images.githubusercontent.com/21036347/236429690-93ea7377-e233-4629-868f-ef953a4dfa4c.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;4）视频检索&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/21036347/236430102-6054b28c-ebeb-42a2-880e-b2656fc32138.mp4&#34;&gt;https://user-images.githubusercontent.com/21036347/236430102-6054b28c-ebeb-42a2-880e-b2656fc32138.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;2、网页转短视频（Url2Video）&lt;/h3&gt; &#xA;&lt;p&gt;界面如下：&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/21036347/236430693-fe9b3d15-8da8-4a50-b7a9-b4dc93614076.png&#34; alt=&#34;url2video&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;1）输入一个url, 例如：&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E7%BE%8E%E5%9B%BD%E7%9F%AD%E6%AF%9B%E7%8C%AB&#34;&gt;https://zh.wikipedia.org/wiki/%E7%BE%8E%E5%9B%BD%E7%9F%AD%E6%AF%9B%E7%8C%AB&lt;/a&gt; 其内容是：美国短毛猫的维基百科&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/21036347/236431138-5fbb6cf2-07c8-41a3-989d-64731a6891d4.png&#34; alt=&#34;wiki&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;2）解析网页并自动摘要成短视频文案，结果如下：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[&#39;\n\n美国短毛猫&#39;, &#39;是一种神奇又魔幻的宠物猫品种&#39;, &#39;它们优雅可爱&#39;, &#39;活力无比&#39;, &#39;能拥有多达80多种头毛色彩&#39;, &#39;最出名的是银虎斑&#39;, &#39;其银色毛发中透着浓厚的黑色斑 &#xA;纹&#39;, &#39;除此之外&#39;, &#39;它们还非常温柔&#39;, &#39;是非常适合家庭和人类相处的宠物&#39;, &#39;并且平均寿命达15-20年&#39;, &#39;这种可爱的猫 &#xA;品种&#39;, &#39;正在受到越来越多人的喜爱&#39;, &#39;不妨试试你也来养一只吧&#39;]&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;3）自动合成短视频 例如图像生成模式下生成的结果如下，其他模式不再一一对比&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/21036347/236431745-9f61ebcc-91b5-4157-adf9-abf9c371e461.mp4&#34;&gt;https://user-images.githubusercontent.com/21036347/236431745-9f61ebcc-91b5-4157-adf9-abf9c371e461.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;3、长视频转短视频（Long Video to Short Video）&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;即将发布，敬请期待&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;安装与使用&lt;/h2&gt; &#xA;&lt;h3&gt;环境安装&lt;/h3&gt; &#xA;&lt;p&gt;根据不同需求，选择不同的安装方式1、2、和3、任选其一。&lt;/p&gt; &#xA;&lt;h4&gt;1、Docker&lt;/h4&gt; &#xA;&lt;p&gt;目前docker环境因为每个人的cuda版本可能不一样，所以无法保证都能够正常使用GPU。目前仅支持图像检索模式，且占用比较多的储存（24G）。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker pull iamjunhonghuang/open-chat-video-editor:retrival&#xA;docker run -it --network=host -v /YourPath/open-chat-video-editor:/YourPath/open-chat-video-editor/ iamjunhonghuang/open-chat-video-editor:retrival bash&#xA;conda activate open_editor&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2、Linux (目前仅在centOS测试)&lt;/h4&gt; &#xA;&lt;p&gt;1）首先安装基于conda的python环境，gcc版本安装测试时是8.5.0，所以尽量升级到8以上&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda env create -f env.yaml&#xA;conda env update -f env.yaml #假如第一行出现错误，需要更新使用的命令&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;2） 接着安装环境依赖，主要目的是正常安装ImageMagick，其他linux版本可以参考&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# yum groupinstall &#39;Development Tools&#39;&#xA;# yum install ghostscript&#xA;# yum -y install bzip2-devel freetype-devel libjpeg-devel libpng-devel libtiff-devel giflib-devel zlib-devel ghostscript-devel djvulibre-devel libwmf-devel jasper-devel libtool-ltdl-devel libX11-devel libXext-devel libXt-devel libxml2-devel librsvg2-devel OpenEXR-devel php-devel&#xA;# wget https://www.imagemagick.org/download/ImageMagick.tar.gz&#xA;# tar xvzf ImageMagick.tar.gz&#xA;# cd ImageMagick*&#xA;# ./configure&#xA;# make&#xA;# make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;3）需要修改moviepy的调用路径，也就是将下面文件&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$HOME/anaconda3/envs/open_editor/lib/python3.8/site-packages/moviepy/config_defaults.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;修改成&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;#IMAGEMAGICK_BINARY = os.getenv(&#39;IMAGEMAGICK_BINARY&#39;, &#39;auto-detect&#39;)&#xA;IMAGEMAGICK_BINARY=&#39;/usr/local/bin/magick&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;4）目前暂不支持中文字幕显示，所以需要修改配置文件yaml中的字体设置，例如’image_by_retrieval_text_by_chatgpt_zh.yaml‘&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  subtitle:&#xA;    font: DejaVu-Sans-Bold-Oblique&#xA;    # font: Cantarell-Regular&#xA;    # font: 华文细黑&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;3、Windows&lt;/h4&gt; &#xA;&lt;p&gt;1）安装pytorch&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# GPU 版本&#xA;pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117&#xA;&#xA;# CPU版本&#xA;pip3 install torch torchvision torchaudio&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;2）安装其他依赖环境&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;3）安装clip&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;pip install git+https://github.com/openai/CLIP.git&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;4）安装faiss&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;conda install -c pytorch faiss-cpu&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;代码执行&lt;/h3&gt; &#xA;&lt;p&gt;1）根据实际需要，选择不同的配置文件&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;配置文件&lt;/th&gt; &#xA;   &lt;th&gt;说明&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;configs/text2video/image_by_retrieval_text_by_chatgpt_zh.yaml&lt;/td&gt; &#xA;   &lt;td&gt;短文本转视频,视频文案采用chatgpt生成,视觉部分采用图像检索来生成&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;configs\text2video\image_by_diffusion_text_by_chatgpt_zh.yaml&lt;/td&gt; &#xA;   &lt;td&gt;短文本转视频,视频文案采用chatgpt生成, 视觉部分采用图像stable diffusion 来生成&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;configs\text2video\image_by_retrieval_then_diffusion_chatgpt_zh.yaml&lt;/td&gt; &#xA;   &lt;td&gt;短文本转视频,视频文案采用chatgpt生成,视觉部分采用先图像检索，然后再基于图像的stable diffusion 来生成&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;configs\text2video\video_by_retrieval_text_by_chatgpt_zh.yaml&lt;/td&gt; &#xA;   &lt;td&gt;短文本转视频, 视频文案采用chatgpt生成,视觉部分采用视频检索来生成&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;configs\url2video\image_by_retrieval_text_by_chatgpt.yaml&lt;/td&gt; &#xA;   &lt;td&gt;url转视频，视频文案采用chatgpt生成,视觉部分采用图像检索来生成&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;configs\url2video\image_by_diffusion_text_by_chatgpt.yaml&lt;/td&gt; &#xA;   &lt;td&gt;url转视频,视频文案采用chatgpt生成, 视觉部分采用图像stable diffusion 来生成&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;configs\url2video\image_by_retrieval_then_diffusion_chatgpt.yaml&lt;/td&gt; &#xA;   &lt;td&gt;url转视频,视频文案采用chatgpt生成,视觉部分采用先图像检索，然后再基于图像的stable diffusion 来生成&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;configs\url2video\video_by_retrieval_text_by_chatgpt.yaml&lt;/td&gt; &#xA;   &lt;td&gt;url转视频,视频文案采用chatgpt生成,视觉部分采用视频检索来生成&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;需要注意的是：如果要采用ChatGPT来生成文案，需要在配置文件里面，添加organization 和 api_key&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;2）下载数据索引和meta信息&lt;a href=&#34;https://pan.quark.cn/s/19fa46ceb2cb&#34;&gt;data.tar&lt;/a&gt;,并解压到 data/index 目录下，&lt;/p&gt; &#xA;&lt;p&gt;3）执行脚本&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Text to video &#xA;python  app/app.py --func Text2VideoEditor  --cfg ${cfg_file}&#xA;&#xA;&#xA;# URL to video &#xA;python  app/app.py --func URL2VideoEditor  --cfg ${cfg_file}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;声明&lt;/h2&gt; &#xA;&lt;p&gt;1、数据来源 图像检索数据来源于:&lt;a href=&#34;https://laion.ai/blog/laion-5b/&#34;&gt;LAION-5B&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;视频检索数据来源于：&lt;a href=&#34;https://m-bain.github.io/webvid-dataset/&#34;&gt;webvid-10m&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;请注意，我们并不拥有数据版权&lt;/p&gt; &#xA;&lt;p&gt;2、该项目仅用于交流学习，不得用于商业，以及其他会对社会带来危害的用途。&lt;/p&gt; &#xA;&lt;h2&gt;交流与学习&lt;/h2&gt; &#xA;&lt;p&gt;欢迎通过&lt;a href=&#34;https://discord.gg/yWt59JUd&#34;&gt;Discard&lt;/a&gt; 或者微信与我们交流学习&lt;/p&gt; &#xA;&lt;p&gt;一群200人已满, &lt;img src=&#34;https://user-images.githubusercontent.com/21036347/236461673-53188ad6-ad27-470f-9910-6e648f92c240.jpg&#34; alt=&#34;微信图片_20230505204811&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;二群200人已满，&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/21036347/236738826-ec47d75e-5b0d-45ad-8f09-8468e9eb8172.jpeg&#34; alt=&#34;WechatIMG1888&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;请加三群：&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/26428693/237003622-af8b9c38-1d88-4518-8080-354666e7fa19.jpg&#34; alt=&#34;301683610444_ pic&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>GFW-knocker/gfw_resist_HTTPS_proxy</title>
    <updated>2023-05-10T01:41:23Z</updated>
    <id>tag:github.com,2023-05-10:/GFW-knocker/gfw_resist_HTTPS_proxy</id>
    <link href="https://github.com/GFW-knocker/gfw_resist_HTTPS_proxy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;HTTPS proxy with Fragment and DoH&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;آپدیت 15-2-1402&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;برای گوشی از پوشه اندروید استفاده کنید&lt;/li&gt; &#xA; &lt;li&gt;با نت ایرانسل بهتر جواب میگیرید&lt;/li&gt; &#xA; &lt;li&gt;کانفیگ v2rayN برای سازگاری بیشتر و سرعت بهتر اصلاح شد&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;یوتیوب و توییتر آزاد شد - بدون سرور - برای ایرانسل&lt;/h1&gt; &#xA;&lt;p&gt;با این &#34;تیزافزار&#34; میتوانید فیلترینگ یوتیوب و توییتر را بدون هیچگونه سروری دور بزنید&lt;br&gt; رو ایرانسل تضمینی جواب میده ، مابقی اپراتورها بگیرنگیر داره فعلا&lt;br&gt; اگر روی نت شما ویدئو ها load نشد دو سه بار refresh صفحه بزنید و چند لحظه صبر کنید&lt;br&gt; بخشی از مشکلات بخاطر محدودیت CORS در سرورهای گوگل میباشد&lt;br&gt; بزودی مجموعه آیپی های تمیز گوگل را اضافه خواهیم کرد&lt;br&gt; این محصول آزمایشی بوده و کارکرد اصلی آن تحقیق روی فیلترینگ میباشد&lt;br&gt;&lt;br&gt; نحوه اجرا :&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;پکیج های dnspython و requests را با دستور pip در cmd روی پایتون نصب کنید&lt;/li&gt; &#xA; &lt;li&gt;اسکریپ pyprox_HTTPS را اجرا کنید&lt;/li&gt; &#xA; &lt;li&gt;مرورگر خود را روی پروکسی HTTPS 127.0.0.1:4500 تنظیم کنید&lt;/li&gt; &#xA; &lt;li&gt;یا از v2ray فایل کانفیگ custom را import کنید&lt;/li&gt; &#xA; &lt;li&gt;اگر روی گوشی هستید باید برنامه pycode را از داخل v2ray مستثنی کنید&lt;/li&gt; &#xA; &lt;li&gt;یوتیوب را باز کنید.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;gfw_resist_HTTPS_proxy&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;HTTPS proxy in single python script&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;Armed with &lt;a href=&#34;https://github.com/GFW-knocker/gfw_resist_tls_proxy&#34;&gt;Fragment technology&lt;/a&gt;&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;Equipped with Offline DNS Resolver&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;plus DNS-over-HTTPS (DoH)&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;plus IP Quality Analyzer&lt;br&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Directly bypass SNI and DNS filtering&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;without any VPS or server&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;bypass SNI filtering using &lt;a href=&#34;https://github.com/GFW-knocker/gfw_resist_tls_proxy&#34;&gt;Fragment&lt;/a&gt;&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;bypass DNS filtering using DoH and offline DNS&lt;br&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;swiss army to injure GFW&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;for developers want to expriment around GFW&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/GFW-knocker/gfw_resist_HTTPS_proxy/main/asset/swiss_army.png?raw=true&#34; width=&#34;200&#34;&gt;&lt;br&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;the structure&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/GFW-knocker/gfw_resist_HTTPS_proxy/main/asset/slide2.png?raw=true&#34; width=&#34;600&#34;&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;how to run:&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;install these python package if you dont have&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/GFW-knocker/gfw_resist_HTTPS_proxy/main/asset/install_packages.png?raw=true&#34; width=&#34;500&#34;&gt;&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;set up your browser to use HTTPS proxy&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/GFW-knocker/gfw_resist_HTTPS_proxy/main/asset/firefox_proxy.png?raw=true&#34; width=&#34;500&#34;&gt;&lt;br&gt;&lt;br&gt; OR setup v2ray by importing custom config&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/GFW-knocker/gfw_resist_HTTPS_proxy/main/asset/v2ray_custom.png?raw=true&#34; width=&#34;500&#34;&gt;&lt;br&gt;&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;run python&lt;br&gt; &lt;code&gt;python pyprox_HTTPS_v1.0.py&lt;/code&gt;&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;surf the web &amp;amp; youtube&lt;br&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;do Research on GFW&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;adjust parameters&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/GFW-knocker/gfw_resist_HTTPS_proxy/main/asset/customize_params.png?raw=true&#34;&gt;&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;add your domain:ip to offline DNS to directly connect to it&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/GFW-knocker/gfw_resist_HTTPS_proxy/main/asset/offline_DNS.png?raw=true&#34;&gt;&lt;br&gt;&lt;/li&gt; &#xA; &lt;li&gt;watch the log&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/GFW-knocker/gfw_resist_HTTPS_proxy/main/asset/IP_Log.png?raw=true&#34;&gt;&lt;br&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Acknowledgement&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;helping on DNS &amp;amp; DoH related things&lt;br&gt; &lt;a href=&#34;https://github.com/msasanmh/SecureDNSClient&#34;&gt;SecureDNSClient&lt;/a&gt; by &lt;a href=&#34;https://github.com/msasanmh&#34;&gt;msasanmh&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/amirhosseinds&#34;&gt;amirhosseinds&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/J-Saeedi&#34;&gt;J-Saeedi&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/alidxdydz&#34;&gt;alidxdydz&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;helping on youtube related things&lt;br&gt; &lt;a href=&#34;https://github.com/Ehsanfarahi22&#34;&gt;Ehsanfarahi22&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/FarhadiAlireza&#34;&gt;FarhadiAlireza&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/free-the-internet&#34;&gt;free-the-internet&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&amp;amp; my lovely friends for everything&lt;br&gt; &lt;a href=&#34;https://t.me/ircfspace&#34;&gt;IRCF.space&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://twitter.com/isegaro&#34;&gt;Segaro&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>RVC-Project/Retrieval-based-Voice-Conversion-WebUI</title>
    <updated>2023-05-10T01:41:23Z</updated>
    <id>tag:github.com,2023-05-10:/RVC-Project/Retrieval-based-Voice-Conversion-WebUI</id>
    <link href="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Voice data &lt;= 10 mins can also be used to train a good VC model!&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;Retrieval-based-Voice-Conversion-WebUI&lt;/h1&gt; 一个基于VITS的简单易用的语音转换（变声器）框架&#xA; &lt;br&gt;&#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/liujing04/Retrieval-based-Voice-Conversion-WebUI&#34;&gt;&lt;img src=&#34;https://forthebadge.com/images/badges/built-with-love.svg?sanitize=true&#34; alt=&#34;madewithlove&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://counter.seku.su/cmoe?name=rvc&amp;amp;theme=r34&#34;&gt;&lt;br&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/liujing04/Retrieval-based-Voice-Conversion-WebUI/blob/main/Retrieval_based_Voice_Conversion_WebUI.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&amp;amp;logo=googlecolab&amp;amp;color=525252&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/liujing04/Retrieval-based-Voice-Conversion-WebUI/raw/main/%E4%BD%BF%E7%94%A8%E9%9C%80%E9%81%B5%E5%AE%88%E7%9A%84%E5%8D%8F%E8%AE%AE-LICENSE.txt&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/liujing04/Retrieval-based-Voice-Conversion-WebUI?style=for-the-badge&#34; alt=&#34;Licence&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/lj1995/VoiceConversionWebUI/tree/main/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20-Spaces-yellow.svg?style=for-the-badge&#34; alt=&#34;Huggingface&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://discord.gg/HcsmBBGyVk&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/RVC%20Developers-Discord-7289DA?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/liujing04/Retrieval-based-Voice-Conversion-WebUI/raw/main/Changelog_CN.md&#34;&gt;&lt;strong&gt;更新日志&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%A7%A3%E7%AD%94&#34;&gt;&lt;strong&gt;常见问题解答&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/Autodl%E8%AE%AD%E7%BB%83RVC%C2%B7AI%E6%AD%8C%E6%89%8B%E6%95%99%E7%A8%8B&#34;&gt;&lt;strong&gt;AutoDL·5毛钱训练AI歌手&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/Autodl%E8%AE%AD%E7%BB%83RVC%C2%B7AI%E6%AD%8C%E6%89%8B%E6%95%99%E7%A8%8B%5D(https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/%E5%AF%B9%E7%85%A7%E5%AE%9E%E9%AA%8C%C2%B7%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95)&#34;&gt;&lt;strong&gt;对照实验记录&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/README.en.md&#34;&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/README.md&#34;&gt;&lt;strong&gt;中文简体&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/README.ja.md&#34;&gt;&lt;strong&gt;日本語&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/README.ko.md&#34;&gt;&lt;strong&gt;한국어&lt;/strong&gt;&lt;/a&gt; (&lt;a href=&#34;https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/README.ko.han.md&#34;&gt;&lt;strong&gt;韓國語&lt;/strong&gt;&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;点此查看我们的&lt;a href=&#34;https://www.bilibili.com/video/BV1pm4y1z7Gm/&#34;&gt;演示视频&lt;/a&gt; !&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;使用了RVC的实时语音转换: &lt;a href=&#34;https://github.com/w-okada/voice-changer&#34;&gt;w-okada/voice-changer&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;底模使用接近50小时的开源高质量VCTK训练集训练，无版权方面的顾虑，请大家放心使用&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;后续会陆续加入高质量有授权歌声训练集训练底模&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;简介&lt;/h2&gt; &#xA;&lt;p&gt;本仓库具有以下特点&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;使用top1检索替换输入源特征为训练集特征来杜绝音色泄漏&lt;/li&gt; &#xA; &lt;li&gt;即便在相对较差的显卡上也能快速训练&lt;/li&gt; &#xA; &lt;li&gt;使用少量数据进行训练也能得到较好结果(推荐至少收集10分钟低底噪语音数据)&lt;/li&gt; &#xA; &lt;li&gt;可以通过模型融合来改变音色(借助ckpt处理选项卡中的ckpt-merge)&lt;/li&gt; &#xA; &lt;li&gt;简单易用的网页界面&lt;/li&gt; &#xA; &lt;li&gt;可调用UVR5模型来快速分离人声和伴奏&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;环境配置&lt;/h2&gt; &#xA;&lt;p&gt;推荐使用poetry配置环境。&lt;/p&gt; &#xA;&lt;p&gt;以下指令需在Python版本大于3.8的环境中执行:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 安装Pytorch及其核心依赖，若已安装则跳过&#xA;# 参考自: https://pytorch.org/get-started/locally/&#xA;pip install torch torchvision torchaudio&#xA;&#xA;#如果是win系统+Nvidia Ampere架构(RTX30xx)，根据 #21 的经验，需要指定pytorch对应的cuda版本&#xA;#pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117&#xA;&#xA;# 安装 Poetry 依赖管理工具, 若已安装则跳过&#xA;# 参考自: https://python-poetry.org/docs/#installation&#xA;curl -sSL https://install.python-poetry.org | python3 -&#xA;&#xA;# 通过poetry安装依赖&#xA;poetry install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;你也可以通过pip来安装依赖：&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;: &lt;code&gt;MacOS&lt;/code&gt;下&lt;code&gt;faiss 1.7.2&lt;/code&gt;版本会导致抛出段错误，在手动安装时请使用命令&lt;code&gt;pip install faiss-cpu==1.7.0&lt;/code&gt;指定使用&lt;code&gt;1.7.0&lt;/code&gt;版本 &lt;code&gt;MacOS&lt;/code&gt;下可通过&lt;code&gt;brew&lt;/code&gt;安装&lt;code&gt;Swig&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install swig&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;其他预模型准备&lt;/h2&gt; &#xA;&lt;p&gt;RVC需要其他一些预模型来推理和训练。&lt;/p&gt; &#xA;&lt;p&gt;你可以从我们的&lt;a href=&#34;https://huggingface.co/lj1995/VoiceConversionWebUI/tree/main/&#34;&gt;Hugging Face space&lt;/a&gt;下载到这些模型。&lt;/p&gt; &#xA;&lt;p&gt;以下是一份清单，包括了所有RVC所需的预模型和其他文件的名称:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hubert_base.pt&#xA;&#xA;./pretrained &#xA;&#xA;./uvr5_weights&#xA;&#xA;#如果你正在使用Windows，则你可能需要这个文件，若ffmpeg和ffprobe已安装则跳过; ubuntu/debian 用户可以通过apt install ffmpeg来安装这2个库&#xA;./ffmpeg&#xA;&#xA;./ffprobe&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;之后使用以下指令来启动WebUI:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python infer-web.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;如果你正在使用Windows，你可以直接下载并解压&lt;code&gt;RVC-beta.7z&lt;/code&gt;，运行&lt;code&gt;go-web.bat&lt;/code&gt;以启动WebUI。&lt;/p&gt; &#xA;&lt;p&gt;仓库内还有一份&lt;code&gt;小白简易教程.doc&lt;/code&gt;以供参考。&lt;/p&gt; &#xA;&lt;h2&gt;参考项目&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/auspicious3000/contentvec/&#34;&gt;ContentVec&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jaywalnut310/vits&#34;&gt;VITS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jik876/hifi-gan&#34;&gt;HIFIGAN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gradio-app/gradio&#34;&gt;Gradio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/FFmpeg/FFmpeg&#34;&gt;FFmpeg&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Anjok07/ultimatevocalremovergui&#34;&gt;Ultimate Vocal Remover&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openvpi/audio-slicer&#34;&gt;audio-slicer&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;感谢所有贡献者作出的努力&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/liujing04/Retrieval-based-Voice-Conversion-WebUI/graphs/contributors&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=liujing04/Retrieval-based-Voice-Conversion-WebUI&#34;&gt; &lt;/a&gt;</summary>
  </entry>
</feed>