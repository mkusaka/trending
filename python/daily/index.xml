<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-09T01:40:19Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>idanya/algo-trader</title>
    <updated>2022-11-09T01:40:19Z</updated>
    <id>tag:github.com,2022-11-09:/idanya/algo-trader</id>
    <link href="https://github.com/idanya/algo-trader" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Trading bot with support for realtime trading, backtesting, custom strategies and much more.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;algo-trader&lt;/h1&gt; &#xA;&lt;p&gt;Trading strategies builder, backtester, and real-time trader.&lt;/p&gt; &#xA;&lt;h2&gt;Intro&lt;/h2&gt; &#xA;&lt;p&gt;algo-trader is an implementation of an algorithmic trading strategy executor and backtester. Capable of backtesting strategies locally and trading them in real-time via your broker API.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Please be aware that this is a &lt;strong&gt;work in progress&lt;/strong&gt; and the trader is missing external market data and trade providers. If you&#39;d like to use the trader for real-world trading, you&#39;ll have to implement your broker API. Although real-time trading is not finished, backtesting is fully functional, so implemented strategies can be backtested and used in real trading when it will be ready.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;algo-trader is written in Python, and its current stack composes of:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;MongoDB as a backend data store for backtesting strategies&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jesse-ai/tulipy&#34;&gt;tulipy&lt;/a&gt; - Python bindings for &lt;a href=&#34;https://tulipindicators.org/&#34;&gt;Tulip Indicators&lt;/a&gt;. Used to provide technical indicators calculations.&lt;/li&gt; &#xA; &lt;li&gt;ib_client (Optional) - Python library to communicate with Interactive Brokers gateway. Only needed if you plan on doing real trading via IB.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Architecture&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/idanya/algo-trader/main/design/diagram.png&#34; alt=&#34;System design&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Sources&lt;/h3&gt; &#xA;&lt;p&gt;A &lt;a href=&#34;https://raw.githubusercontent.com/idanya/algo-trader/main/src/pipeline/source.py&#34;&gt;Source&lt;/a&gt; is an implementation of a Candle Iterator. This is the starting point of the pipeline and the &#34;source&#34; for the incoming candles processed.&lt;/p&gt; &#xA;&lt;h3&gt;Processors&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/idanya/algo-trader/main/src/pipeline/processor.py&#34;&gt;Processor&lt;/a&gt; is the primary processing unit in the pipeline. Processors can be constructed in any order while Candles are flowing from the source, forward through all processors. Each processor is responsible for sending the candles it processes to the next processor (unless it has a reason not to).&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;process()&lt;/code&gt; function gets with each candle also an object called &lt;a href=&#34;https://raw.githubusercontent.com/idanya/algo-trader/main/src/pipeline/shared_context.py&#34;&gt;&lt;code&gt;SharedContext&lt;/code&gt;&lt;/a&gt;. The context is an instance of an in-memory KV store to share context and information between processors.&lt;/p&gt; &#xA;&lt;p&gt;Another way to share data between processors is to make use of the &lt;code&gt;attachments&lt;/code&gt; field on the Candle itself. This field is intended for metadata on the candle, like calculations and state relevant to that candle point in time. Candle attachments are persistent throughout the pipeline.&lt;/p&gt; &#xA;&lt;h4&gt;Reprocessing&lt;/h4&gt; &#xA;&lt;p&gt;Reprocessing is a feature that enables a processor to re-send an already processed candle to the next processor. Reprocessing is useful for processors that do some logic outside the main flow of the pipeline. for example, upon events, external triggers, market/trade provider&#39;s events/issues, etc... An example of reprocessing can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/idanya/algo-trader/main/src/pipeline/processors/assets_correlation.py&#34;&gt;AssetCorrelationProcessor&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Events&lt;/h3&gt; &#xA;&lt;p&gt;An &lt;a href=&#34;https://raw.githubusercontent.com/idanya/algo-trader/main/src/entities/event.py&#34;&gt;Event&lt;/a&gt; as its name suggests, defines an event that occurred in the system. It follows the same flow as the Candles, passing between processors. Each processor is responsible for propagating the event to the next processor (if needed).&lt;/p&gt; &#xA;&lt;p&gt;Because pipelines are data-driven and not time-driven, events can be used as checkpoints to indicate something that happened in the data stream. For example, running the same pipeline from a DB source and a real-time market data source can have different effects if the processor were to rely on time.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;It is crucial to have the same behavior when fast-running from DB and real-time for backtesting to be useful.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Strategies&lt;/h3&gt; &#xA;&lt;p&gt;Strategies are executed per candle by the &lt;a href=&#34;https://raw.githubusercontent.com/idanya/algo-trader/main/src/pipeline/processors/strategy.py&#34;&gt;StrategyProcessor&lt;/a&gt;. A strategy is responsible for executing the trading logic and dispatching Signals (&lt;a href=&#34;https://raw.githubusercontent.com/idanya/algo-trader/main/src/entities/strategy_signal.py&#34;&gt;StrategySignal&lt;/a&gt;). In the event a strategy is raising a trading signal, the StrategyProcessor will catch and pass it to the &lt;a href=&#34;https://raw.githubusercontent.com/idanya/algo-trader/main/src/trade/signals_executor.py&#34;&gt;SignalsExecutor&lt;/a&gt; for execution.&lt;/p&gt; &#xA;&lt;h3&gt;Terminators&lt;/h3&gt; &#xA;&lt;p&gt;A &lt;a href=&#34;https://raw.githubusercontent.com/idanya/algo-trader/main/src/pipeline/terminator.py&#34;&gt;Terminator&lt;/a&gt; is an optional final piece of the pipeline. It&#39;s executed at the very end of a pipeline when the Source iterator has been fully consumed. Terminators are useful for unit testing, backtesting, and environment cleanups.&lt;/p&gt; &#xA;&lt;h2&gt;Running locally&lt;/h2&gt; &#xA;&lt;p&gt;algo-trader is using MongoDB for data storage. To run Mongo locally use &lt;code&gt;docker-compose&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker-compose -f docker-compose.yml up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Virtual environment&lt;/h2&gt; &#xA;&lt;p&gt;It is best to use a virtual environment to run algo-trader.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python3 -m venv run&#xA;source run/bin/activate&#xA;pip3 install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running tests&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Unit: &lt;code&gt;./scripts/test-unit.sh&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Integration (needs IB gateway running): &lt;code&gt;./scripts/test-integration.sh&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;All: &lt;code&gt;./scripts/test-all.sh&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are welcome and much needed. Please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/idanya/algo-trader/main/CONTRIBUTING.md&#34;&gt;guidelines&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>heartexlabs/labelImg</title>
    <updated>2022-11-09T01:40:19Z</updated>
    <id>tag:github.com,2022-11-09:/heartexlabs/labelImg</id>
    <link href="https://github.com/heartexlabs/labelImg" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LabelImg is now part of the Label Studio community. The popular image annotation tool created by Tzutalin is no longer actively being developed, but you can check out Label Studio, the open source data labeling tool for images, text, hypertext, audio, video and time-series data.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. image:: /readme/images/labelimg.png :target: &lt;a href=&#34;https://github.com/heartexlabs/label-studio&#34;&gt;https://github.com/heartexlabs/label-studio&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Label Studio is a modern, multi-modal data annotation tool&lt;/h1&gt; &#xA;&lt;p&gt;LabelImg, the popular image annotation tool created by Tzutalin with the help of dozens contributors, is no longer actively being developed and has become part of the Label Studio community. Check out &lt;code&gt;Label Studio &amp;lt;https://github.com/heartexlabs/label-studio&amp;gt;&lt;/code&gt;&lt;strong&gt;, the most flexible open source data labeling tool for images, text, hypertext, audio, video and time-series data. &lt;code&gt;Install &amp;lt;https://labelstud.io/guide/install.html&amp;gt;&lt;/code&gt;&lt;/strong&gt; Label Studio and join the &lt;code&gt;slack community &amp;lt;https://label-studio.slack.com/&amp;gt;&lt;/code&gt;__ to get started.&lt;/p&gt; &#xA;&lt;p&gt;.. image:: /readme/images/label-studio-1-6-player-screenshot.png :target: &lt;a href=&#34;https://github.com/heartexlabs/label-studio&#34;&gt;https://github.com/heartexlabs/label-studio&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;About LabelImg&lt;/h1&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/pypi/v/labelimg.svg&#34;&gt;https://img.shields.io/pypi/v/labelimg.svg&lt;/a&gt; :target: &lt;a href=&#34;https://pypi.python.org/pypi/labelimg&#34;&gt;https://pypi.python.org/pypi/labelimg&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/github/workflow/status/tzutalin/labelImg/Package?style=for-the-badge&#34;&gt;https://img.shields.io/github/workflow/status/tzutalin/labelImg/Package?style=for-the-badge&lt;/a&gt; :alt: GitHub Workflow Status&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/badge/lang-en-blue.svg&#34;&gt;https://img.shields.io/badge/lang-en-blue.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/tzutalin/labelImg&#34;&gt;https://github.com/tzutalin/labelImg&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/badge/lang-zh-green.svg&#34;&gt;https://img.shields.io/badge/lang-zh-green.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/tzutalin/labelImg/raw/master/readme/README.zh.rst&#34;&gt;https://github.com/tzutalin/labelImg/blob/master/readme/README.zh.rst&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/badge/lang-jp-green.svg&#34;&gt;https://img.shields.io/badge/lang-jp-green.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/tzutalin/labelImg/raw/master/readme/README.jp.rst&#34;&gt;https://github.com/tzutalin/labelImg/blob/master/readme/README.jp.rst&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;LabelImg is a graphical image annotation tool.&lt;/p&gt; &#xA;&lt;p&gt;It is written in Python and uses Qt for its graphical interface.&lt;/p&gt; &#xA;&lt;p&gt;Annotations are saved as XML files in PASCAL VOC format, the format used by &lt;code&gt;ImageNet &amp;lt;http://www.image-net.org/&amp;gt;&lt;/code&gt;__. Besides, it also supports YOLO and CreateML formats.&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://raw.githubusercontent.com/tzutalin/labelImg/master/demo/demo3.jpg&#34;&gt;https://raw.githubusercontent.com/tzutalin/labelImg/master/demo/demo3.jpg&lt;/a&gt; :alt: Demo Image&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://raw.githubusercontent.com/tzutalin/labelImg/master/demo/demo.jpg&#34;&gt;https://raw.githubusercontent.com/tzutalin/labelImg/master/demo/demo.jpg&lt;/a&gt; :alt: Demo Image&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Watch a demo video &amp;lt;https://youtu.be/p0nR2YsCY_U&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Get from PyPI but only python3.0 or above&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;This is the simplest (one-command) install method on modern Linux distributions such as Ubuntu and Fedora.&#xA;&#xA;.. code:: shell&#xA;&#xA;    pip3 install labelImg&#xA;    labelImg&#xA;    labelImg [IMAGE_PATH] [PRE-DEFINED CLASS FILE]&#xA;&#xA;&#xA;Build from source&#xA;~~~~~~~~~~~~~~~~~&#xA;&#xA;Linux/Ubuntu/Mac requires at least `Python&#xA;2.6 &amp;lt;https://www.python.org/getit/&amp;gt;`__ and has been tested with `PyQt&#xA;4.8 &amp;lt;https://www.riverbankcomputing.com/software/pyqt/intro&amp;gt;`__. However, `Python&#xA;3 or above &amp;lt;https://www.python.org/getit/&amp;gt;`__ and  `PyQt5 &amp;lt;https://pypi.org/project/PyQt5/&amp;gt;`__ are strongly recommended.&#xA;&#xA;&#xA;Ubuntu Linux&#xA;^^^^^^^^^^^^&#xA;&#xA;Python 3 + Qt5&#xA;&#xA;.. code:: shell&#xA;&#xA;    sudo apt-get install pyqt5-dev-tools&#xA;    sudo pip3 install -r requirements/requirements-linux-python3.txt&#xA;    make qt5py3&#xA;    python3 labelImg.py&#xA;    python3 labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]&#xA;&#xA;macOS&#xA;^^^^^&#xA;&#xA;Python 3 + Qt5&#xA;&#xA;.. code:: shell&#xA;&#xA;    brew install qt  # Install qt-5.x.x by Homebrew&#xA;    brew install libxml2&#xA;&#xA;    or using pip&#xA;&#xA;    pip3 install pyqt5 lxml # Install qt and lxml by pip&#xA;&#xA;    make qt5py3&#xA;    python3 labelImg.py&#xA;    python3 labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]&#xA;&#xA;&#xA;Python 3 Virtualenv (Recommended)&#xA;&#xA;Virtualenv can avoid a lot of the QT / Python version issues&#xA;&#xA;.. code:: shell&#xA;&#xA;    brew install python3&#xA;    pip3 install pipenv&#xA;    pipenv run pip install pyqt5==5.15.2 lxml&#xA;    pipenv run make qt5py3&#xA;    pipenv run python3 labelImg.py&#xA;    [Optional] rm -rf build dist; pipenv run python setup.py py2app -A;mv &#34;dist/labelImg.app&#34; /Applications&#xA;&#xA;Note: The Last command gives you a nice .app file with a new SVG Icon in your /Applications folder. You can consider using the script: build-tools/build-for-macos.sh&#xA;&#xA;&#xA;Windows&#xA;^^^^^^^&#xA;&#xA;Install `Python &amp;lt;https://www.python.org/downloads/windows/&amp;gt;`__,&#xA;`PyQt5 &amp;lt;https://www.riverbankcomputing.com/software/pyqt/download5&amp;gt;`__&#xA;and `install lxml &amp;lt;http://lxml.de/installation.html&amp;gt;`__.&#xA;&#xA;Open cmd and go to the `labelImg &amp;lt;#labelimg&amp;gt;`__ directory&#xA;&#xA;.. code:: shell&#xA;&#xA;    pyrcc4 -o libs/resources.py resources.qrc&#xA;    For pyqt5, pyrcc5 -o libs/resources.py resources.qrc&#xA;&#xA;    python labelImg.py&#xA;    python labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]&#xA;&#xA;If you want to package it into a separate EXE file&#xA;&#xA;.. code:: shell&#xA;&#xA;    Install pyinstaller and execute:&#xA;&#xA;    pip install pyinstaller&#xA;    pyinstaller --hidden-import=pyqt5 --hidden-import=lxml -F -n &#34;labelImg&#34; -c labelImg.py -p ./libs -p ./&#xA;&#xA;Windows + Anaconda&#xA;^^^^^^^^^^^^^^^^^^&#xA;&#xA;Download and install `Anaconda &amp;lt;https://www.anaconda.com/download/#download&amp;gt;`__ (Python 3+)&#xA;&#xA;Open the Anaconda Prompt and go to the `labelImg &amp;lt;#labelimg&amp;gt;`__ directory&#xA;&#xA;.. code:: shell&#xA;&#xA;    conda install pyqt=5&#xA;    conda install -c anaconda lxml&#xA;    pyrcc5 -o libs/resources.py resources.qrc&#xA;    python labelImg.py&#xA;    python labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]&#xA;&#xA;Use Docker&#xA;~~~~~~~~~~~~~~~~~&#xA;.. code:: shell&#xA;&#xA;    docker run -it \&#xA;    --user $(id -u) \&#xA;    -e DISPLAY=unix$DISPLAY \&#xA;    --workdir=$(pwd) \&#xA;    --volume=&#34;/home/$USER:/home/$USER&#34; \&#xA;    --volume=&#34;/etc/group:/etc/group:ro&#34; \&#xA;    --volume=&#34;/etc/passwd:/etc/passwd:ro&#34; \&#xA;    --volume=&#34;/etc/shadow:/etc/shadow:ro&#34; \&#xA;    --volume=&#34;/etc/sudoers.d:/etc/sudoers.d:ro&#34; \&#xA;    -v /tmp/.X11-unix:/tmp/.X11-unix \&#xA;    tzutalin/py2qt4&#xA;&#xA;    make qt4py2;./labelImg.py&#xA;&#xA;You can pull the image which has all of the installed and required dependencies. `Watch a demo video &amp;lt;https://youtu.be/nw1GexJzbCI&amp;gt;`__&#xA;&#xA;&#xA;Usage&#xA;-----&#xA;&#xA;Steps (PascalVOC)&#xA;~~~~~~~~~~~~~~~~~&#xA;&#xA;1. Build and launch using the instructions above.&#xA;2. Click &#39;Change default saved annotation folder&#39; in Menu/File&#xA;3. Click &#39;Open Dir&#39;&#xA;4. Click &#39;Create RectBox&#39;&#xA;5. Click and release left mouse to select a region to annotate the rect&#xA;   box&#xA;6. You can use right mouse to drag the rect box to copy or move it&#xA;&#xA;The annotation will be saved to the folder you specify.&#xA;&#xA;You can refer to the below hotkeys to speed up your workflow.&#xA;&#xA;Steps (YOLO)&#xA;~~~~~~~~~~~~&#xA;&#xA;1. In ``data/predefined_classes.txt`` define the list of classes that will be used for your training.&#xA;&#xA;2. Build and launch using the instructions above.&#xA;&#xA;3. Right below &#34;Save&#34; button in the toolbar, click &#34;PascalVOC&#34; button to switch to YOLO format.&#xA;&#xA;4. You may use Open/OpenDIR to process single or multiple images. When finished with a single image, click save.&#xA;&#xA;A txt file of YOLO format will be saved in the same folder as your image with same name. A file named &#34;classes.txt&#34; is saved to that folder too. &#34;classes.txt&#34; defines the list of class names that your YOLO label refers to.&#xA;&#xA;Note:&#xA;&#xA;- Your label list shall not change in the middle of processing a list of images. When you save an image, classes.txt will also get updated, while previous annotations will not be updated.&#xA;&#xA;- You shouldn&#39;t use &#34;default class&#34; function when saving to YOLO format, it will not be referred.&#xA;&#xA;- When saving as YOLO format, &#34;difficult&#34; flag is discarded.&#xA;&#xA;Create pre-defined classes&#xA;~~~~~~~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;You can edit the&#xA;`data/predefined\_classes.txt &amp;lt;https://github.com/tzutalin/labelImg/blob/master/data/predefined_classes.txt&amp;gt;`__&#xA;to load pre-defined classes&#xA;&#xA;Annotation visualization&#xA;~~~~~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;1. Copy the existing lables file to same folder with the images. The labels file name must be same with image file name.&#xA;&#xA;2. Click File and choose &#39;Open Dir&#39; then Open the image folder.&#xA;&#xA;3. Select image in File List, it will appear the bounding box and label for all objects in that image.&#xA;&#xA;(Choose Display Labels mode in View to show/hide lablels)&#xA;&#xA;&#xA;Hotkeys&#xA;~~~~~~~&#xA;&#xA;+--------------------+--------------------------------------------+&#xA;| Ctrl + u           | Load all of the images from a directory    |&#xA;+--------------------+--------------------------------------------+&#xA;| Ctrl + r           | Change the default annotation target dir   |&#xA;+--------------------+--------------------------------------------+&#xA;| Ctrl + s           | Save                                       |&#xA;+--------------------+--------------------------------------------+&#xA;| Ctrl + d           | Copy the current label and rect box        |&#xA;+--------------------+--------------------------------------------+&#xA;| Ctrl + Shift + d   | Delete the current image                   |&#xA;+--------------------+--------------------------------------------+&#xA;| Space              | Flag the current image as verified         |&#xA;+--------------------+--------------------------------------------+&#xA;| w                  | Create a rect box                          |&#xA;+--------------------+--------------------------------------------+&#xA;| d                  | Next image                                 |&#xA;+--------------------+--------------------------------------------+&#xA;| a                  | Previous image                             |&#xA;+--------------------+--------------------------------------------+&#xA;| del                | Delete the selected rect box               |&#xA;+--------------------+--------------------------------------------+&#xA;| Ctrl++             | Zoom in                                    |&#xA;+--------------------+--------------------------------------------+&#xA;| Ctrl--             | Zoom out                                   |&#xA;+--------------------+--------------------------------------------+&#xA;| ↑→↓←               | Keyboard arrows to move selected rect box  |&#xA;+--------------------+--------------------------------------------+&#xA;&#xA;**Verify Image:**&#xA;&#xA;When pressing space, the user can flag the image as verified, a green background will appear.&#xA;This is used when creating a dataset automatically, the user can then through all the pictures and flag them instead of annotate them.&#xA;&#xA;**Difficult:**&#xA;&#xA;The difficult field is set to 1 indicates that the object has been annotated as &#34;difficult&#34;, for example, an object which is clearly visible but difficult to recognize without substantial use of context.&#xA;According to your deep neural network implementation, you can include or exclude difficult objects during training.&#xA;&#xA;How to reset the settings&#xA;~~~~~~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;In case there are issues with loading the classes, you can either:&#xA;&#xA;1. From the top menu of the labelimg click on Menu/File/Reset All&#xA;2. Remove the `.labelImgSettings.pkl` from your home directory. In Linux and Mac you can do:&#xA;    `rm ~/.labelImgSettings.pkl`&#xA;&#xA;&#xA;How to contribute&#xA;~~~~~~~~~~~~~~~~~&#xA;&#xA;Send a pull request&#xA;&#xA;License&#xA;~~~~~~~&#xA;`Free software: MIT license &amp;lt;https://github.com/tzutalin/labelImg/blob/master/LICENSE&amp;gt;`_&#xA;&#xA;Citation: Tzutalin. LabelImg. Git code (2015). https://github.com/tzutalin/labelImg&#xA;&#xA;Related and additional tools&#xA;~~~~~~~~~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;1. `Label Studio &amp;lt;https://github.com/heartexlabs/label-studio&amp;gt;`__ to label images, text, audio, video and time-series data for machine learning and AI&#xA;2. `ImageNet Utils &amp;lt;https://github.com/tzutalin/ImageNet_Utils&amp;gt;`__ to&#xA;   download image, create a label text for machine learning, etc&#xA;3. `Use Docker to run labelImg &amp;lt;https://hub.docker.com/r/tzutalin/py2qt4&amp;gt;`__&#xA;4. `Generating the PASCAL VOC TFRecord files &amp;lt;https://github.com/tensorflow/models/blob/4f32535fe7040bb1e429ad0e3c948a492a89482d/research/object_detection/g3doc/preparing_inputs.md#generating-the-pascal-voc-tfrecord-files&amp;gt;`__&#xA;5. `App Icon based on Icon by Nick Roach (GPL) &amp;lt;https://www.elegantthemes.com/&amp;gt;`__&#xA;6. `Setup python development in vscode &amp;lt;https://tzutalin.blogspot.com/2019/04/set-up-visual-studio-code-for-python-in.html&amp;gt;`__&#xA;7. `The link of this project on iHub platform &amp;lt;https://code.ihub.org.cn/projects/260/repository/labelImg&amp;gt;`__&#xA;8. `Convert annotation files to CSV format or format for Google Cloud AutoML &amp;lt;https://github.com/tzutalin/labelImg/tree/master/tools&amp;gt;`__&#xA;&#xA;&#xA;&#xA;Stargazers over time&#xA;~~~~~~~~~~~~~~~~~~~~&#xA;&#xA;.. image:: https://starchart.cc/tzutalin/labelImg.svg&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>streamlit/streamlit</title>
    <updated>2022-11-09T01:40:19Z</updated>
    <id>tag:github.com,2022-11-09:/streamlit/streamlit</id>
    <link href="https://github.com/streamlit/streamlit" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Streamlit — The fastest way to build data apps in Python&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Welcome to Streamlit &lt;span&gt;👋&lt;/span&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;The fastest way to build and share data apps.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Streamlit lets you turn data scripts into shareable web apps in minutes, not weeks. It’s all Python, open-source, and free! And once you’ve created an app you can use our&amp;nbsp;&lt;a href=&#34;https://streamlit.io/cloud&#34;&gt;Community Cloud platform&lt;/a&gt;&amp;nbsp;to deploy, manage, and share your app!&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/streamlit/docs/main/public/images/Streamlit_overview.gif&#34; alt=&#34;Example of live coding an app in Streamlit|635x380&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install streamlit&#xA;streamlit hello&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Streamlit can also be installed in a virtual environment on &lt;a href=&#34;https://github.com/streamlit/streamlit/wiki/Installing-in-a-virtual-environment#on-windows&#34;&gt;Windows&lt;/a&gt;, &lt;a href=&#34;https://github.com/streamlit/streamlit/wiki/Installing-in-a-virtual-environment#on-mac--linux&#34;&gt;Mac&lt;/a&gt;, and &lt;a href=&#34;https://github.com/streamlit/streamlit/wiki/Installing-in-a-virtual-environment#on-mac--linux&#34;&gt;Linux&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;A little example&lt;/h2&gt; &#xA;&lt;p&gt;Streamlit makes it incredibly easy to build interactive apps:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import streamlit as st&#xA;&#xA;x = st.slider(&#39;Select a value&#39;)&#xA;st.write(x, &#39;squared is&#39;, x * x)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/streamlit/docs/main/public/images/simple_example.png&#34;&gt; &#xA;&lt;h2&gt;A bigger example&lt;/h2&gt; &#xA;&lt;p&gt;Streamlit&#39;s simple and focused API lets you build incredibly rich and powerful tools.&amp;nbsp; &lt;a href=&#34;https://github.com/streamlit/demo-self-driving&#34;&gt;This demo project&lt;/a&gt; lets you browse the entire &lt;a href=&#34;https://github.com/udacity/self-driving-car&#34;&gt;Udacity self-driving-car dataset&lt;/a&gt; and run inference in real-time using the &lt;a href=&#34;https://pjreddie.com/darknet/yolo&#34;&gt;YOLO object detection net&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/streamlit/docs/main/public/images/complex_app_example.gif&#34; alt=&#34;Final App Animation&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The complete demo is implemented in less than 300 lines of Python. In fact, the app contains &lt;a href=&#34;https://github.com/streamlit/demo-self-driving/raw/master/streamlit_app.py&#34;&gt;only 23 Streamlit calls&lt;/a&gt; which illustrates all the major building blocks of Streamlit. You can try it right now at &lt;a href=&#34;https://share.streamlit.io/streamlit/demo-self-driving&#34;&gt;share.streamlit.io/streamlit/demo-self-driving&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;The Streamlit GitHub badge&lt;/h2&gt; &#xA;&lt;p&gt;Streamlit&#39;s GitHub badge helps others find and play with your Streamlit app.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://share.streamlit.io/streamlit/demo-face-gan&#34;&gt;&lt;img src=&#34;https://static.streamlit.io/badges/streamlit_badge_black_white.svg?sanitize=true&#34; alt=&#34;Streamlit App&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Once you deploy your app, you can embed this badge right into your GitHub readme.md as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://share.streamlit.io/yourGitHubName/yourRepo/yourApp/)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;More Information&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Our &lt;a href=&#34;https://towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace?source=friends_link&amp;amp;sk=f7774c54571148b33cde3ba6c6310086&#34;&gt;launch post&lt;/a&gt; explaining why we created Streamlit&lt;/li&gt; &#xA; &lt;li&gt;Our &lt;a href=&#34;https://blog.streamlit.io/introducing-streamlit-cloud&#34;&gt;Community Cloud platform announcement&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Our amazing &lt;a href=&#34;https://discuss.streamlit.io/&#34;&gt;community&lt;/a&gt; where Streamlit users share apps, ask questions, and help each other out&lt;/li&gt; &#xA; &lt;li&gt;Streamlit &lt;a href=&#34;https://docs.streamlit.io/&#34;&gt;documentation&lt;/a&gt; and &lt;a href=&#34;https://blog.streamlit.io&#34;&gt;blog&lt;/a&gt; for the latest Streamlit info&lt;/li&gt; &#xA; &lt;li&gt;More &lt;a href=&#34;https://github.com/streamlit/&#34;&gt;demo projects&lt;/a&gt; to inspire you&lt;/li&gt; &#xA; &lt;li&gt;And if you would like to contribute, see &lt;a href=&#34;https://github.com/streamlit/streamlit/wiki/Contributing&#34;&gt;instructions here&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Community Cloud&lt;/h2&gt; &#xA;&lt;p&gt;With &lt;a href=&#34;https://streamlit.io/cloud&#34;&gt;Community Cloud&lt;/a&gt; you can deploy, manage, and share your apps with the world, directly from Streamlit — all for free. Sign-up &lt;a href=&#34;https://share.streamlit.io/signup&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Streamlit is completely free and open-source and licensed under the &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache 2.0&lt;/a&gt; license.&lt;/p&gt;</summary>
  </entry>
</feed>