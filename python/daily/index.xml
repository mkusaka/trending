<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-08-30T01:33:57Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Cinnamon/kotaemon</title>
    <updated>2024-08-30T01:33:57Z</updated>
    <id>tag:github.com,2024-08-30:/Cinnamon/kotaemon</id>
    <link href="https://github.com/Cinnamon/kotaemon" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An open-source RAG-based tool for chatting with your documents.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;kotaemon&lt;/h1&gt; &#xA;&lt;p&gt;An open-source clean &amp;amp; customizable RAG UI for chatting with your documents. Built with both end users and developers in mind.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/preview-graph.png&#34; alt=&#34;Preview&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://huggingface.co/spaces/taprosoft/kotaemon&#34;&gt;Live Demo&lt;/a&gt; | &lt;a href=&#34;https://github.com/Cinnamon/kotaemon&#34;&gt;Source Code&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cinnamon.github.io/kotaemon/&#34;&gt;User Guide&lt;/a&gt; | &lt;a href=&#34;https://cinnamon.github.io/kotaemon/development/&#34;&gt;Developer Guide&lt;/a&gt; | &lt;a href=&#34;https://github.com/Cinnamon/kotaemon/issues&#34;&gt;Feedback&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.python.org/downloads/release/python-31013/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.10+-blue.svg?sanitize=true&#34; alt=&#34;Python 3.10+&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/psf/black&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true&#34; alt=&#34;Code style: black&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/taprosoft/kotaemon&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/docker_pull-kotaemon:v1.0-brightgreen&#34; alt=&#34;docker pull taprosoft/kotaemon:v1.0&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codeium.com&#34;&gt;&lt;img src=&#34;https://codeium.com/badges/main&#34; alt=&#34;built with Codeium&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;This project serves as a functional RAG UI for both end users who want to do QA on their documents and developers who want to build their own RAG pipeline.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For end users: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;A clean &amp;amp; minimalistic UI for RAG-based QA.&lt;/li&gt; &#xA;   &lt;li&gt;Supports LLM API providers (OpenAI, AzureOpenAI, Cohere, etc) and local LLMs (via &lt;code&gt;ollama&lt;/code&gt; and &lt;code&gt;llama-cpp-python&lt;/code&gt;).&lt;/li&gt; &#xA;   &lt;li&gt;Easy installation scripts.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;For developers: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;A framework for building your own RAG-based document QA pipeline.&lt;/li&gt; &#xA;   &lt;li&gt;Customize and see your RAG pipeline in action with the provided UI (built with Gradio).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;+----------------------------------------------------------------------------+&#xA;| End users: Those who use apps built with `kotaemon`.                       |&#xA;| (You use an app like the one in the demo above)                            |&#xA;|     +----------------------------------------------------------------+     |&#xA;|     | Developers: Those who built with `kotaemon`.                   |     |&#xA;|     | (You have `import kotaemon` somewhere in your project)         |     |&#xA;|     |     +----------------------------------------------------+     |     |&#xA;|     |     | Contributors: Those who make `kotaemon` better.    |     |     |&#xA;|     |     | (You make PR to this repo)                         |     |     |&#xA;|     |     +----------------------------------------------------+     |     |&#xA;|     +----------------------------------------------------------------+     |&#xA;+----------------------------------------------------------------------------+&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This repository is under active development. Feedback, issues, and PRs are highly appreciated.&lt;/p&gt; &#xA;&lt;h2&gt;Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Host your own document QA (RAG) web-UI&lt;/strong&gt;. Support multi-user login, organize your files in private / public collections, collaborate and share your favorite chat with others.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Organize your LLM &amp;amp; Embedding models&lt;/strong&gt;. Support both local LLMs &amp;amp; popular API providers (OpenAI, Azure, Ollama, Groq).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hybrid RAG pipeline&lt;/strong&gt;. Sane default RAG pipeline with hybrid (full-text &amp;amp; vector) retriever + re-ranking to ensure best retrieval quality.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-modal QA support&lt;/strong&gt;. Perform Question Answering on multiple documents with figures &amp;amp; tables support. Support multi-modal document parsing (selectable options on UI).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advance citations with document preview&lt;/strong&gt;. By default the system will provide detailed citations to ensure the correctness of LLM answers. View your citations (incl. relevant score) directly in the &lt;em&gt;in-browser PDF viewer&lt;/em&gt; with highlights. Warning when retrieval pipeline return low relevant articles.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Support complex reasoning methods&lt;/strong&gt;. Use question decomposition to answer your complex / multi-hop question. Support agent-based reasoning with ReAct, ReWOO and other agents.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configurable settings UI&lt;/strong&gt;. You can adjust most important aspects of retrieval &amp;amp; generation process on the UI (incl. prompts).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Extensible&lt;/strong&gt;. Being built on Gradio, you are free to customize / add any UI elements as you like. Also, we aim to support multiple strategies for document indexing &amp;amp; retrieval. &lt;code&gt;GraphRAG&lt;/code&gt; indexing pipeline is provided as an example.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/preview.png&#34; alt=&#34;Preview&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;For end users&lt;/h3&gt; &#xA;&lt;p&gt;This document is intended for developers. If you just want to install and use the app as it is, please follow the non-technical &lt;a href=&#34;https://cinnamon.github.io/kotaemon/&#34;&gt;User Guide&lt;/a&gt; (WIP).&lt;/p&gt; &#xA;&lt;h3&gt;For developers&lt;/h3&gt; &#xA;&lt;h4&gt;With Docker (recommended)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use this command to launch the server&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run \&#xA;-e GRADIO_SERVER_NAME=0.0.0.0 \&#xA;-e GRADIO_SERVER_PORT=7860 \&#xA;-p 7860:7860 -it --rm \&#xA;taprosoft/kotaemon:v1.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Navigate to &lt;code&gt;http://localhost:7860/&lt;/code&gt; to access the web UI.&lt;/p&gt; &#xA;&lt;h4&gt;Without Docker&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Clone and install required packages on a fresh python environment.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# optional (setup env)&#xA;conda create -n kotaemon python=3.10&#xA;conda activate kotaemon&#xA;&#xA;# clone this repo&#xA;git clone https://github.com/Cinnamon/kotaemon&#xA;cd kotaemon&#xA;&#xA;pip install -e &#34;libs/kotaemon[all]&#34;&#xA;pip install -e &#34;libs/ktem&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;View and edit your environment variables (API keys, end-points) in &lt;code&gt;.env&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;(Optional) To enable in-browser PDF_JS viewer, download &lt;a href=&#34;https://github.com/mozilla/pdf.js/releases/download/v4.0.379/pdfjs-4.0.379-dist.zip&#34;&gt;PDF_JS_DIST&lt;/a&gt; and extract it to &lt;code&gt;libs/ktem/ktem/assets/prebuilt&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/pdf-viewer-setup.png&#34; alt=&#34;pdf-setup&#34; width=&#34;300&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Start the web server:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The app will be automatically launched in your browser.&lt;/p&gt; &#xA;&lt;p&gt;Default username / password are: &lt;code&gt;admin&lt;/code&gt; / &lt;code&gt;admin&lt;/code&gt;. You can setup additional users directly on the UI.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/chat-tab.png&#34; alt=&#34;Chat tab&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Customize your application&lt;/h2&gt; &#xA;&lt;p&gt;By default, all application data are stored in &lt;code&gt;./ktem_app_data&lt;/code&gt; folder. You can backup or copy this folder to move your installation to a new machine.&lt;/p&gt; &#xA;&lt;p&gt;For advance users or specific use-cases, you can customize those files:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;flowsettings.py&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;.env&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;code&gt;flowsettings.py&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;This file contains the configuration of your application. You can use the example &lt;a href=&#34;https://raw.githubusercontent.com/Cinnamon/kotaemon/main/flowsettings.py&#34;&gt;here&lt;/a&gt; as the starting point.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Notable settings&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;# setup your preferred document store (with full-text search capabilities)&#xA;KH_DOCSTORE=(Elasticsearch | LanceDB | SimpleFileDocumentStore)&#xA;&#xA;# setup your preferred vectorstore (for vector-based search)&#xA;KH_VECTORSTORE=(ChromaDB | LanceDB&#xA;&#xA;# Enable / disable multimodal QA&#xA;KH_REASONINGS_USE_MULTIMODAL=True&#xA;&#xA;# Setup your new reasoning pipeline or modify existing one.&#xA;KH_REASONINGS = [&#xA;    &#34;ktem.reasoning.simple.FullQAPipeline&#34;,&#xA;    &#34;ktem.reasoning.simple.FullDecomposeQAPipeline&#34;,&#xA;    &#34;ktem.reasoning.react.ReactAgentPipeline&#34;,&#xA;    &#34;ktem.reasoning.rewoo.RewooAgentPipeline&#34;,&#xA;]&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;&lt;code&gt;.env&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;This file provides another way to configure your models and credentials.&lt;/p&gt; &#xA;&lt;details markdown&gt; &#xA; &lt;summary&gt;Configure model via the .env file&lt;/summary&gt; &#xA; &lt;p&gt;Alternatively, you can configure the models via the &lt;code&gt;.env&lt;/code&gt; file with the information needed to connect to the LLMs. This file is located in the folder of the application. If you don&#39;t see it, you can create one.&lt;/p&gt; &#xA; &lt;p&gt;Currently, the following providers are supported:&lt;/p&gt; &#xA; &lt;h4&gt;OpenAI&lt;/h4&gt; &#xA; &lt;p&gt;In the &lt;code&gt;.env&lt;/code&gt; file, set the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; variable with your OpenAI API key in order to enable access to OpenAI&#39;s models. There are other variables that can be modified, please feel free to edit them to fit your case. Otherwise, the default parameter should work for most people.&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;OPENAI_API_BASE=https://api.openai.com/v1&#xA;OPENAI_API_KEY=&amp;lt;your OpenAI API key here&amp;gt;&#xA;OPENAI_CHAT_MODEL=gpt-3.5-turbo&#xA;OPENAI_EMBEDDINGS_MODEL=text-embedding-ada-002&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;Azure OpenAI&lt;/h4&gt; &#xA; &lt;p&gt;For OpenAI models via Azure platform, you need to provide your Azure endpoint and API key. Your might also need to provide your developments&#39; name for the chat model and the embedding model depending on how you set up Azure development.&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;AZURE_OPENAI_ENDPOINT=&#xA;AZURE_OPENAI_API_KEY=&#xA;OPENAI_API_VERSION=2024-02-15-preview&#xA;AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-35-turbo&#xA;AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=text-embedding-ada-002&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;h4&gt;Local models&lt;/h4&gt; &#xA; &lt;h5&gt;Using ollama OpenAI compatible server&lt;/h5&gt; &#xA; &lt;p&gt;Install &lt;a href=&#34;https://github.com/ollama/ollama&#34;&gt;ollama&lt;/a&gt; and start the application.&lt;/p&gt; &#xA; &lt;p&gt;Pull your model (e.g):&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code&gt;ollama pull llama3.1:8b&#xA;ollama pull nomic-embed-text&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;Set the model names on web UI and make it as default.&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/models.png&#34; alt=&#34;Models&#34;&gt;&lt;/p&gt; &#xA; &lt;h5&gt;Using GGUF with llama-cpp-python&lt;/h5&gt; &#xA; &lt;p&gt;You can search and download a LLM to be ran locally from the &lt;a href=&#34;https://huggingface.co/models&#34;&gt;Hugging Face Hub&lt;/a&gt;. Currently, these model formats are supported:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;GGUF&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;You should choose a model whose size is less than your device&#39;s memory and should leave about 2 GB. For example, if you have 16 GB of RAM in total, of which 12 GB is available, then you should choose a model that takes up at most 10 GB of RAM. Bigger models tend to give better generation but also take more processing time.&lt;/p&gt; &#xA; &lt;p&gt;Here are some recommendations and their size in memory:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat-GGUF/resolve/main/qwen1_5-1_8b-chat-q8_0.gguf?download=true&#34;&gt;Qwen1.5-1.8B-Chat-GGUF&lt;/a&gt;: around 2 GB&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;Add a new LlamaCpp model with the provided model name on the web uI.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Adding your own RAG pipeline&lt;/h2&gt; &#xA;&lt;h4&gt;Custom reasoning pipeline&lt;/h4&gt; &#xA;&lt;p&gt;First, check the default pipeline implementation in &lt;a href=&#34;https://raw.githubusercontent.com/Cinnamon/kotaemon/main/libs/ktem/ktem/reasoning/simple.py&#34;&gt;here&lt;/a&gt;. You can make quick adjustment to how the default QA pipeline work.&lt;/p&gt; &#xA;&lt;p&gt;Next, if you feel comfortable adding new pipeline, add new &lt;code&gt;.py&lt;/code&gt; implementation in &lt;code&gt;libs/ktem/ktem/reasoning/&lt;/code&gt; and later include it in &lt;code&gt;flowssettings&lt;/code&gt; to enable it on the UI.&lt;/p&gt; &#xA;&lt;h4&gt;Custom indexing pipeline&lt;/h4&gt; &#xA;&lt;p&gt;Check sample implementation in &lt;code&gt;libs/ktem/ktem/index/file/graph&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;(more instruction WIP).&lt;/p&gt; &#xA;&lt;h2&gt;Developer guide&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://cinnamon.github.io/kotaemon/development/&#34;&gt;Developer Guide&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;a href=&#34;https://star-history.com/#Cinnamon/kotaemon&amp;amp;Date&#34;&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;amp;type=Date&amp;amp;theme=dark&#34;&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;amp;type=Date&#34;&gt; &#xA;  &lt;img alt=&#34;Star History Chart&#34; src=&#34;https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;amp;type=Date&#34;&gt; &#xA; &lt;/picture&gt; &lt;/a&gt;</summary>
  </entry>
</feed>