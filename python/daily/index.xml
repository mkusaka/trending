<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-05-23T01:34:52Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>yutiansut/QUANTAXIS</title>
    <updated>2025-05-23T01:34:52Z</updated>
    <id>tag:github.com,2025-05-23:/yutiansut/QUANTAXIS</id>
    <link href="https://github.com/yutiansut/QUANTAXIS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;QUANTAXIS 支持任务调度 分布式部署的 股票/期货/期权 数据/回测/模拟/交易/可视化/多账户 纯本地量化解决方案&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;QUANTAXIS 2.0.0&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/quantaxis/quantaxis/watchers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/watchers/quantaxis/quantaxis.svg?style=social&amp;amp;label=Watchers&amp;amp;&#34; alt=&#34;Github workers&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/quantaxis/quantaxis/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/quantaxis/quantaxis.svg?style=social&amp;amp;label=Star&amp;amp;&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/quantaxis/quantaxis/fork&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/quantaxis/quantaxis.svg?style=social&amp;amp;label=Fork&amp;amp;&#34; alt=&#34;GitHub forks&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;[点击右上角Star和Watch来跟踪项目进展! 点击Fork来创建属于你的QUANTAXIS!]&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;http://picx.gulizhu.com/Fn0TPEcwu_uhraf58_93Ul5yfvAz&#34; alt=&#34;QUANTAXIS_LOGO_LAST_small.jpg&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;http://picx.gulizhu.com/gvp.jpg&#34; alt=&#34;gvp&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;更多文档在&lt;a href=&#34;https://github.com/QUANTAXIS/QUANTAXIS/releases/download/latest/quantaxis.pdf&#34;&gt;QABook Release&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Quantitative Financial FrameWork&lt;/p&gt; &#xA;&lt;p&gt;本项目分为几个大块:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;QASU/ QAFetch 支持多市场数据存储/ 自动运维/ 数据获取(mongodb/ clickhouse)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;QAUtil 支持交易时间, 交易日历, 时间向前向后推算, 市场识别, dataframe 数据转换等&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;QIFI/ QAMarket 一套统一的多市场 多语言账户体系&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;qifiaccount qifi 的标准账户体系, 在多语言上和 rust/cpp 版本的 qifi account 保持一致性&lt;/li&gt; &#xA;   &lt;li&gt;qifimanager qifi 多账户管理体系 支持多个语言的账户统一管理&lt;/li&gt; &#xA;   &lt;li&gt;qaposition 单标的仓位管理模块, 支持对于单标的的精准多空控制(套利场景/ cta 场景/ 股票场景)&lt;/li&gt; &#xA;   &lt;li&gt;marketpreset 市场预制基类, 方便查询期货/股票/虚拟货币 品种 tick/ 保证金/ 手续费等&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;QAFactor 因子研究套件&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;单因子研究入库&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;因子管理, 测试&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;因子合并&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;p&gt;优化器&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;QAData 多标的多市场的数据结构, 可以作为实时计算和回测的内存数据库使用&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;QAIndicator 支持自定义指标编写, 批量全市场 apply, 支持因子表达式构建&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;QAEngine 自定义线程进程基类, 可以自行修改计算的异步和局域网内分布式计算 agent&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;QAPubSub 基于 MQ 的消息队列, 支持 1-1 1-n n-n 的消息分发, 可用于计算任务分发收集, 实时订单流等场景&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;QAStrategy cta/套利回测套件, 支持 QIFI 模式&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;QAWebServer tornadobase 的 webserver 套件, 可以作为中台微服务构建&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;QASchedule 基于 QAWerbServer 的后台任务调度 支持自动运维, 远程任务调度等&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;本版本为不兼容升级的 2.0 quantaxis, 涉及一些改变&lt;/p&gt; &#xA;&lt;h2&gt;数据部分&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;增加 clickhouse client 自建数据源分发&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;增加数据格式&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;对于 tabular data 的支持&lt;/li&gt; &#xA;   &lt;li&gt;支持因子化的数据结构&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;支持 tick/l2 order/transaction 的数据格式&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;微服务部分&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;增加 QAWEBSEBVER&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;支持动态的任务指派的 sechedule&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;增加 基于 DAG模型的pipeline&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;增加 QAPUBSUB模块 支持 rabbitmq&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;账户部分&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;删除 QAARP 不再维护老版本 account 系统&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;升级完整的 qifi 模块 支持多市场/跨市场的账户模型&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;支持保证金模型&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;支持股票&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;支持期货&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;期权[升级中]&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;实盘模拟盘部分&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;使用稳定的 qifi 结构对接&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;支持 CTP 接口的&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;期货&lt;/li&gt; &#xA;   &lt;li&gt;期权&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;支持股票部分&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;QMT 对接&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;母子账户的订单分发跟踪 [OMS]&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ordergateway 风控订单流规则&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;多语言部分&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;支持于 QUANTAXIS Rust 版本的通信&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;基于 arrow 库, 使用多语言支持的 pyarrow 格式, 对接 arrow-rs, datafusion-rs, libarrow(CPP)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;支持 RUST/ CPP 账户&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;支持因子化的 rust job worker&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;社区/项目捐赠&lt;/h2&gt; &#xA;&lt;h3&gt;github&lt;/h3&gt; &#xA;&lt;p&gt;QUANTAXIS 是一个开放的项目, 在开源的3年中有大量的小伙伴加入了我, 并提交了相关的代码, 感谢以下的同学们&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/QUANTAXIS/QUANTAXIS/graphs/contributors&#34;&gt;&lt;img src=&#34;https://opencollective.com/QUANTAXIS/contributors.svg?width=890&amp;amp;button=false&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;许多问题 可以在 &lt;a href=&#34;https://github.com/QUANTAXIS/QUANTAXIS/issues&#34;&gt;GITHUB ISSUE&lt;/a&gt;中找到, 你可以提出新的issue&lt;/p&gt; &#xA;&lt;h3&gt;捐赠&lt;/h3&gt; &#xA;&lt;p&gt;写代码不易...请作者喝杯咖啡呗?&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;http://picx.gulizhu.com/alipay.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;(PS: 支付的时候 请带上你的名字/昵称呀 会维护一个赞助列表~ )&lt;/p&gt; &#xA;&lt;h3&gt;QQ群&lt;/h3&gt; &#xA;&lt;p&gt;欢迎加群讨论: 563280067 &lt;a href=&#34;https://jq.qq.com/?_wv=1027&amp;amp;k=4CEKGzn&#34;&gt;群链接&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;DISCORD 社区 &lt;a href=&#34;https://discord.gg/mkk5RgN&#34;&gt;https://discord.gg/mkk5RgN&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;QUANTAXIS 开发群: 773602202 (如果想要贡献代码 请加这个群 需要备注你的GITHUB ID)&lt;/p&gt; &#xA;&lt;p&gt;QUANTAXIS 期货实盘多账户的本地部署群 (请勿浪费群资源 没有本地多账户部署的请勿加): 945822690&lt;/p&gt; &#xA;&lt;h3&gt;公共号&lt;/h3&gt; &#xA;&lt;p&gt;欢迎关注公众号: &lt;img src=&#34;http://picx.gulizhu.com/Fr0pHbwB7-zrq_HAKsvB8g2zaP_A&#34; alt=&#34;公众号&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;QAPRO公共号免费提供了下单推送接口, 关注公共号回复trade即可使用&lt;/p&gt; &#xA;&lt;h3&gt;论坛 QACLUB&lt;/h3&gt; &#xA;&lt;p&gt;QUANTAXIS 内测版论坛 &lt;a href=&#34;http://www.yutiansut.com:3000&#34;&gt;QUANTAXISCLUB上线&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.yutiansut.com:3000&#34;&gt;http://www.yutiansut.com:3000&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;凡通过论坛进行提问的 均有最高的回复优先级&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>pytorch/torchrec</title>
    <updated>2025-05-23T01:34:52Z</updated>
    <id>tag:github.com,2025-05-23:/pytorch/torchrec</id>
    <link href="https://github.com/pytorch/torchrec" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Pytorch domain library for recommendation systems&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TorchRec&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;TorchRec&lt;/strong&gt; is a PyTorch domain library built to provide common sparsity and parallelism primitives needed for large-scale recommender systems (RecSys). TorchRec allows training and inference of models with large embedding tables sharded across many GPUs and &lt;strong&gt;powers many production RecSys models at Meta&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;External Presence&lt;/h2&gt; &#xA;&lt;p&gt;TorchRec has been used to accelerate advancements in recommendation systems, some examples:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/dlrm&#34;&gt;Latest version of Meta&#39;s DLRM (Deep Learning Recommendation Model)&lt;/a&gt; is built using TorchRec&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2403.00877&#34;&gt;Disaggregated Multi-Tower: Topology-aware Modeling Technique for Efficient Large-Scale Recommendation&lt;/a&gt; paper&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/twitter/the-algorithm-ml&#34;&gt;The Algorithm ML&lt;/a&gt; from Twitter&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.databricks.com/en/machine-learning/train-recommender-models.html&#34;&gt;Training Recommendation Models with Databricks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/3640457.3688037&#34;&gt;Toward 100TB model with Embedding Offloading Paper&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;To begin learning about TorchRec, check out:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Our complete &lt;a href=&#34;https://pytorch.org/tutorials/intermediate/torchrec_intro_tutorial.html&#34;&gt;TorchRec Tutorial&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://pytorch.org/torchrec/&#34;&gt;TorchRec documentation&lt;/a&gt; for an overview of TorchRec and API references&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;TorchRec Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Parallelism primitives that enable easy authoring of large, performant multi-device/multi-node models using hybrid data-parallelism/model-parallelism.&lt;/li&gt; &#xA; &lt;li&gt;Sharders to shard embedding tables with different strategies including data-parallel, table-wise, row-wise, table-wise-row-wise, column-wise, and table-wise-column-wise sharding.&lt;/li&gt; &#xA; &lt;li&gt;Planner that can automatically generate optimized sharding plans for models.&lt;/li&gt; &#xA; &lt;li&gt;Pipelined training overlapping dataloading device transfer (copy to GPU), inter-device communications (input_dist), and computation (forward, backward) for increased performance.&lt;/li&gt; &#xA; &lt;li&gt;Optimized kernels for RecSys powered by &lt;a href=&#34;https://github.com/pytorch/FBGEMM/tree/main&#34;&gt;FBGEMM&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Quantization support for reduced precision training and inference, along with optimizing a TorchRec model for C++ inference.&lt;/li&gt; &#xA; &lt;li&gt;Common modules for RecSys.&lt;/li&gt; &#xA; &lt;li&gt;RecSys datasets (criteo click logs and movielens)&lt;/li&gt; &#xA; &lt;li&gt;Examples of end-to-end training such the dlrm event prediction model trained on criteo click logs dataset.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Check out the &lt;a href=&#34;https://pytorch.org/torchrec/setup-torchrec.html&#34;&gt;Getting Started&lt;/a&gt; section in the documentation for recommended ways to set up Torchrec.&lt;/p&gt; &#xA;&lt;h3&gt;From Source&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Generally, there isn&#39;t a need to build from source&lt;/strong&gt;. For most use cases, follow the section above to set up TorchRec. However, to build from source and to get the latest changes, do the following:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Install pytorch. See &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;pytorch documentation&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;CUDA 12.4&#xA;&#xA;pip install torch --index-url https://download.pytorch.org/whl/nightly/cu124&#xA;&#xA;CUDA 12.1&#xA;&#xA;pip install torch --index-url https://download.pytorch.org/whl/nightly/cu121&#xA;&#xA;CUDA 11.8&#xA;&#xA;pip install torch --index-url https://download.pytorch.org/whl/nightly/cu118&#xA;&#xA;CPU&#xA;&#xA;pip install torch --index-url https://download.pytorch.org/whl/nightly/cpu&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Clone TorchRec.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;git clone --recursive https://github.com/pytorch/torchrec&#xA;cd torchrec&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install FBGEMM.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;CUDA 12.4&#xA;&#xA;pip install fbgemm-gpu --index-url https://download.pytorch.org/whl/nightly/cu124&#xA;&#xA;CUDA 12.1&#xA;&#xA;pip install fbgemm-gpu --index-url https://download.pytorch.org/whl/nightly/cu121&#xA;&#xA;CUDA 11.8&#xA;&#xA;pip install fbgemm-gpu --index-url https://download.pytorch.org/whl/nightly/cu118&#xA;&#xA;CPU&#xA;&#xA;pip install fbgemm-gpu --index-url https://download.pytorch.org/whl/nightly/cpu&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install other requirements.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install TorchRec.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python setup.py install develop&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Test the installation (use torchx-nightly for 3.11; for 3.12, torchx currently doesn&#39;t work).&lt;/p&gt; &lt;pre&gt;&lt;code&gt;GPU mode&#xA;&#xA;torchx run -s local_cwd dist.ddp -j 1x2 --gpu 2 --script test_installation.py&#xA;&#xA;CPU Mode&#xA;&#xA;torchx run -s local_cwd dist.ddp -j 1x2 --script test_installation.py -- --cpu_only&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;See &lt;a href=&#34;https://pytorch.org/torchx/&#34;&gt;TorchX&lt;/a&gt; for more information on launching distributed and remote jobs.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you want to run a more complex example, please take a look at the torchrec &lt;a href=&#34;https://github.com/facebookresearch/dlrm/raw/main/torchrec_dlrm/dlrm_main.py&#34;&gt;DLRM example&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/pytorch/torchrec/raw/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for details about contributing to TorchRec!&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;re using TorchRec, please refer to BibTeX entry to cite this work:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{10.1145/3523227.3547387,&#xA;author = {Ivchenko, Dmytro and Van Der Staay, Dennis and Taylor, Colin and Liu, Xing and Feng, Will and Kindi, Rahul and Sudarshan, Anirudh and Sefati, Shahin},&#xA;title = {TorchRec: a PyTorch Domain Library for Recommendation Systems},&#xA;year = {2022},&#xA;isbn = {9781450392785},&#xA;publisher = {Association for Computing Machinery},&#xA;address = {New York, NY, USA},&#xA;url = {https://doi.org/10.1145/3523227.3547387},&#xA;doi = {10.1145/3523227.3547387},&#xA;abstract = {Recommendation Systems (RecSys) comprise a large footprint of production-deployed AI today. The neural network-based recommender systems differ from deep learning models in other domains in using high-cardinality categorical sparse features that require large embedding tables to be trained. In this talk we introduce TorchRec, a PyTorch domain library for Recommendation Systems. This new library provides common sparsity and parallelism primitives, enabling researchers to build state-of-the-art personalization models and deploy them in production. In this talk we cover the building blocks of the TorchRec library including modeling primitives such as embedding bags and jagged tensors, optimized recommender system kernels powered by FBGEMM, a flexible sharder that supports a veriety of strategies for partitioning embedding tables, a planner that automatically generates optimized and performant sharding plans, support for GPU inference and common modeling modules for building recommender system models. TorchRec library is currently used to train large-scale recommender models at Meta. We will present how TorchRec helped Meta’s recommender system platform to transition from CPU asynchronous training to accelerator-based full-sync training.},&#xA;booktitle = {Proceedings of the 16th ACM Conference on Recommender Systems},&#xA;pages = {482–483},&#xA;numpages = {2},&#xA;keywords = {information retrieval, recommender systems},&#xA;location = {Seattle, WA, USA},&#xA;series = {RecSys &#39;22}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;TorchRec is BSD licensed, as found in the &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/torchrec/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;</summary>
  </entry>
</feed>