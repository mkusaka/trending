<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-18T01:42:20Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>baichuan-inc/baichuan-7B</title>
    <updated>2023-06-18T01:42:20Z</updated>
    <id>tag:github.com,2023-06-18:/baichuan-inc/baichuan-7B</id>
    <link href="https://github.com/baichuan-inc/baichuan-7B" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A large-scale 7B pretraining language model developed by BaiChuan-Inc.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt; baichuan-7B &lt;/h1&gt; &#xA; &lt;p align=&#34;center&#34; style=&#34;display: flex; flex-direction: row; justify-content: center; align-items: center&#34;&gt; ğŸ¤— &lt;a href=&#34;https://huggingface.co/baichuan-inc/baichuan-7B&#34; target=&#34;_blank&#34; style=&#34;margin-right: 15px; margin-left: 10px&#34;&gt;Hugging Face&lt;/a&gt; â€¢ ğŸ¤– &lt;a href=&#34;https://modelscope.cn/organization/baichuan-inc&#34; target=&#34;_blank&#34; style=&#34;margin-left: 10px&#34;&gt;ModelScope&lt;/a&gt; â€¢ &lt;a href=&#34;https://github.com/baichuan-inc/baichuan-7B/raw/main/media/wechat.jpeg?raw=true&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; style=&#34;display: inline-block; margin-left: 10px&#34;&gt; &lt;span style=&#34;color: blue;&#34;&gt;Wechat&lt;/span&gt; &lt;/a&gt; &lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/baichuan-inc/baichuan-7B/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/modelscope/modelscope.svg?sanitize=true&#34; alt=&#34;license&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h4 align=&#34;center&#34;&gt; &lt;p&gt; &lt;b&gt;ä¸­æ–‡&lt;/b&gt; | &lt;a href=&#34;https://github.com/baichuan-inc/baichuan-7B/raw/main/README_EN.md&#34;&gt;English&lt;/a&gt; &lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;/h4&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;ä»‹ç»&lt;/h1&gt; &#xA;&lt;p&gt;baichuan-7B æ˜¯ç”±ç™¾å·æ™ºèƒ½å¼€å‘çš„ä¸€ä¸ªå¼€æºå¯å•†ç”¨çš„å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚åŸºäº Transformer ç»“æ„ï¼Œåœ¨å¤§çº¦1.2ä¸‡äº¿ tokens ä¸Šè®­ç»ƒçš„70äº¿å‚æ•°æ¨¡å‹ï¼Œæ”¯æŒä¸­è‹±åŒè¯­ï¼Œä¸Šä¸‹æ–‡çª—å£é•¿åº¦ä¸º4096ã€‚åœ¨æ ‡å‡†çš„ä¸­æ–‡å’Œè‹±æ–‡æƒå¨ benchmarkï¼ˆC-EVAL/MMLUï¼‰ä¸Šå‡å–å¾—åŒå°ºå¯¸æœ€å¥½çš„æ•ˆæœã€‚&lt;/p&gt; &#xA;&lt;h2&gt;æ•°æ®&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;åŸå§‹æ•°æ®åŒ…æ‹¬å¼€æºçš„ä¸­è‹±æ–‡æ•°æ®å’Œè‡ªè¡ŒæŠ“å–çš„ä¸­æ–‡äº’è”ç½‘æ•°æ®ï¼Œä»¥åŠéƒ¨åˆ†é«˜è´¨é‡çŸ¥è¯†æ€§æ•°æ®ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å‚è€ƒç›¸å…³æ•°æ®å·¥ä½œï¼Œé¢‘ç‡å’Œè´¨é‡æ˜¯æ•°æ®å¤„ç†ç¯èŠ‚é‡ç‚¹è€ƒè™‘çš„ä¸¤ä¸ªç»´åº¦ã€‚ æˆ‘ä»¬åŸºäºå¯å‘å¼è§„åˆ™å’Œè´¨é‡æ¨¡å‹æ‰“åˆ†ï¼Œå¯¹åŸå§‹æ•°æ®é›†è¿›è¡Œç¯‡ç« å’Œå¥å­ç²’åº¦çš„è¿‡æ»¤ã€‚åœ¨å…¨é‡æ•°æ®ä¸Šï¼Œåˆ©ç”¨å±€éƒ¨æ•æ„Ÿå“ˆå¸Œæ–¹æ³•ï¼Œå¯¹ç¯‡ç« å’Œå¥å­ç²’åº¦åšæ»¤é‡ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;æ•´ä½“æµç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/baichuan-inc/baichuan-7B/main/media/data_process.png&#34; width=&#34;90%&#34;&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ç»è¿‡ä¸æ–­çš„è°ƒæ•´å’Œå¤šè½®æµ‹è¯•ï¼Œæœ€ç»ˆç¡®è®¤äº†ä¸€ä¸ªåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¡¨ç°æœ€å¥½çš„ä¸­è‹±æ–‡é…æ¯”ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªåŸºäºè‡ªåŠ¨å­¦ä¹ çš„æ•°æ®æƒé‡ç­–ç•¥ï¼Œå¯¹ä¸åŒç±»åˆ«çš„æ•°æ®è¿›è¡Œé…æ¯”ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;åˆ†è¯&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘ä»¬å‚è€ƒå­¦æœ¯ç•Œæ–¹æ¡ˆä½¿ç”¨ SentencePiece ä¸­çš„ byte pair encoding (BPE)ä½œä¸ºåˆ†è¯ç®—æ³•ï¼Œå¹¶ä¸”è¿›è¡Œäº†ä»¥ä¸‹çš„ä¼˜åŒ–ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ç›®å‰å¤§éƒ¨åˆ†å¼€æºæ¨¡å‹ä¸»è¦åŸºäºè‹±æ–‡ä¼˜åŒ–ï¼Œå› æ­¤å¯¹ä¸­æ–‡è¯­æ–™å­˜åœ¨æ•ˆç‡è¾ƒä½çš„é—®é¢˜ã€‚æˆ‘ä»¬ä½¿ç”¨2000ä¸‡æ¡ä»¥ä¸­è‹±ä¸ºä¸»çš„å¤šè¯­è¨€è¯­æ–™è®­ç»ƒåˆ†è¯æ¨¡å‹ï¼Œæ˜¾è‘—æå‡å¯¹äºä¸­æ–‡çš„å‹ç¼©ç‡ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å¯¹äºæ•°å­¦é¢†åŸŸï¼Œæˆ‘ä»¬å‚è€ƒäº† LLaMA å’Œ Galactica ä¸­çš„æ–¹æ¡ˆï¼Œå¯¹æ•°å­—çš„æ¯ä¸€ä½å•ç‹¬åˆ†å¼€ï¼Œé¿å…å‡ºç°æ•°å­—ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œå¯¹äºæå‡æ•°å­¦èƒ½åŠ›æœ‰é‡è¦å¸®åŠ©ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å¯¹äºç½•è§å­—è¯ï¼ˆå¦‚ç‰¹æ®Šç¬¦å·ç­‰ï¼‰ï¼Œæ”¯æŒ UTF-8-characters çš„ byte ç¼–ç ï¼Œå› æ­¤åšåˆ°æœªçŸ¥å­—è¯çš„å…¨è¦†ç›–ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æˆ‘ä»¬åˆ†æäº†ä¸åŒåˆ†è¯å™¨å¯¹è¯­æ–™çš„å‹ç¼©ç‡ï¼Œå¦‚ä¸‹è¡¨ï¼Œå¯è§æˆ‘ä»¬çš„åˆ†è¯å™¨æ˜æ˜¾ä¼˜äº LLaMA, Falcon ç­‰å¼€æºæ¨¡å‹ï¼Œå¹¶ä¸”å¯¹æ¯”å…¶ä»–ä¸­æ–‡åˆ†è¯å™¨åœ¨å‹ç¼©ç‡ç›¸å½“çš„æƒ…å†µä¸‹ï¼Œè®­ç»ƒå’Œæ¨ç†æ•ˆç‡æ›´é«˜ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;baichuan-7B&lt;/th&gt; &#xA;   &lt;th&gt;LLaMA&lt;/th&gt; &#xA;   &lt;th&gt;Falcon&lt;/th&gt; &#xA;   &lt;th&gt;mpt-7B&lt;/th&gt; &#xA;   &lt;th&gt;ChatGLM&lt;/th&gt; &#xA;   &lt;th&gt;moss-moon-003&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Compress Rate&lt;/td&gt; &#xA;   &lt;td&gt;0.737&lt;/td&gt; &#xA;   &lt;td&gt;1.312&lt;/td&gt; &#xA;   &lt;td&gt;1.049&lt;/td&gt; &#xA;   &lt;td&gt;1.206&lt;/td&gt; &#xA;   &lt;td&gt;0.631&lt;/td&gt; &#xA;   &lt;td&gt;0.659&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vocab Size&lt;/td&gt; &#xA;   &lt;td&gt;64000&lt;/td&gt; &#xA;   &lt;td&gt;32000&lt;/td&gt; &#xA;   &lt;td&gt;65024&lt;/td&gt; &#xA;   &lt;td&gt;50254&lt;/td&gt; &#xA;   &lt;td&gt;130344&lt;/td&gt; &#xA;   &lt;td&gt;106029&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;æ¨¡å‹ç»“æ„&lt;/h2&gt; &#xA;&lt;p&gt;æ•´ä½“æ¨¡å‹åŸºäºæ ‡å‡†çš„ Transformer ç»“æ„ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å’Œ LLaMA ä¸€æ ·çš„æ¨¡å‹è®¾è®¡&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ä½ç½®ç¼–ç ï¼š&lt;a href=&#34;https://arxiv.org/abs/2104.09864&#34;&gt;rotary-embedding&lt;/a&gt; æ˜¯ç°é˜¶æ®µè¢«å¤§å¤šæ¨¡å‹é‡‡ç”¨çš„ä½ç½®ç¼–ç æ–¹æ¡ˆï¼Œå…·æœ‰æ›´å¥½çš„å¤–å»¶æ•ˆæœã€‚è™½ç„¶è®­ç»ƒè¿‡ç¨‹ä¸­æœ€å¤§é•¿åº¦ä¸º4096ï¼Œä½†æ˜¯å®é™…æµ‹è¯•ä¸­æ¨¡å‹å¯ä»¥å¾ˆå¥½çš„æ‰©å±•åˆ° 5000 tokens ä¸Šï¼Œå¦‚ä¸‹å›¾ï¼š &lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/baichuan-inc/baichuan-7B/main/media/long-context-ppl.png&#34; width=&#34;90%&#34;&gt; &lt;br&gt; &lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;æ¿€æ´»å±‚ï¼šSwiGLU, Feedforward å˜åŒ–ä¸º(8/3)å€çš„éšå«å±‚å¤§å°ï¼Œå³11008&lt;/li&gt; &#xA; &lt;li&gt;Layer-Normalization: åŸºäº &lt;a href=&#34;https://arxiv.org/abs/1910.07467&#34;&gt;RMSNorm&lt;/a&gt; çš„ Pre-Normalization&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;è®­ç»ƒç¨³å®šæ€§å’Œåå&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘ä»¬åœ¨åŸæœ¬çš„LLaMAæ¡†æ¶ä¸Šè¿›è¡Œè¯¸å¤šä¿®æ”¹ä»¥æå‡è®­ç»ƒæ—¶çš„ååï¼Œå…·ä½“åŒ…æ‹¬ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ç®—å­ä¼˜åŒ–æŠ€æœ¯ï¼šé‡‡ç”¨æ›´é«˜æ•ˆç®—å­ï¼Œå¦‚ Flash-attentionï¼ŒNVIDIA apex çš„ RMSNorm ç­‰ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ç®—å­åˆ‡åˆ†æŠ€æœ¯ï¼šå°†éƒ¨åˆ†è®¡ç®—ç®—å­è¿›è¡Œåˆ‡åˆ†ï¼Œå‡å°å†…å­˜å³°å€¼ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æ··åˆç²¾åº¦æŠ€æœ¯ï¼šé™ä½åœ¨ä¸æŸå¤±æ¨¡å‹ç²¾åº¦çš„æƒ…å†µä¸‹åŠ é€Ÿè®¡ç®—è¿‡ç¨‹ã€‚&lt;/li&gt; &#xA; &lt;li&gt;è®­ç»ƒå®¹ç¾æŠ€æœ¯ï¼šè®­ç»ƒå¹³å°å’Œè®­ç»ƒæ¡†æ¶è”åˆä¼˜åŒ–ï¼ŒIaaS + PaaS å®ç°åˆ†é’Ÿçº§çš„æ•…éšœå®šä½å’Œä»»åŠ¡æ¢å¤ã€‚&lt;/li&gt; &#xA; &lt;li&gt;é€šä¿¡ä¼˜åŒ–æŠ€æœ¯ï¼Œå…·ä½“åŒ…æ‹¬ï¼š &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;é‡‡ç”¨æ‹“æ‰‘æ„ŸçŸ¥çš„é›†åˆé€šä¿¡ç®—æ³•ï¼Œé¿å…ç½‘ç»œæ‹¥å¡é—®é¢˜ï¼Œæé«˜é€šä¿¡æ•ˆç‡ã€‚&lt;/li&gt; &#xA;   &lt;li&gt;æ ¹æ®å¡æ•°è‡ªé€‚åº”è®¾ç½® bucket sizeï¼Œæé«˜å¸¦å®½åˆ©ç”¨ç‡ã€‚&lt;/li&gt; &#xA;   &lt;li&gt;æ ¹æ®æ¨¡å‹å’Œé›†ç¾¤ç¯å¢ƒï¼Œè°ƒä¼˜é€šä¿¡åŸè¯­çš„è§¦å‘æ—¶æœºï¼Œä»è€Œå°†è®¡ç®—å’Œé€šä¿¡é‡å ã€‚&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;åŸºäºä¸Šè¿°çš„å‡ ä¸ªä¼˜åŒ–æŠ€æœ¯ï¼Œæˆ‘ä»¬åœ¨åƒå¡A800æœºå™¨ä¸Šè¾¾åˆ°äº†7Bæ¨¡å‹182Tflopsçš„ååï¼ŒGPUå³°å€¼ç®—åŠ›åˆ©ç”¨ç‡é«˜è¾¾58.3% ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æœ€ç»ˆçš„losså¦‚ä¸‹å›¾ï¼š&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/baichuan-inc/baichuan-7B/main/media/7b.loss.png&#34; width=&#34;90%&#34;&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;h1&gt;å…¬å¼€benchmarkæ¦œå•&lt;/h1&gt; &#xA;&lt;h2&gt;ä¸­æ–‡è¯„æµ‹&lt;/h2&gt; &#xA;&lt;h3&gt;C-Eval&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cevalbenchmark.com/index.html&#34;&gt;C-Eval æ•°æ®é›†&lt;/a&gt;æ˜¯ä¸€ä¸ªå…¨é¢çš„ä¸­æ–‡åŸºç¡€æ¨¡å‹è¯„æµ‹æ•°æ®é›†ï¼Œæ¶µç›–äº†52ä¸ªå­¦ç§‘å’Œå››ä¸ªéš¾åº¦çš„çº§åˆ«ã€‚æˆ‘ä»¬ä½¿ç”¨è¯¥æ•°æ®é›†çš„devé›†ä½œä¸º few-shot çš„æ¥æºï¼Œåœ¨ test é›†ä¸Šè¿›è¡Œäº† 5-shot æµ‹è¯•ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å…ˆä¿®æ”¹ &lt;code&gt;evaluate_zh.py&lt;/code&gt; ä¸­çš„ OPENMODEL_PATH å’Œ CEVAL_DATA_PATH ä¸¤ä¸ªå€¼ï¼Œåˆ†åˆ«æ˜¯æ¨¡å‹ï¼ˆæ–‡ä»¶å¤¹ï¼‰å­˜æ”¾çš„è·¯å¾„å’Œ C-Eval æ•°æ®é›†çš„è·¯å¾„ã€‚å†æ‰§è¡Œä¸‹é¢çš„è„šæœ¬ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;shot=5  # few-shot&#xA;gpu=0  # æ˜¾å¡id&#xA;split=test  # è¯„ä¼°æµ‹è¯•é›†&#xA;model_id=baichuan-7b   # å¾…è¯„ä¼°çš„æ¨¡å‹&#xA;task=ceval  # ä»»åŠ¡åç§°ï¼šceval&#xA;echo gpu_idx-${gpu}-${model_id}_${task}_${split}_${shot}-shot&#xA;nohup python  evaluate_zh.py --gpu_idx ${gpu} --model_id ${model_id} --task ${task} --shot ${shot} --split ${split} --show_detail  &amp;gt; ${model_id}_${task}_${split}_${shot}-shot_record.txt 2&amp;gt;&amp;amp;1 &amp;amp;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ç»“æœ&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model 5-shot&lt;/th&gt; &#xA;   &lt;th&gt;Average&lt;/th&gt; &#xA;   &lt;th&gt;Avg(Hard)&lt;/th&gt; &#xA;   &lt;th&gt;STEM&lt;/th&gt; &#xA;   &lt;th&gt;Social Sciences&lt;/th&gt; &#xA;   &lt;th&gt;Humanities&lt;/th&gt; &#xA;   &lt;th&gt;Others&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPT-4&lt;/td&gt; &#xA;   &lt;td&gt;68.7&lt;/td&gt; &#xA;   &lt;td&gt;54.9&lt;/td&gt; &#xA;   &lt;td&gt;67.1&lt;/td&gt; &#xA;   &lt;td&gt;77.6&lt;/td&gt; &#xA;   &lt;td&gt;64.5&lt;/td&gt; &#xA;   &lt;td&gt;67.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGPT&lt;/td&gt; &#xA;   &lt;td&gt;54.4&lt;/td&gt; &#xA;   &lt;td&gt;41.4&lt;/td&gt; &#xA;   &lt;td&gt;52.9&lt;/td&gt; &#xA;   &lt;td&gt;61.8&lt;/td&gt; &#xA;   &lt;td&gt;50.9&lt;/td&gt; &#xA;   &lt;td&gt;53.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Claude-v1.3&lt;/td&gt; &#xA;   &lt;td&gt;54.2&lt;/td&gt; &#xA;   &lt;td&gt;39.0&lt;/td&gt; &#xA;   &lt;td&gt;51.9&lt;/td&gt; &#xA;   &lt;td&gt;61.7&lt;/td&gt; &#xA;   &lt;td&gt;52.1&lt;/td&gt; &#xA;   &lt;td&gt;53.7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Claude-instant-v1.0&lt;/td&gt; &#xA;   &lt;td&gt;45.9&lt;/td&gt; &#xA;   &lt;td&gt;35.5&lt;/td&gt; &#xA;   &lt;td&gt;43.1&lt;/td&gt; &#xA;   &lt;td&gt;53.8&lt;/td&gt; &#xA;   &lt;td&gt;44.2&lt;/td&gt; &#xA;   &lt;td&gt;45.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;moss-moon-003-base (16B)&lt;/td&gt; &#xA;   &lt;td&gt;27.4&lt;/td&gt; &#xA;   &lt;td&gt;24.5&lt;/td&gt; &#xA;   &lt;td&gt;27.0&lt;/td&gt; &#xA;   &lt;td&gt;29.1&lt;/td&gt; &#xA;   &lt;td&gt;27.2&lt;/td&gt; &#xA;   &lt;td&gt;26.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ziya-LLaMA-13B-pretrain&lt;/td&gt; &#xA;   &lt;td&gt;30.2&lt;/td&gt; &#xA;   &lt;td&gt;22.7&lt;/td&gt; &#xA;   &lt;td&gt;27.7&lt;/td&gt; &#xA;   &lt;td&gt;34.4&lt;/td&gt; &#xA;   &lt;td&gt;32.0&lt;/td&gt; &#xA;   &lt;td&gt;28.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-7B-hf&lt;/td&gt; &#xA;   &lt;td&gt;27.1&lt;/td&gt; &#xA;   &lt;td&gt;25.9&lt;/td&gt; &#xA;   &lt;td&gt;27.1&lt;/td&gt; &#xA;   &lt;td&gt;26.8&lt;/td&gt; &#xA;   &lt;td&gt;27.9&lt;/td&gt; &#xA;   &lt;td&gt;26.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM-6B&lt;/td&gt; &#xA;   &lt;td&gt;34.5&lt;/td&gt; &#xA;   &lt;td&gt;23.1&lt;/td&gt; &#xA;   &lt;td&gt;30.4&lt;/td&gt; &#xA;   &lt;td&gt;39.6&lt;/td&gt; &#xA;   &lt;td&gt;37.4&lt;/td&gt; &#xA;   &lt;td&gt;34.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Falcon-7B&lt;/td&gt; &#xA;   &lt;td&gt;25.8&lt;/td&gt; &#xA;   &lt;td&gt;24.3&lt;/td&gt; &#xA;   &lt;td&gt;25.8&lt;/td&gt; &#xA;   &lt;td&gt;26.0&lt;/td&gt; &#xA;   &lt;td&gt;25.8&lt;/td&gt; &#xA;   &lt;td&gt;25.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Open-LLaMA-v2-pretrain (7B)&lt;/td&gt; &#xA;   &lt;td&gt;24.0&lt;/td&gt; &#xA;   &lt;td&gt;22.5&lt;/td&gt; &#xA;   &lt;td&gt;23.1&lt;/td&gt; &#xA;   &lt;td&gt;25.3&lt;/td&gt; &#xA;   &lt;td&gt;25.2&lt;/td&gt; &#xA;   &lt;td&gt;23.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TigerBot-7B-base&lt;/td&gt; &#xA;   &lt;td&gt;25.7&lt;/td&gt; &#xA;   &lt;td&gt;27.0&lt;/td&gt; &#xA;   &lt;td&gt;27.3&lt;/td&gt; &#xA;   &lt;td&gt;24.7&lt;/td&gt; &#xA;   &lt;td&gt;23.4&lt;/td&gt; &#xA;   &lt;td&gt;26.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Aquila-7B&lt;sup&gt;*&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td&gt;25.5&lt;/td&gt; &#xA;   &lt;td&gt;25.2&lt;/td&gt; &#xA;   &lt;td&gt;25.6&lt;/td&gt; &#xA;   &lt;td&gt;24.6&lt;/td&gt; &#xA;   &lt;td&gt;25.2&lt;/td&gt; &#xA;   &lt;td&gt;26.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BLOOM-7B&lt;/td&gt; &#xA;   &lt;td&gt;22.8&lt;/td&gt; &#xA;   &lt;td&gt;20.2&lt;/td&gt; &#xA;   &lt;td&gt;21.8&lt;/td&gt; &#xA;   &lt;td&gt;23.3&lt;/td&gt; &#xA;   &lt;td&gt;23.9&lt;/td&gt; &#xA;   &lt;td&gt;23.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BLOOMZ-7B&lt;/td&gt; &#xA;   &lt;td&gt;35.7&lt;/td&gt; &#xA;   &lt;td&gt;25.8&lt;/td&gt; &#xA;   &lt;td&gt;31.3&lt;/td&gt; &#xA;   &lt;td&gt;43.5&lt;/td&gt; &#xA;   &lt;td&gt;36.6&lt;/td&gt; &#xA;   &lt;td&gt;35.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;baichuan-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;42.8&lt;/td&gt; &#xA;   &lt;td&gt;31.5&lt;/td&gt; &#xA;   &lt;td&gt;38.2&lt;/td&gt; &#xA;   &lt;td&gt;52.0&lt;/td&gt; &#xA;   &lt;td&gt;46.2&lt;/td&gt; &#xA;   &lt;td&gt;39.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Gaokao&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ExpressAI/AI-Gaokao&#34;&gt;Gaokao&lt;/a&gt; æ˜¯ä¸€ä¸ªä»¥ä¸­å›½é«˜è€ƒé¢˜ä½œä¸ºè¯„æµ‹å¤§è¯­è¨€æ¨¡å‹èƒ½åŠ›çš„æ•°æ®é›†ï¼Œç”¨ä»¥è¯„ä¼°æ¨¡å‹çš„è¯­è¨€èƒ½åŠ›å’Œé€»è¾‘æ¨ç†èƒ½åŠ›ã€‚ æˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œéšæœºåˆ’åˆ†åå¯¹æ‰€æœ‰æ¨¡å‹è¿›è¡Œç»Ÿä¸€ 5-shot æµ‹è¯•ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;ç»“æœ&lt;/h3&gt; &#xA;&lt;p&gt;ä»¥ä¸‹æ˜¯æµ‹è¯•çš„ç»“æœã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Average&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Open-LLaMA-v2-pretrain&lt;/td&gt; &#xA;   &lt;td&gt;21.41&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ziya-LLaMA-13B-pretrain&lt;/td&gt; &#xA;   &lt;td&gt;23.17&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Falcon-7B&lt;/td&gt; &#xA;   &lt;td&gt;23.98&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TigerBot-7B-base&lt;/td&gt; &#xA;   &lt;td&gt;25.94&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-7B&lt;/td&gt; &#xA;   &lt;td&gt;27.81&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM-6B&lt;/td&gt; &#xA;   &lt;td&gt;21.41&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BLOOM-7B&lt;/td&gt; &#xA;   &lt;td&gt;26.96&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BLOOMZ-7B&lt;/td&gt; &#xA;   &lt;td&gt;28.72&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Aquila-7B&lt;sup&gt;*&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td&gt;24.39&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;baichuan-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;36.24&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;AGIEval&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/AGIEval&#34;&gt;AGIEval&lt;/a&gt; æ—¨åœ¨è¯„ä¼°æ¨¡å‹çš„è®¤çŸ¥å’Œè§£å†³é—®é¢˜ç›¸å…³çš„ä»»åŠ¡ä¸­çš„ä¸€èˆ¬èƒ½åŠ›ã€‚ æˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å››é€‰ä¸€å•é¡¹é€‰æ‹©é¢˜ï¼Œéšæœºåˆ’åˆ†åå¯¹æ‰€æœ‰æ¨¡å‹è¿›è¡Œäº†ç»Ÿä¸€5-shotæµ‹è¯•ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;ç»“æœ&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Average&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Open-LLaMA-v2-pretrain&lt;/td&gt; &#xA;   &lt;td&gt;23.49&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ziya-LLaMA-13B-pretrain&lt;/td&gt; &#xA;   &lt;td&gt;27.64&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Falcon-7B&lt;/td&gt; &#xA;   &lt;td&gt;27.18&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TigerBot-7B-base&lt;/td&gt; &#xA;   &lt;td&gt;25.19&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-7B&lt;/td&gt; &#xA;   &lt;td&gt;28.17&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM-6B&lt;/td&gt; &#xA;   &lt;td&gt;23.49&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BLOOM-7B&lt;/td&gt; &#xA;   &lt;td&gt;26.55&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BLOOMZ-7B&lt;/td&gt; &#xA;   &lt;td&gt;30.27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Aquila-7B&lt;sup&gt;*&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td&gt;25.58&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;baichuan-7B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;34.44&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;sup&gt;*&lt;/sup&gt;å…¶ä¸­ Aquila æ¨¡å‹æ¥æºäºæ™ºæºå®˜æ–¹ç½‘ç«™(&lt;a href=&#34;https://model.baai.ac.cn/model-detail/100098&#34;&gt;https://model.baai.ac.cn/model-detail/100098&lt;/a&gt;) ä»…åšå‚è€ƒ&lt;/p&gt; &#xA;&lt;h2&gt;è‹±æ–‡æ¦œå•&lt;/h2&gt; &#xA;&lt;p&gt;é™¤äº†ä¸­æ–‡ä¹‹å¤–ï¼Œæˆ‘ä»¬ä¹Ÿæµ‹è¯•äº†æ¨¡å‹åœ¨è‹±æ–‡ä¸Šçš„æ•ˆæœï¼Œ&lt;a href=&#34;https://arxiv.org/abs/2009.03300&#34;&gt;MMLU&lt;/a&gt; æ˜¯åŒ…å«57ä¸ªå¤šé€‰ä»»åŠ¡çš„è‹±æ–‡è¯„æµ‹æ•°æ®é›†ï¼Œæ¶µç›–äº†åˆç­‰æ•°å­¦ã€ç¾å›½å†å²ã€è®¡ç®—æœºç§‘å­¦ã€æ³•å¾‹ç­‰ï¼Œéš¾åº¦è¦†ç›–é«˜ä¸­æ°´å¹³åˆ°ä¸“å®¶æ°´å¹³ï¼Œæ˜¯ç›®å‰ä¸»æµçš„LLMè¯„æµ‹æ•°æ®é›†ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æˆ‘ä»¬é‡‡ç”¨äº†&lt;a href=&#34;https://github.com/hendrycks/test&#34;&gt;å¼€æº&lt;/a&gt; çš„è¯„æµ‹æ–¹æ¡ˆï¼Œæœ€ç»ˆ 5-shot ç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š&lt;/p&gt; &#xA;&lt;h3&gt;ç»“æœ&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Humanities&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Social Sciences&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;STEM&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Other&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Average&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-7B&lt;sup&gt;2&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;34.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Falcon-7B&lt;sup&gt;1&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mpt-7B&lt;sup&gt;1&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM-6B&lt;sup&gt;0&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;35.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;41.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;36.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BLOOM-7B&lt;sup&gt;0&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;25.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;25.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BLOOMZ-7B&lt;sup&gt;0&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;31.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;39.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;36.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;moss-moon-003-base (16B)&lt;sup&gt;0&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;24.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;23.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;moss-moon-003-sft (16B)&lt;sup&gt;0&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;30.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;baichuan-7B&lt;sup&gt;0&lt;/sup&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;strong&gt;38.4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;48.9&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;35.6&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;48.1&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;42.3&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;ä¸Šæ ‡è¯´æ˜ï¼š&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;0:é‡æ–°å¤ç°&#xA;1:https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard&#xA;2:https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;å¤ç°æ–¹æ³•&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/hendrycks/test&#xA;cd test&#xA;wget https://people.eecs.berkeley.edu/~hendrycks/data.tar&#xA;tar xf data&#xA;mkdir results&#xA;cp evaluate_mmlu.py .&#xA;python evaluation/evaluate_mmlu.py -m /path/to/baichuan-7b&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å…¶ä¸­åœ¨ MMLU ä¸Š57ä¸ªä»»åŠ¡çš„å…·ä½“ç»†æŒ‡æ ‡å¦‚ä¸‹å›¾ï¼š&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/baichuan-inc/baichuan-7B/main/media/MMLU-57-tasks.png&#34; width=&#34;90%&#34;&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;p&gt;å…¶ä¸­å„ä¸ªå­¦ç§‘çš„æŒ‡æ ‡å¦‚ä¸‹å›¾ï¼š&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;media/MMLU 21 Subjects.png&#34; width=&#34;90%&#34;&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;h1&gt;æ¨ç†æ–¹æ³•&lt;/h1&gt; &#xA;&lt;p&gt;æ¨ç†ä»£ç å·²ç»åœ¨&lt;a href=&#34;https://huggingface.co/baichuan-inc/baichuan-7B&#34;&gt;å®˜æ–¹ Huggingface åº“&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoModelForCausalLM, AutoTokenizer&#xA;&#xA;tokenizer = AutoTokenizer.from_pretrained(&#34;baichuan-inc/baichuan-7B&#34;, trust_remote_code=True)&#xA;model = AutoModelForCausalLM.from_pretrained(&#34;baichuan-inc/baichuan-7B&#34;, device_map=&#34;auto&#34;, trust_remote_code=True)&#xA;inputs = tokenizer(&#39;ç™»é¹³é›€æ¥¼-&amp;gt;ç‹ä¹‹æ¶£\nå¤œé›¨å¯„åŒ—-&amp;gt;&#39;, return_tensors=&#39;pt&#39;)&#xA;inputs = inputs.to(&#39;cuda:0&#39;)&#xA;pred = model.generate(**inputs, max_new_tokens=64,repetition_penalty=1.1)&#xA;print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;è®­ç»ƒæ–¹æ³•&lt;/h1&gt; &#xA;&lt;h2&gt;å®‰è£…ä¾èµ–&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;å‡†å¤‡æ•°æ®&lt;/h2&gt; &#xA;&lt;p&gt;ç”¨æˆ·å°†è®­ç»ƒè¯­æ–™æŒ‰æ€»rankæ•°çš„å€æ•°å‡åŒ€åˆ‡åˆ†æˆå¤šä¸ª UTF-8 æ–‡æœ¬æ–‡ä»¶ï¼Œæ”¾ç½®åœ¨è¯­æ–™ç›®å½•ï¼ˆé»˜è®¤ä¸º &lt;code&gt;data_dir&lt;/code&gt; ï¼‰ä¸‹ã€‚å„ä¸ªrankè¿›ç¨‹å°†ä¼šè¯»å–è¯­æ–™ç›®å½•ä¸‹çš„ä¸åŒæ–‡ä»¶ï¼Œå…¨éƒ¨åŠ è½½åˆ°å†…å­˜åï¼Œå¼€å§‹åç»­è®­ç»ƒè¿‡ç¨‹ã€‚ä»¥ä¸Šæ˜¯ç®€åŒ–çš„ç¤ºèŒƒæµç¨‹ï¼Œå»ºè®®ç”¨æˆ·åœ¨æ­£å¼è®­ç»ƒä»»åŠ¡ä¸­ï¼Œæ ¹æ®éœ€æ±‚è°ƒæ•´æ•°æ®ç”Ÿäº§é€»è¾‘ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ä¸‹è½½ tokenizer æ¨¡å‹&lt;/h2&gt; &#xA;&lt;p&gt;ä¸‹è½½ tokenizer æ¨¡å‹æ–‡ä»¶ &lt;a href=&#34;https://huggingface.co/baichuan-inc/baichuan-7B/blob/main/tokenizer.model&#34;&gt;tokenizer.model&lt;/a&gt; ï¼Œæ”¾ç½®åœ¨é¡¹ç›®ç›®å½•ä¸‹ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;é…ç½® DeepSpeed&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬ç¤ºèŒƒä»£ç é‡‡ç”¨ DeepSpeed æ¡†æ¶è¿›è¡Œè®­ç»ƒã€‚ç”¨æˆ·éœ€æ ¹æ®é›†ç¾¤æƒ…å†µï¼Œä¿®æ”¹ &lt;code&gt;config/hostfile&lt;/code&gt; ï¼Œå¦‚æœæ˜¯å¤šæœºå¤šå¡ï¼Œéœ€è¦ä¿®æ”¹ ssh ä¸­å„ä¸ªèŠ‚ç‚¹çš„ IP é…ç½®ã€‚å…·ä½“å¯ä»¥å‚è§DeepSpeed&lt;a href=&#34;https://www.deepspeed.ai/&#34;&gt;å®˜æ–¹è¯´æ˜&lt;/a&gt; ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;æ‰§è¡Œè®­ç»ƒ&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;scripts/train.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;åè®®&lt;/h1&gt; &#xA;&lt;p&gt;å¯¹æœ¬ä»“åº“æºç çš„ä½¿ç”¨éµå¾ªå¼€æºè®¸å¯åè®® &lt;a href=&#34;https://github.com/baichuan-inc/baichuan-7B/raw/main/LICENSE&#34;&gt;Apache 2.0&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;baichuan-7Bæ”¯æŒå•†ç”¨ã€‚å¦‚æœå°†baichuan-7B æ¨¡å‹æˆ–å…¶è¡ç”Ÿå“ç”¨ä½œå•†ä¸šç”¨é€”ï¼Œè¯·æ‚¨æŒ‰ç…§å¦‚ä¸‹æ–¹å¼è”ç³»è®¸å¯æ–¹ï¼Œä»¥è¿›è¡Œç™»è®°å¹¶å‘è®¸å¯æ–¹ç”³è¯·ä¹¦é¢æˆæƒï¼šè”ç³»é‚®ç®±ï¼š&lt;a href=&#34;mailto:opensource@baichuan-inc.com&#34;&gt;opensource@baichuan-inc.com&lt;/a&gt;ï¼Œ å…·ä½“è®¸å¯åè®®å¯è§&lt;a href=&#34;https://huggingface.co/baichuan-inc/baichuan-7B/resolve/main/baichuan-7B%20%E6%A8%A1%E5%9E%8B%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf&#34;&gt;ã€Šbaichuan-7B æ¨¡å‹è®¸å¯åè®®ã€‹&lt;/a&gt;ã€‚&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>open-mmlab/mmagic</title>
    <updated>2023-06-18T01:42:20Z</updated>
    <id>tag:github.com,2023-06-18:/open-mmlab/mmagic</id>
    <link href="https://github.com/open-mmlab/mmagic" rel="alternate"></link>
    <summary type="html">&lt;p&gt;OpenMMLab Multimodal Advanced, Generative, and Intelligent Creation Toolbox. Unlock the magic ğŸª„: Generative-AI (AIGC), easy-to-use APIs, awsome model zoo, diffusion models, for text-to-image generation, image/video restoration/enhancement, etc.&lt;/p&gt;&lt;hr&gt;&lt;div id=&#34;top&#34; align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/docs/en/_static/image/mmagic-logo.png&#34; width=&#34;500px&#34;&gt; &#xA; &lt;div&gt;&#xA;  &amp;nbsp;&#xA; &lt;/div&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;font size=&#34;10&#34;&gt;&lt;b&gt;M&lt;/b&gt;ultimodal &lt;b&gt;A&lt;/b&gt;dvanced, &lt;b&gt;G&lt;/b&gt;enerative, and &lt;b&gt;I&lt;/b&gt;ntelligent &lt;b&gt;C&lt;/b&gt;reation (MMagic [em&#39;mÃ¦dÊ’Éªk])&lt;/font&gt; &#xA; &lt;/div&gt; &#xA; &lt;div&gt;&#xA;  &amp;nbsp;&#xA; &lt;/div&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;b&gt;&lt;font size=&#34;5&#34;&gt;OpenMMLab website&lt;/font&gt;&lt;/b&gt; &#xA;  &lt;sup&gt; &lt;a href=&#34;https://openmmlab.com&#34;&gt; &lt;i&gt;&lt;font size=&#34;4&#34;&gt;HOT&lt;/font&gt;&lt;/i&gt; &lt;/a&gt; &lt;/sup&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &#xA;  &lt;b&gt;&lt;font size=&#34;5&#34;&gt;OpenMMLab platform&lt;/font&gt;&lt;/b&gt; &#xA;  &lt;sup&gt; &lt;a href=&#34;https://platform.openmmlab.com&#34;&gt; &lt;i&gt;&lt;font size=&#34;4&#34;&gt;TRY IT OUT&lt;/font&gt;&lt;/i&gt; &lt;/a&gt; &lt;/sup&gt; &#xA; &lt;/div&gt; &#xA; &lt;div&gt;&#xA;  &amp;nbsp;&#xA; &lt;/div&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://pypi.org/project/mmagic/&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/mmagic.svg?sanitize=true&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://mmagic.readthedocs.io/en/latest/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-latest-blue&#34; alt=&#34;docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmagic/actions&#34;&gt;&lt;img src=&#34;https://github.com/open-mmlab/mmagic/workflows/build/badge.svg?sanitize=true&#34; alt=&#34;badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/open-mmlab/mmagic&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/open-mmlab/mmagic/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmagic/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/open-mmlab/mmagic.svg?sanitize=true&#34; alt=&#34;license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmagic/issues&#34;&gt;&lt;img src=&#34;https://isitmaintained.com/badge/open/open-mmlab/mmagic.svg?sanitize=true&#34; alt=&#34;open issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmagic/issues&#34;&gt;&lt;img src=&#34;https://isitmaintained.com/badge/resolution/open-mmlab/mmagic.svg?sanitize=true&#34; alt=&#34;issue resolution&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://mmagic.readthedocs.io/en/latest/&#34;&gt;ğŸ“˜Documentation&lt;/a&gt; | &lt;a href=&#34;https://mmagic.readthedocs.io/en/latest/get_started/install.html&#34;&gt;ğŸ› ï¸Installation&lt;/a&gt; | &lt;a href=&#34;https://mmagic.readthedocs.io/en/latest/model_zoo/overview.html&#34;&gt;ğŸ“ŠModel Zoo&lt;/a&gt; | &lt;a href=&#34;https://mmagic.readthedocs.io/en/latest/changelog.html&#34;&gt;ğŸ†•Update News&lt;/a&gt; | &lt;a href=&#34;https://github.com/open-mmlab/mmagic/projects&#34;&gt;ğŸš€Ongoing Projects&lt;/a&gt; | &lt;a href=&#34;https://github.com/open-mmlab/mmagic/issues&#34;&gt;ğŸ¤”Reporting Issues&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/README_zh-CN.md&#34;&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://openmmlab.medium.com/&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218352562-cdded397-b0f3-4ca1-b8dd-a60df8dca75b.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://discord.gg/raweFPmdzG&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218347213-c080267f-cbb6-443e-8532-8e1ed9a58ea9.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://twitter.com/OpenMMLab&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218346637-d30c8a0f-3eba-4699-8131-512fb06d46db.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://www.youtube.com/openmmlab&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218346691-ceb2116a-465a-40af-8424-9f30d2348ca9.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;ğŸš€ What&#39;s New &lt;a&gt;&lt;img width=&#34;35&#34; height=&#34;20&#34; src=&#34;https://user-images.githubusercontent.com/12782558/212848161-5e783dd6-11e8-4fe0-bbba-39ffb77730be.png&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;New release &lt;a href=&#34;https://github.com/open-mmlab/mmagic/releases/tag/v1.0.1&#34;&gt;&lt;strong&gt;MMagic v1.0.1&lt;/strong&gt;&lt;/a&gt; [26/05/2023]:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Support tomesd for StableDiffusion speed-up.&lt;/li&gt; &#xA; &lt;li&gt;Support all inpainting/matting/image restoration models inferencer.&lt;/li&gt; &#xA; &lt;li&gt;Support animated drawings.&lt;/li&gt; &#xA; &lt;li&gt;Support Style-Based Global Appearance Flow for Virtual Try-On.&lt;/li&gt; &#xA; &lt;li&gt;Fix inferencer in pip-install.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We are excited to announce the release of MMagic v1.0.0 that inherits from &lt;a href=&#34;https://github.com/open-mmlab/mmediting&#34;&gt;MMEditing&lt;/a&gt; and &lt;a href=&#34;https://github.com/open-mmlab/mmgeneration&#34;&gt;MMGeneration&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;After iterative updates with OpenMMLab 2.0 framework and merged with MMGeneration, MMEditing has become a powerful tool that supports low-level algorithms based on both GAN and CNN. Today, MMEditing embraces Generative AI and transforms into a more advanced and comprehensive AIGC toolkit: &lt;strong&gt;MMagic&lt;/strong&gt; (&lt;strong&gt;M&lt;/strong&gt;ultimodal &lt;strong&gt;A&lt;/strong&gt;dvanced, &lt;strong&gt;G&lt;/strong&gt;enerative, and &lt;strong&gt;I&lt;/strong&gt;ntelligent &lt;strong&gt;C&lt;/strong&gt;reation). MMagic will provide more agile and flexible experimental support for researchers and AIGC enthusiasts, and help you on your AIGC exploration journey.&lt;/p&gt; &#xA;&lt;p&gt;We highlight the following new features.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;1. New Models&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;We support 11 new models in 4 new tasks.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Text2Image / Diffusion &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ControlNet&lt;/li&gt; &#xA;   &lt;li&gt;DreamBooth&lt;/li&gt; &#xA;   &lt;li&gt;Stable Diffusion&lt;/li&gt; &#xA;   &lt;li&gt;Disco Diffusion&lt;/li&gt; &#xA;   &lt;li&gt;GLIDE&lt;/li&gt; &#xA;   &lt;li&gt;Guided Diffusion&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;3D-aware Generation &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;EG3D&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Image Restoration &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;NAFNet&lt;/li&gt; &#xA;   &lt;li&gt;Restormer&lt;/li&gt; &#xA;   &lt;li&gt;SwinIR&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Image Colorization &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;InstColorization&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;2. Magic Diffusion Model&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;For the Diffusion Model, we provide the following &#34;magic&#34; :&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Support image generation based on Stable Diffusion and Disco Diffusion.&lt;/li&gt; &#xA; &lt;li&gt;Support Finetune methods such as Dreambooth and DreamBooth LoRA.&lt;/li&gt; &#xA; &lt;li&gt;Support controllability in text-to-image generation using ControlNet.&lt;/li&gt; &#xA; &lt;li&gt;Support acceleration and optimization strategies based on xFormers to improve training and inference efficiency.&lt;/li&gt; &#xA; &lt;li&gt;Support video generation based on MultiFrame Render.&lt;/li&gt; &#xA; &lt;li&gt;Support calling basic models and sampling strategies through DiffuserWrapper.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;3. Upgraded Framework&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;By using MMEngine and MMCV of OpenMMLab 2.0 framework, MMagic has upgraded in the following new features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Refactor DataSample to support the combination and splitting of batch dimensions.&lt;/li&gt; &#xA; &lt;li&gt;Refactor DataPreprocessor and unify the data format for various tasks during training and inference.&lt;/li&gt; &#xA; &lt;li&gt;Refactor MultiValLoop and MultiTestLoop, supporting the evaluation of both generation-type metrics (e.g. FID) and reconstruction-type metrics (e.g. SSIM), and supporting the evaluation of multiple datasets at once.&lt;/li&gt; &#xA; &lt;li&gt;Support visualization on local files or using tensorboard and wandb.&lt;/li&gt; &#xA; &lt;li&gt;Support for 33+ algorithms accelerated by Pytorch 2.0.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;MMagic&lt;/strong&gt; has supported all the tasks, models, metrics, and losses in &lt;a href=&#34;https://github.com/open-mmlab/mmediting&#34;&gt;MMEditing&lt;/a&gt; and &lt;a href=&#34;https://github.com/open-mmlab/mmgeneration&#34;&gt;MMGeneration&lt;/a&gt; and unifies interfaces of all components based on &lt;a href=&#34;https://github.com/open-mmlab/mmengine&#34;&gt;MMEngine&lt;/a&gt; ğŸ˜.&lt;/p&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/docs/en/changelog.md&#34;&gt;changelog.md&lt;/a&gt; for details and release history.&lt;/p&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/docs/en/migration/overview.md&#34;&gt;migration documents&lt;/a&gt; to migrate from &lt;a href=&#34;https://github.com/open-mmlab/mmagic/tree/0.x&#34;&gt;old version&lt;/a&gt; MMEditing 0.x to new version MMagic 1.x .&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“„ Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#-introduction&#34;&gt;ğŸ“– Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#-contributing&#34;&gt;ğŸ™Œ Contributing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#%EF%B8%8F-installation&#34;&gt;ğŸ› ï¸ Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#-model-zoo&#34;&gt;ğŸ“Š Model Zoo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#-acknowledgement&#34;&gt;ğŸ¤ Acknowledgement&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#%EF%B8%8F-citation&#34;&gt;ğŸ–Šï¸ Citation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#-license&#34;&gt;ğŸ« License&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#%EF%B8%8F-%EF%B8%8Fopenmmlab-family&#34;&gt;ğŸ—ï¸ ï¸OpenMMLab Family&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#top&#34;&gt;ğŸ”Back to top&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“– Introduction&lt;/h2&gt; &#xA;&lt;p&gt;MMagic (&lt;strong&gt;M&lt;/strong&gt;ultimodal &lt;strong&gt;A&lt;/strong&gt;dvanced, &lt;strong&gt;G&lt;/strong&gt;enerative, and &lt;strong&gt;I&lt;/strong&gt;ntelligent &lt;strong&gt;C&lt;/strong&gt;reation) is an advanced and comprehensive AIGC toolkit that inherits from &lt;a href=&#34;https://github.com/open-mmlab/mmediting&#34;&gt;MMEditing&lt;/a&gt; and &lt;a href=&#34;https://github.com/open-mmlab/mmgeneration&#34;&gt;MMGeneration&lt;/a&gt;. It is an open-source image and video editing&amp;amp;generating toolbox based on PyTorch. It is a part of the &lt;a href=&#34;https://openmmlab.com/&#34;&gt;OpenMMLab&lt;/a&gt; project.&lt;/p&gt; &#xA;&lt;p&gt;Currently, MMagic support multiple image and video generation/editing tasks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/49083766/233564593-7d3d48ed-e843-4432-b610-35e3d257765c.mp4&#34;&gt;https://user-images.githubusercontent.com/49083766/233564593-7d3d48ed-e843-4432-b610-35e3d257765c.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The best practice on our main branch works with &lt;strong&gt;Python 3.8+&lt;/strong&gt; and &lt;strong&gt;PyTorch 1.9+&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;âœ¨ Major features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;State of the Art Models&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;MMagic provides state-of-the-art generative models to process, edit and synthesize images and videos.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Powerful and Popular Applications&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;MMagic supports popular and contemporary image restoration, text-to-image, 3D-aware generation, inpainting, matting, super-resolution and generation applications. Specifically, MMagic supports fine-tuning for stable diffusion and many exciting diffusion&#39;s application such as ControlNet Animation with SAM. MMagic also supports GAN interpolation, GAN projection, GAN manipulations and many other popular GANâ€™s applications. Itâ€™s time to begin your AIGC exploration journey!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Efficient Framework&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;By using MMEngine and MMCV of OpenMMLab 2.0 framework, MMagic decompose the editing framework into different modules and one can easily construct a customized editor framework by combining different modules. We can define the training process just like playing with Legos and provide rich components and strategies. In MMagic, you can complete controls on the training process with different levels of APIs. With the support of &lt;a href=&#34;https://github.com/open-mmlab/mmengine/raw/main/mmengine/model/wrappers/seperate_distributed.py&#34;&gt;MMSeparateDistributedDataParallel&lt;/a&gt;, distributed training for dynamic architectures can be easily implemented.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#top&#34;&gt;ğŸ”Back to top&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ™Œ Contributing&lt;/h2&gt; &#xA;&lt;p&gt;More and more community contributors are joining us to make our repo better. Some recent projects are contributed by the community including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/projects/glide/configs/README.md&#34;&gt;GLIDE&lt;/a&gt; is contributed by @Taited.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/restormer/README.md&#34;&gt;Restormer&lt;/a&gt; is contributed by @AlexZou14.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/swinir/README.md&#34;&gt;SwinIR&lt;/a&gt; is contributed by @Zdafeng.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/projects/README.md&#34;&gt;Projects&lt;/a&gt; is opened to make it easier for everyone to add projects to MMagic.&lt;/p&gt; &#xA;&lt;p&gt;We appreciate all contributions to improve MMagic. Please refer to &lt;a href=&#34;https://github.com/open-mmlab/mmcv/raw/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; in MMCV and &lt;a href=&#34;https://github.com/open-mmlab/mmengine/raw/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; in MMEngine for more details about the contributing guideline.&lt;/p&gt; &#xA;&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#top&#34;&gt;ğŸ”Back to top&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ› ï¸ Installation&lt;/h2&gt; &#xA;&lt;p&gt;MMagic depends on &lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt;, &lt;a href=&#34;https://github.com/open-mmlab/mmengine&#34;&gt;MMEngine&lt;/a&gt; and &lt;a href=&#34;https://github.com/open-mmlab/mmcv&#34;&gt;MMCV&lt;/a&gt;. Below are quick steps for installation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; Install PyTorch following &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;official instructions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt; Install MMCV, MMEngine and MMagic with &lt;a href=&#34;https://github.com/open-mmlab/mim&#34;&gt;MIM&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip3 install openmim&#xA;mim install &#39;mmcv&amp;gt;=2.0.0&#39;&#xA;mim install &#39;mmengine&#39;&#xA;mim install &#39;mmagic&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Step 3.&lt;/strong&gt; Verify MMagic has been successfully installed.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd ~&#xA;python -c &#34;import mmagic; print(mmagic.__version__)&#34;&#xA;# Example output: 1.0.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Getting Started&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;After installing MMagic successfully, now you are able to play with MMagic! To generate an image from text, you only need several lines of codes by MMagic!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mmagic.apis import MMagicInferencer&#xA;sd_inferencer = MMagicInferencer(model_name=&#39;stable_diffusion&#39;)&#xA;text_prompts = &#39;A panda is having dinner at KFC&#39;&#xA;result_out_dir = &#39;output/sd_res.png&#39;&#xA;sd_inferencer.infer(text=text_prompts, result_out_dir=result_out_dir)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/docs/en/get_started/quick_run.md&#34;&gt;quick run&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/docs/en/user_guides/inference.md&#34;&gt;inference&lt;/a&gt; for the basic usage of MMagic.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Install MMagic from source&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can also experiment on the latest developed version rather than the stable release by installing MMagic from source with the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/open-mmlab/mmagic.git&#xA;cd mmagic&#xA;pip3 install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/docs/en/get_started/install.md&#34;&gt;installation&lt;/a&gt; for more detailed instruction.&lt;/p&gt; &#xA;&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#top&#34;&gt;ğŸ”Back to top&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“Š Model Zoo&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;b&gt;Supported algorithms&lt;/b&gt; &#xA;&lt;/div&gt; &#xA;&lt;table align=&#34;center&#34;&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr align=&#34;center&#34; valign=&#34;bottom&#34;&gt; &#xA;   &lt;td&gt; &lt;b&gt;Conditional GANs&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Unconditional GANs&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Image Restoration&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Image Super-Resolution&lt;/b&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr valign=&#34;top&#34;&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/sngan_proj/README.md&#34;&gt;SNGAN/Projection GAN (ICLR&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/sagan/README.md&#34;&gt;SAGAN (ICML&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/biggan/README.md&#34;&gt;BIGGAN/BIGGAN-DEEP (ICLR&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/dcgan/README.md&#34;&gt;DCGAN (ICLR&#39;2016)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/wgan-gp/README.md&#34;&gt;WGAN-GP (NeurIPS&#39;2017)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/lsgan/README.md&#34;&gt;LSGAN (ICCV&#39;2017)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/ggan/README.md&#34;&gt;GGAN (ArXiv&#39;2017)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/pggan/README.md&#34;&gt;PGGAN (ICLR&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/singan/README.md&#34;&gt;SinGAN (ICCV&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/styleganv1/README.md&#34;&gt;StyleGANV1 (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/styleganv2/README.md&#34;&gt;StyleGANV2 (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/styleganv3/README.md&#34;&gt;StyleGANV3 (NeurIPS&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/swinir/README.md&#34;&gt;SwinIR (ICCVW&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/nafnet/README.md&#34;&gt;NAFNet (ECCV&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/restormer/README.md&#34;&gt;Restormer (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/srcnn/README.md&#34;&gt;SRCNN (TPAMI&#39;2015)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/srgan_resnet/README.md&#34;&gt;SRResNet&amp;amp;SRGAN (CVPR&#39;2016)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/edsr/README.md&#34;&gt;EDSR (CVPR&#39;2017)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/esrgan/README.md&#34;&gt;ESRGAN (ECCV&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/rdn/README.md&#34;&gt;RDN (CVPR&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/dic/README.md&#34;&gt;DIC (CVPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/ttsr/README.md&#34;&gt;TTSR (CVPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/glean/README.md&#34;&gt;GLEAN (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/liif/README.md&#34;&gt;LIIF (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/real_esrgan/README.md&#34;&gt;Real-ESRGAN (ICCVW&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt;   &#xA; &lt;/tbody&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr align=&#34;center&#34; valign=&#34;bottom&#34;&gt; &#xA;   &lt;td&gt; &lt;b&gt;Video Super-Resolution&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Video Interpolation&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Image Colorization&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Image Translation&lt;/b&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr valign=&#34;top&#34;&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/edvr/README.md&#34;&gt;EDVR (CVPR&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/tof/README.md&#34;&gt;TOF (IJCV&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/tdan/README.md&#34;&gt;TDAN (CVPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/basicvsr/README.md&#34;&gt;BasicVSR (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/iconvsr/README.md&#34;&gt;IconVSR (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/basicvsr_pp/README.md&#34;&gt;BasicVSR++ (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/real_basicvsr/README.md&#34;&gt;RealBasicVSR (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/tof/README.md&#34;&gt;TOFlow (IJCV&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/cain/README.md&#34;&gt;CAIN (AAAI&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/flavr/README.md&#34;&gt;FLAVR (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/inst_colorization/README.md&#34;&gt;InstColorization (CVPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/pix2pix/README.md&#34;&gt;Pix2Pix (CVPR&#39;2017)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/cyclegan/README.md&#34;&gt;CycleGAN (ICCV&#39;2017)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt;   &#xA; &lt;/tbody&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr align=&#34;center&#34; valign=&#34;bottom&#34;&gt; &#xA;   &lt;td&gt; &lt;b&gt;Inpainting&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Matting&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Text-to-Image&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;3D-aware Generation&lt;/b&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr valign=&#34;top&#34;&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/global_local/README.md&#34;&gt;Global&amp;amp;Local (ToG&#39;2017)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/deepfillv1/README.md&#34;&gt;DeepFillv1 (CVPR&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/partial_conv/README.md&#34;&gt;PConv (ECCV&#39;2018)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/deepfillv2/README.md&#34;&gt;DeepFillv2 (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/aot_gan/README.md&#34;&gt;AOT-GAN (TVCG&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/dim/README.md&#34;&gt;DIM (CVPR&#39;2017)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/indexnet/README.md&#34;&gt;IndexNet (ICCV&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/gca/README.md&#34;&gt;GCA (AAAI&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/projects/glide/configs/README.md&#34;&gt;GLIDE (NeurIPS&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/guided_diffusion/README.md&#34;&gt;Guided Diffusion (NeurIPS&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/disco_diffusion/README.md&#34;&gt;Disco-Diffusion (2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/stable_diffusion/README.md&#34;&gt;Stable-Diffusion (2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/dreambooth/README.md&#34;&gt;DreamBooth (2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/controlnet/README.md&#34;&gt;ControlNet (2023)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/controlnet_animation/README.md&#34;&gt;ControlNet Animation (2023)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/configs/eg3d/README.md&#34;&gt;EG3D (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt;   &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://mmagic.readthedocs.io/en/latest/model_zoo/overview.html&#34;&gt;model_zoo&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#top&#34;&gt;ğŸ”Back to top&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ¤ Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;MMagic is an open source project that is contributed by researchers and engineers from various colleges and companies. We wish that the toolbox and benchmark could serve the growing research community by providing a flexible toolkit to reimplement existing methods and develop their own new methods.&lt;/p&gt; &#xA;&lt;p&gt;We appreciate all the contributors who implement their methods or add new features, as well as users who give valuable feedbacks. Thank you all!&lt;/p&gt; &#xA;&lt;a href=&#34;https://github.com/open-mmlab/mmagic/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=open-mmlab/mmagic&#34;&gt; &lt;/a&gt; &#xA;&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#top&#34;&gt;ğŸ”Back to top&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ–Šï¸ Citation&lt;/h2&gt; &#xA;&lt;p&gt;If MMagic is helpful to your research, please cite it as below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{mmagic2023,&#xA;    title = {{MMagic}: {OpenMMLab} Multimodal Advanced, Generative, and Intelligent Creation Toolbox},&#xA;    author = {{MMagic Contributors}},&#xA;    howpublished = {\url{https://github.com/open-mmlab/mmagic}},&#xA;    year = {2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{mmediting2022,&#xA;    title = {{MMEditing}: {OpenMMLab} Image and Video Editing Toolbox},&#xA;    author = {{MMEditing Contributors}},&#xA;    howpublished = {\url{https://github.com/open-mmlab/mmediting}},&#xA;    year = {2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#top&#34;&gt;ğŸ”Back to top&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ« License&lt;/h2&gt; &#xA;&lt;p&gt;This project is released under the &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;. Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/LICENSE&#34;&gt;LICENSES&lt;/a&gt; for the careful check, if you are using our code for commercial matters.&lt;/p&gt; &#xA;&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#top&#34;&gt;ğŸ”Back to top&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ—ï¸ ï¸OpenMMLab Family&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmengine&#34;&gt;MMEngine&lt;/a&gt;: OpenMMLab foundational library for training deep learning models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmcv&#34;&gt;MMCV&lt;/a&gt;: OpenMMLab foundational library for computer vision.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mim&#34;&gt;MIM&lt;/a&gt;: MIM installs OpenMMLab packages.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmpretrain&#34;&gt;MMPreTrain&lt;/a&gt;: OpenMMLab Pre-training Toolbox and Benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmdetection&#34;&gt;MMDetection&lt;/a&gt;: OpenMMLab detection toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmdetection3d&#34;&gt;MMDetection3D&lt;/a&gt;: OpenMMLab&#39;s next-generation platform for general 3D object detection.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmrotate&#34;&gt;MMRotate&lt;/a&gt;: OpenMMLab rotated object detection toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmsegmentation&#34;&gt;MMSegmentation&lt;/a&gt;: OpenMMLab semantic segmentation toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmocr&#34;&gt;MMOCR&lt;/a&gt;: OpenMMLab text detection, recognition, and understanding toolbox.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmpose&#34;&gt;MMPose&lt;/a&gt;: OpenMMLab pose estimation toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmhuman3d&#34;&gt;MMHuman3D&lt;/a&gt;: OpenMMLab 3D human parametric model toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmselfsup&#34;&gt;MMSelfSup&lt;/a&gt;: OpenMMLab self-supervised learning toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmrazor&#34;&gt;MMRazor&lt;/a&gt;: OpenMMLab model compression toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmfewshot&#34;&gt;MMFewShot&lt;/a&gt;: OpenMMLab fewshot learning toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmaction2&#34;&gt;MMAction2&lt;/a&gt;: OpenMMLab&#39;s next-generation action understanding toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmtracking&#34;&gt;MMTracking&lt;/a&gt;: OpenMMLab video perception toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmflow&#34;&gt;MMFlow&lt;/a&gt;: OpenMMLab optical flow toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmagic&#34;&gt;MMagic&lt;/a&gt;: OpenMMLab Multimodal Advanced, Generative, and Intelligent Creation Toolbox.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmdeploy&#34;&gt;MMDeploy&lt;/a&gt;: OpenMMLab model deployment framework.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmagic/main/#top&#34;&gt;ğŸ”Back to top&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>SqueezeAILab/SqueezeLLM</title>
    <updated>2023-06-18T01:42:20Z</updated>
    <id>tag:github.com,2023-06-18:/SqueezeAILab/SqueezeLLM</id>
    <link href="https://github.com/SqueezeAILab/SqueezeLLM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;SqueezeLLM: Dense-and-Sparse Quantization&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SqueezeLLM: Dense-and-Sparse Quantization [&lt;a href=&#34;https://arxiv.org/abs/2306.07629&#34;&gt;Paper&lt;/a&gt;]&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/SqueezeAILab/SqueezeLLM/main/figs/thumbnail.png&#34; alt=&#34;Thumbnail&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;SqueezeLLM is a post-training quantization framework that incorporates a new method called Dense-and-Sparse Quantization to enable efficient LLM serving.&lt;/p&gt; &#xA;&lt;p&gt;TLDR: Deploying LLMs is difficult due to their large memory size. This can be addressed with reduced precision quantization. But a naive method hurts performance. We address this with a new Dense-and-Sparse Quantization method. Dense-and-Sparse splits weight matrices into two components: A dense component that can be heavily quantized without affecting model performance, as well as a sparse part that preserves sensitive and outlier parts of the weight matrices With this approach, we are able to serve larger models with smaller memory footprint, the same latency, and &lt;strong&gt;yet higher accuracy and quality&lt;/strong&gt;. For instance, the Squeeze variant of the Vicuna models can be served within 6 GB of memory and reach 2% higher MMLU than the baseline model in FP16 with an even 2x larger memory footprint. For more details please check out our &lt;a href=&#34;https://arxiv.org/abs/2306.07629&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Updates:&lt;/strong&gt; Vicuna-7B and 13B, and LLaMA-30B are all supported with both 3-bit and 4-bit.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create a conda environment&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda create --name sqllm python=3.9 -y&#xA;conda activate sqllm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Clone and install the dependencies&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/SqueezeAILab/SqueezeLLM&#xA;cd SqueezeLLM&#xA;pip install -e .&#xA;cd squeezellm&#xA;python setup_cuda.py install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Supported Models&lt;/h2&gt; &#xA;&lt;p&gt;Currently, we support &lt;a href=&#34;https://arxiv.org/abs/2302.13971&#34;&gt;LLaMA&lt;/a&gt; 7B, 13B, and 30B, as well as the instruction-tuned &lt;a href=&#34;https://lmsys.org/blog/2023-03-30-vicuna/&#34;&gt;Vicuna&lt;/a&gt; 7B and 13B. For each model, we support 3-bit and 4-bit quantized models, with sparse levels of 0% (dense-only), 0.05%, and 0.45%. See our &lt;a href=&#34;https://arxiv.org/abs/2306.07629&#34;&gt;Paper&lt;/a&gt; for more detailed information on these configurations. Below are the links to download the models.&lt;/p&gt; &#xA;&lt;h3&gt;LLaMA&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Bitwidth&lt;/th&gt; &#xA;   &lt;th&gt;Dense-only (0%)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-7B&lt;/td&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/squeeze-ai-lab/sq-llama-7b-w3-s0/blob/main/sq-llama-7b-w3-s0.pt&#34;&gt;sq-llama-7b-w3-s0&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-7B&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/squeeze-ai-lab/sq-llama-7b-w4-s0/blob/main/sq-llama-7b-w4-s0.pt&#34;&gt;sq-llama-7b-w4-s0&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-13B&lt;/td&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/squeeze-ai-lab/sq-llama-13b-w3-s0/blob/main/sq-llama-13b-w3-s0.pt&#34;&gt;sq-llama-13b-w3-s0&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-13B&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/squeeze-ai-lab/sq-llama-13b-w4-s0/blob/main/sq-llama-13b-w4-s0.pt&#34;&gt;sq-llama-13b-w4-s0&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-30B&lt;/td&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/squeeze-ai-lab/sq-llama-30b-w3-s0/blob/main/sq-llama-30b-w3-s0.pt&#34;&gt;sq-llama-30b-w3-s0&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-30B&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/squeeze-ai-lab/sq-llama-30b-w4-s0/blob/main/sq-llama-30b-w4-s0.pt&#34;&gt;sq-llama-30b-w4-s0&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Vicuna&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Bitwidth&lt;/th&gt; &#xA;   &lt;th&gt;Dense-only (0%)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vicuna-7B&lt;/td&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/squeeze-ai-lab/sq-vicuna-7b-w3-s0/blob/main/sq-vicuna-7b-w3-s0.pt&#34;&gt;sq-vicuna-7b-w3-s0&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vicuna-7B&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/squeeze-ai-lab/sq-vicuna-7b-w4-s0/blob/main/sq-vicuna-7b-w4-s0.pt&#34;&gt;sq-vicuna-7b-w4-s0&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vicuna-13B&lt;/td&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/squeeze-ai-lab/sq-vicuna-13b-w3-s0/blob/main/sq-vicuna-13b-w3-s0.pt&#34;&gt;sq-vicuna-13b-w3-s0&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vicuna-13B&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/squeeze-ai-lab/sq-vicuna-13b-w4-s0/blob/main/sq-vicuna-13b-w4-s0.pt&#34;&gt;sq-vicuna-13b-w4-s0&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Sparsity levels with 0.05% and 0.45% are coming soon!&lt;/p&gt; &#xA;&lt;p&gt;The LLaMA model &lt;a href=&#34;https://github.com/facebookresearch/llama/raw/main/LICENSE&#34;&gt;license&lt;/a&gt; is currently only available for research purposes. We direct everyone to carefully review the license before using the quantized models. Similar to other works on LLaMA, we only release the quantized portions of the model in &lt;a href=&#34;https://huggingface.co/squeeze-ai-lab&#34;&gt;Huggingface Model Hub&lt;/a&gt;. To successfully run our code, you need to first obtain the original, pre-trained LLaMA model in the Huggingface-compatible format locally and provide the path in the commands below. We have scripts that will substitute the necessary components, but you will need the original model for those scripts to run.&lt;/p&gt; &#xA;&lt;h3&gt;Benchmarking&lt;/h3&gt; &#xA;&lt;p&gt;The following code will run and benchmark the 3-bit quantized LLaMA-7B model on the C4 dataset. The &lt;code&gt;--torch_profile&lt;/code&gt; argument can be passed when running benchmarking to replicate the runtime results from the paper. Download the quantized model (e.g. &lt;code&gt;sq-llama-7b-w3-s0.pt&lt;/code&gt;) locally from the link above. You can follow the same procedure for other quantized models.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;CUDA_VISIBLE_DEVICES=0 python llama.py &amp;lt;path-to-llama-7b-hf&amp;gt; c4 --wbits 3 --load sq-llama-7b-w3-s0.pt --benchmark 128 --check&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Perplexity Evaluation&lt;/h3&gt; &#xA;&lt;p&gt;The following code will evaluate perplexity using the 3-bit quantized LLaMA-7B model on the C4 dataset, following the same evaluation methodology of &lt;a href=&#34;https://github.com/IST-DASLab/gptq&#34;&gt;GPTQ&lt;/a&gt; and &lt;a href=&#34;https://github.com/qwopqwop200/GPTQ-for-LLaMa/&#34;&gt;GPTQ-For-LLaMA&lt;/a&gt;. Download the quantized model (e.g. &lt;code&gt;sq-llama-7b-w3-s0.pt&lt;/code&gt;) locally from the link above. You can follow the same procedure for other quantized models.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;CUDA_VISIBLE_DEVICES=0 python llama.py &amp;lt;path-to-llama-7b-hf&amp;gt; c4 --wbits 3 --load sq-llama-7b-w3-s0.pt --eval&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The code was tested on A5000 and A6000 GPUs with Cuda 11.3 and CUDNN 8.2.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;This code reuses components from several libraries including &lt;a href=&#34;https://github.com/IST-DASLab/gptq&#34;&gt;GPTQ&lt;/a&gt; as well as &lt;a href=&#34;https://github.com/qwopqwop200/GPTQ-for-LLaMa/&#34;&gt;GPTQ-For-LLaMA&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;SqueezeLLM has been developed as part of the following paper. We appreciate it if you would please cite the following paper if you found the library useful for your work:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{kim2023squeezellm,&#xA;  title={SqueezeLLM: Dense-and-Sparse Quantization},&#xA;  author={Kim, Sehoon and Hooper, Coleman and Gholami, Amir and Dong, Zhen and Li, Xiuyu and Shen, Sheng and Mahoney, Michael and Keutzer, Kurt},&#xA;  journal={arXiv},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>