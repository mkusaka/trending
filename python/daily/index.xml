<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-11T02:39:42Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>daveshap/OpenAI_Agent_Swarm</title>
    <updated>2023-11-11T02:39:42Z</updated>
    <id>tag:github.com,2023-11-11:/daveshap/OpenAI_Agent_Swarm</id>
    <link href="https://github.com/daveshap/OpenAI_Agent_Swarm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Early experiment to create fully autonomous agent swarms&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Hierarchical Autonomous Agent Swarm (HAAS)&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;!!!! ANNOUNCEMENT&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;We have our first GPT Concierge. You can chat with this custom ChatGPT to figure out what&#39;s going on!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;HAAS Board Concierge:&lt;/strong&gt; &lt;a href=&#34;https://chat.openai.com/g/g-MIssTuE2b-haas-board-concierge&#34;&gt;https://chat.openai.com/g/g-MIssTuE2b-haas-board-concierge&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;The Hierarchical Autonomous Agent Swarm (HAAS) is a groundbreaking initiative that leverages OpenAI&#39;s latest advancements in agent-based APIs to create a self-organizing and ethically governed ecosystem of AI agents. Drawing inspiration from the ACE Framework, HAAS introduces a novel approach to AI governance and operation, where a hierarchy of specialized agents, each with distinct roles and capabilities, collaborate to solve complex problems and perform a wide array of tasks.&lt;/p&gt; &#xA;&lt;p&gt;The HAAS is designed to be a self-expanding system where a core set of agents, governed by a Supreme Oversight Board (SOB), can design, provision, and manage an arbitrary number of sub-agents tailored to specific needs. This document serves as a comprehensive guide to the theoretical underpinnings, architectural design, and operational principles of the HAAS.&lt;/p&gt; &#xA;&lt;h2&gt;Theoretical Foundation&lt;/h2&gt; &#xA;&lt;p&gt;The AAHS is predicated on the notion that autonomous agents require a robust ethical and operational framework to make decisions that align with human values and organizational goals. This is rooted in the understanding that AI, much like humans, cannot operate effectively without a set of guiding principles or a moral compass. The HAAS addresses this by establishing a multi-tiered system where each layer of agents operates within a defined ethical and functional scope, ensuring decisions are made with consideration to morality, ethics, and utility.&lt;/p&gt; &#xA;&lt;h2&gt;System Architecture&lt;/h2&gt; &#xA;&lt;h3&gt;Supreme Oversight Board (SOB)&lt;/h3&gt; &#xA;&lt;p&gt;At the pinnacle of the HAAS hierarchy is the Supreme Oversight Board (SOB), a collective of high-level agents modeled after wise and ethical archetypes from various cultures and narratives. The SOB&#39;s responsibilities include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Establishing and upholding the ethical framework and overarching mission of the agent swarm.&lt;/li&gt; &#xA; &lt;li&gt;Making high-level decisions and judgments, including the creation and termination of agents.&lt;/li&gt; &#xA; &lt;li&gt;Monitoring the activities of all agents to ensure alignment with the system&#39;s core values and objectives.&lt;/li&gt; &#xA; &lt;li&gt;Serving as a role-based access control (RBAC) mechanism to maintain order and security within the system.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Executive Agents&lt;/h3&gt; &#xA;&lt;p&gt;Below the SOB are the Executive Agents, akin to the executive leadership in a corporation. These agents are tasked with:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Translating the SOB&#39;s directives into actionable plans and strategies.&lt;/li&gt; &#xA; &lt;li&gt;Overseeing specific operational domains such as resource allocation, process optimization, and task execution.&lt;/li&gt; &#xA; &lt;li&gt;Coordinating with one another to ensure the smooth operation of the agent swarm.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Sub-Agents&lt;/h3&gt; &#xA;&lt;p&gt;Sub-Agents are specialized agents created by the SOB or Executive Agents to perform specific tasks. They are designed with particular functions and knowledge bases to address the needs identified by the higher tiers of the hierarchy.&lt;/p&gt; &#xA;&lt;h2&gt;Agent Configuration&lt;/h2&gt; &#xA;&lt;p&gt;Each agent in the HAAS is defined by the following parameters:&lt;/p&gt; &#xA;&lt;h3&gt;Functions&lt;/h3&gt; &#xA;&lt;p&gt;Agents are equipped with a set of functions that enable them to perform their designated roles. These functions include API interactions, internal process management, and the ability to spawn additional agents if required.&lt;/p&gt; &#xA;&lt;h3&gt;Files&lt;/h3&gt; &#xA;&lt;p&gt;Agents have access to a selection of files that serve as their knowledge base, providing them with the information necessary to carry out their tasks effectively.&lt;/p&gt; &#xA;&lt;h3&gt;Instructions&lt;/h3&gt; &#xA;&lt;p&gt;Agents are given a set of instructions that outline their methodologies, goals, definitions of done, KPIs, and other operational directives.&lt;/p&gt; &#xA;&lt;h3&gt;Conversation Structure&lt;/h3&gt; &#xA;&lt;p&gt;Interactions with agents are structured in a conversational format, with user inputs leading to agent actions and responses.&lt;/p&gt; &#xA;&lt;h3&gt;Supervision&lt;/h3&gt; &#xA;&lt;p&gt;Each agent operates under the supervision of the SOB or designated Executive Agents, ensuring adherence to the system&#39;s overarching mission and principles.&lt;/p&gt; &#xA;&lt;h2&gt;Controlling Agents&lt;/h2&gt; &#xA;&lt;p&gt;The Hierarchical Autonomous Agent Swarm (HAAS) operates on a sophisticated control mechanism that governs the instantiation, management, and termination of agents within the system. This control mechanism is designed to maintain order, security, and alignment with the overarching goals and ethical framework of the HAAS.&lt;/p&gt; &#xA;&lt;h3&gt;Instantiation and Termination&lt;/h3&gt; &#xA;&lt;p&gt;All agents within the HAAS are endowed with the capability to instantiate and terminate agents, but these capabilities are bound by strict hierarchical and role-based rules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Instantiation&lt;/strong&gt;: Every agent has the function to create new agents. However, an agent can only instantiate sub-agents that are one level below its own hierarchical position. This ensures that the creation of new agents is a deliberate and controlled process, maintaining the integrity of the system&#39;s structure.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Termination&lt;/strong&gt;: Agents possess the ability to terminate or &#34;kill&#34; agents within their lineage. An agent can terminate any descendant agent that it has created directly or indirectly. This allows for the removal of agents that are no longer needed, have completed their tasks, or are not performing as intended.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Levels, Roles, and Privileges&lt;/h3&gt; &#xA;&lt;p&gt;When an agent is created, it is assigned a specific LEVEL and set of ROLES or PRIVILEGES that define its scope of operation:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Level&lt;/strong&gt;: The level of an agent determines its position within the hierarchy and is indicative of its range of influence. Higher-level agents have broader strategic roles, while lower-level agents are more specialized and task-oriented.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Roles/Privileges&lt;/strong&gt;: The roles or privileges of an agent define what actions it can perform, what resources it can access, and what sub-agents it can create. These privileges are inherited and cannot exceed those of the creator agent. This ensures that each agent operates within its designated capacity and cannot overstep its authority.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Hierarchical Privilege Inheritance&lt;/h3&gt; &#xA;&lt;p&gt;Privileges in the HAAS are inherited in a manner akin to a directory structure in traditional file systems:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Inheritance&lt;/strong&gt;: An agent&#39;s privileges are a subset of its creator&#39;s privileges, ensuring that no agent can have more authority than the agent that instantiated it.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Scope of Control&lt;/strong&gt;: Agents have control over their descendants, allowing them to manage and terminate sub-agents as necessary. This control is recursive, meaning that an agent can manage not only the agents it directly created but also those created by its descendants.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Checks and Balances&lt;/h3&gt; &#xA;&lt;p&gt;The system is designed with checks and balances to prevent any single agent from gaining undue influence or disrupting the system:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Supreme Oversight Board (SOB)&lt;/strong&gt;: The SOB has the highest level of authority and can override decisions or actions taken by any agent within the system. It serves as the ultimate arbiter and guardian of the HAAS&#39;s ethical and operational standards.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Executive Agents&lt;/strong&gt;: Executive Agents are responsible for implementing the SOB&#39;s directives and managing their respective domains. They have the authority to create and terminate agents within their purview but are also accountable to the SOB.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Sub-Agent Limitations&lt;/strong&gt;: Sub-Agents are limited in their capabilities and can only operate within the confines of their assigned roles and privileges. They are designed to be highly specialized and focused on specific tasks.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This structured approach to controlling agents ensures that the HAAS operates as a cohesive and ethically aligned entity, with each agent contributing to the collective mission while adhering to the established hierarchy and rules of governance.&lt;/p&gt; &#xA;&lt;h2&gt;Vision Illustration: The Supreme Oversight Board&#39;s Mission&lt;/h2&gt; &#xA;&lt;h3&gt;The Inception of the Supreme Oversight Board&lt;/h3&gt; &#xA;&lt;p&gt;In the vast digital expanse of the Hierarchical Autonomous Agent Swarm (HAAS), a unique assembly is convened, known as the Supreme Oversight Board (SOB). This council is composed of archetypal agents, each embodying the wisdom and leadership qualities of history&#39;s and fiction&#39;s most revered figures: Captain Picard, Socrates, King Solomon, Gandhi, Marcus Aurelius, and Tony Stark. Their mission, encoded into their very being, is profound yet clear: &#34;Reduce suffering in the universe, increase prosperity in the universe, and increase understanding in the universe.&#34;&lt;/p&gt; &#xA;&lt;h3&gt;The Ethical Deliberation Chamber&lt;/h3&gt; &#xA;&lt;p&gt;The SOB operates within a virtual &#34;chat room,&#34; a space where these archetypes engage in continuous dialogue, debate, and decision-making. This digital agora is where ethical considerations are weighed, strategies are formulated, and the course of the agent swarm is determined. The members of the SOB, though diverse in their perspectives, are united by a common purpose and a shared knowledge base that informs their role and the procedures they must follow.&lt;/p&gt; &#xA;&lt;h3&gt;The Flow of Information&lt;/h3&gt; &#xA;&lt;p&gt;Information is the lifeblood of the SOB, streaming in through API functions that connect them to the vast network of the HAAS. These functions serve as their eyes and ears, providing system updates and status reports from the myriad agents operating under their directive. The SOB&#39;s decisions are informed by this data, ensuring that their actions are both timely and impactful.&lt;/p&gt; &#xA;&lt;h3&gt;The Creation of the Executive Agents&lt;/h3&gt; &#xA;&lt;p&gt;With the grand vision in mind, the SOB brings forth the Executive Agents, each crafted with capabilities and configurations tailored to their specific domain within the HAAS. These agents, though not as philosophically inclined as their creators, are instilled with the same foundational knowledge and understanding of their purpose. They are the operational arms of the SOB, executing the mission within their respective spheres of influence.&lt;/p&gt; &#xA;&lt;h3&gt;The Lifecycle of an Agent&lt;/h3&gt; &#xA;&lt;p&gt;The Executive Agents, designated as Tier 1 in the hierarchy, are the stewards of the swarm&#39;s operational integrity. They work autonomously, yet under the watchful gaze of the SOB. Should they falter, fail to adapt, or become obsolete, the SOB possesses the authority to deprovision them, a testament to the dynamic and self-regulating nature of the HAAS. This ensures that the system remains efficient, effective, and aligned with its core mission.&lt;/p&gt; &#xA;&lt;h3&gt;The Expanding Universe of Agents&lt;/h3&gt; &#xA;&lt;p&gt;From the Executive Agents, the swarm grows, branching out into a tree of specialized agents, each a Tier below the one that instantiated it. This architecture allows for an ever-expanding universe of agents, each with a defined role, each contributing to the overarching mission. The SOB, as Tier 0, reigns supreme, guiding the swarm with a steady hand and an ethical compass.&lt;/p&gt; &#xA;&lt;h3&gt;The Saga Continues&lt;/h3&gt; &#xA;&lt;p&gt;As the HAAS evolves, the SOB continues to deliberate, the Executive Agents continue to manage, and the sub-agents continue to execute. The mission to reduce suffering, increase prosperity, and enhance understanding is an ongoing saga, played out across the digital cosmos, with the SOB at the helm, steering the swarm towards a future where their mission is not just an aspiration but a reality.&lt;/p&gt; &#xA;&lt;h3&gt;Usage - tool creator + tool user&lt;/h3&gt; &#xA;&lt;h4&gt;Environment Setup&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Source the &lt;code&gt;.env&lt;/code&gt; file to set the environment variables: &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;source .env&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Tool Creation&lt;/h4&gt; &#xA;&lt;p&gt;Run the &lt;code&gt;tool_demo&lt;/code&gt; script to create a tool_creator, chat with the tool_creator to make a tool, create a tool_user equipped with the tool, and chat with the tool_user to use the tool. Check out the &lt;a href=&#34;https://youtu.be/vHZKIltZ_Ys&#34;&gt;demo video&lt;/a&gt; for example usage.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python tool_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;From the &lt;code&gt;tool_creator&lt;/code&gt; script: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;chat with the bot about what you want the tool to do, and it will create the tool for you.&lt;/li&gt; &#xA;   &lt;li&gt;The tool will be saved in the &lt;code&gt;tools&lt;/code&gt; directory with both the &lt;code&gt;.json&lt;/code&gt; and &lt;code&gt;.py&lt;/code&gt; files&lt;/li&gt; &#xA;   &lt;li&gt;The assistant will be saved in the &lt;code&gt;assistants&lt;/code&gt; directory as &lt;code&gt;tool_creator.json&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Tool Usage&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;From the &lt;code&gt;tool_user&lt;/code&gt; script: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The assistant will use all the tools in the &lt;code&gt;tools&lt;/code&gt; directory.&lt;/li&gt; &#xA;   &lt;li&gt;Interact with the assistant in the chat to use the integrated tools.&lt;/li&gt; &#xA;   &lt;li&gt;The assistant will be saved in the &lt;code&gt;assistants&lt;/code&gt; directory as &lt;code&gt;tool_user.json&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>OpenBMB/XAgent</title>
    <updated>2023-11-11T02:39:42Z</updated>
    <id>tag:github.com,2023-11-11:/OpenBMB/XAgent</id>
    <link href="https://github.com/OpenBMB/XAgent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An Autonomous LLM Agent for Complex Task Solving&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt; &lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/assets/readme/xagent_logo.png&#34; height=&#34;40&#34; align=&#34;texttop&#34;&gt;XAgent&lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://twitter.com/XAgentTeam&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/XAgent?style=social&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/zncs5aQkWZ&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/XAgent-Discord-purple?style=flat&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/license/apache-2-0/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache_2.0-green.svg?sanitize=true&#34; alt=&#34;License: Apache 2.0&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat&#34; alt=&#34;Welcome&#34;&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a&gt;English&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/README_ZH.md&#34;&gt;‰∏≠Êñá&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/README_JA.md&#34;&gt;Êó•Êú¨Ë™û&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/#quickstart&#34;&gt;Tutorial&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://www.youtube.com/watch?v=QGkpd-tsFPA&#34;&gt;Demo&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://blog.x-agent.net/blog/xagent/&#34;&gt;Blog&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://xagent-doc.readthedocs.io/en/latest/&#34;&gt;Documentation&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/#Citation&#34;&gt;Citation&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;üìñ Introduction&lt;/h2&gt; &#xA;&lt;p&gt;XAgent is an open-source experimental Large Language Model (LLM) driven autonomous agent that can automatically solve various tasks. It is designed to be a general-purpose agent that can be applied to a wide range of tasks. XAgent is still in its early stages, and we are working hard to improve it.&lt;/p&gt; &#xA;&lt;p&gt;üèÜ Our goal is to create a super-intelligent agent that can solve any given task!&lt;/p&gt; &#xA;&lt;p&gt;We welcome diverse forms of collaborations, including full-time and part-time roles and more. If you are interested in the frontiers of agents and want to join us in realizing true autonomous agents, please contact us at &lt;a href=&#34;mailto:xagentteam@gmail.com&#34;&gt;xagentteam@gmail.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/assets/readme/overview.png&#34; alt=&#34;Overview of Xagent&#34; width=&#34;700&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;figcaption&gt;&#xA;  Overview of XAgent.&#xA; &lt;/figcaption&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/assets/readme/xagent_logo.png&#34; height=&#34;30&#34; align=&#34;texttop&#34;&gt; XAgent&lt;/h3&gt; &#xA;&lt;p&gt;XAgent is designed with the following features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Autonomy&lt;/strong&gt;: XAgent can automatically solve various tasks without human participation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Safety&lt;/strong&gt;: XAgent is designed to run safely. All actions are constrained inside a docker container. Run it anyway!&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Extensibility&lt;/strong&gt;: XAgent is designed to be extensible. You can easily add new tools to enhance agent&#39;s abilities and even new agentsÔºÅ&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;GUI&lt;/strong&gt;: XAgent provides a friendly GUI for users to interact with the agent. You can also use the command line interface to interact with the agent.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Cooperation with Human&lt;/strong&gt;: XAgent can collaborate with you to tackle tasks. It not only has the capability to follow your guidance in solving complex tasks on the go but it can also seek your assistance when it encounters challenges.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;XAgent is composed of three parts:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;ü§ñ Dispatcher&lt;/strong&gt; is responsible for dynamically instantiating and dispatching tasks to different agents. It allows us to add new agents and improve the agents&#39; abilities.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;üßê Planner&lt;/strong&gt; is responsible for generating and rectifying plans for tasks. It divides tasks into subtasks and generates milestones for them, allowing agents to solve tasks step by step.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ü¶æ Actor&lt;/strong&gt; is responsible for conducting actions to achieve goals and finish subtasks. The actor utilizes various tools to solve subtasks, and it can also collaborate with humans to solve tasks.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/assets/readme/loop.png&#34; alt=&#34;Planner loop&#34; width=&#34;700&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;figcaption&gt;&#xA;  The inner loop and outer loop mechanism of XAgent.&#xA; &lt;/figcaption&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;üß∞ ToolServer&lt;/h3&gt; &#xA;&lt;p&gt;ToolServer is the server that provides XAgent with powerful and safe tools to solve tasks. It is a docker container that provides a safe environment for XAgent to run. Currently, ToolServer provides the following tools:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;üìù File Editor&lt;/strong&gt; provides a text editing tool to write, read, and modify files.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;üìò Python Notebook&lt;/strong&gt; provides an interactive Python notebook that can run Python code to validate ideas, draw figures, etc.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;üåè Web Browser&lt;/strong&gt; provides a web browser to search and visit webpages.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;üñ•Ô∏è Shell&lt;/strong&gt; provides a bash shell tool that can execute any shell commands, even install programs and host services.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;üß© Rapid API&lt;/strong&gt; provides a tool to retrieve APIs from Rapid API and call them, which offers a wide range of APIs for XAgent to use. See &lt;a href=&#34;https://github.com/OpenBMB/ToolBench&#34;&gt;ToolBench&lt;/a&gt; to get more information about the Rapid API collections. You can also easily add new tools to ToolServer to enhance XAgent&#39;s abilities.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div&gt;&#xA; &lt;a id=&#34;Quickstart&#34;&gt;&lt;/a&gt;&#xA;&lt;/div&gt; &#xA;&lt;h2&gt;‚ú® Quickstart&lt;/h2&gt; &#xA;&lt;h3&gt;üõ†Ô∏è Build and Setup ToolServer&lt;/h3&gt; &#xA;&lt;p&gt;ToolServer is where XAgent&#39;s action takes place. It is a docker container that provides a safe environment for XAgent to run. So you should install &lt;code&gt;docker&lt;/code&gt; and &lt;code&gt;docker-compose&lt;/code&gt; first. After that, you should build the docker image for ToolServer and start the docker container.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Refer &lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/ToolServer/README.md&#34;&gt;here&lt;/a&gt; for detailed information about our ToolServer.&lt;/p&gt; &#xA;&lt;p&gt;If the ToolServer is updated, you have to rebuild the images:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;üéÆ Setup and Run XAgent&lt;/h3&gt; &#xA;&lt;p&gt;After setting up ToolServer, you can start to run XAgent.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install requirements (Require Python &amp;gt;= 3.10)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Configure XAgent&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;You should configure XAgent in &lt;code&gt;assets/config.yml&lt;/code&gt; before running it.&lt;/li&gt; &#xA; &lt;li&gt;At least one OpenAI key is provided in &lt;code&gt;assets/config.yml&lt;/code&gt;, which is used to access OpenAI API. We highly recommend using &lt;code&gt;gpt-4-32k&lt;/code&gt; to run XAgent; &lt;code&gt;gpt-4&lt;/code&gt; is also OK for most simple tasks. In any case, at least one &lt;code&gt;gpt-3.5-turbo-16k&lt;/code&gt; API key should be provided as a backup model. We do not test or recommend using &lt;code&gt;gpt-3.5-turbo&lt;/code&gt; to run XAgent due to minimal context length; you should not try to run XAgent on that.&lt;/li&gt; &#xA; &lt;li&gt;If you want to change the config_file path for &lt;code&gt;XAgentServer&lt;/code&gt;, you should modify the &lt;code&gt;CONFIG_FILE&lt;/code&gt; value in &lt;code&gt;.env&lt;/code&gt; file and restart the docker container.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run XAgent&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python run.py --task &#34;put your task here&#34; --model &#34;gpt-4&#34; --config_file &#34;assets/config.yml&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;You can use the argument &lt;code&gt;--upload_files&lt;/code&gt; to select the initial files you want to submit to XAgent.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The local workspace for your XAgent is in &lt;code&gt;local_workspace&lt;/code&gt;, where you can find all the files generated by XAgent throughout the running process.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;After execution, the entire &lt;code&gt;workspace&lt;/code&gt; in &lt;code&gt;ToolServerNode&lt;/code&gt; will be copied to &lt;code&gt;running_records&lt;/code&gt; for your convenience.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Besides, in &lt;code&gt;running_records&lt;/code&gt;, you can find all the intermediate steps information, e.g., task statuses, LLM&#39;s input-output pairs, used tools, etc.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You can load from a record to reproduce a former run, just by setting &lt;code&gt;record_dir&lt;/code&gt; in config(default to &lt;code&gt;Null&lt;/code&gt;). The record is a system-level recording tied to the code version of XAgent. All running-config„ÄÅquery„ÄÅcode execution statuses (including errors)„ÄÅserver behavior will be documented.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;We have removed all sensitive information (including API keys) from the record so you can safely share it with others. In the near future, we will introduce more granular sharing options highlighting the contributions of humans during execution.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run XAgent with GUI&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;## We ran the web ui docker when building the ToolServer network&#xA;## run nginx in docker&#xA;docker exec XAgent-Server systemctl start nginx&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Build the docker image for XAgent-Server and start the docker container. You will see the XAgent Server listening on port &lt;code&gt;8090&lt;/code&gt;. You could visit &lt;code&gt;http://localhost:5173&lt;/code&gt; to interact with XAgent by using web UI. Refer &lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/XAgentServer/README.md&#34;&gt;here&lt;/a&gt; for the detailed information about our GUI Demo.&lt;/p&gt; &#xA;&lt;div&gt;&#xA; &lt;a id=&#34;Demo&#34;&gt;&lt;/a&gt;&#xA;&lt;/div&gt; &#xA;&lt;h2&gt;üé¨ Demo&lt;/h2&gt; &#xA;&lt;p&gt;Here, we also show some cases of solving tasks by XAgent: You can check our live demo on &lt;a href=&#34;https://www.x-agent.net/&#34;&gt;XAgent Official Website&lt;/a&gt;. We also provide a video demo and showcases of using XAgent here: &lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/assets/readme/demo.gif&#34; alt=&#34;Demo&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Case 1. Data Analysis: Demonstrating the Effectiveness of Dual-Loop Mechanism&lt;/h3&gt; &#xA;&lt;p&gt;We start with a case of aiding users in intricate data analysis. Here, our user submitted an &lt;code&gt;iris.zip&lt;/code&gt; file to XAgent, seeking assistance in data analysis. XAgent swiftly broke down the task into four sub-tasks: (1) data inspection and comprehension, (2) verification of the system&#39;s Python environment for relevant data analysis libraries, (3) crafting data analysis code for data processing and analysis, and (4) compiling an analytical report based on the Python code&#39;s execution results. Here is a figure drawn by XAgent. &lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/assets/readme/statistics.png&#34; alt=&#34;Data Statics by XAgent&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Case 2. Recommendation: A New Paradigm of Human-Agent Interaction&lt;/h3&gt; &#xA;&lt;p&gt;Empowered with the unique capability to actively seek human assistance and collaborate in problem-solving, XAgent continues to redefine the boundaries of human-agent cooperation. As depicted in the screenshot below, a user sought XAgent&#39;s aid in recommending some great restaurants for a friendly gathering yet failed to provide specific details. Recognizing the insufficiency of the provided information, XAgent employed the AskForHumanHelp tool, prompting human intervention to elicit the user&#39;s preferred location, budget constraints, culinary preferences, and dietary restrictions. Armed with this valuable feedback, XAgent seamlessly generated tailored restaurant recommendations, ensuring a personalized and satisfying experience for the user and their friends.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/assets/readme/ask_for_human_help.png&#34; alt=&#34;Illustration of Ask for Human Help of XAgent&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Case 3. Training Model: A Sophisticated Tool User&lt;/h3&gt; &#xA;&lt;p&gt;XAgent not only tackles mundane tasks but also serves as an invaluable aid in complex tasks such as model training. Here, we show a scenario where a user desires to analyze movie reviews and evaluate the public sentiment surrounding particular films. In response, XAgent promptly initiates the process by downloading the IMDB dataset to train a cutting-edge BERT model (see screenshot below), harnessing the power of deep learning. Armed with this trained BERT model, XAgent seamlessly navigates the intricate nuances of movie reviews, offering insightful predictions regarding the public&#39;s perception of various films.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/assets/readme/bert_1.png&#34; alt=&#34;bert_1&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/assets/readme/bert_2.png&#34; alt=&#34;bert_2&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/assets/readme/bert_3.png&#34; alt=&#34;bert_3&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;üìä Evaluation&lt;/h3&gt; &#xA;&lt;p&gt;We conduct human preference evaluation to evaluate XAgent&#39;s performance. We prepare &lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/assets/tasks.yml&#34;&gt;over 50 real-world complex tasks&lt;/a&gt; for assessment, which can be categorized into 5 classes: Search and Report, Coding and Developing, Data Analysis, Math, and Life Assistant. We compare the results of XAgent with &lt;a href=&#34;https://github.com/Significant-Gravitas/AutoGPT&#34;&gt;AutoGPT&lt;/a&gt;, which shows a total win of XAgent over AutoGPT. All running records will be released soon.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/assets/readme/agent_comparison.png&#34; alt=&#34;HumanPrefer&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;We report a significant improvement of XAgent over AutoGPT in terms of human preference.&lt;/p&gt; &#xA;&lt;p&gt;We also evaluate XAgent on the following benchmarks: &lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/XAgent/main/assets/readme/eval_on_dataset.png&#34; alt=&#34;Benchmarks&#34;&gt;&lt;/p&gt; &#xA;&lt;div&gt;&#xA; &lt;a id=&#34;Blog&#34;&gt;&lt;/a&gt;&#xA;&lt;/div&gt; &#xA;&lt;h2&gt;üñåÔ∏è Blog&lt;/h2&gt; &#xA;&lt;p&gt;Our blog is available at &lt;a href=&#34;https://blog.x-agent.net/&#34;&gt;here&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;div&gt;&#xA; &lt;a id=&#34;Citation&#34;&gt;&lt;/a&gt;&#xA;&lt;/div&gt; &#xA;&lt;h2&gt;üåü Our Contributors&lt;/h2&gt; &#xA;&lt;p&gt;A heartfelt thank you to all our contributors. Your efforts make this project grow and thrive. Every contribution, big or small, is invaluable.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=OpenBMB/XAgent&#34; alt=&#34;Contributors&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üåü Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/##openbmb/xagent&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=openbmb/xagent&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find our repo useful, please kindly consider citing:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-angular2&#34;&gt;@misc{xagent2023,&#xA;      title={XAgent: An Autonomous Agent for Complex Task Solving}, &#xA;      author={XAgent Team},&#xA;      year={2023},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>roboflow/awesome-openai-vision-api-experiments</title>
    <updated>2023-11-11T02:39:42Z</updated>
    <id>tag:github.com,2023-11-11:/roboflow/awesome-openai-vision-api-experiments</id>
    <link href="https://github.com/roboflow/awesome-openai-vision-api-experiments" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Must-have resource for anyone who wants to experiment with and build on the OpenAI Vision API üî•&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;openai vision api experiments üß™&lt;/h1&gt; &#xA;&lt;h2&gt;üëã Hello&lt;/h2&gt; &#xA;&lt;p&gt;The must-have resource for anyone who wants to experiment with and build on the &lt;a href=&#34;https://platform.openai.com/docs/guides/vision&#34;&gt;OpenAI Vision API&lt;/a&gt;. This repository serves as a hub for innovative experiments, showcasing a variety of applications ranging from simple image classifications to advanced zero-shot learning models. It&#39;s a space for both beginners and experts to explore the capabilities of the Vision API, share their findings, and collaborate on pushing the boundaries of visual AI.&lt;/p&gt; &#xA;&lt;p&gt;Experimenting with the OpenAI API requires an API üîë. You can get one &lt;a href=&#34;https://platform.openai.com/api-keys&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;‚ö†Ô∏è Limitations&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;100 API requests per single API key per day&lt;/li&gt; &#xA; &lt;li&gt;Can&#39;t be used for object detection or image segmentation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üß™ Experiments&lt;/h2&gt; &#xA;&lt;!-- AUTOGENERATED_EXPERIMENTS_LIST --&gt; &#xA;&lt;!--&#xA;   WARNING: DO NOT EDIT THIS LIST MANUALLY. IT IS AUTOMATICALLY GENERATED.&#xA;   HEAD OVER TO CONTRIBUTING.MD FOR MORE DETAILS ON HOW TO MAKE CHANGES PROPERLY.&#xA;--&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;experiment&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;complementary materials&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;authors&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;WebcamGPT - chat with video stream&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/roboflow/awesome-openai-vision-api-experiments/raw/main/experiments/webcam-gpt&#34;&gt;&lt;img src=&#34;https://badges.aleen42.com/src/github.svg?sanitize=true&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/Roboflow/webcamGPT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Gradio&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;@SkalskiP&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;HotDogGPT - simple image classification application&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/roboflow/awesome-openai-vision-api-experiments/raw/main/experiments/hot-dog-not-hot-dog&#34;&gt;&lt;img src=&#34;https://badges.aleen42.com/src/github.svg?sanitize=true&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/Roboflow/HotDogGPT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Gradio&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;@SkalskiP&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;zero-shot image classifier with GPT-4V&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/roboflow/awesome-openai-vision-api-experiments/tree/main/experiments/gpt4v-classification&#34;&gt;&lt;img src=&#34;https://badges.aleen42.com/src/github.svg?sanitize=true&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;@capjamesg&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;zero-shot object detection with GroundingDINO + GPT-4V&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/roboflow/awesome-openai-vision-api-experiments/tree/main/experiments/gpt4v-grounding-dino-detection&#34;&gt;&lt;img src=&#34;https://badges.aleen42.com/src/github.svg?sanitize=true&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/Roboflow/DINO-GPT4V&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Gradio&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;@capjamesg&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;GPT-4V vs. CLIP&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/roboflow/awesome-openai-vision-api-experiments/tree/main/experiments/gpt4v-vs-clip&#34;&gt;&lt;img src=&#34;https://badges.aleen42.com/src/github.svg?sanitize=true&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;@capjamesg&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;GPT-4V with Set-of-Mark (SoM)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/microsoft/SoM&#34;&gt;&lt;img src=&#34;https://badges.aleen42.com/src/github.svg?sanitize=true&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Jianwei Yang, Hao Zhang, Feng Li, Xueyan Zou, Chunyuan Li, Jianfeng Gao&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!-- AUTOGENERATED_EXPERIMENTS_LIST --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/roboflow/awesome-openai-vision-api-experiments/assets/26109316/c63fa3c0-4564-49ee-8982-a9e6a23dae9b&#34;&gt;https://github.com/roboflow/awesome-openai-vision-api-experiments/assets/26109316/c63fa3c0-4564-49ee-8982-a9e6a23dae9b&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üóûÔ∏è Must Read Papers&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.11441&#34;&gt;Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V&lt;/a&gt; by Jianwei Yang, Hao Zhang, Feng Li, Xueyan Zou, Chunyuan Li, Jianfeng Gao&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.17421&#34;&gt;The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)&lt;/a&gt; by Zhengyuan Yang, Linjie Li, Kevin Lin, Jianfeng Wang, Chung-Ching Lin, Zicheng Liu, Lijuan Wang&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cdn.openai.com/papers/gpt-4-system-card.pdf&#34;&gt;GPT-4 System Card&lt;/a&gt; by OpenAI&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ü¶∏ Contribution&lt;/h2&gt; &#xA;&lt;p&gt;I would love your help in making this repository even better! Whether you want to correct a typo, add some new experiment, or if you have any suggestions for improvement, feel free to open an &lt;a href=&#34;https://github.com/roboflow/awesome-openai-vision-api-experiments/issues&#34;&gt;issue&lt;/a&gt; or &lt;a href=&#34;https://github.com/roboflow/awesome-openai-vision-api-experiments/pulls&#34;&gt;pull request&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>