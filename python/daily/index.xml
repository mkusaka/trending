<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-02-18T01:37:42Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>cocktailpeanut/fluxgym</title>
    <updated>2025-02-18T01:37:42Z</updated>
    <id>tag:github.com,2025-02-18:/cocktailpeanut/fluxgym</id>
    <link href="https://github.com/cocktailpeanut/fluxgym" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Dead simple FLUX LoRA training UI with LOW VRAM support&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Flux Gym&lt;/h1&gt; &#xA;&lt;p&gt;Dead simple web UI for training FLUX LoRA &lt;strong&gt;with LOW VRAM (12GB/16GB/20GB) support.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Frontend:&lt;/strong&gt; The WebUI forked from &lt;a href=&#34;https://github.com/ostris/ai-toolkit&#34;&gt;AI-Toolkit&lt;/a&gt; (Gradio UI created by &lt;a href=&#34;https://x.com/multimodalart&#34;&gt;https://x.com/multimodalart&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Backend:&lt;/strong&gt; The Training script powered by &lt;a href=&#34;https://github.com/kohya-ss/sd-scripts&#34;&gt;Kohya Scripts&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;FluxGym supports 100% of Kohya sd-scripts features through an &lt;a href=&#34;https://raw.githubusercontent.com/cocktailpeanut/fluxgym/main/#advanced&#34;&gt;Advanced&lt;/a&gt; tab, which is hidden by default.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cocktailpeanut/fluxgym/main/screenshot.png&#34; alt=&#34;screenshot.png&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;What is this?&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;I wanted a super simple UI for training Flux LoRAs&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://github.com/ostris/ai-toolkit&#34;&gt;AI-Toolkit&lt;/a&gt; project is great, and the gradio UI contribution by &lt;a href=&#34;https://x.com/multimodalart&#34;&gt;@multimodalart&lt;/a&gt; is perfect, but the project only works for 24GB VRAM.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kohya-ss/sd-scripts&#34;&gt;Kohya Scripts&lt;/a&gt; are very flexible and powerful for training FLUX, but you need to run in terminal.&lt;/li&gt; &#xA; &lt;li&gt;What if you could have the simplicity of AI-Toolkit WebUI and the flexibility of Kohya Scripts?&lt;/li&gt; &#xA; &lt;li&gt;Flux Gym was born. Supports 12GB, 16GB, 20GB VRAMs, and extensible since it uses Kohya Scripts underneath.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;News&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;September 25: Docker support + Autodownload Models (No need to manually download models when setting up) + Support custom base models (not just flux-dev but anything, just need to include in the &lt;a href=&#34;https://raw.githubusercontent.com/cocktailpeanut/fluxgym/main/models.yaml&#34;&gt;models.yaml&lt;/a&gt; file.&lt;/li&gt; &#xA; &lt;li&gt;September 16: Added &#34;Publish to Huggingface&#34; + 100% Kohya sd-scripts feature support: &lt;a href=&#34;https://x.com/cocktailpeanut/status/1835719701172756592&#34;&gt;https://x.com/cocktailpeanut/status/1835719701172756592&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;September 11: Automatic Sample Image Generation + Custom Resolution: &lt;a href=&#34;https://x.com/cocktailpeanut/status/1833881392482066638&#34;&gt;https://x.com/cocktailpeanut/status/1833881392482066638&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Supported Models&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Flux1-dev&lt;/li&gt; &#xA; &lt;li&gt;Flux1-dev2pro (as explained here: &lt;a href=&#34;https://medium.com/@zhiwangshi28/why-flux-lora-so-hard-to-train-and-how-to-overcome-it-a0c70bc59eaf&#34;&gt;https://medium.com/@zhiwangshi28/why-flux-lora-so-hard-to-train-and-how-to-overcome-it-a0c70bc59eaf&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Flux1-schnell (Couldn&#39;t get high quality results, so not really recommended, but feel free to experiment with it)&lt;/li&gt; &#xA; &lt;li&gt;More?&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The models are automatically downloaded when you start training with the model selected.&lt;/p&gt; &#xA;&lt;p&gt;You can easily add more to the supported models list by editing the &lt;a href=&#34;https://raw.githubusercontent.com/cocktailpeanut/fluxgym/main/models.yaml&#34;&gt;models.yaml&lt;/a&gt; file. If you want to share some interesting base models, please send a PR.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;How people are using Fluxgym&lt;/h1&gt; &#xA;&lt;p&gt;Here are people using Fluxgym to locally train Lora sharing their experience:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/fluxgym&#34;&gt;https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/fluxgym&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;More Info&lt;/h1&gt; &#xA;&lt;p&gt;To learn more, check out this X thread: &lt;a href=&#34;https://x.com/cocktailpeanut/status/1832084951115972653&#34;&gt;https://x.com/cocktailpeanut/status/1832084951115972653&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Install&lt;/h1&gt; &#xA;&lt;h2&gt;1. One-Click Install&lt;/h2&gt; &#xA;&lt;p&gt;You can automatically install and launch everything locally with Pinokio 1-click launcher: &lt;a href=&#34;https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/fluxgym&#34;&gt;https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/fluxgym&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;2. Install Manually&lt;/h2&gt; &#xA;&lt;p&gt;First clone Fluxgym and kohya-ss/sd-scripts:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/cocktailpeanut/fluxgym&#xA;cd fluxgym&#xA;git clone -b sd3 https://github.com/kohya-ss/sd-scripts&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Your folder structure will look like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;/fluxgym&#xA;  app.py&#xA;  requirements.txt&#xA;  /sd-scripts&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now activate a venv from the root &lt;code&gt;fluxgym&lt;/code&gt; folder:&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re on Windows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m venv env&#xA;env\Scripts\activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If your&#39;re on Linux:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m venv env&#xA;source env/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will create an &lt;code&gt;env&lt;/code&gt; folder right below the &lt;code&gt;fluxgym&lt;/code&gt; folder:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;/fluxgym&#xA;  app.py&#xA;  requirements.txt&#xA;  /sd-scripts&#xA;  /env&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now go to the &lt;code&gt;sd-scripts&lt;/code&gt; folder and install dependencies to the activated environment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd sd-scripts&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now come back to the root folder and install the app dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd ..&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, install pytorch Nightly:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Start&lt;/h1&gt; &#xA;&lt;p&gt;Go back to the root &lt;code&gt;fluxgym&lt;/code&gt; folder, with the venv activated, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Make sure to have the venv activated before running &lt;code&gt;python app.py&lt;/code&gt;.&lt;/p&gt; &#xA; &lt;p&gt;Windows: &lt;code&gt;env/Scripts/activate&lt;/code&gt; Linux: &lt;code&gt;source env/bin/activate&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;3. Install via Docker&lt;/h2&gt; &#xA;&lt;p&gt;First clone Fluxgym and kohya-ss/sd-scripts:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/cocktailpeanut/fluxgym&#xA;cd fluxgym&#xA;git clone -b sd3 https://github.com/kohya-ss/sd-scripts&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Check your &lt;code&gt;user id&lt;/code&gt; and &lt;code&gt;group id&lt;/code&gt; and change it if it&#39;s not 1000 via &lt;code&gt;environment variables&lt;/code&gt; of &lt;code&gt;PUID&lt;/code&gt; and &lt;code&gt;PGID&lt;/code&gt;. You can find out what these are in linux by running the following command: &lt;code&gt;id&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Now build the image and run it via &lt;code&gt;docker-compose&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker compose up -d --build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open web browser and goto the IP address of the computer/VM: &lt;a href=&#34;http://localhost:7860&#34;&gt;http://localhost:7860&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;p&gt;The usage is pretty straightforward:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Enter the lora info&lt;/li&gt; &#xA; &lt;li&gt;Upload images and caption them (using the trigger word)&lt;/li&gt; &#xA; &lt;li&gt;Click &#34;start&#34;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;That&#39;s all!&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cocktailpeanut/fluxgym/main/flow.gif&#34; alt=&#34;flow.gif&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Configuration&lt;/h1&gt; &#xA;&lt;h2&gt;Sample Images&lt;/h2&gt; &#xA;&lt;p&gt;By default fluxgym doesn&#39;t generate any sample images during training.&lt;/p&gt; &#xA;&lt;p&gt;You can however configure Fluxgym to automatically generate sample images for every N steps. Here&#39;s what it looks like:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cocktailpeanut/fluxgym/main/sample.png&#34; alt=&#34;sample.png&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;To turn this on, just set the two fields:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Sample Image Prompts:&lt;/strong&gt; These prompts will be used to automatically generate images during training. If you want multiple, separate teach prompt with new line.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Sample Image Every N Steps:&lt;/strong&gt; If your &#34;Expected training steps&#34; is 960 and your &#34;Sample Image Every N Steps&#34; is 100, the images will be generated at step 100, 200, 300, 400, 500, 600, 700, 800, 900, for EACH prompt.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cocktailpeanut/fluxgym/main/sample_fields.png&#34; alt=&#34;sample_fields.png&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Advanced Sample Images&lt;/h2&gt; &#xA;&lt;p&gt;Thanks to the built-in syntax from &lt;a href=&#34;https://github.com/kohya-ss/sd-scripts?tab=readme-ov-file#sample-image-generation-during-training&#34;&gt;kohya/sd-scripts&lt;/a&gt;, you can control exactly how the sample images are generated during the training phase:&lt;/p&gt; &#xA;&lt;p&gt;Let&#39;s say the trigger word is &lt;strong&gt;hrld person.&lt;/strong&gt; Normally you would try sample prompts like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;hrld person is riding a bike&#xA;hrld person is a body builder&#xA;hrld person is a rock star&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;But for every prompt you can include &lt;strong&gt;advanced flags&lt;/strong&gt; to fully control the image generation process. For example, the &lt;code&gt;--d&lt;/code&gt; flag lets you specify the SEED.&lt;/p&gt; &#xA;&lt;p&gt;Specifying a seed means every sample image will use that exact seed, which means you can literally see the LoRA evolve. Here&#39;s an example usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;hrld person is riding a bike --d 42&#xA;hrld person is a body builder --d 42&#xA;hrld person is a rock star --d 42&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here&#39;s what it looks like in the UI:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cocktailpeanut/fluxgym/main/flags.png&#34; alt=&#34;flags.png&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;And here are the results:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cocktailpeanut/fluxgym/main/seed.gif&#34; alt=&#34;seed.gif&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;In addition to the &lt;code&gt;--d&lt;/code&gt; flag, here are other flags you can use:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--n&lt;/code&gt;: Negative prompt up to the next option.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--w&lt;/code&gt;: Specifies the width of the generated image.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--h&lt;/code&gt;: Specifies the height of the generated image.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--d&lt;/code&gt;: Specifies the seed of the generated image.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--l&lt;/code&gt;: Specifies the CFG scale of the generated image.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--s&lt;/code&gt;: Specifies the number of steps in the generation.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The prompt weighting such as &lt;code&gt;( )&lt;/code&gt; and &lt;code&gt;[ ]&lt;/code&gt; also work. (Learn more about &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#attentionemphasis&#34;&gt;Attention/Emphasis&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Publishing to Huggingface&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Get your Huggingface Token from &lt;a href=&#34;https://huggingface.co/settings/tokens&#34;&gt;https://huggingface.co/settings/tokens&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Enter the token in the &#34;Huggingface Token&#34; field and click &#34;Login&#34;. This will save the token text in a local file named &lt;code&gt;HF_TOKEN&lt;/code&gt; (All local and private).&lt;/li&gt; &#xA; &lt;li&gt;Once you&#39;re logged in, you will be able to select a trained LoRA from the dropdown, edit the name if you want, and publish to Huggingface.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cocktailpeanut/fluxgym/main/publish_to_hf.png&#34; alt=&#34;publish_to_hf.png&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Advanced&lt;/h2&gt; &#xA;&lt;p&gt;The advanced tab is automatically constructed by parsing the launch flags available to the latest version of &lt;a href=&#34;https://github.com/kohya-ss/sd-scripts&#34;&gt;kohya sd-scripts&lt;/a&gt;. This means Fluxgym is a full fledged UI for using the Kohya script.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;By default the advanced tab is hidden. You can click the &#34;advanced&#34; accordion to expand it.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cocktailpeanut/fluxgym/main/advanced.png&#34; alt=&#34;advanced.png&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Advanced Features&lt;/h2&gt; &#xA;&lt;h3&gt;Uploading Caption Files&lt;/h3&gt; &#xA;&lt;p&gt;You can also upload the caption files along with the image files. You just need to follow the convention:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Every caption file must be a &lt;code&gt;.txt&lt;/code&gt; file.&lt;/li&gt; &#xA; &lt;li&gt;Each caption file needs to have a corresponding image file that has the same name.&lt;/li&gt; &#xA; &lt;li&gt;For example, if you have an image file named &lt;code&gt;img0.png&lt;/code&gt;, the corresponding caption file must be &lt;code&gt;img0.txt&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
</feed>