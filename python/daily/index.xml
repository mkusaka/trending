<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-05T01:38:17Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>cheshire-cat-ai/core</title>
    <updated>2023-12-05T01:38:17Z</updated>
    <id>tag:github.com,2023-12-05:/cheshire-cat-ai/core</id>
    <link href="https://github.com/cheshire-cat-ai/core" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Production ready AI assistant framework&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name=&#34;readme-top&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- PROJECT LOGO --&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h2&gt;Cheshire-Cat (Stregatto)&lt;/h2&gt; &#xA; &lt;br&gt; &#xA; &lt;a href=&#34;https://github.com/cheshire-cat-ai/core&#34;&gt; &lt;img alt=&#34;GitHub Repo stars&#34; src=&#34;https://img.shields.io/github/stars/cheshire-cat-ai/core?style=social&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://discord.gg/bHX5sNFCYU&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/1092359754917089350?logo=discord&#34; alt=&#34;chat on Discord&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/cheshire-cat-ai/core/issues&#34;&gt; &lt;img alt=&#34;GitHub issues&#34; src=&#34;https://img.shields.io/github/issues/cheshire-cat-ai/core&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/cheshire-cat-ai/core/tags&#34;&gt; &lt;img alt=&#34;GitHub tag (with filter)&#34; src=&#34;https://img.shields.io/github/v/tag/cheshire-cat-ai/core&#34;&gt; &lt;/a&gt; &#xA; &lt;img alt=&#34;GitHub top language&#34; src=&#34;https://img.shields.io/github/languages/top/cheshire-cat-ai/core&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;video src=&#34;https://github.com/cheshire-cat-ai/core/assets/6328377/7bc4acff-34bf-4b8a-be61-4d8967fbd60f&#34;&gt;&lt;/video&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Production ready AI assistant framework&lt;/h2&gt; &#xA;&lt;p&gt;The Cheshire Cat is a framework to build custom AIs on top of any language model. If you have ever used systems like WordPress or Django to build web apps, imagine the Cat as a similar tool, but specific for AI.&lt;/p&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;To make Cheshire Cat run on your machine, you just need &lt;a href=&#34;https://docs.docker.com/get-docker/&#34;&gt;&lt;code&gt;docker&lt;/code&gt;&lt;/a&gt; installed:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --rm -it -p 1865:80 ghcr.io/cheshire-cat-ai/core:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Chat with the Cheshire Cat on &lt;a href=&#34;http://localhost:1865/admin&#34;&gt;localhost:1865/admin&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;You can also interact via REST API and try out the endpoints on &lt;a href=&#34;http://localhost:1865/docs&#34;&gt;localhost:1865/docs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;As a first thing, the Cat will ask you to configure your favourite language model. It can be done directly via the interface in the Settings page (top right in the admin).&lt;/p&gt; &#xA;&lt;p&gt;Enjoy the Cat!&lt;/p&gt; &#xA;&lt;h2&gt;Docs and Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cheshire-cat-ai.github.io/docs/&#34;&gt;Official Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.gg/bHX5sNFCYU&#34;&gt;Discord Server&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cheshirecat.ai/&#34;&gt;Website&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/Rvx19TZBCrw&#34;&gt;YouTube tutorial - How to install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cheshirecat.ai/write-your-first-plugin/&#34;&gt;Tutorial - Write your first plugin&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why use the Cat&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üåç Supports any language model (works with OpenAI chatGPT, Llama2, HuggingFace models, custom)&lt;/li&gt; &#xA; &lt;li&gt;üêò Remembers conversations and documents and uses them in conversation&lt;/li&gt; &#xA; &lt;li&gt;üöÄ Extensible via plugins (AI can connect to your APIs or execute custom python code)&lt;/li&gt; &#xA; &lt;li&gt;üêã Production ready - 100% &lt;a href=&#34;https://docs.docker.com/get-docker/&#34;&gt;dockerized&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üë©‚Äçüëß‚Äçüë¶ Active &lt;a href=&#34;https://discord.gg/bHX5sNFCYU&#34;&gt;Discord community&lt;/a&gt; and easy to understand &lt;a href=&#34;https://cheshire-cat-ai.github.io/docs/&#34;&gt;docs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We are committed to openness, privacy and creativity, we want to bring AI to the long tail. If you want to know more about our vision and values, read the &lt;a href=&#34;https://raw.githubusercontent.com/cheshire-cat-ai/core/main/readme/CODE-OF-ETHICS.md&#34;&gt;Code of Ethics&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;p&gt;Detailed roadmap is &lt;a href=&#34;https://raw.githubusercontent.com/cheshire-cat-ai/core/main/readme/ROADMAP.md&#34;&gt;here&lt;/a&gt;. Whilst for the current progress of development, take a look at the &lt;a href=&#34;https://github.com/orgs/cheshire-cat-ai/projects&#34;&gt;projects&lt;/a&gt; marked as open.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;To get the full dev setup, follow &lt;a href=&#34;https://cheshire-cat-ai.github.io/docs/quickstart/installation-configuration/&#34;&gt;install instructions&lt;/a&gt;. Send your pull request to the &lt;code&gt;develop&lt;/code&gt; branch. Here is a &lt;a href=&#34;https://raw.githubusercontent.com/cheshire-cat-ai/core/main/readme/CONTRIBUTING.md&#34;&gt;full guide to contributing&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Join our &lt;a href=&#34;https://discord.gg/bHX5sNFCYU&#34;&gt;community on Discord&lt;/a&gt; and give the project a star ‚≠ê! Thanks again!üôè&lt;/p&gt; &#xA;&lt;h2&gt;Which way to go?&lt;/h2&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/cheshire-cat-ai/core/main/#readme-top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/cheshire-cat-ai/core/main/readme/cheshire-cat.jpeg&#34; width=&#34;400px&#34; alt=&#34;Wikipedia picture of the Cheshire Cat&#34;&gt; &lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#34;Would you tell me, please, which way I ought to go from here?&#34;&#xA;&#34;That depends a good deal on where you want to get to,&#34; said the Cat.&#xA;&#34;I don&#39;t much care where--&#34; said Alice.&#xA;&#34;Then it doesn&#39;t matter which way you go,&#34; said the Cat.&#xA;&#xA;(Alice&#39;s Adventures in Wonderland - Lewis Carroll)&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>unslothai/unsloth</title>
    <updated>2023-12-05T01:38:17Z</updated>
    <id>tag:github.com,2023-12-05:/unslothai/unsloth</id>
    <link href="https://github.com/unslothai/unsloth" rel="alternate"></link>
    <summary type="html">&lt;p&gt;5X faster 50% less memory LLM finetuning&lt;/p&gt;&lt;hr&gt;&lt;div class=&#34;align-center&#34;&gt; &#xA; &lt;img src=&#34;./images/unsloth new logo.png&#34; width=&#34;400&#34;&gt; &#xA; &lt;a href=&#34;https://discord.gg/u54VK8m8tk&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/unslothai/unsloth/main/images/Discord.png&#34; width=&#34;180&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;80% faster 50% less memory local QLoRA finetuning&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Manual autograd engine - hand derived backprop steps.&lt;/li&gt; &#xA; &lt;li&gt;QLoRA / LoRA 80% faster, 50% less memory.&lt;/li&gt; &#xA; &lt;li&gt;All kernels written in OpenAI&#39;s Triton language.&lt;/li&gt; &#xA; &lt;li&gt;0% loss in accuracy - no approximation methods - all exact.&lt;/li&gt; &#xA; &lt;li&gt;No change of hardware necessary. Supports NVIDIA GPUs since 2018+. CUDA 7.5+. Tesla T4, RTX 20, 30, 40 series, A100, H100s&lt;/li&gt; &#xA; &lt;li&gt;Flash Attention support via Xformers.&lt;/li&gt; &#xA; &lt;li&gt;Supports 4bit and 16bit LoRA finetuning.&lt;/li&gt; &#xA; &lt;li&gt;Train Slim Orca &lt;strong&gt;fully locally in 260 hours from 1301 hours (5x faster).&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Open source version trains 5x faster or you can check out &lt;a href=&#34;https://unsloth.ai/&#34;&gt;Unsloth Pro and Max&lt;/a&gt; codepaths for &lt;strong&gt;30x faster training&lt;/strong&gt;!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div class=&#34;align-center&#34;&gt; &#xA; &lt;img src=&#34;./images/Slim Orca 2GPUs.png&#34; width=&#34;400&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/unslothai/unsloth/main/images/LAION%202GPU.svg?sanitize=true&#34; width=&#34;400&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Try our Colab examples for &lt;a href=&#34;https://colab.research.google.com/drive/1oW55fBmwzCOrBVX66RcpptL3a99qWBxb?usp=sharing&#34;&gt;the Alpaca 52K dataset&lt;/a&gt; or &lt;a href=&#34;https://colab.research.google.com/drive/1VNqLARpE8N8eYwNrUSDoHVjtbR9W0_c7?usp=sharing&#34;&gt;the Slim Orca 518K dataset&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Try our Kaggle example for &lt;a href=&#34;https://www.kaggle.com/danielhanchen/unsloth-laion-chip2-kaggle&#34;&gt;the LAION OIG Chip2 dataset&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Join our &lt;a href=&#34;https://discord.gg/nsS4V5Z6ge&#34;&gt;Discord&lt;/a&gt;!&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Installation Instructions - Conda&lt;/h1&gt; &#xA;&lt;p&gt;Unsloth currently only supports Linux distros and Pytorch &amp;gt;= 2.1.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda install cudatoolkit xformers bitsandbytes pytorch pytorch-cuda=12.1 \&#xA;  -c pytorch -c nvidia -c xformers -c conda-forge -y&#xA;pip install &#34;unsloth[kaggle] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Installation Instructions - Pip&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Find your CUDA version via&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;import torch; torch.version.cuda&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Select either cu118 for CUDA 11.8 or cu121 for CUDA 12.1&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install &#34;unsloth[cu118] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;pip install &#34;unsloth[cu121] @ git+https://github.com/unslothai/unsloth.git&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;We only support Pytorch 2.1: You can update Pytorch via Pip:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install --upgrade --force-reinstall --no-cache-dir torch triton \&#xA;  --index-url https://download.pytorch.org/whl/cu121&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Change &lt;code&gt;cu121&lt;/code&gt; to &lt;code&gt;cu118&lt;/code&gt; for CUDA version 11.8 or 12.1. Go to &lt;a href=&#34;https://pytorch.org/&#34;&gt;https://pytorch.org/&lt;/a&gt; to learn more.&lt;/p&gt; &#xA;&lt;h1&gt;Alpaca Example&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;from unsloth import FastLlamaModel&#xA;import torch&#xA;max_seq_length = 2048 # Can change to any number &amp;lt;= 4096&#xA;dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+&#xA;load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.&#xA;&#xA;# Load Llama model&#xA;model, tokenizer = FastLlamaModel.from_pretrained(&#xA;    model_name = &#34;unsloth/llama-2-7b&#34;, # Supports any llama model&#xA;    max_seq_length = max_seq_length,&#xA;    dtype = dtype,&#xA;    load_in_4bit = load_in_4bit,&#xA;    # token = &#34;hf_...&#34;, # use one if using gated models like meta-llama/Llama-2-7b-hf&#xA;)&#xA;&#xA;# Do model patching and add fast LoRA weights&#xA;model = FastLlamaModel.get_peft_model(&#xA;    model,&#xA;    r = 16,&#xA;    target_modules = [&#34;q_proj&#34;, &#34;k_proj&#34;, &#34;v_proj&#34;, &#34;o_proj&#34;,&#xA;                      &#34;gate_proj&#34;, &#34;up_proj&#34;, &#34;down_proj&#34;,],&#xA;    lora_alpha = 16,&#xA;    lora_dropout = 0, # Currently only supports dropout = 0&#xA;    bias = &#34;none&#34;,    # Currently only supports bias = &#34;none&#34;&#xA;    use_gradient_checkpointing = True,&#xA;    random_state = 3407,&#xA;    max_seq_length = max_seq_length,&#xA;)&#xA;&#xA;trainer = .... Use Huggingface&#39;s Trainer and dataset loading&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you trained a model with Unsloth, we made a cool sticker!! &lt;img src=&#34;./images/unsloth made with love.png&#34; width=&#34;200&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Future Milestones and limitations&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Support sqrt gradient checkpointing which further slashes memory usage by 25%.&lt;/li&gt; &#xA; &lt;li&gt;Does not support non Llama models - we do so in the future.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Performance comparisons on 1 Tesla T4 GPU:&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Time taken for 1 epoch&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;System&lt;/th&gt; &#xA;   &lt;th&gt;GPU&lt;/th&gt; &#xA;   &lt;th&gt;Alpaca (52K)&lt;/th&gt; &#xA;   &lt;th&gt;LAION OIG (210K)&lt;/th&gt; &#xA;   &lt;th&gt;Open Assistant (10K)&lt;/th&gt; &#xA;   &lt;th&gt;SlimOrca (518K)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Huggingface&lt;/td&gt; &#xA;   &lt;td&gt;1 T4&lt;/td&gt; &#xA;   &lt;td&gt;23h 15m&lt;/td&gt; &#xA;   &lt;td&gt;56h 28m&lt;/td&gt; &#xA;   &lt;td&gt;8h 38m&lt;/td&gt; &#xA;   &lt;td&gt;391h 41m&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unsloth Open&lt;/td&gt; &#xA;   &lt;td&gt;1 T4&lt;/td&gt; &#xA;   &lt;td&gt;13h 7m (1.8x)&lt;/td&gt; &#xA;   &lt;td&gt;31h 47m (1.8x)&lt;/td&gt; &#xA;   &lt;td&gt;4h 27m (1.9x)&lt;/td&gt; &#xA;   &lt;td&gt;240h 4m (1.6x)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unsloth Pro&lt;/td&gt; &#xA;   &lt;td&gt;1 T4&lt;/td&gt; &#xA;   &lt;td&gt;3h 6m (7.5x)&lt;/td&gt; &#xA;   &lt;td&gt;5h 17m (10.7x)&lt;/td&gt; &#xA;   &lt;td&gt;1h 7m (7.7x)&lt;/td&gt; &#xA;   &lt;td&gt;59h 53m (6.5x)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unsloth Max&lt;/td&gt; &#xA;   &lt;td&gt;1 T4&lt;/td&gt; &#xA;   &lt;td&gt;2h 39m (8.8x)&lt;/td&gt; &#xA;   &lt;td&gt;4h 31m (12.5x)&lt;/td&gt; &#xA;   &lt;td&gt;0h 58m (8.9x)&lt;/td&gt; &#xA;   &lt;td&gt;51h 30m (7.6x)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Peak Memory Usage&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;System&lt;/th&gt; &#xA;   &lt;th&gt;GPU&lt;/th&gt; &#xA;   &lt;th&gt;Alpaca (52K)&lt;/th&gt; &#xA;   &lt;th&gt;LAION OIG (210K)&lt;/th&gt; &#xA;   &lt;th&gt;Open Assistant (10K)&lt;/th&gt; &#xA;   &lt;th&gt;SlimOrca (518K)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Huggingface&lt;/td&gt; &#xA;   &lt;td&gt;1 T4&lt;/td&gt; &#xA;   &lt;td&gt;7.3GB&lt;/td&gt; &#xA;   &lt;td&gt;5.9GB&lt;/td&gt; &#xA;   &lt;td&gt;14.0GB&lt;/td&gt; &#xA;   &lt;td&gt;13.3GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unsloth Open&lt;/td&gt; &#xA;   &lt;td&gt;1 T4&lt;/td&gt; &#xA;   &lt;td&gt;6.8GB&lt;/td&gt; &#xA;   &lt;td&gt;5.7GB&lt;/td&gt; &#xA;   &lt;td&gt;7.8GB&lt;/td&gt; &#xA;   &lt;td&gt;7.7GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unsloth Pro&lt;/td&gt; &#xA;   &lt;td&gt;1 T4&lt;/td&gt; &#xA;   &lt;td&gt;6.4GB&lt;/td&gt; &#xA;   &lt;td&gt;6.4GB&lt;/td&gt; &#xA;   &lt;td&gt;6.4GB&lt;/td&gt; &#xA;   &lt;td&gt;6.4GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unsloth Max&lt;/td&gt; &#xA;   &lt;td&gt;1 T4&lt;/td&gt; &#xA;   &lt;td&gt;11.4GB&lt;/td&gt; &#xA;   &lt;td&gt;12.4GB&lt;/td&gt; &#xA;   &lt;td&gt;11.9GB&lt;/td&gt; &#xA;   &lt;td&gt;14.4GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Performance comparisons on 2 Tesla T4 GPUs via DDP:&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Time taken for 1 epoch&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;System&lt;/th&gt; &#xA;   &lt;th&gt;GPU&lt;/th&gt; &#xA;   &lt;th&gt;Alpaca (52K)&lt;/th&gt; &#xA;   &lt;th&gt;LAION OIG (210K)&lt;/th&gt; &#xA;   &lt;th&gt;Open Assistant (10K)&lt;/th&gt; &#xA;   &lt;th&gt;SlimOrca (518K)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Huggingface&lt;/td&gt; &#xA;   &lt;td&gt;2 T4&lt;/td&gt; &#xA;   &lt;td&gt;84h 47m&lt;/td&gt; &#xA;   &lt;td&gt;163h 48m&lt;/td&gt; &#xA;   &lt;td&gt;30h 51m&lt;/td&gt; &#xA;   &lt;td&gt;1301h 24m&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unsloth Pro&lt;/td&gt; &#xA;   &lt;td&gt;2 T4&lt;/td&gt; &#xA;   &lt;td&gt;3h 20m (25.4x)&lt;/td&gt; &#xA;   &lt;td&gt;5h 43m (28.7x)&lt;/td&gt; &#xA;   &lt;td&gt;1h 12m (25.7x)&lt;/td&gt; &#xA;   &lt;td&gt;71h 40m (18.1x)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unsloth Max&lt;/td&gt; &#xA;   &lt;td&gt;2 T4&lt;/td&gt; &#xA;   &lt;td&gt;3h 4m (27.6x)&lt;/td&gt; &#xA;   &lt;td&gt;5h 14m (31.3x)&lt;/td&gt; &#xA;   &lt;td&gt;1h 6m (28.1x)&lt;/td&gt; &#xA;   &lt;td&gt;54h 20m (23.9x)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Peak Memory Usage on a Multi GPU System (2 GPUs)&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;System&lt;/th&gt; &#xA;   &lt;th&gt;GPU&lt;/th&gt; &#xA;   &lt;th&gt;Alpaca (52K)&lt;/th&gt; &#xA;   &lt;th&gt;LAION OIG (210K)&lt;/th&gt; &#xA;   &lt;th&gt;Open Assistant (10K)&lt;/th&gt; &#xA;   &lt;th&gt;SlimOrca (518K)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Huggingface&lt;/td&gt; &#xA;   &lt;td&gt;2 T4&lt;/td&gt; &#xA;   &lt;td&gt;8.4GB | 6GB&lt;/td&gt; &#xA;   &lt;td&gt;7.2GB | 5.3GB&lt;/td&gt; &#xA;   &lt;td&gt;14.3GB | 6.6GB&lt;/td&gt; &#xA;   &lt;td&gt;10.9GB | 5.9GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unsloth Pro&lt;/td&gt; &#xA;   &lt;td&gt;2 T4&lt;/td&gt; &#xA;   &lt;td&gt;7.7GB | 4.9GB&lt;/td&gt; &#xA;   &lt;td&gt;7.5GB | 4.9GB&lt;/td&gt; &#xA;   &lt;td&gt;8.5GB | 4.9GB&lt;/td&gt; &#xA;   &lt;td&gt;6.2GB | 4.7GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unsloth Max&lt;/td&gt; &#xA;   &lt;td&gt;2 T4&lt;/td&gt; &#xA;   &lt;td&gt;10.5GB | 5GB&lt;/td&gt; &#xA;   &lt;td&gt;10.6GB | 5GB&lt;/td&gt; &#xA;   &lt;td&gt;10.6GB | 5GB&lt;/td&gt; &#xA;   &lt;td&gt;10.5GB | 5GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Troubleshooting&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Sometimes &lt;code&gt;bitsandbytes&lt;/code&gt; or &lt;code&gt;xformers&lt;/code&gt; does not link properly. Try running:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;!ldconfig /usr/lib64-nvidia&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Windows is not supported as of yet - we rely on Xformers and Triton support, so until both packages support Windows officially, Unsloth will then support Windows.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If it doesn&#39;t install - maybe try updating &lt;code&gt;pip&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;./images/unsloth loading page render.png&#34; width=&#34;300&#34;&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/TaskWeaver</title>
    <updated>2023-12-05T01:38:17Z</updated>
    <id>tag:github.com,2023-12-05:/microsoft/TaskWeaver</id>
    <link href="https://github.com/microsoft/TaskWeaver" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A code-first agent framework for seamlessly planning and executing data analytics tasks.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TaskWeaver&lt;/h1&gt; &#xA;&lt;p&gt;A &lt;strong&gt;code-first&lt;/strong&gt; agent framework for seamlessly planning and executing data analytics tasks. This innovative framework interprets user requests through coded snippets and efficiently coordinates a variety of plugins in the form of functions to execute data analytics tasks&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Highlighted Features&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Rich data structure&lt;/strong&gt; - TaskWeaver allows you to work with rich data structures in Python, such as DataFrames, instead of having to work with text strings.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Customized algorithms&lt;/strong&gt; - TaskWeaver allows you to encapsulate your own algorithms into plugins (in the form of Python functions), and orchestrate them to achieve complex tasks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Incorporating domain-specific knowledge&lt;/strong&gt; - TaskWeaver is designed to be easily incorporating domain-specific knowledge, such as the knowledge of execution flow, to improve the reliability of the AI copilot.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Stateful conversation&lt;/strong&gt; - TaskWeaver is designed to support stateful conversation. It can remember the context of the conversation and leverage it to improve the user experience.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Code verification&lt;/strong&gt; - TaskWeaver is designed to verify the generated code before execution. It can detect potential issues in the generated code and provide suggestions to fix them.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Easy to use&lt;/strong&gt; - TaskWeaver is designed to be easy to use. We provide a set of sample plugins and a tutorial to help you get started. Users can easily create their own plugins based on the sample plugins. TaskWeaver offers an open-box experience, allowing users to run a service immediately after installation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Easy to debug&lt;/strong&gt; - TaskWeaver is designed to be easy to debug. We have detailed logs to help you understand what is going on during calling the LLM, the code generation, and execution process.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Security consideration&lt;/strong&gt; - TaskWeaver supports a basic session management to keep different users&#39; data separate. The code execution is separated into different processes in order not to interfere with each other.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Easy extension&lt;/strong&gt; - TaskWeaver is designed to be easily extended to accomplish more complex tasks. You can create multiple AI copilots to act in different roles, and orchestrate them to achieve complex tasks.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Getting started&lt;/h1&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.10 or above&lt;/li&gt; &#xA; &lt;li&gt;OpenAI (or Azure OpenAI) access with GPT-3.5 above models. However, it is strongly recommended to use the GPT-4, which is more stable.&lt;/li&gt; &#xA; &lt;li&gt;Other requirements can be found in the &lt;code&gt;requirements.txt&lt;/code&gt; file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;OpenAI API had a major &lt;a href=&#34;https://github.com/openai/openai-python&#34;&gt;update&lt;/a&gt; from 0.xx to 1.xx in November 2023. Please make sure you are not using an old version because the API is not backward compatible.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;You can install TaskWeaver by running the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/microsoft/TaskWeaver.git&#xA;cd TaskWeaver&#xA;# install the requirements&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Project Directory&lt;/h3&gt; &#xA;&lt;p&gt;TaskWeaver runs as a process, you need to create a project directory to store plugins and configuration files. We provided a sample project directory in the &lt;code&gt;project&lt;/code&gt; folder. You can copy the &lt;code&gt;project&lt;/code&gt; folder to your workspace. A project directory typically contains the following files and folders:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;üì¶project&#xA; ‚î£ üìútaskweaver_config.json # the configuration file for TaskWeaver&#xA; ‚î£ üìÇplugins # the folder to store plugins&#xA; ‚î£ üìÇplanner_examples # the folder to store planner examples&#xA; ‚î£ üìÇcodeinterpreter_examples # the folder to store code interpreter examples&#xA; ‚î£ üìÇsample_data # the folder to store sample data used for evaluations&#xA; ‚î£ üìÇlogs # the folder to store logs, will be generated after program starts&#xA; ‚îó üìÇworkspace # the directory stores session dataÔºå will be generated after program starts&#xA;    ‚îó üìÇ session_id &#xA;      ‚î£ üìÇces # the folder used by the code execution service&#xA;      ‚îó üìÇcwd # the current working directory to run the generated code&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;OpenAI Configuration&lt;/h3&gt; &#xA;&lt;p&gt;Before running TaskWeaver, you need to provide your OpenAI API key and other necessary information. You can do this by editing the &lt;code&gt;taskweaver_config.json&lt;/code&gt; file. If you are using Azure OpenAI, you need to set the following parameters in the &lt;code&gt;taskweaver_config.json&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;h4&gt;Azure OpenAI&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;&#34;llm.api_base&#34;: &#34;https://xxx.openai.azure.com/&#34;,&#xA;&#34;llm.api_key&#34;: &#34;the api key&#34;,&#xA;&#34;llm.api_type&#34;: &#34;azure&#34;,&#xA;&#34;llm.api_version&#34;: &#34;the api version&#34;,&#xA;&#34;llm.model&#34;: &#34;the model name, e.g., gpt-4&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;OpenAI&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;&#34;llm.api_key&#34;: &#34;the api key&#34;,&#xA;&#34;llm.model&#34;: &#34;the model name, e.g., gpt-4&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;üí° Only the latest OpenAI API supports the &lt;code&gt;json_object&lt;/code&gt; response format. If you are using an older version of OpenAI API, you need to set the &lt;code&gt;llm.response_format&lt;/code&gt; to &lt;code&gt;null&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;More configuration options can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/TaskWeaver/main/docs/configuration.md&#34;&gt;configuration documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Start TaskWeaver&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# assume you are in the taskweaver folder&#xA;# -p is the path to the project directory&#xA;python -m taskweaver -p ./project/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will start the TaskWeaver process and you can interact with it through the command line interface. If everything goes well, you will see the following prompt:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;=========================================================&#xA; _____         _     _       __&#xA;|_   _|_ _ ___| | _ | |     / /__  ____ __   _____  _____&#xA;  | |/ _` / __| |/ /| | /| / / _ \/ __ `/ | / / _ \/ ___/&#xA;  | | (_| \__ \   &amp;lt; | |/ |/ /  __/ /_/ /| |/ /  __/ /&#xA;  |_|\__,_|___/_|\_\|__/|__/\___/\__,_/ |___/\___/_/&#xA;=========================================================&#xA;TaskWeaver: I am TaskWeaver, an AI assistant. To get started, could you please enter your request?&#xA;Human: ___&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Two Walkthrough Examples&lt;/h3&gt; &#xA;&lt;h4&gt;Example 1: Pull data from a database and apply an anomaly detection algorithm&lt;/h4&gt; &#xA;&lt;p&gt;In this example, we will show you how to use TaskWeaver to pull data from a database and apply an anomaly detection algorithm.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/TaskWeaver/assets/7489260/9f854acf-f2bf-4566-9d16-f84e915d0f4e&#34;&gt;Anomaly Detection&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you want to follow this example, you need to configure the &lt;code&gt;sql_pull_data&lt;/code&gt; plugin in the &lt;code&gt;project/plugins/sql_pull_data.yaml&lt;/code&gt; file. You need to provide the following information:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;api_type: azure or openai&#xA;api_base: ...&#xA;api_key: ...&#xA;api_version: ...&#xA;deployment_name: ...&#xA;sqlite_db_path: sqlite:///../../../sample_data/anomaly_detection.db&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;sql_pull_data&lt;/code&gt; plugin is a plugin that pulls data from a database. It takes a natural language request as input and returns a DataFrame as output.&lt;/p&gt; &#xA;&lt;p&gt;This plugin is implemented based on &lt;a href=&#34;https://www.langchain.com/&#34;&gt;Langchain&lt;/a&gt;. If you want to follow this example, you need to install the Langchain package:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install langchain&#xA;pip install tabulate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Example 2: Forecast QQQ&#39;s price in the next week&lt;/h4&gt; &#xA;&lt;p&gt;In this example, we will show you how to use TaskWeaver to forecast QQQ&#39;s price in the next week using the ARIMA algorithm.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/TaskWeaver/assets/7489260/c2b09615-52d8-491f-bbbf-e86ba282e59a&#34;&gt;Nasdaq 100 Index Price Forecasting&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you want to follow this example, you need to you have two requirements installed:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install yfinance&#xA;pip install statsmodels&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more examples, please refer to our &lt;a href=&#34;http://export.arxiv.org/abs/2311.17541&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Use TaskWeaver as a library&lt;/h1&gt; &#xA;&lt;p&gt;If you want to use TaskWeaver as a library, you can refer to the following code example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from taskweaver.app.app import TaskWeaverApp&#xA;&#xA;app_dir = &#34;/path/to/project/&#34;&#xA;app = TaskWeaverApp(app_dir=app_dir)&#xA;session = app.get_session()&#xA;&#xA;user_query = &#34;hello, what can you do?&#34;&#xA;response_round = session.send_message(user_query,&#xA;                                      event_handler=lambda x, y: print(f&#34;{x}:\n{y}&#34;))&#xA;print(response_round.to_dict())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;event_handler: a callback function that is utilized to display the response obtained from TaskWeaver step by step. It takes two arguments: the message type (e.g., &lt;code&gt;plan&lt;/code&gt;) and the message content.&lt;/li&gt; &#xA; &lt;li&gt;response_round: the response from TaskWeaver. which is an object of the &lt;code&gt;Round&lt;/code&gt; class. An example of the &lt;code&gt;Round&lt;/code&gt; object is shown below:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;    &#34;id&#34;: &#34;round-20231201-043134-218a2681&#34;,&#xA;    &#34;user_query&#34;: &#34;hello, what can you do?&#34;,&#xA;    &#34;state&#34;: &#34;finished&#34;,&#xA;    &#34;post_list&#34;: [&#xA;        {&#xA;            &#34;id&#34;: &#34;post-20231201-043134-10eedcca&#34;,&#xA;            &#34;message&#34;: &#34;hello, what can you do?&#34;,&#xA;            &#34;send_from&#34;: &#34;User&#34;,&#xA;            &#34;send_to&#34;: &#34;Planner&#34;,&#xA;            &#34;attachment_list&#34;: []&#xA;        },&#xA;        {&#xA;            &#34;id&#34;: &#34;post-20231201-043141-86a2aaff&#34;,&#xA;            &#34;message&#34;: &#34;I can help you with various tasks, such as counting rows in a data file, detecting anomalies in a dataset, searching for products on Klarna, summarizing research papers, and pulling data from a SQL database. Please provide more information about the task you want to accomplish, and I&#39;ll guide you through the process.&#34;,&#xA;            &#34;send_from&#34;: &#34;Planner&#34;,&#xA;            &#34;send_to&#34;: &#34;User&#34;,&#xA;            &#34;attachment_list&#34;: [&#xA;                {&#xA;                    &#34;id&#34;: &#34;atta-20231201-043141-6bc4da86&#34;,&#xA;                    &#34;type&#34;: &#34;init_plan&#34;,&#xA;                    &#34;content&#34;: &#34;1. list the available functions&#34;&#xA;                },&#xA;                {&#xA;                    &#34;id&#34;: &#34;atta-20231201-043141-6f29f6c9&#34;,&#xA;                    &#34;type&#34;: &#34;plan&#34;,&#xA;                    &#34;content&#34;: &#34;1. list the available functions&#34;&#xA;                },&#xA;                {&#xA;                    &#34;id&#34;: &#34;atta-20231201-043141-76186c7a&#34;,&#xA;                    &#34;type&#34;: &#34;current_plan_step&#34;,&#xA;                    &#34;content&#34;: &#34;1. list the available functions&#34;&#xA;                }&#xA;            ]&#xA;        }&#xA;    ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Customizing TaskWeaver&lt;/h2&gt; &#xA;&lt;p&gt;There are two ways to customize TaskWeaver: creating plugins and creating examples.&lt;/p&gt; &#xA;&lt;h3&gt;Creating Plugins&lt;/h3&gt; &#xA;&lt;p&gt;Since TaskWeaver can already perform some basic tasks, you can create plugins to extend its capabilities. A plugin is a python function that takes a set of arguments and returns a set of results.&lt;/p&gt; &#xA;&lt;p&gt;Typically, you only need to write a plugin in the following example scenarios:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You want to encapsulate your own algorithm into a plugin.&lt;/li&gt; &#xA; &lt;li&gt;You want to import a python package that is not supported by TaskWeaver.&lt;/li&gt; &#xA; &lt;li&gt;You want to connect to an external data source to pull data.&lt;/li&gt; &#xA; &lt;li&gt;You want to query a web API.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Refer to the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/TaskWeaver/main/docs/plugin.md&#34;&gt;plugin documentation&lt;/a&gt; for more details. Otherwise, you can leverage TaskWeaver&#39;s code generation capability to perform tasks.&lt;/p&gt; &#xA;&lt;h3&gt;Creating Examples&lt;/h3&gt; &#xA;&lt;p&gt;The purpose of examples is to help LLMs understand how to perform tasks especially when the tasks are complex and need domain-specific knowledge.&lt;/p&gt; &#xA;&lt;p&gt;There are two types of examples: (1) planning examples and (2) code interpreter examples. Planning examples are used to demonstrate how to use TaskWeaver to plan for a specific task. Code generation examples are used to demonstrate how to generate code or orchestrate plugins to perform a specific task.&lt;/p&gt; &#xA;&lt;p&gt;Refer to the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/TaskWeaver/main/docs/example.md&#34;&gt;example documentation&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;Our paper could be found &lt;a href=&#34;http://export.arxiv.org/abs/2311.17541&#34;&gt;here&lt;/a&gt;. If you use TaskWeaver in your research, please cite our paper:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{taskweaver,&#xA;  title={TaskWeaver: ACode-First Agent Framework},&#xA;  author={Bo Qiao, Liqun Li, Xu Zhang, Shilin He, Yu Kang, Chaoyun Zhang, Fangkai Yang, Hang Dong, Jue Zhang, Lu Wang, Minghua Ma, Pu Zhao, Si Qin, Xiaoting Qin, Chao Du, Yong Xu, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang},&#xA;  journal={arXiv preprint arXiv:2311.17541},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Trademarks&lt;/h2&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt;</summary>
  </entry>
</feed>