<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-09T01:42:02Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>open-mmlab/mmpretrain</title>
    <updated>2023-04-09T01:42:02Z</updated>
    <id>tag:github.com,2023-04-09:/open-mmlab/mmpretrain</id>
    <link href="https://github.com/open-mmlab/mmpretrain" rel="alternate"></link>
    <summary type="html">&lt;p&gt;OpenMMLab Pre-training Toolbox and Benchmark&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/resources/mmpt-logo.png&#34; width=&#34;600&#34;&gt; &#xA; &lt;div&gt;&#xA;  &amp;nbsp;&#xA; &lt;/div&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;b&gt;&lt;font size=&#34;5&#34;&gt;OpenMMLab website&lt;/font&gt;&lt;/b&gt; &#xA;  &lt;sup&gt; &lt;a href=&#34;https://openmmlab.com&#34;&gt; &lt;i&gt;&lt;font size=&#34;4&#34;&gt;HOT&lt;/font&gt;&lt;/i&gt; &lt;/a&gt; &lt;/sup&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &#xA;  &lt;b&gt;&lt;font size=&#34;5&#34;&gt;OpenMMLab platform&lt;/font&gt;&lt;/b&gt; &#xA;  &lt;sup&gt; &lt;a href=&#34;https://platform.openmmlab.com&#34;&gt; &lt;i&gt;&lt;font size=&#34;4&#34;&gt;TRY IT OUT&lt;/font&gt;&lt;/i&gt; &lt;/a&gt; &lt;/sup&gt; &#xA; &lt;/div&gt; &#xA; &lt;div&gt;&#xA;  &amp;nbsp;&#xA; &lt;/div&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://pypi.org/project/mmpretrain&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/mmpretrain&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-latest-blue&#34; alt=&#34;Docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmpretrain/actions&#34;&gt;&lt;img src=&#34;https://github.com/open-mmlab/mmpretrain/workflows/build/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/open-mmlab/mmpretrain&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/open-mmlab/mmpretrain/branch/main/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmpretrain/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/open-mmlab/mmpretrain.svg?sanitize=true&#34; alt=&#34;license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmpretrain/issues&#34;&gt;&lt;img src=&#34;https://isitmaintained.com/badge/open/open-mmlab/mmpretrain.svg?sanitize=true&#34; alt=&#34;open issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/open-mmlab/mmpretrain/issues&#34;&gt;&lt;img src=&#34;https://isitmaintained.com/badge/resolution/open-mmlab/mmpretrain.svg?sanitize=true&#34; alt=&#34;issue resolution&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/&#34;&gt;üìò Documentation&lt;/a&gt; | &lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/get_started.html#installation&#34;&gt;üõ†Ô∏è Installation&lt;/a&gt; | &lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/modelzoo_statistics.html&#34;&gt;üëÄ Model Zoo&lt;/a&gt; | &lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/notes/changelog.html&#34;&gt;üÜï Update News&lt;/a&gt; | &lt;a href=&#34;https://github.com/open-mmlab/mmpretrain/issues/new/choose&#34;&gt;ü§î Reporting Issues&lt;/a&gt;&lt;/p&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/36138628/230307505-4727ad0a-7d71-4069-939d-b499c7e272b7.png&#34; width=&#34;400&#34;&gt; &#xA; &lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/README_zh-CN.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt;  &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://openmmlab.medium.com/&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/219255827-67c1a27f-f8c5-46a9-811d-5e57448c61d1.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://discord.gg/raweFPmdzG&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218347213-c080267f-cbb6-443e-8532-8e1ed9a58ea9.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://twitter.com/OpenMMLab&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218346637-d30c8a0f-3eba-4699-8131-512fb06d46db.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://www.youtube.com/openmmlab&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218346691-ceb2116a-465a-40af-8424-9f30d2348ca9.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://space.bilibili.com/1293512903&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/219026751-d7d14cce-a7c9-4e82-9942-8375fca65b99.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://www.zhihu.com/people/openmmlab&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/25839884/219026120-ba71e48b-6e94-4bd4-b4e9-b7d175b5e362.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;MMPreTrain is an open source pre-training toolbox based on PyTorch. It is a part of the &lt;a href=&#34;https://openmmlab.com/&#34;&gt;OpenMMLab&lt;/a&gt; project.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;main&lt;/code&gt; branch works with &lt;strong&gt;PyTorch 1.8+&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Major features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Various backbones and pretrained models&lt;/li&gt; &#xA; &lt;li&gt;Rich training strategies(supervised learning, self-supervised learning, etc.)&lt;/li&gt; &#xA; &lt;li&gt;Bag of training tricks&lt;/li&gt; &#xA; &lt;li&gt;Large-scale training configs&lt;/li&gt; &#xA; &lt;li&gt;High efficiency and extensibility&lt;/li&gt; &#xA; &lt;li&gt;Powerful toolkits for model analysis and experiments&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What&#39;s new&lt;/h2&gt; &#xA;&lt;p&gt;üåü v1.0.0rc7 was released in 07/04/2023&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Integrated Self-supervised learning algorithms from &lt;strong&gt;MMSelfSup&lt;/strong&gt;, such as &lt;strong&gt;MAE&lt;/strong&gt;, &lt;strong&gt;BEiT&lt;/strong&gt;, etc.&lt;/li&gt; &#xA; &lt;li&gt;Support &lt;strong&gt;RIFormer&lt;/strong&gt;, a simple but effective vision backbone by removing token mixer.&lt;/li&gt; &#xA; &lt;li&gt;Add t-SNE visualization.&lt;/li&gt; &#xA; &lt;li&gt;Refactor dataset pipeline visualization.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Update of previous versions&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Support &lt;strong&gt;LeViT&lt;/strong&gt;, &lt;strong&gt;XCiT&lt;/strong&gt;, &lt;strong&gt;ViG&lt;/strong&gt;, &lt;strong&gt;ConvNeXt-V2&lt;/strong&gt;, &lt;strong&gt;EVA&lt;/strong&gt;, &lt;strong&gt;RevViT&lt;/strong&gt;, &lt;strong&gt;EfficientnetV2&lt;/strong&gt;, &lt;strong&gt;CLIP&lt;/strong&gt;, &lt;strong&gt;TinyViT&lt;/strong&gt; and &lt;strong&gt;MixMIM&lt;/strong&gt; backbones.&lt;/li&gt; &#xA; &lt;li&gt;Reproduce the training accuracy of &lt;strong&gt;ConvNeXt&lt;/strong&gt; and &lt;strong&gt;RepVGG&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Support confusion matrix calculation and plot.&lt;/li&gt; &#xA; &lt;li&gt;Support &lt;strong&gt;multi-task&lt;/strong&gt; training and testing.&lt;/li&gt; &#xA; &lt;li&gt;Support Test-time Augmentation.&lt;/li&gt; &#xA; &lt;li&gt;Upgrade API to get pre-defined models of MMPreTrain.&lt;/li&gt; &#xA; &lt;li&gt;Refactor BEiT backbone and support v1/v2 inference.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This release introduced a brand new and flexible training &amp;amp; test engine, but it&#39;s still in progress. Welcome to try according to &lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/&#34;&gt;the documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;And there are some BC-breaking changes. Please check &lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/migration.html&#34;&gt;the migration tutorial&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/notes/changelog.html&#34;&gt;changelog&lt;/a&gt; for more details and other release history.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Below are quick steps for installation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda create -n open-mmlab python=3.8 pytorch==1.10.1 torchvision==0.11.2 cudatoolkit=11.3 -c pytorch -y&#xA;conda activate open-mmlab&#xA;pip install openmim&#xA;git clone https://github.com/open-mmlab/mmpretrain.git&#xA;cd mmpretrain&#xA;mim install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/get_started.html&#34;&gt;installation documentation&lt;/a&gt; for more detailed installation and dataset preparation.&lt;/p&gt; &#xA;&lt;h2&gt;User Guides&lt;/h2&gt; &#xA;&lt;p&gt;We provided a series of tutorials about the basic usage of MMPreTrain for new users:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/user_guides/config.html&#34;&gt;Learn about Configs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/user_guides/dataset_prepare.html&#34;&gt;Prepare Dataset&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/user_guides/inference.html&#34;&gt;Inference with existing models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/user_guides/train.html&#34;&gt;Train&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/user_guides/test.html&#34;&gt;Test&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/user_guides/downstream.html&#34;&gt;Downstream tasks&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For more information, please refer to &lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/&#34;&gt;our documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Model zoo&lt;/h2&gt; &#xA;&lt;p&gt;Results and models are available in the &lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/modelzoo_statistics.html&#34;&gt;model zoo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;b&gt;Overview&lt;/b&gt; &#xA;&lt;/div&gt; &#xA;&lt;table align=&#34;center&#34;&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr align=&#34;center&#34; valign=&#34;bottom&#34;&gt; &#xA;   &lt;td&gt; &lt;b&gt;Supported Backbones&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Self-supervised Learning&lt;/b&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;b&gt;Others&lt;/b&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr valign=&#34;top&#34;&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/vgg&#34;&gt;VGG&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/resnet&#34;&gt;ResNet&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/resnext&#34;&gt;ResNeXt&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/seresnet&#34;&gt;SE-ResNet&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/seresnet&#34;&gt;SE-ResNeXt&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/regnet&#34;&gt;RegNet&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/shufflenet_v1&#34;&gt;ShuffleNet V1&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/shufflenet_v2&#34;&gt;ShuffleNet V2&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/mobilenet_v2&#34;&gt;MobileNet V2&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/mobilenet_v3&#34;&gt;MobileNet V3&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/swin_transformer&#34;&gt;Swin-Transformer&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/swin_transformer_v2&#34;&gt;Swin-Transformer V2&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/repvgg&#34;&gt;RepVGG&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/vision_transformer&#34;&gt;Vision-Transformer&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/tnt&#34;&gt;Transformer-in-Transformer&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/res2net&#34;&gt;Res2Net&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/mlp_mixer&#34;&gt;MLP-Mixer&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/deit&#34;&gt;DeiT&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/deit3&#34;&gt;DeiT-3&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/conformer&#34;&gt;Conformer&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/t2t_vit&#34;&gt;T2T-ViT&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/twins&#34;&gt;Twins&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/efficientnet&#34;&gt;EfficientNet&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/edgenext&#34;&gt;EdgeNeXt&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/convnext&#34;&gt;ConvNeXt&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/hrnet&#34;&gt;HRNet&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/van&#34;&gt;VAN&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/convmixer&#34;&gt;ConvMixer&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/cspnet&#34;&gt;CSPNet&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/poolformer&#34;&gt;PoolFormer&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/inception_v3&#34;&gt;Inception V3&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/mobileone&#34;&gt;MobileOne&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/efficientformer&#34;&gt;EfficientFormer&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/mvit&#34;&gt;MViT&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/hornet&#34;&gt;HorNet&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/mobilevit&#34;&gt;MobileViT&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/davit&#34;&gt;DaViT&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/replknet&#34;&gt;RepLKNet&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/beit&#34;&gt;BEiT&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/mixmim&#34;&gt;MixMIM&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/efficientnet_v2&#34;&gt;EfficientNet V2&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/revvit&#34;&gt;RevViT&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/convnext_v2&#34;&gt;ConvNeXt V2&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/vig&#34;&gt;ViG&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/xcit&#34;&gt;XCiT&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/levit&#34;&gt;LeViT&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/riformer&#34;&gt;RIFormer&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/mocov2&#34;&gt;MoCo V1 (CVPR&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/simclr&#34;&gt;SimCLR (ICML&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/mocov2&#34;&gt;MoCo V2 (arXiv&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/byol&#34;&gt;BYOL (NeurIPS&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/swav&#34;&gt;SwAV (NeurIPS&#39;2020)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/densecl&#34;&gt;DenseCL (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/simsiam&#34;&gt;SimSiam (CVPR&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/barlowtwins&#34;&gt;Barlow Twins (ICML&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/mocov3&#34;&gt;MoCo V3 (ICCV&#39;2021)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/beit&#34;&gt;BEiT (ICLR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/mae&#34;&gt;MAE (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/simmim&#34;&gt;SimMIM (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/maskfeat&#34;&gt;MaskFeat (CVPR&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/cae&#34;&gt;CAE (arXiv&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/milan&#34;&gt;MILAN (arXiv&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/beitv2&#34;&gt;BEiT V2 (arXiv&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/eva&#34;&gt;EVA (CVPR&#39;2023)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/mixmim&#34;&gt;MixMIM (arXiv&#39;2022)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;   &lt;td&gt; Image Retrieval Task: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/configs/arcface&#34;&gt;ArcFace (CVPR&#39;2019)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; Training&amp;amp;Test Tips: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1909.13719&#34;&gt;RandAug&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1805.09501&#34;&gt;AutoAug&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/mmpretrain/datasets/samplers/repeat_aug.py&#34;&gt;RepeatAugSampler&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/mmpretrain/models/tta/score_tta.py&#34;&gt;TTA&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;...&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt;&#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We appreciate all contributions to improve MMPreTrain. Please refer to &lt;a href=&#34;https://mmpretrain.readthedocs.io/en/latest/notes/contribution_guide.html&#34;&gt;CONTRUBUTING&lt;/a&gt; for the contributing guideline.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;MMPreTrain is an open source project that is contributed by researchers and engineers from various colleges and companies. We appreciate all the contributors who implement their methods or add new features, as well as users who give valuable feedbacks. We wish that the toolbox and benchmark could serve the growing research community by providing a flexible toolkit to reimplement existing methods and supporting their own academic research.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find this project useful in your research, please consider cite:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-BibTeX&#34;&gt;@misc{2023mmpretrain,&#xA;    title={OpenMMLab&#39;s Pre-training Toolbox and Benchmark},&#xA;    author={MMPreTrain Contributors},&#xA;    howpublished = {\url{https://github.com/open-mmlab/mmpretrain}},&#xA;    year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is released under the &lt;a href=&#34;https://raw.githubusercontent.com/open-mmlab/mmpretrain/main/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Projects in OpenMMLab&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmengine&#34;&gt;MMEngine&lt;/a&gt;: OpenMMLab foundational library for training deep learning models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmcv&#34;&gt;MMCV&lt;/a&gt;: OpenMMLab foundational library for computer vision.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mim&#34;&gt;MIM&lt;/a&gt;: MIM installs OpenMMLab packages.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmeval&#34;&gt;MMEval&lt;/a&gt;: A unified evaluation library for multiple machine learning libraries.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmpretrain&#34;&gt;MMPreTrain&lt;/a&gt;: OpenMMLab pre-training toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmdetection&#34;&gt;MMDetection&lt;/a&gt;: OpenMMLab detection toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmdetection3d&#34;&gt;MMDetection3D&lt;/a&gt;: OpenMMLab&#39;s next-generation platform for general 3D object detection.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmrotate&#34;&gt;MMRotate&lt;/a&gt;: OpenMMLab rotated object detection toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmyolo&#34;&gt;MMYOLO&lt;/a&gt;: OpenMMLab YOLO series toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmsegmentation&#34;&gt;MMSegmentation&lt;/a&gt;: OpenMMLab semantic segmentation toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmocr&#34;&gt;MMOCR&lt;/a&gt;: OpenMMLab text detection, recognition, and understanding toolbox.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmpose&#34;&gt;MMPose&lt;/a&gt;: OpenMMLab pose estimation toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmhuman3d&#34;&gt;MMHuman3D&lt;/a&gt;: OpenMMLab 3D human parametric model toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmselfsup&#34;&gt;MMSelfSup&lt;/a&gt;: OpenMMLab self-supervised learning toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmrazor&#34;&gt;MMRazor&lt;/a&gt;: OpenMMLab model compression toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmfewshot&#34;&gt;MMFewShot&lt;/a&gt;: OpenMMLab fewshot learning toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmaction2&#34;&gt;MMAction2&lt;/a&gt;: OpenMMLab&#39;s next-generation action understanding toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmtracking&#34;&gt;MMTracking&lt;/a&gt;: OpenMMLab video perception toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmflow&#34;&gt;MMFlow&lt;/a&gt;: OpenMMLab optical flow toolbox and benchmark.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmediting&#34;&gt;MMEditing&lt;/a&gt;: OpenMMLab image and video editing toolbox.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmgeneration&#34;&gt;MMGeneration&lt;/a&gt;: OpenMMLab image and video generative models toolbox.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/open-mmlab/mmdeploy&#34;&gt;MMDeploy&lt;/a&gt;: OpenMMLab model deployment framework.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>abetlen/llama-cpp-python</title>
    <updated>2023-04-09T01:42:02Z</updated>
    <id>tag:github.com,2023-04-09:/abetlen/llama-cpp-python</id>
    <link href="https://github.com/abetlen/llama-cpp-python" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Python bindings for llama.cpp&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ü¶ô Python Bindings for &lt;code&gt;llama.cpp&lt;/code&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://abetlen.github.io/llama-cpp-python&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-passing-green.svg?sanitize=true&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/abetlen/llama-cpp-python/actions/workflows/test.yaml&#34;&gt;&lt;img src=&#34;https://github.com/abetlen/llama-cpp-python/actions/workflows/test.yaml/badge.svg?branch=main&#34; alt=&#34;Tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/llama-cpp-python/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/llama-cpp-python&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/llama-cpp-python/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/llama-cpp-python&#34; alt=&#34;PyPI - Python Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/llama-cpp-python/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/l/llama-cpp-python&#34; alt=&#34;PyPI - License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/llama-cpp-python/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/llama-cpp-python&#34; alt=&#34;PyPI - Downloads&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Simple Python bindings for &lt;strong&gt;@ggerganov&#39;s&lt;/strong&gt; &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;&lt;code&gt;llama.cpp&lt;/code&gt;&lt;/a&gt; library. This package provides:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Low-level access to C API via &lt;code&gt;ctypes&lt;/code&gt; interface.&lt;/li&gt; &#xA; &lt;li&gt;High-level Python API for text completion &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;OpenAI-like API&lt;/li&gt; &#xA;   &lt;li&gt;LangChain compatibility&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Install from PyPI:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install llama-cpp-python&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;High-level API&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from llama_cpp import Llama&#xA;&amp;gt;&amp;gt;&amp;gt; llm = Llama(model_path=&#34;models/7B/...&#34;)&#xA;&amp;gt;&amp;gt;&amp;gt; output = llm(&#34;Q: Name the planets in the solar system? A: &#34;, max_tokens=32, stop=[&#34;Q:&#34;, &#34;\n&#34;], echo=True)&#xA;&amp;gt;&amp;gt;&amp;gt; print(output)&#xA;{&#xA;  &#34;id&#34;: &#34;cmpl-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx&#34;,&#xA;  &#34;object&#34;: &#34;text_completion&#34;,&#xA;  &#34;created&#34;: 1679561337,&#xA;  &#34;model&#34;: &#34;models/7B/...&#34;,&#xA;  &#34;choices&#34;: [&#xA;    {&#xA;      &#34;text&#34;: &#34;Q: Name the planets in the solar system? A: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune and Pluto.&#34;,&#xA;      &#34;index&#34;: 0,&#xA;      &#34;logprobs&#34;: None,&#xA;      &#34;finish_reason&#34;: &#34;stop&#34;&#xA;    }&#xA;  ],&#xA;  &#34;usage&#34;: {&#xA;    &#34;prompt_tokens&#34;: 14,&#xA;    &#34;completion_tokens&#34;: 28,&#xA;    &#34;total_tokens&#34;: 42&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Web Server&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;llama-cpp-python&lt;/code&gt; offers a web server which aims to act as a drop-in replacement for the OpenAI API. This allows you to use llama.cpp compatible models with any OpenAI compatible client (language libraries, services, etc).&lt;/p&gt; &#xA;&lt;p&gt;To install the server package and get started:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install llama-cpp-python[server]&#xA;export MODEL=./models/7B&#xA;python3 -m llama_cpp.server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Navigate to &lt;a href=&#34;http://localhost:8000/docs&#34;&gt;http://localhost:8000/docs&lt;/a&gt; to see the OpenAPI documentation.&lt;/p&gt; &#xA;&lt;h2&gt;Low-level API&lt;/h2&gt; &#xA;&lt;p&gt;The low-level API is a direct &lt;code&gt;ctypes&lt;/code&gt; binding to the C API provided by &lt;code&gt;llama.cpp&lt;/code&gt;. The entire API can be found in &lt;a href=&#34;https://github.com/abetlen/llama-cpp-python/raw/master/llama_cpp/llama_cpp.py&#34;&gt;llama_cpp/llama_cpp.py&lt;/a&gt; and should mirror &lt;a href=&#34;https://github.com/ggerganov/llama.cpp/raw/master/llama.h&#34;&gt;llama.h&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Documentation&lt;/h1&gt; &#xA;&lt;p&gt;Documentation is available at &lt;a href=&#34;https://abetlen.github.io/llama-cpp-python&#34;&gt;https://abetlen.github.io/llama-cpp-python&lt;/a&gt;. If you find any issues with the documentation, please open an issue or submit a PR.&lt;/p&gt; &#xA;&lt;h1&gt;Development&lt;/h1&gt; &#xA;&lt;p&gt;This package is under active development and I welcome any contributions.&lt;/p&gt; &#xA;&lt;p&gt;To get started, clone the repository and install the package in development mode:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone git@github.com:abetlen/llama-cpp-python.git&#xA;git submodule update --init --recursive&#xA;# Will need to be re-run any time vendor/llama.cpp is updated&#xA;python3 setup.py develop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;How does this compare to other Python bindings of &lt;code&gt;llama.cpp&lt;/code&gt;?&lt;/h1&gt; &#xA;&lt;p&gt;I originally wrote this package for my own use with two goals in mind:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Provide a simple process to install &lt;code&gt;llama.cpp&lt;/code&gt; and access the full C API in &lt;code&gt;llama.h&lt;/code&gt; from Python&lt;/li&gt; &#xA; &lt;li&gt;Provide a high-level Python API that can be used as a drop-in replacement for the OpenAI API so existing apps can be easily ported to use &lt;code&gt;llama.cpp&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Any contributions and changes to this package will be made with these goals in mind.&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;This project is licensed under the terms of the MIT license.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Michael-K-Stein/SpotiFile</title>
    <updated>2023-04-09T01:42:02Z</updated>
    <id>tag:github.com,2023-04-09:/Michael-K-Stein/SpotiFile</id>
    <link href="https://github.com/Michael-K-Stein/SpotiFile" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Spotify scraper&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SpotiFile&lt;/h1&gt; &#xA;&lt;h2&gt;A simple and open source spotify scraper.&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;Python 3.8+&lt;/em&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;Make sure you have python 3.8 or above.&lt;br&gt; $ git clone &lt;a href=&#34;https://github.com/Michael-K-Stein/SpotiFile.git&#34;&gt;https://github.com/Michael-K-Stein/SpotiFile.git&lt;/a&gt;&lt;br&gt; $ cd SpotiFile&lt;br&gt; Now open config.py and setup your SP_KEY (Spotify has renamed this to sp_adid) and SP_DC tokens (&lt;a href=&#34;https://github.com/Michael-K-Stein/SpotiFile#sp_key--sp_dc-tokens&#34;&gt;see below&lt;/a&gt;)&lt;br&gt; $ python main.py&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;em&gt;DISCLAIMER: This script is intended for personal and non-commercial use only. The purpose of this script is to create datasets for training machine learning models. Any use of this script that violates Deezer&#39;s Terms of Use or infringes on its intellectual property rights is strictly prohibited. The writer of this script is not responsible for any illegal or unauthorized use of the script by third parties. Users of this script assume all responsibility for their actions and agree to use the script at their own risk.&lt;/em&gt;&lt;br&gt; &lt;em&gt;AVIS DE NON-RESPONSABILIT√â : Ce script est destin√© √† un usage personnel et non commercial uniquement. Le but de ce script est de cr√©er des ensembles de donn√©es pour entra√Æner des mod√®les d&#39;apprentissage automatique. Toute utilisation de ce script qui viole les Conditions d&#39;utilisation de Deezer ou porte atteinte √† ses droits de propri√©t√© intellectuelle est strictement interdite en vertu de la loi fran√ßaise. L&#39;auteur de ce script n&#39;est pas responsable de toute utilisation ill√©gale ou non autoris√©e du script par des tiers. Les utilisateurs de ce script assument toutes les responsabilit√©s de leurs actions et conviennent de l&#39;utiliser √† leurs propres risques.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;What?&lt;/h2&gt; &#xA;&lt;p&gt;SpotiFile is a script which allows users to simply and easily, using a web-gui, scrape on Spotify playlists, albums, artists, etc. More advanced usages can be done by importing the relevant classes (e.g.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from spotify_scraper import SpotifyScraper&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;) and then using IPython to access specific Spotify API features.&lt;/p&gt; &#xA;&lt;h3&gt;Advantages&lt;/h3&gt; &#xA;&lt;p&gt;The main advantage of using SpotiFile is that it completely circumvents all of Spotify&#39;s api call limmits and restrictions. Spotifile offers an API to communicate with Spotify&#39;s API as if it were a real user. This allows SpotiFile to download information en-masse quickly.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Why?&lt;/h2&gt; &#xA;&lt;p&gt;Downloading massive amounts of songs and meta data can help if you prefer listening to music offline, or if you are desgining a music server which runs on an airgapped network. &lt;em&gt;We do not encourage music piracy nor condone any illegal activity. SpotiFile is a usefull research tool. Usage of SpotiFile for other purposes is at the user&#39;s own risk. Be warned, we will not bear any responsibility for improper use of this educational software!&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Proper and legitimate uses of SpotiFile:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Scraping tracks to create datasets for machine learning models.&lt;/li&gt; &#xA; &lt;li&gt;Creating remixes (for personal use only!)&lt;/li&gt; &#xA; &lt;li&gt;Downloading music which no longer falls under copyright law (&lt;a href=&#34;https://www.copyright.gov/help/faq/faq-duration.html&#34;&gt;Generally, content who&#39;s original artist passed away over 70 years ago&lt;/a&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Please notice Spotify&#39;s User Guidelines, and make sure you understand them. See section 5;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;The following is not permitted for any reason whatsoever in relation to the Services and the material or content made available through the Services, or any part thereof: 5. &#34;crawling&#34; or &#34;scraping&#34;, whether manually or by automated means, or otherwise using any automated means (including bots, scrapers, and spiders), to view, access or collect information;&lt;/em&gt; Usage of this &#34;scraper&#34; is in violation of Spotify&#39;s User Guidelines. By using this code, you assume responsibility - as &lt;em&gt;you&lt;/em&gt; are the one &#34;scraping&#34; Spotify using automated means.&lt;/p&gt; &#xA;&lt;h3&gt;Please notice Deezer&#39;s Terms of Use, and make sure you understand them. See article 8 - Intellectual property;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;The Recordings on the Deezer Free Service are protected digital files by national and international copyright and neighboring rights. They may only therefore be listened to within a private or family setting. Any use for a non-private purpose will expose the Deezer Free User to civil and/or criminal proceedings. Any other use of the Recordings is strictly forbidden and more particularly any download or attempt to download, any transfer or attempt to transfer permanently or temporarily on the hard drive of a computer or any other device (notably music players), any burn or attempt to burn a CD or any other support are expressly forbidden. Any resale, exchange or renting of these files is strictly prohibited.&lt;/em&gt; Storing, or attempting to store files from Deezer is strictly prohibited. Use this software only to create, for personal use, a custom streaming app. Notice that you can only use this streaming app in a private or family setting. By using this code, you assume responsibility to perform only legal actions - such as &lt;em&gt;streaming&lt;/em&gt; music from Deezer for personal use.&lt;/p&gt; &#xA;&lt;h3&gt;Do adhere to your local laws regarding intellectual property!&lt;/h3&gt; &#xA;&lt;h4&gt;Notice: Local law (where this was written), explicitly permits reverse engeneering for non-commercial purposes.&lt;/h4&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;How?&lt;/h2&gt; &#xA;&lt;p&gt;SpotiFile starts its life by authenticating as a normal Spotify user, and then performs a wide range of conventional and unconventional API calls to Spotify in order to retrieve relevant information. SpotiFile does not actually download audio from Spotify, since they use proper DRM encryption to protect against piracy. Rather, SpotiFile finds the relevant audio file on Deezer, using the copyright id (ironically). Then SpotiFile downloads the &#34;encrypted&#34; audio file from Deezer, which failed to implement DRM properly. Credit for reversing Deezer&#39;s encryption goes to &lt;a href=&#34;https://git.fuwafuwa.moe/toad/ayeBot/src/branch/master/bot.py&#34;&gt;https://git.fuwafuwa.moe/toad/ayeBot/src/branch/master/bot.py&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://notabug.org/deezpy-dev/Deezpy/src/master/deezpy.py&#34;&gt;https://notabug.org/deezpy-dev/Deezpy/src/master/deezpy.py&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://www.reddit.com/r/deemix/&#34;&gt;https://www.reddit.com/r/deemix/&lt;/a&gt; (Original reversing algorithm has been taken down).&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Authenticating as a legitimate Spotify user.&lt;/li&gt; &#xA; &lt;li&gt;Scraping tracks from a playlist.&lt;/li&gt; &#xA; &lt;li&gt;Scraping tracks from an album.&lt;/li&gt; &#xA; &lt;li&gt;Scraping tracks from an artist.&lt;/li&gt; &#xA; &lt;li&gt;Scraping playlists from a user.&lt;/li&gt; &#xA; &lt;li&gt;Scraping playlists from a catergory.&lt;/li&gt; &#xA; &lt;li&gt;Scraping a track from a track url.&lt;/li&gt; &#xA; &lt;li&gt;Scraping artist images.&lt;/li&gt; &#xA; &lt;li&gt;Scraping popular playlists&#39; metadata and tracks.&lt;/li&gt; &#xA; &lt;li&gt;Premium user token snatching (experimental).&lt;/li&gt; &#xA; &lt;li&gt;Scraping song lyrics (time synced when possible).&lt;/li&gt; &#xA; &lt;li&gt;Scraping track metadata.&lt;/li&gt; &#xA; &lt;li&gt;Scraping category metadata.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;SP_KEY &amp;amp; SP_DC tokens&lt;/h2&gt; &#xA;&lt;p&gt;Obtaining sp_dc and sp_key cookies (sp_key is now called sp_adid) SpotiFile uses two cookies to authenticate against Spotify in order to have access to the required services. &lt;em&gt;Shoutout to @fondberg for the explanation &lt;a href=&#34;https://github.com/fondberg/spotcast&#34;&gt;https://github.com/fondberg/spotcast&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;To obtain the cookies, these different methods can be used:&lt;/p&gt; &#xA;&lt;h3&gt;Chrome based browser&lt;/h3&gt; &#xA;&lt;p&gt;Open a new Incognito window at &lt;a href=&#34;https://open.spotify.com&#34;&gt;https://open.spotify.com&lt;/a&gt; and login to Spotify. Press Command+Option+I (Mac) or Control+Shift+I or F12. This should open the developer tools menu of your browser. Go into the application section. In the menu on the left go int Storage/Cookies/open.spotify.com. Find the sp_dc and sp_key and copy the values. Close the window without logging out (Otherwise the cookies are made invalid).&lt;/p&gt; &#xA;&lt;h3&gt;Firefox based browser&lt;/h3&gt; &#xA;&lt;p&gt;Open a new Incognito window at &lt;a href=&#34;https://open.spotify.com&#34;&gt;https://open.spotify.com&lt;/a&gt; and login to Spotify. Press Command+Option+I (Mac) or Control+Shift+I or F12. This should open the developer tools menu of your browser. Go into the Storage section. (You might have to click on the right arrows to reveal the section). Select the Cookies sub-menu and then &lt;a href=&#34;https://open.spotify.com&#34;&gt;https://open.spotify.com&lt;/a&gt;. Find the sp_dc and sp_key and copy the values. Close the window without logging out (Otherwise the cookies are made invalid).&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Example usages:&lt;/h1&gt; &#xA;&lt;h2&gt;Using SpotiFile to create a song recommendation module based off song lyrics&#39; semantic similarity:&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from spotify_scraper import SpotifyScraper&#xA;import nltk&#xA;from nltk.corpus import stopwords&#xA;from sklearn.feature_extraction.text import TfidfVectorizer&#xA;from sklearn.metrics.pairwise import cosine_similarity&#xA;import sys&#xA;&#xA;&#xA;def semantic_similarity(paragraph1, paragraph2):&#xA;    # Preprocess text&#xA;    stop_words = set(stopwords.words(&#39;english&#39;))&#xA;    paragraph1 = &#39; &#39;.join([word.lower() for word in nltk.word_tokenize(paragraph1) if word.lower() not in stop_words])&#xA;    paragraph2 = &#39; &#39;.join([word.lower() for word in nltk.word_tokenize(paragraph2) if word.lower() not in stop_words])&#xA;&#xA;    # Compute similarity score&#xA;    tfidf_vectorizer = TfidfVectorizer()&#xA;    tfidf_matrix = tfidf_vectorizer.fit_transform([paragraph1, paragraph2])&#xA;    similarity_score = cosine_similarity(tfidf_matrix)[0][1]&#xA;&#xA;    return similarity_score&#xA;&#xA;&#xA;# Usage&#xA;scraper = SpotifyScraper()&#xA;&#xA;lyrics1 = &#39;\n&#39;.join(x[&#39;words&#39;] for x in scraper.get_lyrics(sys.argv[1])[&#39;lyrics&#39;][&#39;lines&#39;])&#xA;lyrics2 = &#39;\n&#39;.join(x[&#39;words&#39;] for x in scraper.get_lyrics(sys.argv[2])[&#39;lyrics&#39;][&#39;lines&#39;])&#xA;&#xA;sim = semantic_similarity(lyrics1, lyrics2)&#xA;&#xA;print(f&#39;The similarity between the two tracks is: {sim}&#39;)&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Legal&lt;/h3&gt; &#xA;&lt;p&gt;The use of a script to download music and lyrics from Deezer for personal use only, to create machine learning datasets for non-commercial use, is not illegal under French and Israeli law. The use of such a script falls under the doctrine of fair use or fair dealing, which allows individuals to make copies of copyrighted works for their own private and non-commercial use without requiring permission from the copyright owner.&lt;/p&gt; &#xA;&lt;p&gt;This interpretation is supported by precedent. In the case of Soci√©t√© Civile des Producteurs Phonographiques v. Delorme, the French Court of Cassation held that copying music for personal and non-commercial use is allowed under the doctrine of fair use. The court held that such copying did not infringe on the rights of the copyright owner as it did not compete with the original work or harm the market for the original work.&lt;/p&gt; &#xA;&lt;p&gt;Furthermore, the purpose of using the script is to create machine learning datasets for non-commercial use, which falls under the category of research and study. Many countries, including France and Israel, have exceptions to copyright infringement for the purposes of research and study, which allow individuals to use copyrighted works without the need for permission from the copyright owner.&lt;/p&gt; &#xA;&lt;p&gt;It is also worth noting that the script is not being used to distribute the copyrighted works to others or to make a profit, which reduces the likelihood of any significant harm to the copyright owner&#39;s rights.&lt;/p&gt; &#xA;&lt;p&gt;Finally, the disclaimer notice attached to the script explicitly states that the script is intended for personal and non-commercial use only, and that any use of the script that violates Deezer&#39;s Terms of Use or infringes on its intellectual property rights is strictly prohibited. The writer of the script has taken reasonable steps to ensure that users understand the limitations of the script and are aware that any unauthorized use is prohibited.&lt;/p&gt; &#xA;&lt;p&gt;In conclusion, the use of a script to download music and lyrics from Deezer for personal use only to create machine learning datasets for non-commercial use is legal under French and Israeli law. The doctrine of fair use and exceptions for research and study, as well as the absence of any significant harm to the copyright owner&#39;s rights and the presence of a clear disclaimer notice, support this interpretation.&lt;/p&gt;</summary>
  </entry>
</feed>