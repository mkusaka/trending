<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-27T01:35:59Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>apple/ml-ferret</title>
    <updated>2023-12-27T01:35:59Z</updated>
    <id>tag:github.com,2023-12-27:/apple/ml-ferret</id>
    <link href="https://github.com/apple/ml-ferret" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://raw.githubusercontent.com/apple/ml-ferret/main/figs/ferret_icon.png&#34; alt=&#34;Alt text for the image&#34; width=&#34;40&#34; height=&#34;45&#34;&gt; Ferret: Refer and Ground Anything Anywhere at Any Granularity&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;An End-to-End MLLM that Accept Any-Form Referring and Ground Anything in Response.&lt;/em&gt; [&lt;a href=&#34;https://arxiv.org/abs/2310.07704&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hxyou.github.io/&#34;&gt;Haoxuan You*&lt;/a&gt;, &lt;a href=&#34;https://haotian-zhang.github.io/&#34;&gt;Haotian Zhang*&lt;/a&gt;, &lt;a href=&#34;https://zhegan27.github.io/&#34;&gt;Zhe Gan&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=l1hP40AAAAAJ&amp;amp;hl=en&#34;&gt;Xianzhi Du&lt;/a&gt;, &lt;a href=&#34;https://zbwglory.github.io/&#34;&gt;Bowen Zhang&lt;/a&gt;, &lt;a href=&#34;https://www.cs.cmu.edu/~ziruiw/&#34;&gt;Zirui Wang&lt;/a&gt;, &lt;a href=&#34;http://llcao.net/&#34;&gt;Liangliang Cao&lt;/a&gt;, &lt;a href=&#34;https://www.ee.columbia.edu/~sfchang/&#34;&gt;Shih-Fu Chang&lt;/a&gt;, &lt;a href=&#34;https://sites.google.com/site/yinfeiyang/&#34;&gt;Yinfei Yang&lt;/a&gt; [*: equal contribution]&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/apple/ml-ferret/main/figs/ferret_fig_diagram_v2.png&#34; width=&#34;100%&#34;&gt; &lt;br&gt; Diagram of Ferret Model. &lt;/p&gt; &#xA;&lt;p&gt;Key Contributions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ferret Model - &lt;strong&gt;Hybrid Region Representation + Spatial-aware Visual Sampler&lt;/strong&gt; enable fine-grained and open-vocabulary referring and grounding in MLLM.&lt;/li&gt; &#xA; &lt;li&gt;GRIT Dataset (~1.1M) - A &lt;strong&gt;Large-scale, Hierarchical, Robust&lt;/strong&gt; ground-and-refer instruction tuning dataset.&lt;/li&gt; &#xA; &lt;li&gt;Ferret-Bench - A multimodal evaluation benchmark that jointly requires &lt;strong&gt;Referring/Grounding, Semantics, Knowledge, and Reasoning&lt;/strong&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Release&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[12/14] üî• We released the &lt;a href=&#34;https://raw.githubusercontent.com/apple/ml-ferret/main/#checkpoints&#34;&gt;checkpoints(7B, 13B)&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;[10/30] üî• We released the code of &lt;strong&gt;FERRET&lt;/strong&gt; model and &lt;a href=&#34;https://raw.githubusercontent.com/apple/ml-ferret/main/ferret/eval/ferret_gpt4_data&#34;&gt;Ferret-Bench&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Usage and License Notices&lt;/strong&gt;: The data, and code is intended and licensed for research use only. They are also restricted to uses that follow the license agreement of LLaMA, Vicuna and GPT-4. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should not be used outside of research purposes.&lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apple/ml-ferret/main/#install&#34;&gt;Install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apple/ml-ferret/main/#train&#34;&gt;Train&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apple/ml-ferret/main/#evaluation&#34;&gt;Evaluation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apple/ml-ferret/main/#demo&#34;&gt;Demo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repository and navigate to FERRET folder&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/apple/ml-ferret&#xA;cd ml-ferret&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Install Package&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;conda create -n ferret python=3.10 -y&#xA;conda activate ferret&#xA;pip install --upgrade pip  # enable PEP 660 support&#xA;pip install -e .&#xA;pip install pycocotools&#xA;pip install protobuf==3.20.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Install additional packages for training cases&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install ninja&#xA;pip install flash-attn --no-build-isolation&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Train&lt;/h2&gt; &#xA;&lt;p&gt;FERRET is trained on 8 A100 GPUs with 80GB memory. To train on fewer GPUs, you can reduce the &lt;code&gt;per_device_train_batch_size&lt;/code&gt; and increase the &lt;code&gt;gradient_accumulation_steps&lt;/code&gt; accordingly. Always keep the global batch size the same: &lt;code&gt;per_device_train_batch_size&lt;/code&gt; x &lt;code&gt;gradient_accumulation_steps&lt;/code&gt; x &lt;code&gt;num_gpus&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Hyperparameters&lt;/h3&gt; &#xA;&lt;p&gt;We use a similar set of hyperparameters as LLaVA(Vicuna) in finetuning.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Hyperparameter&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Global Batch Size&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Learning rate&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Epochs&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Max length&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Weight decay&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FERRET-7B&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;128&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;2e-5&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;3&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;2048&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FERRET-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;128&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;2e-5&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;3&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;2048&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Prepare Vicuna checkpoint and LLaVA&#39;s projector&lt;/h3&gt; &#xA;&lt;p&gt;Before you start, prepare our base model Vicuna, which is an instruction-tuned chatbot. Please download its weights following the instructions &lt;a href=&#34;https://github.com/lm-sys/FastChat#model-weights&#34;&gt;here&lt;/a&gt;. Vicuna v1.3 is used in FERRET.&lt;/p&gt; &#xA;&lt;p&gt;Then download LLaVA&#39;s first-stage pre-trained projector weight (&lt;a href=&#34;https://huggingface.co/liuhaotian/llava-336px-pretrain-vicuna-7b-v1.3&#34;&gt;7B&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3&#34;&gt;13B&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h3&gt;FERRET Training&lt;/h3&gt; &#xA;&lt;p&gt;The scripts are provided (&lt;a href=&#34;https://raw.githubusercontent.com/apple/ml-ferret/main/experiments/ferret_7b_train.sh&#34;&gt;7B&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/apple/ml-ferret/main/experiments/ferret_13b_train.sh&#34;&gt;13B&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h2&gt;Evaluation&lt;/h2&gt; &#xA;&lt;p&gt;Please see this &lt;a href=&#34;https://raw.githubusercontent.com/apple/ml-ferret/main/EVAL.md&#34;&gt;doc&lt;/a&gt; for the details.&lt;/p&gt; &#xA;&lt;h2&gt;Checkpoints&lt;/h2&gt; &#xA;&lt;p&gt;We extracted the &lt;code&gt;delta&lt;/code&gt; between our pre-trained model and Vicuna. Please first download weights of Vicuna following the &lt;a href=&#34;https://raw.githubusercontent.com/apple/ml-ferret/main/#prepare-vicuna-checkpoint-and-llavas-projector&#34;&gt;previous instruction&lt;/a&gt;. Then download our prepared offsets of weights: &lt;a href=&#34;https://docs-assets.developer.apple.com/ml-research/models/ferret/ferret-7b/ferret-7b-delta.zip&#34;&gt;7B&lt;/a&gt;, &lt;a href=&#34;https://docs-assets.developer.apple.com/ml-research/models/ferret/ferret-13b/ferret-13b-delta.zip&#34;&gt;13B&lt;/a&gt; using &lt;code&gt;wget&lt;/code&gt; or &lt;code&gt;curl&lt;/code&gt;, and unzip the downloaded offsets. Lastly, apply the offset to the Vicuna&#39;s weight by running the following script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;# 7B&#xA;python3 -m ferret.model.apply_delta \&#xA;    --base ./model/vicuna-7b-v1-3 \&#xA;    --target ./model/ferret-7b-v1-3 \&#xA;    --delta path/to/ferret-7b-delta&#xA;# 13B&#xA;python3 -m ferret.model.apply_delta \&#xA;    --base ./model/vicuna-13b-v1-3 \&#xA;    --target ./model/ferret-13b-v1-3 \&#xA;    --delta path/to/ferret-13b-delta&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Notices&lt;/strong&gt;: Apple&#39;s rights in the attached weight differentials are hereby licensed under the CC-BY-NC license. Apple makes no representations with regards to LLaMa or any other third party software, which are subject to their own terms.&lt;/p&gt; &#xA;&lt;p&gt;Please refer to the next section about how to set up a local demo with pre-trained weight.&lt;/p&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;To run our demo, you need to train FERRET and use the checkpoints locally. Gradio web UI is used. Please run the following commands one by one.&lt;/p&gt; &#xA;&lt;h4&gt;Launch a controller&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;python -m ferret.serve.controller --host 0.0.0.0 --port 10000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Launch a gradio web server.&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;python -m ferret.serve.gradio_web_server --controller http://localhost:10000 --model-list-mode reload --add_region_feature&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Launch a model worker&lt;/h4&gt; &#xA;&lt;p&gt;This is the worker that load the ckpt and do the inference on the GPU. Each worker is responsible for a single model specified in &lt;code&gt;--model-path&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;CUDA_VISIBLE_DEVICES=0 python -m ferret.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path ./checkpoints/FERRET-13B-v0 --add_region_feature&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Wait until the process finishes loading the model and you see &#34;Uvicorn running on ...&#34;. Now, refresh your Gradio web UI, and you will see the model you just launched in the model list.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/apple/ml-ferret/main/figs/ferret_demo.png&#34; width=&#34;105%&#34;&gt; &lt;br&gt; Example of Ferret Interactive Demo. &lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find Ferret useful, please cite using this BibTeX:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{you2023ferret,&#xA;  title={Ferret: Refer and Ground Anything Anywhere at Any Granularity},&#xA;  author={You, Haoxuan and Zhang, Haotian and Gan, Zhe and Du, Xianzhi and Zhang, Bowen and Wang, Zirui and Cao, Liangliang and Chang, Shih-Fu and Yang, Yinfei},&#xA;  journal={arXiv preprint arXiv:2310.07704},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/haotian-liu/LLaVA&#34;&gt;LLaVA&lt;/a&gt;: the codebase we built upon.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lm-sys/FastChat&#34;&gt;Vicuna&lt;/a&gt;: the LLM codebase.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>K3YOMI/Wall-of-Flippers</title>
    <updated>2023-12-27T01:35:59Z</updated>
    <id>tag:github.com,2023-12-27:/K3YOMI/Wall-of-Flippers</id>
    <link href="https://github.com/K3YOMI/Wall-of-Flippers" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Wall of Flippers is designed to find Flipper Zero devices using BLE (Bluetooth Low Energy)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Wall of Flippers (WoF)&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;                            YAao,                            &#xA;                             Y8888b, &#xA;                           ,oA8888888b,      &#xA;                     ,aaad8888888888888888bo,   &#xA;                  ,d888888888888888888888888888b,               &#xA;                ,888888888888888888888888888888888b,            &#xA;               d8888888888888888888888888888888888888,           &#xA;              d888888888888888888888888888888888888888b                 &#xA;             d888888P&#39;                    `Y88888888Íô® \,             &#xA;             88888P&#39;                    Ybaaaa888888  Íô® l          &#xA;            a8888&#39;                      `Y8888P&#39; `V888888    &#xA;          d8888888a                                `Y8888           &#xA;         AY/&#39;&#39; `\Y8b                                 ``Y8b&#xA;         Y&#39;      `YP                                    ~~&#xA; _       __      ____         ____   _________                           &#xA;| |     / /___ _/ / /  ____  / __/  / ____/ (_)___  ____  ___  __________&#xA;| | /| / / __ `/ / /  / __ \/ /_   / /_  / / / __ \/ __ \/ _ \/ ___/ ___/&#xA;| |/ |/ / /_/ / / /  / /_/ / __/  / __/ / / / /_/ / /_/ /  __/ /  (__  ) &#xA;|__/|__/\__,_/_/_/   \____/_/    /_/   /_/_/ .___/ .___/\___/_/  /____/ &#xA;                                          /_/   /_/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üí° Introduction&lt;/h2&gt; &#xA;&lt;p&gt;Wall of Flippers (WoF) is a Python based project designed for Bluetooth Low Energy (BTLE) exploration. Its primary functionality involves the discovery of the Flipper Zero device and the identification of potential BTLE based attacks. Please keep in mind this is a work in progress and will still continue to get updates.&lt;/p&gt; &#xA;&lt;h2&gt;üõ†Ô∏è Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Flipper Zero Detection (BT Must be Enabled)&lt;/li&gt; &#xA; &lt;li&gt;Flipper Archiving (Saving Past Data)&lt;/li&gt; &#xA; &lt;li&gt;Bluetooth Low Energy Attacks &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;iOS Crash and Popup BTLE Detection&lt;/li&gt; &#xA;   &lt;li&gt;Android Crash and Popup BTLE Detection&lt;/li&gt; &#xA;   &lt;li&gt;Windows Swift Pair BTLE Detection&lt;/li&gt; &#xA;   &lt;li&gt;LoveSpouse BTLE Detection&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/K3YOMI/Wall-of-Flippers/assets/54733885/9e0aeef5-962e-4e0c-b4d5-0b6163441c5c&#34; alt=&#34;ezgif-4-eadf27922b&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;üí° Future Improvements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GoLang Support&lt;/li&gt; &#xA; &lt;li&gt;hcidump / hcitool support&lt;/li&gt; &#xA; &lt;li&gt;Capture the Flippers??? üëÄ&lt;/li&gt; &#xA; &lt;li&gt;Built-in BLE Exploitation&lt;/li&gt; &#xA; &lt;li&gt;Auto-install Functionality&lt;/li&gt; &#xA; &lt;li&gt;Suspicious BLE Advertisements&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìö Documentation&lt;/h2&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;p&gt;A few things are required to properly run WoF. We Recommend the Raspberry Pi as its compact and portable! Additionally, it&#39;s also required to have a &lt;code&gt;chipset&lt;/code&gt; or a USB &lt;code&gt;adapter&lt;/code&gt; that supports BTLE. Additionally, we also now have &lt;em&gt;limited&lt;/em&gt; support for Windows and &lt;em&gt;full&lt;/em&gt; support for linux at this time.&lt;/p&gt; &#xA;&lt;h2&gt;Linux Install Guide&lt;/h2&gt; &#xA;&lt;p&gt;Another &lt;code&gt;requirement&lt;/code&gt; is Python. Debian based install:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get install python3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Additionally, bluepy &lt;code&gt;requires&lt;/code&gt; the &lt;code&gt;libglib2.0-dev&lt;/code&gt; library to be installed. Debian based install:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo apt-get install python3-pip libglib2.0-dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, &lt;code&gt;bluepy&lt;/code&gt; is required. This can be installed with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo pip3 install bluepy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;Your install may look different depending if python3 is used&lt;/em&gt;&lt;br&gt; &lt;em&gt;Additionally, if you are having trouble. Feel free to visit this repo for better documentation: &lt;a href=&#34;https://github.com/IanHarvey/bluepy/&#34;&gt;https://github.com/IanHarvey/bluepy/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Git Clone and Running&lt;/h3&gt; &#xA;&lt;p&gt;Alright, it&#39;s fun for the fun install process. Downloading WoF is quite straightforward as it&#39;s a few commands. I&#39;d recommend using &lt;code&gt;git&lt;/code&gt; as this command can be easily used to retrieve the repository. Otherwise, just donwload via GitHub.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/K3YOMI/Wall-of-Flippers&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After installing, navigate to the Wall of Flippers directory&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd ./Wall\ of\ Flippers&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, run under &lt;code&gt;sudo&lt;/code&gt; as this part is required to properly use the &lt;code&gt;pyblue&lt;/code&gt; functionality.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ sudo python3 WallofFlippers.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Windows Install Guide&lt;/h2&gt; &#xA;&lt;p&gt;Another &lt;code&gt;requirement&lt;/code&gt; is Python. Windows Based Below:&lt;br&gt; &lt;a href=&#34;https://www.python.org/&#34;&gt;https://www.python.org/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;bleak&lt;/code&gt; is required. This can be installed with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pip install bleak&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Additional commands may need to be ran for pip to run properly. see: &lt;a href=&#34;https://stackoverflow.com/questions/23708898/pip-is-not-recognized-as-an-internal-or-external-command&#34;&gt;https://stackoverflow.com/questions/23708898/pip-is-not-recognized-as-an-internal-or-external-command&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Your install may look different depending if py is used&lt;/em&gt;&lt;br&gt; &lt;em&gt;Additionally, if you are having trouble. Feel free to visit this repo for better documentation: &lt;a href=&#34;https://github.com/hbldh/bleak&#34;&gt;https://github.com/hbldh/bleak&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Git Clone and Running&lt;/h3&gt; &#xA;&lt;p&gt;Alright, it&#39;s fun for the fun install process. Downloading WoF is quite straightforward as it&#39;s a few commands. I&#39;d recommend using &lt;code&gt;git&lt;/code&gt; as this command can be easily used to retrieve the repository. Otherwise, just donwload via GitHub.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/K3YOMI/Wall-of-Flippers&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After installing, navigate to the Wall of Flippers directory&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd ./Wall\ of\ Flippers&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, run this command below to start the python script and wallah! You are now running Wall of Flippers!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ py WallofFlippers.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Conclusion&lt;/h3&gt; &#xA;&lt;p&gt;Tad-ah! You are now properly running WoF on your device. Hopefully this small guide works and gets you started on collecting flippers or checking for BTLE based attacks. Feel free to report bugs as this can help improve WoF. You can modify, release, or use Wall of Flippers in any way you want as long as proper credit is given to &lt;code&gt;emilia (jbohack)&lt;/code&gt; and &lt;code&gt;k3yomi (kiyomi)&lt;/code&gt;. Thank you!&lt;/p&gt; &#xA;&lt;h2&gt;Notice (Please Read)&lt;/h2&gt; &#xA;&lt;p&gt;This project isn&#39;t the solution for catching every Bluetooth Low Energy (BLE) attack or Flipper Zero device. Users can easily dodge detection by changing their device&#39;s MAC address or name, or simply turning off Bluetooth. The main purpose here is keeping track of activity to catch a few &#34;script kiddies&#34; now and then. It&#39;s not foolproof, but it&#39;s a useful tool for identifying issues and figuring out how often devices are being misused. The real goal is to encourage updates for vulnerable devices, so they can&#39;t be exploited in the future. While this project doesn&#39;t stop attacks, logging is a crucial step in understanding device issues and abuse patterns. If you have any questions or concerns about bluetooth or the project itself, don&#39;t hesitate to reach out to me!&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/K3YOMI/Wall-of-Flippers/assets/54733885/a146acc6-7786-4406-b818-36a48b29473d&#34; alt=&#34;Untitled2&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Support Kiyomi (Developer)&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ko-fi.com/k3yomi&#34;&gt;&lt;img src=&#34;https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true&#34; alt=&#34;ko-fi&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Support Emilia (Contributor)&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ko-fi.com/emilia0001&#34;&gt;&lt;img src=&#34;https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true&#34; alt=&#34;ko-fi&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Gourieff/comfyui-reactor-node</title>
    <updated>2023-12-27T01:35:59Z</updated>
    <id>tag:github.com,2023-12-27:/Gourieff/comfyui-reactor-node</id>
    <link href="https://github.com/Gourieff/comfyui-reactor-node" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Fast and Simple Face Swap Extension Node for ComfyUI&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/Gourieff/Assets/raw/main/sd-webui-reactor/ReActor_logo_NEW_EN.png?raw=true&#34; alt=&#34;logo&#34; width=&#34;180px&#34;&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/node_version-0.4.1_beta4-green?style=for-the-badge&amp;amp;labelColor=darkgreen&#34; alt=&#34;Version&#34;&gt;&lt;/p&gt; &#xA; &lt;sup&gt; &lt;font color=&#34;brightred&#34;&gt; &lt;h2&gt;!!! &lt;a href=&#34;https://raw.githubusercontent.com/Gourieff/comfyui-reactor-node/main/#latestupdate&#34;&gt;Important Update&lt;/a&gt; !!!&lt;br&gt;Don&#39;t forget to add the Node again in existing workflows&lt;/h2&gt; &lt;/font&gt; &lt;/sup&gt; &#xA; &lt;a href=&#34;https://boosty.to/artgourieff&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://lovemet.ru/www/boosty.jpg&#34; width=&#34;108&#34; alt=&#34;Support Me on Boosty&#34;&gt; &lt;br&gt; &lt;sup&gt; Support This Project &lt;/sup&gt; &lt;/a&gt; &#xA; &lt;hr&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/Gourieff/comfyui-reactor-node/commits/main&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/commit-activity/t/Gourieff/comfyui-reactor-node/main?cacheSeconds=0&#34; alt=&#34;Commit activity&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/last-commit/Gourieff/comfyui-reactor-node/main?cacheSeconds=0&#34; alt=&#34;Last commit&#34;&gt; &lt;a href=&#34;https://github.com/Gourieff/comfyui-reactor-node/issues?cacheSeconds=0&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/Gourieff/comfyui-reactor-node?color=red&#34; alt=&#34;Opened issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Gourieff/comfyui-reactor-node/issues?q=is%3Aissue+is%3Aclosed&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-closed/Gourieff/comfyui-reactor-node?color=green&amp;amp;cacheSeconds=0&#34; alt=&#34;Closed issues&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/license/Gourieff/comfyui-reactor-node&#34; alt=&#34;License&#34;&gt;&lt;/p&gt; &#xA; &lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/Gourieff/comfyui-reactor-node/main/README_RU.md&#34;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h1&gt;ReActor Node for ComfyUI&lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;The Fast and Simple Face Swap Extension Node for ComfyUI, based on &lt;a href=&#34;https://github.com/Gourieff/sd-webui-reactor&#34;&gt;ReActor&lt;/a&gt; SD-WebUI Face Swap Extension&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;This Node goes without NSFW filter (uncensored, use it on your own &lt;a href=&#34;https://raw.githubusercontent.com/Gourieff/comfyui-reactor-node/main/#disclaimer&#34;&gt;responsibility&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;hr&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Gourieff/comfyui-reactor-node/main/#latestupdate&#34;&gt;&lt;strong&gt;What&#39;s new&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/Gourieff/comfyui-reactor-node/main/#installation&#34;&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/Gourieff/comfyui-reactor-node/main/#usage&#34;&gt;&lt;strong&gt;Usage&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/Gourieff/comfyui-reactor-node/main/#troubleshooting&#34;&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/Gourieff/comfyui-reactor-node/main/#updating&#34;&gt;&lt;strong&gt;Updating&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/Gourieff/comfyui-reactor-node/main/#disclaimer&#34;&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/Gourieff/comfyui-reactor-node/main/#note&#34;&gt;&lt;strong&gt;Note!&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;hr&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/Gourieff/Assets/raw/main/comfyui-reactor-node/uploads/demo.gif?raw=true&#34; alt=&#34;demo&#34; width=&#34;100%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;a name=&#34;latestupdate&#34;&gt; &lt;h2&gt;What&#39;s new in the latest update&lt;/h2&gt; &lt;h3&gt;0.4.1 &lt;sub&gt;&lt;sup&gt;BETA1&lt;/sup&gt;&lt;/sub&gt;&lt;/h3&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Face Restore Visibility and CodeFormer Weight (Fidelity) options are now available! Don&#39;t forget to reload the Node in your existing workflow&lt;/li&gt; &#xA; &lt;/ul&gt; &lt;img src=&#34;https://github.com/Gourieff/Assets/raw/main/comfyui-reactor-node/0.4.1-whatsnew-01.jpg?raw=true&#34; alt=&#34;0.4.1-whatsnew-01&#34; width=&#34;100%&#34;&gt; &lt;h3&gt;0.4.0&lt;/h3&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Input &#34;input_image&#34; goes first now, it gives a correct bypass and also it is right to have the main input first;&lt;/li&gt; &#xA;  &lt;li&gt;You can now save face models as &#34;safetensors&#34; files (&lt;code&gt;ComfyUI\models\reactor\faces&lt;/code&gt;) and load them into ReActor implementing different scenarios and keeping super lightweight face models of the faces you use:&lt;/li&gt; &#xA; &lt;/ul&gt; &lt;img src=&#34;https://github.com/Gourieff/Assets/raw/main/comfyui-reactor-node/0.4.0-whatsnew-01.jpg?raw=true&#34; alt=&#34;0.4.0-whatsnew-01&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://github.com/Gourieff/Assets/raw/main/comfyui-reactor-node/0.4.0-whatsnew-02.jpg?raw=true&#34; alt=&#34;0.4.0-whatsnew-02&#34; width=&#34;100%&#34;&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Ability to build and save face models directly from an image:&lt;/li&gt; &#xA; &lt;/ul&gt; &lt;img src=&#34;https://github.com/Gourieff/Assets/raw/main/comfyui-reactor-node/0.4.0-whatsnew-03.jpg?raw=true&#34; alt=&#34;0.4.0-whatsnew-03&#34; width=&#34;50%&#34;&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Both the inputs are optional, just connect one of them according to your workflow; if both is connected - &lt;code&gt;image&lt;/code&gt; has a priority.&lt;/li&gt; &#xA;  &lt;li&gt;Different fixes making this extension better.&lt;/li&gt; &#xA; &lt;/ul&gt; &lt;p&gt;Thanks to everyone who finds bugs, suggests new features and supports this project!&lt;/p&gt; &lt;h2&gt;Installation&lt;/h2&gt; &lt;/a&gt;&#xA;&lt;details&gt;&#xA; &lt;a name=&#34;latestupdate&#34;&gt; &lt;summary&gt;SD WebUI: &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/&#34;&gt;AUTOMATIC1111&lt;/a&gt; or &lt;a href=&#34;https://github.com/vladmandic/automatic&#34;&gt;SD.Next&lt;/a&gt;&lt;/summary&gt;&lt;/a&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Close (stop) your SD-WebUI/Comfy Server if it&#39;s running&lt;/li&gt; &#xA;  &lt;li&gt;(For Windows Users): &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Install &lt;a href=&#34;https://visualstudio.microsoft.com/downloads/&#34;&gt;Visual Studio 2022&lt;/a&gt; (Community version - you need this step to build Insightface)&lt;/li&gt; &#xA;    &lt;li&gt;OR only &lt;a href=&#34;https://visualstudio.microsoft.com/visual-cpp-build-tools/&#34;&gt;VS C++ Build Tools&lt;/a&gt; and select &#34;Desktop Development with C++&#34; under &#34;Workloads -&amp;gt; Desktop &amp;amp; Mobile&#34;&lt;/li&gt; &#xA;    &lt;li&gt;OR if you don&#39;t want to install VS or VS C++ BT - follow &lt;a href=&#34;https://raw.githubusercontent.com/Gourieff/comfyui-reactor-node/main/#insightfacebuild&#34;&gt;this steps (sec. I)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;Go to the &lt;code&gt;extensions\sd-webui-comfyui\ComfyUI\custom_nodes&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Open Console or Terminal and run &lt;code&gt;git clone https://github.com/Gourieff/comfyui-reactor-node&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Go to the SD WebUI root folder, open Console or Terminal and run (Windows users)&lt;code&gt;.\venv\Scripts\activate&lt;/code&gt; or (Linux/MacOS)&lt;code&gt;venv/bin/activate&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;python -m pip install -U pip&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;cd extensions\sd-webui-comfyui\ComfyUI\custom_nodes\comfyui-reactor-node&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;python install.py&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Please, wait until the installation process will be finished&lt;/li&gt; &#xA;  &lt;li&gt;(From the version 0.3.0) Download facerestorers models from the links below and put them into the &lt;code&gt;extensions\sd-webui-comfyui\ComfyUI\custom_nodes\comfyui-reactor-node\models\facerestore_models&lt;/code&gt; directory: &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;CodeFormer: &lt;a href=&#34;https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/codeformer.pth&#34;&gt;https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/codeformer.pth&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;GFPGAN: &lt;a href=&#34;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/GFPGANv1.4.pth&#34;&gt;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/GFPGANv1.4.pth&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;Run SD WebUI and check console for the message that ReActor Node is running:&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;img src=&#34;https://github.com/Gourieff/Assets/raw/main/comfyui-reactor-node/uploads/console_status_running.jpg?raw=true&#34; alt=&#34;console_status_running&#34; width=&#34;759&#34;&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Go to the ComfyUI tab and find there ReActor Node inside the menu &lt;code&gt;ReActor&lt;/code&gt; or by using a search:&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;img src=&#34;https://github.com/Gourieff/Assets/raw/main/comfyui-reactor-node/uploads/webui-demo.png?raw=true&#34; alt=&#34;webui-demo&#34; width=&#34;100%&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/Gourieff/Assets/raw/main/comfyui-reactor-node/uploads/search-demo.png?raw=true&#34; alt=&#34;webui-demo&#34; width=&#34;1043&#34;&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Standalone (Portable) &lt;a href=&#34;https://github.com/comfyanonymous/ComfyUI&#34;&gt;ComfyUI&lt;/a&gt; for Windows&lt;/summary&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Do the following: &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Install &lt;a href=&#34;https://visualstudio.microsoft.com/downloads/&#34;&gt;Visual Studio 2022&lt;/a&gt; (Community version - you need this step to build Insightface)&lt;/li&gt; &#xA;    &lt;li&gt;OR only &lt;a href=&#34;https://visualstudio.microsoft.com/visual-cpp-build-tools/&#34;&gt;VS C++ Build Tools&lt;/a&gt; and select &#34;Desktop Development with C++&#34; under &#34;Workloads -&amp;gt; Desktop &amp;amp; Mobile&#34;&lt;/li&gt; &#xA;    &lt;li&gt;OR if you don&#39;t want to install VS or VS C++ BT - follow &lt;a href=&#34;https://raw.githubusercontent.com/Gourieff/comfyui-reactor-node/main/#insightfacebuild&#34;&gt;this steps (sec. I)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;Go to the &lt;code&gt;ComfyUI\custom_nodes&lt;/code&gt; directory&lt;/li&gt; &#xA;  &lt;li&gt;Open Console and run &lt;code&gt;git clone https://github.com/Gourieff/comfyui-reactor-node&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Run &lt;code&gt;install.bat&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;(From the version 0.3.0) Download facerestorers models from the links below and put them into the &lt;code&gt;ComfyUI\models\facerestore_models&lt;/code&gt; directory: &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;CodeFormer: &lt;a href=&#34;https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/codeformer.pth&#34;&gt;https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/codeformer.pth&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;GFPGAN: &lt;a href=&#34;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/GFPGANv1.4.pth&#34;&gt;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/GFPGANv1.4.pth&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;Run ComfyUI and find there ReActor Node inside the menu &lt;code&gt;ReActor&lt;/code&gt; or by using a search&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;You can find ReActor Nodes inside the menu &lt;code&gt;ReActor&lt;/code&gt; or by using a search (just type &#34;ReActor&#34; in the search field)&lt;/p&gt; &#xA;&lt;p&gt;List of Nodes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ReActorFaceSwap (Main Node)&lt;/li&gt; &#xA; &lt;li&gt;ReActorLoadFaceModel (Load Face Model)&lt;/li&gt; &#xA; &lt;li&gt;ReActorSaveFaceModel (Save Face Model)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Connect all required slots and run the query.&lt;/p&gt; &#xA;&lt;h3&gt;Main Node Inputs&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;input_image&lt;/code&gt; - is an image to be processed (target image, analog of &#34;target image&#34; in the SD WebUI extension); &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Supported Nodes: &#34;Load Image&#34;, &#34;Load Video&#34; or any other nodes providng images as an output;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;source_image&lt;/code&gt; - is an image with a face or faces to swap in the &lt;code&gt;input_image&lt;/code&gt; (source image, analog of &#34;source image&#34; in the SD WebUI extension); &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Supported Nodes: &#34;Load Image&#34;;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;face_model&lt;/code&gt; - is the input for the &#34;Load Face Model&#34; Node or another ReActor node to provide a face model file (face embedding) you created earlier via the &#34;Save Face Model&#34; Node; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Supported Nodes: &#34;Load Face Model&#34;;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Main Node Outputs&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;IMAGE&lt;/code&gt; - is an output with the resulted image; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Supported Nodes: any nodes which have images as an input;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;FACE_MODEL&lt;/code&gt; - is an output providng a source face&#39;s model being built during the swapping process; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Supported Nodes: &#34;Save Face Model&#34;, &#34;ReActor&#34;;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Face Restoration&lt;/h3&gt; &#xA;&lt;p&gt;Since version 0.3.0 ReActor Node has a buil-in face restoration.&lt;br&gt;Just download the models you want (see &lt;a href=&#34;https://raw.githubusercontent.com/Gourieff/comfyui-reactor-node/main/#installation&#34;&gt;Installation&lt;/a&gt; instruction) and select one of them to restore the resulting face(s) during the faceswap. It will enhance face details and make your result more accurate.&lt;/p&gt; &#xA;&lt;h3&gt;Face Indexes&lt;/h3&gt; &#xA;&lt;p&gt;ReActor detects faces in images in the following order:&lt;br&gt;left-&amp;gt;right, top-&amp;gt;bottom&lt;/p&gt; &#xA;&lt;p&gt;And if you need to specify faces, you can set indexes for source and input images.&lt;/p&gt; &#xA;&lt;p&gt;Index of the first detected face is 0.&lt;/p&gt; &#xA;&lt;p&gt;You can set indexes in the order you need.&lt;br&gt; E.g.: 0,1,2 (for Source); 1,0,2 (for Input).&lt;br&gt;This means: the second Input face (index = 1) will be swapped by the first Source face (index = 0) and so on.&lt;/p&gt; &#xA;&lt;h3&gt;Genders&lt;/h3&gt; &#xA;&lt;p&gt;You can specify the gender to detect in images.&lt;br&gt; ReActor will swap a face only if it meets the given condition.&lt;/p&gt; &#xA;&lt;h3&gt;Face Models&lt;/h3&gt; &#xA;&lt;p&gt;Since version 0.4.0 you can save face models as &#34;safetensors&#34; files (stored in &lt;code&gt;ComfyUI\models\reactor\faces&lt;/code&gt;) and load them into ReActor implementing different scenarios and keeping super lightweight face models of the faces you use.&lt;/p&gt; &#xA;&lt;p&gt;To make new models appear in the list of the &#34;Load Face Model&#34; Node - just refresh the page of your ComfyUI web application.&lt;br&gt; (I recommend you to use ComfyUI Manager - otherwise you workflow can be lost after you refresh the page if you didn&#39;t save it before that).&lt;/p&gt; &#xA;&lt;h2&gt;Troubleshooting&lt;/h2&gt; &#xA;&lt;a name=&#34;insightfacebuild&#34;&gt; &lt;h3&gt;&lt;strong&gt;I. (For Windows users) If you still cannot build Insightface for some reasons or just don&#39;t want to install Visual Studio or VS C++ Build Tools - do the following:&lt;/strong&gt;&lt;/h3&gt; &lt;/a&gt;&#xA;&lt;ol&gt;&#xA; &lt;a name=&#34;insightfacebuild&#34;&gt; &lt;li&gt;(ComfyUI Portable) From the root folder check the version of Python:&lt;br&gt;run CMD and type &lt;code&gt;python_embeded\python.exe -V&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Download prebuilt Insightface package &lt;a href=&#34;https://github.com/Gourieff/Assets/raw/main/Insightface/insightface-0.7.3-cp310-cp310-win_amd64.whl&#34;&gt;for Python 3.10&lt;/a&gt; or &lt;a href=&#34;https://github.com/Gourieff/Assets/raw/main/Insightface/insightface-0.7.3-cp311-cp311-win_amd64.whl&#34;&gt;for Python 3.11&lt;/a&gt; (if in the previous step you see 3.11) and put into the stable-diffusion-webui (A1111 or SD.Next) root folder (where you have &#34;webui-user.bat&#34; file) or into ComfyUI root folder if you use ComfyUI Portable&lt;/li&gt;&lt;/a&gt; &#xA; &lt;li&gt;From the root folder run: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;(SD WebUI) CMD and &lt;code&gt;.\venv\Scripts\activate&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;(ComfyUI Portable) run CMD&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Then update your PIP: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;(SD WebUI) &lt;code&gt;python -m pip install -U pip&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;(ComfyUI Portable) &lt;code&gt;python_embeded\python.exe -m pip install -U pip&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Then install Insightface: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;(SD WebUI) &lt;code&gt;pip install insightface-0.7.3-cp310-cp310-win_amd64.whl&lt;/code&gt; (for 3.10) or &lt;code&gt;pip install insightface-0.7.3-cp311-cp311-win_amd64.whl&lt;/code&gt; (for 3.11)&lt;/li&gt; &#xA;   &lt;li&gt;(ComfyUI Portable) &lt;code&gt;python_embeded\python.exe -m pip install insightface-0.7.3-cp310-cp310-win_amd64.whl&lt;/code&gt; (for 3.10) or &lt;code&gt;python_embeded\python.exe -m pip install insightface-0.7.3-cp311-cp311-win_amd64.whl&lt;/code&gt; (for 3.11)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Enjoy!&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;&lt;strong&gt;II. &#34;AttributeError: &#39;NoneType&#39; object has no attribute &#39;get&#39;&#34;&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;This error may occur if there&#39;s smth wrong with the model file &lt;code&gt;inswapper_128.onnx&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Try to download it manually from &lt;a href=&#34;https://github.com/facefusion/facefusion-assets/releases/download/models/inswapper_128.onnx&#34;&gt;here&lt;/a&gt; and put it to the &lt;code&gt;ComfyUI\models\insightface&lt;/code&gt; replacing existing one&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;III. &#34;reactor.execute() got an unexpected keyword argument &#39;reference_image&#39;&#34;&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;This means that input points have been changed with the latest update&lt;br&gt; Remove the current ReActor Node from your workflow and add it again&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;IV. ControlNet Aux Node IMPORT failed error when using with ReActor Node&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Close ComfyUI if it runs&lt;/li&gt; &#xA; &lt;li&gt;Go to the ComfyUI root folder, open CMD there and run: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;python_embeded\python.exe -m pip uninstall -y opencv-python opencv-contrib-python opencv-python-headless&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;python_embeded\python.exe -m pip install opencv-python==4.7.0.72&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;That&#39;s it!&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://github.com/Gourieff/Assets/raw/main/comfyui-reactor-node/uploads/reactor-w-controlnet.png?raw=true&#34; alt=&#34;reactor+controlnet&#34;&gt; &#xA;&lt;h3&gt;&lt;strong&gt;V. &#34;ModuleNotFoundError: No module named &#39;basicsr&#39;&#34; or &#34;subprocess-exited-with-error&#34; during future-0.18.3 installation&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Download &lt;a href=&#34;https://github.com/Gourieff/Assets/raw/main/comfyui-reactor-node/future-0.18.3-py3-none-any.whl&#34;&gt;https://github.com/Gourieff/Assets/raw/main/comfyui-reactor-node/future-0.18.3-py3-none-any.whl&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Put it to ComfyUI root And run:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python_embeded\python.exe -m pip install future-0.18.3-py3-none-any.whl&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Then:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python_embeded\python.exe -m pip install basicsr&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;strong&gt;VI. &#34;fatal: fetch-pack: invalid index-pack output&#34; when you try to &lt;code&gt;git clone&lt;/code&gt; the repository&#34;&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Try to clone with &lt;code&gt;--depth=1&lt;/code&gt; (last commit only):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt; git clone --depth=1 https://github.com/Gourieff/comfyui-reactor-node&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then retrieve the rest (if you need):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt; git fetch --unshallow&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Updating&lt;/h2&gt; &#xA;&lt;p&gt;Just put .bat or .sh script from this &lt;a href=&#34;https://github.com/Gourieff/sd-webui-extensions-updater&#34;&gt;Repo&lt;/a&gt; to the &lt;code&gt;ComfyUI\custom_nodes&lt;/code&gt; directory and run it when you need to check for updates&lt;/p&gt; &#xA;&lt;h3&gt;Disclaimer&lt;/h3&gt; &#xA;&lt;p&gt;This software is meant to be a productive contribution to the rapidly growing AI-generated media industry. It will help artists with tasks such as animating a custom character or using the character as a model for clothing etc.&lt;/p&gt; &#xA;&lt;p&gt;The developers of this software are aware of its possible unethical applicaitons and are committed to take preventative measures against them. We will continue to develop this project in the positive direction while adhering to law and ethics.&lt;/p&gt; &#xA;&lt;p&gt;Users of this software are expected to use this software responsibly while abiding the local law. If face of a real person is being used, users are suggested to get consent from the concerned person and clearly mention that it is a deepfake when posting content online. &lt;strong&gt;Developers and Contributors of this software are not responsible for actions of end-users.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;By using this extension you are agree not to create any content that:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;violates any laws;&lt;/li&gt; &#xA; &lt;li&gt;causes any harm to a person or persons;&lt;/li&gt; &#xA; &lt;li&gt;propogates (spreads) any information (both public or personal) or images (both public or personal) which could be meant for harm;&lt;/li&gt; &#xA; &lt;li&gt;spreads misinformation;&lt;/li&gt; &#xA; &lt;li&gt;targets vulnerable groups of people.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This software utilizes the pre-trained models &lt;code&gt;buffalo_l&lt;/code&gt; and &lt;code&gt;inswapper_128.onnx&lt;/code&gt;, which are provided by &lt;a href=&#34;https://github.com/deepinsight/insightface/&#34;&gt;InsightFace&lt;/a&gt;. These models are included under the following conditions:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/deepinsight/insightface/tree/master/python-package&#34;&gt;From insighface licence&lt;/a&gt;: The InsightFace‚Äôs pre-trained models are available for non-commercial research purposes only. This includes both auto-downloading models and manually downloaded models.&lt;/p&gt; &#xA;&lt;p&gt;Users of this software must strictly adhere to these conditions of use. The developers and maintainers of this software are not responsible for any misuse of InsightFace‚Äôs pre-trained models.&lt;/p&gt; &#xA;&lt;p&gt;Please note that if you intend to use this software for any commercial purposes, you will need to train your own models or find models that can be used commercially.&lt;/p&gt; &#xA;&lt;h3&gt;Models Hashsum&lt;/h3&gt; &#xA;&lt;h4&gt;Safe-to-use models have the folowing hash:&lt;/h4&gt; &#xA;&lt;p&gt;inswapper_128.onnx&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;MD5:a3a155b90354160350efd66fed6b3d80&#xA;SHA256:e4a3f08c753cb72d04e10aa0f7dbe3deebbf39567d4ead6dce08e98aa49e16af&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;1k3d68.onnx&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;MD5:6fb94fcdb0055e3638bf9158e6a108f4&#xA;SHA256:df5c06b8a0c12e422b2ed8947b8869faa4105387f199c477af038aa01f9a45cc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;2d106det.onnx&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;MD5:a3613ef9eb3662b4ef88eb90db1fcf26&#xA;SHA256:f001b856447c413801ef5c42091ed0cd516fcd21f2d6b79635b1e733a7109dbf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;det_10g.onnx&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;MD5:4c10eef5c9e168357a16fdd580fa8371&#xA;SHA256:5838f7fe053675b1c7a08b633df49e7af5495cee0493c7dcf6697200b85b5b91&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;genderage.onnx&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;MD5:81c77ba87ab38163b0dec6b26f8e2af2&#xA;SHA256:4fde69b1c810857b88c64a335084f1c3fe8f01246c9a191b48c7bb756d6652fb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;w600k_r50.onnx&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;MD5:80248d427976241cbd1343889ed132b3&#xA;SHA256:4c06341c33c2ca1f86781dab0e829f88ad5b64be9fba56e56bc9ebdefc619e43&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please check hashsums if you download these models from unverified (or untrusted) sources&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;a name=&#34;note&#34;&gt; &lt;h3&gt;Note!&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;If you encounter any errors when you use ReActor Node - don&#39;t rush to open an issue, first try to remove current ReActor node in your workflow and add it again&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;ReActor Node gets updates from time to time, new functions appears and old node can work with errors or not work at all&lt;/strong&gt;&lt;/p&gt; &lt;/a&gt;</summary>
  </entry>
</feed>