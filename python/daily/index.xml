<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-21T01:31:47Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>lancedb/lancedb</title>
    <updated>2024-05-21T01:31:47Z</updated>
    <id>tag:github.com,2024-05-21:/lancedb/lancedb</id>
    <link href="https://github.com/lancedb/lancedb" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Developer-friendly, serverless vector database for AI applications. Easily add long-term memory to your LLM apps!&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;275&#34; alt=&#34;LanceDB Logo&#34; src=&#34;https://github.com/lancedb/lancedb/assets/5846846/37d7c7ad-c2fd-4f56-9f16-fffb0d17c73a&#34;&gt; &lt;/p&gt;&#xA; &lt;p&gt;&lt;strong&gt;Developer-friendly, database for multimodal AI&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/lancedb/vectordb-recipes/tree/main&#34; target=&#34;_blank&#34;&gt;&lt;img alt=&#34;LanceDB&#34; src=&#34;https://img.shields.io/badge/VectorDB_Recipes-100000?style=for-the-badge&amp;amp;logo=LanceDB&amp;amp;logoColor=white&amp;amp;labelColor=645cfb&amp;amp;color=645cfb&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://lancedb.github.io/lancedb/&#34; target=&#34;_blank&#34;&gt;&lt;img alt=&#34;lancdb&#34; src=&#34;https://img.shields.io/badge/DOCS-100000?style=for-the-badge&amp;amp;logo=lancdb&amp;amp;logoColor=white&amp;amp;labelColor=645cfb&amp;amp;color=645cfb&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://blog.lancedb.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Blog-12100E?style=for-the-badge&amp;amp;logoColor=white&#34; alt=&#34;Blog&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/zMM32dvNtd&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/lancedb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Twitter-%231DA1F2.svg?style=for-the-badge&amp;amp;logo=Twitter&amp;amp;logoColor=white&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;/p&gt; &#xA; &lt;img max-width=&#34;750px&#34; alt=&#34;LanceDB Multimodal Search&#34; src=&#34;https://github.com/lancedb/lancedb/assets/917119/09c5afc5-7816-4687-bae4-f2ca194426ec&#34;&gt; &#xA; &lt;p&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;LanceDB is an open-source database for vector-search built with persistent storage, which greatly simplifies retrieval, filtering and management of embeddings.&lt;/p&gt; &#xA;&lt;p&gt;The key features of LanceDB include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Production-scale vector search with no servers to manage.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Store, query and filter vectors, metadata and multi-modal data (text, images, videos, point clouds, and more).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Support for vector similarity search, full-text search and SQL.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Native Python and Javascript/Typescript support.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Zero-copy, automatic versioning, manage versions of your data without needing extra infrastructure.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;GPU support in building vector index(*).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Ecosystem integrations with &lt;a href=&#34;https://python.langchain.com/docs/integrations/vectorstores/lancedb/&#34;&gt;LangChain ü¶úÔ∏èüîó&lt;/a&gt;, &lt;a href=&#34;https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/LanceDBIndexDemo.html&#34;&gt;LlamaIndex ü¶ô&lt;/a&gt;, Apache-Arrow, Pandas, Polars, DuckDB and more on the way.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;LanceDB&#39;s core is written in Rust ü¶Ä and is built using &lt;a href=&#34;https://github.com/lancedb/lance&#34;&gt;Lance&lt;/a&gt;, an open-source columnar format designed for performant ML workloads.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Javascript&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;npm install vectordb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;const lancedb = require(&#39;vectordb&#39;);&#xA;const db = await lancedb.connect(&#39;data/sample-lancedb&#39;);&#xA;&#xA;const table = await db.createTable({&#xA;  name: &#39;vectors&#39;,&#xA;  data:  [&#xA;    { id: 1, vector: [0.1, 0.2], item: &#34;foo&#34;, price: 10 },&#xA;    { id: 2, vector: [1.1, 1.2], item: &#34;bar&#34;, price: 50 }&#xA;  ]&#xA;})&#xA;&#xA;const query = table.search([0.1, 0.3]).limit(2);&#xA;const results = await query.execute();&#xA;&#xA;// You can also search for rows by specific criteria without involving a vector search.&#xA;const rowsByCriteria = await table.search(undefined).where(&#34;price &amp;gt;= 10&#34;).execute();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Python&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install lancedb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import lancedb&#xA;&#xA;uri = &#34;data/sample-lancedb&#34;&#xA;db = lancedb.connect(uri)&#xA;table = db.create_table(&#34;my_table&#34;,&#xA;                         data=[{&#34;vector&#34;: [3.1, 4.1], &#34;item&#34;: &#34;foo&#34;, &#34;price&#34;: 10.0},&#xA;                               {&#34;vector&#34;: [5.9, 26.5], &#34;item&#34;: &#34;bar&#34;, &#34;price&#34;: 20.0}])&#xA;result = table.search([100, 100]).limit(2).to_pandas()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Blogs, Tutorials &amp;amp; Videos&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üìà &lt;a href=&#34;https://blog.eto.ai/benchmarking-random-access-in-lance-ed690757a826&#34;&gt;2000x better performance with Lance over Parquet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ü§ñ &lt;a href=&#34;https://github.com/lancedb/lancedb/raw/main/docs/src/notebooks/youtube_transcript_search.ipynb&#34;&gt;Build a question and answer bot with LanceDB&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>minyoungg/platonic-rep</title>
    <updated>2024-05-21T01:31:47Z</updated>
    <id>tag:github.com,2024-05-21:/minyoungg/platonic-rep</id>
    <link href="https://github.com/minyoungg/platonic-rep" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;The Platonic Representation Hypothesis&lt;/h1&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt;&lt;a href=&#34;http://arxiv.org/abs/2405.07987&#34; style=&#34;color: #E34F26;&#34;&gt;paper&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://phillipi.github.io/prh/&#34; style=&#34;color: #2088FF;&#34;&gt;project page&lt;/a&gt;&lt;br&gt;&lt;/h3&gt; &#xA;&lt;h5 align=&#34;center&#34;&gt; &lt;a href=&#34;https://minyoungg.github.io/me/&#34; style=&#34;color: #3178C6;&#34;&gt;minyoung huh&lt;/a&gt;* &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://briancheung.github.io/&#34; style=&#34;color: #E34F26;&#34;&gt;brian cheung&lt;/a&gt;* &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://www.tongzhouwang.info/&#34; style=&#34;color: #FCC624;&#34;&gt;tongzhou wang&lt;/a&gt;* &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://web.mit.edu/phillipi/&#34; style=&#34;color: #4EAA25;&#34;&gt;phillip isola&lt;/a&gt;* &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;/h5&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt; Requirements &lt;/h3&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Developed on&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;python = 3.11&lt;/code&gt; &lt;code&gt;PyTorch = 2.2.0&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can install the rest of the requirements via&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt; Running alignment &lt;/h3&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;b&gt; (1) Extracting features&lt;/b&gt;&lt;/p&gt; &#xA;&lt;p&gt;First, we extract features from the models.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# extract all language model features and pool them along each block&#xA;python extract_features.py --dataset minhuh/prh --subset wit_1024 --modelset val --modality language --pool avg&#xA;&#xA;# Extract last layer features of all vision models&#xA;python extract_features.py --dataset minhuh/prh --subset wit_1024 --modelset val --modality vision --pool cls&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The resulting features are stored in &lt;code&gt;./results/features&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;b&gt; (2) Measuring vision-language alignment&lt;/b&gt;&lt;/p&gt; &#xA;&lt;p&gt;After extracting the features, you can compute the alignment score by&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python measure_alignment.py --dataset minhuh/prh --subset wit_1024 --modelset val \&#xA;        --modality_x language --pool_x avg --modality_y vision --pool_y cls&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The resulting alignment scores will be stored in &lt;code&gt;./results/alignment&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; fp = &#39;./results/alignment/minhuh/prh/val/language_pool-avg_prompt-False_vision_pool-cls_prompt-False/mutual_knn_k10.npy&#39;&#xA;&amp;gt;&amp;gt;&amp;gt; result = np.load(fp, allow_pickle=True).item()&#xA;&amp;gt;&amp;gt;&amp;gt; print(results.keys()&#xA;dict_keys([&#39;scores&#39;, &#39;indices&#39;])&#xA;&amp;gt;&amp;gt;&amp;gt; print(result[&#39;scores&#39;].shape) # 12 language models x 17 vision models&#xA;(12, 17)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt; Scoring your own model for alignment to Platonic Representation Hypothesis &lt;/h3&gt; &#xA;&lt;p&gt;We provide code to compute alignment scores for your own model while training/evaluating.&lt;/p&gt; &#xA;&lt;p&gt;&lt;b&gt; (1) Install library as pip package &lt;/b&gt; First install the library as a pip package&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;b&gt; (2) Initiate the metric scoring function &lt;/b&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import platonic&#xA;&#xA;# setup platonic metric&#xA;platonic_metric = platonic.Alignment(&#xA;                    dataset=&#34;minhuh/prh&#34;,&#xA;                    subset=&#34;wit_1024&#34;, &#xA;                    models=[&#34;dinov2_g&#34;, &#34;clip_h&#34;],&#xA;                    ) # optional arguments device, dtype, save_dir (or path to your features)&#xA;&#xA;# load texts&#xA;texts = platonic_metric.get_data(modality=&#34;text&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We provide some precomputed features, so you don&#39;t have to compute it yourself. It will automatically download them for you. See &lt;code&gt;SUPPORTED_DATASETS&lt;/code&gt; in &lt;code&gt;platonic.py&lt;/code&gt;. &lt;b&gt;Note&lt;/b&gt;: We will add more in the upcoming weeks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;b&gt; (3) Extract the features from your model &lt;/b&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# your model has to have `output_hidden_states=True`&#xA;with torch.no_grad():&#xA;        llm_output = language_model(&#xA;            input_ids=token_inputs[&#34;input_ids&#34;],&#xA;            attention_mask=token_inputs[&#34;attention_mask&#34;],&#xA;        )&#xA;        feats = torch.stack(llm_output[&#34;hidden_states&#34;]).permute(1, 0, 2, 3)&#xA;&#xA;# using average pooling (only on valid tokens)&#xA;mask = token_inputs[&#34;attention_mask&#34;].unsqueeze(-1).unsqueeze(1)&#xA;feats = (feats * mask).sum(2) / mask.sum(2)&#xA;&#xA;# compute score. the score is dict for each model where each entry contains the (scores, maximal alignment layer indices)&#xA;score = platonic_metric.score(feats, metric=&#34;mutual_knn&#34;, topk=10, normalize=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We provide examples for both vision and language in &lt;code&gt;examples&lt;/code&gt;. You can run them via &lt;code&gt;python examples/example_language.py&lt;/code&gt;. It will download the features in the local directory if you don&#39;t have it computed already.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt; Customization / Questions &lt;/h3&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;b&gt; ‚ùî Can I add additional models? &lt;/b&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;To add your own set of models, add them and correctly modify the files in &lt;code&gt;tasks.py.&lt;/code&gt; The &lt;code&gt;llm_models&lt;/code&gt; should be auto-regressive models from huggingface and &lt;code&gt;lvm_models&lt;/code&gt; should be ViT models from &lt;code&gt;huggingface/timm&lt;/code&gt;. Most models should work without further modification. Currently, we do not support different vision architectures and language models that are not autoregressive.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;b&gt; ‚ùî What are the metrics that I can use? &lt;/b&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;To check all supported alignment metrics run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt;&amp;gt;&amp;gt; python -c &#39;from metrics import AlignmentMetrics; print(AlignmentMetrics.SUPPORTED_METRICS)&#39;&#xA;[&#39;cycle_knn&#39;, &#39;mutual_knn&#39;, &#39;lcs_knn&#39;, &#39;cka&#39;, &#39;unbiased_cka&#39;, &#39;cknna&#39;, &#39;svcca&#39;, &#39;edit_distance_knn&#39;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Feel free to add your own in &lt;code&gt;metrics.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;b&gt; ‚ùî I want to use the metrics for my own repo. How do I use it? &lt;/b&gt;&lt;br&gt; Simply copy the &lt;code&gt;metrics.py&lt;/code&gt; file to your repo, and you can use it anywhere. It expects a tensor of shape &lt;code&gt;[batch x feats]&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from metrics import AlignmentMetrics&#xA;import torch.nn.functional as F&#xA;&#xA;feats_A = torch.randn(64, 8192)&#xA;feats_B = torch.randn(64, 8192)&#xA;feats_A = F.normalize(feats_A, dim=-1)&#xA;feats_B = F.normalize(feats_B, dim=-1)&#xA;&#xA;# measure score&#xA;score = AlignmentMetrics.measure(&#39;cknna&#39;, feats_A, feats_B, topk=10)&#xA;&#xA;# alternative&#xA;score = AlignmentMetrics.cknna(feats_A, feats_B, topk=10)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;b&gt; ‚ùî I want to add my own custom features for &lt;code&gt;platonic&lt;/code&gt; &lt;/b&gt;&lt;br&gt; To add custom models, add it to &lt;code&gt;SUPPORTED_DATASETS&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;b&gt; ‚ùî Download URL is down. What do I do? &lt;/b&gt;&lt;br&gt; If our download URL is down, please give it some time, as we will try to set it back up as soon as possible. In the meantime, you can compute the same exact features by running the example code in the &lt;code&gt;extracting features&lt;/code&gt; section above.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;b&gt; ‚ùî Reporting alignment scores &lt;/b&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;Note that numbers might vary with different precision and batch-size due to hardware/algorithm variabilities. When evaluating alignment trends, we recommend you to regenerate the features using the same settings when reporting numbers.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt; Citation &lt;/h3&gt; &#xA;&lt;br&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bib&#34;&gt;@inproceedings{huh2024prh,&#xA;  title={The Platonic Representation Hypothesis},&#xA;  author={Huh, Minyoung and Cheung, Brian and Wang, Tongzhou, and Isola, Phillip},&#xA;  booktitle={International Conference on Machine Learning},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>Shubhamsaboo/awesome-llm-apps</title>
    <updated>2024-05-21T01:31:47Z</updated>
    <id>tag:github.com,2024-05-21:/Shubhamsaboo/awesome-llm-apps</id>
    <link href="https://github.com/Shubhamsaboo/awesome-llm-apps" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Collection of awesome LLM apps with RAG using OpenAI, Anthropic, Gemini and opensource models.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://unwindai.substack.com&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/docs/banner/unwind.png&#34; width=&#34;600px&#34; alt=&#34;Unwind AI&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.linkedin.com/in/shubhamsaboo/&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/-Follow%20Shubham Saboo-blue?logo=linkedin&amp;amp;style=flat-square&#34; alt=&#34;LinkedIn&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://twitter.com/Saboo_Shubham_&#34;&gt; &lt;img src=&#34;https://img.shields.io/twitter/follow/Shubham Saboo&#34; alt=&#34;Twitter&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;üåü Awesome LLM Apps&lt;/h1&gt; &#xA;&lt;p&gt;A curated collection of awesome LLM apps built with RAG and AI agents. This repository features LLM apps that use models from OpenAI, Anthropic, Google, and even open-source models like LLaMA that you can run locally on your computer.&lt;/p&gt; &#xA;&lt;h2&gt;ü§î Why Awesome LLM Apps?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üí° Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.&lt;/li&gt; &#xA; &lt;li&gt;üî• Explore apps that combines LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with RAG and AI Agents.&lt;/li&gt; &#xA; &lt;li&gt;üéì Learn from well-documented projects and contribute to the growing opensource ecosystem of LLM-powered applications.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìÇ Featured Projects&lt;/h2&gt; &#xA;&lt;h3&gt;üíª Local Lllama-3 with RAG&lt;/h3&gt; &#xA;&lt;p&gt;Chat with any webpage using local Llama-3 and Retrieval Augmented Generation (RAG) in a Streamlit app. Enjoy 100% free and offline functionality.&lt;/p&gt; &#xA;&lt;h3&gt;üí¨ Chat with GitHub Repo&lt;/h3&gt; &#xA;&lt;p&gt;Engage in natural conversations with your GitHub repositories using GPT-4. Uncover valuable insights and documentation effortlessly.&lt;/p&gt; &#xA;&lt;h3&gt;üì® Chat with Gmail&lt;/h3&gt; &#xA;&lt;p&gt;Interact with your Gmail inbox using natural language. Get accurate answers to your questions based on the content of your emails with Retrieval Augmented Generation (RAG).&lt;/p&gt; &#xA;&lt;h3&gt;üìù Chat with Substack Newsletter&lt;/h3&gt; &#xA;&lt;p&gt;Chat with a Substack newsletter using OpenAI&#39;s API and the Embedchain library in a Streamlit app. Leverage GPT-4 for precise answers based on newsletter content.&lt;/p&gt; &#xA;&lt;h3&gt;üìÑ Chat with PDF&lt;/h3&gt; &#xA;&lt;p&gt;Engage in intelligent conversation and question-answering based on the content of your PDF documents. Simply upload and start asking questions.&lt;/p&gt; &#xA;&lt;h3&gt;üìΩÔ∏è Chat with YouTube Videos&lt;/h3&gt; &#xA;&lt;p&gt;Dive into video content with interactive conversation and question-answering based on YouTube videos. Provide a URL and engage with the video&#39;s content through natural language.&lt;/p&gt; &#xA;&lt;h3&gt;üíª Web Scraping AI Agent&lt;/h3&gt; &#xA;&lt;p&gt;Intelligently scrape websites using OpenAI API and the scrapegraphai library. Specify the URL and extraction requirements, and let the AI agent handle the rest.&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repository&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Navigate to the desired project directory&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd awesome-llm-apps/chat_with_gmail &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Install the required dependencies&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Follow the project-specific instructions in each project&#39;s README.md file to set up and run the app.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;ü§ù Contributing to Opensource&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are welcome! If you have any ideas, improvements, or new apps to add, please create a new &lt;a href=&#34;https://github.com/Shubhamsaboo/awesome-llm-apps/issues&#34;&gt;GitHub Issue&lt;/a&gt; or submit a pull request. Make sure to follow the existing project structure and include a detailed README.md for each new app.&lt;/p&gt; &#xA;&lt;h3&gt;Thank you community for the support üôè&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#Shubhamsaboo/awesome-llm-apps&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;üåü &lt;strong&gt;Don‚Äôt miss out on future updates! Star the repo now and be the first to know about new and exciting LLM applications with RAG.&lt;/strong&gt;&lt;/p&gt;</summary>
  </entry>
</feed>