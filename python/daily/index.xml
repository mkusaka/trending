<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-31T01:46:19Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>lucidrains/musiclm-pytorch</title>
    <updated>2023-01-31T01:46:19Z</updated>
    <id>tag:github.com,2023-01-31:/lucidrains/musiclm-pytorch</id>
    <link href="https://github.com/lucidrains/musiclm-pytorch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Implementation of MusicLM, Google&#39;s new SOTA model for music generation using attention networks, in Pytorch&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lucidrains/musiclm-pytorch/main/musiclm.png&#34; width=&#34;450px&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;MusicLM - Pytorch (wip)&lt;/h2&gt; &#xA;&lt;p&gt;Implementation of &lt;a href=&#34;https://google-research.github.io/seanet/musiclm/examples/&#34;&gt;MusicLM&lt;/a&gt;, Google&#39;s new SOTA model for music generation using attention networks, in Pytorch.&lt;/p&gt; &#xA;&lt;p&gt;They are basically using text-conditioned &lt;a href=&#34;https://github.com/lucidrains/audiolm-pytorch&#34;&gt;AudioLM&lt;/a&gt;, but surprisingly with the embeddings from a text-audio contrastive learned model named &lt;a href=&#34;https://arxiv.org/abs/2208.12415&#34;&gt;MuLan&lt;/a&gt;. MuLan is what will be built out in this repository, with AudioLM modified from the other repository to support the music generation needs here.&lt;/p&gt; &#xA;&lt;h2&gt;Appreciation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://stability.ai/&#34;&gt;Stability.ai&lt;/a&gt; for the generous sponsorship to work and open source cutting edge artificial intelligence research&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citations&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{Agostinelli2023MusicLMGM,&#xA;  title     = {MusicLM: Generating Music From Text},&#xA;  author    = {Andrea Agostinelli and Timo I. Denk and Zal{\&#39;a}n Borsos and Jesse Engel and Mauro Verzetti and Antoine Caillon and Qingqing Huang and Aren Jansen and Adam Roberts and Marco Tagliasacchi and Matthew Sharifi and Neil Zeghidour and C. Frank},&#xA;  year      = {2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{Huang2022MuLanAJ,&#xA;    title   = {MuLan: A Joint Embedding of Music Audio and Natural Language},&#xA;    author  = {Qingqing Huang and Aren Jansen and Joonseok Lee and Ravi Ganti and Judith Yue Li and Daniel P. W. Ellis},&#xA;    journal = {ArXiv},&#xA;    year    = {2022},&#xA;    volume  = {abs/2208.12415}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>promptslab/Promptify</title>
    <updated>2023-01-31T01:46:19Z</updated>
    <id>tag:github.com,2023-01-31:/promptslab/Promptify</id>
    <link href="https://github.com/promptslab/Promptify" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Prompt Engineering | Use GPT or other prompt based models to get structured output. Join our discord for Prompt-Engineering, LLMs and other latest research&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img width=&#34;110px&#34; src=&#34;https://raw.githubusercontent.com/promptslab/Promptify/main/logo/logo.png&#34;&gt; &#xA; &lt;h1&gt;Promptify&lt;/h1&gt;&#xA;&lt;/div&gt; &#xA;&lt;!-- &#xA;&lt;h2 align=&#34;center&#34;&gt;Promptify&lt;/h2&gt; --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt;Prompt Engineering, Solve NLP Problems with LLM&#39;s &amp;amp; Easily generate different NLP Task prompts for popular generative models like GPT, PaLM, and more with Promptify &lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/promptslab/Promptify/raw/main/LICENSE&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true&#34; alt=&#34;Promptify is released under the Apache 2.0 license.&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/promptify/&#34;&gt; &lt;img src=&#34;https://badge.fury.io/py/Promptify.svg?sanitize=true&#34; alt=&#34;PyPI version&#34;&gt; &lt;/a&gt; &lt;a href=&#34;http://makeapullrequest.com&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&#34; alt=&#34;http://makeapullrequest.com&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://discord.gg/m88xfYMbK6&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Discord-Community-orange&#34; alt=&#34;Community&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/promptslab/Promptify/main/#&#34;&gt; &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;colab&#34;&gt; &lt;/a&gt; &lt;/h4&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;With pip&lt;/h3&gt; &#xA;&lt;p&gt;This repository is tested on Python 3.7+, openai 0.25+.&lt;/p&gt; &#xA;&lt;p&gt;You should install Promptify using Pip command&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip3 install promptify&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quick tour&lt;/h2&gt; &#xA;&lt;p&gt;To immediately use a LLM model for your NLP task, we provide the &lt;code&gt;Prompter&lt;/code&gt; API.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from promptify import OpenAI&#xA;from promptify import Prompter&#xA;&#xA;sentence     =  &#34;The patient is a 93-year-old female with a medical  &#x9;&#x9;&#x9;&#x9; &#xA;                history of chronic right hip pain, osteoporosis,&#x9;&#x9;&#x9;&#x9;&#x9;&#xA;                hypertension, depression, and chronic atrial&#x9;&#x9;&#x9;&#x9;&#x9;&#x9;&#xA;                fibrillation admitted for evaluation and management&#x9;&#x9;&#x9;&#x9;&#xA;                of severe nausea and vomiting and urinary tract&#x9;&#x9;&#x9;&#x9;&#xA;                infection&#34;&#xA;&#xA;model        = OpenAI(api_key)&#xA;nlp_prompter = Prompter(model)&#xA;&#xA;&#xA;result       = nlp_prompter.fit(&#39;ner.jinja&#39;,&#xA;                          domain      = &#39;medical&#39;,&#xA;                          text_input  = sentence, &#xA;                          labels      = None)&#xA;                          &#xA;                          &#xA;### Output&#xA;&#xA;[{&#39;E&#39;: &#39;93-year-old&#39;, &#39;T&#39;: &#39;Age&#39;},&#xA; {&#39;E&#39;: &#39;chronic right hip pain&#39;, &#39;T&#39;: &#39;Medical Condition&#39;},&#xA; {&#39;E&#39;: &#39;osteoporosis&#39;, &#39;T&#39;: &#39;Medical Condition&#39;},&#xA; {&#39;E&#39;: &#39;hypertension&#39;, &#39;T&#39;: &#39;Medical Condition&#39;},&#xA; {&#39;E&#39;: &#39;depression&#39;, &#39;T&#39;: &#39;Medical Condition&#39;},&#xA; {&#39;E&#39;: &#39;chronic atrial fibrillation&#39;, &#39;T&#39;: &#39;Medical Condition&#39;},&#xA; {&#39;E&#39;: &#39;severe nausea and vomiting&#39;, &#39;T&#39;: &#39;Symptom&#39;},&#xA; {&#39;E&#39;: &#39;urinary tract infection&#39;, &#39;T&#39;: &#39;Medical Condition&#39;},&#xA; {&#39;Branch&#39;: &#39;Internal Medicine&#39;, &#39;Group&#39;: &#39;Geriatrics&#39;}]&#xA; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p float=&#34;left&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/promptslab/Promptify/main/logo/ner.png&#34; width=&#34;250&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/promptslab/Promptify/main/logo/multilabel.png&#34; width=&#34;250&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/promptslab/Promptify/main/logo/qa_gen.png&#34; width=&#34;250&#34;&gt; &lt;/p&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt;GPT-3 Example with NER, MultiLabel, Question Generation Task&lt;/h4&gt; &#xA;&lt;h2&gt;Features üéÆ &lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; Perform NLP tasks (such as NER and classification) in just 2 lines of code, with no training data required&lt;/li&gt; &#xA; &lt;li&gt; Easily add one shot, two shot, or few shot examples to the prompt&lt;/li&gt; &#xA; &lt;li&gt; Handling out-of-bounds prediction from LLMS (GPT, t5, etc.) &lt;/li&gt;&#xA; &lt;li&gt; Output always provided as a Python object (e.g. list, dictionary) for easy parsing and filtering. This is a major advantage over LLMs generated output, whose unstructured and raw output makes it difficult to use in business or other applications.&lt;/li&gt; &#xA; &lt;li&gt; Custom examples and samples can be easily added to the prompt&lt;/li&gt; &#xA; &lt;li&gt; Optimized prompts to reduce OpenAI token costs (coming soon)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Supporting wide-range of Prompt-Based NLP tasks :&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Task Name&lt;/th&gt; &#xA;   &lt;th&gt;Colab Notebook&lt;/th&gt; &#xA;   &lt;th&gt;Status&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Named Entity Recognition&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/16DUUV72oQPxaZdGMH9xH1WbHYu6Jqk9Q?usp=sharing&#34;&gt;NER Examples with GPT-3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Multi-Label Text Classification&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1gNqDxNyMMUO67DxigzRAOa7C_Tcr2g6M?usp=sharing&#34;&gt;Classification Examples with GPT-3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Multi-Class Text Classification&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1gNqDxNyMMUO67DxigzRAOa7C_Tcr2g6M?usp=sharing&#34;&gt;Classification Examples with GPT-3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Binary Text Classification&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1gNqDxNyMMUO67DxigzRAOa7C_Tcr2g6M?usp=sharing&#34;&gt;Classification Examples with GPT-3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Question-Answering&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1Yhl7iFb7JF0x89r1L3aDuufydVWX_VrL?usp=sharing&#34;&gt;QA Task Examples with GPT-3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Question-Answer Generation&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1Yhl7iFb7JF0x89r1L3aDuufydVWX_VrL?usp=sharing&#34;&gt;QA Task Examples with GPT-3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Summarization&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1PlXIAMDtrK-RyVdDhiSZy6ztcDWsNPNw?usp=sharing&#34;&gt;Summarization Task Examples with GPT-3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Explanation&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1PlXIAMDtrK-RyVdDhiSZy6ztcDWsNPNw?usp=sharing&#34;&gt;Explanation Task Examples with GPT-3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;‚úÖ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Tabular Data&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Image Data&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;More Prompts&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;üíÅ Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome any contributions to our open source project, including new features, improvements to infrastructure, and more comprehensive documentation. Please see the &lt;a href=&#34;https://raw.githubusercontent.com/promptslab/Promptify/main/contribute.md&#34;&gt;contributing guidelines&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>hwchase17/notion-qa</title>
    <updated>2023-01-31T01:46:19Z</updated>
    <id>tag:github.com,2023-01-31:/hwchase17/notion-qa</id>
    <link href="https://github.com/hwchase17/notion-qa" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Notion Question-Answering&lt;/h1&gt; &#xA;&lt;p&gt;ü§ñAsk questions to your Notion database in natural languageü§ñ&lt;/p&gt; &#xA;&lt;p&gt;üí™ Built with &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üå≤ Environment Setup&lt;/h1&gt; &#xA;&lt;p&gt;In order to set your environment up to run the code here, first install all requirements:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then set your OpenAI API key (if you don&#39;t have one, get one &lt;a href=&#34;https://beta.openai.com/playground&#34;&gt;here&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export OPENAI_API_KEY=....&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;üìÑ What is in here?&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Example data from Blendle&lt;/li&gt; &#xA; &lt;li&gt;Python script to query Notion with a question&lt;/li&gt; &#xA; &lt;li&gt;Code to deploy on StreamLit&lt;/li&gt; &#xA; &lt;li&gt;Instructions for ingesting your own dataset&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìä Example Data&lt;/h2&gt; &#xA;&lt;p&gt;This repo uses the &lt;a href=&#34;https://www.notion.so/Blendle-s-Employee-Handbook-7692ffe24f07450785f093b94bbe1a09&#34;&gt;Blendle Employee Handbook&lt;/a&gt; as an example. It was downloaded October 18th so may have changed slightly since then!&lt;/p&gt; &#xA;&lt;h2&gt;üí¨ Ask a question&lt;/h2&gt; &#xA;&lt;p&gt;In order to ask a question, run a command like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python qa.py &#34;What is the work from home policy&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can switch out &lt;code&gt;What is the work from home policy&lt;/code&gt; for any question of your liking!&lt;/p&gt; &#xA;&lt;p&gt;This exposes a chat interface for interacting with a Notion database. IMO, this is a more natural and convenient interface for getting information.&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Code to deploy on StreamLit&lt;/h2&gt; &#xA;&lt;p&gt;The code to run the StreamLit app is in &lt;code&gt;main.py&lt;/code&gt;. Note that when setting up your StreamLit app you should make sure to add &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; as a secret environment variable.&lt;/p&gt; &#xA;&lt;h2&gt;üßë Instructions for ingesting your own dataset&lt;/h2&gt; &#xA;&lt;p&gt;Export your dataset from Notion. You can do this by clicking on the three dots in the upper right hand corner and then clicking &lt;code&gt;Export&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/hwchase17/notion-qa/master/export_notion.png&#34; alt=&#34;export&#34; width=&#34;200&#34;&gt; &#xA;&lt;p&gt;When exporting, make sure to select the &lt;code&gt;Markdown &amp;amp; CSV&lt;/code&gt; format option.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/hwchase17/notion-qa/master/export_format.png&#34; alt=&#34;export-format&#34; width=&#34;200&#34;&gt; &#xA;&lt;p&gt;This will produce a &lt;code&gt;.zip&lt;/code&gt; file in your Downloads folder. Move the &lt;code&gt;.zip&lt;/code&gt; file into this repository.&lt;/p&gt; &#xA;&lt;p&gt;Run the following command to unzip the zip file (replace the &lt;code&gt;Export...&lt;/code&gt; with your own file name as needed).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;unzip Export-d3adfe0f-3131-4bf3-8987-a52017fc1bae.zip -d Notion_DB&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the following command to ingest the data.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python ingest.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Boom! Now you&#39;re done, and you can ask it questions like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python qa.py &#34;What is the work from home policy&#34;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>