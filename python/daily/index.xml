<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-25T01:35:59Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>0xJs/RedTeaming_CheatSheet</title>
    <updated>2022-11-25T01:35:59Z</updated>
    <id>tag:github.com,2022-11-25:/0xJs/RedTeaming_CheatSheet</id>
    <link href="https://github.com/0xJs/RedTeaming_CheatSheet" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Pentesting cheatsheet with all the commands I learned during my learning journey. Will try to to keep it up-to-date.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RedTeaming_CheatSheet&lt;/h1&gt; &#xA;&lt;p&gt;Pentesting / RedTeaming cheatsheet with all the commands and techniques I learned during my learning journey. Will keep it up to date. If you have any recommendations for courses or links or have any questions feel free to dm me on discord. 0xjs#9027&lt;/p&gt; &#xA;&lt;h2&gt;Index&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/#General&#34;&gt;General&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/payloads.md&#34;&gt;Payloads&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/OSINT.md&#34;&gt;Open Source Intelligence&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/python_dependancies.md&#34;&gt;Python Dependancies&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/infrastructure/readme.md&#34;&gt;Infrastructure&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/infrastructure/bufferoverflow.md&#34;&gt;Buffer overflow&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/infrastructure/enumeration.md&#34;&gt;Enumeration&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/infrastructure/exploitation.md&#34;&gt;Exploitation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/infrastructure/privesc_windows.md&#34;&gt;Privilege Escalation Windows&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/infrastructure/privesc_linux.md&#34;&gt;Privilege Escalation Linux&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/infrastructure/post_exploitation.md&#34;&gt;Post Exploitation&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/windows-ad/readme.md&#34;&gt;Windows AD&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/windows-ad/Local-Privilege-Escalation.md&#34;&gt;Local privilege escalation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/windows-ad/Domain-Enumeration.md&#34;&gt;Domain Enumeration&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/windows-ad/Lateral-Movement.md&#34;&gt;Lateral Movement&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/windows-ad/PowerShell-Evasion.md&#34;&gt;Powershell Evasion&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/windows-ad/Domain-Privilege-Escalation.md&#34;&gt;Domain privilege escalation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/windows-ad/Domain-Persistence.md&#34;&gt;Domain Persistence&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cloud/readme.md&#34;&gt;Cloud&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cloud/recon.md&#34;&gt;Recon \ OSINT&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cloud/initial-access-attacks.md&#34;&gt;Initial access attacks&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cloud/readme.md&#34;&gt;Cloud services&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cloud/azure/readme.md&#34;&gt;Azure&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cloud/aws/readme.md&#34;&gt;Amazon Web Services&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cloud/gcb/readme.md&#34;&gt;Google Cloud Platform&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;C2 Frameworks&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/cobalt-strike.md&#34;&gt;Cobalt Strike&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/covenant.md&#34;&gt;Covenant&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/0xJs/RedTeaming_CheatSheet/main/metasploit.md&#34;&gt;Metasploit&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Sources&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Cloud: CARTP from Pentester Academy and breaching the cloud from antisyphon.&lt;/li&gt; &#xA; &lt;li&gt;Windows: CRTP, CRTE from Pentester Academy, ECPTX from eLearnSecurity and CRTO from RastaMouse.&lt;/li&gt; &#xA; &lt;li&gt;Infra: PNPT and Tiberius privesc courses&lt;/li&gt; &#xA; &lt;li&gt;OSINT: PNPT Course&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>baaivision/EVA</title>
    <updated>2022-11-25T01:35:59Z</updated>
    <id>tag:github.com,2022-11-25:/baaivision/EVA</id>
    <link href="https://github.com/baaivision/EVA" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Exploring the Limits of Masked Visual Representation Learning at Scale (https://arxiv.org/abs/2211.07636)&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;EVA: An Open Billion-Scale Vision Foundation Model &lt;/h1&gt; &#xA; &lt;h3&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.07636&#34;&gt;EVA: Exploring the Limits of Masked Visual Representation Learning at Scale&lt;/a&gt;&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://bit.ly/YuxinFang_GoogleScholar&#34;&gt;Yuxin Fang&lt;/a&gt;&lt;sup&gt;2,1&lt;/sup&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=1ks0R04AAAAJ&amp;amp;hl&#34;&gt;Wen Wang&lt;/a&gt;&lt;sup&gt;3,1&lt;/sup&gt;, &lt;a href=&#34;https://binhuixie.github.io/&#34;&gt;Binhui Xie&lt;/a&gt;&lt;sup&gt;4,1&lt;/sup&gt;, &lt;a href=&#34;https://github.com/Quan-Sun&#34;&gt;Quan Sun&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=-eJHVt8AAAAJ&amp;amp;hl=en&#34;&gt;Ledell Wu&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;, &lt;a href=&#34;https://xinggangw.info/&#34;&gt;Xinggang Wang&lt;/a&gt;&lt;sup&gt;2&lt;/sup&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=knvEK4AAAAAJ&amp;amp;hl=en&#34;&gt;Tiejun Huang&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;, &lt;a href=&#34;https://www.xloong.wang/&#34;&gt;Xinlong Wang&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;, &lt;a href=&#34;http://yue-cao.me/&#34;&gt;Yue Cao&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;a href=&#34;https://www.baai.ac.cn/english.html&#34;&gt;BAAI&lt;/a&gt;, &lt;sup&gt;2&lt;/sup&gt;&lt;a href=&#34;http://english.hust.edu.cn/&#34;&gt;HUST&lt;/a&gt;, &lt;sup&gt;3&lt;/sup&gt;&lt;a href=&#34;https://www.zju.edu.cn/english/&#34;&gt;ZJU&lt;/a&gt;, &lt;sup&gt;4&lt;/sup&gt;&lt;a href=&#34;https://english.bit.edu.cn/&#34;&gt;BIT&lt;/a&gt;&lt;/p&gt; &#xA; &lt;!-- [![Paper](http://img.shields.io/badge/paper-arxiv.2211.07636-B31B1B.svg)](https://arxiv.org/abs/2211.07636) --&gt; &#xA; &lt;!-- ArXiv Preprint ([arXiv 2211.07636](https://arxiv.org/abs/2211.07636)) --&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://paperswithcode.com/sota/instance-segmentation-on-coco?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/instance-segmentation-on-coco&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/instance-segmentation-on-coco-minival?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/instance-segmentation-on-coco-minival&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/instance-segmentation-on-lvis-v1-0-val?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/instance-segmentation-on-lvis-v1-0-val&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/object-detection-on-lvis-v1-0-val?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/object-detection-on-lvis-v1-0-val&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/object-detection-on-coco?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/object-detection-on-coco&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/object-detection-on-coco-minival?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/object-detection-on-coco-minival&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/semantic-segmentation-on-ade20k?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/semantic-segmentation-on-ade20k&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/action-classification-on-kinetics-700?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/action-classification-on-kinetics-700&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/action-classification-on-kinetics-400?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/action-classification-on-kinetics-400&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://paperswithcode.com/sota/action-classification-on-kinetics-600?p=eva-exploring-the-limits-of-masked-visual&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/eva-exploring-the-limits-of-masked-visual/action-classification-on-kinetics-600&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;We launch &lt;strong&gt;EVA&lt;/strong&gt;, a vision-centric foundation model to &lt;strong&gt;E&lt;/strong&gt;xplore the limits of &lt;strong&gt;V&lt;/strong&gt;isual representation at sc&lt;strong&gt;A&lt;/strong&gt;le using only publicly accessible data and academic resources. &lt;strong&gt;EVA&lt;/strong&gt; is a vanilla ViT pre-trained to reconstruct the masked out image-text aligned vision features (&lt;em&gt;i.e.&lt;/em&gt;, CLIP features) conditioned on visible image patches. Via this pretext task, we can efficiently scale up EVA to one billion parameters, and sets new records on a broad range of representative vision downstream tasks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;EVA is the first open-sourced billion-scale vision foundation model that achieves state-of-the-art performance on a broad range of downstream tasks.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;strong&gt;All the code &amp;amp; 16x state-of-the-art billion-scale models that are open-sourced!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Nov 22, 2022&lt;/code&gt;: release code &amp;amp; model of &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/det/README.md&#34;&gt;object detection and instance segmentation&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Nov 21, 2022&lt;/code&gt;: release code &amp;amp; model of &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/video/README.md&#34;&gt;video classification&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/seg/README.md&#34;&gt;semantic segmentation&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/clip/README.md&#34;&gt;EVA-CLIP&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Nov 20, 2022&lt;/code&gt;: release code &amp;amp; model of &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/eva/README.md&#34;&gt;pre-training and image classification&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Nov 18, 2022&lt;/code&gt;: release wandb &lt;a href=&#34;https://wandb.ai/baaivision/eva-clip/reports/ViT-g-14--VmlldzoyOTkwMDYy&#34;&gt;log &amp;amp; statistics&lt;/a&gt; of 1.1B EVA-CLIP training.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;span id=&#34;eva_performance_summary&#34;&gt;&lt;/span&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Catalog&lt;/h2&gt; &#xA;&lt;p&gt;All EVA model checkpoints (16 in total) are now available at &lt;a href=&#34;https://huggingface.co/BAAI/EVA/tree/main&#34;&gt;🤗 Hugging Face Models&lt;/a&gt;. Try them out!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/eva&#34;&gt;Pre-training&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/eva&#34;&gt;Image Classification&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/video&#34;&gt;Video Classification&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/det&#34;&gt;Object Detection &amp;amp; Instance Segmentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/seg&#34;&gt;Semantic Segmentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/clip&#34;&gt;CLIP&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Summary of EVA&#39;s performance&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;strong&gt;image &amp;amp; video classification&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;table border=&#34;1&#34; width=&#34;100%&#34;&gt; &#xA;  &lt;tbody&gt;&#xA;   &lt;tr align=&#34;center&#34;&gt; &#xA;    &lt;th&gt; &lt;/th&gt;&#xA;    &lt;th&gt; &lt;/th&gt;&#xA;    &lt;th colspan=&#34;3&#34;&gt;image classification&lt;/th&gt;&#xA;    &lt;th colspan=&#34;3&#34;&gt;video classification&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr align=&#34;center&#34;&gt; &#xA;    &lt;th&gt;model&lt;/th&gt;&#xA;    &lt;th&gt;#param.&lt;/th&gt;&#xA;    &lt;th&gt;IN-1K&lt;/th&gt;&#xA;    &lt;th&gt;IN-1K, zero-shot&lt;/th&gt;&#xA;    &lt;th&gt;12 avg. zero-shot&lt;/th&gt;&#xA;    &lt;th&gt;K400&lt;/th&gt;&#xA;    &lt;th&gt;K600&lt;/th&gt;&#xA;    &lt;th&gt;K700&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr align=&#34;center&#34;&gt; &#xA;    &lt;th&gt;EVA&lt;/th&gt;&#xA;    &lt;th&gt;1.0B&lt;/th&gt;&#xA;    &lt;th&gt;&lt;a href=&#34;https://github.com/baaivision/EVA/raw/master/logs/cls/ft_1k_cls_sz560_89p7.txt&#34;&gt;89.7&lt;/a&gt;&lt;/th&gt;&#xA;    &lt;th&gt;&lt;a href=&#34;https://wandb.ai/baaivision/eva-clip/reports/ViT-g-14--VmlldzoyOTkwMDYy&#34;&gt;78.5&lt;/a&gt;&lt;/th&gt;&#xA;    &lt;th&gt;72.5+&lt;/th&gt;&#xA;    &lt;th&gt;89.7&lt;/th&gt;&#xA;    &lt;th&gt;89.8&lt;/th&gt;&#xA;    &lt;th&gt;82.9&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt;&#xA; &lt;/table&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;strong&gt;object detection &amp;amp; segmentation&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;table border=&#34;1&#34; width=&#34;200%&#34;&gt; &#xA;  &lt;tbody&gt;&#xA;   &lt;tr align=&#34;center&#34;&gt; &#xA;    &lt;th&gt; &lt;/th&gt;&#xA;    &lt;th&gt; &lt;/th&gt;&#xA;    &lt;th colspan=&#34;4&#34;&gt;COCO det &amp;amp; ins seg&lt;/th&gt;&#xA;    &lt;th colspan=&#34;2&#34;&gt;LVIS det &amp;amp; ins seg&lt;/th&gt;&#xA;    &lt;th colspan=&#34;2&#34;&gt;sem seg&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr align=&#34;center&#34;&gt; &#xA;    &lt;th&gt;model&lt;/th&gt;&#xA;    &lt;th&gt;#param.&lt;/th&gt;&#xA;    &lt;th&gt;det (test)&lt;/th&gt;&#xA;    &lt;th&gt;det (val)&lt;/th&gt;&#xA;    &lt;th&gt;seg (test)&lt;/th&gt;&#xA;    &lt;th&gt;seg (val)&lt;/th&gt;&#xA;    &lt;th&gt;det&lt;/th&gt;&#xA;    &lt;th&gt;seg&lt;/th&gt;&#xA;    &lt;th&gt;COCO-Stuff&lt;/th&gt;&#xA;    &lt;th&gt;ADE20K&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr align=&#34;center&#34;&gt; &#xA;    &lt;th&gt;EVA&lt;/th&gt;&#xA;    &lt;th&gt;1.0B&lt;/th&gt;&#xA;    &lt;th&gt;&lt;a href=&#34;https://codalab.lisn.upsaclay.fr/competitions/7384#results&#34;&gt;64.7&lt;/a&gt;&lt;/th&gt;&#xA;    &lt;th&gt;64.5&lt;/th&gt;&#xA;    &lt;th&gt;&lt;a href=&#34;https://codalab.lisn.upsaclay.fr/competitions/7383#results&#34;&gt;55.5&lt;/a&gt;&lt;/th&gt;&#xA;    &lt;th&gt;55.0&lt;/th&gt;&#xA;    &lt;th&gt;62.2&lt;/th&gt;&#xA;    &lt;th&gt;55.0&lt;/th&gt;&#xA;    &lt;th&gt;&lt;a href=&#34;https://github.com/baaivision/EVA/raw/master/logs/sem_seg/ft_cocstuff164k_sem_seg_ss_53p4.txt&#34;&gt;53.4&lt;/a&gt;&lt;/th&gt;&#xA;    &lt;th&gt;&lt;a href=&#34;https://github.com/baaivision/EVA/raw/master/logs/sem_seg/ft_ade20k_sem_seg_ms_62p3.txt&#34;&gt;62.3&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt;&#xA; &lt;/table&gt; &#xA; &lt;br&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find our work helpful, please &lt;strong&gt;star🌟&lt;/strong&gt; this repo and &lt;strong&gt;cite📑&lt;/strong&gt; our paper. Thanks for your support!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{EVA,&#xA;  title={EVA: Exploring the Limits of Masked Visual Representation Learning at Scale},&#xA;  author={Fang, Yuxin and Wang, Wen and Xie, Binhui and Sun, Quan and Wu, Ledell and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},&#xA;  journal={arXiv preprint arXiv:2211.07636},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The content of this project itself is licensed under &lt;a href=&#34;https://raw.githubusercontent.com/baaivision/EVA/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;For help and issues associated with EVA, or reporting a bug, please open a &lt;a href=&#34;https://github.com/baaivision/EVA/issues/new&#34;&gt;GitHub Issue&lt;/a&gt;. Let&#39;s build a better &amp;amp; stronger EVA together :)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;We are hiring&lt;/strong&gt; at all levels at BAAI Vision Team, including full-time researchers, engineers and interns. If you are interested in working with us on &lt;strong&gt;foundation model, self-supervised learning and multimodal learning&lt;/strong&gt;, please contact&amp;nbsp;&lt;a href=&#34;http://yue-cao.me/&#34;&gt;Yue Cao&lt;/a&gt; (&lt;code&gt;caoyue@baai.ac.cn&lt;/code&gt;) and &lt;a href=&#34;https://www.xloong.wang/&#34;&gt;Xinlong Wang&lt;/a&gt; (&lt;code&gt;wangxinlong@baai.ac.cn&lt;/code&gt;).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;↳ Stargazers&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/baaivision/EVA/stargazers&#34;&gt;&lt;img src=&#34;https://reporoster.com/stars/baaivision/EVA&#34; alt=&#34;Stargazers repo roster for @baaivision/EVA&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;↳ Forkers&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/baaivision/EVA/network/members&#34;&gt;&lt;img src=&#34;https://reporoster.com/forks/baaivision/EVA&#34; alt=&#34;Forkers repo roster for @baaivision/EVA&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>biancangming/wtv</title>
    <updated>2022-11-25T01:35:59Z</updated>
    <id>tag:github.com,2022-11-25:/biancangming/wtv</id>
    <link href="https://github.com/biancangming/wtv" rel="alternate"></link>
    <summary type="html">&lt;p&gt;解决电脑、手机看电视直播的苦恼，收集各种直播源，电视直播网站&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; &#xA; &lt;p&gt;QQ群免费开放中....&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://qm.qq.com/cgi-bin/qm/qr?k=xdOuWd8gz2OHO5zY_jvjwzwj-fb_7O2I&amp;amp;jump_from=webapi&#34;&gt;点击链接加入群聊【wtv交流群】，等级低于一个太阳谢绝入内&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;长期更新，建议收藏本页面，资源来源网络，可用性未逐一验证，尽可能保证大多资源可用。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;最新IPTV直播源m3u8下载，电视直播网站推荐，原则上以中文频道为主&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/biancangming/wtv/wiki/%E6%9C%80%E6%96%B0IPTV%E7%9B%B4%E6%92%AD%E6%BA%90m3u8%E4%B8%8B%E8%BD%BD%EF%BC%8C%E7%94%B5%E8%A7%86%E7%9B%B4%E6%92%AD%E7%BD%91%E7%AB%99%E6%8E%A8%E8%8D%90&#34;&gt;https://github.com/biancangming/wtv/wiki/最新IPTV直播源m3u8下载，电视直播网站推荐&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;wtv-tools wtv工具箱&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/biancangming/wtv/issues/8&#34;&gt;https://github.com/biancangming/wtv/issues/8&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;正版看TV网站合集&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/biancangming/wtv/wiki/TV%E7%9B%B4%E6%92%AD%E7%BD%91%E7%AB%99%E5%90%88%E9%9B%86&#34;&gt;https://github.com/biancangming/wtv/wiki/TV直播网站合集&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;github 相关项目推荐&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;北京联通IPTV频道列表 &lt;a href=&#34;https://github.com/qwerttvv/Beijing-IPTV&#34;&gt;https://github.com/qwerttvv/Beijing-IPTV&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;移动直播源汇总 &lt;a href=&#34;https://github.com/SPX372928/MyIPTV&#34;&gt;https://github.com/SPX372928/MyIPTV&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;10086IPTV &lt;a href=&#34;https://github.com/sheng007/10086-IPTV&#34;&gt;https://github.com/sheng007/10086-IPTV&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;世界IPTV库, 内容全： &lt;a href=&#34;https://github.com/iptv-org/iptv&#34;&gt;https://github.com/iptv-org/iptv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;IPTVM3U, &lt;a href=&#34;https://github.com/Sphinxroot/IPTVM3U&#34;&gt;https://github.com/Sphinxroot/IPTVM3U&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[一键管理iptv脚本] &lt;a href=&#34;https://github.com/woniuzfb/iptv&#34;&gt;https://github.com/woniuzfb/iptv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[iptv-pro.github.io] &lt;a href=&#34;https://github.com/iptv-pro/iptv-pro.github.io&#34;&gt;https://github.com/iptv-pro/iptv-pro.github.io&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;PC直播源软件推荐&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;potplayer(影音播放支持流媒体) &lt;a href=&#34;https://daumpotplayer.com/download/&#34;&gt;https://daumpotplayer.com/download/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;vlc（专业流媒体软件） &lt;a href=&#34;https://www.videolan.org/vlc/&#34;&gt;https://www.videolan.org/vlc/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;黑鸟播放器（民间，自带源） &lt;a href=&#34;https://guihet.com/blackbird-player.html&#34;&gt;https://guihet.com/blackbird-player.html&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;m3u 批量检测脚本&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/biancangming/wtv/tree/master/m3uMaker&#34;&gt;https://github.com/biancangming/wtv/tree/master/m3uMaker&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;有兴趣关注我的微信公众号，一个橙子pro&lt;/h1&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/42108047/173232153-a4a60817-cba0-4f0a-8ccb-f26e197314f9.jpg&#34; width=&#34;200&#34; height=&#34;200&#34; alt=&#34;一个橙子pro&#34;&gt;</summary>
  </entry>
</feed>