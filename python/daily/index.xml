<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-23T01:43:02Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>boiled-water-tsar/eat-my-entire-trans-ass-andrew-bailey</title>
    <updated>2023-04-23T01:43:02Z</updated>
    <id>tag:github.com,2023-04-23:/boiled-water-tsar/eat-my-entire-trans-ass-andrew-bailey</id>
    <link href="https://github.com/boiled-water-tsar/eat-my-entire-trans-ass-andrew-bailey" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The purpose of this repository is for trans people not be genocided.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tool for submitting data to the Missouri Attorney General Transgender Center Concerns Form - TRANS RIGHTS&lt;/h1&gt; &#xA;&lt;p&gt;Python program using the frankly terrible code of the Missouri Attorney General&#39;s office to flood their snitching website with garbage and noise.&lt;/p&gt; &#xA;&lt;p&gt;They want us to die but honey, these colors don&#39;t run 🏳️‍⚧️🏳️‍⚧️🏳️‍⚧️&lt;/p&gt; &#xA;&lt;h2&gt;How it&#39;s done and a bit of history&lt;/h2&gt; &#xA;&lt;p&gt;In a nutshell: Garbage and noise is generate -&amp;gt; a captcha is solved -&amp;gt; noise is sent to the REST API serving the snitching form. The program has been through several permutations. From sending the rawest of garbage to sending data specific enough to MO that it would be a herculean task to sort through. Security has been attempted implemented and bypassed from nothing (as in, no security at all lmao what were they thinking) to ensuring an IP could only submit one report to introducing a captcha. As time goes on I&#39;m sure the MO AGs office will introduce even more security, and we will defeat it all.&lt;/p&gt; &#xA;&lt;h2&gt;How to use&lt;/h2&gt; &#xA;&lt;p&gt;Strongly consider using a VPN. Submitting millions of false reports may not be illegal, but it might also be wire fraud? IANAL. For VPNs there&#39;s a number of options such as &lt;a href=&#34;https://1.1.1.1&#34;&gt;Cloudflare WARP&lt;/a&gt; or &lt;a href=&#34;https://protonvpn.com&#34;&gt;Proton VPN&lt;/a&gt;, and of course there&#39;s always Starbucks free WI-FI.&lt;/p&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;Install Python version 3.10 or higher and pip. You can learn how to at &lt;a href=&#34;https://python.org&#34;&gt;https://python.org&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Then either clone this repository or download and extract it&lt;/p&gt; &#xA;&lt;p&gt;Install depedencies&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;python3 -m pip install -r requirements.txt&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;pip install -r requirements.txt&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;When the dependencies have been installed run the program with&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;python3 defend_trans.py&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;If the program is running successfully you should see output akin to&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Response submitted for Barlett, Eric&lt;/p&gt; &#xA; &lt;p&gt;Response submitted for Rivers, Stacey&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;How to contribute&lt;/h2&gt; &#xA;&lt;p&gt;Oh god please contribute this is too important to just have me, a dumb idiot, make and handle.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>thomas-yanxin/LangChain-ChatGLM-Webui</title>
    <updated>2023-04-23T01:43:02Z</updated>
    <id>tag:github.com,2023-04-23:/thomas-yanxin/LangChain-ChatGLM-Webui</id>
    <link href="https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;基于LangChain和ChatGLM-6B的针对本地知识库的自动问答&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://raw.githubusercontent.com/thomas-yanxin/LangChain-ChatGLM-Webui/master/img/bg.jpg&#34;&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GitHub-24292e&#34; alt=&#34;github&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/thomas-yanxin/LangChain-ChatLLM&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/HuggingFace-yellow&#34; alt=&#34;HuggingFace&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://modelscope.cn/studios/AI-ModelScope/LangChain-ChatLLM/summary&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/ModelScope-blueviolet&#34; alt=&#34;modelscope&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://openi.pcl.ac.cn/Learning-Develop-Union/LangChain-ChatGLM-Webui&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-OpenI-337AFF&#34; alt=&#34;OpenI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.bilibili.com/video/BV1So4y1L7Hb/?share_source=copy_web&amp;amp;vd_source=8162f92b2a1a94035ca9e4e0f6e1860a&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-bilibili-ff69b4&#34; alt=&#34;bilibili&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui/stargazers&#34;&gt;&lt;img alt=&#34;GitHub stars&#34; src=&#34;https://img.shields.io/github/stars/thomas-yanxin/LangChain-ChatGLM-Webui?color=brightgreen&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui/graphs/contributors&#34;&gt; &lt;img alt=&#34;GitHub Contributors&#34; src=&#34;https://img.shields.io/github/contributors/thomas-yanxin/LangChain-ChatGLM-Webui&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui/issues&#34;&gt;&lt;img alt=&#34;Issues&#34; src=&#34;https://img.shields.io/github/issues/thomas-yanxin/LangChain-ChatGLM-Webui?color=0088ff&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui/pulls&#34;&gt;&lt;img alt=&#34;GitHub pull requests&#34; src=&#34;https://img.shields.io/github/issues-pr/thomas-yanxin/LangChain-ChatGLM-Webui?color=orange&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.bilibili.com/video/BV1No4y1b7eu/&#34;&gt;&lt;strong&gt;视频教程&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/thomas-yanxin/LangChain-ChatLLM&#34;&gt;&lt;strong&gt;在线体验&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui/raw/master/docs/update_history.md&#34;&gt;&lt;strong&gt;更新日志&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;🔥项目体验&lt;/h2&gt; &#xA;&lt;p&gt;本项目提供基于&lt;a href=&#34;https://huggingface.co/spaces/thomas-yanxin/LangChain-ChatLLM&#34;&gt;HuggingFace社区&lt;/a&gt;和&lt;a href=&#34;https://modelscope.cn/studios/AI-ModelScope/LangChain-ChatLLM/summary&#34;&gt;ModelScope魔搭社区&lt;/a&gt;的在线体验, 欢迎尝试和反馈!&lt;/p&gt; &#xA;&lt;h2&gt;👏项目介绍&lt;/h2&gt; &#xA;&lt;p&gt;受&lt;a href=&#34;https://github.com/imClumsyPanda/langchain-ChatGLM&#34;&gt;langchain-ChatGLM&lt;/a&gt;启发, 利用LangChain和ChatGLM-6B系列模型制作的Webui, 提供基于本地知识的大模型应用.&lt;/p&gt; &#xA;&lt;p&gt;目前支持上传 txt、docx、md、pdf等文本格式文件, 提供包括ChatGLM-6B系列的模型文件以及&lt;a href=&#34;https://huggingface.co/GanymedeNil/text2vec-large-chinese&#34;&gt;GanymedeNil/text2vec-large-chinese&lt;/a&gt;、&lt;a href=&#34;https://huggingface.co/nghuyong/ernie-3.0-base-zh&#34;&gt;nghuyong/ernie-3.0-base-zh&lt;/a&gt;、&lt;a href=&#34;https://huggingface.co/nghuyong/ernie-3.0-nano-zh&#34;&gt;nghuyong/ernie-3.0-nano-zh&lt;/a&gt;等Embedding模型.&lt;/p&gt; &#xA;&lt;p&gt;效果如下: &lt;img src=&#34;https://raw.githubusercontent.com/thomas-yanxin/LangChain-ChatGLM-Webui/master/img/demo_hf.jpg&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/thomas-yanxin/LangChain-ChatGLM-Webui/master/img/demo_ms.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🚀使用方式&lt;/h2&gt; &#xA;&lt;p&gt;提供ModelScope版本和HuggingFace版本.&lt;br&gt; &lt;strong&gt;需要Python&amp;gt;=3.8.1&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;使用步骤&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;git clone本项目: &lt;code&gt;git clone https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui.git&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;进入本项目目录：&lt;code&gt;cd LangChain-ChatGLM-Webui&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;安装依赖包：&lt;code&gt;pip3 install -r requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;执行app.py：&lt;code&gt;python3 app.py&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;详细部署教程可参考: &lt;a href=&#34;https://raw.githubusercontent.com/thomas-yanxin/LangChain-ChatGLM-Webui/master/docs/deploy.md&#34;&gt;部署文档&lt;/a&gt; | &lt;a href=&#34;https://www.bilibili.com/video/BV1No4y1b7eu/&#34;&gt;视频教程&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Docker部署&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;编译镜像：&lt;code&gt;docker build -t langchain-chatglm-webui . &lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;运行镜像：&lt;code&gt;docker run -it --rm --runtime=nvidia --gpus all --network host -v /home/nodecloud/ptuning/chatglm-6b:/data/chatglm-6b langchain-chatglm-webui&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;访问服务：&lt;code&gt;http://ip:7861&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;自适应多GPU场景, 增加多GPU并行处理能力.&lt;/p&gt; &#xA;&lt;h3&gt;支持模型&lt;/h3&gt; &#xA;&lt;p&gt;若存在网络问题可点击以下链接快速下载:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;large language model&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Embedding model&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.openi.org.cn/opendata/attachment/b/3/b33c55bb-8e7c-4e9d-90e5-c310dcc776d9?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=1fa9e58b6899afd26dd3%2F20230416%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20230416T025911Z&amp;amp;X-Amz-Expires=604800&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=attachment%3B%20filename%3D%22chatglm-6b.zip%22&amp;amp;X-Amz-Signature=89de83c6dae3702387d14078845b3728a6b09e5e84fc57dbe66c1566f43482a7&#34;&gt;ChatGLM-6B&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.openi.org.cn/opendata/attachment/a/2/a2f0edca-1b7b-4dfc-b7c8-15730d33cc3e?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=1fa9e58b6899afd26dd3%2F20230416%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20230416T044328Z&amp;amp;X-Amz-Expires=604800&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=attachment%3B%20filename%3D%22text2vec-large-chinese.zip%22&amp;amp;X-Amz-Signature=7468efbc7700f652e61386fe0d04b4d36dbd6cb8ff46d4cfd17c0f37bbaf868e&#34;&gt;text2vec-large-chinese&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.openi.org.cn/opendata/attachment/3/a/3aad10d1-ac8e-48f8-ac5f-cea8b54cf41b?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=1fa9e58b6899afd26dd3%2F20230416%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20230416T032447Z&amp;amp;X-Amz-Expires=604800&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=attachment%3B%20filename%3D%22chatglm-6b-int8.zip%22&amp;amp;X-Amz-Signature=d58c08158ef8550719f934916fe4b6afe67220a9b84036f660e952c07b8b44f6&#34;&gt;ChatGLM-6B-int8&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.openi.org.cn/opendata/attachment/7/3/733fe6e4-2c29-46d8-93e8-6be16194a204?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=1fa9e58b6899afd26dd3%2F20230416%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20230416T044454Z&amp;amp;X-Amz-Expires=604800&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=attachment%3B%20filename%3D%22ernie-3.0-base-zh.zip%22&amp;amp;X-Amz-Signature=554428b51410671dfc5dd6c928cb3e1291b0235abf7e418894bd4d5ac218123e&#34;&gt;ernie-3.0-base-zh&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.openi.org.cn/opendata/attachment/b/2/b2c7f23f-6864-40da-9c81-2c0607cb1d02?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=1fa9e58b6899afd26dd3%2F20230415%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20230415T155352Z&amp;amp;X-Amz-Expires=604800&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=attachment%3B%20filename%3D%22chatglm-6b-int4.zip%22&amp;amp;X-Amz-Signature=0488bd8a55e0b52c846630d609e68d2fa05bd0f0b057059f4f94133a17fbd35b&#34;&gt;ChatGLM-6B-int4&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.openi.org.cn/opendata/attachment/2/2/22833889-1683-422e-a44c-929bc379904c?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=1fa9e58b6899afd26dd3%2F20230416%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20230416T044402Z&amp;amp;X-Amz-Expires=604800&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=attachment%3B%20filename%3D%22ernie-3.0-nano-zh.zip%22&amp;amp;X-Amz-Signature=6599e60b224d0fc05d13dac7a3648f24c2cba0462f39220142cb91923cfdc3c5&#34;&gt;ernie-3.0-nano-zh&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.openi.org.cn/opendata/attachment/b/f/bf5131da-62e0-4b57-b52a-4135c273b4fc?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=1fa9e58b6899afd26dd3%2F20230416%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20230416T051728Z&amp;amp;X-Amz-Expires=604800&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=attachment%3B%20filename%3D%22chatglm-6b-int4-qe.zip%22&amp;amp;X-Amz-Signature=9a137b222f4e0b39c369966c1c1c1d02712728d06185e4e6501a4ae22566c3dc&#34;&gt;ChatGLM-6B-int4-qe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.openi.org.cn/opendata/attachment/c/5/c5f746c3-4c60-4fb7-8424-8f7e40f3cce8?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=1fa9e58b6899afd26dd3%2F20230416%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20230416T063343Z&amp;amp;X-Amz-Expires=604800&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=attachment%3B%20filename%3D%22ernie-3.0-xbase-zh.zip%22&amp;amp;X-Amz-Signature=f2e153cb75ea2dd520b03be88a2e50922c6ca8b86281ebb0b207a9a83254a016&#34;&gt;ernie-3.0-xbase-zh&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.openi.org.cn/opendata/attachment/2/5/25854cfb-3d57-44ff-a842-2a98e1a2dafe?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=1fa9e58b6899afd26dd3%2F20230421%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20230421T110022Z&amp;amp;X-Amz-Expires=604800&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=attachment%3B%20filename%3D%22vicuna-7b-1.1.zip%22&amp;amp;X-Amz-Signature=c0fc5e9cbc48194ffa38d9d87cd2c476230c6536440d3daf961384b4f7f25871&#34;&gt;Vicuna-7b-1.1&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.openi.org.cn/opendata/attachment/2/6/26f570ea-03c8-4e48-8058-e90b4854edfb?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=1fa9e58b6899afd26dd3%2F20230422%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20230422T092629Z&amp;amp;X-Amz-Expires=604800&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=attachment%3B%20filename%3D%22BELLE-LLaMA-7B-2M.zip%22&amp;amp;X-Amz-Signature=c8a3f1c6afe3735134b39c7267a55cfe02ec33121307b7f27867576ea0cd85ae&#34;&gt;BELLE-LLaMA-7B-2M.zip&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Minimax&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;💪更新日志&lt;/h2&gt; &#xA;&lt;p&gt;详情请见: &lt;a href=&#34;https://raw.githubusercontent.com/thomas-yanxin/LangChain-ChatGLM-Webui/master/docs/update_history.md&#34;&gt;更新日志&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;项目处于初期阶段, 有很多可以做的地方和优化的空间, 欢迎感兴趣的社区大佬们一起加入!&lt;/p&gt; &#xA;&lt;h2&gt;❤️引用&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34;&gt;ChatGLM-6B&lt;/a&gt;: ChatGLM-6B: 开源双语对话语言模型&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt;: Building applications with LLMs through composability&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/imClumsyPanda/langchain-ChatGLM&#34;&gt;langchain-ChatGLM&lt;/a&gt;: 基于本地知识的 ChatGLM 应用实现&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;🙇‍感谢&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/imClumsyPanda/langchain-ChatGLM&#34;&gt;langchain-ChatGLM&lt;/a&gt;提供的基础框架&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.cn/home&#34;&gt;魔搭ModelScope&lt;/a&gt;提供展示空间&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openi.pcl.ac.cn/&#34;&gt;OpenI启智社区&lt;/a&gt;提供调试算力&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/online2311&#34;&gt;@online2311&lt;/a&gt;进行&lt;a href=&#34;https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui/issues/4&#34;&gt;多卡测试&lt;/a&gt;、&lt;a href=&#34;https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui/pull/6&#34;&gt;增加外部访问支持、增加ChatGLM-6b-local 本地模型读取路径、修复text2vec 无法加载的错误、增加 Dockerfile、增加Docker 使用说明&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#thomas-yanxin/LangChain-ChatGLM-Webui&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=thomas-yanxin/LangChain-ChatGLM-Webui&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>lucidrains/naturalspeech2-pytorch</title>
    <updated>2023-04-23T01:43:02Z</updated>
    <id>tag:github.com,2023-04-23:/lucidrains/naturalspeech2-pytorch</id>
    <link href="https://github.com/lucidrains/naturalspeech2-pytorch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Implementation of Natural Speech 2, Zero-shot Speech and Singing Synthesizer, in Pytorch&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lucidrains/naturalspeech2-pytorch/main/naturalspeech2.png&#34; width=&#34;450px&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Natural Speech 2 - Pytorch (wip)&lt;/h2&gt; &#xA;&lt;p&gt;Implementation of &lt;a href=&#34;https://arxiv.org/abs/2304.09116&#34;&gt;Natural Speech 2&lt;/a&gt;, Zero-shot Speech and Singing Synthesizer, in Pytorch&lt;/p&gt; &#xA;&lt;p&gt;They simply apply latent diffusion to residual vector quantized latents for these results.&lt;/p&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pip install naturalspeech2-pytorch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from naturalspeech2_pytorch import (&#xA;    EncodecWrapper,&#xA;    Transformer,&#xA;    NaturalSpeech2&#xA;)&#xA;&#xA;# use encodec as an example&#xA;&#xA;codec = EncodecWrapper()&#xA;&#xA;model = Transformer(&#xA;    dim = codec.codebook_dim,&#xA;    depth = 12&#xA;)&#xA;&#xA;# natural speech diffusion model&#xA;&#xA;diffusion = NaturalSpeech2(&#xA;    model = model,&#xA;    codec = codec,&#xA;    timesteps = 1000&#xA;).cuda()&#xA;&#xA;# mock raw audio data&#xA;&#xA;raw_audio = torch.randn(4, 327680).cuda()&#xA;&#xA;loss = diffusion(raw_audio)&#xA;loss.backward()&#xA;&#xA;# do the above in a loop for a lot of raw audio data...&#xA;# then you can sample from your generative model as so&#xA;&#xA;generated_audio = diffusion.sample(length = 1024) # (1, 327680)&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Appreciation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://stability.ai/&#34;&gt;Stability&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/&#34;&gt;🤗 Huggingface&lt;/a&gt; for their generous sponsorships to work on and open source cutting edge artificial intelligence research&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://huggingface.co/&#34;&gt;🤗 Huggingface&lt;/a&gt; for the amazing accelerate library&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citations&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{Shen2023NaturalSpeech2L,&#xA;    title   = {NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers},&#xA;    author  = {Kai Shen and Zeqian Ju and Xu Tan and Yanqing Liu and Yichong Leng and Lei He and Tao Qin and Sheng Zhao and Jiang Bian},&#xA;    year    = {2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>