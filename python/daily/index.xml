<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-08-24T01:33:05Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>SylphAI-Inc/AdalFlow</title>
    <updated>2024-08-24T01:33:05Z</updated>
    <id>tag:github.com,2024-08-24:/SylphAI-Inc/AdalFlow</id>
    <link href="https://github.com/SylphAI-Inc/AdalFlow" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AdalFlow: The ‚ÄúPyTorch‚Äù library to auto-optimize any LLM tasks.&lt;/p&gt;&lt;hr&gt;&lt;h4 align=&#34;center&#34;&gt; &lt;img alt=&#34;AdalFlow logo&#34; src=&#34;https://raw.githubusercontent.com/SylphAI-Inc/LightRAG/main/docs/source/_static/images/adalflow-logo.png&#34; style=&#34;width: 100%;&#34;&gt; &lt;/h4&gt; &#xA;&lt;h2&gt; &lt;p align=&#34;center&#34;&gt; ‚ö° The Library to Build and Auto-optimize LLM Applications ‚ö° &lt;/p&gt; &lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://colab.research.google.com/drive/1TKw_JHE42Z_AWo8UuRYZCO2iuMgyslTZ?usp=sharing&#34;&gt; &lt;img alt=&#34;Try Quickstart in Colab&#34; src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; &lt;p&gt; &lt;a href=&#34;https://adalflow.sylph.ai/&#34;&gt;All Documentation&lt;/a&gt; | &lt;a href=&#34;https://adalflow.sylph.ai/apis/components/components.model_client.html&#34;&gt;Models&lt;/a&gt; | &lt;a href=&#34;https://adalflow.sylph.ai/apis/components/components.retriever.html&#34;&gt;Retrievers&lt;/a&gt; | &lt;a href=&#34;https://adalflow.sylph.ai/apis/components/components.agent.html&#34;&gt;Agents&lt;/a&gt; | &lt;a href=&#34;https://adalflow.sylph.ai/use_cases/question_answering.html&#34;&gt;Trainer &amp;amp; Optimizers&lt;/a&gt; &lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;/h4&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://pypi.org/project/adalflow/&#34;&gt; &lt;img alt=&#34;PyPI Version&#34; src=&#34;https://img.shields.io/pypi/v/adalflow?style=flat-square&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://star-history.com/#SylphAI-Inc/LightRAG&#34;&gt; &lt;img alt=&#34;GitHub stars&#34; src=&#34;https://img.shields.io/github/stars/SylphAI-Inc/LightRAG?style=flat-square&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/SylphAI-Inc/LightRAG/issues&#34;&gt; &lt;img alt=&#34;Open Issues&#34; src=&#34;https://img.shields.io/github/issues-raw/SylphAI-Inc/LightRAG?style=flat-square&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://opensource.org/license/MIT&#34;&gt; &lt;img alt=&#34;License&#34; src=&#34;https://img.shields.io/github/license/SylphAI-Inc/LightRAG&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://discord.gg/ezzszrRZvT&#34;&gt; &lt;img alt=&#34;discord-invite&#34; src=&#34;https://dcbadge.vercel.app/api/server/ezzszrRZvT?style=flat&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;!-- &lt;a href=&#34;https://colab.research.google.com/drive/1PPxYEBa6eu__LquGoFFJZkhYgWVYE6kh?usp=sharing&#34;&gt;&#xA;        &lt;img alt=&#34;Try Quickstart in Colab&#34; src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34;&gt;&#xA;    &lt;/a&gt; --&gt; &#xA;&lt;!-- &lt;a href=&#34;https://pypistats.org/packages/lightrag&#34;&gt;&#xA;&lt;img alt=&#34;PyPI Downloads&#34; src=&#34;https://img.shields.io/pypi/dm/lightRAG?style=flat-square&#34;&gt;&#xA;&lt;/a&gt; --&gt; &#xA;&lt;h1&gt;Why AdalFlow&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Embracing a design pattern similar to PyTorch, AdalFlow is powerful, light, modular, and robust. AdalFlow provides &lt;code&gt;Model-agnostic&lt;/code&gt; building blocks to build LLM task pipeline, ranging from RAG, Agents to classical NLP tasks like text classification and named entity recognition. It is easy to get high performance even with just basic manual promting.&lt;/li&gt; &#xA; &lt;li&gt;AdalFlow provides a unified auto-differentiative framework for both zero-shot prompt optimization and few-shot optimization. It advances existing auto-optimization research, including &lt;code&gt;Text-Grad&lt;/code&gt; and &lt;code&gt;DsPy&lt;/code&gt;. Through our research, &lt;code&gt;Text-Grad 2.0&lt;/code&gt; and &lt;code&gt;Learn-to-Reason Few-shot In Context Learning&lt;/code&gt;, AdalFlow &lt;code&gt;Trainer&lt;/code&gt; achieves the highest accuracy while being the most token-efficient.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;!-- It advances existing auto-optimization research, including Text-Grad and DsPy. Through our research, Text-Grad 2.0, and Learn-to-Reason Few-shot In-Context Learning, AdalFlow Trainer achieves the highest accuracy while being the most token-efficient. --&gt; &#xA;&lt;!-- AdalFlow not only helps developers build model-agnostic LLM task pipelines with full control over prompts and output processing, but it also auto-optimizes these pipelines to achieve SOTA accuracy. --&gt; &#xA;&lt;!-- Embracing a design pattern similar to PyTorch, AdalFlow is powerful, light, modular, and robust. --&gt; &#xA;&lt;p&gt;Here is our optimization demonstration on a text classification task:&lt;/p&gt; &#xA;&lt;!-- &lt;p align=&#34;center&#34;&gt;&#xA;  &lt;img src=&#34;docs/source/_static/images/classification_training_map.png&#34; alt=&#34;AdalFlow Auto-optimization&#34; style=&#34;width: 80%;&#34;&gt;&#xA;&lt;/p&gt;&#xA;&#xA;&lt;p align=&#34;center&#34;&gt;&#xA;  &lt;img src=&#34;docs/source/_static/images/classification_opt_prompt.png&#34; alt=&#34;AdalFlow Auto-optimization&#34; style=&#34;width: 80%;&#34;&gt;&#xA;&lt;/p&gt; --&gt; &#xA;&lt;p align=&#34;center&#34; style=&#34;background-color: #f0f0f0;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/SylphAI-Inc/LightRAG/main/docs/source/_static/images/classification_training_map.png&#34; style=&#34;width: 80%;&#34; alt=&#34;AdalFlow Auto-optimization&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; style=&#34;background-color: #f0f0f0;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/SylphAI-Inc/LightRAG/main/docs/source/_static/images/classification_opt_prompt.png&#34; alt=&#34;AdalFlow Optimized Prompt&#34; style=&#34;width: 80%;&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Among all libraries, we achieved the highest accuracy with manual prompting (starting at 82%) and the highest accuracy after optimization.&lt;/p&gt; &#xA;&lt;p&gt;Further reading: &lt;a href=&#34;https://adalflow.sylph.ai/use_cases/classification.html&#34;&gt;Optimize Classification&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Light, Modular, and Model-agnositc Task Pipeline&lt;/h2&gt; &#xA;&lt;p&gt;LLMs are like water; AdalFlow help developers quickly shape them into any applications, from GenAI applications such as chatbots, translation, summarization, code generation, RAG, and autonomous agents to classical NLP tasks like text classification and named entity recognition.&lt;/p&gt; &#xA;&lt;p&gt;Only two fundamental but powerful base classes: &lt;code&gt;Component&lt;/code&gt; for the pipeline and &lt;code&gt;DataClass&lt;/code&gt; for data interaction with LLMs. The result is a library with bare minimum abstraction, providing developers with &lt;em&gt;maximum customizability&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You have full control over the prompt template, the model you use, and the output parsing for your task pipeline.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/SylphAI-Inc/LightRAG/main/docs/source/_static/images/AdalFlow_task_pipeline.png&#34; alt=&#34;AdalFlow Task Pipeline&#34;&gt; &lt;/p&gt; &#xA;&lt;!-- LLMs are like water; they can be shaped into anything, from GenAI applications such as chatbots, translation, summarization, code generation, and autonomous agents to classical NLP tasks like text classification and named entity recognition. They interact with the world beyond the model‚Äôs internal knowledge via retrievers, memory, and tools (function calls). Each use case is unique in its data, business logic, and user experience.&#xA;&#xA;Because of this, no library can provide out-of-the-box solutions. Users must build towards their own use case. This requires the library to be modular, robust, and have a clean, readable codebase. The only code you should put into production is code you either 100% trust or are 100% clear about how to customize and iterate. --&gt; &#xA;&lt;!-- This is what AdalFlow is: light, modular, and robust, with a 100% readable codebase. --&gt; &#xA;&lt;p&gt;Further reading: &lt;a href=&#34;https://www.linkedin.com/posts/li-yin-ai_both-ai-research-and-engineering-use-pytorch-activity-7189366364694892544-Uk1U?utm_source=share&amp;amp;utm_medium=member_desktop&#34;&gt;How We Started&lt;/a&gt;, &lt;a href=&#34;https://adalflow.sylph.ai/&#34;&gt;Introduction&lt;/a&gt;, &lt;a href=&#34;https://adalflow.sylph.ai/tutorials/lightrag_design_philosophy.html&#34;&gt;Design Philosophy&lt;/a&gt; and &lt;a href=&#34;https://adalflow.sylph.ai/tutorials/class_hierarchy.html&#34;&gt;Class hierarchy&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;!--&#xA;&#xA;**PyTorch**&#xA;&#xA;```python&#xA;import torch&#xA;import torch.nn as nn&#xA;&#xA;class Net(nn.Module):&#xA;   def __init__(self):&#xA;      super(Net, self).__init__()&#xA;      self.conv1 = nn.Conv2d(1, 32, 3, 1)&#xA;      self.conv2 = nn.Conv2d(32, 64, 3, 1)&#xA;      self.dropout1 = nn.Dropout2d(0.25)&#xA;      self.dropout2 = nn.Dropout2d(0.5)&#xA;      self.fc1 = nn.Linear(9216, 128)&#xA;      self.fc2 = nn.Linear(128, 10)&#xA;&#xA;   def forward(self, x):&#xA;      x = self.conv1(x)&#xA;      x = self.conv2(x)&#xA;      x = self.dropout1(x)&#xA;      x = self.dropout2(x)&#xA;      x = self.fc1(x)&#xA;      return self.fc2(x)&#xA;``` --&gt; &#xA;&lt;h2&gt;Unified Framework for Auto-Optimization&lt;/h2&gt; &#xA;&lt;p&gt;AdalFlow provides token-efficient and high-performing prompt optimization within a unified framework. To optimize your pipeline, simply define a &lt;code&gt;Parameter&lt;/code&gt; and pass it to our &lt;code&gt;Generator&lt;/code&gt;. Whether you need to optimize task instructions or few-shot demonstrations, our unified framework offers an easy way to &lt;strong&gt;diagnose&lt;/strong&gt;, &lt;strong&gt;visualize&lt;/strong&gt;, &lt;strong&gt;debug&lt;/strong&gt;, and &lt;strong&gt;train&lt;/strong&gt; your pipeline.&lt;/p&gt; &#xA;&lt;p&gt;This &lt;a href=&#34;https://adalflow.sylph.ai/tutorials/trace_graph.html&#34;&gt;Trace Graph&lt;/a&gt; demonstrates how our auto-differentiation works.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Trainable Task Pipeline&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Just define it as a &lt;code&gt;Parameter&lt;/code&gt; and pass it to our &lt;code&gt;Generator&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/SylphAI-Inc/LightRAG/main/docs/source/_static/images/Trainable_task_pipeline.png&#34; alt=&#34;AdalFlow Trainable Task Pipeline&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;AdalComponent &amp;amp; Trainer&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;AdalComponent&lt;/code&gt; acts as the &lt;code&gt;interpreter&lt;/code&gt; between task pipeline and the trainer, defining training and validation steps, optimizers, evaluators, loss functions, backward engine for textual gradients or tracing the demonstrations, the teacher generator.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/SylphAI-Inc/LightRAG/main/docs/source/_static/images/trainer.png&#34; alt=&#34;AdalFlow AdalComponent &amp;amp; Trainer&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;Quick Install&lt;/h1&gt; &#xA;&lt;p&gt;Install AdalFlow with pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install adalflow&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://adalflow.sylph.ai/get_started/installation.html&#34;&gt;full installation guide&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h1&gt;Documentation&lt;/h1&gt; &#xA;&lt;p&gt;AdalFlow full documentation available at &lt;a href=&#34;https://adalflow.sylph.ai/&#34;&gt;adalflow.sylph.ai&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/posts/li-yin-ai_both-ai-research-and-engineering-use-pytorch-activity-7189366364694892544-Uk1U?utm_source=share&amp;amp;utm_medium=member_desktop&#34;&gt;How We Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://adalflow.sylph.ai/&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://adalflow.sylph.ai/get_started/installation.html&#34;&gt;Full installation guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://adalflow.sylph.ai/tutorials/lightrag_design_philosophy.html&#34;&gt;Design philosophy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://adalflow.sylph.ai/tutorials/class_hierarchy.html&#34;&gt;Class hierarchy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://adalflow.sylph.ai/tutorials/index.html&#34;&gt;Tutorials&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://adalflow.sylph.ai/apis/components/components.model_client.html&#34;&gt;Supported Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://adalflow.sylph.ai/apis/components/components.retriever.html&#34;&gt;Supported Retrievers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://adalflow.sylph.ai/apis/index.html&#34;&gt;API reference&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;AdalFlow: A Tribute to Ada Lovelace&lt;/h1&gt; &#xA;&lt;p&gt;AdalFlow is named in honor of &lt;a href=&#34;https://en.wikipedia.org/wiki/Ada_Lovelace&#34;&gt;Ada Lovelace&lt;/a&gt;, the pioneering female mathematician who first recognized that machines could do more than just calculations. As a female-led team, we aim to inspire more women to enter the AI field.&lt;/p&gt; &#xA;&lt;h1&gt;Contributors&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/SylphAI-Inc/LightRAG/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=SylphAI-Inc/LightRAG&amp;amp;max=2000&#34; alt=&#34;contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Acknowledgements&lt;/h1&gt; &#xA;&lt;p&gt;Many existing works greatly inspired this project! Here is a non-exhaustive list:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üìö &lt;a href=&#34;https://github.com/pytorch/pytorch/&#34;&gt;PyTorch&lt;/a&gt; for design philosophy and design pattern of &lt;code&gt;Component&lt;/code&gt;, &lt;code&gt;Parameter&lt;/code&gt;, &lt;code&gt;Sequential&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;üìö &lt;a href=&#34;https://github.com/karpathy/micrograd&#34;&gt;Micrograd&lt;/a&gt;: A tiny autograd engine for our auto-differentiative architecture.&lt;/li&gt; &#xA; &lt;li&gt;üìö &lt;a href=&#34;https://github.com/zou-group/textgrad&#34;&gt;Text-Grad&lt;/a&gt; for the &lt;code&gt;Textual Gradient Descent&lt;/code&gt; text optimizer.&lt;/li&gt; &#xA; &lt;li&gt;üìö &lt;a href=&#34;https://github.com/stanfordnlp/dspy&#34;&gt;DSPy&lt;/a&gt; for inspiring the &lt;code&gt;__{input/output}__fields&lt;/code&gt; in our &lt;code&gt;DataClass&lt;/code&gt; and the bootstrap few-shot optimizer.&lt;/li&gt; &#xA; &lt;li&gt;üìö &lt;a href=&#34;https://github.com/google-deepmind/opro&#34;&gt;ORPO&lt;/a&gt; for adding past text instruction along with its accuracy in the text optimizer.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Citation&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@software{Yin2024AdalFlow,&#xA;  author = {Li Yin},&#xA;  title = {{AdalFlow: The Library for Large Language Model (LLM) Applications}},&#xA;  month = {7},&#xA;  year = {2024},&#xA;  doi = {10.5281/zenodo.12639531},&#xA;  url = {https://github.com/SylphAI-Inc/LightRAG}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>