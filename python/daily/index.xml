<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-09-11T01:35:50Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>unclecode/crawl4ai</title>
    <updated>2024-09-11T01:35:50Z</updated>
    <id>tag:github.com,2024-09-11:/unclecode/crawl4ai</id>
    <link href="https://github.com/unclecode/crawl4ai" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🔥🕷️ Crawl4AI: Open-source LLM Friendly Web Crawler &amp; Scrapper&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Crawl4AI v0.2.77 🕷️🤖&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/unclecode/crawl4ai/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/unclecode/crawl4ai?style=social&#34; alt=&#34;GitHub Stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/unclecode/crawl4ai/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/unclecode/crawl4ai?style=social&#34; alt=&#34;GitHub Forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/unclecode/crawl4ai/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/unclecode/crawl4ai&#34; alt=&#34;GitHub Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/unclecode/crawl4ai/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-pr/unclecode/crawl4ai&#34; alt=&#34;GitHub Pull Requests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/unclecode/crawl4ai&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Crawl4AI simplifies web crawling and data extraction, making it accessible for large language models (LLMs) and AI applications. 🆓🌐&lt;/p&gt; &#xA;&lt;h4&gt;[v0.2.77] - 2024-08-02&lt;/h4&gt; &#xA;&lt;p&gt;Major improvements in functionality, performance, and cross-platform compatibility! 🚀&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🐳 &lt;strong&gt;Docker enhancements&lt;/strong&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Significantly improved Dockerfile for easy installation on Linux, Mac, and Windows.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;🌐 &lt;strong&gt;Official Docker Hub image&lt;/strong&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Launched our first official image on Docker Hub for streamlined deployment (unclecode/crawl4ai).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;🔧 &lt;strong&gt;Selenium upgrade&lt;/strong&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Removed dependency on ChromeDriver, now using Selenium&#39;s built-in capabilities for better compatibility.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;🖼️ &lt;strong&gt;Image description&lt;/strong&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Implemented ability to generate textual descriptions for extracted images from web pages.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;⚡ &lt;strong&gt;Performance boost&lt;/strong&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Various improvements to enhance overall speed and performance.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Try it Now!&lt;/h2&gt; &#xA;&lt;p&gt;✨ Play around with this &lt;a href=&#34;https://colab.research.google.com/drive/1sJPAmeLj5PMrg2VgOwMJ2ubGIcK0cJeX?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;✨ visit our &lt;a href=&#34;https://crawl4ai.com/mkdocs/&#34;&gt;Documentation Website&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;✨ Check &lt;a href=&#34;https://crawl4ai.com/mkdocs/demo&#34;&gt;Demo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features ✨&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🆓 Completely free and open-source&lt;/li&gt; &#xA; &lt;li&gt;🤖 LLM-friendly output formats (JSON, cleaned HTML, markdown)&lt;/li&gt; &#xA; &lt;li&gt;🌍 Supports crawling multiple URLs simultaneously&lt;/li&gt; &#xA; &lt;li&gt;🎨 Extracts and returns all media tags (Images, Audio, and Video)&lt;/li&gt; &#xA; &lt;li&gt;🔗 Extracts all external and internal links&lt;/li&gt; &#xA; &lt;li&gt;📚 Extracts metadata from the page&lt;/li&gt; &#xA; &lt;li&gt;🔄 Custom hooks for authentication, headers, and page modifications before crawling&lt;/li&gt; &#xA; &lt;li&gt;🕵️ User-agent customization&lt;/li&gt; &#xA; &lt;li&gt;🖼️ Takes screenshots of the page&lt;/li&gt; &#xA; &lt;li&gt;📜 Executes multiple custom JavaScripts before crawling&lt;/li&gt; &#xA; &lt;li&gt;📚 Various chunking strategies: topic-based, regex, sentence, and more&lt;/li&gt; &#xA; &lt;li&gt;🧠 Advanced extraction strategies: cosine clustering, LLM, and more&lt;/li&gt; &#xA; &lt;li&gt;🎯 CSS selector support&lt;/li&gt; &#xA; &lt;li&gt;📝 Passes instructions/keywords to refine extraction&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Crawl4AI&lt;/h1&gt; &#xA;&lt;h2&gt;🌟 Shoutout to Contributors of v0.2.77!&lt;/h2&gt; &#xA;&lt;p&gt;A big thank you to the amazing contributors who&#39;ve made this release possible:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/aravindkarnam&#34;&gt;@aravindkarnam&lt;/a&gt; for the new image description feature&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/FractalMind&#34;&gt;@FractalMind&lt;/a&gt; for our official Docker Hub image&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ketonkss4&#34;&gt;@ketonkss4&lt;/a&gt; for helping streamline our Selenium setup&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Your contributions are driving Crawl4AI forward! 🚀&lt;/p&gt; &#xA;&lt;h2&gt;Cool Examples 🚀&lt;/h2&gt; &#xA;&lt;h3&gt;Quick Start&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from crawl4ai import WebCrawler&#xA;&#xA;# Create an instance of WebCrawler&#xA;crawler = WebCrawler()&#xA;&#xA;# Warm up the crawler (load necessary models)&#xA;crawler.warmup()&#xA;&#xA;# Run the crawler on a URL&#xA;result = crawler.run(url=&#34;https://www.nbcnews.com/business&#34;)&#xA;&#xA;# Print the extracted content&#xA;print(result.markdown)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;How to install 🛠&lt;/h2&gt; &#xA;&lt;h3&gt;Using pip 🐍&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;virtualenv venv&#xA;source venv/bin/activate&#xA;pip install &#34;crawl4ai @ git+https://github.com/unclecode/crawl4ai.git&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Using Docker 🐳&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# For Mac users (M1/M2)&#xA;# docker build --platform linux/amd64 -t crawl4ai .&#xA;docker build -t crawl4ai .&#xA;docker run -d -p 8000:80 crawl4ai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Using Docker Hub 🐳&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker pull unclecode/crawl4ai:latest&#xA;docker run -d -p 8000:80 unclecode/crawl4ai:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Speed-First Design 🚀&lt;/h2&gt; &#xA;&lt;p&gt;Perhaps the most important design principle for this library is speed. We need to ensure it can handle many links and resources in parallel as quickly as possible. By combining this speed with fast LLMs like Groq, the results will be truly amazing.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import time&#xA;from crawl4ai.web_crawler import WebCrawler&#xA;crawler = WebCrawler()&#xA;crawler.warmup()&#xA;&#xA;start = time.time()&#xA;url = r&#34;https://www.nbcnews.com/business&#34;&#xA;result = crawler.run( url, word_count_threshold=10, bypass_cache=True)&#xA;end = time.time()&#xA;print(f&#34;Time taken: {end - start}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Let&#39;s take a look the calculated time for the above code snippet:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[LOG] 🚀 Crawling done, success: True, time taken: 1.3623387813568115 seconds&#xA;[LOG] 🚀 Content extracted, success: True, time taken: 0.05715131759643555 seconds&#xA;[LOG] 🚀 Extraction, time taken: 0.05750393867492676 seconds.&#xA;Time taken: 1.439958095550537&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Fetching the content from the page took 1.3623 seconds, and extracting the content took 0.0575 seconds. 🚀&lt;/p&gt; &#xA;&lt;h3&gt;Extract Structured Data from Web Pages 📊&lt;/h3&gt; &#xA;&lt;p&gt;Crawl all OpenAI models and their fees from the official page.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os&#xA;from crawl4ai import WebCrawler&#xA;from crawl4ai.extraction_strategy import LLMExtractionStrategy&#xA;from pydantic import BaseModel, Field&#xA;&#xA;class OpenAIModelFee(BaseModel):&#xA;    model_name: str = Field(..., description=&#34;Name of the OpenAI model.&#34;)&#xA;    input_fee: str = Field(..., description=&#34;Fee for input token for the OpenAI model.&#34;)&#xA;    output_fee: str = Field(..., description=&#34;Fee for output token ßfor the OpenAI model.&#34;)&#xA;&#xA;url = &#39;https://openai.com/api/pricing/&#39;&#xA;crawler = WebCrawler()&#xA;crawler.warmup()&#xA;&#xA;result = crawler.run(&#xA;        url=url,&#xA;        word_count_threshold=1,&#xA;        extraction_strategy= LLMExtractionStrategy(&#xA;            provider= &#34;openai/gpt-4o&#34;, api_token = os.getenv(&#39;OPENAI_API_KEY&#39;), &#xA;            schema=OpenAIModelFee.schema(),&#xA;            extraction_type=&#34;schema&#34;,&#xA;            instruction=&#34;&#34;&#34;From the crawled content, extract all mentioned model names along with their fees for input and output tokens. &#xA;            Do not miss any models in the entire content. One extracted model JSON format should look like this: &#xA;            {&#34;model_name&#34;: &#34;GPT-4&#34;, &#34;input_fee&#34;: &#34;US$10.00 / 1M tokens&#34;, &#34;output_fee&#34;: &#34;US$30.00 / 1M tokens&#34;}.&#34;&#34;&#34;&#xA;        ),            &#xA;        bypass_cache=True,&#xA;    )&#xA;&#xA;print(result.extracted_content)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Execute JS, Filter Data with CSS Selector, and Clustering&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from crawl4ai import WebCrawler&#xA;from crawl4ai.chunking_strategy import CosineStrategy&#xA;&#xA;js_code = [&#34;const loadMoreButton = Array.from(document.querySelectorAll(&#39;button&#39;)).find(button =&amp;gt; button.textContent.includes(&#39;Load More&#39;)); loadMoreButton &amp;amp;&amp;amp; loadMoreButton.click();&#34;]&#xA;&#xA;crawler = WebCrawler()&#xA;crawler.warmup()&#xA;&#xA;result = crawler.run(&#xA;    url=&#34;https://www.nbcnews.com/business&#34;,&#xA;    js=js_code,&#xA;    css_selector=&#34;p&#34;,&#xA;    extraction_strategy=CosineStrategy(semantic_filter=&#34;technology&#34;)&#xA;)&#xA;&#xA;print(result.extracted_content)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Documentation 📚&lt;/h2&gt; &#xA;&lt;p&gt;For detailed documentation, including installation instructions, advanced features, and API reference, visit our &lt;a href=&#34;https://crawl4ai.com/mkdocs/&#34;&gt;Documentation Website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing 🤝&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions from the open-source community. Check out our &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/CONTRIBUTING.md&#34;&gt;contribution guidelines&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;License 📄&lt;/h2&gt; &#xA;&lt;p&gt;Crawl4AI is released under the &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/LICENSE&#34;&gt;Apache 2.0 License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contact 📧&lt;/h2&gt; &#xA;&lt;p&gt;For questions, suggestions, or feedback, feel free to reach out:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GitHub: &lt;a href=&#34;https://github.com/unclecode&#34;&gt;unclecode&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Twitter: &lt;a href=&#34;https://twitter.com/unclecode&#34;&gt;@unclecode&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Website: &lt;a href=&#34;https://crawl4ai.com&#34;&gt;crawl4ai.com&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Happy Crawling! 🕸️🚀&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#unclecode/crawl4ai&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=unclecode/crawl4ai&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>