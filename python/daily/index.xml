<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-10-07T01:34:00Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>karpathy/build-nanogpt</title>
    <updated>2024-10-07T01:34:00Z</updated>
    <id>tag:github.com,2024-10-07:/karpathy/build-nanogpt</id>
    <link href="https://github.com/karpathy/build-nanogpt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Video+code lecture on building nanoGPT from scratch&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;build nanoGPT&lt;/h1&gt; &#xA;&lt;p&gt;This repo holds the from-scratch reproduction of &lt;a href=&#34;https://github.com/karpathy/nanoGPT/tree/master&#34;&gt;nanoGPT&lt;/a&gt;. The git commits were specifically kept step by step and clean so that one can easily walk through the git commit history to see it built slowly. Additionally, there is an accompanying &lt;a href=&#34;https://youtu.be/l8pRSuU81PU&#34;&gt;video lecture on YouTube&lt;/a&gt; where you can see me introduce each commit and explain the pieces along the way.&lt;/p&gt; &#xA;&lt;p&gt;We basically start from an empty file and work our way to a reproduction of the &lt;a href=&#34;https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf&#34;&gt;GPT-2&lt;/a&gt; (124M) model. If you have more patience or money, the code can also reproduce the &lt;a href=&#34;https://arxiv.org/pdf/2005.14165&#34;&gt;GPT-3&lt;/a&gt; models. While the GPT-2 (124M) model probably trained for quite some time back in the day (2019, ~5 years ago), today, reproducing it is a matter of ~1hr and ~$10. You&#39;ll need a cloud GPU box if you don&#39;t have enough, for that I recommend &lt;a href=&#34;https://lambdalabs.com&#34;&gt;Lambda&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Note that GPT-2 and GPT-3 and both simple language models, trained on internet documents, and all they do is &#34;dream&#34; internet documents. So this repo/video this does not cover Chat finetuning, and you can&#39;t talk to it like you can talk to ChatGPT. The finetuning process (while quite simple conceptually - SFT is just about swapping out the dataset and continuing the training) comes after this part and will be covered at a later time. For now this is the kind of stuff that the 124M model says if you prompt it with &#34;Hello, I&#39;m a language model,&#34; after 10B tokens of training:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Hello, I&#39;m a language model, and my goal is to make English as easy and fun as possible for everyone, and to find out the different grammar rules&#xA;Hello, I&#39;m a language model, so the next time I go, I&#39;ll just say, I like this stuff.&#xA;Hello, I&#39;m a language model, and the question is, what should I do if I want to be a teacher?&#xA;Hello, I&#39;m a language model, and I&#39;m an English person. In languages, &#34;speak&#34; is really speaking. Because for most people, there&#39;s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And after 40B tokens of training:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Hello, I&#39;m a language model, a model of computer science, and it&#39;s a way (in mathematics) to program computer programs to do things like write&#xA;Hello, I&#39;m a language model, not a human. This means that I believe in my language model, as I have no experience with it yet.&#xA;Hello, I&#39;m a language model, but I&#39;m talking about data. You&#39;ve got to create an array of data: you&#39;ve got to create that.&#xA;Hello, I&#39;m a language model, and all of this is about modeling and learning Python. I&#39;m very good in syntax, however I struggle with Python due&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Lol. Anyway, once the video comes out, this will also be a place for FAQ, and a place for fixes and errata, of which I am sure there will be a number :)&lt;/p&gt; &#xA;&lt;p&gt;For discussions and questions, please use &lt;a href=&#34;https://github.com/karpathy/build-nanogpt/discussions&#34;&gt;Discussions tab&lt;/a&gt;, and for faster communication, have a look at my &lt;a href=&#34;https://discord.gg/3zy8kqD9Cp&#34;&gt;Zero To Hero Discord&lt;/a&gt;, channel &lt;strong&gt;#nanoGPT&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/3zy8kqD9Cp&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/3zy8kqD9Cp?compact=true&amp;amp;style=flat&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Video&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/l8pRSuU81PU&#34;&gt;Let&#39;s reproduce GPT-2 (124M) YouTube lecture&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Errata&lt;/h2&gt; &#xA;&lt;p&gt;Minor cleanup, we forgot to delete &lt;code&gt;register_buffer&lt;/code&gt; of the bias once we switched to flash attention, fixed with a recent PR.&lt;/p&gt; &#xA;&lt;p&gt;Earlier version of PyTorch may have difficulty converting from uint16 to long. Inside &lt;code&gt;load_tokens&lt;/code&gt;, we added &lt;code&gt;npt = npt.astype(np.int32)&lt;/code&gt; to use numpy to convert uint16 to int32 before converting to torch tensor and then converting to long.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;torch.autocast&lt;/code&gt; function takes an arg &lt;code&gt;device_type&lt;/code&gt;, to which I tried to stubbornly just pass &lt;code&gt;device&lt;/code&gt; hoping it works ok, but PyTorch actually really wants just the type and creates errors in some version of PyTorch. So we want e.g. the device &lt;code&gt;cuda:3&lt;/code&gt; to get stripped to &lt;code&gt;cuda&lt;/code&gt;. Currently, device &lt;code&gt;mps&lt;/code&gt; (Apple Silicon) would become &lt;code&gt;device_type&lt;/code&gt; CPU, I&#39;m not 100% sure this is the intended PyTorch way.&lt;/p&gt; &#xA;&lt;p&gt;Confusingly, &lt;code&gt;model.require_backward_grad_sync&lt;/code&gt; is actually used by both the forward and backward pass. Moved up the line so that it also gets applied to the forward pass.&lt;/p&gt; &#xA;&lt;h2&gt;Prod&lt;/h2&gt; &#xA;&lt;p&gt;For more production-grade runs that are very similar to nanoGPT, I recommend looking at the following repos:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Lightning-AI/litgpt&#34;&gt;litGPT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jzhang38/TinyLlama&#34;&gt;TinyLlama&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MIT&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ErikBjare/gptme</title>
    <updated>2024-10-07T01:34:00Z</updated>
    <id>tag:github.com,2024-10-07:/ErikBjare/gptme</id>
    <link href="https://github.com/ErikBjare/gptme" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Your agent in your terminal, equipped with local tools: writes code, uses the terminal, browses the web, vision.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://gptme.org/media/logo.png&#34; width=&#34;150&#34;&gt; &lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt;gptme&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;i&gt;/ §iÀê piÀê tiÀê miÀê/&lt;/i&gt; &lt;/p&gt; &#xA;&lt;!-- Links --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://gptme.org/docs/getting-started.html&#34;&gt;Getting Started&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://gptme.org/&#34;&gt;Website&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://gptme.org/docs/&#34;&gt;Documentation&lt;/a&gt; &lt;/p&gt; &#xA;&lt;!-- Badges --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/ErikBjare/gptme/actions/workflows/build.yml&#34;&gt; &lt;img src=&#34;https://github.com/ErikBjare/gptme/actions/workflows/build.yml/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/ErikBjare/gptme/actions/workflows/docs.yml&#34;&gt; &lt;img src=&#34;https://github.com/ErikBjare/gptme/actions/workflows/docs.yml/badge.svg?sanitize=true&#34; alt=&#34;Docs Build Status&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/ErikBjare/gptme&#34;&gt; &lt;img src=&#34;https://codecov.io/gh/ErikBjare/gptme/graph/badge.svg?token=DYAYJ8EF41&#34; alt=&#34;Codecov&#34;&gt; &lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://pypi.org/project/gptme/&#34;&gt; &lt;img src=&#34;https://img.shields.io/pypi/v/gptme&#34; alt=&#34;PyPI version&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/gptme&#34;&gt; &lt;img src=&#34;https://img.shields.io/pepy/dt/gptme&#34; alt=&#34;PyPI - Downloads all-time&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://pypistats.org/packages/gptme&#34;&gt; &lt;img src=&#34;https://img.shields.io/pypi/dd/gptme?color=success&#34; alt=&#34;PyPI - Downloads per day&#34;&gt; &lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://discord.gg/NMaCmmkxWv&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/1271539422017618012?logo=discord&amp;amp;style=social&#34; alt=&#34;Discord&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://twitter.com/ErikBjare&#34;&gt; &lt;img src=&#34;https://img.shields.io/twitter/follow/ErikBjare?style=social&#34; alt=&#34;Twitter&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; üìú Personal AI assistant in your terminal, with tools so it can:&lt;br&gt;Use the terminal, run code, edit files, browse the web, use vision, and much more;&lt;br&gt;Assists in all kinds of knowledge-work, especially programming, from a simple but powerful CLI. &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; An unconstrained local alternative to ChatGPT&#39;s &#34;Code Interpreter&#34;.&lt;br&gt;Not limited by lack of software, internet access, timeouts, or privacy concerns (if using local models). &lt;/p&gt; &#xA;&lt;h2&gt;üìö Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üé• &lt;a href=&#34;https://raw.githubusercontent.com/ErikBjare/gptme/master/#-demos&#34;&gt;Demos&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üåü &lt;a href=&#34;https://raw.githubusercontent.com/ErikBjare/gptme/master/#-features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üöÄ &lt;a href=&#34;https://raw.githubusercontent.com/ErikBjare/gptme/master/#-getting-started&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üõ† &lt;a href=&#34;https://raw.githubusercontent.com/ErikBjare/gptme/master/#-usage&#34;&gt;Usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üìä &lt;a href=&#34;https://raw.githubusercontent.com/ErikBjare/gptme/master/#-stats&#34;&gt;Stats&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üíª &lt;a href=&#34;https://raw.githubusercontent.com/ErikBjare/gptme/master/#-development&#34;&gt;Development&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üîó &lt;a href=&#34;https://raw.githubusercontent.com/ErikBjare/gptme/master/#-links&#34;&gt;Links&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üé• Demos&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] These demos have gotten fairly out of date, but they still give a good idea of what gptme can do.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Fibonacci (old)&lt;/th&gt; &#xA;   &lt;th&gt;Snake with curses&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34;&gt; &lt;p&gt;&lt;a href=&#34;https://asciinema.org/a/606375&#34;&gt;&lt;img src=&#34;https://github.com/ErikBjare/gptme/assets/1405370/5dda4240-bb7d-4cfa-8dd1-cd1218ccf571&#34; alt=&#34;demo screencast with asciinema&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;    &lt;details&gt; &#xA;     &lt;summary&gt;Steps&lt;/summary&gt; &#xA;     &lt;ol&gt; &#xA;      &lt;li&gt; Create a new dir &#39;gptme-test-fib&#39; and git init &lt;/li&gt;&#xA;      &lt;li&gt; Write a fib function to fib.py, commit &lt;/li&gt;&#xA;      &lt;li&gt; Create a public repo and push to GitHub &lt;/li&gt;&#xA;     &lt;/ol&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34;&gt; &lt;p&gt;&lt;a href=&#34;https://asciinema.org/a/621992&#34;&gt;&lt;img src=&#34;https://github.com/ErikBjare/gptme/assets/1405370/72ac819c-b633-495e-b20e-2e40753ec376&#34; alt=&#34;621992-resvg&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;    &lt;details&gt; &#xA;     &lt;summary&gt;Steps&lt;/summary&gt; &#xA;     &lt;ol&gt; &#xA;      &lt;li&gt; Create a snake game with curses to snake.py &lt;/li&gt;&#xA;      &lt;li&gt; Running fails, ask gptme to fix a bug &lt;/li&gt;&#xA;      &lt;li&gt; Game runs &lt;/li&gt;&#xA;      &lt;li&gt; Ask gptme to add color &lt;/li&gt;&#xA;      &lt;li&gt; Minor struggles &lt;/li&gt;&#xA;      &lt;li&gt; Finished game with green snake and red apple pie! &lt;/li&gt;&#xA;     &lt;/ol&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Mandelbrot with curses&lt;/th&gt; &#xA;   &lt;th&gt;Answer question from URL&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34;&gt; &lt;p&gt;&lt;a href=&#34;https://asciinema.org/a/621991&#34;&gt;&lt;img src=&#34;https://github.com/ErikBjare/gptme/assets/1405370/570860ac-80bd-4b21-b8d1-da187d7c1a95&#34; alt=&#34;mandelbrot-curses&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;    &lt;details&gt; &#xA;     &lt;summary&gt;Steps&lt;/summary&gt; &#xA;     &lt;ol&gt; &#xA;      &lt;li&gt; Render mandelbrot with curses to mandelbrot_curses.py &lt;/li&gt;&#xA;      &lt;li&gt; Program runs &lt;/li&gt;&#xA;      &lt;li&gt; Add color &lt;/li&gt;&#xA;     &lt;/ol&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;25%&#34;&gt; &lt;p&gt;&lt;a href=&#34;https://asciinema.org/a/621997&#34;&gt;&lt;img src=&#34;https://github.com/ErikBjare/gptme/assets/1405370/bae45488-f4ed-409c-a656-0c5218877de2&#34; alt=&#34;superuserlabs-ceo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;    &lt;details&gt; &#xA;     &lt;summary&gt;Steps&lt;/summary&gt; &#xA;     &lt;ol&gt; &#xA;      &lt;li&gt; Ask who the CEO of Superuser Labs is, passing website URL &lt;/li&gt;&#xA;      &lt;li&gt; gptme browses the website, and answers correctly &lt;/li&gt;&#xA;     &lt;/ol&gt; &#xA;    &lt;/details&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;You can find more &lt;a href=&#34;https://gptme.org/docs/demos.html&#34;&gt;Demos&lt;/a&gt; and &lt;a href=&#34;https://gptme.org/docs/examples.html&#34;&gt;Examples&lt;/a&gt; in the &lt;a href=&#34;https://gptme.org/docs/&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üåü Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üíª Code execution &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Executes code in your local environment with the &lt;a href=&#34;https://gptme.org/docs/tools.html#shell&#34;&gt;shell&lt;/a&gt; and &lt;a href=&#34;https://gptme.org/docs/tools.html#python&#34;&gt;python&lt;/a&gt; tools.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;üß© Read, write, and change files &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Makes incremental changes with the &lt;a href=&#34;https://gptme.org/docs/tools.html#patch&#34;&gt;patch&lt;/a&gt; tool.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;üåê Search and browse the web. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Can use a browser via Playwright with the &lt;a href=&#34;https://gptme.org/docs/tools.html#browser&#34;&gt;browser&lt;/a&gt; tool.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;üëÄ Vision &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Can see images referenced in prompts, screenshots of your desktop, and web pages.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;üîÑ Self-correcting &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Output is fed back to the assistant, allowing it to respond and self-correct.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ü§ñ Support for several LLM &lt;a href=&#34;https://gptme.org/docs/providers.html&#34;&gt;providers&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Use OpenAI, Anthropic, OpenRouter, or serve locally with &lt;code&gt;llama.cpp&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;‚ú® Many smaller features to ensure a great experience &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;üö∞ Pipe in context via &lt;code&gt;stdin&lt;/code&gt; or as arguments. &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Passing a filename as an argument will read the file and include it as context.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;‚Üí Tab completion&lt;/li&gt; &#xA;   &lt;li&gt;üìù Automatic naming of conversations&lt;/li&gt; &#xA;   &lt;li&gt;üí¨ Optional basic &lt;a href=&#34;https://gptme.org/docs/server.html&#34;&gt;Web UI and REST API&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;üõ† Developer perks&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üß∞ Easy to extend &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Most functionality is implemented as &lt;a href=&#34;https://gptme.org/docs/tools.html&#34;&gt;tools&lt;/a&gt;, making it easy to add new features.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;üß™ Extensive testing, high coverage.&lt;/li&gt; &#xA; &lt;li&gt;üßπ Clean codebase, checked and formatted with &lt;code&gt;mypy&lt;/code&gt;, &lt;code&gt;ruff&lt;/code&gt;, and &lt;code&gt;pyupgrade&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;ü§ñ &lt;a href=&#34;https://gptme.org/docs/bot.html&#34;&gt;GitHub Bot&lt;/a&gt; to request changes from comments! (see &lt;a href=&#34;https://github.com/ErikBjare/gptme/issues/16&#34;&gt;#16&lt;/a&gt;) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Operates in this repo! (see &lt;a href=&#34;https://github.com/ErikBjare/gptme/issues/18&#34;&gt;#18&lt;/a&gt; for example)&lt;/li&gt; &#xA;   &lt;li&gt;Runs entirely in GitHub Actions.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;üìä &lt;a href=&#34;https://gptme.org/docs/evals.html&#34;&gt;Evaluation suite&lt;/a&gt; for testing capabilities of different models&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;üöß In progress&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üèÜ Advanced evals for testing frontier capabilities&lt;/li&gt; &#xA; &lt;li&gt;ü§ñ Long-running agents and advanced agent architectures&lt;/li&gt; &#xA; &lt;li&gt;üå≥ Tree-based conversation structure (see &lt;a href=&#34;https://github.com/ErikBjare/gptme/issues/17&#34;&gt;#17&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;üõ† Use Cases&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üéØ &lt;strong&gt;Shell Copilot:&lt;/strong&gt; Figure out the right shell command using natural language (no more memorizing flags!).&lt;/li&gt; &#xA; &lt;li&gt;üñ• &lt;strong&gt;Development:&lt;/strong&gt; Write, test, and run code with AI assistance.&lt;/li&gt; &#xA; &lt;li&gt;üìä &lt;strong&gt;Data Analysis:&lt;/strong&gt; Easily perform data analysis and manipulations on local files.&lt;/li&gt; &#xA; &lt;li&gt;üéì &lt;strong&gt;Learning &amp;amp; Prototyping:&lt;/strong&gt; Experiment with new libraries and frameworks on-the-fly.&lt;/li&gt; &#xA; &lt;li&gt;ü§ñ &lt;strong&gt;Agents &amp;amp; Tools:&lt;/strong&gt; Experiment with agents and tools in a local environment.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Install with pipx:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# requires Python 3.10+&#xA;pipx install gptme&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now, to get started, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;gptme&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here are some examples:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;gptme &#39;write an impressive and colorful particle effect using three.js to particles.html&#39;&#xA;gptme &#39;render mandelbrot set to mandelbrot.png&#39;&#xA;gptme &#39;suggest improvements to my vimrc&#39;&#xA;gptme &#39;convert to h265 and adjust the volume&#39; video.mp4&#xA;git diff | gptme &#39;complete the TODOs in this diff&#39;&#xA;make test | gptme &#39;fix the failing tests&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more, see the &lt;a href=&#34;https://gptme.org/docs/getting-started.html&#34;&gt;Getting Started&lt;/a&gt; guide and the &lt;a href=&#34;https://gptme.org/docs/examples.html&#34;&gt;Examples&lt;/a&gt; in the &lt;a href=&#34;https://gptme.org/docs/&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üõ† Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ gptme --help&#xA;Usage: gptme [OPTIONS] [PROMPTS]...&#xA;&#xA;  gptme is a chat-CLI for LLMs, empowering them with tools to run shell&#xA;  commands, execute code, read and manipulate files, and more.&#xA;&#xA;  If PROMPTS are provided, a new conversation will be started with it. PROMPTS&#xA;  can be chained with the &#39;-&#39; separator.&#xA;&#xA;  The interface provides user commands that can be used to interact with the&#xA;  system.&#xA;&#xA;  Available commands:&#xA;    /undo         Undo the last action&#xA;    /log          Show the conversation log&#xA;    /edit         Edit the conversation in your editor&#xA;    /rename       Rename the conversation&#xA;    /fork         Create a copy of the conversation with a new name&#xA;    /summarize    Summarize the conversation&#xA;    /replay       Re-execute codeblocks in the conversation, wont store output in log&#xA;    /impersonate  Impersonate the assistant&#xA;    /tokens       Show the number of tokens used&#xA;    /tools        Show available tools&#xA;    /help         Show this help message&#xA;    /exit         Exit the program&#xA;&#xA;Options:&#xA;  -n, --name TEXT        Name of conversation. Defaults to generating a random&#xA;                         name.&#xA;  -m, --model TEXT       Model to use, e.g. openai/gpt-4o,&#xA;                         anthropic/claude-3-5-sonnet-20240620. If only&#xA;                         provider given, a default is used.&#xA;  -w, --workspace TEXT   Path to workspace directory. Pass &#39;@log&#39; to create a&#xA;                         workspace in the log directory.&#xA;  -r, --resume           Load last conversation&#xA;  -y, --no-confirm       Skips all confirmation prompts.&#xA;  -n, --non-interactive  Force non-interactive mode. Implies --no-confirm.&#xA;  --system TEXT          System prompt. Can be &#39;full&#39;, &#39;short&#39;, or something&#xA;                         custom.&#xA;  --no-stream            Don&#39;t stream responses&#xA;  --show-hidden          Show hidden system messages.&#xA;  -v, --verbose          Show verbose output.&#xA;  --version              Show version and configuration information&#xA;  --help                 Show this message and exit.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üìä Stats&lt;/h2&gt; &#xA;&lt;h3&gt;‚≠ê Stargazers over time&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://starchart.cc/ErikBjare/gptme&#34;&gt;&lt;img src=&#34;https://starchart.cc/ErikBjare/gptme.svg?sanitize=true&#34; alt=&#34;Stargazers over time&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;üìà Download Stats&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pepy.tech/project/gptme&#34;&gt;PePy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pypistats.org/packages/gptme&#34;&gt;PyPiStats&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üîó Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gptme.org/&#34;&gt;Website&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gptme.org/docs/&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ErikBjare/gptme&#34;&gt;GitHub&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.gg/NMaCmmkxWv&#34;&gt;Discord&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- links --&gt;</summary>
  </entry>
</feed>