<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-05-01T01:34:22Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>vllm-project/vllm-ascend</title>
    <updated>2025-05-01T01:34:22Z</updated>
    <id>tag:github.com,2025-05-01:/vllm-project/vllm-ascend</id>
    <link href="https://github.com/vllm-project/vllm-ascend" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Community maintained hardware plugin for vLLM on Ascend&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://raw.githubusercontent.com/vllm-project/vllm-ascend/main/docs/source/logos/vllm-ascend-logo-text-dark.png&#34;&gt; &#xA;  &lt;img alt=&#34;vllm-ascend&#34; src=&#34;https://raw.githubusercontent.com/vllm-project/vllm-ascend/main/docs/source/logos/vllm-ascend-logo-text-light.png&#34; width=&#34;55%&#34;&gt; &#xA; &lt;/picture&gt; &lt;/p&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt; vLLM Ascend Plugin &lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; | &lt;a href=&#34;https://www.hiascend.com/en/&#34;&gt;&lt;b&gt;About Ascend&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://vllm-ascend.readthedocs.io/en/latest/&#34;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://slack.vllm.ai&#34;&gt;&lt;b&gt;#sig-ascend&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://discuss.vllm.ai/c/hardware-support/vllm-ascend-support&#34;&gt;&lt;b&gt;Users Forum&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://tinyurl.com/vllm-ascend-meeting&#34;&gt;&lt;b&gt;Weekly Meeting&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a&gt;&lt;b&gt;English&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/vllm-project/vllm-ascend/main/README.zh.md&#34;&gt;&lt;b&gt;ä¸­æ–‡&lt;/b&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;em&gt;Latest News&lt;/em&gt; ðŸ”¥&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2025/03] We hosted the &lt;a href=&#34;https://mp.weixin.qq.com/s/VtxO9WXa5fC-mKqlxNUJUQ&#34;&gt;vLLM Beijing Meetup&lt;/a&gt; with vLLM team! Please find the meetup slides &lt;a href=&#34;https://drive.google.com/drive/folders/1Pid6NSFLU43DZRi0EaTcPgXsAzDvbBqF&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;[2025/02] vLLM community officially created &lt;a href=&#34;https://github.com/vllm-project/vllm-ascend&#34;&gt;vllm-project/vllm-ascend&lt;/a&gt; repo for running vLLM seamlessly on the Ascend NPU.&lt;/li&gt; &#xA; &lt;li&gt;[2024/12] We are working with the vLLM community to support &lt;a href=&#34;https://github.com/vllm-project/vllm/issues/11162&#34;&gt;[RFC]: Hardware pluggable&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;vLLM Ascend (&lt;code&gt;vllm-ascend&lt;/code&gt;) is a community maintained hardware plugin for running vLLM seamlessly on the Ascend NPU.&lt;/p&gt; &#xA;&lt;p&gt;It is the recommended approach for supporting the Ascend backend within the vLLM community. It adheres to the principles outlined in the &lt;a href=&#34;https://github.com/vllm-project/vllm/issues/11162&#34;&gt;[RFC]: Hardware pluggable&lt;/a&gt;, providing a hardware-pluggable interface that decouples the integration of the Ascend NPU with vLLM.&lt;/p&gt; &#xA;&lt;p&gt;By using vLLM Ascend plugin, popular open-source models, including Transformer-like, Mixture-of-Expert, Embedding, Multi-modal LLMs can run seamlessly on the Ascend NPU.&lt;/p&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Hardware: Atlas 800I A2 Inference series, Atlas A2 Training series&lt;/li&gt; &#xA; &lt;li&gt;OS: Linux&lt;/li&gt; &#xA; &lt;li&gt;Software: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Python &amp;gt;= 3.9, &amp;lt; 3.12&lt;/li&gt; &#xA;   &lt;li&gt;CANN &amp;gt;= 8.0.0&lt;/li&gt; &#xA;   &lt;li&gt;PyTorch &amp;gt;= 2.5.1, torch-npu &amp;gt;= 2.5.1&lt;/li&gt; &#xA;   &lt;li&gt;vLLM (the same version as vllm-ascend)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://vllm-ascend.readthedocs.io/en/latest/quick_start.html&#34;&gt;QuickStart&lt;/a&gt; and &lt;a href=&#34;https://vllm-ascend.readthedocs.io/en/latest/installation.html&#34;&gt;Installation&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://vllm-ascend.readthedocs.io/en/main/developer_guide/contributing.html&#34;&gt;CONTRIBUTING&lt;/a&gt; for more details, which is a step-by-step guide to help you set up development environment, build and test.&lt;/p&gt; &#xA;&lt;p&gt;We welcome and value any contributions and collaborations:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Please let us know if you encounter a bug by &lt;a href=&#34;https://github.com/vllm-project/vllm-ascend/issues&#34;&gt;filing an issue&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Please use &lt;a href=&#34;https://discuss.vllm.ai/c/hardware-support/vllm-ascend-support&#34;&gt;User forum&lt;/a&gt; for usage questions and help.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Branch&lt;/h2&gt; &#xA;&lt;p&gt;vllm-ascend has main branch and dev branch.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;main&lt;/strong&gt;: main branchï¼Œcorresponds to the vLLM main branch, and is continuously monitored for quality through Ascend CI.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;vX.Y.Z-dev&lt;/strong&gt;: development branch, created with part of new releases of vLLM. For example, &lt;code&gt;v0.7.3-dev&lt;/code&gt; is the dev branch for vLLM &lt;code&gt;v0.7.3&lt;/code&gt; version.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Below is maintained branches:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Branch&lt;/th&gt; &#xA;   &lt;th&gt;Status&lt;/th&gt; &#xA;   &lt;th&gt;Note&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;main&lt;/td&gt; &#xA;   &lt;td&gt;Maintained&lt;/td&gt; &#xA;   &lt;td&gt;CI commitment for vLLM main branch and vLLM 0.8.x branch&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v0.7.1-dev&lt;/td&gt; &#xA;   &lt;td&gt;Unmaintained&lt;/td&gt; &#xA;   &lt;td&gt;Only doc fixed is allowed&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v0.7.3-dev&lt;/td&gt; &#xA;   &lt;td&gt;Maintained&lt;/td&gt; &#xA;   &lt;td&gt;CI commitment for vLLM 0.7.3 version&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://vllm-ascend.readthedocs.io/en/main/developer_guide/versioning_policy.html&#34;&gt;Versioning policy&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Weekly Meeting&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;vLLM Ascend Weekly Meeting: &lt;a href=&#34;https://tinyurl.com/vllm-ascend-meeting&#34;&gt;https://tinyurl.com/vllm-ascend-meeting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Wednesday, 15:00 - 16:00 (UTC+8, &lt;a href=&#34;https://dateful.com/convert/gmt8?t=15&#34;&gt;Convert to your timezone&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Apache License 2.0, as found in the &lt;a href=&#34;https://raw.githubusercontent.com/vllm-project/vllm-ascend/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>aipotheosis-labs/aci</title>
    <updated>2025-05-01T01:34:22Z</updated>
    <id>tag:github.com,2025-05-01:/aipotheosis-labs/aci</id>
    <link href="https://github.com/aipotheosis-labs/aci" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ACI.dev is the open source platform that connects your AI agents to 600+ tool integrations with multi-tenant auth, granular permissions, and access through direct function calling or a unified MCP server.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/aipotheosis-labs/aci/main/frontend/public/aci-dev-full-logo.svg?sanitize=true&#34; alt=&#34;ACI.dev Logo&#34; width=&#34;100%&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;ACI: Open-Source Infra to Power Unified MCP Servers&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://aci.dev/docs&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Documentation-34a1bf&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/aipotheosis-labs/aci/actions/workflows/devportal.yml&#34;&gt;&lt;img src=&#34;https://github.com/aipotheosis-labs/aci/actions/workflows/devportal.yml/badge.svg?sanitize=true&#34; alt=&#34;Dev Portal CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/aipotheosis-labs/aci/actions/workflows/backend.yml&#34;&gt;&lt;img src=&#34;https://github.com/aipotheosis-labs/aci/actions/workflows/backend.yml/badge.svg?sanitize=true&#34; alt=&#34;Backend CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://badge.fury.io/py/aci-sdk&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/aci-sdk.svg?sanitize=true&#34; alt=&#34;PyPI version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/Apache-2.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.com/invite/UU2XAnfHJh&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Discord-Join_Chat-7289DA.svg?logo=discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://x.com/AipoLabs&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/AipoLabs?style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] This repo is for the ACI.dev platform. If you&#39;re looking for the &lt;strong&gt;Unified MCP&lt;/strong&gt; server built with ACI.dev, see &lt;a href=&#34;https://github.com/aipotheosis-labs/aci-mcp&#34;&gt;aci-mcp&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;ACI.dev is the open-source infrastructure layer for AI-agent tool-use. It gives your agents intent-aware access to 600+ tools with multi-tenant auth, granular permissions, and dynamic tool discoveryâ€”exposed as either direct function calls or through a &lt;strong&gt;Unified Model-Context-Protocol (MCP) server&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; Instead of writing separate OAuth flows and API clients for Google Calendar, Slack, and more, use ACI.dev to manage authentication and provide your AI agents with unified, secure function calls. Access these capabilities through our &lt;strong&gt;Unified&lt;/strong&gt; &lt;a href=&#34;https://github.com/aipotheosis-labs/aci-mcp&#34;&gt;MCP server&lt;/a&gt; or via our lightweight &lt;a href=&#34;https://github.com/aipotheosis-labs/aci-python-sdk&#34;&gt;Python SDK&lt;/a&gt;, compatible with any LLM framework.&lt;/p&gt; &#xA;&lt;p&gt;Build production-ready AI agents without the infrastructure headaches.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aipotheosis-labs/aci/main/frontend/public/aci-architecture-intro.svg?sanitize=true&#34; alt=&#34;ACI.dev Architecture&#34;&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; Join us on &lt;a href=&#34;https://discord.com/invite/UU2XAnfHJh&#34;&gt;Discord&lt;/a&gt; to help shape the future of Open Source AI Infrastructure.&lt;br&gt;&lt;br&gt; ðŸŒŸ &lt;strong&gt;Star ACI.dev to stay updated on new releases!&lt;/strong&gt;&lt;br&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/aipotheosis-labs/aci/stargazers&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/aipotheosis-labs/aci?style=social&#34; alt=&#34;GitHub Stars&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;ðŸ“º Demo Video&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/GSR9P53-_7E?feature=shared&#34;&gt;ACI.dev &lt;strong&gt;Unified MCP Server&lt;/strong&gt; Demo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/GSR9P53-_7E?feature=shared&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aipotheosis-labs/aci/main/frontend/public/umcp-demo-thumbnail.png&#34; alt=&#34;ACI.dev Unified MCP Server Demo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;âœ¨ Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;600+ Pre-built Integrations&lt;/strong&gt;: Connect to popular services and apps in minutes.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Flexible Access Methods&lt;/strong&gt;: Use our unified MCP server or our lightweight SDK for direct function calling.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi-tenant Authentication&lt;/strong&gt;: Built-in OAuth flows and secrets management for both developers and end-users.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Enhanced Agent Reliability&lt;/strong&gt;: Natural language permission boundaries and dynamic tool discovery.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Framework &amp;amp; Model Agnostic&lt;/strong&gt;: Works with any LLM framework and agent architecture.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;100% Open Source&lt;/strong&gt;: Everything released under Apache 2.0 (backend, dev portal, integrations).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ðŸ’¡ Why Use ACI.dev?&lt;/h2&gt; &#xA;&lt;p&gt;ACI.dev solves your critical infrastructure challenges for production-ready AI agents:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Authentication at Scale&lt;/strong&gt;: Connect multiple users to multiple services securely.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Discovery Without Overload&lt;/strong&gt;: Find and use the right tools without overwhelming LLM context windows.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Natural Language Permissions&lt;/strong&gt;: Control agent capabilities with human-readable boundaries.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Build Once, Run Anywhere&lt;/strong&gt;: No vendor lock-in with our open source, framework-agnostic approach.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ðŸ§° Common Use Cases&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Personal Assistant Chatbots:&lt;/strong&gt; Build chatbots that can search the web, manage calendars, send emails, interact with SaaS tools, etc.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Research Agent:&lt;/strong&gt; Conducts research on specific topics and syncs results to other apps (e.g., Notion, Google Sheets).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Outbound Sales Agent:&lt;/strong&gt; Automates lead generation, email outreach, and CRM updates.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Customer Support Agent:&lt;/strong&gt; Provides answers, manages tickets, and performs actions based on customer queries.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ðŸ”— Quick Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Managed Service:&lt;/strong&gt; &lt;a href=&#34;https://www.aci.dev/&#34;&gt;aci.dev&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Documentation:&lt;/strong&gt; &lt;a href=&#34;https://www.aci.dev/docs&#34;&gt;aci.dev/docs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Available Tools List:&lt;/strong&gt; &lt;a href=&#34;https://www.aci.dev/tools&#34;&gt;aci.dev/tools&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Python SDK:&lt;/strong&gt; &lt;a href=&#34;https://github.com/aipotheosis-labs/aci-python-sdk&#34;&gt;github.com/aipotheosis-labs/aci-python-sdk&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Unified MCP Server:&lt;/strong&gt; &lt;a href=&#34;https://github.com/aipotheosis-labs/aci-mcp&#34;&gt;github.com/aipotheosis-labs/aci-mcp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Agent Examples Built with ACI.dev:&lt;/strong&gt; &lt;a href=&#34;https://github.com/aipotheosis-labs/aci-agents&#34;&gt;github.com/aipotheosis-labs/aci-agents&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Blog:&lt;/strong&gt; &lt;a href=&#34;https://www.aci.dev/blog&#34;&gt;aci.dev/blog&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Community:&lt;/strong&gt; &lt;a href=&#34;https://discord.com/invite/UU2XAnfHJh&#34;&gt;Discord&lt;/a&gt; | &lt;a href=&#34;https://x.com/AipoLabs&#34;&gt;Twitter/X&lt;/a&gt; | &lt;a href=&#34;https://www.linkedin.com/company/aipotheosis-labs-aipolabs/posts/?feedView=all&#34;&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ðŸ’» Getting Started: Local Development&lt;/h2&gt; &#xA;&lt;p&gt;To run the full ACI.dev platform (backend server and frontend portal) locally, follow the individual README files for each component:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Backend:&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aipotheosis-labs/aci/main/backend/README.md&#34;&gt;backend/README.md&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Frontend:&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aipotheosis-labs/aci/main/frontend/README.md&#34;&gt;frontend/README.md&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ðŸ‘‹ Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions! Please see our &lt;a href=&#34;https://raw.githubusercontent.com/aipotheosis-labs/aci/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Integration Requests&lt;/h2&gt; &#xA;&lt;p&gt;Missing any integrations (apps or functions) you need? Please see our &lt;a href=&#34;https://raw.githubusercontent.com/aipotheosis-labs/aci/main/.github/ISSUE_TEMPLATE/integration_request.yml&#34;&gt;Integration Request Template&lt;/a&gt; and submit an integration request! Or, if you&#39;re feeling adventurous, you can submit a PR to add the integration yourself!&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>pytorch/executorch</title>
    <updated>2025-05-01T01:34:22Z</updated>
    <id>tag:github.com,2025-05-01:/pytorch/executorch</id>
    <link href="https://github.com/pytorch/executorch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;On-device AI across mobile, embedded and edge for PyTorch&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/pytorch/executorch/main/docs/source/_static/img/et-logo.png&#34; alt=&#34;Logo&#34; width=&#34;200&#34;&gt; &#xA; &lt;h1 align=&#34;center&#34;&gt;ExecuTorch: A powerful on-device AI Framework&lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/pytorch/executorch/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/pytorch/executorch?style=for-the-badge&amp;amp;color=blue&#34; alt=&#34;Contributors&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/pytorch/executorch/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/pytorch/executorch?style=for-the-badge&amp;amp;color=blue&#34; alt=&#34;Stargazers&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://discord.gg/Dh43CKSAdc&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Discord-Join%20Us-purple?logo=discord&amp;amp;logoColor=white&amp;amp;style=for-the-badge&#34; alt=&#34;Join our Discord community&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://pytorch.org/executorch/main/index&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Documentation-000?logo=googledocs&amp;amp;logoColor=FFE165&amp;amp;style=for-the-badge&#34; alt=&#34;Check out the documentation&#34;&gt;&lt;/a&gt; &#xA; &lt;hr&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;strong&gt;ExecuTorch&lt;/strong&gt; is an end-to-end solution for on-device inference and training. It powers much of Meta&#39;s on-device AI experiences across Facebook, Instagram, Meta Quest, Ray-Ban Meta Smart Glasses, WhatsApp, and more.&lt;/p&gt; &#xA;&lt;p&gt;It supports a wide range of models including LLMs (Large Language Models), CV (Computer Vision), ASR (Automatic Speech Recognition), and TTS (Text to Speech).&lt;/p&gt; &#xA;&lt;p&gt;Platform Support:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Operating Systems:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;iOS&lt;/li&gt; &#xA;   &lt;li&gt;Mac&lt;/li&gt; &#xA;   &lt;li&gt;Android&lt;/li&gt; &#xA;   &lt;li&gt;Linux&lt;/li&gt; &#xA;   &lt;li&gt;Microcontrollers&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Hardware Acceleration:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Apple&lt;/li&gt; &#xA;   &lt;li&gt;Arm&lt;/li&gt; &#xA;   &lt;li&gt;Cadence&lt;/li&gt; &#xA;   &lt;li&gt;MediaTek&lt;/li&gt; &#xA;   &lt;li&gt;OpenVINO&lt;/li&gt; &#xA;   &lt;li&gt;Qualcomm&lt;/li&gt; &#xA;   &lt;li&gt;Vulkan&lt;/li&gt; &#xA;   &lt;li&gt;XNNPACK&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Key value propositions of ExecuTorch are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Portability:&lt;/strong&gt; Compatibility with a wide variety of computing platforms, from high-end mobile phones to highly constrained embedded systems and microcontrollers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Productivity:&lt;/strong&gt; Enabling developers to use the same toolchains and Developer Tools from PyTorch model authoring and conversion, to debugging and deployment to a wide variety of platforms.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Performance:&lt;/strong&gt; Providing end users with a seamless and high-performance experience due to a lightweight runtime and utilizing full hardware capabilities such as CPUs, NPUs, and DSPs.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To get started you can:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Visit the &lt;a href=&#34;https://pytorch.org/executorch/stable/getting-started.html&#34;&gt;Step by Step Tutorial&lt;/a&gt; to get things running locally and deploy a model to a device&lt;/li&gt; &#xA; &lt;li&gt;Use this &lt;a href=&#34;https://colab.research.google.com/drive/1qpxrXC3YdJQzly3mRg-4ayYiOjC6rue3?usp=sharing&#34;&gt;Colab Notebook&lt;/a&gt; to start playing around right away&lt;/li&gt; &#xA; &lt;li&gt;Jump straight into LLM use cases by following specific instructions for popular open-source models such as &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/executorch/main/examples/models/llama/README.md&#34;&gt;Llama&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/executorch/main/examples/models/qwen3/README.md&#34;&gt;Qwen 3&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/executorch/main/examples/models/phi_4_mini/README.md&#34;&gt;Phi-4-mini&lt;/a&gt;, and &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/executorch/main/examples/models/llava/README.md&#34;&gt;Llava&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Feedback and Engagement&lt;/h2&gt; &#xA;&lt;p&gt;We welcome any feedback, suggestions, and bug reports from the community to help us improve our technology. Check out the &lt;a href=&#34;https://github.com/pytorch/executorch/discussions&#34;&gt;Discussion Board&lt;/a&gt; or chat real time with us on &lt;a href=&#34;https://discord.gg/Dh43CKSAdc&#34;&gt;Discord&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions. To get started review the &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/executorch/main/CONTRIBUTING.md&#34;&gt;guidelines&lt;/a&gt; and chat with us on &lt;a href=&#34;https://discord.gg/Dh43CKSAdc&#34;&gt;Discord&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Directory Structure&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/executorch/main/CONTRIBUTING.md#codebase-structure&#34;&gt;Codebase structure&lt;/a&gt; section of the &lt;a href=&#34;https://raw.githubusercontent.com/pytorch/executorch/main/CONTRIBUTING.md&#34;&gt;Contributing Guidelines&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;ExecuTorch is BSD licensed, as found in the LICENSE file.&lt;/p&gt;</summary>
  </entry>
</feed>