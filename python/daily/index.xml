<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-06T01:39:48Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Bdenneu/CVE-2022-33679</title>
    <updated>2022-11-06T01:39:48Z</updated>
    <id>tag:github.com,2022-11-06:/Bdenneu/CVE-2022-33679</id>
    <link href="https://github.com/Bdenneu/CVE-2022-33679" rel="alternate"></link>
    <summary type="html">&lt;p&gt;One day based on https://googleprojectzero.blogspot.com/2022/10/rc4-is-still-considered-harmful.html&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CVE-2022-33679&lt;/h1&gt; &#xA;&lt;p&gt;One day based on &lt;a href=&#34;https://googleprojectzero.blogspot.com/2022/10/rc4-is-still-considered-harmful.html&#34;&gt;https://googleprojectzero.blogspot.com/2022/10/rc4-is-still-considered-harmful.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;usage: CVE-2022-33079.py [-h] [-ts] [-debug] [-dc-ip ip address] target serverName&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Bdenneu/CVE-2022-33679/main/images/example.png&#34; alt=&#34;Alt text&#34; title=&#34;Example&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>JingShing/Encryptor-Decryptor</title>
    <updated>2022-11-06T01:39:48Z</updated>
    <id>tag:github.com,2022-11-06:/JingShing/Encryptor-Decryptor</id>
    <link href="https://github.com/JingShing/Encryptor-Decryptor" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A tool for encrypt and decrypt.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/JingShing/Encryptor-Decryptor/main/README_TCH.md&#34;&gt;繁體中文&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Encryptor-Decryptor&lt;/h1&gt; &#xA;&lt;p&gt;A tool for encrypt and decrypt.&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://youtu.be/TyIL7XjMUaw?t=180&#34;&gt;Tutorial Video&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;h1&gt;tutorial&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Import file.&lt;/li&gt; &#xA; &lt;li&gt;Put key in text box.&lt;/li&gt; &#xA; &lt;li&gt;Select function you need. And press button. It will save file automatically.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;UI&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JingShing/Encryptor-Decryptor/main/image/UI.png&#34; alt=&#34;UI&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;test file&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JingShing/Encryptor-Decryptor/main/image/test_word.png&#34; alt=&#34;test&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;After encrypt&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JingShing/Encryptor-Decryptor/main/image/test_word_en.png&#34; alt=&#34;test encrypt&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;After encrypt and After decrypt&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JingShing/Encryptor-Decryptor/main/image/test_word_en_de.png&#34; alt=&#34;test encrypt&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>DataSystemsLab/GeoTorch</title>
    <updated>2022-11-06T01:39:48Z</updated>
    <id>tag:github.com,2022-11-06:/DataSystemsLab/GeoTorch</id>
    <link href="https://github.com/DataSystemsLab/GeoTorch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GeoTorch: A Spatiotemporal Deep Learning Framework&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://github.com/DataSystemsLab/GeoTorch/raw/main/data/GeoTorchLogo.png&#34; class=&#34;center&#34; width=&#34;30%&#34;&gt; &#xA;&lt;h1&gt;GeoTorch: A Spatiotemporal Deep Learning Framework&lt;/h1&gt; &#xA;&lt;p&gt;GeoTorch is a spatiotemporal deep learning framework on top of PyTorch and &lt;a href=&#34;https://sedona.apache.org/&#34;&gt;Apache Sedona&lt;/a&gt;. It enable spatiotemporal machine learning practitioners to easily and efficiently implement deep learning models targeting the applications of raster imagery datasets and spatiotemporal non-imagery datasets. Deep learning applications of raster imagery datasets include satellite imagery classification and satellite image segmentation. Applications of deep learning on spatiotemporal non-imagery datasets are mainly prediction tasks which include but are not limited to traffic volume and traffic flow prediction, taxi/bike flow/volume prediction, precipitation forecasting, and weather forecasting.&lt;/p&gt; &#xA;&lt;h2&gt;GeoTorch Modules&lt;/h2&gt; &#xA;&lt;p&gt;GeoTorch contains various modules for deep learning and data preprocessing in both raster imagery and spatiotemporal non-imagery categories. Deep learning module offers ready-to-use raster and grid datasets, transforms, and neural network models.&lt;/p&gt; &#xA;&lt;img src=&#34;https://github.com/DataSystemsLab/GeoTorch/raw/main/data/architecture.png&#34; class=&#34;center&#34; width=&#34;60%&#34; align=&#34;right&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Datasets: This module conatins processed popular datasets for raster data models and grid based spatio-temporal models. Datasets are available as ready-to-use PyTorch datasets.&lt;/li&gt; &#xA; &lt;li&gt;Models: These are PyTorch layers for popular raster data models and grid based spatio-temporal models.&lt;/li&gt; &#xA; &lt;li&gt;Transforms: Various tranformations operations that can be applied to dataset samples during model training.&lt;/li&gt; &#xA; &lt;li&gt;Preprocessing: Supports preprocessing of raster imagery and spatiotemporal non-imagery datasets in a scalable setting on top of Apache Spark and Apache Sedona. Users don&#39;t need to learn the coding concepts of Apache Sedona and Apache Spark. They only need to write their code on Python while PySpark and Apache Sedona implementations are hidden. The preprocessing module allows machine learning practitioners to prepare a trainable grid-based spatiotemporal tensor from large raw datasets along with performing various transformations on raster imagery datasets.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;GeoTorch Design Principles&lt;/h2&gt; &#xA;&lt;p&gt;GeoTorch is designed in such a way that it has the necessary building blocks for developing raster and spatiotemporal DL applications within the PyTorch ecosystem. Various functionalities available in GeoTorch deep learning module are compatible with PyTorch core units such as neural network layers, datasets, and transformations. We make the deep learning module of GeoTorch GPU compatible so that PyTorch-provided scalability and parallelism on GPU can be achieved with GPU configured devices.&lt;/p&gt; &#xA;&lt;p&gt;Although the data preprocessing module has dependencies on external big data processing libraries such as PySpark and Apache Sedona, the deep learning module only depends on PyTorch. Since the datasets component of the deep learning module provides preprocessed and trainable state-of-the-art benchmark datasets, designing applications with such benchmark datasets can be completed without requiring big data-related dependencies. Furthermore, to help machine learning practitioners build raster and spatiotemporal applications with their preferred raw datasets, our preprocessing module enables raster and spatiotemporal data processing in a pure Pythonic way without requiring the coding knowledge of Apache Spark, Apache Sedona, and other big data processing libraries while providing the scalability of Apache Spark at the same time.&lt;/p&gt; &#xA;&lt;p&gt;Our preprocessing module is designed such that it minimizes the number of methods and classes in the API. Users can perform end-to-end spatiotemporal data preprocessing, which starts by loading raw datasets and ends by generating a trainable Tensor-shaped array, with a minimum number of method calls. It helps the users understand the API fast and reduces their confusion.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Details documentation on installation, API, and programming guide is available on &lt;a href=&#34;https://kanchanchy.github.io/geotorch/&#34;&gt;GeoTorch Website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Dependency Set up&lt;/h2&gt; &#xA;&lt;p&gt;Following libraries need to be set up before using GeoTorch.&lt;/p&gt; &#xA;&lt;h5&gt;Dependencies for Deep Learning Module:&lt;/h5&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;PyTorch &amp;gt;=1.10&lt;/li&gt; &#xA; &lt;li&gt;Rasterio&lt;/li&gt; &#xA; &lt;li&gt;Scikit-image&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h5&gt;Dependencies for Preprocessing Module:&lt;/h5&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;PySpark &amp;gt;=3.0.0&lt;/li&gt; &#xA; &lt;li&gt;Apache Sedona &amp;gt;=1.2.0-incubating&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;End-to-end coding examples for various applications including model training and data preprocessing are available in our &lt;a href=&#34;https://github.com/DataSystemsLab/GeoTorch/tree/main/binders&#34;&gt;binders&lt;/a&gt; and &lt;a href=&#34;https://github.com/DataSystemsLab/GeoTorch/tree/main/examples&#34;&gt;examples&lt;/a&gt; sections.&lt;/p&gt; &#xA;&lt;p&gt;We show a very short example of satellite imagery classification using GeoTorch in a step-by-step manner below. Training a satellite imagery classification model consists of three steps: loading the dataset, initializing the model and parameters, and train the model. We pick the &lt;a href=&#34;https://arxiv.org/abs/1911.07747&#34;&gt;DeepSatV2&lt;/a&gt; model to classify &lt;a href=&#34;https://github.com/phelber/EuroSAT&#34;&gt;EuroSAT&lt;/a&gt; satellite images.&lt;/p&gt; &#xA;&lt;h4&gt;EuroSAT Image Classes&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Annual Crop&lt;/li&gt; &#xA; &lt;li&gt;Forest&lt;/li&gt; &#xA; &lt;li&gt;Herbaceous Vegetation&lt;/li&gt; &#xA; &lt;li&gt;Highway&lt;/li&gt; &#xA; &lt;li&gt;Industrial&lt;/li&gt; &#xA; &lt;li&gt;Pasture&lt;/li&gt; &#xA; &lt;li&gt;Permanent Crop&lt;/li&gt; &#xA; &lt;li&gt;Residential&lt;/li&gt; &#xA; &lt;li&gt;River&lt;/li&gt; &#xA; &lt;li&gt;SeaLake&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Spectral Bands of a Highway Image&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/DataSystemsLab/GeoTorch/raw/main/data/euro-highway.png&#34; alt=&#34;Highway Image&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Spectral Bands of an Industry Image&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/DataSystemsLab/GeoTorch/raw/main/data/euro-industry.png&#34; alt=&#34;Industry Image&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Loading Training Dataset&lt;/h4&gt; &#xA;&lt;p&gt;Load the EuroSAT Dataset. Setting download=True will download the full data in the given directory. If data is already available, set download=False.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;full_data = geotorch.datasets.raser.EuroSAT(root=&#34;data/eurosat&#34;, download=True, include_additional_features=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Split data into 80% train and 20% validation parts&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;dataset_size = len(full_data)&#xA;indices = list(range(dataset_size))&#xA;split = int(np.floor(0.2 * dataset_size))&#xA;np.random.seed(random_seed)&#xA;np.random.shuffle(indices)&#xA;train_indices, val_indices = indices[split:], indices[:split]&#xA;&#xA;train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)&#xA;valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)&#xA;&#xA;train_loader = torch.utils.data.DataLoader(full_data, batch_size=16, sampler=train_sampler)&#xA;val_loader = torch.utils.data.DataLoader(full_data, batch_size=16, sampler=valid_sampler)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Initializing Model and Parameters&lt;/h4&gt; &#xA;&lt;p&gt;Model initialization parameters such as in_channel, in_width, in_height, and num_classes are based on the property of SAT6 dataset.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;model = DeepSatV2(in_channels=13, in_height=64, in_width=64, num_classes=10, num_filtered_features=len(full_data.ADDITIONAL_FEATURES))&#xA;loss_fn = torch.nn.CrossEntropyLoss()&#xA;optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Train the Model for One Epoch&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;for i, sample in enumerate(train_loader):&#xA;    inputs, labels, features = sample&#xA;    # Forward pass&#xA;    outputs = model(inputs, features)&#xA;    loss = loss_fn(outputs, labels)&#xA;    # Backward pass and optimize&#xA;    optimizer.zero_grad()&#xA;    loss.backward()&#xA;    optimizer.step()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Evaluate the Model on Validation Dataset&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;model.eval()&#xA;total_sample = 0&#xA;correct = 0&#xA;for i, sample in enumerate(val_loader):&#xA;    inputs, labels, features = sample&#xA;    # Forward pass&#xA;    outputs = model(inputs, features)&#xA;    total_sample += len(labels)&#xA;    _, predicted = outputs.max(1)&#xA;    correct += predicted.eq(labels).sum().item()&#xA;val_accuracy = 100 * correct / total_sample&#xA;print(&#34;Validation Accuracy: &#34;, val_accuracy, &#34;%&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Other Contributions of this Project&lt;/h2&gt; &#xA;&lt;p&gt;We also contributed to &lt;a href=&#34;https://sedona.apache.org/&#34;&gt;Apache Sedona&lt;/a&gt; to add transformation and write supports for GeoTiff raster images. This contribution is also a part of this project. Contribution reference: &lt;a href=&#34;https://github.com/apache/incubator-sedona/commits?author=kanchanchy&#34;&gt;Commits&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>