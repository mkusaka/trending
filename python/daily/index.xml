<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-20T01:36:36Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Visualize-ML/Book3_Fundamentals-of-Mathematics</title>
    <updated>2022-11-20T01:36:36Z</updated>
    <id>tag:github.com,2022-11-20:/Visualize-ML/Book3_Fundamentals-of-Mathematics</id>
    <link href="https://github.com/Visualize-ML/Book3_Fundamentals-of-Mathematics" rel="alternate"></link>
    <summary type="html">&lt;p&gt;《数学要素》，清华社五审五校中；Github稿件基本稳定，欢迎提意见，会及时修改&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Book3_Fundamentals-of-Mathematics&lt;/h1&gt; &#xA;&lt;h1&gt;BK3 《数学要素》 | 从加减乘除到机器学习&lt;/h1&gt; &#xA;&lt;p&gt;书稿持续更新，注意下载最新版本！ 本PDF文件为作者草稿，发布目的为方便读者在移动终端学习，终稿内容以清华大学出版社纸质出版物为准。 版权归清华大学出版社所有，请勿商用，引用请注明出处。 代码及PDF文件下载：&lt;a href=&#34;https://github.com/Visualize-ML&#34;&gt;https://github.com/Visualize-ML&lt;/a&gt; 本书配套微课视频均发布在B站——生姜DrGinger：&lt;a href=&#34;https://space.bilibili.com/513194466&#34;&gt;https://space.bilibili.com/513194466&lt;/a&gt; 欢迎大家批评指教，本书专属邮箱：&lt;a href=&#34;mailto:jiang.visualize.ml@gmail.com&#34;&gt;jiang.visualize.ml@gmail.com&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>thebaselab/codeapp</title>
    <updated>2022-11-20T01:36:36Z</updated>
    <id>tag:github.com,2022-11-20:/thebaselab/codeapp</id>
    <link href="https://github.com/thebaselab/codeapp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Building a full-fledged code editor for iPad&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Code App&lt;/h1&gt; &#xA;&lt;p&gt;Bringing desktop-like editing experience to iPad, available on &lt;a href=&#34;https://apps.apple.com/us/app/code-app/id1512938504&#34;&gt;App Store&lt;/a&gt; and &lt;a href=&#34;https://testflight.apple.com/join/EgZ8sE2P&#34;&gt;TestFlight&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://thebaselab.com/code/clang.png&#34; alt=&#34;Code App Screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;About the repository&lt;/h2&gt; &#xA;&lt;p&gt;This repository contains the source code of the app. We also work on issues, listen to your feedback and publish our development plan here.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/thebaselab/codeapp/wiki&#34;&gt;Wiki&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;The Plan&lt;/h2&gt; &#xA;&lt;p&gt;Use &lt;a href=&#34;https://github.com/microsoft/vscode&#34;&gt;VS Code&lt;/a&gt; as a design template while providing key functionalities with &lt;a href=&#34;https://github.com/microsoft/monaco-editor&#34;&gt;monaco-editor&lt;/a&gt; and native code:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Version Control (Git clone, commits, diff editor, push, pull and gutter indicator) ✅&lt;/li&gt; &#xA; &lt;li&gt;Embeded terminal (70+ commands avaliable) ✅&lt;/li&gt; &#xA; &lt;li&gt;Local web development environment (Node + PHP) ✅&lt;/li&gt; &#xA; &lt;li&gt;Built in Python runtime ✅&lt;/li&gt; &#xA; &lt;li&gt;C/C++ Runtime with WebAssembly (with clang support) ✅&lt;/li&gt; &#xA; &lt;li&gt;SSH Support ✅&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://microsoft.github.io/language-server-protocol&#34;&gt;LSP&lt;/a&gt; support 🏃&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Building the project&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;./downloadFrameworks.sh&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Open Code.xcworkspace&lt;/li&gt; &#xA; &lt;li&gt;Select project from file navigator&lt;/li&gt; &#xA; &lt;li&gt;Signing &amp;amp; Capabilities -&amp;gt; select your own team&lt;/li&gt; &#xA; &lt;li&gt;Change Bundle Identifier if needed&lt;/li&gt; &#xA; &lt;li&gt;Build and install on a real device (simulator is not supported)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The source code of the built-in languages are hosted on these repositories.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Language&lt;/th&gt; &#xA;   &lt;th&gt;Repository&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Python 3.9.2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/holzschu/cpython/tree/3.9&#34;&gt;cpython&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Clang 14.0.0&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/holzschu/llvm-project&#34;&gt;llvm-project&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PHP 8.0.8&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/bummoblizard/php-src/tree/PHP-8.0.8&#34;&gt;php-src&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Node.js 16.14.2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/1Conan/nodejs-mobile/tree/upstream-node-v16.14.x-ios&#34;&gt;nodejs-mobile&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
  <entry>
    <title>paperswithcode/galai</title>
    <updated>2022-11-20T01:36:36Z</updated>
    <id>tag:github.com,2022-11-20:/paperswithcode/galai</id>
    <link href="https://github.com/paperswithcode/galai" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Model API for GALACTICA&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://github.com/paperswithcode/galai/raw/main/docs/source/img/logo.png#gh-dark-mode-only&#34; width=&#34;400&#34;&gt; &lt;img src=&#34;https://github.com/paperswithcode/galai/raw/main/docs/source/img/logo_black.png#gh-light-mode-only&#34; width=&#34;400&#34;&gt; &lt;br&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/paperswithcode/galai/raw/main/LICENSE&#34;&gt; &lt;img alt=&#34;GitHub&#34; src=&#34;https://img.shields.io/github/license/paperswithcode/galai.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/paperswithcode/galai/releases&#34;&gt; &lt;img alt=&#34;GitHub release&#34; src=&#34;https://img.shields.io/github/release/paperswithcode/galai.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GALACTICA&lt;/strong&gt; is a general-purpose scientific language model. It is trained on a large corpus of scientific text and data. It can perform scientific NLP tasks at a high level, as well as tasks such as citation prediction, mathematical reasoning, molecular property prediction and protein annotation. More information is available at &lt;a href=&#34;https://galactica.org&#34;&gt;galactica.org&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;From pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install galai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;From repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install git+https://github.com/paperswithcode/galai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Models&lt;/h2&gt; &#xA;&lt;p&gt;There are five GALACTICA models available which we detail below:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Size&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Parameters&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;mini&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;125 M&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;base&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.3 B&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;standard&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6.7 B&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;large&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30 B&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;code&gt;huge&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;120 B&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import galai as gal&#xA;&#xA;model = gal.load_model(&#34;standard&#34;)&#xA;model.generate(&#34;Scaled dot product attention:\n\n\\[&#34;)&#xA;# Scaled dot product attention:\n\n\\[ \\displaystyle\\text{Attention}(Q,K,V)=\\text{softmax}(\\frac{QK^{T}}{\\sqrt{d_{k}}}%\n)V \\]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Hugging Face Integration&lt;/h2&gt; &#xA;&lt;p&gt;You can find all the model weights with their model cards and inference widget in the &lt;a href=&#34;https://huggingface.co/models?other=galactica&#34;&gt;Hugging Face Hub&lt;/a&gt;. All the models can be used out of the box with the &lt;code&gt;transformers&lt;/code&gt; library.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install transformers accelerate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can run inference using the high-level &lt;code&gt;pipeline&lt;/code&gt; API&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import pipeline&#xA;&#xA;model = pipeline(&#34;text-generation&#34;, model=&#34;facebook/galactica-6.7b&#34;)&#xA;input_text = &#34;The Transformer architecture [START_REF]&#34;&#xA;model(input_text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or for more control you can use the lower level &lt;code&gt;OPTForCausalLM&lt;/code&gt; class. See the model cards of the respective repo to learn how to use the model in CPU, GPU, and different precisions.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoTokenizer, OPTForCausalLM&#xA;&#xA;tokenizer = AutoTokenizer.from_pretrained(&#34;facebook/galactica-6.7b&#34;)&#xA;model = OPTForCausalLM.from_pretrained(&#34;facebook/galactica-6.7b&#34;, device_map=&#34;auto&#34;)&#xA;&#xA;input_text = &#34;The Transformer architecture [START_REF]&#34;&#xA;input_ids = tokenizer(input_text, return_tensors=&#34;pt&#34;).input_ids.to(&#34;cuda&#34;)&#xA;&#xA;outputs = model.generate(input_ids)&#xA;print(tokenizer.decode(outputs[0]))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Capabilities&lt;/h2&gt; &#xA;&lt;p&gt;We demonstrate some examples using the standard (6.7B) model below.&lt;/p&gt; &#xA;&lt;p&gt;📚 &lt;strong&gt;Predict Citations&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model.generate(&#34;The Transformer architecture [START_REF]&#34;)&#xA;# The Transformer architecture [START_REF] Attention is All you Need, Vaswani[END_REF] is a sequence-to-sequence model that uses self-attention to capture long-range dependencies between input and output tokens. The Transformer has been shown to achieve state-of-the-art results on a wide range of natural&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;🔢 &lt;strong&gt;Predict LaTeX&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model.generate(&#34;The Schwarzschild radius is defined as: \\[&#34;)&#xA;# The Schwarzschild radius is defined as: \\[r_{s}=\\frac{2GM}{c^{2}}\\]\n\nwhere \\(G\\) is the gravitational constant, \\(M\\) is the mass of the black hole, and&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;🤔 &lt;strong&gt;Reasoning&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model.generate(&#34;A force of 0.6N is applied to an object, which accelerates at 3m/s. What is its mass? &amp;lt;work&amp;gt;&#34;)&#xA;# What force should be applied to accelerate an object of mass 3kg to 10m/s? &amp;lt;work&amp;gt;\nWe can use Newton&#39;s second law: F = ma. We can substitute variables to get:\n\n\\[ F = \\left(66kg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;📄 &lt;strong&gt;Generate Documents&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model.generate(&#34;Lecture 1: The Ising Model\n\n&#34;, new_doc=True, top_p=0.7, max_length=200)&#xA;# &#39;Lecture 1: The Ising Model\n\n# 13 Introduction\n\nWe will now look at a simple model for magnetism, the Ising model, which is\na lattice model in which we consider only two spin values, up or down, and\nwe want to understand how these spins interact with each other and how\nthey get arranged in a particular state.\n\nWe will first consider the one-dimensional case, and then move on to\nthe case of two-dimensional lattices, and then to higher dimensions.\n\n# 14 The One-Dimensional Ising Model\n\n# 14.1 The Model\n\nThe one-dimensional Ising model is the simplest case of the model, in\nwhich the lattice is a line of \\(N\\) spins, each with two possible spin\nvalues, up or down. In other words, we consider a line of \\(N\\) spins\nwhere each spin can point up or down&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;⚛️ &lt;strong&gt;Generate Molecules&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model.generate(&#34;[START_I_SMILES]&#34;, top_p=0.6, max_length=200)&#xA;# [START_I_SMILES]CCC1=CC=C(C=C1)C(=O)NC2=CC=CC(=C2)C(=O)NC3=CC=C(C=C3)S(=O)(=O)N[END_I_SMILES]\n\n### Molecular Formula\n\nC22H21N3O4S\n\n## Chemical and Physical Properties\n\nThe following are chemical properties for 3-[[3-(4-ethylphenyl)-3-oxo-propanoyl]amino]-N-(4-sulfamoylphenyl)benzamide.\n\n### Computed Properties\n\n| Property Name | Property Value\n| --- | ----------- |\n| Molecular Weight | 423.5\n| XLogP3-AA Log P | 3.2\n| Hydrogen Bond Donor Count | 3\n| Hydrogen Bond Acceptor Count &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;🧑‍🔬 &lt;strong&gt;Predict Protein Annotations&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model.generate(&#34;[START_AMINO]GHMQSITAGQKVISKHKNGRFYQCEVVRLTTETFYEVNFDDGSFSDNLYPEDIVSQDCLQFGPPAEGEVVQVRWTDGQVYGAKFVASHPIQMYQVEFEDGSQLVVKRDDVYTLDEELP[END_AMINO] ## Keywords&#34;, max_length=200)&#xA;# &#39;[START_AMINO]GHMQSITAGQKVISKHKNGRFYQCEVVRLTTETFYEVNFDDGSFSDNLYPEDIVSQDCLQFGPPAEGEVVQVRWTDGQVYGAKFVASHPIQMYQVEFEDGSQLVVKRDDVYTLDEELP[END_AMINO] ## Keywords\n\nCytoplasm, Methyltransferase, rRNA processing, S-adenosyl-L-methionine, Transferase\n\n## References\n\nQuestion: What are some articles for Ribosomal RNA small subunit methyltransferase H?\n\nAnswer: \n\n[START_REF] Comparative Genomics of 28 Salmonella enterica Isolates: Evidence for CRISPR-Mediated Adaptive Sublineage Evolution, Fricke[END_REF]\n\n&amp;lt;/s&amp;gt;&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{GALACTICA,&#xA;    title={GALACTICA: A Large Language Model for Science},&#xA;    author={Ross Taylor and Marcin Kardas and Guillem Cucurull and Thomas Scialom and Anthony Hartshorn and Elvis Saravia and Andrew Poulton and Viktor Kerkez and Robert Stojnic},&#xA;    year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>