<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-12T01:38:27Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ishan0102/vimGPT</title>
    <updated>2023-11-12T01:38:27Z</updated>
    <id>tag:github.com,2023-11-12:/ishan0102/vimGPT</id>
    <link href="https://github.com/ishan0102/vimGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Browse the web with GPT-4V and Vimium&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;vimGPT&lt;/h1&gt; &#xA;&lt;p&gt;Giving multimodal models an interface to play with.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ishan0102/vimGPT/assets/47067154/467be2ac-7e8d-47de-af89-5bb6f51c1c31&#34;&gt;https://github.com/ishan0102/vimGPT/assets/47067154/467be2ac-7e8d-47de-af89-5bb6f51c1c31&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;LLMs as a way to browse the web is being explored by numerous startups and open-source projects. With this project, I was interested in seeing if we could only use &lt;a href=&#34;https://openai.com/research/gpt-4v-system-card&#34;&gt;GPT-4V&lt;/a&gt;&#39;s vision capabilities for web browsing.&lt;/p&gt; &#xA;&lt;p&gt;The issue with this is it&#39;s hard to determine what the model wants to click on without giving it the browser DOM as text. &lt;a href=&#34;https://vimium.github.io/&#34;&gt;Vimium&lt;/a&gt; is a Chrome extension that lets you navigate the web with only your keyboard. I thought it would be interesting to see if we could use Vimium to give the model a way to interact with the web.&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;Install Python requirements&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Download Vimium locally (have to load the extension manually when running Playwright)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./setup.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Ideas&lt;/h2&gt; &#xA;&lt;p&gt;Feel free to collaborate with me on this, I have a number of ideas:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use &lt;a href=&#34;https://platform.openai.com/docs/assistants/overview&#34;&gt;Assistant API&lt;/a&gt; once it&#39;s released for automatic context retrieval. The Assistant API will create a thread that we can add messages too, to keep the history of actions, but it doesn&#39;t support the Vision API yet.&lt;/li&gt; &#xA; &lt;li&gt;Vimium fork for overlaying elements. A specialized version of Vimium that selectively overlays elements based on context could be useful, effectively pruning based on the user query. Might be worth testing if different sized boxes/colors help.&lt;/li&gt; &#xA; &lt;li&gt;Use higher resolution images, as it seems to fail at low res. I noticed that below a certain threshold, the model wouldn&#39;t detect anything. This might be improved by using higher resolution images but that would require more tokens.&lt;/li&gt; &#xA; &lt;li&gt;Fine-tune &lt;a href=&#34;https://github.com/haotian-liu/LLaVA&#34;&gt;LLaVa&lt;/a&gt; or &lt;a href=&#34;https://github.com/THUDM/CogVLM&#34;&gt;CogVLM&lt;/a&gt; to do this or &lt;a href=&#34;https://www.adept.ai/blog/fuyu-8b&#34;&gt;Fuyu-8B&lt;/a&gt;. Could be faster/cheaper. CogVLM can accurately specify pixel coordinates which may be a good way to augment this.&lt;/li&gt; &#xA; &lt;li&gt;Use JSON mode once it&#39;s released for Vision API. Currently the Vision API doesn&#39;t support JSON mode or function calling, so we have to rely on more primitive prompting methods.&lt;/li&gt; &#xA; &lt;li&gt;Have the Vision API return general instructions, formalized by another call to the JSON mode version of the API. This is a workaround for the JSON mode issue but requires another LLM call, which is slower/more expensive.&lt;/li&gt; &#xA; &lt;li&gt;Add speech-to-text with Whisper or another model to eliminate text input and make this more accessible.&lt;/li&gt; &#xA; &lt;li&gt;Make this work for your own browser instead of spinning up an artificial one. I want to be able to order food with my credit card.&lt;/li&gt; &#xA; &lt;li&gt;Provide the frames with and without Vimium enabled in case the model can&#39;t see what&#39;s under the yellow square.&lt;/li&gt; &#xA; &lt;li&gt;Pass the Chrome accessibility tree in as input in addition to the image. This provides a layout of interactive elements that can be mapped to the Vimium bindings.&lt;/li&gt; &#xA; &lt;li&gt;Have it write longer things based on the context of the page or return information to the user based on the query. Examples are replying to an email, summarizing a news article, etc. Visual question answering.&lt;/li&gt; &#xA; &lt;li&gt;Make this a useful tool for blind people by adding voice mode and a key that creates an Assistant API for a given page. Something where you can &#34;speak to an agent&#34; about a page content in natural language.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Globe-Engineer/globot&#34;&gt;https://github.com/Globe-Engineer/globot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nat/natbot&#34;&gt;https://github.com/nat/natbot&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>AIFSH/MyHeyGen</title>
    <updated>2023-11-12T01:38:27Z</updated>
    <id>tag:github.com,2023-11-12:/AIFSH/MyHeyGen</id>
    <link href="https://github.com/AIFSH/MyHeyGen" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MyHeyGen | &lt;a href=&#34;https://raw.githubusercontent.com/AIFSH/MyHeyGen/main/README_en.md&#34;&gt;EN&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;一个平民版视频翻译工具，音频翻译，翻译校正，视频唇纹合成全流程解决方案&lt;/p&gt; &#xA;&lt;h2&gt;参考项目（感谢他们的优秀作品）&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/BrasD99/HeyGenClone.git&#34;&gt;HeyGenClone&lt;/a&gt;、&lt;a href=&#34;https://github.com/coqui-ai/tts&#34;&gt;TTS&lt;/a&gt;、&lt;a href=&#34;https://github.com/OpenTalker/video-retalking&#34;&gt;Video-retalking&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;实现效果&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1wC4y1E78h/?share_source=copy_web&amp;amp;vd_source=453c36b4abef37acd389d4c01b149023&#34;&gt;【好家伙一下子学了英语、日语、法语、俄语、韩语5国外语，肾好，肾好！ | MyHeyGen效果演示】&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1XN41137Bv/?share_source=copy_web&amp;amp;vd_source=453c36b4abef37acd389d4c01b149023&#34;&gt;【张三老师英文普法！英文区的网友有福啦】&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1vN4y1D7mo/?share_source=copy_web&amp;amp;vd_source=453c36b4abef37acd389d4c01b149023&#34;&gt;【MyHeyGen测试|这英的英语倍儿地道！】&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;视频教程&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV14C4y1J7dY/?share_source=copy_web&amp;amp;vd_source=453c36b4abef37acd389d4c01b149023&#34;&gt;【MyHeyGen来了！！！】&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;微氪方案&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1cN4y1D73X/?share_source=copy_web&amp;amp;vd_source=453c36b4abef37acd389d4c01b149023&#34;&gt;【MyHeyGen教程|这样配置应该简单很多吧】&lt;/a&gt; 相当于一键包，不需要配环境，但是得微氪金&lt;/p&gt; &#xA;&lt;h2&gt;环境准备&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;在&lt;a href=&#34;https://huggingface.co/&#34;&gt;huggingface申请token&lt;/a&gt;,放在config.json的HF_TOKEN参数下&lt;/li&gt; &#xA; &lt;li&gt;在&lt;a href=&#34;https://fanyi-api.baidu.com/?fr=pcHeader&#34;&gt;百度翻译申请APPKey&lt;/a&gt;用于翻译字幕放在config.json的TS_APPID和TS_APPKEY参数下&lt;/li&gt; &#xA; &lt;li&gt;下载&lt;code&gt;weights&lt;/code&gt; &lt;a href=&#34;https://drive.google.com/file/d/1dYy24q_67TmVuv_PbChe2t1zpNYJci1J/view?usp=sharing&#34;&gt;drive&lt;/a&gt; &lt;a href=&#34;https://pan.quark.cn/s/284713c6e873&#34;&gt;夸克&lt;/a&gt;放在MyHeyGen目录下，下载&lt;code&gt;checkpoints&lt;/code&gt; &lt;a href=&#34;https://drive.google.com/drive/folders/18rhjMpxK8LVVxf7PI6XwOidt8Vouv_H0?usp=share_link&#34;&gt;drive&lt;/a&gt; &lt;a href=&#34;https://pan.quark.cn/s/7f7d82d57a1f&#34;&gt;夸克&lt;/a&gt;放在video-retalking目录下,从weights复制GFPGANv1.4.pth到checkpoints，如下图&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;div&gt; &#xA; &lt;figure&gt; &#xA;  &lt;img alt=&#34;weights文件目录&#34; src=&#34;https://raw.githubusercontent.com/AIFSH/MyHeyGen/main/img/weights.png?raw=true&#34; width=&#34;300px&#34;&gt; &#xA;  &lt;img alt=&#34;checkpoints文件目录&#34; src=&#34;https://raw.githubusercontent.com/AIFSH/MyHeyGen/main/img/checkpoints.png?raw=true&#34; width=&#34;300px&#34;&gt; &#xA;  &lt;figure&gt; &#xA;  &lt;/figure&gt;&#xA; &lt;/figure&gt;&#xA;&lt;/div&gt; &#xA;&lt;h2&gt;安装&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/AIFSH/MyHeyGen.git&#xA;cd MyHeyGen&#xA;bash install.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;或者拉取docker镜像&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker pull registry.cn-beijing.aliyuncs.com/codewithgpu2/aifsh-myheygen:o3U7yjrWg5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;测试&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;python translate.py /root/MyHeyGen/test/src.mp4 &#39;zh-cn&#39; -o /root/MyHeyGen/test/out_zh.mp4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;自己使用&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;python translate.py 原视频文件路径 想要翻译成的语言代码 -o 翻译好的视频路径&#xA;## 语言代码可以选择这些中之一：[&#39;en&#39;, &#39;es&#39;, &#39;fr&#39;, &#39;de&#39;, &#39;it&#39;, &#39;pt&#39;, &#39;pl&#39;, &#39;tr&#39;, &#39;ru&#39;, &#39;nl&#39;, &#39;cs&#39;, &#39;ar&#39;, &#39;zh-cn&#39;, &#39;ja&#39;,&#39;hu&#39;,&#39;ko&#39;]&#xA;##分别对应[英语、西班牙语、法语、德语、意大利语、葡萄牙语、波兰语、土耳其语、俄语、荷兰语、捷克语、阿拉伯语、中文（简体）、日语、匈牙利语、韩语]16种语言&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Update log&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2023.11.7 add TTS_MODEL in config.json to custom model&lt;/li&gt; &#xA; &lt;li&gt;2023.11.8 update TTS for more reality&lt;/li&gt; &#xA; &lt;li&gt;2023.11.9 fix video-retalking oface error&lt;/li&gt; &#xA; &lt;li&gt;2023.11.10 fix librosa version conflict with latest TTS&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;交流群及打赏码&lt;/h2&gt; &#xA;&lt;div&gt; &#xA; &lt;figure&gt; &#xA;  &lt;img alt=&#34;交流群&#34; src=&#34;https://raw.githubusercontent.com/AIFSH/MyHeyGen/main/img/chat.jpg?raw=true&#34; width=&#34;300px&#34;&gt; &#xA;  &lt;img alt=&#34;赏卤蛋&#34; src=&#34;https://raw.githubusercontent.com/AIFSH/MyHeyGen/main/img/ludan.jpg?raw=true&#34; width=&#34;300px&#34;&gt; &#xA;  &lt;figure&gt; &#xA;  &lt;/figure&gt;&#xA; &lt;/figure&gt;&#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>odoo/odoo</title>
    <updated>2023-11-12T01:38:27Z</updated>
    <id>tag:github.com,2023-11-12:/odoo/odoo</id>
    <link href="https://github.com/odoo/odoo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Odoo. Open Source Apps To Grow Your Business.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://runbot.odoo.com/runbot&#34;&gt;&lt;img src=&#34;https://runbot.odoo.com/runbot/badge/flat/1/master.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.odoo.com/documentation/17.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/master-docs-875A7B.svg?style=flat&amp;amp;colorA=8F8F8F&#34; alt=&#34;Tech Doc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.odoo.com/forum/help-1&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/master-help-875A7B.svg?style=flat&amp;amp;colorA=8F8F8F&#34; alt=&#34;Help&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://nightly.odoo.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/master-nightly-875A7B.svg?style=flat&amp;amp;colorA=8F8F8F&#34; alt=&#34;Nightly Builds&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Odoo&lt;/h2&gt; &#xA;&lt;p&gt;Odoo is a suite of web based open source business apps.&lt;/p&gt; &#xA;&lt;p&gt;The main Odoo Apps include an &lt;a href=&#34;https://www.odoo.com/page/crm&#34;&gt;Open Source CRM&lt;/a&gt;, &lt;a href=&#34;https://www.odoo.com/app/website&#34;&gt;Website Builder&lt;/a&gt;, &lt;a href=&#34;https://www.odoo.com/app/ecommerce&#34;&gt;eCommerce&lt;/a&gt;, &lt;a href=&#34;https://www.odoo.com/app/inventory&#34;&gt;Warehouse Management&lt;/a&gt;, &lt;a href=&#34;https://www.odoo.com/app/project&#34;&gt;Project Management&lt;/a&gt;, &lt;a href=&#34;https://www.odoo.com/app/accounting&#34;&gt;Billing &amp;amp; Accounting&lt;/a&gt;, &lt;a href=&#34;https://www.odoo.com/app/point-of-sale-shop&#34;&gt;Point of Sale&lt;/a&gt;, &lt;a href=&#34;https://www.odoo.com/app/employees&#34;&gt;Human Resources&lt;/a&gt;, &lt;a href=&#34;https://www.odoo.com/app/social-marketing&#34;&gt;Marketing&lt;/a&gt;, &lt;a href=&#34;https://www.odoo.com/app/manufacturing&#34;&gt;Manufacturing&lt;/a&gt;, &lt;a href=&#34;https://www.odoo.com/&#34;&gt;...&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Odoo Apps can be used as stand-alone applications, but they also integrate seamlessly so you get a full-featured &lt;a href=&#34;https://www.odoo.com&#34;&gt;Open Source ERP&lt;/a&gt; when you install several Apps.&lt;/p&gt; &#xA;&lt;h2&gt;Getting started with Odoo&lt;/h2&gt; &#xA;&lt;p&gt;For a standard installation please follow the &lt;a href=&#34;https://www.odoo.com/documentation/17.0/administration/install/install.html&#34;&gt;Setup instructions&lt;/a&gt; from the documentation.&lt;/p&gt; &#xA;&lt;p&gt;To learn the software, we recommend the &lt;a href=&#34;https://www.odoo.com/slides&#34;&gt;Odoo eLearning&lt;/a&gt;, or &lt;a href=&#34;https://www.odoo.com/page/scale-up-business-game&#34;&gt;Scale-up&lt;/a&gt;, the &lt;a href=&#34;https://www.odoo.com/page/scale-up-business-game&#34;&gt;business game&lt;/a&gt;. Developers can start with &lt;a href=&#34;https://www.odoo.com/documentation/17.0/developer/howtos.html&#34;&gt;the developer tutorials&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>