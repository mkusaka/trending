<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-21T01:39:16Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>shashank-ineuron/Python-Class</title>
    <updated>2022-11-21T01:39:16Z</updated>
    <id>tag:github.com,2022-11-21:/shashank-ineuron/Python-Class</id>
    <link href="https://github.com/shashank-ineuron/Python-Class" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;</summary>
  </entry>
  <entry>
    <title>ShoufaChen/DiffusionDet</title>
    <updated>2022-11-21T01:39:16Z</updated>
    <id>tag:github.com,2022-11-21:/ShoufaChen/DiffusionDet</id>
    <link href="https://github.com/ShoufaChen/DiffusionDet" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PyTorch implementation of DiffusionDet (https://arxiv.org/abs/2211.09788)&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;DiffusionDet: Diffusion Model for Object Detection&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;DiffusionDet is the first work of diffusion model for object detection.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ShoufaChen/DiffusionDet/main/teaser.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.09788&#34;&gt;&lt;strong&gt;DiffusionDet: Diffusion Model for Object Detection&lt;/strong&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://www.shoufachen.com/&#34;&gt;Shoufa Chen&lt;/a&gt;, &lt;a href=&#34;https://peizesun.github.io/&#34;&gt;Peize Sun&lt;/a&gt;, &lt;a href=&#34;https://ybsong00.github.io/&#34;&gt;Yibing Song&lt;/a&gt;, &lt;a href=&#34;http://luoping.me/&#34;&gt;Ping Luo&lt;/a&gt;&lt;br&gt; &lt;em&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.09788&#34;&gt;arXiv 2211.09788&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Updates&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;(11/2022) Code is released.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Models&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Box AP (1 step)&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Box AP (4 step)&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Download&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ShoufaChen/DiffusionDet/main/configs/diffdet.coco.res50.yaml&#34;&gt;COCO-Res50&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ShoufaChen/DiffusionDet/releases/download/v0.1/diffdet_coco_res50.pth&#34;&gt;model&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ShoufaChen/DiffusionDet/main/configs/diffdet.coco.res101.yaml&#34;&gt;COCO-Res101&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ShoufaChen/DiffusionDet/releases/download/v0.1/diffdet_coco_res101.pth&#34;&gt;model&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ShoufaChen/DiffusionDet/main/configs/diffdet.coco.swinbase.yaml&#34;&gt;COCO-SwinBase&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ShoufaChen/DiffusionDet/releases/download/v0.1/diffdet_coco_swinbase.pth&#34;&gt;model&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ShoufaChen/DiffusionDet/main/configs/diffdet.lvis.res50.yaml&#34;&gt;LVIS-Res50&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ShoufaChen/DiffusionDet/releases/download/v0.1/diffdet_lvis_res50.pth&#34;&gt;model&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ShoufaChen/DiffusionDet/main/configs/diffdet.lvis.res101.yaml&#34;&gt;LVIS-Res101&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ShoufaChen/DiffusionDet/releases/download/v0.1/diffdet_lvis_res101.pth&#34;&gt;model&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ShoufaChen/DiffusionDet/main/configs/diffdet.lvis.swinbase.yaml&#34;&gt;LVIS-SwinBase&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;41.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ShoufaChen/DiffusionDet/releases/download/v0.1/diffdet_lvis_swinbase.pth&#34;&gt;model&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;The installation instruction and usage are in &lt;a href=&#34;https://raw.githubusercontent.com/ShoufaChen/DiffusionDet/main/GETTING_STARTED.md&#34;&gt;Getting Started with DiffusionDet&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is under the CC-BY-NC 4.0 license. See &lt;a href=&#34;https://raw.githubusercontent.com/ShoufaChen/DiffusionDet/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;h2&gt;Citing DiffusionDet&lt;/h2&gt; &#xA;&lt;p&gt;If you use DiffusionDet in your research or wish to refer to the baseline results published here, please use the following BibTeX entry.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-BibTeX&#34;&gt;@article{chen2022diffusiondet,&#xA;      title={DiffusionDet: Diffusion Model for Object Detection},&#xA;      author={Chen, Shoufa and Sun, Peize and Song, Yibing and Luo, Ping},&#xA;      journal={arXiv preprint arXiv:2211.09788},&#xA;      year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>FlagAI-Open/FlagAI</title>
    <updated>2022-11-21T01:39:16Z</updated>
    <id>tag:github.com,2022-11-21:/FlagAI-Open/FlagAI</id>
    <link href="https://github.com/FlagAI-Open/FlagAI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;FlagAI (Fast LArge-scale General AI models) is a fast, easy-to-use and extensible toolkit for large-scale model.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/logo.png&#34; alt=&#34;FlagAI&#34;&gt; &lt;a href=&#34;https://bestpractices.coreinfrastructure.org/projects/6052&#34;&gt;&lt;img src=&#34;https://bestpractices.coreinfrastructure.org/projects/6052/badge&#34; alt=&#34;CII Best Practices&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/FlagAI-Open/FlagAI/actions/workflows/python-app.yml&#34;&gt;&lt;img src=&#34;https://github.com/FlagAI-Open/FlagAI/actions/workflows/python-app.yml/badge.svg?sanitize=true&#34; alt=&#34;Python application&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/v/release/FlagAI-Open/FlagAI?include_prereleases&amp;amp;style=social&#34; alt=&#34;GitHub release (release name instead of tag name)&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/README_zh.md&#34;&gt;简体中文&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;FlagAI (Fast LArge-scale General AI models) is a fast, easy-to-use and extensible toolkit for large-scale model. Our goal is to support training, fine-tuning, and deployment of large-scale models on various downstream tasks with multi-modality.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Now it supports text-image multi-modal model &lt;a href=&#34;https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP&#34;&gt;&lt;strong&gt;AltCLIP&lt;/strong&gt;&lt;/a&gt; and text-to-imge model &lt;a href=&#34;https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltDiffusion&#34;&gt;&lt;strong&gt;AltDiffusion&lt;/strong&gt;&lt;/a&gt;. And it support &lt;strong&gt;WuDao GLM&lt;/strong&gt; with a maximum of 10 billion parameters (see &lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/GLM.md&#34;&gt;Introduction to GLM&lt;/a&gt;). It also supports &lt;strong&gt;OPT&lt;/strong&gt;, &lt;strong&gt;BERT&lt;/strong&gt;, &lt;strong&gt;RoBERTa&lt;/strong&gt;, &lt;strong&gt;GPT2&lt;/strong&gt;, &lt;strong&gt;T5&lt;/strong&gt;, and models from Huggingface Transformers.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;It provides APIs to quickly download and use those pre-trained models on a given text, fine-tune them on widely-used datasets collected from &lt;a href=&#34;https://super.gluebenchmark.com/&#34;&gt;SuperGLUE&lt;/a&gt; and &lt;a href=&#34;https://github.com/CLUEbenchmark/CLUE&#34;&gt;CLUE&lt;/a&gt; benchmarks, and then share them with the community on our model hub. It also provides &lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_7_PROMPT_LEARNING.md&#34;&gt;prompt-learning&lt;/a&gt; toolkit for few shot tasks.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;These models can be applied to (Chinese/English) Text, for tasks like text classification, information extraction, question answering, summarization, and text generation.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;FlagAI is backed by the three most popular data/model parallel libraries — &lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt;/&lt;a href=&#34;https://www.deepspeed.ai/&#34;&gt;Deepspeed&lt;/a&gt;/&lt;a href=&#34;https://github.com/NVIDIA/Megatron-LM&#34;&gt;Megatron-LM&lt;/a&gt; — with seamless integration between them. Users can parallel their training/testing process with less than ten lines of code.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The code is partially based on &lt;a href=&#34;https://github.com/THUDM/GLM&#34;&gt;GLM&lt;/a&gt;, &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;Transformers&lt;/a&gt; and &lt;a href=&#34;https://github.com/microsoft/DeepSpeedExamples/tree/master/Megatron-LM&#34;&gt;DeepSpeedExamples&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[10 Nov 2022] release v1.4.0, support &lt;a href=&#34;https://arxiv.org/abs/2211.06679v1&#34;&gt;AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities&lt;/a&gt;, examples in &lt;a href=&#34;https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP&#34;&gt;&lt;strong&gt;AltCLIP&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltDiffusion&#34;&gt;&lt;strong&gt;AltDiffusion&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[29 Aug 2022] release v1.3.0, Added CLIP module and redesigned tokenizer apis in &lt;a href=&#34;https://github.com/FlagAI-Open/FlagAI/pull/81&#34;&gt;#81&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[21 Jul 2022] release v1.2.0, ViTs are supported in &lt;a href=&#34;https://github.com/FlagAI-Open/FlagAI/pull/71&#34;&gt;#71&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[29 Jun 2022] release v1.1.0, support OPTs downloading and inference/finetuning &lt;a href=&#34;https://github.com/FlagAI-Open/FlagAI/pull/63&#34;&gt;#63&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[17 May 2022] made our first contribution in &lt;a href=&#34;https://github.com/FlagAI-Open/FlagAI/pull/1&#34;&gt;#1&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;!-- toc --&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/#requirements-and-installation&#34;&gt;Requirements and Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/#quick-start&#34;&gt;Quick Started&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/#load-model-and-tokenizer&#34;&gt;Load model and tokenizer&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/#predictor&#34;&gt;Predictor&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/#ner-task&#34;&gt;NER task&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/#title-generation-task&#34;&gt;Title generation task&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/#semantic-matching-task&#34;&gt;Semantic matching task&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/#pretrained-models-and-examples&#34;&gt;Pretrained Models and examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/#tutorials&#34;&gt;Tutorials&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/#contact-us&#34;&gt;Contact us&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- tocstop --&gt; &#xA;&lt;h2&gt;Requirements and Installation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;PyTorch version &amp;gt;= 1.8.0&lt;/li&gt; &#xA; &lt;li&gt;Python version &amp;gt;= 3.8&lt;/li&gt; &#xA; &lt;li&gt;For training/testing models on GPUs, you&#39;ll also need install CUDA and NCCL&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To install FlagAI with pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install -U flagai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[Optional]To install FlagAI and develop locally:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/FlagAI-Open/FlagAI.git&#xA;python setup.py install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[Optional] For faster training install NVIDIA&#39;s &lt;a href=&#34;https://github.com/NVIDIA/apex&#34;&gt;apex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/NVIDIA/apex&#xA;cd apex&#xA;pip install -v --disable-pip-version-check --no-cache-dir --global-option=&#34;--cpp_ext&#34; --global-option=&#34;--cuda_ext&#34; ./&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[Optional] For ZeRO optimizers install &lt;a href=&#34;https://github.com/microsoft/DeepSpeed&#34;&gt;DEEPSPEED&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/microsoft/DeepSpeed&#xA;cd DeepSpeed&#xA;DS_BUILD_CPU_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 pip install -e .&#xA;ds_report # check the deespeed status&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[Tips] For single-node docker enviroments, we need to setup ports for your ssh. e.g., root@127.0.0.1 with port 7110&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; vim ~/.ssh/config&#xA;Host 127.0.0.1&#xA;    Hostname 127.0.0.1&#xA;    Port 7110&#xA;    User root&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[Tips] For multi-node docker enviroments, generate ssh keys and copy the public key to all nodes (in &lt;code&gt;~/.ssh/&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; ssh-keygen -t rsa -C &#34;xxx@xxx.com&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;We provide many models which are trained to perform different tasks. You can load these models by AutoLoader to make prediction. See more in &lt;code&gt;FlagAI/quickstart&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Load model and tokenizer&lt;/h2&gt; &#xA;&lt;p&gt;We provide the AutoLoad class to load the model and tokenizer quickly, for example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from flagai.auto_model.auto_loader import AutoLoader&#xA;&#xA;auto_loader = AutoLoader(&#xA;    task_name=&#34;title-generation&#34;,&#xA;    model_name=&#34;BERT-base-en&#34;&#xA;)&#xA;model = auto_loader.get_model()&#xA;tokenizer = auto_loader.get_tokenizer()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This example is for the &lt;code&gt;title_generation&lt;/code&gt; task, and you can also model other tasks by modifying the &lt;code&gt;task_name&lt;/code&gt;. Then you can use the model and tokenizer to finetune or test.&lt;/p&gt; &#xA;&lt;h2&gt;Predictor&lt;/h2&gt; &#xA;&lt;p&gt;We provide the &lt;code&gt;Predictor&lt;/code&gt; class to predict for different tasks, for example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from flagai.model.predictor.predictor import Predictor&#xA;predictor = Predictor(model, tokenizer)&#xA;test_data = [&#xA;    &#34;Four minutes after the red card, Emerson Royal nodded a corner into the path of the unmarked Kane at the far post, who nudged the ball in for his 12th goal in 17 North London derby appearances. Arteta&#39;s misery was compounded two minutes after half-time when Kane held the ball up in front of goal and teed up Son to smash a shot beyond a crowd of defenders to make it 3-0.The goal moved the South Korea talisman a goal behind Premier League top scorer Mohamed Salah on 21 for the season, and he looked perturbed when he was hauled off with 18 minutes remaining, receiving words of consolation from Pierre-Emile Hojbjerg.Once his frustrations have eased, Son and Spurs will look ahead to two final games in which they only need a point more than Arsenal to finish fourth.&#34;,&#xA;]&#xA;&#xA;for text in test_data:&#xA;    print(&#xA;        predictor.predict_generate_beamsearch(text,&#xA;                                              out_max_length=50,&#xA;                                              beam_size=3))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Pretrained Models and examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_11_GLM_BLANK_FILLING_QA.md&#34;&gt;Blank_Filling_QA with GLM &lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_12_GLM_EXAMPLE_TITLE_GENERATION.md&#34;&gt;Title Generation with GLM &lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_13_GLM_EXAMPLE_PEOTRY_GENERATION.md&#34;&gt;Poetry generation with GLM-large-ch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_14_HUGGINGFACE_T5.md&#34;&gt;Using huggingface&#39;s t5-11b &amp;amp; tricks &lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_15_BERT_EXAMPLE_TITLE_GENERATION.md&#34;&gt;Title Generation with RoBerta-WWM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_16_BERT_EXAMPLE_SEMANTIC_MATCHING.md&#34;&gt;Semantic Matching with RoBerta-WWM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_17_BERT_EXAMPLE_NER.md&#34;&gt;NER with RoBerta-WWM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_18_GPT2_WRITING.md&#34;&gt;Writing with GPT-2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_19_T5_EXAMPLE_TITLE_GENERATION.md&#34;&gt;Title generation with T5&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/examples/opt/README.md&#34;&gt;Example of OPT&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This session explains how the base NLP classes work, how you can load pre-trained models to tag your text, how you can embed your text with different word or document embeddings, and how you can train your own language models, sequence labeling models, and text classification models. Let us know if anything is unclear. See more in &lt;code&gt;FlagAI/examples&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Tutorials&lt;/h2&gt; &#xA;&lt;p&gt;We provide a set of quick tutorials to get you started with the library:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_1_TOKENIZER.md&#34;&gt;Tutorial 1: How to construct and use Tokenizer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_2_DATASET.md&#34;&gt;Tutorial 2: Dataset Preprocessing Pipeline&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_3_MODEL.md&#34;&gt;Tutorial 3: Major Function of Model Module&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_4_TRAINER.md&#34;&gt;Tutorial 4: Customize trainer for model and data-parallel training&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_5_INSTRUCTIONS_FOR_AutoLoader.md&#34;&gt;Tutorial 5: Simplify model and tokenizer Initialization by Using Autoloader&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_6_INSTRUCTIONS_FOR_PREDICTOR.md&#34;&gt;Tutorial 6: Use off-the-shelf inference Algorithms with Predictor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_7_PROMPT_LERANING.md&#34;&gt;Tutorial 7: Use FlagAI prompt-learning tool-kit to improve performance on SuperGLUE&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_8_ENVIRONMENT_SETUP.md&#34;&gt;Tutorial 8: Setup environment for training models with multi-machine&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_9_SEQ2SEQ_METHOD.md&#34;&gt;Tutorial 9: Text generation with encoder/decoder/encoder-decoder models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/docs/TUTORIAL_10_MEGATRON.md&#34;&gt;Tutorial 10: How to transform a customized model into a megatron-LM-style parallel model&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Thanks for your interest in contributing! There are many ways to get involved; start with our &lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/CONTRIBUTING.md&#34;&gt;contributor guidelines&lt;/a&gt; and then check these &lt;a href=&#34;https://github.com/FlagAI-Open/FlagAI/issues&#34;&gt;open issues&lt;/a&gt; for specific tasks.&lt;/p&gt; &#xA;&lt;h2&gt;Contact us&lt;/h2&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/flagai_wechat.png&#34; width=&#34;200&#34; height=&#34;200&#34; align=&#34;center&#34;&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/LICENSE&#34;&gt;License&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;The majority of FlagAI is licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/FlagAI-Open/FlagAI/master/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;, however portions of the project are available under separate license terms:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Megatron-LM is licensed under the &lt;a href=&#34;https://github.com/NVIDIA/Megatron-LM/raw/main/LICENSE&#34;&gt;Megatron-LM license&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;GLM is licensed under the &lt;a href=&#34;https://github.com/THUDM/GLM/raw/main/LICENSE&#34;&gt;MIT license&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>