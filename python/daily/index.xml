<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Python Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-13T01:43:42Z</updated>
  <subtitle>Daily Trending of Python in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ultralytics/ultralytics</title>
    <updated>2023-01-13T01:43:42Z</updated>
    <id>tag:github.com,2023-01-13:/ultralytics/ultralytics</id>
    <link href="https://github.com/ultralytics/ultralytics" rel="alternate"></link>
    <summary type="html">&lt;p&gt;YOLOv8 üöÄ in PyTorch &gt; ONNX &gt; CoreML &gt; TFLite&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt; &lt;a align=&#34;center&#34; href=&#34;https://ultralytics.com/yolov8&#34; target=&#34;_blank&#34;&gt; &lt;img width=&#34;100%&#34; src=&#34;https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ultralytics/ultralytics/main/README.md&#34;&gt;English&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/ultralytics/ultralytics/main/README.zh-CN.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA; &lt;div&gt; &#xA;  &lt;a href=&#34;https://github.com/ultralytics/ultralytics/actions/workflows/ci.yaml&#34;&gt;&lt;img src=&#34;https://github.com/ultralytics/ultralytics/actions/workflows/ci.yaml/badge.svg?sanitize=true&#34; alt=&#34;Ultralytics CI&#34;&gt;&lt;/a&gt; &#xA;  &lt;a href=&#34;https://zenodo.org/badge/latestdoi/264818686&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/264818686.svg?sanitize=true&#34; alt=&#34;YOLOv8 Citation&#34;&gt;&lt;/a&gt; &#xA;  &lt;a href=&#34;https://hub.docker.com/r/ultralytics/ultralytics&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/ultralytics/ultralytics?logo=docker&#34; alt=&#34;Docker Pulls&#34;&gt;&lt;/a&gt; &#xA;  &lt;br&gt; &#xA;  &lt;a href=&#34;https://console.paperspace.com/github/ultralytics/ultralytics&#34;&gt;&lt;img src=&#34;https://assets.paperspace.io/img/gradient-badge.svg?sanitize=true&#34; alt=&#34;Run on Gradient&#34;&gt;&lt;/a&gt; &#xA;  &lt;a href=&#34;https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; &#xA;  &lt;a href=&#34;https://www.kaggle.com/ultralytics/yolov8&#34;&gt;&lt;img src=&#34;https://kaggle.com/static/images/open-in-kaggle.svg?sanitize=true&#34; alt=&#34;Open In Kaggle&#34;&gt;&lt;/a&gt; &#xA; &lt;/div&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/ultralytics/ultralytics&#34;&gt;Ultralytics YOLOv8&lt;/a&gt;, developed by &lt;a href=&#34;https://ultralytics.com&#34;&gt;Ultralytics&lt;/a&gt;, is a cutting-edge, state-of-the-art (SOTA) model that builds upon the success of previous YOLO versions and introduces new features and improvements to further boost performance and flexibility. YOLOv8 is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection, image segmentation and image classification tasks.&lt;/p&gt; &#xA; &lt;p&gt;To request an Enterprise License please complete the form at &lt;a href=&#34;https://ultralytics.com/license&#34;&gt;Ultralytics Licensing&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;p&gt;&lt;img width=&#34;100%&#34; src=&#34;https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/yolo-comparison-plots.png&#34;&gt;&lt;/p&gt; &#xA; &lt;div align=&#34;center&#34;&gt; &#xA;  &lt;a href=&#34;https://github.com/ultralytics&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-social-github.png&#34; width=&#34;2%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA;  &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;2%&#34; alt=&#34;&#34;&gt; &#xA;  &lt;a href=&#34;https://www.linkedin.com/company/ultralytics&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-social-linkedin.png&#34; width=&#34;2%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA;  &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;2%&#34; alt=&#34;&#34;&gt; &#xA;  &lt;a href=&#34;https://twitter.com/ultralytics&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-social-twitter.png&#34; width=&#34;2%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA;  &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;2%&#34; alt=&#34;&#34;&gt; &#xA;  &lt;a href=&#34;https://www.producthunt.com/@glenn_jocher&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-social-producthunt.png&#34; width=&#34;2%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA;  &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;2%&#34; alt=&#34;&#34;&gt; &#xA;  &lt;a href=&#34;https://youtube.com/ultralytics&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-social-youtube.png&#34; width=&#34;2%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA;  &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;2%&#34; alt=&#34;&#34;&gt; &#xA;  &lt;a href=&#34;https://www.facebook.com/ultralytics&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-social-facebook.png&#34; width=&#34;2%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA;  &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;2%&#34; alt=&#34;&#34;&gt; &#xA;  &lt;a href=&#34;https://www.instagram.com/ultralytics/&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-social-instagram.png&#34; width=&#34;2%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;&#xA; &lt;div align=&#34;center&#34;&gt;&#xA;  Documentation&#xA; &lt;/div&gt;&lt;/h2&gt; &#xA;&lt;p&gt;See below for a quickstart installation and usage example, and see the &lt;a href=&#34;https://docs.ultralytics.com&#34;&gt;YOLOv8 Docs&lt;/a&gt; for full documentation on training, validation, prediction and deployment.&lt;/p&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;Install&lt;/summary&gt; &#xA; &lt;p&gt;Pip install the ultralytics package including all &lt;a href=&#34;https://github.com/ultralytics/ultralytics/raw/main/requirements.txt&#34;&gt;requirements.txt&lt;/a&gt; in a &lt;a href=&#34;https://www.python.org/&#34;&gt;&lt;strong&gt;Python&amp;gt;=3.7.0&lt;/strong&gt;&lt;/a&gt; environment, including &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;&lt;strong&gt;PyTorch&amp;gt;=1.7&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install ultralytics&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;Usage&lt;/summary&gt; &#xA; &lt;p&gt;YOLOv8 may be used directly in the Command Line Interface (CLI) with a &lt;code&gt;yolo&lt;/code&gt; command:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yolo task=detect mode=predict model=yolov8n.pt source=&#34;https://ultralytics.com/images/bus.jpg&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;code&gt;yolo&lt;/code&gt; can be used for a variety of tasks and modes and accepts additional arguments, i.e. &lt;code&gt;imgsz=640&lt;/code&gt;. See a full list of available &lt;code&gt;yolo&lt;/code&gt; &lt;a href=&#34;https://docs.ultralytics.com/config/&#34;&gt;arguments&lt;/a&gt; in the YOLOv8 &lt;a href=&#34;https://docs.ultralytics.com&#34;&gt;Docs&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yolo task=detect    mode=train    model=yolov8n.pt        args...&#xA;          classify       predict        yolov8n-cls.yaml  args...&#xA;          segment        val            yolov8n-seg.yaml  args...&#xA;                         export         yolov8n.pt        format=onnx  args...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;YOLOv8 may also be used directly in a Python environment, and accepts the same &lt;a href=&#34;https://docs.ultralytics.com/config/&#34;&gt;arguments&lt;/a&gt; as in the CLI example above:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from ultralytics import YOLO&#xA;&#xA;# Load a model&#xA;model = YOLO(&#34;yolov8n.yaml&#34;)  # build a new model from scratch&#xA;model = YOLO(&#34;yolov8n.pt&#34;)  # load a pretrained model (recommended for training)&#xA;&#xA;# Use the model&#xA;results = model.train(data=&#34;coco128.yaml&#34;, epochs=3)  # train the model&#xA;results = model.val()  # evaluate model performance on the validation set&#xA;results = model(&#34;https://ultralytics.com/images/bus.jpg&#34;)  # predict on an image&#xA;success = model.export(format=&#34;onnx&#34;)  # export the model to ONNX format&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/ultralytics/ultralytics/tree/main/ultralytics/models&#34;&gt;Models&lt;/a&gt; download automatically from the latest Ultralytics &lt;a href=&#34;https://github.com/ultralytics/assets/releases&#34;&gt;release&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;h3&gt;Known Issues / TODOs&lt;/h3&gt; &#xA; &lt;p&gt;We are still working on several parts of YOLOv8! We aim to have these completed soon to bring the YOLOv8 feature set up to par with YOLOv5, including export and inference to all the same formats. We are also writing a YOLOv8 paper which we will submit to &lt;a href=&#34;https://arxiv.org&#34;&gt;arxiv.org&lt;/a&gt; once complete.&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; TensorFlow exports&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; DDP resume&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://arxiv.org&#34;&gt;arxiv.org&lt;/a&gt; paper&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;&#xA; &lt;div align=&#34;center&#34;&gt;&#xA;  Models&#xA; &lt;/div&gt;&lt;/h2&gt; &#xA;&lt;p&gt;All YOLOv8 pretrained models are available here. Detection and Segmentation models are pretrained on the COCO dataset, while Classification models are pretrained on the ImageNet dataset.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ultralytics/ultralytics/tree/main/ultralytics/models&#34;&gt;Models&lt;/a&gt; download automatically from the latest Ultralytics &lt;a href=&#34;https://github.com/ultralytics/assets/releases&#34;&gt;release&lt;/a&gt; on first use.&lt;/p&gt; &#xA;&lt;details open&gt;&#xA; &lt;summary&gt;Detection&lt;/summary&gt; &#xA; &lt;p&gt;See &lt;a href=&#34;https://docs.ultralytics.com/tasks/detection/&#34;&gt;Detection Docs&lt;/a&gt; for usage examples with these models.&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;size&lt;br&gt;&lt;sup&gt;(pixels)&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;mAP&lt;sup&gt;val&lt;br&gt;50-95&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;Speed&lt;br&gt;&lt;sup&gt;CPU ONNX&lt;br&gt;(ms)&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;Speed&lt;br&gt;&lt;sup&gt;A100 TensorRT&lt;br&gt;(ms)&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;params&lt;br&gt;&lt;sup&gt;(M)&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;FLOPs&lt;br&gt;&lt;sup&gt;(B)&lt;/sup&gt;&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt&#34;&gt;YOLOv8n&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;640&lt;/td&gt; &#xA;    &lt;td&gt;37.3&lt;/td&gt; &#xA;    &lt;td&gt;80.4&lt;/td&gt; &#xA;    &lt;td&gt;0.99&lt;/td&gt; &#xA;    &lt;td&gt;3.2&lt;/td&gt; &#xA;    &lt;td&gt;8.7&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt&#34;&gt;YOLOv8s&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;640&lt;/td&gt; &#xA;    &lt;td&gt;44.9&lt;/td&gt; &#xA;    &lt;td&gt;128.4&lt;/td&gt; &#xA;    &lt;td&gt;1.20&lt;/td&gt; &#xA;    &lt;td&gt;11.2&lt;/td&gt; &#xA;    &lt;td&gt;28.6&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt&#34;&gt;YOLOv8m&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;640&lt;/td&gt; &#xA;    &lt;td&gt;50.2&lt;/td&gt; &#xA;    &lt;td&gt;234.7&lt;/td&gt; &#xA;    &lt;td&gt;1.83&lt;/td&gt; &#xA;    &lt;td&gt;25.9&lt;/td&gt; &#xA;    &lt;td&gt;78.9&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l.pt&#34;&gt;YOLOv8l&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;640&lt;/td&gt; &#xA;    &lt;td&gt;52.9&lt;/td&gt; &#xA;    &lt;td&gt;375.2&lt;/td&gt; &#xA;    &lt;td&gt;2.39&lt;/td&gt; &#xA;    &lt;td&gt;43.7&lt;/td&gt; &#xA;    &lt;td&gt;165.2&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt&#34;&gt;YOLOv8x&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;640&lt;/td&gt; &#xA;    &lt;td&gt;53.9&lt;/td&gt; &#xA;    &lt;td&gt;479.1&lt;/td&gt; &#xA;    &lt;td&gt;3.53&lt;/td&gt; &#xA;    &lt;td&gt;68.2&lt;/td&gt; &#xA;    &lt;td&gt;257.8&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;mAP&lt;sup&gt;val&lt;/sup&gt;&lt;/strong&gt; values are for single-model single-scale on &lt;a href=&#34;http://cocodataset.org&#34;&gt;COCO val2017&lt;/a&gt; dataset. &lt;br&gt;Reproduce by &lt;code&gt;yolo mode=val task=detect data=coco.yaml device=0&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt; averaged over COCO val images using an &lt;a href=&#34;https://aws.amazon.com/ec2/instance-types/p4/&#34;&gt;Amazon EC2 P4d&lt;/a&gt; instance. &lt;br&gt;Reproduce by &lt;code&gt;yolo mode=val task=detect data=coco128.yaml batch=1 device=0/cpu&lt;/code&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Segmentation&lt;/summary&gt; &#xA; &lt;p&gt;See &lt;a href=&#34;https://docs.ultralytics.com/tasks/segmentation/&#34;&gt;Segmentation Docs&lt;/a&gt; for usage examples with these models.&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;size&lt;br&gt;&lt;sup&gt;(pixels)&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;mAP&lt;sup&gt;box&lt;br&gt;50-95&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;mAP&lt;sup&gt;mask&lt;br&gt;50-95&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;Speed&lt;br&gt;&lt;sup&gt;CPU ONNX&lt;br&gt;(ms)&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;Speed&lt;br&gt;&lt;sup&gt;A100 TensorRT&lt;br&gt;(ms)&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;params&lt;br&gt;&lt;sup&gt;(M)&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;FLOPs&lt;br&gt;&lt;sup&gt;(B)&lt;/sup&gt;&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-seg.pt&#34;&gt;YOLOv8n&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;640&lt;/td&gt; &#xA;    &lt;td&gt;36.7&lt;/td&gt; &#xA;    &lt;td&gt;30.5&lt;/td&gt; &#xA;    &lt;td&gt;96.1&lt;/td&gt; &#xA;    &lt;td&gt;1.21&lt;/td&gt; &#xA;    &lt;td&gt;3.4&lt;/td&gt; &#xA;    &lt;td&gt;12.6&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s-seg.pt&#34;&gt;YOLOv8s&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;640&lt;/td&gt; &#xA;    &lt;td&gt;44.6&lt;/td&gt; &#xA;    &lt;td&gt;36.8&lt;/td&gt; &#xA;    &lt;td&gt;155.7&lt;/td&gt; &#xA;    &lt;td&gt;1.47&lt;/td&gt; &#xA;    &lt;td&gt;11.8&lt;/td&gt; &#xA;    &lt;td&gt;42.6&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt&#34;&gt;YOLOv8m&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;640&lt;/td&gt; &#xA;    &lt;td&gt;49.9&lt;/td&gt; &#xA;    &lt;td&gt;40.8&lt;/td&gt; &#xA;    &lt;td&gt;317.0&lt;/td&gt; &#xA;    &lt;td&gt;2.18&lt;/td&gt; &#xA;    &lt;td&gt;27.3&lt;/td&gt; &#xA;    &lt;td&gt;110.2&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-seg.pt&#34;&gt;YOLOv8l&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;640&lt;/td&gt; &#xA;    &lt;td&gt;52.3&lt;/td&gt; &#xA;    &lt;td&gt;42.6&lt;/td&gt; &#xA;    &lt;td&gt;572.4&lt;/td&gt; &#xA;    &lt;td&gt;2.79&lt;/td&gt; &#xA;    &lt;td&gt;46.0&lt;/td&gt; &#xA;    &lt;td&gt;220.5&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x-seg.pt&#34;&gt;YOLOv8x&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;640&lt;/td&gt; &#xA;    &lt;td&gt;53.4&lt;/td&gt; &#xA;    &lt;td&gt;43.4&lt;/td&gt; &#xA;    &lt;td&gt;712.1&lt;/td&gt; &#xA;    &lt;td&gt;4.02&lt;/td&gt; &#xA;    &lt;td&gt;71.8&lt;/td&gt; &#xA;    &lt;td&gt;344.1&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;mAP&lt;sup&gt;val&lt;/sup&gt;&lt;/strong&gt; values are for single-model single-scale on &lt;a href=&#34;http://cocodataset.org&#34;&gt;COCO val2017&lt;/a&gt; dataset. &lt;br&gt;Reproduce by &lt;code&gt;yolo mode=val task=segment data=coco.yaml device=0&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt; averaged over COCO val images using an &lt;a href=&#34;https://aws.amazon.com/ec2/instance-types/p4/&#34;&gt;Amazon EC2 P4d&lt;/a&gt; instance. &lt;br&gt;Reproduce by &lt;code&gt;yolo mode=val task=segment data=coco128-seg.yaml batch=1 device=0/cpu&lt;/code&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Classification&lt;/summary&gt; &#xA; &lt;p&gt;See &lt;a href=&#34;https://docs.ultralytics.com/tasks/classification/&#34;&gt;Classification Docs&lt;/a&gt; for usage examples with these models.&lt;/p&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;size&lt;br&gt;&lt;sup&gt;(pixels)&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;acc&lt;br&gt;&lt;sup&gt;top1&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;acc&lt;br&gt;&lt;sup&gt;top5&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;Speed&lt;br&gt;&lt;sup&gt;CPU ONNX&lt;br&gt;(ms)&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;Speed&lt;br&gt;&lt;sup&gt;A100 TensorRT&lt;br&gt;(ms)&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;params&lt;br&gt;&lt;sup&gt;(M)&lt;/sup&gt;&lt;/th&gt; &#xA;    &lt;th&gt;FLOPs&lt;br&gt;&lt;sup&gt;(B) at 640&lt;/sup&gt;&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-cls.pt&#34;&gt;YOLOv8n&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;224&lt;/td&gt; &#xA;    &lt;td&gt;66.6&lt;/td&gt; &#xA;    &lt;td&gt;87.0&lt;/td&gt; &#xA;    &lt;td&gt;12.9&lt;/td&gt; &#xA;    &lt;td&gt;0.31&lt;/td&gt; &#xA;    &lt;td&gt;2.7&lt;/td&gt; &#xA;    &lt;td&gt;4.3&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s-cls.pt&#34;&gt;YOLOv8s&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;224&lt;/td&gt; &#xA;    &lt;td&gt;72.3&lt;/td&gt; &#xA;    &lt;td&gt;91.1&lt;/td&gt; &#xA;    &lt;td&gt;23.4&lt;/td&gt; &#xA;    &lt;td&gt;0.35&lt;/td&gt; &#xA;    &lt;td&gt;6.4&lt;/td&gt; &#xA;    &lt;td&gt;13.5&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-cls.pt&#34;&gt;YOLOv8m&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;224&lt;/td&gt; &#xA;    &lt;td&gt;76.4&lt;/td&gt; &#xA;    &lt;td&gt;93.2&lt;/td&gt; &#xA;    &lt;td&gt;85.4&lt;/td&gt; &#xA;    &lt;td&gt;0.62&lt;/td&gt; &#xA;    &lt;td&gt;17.0&lt;/td&gt; &#xA;    &lt;td&gt;42.7&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-cls.pt&#34;&gt;YOLOv8l&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;224&lt;/td&gt; &#xA;    &lt;td&gt;78.0&lt;/td&gt; &#xA;    &lt;td&gt;94.1&lt;/td&gt; &#xA;    &lt;td&gt;163.0&lt;/td&gt; &#xA;    &lt;td&gt;0.87&lt;/td&gt; &#xA;    &lt;td&gt;37.5&lt;/td&gt; &#xA;    &lt;td&gt;99.7&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x-cls.pt&#34;&gt;YOLOv8x&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt;224&lt;/td&gt; &#xA;    &lt;td&gt;78.4&lt;/td&gt; &#xA;    &lt;td&gt;94.3&lt;/td&gt; &#xA;    &lt;td&gt;232.0&lt;/td&gt; &#xA;    &lt;td&gt;1.01&lt;/td&gt; &#xA;    &lt;td&gt;57.4&lt;/td&gt; &#xA;    &lt;td&gt;154.8&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;acc&lt;/strong&gt; values are model accuracies on the &lt;a href=&#34;https://www.image-net.org/&#34;&gt;ImageNet&lt;/a&gt; dataset validation set. &lt;br&gt;Reproduce by &lt;code&gt;yolo mode=val task=classify data=path/to/ImageNet device=0&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt; averaged over ImageNet val images using an &lt;a href=&#34;https://aws.amazon.com/ec2/instance-types/p4/&#34;&gt;Amazon EC2 P4d&lt;/a&gt; instance. &lt;br&gt;Reproduce by &lt;code&gt;yolo mode=val task=classify data=path/to/ImageNet batch=1 device=0/cpu&lt;/code&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;&#xA; &lt;div align=&#34;center&#34;&gt;&#xA;  Integrations&#xA; &lt;/div&gt;&lt;/h2&gt; &#xA;&lt;br&gt; &#xA;&lt;a align=&#34;center&#34; href=&#34;https://bit.ly/ultralytics_hub&#34; target=&#34;_blank&#34;&gt; &lt;img width=&#34;100%&#34; src=&#34;https://github.com/ultralytics/assets/raw/main/yolov8/banner-integrations.png&#34;&gt;&lt;/a&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://roboflow.com/?ref=ultralytics&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-roboflow.png&#34; width=&#34;10%&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;15%&#34; height=&#34;0&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://cutt.ly/yolov5-readme-clearml&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-clearml.png&#34; width=&#34;10%&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;15%&#34; height=&#34;0&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://bit.ly/yolov5-readme-comet&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-comet.png&#34; width=&#34;10%&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;15%&#34; height=&#34;0&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://bit.ly/yolov5-neuralmagic&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-neuralmagic.png&#34; width=&#34;10%&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Roboflow&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;ClearML ‚≠ê NEW&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Comet ‚≠ê NEW&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Neural Magic ‚≠ê NEW&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Label and export your custom datasets directly to YOLOv8 for training with &lt;a href=&#34;https://roboflow.com/?ref=ultralytics&#34;&gt;Roboflow&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Automatically track, visualize and even remotely train YOLOv8 using &lt;a href=&#34;https://cutt.ly/yolov5-readme-clearml&#34;&gt;ClearML&lt;/a&gt; (open-source!)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Free forever, &lt;a href=&#34;https://bit.ly/yolov5-readme-comet2&#34;&gt;Comet&lt;/a&gt; lets you save YOLOv8 models, resume training, and interactively visualize and debug predictions&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Run YOLOv8 inference up to 6x faster with &lt;a href=&#34;https://bit.ly/yolov5-neuralmagic&#34;&gt;Neural Magic DeepSparse&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;&#xA; &lt;div align=&#34;center&#34;&gt;&#xA;  Ultralytics HUB&#xA; &lt;/div&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://bit.ly/ultralytics_hub&#34;&gt;Ultralytics HUB&lt;/a&gt; is our ‚≠ê &lt;strong&gt;NEW&lt;/strong&gt; no-code solution to visualize datasets, train YOLOv8 üöÄ models, and deploy to the real world in a seamless experience. Get started for &lt;strong&gt;Free&lt;/strong&gt; now! Also run YOLOv8 models on your iOS or Android device by downloading the &lt;a href=&#34;https://ultralytics.com/app_install&#34;&gt;Ultralytics App&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;a align=&#34;center&#34; href=&#34;https://bit.ly/ultralytics_hub&#34; target=&#34;_blank&#34;&gt; &lt;img width=&#34;100%&#34; src=&#34;https://github.com/ultralytics/assets/raw/main/im/ultralytics-hub.png&#34;&gt;&lt;/a&gt; &#xA;&lt;h2&gt;&#xA; &lt;div align=&#34;center&#34;&gt;&#xA;  Contribute&#xA; &lt;/div&gt;&lt;/h2&gt; &#xA;&lt;p&gt;We love your input! YOLOv5 and YOLOv8 would not be possible without help from our community. Please see our &lt;a href=&#34;https://raw.githubusercontent.com/ultralytics/ultralytics/main/CONTRIBUTING.md&#34;&gt;Contributing Guide&lt;/a&gt; to get started, and fill out our &lt;a href=&#34;https://ultralytics.com/survey?utm_source=github&amp;amp;utm_medium=social&amp;amp;utm_campaign=Survey&#34;&gt;Survey&lt;/a&gt; to send us feedback on your experience. Thank you üôè to all our contributors!&lt;/p&gt; &#xA;&lt;!-- SVG image from https://opencollective.com/ultralytics/contributors.svg?width=990 --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ultralytics/ultralytics/graphs/contributors&#34;&gt;&lt;img src=&#34;https://github.com/ultralytics/yolov5/releases/download/v1.0/image-contributors-1280.png&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&#xA; &lt;div align=&#34;center&#34;&gt;&#xA;  License&#xA; &lt;/div&gt;&lt;/h2&gt; &#xA;&lt;p&gt;YOLOv8 is available under two different licenses:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;GPL-3.0 License&lt;/strong&gt;: See &lt;a href=&#34;https://github.com/ultralytics/ultralytics/raw/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Enterprise License&lt;/strong&gt;: Provides greater flexibility for commercial product development without the open-source requirements of GPL-3.0. Typical use cases are embedding Ultralytics software and AI models in commercial products and applications. Request an Enterprise License at &lt;a href=&#34;https://ultralytics.com/license&#34;&gt;Ultralytics Licensing&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&#xA; &lt;div align=&#34;center&#34;&gt;&#xA;  Contact&#xA; &lt;/div&gt;&lt;/h2&gt; &#xA;&lt;p&gt;For YOLOv8 bugs and feature requests please visit &lt;a href=&#34;https://github.com/ultralytics/ultralytics/issues&#34;&gt;GitHub Issues&lt;/a&gt;. For professional support please &lt;a href=&#34;https://ultralytics.com/contact&#34;&gt;Contact Us&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/ultralytics&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-social-github.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://www.linkedin.com/company/ultralytics&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-social-linkedin.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://twitter.com/ultralytics&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-social-twitter.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://www.producthunt.com/@glenn_jocher&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-social-producthunt.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://youtube.com/ultralytics&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-social-youtube.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://www.facebook.com/ultralytics&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-social-facebook.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt; &#xA; &lt;a href=&#34;https://www.instagram.com/ultralytics/&#34; style=&#34;text-decoration:none;&#34;&gt; &lt;img src=&#34;https://github.com/ultralytics/assets/raw/main/social/logo-social-instagram.png&#34; width=&#34;3%&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <title>networkx/networkx</title>
    <updated>2023-01-13T01:43:42Z</updated>
    <id>tag:github.com,2023-01-13:/networkx/networkx</id>
    <link href="https://github.com/networkx/networkx" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Network Analysis in Python&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;NetworkX&lt;/h1&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://github.com/networkx/networkx/workflows/test/badge.svg?branch=main&#34;&gt;https://github.com/networkx/networkx/workflows/test/badge.svg?branch=main&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/networkx/networkx/actions?query=workflow%3A%22test%22&#34;&gt;https://github.com/networkx/networkx/actions?query=workflow%3A%22test%22&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://codecov.io/gh/networkx/networkx/branch/main/graph/badge.svg&#34;&gt;https://codecov.io/gh/networkx/networkx/branch/main/graph/badge.svg&lt;/a&gt; :target: &lt;a href=&#34;https://app.codecov.io/gh/networkx/networkx/branch/main&#34;&gt;https://app.codecov.io/gh/networkx/networkx/branch/main&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://img.shields.io/github/labels/networkx/networkx/Good%20First%20Issue?color=green&amp;amp;label=Contribute%20&amp;amp;style=flat-square&#34;&gt;https://img.shields.io/github/labels/networkx/networkx/Good%20First%20Issue?color=green&amp;amp;label=Contribute%20&amp;amp;style=flat-square&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/networkx/networkx/issues?q=is%3Aopen+is%3Aissue+label%3A%22Good+First+Issue%22&#34;&gt;https://github.com/networkx/networkx/issues?q=is%3Aopen+is%3Aissue+label%3A%22Good+First+Issue%22&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Website (including documentation):&lt;/strong&gt; &lt;a href=&#34;https://networkx.org&#34;&gt;https://networkx.org&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Mailing list:&lt;/strong&gt; &lt;a href=&#34;https://groups.google.com/forum/#!forum/networkx-discuss&#34;&gt;https://groups.google.com/forum/#!forum/networkx-discuss&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href=&#34;https://github.com/networkx/networkx&#34;&gt;https://github.com/networkx/networkx&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Bug reports:&lt;/strong&gt; &lt;a href=&#34;https://github.com/networkx/networkx/issues&#34;&gt;https://github.com/networkx/networkx/issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Report a security vulnerability:&lt;/strong&gt; &lt;a href=&#34;https://tidelift.com/security&#34;&gt;https://tidelift.com/security&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Tutorial:&lt;/strong&gt; &lt;a href=&#34;https://networkx.org/documentation/latest/tutorial.html&#34;&gt;https://networkx.org/documentation/latest/tutorial.html&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;GitHub Discussions:&lt;/strong&gt; &lt;a href=&#34;https://github.com/networkx/networkx/discussions&#34;&gt;https://github.com/networkx/networkx/discussions&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Simple example&lt;/h2&gt; &#xA;&lt;p&gt;Find the shortest path between two nodes in an undirected graph:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: pycon&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import networkx as nx&#xA;&amp;gt;&amp;gt;&amp;gt; G = nx.Graph()&#xA;&amp;gt;&amp;gt;&amp;gt; G.add_edge(&#34;A&#34;, &#34;B&#34;, weight=4)&#xA;&amp;gt;&amp;gt;&amp;gt; G.add_edge(&#34;B&#34;, &#34;D&#34;, weight=2)&#xA;&amp;gt;&amp;gt;&amp;gt; G.add_edge(&#34;A&#34;, &#34;C&#34;, weight=3)&#xA;&amp;gt;&amp;gt;&amp;gt; G.add_edge(&#34;C&#34;, &#34;D&#34;, weight=4)&#xA;&amp;gt;&amp;gt;&amp;gt; nx.shortest_path(G, &#34;A&#34;, &#34;D&#34;, weight=&#34;weight&#34;)&#xA;[&#39;A&#39;, &#39;B&#39;, &#39;D&#39;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;Install the latest version of NetworkX::&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pip install networkx&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install with all optional dependencies::&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pip install networkx[all]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For additional details, please see &lt;code&gt;INSTALL.rst&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Bugs&lt;/h2&gt; &#xA;&lt;p&gt;Please report any bugs that you find &lt;code&gt;here &amp;lt;https://github.com/networkx/networkx/issues&amp;gt;&lt;/code&gt;&lt;em&gt;. Or, even better, fork the repository on &lt;code&gt;GitHub &amp;lt;https://github.com/networkx/networkx&amp;gt;&lt;/code&gt;&lt;/em&gt; and create a pull request (PR). We welcome all changes, big or small, and we will help you make the PR if you are new to &lt;code&gt;git&lt;/code&gt; (just ask on the issue and/or see &lt;code&gt;CONTRIBUTING.rst&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Released under the 3-Clause BSD license (see &lt;code&gt;LICENSE.txt&lt;/code&gt;)::&lt;/p&gt; &#xA;&lt;p&gt;Copyright (C) 2004-2023 NetworkX Developers Aric Hagberg &lt;a href=&#34;mailto:hagberg@lanl.gov&#34;&gt;hagberg@lanl.gov&lt;/a&gt; Dan Schult &lt;a href=&#34;mailto:dschult@colgate.edu&#34;&gt;dschult@colgate.edu&lt;/a&gt; Pieter Swart &lt;a href=&#34;mailto:swart@lanl.gov&#34;&gt;swart@lanl.gov&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>blasty/lexmark</title>
    <updated>2023-01-13T01:43:42Z</updated>
    <id>tag:github.com,2023-01-13:/blasty/lexmark</id>
    <link href="https://github.com/blasty/lexmark" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;lexmark printer haxx&lt;/h1&gt; &#xA;&lt;p&gt;I made an entry for Pwn2Own Toronto 2022, that magically failed during the actual competition. ZDI offered to buy the bug(s) anyway for a laughable monetary amount and I promptly forgot about their offer.&lt;/p&gt; &#xA;&lt;p&gt;Here is a small archive with exploit, writeup and tools.&lt;/p&gt; &#xA;&lt;p&gt;Exploit was tested against the Lexmark &#39;MC3224adwe&#39; but is reported to work against other printers/copiers as well. ;-)&lt;/p&gt; &#xA;&lt;p&gt;This is all still &#34;0day&#34; at the time of writing (2023-01-10, tested against firmware CXLBL.081.225)&lt;/p&gt; &#xA;&lt;p&gt;Everything is distributed as-is, don&#39;t expect support/updates.&lt;/p&gt; &#xA;&lt;p&gt;Enjoy!&lt;/p&gt; &#xA;&lt;p&gt;-- blasty &lt;a href=&#34;mailto:peter@haxx.in&#34;&gt;peter@haxx.in&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>