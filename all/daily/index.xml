<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-07-15T01:29:40Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>TomBursch/kitchenowl</title>
    <updated>2025-07-15T01:29:40Z</updated>
    <id>tag:github.com,2025-07-15:/TomBursch/kitchenowl</id>
    <link href="https://github.com/TomBursch/kitchenowl" rel="alternate"></link>
    <summary type="html">&lt;p&gt;KitchenOwl is a self-hosted grocery list and recipe manager. The backend is made with Flask and the frontend with Flutter. Easily add items to your shopping list before you go shopping. You can also create recipes and add items based on what you want to cook.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;./docs/docs/img/icon.png&#34;&gt; &#xA;  &lt;img width=&#34;128&#34; src=&#34;https://raw.githubusercontent.com/TomBursch/kitchenowl/main/docs/docs/img/logo.png&#34; alt=&#34;KitchenOwl&#34;&gt; &#xA; &lt;/picture&gt; &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt;A smart grocery list and recipe manager.&lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; &lt;a href=&#34;https://kitchenowl.org&#34;&gt;Website&lt;/a&gt; | &lt;a href=&#34;https://docs.kitchenowl.org&#34;&gt;Docs&lt;/a&gt; | &lt;a href=&#34;https://docs.kitchenowl.org/latest/self-hosting/&#34;&gt;Self-Hosting&lt;/a&gt; | &lt;a href=&#34;https://matrix.to/#/%23kitchenowl:matrix.org&#34;&gt;Matrix&lt;/a&gt; &lt;/h4&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/TomBursch/kitchenowl&#34;&gt; &lt;img alt=&#34;Stars&#34; src=&#34;https://img.shields.io/github/stars/tombursch/kitchenowl&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://hosted.weblate.org/engage/kitchenowl/&#34;&gt; &lt;img alt=&#34;Translation&#34; src=&#34;https://hosted.weblate.org/widgets/kitchenowl/-/kitchenowl/svg-badge.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://matrix.to/#/%23kitchenowl:matrix.org&#34;&gt; &lt;img alt=&#34;Matrix&#34; src=&#34;https://img.shields.io/matrix/kitchenowl:matrix.org&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/TomBursch/kitchenowl/main/LICENSE&#34;&gt; &lt;img alt=&#34;License&#34; src=&#34;https://img.shields.io/github/license/TomBursch/kitchenowl&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/TomBursch/kitchenowl/releases&#34;&gt; &lt;img alt=&#34;GitHub release (latest by date)&#34; src=&#34;https://img.shields.io/github/v/release/tombursch/kitchenowl&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/repository/docker/tombursch/kitchenowl&#34;&gt; &lt;img alt=&#34;Docker pulls&#34; src=&#34;https://img.shields.io/docker/pulls/tombursch/kitchenowl&#34;&gt; &lt;/a&gt; &lt;/h4&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://play.google.com/store/apps/details?id=com.tombursch.kitchenowl&#34;&gt; &lt;img alt=&#34;Get it on Google Play&#34; src=&#34;https://raw.githubusercontent.com/TomBursch/kitchenowl/main/docs/docs/img/badges/playstore.png&#34; height=&#34;50&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://f-droid.org/packages/com.tombursch.kitchenowl/&#34;&gt; &lt;img alt=&#34;Get it on F-Droid&#34; src=&#34;https://raw.githubusercontent.com/TomBursch/kitchenowl/main/docs/docs/img/badges/f-droid.png&#34; height=&#34;50&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://apps.apple.com/app/kitchenowl/id1557453670&#34;&gt; &lt;img alt=&#34;Get it on the AppStore&#34; src=&#34;https://raw.githubusercontent.com/TomBursch/kitchenowl/main/docs/docs/img/badges/appstore.png&#34; height=&#34;50&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://my.home-assistant.io/redirect/hacs_repository/?owner=TomBursch&amp;amp;repository=kitchenowl-ha&amp;amp;category=integration&#34;&gt; &lt;img alt=&#34;Get it on the Home Assistant Community Store&#34; src=&#34;https://raw.githubusercontent.com/TomBursch/kitchenowl/main/docs/docs/img/badges/hacs_repository.svg?sanitize=true&#34; height=&#34;50&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt; üç´ ü•ò üçΩ &lt;/h3&gt; &#xA;&lt;p&gt;KitchenOwl is a smart self-hosted grocery list and recipe manager. Easily add items to your shopping list before you go shopping. You can also create recipes and get suggestions on what you want to cook. Track your expenses so you know how much you&#39;ve spent.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Native Mobile/Web/Desktop apps with a great design&lt;/li&gt; &#xA; &lt;li&gt;Add items to your shopping list and sync them in real-time with multiple users&lt;/li&gt; &#xA; &lt;li&gt;Partial offline support, so you don&#39;t lose track of what to buy even when there is no signal&lt;/li&gt; &#xA; &lt;li&gt;Manage recipes and add them to your shopping list&lt;/li&gt; &#xA; &lt;li&gt;Share recipes with friends and family&lt;/li&gt; &#xA; &lt;li&gt;Create a meal plan to always know what you&#39;ll be eating&lt;/li&gt; &#xA; &lt;li&gt;Manage balances and track expenses of your household&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please keep in mind that this project is still in development.&lt;/p&gt; &#xA;&lt;p&gt;For a full list check out the &lt;a href=&#34;https://kitchenowl.org&#34;&gt;website&lt;/a&gt;. For a list of planned features, take a look at the &lt;a href=&#34;https://github.com/users/TomBursch/projects/1&#34;&gt;Roadmap&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;üì± Screenshots&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img alt=&#34;Groceries page&#34; src=&#34;https://raw.githubusercontent.com/TomBursch/kitchenowl/main/metadata/en-US/images/phoneScreenshots/groceries.png&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img alt=&#34;Recipe page&#34; src=&#34;https://raw.githubusercontent.com/TomBursch/kitchenowl/main/metadata/en-US/images/phoneScreenshots/recipe.png&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img alt=&#34;Plan page&#34; src=&#34;https://raw.githubusercontent.com/TomBursch/kitchenowl/main/metadata/en-US/images/phoneScreenshots/plan.png&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img alt=&#34;Expense page&#34; src=&#34;https://raw.githubusercontent.com/TomBursch/kitchenowl/main/metadata/en-US/images/phoneScreenshots/expenses.png&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;ü§ñ App Install&lt;/h2&gt; &#xA;&lt;p&gt;Get it in your favorite store or find the current release for your operating system on the &lt;a href=&#34;https://github.com/TomBursch/kitchenowl/releases&#34;&gt;releases page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Get started&lt;/h2&gt; &#xA;&lt;p&gt;Please take a look at the &lt;a href=&#34;https://docs.kitchenowl.org/latest/self-hosting/&#34;&gt;get started guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üôå Contributing&lt;/h2&gt; &#xA;&lt;p&gt;From opening a bug report to creating a pull request: every contribution is appreciated and welcomed. If you&#39;re planning to implement a new feature or change the API please create an issue first. This way, we can ensure your work is not in vain. For more information see &lt;a href=&#34;https://raw.githubusercontent.com/TomBursch/kitchenowl/main/CONTRIBUTING.md&#34;&gt;Contributing&lt;/a&gt; or get in contact by joining our &lt;a href=&#34;https://matrix.to/#/%23kitchenowl:matrix.org&#34;&gt;Matrix space&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;üåç Translations&lt;/h3&gt; &#xA;&lt;p&gt;You can help translate the App into your language by using &lt;a href=&#34;https://hosted.weblate.org/engage/kitchenowl/&#34;&gt;Weblate&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://hosted.weblate.org/engage/kitchenowl/&#34;&gt; &lt;img src=&#34;https://hosted.weblate.org/widgets/kitchenowl/-/kitchenowl/multi-auto.svg?sanitize=true&#34; alt=&#34;Translation status&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;üõéÔ∏è Stay Up-to-Date&lt;/h2&gt; &#xA;&lt;p&gt;KitchenOwl is moving fast, to stay updated consider starring and watching the releases of this repository.&lt;/p&gt; &#xA;&lt;h3&gt;üí¨ Status&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Public Alpha: Still working on stuff (rarely things might break)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Public Beta: Stable and most planned features complete&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Public: Production-ready&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìö Related&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kitchenowl.org&#34;&gt;Website&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.kitchenowl.org&#34;&gt;Docs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/TomBursch/kitchenowl-backend&#34;&gt;KitchenOwl Backend&lt;/a&gt; Repository&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/TomBursch/kitchenowl-website&#34;&gt;KitchenOwl Website&lt;/a&gt; Repository&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/TomBursch/kitchenowl-python&#34;&gt;KitchenOwl Python Client&lt;/a&gt; Repository&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/TomBursch/kitchenowl-ha&#34;&gt;KitchenOwl Home Assistant Integration&lt;/a&gt; Repository&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hub.docker.com/r/tombursch/kitchenowl&#34;&gt;DockerHub&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hhursev/recipe-scrapers&#34;&gt;Recipe scrapers&lt;/a&gt; used for scraping recipes from the web&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://weblate.org/&#34;&gt;Weblate&lt;/a&gt; is helping with continuous localization as part of their ongoing support for open-source software projects.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;üî® Built With&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://flask.palletsprojects.com/&#34;&gt;Flask&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://flutter.dev/&#34;&gt;Flutter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.docker.com/&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üçÄ Contributors&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/tombursch/KitchenOwl/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=tombursch/KitchenOwl&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;üìú License&lt;/h2&gt; &#xA;&lt;p&gt;KitchenOwl is Free Software: You can use, study share and improve it at your will. Specifically you can redistribute and/or modify it under the terms of the AGPL-3.0 License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>nisargjhaveri/WirelessAndroidAutoDongle</title>
    <updated>2025-07-15T01:29:40Z</updated>
    <id>tag:github.com,2025-07-15:/nisargjhaveri/WirelessAndroidAutoDongle</id>
    <link href="https://github.com/nisargjhaveri/WirelessAndroidAutoDongle" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Use Wireless Android Auto with a car that supports only wired Android Auto using a Raspberry Pi.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Wireless Android Auto Dongle&lt;/h1&gt; &#xA;&lt;p&gt;DIY Wireless Android Auto adapter to use with a car that supports only wired Android Auto using a Raspberry Pi.&lt;/p&gt; &#xA;&lt;p&gt;This repository consists of the buildroot setup to generate an sd card image to create your own Wireless Android Auto adapter.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Native Wireless Android Auto connection to the phone, no extra app needed on the phone.&lt;/li&gt; &#xA; &lt;li&gt;Passes through all Android Auto traffic without any modifications to ensure seamless and safe experience.&lt;/li&gt; &#xA; &lt;li&gt;Fast bootup, connection under 30 seconds.&lt;/li&gt; &#xA; &lt;li&gt;Supports multiple boards (Currently multiple Raspberry Pi boards).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Supported Hardware&lt;/h2&gt; &#xA;&lt;p&gt;This is currently tested and built for the following Raspberry Pi boards supporting USB OTG.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Raspberry Pi Zero W&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Raspberry Pi Zero 2 W&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Raspberry Pi 3 A+&lt;/strong&gt; &lt;em&gt;(Raspberry Pi 3 B+ is not supported)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Raspberry Pi 4&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In theory, this can be extended to more hardware in future with these basic requirements.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The board should support USB OTG or Gadget mode.&lt;/li&gt; &#xA; &lt;li&gt;Has Wifi and Bluetooth. External should also work if not in-built.&lt;/li&gt; &#xA; &lt;li&gt;Should be able to operate on power provided by the car.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Install and run&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/nisargjhaveri/WirelessAndroidAutoDongle/releases&#34;&gt;Download a pre-built sd card image&lt;/a&gt; for your board. You can also &lt;a href=&#34;https://raw.githubusercontent.com/nisargjhaveri/WirelessAndroidAutoDongle/main/BUILDING.md&#34;&gt;build one yourself&lt;/a&gt;. Install the image on the SD card using your favorite tool.&lt;/p&gt; &#xA;&lt;p&gt;You may want to update the country code and other settings that works best for you. See &lt;a href=&#34;https://raw.githubusercontent.com/nisargjhaveri/WirelessAndroidAutoDongle/main/#Configurations&#34;&gt;Configurations&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;First-time connection&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Connect the phone to headunit via USB cable, make sure Android Auto starts. Disconnect phone.&lt;/li&gt; &#xA; &lt;li&gt;Connect the board to the car. Make sure to use a data cable, with the USB OTG enabled port on the board. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;On &lt;strong&gt;Raspberry Pi Zero W&lt;/strong&gt; and &lt;strong&gt;Raspberry Pi Zero 2 W&lt;/strong&gt;: Use the second micro-usb port marked &#34;USB&#34; and not &#34;PWR&#34;.&lt;/li&gt; &#xA;   &lt;li&gt;On &lt;strong&gt;Raspberry Pi 3 A+&lt;/strong&gt;: Use the only USB-A port with an USB-A to USB-A cable.&lt;/li&gt; &#xA;   &lt;li&gt;On &lt;strong&gt;Raspberry Pi 4&lt;/strong&gt;, use the USB-C port used for normally powering the board.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Open Bluetooth settings and pair the new device called &lt;code&gt;AndroidAuto-Dongle-*&lt;/code&gt; or &lt;code&gt;WirelessAADongle-*&lt;/code&gt; on your phone.&lt;/li&gt; &#xA; &lt;li&gt;After this phone should automatically connect via Wifi and the dongle will connect to the headunit via USB and start Android Auto on the car screen.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Subsequent connections&lt;/h3&gt; &#xA;&lt;p&gt;From the next time, it should automatically connect to the phone and start Android Auto.&lt;/p&gt; &#xA;&lt;p&gt;Make sure your Bluetooth and Wifi are enabled on the phone.&lt;/p&gt; &#xA;&lt;h2&gt;Configurations&lt;/h2&gt; &#xA;&lt;p&gt;Once the image is installed on the SD card, you can see the SD card as &lt;code&gt;WirelessAA&lt;/code&gt; drive.&lt;/p&gt; &#xA;&lt;p&gt;Edit the &lt;code&gt;aawgd.conf&lt;/code&gt; file inside the &lt;code&gt;WirelessAA&lt;/code&gt; drive using a text editor to update the configurations. The file contains the possible configuration options with their explanations.&lt;/p&gt; &#xA;&lt;h2&gt;Troubleshoot&lt;/h2&gt; &#xA;&lt;h3&gt;Common issues&lt;/h3&gt; &#xA;&lt;h4&gt;Bluetooth and Wifi seems connected, but the phone stuck at &#34;Looking for Android Auto&#34;&lt;/h4&gt; &#xA;&lt;p&gt;The most common issue behind this is either bad USB cable or use of wrong USB port on the device. Make sure:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The cable is good quality data cable and not power-only cable&lt;/li&gt; &#xA; &lt;li&gt;You&#39;re using the OTG enabled usb port on the board, and not the power-only port.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Getting logs&lt;/h3&gt; &#xA;&lt;p&gt;Once you&#39;ve already tried multiple times and it still does not work, you can ssh into the device and try to get some logs.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Set a static password by setting the &lt;code&gt;AAWG_WIFI_PASSWORD&lt;/code&gt; config, and enable SSH by setting the &lt;code&gt;AAWG_ENABLE_SSH&lt;/code&gt; config. See &lt;a href=&#34;https://raw.githubusercontent.com/nisargjhaveri/WirelessAndroidAutoDongle/main/#Configurations&#34;&gt;the instructions to update the configurations&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Connect the device to the headunit, let it boot and try to connect once. The logs are not persisted across reboots, so you need to get the logs in the same instance soon after you observe the issue.&lt;/li&gt; &#xA; &lt;li&gt;Connect to the device using wifi (SSID: AAWirelessDongle, Password: &amp;lt;as set in the first step&amp;gt;).&lt;/li&gt; &#xA; &lt;li&gt;SSH into the device (username: root, password: password, see relevant defconfigs e.g. &lt;a href=&#34;https://raw.githubusercontent.com/nisargjhaveri/WirelessAndroidAutoDongle/main/aa_wireless_dongle/configs/raspberrypi0w_defconfig&#34;&gt;raspberrypi0w_defconfig&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Once you&#39;re in, try to have a look at &lt;code&gt;/var/log/messages&lt;/code&gt; file, it should have most relevant logs to start with. You can also copy the file and attach to issues you create if any.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contribute&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/nisargjhaveri/WirelessAndroidAutoDongle/issues&#34;&gt;Find or create a new issue&lt;/a&gt; for any bugs or improvements.&lt;/p&gt; &#xA;&lt;p&gt;Feel free to &lt;a href=&#34;https://github.com/nisargjhaveri/WirelessAndroidAutoDongle/pulls&#34;&gt;Create a PR&lt;/a&gt; to fix any issues. Refer &lt;a href=&#34;https://raw.githubusercontent.com/nisargjhaveri/WirelessAndroidAutoDongle/main/BUILDING.md&#34;&gt;BUILDING.md&lt;/a&gt; for instructions on how to build locally.&lt;/p&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;Please &lt;a href=&#34;https://github.com/sponsors/nisargjhaveri&#34;&gt;consider sponsoring&lt;/a&gt; if you find the project useful. Even a small donation helps. This will help continuing fixing issues and getting support for more devices and headunit in future.&lt;/p&gt; &#xA;&lt;p&gt;In any case, don&#39;t forget to star on github and spread the word if you think this project might be useful to someone else as well.&lt;/p&gt; &#xA;&lt;h2&gt;Limitations&lt;/h2&gt; &#xA;&lt;p&gt;This is currently tested with very limited set of headunits and cars. Let me know if it does not work with your headunit.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>OpenPipe/ART</title>
    <updated>2025-07-15T01:29:40Z</updated>
    <id>tag:github.com,2025-07-15:/OpenPipe/ART</id>
    <link href="https://github.com/OpenPipe/ART" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Agent Reinforcement Trainer: train multi-step agents for real-world tasks using GRPO. Give your agents on-the-job training. Reinforcement learning for Qwen2.5, Qwen3, Llama, Kimi, and more!&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://art.openpipe.ai&#34;&gt;&#xA;   &lt;picture&gt; &#xA;    &lt;img alt=&#34;ART logo&#34; src=&#34;https://github.com/openpipe/art/raw/main/assets/ART_logo.png&#34; width=&#34;160px&#34;&gt; &#xA;   &lt;/picture&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA; &lt;h1&gt;Agent Reinforcement Trainer&lt;/h1&gt; &#xA; &lt;p&gt;&lt;/p&gt; &#xA; &lt;p&gt; Train multi-step agents for real-world tasks using GRPO. &lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/openpipe/art/raw/main/CONTRIBUTING.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-blue.svg?sanitize=true&#34; alt=&#34;PRs-Welcome&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/openpipe-art/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/openpipe-art?color=364fc7&amp;amp;logoColor=364fc7&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/openpipe/art/blob/main/examples/2048/2048.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Train Agent&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://discord.gg/zbBHRUpwf4&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Join%20Discord-5865F2?style=plastic&amp;amp;logo=discord&amp;amp;logoColor=white&#34; alt=&#34;Join Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://art.openpipe.ai&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Documentation-orange?style=plastic&amp;amp;logo=gitbook&amp;amp;logoColor=white&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;üìè RULER: Zero-Shot Agent Rewards&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;RULER&lt;/strong&gt; (Relative Universal LLM-Elicited Rewards) eliminates the need for hand-crafted reward functions by using an LLM-as-judge to automatically score agent trajectories. Simply define your task in the system prompt, and RULER handles the rest‚Äî&lt;strong&gt;no labeled data, expert feedback, or reward engineering required&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;‚ú® &lt;strong&gt;Key Benefits:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;2-3x faster development&lt;/strong&gt; - Skip reward function engineering entirely&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;General-purpose&lt;/strong&gt; - Works across any task without modification&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Strong performance&lt;/strong&gt; - Matches or exceeds hand-crafted rewards in 3/4 benchmarks&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Easy integration&lt;/strong&gt; - Drop-in replacement for manual reward functions&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Before: Hours of reward engineering&#xA;def complex_reward_function(trajectory):&#xA;    # 50+ lines of careful scoring logic...&#xA;    pass&#xA;&#xA;# After: One line with RULER&#xA;judged_group = await ruler_score_group(group, &#34;openai/o3&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://art.openpipe.ai/fundamentals/ruler&#34;&gt;üìñ Learn more about RULER ‚Üí&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ART Overview&lt;/h2&gt; &#xA;&lt;p&gt;ART is an open-source RL framework that improves agent reliability by allowing LLMs to &lt;strong&gt;learn from experience&lt;/strong&gt;. ART provides an ergonomic harness for integrating GRPO into any python application. For a quick hands-on introduction, run one of the notebooks below. When you&#39;re ready to learn more, check out the &lt;a href=&#34;https://art.openpipe.ai&#34;&gt;docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üìí Notebooks&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Agent Task&lt;/th&gt; &#xA;   &lt;th&gt;Example Notebook&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Comparative Performance&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;2048&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/openpipe/art/blob/main/examples/2048/2048.ipynb&#34;&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Qwen 2.5 3B learns to play 2048&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/openpipe/art/raw/main/assets/benchmarks/2048/accuracy-training-progress.svg?sanitize=true&#34; height=&#34;72&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenPipe/ART/main/examples/2048/benchmark_2048.ipynb&#34;&gt;benchmarks&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Temporal Clue&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/openpipe/art/blob/main/examples/temporal_clue/temporal-clue.ipynb&#34;&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Qwen 2.5 7B learns to solve Temporal Clue&lt;/td&gt; &#xA;   &lt;td&gt;[Link coming soon]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Tic Tac Toe&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/openpipe/art/blob/main/examples/tic_tac_toe/tic-tac-toe.ipynb&#34;&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Qwen 2.5 3B learns to play Tic Tac Toe&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/openpipe/art/raw/main/assets/benchmarks/tic-tac-toe-local/accuracy-training-progress.svg?sanitize=true&#34; height=&#34;72&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenPipe/ART/main/examples/tic_tac_toe/benchmark_tic_tac_toe.ipynb&#34;&gt;benchmarks&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Codenames&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/openpipe/art/blob/main/examples/codenames/Codenames_RL.ipynb&#34;&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Qwen 2.5 3B learns to play Codenames&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/openpipe/art/raw/main/assets/benchmarks/codenames/win_rate_over_time.png&#34; height=&#34;72&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenPipe/ART/main/examples/codenames/Codenames_RL.ipynb&#34;&gt;benchmarks&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Why ART?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ART provides convenient wrappers for introducing RL training into &lt;strong&gt;existing applications&lt;/strong&gt;. We abstract the training server into a modular service that your code doesn&#39;t need to interface with.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Train from anywhere.&lt;/strong&gt; Run the ART client on your laptop and let the ART server kick off an ephemeral GPU-enabled environment, or run on a local GPU.&lt;/li&gt; &#xA; &lt;li&gt;Integrations with hosted platforms like W&amp;amp;B, Langfuse, and OpenPipe provide flexible observability and &lt;strong&gt;simplify debugging&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;ART is customizable with &lt;strong&gt;intelligent defaults&lt;/strong&gt;. You can configure training parameters and inference engine configurations to meet specific needs, or take advantage of the defaults, which have been optimized for training efficiency and stability.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;ART agents can be trained from any client machine that runs python. To add to an existing project, run this command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install openpipe-art&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ü§ñ ART‚Ä¢E Agent&lt;/h2&gt; &#xA;&lt;p&gt;Curious about how to use ART for a real-world task? Check out the &lt;a href=&#34;https://openpipe.ai/blog/art-e-mail-agent&#34;&gt;ART‚Ä¢E Agent&lt;/a&gt; blog post, where we detail how we trained Qwen 2.5 14B to beat o3 at email retrieval!&lt;/p&gt; &#xA;&lt;img src=&#34;https://github.com/openpipe/art/raw/main/assets/ART_E_graphs.png&#34; width=&#34;700&#34;&gt; &#xA;&lt;h2&gt;üîÅ Training Loop Overview&lt;/h2&gt; &#xA;&lt;p&gt;ART&#39;s functionality is divided into a &lt;strong&gt;client&lt;/strong&gt; and a &lt;strong&gt;server&lt;/strong&gt;. The OpenAI-compatible client is responsible for interfacing between ART and your codebase. Using the client, you can pass messages and get completions from your LLM as it improves. The server runs independently on any machine with a GPU. It abstracts away the complexity of the inference and training portions of the RL loop while allowing for some custom configuration. An outline of the training loop is shown below:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Inference&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Your code uses the ART client to perform an agentic workflow (usually executing several rollouts in parallel to gather data faster).&lt;/li&gt; &#xA;   &lt;li&gt;Completion requests are routed to the ART server, which runs the model&#39;s latest LoRA in vLLM.&lt;/li&gt; &#xA;   &lt;li&gt;As the agent executes, each &lt;code&gt;system&lt;/code&gt;, &lt;code&gt;user&lt;/code&gt;, and &lt;code&gt;assistant&lt;/code&gt; message is stored in a Trajectory.&lt;/li&gt; &#xA;   &lt;li&gt;When a rollout finishes, your code assigns a &lt;code&gt;reward&lt;/code&gt; to its Trajectory, indicating the performance of the LLM.&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Training&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;When each rollout has finished, Trajectories are grouped and sent to the server. Inference is blocked while training executes.&lt;/li&gt; &#xA;   &lt;li&gt;The server trains your model using GRPO, initializing from the latest checkpoint (or an empty LoRA on the first iteration).&lt;/li&gt; &#xA;   &lt;li&gt;The server saves the newly trained LoRA to a local directory and loads it into vLLM.&lt;/li&gt; &#xA;   &lt;li&gt;Inference is unblocked and the loop resumes at step 1.&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;This training loop runs until a specified number of inference and training iterations have completed.&lt;/p&gt; &#xA;&lt;h2&gt;üß© Supported Models&lt;/h2&gt; &#xA;&lt;p&gt;ART should work with most vLLM/HuggingFace-transformers compatible causal language models, or at least the ones supported by &lt;a href=&#34;https://docs.unsloth.ai/get-started/all-our-models&#34;&gt;Unsloth&lt;/a&gt;. Gemma 3 does not appear to be supported for the time being. If any other model isn&#39;t working for you, please let us know on &lt;a href=&#34;https://discord.gg/zbBHRUpwf4&#34;&gt;Discord&lt;/a&gt; or open an issue on &lt;a href=&#34;https://github.com/openpipe/art/issues&#34;&gt;GitHub&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; &#xA;&lt;p&gt;ART is in active development, and contributions are most welcome! Please see the &lt;a href=&#34;https://raw.githubusercontent.com/OpenPipe/ART/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; file for more information.&lt;/p&gt; &#xA;&lt;h2&gt;üìñ Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{hilton2025art,&#xA;  author = {Brad Hilton and Kyle Corbitt and David Corbitt and Saumya Gandhi and Angky William and Bohdan Kovalenskyi and Andie Jones},&#xA;  title = {ART: Agent Reinforcement Trainer},&#xA;  year = {2025},&#xA;  publisher = {GitHub},&#xA;  journal = {GitHub repository},&#xA;  howpublished = {\url{https://github.com/openpipe/art}}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;‚öñÔ∏è License&lt;/h2&gt; &#xA;&lt;p&gt;This repository&#39;s source code is available under the &lt;a href=&#34;https://raw.githubusercontent.com/OpenPipe/ART/main/LICENSE&#34;&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üôè Credits&lt;/h2&gt; &#xA;&lt;p&gt;ART stands on the shoulders of giants. While we owe many of the ideas and early experiments that led to ART&#39;s development to the open source RL community at large, we&#39;re especially grateful to the authors of the following projects:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/unslothai/unsloth&#34;&gt;Unsloth&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vllm-project/vllm&#34;&gt;vLLM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/trl&#34;&gt;trl&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/torchtune&#34;&gt;torchtune&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/skypilot-org/skypilot&#34;&gt;SkyPilot&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Finally, thank you to our partners who&#39;ve helped us test ART in the wild! We&#39;re excited to see what you all build with it.&lt;/p&gt;</summary>
  </entry>
</feed>