<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-15T01:30:28Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ggerganov/ggml</title>
    <updated>2023-03-15T01:30:28Z</updated>
    <id>tag:github.com,2023-03-15:/ggerganov/ggml</id>
    <link href="https://github.com/ggerganov/ggml" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Tensor library for machine learning&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ggml&lt;/h1&gt; &#xA;&lt;p&gt;Tensor library for machine learning&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note that this project is under development and not ready for production use. &lt;br&gt; Some of the development is currently happening in the &lt;a href=&#34;https://github.com/ggerganov/whisper.cpp&#34;&gt;whisper.cpp&lt;/a&gt; repo&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Written in C&lt;/li&gt; &#xA; &lt;li&gt;16-bit float support&lt;/li&gt; &#xA; &lt;li&gt;Automatic differentiation (WIP in progress)&lt;/li&gt; &#xA; &lt;li&gt;ADAM and L-BFGS optimizers&lt;/li&gt; &#xA; &lt;li&gt;Optimized for Apple silicon via NEON intrinsics and Accelerate framework&lt;/li&gt; &#xA; &lt;li&gt;On x86 architectures utilzes AVX intrinsics&lt;/li&gt; &#xA; &lt;li&gt;No third-party dependencies&lt;/li&gt; &#xA; &lt;li&gt;Zero memory allocations during runtime&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Example of GPT-2 inference &lt;a href=&#34;https://github.com/ggerganov/ggml/tree/master/examples/gpt-2&#34;&gt;examples/gpt-2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Example of GPT-J inference &lt;a href=&#34;https://github.com/ggerganov/ggml/tree/master/examples/gpt-j&#34;&gt;examples/gpt-j&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Example of Whisper inference &lt;a href=&#34;https://github.com/ggerganov/ggml/tree/master/examples/whisper&#34;&gt;examples/whisper&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Support 4-bit integer quantization &lt;a href=&#34;https://github.com/ggerganov/ggml/pull/27&#34;&gt;https://github.com/ggerganov/ggml/pull/27&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Example of FLAN-T5 inference &lt;a href=&#34;https://github.com/ggerganov/ggml/pull/12&#34;&gt;https://github.com/ggerganov/ggml/pull/12&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Example of LLaMA inference&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Example of RWKV inference&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Whisper inference (example)&lt;/h2&gt; &#xA;&lt;p&gt;With ggml you can efficiently run &lt;a href=&#34;https://raw.githubusercontent.com/ggerganov/ggml/master/examples/whisper&#34;&gt;Whisper&lt;/a&gt; inference on the CPU.&lt;/p&gt; &#xA;&lt;p&gt;Memory requirements:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Disk&lt;/th&gt; &#xA;   &lt;th&gt;Mem&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;tiny&lt;/td&gt; &#xA;   &lt;td&gt;75 MB&lt;/td&gt; &#xA;   &lt;td&gt;~280 MB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;base&lt;/td&gt; &#xA;   &lt;td&gt;142 MB&lt;/td&gt; &#xA;   &lt;td&gt;~430 MB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;small&lt;/td&gt; &#xA;   &lt;td&gt;466 MB&lt;/td&gt; &#xA;   &lt;td&gt;~1.0 GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;medium&lt;/td&gt; &#xA;   &lt;td&gt;1.5 GB&lt;/td&gt; &#xA;   &lt;td&gt;~2.6 GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;large&lt;/td&gt; &#xA;   &lt;td&gt;2.9 GB&lt;/td&gt; &#xA;   &lt;td&gt;~4.7 GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;GPT inference (example)&lt;/h2&gt; &#xA;&lt;p&gt;With ggml you can efficiently run &lt;a href=&#34;https://raw.githubusercontent.com/ggerganov/ggml/master/examples/gpt-2&#34;&gt;GPT-2&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/ggerganov/ggml/master/examples/gpt-j&#34;&gt;GPT-J&lt;/a&gt; inference on the CPU.&lt;/p&gt; &#xA;&lt;p&gt;Here is how to run the example programs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Build ggml + examples&#xA;git clone https://github.com/ggerganov/ggml&#xA;cd ggml&#xA;mkdir build &amp;amp;&amp;amp; cd build&#xA;cmake ..&#xA;make -j4 gpt-2 gpt-j&#xA;&#xA;# Run the GPT-2 small 117M model&#xA;../examples/gpt-2/download-ggml-model.sh 117M&#xA;./bin/gpt-2 -m models/gpt-2-117M/ggml-model.bin -p &#34;This is an example&#34;&#xA;&#xA;# Run the GPT-J 6B model (requires 12GB disk space and 16GB CPU RAM)&#xA;../examples/gpt-j/download-ggml-model.sh 6B&#xA;./bin/gpt-j -m models/gpt-j-6B/ggml-model.bin -p &#34;This is an example&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The inference speeds that I get for the different models on my 32GB MacBook M1 Pro are as follows:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Size&lt;/th&gt; &#xA;   &lt;th&gt;Time / Token&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPT-2&lt;/td&gt; &#xA;   &lt;td&gt;117M&lt;/td&gt; &#xA;   &lt;td&gt;5 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPT-2&lt;/td&gt; &#xA;   &lt;td&gt;345M&lt;/td&gt; &#xA;   &lt;td&gt;12 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPT-2&lt;/td&gt; &#xA;   &lt;td&gt;774M&lt;/td&gt; &#xA;   &lt;td&gt;23 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPT-2&lt;/td&gt; &#xA;   &lt;td&gt;1558M&lt;/td&gt; &#xA;   &lt;td&gt;42 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;---&lt;/td&gt; &#xA;   &lt;td&gt;---&lt;/td&gt; &#xA;   &lt;td&gt;---&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPT-J&lt;/td&gt; &#xA;   &lt;td&gt;6B&lt;/td&gt; &#xA;   &lt;td&gt;125 ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;For more information, checkout the corresponding programs in the &lt;a href=&#34;https://raw.githubusercontent.com/ggerganov/ggml/master/examples&#34;&gt;examples&lt;/a&gt; folder.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ccfos/nightingale</title>
    <updated>2023-03-15T01:30:28Z</updated>
    <id>tag:github.com,2023-03-15:/ccfos/nightingale</id>
    <link href="https://github.com/ccfos/nightingale" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An enterprise-level cloud-native monitoring system, which can be used as drop-in replacement of Prometheus for alerting and Grafana for visualization.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/ccfos/nightingale&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ccfos/nightingale/main/doc/img/nightingale_logo_h.png&#34; alt=&#34;nightingale - cloud native monitoring&#34; width=&#34;240&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img alt=&#34;GitHub latest release&#34; src=&#34;https://img.shields.io/github/v/release/ccfos/nightingale&#34;&gt; &lt;a href=&#34;https://n9e.github.io&#34;&gt; &lt;img alt=&#34;Docs&#34; src=&#34;https://img.shields.io/badge/docs-get%20started-brightgreen&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/u/flashcatcloud&#34;&gt; &lt;img alt=&#34;Docker pulls&#34; src=&#34;https://img.shields.io/docker/pulls/flashcatcloud/nightingale&#34;&gt;&lt;/a&gt; &lt;img alt=&#34;GitHub Repo stars&#34; src=&#34;https://img.shields.io/github/stars/ccfos/nightingale&#34;&gt; &lt;img alt=&#34;GitHub Repo issues&#34; src=&#34;https://img.shields.io/github/issues/ccfos/nightingale&#34;&gt; &lt;img alt=&#34;GitHub Repo issues closed&#34; src=&#34;https://img.shields.io/github/issues-closed/ccfos/nightingale&#34;&gt; &lt;img alt=&#34;GitHub forks&#34; src=&#34;https://img.shields.io/github/forks/ccfos/nightingale&#34;&gt; &lt;a href=&#34;https://github.com/ccfos/nightingale/graphs/contributors&#34;&gt; &lt;img alt=&#34;GitHub contributors&#34; src=&#34;https://img.shields.io/github/contributors-anon/ccfos/nightingale&#34;&gt;&lt;/a&gt; &lt;img alt=&#34;License&#34; src=&#34;https://img.shields.io/badge/license-Apache--2.0-blue&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;b&gt;All-in-one&lt;/b&gt; 的开源云原生监控系统 &lt;br&gt; &lt;b&gt;开箱即用&lt;/b&gt;，集数据采集、可视化、监控告警于一体 &lt;br&gt; 推荐升级您的 &lt;b&gt;Prometheus + AlertManager + Grafana&lt;/b&gt; 组合方案到夜莺！ &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ccfos/nightingale/main/README_EN.md&#34;&gt;English&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/ccfos/nightingale/main/README.md&#34;&gt;中文&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Highlighted Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;开箱即用&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;支持 Docker、Helm Chart、云服务等多种部署方式，集数据采集、监控告警、可视化为一体，内置多种监控仪表盘、快捷视图、告警规则模板，导入即可快速使用，&lt;strong&gt;大幅降低云原生监控系统的建设成本、学习成本、使用成本&lt;/strong&gt;；&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;专业告警&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;可视化的告警配置和管理，支持丰富的告警规则，提供屏蔽规则、订阅规则的配置能力，支持告警多种送达渠道，支持告警自愈、告警事件管理等；&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;云原生&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;以交钥匙的方式快速构建企业级的云原生监控体系，支持 &lt;a href=&#34;https://github.com/flashcatcloud/categraf&#34;&gt;Categraf&lt;/a&gt;、Telegraf、Grafana-agent 等多种采集器，支持 Prometheus、VictoriaMetrics、M3DB、ElasticSearch 等多种数据库，兼容支持导入 Grafana 仪表盘，&lt;strong&gt;与云原生生态无缝集成&lt;/strong&gt;；&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;高性能 高可用&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;得益于夜莺的多数据源管理引擎，和夜莺引擎侧优秀的架构设计，借助于高性能时序库，可以满足数亿时间线的采集、存储、告警分析场景，节省大量成本；&lt;/li&gt; &#xA;   &lt;li&gt;夜莺监控组件均可水平扩展，无单点，已在上千家企业部署落地，经受了严苛的生产实践检验。众多互联网头部公司，夜莺集群机器达百台，处理数亿级时间线，重度使用夜莺监控；&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;灵活扩展 中心化管理&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;夜莺监控，可部署在 1 核 1G 的云主机，可在上百台机器集群化部署，可运行在 K8s 中；也可将时序库、告警引擎等组件下沉到各机房、各 Region，兼顾边缘部署和中心化统一管理，&lt;strong&gt;解决数据割裂，缺乏统一视图的难题&lt;/strong&gt;；&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;开放社区&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;托管于&lt;a href=&#34;https://www.ccf.org.cn/kyfzwyh/&#34;&gt;中国计算机学会开源发展委员会&lt;/a&gt;，有&lt;a href=&#34;https://flashcat.cloud&#34;&gt;快猫星云&lt;/a&gt;和众多公司的持续投入，和数千名社区用户的积极参与，以及夜莺监控项目清晰明确的定位，都保证了夜莺开源社区健康、长久的发展。活跃、专业的社区用户也在持续迭代和沉淀更多的最佳实践于产品中；&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;如果您在使用 Prometheus 过程中，有以下的一个或者多个需求场景，推荐您无缝升级到夜莺&lt;/strong&gt;：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Prometheus、Alertmanager、Grafana 等多个系统较为割裂，缺乏统一视图，无法开箱即用;&lt;/li&gt; &#xA; &lt;li&gt;通过修改配置文件来管理 Prometheus、Alertmanager 的方式，学习曲线大，协同有难度;&lt;/li&gt; &#xA; &lt;li&gt;数据量过大而无法扩展您的 Prometheus 集群；&lt;/li&gt; &#xA; &lt;li&gt;生产环境运行多套 Prometheus 集群，面临管理和使用成本高的问题；&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;如果您在使用 Zabbix，有以下的场景，推荐您升级到夜莺&lt;/strong&gt;：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;监控的数据量太大，希望有更好的扩展解决方案；&lt;/li&gt; &#xA; &lt;li&gt;学习曲线高，多人多团队模式下，希望有更好的协同使用效率；&lt;/li&gt; &#xA; &lt;li&gt;微服务和云原生架构下，监控数据的生命周期多变、监控数据维度基数高，Zabbix 数据模型不易适配；&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;了解更多Zabbix和夜莺监控的对比，推荐您进一步阅读&lt;a href=&#34;https://flashcat.cloud/blog/zabbx-vs-nightingale/&#34;&gt;《Zabbix 和夜莺监控选型对比》&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;strong&gt;如果您在使用 &lt;a href=&#34;https://github.com/open-falcon/falcon-plus&#34;&gt;Open-Falcon&lt;/a&gt;，我们推荐您升级到夜莺：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;关于 Open-Falcon 和夜莺的详细介绍，请参考阅读：&lt;a href=&#34;http://flashcat.cloud/blog/10-trends-of-cloudnative-monitoring/&#34;&gt;《云原生监控的十个特点和趋势》&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;我们推荐您使用 &lt;a href=&#34;https://github.com/flashcatcloud/categraf&#34;&gt;Categraf&lt;/a&gt; 作为首选的监控数据采集器&lt;/strong&gt;：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/flashcatcloud/categraf&#34;&gt;Categraf&lt;/a&gt; 是夜莺监控的默认采集器，采用开放插件机制和 All-in-one 的设计理念，同时支持 metric、log、trace、event 的采集。Categraf 不仅可以采集 CPU、内存、网络等系统层面的指标，也集成了众多开源组件的采集能力，支持K8s生态。Categraf 内置了对应的仪表盘和告警规则，开箱即用。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://n9e.github.io/&#34;&gt;国外文档&lt;/a&gt; | &lt;a href=&#34;http://n9e.flashcat.cloud/&#34;&gt;国内文档&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Screenshots&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/792850/216888712-2565fcea-9df5-47bd-a49e-d60af9bd76e8.mp4&#34;&gt;https://user-images.githubusercontent.com/792850/216888712-2565fcea-9df5-47bd-a49e-d60af9bd76e8.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Architecture&lt;/h2&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/ccfos/nightingale/main/doc/img/arch-product.png&#34; width=&#34;600&#34;&gt; &#xA;&lt;p&gt;夜莺监控可以接收各种采集器上报的监控数据（比如 &lt;a href=&#34;https://github.com/flashcatcloud/categraf&#34;&gt;Categraf&lt;/a&gt;、telegraf、grafana-agent、Prometheus），并写入多种流行的时序数据库中（可以支持Prometheus、M3DB、VictoriaMetrics、Thanos、TDEngine等），提供告警规则、屏蔽规则、订阅规则的配置能力，提供监控数据的查看能力，提供告警自愈机制（告警触发之后自动回调某个webhook地址或者执行某个脚本），提供历史告警事件的存储管理、分组查看的能力。&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/ccfos/nightingale/main/doc/img/arch-system.png&#34; width=&#34;600&#34;&gt; &#xA;&lt;p&gt;夜莺 v5 版本的设计非常简单，核心是 server 和 webapi 两个模块，webapi 无状态，放到中心端，承接前端请求，将用户配置写入数据库；server 是告警引擎和数据转发模块，一般随着时序库走，一个时序库就对应一套 server，每套 server 可以只用一个实例，也可以多个实例组成集群，server 可以接收 Categraf、Telegraf、Grafana-Agent、Datadog-Agent、Falcon-Plugins 上报的数据，写入后端时序库，周期性从数据库同步告警规则，然后查询时序库做告警判断。每套 server 依赖一个 redis。&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/ccfos/nightingale/main/doc/img/install-vm.png&#34; width=&#34;600&#34;&gt; &#xA;&lt;p&gt;如果单机版本的时序数据库（比如 Prometheus） 性能有瓶颈或容灾较差，我们推荐使用 &lt;a href=&#34;https://github.com/VictoriaMetrics/VictoriaMetrics&#34;&gt;VictoriaMetrics&lt;/a&gt;，VictoriaMetrics 架构较为简单，性能优异，易于部署和运维，架构图如上。VictoriaMetrics 更详尽的文档，还请参考其&lt;a href=&#34;https://victoriametrics.com/&#34;&gt;官网&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;开源项目要更有生命力，离不开开放的治理架构和源源不断的开发者和用户共同参与，我们致力于建立开放、中立的开源治理架构，吸纳更多来自企业、高校等各方面对云原生监控感兴趣、有热情的开发者，一起打造有活力的夜莺开源社区。关于《夜莺开源项目和社区治理架构（草案）》，请查阅 &lt;a href=&#34;https://raw.githubusercontent.com/ccfos/nightingale/main/doc/community-governance.md&#34;&gt;COMMUNITY GOVERNANCE&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;我们欢迎您以各种方式参与到夜莺开源项目和开源社区中来，工作包括不限于&lt;/strong&gt;：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;补充和完善文档 =&amp;gt; &lt;a href=&#34;https://n9e.github.io/&#34;&gt;n9e.github.io&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;分享您在使用夜莺监控过程中的最佳实践和经验心得 =&amp;gt; &lt;a href=&#34;https://n9e.github.io/docs/prologue/share/&#34;&gt;文章分享&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;提交产品建议 =》 &lt;a href=&#34;https://github.com/ccfos/nightingale/issues/new?assignees=&amp;amp;labels=kind%2Ffeature&amp;amp;template=enhancement.md&#34;&gt;github issue&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;提交代码，让夜莺监控更快、更稳、更好用 =&amp;gt; &lt;a href=&#34;https://github.com/didi/nightingale/pulls&#34;&gt;github pull request&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;尊重、认可和记录每一位贡献者的工作&lt;/strong&gt;是夜莺开源社区的第一指导原则，我们提倡&lt;strong&gt;高效的提问&lt;/strong&gt;，这既是对开发者时间的尊重，也是对整个社区知识沉淀的贡献：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;提问之前请先查阅 &lt;a href=&#34;https://www.gitlink.org.cn/ccfos/nightingale/wiki/faq&#34;&gt;FAQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;我们使用&lt;a href=&#34;https://github.com/ccfos/nightingale/discussions&#34;&gt;GitHub Discussions&lt;/a&gt;作为交流论坛，有问题可以到这里搜索、提问&lt;/li&gt; &#xA; &lt;li&gt;我们也推荐你加入微信群，和其他夜莺用户交流经验 (请先加好友：&lt;a href=&#34;https://www.gitlink.org.cn/UlricQin/gist/tree/master/self.jpeg&#34;&gt;picobyte&lt;/a&gt; 备注：夜莺加群+姓名+公司)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Who is using Nightingale&lt;/h2&gt; &#xA;&lt;p&gt;您可以通过在 &lt;strong&gt;&lt;a href=&#34;https://github.com/ccfos/nightingale/issues/897&#34;&gt;Who is Using Nightingale&lt;/a&gt;&lt;/strong&gt; 登记您的使用情况，分享您的使用经验。&lt;/p&gt; &#xA;&lt;h2&gt;Stargazers over time&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://starchart.cc/ccfos/nightingale&#34;&gt;&lt;img src=&#34;https://starchart.cc/ccfos/nightingale.svg?sanitize=true&#34; alt=&#34;Stargazers over time&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/ccfos/nightingale/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=ccfos/nightingale&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/didi/nightingale/raw/main/LICENSE&#34;&gt;Apache License V2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;加入交流群&lt;/h2&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/ccfos/nightingale/main/doc/img/wecom.png&#34; width=&#34;120&#34;&gt;</summary>
  </entry>
  <entry>
    <title>pgrok/pgrok</title>
    <updated>2023-03-15T01:30:28Z</updated>
    <id>tag:github.com,2023-03-15:/pgrok/pgrok</id>
    <link href="https://github.com/pgrok/pgrok" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Poor man&#39;s ngrok - a multi-tenant HTTP reverse tunnel solution through SSH remote port forwarding&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;pgrok - Poor man&#39;s ngrok&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://sourcegraph.com/github.com/pgrok/pgrok&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/view%20on-Sourcegraph-brightgreen.svg?style=for-the-badge&amp;amp;logo=sourcegraph&#34; alt=&#34;Sourcegraph&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What?&lt;/h2&gt; &#xA;&lt;p&gt;The pgrok is a multi-tenant HTTP reverse tunnel solution through remote port forwarding from the SSH protocol.&lt;/p&gt; &#xA;&lt;p&gt;This is intended for small teams that need to expose the local development environment to the public internet, and you need to bring your own domain name and SSO provider.&lt;/p&gt; &#xA;&lt;p&gt;It gives stable subdomain for every user, and gated by your SSO through OIDC protocol.&lt;/p&gt; &#xA;&lt;p&gt;Think of this as a bare-bones alternative to the &lt;a href=&#34;https://ngrok.com/pricing&#34;&gt;ngrok&#39;s $65/user/month enterprise tier&lt;/a&gt;. Trying to put this behind a production system will blow up your SLA.&lt;/p&gt; &#xA;&lt;p&gt;For individuals and production systems, just buy ngrok, it is still my favorite.&lt;/p&gt; &#xA;&lt;h2&gt;Why?&lt;/h2&gt; &#xA;&lt;p&gt;Stable subdomains and SSO are two things too expensive.&lt;/p&gt; &#xA;&lt;p&gt;Why not just pick one from the &lt;a href=&#34;https://github.com/anderspitman/awesome-tunneling&#34;&gt;Awesome Tunneling&lt;/a&gt;? Think broader. Not everyone is a dev who knows about server operations. For people working as community managers, sales, and PMs, booting up something locally could already be a stretch and requiring them to understand how to set up and fix server problems is a waste of team&#39;s productivity.&lt;/p&gt; &#xA;&lt;p&gt;Copy, paste, and run is the best UX for everyone.&lt;/p&gt; &#xA;&lt;h2&gt;How?&lt;/h2&gt; &#xA;&lt;p&gt;Before you get started, make sure you have the following:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;A domain name (e.g. &lt;code&gt;pgrok.dev&lt;/code&gt;, this will be used as the example throughout this section).&lt;/li&gt; &#xA; &lt;li&gt;A server (dedicated server, VPS) with a public IP address (e.g. &lt;code&gt;111.33.5.14&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;An SSO provider (e.g. Google, Okta, Keycloak) that allows you to create OIDC clients.&lt;/li&gt; &#xA; &lt;li&gt;A PostgreSQL server (&lt;a href=&#34;https://bit.io/&#34;&gt;bit.io&lt;/a&gt;, Cloud SQL, self-host).&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;HTTPS for the web and proxy server is not required for this to work, while recommended if possible. Examples in the section all use HTTP.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Set up the server (&lt;code&gt;pgrokd&lt;/code&gt;)&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Add the following DNS records for your domain name: &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;&lt;code&gt;A&lt;/code&gt; record for &lt;code&gt;pgrok.dev&lt;/code&gt; to &lt;code&gt;111.33.5.14&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;A&lt;/code&gt; record for &lt;code&gt;*.pgrok.dev&lt;/code&gt; to &lt;code&gt;111.33.5.14&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;Create a &lt;code&gt;pgrokd.yml&lt;/code&gt; file: &lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;external_url: &#34;http://pgrok.dev&#34;&#xA;web:&#xA;  port: 3320&#xA;proxy:&#xA;  port: 3000&#xA;  scheme: &#34;http&#34;&#xA;  domain: &#34;pgrok.dev&#34;&#xA;sshd:&#xA;  port: 2222&#xA;&#xA;database:&#xA;  host: &#34;localhost&#34;&#xA;  port: 5432&#xA;  user: &#34;REDACTED&#34;&#xA;  password: &#34;REDACTED&#34;&#xA;  database: &#34;pgrokd&#34;&#xA;&#xA;identity_provider:&#xA;  type: &#34;oidc&#34;&#xA;  display_name: &#34;Google&#34;&#xA;  issuer: &#34;https://accounts.google.com&#34;&#xA;  client_id: &#34;REDACTED&#34;&#xA;  client_secret: &#34;REDACTED&#34;&#xA;  field_mapping:&#xA;    identifier: &#34;email&#34;&#xA;    display_name: &#34;name&#34;&#xA;    email: &#34;email&#34;&#xA;#  # The required domain name, &#34;field_mapping.email&#34; is required to set for this to work.&#xA;#  required_domain: &#34;example.com&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Download the latest version of the &lt;code&gt;pgrokd&lt;/code&gt; archive from the &lt;a href=&#34;https://github.com/pgrok/pgrok/releases&#34;&gt;Releases&lt;/a&gt; page.&lt;/li&gt; &#xA; &lt;li&gt;Launch the &lt;code&gt;pgrokd&lt;/code&gt; in background (systemd, screen, nohup). &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;By default, &lt;code&gt;pgrokd&lt;/code&gt; expects the &lt;code&gt;pgrokd.yml&lt;/code&gt; is available in the working directory. Use &lt;code&gt;--config&lt;/code&gt; flag to specify a different path for the config file.&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;Alter your network security policy (if applicable) to allow inbound requests to port 2222 from &lt;code&gt;0.0.0.0/0&lt;/code&gt; (anywhere).&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://caddyserver.com/docs/install&#34;&gt;Download and install Caddy 2&lt;/a&gt; on your server, and use the following Caddyfile config: &lt;pre&gt;&lt;code class=&#34;language-caddyfile&#34;&gt;http://pgrok.dev {&#xA;    reverse_proxy * localhost:3320&#xA;}&#xA;&#xA;http://*.pgrok.dev {&#xA;    reverse_proxy * localhost:3000&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Create a new OIDC client in your SSO with the &lt;strong&gt;Redirect URI&lt;/strong&gt; to be &lt;code&gt;http://pgrok.dev/-/oidc/callback&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Set up the client (&lt;code&gt;pgrok&lt;/code&gt;)&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Go to &lt;a href=&#34;http://pgrok.dev&#34;&gt;http://pgrok.dev&lt;/a&gt;, authenticate with your SSO to obtain the token and URL (e.g. &lt;code&gt;http://unknwon.pgrok.dev&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Download the latest version of the &lt;code&gt;pgrok&lt;/code&gt;: &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;For Homebrew: &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;brew install pgrok/tap/pgrok&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt;For others, download the archive from the &lt;a href=&#34;https://github.com/pgrok/pgrok/releases&#34;&gt;Releases&lt;/a&gt; page.&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;Initialize a &lt;code&gt;pgrok.yml&lt;/code&gt; file with the following command (assuming you want to forward requests to &lt;code&gt;http://localhost:3000&lt;/code&gt;): &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pgrok init --remote-addr pgrok.dev:2222 --forward-addr http://localhost:3000 --token {YOUR_TOKEN}&#xA;&lt;/code&gt;&lt;/pre&gt; By default, the config file is created under the home directory (&lt;code&gt;~/.pgrok/pgrok.yml&lt;/code&gt;). Use &lt;code&gt;--config&lt;/code&gt; flag to specify a different path for the config file.&lt;/li&gt; &#xA; &lt;li&gt;Launch the client by executing the &lt;code&gt;pgrok&lt;/code&gt; or &lt;code&gt;pgrok http&lt;/code&gt; command. &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;By default, &lt;code&gt;pgrok&lt;/code&gt; expects the &lt;code&gt;pgrok.yml&lt;/code&gt; is available under the home directory (&lt;code&gt;~/.pgrok/pgrok.yml&lt;/code&gt;). Use &lt;code&gt;--config&lt;/code&gt; flag to specify a different path for the config file.&lt;/li&gt; &#xA;   &lt;li&gt;Use the &lt;code&gt;--debug&lt;/code&gt; flag to turn on debug logging.&lt;/li&gt; &#xA;   &lt;li&gt;Upon successful startup, you should see a log looks like: &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;YYYY-MM-DD 12:34:56 INFO Tunneling connection established remote=pgrok.dev:2222&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;Now visit the URL.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;Override config options&lt;/h4&gt; &#xA;&lt;p&gt;Following config options can be overridden through CLI flags:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--remote-addr&lt;/code&gt; -&amp;gt; &lt;code&gt;remote_addr&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--forward-addr&lt;/code&gt; -&amp;gt; &lt;code&gt;forward_addr&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--token&lt;/code&gt; -&amp;gt; &lt;code&gt;token&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;As a special case, the first argument of the &lt;code&gt;pgrok http&lt;/code&gt; can be used to specify forward address, e.g.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pgrok http 8080&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Dynamic forwards&lt;/h4&gt; &#xA;&lt;p&gt;In addition to traditional request forwarding to a single address, &lt;code&gt;pgrok&lt;/code&gt; can be configured to have dynamic forward rules.&lt;/p&gt; &#xA;&lt;p&gt;For example, if your local frontend is running at &lt;code&gt;http://localhost:3000&lt;/code&gt; but some gRPC endpoints need to talk to the backend directly at &lt;code&gt;http://localhost:8080&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;dynamic_forwards: |&#xA;  /api http://localhost:8080&#xA;  /hook http://localhost:8080&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then all requests prefixed with the path &lt;code&gt;/api&lt;/code&gt; and &lt;code&gt;/hook&lt;/code&gt; will be forwarded to &lt;code&gt;http://localhost:8080&lt;/code&gt; and all the rest are forwarded to the &lt;code&gt;forward_addr&lt;/code&gt; (&lt;code&gt;http://localhost:3000&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;h3&gt;Vanilla SSH&lt;/h3&gt; &#xA;&lt;p&gt;Because the standard SSH protocol is used for tunneling, you may well just use the vanilla SSH client.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Go to &lt;a href=&#34;http://pgrok.dev&#34;&gt;http://pgrok.dev&lt;/a&gt;, authenticate with your SSO to obtain the token and URL (e.g. &lt;code&gt;http://unknwon.pgrok.dev&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Launch the client by executing the &lt;code&gt;ssh -N -R 0::3000 pgrok.dev -p 2222&lt;/code&gt; command: &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Enter the token as your password.&lt;/li&gt; &#xA;   &lt;li&gt;Use the &lt;code&gt;-v&lt;/code&gt; flag to turn on debug logging.&lt;/li&gt; &#xA;   &lt;li&gt;Upon successful startup, you should see a log looks like: &lt;pre&gt;&lt;code&gt;Allocated port 22487 for remote forward to :3000&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;Now visit the URL.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Explain it to me&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/2946214/224469633-4d03a2cb-8561-4584-a743-c70f3fda0aef.png&#34; alt=&#34;pgrok network diagram&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Sponsors&lt;/h2&gt; &#xA;&lt;p&gt; &lt;a href=&#34;https://www.bytebase.com&#34;&gt; &lt;img src=&#34;https://www.bytebase.com/_nuxt/img/logo-full.79b60e4.svg?sanitize=true&#34; width=&#34;300&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://www.flaticon.com/free-icon/nat_9168228&#34;&gt;logo&lt;/a&gt; is from &lt;a href=&#34;https://www.flaticon.com/&#34;&gt;flaticon.com&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The project wouldn&#39;t be possible without reading &lt;a href=&#34;https://github.com/function61/holepunch-server&#34;&gt;function61/holepunch-server&lt;/a&gt;, &lt;a href=&#34;https://github.com/function61/holepunch-client&#34;&gt;function61/holepunch-client&lt;/a&gt;, and &lt;a href=&#34;https://github.com/apache/mina-sshd/raw/master/docs/technical/tcpip-forwarding.md&#34;&gt;TCP/IP Port Forwarding&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is under the MIT License. See the &lt;a href=&#34;https://raw.githubusercontent.com/pgrok/pgrok/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for the full license text.&lt;/p&gt;</summary>
  </entry>
</feed>