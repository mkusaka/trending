<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-05-26T01:29:06Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>duixcom/Duix.Heygem</title>
    <updated>2025-05-26T01:29:06Z</updated>
    <id>tag:github.com,2025-05-26:/duixcom/Duix.Heygem</id>
    <link href="https://github.com/duixcom/Duix.Heygem" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/1.png&#34; style=&#34;width: 220px; height: auto;&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;HeyGem - Open Source Alternative to Heygen&lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;Table of Contents&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/#1-whats-heygem&#34;&gt;What&#39;s HeyGem&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/#2-introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/#3-how-to-run-locally&#34;&gt;How to Run Locally&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/#4-open-apis&#34;&gt;Open APIs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/#5-whats-new&#34;&gt;What&#39;s New&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/#6-faq&#34;&gt;FAQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/#7-how-to-interact-in-real-time&#34;&gt;How to Interact in real time&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/#8-contact&#34;&gt;Contact&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/#9-license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/#10-acknowledgments&#34;&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/#11-star-history&#34;&gt;Star History&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;1. What&#39;s HeyGem&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;HeyGem&lt;/strong&gt; is a free and open-source AI avatar project developed by &lt;strong&gt;Duix.com&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Seven years ago, a group of young pioneers chose an unconventional technical path, developing a method to train digital human models using real-person video data. Unlike traditional costly 3D digital human approaches, we leveraged AI-generated technology to create ultra-realistic digital humans, slashing production costs from hundreds of thousands of dollars to just $1,000. This innovation has empowered over 10,000 enterprises and generated over 500,000 personalized avatars for professionals across fields – educators, content creators, legal experts, medical practitioners, and entrepreneurs – dramatically enhancing their video production efficiency. However, our vision extends beyond commercial applications. We believe this transformative technology should be accessible to everyone. To democratize digital human creation, we&#39;ve open-sourced our cloning technology and video production framework. Our commitment remains: breaking down technological barriers to make cutting-edge tools available to all. Now, anyone with a computer can freely craft their own AI Avatar and produce videos at zero cost – this is the essence of &lt;strong&gt;HeyGem&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;2. Introduction&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/2.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Heygem is a fully offline video synthesis tool designed for Windows systems that can precisely clone your appearance and voice, digitalizing your image. You can create videos by driving virtual avatars through text and voice. No internet connection is required, protecting your privacy while enjoying convenient and efficient digital experiences.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Core Features &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Precise Appearance and Voice Cloning: Using advanced AI algorithms to capture human facial features with high precision, including facial features, contours, etc., to build realistic virtual models. It can also precisely clone voices, capturing and reproducing subtle characteristics of human voices, supporting various voice parameter settings to create highly similar cloning effects.&lt;/li&gt; &#xA;   &lt;li&gt;Text and Voice-Driven Virtual Avatars: Understanding text content through natural language processing technology, converting text into natural and fluent speech to drive virtual avatars. Voice input can also be used directly, allowing virtual avatars to perform corresponding actions and facial expressions based on the rhythm and intonation of the voice, making the virtual avatar&#39;s performance more natural and vivid.&lt;/li&gt; &#xA;   &lt;li&gt;Efficient Video Synthesis: Highly synchronizing digital human video images with sound, achieving natural and smooth lip-syncing, intelligently optimizing audio-video synchronization effects.&lt;/li&gt; &#xA;   &lt;li&gt;Multi-language Support: Scripts support eight languages - English, Japanese, Korean, Chinese, French, German, Arabic, and Spanish.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Key Advantages &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fully Offline Operation: No internet connection required, effectively protecting user privacy, allowing users to create in a secure, independent environment, avoiding potential data leaks during network transmission.&lt;/li&gt; &#xA;   &lt;li&gt;User-Friendly: Clean and intuitive interface, easy to use even for beginners with no technical background, quickly mastering the software&#39;s usage to start their digital human creation journey.&lt;/li&gt; &#xA;   &lt;li&gt;Multiple Model Support: Supports importing multiple models and managing them through one-click startup packages, making it convenient for users to choose suitable models based on different creative needs and application scenarios.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Technical Support &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Voice Cloning Technology: Using advanced technologies like artificial intelligence to generate similar or identical voices based on given voice samples, covering context, intonation, speed, and other aspects of speech.&lt;/li&gt; &#xA;   &lt;li&gt;Automatic Speech Recognition: Technology that converts human speech vocabulary content into computer-readable input (text format), enabling computers to &#34;understand&#34; human speech.&lt;/li&gt; &#xA;   &lt;li&gt;Computer Vision Technology: Used in video synthesis for visual processing, including facial recognition and lip movement analysis, ensuring virtual avatar lip movements match voice and text content.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;3. How to Run Locally&lt;/h2&gt; &#xA;&lt;p&gt;HeyGem supports Docker-based rapid deployment. Prior to deployment, ensure your hardware and software environments meet the specified requirements.&lt;/p&gt; &#xA;&lt;p&gt;HeyGem support two deployment modes：Windows / Ubuntu 22.04 Installation&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Dependencies&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Nodejs 18&lt;/li&gt; &#xA; &lt;li&gt;Docker Images &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;docker pull guiji2025/fun-asr&lt;/li&gt; &#xA;   &lt;li&gt;docker pull guiji2025/fish-speech-ziming&lt;/li&gt; &#xA;   &lt;li&gt;docker pull guiji2025/heygem.ai&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Mode 1：Windows Installation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;System Requirements:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Currently supports Windows 10 19042.1526 or higher&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Hardware Requirements：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Must have D Drive: Mainly used for storing digital human and project data&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Free space requirement: More than 30GB&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;C Drive: Used for storing service image files&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Free space requirement: More than 100GB&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;If less than 100GB is available, after installing Docker, you can choose a different disk folder with more than 100GB of remaining space at the location shown below.&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/7.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Recommended Configuration:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;CPU: 13th Gen Intel Core i5-13400F&lt;/li&gt; &#xA;   &lt;li&gt;Memory: 32GB&lt;/li&gt; &#xA;   &lt;li&gt;Graphics Card: RTX 4070&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Ensure you have an NVIDIA graphics card with properly installed drivers&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;NVIDIA driver download link: &lt;a href=&#34;https://www.nvidia.cn/drivers/lookup/&#34;&gt;https://www.nvidia.cn/drivers/lookup/&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/14.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;&lt;strong&gt;Installing Windows Docker&lt;/strong&gt;&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Use the command &lt;code&gt;wsl --list --verbose&lt;/code&gt; to check if WSL is installed. If it shows as below, it&#39;s already installed and no further installation is needed.&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/11.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Update WSL using &lt;code&gt;wsl --update&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/10.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.docker.com/&#34;&gt;Download Docker for Windows&lt;/a&gt;, choose the appropriate installation package based on your CPU architecture.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;When you see this interface, installation is successful.&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/5.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run Docker&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/12.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Accept the agreement and skip login on first run&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/8.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/13.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/3.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;&lt;strong&gt;Installing the Server&lt;/strong&gt;&lt;/h4&gt; &#xA;&lt;p&gt;Installation using Docker, docker-compose as follows:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;docker-compose.yml&lt;/code&gt; file is in the &lt;code&gt;/deploy&lt;/code&gt; directory.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Execute &lt;code&gt;docker-compose up -d&lt;/code&gt; in the &lt;code&gt;/deploy&lt;/code&gt; directory, if you want to use the lite version, execute &lt;code&gt;docker-compose -f docker-compose-lite.yml up -d&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Wait patiently (about half an hour, speed depends on network), download will consume about 70GB of traffic, make sure to use WiFi&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;When you see three services in Docker, it indicates success (the lite version has only one service &lt;code&gt;heygem-gen-video&lt;/code&gt;)&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/6.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;&lt;strong&gt;Server Deployment Solution for NVIDIA 50 Series Graphics Cards&lt;/strong&gt;&lt;/h4&gt; &#xA;&lt;p&gt;For 50 series graphics cards (tested and also works for 30/40 series with CUDA 12.8) Uses the official preview version of PyTorch&lt;/p&gt; &#xA;&lt;h4&gt;&lt;strong&gt;Client&lt;/strong&gt;&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Directly download the &lt;a href=&#34;https://github.com/GuijiAI/HeyGem.ai/releases&#34;&gt;officially built installation package&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Double-click &lt;code&gt;HeyGem-x.x.x-setup.exe&lt;/code&gt; to install&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Mode 2：Ubuntu 22.04 Installation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;System Requirements：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;We have conducted a complete test on &lt;strong&gt;Ubuntu 22.04&lt;/strong&gt;. However, theoretically, it supports desktop Linux distributions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Hardware Requirements：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Recommended Configuration&lt;/li&gt; &#xA; &lt;li&gt;CPU: 13th Generation Intel Core i5 - 13400F&lt;/li&gt; &#xA; &lt;li&gt;Memory: 32G or more (necessary)&lt;/li&gt; &#xA; &lt;li&gt;Graphics Card: RTX - 4070 (Ensure you have an NVIDIA graphics card and the graphics card driver is correctly installed)&lt;/li&gt; &#xA; &lt;li&gt;Hard Disk: Free space greater than 100G&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Install Docker:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;First, use&lt;code&gt; docker --version&lt;/code&gt; to check if Docker is installed. If it is installed, skip the following steps.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo apt update&#xA;sudo apt install docker.io&#xA;sudo apt install docker-compose&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Install the graphics card driver:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install the graphics card driver by referring to the official documentation(&lt;a href=&#34;https://www.nvidia.cn/drivers/lookup/&#34;&gt;https://www.nvidia.cn/drivers/lookup/&lt;/a&gt;).&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;After installation, execute the &lt;code&gt;nvidia-smi&lt;/code&gt; command. If the graphics card information is displayed, the installation is successful.&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Install the NVIDIA Container Toolkit&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;​ The NVIDIA Container Toolkit is a necessary tool for Docker to use NVIDIA GPUs. The installation steps are as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Add the NVIDIA package repository:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \&#xA;  &amp;amp;&amp;amp; curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | sudo apt-key add - \&#xA;  &amp;amp;&amp;amp; curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Update the package list and install the toolkit:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo apt-get update&#xA;sudo apt-get install -y nvidia-container-toolkit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Configure Docker to use the NVIDIA runtime:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo nvidia-ctk runtime configure --runtime=docker&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Restart the Docker service:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo systemctl restart docker&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;&lt;strong&gt;Install the server&lt;/strong&gt;&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd /deploy&#xA;docker-compose -f docker-compose-linux.yml up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;&lt;strong&gt;Install the client&lt;/strong&gt;&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Directly download the Linux version of the &lt;a href=&#34;https://github.com/GuijiAI/HeyGem.ai/releases&#34;&gt;officially built installation package&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Double click &lt;code&gt;HeyGem-x.x.x.AppImage&lt;/code&gt; to launch it. No installation is required.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Reminder: In the Ubuntu system, if you enter the desktop as the &lt;code&gt;root&lt;/code&gt; user, directly double - clicking &lt;code&gt;HeyGem - x.x.x.AppImage&lt;/code&gt; may not work. You need to execute &lt;code&gt;./HeyGem - x.x.x.AppImage --no - sandbox&lt;/code&gt; in the command - line terminal. Adding the &lt;code&gt;--no - sandbox&lt;/code&gt; parameter will do the trick.&lt;/p&gt; &#xA;&lt;h2&gt;4. Open APIs&lt;/h2&gt; &#xA;&lt;p&gt;We have opened APIs for model training and video synthesis. After Docker starts, several ports will be exposed locally, accessible through &lt;code&gt;http://127.0.0.1&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For specific code, refer to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;src/main/service/model.js&lt;/li&gt; &#xA; &lt;li&gt;src/main/service/video.js&lt;/li&gt; &#xA; &lt;li&gt;src/main/service/voice.js&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Model Training&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Separate video into silent video + audio&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Place audio in&lt;/p&gt; &lt;p&gt;&lt;code&gt;D:\heygem_data\voice\data&lt;/code&gt; is agreed with the &lt;code&gt;guiji2025/fish-speech-ziming&lt;/code&gt; service, can be modified in docker-compose&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Call the&lt;/p&gt; &lt;p&gt;Parameter example:Response example:&lt;strong&gt;Record the response results as they will be needed for subsequent audio synthesis&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Audio Synthesis&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Interface: &lt;code&gt;http://127.0.0.1:18180/v1/invoke&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;// Request parameters&#xA;{&#xA;  &#34;speaker&#34;: &#34;{uuid}&#34;, // A unique UUID&#xA;  &#34;text&#34;: &#34;xxxxxxxxxx&#34;, // Text content to synthesize&#xA;  &#34;format&#34;: &#34;wav&#34;, // Fixed parameter&#xA;  &#34;topP&#34;: 0.7, // Fixed parameter&#xA;  &#34;max_new_tokens&#34;: 1024, // Fixed parameter&#xA;  &#34;chunk_length&#34;: 100, // Fixed parameter&#xA;  &#34;repetition_penalty&#34;: 1.2, // Fixed parameter&#xA;  &#34;temperature&#34;: 0.7, // Fixed parameter&#xA;  &#34;need_asr&#34;: false, // Fixed parameter&#xA;  &#34;streaming&#34;: false, // Fixed parameter&#xA;  &#34;is_fixed_seed&#34;: 0, // Fixed parameter&#xA;  &#34;is_norm&#34;: 0, // Fixed parameter&#xA;  &#34;reference_audio&#34;: &#34;{voice.asr_format_audio_url}&#34;, // Return value from previous &#34;Model Training&#34; step&#xA;  &#34;reference_text&#34;: &#34;{voice.reference_audio_text}&#34; // Return value from previous &#34;Model Training&#34; step&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Video Synthesis&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Synthesis interface: &lt;code&gt;http://127.0.0.1:8383/easy/submit&lt;/code&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;// Request parameters&#xA;{&#xA;  &#34;audio_url&#34;: &#34;{audioPath}&#34;, // Audio path&#xA;  &#34;video_url&#34;: &#34;{videoPath}&#34;, // Video path&#xA;  &#34;code&#34;: &#34;{uuid}&#34;, // Unique key&#xA;  &#34;chaofen&#34;: 0, // Fixed value&#xA;  &#34;watermark_switch&#34;: 0, // Fixed value&#xA;  &#34;pn&#34;: 1 // Fixed value&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Progress query: &lt;code&gt;http://127.0.0.1:8383/easy/query?code=${taskCode}&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;GET request, the parameter &lt;code&gt;taskCode&lt;/code&gt; is the &lt;code&gt;code&lt;/code&gt; from the synthesis interface input above&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Important Notice to Developer Partners&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;we are now announcing two parallel service solutions:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Project&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;HeyGem Open Source Local Deployment&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Digital Human/Clone Voice API Service&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Usage&lt;/td&gt; &#xA;   &lt;td&gt;Open Source Local Deployment&lt;/td&gt; &#xA;   &lt;td&gt;Rapid Clone API Service&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Recommended&lt;/td&gt; &#xA;   &lt;td&gt;Technical Users&lt;/td&gt; &#xA;   &lt;td&gt;Business Users&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Technical Threshold&lt;/td&gt; &#xA;   &lt;td&gt;Developers with deep learning framework experience/pursuing deep customization/wishing to participate in community co-construction&lt;/td&gt; &#xA;   &lt;td&gt;Quick business integration/focus on upper-level application development/need enterprise-level SLA assurance for commercial scenarios&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Hardware Requirements&lt;/td&gt; &#xA;   &lt;td&gt;Need to purchase GPU server&lt;/td&gt; &#xA;   &lt;td&gt;No need to purchase GPU server&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Customization&lt;/td&gt; &#xA;   &lt;td&gt;Can modify and extend the code according to your needs, fully controlling the software&#39;s functions and behavior&lt;/td&gt; &#xA;   &lt;td&gt;Cannot directly modify the source code, can only extend functions through API-provided interfaces, less flexible than open source projects&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Technical Support&lt;/td&gt; &#xA;   &lt;td&gt;Community Support&lt;/td&gt; &#xA;   &lt;td&gt;Dynamic expansion support + professional technical response team&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Maintenance Cost&lt;/td&gt; &#xA;   &lt;td&gt;High maintenance cost&lt;/td&gt; &#xA;   &lt;td&gt;Simple maintenance&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lip Sync Effect&lt;/td&gt; &#xA;   &lt;td&gt;Usable effect&lt;/td&gt; &#xA;   &lt;td&gt;Stunning and higher definition effect&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Commercial Authorization&lt;/td&gt; &#xA;   &lt;td&gt;Supports global free commercial use (enterprises with more than 100,000 users or annual revenue exceeding 10 million USD need to sign a commercial license agreement)&lt;/td&gt; &#xA;   &lt;td&gt;Commercial use allowed&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Iteration Speed&lt;/td&gt; &#xA;   &lt;td&gt;Slow updates, bug fixes depend on the community&lt;/td&gt; &#xA;   &lt;td&gt;Latest models/algorithms are prioritized, fast problem resolution&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;We always adhere to the open source spirit, and the launch of the API service aims to provide a more complete solution matrix for developers with different needs. No matter which method you choose, you can always obtain technical support documents through &lt;a href=&#34;https://duix.com/&#34;&gt;https://duix.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;We look forward to working with you to promote the inclusive development of digital human technology!&lt;/p&gt; &#xA;&lt;p&gt;You can chat with Heygem Digital Human on the official website: &lt;a href=&#34;https://duix.com/&#34;&gt;https://duix.com/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;We also provide APl at DUIX Platform: &lt;a href=&#34;https://docs.duix.com/api-reference/api/Introduction&#34;&gt;https://docs.duix.com/api-reference/api/Introduction&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;5. What&#39;s New&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;strong&gt;[Nvidia 50 Series GPU Version Notice]&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Tested and verified on 5090 GPU&lt;/li&gt; &#xA; &lt;li&gt;For installation instructions, see &lt;a href=&#34;https://github.com/duixcom/Duix.Heygem?tab=readme-ov-file#Server-Deployment-Solution-for-NVIDIA-50-Series-Graphics-Cards&#34;&gt;Server Deployment Solution for NVIDIA 50 Series Graphics Cards&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;&lt;strong&gt;[New Ubuntu Version Notice]&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Ubuntu Version Officially Released&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Adaptation and verification work for Ubuntu 22.04 Desktop version (kernel 6.8.0-52-generic) has been completed. Compatibility testing for other Linux versions has not yet been conducted.&lt;/li&gt; &#xA; &lt;li&gt;Added internationalization (English) for the client program interface.&lt;/li&gt; &#xA; &lt;li&gt;Fixed some known issues &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;#304&lt;/li&gt; &#xA;   &lt;li&gt;#292&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/GuijiAI/HeyGem.ai?tab=readme-ov-file#ubuntu-2204-installation&#34;&gt;Ubuntu22.04 Installation Documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;6. FAQ&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Self-Check Steps Before Asking Questions&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Check if all three services are in Running status&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/9.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Confirm that your machine has an NVIDIA graphics card and drivers are correctly installed.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;All computing power for this project is local. The three services won&#39;t start without an NVIDIA graphics card or proper drivers.&lt;/p&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Ensure both server and client are updated to the latest version. The project is newly open-sourced, the community is very active, and updates are frequent. Your issue might have been resolved in a new version. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Server: Go to &lt;code&gt;/deploy&lt;/code&gt; directory and re-execute &lt;code&gt;docker-compose up -d&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Client: &lt;code&gt;pull&lt;/code&gt; code and re-&lt;code&gt;build&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/GuijiAI/HeyGem.ai/issues&#34;&gt;GitHub Issues&lt;/a&gt; are continuously updated, issues are being resolved and closed daily. Check frequently, your issue might already be resolved.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Question Template&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Problem Description&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Describe the reproduction steps in detail, with screenshots if possible.&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Provide Error Logs &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;How to get client logs:&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/4.jpeg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Server logs:&lt;/p&gt; &lt;p&gt;Find the key location, or click on our three Docker services, and &#34;Copy&#34; as shown below.&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/README.assets/15.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;7. How to Interact in real time&lt;/h2&gt; &#xA;&lt;p&gt;HeyGem&#39;s digital human realizes digital human cloning and non-real-time video synthesis.&lt;/p&gt; &#xA;&lt;p&gt;If you want a digital human to support interaction, you can visit &lt;a href=&#34;https://raw.githubusercontent.com/duixcom/Duix.Heygem/main/www.duix.com&#34;&gt;duix.com&lt;/a&gt; to experience the free test.&lt;/p&gt; &#xA;&lt;h2&gt;8. Contact&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions, please raise an issue or contact us at &lt;a href=&#34;mailto:james@duix.com&#34;&gt;james@duix.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;9. License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/GuijiAI/HeyGem.ai/raw/main/LICENSE&#34;&gt;https://github.com/GuijiAI/HeyGem.ai/blob/main/LICENSE&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;10. Acknowledgments&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ASR based on fun-asr&lt;/li&gt; &#xA; &lt;li&gt;TTS based on fish-speech-ziming&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;11. Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.star-history.com/#GuijiAI/HeyGem.ai&amp;amp;Date&#34;&gt;GitHub Star History&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>groupultra/telegram-search</title>
    <updated>2025-05-26T01:29:06Z</updated>
    <id>tag:github.com,2025-05-26:/groupultra/telegram-search</id>
    <link href="https://github.com/groupultra/telegram-search" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🔍 一个功能强大的 Telegram 聊天记录搜索客户端，支持聊天记录备份和向量搜索。&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Telegram Search&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/groupultra/telegram-search/main/README_EN.md&#34;&gt;English&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://t.me/+Gs3SH2qAPeFhYmU9&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;amp;logo=telegram&amp;amp;logoColor=white&#34; alt=&#34;Telegram&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/NzYsmJSgCT&#34;&gt;&lt;img src=&#34;https://dcbadge.limes.pink/api/server/NzYsmJSgCT&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;一个功能强大的 Telegram 聊天记录搜索工具，支持向量搜索和语义匹配。基于 OpenAI 的语义向量技术，让你的 Telegram 消息检索更智能、更精准。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;欢迎 PR 贡献！&lt;/li&gt; &#xA; &lt;li&gt;由于项目处于快速迭代阶段，可能会出现数据库不兼容的情况，建议定期备份数据。&lt;/li&gt; &#xA; &lt;li&gt;获取 API key: &lt;a href=&#34;https://github.com/GramSearch/telegram-search/issues/111&#34;&gt;#111&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/0fa3ba2f-9a3d-4530-9ecd-3336a0f952ad&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;💖 赞助者&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/luoling8192/luoling8192/raw/master/sponsorkit/sponsors.svg?sanitize=true&#34; alt=&#34;Sponsors&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🚀 快速开始&lt;/h2&gt; &#xA;&lt;h3&gt;安装步骤&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;克隆仓库：&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/GramSearch/telegram-search.git&#xA;cd telegram-search&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;安装依赖：&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pnpm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;配置环境：&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp config/config.example.yaml config/config.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;启动数据库容器:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;同步数据库表结构：&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pnpm run db:migrate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;启动服务：&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 启动后端服务&#xA;pnpm run dev:server&#xA;&#xA;# 启动前端界面&#xA;pnpm run dev:frontend&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;访问 &lt;code&gt;http://localhost:3333&lt;/code&gt; 即可打开搜索界面。&lt;/p&gt; &#xA;&lt;h2&gt;🚀 Activity&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#luoling8192/telegram-search&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=luoling8192/telegram-search&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://repobeats.axiom.co/api/embed/c0fe5f057a33ce830a632c6ae421433f50e9083f.svg?sanitize=true&#34; alt=&#34;Alt&#34; title=&#34;Repobeats analytics image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;📝 License&lt;/h2&gt; &#xA;&lt;p&gt;MIT License © 2025&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/typescript-go</title>
    <updated>2025-05-26T01:29:06Z</updated>
    <id>tag:github.com,2025-05-26:/microsoft/typescript-go</id>
    <link href="https://github.com/microsoft/typescript-go" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Staging repo for development of native port of TypeScript&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TypeScript 7&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://devblogs.microsoft.com/typescript/typescript-native-port/&#34;&gt;Not sure what this is? Read the announcement post!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Preview&lt;/h2&gt; &#xA;&lt;p&gt;A preview build is available on npm as &lt;code&gt;@typescript/native-preview&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm install @typescript/native-preview&#xA;npx tsgo # Use this as you would tsc.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A preview VS Code extension is &lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=TypeScriptTeam.native-preview&#34;&gt;available on the VS Code marketplace&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To use this, set this in your VS Code settings:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;    &#34;typescript.experimental.useTsgo&#34;: true&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;How to Build and Run&lt;/h2&gt; &#xA;&lt;p&gt;This repo uses &lt;a href=&#34;https://go.dev/dl/&#34;&gt;Go 1.24 or higher&lt;/a&gt;, &lt;a href=&#34;https://www.rust-lang.org/tools/install&#34;&gt;Rust 1.85 or higher&lt;/a&gt;, &lt;a href=&#34;https://nodejs.org/&#34;&gt;Node.js with npm&lt;/a&gt;, and &lt;a href=&#34;https://www.npmjs.com/package/hereby&#34;&gt;&lt;code&gt;hereby&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For tests and code generation, this repo contains a git submodule to the main TypeScript repo pointing to the commit being ported. When cloning, you&#39;ll want to clone with submodules:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone --recurse-submodules https://github.com/microsoft/typescript-go.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you have already cloned the repo, you can initialize the submodule with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git submodule update --init --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;With the submodule in place and &lt;code&gt;npm ci&lt;/code&gt;, you can run tasks via &lt;code&gt;hereby&lt;/code&gt;, similar to the TypeScript repo:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;hereby build          # Verify that the project builds&#xA;hereby test           # Run all tests&#xA;hereby install-tools  # Install additional tools such as linters&#xA;hereby lint           # Run all linters&#xA;hereby format         # Format all code&#xA;hereby generate       # Generate all Go code (e.g. diagnostics, committed to repo)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Additional tasks are a work in progress.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;hereby&lt;/code&gt; is not required to work on the repo; the regular &lt;code&gt;go&lt;/code&gt; tooling (e.g., &lt;code&gt;go build&lt;/code&gt;, &lt;code&gt;go test ./...&lt;/code&gt;) will work as expected. &lt;code&gt;hereby&lt;/code&gt; tasks are provided as a convenience for those familiar with the TypeScript repo.&lt;/p&gt; &#xA;&lt;h3&gt;Running &lt;code&gt;tsgo&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;After running &lt;code&gt;hereby build&lt;/code&gt;, you can run &lt;code&gt;built/local/tsgo&lt;/code&gt;, which behaves mostly the same as &lt;code&gt;tsc&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Running LSP Prototype&lt;/h3&gt; &#xA;&lt;p&gt;To debug and run the VS Code extension without installing it globally:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run VS Code in the repo workspace (&lt;code&gt;code .&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Copy &lt;code&gt;.vscode/launch.template.json&lt;/code&gt; to &lt;code&gt;.vscode/launch.json&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;kbd&gt;F5&lt;/kbd&gt; (or &lt;code&gt;Debug: Start Debugging&lt;/code&gt; from the command palette)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This will launch a new VS Code instance which uses the Corsa LS as the backend. If correctly set up, you should see &#34;tsgo&#34; in the status bar when a TypeScript or JavaScript file is open:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/typescript-go/main/.github/ls-screenshot.png&#34; alt=&#34;LSP Prototype Screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What Works So Far?&lt;/h2&gt; &#xA;&lt;p&gt;This is still a work in progress and is not yet at full feature parity with TypeScript. Bugs may exist. Please check this list carefully before logging a new issue or assuming an intentional change.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Feature&lt;/th&gt; &#xA;   &lt;th&gt;Status&lt;/th&gt; &#xA;   &lt;th&gt;Notes&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Program creation&lt;/td&gt; &#xA;   &lt;td&gt;done&lt;/td&gt; &#xA;   &lt;td&gt;Same files and module resolution as TS5.8. Not all resolution modes supported yet.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Parsing/scanning&lt;/td&gt; &#xA;   &lt;td&gt;done&lt;/td&gt; &#xA;   &lt;td&gt;Exact same syntax errors as TS5.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Commandline and &lt;code&gt;tsconfig.json&lt;/code&gt; parsing&lt;/td&gt; &#xA;   &lt;td&gt;mostly done&lt;/td&gt; &#xA;   &lt;td&gt;Entry point slightly different for now&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Type resolution&lt;/td&gt; &#xA;   &lt;td&gt;done&lt;/td&gt; &#xA;   &lt;td&gt;Same types as TS5.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Type checking&lt;/td&gt; &#xA;   &lt;td&gt;done&lt;/td&gt; &#xA;   &lt;td&gt;Same errors, locations, and messages as TS5.8. Types printback in errors may display differently (in progress)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;JavaScript-specific inference and JS Doc&lt;/td&gt; &#xA;   &lt;td&gt;not ready&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;JSX&lt;/td&gt; &#xA;   &lt;td&gt;done&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Declaration emit&lt;/td&gt; &#xA;   &lt;td&gt;not ready&lt;/td&gt; &#xA;   &lt;td&gt;Coming soon&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Emit (JS output)&lt;/td&gt; &#xA;   &lt;td&gt;in progress&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;target: esnext&lt;/code&gt; well-supported, other targets may have gaps&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Watch mode&lt;/td&gt; &#xA;   &lt;td&gt;prototype&lt;/td&gt; &#xA;   &lt;td&gt;Watches files and rebuilds, but no incremental rechecking&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Build mode / project references&lt;/td&gt; &#xA;   &lt;td&gt;not ready&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Incremental build&lt;/td&gt; &#xA;   &lt;td&gt;not ready&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Language service (LSP)&lt;/td&gt; &#xA;   &lt;td&gt;prototype&lt;/td&gt; &#xA;   &lt;td&gt;Minimal functionality (errors, hover, go to def). More features coming soon&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;API&lt;/td&gt; &#xA;   &lt;td&gt;not ready&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Definitions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;done&lt;/strong&gt; aka &#34;believed done&#34;: We&#39;re not currently aware of any deficits or major left work to do. OK to log bugs&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;in progress&lt;/strong&gt;: currently being worked on; some features may work and some might not. OK to log panics, but nothing else please&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;prototype&lt;/strong&gt;: proof-of-concept only; do not log bugs&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;not ready&lt;/strong&gt;: either haven&#39;t even started yet, or far enough from ready that you shouldn&#39;t bother messing with it yet&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Other Notes&lt;/h2&gt; &#xA;&lt;p&gt;Long-term, we expect that this repo and its contents will be merged into &lt;code&gt;microsoft/TypeScript&lt;/code&gt;. As a result, the repo and issue tracker for typescript-go will eventually be closed, so treat discussions/issues accordingly.&lt;/p&gt; &#xA;&lt;p&gt;For a list of intentional changes with respect to TypeScript 5.7, see CHANGES.md.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&#34;https://cla.opensource.microsoft.com&#34;&gt;Contributor License Agreements&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h2&gt;Trademarks&lt;/h2&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt;</summary>
  </entry>
</feed>