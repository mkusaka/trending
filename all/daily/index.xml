<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-11-20T01:28:45Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>awslabs/multi-agent-orchestrator</title>
    <updated>2024-11-20T01:28:45Z</updated>
    <id>tag:github.com,2024-11-20:/awslabs/multi-agent-orchestrator</id>
    <link href="https://github.com/awslabs/multi-agent-orchestrator" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Flexible and powerful framework for managing multiple AI agents and handling complex conversations&lt;/p&gt;&lt;hr&gt;&lt;h2 align=&#34;center&#34;&gt;Multi-Agent Orchestrator&amp;nbsp;&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt;Flexible and powerful framework for managing multiple AI agents and handling complex conversations.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/awslabs/multi-agent-orchestrator&#34;&gt;&lt;img alt=&#34;GitHub Repo&#34; src=&#34;https://img.shields.io/badge/GitHub-Repo-green.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.npmjs.com/package/multi-agent-orchestrator&#34;&gt;&lt;img alt=&#34;npm&#34; src=&#34;https://img.shields.io/npm/v/multi-agent-orchestrator.svg?style=flat-square&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/multi-agent-orchestrator/&#34;&gt;&lt;img alt=&#34;PyPI&#34; src=&#34;https://img.shields.io/pypi/v/multi-agent-orchestrator.svg?style=flat-square&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://awslabs.github.io/multi-agent-orchestrator/&#34;&gt;&lt;img alt=&#34;Documentation&#34; src=&#34;https://img.shields.io/badge/docs-book-blue.svg?style=flat-square&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;üîñ Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üß† &lt;strong&gt;Intelligent intent classification&lt;/strong&gt; ‚Äî Dynamically route queries to the most suitable agent based on context and content.&lt;/li&gt; &#xA; &lt;li&gt;üî§ &lt;strong&gt;Dual language support&lt;/strong&gt; ‚Äî Fully implemented in both &lt;strong&gt;Python&lt;/strong&gt; and &lt;strong&gt;TypeScript&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;üåä &lt;strong&gt;Flexible agent responses&lt;/strong&gt; ‚Äî Support for both streaming and non-streaming responses from different agents.&lt;/li&gt; &#xA; &lt;li&gt;üìö &lt;strong&gt;Context management&lt;/strong&gt; ‚Äî Maintain and utilize conversation context across multiple agents for coherent interactions.&lt;/li&gt; &#xA; &lt;li&gt;üîß &lt;strong&gt;Extensible architecture&lt;/strong&gt; ‚Äî Easily integrate new agents or customize existing ones to fit your specific needs.&lt;/li&gt; &#xA; &lt;li&gt;üåê &lt;strong&gt;Universal deployment&lt;/strong&gt; ‚Äî Run anywhere - from AWS Lambda to your local environment or any cloud platform.&lt;/li&gt; &#xA; &lt;li&gt;üì¶ &lt;strong&gt;Pre-built agents and classifiers&lt;/strong&gt; ‚Äî A variety of ready-to-use agents and multiple classifier implementations available.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What&#39;s the Multi-Agent Orchestrator ‚ùì&lt;/h2&gt; &#xA;&lt;p&gt;The Multi-Agent Orchestrator is a flexible framework for managing multiple AI agents and handling complex conversations. It intelligently routes queries and maintains context across interactions.&lt;/p&gt; &#xA;&lt;p&gt;The system offers pre-built components for quick deployment, while also allowing easy integration of custom agents and conversation messages storage solutions.&lt;/p&gt; &#xA;&lt;p&gt;This adaptability makes it suitable for a wide range of applications, from simple chatbots to sophisticated AI systems, accommodating diverse requirements and scaling efficiently.&lt;/p&gt; &#xA;&lt;h2&gt;üèóÔ∏è High-level architecture flow diagram&lt;/h2&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/awslabs/multi-agent-orchestrator/main/img/flow.jpg&#34; alt=&#34;High-level architecture flow diagram&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The process begins with user input, which is analyzed by a Classifier.&lt;/li&gt; &#xA; &lt;li&gt;The Classifier leverages both Agents&#39; Characteristics and Agents&#39; Conversation history to select the most appropriate agent for the task.&lt;/li&gt; &#xA; &lt;li&gt;Once an agent is selected, it processes the user input.&lt;/li&gt; &#xA; &lt;li&gt;The orchestrator then saves the conversation, updating the Agents&#39; Conversation history, before delivering the response back to the user.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;üí¨ Demo App&lt;/h2&gt; &#xA;&lt;p&gt;To quickly get a feel for the Multi-Agent Orchestrator, we&#39;ve provided a Demo App with a few basic agents. This interactive demo showcases the orchestrator&#39;s capabilities in a user-friendly interface. To learn more about setting up and running the demo app, please refer to our &lt;a href=&#34;https://awslabs.github.io/multi-agent-orchestrator/cookbook/examples/chat-demo-app/&#34;&gt;Demo App&lt;/a&gt; section.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;In the screen recording below, we demonstrate an extended version of the demo app that uses 6 specialized agents:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Travel Agent&lt;/strong&gt;: Powered by an Amazon Lex Bot&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Weather Agent&lt;/strong&gt;: Utilizes a Bedrock LLM Agent with a tool to query the open-meteo API&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Restaurant Agent&lt;/strong&gt;: Implemented as an Amazon Bedrock Agent&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Math Agent&lt;/strong&gt;: Utilizes a Bedrock LLM Agent with two tools for executing mathematical operations&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Tech Agent&lt;/strong&gt;: A Bedrock LLM Agent designed to answer questions on technical topics&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Health Agent&lt;/strong&gt;: A Bedrock LLM Agent focused on addressing health-related queries&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Watch as the system seamlessly switches context between diverse topics, from booking flights to checking weather, solving math problems, and providing health information. Notice how the appropriate agent is selected for each query, maintaining coherence even with brief follow-up inputs.&lt;/p&gt; &#xA;&lt;p&gt;The demo highlights the system&#39;s ability to handle complex, multi-turn conversations while preserving context and leveraging specialized agents across various domains.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/awslabs/multi-agent-orchestrator/main/img/demo-app.gif?raw=true&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;To quickly get a feel for the Multi-Agent Orchestrator, check out our &lt;a href=&#34;https://awslabs.github.io/multi-agent-orchestrator/cookbook/examples/chat-demo-app/&#34;&gt;Demo App&lt;/a&gt;. Additional code examples are available in both the documentation and the &lt;code&gt;examples&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;h2&gt;üéØ Examples &amp;amp; Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;Get hands-on experience with the Multi-Agent Orchestrator through our diverse set of examples:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Ready-to-run Scripts&lt;/strong&gt;: Start locally with our collection of standalone scripts in both Python and TypeScript.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Demo Applications&lt;/strong&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://awslabs.github.io/multi-agent-orchestrator/cookbook/examples/chat-demo-app/&#34;&gt;Chat Demo App&lt;/a&gt;: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Explore multiple specialized agents handling various domains like travel, weather, math, and health&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://awslabs.github.io/multi-agent-orchestrator/cookbook/examples/ecommerce-support-simulator/&#34;&gt;E-commerce Support Simulator&lt;/a&gt;: Experience AI-powered customer support with: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Automated response generation for common queries&lt;/li&gt; &#xA;     &lt;li&gt;Intelligent routing of complex issues to human support&lt;/li&gt; &#xA;     &lt;li&gt;Real-time chat and email-style communication&lt;/li&gt; &#xA;     &lt;li&gt;Human-in-the-loop interactions for complex cases&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Sample Projects&lt;/strong&gt;: Explore our example implementations in the &lt;code&gt;examples&lt;/code&gt; folder: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/multi-agent-orchestrator/tree/main/examples/chat-demo-app&#34;&gt;&lt;code&gt;chat-demo-app&lt;/code&gt;&lt;/a&gt;: Web-based chat interface with multiple specialized agents&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/multi-agent-orchestrator/tree/main/examples/ecommerce-support-simulator&#34;&gt;&lt;code&gt;ecommerce-support-simulator&lt;/code&gt;&lt;/a&gt;: AI-powered customer support system&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/multi-agent-orchestrator/tree/main/examples/chat-chainlit-app&#34;&gt;&lt;code&gt;chat-chainlit-app&lt;/code&gt;&lt;/a&gt;: Chat application built with Chainlit&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/multi-agent-orchestrator/tree/main/examples/fast-api-streaming&#34;&gt;&lt;code&gt;fast-api-streaming&lt;/code&gt;&lt;/a&gt;: FastAPI implementation with streaming support&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/awslabs/multi-agent-orchestrator/tree/main/examples/text-2-structured-output&#34;&gt;&lt;code&gt;text-2-structured-output&lt;/code&gt;&lt;/a&gt;: Natural Language to Structured Data&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All examples are available in both Python and TypeScript implementations. Check out our &lt;a href=&#34;https://awslabs.github.io/multi-agent-orchestrator/&#34;&gt;documentation&lt;/a&gt; for comprehensive guides on setting up and using the Multi-Agent Orchestrator!&lt;/p&gt; &#xA;&lt;h2&gt;üåü Use cases and implementations&lt;/h2&gt; &#xA;&lt;p&gt;Discover creative implementations and diverse applications of the Multi-Agent Orchestrator:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://community.aws/content/2lCi8jEKydhDm8eE8QFIQ5K23pF/from-bonjour-to-boarding-pass-multilingual-ai-chatbot-for-flight-reservations&#34;&gt;From &#39;Bonjour&#39; to &#39;Boarding Pass&#39;: Multilingual AI Chatbot for Flight Reservations&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This article demonstrates how to build a multilingual chatbot using the Multi-Agent Orchestrator framework. The article explains how to use an &lt;strong&gt;Amazon Lex&lt;/strong&gt; bot as an agent, along with 2 other new agents to make it work in many languages with just a few lines of code.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://community.aws/content/2lq6cYYwTYGc7S3Zmz28xZoQNQj/beyond-auto-replies-building-an-ai-powered-e-commerce-support-system&#34;&gt;Beyond Auto-Replies: Building an AI-Powered E-commerce Support system&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This article demonstrates how to build an AI-driven multi-agent system for automated e-commerce customer email support. It covers the architecture and setup of specialized AI agents using the Multi-Agent Orchestrator framework, integrating automated processing with human-in-the-loop oversight. The guide explores email ingestion, intelligent routing, automated response generation, and human verification, providing a comprehensive approach to balancing AI efficiency with human expertise in customer support.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://community.aws/content/2mt7CFG7xg4yw6GRHwH9akhg0oD/speak-up-ai-voicing-your-agents-with-amazon-connect-lex-and-bedrock&#34;&gt;Speak Up, AI: Voicing Your Agents with Amazon Connect, Lex, and Bedrock&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This article demonstrates how to build an AI customer call center. It covers the architecture and setup of specialiazed AI agents using the Multi-Agent Orchestrator framework interacting with voice via &lt;strong&gt;Amazon Connect&lt;/strong&gt; and &lt;strong&gt;Amazon Lex&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;TypeScript Version&lt;/h3&gt; &#xA;&lt;h4&gt;Installation&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install multi-agent-orchestrator&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Usage&lt;/h4&gt; &#xA;&lt;p&gt;The following example demonstrates how to use the Multi-Agent Orchestrator with two different types of agents: a Bedrock LLM Agent with Converse API support and a Lex Bot Agent. This showcases the flexibility of the system in integrating various AI services.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import { MultiAgentOrchestrator, BedrockLLMAgent, LexBotAgent } from &#34;multi-agent-orchestrator&#34;;&#xA;&#xA;const orchestrator = new MultiAgentOrchestrator();&#xA;&#xA;// Add a Bedrock LLM Agent with Converse API support&#xA;orchestrator.addAgent(&#xA;  new BedrockLLMAgent({&#xA;      name: &#34;Tech Agent&#34;,&#xA;      description:&#xA;        &#34;Specializes in technology areas including software development, hardware, AI, cybersecurity, blockchain, cloud computing, emerging tech innovations, and pricing/costs related to technology products and services.&#34;,&#xA;      streaming: true&#xA;  })&#xA;);&#xA;&#xA;// Add a Lex Bot Agent for handling travel-related queries&#xA;orchestrator.addAgent(&#xA;  new LexBotAgent({&#xA;    name: &#34;Travel Agent&#34;,&#xA;    description: &#34;Helps users book and manage their flight reservations&#34;,&#xA;    botId: process.env.LEX_BOT_ID,&#xA;    botAliasId: process.env.LEX_BOT_ALIAS_ID,&#xA;    localeId: &#34;en_US&#34;,&#xA;  })&#xA;);&#xA;&#xA;// Example usage&#xA;const response = await orchestrator.routeRequest(&#xA;  &#34;I want to book a flight&#34;,&#xA;  &#39;user123&#39;,&#xA;  &#39;session456&#39;&#xA;);&#xA;&#xA;// Handle the response (streaming or non-streaming)&#xA;if (response.streaming == true) {&#xA;    console.log(&#34;\n** RESPONSE STREAMING ** \n&#34;);&#xA;    // Send metadata immediately&#xA;    console.log(`&amp;gt; Agent ID: ${response.metadata.agentId}`);&#xA;    console.log(`&amp;gt; Agent Name: ${response.metadata.agentName}`);&#xA;    console.log(`&amp;gt; User Input: ${response.metadata.userInput}`);&#xA;    console.log(`&amp;gt; User ID: ${response.metadata.userId}`);&#xA;    console.log(`&amp;gt; Session ID: ${response.metadata.sessionId}`);&#xA;    console.log(&#xA;      `&amp;gt; Additional Parameters:`,&#xA;      response.metadata.additionalParams&#xA;    );&#xA;    console.log(`\n&amp;gt; Response: `);&#xA;&#xA;    // Stream the content&#xA;    for await (const chunk of response.output) {&#xA;      if (typeof chunk === &#34;string&#34;) {&#xA;        process.stdout.write(chunk);&#xA;      } else {&#xA;        console.error(&#34;Received unexpected chunk type:&#34;, typeof chunk);&#xA;      }&#xA;    }&#xA;&#xA;} else {&#xA;    // Handle non-streaming response (AgentProcessingResult)&#xA;    console.log(&#34;\n** RESPONSE ** \n&#34;);&#xA;    console.log(`&amp;gt; Agent ID: ${response.metadata.agentId}`);&#xA;    console.log(`&amp;gt; Agent Name: ${response.metadata.agentName}`);&#xA;    console.log(`&amp;gt; User Input: ${response.metadata.userInput}`);&#xA;    console.log(`&amp;gt; User ID: ${response.metadata.userId}`);&#xA;    console.log(`&amp;gt; Session ID: ${response.metadata.sessionId}`);&#xA;    console.log(&#xA;      `&amp;gt; Additional Parameters:`,&#xA;      response.metadata.additionalParams&#xA;    );&#xA;    console.log(`\n&amp;gt; Response: ${response.output}`);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Python Version&lt;/h3&gt; &#xA;&lt;h4&gt;Installation&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Optional: Set up a virtual environment&#xA;python -m venv venv&#xA;source venv/bin/activate  # On Windows use `venv\Scripts\activate`&#xA;pip install multi-agent-orchestrator&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Usage&lt;/h4&gt; &#xA;&lt;p&gt;Here&#39;s an equivalent Python example demonstrating the use of the Multi-Agent Orchestrator with a Bedrock LLM Agent and a Lex Bot Agent:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os&#xA;import asyncio&#xA;from multi_agent_orchestrator.orchestrator import MultiAgentOrchestrator&#xA;from multi_agent_orchestrator.agents import BedrockLLMAgent, LexBotAgent, BedrockLLMAgentOptions, LexBotAgentOptions, AgentCallbacks&#xA;&#xA;orchestrator = MultiAgentOrchestrator()&#xA;&#xA;class BedrockLLMAgentCallbacks(AgentCallbacks):&#xA;    def on_llm_new_token(self, token: str) -&amp;gt; None:&#xA;        # handle response streaming here&#xA;        print(token, end=&#39;&#39;, flush=True)&#xA;&#xA;tech_agent = BedrockLLMAgent(BedrockLLMAgentOptions(&#xA;  name=&#34;Tech Agent&#34;,&#xA;  streaming=True,&#xA;  description=&#34;Specializes in technology areas including software development, hardware, AI, \&#xA;  cybersecurity, blockchain, cloud computing, emerging tech innovations, and pricing/costs \&#xA;  related to technology products and services.&#34;,&#xA;  model_id=&#34;anthropic.claude-3-sonnet-20240229-v1:0&#34;,&#xA;  callbacks=BedrockLLMAgentCallbacks()&#xA;))&#xA;orchestrator.add_agent(tech_agent)&#xA;&#xA;&#xA;# Add a Lex Bot Agent for handling travel-related queries&#xA;orchestrator.add_agent(&#xA;    LexBotAgent(LexBotAgentOptions(&#xA;        name=&#34;Travel Agent&#34;,&#xA;        description=&#34;Helps users book and manage their flight reservations&#34;,&#xA;        bot_id=os.environ.get(&#39;LEX_BOT_ID&#39;),&#xA;        bot_alias_id=os.environ.get(&#39;LEX_BOT_ALIAS_ID&#39;),&#xA;        locale_id=&#34;en_US&#34;,&#xA;    ))&#xA;)&#xA;&#xA;async def main():&#xA;    # Example usage&#xA;    response = await orchestrator.route_request(&#xA;        &#34;I want to book a flight&#34;,&#xA;        &#39;user123&#39;,&#xA;        &#39;session456&#39;&#xA;    )&#xA;&#xA;    # Handle the response (streaming or non-streaming)&#xA;    if response.streaming:&#xA;        print(&#34;\n** RESPONSE STREAMING ** \n&#34;)&#xA;        # Send metadata immediately&#xA;        print(f&#34;&amp;gt; Agent ID: {response.metadata.agent_id}&#34;)&#xA;        print(f&#34;&amp;gt; Agent Name: {response.metadata.agent_name}&#34;)&#xA;        print(f&#34;&amp;gt; User Input: {response.metadata.user_input}&#34;)&#xA;        print(f&#34;&amp;gt; User ID: {response.metadata.user_id}&#34;)&#xA;        print(f&#34;&amp;gt; Session ID: {response.metadata.session_id}&#34;)&#xA;        print(f&#34;&amp;gt; Additional Parameters: {response.metadata.additional_params}&#34;)&#xA;        print(&#34;\n&amp;gt; Response: &#34;)&#xA;&#xA;        # Stream the content&#xA;        async for chunk in response.output:&#xA;            if isinstance(chunk, str):&#xA;                print(chunk, end=&#39;&#39;, flush=True)&#xA;            else:&#xA;                print(f&#34;Received unexpected chunk type: {type(chunk)}&#34;, file=sys.stderr)&#xA;&#xA;    else:&#xA;        # Handle non-streaming response (AgentProcessingResult)&#xA;        print(&#34;\n** RESPONSE ** \n&#34;)&#xA;        print(f&#34;&amp;gt; Agent ID: {response.metadata.agent_id}&#34;)&#xA;        print(f&#34;&amp;gt; Agent Name: {response.metadata.agent_name}&#34;)&#xA;        print(f&#34;&amp;gt; User Input: {response.metadata.user_input}&#34;)&#xA;        print(f&#34;&amp;gt; User ID: {response.metadata.user_id}&#34;)&#xA;        print(f&#34;&amp;gt; Session ID: {response.metadata.session_id}&#34;)&#xA;        print(f&#34;&amp;gt; Additional Parameters: {response.metadata.additional_params}&#34;)&#xA;        print(f&#34;\n&amp;gt; Response: {response.output.content}&#34;)&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(main())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;These examples showcase:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The use of a Bedrock LLM Agent with Converse API support, allowing for multi-turn conversations.&lt;/li&gt; &#xA; &lt;li&gt;Integration of a Lex Bot Agent for specialized tasks (in this case, travel-related queries).&lt;/li&gt; &#xA; &lt;li&gt;The orchestrator&#39;s ability to route requests to the most appropriate agent based on the input.&lt;/li&gt; &#xA; &lt;li&gt;Handling of both streaming and non-streaming responses from different types of agents.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions! Please see our &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/multi-agent-orchestrator/main/CONTRIBUTING.md&#34;&gt;Contributing Guide&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h1&gt;Authors&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/corneliucroitoru/&#34;&gt;Corneliu Croitoru&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/anthonybernabeu/&#34;&gt;Anthony Bernabeu&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Contributors&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/multi-agent-orchestrator/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=awslabs/multi-agent-orchestrator&amp;amp;max=2000&#34; alt=&#34;contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üìÑ LICENSE&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the Apache 2.0 licence - see the &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/multi-agent-orchestrator/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; &#xA;&lt;h2&gt;üìÑ Font License&lt;/h2&gt; &#xA;&lt;p&gt;This project uses the JetBrainsMono NF font, licensed under the SIL Open Font License 1.1. For full license details, see &lt;a href=&#34;https://github.com/JetBrains/JetBrainsMono/raw/master/OFL.txt&#34;&gt;FONT-LICENSE.md&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>arkohut/pensieve</title>
    <updated>2024-11-20T01:28:45Z</updated>
    <id>tag:github.com,2024-11-20:/arkohut/pensieve</id>
    <link href="https://github.com/arkohut/pensieve" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A passive recording project allows you to have complete control over your data. ‰∏Ä‰∏™ÂÆåÂÖ®Áî±‰Ω†ÊéåÊéßÊï∞ÊçÆÁöÑ„ÄåË¢´Âä®ËÆ∞ÂΩï„ÄçÈ°πÁõÆ„ÄÇ&lt;/p&gt;&lt;hr&gt;&lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/arkohut/pensieve/master/README_ZH.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/arkohut/pensieve/master/docs/images/memos-search-en.gif&#34; alt=&#34;memos-search&#34;&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;I changed the name to Pensieve because Memos was already taken.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;Pensieve (previously named Memos)&lt;/h1&gt; &#xA;&lt;p&gt;Pensieve is a privacy-focused passive recording project. It can automatically record screen content, build intelligent indices, and provide a convenient web interface to retrieve historical records.&lt;/p&gt; &#xA;&lt;p&gt;This project draws heavily from two other projects: one called &lt;a href=&#34;https://www.rewind.ai/&#34;&gt;Rewind&lt;/a&gt; and another called &lt;a href=&#34;https://support.microsoft.com/en-us/windows/retrace-your-steps-with-recall-aa03f8a0-a78b-4b3e-b0a1-2eb8ac48701c&#34;&gt;Windows Recall&lt;/a&gt;. However, unlike both of them, Pensieve allows you to have complete control over your data, avoiding the transfer of data to untrusted data centers.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üöÄ Simple installation: just install dependencies via pip to get started&lt;/li&gt; &#xA; &lt;li&gt;üîí Complete data control: all data is stored locally, allowing for full local operation and self-managed data processing&lt;/li&gt; &#xA; &lt;li&gt;üîç Full-text and vector search support&lt;/li&gt; &#xA; &lt;li&gt;ü§ñ Integrates with Ollama, using it as the machine learning engine for Pensieve&lt;/li&gt; &#xA; &lt;li&gt;üåê Compatible with any OpenAI API models (e.g., OpenAI, Azure OpenAI, vLLM, etc.)&lt;/li&gt; &#xA; &lt;li&gt;üíª Supports Mac and Windows (Linux support is in development)&lt;/li&gt; &#xA; &lt;li&gt;üîå Extensible functionality through plugins&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/arkohut/pensieve/master/docs/images/memos-installation.gif&#34; alt=&#34;memos-installation&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;1. Install Pensieve&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install memos&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Initialize&lt;/h3&gt; &#xA;&lt;p&gt;Initialize the pensieve configuration file and sqlite database:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;memos init&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Data will be stored in the &lt;code&gt;~/.memos&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;h3&gt;3. Start the Service&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;memos enable&#xA;memos start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command will:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Begin recording all screens&lt;/li&gt; &#xA; &lt;li&gt;Start the Web service&lt;/li&gt; &#xA; &lt;li&gt;Set the service to start on boot&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;4. Access the Web Interface&lt;/h3&gt; &#xA;&lt;p&gt;Open your browser and visit &lt;code&gt;http://localhost:8839&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/arkohut/pensieve/master/docs/images/init-page-en.png&#34; alt=&#34;init page&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Mac Permission Issues&lt;/h3&gt; &#xA;&lt;p&gt;On Mac, Pensieve needs screen recording permission. When the program starts, Mac will prompt for screen recording permission - please allow it to proceed.&lt;/p&gt; &#xA;&lt;h2&gt;User Guide&lt;/h2&gt; &#xA;&lt;h3&gt;Using the Appropriate Embedding Model&lt;/h3&gt; &#xA;&lt;h4&gt;1. Model Selection&lt;/h4&gt; &#xA;&lt;p&gt;Pensieve uses embedding models to extract semantic information and build vector indices. Therefore, choosing an appropriate embedding model is crucial. Depending on the user&#39;s primary language, different embedding models should be selected.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For Chinese scenarios, you can use the &lt;a href=&#34;https://huggingface.co/jinaai/jina-embeddings-v2-base-zh&#34;&gt;jinaai/jina-embeddings-v2-base-zh&lt;/a&gt; model.&lt;/li&gt; &#xA; &lt;li&gt;For English scenarios, you can use the &lt;a href=&#34;https://huggingface.co/jinaai/jina-embeddings-v2-base-en&#34;&gt;jinaai/jina-embeddings-v2-base-en&lt;/a&gt; model.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;2. Adjust Memos Configuration&lt;/h4&gt; &#xA;&lt;p&gt;Open the &lt;code&gt;~/.memos/config.yaml&lt;/code&gt; file with your preferred text editor and modify the &lt;code&gt;embedding&lt;/code&gt; configuration:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;embedding:&#xA;  use_local: true&#xA;  model: jinaai/jina-embeddings-v2-base-en   # Model name used&#xA;  num_dim: 768                               # Model dimensions&#xA;  use_modelscope: false                      # Whether to use ModelScope&#39;s model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;3. Restart Memos Service&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;memos stop&#xA;memos start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The first time you use the embedding model, Pensieve will automatically download and load the model.&lt;/p&gt; &#xA;&lt;h4&gt;4. Rebuild Index&lt;/h4&gt; &#xA;&lt;p&gt;If you switch the embedding model during use, meaning you have already indexed screenshots before, you need to rebuild the index:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;memos reindex --force&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;--force&lt;/code&gt; parameter indicates rebuilding the index table and deleting previously indexed screenshot data.&lt;/p&gt; &#xA;&lt;h3&gt;Using Ollama for Visual Search&lt;/h3&gt; &#xA;&lt;p&gt;By default, Pensieve only enables the OCR plugin to extract text from screenshots and build indices. However, this method significantly limits search effectiveness for images without text.&lt;/p&gt; &#xA;&lt;p&gt;To achieve more comprehensive visual search capabilities, we need a multimodal image understanding service compatible with the OpenAI API. Ollama perfectly fits this role.&lt;/p&gt; &#xA;&lt;h4&gt;Important Notes Before Use&lt;/h4&gt; &#xA;&lt;p&gt;Before deciding to enable the VLM feature, please note the following:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hardware Requirements&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Recommended configuration: NVIDIA graphics card with at least 8GB VRAM or Mac with M series chip&lt;/li&gt; &#xA;   &lt;li&gt;The minicpm-v model will occupy about 5.5GB of storage space&lt;/li&gt; &#xA;   &lt;li&gt;CPU mode is not recommended as it will cause severe system lag&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Performance and Power Consumption Impact&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Enabling VLM will significantly increase system power consumption&lt;/li&gt; &#xA;   &lt;li&gt;Consider using other devices to provide OpenAI API compatible model services&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;1. Install Ollama&lt;/h4&gt; &#xA;&lt;p&gt;Visit the &lt;a href=&#34;https://ollama.com&#34;&gt;Ollama official documentation&lt;/a&gt; for detailed installation and configuration instructions.&lt;/p&gt; &#xA;&lt;h4&gt;2. Prepare the Multimodal Model&lt;/h4&gt; &#xA;&lt;p&gt;Download and run the multimodal model &lt;code&gt;minicpm-v&lt;/code&gt; using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;ollama run minicpm-v &#34;Describe what this service is&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command will download and run the minicpm-v model. If the running speed is too slow, it is not recommended to use this feature.&lt;/p&gt; &#xA;&lt;h4&gt;3. Configure Pensieve to Use Ollama&lt;/h4&gt; &#xA;&lt;p&gt;Open the &lt;code&gt;~/.memos/config.yaml&lt;/code&gt; file with your preferred text editor and modify the &lt;code&gt;vlm&lt;/code&gt; configuration:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;vlm:&#xA;  endpoint: http://localhost:11434  # Ollama service address&#xA;  modelname: minicpm-v              # Model name to use&#xA;  force_jpeg: true                  # Convert images to JPEG format to ensure compatibility&#xA;  prompt: Please describe the content of this image, including the layout and visual elements  # Prompt sent to the model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Use the above configuration to overwrite the &lt;code&gt;vlm&lt;/code&gt; configuration in the &lt;code&gt;~/.memos/config.yaml&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;p&gt;Also, modify the &lt;code&gt;default_plugins&lt;/code&gt; configuration in the &lt;code&gt;~/.memos/plugins/vlm/config.yaml&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;default_plugins:&#xA;- builtin_ocr&#xA;- builtin_vlm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This adds the &lt;code&gt;builtin_vlm&lt;/code&gt; plugin to the default plugin list.&lt;/p&gt; &#xA;&lt;h4&gt;4. Restart Pensieve Service&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;memos stop&#xA;memos start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After restarting the Pensieve service, wait a moment to see the data extracted by VLM in the latest screenshots on the Pensieve web interface:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/arkohut/pensieve/master/docs/images/single-screenshot-view-with-minicpm-result.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you do not see the VLM results, you can:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Use the command &lt;code&gt;memos ps&lt;/code&gt; to check if the Pensieve process is running normally&lt;/li&gt; &#xA; &lt;li&gt;Check for error messages in &lt;code&gt;~/.memos/logs/memos.log&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Confirm whether the Ollama model is loaded correctly (&lt;code&gt;ollama ps&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Full Indexing&lt;/h3&gt; &#xA;&lt;p&gt;Pensieve is a compute-intensive application. The indexing process requires the collaboration of OCR, VLM, and embedding models. To minimize the impact on the user&#39;s computer, Pensieve calculates the average processing time for each screenshot and adjusts the indexing frequency accordingly. Therefore, not all screenshots are indexed immediately by default.&lt;/p&gt; &#xA;&lt;p&gt;If you want to index all screenshots, you can use the following command for full indexing:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;memos scan&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command will scan and index all recorded screenshots. Note that depending on the number of screenshots and system configuration, this process may take some time and consume significant system resources. The index construction is idempotent, and running this command multiple times will not re-index already indexed data.&lt;/p&gt; &#xA;&lt;h2&gt;Privacy and Security&lt;/h2&gt; &#xA;&lt;p&gt;During the development of Pensieve, I closely followed the progress of similar products, especially &lt;a href=&#34;https://www.rewind.ai/&#34;&gt;Rewind&lt;/a&gt; and &lt;a href=&#34;https://support.microsoft.com/en-us/windows/retrace-your-steps-with-recall-aa03f8a0-a78b-4b3e-b0a1-2eb8ac48701c&#34;&gt;Windows Recall&lt;/a&gt;. I greatly appreciate their product philosophy, but they do not do enough in terms of privacy protection, which is a concern for many users (or potential users). Recording the screen of a personal computer may expose extremely sensitive private data, such as bank accounts, passwords, chat records, etc. Therefore, ensuring that data storage and processing are completely controlled by the user to prevent data leakage is particularly important.&lt;/p&gt; &#xA;&lt;p&gt;The advantages of Pensieve are:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The code is completely open-source and easy-to-understand Python code, allowing anyone to review the code to ensure there are no backdoors.&lt;/li&gt; &#xA; &lt;li&gt;Data is completely localized, all data is stored locally, and data processing is entirely controlled by the user. Data will be stored in the user&#39;s &lt;code&gt;~/.memos&lt;/code&gt; directory.&lt;/li&gt; &#xA; &lt;li&gt;Easy to uninstall. If you no longer use Pensieve, you can close the program with &lt;code&gt;memos stop &amp;amp;&amp;amp; memos disable&lt;/code&gt;, then uninstall it with &lt;code&gt;pip uninstall memos&lt;/code&gt;, and finally delete the &lt;code&gt;~/.memos&lt;/code&gt; directory to clean up all databases and screenshot data.&lt;/li&gt; &#xA; &lt;li&gt;Data processing is entirely controlled by the user. Pensieve is an independent project, and the machine learning models used (including VLM and embedding models) are chosen by the user. Due to Pensieve&#39; operating mode, using smaller models can also achieve good results.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Of course, there is still room for improvement in terms of privacy, and contributions are welcome to make Pensieve better.&lt;/p&gt; &#xA;&lt;h2&gt;Other Noteworthy Content&lt;/h2&gt; &#xA;&lt;h3&gt;About Storage Space&lt;/h3&gt; &#xA;&lt;p&gt;Pensieve records the screen every 5 seconds and saves the original screenshots in the &lt;code&gt;~/.memos/screenshots&lt;/code&gt; directory. Storage space usage mainly depends on the following factors:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Screenshot Data&lt;/strong&gt;:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Single screenshot size: about 40-400KB (depending on screen resolution and display complexity)&lt;/li&gt; &#xA;   &lt;li&gt;Daily data volume: about 400MB (based on 10 hours of usage, single screen 2560x1440 resolution)&lt;/li&gt; &#xA;   &lt;li&gt;Multi-screen usage: data volume increases with the number of screens&lt;/li&gt; &#xA;   &lt;li&gt;Monthly estimate: about 8GB based on 20 working days&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;Screenshots are deduplicated. If the content of consecutive screenshots does not change much, only one screenshot will be retained. The deduplication mechanism can significantly reduce storage usage in scenarios where content does not change frequently (such as reading, document editing, etc.).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Database Space&lt;/strong&gt;:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;SQLite database size depends on the number of indexed screenshots&lt;/li&gt; &#xA;   &lt;li&gt;Reference value: about 2.2GB of storage space after indexing 100,000 screenshots&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;About Power Consumption&lt;/h3&gt; &#xA;&lt;p&gt;Pensieve requires two compute-intensive tasks by default:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;One is the OCR task, used to extract text from screenshots&lt;/li&gt; &#xA; &lt;li&gt;The other is the embedding task, used to extract semantic information and build vector indices&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Resource Usage&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;OCR Task&lt;/strong&gt;: Executed using the CPU, and optimized to select the OCR engine based on different operating systems to minimize CPU usage&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Embedding Task&lt;/strong&gt;: Intelligently selects the computing device&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;NVIDIA GPU devices prioritize using the GPU&lt;/li&gt; &#xA;   &lt;li&gt;Mac devices prioritize using Metal GPU&lt;/li&gt; &#xA;   &lt;li&gt;Other devices use the CPU&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Performance Optimization Strategy&lt;/h4&gt; &#xA;&lt;p&gt;To avoid affecting users&#39; daily use, Pensieve has adopted the following optimization measures:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Dynamically adjust the indexing frequency, adapting to system processing speed&lt;/li&gt; &#xA; &lt;li&gt;Automatically reduce processing frequency when on battery power to save power&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Development Guide&lt;/h2&gt; &#xA;&lt;h3&gt;Peeling the First Layer of the Onion&lt;/h3&gt; &#xA;&lt;p&gt;In fact, after Pensieve starts, it runs three programs:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;memos serve&lt;/code&gt; starts the web service&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;memos record&lt;/code&gt; starts the screenshot recording program&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;memos watch&lt;/code&gt; listens to the image events generated by &lt;code&gt;memos record&lt;/code&gt; and dynamically submits indexing requests to the server based on actual processing speed&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Therefore, if you are a developer or want to see the logs of the entire project running more clearly, you can use these three commands to run each part in the foreground instead of the &lt;code&gt;memos enable &amp;amp;&amp;amp; memos start&lt;/code&gt; command.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>projectdiscovery/katana</title>
    <updated>2024-11-20T01:28:45Z</updated>
    <id>tag:github.com,2024-11-20:/projectdiscovery/katana</id>
    <link href="https://github.com/projectdiscovery/katana" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A next-generation crawling and spidering framework.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/8293321/196779266-421c79d4-643a-4f73-9b54-3da379bbac09.png&#34; alt=&#34;katana&#34; width=&#34;200px&#34;&gt; &lt;br&gt; &lt;/h1&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt;A next-generation crawling and spidering framework&lt;/h4&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://goreportcard.com/report/github.com/projectdiscovery/katana&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/projectdiscovery/katana&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/projectdiscovery/katana/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/projectdiscovery/katana/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/release/projectdiscovery/katana&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/pdiscoveryio&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/pdiscoveryio.svg?logo=twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/projectdiscovery&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/695645237418131507.svg?logo=discord&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/projectdiscovery/katana/main/#features&#34;&gt;Features&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/projectdiscovery/katana/main/#installation&#34;&gt;Installation&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/projectdiscovery/katana/main/#usage&#34;&gt;Usage&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/projectdiscovery/katana/main/#scope-control&#34;&gt;Scope&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/projectdiscovery/katana/main/#crawler-configuration&#34;&gt;Config&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://raw.githubusercontent.com/projectdiscovery/katana/main/#filters&#34;&gt;Filters&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://discord.gg/projectdiscovery&#34;&gt;Join Discord&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h1&gt;Features&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/8293321/199371558-daba03b6-bf9c-4883-8506-76497c6c3a44.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fast And fully configurable web crawling&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Standard&lt;/strong&gt; and &lt;strong&gt;Headless&lt;/strong&gt; mode&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;JavaScript&lt;/strong&gt; parsing / crawling&lt;/li&gt; &#xA; &lt;li&gt;Customizable &lt;strong&gt;automatic form filling&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Scope control&lt;/strong&gt; - Preconfigured field / Regex&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Customizable output&lt;/strong&gt; - Preconfigured fields&lt;/li&gt; &#xA; &lt;li&gt;INPUT - &lt;strong&gt;STDIN&lt;/strong&gt;, &lt;strong&gt;URL&lt;/strong&gt; and &lt;strong&gt;LIST&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;OUTPUT - &lt;strong&gt;STDOUT&lt;/strong&gt;, &lt;strong&gt;FILE&lt;/strong&gt; and &lt;strong&gt;JSON&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;katana requires &lt;strong&gt;Go 1.18&lt;/strong&gt; to install successfully. To install, just run the below command or download pre-compiled binary from &lt;a href=&#34;https://github.com/projectdiscovery/katana/releases&#34;&gt;release page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;CGO_ENABLED=1 go install github.com/projectdiscovery/katana/cmd/katana@latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;More options to install / run katana-&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Docker&lt;/summary&gt; &#xA; &lt;blockquote&gt; &#xA;  &lt;p&gt;To install / update docker to latest tag -&lt;/p&gt; &#xA; &lt;/blockquote&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker pull projectdiscovery/katana:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;blockquote&gt; &#xA;  &lt;p&gt;To run katana in standard mode using docker -&lt;/p&gt; &#xA; &lt;/blockquote&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run projectdiscovery/katana:latest -u https://tesla.com&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;blockquote&gt; &#xA;  &lt;p&gt;To run katana in headless mode using docker -&lt;/p&gt; &#xA; &lt;/blockquote&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run projectdiscovery/katana:latest -u https://tesla.com -system-chrome -headless&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Ubuntu&lt;/summary&gt; &#xA; &lt;blockquote&gt; &#xA;  &lt;p&gt;It&#39;s recommended to install the following prerequisites -&lt;/p&gt; &#xA; &lt;/blockquote&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo apt update&#xA;sudo snap refresh&#xA;sudo apt install zip curl wget git&#xA;sudo snap install golang --classic&#xA;wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add - &#xA;sudo sh -c &#39;echo &#34;deb http://dl.google.com/linux/chrome/deb/ stable main&#34; &amp;gt;&amp;gt; /etc/apt/sources.list.d/google.list&#39;&#xA;sudo apt update &#xA;sudo apt install google-chrome-stable&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;blockquote&gt; &#xA;  &lt;p&gt;install katana -&lt;/p&gt; &#xA; &lt;/blockquote&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go install github.com/projectdiscovery/katana/cmd/katana@latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -h&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will display help for the tool. Here are all the switches it supports.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;Katana is a fast crawler focused on execution in automation&#xA;pipelines offering both headless and non-headless crawling.&#xA;&#xA;Usage:&#xA;  ./katana [flags]&#xA;&#xA;Flags:&#xA;INPUT:&#xA;   -u, -list string[]  target url / list to crawl&#xA;   -resume string      resume scan using resume.cfg&#xA;   -e, -exclude string[]  exclude host matching specified filter (&#39;cdn&#39;, &#39;private-ips&#39;, cidr, ip, regex)&#xA;&#xA;CONFIGURATION:&#xA;   -r, -resolvers string[]       list of custom resolver (file or comma separated)&#xA;   -d, -depth int                maximum depth to crawl (default 3)&#xA;   -jc, -js-crawl                enable endpoint parsing / crawling in javascript file&#xA;   -jsl, -jsluice                enable jsluice parsing in javascript file (memory intensive)&#xA;   -ct, -crawl-duration value    maximum duration to crawl the target for (s, m, h, d) (default s)&#xA;   -kf, -known-files string      enable crawling of known files (all,robotstxt,sitemapxml), a minimum depth of 3 is required to ensure all known files are properly crawled.&#xA;   -mrs, -max-response-size int  maximum response size to read (default 9223372036854775807)&#xA;   -timeout int                  time to wait for request in seconds (default 10)&#xA;   -aff, -automatic-form-fill    enable automatic form filling (experimental)&#xA;   -fx, -form-extraction         extract form, input, textarea &amp;amp; select elements in jsonl output&#xA;   -retry int                    number of times to retry the request (default 1)&#xA;   -proxy string                 http/socks5 proxy to use&#xA;   -H, -headers string[]         custom header/cookie to include in all http request in header:value format (file)&#xA;   -config string                path to the katana configuration file&#xA;   -fc, -form-config string      path to custom form configuration file&#xA;   -flc, -field-config string    path to custom field configuration file&#xA;   -s, -strategy string          Visit strategy (depth-first, breadth-first) (default &#34;depth-first&#34;)&#xA;   -iqp, -ignore-query-params    Ignore crawling same path with different query-param values&#xA;   -tlsi, -tls-impersonate       enable experimental client hello (ja3) tls randomization&#xA;   -dr, -disable-redirects       disable following redirects (default false)&#xA;&#xA;DEBUG:&#xA;   -health-check, -hc        run diagnostic check up&#xA;   -elog, -error-log string  file to write sent requests error log&#xA;&#xA;HEADLESS:&#xA;   -hl, -headless                    enable headless hybrid crawling (experimental)&#xA;   -sc, -system-chrome               use local installed chrome browser instead of katana installed&#xA;   -sb, -show-browser                show the browser on the screen with headless mode&#xA;   -ho, -headless-options string[]   start headless chrome with additional options&#xA;   -nos, -no-sandbox                 start headless chrome in --no-sandbox mode&#xA;   -cdd, -chrome-data-dir string     path to store chrome browser data&#xA;   -scp, -system-chrome-path string  use specified chrome browser for headless crawling&#xA;   -noi, -no-incognito               start headless chrome without incognito mode&#xA;   -cwu, -chrome-ws-url string       use chrome browser instance launched elsewhere with the debugger listening at this URL&#xA;   -xhr, -xhr-extraction             extract xhr request url,method in jsonl output&#xA;&#xA;SCOPE:&#xA;   -cs, -crawl-scope string[]       in scope url regex to be followed by crawler&#xA;   -cos, -crawl-out-scope string[]  out of scope url regex to be excluded by crawler&#xA;   -fs, -field-scope string         pre-defined scope field (dn,rdn,fqdn) or custom regex (e.g., &#39;(company-staging.io|company.com)&#39;) (default &#34;rdn&#34;)&#xA;   -ns, -no-scope                   disables host based default scope&#xA;   -do, -display-out-scope          display external endpoint from scoped crawling&#xA;&#xA;FILTER:&#xA;   -mr, -match-regex string[]       regex or list of regex to match on output url (cli, file)&#xA;   -fr, -filter-regex string[]      regex or list of regex to filter on output url (cli, file)&#xA;   -f, -field string                field to display in output (url,path,fqdn,rdn,rurl,qurl,qpath,file,ufile,key,value,kv,dir,udir)&#xA;   -sf, -store-field string         field to store in per-host output (url,path,fqdn,rdn,rurl,qurl,qpath,file,ufile,key,value,kv,dir,udir)&#xA;   -em, -extension-match string[]   match output for given extension (eg, -em php,html,js)&#xA;   -ef, -extension-filter string[]  filter output for given extension (eg, -ef png,css)&#xA;   -mdc, -match-condition string    match response with dsl based condition&#xA;   -fdc, -filter-condition string   filter response with dsl based condition&#xA;&#xA;RATE-LIMIT:&#xA;   -c, -concurrency int          number of concurrent fetchers to use (default 10)&#xA;   -p, -parallelism int          number of concurrent inputs to process (default 10)&#xA;   -rd, -delay int               request delay between each request in seconds&#xA;   -rl, -rate-limit int          maximum requests to send per second (default 150)&#xA;   -rlm, -rate-limit-minute int  maximum number of requests to send per minute&#xA;&#xA;UPDATE:&#xA;   -up, -update                 update katana to latest version&#xA;   -duc, -disable-update-check  disable automatic katana update check&#xA;&#xA;OUTPUT:&#xA;   -o, -output string                file to write output to&#xA;   -sr, -store-response              store http requests/responses&#xA;   -srd, -store-response-dir string  store http requests/responses to custom directory&#xA;   -sfd, -store-field-dir string     store per-host field to custom directory&#xA;   -or, -omit-raw                    omit raw requests/responses from jsonl output&#xA;   -ob, -omit-body                   omit response body from jsonl output&#xA;   -j, -jsonl                        write output in jsonl format&#xA;   -nc, -no-color                    disable output content coloring (ANSI escape codes)&#xA;   -silent                           display output only&#xA;   -v, -verbose                      display verbose output&#xA;   -debug                            display debug output&#xA;   -version                          display project version&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running Katana&lt;/h2&gt; &#xA;&lt;h3&gt;Input for katana&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;katana&lt;/strong&gt; requires &lt;strong&gt;url&lt;/strong&gt; or &lt;strong&gt;endpoint&lt;/strong&gt; to crawl and accepts single or multiple inputs.&lt;/p&gt; &#xA;&lt;p&gt;Input URL can be provided using &lt;code&gt;-u&lt;/code&gt; option, and multiple values can be provided using comma-separated input, similarly &lt;strong&gt;file&lt;/strong&gt; input is supported using &lt;code&gt;-list&lt;/code&gt; option and additionally piped input (stdin) is also supported.&lt;/p&gt; &#xA;&lt;h4&gt;URL Input&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;katana -u https://tesla.com&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Multiple URL Input (comma-separated)&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;katana -u https://tesla.com,https://google.com&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;List Input&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cat url_list.txt&#xA;&#xA;https://tesla.com&#xA;https://google.com&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -list url_list.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;STDIN (piped) Input&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;echo https://tesla.com | katana&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cat domains | httpx | katana&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example running katana -&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -u https://youtube.com&#xA;&#xA;   __        __                &#xA;  / /_____ _/ /____ ____  ___ _&#xA; /  &#39;_/ _  / __/ _  / _ \/ _  /&#xA;/_/\_\\_,_/\__/\_,_/_//_/\_,_/ v0.0.1                     &#xA;&#xA;      projectdiscovery.io&#xA;&#xA;[WRN] Use with caution. You are responsible for your actions.&#xA;[WRN] Developers assume no liability and are not responsible for any misuse or damage.&#xA;https://www.youtube.com/&#xA;https://www.youtube.com/about/&#xA;https://www.youtube.com/about/press/&#xA;https://www.youtube.com/about/copyright/&#xA;https://www.youtube.com/t/contact_us/&#xA;https://www.youtube.com/creators/&#xA;https://www.youtube.com/ads/&#xA;https://www.youtube.com/t/terms&#xA;https://www.youtube.com/t/privacy&#xA;https://www.youtube.com/about/policies/&#xA;https://www.youtube.com/howyoutubeworks?utm_campaign=ytgen&amp;amp;utm_source=ythp&amp;amp;utm_medium=LeftNav&amp;amp;utm_content=txt&amp;amp;u=https%3A%2F%2Fwww.youtube.com%2Fhowyoutubeworks%3Futm_source%3Dythp%26utm_medium%3DLeftNav%26utm_campaign%3Dytgen&#xA;https://www.youtube.com/new&#xA;https://m.youtube.com/&#xA;https://www.youtube.com/s/desktop/4965577f/jsbin/desktop_polymer.vflset/desktop_polymer.js&#xA;https://www.youtube.com/s/desktop/4965577f/cssbin/www-main-desktop-home-page-skeleton.css&#xA;https://www.youtube.com/s/desktop/4965577f/cssbin/www-onepick.css&#xA;https://www.youtube.com/s/_/ytmainappweb/_/ss/k=ytmainappweb.kevlar_base.0Zo5FUcPkCg.L.B1.O/am=gAE/d=0/rs=AGKMywG5nh5Qp-BGPbOaI1evhF5BVGRZGA&#xA;https://www.youtube.com/opensearch?locale=en_GB&#xA;https://www.youtube.com/manifest.webmanifest&#xA;https://www.youtube.com/s/desktop/4965577f/cssbin/www-main-desktop-watch-page-skeleton.css&#xA;https://www.youtube.com/s/desktop/4965577f/jsbin/web-animations-next-lite.min.vflset/web-animations-next-lite.min.js&#xA;https://www.youtube.com/s/desktop/4965577f/jsbin/custom-elements-es5-adapter.vflset/custom-elements-es5-adapter.js&#xA;https://www.youtube.com/s/desktop/4965577f/jsbin/webcomponents-sd.vflset/webcomponents-sd.js&#xA;https://www.youtube.com/s/desktop/4965577f/jsbin/intersection-observer.min.vflset/intersection-observer.min.js&#xA;https://www.youtube.com/s/desktop/4965577f/jsbin/scheduler.vflset/scheduler.js&#xA;https://www.youtube.com/s/desktop/4965577f/jsbin/www-i18n-constants-en_GB.vflset/www-i18n-constants.js&#xA;https://www.youtube.com/s/desktop/4965577f/jsbin/www-tampering.vflset/www-tampering.js&#xA;https://www.youtube.com/s/desktop/4965577f/jsbin/spf.vflset/spf.js&#xA;https://www.youtube.com/s/desktop/4965577f/jsbin/network.vflset/network.js&#xA;https://www.youtube.com/howyoutubeworks/&#xA;https://www.youtube.com/trends/&#xA;https://www.youtube.com/jobs/&#xA;https://www.youtube.com/kids/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Crawling Mode&lt;/h2&gt; &#xA;&lt;h3&gt;Standard Mode&lt;/h3&gt; &#xA;&lt;p&gt;Standard crawling modality uses the standard go http library under the hood to handle HTTP requests/responses. This modality is much faster as it doesn&#39;t have the browser overhead. Still, it analyzes HTTP responses body as is, without any javascript or DOM rendering, potentially missing post-dom-rendered endpoints or asynchronous endpoint calls that might happen in complex web applications depending, for example, on browser-specific events.&lt;/p&gt; &#xA;&lt;h3&gt;Headless Mode&lt;/h3&gt; &#xA;&lt;p&gt;Headless mode hooks internal headless calls to handle HTTP requests/responses directly within the browser context. This offers two advantages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The HTTP fingerprint (TLS and user agent) fully identify the client as a legitimate browser&lt;/li&gt; &#xA; &lt;li&gt;Better coverage since the endpoints are discovered analyzing the standard raw response, as in the previous modality, and also the browser-rendered one with javascript enabled.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Headless crawling is optional and can be enabled using &lt;code&gt;-headless&lt;/code&gt; option.&lt;/p&gt; &#xA;&lt;p&gt;Here are other headless CLI options -&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -h headless&#xA;&#xA;Flags:&#xA;HEADLESS:&#xA;   -hl, -headless                    enable headless hybrid crawling (experimental)&#xA;   -sc, -system-chrome               use local installed chrome browser instead of katana installed&#xA;   -sb, -show-browser                show the browser on the screen with headless mode&#xA;   -ho, -headless-options string[]   start headless chrome with additional options&#xA;   -nos, -no-sandbox                 start headless chrome in --no-sandbox mode&#xA;   -cdd, -chrome-data-dir string     path to store chrome browser data&#xA;   -scp, -system-chrome-path string  use specified chrome browser for headless crawling&#xA;   -noi, -no-incognito               start headless chrome without incognito mode&#xA;   -cwu, -chrome-ws-url string       use chrome browser instance launched elsewhere with the debugger listening at this URL&#xA;   -xhr, -xhr-extraction             extract xhr requests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-no-sandbox&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Runs headless chrome browser with &lt;strong&gt;no-sandbox&lt;/strong&gt; option, useful when running as root user.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -u https://tesla.com -headless -no-sandbox&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-no-incognito&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Runs headless chrome browser without incognito mode, useful when using the local browser.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -u https://tesla.com -headless -no-incognito&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-headless-options&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;When crawling in headless mode, additional chrome options can be specified using &lt;code&gt;-headless-options&lt;/code&gt;, for example -&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -u https://tesla.com -headless -system-chrome -headless-options --disable-gpu,proxy-server=http://127.0.0.1:8080&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Scope Control&lt;/h2&gt; &#xA;&lt;p&gt;Crawling can be endless if not scoped, as such katana comes with multiple support to define the crawl scope.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-field-scope&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Most handy option to define scope with predefined field name, &lt;code&gt;rdn&lt;/code&gt; being default option for field scope.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;rdn&lt;/code&gt; - crawling scoped to root domain name and all subdomains (e.g. &lt;code&gt;*example.com&lt;/code&gt;) (default)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;fqdn&lt;/code&gt; - crawling scoped to given sub(domain) (e.g. &lt;code&gt;www.example.com&lt;/code&gt; or &lt;code&gt;api.example.com&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;dn&lt;/code&gt; - crawling scoped to domain name keyword (e.g. &lt;code&gt;example&lt;/code&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -u https://tesla.com -fs dn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-crawl-scope&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;For advanced scope control, &lt;code&gt;-cs&lt;/code&gt; option can be used that comes with &lt;strong&gt;regex&lt;/strong&gt; support.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -u https://tesla.com -cs login&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For multiple in scope rules, file input with multiline string / regex can be passed.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cat in_scope.txt&#xA;&#xA;login/&#xA;admin/&#xA;app/&#xA;wordpress/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -u https://tesla.com -cs in_scope.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-crawl-out-scope&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;For defining what not to crawl, &lt;code&gt;-cos&lt;/code&gt; option can be used and also support &lt;strong&gt;regex&lt;/strong&gt; input.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -u https://tesla.com -cos logout&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For multiple out of scope rules, file input with multiline string / regex can be passed.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cat out_of_scope.txt&#xA;&#xA;/logout&#xA;/log_out&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -u https://tesla.com -cos out_of_scope.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-no-scope&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Katana is default to scope &lt;code&gt;*.domain&lt;/code&gt;, to disable this &lt;code&gt;-ns&lt;/code&gt; option can be used and also to crawl the internet.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -u https://tesla.com -ns&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-display-out-scope&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;As default, when scope option is used, it also applies for the links to display as output, as such &lt;strong&gt;external URLs are default to exclude&lt;/strong&gt; and to overwrite this behavior, &lt;code&gt;-do&lt;/code&gt; option can be used to display all the external URLs that exist in targets scoped URL / Endpoint.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -do&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here is all the CLI options for the scope control -&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -h scope&#xA;&#xA;Flags:&#xA;SCOPE:&#xA;   -cs, -crawl-scope string[]       in scope url regex to be followed by crawler&#xA;   -cos, -crawl-out-scope string[]  out of scope url regex to be excluded by crawler&#xA;   -fs, -field-scope string         pre-defined scope field (dn,rdn,fqdn) (default &#34;rdn&#34;)&#xA;   -ns, -no-scope                   disables host based default scope&#xA;   -do, -display-out-scope          display external endpoint from scoped crawling&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Crawler Configuration&lt;/h2&gt; &#xA;&lt;p&gt;Katana comes with multiple options to configure and control the crawl as the way we want.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-depth&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Option to define the &lt;code&gt;depth&lt;/code&gt; to follow the urls for crawling, the more depth the more number of endpoint being crawled + time for crawl.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -d 5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-js-crawl&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Option to enable JavaScript file parsing + crawling the endpoints discovered in JavaScript files, disabled as default.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -jc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-crawl-duration&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Option to predefined crawl duration, disabled as default.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -ct 2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-known-files&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Option to enable crawling &lt;code&gt;robots.txt&lt;/code&gt; and &lt;code&gt;sitemap.xml&lt;/code&gt; file, disabled as default.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -kf robotstxt,sitemapxml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-automatic-form-fill&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Option to enable automatic form filling for known / unknown fields, known field values can be customized as needed by updating form config file at &lt;code&gt;$HOME/.config/katana/form-config.yaml&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Automatic form filling is experimental feature.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -aff&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Authenticated Crawling&lt;/h2&gt; &#xA;&lt;p&gt;Authenticated crawling involves including custom headers or cookies in HTTP requests to access protected resources. These headers provide authentication or authorization information, allowing you to crawl authenticated content / endpoint. You can specify headers directly in the command line or provide them as a file with katana to perfrom authenticated crawling.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: User needs to be manually perform the authentication and export the session cookie / header to file to use with katana.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-headers&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Option to add a custom header or cookie to the request.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Syntax of &lt;a href=&#34;https://datatracker.ietf.org/doc/html/rfc7230#section-3.2&#34;&gt;headers&lt;/a&gt; in the HTTP specification&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Here is an example of adding a cookie to the request:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -H &#39;Cookie: usrsess=AmljNrESo&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It is also possible to supply headers or cookies as a file. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cat cookie.txt&#xA;&#xA;Cookie: PHPSESSIONID=XXXXXXXXX&#xA;X-API-KEY: XXXXX&#xA;TOKEN=XX&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -H cookie.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There are more options to configure when needed, here is all the config related CLI options -&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -h config&#xA;&#xA;Flags:&#xA;CONFIGURATION:&#xA;   -r, -resolvers string[]       list of custom resolver (file or comma separated)&#xA;   -d, -depth int                maximum depth to crawl (default 3)&#xA;   -jc, -js-crawl                enable endpoint parsing / crawling in javascript file&#xA;   -ct, -crawl-duration int      maximum duration to crawl the target for&#xA;   -kf, -known-files string      enable crawling of known files (all,robotstxt,sitemapxml)&#xA;   -mrs, -max-response-size int  maximum response size to read (default 9223372036854775807)&#xA;   -timeout int                  time to wait for request in seconds (default 10)&#xA;   -aff, -automatic-form-fill    enable automatic form filling (experimental)&#xA;   -fx, -form-extraction         enable extraction of form, input, textarea &amp;amp; select elements&#xA;   -retry int                    number of times to retry the request (default 1)&#xA;   -proxy string                 http/socks5 proxy to use&#xA;   -H, -headers string[]         custom header/cookie to include in request&#xA;   -config string                path to the katana configuration file&#xA;   -fc, -form-config string      path to custom form configuration file&#xA;   -flc, -field-config string    path to custom field configuration file&#xA;   -s, -strategy string          Visit strategy (depth-first, breadth-first) (default &#34;depth-first&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Connecting to Active Browser Session&lt;/h3&gt; &#xA;&lt;p&gt;Katana can also connect to active browser session where user is already logged in and authenticated. and use it for crawling. The only requirement for this is to start browser with remote debugging enabled.&lt;/p&gt; &#xA;&lt;p&gt;Here is an example of starting chrome browser with remote debugging enabled and using it with katana -&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;step 1) First Locate path of chrome executable&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Operating System&lt;/th&gt; &#xA;   &lt;th&gt;Chromium Executable Location&lt;/th&gt; &#xA;   &lt;th&gt;Google Chrome Executable Location&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Windows (64-bit)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;C:\Program Files (x86)\Google\Chromium\Application\chrome.exe&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;C:\Program Files (x86)\Google\Chrome\Application\chrome.exe&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Windows (32-bit)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;C:\Program Files\Google\Chromium\Application\chrome.exe&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;C:\Program Files\Google\Chrome\Application\chrome.exe&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;macOS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;/Applications/Chromium.app/Contents/MacOS/Chromium&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;/Applications/Google Chrome.app/Contents/MacOS/Google Chrome&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Linux&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;/usr/bin/chromium&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;/usr/bin/google-chrome&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;step 2) Start chrome with remote debugging enabled and it will return websocker url. For example, on MacOS, you can start chrome with remote debugging enabled using following command&lt;/strong&gt; -&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ /Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --remote-debugging-port=9222&#xA;&#xA;&#xA;DevTools listening on ws://127.0.0.1:9222/devtools/browser/c5316c9c-19d6-42dc-847a-41d1aeebf7d6&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Now login to the website you want to crawl and keep the browser open.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;strong&gt;step 3) Now use the websocket url with katana to connect to the active browser session and crawl the website&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -headless -u https://tesla.com -cwu ws://127.0.0.1:9222/devtools/browser/c5316c9c-19d6-42dc-847a-41d1aeebf7d6 -no-incognito&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: you can use &lt;code&gt;-cdd&lt;/code&gt; option to specify custom chrome data directory to store browser data and cookies but that does not save session data if cookie is set to &lt;code&gt;Session&lt;/code&gt; only or expires after certain time.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Filters&lt;/h2&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-field&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Katana comes with built in fields that can be used to filter the output for the desired information, &lt;code&gt;-f&lt;/code&gt; option can be used to specify any of the available fields.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;   -f, -field string  field to display in output (url,path,fqdn,rdn,rurl,qurl,qpath,file,key,value,kv,dir,udir)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here is a table with examples of each field and expected output when used -&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;FIELD&lt;/th&gt; &#xA;   &lt;th&gt;DESCRIPTION&lt;/th&gt; &#xA;   &lt;th&gt;EXAMPLE&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;url&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;URL Endpoint&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;https://admin.projectdiscovery.io/admin/login?user=admin&amp;amp;password=admin&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;qurl&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;URL including query param&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;https://admin.projectdiscovery.io/admin/login.php?user=admin&amp;amp;password=admin&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;qpath&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Path including query param&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;/login?user=admin&amp;amp;password=admin&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;path&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;URL Path&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;https://admin.projectdiscovery.io/admin/login&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;fqdn&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Fully Qualified Domain name&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;admin.projectdiscovery.io&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;rdn&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Root Domain name&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;projectdiscovery.io&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;rurl&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Root URL&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;https://admin.projectdiscovery.io&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;ufile&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;URL with File&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;https://admin.projectdiscovery.io/login.js&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;file&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Filename in URL&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;login.php&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;key&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Parameter keys in URL&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;user,password&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;value&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Parameter values in URL&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;admin,admin&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;kv&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Keys=Values in URL&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;user=admin&amp;amp;password=admin&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;dir&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;URL Directory name&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;/admin/&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;udir&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;URL with Directory&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;https://admin.projectdiscovery.io/admin/&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Here is an example of using field option to only display all the urls with query parameter in it -&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -f qurl -silent&#xA;&#xA;https://shop.tesla.com/en_au?redirect=no&#xA;https://shop.tesla.com/en_nz?redirect=no&#xA;https://shop.tesla.com/product/men_s-raven-lightweight-zip-up-bomber-jacket?sku=1740250-00-A&#xA;https://shop.tesla.com/product/tesla-shop-gift-card?sku=1767247-00-A&#xA;https://shop.tesla.com/product/men_s-chill-crew-neck-sweatshirt?sku=1740176-00-A&#xA;https://www.tesla.com/about?redirect=no&#xA;https://www.tesla.com/about/legal?redirect=no&#xA;https://www.tesla.com/findus/list?redirect=no&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Custom Fields&lt;/h3&gt; &#xA;&lt;p&gt;You can create custom fields to extract and store specific information from page responses using regex rules. These custom fields are defined using a YAML config file and are loaded from the default location at &lt;code&gt;$HOME/.config/katana/field-config.yaml&lt;/code&gt;. Alternatively, you can use the &lt;code&gt;-flc&lt;/code&gt; option to load a custom field config file from a different location. Here is example custom field.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;- name: email&#xA;  type: regex&#xA;  regex:&#xA;  - &#39;([a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+\.[a-zA-Z0-9_-]+)&#39;&#xA;  - &#39;([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\.[a-zA-Z0-9_-]+)&#39;&#xA;&#xA;- name: phone&#xA;  type: regex&#xA;  regex:&#xA;  - &#39;\d{3}-\d{8}|\d{4}-\d{7}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When defining custom fields, following attributes are supported:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;name&lt;/strong&gt; (required)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;The value of &lt;strong&gt;name&lt;/strong&gt; attribute is used as the &lt;code&gt;-field&lt;/code&gt; cli option value.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;type&lt;/strong&gt; (required)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;The type of custom attribute, currenly supported option - &lt;code&gt;regex&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;part&lt;/strong&gt; (optional)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;The part of the response to extract the information from. The default value is &lt;code&gt;response&lt;/code&gt;, which includes both the header and body. Other possible values are &lt;code&gt;header&lt;/code&gt; and &lt;code&gt;body&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;group (optional)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;You can use this attribute to select a specific matched group in regex, for example: &lt;code&gt;group: 1&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;Running katana using custom field:&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -u https://tesla.com -f email,phone&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-store-field&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;To compliment &lt;code&gt;field&lt;/code&gt; option which is useful to filter output at run time, there is &lt;code&gt;-sf, -store-fields&lt;/code&gt; option which works exactly like field option except instead of filtering, it stores all the information on the disk under &lt;code&gt;katana_field&lt;/code&gt; directory sorted by target url. Use &lt;code&gt;-sfd&lt;/code&gt; or &lt;code&gt;-store-field-dir&lt;/code&gt; to store data in a different location.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -sf key,fqdn,qurl -silent&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ls katana_field/&#xA;&#xA;https_www.tesla.com_fqdn.txt&#xA;https_www.tesla.com_key.txt&#xA;https_www.tesla.com_qurl.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;-store-field&lt;/code&gt; option can be useful for collecting information to build a targeted wordlist for various purposes, including but not limited to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Identifying the most commonly used parameters&lt;/li&gt; &#xA; &lt;li&gt;Discovering frequently used paths&lt;/li&gt; &#xA; &lt;li&gt;Finding commonly used files&lt;/li&gt; &#xA; &lt;li&gt;Identifying related or unknown subdomains&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Katana Filters&lt;/h3&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-extension-match&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Crawl output can be easily matched for specific extension using &lt;code&gt;-em&lt;/code&gt; option to ensure to display only output containing given extension.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -silent -em js,jsp,json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-extension-filter&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Crawl output can be easily filtered for specific extension using &lt;code&gt;-ef&lt;/code&gt; option which ensure to remove all the urls containing given extension.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -silent -ef css,txt,md&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-match-regex&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;-match-regex&lt;/code&gt; or &lt;code&gt;-mr&lt;/code&gt; flag allows you to filter output URLs using regular expressions. When using this flag, only URLs that match the specified regular expression will be printed in the output.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -mr &#39;https://shop\.tesla\.com/*&#39; -silent&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-filter-regex&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;-filter-regex&lt;/code&gt; or &lt;code&gt;-fr&lt;/code&gt; flag allows you to filter output URLs using regular expressions. When using this flag, it will skip the URLs that are match the specified regular expression.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -fr &#39;https://www\.tesla\.com/*&#39; -silent&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Advance Filtering&lt;/h3&gt; &#xA;&lt;p&gt;Katana supports DSL-based expressions for advanced matching and filtering capabilities:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To match endpoints with a 200 status code:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;katana -u https://www.hackerone.com -mdc &#39;status_code == 200&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To match endpoints that contain &#34;default&#34; and have a status code other than 403:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;katana -u https://www.hackerone.com -mdc &#39;contains(endpoint, &#34;default&#34;) &amp;amp;&amp;amp; status_code != 403&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To match endpoints with PHP technologies:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;katana -u https://www.hackerone.com -mdc &#39;contains(to_lower(technologies), &#34;php&#34;)&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To filter out endpoints running on Cloudflare:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;katana -u https://www.hackerone.com -fdc &#39;contains(to_lower(technologies), &#34;cloudflare&#34;)&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;DSL functions can be applied to any keys in the jsonl output. For more information on available DSL functions, please visit the &lt;a href=&#34;https://github.com/projectdiscovery/dsl&#34;&gt;dsl project&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Here are additional filter options -&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -h filter&#xA;&#xA;Flags:&#xA;FILTER:&#xA;   -mr, -match-regex string[]       regex or list of regex to match on output url (cli, file)&#xA;   -fr, -filter-regex string[]      regex or list of regex to filter on output url (cli, file)&#xA;   -f, -field string                field to display in output (url,path,fqdn,rdn,rurl,qurl,qpath,file,ufile,key,value,kv,dir,udir)&#xA;   -sf, -store-field string         field to store in per-host output (url,path,fqdn,rdn,rurl,qurl,qpath,file,ufile,key,value,kv,dir,udir)&#xA;   -em, -extension-match string[]   match output for given extension (eg, -em php,html,js)&#xA;   -ef, -extension-filter string[]  filter output for given extension (eg, -ef png,css)&#xA;   -mdc, -match-condition string    match response with dsl based condition&#xA;   -fdc, -filter-condition string   filter response with dsl based condition&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Rate Limit&lt;/h2&gt; &#xA;&lt;p&gt;It&#39;s easy to get blocked / banned while crawling if not following target websites limits, katana comes with multiple option to tune the crawl to go as fast / slow we want.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-delay&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;option to introduce a delay in seconds between each new request katana makes while crawling, disabled as default.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -delay 20&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-concurrency&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;option to control the number of urls per target to fetch at the same time.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -c 20&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-parallelism&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;option to define number of target to process at same time from list input.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -p 20&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-rate-limit&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;option to use to define max number of request can go out per second.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -rl 100&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-rate-limit-minute&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;option to use to define max number of request can go out per minute.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -rlm 500&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here is all long / short CLI options for rate limit control -&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -h rate-limit&#xA;&#xA;Flags:&#xA;RATE-LIMIT:&#xA;   -c, -concurrency int          number of concurrent fetchers to use (default 10)&#xA;   -p, -parallelism int          number of concurrent inputs to process (default 10)&#xA;   -rd, -delay int               request delay between each request in seconds&#xA;   -rl, -rate-limit int          maximum requests to send per second (default 150)&#xA;   -rlm, -rate-limit-minute int  maximum number of requests to send per minute&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Output&lt;/h2&gt; &#xA;&lt;p&gt;Katana support both file output in plain text format as well as JSON which includes additional information like, &lt;code&gt;source&lt;/code&gt;, &lt;code&gt;tag&lt;/code&gt;, and &lt;code&gt;attribute&lt;/code&gt; name to co-related the discovered endpoint.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;code&gt;-output&lt;/code&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;By default, katana outputs the crawled endpoints in plain text format. The results can be written to a file by using the -output option.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -u https://example.com -no-scope -output example_endpoints.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-jsonl&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -u https://example.com -jsonl | jq .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;timestamp&#34;: &#34;2023-03-20T16:23:58.027559+05:30&#34;,&#xA;  &#34;request&#34;: {&#xA;    &#34;method&#34;: &#34;GET&#34;,&#xA;    &#34;endpoint&#34;: &#34;https://example.com&#34;,&#xA;    &#34;raw&#34;: &#34;GET / HTTP/1.1\r\nHost: example.com\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\r\nAccept-Encoding: gzip\r\n\r\n&#34;&#xA;  },&#xA;  &#34;response&#34;: {&#xA;    &#34;status_code&#34;: 200,&#xA;    &#34;headers&#34;: {&#xA;      &#34;accept_ranges&#34;: &#34;bytes&#34;,&#xA;      &#34;expires&#34;: &#34;Mon, 27 Mar 2023 10:53:58 GMT&#34;,&#xA;      &#34;last_modified&#34;: &#34;Thu, 17 Oct 2019 07:18:26 GMT&#34;,&#xA;      &#34;content_type&#34;: &#34;text/html; charset=UTF-8&#34;,&#xA;      &#34;server&#34;: &#34;ECS (dcb/7EA3)&#34;,&#xA;      &#34;vary&#34;: &#34;Accept-Encoding&#34;,&#xA;      &#34;etag&#34;: &#34;\&#34;3147526947\&#34;&#34;,&#xA;      &#34;cache_control&#34;: &#34;max-age=604800&#34;,&#xA;      &#34;x_cache&#34;: &#34;HIT&#34;,&#xA;      &#34;date&#34;: &#34;Mon, 20 Mar 2023 10:53:58 GMT&#34;,&#xA;      &#34;age&#34;: &#34;331239&#34;&#xA;    },&#xA;    &#34;body&#34;: &#34;&amp;lt;!doctype html&amp;gt;\n&amp;lt;html&amp;gt;\n&amp;lt;head&amp;gt;\n    &amp;lt;title&amp;gt;Example Domain&amp;lt;/title&amp;gt;\n\n    &amp;lt;meta charset=\&#34;utf-8\&#34; /&amp;gt;\n    &amp;lt;meta http-equiv=\&#34;Content-type\&#34; content=\&#34;text/html; charset=utf-8\&#34; /&amp;gt;\n    &amp;lt;meta name=\&#34;viewport\&#34; content=\&#34;width=device-width, initial-scale=1\&#34; /&amp;gt;\n    &amp;lt;style type=\&#34;text/css\&#34;&amp;gt;\n    body {\n        background-color: #f0f0f2;\n        margin: 0;\n        padding: 0;\n        font-family: -apple-system, system-ui, BlinkMacSystemFont, \&#34;Segoe UI\&#34;, \&#34;Open Sans\&#34;, \&#34;Helvetica Neue\&#34;, Helvetica, Arial, sans-serif;\n        \n    }\n    div {\n        width: 600px;\n        margin: 5em auto;\n        padding: 2em;\n        background-color: #fdfdff;\n        border-radius: 0.5em;\n        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n    }\n    a:link, a:visited {\n        color: #38488f;\n        text-decoration: none;\n    }\n    @media (max-width: 700px) {\n        div {\n            margin: 0 auto;\n            width: auto;\n        }\n    }\n    &amp;lt;/style&amp;gt;    \n&amp;lt;/head&amp;gt;\n\n&amp;lt;body&amp;gt;\n&amp;lt;div&amp;gt;\n    &amp;lt;h1&amp;gt;Example Domain&amp;lt;/h1&amp;gt;\n    &amp;lt;p&amp;gt;This domain is for use in illustrative examples in documents. You may use this\n    domain in literature without prior coordination or asking for permission.&amp;lt;/p&amp;gt;\n    &amp;lt;p&amp;gt;&amp;lt;a href=\&#34;https://www.iana.org/domains/example\&#34;&amp;gt;More information...&amp;lt;/a&amp;gt;&amp;lt;/p&amp;gt;\n&amp;lt;/div&amp;gt;\n&amp;lt;/body&amp;gt;\n&amp;lt;/html&amp;gt;\n&#34;,&#xA;    &#34;technologies&#34;: [&#xA;      &#34;Azure&#34;,&#xA;      &#34;Amazon ECS&#34;,&#xA;      &#34;Amazon Web Services&#34;,&#xA;      &#34;Docker&#34;,&#xA;      &#34;Azure CDN&#34;&#xA;    ],&#xA;    &#34;raw&#34;: &#34;HTTP/1.1 200 OK\r\nContent-Length: 1256\r\nAccept-Ranges: bytes\r\nAge: 331239\r\nCache-Control: max-age=604800\r\nContent-Type: text/html; charset=UTF-8\r\nDate: Mon, 20 Mar 2023 10:53:58 GMT\r\nEtag: \&#34;3147526947\&#34;\r\nExpires: Mon, 27 Mar 2023 10:53:58 GMT\r\nLast-Modified: Thu, 17 Oct 2019 07:18:26 GMT\r\nServer: ECS (dcb/7EA3)\r\nVary: Accept-Encoding\r\nX-Cache: HIT\r\n\r\n&amp;lt;!doctype html&amp;gt;\n&amp;lt;html&amp;gt;\n&amp;lt;head&amp;gt;\n    &amp;lt;title&amp;gt;Example Domain&amp;lt;/title&amp;gt;\n\n    &amp;lt;meta charset=\&#34;utf-8\&#34; /&amp;gt;\n    &amp;lt;meta http-equiv=\&#34;Content-type\&#34; content=\&#34;text/html; charset=utf-8\&#34; /&amp;gt;\n    &amp;lt;meta name=\&#34;viewport\&#34; content=\&#34;width=device-width, initial-scale=1\&#34; /&amp;gt;\n    &amp;lt;style type=\&#34;text/css\&#34;&amp;gt;\n    body {\n        background-color: #f0f0f2;\n        margin: 0;\n        padding: 0;\n        font-family: -apple-system, system-ui, BlinkMacSystemFont, \&#34;Segoe UI\&#34;, \&#34;Open Sans\&#34;, \&#34;Helvetica Neue\&#34;, Helvetica, Arial, sans-serif;\n        \n    }\n    div {\n        width: 600px;\n        margin: 5em auto;\n        padding: 2em;\n        background-color: #fdfdff;\n        border-radius: 0.5em;\n        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n    }\n    a:link, a:visited {\n        color: #38488f;\n        text-decoration: none;\n    }\n    @media (max-width: 700px) {\n        div {\n            margin: 0 auto;\n            width: auto;\n        }\n    }\n    &amp;lt;/style&amp;gt;    \n&amp;lt;/head&amp;gt;\n\n&amp;lt;body&amp;gt;\n&amp;lt;div&amp;gt;\n    &amp;lt;h1&amp;gt;Example Domain&amp;lt;/h1&amp;gt;\n    &amp;lt;p&amp;gt;This domain is for use in illustrative examples in documents. You may use this\n    domain in literature without prior coordination or asking for permission.&amp;lt;/p&amp;gt;\n    &amp;lt;p&amp;gt;&amp;lt;a href=\&#34;https://www.iana.org/domains/example\&#34;&amp;gt;More information...&amp;lt;/a&amp;gt;&amp;lt;/p&amp;gt;\n&amp;lt;/div&amp;gt;\n&amp;lt;/body&amp;gt;\n&amp;lt;/html&amp;gt;\n&#34;&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;em&gt;&lt;code&gt;-store-response&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;-store-response&lt;/code&gt; option allows for writing all crawled endpoint requests and responses to a text file. When this option is used, text files including the request and response will be written to the &lt;strong&gt;katana_response&lt;/strong&gt; directory. If you would like to specify a custom directory, you can use the &lt;code&gt;-store-response-dir&lt;/code&gt; option.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -u https://example.com -no-scope -store-response&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cat katana_response/index.txt&#xA;&#xA;katana_response/example.com/327c3fda87ce286848a574982ddd0b7c7487f816.txt https://example.com (200 OK)&#xA;katana_response/www.iana.org/bfc096e6dd93b993ca8918bf4c08fdc707a70723.txt http://www.iana.org/domains/reserved (200 OK)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;code&gt;-store-response&lt;/code&gt; option is not supported in &lt;code&gt;-headless&lt;/code&gt; mode.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Here are additional CLI options related to output -&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;katana -h output&#xA;&#xA;OUTPUT:&#xA;   -o, -output string                file to write output to&#xA;   -sr, -store-response              store http requests/responses&#xA;   -srd, -store-response-dir string  store http requests/responses to custom directory&#xA;   -j, -json                         write output in JSONL(ines) format&#xA;   -nc, -no-color                    disable output content coloring (ANSI escape codes)&#xA;   -silent                           display output only&#xA;   -v, -verbose                      display verbose output&#xA;   -version                          display project version&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Katana as a library&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;katana&lt;/code&gt; can be used as a library by creating an instance of the &lt;code&gt;Option&lt;/code&gt; struct and populating it with the same options that would be specified via CLI. Using the options you can create &lt;code&gt;crawlerOptions&lt;/code&gt; and so standard or hybrid &lt;code&gt;crawler&lt;/code&gt;. &lt;code&gt;crawler.Crawl&lt;/code&gt; method should be called to crawl the input.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main&#xA;&#xA;import (&#xA;&#x9;&#34;math&#34;&#xA;&#xA;&#x9;&#34;github.com/projectdiscovery/gologger&#34;&#xA;&#x9;&#34;github.com/projectdiscovery/katana/pkg/engine/standard&#34;&#xA;&#x9;&#34;github.com/projectdiscovery/katana/pkg/output&#34;&#xA;&#x9;&#34;github.com/projectdiscovery/katana/pkg/types&#34;&#xA;)&#xA;&#xA;func main() {&#xA;&#x9;options := &amp;amp;types.Options{&#xA;&#x9;&#x9;MaxDepth:     3,             // Maximum depth to crawl&#xA;&#x9;&#x9;FieldScope:   &#34;rdn&#34;,         // Crawling Scope Field&#xA;&#x9;&#x9;BodyReadSize: math.MaxInt,   // Maximum response size to read&#xA;&#x9;&#x9;Timeout:      10,            // Timeout is the time to wait for request in seconds&#xA;&#x9;&#x9;Concurrency:  10,            // Concurrency is the number of concurrent crawling goroutines&#xA;&#x9;&#x9;Parallelism:  10,            // Parallelism is the number of urls processing goroutines&#xA;&#x9;&#x9;Delay:        0,             // Delay is the delay between each crawl requests in seconds&#xA;&#x9;&#x9;RateLimit:    150,           // Maximum requests to send per second&#xA;&#x9;&#x9;Strategy:     &#34;depth-first&#34;, // Visit strategy (depth-first, breadth-first)&#xA;&#x9;&#x9;OnResult: func(result output.Result) { // Callback function to execute for result&#xA;&#x9;&#x9;&#x9;gologger.Info().Msg(result.Request.URL)&#xA;&#x9;&#x9;},&#xA;&#x9;}&#xA;&#x9;crawlerOptions, err := types.NewCrawlerOptions(options)&#xA;&#x9;if err != nil {&#xA;&#x9;&#x9;gologger.Fatal().Msg(err.Error())&#xA;&#x9;}&#xA;&#x9;defer crawlerOptions.Close()&#xA;&#x9;crawler, err := standard.New(crawlerOptions)&#xA;&#x9;if err != nil {&#xA;&#x9;&#x9;gologger.Fatal().Msg(err.Error())&#xA;&#x9;}&#xA;&#x9;defer crawler.Close()&#xA;&#x9;var input = &#34;https://www.hackerone.com&#34;&#xA;&#x9;err = crawler.Crawl(input)&#xA;&#x9;if err != nil {&#xA;&#x9;&#x9;gologger.Warning().Msgf(&#34;Could not crawl %s: %s&#34;, input, err.Error())&#xA;&#x9;}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;katana is made with ‚ù§Ô∏è by the &lt;a href=&#34;https://projectdiscovery.io&#34;&gt;projectdiscovery&lt;/a&gt; team and distributed under &lt;a href=&#34;https://raw.githubusercontent.com/projectdiscovery/katana/main/LICENSE.md&#34;&gt;MIT License&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://discord.gg/projectdiscovery&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/projectdiscovery/nuclei-burp-plugin/main/static/join-discord.png&#34; width=&#34;300&#34; alt=&#34;Join Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt;</summary>
  </entry>
</feed>