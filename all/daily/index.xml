<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-11T01:25:39Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>cyberus-technology/virtualbox-kvm</title>
    <updated>2024-02-11T01:25:39Z</updated>
    <id>tag:github.com,2024-02-11:/cyberus-technology/virtualbox-kvm</id>
    <link href="https://github.com/cyberus-technology/virtualbox-kvm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;VirtualBox with KVM Backend&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;VirtualBox KVM&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains an adapted version of the open source virtualization tool VirtualBox called VirtualBox KVM. VirtualBox KVM uses Linux KVM as the underlying hypervisor.&lt;/p&gt; &#xA;&lt;h2&gt;What to expect&lt;/h2&gt; &#xA;&lt;p&gt;The basic look and feel of VirtualBox KVM will be the same as with an conventional VirtualBox. The user is able to boot the same guest VMs in their existing VirtualBox configuration.&lt;/p&gt; &#xA;&lt;p&gt;Nonetheless, there are the following benefits of using VirtualBox KVM compared to the conventional VirtualBox:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;VirtualBox can run in parallel to QEMU/KVM&lt;/li&gt; &#xA; &lt;li&gt;VirtualBox kernel driver (&lt;code&gt;vboxdrv&lt;/code&gt;) is not required&lt;/li&gt; &#xA; &lt;li&gt;Modern virtualization features supported by KVM are automatically used (e.g. APICv)&lt;/li&gt; &#xA; &lt;li&gt;KVM is part of the Linux kernel and therefore always directly available with every kernel update&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Due to the replacement of the underlying hypervisor, there will be differences in the guest performance. Performance differences heavily depend on the guest workload.&lt;/p&gt; &#xA;&lt;h2&gt;How to use&lt;/h2&gt; &#xA;&lt;p&gt;There are no prebuilt packages of VirtualBox KVM and it needs to be built from source. The process of building VirtualBox from source can be found &lt;a href=&#34;https://www.virtualbox.org/wiki/Linux%20build%20instructions&#34;&gt;on virtualbox.org&lt;/a&gt; and only minor adjustments are required to build VirtualBox with KVM as a backend.&lt;/p&gt; &#xA;&lt;p&gt;On a fresh install of Ubuntu 22.04, you can use the following command to install all prerequisites via &lt;code&gt;apt&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;apt install acpica-tools chrpath doxygen g++-multilib libasound2-dev libcap-dev \&#xA;        libcurl4-openssl-dev libdevmapper-dev libidl-dev libopus-dev libpam0g-dev \&#xA;        libpulse-dev libqt5opengl5-dev libqt5x11extras5-dev qttools5-dev libsdl1.2-dev libsdl-ttf2.0-dev \&#xA;        libssl-dev libvpx-dev libxcursor-dev libxinerama-dev libxml2-dev libxml2-utils \&#xA;        libxmu-dev libxrandr-dev make nasm python3-dev python2-dev qttools5-dev-tools \&#xA;        texlive texlive-fonts-extra texlive-latex-extra unzip xsltproc \&#xA;        \&#xA;        default-jdk libstdc++5 libxslt1-dev linux-kernel-headers makeself \&#xA;        mesa-common-dev subversion yasm zlib1g-dev glslang-tools \&#xA;        libc6-dev-i386 lib32stdc++6 libtpms-dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Newer GCC versions (&amp;gt;= 12) might cause build issues. The command above installs a compatible version on Ubuntu 22.04.&lt;/p&gt; &#xA;&lt;p&gt;After having all the prerequisites installed, the build process can be condensed to the following steps:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ./configure --with-kvm --disable-kmods --disable-docs --disable-hardening --disable-java&#xA;$ source ./env.sh&#xA;$ kmk&#xA;$ out/linux.amd64/release/bin/VirtualBox&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The noticeable difference to the official build process is the addition of &lt;code&gt;--with-kvm&lt;/code&gt; when calling &lt;code&gt;./configure&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Known issues and limitations&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Currently, Intel x86_64 is the only supported host platform. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;AMD will most likely work too but is considered experimental at the moment.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Linux is required as a host operating system for building and running VirtualBox KVM.&lt;/li&gt; &#xA; &lt;li&gt;Starting with Intel Tiger Lake (11th Gen Core processors) or newer, split lock detection must be turned off in the host system. This can be achieved using the Linux kernel command line parameter &lt;code&gt;split_lock_detect=off&lt;/code&gt; or using the &lt;code&gt;split_lock_mitigate&lt;/code&gt; sysctl.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to engage&lt;/h2&gt; &#xA;&lt;p&gt;If you would like to use VirtualBox with KVM or if you have a need for custom virtualization solutions, we are happy to provide guidance and engineering services. Please reach out to us via our &lt;a href=&#34;https://cyberus-technology.de/contact&#34;&gt;support form&lt;/a&gt; or via e-mail at &lt;a href=&#34;mailto:service@cyberus-technology.de&#34;&gt;service@cyberus-technology.de&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you encounter any issues please use the provided issue template and describe your problem as detailed as possible.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>awslabs/llrt</title>
    <updated>2024-02-11T01:25:39Z</updated>
    <id>tag:github.com,2024-02-11:/awslabs/llrt</id>
    <link href="https://github.com/awslabs/llrt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LLRT (Low Latency Runtime) is an experimental, lightweight JavaScript runtime designed to address the growing demand for fast and efficient Serverless applications.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/awslabs/llrt/actions/workflows/ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/awslabs/llrt/actions/workflows/ci.yml/badge.svg?branch=main&#34; alt=&#34;LLRT CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/awslabs/llrt/actions/workflows/release.yml&#34;&gt;&lt;img src=&#34;https://github.com/awslabs/llrt/actions/workflows/release.yml/badge.svg?sanitize=true&#34; alt=&#34;LLRT Release&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;LLRT (&lt;strong&gt;L&lt;/strong&gt;ow &lt;strong&gt;L&lt;/strong&gt;atency &lt;strong&gt;R&lt;/strong&gt;un&lt;strong&gt;t&lt;/strong&gt;ime) is a lightweight JavaScript runtime designed to address the growing demand for fast and efficient Serverless applications. LLRT offers up to over &lt;strong&gt;10x&lt;/strong&gt; faster startup and up to &lt;strong&gt;2x&lt;/strong&gt; overall lower cost compared to other JavaScript runtimes running on &lt;strong&gt;AWS Lambda&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s built in Rust, utilizing QuickJS as JavaScript engine, ensuring efficient memory usage and swift startup.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!WARNING] LLRT is an &lt;strong&gt;experimental&lt;/strong&gt; package. It is subject to change and intended only for evaluation purposes.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;sub&gt;LLRT - &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/llrt/main/example/functions/src/v3-lib.mjs&#34;&gt;DynamoDB Put, ARM, 128MB&lt;/a&gt;:&lt;sub&gt; &lt;img src=&#34;https://raw.githubusercontent.com/awslabs/llrt/main/benchmarks/llrt-ddb-put.png&#34; alt=&#34;DynamoDB Put LLRT&#34; title=&#34;LLRT DynamoDB Put&#34;&gt;&lt;/sub&gt;&lt;/sub&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;sub&gt;Node.js 20 - &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/llrt/main/example/functions/src/v3-lib.mjs&#34;&gt;DynamoDB Put, ARM, 128MB&lt;/a&gt;:&lt;sub&gt; &lt;img src=&#34;https://raw.githubusercontent.com/awslabs/llrt/main/benchmarks/node20-ddb-put.png&#34; alt=&#34;DynamoDB Put Node20&#34; title=&#34;Node20 DynamoDB Put&#34;&gt;&lt;/sub&gt;&lt;/sub&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Configure Lambda functions to use LLRT&lt;/h2&gt; &#xA;&lt;p&gt;Download the last LLRT release from &lt;a href=&#34;https://github.com/awslabs/llrt/releases&#34;&gt;https://github.com/awslabs/llrt/releases&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Option 1: Custom runtime (recommended)&lt;/h3&gt; &#xA;&lt;p&gt;Choose &lt;code&gt;Custom Runtime on Amazon Linux 2023&lt;/code&gt; and package the LLRT &lt;code&gt;bootstrap&lt;/code&gt; binary together with your JS code.&lt;/p&gt; &#xA;&lt;h3&gt;Option 2: Use a layer&lt;/h3&gt; &#xA;&lt;p&gt;Choose &lt;code&gt;Custom Runtime on Amazon Linux 2023&lt;/code&gt;, upload &lt;code&gt;llrt-lambda-arm64.zip&lt;/code&gt; or &lt;code&gt;llrt-lambda-x86.zip&lt;/code&gt; as a layer and add to your function&lt;/p&gt; &#xA;&lt;p&gt;Thats it 🎉&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT] Even though LLRT supports &lt;a href=&#34;https://262.ecma-international.org/11.0/&#34;&gt;ES2020&lt;/a&gt; it&#39;s &lt;strong&gt;NOT&lt;/strong&gt; a drop in replacement for Node.js. Consult &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/llrt/main/#compatibility-matrix&#34;&gt;Compatibility matrix&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/llrt/main/API.md&#34;&gt;API&lt;/a&gt; for more details. All dependencies should be bundled for a &lt;code&gt;browser&lt;/code&gt; platform and mark included &lt;code&gt;@aws-sdk&lt;/code&gt; packages as external.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Testing &amp;amp; ensuring compatibility&lt;/h2&gt; &#xA;&lt;p&gt;The best way to ensure that your code is compatible with LLRT is to write tests and executing them via the built in test runner&lt;/p&gt; &#xA;&lt;h3&gt;Test runner&lt;/h3&gt; &#xA;&lt;p&gt;Test runner uses a lightweight Jest-like API and uses the &lt;a href=&#34;https://nodejs.org/api/assert.html&#34;&gt;assert module&lt;/a&gt; from Node.js for test assertions. For examples how to implement tests for LLRT see the &lt;code&gt;/tests&lt;/code&gt; folder of this repository.&lt;/p&gt; &#xA;&lt;p&gt;To run tests, execute the &lt;code&gt;llrt test&lt;/code&gt; command. LLRT scans the current directory and sub-directories for files that ends with &lt;code&gt;*.test.js&lt;/code&gt; or &lt;code&gt;*.test.mjs&lt;/code&gt;. You can also provide a specific test directory to scan by using the &lt;code&gt;llrt test -d &amp;lt;directory&amp;gt;&lt;/code&gt; option.&lt;/p&gt; &#xA;&lt;p&gt;The test runner also has support for filters. Using filters is as simple as adding additional command line arguments, i.e: &lt;code&gt;llrt test crypto&lt;/code&gt; will only run tests that match the filename containing &lt;code&gt;crypto&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Compatibility matrix&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] LLRT only support a fraction of the Node.js APIs. It is &lt;strong&gt;NOT&lt;/strong&gt; a drop in replacement for Node.js, nor will it ever be. Below is a high level overview of partially supported APIs and modules. For more details consult the &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/llrt/main/API.md&#34;&gt;API&lt;/a&gt; documentation&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;Node.js&lt;/th&gt; &#xA;   &lt;th&gt;LLRT ⚠️&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;buffer&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎️&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;streams&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;child_process&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎⏱&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;net:sockets&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎⏱&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;net:server&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;tls&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✘⏱&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;fetch&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;http&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✘⏱**&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;https&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✘⏱**&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;fs/promises&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;fs&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✘⏱&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;path&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;timers&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;uuid&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;crypto&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;process&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;encoding&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;console&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;events&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ESM&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CJS&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;async/await&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Other modules&lt;/td&gt; &#xA;   &lt;td&gt;✔︎&lt;/td&gt; &#xA;   &lt;td&gt;✘&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;em&gt;⚠️ = partially supported in LLRT&lt;/em&gt; &lt;em&gt;⏱ = planned partial support&lt;/em&gt; &lt;em&gt;* = Not native&lt;/em&gt; &lt;em&gt;** = Use fetch instead&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Using node_modules (dependencies) with LLRT&lt;/h2&gt; &#xA;&lt;p&gt;Since LLRT is meant for performance critical application it&#39;s not recommended to deploy &lt;code&gt;node_modules&lt;/code&gt; without bundling, minification and tree-shaking.&lt;/p&gt; &#xA;&lt;p&gt;LLRT can work with any bundler of your choice. Below are some configurations for popular bundlers:&lt;/p&gt; &#xA;&lt;h3&gt;ESBuild&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;esbuild index.js --platform=node --target=es2020 --format=esm --bundle --minify --external:@aws-sdk --external:uuid&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Rollup&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import resolve from &#39;rollup-plugin-node-resolve&#39;;&#xA;import commonjs from &#39;rollup-plugin-commonjs&#39;;&#xA;import { terser } from &#39;rollup-plugin-terser&#39;;&#xA;&#xA;export default {&#xA;  input: &#39;index.js&#39;,&#xA;  output: {&#xA;    file: &#39;dist/bundle.js&#39;,&#xA;    format: &#39;esm&#39;,&#xA;    sourcemap: true,&#xA;    target: &#39;es2020&#39;,&#xA;  },&#xA;  plugins: [&#xA;    resolve(), &#xA;    commonjs(),&#xA;    terser(), &#xA;  ],&#xA;  external: [&#34;@aws-sdk&#34;,&#34;uuid&#34;],&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Webpack&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import TerserPlugin from &#39;terser-webpack-plugin&#39;;&#xA;import nodeExternals from &#39;webpack-node-externals&#39;;&#xA;&#xA;export default {&#xA;  entry: &#39;./index.js&#39;, &#xA;  output: {&#xA;    path: &#34;dist&#34;,&#xA;    filename: &#39;bundle.js&#39;,&#xA;    libraryTarget: &#39;module&#39;, &#xA;  },&#xA;  target: &#39;web&#39;, &#xA;  mode: &#39;production&#39;,&#xA;  resolve: {&#xA;    extensions: [&#39;.js&#39;],&#xA;  },&#xA;  externals: [nodeExternals(),&#34;@aws-sdk&#34;,&#34;uuid&#34;],&#xA;  optimization: {&#xA;    minimize: true,&#xA;    minimizer: [&#xA;      new TerserPlugin({&#xA;        terserOptions: {&#xA;          ecma: 2020, &#xA;        },&#xA;      }),&#xA;    ],&#xA;  },&#xA;};&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Using AWS SDK (v3) with LLRT&lt;/h2&gt; &#xA;&lt;p&gt;LLRT includes many AWS SDK clients and utils as part of the runtime, built into the executable. These SDK Clients have been specifically fine-tuned to offer best performance while not compromising on compatibility. LLRT replaces some JavaScript dependencies used by the AWS SDK by native ones such as Hash calculations and XML parsing. V3 SDK packages not included in the list below have to be bundled with your source code while marking the following packages as external.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bundled AWS SDK packages:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;@aws-sdk/client-dynamodb&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/lib-dynamodb&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-kms&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-lambda&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-s3&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-secrets-manager&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-ses&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-sns&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-sqs&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-sts&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-ssm&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-cloudwatch-logs&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-cloudwatch-events&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-eventbridge&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-sfn&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-xray&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/client-cognito-identity&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/util-dynamodb&lt;/li&gt; &#xA; &lt;li&gt;@aws-sdk/credential-providers&lt;/li&gt; &#xA; &lt;li&gt;@smithy/signature-v4&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Running TypeScript with LLRT&lt;/h2&gt; &#xA;&lt;p&gt;Same principle as dependencies applies when using TypeScript. TypeScript must be bundled and transpiled into ES2020 JavaScript.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] LLRT will not support running TypeScript without transpilation. This is by design for performance reasons. Transpiling requires CPU and memory that adds latency and cost during execution. This can be avoided if done ahead of time during deployment.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Rationale&lt;/h2&gt; &#xA;&lt;p&gt;What justifies the introduction of another JavaScript runtime in light of existing options such as &lt;a href=&#34;https://nodejs.org/en&#34;&gt;Node.js&lt;/a&gt;, &lt;a href=&#34;https://bun.sh&#34;&gt;Bun&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://deno.com/&#34;&gt;Deno&lt;/a&gt;?&lt;/p&gt; &#xA;&lt;p&gt;Node.js, Bun, and Deno represent highly proficient JavaScript runtimes. However, they are designed with general-purpose applications in mind. These runtimes were not specifically tailored for the demands of a Serverless environment, characterized by short-lived runtime instances. They each depend on a (&lt;a href=&#34;https://en.wikipedia.org/wiki/Just-in-time_compilation&#34;&gt;Just-In-Time compiler (JIT)&lt;/a&gt; for dynamic code compilation and optimization during execution. While JIT compilation offers substantial long-term performance advantages, it carries a computational and memory overhead.&lt;/p&gt; &#xA;&lt;p&gt;In contrast, LLRT distinguishes itself by not incorporating a JIT compiler, a strategic decision that yields two significant advantages:&lt;/p&gt; &#xA;&lt;p&gt;A) JIT compilation is a notably sophisticated technological component, introducing increased system complexity and contributing substantially to the runtime&#39;s overall size.&lt;/p&gt; &#xA;&lt;p&gt;B) Without the JIT overhead, LLRT conserves both CPU and memory resources that can be more efficiently allocated to code execution tasks, thereby reducing application startup times.&lt;/p&gt; &#xA;&lt;h2&gt;Limitations&lt;/h2&gt; &#xA;&lt;p&gt;There are many cases where LLRT shows notable performance drawbacks compared with JIT-powered runtimes, such as large data processing, Monte Carlo simulations or performing tasks with hundreds of thousands or millions of iterations. LLRT is most effective when applied to smaller Serverless functions dedicated to tasks such as data transformation, real time processing, AWS service integrations, authorization, validation etc. It is designed to complement existing components rather than serve as a comprehensive replacement for everything. Notably, given its supported APIs are based on Node.js specification, transitioning back to alternative solutions requires minimal code adjustments.&lt;/p&gt; &#xA;&lt;h2&gt;Building from source&lt;/h2&gt; &#xA;&lt;p&gt;Clone code and cd to directory&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:awslabs/llrt.git --recursive&#xA;cd llrt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install rust&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | bash -s -- -y&#xA;source &#34;$HOME/.cargo/env&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install dependencies&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# MacOS&#xA;brew install zig make zstd node corepack&#xA;&#xA;# Ubuntu&#xA;sudo apt -y install make zstd&#xA;sudo snap install zig --classic --beta&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install Node.js packages&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;corepack enable&#xA;yarn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install generate libs and setup rust targets &amp;amp; toolchains&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make stdlib &amp;amp;&amp;amp; make libs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Build release for Lambda&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make release-arm64&#xA;# or for x86-64, use&#xA;make release-x64&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Optionally build for your local machine (Mac or Linux)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You should now have a &lt;code&gt;llrt-lambda-arm64.zip&lt;/code&gt; or &lt;code&gt;llrt-lambda-x86.zip&lt;/code&gt;. You can manually upload this as a Lambda layer or use it via your Infrastructure-as-code pipeline&lt;/p&gt; &#xA;&lt;h2&gt;Running Lambda emulator&lt;/h2&gt; &#xA;&lt;p&gt;Please note that in order to run the example you will need:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Valid AWS credentials via a &lt;code&gt;~/.aws/credentials&lt;/code&gt; or via environment variables.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export AWS_ACCESS_KEY_ID=XXX&#xA;export AWS_SECRET_ACCESS_KEY=YYY&#xA;export AWS_REGION=us-east-1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A DynamoDB table (with &lt;code&gt;id&lt;/code&gt; as the partition key) on &lt;code&gt;us-east-1&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;The &lt;code&gt;dynamodb:PutItem&lt;/code&gt; IAM permission on this table. You can use this policy (don&#39;t forget to modify &amp;lt;YOUR_ACCOUNT_ID&amp;gt;):&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;&#x9;&#34;Version&#34;: &#34;2012-10-17&#34;,&#xA;&#x9;&#34;Statement&#34;: [&#xA;&#x9;&#x9;{&#xA;&#x9;&#x9;&#x9;&#34;Sid&#34;: &#34;putItem&#34;,&#xA;&#x9;&#x9;&#x9;&#34;Effect&#34;: &#34;Allow&#34;,&#xA;&#x9;&#x9;&#x9;&#34;Action&#34;: &#34;dynamodb:PutItem&#34;,&#xA;&#x9;&#x9;&#x9;&#34;Resource&#34;: &#34;arn:aws:dynamodb:us-east-1:&amp;lt;YOUR_ACCOUNT_ID&amp;gt;:table/quickjs-table&#34;&#xA;&#x9;&#x9;}&#xA;&#x9;]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Start the &lt;code&gt;lambda-server.js&lt;/code&gt; in a separate terminal&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;node lambda-server.js&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then run llrt:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Security&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/llrt/main/CONTRIBUTING.md#security-issue-notifications&#34;&gt;CONTRIBUTING&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This library is licensed under the MIT-0 License. See the &lt;a href=&#34;https://raw.githubusercontent.com/awslabs/llrt/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>metavoiceio/metavoice-src</title>
    <updated>2024-02-11T01:25:39Z</updated>
    <id>tag:github.com,2024-02-11:/metavoiceio/metavoice-src</id>
    <link href="https://github.com/metavoiceio/metavoice-src" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Foundational model for human-like, emotive TTS&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MetaVoice-1B&lt;/h1&gt; &#xA;&lt;p&gt;MetaVoice-1B is a 1.2B parameter base model trained on 100K hours of speech for TTS (text-to-speech). It has been built with the following priorities:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Emotional speech rhythm and tone&lt;/strong&gt; in English. No hallucinations.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Zero-shot cloning for American &amp;amp; British voices&lt;/strong&gt;, with 30s reference audio.&lt;/li&gt; &#xA; &lt;li&gt;Support for (cross-lingual) &lt;strong&gt;voice cloning with finetuning&lt;/strong&gt;. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;We have had success with as little as 1 minute training data for Indian speakers.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Support for &lt;strong&gt;long-form synthesis&lt;/strong&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We’re releasing MetaVoice-1B under the Apache 2.0 license, &lt;em&gt;it can be used without restrictions&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Try out the &lt;a href=&#34;https://ttsdemo.themetavoice.xyz/&#34;&gt;demo&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pre-requisites:&lt;/strong&gt; Python &amp;gt;=3.10,&amp;lt;3.12; GPU with &amp;gt;=24GB RAM.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# install ffmpeg&#xA;wget https://johnvansickle.com/ffmpeg/builds/ffmpeg-git-amd64-static.tar.xz&#xA;wget https://johnvansickle.com/ffmpeg/builds/ffmpeg-git-amd64-static.tar.xz.md5&#xA;md5sum -c ffmpeg-git-amd64-static.tar.xz.md5&#xA;tar xvf ffmpeg-git-amd64-static.tar.xz&#xA;sudo mv ffmpeg-git-*-static/ffprobe ffmpeg-git-*-static/ffmpeg /usr/local/bin/&#xA;rm -rf ffmpeg-git-*&#xA;&#xA;pip install -r requirements.txt&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download it and use it anywhere (including locally) with our &lt;a href=&#34;https://raw.githubusercontent.com/metavoiceio/metavoice-src/main/fam/llm/sample.py&#34;&gt;reference implementation&lt;/a&gt;,&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python fam/llm/sample.py --huggingface_repo_id=&#34;metavoiceio/metavoice-1B-v0.1&#34; --spk_cond_path=&#34;assets/bria.mp3&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Deploy it on any cloud (AWS/GCP/Azure), using our &lt;a href=&#34;https://raw.githubusercontent.com/metavoiceio/metavoice-src/main/fam/llm/serving.py&#34;&gt;inference server&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python fam/llm/serving.py --huggingface_repo_id=&#34;metavoiceio/metavoice-1B-v0.1&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Use it via &lt;a href=&#34;https://huggingface.co/metavoiceio&#34;&gt;Hugging Face&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Soon&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Long form TTS&lt;/li&gt; &#xA; &lt;li&gt;Fine-tuning code&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Architecture&lt;/h2&gt; &#xA;&lt;p&gt;We predict EnCodec tokens from text, and speaker information. This is then diffused up to the waveform level, with post-processing applied to clean up the audio.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;We use a causal GPT to predict the first two hierarchies of EnCodec tokens. Text and audio are part of the LLM context. Speaker information is passed via conditioning at the token embedding layer. This speaker conditioning is obtained from a separately trained speaker verification network. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The two hierarchies are predicted in a &#34;flattened interleaved&#34; manner, we predict the first token of the first hierarchy, then the first token of the second hierarchy, then the second token of the first hierarchy, and so on.&lt;/li&gt; &#xA;   &lt;li&gt;We use condition-free sampling to boost the cloning capability of the model.&lt;/li&gt; &#xA;   &lt;li&gt;The text is tokenised using a custom trained BPE tokeniser with 512 tokens.&lt;/li&gt; &#xA;   &lt;li&gt;Note that we&#39;ve skipped predicting semantic tokens as done in other works, as we found that this isn&#39;t strictly necessary.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;We use a non-causal (encoder-style) transformer to predict the rest of the 6 hierarchies from the first two hierarchies. This is a super small model (~10Mn parameters), and has extensive zero-shot generalisation to most speakers we&#39;ve tried. Since it&#39;s non-causal, we&#39;re also able to predict all the timesteps in parallel.&lt;/li&gt; &#xA; &lt;li&gt;We use multi-band diffusion to generate waveforms from the EnCodec tokens. We noticed that the speech is clearer than using the original RVQ decoder or VOCOS. However, the diffusion at waveform level leaves some background artifacts which are quite unpleasant to the ear. We clean this up in the next step.&lt;/li&gt; &#xA; &lt;li&gt;We use DeepFilterNet to clear up the artifacts introduced by the multi-band diffusion.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Optimizations&lt;/h2&gt; &#xA;&lt;p&gt;The model supports:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;KV-caching via Flash Decoding&lt;/li&gt; &#xA; &lt;li&gt;Batching (including texts of different lengths)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Contribute&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;See all &lt;a href=&#34;https://github.com/metavoiceio/metavoice-src/issues&#34;&gt;active issues&lt;/a&gt;!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;We are grateful to Together.ai for their 24/7 help in marshalling our cluster. We thank the teams of AWS, GCP &amp;amp; Hugging Face for support with their cloud platforms.&lt;/p&gt;</summary>
  </entry>
</feed>