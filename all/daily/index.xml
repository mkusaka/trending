<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-06-23T01:28:51Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>niedev/RTranslator</title>
    <updated>2024-06-23T01:28:51Z</updated>
    <id>tag:github.com,2024-06-23:/niedev/RTranslator</id>
    <link href="https://github.com/niedev/RTranslator" rel="alternate"></link>
    <summary type="html">&lt;p&gt;RTranslator is the world&#39;s first open source real-time translation app.&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://github.com/niedev/RTranslator/raw/v2.00/images/logo_beta_cut.png&#34; width=&#34;280&#34;&gt; &#xA;&lt;p&gt;RTranslator is an (&lt;a href=&#34;https://github.com/niedev/RTranslator?tab=readme-ov-file#libraries-and-models&#34;&gt;almost&lt;/a&gt;) open-source, free, and offline real-time translation app for Android.&lt;/p&gt; &#xA;&lt;p&gt;Connect to someone who has the app, connect Bluetooth headphones, put the phone in your pocket and you can have a conversation as if the other person spoke your language. &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/niedev/RTranslator/raw/v2.00/images/Conversation_image.png&#34; alt=&#34;Conversation mode&#34;&gt; &lt;br&gt;&lt;br&gt; &lt;img src=&#34;https://github.com/niedev/RTranslator/raw/v2.00/images/TextTranslation_and_WalkieTalkie.png&#34; alt=&#34;WalkieTalkie mode and Costs&#34;&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Conversation mode&lt;/h3&gt; &#xA;&lt;p&gt;The Conversation mode is the main feature of RTranslator. In this mode, you can connect with another phone that uses this app. If the user accepts your connection request:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;When you talk, your phone (or the Bluetooth headset, if connected) will capture the audio.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The audio captured will be converted into text and sent to the interlocutor&#39;s phone.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The interlocutors&#39; phone will translate the text received into his language.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The interlocutors&#39; phone will convert the translated text into audio and will reproduce it from its speaker (or by the Bluetooth headset of the interlocutor if connected to his phone).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All this in both directions.&lt;/p&gt; &#xA;&lt;p&gt;Each user can have more than one connected phone so that you can translate conversations between more than two people and in any combination. &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;WalkieTalkie mode&lt;/h3&gt; &#xA;&lt;p&gt;If conversation mode is useful for having a long conversation with someone, this mode instead is designed for quick conversations, such as asking for information on the street or talking to a shop assistant.&lt;/p&gt; &#xA;&lt;p&gt;This mode only translates conversations between two people, it doesn&#39;t work with Bluetooth headsets, and you have to talk in turns. It&#39;s not a real simultaneous translation, but it can work with only one phone.&lt;/p&gt; &#xA;&lt;p&gt;In this mode, the smartphone microphone will listen in two languages (selectable in the same screen of the walkie talkie mode) simultaneously. &lt;br&gt; The app will detect in which language the interlocutor is speaking, translate the audio into the other language, convert the text into audio, and then reproduce it from the phone speaker. When the TTS has finished, it will automatically resume listening. &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Text translation mode&lt;/h3&gt; &#xA;&lt;p&gt;This mode is just a classic text translator, but always useful. &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;General&lt;/h3&gt; &#xA;&lt;p&gt;RTranslator uses &lt;a href=&#34;https://ai.meta.com/research/no-language-left-behind/&#34;&gt;Meta&#39;s NLLB&lt;/a&gt; for translation and &lt;a href=&#34;https://openai.com/index/whisper/&#34;&gt;OpenAi&#39;s Whisper&lt;/a&gt; for speech recognition, both are (&lt;a href=&#34;https://github.com/niedev/RTranslator?tab=readme-ov-file#libraries-and-models&#34;&gt;almost&lt;/a&gt;) open-source and state of the art AIs, have excellent quality and run directly on the phone, ensuring absolute privacy and the possibility of using RTranslator even offline without loss of quality.&lt;/p&gt; &#xA;&lt;p&gt;Also, RTranslator works even in the background, with the phone on standby or when using other apps (only when you use Conversation or WalkieTalkie modes). However, some phones limit the power in the background so in that case it is better to avoid it and keep the app open with the screen on.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.producthunt.com/posts/rtranslator?utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-rtranslator&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=274849&amp;amp;theme=light&#34; alt=&#34;RTranslator - World&#39;s first open-source simultaneous translation app. | Product Hunt&#34; style=&#34;width: 250px; height: 80px;&#34;&gt;&lt;/a&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;What&#39;s new in version 2.0&lt;/h3&gt; &#xA;&lt;p&gt;The Google API&#39;s have been replaced by &lt;a href=&#34;https://ai.meta.com/research/no-language-left-behind/&#34;&gt;Meta&#39;s NLLB&lt;/a&gt; for translation and &lt;a href=&#34;https://openai.com/index/whisper/&#34;&gt;OpenAi&#39;s Whisper&lt;/a&gt; for speech recognition. These AI models run directly on your phone, so now the app is totally free and with no configuration required!&lt;/p&gt; &#xA;&lt;p&gt;A classic text translation mode has been added.&lt;/p&gt; &#xA;&lt;p&gt;Bluetooth LE device search has been improved.&lt;/p&gt; &#xA;&lt;p&gt;Fixed some bugs. &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Performance&lt;/h3&gt; &#xA;&lt;p&gt;I have optimized the AI models a lot to minimize RAM consumption and execution time, despite this however to be able to use the app without the risk of crashing you need a phone with at least &lt;strong&gt;6GB of RAM&lt;/strong&gt;, and to have a good enough execution time you need a phone with a fast enough CPU.&lt;/p&gt; &#xA;&lt;p&gt;If you have a pretty crappy phone (or if you want maximum speed) you can always use &lt;a href=&#34;https://github.com/niedev/RTranslator/tree/v1.00&#34;&gt;version 1.0 of RTranslator&lt;/a&gt; (but since it uses Google APIs it&#39;s not free and needs some initial setup). &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Download&lt;/h3&gt; &#xA;&lt;p&gt;To install the app, download the latest version of the app apk file from &lt;a href=&#34;https://github.com/niedev/RTranslator/releases/&#34;&gt;https://github.com/niedev/RTranslator/releases/&lt;/a&gt; and install it (ignore the other files, those will be downloaded automatically by the app on the first start).&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/niedev/RTranslator/releases&#34;&gt;&lt;img alt=&#34;Get it on GitHub&#34; src=&#34;https://github.com/niedev/RTranslator/raw/v2.00/images/get_it_on_github.png&#34; style=&#34;width: 180px; height: 58px;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;On the first launch, you will need to download the models for translation and speech recognition (1.2GB) and once done you can start translating. &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Supported languages&lt;/h3&gt; &#xA;&lt;p&gt;The languages supported are as follows:&lt;/p&gt; &#xA;&lt;p&gt;Arabic, Bulgarian, Catalan, Chinese, Czech, Danish, German, Greek, English, Spanish, Finnish, French, Croatian, Italian, Japanese, Korean, Dutch, Polish, Portuguese, Romanian, Russian, Slovak, Swedish, Tamil, Thai, Turkish, Ukrainian, Urdu, Vietnamese. &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Privacy&lt;/h3&gt; &#xA;&lt;p&gt;Privacy is a fundamental right. That&#39;s why RTranslator does not collect any personal data (I don&#39;t even have a server). For more information, read the &lt;a href=&#34;https://github.com/niedev/RTranslator/raw/v2.00/privacy/Privacy_Policy_en.md&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;privacy policy&lt;/a&gt; (for now is the same privacy policy of RTranslator 1.0, but I will update it in the future). &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Libraries and models&lt;/h3&gt; &#xA;&lt;p&gt;RTranslator code is completely open-source, but some of the external libraries it uses have less permissive licenses, these are all the external libraries used by the app (with the indication of their license):&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/niedev/BluetoothCommunicator&#34;&gt;BluetoothCommunicator&lt;/a&gt; (open-source): Used for Bluetooth LE communication between devices.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/niedev/GalleryImageSelector&#34;&gt;GalleryImageSelector&lt;/a&gt; (open-source): Used for selecting and cropping the profile image from the gallery.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/onnxruntime&#34;&gt;OnnxRuntime&lt;/a&gt; (open-source): Used as an accelerator engine for the AI models.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/google/sentencepiece&#34;&gt;SentencePiece&lt;/a&gt; (open-source): Used for tokenization of the input text for NLLB.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://developers.google.com/ml-kit/language/identification&#34;&gt;Ml Kit&lt;/a&gt; (closed-source): Used for the identification of the language in the WalkieTalkie mode. &lt;br&gt;&lt;br&gt; And the following AI models:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/facebookresearch/fairseq/tree/nllb&#34;&gt;NLLB&lt;/a&gt; (open-source, but only for non-commercial use): The model used is NLLB-Distilled-600M with KV cache.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/openai/whisper&#34;&gt;Whisper&lt;/a&gt; (open-source): The model used is Whisper-Small-244M with KV cache.&lt;/p&gt; &#xA;&lt;p&gt;I converted both models to onnx format and quantized them in int8 (excluding some weights to ensure almost zero quality loss), also I separated some parts of the models to reduce RAM consumption (without this separation some weights were duplicated at runtime consuming more RAM than expected). &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Donations&lt;/h3&gt; &#xA;&lt;p&gt;This is an open-source and completely ad-free app, I don&#39;t make any money from it.&lt;/p&gt; &#xA;&lt;p&gt;So, if you like the app and want to say thank you and support the project, you can make a donation via PayPal by clicking on the button below (any amount is well accepted).&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.paypal.com/donate/?business=3VBKS3WC6AFHN&amp;amp;no_recurring=0&amp;amp;currency_code=EUR&#34;&gt;&lt;img alt=&#34;Donate&#34; src=&#34;https://raw.githubusercontent.com/niedev/RTranslator/v2.00/images/Paypal.png&#34; style=&#34;width: 190px; height: 80px;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;In case you will donate, or just live a star, thank you &lt;span&gt;❤️&lt;/span&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Bugs and problems&lt;/h3&gt; I remind you that the app is still in beta. The bugs found are the following: &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For some languages, the TTS does not work. Reinstall the text-to-speech engine to solve.&lt;/li&gt; &#xA; &lt;li&gt;Sometimes the Bluetooth connection drops.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you have found any bug please report it by opening an issue, or by writing an email to &lt;a href=&#34;mailto:contact.niedev@gmail.com&#34;&gt;contact.niedev@gmail.com&lt;/a&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;Enjoy your simultaneous translator.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>karpathy/micrograd</title>
    <updated>2024-06-23T01:28:51Z</updated>
    <id>tag:github.com,2024-06-23:/karpathy/micrograd</id>
    <link href="https://github.com/karpathy/micrograd" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A tiny scalar-valued autograd engine and a neural net library on top of it with PyTorch-like API&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;micrograd&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/karpathy/micrograd/master/puppy.jpg&#34; alt=&#34;awww&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;A tiny Autograd engine (with a bite! :)). Implements backpropagation (reverse-mode autodiff) over a dynamically built DAG and a small neural networks library on top of it with a PyTorch-like API. Both are tiny, with about 100 and 50 lines of code respectively. The DAG only operates over scalar values, so e.g. we chop up each neuron into all of its individual tiny adds and multiplies. However, this is enough to build up entire deep neural nets doing binary classification, as the demo notebook shows. Potentially useful for educational purposes.&lt;/p&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install micrograd&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Example usage&lt;/h3&gt; &#xA;&lt;p&gt;Below is a slightly contrived example showing a number of possible supported operations:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from micrograd.engine import Value&#xA;&#xA;a = Value(-4.0)&#xA;b = Value(2.0)&#xA;c = a + b&#xA;d = a * b + b**3&#xA;c += c + 1&#xA;c += 1 + c + (-a)&#xA;d += d * 2 + (b + a).relu()&#xA;d += 3 * d + (b - a).relu()&#xA;e = c - d&#xA;f = e**2&#xA;g = f / 2.0&#xA;g += 10.0 / f&#xA;print(f&#39;{g.data:.4f}&#39;) # prints 24.7041, the outcome of this forward pass&#xA;g.backward()&#xA;print(f&#39;{a.grad:.4f}&#39;) # prints 138.8338, i.e. the numerical value of dg/da&#xA;print(f&#39;{b.grad:.4f}&#39;) # prints 645.5773, i.e. the numerical value of dg/db&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Training a neural net&lt;/h3&gt; &#xA;&lt;p&gt;The notebook &lt;code&gt;demo.ipynb&lt;/code&gt; provides a full demo of training an 2-layer neural network (MLP) binary classifier. This is achieved by initializing a neural net from &lt;code&gt;micrograd.nn&lt;/code&gt; module, implementing a simple svm &#34;max-margin&#34; binary classification loss and using SGD for optimization. As shown in the notebook, using a 2-layer neural net with two 16-node hidden layers we achieve the following decision boundary on the moon dataset:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/karpathy/micrograd/master/moon_mlp.png&#34; alt=&#34;2d neuron&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Tracing / visualization&lt;/h3&gt; &#xA;&lt;p&gt;For added convenience, the notebook &lt;code&gt;trace_graph.ipynb&lt;/code&gt; produces graphviz visualizations. E.g. this one below is of a simple 2D neuron, arrived at by calling &lt;code&gt;draw_dot&lt;/code&gt; on the code below, and it shows both the data (left number in each node) and the gradient (right number in each node).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from micrograd import nn&#xA;n = nn.Neuron(2)&#xA;x = [Value(1.0), Value(-2.0)]&#xA;y = n(x)&#xA;dot = draw_dot(y)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/karpathy/micrograd/master/gout.svg?sanitize=true&#34; alt=&#34;2d neuron&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Running tests&lt;/h3&gt; &#xA;&lt;p&gt;To run the unit tests you will have to install &lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt;, which the tests use as a reference for verifying the correctness of the calculated gradients. Then simply:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m pytest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;License&lt;/h3&gt; &#xA;&lt;p&gt;MIT&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>influxdata/telegraf</title>
    <updated>2024-06-23T01:28:51Z</updated>
    <id>tag:github.com,2024-06-23:/influxdata/telegraf</id>
    <link href="https://github.com/influxdata/telegraf" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://raw.githubusercontent.com/influxdata/telegraf/master/assets/TelegrafTigerSmall.png&#34; alt=&#34;tiger&#34; title=&#34;tiger&#34;&gt; Telegraf&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://godoc.org/github.com/influxdata/telegraf&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/doc-reference-00ADD8.svg?logo=go&#34; alt=&#34;GoDoc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/_/telegraf/&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/library/telegraf.svg?sanitize=true&#34; alt=&#34;Docker pulls&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://goreportcard.com/report/github.com/influxdata/telegraf&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/influxdata/telegraf&#34; alt=&#34;Go Report Card&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://circleci.com/gh/influxdata/telegraf&#34;&gt;&lt;img src=&#34;https://circleci.com/gh/influxdata/telegraf.svg?style=svg&#34; alt=&#34;Circle CI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Telegraf is an agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Offers a comprehensive suite of over 300 plugins, covering a wide range of functionalities including system monitoring, cloud services, and message passing&lt;/li&gt; &#xA; &lt;li&gt;Enables the integration of user-defined code to collect, transform, and transmit data efficiently&lt;/li&gt; &#xA; &lt;li&gt;Compiles into a standalone static binary without any external dependencies, ensuring a streamlined deployment process&lt;/li&gt; &#xA; &lt;li&gt;Utilizes TOML for configuration, providing a user-friendly and unambiguous setup experience&lt;/li&gt; &#xA; &lt;li&gt;Developed with contributions from a diverse community of over 1,200 contributors&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Users can choose plugins from a wide range of topics, including but not limited to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Devices: &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opcua&#34;&gt;OPC UA&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/modbus&#34;&gt;Modbus&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Logs: &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/file&#34;&gt;File&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/tail&#34;&gt;Tail&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/directory_monitor&#34;&gt;Directory Monitor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Messaging: &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/amqp_consumer&#34;&gt;AMQP&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/kafka_consumer&#34;&gt;Kafka&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mqtt_consumer&#34;&gt;MQTT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Monitoring: &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opentelemetry&#34;&gt;OpenTelemetry&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/prometheus&#34;&gt;Prometheus&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Networking: &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cisco_telemetry_mdt&#34;&gt;Cisco TelemetryMDT&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/gnmi&#34;&gt;gNMI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;System monitoring: &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cpu&#34;&gt;CPU&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mem&#34;&gt;Memory&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/disk&#34;&gt;Disk&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/net&#34;&gt;Network&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/smartctl&#34;&gt;SMART&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker&#34;&gt;Docker&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/nvidia_smi&#34;&gt;Nvidia SMI&lt;/a&gt;, etc.&lt;/li&gt; &#xA; &lt;li&gt;Universal: &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/exec&#34;&gt;Exec&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http&#34;&gt;HTTP&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http_listener_v2&#34;&gt;HTTP Listener&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/snmp&#34;&gt;SNMP&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/sql&#34;&gt;SQL&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Windows: &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_eventlog&#34;&gt;Event Log&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_wmi&#34;&gt;Management Instrumentation&lt;/a&gt;, &lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters&#34;&gt;Performance Counters&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🔨 Installation&lt;/h2&gt; &#xA;&lt;p&gt;For binary builds, Docker images, RPM &amp;amp; DEB packages, and other builds of Telegraf, please see the &lt;a href=&#34;https://raw.githubusercontent.com/influxdata/telegraf/master/docs/INSTALL_GUIDE.md&#34;&gt;install guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/influxdata/telegraf/master/docs/RELEASES.md&#34;&gt;releases documentation&lt;/a&gt; for details on versioning and when releases are made.&lt;/p&gt; &#xA;&lt;h2&gt;💻 Usage&lt;/h2&gt; &#xA;&lt;p&gt;Users define a TOML configuration with the plugins and settings they wish to use, then pass that configuration to Telegraf. The Telegraf agent then collects data from inputs at each interval and sends data to outputs at each flush interval.&lt;/p&gt; &#xA;&lt;p&gt;For a basic walkthrough see &lt;a href=&#34;https://raw.githubusercontent.com/influxdata/telegraf/master/docs/QUICK_START.md&#34;&gt;quick start&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;📖 Documentation&lt;/h2&gt; &#xA;&lt;p&gt;For a full list of documentation including tutorials, reference and other material, start with the &lt;a href=&#34;https://raw.githubusercontent.com/influxdata/telegraf/master/docs/README.md&#34;&gt;/docs directory&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Additionally, each plugin has its own README that includes details about how to configure, use, and sometimes debug or troubleshoot. Look under the &lt;a href=&#34;https://raw.githubusercontent.com/influxdata/telegraf/master/plugins/&#34;&gt;/plugins directory&lt;/a&gt; for specific plugins.&lt;/p&gt; &#xA;&lt;p&gt;Here are some commonly used documents:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/influxdata/telegraf/master/CHANGELOG.md&#34;&gt;Changelog&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/influxdata/telegraf/master/docs/CONFIGURATION.md&#34;&gt;Configuration&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/influxdata/telegraf/master/docs/FAQ.md&#34;&gt;FAQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/influxdata/telegraf/releases&#34;&gt;Releases&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/influxdata/telegraf/master/SECURITY.md&#34;&gt;Security&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;❤️ Contribute&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/influxdata/telegraf/raw/master/CONTRIBUTING.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/contribute-to_telegraf-blue.svg?logo=influxdb&#34; alt=&#34;Contribute&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;We love our community of over 1,200 contributors! Many of the plugins included in Telegraf were originally contributed by community members. Check out our &lt;a href=&#34;https://raw.githubusercontent.com/influxdata/telegraf/master/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt; if you are interested in helping out. Also, join us on our &lt;a href=&#34;https://influxdata.com/slack&#34;&gt;Community Slack&lt;/a&gt; or &lt;a href=&#34;https://community.influxdata.com/&#34;&gt;Community Forums&lt;/a&gt; if you have questions or comments for our engineering teams.&lt;/p&gt; &#xA;&lt;p&gt;If you are completely new to Telegraf and InfluxDB, you can also enroll for free at &lt;a href=&#34;https://www.influxdata.com/university/&#34;&gt;InfluxDB university&lt;/a&gt; to take courses to learn more.&lt;/p&gt; &#xA;&lt;h2&gt;ℹ️ Support&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.influxdata.com/slack&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/slack-join_chat-blue.svg?logo=slack&#34; alt=&#34;Slack&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://community.influxdata.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/discourse-join_forums-blue.svg?logo=discourse&#34; alt=&#34;Forums&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Please use the &lt;a href=&#34;https://influxdata.com/slack&#34;&gt;Community Slack&lt;/a&gt; or &lt;a href=&#34;https://community.influxdata.com/&#34;&gt;Community Forums&lt;/a&gt; if you have questions or comments for our engineering teams. GitHub issues are limited to actual issues and feature requests only.&lt;/p&gt; &#xA;&lt;h2&gt;📜 License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/influxdata/telegraf/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-blue&#34; alt=&#34;MIT&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>