<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-24T01:30:49Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>huggingface/diffusers</title>
    <updated>2022-08-24T01:30:49Z</updated>
    <id>tag:github.com,2022-08-24:/huggingface/diffusers</id>
    <link href="https://github.com/huggingface/diffusers" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🤗 Diffusers: State-of-the-art diffusion models for image and audio generation in PyTorch&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/huggingface/diffusers/main/docs/source/imgs/diffusers_library.jpg&#34; width=&#34;400&#34;&gt; &lt;br&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/huggingface/diffusers/raw/main/LICENSE&#34;&gt; &lt;img alt=&#34;GitHub&#34; src=&#34;https://img.shields.io/github/license/huggingface/datasets.svg?color=blue&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/huggingface/diffusers/releases&#34;&gt; &lt;img alt=&#34;GitHub release&#34; src=&#34;https://img.shields.io/github/release/huggingface/diffusers.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/huggingface/diffusers/main/CODE_OF_CONDUCT.md&#34;&gt; &lt;img alt=&#34;Contributor Covenant&#34; src=&#34;https://img.shields.io/badge/Contributor%20Covenant-2.0-4baaaa.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;🤗 Diffusers provides pretrained diffusion models across multiple modalities, such as vision and audio, and serves as a modular toolbox for inference and training of diffusion models.&lt;/p&gt; &#xA;&lt;p&gt;More precisely, 🤗 Diffusers offers:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;State-of-the-art diffusion pipelines that can be run in inference with just a couple of lines of code (see &lt;a href=&#34;https://github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines&#34;&gt;src/diffusers/pipelines&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Various noise schedulers that can be used interchangeably for the prefered speed vs. quality trade-off in inference (see &lt;a href=&#34;https://github.com/huggingface/diffusers/tree/main/src/diffusers/schedulers&#34;&gt;src/diffusers/schedulers&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Multiple types of models, such as UNet, can be used as building blocks in an end-to-end diffusion system (see &lt;a href=&#34;https://github.com/huggingface/diffusers/tree/main/src/diffusers/models&#34;&gt;src/diffusers/models&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Training examples to show how to train the most popular diffusion models (see &lt;a href=&#34;https://github.com/huggingface/diffusers/tree/main/examples/training&#34;&gt;examples/training&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Inference examples to show how to create custom pipelines for advanced tasks such as image2image, in-painting (see &lt;a href=&#34;https://github.com/huggingface/diffusers/tree/main/examples/inference&#34;&gt;examples/inference&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;In order to get started, we recommend taking a look at two notebooks:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb&#34;&gt;Getting started with Diffusers&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; notebook, which showcases an end-to-end example of usage for diffusion models, schedulers and pipelines. Take a look at this notebook to learn how to use the pipeline abstraction, which takes care of everything (model, scheduler, noise handling) for you, and also to understand each independent building block in the library.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/training_example.ipynb&#34;&gt;Training a diffusers model&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/training_example.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; notebook summarizes diffuser model training methods. This notebook takes a step-by-step approach to training your diffuser model on an image dataset, with explanatory graphics.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;strong&gt;New 🎨🎨🎨&lt;/strong&gt; Stable Diffusion is now fully compatible with &lt;code&gt;diffusers&lt;/code&gt;!&lt;/h2&gt; &#xA;&lt;p&gt;Stable Diffusion is a text-to-image latent diffusion model created by the researchers and engineers from &lt;a href=&#34;https://github.com/CompVis&#34;&gt;CompVis&lt;/a&gt;, &lt;a href=&#34;https://stability.ai/&#34;&gt;Stability AI&lt;/a&gt; and &lt;a href=&#34;https://laion.ai/&#34;&gt;LAION&lt;/a&gt;. It&#39;s trained on 512x512 images from a subset of the &lt;a href=&#34;https://laion.ai/blog/laion-5b/&#34;&gt;LAION-5B&lt;/a&gt; database. This model uses a frozen CLIP ViT-L/14 text encoder to condition the model on text prompts. With its 860M UNet and 123M text encoder, the model is relatively lightweight and runs on a GPU with at least 10GB VRAM. See the &lt;a href=&#34;https://huggingface.co/CompVis/stable-diffusion&#34;&gt;model card&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;p&gt;You need to accept the model license before downloading or using the Stable Diffusion weights. Please, visit the &lt;a href=&#34;https://huggingface.co/CompVis/stable-diffusion-v1-3&#34;&gt;model card&lt;/a&gt;, read the license and tick the checkbox if you agree. You have to be a registered user in 🤗 Hugging Face Hub, and you&#39;ll also need to use an access token for the code to work. For more information on access tokens, please refer to &lt;a href=&#34;https://huggingface.co/docs/hub/security-tokens&#34;&gt;this section&lt;/a&gt; of the documentation.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;# make sure you&#39;re logged in with `huggingface-cli login`&#xA;from torch import autocast&#xA;from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler&#xA;&#xA;lms = LMSDiscreteScheduler(&#xA;    beta_start=0.00085, &#xA;    beta_end=0.012, &#xA;    beta_schedule=&#34;scaled_linear&#34;&#xA;)&#xA;&#xA;pipe = StableDiffusionPipeline.from_pretrained(&#xA;    &#34;CompVis/stable-diffusion-v1-3&#34;, &#xA;    scheduler=lms,&#xA;    use_auth_token=True&#xA;).to(&#34;cuda&#34;)&#xA;&#xA;prompt = &#34;a photo of an astronaut riding a horse on mars&#34;&#xA;with autocast(&#34;cuda&#34;):&#xA;    image = pipe(prompt)[&#34;sample&#34;][0]  &#xA;    &#xA;image.save(&#34;astronaut_rides_horse.png&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more details, check out &lt;a href=&#34;https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb&#34;&gt;the Stable Diffusion notebook&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; and have a look into the &lt;a href=&#34;https://github.com/huggingface/diffusers/releases/tag/v0.2.0&#34;&gt;release notes&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;If you want to run the code yourself 💻, you can try out:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/CompVis/ldm-text2im-large-256&#34;&gt;Text-to-Image Latent Diffusion&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# !pip install diffusers transformers&#xA;from diffusers import DiffusionPipeline&#xA;&#xA;model_id = &#34;CompVis/ldm-text2im-large-256&#34;&#xA;&#xA;# load model and scheduler&#xA;ldm = DiffusionPipeline.from_pretrained(model_id)&#xA;&#xA;# run pipeline in inference (sample random noise and denoise)&#xA;prompt = &#34;A painting of a squirrel eating a burger&#34;&#xA;images = ldm([prompt], num_inference_steps=50, eta=0.3, guidance_scale=6)[&#34;sample&#34;]&#xA;&#xA;# save images&#xA;for idx, image in enumerate(images):&#xA;    image.save(f&#34;squirrel-{idx}.png&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/google/ddpm-celebahq-256&#34;&gt;Unconditional Diffusion with discrete scheduler&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# !pip install diffusers&#xA;from diffusers import DDPMPipeline, DDIMPipeline, PNDMPipeline&#xA;&#xA;model_id = &#34;google/ddpm-celebahq-256&#34;&#xA;&#xA;# load model and scheduler&#xA;ddpm = DDPMPipeline.from_pretrained(model_id)  # you can replace DDPMPipeline with DDIMPipeline or PNDMPipeline for faster inference&#xA;&#xA;# run pipeline in inference (sample random noise and denoise)&#xA;image = ddpm()[&#34;sample&#34;]&#xA;&#xA;# save image&#xA;image[0].save(&#34;ddpm_generated_image.png&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/CompVis/ldm-celebahq-256&#34;&gt;Unconditional Latent Diffusion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/google/ncsnpp-ffhq-1024&#34;&gt;Unconditional Diffusion with continous scheduler&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you just want to play around with some web demos, you can try out the following 🚀 Spaces:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Hugging Face Spaces&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Text-to-Image Latent Diffusion&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/spaces/CompVis/text2img-latent-diffusion&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Faces generator&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/spaces/CompVis/celeba-latent-diffusion&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DDPM with different schedulers&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/spaces/fusing/celeba-diffusion&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Definitions&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Models&lt;/strong&gt;: Neural network that models $p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)$ (see image below) and is trained end-to-end to &lt;em&gt;denoise&lt;/em&gt; a noisy input to an image. &lt;em&gt;Examples&lt;/em&gt;: UNet, Conditioned UNet, 3D UNet, Transformer UNet&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/10695622/174349667-04e9e485-793b-429a-affe-096e8199ad5b.png&#34; width=&#34;800&#34;&gt; &lt;br&gt; &lt;em&gt; Figure from DDPM paper (https://arxiv.org/abs/2006.11239). &lt;/em&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Schedulers&lt;/strong&gt;: Algorithm class for both &lt;strong&gt;inference&lt;/strong&gt; and &lt;strong&gt;training&lt;/strong&gt;. The class provides functionality to compute previous image according to alpha, beta schedule as well as predict noise for training. &lt;em&gt;Examples&lt;/em&gt;: &lt;a href=&#34;https://arxiv.org/abs/2006.11239&#34;&gt;DDPM&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2010.02502&#34;&gt;DDIM&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2202.09778&#34;&gt;PNDM&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2204.13902&#34;&gt;DEIS&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/10695622/174349706-53d58acc-a4d1-4cda-b3e8-432d9dc7ad38.png&#34; width=&#34;800&#34;&gt; &lt;br&gt; &lt;em&gt; Sampling and training algorithms. Figure from DDPM paper (https://arxiv.org/abs/2006.11239). &lt;/em&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Diffusion Pipeline&lt;/strong&gt;: End-to-end pipeline that includes multiple diffusion models, possible text encoders, ... &lt;em&gt;Examples&lt;/em&gt;: Glide, Latent-Diffusion, Imagen, DALL-E 2&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/10695622/174348898-481bd7c2-5457-4830-89bc-f0907756f64c.jpeg&#34; width=&#34;550&#34;&gt; &lt;br&gt; &lt;em&gt; Figure from ImageGen (https://imagen.research.google/). &lt;/em&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;h2&gt;Philosophy&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Readability and clarity is prefered over highly optimized code. A strong importance is put on providing readable, intuitive and elementary code design. &lt;em&gt;E.g.&lt;/em&gt;, the provided &lt;a href=&#34;https://github.com/huggingface/diffusers/tree/main/src/diffusers/schedulers&#34;&gt;schedulers&lt;/a&gt; are separated from the provided &lt;a href=&#34;https://github.com/huggingface/diffusers/tree/main/src/diffusers/models&#34;&gt;models&lt;/a&gt; and provide well-commented code that can be read alongside the original paper.&lt;/li&gt; &#xA; &lt;li&gt;Diffusers is &lt;strong&gt;modality independent&lt;/strong&gt; and focuses on providing pretrained models and tools to build systems that generate &lt;strong&gt;continous outputs&lt;/strong&gt;, &lt;em&gt;e.g.&lt;/em&gt; vision and audio.&lt;/li&gt; &#xA; &lt;li&gt;Diffusion models and schedulers are provided as concise, elementary building blocks. In contrast, diffusion pipelines are a collection of end-to-end diffusion systems that can be used out-of-the-box, should stay as close as possible to their original implementation and can include components of another library, such as text-encoders. Examples for diffusion pipelines are &lt;a href=&#34;https://github.com/openai/glide-text2im&#34;&gt;Glide&lt;/a&gt; and &lt;a href=&#34;https://github.com/CompVis/latent-diffusion&#34;&gt;Latent Diffusion&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;With &lt;code&gt;pip&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install --upgrade diffusers  # should install diffusers 0.2.4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;With &lt;code&gt;conda&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;conda install -c conda-forge diffusers&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;In the works&lt;/h2&gt; &#xA;&lt;p&gt;For the first release, 🤗 Diffusers focuses on text-to-image diffusion techniques. However, diffusers can be used for much more than that! Over the upcoming releases, we&#39;ll be focusing on:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Diffusers for audio&lt;/li&gt; &#xA; &lt;li&gt;Diffusers for reinforcement learning (initial work happening in &lt;a href=&#34;https://github.com/huggingface/diffusers/pull/105&#34;&gt;https://github.com/huggingface/diffusers/pull/105&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Diffusers for video generation&lt;/li&gt; &#xA; &lt;li&gt;Diffusers for molecule generation (initial work happening in &lt;a href=&#34;https://github.com/huggingface/diffusers/pull/54&#34;&gt;https://github.com/huggingface/diffusers/pull/54&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;A few pipeline components are already being worked on, namely:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;BDDMPipeline for spectrogram-to-sound vocoding&lt;/li&gt; &#xA; &lt;li&gt;GLIDEPipeline to support OpenAI&#39;s GLIDE model&lt;/li&gt; &#xA; &lt;li&gt;Grad-TTS for text to audio generation / conditional audio generation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We want diffusers to be a toolbox useful for diffusers models in general; if you find yourself limited in any way by the current API, or would like to see additional models, schedulers, or techniques, please open a &lt;a href=&#34;https://github.com/huggingface/diffusers/issues&#34;&gt;GitHub issue&lt;/a&gt; mentioning what you would like to see.&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;This library concretizes previous work by many different authors and would not have been possible without their great research and implementations. We&#39;d like to thank, in particular, the following implementations which have helped us in our development and without which the API could not have been as polished today:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;@CompVis&#39; latent diffusion models library, available &lt;a href=&#34;https://github.com/CompVis/latent-diffusion&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;@hojonathanho original DDPM implementation, available &lt;a href=&#34;https://github.com/hojonathanho/diffusion&#34;&gt;here&lt;/a&gt; as well as the extremely useful translation into PyTorch by @pesser, available &lt;a href=&#34;https://github.com/pesser/pytorch_diffusion&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;@ermongroup&#39;s DDIM implementation, available &lt;a href=&#34;https://github.com/ermongroup/ddim&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;@yang-song&#39;s Score-VE and Score-VP implementations, available &lt;a href=&#34;https://github.com/yang-song/score_sde_pytorch&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We also want to thank @heejkoo for the very helpful overview of papers, code and resources on diffusion models, available &lt;a href=&#34;https://github.com/heejkoo/Awesome-Diffusion-Models&#34;&gt;here&lt;/a&gt; as well as @crowsonkb and @rromb for useful discussions and insights.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>rahuldkjain/github-profile-readme-generator</title>
    <updated>2022-08-24T01:30:49Z</updated>
    <id>tag:github.com,2022-08-24:/rahuldkjain/github-profile-readme-generator</id>
    <link href="https://github.com/rahuldkjain/github-profile-readme-generator" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🚀 Generate GitHub profile README easily with the latest add-ons like visitors count, GitHub stats, etc using minimal UI.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://rahuldkjain.github.io/gh-profile-readme-generator&#34;&gt; &lt;img alt=&#34;GitHub Profile Readme Generator&#34; src=&#34;https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/mdg.png&#34; width=&#34;60&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt; GitHub Profile README Generator &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/rahuldkjain/github-profile-readme-generator/raw/master/LICENSE&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/rahuldkjain/github-profile-readme-generator?style=flat-square&#34; alt=&#34;github-profile-readme-generator license&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/rahuldkjain/github-profile-readme-generator/fork&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/forks/rahuldkjain/github-profile-readme-generator?style=flat-square&#34; alt=&#34;github-profile-readme-generator forks&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/rahuldkjain/github-profile-readme-generator/stargazers&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/rahuldkjain/github-profile-readme-generator?style=flat-square&#34; alt=&#34;github-profile-readme-generator stars&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/rahuldkjain/github-profile-readme-generator/issues&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/issues/rahuldkjain/github-profile-readme-generator?style=flat-square&#34; alt=&#34;github-profile-readme-generator issues&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/rahuldkjain/github-profile-readme-generator/pulls&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/issues-pr/rahuldkjain/github-profile-readme-generator?style=flat-square&#34; alt=&#34;github-profile-readme-generator pull-requests&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://discord.gg/HHMs7Eg&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/735303195105951764?label=Join%20Community&amp;amp;logo=discord&amp;amp;style=flat-square&#34; alt=&#34;join discord community of github profile readme generator&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/github-profile-readme-generator.gif&#34; alt=&#34;github-profile-readme-generator gif&#34;&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://rahuldkjain.github.io/gh-profile-readme-generator&#34; target=&#34;blank&#34;&gt;View Demo&lt;/a&gt; · &lt;a href=&#34;https://github.com/rahuldkjain/github-profile-readme-generator/issues/new/choose&#34;&gt;Report Bug&lt;/a&gt; · &lt;a href=&#34;https://github.com/rahuldkjain/github-profile-readme-generator/issues/new/choose&#34;&gt;Request Feature&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;i&gt;Loved the tool? Please consider &lt;a href=&#34;https://paypal.me/rahuldkjain/10&#34;&gt;donating&lt;/a&gt; 💸 to help it improve!&lt;/i&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.paypal.me/rahuldkjain&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/support-PayPal-blue?logo=PayPal&amp;amp;style=flat-square&amp;amp;label=Donate&#34; alt=&#34;sponsor github profile readme generator&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://ko-fi.com/A0A81XXSX&#34; target=&#34;_blank&#34;&gt;&lt;img height=&#34;23&#34; width=&#34;100&#34; src=&#34;https://cdn.ko-fi.com/cdn/kofi3.png?v=2&#34; alt=&#34;Buy Coffee for rahuldkjain&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://www.buymeacoffee.com/rahuldkjain&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;23&#34; width=&#34;100&#34; style=&#34;border-radius:1px&#34;&gt; &lt;/a&gt;&lt;/p&gt;&#xA;&lt;a href=&#34;https://www.buymeacoffee.com/rahuldkjain&#34; target=&#34;_blank&#34;&gt; &lt;h4&gt;Tired of editing GitHub Profile README with new features?&lt;/h4&gt; &lt;p&gt;This tool provides an easy way to create a GitHub profile readme with the latest add-ons such as &lt;code&gt;visitors count&lt;/code&gt;, &lt;code&gt;github stats&lt;/code&gt;, etc.&lt;/p&gt; &lt;h2&gt;🚀 Demo&lt;/h2&gt; &lt;/a&gt;&#xA;&lt;a href=&#34;https://rahuldkjain.github.io/gh-profile-readme-generator&#34; target=&#34;blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/website?url=https%3A%2F%2Frahuldkjain.github.io%2Fgh-profile-readme-generator&amp;amp;logo=github&amp;amp;style=flat-square&#34;&gt; &lt;/a&gt; &#xA;&lt;p&gt;Try the tool: &lt;a href=&#34;https://rahuldkjain.github.io/gh-profile-readme-generator&#34;&gt;GitHub Profile README Generator&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🧐 Features&lt;/h2&gt; &#xA;&lt;p&gt;Just fill in the details such as &lt;code&gt;Name&lt;/code&gt;, &lt;code&gt;Tagline&lt;/code&gt;, &lt;code&gt;Dev Platforms Username&lt;/code&gt;, &lt;code&gt;Current Work&lt;/code&gt;, &lt;code&gt;Portfolio&lt;/code&gt;, &lt;code&gt;Blog&lt;/code&gt;, etc. with a minimal UI.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Uniform Dev Icons&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Uniform Social Icons&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Visitors Counter Badge&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;GitHub Profile Stats Card&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;GitHub Top Skills&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;GitHub Streak Stats&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic Dev(.)to Blogs&lt;/strong&gt; (GitHub Action)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic Medium Blogs&lt;/strong&gt; (GitHub Action)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic Personal Blogs from RSS Feed&lt;/strong&gt; (GitHub Action)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Wakatime Stats&lt;/strong&gt; &lt;a href=&#34;https://github.com/rahuldkjain/github-profile-readme-generator/issues/115&#34;&gt;contribute&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Buy Me A Coffee button&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Click on &lt;code&gt;Generate README&lt;/code&gt; to get your README in &lt;code&gt;markdown&lt;/code&gt;. You can preview the README too.&lt;/p&gt; &#xA;&lt;h2&gt;🛠️ Installation Steps&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repository&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/rahuldkjain/github-profile-readme-generator.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Change the working directory&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd github-profile-readme-generator&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Install dependencies&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Run the app&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;🌟 You are all set!&lt;/p&gt; &#xA;&lt;h2&gt;🍰 Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please contribute using &lt;a href=&#34;https://guides.github.com/introduction/flow&#34;&gt;GitHub Flow&lt;/a&gt;. Create a branch, add commits, and &lt;a href=&#34;https://github.com/rahuldkjain/github-profile-readme-generator/compare&#34;&gt;open a pull request&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Please read &lt;a href=&#34;https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/CONTRIBUTING.md&#34;&gt;&lt;code&gt;CONTRIBUTING&lt;/code&gt;&lt;/a&gt; for details on our &lt;a href=&#34;https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/CODE_OF_CONDUCT.md&#34;&gt;&lt;code&gt;CODE OF CONDUCT&lt;/code&gt;&lt;/a&gt;, and the process for submitting pull requests to us.&lt;/p&gt; &#xA;&lt;h2&gt;💻 Built with&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gatsbyjs.com/&#34;&gt;Gatsby&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tailwindcss.com/&#34;&gt;Tailwind CSS&lt;/a&gt;: for styling&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://greensock.com/gsap/&#34;&gt;GSAP&lt;/a&gt;: for small SVG Animations&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🙇 Special Thanks&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/anuraghazra&#34;&gt;Anurag Hazra&lt;/a&gt; for amazing &lt;a href=&#34;https://github.com/anuraghazra/github-readme-stats&#34;&gt;github-readme-stats&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/antonkomarev&#34;&gt;Anton Komarev&lt;/a&gt; for super cool &lt;a href=&#34;https://github.com/antonkomarev/github-profile-views-counter&#34;&gt;github-profile-views-counter&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gautamkrishnar&#34;&gt;Gautam Krishna R&lt;/a&gt; for the awesome &lt;a href=&#34;https://github.com/gautamkrishnar/blog-post-workflow&#34;&gt;blog post workflow&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/DenverCoder1&#34;&gt;Jonah Lawrence&lt;/a&gt; for the incredible &lt;a href=&#34;https://github.com/DenverCoder1/github-readme-streak-stats&#34;&gt;github-readme-streak-stats&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/konpa&#34;&gt;Julien Monty&lt;/a&gt; for super useful &lt;a href=&#34;https://github.com/konpa/devicon&#34;&gt;devicon&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/techieeliot&#34;&gt;Eliot Sanford&lt;/a&gt; for adding hashnode as a blog input&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🙇 Sponsors&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/scottcwilson&#34;&gt;Scott C Wilson&lt;/a&gt; donated the first-ever grant to this tool. A big thanks to him.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mxschmitt&#34;&gt;Max Schmitt&lt;/a&gt; loved the tool and showed support with his donation. Thanks a lot.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/aaditkamat&#34;&gt;Aadit Kamat&lt;/a&gt; find the tool useful and showed support with his donation. A big thanks to him.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jmfayard&#34;&gt;Jean-Michel Fayard&lt;/a&gt; used the generator to create his GitHub Profile README and he loved it. Thanks to him for showing support to the tool with the donation.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🙏 Support&lt;/h2&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;a href=&#34;https://www.paypal.me/rahuldkjain/10&#34;&gt;&lt;img src=&#34;https://ionicabizau.github.io/badges/paypal.svg?sanitize=true&#34; alt=&#34;sponsor github profile readme generator&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://twitter.com/intent/tweet?text=Wow:&amp;amp;url=https%3A%2F%2Frahuldkjain.github.io%2Fgithub-profile-readme-generator&#34;&gt; &lt;img src=&#34;https://img.shields.io/twitter/url?style=social&amp;amp;url=https%3A%2F%2Frahuldkjain.github.io%2Fgithub-profile-readme-generator&#34; alt=&#34;tweet github profile readme generator&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;a href=&#34;https://ko-fi.com/A0A81XXSX&#34; target=&#34;_blank&#34;&gt;&lt;img height=&#34;23&#34; width=&#34;100&#34; src=&#34;https://cdn.ko-fi.com/cdn/kofi3.png?v=2&#34; alt=&#34;Buy Coffee for rahuldkjain&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://www.buymeacoffee.com/rahuldkjain&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/default-orange.png&#34; alt=&#34;Buy Me A Coffee&#34; height=&#34;23&#34; width=&#34;100&#34; style=&#34;border-radius:2px&#34;&gt; &lt;/a&gt;&lt;/p&gt;&#xA;&lt;a href=&#34;https://www.buymeacoffee.com/rahuldkjain&#34; target=&#34;_blank&#34;&gt; &#xA; &lt;hr&gt; &lt;p align=&#34;center&#34;&gt; Developed with ❤️ in India 🇮🇳 &lt;/p&gt; &lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>opcodesio/log-viewer</title>
    <updated>2022-08-24T01:30:49Z</updated>
    <id>tag:github.com,2022-08-24:/opcodesio/log-viewer</id>
    <link href="https://github.com/opcodesio/log-viewer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Fast and easy-to-use Log Viewer for your Laravel application&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt; &lt;/p&gt;&#xA; &lt;h1&gt;Log Viewer&lt;br&gt;Fast and easy-to-use&lt;/h1&gt; &#xA; &lt;p&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/opcodesio/log-viewer/main/#features&#34;&gt;Features&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/opcodesio/log-viewer/main/#installation&#34;&gt;Installation&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/opcodesio/log-viewer/main/#configuration&#34;&gt;Configuration&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/opcodesio/log-viewer/main/#credits&#34;&gt;Credits&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://packagist.org/packages/opcodesio/log-viewer&#34;&gt;&lt;img src=&#34;https://img.shields.io/packagist/v/opcodesio/log-viewer.svg?style=flat-square&#34; alt=&#34;Packagist&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://packagist.org/packages/opcodesio/log-viewer&#34;&gt;&lt;img src=&#34;https://img.shields.io/packagist/dm/opcodesio/log-viewer.svg?style=flat-square&#34; alt=&#34;Packagist&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://packagist.org/packages/opcodesio/log-viewer&#34;&gt;&lt;img src=&#34;https://img.shields.io/packagist/php-v/opcodesio/log-viewer.svg?style=flat-square&#34; alt=&#34;PHP from Packagist&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://packagist.org/packages/opcodesio/log-viewer&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Laravel-8.x,%209.x-brightgreen.svg?style=flat-square&#34; alt=&#34;Laravel Version&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/8697942/184591230-e6dfb1e6-215e-418b-a61e-58c9cdbb392a.png&#34; alt=&#34;log-viewer-screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.opcodes.io/&#34;&gt;OPcodes&#39;s&lt;/a&gt; &lt;strong&gt;Log Viewer&lt;/strong&gt; is a perfect companion for your &lt;a href=&#34;https://laravel.com/&#34;&gt;Laravel&lt;/a&gt; app.&lt;/p&gt; &#xA;&lt;p&gt;You will no longer need to read the raw Laravel log files trying to find what you&#39;re looking for.&lt;/p&gt; &#xA;&lt;p&gt;Log Viewer helps you quickly and clearly see individual log entries, to &lt;strong&gt;search&lt;/strong&gt;, &lt;strong&gt;filter&lt;/strong&gt;, and make sense of your Laravel logs &lt;strong&gt;fast&lt;/strong&gt;. It is free and easy to install.&lt;/p&gt; &#xA;&lt;h3&gt;Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;📂 &lt;strong&gt;View all the Laravel logs&lt;/strong&gt; in your &lt;code&gt;storage/logs&lt;/code&gt; directory,&lt;/li&gt; &#xA; &lt;li&gt;🔍 &lt;strong&gt;Search&lt;/strong&gt; the logs,&lt;/li&gt; &#xA; &lt;li&gt;🎚 &lt;strong&gt;Filter&lt;/strong&gt; by log level (error, info, debug, etc.),&lt;/li&gt; &#xA; &lt;li&gt;🔗 &lt;strong&gt;Sharable links&lt;/strong&gt; to individual log entries,&lt;/li&gt; &#xA; &lt;li&gt;💾 &lt;strong&gt;Download &amp;amp; delete&lt;/strong&gt; log files from the UI,&lt;/li&gt; &#xA; &lt;li&gt;☑️ &lt;strong&gt;Horizon&lt;/strong&gt; log support,&lt;/li&gt; &#xA; &lt;li&gt;and more...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;PHP 8.0+&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Laravel 8+&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;To install the package via composer, Run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;composer require opcodesio/log-viewer&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;Once the installation is complete, you will be able to access &lt;strong&gt;Log Viewer&lt;/strong&gt; directly in your browser.&lt;/p&gt; &#xA;&lt;p&gt;By default, the application is available at: &lt;code&gt;{APP_URL}/log-viewer&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;(for example: &lt;code&gt;https://my-app.test/log-viewer&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;h3&gt;Configuration&lt;/h3&gt; &#xA;&lt;h4&gt;Config file&lt;/h4&gt; &#xA;&lt;p&gt;To publish the &lt;a href=&#34;https://github.com/opcodesio/log-viewer/raw/main/config/log-viewer.php&#34;&gt;config file&lt;/a&gt;, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;php artisan vendor:publish --tag=&#34;log-viewer-config&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Route &amp;amp; Middleware&lt;/h3&gt; &#xA;&lt;p&gt;You can easily change the default route and its middleware in the config/log-viewer.php.&lt;/p&gt; &#xA;&lt;p&gt;See the configuration below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;    /*&#xA;    |--------------------------------------------------------------------------&#xA;    | Log Viewer Route&#xA;    |--------------------------------------------------------------------------&#xA;    | Log Viewer will be available under this URL.&#xA;    |&#xA;    */&#xA;&#xA;    &#39;route_path&#39; =&amp;gt; &#39;log-viewer&#39;,&#xA;&#xA;    /*&#xA;    |--------------------------------------------------------------------------&#xA;    | Log Viewer route middleware.&#xA;    |--------------------------------------------------------------------------&#xA;    | The middleware should enable session and cookies support in order for the Log Viewer to work.&#xA;    | The &#39;web&#39; middleware will be applied automatically if empty.&#xA;    |&#xA;    */&#xA;&#xA;    &#39;middleware&#39; =&amp;gt; [&#39;web&#39;],&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Screenshots&lt;/h2&gt; &#xA;&lt;p&gt;Read the &lt;strong&gt;&lt;a href=&#34;https://arunas.dev/log-viewer-for-laravel/&#34;&gt;release blog post&lt;/a&gt;&lt;/strong&gt; for screenshots and more information about Log Viewer&#39;s features.&lt;/p&gt; &#xA;&lt;h2&gt;Changelog&lt;/h2&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://raw.githubusercontent.com/opcodesio/log-viewer/main/CHANGELOG.md&#34;&gt;CHANGELOG&lt;/a&gt; for more information on what has changed recently.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://github.com/arukompas/.github/raw/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;h2&gt;Security Vulnerabilities&lt;/h2&gt; &#xA;&lt;p&gt;Please review &lt;a href=&#34;https://raw.githubusercontent.com/opcodesio/security/policy&#34;&gt;our security policy&lt;/a&gt; on how to report security vulnerabilities.&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/arukompas&#34;&gt;Arunas Skirius&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/opcodesio/contributors&#34;&gt;All Contributors&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The MIT License (MIT). Please see &lt;a href=&#34;https://raw.githubusercontent.com/opcodesio/log-viewer/main/LICENSE.md&#34;&gt;License File&lt;/a&gt; for more information.&lt;/p&gt;</summary>
  </entry>
</feed>