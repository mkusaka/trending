<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-19T01:29:39Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>joschan21/breadit</title>
    <updated>2023-06-19T01:29:39Z</updated>
    <id>tag:github.com,2023-06-19:/joschan21/breadit</id>
    <link href="https://github.com/joschan21/breadit" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Modern Fullstack Reddit Clone in Next.js 13 &amp; TypeScript&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Breadit - A Modern Fullstack Reddit Clone&lt;/h1&gt; &#xA;&lt;p&gt;Built with the Next.js App Router, TypeScript &amp;amp; Tailwind&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Infinite scrolling for dynamically loading posts&lt;/li&gt; &#xA; &lt;li&gt;Authentication using NextAuth &amp;amp; Google&lt;/li&gt; &#xA; &lt;li&gt;Custom feed for authenticated users&lt;/li&gt; &#xA; &lt;li&gt;Advanced caching using &lt;a href=&#34;https://upstash.com/?utm_source=Josh2&#34;&gt;Upstash Redis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Optimistic updates for a great user experience&lt;/li&gt; &#xA; &lt;li&gt;Modern data fetching using React-Query&lt;/li&gt; &#xA; &lt;li&gt;A beautiful and highly functional post editor&lt;/li&gt; &#xA; &lt;li&gt;Image uploads &amp;amp; link previews&lt;/li&gt; &#xA; &lt;li&gt;Full comment functionality with nested replies&lt;/li&gt; &#xA; &lt;li&gt;... and much more&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;p&gt;To get started with this project, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  git clone -b starter-code https://github.com/joschan21/breadit.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and copy these .env.example variables into a separate .env file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;DATABASE_URL=&#xA;NEXTAUTH_SECRET=&#xA;&#xA;GOOGLE_CLIENT_ID=&#xA;GOOGLE_CLIENT_SECRET=&#xA;&#xA;UPLOADTHING_SECRET=&#xA;UPLOADTHING_APP_ID=&#xA;&#xA;REDIS_URL=&#xA;REDIS_SECRET=&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;if you&#39;d like, you can paste this snippet for quick component creation (optional):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;// vscode settings -&amp;gt; user snippets -&amp;gt; typescriptreact.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;&#34;Typescript React Function Component&#34;: {&#xA;    &#34;prefix&#34;: &#34;fc&#34;,&#xA;    &#34;body&#34;: [&#xA;      &#34;import { FC } from &#39;react&#39;&#34;,&#xA;      &#34;&#34;,&#xA;      &#34;interface ${TM_FILENAME_BASE}Props {&#34;,&#xA;      &#34;  $1&#34;,&#xA;      &#34;}&#34;,&#xA;      &#34;&#34;,&#xA;      &#34;const $TM_FILENAME_BASE: FC&amp;lt;${TM_FILENAME_BASE}Props&amp;gt; = ({$2}) =&amp;gt; {&#34;,&#xA;      &#34;  return &amp;lt;div&amp;gt;$TM_FILENAME_BASE&amp;lt;/div&amp;gt;&#34;,&#xA;      &#34;}&#34;,&#xA;      &#34;&#34;,&#xA;      &#34;export default $TM_FILENAME_BASE&#34;&#xA;    ],&#xA;    &#34;description&#34;: &#34;Typescript React Function Component&#34;&#xA;  },&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and that&#39;s all you need to get started!&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://upstash.com/?utm_source=Josh2&#34;&gt;Upstash Redis&lt;/a&gt; for making this possible&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/@codewithantonio&#34;&gt;Code with Antonio&lt;/a&gt; for thumbnail design inspiration&lt;/li&gt; &#xA; &lt;li&gt;Shadcn&#39;s &lt;a href=&#34;https://github.com/shadcn/taxonomy&#34;&gt;Taxonomy respository&lt;/a&gt; for showcasing the post editor&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>hiyouga/LLaMA-Efficient-Tuning</title>
    <updated>2023-06-19T01:29:39Z</updated>
    <id>tag:github.com,2023-06-19:/hiyouga/LLaMA-Efficient-Tuning</id>
    <link href="https://github.com/hiyouga/LLaMA-Efficient-Tuning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Fine-tuning LLaMA with PEFT (PT+SFT+RLHF with QLoRA)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LLaMA Efficient Tuning&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/stars/hiyouga/LLaMA-Efficient-Tuning?style=social&#34; alt=&#34;GitHub Repo stars&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/hiyouga/LLaMA-Efficient-Tuning&#34; alt=&#34;GitHub Code License&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/last-commit/hiyouga/LLaMA-Efficient-Tuning&#34; alt=&#34;GitHub last commit&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-blue&#34; alt=&#34;GitHub pull request&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;üëã Join our &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Efficient-Tuning/main/assets/wechat.jpg&#34;&gt;WeChat&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Changelog&lt;/h2&gt; &#xA;&lt;p&gt;[23/06/15] Now we support training the baichuan-7B model in this repo. Try &lt;code&gt;--model_name_or_path baichuan-inc/baichuan-7B&lt;/code&gt; argument to use the baichuan-7B model.&lt;/p&gt; &#xA;&lt;p&gt;[23/06/03] Now we support quantized training and inference (aka &lt;a href=&#34;https://github.com/artidoro/qlora&#34;&gt;QLoRA&lt;/a&gt;). Try &lt;code&gt;--quantization_bit 4/8&lt;/code&gt; argument to work with quantized model. (experimental feature)&lt;/p&gt; &#xA;&lt;p&gt;[23/05/31] Now we support training the BLOOM &amp;amp; BLOOMZ models in this repo. Try &lt;code&gt;--model_name_or_path bigscience/bloomz-7b1-mt&lt;/code&gt; argument to use the BLOOMZ model.&lt;/p&gt; &#xA;&lt;h2&gt;Supported Models&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;LLaMA&lt;/a&gt; (7B/13B/33B/65B)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/bigscience/bloom&#34;&gt;BLOOM&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://huggingface.co/bigscience/bloomz&#34;&gt;BLOOMZ&lt;/a&gt; (560M/1.1B/1.7B/3B/7.1B/176B)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/baichuan-inc/baichuan-7B&#34;&gt;baichuan&lt;/a&gt; (7B)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Supported Training Approaches&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf&#34;&gt;(Continually) pre-training&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Full-parameter tuning&lt;/li&gt; &#xA;   &lt;li&gt;Partial-parameter tuning&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;LoRA&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.14314&#34;&gt;QLoRA&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2109.01652&#34;&gt;Supervised fine-tuning&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Full-parameter tuning&lt;/li&gt; &#xA;   &lt;li&gt;Partial-parameter tuning&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;LoRA&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.14314&#34;&gt;QLoRA&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.02155&#34;&gt;RLHF&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;LoRA&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.14314&#34;&gt;QLoRA&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Provided Datasets&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For pre-training: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Efficient-Tuning/main/data/wiki_demo.txt&#34;&gt;Wiki Demo&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;For supervised fine-tuning: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca&#34;&gt;Stanford Alpaca (Chinese)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM&#34;&gt;GPT-4 Generated Data&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/train_2M_CN&#34;&gt;BELLE 2M&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/train_1M_CN&#34;&gt;BELLE 1M&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/train_0.5M_CN&#34;&gt;BELLE 0.5M&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M&#34;&gt;BELLE Dialogue 0.4M&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/school_math_0.25M&#34;&gt;BELLE School Math 0.25M&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M&#34;&gt;BELLE Multiturn Chat 0.8M&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/JosephusCheung/GuanacoDataset&#34;&gt;Guanaco Dataset&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M&#34;&gt;Firefly 1.1M&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k&#34;&gt;CodeAlpaca 20k&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/QingyiSi/Alpaca-CoT&#34;&gt;Alpaca CoT&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/suolyer/webqa&#34;&gt;Web QA (Chinese)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/thunlp/UltraChat&#34;&gt;UltraChat&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;For reward model training: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/Anthropic/hh-rlhf&#34;&gt;HH-RLHF&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM&#34;&gt;GPT-4 Generated Data&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM&#34;&gt;GPT-4 Generated Data (Chinese)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Efficient-Tuning/main/data/README.md&#34;&gt;data/README.md&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;p&gt;Some datasets require confirmation before using them, so we recommend logging in with your HuggingFace account using these commands.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install --upgrade huggingface_hub&#xA;huggingface-cli login&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Requirement&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.8+ and PyTorch 1.13.1+&lt;/li&gt; &#xA; &lt;li&gt;ü§óTransformers, Datasets, Accelerate, PEFT and TRL&lt;/li&gt; &#xA; &lt;li&gt;protobuf, cpm_kernels and sentencepiece&lt;/li&gt; &#xA; &lt;li&gt;jieba, rouge_chinese and nltk (used at evaluation)&lt;/li&gt; &#xA; &lt;li&gt;gradio and mdtex2html (used in web_demo.py)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;And &lt;strong&gt;powerful GPUs&lt;/strong&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Data Preparation (optional)&lt;/h3&gt; &#xA;&lt;p&gt;Please refer to &lt;code&gt;data/example_dataset&lt;/code&gt; for checking the details about the format of dataset files. You can either use a single &lt;code&gt;.json&lt;/code&gt; file or a &lt;a href=&#34;https://huggingface.co/docs/datasets/dataset_script&#34;&gt;dataset loading script&lt;/a&gt; with multiple files to create a custom dataset.&lt;/p&gt; &#xA;&lt;p&gt;Note: please update &lt;code&gt;data/dataset_info.json&lt;/code&gt; to use your custom dataset. About the format of this file, please refer to &lt;code&gt;data/README.md&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Dependence Installation (optional)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/hiyouga/LLaMA-Efficient-Tuning.git&#xA;conda create -n llama_etuning python=3.10&#xA;conda activate llama_etuning&#xA;cd LLaMA-Efficient-Tuning&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;LLaMA Weights Preparation&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download the weights of the LLaMA models.&lt;/li&gt; &#xA; &lt;li&gt;Convert them to HF format using the following command.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m transformers.models.llama.convert_llama_weights_to_hf \&#xA;    --input_dir path_to_llama_weights --model_size 7B --output_dir path_to_llama_model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;(Continually) Pre-Training&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_pt.py \&#xA;    --model_name_or_path path_to_your_model \&#xA;    --do_train \&#xA;    --dataset wiki_demo \&#xA;    --finetuning_type lora \&#xA;    --output_dir path_to_pt_checkpoint \&#xA;    --overwrite_cache \&#xA;    --per_device_train_batch_size 4 \&#xA;    --gradient_accumulation_steps 4 \&#xA;    --lr_scheduler_type cosine \&#xA;    --logging_steps 10 \&#xA;    --save_steps 1000 \&#xA;    --learning_rate 5e-5 \&#xA;    --num_train_epochs 3.0 \&#xA;    --plot_loss \&#xA;    --fp16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Supervised Fine-Tuning&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_sft.py \&#xA;    --model_name_or_path path_to_your_model \&#xA;    --do_train \&#xA;    --dataset alpaca_gpt4_en \&#xA;    --finetuning_type lora \&#xA;    --output_dir path_to_sft_checkpoint \&#xA;    --overwrite_cache \&#xA;    --per_device_train_batch_size 4 \&#xA;    --gradient_accumulation_steps 4 \&#xA;    --lr_scheduler_type cosine \&#xA;    --logging_steps 10 \&#xA;    --save_steps 1000 \&#xA;    --learning_rate 5e-5 \&#xA;    --num_train_epochs 3.0 \&#xA;    --plot_loss \&#xA;    --fp16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Reward Model Training&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_rm.py \&#xA;    --model_name_or_path path_to_your_model \&#xA;    --do_train \&#xA;    --dataset comparison_gpt4_en \&#xA;    --finetuning_type lora \&#xA;    --output_dir path_to_rm_checkpoint \&#xA;    --per_device_train_batch_size 4 \&#xA;    --gradient_accumulation_steps 4 \&#xA;    --lr_scheduler_type cosine \&#xA;    --logging_steps 10 \&#xA;    --save_steps 1000 \&#xA;    --learning_rate 1e-5 \&#xA;    --num_train_epochs 1.0 \&#xA;    --plot_loss \&#xA;    --fp16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;PPO Training (RLHF)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_ppo.py \&#xA;    --model_name_or_path path_to_your_model \&#xA;    --do_train \&#xA;    --dataset alpaca_gpt4_en \&#xA;    --finetuning_type lora \&#xA;    --checkpoint_dir path_to_sft_checkpoint \&#xA;    --reward_model path_to_rm_checkpoint \&#xA;    --output_dir path_to_ppo_checkpoint \&#xA;    --per_device_train_batch_size 2 \&#xA;    --gradient_accumulation_steps 4 \&#xA;    --lr_scheduler_type cosine \&#xA;    --logging_steps 10 \&#xA;    --save_steps 1000 \&#xA;    --learning_rate 1e-5 \&#xA;    --num_train_epochs 1.0 \&#xA;    --resume_lora_training False \&#xA;    --plot_loss&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Distributed Training&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;accelerate config # configure the environment&#xA;accelerate launch src/train_XX.py # arguments (same as above)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Evaluation (BLEU and ROUGE_CHINESE)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_sft.py \&#xA;    --model_name_or_path path_to_your_model \&#xA;    --do_eval \&#xA;    --dataset alpaca_gpt4_en \&#xA;    --checkpoint_dir path_to_checkpoint \&#xA;    --output_dir path_to_eval_result \&#xA;    --per_device_eval_batch_size 8 \&#xA;    --max_samples 50 \&#xA;    --predict_with_generate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We recommend using &lt;code&gt;--per_device_eval_batch_size=1&lt;/code&gt; and &lt;code&gt;--max_target_length 128&lt;/code&gt; at 4/8-bit evaluation.&lt;/p&gt; &#xA;&lt;h3&gt;CLI Demo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python src/cli_demo.py \&#xA;    --model_name_or_path path_to_your_model \&#xA;    --checkpoint_dir path_to_checkpoint&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Web Demo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python src/web_demo.py \&#xA;    --model_name_or_path path_to_your_model \&#xA;    --checkpoint_dir path_to_checkpoint&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Export model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python src/export_model.py \&#xA;    --model_name_or_path path_to_your_model \&#xA;    --checkpoint_dir path_to_checkpoint \&#xA;    --output_dir path_to_export&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This repository is licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/LLaMA-Efficient-Tuning/main/LICENSE&#34;&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Please follow the &lt;a href=&#34;https://github.com/facebookresearch/llama/raw/main/MODEL_CARD.md&#34;&gt;Model Card&lt;/a&gt; to use the LLaMA models.&lt;/p&gt; &#xA;&lt;p&gt;Please follow the &lt;a href=&#34;https://huggingface.co/spaces/bigscience/license&#34;&gt;RAIL License&lt;/a&gt; to use the BLOOM &amp;amp; BLOOMZ models.&lt;/p&gt; &#xA;&lt;p&gt;Please follow the &lt;a href=&#34;https://huggingface.co/baichuan-inc/baichuan-7B/resolve/main/baichuan-7B%20%E6%A8%A1%E5%9E%8B%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf&#34;&gt;baichuan-7B License&lt;/a&gt; to use the baichuan-7B model.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If this work is helpful, please cite as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@Misc{llama-efficient-tuning,&#xA;  title = {LLaMA Efficient Tuning},&#xA;  author = {hiyouga},&#xA;  howpublished = {\url{https://github.com/hiyouga/LLaMA-Efficient-Tuning}},&#xA;  year = {2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;This repo is a sibling of &lt;a href=&#34;https://github.com/hiyouga/ChatGLM-Efficient-Tuning&#34;&gt;ChatGLM-Efficient-Tuning&lt;/a&gt;. They share a similar code structure of efficient tuning on large language models.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>PostHog/HouseWatch</title>
    <updated>2023-06-19T01:29:39Z</updated>
    <id>tag:github.com,2023-06-19:/PostHog/HouseWatch</id>
    <link href="https://github.com/PostHog/HouseWatch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Open source tool for monitoring and managing ClickHouse clusters&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/banner-light.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/overview.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;üìà Open source tool for monitoring and managing ClickHouse clusters&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Get an overview of cluster load and performance&lt;/li&gt; &#xA; &lt;li&gt;Drill down into your queries and understand the load they put on your cluster&lt;/li&gt; &#xA; &lt;li&gt;Search through logs and errors&lt;/li&gt; &#xA; &lt;li&gt;Monitor and kill running queries with the click of a button&lt;/li&gt; &#xA; &lt;li&gt;Get stats on your disk usage per node, and understand how much disk space tables, columns, and parts take up&lt;/li&gt; &#xA; &lt;li&gt;Run your own queries straight from the interface to further dig into performance and cluster issues&lt;/li&gt; &#xA; &lt;li&gt;Setup operations to run in the background with automatic rollbacks for failures&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üíª Deploy&lt;/h2&gt; &#xA;&lt;p&gt;To deploy HouseWatch, clone this repo and then run the following, substituting the environment variables for the relevant values of one of your ClickHouse instances:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CLICKHOUSE_HOST=localhost \&#xA;CLICKHOUSE_CLUSTER=mycluster \&#xA;CLICKHOUSE_USER=default \&#xA;CLICKHOUSE_PASSWORD=xxxxxxxxxxx \&#xA;docker compose -f docker-compose.yml up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After running the above, the UI will be running on &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt;. For production installs, you might want to setup something like &lt;a href=&#34;https://caddyserver.com/&#34;&gt;Caddy&lt;/a&gt; or &lt;a href=&#34;https://nginx.org/en/&#34;&gt;NGINX&lt;/a&gt; with a &lt;a href=&#34;https://letsencrypt.org/&#34;&gt;Let&#39;s Encrypt&lt;/a&gt; TLS certificate.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Read more&lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;The following are the supported environment variables for configuring your HouseWatch deployment:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;code&gt;CLICKHOUSE_HOST&lt;/code&gt;: Required - hostname of the instance to connect to.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;CLICKHOUSE_USER&lt;/code&gt;: Required - username to access ClickHouse. Can be a read-only user, but in that case not all features will work.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;CLICKHOUSE_PASSWORD&lt;/code&gt;: Required - password for the specified user.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;CLICKHOUSE_DATABASE&lt;/code&gt;: Optional - database to connect to by default.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;CLICKHOUSE_CLUSTER&lt;/code&gt;: Optional - cluster name, to analyze data from the whole cluster.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;CLICKHOUSE_SECURE&lt;/code&gt;: Optional - see &lt;a href=&#34;https://clickhouse-driver.readthedocs.io/en/latest/index.html&#34;&gt;clickhouse-driver docs&lt;/a&gt; for more information&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;CLICKHOUSE_VERIFY&lt;/code&gt;: Optional - see &lt;a href=&#34;https://clickhouse-driver.readthedocs.io/en/latest/index.html&#34;&gt;clickhouse-driver docs&lt;/a&gt; for more information&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;CLICKHOUSE_CA&lt;/code&gt;: Optional - see &lt;a href=&#34;https://clickhouse-driver.readthedocs.io/en/latest/index.html&#34;&gt;clickhouse-driver docs&lt;/a&gt; for more information&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;: Optional - enables the experimental &#34;AI Tools&#34; page, which currently features a natural language query editor&lt;/li&gt; &#xA;  &lt;li&gt;&lt;code&gt;OPENAI_MODEL&lt;/code&gt;: Optional - a valid OpenAI model (e.g. &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;, &lt;code&gt;gpt-4&lt;/code&gt;) that you have access to with the key above to be used for the AI features&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;üí° Motivation&lt;/h2&gt; &#xA;&lt;p&gt;At PostHog we manage a few large ClickHouse clusters and found ourselves in need of a tool to monitor and manage these more easily.&lt;/p&gt; &#xA;&lt;p&gt;ClickHouse is fantastic at introspection, providing a lot of metadata about the system in its system tables so that it can be easily queried. However, knowing exactly how to query and parse the available information can be a difficult task. Over the years at PostHog, we&#39;ve developed great intuition for how to debug ClickHouse issues using ClickHouse, and HouseWatch is the compilation of this knowledge into a tool.&lt;/p&gt; &#xA;&lt;p&gt;Beyond monitoring, we also built internal systems and processes for managing the clusters that spanned various platforms. We would use Grafana to look at metrics, SSH into nodes for running operations and using specialized tooling, query via Metabase to dig deeper into the data in the system tables and create dashboards, and then a combination of tools baked into the PostHog product for further debugging and streamlined operations such as our &lt;a href=&#34;https://posthog.com/blog/async-migrations&#34;&gt;async migrations&lt;/a&gt; tool, and internal views for listing queries and analyzing their performance.&lt;/p&gt; &#xA;&lt;p&gt;As a result, we felt it was appropriate to have these tools live in one place. Ultimately, our vision for HouseWatch is that it can both serve the purpose of a pganalyze for the ClickHouse ecosystem, while also including tooling for taking action on insights derived from the analysis.&lt;/p&gt; &#xA;&lt;h2&gt;üèóÔ∏è Status of the project&lt;/h2&gt; &#xA;&lt;p&gt;HouseWatch is in its early days and we have a lot more features in mind that we&#39;d like to build into it going forward. The code could also use some cleaning up :) As of right now, it is considered Beta software and you should exercise caution when using it in production.&lt;/p&gt; &#xA;&lt;p&gt;One potential approach is to connect HouseWatch to ClickHouse using a read-only user. In this case, the cluster management features will not work (e.g. operations, query editor), but the analysis toolset will function normally.&lt;/p&gt; &#xA;&lt;h2&gt;‚ÑπÔ∏è Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are certainly welcome! However, if you&#39;d like to build a new feature, please open up an issue first.&lt;/p&gt; &#xA;&lt;h2&gt;‚≠ê Features&lt;/h2&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;Query performance&lt;/h2&gt; &#xA;&lt;div style=&#34;display: flex&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/slow-queries.png&#34; width=&#34;48%&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/normalized-query.png&#34; width=&#34;48%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div style=&#34;display: flex&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/query-stats.png&#34; width=&#34;48%&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/explain.png&#34; width=&#34;48%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;Schema stats&lt;/h2&gt; &#xA;&lt;div style=&#34;display: flex&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/schema.png&#34; width=&#34;48%&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/schema-drilldown.png&#34; width=&#34;48%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;Query benchmarking&lt;/h2&gt; &#xA;&lt;div style=&#34;display: flex&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/benchmark1.png&#34; width=&#34;48%&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/benchmark2.png&#34; width=&#34;48%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;Logs&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/logs.png&#34; align=&#34;center&#34;&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;Query editor&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/query-editor.png&#34;&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;Disk usage&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/disk-usage.png&#34;&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;Errors&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/errors.png&#34;&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;Operations&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/PostHog/HouseWatch/main/operations.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;üóíÔ∏è To-do list&lt;/h2&gt; &#xA;&lt;p&gt;A public list of things we intend to do with HouseWatch in the near future.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;See list&lt;/summary&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;b&gt;Features&lt;/b&gt;&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; System issues tab&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; EXPLAIN visualizer&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Multiple instance support&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Stats on page cache hit percentage&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Make operations resilient to Celery going down (as we do in PostHog with async migrations)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Read-only mode&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Button to force refresh running queries list&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Logs pagination&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Allow copying example queries&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Configurable time ranges&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Whole cluster schema stats&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; More operation controls: view, delete, edit, re-run, display errors&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;&lt;b&gt;Developer experience&lt;/b&gt;&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Configure instance from UI&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Publish a Docker image&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Development docker-compose.yml with baked in ClickHouse&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;&lt;b&gt;Cleanup&lt;/b&gt;&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Extract README images out of repo&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Make banner subtitle work on dark mode&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Fetch data independently on the query analyzer&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Breakpoint for logs search&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Run Django &#34;production server&#34;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Write tests :)&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Query editor pipe all errors to client&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Abstraction to load data from API as JSON&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt;</summary>
  </entry>
</feed>