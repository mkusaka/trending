<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-08-21T01:23:34Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>qiuyu96/CoDeF</title>
    <updated>2023-08-21T01:23:34Z</updated>
    <id>tag:github.com,2023-08-21:/qiuyu96/CoDeF</id>
    <link href="https://github.com/qiuyu96/CoDeF" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official PyTorch implementation of CoDeF: Content Deformation Fields for Temporally Consistent Video Processing&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CoDeF: Content Deformation Fields for Temporally Consistent Video Processing&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/qiuyu96/CoDeF/main/docs/teaser.gif&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ken-ouyang.github.io/&#34;&gt;Hao Ouyang&lt;/a&gt;*, &lt;a href=&#34;https://github.com/qiuyu96/&#34;&gt;Qiuyu Wang&lt;/a&gt;*, &lt;a href=&#34;https://henry123-boy.github.io/&#34;&gt;Yuxi Xiao&lt;/a&gt;*, &lt;a href=&#34;https://scholar.google.com/citations?user=xUMjxi4AAAAJ&amp;amp;hl=en&#34;&gt;Qingyan Bai&lt;/a&gt;, &lt;a href=&#34;https://github.com/JordanZh&#34;&gt;Juntao Zhang&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=hMDQifQAAAAJ&#34;&gt;Kecheng Zheng&lt;/a&gt;, &lt;a href=&#34;https://xzhou.me/&#34;&gt;Xiaowei Zhou&lt;/a&gt;, &lt;a href=&#34;https://cqf.io/&#34;&gt;Qifeng Chen&lt;/a&gt;‚Ä†, &lt;a href=&#34;https://shenyujun.github.io/&#34;&gt;Yujun Shen&lt;/a&gt;‚Ä† (*equal contribution, ‚Ä†corresponding author)&lt;/p&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://qiuyu96.github.io/CoDeF/&#34;&gt;Project Page&lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/abs/2308.07926&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://ezioby.github.io/CoDeF_Demo/&#34;&gt;High-Res Translation Demo&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;!-- Abstract: *This work presents the content deformation field **CoDeF** as a new type of video representation, which consists of a canonical content field aggregating the static contents in the entire video and a temporal deformation field recording the transformations from the canonical image (i.e., rendered from the canonical content field) to each individual frame along the time axis. Given a target video, these two fields are jointly optimized to reconstruct it through a carefully tailored rendering pipeline. We also introduce some decent regularizations into the optimization process, urging the canonical content field to inherit semantics (e.g., the object shape) from the video. With such a design, **CoDeF** naturally supports lifting image algorithms to videos, in the sense that one can apply an image algorithm to the canonical image and effortlessly propagate the outcomes to the entire video with the aid of the temporal deformation field. We experimentally show that **CoDeF** is able to lift image-to-image translation to video-to-video translation and lift keypoint detection to keypoint tracking without any training. More importantly, thanks to our lifting strategy that deploys the algorithms on only one image, we achieve superior cross-frame consistency in translated videos compared to existing video-to-video translation approaches, and even manage to track non-rigid objects like water and smog.* --&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;The codebase is tested on&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ubuntu 20.04&lt;/li&gt; &#xA; &lt;li&gt;Python 3.10&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt; 2.0.0&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pytorchlightning.ai/index.html&#34;&gt;PyTorch Lightning&lt;/a&gt; 2.0.2&lt;/li&gt; &#xA; &lt;li&gt;1 Nvidia GPU (RTX A6000 48GB) with CUDA version 11.7 (Other GPUs are also suitable, and 10GB of GPU memory is sufficient to run our code.)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To use video visualizer, please install &lt;code&gt;ffmpeg&lt;/code&gt; by:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo apt-get install ffmpeg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For additional Python libraries, please install by:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Our code also depends on &lt;a href=&#34;https://github.com/NVlabs/tiny-cuda-nn&#34;&gt;tiny-cuda-nn&lt;/a&gt;. See &lt;a href=&#34;https://github.com/NVlabs/tiny-cuda-nn#pytorch-extension&#34;&gt;this&lt;/a&gt; for Pytorch extension install instructions.&lt;/p&gt; &#xA;&lt;h2&gt;Data&lt;/h2&gt; &#xA;&lt;h3&gt;Our data&lt;/h3&gt; &#xA;&lt;p&gt;Download our data from &lt;a href=&#34;https://drive.google.com/file/d/1cKZF6ILeokCjsSAGBmummcQh0uRGaC_F/view?usp=sharing&#34;&gt;this URL&lt;/a&gt;, unzip the file and put it in the current directory. Some additional data can be downloaded from &lt;a href=&#34;https://rec.ustc.edu.cn/share/5d1e0bb0-31d7-11ee-aa60-d1fd6c62dfb4&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Customize your own data&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;To be released.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;And organize files as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;CoDeF&#xA;‚îÇ&#xA;‚îî‚îÄ‚îÄ‚îÄ all_sequences&#xA;    ‚îÇ&#xA;    ‚îî‚îÄ‚îÄ‚îÄ NAME1&#xA;           ‚îî‚îÄ NAME1&#xA;           ‚îî‚îÄ NAME1_masks_0 (optional)&#xA;           ‚îî‚îÄ NAME1_masks_1 (optional)&#xA;           ‚îî‚îÄ NAME1_flow (optional)&#xA;           ‚îî‚îÄ NAME1_flow_confidence (optional)&#xA;    ‚îÇ&#xA;    ‚îî‚îÄ‚îÄ‚îÄ NAME2&#xA;           ‚îî‚îÄ NAME2&#xA;           ‚îî‚îÄ NAME2_masks_0 (optional)&#xA;           ‚îî‚îÄ NAME2_masks_1 (optional)&#xA;           ‚îî‚îÄ NAME2_flow (optional)&#xA;           ‚îî‚îÄ NAME2_flow_confidence (optional)&#xA;    ‚îÇ&#xA;    ‚îî‚îÄ‚îÄ‚îÄ ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Pretrained checkpoints&lt;/h2&gt; &#xA;&lt;p&gt;You can download the pre-trained checkpoints trained with the current codebase as follows:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Sequence Name&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Config&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Download&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;beauty_0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;configs/beauty_0/base.yaml&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/11SWfnfDct8bE16802PyqYJqsU4x6ACn8/view?usp=sharing&#34;&gt;Google drive link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;beauty_1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;configs/beauty_1/base.yaml&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/1bSK0ChbPdURWGLdtc9CPLkN4Tfnng51k/view?usp=sharing&#34;&gt;Google drive link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;white_smoke&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;configs/white_smoke/base.yaml&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/1QOBCDGV2hHwxq4eL1E_45z5zhZ-wTJR7/view?usp=sharing&#34;&gt;Google drive link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;lemon_hit&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;configs/lemon_hit/base.yaml&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/140ctcLbv7JTIiy53MuCYtI4_zpIvRXzq/view?usp=sharing&#34;&gt;Google drive link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;scene_0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;configs/scene_0/base.yaml&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/1abOdREarfw1DGscahOJd2gZf1Xn_zN-F/view?usp=sharing&#34;&gt;Google drive link&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;And organize files as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;CoDeF&#xA;‚îÇ&#xA;‚îî‚îÄ‚îÄ‚îÄ ckpts/all_sequences&#xA;    ‚îÇ&#xA;    ‚îî‚îÄ‚îÄ‚îÄ NAME1&#xA;        ‚îÇ&#xA;        ‚îî‚îÄ‚îÄ‚îÄ EXP_NAME (base)&#xA;            ‚îÇ&#xA;            ‚îî‚îÄ‚îÄ‚îÄ NAME1.ckpt&#xA;    ‚îÇ&#xA;    ‚îî‚îÄ‚îÄ‚îÄ NAME2&#xA;        ‚îÇ&#xA;        ‚îî‚îÄ‚îÄ‚îÄ EXP_NAME (base)&#xA;            ‚îÇ&#xA;            ‚îî‚îÄ‚îÄ‚îÄ NAME2.ckpt&#xA;    |&#xA;    ‚îî‚îÄ‚îÄ‚îÄ ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Train a new model&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./scripts/train_multi.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;GPU&lt;/code&gt;: Decide which GPU to train on;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;NAME&lt;/code&gt;: Name of the video sequence;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;EXP_NAME&lt;/code&gt;: Name of the experiment;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;ROOT_DIRECTORY&lt;/code&gt;: Directory of the input video sequence;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;MODEL_SAVE_PATH&lt;/code&gt;: Path to save the checkpoints;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;LOG_SAVE_PATH&lt;/code&gt;: Path to save the logs;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;MASK_DIRECTORY&lt;/code&gt;: Directory of the preprocessed masks (optional);&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;FLOW_DIRECTORY&lt;/code&gt;: Directory of the preprocessed optical flows (optional);&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please check configuration files in &lt;code&gt;configs/&lt;/code&gt;, and you can always add your own model config.&lt;/p&gt; &#xA;&lt;h2&gt;Test reconstruction &lt;a id=&#34;anchor&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./scripts/test_multi.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After running the script, the reconstructed videos can be found in &lt;code&gt;results/all_sequences/{NAME}/{EXP_NAME}&lt;/code&gt;, along with the canonical image.&lt;/p&gt; &#xA;&lt;h2&gt;Test video translation&lt;/h2&gt; &#xA;&lt;p&gt;After obtaining the canonical image through &lt;a href=&#34;https://raw.githubusercontent.com/qiuyu96/CoDeF/main/#anchor&#34;&gt;this step&lt;/a&gt;, use your preferred text prompts to transfer it using &lt;a href=&#34;https://github.com/lllyasviel/ControlNet&#34;&gt;ControlNet&lt;/a&gt;. Once you have the transferred canonical image, place it in &lt;code&gt;all_sequences/${NAME}/${EXP_NAME}_control&lt;/code&gt; (i.e. &lt;code&gt;CANONICAL_DIR&lt;/code&gt; in &lt;code&gt;scripts/test_canonical.sh&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;Then run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./scripts/test_canonical.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The transferred results can be seen in &lt;code&gt;results/all_sequences/{NAME}/{EXP_NAME}_transformed&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: The &lt;code&gt;canonical_wh&lt;/code&gt; option in the configuration file should be set with caution, usually a little larger than &lt;code&gt;img_wh&lt;/code&gt;, as it determines the field of view of the canonical image.&lt;/p&gt; &#xA;&lt;h3&gt;BibTeX&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{ouyang2023codef,&#xA;      title={CoDeF: Content Deformation Fields for Temporally Consistent Video Processing}, &#xA;      author={Hao Ouyang and Qiuyu Wang and Yuxi Xiao and Qingyan Bai and Juntao Zhang and Kecheng Zheng and Xiaowei Zhou and Qifeng Chen and Yujun Shen},&#xA;      journal={arXiv preprint arXiv:2308.07926},&#xA;      year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>documenso/documenso</title>
    <updated>2023-08-21T01:23:34Z</updated>
    <id>tag:github.com,2023-08-21:/documenso/documenso</id>
    <link href="https://github.com/documenso/documenso" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Open Source DocuSign Alternative.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34; style=&#34;margin-top: 120px&#34;&gt; &lt;a href=&#34;https://github.com/documenso/documenso&#34;&gt; &lt;img width=&#34;250px&#34; src=&#34;https://github.com/documenso/documenso/assets/1309312/cd7823ec-4baa-40b9-be78-4acb3b1c73cb&#34; alt=&#34;Documenso Logo&#34;&gt; &lt;/a&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; The Open Source DocuSign Alternative. &lt;br&gt; &lt;a href=&#34;https://documenso.com&#34;&gt;&lt;strong&gt;Learn more ¬ª&lt;/strong&gt;&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://documen.so/discord&#34;&gt;Discord&lt;/a&gt; ¬∑ &lt;a href=&#34;https://documenso.com&#34;&gt;Website&lt;/a&gt; ¬∑ &lt;a href=&#34;https://github.com/documenso/documenso/issues&#34;&gt;Issues&lt;/a&gt; ¬∑ &lt;a href=&#34;https://github.com/documenso/documenso/milestones&#34;&gt;Roadmap&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://documen.so/discord&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Discord-documen.so/discord-%235865F2&#34; alt=&#34;Join Documenso on Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/documenso/documenso/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/documenso/documenso&#34; alt=&#34;Github Stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/documenso/documenso/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-AGPLv3-purple&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/documenso/documenso/pulse&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/commit-activity/m/documenso/documenso&#34; alt=&#34;Commits-per-month&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h1&gt;Documenso 0.9 - Developer Preview&lt;/h1&gt; &#xA;&lt;div&gt; &#xA; &lt;img style=&#34;display: block; height: 120px; width: 24%&#34; src=&#34;https://user-images.githubusercontent.com/1309312/224570645-167128ee-3e39-4578-85d2-5394d9a0379c.png&#34;&gt; &#xA; &lt;img style=&#34;display: block; height: 120px; width: 24%&#34; src=&#34;https://user-images.githubusercontent.com/1309312/224570651-0afd12f8-cfe3-49d1-805e-e495af963d91.png&#34;&gt; &#xA; &lt;img style=&#34;display: block; height: 120px; width: 24%&#34; src=&#34;https://user-images.githubusercontent.com/1309312/224570655-328d2279-058d-4a3e-b5c3-5cbd8a1f4e05.png&#34;&gt; &#xA; &lt;img style=&#34;display: block; height: 120px; width: 24%&#34; src=&#34;https://user-images.githubusercontent.com/1309312/224571617-1f3c2811-c1ac-4d7d-b9b0-4ab183731405.png&#34;&gt; &#xA; &lt;img style=&#34;display: block; height: 120px; width: 24%&#34; src=&#34;https://user-images.githubusercontent.com/1309312/224570322-b2c76ea8-7482-4043-ad97-f1221220c591.png&#34;&gt; &#xA; &lt;img style=&#34;display: block; height: 120px; width: 24%&#34; src=&#34;https://user-images.githubusercontent.com/1309312/224570325-a8055f24-9826-4a23-b116-4fbb0577581a.png&#34;&gt; &#xA; &lt;img style=&#34;display: block; height: 120px; width: 24%&#34; src=&#34;https://user-images.githubusercontent.com/1309312/224570318-f724bbd9-c394-4bdc-bace-2d78af92de44.png&#34;&gt; &#xA; &lt;img style=&#34;display: block; height: 120px; width: 24%&#34; src=&#34;https://user-images.githubusercontent.com/1309312/224571539-f019b860-f613-4b20-86e8-4437c5784265.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; This project is currently under community review and will publish it&#39;s first production release soon‚Ñ¢.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;About this project&lt;/h2&gt; &#xA;&lt;p&gt;Signing documents digitally is fast, easy and should be best practice for every document signed worldwide. This is technically quite easy today, but it also introduces a new party to every signature: The signing tool providers. While this is not a problem in itself, it should make us think about how we want these providers of trust to work. Documenso aims to be the world&#39;s most trusted document signing tool. This trust is built by empowering you to self-host Documenso and review how it works under the hood. Join us in creating the next generation of open trust infrastructure.&lt;/p&gt; &#xA;&lt;h2&gt;Recognition&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.producthunt.com/posts/documenso?utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-documenso&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=395047&amp;amp;theme=light&amp;amp;period=daily&#34; alt=&#34;Documenso - The open source DocuSign alternative | Product Hunt&#34; style=&#34;width: 250px; height: 54px;&#34; width=&#34;250&#34; height=&#34;54&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.producthunt.com/posts/documenso?utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-documenso&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=395047&amp;amp;theme=light&#34; alt=&#34;Documenso - The Open Source DocuSign Alternative. | Product Hunt&#34; style=&#34;width: 250px; height: 54px;&#34; width=&#34;250&#34; height=&#34;54&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Community and Next Steps üéØ&lt;/h2&gt; &#xA;&lt;p&gt;We&#39;re currently working on a redesign of the application including a revamp of the codebase so Documenso can be more intuitive to use and robust to develop upon.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Check out the first source code release in this repository and test it&lt;/li&gt; &#xA; &lt;li&gt;Tell us what you think in the current &lt;a href=&#34;https://github.com/documenso/documenso/discussions&#34;&gt;Discussions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Join the &lt;a href=&#34;https://documen.so/discord&#34;&gt;Discord server&lt;/a&gt; for any questions and getting to know to other community members&lt;/li&gt; &#xA; &lt;li&gt;‚≠ê the repository to help us raise awareness&lt;/li&gt; &#xA; &lt;li&gt;Spread the word on Twitter, that Documenso is working towards a more open signing tool&lt;/li&gt; &#xA; &lt;li&gt;Fix or create &lt;a href=&#34;https://github.com/documenso/documenso/issues&#34;&gt;issues&lt;/a&gt;, that are needed for the first production release&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To contribute please see our &lt;a href=&#34;https://github.com/documenso/documenso/raw/main/CONTRIBUTING.md&#34;&gt;contribution guide&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contact us&lt;/h2&gt; &#xA;&lt;p&gt;Contact us if you are interested in our Enterprise plan for large organizations that need extra flexibility and control.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://cal.com/timurercan/enterprise-customers?utm_source=banner&amp;amp;utm_campaign=oss&#34;&gt;&lt;img alt=&#34;Book us with Cal.com&#34; src=&#34;https://cal.com/book-with-cal-dark.svg?sanitize=true&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Tech&lt;/h1&gt; &#xA;&lt;p&gt;Documenso is built using awesome open source tech including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.typescriptlang.org/&#34;&gt;Typescript&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/JavaScript&#34;&gt;Javascript (when necessary)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nextjs.org/&#34;&gt;NextJS (JS Fullstack Framework)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/&#34;&gt;Postgres SQL (Database)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.prisma.io/&#34;&gt;Prisma (ORM - Object-relational mapping)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tailwindcss.com/&#34;&gt;Tailwind CSS (Styling)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vbuch/node-signpdf&#34;&gt;Node SignPDF (Digital Signature)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/wojtekmaj/react-pdf&#34;&gt;React-PDF for viewing PDFs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Hopding/pdf-lib&#34;&gt;PDF-Lib for PDF manipulation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Check out &lt;code&gt;/package.json&lt;/code&gt; and &lt;code&gt;/apps/web/package.json&lt;/code&gt; for more&lt;/li&gt; &#xA; &lt;li&gt;Support for &lt;a href=&#34;https://github.com/open-pdf-sign&#34;&gt;opensignpdf (requires Java on server)&lt;/a&gt; is currently planned.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;To run Documenso locally you need&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nodejs.org/en/download/&#34;&gt;Node.js (Version: &amp;gt;=18.x)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Node Package Manager NPM - included in Node.js&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/download/&#34;&gt;PostgreSQL (local or remote)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Developer Quickstart&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This is a quickstart for developers. It assumes that you have both &lt;a href=&#34;https://docs.docker.com/get-docker/&#34;&gt;docker&lt;/a&gt; and &lt;a href=&#34;https://docs.docker.com/compose/&#34;&gt;docker-compose&lt;/a&gt; installed on your machine.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Want to get up and running quickly? Follow these steps:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://help.github.com/articles/cloning-a-repository/&#34;&gt;Clone the repository&lt;/a&gt; it to your local device.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/documenso/documenso&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Set up your &lt;code&gt;.env&lt;/code&gt; file using the recommendations in the &lt;code&gt;.env.example&lt;/code&gt; file.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run &lt;code&gt;npm run dx&lt;/code&gt; in the root directory&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This will spin up a postgres database and inbucket mail server in docker containers.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run &lt;code&gt;npm run dev&lt;/code&gt; in the root directory&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Want it even faster? Just use&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm run d&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;That&#39;s it! You should now be able to access the app at &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Incoming mail will be available at &lt;a href=&#34;http://localhost:9000&#34;&gt;http://localhost:9000&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Your database will also be available on port &lt;code&gt;54320&lt;/code&gt;. You can connect to it using your favorite database client.&lt;/p&gt; &#xA;&lt;h2&gt;Developer Setup&lt;/h2&gt; &#xA;&lt;p&gt;Follow these steps to setup documenso on you local machine:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://help.github.com/articles/cloning-a-repository/&#34;&gt;Clone the repository&lt;/a&gt; it to your local device. &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/documenso/documenso&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;npm i&lt;/code&gt; in root directory&lt;/li&gt; &#xA; &lt;li&gt;Rename &lt;code&gt;.env.example&lt;/code&gt; to &lt;code&gt;.env&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Set DATABASE_URL value in .env file &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;You can use the provided test database url (may be wiped at any point)&lt;/li&gt; &#xA;   &lt;li&gt;Or setup a local postgres sql instance (recommended)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Create the database scheme by running &lt;code&gt;db-migrate:dev&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Setup your mail provider &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Set &lt;code&gt;SENDGRID_API_KEY&lt;/code&gt; value in .env file&lt;/li&gt; &#xA;   &lt;li&gt;You need a SendGrid account, which you can create &lt;a href=&#34;https://signup.sendgrid.com/&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;Documenso uses &lt;a href=&#34;https://nodemailer.com/about/&#34;&gt;Nodemailer&lt;/a&gt; so you can easily use your own SMTP server by setting the `SMTP _&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;variables` in your .env&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;npm run dev&lt;/code&gt; root directory to start&lt;/li&gt; &#xA; &lt;li&gt;Register a new user at &lt;a href=&#34;http://localhost:3000/signup&#34;&gt;http://localhost:3000/signup&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Optional: Seed the database using &lt;code&gt;npm run db-seed&lt;/code&gt; to create a test user and document&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Optional: Upload and sign &lt;code&gt;apps/web/resources/example.pdf&lt;/code&gt; manually to test your setup&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Optional: Create your own signing certificate&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;A demo certificate is provided in &lt;code&gt;/app/web/resources/certificate.p12&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;To generate your own using these steps and a Linux Terminal or Windows Subsystem for Linux (WSL) see &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/documenso/documenso/main/#creating-your-own-signing-certificate&#34;&gt;Create your own signing certificate&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Updating&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you pull the newest version from main, using &lt;code&gt;git pull&lt;/code&gt;, it may be necessary to regenerate your database client&lt;/li&gt; &#xA; &lt;li&gt;You can do this by running the generate command in &lt;code&gt;/packages/prisma&lt;/code&gt;: &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npx prisma generate&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;This is not necessary on first clone.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Creating your own signing certificate&lt;/h1&gt; &#xA;&lt;p&gt;For the digital signature of your documents you need a signing certificate in .p12 format (public and private key). You can buy one (not recommended for dev) or use the steps to create a self-signed one:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Generate a private key using the OpenSSL command. You can run the following command to generate a 2048-bit RSA key:&lt;/p&gt; &lt;p&gt;&lt;code&gt;openssl genrsa -out private.key 2048&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Generate a self-signed certificate using the private key. You can run the following command to generate a self-signed certificate:&lt;/p&gt; &lt;p&gt;&lt;code&gt;openssl req -new -x509 -key private.key -out certificate.crt -days 365&lt;/code&gt;&lt;/p&gt; &lt;p&gt;This will prompt you to enter some information, such as the Common Name (CN) for the certificate. Make sure you enter the correct information. The -days parameter sets the number of days for which the certificate is valid.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Combine the private key and the self-signed certificate to create the p12 certificate. You can run the following command to do this:&lt;/p&gt; &lt;p&gt;&lt;code&gt;openssl pkcs12 -export -out certificate.p12 -inkey private.key -in certificate.crt&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You will be prompted to enter a password for the p12 file. Choose a strong password and remember it, as you will need it to use the certificate (&lt;strong&gt;can be empty for dev certificates&lt;/strong&gt;)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Place the certificate &lt;code&gt;/apps/web/resources/certificate.p12&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Docker&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;We are still working on the publishing of docker images, in the meantime you can follow the steps below to create a production ready docker image.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Want to create a production ready docker image? Follow these steps:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run &lt;code&gt;./docker/build.sh&lt;/code&gt; in the root directory.&lt;/li&gt; &#xA; &lt;li&gt;Publish the image to your docker registry of choice.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Deployment&lt;/h1&gt; &#xA;&lt;p&gt;We support a variety of deployment methods, and are actively working on adding more. Stay tuned for updates!&lt;/p&gt; &#xA;&lt;h2&gt;Railway&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://railway.app/template/DjrRRX&#34;&gt;&lt;img src=&#34;https://railway.app/button.svg?sanitize=true&#34; alt=&#34;Deploy on Railway&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Troubleshooting&lt;/h1&gt; &#xA;&lt;h2&gt;I&#39;m not receiving any emails when using the developer quickstart&lt;/h2&gt; &#xA;&lt;p&gt;When using the developer quickstart an &lt;a href=&#34;https://inbucket.org/&#34;&gt;Inbucket&lt;/a&gt; server will be spun up in a docker container that will store all outgoing email locally for you to view.&lt;/p&gt; &#xA;&lt;p&gt;The Web UI can be found at &lt;a href=&#34;http://localhost:9000&#34;&gt;http://localhost:9000&lt;/a&gt; while the SMTP port will be on localhost:2500.&lt;/p&gt; &#xA;&lt;h2&gt;Support IPv6&lt;/h2&gt; &#xA;&lt;p&gt;In case you are deploying to a cluster that uses only IPv6. You can use a custom command to pass a parameter to the NextJS start command&lt;/p&gt; &#xA;&lt;p&gt;For local docker run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -it documenso:latest npm run start -- -H ::&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For k8s or docker-compose&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;containers:&#xA;  - name: documenso&#xA;    image: documenso:latest&#xA;    imagePullPolicy: IfNotPresent&#xA;    command:&#xA;      - npm&#xA;    args:&#xA;      - run&#xA;      - start&#xA;      - --&#xA;      - -H&#xA;      - &#34;::&#34;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>leejet/stable-diffusion.cpp</title>
    <updated>2023-08-21T01:23:34Z</updated>
    <id>tag:github.com,2023-08-21:/leejet/stable-diffusion.cpp</id>
    <link href="https://github.com/leejet/stable-diffusion.cpp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Stable Diffusion in pure C/C++&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/a%20lovely%20cat.png&#34; width=&#34;256x&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;stable-diffusion.cpp&lt;/h1&gt; &#xA;&lt;p&gt;Inference of &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt; in pure C/C++&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Plain C/C++ implementation based on &lt;a href=&#34;https://github.com/ggerganov/ggml&#34;&gt;ggml&lt;/a&gt;, working in the same way as &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;16-bit, 32-bit float support&lt;/li&gt; &#xA; &lt;li&gt;4-bit, 5-bit and 8-bit integer quantization support&lt;/li&gt; &#xA; &lt;li&gt;Accelerated memory-efficient CPU inference &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Only requires ~2.3GB when using txt2img with fp16 precision to generate a 512x512 image&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;AVX, AVX2 and AVX512 support for x86 architectures&lt;/li&gt; &#xA; &lt;li&gt;Original &lt;code&gt;txt2img&lt;/code&gt; and &lt;code&gt;img2img&lt;/code&gt; mode&lt;/li&gt; &#xA; &lt;li&gt;Negative prompt&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;stable-diffusion-webui&lt;/a&gt; style tokenizer (not all the features, only token weighting for now)&lt;/li&gt; &#xA; &lt;li&gt;Sampling method &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;Euler A&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Supported platforms &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Linux&lt;/li&gt; &#xA;   &lt;li&gt;Mac OS&lt;/li&gt; &#xA;   &lt;li&gt;Windows&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;TODO&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; More sampling methods&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; GPU support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Make inference faster &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The current implementation of ggml_conv_2d is slow and has high memory usage&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Continuing to reduce memory usage (quantizing the weights of ggml_conv_2d)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; LoRA support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; k-quants support&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Cross-platform reproducibility (perhaps ensuring consistency with the original SD)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Get the Code&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone --recursive https://github.com/leejet/stable-diffusion.cpp&#xA;cd stable-diffusion.cpp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you have already cloned the repository, you can use the following command to update the repository to the latest code.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd stable-diffusion.cpp&#xA;git pull origin master&#xA;git submodule update&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Convert weights&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;download original weights(.ckpt or .safetensors). For example&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Stable Diffusion v1.4 from &lt;a href=&#34;https://huggingface.co/CompVis/stable-diffusion-v-1-4-original&#34;&gt;https://huggingface.co/CompVis/stable-diffusion-v-1-4-original&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Stable Diffusion v1.5 from &lt;a href=&#34;https://huggingface.co/runwayml/stable-diffusion-v1-5&#34;&gt;https://huggingface.co/runwayml/stable-diffusion-v1-5&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -L -O https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt&#xA;# curl -L -O https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;convert weights to ggml model format&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd models&#xA;pip install -r requirements.txt&#xA;python convert.py [path to weights] --out_type [output precision]&#xA;# For example, python convert.py sd-v1-4.ckpt --out_type f16&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Quantization&lt;/h3&gt; &#xA;&lt;p&gt;You can specify the output model format using the --out_type parameter&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;f16&lt;/code&gt; for 16-bit floating-point&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;f32&lt;/code&gt; for 32-bit floating-point&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;q8_0&lt;/code&gt; for 8-bit integer quantization&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;q5_0&lt;/code&gt; or &lt;code&gt;q5_1&lt;/code&gt; for 5-bit integer quantization&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;q4_0&lt;/code&gt; or &lt;code&gt;q4_1&lt;/code&gt; for 4-bit integer quantization&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Build&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir build&#xA;cd build&#xA;cmake ..&#xA;cmake --build . --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Using OpenBLAS&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;cmake .. -DGGML_OPENBLAS=ON&#xA;cmake --build . --config Release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;usage: ./bin/sd [arguments]&#xA;&#xA;arguments:&#xA;  -h, --help                         show this help message and exit&#xA;  -M, --mode [txt2img or img2img]    generation mode (default: txt2img)&#xA;  -t, --threads N                    number of threads to use during computation (default: -1).&#xA;                                     If threads &amp;lt;= 0, then threads will be set to the number of CPU physical cores&#xA;  -m, --model [MODEL]                path to model&#xA;  -i, --init-img [IMAGE]             path to the input image, required by img2img&#xA;  -o, --output OUTPUT                path to write result image to (default: .\output.png)&#xA;  -p, --prompt [PROMPT]              the prompt to render&#xA;  -n, --negative-prompt PROMPT       the negative prompt (default: &#34;&#34;)&#xA;  --cfg-scale SCALE                  unconditional guidance scale: (default: 7.0)&#xA;  --strength STRENGTH                strength for noising/unnoising (default: 0.75)&#xA;                                     1.0 corresponds to full destruction of information in init image&#xA;  -H, --height H                     image height, in pixel space (default: 512)&#xA;  -W, --width W                      image width, in pixel space (default: 512)&#xA;  --sample-method SAMPLE_METHOD      sample method (default: &#34;eular a&#34;)&#xA;  --steps  STEPS                     number of sample steps (default: 20)&#xA;  -s SEED, --seed SEED               RNG seed (default: 42, use random seed for &amp;lt; 0)&#xA;  -v, --verbose                      print extra info&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;txt2img example&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;./bin/sd -m ../models/sd-v1-4-ggml-model-f16.bin -p &#34;a lovely cat&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Using formats of different precisions will yield results of varying quality.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;f32&lt;/th&gt; &#xA;   &lt;th&gt;f16&lt;/th&gt; &#xA;   &lt;th&gt;q8_0&lt;/th&gt; &#xA;   &lt;th&gt;q5_0&lt;/th&gt; &#xA;   &lt;th&gt;q5_1&lt;/th&gt; &#xA;   &lt;th&gt;q4_0&lt;/th&gt; &#xA;   &lt;th&gt;q4_1&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/f32.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/f16.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q8_0.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q5_0.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q5_1.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q4_0.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/q4_1.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;img2img example&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;./output.png&lt;/code&gt; is the image generated from the above txt2img pipeline&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;./bin/sd --mode img2img -m ../models/sd-v1-4-ggml-model-f16.bin -p &#34;cat with blue eyes&#34; -i ./output.png -o ./img2img_output.png --strength 0.4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/leejet/stable-diffusion.cpp/master/assets/img2img_output.png&#34; width=&#34;256x&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Memory/Disk Requirements&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;precision&lt;/th&gt; &#xA;   &lt;th&gt;f32&lt;/th&gt; &#xA;   &lt;th&gt;f16&lt;/th&gt; &#xA;   &lt;th&gt;q8_0&lt;/th&gt; &#xA;   &lt;th&gt;q5_0&lt;/th&gt; &#xA;   &lt;th&gt;q5_1&lt;/th&gt; &#xA;   &lt;th&gt;q4_0&lt;/th&gt; &#xA;   &lt;th&gt;q4_1&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Disk&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;2.7G&lt;/td&gt; &#xA;   &lt;td&gt;2.0G&lt;/td&gt; &#xA;   &lt;td&gt;1.7G&lt;/td&gt; &#xA;   &lt;td&gt;1.6G&lt;/td&gt; &#xA;   &lt;td&gt;1.6G&lt;/td&gt; &#xA;   &lt;td&gt;1.5G&lt;/td&gt; &#xA;   &lt;td&gt;1.5G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Memory&lt;/strong&gt;(txt2img - 512 x 512)&lt;/td&gt; &#xA;   &lt;td&gt;~2.8G&lt;/td&gt; &#xA;   &lt;td&gt;~2.3G&lt;/td&gt; &#xA;   &lt;td&gt;~2.1G&lt;/td&gt; &#xA;   &lt;td&gt;~2.0G&lt;/td&gt; &#xA;   &lt;td&gt;~2.0G&lt;/td&gt; &#xA;   &lt;td&gt;~2.0G&lt;/td&gt; &#xA;   &lt;td&gt;~2.0G&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ggerganov/ggml&#34;&gt;ggml&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;stable-diffusion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;stable-diffusion-webui&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/crowsonkb/k-diffusion&#34;&gt;k-diffusion&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>