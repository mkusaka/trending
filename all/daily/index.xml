<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-01T01:29:05Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>nomic-ai/gpt4all</title>
    <updated>2023-04-01T01:29:05Z</updated>
    <id>tag:github.com,2023-04-01:/nomic-ai/gpt4all</id>
    <link href="https://github.com/nomic-ai/gpt4all" rel="alternate"></link>
    <summary type="html">&lt;p&gt;gpt4all: a chatbot trained on a massive collection of clean assistant data including code, stories and dialogue&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;GPT4All&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt;Demo, data and code to train an assistant-style large language model with ~800k GPT-3.5-Turbo Generations based on LLaMa&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf&#34;&gt;&lt;span&gt;ðŸ“—&lt;/span&gt; Technical Report&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://discord.gg/kvmy6dQB&#34;&gt;Discord&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/13879686/228352356-de66ca7a-df70-474e-b929-2e3656165051.gif&#34; alt=&#34;gpt4all-lora-demo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Run on M1 Mac (not sped up!)&lt;/p&gt; &#xA;&lt;h1&gt;Try it yourself&lt;/h1&gt; &#xA;&lt;p&gt;Here&#39;s how to get started with the CPU quantized gpt4all model checkpoint:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download the &lt;code&gt;gpt4all-lora-quantized.bin&lt;/code&gt; file from &lt;a href=&#34;https://the-eye.eu/public/AI/models/nomic-ai/gpt4all/gpt4all-lora-quantized.bin&#34;&gt;Direct Link&lt;/a&gt; or &lt;a href=&#34;https://tinyurl.com/gpt4all-lora-quantized&#34;&gt;[Torrent-Magnet]&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Clone this repository, navigate to &lt;code&gt;chat&lt;/code&gt;, and place the downloaded file there.&lt;/li&gt; &#xA; &lt;li&gt;Run the appropriate command for your OS: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;M1 Mac/OSX: &lt;code&gt;cd chat;./gpt4all-lora-quantized-OSX-m1&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Linux: &lt;code&gt;cd chat;./gpt4all-lora-quantized-linux-x86&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Windows (PowerShell): &lt;code&gt;cd chat;./gpt4all-lora-quantized-win64.exe&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Intel Mac/OSX: &lt;code&gt;cd chat;./gpt4all-lora-quantized-OSX-intel&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For custom hardware compilation, see our &lt;a href=&#34;https://github.com/zanussbaum/gpt4all.cpp&#34;&gt;llama.cpp&lt;/a&gt; fork.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://the-eye.eu/public/AI/models/nomic-ai/gpt4all/gpt4all-lora-unfiltered-quantized.bin&#34;&gt;Secret Unfiltered Checkpoint&lt;/a&gt; - &lt;a href=&#34;https://the-eye.eu/public/AI/models/nomic-ai/gpt4all/gpt4all-lora-unfiltered-quantized.bin.torrent&#34;&gt;[Torrent]&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This model had all refusal to answer responses removed from training. Try it with:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;cd chat;./gpt4all-lora-quantized-OSX-m1 -m gpt4all-lora-unfiltered-quantized.bin&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Note: the full model on GPU (16GB of RAM required) performs much better in our qualitative evaluations.&lt;/p&gt; &#xA;&lt;h1&gt;Python Client&lt;/h1&gt; &#xA;&lt;h2&gt;CPU Interface&lt;/h2&gt; &#xA;&lt;p&gt;To get running using the python client with the CPU interface, first install the &lt;a href=&#34;https://github.com/nomic-ai/nomic&#34;&gt;nomic client&lt;/a&gt; using &lt;code&gt;pip install nomic&lt;/code&gt; Then, you can use the following script to interact with GPT4All:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from nomic.gpt4all import GPT4All&#xA;m = GPT4All()&#xA;m.open()&#xA;m.prompt(&#39;write me a story about a lonely computer&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;GPU Interface&lt;/h2&gt; &#xA;&lt;p&gt;There are two ways to get up and running with this model on GPU. The setup here is slightly more involved than the CPU model.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;clone the nomic client &lt;a href=&#34;https://github.com/nomic-ai/nomic&#34;&gt;repo&lt;/a&gt; and run &lt;code&gt;pip install .[GPT4All]&lt;/code&gt; in the home dir.&lt;/li&gt; &#xA; &lt;li&gt;run &lt;code&gt;pip install nomic&lt;/code&gt; and install the additional deps from the wheels built &lt;a href=&#34;https://github.com/nomic-ai/nomic/tree/main/bin&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Once this is done, you can run the model on GPU with a script like the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from nomic.gpt4all import GPT4AllGPU&#xA;m = GPT4AllGPU(LLAMA_PATH)&#xA;config = {&#39;num_beams&#39;: 2,&#xA;          &#39;min_new_tokens&#39;: 10,&#xA;          &#39;max_length&#39;: 100,&#xA;          &#39;repetition_penalty&#39;: 2.0}&#xA;out = m.generate(&#39;write me a story about a lonely computer&#39;, config)&#xA;print(out)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Where LLAMA_PATH is the path to a Huggingface Automodel compliant LLAMA model. Nomic is unable to distribute this file at this time. We are working on a GPT4All that does not have this limitation right now.&lt;/p&gt; &#xA;&lt;p&gt;You can pass any of the &lt;a href=&#34;https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig&#34;&gt;huggingface generation config params&lt;/a&gt; in the config.&lt;/p&gt; &#xA;&lt;h1&gt;Roadmap&lt;/h1&gt; &#xA;&lt;h2&gt;Short Term&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;span style=&#34;color:green&#34;&gt;(IN PROGRESS)&lt;/span&gt; Train a GPT4All model based on GPTJ to alleviate llama distribution issues.&lt;/li&gt; &#xA; &lt;li&gt;&lt;span style=&#34;color:green&#34;&gt;(IN PROGRESS)&lt;/span&gt; Create improved CPU and GPU interfaces for this model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;span style=&#34;color:red&#34;&gt;(NOT STARTED)&lt;/span&gt; Integrate llama.cpp bindings&lt;/li&gt; &#xA; &lt;li&gt;&lt;span style=&#34;color:red&#34;&gt;(NOT STARTED)&lt;/span&gt; Create a good conversational chat interface for the model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;span style=&#34;color:red&#34;&gt;(NOT STARTED)&lt;/span&gt; Allow users to opt in and submit their chats for subsequent training runs&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Medium Term&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;span style=&#34;color:red&#34;&gt;(NOT STARTED)&lt;/span&gt; Integrate GPT4All with &lt;a href=&#34;https://atlas.nomic.ai&#34;&gt;Atlas&lt;/a&gt; to allow for document retrieval. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;BLOCKED by GPT4All based on GPTJ&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;span style=&#34;color:red&#34;&gt;(NOT STARTED)&lt;/span&gt; Integrate GPT4All with Langchain.&lt;/li&gt; &#xA; &lt;li&gt;&lt;span style=&#34;color:green&#34;&gt;(IN PROGRESS)&lt;/span&gt; Build easy custom training scripts to allow users to fine tune models.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Long Term&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;span style=&#34;color:red&#34;&gt;(NOT STARTED)&lt;/span&gt; Allow anyone to curate training data for subsequent GPT4All releases using Atlas.&lt;/li&gt; &#xA; &lt;li&gt;&lt;span style=&#34;color:green&#34;&gt;(IN PROGRESS)&lt;/span&gt; Democratize AI.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Reproducibility&lt;/h1&gt; &#xA;&lt;p&gt;Trained LoRa Weights:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;gpt4all-lora (four full epochs of training): &lt;a href=&#34;https://huggingface.co/nomic-ai/gpt4all-lora&#34;&gt;https://huggingface.co/nomic-ai/gpt4all-lora&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;gpt4all-lora-epoch-2 (three full epochs of training) &lt;a href=&#34;https://huggingface.co/nomic-ai/gpt4all-lora-epoch-2&#34;&gt;https://huggingface.co/nomic-ai/gpt4all-lora-epoch-2&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Raw Data:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations&#34;&gt;Training Data Without P3&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Explorer: &lt;a href=&#34;https://atlas.nomic.ai/map/gpt4all_data_clean_without_p3&#34;&gt;https://atlas.nomic.ai/map/gpt4all_data_clean_without_p3&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations_with_p3&#34;&gt;Full Dataset with P3&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Explorer: &lt;a href=&#34;https://atlas.nomic.ai/map/gpt4all_data_clean&#34;&gt;https://atlas.nomic.ai/map/gpt4all_data_clean&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We are not distributing a LLaMa 7B checkpoint.&lt;/p&gt; &#xA;&lt;p&gt;You can reproduce our trained model by doing the following:&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;Clone the repo&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;git clone --recurse-submodules https://github.com/nomic-ai/gpt4all.git&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;git submodule configure &amp;amp;&amp;amp; git submodule update&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Setup the environment&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m pip install -r requirements.txt&#xA;&#xA;cd transformers&#xA;pip install -e . &#xA;&#xA;cd ../peft&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;accelerate launch --dynamo_backend=inductor --num_processes=8 --num_machines=1 --machine_rank=0 --deepspeed_multinode_launcher standard --mixed_precision=bf16  --use_deepspeed --deepspeed_config_file=configs/deepspeed/ds_config.json train.py --config configs/train/finetune-7b.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Generate&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python generate.py --config configs/generate/generate.yaml --prompt &#34;Write a script to reverse a string in Python&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Need Help?&lt;/h2&gt; &#xA;&lt;p&gt;Join the &lt;a href=&#34;https://discord.gg/kvmy6dQB&#34;&gt; Discord &lt;/a&gt; and ask for help in &lt;code&gt;#gpt4all-help&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Sample Generations&lt;/h1&gt; &#xA;&lt;h3&gt;Provide instructions for the given exercise. Leg Raises&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Leg Raises&lt;/p&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Stand with your feet shoulder-width apart and your knees slightly bent.&lt;/li&gt; &#xA;  &lt;li&gt;Raise your arms straight out in front of you.&lt;/li&gt; &#xA;  &lt;li&gt;Slowly bend your knees and raise your heels off the ground.&lt;/li&gt; &#xA;  &lt;li&gt;Hold this position for a count of 3, then slowly lower your heels back to the ground.&lt;/li&gt; &#xA;  &lt;li&gt;Repeat the exercise 10 times.&lt;/li&gt; &#xA;  &lt;li&gt;Do not let your knees go beyond your toes.&lt;/li&gt; &#xA;  &lt;li&gt;Keep your back straight and your abdominal muscles engaged.&lt;/li&gt; &#xA;  &lt;li&gt;Do not let your hips sag or your back arch.&lt;/li&gt; &#xA;  &lt;li&gt;Keep your arms straight and your elbows locked.&lt;/li&gt; &#xA;  &lt;li&gt;Do not let your head drop or your shoulders rise.&lt;/li&gt; &#xA;  &lt;li&gt;Breathe normally throughout the exercise.&lt;/li&gt; &#xA;  &lt;li&gt;Rest for 30 seconds before repeating the exercise.&lt;/li&gt; &#xA;  &lt;li&gt;Gradually increase the number of repetitions as you become stronger.&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;A color description has been provided. Find the CSS code associated with that color. A light red color with a medium light shade of pink&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;The CSS code associated with the color provided is: #FF6347&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Come up with an interesting idea for a new movie plot. Your plot should be described with a title and a summary.&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;The title of your movie plot should be &#34;The Last Stand&#34;. 2. The summary of your movie plot should be: A group of mercenaries are hired to protect a small town from a dangerous criminal who is on the run. However, the town&#39;s sheriff is not willing to let them take over and decides to take matters into his own hands.&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Reverse a string in python.&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;In Python, you can reverse a list or tuple by using the reversed() function on it. Here&#39;s an example of how to use this method with strings:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;my_string = &#34;Hello World&#34; # Define your original string here&#xA;reversed_str = my_string[::-1]   # Use a slice and negative index for reverse order&#xA;print(reversed_str)     # Output will be reversed version of the inputted string.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;List 10 dogs.&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Labrador Retriever&lt;/li&gt; &#xA;  &lt;li&gt;Golden Retriever&lt;/li&gt; &#xA;  &lt;li&gt;Beagle&lt;/li&gt; &#xA;  &lt;li&gt;Poodle&lt;/li&gt; &#xA;  &lt;li&gt;German Shepherd&lt;/li&gt; &#xA;  &lt;li&gt;Bulldog&lt;/li&gt; &#xA;  &lt;li&gt;Rottweiler&lt;/li&gt; &#xA;  &lt;li&gt;Boxer&lt;/li&gt; &#xA;  &lt;li&gt;Shih Tzu&lt;/li&gt; &#xA;  &lt;li&gt;Pug&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Write me a poem about the fall of Julius Ceasar into a ceasar salad in iambic pentameter.&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;The fall of Julius Ceasar into a ceasar salad In iambic pentameter, The mighty Roman emperor Fell into a salad of lettuce and croutons, His empire crumbling around him, As he was devoured by the hungry diners. The once mighty emperor Was now just a salad topping, His legacy reduced to a mere garnish, As he was consumed by the masses. The fall of Julius Ceasar into a ceasar salad, In iambic pentameter, Was a tragic end to a great man, Who had once ruled the world with an iron fist. But now, he was just a salad topping, His legacy reduced to a mere garnish, As he was consumed by the masses.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;What is a three word topic describing the following keywords: baseball, football, soccer:&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Sports, athletics, games&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you utilize this reposistory, models or data in a downstream project, please consider citing it with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{gpt4all,&#xA;  author = {Yuvanesh Anand and Zach Nussbaum and Brandon Duderstadt and Benjamin Schmidt and Andriy Mulyar},&#xA;  title = {GPT4All: Training an Assistant-style Chatbot with Large Scale Data Distillation from GPT-3.5-Turbo},&#xA;  year = {2023},&#xA;  publisher = {GitHub},&#xA;  journal = {GitHub repository},&#xA;  howpublished = {\url{https://github.com/nomic-ai/gpt4all}},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>gkamradt/langchain-tutorials</title>
    <updated>2023-04-01T01:29:05Z</updated>
    <id>tag:github.com,2023-04-01:/gkamradt/langchain-tutorials</id>
    <link href="https://github.com/gkamradt/langchain-tutorials" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Overview and tutorial of the LangChain Library&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LangChain Tutorials&lt;/h1&gt; &#xA;&lt;p&gt;Overview and tutorial of the &lt;a href=&#34;https://langchain.readthedocs.io/en/latest/&#34;&gt;LangChain library&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See the accompanying YouTube tutorials @ &lt;a href=&#34;https://www.youtube.com/channel/UCyR2Ct3pDOeZSRyZH5hPO-Q&#34;&gt;https://www.youtube.com/channel/UCyR2Ct3pDOeZSRyZH5hPO-Q&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you want to get updated when new tutorials are out, sign up at &lt;a href=&#34;https://dataindependent.com/&#34;&gt;DataIndependent&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This series is provided by and associated with &lt;a href=&#34;https://dataindependent.com/&#34;&gt;DataIndependent&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>di-sukharev/opencommit</title>
    <updated>2023-04-01T01:29:05Z</updated>
    <id>tag:github.com,2023-04-01:/di-sukharev/opencommit</id>
    <link href="https://github.com/di-sukharev/opencommit" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GPT CLI to auto-generate impressive commits in 1 second ðŸ¤¯ðŸ”«&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;div&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/di-sukharev/opencommit/master/.github/logo-grad.svg?sanitize=true&#34; alt=&#34;OpenCommit logo&#34;&gt; &#xA;  &lt;h1 align=&#34;center&#34;&gt;OpenCommit&lt;/h1&gt; &#xA;  &lt;h4 align=&#34;center&#34;&gt;Follow the bird &lt;a href=&#34;https://twitter.com/io_Y_oi&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/io_Y_oi?style=flat&amp;amp;label=io_Y_oi&amp;amp;logo=twitter&amp;amp;color=0bf&amp;amp;logoColor=fff&#34; align=&#34;center&#34;&gt;&lt;/a&gt; &lt;/h4&gt; &#xA; &lt;/div&gt; &#xA; &lt;h2&gt;GPT CLI to auto-generate impressive commits in 1 second&lt;/h2&gt; &#xA; &lt;p&gt;Killing lame commits with AI ðŸ¤¯ðŸ”«&lt;/p&gt; &#xA; &lt;a href=&#34;https://www.npmjs.com/package/opencommit&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/opencommit&#34; alt=&#34;Current version&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/di-sukharev/opencommit/master/.github/opencommit-example.png&#34; alt=&#34;OpenCommit example&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;All the commits in this repo are done with OpenCommit â€” look into &lt;a href=&#34;https://github.com/di-sukharev/opencommit/commit/eae7618d575ee8d2e9fff5de56da79d40c4bc5fc&#34;&gt;the commits&lt;/a&gt; to see how OpenCommit works. Emoji and long commit description text is configurable.&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Install OpenCommit globally to use in any repository:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm install -g opencommit&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Get your API key from &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;OpenAI&lt;/a&gt;. Make sure you add payment details, so API works.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Set the key to OpenCommit config:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;opencommit config set OPENAI_API_KEY=&amp;lt;your_api_key&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Your api key is stored locally in &lt;code&gt;~/.opencommit&lt;/code&gt; config file.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;You can call OpenCommit directly to generate a commit message for your staged changes:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git add &amp;lt;files...&amp;gt;&#xA;opencommit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also use the &lt;code&gt;oc&lt;/code&gt; shortcut:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git add &amp;lt;files...&amp;gt;&#xA;oc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;h3&gt;Preface commits with emoji ðŸ¤ &lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitmoji.dev/&#34;&gt;GitMoji&lt;/a&gt; convention is used.&lt;/p&gt; &#xA;&lt;p&gt;To add emoji:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;oc config set emoji=true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To remove emoji:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;oc config set emoji=false&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Postface commits with descriptions of changes&lt;/h3&gt; &#xA;&lt;p&gt;To add descriptions:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;oc config set description=true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To remove description:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;oc config set description=false&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Internationalization support&lt;/h3&gt; &#xA;&lt;p&gt;To specify the language used to generate commit messages:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# de, German ,Deutsch&#xA;oc config set language=de&#xA;oc config set language=German&#xA;oc config set language=Deutsch&#xA;&#xA;# fr, French, franÃ§aise&#xA;oc config set language=fr&#xA;oc config set language=French&#xA;oc config set language=franÃ§aise&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The default language set is &lt;strong&gt;English&lt;/strong&gt;&lt;br&gt; All available languages are currently listed in the &lt;a href=&#34;https://github.com/di-sukharev/opencommit/tree/master/src/i18n&#34;&gt;i18n&lt;/a&gt; folder&lt;/p&gt; &#xA;&lt;h3&gt;Git flags&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;opencommit&lt;/code&gt; or &lt;code&gt;oc&lt;/code&gt; commands can be used in place of the &lt;code&gt;git commit -m &#34;${generatedMessage}&#34;&lt;/code&gt; command. This means that any regular flags that are used with the &lt;code&gt;git commit&lt;/code&gt; command will also be applied when using &lt;code&gt;opencommit&lt;/code&gt; or &lt;code&gt;oc&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;oc --no-verify&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;is translated to :&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git commit -m &#34;${generatedMessage}&#34; --no-verify&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Ignore files&lt;/h3&gt; &#xA;&lt;p&gt;You can ignore files from submission to OpenAI by creating a &lt;code&gt;.opencommitignore&lt;/code&gt; file. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ignorelang&#34;&gt;path/to/large-asset.zip&#xA;**/*.jpg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is useful for preventing opencommit from uploading artifacts and large files.&lt;/p&gt; &#xA;&lt;p&gt;By default, opencommit ignores files matching: &lt;code&gt;*-lock.*&lt;/code&gt; and &lt;code&gt;*.lock&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Git hook&lt;/h2&gt; &#xA;&lt;p&gt;You can set OpenCommit as Git &lt;a href=&#34;https://git-scm.com/docs/githooks#_prepare_commit_msg&#34;&gt;&lt;code&gt;prepare-commit-msg&lt;/code&gt;&lt;/a&gt; hook. Hook integrates with you IDE Source Control and allows you edit the message before commit.&lt;/p&gt; &#xA;&lt;p&gt;To set the hook:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;oc hook set&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To unset the hook:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;oc hook unset&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To use the hook:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git add &amp;lt;files...&amp;gt;&#xA;git commit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or follow the process of your IDE Source Control feature, when it calls &lt;code&gt;git commit&lt;/code&gt; command â€” OpenCommit will integrate into the flow.&lt;/p&gt; &#xA;&lt;h2&gt;Payments&lt;/h2&gt; &#xA;&lt;p&gt;You pay for your own requests to OpenAI API. OpenCommit uses ChatGPT official model, that is ~10x times cheaper than GPT-3 and ~6x times cheaper than GPT-4.&lt;/p&gt;</summary>
  </entry>
</feed>