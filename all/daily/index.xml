<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-16T01:28:55Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>StanGirard/quivr</title>
    <updated>2023-05-16T01:28:55Z</updated>
    <id>tag:github.com,2023-05-16:/StanGirard/quivr</id>
    <link href="https://github.com/StanGirard/quivr" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Dump all your files and thoughts into your GenerativeAI brain and chat with it&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Quivr&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/StanGirard/quivr/main/logo.png&#34; alt=&#34;Quivr-logo&#34; width=&#34;30%&#34;&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;p&gt;Join our &lt;a href=&#34;https://discord.gg/5SDcUSzF&#34;&gt;discord&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Quivr is your second brain in the cloud, designed to easily store and retrieve unstructured information. It&#39;s like Obsidian but powered by generative AI.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Store Anything&lt;/strong&gt;: Quivr can handle almost any type of data you throw at it. Text, images, code snippets, you name it.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Generative AI&lt;/strong&gt;: Quivr uses advanced AI to help you generate and retrieve information.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fast and Efficient&lt;/strong&gt;: Designed with speed and efficiency in mind. Quivr makes sure you can access your data as quickly as possible.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Secure&lt;/strong&gt;: Your data is stored securely in the cloud and is always under your control.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Compatible Files&lt;/strong&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Text&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Markdown&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;PDF&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Audio&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Open Source&lt;/strong&gt;: Quivr is open source and free to use.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;h3&gt;Demo with GPT3.5&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/StanGirard/Quivr/assets/19614572/a3cddc6a-ca28-44ad-9ede-3122fa918b51&#34;&gt;https://github.com/StanGirard/Quivr/assets/19614572/a3cddc6a-ca28-44ad-9ede-3122fa918b51&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Demo with Claude 100k context&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/StanGirard/quivr/assets/5101573/9dba918c-9032-4c8d-9eea-94336d2c8bd4&#34;&gt;https://github.com/StanGirard/quivr/assets/5101573/9dba918c-9032-4c8d-9eea-94336d2c8bd4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;These instructions will get you a copy of the project up and running on your local machine for development and testing purposes.&lt;/p&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;p&gt;What things you need to install the software and how to install them.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.10 or higher&lt;/li&gt; &#xA; &lt;li&gt;Pip&lt;/li&gt; &#xA; &lt;li&gt;Virtualenv&lt;/li&gt; &#xA; &lt;li&gt;Supabase account&lt;/li&gt; &#xA; &lt;li&gt;Supabase API key&lt;/li&gt; &#xA; &lt;li&gt;Supabase URL&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installing&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Clone the repository&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone git@github.com:StanGirard/Quivr.git &amp;amp; cd Quivr&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a virtual environment&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;virtualenv venv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Activate the virtual environment&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;source venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install the dependencies&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Copy the streamlit secrets.toml example file&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp .streamlit/secrets.toml.example .streamlit/secrets.toml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Add your credentials to .streamlit/secrets.toml file&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;supabase_url = &#34;SUPABASE_URL&#34;&#xA;supabase_service_key = &#34;SUPABASE_SERVICE_KEY&#34;&#xA;openai_api_key = &#34;OPENAI_API_KEY&#34;&#xA;anthropic_api_key = &#34;ANTHROPIC_API_KEY&#34; # Optional&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run the migration script on the Supabase database via the web interface&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- Enable the pgvector extension to work with embedding vectors&#xA;       create extension vector;&#xA;&#xA;       -- Create a table to store your documents&#xA;       create table documents (&#xA;       id bigserial primary key,&#xA;       content text, -- corresponds to Document.pageContent&#xA;       metadata jsonb, -- corresponds to Document.metadata&#xA;       embedding vector(1536) -- 1536 works for OpenAI embeddings, change if needed&#xA;       );&#xA;&#xA;       CREATE FUNCTION match_documents(query_embedding vector(1536), match_count int)&#xA;           RETURNS TABLE(&#xA;               id bigint,&#xA;               content text,&#xA;               metadata jsonb,&#xA;               -- we return matched vectors to enable maximal marginal relevance searches&#xA;               embedding vector(1536),&#xA;               similarity float)&#xA;           LANGUAGE plpgsql&#xA;           AS $$&#xA;           # variable_conflict use_column&#xA;       BEGIN&#xA;           RETURN query&#xA;           SELECT&#xA;               id,&#xA;               content,&#xA;               metadata,&#xA;               embedding,&#xA;               1 -(documents.embedding &amp;lt;=&amp;gt; query_embedding) AS similarity&#xA;           FROM&#xA;               documents&#xA;           ORDER BY&#xA;               documents.embedding &amp;lt;=&amp;gt; query_embedding&#xA;           LIMIT match_count;&#xA;       END;&#xA;       $$;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run the app&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;streamlit run main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Built With&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.python.org/&#34;&gt;Python&lt;/a&gt; - The programming language used.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://streamlit.io/&#34;&gt;Streamlit&lt;/a&gt; - The web framework used.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://supabase.io/&#34;&gt;Supabase&lt;/a&gt; - The open source Firebase alternative.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Open a pull request and we&#39;ll review it as soon as possible.&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#StanGirard/quivr&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=StanGirard/quivr&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>csunny/DB-GPT</title>
    <updated>2023-05-16T01:28:55Z</updated>
    <id>tag:github.com,2023-05-16:/csunny/DB-GPT</id>
    <link href="https://github.com/csunny/DB-GPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Interact your data and environment using the local GPT, no data leaks, 100% privately, 100% security&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DB-GPT &lt;img src=&#34;https://img.shields.io/github/stars/csunny/db-gpt?style=social&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/h1&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/csunny/DB-GPT/main/README.en.md&#34;&gt;English Edition&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;背景&lt;/h2&gt; &#xA;&lt;p&gt;随着大模型的发布迭代，大模型变得越来越智能，在使用大模型的过程当中，遇到极大的数据安全与隐私挑战。在利用大模型能力的过程中我们的私密数据跟环境需要掌握自己的手里，完全可控，避免任何的数据隐私泄露以及安全风险。基于此，我们发起了DB-GPT项目，为所有以数据库为基础的场景，构建一套完整的私有大模型解决方案。 此方案因为支持本地部署，所以不仅仅可以应用于独立私有环境，而且还可以根据业务模块独立部署隔离，让大模型的能力绝对私有、安全、可控。&lt;/p&gt; &#xA;&lt;h2&gt;愿景&lt;/h2&gt; &#xA;&lt;p&gt;DB-GPT 是一个开源的以数据库为基础的GPT实验项目，使用本地化的GPT大模型与您的数据和环境进行交互，无数据泄露风险，100% 私密，100% 安全。&lt;/p&gt; &#xA;&lt;h2&gt;特性一览&lt;/h2&gt; &#xA;&lt;p&gt;目前我们已经发布了多种关键的特性，这里一一列举展示一下当前发布的能力。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;SQL 语言能力 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;SQL生成&lt;/li&gt; &#xA;   &lt;li&gt;SQL诊断&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;私域问答与数据处理 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;数据库知识问答&lt;/li&gt; &#xA;   &lt;li&gt;数据处理&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;插件模型 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;支持自定义插件执行任务，原生支持Auto-GPT插件。如: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;SQL自动执行，获取查询结果&lt;/li&gt; &#xA;     &lt;li&gt;自动爬取学习知识&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;知识库统一向量存储/索引 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;非结构化数据支持&lt;/li&gt; &#xA;   &lt;li&gt;PDF、MarkDown、CSV、WebURL&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;效果演示&lt;/h2&gt; &#xA;&lt;p&gt;示例通过 RTX 4090 GPU 演示，&lt;a href=&#34;https://www.youtube.com/watch?v=1PWI6F89LPo&#34;&gt;YouTube 地址&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;运行环境演示&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;./assets/演示.gif&#34; width=&#34;600px&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/csunny/DB-GPT/main/assets/Auto-DB-GPT.gif&#34; width=&#34;600px&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;SQL 生成&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;生成建表语句&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/csunny/DB-GPT/main/assets/SQL_Gen_CreateTable.png&#34; width=&#34;600px&#34;&gt; &lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;生成可运行SQL 首先选择对应的数据库, 然后模型即可根据对应的数据库 Schema 信息生成 SQL, 运行成功的效果如下面的演示：&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/csunny/DB-GPT/main/assets/exeable.png&#34; width=&#34;600px&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;数据库问答&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/csunny/DB-GPT/main/assets/DB_QA.png&#34; width=&#34;600px&#34;&gt; &lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;基于默认内置知识库问答&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/csunny/DB-GPT/main/assets/VectorDBQA.png&#34; width=&#34;600px&#34;&gt; &lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;自己新增知识库&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/csunny/DB-GPT/main/assets/new_knownledge.gif&#34; width=&#34;600px&#34;&gt; &lt;/p&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;从网络自己爬取数据学习&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;TODO&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;架构方案&lt;/h2&gt; &#xA;&lt;p&gt;DB-GPT基于&lt;a href=&#34;https://github.com/lm-sys/FastChat&#34;&gt;FastChat&lt;/a&gt; 构建大模型运行环境，并提供 vicuna 作为基础的大语言模型。此外，我们通过langchain提供私域知识库问答能力。同时我们支持插件模式, 在设计上原生支持Auto-GPT插件。&lt;/p&gt; &#xA;&lt;p&gt;整个DB-GPT的架构，如下图所示&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/csunny/DB-GPT/main/assets/DB-GPT.png&#34; width=&#34;600px&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;核心能力主要有以下几个部分。&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;知识库能力&lt;/li&gt; &#xA; &lt;li&gt;大模型管理能力&lt;/li&gt; &#xA; &lt;li&gt;统一的数据向量化存储与索引&lt;/li&gt; &#xA; &lt;li&gt;连接模块&lt;/li&gt; &#xA; &lt;li&gt;Agent与插件&lt;/li&gt; &#xA; &lt;li&gt;Prompt自动生成与优化&lt;/li&gt; &#xA; &lt;li&gt;多端产品界面&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;下面对每个模块也做一些简要的介绍:&lt;/p&gt; &#xA;&lt;h3&gt;知识库能力&lt;/h3&gt; &#xA;&lt;p&gt;知识库作为当前用户需求最大的场景，我们原生支持知识库的构建与处理。同时在本项目当中，也提供了多种知识库的管理策略。 如: 1. 默认内置知识库 2. 自定义新增知识库 3. 通过插件能力自抓取构建知识库等多种使用场景。 用户只需要整理好知识文档，即可用我们现有的能力构建大模型所需要的知识库能力。&lt;/p&gt; &#xA;&lt;h3&gt;大模型管理能力&lt;/h3&gt; &#xA;&lt;p&gt;在底层大模型接入中，设计了开放的接口，支持对接多种大模型。同时对于接入模型的效果，我们有非常严格的把控与评审机制。对大模型能力上与ChatGPT对比，在准确率上需要满足85%以上的能力对齐。我们用更高的标准筛选模型，是期望在用户使用过程中，可以省去前面繁琐的测试评估环节。&lt;/p&gt; &#xA;&lt;h3&gt;统一的数据向量化存储与索引&lt;/h3&gt; &#xA;&lt;p&gt;为了方便对知识向量化之后的管理，我们内置了多种向量存储引擎，从基于内存的Chroma到分布式的Milvus, 可以根据自己的场景需求，选择不同的存储引擎，整个知识向量存储是AI能力增强的基石，向量作为人与大语言模型交互的中间语言，在本项目中的作用非常重要。&lt;/p&gt; &#xA;&lt;h3&gt;连接模块&lt;/h3&gt; &#xA;&lt;p&gt;为了能够更方便的与用户的私有环境进行交互，项目设计了连接模块，连接模块可以支持连接到数据库、Excel、知识库等等多种环境当中，实现信息与数据交互。&lt;/p&gt; &#xA;&lt;h3&gt;Agent与插件&lt;/h3&gt; &#xA;&lt;p&gt;Agent与插件能力是大模型能否自动化的核心，在本的项目中，原生支持插件模式，大模型可以自动化完成目标。 同时为了充分发挥社区的优势，本项目中所用的插件原生支持Auto-GPT插件生态，即Auto-GPT的插件可以直接在我们的项目中运行。&lt;/p&gt; &#xA;&lt;h3&gt;Prompt自动生成与优化&lt;/h3&gt; &#xA;&lt;p&gt;Prompt是与大模型交互过程中非常重要的部分，一定程度上Prompt决定了大模型生成答案的质量与准确性，在本的项目中，我们会根据用户输入与使用场景，自动优化对应的Prompt，让用户使用大语言模型变得更简单、更高效。&lt;/p&gt; &#xA;&lt;h3&gt;多端产品界面&lt;/h3&gt; &#xA;&lt;p&gt;TODO: 在终端展示上，我们将提供多端产品界面。包括PC、手机、命令行、slack等多种模式。&lt;/p&gt; &#xA;&lt;h2&gt;安装教程&lt;/h2&gt; &#xA;&lt;h3&gt;硬件说明&lt;/h3&gt; &#xA;&lt;p&gt;因为我们的项目在效果上具备ChatGPT 85%以上的能力，因此对硬件有一定的要求。 但总体来说，我们在消费级的显卡上即可完成项目的部署使用，具体部署的硬件说明如下:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;GPU型号 |  显存大小 |   性能&#xA;-------|----------|------------------------------&#xA;TRX4090| 24G      |可以流畅的进行对话推理，无卡顿&#xA;TRX3090| 24G      |可以流畅进行对话推理，有卡顿感，但好与V100&#xA;V100   | 16G      |可以进行对话推理，有明显卡顿&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;DB-GPT安装&lt;/h3&gt; &#xA;&lt;p&gt;本项目依赖一个本地的 MySQL 数据库服务，你需要本地安装，推荐直接使用 Docker 安装。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --name=mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=aa12345678 -dit mysql:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;向量数据库我们默认使用的是Chroma内存数据库，所以无需特殊安装，如果有需要连接其他的同学，可以按照我们的教程进行安装配置。整个DB-GPT的安装过程，我们使用的是miniconda3的虚拟环境。创建虚拟环境，并安装python依赖包&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python&amp;gt;=3.10&#xA;conda create -n dbgpt_env python=3.10&#xA;conda activate dbgpt_env&#xA;pip install -r requirements.txt&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;或者也可以使用命令:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd DB-GPT&#xA;conda env create -f environment.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;另外需要设置一下python包路径, 避免出现运行时找不到包&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;echo &#34;/root/workspace/DB-GPT&#34; &amp;gt; /root/miniconda3/env/dbgpt_env/lib/python3.10/site-packages/dbgpt.pth &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. 运行大模型&lt;/h3&gt; &#xA;&lt;p&gt;关于基础模型, 可以根据&lt;a href=&#34;https://github.com/lm-sys/FastChat/raw/main/README.md#model-weights&#34;&gt;vicuna&lt;/a&gt;合成教程进行合成。 如果此步有困难的同学，也可以直接使用&lt;a href=&#34;https://huggingface.co/&#34;&gt;Hugging Face&lt;/a&gt;上的模型进行替代. &lt;a href=&#34;https://huggingface.co/Tribbiani/vicuna-7b&#34;&gt;替代模型&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;运行模型服务&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd pilot/server&#xA;python llmserver.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;运行 gradio webui&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ python webserver.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;使用说明&lt;/h2&gt; &#xA;&lt;p&gt;我们提供了gradio的用户界面，可以通过我们的用户界面使用DB-GPT， 同时关于我们项目相关的一些代码跟原理介绍，我们也准备了以下几篇参考文章。&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/628750042&#34;&gt;大模型实战系列(1) —— 强强联合Langchain-Vicuna应用实战&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/629467580&#34;&gt;大模型实战系列(2) —— DB-GPT 阿里云部署指南&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/629623125&#34;&gt;大模型实战系列(3) —— DB-GPT插件模型原理与使用&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;感谢&lt;/h2&gt; &#xA;&lt;p&gt;项目取得的成果，需要感谢技术社区，尤其以下项目。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lm-sys/FastChat&#34;&gt;FastChat&lt;/a&gt; 提供 chat 服务&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/Tribbiani/vicuna-13b&#34;&gt;vicuna-13b&lt;/a&gt; 作为基础模型&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;langchain&lt;/a&gt; 工具链&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Significant-Gravitas/Auto-GPT&#34;&gt;AutoGPT&lt;/a&gt; 通用的插件模版&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/&#34;&gt;Hugging Face&lt;/a&gt; 大模型管理&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/chroma-core/chroma&#34;&gt;Chroma&lt;/a&gt; 向量存储&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://milvus.io/&#34;&gt;Milvus&lt;/a&gt; 分布式向量存储&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34;&gt;ChatGLM&lt;/a&gt; 基础模型&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jerryjliu/llama_index&#34;&gt;llama-index&lt;/a&gt; 基于现有知识库进行&lt;a href=&#34;https://arxiv.org/abs/2301.00234&#34;&gt;In-Context Learning&lt;/a&gt;来对其进行数据库相关知识的增强。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- GITCONTRIBUTOR_START --&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/csunny&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/17919400?v=4&#34; width=&#34;100px;&#34;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;csunny&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/xudafeng&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/1011681?v=4&#34; width=&#34;100px;&#34;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;xudafeng&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/yhjun1026&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/7636723?s=96&amp;amp;v=4&#34; width=&#34;100px;&#34;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;明天&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/Aries-ckt&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/13723926?v=4&#34; width=&#34;100px;&#34;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Aries-ckt&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/thebigbone&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/95130644?v=4&#34; width=&#34;100px;&#34;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;thebigbone&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;This project follows the git-contributor &lt;a href=&#34;https://github.com/xudafeng/git-contributor&#34;&gt;spec&lt;/a&gt;, auto updated at &lt;code&gt;Sun May 14 2023 23:02:43 GMT+0800&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;!-- GITCONTRIBUTOR_END --&gt; &#xA;&lt;p&gt;这是一个用于数据库的复杂且创新的工具, 我们的项目也在紧急的开发当中, 会陆续发布一些新的feature。如在使用当中有任何具体问题, 优先在项目下提issue, 如有需要, 请联系如下微信，我会尽力提供帮助，同时也非常欢迎大家参与到项目建设中。&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/csunny/DB-GPT/main/assets/wechat.jpg&#34; width=&#34;320px&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Licence&lt;/h2&gt; &#xA;&lt;p&gt;The MIT License (MIT)&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Bing-su/adetailer</title>
    <updated>2023-05-16T01:28:55Z</updated>
    <id>tag:github.com,2023-05-16:/Bing-su/adetailer</id>
    <link href="https://github.com/Bing-su/adetailer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Auto detecting, masking and inpainting with detection model.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;!After Detailer&lt;/h1&gt; &#xA;&lt;p&gt;!After Detailer is a extension for stable diffusion webui, similar to Detection Detailer, except it uses ultralytics instead of the mmdet.&lt;/p&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;(from Mikubill/sd-webui-controlnet)&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open &#34;Extensions&#34; tab.&lt;/li&gt; &#xA; &lt;li&gt;Open &#34;Install from URL&#34; tab in the tab.&lt;/li&gt; &#xA; &lt;li&gt;Enter &lt;code&gt;https://github.com/Bing-su/adetailer.git&lt;/code&gt; to &#34;URL for extension&#39;s git repository&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Press &#34;Install&#34; button.&lt;/li&gt; &#xA; &lt;li&gt;Wait 5 seconds, and you will see the message &#34;Installed into stable-diffusion-webui\extensions\adetailer. Use Installed tab to restart&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Go to &#34;Installed&#34; tab, click &#34;Check for updates&#34;, and then click &#34;Apply and restart UI&#34;. (The next time you can also use this method to update extensions.)&lt;/li&gt; &#xA; &lt;li&gt;Completely restart A1111 webui including your terminal. (If you do not know what is a &#34;terminal&#34;, you can reboot your computer: turn your computer off and turn it on again.)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You &lt;strong&gt;DON&#39;T&lt;/strong&gt; need to download any model from huggingface.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;It&#39;s auto detecting, masking, and inpainting tool.&lt;/p&gt; &#xA;&lt;p&gt;So some options correspond to options on the inpaint tab.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/Bm7YLEA.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Other options:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Option&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ADetailer model&lt;/td&gt; &#xA;   &lt;td&gt;Determine what to detect.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;None&lt;/code&gt;&amp;nbsp;= disable&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ADetailer prompt,&amp;nbsp;negative prompt&lt;/td&gt; &#xA;   &lt;td&gt;Prompts and negative prompts to apply&lt;/td&gt; &#xA;   &lt;td&gt;If left blank, it will use the same as the input.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Detection model confidence threshold %&lt;/td&gt; &#xA;   &lt;td&gt;Only objects with a detection model confidence above this threshold are used for inpainting.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mask erosion (-) / dilation (+)&lt;/td&gt; &#xA;   &lt;td&gt;Enlarge or reduce the detected mask.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.opencv.org/4.7.0/db/df6/tutorial_erosion_dilatation.html&#34;&gt;opencv example&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mask x, y offset&lt;/td&gt; &#xA;   &lt;td&gt;Moves the mask horizontally and vertically by pixels.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;ControlNet Inpainting&lt;/h2&gt; &#xA;&lt;p&gt;You can use the ControlNet inpaint extension if you have ControlNet installed and a ControlNet inpaint model.&lt;/p&gt; &#xA;&lt;p&gt;On the ControlNet tab, select a ControlNet inpaint model and set the model weights.&lt;/p&gt; &#xA;&lt;h2&gt;Model&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Target&lt;/th&gt; &#xA;   &lt;th&gt;mAP 50&lt;/th&gt; &#xA;   &lt;th&gt;mAP 50-95&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;face_yolov8n.pt&lt;/td&gt; &#xA;   &lt;td&gt;2D / realistic face&lt;/td&gt; &#xA;   &lt;td&gt;0.660&lt;/td&gt; &#xA;   &lt;td&gt;0.366&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;face_yolov8s.pt&lt;/td&gt; &#xA;   &lt;td&gt;2D / realistic face&lt;/td&gt; &#xA;   &lt;td&gt;0.713&lt;/td&gt; &#xA;   &lt;td&gt;0.404&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mediapipe_face_full&lt;/td&gt; &#xA;   &lt;td&gt;realistic face&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mediapipe_face_short&lt;/td&gt; &#xA;   &lt;td&gt;realistic face&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;hand_yolov8n.pt&lt;/td&gt; &#xA;   &lt;td&gt;2D / realistic hand&lt;/td&gt; &#xA;   &lt;td&gt;0.767&lt;/td&gt; &#xA;   &lt;td&gt;0.505&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;person_yolov8n-seg.pt&lt;/td&gt; &#xA;   &lt;td&gt;2D / realistic person&lt;/td&gt; &#xA;   &lt;td&gt;0.782 (bbox)&lt;br&gt;0.761 (mask)&lt;/td&gt; &#xA;   &lt;td&gt;0.555 (bbox)&lt;br&gt;0.460 (mask)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;person_yolov8s-seg.pt&lt;/td&gt; &#xA;   &lt;td&gt;2D / realistic person&lt;/td&gt; &#xA;   &lt;td&gt;0.824 (bbox)&lt;br&gt;0.809 (mask)&lt;/td&gt; &#xA;   &lt;td&gt;0.605 (bbox)&lt;br&gt;0.508 (mask)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;The yolo models can be found on huggingface &lt;a href=&#34;https://huggingface.co/Bingsu/adetailer&#34;&gt;Bingsu/adetailer&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;User Model&lt;/h3&gt; &#xA;&lt;p&gt;Put your &lt;a href=&#34;https://github.com/ultralytics/ultralytics&#34;&gt;ultralytics&lt;/a&gt; model in &lt;code&gt;webui/models/adetailer&lt;/code&gt;. The model name should end with &lt;code&gt;.pt&lt;/code&gt; or &lt;code&gt;.pth&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;It must be a bbox detection or segment model and use all label.&lt;/p&gt; &#xA;&lt;h3&gt;Dataset&lt;/h3&gt; &#xA;&lt;p&gt;Datasets used for training the yolo models are:&lt;/p&gt; &#xA;&lt;h4&gt;Face&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://universe.roboflow.com/my-workspace-mph8o/anime-face-createml&#34;&gt;Anime Face CreateML&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://universe.roboflow.com/0oooooo0/xml2txt-njqx1&#34;&gt;xml2txt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://universe.roboflow.com/sed-b8vkf/an-lfg5i&#34;&gt;AN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://shuoyang1213.me/WIDERFACE/index.html&#34;&gt;wider face&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Hand&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://universe.roboflow.com/1-yshhi/anhdet&#34;&gt;AnHDet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://universe.roboflow.com/catwithawand/hand-detection-fuao9&#34;&gt;hand-detection-fuao9&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Person&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cocodataset.org/#home&#34;&gt;coco2017&lt;/a&gt; (only person)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jerryli27/AniSeg&#34;&gt;AniSeg&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/skytnt/anime-segmentation&#34;&gt;skytnt/anime-segmentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/38RSxSO.png&#34; alt=&#34;image&#34;&gt; &lt;img src=&#34;https://i.imgur.com/2CYgjLx.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ko-fi.com/F1F1L7V2N&#34;&gt;&lt;img src=&#34;https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true&#34; alt=&#34;ko-fi&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>