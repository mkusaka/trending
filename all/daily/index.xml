<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-10-25T01:23:20Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ZachGoldberg/Startup-CTO-Handbook</title>
    <updated>2023-10-25T01:23:20Z</updated>
    <id>tag:github.com,2023-10-25:/ZachGoldberg/Startup-CTO-Handbook</id>
    <link href="https://github.com/ZachGoldberg/Startup-CTO-Handbook" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Startup CTO&#39;s Handbook, a book covering leadership, management and technical topics for leaders of software engineering teams&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;200&#34; src=&#34;https://raw.githubusercontent.com/ZachGoldberg/Startup-CTO-Handbook/main/published_files/cover.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;NOTE:&lt;/em&gt; As of October 2023 I&#39;m still working on porting the book content into markdown. Everything is in there (via a .doc to .md auto-converter) but the formatting is all over the place and needs a lot of cleanup still, apologies for my mess in the interim!&lt;/p&gt; &#xA;&lt;h1&gt;The Book&lt;/h1&gt; &#xA;&lt;p&gt;You can view the latest content of the book in markdown &lt;a href=&#34;https://raw.githubusercontent.com/ZachGoldberg/Startup-CTO-Handbook/main/StartupCTOHandbook.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can buy the book on &lt;a href=&#34;https://www.amazon.com/dp/1955811563&#34;&gt;amazon&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;(Coming Soon) Link of the latest version of the markdown rendered to PDF&lt;/p&gt; &#xA;&lt;p&gt;The original manuscript (now outdated) can be found as a &lt;a href=&#34;https://docs.google.com/document/d/147KVarJdNQ2ZdmDHOSsd7W39anejRu2NfxEWCzwl0IU/edit&#34;&gt;google doc&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Welcome&lt;/h1&gt; &#xA;&lt;p&gt;Hi, thanks for checking out the Startup CTO&#39;s Handbook! This repository has the latest version of the content of the book. You&#39;re welcome and encouraged to contribute issues or pull requests for additions / changes / suggestions / criticisms to be included in future editions. Please feel free to add your name to ACKNOWLEDGEMENTS if you do so.&lt;/p&gt; &#xA;&lt;h1&gt;The Author&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/zachgoldberg/&#34;&gt;Linkedin&lt;/a&gt; / &lt;a href=&#34;https://zachgoldberg.com&#34;&gt;Website&lt;/a&gt; / &lt;a href=&#34;mailto:zach@zachgoldberg.com&#34;&gt;Email&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Licensing&lt;/h1&gt; &#xA;&lt;p&gt;See the LICENSE file, but tl;dr - you&#39;re welcome to make copies, changes, redistribute etc. so long as you&#39;re not reselling, you keep my name/attribution attached, and you keep future versions open under a similar/the same license.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>eureka-research/Eureka</title>
    <updated>2023-10-25T01:23:20Z</updated>
    <id>tag:github.com,2023-10-25:/eureka-research/Eureka</id>
    <link href="https://github.com/eureka-research/Eureka" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official Repository for &#34;Eureka: Human-Level Reward Design via Coding Large Language Models&#34;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Eureka: Human-Level Reward Design via Coding Large Language Models&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://eureka-research.github.io&#34;&gt;[Website]&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2310.12931&#34;&gt;[arXiv]&lt;/a&gt; &lt;a href=&#34;https://eureka-research.github.io/assets/eureka_paper.pdf&#34;&gt;[PDF]&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/eureka-research/Eureka&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-3.8-blue.svg?sanitize=true&#34; alt=&#34;Python Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pytorch.org/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Framework-PyTorch-red.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/eureka-research/Eureka/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/eureka-research/Eureka&#34; alt=&#34;GitHub license&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;hr&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/eureka-research/Eureka/assets/21993118/1abb960d-321a-4de9-b311-113b5fc53d4a&#34;&gt;https://github.com/eureka-research/Eureka/assets/21993118/1abb960d-321a-4de9-b311-113b5fc53d4a&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/eureka-research/Eureka/main/images/eureka.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Large Language Models (LLMs) have excelled as high-level semantic planners for sequential decision-making tasks. However, harnessing them to learn complex low-level manipulation tasks, such as dexterous pen spinning, remains an open problem. We bridge this fundamental gap and present Eureka, a &lt;strong&gt;human-level&lt;/strong&gt; reward design algorithm powered by LLMs. Eureka exploits the remarkable zero-shot generation, code-writing, and in-context improvement capabilities of state-of-the-art LLMs, such as GPT-4, to perform in-context evolutionary optimization over reward code. The resulting rewards can then be used to acquire complex skills via reinforcement learning. Eureka generates reward functions that outperform expert human-engineered rewards without any task-specific prompting or pre-defined reward templates. In a diverse suite of 29 open-source RL environments that include 10 distinct robot morphologies, Eureka outperforms human expert on &lt;strong&gt;83%&lt;/strong&gt; of the tasks leading to an average normalized improvement of &lt;strong&gt;52%&lt;/strong&gt;. The generality of Eureka also enables a new gradient-free approach to reinforcement learning from human feedback (RLHF), readily incorporating human oversight to improve the quality and the safety of the generated rewards in context. Finally, using Eureka rewards in a curriculum learning setting, we demonstrate for the first time a simulated five-finger Shadow Hand capable of performing pen spinning tricks, adeptly manipulating a pen in circles at human speed.&lt;/p&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;p&gt;Eureka requires Python ‚â• 3.8. We have tested on Ubuntu 20.04 and 22.04.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Create a new conda environment with:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;conda create -n eureka python=3.8&#xA;conda activate eureka&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install IsaacGym (tested with &lt;code&gt;Preview Release 4/4&lt;/code&gt;). Follow the &lt;a href=&#34;https://developer.nvidia.com/isaac-gym&#34;&gt;instruction&lt;/a&gt; to download the package.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;tar -xvf IsaacGym_Preview_4_Package.tar.gz&#xA;cd isaacgym/python&#xA;pip install -e .&#xA;(test installation) python examples/joint_monkey.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Install Eureka&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/eureka-research/Eureka.git&#xA;cd Eureka; pip install -e .&#xA;cd isaacgymenvs; pip install -e .&#xA;cd ../rl_games; pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Eureka currently uses OpenAI API for language model queries. You need to have an OpenAI API key to use Eureka &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;here&lt;/a&gt;/. Then, set the environment variable in your terminal&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;export OPENAI_API_KEY= &#34;YOUR_API_KEY&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;p&gt;Navigate to the &lt;code&gt;eureka&lt;/code&gt; directory and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python eureka.py env={environment} iteration={num_iterations} sample={num_samples}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;{environment}&lt;/code&gt; is the task to perform. Options are listed in &lt;code&gt;eureka/cfg/env&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;{num_samples}&lt;/code&gt; is the number of reward samples to generate per iteration. Default value is &lt;code&gt;16&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;{num_iterations}&lt;/code&gt; is the number of Eureka iterations to run. Default value is &lt;code&gt;5&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Below are some example commands to try out Eureka:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python eureka.py env=shadow_hand sample=4 iteration=2 model=gpt-4-0314&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;python eureka.py env=humanoid sample=16 iteration=5 model=gpt-3.5-turbo-16k-0613&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Each run will create a timestamp folder in &lt;code&gt;eureka/outputs&lt;/code&gt; that saves the Eureka log as well as all intermediate reward functions and associated policies.&lt;/p&gt; &#xA;&lt;p&gt;Other command line parameters can be found in &lt;code&gt;eureka/cfg/config.yaml&lt;/code&gt;. The list of supported environments can be found in &lt;code&gt;eureka/cfg/env&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Eureka Pen Spinning Demo&lt;/h1&gt; &#xA;&lt;p&gt;We have released Eureka pen spinning policy in &lt;code&gt;isaacgymenvs/isaacgymenvs/checkpoints&lt;/code&gt;. Try visualizing it with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd isaacgymenvs/isaacgymenvs&#xA;python train.py test=True headless=False force_render=True task=ShadowHandSpin checkpoint=checkpoints/EurekaPenSpinning.pth&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that this script use the default Isaac Gym renderer and not the Omniverse rendering in the paper videos.&lt;/p&gt; &#xA;&lt;h1&gt;Running Eureka on a New Environment&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create a new IsaacGym environment; instructions can be found in &lt;a href=&#34;https://raw.githubusercontent.com/eureka-research/Eureka/main/isaacgymenvs/docs/framework.md&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Verify that standard RL works for your new environment.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd isaacgymenvs/isaacgymenvs&#xA;python train.py task=YOUR_NEW_TASK&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Create a new yaml file &lt;code&gt;your_new_task.yaml&lt;/code&gt; in &lt;code&gt;eureka/cfg/env&lt;/code&gt;:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;env_name: your_new_task&#xA;task: YOUR_NEW_TASK &#xA;description: ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Construct the raw environment code that will serve as context for Eureka as well as the skeleton environment code on which the Eureka reward will be appended to:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd eureka/utils&#xA;python prune_env.py your_new_task&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;Try out Eureka!&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;python eureka.py env=your_new_task&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Acknowledgement&lt;/h1&gt; &#xA;&lt;p&gt;We thank the following open-sourced projects:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Our environments are from &lt;a href=&#34;https://github.com/NVIDIA-Omniverse/IsaacGymEnvs&#34;&gt;IsaacGym&lt;/a&gt; and &lt;a href=&#34;https://github.com/PKU-MARL/DexterousHands/&#34;&gt;DexterousHands&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Our RL training code is based on &lt;a href=&#34;https://github.com/Denys88/rl_games&#34;&gt;rl_games&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;This codebase is released under &lt;a href=&#34;https://raw.githubusercontent.com/eureka-research/Eureka/main/LICENSE&#34;&gt;MIT License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Citation&lt;/h1&gt; &#xA;&lt;p&gt;If you find our work useful, please consider citing us!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{ma2023eureka,&#xA;  title   = {Eureka: Human-Level Reward Design via Coding Large Language Models},&#xA;  author  = {Yecheng Jason Ma and William Liang and Guanzhi Wang and De-An Huang and Osbert Bastani and Dinesh Jayaraman and Yuke Zhu and Linxi Fan and Anima Anandkumar},&#xA;  year    = {2023},&#xA;  journal = {arXiv preprint arXiv: Arxiv-2310.12931}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Disclaimer: This project is strictly for research purposes, and not an official product from NVIDIA.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Significant-Gravitas/AutoGPT</title>
    <updated>2023-10-25T01:23:20Z</updated>
    <id>tag:github.com,2023-10-25:/Significant-Gravitas/AutoGPT</id>
    <link href="https://github.com/Significant-Gravitas/AutoGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An experimental open-source attempt to make GPT-4 fully autonomous.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üåü AutoGPT: the heart of the open-source agent ecosystem&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/autogpt&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/autogpt?style=flat&#34; alt=&#34;Discord Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Significant-Gravitas/AutoGPT/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/Significant-Gravitas/AutoGPT?style=social&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/Auto_GPT&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/auto_gpt?style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&#34; alt=&#34;License: MIT&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AutoGPT&lt;/strong&gt; is your go-to toolkit for supercharging agents. With its modular and extensible framework, you&#39;re empowered to focus on:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üèóÔ∏è &lt;strong&gt;Building&lt;/strong&gt; - Lay the foundation for something amazing.&lt;/li&gt; &#xA; &lt;li&gt;üß™ &lt;strong&gt;Testing&lt;/strong&gt; - Fine-tune your agent to perfection.&lt;/li&gt; &#xA; &lt;li&gt;üëÄ &lt;strong&gt;Viewing&lt;/strong&gt; - See your progress come to life.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Be part of the revolution! &lt;strong&gt;AutoGPT&lt;/strong&gt; stays at the forefront of AI innovation, featuring the codebase for the reigning champion in the Open-Source ecosystem.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://lablab.ai/event/autogpt-arena-hacks&#34;&gt; &lt;img src=&#34;https://lablab.ai/_next/image?url=https%3A%2F%2Fstorage.googleapis.com%2Flablab-static-eu%2Fimages%2Fevents%2Fcll6p5cxj0000356zslac05gg%2Fcll6p5cxj0000356zslac05gg_imageLink_562z1jzj.jpg&amp;amp;w=1080&amp;amp;q=75&#34; alt=&#34;AutoGPT Arena Hacks Hackathon&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;strong&gt;We&#39;re hosting a Hackathon!&lt;/strong&gt; &lt;br&gt; Click the banner above for details and registration! &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ü•á Current Best Agent: AutoGPT&lt;/h2&gt; &#xA;&lt;p&gt;Among our currently benchmarked agents, AutoGPT scores the best. This will change after the hackathon - the top-performing generalist agent will earn the esteemed position as the primary AutoGPT üéä&lt;/p&gt; &#xA;&lt;p&gt;üìà To enter, submit your benchmark run through the UI.&lt;/p&gt; &#xA;&lt;h2&gt;üåü Quickstart&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;To build your own agent&lt;/strong&gt; and to be eligible for the hackathon, follow the quickstart guide &lt;a href=&#34;https://github.com/Significant-Gravitas/AutoGPT/raw/master/autogpts/forge/tutorials/001_getting_started.md&#34;&gt;here&lt;/a&gt;. This will guide you through the process of creating your own agent and using the benchmark and user interface.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;To activate the best agent&lt;/strong&gt; follow the guide &lt;a href=&#34;https://github.com/Significant-Gravitas/AutoGPT/raw/master/autogpts/autogpt/README.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Want to build your own groundbreaking agent using AutoGPT? üõ†Ô∏è There are three major components to focus on:&lt;/p&gt; &#xA;&lt;h3&gt;üèóÔ∏è the Forge&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Forge your future!&lt;/strong&gt; The &lt;code&gt;forge&lt;/code&gt; is your innovation lab. All the boilerplate code is already handled, letting you channel all your creativity into building a revolutionary agent. It&#39;s more than a starting point, it&#39;s a launchpad for your ideas. All tutorials are located &lt;a href=&#34;https://medium.com/@aiedge/autogpt-forge-e3de53cc58ec&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;üìò &lt;a href=&#34;https://github.com/Significant-Gravitas/AutoGPT/tree/master/autogpts/forge&#34;&gt;Learn More&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;üéØ the Benchmark&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Test to impress!&lt;/strong&gt; The &lt;code&gt;benchmark&lt;/code&gt; offers a stringent testing environment. Our framework allows for autonomous, objective performance evaluations, ensuring your agents are primed for real-world action.&lt;/p&gt; &#xA;&lt;p&gt;üìò &lt;a href=&#34;https://github.com/Significant-Gravitas/AutoGPT/raw/master/benchmark&#34;&gt;Learn More&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;üéÆ the UI&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Take Control!&lt;/strong&gt; The &lt;code&gt;frontend&lt;/code&gt; is your personal command center. It gives you a user-friendly interface to control and monitor your agents, making it easier to bring your ideas to life.&lt;/p&gt; &#xA;&lt;p&gt;üìò &lt;a href=&#34;https://github.com/Significant-Gravitas/AutoGPT/tree/master/frontend&#34;&gt;Learn More&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;üîÑ Agent Protocol&lt;/h3&gt; &#xA;&lt;p&gt;üîå &lt;strong&gt;Standardize to Maximize!&lt;/strong&gt; To maintain a uniform standard and ensure seamless compatibility, AutoGPT employs the &lt;a href=&#34;https://agentprotocol.ai/&#34;&gt;agent protocol&lt;/a&gt; from the AI Engineer Foundation. This standardizes the communication pathways from your agent to the frontend and benchmark.&lt;/p&gt; &#xA;&lt;h3&gt;ü§î Questions? Problems? Suggestions?&lt;/h3&gt; &#xA;&lt;h4&gt;Get help - &lt;a href=&#34;https://discord.gg/autogpt&#34;&gt;Discord üí¨&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/autogpt&#34;&gt;&lt;img src=&#34;https://invidget.switchblade.xyz/autogpt&#34; alt=&#34;Join us on Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;To report a bug or request a feature, create a &lt;a href=&#34;https://github.com/Significant-Gravitas/AutoGPT/issues/new/choose&#34;&gt;GitHub Issue&lt;/a&gt;. Please ensure someone else hasn‚Äôt created an issue for the same topic.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://star-history.com/#Significant-Gravitas/AutoGPT&amp;amp;Date&#34;&gt; &lt;img src=&#34;https://api.star-history.com/svg?repos=Significant-Gravitas/AutoGPT&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt; &lt;/a&gt; &lt;/p&gt;</summary>
  </entry>
</feed>