<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-06-17T01:28:39Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>pymc-devs/pymc</title>
    <updated>2024-06-17T01:28:39Z</updated>
    <id>tag:github.com,2024-06-17:/pymc-devs/pymc</id>
    <link href="https://github.com/pymc-devs/pymc" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Bayesian Modeling and Probabilistic Programming in Python&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. image:: &lt;a href=&#34;https://cdn.rawgit.com/pymc-devs/pymc/main/docs/logos/svg/PyMC_banner.svg&#34;&gt;https://cdn.rawgit.com/pymc-devs/pymc/main/docs/logos/svg/PyMC_banner.svg&lt;/a&gt; :height: 100px :alt: PyMC logo :align: center&lt;/p&gt; &#xA;&lt;p&gt;|Build Status| |Coverage| |NumFOCUS_badge| |Binder| |Dockerhub| |DOIzenodo|&lt;/p&gt; &#xA;&lt;p&gt;PyMC (formerly PyMC3) is a Python package for Bayesian statistical modeling focusing on advanced Markov chain Monte Carlo (MCMC) and variational inference (VI) algorithms. Its flexibility and extensibility make it applicable to a large suite of problems.&lt;/p&gt; &#xA;&lt;p&gt;Check out the &lt;code&gt;PyMC overview &amp;lt;https://docs.pymc.io/en/latest/learn/core_notebooks/pymc_overview.html&amp;gt;&lt;/code&gt;&lt;strong&gt;, or one of &lt;code&gt;the many examples &amp;lt;https://www.pymc.io/projects/examples/en/latest/gallery.html&amp;gt;&lt;/code&gt;&lt;/strong&gt;! For questions on PyMC, head on over to our &lt;code&gt;PyMC Discourse &amp;lt;https://discourse.pymc.io/&amp;gt;&lt;/code&gt;__ forum.&lt;/p&gt; &#xA;&lt;h1&gt;Features&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Intuitive model specification syntax, for example, &lt;code&gt;x ~ N(0,1)&lt;/code&gt; translates to &lt;code&gt;x = Normal(&#39;x&#39;,0,1)&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Powerful sampling algorithms&lt;/strong&gt;, such as the &lt;code&gt;No U-Turn Sampler &amp;lt;http://www.jmlr.org/papers/v15/hoffman14a.html&amp;gt;&lt;/code&gt;__, allow complex models with thousands of parameters with little specialized knowledge of fitting algorithms.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Variational inference&lt;/strong&gt;: &lt;code&gt;ADVI &amp;lt;http://www.jmlr.org/papers/v18/16-107.html&amp;gt;&lt;/code&gt;__ for fast approximate posterior estimation as well as mini-batch ADVI for large data sets.&lt;/li&gt; &#xA; &lt;li&gt;Relies on &lt;code&gt;PyTensor &amp;lt;https://pytensor.readthedocs.io/en/latest/&amp;gt;&lt;/code&gt;__ which provides: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Computation optimization and dynamic C or JAX compilation&lt;/li&gt; &#xA;   &lt;li&gt;NumPy broadcasting and advanced indexing&lt;/li&gt; &#xA;   &lt;li&gt;Linear algebra operators&lt;/li&gt; &#xA;   &lt;li&gt;Simple extensibility&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Transparent support for missing value imputation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Linear Regression Example&lt;/h1&gt; &#xA;&lt;p&gt;Plant growth can be influenced by multiple factors, and understanding these relationships is crucial for optimizing agricultural practices.&lt;/p&gt; &#xA;&lt;p&gt;Imagine we conduct an experiment to predict the growth of a plant based on different environmental variables.&lt;/p&gt; &#xA;&lt;p&gt;.. code-block:: python&lt;/p&gt; &#xA;&lt;p&gt;import pymc as pm&lt;/p&gt; &#xA;&lt;h1&gt;Taking draws from a normal distribution&lt;/h1&gt; &#xA;&lt;p&gt;seed = 42 x_dist = pm.Normal.dist(shape=(100, 3)) x_data = pm.draw(x_dist, random_seed=seed)&lt;/p&gt; &#xA;&lt;h1&gt;Independent Variables:&lt;/h1&gt; &#xA;&lt;h1&gt;Sunlight Hours: Number of hours the plant is exposed to sunlight daily.&lt;/h1&gt; &#xA;&lt;h1&gt;Water Amount: Daily water amount given to the plant (in milliliters).&lt;/h1&gt; &#xA;&lt;h1&gt;Soil Nitrogen Content: Percentage of nitrogen content in the soil.&lt;/h1&gt; &#xA;&lt;h1&gt;Dependent Variable:&lt;/h1&gt; &#xA;&lt;h1&gt;Plant Growth (y): Measured as the increase in plant height (in centimeters) over a certain period.&lt;/h1&gt; &#xA;&lt;h1&gt;Define coordinate values for all dimensions of the data&lt;/h1&gt; &#xA;&lt;p&gt;coords={ &#34;trial&#34;: range(100), &#34;features&#34;: [&#34;sunlight hours&#34;, &#34;water amount&#34;, &#34;soil nitrogen&#34;], }&lt;/p&gt; &#xA;&lt;h1&gt;Define generative model&lt;/h1&gt; &#xA;&lt;p&gt;with pm.Model(coords=coords) as generative_model: x = pm.Data(&#34;x&#34;, x_data, dims=[&#34;trial&#34;, &#34;features&#34;])&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  # Model parameters&#xA;  betas = pm.Normal(&#34;betas&#34;, dims=&#34;features&#34;)&#xA;  sigma = pm.HalfNormal(&#34;sigma&#34;)&#xA;&#xA;  # Linear model&#xA;  mu = x @ betas&#xA;&#xA;  # Likelihood&#xA;  # Assuming we measure deviation of each plant from baseline&#xA;  plant_growth = pm.Normal(&#34;plant growth&#34;, mu, sigma, dims=&#34;trial&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Generating data from model by fixing parameters&lt;/h1&gt; &#xA;&lt;p&gt;fixed_parameters = { &#34;betas&#34;: [5, 20, 2], &#34;sigma&#34;: 0.5, } with pm.do(generative_model, fixed_parameters) as synthetic_model: idata = pm.sample_prior_predictive(random_seed=seed) # Sample from prior predictive distribution. synthetic_y = idata.prior[&#34;plant growth&#34;].sel(draw=0, chain=0)&lt;/p&gt; &#xA;&lt;h1&gt;Infer parameters conditioned on observed data&lt;/h1&gt; &#xA;&lt;p&gt;with pm.observe(generative_model, {&#34;plant growth&#34;: synthetic_y}) as inference_model: idata = pm.sample(random_seed=seed)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  summary = pm.stats.summary(idata, var_names=[&#34;betas&#34;, &#34;sigma&#34;])&#xA;  print(summary)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;From the summary, we can see that the mean of the inferred parameters are very close to the fixed parameters&lt;/p&gt; &#xA;&lt;p&gt;===================== ====== ===== ======== ========= =========== ========= ========== ========== ======= Params mean sd hdi_3% hdi_97% mcse_mean mcse_sd ess_bulk ess_tail r_hat ===================== ====== ===== ======== ========= =========== ========= ========== ========== ======= betas[sunlight hours] 4.972 0.054 4.866 5.066 0.001 0.001 3003 1257 1 betas[water amount] 19.963 0.051 19.872 20.062 0.001 0.001 3112 1658 1 betas[soil nitrogen] 1.994 0.055 1.899 2.107 0.001 0.001 3221 1559 1 sigma 0.511 0.037 0.438 0.575 0.001 0 2945 1522 1 ===================== ====== ===== ======== ========= =========== ========= ========== ========== =======&lt;/p&gt; &#xA;&lt;p&gt;.. code-block:: python&lt;/p&gt; &#xA;&lt;h1&gt;Simulate new data conditioned on inferred parameters&lt;/h1&gt; &#xA;&lt;p&gt;new_x_data = pm.draw( pm.Normal.dist(shape=(3, 3)), random_seed=seed, ) new_coords = coords | {&#34;trial&#34;: [0, 1, 2]}&lt;/p&gt; &#xA;&lt;p&gt;with inference_model: pm.set_data({&#34;x&#34;: new_x_data}, coords=new_coords) pm.sample_posterior_predictive( idata, predictions=True, extend_inferencedata=True, random_seed=seed, )&lt;/p&gt; &#xA;&lt;p&gt;pm.stats.summary(idata.predictions, kind=&#34;stats&#34;)&lt;/p&gt; &#xA;&lt;p&gt;The new data conditioned on inferred parameters would look like:&lt;/p&gt; &#xA;&lt;p&gt;================ ======== ======= ======== ========= Output mean sd hdi_3% hdi_97% ================ ======== ======= ======== ========= plant growth[0] 14.229 0.515 13.325 15.272 plant growth[1] 24.418 0.511 23.428 25.326 plant growth[2] -6.747 0.511 -7.740 -5.797 ================ ======== ======= ======== =========&lt;/p&gt; &#xA;&lt;p&gt;.. code-block:: python&lt;/p&gt; &#xA;&lt;h1&gt;Simulate new data, under a scenario where the first beta is zero&lt;/h1&gt; &#xA;&lt;p&gt;with pm.do( inference_model, {inference_model[&#34;betas&#34;]: inference_model[&#34;betas&#34;] * [0, 1, 1]}, ) as plant_growth_model: new_predictions = pm.sample_posterior_predictive( idata, predictions=True, random_seed=seed, )&lt;/p&gt; &#xA;&lt;p&gt;pm.stats.summary(new_predictions, kind=&#34;stats&#34;)&lt;/p&gt; &#xA;&lt;p&gt;The new data, under the above scenario would look like:&lt;/p&gt; &#xA;&lt;p&gt;================ ======== ======= ======== ========= Output mean sd hdi_3% hdi_97% ================ ======== ======= ======== ========= plant growth[0] 12.149 0.515 11.193 13.135 plant growth[1] 29.809 0.508 28.832 30.717 plant growth[2] -0.131 0.507 -1.121 0.791 ================ ======== ======= ======== =========&lt;/p&gt; &#xA;&lt;h1&gt;Getting started&lt;/h1&gt; &#xA;&lt;h2&gt;If you already know about Bayesian statistics:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;API quickstart guide &amp;lt;https://www.pymc.io/projects/examples/en/latest/introductory/api_quickstart.html&amp;gt;&lt;/code&gt;__&lt;/li&gt; &#xA; &lt;li&gt;The &lt;code&gt;PyMC tutorial &amp;lt;https://docs.pymc.io/en/latest/learn/core_notebooks/pymc_overview.html&amp;gt;&lt;/code&gt;__&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;PyMC examples &amp;lt;https://www.pymc.io/projects/examples/en/latest/gallery.html&amp;gt;&lt;/code&gt;__ and the &lt;code&gt;API reference &amp;lt;https://docs.pymc.io/en/stable/api.html&amp;gt;&lt;/code&gt;__&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Learn Bayesian statistics with a book together with PyMC&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Bayesian Analysis with Python &amp;lt;http://bap.com.ar/&amp;gt;&lt;/code&gt;__ (third edition) by Osvaldo Martin: Great introductory book.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Probabilistic Programming and Bayesian Methods for Hackers &amp;lt;https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers&amp;gt;&lt;/code&gt;__: Fantastic book with many applied code examples.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;PyMC port of the book &#34;Doing Bayesian Data Analysis&#34; by John Kruschke &amp;lt;https://github.com/cluhmann/DBDA-python&amp;gt;&lt;/code&gt;__ as well as the &lt;code&gt;first edition &amp;lt;https://github.com/aloctavodia/Doing_bayesian_data_analysis&amp;gt;&lt;/code&gt;__.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;PyMC port of the book &#34;Statistical Rethinking A Bayesian Course with Examples in R and Stan&#34; by Richard McElreath &amp;lt;https://github.com/pymc-devs/resources/tree/master/Rethinking&amp;gt;&lt;/code&gt;__&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;PyMC port of the book &#34;Bayesian Cognitive Modeling&#34; by Michael Lee and EJ Wagenmakers &amp;lt;https://github.com/pymc-devs/resources/tree/master/BCM&amp;gt;&lt;/code&gt;__: Focused on using Bayesian statistics in cognitive modeling.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Audio &amp;amp; Video&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Here is a &lt;code&gt;YouTube playlist &amp;lt;https://www.youtube.com/playlist?list=PL1Ma_1DBbE82OVW8Fz_6Ts1oOeyOAiovy&amp;gt;&lt;/code&gt;__ gathering several talks on PyMC.&lt;/li&gt; &#xA; &lt;li&gt;You can also find all the talks given at &lt;strong&gt;PyMCon 2020&lt;/strong&gt; &lt;code&gt;here &amp;lt;https://discourse.pymc.io/c/pymcon/2020talks/15&amp;gt;&lt;/code&gt;__.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;code&gt;&#34;Learning Bayesian Statistics&#34; podcast &amp;lt;https://www.learnbayesstats.com/&amp;gt;&lt;/code&gt;__ helps you discover and stay up-to-date with the vast Bayesian community. Bonus: it&#39;s hosted by Alex Andorra, one of the PyMC core devs!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;p&gt;To install PyMC on your system, follow the instructions on the &lt;code&gt;installation guide &amp;lt;https://www.pymc.io/projects/docs/en/latest/installation.html&amp;gt;&lt;/code&gt;__.&lt;/p&gt; &#xA;&lt;h1&gt;Citing PyMC&lt;/h1&gt; &#xA;&lt;p&gt;Please choose from the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;|DOIpaper| &lt;em&gt;PyMC: A Modern and Comprehensive Probabilistic Programming Framework in Python&lt;/em&gt;, Abril-Pla O, Andreani V, Carroll C, Dong L, Fonnesbeck CJ, Kochurov M, Kumar R, Lao J, Luhmann CC, Martin OA, Osthege M, Vieira R, Wiecki T, Zinkov R. (2023)&lt;/li&gt; &#xA; &lt;li&gt;|DOIzenodo| A DOI for all versions.&lt;/li&gt; &#xA; &lt;li&gt;DOIs for specific versions are shown on Zenodo and under &lt;code&gt;Releases &amp;lt;https://github.com/pymc-devs/pymc/releases&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;.. |DOIpaper| image:: &lt;a href=&#34;https://img.shields.io/badge/DOI-10.7717%2Fpeerj--cs.1516-blue.svg&#34;&gt;https://img.shields.io/badge/DOI-10.7717%2Fpeerj--cs.1516-blue.svg&lt;/a&gt; :target: &lt;a href=&#34;https://doi.org/10.7717/peerj-cs.1516&#34;&gt;https://doi.org/10.7717/peerj-cs.1516&lt;/a&gt; .. |DOIzenodo| image:: &lt;a href=&#34;https://zenodo.org/badge/DOI/10.5281/zenodo.4603970.svg&#34;&gt;https://zenodo.org/badge/DOI/10.5281/zenodo.4603970.svg&lt;/a&gt; :target: &lt;a href=&#34;https://doi.org/10.5281/zenodo.4603970&#34;&gt;https://doi.org/10.5281/zenodo.4603970&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Contact&lt;/h1&gt; &#xA;&lt;p&gt;We are using &lt;code&gt;discourse.pymc.io &amp;lt;https://discourse.pymc.io/&amp;gt;&lt;/code&gt;__ as our main communication channel.&lt;/p&gt; &#xA;&lt;p&gt;To ask a question regarding modeling or usage of PyMC we encourage posting to our Discourse forum under the &lt;code&gt;“Questions” Category &amp;lt;https://discourse.pymc.io/c/questions&amp;gt;&lt;/code&gt;&lt;strong&gt;. You can also suggest feature in the &lt;code&gt;“Development” Category &amp;lt;https://discourse.pymc.io/c/development&amp;gt;&lt;/code&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can also follow us on these social media platforms for updates and other announcements:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;LinkedIn @pymc &amp;lt;https://www.linkedin.com/company/pymc/&amp;gt;&lt;/code&gt;__&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;YouTube @PyMCDevelopers &amp;lt;https://www.youtube.com/c/PyMCDevelopers&amp;gt;&lt;/code&gt;__&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Twitter @pymc_devs &amp;lt;https://twitter.com/pymc_devs&amp;gt;&lt;/code&gt;__&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Mastodon @pymc@bayes.club &amp;lt;https://bayes.club/@pymc&amp;gt;&lt;/code&gt;__&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To report an issue with PyMC please use the &lt;code&gt;issue tracker &amp;lt;https://github.com/pymc-devs/pymc/issues&amp;gt;&lt;/code&gt;__.&lt;/p&gt; &#xA;&lt;p&gt;Finally, if you need to get in touch for non-technical information about the project, &lt;code&gt;send us an e-mail &amp;lt;info@pymc-devs.org&amp;gt;&lt;/code&gt;__.&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;Apache License, Version 2.0 &amp;lt;https://github.com/pymc-devs/pymc/blob/main/LICENSE&amp;gt;&lt;/code&gt;__&lt;/p&gt; &#xA;&lt;h1&gt;Software using PyMC&lt;/h1&gt; &#xA;&lt;h2&gt;General purpose&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Bambi &amp;lt;https://github.com/bambinos/bambi&amp;gt;&lt;/code&gt;__: BAyesian Model-Building Interface (BAMBI) in Python.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;calibr8 &amp;lt;https://calibr8.readthedocs.io&amp;gt;&lt;/code&gt;__: A toolbox for constructing detailed observation models to be used as likelihoods in PyMC.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;gumbi &amp;lt;https://github.com/JohnGoertz/Gumbi&amp;gt;&lt;/code&gt;__: A high-level interface for building GP models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;SunODE &amp;lt;https://github.com/aseyboldt/sunode&amp;gt;&lt;/code&gt;__: Fast ODE solver, much faster than the one that comes with PyMC.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;pymc-learn &amp;lt;https://github.com/pymc-learn/pymc-learn&amp;gt;&lt;/code&gt;__: Custom PyMC models built on top of pymc3_models/scikit-learn API&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Domain specific&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Exoplanet &amp;lt;https://github.com/dfm/exoplanet&amp;gt;&lt;/code&gt;__: a toolkit for modeling of transit and/or radial velocity observations of exoplanets and other astronomical time series.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;beat &amp;lt;https://github.com/hvasbath/beat&amp;gt;&lt;/code&gt;__: Bayesian Earthquake Analysis Tool.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;CausalPy &amp;lt;https://github.com/pymc-labs/CausalPy&amp;gt;&lt;/code&gt;__: A package focussing on causal inference in quasi-experimental settings.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please contact us if your software is not listed here.&lt;/p&gt; &#xA;&lt;h1&gt;Papers citing PyMC&lt;/h1&gt; &#xA;&lt;p&gt;See Google Scholar &lt;code&gt;here &amp;lt;https://scholar.google.com/scholar?cites=6357998555684300962&amp;gt;&lt;/code&gt;__ and &lt;code&gt;here &amp;lt;https://scholar.google.com/scholar?cites=6936955228135731011&amp;gt;&lt;/code&gt;__ for a continuously updated list.&lt;/p&gt; &#xA;&lt;h1&gt;Contributors&lt;/h1&gt; &#xA;&lt;p&gt;See the &lt;code&gt;GitHub contributor page &amp;lt;https://github.com/pymc-devs/pymc/graphs/contributors&amp;gt;&lt;/code&gt;&lt;strong&gt;. Also read our &lt;code&gt;Code of Conduct &amp;lt;https://github.com/pymc-devs/pymc/blob/main/CODE_OF_CONDUCT.md&amp;gt;&lt;/code&gt;&lt;/strong&gt; guidelines for a better contributing experience.&lt;/p&gt; &#xA;&lt;h1&gt;Support&lt;/h1&gt; &#xA;&lt;p&gt;PyMC is a non-profit project under NumFOCUS umbrella. If you want to support PyMC financially, you can donate &lt;code&gt;here &amp;lt;https://numfocus.salsalabs.org/donate-to-pymc3/index.html&amp;gt;&lt;/code&gt;__.&lt;/p&gt; &#xA;&lt;h1&gt;Professional Consulting Support&lt;/h1&gt; &#xA;&lt;p&gt;You can get professional consulting support from &lt;code&gt;PyMC Labs &amp;lt;https://www.pymc-labs.io&amp;gt;&lt;/code&gt;__.&lt;/p&gt; &#xA;&lt;h1&gt;Sponsors&lt;/h1&gt; &#xA;&lt;p&gt;|NumFOCUS|&lt;/p&gt; &#xA;&lt;p&gt;|PyMCLabs|&lt;/p&gt; &#xA;&lt;p&gt;|Mistplay|&lt;/p&gt; &#xA;&lt;p&gt;|ODSC|&lt;/p&gt; &#xA;&lt;h1&gt;Thanks to our contributors&lt;/h1&gt; &#xA;&lt;p&gt;|contributors|&lt;/p&gt; &#xA;&lt;p&gt;.. |Binder| image:: &lt;a href=&#34;https://mybinder.org/badge_logo.svg&#34;&gt;https://mybinder.org/badge_logo.svg&lt;/a&gt; :target: &lt;a href=&#34;https://mybinder.org/v2/gh/pymc-devs/pymc/main?filepath=%2Fdocs%2Fsource%2Fnotebooks&#34;&gt;https://mybinder.org/v2/gh/pymc-devs/pymc/main?filepath=%2Fdocs%2Fsource%2Fnotebooks&lt;/a&gt; .. |Build Status| image:: &lt;a href=&#34;https://github.com/pymc-devs/pymc/workflows/pytest/badge.svg&#34;&gt;https://github.com/pymc-devs/pymc/workflows/pytest/badge.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/pymc-devs/pymc/actions&#34;&gt;https://github.com/pymc-devs/pymc/actions&lt;/a&gt; .. |Coverage| image:: &lt;a href=&#34;https://codecov.io/gh/pymc-devs/pymc/branch/main/graph/badge.svg&#34;&gt;https://codecov.io/gh/pymc-devs/pymc/branch/main/graph/badge.svg&lt;/a&gt; :target: &lt;a href=&#34;https://codecov.io/gh/pymc-devs/pymc&#34;&gt;https://codecov.io/gh/pymc-devs/pymc&lt;/a&gt; .. |Dockerhub| image:: &lt;a href=&#34;https://img.shields.io/docker/automated/pymc/pymc.svg&#34;&gt;https://img.shields.io/docker/automated/pymc/pymc.svg&lt;/a&gt; :target: &lt;a href=&#34;https://hub.docker.com/r/pymc/pymc&#34;&gt;https://hub.docker.com/r/pymc/pymc&lt;/a&gt; .. |NumFOCUS_badge| image:: &lt;a href=&#34;https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&amp;amp;colorA=E1523D&amp;amp;colorB=007D8A&#34;&gt;https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&amp;amp;colorA=E1523D&amp;amp;colorB=007D8A&lt;/a&gt; :target: &lt;a href=&#34;http://www.numfocus.org/&#34;&gt;http://www.numfocus.org/&lt;/a&gt; .. |NumFOCUS| image:: &lt;a href=&#34;https://github.com/pymc-devs/brand/raw/main/sponsors/sponsor_logos/sponsor_numfocus.png?raw=true&#34;&gt;https://github.com/pymc-devs/brand/blob/main/sponsors/sponsor_logos/sponsor_numfocus.png?raw=true&lt;/a&gt; :target: &lt;a href=&#34;http://www.numfocus.org/&#34;&gt;http://www.numfocus.org/&lt;/a&gt; .. |PyMCLabs| image:: &lt;a href=&#34;https://github.com/pymc-devs/brand/raw/main/sponsors/sponsor_logos/sponsor_pymc_labs.png?raw=true&#34;&gt;https://github.com/pymc-devs/brand/blob/main/sponsors/sponsor_logos/sponsor_pymc_labs.png?raw=true&lt;/a&gt; :target: &lt;a href=&#34;https://pymc-labs.io&#34;&gt;https://pymc-labs.io&lt;/a&gt; .. |Mistplay| image:: &lt;a href=&#34;https://github.com/pymc-devs/brand/raw/main/sponsors/sponsor_logos/sponsor_mistplay.png?raw=true&#34;&gt;https://github.com/pymc-devs/brand/blob/main/sponsors/sponsor_logos/sponsor_mistplay.png?raw=true&lt;/a&gt; :target: &lt;a href=&#34;https://www.mistplay.com/&#34;&gt;https://www.mistplay.com/&lt;/a&gt; .. |ODSC| image:: &lt;a href=&#34;https://github.com/pymc-devs/brand/raw/main/sponsors/sponsor_logos/odsc/sponsor_odsc.png?raw=true&#34;&gt;https://github.com/pymc-devs/brand/blob/main/sponsors/sponsor_logos/odsc/sponsor_odsc.png?raw=true&lt;/a&gt; :target: &lt;a href=&#34;https://odsc.com/california/?utm_source=pymc&amp;amp;utm_medium=referral&#34;&gt;https://odsc.com/california/?utm_source=pymc&amp;amp;utm_medium=referral&lt;/a&gt; .. |contributors| image:: &lt;a href=&#34;https://contrib.rocks/image?repo=pymc-devs/pymc&#34;&gt;https://contrib.rocks/image?repo=pymc-devs/pymc&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/pymc-devs/pymc/graphs/contributors&#34;&gt;https://github.com/pymc-devs/pymc/graphs/contributors&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>NVIDIA/TensorRT</title>
    <updated>2024-06-17T01:28:39Z</updated>
    <id>tag:github.com,2024-06-17:/NVIDIA/TensorRT</id>
    <link href="https://github.com/NVIDIA/TensorRT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;NVIDIA® TensorRT™ is an SDK for high-performance deep learning inference on NVIDIA GPUs. This repository contains the open source components of TensorRT.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://opensource.org/licenses/Apache-2.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/TensorRT-documentation-brightgreen.svg?sanitize=true&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;TensorRT Open Source Software&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the Open Source Software (OSS) components of NVIDIA TensorRT. It includes the sources for TensorRT plugins and ONNX parser, as well as sample applications demonstrating usage and capabilities of the TensorRT platform. These open source software components are a subset of the TensorRT General Availability (GA) release with some extensions and bug-fixes.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For code contributions to TensorRT-OSS, please see our &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/TensorRT/release/10.0/CONTRIBUTING.md&#34;&gt;Contribution Guide&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/TensorRT/release/10.0/CODING-GUIDELINES.md&#34;&gt;Coding Guidelines&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;For a summary of new additions and updates shipped with TensorRT-OSS releases, please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/TensorRT/release/10.0/CHANGELOG.md&#34;&gt;Changelog&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;For business inquiries, please contact &lt;a href=&#34;mailto:researchinquiries@nvidia.com&#34;&gt;researchinquiries@nvidia.com&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;For press and other inquiries, please contact Hector Marinez at &lt;a href=&#34;mailto:hmarinez@nvidia.com&#34;&gt;hmarinez@nvidia.com&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Need enterprise support? NVIDIA global support is available for TensorRT with the &lt;a href=&#34;https://www.nvidia.com/en-us/data-center/products/ai-enterprise/&#34;&gt;NVIDIA AI Enterprise software suite&lt;/a&gt;. Check out &lt;a href=&#34;https://www.nvidia.com/en-us/launchpad/ai/ai-enterprise/&#34;&gt;NVIDIA LaunchPad&lt;/a&gt; for free access to a set of hands-on labs with TensorRT hosted on NVIDIA infrastructure.&lt;/p&gt; &#xA;&lt;p&gt;Join the &lt;a href=&#34;https://www.nvidia.com/en-us/deep-learning-ai/triton-tensorrt-newsletter/&#34;&gt;TensorRT and Triton community&lt;/a&gt; and stay current on the latest product updates, bug fixes, content, best practices, and more.&lt;/p&gt; &#xA;&lt;h1&gt;Prebuilt TensorRT Python Package&lt;/h1&gt; &#xA;&lt;p&gt;We provide the TensorRT Python package for an easy installation. &lt;br&gt; To install:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install tensorrt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can skip the &lt;strong&gt;Build&lt;/strong&gt; section to enjoy TensorRT with Python.&lt;/p&gt; &#xA;&lt;h1&gt;Build&lt;/h1&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;To build the TensorRT-OSS components, you will first need the following software packages.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TensorRT GA build&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;TensorRT v10.0.1.6 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Available from direct download links listed below&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;System Packages&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-toolkit&#34;&gt;CUDA&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Recommended versions:&lt;/li&gt; &#xA;   &lt;li&gt;cuda-12.2.0 + cuDNN-8.9&lt;/li&gt; &#xA;   &lt;li&gt;cuda-11.8.0 + cuDNN-8.9&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ftp.gnu.org/gnu/make/&#34;&gt;GNU make&lt;/a&gt; &amp;gt;= v4.1&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Kitware/CMake/releases&#34;&gt;cmake&lt;/a&gt; &amp;gt;= v3.13&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;python&lt;/a&gt; &amp;gt;= v3.8, &amp;lt;= v3.10.x&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pypi.org/project/pip/#history&#34;&gt;pip&lt;/a&gt; &amp;gt;= v19.0&lt;/li&gt; &#xA; &lt;li&gt;Essential utilities &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://git-scm.com/downloads&#34;&gt;git&lt;/a&gt;, &lt;a href=&#34;https://www.freedesktop.org/wiki/Software/pkg-config/&#34;&gt;pkg-config&lt;/a&gt;, &lt;a href=&#34;https://www.gnu.org/software/wget/faq.html#download&#34;&gt;wget&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Optional Packages&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Containerized build&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.docker.com/install/&#34;&gt;Docker&lt;/a&gt; &amp;gt;= 19.03&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/NVIDIA/nvidia-docker&#34;&gt;NVIDIA Container Toolkit&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;PyPI packages (for demo applications/tests)&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://pypi.org/project/onnx/&#34;&gt;onnx&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://pypi.org/project/onnxruntime/&#34;&gt;onnxruntime&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://pypi.org/project/tensorflow/&#34;&gt;tensorflow-gpu&lt;/a&gt; &amp;gt;= 2.5.1&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://pypi.org/project/Pillow/&#34;&gt;Pillow&lt;/a&gt; &amp;gt;= 9.0.1&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://pypi.org/project/pycuda/&#34;&gt;pycuda&lt;/a&gt; &amp;lt; 2021.1&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://pypi.org/project/numpy/&#34;&gt;numpy&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://pypi.org/project/pytest/&#34;&gt;pytest&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Code formatting tools (for contributors)&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://clang.llvm.org/docs/ClangFormat.html&#34;&gt;Clang-format&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/llvm-mirror/clang/raw/master/tools/clang-format/git-clang-format&#34;&gt;Git-clang-format&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;NOTE: &lt;a href=&#34;https://github.com/onnx/onnx-tensorrt&#34;&gt;onnx-tensorrt&lt;/a&gt;, &lt;a href=&#34;http://nvlabs.github.io/cub/&#34;&gt;cub&lt;/a&gt;, and &lt;a href=&#34;https://github.com/protocolbuffers/protobuf.git&#34;&gt;protobuf&lt;/a&gt; packages are downloaded along with TensorRT OSS, and not required to be installed.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Downloading TensorRT Build&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;h4&gt;Download TensorRT OSS&lt;/h4&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone -b main https://github.com/nvidia/TensorRT TensorRT&#xA;cd TensorRT&#xA;git submodule update --init --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;h4&gt;(Optional - if not using TensorRT container) Specify the TensorRT GA release build path&lt;/h4&gt; &lt;p&gt;If using the TensorRT OSS build container, TensorRT libraries are preinstalled under &lt;code&gt;/usr/lib/x86_64-linux-gnu&lt;/code&gt; and you may skip this step.&lt;/p&gt; &lt;p&gt;Else download and extract the TensorRT GA build from &lt;a href=&#34;https://developer.nvidia.com&#34;&gt;NVIDIA Developer Zone&lt;/a&gt; with the direct links below:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/10.0.1/tars/TensorRT-10.0.1.6.Linux.x86_64-gnu.cuda-11.8.tar.gz&#34;&gt;TensorRT 10.0.1.6 for CUDA 11.8, Linux x86_64&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/10.0.1/tars/TensorRT-10.0.1.6.Linux.x86_64-gnu.cuda-12.4.tar.gz&#34;&gt;TensorRT 10.0.1.6 for CUDA 12.4, Linux x86_64&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/10.0.1/zip/TensorRT-10.0.1.6.Windows10.win10.cuda-11.8.zip&#34;&gt;TensorRT 10.0.1.6 for CUDA 11.8, Windows x86_64&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/10.0.1/zip/TensorRT-10.0.1.6.Windows10.win10.cuda-12.4.zip&#34;&gt;TensorRT 10.0.1.6 for CUDA 12.4, Windows x86_64&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Example: Ubuntu 20.04 on x86-64 with cuda-12.4&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ~/Downloads&#xA;tar -xvzf TensorRT-10.0.1.6.Linux.x86_64-gnu.cuda-12.4.tar.gz&#xA;export TRT_LIBPATH=`pwd`/TensorRT-10.0.1.6&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Example: Windows on x86-64 with cuda-12.4&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Expand-Archive -Path TensorRT-10.0.1.6.Windows10.win10.cuda-12.4.zip&#xA;$env:TRT_LIBPATH=&#34;$pwd\TensorRT-10.0.1.6\lib&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Setting Up The Build Environment&lt;/h2&gt; &#xA;&lt;p&gt;For Linux platforms, we recommend that you generate a docker container for building TensorRT OSS as described below. For native builds, please install the &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/TensorRT/release/10.0/#prerequisites&#34;&gt;prerequisite&lt;/a&gt; &lt;em&gt;System Packages&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;h4&gt;Generate the TensorRT-OSS build container.&lt;/h4&gt; &lt;p&gt;The TensorRT-OSS build container can be generated using the supplied Dockerfiles and build scripts. The build containers are configured for building TensorRT OSS out-of-the-box.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example: Ubuntu 20.04 on x86-64 with cuda-12.4 (default)&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./docker/build.sh --file docker/ubuntu-20.04.Dockerfile --tag tensorrt-ubuntu20.04-cuda12.4&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Example: Rockylinux8 on x86-64 with cuda-12.4&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./docker/build.sh --file docker/rockylinux8.Dockerfile --tag tensorrt-rockylinux8-cuda12.4&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Example: Ubuntu 22.04 cross-compile for Jetson (aarch64) with cuda-12.4 (JetPack SDK)&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./docker/build.sh --file docker/ubuntu-cross-aarch64.Dockerfile --tag tensorrt-jetpack-cuda12.4&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Example: Ubuntu 22.04 on aarch64 with cuda-12.4&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./docker/build.sh --file docker/ubuntu-22.04-aarch64.Dockerfile --tag tensorrt-aarch64-ubuntu22.04-cuda12.4&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;h4&gt;Launch the TensorRT-OSS build container.&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Example: Ubuntu 20.04 build container&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./docker/launch.sh --tag tensorrt-ubuntu20.04-cuda12.4 --gpus all&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;NOTE: &lt;br&gt; 1. Use the &lt;code&gt;--tag&lt;/code&gt; corresponding to build container generated in Step 1. &lt;br&gt; 2. &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIA/TensorRT/release/10.0/#prerequisites&#34;&gt;NVIDIA Container Toolkit&lt;/a&gt; is required for GPU access (running TensorRT applications) inside the build container. &lt;br&gt; 3. &lt;code&gt;sudo&lt;/code&gt; password for Ubuntu build containers is &#39;nvidia&#39;. &lt;br&gt; 4. Specify port number using &lt;code&gt;--jupyter &amp;lt;port&amp;gt;&lt;/code&gt; for launching Jupyter notebooks.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Building TensorRT-OSS&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Generate Makefiles and build.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example: Linux (x86-64) build with default cuda-12.4&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; cd $TRT_OSSPATH&#xA; mkdir -p build &amp;amp;&amp;amp; cd build&#xA; cmake .. -DTRT_LIB_DIR=$TRT_LIBPATH -DTRT_OUT_DIR=`pwd`/out&#xA; make -j$(nproc)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Example: Linux (aarch64) build with default cuda-12.4&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; cd $TRT_OSSPATH&#xA; mkdir -p build &amp;amp;&amp;amp; cd build&#xA; cmake .. -DTRT_LIB_DIR=$TRT_LIBPATH -DTRT_OUT_DIR=`pwd`/out -DCMAKE_TOOLCHAIN_FILE=$TRT_OSSPATH/cmake/toolchains/cmake_aarch64-native.toolchain&#xA; make -j$(nproc)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Example: Native build on Jetson (aarch64) with cuda-12.4&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; cd $TRT_OSSPATH&#xA; mkdir -p build &amp;amp;&amp;amp; cd build&#xA; cmake .. -DTRT_LIB_DIR=$TRT_LIBPATH -DTRT_OUT_DIR=`pwd`/out -DTRT_PLATFORM_ID=aarch64 -DCUDA_VERSION=12.4&#xA;CC=/usr/bin/gcc make -j$(nproc)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;NOTE: C compiler must be explicitly specified via CC= for native aarch64 builds of protobuf.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;p&gt;&lt;strong&gt;Example: Ubuntu 22.04 Cross-Compile for Jetson (aarch64) with cuda-12.4 (JetPack)&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; cd $TRT_OSSPATH&#xA; mkdir -p build &amp;amp;&amp;amp; cd build&#xA; cmake .. -DCMAKE_TOOLCHAIN_FILE=$TRT_OSSPATH/cmake/toolchains/cmake_aarch64.toolchain -DCUDA_VERSION=12.4 -DCUDNN_LIB=/pdk_files/cudnn/usr/lib/aarch64-linux-gnu/libcudnn.so -DCUBLAS_LIB=/usr/local/cuda-12.4/targets/aarch64-linux/lib/stubs/libcublas.so -DCUBLASLT_LIB=/usr/local/cuda-12.4/targets/aarch64-linux/lib/stubs/libcublasLt.so -DTRT_LIB_DIR=/pdk_files/tensorrt/lib&#xA; make -j$(nproc)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code&gt;**Example: Native builds on Windows (x86) with cuda-12.4**&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt; cd $TRT_OSSPATH&#xA; mkdir -p build&#xA; cd -p build&#xA; cmake .. -DTRT_LIB_DIR=&#34;$env:TRT_LIBPATH&#34; -DCUDNN_ROOT_DIR=&#34;$env:CUDNN_PATH&#34; -DTRT_OUT_DIR=&#34;$pwd\\out&#34;&#xA; msbuild TensorRT.sln /property:Configuration=Release -m:$env:NUMBER_OF_PROCESSORS&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;NOTE: &lt;br&gt; 1. The default CUDA version used by CMake is 12.4.0. To override this, for example to 11.8, append &lt;code&gt;-DCUDA_VERSION=11.8&lt;/code&gt; to the cmake command.&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Required CMake build arguments are:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;TRT_LIB_DIR&lt;/code&gt;: Path to the TensorRT installation directory containing libraries.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;TRT_OUT_DIR&lt;/code&gt;: Output directory where generated build artifacts will be copied.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Optional CMake build arguments:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;CMAKE_BUILD_TYPE&lt;/code&gt;: Specify if binaries generated are for release or debug (contain debug symbols). Values consists of [&lt;code&gt;Release&lt;/code&gt;] | &lt;code&gt;Debug&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;CUDA_VERSION&lt;/code&gt;: The version of CUDA to target, for example [&lt;code&gt;11.7.1&lt;/code&gt;].&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;CUDNN_VERSION&lt;/code&gt;: The version of cuDNN to target, for example [&lt;code&gt;8.6&lt;/code&gt;].&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;PROTOBUF_VERSION&lt;/code&gt;: The version of Protobuf to use, for example [&lt;code&gt;3.0.0&lt;/code&gt;]. Note: Changing this will not configure CMake to use a system version of Protobuf, it will configure CMake to download and try building that version.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;CMAKE_TOOLCHAIN_FILE&lt;/code&gt;: The path to a toolchain file for cross compilation.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;BUILD_PARSERS&lt;/code&gt;: Specify if the parsers should be built, for example [&lt;code&gt;ON&lt;/code&gt;] | &lt;code&gt;OFF&lt;/code&gt;. If turned OFF, CMake will try to find precompiled versions of the parser libraries to use in compiling samples. First in &lt;code&gt;${TRT_LIB_DIR}&lt;/code&gt;, then on the system. If the build type is Debug, then it will prefer debug builds of the libraries before release versions if available.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;BUILD_PLUGINS&lt;/code&gt;: Specify if the plugins should be built, for example [&lt;code&gt;ON&lt;/code&gt;] | &lt;code&gt;OFF&lt;/code&gt;. If turned OFF, CMake will try to find a precompiled version of the plugin library to use in compiling samples. First in &lt;code&gt;${TRT_LIB_DIR}&lt;/code&gt;, then on the system. If the build type is Debug, then it will prefer debug builds of the libraries before release versions if available.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;BUILD_SAMPLES&lt;/code&gt;: Specify if the samples should be built, for example [&lt;code&gt;ON&lt;/code&gt;] | &lt;code&gt;OFF&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;GPU_ARCHS&lt;/code&gt;: GPU (SM) architectures to target. By default we generate CUDA code for all major SMs. Specific SM versions can be specified here as a quoted space-separated list to reduce compilation time and binary size. Table of compute capabilities of NVIDIA GPUs can be found &lt;a href=&#34;https://developer.nvidia.com/cuda-gpus&#34;&gt;here&lt;/a&gt;. Examples: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;NVidia A100: &lt;code&gt;-DGPU_ARCHS=&#34;80&#34;&lt;/code&gt;&lt;/li&gt; &#xA;     &lt;li&gt;Tesla T4, GeForce RTX 2080: &lt;code&gt;-DGPU_ARCHS=&#34;75&#34;&lt;/code&gt;&lt;/li&gt; &#xA;     &lt;li&gt;Titan V, Tesla V100: &lt;code&gt;-DGPU_ARCHS=&#34;70&#34;&lt;/code&gt;&lt;/li&gt; &#xA;     &lt;li&gt;Multiple SMs: &lt;code&gt;-DGPU_ARCHS=&#34;80 75&#34;&lt;/code&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;TRT_PLATFORM_ID&lt;/code&gt;: Bare-metal build (unlike containerized cross-compilation). Currently supported options: &lt;code&gt;x86_64&lt;/code&gt; (default).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;References&lt;/h1&gt; &#xA;&lt;h2&gt;TensorRT Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/tensorrt&#34;&gt;TensorRT Developer Home&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html&#34;&gt;TensorRT QuickStart Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html&#34;&gt;TensorRT Developer Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/tensorrt/sample-support-guide/index.html&#34;&gt;TensorRT Sample Support Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/tensorrt/index.html#tools&#34;&gt;TensorRT ONNX Tools&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://devtalk.nvidia.com/default/board/304/tensorrt/&#34;&gt;TensorRT Discussion Forums&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/tensorrt/release-notes/index.html&#34;&gt;TensorRT Release Notes&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Known Issues&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Please refer to &lt;a href=&#34;https://docs.nvidia.com/deeplearning/tensorrt/release-notes&#34;&gt;TensorRT Release Notes&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>odin-lang/Odin</title>
    <updated>2024-06-17T01:28:39Z</updated>
    <id>tag:github.com,2024-06-17:/odin-lang/Odin</id>
    <link href="https://github.com/odin-lang/Odin" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Odin Programming Language&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/odin-lang/Odin/master/misc/logo-slim.png&#34; alt=&#34;Odin logo&#34; style=&#34;width:65%&#34;&gt; &lt;br&gt; The Data-Oriented Language for Sane Software Development. &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/odin-lang/odin/releases/latest&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/release/odin-lang/odin.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/odin-lang/odin/releases/latest&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/platforms-Windows%20|%20Linux%20|%20macOS-green.svg&#34;&gt; &lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://discord.com/invite/sVBPHEv&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/568138951836172421?logo=discord&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/odin-lang/odin/actions&#34;&gt; &lt;img src=&#34;https://github.com/odin-lang/odin/workflows/CI/badge.svg?branch=master&amp;amp;event=push&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h1&gt;The Odin Programming Language&lt;/h1&gt; &#xA;&lt;p&gt;Odin is a general-purpose programming language with distinct typing, built for high performance, modern systems, and built-in data-oriented data types. The Odin Programming Language, the C alternative for the joy of programming.&lt;/p&gt; &#xA;&lt;p&gt;Website: &lt;a href=&#34;https://odin-lang.org/&#34;&gt;https://odin-lang.org/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-odin&#34;&gt;package main&#xA;&#xA;import &#34;core:fmt&#34;&#xA;&#xA;main :: proc() {&#xA;&#x9;program := &#34;+ + * 😃 - /&#34;&#xA;&#x9;accumulator := 0&#xA;&#xA;&#x9;for token in program {&#xA;&#x9;&#x9;switch token {&#xA;&#x9;&#x9;case &#39;+&#39;: accumulator += 1&#xA;&#x9;&#x9;case &#39;-&#39;: accumulator -= 1&#xA;&#x9;&#x9;case &#39;*&#39;: accumulator *= 2&#xA;&#x9;&#x9;case &#39;/&#39;: accumulator /= 2&#xA;&#x9;&#x9;case &#39;😃&#39;: accumulator *= accumulator&#xA;&#x9;&#x9;case: // Ignore everything else&#xA;&#x9;&#x9;}&#xA;&#x9;}&#xA;&#xA;&#x9;fmt.printf(&#34;The program \&#34;%s\&#34; calculates the value %d\n&#34;,&#xA;&#x9;           program, accumulator)&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://odin-lang.org/docs/install&#34;&gt;Getting Started&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;Instructions for downloading and installing the Odin compiler and libraries.&lt;/p&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://odin-lang.org/docs/nightly/&#34;&gt;Nightly Builds&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;Get the latest nightly builds of Odin.&lt;/p&gt; &#xA;&lt;h3&gt;Learning Odin&lt;/h3&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://odin-lang.org/docs/overview&#34;&gt;Overview of Odin&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;An overview of the Odin programming language.&lt;/p&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://odin-lang.org/docs/faq&#34;&gt;Frequently Asked Questions (FAQ)&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;Answers to common questions about Odin.&lt;/p&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://pkg.odin-lang.org/&#34;&gt;Packages&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;Documentation for all the official packages part of the &lt;a href=&#34;https://pkg.odin-lang.org/core/&#34;&gt;core&lt;/a&gt; and &lt;a href=&#34;https://pkg.odin-lang.org/vendor/&#34;&gt;vendor&lt;/a&gt; library collections.&lt;/p&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://github.com/odin-lang/Odin/wiki&#34;&gt;The Odin Wiki&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;A wiki maintained by the Odin community.&lt;/p&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://discord.gg/sVBPHEv&#34;&gt;Odin Discord&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;Get live support and talk with other Odin programmers on the Odin Discord.&lt;/p&gt; &#xA;&lt;h3&gt;Articles&lt;/h3&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://odin-lang.org/news/&#34;&gt;The Odin Blog&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;The official blog of the Odin programming language, featuring announcements, news, and in-depth articles by the Odin team and guests.&lt;/p&gt; &#xA;&lt;h2&gt;Warnings&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The Odin compiler is still in development.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>