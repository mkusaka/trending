<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-15T01:29:46Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>aler9/rtsp-simple-server</title>
    <updated>2022-12-15T01:29:46Z</updated>
    <id>tag:github.com,2022-12-15:/aler9/rtsp-simple-server</id>
    <link href="https://github.com/aler9/rtsp-simple-server" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ready-to-use RTSP / RTMP / LL-HLS server and proxy that allows to read, publish and proxy video and audio streams&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/logo.png&#34; alt=&#34;rtsp-simple-server&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;rtsp-simple-server&lt;/em&gt; is a ready-to-use and zero-dependency server and proxy that allows users to publish, read and proxy live video and audio streams through various protocols:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;protocol&lt;/th&gt; &#xA;   &lt;th&gt;description&lt;/th&gt; &#xA;   &lt;th&gt;variants&lt;/th&gt; &#xA;   &lt;th&gt;publish&lt;/th&gt; &#xA;   &lt;th&gt;read&lt;/th&gt; &#xA;   &lt;th&gt;proxy&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RTSP&lt;/td&gt; &#xA;   &lt;td&gt;fastest way to publish and read streams&lt;/td&gt; &#xA;   &lt;td&gt;RTSP, RTSPS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RTMP&lt;/td&gt; &#xA;   &lt;td&gt;allows to interact with legacy software&lt;/td&gt; &#xA;   &lt;td&gt;RTMP, RTMPS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HLS&lt;/td&gt; &#xA;   &lt;td&gt;allows to embed streams into a web page&lt;/td&gt; &#xA;   &lt;td&gt;Low-Latency HLS, standard HLS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;❌&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;span&gt;✔&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Publish live streams to the server&lt;/li&gt; &#xA; &lt;li&gt;Read live streams from the server&lt;/li&gt; &#xA; &lt;li&gt;Proxy streams from other servers or cameras, always or on-demand&lt;/li&gt; &#xA; &lt;li&gt;Each stream can have multiple video and audio tracks, encoded with any RTP-compatible codec, including H264, H265, VP8, VP9, MPEG2, MP3, AAC, Opus, PCM, JPEG&lt;/li&gt; &#xA; &lt;li&gt;Streams are automatically converted from a protocol to another. For instance, it&#39;s possible to publish a stream with RTSP and read it with HLS&lt;/li&gt; &#xA; &lt;li&gt;Serve multiple streams at once in separate paths&lt;/li&gt; &#xA; &lt;li&gt;Authenticate users; use internal or external authentication&lt;/li&gt; &#xA; &lt;li&gt;Redirect readers to other RTSP servers (load balancing)&lt;/li&gt; &#xA; &lt;li&gt;Query and control the server through an HTTP API&lt;/li&gt; &#xA; &lt;li&gt;Reload the configuration without disconnecting existing clients (hot reloading)&lt;/li&gt; &#xA; &lt;li&gt;Read Prometheus-compatible metrics&lt;/li&gt; &#xA; &lt;li&gt;Run external commands when clients connect, disconnect, read or publish streams&lt;/li&gt; &#xA; &lt;li&gt;Natively compatible with the Raspberry Pi Camera&lt;/li&gt; &#xA; &lt;li&gt;Compatible with Linux, Windows and macOS, does not require any dependency or interpreter, it&#39;s a single executable&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/aler9/rtsp-simple-server/actions?query=workflow:test&#34;&gt;&lt;img src=&#34;https://github.com/aler9/rtsp-simple-server/workflows/test/badge.svg?sanitize=true&#34; alt=&#34;Test&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/aler9/rtsp-simple-server/actions?query=workflow:lint&#34;&gt;&lt;img src=&#34;https://github.com/aler9/rtsp-simple-server/workflows/lint/badge.svg?sanitize=true&#34; alt=&#34;Lint&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/aler9/rtsp-simple-server/branch/main&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/aler9/rtsp-simple-server/branch/main/graph/badge.svg?sanitize=true&#34; alt=&#34;CodeCov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/aler9/rtsp-simple-server/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/aler9/rtsp-simple-server&#34; alt=&#34;Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/aler9/rtsp-simple-server&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docker-aler9/rtsp--simple--server-blue&#34; alt=&#34;Docker Hub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://aler9.github.io/rtsp-simple-server&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/api-documentation-blue&#34; alt=&#34;API Documentation&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Table of contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#installation&#34;&gt;Installation&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#standard&#34;&gt;Standard&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#docker&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#basic-usage&#34;&gt;Basic usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#general&#34;&gt;General&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#configuration&#34;&gt;Configuration&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#authentication&#34;&gt;Authentication&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#encrypt-the-configuration&#34;&gt;Encrypt the configuration&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#proxy-mode&#34;&gt;Proxy mode&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#remuxing-re-encoding-compression&#34;&gt;Remuxing, re-encoding, compression&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#save-streams-to-disk&#34;&gt;Save streams to disk&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#on-demand-publishing&#34;&gt;On-demand publishing&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#start-on-boot&#34;&gt;Start on boot&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#linux&#34;&gt;Linux&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#windows&#34;&gt;Windows&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#http-api&#34;&gt;HTTP API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#metrics&#34;&gt;Metrics&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#pprof&#34;&gt;pprof&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#compile-and-run-from-source&#34;&gt;Compile and run from source&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#publish-to-the-server&#34;&gt;Publish to the server&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#from-a-webcam&#34;&gt;From a webcam&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#from-a-raspberry-pi-camera&#34;&gt;From a Raspberry Pi Camera&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#from-obs-studio&#34;&gt;From OBS Studio&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#from-opencv&#34;&gt;From OpenCV&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#read-from-the-server&#34;&gt;Read from the server&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#from-vlc-and-ubuntu&#34;&gt;From VLC and Ubuntu&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#rtsp-protocol&#34;&gt;RTSP protocol&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#general-usage&#34;&gt;General usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#tcp-transport&#34;&gt;TCP transport&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#udp-multicast-transport&#34;&gt;UDP-multicast transport&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#encryption&#34;&gt;Encryption&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#redirect-to-another-server&#34;&gt;Redirect to another server&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#fallback-stream&#34;&gt;Fallback stream&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#corrupted-frames&#34;&gt;Corrupted frames&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#rtmp-protocol&#34;&gt;RTMP protocol&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#general-usage-1&#34;&gt;General usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#encryption-1&#34;&gt;Encryption&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#hls-protocol&#34;&gt;HLS protocol&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#general-usage-2&#34;&gt;General usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#embedding&#34;&gt;Embedding&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#low-latency-variant&#34;&gt;Low-Latency variant&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#decreasing-latency&#34;&gt;Decreasing latency&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#links&#34;&gt;Links&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Standard&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Download and extract a precompiled binary from the &lt;a href=&#34;https://github.com/aler9/rtsp-simple-server/releases&#34;&gt;release page&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Start the server:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;./rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;Download and launch the image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --rm -it --network=host aler9/rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;--network=host&lt;/code&gt; flag is mandatory since Docker can change the source port of UDP packets for routing reasons, and this doesn&#39;t allow the server to find out the author of the packets. This issue can be avoided by disabling the UDP transport protocol:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --rm -it -e RTSP_PROTOCOLS=tcp -p 8554:8554 -p 1935:1935 -p 8888:8888 aler9/rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please keep in mind that the Docker image doesn&#39;t include &lt;em&gt;FFmpeg&lt;/em&gt;. if you need to use &lt;em&gt;FFmpeg&lt;/em&gt; for an external command or anything else, you need to build a Docker image that contains both &lt;em&gt;rtsp-simple-server&lt;/em&gt; and &lt;em&gt;FFmpeg&lt;/em&gt;, by following instructions &lt;a href=&#34;https://github.com/aler9/rtsp-simple-server/discussions/278#discussioncomment-549104&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Basic usage&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Publish a stream. For instance, you can publish a video/audio file with &lt;em&gt;FFmpeg&lt;/em&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;or &lt;em&gt;GStreamer&lt;/em&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;gst-launch-1.0 rtspclientsink name=s location=rtsp://localhost:8554/mystream filesrc location=file.mp4 ! qtdemux name=d d.video_0 ! queue ! s.sink_0 d.audio_0 ! queue ! s.sink_1&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To publish from other hardware / software, take a look at the &lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#publish-to-the-server&#34;&gt;Publish to the server&lt;/a&gt; section.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open the stream. For instance, you can open the stream with &lt;em&gt;VLC&lt;/em&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;vlc rtsp://localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;or &lt;em&gt;GStreamer&lt;/em&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;gst-play-1.0 rtsp://localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;or &lt;em&gt;FFmpeg&lt;/em&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ffmpeg -i rtsp://localhost:8554/mystream -c copy output.mp4&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;General&lt;/h2&gt; &#xA;&lt;h3&gt;Configuration&lt;/h3&gt; &#xA;&lt;p&gt;All the configuration parameters are listed and commented in the &lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/rtsp-simple-server.yml&#34;&gt;configuration file&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;There are 3 ways to change the configuration:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;By editing the &lt;code&gt;rtsp-simple-server.yml&lt;/code&gt; file, that is&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;included into the release bundle&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;available in the root folder of the Docker image (&lt;code&gt;/rtsp-simple-server.yml&lt;/code&gt;); it can be overridden in this way:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;docker run --rm -it --network=host -v $PWD/rtsp-simple-server.yml:/rtsp-simple-server.yml aler9/rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;The configuration can be changed dynamically when the server is running (hot reloading) by writing to the configuration file. Changes are detected and applied without disconnecting existing clients, whenever it&#39;s possible.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;By overriding configuration parameters with environment variables, in the format &lt;code&gt;RTSP_PARAMNAME&lt;/code&gt;, where &lt;code&gt;PARAMNAME&lt;/code&gt; is the uppercase name of a parameter. For instance, the &lt;code&gt;rtspAddress&lt;/code&gt; parameter can be overridden in the following way:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;RTSP_RTSPADDRESS=&#34;127.0.0.1:8554&#34; ./rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Parameters that have array as value can be overriden by setting a comma-separated list. For example:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;RTSP_PROTOCOLS=&#34;tcp,udp&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Parameters in maps can be overridden by using underscores, in the following way:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;RTSP_PATHS_TEST_SOURCE=rtsp://myurl ./rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This method is particularly useful when using Docker; any configuration parameter can be changed by passing environment variables with the &lt;code&gt;-e&lt;/code&gt; flag:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;docker run --rm -it --network=host -e RTSP_PATHS_TEST_SOURCE=rtsp://myurl aler9/rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;By using the &lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#http-api&#34;&gt;HTTP API&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Authentication&lt;/h3&gt; &#xA;&lt;p&gt;Edit &lt;code&gt;rtsp-simple-server.yml&lt;/code&gt; and replace everything inside section &lt;code&gt;paths&lt;/code&gt; with the following content:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  all:&#xA;    publishUser: myuser&#xA;    publishPass: mypass&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Only publishers that provide both username and password will be able to proceed:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://myuser:mypass@localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It&#39;s possible to setup authentication for readers too:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  all:&#xA;    publishUser: myuser&#xA;    publishPass: mypass&#xA;&#xA;    readUser: user&#xA;    readPass: userpass&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If storing plain credentials in the configuration file is a security problem, username and passwords can be stored as sha256-hashed strings; a string must be hashed with sha256 and encoded with base64:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;echo -n &#34;userpass&#34; | openssl dgst -binary -sha256 | openssl base64&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then stored with the &lt;code&gt;sha256:&lt;/code&gt; prefix:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  all:&#xA;    readUser: sha256:j1tsRqDEw9xvq/D7/9tMx6Jh/jMhk3UfjwIB2f1zgMo=&#xA;    readPass: sha256:BdSWkrdV+ZxFBLUQQY7+7uv9RmiSVA8nrPmjGjJtZQQ=&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: enable encryption or use a VPN to ensure that no one is intercepting the credentials.&lt;/p&gt; &#xA;&lt;p&gt;Authentication can be delegated to an external HTTP server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;externalAuthenticationURL: http://myauthserver/auth&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Each time a user needs to be authenticated, the specified URL will be requested with the POST method and this payload:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;ip&#34;: &#34;ip&#34;,&#xA;  &#34;user&#34;: &#34;user&#34;,&#xA;  &#34;password&#34;: &#34;password&#34;,&#xA;  &#34;path&#34;: &#34;path&#34;,&#xA;  &#34;action&#34;: &#34;read|publish&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the URL returns a status code that begins with &lt;code&gt;20&lt;/code&gt; (i.e. &lt;code&gt;200&lt;/code&gt;), authentication is successful, otherwise it fails.&lt;/p&gt; &#xA;&lt;p&gt;Please be aware that it&#39;s perfectly normal for the authentication server to receive requests with empty users and passwords, i.e.:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;user&#34;: &#34;&#34;,&#xA;  &#34;password&#34;: &#34;&#34;,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This happens because a RTSP client doesn&#39;t provide credentials until it is asked to. In order to receive the credentials, the authentication server must reply with status code &lt;code&gt;401&lt;/code&gt; - the client will then send credentials.&lt;/p&gt; &#xA;&lt;h3&gt;Encrypt the configuration&lt;/h3&gt; &#xA;&lt;p&gt;The configuration file can be entirely encrypted for security purposes.&lt;/p&gt; &#xA;&lt;p&gt;An online encryption tool is &lt;a href=&#34;https://play.golang.org/p/rX29jwObNe4&#34;&gt;available here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The encryption procedure is the following:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;NaCL&#39;s &lt;code&gt;crypto_secretbox&lt;/code&gt; function is applied to the content of the configuration. NaCL is a cryptographic library available for &lt;a href=&#34;https://nacl.cr.yp.to/secretbox.html&#34;&gt;C/C++&lt;/a&gt;, &lt;a href=&#34;https://pkg.go.dev/golang.org/x/crypto/nacl/secretbox&#34;&gt;Go&lt;/a&gt;, &lt;a href=&#34;https://github.com/somdoron/NaCl.net&#34;&gt;C#&lt;/a&gt; and many other languages;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The string is prefixed with the nonce;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The string is encoded with base64.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;After performing the encryption, put the base64-encoded result into the configuration file, and launch the server with the &lt;code&gt;RTSP_CONFKEY&lt;/code&gt; variable:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;RTSP_CONFKEY=mykey ./rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Proxy mode&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;rtsp-simple-server&lt;/em&gt; is also a proxy, that is usually deployed in one of these scenarios:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;when there are multiple users that are reading a stream and the bandwidth is limited; the proxy is used to receive the stream once. Users can then connect to the proxy instead of the original source.&lt;/li&gt; &#xA; &lt;li&gt;when there&#39;s a NAT / firewall between a stream and the users; the proxy is installed on the NAT and makes the stream available to the outside world.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Edit &lt;code&gt;rtsp-simple-server.yml&lt;/code&gt; and replace everything inside section &lt;code&gt;paths&lt;/code&gt; with the following content:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  proxied:&#xA;    # url of the source stream, in the format rtsp://user:pass@host:port/path&#xA;    source: rtsp://original-url&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After starting the server, users can connect to &lt;code&gt;rtsp://localhost:8554/proxied&lt;/code&gt;, instead of connecting to the original url. The server supports any number of source streams, it&#39;s enough to add additional entries to the &lt;code&gt;paths&lt;/code&gt; section:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  proxied1:&#xA;    source: rtsp://url1&#xA;&#xA;  proxied2:&#xA;    source: rtsp://url1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It&#39;s possible to save bandwidth by enabling the on-demand mode: the stream will be pulled only when at least a client is connected:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  proxied:&#xA;    source: rtsp://original-url&#xA;    sourceOnDemand: yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Remuxing, re-encoding, compression&lt;/h3&gt; &#xA;&lt;p&gt;To change the format, codec or compression of a stream, use &lt;em&gt;FFmpeg&lt;/em&gt; or &lt;em&gt;GStreamer&lt;/em&gt; together with &lt;em&gt;rtsp-simple-server&lt;/em&gt;. For instance, to re-encode an existing stream, that is available in the &lt;code&gt;/original&lt;/code&gt; path, and publish the resulting stream in the &lt;code&gt;/compressed&lt;/code&gt; path, edit &lt;code&gt;rtsp-simple-server.yml&lt;/code&gt; and replace everything inside section &lt;code&gt;paths&lt;/code&gt; with the following content:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  all:&#xA;  original:&#xA;    runOnReady: ffmpeg -i rtsp://localhost:$RTSP_PORT/$RTSP_PATH -pix_fmt yuv420p -c:v libx264 -preset ultrafast -b:v 600k -max_muxing_queue_size 1024 -f rtsp rtsp://localhost:$RTSP_PORT/compressed&#xA;    runOnReadyRestart: yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Save streams to disk&lt;/h3&gt; &#xA;&lt;p&gt;To save available streams to disk, you can use the &lt;code&gt;runOnReady&lt;/code&gt; parameter and &lt;em&gt;FFmpeg&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  all:&#xA;  original:&#xA;    runOnReady: ffmpeg -i rtsp://localhost:$RTSP_PORT/$RTSP_PATH -c copy -f segment -strftime 1 -segment_time 60 -segment_format mpegts saved_%Y-%m-%d_%H-%M-%S.ts&#xA;    runOnReadyRestart: yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the example configuration, streams are saved into TS files, that can be read even if the system crashes, while MP4 files can&#39;t.&lt;/p&gt; &#xA;&lt;h3&gt;On-demand publishing&lt;/h3&gt; &#xA;&lt;p&gt;Edit &lt;code&gt;rtsp-simple-server.yml&lt;/code&gt; and replace everything inside section &lt;code&gt;paths&lt;/code&gt; with the following content:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  ondemand:&#xA;    runOnDemand: ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://localhost:$RTSP_PORT/$RTSP_PATH&#xA;    runOnDemandRestart: yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The command inserted into &lt;code&gt;runOnDemand&lt;/code&gt; will start only when a client requests the path &lt;code&gt;ondemand&lt;/code&gt;, therefore the file will start streaming only when requested.&lt;/p&gt; &#xA;&lt;h3&gt;Start on boot&lt;/h3&gt; &#xA;&lt;h4&gt;Linux&lt;/h4&gt; &#xA;&lt;p&gt;Systemd is the service manager used by Ubuntu, Debian and many other Linux distributions, and allows to launch &lt;em&gt;rtsp-simple-server&lt;/em&gt; on boot.&lt;/p&gt; &#xA;&lt;p&gt;Download a release bundle from the &lt;a href=&#34;https://github.com/aler9/rtsp-simple-server/releases&#34;&gt;release page&lt;/a&gt;, unzip it, and move the executable and configuration in the system:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo mv rtsp-simple-server /usr/local/bin/&#xA;sudo mv rtsp-simple-server.yml /usr/local/etc/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create the service:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo tee /etc/systemd/system/rtsp-simple-server.service &amp;gt;/dev/null &amp;lt;&amp;lt; EOF&#xA;[Unit]&#xA;Wants=network.target&#xA;[Service]&#xA;ExecStart=/usr/local/bin/rtsp-simple-server /usr/local/etc/rtsp-simple-server.yml&#xA;[Install]&#xA;WantedBy=multi-user.target&#xA;EOF&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Enable and start the service:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo systemctl enable rtsp-simple-server&#xA;sudo systemctl start rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Windows&lt;/h4&gt; &#xA;&lt;p&gt;Download the &lt;a href=&#34;https://github.com/winsw/winsw/releases/download/v2.11.0/WinSW-x64.exe&#34;&gt;WinSW v2 executable&lt;/a&gt; and place it into the same folder of &lt;code&gt;rtsp-simple-server.exe&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In the same folder, create a file named &lt;code&gt;WinSW-x64.xml&lt;/code&gt; with this content:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;service&amp;gt;&#xA;  &amp;lt;id&amp;gt;rtsp-simple-server&amp;lt;/id&amp;gt;&#xA;  &amp;lt;name&amp;gt;rtsp-simple-server&amp;lt;/name&amp;gt;&#xA;  &amp;lt;description&amp;gt;&amp;lt;/description&amp;gt;&#xA;  &amp;lt;executable&amp;gt;%BASE%/rtsp-simple-server.exe&amp;lt;/executable&amp;gt;&#xA;&amp;lt;/service&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open a terminal, navigate to the folder and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;WinSW-x64 install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The server is now installed as a system service and will start at boot time.&lt;/p&gt; &#xA;&lt;h3&gt;HTTP API&lt;/h3&gt; &#xA;&lt;p&gt;The server can be queried and controlled with an HTTP API, that must be enabled by setting the &lt;code&gt;api&lt;/code&gt; parameter in the configuration:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;api: yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The API listens on &lt;code&gt;apiAddress&lt;/code&gt;, that by default is &lt;code&gt;127.0.0.1:9997&lt;/code&gt;; for instance, to obtain a list of active paths, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl http://127.0.0.1:9997/v1/paths/list&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Full documentation of the API is available on the &lt;a href=&#34;https://aler9.github.io/rtsp-simple-server/&#34;&gt;dedicated site&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Metrics&lt;/h3&gt; &#xA;&lt;p&gt;A metrics exporter, compatible with &lt;a href=&#34;https://prometheus.io/&#34;&gt;Prometheus&lt;/a&gt;, can be enabled with the parameter &lt;code&gt;metrics: yes&lt;/code&gt;; then the server can be queried for metrics with Prometheus or with a simple HTTP request:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;wget -qO- localhost:9998/metrics&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Obtaining:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;# metrics of every path&#xA;paths{name=&#34;[path_name]&#34;,state=&#34;[state]&#34;} 1&#xA;paths_bytes_received{name=&#34;[path_name]&#34;,state=&#34;[state]&#34;} 1234&#xA;&#xA;# metrics of every RTSP connection&#xA;rtsp_conns{id=&#34;[id]&#34;} 1&#xA;rtsp_conns_bytes_received{id=&#34;[id]&#34;} 1234&#xA;rtsp_conns_bytes_sent{id=&#34;[id]&#34;} 187&#xA;&#xA;# metrics of every RTSP session&#xA;rtsp_sessions{id=&#34;[id]&#34;,state=&#34;idle&#34;} 1&#xA;rtsp_sessions_bytes_received{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 1234&#xA;rtsp_sessions_bytes_sent{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 187&#xA;&#xA;# metrics of every RTSPS connection&#xA;rtsps_conns{id=&#34;[id]&#34;} 1&#xA;rtsps_conns_bytes_received{id=&#34;[id]&#34;} 1234&#xA;rtsps_conns_bytes_sent{id=&#34;[id]&#34;} 187&#xA;&#xA;# metrics of every RTSPS session&#xA;rtsps_sessions{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 1&#xA;rtsps_sessions_bytes_received{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 1234&#xA;rtsps_sessions_bytes_sent{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 187&#xA;&#xA;# metrics of every RTMP connection&#xA;rtmp_conns{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 1&#xA;rtmp_conns_bytes_received{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 1234&#xA;rtmp_conns_bytes_sent{id=&#34;[id]&#34;,state=&#34;[state]&#34;} 187&#xA;&#xA;# metrics of every HLS muxer&#xA;hls_muxers{name=&#34;[name]&#34;} 1&#xA;hls_muxers_bytes_sent{name=&#34;[name]&#34;} 187&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;pprof&lt;/h3&gt; &#xA;&lt;p&gt;A performance monitor, compatible with pprof, can be enabled with the parameter &lt;code&gt;pprof: yes&lt;/code&gt;; then the server can be queried for metrics with pprof-compatible tools, like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;go tool pprof -text http://localhost:9999/debug/pprof/goroutine&#xA;go tool pprof -text http://localhost:9999/debug/pprof/heap&#xA;go tool pprof -text http://localhost:9999/debug/pprof/profile?seconds=30&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Compile and run from source&lt;/h3&gt; &#xA;&lt;p&gt;Install Go 1.18, download the repository, open a terminal in it and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go run .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Compilation for all supported platform can be launched by using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;make binaries&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In order to compile and run with support for the Raspberry Pi Camera:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd internal/rpicamera/exe&#xA;make&#xA;cd ../../../&#xA;go build -tags rpicamera&#xA;./rtsp-simple-server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Publish to the server&lt;/h2&gt; &#xA;&lt;h3&gt;From a webcam&lt;/h3&gt; &#xA;&lt;p&gt;To publish the video stream of a generic webcam to the server, edit &lt;code&gt;rtsp-simple-server.yml&lt;/code&gt; and replace everything inside section &lt;code&gt;paths&lt;/code&gt; with the following content:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  cam:&#xA;    runOnInit: ffmpeg -f v4l2 -i /dev/video0 -pix_fmt yuv420p -preset ultrafast -b:v 600k -f rtsp rtsp://localhost:$RTSP_PORT/$RTSP_PATH&#xA;    runOnInitRestart: yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the platform is Windows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  cam:&#xA;    runOnInit: ffmpeg -f dshow -i video=&#34;USB2.0 HD UVC WebCam&#34; -pix_fmt yuv420p -c:v libx264 -preset ultrafast -b:v 600k -f rtsp rtsp://localhost:$RTSP_PORT/$RTSP_PATH&#xA;    runOnInitRestart: yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Where &lt;code&gt;USB2.0 HD UVC WebCam&lt;/code&gt; is the name of your webcam, that can be obtained with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -list_devices true -f dshow -i dummy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After starting the server, the webcam can be reached on &lt;code&gt;rtsp://localhost:8554/cam&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;From a Raspberry Pi Camera&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;rtsp-simple-server&lt;/em&gt; natively support the Raspberry Pi Camera, enabling high-quality and low-latency video streaming from the camera to any user. There are a couple of requisites:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;The server must run on a Raspberry Pi, with Raspberry Pi OS bullseye or newer as operative system. Both 32 bit and 64 bit operative systems are supported.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Make sure that the legacy camera stack is disabled. Type &lt;code&gt;sudo raspi-config&lt;/code&gt;, then go to &lt;code&gt;Interfacing options&lt;/code&gt;, &lt;code&gt;enable/disable legacy camera support&lt;/code&gt;, choose &lt;code&gt;no&lt;/code&gt;. Reboot the system.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;If you want to run the standard (non-containerized) version of the server:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Make sure that the &lt;code&gt;libcamera0&lt;/code&gt; package version is at least &lt;code&gt;0.0.2&lt;/code&gt;, otherwise upgrade it with &lt;code&gt;sudo apt update &amp;amp;&amp;amp; sudo apt install libcamera0&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;download the server executable. If you&#39;re using 64-bit version of the operative system, make sure to pick the &lt;code&gt;arm64&lt;/code&gt; variant.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;edit &lt;code&gt;rtsp-simple-server.yml&lt;/code&gt; and replace everything inside section &lt;code&gt;paths&lt;/code&gt; with the following content:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  cam:&#xA;    source: rpiCamera&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;If you want to run the server with Docker, you need to use the &lt;code&gt;latest-rpi&lt;/code&gt; image (that already contains libcamera) and set some additional flags:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --rm -it \&#xA;--network=host \&#xA;--privileged \&#xA;--tmpfs /dev/shm:exec \&#xA;-v /run/udev:/run/udev:ro \&#xA;-e RTSP_PATHS_CAM_SOURCE=rpiCamera \&#xA;aler9/rtsp-simple-server:latest-rpi&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After starting the server, the camera can be reached on &lt;code&gt;rtsp://raspberry-pi:8554/cam&lt;/code&gt; or &lt;code&gt;http://raspberry-pi:8888/cam&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Camera settings can be changed by using the &lt;code&gt;rpiCamera*&lt;/code&gt; parameters:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  cam:&#xA;    source: rpiCamera&#xA;    rpiCameraWidth: 1920&#xA;    rpiCameraHeight: 1080&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;All available parameters are listed in the &lt;a href=&#34;https://github.com/aler9/rtsp-simple-server/raw/master/rtsp-simple-server.yml#L230&#34;&gt;sample configuration file&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;From OBS Studio&lt;/h3&gt; &#xA;&lt;p&gt;OBS Studio can publish to the server by using the RTMP protocol. In &lt;code&gt;Settings -&amp;gt; Stream&lt;/code&gt; (or in the Auto-configuration Wizard), use the following parameters:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Service: &lt;code&gt;Custom...&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Server: &lt;code&gt;rtmp://localhost&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Stream key: &lt;code&gt;mystream&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If credentials are in use, use the following parameters:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Service: &lt;code&gt;Custom...&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Server: &lt;code&gt;rtmp://localhost&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Stream key: &lt;code&gt;mystream?user=myuser&amp;amp;pass=mypass&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;From OpenCV&lt;/h3&gt; &#xA;&lt;p&gt;To publish a video stream from OpenCV to the server, OpenCV must be compiled with GStreamer support, by following this procedure:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo apt install -y libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev gstreamer1.0-plugins-ugly gstreamer1.0-rtsp python3-dev python3-numpy&#xA;git clone --depth=1 -b 4.5.4 https://github.com/opencv/opencv&#xA;cd opencv&#xA;mkdir build &amp;amp;&amp;amp; cd build&#xA;cmake -D CMAKE_INSTALL_PREFIX=/usr -D WITH_GSTREAMER=ON ..&#xA;make -j$(nproc)&#xA;sudo make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Videos can be published with &lt;code&gt;VideoWriter&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import cv2&#xA;import numpy as np&#xA;from time import sleep&#xA;&#xA;fps = 20&#xA;width = 800&#xA;height = 600&#xA;&#xA;out = cv2.VideoWriter(&#39;appsrc ! videoconvert&#39; + \&#xA;    &#39; ! x264enc speed-preset=ultrafast bitrate=600 key-int-max=40&#39; + \&#xA;    &#39; ! rtspclientsink location=rtsp://localhost:8554/mystream&#39;,&#xA;    cv2.CAP_GSTREAMER, 0, fps, (width, height), True)&#xA;if not out.isOpened():&#xA;    raise Exception(&#34;can&#39;t open video writer&#34;)&#xA;&#xA;while True:&#xA;    frame = np.zeros((height, width, 3), np.uint8)&#xA;&#xA;    # create a red rectangle&#xA;    for y in range(0, int(frame.shape[0] / 2)):&#xA;        for x in range(0, int(frame.shape[1] / 2)):&#xA;            frame[y][x] = (0, 0, 255)&#xA;&#xA;    out.write(frame)&#xA;    print(&#34;frame written to the server&#34;)&#xA;&#xA;    sleep(1 / fps)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Read from the server&lt;/h2&gt; &#xA;&lt;h3&gt;From VLC and Ubuntu&lt;/h3&gt; &#xA;&lt;p&gt;The VLC shipped with Ubuntu 21.10 doesn&#39;t support playing RTSP due to a license issue (see &lt;a href=&#34;https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=982299&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://stackoverflow.com/questions/69766748/cvlc-cannot-play-rtsp-omxplayer-instead-can&#34;&gt;here&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;To overcome the issue, remove the default VLC instance and install the snap version:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo apt purge -y vlc&#xA;snap install vlc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then use it to read the stream:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;vlc rtsp://localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;RTSP protocol&lt;/h2&gt; &#xA;&lt;h3&gt;General usage&lt;/h3&gt; &#xA;&lt;p&gt;RTSP is a standardized protocol that allows to publish and read streams; in particular, it supports different underlying transport protocols, that are chosen by clients during the handshake with the server:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;UDP: the most performant, but doesn&#39;t work when there&#39;s a NAT/firewall between server and clients. It doesn&#39;t support encryption.&lt;/li&gt; &#xA; &lt;li&gt;UDP-multicast: allows to save bandwidth when clients are all in the same LAN, by sending packets once to a fixed multicast IP. It doesn&#39;t support encryption.&lt;/li&gt; &#xA; &lt;li&gt;TCP: the most versatile, does support encryption.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The default transport protocol is UDP. To change the transport protocol, you have to tune the configuration of your client of choice.&lt;/p&gt; &#xA;&lt;h3&gt;TCP transport&lt;/h3&gt; &#xA;&lt;p&gt;The RTSP protocol supports the TCP transport protocol, that allows to receive packets even when there&#39;s a NAT/firewall between server and clients, and supports encryption (see &lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/#encryption&#34;&gt;Encryption&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;You can use &lt;em&gt;FFmpeg&lt;/em&gt; to publish a stream with the TCP transport protocol:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp -rtsp_transport tcp rtsp://localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can use &lt;em&gt;FFmpeg&lt;/em&gt; to read that stream with the TCP transport protocol:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -rtsp_transport tcp -i rtsp://localhost:8554/mystream -c copy output.mp4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can use &lt;em&gt;GStreamer&lt;/em&gt; to read that stream with the TCP transport protocol:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gst-launch-1.0 rtspsrc protocols=tcp location=rtsp://localhost:8554/mystream ! fakesink&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can use &lt;em&gt;VLC&lt;/em&gt; to read that stream with the TCP transport protocol:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;vlc --rtsp-tcp rtsp://localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;UDP-multicast transport&lt;/h3&gt; &#xA;&lt;p&gt;The RTSP protocol supports the UDP-multicast transport protocol, that allows a server to send packets once, regardless of the number of connected readers, saving bandwidth.&lt;/p&gt; &#xA;&lt;p&gt;This mode must be requested by readers when handshaking with the server; once a reader has completed a handshake, the server will start sending multicast packets. Other readers will be instructed to read existing multicast packets. When all multicast readers have disconnected from the server, the latter will stop sending multicast packets.&lt;/p&gt; &#xA;&lt;p&gt;If you want to use the UDP-multicast protocol in a Wireless LAN, please be aware that the maximum bitrate supported by multicast is the one that corresponds to the lowest enabled WiFi data rate. For instance, if the 1 Mbps data rate is enabled on your router (and it is on most routers), the maximum bitrate will be 1 Mbps. To increase the maximum bitrate, use a cabled LAN or change your router settings.&lt;/p&gt; &#xA;&lt;p&gt;To request and read a stream with UDP-multicast, you can use &lt;em&gt;FFmpeg&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -rtsp_transport udp_multicast -i rtsp://localhost:8554/mystream -c copy output.mp4&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or &lt;em&gt;GStreamer&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gst-launch-1.0 rtspsrc protocols=udp-mcast location=rtsps://ip:8554/...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or &lt;em&gt;VLC&lt;/em&gt; (append &lt;code&gt;?vlcmulticast&lt;/code&gt; to the URL):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;vlc rtsp://localhost:8554/mystream?vlcmulticast&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Encryption&lt;/h3&gt; &#xA;&lt;p&gt;Incoming and outgoing RTSP streams can be encrypted with TLS (obtaining the RTSPS protocol). A TLS certificate is needed and can be generated with OpenSSL:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;openssl genrsa -out server.key 2048&#xA;openssl req -new -x509 -sha256 -key server.key -out server.crt -days 3650&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Edit &lt;code&gt;rtsp-simple-server.yml&lt;/code&gt;, and set the &lt;code&gt;protocols&lt;/code&gt;, &lt;code&gt;encryption&lt;/code&gt;, &lt;code&gt;serverKey&lt;/code&gt; and &lt;code&gt;serverCert&lt;/code&gt; parameters:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;protocols: [tcp]&#xA;encryption: optional&#xA;serverKey: server.key&#xA;serverCert: server.crt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Streams can be published and read with the &lt;code&gt;rtsps&lt;/code&gt; scheme and the &lt;code&gt;8322&lt;/code&gt; port:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -i rtsps://ip:8322/...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the client is &lt;em&gt;GStreamer&lt;/em&gt;, disable the certificate validation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gst-launch-1.0 rtspsrc tls-validation-flags=0 location=rtsps://ip:8322/...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;At the moment &lt;em&gt;VLC&lt;/em&gt; doesn&#39;t support reading encrypted RTSP streams. A workaround consists in launching an instance of &lt;em&gt;rtsp-simple-server&lt;/em&gt; on the same machine in which &lt;em&gt;VLC&lt;/em&gt; is running, using it for reading the encrypted stream with the proxy mode, and reading the proxied stream with &lt;em&gt;VLC&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Redirect to another server&lt;/h3&gt; &#xA;&lt;p&gt;To redirect to another server, use the &lt;code&gt;redirect&lt;/code&gt; source:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  redirected:&#xA;    source: redirect&#xA;    sourceRedirect: rtsp://otherurl/otherpath&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Fallback stream&lt;/h3&gt; &#xA;&lt;p&gt;If no one is publishing to the server, readers can be redirected to a fallback path or URL that is serving a fallback stream:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  withfallback:&#xA;    fallback: /otherpath&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Corrupted frames&lt;/h3&gt; &#xA;&lt;p&gt;In some scenarios, when reading RTSP from the server, decoded frames can be corrupted or incomplete. This can be caused by multiple reasons:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;the packet buffer of the server is too small and can&#39;t keep up with the stream throughput. A solution consists in increasing its size:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;readBufferCount: 1024&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The stream throughput is too big and the stream can&#39;t be sent correctly with the UDP transport. UDP is more performant, faster and more efficient than TCP, but doesn&#39;t have a retransmission mechanism, that is needed in case of streams that need a large bandwidth. A solution consists in switching to TCP:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;protocols: [tcp]&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In case the source is a camera:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;paths:&#xA;  test:&#xA;    source: rtsp://..&#xA;    sourceProtocol: tcp&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;RTMP protocol&lt;/h2&gt; &#xA;&lt;h3&gt;General usage&lt;/h3&gt; &#xA;&lt;p&gt;RTMP is a protocol that allows to read and publish streams, but is less versatile and less efficient than RTSP (doesn&#39;t support UDP, encryption, doesn&#39;t support most RTSP codecs, doesn&#39;t support feedback mechanism). It is used when there&#39;s need of publishing or reading streams from a software that supports only RTMP (for instance, OBS Studio and DJI drones).&lt;/p&gt; &#xA;&lt;p&gt;At the moment, only the H264 and AAC codecs can be used with the RTMP protocol.&lt;/p&gt; &#xA;&lt;p&gt;Streams can be published or read with the RTMP protocol, for instance with &lt;em&gt;FFmpeg&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -re -stream_loop -1 -i file.ts -c copy -f flv rtmp://localhost/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or &lt;em&gt;GStreamer&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gst-launch-1.0 -v flvmux name=s ! rtmpsink location=rtmp://localhost/mystream filesrc location=file.mp4 ! qtdemux name=d d.video_0 ! queue ! s.video d.audio_0 ! queue ! s.audio&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Credentials can be provided by appending to the URL the &lt;code&gt;user&lt;/code&gt; and &lt;code&gt;pass&lt;/code&gt; parameters:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -re -stream_loop -1 -i file.ts -c copy -f flv rtmp://localhost:8554/mystream?user=myuser&amp;amp;pass=mypass&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Encryption&lt;/h3&gt; &#xA;&lt;p&gt;RTMP connections can be encrypted with TLS, obtaining the RTMPS protocol. A TLS certificate is needed and can be generated with OpenSSL:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;openssl genrsa -out server.key 2048&#xA;openssl req -new -x509 -sha256 -key server.key -out server.crt -days 3650&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Edit &lt;code&gt;rtsp-simple-server.yml&lt;/code&gt;, and set the &lt;code&gt;rtmpEncryption&lt;/code&gt;, &lt;code&gt;rtmpServerKey&lt;/code&gt; and &lt;code&gt;rtmpServerCert&lt;/code&gt; parameters:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;rtmpEncryption: optional&#xA;rtmpServerKey: server.key&#xA;rtmpServerCert: server.crt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Streams can be published and read with the &lt;code&gt;rtmps&lt;/code&gt; scheme and the &lt;code&gt;1937&lt;/code&gt; port:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;rtmps://localhost:1937/...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please be aware that RTMPS is currently unsupported by &lt;em&gt;VLC&lt;/em&gt;, &lt;em&gt;FFmpeg&lt;/em&gt; and &lt;em&gt;GStreamer&lt;/em&gt;. However, you can use a proxy like &lt;a href=&#34;https://www.stunnel.org/&#34;&gt;stunnel&lt;/a&gt; or &lt;a href=&#34;https://nginx.org/&#34;&gt;nginx&lt;/a&gt; to allow RTMP clients to access RTMPS resources.&lt;/p&gt; &#xA;&lt;h2&gt;HLS protocol&lt;/h2&gt; &#xA;&lt;h3&gt;General usage&lt;/h3&gt; &#xA;&lt;p&gt;HLS is a protocol that allows to embed live streams into web pages. It works by splitting streams into segments, and by serving these segments with the HTTP protocol. Every stream published to the server can be accessed by visiting:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;http://localhost:8888/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;mystream&lt;/code&gt; is the name of a stream that is being published.&lt;/p&gt; &#xA;&lt;p&gt;Please be aware that HLS only supports a single H264 video track and a single AAC audio track due to limitations of most browsers. If you want to use HLS with streams that use other codecs, you have to re-encode them, for instance by using &lt;em&gt;FFmpeg&lt;/em&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -i rtsp://original-source -pix_fmt yuv420p -c:v libx264 -preset ultrafast -b:v 600k -c:a aac -b:a 160k -f rtsp rtsp://localhost:8554/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Embedding&lt;/h3&gt; &#xA;&lt;p&gt;The simples way to embed a live stream into a web page consists in using an iframe tag:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;iframe src=&#34;http://rtsp-simple-server-ip:8888/mystream&#34; scrolling=&#34;no&#34;&amp;gt;&amp;lt;/iframe&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively you can create a video tag that points directly to the stream playlist:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;video src=&#34;http://localhost:8888/mystream/index.m3u8&#34;&amp;gt;&amp;lt;/video&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please note that most browsers don&#39;t support HLS directly (except Safari); a Javascript library, like &lt;a href=&#34;https://github.com/video-dev/hls.js&#34;&gt;hls.js&lt;/a&gt;, must be used to load the stream. You can find a working example by looking at the &lt;a href=&#34;https://raw.githubusercontent.com/aler9/rtsp-simple-server/main/internal/core/hls_muxer.go&#34;&gt;source code of the HLS muxer&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Low-Latency variant&lt;/h3&gt; &#xA;&lt;p&gt;Low-Latency HLS is a &lt;a href=&#34;https://datatracker.ietf.org/doc/html/draft-pantos-hls-rfc8216bis&#34;&gt;recently standardized&lt;/a&gt; variant of the protocol that allows to greatly reduce playback latency. It works by splitting segments into parts, that are served before the segment is complete.&lt;/p&gt; &#xA;&lt;p&gt;LL-HLS is disabled by default. To enable it, a TLS certificate is needed and can be generated with OpenSSL:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;openssl genrsa -out server.key 2048&#xA;openssl req -new -x509 -sha256 -key server.key -out server.crt -days 3650&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Set the &lt;code&gt;hlsVariant&lt;/code&gt;, &lt;code&gt;hlsEncryption&lt;/code&gt;, &lt;code&gt;hlsServerKey&lt;/code&gt; and &lt;code&gt;hlsServerCert&lt;/code&gt; parameters in the configuration file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;hlsVariant: lowLatency&#xA;hlsEncryption: yes&#xA;hlsServerKey: server.key&#xA;hlsServerCert: server.crt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Every stream published to the server can be read with LL-HLS by visiting:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;https://localhost:8888/mystream&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the stream is not shown correctly, try tuning the &lt;code&gt;hlsPartDuration&lt;/code&gt; parameter, for instance:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;hlsPartDuration: 500ms&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Decreasing latency&lt;/h3&gt; &#xA;&lt;p&gt;in HLS, latency is introduced since a client must wait for the server to generate segments before downloading them. This latency amounts to 1-15secs depending on the duration of each segment, and to 500ms-3s if the Low-Latency variant is enabled.&lt;/p&gt; &#xA;&lt;p&gt;To decrease the latency, you can:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;enable the Low-Latency variant of the HLS protocol, as explained in the previous section;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;if Low-latency is enabled, try decreasing the &lt;code&gt;hlsPartDuration&lt;/code&gt; parameter;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;try decreasing the &lt;code&gt;hlsSegmentDuration&lt;/code&gt; parameter;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The segment duration is influenced by the interval between the IDR frames of the video track. An IDR frame is a frame that can be decoded independently from the others. The server changes the segment duration in order to include at least one IDR frame into each segment. Therefore, you need to decrease the interval between the IDR frames. This can be done in two ways:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;if the stream is being hardware-generated (i.e. by a camera), there&#39;s usually a setting called &lt;em&gt;Key-Frame Interval&lt;/em&gt; in the camera configuration page&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;otherwise, the stream must be re-encoded. It&#39;s possible to tune the IDR frame interval by using ffmpeg&#39;s &lt;code&gt;-g&lt;/code&gt; option:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ffmpeg -i rtsp://original-stream -pix_fmt yuv420p -c:v libx264 -preset ultrafast -b:v 600k -max_muxing_queue_size 1024 -g 30 -f rtsp rtsp://localhost:$RTSP_PORT/compressed&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;p&gt;Related projects&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;gortsplib (RTSP library used internally) &lt;a href=&#34;https://github.com/aler9/gortsplib&#34;&gt;https://github.com/aler9/gortsplib&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;pion/sdp (SDP library used internally) &lt;a href=&#34;https://github.com/pion/sdp&#34;&gt;https://github.com/pion/sdp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;pion/rtp (RTP library used internally) &lt;a href=&#34;https://github.com/pion/rtp&#34;&gt;https://github.com/pion/rtp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;pion/rtcp (RTCP library used internally) &lt;a href=&#34;https://github.com/pion/rtcp&#34;&gt;https://github.com/pion/rtcp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;notedit/rtmp (RTMP library used internally) &lt;a href=&#34;https://github.com/notedit/rtmp&#34;&gt;https://github.com/notedit/rtmp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;go-astits (MPEG-TS library used internally) &lt;a href=&#34;https://github.com/asticode/go-astits&#34;&gt;https://github.com/asticode/go-astits&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;go-mp4 (MP4 library used internally) &lt;a href=&#34;https://github.com/abema/go-mp4&#34;&gt;https://github.com/abema/go-mp4&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/flaviostutz/rtsp-relay&#34;&gt;https://github.com/flaviostutz/rtsp-relay&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Standards&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;RTSP 1.0 &lt;a href=&#34;https://datatracker.ietf.org/doc/html/rfc2326&#34;&gt;https://datatracker.ietf.org/doc/html/rfc2326&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;RTSP 2.0 &lt;a href=&#34;https://datatracker.ietf.org/doc/html/rfc7826&#34;&gt;https://datatracker.ietf.org/doc/html/rfc7826&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;HTTP 1.1 &lt;a href=&#34;https://datatracker.ietf.org/doc/html/rfc2616&#34;&gt;https://datatracker.ietf.org/doc/html/rfc2616&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;HLS &lt;a href=&#34;https://datatracker.ietf.org/doc/html/rfc8216&#34;&gt;https://datatracker.ietf.org/doc/html/rfc8216&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;HLS v2 &lt;a href=&#34;https://datatracker.ietf.org/doc/html/draft-pantos-hls-rfc8216bis&#34;&gt;https://datatracker.ietf.org/doc/html/draft-pantos-hls-rfc8216bis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Golang project layout &lt;a href=&#34;https://github.com/golang-standards/project-layout&#34;&gt;https://github.com/golang-standards/project-layout&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>cloneofsimo/lora</title>
    <updated>2022-12-15T01:29:46Z</updated>
    <id>tag:github.com,2022-12-15:/cloneofsimo/lora</id>
    <link href="https://github.com/cloneofsimo/lora" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Using Low-rank adaptation to quickly fine-tune diffusion models.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Low-rank Adaptation for Fast Text-to-Image Diffusion Fine-tuning&lt;/h1&gt; &#xA;&lt;!-- #region --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cloneofsimo/lora/master/contents/alpha_scale.gif&#34;&gt; &lt;/p&gt; &#xA;&lt;!-- #endregion --&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Using LoRA to fine tune on illustration dataset : $W = W_0 + \alpha \Delta W$, where $\alpha$ is the merging ratio. Above gif is scaling alpha from 0 to 1. Setting alpha to 0 is same as using the original model, and setting alpha to 1 is same as using the fully fine-tuned model.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;!-- #region --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cloneofsimo/lora/master/contents/lora_with_clip.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;!-- #endregion --&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;game character bnha, wearing a red shirt, riding a donkey&#34;, with Overwatch-fine-tuned LoRA model, for both CLIP and Unet.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;!-- #region --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cloneofsimo/lora/master/contents/disney_lora.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;!-- #endregion --&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;style of sks, baby lion&#34;, with disney-style LoRA model.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;!-- #region --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cloneofsimo/lora/master/contents/pop_art.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;!-- #endregion --&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;style of sks, superman&#34;, with pop-art style LoRA model.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Main Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fine-tune Stable diffusion models twice as faster than dreambooth method, by Low-rank Adaptation&lt;/li&gt; &#xA; &lt;li&gt;Get insanely small end result (3MB for just unet, 6MB for both unet + clip), easy to share and download.&lt;/li&gt; &#xA; &lt;li&gt;Easy to use, compatible with &lt;code&gt;diffusers&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Sometimes &lt;em&gt;even better performance&lt;/em&gt; than full fine-tuning (but left as future work for extensive comparisons)&lt;/li&gt; &#xA; &lt;li&gt;Merge checkpoints + Build recipes by merging LoRAs together&lt;/li&gt; &#xA; &lt;li&gt;Fine-tune both CLIP &amp;amp; Unet to gain better results.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Web Demo&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Integrated into &lt;a href=&#34;https://huggingface.co/spaces&#34;&gt;Huggingface Spaces 🤗&lt;/a&gt; using &lt;a href=&#34;https://github.com/gradio-app/gradio&#34;&gt;Gradio&lt;/a&gt;. Try out the Web Demo &lt;a href=&#34;https://huggingface.co/spaces/ysharma/Low-rank-Adaptation&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Easy &lt;a href=&#34;https://colab.research.google.com/drive/1iSFDpRBKEWr2HLlz243rbym3J2X95kcy?usp=sharing&#34;&gt;colab running example&lt;/a&gt; of Dreambooth by @pedrogengo&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;UPDATES &amp;amp; Notes&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;You can now fine-tune text_encoder as well! Enabled with simple &lt;code&gt;--train_text_encoder&lt;/code&gt;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Converting to CKPT format for A1111&#39;s repo consumption!&lt;/strong&gt; (Thanks to &lt;a href=&#34;https://github.com/jachiam&#34;&gt;jachiam&lt;/a&gt;&#39;s conversion script)&lt;/li&gt; &#xA; &lt;li&gt;Img2Img Examples added.&lt;/li&gt; &#xA; &lt;li&gt;Please use large learning rate! Around 1e-4 worked well for me, but certainly not around 1e-6 which will not be able to learn anything.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Lengthy Introduction&lt;/h1&gt; &#xA;&lt;p&gt;Thanks to the generous work of Stability AI and Huggingface, so many people have enjoyed fine-tuning stable diffusion models to fit their needs and generate higher fidelity images. &lt;strong&gt;However, the fine-tuning process is very slow, and it is not easy to find a good balance between the number of steps and the quality of the results.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Also, the final results (fully fined-tuned model) is very large. Some people instead works with textual-inversion as an alternative for this. But clearly this is suboptimal: textual inversion only creates a small word-embedding, and the final image is not as good as a fully fine-tuned model.&lt;/p&gt; &#xA;&lt;p&gt;Well, what&#39;s the alternative? In the domain of LLM, researchers have developed Efficient fine-tuning methods. LoRA, especially, tackles the very problem the community currently has: end users with Open-sourced stable-diffusion model want to try various other fine-tuned model that is created by the community, but the model is too large to download and use. LoRA instead attempts to fine-tune the &#34;residual&#34; of the model instead of the entire model: i.e., train the $\Delta W$ instead of $W$.&lt;/p&gt; &#xA;&lt;p&gt;$$ W&#39; = W + \Delta W $$&lt;/p&gt; &#xA;&lt;p&gt;Where we can further decompose $\Delta W$ into low-rank matrices : $\Delta W = A B^T $, where $A, \in \mathbb{R}^{n \times d}, B \in \mathbb{R}^{m \times d}, d &amp;lt;&amp;lt; n$. This is the key idea of LoRA. We can then fine-tune $A$ and $B$ instead of $W$. In the end, you get an insanely small model as $A$ and $B$ are much smaller than $W$.&lt;/p&gt; &#xA;&lt;p&gt;Also, not all of the parameters need tuning: they found that often, $Q, K, V, O$ (i.e., attention layer) of the transformer model is enough to tune. (This is also the reason why the end result is so small). This repo will follow the same idea.&lt;/p&gt; &#xA;&lt;p&gt;Enough of the lengthy introduction, let&#39;s get to the code.&lt;/p&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install git+https://github.com/cloneofsimo/lora.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Getting Started&lt;/h1&gt; &#xA;&lt;h2&gt;Fine-tuning Stable diffusion with LoRA.&lt;/h2&gt; &#xA;&lt;p&gt;Basic usage is as follows: prepare sets of $A, B$ matrices in an unet model, and fine-tune them.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from lora_diffusion import inject_trainable_lora, extract_lora_up_downs&#xA;&#xA;...&#xA;&#xA;unet = UNet2DConditionModel.from_pretrained(&#xA;    pretrained_model_name_or_path,&#xA;    subfolder=&#34;unet&#34;,&#xA;)&#xA;unet.requires_grad_(False)&#xA;unet_lora_params, train_names = inject_trainable_lora(unet)  # This will&#xA;# turn off all of the gradients of unet, except for the trainable LoRA params.&#xA;optimizer = optim.Adam(&#xA;    itertools.chain(*unet_lora_params, text_encoder.parameters()), lr=1e-4&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;An example of this can be found in &lt;code&gt;train_lora_dreambooth.py&lt;/code&gt;. Run this example with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;run_lora_db.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Another dreambooth example, with text_encoder training on can be run with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;run_lora_db_w_text.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Loading, merging, and interpolating trained LORAs with CLIs.&lt;/h2&gt; &#xA;&lt;p&gt;We&#39;ve seen that people have been merging different checkpoints with different ratios, and this seems to be very useful to the community. LoRA is extremely easy to merge.&lt;/p&gt; &#xA;&lt;p&gt;By the nature of LoRA, one can interpolate between different fine-tuned models by adding different $A, B$ matrices.&lt;/p&gt; &#xA;&lt;p&gt;Currently, LoRA cli has three options : merge full model with LoRA, merge LoRA with LoRA, or merge full model with LoRA and changes to &lt;code&gt;ckpt&lt;/code&gt; format (original format)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;SYNOPSIS&#xA;    lora_add PATH_1 PATH_2 OUTPUT_PATH &amp;lt;flags&amp;gt;&#xA;&#xA;POSITIONAL ARGUMENTS&#xA;    PATH_1&#xA;        Type: str&#xA;    PATH_2&#xA;        Type: str&#xA;    OUTPUT_PATH&#xA;        Type: str&#xA;&#xA;FLAGS&#xA;    --alpha&#xA;        Type: float&#xA;        Default: 0.5&#xA;    --mode&#xA;        Type: Literal[&#39;upl&#39;, &#39;lpl&#39;, &#39;upl&#39;, &#39;upl-ckpt-v2&#39;]&#xA;        Default: &#39;lpl&#39;&#xA;    --with_text_lora&#xA;        Type: bool&#xA;        Default: False&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Merging full model with LoRA&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ lora_add --path_1 PATH_TO_DIFFUSER_FORMAT_MODEL --path_2 PATH_TO_LORA.PT --mode upl --alpha 1.0 --output_path OUTPUT_PATH&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;path_1&lt;/code&gt; can be both local path or huggingface model name. When adding LoRA to unet, alpha is the constant as below:&lt;/p&gt; &#xA;&lt;p&gt;$$ W&#39; = W + \alpha \Delta W $$&lt;/p&gt; &#xA;&lt;p&gt;So, set alpha to 1.0 to fully add LoRA. If the LoRA seems to have too much effect (i.e., overfitted), set alpha to lower value. If the LoRA seems to have too little effect, set alpha to higher than 1.0. You can tune these values to your needs. This value can be even slightly greater than 1.0!&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ lora_add --path_1 stabilityai/stable-diffusion-2-base --path_2 lora_illust.pt --mode upl --alpha 1.0 --output_path merged_model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Mergigng Full model with LoRA and changing to original CKPT format&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;TESTED WITH V2, V2.1 ONLY!&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Everything same as above, but with mode &lt;code&gt;upl-ckpt-v2&lt;/code&gt; instead of &lt;code&gt;upl&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ lora_add --path_1 stabilityai/stable-diffusion-2-base --path_2 lora_illust.pt --mode upl-ckpt-v2 --alpha 1.2 --output_path merged_model.ckpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Merging LoRA with LoRA&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ lora_add --path_1 PATH_TO_LORA.PT --path_2 PATH_TO_LORA.PT --mode lpl --alpha 0.5 --output_path OUTPUT_PATH.PT&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;alpha is the ratio of the first model to the second model. i.e.,&lt;/p&gt; &#xA;&lt;p&gt;$$ \Delta W = (\alpha A_1 + (1 - \alpha) A_2) (\alpha B_1 + (1 - \alpha) B_2)^T $$&lt;/p&gt; &#xA;&lt;p&gt;Set alpha to 0.5 to get the average of the two models. Set alpha close to 1.0 to get more effect of the first model, and set alpha close to 0.0 to get more effect of the second model.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ lora_add --path_1 lora_illust.pt --path_2 lora_pop.pt --alpha 0.3 --output_path lora_merged.pt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;More bash examples with Text Encoder Lora:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ lora_add --path_1 stabilityai/stable-diffusion-2-base --path_2 lora_kiriko.pt --mode upl-ckpt-v2 --alpha 1.2 --with_text_lora --output_path merged_model.ckpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;: This will build a &lt;code&gt;merged_model.ckpt&lt;/code&gt; with LoRA merged with $\alpha=1.2$ and text encoder LoRA.&lt;/p&gt; &#xA;&lt;h3&gt;Making Text2Img Inference with trained LoRA&lt;/h3&gt; &#xA;&lt;p&gt;Checkout &lt;code&gt;scripts/run_inference.ipynb&lt;/code&gt; for an example of how to make inference with LoRA.&lt;/p&gt; &#xA;&lt;h3&gt;Making Img2Img Inference with LoRA&lt;/h3&gt; &#xA;&lt;p&gt;Checkout &lt;code&gt;scripts/run_img2img.ipynb&lt;/code&gt; for an example of how to make inference with LoRA.&lt;/p&gt; &#xA;&lt;h3&gt;Merging Lora with Lora, and making inference dynamically using &lt;code&gt;monkeypatch_add_lora&lt;/code&gt;.&lt;/h3&gt; &#xA;&lt;p&gt;Checkout &lt;code&gt;scripts/merge_lora_with_lora.ipynb&lt;/code&gt; for an example of how to merge Lora with Lora, and make inference dynamically using &lt;code&gt;monkeypatch_add_lora&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;!-- #region --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cloneofsimo/lora/master/contents/lora_with_clip_and_illust.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;!-- #endregion --&gt; &#xA;&lt;p&gt;Above results are from merging &lt;code&gt;lora_illust.pt&lt;/code&gt; with &lt;code&gt;lora_kiriko.pt&lt;/code&gt; with both 1.0 as weights and 0.5 as $\alpha$.&lt;/p&gt; &#xA;&lt;p&gt;$$ W_{unet} \leftarrow W_{unet} + 0.5 (A_{kiriko} + A_{illust})(B_{kiriko} + B_{illust})^T $$&lt;/p&gt; &#xA;&lt;p&gt;and&lt;/p&gt; &#xA;&lt;p&gt;$$ W_{clip} \leftarrow W_{clip} + 0.5 A_{kiriko}B_{kiriko}^T $$&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Tips and Discussions&lt;/h1&gt; &#xA;&lt;h2&gt;&lt;strong&gt;Training tips in general&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;p&gt;I&#39;m curating a list of tips and discussions here. Feel free to add your own tips and discussions with a PR!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Discussion by @nitrosocke, can be found &lt;a href=&#34;https://github.com/cloneofsimo/lora/issues/19#issuecomment-1347149627&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Configurations by @xsteenbrugge, Using Clip-interrogator to get a decent prompt seems to work well for him, &lt;a href=&#34;https://twitter.com/xsteenbrugge/status/1602799180698763264&#34;&gt;https://twitter.com/xsteenbrugge/status/1602799180698763264&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Super easy &lt;a href=&#34;https://colab.research.google.com/drive/1iSFDpRBKEWr2HLlz243rbym3J2X95kcy?usp=sharing&#34;&gt;colab running example&lt;/a&gt; of Dreambooth by @pedrogengo&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cloneofsimo/lora/discussions/37&#34;&gt;Amazing in-depth analysis&lt;/a&gt; on the effect of rank, $\alpha_{unet}$, $\alpha_{clip}$, and training configurations from brian6091!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;&lt;strong&gt;How long should you train?&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Effect of fine tuning (both Unet + CLIP) can be seen in the following image, where each image is another 500 steps. Trained with 9 images, with lr of &lt;code&gt;1e-4&lt;/code&gt; for unet, and &lt;code&gt;5e-5&lt;/code&gt; for CLIP. (You can adjust this with &lt;code&gt;--learning_rate=1e-4&lt;/code&gt; and &lt;code&gt;--learning_rate_text=5e-5&lt;/code&gt;)&lt;/p&gt; &#xA;&lt;!-- #region --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cloneofsimo/lora/master/contents/lora_with_clip_4x4_training_progress.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;!-- #endregion --&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;female game character bnha, in a steampunk city, 4K render, trending on artstation, masterpiece&#34;. Visualization notebook can be found at scripts/lora_training_process_visualized.ipynb&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;You can see that with 2500 steps, you already get somewhat good results.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;What is a good learning rate for LoRA?&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;People using dreambooth are used to using lr around &lt;code&gt;1e-6&lt;/code&gt;, but this is way too small for training LoRAs. &lt;strong&gt;I&#39;ve tried using 1e-4, and it is OK&lt;/strong&gt;. I think these values should be more explored statistically.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;What happens to Text Encoder LoRA and Unet LoRA?&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Let&#39;s see: the following is only using Unet LoRA:&lt;/p&gt; &#xA;&lt;!-- #region --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cloneofsimo/lora/master/contents/lora_just_unet.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;!-- #endregion --&gt; &#xA;&lt;p&gt;And the following is only using Text Encoder LoRA:&lt;/p&gt; &#xA;&lt;!-- #region --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cloneofsimo/lora/master/contents/lora_just_text_encoder.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;!-- #endregion --&gt; &#xA;&lt;p&gt;So they learnt different aspect of the dataset, but they are not mutually exclusive. You can use both of them to get better results, and tune them seperately to get even better results.&lt;/p&gt; &#xA;&lt;p&gt;With LoRA Text Encoder, Unet, all the schedulers, guidance scale, negative prompt etc. etc., you have so much to play around with to get the best result you want. For example, with $\alpha_{unet} = 0.6$, $\alpha_{text} = 0.9$, you get a better result compared to $\alpha_{unet} = 1.0$, $\alpha_{text} = 1.0$ (default). Checkout below:&lt;/p&gt; &#xA;&lt;!-- #region --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cloneofsimo/lora/master/contents/lora_some_tweaks.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;!-- #endregion --&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Left with tuned $\alpha_{unet} = 0.6$, $\alpha_{text} = 0.9$, right with $\alpha_{unet} = 1.0$, $\alpha_{text} = 1.0$.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Here is an extensive visualization on the effect of $\alpha_{unet}$, $\alpha_{text}$, by @brian6091 from &lt;a href=&#34;https://github.com/cloneofsimo/lora/discussions/37&#34;&gt;his analysis &lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- #region --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cloneofsimo/lora/master/contents/comp_scale_clip_unet.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;!-- #endregion --&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;a photo of (S*)&#34;, trained with 21 images, with rank 16 LoRA. More details can be found &lt;a href=&#34;https://github.com/cloneofsimo/lora/discussions/37&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;TODOS&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Make this more user friendly for non-programmers&lt;/li&gt; &#xA; &lt;li&gt;Make a better CLI&lt;/li&gt; &#xA; &lt;li&gt;Make a better documentation&lt;/li&gt; &#xA; &lt;li&gt;Kronecker product, like LoRA [https://arxiv.org/abs/2106.04647]&lt;/li&gt; &#xA; &lt;li&gt;Adaptor-guidance&lt;/li&gt; &#xA; &lt;li&gt;Time-aware fine-tuning.&lt;/li&gt; &#xA; &lt;li&gt;Test alpha scheduling. I think it will be meaningful.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>lencx/ChatGPT</title>
    <updated>2022-12-15T01:29:46Z</updated>
    <id>tag:github.com,2022-12-15:/lencx/ChatGPT</id>
    <link href="https://github.com/lencx/ChatGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🤖 ChatGPT Desktop Application (Mac, Windows and Linux)&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;180&#34; src=&#34;https://raw.githubusercontent.com/lencx/ChatGPT/main/public/logo.png&#34; alt=&#34;ChatGPT&#34;&gt; &lt;/p&gt;&#xA;&lt;h1 align=&#34;center&#34;&gt;ChatGPT&lt;/h1&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ChatGPT Desktop Application&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lencx/ChatGPT/main/README.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%E8%8B%B1%E6%96%87-English-blue&#34; alt=&#34;English badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/lencx/ChatGPT/main/README-ZH.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%E4%B8%AD%E6%96%87-Traditional%20Chinese-blue&#34; alt=&#34;中文版 badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lencx/ChatGPT/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/downloads/lencx/ChatGPT/total.svg?style=flat-square&#34; alt=&#34;ChatGPT downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/lencx_&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/lencx_.svg?style=social&#34; alt=&#34;lencx&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lencx/ChatGPT/main/AWESOME.md&#34;&gt;Awesome ChatGPT&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;📦 Downloads&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lencx/ChatGPT/main/UPDATE_LOG.md&#34;&gt;📝 Update Log&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- download start --&gt; &#xA;&lt;p&gt;&lt;strong&gt;Latest:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Mac&lt;/code&gt;: &lt;a href=&#34;https://github.com/lencx/ChatGPT/releases/download/v0.2.1/ChatGPT_0.2.1_x64.dmg&#34;&gt;ChatGPT_0.2.1_x64.dmg&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Linux&lt;/code&gt;: &lt;a href=&#34;https://github.com/lencx/ChatGPT/releases/download/v0.2.1/chat-gpt_0.2.1_amd64.deb&#34;&gt;chat-gpt_0.2.1_amd64.deb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Windows&lt;/code&gt;: &lt;a href=&#34;https://github.com/lencx/ChatGPT/releases/download/v0.2.1/ChatGPT_0.2.1_x64_en-US.msi&#34;&gt;ChatGPT_0.2.1_x64_en-US.msi&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/lencx/ChatGPT/releases&#34;&gt;Other version...&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- download end --&gt; &#xA;&lt;h3&gt;Install&lt;/h3&gt; &#xA;&lt;p&gt;Easily install with &lt;em&gt;&lt;a href=&#34;https://brew.sh&#34;&gt;Homebrew&lt;/a&gt; (&lt;a href=&#34;https://docs.brew.sh/Cask-Cookbook&#34;&gt;Cask&lt;/a&gt;):&lt;/em&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;brew tap lencx/chatgpt https://github.com/lencx/ChatGPT.git&#xA;brew install --cask chatgpt --no-quarantine&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Also, if you keep a &lt;em&gt;&lt;a href=&#34;https://github.com/Homebrew/homebrew-bundle#usage&#34;&gt;Brewfile&lt;/a&gt;&lt;/em&gt;, you can add something like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-rb&#34;&gt;repo = &#34;lencx/chatgpt&#34;&#xA;tap repo, &#34;https://github.com/#{repo}.git&#34;&#xA;cask &#34;popcorn-time&#34;, args: { &#34;no-quarantine&#34;: true }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;✨ Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Multi-platform: &lt;code&gt;macOS&lt;/code&gt; &lt;code&gt;Linux&lt;/code&gt; &lt;code&gt;Windows&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Export ChatGPT history (PNG, PDF and Share Link)&lt;/li&gt; &#xA; &lt;li&gt;Automatic application upgrade notification&lt;/li&gt; &#xA; &lt;li&gt;Common shortcut keys&lt;/li&gt; &#xA; &lt;li&gt;System tray hover window&lt;/li&gt; &#xA; &lt;li&gt;Powerful menu items&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;MenuItem&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Preferences&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;Theme&lt;/code&gt; - &lt;code&gt;Light&lt;/code&gt;, &lt;code&gt;Dark&lt;/code&gt; (Only macOS and Windows are supported).&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;Always on Top&lt;/code&gt;: The window is always on top of other windows.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;Titlebar&lt;/code&gt;: Whether to display the titlebar, supported by macOS only.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;User Agent&lt;/code&gt; (&lt;a href=&#34;https://github.com/lencx/ChatGPT/issues/17&#34;&gt;#17&lt;/a&gt;): Custom &lt;code&gt;user agent&lt;/code&gt;, which may be required in some scenarios. The default value is the empty string.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;Inject Script&lt;/code&gt;: Using scripts to modify pages.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;Switch Origin&lt;/code&gt; (&lt;a href=&#34;https://github.com/lencx/ChatGPT/issues/14&#34;&gt;#14&lt;/a&gt;): Switch the site source address, the default is &lt;code&gt;https://chat.openai.com&lt;/code&gt;, please make sure the mirror site UI is the same as the original address. Otherwise, some functions may not be available.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;Clear Config&lt;/code&gt;: Clear the configuration file (&lt;code&gt;path: ~/.chatgpt/*&lt;/code&gt;), dangerous operation, please backup the data in advance.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;Restart ChatGPT&lt;/code&gt;: Restart the application, for example: the program is stuck or the injection script can take effect by restarting the application after editing.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;Awesome ChatGPT&lt;/code&gt;: Recommended Related Resources.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Edit&lt;/strong&gt; - &lt;code&gt;Undo&lt;/code&gt;, &lt;code&gt;Redo&lt;/code&gt;, &lt;code&gt;Cut&lt;/code&gt;, &lt;code&gt;Copy&lt;/code&gt;, &lt;code&gt;SelectAll&lt;/code&gt;, ...&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;View&lt;/strong&gt; - &lt;code&gt;Go Back&lt;/code&gt;, &lt;code&gt;Go Forward&lt;/code&gt;, &lt;code&gt;Scroll to Top of Screen&lt;/code&gt;, &lt;code&gt;Scroll to Bottom of Screen&lt;/code&gt;, &lt;code&gt;Refresh the Screen&lt;/code&gt;, ...&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Help&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;Update Log&lt;/code&gt;: ChatGPT changelog.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;Report Bug&lt;/code&gt;: Report a bug or give feedback.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;Toggle Developer Tools&lt;/code&gt;: Developer debugging tools.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;TODO&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Web access capability (&lt;a href=&#34;https://github.com/lencx/ChatGPT/issues/20&#34;&gt;#20&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Shortcut command typing chatgpt prompt&lt;/li&gt; &#xA; &lt;li&gt;...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;👀 Preview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img width=&#34;320&#34; src=&#34;https://raw.githubusercontent.com/lencx/ChatGPT/main/assets/install.png&#34; alt=&#34;install&#34;&gt; &lt;img width=&#34;320&#34; src=&#34;https://raw.githubusercontent.com/lencx/ChatGPT/main/assets/chat.png&#34; alt=&#34;chat&#34;&gt; &lt;img width=&#34;320&#34; src=&#34;https://raw.githubusercontent.com/lencx/ChatGPT/main/assets/export.png&#34; alt=&#34;export&#34;&gt; &lt;img width=&#34;320&#34; src=&#34;https://raw.githubusercontent.com/lencx/ChatGPT/main/assets/tray.png&#34; alt=&#34;tray&#34;&gt; &lt;img width=&#34;320&#34; src=&#34;https://raw.githubusercontent.com/lencx/ChatGPT/main/assets/chat-ua.png&#34; alt=&#34;user agent&#34;&gt; &lt;img width=&#34;320&#34; src=&#34;https://raw.githubusercontent.com/lencx/ChatGPT/main/assets/auto-update.png&#34; alt=&#34;auto update&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/lencx&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cdn.buymeacoffee.com/buttons/v2/default-blue.png&#34; alt=&#34;Buy Me A Coffee&#34; style=&#34;height: 60px !important;width: 217px !important;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;❓FAQ&lt;/h2&gt; &#xA;&lt;h3&gt;Can&#39;t open ChatGPT&lt;/h3&gt; &#xA;&lt;p&gt;If you cannot open the application after the upgrade, please try to clear the configuration file, which is in the &lt;code&gt;~/.chatgpt/*&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;h3&gt;Is it safe?&lt;/h3&gt; &#xA;&lt;p&gt;It&#39;s safe, just a wrapper for &lt;a href=&#34;https://chat.openai.com&#34;&gt;OpenAI ChatGPT&lt;/a&gt; website, no other data transfer exists (you can check the source code).&lt;/p&gt; &#xA;&lt;h3&gt;Developer cannot be verified?&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://support.apple.com/en-sg/guide/mac-help/mh40616/mac&#34;&gt;Open a Mac app from an unidentified developer&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;How do i build it?&lt;/h3&gt; &#xA;&lt;h4&gt;PreInstall&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.rust-lang.org/&#34;&gt;Rust&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://code.visualstudio.com/&#34;&gt;VS Code&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=rust-lang.rust-analyzer&#34;&gt;rust-analyzer&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=tauri-apps.tauri-vscode&#34;&gt;tauri&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Start&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# step1:&#xA;git clone https://github.com/lencx/ChatGPT.git&#xA;&#xA;# step2:&#xA;cd ChatGPT&#xA;&#xA;# step3: install deps&#xA;yarn&#xA;&#xA;# step4:&#xA;yarn dev&#xA;&#xA;# step5:&#xA;# bundle path: src-tauri/target/release/bundle&#xA;yarn build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;❤️ Thanks&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The core implementation of the share button code was copied from the &lt;a href=&#34;https://github.com/liady&#34;&gt;@liady&lt;/a&gt; extension with some modifications.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#lencx/chatgpt&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=lencx/chatgpt&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Apache License&lt;/p&gt;</summary>
  </entry>
</feed>