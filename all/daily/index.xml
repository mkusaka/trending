<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-21T01:29:28Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>hiteshchoudhary/apihub</title>
    <updated>2023-07-21T01:29:28Z</updated>
    <id>tag:github.com,2023-07-21:/hiteshchoudhary/apihub</id>
    <link href="https://github.com/hiteshchoudhary/apihub" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Your own API Hub to learn and master API interaction. Ideal for frontend, mobile dev and backend developers.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FreeAPI.app&lt;/h1&gt; &#xA;&lt;h2&gt;Problem&lt;/h2&gt; &#xA;&lt;p&gt;We are trying to build a single source API hub that can be used to learn api handling in any programming language. Users can build their front end portfolio in web and mobile apps using this api hub.&lt;/p&gt; &#xA;&lt;h1&gt;What is FreeAPI.app&lt;/h1&gt; &#xA;&lt;p&gt;The FreeAPI project is an innovative and community-driven initiative aimed at providing developers with free and accessible APIs for their projects.&lt;/p&gt; &#xA;&lt;p&gt;The project focuses on delivering a wide range of APIs that cater to various domains and functionalities, enabling developers to seamlessly integrate these APIs into their applications.&lt;/p&gt; &#xA;&lt;p&gt;Key highlights of the FreeAPI project include:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Accessibility:&lt;/strong&gt; The FreeAPI project is committed to eliminating barriers by providing free access to its collection of APIs. Developers can leverage these APIs without any cost limitations, allowing them to experiment, learn, and build innovative applications.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Diverse API Collection:&lt;/strong&gt; The project offers a diverse and comprehensive collection of APIs that span across different industries, domains, and functionalities. Whether you require social media integrations, payment gateways, machine learning algorithms, or IoT device connectivity, the FreeAPI project has you covered.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Simplified Integration:&lt;/strong&gt; The FreeAPI project understands the challenges developers face when integrating APIs into their applications. To address this, the project provides clear documentation, code samples, and SDKs, simplifying the integration process and reducing development time and effort.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Community-Driven Development:&lt;/strong&gt; The project fosters a vibrant and collaborative community of developers. Contributors are encouraged to share their knowledge, engage in discussions, and collaborate on API-related projects. This collective effort ensures the continuous improvement and reliability of the APIs offered by the FreeAPI project.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Learning and Skill Development:&lt;/strong&gt; The FreeAPI project aims to empower developers by providing a platform for learning and skill development. Through access to various APIs and educational resources, developers can enhance their understanding of API integration, expand their knowledge, and showcase their expertise through building complete projects.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Overall, the FreeAPI project is a valuable resource for developers seeking accessible and diverse APIs.&lt;/p&gt; &#xA;&lt;p&gt;By fostering a supportive community, the project empowers developers to learn, create, and innovate, ultimately contributing to the growth and advancement of the API integration landscape.&lt;/p&gt; &#xA;&lt;h2&gt;Features:&lt;/h2&gt; &#xA;&lt;p&gt;Introducing our groundbreaking open source API hub project, a dynamic platform designed to revolutionize the way developers interact with APIs.&lt;/p&gt; &#xA;&lt;p&gt;With an emphasis on openness, accessibility, and learning, our API hub empowers developers of all levels to explore, experiment, and grow their skills in API integration.&lt;/p&gt; &#xA;&lt;p&gt;Highlights:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Open Source:&lt;/strong&gt; Our API hub is built on the principles of open source, ensuring transparency, collaboration, and community-driven development. This means that the source code is freely available, allowing developers to customize, extend, and contribute to the project.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Free to Use:&lt;/strong&gt; We firmly believe in removing barriers to entry, which is why our API hub is completely free to use. Whether you&#39;re a seasoned developer or just starting your coding journey, you can leverage our platform without any cost limitations.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Local or Deployment&lt;/strong&gt;: Flexibility is at the core of our API hub. You have the option to use it locally, running on your own machine, or deploy it to a server, making it accessible to others. This versatility ensures that you can adapt the platform to your specific development environment.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Learning Resource&lt;/strong&gt;: Our API hub is designed as a comprehensive learning resource, offering a wealth of educational materials, tutorials, and documentation. Whether you&#39;re a beginner or seeking to expand your API knowledge, our platform provides the resources you need to learn and improve.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Custom Endpoints for Beginners&lt;/strong&gt;: For developers at the beginner level, our API hub offers custom endpoints that provide a hands-on experience in handling API responses. These beginner-friendly APIs allow you to practice and familiarize yourself with the basics of working with APIs.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced APIs for Portfolio Building&lt;/strong&gt;: In addition to beginner-level endpoints, our API hub also provides advanced APIs to challenge and stretch your skills. These APIs enable you to tackle more complex integration scenarios, helping you build a robust portfolio of projects to showcase your expertise.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;By combining open source principles, accessibility, and a focus on learning, our API hub project paves the way for developers to thrive in the world of API integration. Join our vibrant community and embark on an exciting journey of discovery, growth, and innovation.&lt;/p&gt; &#xA;&lt;h3&gt;How to contribute - Guidelines&lt;/h3&gt; &#xA;&lt;p&gt;We welcome your interest in contributing to our open source project!&lt;/p&gt; &#xA;&lt;p&gt;To contribute to FreeAPI, please follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Fork the repository.&lt;/li&gt; &#xA; &lt;li&gt;Create a new branch for your feature or bug fix: &lt;code&gt;git checkout -b feat/your-feature-name&lt;/code&gt; or &lt;code&gt;git checkout -b fix/your-bug-fix-name&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Make your changes and commit them with descriptive messages: &lt;code&gt;git commit -am &#39;Add your commit message&#39;&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Push your changes to your forked repository: &lt;code&gt;git push origin feat/your-feature-name&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Submit a pull request to the main repository, explaining the changes you&#39;ve made and providing any necessary details.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Here&#39;s a guide on how you can effectively contribute to our API hub:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Pull Requests for Readme Updates: Please refrain from sending pull requests solely for updating the project&#39;s readme file. While we appreciate the importance of clear and concise documentation, we prefer to focus on substantial code contributions and feature enhancements.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Grammar Updates: Our team values effective communication, but we&#39;re not grammar sticklers. You don&#39;t need to send pull requests solely for grammar fixes or minor language improvements. Instead, concentrate on the core functionalities and features of the project.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Avoid Updating Existing Public APIs: To maintain stability and consistency, we discourage direct updates to existing public APIs within the API hub. These APIs have been thoroughly tested and approved. However, if you encounter any bugs or issues, we encourage you to open an issue on our project&#39;s issue tracker to notify us.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Build New Project APIs: We encourage you to explore your creativity and contribute by building complete project APIs. These APIs should provide comprehensive solutions that can assist developers in constructing complex projects to showcase their skills and abilities. Your contributions in this area will greatly benefit the community.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Draft a Proposal and Discuss on Discord: Before diving into your project, we recommend drafting a proposal. This can include a mind map or outline of the API you intend to build and its potential benefits. Join our Discord community, where you can share your proposal, discuss ideas, and gather feedback from fellow contributors. Engaging in these discussions will enhance your backend portfolio and help shape the future direction of the project.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;We appreciate your enthusiasm and look forward to your valuable contributions to our open source API hub project.&lt;/p&gt; &#xA;&lt;p&gt;Together, we can foster a collaborative environment and make a significant impact in the API integration landscape.&lt;/p&gt; &#xA;&lt;p&gt;Click &lt;a href=&#34;https://github.com/hiteshchoudhary/apihub/raw/dev/CONTRIBUTING.md&#34;&gt;here&lt;/a&gt; for detailed contribution guide.&lt;/p&gt; &#xA;&lt;h2&gt;üèÅ Installation&lt;/h2&gt; &#xA;&lt;h3&gt;üì¶ Using Docker (recommended)&lt;/h3&gt; &#xA;&lt;p&gt;To run the FreeAPI project, follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt; on your machine.&lt;/li&gt; &#xA; &lt;li&gt;Clone the project repository.&lt;/li&gt; &#xA; &lt;li&gt;Navigate to the project directory.&lt;/li&gt; &#xA; &lt;li&gt;Create &lt;code&gt;.env&lt;/code&gt; file in the root folder and copy paste the content of &lt;code&gt;.env.sample&lt;/code&gt;, and add necessary credentials.&lt;/li&gt; &#xA; &lt;li&gt;Run the Docker Compose command:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose up --build --attach backend&#xA;&#xA;# --build: Rebuild the image and run the containers&#xA;# --attach: only show logs of Node app container and not mongodb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;Access the project APIs at the specified endpoints.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;üíª Running locally&lt;/h3&gt; &#xA;&lt;p&gt;To run the FreeAPI project locally, follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://yarnpkg.com/&#34;&gt;Yarn&lt;/a&gt;, &lt;a href=&#34;https://www.nodejs.org/&#34;&gt;NodeJs&lt;/a&gt;, &lt;a href=&#34;https://www.mongodb.com&#34;&gt;MongoDB&lt;/a&gt; and &lt;a href=&#34;https://www.mongodb.com/products/compass&#34;&gt;MongoDB Compass (optional)&lt;/a&gt; on your machine.&lt;/li&gt; &#xA; &lt;li&gt;Clone the project repository.&lt;/li&gt; &#xA; &lt;li&gt;Navigate to the project directory.&lt;/li&gt; &#xA; &lt;li&gt;Create &lt;code&gt;.env&lt;/code&gt; file in the root folder and copy paste the content of &lt;code&gt;.env.sample&lt;/code&gt;, and add necessary credentials.&lt;/li&gt; &#xA; &lt;li&gt;Install the packages:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yarn install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;6&#34;&gt; &#xA; &lt;li&gt;Run the project:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yarn start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;7&#34;&gt; &#xA; &lt;li&gt;Access the project APIs at the specified endpoints.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;üöÑ Using Railway (One-click Deploy)&lt;/h3&gt; &#xA;&lt;p&gt;To self-host the FreeAPI.app application, you can take advantage of a pre-built template that is readily available.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://railway.app/template/B2f7Hq&#34;&gt;&lt;img src=&#34;https://railway.app/button.svg?sanitize=true&#34; alt=&#34;Deploy FreeAPI.app&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Click the button above to visit railway.app.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Click on the &lt;strong&gt;Deploy Now&lt;/strong&gt; button.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;(Optional) Sign in with GitHub to deploy.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Fill in the Repository details:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Specify the repo name (e.g., freeapi-app).&lt;/li&gt; &#xA;   &lt;li&gt;Checkmark for Public/Private repository.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For Environment variables, we have provided some default values in the &lt;code&gt;ENV&lt;/code&gt; to reduce the burden, but some parameters are mandatory:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;PORT&lt;/code&gt;: Do not change the value, let it be set to 8080 to view the swagger docs after deployment.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;MONGODB_URI&lt;/code&gt;: Provide the MongoDB Atlas database URL. An example is prefilled for you, edit/update it to continue.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;NODE_ENV&lt;/code&gt;: Default set to &#39;development&#39; to view the logs. You may choose to change it to any other value such as &#39;prod&#39; to hide them.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;EXPRESS_SESSION_SECRET&lt;/code&gt;: It is advised to change the default value to your own secret value.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;ACCESS_TOKEN_SECRET&lt;/code&gt;: It is advised to change the default value to your own secret value.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;ACCESS_TOKEN_EXPIRY&lt;/code&gt;: Set to 1 day as default.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;REFRESH_TOKEN_SECRET&lt;/code&gt;: It is advised to change the default value to your own secret value.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;REFRESH_TOKEN_EXPIRY&lt;/code&gt;: Set to 10 days as default.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Once you fill in the required environment parameters, if you choose to add others such as PayPal, Google, and Razorpay, please proceed to mention your credentials in the form.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Click on the &lt;strong&gt;Deploy&lt;/strong&gt; button to trigger the first build.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Monitor the server logs; if you come across any deployment problems, feel free to raise an issue for our team to look into.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Note: Once the application is deployed, please wait for 3-5 minutes for the swagger docs to be available.&lt;/p&gt; &#xA;&lt;h1&gt;üìú Swagger Docs&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://localhost:8080&#34;&gt;Swagger Docs&lt;/a&gt;: &lt;a href=&#34;http://localhost:8080&#34;&gt;http://localhost:8080&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>facebookresearch/llama-recipes</title>
    <updated>2023-07-21T01:29:28Z</updated>
    <id>tag:github.com,2023-07-21:/facebookresearch/llama-recipes</id>
    <link href="https://github.com/facebookresearch/llama-recipes" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Examples and recipes for Llama 2 model&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Llama 2 Fine-tuning / Inference Recipes and Examples&lt;/h1&gt; &#xA;&lt;p&gt;The &#39;llama-recipes&#39; repository is a companion to the &lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;Llama 2 model&lt;/a&gt;. The goal of this repository is to provide examples to quickly get started with fine-tuning for domain adaptation and how to run inference for the fine-tuned models. For ease of use, the examples use Hugging Face converted versions of the models. See steps for conversion of the model &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/#model-conversion-to-hugging-face&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Llama 2 is a new technology that carries potential risks with use. Testing conducted to date has not ‚Äî and could not ‚Äî cover all scenarios. In order to help developers address these risks, we have created the &lt;a href=&#34;https://github.com/facebookresearch/llama/raw/main/Responsible-Use-Guide.pdf&#34;&gt;Responsible Use Guide&lt;/a&gt;. More details can be found in our research paper as well. For downloading the models, follow the instructions on &lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;Llama 2 repo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Table of Contents&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/#quick-start&#34;&gt;Quick start&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/#fine-tuning&#34;&gt;Fine-tuning&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/#single-gpu&#34;&gt;Single GPU&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/#multiple-gpus-one-node&#34;&gt;Multi GPU One Node&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/#multi-gpu-multi-node&#34;&gt;Multi GPU Multi Node&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/docs/inference.md&#34;&gt;Inference&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/#model-conversion-to-hugging-face&#34;&gt;Model Conversion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/#repository-organization&#34;&gt;Repository Organization&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/#license&#34;&gt;License and Acceptable Use Policy&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Quick Start&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/quickstart.ipynb&#34;&gt;Llama 2 Jupyter Notebook&lt;/a&gt;: This jupyter notebook steps you through how to finetune a Llama 2 model on the text summarization task using the &lt;a href=&#34;https://huggingface.co/datasets/samsum&#34;&gt;samsum&lt;/a&gt;. The notebook uses parameter efficient finetuning (PEFT) and int8 quantization to finetune a 7B on a single GPU like an A10 with 24GB gpu memory.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; All the setting defined in &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/configs/&#34;&gt;config files&lt;/a&gt; can be passed as args through CLI when running the script, there is no need to change from config files directly.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; In case need to run PEFT model with FSDP, please make sure to use the PyTorch Nightlies.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;For more in depth information checkout the following:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/docs/single_gpu.md&#34;&gt;Single GPU Fine-tuning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/docs/mutli_gpu.md&#34;&gt;Multi-GPU Fine-tuning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/docs/LLM_finetuning.md&#34;&gt;LLM Fine-tuning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/docs/Dataset.md&#34;&gt;Adding custom datasets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/docs/inference.md&#34;&gt;Inference&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/docs/FAQ.md&#34;&gt;FAQs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;To run the examples, make sure to install the requirements using&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&#xA;pip install -r requirements.txt&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please note that the above requirements.txt will install PyTorch 2.0.1 version, in case you want to run FSDP + PEFT, please make sure to install PyTorch nightlies.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Fine-tuning&lt;/h1&gt; &#xA;&lt;p&gt;For fine-tuning Llama 2 models for your domain-specific use cases recipes for PEFT, FSDP, PEFT+FSDP have been included along with a few test datasets. For details see &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/docs/LLM_finetuning.md&#34;&gt;LLM Fine-tuning&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Single and Multi GPU Finetune&lt;/h2&gt; &#xA;&lt;p&gt;If you want to dive right into single or multi GPU fine-tuning, run the examples below on a single GPU like A10, T4, V100, A100 etc. All the parameters in the examples and recipes below need to be further tuned to have desired results based on the model, method, data and task at hand.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;To change the dataset in the commands below pass the &lt;code&gt;dataset&lt;/code&gt; arg. Current options for dataset are &lt;code&gt;grammar_dataset&lt;/code&gt;, &lt;code&gt;alpaca_dataset&lt;/code&gt;and &lt;code&gt;samsum_dataset&lt;/code&gt;. A description of the datasets and how to add custom datasets can be found in &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/docs/Dataset.md&#34;&gt;Dataset.md&lt;/a&gt;. For &lt;code&gt;grammar_dataset&lt;/code&gt;, &lt;code&gt;alpaca_dataset&lt;/code&gt; please make sure you use the suggested instructions from &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/docs/single_gpu.md#how-to-run-with-different-datasets&#34;&gt;here&lt;/a&gt; to set them up.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Default dataset and other LORA config has been set to &lt;code&gt;samsum_dataset&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Make sure to set the right path to the model in the &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/configs/training.py&#34;&gt;training config&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Single GPU:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#if running on multi-gpu machine&#xA;export CUDA_VISIBLE_DEVICES=0&#xA;&#xA;python llama_finetuning.py  --use_peft --peft_method lora --quantization --model_name /patht_of_model_folder/7B --output_dir Path/to/save/PEFT/model&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here we make use of Parameter Efficient Methods (PEFT) as described in the next section. To run the command above make sure to pass the &lt;code&gt;peft_method&lt;/code&gt; arg which can be set to &lt;code&gt;lora&lt;/code&gt;, &lt;code&gt;llama_adapter&lt;/code&gt; or &lt;code&gt;prefix&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; if you are running on a machine with multiple GPUs please make sure to only make one of them visible using &lt;code&gt;export CUDA_VISIBLE_DEVICES=GPU:id&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Make sure you set &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/configs/training.py&#34;&gt;save_model&lt;/a&gt; in &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/configs/training.py&#34;&gt;training.py&lt;/a&gt; to save the model. Be sure to check the other training settings in &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/configs/training.py&#34;&gt;train config&lt;/a&gt; as well as others in the config folder as needed or they can be passed as args to the training script as well.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Multiple GPUs One Node:&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; please make sure to use PyTorch Nightlies for using PEFT+FSDP. Also, note that int8 quantization from bit&amp;amp;bytes currently is not supported in FSDP.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&#xA;torchrun --nnodes 1 --nproc_per_node 4  llama_finetuning.py --enable_fsdp --use_peft --peft_method lora --model_name /patht_of_model_folder/7B --pure_bf16 --output_dir Path/to/save/PEFT/model&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here we use FSDP as discussed in the next section which can be used along with PEFT methods. To make use of PEFT methods with FSDP make sure to pass &lt;code&gt;use_peft&lt;/code&gt; and &lt;code&gt;peft_method&lt;/code&gt; args along with &lt;code&gt;enable_fsdp&lt;/code&gt;. Here we are using &lt;code&gt;BF16&lt;/code&gt; for training.&lt;/p&gt; &#xA;&lt;h3&gt;Fine-tuning using FSDP Only&lt;/h3&gt; &#xA;&lt;p&gt;If you are interested in running full parameter fine-tuning without making use of PEFT methods, please use the following command. Make sure to change the &lt;code&gt;nproc_per_node&lt;/code&gt; to your available GPUs. This has been tested with &lt;code&gt;BF16&lt;/code&gt; on 8xA100, 40GB GPUs.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&#xA;torchrun --nnodes 1 --nproc_per_node 8  llama_finetuning.py --enable_fsdp --model_name /patht_of_model_folder/7B --dist_checkpoint_root_folder model_checkpoints --dist_checkpoint_folder fine-tuned&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Multi GPU Multi Node:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&#xA;sbatch multi_node.slurm&#xA;# Change the num nodes and GPU per nodes in the script before running.&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can read more about our fine-tuning strategies &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/docs/LLM_finetuning.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Model conversion to Hugging Face&lt;/h1&gt; &#xA;&lt;p&gt;The recipes and notebooks in this folder are using the Llama 2 model definition provided by Hugging Face&#39;s transformers library.&lt;/p&gt; &#xA;&lt;p&gt;Given that the original checkpoint resides under models/7B you can install all requirements and convert the checkpoint with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;## Install HuggingFace Transformers from source&#xA;pip install git+https://github.com/huggingface/transformers&#xA;cd transformers&#xA;&#xA;python src/transformers/models/llama/convert_llama_weights_to_hf.py \&#xA;    --input_dir /path/to/downloaded/llama/weights --model_size 7B --output_dir models_hf/7B&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Repository Organization&lt;/h1&gt; &#xA;&lt;p&gt;This repository is organized in the following way:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/configs/&#34;&gt;configs&lt;/a&gt;: Contains the configuration files for PEFT methods, FSDP, Datasets.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/docs/&#34;&gt;docs&lt;/a&gt;: Example recipes for single and multi-gpu fine-tuning recipes.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/ft_datasets/&#34;&gt;ft_datasets&lt;/a&gt;: Contains individual scripts for each dataset to download and process. Note: Use of any of the datasets should be in compliance with the dataset&#39;s underlying licenses (including but not limited to non-commercial uses)&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/inference/&#34;&gt;inference&lt;/a&gt;: Includes examples for inference for the fine-tuned models and how to use them safely.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/model_checkpointing/&#34;&gt;model_checkpointing&lt;/a&gt;: Contains FSDP checkpoint handlers.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/policies/&#34;&gt;policies&lt;/a&gt;: Contains FSDP scripts to provide different policies, such as mixed precision, transformer wrapping policy and activation checkpointing along with any precision optimizer (used for running FSDP with pure bf16 mode).&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/utils/&#34;&gt;utils&lt;/a&gt;: Utility files for:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;train_utils.py&lt;/code&gt; provides training/eval loop and more train utils.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;dataset_utils.py&lt;/code&gt; to get preprocessed datasets.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;config_utils.py&lt;/code&gt; to override the configs received from CLI.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;fsdp_utils.py&lt;/code&gt; provides FSDP wrapping policy for PEFT methods.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;memory_utils.py&lt;/code&gt; context manager to track different memory stats in train loop.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;See the License file &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/LICENSE&#34;&gt;here&lt;/a&gt; and Acceptable Use Policy &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/llama-recipes/main/USE_POLICY.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>RayVentura/ShortGPT</title>
    <updated>2023-07-21T01:29:28Z</updated>
    <id>tag:github.com,2023-07-21:/RayVentura/ShortGPT</id>
    <link href="https://github.com/RayVentura/ShortGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üöÄüé¨ ShortGPT - An experimental AI framework for automated short/video content creation. Enables creators to rapidly produce, manage, and deliver content using AI and automation.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üöÄüé¨ ShortGPT&lt;/h1&gt; &#xA;&lt;!-- [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/uERx39ru3R&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/uERx39ru3R?compact=true&amp;amp;style=flat&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/RayVenturaHQ&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url/https/twitter.com/rayventurahq.svg?style=social&amp;amp;label=Follow%20%40RayVentura&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://star-history.com/#rayventura/shortgpt&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/rayventura/shortgpt?style=social&#34; alt=&#34;GitHub star chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/RayVentura/ShortGPT/assets/121462835/083c8dc3-bac5-42c1-a08d-3ff9686d18c5&#34; alt=&#34;ShortGPT-logo&#34; style=&#34;border-radius: 20px;&#34; width=&#34;22%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;!--![android-chrome-192x192](https://github.com/RayVentura/ShortGPT/assets/121462835/083c8dc3-bac5-42c1-a08d-3ff9686d18c5) --&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://discord.gg/uERx39ru3R&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/discord-join%20chat-blue.svg?sanitize=true&#34; alt=&#34;Join our Discord&#34; height=&#34;34&#34;&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA;  ‚ö° Automating video and short content creation with AI ‚ö° &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;üé• Showcase (&lt;a href=&#34;https://youtu.be/hpoSHq-ER8U&#34;&gt;Full video on YouTube&lt;/a&gt;)&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/RayVentura/ShortGPT/assets/121462835/a802faad-0fd7-4fcb-aa82-6365c27ea5fe&#34;&gt;https://github.com/RayVentura/ShortGPT/assets/121462835/a802faad-0fd7-4fcb-aa82-6365c27ea5fe&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üìù Introduction to ShortGPT&lt;/h2&gt; &#xA;&lt;p&gt;ShortGPT is a powerful framework for automating content creation. It simplifies video creation, footage sourcing, voiceover synthesis, and editing tasks.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;üéûÔ∏è &lt;strong&gt;Automated editing framework&lt;/strong&gt;: Streamlines the video creation process with an LLM oriented video editing language.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üìÉ &lt;strong&gt;Scripts and Prompts&lt;/strong&gt;: Provides ready-to-use scripts and prompts for various LLM automated editing processes.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üó£Ô∏è &lt;strong&gt;Voiceover / Content Creation&lt;/strong&gt;: Supports multiple languages including English üá∫üá∏, Spanish üá™üá∏, Arabic üá¶üá™, French üá´üá∑, Polish üáµüá±, German üá©üá™, Italian üáÆüáπ, and Portuguese üáµüáπ.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üîó &lt;strong&gt;Caption Generation&lt;/strong&gt;: Automates the generation of video captions.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üåêüé• &lt;strong&gt;Asset Sourcing&lt;/strong&gt;: Sources images and video footage from the internet, connecting with the web and Pexels API as necessary.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üß† &lt;strong&gt;Memory and persistency&lt;/strong&gt;: Ensures long-term persistency of automated editing variables with TinyDB.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üõ†Ô∏è How it works&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/RayVentura/ShortGPT/assets/121462835/fcee74d4-f856-4481-949f-244558bf3bfa&#34; alt=&#34;alt text&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Quick Start: Run ShortGPT on Google Colab (&lt;a href=&#34;https://colab.research.google.com/drive/1_2UKdpF6lqxCqWaAcZb3rwMVQqtbisdE?usp=sharing&#34;&gt;https://colab.research.google.com/drive/1_2UKdpF6lqxCqWaAcZb3rwMVQqtbisdE?usp=sharing&lt;/a&gt;)&lt;/h2&gt; &#xA;&lt;p&gt;If you prefer not to install the prerequisites on your local system, you can use the Google Colab notebook. This option is free and requires no installation setup.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Click on the link to the Google Colab notebook: &lt;a href=&#34;https://colab.research.google.com/drive/1_2UKdpF6lqxCqWaAcZb3rwMVQqtbisdE?usp=sharing&#34;&gt;https://colab.research.google.com/drive/1_2UKdpF6lqxCqWaAcZb3rwMVQqtbisdE?usp=sharing&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Once you&#39;re in the notebook, simply run the cells in order from top to bottom. You can do this by clicking on each cell and pressing the &#39;Play&#39; button, or by using the keyboard . Enjoy using ShortGPT!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;üåü Show Your Support&lt;/h2&gt; &#xA;&lt;p&gt;We hope you find ShortGPT helpful! If you do, let us know by giving us a star ‚≠ê on the repo. It&#39;s easy, just click on the &#39;Star&#39; button at the top right of the page. Your support means a lot to us and keeps us motivated to improve and expand ShortGPT. Thank you and happy content creating! üéâ&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/RayVentura/ShortGPT/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/rayventura/shortgpt?style=social&#34; alt=&#34;GitHub star chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Instructions for running shortGPT&lt;/h1&gt; &#xA;&lt;p&gt;This guide provides step-by-step instructions for installing ImageMagick and FFmpeg on your system, which are both required to do automated editing. Once installed, you can proceed to run &lt;code&gt;runShortGPT.py&lt;/code&gt; successfully.&lt;/p&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;Before you begin, ensure that you have the following prerequisites installed on your system:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.x&lt;/li&gt; &#xA; &lt;li&gt;Pip (Python package installer)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation Steps&lt;/h2&gt; &#xA;&lt;p&gt;Follow the instructions below to install ImageMagick, FFmpeg, and clone the shortGPT repository:&lt;/p&gt; &#xA;&lt;h3&gt;Step 1: Install ImageMagick&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;For &lt;code&gt;Windows&lt;/code&gt; download the installer from the official ImageMagick website and follow the installation instructions.&lt;/p&gt; &lt;p&gt;&lt;a href=&#34;https://imagemagick.org/script/download.php&#34;&gt;https://imagemagick.org/script/download.php&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For Ubuntu/Debian-based systems, use the command:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo apt-get install imagemagick&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then run the following command to fix a moviepy Imagemagick policy.xml incompatibility problem:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;!sed -i &#39;/&amp;lt;policy domain=&#34;path&#34; rights=&#34;none&#34; pattern=&#34;@\*&#34;/d&#39; /etc/ImageMagick-6/policy.xml&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For macOS using Homebrew, use the command:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;brew install imagemagick&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Verify the installation by running the following command:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;convert --version&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You should see the ImageMagick version information if the installation was successful.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Step 2: Install FFmpeg (REQUIRED FOR SHORTGPT TO WORK)&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;For &lt;code&gt;Windows&lt;/code&gt;Download the FFmpeg binaries from this Windows Installer (It will download ffmpeg, ffprobe and add it to your path).&lt;/p&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/icedterminal/ffmpeg-installer/releases/tag/6.0.0.20230306&#34;&gt;https://github.com/icedterminal/ffmpeg-installer/releases/tag/6.0.0.20230306&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For macOS using Homebrew, use the command:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;brew install ffmpeg&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For Ubuntu/Debian-based systems, use the command:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo apt-get install ffmpeg&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Verify the installation by running the following command:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ffmpeg -version&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You should see the FFmpeg version information if the installation was successful.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Step 3: Clone the shortGPT Repository&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open a terminal or command prompt.&lt;/li&gt; &#xA; &lt;li&gt;Execute the following command to clone the shortGPT repository: &lt;pre&gt;&lt;code&gt;git clone https://github.com/rayventura/shortgpt.git&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Step 4: Install Python Dependencies&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Open a terminal or command prompt.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Navigate to the directory where &lt;code&gt;runShortGPT.py&lt;/code&gt; is located (the cloned repo).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Execute the following command to install the required Python dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This command will install the necessary packages specified in the &lt;code&gt;requirements.txt&lt;/code&gt; file.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Running runShortGPT.py Web Interface&lt;/h2&gt; &#xA;&lt;p&gt;Once you have successfully installed ImageMagick, FFmpeg, and the Python dependencies, you can run &lt;code&gt;runShortGPT.py&lt;/code&gt; by following these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open a terminal or command prompt.&lt;/li&gt; &#xA; &lt;li&gt;Navigate to the directory where &lt;code&gt;runShortGPT.py&lt;/code&gt; is located (the cloned repo).&lt;/li&gt; &#xA; &lt;li&gt;Execute the following command to run the script: &lt;pre&gt;&lt;code&gt;python runShortGPT.py&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;After running the script, a Gradio interface should open at your local host on port 31415 (&lt;a href=&#34;http://localhost:31415&#34;&gt;http://localhost:31415&lt;/a&gt;).&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Putting API Keys&lt;/h2&gt; &#xA;&lt;p&gt;The ShortGPT UI needs you to input at least OpenAI and ElevenLabs api keys for running short automations. For video automations, you will also need to add a Pexels API.&lt;/p&gt; &#xA;&lt;p&gt;Follow these steps to add your OpenAI and ElevenLabs API keys:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open &lt;a href=&#34;http://localhost:31415/?__theme=light&#34;&gt;http://localhost:31415/?__theme=light&lt;/a&gt; from a web browser.&lt;/li&gt; &#xA; &lt;li&gt;Click on the &lt;code&gt;config&lt;/code&gt; tab located at the left side bar of the user interface.&lt;/li&gt; &#xA; &lt;li&gt;Add your &lt;code&gt;OPENAI API KEY&lt;/code&gt; and &lt;code&gt;ELEVENLABS API KEY&lt;/code&gt; in the corresponding input fields.&lt;/li&gt; &#xA; &lt;li&gt;Click &lt;code&gt;Save&lt;/code&gt; to save your API keys.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;That&#39;s it! You have successfully set up your API keys and can now utilize the functionality of ShortGPT in the Gradio interface.&lt;/p&gt; &#xA;&lt;h2&gt;üíÅ Contributing&lt;/h2&gt; &#xA;&lt;p&gt;As an open-source project in a rapidly developing field, we are extremely open to contributions, whether it be in the form of a new feature, improved infrastructure, or better documentation.&lt;/p&gt; &#xA;&lt;h2&gt;Framework overview&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;üé¨ The &lt;code&gt;ContentShortEngine&lt;/code&gt; is designed for creating shorts, handling tasks from script generation to final rendering, including adding YouTube metadata.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üé• The &lt;code&gt;ContentVideoEngine&lt;/code&gt; is ideal for longer videos, taking care of tasks like generating audio, automatically sourcing background video footage, timing captions, and preparing background assets.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;üéûÔ∏è The automated &lt;code&gt;EditingEngine&lt;/code&gt;, using Editing Markup Language and JSON, breaks down the editing process into manageable and customizable blocks, comprehensible to Large Language Models.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;üí° ShortGPT offers customization options to suit your needs, from language selection to watermark addition.&lt;/p&gt; &#xA;&lt;p&gt;üîß As a framework, ShortGPT is adaptable and flexible, offering the potential for efficient, creative content creation.&lt;/p&gt; &#xA;&lt;p&gt;More documentation incomming, please be patient.&lt;/p&gt; &#xA;&lt;h2&gt;Technologies Used&lt;/h2&gt; &#xA;&lt;p&gt;ShortGPT utilizes the following technologies to power its functionality:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Moviepy&lt;/strong&gt;: Moviepy is used for video editing, allowing ShortGPT to make video editing and rendering&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Openai&lt;/strong&gt;: Openai is used for automating the entire process, including generating scripts and prompts for LLM automated editing processes.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;ElevenLabs&lt;/strong&gt;: ElevenLabs is used for voice synthesis, supporting multiple languages for voiceover creation.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Pexels&lt;/strong&gt;: Pexels is used for sourcing background footage, allowing ShortGPT to connect with the web and access a wide range of images and videos.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bing Image&lt;/strong&gt;: Bing Image is used for sourcing images, providing a comprehensive database for ShortGPT to retrieve relevant visuals.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;These technologies work together to provide a seamless and efficient experience in automating video and short content creation with AI.&lt;/p&gt; &#xA;&lt;h2&gt;üîó Get in touch on Twitter üê¶&lt;/h2&gt; &#xA;&lt;p&gt;Keep up with the latest happenings, announcements, and insights about Short-GPT by checking out our Twitter accounts. Spark a conversation with our developer and the AI&#39;s own account for fascinating dialogues, latest news about the project, and more.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Developer&lt;/strong&gt;: Stay updated &lt;a href=&#34;https://twitter.com/RayVenturaHQ&#34;&gt;@RayVentura&lt;/a&gt;. Deep-dive into behind-the-scenes, project news, and related topics from the person behind ShortGPT.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We&#39;re eager to interact with you and listen to your feedback, concepts, and experiences with Short-GPT. Come on board on Twitter and let&#39;s navigate the future of AI as a team! üí°ü§ñ&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://star-history.com/#RayVentura/ShortGPT&amp;amp;Date&#34;&gt; &lt;img src=&#34;https://api.star-history.com/svg?repos=RayVentura/ShortGPT&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt; &lt;/a&gt; &lt;/p&gt;</summary>
  </entry>
</feed>