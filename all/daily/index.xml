<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-22T01:29:00Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>gannonh/gpt3.5-turbo-pgvector</title>
    <updated>2023-03-22T01:29:00Z</updated>
    <id>tag:github.com,2023-03-22:/gannonh/gpt3.5-turbo-pgvector</id>
    <link href="https://github.com/gannonh/gpt3.5-turbo-pgvector" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ChatGTP (gpt3.5-turbo) starter app&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Domain-specific ChatGTP (gpt-3.5-turbo) Starter App&lt;/h1&gt; &#xA;&lt;p&gt;⚠️ UPDATE: Now uses the new &#34;ChatGPT API&#34; (model gpt-3.5-turbo). More on the new API: &lt;a href=&#34;https://platform.openai.com/docs/guides/chat&#34;&gt;https://platform.openai.com/docs/guides/chat&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Use this starter app to build your own ChatGPT style app trained on specific websites that you define. Live demo: &lt;a href=&#34;https://astro-labs.app/docs&#34;&gt;https://astro-labs.app/docs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;ChatGPT is great for casual, general-purpose question-answers but falls short when domain-specific knowledge is needed. Further, it makes up answers to fill its knowledge gaps and never cites its sources, so it can&#39;t really be trusted. This starter app uses embeddings coupled with vector search to solve this, or more specifically, to show how OpenAI&#39;s GPT-3 API can be used to create a conversational interfaces to domain-specific knowledge.&lt;/p&gt; &#xA;&lt;p&gt;Embeddings, as represented by vectors of floating-point numbers, measure the &#34;relatedness&#34; of text strings. These are super useful for ranking search results, clustering, classification, etc. Relatedness is measured by cosine similarity. If the cosine similarity between two vectors is close to 1, the vectors are highly similar and point in the same direction. In the case of text embeddings, a high cosine similarity between two embedding vectors indicates that the corresponding text strings are highly related.&lt;/p&gt; &#xA;&lt;p&gt;This starter app uses embeddings to generate a vector representation of a document, and then uses vector search to find the most similar documents to the query. The results of the vector search are then used to construct a prompt for GPT-3, which is then used to generate a response. The response is then streamed to the user. Check out the Supabase blog posts on &lt;a href=&#34;https://supabase.com/blog/openai-embeddings-postgres-vector&#34;&gt;pgvector and OpenAI embeddings&lt;/a&gt; for more background.&lt;/p&gt; &#xA;&lt;p&gt;Technologies used:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Nextjs (React framework) + Vercel hosting&lt;/li&gt; &#xA; &lt;li&gt;Supabase (using their pgvector implementation as the vector database)&lt;/li&gt; &#xA; &lt;li&gt;OpenAI API (for generating embeddings and GPT-3 responses)&lt;/li&gt; &#xA; &lt;li&gt;TailwindCSS (for styling)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Functional Overview&lt;/h2&gt; &#xA;&lt;p&gt;Creating and storing the embeddings:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Web pages are scraped, stripped to plain text and split into 1000-character documents&lt;/li&gt; &#xA; &lt;li&gt;OpenAI&#39;s embedding API is used to generate embeddings for each document using the &#34;text-embedding-ada-002&#34; model&lt;/li&gt; &#xA; &lt;li&gt;The embeddings are then stored in a Supabase postgres table using pgvector; the table has three columns: the document text, the source URL, and the embedding vectors returned from the OpenAI API.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Responding to queries:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A single embedding is generated from the user prompt&lt;/li&gt; &#xA; &lt;li&gt;That embedding is used to perform a similarity search against the vector database&lt;/li&gt; &#xA; &lt;li&gt;The results of the similarity search are used to construct a prompt for GPT-3&lt;/li&gt; &#xA; &lt;li&gt;The GTP-3 response is then streamed to the user.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;The following set-up guide assumes at least basic familiarity developing web apps with React and Nextjs. Experience with OpenAI APIs and Supabase is helpful but not required to get things working.&lt;/p&gt; &#xA;&lt;h3&gt;Set-up Supabase&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a Supabase account and project at &lt;a href=&#34;https://app.supabase.com/sign-in&#34;&gt;https://app.supabase.com/sign-in&lt;/a&gt;. NOTE: Supabase support for pgvector is relatively new (02/2023), so it&#39;s important to create a new project if your project was created before then.&lt;/li&gt; &#xA; &lt;li&gt;First we&#39;ll enable the Vector extension. In Supabase, this can be done from the web portal through &lt;code&gt;Database&lt;/code&gt; → &lt;code&gt;Extensions&lt;/code&gt;. You can also do this in SQL by running:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;create extension vector;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Next let&#39;s create a table to store our documents and their embeddings. Head over to the SQL Editor and run the following query:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create table documents (&#xA;  id bigserial primary key,&#xA;  content text,&#xA;  url text,&#xA;  embedding vector (1536)&#xA;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Finally, we&#39;ll create a function that will be used to perform similarity searches. Head over to the SQL Editor and run the following query:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create or replace function match_documents (&#xA;  query_embedding vector(1536),&#xA;  similarity_threshold float,&#xA;  match_count int&#xA;)&#xA;returns table (&#xA;  id bigint,&#xA;  content text,&#xA;  url text,&#xA;  similarity float&#xA;)&#xA;language plpgsql&#xA;as $$&#xA;begin&#xA;  return query&#xA;  select&#xA;    documents.id,&#xA;    documents.content,&#xA;    documents.url,&#xA;    1 - (documents.embedding &amp;lt;=&amp;gt; query_embedding) as similarity&#xA;  from documents&#xA;  where 1 - (documents.embedding &amp;lt;=&amp;gt; query_embedding) &amp;gt; similarity_threshold&#xA;  order by documents.embedding &amp;lt;=&amp;gt; query_embedding&#xA;  limit match_count;&#xA;end;&#xA;$$;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Set-up local environment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;clone the repo: &lt;code&gt;gh repo clone gannonh/gpt3.5-turbo-pgvector&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;unzip and open in your favorite editor (the following assumes VS Code on a Mac)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd gpt3.5-turbo-pgvector&#xA;code .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;install dependencies&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;create a .env.local file in the root directory to store environment variables:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp .env.local.example .env.local&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;open the .env.local file and add your Supabase project URL and API key. You can find these in the Supabase web portal under &lt;code&gt;Project&lt;/code&gt; → &lt;code&gt;API&lt;/code&gt;. The API key should be stored in the &lt;code&gt;SUPABASE_ANON_KEY&lt;/code&gt; variable and project URL should be stored under &lt;code&gt;NEXT_PUBLIC_SUPABASE_URL&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Add your OPENAI PI key to .env.local. You can find this in the OpenAI web portal under &lt;code&gt;API Keys&lt;/code&gt;. The API key should be stored in the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; variable.&lt;/li&gt; &#xA; &lt;li&gt;Start the app&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Open &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt; in your browser to view the app.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>D4RK-R4BB1T/Dark-Web-Archives</title>
    <updated>2023-03-22T01:29:00Z</updated>
    <id>tag:github.com,2023-03-22:/D4RK-R4BB1T/Dark-Web-Archives</id>
    <link href="https://github.com/D4RK-R4BB1T/Dark-Web-Archives" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Archives of the criminal side of the internet&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Dark Web Archives&lt;/h1&gt; &#xA;&lt;p&gt;All public/Privately leaked Dark Web Marketplace (DNM) Scripts, Source codes and information.&lt;/p&gt; &#xA;&lt;p&gt;This archive will be a place for researchers, law enforcemet and etc to study DNMs, Fraud Markets and Common Dark Web Scams without the need to venture to Tor/I2P to find them, do research and etc. We&#39;ll do that for you. In this archive you can find everything found below and than some. You may have questions which will be answered in the FAQ Below the contents&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Update: Fixed CannaHome, Ekmer&#39;s script, Solaris is being a bitch so don&#39;t expect it to work properly. Everything else should.&lt;/h1&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;What can you find here:&lt;/p&gt; &#xA;&lt;p&gt;Solaris - Russian Based DNM, hacked by Hold Security LLC.&lt;/p&gt; &#xA;&lt;p&gt;CannaHome - English based, Cannabis/Shrooms Marketplace&lt;/p&gt; &#xA;&lt;p&gt;2 Other Marketplaces which will be named when I can remember them&lt;/p&gt; &#xA;&lt;p&gt;Ransomware/Malware Source Codes in General&lt;/p&gt; &#xA;&lt;p&gt;Server/IP Information (TXT Files)&lt;/p&gt; &#xA;&lt;p&gt;Structures of Scam Marketplaces found through open Directories&lt;/p&gt; &#xA;&lt;p&gt;Links to where the information can be viewed.&lt;/p&gt; &#xA;&lt;p&gt;Directories Known&lt;/p&gt; &#xA;&lt;p&gt;Sensitive Information from public Directories&lt;/p&gt; &#xA;&lt;p&gt;Possible Vulds&lt;/p&gt; &#xA;&lt;p&gt;Technology Used&lt;/p&gt; &#xA;&lt;p&gt;Users (Scraped/Public Info)&lt;/p&gt; &#xA;&lt;p&gt;Ransomware Statistics&lt;/p&gt; &#xA;&lt;p&gt;.onion &amp;amp; .i2p Links&lt;/p&gt; &#xA;&lt;p&gt;Potential Leads&lt;/p&gt; &#xA;&lt;p&gt;and more&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Frequently Asked Questions:&lt;/p&gt; &#xA;&lt;p&gt;Q. Why isn&#39;t this private?&lt;/p&gt; &#xA;&lt;p&gt;A. Information should remain unrestricted if it benifits all parties even bad actors, Limiting said information may cause issues, Even if bad actors have said info the chances of them being able to run long term is just not possible, Instead we plan to educate everyone. We&#39;re not here to care about drug abuse, that&#39;s a dumb idea to begin with. If we cared we&#39;d of started doxing vendors who sell cannabis for crying out loud.&lt;/p&gt; &#xA;&lt;p&gt;Q. So how big is this going to be?&lt;/p&gt; &#xA;&lt;p&gt;A. As long as cyber crime exists, we&#39;ll continue to build this archive so it&#39;ll be as big as the amount of things I can fit into it.&lt;/p&gt; &#xA;&lt;p&gt;Q. Is it safe to run the DNM Scripts?&lt;/p&gt; &#xA;&lt;p&gt;A. Yes &amp;amp; No, They have a vuld in them that allowed the SRC to be leaked, If you&#39;re running it locally, whitelist/blacklisting traffic or offline it&#39;s fine.&lt;/p&gt; &#xA;&lt;p&gt;Q. So, Will this include PII of Threat Actors and Vendors?&lt;/p&gt; &#xA;&lt;p&gt;A. Limited. Will be published offsite if needed.&lt;/p&gt; &#xA;&lt;p&gt;Q. Will you be adding Conti Leaks or any others in the same catagory?&lt;/p&gt; &#xA;&lt;p&gt;A. Yes &amp;amp; No, If we fear the leaks maybe deleted due to ToS of another platform than yes, otherwise no.&lt;/p&gt; &#xA;&lt;p&gt;Q. Will you be sharing executables?&lt;/p&gt; &#xA;&lt;p&gt;A. Yes, Password is infected (VX-Underground has the same password, so we&#39;ll keep it simple. Don&#39;t ask we won&#39;t answer).&lt;/p&gt; &#xA;&lt;p&gt;Q. Do you fear people will find the exploit used to hack the DNMs and patch it and use it to run the DNMs?&lt;/p&gt; &#xA;&lt;p&gt;A. I Have no doubt they&#39;ll be used and patched, However I am not responsable for this and since it&#39;s a public repo I&#39;m sure MS Tracks downloads quite well.&lt;/p&gt; &#xA;&lt;p&gt;Q. Why are you stealing other people&#39;s work and publishing it?&lt;/p&gt; &#xA;&lt;p&gt;A. Stealing is the incorrect term, I Am not stealing work, everything is credited to the leaker.&lt;/p&gt; &#xA;&lt;p&gt;Q. So, you&#39;re going to help criminals begin their franchise for free?&lt;/p&gt; &#xA;&lt;p&gt;A. Finding a reputable PHP programmer isn&#39;t hard, I&#39;ve seen some doing work for less than US-Federal Minimum wage which is like $7.65/hr they went for $7/hr so I&#39;m not really doing anyone a favor but saving someone idk? $100 USD at best? Servers will cost them more as any serious criminal would code their own shit rather than using some potentially vulderable script found on github.&lt;/p&gt; &#xA;&lt;p&gt;Q. Where can I contact you?&lt;/p&gt; &#xA;&lt;p&gt;A. Discord, Telegram, Twitter, Tox found at the below&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;CONTACTS:&lt;/p&gt; &#xA;&lt;p&gt;Discord: Will update later&lt;/p&gt; &#xA;&lt;p&gt;Telegram: &lt;a href=&#34;https://t.me/BugHunter47&#34;&gt;https://t.me/BugHunter47&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Tox: 906F431F8DBF8E6FF031F92289764737F29C5D2ADD5F942C47D8785151E55E6E87CDE2E7A41F&lt;/p&gt; &#xA;&lt;p&gt;(Use a note when sending an Friend Request on tox, Really helps me figure out what you need before I accept it)&lt;/p&gt; &#xA;&lt;p&gt;Twitter: &lt;a href=&#34;https://twitter.com/D4RKR4BB1T47&#34;&gt;https://twitter.com/D4RKR4BB1T47&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>yuezk/chatgpt-mirror</title>
    <updated>2023-03-22T01:29:00Z</updated>
    <id>tag:github.com,2023-03-22:/yuezk/chatgpt-mirror</id>
    <link href="https://github.com/yuezk/chatgpt-mirror" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A mirror of ChatGPT based on the gpt-3.5-turbo model.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGPT Mirror&lt;/h1&gt; &#xA;&lt;p&gt;Based on model &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;. Demo: &lt;a href=&#34;https://fastgpt.app&#34;&gt;https://fastgpt.app&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Tested on Node.js 18.x.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pnpm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running the app&lt;/h2&gt; &#xA;&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the root directory and add your OpenAI API key:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-properties&#34;&gt;OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&#xA;# optional, support http or socks proxy&#xA;HTTP_PROXY=http://proxy-server:port&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# development&#xA;$ pnpm run start&#xA;&#xA;# watch mode&#xA;$ pnpm run start:dev&#xA;&#xA;# production mode&#xA;$ pnpm run start:prod&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Visit &lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Running the app with Docker&lt;/h2&gt; &#xA;&lt;h3&gt;Build the image&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker build -t chatgpt-mirror .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run the container&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker run -d -p 3000:3000 --env-file .env chatgpt-mirror&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run with the config file&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker run -d -p 3000:3000 --env-file .env -v $(pwd)/config/app.config.json:/app/config/app.config.json chatgpt-mirror&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;You can configure the app by copying the &lt;code&gt;config/example.json&lt;/code&gt; to &lt;code&gt;config/app.config.json&lt;/code&gt; and editing its values. Note: comments are not allowed in JSON files.&lt;/p&gt; &#xA;&lt;h2&gt;Error messages&lt;/h2&gt; &#xA;&lt;p&gt;Error messages for the OpenAI API can be customized by editing the &lt;code&gt;config/app.config.json&lt;/code&gt; file. See the examples in the &lt;code&gt;config/example.json&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;Thanks: &lt;a href=&#34;https://github.com/transitive-bullshit/chatgpt-api&#34;&gt;transitive-bullshit/chatgpt-api&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yuezk/chatgpt-mirror/main/LICENSE&#34;&gt;MIT licensed&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>