<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-01T01:30:41Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>jerryjliu/gpt_index</title>
    <updated>2023-01-01T01:30:41Z</updated>
    <id>tag:github.com,2023-01-01:/jerryjliu/gpt_index</id>
    <link href="https://github.com/jerryjliu/gpt_index" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An index created by GPT to organize external information and answer queries!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üóÇÔ∏è Ô∏èGPT Index&lt;/h1&gt; &#xA;&lt;p&gt;GPT Index is a project consisting of a set of &lt;em&gt;data structures&lt;/em&gt; that are created using LLMs and can be traversed using LLMs in order to answer queries.&lt;/p&gt; &#xA;&lt;p&gt;PyPi: &lt;a href=&#34;https://pypi.org/project/gpt-index/&#34;&gt;https://pypi.org/project/gpt-index/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Documentation: &lt;a href=&#34;https://gpt-index.readthedocs.io/en/latest/&#34;&gt;https://gpt-index.readthedocs.io/en/latest/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: This README is not updated as frequently as the documentation. Please check out the documentation above for the latest updates!&lt;/p&gt; &#xA;&lt;h4&gt;Context&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;LLMs are a phenomenonal piece of technology for knowledge generation and reasoning.&lt;/li&gt; &#xA; &lt;li&gt;A big limitation of LLMs is context size (e.g. OpenAI&#39;s &lt;code&gt;davinci&lt;/code&gt; model for GPT-3 has a &lt;a href=&#34;https://openai.com/api/pricing/&#34;&gt;limit&lt;/a&gt; of 4096 tokens. Large, but not infinite).&lt;/li&gt; &#xA; &lt;li&gt;The ability to feed &#34;knowledge&#34; to LLMs is restricted to this limited prompt size and model weights.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Thought&lt;/strong&gt;: What if LLMs can have access to potentially a much larger database of knowledge without retraining/finetuning?&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Proposed Solution&lt;/h4&gt; &#xA;&lt;p&gt;That&#39;s where the &lt;strong&gt;GPT Index&lt;/strong&gt; comes in. GPT Index is a simple, flexible interface between your external data and LLMs. It resolves the following pain points:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Provides simple data structures to resolve prompt size limitations.&lt;/li&gt; &#xA; &lt;li&gt;Offers data connectors to your external data sources.&lt;/li&gt; &#xA; &lt;li&gt;Offers you a comprehensive toolset trading off cost and performance.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;At the core of GPT Index is a &lt;strong&gt;data structure&lt;/strong&gt;. Instead of relying on world knowledge encoded in the model weights, a GPT Index data structure does the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Uses a pre-trained LLM primarily for &lt;em&gt;reasoning&lt;/em&gt;/&lt;em&gt;summarization&lt;/em&gt; instead of prior knowledge.&lt;/li&gt; &#xA; &lt;li&gt;Takes as input a large corpus of text data and build a structured index over it (using an LLM or heuristics).&lt;/li&gt; &#xA; &lt;li&gt;Allow users to &lt;em&gt;query&lt;/em&gt; the index in order to synthesize an answer to the question - this requires both &lt;em&gt;traversal&lt;/em&gt; of the index as well as a synthesis of the answer.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìÑ Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Full documentation can be found here: &lt;a href=&#34;https://gpt-index.readthedocs.io/en/latest/&#34;&gt;https://gpt-index.readthedocs.io/en/latest/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Please check it out for the most up-to-date tutorials, how-to guides, references, and other resources!&lt;/p&gt; &#xA;&lt;h2&gt;üíª Example Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install gpt-index&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Examples are in the &lt;code&gt;examples&lt;/code&gt; folder. Indices are in the &lt;code&gt;indices&lt;/code&gt; folder (see list of indices below).&lt;/p&gt; &#xA;&lt;p&gt;To build a tree index do the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from gpt_index import GPTTreeIndex, SimpleDirectoryReader&#xA;documents = SimpleDirectoryReader(&#39;data&#39;).load_data()&#xA;index = GPTTreeIndex(documents)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To save to disk and load from disk, do&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# save to disk&#xA;index.save_to_disk(&#39;index.json&#39;)&#xA;# load from disk&#xA;index = GPTTreeIndex.load_from_disk(&#39;index.json&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To query,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;index.query(&#34;&amp;lt;question_text&amp;gt;?&#34;, child_branch_factor=1)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üîß Dependencies&lt;/h2&gt; &#xA;&lt;p&gt;The main third-party package requirements are &lt;code&gt;tiktoken&lt;/code&gt;, &lt;code&gt;openai&lt;/code&gt;, and &lt;code&gt;langchain&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;All requirements should be contained within the &lt;code&gt;setup.py&lt;/code&gt; file. To run the package locally without building the wheel, simply do &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>sczhou/CodeFormer</title>
    <updated>2023-01-01T01:30:41Z</updated>
    <id>tag:github.com,2023-01-01:/sczhou/CodeFormer</id>
    <link href="https://github.com/sczhou/CodeFormer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;[NeurIPS 2022] Towards Robust Blind Face Restoration with Codebook Lookup Transformer&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/CodeFormer_logo.png&#34; height=&#34;110&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Towards Robust Blind Face Restoration with Codebook Lookup Transformer (NeurIPS 2022)&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2206.11253&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://shangchenzhou.com/projects/CodeFormer/&#34;&gt;Project Page&lt;/a&gt; | &lt;a href=&#34;https://youtu.be/d3VDpkXlueI&#34;&gt;Video&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1m52PNveE4PBhYrecj34cnpEeiHcC5LTb?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;google colab logo&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/sczhou/CodeFormer&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Demo-%F0%9F%A4%97%20Hugging%20Face-blue&#34; alt=&#34;Hugging Face&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://replicate.com/sczhou/codeformer&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Demo-%F0%9F%9A%80%20Replicate-blue&#34; alt=&#34;Replicate&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://visitor-badge.laobi.icu/badge?page_id=sczhou/CodeFormer&#34; alt=&#34;visitors&#34;&gt;&lt;/p&gt; &#xA;&lt;!-- ![visitors](https://visitor-badge.glitch.me/badge?page_id=sczhou/CodeFormer) --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://shangchenzhou.com/&#34;&gt;Shangchen Zhou&lt;/a&gt;, &lt;a href=&#34;https://ckkelvinchan.github.io/&#34;&gt;Kelvin C.K. Chan&lt;/a&gt;, &lt;a href=&#34;https://li-chongyi.github.io/&#34;&gt;Chongyi Li&lt;/a&gt;, &lt;a href=&#34;https://www.mmlab-ntu.com/person/ccloy/&#34;&gt;Chen Change Loy&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;S-Lab, Nanyang Technological University&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/network.jpg&#34; width=&#34;800px&#34;&gt; &#xA;&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; If CodeFormer is helpful to your images or projects, please help star this repo. Thanks! &lt;span&gt;ü§ó&lt;/span&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;[&lt;font color=&#34;#d1585d&#34;&gt;News&lt;/font&gt;]&lt;/strong&gt;: &lt;span&gt;üê≥&lt;/span&gt; &lt;em&gt;Due to copyright issues, we have to delay the release of the training code (expected by the end of this year). Please star and stay tuned for our future updates!&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Update&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.10.05&lt;/strong&gt;: Support video input &lt;code&gt;--input_path [YOUR_VIDOE.mp4]&lt;/code&gt;. Try it to enhance your videos! &lt;span&gt;üé¨&lt;/span&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.09.14&lt;/strong&gt;: Integrated to &lt;span&gt;ü§ó&lt;/span&gt; &lt;a href=&#34;https://huggingface.co/spaces&#34;&gt;Hugging Face&lt;/a&gt;. Try out online demo! &lt;a href=&#34;https://huggingface.co/spaces/sczhou/CodeFormer&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Demo-%F0%9F%A4%97%20Hugging%20Face-blue&#34; alt=&#34;Hugging Face&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.09.09&lt;/strong&gt;: Integrated to &lt;span&gt;üöÄ&lt;/span&gt; &lt;a href=&#34;https://replicate.com/explore&#34;&gt;Replicate&lt;/a&gt;. Try out online demo! &lt;a href=&#34;https://replicate.com/sczhou/codeformer&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Demo-%F0%9F%9A%80%20Replicate-blue&#34; alt=&#34;Replicate&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.09.04&lt;/strong&gt;: Add face upsampling &lt;code&gt;--face_upsample&lt;/code&gt; for high-resolution AI-created face enhancement.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.08.23&lt;/strong&gt;: Some modifications on face detection and fusion for better AI-created face enhancement.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.08.07&lt;/strong&gt;: Integrate &lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN&#34;&gt;Real-ESRGAN&lt;/a&gt; to support background image enhancement.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.07.29&lt;/strong&gt;: Integrate new face detectors of &lt;code&gt;[&#39;RetinaFace&#39;(default), &#39;YOLOv5&#39;]&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.07.17&lt;/strong&gt;: Add Colab demo of CodeFormer. &lt;a href=&#34;https://colab.research.google.com/drive/1m52PNveE4PBhYrecj34cnpEeiHcC5LTb?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;google colab logo&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.07.16&lt;/strong&gt;: Release inference code for face restoration. &lt;span&gt;üòä&lt;/span&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;2022.06.21&lt;/strong&gt;: This repo is created.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;TODO&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add checkpoint for face inpainting&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add checkpoint for face colorization&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add training code and config files&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;del&gt;Add background image enhancement&lt;/del&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;&lt;span&gt;üêº&lt;/span&gt; Try Enhancing Old Photos / Fixing AI-arts&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://imgsli.com/MTI3NTE2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/imgsli_1.jpg&#34; height=&#34;226px&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://imgsli.com/MTI3NTE1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/imgsli_2.jpg&#34; height=&#34;226px&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://imgsli.com/MTI3NTIw&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/imgsli_3.jpg&#34; height=&#34;226px&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Face Restoration&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/restoration_result1.png&#34; width=&#34;400px&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/restoration_result2.png&#34; width=&#34;400px&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/restoration_result3.png&#34; width=&#34;400px&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/restoration_result4.png&#34; width=&#34;400px&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Face Color Enhancement and Restoration&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/color_enhancement_result1.png&#34; width=&#34;400px&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/color_enhancement_result2.png&#34; width=&#34;400px&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Face Inpainting&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/inpainting_result1.png&#34; width=&#34;400px&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/sczhou/CodeFormer/master/assets/inpainting_result2.png&#34; width=&#34;400px&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Dependencies and Installation&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Pytorch &amp;gt;= 1.7.1&lt;/li&gt; &#xA; &lt;li&gt;CUDA &amp;gt;= 10.1&lt;/li&gt; &#xA; &lt;li&gt;Other required packages in &lt;code&gt;requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# git clone this repository&#xA;git clone https://github.com/sczhou/CodeFormer&#xA;cd CodeFormer&#xA;&#xA;# create new anaconda env&#xA;conda create -n codeformer python=3.8 -y&#xA;conda activate codeformer&#xA;&#xA;# install python dependencies&#xA;pip3 install -r requirements.txt&#xA;python basicsr/setup.py develop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- conda install -c conda-forge dlib --&gt; &#xA;&lt;h3&gt;Quick Inference&lt;/h3&gt; &#xA;&lt;h4&gt;Download Pre-trained Models:&lt;/h4&gt; &#xA;&lt;p&gt;Download the facelib pretrained models from [&lt;a href=&#34;https://drive.google.com/drive/folders/1b_3qwrzY_kTQh0-SnBoGBgOrJ_PLZSKm?usp=sharing&#34;&gt;Google Drive&lt;/a&gt; | &lt;a href=&#34;https://entuedu-my.sharepoint.com/:f:/g/personal/s200094_e_ntu_edu_sg/EvDxR7FcAbZMp_MA9ouq7aQB8XTppMb3-T0uGZ_2anI2mg?e=DXsJFo&#34;&gt;OneDrive&lt;/a&gt;] to the &lt;code&gt;weights/facelib&lt;/code&gt; folder. You can manually download the pretrained models OR download by running the following command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/download_pretrained_models.py facelib&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Download the CodeFormer pretrained models from [&lt;a href=&#34;https://drive.google.com/drive/folders/1CNNByjHDFt0b95q54yMVp6Ifo5iuU6QS?usp=sharing&#34;&gt;Google Drive&lt;/a&gt; | &lt;a href=&#34;https://entuedu-my.sharepoint.com/:f:/g/personal/s200094_e_ntu_edu_sg/EoKFj4wo8cdIn2-TY2IV6CYBhZ0pIG4kUOeHdPR_A5nlbg?e=AO8UN9&#34;&gt;OneDrive&lt;/a&gt;] to the &lt;code&gt;weights/CodeFormer&lt;/code&gt; folder. You can manually download the pretrained models OR download by running the following command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/download_pretrained_models.py CodeFormer&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Prepare Testing Data:&lt;/h4&gt; &#xA;&lt;p&gt;You can put the testing images in the &lt;code&gt;inputs/TestWhole&lt;/code&gt; folder. If you would like to test on cropped and aligned faces, you can put them in the &lt;code&gt;inputs/cropped_faces&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;h4&gt;Testing on Face Restoration:&lt;/h4&gt; &#xA;&lt;p&gt;[Note] If you want to compare CodeFormer in your paper, please run the following command indicating &lt;code&gt;--has_aligned&lt;/code&gt; (for cropped and aligned face), as the command for the whole image will involve a process of face-background fusion that may damage hair texture on the boundary, which leads to unfair comparison.&lt;/p&gt; &#xA;&lt;p&gt;üßëüèª Face Restoration (cropped and aligned face)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# For cropped and aligned faces&#xA;python inference_codeformer.py -w 0.5 --has_aligned --input_path [input folder]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;span&gt;üñº&lt;/span&gt; Whole Image Enhancement&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# For whole image&#xA;# Add &#39;--bg_upsampler realesrgan&#39; to enhance the background regions with Real-ESRGAN&#xA;# Add &#39;--face_upsample&#39; to further upsample restorated face with Real-ESRGAN&#xA;python inference_codeformer.py -w 0.7 --input_path [image folder/image path]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;span&gt;üé¨&lt;/span&gt; Video Enhancement&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# For video clips&#xA;python inference_codeformer.py --bg_upsampler realesrgan --face_upsample -w 1.0 --input_path [video path]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Fidelity weight &lt;em&gt;w&lt;/em&gt; lays in [0, 1]. Generally, smaller &lt;em&gt;w&lt;/em&gt; tends to produce a higher-quality result, while larger &lt;em&gt;w&lt;/em&gt; yields a higher-fidelity result.&lt;/p&gt; &#xA;&lt;p&gt;The results will be saved in the &lt;code&gt;results&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;h3&gt;Citation&lt;/h3&gt; &#xA;&lt;p&gt;If our work is useful for your research, please consider citing:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{zhou2022codeformer,&#xA;    author = {Zhou, Shangchen and Chan, Kelvin C.K. and Li, Chongyi and Loy, Chen Change},&#xA;    title = {Towards Robust Blind Face Restoration with Codebook Lookup TransFormer},&#xA;    booktitle = {NeurIPS},&#xA;    year = {2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;License&lt;/h3&gt; &#xA;&lt;p&gt;This project is licensed under &lt;a rel=&#34;license&#34; href=&#34;https://github.com/sczhou/CodeFormer/raw/master/LICENSE&#34;&gt;NTU S-Lab License 1.0&lt;/a&gt;. Redistribution and use should follow this license.&lt;/p&gt; &#xA;&lt;h3&gt;Acknowledgement&lt;/h3&gt; &#xA;&lt;p&gt;This project is based on &lt;a href=&#34;https://github.com/XPixelGroup/BasicSR&#34;&gt;BasicSR&lt;/a&gt;. Some codes are brought from &lt;a href=&#34;https://github.com/samb-t/unleashing-transformers&#34;&gt;Unleashing Transformers&lt;/a&gt;, &lt;a href=&#34;https://github.com/deepcam-cn/yolov5-face&#34;&gt;YOLOv5-face&lt;/a&gt;, and &lt;a href=&#34;https://github.com/xinntao/facexlib&#34;&gt;FaceXLib&lt;/a&gt;. We also adopt &lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN&#34;&gt;Real-ESRGAN&lt;/a&gt; to support background image enhancement. Thanks for their awesome works.&lt;/p&gt; &#xA;&lt;h3&gt;Contact&lt;/h3&gt; &#xA;&lt;p&gt;If you have any question, please feel free to reach me out at &lt;code&gt;shangchenzhou@gmail.com&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>google/osv-scanner</title>
    <updated>2023-01-01T01:30:41Z</updated>
    <id>tag:github.com,2023-01-01:/google/osv-scanner</id>
    <link href="https://github.com/google/osv-scanner" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Vulnerability scanner written in Go which uses the data provided by https://osv.dev&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://api.securityscorecards.dev/projects/github.com/google/osv-scanner&#34;&gt;&lt;img src=&#34;https://api.securityscorecards.dev/projects/github.com/google/osv-scanner/badge&#34; alt=&#34;OpenSSF Scorecard&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;OSV-Scanner&lt;/h1&gt; &#xA;&lt;p&gt;Use OSV-Scanner to find existing vulnerabilities affecting your project&#39;s dependencies.&lt;/p&gt; &#xA;&lt;p&gt;OSV-Scanner provides an officially supported frontend to the &lt;a href=&#34;https://osv.dev/&#34;&gt;OSV database&lt;/a&gt; that connects a project‚Äôs list of dependencies with the vulnerabilities that affect them. Since the OSV.dev database is open source and distributed, it has several benefits in comparison with closed source advisory databases and scanners:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Each advisory comes from an open and authoritative source (e.g. the &lt;a href=&#34;https://github.com/rustsec/advisory-db&#34;&gt;RustSec Advisory Database&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Anyone can suggest improvements to advisories, resulting in a very high quality database&lt;/li&gt; &#xA; &lt;li&gt;The OSV format unambiguously stores information about affected versions in a machine-readable format that precisely maps onto a developer‚Äôs list of packages&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The above all results in fewer, more actionable vulnerability notifications, which reduces the time needed to resolve them. Check out our &lt;a href=&#34;https://security.googleblog.com/2022/12/announcing-osv-scanner-vulnerability.html&#34;&gt;announcement blog post&lt;/a&gt; for more details!&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#osv-scanner&#34;&gt;OSV-Scanner&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#table-of-contents&#34;&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#installing&#34;&gt;Installing&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#package-managers&#34;&gt;Package Managers&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#install-from-source&#34;&gt;Install from source&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#semver-adherence&#34;&gt;SemVer Adherence&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#usage&#34;&gt;Usage&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#scan-a-directory&#34;&gt;Scan a directory&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#input-an-sbom&#34;&gt;Input an SBOM&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#input-a-lockfile&#34;&gt;Input a lockfile&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#scanning-a-debian-based-docker-image-packages-preview&#34;&gt;Scanning a Debian based docker image packages (preview)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#configure-osv-scanner&#34;&gt;Configure OSV-Scanner&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#ignore-vulnerabilities-by-id&#34;&gt;Ignore vulnerabilities by ID&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#json-output&#34;&gt;JSON output&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/osv-scanner/main/#output-format&#34;&gt;Output Format&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installing&lt;/h2&gt; &#xA;&lt;p&gt;You may download the &lt;a href=&#34;https://slsa.dev&#34;&gt;SLSA3&lt;/a&gt; compliant binaries for Linux, macOS, and Windows from our &lt;a href=&#34;https://github.com/google/osv-scanner/releases&#34;&gt;releases page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Package Managers&lt;/h3&gt; &#xA;&lt;p&gt;If you&#39;re a &lt;a href=&#34;https://scoop.sh&#34;&gt;&lt;strong&gt;Windows Scoop&lt;/strong&gt;&lt;/a&gt; user, then you can install osv-scanner from the &lt;a href=&#34;https://github.com/ScoopInstaller/Main/raw/master/bucket/osv-scanner.json&#34;&gt;official bucket&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;scoop install osv-scanner&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you&#39;re a &lt;a href=&#34;https://brew.sh/&#34;&gt;Homebrew&lt;/a&gt; user, you can install &lt;a href=&#34;https://formulae.brew.sh/formula/osv-scanner&#34;&gt;osv-scanner&lt;/a&gt; via:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ brew install osv-scanner&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Install from source&lt;/h3&gt; &#xA;&lt;p&gt;Alternatively, you can install this from source by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ go install github.com/google/osv-scanner/cmd/osv-scanner@v1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This requires Go 1.18+ to be installed.&lt;/p&gt; &#xA;&lt;h3&gt;SemVer Adherence&lt;/h3&gt; &#xA;&lt;p&gt;All releases on the same Major version will be guaranteed to have backward compatible JSON output and CLI arguments.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;OSV-Scanner collects a list of dependencies and versions that are used in your project, before matching this list against the OSV database via the &lt;a href=&#34;https://osv.dev#use-the-api&#34;&gt;OSV.dev API&lt;/a&gt;. To build the list of dependencies, you can point OSV-Scanner at your project directory, or manually pass in the path to individual manifest files.&lt;/p&gt; &#xA;&lt;h3&gt;Scan a directory&lt;/h3&gt; &#xA;&lt;p&gt;Walks through a list of directories to find:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lockfiles&lt;/li&gt; &#xA; &lt;li&gt;SBOMs&lt;/li&gt; &#xA; &lt;li&gt;git directories for the latest commit hash&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;which is used to build the list of dependencies to be matched against OSV vulnerabilities.&lt;/p&gt; &#xA;&lt;p&gt;Can be configured to recursively walk through subdirectories with the &lt;code&gt;--recursive&lt;/code&gt; / &lt;code&gt;-r&lt;/code&gt; flag.&lt;/p&gt; &#xA;&lt;p&gt;Searching for git commit hash is intended to work with projects that use git submodules or a similar mechanism where dependencies are checked out as real git repositories.&lt;/p&gt; &#xA;&lt;h4&gt;Example&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ osv-scanner -r /path/to/your/dir&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Input an SBOM&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://spdx.dev/&#34;&gt;SPDX&lt;/a&gt; and &lt;a href=&#34;https://cyclonedx.org/&#34;&gt;CycloneDX&lt;/a&gt; SBOMs using &lt;a href=&#34;https://github.com/package-url/purl-spec&#34;&gt;Package URLs&lt;/a&gt; are supported. The format is auto-detected based on the input file contents.&lt;/p&gt; &#xA;&lt;h4&gt;Example&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ osv-scanner --sbom=/path/to/your/sbom.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Input a lockfile&lt;/h3&gt; &#xA;&lt;p&gt;A wide range of lockfiles are supported by utilizing this &lt;a href=&#34;https://github.com/google/osv-scanner/tree/main/pkg/lockfile&#34;&gt;lockfile package&lt;/a&gt;. This is the current list of supported lockfiles:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Cargo.lock&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;package-lock.json&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;yarn.lock&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;pnpm-lock.yaml&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;composer.lock&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Gemfile.lock&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;go.mod&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;mix.lock&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;poetry.lock&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;pubspec.lock&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;pom.xml&lt;/code&gt;&lt;a href=&#34;https://github.com/google/osv-scanner/issues/35&#34;&gt;*&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;requirements.txt&lt;/code&gt;&lt;a href=&#34;https://github.com/google/osv-scanner/issues/34&#34;&gt;*&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;gradle.lockfile&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;buildscript-gradle.lockfile&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Example&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ osv-scanner --lockfile=/path/to/your/package-lock.json --lockfile=/path/to/another/Cargo.lock&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Scanning a Debian based docker image packages (preview)&lt;/h3&gt; &#xA;&lt;p&gt;This tool will scrape the list of installed packages in a Debian image and query for vulnerabilities on them.&lt;/p&gt; &#xA;&lt;p&gt;Currently only Debian based docker image scanning is supported.&lt;/p&gt; &#xA;&lt;p&gt;Requires &lt;code&gt;docker&lt;/code&gt; to be installed and the tool to have permission calling it.&lt;/p&gt; &#xA;&lt;p&gt;This currently does not scan the filesystem of the Docker container, and has various other limitations. Follow &lt;a href=&#34;https://github.com/google/osv-scanner/issues/64&#34;&gt;this issue&lt;/a&gt; for updates on container scanning!&lt;/p&gt; &#xA;&lt;h4&gt;Example&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ osv-scanner --docker image_name:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Configure OSV-Scanner&lt;/h2&gt; &#xA;&lt;p&gt;To configure scanning, place an osv-scanner.toml file in the scanned file&#39;s directory. To override this osv-scanner.toml file, pass the &lt;code&gt;--config=/path/to/config.toml&lt;/code&gt; flag with the path to the configuration you want to apply instead.&lt;/p&gt; &#xA;&lt;p&gt;Currently, there is only 1 option to configure:&lt;/p&gt; &#xA;&lt;h3&gt;Ignore vulnerabilities by ID&lt;/h3&gt; &#xA;&lt;p&gt;To ignore a vulnerability, enter the ID under the &lt;code&gt;IgnoreVulns&lt;/code&gt; key. Optionally, add an expiry date or reason.&lt;/p&gt; &#xA;&lt;h4&gt;Example&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;[[IgnoredVulns]]&#xA;id = &#34;GO-2022-0968&#34;&#xA;# ignoreUntil = 2022-11-09 # Optional exception expiry date&#xA;reason = &#34;No ssh servers are connected to or hosted in Go lang&#34;&#xA;&#xA;id = &#34;GO-2022-1059&#34;&#xA;# ignoreUntil = 2022-11-09 # Optional exception expiry date&#xA;reason = &#34;No external http servers are written in Go lang.&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;JSON output&lt;/h2&gt; &#xA;&lt;p&gt;By default osv-scanner outputs a human readable table. To have osv-scanner output JSON instead, pass the &lt;code&gt;--json&lt;/code&gt; flag when calling osv-scanner.&lt;/p&gt; &#xA;&lt;p&gt;When using the --json flag, only the JSON output will be printed to stdout, with all other outputs being directed to stderr. So to save only the json output to file, you can redirect the output with &lt;code&gt;osv-scanner --json ... &amp;gt; /path/to/file.json&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Output Format&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json5&#34;&gt;{&#xA;  &#34;results&#34;: [&#xA;    {&#xA;      &#34;packageSource&#34;: {&#xA;        &#34;path&#34;: &#34;/absolute/path/to/go.mod&#34;,&#xA;        // One of: lockfile, sbom, git, docker&#xA;        &#34;type&#34;: &#34;lockfile&#34;&#xA;      },&#xA;      &#34;packages&#34;: [&#xA;        {&#xA;          &#34;Package&#34;: {&#xA;            &#34;name&#34;: &#34;github.com/gogo/protobuf&#34;,&#xA;            &#34;version&#34;: &#34;1.3.1&#34;,&#xA;            &#34;ecosystem&#34;: &#34;Go&#34;&#xA;          },&#xA;          &#34;vulnerabilities&#34;: [&#xA;            {&#xA;              &#34;id&#34;: &#34;GHSA-c3h9-896r-86jm&#34;,&#xA;              &#34;aliases&#34;: [&#xA;                &#34;CVE-2021-3121&#34;&#xA;              ],&#xA;              // ... Full OSV&#xA;            },&#xA;            {&#xA;              &#34;id&#34;: &#34;GO-2021-0053&#34;,&#xA;              &#34;aliases&#34;: [&#xA;                &#34;CVE-2021-3121&#34;,&#xA;                &#34;GHSA-c3h9-896r-86jm&#34;&#xA;              ],&#xA;              // ... Full OSV&#xA;            }&#xA;          ],&#xA;          // Grouping based on aliases, if two vulnerability share the same alias, or alias each other,&#xA;          // they are considered the same vulnerability, and is grouped here under the id field.&#xA;          &#34;groups&#34;: [&#xA;            {&#xA;              &#34;ids&#34;: [&#xA;                &#34;GHSA-c3h9-896r-86jm&#34;,&#xA;                &#34;GO-2021-0053&#34;&#xA;              ]&#xA;            }&#xA;          ]&#xA;        }&#xA;      ]&#xA;    },&#xA;    {&#xA;      &#34;packageSource&#34;: {&#xA;        &#34;path&#34;: &#34;/absolute/path/to/Cargo.lock&#34;,&#xA;        &#34;type&#34;: &#34;lockfile&#34;&#xA;      },&#xA;      &#34;packages&#34;: [&#xA;        {&#xA;          &#34;Package&#34;: {&#xA;            &#34;name&#34;: &#34;regex&#34;,&#xA;            &#34;version&#34;: &#34;1.5.1&#34;,&#xA;            &#34;ecosystem&#34;: &#34;crates.io&#34;&#xA;          },&#xA;          &#34;vulnerabilities&#34;: [&#xA;            {&#xA;              &#34;id&#34;: &#34;GHSA-m5pq-gvj9-9vr8&#34;,&#xA;              &#34;aliases&#34;: [&#xA;                &#34;CVE-2022-24713&#34;&#xA;              ],&#xA;              // ... Full OSV&#xA;            },&#xA;            {&#xA;              &#34;id&#34;: &#34;RUSTSEC-2022-0013&#34;,&#xA;              &#34;aliases&#34;: [&#xA;                &#34;CVE-2022-24713&#34;&#xA;              ],&#xA;              // ... Full OSV&#xA;            }&#xA;          ],&#xA;          &#34;groups&#34;: [&#xA;            {&#xA;              &#34;ids&#34;: [&#xA;                &#34;GHSA-m5pq-gvj9-9vr8&#34;,&#xA;                &#34;RUSTSEC-2022-0013&#34;&#xA;              ]&#xA;            }&#xA;          ]&#xA;        }&#xA;      ]&#xA;    }&#xA;  ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>