<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-09-30T01:28:34Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>exo-explore/exo</title>
    <updated>2024-09-30T01:28:34Z</updated>
    <id>tag:github.com,2024-09-30:/exo-explore/exo</id>
    <link href="https://github.com/exo-explore/exo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Run your own AI cluster at home with everyday devices üì±üíª üñ•Ô∏è‚åö&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;/docs/exo-logo-black-bg.jpg&#34;&gt; &#xA;  &lt;img alt=&#34;exo logo&#34; src=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/docs/exo-logo-transparent.png&#34; width=&#34;50%&#34; height=&#34;50%&#34;&gt; &#xA; &lt;/picture&gt; &#xA; &lt;p&gt;exo: Run your own AI cluster at home with everyday devices. Maintained by &lt;a href=&#34;https://x.com/exolabs&#34;&gt;exo labs&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;h3&gt; &lt;p&gt;&lt;a href=&#34;https://discord.gg/EUnjGpsmWw&#34;&gt;Discord&lt;/a&gt; | &lt;a href=&#34;https://t.me/+Kh-KqHTzFYg3MGNk&#34;&gt;Telegram&lt;/a&gt; | &lt;a href=&#34;https://x.com/exolabs&#34;&gt;X&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/exo-explore/exo/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/exo-explore/exo&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://dl.circleci.com/status-badge/redirect/circleci/TrkofJDoGzdQAeL6yVHKsg/4i5hJuafuwZYZQxbRAWS71/tree/main&#34;&gt;&lt;img src=&#34;https://dl.circleci.com/status-badge/img/circleci/TrkofJDoGzdQAeL6yVHKsg/4i5hJuafuwZYZQxbRAWS71/tree/main.svg?style=svg&#34; alt=&#34;Tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.gnu.org/licenses/gpl-3.0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-GPLv3-blue.svg?sanitize=true&#34; alt=&#34;License: GPL v3&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Forget expensive NVIDIA GPUs, unify your existing devices into one powerful GPU: iPhone, iPad, Android, Mac, Linux, pretty much any device!&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h2&gt;Update: exo is hiring. See &lt;a href=&#34;https://exolabs.net&#34;&gt;here&lt;/a&gt; for more details.&lt;/h2&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Get Involved&lt;/h2&gt; &#xA;&lt;p&gt;exo is &lt;strong&gt;experimental&lt;/strong&gt; software. Expect bugs early on. Create issues so they can be fixed. The &lt;a href=&#34;https://x.com/exolabs&#34;&gt;exo labs&lt;/a&gt; team will strive to resolve issues quickly.&lt;/p&gt; &#xA;&lt;p&gt;We also welcome contributions from the community. We have a list of bounties in &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1cTCpTIp48UnnIvHeLEUNg1iMy_Q6lRybgECSFCoVJpE/edit?usp=sharing&#34;&gt;this sheet&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;h3&gt;Wide Model Support&lt;/h3&gt; &#xA;&lt;p&gt;exo supports different models including LLaMA (&lt;a href=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/mlx/models/llama.py&#34;&gt;MLX&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/tinygrad/models/llama.py&#34;&gt;tinygrad&lt;/a&gt;), Mistral, LlaVA, Qwen and Deepseek.&lt;/p&gt; &#xA;&lt;h3&gt;Dynamic Model Partitioning&lt;/h3&gt; &#xA;&lt;p&gt;exo &lt;a href=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/exo/topology/ring_memory_weighted_partitioning_strategy.py&#34;&gt;optimally splits up models&lt;/a&gt; based on the current network topology and device resources available. This enables you to run larger models than you would be able to on any single device.&lt;/p&gt; &#xA;&lt;h3&gt;Automatic Device Discovery&lt;/h3&gt; &#xA;&lt;p&gt;exo will &lt;a href=&#34;https://github.com/exo-explore/exo/raw/945f90f676182a751d2ad7bcf20987ab7fe0181e/exo/orchestration/standard_node.py#L154&#34;&gt;automatically discover&lt;/a&gt; other devices using the best method available. Zero manual configuration.&lt;/p&gt; &#xA;&lt;h3&gt;ChatGPT-compatible API&lt;/h3&gt; &#xA;&lt;p&gt;exo provides a &lt;a href=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/exo/api/chatgpt_api.py&#34;&gt;ChatGPT-compatible API&lt;/a&gt; for running models. It&#39;s a &lt;a href=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/examples/chatgpt_api.sh&#34;&gt;one-line change&lt;/a&gt; in your application to run models on your own hardware using exo.&lt;/p&gt; &#xA;&lt;h3&gt;Device Equality&lt;/h3&gt; &#xA;&lt;p&gt;Unlike other distributed inference frameworks, exo does not use a master-worker architecture. Instead, exo devices &lt;a href=&#34;https://github.com/exo-explore/exo/raw/945f90f676182a751d2ad7bcf20987ab7fe0181e/exo/orchestration/standard_node.py#L161&#34;&gt;connect p2p&lt;/a&gt;. As long as a device is connected somewhere in the network, it can be used to run models.&lt;/p&gt; &#xA;&lt;p&gt;Exo supports different &lt;a href=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/exo/topology/partitioning_strategy.py&#34;&gt;partitioning strategies&lt;/a&gt; to split up a model across devices. The default partitioning strategy is &lt;a href=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/exo/topology/ring_memory_weighted_partitioning_strategy.py&#34;&gt;ring memory weighted partitioning&lt;/a&gt;. This runs an inference in a ring where each device runs a number of model layers proportional to the memory of the device.&lt;/p&gt; &#xA;&lt;p&gt; &#xA; &lt;picture&gt; &#xA;  &lt;img alt=&#34;ring topology&#34; src=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/docs/ring-topology.png&#34; width=&#34;30%&#34; height=&#34;30%&#34;&gt; &#xA; &lt;/picture&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;The current recommended way to install exo is from source.&lt;/p&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python&amp;gt;=3.12.0 is required because of &lt;a href=&#34;https://github.com/exo-explore/exo/issues/5&#34;&gt;issues with asyncio&lt;/a&gt; in previous versions.&lt;/li&gt; &#xA; &lt;li&gt;Linux (with NVIDIA card): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;NVIDIA driver (test with &lt;code&gt;nvidia-smi&lt;/code&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;CUDA (&lt;a href=&#34;https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-cross-platform-installation&#34;&gt;https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-cross-platform-installation&lt;/a&gt;) (test with &lt;code&gt;nvcc --version&lt;/code&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;cuDNN (&lt;a href=&#34;https://developer.nvidia.com/cudnn-downloads&#34;&gt;https://developer.nvidia.com/cudnn-downloads&lt;/a&gt;) (test with &lt;a href=&#34;https://docs.nvidia.com/deeplearning/cudnn/latest/installation/linux.html#verifying-the-install-on-linux:~:text=at%20a%20time.-,Verifying%20the%20Install%20on%20Linux,Test%20passed!,-Upgrading%20From%20Older&#34;&gt;link&lt;/a&gt;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;From source&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/exo-explore/exo.git&#xA;cd exo&#xA;pip install .&#xA;# alternatively, with venv&#xA;source install.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Troubleshooting&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If running on Mac, MLX has an &lt;a href=&#34;https://ml-explore.github.io/mlx/build/html/install.html&#34;&gt;install guide&lt;/a&gt; with troubleshooting steps.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Performance&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;There are a number of things users have empirically found to improve performance on Apple Silicon Macs:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Upgrade to the latest version of MacOS 15.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;./configure_mlx.sh&lt;/code&gt;. This runs commands to optimize GPU memory allocation on Apple Silicon Macs.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;h3&gt;Example Usage on Multiple MacOS Devices&lt;/h3&gt; &#xA;&lt;h4&gt;Device 1:&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python3 main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Device 2:&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python3 main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That&#39;s it! No configuration required - exo will automatically discover the other device(s).&lt;/p&gt; &#xA;&lt;p&gt;exo starts a ChatGPT-like WebUI (powered by &lt;a href=&#34;https://github.com/tinygrad/tinygrad/tree/master/examples/tinychat&#34;&gt;tinygrad tinychat&lt;/a&gt;) on &lt;a href=&#34;http://localhost:8000&#34;&gt;http://localhost:8000&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;For developers, exo also starts a ChatGPT-compatible API endpoint on &lt;a href=&#34;http://localhost:8000/v1/chat/completions&#34;&gt;http://localhost:8000/v1/chat/completions&lt;/a&gt;. Example with curls:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl http://localhost:8000/v1/chat/completions \&#xA;  -H &#34;Content-Type: application/json&#34; \&#xA;  -d &#39;{&#xA;     &#34;model&#34;: &#34;llama-3.1-8b&#34;,&#xA;     &#34;messages&#34;: [{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;What is the meaning of exo?&#34;}],&#xA;     &#34;temperature&#34;: 0.7&#xA;   }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl http://localhost:8000/v1/chat/completions \&#xA;  -H &#34;Content-Type: application/json&#34; \&#xA;  -d &#39;{&#xA;     &#34;model&#34;: &#34;llava-1.5-7b-hf&#34;,&#xA;     &#34;messages&#34;: [&#xA;      {&#xA;        &#34;role&#34;: &#34;user&#34;,&#xA;        &#34;content&#34;: [&#xA;          {&#xA;            &#34;type&#34;: &#34;text&#34;,&#xA;            &#34;text&#34;: &#34;What are these?&#34;&#xA;          },&#xA;          {&#xA;            &#34;type&#34;: &#34;image_url&#34;,&#xA;            &#34;image_url&#34;: {&#xA;              &#34;url&#34;: &#34;http://images.cocodataset.org/val2017/000000039769.jpg&#34;&#xA;            }&#xA;          }&#xA;        ]&#xA;      }&#xA;    ],&#xA;     &#34;temperature&#34;: 0.0&#xA;   }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Example Usage on Multiple Heterogenous Devices (MacOS + Linux)&lt;/h3&gt; &#xA;&lt;h4&gt;Device 1 (MacOS):&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python3 main.py --inference-engine tinygrad&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here we explicitly tell exo to use the &lt;strong&gt;tinygrad&lt;/strong&gt; inference engine.&lt;/p&gt; &#xA;&lt;h4&gt;Device 2 (Linux):&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python3 main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Linux devices will automatically default to using the &lt;strong&gt;tinygrad&lt;/strong&gt; inference engine.&lt;/p&gt; &#xA;&lt;p&gt;You can read about tinygrad-specific env vars &lt;a href=&#34;https://docs.tinygrad.org/env_vars/&#34;&gt;here&lt;/a&gt;. For example, you can configure tinygrad to use the cpu by specifying &lt;code&gt;CLANG=1&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Debugging&lt;/h2&gt; &#xA;&lt;p&gt;Enable debug logs with the DEBUG environment variable (0-9).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;DEBUG=9 python3 main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For the &lt;strong&gt;tinygrad&lt;/strong&gt; inference engine specifically, there is a separate DEBUG flag &lt;code&gt;TINYGRAD_DEBUG&lt;/code&gt; that can be used to enable debug logs (1-6).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;TINYGRAD_DEBUG=2 python3 main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Known Issues&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;On some versions of MacOS/Python, certificates are not installed properly which can lead to SSL errors (e.g. SSL error with huggingface.co). To fix this, run the Install Certificates command, usually:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/Applications/Python 3.x/Install Certificates.command&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üöß As the library is evolving so quickly, the iOS implementation has fallen behind Python. We have decided for now not to put out the buggy iOS version and receive a bunch of GitHub issues for outdated code. We are working on solving this properly and will make an announcement when it&#39;s ready. If you would like access to the iOS implementation now, please email &lt;a href=&#34;mailto:alex@exolabs.net&#34;&gt;alex@exolabs.net&lt;/a&gt; with your GitHub username explaining your use-case and you will be granted access on GitHub.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Inference Engines&lt;/h2&gt; &#xA;&lt;p&gt;exo supports the following inference engines:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚úÖ &lt;a href=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/mlx/sharded_inference_engine.py&#34;&gt;MLX&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;‚úÖ &lt;a href=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/tinygrad/inference.py&#34;&gt;tinygrad&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üöß &lt;a href=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/TODO&#34;&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Networking Modules&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚úÖ &lt;a href=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/exo/networking/grpc&#34;&gt;GRPC&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üöß &lt;a href=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/TODO&#34;&gt;Radio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üöß &lt;a href=&#34;https://raw.githubusercontent.com/exo-explore/exo/main/TODO&#34;&gt;Bluetooth&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>unclecode/crawl4ai</title>
    <updated>2024-09-30T01:28:34Z</updated>
    <id>tag:github.com,2024-09-30:/unclecode/crawl4ai</id>
    <link href="https://github.com/unclecode/crawl4ai" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üî•üï∑Ô∏è Crawl4AI: Open-source LLM Friendly Web Crawler &amp; Scrapper&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Crawl4AI (Async Version) üï∑Ô∏èü§ñ&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/unclecode/crawl4ai/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/unclecode/crawl4ai?style=social&#34; alt=&#34;GitHub Stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/unclecode/crawl4ai/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/unclecode/crawl4ai?style=social&#34; alt=&#34;GitHub Forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/unclecode/crawl4ai/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/unclecode/crawl4ai&#34; alt=&#34;GitHub Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/unclecode/crawl4ai/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-pr/unclecode/crawl4ai&#34; alt=&#34;GitHub Pull Requests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/unclecode/crawl4ai&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Crawl4AI simplifies asynchronous web crawling and data extraction, making it accessible for large language models (LLMs) and AI applications. üÜìüåê&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Looking for the synchronous version? Check out &lt;a href=&#34;https://raw.githubusercontent.com/unclecode/crawl4ai/main/README.sync.md&#34;&gt;README.sync.md&lt;/a&gt;. You can also access the previous version in the branch &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/v0.2.76&#34;&gt;V0.2.76&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Try it Now!&lt;/h2&gt; &#xA;&lt;p&gt;‚ú® Play around with this &lt;a href=&#34;https://colab.research.google.com/drive/1REChY6fXQf-EaVYLv0eHEWvzlYxGm0pd?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;‚ú® Visit our &lt;a href=&#34;https://crawl4ai.com/mkdocs/&#34;&gt;Documentation Website&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features ‚ú®&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üÜì Completely free and open-source&lt;/li&gt; &#xA; &lt;li&gt;üöÄ Blazing fast performance, outperforming many paid services&lt;/li&gt; &#xA; &lt;li&gt;ü§ñ LLM-friendly output formats (JSON, cleaned HTML, markdown)&lt;/li&gt; &#xA; &lt;li&gt;üåç Supports crawling multiple URLs simultaneously&lt;/li&gt; &#xA; &lt;li&gt;üé® Extracts and returns all media tags (Images, Audio, and Video)&lt;/li&gt; &#xA; &lt;li&gt;üîó Extracts all external and internal links&lt;/li&gt; &#xA; &lt;li&gt;üìö Extracts metadata from the page&lt;/li&gt; &#xA; &lt;li&gt;üîÑ Custom hooks for authentication, headers, and page modifications before crawling&lt;/li&gt; &#xA; &lt;li&gt;üïµÔ∏è User-agent customization&lt;/li&gt; &#xA; &lt;li&gt;üñºÔ∏è Takes screenshots of the page&lt;/li&gt; &#xA; &lt;li&gt;üìú Executes multiple custom JavaScripts before crawling&lt;/li&gt; &#xA; &lt;li&gt;üìä Generates structured output without LLM using JsonCssExtractionStrategy&lt;/li&gt; &#xA; &lt;li&gt;üìö Various chunking strategies: topic-based, regex, sentence, and more&lt;/li&gt; &#xA; &lt;li&gt;üß† Advanced extraction strategies: cosine clustering, LLM, and more&lt;/li&gt; &#xA; &lt;li&gt;üéØ CSS selector support for precise data extraction&lt;/li&gt; &#xA; &lt;li&gt;üìù Passes instructions/keywords to refine extraction&lt;/li&gt; &#xA; &lt;li&gt;üîí Proxy support for enhanced privacy and access&lt;/li&gt; &#xA; &lt;li&gt;üîÑ Session management for complex multi-page crawling scenarios&lt;/li&gt; &#xA; &lt;li&gt;üåê Asynchronous architecture for improved performance and scalability&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation üõ†Ô∏è&lt;/h2&gt; &#xA;&lt;p&gt;Crawl4AI offers flexible installation options to suit various use cases. You can install it as a Python package or use Docker.&lt;/p&gt; &#xA;&lt;h3&gt;Using pip üêç&lt;/h3&gt; &#xA;&lt;p&gt;Choose the installation option that best fits your needs:&lt;/p&gt; &#xA;&lt;h4&gt;Basic Installation&lt;/h4&gt; &#xA;&lt;p&gt;For basic web crawling and scraping tasks:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install crawl4ai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, this will install the asynchronous version of Crawl4AI, using Playwright for web crawling.&lt;/p&gt; &#xA;&lt;p&gt;üëâ Note: When you install Crawl4AI, the setup script should automatically install and set up Playwright. However, if you encounter any Playwright-related errors, you can manually install it using one of these methods:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Through the command line:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;playwright install&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If the above doesn&#39;t work, try this more specific command:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m playwright install chromium&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;This second method has proven to be more reliable in some cases.&lt;/p&gt; &#xA;&lt;h4&gt;Installation with Synchronous Version&lt;/h4&gt; &#xA;&lt;p&gt;If you need the synchronous version using Selenium:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install crawl4ai[sync]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Development Installation&lt;/h4&gt; &#xA;&lt;p&gt;For contributors who plan to modify the source code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/unclecode/crawl4ai.git&#xA;cd crawl4ai&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Using Docker üê≥&lt;/h3&gt; &#xA;&lt;p&gt;We&#39;re in the process of creating Docker images and pushing them to Docker Hub. This will provide an easy way to run Crawl4AI in a containerized environment. Stay tuned for updates!&lt;/p&gt; &#xA;&lt;p&gt;For more detailed installation instructions and options, please refer to our &lt;a href=&#34;https://crawl4ai.com/mkdocs/installation&#34;&gt;Installation Guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start üöÄ&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio&#xA;from crawl4ai import AsyncWebCrawler&#xA;&#xA;async def main():&#xA;    async with AsyncWebCrawler(verbose=True) as crawler:&#xA;        result = await crawler.arun(url=&#34;https://www.nbcnews.com/business&#34;)&#xA;        print(result.markdown)&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(main())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Advanced Usage üî¨&lt;/h2&gt; &#xA;&lt;h3&gt;Executing JavaScript and Using CSS Selectors&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio&#xA;from crawl4ai import AsyncWebCrawler&#xA;&#xA;async def main():&#xA;    async with AsyncWebCrawler(verbose=True) as crawler:&#xA;        js_code = [&#34;const loadMoreButton = Array.from(document.querySelectorAll(&#39;button&#39;)).find(button =&amp;gt; button.textContent.includes(&#39;Load More&#39;)); loadMoreButton &amp;amp;&amp;amp; loadMoreButton.click();&#34;]&#xA;        result = await crawler.arun(&#xA;            url=&#34;https://www.nbcnews.com/business&#34;,&#xA;            js_code=js_code,&#xA;            css_selector=&#34;article.tease-card&#34;,&#xA;            bypass_cache=True&#xA;        )&#xA;        print(result.extracted_content)&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(main())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Using a Proxy&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio&#xA;from crawl4ai import AsyncWebCrawler&#xA;&#xA;async def main():&#xA;    async with AsyncWebCrawler(verbose=True, proxy=&#34;http://127.0.0.1:7890&#34;) as crawler:&#xA;        result = await crawler.arun(&#xA;            url=&#34;https://www.nbcnews.com/business&#34;,&#xA;            bypass_cache=True&#xA;        )&#xA;        print(result.markdown)&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(main())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Extracting Structured Data without LLM&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;JsonCssExtractionStrategy&lt;/code&gt; allows for precise extraction of structured data from web pages using CSS selectors.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio&#xA;import json&#xA;from crawl4ai import AsyncWebCrawler&#xA;from crawl4ai.extraction_strategy import JsonCssExtractionStrategy&#xA;&#xA;async def extract_news_teasers():&#xA;    schema = {&#xA;        &#34;name&#34;: &#34;News Teaser Extractor&#34;,&#xA;        &#34;baseSelector&#34;: &#34;.wide-tease-item__wrapper&#34;,&#xA;        &#34;fields&#34;: [&#xA;            {&#xA;                &#34;name&#34;: &#34;category&#34;,&#xA;                &#34;selector&#34;: &#34;.unibrow span[data-testid=&#39;unibrow-text&#39;]&#34;,&#xA;                &#34;type&#34;: &#34;text&#34;,&#xA;            },&#xA;            {&#xA;                &#34;name&#34;: &#34;headline&#34;,&#xA;                &#34;selector&#34;: &#34;.wide-tease-item__headline&#34;,&#xA;                &#34;type&#34;: &#34;text&#34;,&#xA;            },&#xA;            {&#xA;                &#34;name&#34;: &#34;summary&#34;,&#xA;                &#34;selector&#34;: &#34;.wide-tease-item__description&#34;,&#xA;                &#34;type&#34;: &#34;text&#34;,&#xA;            },&#xA;            {&#xA;                &#34;name&#34;: &#34;time&#34;,&#xA;                &#34;selector&#34;: &#34;[data-testid=&#39;wide-tease-date&#39;]&#34;,&#xA;                &#34;type&#34;: &#34;text&#34;,&#xA;            },&#xA;            {&#xA;                &#34;name&#34;: &#34;image&#34;,&#xA;                &#34;type&#34;: &#34;nested&#34;,&#xA;                &#34;selector&#34;: &#34;picture.teasePicture img&#34;,&#xA;                &#34;fields&#34;: [&#xA;                    {&#34;name&#34;: &#34;src&#34;, &#34;type&#34;: &#34;attribute&#34;, &#34;attribute&#34;: &#34;src&#34;},&#xA;                    {&#34;name&#34;: &#34;alt&#34;, &#34;type&#34;: &#34;attribute&#34;, &#34;attribute&#34;: &#34;alt&#34;},&#xA;                ],&#xA;            },&#xA;            {&#xA;                &#34;name&#34;: &#34;link&#34;,&#xA;                &#34;selector&#34;: &#34;a[href]&#34;,&#xA;                &#34;type&#34;: &#34;attribute&#34;,&#xA;                &#34;attribute&#34;: &#34;href&#34;,&#xA;            },&#xA;        ],&#xA;    }&#xA;&#xA;    extraction_strategy = JsonCssExtractionStrategy(schema, verbose=True)&#xA;&#xA;    async with AsyncWebCrawler(verbose=True) as crawler:&#xA;        result = await crawler.arun(&#xA;            url=&#34;https://www.nbcnews.com/business&#34;,&#xA;            extraction_strategy=extraction_strategy,&#xA;            bypass_cache=True,&#xA;        )&#xA;&#xA;        assert result.success, &#34;Failed to crawl the page&#34;&#xA;&#xA;        news_teasers = json.loads(result.extracted_content)&#xA;        print(f&#34;Successfully extracted {len(news_teasers)} news teasers&#34;)&#xA;        print(json.dumps(news_teasers[0], indent=2))&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(extract_news_teasers())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more advanced usage examples, check out our &lt;a href=&#34;https://crawl4ai.com/mkdocs/full_details/advanced_jsoncss_extraction.md&#34;&gt;Examples&lt;/a&gt; section in the documentation.&lt;/p&gt; &#xA;&lt;h3&gt;Extracting Structured Data with OpenAI&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os&#xA;import asyncio&#xA;from crawl4ai import AsyncWebCrawler&#xA;from crawl4ai.extraction_strategy import LLMExtractionStrategy&#xA;from pydantic import BaseModel, Field&#xA;&#xA;class OpenAIModelFee(BaseModel):&#xA;    model_name: str = Field(..., description=&#34;Name of the OpenAI model.&#34;)&#xA;    input_fee: str = Field(..., description=&#34;Fee for input token for the OpenAI model.&#34;)&#xA;    output_fee: str = Field(..., description=&#34;Fee for output token for the OpenAI model.&#34;)&#xA;&#xA;async def main():&#xA;    async with AsyncWebCrawler(verbose=True) as crawler:&#xA;        result = await crawler.arun(&#xA;            url=&#39;https://openai.com/api/pricing/&#39;,&#xA;            word_count_threshold=1,&#xA;            extraction_strategy=LLMExtractionStrategy(&#xA;                provider=&#34;openai/gpt-4o&#34;, api_token=os.getenv(&#39;OPENAI_API_KEY&#39;), &#xA;                schema=OpenAIModelFee.schema(),&#xA;                extraction_type=&#34;schema&#34;,&#xA;                instruction=&#34;&#34;&#34;From the crawled content, extract all mentioned model names along with their fees for input and output tokens. &#xA;                Do not miss any models in the entire content. One extracted model JSON format should look like this: &#xA;                {&#34;model_name&#34;: &#34;GPT-4&#34;, &#34;input_fee&#34;: &#34;US$10.00 / 1M tokens&#34;, &#34;output_fee&#34;: &#34;US$30.00 / 1M tokens&#34;}.&#34;&#34;&#34;&#xA;            ),            &#xA;            bypass_cache=True,&#xA;        )&#xA;        print(result.extracted_content)&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(main())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Session Management and Dynamic Content Crawling&lt;/h3&gt; &#xA;&lt;p&gt;Crawl4AI excels at handling complex scenarios, such as crawling multiple pages with dynamic content loaded via JavaScript. Here&#39;s an example of crawling GitHub commits across multiple pages:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio&#xA;import re&#xA;from bs4 import BeautifulSoup&#xA;from crawl4ai import AsyncWebCrawler&#xA;&#xA;async def crawl_typescript_commits():&#xA;    first_commit = &#34;&#34;&#xA;    async def on_execution_started(page):&#xA;        nonlocal first_commit &#xA;        try:&#xA;            while True:&#xA;                await page.wait_for_selector(&#39;li.Box-sc-g0xbh4-0 h4&#39;)&#xA;                commit = await page.query_selector(&#39;li.Box-sc-g0xbh4-0 h4&#39;)&#xA;                commit = await commit.evaluate(&#39;(element) =&amp;gt; element.textContent&#39;)&#xA;                commit = re.sub(r&#39;\s+&#39;, &#39;&#39;, commit)&#xA;                if commit and commit != first_commit:&#xA;                    first_commit = commit&#xA;                    break&#xA;                await asyncio.sleep(0.5)&#xA;        except Exception as e:&#xA;            print(f&#34;Warning: New content didn&#39;t appear after JavaScript execution: {e}&#34;)&#xA;&#xA;    async with AsyncWebCrawler(verbose=True) as crawler:&#xA;        crawler.crawler_strategy.set_hook(&#39;on_execution_started&#39;, on_execution_started)&#xA;&#xA;        url = &#34;https://github.com/microsoft/TypeScript/commits/main&#34;&#xA;        session_id = &#34;typescript_commits_session&#34;&#xA;        all_commits = []&#xA;&#xA;        js_next_page = &#34;&#34;&#34;&#xA;        const button = document.querySelector(&#39;a[data-testid=&#34;pagination-next-button&#34;]&#39;);&#xA;        if (button) button.click();&#xA;        &#34;&#34;&#34;&#xA;&#xA;        for page in range(3):  # Crawl 3 pages&#xA;            result = await crawler.arun(&#xA;                url=url,&#xA;                session_id=session_id,&#xA;                css_selector=&#34;li.Box-sc-g0xbh4-0&#34;,&#xA;                js=js_next_page if page &amp;gt; 0 else None,&#xA;                bypass_cache=True,&#xA;                js_only=page &amp;gt; 0&#xA;            )&#xA;&#xA;            assert result.success, f&#34;Failed to crawl page {page + 1}&#34;&#xA;&#xA;            soup = BeautifulSoup(result.cleaned_html, &#39;html.parser&#39;)&#xA;            commits = soup.select(&#34;li&#34;)&#xA;            all_commits.extend(commits)&#xA;&#xA;            print(f&#34;Page {page + 1}: Found {len(commits)} commits&#34;)&#xA;&#xA;        await crawler.crawler_strategy.kill_session(session_id)&#xA;        print(f&#34;Successfully crawled {len(all_commits)} commits across 3 pages&#34;)&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(crawl_typescript_commits())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This example demonstrates Crawl4AI&#39;s ability to handle complex scenarios where content is loaded asynchronously. It crawls multiple pages of GitHub commits, executing JavaScript to load new content and using custom hooks to ensure data is loaded before proceeding.&lt;/p&gt; &#xA;&lt;p&gt;For more advanced usage examples, check out our &lt;a href=&#34;https://crawl4ai.com/mkdocs/full_details/session_based_crawling.md&#34;&gt;Examples&lt;/a&gt; section in the documentation.&lt;/p&gt; &#xA;&lt;h2&gt;Speed Comparison üöÄ&lt;/h2&gt; &#xA;&lt;p&gt;Crawl4AI is designed with speed as a primary focus. Our goal is to provide the fastest possible response with high-quality data extraction, minimizing abstractions between the data and the user.&lt;/p&gt; &#xA;&lt;p&gt;We&#39;ve conducted a speed comparison between Crawl4AI and Firecrawl, a paid service. The results demonstrate Crawl4AI&#39;s superior performance:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Firecrawl:&#xA;Time taken: 7.02 seconds&#xA;Content length: 42074 characters&#xA;Images found: 49&#xA;&#xA;Crawl4AI (simple crawl):&#xA;Time taken: 1.60 seconds&#xA;Content length: 18238 characters&#xA;Images found: 49&#xA;&#xA;Crawl4AI (with JavaScript execution):&#xA;Time taken: 4.64 seconds&#xA;Content length: 40869 characters&#xA;Images found: 89&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;As you can see, Crawl4AI outperforms Firecrawl significantly:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Simple crawl: Crawl4AI is over 4 times faster than Firecrawl.&lt;/li&gt; &#xA; &lt;li&gt;With JavaScript execution: Even when executing JavaScript to load more content (doubling the number of images found), Crawl4AI is still faster than Firecrawl&#39;s simple crawl.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can find the full comparison code in our repository at &lt;code&gt;docs/examples/crawl4ai_vs_firecrawl.py&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation üìö&lt;/h2&gt; &#xA;&lt;p&gt;For detailed documentation, including installation instructions, advanced features, and API reference, visit our &lt;a href=&#34;https://crawl4ai.com/mkdocs/&#34;&gt;Documentation Website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing ü§ù&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions from the open-source community. Check out our &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/CONTRIBUTING.md&#34;&gt;contribution guidelines&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;License üìÑ&lt;/h2&gt; &#xA;&lt;p&gt;Crawl4AI is released under the &lt;a href=&#34;https://github.com/unclecode/crawl4ai/raw/main/LICENSE&#34;&gt;Apache 2.0 License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contact üìß&lt;/h2&gt; &#xA;&lt;p&gt;For questions, suggestions, or feedback, feel free to reach out:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GitHub: &lt;a href=&#34;https://github.com/unclecode&#34;&gt;unclecode&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Twitter: &lt;a href=&#34;https://twitter.com/unclecode&#34;&gt;@unclecode&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Website: &lt;a href=&#34;https://crawl4ai.com&#34;&gt;crawl4ai.com&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Happy Crawling! üï∏Ô∏èüöÄ&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#unclecode/crawl4ai&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=unclecode/crawl4ai&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>RVC-Project/Retrieval-based-Voice-Conversion-WebUI</title>
    <updated>2024-09-30T01:28:34Z</updated>
    <id>tag:github.com,2024-09-30:/RVC-Project/Retrieval-based-Voice-Conversion-WebUI</id>
    <link href="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Easily train a good VC model with voice data &lt;= 10 mins!&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;Retrieval-based-Voice-Conversion-WebUI&lt;/h1&gt; ‰∏Ä‰∏™Âü∫‰∫éVITSÁöÑÁÆÄÂçïÊòìÁî®ÁöÑÂèòÂ£∞Ê°ÜÊû∂&#xA; &lt;br&gt;&#xA; &lt;br&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/made_with-%E2%9D%A4-red?style=for-the-badge&amp;amp;labelColor=orange&#34; alt=&#34;madewithlove&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://counter.seku.su/cmoe?name=rvc&amp;amp;theme=r34&#34;&gt;&lt;br&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/blob/main/Retrieval_based_Voice_Conversion_WebUI.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&amp;amp;logo=googlecolab&amp;amp;color=525252&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/LICENSE-MIT-green.svg?style=for-the-badge&#34; alt=&#34;Licence&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/lj1995/VoiceConversionWebUI/tree/main/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20-Spaces-yellow.svg?style=for-the-badge&#34; alt=&#34;Huggingface&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://discord.gg/HcsmBBGyVk&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/RVC%20Developers-Discord-7289DA?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/raw/main/docs/Changelog_CN.md&#34;&gt;&lt;strong&gt;Êõ¥Êñ∞Êó•Âøó&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%A7%A3%E7%AD%94&#34;&gt;&lt;strong&gt;Â∏∏ËßÅÈóÆÈ¢òËß£Á≠î&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/Autodl%E8%AE%AD%E7%BB%83RVC%C2%B7AI%E6%AD%8C%E6%89%8B%E6%95%99%E7%A8%8B&#34;&gt;&lt;strong&gt;AutoDL¬∑5ÊØõÈí±ËÆ≠ÁªÉAIÊ≠åÊâã&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/Autodl%E8%AE%AD%E7%BB%83RVC%C2%B7AI%E6%AD%8C%E6%89%8B%E6%95%99%E7%A8%8B%5D(https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/%E5%AF%B9%E7%85%A7%E5%AE%9E%E9%AA%8C%C2%B7%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95)&#34;&gt;&lt;strong&gt;ÂØπÁÖßÂÆûÈ™åËÆ∞ÂΩï&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://modelscope.cn/studios/FlowerCry/RVCv2demo&#34;&gt;&lt;strong&gt;Âú®Á∫øÊºîÁ§∫&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/en/README.en.md&#34;&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/README.md&#34;&gt;&lt;strong&gt;‰∏≠ÊñáÁÆÄ‰Ωì&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/jp/README.ja.md&#34;&gt;&lt;strong&gt;Êó•Êú¨Ë™û&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/kr/README.ko.md&#34;&gt;&lt;strong&gt;ÌïúÍµ≠Ïñ¥&lt;/strong&gt;&lt;/a&gt; (&lt;a href=&#34;https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/kr/README.ko.han.md&#34;&gt;&lt;strong&gt;ÈüìÂúãË™û&lt;/strong&gt;&lt;/a&gt;) | &lt;a href=&#34;https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/fr/README.fr.md&#34;&gt;&lt;strong&gt;Fran√ßais&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/tr/README.tr.md&#34;&gt;&lt;strong&gt;T√ºrk√ße&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/docs/pt/README.pt.md&#34;&gt;&lt;strong&gt;Portugu√™s&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Â∫ïÊ®°‰ΩøÁî®Êé•Ëøë50Â∞èÊó∂ÁöÑÂºÄÊ∫êÈ´òË¥®ÈáèVCTKËÆ≠ÁªÉÈõÜËÆ≠ÁªÉÔºåÊó†ÁâàÊùÉÊñπÈù¢ÁöÑÈ°æËôëÔºåËØ∑Â§ßÂÆ∂ÊîæÂøÉ‰ΩøÁî®&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ËØ∑ÊúüÂæÖRVCv3ÁöÑÂ∫ïÊ®°ÔºåÂèÇÊï∞Êõ¥Â§ßÔºåÊï∞ÊçÆÊõ¥Â§ßÔºåÊïàÊûúÊõ¥Â•ΩÔºåÂü∫Êú¨ÊåÅÂπ≥ÁöÑÊé®ÁêÜÈÄüÂ∫¶ÔºåÈúÄË¶ÅËÆ≠ÁªÉÊï∞ÊçÆÈáèÊõ¥Â∞ë„ÄÇ&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ËÆ≠ÁªÉÊé®ÁêÜÁïåÈù¢&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ÂÆûÊó∂ÂèòÂ£∞ÁïåÈù¢&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/assets/129054828/092e5c12-0d49-4168-a590-0b0ef6a4f630&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/assets/129054828/730b4114-8805-44a1-ab1a-04668f3c30a6&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;go-web.bat&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;go-realtime-gui.bat&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ÂèØ‰ª•Ëá™Áî±ÈÄâÊã©ÊÉ≥Ë¶ÅÊâßË°åÁöÑÊìç‰Ωú„ÄÇ&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Êàë‰ª¨Â∑≤ÁªèÂÆûÁé∞Á´ØÂà∞Á´Ø170msÂª∂Ëøü„ÄÇÂ¶Ç‰ΩøÁî®ASIOËæìÂÖ•ËæìÂá∫ËÆæÂ§áÔºåÂ∑≤ËÉΩÂÆûÁé∞Á´ØÂà∞Á´Ø90msÂª∂ËøüÔºå‰ΩÜÈùûÂ∏∏‰æùËµñÁ°¨‰ª∂È©±Âä®ÊîØÊåÅ„ÄÇ&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;ÁÆÄ‰ªã&lt;/h2&gt; &#xA;&lt;p&gt;Êú¨‰ªìÂ∫ìÂÖ∑Êúâ‰ª•‰∏ãÁâπÁÇπ&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‰ΩøÁî®top1Ê£ÄÁ¥¢ÊõøÊç¢ËæìÂÖ•Ê∫êÁâπÂæÅ‰∏∫ËÆ≠ÁªÉÈõÜÁâπÂæÅÊù•ÊùúÁªùÈü≥Ëâ≤Ê≥ÑÊºè&lt;/li&gt; &#xA; &lt;li&gt;Âç≥‰æøÂú®Áõ∏ÂØπËæÉÂ∑ÆÁöÑÊòæÂç°‰∏ä‰πüËÉΩÂø´ÈÄüËÆ≠ÁªÉ&lt;/li&gt; &#xA; &lt;li&gt;‰ΩøÁî®Â∞ëÈáèÊï∞ÊçÆËøõË°åËÆ≠ÁªÉ‰πüËÉΩÂæóÂà∞ËæÉÂ•ΩÁªìÊûú(Êé®ËçêËá≥Â∞ëÊî∂ÈõÜ10ÂàÜÈíü‰ΩéÂ∫ïÂô™ËØ≠Èü≥Êï∞ÊçÆ)&lt;/li&gt; &#xA; &lt;li&gt;ÂèØ‰ª•ÈÄöËøáÊ®°ÂûãËûçÂêàÊù•ÊîπÂèòÈü≥Ëâ≤(ÂÄüÂä©ckptÂ§ÑÁêÜÈÄâÈ°πÂç°‰∏≠ÁöÑckpt-merge)&lt;/li&gt; &#xA; &lt;li&gt;ÁÆÄÂçïÊòìÁî®ÁöÑÁΩëÈ°µÁïåÈù¢&lt;/li&gt; &#xA; &lt;li&gt;ÂèØË∞ÉÁî®UVR5Ê®°ÂûãÊù•Âø´ÈÄüÂàÜÁ¶ª‰∫∫Â£∞Âíå‰º¥Â•è&lt;/li&gt; &#xA; &lt;li&gt;‰ΩøÁî®ÊúÄÂÖàËøõÁöÑ&lt;a href=&#34;https://raw.githubusercontent.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/main/#%E5%8F%82%E8%80%83%E9%A1%B9%E7%9B%AE&#34;&gt;‰∫∫Â£∞Èü≥È´òÊèêÂèñÁÆóÊ≥ïInterSpeech2023-RMVPE&lt;/a&gt;Ê†πÁªùÂìëÈü≥ÈóÆÈ¢ò„ÄÇÊïàÊûúÊúÄÂ•ΩÔºàÊòæËëóÂú∞Ôºâ‰ΩÜÊØîcrepe_fullÊõ¥Âø´„ÄÅËµÑÊ∫êÂç†Áî®Êõ¥Â∞è&lt;/li&gt; &#xA; &lt;li&gt;AÂç°IÂç°Âä†ÈÄüÊîØÊåÅ&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;ÁÇπÊ≠§Êü•ÁúãÊàë‰ª¨ÁöÑ&lt;a href=&#34;https://www.bilibili.com/video/BV1pm4y1z7Gm/&#34;&gt;ÊºîÁ§∫ËßÜÈ¢ë&lt;/a&gt; !&lt;/p&gt; &#xA;&lt;h2&gt;ÁéØÂ¢ÉÈÖçÁΩÆ&lt;/h2&gt; &#xA;&lt;p&gt;‰ª•‰∏ãÊåá‰ª§ÈúÄÂú® Python ÁâàÊú¨Â§ß‰∫é3.8ÁöÑÁéØÂ¢É‰∏≠ÊâßË°å„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;Windows/Linux/MacOSÁ≠âÂπ≥Âè∞ÈÄöÁî®ÊñπÊ≥ï&lt;/h3&gt; &#xA;&lt;p&gt;‰∏ãÂàóÊñπÊ≥ï‰ªªÈÄâÂÖ∂‰∏Ä„ÄÇ&lt;/p&gt; &#xA;&lt;h4&gt;1. ÈÄöËøá pip ÂÆâË£Ö‰æùËµñ&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ÂÆâË£ÖPytorchÂèäÂÖ∂Ê†∏ÂøÉ‰æùËµñÔºåËã•Â∑≤ÂÆâË£ÖÂàôË∑≥Ëøá„ÄÇÂèÇËÄÉËá™: &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install torch torchvision torchaudio&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Â¶ÇÊûúÊòØ win Á≥ªÁªü + Nvidia Ampere Êû∂ÊûÑ(RTX30xx)ÔºåÊ†πÊçÆ #21 ÁöÑÁªèÈ™åÔºåÈúÄË¶ÅÊåáÂÆö pytorch ÂØπÂ∫îÁöÑ cuda ÁâàÊú¨&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Ê†πÊçÆËá™Â∑±ÁöÑÊòæÂç°ÂÆâË£ÖÂØπÂ∫î‰æùËµñ&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;NÂç°&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;AÂç°/IÂç°&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements-dml.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;AÂç°ROCM(Linux)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements-amd.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;IÂç°IPEX(Linux)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements-ipex.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2. ÈÄöËøá poetry Êù•ÂÆâË£Ö‰æùËµñ&lt;/h4&gt; &#xA;&lt;p&gt;ÂÆâË£Ö Poetry ‰æùËµñÁÆ°ÁêÜÂ∑•ÂÖ∑ÔºåËã•Â∑≤ÂÆâË£ÖÂàôË∑≥Ëøá„ÄÇÂèÇËÄÉËá™: &lt;a href=&#34;https://python-poetry.org/docs/#installation&#34;&gt;https://python-poetry.org/docs/#installation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -sSL https://install.python-poetry.org | python3 -&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ÈÄöËøá Poetry ÂÆâË£Ö‰æùËµñÊó∂Ôºåpython Âª∫ËÆÆ‰ΩøÁî® 3.7-3.10 ÁâàÊú¨ÔºåÂÖ∂‰ΩôÁâàÊú¨Âú®ÂÆâË£Ö llvmlite==0.39.0 Êó∂‰ºöÂá∫Áé∞ÂÜ≤Á™Å&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;poetry init -n&#xA;poetry env use &#34;path to your python.exe&#34;&#xA;poetry run pip install -r requirments.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;MacOS&lt;/h3&gt; &#xA;&lt;p&gt;ÂèØ‰ª•ÈÄöËøá &lt;code&gt;run.sh&lt;/code&gt; Êù•ÂÆâË£Ö‰æùËµñ&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sh ./run.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ÂÖ∂‰ªñÈ¢ÑÊ®°ÂûãÂáÜÂ§á&lt;/h2&gt; &#xA;&lt;p&gt;RVCÈúÄË¶ÅÂÖ∂‰ªñ‰∏Ä‰∫õÈ¢ÑÊ®°ÂûãÊù•Êé®ÁêÜÂíåËÆ≠ÁªÉ„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;‰Ω†ÂèØ‰ª•‰ªéÊàë‰ª¨ÁöÑ&lt;a href=&#34;https://huggingface.co/lj1995/VoiceConversionWebUI/tree/main/&#34;&gt;Hugging Face space&lt;/a&gt;‰∏ãËΩΩÂà∞Ëøô‰∫õÊ®°Âûã„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;1. ‰∏ãËΩΩ assets&lt;/h3&gt; &#xA;&lt;p&gt;‰ª•‰∏ãÊòØ‰∏Ä‰ªΩÊ∏ÖÂçïÔºåÂåÖÊã¨‰∫ÜÊâÄÊúâRVCÊâÄÈúÄÁöÑÈ¢ÑÊ®°ÂûãÂíåÂÖ∂‰ªñÊñá‰ª∂ÁöÑÂêçÁß∞„ÄÇ‰Ω†ÂèØ‰ª•Âú®&lt;code&gt;tools&lt;/code&gt;Êñá‰ª∂Â§πÊâæÂà∞‰∏ãËΩΩÂÆÉ‰ª¨ÁöÑËÑöÊú¨„ÄÇ&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;./assets/hubert/hubert_base.pt&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;./assets/pretrained&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;./assets/uvr5_weights&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;ÊÉ≥‰ΩøÁî®v2ÁâàÊú¨Ê®°ÂûãÁöÑËØùÔºåÈúÄË¶ÅÈ¢ùÂ§ñ‰∏ãËΩΩ&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;./assets/pretrained_v2&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2. ÂÆâË£Ö ffmpeg&lt;/h3&gt; &#xA;&lt;p&gt;Ëã•ffmpegÂíåffprobeÂ∑≤ÂÆâË£ÖÂàôË∑≥Ëøá„ÄÇ&lt;/p&gt; &#xA;&lt;h4&gt;Ubuntu/Debian Áî®Êà∑&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt install ffmpeg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;MacOS Áî®Êà∑&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install ffmpeg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Windows Áî®Êà∑&lt;/h4&gt; &#xA;&lt;p&gt;‰∏ãËΩΩÂêéÊîæÁΩÆÂú®Ê†πÁõÆÂΩï„ÄÇ&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;‰∏ãËΩΩ&lt;a href=&#34;https://huggingface.co/lj1995/VoiceConversionWebUI/blob/main/ffmpeg.exe&#34;&gt;ffmpeg.exe&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;‰∏ãËΩΩ&lt;a href=&#34;https://huggingface.co/lj1995/VoiceConversionWebUI/blob/main/ffprobe.exe&#34;&gt;ffprobe.exe&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;3. ‰∏ãËΩΩ rmvpe ‰∫∫Â£∞Èü≥È´òÊèêÂèñÁÆóÊ≥ïÊâÄÈúÄÊñá‰ª∂&lt;/h3&gt; &#xA;&lt;p&gt;Â¶ÇÊûú‰Ω†ÊÉ≥‰ΩøÁî®ÊúÄÊñ∞ÁöÑRMVPE‰∫∫Â£∞Èü≥È´òÊèêÂèñÁÆóÊ≥ïÔºåÂàô‰Ω†ÈúÄË¶Å‰∏ãËΩΩÈü≥È´òÊèêÂèñÊ®°ÂûãÂèÇÊï∞Âπ∂ÊîæÁΩÆ‰∫éRVCÊ†πÁõÆÂΩï„ÄÇ&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‰∏ãËΩΩ&lt;a href=&#34;https://huggingface.co/lj1995/VoiceConversionWebUI/blob/main/rmvpe.pt&#34;&gt;rmvpe.pt&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;‰∏ãËΩΩ rmvpe ÁöÑ dml ÁéØÂ¢É(ÂèØÈÄâ, AÂç°/IÂç°Áî®Êà∑)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‰∏ãËΩΩ&lt;a href=&#34;https://huggingface.co/lj1995/VoiceConversionWebUI/blob/main/rmvpe.onnx&#34;&gt;rmvpe.onnx&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;4. AMDÊòæÂç°Rocm(ÂèØÈÄâ, ‰ªÖLinux)&lt;/h3&gt; &#xA;&lt;p&gt;Â¶ÇÊûú‰Ω†ÊÉ≥Âü∫‰∫éAMDÁöÑRocmÊäÄÊúØÂú®LinuxÁ≥ªÁªü‰∏äËøêË°åRVCÔºåËØ∑ÂÖàÂú®&lt;a href=&#34;https://rocm.docs.amd.com/en/latest/deploy/linux/os-native/install.html&#34;&gt;ËøôÈáå&lt;/a&gt;ÂÆâË£ÖÊâÄÈúÄÁöÑÈ©±Âä®„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Ëã•‰Ω†‰ΩøÁî®ÁöÑÊòØArch LinuxÔºåÂèØ‰ª•‰ΩøÁî®pacmanÊù•ÂÆâË£ÖÊâÄÈúÄÈ©±Âä®Ôºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pacman -S rocm-hip-sdk rocm-opencl-sdk&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ÂØπ‰∫éÊüê‰∫õÂûãÂè∑ÁöÑÊòæÂç°Ôºå‰Ω†ÂèØËÉΩÈúÄË¶ÅÈ¢ùÂ§ñÈÖçÁΩÆÂ¶Ç‰∏ãÁöÑÁéØÂ¢ÉÂèòÈáèÔºàÂ¶ÇÔºöRX6700XTÔºâÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export ROCM_PATH=/opt/rocm&#xA;export HSA_OVERRIDE_GFX_VERSION=10.3.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ÂêåÊó∂Á°Æ‰øù‰Ω†ÁöÑÂΩìÂâçÁî®Êà∑Â§Ñ‰∫é&lt;code&gt;render&lt;/code&gt;‰∏é&lt;code&gt;video&lt;/code&gt;Áî®Êà∑ÁªÑÂÜÖÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo usermod -aG render $USERNAME&#xA;sudo usermod -aG video $USERNAME&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ÂºÄÂßã‰ΩøÁî®&lt;/h2&gt; &#xA;&lt;h3&gt;Áõ¥Êé•ÂêØÂä®&lt;/h3&gt; &#xA;&lt;p&gt;‰ΩøÁî®‰ª•‰∏ãÊåá‰ª§Êù•ÂêØÂä® WebUI&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python infer-web.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Ëã•ÂÖàÂâç‰ΩøÁî® Poetry ÂÆâË£Ö‰æùËµñÔºåÂàôÂèØ‰ª•ÈÄöËøá‰ª•‰∏ãÊñπÂºèÂêØÂä®WebUI&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;poetry run python infer-web.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;‰ΩøÁî®Êï¥ÂêàÂåÖ&lt;/h3&gt; &#xA;&lt;p&gt;‰∏ãËΩΩÂπ∂Ëß£Âéã&lt;code&gt;RVC-beta.7z&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Windows Áî®Êà∑&lt;/h4&gt; &#xA;&lt;p&gt;ÂèåÂáª&lt;code&gt;go-web.bat&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h4&gt;MacOS Áî®Êà∑&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sh ./run.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ÂØπ‰∫éÈúÄË¶Å‰ΩøÁî®IPEXÊäÄÊúØÁöÑIÂç°Áî®Êà∑(‰ªÖLinux)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;source /opt/intel/oneapi/setvars.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ÂèÇËÄÉÈ°πÁõÆ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/auspicious3000/contentvec/&#34;&gt;ContentVec&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jaywalnut310/vits&#34;&gt;VITS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jik876/hifi-gan&#34;&gt;HIFIGAN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gradio-app/gradio&#34;&gt;Gradio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/FFmpeg/FFmpeg&#34;&gt;FFmpeg&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Anjok07/ultimatevocalremovergui&#34;&gt;Ultimate Vocal Remover&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openvpi/audio-slicer&#34;&gt;audio-slicer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Dream-High/RMVPE&#34;&gt;Vocal pitch extraction:RMVPE&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The pretrained model is trained and tested by &lt;a href=&#34;https://github.com/yxlllc/RMVPE&#34;&gt;yxlllc&lt;/a&gt; and &lt;a href=&#34;https://github.com/RVC-Boss&#34;&gt;RVC-Boss&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ÊÑüË∞¢ÊâÄÊúâË¥°ÁåÆËÄÖ‰ΩúÂá∫ÁöÑÂä™Âäõ&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/graphs/contributors&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=RVC-Project/Retrieval-based-Voice-Conversion-WebUI&#34;&gt; &lt;/a&gt;</summary>
  </entry>
</feed>