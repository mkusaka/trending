<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-24T01:34:07Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>LeadCoding/3-weeks-Google-Prep</title>
    <updated>2022-06-24T01:34:07Z</updated>
    <id>tag:github.com,2022-06-24:/LeadCoding/3-weeks-Google-Prep</id>
    <link href="https://github.com/LeadCoding/3-weeks-Google-Prep" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;3-weeks-Google-Prep&lt;/h1&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://youtu.be/YlP7CWpHgS4&#34;&gt;How I Cracked my Dream Company GOOGLE&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=NXQi_g1pVqI/&#34;&gt;For rest of the topics I reffered my DSA Sheet Questions&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;These are some selected questions apart from my DSA Sheet that I solved to prepare for my Google interviews&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Dynamic Programming &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Digit DP &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;MagicNumbers.cpp&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Barcode.cpp&lt;/li&gt; &#xA;   &lt;li&gt;cherryPick.cpp&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Graphs &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;1.Representation &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;List.cpp&lt;/li&gt; &#xA;     &lt;li&gt;Matrix.cpp&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;10.Articulation Point and Bridges &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;CutEdges.cpp&lt;/li&gt; &#xA;     &lt;li&gt;CutVertex.cpp&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;2.CycleDetection &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;1.DetectCycleUndirectedGraph.cpp&lt;/li&gt; &#xA;     &lt;li&gt;2.DetectCycleDirectedGraph.cpp&lt;/li&gt; &#xA;     &lt;li&gt;3.IsBipartite.cpp&lt;/li&gt; &#xA;     &lt;li&gt;4.LengthOfSmallestCycle.cpp&lt;/li&gt; &#xA;     &lt;li&gt;5.DetectCyclesin2DGrid.cpp&lt;/li&gt; &#xA;     &lt;li&gt;6.Maximum Employees to Be Invited to a Meeting.cpp&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;3.DSU &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;1.Redundant Connection II.cpp&lt;/li&gt; &#xA;     &lt;li&gt;DSUSnippetClass.cpp&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;4.Topological Sort &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;GameRoutes.cpp&lt;/li&gt; &#xA;     &lt;li&gt;LargestColorValueInADirectedGraph.cpp&lt;/li&gt; &#xA;     &lt;li&gt;TopologicalBFS.cpp&lt;/li&gt; &#xA;     &lt;li&gt;TopologicalDFS.cpp&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;5.MST &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Kruskals.cpp&lt;/li&gt; &#xA;     &lt;li&gt;Prims.cpp&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;6.BFS &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;MultiSourceBFS.cpp&lt;/li&gt; &#xA;     &lt;li&gt;ValidBFS.cpp&lt;/li&gt; &#xA;     &lt;li&gt;WorldLadder2.cpp&lt;/li&gt; &#xA;     &lt;li&gt;boredom.cpp&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;7.DFS &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;ConnectedComponents.cpp&lt;/li&gt; &#xA;     &lt;li&gt;DFSwithStoppingCondition.cpp&lt;/li&gt; &#xA;     &lt;li&gt;JourneyToTheMoon.cpp&lt;/li&gt; &#xA;     &lt;li&gt;ReconstructItinerary.cpp&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;8.Shortest Paths Algo &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;BellmanFord.cpp&lt;/li&gt; &#xA;     &lt;li&gt;Dijkstras.cpp&lt;/li&gt; &#xA;     &lt;li&gt;FLoydWarshall.cpp&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;9.StronglyConnected &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;kosarju.cpp&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Readme.md&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Rest of the Topic &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Readme.md&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Rolling hash &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;rabin_carp.cpp&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;SegmentTree &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;SegmentTreeSnippetClass.cpp&lt;/li&gt; &#xA;   &lt;li&gt;Xenia.cpp&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;README.md&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;BONUS ;) &lt;a href=&#34;https://www.youtube.com/c/LeadCodingbyFRAZ&#34;&gt;Learn from me&lt;/a&gt;&lt;/h2&gt;</summary>
  </entry>
  <entry>
    <title>scottbez1/smartknob</title>
    <updated>2022-06-24T01:34:07Z</updated>
    <id>tag:github.com,2022-06-24:/scottbez1/smartknob</id>
    <link href="https://github.com/scottbez1/smartknob" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Haptic input knob with software-defined endstops and virtual detents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SmartKnob&lt;/h1&gt; &#xA;&lt;p&gt;SmartKnob is an open-source input device with software-configurable endstops and virtual detents.&lt;/p&gt; &#xA;&lt;p&gt;A brushless gimbal motor is paired with a magnetic encoder to provide closed-loop torque feedback control, making it possible to dynamically create and adjust the feel of detents and endstops.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/scottbez1/smartknob/actions/workflows/electronics.yml&#34;&gt;&lt;img src=&#34;https://github.com/scottbez1/smartknob/actions/workflows/electronics.yml/badge.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/scottbez1/smartknob/actions/workflows/pio.yml&#34;&gt;&lt;img src=&#34;https://github.com/scottbez1/smartknob/actions/workflows/pio.yml/badge.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Designs&lt;/h1&gt; &#xA;&lt;h2&gt;SmartKnob View&lt;/h2&gt; &#xA;&lt;p&gt;Premium SmartKnob experience. Under active development.&lt;/p&gt; &#xA;&lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Update (2022-03-24): As a result of the popularity of this project, it seems like the recommended motors are unfortunately no longer available.&lt;/strong&gt; I expect that these motors are simply no longer in production and therefore limited stock was available (for future reference in case you find them being sold elsewhere at a higher price, they were originally selling for US$2.56 each before this project was published). However... üëá&lt;/p&gt; &#xA;&lt;p&gt;üí° &lt;strong&gt;There is an ongoing search for new motors in &lt;a href=&#34;https://github.com/scottbez1/smartknob/issues/16&#34;&gt;issue #16&lt;/a&gt;&lt;/strong&gt; - follow along there for the latest info (or join in and help us find a good replacement). Any change in motor will likely require substantial redesigns, so &lt;em&gt;don&#39;t order PCBs/printed parts until there is more clarity on the motor.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;240x240 round LCD (&#34;GC9A01&#34;), protected by 39.5mm watch glass on rotor&lt;/li&gt; &#xA; &lt;li&gt;BLDC gimbal motor, with a hollow shaft for mechanically &amp;amp; electrically connecting the LCD&lt;/li&gt; &#xA; &lt;li&gt;Powered by ESP32-PICO-V3-02 (Lilygo TMicro32 Plus module)&lt;/li&gt; &#xA; &lt;li&gt;PCB flexure and strain gauges used for press detection (haptic feedback provided via the motor)&lt;/li&gt; &#xA; &lt;li&gt;8 side-firing RGB LEDs (SK6812-SIDE-A) illuminate ring around the knob&lt;/li&gt; &#xA; &lt;li&gt;USB-C (2.0) connector for 5V power and serial data/programming (CH340)&lt;/li&gt; &#xA; &lt;li&gt;VEML7700 ambient light sensor for automatic backlight &amp;amp; LED intensity adjustment&lt;/li&gt; &#xA; &lt;li&gt;Versatile back plate for mounting - use either 4x screws, or 2x 3M medium Command strips (with cutouts for accessing removal tabs after installation)&lt;/li&gt; &#xA; &lt;li&gt;Front cover snaps on for easy access to the PCB&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Current status:&lt;/strong&gt; Not recommended for general use (mechanical and electrical revisions are planned)&lt;/p&gt; &#xA;&lt;h3&gt;Demo video&lt;/h3&gt; &#xA;&lt;a href=&#34;https://www.youtube.com/watch?v=ip641WmY4pA&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/ip641WmY4pA/maxresdefault.jpg&#34; width=&#34;480&#34;&gt; &lt;/a&gt; &#xA;&lt;h3&gt;3D CAD&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/scottbez1/smartknob/master/doc/img/explodedv145.gif&#34; alt=&#34;Exploded view&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Latest Fusion 360 Model: &lt;a href=&#34;https://a360.co/3BzkU0n&#34;&gt;https://a360.co/3BzkU0n&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Build your own?&lt;/h3&gt; &#xA;&lt;p&gt;While this is a &#34;DIY&#34; open-source project, it is not yet a mature plug-and-play project. If you intend to build your own, note that it requires advanced soldering experience to build - very small-pitch surface-mount soldering is required (reflow or hot air recommended), and assembly is quite time-consuming and delicate. Please go into it with the expectation that you will almost certainly need to be able to troubleshoot some hardware and firmware issues yourself - I recommend reviewing/understanding the schematics and basic firmware before jumping in!&lt;/p&gt; &#xA;&lt;p&gt;More documentation on the BOM and what parts you need to order is coming in the future - thanks so much for your interest! Follow me on &lt;a href=&#34;https://twitter.com/scottbez1&#34;&gt;Twitter&lt;/a&gt; for the latest updates on this and other projects.&lt;/p&gt; &#xA;&lt;p&gt;View the latest auto-generated (untested) &lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_base-ibom.html&#34;&gt;Base PCB Interactive BOM&lt;/a&gt; and &lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_screen-ibom.html&#34;&gt;Screen PCB Interactive BOM&lt;/a&gt; (or, the combined &lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_base-bom.csv&#34;&gt;BOM csv&lt;/a&gt;) for electronics/hardware parts list. ‚ö†Ô∏è These are auto-generated from the latest untested revision on GitHub. For tested/stable/recommended artifacts, use a &lt;a href=&#34;https://github.com/scottbez1/smartknob/releases&#34;&gt;release&lt;/a&gt; instead.&lt;/p&gt; &#xA;&lt;p&gt;A few miscellaneous notes in the meantime:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;This can &lt;em&gt;probably&lt;/em&gt; be FDM 3D printed with a well-tuned printer, but the parts shown in videos/photos were MJF printed in nylon for tight tolerances and better surface finish&lt;/li&gt; &#xA; &lt;li&gt;If you wanted a simpler build, you could omit the LCD and just merge the knob + glass from the model into a single STL to get a closed-top knob&lt;/li&gt; &#xA; &lt;li&gt;There&#39;s limited space inside the LCD mount for wiring, and 8 wires need to fit through the hole in the center. I used 30 AWG wire-wrapping wire. Enamel-coated wire would probably work too.&lt;/li&gt; &#xA; &lt;li&gt;Strain gauges are BF350-3AA, and glued in place with CA glue (I&#39;ll include video of this process in the future, but essentially I used kapton tape to pick up the strain gauge and hold it in place during curing). This has to be done after reflow soldering, and would be hard to remove/fix in case of a mistake, so MAKE SURE TO PRACTICE GLUING strain gauges to other items before attempting on the PCB!&lt;/li&gt; &#xA; &lt;li&gt;The TMC6300 is &lt;em&gt;tiny&lt;/em&gt; and has a bottom pad, so I would seriously consider getting a stencil along with the PCB order. Even with the stencil I needed to manually clean up some bridging afterward; I &lt;em&gt;highly&lt;/em&gt; recommend Chip Quik NC191 gel flux, available on &lt;a href=&#34;https://amzn.to/3MGDSr5&#34;&gt;Amazon&lt;/a&gt; (or use this &lt;a href=&#34;https://www.amazon.com/Smooth-Flow-No-Clean-syringe-plunger/dp/B08KJPG3NZ&#34;&gt;non-affiliate link&lt;/a&gt; instead) or from your electronics distributor of choice. Flux is also very helpful when soldering the LCD ribbon cable to to screen PCB.&lt;/li&gt; &#xA; &lt;li&gt;For breadboard prototyping, the &lt;a href=&#34;https://www.trinamic.com/support/eval-kits/details/tmc6300-bob/&#34;&gt;TMC6300-BOB&lt;/a&gt; is awesome and way easier to work with than the bare chip if you just want to play around with low current BLDC motors&lt;/li&gt; &#xA; &lt;li&gt;For AliExpress purchases: I highly recommend &lt;strong&gt;only&lt;/strong&gt; using AliExpress Standard Shipping (purchasing in the US). I have had multiple purchases take months or never get delivered when purchased with Cainiao or other low cost shipping options, whereas AliExpress Standard is very reliable and generally faster in my experience.&lt;/li&gt; &#xA; &lt;li&gt;Make sure to check the &lt;a href=&#34;https://github.com/scottbez1/smartknob/issues&#34;&gt;open issues&lt;/a&gt; - this design is not yet &#34;stable&#34;, so beware that everything may not go smoothly. I would not recommend ordering these parts yourself until the &lt;a href=&#34;https://github.com/scottbez1/smartknob/milestone/1&#34;&gt;stable release v1.0 milestone&lt;/a&gt; is complete, as there are some mechanical interference issues in the current revision.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Future plans:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;consider switch to using an ESP32-S3-MINI-1 module (once Arduino core support is complete), as that would allow for direct USB HID support (for joystick/macro-pad type input to a computer)&lt;/li&gt; &#xA; &lt;li&gt;Bluetooth HID support?&lt;/li&gt; &#xA; &lt;li&gt;get wifi configured and working (probably MQTT?). Currently memory is an issue with the full display framebuffer sprite. PSRAM might fix this (requires newer ESP-IDF &amp;amp; unreleased Arduino core, and from a brief test I got horrible performance with PSRAM enabled), or the next item might help reduce memory:&lt;/li&gt; &#xA; &lt;li&gt;migrate to LVGL, for better display rendering and easy support for menus, etc. Shouldn&#39;t require a full 240x240x24b framebuffer in memory, freeing some for wifi, etc.&lt;/li&gt; &#xA; &lt;li&gt;integrate nanopb for structured serial data (see &lt;a href=&#34;https://github.com/scottbez1/splitflap/raw/1440aba54d5b0d822ec5da68762431879988d7ef/arduino/splitflap/esp32/splitflap/serial_proto_protocol.cpp&#34;&gt;splitflap protobuf protocol&lt;/a&gt; for example)&lt;/li&gt; &#xA; &lt;li&gt;Home Assistant integration, or other real-world applications&lt;/li&gt; &#xA; &lt;li&gt;???&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sponsors/scottbez1/&#34;&gt;Profit&lt;/a&gt; üòâ&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Base PCB&lt;/h4&gt; &#xA;&lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_base-front-3d.png&#34;&gt; &lt;img src=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_base-front-3d.png&#34; width=&#34;300&#34;&gt; &lt;/a&gt; &#xA;&lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_base-back-3d.png&#34;&gt; &lt;img src=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_base-back-3d.png&#34; width=&#34;300&#34;&gt; &lt;/a&gt; &#xA;&lt;p&gt;Ordering notes: use white soldermask, for reflecting light from RGB LED ring around the knob. Should be 1.2mm thick (not &#34;standard&#34; 1.6mm).&lt;/p&gt; &#xA;&lt;p&gt;Latest auto-generated (untested and likely broken!) artifacts‚ö†Ô∏è:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_base-schematic.pdf&#34;&gt;Schematic&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_base-ibom.html&#34;&gt;Interactive BOM&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_base-pcb-packet.pdf&#34;&gt;PCB Packet&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_base-jlc/gerbers.zip&#34;&gt;Gerbers&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;‚ö†Ô∏è For tested/stable/recommended artifacts, use a &lt;a href=&#34;https://github.com/scottbez1/smartknob/releases&#34;&gt;release&lt;/a&gt; instead.&lt;/p&gt; &#xA;&lt;h4&gt;Screen PCB&lt;/h4&gt; &#xA;&lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_screen-front-3d.png&#34;&gt; &lt;img src=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_screen-front-3d.png&#34; width=&#34;300&#34;&gt; &lt;/a&gt; &#xA;&lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_screen-back-3d.png&#34;&gt; &lt;img src=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_screen-back-3d.png&#34; width=&#34;300&#34;&gt; &lt;/a&gt; &#xA;&lt;p&gt;Ordering notes: Must be 1.2mm thick (not &#34;standard&#34; 1.6mm) per mechanical design.&lt;/p&gt; &#xA;&lt;p&gt;Latest auto-generated (untested and likely broken!) artifacts‚ö†Ô∏è:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_screen-schematic.pdf&#34;&gt;Schematic&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_screen-ibom.html&#34;&gt;Interactive BOM&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_screen-pcb-packet.pdf&#34;&gt;PCB Packet&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://smartknob-artifacts.s3.us-west-1.amazonaws.com/master/electronics/view_screen-jlc/gerbers.zip&#34;&gt;Gerbers&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;‚ö†Ô∏è For tested/stable/recommended artifacts, use a &lt;a href=&#34;https://github.com/scottbez1/smartknob/releases&#34;&gt;release&lt;/a&gt; instead.&lt;/p&gt; &#xA;&lt;h2&gt;SmartKnob Mini&lt;/h2&gt; &#xA;&lt;p&gt;Planned for the future.&lt;/p&gt; &#xA;&lt;h1&gt;Frequently Asked Questions (FAQ)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;How much does it cost?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;I wish I could tell you now, but I don&#39;t actually know off the top of my head. Check back soon - I&#39;ve only built 1 so far, which was the result of a bunch of tinkering and prototyping over an extended period, so I don&#39;t have all the expenses tallied up yet. Certainly less than $200 in parts, and maybe closer to $100?&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Does it work with XYZ?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Not yet. So far I&#39;ve only implemented enough firmware for the demo shown in the video, so you can&#39;t actually use it for anything productive yet. The basic detent configuration API is there, but not much else. Lots of firmware work remains to be done. If you build one, I&#39;d love your help adding support for XYZ though!&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Can I buy one as a kit or already assembled?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Probably not? Or at least, I don&#39;t have any immediate plans to sell them myself. It&#39;s not that I don&#39;t want you to be happy, but hardware is a hard business and I just work on this stuff in my free time.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s open source with a fairly permissive license though, so in theory anyone could start offering kits/assemblies. If someone does go down that route of selling them, note that attribution is &lt;em&gt;required&lt;/em&gt; (and I wouldn&#39;t say no to &lt;a href=&#34;https://github.com/sponsors/scottbez1/&#34;&gt;royalties/tips/thanks&lt;/a&gt; if you&#39;re in a giving mood üôÇ).&lt;/p&gt; &#xA;&lt;h2&gt;General Component Info&lt;/h2&gt; &#xA;&lt;h3&gt;Magnetic encoders&lt;/h3&gt; &#xA;&lt;h4&gt;MT6701 (MagnTek)&lt;/h4&gt; &#xA;&lt;p&gt;Excellent sensor at a reasonable price - highly recommended. Less noisy than TLV493D, and more responsive (control loop is more stable) using SSI.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lots of IO options - SSI, I2C, and ABZ - should offer good response latency&lt;/li&gt; &#xA; &lt;li&gt;SSI includes CRC to validate data&lt;/li&gt; &#xA; &lt;li&gt;No power-down or low-power options - may not be ideal for battery-powered devices&lt;/li&gt; &#xA; &lt;li&gt;Not available from US distributors (Mouser, Digi-Key)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.magntek.com.cn/upload/MT6701_Rev.1.5.pdf&#34;&gt;Datasheet&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://lcsc.com/product-detail/Angle-Linear-Position-Sensors_Magn-Tek-MT6701CT-STD_C2856764.html&#34;&gt;Ordering (LCSC)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;TLV493D (Infineon)&lt;/h4&gt; &#xA;&lt;p&gt;A mediocre choice. Easy to prototype with using &lt;a href=&#34;https://www.adafruit.com/product/4366&#34;&gt;Adafruit&#39;s QWIIC breakout board&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In my testing, it is a little noisy, requiring filtering/smoothing that can slow responsiveness, hurting control loop stability. Or, with less filtering, the noise can easily be &#34;amplified&#34; by the derivative component in the PID motor torque controller, causing audible (and tactile) humming/buzzing.&lt;/p&gt; &#xA;&lt;p&gt;There is also apparently a known silicon issue that causes the internal ADC to sometimes completely lock up, requiring a full reset and re-configuration. See section 5.6 in the &lt;a href=&#34;https://www.infineon.com/dgdl/Infineon-TLV493D-A1B6_3DMagnetic-UM-v01_03-EN.pdf?fileId=5546d46261d5e6820161e75721903ddd&#34;&gt;User Manual&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;In the Master Controlled Mode (MCM) or the Fast Mode (FM) the ADC conversion may hang up. A hang up can&#xA;be detected by:&#xA; - Frame Counter (FRM) counter stucks and does not increment anymore.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In my experience testing 4 different Adafruit breakout boards, 2 of them (50%) regularly exhibit this lockup behavior within a minute or two of use. It is possible to detect and auto-reset (and there is code in the project to do so), but it is slow and may cause undesirable jumps/delays if the sensor locks up often.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.mouser.com/datasheet/2/196/Infineon_TLV493D_A1B6_DataSheet_v01_10_EN-1227967.pdf&#34;&gt;Datasheet&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;AS5600 (AMS)&lt;/h4&gt; &#xA;&lt;p&gt;A mediocre choice. Cheap breakout boards are readily available.&lt;/p&gt; &#xA;&lt;p&gt;In my testing, it&#39;s fairly noisy (anecdotally, noisier than the TLV493d), requiring filtering/smoothing that can slow responsiveness, hurting control loop stability. Additionally, it saturates at a lower magnetic field strength than other sensors I tested, requiring a significant air gap (8-10mm) when used with a strong neodymium diametric magnet like &lt;a href=&#34;https://www.digikey.com/en/products/detail/radial-magnets-inc/8995/5126077&#34;&gt;Radial Magnets 8995&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ams.com/documents/20143/36005/AS5600_DS000365_5-00.pdf&#34;&gt;Datasheet&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Motor drivers&lt;/h3&gt; &#xA;&lt;h4&gt;TMC6300-LA&lt;/h4&gt; &#xA;&lt;p&gt;This is a relatively new IC and it&#39;s a perfect match! There generally aren&#39;t any other drivers (with integrated fets) that meet the requirements for the low-voltage and low-current motors used in this project (DRV8316 might work, but has not been tested).&lt;/p&gt; &#xA;&lt;p&gt;Highlights:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2-11V DC motor supply input&lt;/li&gt; &#xA; &lt;li&gt;Up to 1.2A RMS&lt;/li&gt; &#xA; &lt;li&gt;Tiny (3x3mm QFN)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.trinamic.com/fileadmin/assets/Products/ICs_Documents/TMC6300_datasheet_rev1.07.pdf&#34;&gt;Datasheet&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.trinamic.com/products/integrated-circuits/details/tmc6300-la/&#34;&gt;Product page&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Motors&lt;/h3&gt; &#xA;&lt;h4&gt;32mm Rotor, Hollow Shaft, Diametric magnet&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/scottbez1/smartknob/master/doc/img/motors/PXL_20220121_221746595.jpg&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/scottbez1/smartknob/master/doc/img/motors/PXL_20220121_221746595.jpg&#34; width=&#34;200&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/scottbez1/smartknob/master/doc/img/motors/PXL_20220121_221738745.jpg&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/scottbez1/smartknob/master/doc/img/motors/PXL_20220121_221738745.jpg&#34; width=&#34;200&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;32mm rotor&lt;/li&gt; &#xA; &lt;li&gt;15mm overall height (including magnet), 12.75mm height w/o magnet, 9mm rotor height&lt;/li&gt; &#xA; &lt;li&gt;low/zero cogging - excellent for completely smooth input&lt;/li&gt; &#xA; &lt;li&gt;5.9mm hollow shaft&lt;/li&gt; &#xA; &lt;li&gt;built-in diametric magnet for encoder&lt;/li&gt; &#xA; &lt;li&gt;Proven option&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This is overall the easiest motor to get started with. Low cogging and a built-in diametric magnet are great!&lt;/p&gt; &#xA;&lt;p&gt;Sadly, does not seem to be available any longer.&lt;/p&gt; &#xA;&lt;h1&gt;Firmware&lt;/h1&gt; &#xA;&lt;p&gt;TODO: document this&lt;/p&gt; &#xA;&lt;p&gt;Also TODO: implement a lot more of the firmware&lt;/p&gt; &#xA;&lt;h1&gt;Acknowledgements&lt;/h1&gt; &#xA;&lt;p&gt;This project was greatly inspired by Jesse Schoch&#39;s video &#34;&lt;a href=&#34;https://www.youtube.com/watch?v=1gPQfDkX3BU&#34;&gt;haptic textures and virtual detents&lt;/a&gt;&#34; and the corresponding &lt;a href=&#34;https://community.simplefoc.com/t/haptic-textures/301&#34;&gt;discussion in the SimpleFOC community&lt;/a&gt;. Seriously, this project wouldn&#39;t exist if not for that video - thank you Jesse!&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;This project is licensed under Apache v2 (software, electronics, documentation) and Creative Commons Attribution 4.0 (hardware/mechanical) (see &lt;a href=&#34;https://raw.githubusercontent.com/scottbez1/smartknob/master/LICENSE.txt&#34;&gt;LICENSE.txt&lt;/a&gt; and &lt;a href=&#34;https://creativecommons.org/licenses/by/4.0/&#34;&gt;Creative Commons&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Copyright 2022 Scott Bezek&#xA;&#xA;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);&#xA;you may not use this file except in compliance with the License.&#xA;You may obtain a copy of the License at&#xA;&#xA;    http://www.apache.org/licenses/LICENSE-2.0&#xA;&#xA;Unless required by applicable law or agreed to in writing, software&#xA;distributed under the License is distributed on an &#34;AS IS&#34; BASIS,&#xA;WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&#xA;See the License for the specific language governing permissions and&#xA;limitations under the License.&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>mosaicml/composer</title>
    <updated>2022-06-24T01:34:07Z</updated>
    <id>tag:github.com,2022-06-24:/mosaicml/composer</id>
    <link href="https://github.com/mosaicml/composer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;train neural networks up to 7x faster&lt;/p&gt;&lt;hr&gt;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/mosaicml/composer#gh-light-mode-only&#34; class=&#34;only-light&#34;&gt; &lt;img src=&#34;https://storage.googleapis.com/docs.mosaicml.com/images/header_light.svg?sanitize=true&#34; width=&#34;50%&#34;&gt; &lt;/a&gt; &#xA; &lt;!-- SETUPTOOLS_LONG_DESCRIPTION_HIDE_BEGIN --&gt; &lt;a href=&#34;https://github.com/mosaicml/composer#gh-dark-mode-only&#34; class=&#34;only-dark&#34;&gt; &lt;img src=&#34;https://storage.googleapis.com/docs.mosaicml.com/images/header_dark.svg?sanitize=true&#34; width=&#34;50%&#34;&gt; &lt;/a&gt; &#xA; &lt;!-- SETUPTOOLS_LONG_DESCRIPTION_HIDE_END --&gt; &lt;/p&gt; &#xA;&lt;h2&gt;&lt;p align=&#34;center&#34;&gt;A PyTorch Library for Efficient Neural Network Training&lt;/p&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;p align=&#34;center&#34;&gt;Train Faster, Reduce Cost, Get Better Models&lt;/p&gt;&lt;/h3&gt; &#xA;&lt;h4&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.mosaicml.com&#34;&gt;[Website]&lt;/a&gt; - &lt;a href=&#34;https://docs.mosaicml.com/en/stable/getting_started/installation.html&#34;&gt;[Getting Started]&lt;/a&gt; - &lt;a href=&#34;https://docs.mosaicml.com/&#34;&gt;[Docs]&lt;/a&gt; - &lt;a href=&#34;https://docs.mosaicml.com/en/stable/method_cards/methods_overview.html&#34;&gt;[Methods]&lt;/a&gt; - &lt;a href=&#34;https://www.mosaicml.com/team&#34;&gt;[We&#39;re Hiring!]&lt;/a&gt; &lt;/p&gt;&lt;/h4&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://pypi.org/project/mosaicml/&#34;&gt; &lt;img alt=&#34;PyPi Version&#34; src=&#34;https://img.shields.io/pypi/pyversions/mosaicml&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/mosaicml/&#34;&gt; &lt;img alt=&#34;PyPi Package Version&#34; src=&#34;https://img.shields.io/pypi/v/mosaicml&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/mosaicml/&#34;&gt; &lt;img alt=&#34;PyPi Downloads&#34; src=&#34;https://img.shields.io/pypi/dm/mosaicml&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://docs.mosaicml.com/en/stable/&#34;&gt; &lt;img alt=&#34;Documentation&#34; src=&#34;https://readthedocs.org/projects/composer/badge/?version=stable&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://join.slack.com/t/mosaicml-community/shared_invite/zt-w0tiddn9-WGTlRpfjcO9J5jyrMub1dg&#34;&gt; &lt;img alt=&#34;Chat @ Slack&#34; src=&#34;https://img.shields.io/badge/slack-chat-2eb67d.svg?logo=slack&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/mosaicml/composer/raw/dev/LICENSE&#34;&gt; &lt;img alt=&#34;License&#34; src=&#34;https://img.shields.io/badge/License-Apache%202.0-green.svg?logo=slack&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;üëã Welcome&lt;/h1&gt; &#xA;&lt;p&gt;Composer is a library written in PyTorch that enables you to &lt;b&gt;train neural networks faster, at lower cost, and to higher accuracy&lt;/b&gt;. We&#39;ve implemented more than two dozen speed-up methods that can be applied to your training loop in just a few lines of code, or used with our built-in Trainer. We continually integrate the latest state-of-the-art in efficient neural network training.&lt;/p&gt; &#xA;&lt;p&gt;Composer features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;20+ methods for speeding up training networks for computer vision and language modeling. Don&#39;t waste hours trying to reproduce research papers when Composer has done the work for you.&lt;/li&gt; &#xA; &lt;li&gt;An easy-to-use trainer that has been written to be as performant as possible and &lt;a href=&#34;https://www.mosaicml.com/blog/5-best-practices-for-efficient-model-training&#34;&gt;integrates best practices&lt;/a&gt; for efficient training.&lt;/li&gt; &#xA; &lt;li&gt;Functional forms of all of our speedup methods that allow you to integrate them into your existing training loop.&lt;/li&gt; &#xA; &lt;li&gt;Strong, &lt;em&gt;reproducible&lt;/em&gt; baselines to get you started as quickly as possible.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Benefits&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://storage.googleapis.com/docs.mosaicml.com/images/composer_graph_light_06212022.svg?ref=Fiey0Xei#gh-light-mode-only&#34; class=&#34;only-light&#34;&gt; &lt;img src=&#34;https://storage.googleapis.com/docs.mosaicml.com/images/composer_graph_light_06212022.svg?ref=Fiey0Xei&#34; width=&#34;75%&#34;&gt; &lt;/a&gt; &#xA; &lt;!-- link to the light mode image even on dark mode, so it will be readable in a new tab --&gt; &#xA; &lt;!-- SETUPTOOLS_LONG_DESCRIPTION_HIDE_BEGIN --&gt; &lt;a href=&#34;https://storage.googleapis.com/docs.mosaicml.com/images/composer_graph_dark_06212022.svg?ref=Fiey0Xei#gh-dark-mode-only&#34; class=&#34;only-dark&#34;&gt; &lt;img src=&#34;https://storage.googleapis.com/docs.mosaicml.com/images/composer_graph_dark_06212022.svg?ref=Fiey0Xei&#34; width=&#34;75%&#34;&gt; &lt;/a&gt; &#xA; &lt;!-- SETUPTOOLS_LONG_DESCRIPTION_HIDE_END --&gt; &lt;/p&gt; &#xA;&lt;p&gt;With no additional tuning, you can apply our methods to:&lt;/p&gt; &#xA;&lt;!-- start numbers --&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Train ResNet-50 on ImageNet to the standard 76.6% top-one accuracy for $15 in 27 minutes (&lt;em&gt;with vanilla PyTorch:&lt;/em&gt; $116 in 3.5 hours) on AWS.&lt;/li&gt; &#xA; &lt;li&gt;Train GPT-2 125M to a the standard perplexity of 24.11 for $145 in 4.5 hours (&lt;em&gt;with vanilla PyTorch&lt;/em&gt;: $255 in 7.8 hours) on AWS.&lt;/li&gt; &#xA; &lt;li&gt;Train DeepLab-v3 on ADE20k to the standard mean IOU of 45.7 for $36 in 1.1 hours (&lt;em&gt;with vanilla PyTorch&lt;/em&gt;: $110 in 3.5 hours on AWS)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- end numbers --&gt; &#xA;&lt;h1&gt;üöÄ Quickstart&lt;/h1&gt; &#xA;&lt;h2&gt;üíæ Installation&lt;/h2&gt; &#xA;&lt;p&gt;Composer is available with Pip:&lt;/p&gt; &#xA;&lt;!--pytest-codeblocks:skip--&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install mosaicml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, install Composer with Conda:&lt;/p&gt; &#xA;&lt;!--pytest-codeblocks:skip--&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda install -c mosaicml mosaicml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;üöå Usage&lt;/h2&gt; &#xA;&lt;p&gt;You can use Composer&#39;s speedup methods in two ways:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Through a standalone &lt;strong&gt;Functional API&lt;/strong&gt; (similar to &lt;code&gt;torch.nn.functional&lt;/code&gt;) that allows you to integrate them into your existing training code.&lt;/li&gt; &#xA; &lt;li&gt;Using Composer&#39;s built-in &lt;strong&gt;Trainer&lt;/strong&gt;, which is designed to be performant and automatically takes care of many of the low-level details of using speedup methods.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Example: Functional API &lt;a href=&#34;https://colab.research.google.com/github/mosaicml/composer/blob/dev/examples/functional_api.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Integrate our speed-up methods into your training loop with just a few lines of code, and see the results. Here we easily apply &lt;a href=&#34;https://docs.mosaicml.com/en/stable/method_cards/blurpool.html&#34;&gt;BlurPool&lt;/a&gt; and SqueezeExcite:&lt;/p&gt; &#xA;&lt;!-- begin_example_1 ---&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import composer.functional as cf&#xA;from torchvision import models&#xA;&#xA;my_model = models.resnet18()&#xA;&#xA;# add blurpool and squeeze excite layers&#xA;my_model = cf.apply_blurpool(my_model)&#xA;my_model = cf.apply_squeeze_excite(my_model)&#xA;&#xA;# your own training code starts here&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- end_example_1 ---&gt; &#xA;&lt;p&gt;For more examples, see the &lt;a href=&#34;https://colab.research.google.com/github/mosaicml/composer/blob/dev/examples/functional_api.ipynb&#34;&gt;Composer Functional API Colab notebook&lt;/a&gt; and &lt;a href=&#34;https://docs.mosaicml.com/en/latest/functional_api.html&#34;&gt;Functional API guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Example: Trainer &lt;a href=&#34;https://colab.research.google.com/github/mosaicml/composer/blob/dev/examples/getting_started.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;For the best experience and the most efficient possible training, we recommend using Composer&#39;s built-in trainer, which automatically takes care of the low-level details of using speedup methods and provides useful abstractions that facilitate rapid experimentation.&lt;/p&gt; &#xA;&lt;!-- begin_example_2 ---&gt; &#xA;&lt;!-- TODO: Address timeouts --&gt; &#xA;&lt;!--pytest-codeblocks:skip--&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from torch.utils.data import DataLoader&#xA;from torchvision import datasets, transforms&#xA;&#xA;from composer import Trainer&#xA;from composer.algorithms import BlurPool, ChannelsLast, CutMix, LabelSmoothing&#xA;from composer.models import MNIST_Classifier&#xA;&#xA;transform = transforms.Compose([transforms.ToTensor()])&#xA;train_dataset = datasets.MNIST(&#34;data&#34;, download=True, train=True, transform=transform)&#xA;eval_dataset = datasets.MNIST(&#34;data&#34;, download=True, train=False, transform=transform)&#xA;train_dataloader = DataLoader(train_dataset, batch_size=128)&#xA;eval_dataloader = DataLoader(eval_dataset, batch_size=128)&#xA;&#xA;trainer = Trainer(&#xA;    model=MNIST_Classifier(num_classes=10),&#xA;    train_dataloader=train_dataloader,&#xA;    eval_dataloader=eval_dataloader,&#xA;    max_duration=&#34;2ep&#34;,&#xA;    algorithms=[&#xA;        BlurPool(replace_convs=True, replace_maxpools=True, blur_first=True),&#xA;        ChannelsLast(),&#xA;        CutMix(num_classes=10),&#xA;        LabelSmoothing(smoothing=0.1),&#xA;    ]&#xA;)&#xA;trainer.fit()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- end_example_2 --&gt; &#xA;&lt;p&gt;Composer&#39;s built-in &lt;a href=&#34;https://docs.mosaicml.com/en/stable/trainer/using_the_trainer.html&#34;&gt;trainer&lt;/a&gt; makes it easy to &lt;strong&gt;add multiple speedup methods in a single line of code!&lt;/strong&gt; Trying out new methods or combinations of methods is as easy as changing a single list. As we continually implement more methods, they will be easy for you to add to your code.&lt;/p&gt; &#xA;&lt;p&gt;For concrete examples of methods in Composer, here are some (&lt;a href=&#34;https://docs.mosaicml.com/en/latest/trainer/algorithms.html&#34;&gt;&lt;em&gt;see here for all&lt;/em&gt;&lt;/a&gt;) speedup methods currently in Composer:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Attribution&lt;/th&gt; &#xA;   &lt;th&gt;tl;dr&lt;/th&gt; &#xA;   &lt;th&gt;Example Benchmark&lt;/th&gt; &#xA;   &lt;th&gt;Speed Up*&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/alibi&#34;&gt;Alibi&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2108.12409&#34;&gt;Press et al, 2021&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Replace attention with AliBi.&lt;/td&gt; &#xA;   &lt;td&gt;GPT-2&lt;/td&gt; &#xA;   &lt;td&gt;1.5x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/blurpool&#34;&gt;BlurPool&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1904.11486&#34;&gt;Zhang, 2019&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Applies an anti-aliasing filter before every downsampling operation.&lt;/td&gt; &#xA;   &lt;td&gt;ResNet-101&lt;/td&gt; &#xA;   &lt;td&gt;1.2x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/channels_last&#34;&gt;ChannelsLast&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://pytorch.org/tutorials/intermediate/memory_format_tutorial.html&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Uses channels last memory format (NHWC).&lt;/td&gt; &#xA;   &lt;td&gt;ResNet-101&lt;/td&gt; &#xA;   &lt;td&gt;1.5x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mosaicml.com/en/latest/method_cards/cutout.html&#34;&gt;CutOut&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1708.04552&#34;&gt;DeVries et al, 2017&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Randomly erases rectangular blocks from the image.&lt;/td&gt; &#xA;   &lt;td&gt;ResNet-101&lt;/td&gt; &#xA;   &lt;td&gt;1.2x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/label_smoothing&#34;&gt;LabelSmoothing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1512.00567&#34;&gt;Szegedy et al, 2015&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Smooths the labels with a uniform prior&lt;/td&gt; &#xA;   &lt;td&gt;ResNet-101&lt;/td&gt; &#xA;   &lt;td&gt;1.5x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/mixup&#34;&gt;MixUp&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.09412&#34;&gt;Zhang et al, 2017&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Blends pairs of examples and labels.&lt;/td&gt; &#xA;   &lt;td&gt;ResNet-101&lt;/td&gt; &#xA;   &lt;td&gt;1.5x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/randaugment&#34;&gt;RandAugment&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content_CVPRW_2020/html/w40/Cubuk_Randaugment_Practical_Automated_Data_Augmentation_With_a_Reduced_Search_Space_CVPRW_2020_paper.html&#34;&gt;Cubuk et al, 2020&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Applies a series of random augmentations to each image.&lt;/td&gt; &#xA;   &lt;td&gt;ResNet-101&lt;/td&gt; &#xA;   &lt;td&gt;1.3x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/sam&#34;&gt;SAM&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.01412&#34;&gt;Foret et al, 2021&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;An optimization strategy that seeks flatter minima.&lt;/td&gt; &#xA;   &lt;td&gt;ResNet-101&lt;/td&gt; &#xA;   &lt;td&gt;1.4x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/seq_length_warmup&#34;&gt;SeqLengthWarmup&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2108.06084&#34;&gt;Li et al, 2021&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Progressively increase sequence length.&lt;/td&gt; &#xA;   &lt;td&gt;GPT-2&lt;/td&gt; &#xA;   &lt;td&gt;1.2x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.mosaicml.com/en/latest/method_cards/stochastic_depth.html&#34;&gt;Stochastic Depth&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1603.09382&#34;&gt;Huang et al, 2016&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Replaces a specified layer with a stochastic version that randomly drops the layer or samples during training&lt;/td&gt; &#xA;   &lt;td&gt;ResNet-101&lt;/td&gt; &#xA;   &lt;td&gt;1.1x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p align=&#34;right&#34;&gt;* = time-to-train to the same quality as the baseline.&lt;/p&gt; &#xA;&lt;h2&gt;üõ† Building Speedup Recipes&lt;/h2&gt; &#xA;&lt;p&gt;Given two methods that speed up training by 1.5x each, do they combine to provide a 2.25x (1.5x * 1.5x) speedup? Not necessarily. They may optimize the &lt;a href=&#34;https://en.wikipedia.org/wiki/Amdahl&#39;s_law&#34;&gt;same part of the training process&lt;/a&gt; and lead to diminishing returns, or they may even interact in ways that prove detrimental. Determining which methods to compose together isn&#39;t as simple as assembling a set of methods that perform best individually.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;We have come up with compositions of methods that work especially well together&lt;/strong&gt; through rigorous exploration of the design space of recipes and research on the science behind composition. The &lt;a href=&#34;https://app.mosaicml.com/&#34;&gt;MosaicML Explorer&lt;/a&gt; contains all of the data we have collected so far on composition, and it highlights the compositions of methods that are &lt;em&gt;pareto-optimal&lt;/em&gt; - that provide the &lt;strong&gt;best possible tradeoffs between training time or cost and the quality of the trained model&lt;/strong&gt;. Whether you want to reach the same quality faster or get better quality within your current budget, Explorer can help you decide which speedup methods to use. We update this data regularly as we add new methods and develop better recipes.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://storage.googleapis.com/docs.mosaicml.com/images/methods/explorer.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;As an example, here are two performant recipes, one for ResNet-101 on ImageNet, and the other for GPT-2 on OpenWebText, on 8xA100s:&lt;/p&gt; &#xA;&lt;h3&gt;ResNet-101&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Functional&lt;/th&gt; &#xA;   &lt;th&gt;tl;dr&lt;/th&gt; &#xA;   &lt;th&gt;Benchmark&lt;/th&gt; &#xA;   &lt;th&gt;Speed Up&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/blurpool&#34;&gt;Blur Pool&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;cf.apply_blurpool&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1904.11486&#34;&gt;Applies an anti-aliasing filter before every downsampling operation.&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ResNet-101&lt;/td&gt; &#xA;   &lt;td&gt;1.2x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/channels_last&#34;&gt;Channels Last&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;cf.apply_&lt;/code&gt;&lt;br&gt;&lt;code&gt;channels_last&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://pytorch.org/tutorials/intermediate/memory_format_tutorial.html&#34;&gt;Uses channels last memory format (NHWC).&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ResNet-101&lt;/td&gt; &#xA;   &lt;td&gt;1.5x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/label_smoothing&#34;&gt;Label Smoothing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;cf.smooth_labels&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1512.00567&#34;&gt;Smooths the labels with a uniform prior.&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ResNet-101&lt;/td&gt; &#xA;   &lt;td&gt;1.5x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/mixup&#34;&gt;MixUp&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;CF.mixup_batch&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.09412&#34;&gt;Blends pairs of examples and labels.&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ResNet-101&lt;/td&gt; &#xA;   &lt;td&gt;1.5x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/progressive_resizing&#34;&gt;Progressive Resizing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;cf.resize_batch&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/fastai/fastbook/raw/780b76bef3127ce5b64f8230fce60e915a7e0735/07_sizing_and_tta.ipynb&#34;&gt;Increases the input image size during training.&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ResNet-101&lt;/td&gt; &#xA;   &lt;td&gt;1.3x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/sam&#34;&gt;SAM&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.01412&#34;&gt;SAM optimizer measures sharpness of optimization space.&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ResNet-101&lt;/td&gt; &#xA;   &lt;td&gt;1.5x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Composition&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Cheapest: $49 @ 78.1% Acc&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;ResNet-101&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;3.5x&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;GPT-2&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;Functional&lt;/th&gt; &#xA;   &lt;th&gt;tl;dr&lt;/th&gt; &#xA;   &lt;th&gt;Benchmark&lt;/th&gt; &#xA;   &lt;th&gt;Speed Up&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/alibi&#34;&gt;Alibi&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;cf.apply_alibi&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2108.12409&#34;&gt;Replace attention with AliBi.&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GPT-2&lt;/td&gt; &#xA;   &lt;td&gt;1.6x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/mosaicml/composer/tree/dev/composer/algorithms/seq_length_warmup&#34;&gt;Seq Length Warmup&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;cf.set_batch_&lt;/code&gt;&lt;br&gt;&lt;code&gt;sequence_length&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2108.06084&#34;&gt;Progressively increase sequence length.&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GPT-2&lt;/td&gt; &#xA;   &lt;td&gt;1.5x&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Composition&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Cheapest: $145 @ 24.11 PPL&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;GPT-2&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;1.7x&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;‚öôÔ∏è What benchmarks does Composer support?&lt;/h1&gt; &#xA;&lt;p&gt;Composer uses a &lt;em&gt;benchmark&lt;/em&gt; as a term to denote a particular model trained on a particular dataset in a standardized, reproducible way. A benchmark is a specific model trained for a task, where a task = dataset + loss function + metric.&lt;/p&gt; &#xA;&lt;p&gt;We support computer vision and natural language processing use cases, such as (but not limited to) the following. New benchmarks will be added regularly, as will compatibility with existing libraries.&lt;/p&gt; &#xA;&lt;div class=&#34;center&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Dataset&lt;/th&gt; &#xA;    &lt;th&gt;Loss&lt;/th&gt; &#xA;    &lt;th&gt;Task&lt;/th&gt; &#xA;    &lt;th&gt;Evaluation Metrics&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td colspan=&#34;5&#34; align=&#34;center&#34;&gt;&lt;b&gt;Computer Vision&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;ResNet Family&lt;/td&gt; &#xA;    &lt;td&gt;CIFAR-10&lt;/td&gt; &#xA;    &lt;td&gt;Cross Entropy&lt;/td&gt; &#xA;    &lt;td&gt;Image Classification&lt;/td&gt; &#xA;    &lt;td&gt;Classification Accuracy&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;ResNet Family&lt;/td&gt; &#xA;    &lt;td&gt;ImageNet&lt;/td&gt; &#xA;    &lt;td&gt;Cross Entropy&lt;/td&gt; &#xA;    &lt;td&gt;Image Classification&lt;/td&gt; &#xA;    &lt;td&gt;Classification Accuracy&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;EfficientNet Family&lt;/td&gt; &#xA;    &lt;td&gt;ImageNet&lt;/td&gt; &#xA;    &lt;td&gt;Cross Entropy&lt;/td&gt; &#xA;    &lt;td&gt;Image Classification&lt;/td&gt; &#xA;    &lt;td&gt;Classification Accuracy&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;UNet&lt;/td&gt; &#xA;    &lt;td&gt;BraTS&lt;/td&gt; &#xA;    &lt;td&gt;Dice Loss&lt;/td&gt; &#xA;    &lt;td&gt;Image Segmentation&lt;/td&gt; &#xA;    &lt;td&gt;Dice Coefficient&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;DeepLab v3&lt;/td&gt; &#xA;    &lt;td&gt;ADE20K&lt;/td&gt; &#xA;    &lt;td&gt;Cross Entropy&lt;/td&gt; &#xA;    &lt;td&gt;Image Segmentation&lt;/td&gt; &#xA;    &lt;td&gt;mIoU&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34; colspan=&#34;5&#34;&gt;&lt;b&gt;Natural Language Processing&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;BERT Family&lt;/td&gt; &#xA;    &lt;td&gt;{Wikipedia &amp;amp; BooksCorpus, C4}&lt;/td&gt; &#xA;    &lt;td&gt;Cross Entropy&lt;/td&gt; &#xA;    &lt;td&gt;Masked Language Modeling&lt;/td&gt; &#xA;    &lt;td&gt;GLUE &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;GPT Family&lt;/td&gt; &#xA;    &lt;td&gt;{OpenWebText, C4}&lt;/td&gt; &#xA;    &lt;td&gt;Cross Entropy&lt;/td&gt; &#xA;    &lt;td&gt;Language Modeling&lt;br&gt;&lt;/td&gt; &#xA;    &lt;td&gt;Perplexity&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;ü§î Why should I use Composer?&lt;/h1&gt; &#xA;&lt;p&gt;The compute required to train a state-of-the-art machine learning model is &lt;a href=&#34;https://arxiv.org/abs/2202.05924&#34;&gt;doubling every 6 months&lt;/a&gt;, putting these capabilities further and further out of reach for the broader community with each passing day. Composer addresses this challenge by focusing on training efficiency: it contains cutting-edge speedup methods that modify the training algorithm to reduce the time and cost necessary to train deep learning models. &lt;strong&gt;When you use Composer, you can rest assured that you are training efficiently.&lt;/strong&gt; We have combed the literature, done the science, and built industrial-grade implementations to ensure this is the case.&lt;/p&gt; &#xA;&lt;p&gt;Even after these speedup methods are implemented, assembling them together into recipes is nontrivial. We designed Composer with the &lt;strong&gt;right abstractions to composing (and creating new) speedup methods.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Specifically, Composer&#39;s efficiency methods use &lt;strong&gt;two-way callbacks&lt;/strong&gt; from (&lt;a href=&#34;https://arxiv.org/abs/2002.04688&#34;&gt;Howard et al, 2020&lt;/a&gt;) to modify the &lt;strong&gt;entire training state&lt;/strong&gt; at particular events in the training loop to effect speed-ups. We handle collisions between methods, the proper order of execution for algorithms, and more.&lt;/p&gt; &#xA;&lt;p&gt;Through this, our methods can modify:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;data inputs for batches (data augmentations, sequence length warmup, skipping examples, etc.)&lt;/li&gt; &#xA; &lt;li&gt;neural network architecture (pruning, model surgery, etc.)&lt;/li&gt; &#xA; &lt;li&gt;loss function (label smoothing, MixUp, CutMix, etc.)&lt;/li&gt; &#xA; &lt;li&gt;optimizer (Sharpness Aware Minimization)&lt;/li&gt; &#xA; &lt;li&gt;training dynamics (layer freezing, selective backprop, etc.)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Easily &lt;a href=&#34;https://colab.research.google.com/github/mosaicml/composer/blob/dev/examples/custom_speedup_methods.ipynb&#34;&gt;add your own methods&lt;/a&gt; or callbacks to instrument any part of the training loop.&lt;/p&gt; &#xA;&lt;h1&gt;üßê Why shouldn‚Äôt I use Composer?&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Composer is mostly optimized for computer vision (CV) and natural language processing (NLP) use cases, including &lt;a href=&#34;https://docs.mosaicml.com/en/stable/composer_model.html&#34;&gt;custom models&lt;/a&gt; and custom datasets. We strongly encourage exploration on integrating our algorithms into new domains, such as reinforcement learning. Feel free to &lt;a href=&#34;https://join.slack.com/t/mosaicml-community/shared_invite/zt-w0tiddn9-WGTlRpfjcO9J5jyrMub1dg&#34;&gt;join our Slack&lt;/a&gt; and discuss!&lt;/li&gt; &#xA; &lt;li&gt;Composer currently supports NVIDIA GPUs. We are adding support for additional hardware platforms, and you should expect more soon.&lt;/li&gt; &#xA; &lt;li&gt;Composer is an active and ongoing project. Since Composer is still in alpha, our API may not be stable. We recommend pegging your work to a Composer version, and we will respond quickly to issues posted to this repository.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;üìö Learn More&lt;/h1&gt; &#xA;&lt;p&gt;Here&#39;s some resources actively maintained by the Composer community to help you get started:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;b&gt;Resource&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;b&gt;Details&lt;/b&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/mosaicml/composer/blob/dev/examples/getting_started.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Getting started with our Trainer&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;An interactive Colab Notebook aimed at teaching users about our Trainer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/mosaicml/composer/blob/dev/examples/functional_api.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Getting started with our Functional API&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;An interactive Colab Notebook aimed at teaching users about our Functional API&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/mosaicml/composer/blob/dev/examples/custom_speedup_methods.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Building Speedup Methods&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;An interactive Colab Notebook aimed at teaching users about building speedup methods on top of Composer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/mosaicml/composer/blob/dev/examples/nlp_models.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Training BERTs with Composer&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;An interactive Colab Notebook aimed at helping users learn how to train BERT models with Composer!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mosaicml.com/jobs&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;We&#39;re Hiring!&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Join us! ü§©&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;If you have any questions, please feel free to reach out to us on &lt;a href=&#34;https://twitter.com/mosaicml&#34;&gt;Twitter&lt;/a&gt;, &lt;a href=&#34;mailto:community@mosaicml.com&#34;&gt;email&lt;/a&gt;, or our &lt;a href=&#34;https://join.slack.com/t/mosaicml-community/shared_invite/zt-w0tiddn9-WGTlRpfjcO9J5jyrMub1dg&#34;&gt;Community Slack&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h1&gt;üí´ Contributors&lt;/h1&gt; &#xA;&lt;p&gt;Composer is part of the broader Machine Learning community, and we welcome any contributions, pull requests, or issues!&lt;/p&gt; &#xA;&lt;p&gt;To start contributing, see our &lt;a href=&#34;https://github.com/mosaicml/composer/raw/dev/CONTRIBUTING.md&#34;&gt;Contributing&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;h1&gt;‚úçÔ∏è Citation&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{mosaicml2022composer,&#xA;    author = {The Mosaic ML Team},&#xA;    title = {composer},&#xA;    year = {2021},&#xA;    howpublished = {\url{https://github.com/mosaicml/composer/}},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>