<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-06-08T01:28:00Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Stability-AI/stable-audio-tools</title>
    <updated>2024-06-08T01:28:00Z</updated>
    <id>tag:github.com,2024-06-08:/Stability-AI/stable-audio-tools</id>
    <link href="https://github.com/Stability-AI/stable-audio-tools" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Generative models for conditional audio generation&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;stable-audio-tools&lt;/h1&gt; &#xA;&lt;p&gt;Training and inference code for audio generation models&lt;/p&gt; &#xA;&lt;h1&gt;Install&lt;/h1&gt; &#xA;&lt;p&gt;The library can be installed from PyPI with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pip install stable-audio-tools&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run the training scripts or inference code, you&#39;ll want to clone this repository, navigate to the root, and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Requirements&lt;/h1&gt; &#xA;&lt;p&gt;Requires PyTorch 2.0 or later for Flash Attention support&lt;/p&gt; &#xA;&lt;p&gt;Development for the repo is done in Python 3.8.10&lt;/p&gt; &#xA;&lt;h1&gt;Interface&lt;/h1&gt; &#xA;&lt;p&gt;A basic Gradio interface is provided to test out trained models.&lt;/p&gt; &#xA;&lt;p&gt;For example, to create an interface for the &lt;a href=&#34;https://huggingface.co/stabilityai/stable-audio-open-1.0&#34;&gt;&lt;code&gt;stable-audio-open-1.0&lt;/code&gt;&lt;/a&gt; model, once you&#39;ve accepted the terms for the model on Hugging Face, you can run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ python3 ./run_gradio.py --pretrained-name stabilityai/stable-audio-open-1.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;run_gradio.py&lt;/code&gt; script accepts the following command line arguments:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--pretrained-name&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Hugging Face repository name for a Stable Audio Tools model&lt;/li&gt; &#xA;   &lt;li&gt;Will prioritize &lt;code&gt;model.safetensors&lt;/code&gt; over &lt;code&gt;model.ckpt&lt;/code&gt; in the repo&lt;/li&gt; &#xA;   &lt;li&gt;Optional, used in place of &lt;code&gt;model-config&lt;/code&gt; and &lt;code&gt;ckpt-path&lt;/code&gt; when using pre-trained model checkpoints on Hugging Face&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--model-config&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Path to the model config file for a local model&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--ckpt-path&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Path to unwrapped model checkpoint file for a local model&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--pretransform-ckpt-path&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Path to an unwrapped pretransform checkpoint, replaces the pretransform in the model, useful for testing out fine-tuned decoders&lt;/li&gt; &#xA;   &lt;li&gt;Optional&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--username&lt;/code&gt; and &lt;code&gt;--password&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Used together to set a login for the Gradio demo&lt;/li&gt; &#xA;   &lt;li&gt;Optional&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--model-half&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;If true, the model weights to half-precision&lt;/li&gt; &#xA;   &lt;li&gt;Optonal&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Training&lt;/h1&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;Before starting your training run, you&#39;ll need a model config file, as well as a dataset config file. For more information about those, refer to the Configurations section below&lt;/p&gt; &#xA;&lt;p&gt;The training code also requires a Weights &amp;amp; Biases account to log the training outputs and demos. Create an account and log in with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ wandb login&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Start training&lt;/h2&gt; &#xA;&lt;p&gt;To start a training run, run the &lt;code&gt;train.py&lt;/code&gt; script in the repo root with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ python3 ./train.py --dataset-config /path/to/dataset/config --model-config /path/to/model/config --name harmonai_train&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;--name&lt;/code&gt; parameter will set the project name for your Weights and Biases run.&lt;/p&gt; &#xA;&lt;h2&gt;Training wrappers and model unwrapping&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;stable-audio-tools&lt;/code&gt; uses PyTorch Lightning to facilitate multi-GPU and multi-node training.&lt;/p&gt; &#xA;&lt;p&gt;When a model is being trained, it is wrapped in a &#34;training wrapper&#34;, which is a &lt;code&gt;pl.LightningModule&lt;/code&gt; that contains all of the relevant objects needed only for training. That includes things like discriminators for autoencoders, EMA copies of models, and all of the optimizer states.&lt;/p&gt; &#xA;&lt;p&gt;The checkpoint files created during training include this training wrapper, which greatly increases the size of the checkpoint file.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;unwrap_model.py&lt;/code&gt; in the repo root will take in a wrapped model checkpoint and save a new checkpoint file including only the model itself.&lt;/p&gt; &#xA;&lt;p&gt;That can be run with from the repo root with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ python3 ./unwrap_model.py --model-config /path/to/model/config --ckpt-path /path/to/wrapped/ckpt --name model_unwrap&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Unwrapped model checkpoints are required for:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Inference scripts&lt;/li&gt; &#xA; &lt;li&gt;Using a model as a pretransform for another model (e.g. using an autoencoder model for latent diffusion)&lt;/li&gt; &#xA; &lt;li&gt;Fine-tuning a pre-trained model with a modified configuration (i.e. partial initialization)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Fine-tuning&lt;/h2&gt; &#xA;&lt;p&gt;Fine-tuning a model involves continuning a training run from a pre-trained checkpoint.&lt;/p&gt; &#xA;&lt;p&gt;To continue a training run from a wrapped model checkpoint, you can pass in the checkpoint path to &lt;code&gt;train.py&lt;/code&gt; with the &lt;code&gt;--ckpt-path&lt;/code&gt; flag.&lt;/p&gt; &#xA;&lt;p&gt;To start a fresh training run using a pre-trained unwrapped model, you can pass in the unwrapped checkpoint to &lt;code&gt;train.py&lt;/code&gt; with the &lt;code&gt;--pretrained-ckpt-path&lt;/code&gt; flag.&lt;/p&gt; &#xA;&lt;h2&gt;Additional training flags&lt;/h2&gt; &#xA;&lt;p&gt;Additional optional flags for &lt;code&gt;train.py&lt;/code&gt; include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--config-file&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The path to the defaults.ini file in the repo root, required if running &lt;code&gt;train.py&lt;/code&gt; from a directory other than the repo root&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--pretransform-ckpt-path&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Used in various model types such as latent diffusion models to load a pre-trained autoencoder. Requires an unwrapped model checkpoint.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--save-dir&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The directory in which to save the model checkpoints&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--checkpoint-every&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The number of steps between saved checkpoints.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;em&gt;Default&lt;/em&gt;: 10000&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--batch-size&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Number of samples per-GPU during training. Should be set as large as your GPU VRAM will allow.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;em&gt;Default&lt;/em&gt;: 8&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--num-gpus&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Number of GPUs per-node to use for training&lt;/li&gt; &#xA;   &lt;li&gt;&lt;em&gt;Default&lt;/em&gt;: 1&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--num-nodes&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Number of GPU nodes being used for training&lt;/li&gt; &#xA;   &lt;li&gt;&lt;em&gt;Default&lt;/em&gt;: 1&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--accum-batches&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Enables and sets the number of batches for gradient batch accumulation. Useful for increasing effective batch size when training on smaller GPUs.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--strategy&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Multi-GPU strategy for distributed training. Setting to &lt;code&gt;deepspeed&lt;/code&gt; will enable DeepSpeed ZeRO Stage 2.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;em&gt;Default&lt;/em&gt;: &lt;code&gt;ddp&lt;/code&gt; if &lt;code&gt;--num_gpus&lt;/code&gt; &amp;gt; 1, else None&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--precision&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;floating-point precision to use during training&lt;/li&gt; &#xA;   &lt;li&gt;&lt;em&gt;Default&lt;/em&gt;: 16&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--num-workers&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Number of CPU workers used by the data loader&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--seed&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;RNG seed for PyTorch, helps with deterministic training&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Configurations&lt;/h1&gt; &#xA;&lt;p&gt;Training and inference code for &lt;code&gt;stable-audio-tools&lt;/code&gt; is based around JSON configuration files that define model hyperparameters, training settings, and information about your training dataset.&lt;/p&gt; &#xA;&lt;h2&gt;Model config&lt;/h2&gt; &#xA;&lt;p&gt;The model config file defines all of the information needed to load a model for training or inference. It also contains the training configuration needed to fine-tune a model or train from scratch.&lt;/p&gt; &#xA;&lt;p&gt;The following properties are defined in the top level of the model configuration:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;model_type&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The type of model being defined, currently limited to one of &lt;code&gt;&#34;autoencoder&#34;, &#34;diffusion_uncond&#34;, &#34;diffusion_cond&#34;, &#34;diffusion_cond_inpaint&#34;, &#34;diffusion_autoencoder&#34;, &#34;lm&#34;&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;sample_size&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The length of the audio provided to the model during training, in samples. For diffusion models, this is also the raw audio sample length used for inference.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;sample_rate&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The sample rate of the audio provided to the model during training, and generated during inference, in Hz.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;audio_channels&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The number of channels of audio provided to the model during training, and generated during inference. Defaults to 2. Set to 1 for mono.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;model&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The specific configuration for the model being defined, varies based on &lt;code&gt;model_type&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;training&lt;/code&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The training configuration for the model, varies based on &lt;code&gt;model_type&lt;/code&gt;. Provides parameters for training as well as demos.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Dataset config&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;stable-audio-tools&lt;/code&gt; currently supports two kinds of data sources: local directories of audio files, and WebDataset datasets stored in Amazon S3. More information can be found in &lt;a href=&#34;https://raw.githubusercontent.com/Stability-AI/stable-audio-tools/main/docs/datasets.md&#34;&gt;the dataset config documentation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Todo&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add troubleshooting section&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add contribution guidelines&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/vscode</title>
    <updated>2024-06-08T01:28:00Z</updated>
    <id>tag:github.com,2024-06-08:/microsoft/vscode</id>
    <link href="https://github.com/microsoft/vscode" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Visual Studio Code&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Visual Studio Code - Open Source (&#34;Code - OSS&#34;)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/microsoft/vscode/feature-request.svg?sanitize=true&#34; alt=&#34;Feature Requests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/microsoft/vscode/issues?utf8=%E2%9C%93&amp;amp;q=is%3Aissue+is%3Aopen+label%3Abug&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/microsoft/vscode/bug.svg?sanitize=true&#34; alt=&#34;Bugs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://gitter.im/Microsoft/vscode&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/chat-on%20gitter-yellow.svg?sanitize=true&#34; alt=&#34;Gitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;The Repository&lt;/h2&gt; &#xA;&lt;p&gt;This repository (&#34;&lt;code&gt;Code - OSS&lt;/code&gt;&#34;) is where we (Microsoft) develop the &lt;a href=&#34;https://code.visualstudio.com&#34;&gt;Visual Studio Code&lt;/a&gt; product together with the community. Not only do we work on code and issues here, we also publish our &lt;a href=&#34;https://github.com/microsoft/vscode/wiki/Roadmap&#34;&gt;roadmap&lt;/a&gt;, &lt;a href=&#34;https://github.com/microsoft/vscode/wiki/Iteration-Plans&#34;&gt;monthly iteration plans&lt;/a&gt;, and our &lt;a href=&#34;https://github.com/microsoft/vscode/wiki/Running-the-Endgame&#34;&gt;endgame plans&lt;/a&gt;. This source code is available to everyone under the standard &lt;a href=&#34;https://github.com/microsoft/vscode/raw/main/LICENSE.txt&#34;&gt;MIT license&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Visual Studio Code&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img alt=&#34;VS Code in action&#34; src=&#34;https://user-images.githubusercontent.com/35271042/118224532-3842c400-b438-11eb-923d-a5f66fa6785a.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://code.visualstudio.com&#34;&gt;Visual Studio Code&lt;/a&gt; is a distribution of the &lt;code&gt;Code - OSS&lt;/code&gt; repository with Microsoft-specific customizations released under a traditional &lt;a href=&#34;https://code.visualstudio.com/License/&#34;&gt;Microsoft product license&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://code.visualstudio.com&#34;&gt;Visual Studio Code&lt;/a&gt; combines the simplicity of a code editor with what developers need for their core edit-build-debug cycle. It provides comprehensive code editing, navigation, and understanding support along with lightweight debugging, a rich extensibility model, and lightweight integration with existing tools.&lt;/p&gt; &#xA;&lt;p&gt;Visual Studio Code is updated monthly with new features and bug fixes. You can download it for Windows, macOS, and Linux on &lt;a href=&#34;https://code.visualstudio.com/Download&#34;&gt;Visual Studio Code&#39;s website&lt;/a&gt;. To get the latest releases every day, install the &lt;a href=&#34;https://code.visualstudio.com/insiders&#34;&gt;Insiders build&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;There are many ways in which you can participate in this project, for example:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/vscode/issues&#34;&gt;Submit bugs and feature requests&lt;/a&gt;, and help us verify as they are checked in&lt;/li&gt; &#xA; &lt;li&gt;Review &lt;a href=&#34;https://github.com/microsoft/vscode/pulls&#34;&gt;source code changes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Review the &lt;a href=&#34;https://github.com/microsoft/vscode-docs&#34;&gt;documentation&lt;/a&gt; and make pull requests for anything from typos to additional and new content&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you are interested in fixing issues and contributing directly to the code base, please see the document &lt;a href=&#34;https://github.com/microsoft/vscode/wiki/How-to-Contribute&#34;&gt;How to Contribute&lt;/a&gt;, which covers the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/vscode/wiki/How-to-Contribute&#34;&gt;How to build and run from source&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/vscode/wiki/How-to-Contribute#debugging&#34;&gt;The development workflow, including debugging and running tests&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/vscode/wiki/Coding-Guidelines&#34;&gt;Coding guidelines&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests&#34;&gt;Submitting pull requests&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/vscode/wiki/How-to-Contribute#where-to-contribute&#34;&gt;Finding an issue to work on&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/vscodeloc&#34;&gt;Contributing to translations&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Feedback&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ask a question on &lt;a href=&#34;https://stackoverflow.com/questions/tagged/vscode&#34;&gt;Stack Overflow&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/vscode/main/CONTRIBUTING.md&#34;&gt;Request a new feature&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Upvote &lt;a href=&#34;https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc&#34;&gt;popular feature requests&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/vscode/issues&#34;&gt;File an issue&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Connect with the extension author community on &lt;a href=&#34;https://github.com/microsoft/vscode-discussions/discussions&#34;&gt;GitHub Discussions&lt;/a&gt; or &lt;a href=&#34;https://aka.ms/vscode-dev-community&#34;&gt;Slack&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Follow &lt;a href=&#34;https://twitter.com/code&#34;&gt;@code&lt;/a&gt; and let us know what you think!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See our &lt;a href=&#34;https://github.com/microsoft/vscode/wiki/Feedback-Channels&#34;&gt;wiki&lt;/a&gt; for a description of each of these channels and information on some other available community-driven channels.&lt;/p&gt; &#xA;&lt;h2&gt;Related Projects&lt;/h2&gt; &#xA;&lt;p&gt;Many of the core components and extensions to VS Code live in their own repositories on GitHub. For example, the &lt;a href=&#34;https://github.com/microsoft/vscode-node-debug&#34;&gt;node debug adapter&lt;/a&gt; and the &lt;a href=&#34;https://github.com/microsoft/vscode-mono-debug&#34;&gt;mono debug adapter&lt;/a&gt; repositories are separate from each other. For a complete list, please visit the &lt;a href=&#34;https://github.com/microsoft/vscode/wiki/Related-Projects&#34;&gt;Related Projects&lt;/a&gt; page on our &lt;a href=&#34;https://github.com/microsoft/vscode/wiki&#34;&gt;wiki&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Bundled Extensions&lt;/h2&gt; &#xA;&lt;p&gt;VS Code includes a set of built-in extensions located in the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/vscode/main/extensions&#34;&gt;extensions&lt;/a&gt; folder, including grammars and snippets for many languages. Extensions that provide rich language support (code completion, Go to Definition) for a language have the suffix &lt;code&gt;language-features&lt;/code&gt;. For example, the &lt;code&gt;json&lt;/code&gt; extension provides coloring for &lt;code&gt;JSON&lt;/code&gt; and the &lt;code&gt;json-language-features&lt;/code&gt; extension provides rich language support for &lt;code&gt;JSON&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Development Container&lt;/h2&gt; &#xA;&lt;p&gt;This repository includes a Visual Studio Code Dev Containers / GitHub Codespaces development container.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;For &lt;a href=&#34;https://aka.ms/vscode-remote/download/containers&#34;&gt;Dev Containers&lt;/a&gt;, use the &lt;strong&gt;Dev Containers: Clone Repository in Container Volume...&lt;/strong&gt; command which creates a Docker volume for better disk I/O on macOS and Windows.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;If you already have VS Code and Docker installed, you can also click &lt;a href=&#34;https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/vscode&#34;&gt;here&lt;/a&gt; to get started. This will cause VS Code to automatically install the Dev Containers extension if needed, clone the source code into a container volume, and spin up a dev container for use.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For Codespaces, install the &lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=GitHub.codespaces&#34;&gt;GitHub Codespaces&lt;/a&gt; extension in VS Code, and use the &lt;strong&gt;Codespaces: Create New Codespace&lt;/strong&gt; command.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Docker / the Codespace should have at least &lt;strong&gt;4 Cores and 6 GB of RAM (8 GB recommended)&lt;/strong&gt; to run full build. See the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/vscode/main/.devcontainer/README.md&#34;&gt;development container README&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright (c) Microsoft Corporation. All rights reserved.&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/vscode/main/LICENSE.txt&#34;&gt;MIT&lt;/a&gt; license.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>livekit/livekit</title>
    <updated>2024-06-08T01:28:00Z</updated>
    <id>tag:github.com,2024-06-08:/livekit/livekit</id>
    <link href="https://github.com/livekit/livekit" rel="alternate"></link>
    <summary type="html">&lt;p&gt;End-to-end stack for WebRTC. SFU media server and SDKs.&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; &#xA; &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;/.github/banner_dark.png&#34;&gt; &#xA; &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;/.github/banner_light.png&#34;&gt; &#xA; &lt;img style=&#34;width:100%;&#34; alt=&#34;The LiveKit icon, the name of the repository and some sample code in the background.&#34; src=&#34;https://raw.githubusercontent.com/livekit/livekit/main/.github/banner_light.png&#34;&gt; &#xA;&lt;/picture&gt; &#xA;&lt;!--END_BANNER_IMAGE--&gt; &#xA;&lt;h1&gt;LiveKit: Real-time video, audio and data for developers&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://livekit.io&#34;&gt;LiveKit&lt;/a&gt; is an open source project that provides scalable, multi-user conferencing based on WebRTC. It&#39;s designed to provide everything you need to build real-time video audio data capabilities in your applications.&lt;/p&gt; &#xA;&lt;p&gt;LiveKit&#39;s server is written in Go, using the awesome &lt;a href=&#34;https://github.com/pion/webrtc&#34;&gt;Pion WebRTC&lt;/a&gt; implementation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/livekit/livekit/stargazers/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/livekit/livekit?style=social&amp;amp;label=Star&amp;amp;maxAge=2592000&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://livekit.io/join-slack&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint?url=https%3A%2F%2Flivekit.io%2Fbadges%2Fslack&#34; alt=&#34;Slack community&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/livekit&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/livekit&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/livekit/livekit/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/livekit/livekit&#34; alt=&#34;GitHub release (latest SemVer)&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/livekit/livekit/actions/workflows/buildtest.yaml&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/livekit/livekit/buildtest.yaml?branch=master&#34; alt=&#34;GitHub Workflow Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/livekit/livekit/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/livekit/livekit&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Scalable, distributed WebRTC SFU (Selective Forwarding Unit)&lt;/li&gt; &#xA; &lt;li&gt;Modern, full-featured client SDKs&lt;/li&gt; &#xA; &lt;li&gt;Built for production, supports JWT authentication&lt;/li&gt; &#xA; &lt;li&gt;Robust networking and connectivity, UDP/TCP/TURN&lt;/li&gt; &#xA; &lt;li&gt;Easy to deploy: single binary, Docker or Kubernetes&lt;/li&gt; &#xA; &lt;li&gt;Advanced features including: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.livekit.io/guides/room/receive/#speaker-detection&#34;&gt;speaker detection&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.livekit.io/guides/room/publish/#video-simulcast&#34;&gt;simulcast&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://blog.livekit.io/livekit-one-dot-zero/&#34;&gt;end-to-end optimizations&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.livekit.io/guides/room/receive/#selective-subscription&#34;&gt;selective subscription&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.livekit.io/guides/server-api/&#34;&gt;moderation APIs&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;end-to-end encryption&lt;/li&gt; &#xA;   &lt;li&gt;SVC codecs (VP9, AV1)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.livekit.io/guides/webhooks/&#34;&gt;webhooks&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.livekit.io/deploy/distributed/&#34;&gt;distributed and multi-region&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation &amp;amp; Guides&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.livekit.io&#34;&gt;https://docs.livekit.io&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Live Demos&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://meet.livekit.io&#34;&gt;LiveKit Meet&lt;/a&gt; (&lt;a href=&#34;https://github.com/livekit-examples/meet&#34;&gt;source&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://spatial-audio-demo.livekit.io/&#34;&gt;Spatial Audio&lt;/a&gt; (&lt;a href=&#34;https://github.com/livekit-examples/spatial-audio&#34;&gt;source&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Livestreaming from OBS Studio (&lt;a href=&#34;https://github.com/livekit-examples/livestream&#34;&gt;source&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://livekit.io/kitt&#34;&gt;AI voice assistant using ChatGPT&lt;/a&gt; (&lt;a href=&#34;https://github.com/livekit-examples/kitt&#34;&gt;source&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Ecosystem&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/livekit/agents&#34;&gt;Agents&lt;/a&gt;: build real-time multimodal AI applications with programmable backend participants&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/livekit/egress&#34;&gt;Egress&lt;/a&gt;: record or multi-stream rooms and export individual tracks&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/livekit/ingress&#34;&gt;Ingress&lt;/a&gt;: ingest streams from external sources like RTMP, WHIP, HLS, or OBS Studio&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;SDKs &amp;amp; Tools&lt;/h2&gt; &#xA;&lt;h3&gt;Client SDKs&lt;/h3&gt; &#xA;&lt;p&gt;Client SDKs enable your frontend to include interactive, multi-user experiences.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Language&lt;/th&gt; &#xA;   &lt;th&gt;Repo&lt;/th&gt; &#xA;   &lt;th&gt; &lt;a href=&#34;https://docs.livekit.io/guides/room/events/#declarative-ui&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Declarative UI&lt;/a&gt; &lt;/th&gt; &#xA;   &lt;th&gt;Links&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;!-- BEGIN Template&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Language&lt;/td&gt;&#xA;    &lt;td&gt;&#xA;      &lt;a href=&#34;&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;&lt;/a&gt;&#xA;    &lt;/td&gt;&#xA;    &lt;td&gt;&lt;/td&gt;&#xA;    &lt;td&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  END --&gt; &#xA;  &lt;!-- JavaScript --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;JavaScript (TypeScript)&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/livekit/client-sdk-js&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;client-sdk-js&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/livekit/livekit-react&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;React&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://docs.livekit.io/client-sdk-js/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;docs&lt;/a&gt; | &lt;a href=&#34;https://github.com/livekit/client-sdk-js/tree/main/example&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;JS example&lt;/a&gt; | &lt;a href=&#34;https://github.com/livekit/client-sdk-js/tree/main/example&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;React example&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;!-- Swift --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Swift (iOS / MacOS)&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/livekit/client-sdk-swift&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;client-sdk-swift&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Swift UI&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://docs.livekit.io/client-sdk-swift/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;docs&lt;/a&gt; | &lt;a href=&#34;https://github.com/livekit/client-example-swift&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;example&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;!-- Kotlin --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Kotlin (Android)&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/livekit/client-sdk-android&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;client-sdk-android&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;Compose&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://docs.livekit.io/client-sdk-android/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;docs&lt;/a&gt; | &lt;a href=&#34;https://github.com/livekit/client-sdk-android/tree/main/sample-app/src/main/java/io/livekit/android/sample&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;example&lt;/a&gt; | &lt;a href=&#34;https://github.com/livekit/client-sdk-android/tree/main/sample-app-compose/src/main/java/io/livekit/android/composesample&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Compose example&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;!-- Flutter --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Flutter (all platforms)&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/livekit/client-sdk-flutter&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;client-sdk-flutter&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;native&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://docs.livekit.io/client-sdk-flutter/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;docs&lt;/a&gt; | &lt;a href=&#34;https://github.com/livekit/client-sdk-flutter/tree/main/example&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;example&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;!-- Unity --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unity WebGL&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/livekit/client-sdk-unity-web&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;client-sdk-unity-web&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://livekit.github.io/client-sdk-unity-web/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;docs&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;!-- React Native --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;React Native (beta)&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/livekit/client-sdk-react-native&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;client-sdk-react-native&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;native&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;!-- Rust --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Rust&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/livekit/client-sdk-rust&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;client-sdk-rust&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Server SDKs&lt;/h3&gt; &#xA;&lt;p&gt;Server SDKs enable your backend to generate &lt;a href=&#34;https://docs.livekit.io/guides/access-tokens/&#34;&gt;access tokens&lt;/a&gt;, call &lt;a href=&#34;https://docs.livekit.io/guides/server-api/&#34;&gt;server APIs&lt;/a&gt;, and receive &lt;a href=&#34;https://docs.livekit.io/guides/webhooks/&#34;&gt;webhooks&lt;/a&gt;. In addition, the Go SDK includes client capabilities, enabling you to build automations that behave like end-users.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Language&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Repo&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Docs&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Go&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/livekit/server-sdk-go&#34;&gt;server-sdk-go&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://pkg.go.dev/github.com/livekit/server-sdk-go&#34;&gt;docs&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;JavaScript (TypeScript)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/livekit/server-sdk-js&#34;&gt;server-sdk-js&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://docs.livekit.io/server-sdk-js/&#34;&gt;docs&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Ruby&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/livekit/server-sdk-ruby&#34;&gt;server-sdk-ruby&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Java (Kotlin)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/livekit/server-sdk-kotlin&#34;&gt;server-sdk-kotlin&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Python (community)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/livekit/python-sdks&#34;&gt;python-sdks&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;PHP (community)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/agence104/livekit-server-sdk-php&#34;&gt;agence104/livekit-server-sdk-php&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Tools&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/livekit/livekit-cli&#34;&gt;CLI&lt;/a&gt; - command line interface &amp;amp; load tester&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hub.docker.com/r/livekit/livekit-server&#34;&gt;Docker image&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/livekit/livekit-helm&#34;&gt;Helm charts&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] We recommend installing &lt;a href=&#34;https://github.com/livekit/livekit-cli&#34;&gt;LiveKit CLI&lt;/a&gt; along with the server. It lets you access server APIs, create tokens, and generate test traffic.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;The following will install LiveKit&#39;s media server:&lt;/p&gt; &#xA;&lt;h3&gt;MacOS&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;brew install livekit&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Linux&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -sSL https://get.livekit.io | bash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Windows&lt;/h3&gt; &#xA;&lt;p&gt;Download the &lt;a href=&#34;https://github.com/livekit/livekit/releases/latest&#34;&gt;latest release here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Starting LiveKit&lt;/h3&gt; &#xA;&lt;p&gt;Start LiveKit in development mode by running &lt;code&gt;livekit-server --dev&lt;/code&gt;. It&#39;ll use a placeholder API key/secret pair.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;API Key: devkey&#xA;API Secret: secret&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To customize your setup for production, refer to our &lt;a href=&#34;https://docs.livekit.io/deploy/&#34;&gt;deployment docs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Creating access token&lt;/h3&gt; &#xA;&lt;p&gt;A user connecting to a LiveKit room requires an &lt;a href=&#34;https://docs.livekit.io/guides/access-tokens/&#34;&gt;access token&lt;/a&gt;. Access tokens (JWT) encode the user&#39;s identity and the room permissions they&#39;ve been granted. You can generate a token with our CLI:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;livekit-cli create-token \&#xA;    --api-key devkey --api-secret secret \&#xA;    --join --room my-first-room --identity user1 \&#xA;    --valid-for 24h&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Test with example app&lt;/h3&gt; &#xA;&lt;p&gt;Head over to our &lt;a href=&#34;https://example.livekit.io&#34;&gt;example app&lt;/a&gt; and enter a generated token to connect to your LiveKit server. This app is built with our &lt;a href=&#34;https://github.com/livekit/livekit-react&#34;&gt;React SDK&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Once connected, your video and audio are now being published to your new LiveKit instance!&lt;/p&gt; &#xA;&lt;h3&gt;Simulating a test publisher&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;livekit-cli join-room \&#xA;    --url ws://localhost:7880 \&#xA;    --api-key devkey --api-secret secret \&#xA;    --room my-first-room --identity bot-user1 \&#xA;    --publish-demo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command publishes a looped demo video to a room. Due to how the video clip was encoded (keyframes every 3s), there&#39;s a slight delay before the browser has sufficient data to begin rendering frames. This is an artifact of the simulation.&lt;/p&gt; &#xA;&lt;h2&gt;Deployment&lt;/h2&gt; &#xA;&lt;h3&gt;Use LiveKit Cloud&lt;/h3&gt; &#xA;&lt;p&gt;LiveKit Cloud is the fastest and most reliable way to run LiveKit. Every project gets free monthly bandwidth and transcoding credits.&lt;/p&gt; &#xA;&lt;p&gt;Sign up for &lt;a href=&#34;https://cloud.livekit.io/&#34;&gt;LiveKit Cloud&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Self-host&lt;/h3&gt; &#xA;&lt;p&gt;Read our &lt;a href=&#34;https://docs.livekit.io/deploy/&#34;&gt;deployment docs&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Building from source&lt;/h2&gt; &#xA;&lt;p&gt;Pre-requisites:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Go 1.20+ is installed&lt;/li&gt; &#xA; &lt;li&gt;GOPATH/bin is in your PATH&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Then run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/livekit/livekit&#xA;cd livekit&#xA;./bootstrap.sh&#xA;mage&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome your contributions toward improving LiveKit! Please join us &lt;a href=&#34;http://livekit.io/join-slack&#34;&gt;on Slack&lt;/a&gt; to discuss your ideas and/or PRs.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;LiveKit server is licensed under Apache License v2.0.&lt;/p&gt; &#xA;&lt;!--BEGIN_REPO_NAV--&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&lt;table&gt; &#xA; &lt;thead&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;th colspan=&#34;2&#34;&gt;LiveKit Ecosystem&lt;/th&gt;&#xA;  &lt;/tr&gt;&#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;Real-time SDKs&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/livekit/components-js&#34;&gt;React Components&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/client-sdk-js&#34;&gt;Browser&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/client-sdk-swift&#34;&gt;iOS/macOS&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/client-sdk-android&#34;&gt;Android&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/client-sdk-flutter&#34;&gt;Flutter&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/client-sdk-react-native&#34;&gt;React Native&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/rust-sdks&#34;&gt;Rust&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/node-sdks&#34;&gt;Node.js&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/python-sdks&#34;&gt;Python&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/client-sdk-unity-web&#34;&gt;Unity (web)&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/client-sdk-unity&#34;&gt;Unity (beta)&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;Server APIs&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/livekit/node-sdks&#34;&gt;Node.js&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/server-sdk-go&#34;&gt;Golang&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/server-sdk-ruby&#34;&gt;Ruby&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/server-sdk-kotlin&#34;&gt;Java/Kotlin&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/python-sdks&#34;&gt;Python&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/rust-sdks&#34;&gt;Rust&lt;/a&gt; · &lt;a href=&#34;https://github.com/agence104/livekit-server-sdk-php&#34;&gt;PHP (community)&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;Agents Frameworks&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/livekit/agents&#34;&gt;Python&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/agent-playground&#34;&gt;Playground&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;Services&lt;/td&gt;&#xA;   &lt;td&gt;&lt;b&gt;Livekit server&lt;/b&gt; · &lt;a href=&#34;https://github.com/livekit/egress&#34;&gt;Egress&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/ingress&#34;&gt;Ingress&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/sip&#34;&gt;SIP&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td&gt;Resources&lt;/td&gt;&#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.livekit.io&#34;&gt;Docs&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit-examples&#34;&gt;Example apps&lt;/a&gt; · &lt;a href=&#34;https://livekit.io/cloud&#34;&gt;Cloud&lt;/a&gt; · &lt;a href=&#34;https://docs.livekit.io/oss/deployment&#34;&gt;Self-hosting&lt;/a&gt; · &lt;a href=&#34;https://github.com/livekit/livekit-cli&#34;&gt;CLI&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!--END_REPO_NAV--&gt;</summary>
  </entry>
</feed>