<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-12-21T01:28:18Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>taichi-dev/taichi</title>
    <updated>2024-12-21T01:28:18Z</updated>
    <id>tag:github.com,2024-12-21:/taichi-dev/taichi</id>
    <link href="https://github.com/taichi-dev/taichi" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Productive, portable, and performant GPU programming in Python.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img width=&#34;500px&#34; src=&#34;https://github.com/taichi-dev/taichi/raw/master/misc/logo.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/taichi-dev/taichi/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/taichi-dev/taichi?color=blue&amp;amp;label=Latest%20Release&#34; alt=&#34;Latest Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/taichi&#34;&gt;&lt;img src=&#34;https://pepy.tech/badge/taichi&#34; alt=&#34;downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/taichi-dev/taichi/actions/workflows/testing.yml&#34;&gt;&lt;img src=&#34;https://github.com/taichi-dev/taichi/actions/workflows/testing.yml/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/taichi-dev/taichi/actions/workflows/release.yml&#34;&gt;&lt;img src=&#34;https://github.com/taichi-dev/taichi/actions/workflows/release.yml/badge.svg?sanitize=true&#34; alt=&#34;Nightly Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/f25GRdXRfg&#34;&gt;&lt;img alt=&#34;discord invitation link&#34; src=&#34;https://dcbadge.vercel.app/api/server/f25GRdXRfg?style=flat&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install taichi  # Install Taichi Lang&#xA;ti gallery          # Launch demo gallery&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;What is Taichi Lang?&lt;/h2&gt; &#xA;&lt;p&gt;Taichi Lang is an open-source, imperative, parallel programming language for high-performance numerical computation. It is embedded in Python and uses just-in-time (JIT) compiler frameworks, for example LLVM, to offload the compute-intensive Python code to the native GPU or CPU instructions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/taichi-dev/taichi/raw/master/python/taichi/examples/simulation/fractal.py#L1-L31&#34;&gt; &lt;img src=&#34;https://github.com/taichi-dev/public_files/raw/master/taichi/fractal_code.png&#34; height=&#34;270px&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://raw.githubusercontent.com/taichi-dev/public_files/master/taichi/fractal_small.gif&#34; height=&#34;270px&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The language has broad applications spanning real-time physical simulation, numerical computation, augmented reality, artificial intelligence, vision and robotics, visual effects in films and games, general-purpose computing, and much more.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/taichi-dev/taichi/raw/master/python/taichi/examples/simulation/mpm128.py&#34;&gt;&lt;img src=&#34;https://github.com/taichi-dev/public_files/raw/master/taichi/mpm128.gif&#34; height=&#34;192px&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/taichi-dev/quantaichi&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/taichi-dev/public_files/master/taichi/smoke_3d.gif&#34; height=&#34;192px&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/taichi-dev/taichi/raw/master/python/taichi/examples/rendering/sdf_renderer.py&#34;&gt;&lt;img src=&#34;https://github.com/taichi-dev/public_files/raw/master/taichi/sdf_renderer.jpg&#34; height=&#34;192px&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/taichi-dev/taichi/raw/master/python/taichi/examples/simulation/euler.py&#34;&gt;&lt;img src=&#34;https://github.com/taichi-dev/public_files/raw/master/taichi/euler.gif&#34; height=&#34;192px&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/taichi-dev/quantaichi&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/taichi-dev/public_files/master/taichi/elastic_letters.gif&#34; height=&#34;213px&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/taichi-dev/quantaichi&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/taichi-dev/public_files/master/taichi/fluid_with_bunnies.gif&#34; height=&#34;213px&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/taichi-dev/taichi/master/#demos&#34;&gt;...More&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Why Taichi Lang?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Built around Python: Taichi Lang shares almost the same syntax with Python, allowing you to write algorithms with minimal language barrier. It is also well integrated into the Python ecosystem, including NumPy and PyTorch.&lt;/li&gt; &#xA; &lt;li&gt;Flexibility: Taichi Lang provides a set of generic data containers known as &lt;em&gt;SNode&lt;/em&gt; (/Ààsno äd/), an effective mechanism for composing hierarchical, multi-dimensional fields. This can cover many use patterns in numerical simulation (e.g. &lt;a href=&#34;https://docs.taichi-lang.org/docs/sparse&#34;&gt;spatially sparse computing&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Performance: With the &lt;code&gt;@ti.kernel&lt;/code&gt; decorator, Taichi Lang&#39;s JIT compiler automatically compiles your Python functions into efficient GPU or CPU machine code for parallel execution.&lt;/li&gt; &#xA; &lt;li&gt;Portability: Write your code once and run it everywhere. Currently, Taichi Lang supports most mainstream GPU APIs, such as CUDA and Vulkan.&lt;/li&gt; &#xA; &lt;li&gt;... and many more features! A cross-platform, Vulkan-based 3D visualizer, &lt;a href=&#34;https://docs.taichi-lang.org/docs/differentiable_programming&#34;&gt;differentiable programming&lt;/a&gt;, &lt;a href=&#34;https://github.com/taichi-dev/quantaichi&#34;&gt;quantized computation&lt;/a&gt; (experimental), etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Prerequisites&lt;/summary&gt; &#xA; &lt;!--TODO: Precise OS versions--&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Operating systems &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Windows&lt;/li&gt; &#xA;    &lt;li&gt;Linux&lt;/li&gt; &#xA;    &lt;li&gt;macOS&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;Python: 3.6 ~ 3.10 (64-bit only)&lt;/li&gt; &#xA;  &lt;li&gt;Compute backends &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;x64/ARM CPUs&lt;/li&gt; &#xA;    &lt;li&gt;CUDA&lt;/li&gt; &#xA;    &lt;li&gt;Vulkan&lt;/li&gt; &#xA;    &lt;li&gt;OpenGL (4.3+)&lt;/li&gt; &#xA;    &lt;li&gt;Apple Metal&lt;/li&gt; &#xA;    &lt;li&gt;WebAssembly (experiemental)&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;Use Python&#39;s package installer &lt;strong&gt;pip&lt;/strong&gt; to install Taichi Lang:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install --upgrade taichi&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;We also provide a nightly package. Note that nightly packages may crash because they are not fully tested. We cannot guarantee their validity, and you are at your own risk trying out our latest, untested features. The nightly packages can be installed from our self-hosted PyPI (Using self-hosted PyPI allows us to provide more frequent releases over a longer period of time)&lt;/em&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -i https://pypi.taichi.graphics/simple/ taichi-nightly&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run your &#34;Hello, world!&#34;&lt;/h3&gt; &#xA;&lt;p&gt;Here is how you can program a 2D fractal in Taichi:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;# python/taichi/examples/simulation/fractal.py&#xA;&#xA;import taichi as ti&#xA;&#xA;ti.init(arch=ti.gpu)&#xA;&#xA;n = 320&#xA;pixels = ti.field(dtype=float, shape=(n * 2, n))&#xA;&#xA;&#xA;@ti.func&#xA;def complex_sqr(z):&#xA;    return ti.Vector([z[0]**2 - z[1]**2, z[1] * z[0] * 2])&#xA;&#xA;&#xA;@ti.kernel&#xA;def paint(t: float):&#xA;    for i, j in pixels:  # Parallelized over all pixels&#xA;        c = ti.Vector([-0.8, ti.cos(t) * 0.2])&#xA;        z = ti.Vector([i / n - 1, j / n - 0.5]) * 2&#xA;        iterations = 0&#xA;        while z.norm() &amp;lt; 20 and iterations &amp;lt; 50:&#xA;            z = complex_sqr(z) + c&#xA;            iterations += 1&#xA;        pixels[i, j] = 1 - iterations * 0.02&#xA;&#xA;&#xA;gui = ti.GUI(&#34;Julia Set&#34;, res=(n * 2, n))&#xA;&#xA;for i in range(1000000):&#xA;    paint(i * 0.03)&#xA;    gui.set_image(pixels)&#xA;    gui.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;If Taichi Lang is properly installed, you should get the animation below üéâ:&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/taichi-dev/taichi/raw/master/python/taichi/examples/simulation/fractal.py#L1-L31&#34;&gt; &lt;/a&gt;&lt;img src=&#34;https://raw.githubusercontent.com/taichi-dev/public_files/master/taichi/fractal_small.gif&#34; height=&#34;270px&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://docs.taichi-lang.org&#34;&gt;Get started&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h3&gt;Build from source&lt;/h3&gt; &#xA;&lt;p&gt;If you wish to try our our experimental features or build Taichi Lang for your own environments, see &lt;a href=&#34;https://docs.taichi-lang.org/docs/dev_install&#34;&gt;Developer installation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.taichi-lang.org/&#34;&gt;Technical documents&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.taichi-lang.org/api/&#34;&gt;API Reference&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.taichi-lang.org/blog&#34;&gt;Blog&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Community activity &lt;a href=&#34;https://repography.com&#34;&gt;&lt;img src=&#34;https://images.repography.com/32602247/taichi-dev/taichi/recent-activity/RlhQybvihwEjfE7ngXyQR9tudBDYAvl27v-NVNMxUrg_badge.svg?sanitize=true&#34; alt=&#34;Time period&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/taichi-dev/taichi/commits&#34;&gt;&lt;img src=&#34;https://images.repography.com/32602247/taichi-dev/taichi/recent-activity/RlhQybvihwEjfE7ngXyQR9tudBDYAvl27v-NVNMxUrg_timeline.svg?sanitize=true&#34; alt=&#34;Timeline graph&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/taichi-dev/taichi/issues&#34;&gt;&lt;img src=&#34;https://images.repography.com/32602247/taichi-dev/taichi/recent-activity/RlhQybvihwEjfE7ngXyQR9tudBDYAvl27v-NVNMxUrg_issues.svg?sanitize=true&#34; alt=&#34;Issue status graph&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/taichi-dev/taichi/pulls&#34;&gt;&lt;img src=&#34;https://images.repography.com/32602247/taichi-dev/taichi/recent-activity/RlhQybvihwEjfE7ngXyQR9tudBDYAvl27v-NVNMxUrg_prs.svg?sanitize=true&#34; alt=&#34;Pull request status graph&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/taichi-dev/taichi/commits&#34;&gt;&lt;img src=&#34;https://images.repography.com/32602247/taichi-dev/taichi/recent-activity/RlhQybvihwEjfE7ngXyQR9tudBDYAvl27v-NVNMxUrg_words.svg?sanitize=true&#34; alt=&#34;Trending topics&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Kudos to all of our amazing contributors! Taichi Lang thrives through open-source. In that spirit, we welcome all kinds of contributions from the community. If you would like to participate, check out the &lt;a href=&#34;https://raw.githubusercontent.com/taichi-dev/taichi/master/CONTRIBUTING.md&#34;&gt;Contribution Guidelines&lt;/a&gt; first.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/taichi-dev/taichi/graphs/contributors&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/taichi-dev/public_files/master/taichi/contributors_taichi-dev_taichi_18.png&#34; width=&#34;800px&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Contributor avatars are randomly shuffled.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Taichi Lang is distributed under the terms of Apache License (Version 2.0).&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/taichi-dev/taichi/raw/master/LICENSE&#34;&gt;Apache License&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;For more information about the events or community, please refer to &lt;a href=&#34;https://github.com/taichi-dev/community&#34;&gt;this page&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Join our discussions&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.gg/f25GRdXRfg&#34;&gt;Discord&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/taichi-dev/taichi/discussions&#34;&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://forum.taichi.graphics/&#34;&gt;Â§™ÊûÅÁºñÁ®ãËØ≠Ë®Ä‰∏≠ÊñáËÆ∫Âùõ&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Report an issue&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you spot an technical or documentation issue, file an issue at &lt;a href=&#34;https://github.com/taichi-dev/taichi/issues&#34;&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;If you spot any security issue, mail directly to &lt;a href=&#34;mailto:security@taichi.graphics?subject%20=%20Taichi%20Security%20Problem&#34;&gt;&lt;/a&gt;&lt;a href=&#34;mailto:security@taichi.graphics&#34;&gt;security@taichi.graphics&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Contact us&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.gg/f25GRdXRfg&#34;&gt;Discord&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://forum.taichi-lang.cn/t/topic/2884&#34;&gt;WeChat&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Reference&lt;/h2&gt; &#xA;&lt;h3&gt;Demos&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/taichi-dev/taichi-nerfs&#34;&gt;Nerf with Taichi&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/taichi-dev/taichi/tree/master/python/taichi/examples&#34;&gt;Taichi Lang examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/taichi-dev/advanced_examples&#34;&gt;Advanced Taichi Lang examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/taichi-dev/awesome-taichi&#34;&gt;Awesome Taichi&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/taichi-dev/difftaichi&#34;&gt;DiffTaichi&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/taichi-dev/taichi_elements&#34;&gt;Taichi elements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/taichi-dev/taichi_houdini&#34;&gt;Taichi Houdini&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/taichi-dev/taichi/master/misc/links.md&#34;&gt;More...&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;AOT deployment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/taichi-dev/taichi-aot-demo/&#34;&gt;Taichi AOT demos &amp;amp; tutorial&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Lectures &amp;amp; talks&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;SIGGRAPH 2020 course on Taichi basics: &lt;a href=&#34;https://youtu.be/Y0-76n3aZFA&#34;&gt;YouTube&lt;/a&gt;, &lt;a href=&#34;https://www.bilibili.com/video/BV1kA411n7jk/&#34;&gt;Bilibili&lt;/a&gt;, &lt;a href=&#34;https://yuanming.taichi.graphics/publication/2020-taichi-tutorial/taichi-tutorial.pdf&#34;&gt;slides (pdf)&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Chinagraph 2020 Áî®Â§™ÊûÅÁºñÂÜôÁâ©ÁêÜÂºïÊìé: &lt;a href=&#34;https://www.bilibili.com/video/BV1gA411j7H5&#34;&gt;ÂìîÂì©ÂìîÂì©&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;GAMES 201 È´òÁ∫ßÁâ©ÁêÜÂºïÊìéÂÆûÊàòÊåáÂçó 2020: &lt;a href=&#34;https://github.com/taichi-dev/games201&#34;&gt;ËØæ‰ª∂&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Â§™ÊûÅÂõæÂΩ¢ËØæÁ¨¨‰∏ÄÂ≠£Ôºö&lt;a href=&#34;https://github.com/taichiCourse01&#34;&gt;ËØæ‰ª∂&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/taichi-dev/taichicon&#34;&gt;TaichiCon&lt;/a&gt;: Taichi Developer Conferences&lt;/li&gt; &#xA; &lt;li&gt;More to come...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Citations&lt;/h3&gt; &#xA;&lt;p&gt;If you use Taichi Lang in your research, please cite the corresponding papers:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yuanming.taichi.graphics/publication/2019-taichi/taichi-lang.pdf&#34;&gt;&lt;strong&gt;(SIGGRAPH Asia 2019) Taichi: High-Performance Computation on Sparse Data Structures&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;https://youtu.be/wKw8LMF3Djo&#34;&gt;[Video]&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/taichi-dev/taichi/master/misc/taichi_bibtex.txt&#34;&gt;[BibTex]&lt;/a&gt; &lt;a href=&#34;https://github.com/taichi-dev/taichi&#34;&gt;[Code]&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1910.00935&#34;&gt;&lt;strong&gt;(ICLR 2020) DiffTaichi: Differentiable Programming for Physical Simulation&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=Z1xvAZve9aE&#34;&gt;[Video]&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/taichi-dev/taichi/master/misc/difftaichi_bibtex.txt&#34;&gt;[BibTex]&lt;/a&gt; &lt;a href=&#34;https://github.com/yuanming-hu/difftaichi&#34;&gt;[Code]&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yuanming.taichi.graphics/publication/2021-quantaichi/quantaichi.pdf&#34;&gt;&lt;strong&gt;(SIGGRAPH 2021) QuanTaichi: A Compiler for Quantized Simulations&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=0jdrAQOxJlY&#34;&gt;[Video]&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/taichi-dev/taichi/master/misc/quantaichi_bibtex.txt&#34;&gt;[BibTex]&lt;/a&gt; &lt;a href=&#34;https://github.com/taichi-dev/quantaichi&#34;&gt;[Code]&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>comet-ml/opik</title>
    <updated>2024-12-21T01:28:18Z</updated>
    <id>tag:github.com,2024-12-21:/comet-ml/opik</id>
    <link href="https://github.com/comet-ml/opik" rel="alternate"></link>
    <summary type="html">&lt;p&gt;From RAG chatbots to code assistants to complex agentic pipelines and beyond, build LLM systems that run better, faster, and cheaper with tracing, evaluations, and dashboards.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34; style=&#34;border-bottom: none&#34;&gt; &#xA; &lt;div&gt; &#xA;  &lt;a href=&#34;https://www.comet.com/site/products/opik/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=header_img&amp;amp;utm_campaign=opik&#34;&gt;&#xA;   &lt;picture&gt; &#xA;    &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;/apps/opik-documentation/documentation/static/img/logo-dark-mode.svg&#34;&gt; &#xA;    &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;/apps/opik-documentation/documentation/static/img/opik-logo.svg&#34;&gt; &#xA;    &lt;img alt=&#34;Comet Opik logo&#34; src=&#34;https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/static/img/opik-logo.svg?sanitize=true&#34; width=&#34;200&#34;&gt; &#xA;   &lt;/picture&gt;&lt;/a&gt; &#xA;  &lt;br&gt; Opik &#xA; &lt;/div&gt; Open source LLM evaluation framework&lt;br&gt; &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; From RAG chatbots to code assistants to complex agentic pipelines and beyond, build LLM systems that run better, faster, and cheaper with tracing, evaluations, and dashboards. &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://pypi.org/project/opik/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/opik&#34; alt=&#34;Python SDK&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/comet-ml/opik/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/comet-ml/opik&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/comet-ml/opik/actions/workflows/build_apps.yml&#34;&gt;&lt;img src=&#34;https://github.com/comet-ml/opik/actions/workflows/build_apps.yml/badge.svg?sanitize=true&#34; alt=&#34;Build&#34;&gt;&lt;/a&gt; &lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/opik_quickstart.ipynb&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA; &lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/opik_quickstart.ipynb&#34;&gt; &#xA;  &lt;!-- &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; alt=&#34;Open Quickstart In Colab&#34;/&gt; --&gt; &lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.comet.com/site/products/opik/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=website_button&amp;amp;utm_campaign=opik&#34;&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://chat.comet.com&#34;&gt;&lt;b&gt;Slack community&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://x.com/Cometml&#34;&gt;&lt;b&gt;Twitter&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href=&#34;https://www.comet.com/docs/opik/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=docs_button&amp;amp;utm_campaign=opik&#34;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/comet-ml/opik/main/readme-thumbnail.png&#34; alt=&#34;Opik thumbnail&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ What is Opik?&lt;/h2&gt; &#xA;&lt;p&gt;Opik is an open-source platform for evaluating, testing and monitoring LLM applications. Built by &lt;a href=&#34;https://www.comet.com?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=what_is_opik_link&amp;amp;utm_campaign=opik&#34;&gt;Comet&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;You can use Opik for:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Development:&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tracing:&lt;/strong&gt; Track all LLM calls and traces during development and production (&lt;a href=&#34;https://www.comet.com/docs/opik/quickstart/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=quickstart_link&amp;amp;utm_campaign=opik&#34;&gt;Quickstart&lt;/a&gt;, &lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/overview/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=integrations_link&amp;amp;utm_campaign=opik&#34;&gt;Integrations&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Annotations:&lt;/strong&gt; Annotate your LLM calls by logging feedback scores using the &lt;a href=&#34;https://www.comet.com/docs/opik/tracing/annotate_traces/#annotating-traces-and-spans-using-the-sdk?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=sdk_link&amp;amp;utm_campaign=opik&#34;&gt;Python SDK&lt;/a&gt; or the &lt;a href=&#34;https://www.comet.com/docs/opik/tracing/annotate_traces/#annotating-traces-through-the-ui?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=ui_link&amp;amp;utm_campaign=opik&#34;&gt;UI&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Evaluation&lt;/strong&gt;: Automate the evaluation process of your LLM application:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Datasets and Experiments&lt;/strong&gt;: Store test cases and run experiments (&lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/manage_datasets/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=datasets_link&amp;amp;utm_campaign=opik&#34;&gt;Datasets&lt;/a&gt;, &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/evaluate_your_llm/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=eval_link&amp;amp;utm_campaign=opik&#34;&gt;Evaluate your LLM Application&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;LLM as a judge metrics&lt;/strong&gt;: Use Opik&#39;s LLM as a judge metric for complex issues like &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/metrics/hallucination/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=hallucination_link&amp;amp;utm_campaign=opik&#34;&gt;hallucination detection&lt;/a&gt;, &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/metrics/moderation/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=moderation_link&amp;amp;utm_campaign=opik&#34;&gt;moderation&lt;/a&gt; and RAG evaluation (&lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/metrics/answer_relevance/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=alex_link&amp;amp;utm_campaign=opik&#34;&gt;Answer Relevance&lt;/a&gt;, &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/metrics/context_precision/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=context_link&amp;amp;utm_campaign=opik&#34;&gt;Context Precision&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;CI/CD integration&lt;/strong&gt;: Run evaluations as part of your CI/CD pipeline using our &lt;a href=&#34;https://www.comet.com/docs/opik/testing/pytest_integration/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=pytest_link&amp;amp;utm_campaign=opik&#34;&gt;PyTest integration&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Production Monitoring&lt;/strong&gt;:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Log all your production traces&lt;/strong&gt;: Opik has been designed to support high volumes of traces, making it easy to monitor your production applications.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Monitoring dashboards&lt;/strong&gt;: Review your feedback scores, trace count and tokens over time in the &lt;a href=&#34;https://www.comet.com/docs/opik/self-host/opik_dashboard/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=dashboard_link&amp;amp;utm_campaign=opik&#34;&gt;Opik Dashboard&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP]&lt;br&gt; If you are looking for features that Opik doesn&#39;t have today, please raise a new &lt;a href=&#34;https://github.com/comet-ml/opik/issues/new/choose&#34;&gt;Feature request&lt;/a&gt; üöÄ&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;üõ†Ô∏è Installation&lt;/h2&gt; &#xA;&lt;p&gt;Opik is available as a fully open source local installation or using Comet.com as a hosted solution. The easiest way to get started with Opik is by creating a free Comet account at &lt;a href=&#34;https://www.comet.com/signup?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=install&amp;amp;utm_campaign=opik&#34;&gt;comet.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;d like to self-host Opik, you can do so by cloning the repository and starting the platform using Docker Compose:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Clone the Opik repository&#xA;git clone https://github.com/comet-ml/opik.git&#xA;&#xA;# Navigate to the opik/deployment/docker-compose directory&#xA;cd opik/deployment/docker-compose&#xA;&#xA;# Start the Opik platform&#xA;docker compose up --detach&#xA;&#xA;# You can now visit http://localhost:5173 on your browser!&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information about the different deployment options, please see our deployment guides:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Installation methods&lt;/th&gt; &#xA;   &lt;th&gt;Docs link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Local instance&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/self-host/local_deployment?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=self_host_link&amp;amp;utm_campaign=opik&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Local%20Deployments-%232496ED?style=flat&amp;amp;logo=docker&amp;amp;logoColor=white&#34; alt=&#34;Local Deployment&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Kubernetes&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/self-host/kubernetes/#kubernetes-installation?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=kubernetes_link&amp;amp;utm_campaign=opik&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Kubernetes-%23326ce5.svg?&amp;amp;logo=kubernetes&amp;amp;logoColor=white&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;üèÅ Get Started&lt;/h2&gt; &#xA;&lt;p&gt;To get started, you will need to first install the Python SDK:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install opik&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once the SDK is installed, you can configure it by running the &lt;code&gt;opik configure&lt;/code&gt; command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;opik configure&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will allow you to configure Opik locally by setting the correct local server address or if you&#39;re using the Cloud platform by setting the API Key&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP]&lt;br&gt; You can also call the &lt;code&gt;opik.configure(use_local=True)&lt;/code&gt; method from your Python code to configure the SDK to run on the local installation.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;You are now ready to start logging traces using the &lt;a href=&#34;https://www.comet.com/docs/opik/python-sdk-reference/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=sdk_link2&amp;amp;utm_campaign=opik&#34;&gt;Python SDK&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;üìù Logging Traces&lt;/h3&gt; &#xA;&lt;p&gt;The easiest way to get started is to use one of our integrations. Opik supports:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Integration&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Documentation&lt;/th&gt; &#xA;   &lt;th&gt;Try in Colab&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OpenAI&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all OpenAI LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/openai/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=openai_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/openai.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LiteLLM&lt;/td&gt; &#xA;   &lt;td&gt;Call any LLM model using the OpenAI format&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/comet-ml/opik/main/tracing/integrations/litellm.md&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/litellm.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LangChain&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all LangChain LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/langchain/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=langchain_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/langchain.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Haystack&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all Haystack calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/haystack/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=haystack_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/haystack.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Bedrock&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all Bedrock LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/bedrock?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=bedrock_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/bedrock.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Anthropic&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all Anthropic LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/anthropic?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=anthropic_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/anthropic.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gemini&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all Gemini LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/gemini?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=gemini_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/gemini.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Groq&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all Groq LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/groq?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=groq_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/groq.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LangGraph&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all LangGraph executions&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/langgraph/?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=langchain_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/langgraph.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LlamaIndex&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all LlamaIndex LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/llama_index?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=llama_index_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/llama-index.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ollama&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all Ollama LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/ollama?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=ollama_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/ollama.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Predibase&lt;/td&gt; &#xA;   &lt;td&gt;Fine-tune and serve open-source Large Language Models&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/predibase?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=predibase_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/predibase.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ragas&lt;/td&gt; &#xA;   &lt;td&gt;Evaluation framework for your Retrieval Augmented Generation (RAG) pipelines&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/ragas?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=ragas_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/ragas.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;watsonx&lt;/td&gt; &#xA;   &lt;td&gt;Log traces for all watsonx LLM calls&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.comet.com/docs/opik/tracing/integrations/watsonx?utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=watsonx_link&amp;amp;utm_campaign=opik&#34;&gt;Documentation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/watsonx.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Quickstart In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP]&lt;br&gt; If the framework you are using is not listed above, feel free to &lt;a href=&#34;https://github.com/comet-ml/opik/issues&#34;&gt;open an issue&lt;/a&gt; or submit a PR with the integration.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;If you are not using any of the frameworks above, you can also use the &lt;code&gt;track&lt;/code&gt; function decorator to &lt;a href=&#34;https://www.comet.com/docs/opik/tracing/log_traces/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=traces_link&amp;amp;utm_campaign=opik&#34;&gt;log traces&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import opik&#xA;&#xA;opik.configure(use_local=True) # Run locally&#xA;&#xA;@opik.track&#xA;def my_llm_function(user_question: str) -&amp;gt; str:&#xA;    # Your LLM code here&#xA;&#xA;    return &#34;Hello&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP]&lt;br&gt; The track decorator can be used in conjunction with any of our integrations and can also be used to track nested function calls.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;üßë‚Äç‚öñÔ∏è LLM as a Judge metrics&lt;/h3&gt; &#xA;&lt;p&gt;The Python Opik SDK includes a number of LLM as a judge metrics to help you evaluate your LLM application. Learn more about it in the &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/metrics/overview/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=metrics_2_link&amp;amp;utm_campaign=opik&#34;&gt;metrics documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To use them, simply import the relevant metric and use the &lt;code&gt;score&lt;/code&gt; function:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from opik.evaluation.metrics import Hallucination&#xA;&#xA;metric = Hallucination()&#xA;score = metric.score(&#xA;    input=&#34;What is the capital of France?&#34;,&#xA;    output=&#34;Paris&#34;,&#xA;    context=[&#34;France is a country in Europe.&#34;]&#xA;)&#xA;print(score)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Opik also includes a number of pre-built heuristic metrics as well as the ability to create your own. Learn more about it in the &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/metrics/overview?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=metrics_3_link&amp;amp;utm_campaign=opik&#34;&gt;metrics documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;üîç Evaluating your LLM Application&lt;/h3&gt; &#xA;&lt;p&gt;Opik allows you to evaluate your LLM application during development through &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/manage_datasets/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=datasets_2_link&amp;amp;utm_campaign=opik&#34;&gt;Datasets&lt;/a&gt; and &lt;a href=&#34;https://www.comet.com/docs/opik/evaluation/evaluate_your_llm/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=experiments_link&amp;amp;utm_campaign=opik&#34;&gt;Experiments&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can also run evaluations as part of your CI/CD pipeline using our &lt;a href=&#34;https://www.comet.com/docs/opik/testing/pytest_integration/?from=llm&amp;amp;utm_source=opik&amp;amp;utm_medium=github&amp;amp;utm_content=pytest_2_link&amp;amp;utm_campaign=opik&#34;&gt;PyTest integration&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; &#xA;&lt;p&gt;There are many ways to contribute to Opik:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Submit &lt;a href=&#34;https://github.com/comet-ml/opik/issues&#34;&gt;bug reports&lt;/a&gt; and &lt;a href=&#34;https://github.com/comet-ml/opik/issues&#34;&gt;feature requests&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Review the documentation and submit &lt;a href=&#34;https://github.com/comet-ml/opik/pulls&#34;&gt;Pull Requests&lt;/a&gt; to improve it&lt;/li&gt; &#xA; &lt;li&gt;Speaking or writing about Opik and &lt;a href=&#34;https://chat.comet.com&#34;&gt;letting us know&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Upvoting &lt;a href=&#34;https://github.com/comet-ml/opik/issues?q=is%3Aissue+is%3Aopen+label%3A%22enhancement%22&#34;&gt;popular feature requests&lt;/a&gt; to show your support&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To learn more about how to contribute to Opik, please see our &lt;a href=&#34;https://raw.githubusercontent.com/comet-ml/opik/main/CONTRIBUTING.md&#34;&gt;contributing guidelines&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>scylladb/scylladb</title>
    <updated>2024-12-21T01:28:18Z</updated>
    <id>tag:github.com,2024-12-21:/scylladb/scylladb</id>
    <link href="https://github.com/scylladb/scylladb" rel="alternate"></link>
    <summary type="html">&lt;p&gt;NoSQL data store using the seastar framework, compatible with Apache Cassandra&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Scylla&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://slack.scylladb.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/slack-scylla-brightgreen.svg?logo=slack&#34; alt=&#34;Slack&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/intent/follow?screen_name=ScyllaDB&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/ScyllaDB.svg?style=social&amp;amp;label=Follow&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is Scylla?&lt;/h2&gt; &#xA;&lt;p&gt;Scylla is the real-time big data database that is API-compatible with Apache Cassandra and Amazon DynamoDB. Scylla embraces a shared-nothing approach that increases throughput and storage capacity to realize order-of-magnitude performance improvements and reduce hardware costs.&lt;/p&gt; &#xA;&lt;p&gt;For more information, please see the &lt;a href=&#34;https://www.scylladb.com&#34;&gt;ScyllaDB web site&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Build Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;Scylla is fairly fussy about its build environment, requiring very recent versions of the C++23 compiler and of many libraries to build. The document &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/HACKING.md&#34;&gt;HACKING.md&lt;/a&gt; includes detailed information on building and developing Scylla, but to get Scylla building quickly on (almost) any build machine, Scylla offers a &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/tools/toolchain/README.md&#34;&gt;frozen toolchain&lt;/a&gt;, This is a pre-configured Docker image which includes recent versions of all the required compilers, libraries and build tools. Using the frozen toolchain allows you to avoid changing anything in your build machine to meet Scylla&#39;s requirements - you just need to meet the frozen toolchain&#39;s prerequisites (mostly, Docker or Podman being available).&lt;/p&gt; &#xA;&lt;h2&gt;Building Scylla&lt;/h2&gt; &#xA;&lt;p&gt;Building Scylla with the frozen toolchain &lt;code&gt;dbuild&lt;/code&gt; is as easy as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git submodule update --init --force --recursive&#xA;$ ./tools/toolchain/dbuild ./configure.py&#xA;$ ./tools/toolchain/dbuild ninja build/release/scylla&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For further information, please see:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/HACKING.md&#34;&gt;Developer documentation&lt;/a&gt; for more information on building Scylla.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/docs/dev/building.md&#34;&gt;Build documentation&lt;/a&gt; on how to build Scylla binaries, tests, and packages.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/dist/docker/debian/README.md&#34;&gt;Docker image build documentation&lt;/a&gt; for information on how to build Docker images.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Running Scylla&lt;/h2&gt; &#xA;&lt;p&gt;To start Scylla server, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./tools/toolchain/dbuild ./build/release/scylla --workdir tmp --smp 1 --developer-mode 1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will start a Scylla node with one CPU core allocated to it and data files stored in the &lt;code&gt;tmp&lt;/code&gt; directory. The &lt;code&gt;--developer-mode&lt;/code&gt; is needed to disable the various checks Scylla performs at startup to ensure the machine is configured for maximum performance (not relevant on development workstations). Please note that you need to run Scylla with &lt;code&gt;dbuild&lt;/code&gt; if you built it with the frozen toolchain.&lt;/p&gt; &#xA;&lt;p&gt;For more run options, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./tools/toolchain/dbuild ./build/release/scylla --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Testing&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/scylladb/scylladb/actions/workflows/seastar.yaml&#34;&gt;&lt;img src=&#34;https://github.com/scylladb/scylladb/actions/workflows/seastar.yaml/badge.svg?sanitize=true&#34; alt=&#34;Build with the latest Seastar&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/scylladb/scylladb/actions/workflows/reproducible-build.yaml&#34;&gt;&lt;img src=&#34;https://github.com/scylladb/scylladb/actions/workflows/reproducible-build.yaml/badge.svg?sanitize=true&#34; alt=&#34;Check Reproducible Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/scylladb/scylladb/actions/workflows/clang-nightly.yaml&#34;&gt;&lt;img src=&#34;https://github.com/scylladb/scylladb/actions/workflows/clang-nightly.yaml/badge.svg?sanitize=true&#34; alt=&#34;clang-nightly&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/docs/dev/testing.md&#34;&gt;test.py manual&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Scylla APIs and compatibility&lt;/h2&gt; &#xA;&lt;p&gt;By default, Scylla is compatible with Apache Cassandra and its API - CQL. There is also support for the API of Amazon DynamoDB‚Ñ¢, which needs to be enabled and configured in order to be used. For more information on how to enable the DynamoDB‚Ñ¢ API in Scylla, and the current compatibility of this feature as well as Scylla-specific extensions, see &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/docs/alternator/alternator.md&#34;&gt;Alternator&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/docs/alternator/getting-started.md&#34;&gt;Getting started with Alternator&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Documentation can be found &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/docs/dev/README.md&#34;&gt;here&lt;/a&gt;. Seastar documentation can be found &lt;a href=&#34;http://docs.seastar.io/master/index.html&#34;&gt;here&lt;/a&gt;. User documentation can be found &lt;a href=&#34;https://docs.scylladb.com/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;Training material and online courses can be found at &lt;a href=&#34;https://university.scylladb.com/&#34;&gt;Scylla University&lt;/a&gt;. The courses are free, self-paced and include hands-on examples. They cover a variety of topics including Scylla data modeling, administration, architecture, basic NoSQL concepts, using drivers for application development, Scylla setup, failover, compactions, multi-datacenters and how Scylla integrates with third-party applications.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing to Scylla&lt;/h2&gt; &#xA;&lt;p&gt;If you want to report a bug or submit a pull request or a patch, please read the &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/CONTRIBUTING.md&#34;&gt;contribution guidelines&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you are a developer working on Scylla, please read the &lt;a href=&#34;https://raw.githubusercontent.com/scylladb/scylladb/master/HACKING.md&#34;&gt;developer guidelines&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://forum.scylladb.com/&#34;&gt;community forum&lt;/a&gt; and &lt;a href=&#34;http://slack.scylladb.com/&#34;&gt;Slack channel&lt;/a&gt; are for users to discuss configuration, management, and operations of the ScyllaDB open source.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://groups.google.com/forum/#!forum/scylladb-dev&#34;&gt;developers mailing list&lt;/a&gt; is for developers and people interested in following the development of ScyllaDB to discuss technical topics.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>