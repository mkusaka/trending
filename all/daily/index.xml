<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-09-15T01:31:12Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>joeyballentine/chaiNNer</title>
    <updated>2022-09-15T01:31:12Z</updated>
    <id>tag:github.com,2022-09-15:/joeyballentine/chaiNNer</id>
    <link href="https://github.com/joeyballentine/chaiNNer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A flowchart/node-based image processing GUI aimed at making chaining image processing tasks (especially upscaling done by neural networks) easy, intuitive, and customizable.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;chaiNNer&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/joeyballentine/chaiNNer/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/joeyballentine/chaiNNer&#34; alt=&#34;GitHub Latest Release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/joeyballentine/chaiNNer/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/downloads/joeyballentine/chaiNNer/total&#34; alt=&#34;GitHub Total Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/joeyballentine/chaiNNer/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/joeyballentine/chaiNNer&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/pzvAKPKyHM&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/930865462852591648?label=Discord&amp;amp;logo=Discord&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/joeyballentine/chaiNNer/releases&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/joeyballentine/chaiNNer/main/src/public/banner.png&#34; width=&#34;720&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;A flowchart/node-based image processing GUI aimed at making chaining image processing tasks (especially upscaling done by neural networks) easy, intuitive, and customizable.&lt;/p&gt; &#xA;&lt;p&gt;No existing upscaling GUI gives you the level of customization of your image processing workflow that chaiNNer does. Not only do you have full control over your processing pipeline, you can do incredibly complex tasks just by connecting a few nodes together.&lt;/p&gt; &#xA;&lt;p&gt;chaiNNer is also cross-platform, meaning you can run it on Windows, MacOS, and Linux.&lt;/p&gt; &#xA;&lt;p&gt;For help, suggestions, or just to hang out, you can join the &lt;a href=&#34;https://discord.gg/pzvAKPKyHM&#34;&gt;chaiNNer Discord server&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Remember: chaiNNer is still a work in progress and in alpha. While it is slowly getting more to where we want it, it is going to take quite some time to have every possible feature we want to add. If you&#39;re knowledgeable in TypeScript, React, or Python, feel free to contribute to this project and help us get closer to that goal.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Download the latest release from the &lt;a href=&#34;https://github.com/joeyballentine/chaiNNer/releases&#34;&gt;Github releases page&lt;/a&gt; and run the installer best suited for your system. Simple as that.&lt;/p&gt; &#xA;&lt;p&gt;You don&#39;t even need to have Python installed, as chaiNNer will download an isolated integrated Python build on startup. From there, you can install all the other dependencies via the Dependency Manager.&lt;/p&gt; &#xA;&lt;p&gt;If you do wish to use your system Python installation still, you can turn the system Python setting on. However, it is much more recommended to use the integrated Python. If you do wish to use your system Python, make sure the Python version you are using is either 3.8 or 3.9. 3.10 also should work for the most part, but it is not fully supported at this time.&lt;/p&gt; &#xA;&lt;p&gt;If you are using the provided .zip portable version of chaiNNer, please be aware that the integrated Python it uses is not portable like the rest of it.&lt;/p&gt; &#xA;&lt;h2&gt;How To Use&lt;/h2&gt; &#xA;&lt;h3&gt;Basic Usage&lt;/h3&gt; &#xA;&lt;p&gt;While it might seem intimidating at first due to all the possible options, chaiNNer is pretty simple to use. For example, this is all you need to do in order to perform an upscale:&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/joeyballentine/chaiNNer/main/src/public/simple_screenshot.png&#34; width=&#34;480&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Before you get to this point though, you&#39;ll need to install one of the neural network frameworks from the dependency manager. You can access this via the button in the upper-right-hand corner. ChaiNNer offers support for PyTorch (with select model architectures), NCNN, and ONNX. For Nvidia users, PyTorch will be the preferred way to upscale. For AMD users, NCNN will be the preferred way to upscale.&lt;/p&gt; &#xA;&lt;p&gt;All the other Python dependencies are automatically installed, and chaiNNer even carries its own integrated Python support so that you do not have to modify your existing Python configuration.&lt;/p&gt; &#xA;&lt;p&gt;Then, all you have to do is drag and drop (or double click) node names in the selection panel to bring them into the editor. Then, drag from one node handle to another to connect the nodes. Each handle is color-coded to its specific type, and while connecting will show you only the compatible connections. This makes it very easy to know what to connect where.&lt;/p&gt; &#xA;&lt;p&gt;Once you have a working chain set up in the editor, you can press the green &#34;run&#34; button in the top bar to run the chain you have made. You will see the connections between nodes become animated, and start to un-animate as they finish processing. You can stop or pause processing with the red &#34;stop&#34; and yellow &#34;pause&#34; buttons respectively. Note: pressing stop is usually unable to kill an in-progress upscale during the actual upscaling step. This is a known issue without a workaround at the moment, so just be patient and wait for it to finish or restart chaiNNer.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/joeyballentine/chaiNNer/main/src/public/screenshot.png&#34; width=&#34;540&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Don&#39;t forget, there&#39;s plenty of non-upscaling tasks you can do with chaiNNer as well!&lt;/p&gt; &#xA;&lt;h3&gt;Tips &amp;amp; Tricks&lt;/h3&gt; &#xA;&lt;p&gt;To select multiple nodes, hold down shift and drag around all the nodes you want selected. You can also select an individual node by just clicking on it. When nodes are selected, you can press backspace or delete to delete them from the editor.&lt;/p&gt; &#xA;&lt;p&gt;To batch upscale, create an Image Iterator node and drag the nodes you want to use into the iterator&#39;s editor area. You can expand the iterator by clicking and dragging the bottom right corner outwards (like you would a UI window). Simply wire up a chain in an iterator the same as you would normally, and when you click run it will run on every image in the folder you chose. You also can select an entire existing chain, and drag it into the iterator&#39;s editor area to essentially convert the entire thing into an iterable chain.&lt;/p&gt; &#xA;&lt;p&gt;You can right-click in the editor viewport to show an inline nodes list to select from. You also can get this menu by dragging a connection out to the editor rather than making an actual connection, and it will show compatible nodes to automatically create a connection with.&lt;/p&gt; &#xA;&lt;h3&gt;Helpful Resources&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kimberly990/kim-chaiNNer-Templates/&#34;&gt;Kim&#39;s chaiNNer Templates&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;A collection of useful chain templates that can quickly get you started if you are still new to using chaiNNer.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://upscale.wiki/wiki/Model_Database&#34;&gt;Upscale Wiki Model Database&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;A very nice collection of mostly ESRGAN models that have been trained for various tasks.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Compatibility Notes&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;MacOS versions older than 10.15 are not supported at this time. This is due to a major dependency (opencv) not yet having a build for this version. The next release of it should be compatible though, so stay tuned for an update that adds support for that.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Apple M1 laptops are mostly untested, though they should support almost everything. Although, ONNX is unable to be installed as it does not yet have an arm64 build, and NCNN sometimes does not work properly.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Some NCNN users with non-Nvidia GPUs might get all-black outputs. I am not sure what to do to fix this as it appears to be due to the graphics driver crashing as a result of going out of memory. If this happens to you, try manually setting a tiling amount.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Arch Linux users may need to manually install libxcrypt before chaiNner&#39;s integrated Python will correctly start up.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To use the Clipboard nodes, Linux users need to have xclip or, for wayland users, wl-copy installed.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;GPU Support&lt;/h2&gt; &#xA;&lt;p&gt;For PyTorch inference, only Nvidia GPUs are supported. If you do not have an Nvidia GPU, you will have to use PyTorch in CPU mode. This is because PyTorch only support&#39;s Nvidia&#39;s CUDA. MacOS also does not support CUDA at all, so PyTorch will only work in CPU mode on MacOS.&lt;/p&gt; &#xA;&lt;p&gt;If you have an AMD or Intel GPU that supports NCNN however, chaiNNer now supports NCNN inference. You can use any existing NCNN .bin/.param model files (only ESRGAN-related SR models have been tested), or use chaiNNer to convert a PyTorch or ONNX model to NCNN.&lt;/p&gt; &#xA;&lt;p&gt;For NCNN, make sure to select which GPU you want to use in the settings. It might be defaulting to your integrated graphics!&lt;/p&gt; &#xA;&lt;p&gt;For Nvidia GPUs, ONNX is also an option to be used. ONNX will use CPU mode on non-Nvidia GPUs, similar to PyTorch.&lt;/p&gt; &#xA;&lt;h2&gt;Model Architecture Support&lt;/h2&gt; &#xA;&lt;p&gt;chaiNNer currently supports a limited amount of neural network architectures. More architectures will be supported in the future.&lt;/p&gt; &#xA;&lt;h3&gt;Pytorch&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/xinntao/ESRGAN&#34;&gt;ESRGAN&lt;/a&gt; (RRDBNet) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This includes regular &lt;a href=&#34;https://github.com/xinntao/ESRGAN&#34;&gt;ESRGAN&lt;/a&gt;, &lt;a href=&#34;https://github.com/ncarraz/ESRGANplus&#34;&gt;ESRGAN+&lt;/a&gt;, &#34;new-arch ESRGAN&#34; (&lt;a href=&#34;https://github.com/jixiaozhong/RealSR&#34;&gt;RealSR&lt;/a&gt;, &lt;a href=&#34;https://github.com/cszn/BSRGAN&#34;&gt;BSRGAN&lt;/a&gt;), &lt;a href=&#34;https://github.com/Maclory/SPSR&#34;&gt;SPSR&lt;/a&gt;, and &lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN&#34;&gt;Real-ESRGAN&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN&#34;&gt;Real-ESRGAN Compact&lt;/a&gt; (SRVGGNet)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Koushik0901/Swift-SRGAN&#34;&gt;Swift-SRGAN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/JingyunLiang/SwinIR&#34;&gt;SwinIR&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;NCNN&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Technically, almost any SR model should work assuming they follow a typical CNN-based SR structure, however I have only tested with ESRGAN (and its variants) and with Waifu2x&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ONNX&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Similarly to NCNN, technically almost any SR model should work assuming they follow a typical CNN-based SR structure, however I have only tested with ESRGAN.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Building chaiNNer Yourself&lt;/h2&gt; &#xA;&lt;p&gt;I provide pre-built versions of chaiNNer here on GitHub. However, if you would like to build chaiNNer yourself, simply run &lt;code&gt;npm install&lt;/code&gt; (make sure that you have at least npm v7 installed) to install all the nodejs dependencies, and &lt;code&gt;npm run make&lt;/code&gt; to build the application.&lt;/p&gt; &#xA;&lt;h2&gt;Planned Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Check the Discord server for a list of planned features.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;What does the name mean?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;chaiNNer is a play on the fact that you can &#34;chain&#34; different tasks together, with the NN in the name being a common abbreviation for Neural Networks. This is following the brilliant naming scheme of victorca25&#39;s machine learning tools (traiNNer, iNNfer, augmeNNt) which he granted me permission to use for this as well.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Why not just use Cupscale/IEU/CLI?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;All of these tools are viable options, but as anyone who has used them before knows they can be limited in what they can do. Many features like chaining or interpolating models are hardcoded and provide little flexibility. Certain features that would be useful, like being able to use a separate model on the alpha layer of an image for example, just do not exist in Cupscale. Inversely, you can pretty much do whatever you want with chaiNNer provided there are nodes implemented. Whatever weird feature you want implemented, you can implement yourself by connecting nodes however you want. Cupscale also does not have other image processing abilities like chaiNNer does, such as adjusting contrast.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Cupscale and IEU are also seemingly no longer maintained at the moment, while chaiNNer is being actively worked on still.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Wouldn&#39;t this make it more difficult to do things?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;In a way, yes. Similarly to how programming your own script to do this stuff is more difficult, chaiNNer will also be a bit more difficult than simply dragging and dropping an image and messing with some sliders and pressing an upscale button. However, this gives you a lot more flexibility in what you can do. The added complexity is really just connecting some dots together to do what you want. That doesn&#39;t sound that bad, right?&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;What platforms are supported?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Windows, Linux, and MacOS are all supported by chaiNNer. However, MacOS currently lacks GPU support for PyTorch, meaning you will need to use NCNN in order to get GPU upscaling functionality. MacOS versions under 10.15 are also currently not supported as mentioned earlier in this readme. M1 MacBooks also are not very well tested, but should work now.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>n8n-io/n8n</title>
    <updated>2022-09-15T01:31:12Z</updated>
    <id>tag:github.com,2022-09-15:/n8n-io/n8n</id>
    <link href="https://github.com/n8n-io/n8n" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Free and source-available fair-code licensed workflow automation tool. Easily automate tasks across different services.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/65276001/173571060-9f2f6d7b-bac0-43b6-bdb2-001da9694058.png&#34; alt=&#34;n8n.io - Workflow Automation&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;n8n - Workflow automation tool&lt;/h1&gt; &#xA;&lt;p&gt;n8n is an extendable workflow automation tool. With a &lt;a href=&#34;http://faircode.io&#34;&gt;fair-code&lt;/a&gt; distribution model, n8n will always have visible source code, be available to self-host, and allow you to add your own custom functions, logic and apps. n8n&#39;s node-based approach makes it highly versatile, enabling you to connect anything to everything.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/n8n-io/n8n/master/assets/n8n-screenshot.png&#34; alt=&#34;n8n.io - Screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=RpjQTGKm-ok&#34;&gt;&lt;span&gt;📺&lt;/span&gt; A short video (&amp;lt; 4 min)&lt;/a&gt; that goes over key concepts of creating workflows in n8n.&lt;/p&gt; &#xA;&lt;h2&gt;Available integrations&lt;/h2&gt; &#xA;&lt;p&gt;n8n has 200+ different nodes to automate workflows. The list can be found on: &lt;a href=&#34;https://n8n.io/integrations&#34;&gt;https://n8n.io/integrations&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;The official n8n documentation can be found under: &lt;a href=&#34;https://docs.n8n.io&#34;&gt;https://docs.n8n.io&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Additional information and example workflows on the n8n.io website: &lt;a href=&#34;https://n8n.io&#34;&gt;https://n8n.io&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The changelog can be found &lt;a href=&#34;https://docs.n8n.io/reference/changelog.html&#34;&gt;here&lt;/a&gt; and the list of breaking changes &lt;a href=&#34;https://github.com/n8n-io/n8n/raw/master/packages/cli/BREAKING-CHANGES.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;span&gt;📚&lt;/span&gt; Learn &lt;a href=&#34;https://github.com/n8n-io/n8n/tree/master/packages/cli/README.md&#34;&gt;how to &lt;strong&gt;install&lt;/strong&gt; and &lt;strong&gt;use&lt;/strong&gt; it from the command line&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;🐳&lt;/span&gt; Learn &lt;a href=&#34;https://github.com/n8n-io/n8n/tree/master/docker/images/n8n/README.md&#34;&gt;how to run n8n in &lt;strong&gt;Docker&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Start&lt;/h2&gt; &#xA;&lt;p&gt;Execute: &lt;code&gt;npx n8n&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;n8n cloud&lt;/h2&gt; &#xA;&lt;p&gt;Sign-up for an &lt;a href=&#34;https://www.n8n.io/cloud/&#34;&gt;n8n cloud&lt;/a&gt; account.&lt;/p&gt; &#xA;&lt;p&gt;While n8n cloud and n8n are the same in terms of features, n8 cloud provides certain conveniences such as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Not having to set up and maintain your n8n instance&lt;/li&gt; &#xA; &lt;li&gt;Managed OAuth for authentication&lt;/li&gt; &#xA; &lt;li&gt;Easily upgrading to the newer n8n versions&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;If you have problems or questions go to our forum, we will then try to help you asap:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://community.n8n.io&#34;&gt;https://community.n8n.io&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Jobs&lt;/h2&gt; &#xA;&lt;p&gt;If you are interested in working for n8n and so shape the future of the project check out our &lt;a href=&#34;https://apply.workable.com/n8n/&#34;&gt;job posts&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What does n8n mean and how do you pronounce it?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Short answer:&lt;/strong&gt; It means &#34;nodemation&#34; and it is pronounced as n-eight-n.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Long answer:&lt;/strong&gt; &#34;I get that question quite often (more often than I expected) so I decided it is probably best to answer it here. While looking for a good name for the project with a free domain I realized very quickly that all the good ones I could think of were already taken. So, in the end, I chose nodemation. &#39;node-&#39; in the sense that it uses a Node-View and that it uses Node.js and &#39;-mation&#39; for &#39;automation&#39; which is what the project is supposed to help with. However, I did not like how long the name was and I could not imagine writing something that long every time in the CLI. That is when I then ended up on &#39;n8n&#39;.&#34; - &lt;strong&gt;Jan Oberhauser, Founder and CEO, n8n.io&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Development setup&lt;/h2&gt; &#xA;&lt;p&gt;Have you found a bug &lt;span&gt;🐛&lt;/span&gt; ? Or maybe you have a nice feature &lt;span&gt;✨&lt;/span&gt; to contribute ? The &lt;a href=&#34;https://github.com/n8n-io/n8n/raw/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING guide&lt;/a&gt; will help you get your development environment ready in minutes.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;n8n is &lt;a href=&#34;http://faircode.io&#34;&gt;fair-code&lt;/a&gt; distributed under the &lt;a href=&#34;https://github.com/n8n-io/n8n/raw/master/packages/cli/LICENSE.md&#34;&gt;&lt;strong&gt;Sustainable Use License&lt;/strong&gt;&lt;/a&gt; and the &lt;a href=&#34;https://github.com/n8n-io/n8n/raw/master/packages/cli/LICENSE_EE.md&#34;&gt;&lt;strong&gt;n8n Enterprise License&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Additional information about the license model can be found in the &lt;a href=&#34;https://docs.n8n.io/reference/license/&#34;&gt;docs&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>divamgupta/diffusionbee-stable-diffusion-ui</title>
    <updated>2022-09-15T01:31:12Z</updated>
    <id>tag:github.com,2022-09-15:/divamgupta/diffusionbee-stable-diffusion-ui</id>
    <link href="https://github.com/divamgupta/diffusionbee-stable-diffusion-ui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Diffusion Bee is the easiest way to run Stable Diffusion locally on your M1 Mac. Comes with a one-click installer. No dependencies or technical knowledge needed.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Diffusion Bee - Stable Diffusion GUI App for M1 Mac&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/divamgupta&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url.svg?label=Follow%20%40divamgupta&amp;amp;style=social&amp;amp;url=https%3A%2F%2Ftwitter.com%2Fdivamgupta&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Diffusion Bee is the easiest way to run Stable Diffusion locally on your M1 Mac. Comes with a one-click installer. No dependencies or technical knowledge needed.&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Runs locally on your computer no data is sent to the cloud ( other than request to download the weights and checking for software updates ).&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;If you like Diffusion Bee, consider checking &lt;a href=&#34;https://Liner.ai&#34;&gt;https://Liner.ai&lt;/a&gt; , a one-click tool to train machine learning models&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://diffusionbee.com/&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1890549/189538422-52d50488-c1fa-4924-bec6-186c9e0f307b.png&#34; alt=&#34;Download&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/divamgupta/diffusionbee-stable-diffusion-ui/releases/download/0.1.0/DiffusionBee-0.1.0-arm64.dmg&#34;&gt;https://github.com/divamgupta/diffusionbee-stable-diffusion-ui/releases/download/0.1.0/DiffusionBee-0.1.0-arm64.dmg&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;For prompt ideas visit &lt;a href=&#34;https://arthub.ai&#34;&gt;https://arthub.ai&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Join discord server : &lt;a href=&#34;https://discord.gg/t6rC5RaJQn&#34;&gt;https://discord.gg/t6rC5RaJQn&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Full data privacy - nothing is sent to the cloud&lt;/li&gt; &#xA; &lt;li&gt;Clean and easy to use UI&lt;/li&gt; &#xA; &lt;li&gt;One click installer&lt;/li&gt; &#xA; &lt;li&gt;No dependencies needed&lt;/li&gt; &#xA; &lt;li&gt;Multiple image sizes&lt;/li&gt; &#xA; &lt;li&gt;Optimized for M1/M2 Chips&lt;/li&gt; &#xA; &lt;li&gt;Runs locally on your computer&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to use&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Download and start the application&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Enter the text prompt.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img width=&#34;1162&#34; alt=&#34;Screen Shot 2022-09-11 at 12 33 52 PM&#34; src=&#34;https://user-images.githubusercontent.com/1890549/189538839-45ac91b1-cd66-4543-9ece-956220d0d769.png&#34;&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Wait a few seconds to get the generated image&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1890549/189539684-222482fb-63f7-4799-bfc1-005b84508e35.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;M1 / M2 Mac&lt;/li&gt; &#xA; &lt;li&gt;16 GB RAM preferred. It will run a bit slow with 8GB ram.&lt;/li&gt; &#xA; &lt;li&gt;MacOS 12.5.1 or later&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;License : Stable Diffusion is released under the CreativeML OpenRAIL M license : &lt;a href=&#34;https://github.com/CompVis/stable-diffusion/raw/main/LICENSE&#34;&gt;https://github.com/CompVis/stable-diffusion/blob/main/LICENSE&lt;/a&gt; Diffusion Bee is just a GUI wrapper on top of Stable Diffusion, so all the term of Stable Diffusion are applied on the outputs.&lt;/p&gt; &#xA;&lt;p&gt;References&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bfirsh/stable-diffusion/tree/apple-silicon-mps-support&#34;&gt;https://github.com/bfirsh/stable-diffusion/tree/apple-silicon-mps-support&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
</feed>