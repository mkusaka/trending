<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-06-06T01:29:18Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>netbirdio/netbird</title>
    <updated>2025-06-06T01:29:18Z</updated>
    <id>tag:github.com,2025-06-06:/netbirdio/netbird</id>
    <link href="https://github.com/netbirdio/netbird" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Connect your devices into a secure WireGuard®-based overlay network with SSO, MFA and granular access controls.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;br&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;234&#34; src=&#34;https://raw.githubusercontent.com/netbirdio/netbird/main/docs/media/logo-full.png&#34;&gt; &lt;/p&gt; &#xA; &lt;p&gt; &lt;a href=&#34;https://img.shields.io/badge/license-BSD--3-blue)&#34;&gt; &lt;img src=&#34;https://sonarcloud.io/api/project_badges/measure?project=netbirdio_netbird&amp;amp;metric=alert_status&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/netbirdio/netbird/raw/main/LICENSE&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/license-BSD--3-blue&#34;&gt; &lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://join.slack.com/t/netbirdio/shared_invite/zt-31rofwmxc-27akKd0Le0vyRpBcwXkP0g&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/slack-@netbird-red.svg?logo=slack&#34;&gt; &lt;/a&gt; &lt;br&gt; &lt;a href=&#34;https://gurubase.io/g/netbird&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Gurubase-Ask%20NetBird%20Guru-006BFF&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;strong&gt; Start using NetBird at &lt;a href=&#34;https://netbird.io/pricing&#34;&gt;netbird.io&lt;/a&gt; &lt;br&gt; See &lt;a href=&#34;https://netbird.io/docs/&#34;&gt;Documentation&lt;/a&gt; &lt;br&gt; Join our &lt;a href=&#34;https://join.slack.com/t/netbirdio/shared_invite/zt-31rofwmxc-27akKd0Le0vyRpBcwXkP0g&#34;&gt;Slack channel&lt;/a&gt; &lt;br&gt; &lt;/strong&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/netbirdio/kubernetes-operator&#34;&gt; New: NetBird Kubernetes Operator &lt;/a&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;strong&gt;NetBird combines a configuration-free peer-to-peer private network and a centralized access control system in a single platform, making it easy to create secure private networks for your organization or home.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Connect.&lt;/strong&gt; NetBird creates a WireGuard-based overlay network that automatically connects your machines over an encrypted tunnel, leaving behind the hassle of opening ports, complex firewall rules, VPN gateways, and so forth.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Secure.&lt;/strong&gt; NetBird enables secure remote access by applying granular access policies while allowing you to manage them intuitively from a single place. Works universally on any infrastructure.&lt;/p&gt; &#xA;&lt;h3&gt;Open-Source Network Security in a Single Platform&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/netbirdio/netbird/assets/700848/46bc3b73-508d-4a0e-bb9a-f465d68646ab&#34; alt=&#34;netbird_2&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;NetBird on Lawrence Systems (Video)&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Kwrff6h0rEw&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/Kwrff6h0rEw/0.jpg&#34; alt=&#34;Watch the video&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Key features&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Connectivity&lt;/th&gt; &#xA;   &lt;th&gt;Management&lt;/th&gt; &#xA;   &lt;th&gt;Security&lt;/th&gt; &#xA;   &lt;th&gt;Automation&lt;/th&gt; &#xA;   &lt;th&gt;Platforms&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] Kernel WireGuard&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://github.com/netbirdio/dashboard&#34;&gt;Admin Web UI&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://docs.netbird.io/how-to/installation#running-net-bird-with-sso-login&#34;&gt;SSO &amp;amp; MFA support&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://docs.netbird.io/api&#34;&gt;Public API&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] Linux&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] Peer-to-peer connections&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] Auto peer discovery and configuration&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://docs.netbird.io/how-to/manage-network-access&#34;&gt;Access control - groups &amp;amp; rules&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://docs.netbird.io/how-to/register-machines-using-setup-keys&#34;&gt;Setup keys for bulk network provisioning&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] Mac&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] Connection relay fallback&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://docs.netbird.io/selfhosted/identity-providers&#34;&gt;IdP integrations&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://docs.netbird.io/how-to/audit-events-logging&#34;&gt;Activity logging&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://docs.netbird.io/selfhosted/selfhosted-quickstart&#34;&gt;Self-hosting quickstart script&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] Windows&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://docs.netbird.io/how-to/routing-traffic-to-private-networks&#34;&gt;Routes to external networks&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://docs.netbird.io/how-to/manage-dns-in-your-network&#34;&gt;Private DNS&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://docs.netbird.io/how-to/manage-posture-checks&#34;&gt;Device posture checks&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] IdP groups sync with JWT&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] Android&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] NAT traversal with BPF&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://docs.netbird.io/how-to/add-users-to-your-network&#34;&gt;Multiuser support&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] Peer-to-peer encryption&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] iOS&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://netbird.io/knowledge-hub/the-first-quantum-resistant-mesh-vpn&#34;&gt;Quantum-resistance with Rosenpass&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] OpenWRT&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://docs.netbird.io/how-to/enforce-periodic-user-authentication&#34;&gt;Periodic re-authentication&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] &lt;a href=&#34;https://docs.netbird.io/how-to/netbird-on-faas&#34;&gt;Serverless&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&#xA;    &lt;ul&gt;&#xA;     &lt;li&gt;- [x] Docker&lt;/li&gt;&#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Quickstart with NetBird Cloud&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download and install NetBird at &lt;a href=&#34;https://app.netbird.io/install&#34;&gt;https://app.netbird.io/install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Follow the steps to sign-up with Google, Microsoft, GitHub or your email address.&lt;/li&gt; &#xA; &lt;li&gt;Check NetBird &lt;a href=&#34;https://app.netbird.io/&#34;&gt;admin UI&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Add more machines.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Quickstart with self-hosted NetBird&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;This is the quickest way to try self-hosted NetBird. It should take around 5 minutes to get started if you already have a public domain and a VM. Follow the &lt;a href=&#34;https://docs.netbird.io/selfhosted/selfhosted-guide#advanced-guide-with-a-custom-identity-provider&#34;&gt;Advanced guide with a custom identity provider&lt;/a&gt; for installations with different IDPs.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;strong&gt;Infrastructure requirements:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A Linux VM with at least &lt;strong&gt;1CPU&lt;/strong&gt; and &lt;strong&gt;2GB&lt;/strong&gt; of memory.&lt;/li&gt; &#xA; &lt;li&gt;The VM should be publicly accessible on TCP ports &lt;strong&gt;80&lt;/strong&gt; and &lt;strong&gt;443&lt;/strong&gt; and UDP ports: &lt;strong&gt;3478&lt;/strong&gt;, &lt;strong&gt;49152-65535&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Public domain&lt;/strong&gt; name pointing to the VM.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Software requirements:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Docker installed on the VM with the docker-compose plugin (&lt;a href=&#34;https://docs.docker.com/engine/install/&#34;&gt;Docker installation guide&lt;/a&gt;) or docker with docker-compose in version 2 or higher.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jqlang.github.io/jq/&#34;&gt;jq&lt;/a&gt; installed. In most distributions Usually available in the official repositories and can be installed with &lt;code&gt;sudo apt install jq&lt;/code&gt; or &lt;code&gt;sudo yum install jq&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://curl.se/&#34;&gt;curl&lt;/a&gt; installed. Usually available in the official repositories and can be installed with &lt;code&gt;sudo apt install curl&lt;/code&gt; or &lt;code&gt;sudo yum install curl&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Steps&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download and run the installation script:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export NETBIRD_DOMAIN=netbird.example.com; curl -fsSL https://github.com/netbirdio/netbird/releases/latest/download/getting-started-with-zitadel.sh | bash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Once finished, you can manage the resources via &lt;code&gt;docker-compose&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;A bit on NetBird internals&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Every machine in the network runs &lt;a href=&#34;https://raw.githubusercontent.com/netbirdio/netbird/main/client/&#34;&gt;NetBird Agent (or Client)&lt;/a&gt; that manages WireGuard.&lt;/li&gt; &#xA; &lt;li&gt;Every agent connects to &lt;a href=&#34;https://raw.githubusercontent.com/netbirdio/netbird/main/management/&#34;&gt;Management Service&lt;/a&gt; that holds network state, manages peer IPs, and distributes network updates to agents (peers).&lt;/li&gt; &#xA; &lt;li&gt;NetBird agent uses WebRTC ICE implemented in &lt;a href=&#34;https://github.com/pion/ice&#34;&gt;pion/ice library&lt;/a&gt; to discover connection candidates when establishing a peer-to-peer connection between machines.&lt;/li&gt; &#xA; &lt;li&gt;Connection candidates are discovered with the help of &lt;a href=&#34;https://en.wikipedia.org/wiki/STUN&#34;&gt;STUN&lt;/a&gt; servers.&lt;/li&gt; &#xA; &lt;li&gt;Agents negotiate a connection through &lt;a href=&#34;https://raw.githubusercontent.com/netbirdio/netbird/main/signal/&#34;&gt;Signal Service&lt;/a&gt; passing p2p encrypted messages with candidates.&lt;/li&gt; &#xA; &lt;li&gt;Sometimes the NAT traversal is unsuccessful due to strict NATs (e.g. mobile carrier-grade NAT) and a p2p connection isn&#39;t possible. When this occurs the system falls back to a relay server called &lt;a href=&#34;https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT&#34;&gt;TURN&lt;/a&gt;, and a secure WireGuard tunnel is established via the TURN server.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/coturn/coturn&#34;&gt;Coturn&lt;/a&gt; is the one that has been successfully used for STUN and TURN in NetBird setups.&lt;/p&gt; &#xA;&lt;p float=&#34;left&#34; align=&#34;middle&#34;&gt; &lt;img src=&#34;https://docs.netbird.io/docs-static/img/architecture/high-level-dia.png&#34; width=&#34;700&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;See a complete &lt;a href=&#34;https://docs.netbird.io/about-netbird/how-netbird-works#architecture&#34;&gt;architecture overview&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;h3&gt;Community projects&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/physk/netbird-installer&#34;&gt;NetBird installer script&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://galaxy.ansible.com/ui/repo/published/dominion_solutions/netbird/&#34;&gt;NetBird ansible collection by Dominion Solutions&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;main&lt;/code&gt; branch may be in an &lt;em&gt;unstable or even broken state&lt;/em&gt; during development. For stable versions, see &lt;a href=&#34;https://github.com/netbirdio/netbird/releases&#34;&gt;releases&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Support acknowledgement&lt;/h3&gt; &#xA;&lt;p&gt;In November 2022, NetBird joined the &lt;a href=&#34;https://www.forschung-it-sicherheit-kommunikationssysteme.de/foerderung/bekanntmachungen/startup-secure&#34;&gt;StartUpSecure program&lt;/a&gt; sponsored by The Federal Ministry of Education and Research of The Federal Republic of Germany. Together with &lt;a href=&#34;https://cispa.de/en&#34;&gt;CISPA Helmholtz Center for Information Security&lt;/a&gt; NetBird brings the security best practices and simplicity to private networking.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/700848/203091324-c6d311a0-22b5-4b05-a288-91cbc6cdcc46.png&#34; alt=&#34;CISPA_Logo_BLACK_EN_RZ_RGB (1)&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Testimonials&lt;/h3&gt; &#xA;&lt;p&gt;We use open-source technologies like &lt;a href=&#34;https://www.wireguard.com/&#34;&gt;WireGuard®&lt;/a&gt;, &lt;a href=&#34;https://github.com/pion/ice&#34;&gt;Pion ICE (WebRTC)&lt;/a&gt;, &lt;a href=&#34;https://github.com/coturn/coturn&#34;&gt;Coturn&lt;/a&gt;, and &lt;a href=&#34;https://rosenpass.eu&#34;&gt;Rosenpass&lt;/a&gt;. We very much appreciate the work these guys are doing and we&#39;d greatly appreciate if you could support them in any way (e.g., by giving a star or a contribution).&lt;/p&gt; &#xA;&lt;h3&gt;Legal&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;WireGuard&lt;/em&gt; and the &lt;em&gt;WireGuard&lt;/em&gt; logo are &lt;a href=&#34;https://www.wireguard.com/trademark-policy/&#34;&gt;registered trademarks&lt;/a&gt; of Jason A. Donenfeld.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>modelcontextprotocol/ruby-sdk</title>
    <updated>2025-06-06T01:29:18Z</updated>
    <id>tag:github.com,2025-06-06:/modelcontextprotocol/ruby-sdk</id>
    <link href="https://github.com/modelcontextprotocol/ruby-sdk" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The official Ruby SDK for the Model Context Protocol. Maintained in collaboration with Shopify.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MCP Ruby SDK &lt;img src=&#34;https://img.shields.io/gem/v/mcp&#34; alt=&#34;Gem Version&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/license-MIT-green&#34; alt=&#34;MIT licensed&#34;&gt; &lt;a href=&#34;https://github.com/modelcontextprotocol/ruby-sdk/actions/workflows/ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/modelcontextprotocol/ruby-sdk/actions/workflows/ci.yml/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;The official Ruby SDK for Model Context Protocol servers and clients.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Add this line to your application&#39;s Gemfile:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;gem &#39;mcp&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then execute:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ bundle install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or install it yourself as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ gem install mcp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;MCP Server&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;MCP::Server&lt;/code&gt; class is the core component that handles JSON-RPC requests and responses. It implements the Model Context Protocol specification, handling model context requests and responses.&lt;/p&gt; &#xA;&lt;h3&gt;Key Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Implements JSON-RPC 2.0 message handling&lt;/li&gt; &#xA; &lt;li&gt;Supports protocol initialization and capability negotiation&lt;/li&gt; &#xA; &lt;li&gt;Manages tool registration and invocation&lt;/li&gt; &#xA; &lt;li&gt;Supports prompt registration and execution&lt;/li&gt; &#xA; &lt;li&gt;Supports resource registration and retrieval&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Supported Methods&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;initialize&lt;/code&gt; - Initializes the protocol and returns server capabilities&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;ping&lt;/code&gt; - Simple health check&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;tools/list&lt;/code&gt; - Lists all registered tools and their schemas&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;tools/call&lt;/code&gt; - Invokes a specific tool with provided arguments&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;prompts/list&lt;/code&gt; - Lists all registered prompts and their schemas&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;prompts/get&lt;/code&gt; - Retrieves a specific prompt by name&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;resources/list&lt;/code&gt; - Lists all registered resources and their schemas&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;resources/read&lt;/code&gt; - Retrieves a specific resource by name&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;resources/templates/list&lt;/code&gt; - Lists all registered resource templates and their schemas&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Unsupported Features ( to be implemented in future versions )&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Notifications&lt;/li&gt; &#xA; &lt;li&gt;Log Level&lt;/li&gt; &#xA; &lt;li&gt;Resource subscriptions&lt;/li&gt; &#xA; &lt;li&gt;Completions&lt;/li&gt; &#xA; &lt;li&gt;Complete StreamableHTTP implementation with streaming responses&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;h4&gt;Rails Controller&lt;/h4&gt; &#xA;&lt;p&gt;When added to a Rails controller on a route that handles POST requests, your server will be compliant with non-streaming &lt;a href=&#34;https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#streamable-http&#34;&gt;StreamableHTTP&lt;/a&gt; transport requests.&lt;/p&gt; &#xA;&lt;p&gt;You can use the &lt;code&gt;Server#handle_json&lt;/code&gt; method to handle requests.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;class ApplicationController &amp;lt; ActionController::Base&#xA;&#xA;  def index&#xA;    server = MCP::Server.new(&#xA;      name: &#34;my_server&#34;,&#xA;      version: &#34;1.0.0&#34;,&#xA;      tools: [SomeTool, AnotherTool],&#xA;      prompts: [MyPrompt],&#xA;      server_context: { user_id: current_user.id },&#xA;    )&#xA;    render(json: server.handle_json(request.body.read))&#xA;  end&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Stdio Transport&lt;/h4&gt; &#xA;&lt;p&gt;If you want to build a local command-line application, you can use the stdio transport:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;#!/usr/bin/env ruby&#xA;require &#34;mcp&#34;&#xA;require &#34;mcp/server/transports/stdio_transport&#34;&#xA;&#xA;# Create a simple tool&#xA;class ExampleTool &amp;lt; MCP::Tool&#xA;  description &#34;A simple example tool that echoes back its arguments&#34;&#xA;  input_schema(&#xA;    properties: {&#xA;      message: { type: &#34;string&#34; },&#xA;    },&#xA;    required: [&#34;message&#34;]&#xA;  )&#xA;&#xA;  class &amp;lt;&amp;lt; self&#xA;    def call(message:, server_context:)&#xA;      MCP::Tool::Response.new([{&#xA;        type: &#34;text&#34;,&#xA;        text: &#34;Hello from example tool! Message: #{message}&#34;,&#xA;      }])&#xA;    end&#xA;  end&#xA;end&#xA;&#xA;# Set up the server&#xA;server = MCP::Server.new(&#xA;  name: &#34;example_server&#34;,&#xA;  tools: [ExampleTool],&#xA;)&#xA;&#xA;# Create and start the transport&#xA;transport = MCP::Server::Transports::StdioTransport.new(server)&#xA;transport.open&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can run this script and then type in requests to the server at the command line.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./examples/stdio_server.rb&#xA;{&#34;jsonrpc&#34;:&#34;2.0&#34;,&#34;id&#34;:&#34;1&#34;,&#34;method&#34;:&#34;ping&#34;}&#xA;{&#34;jsonrpc&#34;:&#34;2.0&#34;,&#34;id&#34;:&#34;2&#34;,&#34;method&#34;:&#34;tools/list&#34;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;The gem can be configured using the &lt;code&gt;MCP.configure&lt;/code&gt; block:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;MCP.configure do |config|&#xA;  config.exception_reporter = -&amp;gt;(exception, server_context) {&#xA;    # Your exception reporting logic here&#xA;    # For example with Bugsnag:&#xA;    Bugsnag.notify(exception) do |report|&#xA;      report.add_metadata(:model_context_protocol, server_context)&#xA;    end&#xA;  }&#xA;&#xA;  config.instrumentation_callback = -&amp;gt;(data) {&#xA;    puts &#34;Got instrumentation data #{data.inspect}&#34;&#xA;  }&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or by creating an explicit configuration and passing it into the server. This is useful for systems where an application hosts more than one MCP server but they might require different instrumentation callbacks.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;configuration = MCP::Configuration.new&#xA;configuration.exception_reporter = -&amp;gt;(exception, server_context) {&#xA;  # Your exception reporting logic here&#xA;  # For example with Bugsnag:&#xA;  Bugsnag.notify(exception) do |report|&#xA;    report.add_metadata(:model_context_protocol, server_context)&#xA;  end&#xA;}&#xA;&#xA;configuration.instrumentation_callback = -&amp;gt;(data) {&#xA;  puts &#34;Got instrumentation data #{data.inspect}&#34;&#xA;}&#xA;&#xA;server = MCP::Server.new(&#xA;  # ... all other options&#xA;  configuration:,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Server Context and Configuration Block Data&lt;/h3&gt; &#xA;&lt;h4&gt;&lt;code&gt;server_context&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;p&gt;The &lt;code&gt;server_context&lt;/code&gt; is a user-defined hash that is passed into the server instance and made available to tools, prompts, and exception/instrumentation callbacks. It can be used to provide contextual information such as authentication state, user IDs, or request-specific data.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Type:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;server_context: { [String, Symbol] =&amp;gt; Any }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;server = MCP::Server.new(&#xA;  name: &#34;my_server&#34;,&#xA;  server_context: { user_id: current_user.id, request_id: request.uuid }&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This hash is then passed as the &lt;code&gt;server_context&lt;/code&gt; argument to tool and prompt calls, and is included in exception and instrumentation callbacks.&lt;/p&gt; &#xA;&lt;h4&gt;Configuration Block Data&lt;/h4&gt; &#xA;&lt;h5&gt;Exception Reporter&lt;/h5&gt; &#xA;&lt;p&gt;The exception reporter receives:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;exception&lt;/code&gt;: The Ruby exception object that was raised&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;server_context&lt;/code&gt;: The context hash provided to the server&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Signature:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;exception_reporter = -&amp;gt;(exception, server_context) { ... }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Instrumentation Callback&lt;/h5&gt; &#xA;&lt;p&gt;The instrumentation callback receives a hash with the following possible keys:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;method&lt;/code&gt;: (String) The protocol method called (e.g., &#34;ping&#34;, &#34;tools/list&#34;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;tool_name&lt;/code&gt;: (String, optional) The name of the tool called&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;prompt_name&lt;/code&gt;: (String, optional) The name of the prompt called&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;resource_uri&lt;/code&gt;: (String, optional) The URI of the resource called&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;error&lt;/code&gt;: (String, optional) Error code if a lookup failed&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;duration&lt;/code&gt;: (Float) Duration of the call in seconds&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Type:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;instrumentation_callback = -&amp;gt;(data) { ... }&#xA;# where data is a Hash with keys as described above&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;config.instrumentation_callback = -&amp;gt;(data) {&#xA;  puts &#34;Instrumentation: #{data.inspect}&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Server Protocol Version&lt;/h3&gt; &#xA;&lt;p&gt;The server&#39;s protocol version can be overridden using the &lt;code&gt;protocol_version&lt;/code&gt; class method:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;MCP::Server.protocol_version = &#34;2024-11-05&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will make all new server instances use the specified protocol version instead of the default version. The protocol version can be reset to the default by setting it to &lt;code&gt;nil&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;MCP::Server.protocol_version = nil&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Be sure to check the &lt;a href=&#34;https://spec.modelcontextprotocol.io/specification/2024-11-05/&#34;&gt;MCP spec&lt;/a&gt; for the protocol version to understand the supported features for the version being set.&lt;/p&gt; &#xA;&lt;h3&gt;Exception Reporting&lt;/h3&gt; &#xA;&lt;p&gt;The exception reporter receives two arguments:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;exception&lt;/code&gt;: The Ruby exception object that was raised&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;server_context&lt;/code&gt;: A hash containing contextual information about where the error occurred&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The server_context hash includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For tool calls: &lt;code&gt;{ tool_name: &#34;name&#34;, arguments: { ... } }&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;For general request handling: &lt;code&gt;{ request: { ... } }&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When an exception occurs:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The exception is reported via the configured reporter&lt;/li&gt; &#xA; &lt;li&gt;For tool calls, a generic error response is returned to the client: &lt;code&gt;{ error: &#34;Internal error occurred&#34;, isError: true }&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;For other requests, the exception is re-raised after reporting&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;If no exception reporter is configured, a default no-op reporter is used that silently ignores exceptions.&lt;/p&gt; &#xA;&lt;h2&gt;Tools&lt;/h2&gt; &#xA;&lt;p&gt;MCP spec includes &lt;a href=&#34;https://modelcontextprotocol.io/docs/concepts/tools&#34;&gt;Tools&lt;/a&gt; which provide functionality to LLM apps.&lt;/p&gt; &#xA;&lt;p&gt;This gem provides a &lt;code&gt;MCP::Tool&lt;/code&gt; class that can be used to create tools in two ways:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;As a class definition:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;class MyTool &amp;lt; MCP::Tool&#xA;  description &#34;This tool performs specific functionality...&#34;&#xA;  input_schema(&#xA;    properties: {&#xA;      message: { type: &#34;string&#34; },&#xA;    },&#xA;    required: [&#34;message&#34;]&#xA;  )&#xA;  annotations(&#xA;    title: &#34;My Tool&#34;,&#xA;    read_only_hint: true,&#xA;    destructive_hint: false,&#xA;    idempotent_hint: true,&#xA;    open_world_hint: false&#xA;  )&#xA;&#xA;  def self.call(message:, server_context:)&#xA;    MCP::Tool::Response.new([{ type: &#34;text&#34;, text: &#34;OK&#34; }])&#xA;  end&#xA;end&#xA;&#xA;tool = MyTool&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;By using the &lt;code&gt;MCP::Tool.define&lt;/code&gt; method with a block:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;tool = MCP::Tool.define(&#xA;  name: &#34;my_tool&#34;,&#xA;  description: &#34;This tool performs specific functionality...&#34;,&#xA;  annotations: {&#xA;    title: &#34;My Tool&#34;,&#xA;    read_only_hint: true&#xA;  }&#xA;) do |args, server_context|&#xA;  Tool::Response.new([{ type: &#34;text&#34;, text: &#34;OK&#34; }])&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The server_context parameter is the server_context passed into the server and can be used to pass per request information, e.g. around authentication state.&lt;/p&gt; &#xA;&lt;h3&gt;Tool Annotations&lt;/h3&gt; &#xA;&lt;p&gt;Tools can include annotations that provide additional metadata about their behavior. The following annotations are supported:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;title&lt;/code&gt;: A human-readable title for the tool&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;read_only_hint&lt;/code&gt;: Indicates if the tool only reads data (doesn&#39;t modify state)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;destructive_hint&lt;/code&gt;: Indicates if the tool performs destructive operations&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;idempotent_hint&lt;/code&gt;: Indicates if the tool&#39;s operations are idempotent&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;open_world_hint&lt;/code&gt;: Indicates if the tool operates in an open world context&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Annotations can be set either through the class definition using the &lt;code&gt;annotations&lt;/code&gt; class method or when defining a tool using the &lt;code&gt;define&lt;/code&gt; method.&lt;/p&gt; &#xA;&lt;h2&gt;Prompts&lt;/h2&gt; &#xA;&lt;p&gt;MCP spec includes &lt;a href=&#34;https://modelcontextprotocol.io/docs/concepts/prompts&#34;&gt;Prompts&lt;/a&gt;, which enable servers to define reusable prompt templates and workflows that clients can easily surface to users and LLMs.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;MCP::Prompt&lt;/code&gt; class provides two ways to create prompts:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;As a class definition with metadata:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;class MyPrompt &amp;lt; MCP::Prompt&#xA;  prompt_name &#34;my_prompt&#34;  # Optional - defaults to underscored class name&#xA;  description &#34;This prompt performs specific functionality...&#34;&#xA;  arguments [&#xA;    Prompt::Argument.new(&#xA;      name: &#34;message&#34;,&#xA;      description: &#34;Input message&#34;,&#xA;      required: true&#xA;    )&#xA;  ]&#xA;&#xA;  class &amp;lt;&amp;lt; self&#xA;    def template(args, server_context:)&#xA;      Prompt::Result.new(&#xA;        description: &#34;Response description&#34;,&#xA;        messages: [&#xA;          Prompt::Message.new(&#xA;            role: &#34;user&#34;,&#xA;            content: Content::Text.new(&#34;User message&#34;)&#xA;          ),&#xA;          Prompt::Message.new(&#xA;            role: &#34;assistant&#34;,&#xA;            content: Content::Text.new(args[&#34;message&#34;])&#xA;          )&#xA;        ]&#xA;      )&#xA;    end&#xA;  end&#xA;end&#xA;&#xA;prompt = MyPrompt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Using the &lt;code&gt;MCP::Prompt.define&lt;/code&gt; method:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;prompt = MCP::Prompt.define(&#xA;  name: &#34;my_prompt&#34;,&#xA;  description: &#34;This prompt performs specific functionality...&#34;,&#xA;  arguments: [&#xA;    Prompt::Argument.new(&#xA;      name: &#34;message&#34;,&#xA;      description: &#34;Input message&#34;,&#xA;      required: true&#xA;    )&#xA;  ]&#xA;) do |args, server_context:|&#xA;  Prompt::Result.new(&#xA;    description: &#34;Response description&#34;,&#xA;    messages: [&#xA;      Prompt::Message.new(&#xA;        role: &#34;user&#34;,&#xA;        content: Content::Text.new(&#34;User message&#34;)&#xA;      ),&#xA;      Prompt::Message.new(&#xA;        role: &#34;assistant&#34;,&#xA;        content: Content::Text.new(args[&#34;message&#34;])&#xA;      )&#xA;    ]&#xA;  )&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The server_context parameter is the server_context passed into the server and can be used to pass per request information, e.g. around authentication state or user preferences.&lt;/p&gt; &#xA;&lt;h3&gt;Key Components&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Prompt::Argument&lt;/code&gt; - Defines input parameters for the prompt template&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Prompt::Message&lt;/code&gt; - Represents a message in the conversation with a role and content&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Prompt::Result&lt;/code&gt; - The output of a prompt template containing description and messages&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Content::Text&lt;/code&gt; - Text content for messages&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;Register prompts with the MCP server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;server = MCP::Server.new(&#xA;  name: &#34;my_server&#34;,&#xA;  prompts: [MyPrompt],&#xA;  server_context: { user_id: current_user.id },&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The server will handle prompt listing and execution through the MCP protocol methods:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;prompts/list&lt;/code&gt; - Lists all registered prompts and their schemas&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;prompts/get&lt;/code&gt; - Retrieves and executes a specific prompt with arguments&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Instrumentation&lt;/h3&gt; &#xA;&lt;p&gt;The server allows registering a callback to receive information about instrumentation. To register a handler pass a proc/lambda to as &lt;code&gt;instrumentation_callback&lt;/code&gt; into the server constructor.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;MCP.configure do |config|&#xA;  config.instrumentation_callback = -&amp;gt;(data) {&#xA;    puts &#34;Got instrumentation data #{data.inspect}&#34;&#xA;  }&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The data contains the following keys: &lt;code&gt;method&lt;/code&gt;: the metod called, e.g. &lt;code&gt;ping&lt;/code&gt;, &lt;code&gt;tools/list&lt;/code&gt;, &lt;code&gt;tools/call&lt;/code&gt; etc &lt;code&gt;tool_name&lt;/code&gt;: the name of the tool called &lt;code&gt;prompt_name&lt;/code&gt;: the name of the prompt called &lt;code&gt;resource_uri&lt;/code&gt;: the uri of the resource called &lt;code&gt;error&lt;/code&gt;: if looking up tools/prompts etc failed, e.g. &lt;code&gt;tool_not_found&lt;/code&gt; &lt;code&gt;duration&lt;/code&gt;: the duration of the call in seconds&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;tool_name&lt;/code&gt;, &lt;code&gt;prompt_name&lt;/code&gt; and &lt;code&gt;resource_uri&lt;/code&gt; are only populated if a matching handler is registered. This is to avoid potential issues with metric cardinality&lt;/p&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;p&gt;MCP spec includes &lt;a href=&#34;https://modelcontextprotocol.io/docs/concepts/resources&#34;&gt;Resources&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;MCP::Resource&lt;/code&gt; class provides a way to register resources with the server.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;resource = MCP::Resource.new(&#xA;  uri: &#34;example.com/my_resource&#34;,&#xA;  mime_type: &#34;text/plain&#34;,&#xA;  text: &#34;Lorem ipsum dolor sit amet&#34;&#xA;)&#xA;&#xA;server = MCP::Server.new(&#xA;  name: &#34;my_server&#34;,&#xA;  resources: [resource],&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The server must register a handler for the &lt;code&gt;resources/read&lt;/code&gt; method to retrieve a resource dynamically.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;server.resources_read_handler do |params|&#xA;  [{&#xA;    uri: params[:uri],&#xA;    mimeType: &#34;text/plain&#34;,&#xA;    text: &#34;Hello, world!&#34;,&#xA;  }]&#xA;end&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;otherwise &#39;resources/read&#39; requests will be a no-op.&lt;/p&gt; &#xA;&lt;h2&gt;Releases&lt;/h2&gt; &#xA;&lt;p&gt;This gem is published to &lt;a href=&#34;https://rubygems.org/gems/mcp&#34;&gt;RubyGems.org&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Releases are triggered by PRs to the &lt;code&gt;main&lt;/code&gt; branch updating the version number in &lt;code&gt;lib/mcp/version.rb&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Update the version number&lt;/strong&gt; in &lt;code&gt;lib/mcp/version.rb&lt;/code&gt;, following &lt;a href=&#34;https://semver.org/&#34;&gt;semver&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Create A PR and get approval from a maintainer&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Merge your PR to the main branch&lt;/strong&gt; - This will automatically trigger the release workflow via GitHub Actions&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;When changes are merged to the &lt;code&gt;main&lt;/code&gt; branch, the GitHub Actions workflow (&lt;code&gt;.github/workflows/release.yml&lt;/code&gt;) is triggered and the gem is published to RubyGems.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>lastmile-ai/mcp-agent</title>
    <updated>2025-06-06T01:29:18Z</updated>
    <id>tag:github.com,2025-06-06:/lastmile-ai/mcp-agent</id>
    <link href="https://github.com/lastmile-ai/mcp-agent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Build effective agents using Model Context Protocol and simple workflow patterns&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/user-attachments/assets/c8d059e5-bd56-4ea2-a72d-807fb4897bde&#34; alt=&#34;Logo&#34; width=&#34;300&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;em&gt;Build effective agents with Model Context Protocol using simple, composable patterns.&lt;/em&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/lastmile-ai/mcp-agent/tree/main/examples&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://www.anthropic.com/research/building-effective-agents&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Building Effective Agents&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://modelcontextprotocol.io/introduction&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;MCP&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://pypi.org/project/mcp-agent/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/mcp-agent?color=%2334D058&amp;amp;label=pypi&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lastmile-ai/mcp-agent/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-raw/lastmile-ai/mcp-agent&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://lmai.link/discord/mcp-agent&#34;&gt;&lt;img src=&#34;https://shields.io/discord/1089284610329952357&#34; alt=&#34;discord&#34;&gt;&lt;/a&gt; &lt;img alt=&#34;Pepy Total Downloads&#34; src=&#34;https://img.shields.io/pepy/dt/mcp-agent?label=pypi%20%7C%20downloads&#34;&gt; &lt;a href=&#34;https://github.com/lastmile-ai/mcp-agent/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/l/mcp-agent&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;mcp-agent&lt;/code&gt;&lt;/strong&gt; is a simple, composable framework to build agents using &lt;a href=&#34;https://modelcontextprotocol.io/introduction&#34;&gt;Model Context Protocol&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Inspiration&lt;/strong&gt;: Anthropic announced 2 foundational updates for AI application developers:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.anthropic.com/news/model-context-protocol&#34;&gt;Model Context Protocol&lt;/a&gt; - a standardized interface to let any software be accessible to AI assistants via MCP servers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.anthropic.com/research/building-effective-agents&#34;&gt;Building Effective Agents&lt;/a&gt; - a seminal writeup on simple, composable patterns for building production-ready AI agents.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;code&gt;mcp-agent&lt;/code&gt; puts these two foundational pieces into an AI application framework:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;It handles the pesky business of managing the lifecycle of MCP server connections so you don&#39;t have to.&lt;/li&gt; &#xA; &lt;li&gt;It implements every pattern described in Building Effective Agents, and does so in a &lt;em&gt;composable&lt;/em&gt; way, allowing you to chain these patterns together.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Bonus&lt;/strong&gt;: It implements &lt;a href=&#34;https://github.com/openai/swarm&#34;&gt;OpenAI&#39;s Swarm&lt;/a&gt; pattern for multi-agent orchestration, but in a model-agnostic way.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Altogether, this is the simplest and easiest way to build robust agent applications. Much like MCP, this project is in early development. We welcome all kinds of &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/CONTRIBUTING.md&#34;&gt;contributions&lt;/a&gt;, feedback and your help in growing this to become a new standard.&lt;/p&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;p&gt;We recommend using &lt;a href=&#34;https://docs.astral.sh/uv/&#34;&gt;uv&lt;/a&gt; to manage your Python projects:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uv add &#34;mcp-agent&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install mcp-agent&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Quickstart&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] The &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples&#34;&gt;&lt;code&gt;examples&lt;/code&gt;&lt;/a&gt; directory has several example applications to get started with. To run an example, clone this repo, then:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd examples/basic/mcp_basic_agent # Or any other example&#xA;cp mcp_agent.secrets.yaml.example mcp_agent.secrets.yaml # Update API keys&#xA;uv run main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Here is a basic &#34;finder&#34; agent that uses the fetch and filesystem servers to look up a file, read a blog and write a tweet. &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/basic/mcp_basic_agent/&#34;&gt;Example link&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;finder_agent.py&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio&#xA;import os&#xA;&#xA;from mcp_agent.app import MCPApp&#xA;from mcp_agent.agents.agent import Agent&#xA;from mcp_agent.workflows.llm.augmented_llm_openai import OpenAIAugmentedLLM&#xA;&#xA;app = MCPApp(name=&#34;hello_world_agent&#34;)&#xA;&#xA;async def example_usage():&#xA;    async with app.run() as mcp_agent_app:&#xA;        logger = mcp_agent_app.logger&#xA;        # This agent can read the filesystem or fetch URLs&#xA;        finder_agent = Agent(&#xA;            name=&#34;finder&#34;,&#xA;            instruction=&#34;&#34;&#34;You can read local files or fetch URLs.&#xA;                Return the requested information when asked.&#34;&#34;&#34;,&#xA;            server_names=[&#34;fetch&#34;, &#34;filesystem&#34;], # MCP servers this Agent can use&#xA;        )&#xA;&#xA;        async with finder_agent:&#xA;            # Automatically initializes the MCP servers and adds their tools for LLM use&#xA;            tools = await finder_agent.list_tools()&#xA;            logger.info(f&#34;Tools available:&#34;, data=tools)&#xA;&#xA;            # Attach an OpenAI LLM to the agent (defaults to GPT-4o)&#xA;            llm = await finder_agent.attach_llm(OpenAIAugmentedLLM)&#xA;&#xA;            # This will perform a file lookup and read using the filesystem server&#xA;            result = await llm.generate_str(&#xA;                message=&#34;Show me what&#39;s in README.md verbatim&#34;&#xA;            )&#xA;            logger.info(f&#34;README.md contents: {result}&#34;)&#xA;&#xA;            # Uses the fetch server to fetch the content from URL&#xA;            result = await llm.generate_str(&#xA;                message=&#34;Print the first two paragraphs from https://www.anthropic.com/research/building-effective-agents&#34;&#xA;            )&#xA;            logger.info(f&#34;Blog intro: {result}&#34;)&#xA;&#xA;            # Multi-turn interactions by default&#xA;            result = await llm.generate_str(&#34;Summarize that in a 128-char tweet&#34;)&#xA;            logger.info(f&#34;Tweet: {result}&#34;)&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(example_usage())&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;mcp_agent.config.yaml&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;execution_engine: asyncio&#xA;logger:&#xA;  transports: [console] # You can use [file, console] for both&#xA;  level: debug&#xA;  path: &#34;logs/mcp-agent.jsonl&#34; # Used for file transport&#xA;  # For dynamic log filenames:&#xA;  # path_settings:&#xA;  #   path_pattern: &#34;logs/mcp-agent-{unique_id}.jsonl&#34;&#xA;  #   unique_id: &#34;timestamp&#34;  # Or &#34;session_id&#34;&#xA;  #   timestamp_format: &#34;%Y%m%d_%H%M%S&#34;&#xA;&#xA;mcp:&#xA;  servers:&#xA;    fetch:&#xA;      command: &#34;uvx&#34;&#xA;      args: [&#34;mcp-server-fetch&#34;]&#xA;    filesystem:&#xA;      command: &#34;npx&#34;&#xA;      args:&#xA;        [&#xA;          &#34;-y&#34;,&#xA;          &#34;@modelcontextprotocol/server-filesystem&#34;,&#xA;          &#34;&amp;lt;add_your_directories&amp;gt;&#34;,&#xA;        ]&#xA;&#xA;openai:&#xA;  # Secrets (API keys, etc.) are stored in an mcp_agent.secrets.yaml file which can be gitignored&#xA;  default_model: gpt-4o&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Agent output&lt;/summary&gt; &#xA; &lt;img width=&#34;2398&#34; alt=&#34;Image&#34; src=&#34;https://github.com/user-attachments/assets/eaa60fdf-bcc6-460b-926e-6fa8534e9089&#34;&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#why-use-mcp-agent&#34;&gt;Why use mcp-agent?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#examples&#34;&gt;Example Applications&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#claude-desktop&#34;&gt;Claude Desktop&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#streamlit&#34;&gt;Streamlit&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#gmail-agent&#34;&gt;Gmail Agent&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#simple-rag-chatbot&#34;&gt;RAG&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#marimo&#34;&gt;Marimo&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#python&#34;&gt;Python&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#swarm&#34;&gt;Swarm (CLI)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#core-components&#34;&gt;Core Concepts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#workflows&#34;&gt;Workflows Patterns&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#augmentedllm&#34;&gt;Augmented LLM&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#parallel&#34;&gt;Parallel&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#router&#34;&gt;Router&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#intentclassifier&#34;&gt;Intent-Classifier&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#orchestrator-workers&#34;&gt;Orchestrator-Workers&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#evaluator-optimizer&#34;&gt;Evaluator-Optimizer&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#swarm-1&#34;&gt;OpenAI Swarm&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#advanced&#34;&gt;Advanced&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#composability&#34;&gt;Composing multiple workflows&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#signaling-and-human-input&#34;&gt;Signaling and Human input&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#app-config&#34;&gt;App Config&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#mcp-server-management&#34;&gt;MCP Server Management&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#roadmap&#34;&gt;Roadmap&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#faqs&#34;&gt;FAQs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why use &lt;code&gt;mcp-agent&lt;/code&gt;?&lt;/h2&gt; &#xA;&lt;p&gt;There are too many AI frameworks out there already. But &lt;code&gt;mcp-agent&lt;/code&gt; is the only one that is purpose-built for a shared protocol - &lt;a href=&#34;https://modelcontextprotocol.io/introduction&#34;&gt;MCP&lt;/a&gt;. It is also the most lightweight, and is closer to an agent pattern library than a framework.&lt;/p&gt; &#xA;&lt;p&gt;As &lt;a href=&#34;https://github.com/punkpeye/awesome-mcp-servers&#34;&gt;more services become MCP-aware&lt;/a&gt;, you can use mcp-agent to build robust and controllable AI agents that can leverage those services out-of-the-box.&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;Before we go into the core concepts of mcp-agent, let&#39;s show what you can build with it.&lt;/p&gt; &#xA;&lt;p&gt;In short, you can build any kind of AI application with mcp-agent: multi-agent collaborative workflows, human-in-the-loop workflows, RAG pipelines and more.&lt;/p&gt; &#xA;&lt;h3&gt;Claude Desktop&lt;/h3&gt; &#xA;&lt;p&gt;You can integrate mcp-agent apps into MCP clients like Claude Desktop.&lt;/p&gt; &#xA;&lt;h4&gt;mcp-agent server&lt;/h4&gt; &#xA;&lt;p&gt;This app wraps an mcp-agent application inside an MCP server, and exposes that server to Claude Desktop. The app exposes agents and workflows that Claude Desktop can invoke to service of the user&#39;s request.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/7807cffd-dba7-4f0c-9c70-9482fd7e0699&#34;&gt;https://github.com/user-attachments/assets/7807cffd-dba7-4f0c-9c70-9482fd7e0699&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This demo shows a multi-agent evaluation task where each agent evaluates aspects of an input poem, and then an aggregator summarizes their findings into a final response.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Details&lt;/strong&gt;: Starting from a user&#39;s request over text, the application:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;dynamically defines agents to do the job&lt;/li&gt; &#xA; &lt;li&gt;uses the appropriate workflow to orchestrate those agents (in this case the Parallel workflow)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Link to code&lt;/strong&gt;: &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/basic/mcp_agent_server&#34;&gt;examples/basic/mcp_agent_server&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] Huge thanks to &lt;a href=&#34;https://github.com/StreetLamb&#34;&gt;Jerron Lim (@StreetLamb)&lt;/a&gt; for developing and contributing this example!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Streamlit&lt;/h3&gt; &#xA;&lt;p&gt;You can deploy mcp-agent apps using Streamlit.&lt;/p&gt; &#xA;&lt;h4&gt;Gmail agent&lt;/h4&gt; &#xA;&lt;p&gt;This app is able to perform read and write actions on gmail using text prompts -- i.e. read, delete, send emails, mark as read/unread, etc. It uses an MCP server for Gmail.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/54899cac-de24-4102-bd7e-4b2022c956e3&#34;&gt;https://github.com/user-attachments/assets/54899cac-de24-4102-bd7e-4b2022c956e3&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Link to code&lt;/strong&gt;: &lt;a href=&#34;https://github.com/jasonsum/gmail-mcp-server/raw/add-mcp-agent-streamlit/streamlit_app.py&#34;&gt;gmail-mcp-server&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] Huge thanks to &lt;a href=&#34;https://github.com/jasonsum&#34;&gt;Jason Summer (@jasonsum)&lt;/a&gt; for developing and contributing this example!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;Simple RAG Chatbot&lt;/h4&gt; &#xA;&lt;p&gt;This app uses a Qdrant vector database (via an MCP server) to do Q&amp;amp;A over a corpus of text.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/f4dcd227-cae9-4a59-aa9e-0eceeb4acaf4&#34;&gt;https://github.com/user-attachments/assets/f4dcd227-cae9-4a59-aa9e-0eceeb4acaf4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Link to code&lt;/strong&gt;: &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/usecases/streamlit_mcp_rag_agent/&#34;&gt;examples/usecases/streamlit_mcp_rag_agent&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] Huge thanks to &lt;a href=&#34;https://github.com/StreetLamb&#34;&gt;Jerron Lim (@StreetLamb)&lt;/a&gt; for developing and contributing this example!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Marimo&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/marimo-team/marimo&#34;&gt;Marimo&lt;/a&gt; is a reactive Python notebook that replaces Jupyter and Streamlit. Here&#39;s the &#34;file finder&#34; agent from &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#quickstart&#34;&gt;Quickstart&lt;/a&gt; implemented in Marimo:&lt;/p&gt; &#xA;&lt;img src=&#34;https://github.com/user-attachments/assets/139a95a5-e3ac-4ea7-9c8f-bad6577e8597&#34; width=&#34;400&#34;&gt; &#xA;&lt;p&gt;&lt;strong&gt;Link to code&lt;/strong&gt;: &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/usecases/marimo_mcp_basic_agent/&#34;&gt;examples/usecases/marimo_mcp_basic_agent&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] Huge thanks to &lt;a href=&#34;https://github.com/akshayka&#34;&gt;Akshay Agrawal (@akshayka)&lt;/a&gt; for developing and contributing this example!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Python&lt;/h3&gt; &#xA;&lt;p&gt;You can write mcp-agent apps as Python scripts or Jupyter notebooks.&lt;/p&gt; &#xA;&lt;h4&gt;Swarm&lt;/h4&gt; &#xA;&lt;p&gt;This example demonstrates a multi-agent setup for handling different customer service requests in an airline context using the Swarm workflow pattern. The agents can triage requests, handle flight modifications, cancellations, and lost baggage cases.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/b314d75d-7945-4de6-965b-7f21eb14a8bd&#34;&gt;https://github.com/user-attachments/assets/b314d75d-7945-4de6-965b-7f21eb14a8bd&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Link to code&lt;/strong&gt;: &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/workflows/workflow_swarm/&#34;&gt;examples/workflows/workflow_swarm&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Core Components&lt;/h2&gt; &#xA;&lt;p&gt;The following are the building blocks of the mcp-agent framework:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/app.py&#34;&gt;MCPApp&lt;/a&gt;&lt;/strong&gt;: global state and app configuration&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;MCP server management&lt;/strong&gt;: &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/mcp/gen_client.py&#34;&gt;&lt;code&gt;gen_client&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/mcp/mcp_connection_manager.py&#34;&gt;&lt;code&gt;MCPConnectionManager&lt;/code&gt;&lt;/a&gt; to easily connect to MCP servers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/agents/agent.py&#34;&gt;Agent&lt;/a&gt;&lt;/strong&gt;: An Agent is an entity that has access to a set of MCP servers and exposes them to an LLM as tool calls. It has a name and purpose (instruction).&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/llm/augmented_llm.py&#34;&gt;AugmentedLLM&lt;/a&gt;&lt;/strong&gt;: An LLM that is enhanced with tools provided from a collection of MCP servers. Every Workflow pattern described below is an &lt;code&gt;AugmentedLLM&lt;/code&gt; itself, allowing you to compose and chain them together.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Everything in the framework is a derivative of these core capabilities.&lt;/p&gt; &#xA;&lt;h2&gt;Workflows&lt;/h2&gt; &#xA;&lt;p&gt;mcp-agent provides implementations for every pattern in Anthropic’s &lt;a href=&#34;https://www.anthropic.com/research/building-effective-agents&#34;&gt;Building Effective Agents&lt;/a&gt;, as well as the OpenAI &lt;a href=&#34;https://github.com/openai/swarm&#34;&gt;Swarm&lt;/a&gt; pattern. Each pattern is model-agnostic, and exposed as an &lt;code&gt;AugmentedLLM&lt;/code&gt;, making everything very composable.&lt;/p&gt; &#xA;&lt;h3&gt;AugmentedLLM&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/llm/augmented_llm.py&#34;&gt;AugmentedLLM&lt;/a&gt; is an LLM that has access to MCP servers and functions via Agents.&lt;/p&gt; &#xA;&lt;p&gt;LLM providers implement the AugmentedLLM interface to expose 3 functions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;generate&lt;/code&gt;: Generate message(s) given a prompt, possibly over multiple iterations and making tool calls as needed.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;generate_str&lt;/code&gt;: Calls &lt;code&gt;generate&lt;/code&gt; and returns result as a string output.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;generate_structured&lt;/code&gt;: Uses &lt;a href=&#34;https://github.com/instructor-ai/instructor&#34;&gt;Instructor&lt;/a&gt; to return the generated result as a Pydantic model.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Additionally, &lt;code&gt;AugmentedLLM&lt;/code&gt; has memory, to keep track of long or short-term history.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Example&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mcp_agent.agents.agent import Agent&#xA;from mcp_agent.workflows.llm.augmented_llm_anthropic import AnthropicAugmentedLLM&#xA;&#xA;finder_agent = Agent(&#xA;    name=&#34;finder&#34;,&#xA;    instruction=&#34;You are an agent with filesystem + fetch access. Return the requested file or URL contents.&#34;,&#xA;    server_names=[&#34;fetch&#34;, &#34;filesystem&#34;],&#xA;)&#xA;&#xA;async with finder_agent:&#xA;   llm = await finder_agent.attach_llm(AnthropicAugmentedLLM)&#xA;&#xA;   result = await llm.generate_str(&#xA;      message=&#34;Print the first 2 paragraphs of https://www.anthropic.com/research/building-effective-agents&#34;,&#xA;      # Can override model, tokens and other defaults&#xA;   )&#xA;   logger.info(f&#34;Result: {result}&#34;)&#xA;&#xA;   # Multi-turn conversation&#xA;   result = await llm.generate_str(&#xA;      message=&#34;Summarize those paragraphs in a 128 character tweet&#34;,&#xA;   )&#xA;   logger.info(f&#34;Result: {result}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/parallel/parallel_llm.py&#34;&gt;Parallel&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.png&amp;amp;w=3840&amp;amp;q=75&#34; alt=&#34;Parallel workflow (Image credit: Anthropic)&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Fan-out tasks to multiple sub-agents and fan-in the results. Each subtask is an AugmentedLLM, as is the overall Parallel workflow, meaning each subtask can optionally be a more complex workflow itself.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/workflows/workflow_parallel/main.py&#34;&gt;Link to full example&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Example&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;proofreader = Agent(name=&#34;proofreader&#34;, instruction=&#34;Review grammar...&#34;)&#xA;fact_checker = Agent(name=&#34;fact_checker&#34;, instruction=&#34;Check factual consistency...&#34;)&#xA;style_enforcer = Agent(name=&#34;style_enforcer&#34;, instruction=&#34;Enforce style guidelines...&#34;)&#xA;&#xA;grader = Agent(name=&#34;grader&#34;, instruction=&#34;Combine feedback into a structured report.&#34;)&#xA;&#xA;parallel = ParallelLLM(&#xA;    fan_in_agent=grader,&#xA;    fan_out_agents=[proofreader, fact_checker, style_enforcer],&#xA;    llm_factory=OpenAIAugmentedLLM,&#xA;)&#xA;&#xA;result = await parallel.generate_str(&#34;Student short story submission: ...&#34;, RequestParams(model=&#34;gpt4-o&#34;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/router/&#34;&gt;Router&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.png&amp;amp;w=3840&amp;amp;q=75&#34; alt=&#34;Router workflow (Image credit: Anthropic)&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Given an input, route to the &lt;code&gt;top_k&lt;/code&gt; most relevant categories. A category can be an Agent, an MCP server or a regular function.&lt;/p&gt; &#xA;&lt;p&gt;mcp-agent provides several router implementations, including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/router/router_embedding.py&#34;&gt;&lt;code&gt;EmbeddingRouter&lt;/code&gt;&lt;/a&gt;: uses embedding models for classification&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/router/router_llm.py&#34;&gt;&lt;code&gt;LLMRouter&lt;/code&gt;&lt;/a&gt;: uses LLMs for classification&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/workflows/workflow_router/main.py&#34;&gt;Link to full example&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Example&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def print_hello_world:&#xA;     print(&#34;Hello, world!&#34;)&#xA;&#xA;finder_agent = Agent(name=&#34;finder&#34;, server_names=[&#34;fetch&#34;, &#34;filesystem&#34;])&#xA;writer_agent = Agent(name=&#34;writer&#34;, server_names=[&#34;filesystem&#34;])&#xA;&#xA;llm = OpenAIAugmentedLLM()&#xA;router = LLMRouter(&#xA;    llm=llm,&#xA;    agents=[finder_agent, writer_agent],&#xA;    functions=[print_hello_world],&#xA;)&#xA;&#xA;results = await router.route( # Also available: route_to_agent, route_to_server&#xA;    request=&#34;Find and print the contents of README.md verbatim&#34;,&#xA;    top_k=1&#xA;)&#xA;chosen_agent = results[0].result&#xA;async with chosen_agent:&#xA;    ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/intent_classifier/&#34;&gt;IntentClassifier&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;A close sibling of Router, the Intent Classifier pattern identifies the &lt;code&gt;top_k&lt;/code&gt; Intents that most closely match a given input. Just like a Router, mcp-agent provides both an &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/intent_classifier/intent_classifier_embedding.py&#34;&gt;embedding&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/intent_classifier/intent_classifier_llm.py&#34;&gt;LLM-based&lt;/a&gt; intent classifier.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/evaluator_optimizer/evaluator_optimizer.py&#34;&gt;Evaluator-Optimizer&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.png&amp;amp;w=3840&amp;amp;q=75&#34; alt=&#34;Evaluator-optimizer workflow (Image credit: Anthropic)&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;One LLM (the “optimizer”) refines a response, another (the “evaluator”) critiques it until a response exceeds a quality criteria.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/workflows/workflow_evaluator_optimizer/main.py&#34;&gt;Link to full example&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Example&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;optimizer = Agent(name=&#34;cover_letter_writer&#34;, server_names=[&#34;fetch&#34;], instruction=&#34;Generate a cover letter ...&#34;)&#xA;evaluator = Agent(name=&#34;critiquer&#34;, instruction=&#34;Evaluate clarity, specificity, relevance...&#34;)&#xA;&#xA;llm = EvaluatorOptimizerLLM(&#xA;    optimizer=optimizer,&#xA;    evaluator=evaluator,&#xA;    llm_factory=OpenAIAugmentedLLM,&#xA;    min_rating=QualityRating.EXCELLENT, # Keep iterating until the minimum quality bar is reached&#xA;)&#xA;&#xA;result = await eo_llm.generate_str(&#34;Write a job cover letter for an AI framework developer role at LastMile AI.&#34;)&#xA;print(&#34;Final refined cover letter:&#34;, result)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/orchestrator/orchestrator.py&#34;&gt;Orchestrator-workers&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png&amp;amp;w=3840&amp;amp;q=75&#34; alt=&#34;Orchestrator workflow (Image credit: Anthropic)&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;A higher-level LLM generates a plan, then assigns them to sub-agents, and synthesizes the results. The Orchestrator workflow automatically parallelizes steps that can be done in parallel, and blocks on dependencies.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/workflows/workflow_orchestrator_worker/main.py&#34;&gt;Link to full example&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Example&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;finder_agent = Agent(name=&#34;finder&#34;, server_names=[&#34;fetch&#34;, &#34;filesystem&#34;])&#xA;writer_agent = Agent(name=&#34;writer&#34;, server_names=[&#34;filesystem&#34;])&#xA;proofreader = Agent(name=&#34;proofreader&#34;, ...)&#xA;fact_checker = Agent(name=&#34;fact_checker&#34;, ...)&#xA;style_enforcer = Agent(name=&#34;style_enforcer&#34;, instructions=&#34;Use APA style guide from ...&#34;, server_names=[&#34;fetch&#34;])&#xA;&#xA;orchestrator = Orchestrator(&#xA;    llm_factory=AnthropicAugmentedLLM,&#xA;    available_agents=[finder_agent, writer_agent, proofreader, fact_checker, style_enforcer],&#xA;)&#xA;&#xA;task = &#34;Load short_story.md, evaluate it, produce a graded_report.md with multiple feedback aspects.&#34;&#xA;result = await orchestrator.generate_str(task, RequestParams(model=&#34;gpt-4o&#34;))&#xA;print(result)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/swarm/swarm.py&#34;&gt;Swarm&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;OpenAI has an experimental multi-agent pattern called &lt;a href=&#34;https://github.com/openai/swarm&#34;&gt;Swarm&lt;/a&gt;, which we provide a model-agnostic reference implementation for in mcp-agent.&lt;/p&gt; &#xA;&lt;img src=&#34;https://github.com/openai/swarm/raw/main/assets/swarm_diagram.png?raw=true&#34; width=&#34;500&#34;&gt; &#xA;&lt;p&gt;The mcp-agent Swarm pattern works seamlessly with MCP servers, and is exposed as an &lt;code&gt;AugmentedLLM&lt;/code&gt;, allowing for composability with other patterns above.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/workflows/workflow_swarm/main.py&#34;&gt;Link to full example&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Example&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;triage_agent = SwarmAgent(...)&#xA;flight_mod_agent = SwarmAgent(...)&#xA;lost_baggage_agent = SwarmAgent(...)&#xA;&#xA;# The triage agent decides whether to route to flight_mod_agent or lost_baggage_agent&#xA;swarm = AnthropicSwarm(agent=triage_agent, context_variables={...})&#xA;&#xA;test_input = &#34;My bag was not delivered!&#34;&#xA;result = await swarm.generate_str(test_input)&#xA;print(&#34;Result:&#34;, result)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Advanced&lt;/h2&gt; &#xA;&lt;h3&gt;Composability&lt;/h3&gt; &#xA;&lt;p&gt;An example of composability is using an &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#evaluator-optimizer&#34;&gt;Evaluator-Optimizer&lt;/a&gt; workflow as the planner LLM inside the &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#orchestrator-workers&#34;&gt;Orchestrator&lt;/a&gt; workflow. Generating a high-quality plan to execute is important for robust behavior, and an evaluator-optimizer can help ensure that.&lt;/p&gt; &#xA;&lt;p&gt;Doing so is seamless in mcp-agent, because each workflow is implemented as an &lt;code&gt;AugmentedLLM&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Example&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;optimizer = Agent(name=&#34;plan_optimizer&#34;, server_names=[...], instruction=&#34;Generate a plan given an objective ...&#34;)&#xA;evaluator = Agent(name=&#34;plan_evaluator&#34;, instruction=&#34;Evaluate logic, ordering and precision of plan......&#34;)&#xA;&#xA;planner_llm = EvaluatorOptimizerLLM(&#xA;    optimizer=optimizer,&#xA;    evaluator=evaluator,&#xA;    llm_factory=OpenAIAugmentedLLM,&#xA;    min_rating=QualityRating.EXCELLENT,&#xA;)&#xA;&#xA;orchestrator = Orchestrator(&#xA;    llm_factory=AnthropicAugmentedLLM,&#xA;    available_agents=[finder_agent, writer_agent, proofreader, fact_checker, style_enforcer],&#xA;    planner=planner_llm # It&#39;s that simple&#xA;)&#xA;&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;Signaling and Human Input&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Signaling&lt;/strong&gt;: The framework can pause/resume tasks. The agent or LLM might “signal” that it needs user input, so the workflow awaits. A developer may signal during a workflow to seek approval or review before continuing with a workflow.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Human Input&lt;/strong&gt;: If an Agent has a &lt;code&gt;human_input_callback&lt;/code&gt;, the LLM can call a &lt;code&gt;__human_input__&lt;/code&gt; tool to request user input mid-workflow.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Example&lt;/summary&gt; &#xA; &lt;p&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/workflows/workflow_swarm/main.py&#34;&gt;Swarm example&lt;/a&gt; shows this in action.&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mcp_agent.human_input.handler import console_input_callback&#xA;&#xA;lost_baggage = SwarmAgent(&#xA;    name=&#34;Lost baggage traversal&#34;,&#xA;    instruction=lambda context_variables: f&#34;&#34;&#34;&#xA;        {&#xA;        FLY_AIR_AGENT_PROMPT.format(&#xA;            customer_context=context_variables.get(&#34;customer_context&#34;, &#34;None&#34;),&#xA;            flight_context=context_variables.get(&#34;flight_context&#34;, &#34;None&#34;),&#xA;        )&#xA;    }\n Lost baggage policy: policies/lost_baggage_policy.md&#34;&#34;&#34;,&#xA;    functions=[&#xA;        escalate_to_agent,&#xA;        initiate_baggage_search,&#xA;        transfer_to_triage,&#xA;        case_resolved,&#xA;    ],&#xA;    server_names=[&#34;fetch&#34;, &#34;filesystem&#34;],&#xA;    human_input_callback=console_input_callback, # Request input from the console&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;App Config&lt;/h3&gt; &#xA;&lt;p&gt;Create an &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/schema/mcp-agent.config.schema.json&#34;&gt;&lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;&lt;/a&gt; and a gitignored &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/basic/mcp_basic_agent/mcp_agent.secrets.yaml.example&#34;&gt;&lt;code&gt;mcp_agent.secrets.yaml&lt;/code&gt;&lt;/a&gt; to define MCP app configuration. This controls logging, execution, LLM provider APIs, and MCP server configuration.&lt;/p&gt; &#xA;&lt;h3&gt;MCP server management&lt;/h3&gt; &#xA;&lt;p&gt;mcp-agent makes it trivial to connect to MCP servers. Create an &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/schema/mcp-agent.config.schema.json&#34;&gt;&lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;&lt;/a&gt; to define server configuration under the &lt;code&gt;mcp&lt;/code&gt; section:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;mcp:&#xA;  servers:&#xA;    fetch:&#xA;      command: &#34;uvx&#34;&#xA;      args: [&#34;mcp-server-fetch&#34;]&#xA;      description: &#34;Fetch content at URLs from the world wide web&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/mcp/gen_client.py&#34;&gt;&lt;code&gt;gen_client&lt;/code&gt;&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;Manage the lifecycle of an MCP server within an async context manager:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mcp_agent.mcp.gen_client import gen_client&#xA;&#xA;async with gen_client(&#34;fetch&#34;) as fetch_client:&#xA;    # Fetch server is initialized and ready to use&#xA;    result = await fetch_client.list_tools()&#xA;&#xA;# Fetch server is automatically disconnected/shutdown&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The gen_client function makes it easy to spin up connections to MCP servers.&lt;/p&gt; &#xA;&lt;h4&gt;Persistent server connections&lt;/h4&gt; &#xA;&lt;p&gt;In many cases, you want an MCP server to stay online for persistent use (e.g. in a multi-step tool use workflow). For persistent connections, use:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/(src/mcp_agent/mcp/gen_client.py)&#34;&gt;&lt;code&gt;connect&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/mcp/gen_client.py&#34;&gt;&lt;code&gt;disconnect&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mcp_agent.mcp.gen_client import connect, disconnect&#xA;&#xA;fetch_client = None&#xA;try:&#xA;     fetch_client = connect(&#34;fetch&#34;)&#xA;     result = await fetch_client.list_tools()&#xA;finally:&#xA;     disconnect(&#34;fetch&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/mcp/mcp_connection_manager.py&#34;&gt;&lt;code&gt;MCPConnectionManager&lt;/code&gt;&lt;/a&gt; For even more fine-grained control over server connections, you can use the MCPConnectionManager.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Example&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mcp_agent.context import get_current_context&#xA;from mcp_agent.mcp.mcp_connection_manager import MCPConnectionManager&#xA;&#xA;context = get_current_context()&#xA;connection_manager = MCPConnectionManager(context.server_registry)&#xA;&#xA;async with connection_manager:&#xA;fetch_client = await connection_manager.get_server(&#34;fetch&#34;) # Initializes fetch server&#xA;result = fetch_client.list_tool()&#xA;fetch_client2 = await connection_manager.get_server(&#34;fetch&#34;) # Reuses same server connection&#xA;&#xA;# All servers managed by connection manager are automatically disconnected/shut down&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h4&gt;MCP Server Aggregator&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/mcp/mcp_aggregator.py&#34;&gt;&lt;code&gt;MCPAggregator&lt;/code&gt;&lt;/a&gt; acts as a &#34;server-of-servers&#34;. It provides a single MCP server interface for interacting with multiple MCP servers. This allows you to expose tools from multiple servers to LLM applications.&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Example&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mcp_agent.mcp.mcp_aggregator import MCPAggregator&#xA;&#xA;aggregator = await MCPAggregator.create(server_names=[&#34;fetch&#34;, &#34;filesystem&#34;])&#xA;&#xA;async with aggregator:&#xA;   # combined list of tools exposed by &#39;fetch&#39; and &#39;filesystem&#39; servers&#xA;   tools = await aggregator.list_tools()&#xA;&#xA;   # namespacing -- invokes the &#39;fetch&#39; server to call the &#39;fetch&#39; tool&#xA;   fetch_result = await aggregator.call_tool(name=&#34;fetch-fetch&#34;, arguments={&#34;url&#34;: &#34;https://www.anthropic.com/research/building-effective-agents&#34;})&#xA;&#xA;   # no namespacing -- first server in the aggregator exposing that tool wins&#xA;   read_file_result = await aggregator.call_tool(name=&#34;read_file&#34;, arguments={})&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome any and all kinds of contributions. Please see the &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING guidelines&lt;/a&gt; to get started.&lt;/p&gt; &#xA;&lt;h3&gt;Special Mentions&lt;/h3&gt; &#xA;&lt;p&gt;There have already been incredible community contributors who are driving this project forward:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/evalstate&#34;&gt;Shaun Smith (@evalstate)&lt;/a&gt; -- who has been leading the charge on countless complex improvements, both to &lt;code&gt;mcp-agent&lt;/code&gt; and generally to the MCP ecosystem.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/StreetLamb&#34;&gt;Jerron Lim (@StreetLamb)&lt;/a&gt; -- who has contributed countless hours and excellent examples, and great ideas to the project.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jasonsum&#34;&gt;Jason Summer (@jasonsum)&lt;/a&gt; -- for identifying several issues and adapting his Gmail MCP server to work with mcp-agent&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;p&gt;We will be adding a detailed roadmap (ideally driven by your feedback). The current set of priorities include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Durable Execution&lt;/strong&gt; -- allow workflows to pause/resume and serialize state so they can be replayed or be paused indefinitely. We are working on integrating &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/executor/temporal.py&#34;&gt;Temporal&lt;/a&gt; for this purpose.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Memory&lt;/strong&gt; -- adding support for long-term memory&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Streaming&lt;/strong&gt; -- Support streaming listeners for iterative progress&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Additional MCP capabilities&lt;/strong&gt; -- Expand beyond tool calls to support: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Resources&lt;/li&gt; &#xA;   &lt;li&gt;Prompts&lt;/li&gt; &#xA;   &lt;li&gt;Notifications&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;FAQs&lt;/h2&gt; &#xA;&lt;h3&gt;What are the core benefits of using mcp-agent?&lt;/h3&gt; &#xA;&lt;p&gt;mcp-agent provides a streamlined approach to building AI agents using capabilities exposed by &lt;strong&gt;MCP&lt;/strong&gt; (Model Context Protocol) servers.&lt;/p&gt; &#xA;&lt;p&gt;MCP is quite low-level, and this framework handles the mechanics of connecting to servers, working with LLMs, handling external signals (like human input) and supporting persistent state via durable execution. That lets you, the developer, focus on the core business logic of your AI application.&lt;/p&gt; &#xA;&lt;p&gt;Core benefits:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🤝 &lt;strong&gt;Interoperability&lt;/strong&gt;: ensures that any tool exposed by any number of MCP servers can seamlessly plug in to your agents.&lt;/li&gt; &#xA; &lt;li&gt;⛓️ &lt;strong&gt;Composability &amp;amp; Cutstomizability&lt;/strong&gt;: Implements well-defined workflows, but in a composable way that enables compound workflows, and allows full customization across model provider, logging, orchestrator, etc.&lt;/li&gt; &#xA; &lt;li&gt;💻 &lt;strong&gt;Programmatic control flow&lt;/strong&gt;: Keeps things simple as developers just write code instead of thinking in graphs, nodes and edges. For branching logic, you write &lt;code&gt;if&lt;/code&gt; statements. For cycles, use &lt;code&gt;while&lt;/code&gt; loops.&lt;/li&gt; &#xA; &lt;li&gt;🖐️ &lt;strong&gt;Human Input &amp;amp; Signals&lt;/strong&gt;: Supports pausing workflows for external signals, such as human input, which are exposed as tool calls an Agent can make.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Do you need an MCP client to use mcp-agent?&lt;/h3&gt; &#xA;&lt;p&gt;No, you can use mcp-agent anywhere, since it handles MCPClient creation for you. This allows you to leverage MCP servers outside of MCP hosts like Claude Desktop.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s all the ways you can set up your mcp-agent application:&lt;/p&gt; &#xA;&lt;h4&gt;MCP-Agent Server&lt;/h4&gt; &#xA;&lt;p&gt;You can expose mcp-agent applications as MCP servers themselves (see &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/basic/mcp_agent_server&#34;&gt;example&lt;/a&gt;), allowing MCP clients to interface with sophisticated AI workflows using the standard tools API of MCP servers. This is effectively a server-of-servers.&lt;/p&gt; &#xA;&lt;h4&gt;MCP Client or Host&lt;/h4&gt; &#xA;&lt;p&gt;You can embed mcp-agent in an MCP client directly to manage the orchestration across multiple MCP servers.&lt;/p&gt; &#xA;&lt;h4&gt;Standalone&lt;/h4&gt; &#xA;&lt;p&gt;You can use mcp-agent applications in a standalone fashion (i.e. they aren&#39;t part of an MCP client). The &lt;a href=&#34;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/&#34;&gt;&lt;code&gt;examples&lt;/code&gt;&lt;/a&gt; are all standalone applications.&lt;/p&gt; &#xA;&lt;h3&gt;Tell me a fun fact&lt;/h3&gt; &#xA;&lt;p&gt;I debated naming this project &lt;em&gt;silsila&lt;/em&gt; (سلسلہ), which means chain of events in Urdu. mcp-agent is more matter-of-fact, but there&#39;s still an easter egg in the project paying homage to silsila.&lt;/p&gt;</summary>
  </entry>
</feed>