<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-04-11T01:28:47Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>krillinai/KrillinAI</title>
    <updated>2025-04-11T01:28:47Z</updated>
    <id>tag:github.com,2025-04-11:/krillinai/KrillinAI</id>
    <link href="https://github.com/krillinai/KrillinAI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A video translation and dubbing tool powered by LLMs, offering professional-grade translations and one-click full-process deployment. It can generate content optimized for platforms like YouTube，TikTok, and Shorts. 基于AI大模型的视频翻译和配音工具，专业级翻译，一键部署全流程，可以生成适配抖音，小红书，哔哩哔哩，视频号，TikTok，Youtube Shorts等形态的内容&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/images/logo.png&#34; alt=&#34;KrillinAI&#34; height=&#34;90&#34;&gt; &#xA; &lt;h1&gt;AI Audio&amp;amp;Video Translation and Dubbing Tool&lt;/h1&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://trendshift.io/repositories/13360&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://trendshift.io/api/badge/repositories/13360&#34; alt=&#34;krillinai%2FKrillinAI | Trendshift&#34; style=&#34;width: 250px; height: 55px;&#34; width=&#34;250&#34; height=&#34;55&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/README.md&#34;&gt;English&lt;/a&gt;｜&lt;a href=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/README_zh.md&#34;&gt;简体中文&lt;/a&gt;｜&lt;a href=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/README_jp.md&#34;&gt;日本語&lt;/a&gt;｜&lt;a href=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/README_kr.md&#34;&gt;한국어&lt;/a&gt;｜&lt;a href=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/README_fr.md&#34;&gt;Français&lt;/a&gt;｜&lt;a href=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/README_de.md&#34;&gt;Deutsch&lt;/a&gt;｜&lt;a href=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/README_es.md&#34;&gt;Español&lt;/a&gt;｜&lt;a href=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/README_pt.md&#34;&gt;Português&lt;/a&gt;｜&lt;a href=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/README_rus.md&#34;&gt;Русский&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://x.com/KrillinAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Twitter-KrillinAI-orange?logo=twitter&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://space.bilibili.com/242124650&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/dynamic/json?label=Bilibili&amp;amp;query=%24.data.follower&amp;amp;suffix=%20followers&amp;amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Frelation%2Fstat%3Fvmid%3D242124650&amp;amp;logo=bilibili&amp;amp;color=00A1D6&amp;amp;labelColor=FE7398&amp;amp;logoColor=FFFFFF&#34; alt=&#34;Bilibili&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://jq.qq.com/?_wv=1027&amp;amp;k=754069680&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/QQ%20%E7%BE%A4-754069680-green?logo=tencent-qq&#34; alt=&#34;QQ 群&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;📢 New Release for Win &amp;amp; Mac Desktop Version – Welcome to Test and Provide Feedback&lt;/h3&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;Krillin AI is an all-in-one solution for effortless video localization and enhancement. This minimalist yet powerful tool handles everything from translation, dubbing to voice cloning，formatting—seamlessly converting videos between landscape and portrait modes for optimal display across all content platforms(YouTube, TikTok, Bilibili, Douyin, WeChat Channel, RedNote, Kuaishou). With its end-to-end workflow, Krillin AI transforms raw footage into polished, platform-ready content in just a few clicks.&lt;/p&gt; &#xA;&lt;h2&gt;Key Features:&lt;/h2&gt; &#xA;&lt;p&gt;🎯 &lt;strong&gt;One-Click Start&lt;/strong&gt; - Launch your workflow instantly,New desktop version available—easier to use!&lt;/p&gt; &#xA;&lt;p&gt;📥 &lt;strong&gt;Video download&lt;/strong&gt; - yt-dlp and local file uploading supported&lt;/p&gt; &#xA;&lt;p&gt;📜 &lt;strong&gt;Precise Subtitles&lt;/strong&gt; - Whisper-powered high-accuracy recognition&lt;/p&gt; &#xA;&lt;p&gt;🧠 &lt;strong&gt;Smart Segmentation&lt;/strong&gt; - LLM-based subtitle chunking &amp;amp; alignment&lt;/p&gt; &#xA;&lt;p&gt;🌍 &lt;strong&gt;Professional Translation&lt;/strong&gt; - Paragraph-level translation for consistency&lt;/p&gt; &#xA;&lt;p&gt;🔄 &lt;strong&gt;Term Replacement&lt;/strong&gt; - One-click domain-specific vocabulary swap&lt;/p&gt; &#xA;&lt;p&gt;🎙️ &lt;strong&gt;Dubbing and Voice Cloning&lt;/strong&gt; - CosyVoice selected or cloning voices&lt;/p&gt; &#xA;&lt;p&gt;🎬 &lt;strong&gt;Video Composition&lt;/strong&gt; - Auto-formatting for horizontal/vertical layouts&lt;/p&gt; &#xA;&lt;h2&gt;Showcase&lt;/h2&gt; &#xA;&lt;p&gt;The following picture demonstrates the effect after the subtitle file, which was generated through a one-click operation after importing a 46-minute local video, was inserted into the track. There was no manual adjustment involved at all. There are no missing or overlapping subtitles, the sentence segmentation is natural, and the translation quality is also quite high. &lt;img src=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/images/alignment.png&#34; alt=&#34;Alignment&#34;&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;33%&#34;&gt; &lt;h3&gt;Subtitle Translation&lt;/h3&gt; &#xA;    &lt;hr&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/bba1ac0a-fe6b-4947-b58d-ba99306d0339&#34;&gt;https://github.com/user-attachments/assets/bba1ac0a-fe6b-4947-b58d-ba99306d0339&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;33%&#34;&gt; &lt;h3&gt;Dubbing&lt;/h3&gt; &#xA;    &lt;hr&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/0b32fad3-c3ad-4b6a-abf0-0865f0dd2385&#34;&gt;https://github.com/user-attachments/assets/0b32fad3-c3ad-4b6a-abf0-0865f0dd2385&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;33%&#34;&gt; &lt;h3&gt;Portrait&lt;/h3&gt; &#xA;    &lt;hr&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/c2c7b528-0ef8-4ba9-b8ac-f9f92f6d4e71&#34;&gt;https://github.com/user-attachments/assets/c2c7b528-0ef8-4ba9-b8ac-f9f92f6d4e71&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;🌍 Language Support&lt;/h2&gt; &#xA;&lt;p&gt;Input languages: Chinese, English, Japanese, German, Turkish supported (more languages being added)&lt;br&gt; Translation languages: 56 languages supported, including English, Chinese, Russian, Spanish, French, etc.&lt;/p&gt; &#xA;&lt;h2&gt;Interface Preview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/images/ui_desktop.png&#34; alt=&#34;ui preview&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; &#xA;&lt;h3&gt;Basic Steps&lt;/h3&gt; &#xA;&lt;p&gt;First, download the Release executable file that matches your device&#39;s system. Follow the instructions below to choose between the desktop or non-desktop version, then place the software in an empty folder. Running the program will generate some directories, so keeping it in an empty folder makes management easier.&lt;/p&gt; &#xA;&lt;p&gt;[For the desktop version (release files with &#34;desktop&#34; in the name), refer here]&lt;br&gt; &lt;em&gt;The desktop version is newly released to address the difficulty beginners face in editing configuration files correctly. It still has some bugs and is being continuously updated.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Double-click the file to start using it.&lt;/p&gt; &#xA;&lt;p&gt;[For the non-desktop version (release files without &#34;desktop&#34; in the name), refer here]&lt;br&gt; &lt;em&gt;The non-desktop version is the original release, with more complex configuration but stable functionality. It is also suitable for server deployment, as it provides a web-based UI.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Create a &lt;code&gt;config&lt;/code&gt; folder in the directory, then create a &lt;code&gt;config.toml&lt;/code&gt; file inside it. Copy the contents of the &lt;code&gt;config-example.toml&lt;/code&gt; file from the source code&#39;s &lt;code&gt;config&lt;/code&gt; directory into your &lt;code&gt;config.toml&lt;/code&gt; and fill in your configuration details. (If you want to use OpenAI models but don’t know how to get a key, you can join the group for free trial access.)&lt;/p&gt; &#xA;&lt;p&gt;Double-click the executable or run it in the terminal to start the service.&lt;/p&gt; &#xA;&lt;p&gt;Open your browser and enter &lt;a href=&#34;http://127.0.0.1:8888&#34;&gt;http://127.0.0.1:8888&lt;/a&gt; to begin using it. (Replace 8888 with the port number you specified in the config file.)&lt;/p&gt; &#xA;&lt;h3&gt;To: macOS Users&lt;/h3&gt; &#xA;&lt;p&gt;[For the desktop version, i.e., release files with &#34;desktop&#34; in the name, refer here]&lt;br&gt; The current packaging method for the desktop version cannot support direct double-click execution or DMG installation due to signing issues. Manual trust configuration is required as follows:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Open the directory containing the executable file (assuming the filename is KrillinAI_1.0.0_desktop_macOS_arm64) in Terminal&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Execute the following commands sequentially:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo xattr -cr ./KrillinAI_1.0.0_desktop_macOS_arm64  &#xA;sudo chmod +x ./KrillinAI_1.0.0_desktop_macOS_arm64  &#xA;./KrillinAI_1.0.0_desktop_macOS_arm64  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;[For the non-desktop version, i.e., release files without &#34;desktop&#34; in the name, refer here]&lt;br&gt; This software is not signed, so after completing the file configuration in the &#34;Basic Steps,&#34; you will need to manually trust the application on macOS. Follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open the terminal and navigate to the directory where the executable file (assuming the file name is &lt;code&gt;KrillinAI_1.0.0_macOS_arm64&lt;/code&gt;) is located.&lt;/li&gt; &#xA; &lt;li&gt;Execute the following commands in sequence:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo xattr -rd com.apple.quarantine ./KrillinAI_1.0.0_macOS_arm64&#xA;sudo chmod +x ./KrillinAI_1.0.0_macOS_arm64&#xA;./KrillinAI_1.0.0_macOS_arm64&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will start the service.&lt;/p&gt; &#xA;&lt;h3&gt;Docker Deployment&lt;/h3&gt; &#xA;&lt;p&gt;This project supports Docker deployment. Please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/docker.md&#34;&gt;Docker Deployment Instructions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Cookie Configuration Instructions&lt;/h3&gt; &#xA;&lt;p&gt;If you encounter video download failures, please refer to the &lt;a href=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/get_cookies.md&#34;&gt;Cookie Configuration Instructions&lt;/a&gt; to configure your cookie information.&lt;/p&gt; &#xA;&lt;h3&gt;Configuration Help&lt;/h3&gt; &#xA;&lt;p&gt;The quickest and most convenient configuration method:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Select &lt;code&gt;openai&lt;/code&gt; for both &lt;code&gt;transcription_provider&lt;/code&gt; and &lt;code&gt;llm_provider&lt;/code&gt;. In this way, you only need to fill in &lt;code&gt;openai.apikey&lt;/code&gt; in the following three major configuration item categories, namely &lt;code&gt;openai&lt;/code&gt;, &lt;code&gt;local_model&lt;/code&gt;, and &lt;code&gt;aliyun&lt;/code&gt;, and then you can conduct subtitle translation. (Fill in &lt;code&gt;app.proxy&lt;/code&gt;, &lt;code&gt;model&lt;/code&gt; and &lt;code&gt;openai.base_url&lt;/code&gt; as per your own situation.)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The configuration method for using the local speech recognition model (macOS is not supported for the time being) (a choice that takes into account cost, speed, and quality):&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fill in &lt;code&gt;fasterwhisper&lt;/code&gt; for &lt;code&gt;transcription_provider&lt;/code&gt; and &lt;code&gt;openai&lt;/code&gt; for &lt;code&gt;llm_provider&lt;/code&gt;. In this way, you only need to fill in &lt;code&gt;openai.apikey&lt;/code&gt; and &lt;code&gt;local_model.faster_whisper&lt;/code&gt; in the following three major configuration item categories, namely &lt;code&gt;openai&lt;/code&gt; and &lt;code&gt;local_model&lt;/code&gt;, and then you can conduct subtitle translation. The local model will be downloaded automatically. (The same applies to &lt;code&gt;app.proxy&lt;/code&gt; and &lt;code&gt;openai.base_url&lt;/code&gt; as mentioned above.)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following usage situations require the configuration of Alibaba Cloud:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If &lt;code&gt;llm_provider&lt;/code&gt; is filled with &lt;code&gt;aliyun&lt;/code&gt;, it indicates that the large model service of Alibaba Cloud will be used. Consequently, the configuration of the &lt;code&gt;aliyun.bailian&lt;/code&gt; item needs to be set up.&lt;/li&gt; &#xA; &lt;li&gt;If &lt;code&gt;transcription_provider&lt;/code&gt; is filled with &lt;code&gt;aliyun&lt;/code&gt;, or if the &#34;voice dubbing&#34; function is enabled when starting a task, the voice service of Alibaba Cloud will be utilized. Therefore, the configuration of the &lt;code&gt;aliyun.speech&lt;/code&gt; item needs to be filled in.&lt;/li&gt; &#xA; &lt;li&gt;If the &#34;voice dubbing&#34; function is enabled and local audio files are uploaded for voice timbre cloning at the same time, the OSS cloud storage service of Alibaba Cloud will also be used. Hence, the configuration of the &lt;code&gt;aliyun.oss&lt;/code&gt; item needs to be filled in. Configuration Guide: &lt;a href=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/aliyun.md&#34;&gt;Alibaba Cloud Configuration Instructions&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Frequently Asked Questions&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/faq.md&#34;&gt;Frequently Asked Questions&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contribution Guidelines&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Do not submit unnecessary files like &lt;code&gt;.vscode&lt;/code&gt;, &lt;code&gt;.idea&lt;/code&gt;, etc. Please make good use of &lt;code&gt;.gitignore&lt;/code&gt; to filter them.&lt;/li&gt; &#xA; &lt;li&gt;Do not submit &lt;code&gt;config.toml&lt;/code&gt;; instead, submit &lt;code&gt;config-example.toml&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#krillinai/KrillinAI&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=krillinai/KrillinAI&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>NVIDIA/cuda-python</title>
    <updated>2025-04-11T01:28:47Z</updated>
    <id>tag:github.com,2025-04-11:/NVIDIA/cuda-python</id>
    <link href="https://github.com/NVIDIA/cuda-python" rel="alternate"></link>
    <summary type="html">&lt;p&gt;CUDA Python: Performance meets Productivity&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;cuda-python&lt;/h1&gt; &#xA;&lt;p&gt;CUDA Python is the home for accessing NVIDIA’s CUDA platform from Python. It consists of multiple components:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nvidia.github.io/cuda-python/cuda-core/latest&#34;&gt;cuda.core&lt;/a&gt;: Pythonic access to CUDA Runtime and other core functionalities&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nvidia.github.io/cuda-python/cuda-bindings/latest&#34;&gt;cuda.bindings&lt;/a&gt;: Low-level Python bindings to CUDA C APIs&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nvidia.github.io/cccl/cuda_cooperative/&#34;&gt;cuda.cooperative&lt;/a&gt;: A Python package providing CCCL&#39;s reusable block-wide and warp-wide &lt;em&gt;device&lt;/em&gt; primitives for use within Numba CUDA kernels&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nvidia.github.io/cccl/cuda_parallel/&#34;&gt;cuda.parallel&lt;/a&gt;: A Python package for easy access to CCCL&#39;s highly efficient and customizable parallel algorithms, like &lt;code&gt;sort&lt;/code&gt;, &lt;code&gt;scan&lt;/code&gt;, &lt;code&gt;reduce&lt;/code&gt;, &lt;code&gt;transform&lt;/code&gt;, etc, that are callable on the &lt;em&gt;host&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nvidia.github.io/numba-cuda/&#34;&gt;numba.cuda&lt;/a&gt;: Numba&#39;s target for CUDA GPU programming by directly compiling a restricted subset of Python code into CUDA kernels and device functions following the CUDA execution model.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For access to NVIDIA CPU &amp;amp; GPU Math Libraries, please refer to &lt;a href=&#34;https://docs.nvidia.com/cuda/nvmath-python/latest&#34;&gt;nvmath-python&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;CUDA Python is currently undergoing an overhaul to improve existing and bring up new components. All of the previously available functionalities from the &lt;code&gt;cuda-python&lt;/code&gt; package will continue to be available, please refer to the &lt;a href=&#34;https://nvidia.github.io/cuda-python/cuda-bindings/latest&#34;&gt;cuda.bindings&lt;/a&gt; documentation for installation guide and further detail.&lt;/p&gt; &#xA;&lt;h2&gt;cuda-python as a metapackage&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;cuda-python&lt;/code&gt; is being re-structured to become a metapackage that contains a collection of subpackages. Each subpackage is versioned independently, allowing installation of each component as needed.&lt;/p&gt; &#xA;&lt;h3&gt;Subpackage: &lt;code&gt;cuda.core&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;cuda.core&lt;/code&gt; package offers idiomatic, pythonic access to CUDA Runtime and other functionalities.&lt;/p&gt; &#xA;&lt;p&gt;The goals are to&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Provide &lt;strong&gt;idiomatic (&#34;pythonic&#34;)&lt;/strong&gt; access to CUDA Driver, Runtime, and JIT compiler toolchain&lt;/li&gt; &#xA; &lt;li&gt;Focus on &lt;strong&gt;developer productivity&lt;/strong&gt; by ensuring end-to-end CUDA development can be performed quickly and entirely in Python&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Avoid homegrown&lt;/strong&gt; Python abstractions for CUDA for new Python GPU libraries starting from scratch&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Ease&lt;/strong&gt; developer &lt;strong&gt;burden of maintaining&lt;/strong&gt; and catching up with latest CUDA features&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Flatten the learning curve&lt;/strong&gt; for current and future generations of CUDA developers&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Subpackage: &lt;code&gt;cuda.bindings&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;code&gt;cuda.bindings&lt;/code&gt; package is a standard set of low-level interfaces, providing full coverage of and access to the CUDA host APIs from Python.&lt;/p&gt; &#xA;&lt;p&gt;The list of available interfaces are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;CUDA Driver&lt;/li&gt; &#xA; &lt;li&gt;CUDA Runtime&lt;/li&gt; &#xA; &lt;li&gt;NVRTC&lt;/li&gt; &#xA; &lt;li&gt;nvJitLink&lt;/li&gt; &#xA; &lt;li&gt;NVVM&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>