<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-15T01:24:41Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>netease-youdao/EmotiVoice</title>
    <updated>2023-11-15T01:24:41Z</updated>
    <id>tag:github.com,2023-11-15:/netease-youdao/EmotiVoice</id>
    <link href="https://github.com/netease-youdao/EmotiVoice" rel="alternate"></link>
    <summary type="html">&lt;p&gt;EmotiVoice üòä: a Multi-Voice and Prompt-Controlled TTS Engine&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;font size=&#34;4&#34;&gt; README: EN | &lt;a href=&#34;https://raw.githubusercontent.com/netease-youdao/EmotiVoice/main/README.zh.md&#34;&gt;‰∏≠Êñá&lt;/a&gt; &lt;/font&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;EmotiVoice üòä: a Multi-Voice and Prompt-Controlled TTS Engine&lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/netease-youdao/EmotiVoice/main/README.zh.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/README-‰∏≠ÊñáÁâàÊú¨-red&#34;&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &#xA; &lt;a href=&#34;https://raw.githubusercontent.com/netease-youdao/EmotiVoice/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache--2.0-yellow&#34;&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &#xA; &lt;a href=&#34;https://twitter.com/YDopensource&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/follow-%40YDOpenSource-1DA1F2?logo=twitter&amp;amp;style={style}&#34;&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;strong&gt;EmotiVoice&lt;/strong&gt; is a powerful and modern open-source text-to-speech engine. EmotiVoice speaks both English and Chinese, and with over 2000 different voices. The most prominent feature is &lt;strong&gt;emotional synthesis&lt;/strong&gt;, allowing you to create speech with a wide range of emotions, including happy, excited, sad, angry and others.&lt;/p&gt; &#xA;&lt;p&gt;An easy-to-use web interface is provided. There is also a scripting interface for batch generation of results.&lt;/p&gt; &#xA;&lt;p&gt;Here are a few samples that EmotiVoice generates:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/netease-youdao/EmotiVoice/assets/3909232/6426d7c1-d620-4bfc-ba03-cd7fc046a4fb&#34;&gt;Chinese audio sample&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/netease-youdao/EmotiVoice/assets/3909232/8f272eba-49db-493b-b479-2d9e5a419e26&#34;&gt;English audio sample&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/netease-youdao/EmotiVoice/assets/3909232/a0709012-c3ef-4182-bb0e-b7a2ba386f1c&#34;&gt;Chinese-accent English audio sample&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;h3&gt;EmotiVoice Docker image&lt;/h3&gt; &#xA;&lt;p&gt;The easiest way to try EmotiVoice is by running the docker image. You need a machine with a NVidia GPU. If you have not done so, set up NVidia container toolkit by following the instructions for &lt;a href=&#34;https://www.server-world.info/en/note?os=Ubuntu_22.04&amp;amp;p=nvidia&amp;amp;f=2&#34;&gt;Linux&lt;/a&gt; or &lt;a href=&#34;https://github.com/nyp-sit/it3103/raw/main/nvidia-docker-wsl2.md&#34;&gt;Windows WSL2&lt;/a&gt;. Then EmotiVoice can be run with,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run -dp 127.0.0.1:8501:8501 syq163/emoti-voice:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now open your browser and navigate to &lt;a href=&#34;http://localhost:8501&#34;&gt;http://localhost:8501&lt;/a&gt; to start using EmotiVoice&#39;s powerful TTS capabilities.&lt;/p&gt; &#xA;&lt;h3&gt;Full installation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;conda create -n EmotiVoice python=3.8 -y&#xA;conda activate EmotiVoice&#xA;pip install torch torchaudio&#xA;pip install numpy numba scipy transformers==4.26.1 soundfile yacs g2p_en jieba pypinyin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Prepare model files&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git lfs install&#xA;git lfs clone https://huggingface.co/WangZeJun/simbert-base-chinese WangZeJun/simbert-base-chinese&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or, you can run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mkdir -p WangZeJun/simbert-base-chinese&#xA;wget https://huggingface.co/WangZeJun/simbert-base-chinese/resolve/main/config.json -P WangZeJun/simbert-base-chinese&#xA;wget https://huggingface.co/WangZeJun/simbert-base-chinese/resolve/main/pytorch_model.bin -P WangZeJun/simbert-base-chinese&#xA;wget https://huggingface.co/WangZeJun/simbert-base-chinese/resolve/main/vocab.txt -P WangZeJun/simbert-base-chinese&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Inference&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;You have to download the &lt;a href=&#34;https://drive.google.com/drive/folders/1y6Xwj_GG9ulsAonca_unSGbJ4lxbNymM?usp=sharing&#34;&gt;pretrained models&lt;/a&gt;, and run:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mkdir -p outputs/style_encoder/ckpt&#xA;mkdir -p outputs/prompt_tts_open_source_joint/ckpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;And place &lt;code&gt;g_*&lt;/code&gt;, &lt;code&gt;do_*&lt;/code&gt; under &lt;code&gt;outputs/prompt_tts_open_source_joint/ckpt&lt;/code&gt; and put &lt;code&gt;checkpoint_*&lt;/code&gt; in &lt;code&gt;outputs/style_encoder/ckpt&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The inference text format is &lt;code&gt;&amp;lt;speaker&amp;gt;|&amp;lt;style_prompt/emotion_prompt/content&amp;gt;|&amp;lt;phoneme&amp;gt;|&amp;lt;content&amp;gt;&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;inference text example: &lt;code&gt;Maria_Kasper|Happy|&amp;lt;sos/eos&amp;gt; [IH0] [M] [AA1] [T] engsp4 [V] [OY1] [S] engsp4 [AH0] engsp1 [M] [AH1] [L] [T] [IY0] engsp4 [V] [OY1] [S] engsp1 [AE1] [N] [D] engsp1 [P] [R] [AA1] [M] [P] [T] engsp4 [K] [AH0] [N] [T] [R] [OW1] [L] [D] engsp1 [T] [IY1] engsp4 [T] [IY1] engsp4 [EH1] [S] engsp1 [EH1] [N] [JH] [AH0] [N] . &amp;lt;sos/eos&amp;gt;|Emoti-Voice - a Multi-Voice and Prompt-Controlled T-T-S Engine&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;You can get phonemes by &lt;code&gt;python frontend_en.py data/my_text.txt &amp;gt; data/my_text_for_tts.txt&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Then run:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;TEXT=data/inference/text&#xA;python inference_am_vocoder_joint.py \&#xA;--logdir prompt_tts_open_source_joint \&#xA;--config_folder config/joint \&#xA;--checkpoint g_00140000 \&#xA;--test_file $TEXT&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;the synthesized speech is under &lt;code&gt;outputs/prompt_tts_open_source_joint/test_audio&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Or if you just want to use the interactive TTS demo page, run:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install streamlit&#xA;streamlit run demo_page.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;To be released.&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap &amp;amp; Future work&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Our future plan can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/netease-youdao/EmotiVoice/main/ROADMAP.md&#34;&gt;ROADMAP&lt;/a&gt; file.&lt;/li&gt; &#xA; &lt;li&gt;The current implementation focuses on emotion/style control by prompts. It uses only pitch, speed, energy, and emotion as style factors, and does not use gender. But it is not complicated to change it to style/timbre control.&lt;/li&gt; &#xA; &lt;li&gt;Suggestions are welcome. You can file issues or &lt;a href=&#34;https://twitter.com/YDopensource&#34;&gt;@ydopensource&lt;/a&gt; on twitter.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;WeChat group&lt;/h2&gt; &#xA;&lt;p&gt;Welcome to scan the personal QR code below and join the WeChat group.&lt;/p&gt; &#xA;&lt;img src=&#34;https://github.com/netease-youdao/EmotiVoice/assets/3909232/94ee0824-0304-4487-8682-664fafd09cdf&#34; alt=&#34;qr&#34; width=&#34;150&#34;&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://speechresearch.github.io/prompttts/&#34;&gt;PromptTTS&lt;/a&gt;. The PromptTTS paper is a key basis of this project.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.openslr.org/60/&#34;&gt;LibriTTS&lt;/a&gt;. The LibriTTS dataset is used in training of EmotiVoice.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.openslr.org/109/&#34;&gt;HiFiTTS&lt;/a&gt;. The HiFi TTS dataset is used in training of EmotiVoice.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/espnet/espnet&#34;&gt;ESPnet&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/wenet-e2e/wetts&#34;&gt;WeTTS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jik876/hifi-gan&#34;&gt;HiFi-GAN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;Transformers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/keithito/tacotron&#34;&gt;tacotron&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/alibaba-damo-academy/KAN-TTS&#34;&gt;KAN-TTS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yl4579/StyleTTS&#34;&gt;StyleTTS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ZhuiyiTechnology/simbert&#34;&gt;Simbert&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;EmotiVoice is provided under the Apache-2.0 License - see the &lt;a href=&#34;https://raw.githubusercontent.com/netease-youdao/EmotiVoice/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; &#xA;&lt;p&gt;The interactive page is provided under the &lt;a href=&#34;https://raw.githubusercontent.com/netease-youdao/EmotiVoice/main/EmotiVoice_UserAgreement_%E6%98%93%E9%AD%94%E5%A3%B0%E7%94%A8%E6%88%B7%E5%8D%8F%E8%AE%AE.pdf&#34;&gt;User Agreement&lt;/a&gt; file.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>disler/multi-agent-postgres-data-analytics</title>
    <updated>2023-11-15T01:24:41Z</updated>
    <id>tag:github.com,2023-11-15:/disler/multi-agent-postgres-data-analytics</id>
    <link href="https://github.com/disler/multi-agent-postgres-data-analytics" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The way we interact with our data is changing.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Multi-Agent Postgres Data Analytics&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;The way we interact with our data is changing.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/multi-agent-coding.png&#34; alt=&#34;Multi-Agent Postgres Data Analytics&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üí¨ Read This First üí¨&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;This repo is an &lt;strong&gt;&lt;em&gt;experiment&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;learning tool&lt;/em&gt;&lt;/strong&gt; for building multi-agent systems.&lt;/p&gt; &#xA; &lt;p&gt;It is &lt;strong&gt;ONE&lt;/strong&gt; of &lt;strong&gt;MANY&lt;/strong&gt; steps toward building fully autonomous, &lt;em&gt;agentic software&lt;/em&gt;.&lt;/p&gt; &#xA; &lt;p&gt;It is &lt;strong&gt;NOT&lt;/strong&gt; a framework, or library, or shortcut.&lt;/p&gt; &#xA; &lt;p&gt;It &lt;strong&gt;IS&lt;/strong&gt; a &lt;strong&gt;&lt;em&gt;stepping stone&lt;/em&gt;&lt;/strong&gt; to help you internalize concepts, patterns and building blocks for your own multi-agent systems and applications.&lt;/p&gt; &#xA; &lt;p&gt;Code only tells a story at a moment in time. I highly recommend you watch the &lt;a href=&#34;https://www.youtube.com/playlist?list=PLS_o2ayVCKvDzj2YxeFqMq9UbR1PkPEh0&#34;&gt;video series&lt;/a&gt; to see the &lt;strong&gt;how and the why&lt;/strong&gt; behind the structure of this experimental codebase.&lt;/p&gt; &#xA; &lt;p&gt;In the series we build this from scratch and dive deep into complexities, principles, patterns and ideas surrounding multi-agent software. The video order is linked below, mapping branches to videos.&lt;/p&gt; &#xA; &lt;p&gt;This repo will not be maintained or updated beyond the lifespan of the series. It is a snapshot in time of the code we built in the video series and is meant only to be a reference for you on your journey to building your own multi-agent systems, &lt;strong&gt;&lt;em&gt;nothing more&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA; &lt;p&gt;When we complete the series will we freeze the codebase. We will then use it as a reference for experiments, products, and videos.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;üíª Multi-Agent Postgres Data Analytics Tool üíª&lt;/h2&gt; &#xA;&lt;p&gt;This is a multi-agent system that allows you to ask questions about your postgres database in natural language.&lt;/p&gt; &#xA;&lt;p&gt;The codebase is powered by GPT-4, Assistance API, AutoGen, Postgres, and Guidance.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s the first of many multi-agent applications that utilize LLMs (large language models) to enable reasoning and decision making with reduced need for explicit rules or logic.&lt;/p&gt; &#xA;&lt;h2&gt;üíª Setup üíª&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Read the codebase first&lt;/strong&gt;. Remember, this is an experiment and learning tool. It&#39;s not meant to be a framework or library.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;git branch -a&lt;/code&gt; to view all branches. Each branch is a video in the series. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;git checkout &amp;lt;branch-name&amp;gt;&lt;/code&gt; you want to view.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;poetry install&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;cp .env.sample .env&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Fill out &lt;code&gt;.env&lt;/code&gt; with your postgres url and openai api key&lt;/li&gt; &#xA; &lt;li&gt;Run a prompt against your database &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;poetry run start --prompt &#34;&amp;lt;ask your agent a question about your postgres database&amp;gt;&#34;&lt;/code&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Start with something simple to get a feel for it and then build up to more complex questions.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üõ†Ô∏è Core Tech Stack üõ†Ô∏è&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openai.com/&#34;&gt;OpenAI&lt;/a&gt; - GPT-4, GPT-4 Turbo, Assistance API&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://microsoft.github.io/autogen/&#34;&gt;AutoGen&lt;/a&gt; - Multi-Agent Framework&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.postgresql.org/&#34;&gt;Postgres&lt;/a&gt; - Database&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/guidance-ai/guidance&#34;&gt;Guidance&lt;/a&gt; - Structured LLM Responses&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aider.chat/&#34;&gt;Aider&lt;/a&gt; - AI Pair Programming&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://python-poetry.org/&#34;&gt;Poetry&lt;/a&gt; - Package Manager&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.python.org/downloads/release/python-3100/&#34;&gt;Python ^3.10&lt;/a&gt; - Programming Language&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üîµ Multi-Agent Patterns &amp;amp; Terminology üîµ&lt;/h2&gt; &#xA;&lt;p&gt;Throughout the codebase we built up several existing and new patterns and terminology you&#39;ve likely seen in some shape or form. Here&#39;s a quick overview of the most important ones.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Agent&lt;/strong&gt; - An agent is LLM powered tool with a single purpose that can be assigned a function and/or prompt.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi-Agent Team&lt;/strong&gt; - A collection of agents that exchange messages and work together to accomplish a goal.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Conversations&lt;/strong&gt; - The exchange of messages between a multi-agent team.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Conversation Flows&lt;/strong&gt; - The way agents communicate with each other. How you&#39;re agents communicate completely changes the way your application works. The conversation flow dictates which agent speaks, the order in which they speak, who they speak to and what they say.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Orchestrator&lt;/strong&gt; - Manages a single agent team, their conversations and their output. Orchestrators contain different types of conversation flows.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Instruments&lt;/strong&gt; - Instruments are the tools agents can use. Think of it like a front-end store. It contains state and functions that both agents and orchestrators can utilize throughout the lifecycle of the application. Agents and Orchestrators can consume and manipulate the state of instruments although typically, only agents update state.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Decision Agents&lt;/strong&gt; - Agents that respond with concrete decisions which can dictate the flow of your applications. To build complex agentic systems you need agents to have the ability to make concrete decisions that then drive the flow of your application.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Structured vs Unstructured Agents&lt;/strong&gt; - Structured agents are agents that respond with structured data. Unstructured agents are agents that respond with unstructured data. Structured agents are typically decision agents.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üì∫ Video Series - Learn By Watching üì∫&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://youtu.be/jmDMusirPKA&#34;&gt;Part 1 - Prompt Engineering an ENTIRE codebase: Postgres Data Analytics Al Agent&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Branch: &lt;a href=&#34;https://github.com/disler/multi-agent-postgres-data-analytics/tree/v1-prompt-engineering-an-entire-codebase&#34;&gt;v1-prompt-engineering-an-entire-codebase&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Video: &lt;a href=&#34;https://youtu.be/jmDMusirPKA&#34;&gt;https://youtu.be/jmDMusirPKA&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/1-prompt-engineering-postgres-ai-data-analytics-agent.png&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://youtu.be/JjVvYDPVrAQ&#34;&gt;Part 2 - One Prompt is NOT enough: Using AutoGen to code a Multi-Agent Postgres AI Tool&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Branch: &lt;a href=&#34;https://github.com/disler/multi-agent-postgres-data-analytics/tree/v2-using-autogen-to-build-our-multi-agent-tool&#34;&gt;v2-using-autogen-to-build-our-multi-agent-tool&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Video: &lt;a href=&#34;https://youtu.be/JjVvYDPVrAQ&#34;&gt;https://youtu.be/JjVvYDPVrAQ&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/2-using-autogen-to-build-our-multi-agent-postgres-data-analytics-tool.png&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://youtu.be/4o8tymMQ5GM&#34;&gt;Part 3 - Make AutoGen Consistent: CONTROL your LLM agents for ACCURATE Postgres Al Data Analytics&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Branch: &lt;a href=&#34;https://github.com/disler/multi-agent-postgres-data-analytics/tree/v3-make-autogen-consistent-control-your-llm&#34;&gt;v3-make-autogen-consistent-control-your-llm&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Video: &lt;a href=&#34;https://youtu.be/4o8tymMQ5GM&#34;&gt;https://youtu.be/4o8tymMQ5GM&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/3-make-autogen-consistent-to-build-our-multi-agent-postgres-data-analytics-tool.png&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://youtu.be/CKo-czvxFkY&#34;&gt;Part 4 - AutoGen Token Tactics: FIRING AI Agents, USELESS Vector Embeddings, GPT-4 Memory Tricks&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Branch: &lt;a href=&#34;https://github.com/disler/multi-agent-postgres-data-analytics/tree/v4-autogen-token-tactics-firing-ai-agents&#34;&gt;v4-autogen-token-tactics-firing-ai-agents&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Video: &lt;a href=&#34;https://youtu.be/CKo-czvxFkY&#34;&gt;https://youtu.be/CKo-czvxFkY&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/4-autogen-token-tactics-managing-llm-memory-and-costs-multi-agent-postgres-ai-data-analytics.png&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://youtu.be/UA6IVMDPuC8&#34;&gt;Part 5 - AutoGen SPYWARE: Coding Systems for SUCCESSFUL AI Agents (Postgres Data Analytics)&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Branch: &lt;a href=&#34;https://github.com/disler/multi-agent-postgres-data-analytics/tree/v5-autogen-spyware-coding-systems-for-successful-ai&#34;&gt;v5-autogen-spyware-coding-systems-for-successful-ai&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Video: &lt;a href=&#34;https://youtu.be/UA6IVMDPuC8&#34;&gt;https://youtu.be/UA6IVMDPuC8&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/5-autogen-spyware-for-ai-agents-postgres-data-analytics-tool-ai.png&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://youtu.be/XGCWyfA3rgQ&#34;&gt;Part 6 - Using AUTOGEN &amp;amp; GUIDANCE to code LLM Control Flow &amp;amp; JSON Agents (No Prompt Engineering)&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Branch: &lt;a href=&#34;https://github.com/disler/multi-agent-postgres-data-analytics/tree/v6-control-flow-and-structured-response&#34;&gt;v6-control-flow-and-structured-response&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Video: &lt;a href=&#34;https://youtu.be/XGCWyfA3rgQ&#34;&gt;https://youtu.be/XGCWyfA3rgQ&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/6-autogen-and-guidance-for-autonomous-control-flow.png&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://youtu.be/KwcrjP3vuy0&#34;&gt;Part 7 - OpenAI Macro &amp;amp; Micro Strategy: Master Assistants API, Threads, Messages, and Runs&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Branch: &lt;a href=&#34;https://github.com/disler/multi-agent-postgres-data-analytics/tree/v7-turbo4-assistants-threads-messages&#34;&gt;v7-turbo4-assistants-threads-messages&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Video: &lt;a href=&#34;https://youtu.be/KwcrjP3vuy0&#34;&gt;https://youtu.be/KwcrjP3vuy0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/imgs/7-turbo4-assistants-threads-messages.png&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/#&#34;&gt;Part 8 - UNRELEASED&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/#&#34;&gt;Part 9 - UNRELEASED&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/disler/multi-agent-postgres-data-analytics/main/#&#34;&gt;Part 10 - UNRELEASED&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;üß† Major Learnings Throughout the Series üß†&lt;/h1&gt; &#xA;&lt;h2&gt;üí° Why are multi-agent applications important?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;They&#39;re important because they allows us to create a more accurate model of the world.&lt;/li&gt; &#xA; &lt;li&gt;We become orchestrators enabling less engineering level and more product level work.&lt;/li&gt; &#xA; &lt;li&gt;They enable reasoning and decision making in a way that is more human like than ever before.&lt;/li&gt; &#xA; &lt;li&gt;We can build systems that make decisions as we would while operating alongside us.&lt;/li&gt; &#xA; &lt;li&gt;We can solve problems that previously required a dedicated hire or an entire team to solve.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;‚úÖ Multi-Agent Systems: The Good&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Can assign functions &amp;amp; prompts to specific agents, enabling specialization yielding better results.&lt;/li&gt; &#xA; &lt;li&gt;Agents can reflect on results to provide feedback thus improving the results.&lt;/li&gt; &#xA; &lt;li&gt;Can role play real organizational structures, existing and new.&lt;/li&gt; &#xA; &lt;li&gt;Ecosystem is evolving rapidly. New tools and frameworks are being built every day.&lt;/li&gt; &#xA; &lt;li&gt;Upside potential is ridiculously massive. We&#39;re talking asymmetric ROI, max &lt;a href=&#34;https://www.navalmanack.com/almanack-of-naval-ravikant/find-a-position-of-leverage&#34;&gt;leverage&lt;/a&gt;, &lt;a href=&#34;http://www.paulgraham.com/superlinear.html&#34;&gt;superlinear&lt;/a&gt; upside. The more agentic build blocks you have the more powerful your engineering and product potential becomes.&lt;/li&gt; &#xA; &lt;li&gt;Multi-agent engineering is probably the most important thing happening in software right now (2023-2024).&lt;/li&gt; &#xA; &lt;li&gt;The road to agentic software is clear. Solve small problems, create reusable building blocks, and then combine them to solve bigger problems.&lt;/li&gt; &#xA; &lt;li&gt;GPT-4 can support multi-agent systems without a doubt. It is the best model by light-years and drives incredible reasoning readily available at your fingertips.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;‚ùå Multi-Agent Systems: The Bad&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;It&#39;s an art to get the roles and the function of your agent right. How many do you need? What are they? How do you know?&lt;/li&gt; &#xA; &lt;li&gt;Can get expensive in testing and scales with # of agents. The more agents the more expensive each query is.&lt;/li&gt; &#xA; &lt;li&gt;Can be difficult to debug why a multi-agent system is not working as expected due to the non-deterministic nature of LLMs.&lt;/li&gt; &#xA; &lt;li&gt;Memory management is a major issue. The context window is forcing a lot of weird, intricate code to manage memory.&lt;/li&gt; &#xA; &lt;li&gt;Too much noise and hype in the AI Agent ecosystem. Lot&#39;s of clickbait hype with little follow through value. Hard to find good resources.&lt;/li&gt; &#xA; &lt;li&gt;Very few are engineers are publicly building multi-agent systems. Most are toy examples or ripping from example codebases.&lt;/li&gt; &#xA; &lt;li&gt;OpenAI is inadvertently killing startups with every new release. Risky to commit to building LLM powered applications.&lt;/li&gt; &#xA; &lt;li&gt;At the current price, we cannot run a fully agentic system that runs 24/7 or even for an hour on GPT-4 without burning thousands per day. The price must come down WITHOUT sacrificing quality (looking at you open source models).&lt;/li&gt; &#xA; &lt;li&gt;It&#39;s tricky to know when to write explicit code vs prompt engineer vs build a multi-agent team. This is a new skill that will take time to master.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üß† 2024 Multi-agent / LLM / Agentic Predictions üß†&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;stay tuned for predictions&lt;/p&gt; &#xA;&lt;/blockquote&gt;</summary>
  </entry>
  <entry>
    <title>atomicals/atomicals-js</title>
    <updated>2023-11-15T01:24:41Z</updated>
    <id>tag:github.com,2023-11-15:/atomicals/atomicals-js</id>
    <link href="https://github.com/atomicals/atomicals-js" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Atomicals CLI and Javascript Library&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Atomicals Javascript Library&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;atomicals.xyz Documentation: &lt;a href=&#34;https://docs.atomicals.xyz&#34;&gt;https://docs.atomicals.xyz&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/atomicals/atomicals-js/master/banner.png&#34; alt=&#34;Atomicals&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Install, Build and Run Tests&lt;/h3&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;Download the github repo and then run:&#xA;&#xA;npm install&#xA;npm run build&#xA;&#xA;See all commands at:&#xA;&#xA;npm run cli --help&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Quick Start - Command Line (CLI)&lt;/h3&gt; &#xA;&lt;p&gt;First install packages and build, then follow the steps here to create your first Atomical and query the status. Use &lt;code&gt;yarn cli&lt;/code&gt;to get a list of all commands available.&lt;/p&gt; &#xA;&lt;h4&gt;0. Environment File (.env)&lt;/h4&gt; &#xA;&lt;p&gt;The environment file comes with defaults (&lt;code&gt;.env.example&lt;/code&gt;), but it is highly recommend to install and operate your own ElectrumX server. Web browser communication is possible through the &lt;code&gt;wss&lt;/code&gt; (secure websockets) interface of ElectrumX.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ELECTRUMX_WSS=wss://electrumx.atomicals.xyz:50012&#xA;&#xA;// Optional (defaults to wallet.json)&#xA;WALLET_PATH=path-to-wallet.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;ELECTRUMX_WSS&lt;/em&gt;: URL of the ElectrumX with Atomicals support. Note that only &lt;code&gt;wss&lt;/code&gt; endpoints are accessible from web browsers.&lt;/p&gt; &#xA;&lt;h4&gt;1. Wallet Setup&lt;/h4&gt; &#xA;&lt;p&gt;The purpose of the wallet is to create p2tr (pay-to-taproot) spend scripts and to receive change from the transactions made for the various operations. &lt;em&gt;Do not put more funds than you can afford to lose, as this is still beta!&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;To initialize a new &lt;code&gt;wallet.json&lt;/code&gt; file that will store your address for receiving change use the &lt;code&gt;wallet-init&lt;/code&gt; command. Alternatively, you may populate the &lt;code&gt;wallet.json&lt;/code&gt; manually, ensuring that the address at &lt;code&gt;m/44&#39;/0&#39;/0&#39;/0/0&lt;/code&gt; is equal to the address and the derivePath is set correctly.&lt;/p&gt; &#xA;&lt;p&gt;Configure the path in the environment &lt;code&gt;.env&lt;/code&gt; file to point to your wallet file. defaults to &lt;code&gt;./wallet.json&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Default:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;WALLET_PATH=.&#xA;WALLET_FILE=wallet.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Update to &lt;code&gt;wallets/&lt;/code&gt; directory:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;WALLET_PATH=./wallets&#xA;WALLET_FILE=wallet.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create the wallet:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;yarn cli wallet-init&#xA;&#xA;&amp;gt;&amp;gt;&amp;gt;&#xA;&#xA;Wallet created at wallet.json&#xA;phrase: maple maple maple maple maple maple maple maple maple maple maple maple&#xA;Legacy address (for change): 1FXL2CJ9nAC...u3e9Evdsa2pKrPhkag&#xA;Derive Path: m/44&#39;/0&#39;/0&#39;/0/0&#xA;WIF: L5Sa65gNR6QsBjqK.....r6o4YzcqNRnJ1p4a6GPxqQQ&#xA;------------------------------------------------------&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2. Explore the CLI&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;yarn cli --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;3. Quick Commands&lt;/h4&gt; &#xA;&lt;p&gt;Get all of the commands available:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm run cli --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Read the documentation at &lt;a href=&#34;https://docs.atomicals.xyz&#34;&gt;https://docs.atomicals.xyz&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ElectrumX Server RPC Interface&lt;/h2&gt; &#xA;&lt;p&gt;See updated ElectrumX (&lt;a href=&#34;https://github.com/atomicals/electrumx-atomicals&#34;&gt;https://github.com/atomicals/electrumx-atomicals&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Any questions or ideas?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://atomicals.xyz&#34;&gt;https://atomicals.xyz&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://x.com/atomicalsxyz&#34;&gt;https://x.com/atomicalsxyz&lt;/a&gt; (X - Formerly Twitter)&lt;/p&gt; &#xA;&lt;h2&gt;Donate to Atomicals Development&lt;/h2&gt; &#xA;&lt;p&gt;We greatly appreciate any donation to help support Atomicals Protocol development. We worked out of passion and kindness for the world, we believe this technology must exist and be free for all to use. Bitcoin is our one hope for freedom and digital sovereignty and we intend to do our best to make it a reality.&lt;/p&gt; &#xA;&lt;p&gt;BTC: bc1pljy9g0ugrgumpd5y6v9tv23rvz5y8dhaq980r9qfgyhd4dmgkwmqpdpr5q&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/atomicals/atomicals-js/master/donate.png&#34; alt=&#34;Donate to Atomicals Development&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>