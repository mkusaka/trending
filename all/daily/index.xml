<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-27T01:24:08Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Enraged-Rabbit-Community/ERCF_v2</title>
    <updated>2023-12-27T01:24:08Z</updated>
    <id>tag:github.com,2023-12-27:/Enraged-Rabbit-Community/ERCF_v2</id>
    <link href="https://github.com/Enraged-Rabbit-Community/ERCF_v2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Community designed ERCF v2&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Enraged Rabbit Community Project&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Full_CAD.jpg&#34; alt=&#34;ERCFv2&#34; width=&#34;70%&#34;&gt; &lt;/p&gt;&#xA;&lt;h1 align=&#34;center&#34;&gt;ERCF v2 - RC1&lt;/h1&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; An expandable MMU for Klipper based 3D-Printers &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a aria-label=&#34;Downloads&#34; href=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/release/Enraged-Rabbit-Community/ERCF_v2?display_name=tag&amp;amp;style=flat-square&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a aria-label=&#34;Stars&#34; href=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/Enraged-Rabbit-Community/ERCF_v2?style=flat-square&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a aria-label=&#34;Forks&#34; href=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/Enraged-Rabbit-Community/ERCF_v2?style=flat-square&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a aria-label=&#34;License&#34; href=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/Enraged-Rabbit-Community/ERCF_v2?style=flat-square&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Enraged_Rabbit_v2.png&#34; alt=&#34;RabbitV2&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt; This is a community born project and major update to the Voron ERCF MMU that was started a couple of years ago by Ette. It is endorsed by Ette and the guiding philosophy wasn&#39;t to start again with a new MMU design but to refine what has already proven to be a very capable machine and push it to be the best it can be by simplifying problematic construction, improving reliability and aligning as close as possible to v1.1 BOM. However the project includes an all new optional integrated filament buffer system (ERCT), filament cutter option (ERF), a collection of recommended toolhead sensor modifications and a bit of Bling! It fully leverages the Happy Hare firmware MMU control software with Klipper Screen entensions. &lt;p&gt; &lt;/p&gt;&lt;p&gt;There are a rapidly growing list of MMUs in the market place from the mass produced &#34;Fords&#34; who pioneered the market to the &#34;Toyota&#34; that are more recent efficient engineering feat but somehow lack soul. We consider ERCFv2 the &#34;BMW&#34; - a little over engineered perhaps but distinctively cool and you feel good driving it. We hope you enjoy! &amp;nbsp;&amp;nbsp; Videos: &lt;a href=&#34;https://www.youtube.com/watch?v=U2QwvPacIUk&#34;&gt;Teaser&lt;/a&gt; &amp;nbsp; &lt;a href=&#34;https://www.youtube.com/watch?v=EJCPerBsM3Q&#34;&gt;Release&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Table of Content&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#enraged-rabbit-carrot-feeder-ercf&#34;&gt;ERCF&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#enraged-rabbit-cotton-tail-erct&#34;&gt;ERCT&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#enraged-rabbit-filametrix-erf&#34;&gt;ERF&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#toolhead-sensor-modifications&#34;&gt;Toolhead Sensor Modifications&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#firmware&#34;&gt;Firmware&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#documentation&#34;&gt;Documentation&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#bom&#34;&gt;BOM&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#cad&#34;&gt;CAD&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#faq&#34;&gt;FAQ&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#acknowledgements&#34;&gt;Acknowledgements&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#vendors&#34;&gt;Vendors&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#changelog&#34;&gt;Changelog&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#build-photos&#34;&gt;Build Photos&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#user-print-showroom&#34;&gt;Showroom&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;!--&#xA;**[FAQ](Assets/FAQ.md)&#xA;--&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Enraged Rabbit Carrot Feeder (ERCF)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;45%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/ERCFv2.png&#34;&gt;An MMU or Multimaterial Unit/Upgrade allows for the automatic change of filaments on your 3D printer. You can use it to create beautiful multi-colored prints or, if you&#39;re lazy, simply to avoid loading filament by hand. If you are familar with ERCF v1.1 this will serve as an overview of updates:&lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ol&gt; &#xA;     &lt;li&gt;Sturdy backbone - no more flex &lt;/li&gt;&#xA;     &lt;li&gt;Reliable (and custom) encoder design &lt;/li&gt;&#xA;     &lt;li&gt;Sprung servo instead of adjustable top hats &lt;/li&gt;&#xA;     &lt;li&gt;Innovative Filament trap in blocks instead of magnetic gates &lt;/li&gt;&#xA;     &lt;li&gt;Formal filament bypass &lt;/li&gt;&#xA;     &lt;li&gt;Reinforced gearbox assembly &lt;/li&gt;&#xA;     &lt;li&gt;Beautifully illustrated Manual &lt;/li&gt;&#xA;     &lt;li&gt;High Quality Step-by-step CAD &lt;/li&gt;&#xA;     &lt;li&gt;New integrated passive buffer system (Cotton Tail) &lt;/li&gt;&#xA;     &lt;li&gt;Perfect tips with Filametrix Filament cutter &lt;/li&gt;&#xA;     &lt;li&gt;Functional and asthetic LED status indication &lt;/li&gt;&#xA;    &lt;/ol&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Optional Enraged Rabbit Components&lt;/h2&gt; &#xA;&lt;h3&gt;Enraged Rabbit Cotton Tail (ERCT)&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Recommended_Options/ERCT_Buffer/Assets/heroimage_ERCT.png&#34; alt=&#34;ERCT&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt; When an MMU changes tool, the unloaded filament needs to be thoughtfully managed so that it doesn&#39;t tangle. The Enraged Rabbit Cotton Tail (ERCT) buffer system is designed to attach directly to ERCF V2. It is a passive system that optimizes space and is also designed to reduce resistance in the filament path, creating a consistent system for calibration. &lt;p&gt; &lt;/p&gt;&lt;p&gt;ERCT includes a pregate filament sensor to more reliably manage endless spools. It also incorporates a NEOpixel on each gate that, when driven by the Happy Hare firmware, provides functional feedback and the necessary &#34;bling!&#34; Enjoy!&lt;/p&gt; &lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Recommended_Options/ERCT_Buffer/README.md&#34;&gt;Read more&lt;/a&gt; &amp;nbsp;&amp;nbsp; Videos: &lt;a href=&#34;https://youtu.be/9jzB5Un6HKo&#34;&gt;Rear Loading&lt;/a&gt; &lt;a href=&#34;https://youtu.be/GlSXtUkd-b8&#34;&gt;Front Loading&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Enraged Rabbit Filametrix (ERF)&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; Before the MMU can unload a filament it must prepare the tip so that it can be cleanly loaded next time. This tip forming process is very difficult to tune and varies based on material type, temperature, hotend type and even weather! Introducing Enraged Rabbit Filametrix (ERF) filament cutting system. This lightweight addition to your Stealthburner toolhead adds a cutting blade. When retracting the problematic tip of the filament is simply cut off for perfect tips and no jams. &lt;p&gt; &lt;/p&gt;&lt;p&gt;ERF also supports an optional servo operated ganrtry activation pin so no print area is lost with this addition. ERF designs also include the recommended integrated toolhead sensor&lt;/p&gt; &lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Recommended_Options/ERF_Filament_Cutter/README.md&#34;&gt;Read more&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Recommended_Options/ERF_Filament_Cutter/Assets/ERF.png&#34; alt=&#34;ERF&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Toolhead Sensor Modifications&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; ERCF can be operated without a toolhead sensor (filament detection) in the toolhead but it is **not recommended**. A toolhead sensor provides an accurate homing point very close to the nozzle but also adds reliability to the tool change process. ERCF includes a set of toolhead sensor modifications for popular extruders. These work reliably through coupling a microswitch to the filament path. &lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Recommended_Options/Toolhead_Modifications/README.md&#34;&gt;Read more&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Purge System (ERPS)&lt;/h3&gt; &#xA;&lt;p&gt;Pellet purge system to remove the need for the wipe tower. Stay tuned.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Firmware&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34;&gt;&lt;img src=&#34;https://github.com/moggieuk/KlipperScreen-Happy-Hare-Edition/raw/master/docs/img/mmu/mmu_main.png&#34; alt=&#34;KlipperScreen&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt; ERCF is designed to be used with the Happy Hare MMU firmware for Klipper which adds a set of klipper extensions for configuration setup, testing and operation of ERCF. These commands are available through the command line or macros but are perhaps best operated with an interactive UI with the optional KlipperScreen extension. &lt;p&gt; &lt;/p&gt;&lt;p&gt;Happy Hare provides an easy installation script which has knowledge of recommended settings and will greatly accelarate the setup process.&lt;/p&gt; &lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/moggieuk/Happy-Hare/doc/ercf_v2.md&#34;&gt;Happy Hare&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://github.com/moggieuk/KlipperScreen-Happy-Hare-Edition&#34;&gt;KlipperScreen&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; Building something as complex as an MMU is a challenging undertaking but ERCFv2 project contains an amazingly detailed and illustrated manual with step-by-step instructions. We have tried to make the process similar to fitting together a jigsaw puzzle, albeit with a few optional pieces. &lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Documentation/ERCF_v2_Manual.pdf&#34;&gt;ERCFv2 PDF Manual&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Manual_Page.png&#34; alt=&#34;ERCF Manual&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;BOM&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/BOM.png&#34; alt=&#34;ERCF Project BOM&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt; You can find a Bill of Materials and a convenient printed parts tracker for the project and options here. Note that the BOM also contains an upgrade list for those of you wanting to use your existing ERCF v1.1 kits. Please make a copy and edit the &#34;Filament Blocks #&#34; to be the number of gates for your build. This can be any number but we encourage kit vendors to use 4/8/12 as size variations. Note that there are separate columns for core ERCF, the optional ERCT and ERF options as well as the suggested &#34;extras&#34; &lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://docs.google.com/spreadsheets/d/1HtVIu4yqzS6xJQr63-JKtMAh4Xq7wbtWPFeuiCnrnnE&#34;&gt;BOM&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1h1bJurR6Z8Ou36c5U9cWmqI86tXKlWrcZrWrHgGN13A&#34;&gt;Printed Parts Tracker&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;CAD&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; A lot of work has gone into creating a quality CAD model of the project carefully organized into folders that match the documentation! It is hightly recommended that you open the CAD and hide every folder and then expose them one at a time as you work through the build. &lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/CAD&#34;&gt;Master CAD&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/CAD.png&#34; alt=&#34;ERCF Master CAD&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;p&gt;ERCF v2 is currently in the RC1 phase. That means that we hope the BOM and parts are complete but there are still some areas of polish needed: documentation, kit availability, etc. Therefore we&#39;re sure there will be lots of questions. To avoid repetition on the various support channels you can find a list of &lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/FAQ.md&#34;&gt;frequently asked questions&lt;/a&gt; here. If something isn&#39;t answered the best place to go is the primary &lt;a href=&#34;https://discord.com/channels/460117602945990666/909743915475816458&#34;&gt;Voron #ercf_questions&lt;/a&gt; Discord server&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;Most importantly let me introduce the development, test and doc team. A project like this doesn&#39;t happen without many hundreds of hours of volunteer effort and all of these folks are truely awesome. Please give some &lt;span&gt;ğŸ‘&lt;/span&gt; &lt;span&gt;ğŸ‘&lt;/span&gt; &lt;span&gt;ğŸ‘&lt;/span&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;@moggieuk V0.1503 | V2.4088 (Mr Happy Hare &amp;amp; Chief whip) &lt;/li&gt;&#xA; &lt;li&gt;@gneu V2.5345 (Filament block &amp;amp; bling innovator) &lt;/li&gt;&#xA; &lt;li&gt;@sneakytreesnake V2.3804 (The project backbone!) &lt;/li&gt;&#xA; &lt;li&gt;@mneuhaus VT.483 (Mr Binky) &lt;/li&gt;&#xA; &lt;li&gt;@Miriax (Designer &amp;amp; Doc Demon) &lt;/li&gt;&#xA; &lt;li&gt;@kinematicdigit (Mr Cotton Tail &amp;amp; Doc Illustrator) &lt;/li&gt;&#xA; &lt;li&gt;@ningpj (Tester, Breaker &amp;amp; Documenter) &lt;/li&gt;&#xA; &lt;li&gt;@fizzy (King of CAD) &lt;/li&gt;&#xA; &lt;li&gt;@gsx8299 (Test Builder Extraordinaire) &lt;/li&gt;&#xA; &lt;li&gt;@sorted (Filametix &#34;don&#39;t get enraged&#34; filament cutting system) &lt;/li&gt;&#xA; &lt;li&gt;@kierantheman (Mr ThumperBlocks) &lt;/li&gt;&#xA; &lt;li&gt;@Fragmon (Videographer) &lt;/li&gt;&#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Vendors&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;25%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Certified.jpg&#34; alt=&#34;Vendor Certification&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt; These kits and specialty parts have been checked by us and meet good quality standards: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;On the way... stay tuned! &lt;/li&gt; &#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Manufacturers:&lt;/strong&gt; &lt;em&gt;If you want to be included, please contact us. We are happy to validate your kit/parts and then add you to the list...&lt;/em&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Changelog&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;v2.0 rc1 - Initial Release (Merry Christmas!) &lt;/li&gt;&#xA;&lt;/ul&gt; &#xA;&lt;p&gt;CAD Design Guidelines used in this project (in case you were interested) can be found: &lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Dev_Notes.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;i&gt; There once was a printer so keen,&lt;br&gt; To print in red, yellow, and green.&lt;br&gt; It whirred and it spun,&lt;br&gt; Mixing colors for fun,&lt;br&gt; The most vibrant prints ever seen! &lt;/i&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Build Photos&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/3d18d3fe-b8f0-4750-8b06-f487ab54ef35&#34; alt=&#34;20231116_230501&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/971ceefa-8946-438d-9de7-a26cfcdae56b&#34; alt=&#34;20231116_211032&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/5781d748-67eb-44f2-a793-cf8f4229b99f&#34; alt=&#34;20231116_214903&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/5df5f56e-9424-42d0-9985-a84c04d67c12&#34; alt=&#34;20231116_211045&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/ed578c32-6d4d-4698-8aeb-008a0cdf959e&#34; alt=&#34;20231116_230638&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/fde29ef8-6356-4a68-bd17-26fd160b5c9f&#34; alt=&#34;IMG_2446&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/bb66a3e3-326e-4866-97da-3e80767f3dc7&#34; alt=&#34;IMG_2448&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/1b943168-492d-44d6-ad12-038a6f12a8ca&#34; alt=&#34;IMG_2445&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/147fb32d-f3e4-4365-b579-de3997274053&#34; alt=&#34;IMG_2443&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/6d84f624-84b9-4a88-ad7c-de2a09619397&#34; alt=&#34;IMG_2444&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/52122c6a-e28c-4bd7-a8a8-324b2cc9a74f&#34; alt=&#34;IMG_2447&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;User Print Showroom&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Showroom/Spidermans.png&#34; alt=&#34;Spidermans&#34; width=&#34;950&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Showroom/NoS_Prints.png&#34; alt=&#34;NoS_prints&#34; width=&#34;950&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Showroom/BnE_Prints.png&#34; alt=&#34;BnE_Prints&#34; width=&#34;950&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Showroom/Bimaterial_logo.png&#34; alt=&#34;Voron Logo TPU&#34; width=&#34;650&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Showroom/9_colors_test.png&#34; alt=&#34;9_colors_test&#34; width=&#34;400&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>JoeanAmier/TikTokDownloader</title>
    <updated>2023-12-27T01:24:08Z</updated>
    <id>tag:github.com,2023-12-27:/JoeanAmier/TikTokDownloader</id>
    <link href="https://github.com/JoeanAmier/TikTokDownloader" rel="alternate"></link>
    <summary type="html">&lt;p&gt;å®Œå…¨å…è´¹å¼€æºï¼ŒåŸºäº Requests æ¨¡å—å®ç°ï¼šTikTok ä¸»é¡µ/è§†é¢‘/å›¾é›†/åŸå£°ï¼›æŠ–éŸ³ä¸»é¡µ/è§†é¢‘/å›¾é›†/æ”¶è—/ç›´æ’­/åŸå£°/åˆé›†/è¯„è®º/è´¦å·/æœç´¢/çƒ­æ¦œæ•°æ®é‡‡é›†å·¥å…·&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/JoeanAmier/TikTokDownloader/raw/master/static/images/TikTokDownloader.png&#34; alt=&#34;TikTokDownloader&#34; height=&#34;256&#34; width=&#34;256&#34;&gt;&#xA; &lt;br&gt; &#xA; &lt;h1&gt;TikTokDownloader&lt;/h1&gt; &#xA; &lt;img alt=&#34;GitHub&#34; src=&#34;https://img.shields.io/github/license/JoeanAmier/TikTokDownloader?style=for-the-badge&amp;amp;color=ff7a45&#34;&gt; &#xA; &lt;img alt=&#34;GitHub forks&#34; src=&#34;https://img.shields.io/github/forks/JoeanAmier/TikTokDownloader?style=for-the-badge&amp;amp;color=fa8c16&#34;&gt; &#xA; &lt;img alt=&#34;GitHub Repo stars&#34; src=&#34;https://img.shields.io/github/stars/JoeanAmier/TikTokDownloader?style=for-the-badge&amp;amp;color=ff4d4f&#34;&gt; &#xA; &lt;img alt=&#34;GitHub code size in bytes&#34; src=&#34;https://img.shields.io/github/languages/code-size/JoeanAmier/TikTokDownloader?style=for-the-badge&amp;amp;color=13c2c2&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;img alt=&#34;GitHub release (with filter)&#34; src=&#34;https://img.shields.io/github/v/release/JoeanAmier/TikTokDownloader?style=for-the-badge&amp;amp;color=f759ab&#34;&gt; &#xA; &lt;img src=&#34;https://img.shields.io/badge/Sourcery-enabled-884898?style=for-the-badge&amp;amp;color=1890ff&#34; alt=&#34;&#34;&gt; &#xA; &lt;img alt=&#34;GitHub all releases&#34; src=&#34;https://img.shields.io/github/downloads/JoeanAmier/TikTokDownloader/total?style=for-the-badge&amp;amp;color=52c41a&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;ğŸ”¥ &lt;b&gt;TikTok ä¸»é¡µ/è§†é¢‘/å›¾é›†/åŸå£°ï¼›æŠ–éŸ³ä¸»é¡µ/è§†é¢‘/å›¾é›†/æ”¶è—/ç›´æ’­/åŸå£°/åˆé›†/è¯„è®º/è´¦å·/æœç´¢/çƒ­æ¦œæ•°æ®é‡‡é›†å·¥å…·ï¼š&lt;/b&gt;å®Œå…¨å¼€æºï¼ŒåŸºäº Requests æ¨¡å—å®ç°çš„å…è´¹å·¥å…·ï¼›æ‰¹é‡ä¸‹è½½æŠ–éŸ³è´¦å·å‘å¸ƒã€å–œæ¬¢ã€æ”¶è—ä½œå“ï¼›æ‰¹é‡ä¸‹è½½ TikTok è´¦å·ä¸»é¡µä½œå“ï¼›ä¸‹è½½æŠ–éŸ³é“¾æ¥æˆ– TikTok é“¾æ¥ä½œå“ï¼›è·å–æŠ–éŸ³ç›´æ’­æ¨æµåœ°å€ï¼›ä¸‹è½½æŠ–éŸ³ç›´æ’­è§†é¢‘ï¼›é‡‡é›†æŠ–éŸ³ä½œå“è¯„è®ºæ•°æ®ï¼›æ‰¹é‡ä¸‹è½½æŠ–éŸ³åˆé›†ä½œå“ï¼›é‡‡é›†æŠ–éŸ³è´¦å·è¯¦ç»†æ•°æ®ï¼›é‡‡é›†æŠ–éŸ³ç”¨æˆ· / ä½œå“ / ç›´æ’­æœç´¢ç»“æœï¼›é‡‡é›†æŠ–éŸ³çƒ­æ¦œæ•°æ®ã€‚&lt;/p&gt; &#xA;&lt;p&gt;â­ Windows 10 åŠä»¥ä¸Šç”¨æˆ·å¯å‰å¾€ &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/releases/latest&#34;&gt;Releases&lt;/a&gt; ä¸‹è½½å·²ç¼–è¯‘çš„ exe ç¨‹åºï¼Œå¼€ç®±å³ç”¨ï¼&lt;/p&gt; &#xA;&lt;p&gt;â¤ï¸ ä½œè€…ä»…åœ¨ GitHub å‘å¸ƒ TikTokDownloaderï¼Œæœªä¸ä»»ä½•ä¸ªäººæˆ–ç½‘ç«™åˆä½œï¼Œä¸”æ²¡æœ‰ä»»ä½•æ”¶è´¹è®¡åˆ’ï¼&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;ğŸ“ åŠŸèƒ½æ¸…å•(Function)&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;âœ… ä¸‹è½½æŠ–éŸ³æ— æ°´å°è§†é¢‘/å›¾é›†&lt;/li&gt; &#xA; &lt;li&gt;âœ… ä¸‹è½½ TikTok æ— æ°´å°è§†é¢‘/å›¾é›†&lt;/li&gt; &#xA; &lt;li&gt;âœ… æ‰¹é‡ä¸‹è½½æŠ–éŸ³è´¦å·å‘å¸ƒ/å–œæ¬¢/æ”¶è—ä½œå“&lt;/li&gt; &#xA; &lt;li&gt;âœ… æ‰¹é‡ä¸‹è½½ TikTok è´¦å·å‘å¸ƒ/å–œæ¬¢ä½œå“&lt;/li&gt; &#xA; &lt;li&gt;âœ… é‡‡é›†æŠ–éŸ³ / TikTok è¯¦ç»†æ•°æ®&lt;/li&gt; &#xA; &lt;li&gt;âœ… æ‰¹é‡ä¸‹è½½é“¾æ¥ä½œå“&lt;/li&gt; &#xA; &lt;li&gt;âœ… å¤šè´¦å·æ‰¹é‡ä¸‹è½½ä½œå“&lt;/li&gt; &#xA; &lt;li&gt;âœ… è‡ªåŠ¨è·³è¿‡å·²ä¸‹è½½çš„æ–‡ä»¶&lt;/li&gt; &#xA; &lt;li&gt;âœ… æŒä¹…åŒ–ä¿å­˜é‡‡é›†æ•°æ®&lt;/li&gt; &#xA; &lt;li&gt;âœ… ä¸‹è½½åŠ¨æ€/é™æ€å°é¢å›¾&lt;/li&gt; &#xA; &lt;li&gt;âœ… è·å–æŠ–éŸ³ç›´æ’­æ¨æµåœ°å€&lt;/li&gt; &#xA; &lt;li&gt;âœ… è°ƒç”¨ ffmpeg ä¸‹è½½ç›´æ’­&lt;/li&gt; &#xA; &lt;li&gt;âœ… Web UI äº¤äº’ç•Œé¢&lt;/li&gt; &#xA; &lt;li&gt;âœ… é‡‡é›†æŠ–éŸ³ä½œå“è¯„è®ºæ•°æ®&lt;/li&gt; &#xA; &lt;li&gt;âœ… æ‰¹é‡ä¸‹è½½æŠ–éŸ³åˆé›†ä½œå“&lt;/li&gt; &#xA; &lt;li&gt;âœ… è®°å½•ç‚¹èµæ”¶è—ç­‰ç»Ÿè®¡æ•°æ®&lt;/li&gt; &#xA; &lt;li&gt;âœ… ç­›é€‰ä½œå“å‘å¸ƒæ—¶é—´&lt;/li&gt; &#xA; &lt;li&gt;âœ… æ”¯æŒè´¦å·ä½œå“å¢é‡ä¸‹è½½&lt;/li&gt; &#xA; &lt;li&gt;âœ… æ”¯æŒä½¿ç”¨ä»£ç†é‡‡é›†æ•°æ®&lt;/li&gt; &#xA; &lt;li&gt;âœ… æ”¯æŒå±€åŸŸç½‘è¿œç¨‹è®¿é—®&lt;/li&gt; &#xA; &lt;li&gt;âœ… é‡‡é›†æŠ–éŸ³è´¦å·è¯¦ç»†æ•°æ®&lt;/li&gt; &#xA; &lt;li&gt;âœ… ä½œå“ç»Ÿè®¡æ•°æ®æ›´æ–°&lt;/li&gt; &#xA; &lt;li&gt;âœ… è‡ªåŠ¨æ›´æ–°è´¦å·æ˜µç§°&lt;/li&gt; &#xA; &lt;li&gt;âœ… éƒ¨ç½²è‡³ç§æœ‰æœåŠ¡å™¨&lt;/li&gt; &#xA; &lt;li&gt;âœ… éƒ¨ç½²è‡³å…¬å¼€æœåŠ¡å™¨&lt;/li&gt; &#xA; &lt;li&gt;âœ… é‡‡é›†æŠ–éŸ³æœç´¢æ•°æ®&lt;/li&gt; &#xA; &lt;li&gt;âœ… é‡‡é›†æŠ–éŸ³çƒ­æ¦œæ•°æ®&lt;/li&gt; &#xA; &lt;li&gt;âœ… è®°å½•å·²ä¸‹è½½ä½œå“ ID&lt;/li&gt; &#xA; &lt;li&gt;âœ… æ‰«ç ç™»é™†è·å– Cookie&lt;/li&gt; &#xA; &lt;li&gt;âœ… æ”¯æŒ Web API è°ƒç”¨&lt;/li&gt; &#xA; &lt;li&gt;âœ… æ”¯æŒå¤šçº¿ç¨‹ä¸‹è½½ä½œå“&lt;/li&gt; &#xA; &lt;li&gt;âœ… æ–‡ä»¶å®Œæ•´æ€§å¤„ç†æœºåˆ¶&lt;/li&gt; &#xA; &lt;li&gt;âœ… è‡ªå®šä¹‰è§„åˆ™ç­›é€‰ä½œå“&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;ğŸ’» ç¨‹åºç•Œé¢(Screenshot)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;ç»ˆç«¯å‘½ä»¤è¡Œæ¨¡å¼ï¼š&lt;/strong&gt; &lt;br&gt;&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/%E7%BB%88%E7%AB%AF%E6%A8%A1%E5%BC%8F%E6%88%AA%E5%9B%BE1.png&#34; alt=&#34;ç»ˆç«¯æ¨¡å¼æˆªå›¾&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/%E7%BB%88%E7%AB%AF%E6%A8%A1%E5%BC%8F%E6%88%AA%E5%9B%BE2.png&#34; alt=&#34;ç»ˆç«¯æ¨¡å¼æˆªå›¾&#34;&gt; &lt;br&gt;&lt;br&gt; &lt;strong&gt;Web UI äº¤äº’æ¨¡å¼ï¼š&lt;/strong&gt; &lt;br&gt;&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/WebUI%E6%A8%A1%E5%BC%8F%E6%88%AA%E5%9B%BE1.png&#34; alt=&#34;WebUIæ¨¡å¼æˆªå›¾&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/WebUI%E6%A8%A1%E5%BC%8F%E6%88%AA%E5%9B%BE2.png&#34; alt=&#34;WebUIæ¨¡å¼æˆªå›¾&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/WebUI%E6%A8%A1%E5%BC%8F%E6%88%AA%E5%9B%BE3.png&#34; alt=&#34;WebUIæ¨¡å¼æˆªå›¾&#34;&gt; &lt;br&gt;&lt;br&gt; &lt;strong&gt;Web API æ¥å£æ¨¡å¼ï¼š&lt;/strong&gt; &lt;br&gt;&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/WebAPI%E6%A8%A1%E5%BC%8F%E6%88%AA%E5%9B%BE.png&#34; alt=&#34;WebAPIæ¨¡å¼æˆªå›¾&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;ğŸ“½ è¿è¡Œæ¼”ç¤º(Example)&lt;/h1&gt; &#xA;&lt;h2&gt;æ‰¹é‡ä¸‹è½½è´¦å·å‘å¸ƒä½œå“&lt;/h2&gt; &#xA;&lt;p&gt;&lt;b&gt;ğŸ¥ ç‚¹å‡»å›¾ç‰‡è§‚çœ‹æ¼”ç¤ºè§†é¢‘ï¼Œå»ºè®®é€šè¿‡é…ç½®æ–‡ä»¶ç®¡ç†è´¦å·ï¼Œæ›´å¤šä»‹ç»è¯·æŸ¥é˜… &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/wiki/Documentation&#34;&gt;æ–‡æ¡£&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Nu4y1L7LW/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/%E7%A8%8B%E5%BA%8F%E8%BF%90%E8%A1%8C%E6%BC%94%E7%A4%BA.png&#34; alt=&#34;æ¼”ç¤ºè§†é¢‘&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;ğŸ“ˆ é¡¹ç›®çŠ¶æ€(Status)&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸŸ¢ &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/releases/latest&#34;&gt;Releases&lt;/a&gt; å‘å¸ƒçš„æºç å·²å®Œæˆæµ‹è¯•ï¼Œæ‰€æœ‰åŠŸèƒ½å‡å¯æ­£å¸¸ä½¿ç”¨&lt;/li&gt; &#xA; &lt;li&gt;ğŸŸ¢ æ­£åœ¨é‡æ„é¡¹ç›®ä»£ç ï¼Œä¼˜åŒ–é¡¹ç›®ç»“æ„&lt;/li&gt; &#xA; &lt;li&gt;ğŸŸ¢ å³å°†ä½¿ç”¨åç¨‹æŠ€æœ¯ä¼˜åŒ–é¡¹ç›®ä»£ç &lt;/li&gt; &#xA; &lt;li&gt;ğŸŸ¡ æœªæ¥å¯èƒ½æ–°å¢å¯è§†åŒ–ç¼–è¾‘é…ç½®æ–‡ä»¶åŠŸèƒ½&lt;/li&gt; &#xA; &lt;li&gt;ğŸŸ¡ æœªæ¥å¯èƒ½æ”¯æŒæ›´å¤šæŠ–éŸ³çƒ­æ¦œç±»å‹&lt;/li&gt; &#xA; &lt;li&gt;ğŸŸ¡ æœªæ¥å¯èƒ½æ–°å¢ç»ˆç«¯æ–‡æœ¬ç”¨æˆ·ç•Œé¢(TUI)æ¨¡å¼&lt;/li&gt; &#xA; &lt;li&gt;ğŸŸ¡ æœªæ¥å¯èƒ½æ”¯æŒå…¨åŠŸèƒ½ç‰ˆçš„ Web UI äº¤äº’æ¨¡å¼&lt;/li&gt; &#xA; &lt;li&gt;ğŸŸ¡ æœªæ¥å¯èƒ½æ–°å¢ç›‘å¬å‰ªè´´æ¿ä¸‹è½½ä½œå“åŠŸèƒ½&lt;/li&gt; &#xA; &lt;li&gt;ğŸŸ¡ æœªæ¥å¯èƒ½æ–°å¢è´¦å·æ–°ä½œå“ç›‘æµ‹åŠŸèƒ½&lt;/li&gt; &#xA; &lt;li&gt;ğŸŸ¡ æœªæ¥å¯èƒ½æ–°å¢åˆé›†æ–°ä½œå“ç›‘æµ‹åŠŸèƒ½&lt;/li&gt; &#xA; &lt;li&gt;ğŸŸ¡ æœªæ¥å¯èƒ½æ–°å¢ç›´æ’­å¼€æ’­ç›‘æµ‹åŠŸèƒ½&lt;/li&gt; &#xA; &lt;li&gt;ğŸŸ¡ æœªæ¥å¯èƒ½æ–°å¢è°ƒç”¨ API ä¸‹è½½ä½œå“æ–‡ä»¶åŠŸèƒ½&lt;/li&gt; &#xA; &lt;li&gt;ğŸŸ¡ æœªæ¥å¯èƒ½æ–°å¢è·å–è´¦å·å…³æ³¨åˆ—è¡¨åŠŸèƒ½&lt;/li&gt; &#xA; &lt;li&gt;ğŸŸ¡ æœªæ¥å¯èƒ½æ–°å¢è·å–è´¦å·æ”¶è—åˆé›†åˆ—è¡¨åŠŸèƒ½&lt;/li&gt; &#xA; &lt;li&gt;ğŸŸ¡ æœªæ¥å¯èƒ½ä¼˜åŒ– TikTok å¹³å°æ‰¹é‡ä¸‹è½½åŠŸèƒ½&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”´ æœ€æ–°ç‰ˆæœ¬çš„æºç å¯èƒ½å­˜åœ¨ä¸ç¨³å®šçš„ Bug&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”´ å¦‚æœåœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­å‘ç°ç¨‹åº Bugï¼Œè¯·åŠæ—¶å‘ŠçŸ¥ä½œè€…ä¿®å¤&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”´ å‘ç° Cookie ä¼šå½±å“ä¸‹è½½çš„è§†é¢‘ä½œå“æ–‡ä»¶åˆ†è¾¨ç‡&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;ğŸ“‹ é¡¹ç›®è¯´æ˜(Instructions)&lt;/h1&gt; &#xA;&lt;h2&gt;å¿«é€Ÿå…¥é—¨&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;b&gt;ä¸‹è½½ EXE ç¨‹åº&lt;/b&gt; æˆ–è€… &lt;b&gt;é…ç½®è¿è¡Œç¯å¢ƒ&lt;/b&gt; &#xA;  &lt;ol&gt;&#xA;   &lt;b&gt;ç›´æ¥è¿è¡Œç¨‹åº&lt;/b&gt; &#xA;   &lt;li&gt;ä¸‹è½½ &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/releases/latest&#34;&gt;Releases&lt;/a&gt; å‘å¸ƒçš„ EXE ç¨‹åºå‹ç¼©åŒ…&lt;/li&gt; &#xA;   &lt;li&gt;è§£å‹åæ‰“å¼€ç¨‹åºæ–‡ä»¶å¤¹ï¼ŒåŒå‡»è¿è¡Œ &lt;code&gt;main.exe&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &#xA;  &lt;ol&gt;&#xA;   &lt;b&gt;é€šè¿‡æºç è¿è¡Œ&lt;/b&gt; &#xA;   &lt;li&gt;å®‰è£…ä¸ä½äº &lt;code&gt;3.12&lt;/code&gt; ç‰ˆæœ¬çš„ &lt;a href=&#34;https://www.python.org/&#34;&gt;Python&lt;/a&gt; è§£é‡Šå™¨&lt;/li&gt; &#xA;   &lt;li&gt;ä¸‹è½½æœ€æ–°çš„æºç æˆ– &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/releases/latest&#34;&gt;Releases&lt;/a&gt; å‘å¸ƒçš„æºç è‡³æœ¬åœ°&lt;/li&gt; &#xA;   &lt;li&gt;è¿è¡Œ &lt;code&gt;python -m venv venv&lt;/code&gt; å‘½ä»¤åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆå¯é€‰ï¼‰&lt;/li&gt; &#xA;   &lt;li&gt;è¿è¡Œ &lt;code&gt;.\venv\Scripts\activate.ps1&lt;/code&gt; æˆ–è€… &lt;code&gt;venv\Scripts\activate&lt;/code&gt; å‘½ä»¤æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆå¯é€‰ï¼‰&lt;/li&gt; &#xA;   &lt;li&gt;è¿è¡Œ &lt;code&gt;pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt&lt;/code&gt; å‘½ä»¤å®‰è£…ç¨‹åºæ‰€éœ€æ¨¡å—&lt;/li&gt; &#xA;   &lt;li&gt;è¿è¡Œ &lt;code&gt;python .\main.py&lt;/code&gt; æˆ–è€… &lt;code&gt;python main.py&lt;/code&gt; å‘½ä»¤å¯åŠ¨ TikTokDownloader&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;é˜…è¯» TikTokDownloader çš„å…è´£å£°æ˜ï¼Œæ ¹æ®æç¤ºè¾“å…¥å†…å®¹&lt;/li&gt; &#xA; &lt;li&gt;å°† Cookie ä¿¡æ¯å†™å…¥é…ç½®æ–‡ä»¶ &#xA;  &lt;ol&gt;&#xA;   &lt;b&gt;æ‰‹åŠ¨å¤åˆ¶ç²˜è´´(æ¨è)&lt;/b&gt; &#xA;   &lt;li&gt;å‚è€ƒ &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/raw/master/docs/Cookie%E6%95%99%E7%A8%8B.md&#34;&gt;Cookie æå–æ•™ç¨‹&lt;/a&gt;ï¼Œå¤åˆ¶æ‰€éœ€ Cookie è‡³å‰ªè´´æ¿&lt;/li&gt; &#xA;   &lt;li&gt;é€‰æ‹© &lt;code&gt;å¤åˆ¶ç²˜è´´å†™å…¥ Cookie&lt;/code&gt; é€‰é¡¹ï¼ŒæŒ‰ç…§æç¤ºå°† Cookie å†™å…¥é…ç½®æ–‡ä»¶&lt;/li&gt; &#xA;  &lt;/ol&gt; &#xA;  &lt;ol&gt;&#xA;   &lt;b&gt;æ‰«ç ç™»å½•è·å–&lt;/b&gt; &#xA;   &lt;li&gt;é€‰æ‹© &lt;code&gt;æ‰«ç ç™»é™†å†™å…¥ Cookie&lt;/code&gt; é€‰é¡¹ï¼Œç¨‹åºä¼šæ˜¾ç¤ºç™»å½•äºŒç»´ç å›¾ç‰‡ï¼Œå¹¶ä½¿ç”¨é»˜è®¤åº”ç”¨æ‰“å¼€å›¾ç‰‡&lt;/li&gt; &#xA;   &lt;li&gt;ä½¿ç”¨æŠ–éŸ³ APP æ‰«æäºŒç»´ç å¹¶ç™»å½•è´¦å·&lt;/li&gt; &#xA;   &lt;li&gt;æŒ‰ç…§æç¤ºæ“ä½œï¼Œå°† Cookie å†™å…¥é…ç½®æ–‡ä»¶&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;è¿”å›ç¨‹åºç•Œé¢ï¼Œä¾æ¬¡é€‰æ‹© &lt;code&gt;ç»ˆç«¯å‘½ä»¤è¡Œæ¨¡å¼&lt;/code&gt; -&amp;gt; &lt;code&gt;æ‰¹é‡ä¸‹è½½é“¾æ¥ä½œå“&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;è¾“å…¥æŠ–éŸ³æˆ– TikTok ä½œå“é“¾æ¥å³å¯ä¸‹è½½ä½œå“æ–‡ä»¶&lt;/li&gt; &#xA; &lt;li&gt;æ›´å¤šè¯¦ç»†è¯´æ˜è¯·æŸ¥çœ‹ &lt;b&gt;&lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/wiki/Documentation&#34;&gt;é¡¹ç›®æ–‡æ¡£&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;â­ æ¨èä½¿ç”¨ &lt;a href=&#34;https://learn.microsoft.com/zh-cn/windows/terminal/install&#34;&gt;Windows ç»ˆç«¯&lt;/a&gt;ï¼ˆWindows 11 è‡ªå¸¦é»˜è®¤ç»ˆç«¯ï¼‰&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;å…³äº Cookie&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/raw/master/docs/Cookie%E6%95%99%E7%A8%8B.md&#34;&gt;ç‚¹å‡»æŸ¥çœ‹ Cookie è·å–æ•™ç¨‹&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;ç¨‹åºåŠŸèƒ½&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;æ˜¯å¦éœ€è¦ç™»å½•&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ä¸‹è½½è´¦å·å‘å¸ƒä½œå“&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;â­•å»ºè®®ç™»å½•&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ä¸‹è½½è´¦å·å–œæ¬¢ä½œå“&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;â­•å»ºè®®ç™»å½•&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ä¸‹è½½é“¾æ¥ä½œå“&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;â­•å»ºè®®ç™»å½•&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;è·å–ç›´æ’­æ¨æµåœ°å€&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âŒæ— éœ€ç™»å½•&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ä¸‹è½½ç›´æ’­è§†é¢‘&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âŒæ— éœ€ç™»å½•&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;è·å–ä½œå“è¯„è®ºæ•°æ®&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;â­•å»ºè®®ç™»å½•&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ä¸‹è½½åˆé›†ä½œå“&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;â­•å»ºè®®ç™»å½•&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;è·å–è´¦å·æ•°æ®&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;â­•å»ºè®®ç™»å½•&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;é‡‡é›†æœç´¢ç»“æœ&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;â­•å»ºè®®ç™»å½•&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;é‡‡é›†çƒ­æ¦œæ•°æ®&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âŒæ— éœ€ç™»å½•&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ä¸‹è½½è´¦å·æ”¶è—ä½œå“&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;âœ”ï¸éœ€è¦ç™»å½•&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Cookie ä»…éœ€åœ¨å¤±æ•ˆåé‡æ–°å†™å…¥é…ç½®æ–‡ä»¶ï¼Œå¹¶éæ¯æ¬¡è¿è¡Œç¨‹åºéƒ½è¦å†™å…¥é…ç½®æ–‡ä»¶ï¼&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ç¨‹åºè·å–æ•°æ®å¤±è´¥æ—¶ï¼Œå¯ä»¥å°è¯•æ›´æ–° Cookie æˆ–è€…ä½¿ç”¨å·²ç™»å½•çš„ Cookieï¼&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;å…¶ä»–è¯´æ˜&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ç¨‹åºæç¤ºç”¨æˆ·è¾“å…¥æ—¶ï¼Œç›´æ¥å›è½¦ä»£è¡¨è¿”å›ä¸Šçº§èœå•ï¼Œè¾“å…¥ &lt;code&gt;Q&lt;/code&gt; æˆ– &lt;code&gt;q&lt;/code&gt; ä»£è¡¨ç»“æŸè¿è¡Œ&lt;/li&gt; &#xA; &lt;li&gt;ç”±äºè·å–è´¦å·å–œæ¬¢ä½œå“å’Œæ”¶è—ä½œå“æ•°æ®ä»…è¿”å›å–œæ¬¢ / æ”¶è—ä½œå“çš„å‘å¸ƒæ—¥æœŸï¼Œä¸è¿”å›æ“ä½œæ—¥æœŸï¼Œå› æ­¤ç¨‹åºéœ€è¦è·å–å…¨éƒ¨å–œæ¬¢ / æ”¶è—ä½œå“æ•°æ®å†è¿›è¡Œæ—¥æœŸç­›é€‰ï¼›å¦‚æœä½œå“æ•°é‡è¾ƒå¤šï¼Œå¯èƒ½ä¼šèŠ±è´¹è¾ƒé•¿çš„æ—¶é—´ï¼›å¯é€šè¿‡ &lt;code&gt;max_pages&lt;/code&gt; å‚æ•°æ§åˆ¶è¯·æ±‚æ¬¡æ•°&lt;/li&gt; &#xA; &lt;li&gt;è·å–ç§å¯†è´¦å·çš„å‘å¸ƒä½œå“æ•°æ®éœ€è¦ç™»å½•åçš„ Cookieï¼Œä¸”ç™»å½•çš„è´¦å·éœ€è¦å…³æ³¨è¯¥ç§å¯†è´¦å·&lt;/li&gt; &#xA; &lt;li&gt;æ‰¹é‡ä¸‹è½½è´¦å·ä½œå“æˆ–åˆé›†ä½œå“æ—¶ï¼Œå¦‚æœå¯¹åº”çš„æ˜µç§°æˆ–æ ‡è¯†å‘ç”Ÿå˜åŒ–ï¼Œç¨‹åºä¼šè‡ªåŠ¨æ›´æ–°å·²ä¸‹è½½ä½œå“æ–‡ä»¶åç§°ä¸­çš„æ˜µç§°å’Œæ ‡è¯†&lt;/li&gt; &#xA; &lt;li&gt;ç¨‹åºä¸‹è½½æ–‡ä»¶æ—¶ä¼šå…ˆå°†æ–‡ä»¶ä¸‹è½½è‡³ä¸´æ—¶æ–‡ä»¶å¤¹ï¼Œä¸‹è½½å®Œæˆåå†ç§»åŠ¨è‡³å‚¨å­˜æ–‡ä»¶å¤¹ï¼›ç¨‹åºè¿è¡Œç»“æŸæ—¶ä¼šæ¸…ç©ºä¸´æ—¶æ–‡ä»¶å¤¹&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;æ‰¹é‡ä¸‹è½½æ”¶è—ä½œå“æ¨¡å¼&lt;/code&gt; ç›®å‰ä»…æ”¯æŒä¸‹è½½å½“å‰å·²ç™»å½• Cookie å¯¹åº”è´¦å·çš„æ”¶è—ä½œå“ï¼Œæš‚ä¸æ”¯æŒå¤šè´¦å·&lt;/li&gt; &#xA; &lt;li&gt;å¦‚æœæƒ³è¦ç¨‹åºä½¿ç”¨ä»£ç†ï¼Œå¿…é¡»åœ¨ &lt;code&gt;settings.json&lt;/code&gt; è®¾ç½® &lt;code&gt;proxies&lt;/code&gt; å‚æ•°ï¼Œå¦åˆ™ç¨‹åºä¸ä¼šä½¿ç”¨ä»£ç†&lt;/li&gt; &#xA; &lt;li&gt;éƒ¨åˆ†ä½¿ç”¨è€…åé¦ˆï¼Œæ–°å‘å¸ƒçš„ä½œå“è¿‡æ—©ä¸‹è½½ä¼šä¸‹è½½åˆ°ä½åˆ†è¾¨ç‡çš„æ–‡ä»¶ï¼Œä¸€æ®µæ—¶é—´åæ‰èƒ½ä¸‹è½½åˆ°é«˜åˆ†è¾¨ç‡æ–‡ä»¶ï¼Œä½†æ—¶é—´è§„å¾‹å°šä¸æ˜ç¡®&lt;/li&gt; &#xA; &lt;li&gt;é€€å‡ºç¨‹åºæ—¶ï¼Œè¯·ä»¥æ­£å¸¸æ–¹å¼ç»“æŸè¿è¡Œæˆ–è€…æŒ‰ä¸‹ Ctrl + C ç»“æŸè¿è¡Œï¼Œä¸è¦ç›´æ¥ç‚¹å‡»ç»ˆç«¯çª—å£çš„å…³é—­æŒ‰é’®ç»“æŸè¿è¡Œï¼Œå¦åˆ™ä¼šå¯¼è‡´æ•°æ®ä¸¢å¤±&lt;/li&gt; &#xA; &lt;li&gt;å¦‚æœæ‚¨çš„è®¡ç®—æœºæ²¡æœ‰åˆé€‚çš„ç¨‹åºç¼–è¾‘ JSON æ–‡ä»¶ï¼Œå»ºè®®ä½¿ç”¨ &lt;a href=&#34;https://try8.cn/tool/format/json&#34;&gt;JSON åœ¨çº¿å·¥å…·&lt;/a&gt; ç¼–è¾‘é…ç½®æ–‡ä»¶å†…å®¹&lt;/li&gt; &#xA; &lt;li&gt;å½“ç¨‹åºè¯·æ±‚ç”¨æˆ·è¾“å…¥å†…å®¹æˆ–é“¾æ¥æ—¶ï¼Œè¯·æ³¨æ„é¿å…è¾“å…¥çš„å†…å®¹æˆ–é“¾æ¥åŒ…å«æ¢è¡Œç¬¦ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´é¢„æœŸä¹‹å¤–çš„é—®é¢˜&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;EXE æ›´æ–°&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ–¹æ¡ˆä¸€ï¼š&lt;/strong&gt; ä¸‹è½½å¹¶è§£å‹æ–‡ä»¶ï¼Œå°†æ—§ç‰ˆæœ¬çš„ &lt;code&gt;cache&lt;/code&gt; æ–‡ä»¶å¤¹å’Œ &lt;code&gt;settings.json&lt;/code&gt; æ–‡ä»¶å¤åˆ¶åˆ° &lt;code&gt;_internal&lt;/code&gt; æ–‡ä»¶å¤¹ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ–¹æ¡ˆäºŒï¼š&lt;/strong&gt; ä¸‹è½½å¹¶è§£å‹æ–‡ä»¶ï¼Œå¤åˆ¶å…¨éƒ¨æ–‡ä»¶ï¼Œç›´æ¥è¦†ç›–æ—§ç‰ˆæœ¬æ–‡ä»¶ã€‚&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;âš ï¸ å…è´£å£°æ˜(Disclaimers)&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ä½¿ç”¨è€…å¯¹æœ¬é¡¹ç›®çš„ä½¿ç”¨ç”±ä½¿ç”¨è€…è‡ªè¡Œå†³å®šï¼Œå¹¶è‡ªè¡Œæ‰¿æ‹…é£é™©ã€‚ä½œè€…å¯¹ä½¿ç”¨è€…ä½¿ç”¨æœ¬é¡¹ç›®æ‰€äº§ç”Ÿçš„ä»»ä½•æŸå¤±ã€è´£ä»»ã€æˆ–é£é™©æ¦‚ä¸è´Ÿè´£ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æœ¬é¡¹ç›®çš„ä½œè€…æä¾›çš„ä»£ç å’ŒåŠŸèƒ½æ˜¯åŸºäºç°æœ‰çŸ¥è¯†å’ŒæŠ€æœ¯çš„å¼€å‘æˆæœã€‚ä½œè€…å°½åŠ›ç¡®ä¿ä»£ç çš„æ­£ç¡®æ€§å’Œå®‰å…¨æ€§ï¼Œä½†ä¸ä¿è¯ä»£ç å®Œå…¨æ²¡æœ‰é”™è¯¯æˆ–ç¼ºé™·ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ä½¿ç”¨è€…åœ¨ä½¿ç”¨æœ¬é¡¹ç›®æ—¶å¿…é¡»ä¸¥æ ¼éµå®ˆ &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/raw/master/license&#34;&gt;GNU General Public License v3.0&lt;/a&gt; çš„è¦æ±‚ï¼Œå¹¶åœ¨é€‚å½“çš„åœ°æ–¹æ³¨æ˜ä½¿ç”¨äº† &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/raw/master/license&#34;&gt;GNU General Public License v3.0&lt;/a&gt; çš„ä»£ç ã€‚ &lt;/li&gt; &#xA; &lt;li&gt;ä½¿ç”¨è€…åœ¨ä»»ä½•æƒ…å†µä¸‹å‡ä¸å¾—å°†æœ¬é¡¹ç›®çš„ä½œè€…ã€è´¡çŒ®è€…æˆ–å…¶ä»–ç›¸å…³æ–¹ä¸ä½¿ç”¨è€…çš„ä½¿ç”¨è¡Œä¸ºè”ç³»èµ·æ¥ï¼Œæˆ–è¦æ±‚å…¶å¯¹ä½¿ç”¨è€…ä½¿ç”¨æœ¬é¡¹ç›®æ‰€äº§ç”Ÿçš„ä»»ä½•æŸå¤±æˆ–æŸå®³è´Ÿè´£ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ä½¿ç”¨è€…åœ¨ä½¿ç”¨æœ¬é¡¹ç›®çš„ä»£ç å’ŒåŠŸèƒ½æ—¶ï¼Œå¿…é¡»è‡ªè¡Œç ”ç©¶ç›¸å…³æ³•å¾‹æ³•è§„ï¼Œå¹¶ç¡®ä¿å…¶ä½¿ç”¨è¡Œä¸ºåˆæ³•åˆè§„ã€‚ä»»ä½•å› è¿åæ³•å¾‹æ³•è§„è€Œå¯¼è‡´çš„æ³•å¾‹è´£ä»»å’Œé£é™©ï¼Œå‡ç”±ä½¿ç”¨è€…è‡ªè¡Œæ‰¿æ‹…ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æœ¬é¡¹ç›®çš„ä½œè€…ä¸ä¼šæä¾› TikTokDownloader é¡¹ç›®çš„ä»˜è´¹ç‰ˆæœ¬ï¼Œä¹Ÿä¸ä¼šæä¾›ä¸ TikTokDownloader é¡¹ç›®ç›¸å…³çš„ä»»ä½•å•†ä¸šæœåŠ¡ã€‚&lt;/li&gt; &#xA; &lt;li&gt;åŸºäºæœ¬é¡¹ç›®è¿›è¡Œçš„ä»»ä½•äºŒæ¬¡å¼€å‘ã€ä¿®æ”¹æˆ–ç¼–è¯‘çš„ç¨‹åºä¸åŸåˆ›ä½œè€…æ— å…³ï¼ŒåŸåˆ›ä½œè€…ä¸æ‰¿æ‹…ä¸äºŒæ¬¡å¼€å‘è¡Œä¸ºæˆ–å…¶ç»“æœç›¸å…³çš„ä»»ä½•è´£ä»»ï¼Œä½¿ç”¨è€…åº”è‡ªè¡Œå¯¹å› äºŒæ¬¡å¼€å‘å¯èƒ½å¸¦æ¥çš„å„ç§æƒ…å†µè´Ÿå…¨éƒ¨è´£ä»»ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;b&gt;åœ¨ä½¿ç”¨æœ¬é¡¹ç›®çš„ä»£ç å’ŒåŠŸèƒ½ä¹‹å‰ï¼Œè¯·æ‚¨è®¤çœŸè€ƒè™‘å¹¶æ¥å—ä»¥ä¸Šå…è´£å£°æ˜ã€‚å¦‚æœæ‚¨å¯¹ä¸Šè¿°å£°æ˜æœ‰ä»»ä½•ç–‘é—®æˆ–ä¸åŒæ„ï¼Œè¯·ä¸è¦ä½¿ç”¨æœ¬é¡¹ç›®çš„ä»£ç å’ŒåŠŸèƒ½ã€‚å¦‚æœæ‚¨ä½¿ç”¨äº†æœ¬é¡¹ç›®çš„ä»£ç å’ŒåŠŸèƒ½ï¼Œåˆ™è§†ä¸ºæ‚¨å·²å®Œå…¨ç†è§£å¹¶æ¥å—ä¸Šè¿°å…è´£å£°æ˜ï¼Œå¹¶è‡ªæ„¿æ‰¿æ‹…ä½¿ç”¨æœ¬é¡¹ç›®çš„ä¸€åˆ‡é£é™©å’Œåæœã€‚&lt;/b&gt; &#xA;&lt;h1&gt;âœ‰ï¸ è”ç³»ä½œè€…(Contact)&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;QQ: 2437596031ï¼ˆè”ç³»è¯·è¯´æ˜æ¥æ„ï¼‰&lt;/li&gt; &#xA; &lt;li&gt;QQ Group: &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/raw/master/docs/QQ%E7%BE%A4%E8%81%8A%E4%BA%8C%E7%BB%B4%E7%A0%81.png&#34;&gt;ç‚¹å‡»æ‰«ç åŠ å…¥ç¾¤èŠ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Email: yonglelolu@gmail.com&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt; &lt;b&gt;TikTokDownloader æ˜¯æˆ‘ä¸ªäººç‹¬ç«‹ç»´æŠ¤çš„ä¸€ä¸ªå¼€æºé¡¹ç›®ï¼Œé‰´äºä¸ªäººç²¾åŠ›æœ‰é™ï¼Œè¯·ç†è§£é¡¹ç›®è¿›å±•å¯èƒ½è¾ƒä¸ºç¼“æ…¢ï¼Œæˆ‘ä¼šå°½åŠ›ä¿æŒæ›´æ–°å’Œç»´æŠ¤ï¼Œä»¥ç¡®ä¿é¡¹ç›®çš„ç¨³å®šæ€§å’ŒåŠŸèƒ½çš„ä¸æ–­æ”¹è¿›ã€‚&lt;/b&gt; &lt;/p&gt; &#xA;&lt;p&gt; &lt;b&gt;å¦‚æœæ‚¨é€šè¿‡ Email è”ç³»æˆ‘ï¼Œæˆ‘å¯èƒ½æ— æ³•åŠæ—¶æŸ¥çœ‹å¹¶å›å¤ä¿¡æ¯ï¼Œæˆ‘ä¼šå°½åŠ›åœ¨ä¸ƒå¤©å†…å›å¤æ‚¨çš„é‚®ä»¶ï¼›å¦‚æœæœ‰ç´§æ€¥äº‹é¡¹æˆ–éœ€è¦æ›´å¿«çš„å›å¤ï¼Œè¯·é€šè¿‡å…¶ä»–æ–¹å¼ä¸æˆ‘è”ç³»ï¼Œè°¢è°¢ç†è§£ï¼&lt;/b&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;b&gt;å¦‚æœæ‚¨å¯¹å°çº¢ä¹¦æ„Ÿå…´è¶£ï¼Œå¯ä»¥äº†è§£ä¸€ä¸‹æˆ‘çš„å¦ä¸€ä¸ªå¼€æºé¡¹ç›® &lt;a href=&#34;https://github.com/JoeanAmier/XHS-Downloader&#34;&gt;XHS-Downloader&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &#xA;&lt;h1&gt;â™¥ï¸ æ”¯æŒé¡¹ç›®(Support)&lt;/h1&gt; &#xA;&lt;p&gt;å¦‚æœ &lt;b&gt;TikTokDownloader&lt;/b&gt; å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘ä¸ºå®ƒç‚¹ä¸ª &lt;b&gt;Star&lt;/b&gt; â­ï¼Œæ„Ÿè°¢æ‚¨çš„æ”¯æŒï¼&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;å¾®ä¿¡(WeChat)&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;æ”¯ä»˜å®(Alipay)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;./docs/å¾®ä¿¡èµåŠ©äºŒç»´ç .png&#34; alt=&#34;å¾®ä¿¡èµåŠ©äºŒç»´ç &#34; height=&#34;200&#34; width=&#34;200&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;./docs/æ”¯ä»˜å®èµåŠ©äºŒç»´ç .png&#34; alt=&#34;æ”¯ä»˜å®èµåŠ©äºŒç»´ç &#34; height=&#34;200&#34; width=&#34;200&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;å¦‚æœæ‚¨æ„¿æ„ï¼Œå¯ä»¥è€ƒè™‘æä¾›èµ„åŠ©ä¸º &lt;b&gt;TikTokDownloader&lt;/b&gt; æä¾›é¢å¤–çš„æ”¯æŒï¼&lt;/p&gt; &#xA;&lt;h1&gt;ğŸ’¡ ä»£ç å‚è€ƒ(Refer)&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Johnserf-Seed/f2&#34;&gt;https://github.com/Johnserf-Seed/f2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Johnserf-Seed/TikTokDownload&#34;&gt;https://github.com/Johnserf-Seed/TikTokDownload&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Evil0ctal/Douyin_TikTok_Download_API&#34;&gt;https://github.com/Evil0ctal/Douyin_TikTok_Download_API&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ihmily/DouyinLiveRecorder&#34;&gt;https://github.com/ihmily/DouyinLiveRecorder&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/davidteather/TikTok-Api&#34;&gt;https://github.com/davidteather/TikTok-Api&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/psf/requests&#34;&gt;https://github.com/psf/requests&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pallets/flask&#34;&gt;https://github.com/pallets/flask&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Textualize/rich&#34;&gt;https://github.com/Textualize/rich&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pyinstaller/pyinstaller&#34;&gt;https://github.com/pyinstaller/pyinstaller&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ffmpeg.org/ffmpeg-all.html&#34;&gt;https://ffmpeg.org/ffmpeg-all.html&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://html5up.net/hyperspace&#34;&gt;https://html5up.net/hyperspace&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>JShollaj/awesome-llm-interpretability</title>
    <updated>2023-12-27T01:24:08Z</updated>
    <id>tag:github.com,2023-12-27:/JShollaj/awesome-llm-interpretability</id>
    <link href="https://github.com/JShollaj/awesome-llm-interpretability" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A curated list of Large Language Model (LLM) Interpretability resources.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Awesome LLM Interpretability &lt;img src=&#34;https://github.com/your-username/awesome-llm-interpretability/workflows/Awesome%20Bot/badge.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;A curated list of amazingly awesome tools, papers, articles, and communities focused on Large Language Model (LLM) Interpretability.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JShollaj/awesome-llm-interpretability/main/#awesome-llm-interpretability&#34;&gt;Awesome LLM Interpretability&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JShollaj/awesome-llm-interpretability/main/#llm-interpretability-tools&#34;&gt;LLM Interpretability Tools&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JShollaj/awesome-llm-interpretability/main/#llm-interpretability-papers&#34;&gt;LLM Interpretability Papers&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JShollaj/awesome-llm-interpretability/main/#llm-interpretability-articles&#34;&gt;LLM Interpretability Articles&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JShollaj/awesome-llm-interpretability/main/#llm-interpretability-groups&#34;&gt;LLM Interpretability Groups&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;LLM Interpretability Tools&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;Tools and libraries for LLM interpretability and analysis.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/FlorianDietz/comgra&#34;&gt;Comgra&lt;/a&gt; - Comgra helps you analyze and debug neural networks in pytorch.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/EleutherAI/pythia&#34;&gt;Pythia&lt;/a&gt; - Interpretability analysis to understand how knowledge develops and evolves during training in autoregressive transformers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Arize-ai/phoenix&#34;&gt;Phoenix&lt;/a&gt; - AI Observability &amp;amp; Evaluation - Evaluate, troubleshoot, and fine tune your LLM, CV, and NLP models in a notebook.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/automated-interpretability&#34;&gt;Automated Interpretability&lt;/a&gt; - Code for automatically generating, simulating, and scoring explanations of neuron behavior.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/BizarreCake/fmr.ai&#34;&gt;Fmr.ai&lt;/a&gt; - AI interpretability and explainability platform.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/clarkkev/attention-analysis&#34;&gt;Attention Analysis&lt;/a&gt; - Analyzing attention maps from BERT transformer.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mwatkins1970/SpellGPT&#34;&gt;SpellGPT&lt;/a&gt; - Explores GPT-3â€™s ability to spell own token strings.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/JetRunner/SuperICL&#34;&gt;SuperICL&lt;/a&gt; - Super In-Context Learning code which allows black-box LLMs to work with locally fine-tuned smaller models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/samuela/git-re-basin&#34;&gt;Git Re-Basin&lt;/a&gt; - Code release for &#34;Git Re-Basin: Merging Models modulo Permutation Symmetries.â€&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MeetKai/functionary&#34;&gt;Functionary&lt;/a&gt; - Chat language model that can interpret and execute functions/plugins.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ai-safety-foundation/sparse_autoencoder&#34;&gt;Sparse Autoencoder&lt;/a&gt; - Sparse Autoencoder for Mechanistic Interpretability.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kmeng01/rome&#34;&gt;Rome&lt;/a&gt; - Locating and editing factual associations in GPT.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/inseq-team/inseq&#34;&gt;Inseq&lt;/a&gt; - Interpretability for sequence generation models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openaipublic.blob.core.windows.net/neuron-explainer/neuron-viewer/index.html&#34;&gt;Neuron Viewer&lt;/a&gt; - Tool for viewing neuron activations and explanations.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://bbycroft.net/llm&#34;&gt;LLM Visualization&lt;/a&gt; - Visualizing LLMs in low level.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vanna-ai/vanna&#34;&gt;Vanna&lt;/a&gt; - Abstractions to use RAG to generate SQL with any LLM&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;LLM Interpretability Papers&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;Academic and industry papers on LLM interpretability.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.01610&#34;&gt;Finding Neurons in a Haystack: Case Studies with Sparse Probing&lt;/a&gt; - Explores the representation of high-level human-interpretable features within neuron activations of large language models (LLMs).&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.04625&#34;&gt;Copy Suppression: Comprehensively Understanding an Attention Head&lt;/a&gt; - Investigates a specific attention head in GPT-2 Small, revealing its primary role in copy suppression.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.15154&#34;&gt;Linear Representations of Sentiment in Large Language Models&lt;/a&gt; - Shows how sentiment is represented in Large Language Models (LLMs), finding that sentiment is linearly represented in these models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.13382&#34;&gt;Emergent world representations: Exploring a sequence model trained on a synthetic task&lt;/a&gt; - Explores emergent internal representations in a GPT variant trained to predict legal moves in the board game Othello.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.14997&#34;&gt;Towards Automated Circuit Discovery for Mechanistic Interpretability&lt;/a&gt; - Introduces the Automatic Circuit Discovery (ACDC) algorithm for identifying important units in neural networks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.03025&#34;&gt;A Toy Model of Universality: Reverse Engineering How Networks Learn Group Operations&lt;/a&gt; - Examines small neural networks to understand how they learn group compositions, using representation theory.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2004.12265&#34;&gt;Causal Mediation Analysis for Interpreting Neural NLP: The Case of Gender Bias&lt;/a&gt; - Causal mediation analysis as a method for interpreting neural models in natural language processing.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.13506&#34;&gt;The Quantization Model of Neural Scaling&lt;/a&gt; - Proposes the Quantization Model for explaining neural scaling laws in neural networks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.03827&#34;&gt;Discovering Latent Knowledge in Language Models Without Supervision&lt;/a&gt; - Presents a method for extracting accurate answers to yes-no questions from language models&#39; internal activations without supervision.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.00586&#34;&gt;How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model&lt;/a&gt; - Analyzes mathematical capabilities of GPT-2 Small, focusing on its ability to perform the &#39;greater-than&#39; operation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://transformer-circuits.pub/2023/monosemantic-features/index.html&#34;&gt;Towards Monosemanticity: Decomposing Language Models With Dictionary Learning&lt;/a&gt; - Using a sparse autoencoder to decompose the activations of a one-layer transformer into interpretable, monosemantic features.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html&#34;&gt;Language models can explain neurons in language models&lt;/a&gt; - Explores how language models like GPT-4 can be used to explain the functioning of neurons within similar models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.00941&#34;&gt;Emergent Linear Representations in World Models of Self-Supervised Sequence Models&lt;/a&gt; - Linear representations in a world model of Othello-playing sequence models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=VJEcAnFPqC&#34;&gt;&#34;Toward a Mechanistic Understanding of Stepwise Inference in Transformers: A Synthetic Graph Navigation Model&#34;&lt;/a&gt; - Explores stepwise inference in autoregressive language models using a synthetic task based on navigating directed acyclic graphs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=kvcbV8KQsi&#34;&gt;&#34;Successor Heads: Recurring, Interpretable Attention Heads In The Wild&#34;&lt;/a&gt; - Introduces &#39;successor heads,&#39; attention heads that increment tokens with a natural ordering, such as numbers and days, in LLMâ€™s.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=shr9PXz7T0&#34;&gt;&#34;Large Language Models Are Not Robust Multiple Choice Selectors&#34;&lt;/a&gt; - Analyzes the bias and robustness of LLMs in multiple-choice questions, revealing their vulnerability to option position changes due to inherent &#34;selection biasâ€.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=4bSQ3lsfEV&#34;&gt;&#34;Going Beyond Neural Network Feature Similarity: The Network Feature Complexity and Its Interpretation Using Category Theory&#34;&lt;/a&gt; - Presents a novel approach to understanding neural networks by examining feature complexity through category theory.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=v8L0pN6EOi&#34;&gt;&#34;Let&#39;s Verify Step by Step&#34;&lt;/a&gt; - Focuses on improving the reliability of LLMs in multi-step reasoning tasks using step-level human feedback.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=v675Iyu0ta&#34;&gt;&#34;Interpretability Illusions in the Generalization of Simplified Models&#34;&lt;/a&gt; - Examines the limitations of simplified representations (like SVD) used to interpret deep learning systems, especially in out-of-distribution scenarios.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=SQGUDc9tC8&#34;&gt;&#34;The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Language Models&#34;&lt;/a&gt; - Presents a novel approach for identifying and mitigating social biases in language models, introducing the concept of &#39;Social Bias Neurons&#39;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=VpCqrMMGVm&#34;&gt;&#34;Interpreting the Inner Mechanisms of Large Language Models in Mathematical Addition&#34;&lt;/a&gt; - Investigates how LLMs perform the task of mathematical addition.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=SznHfMwmjG&#34;&gt;&#34;Measuring Feature Sparsity in Language Models&#34;&lt;/a&gt; - Develops metrics to evaluate the success of sparse coding techniques in language model activations.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://transformer-circuits.pub/2022/toy_model/index.html&#34;&gt;Toy Models of Superposition&lt;/a&gt; - Investigates how models represent more features than dimensions, especially when features are sparse.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1711.08792&#34;&gt;Spine: Sparse interpretable neural embeddings&lt;/a&gt; - Presents SPINE, a method transforming dense word embeddings into sparse, interpretable ones using denoising autoencoders.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.15949&#34;&gt;Transformer visualization via dictionary learning: contextualized embedding as a linear superposition of transformer factors&lt;/a&gt; - Introduces a novel method for visualizing transformer networks using dictionary learning.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.11207&#34;&gt;Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling&lt;/a&gt; - Introduces Pythia, a toolset designed for analyzing the training and scaling behaviors of LLMs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zuva.ai/science/interpretability-and-feature-representations/&#34;&gt;On Interpretability and Feature Representations: An Analysis of the Sentiment Neuron&lt;/a&gt; - Critically examines the effectiveness of the &#34;Sentiment Neuronâ€.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.09169&#34;&gt;Engineering monosemanticity in toy models&lt;/a&gt; - Explores engineering monosemanticity in neural networks, where individual neurons correspond to distinct features.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.01892&#34;&gt;Polysemanticity and capacity in neural networks&lt;/a&gt; - Investigates polysemanticity in neural networks, where individual neurons represent multiple features.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://distill.pub/2020/circuits/early-vision/&#34;&gt;An Overview of Early Vision in InceptionV1&lt;/a&gt; - A comprehensive exploration of the initial five layers of the InceptionV1 neural network, focusing on early vision.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1906.02715&#34;&gt;Visualizing and measuring the geometry of BERT&lt;/a&gt; - Delves into BERT&#39;s internal representation of linguistic information, focusing on both syntactic and semantic aspects.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.04827&#34;&gt;Neurons in Large Language Models: Dead, N-gram, Positional&lt;/a&gt; - An analysis of neurons in large language models, focusing on the OPT family.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.11207&#34;&gt;Can Large Language Models Explain Themselves?&lt;/a&gt; - Evaluates the effectiveness of self-explanations generated by LLMs in sentiment analysis tasks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.00593&#34;&gt;Interpretability in the Wild: GPT-2 small (arXiv)&lt;/a&gt; - Provides a mechanistic explanation of how GPT-2 small performs indirect object identification (IOI) in natural language processing.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.11207&#34;&gt;Sparse Autoencoders Find Highly Interpretable Features in Language Models&lt;/a&gt; - Explores the use of sparse autoencoders to extract more interpretable and less polysemantic features from LLMs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.11207&#34;&gt;Emergent and Predictable Memorization in Large Language Models&lt;/a&gt; - Investigates the use of sparse autoencoders for enhancing the interpretability of features in LLMs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2312.01429&#34;&gt;Transformers are uninterpretable with myopic methods: a case study with bounded Dyck grammars&lt;/a&gt; - Demonstrates that focusing only on specific parts like attention heads or weight matrices in Transformers can lead to misleading interpretability claims.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.06824&#34;&gt;The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets&lt;/a&gt; - This paper investigates the representation of truth in Large Language Models (LLMs) using true/false datasets.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.08809&#34;&gt;Interpretability at Scale: Identifying Causal Mechanisms in Alpaca&lt;/a&gt; - This study presents Boundless Distributed Alignment Search (Boundless DAS), an advanced method for interpreting LLMs like Alpaca.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.01405&#34;&gt;Representation Engineering: A Top-Down Approach to AI Transparency&lt;/a&gt; - Introduces Representation Engineering (RepE), a novel approach for enhancing AI transparency, focusing on high-level representations rather than neurons or circuits.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.09863&#34;&gt;Explaining black box text modules in natural language with language models&lt;/a&gt; - Natural language explanations for LLM attention heads, evaluated using synthetic text&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.12918&#34;&gt;N2G: A Scalable Approach for Quantifying Interpretable Neuron Representations in Large Language Models&lt;/a&gt; - Explain each LLM neuron as a graph&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.11799&#34;&gt;Augmenting Interpretable Models with LLMs during Training&lt;/a&gt; - Use LLMs to build interpretable classifiers of text data&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;LLM Interpretability Articles&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;Insightful articles and blog posts on LLM interpretability.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.quantamagazine.org/a-new-approach-to-computation-reimagines-artificial-intelligence-20230413/?mc_cid=ad9a93c472&amp;amp;mc_eid=506130a407&#34;&gt;A New Approach to Computation Reimagines Artificial Intelligenceg&lt;/a&gt; - Discusses hyperdimensional computing, a novel method involving hyperdimensional vectors (hypervectors) for more efficient, transparent, and robust artificial intelligence.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens&#34;&gt;Interpreting GPT: the logit lens&lt;/a&gt; - Explores how the logit lens, reveals a gradual convergence of GPT&#39;s probabilistic predictions across its layers, from initial nonsensical or shallow guesses to more refined predictions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/N6WM6hs7RQMKDhYjB/a-mechanistic-interpretability-analysis-of-grokking&#34;&gt;A Mechanistic Interpretability Analysis of Grokking&lt;/a&gt; - Explores the phenomenon of &#39;grokking&#39; in deep learning, where models suddenly shift from memorization to generalization during training.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/s/yivyHaCAmMJ3CqSyj&#34;&gt;200 Concrete Open Problems in Mechanistic Interpretability&lt;/a&gt; - Series of posts discussing open research problems in the field of Mechanistic Interpretability (MI), which focuses on reverse-engineering neural networks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.cs.princeton.edu/~arvindn/talks/evaluating_llms_minefield/&#34;&gt;Evaluating LLMs is a minefield&lt;/a&gt; - Challenges in assessing the performance and biases of large language models (LLMs) like GPT.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.neelnanda.io/mechanistic-interpretability/attribution-patching&#34;&gt;Attribution Patching: Activation Patching At Industrial Scale&lt;/a&gt; - Method that uses gradients for a linear approximation of activation patching in neural networks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/JvZhhzycHu2Yd57RN/causal-scrubbing-a-method-for-rigorously-testing&#34;&gt;Causal Scrubbing: a method for rigorously testing interpretability hypotheses [Redwood Research]&lt;/a&gt; - Introduces causal scrubbing, a method for evaluating the quality of mechanistic interpretations in neural networks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/u6KXXmKFbXfWzoAXn/a-circuit-for-python-docstrings-in-a-4-layer-attention-only&#34;&gt;A circuit for Python docstrings in a 4-layer attention-only transformer&lt;/a&gt; - Proposes the Quantization Model for explaining neural scaling laws in neural networks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.03827&#34;&gt;Discovering Latent Knowledge in Language Models Without Supervision&lt;/a&gt; - Examines a specific neural circuit within a 4-layer transformer model responsible for generating Python docstrings.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2207.13243&#34;&gt;Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks&lt;/a&gt; - Survey on mechanistic interpretability&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;LLM Interpretability Groups&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;Communities and groups dedicated to LLM interpretability.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.com/invite/ad27GQgc7K&#34;&gt;Alignment Lab AI&lt;/a&gt; - Group of researchers focusing on AI alignment.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.com/invite/AVB9jkHZ&#34;&gt;Nous Research&lt;/a&gt; - Research group discussing various topics on interpretability.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.com/invite/4pEBpVTN&#34;&gt;EleutherAI&lt;/a&gt; - Non-profit AI research lab that focuses on interpretability and alignment of large models.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Contributing and Collaborating&lt;/h2&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://github.com/your-username/awesome-llm-interpretability/raw/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING&lt;/a&gt; and &lt;a href=&#34;https://github.com/your-username/awesome-llm-interpretability/raw/master/CODE-OF-CONDUCT.md&#34;&gt;CODE-OF-CONDUCT&lt;/a&gt; for details.&lt;/p&gt;</summary>
  </entry>
</feed>