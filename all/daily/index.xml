<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-01-20T01:26:08Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>sgl-project/sglang</title>
    <updated>2024-01-20T01:26:08Z</updated>
    <id>tag:github.com,2024-01-20:/sgl-project/sglang</id>
    <link href="https://github.com/sgl-project/sglang" rel="alternate"></link>
    <summary type="html">&lt;p&gt;SGLang is a structured generation language designed for large language models (LLMs). It makes your interaction with LLMs faster and more controllable.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SGLang&lt;/h1&gt; &#xA;&lt;p&gt;| &lt;a href=&#34;https://lmsys.org/blog/2024-01-17-sglang/&#34;&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/abs/2312.07104&#34;&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/a&gt; |&lt;/p&gt; &#xA;&lt;p&gt;SGLang is a structured generation language designed for large language models (LLMs). It makes your interaction with LLMs faster and more controllable by co-designing the frontend language and the runtime system.&lt;/p&gt; &#xA;&lt;p&gt;The core features of SGLang include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;A Flexible Front-End Language&lt;/strong&gt;: This allows for easy programming of LLM applications with multiple chained generation calls, advanced prompting techniques, control flow, multiple modalities, parallelism, and external interaction.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;A High-Performance Runtime with RadixAttention&lt;/strong&gt;: This feature significantly accelerates the execution of complex LLM programs by automatic KV cache reuse across multiple calls. It also supports other common techniques like continuous batching and tensor parallelism.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/sgl-project/sglang/main/#install&#34;&gt;Install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/sgl-project/sglang/main/#quick-start&#34;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/sgl-project/sglang/main/#frontend-structured-generation-langauge-sglang&#34;&gt;Frontend: Structured Generation Langauge (SGLang)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/sgl-project/sglang/main/#backend-sglang-runtime-srt&#34;&gt;Backend: SGLang Runtime (SRT)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/sgl-project/sglang/main/#benchmark-and-performance&#34;&gt;Benchmark And Performance&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/sgl-project/sglang/main/#roadmap&#34;&gt;Roadmap&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/sgl-project/sglang/main/#citation-and-acknowledgment&#34;&gt;Citation And Acknowledgment&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;h3&gt;Method 1: With pip&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install &#34;sglang[all]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Method 2: From source&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:sgl-project/sglang.git&#xA;cd sglang&#xA;&#xA;pip install --upgrade pip&#xA;pip install -e &#34;python[all]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Notes&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you are using older GPUs (NVIDIA T4, V100), please use &lt;code&gt;pip install &#34;triton&amp;gt;=2.2.0&#34;&lt;/code&gt; to avoid some bugs in the triton compiler&lt;/li&gt; &#xA; &lt;li&gt;If you only need to use the OpenAI backend, you can avoid installing other dependencies by using &lt;code&gt;pip install sglang[openai]&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;The example below shows how to use sglang to answer a mulit-turn question.&lt;/p&gt; &#xA;&lt;h3&gt;Using OpenAI Models&lt;/h3&gt; &#xA;&lt;p&gt;Set the OpenAI API Key&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export OPENAI_API_KEY=sk-******&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, answer a multi-turn question.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sglang import function, system, user, assistant, gen, set_default_backend, OpenAI&#xA;&#xA;@function&#xA;def multi_turn_question(s, question_1, question_2):&#xA;    s += system(&#34;You are a helpful assistant.&#34;)&#xA;    s += user(question_1)&#xA;    s += assistant(gen(&#34;answer_1&#34;, max_tokens=256))&#xA;    s += user(question_2)&#xA;    s += assistant(gen(&#34;answer_2&#34;, max_tokens=256))&#xA;&#xA;set_default_backend(OpenAI(&#34;gpt-3.5-turbo&#34;))&#xA;&#xA;state = multi_turn_question.run(&#xA;    question_1=&#34;What is the capital of the United States?&#34;,&#xA;    question_2=&#34;List two local attractions.&#34;,&#xA;)&#xA;&#xA;for m in state.messages():&#xA;    print(m[&#34;role&#34;], &#34;:&#34;, m[&#34;content&#34;])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Using Local Models&lt;/h3&gt; &#xA;&lt;p&gt;First, launch a server with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m sglang.launch_server --model-path meta-llama/Llama-2-7b-chat-hf --port 30000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, connect to the server and answer a multi-turn question.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sglang import function, system, user, assistant, gen, set_default_backend, RuntimeEndpoint&#xA;&#xA;@function&#xA;def multi_turn_question(s, question_1, question_2):&#xA;    s += system(&#34;You are a helpful assistant.&#34;)&#xA;    s += user(question_1)&#xA;    s += assistant(gen(&#34;answer_1&#34;, max_tokens=256))&#xA;    s += user(question_2)&#xA;    s += assistant(gen(&#34;answer_2&#34;, max_tokens=256))&#xA;&#xA;set_default_backend(RuntimeEndpoint(&#34;http://localhost:30000&#34;))&#xA;&#xA;state = multi_turn_question.run(&#xA;    question_1=&#34;What is the capital of the United States?&#34;,&#xA;    question_2=&#34;List two local attractions.&#34;,&#xA;)&#xA;&#xA;for m in state.messages():&#xA;    print(m[&#34;role&#34;], &#34;:&#34;, m[&#34;content&#34;])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;More Examples&lt;/h3&gt; &#xA;&lt;p&gt;Anthropic and VertexAI (Gemini) models are also supported. You can find more examples at &lt;a href=&#34;https://raw.githubusercontent.com/sgl-project/sglang/main/examples/quick_start&#34;&gt;examples/quick_start&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Frontend: Structured Generation Langauge (SGLang)&lt;/h2&gt; &#xA;&lt;p&gt;To begin with, import sglang.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import sglang as sgl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;sglang&lt;/code&gt; provides some simple primitives such as &lt;code&gt;gen&lt;/code&gt;, &lt;code&gt;select&lt;/code&gt;, &lt;code&gt;fork&lt;/code&gt;, &lt;code&gt;image&lt;/code&gt;. You can implement your prompt flow in a function decorated by &lt;code&gt;sgl.function&lt;/code&gt;. You can then invoke the function with &lt;code&gt;run&lt;/code&gt; or &lt;code&gt;run_batch&lt;/code&gt;. The system will manage the state, chat template, and parallelism for you.&lt;/p&gt; &#xA;&lt;h3&gt;Control Flow&lt;/h3&gt; &#xA;&lt;p&gt;You can use any Python code within the function body, including control flow, nested function calls, and external libraries.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@sgl.function&#xA;def control_flow(s, question):&#xA;    s += &#34;To answer this question: &#34; + question + &#34;, &#34;&#xA;    s += &#34;I need to use a &#34; + sgl.gen(&#34;tool&#34;, choices=[&#34;calculator&#34;, &#34;web browser&#34;]) + &#34;. &#34;&#xA;&#xA;    if s[&#34;tool&#34;] == &#34;calculator&#34;:&#xA;        s += &#34;The math expression is&#34; + sgl.gen(&#34;expression&#34;)&#xA;    elif s[&#34;tool&#34;] == &#34;web browser&#34;:&#xA;        s += &#34;The website url is&#34; + sgl.gen(&#34;url&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Parallelism&lt;/h3&gt; &#xA;&lt;p&gt;Use &lt;code&gt;fork&lt;/code&gt; to launch parallel prompts. Because &lt;code&gt;sgl.gen&lt;/code&gt; is non-blocking, the for loop below issues two generation calls in parallel.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@sgl.function&#xA;def tip_suggestion(s):&#xA;    s += (&#xA;        &#34;Here are two tips for staying healthy: &#34;&#xA;        &#34;1. Balanced Diet. 2. Regular Exercise.\n\n&#34;&#xA;    )&#xA;&#xA;    forks = s.fork(2)&#xA;    for i, f in enumerate(forks):&#xA;        f += f&#34;Now, expand tip {i+1} into a paragraph:\n&#34;&#xA;        f += sgl.gen(f&#34;detailed_tip&#34;, max_tokens=256, stop=&#34;\n\n&#34;)&#xA;&#xA;    s += &#34;Tip 1:&#34; + forks[0][&#34;detailed_tip&#34;] + &#34;\n&#34;&#xA;    s += &#34;Tip 2:&#34; + forks[1][&#34;detailed_tip&#34;] + &#34;\n&#34;&#xA;    s += &#34;In summary&#34; + sgl.gen(&#34;summary&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Multi Modality&lt;/h3&gt; &#xA;&lt;p&gt;Use &lt;code&gt;sgl.image&lt;/code&gt; to pass an image as input.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@sgl.function&#xA;def image_qa(s, image_file, question):&#xA;    s += sgl.user(sgl.image(image_file) + question)&#xA;    s += sgl.assistant(sgl.gen(&#34;answer&#34;, max_tokens=256)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Constrained Decoding&lt;/h3&gt; &#xA;&lt;p&gt;Use &lt;code&gt;regex=&lt;/code&gt; to specify a regular expression as a decoding constraint.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@sgl.function&#xA;def regular_expression_gen(s):&#xA;    s += &#34;Q: What is the IP address of the Google DNS servers?\n&#34;&#xA;    s += &#34;A: &#34; + sgl.gen(&#xA;        &#34;answer&#34;,&#xA;        temperature=0,&#xA;        regex=r&#34;((25[0-5]|2[0-4]\d|[01]?\d\d?).){3}(25[0-5]|2[0-4]\d|[01]?\d\d?)&#34;,&#xA;    )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Batching&lt;/h3&gt; &#xA;&lt;p&gt;Use &lt;code&gt;run_batch&lt;/code&gt; to run a batch of requests with continuous batching.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@sgl.function&#xA;def text_qa(s, question):&#xA;    s += &#34;Q: &#34; + question + &#34;\n&#34;&#xA;    s += &#34;A:&#34; + sgl.gen(&#34;answer&#34;, stop=&#34;\n&#34;)&#xA;&#xA;states = text_qa.run_batch(&#xA;    [&#xA;        {&#34;question&#34;: &#34;What is the capital of the United Kingdom?&#34;},&#xA;        {&#34;question&#34;: &#34;What is the capital of France?&#34;},&#xA;        {&#34;question&#34;: &#34;What is the capital of Japan?&#34;},&#xA;    ],&#xA;    progress_bar=True&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Streaming&lt;/h3&gt; &#xA;&lt;p&gt;Add &lt;code&gt;stream=True&lt;/code&gt; to enable streaming.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@sgl.function&#xA;def text_qa(s, question):&#xA;    s += &#34;Q: &#34; + question + &#34;\n&#34;&#xA;    s += &#34;A:&#34; + sgl.gen(&#34;answer&#34;, stop=&#34;\n&#34;)&#xA;&#xA;states = text_qa.run(&#xA;    question=&#34;What is the capital of France?&#34;,&#xA;    temperature=0.1,&#xA;    stream=True&#xA;)&#xA;&#xA;for out in state.text_iter():&#xA;    print(out, end=&#34;&#34;, flush=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Backend: SGLang Runtime (SRT)&lt;/h2&gt; &#xA;&lt;p&gt;The SGLang Runtime (SRT) is designed to work best with the SGLang frontend. However, it can also be used as a standalone API server. In this case, the &lt;a href=&#34;https://arxiv.org/abs/2312.07104&#34;&gt;RadixAttention&lt;/a&gt; can still greatly accelerate many use cases with automatic KV cache reuse.&lt;/p&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;Launch a server&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m sglang.launch_server --model-path meta-llama/Llama-2-7b-chat-hf --port 30000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Send a request&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl http://localhost:30000/generate \&#xA;  -H &#34;Content-Type: application/json&#34; \&#xA;  -d &#39;{&#xA;    &#34;text&#34;: &#34;Once upon a time,&#34;,&#xA;    &#34;parameters&#34;: {&#xA;      &#34;max_new_tokens&#34;: 16,&#xA;      &#34;temperature&#34;: 0&#xA;    }&#xA;  }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Learn more about the argument format &lt;a href=&#34;https://raw.githubusercontent.com/sgl-project/sglang/main/docs/sampling_params.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;OpenAI Compatible API&lt;/h3&gt; &#xA;&lt;p&gt;In addition, the server supports an experimental OpenAI-compatible API.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import openai&#xA;client = openai.Client(&#xA;    base_url=&#34;http://127.0.0.1:30000/v1&#34;, api_key=&#34;EMPTY&#34;)&#xA;&#xA;# Text completion&#xA;response = client.completions.create(&#xA;&#x9;model=&#34;default&#34;,&#xA;&#x9;prompt=&#34;The capital of France is&#34;,&#xA;&#x9;temperature=0,&#xA;&#x9;max_tokens=32,&#xA;)&#xA;print(response)&#xA;&#xA;# Chat completion&#xA;response = client.chat.completions.create(&#xA;    model=&#34;default&#34;,&#xA;    messages=[&#xA;        {&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: &#34;You are a helpful AI assistant&#34;},&#xA;        {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;List 3 countries and their capitals.&#34;},&#xA;    ],&#xA;    temperature=0,&#xA;    max_tokens=64,&#xA;)&#xA;print(response)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In above example, the server uses the chat template specified in the model tokenizer. You can override the chat template if needed when launching the server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m sglang.launch_server --model-path meta-llama/Llama-2-7b-chat-hf --port 30000 --chat-template llama-2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the chat template you are looking for is missing, you are welcome to contribute it. Meanwhile, you can also temporary register your chat template as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;name&#34;: &#34;my_model&#34;,&#xA;  &#34;system&#34;: &#34;&amp;lt;|im_start|&amp;gt;system&#34;,&#xA;  &#34;user&#34;: &#34;&amp;lt;|im_start|&amp;gt;user&#34;,&#xA;  &#34;assistant&#34;: &#34;&amp;lt;|im_start|&amp;gt;assistant&#34;,&#xA;  &#34;sep_style&#34;: &#34;CHATML&#34;,&#xA;  &#34;sep&#34;: &#34;&amp;lt;|im_end|&amp;gt;&#34;,&#xA;  &#34;stop_str&#34;: [&#34;&amp;lt;|im_end|&amp;gt;&#34;, &#34;&amp;lt;|im_start|&amp;gt;&#34;]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m sglang.launch_server --model-path meta-llama/Llama-2-7b-chat-hf --port 30000 --chat-template ./my_model_template.json&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Additional Arguments&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Add &lt;code&gt;--tp 2&lt;/code&gt; to enable tensor parallelism.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m sglang.launch_server --model-path meta-llama/Llama-2-7b-chat-hf --port 30000 --tp 2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you see out-of-memory errors during serving, please try to reduce the memory usage of the KV cache pool by setting a smaller value of &lt;code&gt;--mem-fraction-static&lt;/code&gt;. The default value is &lt;code&gt;0.9&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m sglang.launch_server --model-path meta-llama/Llama-2-7b-chat-hf --port 30000 --mem-fraction-static 0.7&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Supported Models&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Llama&lt;/li&gt; &#xA; &lt;li&gt;Mistral&lt;/li&gt; &#xA; &lt;li&gt;Mixtral&lt;/li&gt; &#xA; &lt;li&gt;LLaVA &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;python3 -m sglang.launch_server --model-path liuhaotian/llava-v1.5-7b --tokenizer-path llava-hf/llava-1.5-7b-hf --port 30000&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;AWQ quantization&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Benchmark And Performance&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama-7B on NVIDIA A10G, FP16, Tensor Parallelism=1 &lt;img src=&#34;https://raw.githubusercontent.com/sgl-project/sglang/main/assets/llama_7b.jpg&#34; alt=&#34;llama_7b&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Mixtral-8x7B on NVIDIA A10G, FP16, Tensor Parallelism=8 &lt;img src=&#34;https://raw.githubusercontent.com/sgl-project/sglang/main/assets/mixtral_8x7b.jpg&#34; alt=&#34;mixtral_8x7b&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Learn more &lt;a href=&#34;https://raw.githubusercontent.com/sgl-project/sglang/main/docs/benchmark_results.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Function call APIs&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; S-LoRA&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Support more models&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Support more hardware backends&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation And Acknowledgment&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{zheng2023efficiently,&#xA;      title={Efficiently Programming Large Language Models using SGLang},&#xA;      author={Lianmin Zheng and Liangsheng Yin and Zhiqiang Xie and Jeff Huang and Chuyue Sun and Cody Hao Yu and Shiyi Cao and Christos Kozyrakis and Ion Stoica and Joseph E. Gonzalez and Clark Barrett and Ying Sheng},&#xA;      year={2023},&#xA;      eprint={2312.07104},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.AI}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We learned from the design and reused some code of the following projects: &lt;a href=&#34;https://github.com/guidance-ai/guidance&#34;&gt;Guidance&lt;/a&gt;, &lt;a href=&#34;https://github.com/vllm-project/vllm&#34;&gt;vLLM&lt;/a&gt;, &lt;a href=&#34;https://github.com/ModelTC/lightllm&#34;&gt;LightLLM&lt;/a&gt;, &lt;a href=&#34;https://github.com/flashinfer-ai/flashinfer&#34;&gt;FlashInfer&lt;/a&gt;, &lt;a href=&#34;https://github.com/outlines-dev/outlines&#34;&gt;Outlines&lt;/a&gt;, &lt;a href=&#34;https://github.com/eth-sri/lmql&#34;&gt;LMQL&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Vaibhavs10/open-tts-tracker</title>
    <updated>2024-01-20T01:26:08Z</updated>
    <id>tag:github.com,2024-01-20:/Vaibhavs10/open-tts-tracker</id>
    <link href="https://github.com/Vaibhavs10/open-tts-tracker" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;🗣️ Open TTS Tracker&lt;/h1&gt; &#xA;&lt;p&gt;A one stop shop to track all open-access/ source TTS models as they come out. Feel free to make a PR for all those that aren&#39;t linked here.&lt;/p&gt; &#xA;&lt;p&gt;This is aimed as a resource to increase awareness for these models and to make it easier for researchers, developers, and enthusiasts to stay informed about the latest advancements in the field.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;br&gt; This repo will only track open source/access codebase TTS models. More motivation for everyone to open-source! 🤗&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;GitHub&lt;/th&gt; &#xA;   &lt;th&gt;Weights&lt;/th&gt; &#xA;   &lt;th&gt;License&lt;/th&gt; &#xA;   &lt;th&gt;Fine-tune&lt;/th&gt; &#xA;   &lt;th&gt;Languages&lt;/th&gt; &#xA;   &lt;th&gt;Paper&lt;/th&gt; &#xA;   &lt;th&gt;Demo&lt;/th&gt; &#xA;   &lt;th&gt;Issues&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;XTTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/coqui-ai/TTS&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/coqui/XTTS-v2&#34;&gt;🤗 Hub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://coqui.ai/cpml&#34;&gt;CPML&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.coqui.ai/en/latest/models/xtts.html#training&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Multilingual&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://erogol.substack.com/p/xttsv2-notes&#34;&gt;Technical notes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/spaces/coqui/xtts&#34;&gt;🤗 Space&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TorToiSe TTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/neonbjb/tortoise-tts&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/jbetker/tortoise-tts-v2&#34;&gt;🤗 Hub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/neonbjb/tortoise-tts/raw/main/LICENSE&#34;&gt;Apache 2.0&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://git.ecker.tech/mrq/tortoise-tts&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;English&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.07243&#34;&gt;Technical report&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/spaces/Manmay/tortoise-tts&#34;&gt;🤗 Space&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;VITS/ MMS-TTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/transformers/tree/7142bdfa90a3526cfbed7483ede3afbef7b63939/src/transformers/models/vits&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/kakao-enterprise&#34;&gt;🤗 Hub&lt;/a&gt; / &lt;a href=&#34;https://huggingface.co/models?search=mms-tts&#34;&gt;MMS&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/transformers/raw/main/LICENSE&#34;&gt;Apache 2.0&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/ylacombe/finetune-hf-vits&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;English&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.06103&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/spaces/kakao-enterprise/vits&#34;&gt;🤗 Space&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Pheme&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/PolyAI-LDN/pheme&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/PolyAI/pheme&#34;&gt;🤗 Hub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/PolyAI-LDN/pheme/raw/main/LICENSE&#34;&gt;CC-BY&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/PolyAI-LDN/pheme#training&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;English&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2401.02839&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/spaces/PolyAI/pheme&#34;&gt;🤗 Space&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OpenVoice&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/myshell-ai/OpenVoice&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/myshell-ai/OpenVoice&#34;&gt;🤗 Hub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/myshell-ai/OpenVoice/raw/main/LICENSE&#34;&gt;CC-BY-NC 4.0&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;ZH + EN&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2312.01479&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/spaces/myshell-ai/OpenVoice&#34;&gt;🤗 Space&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;IMS-Toucan&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/DigitalPhonetics/IMS-Toucan&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/DigitalPhonetics/IMS-Toucan/tags&#34;&gt;GH release&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/DigitalPhonetics/IMS-Toucan/raw/ToucanTTS/LICENSE&#34;&gt;Apache 2.0&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/DigitalPhonetics/IMS-Toucan#build-a-toucantts-pipeline&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Multilingual&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2206.12229&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/spaces/Flux9665/IMS-Toucan&#34;&gt;🤗 Space&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Matcha-TTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/shivammehta25/Matcha-TTS&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/17C_gYgEHOxI5ZypcfE_k1piKCtyR0isJ&#34;&gt;GDrive&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/shivammehta25/Matcha-TTS/raw/main/LICENSE&#34;&gt;MIT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/shivammehta25/Matcha-TTS/tree/main#train-with-your-own-dataset&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;English&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.03199&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/spaces/shivammehta25/Matcha-TTS&#34;&gt;🤗 Space&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GPL-licensed phonemizer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;pflowTTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/p0p4k/pflowtts_pytorch&#34;&gt;Unofficial Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1x-A2Ezmmiz01YqittO_GLYhngJXazaF0&#34;&gt;GDrive&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/p0p4k/pflowtts_pytorch/raw/master/LICENSE&#34;&gt;MIT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/p0p4k/pflowtts_pytorch#instructions-to-run&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;English&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://openreview.net/pdf?id=zNA7u7wtIN&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Not Available&lt;/td&gt; &#xA;   &lt;td&gt;GPL-licensed phonemizer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;StyleTTS 2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/yl4579/StyleTTS2&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/yl4579/StyleTTS2-LibriTTS/tree/main&#34;&gt;🤗 Hub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/yl4579/StyleTTS2/raw/main/LICENSE&#34;&gt;MIT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/yl4579/StyleTTS2#finetuning&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;English&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.07691&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/spaces/styletts2/styletts2&#34;&gt;🤗 Space&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GPL-licensed phonemizer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;VALL-E&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enhuiz/vall-e&#34;&gt;Unofficial Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Not Available&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enhuiz/vall-e/raw/main/LICENSE&#34;&gt;MIT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enhuiz/vall-e#get-started&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;NA&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.02111&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Not Available&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;HierSpeech++&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/sh-lee-prml/HierSpeechpp&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1-L_90BlCkbPyKWWHTUjt5Fsu3kz0du0w&#34;&gt;GDrive&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/sh-lee-prml/HierSpeechpp/raw/main/LICENSE&#34;&gt;CC-BY-NC-SA 4.0&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;KR + EN&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2311.12454&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/spaces/LeeSangHoon/HierSpeech_TTS&#34;&gt;🤗 Space&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Bark&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/transformers/tree/main/src/transformers/models/bark&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/suno/bark&#34;&gt;🤗 Hub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/suno-ai/bark/raw/main/LICENSE&#34;&gt;MIT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;Multilingual&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.03143&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/spaces/suno/bark&#34;&gt;🤗 Space&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;EmotiVoice&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/netease-youdao/EmotiVoice&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1y6Xwj_GG9ulsAonca_unSGbJ4lxbNymM&#34;&gt;GDrive&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/netease-youdao/EmotiVoice/raw/main/LICENSE&#34;&gt;Apache 2.0&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/netease-youdao/EmotiVoice/wiki/Voice-Cloning-with-your-personal-data&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ZH + EN&lt;/td&gt; &#xA;   &lt;td&gt;Not Available&lt;/td&gt; &#xA;   &lt;td&gt;Not Available&lt;/td&gt; &#xA;   &lt;td&gt;Separate &lt;a href=&#34;https://github.com/netease-youdao/EmotiVoice/raw/main/EmotiVoice_UserAgreement_%E6%98%93%E9%AD%94%E5%A3%B0%E7%94%A8%E6%88%B7%E5%8D%8F%E8%AE%AE.pdf&#34;&gt;GUI agreement&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Amphion&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/open-mmlab/Amphion&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/amphion&#34;&gt;🤗 Hub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/open-mmlab/Amphion/raw/main/LICENSE&#34;&gt;MIT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;Multilingual&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2312.09911&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/amphion&#34;&gt;🤗 Space&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;xVASynth&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/DanRuta/xVA-Synth&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/DanRuta/xVA-Synth/tree/master/python/xvapitch/speaker_rep&#34;&gt;GH commit&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/DanRuta/xVA-Synth/raw/master/LICENSE.md&#34;&gt;GPL-3.0&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/DanRuta/xva-trainer&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Multilingual&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2009.14153&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Not Available&lt;/td&gt; &#xA;   &lt;td&gt;Copyright materials used for training.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OverFlow TTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/shivammehta25/OverFlow&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/shivammehta25/OverFlow/releases&#34;&gt;GitHub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/shivammehta25/OverFlow/raw/main/LICENSE&#34;&gt;MIT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/shivammehta25/OverFlow/tree/main?tab=readme-ov-file#setup-and-training-using-lj-speech&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;English&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.06892&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://shivammehta25.github.io/OverFlow/&#34;&gt;GH Pages&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Neural-HMM TTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/shivammehta25/Neural-HMM&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/shivammehta25/Neural-HMM/releases&#34;&gt;GitHub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/shivammehta25/Neural-HMM/raw/main/LICENSE&#34;&gt;MIT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/shivammehta25/Neural-HMM?tab=readme-ov-file#setup-and-training-using-lj-speech&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;English&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2108.13320&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://shivammehta25.github.io/Neural-HMM/&#34;&gt;GH Pages&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Tacotron 2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NVIDIA/tacotron2&#34;&gt;Unofficial Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1c5ZTuT7J08wLUoVZ2KkUs_VdZuJ86ZqA/view&#34;&gt;GDrive&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NVIDIA/tacotron2/raw/master/LICENSE&#34;&gt;BSD-3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/NVIDIA/tacotron2/tree/master?tab=readme-ov-file#training&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;English&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1712.05884&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://google.github.io/tacotron/publications/tacotron2/&#34;&gt;Webpage&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Glow-TTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/jaywalnut310/glow-tts&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1JiCMBVTG4BMREK8cT3MYck1MgYvwASL0/view&#34;&gt;GDrive&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/jaywalnut310/glow-tts/raw/master/LICENSE&#34;&gt;MIT&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/jaywalnut310/glow-tts?tab=readme-ov-file#2-pre-requisites&#34;&gt;Yes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;English&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.11129&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://jaywalnut310.github.io/glow-tts-demo/index.html&#34;&gt;GH Pages&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Silero&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/snakers4/silero-models&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/snakers4/silero-models/raw/master/models.yml&#34;&gt;GH links&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/snakers4/silero-models/raw/master/LICENSE&#34;&gt;CC BY-NC-SA&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/snakers4/silero-models/discussions/78&#34;&gt;No&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;EM + DE + ES + EA&lt;/td&gt; &#xA;   &lt;td&gt;Not Available&lt;/td&gt; &#xA;   &lt;td&gt;Not Available&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/snakers4/silero-models/wiki/Licensing-and-Tiers&#34;&gt;Non Commercial&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MahaTTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/dubverse-ai/MahaTTS&#34;&gt;Repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/Dubverse/MahaTTS&#34;&gt;🤗 Hub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/dubverse-ai/MahaTTS/raw/main/LICENSE&#34;&gt;Apache 2.0&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;English, Hindi, Indian English, Bengali, Tamil, Telugu, Punjabi, Marathi, Gujarati, Assamese&lt;/td&gt; &#xA;   &lt;td&gt;Not Available&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/dubverse-ai/MahaTTS/raw/main/README.md#sample-outputs&#34;&gt;Recordings&lt;/a&gt;, &lt;a href=&#34;https://colab.research.google.com/drive/1qkZz2km-PX75P0f6mUb2y5e-uzub27NW?usp=sharing&#34;&gt;Colab&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;How can you help?&lt;/h2&gt; &#xA;&lt;p&gt;Help make this list more complete. Create demos on the Hugging Face Hub and link them here :) Got any questions? Drop me a DM on Twitter &lt;a href=&#34;https://twitter.com/reach_vb&#34;&gt;@reach_vb&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ejoy/ant</title>
    <updated>2024-01-20T01:26:08Z</updated>
    <id>tag:github.com,2024-01-20:/ejoy/ant</id>
    <link href="https://github.com/ejoy/ant" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Ant game engine&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ant 游戏引擎&lt;/h1&gt; &#xA;&lt;p&gt;Ant 是由灵犀互娱开发的开源游戏引擎。现阶段仅将代码仓库公开，尚未正式发布。文档、示例等均待在 &lt;a href=&#34;https://github.com/ejoy/ant/wiki&#34;&gt;Wiki&lt;/a&gt; 上逐步完善。如有任何问题，可在 &lt;a href=&#34;https://github.com/ejoy/ant/discussions&#34;&gt;Discussions&lt;/a&gt; 发帖讨论。Issues 仅用于 Bug 跟踪，请不要在里面提问题。&lt;/p&gt; &#xA;&lt;h3&gt;更新并初始化第三方库：&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;git submodule update --init&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;搭建编译环境&lt;/h3&gt; &#xA;&lt;h4&gt;MSVC&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;安装Visual Studio&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;MINGW&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;下载并安装&lt;a href=&#34;https://www.msys2.org/&#34;&gt;msys2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;找到msys2安装目录，用mingw64.exe打开msys2的终端&lt;/li&gt; &#xA; &lt;li&gt;修改镜像服务器&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo &#34;Server = https://mirrors.tuna.tsinghua.edu.cn/msys2/mingw/i686/&#34; &amp;gt; /etc/pacman.d/mirrorlist.mingw32&#xA;echo &#34;Server = https://mirrors.tuna.tsinghua.edu.cn/msys2/mingw/x86_64/&#34; &amp;gt; /etc/pacman.d/mirrorlist.mingw64&#xA;echo &#34;Server = https://mirrors.tuna.tsinghua.edu.cn/msys2/msys/\$arch/&#34; &amp;gt; /etc/pacman.d/mirrorlist.msys&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;把ming64的路径加到环境变量&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo &#34;export MINGW=/mingw64&#34; &amp;gt;&amp;gt; ~/.bash_profile&#xA;echo &#34;export PATH=\$MINGW/bin:\$PATH&#34; &amp;gt;&amp;gt; ~/.bash_profile&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;安装gcc/ninja&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pacman -Syu mingw-w64-x86_64-gcc mingw-w64-x86_64-ninja&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;MACOS&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;安装xcode, ninja&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;编译&lt;/h3&gt; &#xA;&lt;h4&gt;编译构建工具 luamake&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/actboy168/luamake&#xA;cd luamake&#xA;git submodule update --init&#xA;.\compile\install.bat (msvc)&#xA;./compile/install.sh (mingw/linux/macos)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;编译runtime&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;luamake&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;编译tools&lt;/h4&gt; &#xA;&lt;p&gt;tools包含：shaderc, texturec, gltf2ozz，release模式会快一个数量级（debug模式下的tools可以不编译）&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;luamake -mode release tools&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;编译选项&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;luamake [target] -mode [debug/release] #-mode默认是debug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;运行&lt;/h3&gt; &#xA;&lt;p&gt;运行一个最简单的示例&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bin/msvc/debug/lua.exe test/simple/main.lua&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;启动编辑器&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bin/msvc/debug/lua.exe tools/editor/main.lua&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;调试&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;安装VSCode；&lt;/li&gt; &#xA; &lt;li&gt;安装&lt;strong&gt;Lua Debug&lt;/strong&gt;插件；&lt;/li&gt; &#xA; &lt;li&gt;添加调试配置到&lt;code&gt;.vscode/launch.json&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;    &#34;version&#34;: &#34;0.2.0&#34;,&#xA;    &#34;configurations&#34;: [&#xA;        {&#xA;            &#34;type&#34;: &#34;lua&#34;,&#xA;            &#34;request&#34;: &#34;launch&#34;,&#xA;            &#34;name&#34;: &#34;Debug&#34;,&#xA;            &#34;luaexe&#34;: &#34;${workspaceFolder}/bin/msvc/debug/lua.exe&#34;,&#xA;            &#34;console&#34;: &#34;integratedTerminal&#34;,&#xA;            &#34;stopOnEntry&#34;: true,&#xA;            &#34;outputCapture&#34;: [],&#xA;            &#34;program&#34;: &#34;test/simple/main.lua&#34;,&#xA;            &#34;arg&#34;: []&#xA;        }&#xA;    ]&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;关于ant目录结构&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;bin&lt;/strong&gt;：编译结果，exe/dll/lib等&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;build&lt;/strong&gt;：编译的中间结果&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;clibs&lt;/strong&gt;：c/c++代码&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;engine&lt;/strong&gt;：引擎基础支持代码，包括包管理器、启动代码等&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;pkg&lt;/strong&gt;：引擎的各个功能包（包与包之间有依赖）&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;runtime&lt;/strong&gt;：引擎运行时的不同平台支持&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;test&lt;/strong&gt;：测试工程&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;tools&lt;/strong&gt;：引擎相关的工具&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>