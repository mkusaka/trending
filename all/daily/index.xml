<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-29T01:23:17Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>fudan-generative-vision/champ</title>
    <updated>2024-03-29T01:23:17Z</updated>
    <id>tag:github.com,2024-03-29:/fudan-generative-vision/champ</id>
    <link href="https://github.com/fudan-generative-vision/champ" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;Center&#34;&gt;Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance&lt;/h1&gt; &#xA;&lt;div align=&#34;Center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/ShenhaoZhu&#34; target=&#34;_blank&#34;&gt;Shenhao Zhu&lt;/a&gt;&#xA; &lt;sup&gt;*1&lt;/sup&gt;â€ƒ &#xA; &lt;a href=&#34;https://github.com/Leoooo333&#34; target=&#34;_blank&#34;&gt;Junming Leo Chen&lt;/a&gt;&#xA; &lt;sup&gt;*2&lt;/sup&gt;â€ƒ &#xA; &lt;a href=&#34;https://github.com/daizuozhuo&#34; target=&#34;_blank&#34;&gt;Zuozhuo Dai&lt;/a&gt;&#xA; &lt;sup&gt;3&lt;/sup&gt;â€ƒ &#xA; &lt;a href=&#34;https://ai3.fudan.edu.cn/info/1088/1266.htm&#34; target=&#34;_blank&#34;&gt;Yinghui Xu&lt;/a&gt;&#xA; &lt;sup&gt;2&lt;/sup&gt;â€ƒ &#xA; &lt;a href=&#34;https://cite.nju.edu.cn/People/Faculty/20190621/i5054.html&#34; target=&#34;_blank&#34;&gt;Xun Cao&lt;/a&gt;&#xA; &lt;sup&gt;1&lt;/sup&gt;â€ƒ &#xA; &lt;a href=&#34;https://yoyo000.github.io/&#34; target=&#34;_blank&#34;&gt;Yao Yao&lt;/a&gt;&#xA; &lt;sup&gt;1&lt;/sup&gt;â€ƒ &#xA; &lt;a href=&#34;http://zhuhao.cc/home/&#34; target=&#34;_blank&#34;&gt;Hao Zhu&lt;/a&gt;&#xA; &lt;sup&gt;+1&lt;/sup&gt;â€ƒ &#xA; &lt;a href=&#34;https://sites.google.com/site/zhusiyucs/home&#34; target=&#34;_blank&#34;&gt;Siyu Zhu&lt;/a&gt;&#xA; &lt;sup&gt;+2&lt;/sup&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;Center&#34;&gt; &#xA; &lt;sup&gt;1&lt;/sup&gt;Nanjing University &#xA; &lt;sup&gt;2&lt;/sup&gt;Fudan University &#xA; &lt;sup&gt;3&lt;/sup&gt;Alibaba Group &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;Center&#34;&gt; &#xA; &lt;sup&gt;*&lt;/sup&gt;Equal Contribution &#xA; &lt;sup&gt;+&lt;/sup&gt;Corresponding Author &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;Center&#34;&gt; &#xA; &lt;a href=&#34;https://fudan-generative-vision.github.io/champ/#/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project-Page-Green&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://arxiv.org/abs/2403.14781&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Paper-Arxiv-red&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://youtu.be/2XVsy9tQRAY&#34;&gt;&lt;img src=&#34;https://badges.aleen42.com/src/youtube.svg?sanitize=true&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/fudan-generative-vision/champ/assets/82803297/b4571be6-dfb0-4926-8440-3db229ebd4aa&#34;&gt;https://github.com/fudan-generative-vision/champ/assets/82803297/b4571be6-dfb0-4926-8440-3db229ebd4aa&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Framework&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/fudan-generative-vision/champ/master/assets/framework.jpg&#34; alt=&#34;framework&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;System requirement: Ubuntu20.04&lt;/li&gt; &#xA; &lt;li&gt;Tested GPUs: A100, RTX3090&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Create conda environment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  conda create -n champ python=3.10&#xA;  conda activate champ&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install packages with &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Download pretrained models&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Download pretrained weight of base models:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/runwayml/stable-diffusion-v1-5&#34;&gt;StableDiffusion V1.5&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/stabilityai/sd-vae-ft-mse&#34;&gt;sd-vae-ft-mse&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/lambdalabs/sd-image-variations-diffusers/tree/main/image_encoder&#34;&gt;image_encoder&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Download our checkpoints: \&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Our &lt;a href=&#34;https://huggingface.co/fudan-generative-ai/champ/tree/main&#34;&gt;checkpoints&lt;/a&gt; consist of denoising UNet, guidance encoders, Reference UNet, and motion module.&lt;/p&gt; &#xA;&lt;p&gt;Finally, these pretrained models should be organized as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;./pretrained_models/&#xA;|-- champ&#xA;|   |-- denoising_unet.pth&#xA;|   |-- guidance_encoder_depth.pth&#xA;|   |-- guidance_encoder_dwpose.pth&#xA;|   |-- guidance_encoder_normal.pth&#xA;|   |-- guidance_encoder_semantic_map.pth&#xA;|   |-- reference_unet.pth&#xA;|   `-- motion_module.pth&#xA;|-- image_encoder&#xA;|   |-- config.json&#xA;|   `-- pytorch_model.bin&#xA;|-- sd-vae-ft-mse&#xA;|   |-- config.json&#xA;|   |-- diffusion_pytorch_model.bin&#xA;|   `-- diffusion_pytorch_model.safetensors&#xA;`-- stable-diffusion-v1-5&#xA;    |-- feature_extractor&#xA;    |   `-- preprocessor_config.json&#xA;    |-- model_index.json&#xA;    |-- unet&#xA;    |   |-- config.json&#xA;    |   `-- diffusion_pytorch_model.bin&#xA;    `-- v1-inference.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Inference&lt;/h1&gt; &#xA;&lt;p&gt;We have provided several sets of &lt;a href=&#34;https://huggingface.co/fudan-generative-ai/champ/tree/main&#34;&gt;example data&lt;/a&gt; for inference. Please first download and place them in the &lt;code&gt;example_data&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;p&gt;Here is the command for inference:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  python inference.py --config configs/inference.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Animation results will be saved in &lt;code&gt;results&lt;/code&gt; folder. You can change the reference image or the guidance motion by modifying &lt;code&gt;inference.yaml&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can also extract the driving motion from any videos and then render with Blender. We will later provide the instructions and scripts for this.&lt;/p&gt; &#xA;&lt;p&gt;Note: The default motion-01 in &lt;code&gt;inference.yaml&lt;/code&gt; has more than 500 frames and takes about 36GB VRAM. If you encounter VRAM issues, consider switching to other example data with less frames.&lt;/p&gt; &#xA;&lt;h1&gt;Acknowledgements&lt;/h1&gt; &#xA;&lt;p&gt;We thank the authors of &lt;a href=&#34;https://github.com/magic-research/magic-animate&#34;&gt;MagicAnimate&lt;/a&gt;, &lt;a href=&#34;https://github.com/HumanAIGC/AnimateAnyone&#34;&gt;Animate Anyone&lt;/a&gt;, and &lt;a href=&#34;https://github.com/guoyww/AnimateDiff&#34;&gt;AnimateDiff&lt;/a&gt; for their excellent work. Our project is built upon &lt;a href=&#34;https://github.com/MooreThreads/Moore-AnimateAnyone&#34;&gt;Moore-AnimateAnyone&lt;/a&gt;, and we are grateful for their open-source contributions.&lt;/p&gt; &#xA;&lt;h1&gt;Roadmap&lt;/h1&gt; &#xA;&lt;p&gt;Visit &lt;a href=&#34;https://github.com/fudan-generative-vision/champ/raw/master/docs/ROADMAP.md&#34;&gt;our roadmap&lt;/a&gt; to preview the future of Champ.&lt;/p&gt; &#xA;&lt;h1&gt;Citation&lt;/h1&gt; &#xA;&lt;p&gt;If you find our work useful for your research, please consider citing the paper:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{zhu2024champ,&#xA;      title={Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance},&#xA;      author={Shenhao Zhu and Junming Leo Chen and Zuozhuo Dai and Yinghui Xu and Xun Cao and Yao Yao and Hao Zhu and Siyu Zhu},&#xA;      year={2024},&#xA;      eprint={2403.14781},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Opportunities available&lt;/h1&gt; &#xA;&lt;p&gt;Multiple research positions are open at the &lt;strong&gt;Generative Vision Lab, Fudan University&lt;/strong&gt;! Include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Research assistant&lt;/li&gt; &#xA; &lt;li&gt;Postdoctoral researcher&lt;/li&gt; &#xA; &lt;li&gt;PhD candidate&lt;/li&gt; &#xA; &lt;li&gt;Master students&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Interested individuals are encouraged to contact us at &lt;a href=&#34;mailto://siyuzhu@fudan.edu.cn&#34;&gt;siyuzhu@fudan.edu.cn&lt;/a&gt; for further information.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>joaomdmoura/crewAI</title>
    <updated>2024-03-29T01:23:17Z</updated>
    <id>tag:github.com,2024-03-29:/joaomdmoura/crewAI</id>
    <link href="https://github.com/joaomdmoura/crewAI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/docs/crewai_logo.png&#34; alt=&#34;Logo of crewAI, two people rowing on a boat&#34;&gt;&lt;/p&gt; &#xA; &lt;h1&gt;&lt;strong&gt;crewAI&lt;/strong&gt;&lt;/h1&gt; &#xA; &lt;p&gt;ðŸ¤– &lt;strong&gt;crewAI&lt;/strong&gt;: Cutting-edge framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.&lt;/p&gt; &#xA; &lt;h3&gt; &lt;p&gt;&lt;a href=&#34;https://www.crewai.io/&#34;&gt;Homepage&lt;/a&gt; | &lt;a href=&#34;https://docs.crewai.com/&#34;&gt;Documentation&lt;/a&gt; | &lt;a href=&#34;https://chatg.pt/DWjSBZn&#34;&gt;Chat with Docs&lt;/a&gt; | &lt;a href=&#34;https://github.com/joaomdmoura/crewai-examples&#34;&gt;Examples&lt;/a&gt; | &lt;a href=&#34;https://discord.com/invite/X4JWnZnxPb&#34;&gt;Discord&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/joaomdmoura/crewAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/joaomdmoura/crewAI&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-green.svg?sanitize=true&#34; alt=&#34;License: MIT&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Table of contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/#why-crewai&#34;&gt;Why CrewAI?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/#getting-started&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/#key-features&#34;&gt;Key Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/#examples&#34;&gt;Examples&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/#quick-tutorial&#34;&gt;Quick Tutorial&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/#write-job-descriptions&#34;&gt;Write Job Descriptions&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/#trip-planner&#34;&gt;Trip Planner&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/#stock-analysis&#34;&gt;Stock Analysis&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/#connecting-your-crew-to-a-model&#34;&gt;Connecting Your Crew to a Model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/#how-crewai-compares&#34;&gt;How CrewAI Compares&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/#contribution&#34;&gt;Contribution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/#hire-crewai&#34;&gt;Hire CrewAI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/#telemetry&#34;&gt;Telemetry&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why CrewAI?&lt;/h2&gt; &#xA;&lt;p&gt;The power of AI collaboration has too much to offer. CrewAI is designed to enable AI agents to assume roles, share goals, and operate in a cohesive unit - much like a well-oiled crew. Whether you&#39;re building a smart assistant platform, an automated customer service ensemble, or a multi-agent research team, CrewAI provides the backbone for sophisticated multi-agent interactions.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To get started with CrewAI, follow these simple steps:&lt;/p&gt; &#xA;&lt;h3&gt;1. Installation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install crewai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to also install crewai-tools, which is a package with tools that can be used by the agents, but more dependencies, you can install it with, example bellow uses it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install &#39;crewai[tools]&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Setting Up Your Crew&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os&#xA;from crewai import Agent, Task, Crew, Process&#xA;from crewai_tools import SerperDevTool&#xA;&#xA;os.environ[&#34;OPENAI_API_KEY&#34;] = &#34;YOUR_API_KEY&#34;&#xA;os.environ[&#34;SERPER_API_KEY&#34;] = &#34;Your Key&#34; # serper.dev API key&#xA;&#xA;# You can choose to use a local model through Ollama for example. See https://docs.crewai.com/how-to/LLM-Connections/ for more information.&#xA;&#xA;# os.environ[&#34;OPENAI_API_BASE&#34;] = &#39;http://localhost:11434/v1&#39;&#xA;# os.environ[&#34;OPENAI_MODEL_NAME&#34;] =&#39;openhermes&#39;  # Adjust based on available model&#xA;# os.environ[&#34;OPENAI_API_KEY&#34;] =&#39;sk-111111111111111111111111111111111111111111111111&#39;&#xA;&#xA;search_tool = SerperDevTool()&#xA;&#xA;# Define your agents with roles and goals&#xA;researcher = Agent(&#xA;  role=&#39;Senior Research Analyst&#39;,&#xA;  goal=&#39;Uncover cutting-edge developments in AI and data science&#39;,&#xA;  backstory=&#34;&#34;&#34;You work at a leading tech think tank.&#xA;  Your expertise lies in identifying emerging trends.&#xA;  You have a knack for dissecting complex data and presenting actionable insights.&#34;&#34;&#34;,&#xA;  verbose=True,&#xA;  allow_delegation=False,&#xA;  tools=[search_tool]&#xA;  # You can pass an optional llm attribute specifying what mode you wanna use.&#xA;  # It can be a local model through Ollama / LM Studio or a remote&#xA;  # model like OpenAI, Mistral, Antrophic or others (https://docs.crewai.com/how-to/LLM-Connections/)&#xA;  #&#xA;  # import os&#xA;  # os.environ[&#39;OPENAI_MODEL_NAME&#39;] = &#39;gpt-3.5-turbo&#39;&#xA;  #&#xA;  # OR&#xA;  #&#xA;  # from langchain_openai import ChatOpenAI&#xA;  # llm=ChatOpenAI(model_name=&#34;gpt-3.5&#34;, temperature=0.7)&#xA;)&#xA;writer = Agent(&#xA;  role=&#39;Tech Content Strategist&#39;,&#xA;  goal=&#39;Craft compelling content on tech advancements&#39;,&#xA;  backstory=&#34;&#34;&#34;You are a renowned Content Strategist, known for your insightful and engaging articles.&#xA;  You transform complex concepts into compelling narratives.&#34;&#34;&#34;,&#xA;  verbose=True,&#xA;  allow_delegation=True&#xA;)&#xA;&#xA;# Create tasks for your agents&#xA;task1 = Task(&#xA;  description=&#34;&#34;&#34;Conduct a comprehensive analysis of the latest advancements in AI in 2024.&#xA;  Identify key trends, breakthrough technologies, and potential industry impacts.&#34;&#34;&#34;,&#xA;  expected_output=&#34;Full analysis report in bullet points&#34;,&#xA;  agent=researcher&#xA;)&#xA;&#xA;task2 = Task(&#xA;  description=&#34;&#34;&#34;Using the insights provided, develop an engaging blog&#xA;  post that highlights the most significant AI advancements.&#xA;  Your post should be informative yet accessible, catering to a tech-savvy audience.&#xA;  Make it sound cool, avoid complex words so it doesn&#39;t sound like AI.&#34;&#34;&#34;,&#xA;  expected_output=&#34;Full blog post of at least 4 paragraphs&#34;,&#xA;  agent=writer&#xA;)&#xA;&#xA;# Instantiate your crew with a sequential process&#xA;crew = Crew(&#xA;  agents=[researcher, writer],&#xA;  tasks=[task1, task2],&#xA;  verbose=2, # You can set it to 1 or 2 to different logging levels&#xA;)&#xA;&#xA;# Get your crew to work!&#xA;result = crew.kickoff()&#xA;&#xA;print(&#34;######################&#34;)&#xA;print(result)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In addition to the sequential process, you can use the hierarchical process, which automatically assigns a manager to the defined crew to properly coordinate the planning and execution of tasks through delegation and validation of results. &lt;a href=&#34;https://docs.crewai.com/core-concepts/Processes/&#34;&gt;See more about the processes here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Role-Based Agent Design&lt;/strong&gt;: Customize agents with specific roles, goals, and tools.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Autonomous Inter-Agent Delegation&lt;/strong&gt;: Agents can autonomously delegate tasks and inquire amongst themselves, enhancing problem-solving efficiency.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Flexible Task Management&lt;/strong&gt;: Define tasks with customizable tools and assign them to agents dynamically.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Processes Driven&lt;/strong&gt;: Currently only supports &lt;code&gt;sequential&lt;/code&gt; task execution and &lt;code&gt;hierarchical&lt;/code&gt; processes, but more complex processes like consensual and autonomous are being worked on.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Save output as file&lt;/strong&gt;: Save the output of individual tasks as a file, so you can use it later.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Parse output as Pydantic or Json&lt;/strong&gt;: Parse the output of individual tasks as a Pydantic model or as a Json if you want to.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Works with Open Source Models&lt;/strong&gt;: Run your crew using Open AI or open source models refer to the &lt;a href=&#34;https://docs.crewai.com/how-to/LLM-Connections/&#34;&gt;Connect crewAI to LLMs&lt;/a&gt; page for details on configuring your agents&#39; connections to models, even ones running locally!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/joaomdmoura/crewAI/main/docs/crewAI-mindmap.png&#34; alt=&#34;CrewAI Mind Map&#34; title=&#34;CrewAI Mind Map&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;You can test different real life examples of AI crews in the &lt;a href=&#34;https://github.com/joaomdmoura/crewAI-examples?tab=readme-ov-file&#34;&gt;crewAI-examples repo&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/joaomdmoura/crewAI-examples/tree/main/landing_page_generator&#34;&gt;Landing Page Generator&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.crewai.com/how-to/Human-Input-on-Execution&#34;&gt;Having Human input on the execution&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/joaomdmoura/crewAI-examples/tree/main/trip_planner&#34;&gt;Trip Planner&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/joaomdmoura/crewAI-examples/tree/main/stock_analysis&#34;&gt;Stock Analysis&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Quick Tutorial&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=tnejrr-0a94&#34; title=&#34;CrewAI Tutorial&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/tnejrr-0a94/maxresdefault.jpg&#34; alt=&#34;CrewAI Tutorial&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Write Job Descriptions&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/joaomdmoura/crewAI-examples/tree/main/job-posting&#34;&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=u98wEMz-9to&#34; title=&#34;Jobs postings&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/u98wEMz-9to/maxresdefault.jpg&#34; alt=&#34;Jobs postings&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Trip Planner&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/joaomdmoura/crewAI-examples/tree/main/trip_planner&#34;&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=xis7rWp-hjs&#34; title=&#34;Trip Planner&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/xis7rWp-hjs/maxresdefault.jpg&#34; alt=&#34;Trip Planner&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Stock Analysis&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/joaomdmoura/crewAI-examples/tree/main/stock_analysis&#34;&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=e0Uj4yWdaAg&#34; title=&#34;Stock Analysis&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/e0Uj4yWdaAg/maxresdefault.jpg&#34; alt=&#34;Stock Analysis&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Connecting Your Crew to a Model&lt;/h2&gt; &#xA;&lt;p&gt;crewAI supports using various LLMs through a variety of connection options. By default your agents will use the OpenAI API when querying the model. However, there are several other ways to allow your agents to connect to models. For example, you can configure your agents to use a local model via the Ollama tool.&lt;/p&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://docs.crewai.com/how-to/LLM-Connections/&#34;&gt;Connect crewAI to LLMs&lt;/a&gt; page for details on configuring you agents&#39; connections to models.&lt;/p&gt; &#xA;&lt;h2&gt;How CrewAI Compares&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Autogen&lt;/strong&gt;: While Autogen does good in creating conversational agents capable of working together, it lacks an inherent concept of process. In Autogen, orchestrating agents&#39; interactions requires additional programming, which can become complex and cumbersome as the scale of tasks grows.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;ChatDev&lt;/strong&gt;: ChatDev introduced the idea of processes into the realm of AI agents, but its implementation is quite rigid. Customizations in ChatDev are limited and not geared towards production environments, which can hinder scalability and flexibility in real-world applications.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;CrewAI&#39;s Advantage&lt;/strong&gt;: CrewAI is built with production in mind. It offers the flexibility of Autogen&#39;s conversational agents and the structured process approach of ChatDev, but without the rigidity. CrewAI&#39;s processes are designed to be dynamic and adaptable, fitting seamlessly into both development and production workflows.&lt;/p&gt; &#xA;&lt;h2&gt;Contribution&lt;/h2&gt; &#xA;&lt;p&gt;CrewAI is open-source and we welcome contributions. If you&#39;re looking to contribute, please:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fork the repository.&lt;/li&gt; &#xA; &lt;li&gt;Create a new branch for your feature.&lt;/li&gt; &#xA; &lt;li&gt;Add your feature or improvement.&lt;/li&gt; &#xA; &lt;li&gt;Send a pull request.&lt;/li&gt; &#xA; &lt;li&gt;We appreciate your input!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installing Dependencies&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;poetry lock&#xA;poetry install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Virtual Env&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;poetry shell&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Pre-commit hooks&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pre-commit install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running Tests&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;poetry run pytest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running static type checks&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;poetry run pyright&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Packaging&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;poetry build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Installing Locally&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install dist/*.tar.gz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Hire CrewAI&lt;/h2&gt; &#xA;&lt;p&gt;We&#39;re a company developing crewAI and crewAI Enterprise, we for a limited time are offer consulting with selected customers, to get them early access to our enterprise solution If you are interested on having access to it and hiring weekly hours with our team, feel free to email us at &lt;a href=&#34;mailto:joao@crewai.com&#34;&gt;joao@crewai.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Telemetry&lt;/h2&gt; &#xA;&lt;p&gt;CrewAI uses anonymous telemetry to collect usage data with the main purpose of helping us improve the library by focusing our efforts on the most used features, integrations and tools.&lt;/p&gt; &#xA;&lt;p&gt;There is NO data being collected on the prompts, tasks descriptions agents backstories or goals nor tools usage, no API calls, nor responses nor any data that is being processed by the agents, nor any secrets and env vars.&lt;/p&gt; &#xA;&lt;p&gt;Data collected includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Version of crewAI &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;So we can understand how many users are using the latest version&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Version of Python &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;So we can decide on what versions to better support&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;General OS (e.g. number of CPUs, macOS/Windows/Linux) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;So we know what OS we should focus on and if we could build specific OS related features&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Number of agents and tasks in a crew &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;So we make sure we are testing internally with similar use cases and educate people on the best practices&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Crew Process being used &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand where we should focus our efforts&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;If Agents are using memory or allowing delegation &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand if we improved the features or maybe even drop them&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;If Tasks are being executed in parallel or sequentially &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand if we should focus more on parallel execution&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Language model being used &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Improved support on most used languages&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Roles of agents in a crew &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand high level use cases so we can build better tools, integrations and examples about it&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Tools names available &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Understand out of the publically available tools, which ones are being used the most so we can improve them&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Users can opt-in sharing the complete telemetry data by setting the &lt;code&gt;share_crew&lt;/code&gt; attribute to &lt;code&gt;True&lt;/code&gt; on their Crews.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;CrewAI is released under the MIT License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>langchain4j/langchain4j-examples</title>
    <updated>2024-03-29T01:23:17Z</updated>
    <id>tag:github.com,2024-03-29:/langchain4j/langchain4j-examples</id>
    <link href="https://github.com/langchain4j/langchain4j-examples" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href=&#34;https://github.com/langchain4j/langchain4j&#34;&gt;LangChain4j&lt;/a&gt; Examples&lt;/h1&gt; &#xA;&lt;p&gt;This repository provides several examples using the LangChain4j library.&lt;/p&gt; &#xA;&lt;p&gt;A good place to start includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/langchain4j/langchain4j-examples/tree/main/tutorials/src/main/java&#34;&gt;Tutorials&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/langchain4j/langchain4j-examples/tree/main/other-examples/src/main/java&#34;&gt;More examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/langchain4j/langchain4j-examples/tree/main/rag-examples/src/main/java&#34;&gt;Examples of using advanced RAG techniques&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/langchain4j/langchain4j-examples/raw/5a19b723661530cf64846a256e2b01b060e7fb0b/customer-support-agent-example/src/main/java/dev/langchain4j/example/CustomerSupportAgentApplication.java#L39&#34;&gt;Example of an agent with memory, tools and RAG&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>