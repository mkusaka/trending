<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-09-29T01:28:45Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>nikitabobko/AeroSpace</title>
    <updated>2024-09-29T01:28:45Z</updated>
    <id>tag:github.com,2024-09-29:/nikitabobko/AeroSpace</id>
    <link href="https://github.com/nikitabobko/AeroSpace" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AeroSpace is an i3-like tiling window manager for macOS&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://raw.githubusercontent.com/nikitabobko/AeroSpace/main/resources/Assets.xcassets/AppIcon.appiconset/icon.png&#34; width=&#34;40%&#34; height=&#34;40%&#34; align=&#34;right&#34;&gt; &#xA;&lt;h1&gt;AeroSpace Beta &lt;a href=&#34;https://github.com/nikitabobko/AeroSpace/actions/workflows/build.yml&#34;&gt;&lt;img src=&#34;https://github.com/nikitabobko/AeroSpace/actions/workflows/build.yml/badge.svg?branch=main&#34; alt=&#34;Build&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;AeroSpace is an i3-like tiling window manager for macOS&lt;/p&gt; &#xA;&lt;p&gt;Videos:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=UOl7ErqWbrk&#34;&gt;YouTube 91 sec Demo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=-FoWClVHG5g&#34;&gt;YouTube Guide by Josean Martinez&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Docs:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nikitabobko.github.io/AeroSpace/guide&#34;&gt;AeroSpace Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nikitabobko.github.io/AeroSpace/commands&#34;&gt;AeroSpace Commands&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nikitabobko.github.io/AeroSpace/goodness&#34;&gt;AeroSpace Goodness&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Project status&lt;/h2&gt; &#xA;&lt;p&gt;Public Beta. AeroSpace can be used as a daily driver, but expect breaking changes until 1.0 is reached.&lt;/p&gt; &#xA;&lt;h2&gt;Key features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Tiling window manager based on a &lt;a href=&#34;https://nikitabobko.github.io/AeroSpace/guide#tree&#34;&gt;tree paradigm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://i3wm.org/&#34;&gt;i3&lt;/a&gt; inspired&lt;/li&gt; &#xA; &lt;li&gt;Fast workspaces switching without animations and without the necessity to disable SIP&lt;/li&gt; &#xA; &lt;li&gt;AeroSpace employs its &lt;a href=&#34;https://nikitabobko.github.io/AeroSpace/guide#emulation-of-virtual-workspaces&#34;&gt;own emulation of virtual workspaces&lt;/a&gt; instead of relying on native macOS Spaces due to &lt;a href=&#34;https://nikitabobko.github.io/AeroSpace/guide#emulation-of-virtual-workspaces&#34;&gt;their considerable limitations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Plain text configuration (dotfiles friendly). See: &lt;a href=&#34;https://nikitabobko.github.io/AeroSpace/guide#default-config&#34;&gt;default-config.toml&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CLI first (manpages and shell completion included)&lt;/li&gt; &#xA; &lt;li&gt;Doesn&#39;t require disabling SIP (System Integrity Protection)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nikitabobko.github.io/AeroSpace/guide#multiple-monitors&#34;&gt;Proper multi-monitor support&lt;/a&gt; (i3-like paradigm)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Install via &lt;a href=&#34;https://brew.sh/&#34;&gt;Homebrew&lt;/a&gt; to get autoupdates (Preferred)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;brew install --cask nikitabobko/tap/aerospace&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;(Optional)&lt;/strong&gt; You might need to configure your shell to enable completion provided by homebrew packages: &lt;a href=&#34;https://docs.brew.sh/Shell-Completion&#34;&gt;https://docs.brew.sh/Shell-Completion&lt;/a&gt; AeroSpace provides bash, fish and zsh completions.&lt;/p&gt; &#xA;&lt;p&gt;In multi-monitor setup please make sure that monitors &lt;a href=&#34;https://nikitabobko.github.io/AeroSpace/guide#proper-monitor-arrangement&#34;&gt;are properly arranged&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can also install specific previous versions:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;brew install --cask nikitabobko/tap/aerospace@0.12.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For the list of all the versions available for installation via brew see: &lt;a href=&#34;https://github.com/nikitabobko/homebrew-tap/tree/main/Casks&#34;&gt;https://github.com/nikitabobko/homebrew-tap/tree/main/Casks&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://nikitabobko.github.io/AeroSpace/guide#manual-installation&#34;&gt;Manual installation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] By using AeroSpace, you acknowledge that it&#39;s not &lt;a href=&#34;https://developer.apple.com/documentation/security/notarizing_macos_software_before_distribution&#34;&gt;notarized&lt;/a&gt;.&lt;/p&gt; &#xA; &lt;p&gt;Notarization is a &#34;security&#34; feature by Apple. You send binaries to Apple, and they either approve the binaries or not. In reality, notarization is about building binaries the way Apple likes it.&lt;/p&gt; &#xA; &lt;p&gt;Let&#39;s be honest. Tiling window manager is not something Apple will be totally ok with. Even if they approve one version, it doesn&#39;t mean that they won&#39;t revoke it (yes, they can do it), or approve further versions.&lt;/p&gt; &#xA; &lt;p&gt;I don&#39;t have anything against notarization as a concept. I specifically don&#39;t like the way Apple does notarization. I don&#39;t have time to fight Apple.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/nikitabobko/homebrew-tap/raw/main/Casks/aerospace.rb&#34;&gt;Homebrew installation script&lt;/a&gt; is configured to automatically delete &lt;code&gt;com.apple.quarantine&lt;/code&gt; attribute, that&#39;s why the app should work out of the box, without any warnings that &#34;Apple cannot check AeroSpace for malicious software&#34;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Contributing, creating issues, submitting pull requests&lt;/h2&gt; &#xA;&lt;p&gt;See: &lt;a href=&#34;https://raw.githubusercontent.com/nikitabobko/AeroSpace/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;p&gt;A notes on how to setup the project, build it, how to run the tests, etc. can be found here: &lt;a href=&#34;https://raw.githubusercontent.com/nikitabobko/AeroSpace/main/dev-docs/development.md&#34;&gt;dev-docs/development.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Project values&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Values&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;AeroSpace is targeted at advanced users and developers&lt;/li&gt; &#xA; &lt;li&gt;Keyboard centric&lt;/li&gt; &#xA; &lt;li&gt;Breaking changes (configuration files, CLI, behavior) are avoided as much as possible, but it must not let the software stagnate. Thus breaking changes can happen, but with careful considerations and helpful message. &lt;a href=&#34;https://semver.org/&#34;&gt;Semver&lt;/a&gt; major version is bumped in case of a breaking change (It&#39;s all guaranteed once AeroSpace reaches 1.0 version, until then breaking changes just happen)&lt;/li&gt; &#xA; &lt;li&gt;AeroSpace doesn&#39;t use GUI, unless necessarily &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;AeroSpace will never provide a GUI for configuration. For advanced users, it&#39;s easier to edit a configuration file in text editor rather than navigating through checkboxes in GUI.&lt;/li&gt; &#xA;   &lt;li&gt;Status menu icon is ok, because visual feedback is needed&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Provide &lt;em&gt;practical&lt;/em&gt; features. Fancy appearance features are not &lt;em&gt;practical&lt;/em&gt; (e.g. window borders, transparency, animations, etc.)&lt;/li&gt; &#xA; &lt;li&gt;If &#34;dark magic&#34; (aka &#34;private APIs&#34;, &#34;code injections&#34;, etc) can be avoided, it must be avoided &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Right now, AeroSpace uses only a single private API to get window ID of accessibility object &lt;code&gt;_AXUIElementGetWindow&lt;/code&gt;. Everything else is &lt;a href=&#34;https://developer.apple.com/documentation/applicationservices/axuielement_h&#34;&gt;macOS public accessibility API&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;AeroSpace will never require you to disable SIP (System Integrity Protection). For example, yabai &lt;a href=&#34;https://github.com/koekeishiya/yabai/issues/1863&#34;&gt;requires you to disable SIP&lt;/a&gt; to use some of its features. AeroSpace will either find another way (such as &lt;a href=&#34;https://nikitabobko.github.io/AeroSpace/guide#emulation-of-virtual-workspaces&#34;&gt;emulation of workspaces&lt;/a&gt;) or will not implement this feature at all (window transparency and window shadowing are not &lt;em&gt;practical&lt;/em&gt; features)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Non Values&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Play nicely with existing macOS features. If limitations are imposed then AeroSpace won&#39;t play nicely with existing macOS features (For example, AeroSpace doesn&#39;t acknowledge the existence of macOS Spaces, and it uses &lt;a href=&#34;https://nikitabobko.github.io/AeroSpace/guide#emulation-of-virtual-workspaces&#34;&gt;emulation of its own workspaces&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Tip of the day&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;defaults write -g NSWindowShouldDragOnGesture -bool true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Now, you can move windows by holding &lt;code&gt;ctrl&lt;/code&gt;+&lt;code&gt;cmd&lt;/code&gt; and dragging any part of the window (not necessarily the window title)&lt;/p&gt; &#xA;&lt;p&gt;Source: &lt;a href=&#34;https://www.reddit.com/r/MacOS/comments/k6hiwk/keyboard_modifier_to_simplify_click_drag_of/&#34;&gt;reddit&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Related projects&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ianyh/Amethyst&#34;&gt;Amethyst&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/koekeishiya/yabai&#34;&gt;yabai&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>huggingface/trl</title>
    <updated>2024-09-29T01:28:45Z</updated>
    <id>tag:github.com,2024-09-29:/huggingface/trl</id>
    <link href="https://github.com/huggingface/trl" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Train transformer language models with reinforcement learning.&lt;/p&gt;&lt;hr&gt;&lt;div style=&#34;text-align: center&#34;&gt; &#xA; &lt;img src=&#34;https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/trl_banner_dark.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;TRL - Transformer Reinforcement Learning&lt;/h1&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt; &lt;p&gt;Full stack library to post-train large language models.&lt;/p&gt; &lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/huggingface/trl/raw/main/LICENSE&#34;&gt; &lt;img alt=&#34;License&#34; src=&#34;https://img.shields.io/github/license/huggingface/trl.svg?color=blue&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://huggingface.co/docs/trl/index&#34;&gt; &lt;img alt=&#34;Documentation&#34; src=&#34;https://img.shields.io/website/http/huggingface.co/docs/trl/index.svg?down_color=red&amp;amp;down_message=offline&amp;amp;up_message=online&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/huggingface/trl/releases&#34;&gt; &lt;img alt=&#34;GitHub release&#34; src=&#34;https://img.shields.io/github/release/huggingface/trl.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;What is it?&lt;/h2&gt; &#xA;&lt;p&gt;TRL is a library to post-train LLMs and diffusion models with methods such as Supervised Fine-tuning (SFT), Proximal Policy Optimization (PPO), and Direct Preference Optimization (DPO).&lt;/p&gt; &#xA;&lt;p&gt;The library is built on top of &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;🤗 Transformers&lt;/a&gt; and is compatible with any model architecture available there.&lt;/p&gt; &#xA;&lt;h2&gt;Highlights&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;Efficient and scalable&lt;/code&gt;&lt;/strong&gt;: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/accelerate&#34;&gt;🤗 Accelerate&lt;/a&gt; is the backbone of TRL that model training to scale from a single GPU to a large scale multi-node cluster with methods such as DDP and DeepSpeed.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/peft&#34;&gt;&lt;code&gt;PEFT&lt;/code&gt;&lt;/a&gt; is fully integrated and allows to train even the largest models on modest hardware with quantisation and methods such as LoRA or QLoRA.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/unslothai/unsloth&#34;&gt;Unsloth&lt;/a&gt; is also integrated and allows to significantly speed up training with dedicated kernels.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;CLI&lt;/code&gt;&lt;/strong&gt;: With the &lt;a href=&#34;https://huggingface.co/docs/trl/clis&#34;&gt;CLI&lt;/a&gt; you can fine-tune and chat with LLMs without writing any code using a single command and a flexible config system.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;Trainers&lt;/code&gt;&lt;/strong&gt;: The trainer classes are an abstraction to apply many fine-tuning methods with ease such as the &lt;a href=&#34;https://huggingface.co/docs/trl/sft_trainer&#34;&gt;&lt;code&gt;SFTTrainer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/docs/trl/dpo_trainer&#34;&gt;&lt;code&gt;DPOTrainer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/docs/trl/reward_trainer&#34;&gt;&lt;code&gt;RewardTrainer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/docs/trl/ppov2_trainer&#34;&gt;&lt;code&gt;PPOTrainer&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&#34;https://huggingface.co/docs/trl/orpo_trainer&#34;&gt;&lt;code&gt;ORPOTrainer&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;AutoModels&lt;/code&gt;&lt;/strong&gt;: The &lt;a href=&#34;https://huggingface.co/docs/trl/models#trl.AutoModelForCausalLMWithValueHead&#34;&gt;&lt;code&gt;AutoModelForCausalLMWithValueHead&lt;/code&gt;&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://huggingface.co/docs/trl/models#trl.AutoModelForSeq2SeqLMWithValueHead&#34;&gt;&lt;code&gt;AutoModelForSeq2SeqLMWithValueHead&lt;/code&gt;&lt;/a&gt; classes add an additional value head to the model which allows to train them with RL algorithms such as PPO.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;Examples&lt;/code&gt;&lt;/strong&gt;: Fine-tune Llama for chat applications or apply full RLHF using adapters etc, following the &lt;a href=&#34;https://github.com/huggingface/trl/tree/main/examples&#34;&gt;examples&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Python package&lt;/h3&gt; &#xA;&lt;p&gt;Install the library with &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install trl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;From source&lt;/h3&gt; &#xA;&lt;p&gt;If you want to use the latest features before an official release you can install from source:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install git+https://github.com/huggingface/trl.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Repository&lt;/h3&gt; &#xA;&lt;p&gt;If you want to use the examples you can clone the repository with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/huggingface/trl.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Command Line Interface (CLI)&lt;/h2&gt; &#xA;&lt;p&gt;You can use TRL Command Line Interface (CLI) to quickly get started with Supervised Fine-tuning (SFT) and Direct Preference Optimization (DPO), or vibe check your model with the chat CLI:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;SFT:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;trl sft --model_name_or_path Qwen/Qwen2.5-0.5B --dataset_name trl-lib/Capybara --output_dir Qwen2.5-0.5B-SFT&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;DPO:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;trl dpo --model_name_or_path Qwen/Qwen2.5-0.5B-Instruct --dataset_name argilla/Capybara-Preferences --output_dir Qwen2.5-0.5B-DPO &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Chat:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;trl chat --model_name_or_path Qwen/Qwen2.5-0.5B-Instruct&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Read more about CLI in the &lt;a href=&#34;https://huggingface.co/docs/trl/main/en/clis&#34;&gt;relevant documentation section&lt;/a&gt; or use &lt;code&gt;--help&lt;/code&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;How to use&lt;/h2&gt; &#xA;&lt;p&gt;For more flexibility and control over training, TRL provides dedicated trainer classes to post-train language models or PEFT adapters on a custom dataset. Each trainer in TRL is a light wrapper around the 🤗 Transformers trainer and natively supports distributed training methods like DDP, DeepSpeed ZeRO, and FSDP.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;SFTTrainer&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Here is a basic example on how to use the &lt;code&gt;SFTTrainer&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from trl import SFTConfig, SFTTrainer&#xA;from datasets import load_dataset&#xA;&#xA;dataset = load_dataset(&#34;trl-lib/Capybara&#34;, split=&#34;train&#34;)&#xA;&#xA;training_args = SFTConfig(output_dir=&#34;Qwen/Qwen2.5-0.5B-SFT&#34;)&#xA;trainer = SFTTrainer(&#xA;    args=training_args,&#xA;    model=&#34;Qwen/Qwen2.5-0.5B&#34;,&#xA;    train_dataset=dataset,&#xA;)&#xA;trainer.train()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;&lt;code&gt;RewardTrainer&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Here is a basic example on how to use the &lt;code&gt;RewardTrainer&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from trl import RewardConfig, RewardTrainer&#xA;from datasets import load_dataset&#xA;from transformers import AutoModelForSequenceClassification, AutoTokenizer&#xA;&#xA;tokenizer = AutoTokenizer.from_pretrained(&#34;Qwen/Qwen2.5-0.5B-Instruct&#34;)&#xA;model = AutoModelForSequenceClassification.from_pretrained(&#xA;    &#34;Qwen/Qwen2.5-0.5B-Instruct&#34;, num_labels=1&#xA;)&#xA;model.config.pad_token_id = tokenizer.pad_token_id&#xA;&#xA;dataset = load_dataset(&#34;trl-lib/ultrafeedback_binarized&#34;, split=&#34;train&#34;)&#xA;&#xA;training_args = RewardConfig(output_dir=&#34;Qwen2.5-0.5B-Reward&#34;, per_device_train_batch_size=2)&#xA;trainer = RewardTrainer(&#xA;    args=training_args,&#xA;    model=model,&#xA;    tokenizer=tokenizer,&#xA;    train_dataset=dataset,&#xA;)&#xA;trainer.train()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;&lt;code&gt;RLOOTrainer&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;RLOOTrainer&lt;/code&gt; implements a &lt;a href=&#34;https://huggingface.co/papers/2402.14740&#34;&gt;REINFORCE-style optimization&lt;/a&gt; for RLHF that is more performant and memory-efficient than PPO. Here is a basic example of how to use the &lt;code&gt;RLOOTrainer&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from trl import RLOOConfig, RLOOTrainer, apply_chat_template&#xA;from datasets import load_dataset&#xA;from transformers import (&#xA;    AutoModelForCausalLM,&#xA;    AutoModelForSequenceClassification,&#xA;    AutoTokenizer,&#xA;)&#xA;&#xA;tokenizer = AutoTokenizer.from_pretrained(&#34;Qwen/Qwen2.5-0.5B-Instruct&#34;)&#xA;reward_model = AutoModelForSequenceClassification.from_pretrained(&#xA;    &#34;Qwen/Qwen2.5-0.5B-Instruct&#34;, num_labels=1&#xA;)&#xA;ref_policy = AutoModelForCausalLM.from_pretrained(&#34;Qwen/Qwen2.5-0.5B-Instruct&#34;)&#xA;policy = AutoModelForCausalLM.from_pretrained(&#34;Qwen/Qwen2.5-0.5B-Instruct&#34;)&#xA;&#xA;dataset = load_dataset(&#34;trl-lib/ultrafeedback-prompt&#34;)&#xA;dataset = dataset.map(apply_chat_template, fn_kwargs={&#34;tokenizer&#34;: tokenizer})&#xA;dataset = dataset.map(lambda x: tokenizer(x[&#34;prompt&#34;]), remove_columns=&#34;prompt&#34;)&#xA;&#xA;training_args = RLOOConfig(output_dir=&#34;Qwen2.5-0.5B-RL&#34;)&#xA;trainer = RLOOTrainer(&#xA;    config=training_args,&#xA;    tokenizer=tokenizer,&#xA;    policy=policy,&#xA;    ref_policy=ref_policy,&#xA;    reward_model=reward_model,&#xA;    train_dataset=dataset[&#34;train&#34;],&#xA;    eval_dataset=dataset[&#34;test&#34;],&#xA;)&#xA;trainer.train()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;&lt;code&gt;DPOTrainer&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;DPOTrainer&lt;/code&gt; implements the popular &lt;a href=&#34;https://huggingface.co/papers/2305.18290&#34;&gt;Direct Preference Optimization (DPO) algorithm&lt;/a&gt; that was used to post-train Llama 3 and many other models. Here is a basic example on how to use the &lt;code&gt;DPOTrainer&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from trl import DPOConfig, DPOTrainer, maybe_extract_prompt, maybe_apply_chat_template&#xA;from datasets import load_dataset&#xA;from transformers import AutoModelForCausalLM, AutoTokenizer&#xA;&#xA;tokenizer = AutoTokenizer.from_pretrained(&#34;Qwen/Qwen2.5-0.5B-Instruct&#34;)&#xA;model = AutoModelForCausalLM.from_pretrained(&#34;Qwen/Qwen2.5-0.5B-Instruct&#34;)&#xA;&#xA;dataset = load_dataset(&#34;trl-lib/Capybara-Preferences&#34;, split=&#34;train&#34;)&#xA;dataset = dataset.map(maybe_extract_prompt)&#xA;dataset = dataset.map(maybe_apply_chat_template, fn_kwargs={&#34;tokenizer&#34;: tokenizer})&#xA;&#xA;training_args = DPOConfig(output_dir=&#34;Qwen2.5-0.5B-DPO&#34;)&#xA;trainer = DPOTrainer(&#xA;    args=training_args,&#xA;    model=model,&#xA;    tokenizer=tokenizer,&#xA;    train_dataset=dataset,&#xA;)&#xA;trainer.train()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Development&lt;/h2&gt; &#xA;&lt;p&gt;If you want to contribute to &lt;code&gt;trl&lt;/code&gt; or customizing it to your needs make sure to read the &lt;a href=&#34;https://github.com/huggingface/trl/raw/main/CONTRIBUTING.md&#34;&gt;contribution guide&lt;/a&gt; and make sure you make a dev install:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/huggingface/trl.git&#xA;cd trl/&#xA;make dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{vonwerra2022trl,&#xA;  author = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},&#xA;  title = {TRL: Transformer Reinforcement Learning},&#xA;  year = {2020},&#xA;  publisher = {GitHub},&#xA;  journal = {GitHub repository},&#xA;  howpublished = {\url{https://github.com/huggingface/trl}}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>mediar-ai/screenpipe</title>
    <updated>2024-09-29T01:28:45Z</updated>
    <id>tag:github.com,2024-09-29:/mediar-ai/screenpipe</id>
    <link href="https://github.com/mediar-ai/screenpipe" rel="alternate"></link>
    <summary type="html">&lt;p&gt;24/7 local AI screen &amp; mic recording. Build AI apps that have the full context. Works with Ollama. Alternative to Rewind.ai. Open. Secure. You own your data. Rust.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://screenpi.pe&#34;&gt; &lt;img src=&#34;https://github.com/user-attachments/assets/d3b1de26-c3c0-4c84-b9c4-b03213b97a30&#34; alt=&#34;logo&#34; width=&#34;200&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;pre align=&#34;center&#34;&gt;&#xA;   ___  ___ _ __ ___  ___ _ __  _ __ (_)_ __   ___ &#xA;  / __|/ __| &#39;__/ _ \/ _ \ &#39;_ \| &#39;_ \| | &#39;_ \ / _ \&#xA;  \__ \ (__| | |  __/  __/ | | | |_) | | |_) |  __/&#xA;  |___/\___|_|  \___|\___|_| |_| .__/|_| .__/ \___|&#xA;                               |_|     |_|         &#xA;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://screenpi.pe&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Download%20The-Desktop%20App-blue?style=for-the-badge&#34; alt=&#34;Download the Desktop App&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.youtube.com/@mediar_ai&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/endpoint?style=for-the-badge&amp;amp;url=https%3A%2F%2Fyoutube-channel-badge.ngoldack.vercel.app%2Fapi%2Fsubscriber&#34; alt=&#34;Subs&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://discord.gg/dU9EBuw7Uq&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/823813159592001537?color=5865F2&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;Join us on Discord&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://twitter.com/screen_pipe&#34;&gt;&lt;img alt=&#34;X account&#34; src=&#34;https://img.shields.io/twitter/url/https/twitter.com/diffuserslib.svg?style=social&amp;amp;label=Follow%20%40screen_pipe&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://cal.com/louis030195/screenpipe&#34;&gt; &lt;img alt=&#34;Let&#39;s chat&#34; src=&#34;https://cal.com/book-with-cal-dark.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://screenpi.pe&#34;&gt; &lt;img alt=&#34;demo&#34; src=&#34;https://github.com/user-attachments/assets/39d27adc-e17e-4ca5-89c5-faf45a3ea20f&#34; width=&#34;800&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;em&gt;Latest News&lt;/em&gt; 🔥&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2024/09] 70 users run screenpipe 24/7!&lt;/li&gt; &#xA; &lt;li&gt;[2024/09] Released a v0 of our &lt;a href=&#34;https://docs.screenpi.pe/&#34;&gt;documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2024/08] Anyone can now &lt;a href=&#34;https://youtu.be/iCqHgZgQHyA?si=DjKJir7HfZoQKItK&#34;&gt;create, share, install pipes&lt;/a&gt; (plugins) from the app interface based on a github repo/dir&lt;/li&gt; &#xA; &lt;li&gt;[2024/08] We&#39;re running bounties! Contribute to screenpipe &amp;amp; make money, &lt;a href=&#34;https://github.com/mediar-ai/screenpipe/issues&#34;&gt;check issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2024/08] Audio input &amp;amp; output now works perfect on Windows, Linux, MacOS (&amp;lt;15.0). We also support multi monitor capture and defaulting STT to Whisper Distil large v3&lt;/li&gt; &#xA; &lt;li&gt;[2024/08] We released video embedding. AI gives you links to your video recording in the chat!&lt;/li&gt; &#xA; &lt;li&gt;[2024/08] We released the pipe store! Create, share, use plugins that get you the most out of your data in less than 30s, even if you are not technical.&lt;/li&gt; &#xA; &lt;li&gt;[2024/08] We released Apple &amp;amp; Windows Native OCR.&lt;/li&gt; &#xA; &lt;li&gt;[2024/08] &lt;strong&gt;The Linux desktop app is here!&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;[2024/07] &lt;strong&gt;The Windows desktop app is here! &lt;a href=&#34;https://screenpi.pe&#34;&gt;Get it now!&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;[2024/07] 🎁 Screenpipe won Friends (the AI necklace) hackathon at AGI House (integrations soon)&lt;/li&gt; &#xA; &lt;li&gt;[2024/07] &lt;strong&gt;We just launched the desktop app! &lt;a href=&#34;https://screenpi.pe&#34;&gt;Download now!&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;24/7 Screen &amp;amp; Audio Capture&lt;/h1&gt; &#xA;&lt;p&gt;Library to build personalized AI powered by what you&#39;ve seen, said, or heard. Works with Ollama. Alternative to Rewind.ai. Open. Secure. You own your data. Rust.&lt;br&gt; We are shipping daily, make suggestions, post bugs, &lt;a href=&#34;mailto:louis@screenpi.pe?subject=Screenpipe%20Feedback&amp;amp;body=I&#39;d%20like%20to%20use%20Screenpipe%20for%20...%0D%0A%0D%0AI%20cannot%20because%20of%20...%0D%0A%0D%0AWe%20can%20also%20have%20a%20call,%20book%20at%20https://cal.com/louis030195/screenpipe&#34;&gt;give feedback&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mediar-ai/screenpipe/main/content/diagram2.png&#34; alt=&#34;diagram&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Why?&lt;/h1&gt; &#xA;&lt;p&gt;Building a reliable stream of audio and screenshot data, where a user simply clicks a button and the script runs in the background 24/7, collecting and extracting data from screen and audio input/output, can be frustrating.&lt;/p&gt; &#xA;&lt;p&gt;There are numerous use cases that can be built on top of this layer. To simplify life for other developers, we decided to solve this non-trivial problem. It&#39;s still in its early stages, but it works end-to-end. We&#39;re working on this full-time and would love to hear your feedback and suggestions.&lt;/p&gt; &#xA;&lt;h2&gt;Get started&lt;/h2&gt; &#xA;&lt;p&gt;There are multiple ways to install screenpipe:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;as a CLI for technical users&lt;/li&gt; &#xA; &lt;li&gt;as a &lt;a href=&#34;https://screenpi.pe/onboarding&#34;&gt;paid desktop app&lt;/a&gt; with 1 year updates, priority support, and priority features&lt;/li&gt; &#xA; &lt;li&gt;as a free forever desktop app (but you need to build it yourself). We&#39;re 100% OSS.&lt;/li&gt; &#xA; &lt;li&gt;as a free forever desktop app - by sending a PR (&lt;a href=&#34;https://github.com/mediar-ai/screenpipe/issues/120#issuecomment-2275043418&#34;&gt;example&lt;/a&gt;) or &lt;a href=&#34;https://screenpi.pe/onboarding/free-community&#34;&gt;sharing about screenpipe online&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;as a Rust or WASM library - check this &lt;a href=&#34;https://github.com/mediar-ai/screenpipe/raw/main/screenpipe-vision/examples/websocket.rs&#34;&gt;websocket&lt;/a&gt; to stream frames + OCR to your app&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cal.com/louis030195/screenpipe-for-businesses&#34;&gt;as a business&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.screenpi.pe/docs/getting-started&#34;&gt;&lt;strong&gt;👉 install screenpipe now&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;usage&lt;/h2&gt; &#xA;&lt;p&gt;screenpipe has a plugin system called &#34;pipe&#34; which lets you run code in a sandboxed environment within the Rust code, &lt;a href=&#34;https://docs.screenpi.pe/docs/plugins&#34;&gt;get started&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;examples&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.screenpi.pe/docs/examples&#34;&gt;check examples&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;star history&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/533d4b26-e3b5-4b11-8cef-df17b3cd9197&#34; alt=&#34;GitHub Star History (1)&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are welcome! If you&#39;d like to contribute, please read &lt;a href=&#34;https://raw.githubusercontent.com/mediar-ai/screenpipe/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>