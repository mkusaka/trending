<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-27T01:24:08Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Enraged-Rabbit-Community/ERCF_v2</title>
    <updated>2023-12-27T01:24:08Z</updated>
    <id>tag:github.com,2023-12-27:/Enraged-Rabbit-Community/ERCF_v2</id>
    <link href="https://github.com/Enraged-Rabbit-Community/ERCF_v2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Community designed ERCF v2&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Enraged Rabbit Community Project&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Full_CAD.jpg&#34; alt=&#34;ERCFv2&#34; width=&#34;70%&#34;&gt; &lt;/p&gt;&#xA;&lt;h1 align=&#34;center&#34;&gt;ERCF v2 - RC1&lt;/h1&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; An expandable MMU for Klipper based 3D-Printers &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a aria-label=&#34;Downloads&#34; href=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/release/Enraged-Rabbit-Community/ERCF_v2?display_name=tag&amp;amp;style=flat-square&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a aria-label=&#34;Stars&#34; href=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/Enraged-Rabbit-Community/ERCF_v2?style=flat-square&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a aria-label=&#34;Forks&#34; href=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/Enraged-Rabbit-Community/ERCF_v2?style=flat-square&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;a aria-label=&#34;License&#34; href=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/Enraged-Rabbit-Community/ERCF_v2?style=flat-square&#34;&gt;&lt;/a&gt; &amp;nbsp; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Enraged_Rabbit_v2.png&#34; alt=&#34;RabbitV2&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt; This is a community born project and major update to the Voron ERCF MMU that was started a couple of years ago by Ette. It is endorsed by Ette and the guiding philosophy wasn&#39;t to start again with a new MMU design but to refine what has already proven to be a very capable machine and push it to be the best it can be by simplifying problematic construction, improving reliability and aligning as close as possible to v1.1 BOM. However the project includes an all new optional integrated filament buffer system (ERCT), filament cutter option (ERF), a collection of recommended toolhead sensor modifications and a bit of Bling! It fully leverages the Happy Hare firmware MMU control software with Klipper Screen entensions. &lt;p&gt; &lt;/p&gt;&lt;p&gt;There are a rapidly growing list of MMUs in the market place from the mass produced &#34;Fords&#34; who pioneered the market to the &#34;Toyota&#34; that are more recent efficient engineering feat but somehow lack soul. We consider ERCFv2 the &#34;BMW&#34; - a little over engineered perhaps but distinctively cool and you feel good driving it. We hope you enjoy! &amp;nbsp;&amp;nbsp; Videos: &lt;a href=&#34;https://www.youtube.com/watch?v=U2QwvPacIUk&#34;&gt;Teaser&lt;/a&gt; &amp;nbsp; &lt;a href=&#34;https://www.youtube.com/watch?v=EJCPerBsM3Q&#34;&gt;Release&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Table of Content&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#enraged-rabbit-carrot-feeder-ercf&#34;&gt;ERCF&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#enraged-rabbit-cotton-tail-erct&#34;&gt;ERCT&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#enraged-rabbit-filametrix-erf&#34;&gt;ERF&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#toolhead-sensor-modifications&#34;&gt;Toolhead Sensor Modifications&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#firmware&#34;&gt;Firmware&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#documentation&#34;&gt;Documentation&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#bom&#34;&gt;BOM&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#cad&#34;&gt;CAD&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#faq&#34;&gt;FAQ&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#acknowledgements&#34;&gt;Acknowledgements&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#vendors&#34;&gt;Vendors&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#changelog&#34;&gt;Changelog&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#build-photos&#34;&gt;Build Photos&lt;/a&gt;&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/#user-print-showroom&#34;&gt;Showroom&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;!--&#xA;**[FAQ](Assets/FAQ.md)&#xA;--&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Enraged Rabbit Carrot Feeder (ERCF)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;45%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/ERCFv2.png&#34;&gt;An MMU or Multimaterial Unit/Upgrade allows for the automatic change of filaments on your 3D printer. You can use it to create beautiful multi-colored prints or, if you&#39;re lazy, simply to avoid loading filament by hand. If you are familar with ERCF v1.1 this will serve as an overview of updates:&lt;/td&gt; &#xA;   &lt;td&gt; &#xA;    &lt;ol&gt; &#xA;     &lt;li&gt;Sturdy backbone - no more flex &lt;/li&gt;&#xA;     &lt;li&gt;Reliable (and custom) encoder design &lt;/li&gt;&#xA;     &lt;li&gt;Sprung servo instead of adjustable top hats &lt;/li&gt;&#xA;     &lt;li&gt;Innovative Filament trap in blocks instead of magnetic gates &lt;/li&gt;&#xA;     &lt;li&gt;Formal filament bypass &lt;/li&gt;&#xA;     &lt;li&gt;Reinforced gearbox assembly &lt;/li&gt;&#xA;     &lt;li&gt;Beautifully illustrated Manual &lt;/li&gt;&#xA;     &lt;li&gt;High Quality Step-by-step CAD &lt;/li&gt;&#xA;     &lt;li&gt;New integrated passive buffer system (Cotton Tail) &lt;/li&gt;&#xA;     &lt;li&gt;Perfect tips with Filametrix Filament cutter &lt;/li&gt;&#xA;     &lt;li&gt;Functional and asthetic LED status indication &lt;/li&gt;&#xA;    &lt;/ol&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Optional Enraged Rabbit Components&lt;/h2&gt; &#xA;&lt;h3&gt;Enraged Rabbit Cotton Tail (ERCT)&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Recommended_Options/ERCT_Buffer/Assets/heroimage_ERCT.png&#34; alt=&#34;ERCT&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt; When an MMU changes tool, the unloaded filament needs to be thoughtfully managed so that it doesn&#39;t tangle. The Enraged Rabbit Cotton Tail (ERCT) buffer system is designed to attach directly to ERCF V2. It is a passive system that optimizes space and is also designed to reduce resistance in the filament path, creating a consistent system for calibration. &lt;p&gt; &lt;/p&gt;&lt;p&gt;ERCT includes a pregate filament sensor to more reliably manage endless spools. It also incorporates a NEOpixel on each gate that, when driven by the Happy Hare firmware, provides functional feedback and the necessary &#34;bling!&#34; Enjoy!&lt;/p&gt; &lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Recommended_Options/ERCT_Buffer/README.md&#34;&gt;Read more&lt;/a&gt; &amp;nbsp;&amp;nbsp; Videos: &lt;a href=&#34;https://youtu.be/9jzB5Un6HKo&#34;&gt;Rear Loading&lt;/a&gt; &lt;a href=&#34;https://youtu.be/GlSXtUkd-b8&#34;&gt;Front Loading&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Enraged Rabbit Filametrix (ERF)&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; Before the MMU can unload a filament it must prepare the tip so that it can be cleanly loaded next time. This tip forming process is very difficult to tune and varies based on material type, temperature, hotend type and even weather! Introducing Enraged Rabbit Filametrix (ERF) filament cutting system. This lightweight addition to your Stealthburner toolhead adds a cutting blade. When retracting the problematic tip of the filament is simply cut off for perfect tips and no jams. &lt;p&gt; &lt;/p&gt;&lt;p&gt;ERF also supports an optional servo operated ganrtry activation pin so no print area is lost with this addition. ERF designs also include the recommended integrated toolhead sensor&lt;/p&gt; &lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Recommended_Options/ERF_Filament_Cutter/README.md&#34;&gt;Read more&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Recommended_Options/ERF_Filament_Cutter/Assets/ERF.png&#34; alt=&#34;ERF&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Toolhead Sensor Modifications&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; ERCF can be operated without a toolhead sensor (filament detection) in the toolhead but it is **not recommended**. A toolhead sensor provides an accurate homing point very close to the nozzle but also adds reliability to the tool change process. ERCF includes a set of toolhead sensor modifications for popular extruders. These work reliably through coupling a microswitch to the filament path. &lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Recommended_Options/Toolhead_Modifications/README.md&#34;&gt;Read more&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Purge System (ERPS)&lt;/h3&gt; &#xA;&lt;p&gt;Pellet purge system to remove the need for the wipe tower. Stay tuned.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Firmware&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34;&gt;&lt;img src=&#34;https://github.com/moggieuk/KlipperScreen-Happy-Hare-Edition/raw/master/docs/img/mmu/mmu_main.png&#34; alt=&#34;KlipperScreen&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt; ERCF is designed to be used with the Happy Hare MMU firmware for Klipper which adds a set of klipper extensions for configuration setup, testing and operation of ERCF. These commands are available through the command line or macros but are perhaps best operated with an interactive UI with the optional KlipperScreen extension. &lt;p&gt; &lt;/p&gt;&lt;p&gt;Happy Hare provides an easy installation script which has knowledge of recommended settings and will greatly accelarate the setup process.&lt;/p&gt; &lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/moggieuk/Happy-Hare/doc/ercf_v2.md&#34;&gt;Happy Hare&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://github.com/moggieuk/KlipperScreen-Happy-Hare-Edition&#34;&gt;KlipperScreen&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; Building something as complex as an MMU is a challenging undertaking but ERCFv2 project contains an amazingly detailed and illustrated manual with step-by-step instructions. We have tried to make the process similar to fitting together a jigsaw puzzle, albeit with a few optional pieces. &lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Documentation/ERCF_v2_Manual.pdf&#34;&gt;ERCFv2 PDF Manual&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Manual_Page.png&#34; alt=&#34;ERCF Manual&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;BOM&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/BOM.png&#34; alt=&#34;ERCF Project BOM&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt; You can find a Bill of Materials and a convenient printed parts tracker for the project and options here. Note that the BOM also contains an upgrade list for those of you wanting to use your existing ERCF v1.1 kits. Please make a copy and edit the &#34;Filament Blocks #&#34; to be the number of gates for your build. This can be any number but we encourage kit vendors to use 4/8/12 as size variations. Note that there are separate columns for core ERCF, the optional ERCT and ERF options as well as the suggested &#34;extras&#34; &lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://docs.google.com/spreadsheets/d/1HtVIu4yqzS6xJQr63-JKtMAh4Xq7wbtWPFeuiCnrnnE&#34;&gt;BOM&lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1h1bJurR6Z8Ou36c5U9cWmqI86tXKlWrcZrWrHgGN13A&#34;&gt;Printed Parts Tracker&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;CAD&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; A lot of work has gone into creating a quality CAD model of the project carefully organized into folders that match the documentation! It is hightly recommended that you open the CAD and hide every folder and then expose them one at a time as you work through the build. &lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/CAD&#34;&gt;Master CAD&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;30%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/CAD.png&#34; alt=&#34;ERCF Master CAD&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;p&gt;ERCF v2 is currently in the RC1 phase. That means that we hope the BOM and parts are complete but there are still some areas of polish needed: documentation, kit availability, etc. Therefore we&#39;re sure there will be lots of questions. To avoid repetition on the various support channels you can find a list of &lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/FAQ.md&#34;&gt;frequently asked questions&lt;/a&gt; here. If something isn&#39;t answered the best place to go is the primary &lt;a href=&#34;https://discord.com/channels/460117602945990666/909743915475816458&#34;&gt;Voron #ercf_questions&lt;/a&gt; Discord server&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;Most importantly let me introduce the development, test and doc team. A project like this doesn&#39;t happen without many hundreds of hours of volunteer effort and all of these folks are truely awesome. Please give some &lt;span&gt;👏&lt;/span&gt; &lt;span&gt;👏&lt;/span&gt; &lt;span&gt;👏&lt;/span&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;@moggieuk V0.1503 | V2.4088 (Mr Happy Hare &amp;amp; Chief whip) &lt;/li&gt;&#xA; &lt;li&gt;@gneu V2.5345 (Filament block &amp;amp; bling innovator) &lt;/li&gt;&#xA; &lt;li&gt;@sneakytreesnake V2.3804 (The project backbone!) &lt;/li&gt;&#xA; &lt;li&gt;@mneuhaus VT.483 (Mr Binky) &lt;/li&gt;&#xA; &lt;li&gt;@Miriax (Designer &amp;amp; Doc Demon) &lt;/li&gt;&#xA; &lt;li&gt;@kinematicdigit (Mr Cotton Tail &amp;amp; Doc Illustrator) &lt;/li&gt;&#xA; &lt;li&gt;@ningpj (Tester, Breaker &amp;amp; Documenter) &lt;/li&gt;&#xA; &lt;li&gt;@fizzy (King of CAD) &lt;/li&gt;&#xA; &lt;li&gt;@gsx8299 (Test Builder Extraordinaire) &lt;/li&gt;&#xA; &lt;li&gt;@sorted (Filametix &#34;don&#39;t get enraged&#34; filament cutting system) &lt;/li&gt;&#xA; &lt;li&gt;@kierantheman (Mr ThumperBlocks) &lt;/li&gt;&#xA; &lt;li&gt;@Fragmon (Videographer) &lt;/li&gt;&#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Vendors&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;25%&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Certified.jpg&#34; alt=&#34;Vendor Certification&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt; These kits and specialty parts have been checked by us and meet good quality standards: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;On the way... stay tuned! &lt;/li&gt; &#xA;    &lt;/ul&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Manufacturers:&lt;/strong&gt; &lt;em&gt;If you want to be included, please contact us. We are happy to validate your kit/parts and then add you to the list...&lt;/em&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Changelog&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;v2.0 rc1 - Initial Release (Merry Christmas!) &lt;/li&gt;&#xA;&lt;/ul&gt; &#xA;&lt;p&gt;CAD Design Guidelines used in this project (in case you were interested) can be found: &lt;a href=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Dev_Notes.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;i&gt; There once was a printer so keen,&lt;br&gt; To print in red, yellow, and green.&lt;br&gt; It whirred and it spun,&lt;br&gt; Mixing colors for fun,&lt;br&gt; The most vibrant prints ever seen! &lt;/i&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Build Photos&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/3d18d3fe-b8f0-4750-8b06-f487ab54ef35&#34; alt=&#34;20231116_230501&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/971ceefa-8946-438d-9de7-a26cfcdae56b&#34; alt=&#34;20231116_211032&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/5781d748-67eb-44f2-a793-cf8f4229b99f&#34; alt=&#34;20231116_214903&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/5df5f56e-9424-42d0-9985-a84c04d67c12&#34; alt=&#34;20231116_211045&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/ed578c32-6d4d-4698-8aeb-008a0cdf959e&#34; alt=&#34;20231116_230638&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/fde29ef8-6356-4a68-bd17-26fd160b5c9f&#34; alt=&#34;IMG_2446&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/bb66a3e3-326e-4866-97da-3e80767f3dc7&#34; alt=&#34;IMG_2448&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/1b943168-492d-44d6-ad12-038a6f12a8ca&#34; alt=&#34;IMG_2445&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/147fb32d-f3e4-4365-b579-de3997274053&#34; alt=&#34;IMG_2443&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/6d84f624-84b9-4a88-ad7c-de2a09619397&#34; alt=&#34;IMG_2444&#34;&gt; &lt;img src=&#34;https://github.com/Enraged-Rabbit-Community/ERCF_v2/assets/121695166/52122c6a-e28c-4bd7-a8a8-324b2cc9a74f&#34; alt=&#34;IMG_2447&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;User Print Showroom&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Showroom/Spidermans.png&#34; alt=&#34;Spidermans&#34; width=&#34;950&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Showroom/NoS_Prints.png&#34; alt=&#34;NoS_prints&#34; width=&#34;950&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Showroom/BnE_Prints.png&#34; alt=&#34;BnE_Prints&#34; width=&#34;950&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Showroom/Bimaterial_logo.png&#34; alt=&#34;Voron Logo TPU&#34; width=&#34;650&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Enraged-Rabbit-Community/ERCF_v2/master/Assets/Showroom/9_colors_test.png&#34; alt=&#34;9_colors_test&#34; width=&#34;400&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>JoeanAmier/TikTokDownloader</title>
    <updated>2023-12-27T01:24:08Z</updated>
    <id>tag:github.com,2023-12-27:/JoeanAmier/TikTokDownloader</id>
    <link href="https://github.com/JoeanAmier/TikTokDownloader" rel="alternate"></link>
    <summary type="html">&lt;p&gt;完全免费开源，基于 Requests 模块实现：TikTok 主页/视频/图集/原声；抖音主页/视频/图集/收藏/直播/原声/合集/评论/账号/搜索/热榜数据采集工具&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/JoeanAmier/TikTokDownloader/raw/master/static/images/TikTokDownloader.png&#34; alt=&#34;TikTokDownloader&#34; height=&#34;256&#34; width=&#34;256&#34;&gt;&#xA; &lt;br&gt; &#xA; &lt;h1&gt;TikTokDownloader&lt;/h1&gt; &#xA; &lt;img alt=&#34;GitHub&#34; src=&#34;https://img.shields.io/github/license/JoeanAmier/TikTokDownloader?style=for-the-badge&amp;amp;color=ff7a45&#34;&gt; &#xA; &lt;img alt=&#34;GitHub forks&#34; src=&#34;https://img.shields.io/github/forks/JoeanAmier/TikTokDownloader?style=for-the-badge&amp;amp;color=fa8c16&#34;&gt; &#xA; &lt;img alt=&#34;GitHub Repo stars&#34; src=&#34;https://img.shields.io/github/stars/JoeanAmier/TikTokDownloader?style=for-the-badge&amp;amp;color=ff4d4f&#34;&gt; &#xA; &lt;img alt=&#34;GitHub code size in bytes&#34; src=&#34;https://img.shields.io/github/languages/code-size/JoeanAmier/TikTokDownloader?style=for-the-badge&amp;amp;color=13c2c2&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;img alt=&#34;GitHub release (with filter)&#34; src=&#34;https://img.shields.io/github/v/release/JoeanAmier/TikTokDownloader?style=for-the-badge&amp;amp;color=f759ab&#34;&gt; &#xA; &lt;img src=&#34;https://img.shields.io/badge/Sourcery-enabled-884898?style=for-the-badge&amp;amp;color=1890ff&#34; alt=&#34;&#34;&gt; &#xA; &lt;img alt=&#34;GitHub all releases&#34; src=&#34;https://img.shields.io/github/downloads/JoeanAmier/TikTokDownloader/total?style=for-the-badge&amp;amp;color=52c41a&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;🔥 &lt;b&gt;TikTok 主页/视频/图集/原声；抖音主页/视频/图集/收藏/直播/原声/合集/评论/账号/搜索/热榜数据采集工具：&lt;/b&gt;完全开源，基于 Requests 模块实现的免费工具；批量下载抖音账号发布、喜欢、收藏作品；批量下载 TikTok 账号主页作品；下载抖音链接或 TikTok 链接作品；获取抖音直播推流地址；下载抖音直播视频；采集抖音作品评论数据；批量下载抖音合集作品；采集抖音账号详细数据；采集抖音用户 / 作品 / 直播搜索结果；采集抖音热榜数据。&lt;/p&gt; &#xA;&lt;p&gt;⭐ Windows 10 及以上用户可前往 &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/releases/latest&#34;&gt;Releases&lt;/a&gt; 下载已编译的 exe 程序，开箱即用！&lt;/p&gt; &#xA;&lt;p&gt;❤️ 作者仅在 GitHub 发布 TikTokDownloader，未与任何个人或网站合作，且没有任何收费计划！&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;📝 功能清单(Function)&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;✅ 下载抖音无水印视频/图集&lt;/li&gt; &#xA; &lt;li&gt;✅ 下载 TikTok 无水印视频/图集&lt;/li&gt; &#xA; &lt;li&gt;✅ 批量下载抖音账号发布/喜欢/收藏作品&lt;/li&gt; &#xA; &lt;li&gt;✅ 批量下载 TikTok 账号发布/喜欢作品&lt;/li&gt; &#xA; &lt;li&gt;✅ 采集抖音 / TikTok 详细数据&lt;/li&gt; &#xA; &lt;li&gt;✅ 批量下载链接作品&lt;/li&gt; &#xA; &lt;li&gt;✅ 多账号批量下载作品&lt;/li&gt; &#xA; &lt;li&gt;✅ 自动跳过已下载的文件&lt;/li&gt; &#xA; &lt;li&gt;✅ 持久化保存采集数据&lt;/li&gt; &#xA; &lt;li&gt;✅ 下载动态/静态封面图&lt;/li&gt; &#xA; &lt;li&gt;✅ 获取抖音直播推流地址&lt;/li&gt; &#xA; &lt;li&gt;✅ 调用 ffmpeg 下载直播&lt;/li&gt; &#xA; &lt;li&gt;✅ Web UI 交互界面&lt;/li&gt; &#xA; &lt;li&gt;✅ 采集抖音作品评论数据&lt;/li&gt; &#xA; &lt;li&gt;✅ 批量下载抖音合集作品&lt;/li&gt; &#xA; &lt;li&gt;✅ 记录点赞收藏等统计数据&lt;/li&gt; &#xA; &lt;li&gt;✅ 筛选作品发布时间&lt;/li&gt; &#xA; &lt;li&gt;✅ 支持账号作品增量下载&lt;/li&gt; &#xA; &lt;li&gt;✅ 支持使用代理采集数据&lt;/li&gt; &#xA; &lt;li&gt;✅ 支持局域网远程访问&lt;/li&gt; &#xA; &lt;li&gt;✅ 采集抖音账号详细数据&lt;/li&gt; &#xA; &lt;li&gt;✅ 作品统计数据更新&lt;/li&gt; &#xA; &lt;li&gt;✅ 自动更新账号昵称&lt;/li&gt; &#xA; &lt;li&gt;✅ 部署至私有服务器&lt;/li&gt; &#xA; &lt;li&gt;✅ 部署至公开服务器&lt;/li&gt; &#xA; &lt;li&gt;✅ 采集抖音搜索数据&lt;/li&gt; &#xA; &lt;li&gt;✅ 采集抖音热榜数据&lt;/li&gt; &#xA; &lt;li&gt;✅ 记录已下载作品 ID&lt;/li&gt; &#xA; &lt;li&gt;✅ 扫码登陆获取 Cookie&lt;/li&gt; &#xA; &lt;li&gt;✅ 支持 Web API 调用&lt;/li&gt; &#xA; &lt;li&gt;✅ 支持多线程下载作品&lt;/li&gt; &#xA; &lt;li&gt;✅ 文件完整性处理机制&lt;/li&gt; &#xA; &lt;li&gt;✅ 自定义规则筛选作品&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;💻 程序界面(Screenshot)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;终端命令行模式：&lt;/strong&gt; &lt;br&gt;&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/%E7%BB%88%E7%AB%AF%E6%A8%A1%E5%BC%8F%E6%88%AA%E5%9B%BE1.png&#34; alt=&#34;终端模式截图&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/%E7%BB%88%E7%AB%AF%E6%A8%A1%E5%BC%8F%E6%88%AA%E5%9B%BE2.png&#34; alt=&#34;终端模式截图&#34;&gt; &lt;br&gt;&lt;br&gt; &lt;strong&gt;Web UI 交互模式：&lt;/strong&gt; &lt;br&gt;&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/WebUI%E6%A8%A1%E5%BC%8F%E6%88%AA%E5%9B%BE1.png&#34; alt=&#34;WebUI模式截图&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/WebUI%E6%A8%A1%E5%BC%8F%E6%88%AA%E5%9B%BE2.png&#34; alt=&#34;WebUI模式截图&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/WebUI%E6%A8%A1%E5%BC%8F%E6%88%AA%E5%9B%BE3.png&#34; alt=&#34;WebUI模式截图&#34;&gt; &lt;br&gt;&lt;br&gt; &lt;strong&gt;Web API 接口模式：&lt;/strong&gt; &lt;br&gt;&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/WebAPI%E6%A8%A1%E5%BC%8F%E6%88%AA%E5%9B%BE.png&#34; alt=&#34;WebAPI模式截图&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;📽 运行演示(Example)&lt;/h1&gt; &#xA;&lt;h2&gt;批量下载账号发布作品&lt;/h2&gt; &#xA;&lt;p&gt;&lt;b&gt;🎥 点击图片观看演示视频，建议通过配置文件管理账号，更多介绍请查阅 &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/wiki/Documentation&#34;&gt;文档&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Nu4y1L7LW/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/%E7%A8%8B%E5%BA%8F%E8%BF%90%E8%A1%8C%E6%BC%94%E7%A4%BA.png&#34; alt=&#34;演示视频&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;📈 项目状态(Status)&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🟢 &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/releases/latest&#34;&gt;Releases&lt;/a&gt; 发布的源码已完成测试，所有功能均可正常使用&lt;/li&gt; &#xA; &lt;li&gt;🟢 正在重构项目代码，优化项目结构&lt;/li&gt; &#xA; &lt;li&gt;🟢 即将使用协程技术优化项目代码&lt;/li&gt; &#xA; &lt;li&gt;🟡 未来可能新增可视化编辑配置文件功能&lt;/li&gt; &#xA; &lt;li&gt;🟡 未来可能支持更多抖音热榜类型&lt;/li&gt; &#xA; &lt;li&gt;🟡 未来可能新增终端文本用户界面(TUI)模式&lt;/li&gt; &#xA; &lt;li&gt;🟡 未来可能支持全功能版的 Web UI 交互模式&lt;/li&gt; &#xA; &lt;li&gt;🟡 未来可能新增监听剪贴板下载作品功能&lt;/li&gt; &#xA; &lt;li&gt;🟡 未来可能新增账号新作品监测功能&lt;/li&gt; &#xA; &lt;li&gt;🟡 未来可能新增合集新作品监测功能&lt;/li&gt; &#xA; &lt;li&gt;🟡 未来可能新增直播开播监测功能&lt;/li&gt; &#xA; &lt;li&gt;🟡 未来可能新增调用 API 下载作品文件功能&lt;/li&gt; &#xA; &lt;li&gt;🟡 未来可能新增获取账号关注列表功能&lt;/li&gt; &#xA; &lt;li&gt;🟡 未来可能新增获取账号收藏合集列表功能&lt;/li&gt; &#xA; &lt;li&gt;🟡 未来可能优化 TikTok 平台批量下载功能&lt;/li&gt; &#xA; &lt;li&gt;🔴 最新版本的源码可能存在不稳定的 Bug&lt;/li&gt; &#xA; &lt;li&gt;🔴 如果在使用过程中发现程序 Bug，请及时告知作者修复&lt;/li&gt; &#xA; &lt;li&gt;🔴 发现 Cookie 会影响下载的视频作品文件分辨率&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;📋 项目说明(Instructions)&lt;/h1&gt; &#xA;&lt;h2&gt;快速入门&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;b&gt;下载 EXE 程序&lt;/b&gt; 或者 &lt;b&gt;配置运行环境&lt;/b&gt; &#xA;  &lt;ol&gt;&#xA;   &lt;b&gt;直接运行程序&lt;/b&gt; &#xA;   &lt;li&gt;下载 &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/releases/latest&#34;&gt;Releases&lt;/a&gt; 发布的 EXE 程序压缩包&lt;/li&gt; &#xA;   &lt;li&gt;解压后打开程序文件夹，双击运行 &lt;code&gt;main.exe&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &#xA;  &lt;ol&gt;&#xA;   &lt;b&gt;通过源码运行&lt;/b&gt; &#xA;   &lt;li&gt;安装不低于 &lt;code&gt;3.12&lt;/code&gt; 版本的 &lt;a href=&#34;https://www.python.org/&#34;&gt;Python&lt;/a&gt; 解释器&lt;/li&gt; &#xA;   &lt;li&gt;下载最新的源码或 &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/releases/latest&#34;&gt;Releases&lt;/a&gt; 发布的源码至本地&lt;/li&gt; &#xA;   &lt;li&gt;运行 &lt;code&gt;python -m venv venv&lt;/code&gt; 命令创建虚拟环境（可选）&lt;/li&gt; &#xA;   &lt;li&gt;运行 &lt;code&gt;.\venv\Scripts\activate.ps1&lt;/code&gt; 或者 &lt;code&gt;venv\Scripts\activate&lt;/code&gt; 命令激活虚拟环境（可选）&lt;/li&gt; &#xA;   &lt;li&gt;运行 &lt;code&gt;pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt&lt;/code&gt; 命令安装程序所需模块&lt;/li&gt; &#xA;   &lt;li&gt;运行 &lt;code&gt;python .\main.py&lt;/code&gt; 或者 &lt;code&gt;python main.py&lt;/code&gt; 命令启动 TikTokDownloader&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;阅读 TikTokDownloader 的免责声明，根据提示输入内容&lt;/li&gt; &#xA; &lt;li&gt;将 Cookie 信息写入配置文件 &#xA;  &lt;ol&gt;&#xA;   &lt;b&gt;手动复制粘贴(推荐)&lt;/b&gt; &#xA;   &lt;li&gt;参考 &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/raw/master/docs/Cookie%E6%95%99%E7%A8%8B.md&#34;&gt;Cookie 提取教程&lt;/a&gt;，复制所需 Cookie 至剪贴板&lt;/li&gt; &#xA;   &lt;li&gt;选择 &lt;code&gt;复制粘贴写入 Cookie&lt;/code&gt; 选项，按照提示将 Cookie 写入配置文件&lt;/li&gt; &#xA;  &lt;/ol&gt; &#xA;  &lt;ol&gt;&#xA;   &lt;b&gt;扫码登录获取&lt;/b&gt; &#xA;   &lt;li&gt;选择 &lt;code&gt;扫码登陆写入 Cookie&lt;/code&gt; 选项，程序会显示登录二维码图片，并使用默认应用打开图片&lt;/li&gt; &#xA;   &lt;li&gt;使用抖音 APP 扫描二维码并登录账号&lt;/li&gt; &#xA;   &lt;li&gt;按照提示操作，将 Cookie 写入配置文件&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;返回程序界面，依次选择 &lt;code&gt;终端命令行模式&lt;/code&gt; -&amp;gt; &lt;code&gt;批量下载链接作品&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;输入抖音或 TikTok 作品链接即可下载作品文件&lt;/li&gt; &#xA; &lt;li&gt;更多详细说明请查看 &lt;b&gt;&lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/wiki/Documentation&#34;&gt;项目文档&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;⭐ 推荐使用 &lt;a href=&#34;https://learn.microsoft.com/zh-cn/windows/terminal/install&#34;&gt;Windows 终端&lt;/a&gt;（Windows 11 自带默认终端）&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;关于 Cookie&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/raw/master/docs/Cookie%E6%95%99%E7%A8%8B.md&#34;&gt;点击查看 Cookie 获取教程&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;程序功能&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;是否需要登录&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;下载账号发布作品&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;⭕建议登录&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;下载账号喜欢作品&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;⭕建议登录&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;下载链接作品&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;⭕建议登录&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;获取直播推流地址&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;❌无需登录&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;下载直播视频&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;❌无需登录&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;获取作品评论数据&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;⭕建议登录&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;下载合集作品&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;⭕建议登录&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;获取账号数据&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;⭕建议登录&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;采集搜索结果&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;⭕建议登录&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;采集热榜数据&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;❌无需登录&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;下载账号收藏作品&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;✔️需要登录&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Cookie 仅需在失效后重新写入配置文件，并非每次运行程序都要写入配置文件！&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;程序获取数据失败时，可以尝试更新 Cookie 或者使用已登录的 Cookie！&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;其他说明&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;程序提示用户输入时，直接回车代表返回上级菜单，输入 &lt;code&gt;Q&lt;/code&gt; 或 &lt;code&gt;q&lt;/code&gt; 代表结束运行&lt;/li&gt; &#xA; &lt;li&gt;由于获取账号喜欢作品和收藏作品数据仅返回喜欢 / 收藏作品的发布日期，不返回操作日期，因此程序需要获取全部喜欢 / 收藏作品数据再进行日期筛选；如果作品数量较多，可能会花费较长的时间；可通过 &lt;code&gt;max_pages&lt;/code&gt; 参数控制请求次数&lt;/li&gt; &#xA; &lt;li&gt;获取私密账号的发布作品数据需要登录后的 Cookie，且登录的账号需要关注该私密账号&lt;/li&gt; &#xA; &lt;li&gt;批量下载账号作品或合集作品时，如果对应的昵称或标识发生变化，程序会自动更新已下载作品文件名称中的昵称和标识&lt;/li&gt; &#xA; &lt;li&gt;程序下载文件时会先将文件下载至临时文件夹，下载完成后再移动至储存文件夹；程序运行结束时会清空临时文件夹&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;批量下载收藏作品模式&lt;/code&gt; 目前仅支持下载当前已登录 Cookie 对应账号的收藏作品，暂不支持多账号&lt;/li&gt; &#xA; &lt;li&gt;如果想要程序使用代理，必须在 &lt;code&gt;settings.json&lt;/code&gt; 设置 &lt;code&gt;proxies&lt;/code&gt; 参数，否则程序不会使用代理&lt;/li&gt; &#xA; &lt;li&gt;部分使用者反馈，新发布的作品过早下载会下载到低分辨率的文件，一段时间后才能下载到高分辨率文件，但时间规律尚不明确&lt;/li&gt; &#xA; &lt;li&gt;退出程序时，请以正常方式结束运行或者按下 Ctrl + C 结束运行，不要直接点击终端窗口的关闭按钮结束运行，否则会导致数据丢失&lt;/li&gt; &#xA; &lt;li&gt;如果您的计算机没有合适的程序编辑 JSON 文件，建议使用 &lt;a href=&#34;https://try8.cn/tool/format/json&#34;&gt;JSON 在线工具&lt;/a&gt; 编辑配置文件内容&lt;/li&gt; &#xA; &lt;li&gt;当程序请求用户输入内容或链接时，请注意避免输入的内容或链接包含换行符，这可能会导致预期之外的问题&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;EXE 更新&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;方案一：&lt;/strong&gt; 下载并解压文件，将旧版本的 &lt;code&gt;cache&lt;/code&gt; 文件夹和 &lt;code&gt;settings.json&lt;/code&gt; 文件复制到 &lt;code&gt;_internal&lt;/code&gt; 文件夹。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;方案二：&lt;/strong&gt; 下载并解压文件，复制全部文件，直接覆盖旧版本文件。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;⚠️ 免责声明(Disclaimers)&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;使用者对本项目的使用由使用者自行决定，并自行承担风险。作者对使用者使用本项目所产生的任何损失、责任、或风险概不负责。&lt;/li&gt; &#xA; &lt;li&gt;本项目的作者提供的代码和功能是基于现有知识和技术的开发成果。作者尽力确保代码的正确性和安全性，但不保证代码完全没有错误或缺陷。&lt;/li&gt; &#xA; &lt;li&gt;使用者在使用本项目时必须严格遵守 &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/raw/master/license&#34;&gt;GNU General Public License v3.0&lt;/a&gt; 的要求，并在适当的地方注明使用了 &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/raw/master/license&#34;&gt;GNU General Public License v3.0&lt;/a&gt; 的代码。 &lt;/li&gt; &#xA; &lt;li&gt;使用者在任何情况下均不得将本项目的作者、贡献者或其他相关方与使用者的使用行为联系起来，或要求其对使用者使用本项目所产生的任何损失或损害负责。&lt;/li&gt; &#xA; &lt;li&gt;使用者在使用本项目的代码和功能时，必须自行研究相关法律法规，并确保其使用行为合法合规。任何因违反法律法规而导致的法律责任和风险，均由使用者自行承担。&lt;/li&gt; &#xA; &lt;li&gt;本项目的作者不会提供 TikTokDownloader 项目的付费版本，也不会提供与 TikTokDownloader 项目相关的任何商业服务。&lt;/li&gt; &#xA; &lt;li&gt;基于本项目进行的任何二次开发、修改或编译的程序与原创作者无关，原创作者不承担与二次开发行为或其结果相关的任何责任，使用者应自行对因二次开发可能带来的各种情况负全部责任。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;b&gt;在使用本项目的代码和功能之前，请您认真考虑并接受以上免责声明。如果您对上述声明有任何疑问或不同意，请不要使用本项目的代码和功能。如果您使用了本项目的代码和功能，则视为您已完全理解并接受上述免责声明，并自愿承担使用本项目的一切风险和后果。&lt;/b&gt; &#xA;&lt;h1&gt;✉️ 联系作者(Contact)&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;QQ: 2437596031（联系请说明来意）&lt;/li&gt; &#xA; &lt;li&gt;QQ Group: &lt;a href=&#34;https://github.com/JoeanAmier/TikTokDownloader/raw/master/docs/QQ%E7%BE%A4%E8%81%8A%E4%BA%8C%E7%BB%B4%E7%A0%81.png&#34;&gt;点击扫码加入群聊&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Email: yonglelolu@gmail.com&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt; &lt;b&gt;TikTokDownloader 是我个人独立维护的一个开源项目，鉴于个人精力有限，请理解项目进展可能较为缓慢，我会尽力保持更新和维护，以确保项目的稳定性和功能的不断改进。&lt;/b&gt; &lt;/p&gt; &#xA;&lt;p&gt; &lt;b&gt;如果您通过 Email 联系我，我可能无法及时查看并回复信息，我会尽力在七天内回复您的邮件；如果有紧急事项或需要更快的回复，请通过其他方式与我联系，谢谢理解！&lt;/b&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;b&gt;如果您对小红书感兴趣，可以了解一下我的另一个开源项目 &lt;a href=&#34;https://github.com/JoeanAmier/XHS-Downloader&#34;&gt;XHS-Downloader&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &#xA;&lt;h1&gt;♥️ 支持项目(Support)&lt;/h1&gt; &#xA;&lt;p&gt;如果 &lt;b&gt;TikTokDownloader&lt;/b&gt; 对您有帮助，请考虑为它点个 &lt;b&gt;Star&lt;/b&gt; ⭐，感谢您的支持！&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;微信(WeChat)&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;支付宝(Alipay)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;./docs/微信赞助二维码.png&#34; alt=&#34;微信赞助二维码&#34; height=&#34;200&#34; width=&#34;200&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;./docs/支付宝赞助二维码.png&#34; alt=&#34;支付宝赞助二维码&#34; height=&#34;200&#34; width=&#34;200&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;如果您愿意，可以考虑提供资助为 &lt;b&gt;TikTokDownloader&lt;/b&gt; 提供额外的支持！&lt;/p&gt; &#xA;&lt;h1&gt;💡 代码参考(Refer)&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Johnserf-Seed/f2&#34;&gt;https://github.com/Johnserf-Seed/f2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Johnserf-Seed/TikTokDownload&#34;&gt;https://github.com/Johnserf-Seed/TikTokDownload&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Evil0ctal/Douyin_TikTok_Download_API&#34;&gt;https://github.com/Evil0ctal/Douyin_TikTok_Download_API&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ihmily/DouyinLiveRecorder&#34;&gt;https://github.com/ihmily/DouyinLiveRecorder&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/davidteather/TikTok-Api&#34;&gt;https://github.com/davidteather/TikTok-Api&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/psf/requests&#34;&gt;https://github.com/psf/requests&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pallets/flask&#34;&gt;https://github.com/pallets/flask&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Textualize/rich&#34;&gt;https://github.com/Textualize/rich&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pyinstaller/pyinstaller&#34;&gt;https://github.com/pyinstaller/pyinstaller&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ffmpeg.org/ffmpeg-all.html&#34;&gt;https://ffmpeg.org/ffmpeg-all.html&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://html5up.net/hyperspace&#34;&gt;https://html5up.net/hyperspace&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>JShollaj/awesome-llm-interpretability</title>
    <updated>2023-12-27T01:24:08Z</updated>
    <id>tag:github.com,2023-12-27:/JShollaj/awesome-llm-interpretability</id>
    <link href="https://github.com/JShollaj/awesome-llm-interpretability" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A curated list of Large Language Model (LLM) Interpretability resources.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Awesome LLM Interpretability &lt;img src=&#34;https://github.com/your-username/awesome-llm-interpretability/workflows/Awesome%20Bot/badge.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;A curated list of amazingly awesome tools, papers, articles, and communities focused on Large Language Model (LLM) Interpretability.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JShollaj/awesome-llm-interpretability/main/#awesome-llm-interpretability&#34;&gt;Awesome LLM Interpretability&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JShollaj/awesome-llm-interpretability/main/#llm-interpretability-tools&#34;&gt;LLM Interpretability Tools&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JShollaj/awesome-llm-interpretability/main/#llm-interpretability-papers&#34;&gt;LLM Interpretability Papers&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JShollaj/awesome-llm-interpretability/main/#llm-interpretability-articles&#34;&gt;LLM Interpretability Articles&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/JShollaj/awesome-llm-interpretability/main/#llm-interpretability-groups&#34;&gt;LLM Interpretability Groups&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;LLM Interpretability Tools&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;Tools and libraries for LLM interpretability and analysis.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/FlorianDietz/comgra&#34;&gt;Comgra&lt;/a&gt; - Comgra helps you analyze and debug neural networks in pytorch.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/EleutherAI/pythia&#34;&gt;Pythia&lt;/a&gt; - Interpretability analysis to understand how knowledge develops and evolves during training in autoregressive transformers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Arize-ai/phoenix&#34;&gt;Phoenix&lt;/a&gt; - AI Observability &amp;amp; Evaluation - Evaluate, troubleshoot, and fine tune your LLM, CV, and NLP models in a notebook.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/automated-interpretability&#34;&gt;Automated Interpretability&lt;/a&gt; - Code for automatically generating, simulating, and scoring explanations of neuron behavior.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/BizarreCake/fmr.ai&#34;&gt;Fmr.ai&lt;/a&gt; - AI interpretability and explainability platform.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/clarkkev/attention-analysis&#34;&gt;Attention Analysis&lt;/a&gt; - Analyzing attention maps from BERT transformer.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mwatkins1970/SpellGPT&#34;&gt;SpellGPT&lt;/a&gt; - Explores GPT-3’s ability to spell own token strings.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/JetRunner/SuperICL&#34;&gt;SuperICL&lt;/a&gt; - Super In-Context Learning code which allows black-box LLMs to work with locally fine-tuned smaller models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/samuela/git-re-basin&#34;&gt;Git Re-Basin&lt;/a&gt; - Code release for &#34;Git Re-Basin: Merging Models modulo Permutation Symmetries.”&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MeetKai/functionary&#34;&gt;Functionary&lt;/a&gt; - Chat language model that can interpret and execute functions/plugins.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ai-safety-foundation/sparse_autoencoder&#34;&gt;Sparse Autoencoder&lt;/a&gt; - Sparse Autoencoder for Mechanistic Interpretability.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kmeng01/rome&#34;&gt;Rome&lt;/a&gt; - Locating and editing factual associations in GPT.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/inseq-team/inseq&#34;&gt;Inseq&lt;/a&gt; - Interpretability for sequence generation models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openaipublic.blob.core.windows.net/neuron-explainer/neuron-viewer/index.html&#34;&gt;Neuron Viewer&lt;/a&gt; - Tool for viewing neuron activations and explanations.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://bbycroft.net/llm&#34;&gt;LLM Visualization&lt;/a&gt; - Visualizing LLMs in low level.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vanna-ai/vanna&#34;&gt;Vanna&lt;/a&gt; - Abstractions to use RAG to generate SQL with any LLM&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;LLM Interpretability Papers&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;Academic and industry papers on LLM interpretability.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.01610&#34;&gt;Finding Neurons in a Haystack: Case Studies with Sparse Probing&lt;/a&gt; - Explores the representation of high-level human-interpretable features within neuron activations of large language models (LLMs).&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.04625&#34;&gt;Copy Suppression: Comprehensively Understanding an Attention Head&lt;/a&gt; - Investigates a specific attention head in GPT-2 Small, revealing its primary role in copy suppression.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.15154&#34;&gt;Linear Representations of Sentiment in Large Language Models&lt;/a&gt; - Shows how sentiment is represented in Large Language Models (LLMs), finding that sentiment is linearly represented in these models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.13382&#34;&gt;Emergent world representations: Exploring a sequence model trained on a synthetic task&lt;/a&gt; - Explores emergent internal representations in a GPT variant trained to predict legal moves in the board game Othello.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.14997&#34;&gt;Towards Automated Circuit Discovery for Mechanistic Interpretability&lt;/a&gt; - Introduces the Automatic Circuit Discovery (ACDC) algorithm for identifying important units in neural networks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.03025&#34;&gt;A Toy Model of Universality: Reverse Engineering How Networks Learn Group Operations&lt;/a&gt; - Examines small neural networks to understand how they learn group compositions, using representation theory.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2004.12265&#34;&gt;Causal Mediation Analysis for Interpreting Neural NLP: The Case of Gender Bias&lt;/a&gt; - Causal mediation analysis as a method for interpreting neural models in natural language processing.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.13506&#34;&gt;The Quantization Model of Neural Scaling&lt;/a&gt; - Proposes the Quantization Model for explaining neural scaling laws in neural networks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.03827&#34;&gt;Discovering Latent Knowledge in Language Models Without Supervision&lt;/a&gt; - Presents a method for extracting accurate answers to yes-no questions from language models&#39; internal activations without supervision.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.00586&#34;&gt;How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model&lt;/a&gt; - Analyzes mathematical capabilities of GPT-2 Small, focusing on its ability to perform the &#39;greater-than&#39; operation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://transformer-circuits.pub/2023/monosemantic-features/index.html&#34;&gt;Towards Monosemanticity: Decomposing Language Models With Dictionary Learning&lt;/a&gt; - Using a sparse autoencoder to decompose the activations of a one-layer transformer into interpretable, monosemantic features.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html&#34;&gt;Language models can explain neurons in language models&lt;/a&gt; - Explores how language models like GPT-4 can be used to explain the functioning of neurons within similar models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.00941&#34;&gt;Emergent Linear Representations in World Models of Self-Supervised Sequence Models&lt;/a&gt; - Linear representations in a world model of Othello-playing sequence models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=VJEcAnFPqC&#34;&gt;&#34;Toward a Mechanistic Understanding of Stepwise Inference in Transformers: A Synthetic Graph Navigation Model&#34;&lt;/a&gt; - Explores stepwise inference in autoregressive language models using a synthetic task based on navigating directed acyclic graphs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=kvcbV8KQsi&#34;&gt;&#34;Successor Heads: Recurring, Interpretable Attention Heads In The Wild&#34;&lt;/a&gt; - Introduces &#39;successor heads,&#39; attention heads that increment tokens with a natural ordering, such as numbers and days, in LLM’s.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=shr9PXz7T0&#34;&gt;&#34;Large Language Models Are Not Robust Multiple Choice Selectors&#34;&lt;/a&gt; - Analyzes the bias and robustness of LLMs in multiple-choice questions, revealing their vulnerability to option position changes due to inherent &#34;selection bias”.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=4bSQ3lsfEV&#34;&gt;&#34;Going Beyond Neural Network Feature Similarity: The Network Feature Complexity and Its Interpretation Using Category Theory&#34;&lt;/a&gt; - Presents a novel approach to understanding neural networks by examining feature complexity through category theory.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=v8L0pN6EOi&#34;&gt;&#34;Let&#39;s Verify Step by Step&#34;&lt;/a&gt; - Focuses on improving the reliability of LLMs in multi-step reasoning tasks using step-level human feedback.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=v675Iyu0ta&#34;&gt;&#34;Interpretability Illusions in the Generalization of Simplified Models&#34;&lt;/a&gt; - Examines the limitations of simplified representations (like SVD) used to interpret deep learning systems, especially in out-of-distribution scenarios.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=SQGUDc9tC8&#34;&gt;&#34;The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Language Models&#34;&lt;/a&gt; - Presents a novel approach for identifying and mitigating social biases in language models, introducing the concept of &#39;Social Bias Neurons&#39;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=VpCqrMMGVm&#34;&gt;&#34;Interpreting the Inner Mechanisms of Large Language Models in Mathematical Addition&#34;&lt;/a&gt; - Investigates how LLMs perform the task of mathematical addition.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openreview.net/forum?id=SznHfMwmjG&#34;&gt;&#34;Measuring Feature Sparsity in Language Models&#34;&lt;/a&gt; - Develops metrics to evaluate the success of sparse coding techniques in language model activations.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://transformer-circuits.pub/2022/toy_model/index.html&#34;&gt;Toy Models of Superposition&lt;/a&gt; - Investigates how models represent more features than dimensions, especially when features are sparse.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1711.08792&#34;&gt;Spine: Sparse interpretable neural embeddings&lt;/a&gt; - Presents SPINE, a method transforming dense word embeddings into sparse, interpretable ones using denoising autoencoders.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.15949&#34;&gt;Transformer visualization via dictionary learning: contextualized embedding as a linear superposition of transformer factors&lt;/a&gt; - Introduces a novel method for visualizing transformer networks using dictionary learning.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.11207&#34;&gt;Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling&lt;/a&gt; - Introduces Pythia, a toolset designed for analyzing the training and scaling behaviors of LLMs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zuva.ai/science/interpretability-and-feature-representations/&#34;&gt;On Interpretability and Feature Representations: An Analysis of the Sentiment Neuron&lt;/a&gt; - Critically examines the effectiveness of the &#34;Sentiment Neuron”.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.09169&#34;&gt;Engineering monosemanticity in toy models&lt;/a&gt; - Explores engineering monosemanticity in neural networks, where individual neurons correspond to distinct features.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.01892&#34;&gt;Polysemanticity and capacity in neural networks&lt;/a&gt; - Investigates polysemanticity in neural networks, where individual neurons represent multiple features.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://distill.pub/2020/circuits/early-vision/&#34;&gt;An Overview of Early Vision in InceptionV1&lt;/a&gt; - A comprehensive exploration of the initial five layers of the InceptionV1 neural network, focusing on early vision.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1906.02715&#34;&gt;Visualizing and measuring the geometry of BERT&lt;/a&gt; - Delves into BERT&#39;s internal representation of linguistic information, focusing on both syntactic and semantic aspects.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.04827&#34;&gt;Neurons in Large Language Models: Dead, N-gram, Positional&lt;/a&gt; - An analysis of neurons in large language models, focusing on the OPT family.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.11207&#34;&gt;Can Large Language Models Explain Themselves?&lt;/a&gt; - Evaluates the effectiveness of self-explanations generated by LLMs in sentiment analysis tasks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.00593&#34;&gt;Interpretability in the Wild: GPT-2 small (arXiv)&lt;/a&gt; - Provides a mechanistic explanation of how GPT-2 small performs indirect object identification (IOI) in natural language processing.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.11207&#34;&gt;Sparse Autoencoders Find Highly Interpretable Features in Language Models&lt;/a&gt; - Explores the use of sparse autoencoders to extract more interpretable and less polysemantic features from LLMs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.11207&#34;&gt;Emergent and Predictable Memorization in Large Language Models&lt;/a&gt; - Investigates the use of sparse autoencoders for enhancing the interpretability of features in LLMs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2312.01429&#34;&gt;Transformers are uninterpretable with myopic methods: a case study with bounded Dyck grammars&lt;/a&gt; - Demonstrates that focusing only on specific parts like attention heads or weight matrices in Transformers can lead to misleading interpretability claims.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.06824&#34;&gt;The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets&lt;/a&gt; - This paper investigates the representation of truth in Large Language Models (LLMs) using true/false datasets.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.08809&#34;&gt;Interpretability at Scale: Identifying Causal Mechanisms in Alpaca&lt;/a&gt; - This study presents Boundless Distributed Alignment Search (Boundless DAS), an advanced method for interpreting LLMs like Alpaca.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.01405&#34;&gt;Representation Engineering: A Top-Down Approach to AI Transparency&lt;/a&gt; - Introduces Representation Engineering (RepE), a novel approach for enhancing AI transparency, focusing on high-level representations rather than neurons or circuits.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.09863&#34;&gt;Explaining black box text modules in natural language with language models&lt;/a&gt; - Natural language explanations for LLM attention heads, evaluated using synthetic text&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.12918&#34;&gt;N2G: A Scalable Approach for Quantifying Interpretable Neuron Representations in Large Language Models&lt;/a&gt; - Explain each LLM neuron as a graph&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.11799&#34;&gt;Augmenting Interpretable Models with LLMs during Training&lt;/a&gt; - Use LLMs to build interpretable classifiers of text data&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;LLM Interpretability Articles&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;Insightful articles and blog posts on LLM interpretability.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.quantamagazine.org/a-new-approach-to-computation-reimagines-artificial-intelligence-20230413/?mc_cid=ad9a93c472&amp;amp;mc_eid=506130a407&#34;&gt;A New Approach to Computation Reimagines Artificial Intelligenceg&lt;/a&gt; - Discusses hyperdimensional computing, a novel method involving hyperdimensional vectors (hypervectors) for more efficient, transparent, and robust artificial intelligence.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens&#34;&gt;Interpreting GPT: the logit lens&lt;/a&gt; - Explores how the logit lens, reveals a gradual convergence of GPT&#39;s probabilistic predictions across its layers, from initial nonsensical or shallow guesses to more refined predictions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/N6WM6hs7RQMKDhYjB/a-mechanistic-interpretability-analysis-of-grokking&#34;&gt;A Mechanistic Interpretability Analysis of Grokking&lt;/a&gt; - Explores the phenomenon of &#39;grokking&#39; in deep learning, where models suddenly shift from memorization to generalization during training.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/s/yivyHaCAmMJ3CqSyj&#34;&gt;200 Concrete Open Problems in Mechanistic Interpretability&lt;/a&gt; - Series of posts discussing open research problems in the field of Mechanistic Interpretability (MI), which focuses on reverse-engineering neural networks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.cs.princeton.edu/~arvindn/talks/evaluating_llms_minefield/&#34;&gt;Evaluating LLMs is a minefield&lt;/a&gt; - Challenges in assessing the performance and biases of large language models (LLMs) like GPT.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.neelnanda.io/mechanistic-interpretability/attribution-patching&#34;&gt;Attribution Patching: Activation Patching At Industrial Scale&lt;/a&gt; - Method that uses gradients for a linear approximation of activation patching in neural networks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/JvZhhzycHu2Yd57RN/causal-scrubbing-a-method-for-rigorously-testing&#34;&gt;Causal Scrubbing: a method for rigorously testing interpretability hypotheses [Redwood Research]&lt;/a&gt; - Introduces causal scrubbing, a method for evaluating the quality of mechanistic interpretations in neural networks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/u6KXXmKFbXfWzoAXn/a-circuit-for-python-docstrings-in-a-4-layer-attention-only&#34;&gt;A circuit for Python docstrings in a 4-layer attention-only transformer&lt;/a&gt; - Proposes the Quantization Model for explaining neural scaling laws in neural networks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.03827&#34;&gt;Discovering Latent Knowledge in Language Models Without Supervision&lt;/a&gt; - Examines a specific neural circuit within a 4-layer transformer model responsible for generating Python docstrings.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2207.13243&#34;&gt;Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks&lt;/a&gt; - Survey on mechanistic interpretability&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;LLM Interpretability Groups&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;Communities and groups dedicated to LLM interpretability.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.com/invite/ad27GQgc7K&#34;&gt;Alignment Lab AI&lt;/a&gt; - Group of researchers focusing on AI alignment.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.com/invite/AVB9jkHZ&#34;&gt;Nous Research&lt;/a&gt; - Research group discussing various topics on interpretability.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.com/invite/4pEBpVTN&#34;&gt;EleutherAI&lt;/a&gt; - Non-profit AI research lab that focuses on interpretability and alignment of large models.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Contributing and Collaborating&lt;/h2&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://github.com/your-username/awesome-llm-interpretability/raw/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING&lt;/a&gt; and &lt;a href=&#34;https://github.com/your-username/awesome-llm-interpretability/raw/master/CODE-OF-CONDUCT.md&#34;&gt;CODE-OF-CONDUCT&lt;/a&gt; for details.&lt;/p&gt;</summary>
  </entry>
</feed>