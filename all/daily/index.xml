<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-02T01:30:38Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>satellitecomponent/Neurite</title>
    <updated>2023-06-02T01:30:38Z</updated>
    <id>tag:github.com,2023-06-02:/satellitecomponent/Neurite</id>
    <link href="https://github.com/satellitecomponent/Neurite" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A fractal mind-mapping tool with ai-integration.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Neurite&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://satellitecomponent.github.io/Neurite/&#34;&gt;https://satellitecomponent.github.io/Neurite/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;WARNING: Neurite contains zooming, flashing lights, and colors which may not be suitable for people with photosensitive epilepsy.&lt;/p&gt; &#xA;&lt;p&gt;Neurite opens up a new dimension of organization...&lt;/p&gt; &#xA;&lt;p&gt;...the fractal dimension....&lt;/p&gt; &#xA;&lt;p&gt;this is an open-source software in early alpha, we are looking to grow our team!&lt;/p&gt; &#xA;&lt;p&gt;join us on discord! &lt;a href=&#34;https://discord.gg/hnY8UpeE22&#34;&gt;https://discord.gg/hnY8UpeE22&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;How-to use Neurite&lt;/h1&gt; &#xA;&lt;p&gt;Neurite embeds text, photos, audio, video, pdfs, or any i-frame content onto a rendering of the Mandelbrot set.&lt;/p&gt; &#xA;&lt;p&gt;Files can be dragged and dropped into the fractal from your local files, or embed links can be copied and pasted onto the fractal. (Make sure its an embed link)&lt;/p&gt; &#xA;&lt;h1&gt;FractalGPT&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ai Driven Note Taking with embeddings.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Neurite has evolved into an advanced cognitive architecture for Large Language Models that runs directly in the browser.&lt;/p&gt; &#xA;&lt;p&gt;To interact with the Ai, you will need an OpenAi API key. (More LLM models to be supported in the future)&lt;/p&gt; &#xA;&lt;p&gt;The LLM‚Äôs responses format themselves into notes and connections within the fractal mind map, leading to an emergent graph structure that represents the AI‚Äôs memory.&lt;/p&gt; &#xA;&lt;p&gt;The Ai currently has the following capabilities...&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Auto Mode&lt;/li&gt; &#xA; &lt;li&gt;Node based memory retrieval that allows for long term conversation context.&lt;/li&gt; &#xA; &lt;li&gt;HTML/JS and In-browser Python (pyodide) environment for directly rendering GPT&#39;s code output.&lt;/li&gt; &#xA; &lt;li&gt;Web Search (requires google programmable search api key and search engine id) (to search without an API key, send a url within the prompt input and the webpage will display without going through Google.)&lt;/li&gt; &#xA; &lt;li&gt;Webpage and PDF text extraction. (requires setting up the &#39;scrape&#39; local-host server found in the repo)&lt;/li&gt; &#xA; &lt;li&gt;Wikipedia Summaries (Requires setting up the &#39;wiki-server&#39; found in the repo)&lt;/li&gt; &#xA; &lt;li&gt;Wolfram Alpha Results. (Requires an API key and setting up the &#39;wolfram-server&#39; in the repo)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;All API keys can be input through the Ai tab of the menu dropdown.&lt;/p&gt; &#xA;&lt;p&gt;We have recently included an Ai node funcitonality. Alt + Double click creates a node with a more traditional ai chat interface. (you can create multiple) The Ai node will retain the context for any other text or Ai nodes that are connected to it.&lt;/p&gt; &#xA;&lt;h1&gt;Local Server Setup&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To set up the Wikipedia, Wolfram, and web scrape servers, you will require Python and Node.js. You can find more info on setting up servers in the README for each server.&lt;/li&gt; &#xA; &lt;li&gt;Without any servers running, Wolfram, Wiki, and Webpage extractions will not function.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In the &#39;?&#39; tab, the AI HOW-TO checkbox will send a context message to the ai which allows it to answer questions about Neurite.&lt;/p&gt; &#xA;&lt;h1&gt;User Guide&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Search: Enter a search query to locate windows containing that text. A list of search results will display to the left of the menu. Click on a search result to zoom your view window to where the window is positioned and scaled within the Mandelbrot set (fractal).&lt;/li&gt; &#xA; &lt;li&gt;Saving: Saving is currently a work-in-progress. Text windows and connections between windows can be saved via the Settings tab. Non-textual content currently needs to be re-inserted.&lt;/li&gt; &#xA; &lt;li&gt;Zettelkasten: The Zettelkasten method enables nodes to be created by typing into the main text area. The ai follows this format to create and connect its responses together. This allows for a tree of thought reasoning process within the Mandelbrot set.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;The Future of Neurite&lt;/h1&gt; &#xA;&lt;p&gt;The app is a recursive environment to generate ideas. As we are in the middle of a rapid acceleration in AI developement, new tools to visualize and organize information will be become ever more necessary.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;VR&lt;/li&gt; &#xA; &lt;li&gt;deeper zoom&lt;/li&gt; &#xA; &lt;li&gt;color selection&lt;/li&gt; &#xA; &lt;li&gt;customizability/accessability&lt;/li&gt; &#xA; &lt;li&gt;auto embed formats&lt;/li&gt; &#xA; &lt;li&gt;custom equations for the fractal&lt;/li&gt; &#xA; &lt;li&gt;drawing-tool&lt;/li&gt; &#xA; &lt;li&gt;user feeback/bug fixes&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you are a developer who is intereested in contributing to this project, I would love to get in contact!&lt;/p&gt; &#xA;&lt;p&gt;contact us at &lt;a href=&#34;mailto:contactdendrite@gmail.com&#34;&gt;contactdendrite@gmail.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;or visit out discord &lt;a href=&#34;https://discord.gg/hnY8UpeE22&#34;&gt;https://discord.gg/hnY8UpeE22&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>dair-ai/ML-Papers-of-the-Week</title>
    <updated>2023-06-02T01:30:38Z</updated>
    <id>tag:github.com,2023-06-02:/dair-ai/ML-Papers-of-the-Week</id>
    <link href="https://github.com/dair-ai/ML-Papers-of-the-Week" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üî•Highlighting the top ML papers every week.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;strong&gt;ML Papers of The Week&lt;/strong&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://nlpnews.substack.com/&#34;&gt;Subscribe to our newsletter&lt;/a&gt; to get a weekly list of top ML papers in your inbox.&lt;/p&gt; &#xA;&lt;p&gt;At DAIR.AI we ‚ù§Ô∏è reading ML papers so we&#39;ve created this repo to highlight the top ML papers of every week.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week/raw/main/README.md#top-ml-papers-of-the-week-may-22-28&#34;&gt;Top ML Papers of the Week (May 22 - 28)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week/raw/main/README.md#top-ml-papers-of-the-week-may-15-21&#34;&gt;Top ML Papers of the Week (May 15 - 21)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week/raw/main/README.md#top-ml-papers-of-the-week-may-8-14&#34;&gt;Top ML Papers of the Week (May 8 - 14)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week/raw/main/README.md#top-ml-papers-of-the-week-may-1-7&#34;&gt;Top ML Papers of the Week (May 1-7)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week/raw/main/README.md#top-ml-papers-of-the-week-april-24---april-30&#34;&gt;Top ML Papers of the Week (April 24 - April 30)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week/raw/main/README.md#top-ml-papers-of-the-week-april-17---april-23&#34;&gt;Top ML Papers of the Week (April 17 - April 23)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week/raw/main/README.md#top-ml-papers-of-the-week-april-10---april-16&#34;&gt;Top ML Papers of the Week (April 10 - April 16)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-april-3---april-9&#34;&gt;Top ML Papers of the Week (April 3 - April 9)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-mar-27---april-2&#34;&gt;Top ML Papers of the Week (Mar 27 - April 2)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-mar-20-mar-26&#34;&gt;Top ML Papers of the Week (Mar 20-Mar 26)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-mar-13-mar-19&#34;&gt;Top ML Papers of the Week (Mar 13-Mar 19)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-mar-6-mar-12&#34;&gt;Top ML Papers of the Week (Mar 6-Mar 12)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-feb-27-mar-5&#34;&gt;Top ML Papers of the Week (Feb 27-Mar 5)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-feb-20-26&#34;&gt;Top ML Papers of the Week (Feb 20-26)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-feb-13---19&#34;&gt;Top ML Papers of the Week (Feb 13 - 19)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-feb-6---12&#34;&gt;Top ML Papers of the Week (Feb 6 - 12)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-jan-30-feb-5&#34;&gt;Top ML Papers of the Week (Jan 30-Feb 5)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-jan-23-29&#34;&gt;Top ML Papers of the Week (Jan 23-29)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-jan-16-22&#34;&gt;Top ML Papers of the Week (Jan 16-22)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-jan-9-15&#34;&gt;Top ML Papers of the Week (Jan 9-15)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-jan-1-8&#34;&gt;Top ML Papers of the Week (Jan 1-8)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/dair_ai&#34;&gt;Follow us on Twitter&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/SKgkVT8BGJ&#34;&gt;Join our Discord&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (May 22-28)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;QLoRA&lt;/strong&gt; - an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning performance.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.14314&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/Tim_Dettmers/status/1661379354507476994?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;LIMA&lt;/strong&gt; - a new 65B parameter LLaMa model fine-tuned on 1000 carefully curated prompts and responses; it doesn&#39;t use RLHF, generalizes well to unseen tasks not available in the training data, and generates responses equivalent or preferred to GPT-4 in 43% of cases, and even higher compared to Bard.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.11206&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/violet_zct/status/1660789120069926912?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;Voyager&lt;/strong&gt; - an LLM-powered embodied lifelong learning agent in Minecraft that can continuously explore worlds, acquire skills, and make novel discoveries without human intervention.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.16291&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/DrJimFan/status/1662115266933972993?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;Gorilla&lt;/strong&gt; - a finetuned LLaMA-based model that surpasses GPT-4 on writing API calls. This capability can help identify the right API, boosting the ability of LLMs to interact with external tools to complete specific tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.15334&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/omarsar0/status/1661540207206846464?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5. &lt;strong&gt;The False Promise of Imitating Proprietary LLMs&lt;/strong&gt; - provides a critical analysis of models that are finetuned on the outputs of a stronger model; argues that model imitation is a false premise and that the higher leverage action to improve open source models is to develop better base models.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.15717&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/arankomatsuzaki/status/1661908342829187072?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;Sophia&lt;/strong&gt; - presents a simple scalable second-order optimizer that has negligible average per-step time and memory overhead; on language modeling, Sophia achieves 2x speed-up compared to Adam in the number of steps, total compute, and wall-clock time.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.14342&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/tengyuma/status/1661412995430219786?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;The Larger They Are, the Harder They Fail&lt;/strong&gt; - shows that LLMs fail to generate correct Python code when default function names are swapped; they also strongly prefer incorrect continuation as they become bigger.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.15507&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/AVMiceliBarone/status/1662150656327663617?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;Model Evaluation for Extreme Risks&lt;/strong&gt; - discusses the importance of model evaluation for addressing extreme risks and making responsible decisions about model training, deployment, and security.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.15324&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/soundboy/status/1661728733156503555?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;LLM Research Directions&lt;/strong&gt; - discusses a list of research directions for students looking to do research with LLMs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.12544&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/omarsar0/status/1661405738059571201?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;Reinventing RNNs for the Transformer Era&lt;/strong&gt; - proposes an approach that combines the efficient parallelizable training of Transformers with the efficient inference of RNNs; results show that the method performs on part with similarly sized Transformers.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.13048&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/_akhaliq/status/1660816265454419969?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (May 15-21)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold&lt;/strong&gt; - an approach for controlling GANs that allows dragging points of the image to precisely reach target points in a user-interactive manner.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.10973v1&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1660268470057967616?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Evidence of Meaning in Language Models Trained on Programs&lt;/strong&gt; - argues that language models can learn meaning despite being trained only to perform next token prediction on text.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.11169&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1660268472129945600?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;Towards Expert-Level Medical Question Answering with Large Language Models&lt;/strong&gt; - a top-performing LLM for medical question answering; scored up to 86.5% on the MedQA dataset (a new state-of-the-art); approaches or exceeds SoTA across MedMCQA, PubMedQA, and MMLU clinical topics datasets.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.09617&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1660268473853829121?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers&lt;/strong&gt; - a multi-scale decoder architecture enabling end-to-end modeling of sequences of over one million bytes; enables sub-quadratic self-attention and improved parallelism during decoding.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.07185&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1660268475762327552?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5. &lt;strong&gt;StructGPT: A General Framework for Large Language Model to Reason over Structured Data&lt;/strong&gt; - improves the zero-shot reasoning ability of LLMs over structured data; effective for solving question answering tasks based on structured data.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.09645&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1660268477628727298?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;TinyStories: How Small Can Language Models Be and Still Speak Coherent English?&lt;/strong&gt; - uses a synthetic dataset of short stories to train and evaluate LMs that are much smaller than SoTA models but can produce fluent and consistent stories with several paragraphs, and demonstrate reasoning capabilities.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.07759&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1660268479642054660?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining&lt;/strong&gt; - trains a small proxy model over domains to produce domain weights without knowledge of downstream tasks; it then resamples a dataset with the domain weights and trains a larger model; this enables using a 280M proxy model to train an 8B model (30x larger) more efficiently.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.10429&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1660268481466572802?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;CodeT5+: Open Code Large Language Models for Code Understanding and Generation&lt;/strong&gt; - supports a wide range of code understanding and generation tasks and different training methods to improve efficacy and computing efficiency; tested on 20 code-related benchmarks using different settings like zero-shot, fine-tuning, and instruction tuning; achieves SoTA on tasks like code completion, math programming, and text-to-code retrieval tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.07922&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1660268483152584704?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Symbol tuning improves in-context learning in language models&lt;/strong&gt; - an approach to finetune LMs on in-context input-label pairs where natural language labels are replaced by arbitrary symbols; boosts performance on unseen in-context learning tasks and algorithmic reasoning tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.08298&#34;&gt;Paper&lt;/a&gt;), &lt;a href=&#34;https://twitter.com/dair_ai/status/1660268485035819009?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;Searching for Needles in a Haystack: On the Role of Incidental Bilingualism in PaLM&#39;s Translation Capability&lt;/strong&gt; - shows that PaLM is exposed to over 30 million translation pairs across at least 44 languages; shows that incidental bilingualism connects to the translation capabilities of PaLM.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.10266&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1660268486839476224?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (May 8-14)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;LLM explains neurons in LLMs&lt;/strong&gt; - applies GPT-4 to automatically write explanations on the behavior of neurons in LLMs and even score those explanations; this offers a promising way to improve interpretability in future LLMs and potentially detect alignment and safety problems.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/OpenAI/status/1655982364273831936?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;PaLM 2&lt;/strong&gt; - a new state-of-the-art language model integrated into AI features and tools like Bard and the PaLM API; displays competitive performance in mathematical reasoning compared to GPT-4; instruction-tuned model, Flan-PaLM 2, shows good performance on benchmarks like MMLU and BIG-bench Hard.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ai.google/static/documents/palm2techreport.pdf&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/Google/status/1656347171556294669?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;ImageBind&lt;/strong&gt; - an approach that learns joint embedding data across six modalities at once; extends zero-shot capabilities to new modalities and enables emergent applications including cross-modal retrieval, composing modalities with arithmetic, cross-modal detection, and generation.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.05665&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/MetaAI/status/1655989274620358656?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;TidyBot&lt;/strong&gt; - shows that robots can combine language-based planning and perception with the few-shot summarization capabilities of LLMs to infer generalized user preferences that are applicable to future interactions.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.05658&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/_akhaliq/status/1656117478760796160?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5. &lt;strong&gt;Unfaithful Explanations in Chain-of-Thought Prompting&lt;/strong&gt; - demonstrates that CoT explanations can misrepresent the true reason for a model‚Äôs prediction; when models are biased towards incorrect answers, CoT generation explanations supporting those answers.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.04388&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/milesaturpin/status/1656010877269602304?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;InstructBLIP&lt;/strong&gt; - explores visual-language instruction tuning based on the pre-trained BLIP-2 models; achieves state-of-the-art zero-shot performance on 13 held-out datasets, outperforming BLIP-2 and Flamingo.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.06500&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/LiJunnan0409/status/1656821806593101827?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;Active Retrieval Augmented LLMs&lt;/strong&gt; - introduces FLARE, retrieval augmented generation to improve the reliability of LLMs; FLARE actively decides when and what to retrieve across the course of the generation; demonstrates superior or competitive performance on long-form knowledge-intensive generation tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.06983&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/omarsar0/status/1657004417726423042?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;FrugalGPT&lt;/strong&gt; - presents strategies to reduce the inference cost associated with using LLMs while improving performance.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.05176&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/omarsar0/status/1656105704808419329?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;StarCoder&lt;/strong&gt; - an open-access 15.5B parameter LLM with 8K context length and is trained on large amounts of code spanning 80+ programming languages.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.06161&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/_akhaliq/status/1656479380296613894?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;MultiModal-GPT&lt;/strong&gt; - a vision and language model for multi-round dialogue with humans; the model is fine-tuned from OpenFlamingo, with LoRA added in the cross-attention and self-attention parts of the language model.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.04790&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/OpenMMLab/status/1656127026687000578?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (May 1-7)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;scGPT: Towards Building a Foundation Model for Single-Cell Multi-omics Using Generative AI&lt;/strong&gt; - a foundation large language model pretrained on 10 million cells for single-cell biology.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2023.04.30.538439v1&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1655223088152211456?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;GPTutor: a ChatGPT-powered programming tool for code explanation&lt;/strong&gt; - a ChatGPT-powered tool for code explanation provided as a VSCode extension; claims to deliver more concise and accurate explanations than vanilla ChatGPT and Copilot; performance and personalization enhanced via prompt engineering; programmed to use more relevant code in its prompts.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.01863&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1655223089754517509?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;Shap-E: Generating Conditional 3D Implicit Functions&lt;/strong&gt; - a conditional generative model for 3D assets; unlike previous 3D generative models, this model generates implicit functions that enable rendering textured meshes and neural radiance fields.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.02463&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1655223091482566663?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;Are Emergent Abilities of Large Language Models a Mirage?&lt;/strong&gt; - presents an alternative explanation to the emergent abilities of LLMs; suggests that existing claims are creations of the researcher‚Äôs analyses and not fundamental changes in model behavior on specific tasks with scale&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.15004&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1655223092975640578?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5. &lt;strong&gt;Interpretable Machine Learning for Science with PySR and SymbolicRegression.jl&lt;/strong&gt; - releases PySR, an open-source library for practical symbolic regression for the sciences; it‚Äôs built on a high-performance distributed back-end and interfaces with several deep learning packages; in addition, a new benchmark, ‚ÄúEmpiricalBench‚Äù, is released to quantify applicability of symbolic regression algorithms in science.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.01582&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1655223094640889856?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;PMC-LLaMA: Further Finetuning LLaMA on Medical Papers&lt;/strong&gt; - a LLaMA model fine-tuned on 4.8 million medical papers; enhances capabilities in the medical domain and achieves high performance on biomedical QA benchmarks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.14454&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1655223096301740032?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes&lt;/strong&gt; - a mechanism to extract rationales from LLMs to train smaller models that outperform larger language models with less training data needed by finetuning or distillation.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.02301&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1655223098730217472?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;Poisoning Language Models During Instruction Tuning&lt;/strong&gt; - show that adversaries can poison LLMs during instruction tuning by contributing poison examples to datasets; it can induce degenerate outputs across different held-out tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.00944&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1655223100286332934?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Unlimiformer: Long-Range Transformers with Unlimited Length Input&lt;/strong&gt; - proposes long-range transformers with unlimited length input by augmenting pre-trained encoder-decoder transformer with external datastore to support unlimited length input; shows usefulness in long-document summarization; could potentially be used to improve the performance of retrieval-enhanced LLMs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.01625&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1655223101913718784?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;Learning to Reason and Memorize with Self-Notes&lt;/strong&gt; - an approach that enables LLMs to reason and memorize enabling them to deviate from the input sequence at any time to explicitly ‚Äúthink‚Äù; this enables the LM to recall information and perform reasoning on the fly; experiments show that this method scales better to longer sequences unseen during training.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.00833&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1655223103662829569?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (April 24 - April 30)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning&lt;/strong&gt; - applies deep reinforcement learning to synthesize agile soccer skills for a miniature humanoid robot; the resulting policy allows dynamic movement skills such as fast recovery, walking, and kicking.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.13653&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1652693172810571780?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Scaling Transformer to 1M tokens and beyond with RMT&lt;/strong&gt; - leverages a recurrent memory transformer architecture to increase BERT‚Äôs effective context length to two million tokens while maintaining high memory retrieval accuracy.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.11062&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1652693174576349185?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;Track Anything: Segment Anything Meets Videos&lt;/strong&gt; - an interactive tool for video object tracking and segmentation; it‚Äôs built on top segment anything and allows flexible tracking and segmenting via user clicks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.11968&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1652693176644165634?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;A Cookbook of Self-Supervised Learning&lt;/strong&gt; - provides an overview of fundamental techniques and key concepts in SSL; it also introduces practical considerations for implementing SSL methods successfully.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.12210&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1652693178724626435?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5. &lt;strong&gt;Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond&lt;/strong&gt; - a comprehensive and practical guide for practitioners working with LLMs; discusses many use cases with practical applications and limitations of LLMs in real-world scenarios.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.13712&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1652693180381274114?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head&lt;/strong&gt; - connects ChatGPT with audio foundational models to handle challenging audio tasks and a modality transformation interface to enable spoken dialogue.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.12995&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1652693181895409666?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;DataComp: In search of the next generation of multimodal datasets&lt;/strong&gt; - releases a new multimodal dataset benchmark containing 12.8B image-text pairs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.14108&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1652693183493447681?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;ChatGPT for Information Extraction&lt;/strong&gt; - provides a deeper assessment of ChatGPT&#39;s performance on the important information extraction task.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.11633&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1652693184927989768?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Comparing Physician vs ChatGPT&lt;/strong&gt; - investigates if chatbot assistants like ChatGPT can provide responses to patient questions while emphasizing quality and empathy; finds that chatbot responses were preferred over physician responses and rated significantly higher in terms of both quality and empathy.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2804309&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1652693186467299331?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;Stable and low-precision training for large-scale vision-language models&lt;/strong&gt; - introduces methods for accelerating and stabilizing training of large-scale language vision models.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.13013&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1652693187960479745?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (April 17 - April 23)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;DINOv2: Learning Robust Visual Features without Supervision&lt;/strong&gt; - a new method for training high-performance computer vision models based on self-supervised learning; enables learning rich and robust visual features without supervision which are useful for both image-level visual tasks and pixel-level tasks; tasks supported include image classification, instance retrieval, video understanding, depth estimation, and much more.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.07193&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1650145892941324288?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Learning to Compress Prompts with Gist Tokens&lt;/strong&gt; - an approach that trains language models to compress prompts into gist tokens reused for compute efficiency; this approach enables 26x compression of prompts, resulting in up to 40% FLOPs reductions.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.08467&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1650145895332163585?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;Scaling the leading accuracy of deep equivariant models to biomolecular simulations of realistic size&lt;/strong&gt; - presents a framework for large-scale biomolecular simulation; this is achieved through the high accuracy of equivariant deep learning and the ability to scale to large and long simulations; the system is able to ‚Äúperform nanoseconds-long stable simulations of protein dynamics and scale up to a 44-million atom structure of a complete, all-atom, explicitly solvated HIV capsid on the Perlmutter supercomputer.‚Äù&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.10061&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1650145897689350144?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;Evaluating Verifiability in Generative Search Engines&lt;/strong&gt; - performs human evaluation to audit popular generative search engines such as Bing Chat, Perplexity AI, and NeevaAI; finds that, on average, only 52% of generated sentences are supported by citations and 75% of citations support their associated sentence.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.09848&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1650145900180779009?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5. &lt;strong&gt;Generative Disco: Text-to-Video Generation for Music Visualization&lt;/strong&gt; - an AI system based on LLMs and text-to-image models that generates music visualizations.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.08551&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1650145904219832324?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;Architectures of Topological Deep Learning: A Survey on Topological Neural Networks&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.10031&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1650145906560311298?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;Visual Instruction Tuning&lt;/strong&gt; - presents an approach that uses language-only GPT-4 to generate multimodal language-image instruction-following data; applies instruction tuning with the data and introduces LLaVA, an end-to-end trained large multimodal model for general-purpose visual and language understanding.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.08485&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1650145909387214848?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;ChatGPT: Applications, Opportunities, and Threats&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.09103&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1650145911836745736?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models&lt;/strong&gt; - a plug-and-play compositional reasoning framework that augments LLMs and can infer the appropriate sequence of tools to compose and execute in order to generate final responses; achieves 87% accuracy on ScienceQA and 99% on TabMWP.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.09842&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1650145914420330496?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models&lt;/strong&gt; - applies latent diffusion models to high-resolution video generation; validates the model on creative content creation and real driving videos of 512 x 1024 and achieves state-of-the-art performance.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.08818&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1650145916794314752?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (April 10 - April 16)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields&lt;/strong&gt; - combines mip-NeRF 360 and grid-based models to improve NeRFs that train 22x faster than mip-NeRF 360.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.06706&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1647613826425147401?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Generative Agents: Interactive Simulacra of Human Behavior&lt;/strong&gt; - proposes an architecture that extends LLMs to build agents that enable simulations of human-like behavior; these capabilities are possible by storing a complete record of an agent&#39;s experiences, synthesizing memories over time into higher-level reflections, and retrieving them dynamically to plan behavior.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.03442&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1647613828417351682?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;Emergent autonomous scientific research capabilities of large language models&lt;/strong&gt; - presents an agent that combines LLMs for autonomous design, planning, and execution of scientific experiments; shows emergent scientific research capabilities, including the successful performance of catalyzed cross-coupling reactions.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.05332&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1647613830233571328?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;Automatic Gradient Descent: Deep Learning without Hyperparameters&lt;/strong&gt; - derives optimization algorithms that explicitly leverage neural architecture; it proposes a first-order optimizer without hyperparameters that trains CNNs at ImageNet scale.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.05187&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1647613832804589569?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5. &lt;strong&gt;ChemCrow: Augmenting large-language models with chemistry tools&lt;/strong&gt; - presents an LLM chemistry agent that performs tasks across synthesis, drug discovery, and materials design; it integrates 13 expert-design tools to augment LLM performance in chemistry and demonstrate effectiveness in automating chemical tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.05376&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1647613834813644800?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era&lt;/strong&gt; - A Survey of ChatGPT and GPT-4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.06488&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1647613836617195525?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;OpenAGI: When LLM Meets Domain Experts&lt;/strong&gt; - an open-source research platform to facilitate the development and evaluation of LLMs in solving complex, multi-step tasks through manipulating various domain expert models.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.04370&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1647613838567546886?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models&lt;/strong&gt; - a new benchmark to assess foundational models in the context of human-centric standardized exams, including college entrance exams, law school admission tests, and math competitions, among others.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.06364&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1647613840400498700?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Teaching Large Language Models to Self-Debug&lt;/strong&gt; - proposes an approach that teaches LLMs to debug their predicted program via few-shot demonstrations; this allows a model to identify its mistakes by explaining generated code in natural language; achieves SoTA on several code generation tasks like text-to-SQL generation.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.05128&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1647613842300497924?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;Segment Everything Everywhere All at Once&lt;/strong&gt; - a promptable, interactive model for various segmentation tasks that yields competitive performance on open-vocabulary and interactive segmentation benchmarks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.06718&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1647613844087361537?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (April 3 - April 9)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;Segment Anything&lt;/strong&gt; - presents a set of resources to establish foundational models for image segmentation; releases the largest segmentation dataset with over 1 billion masks on 11M licensed images; the model‚Äôs zero-shot performance is competitive with or even superior to fully supervised results.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.02643v1&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1645089444280561666?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Instruction Tuning with GPT-4&lt;/strong&gt; - presents GPT-4-LLM, a &#34;first attempt&#34; to use GPT-4 to generate instruction-following data for LLM fine-tuning; the dataset is released and includes 52K unique English and Chinese instruction-following data; the dataset is used to instruction-tune LLaMA models which leads to superior zero-shot performance on new tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.03277&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1645089446524534788?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;Eight Things to Know about Large Language Models&lt;/strong&gt; - discusses important considerations regarding the capabilities and limitations of LLMs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.00612v1&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1645089448428699650?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;A Survey of Large Language Models&lt;/strong&gt; - a new 50 pages survey on large language models.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.18223&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1645089450395852802?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5. &lt;strong&gt;Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data&lt;/strong&gt; - an open-source chat model fine-tuned with LoRA. Leverages 100K dialogs generated from ChatGPT chatting with itself; it releases the dialogs along with 7B, 13B, and 30B parameter models.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.01196&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1645089452081938433?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark&lt;/strong&gt; - a new benchmark of 134 text-based Choose-Your-Own-Adventure games to evaluate the capabilities and unethical behaviors of LLMs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.03279&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1645089453780639744?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;Better Language Models of Code through Self-Improvement&lt;/strong&gt; - generates pseudo data from knowledge gained through pre-training and fine-tuning; adds the data to the training dataset for the next step; results show that different frameworks can be improved in performance using code-related generation tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.01228v1&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1645089455659687937?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models&lt;/strong&gt; - an overview of applications of ChatGPT and GPT-4; the analysis is done on 194 relevant papers and discusses capabilities, limitations, concerns, and more&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.01852&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1645089457488404486?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling&lt;/strong&gt; - a suite for analyzing LLMs across training and scaling; includes 16 LLMs trained on public data and ranging in size from 70M to 12B parameters.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.01373&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1645089459191382016?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;SegGPT: Segmenting Everything In Context&lt;/strong&gt; - unifies segmentation tasks into a generalist model through an in-context framework that supports different kinds of data.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.03284&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1645089461124886529?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (Mar 27 - April 2)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;BloombergGPT: A Large Language Model for Finance&lt;/strong&gt; - a new 50B parameter large language model for finance. Claims the largest domain-specific dataset yet with 363 billion tokens... further augmented with 345 billion tokens from general-purpose datasets; outperforms existing models on financial tasks while not sacrificing performance on general LLM benchmarks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.17564v1&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/omarsar0/status/1641787456436547584?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware&lt;/strong&gt; - a low-cost system that performs end-to-end imitation learning from real demonstrations; also presents an algorithm called Action Chunking with Transformers to learn a generative model that allows a robot to learn difficult tasks in the real world.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://tonyzhaozh.github.io/aloha/&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/tonyzzhao/status/1640393026341322754?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace&lt;/strong&gt; - a system that leverages LLMs like ChatGPT to conduct task planning, select models and act as a controller to execute subtasks and summarize responses according to execution results.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.17580&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/johnjnay/status/1641609645713129473?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge&lt;/strong&gt; - a medical chat model fine-tuned on LLaMA using medical domain knowledge. Collects data on around 700 diseases and generated 5K doctor-patient conversations to finetune the LLM.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.14070&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/omarsar0/status/1640525256719753217?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5. &lt;strong&gt;LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention&lt;/strong&gt; - a lightweight adaption method to efficiently fine-tune LLaMA into an instruction-following model; generates responses comparable to Alpaca with fully fine-tuned 7B parameter; it‚Äôs also extended for multi-modal input support.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.16199&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/rasbt/status/1641457696074334209?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks&lt;/strong&gt; - demonstrates that ChatGPT can outperform crowd-workers for several annotation tasks such as relevance, topics, and frames detection; besides better zero-shot accuracy, the per-annotation cost of ChatGPT is less 20 times cheaper than MTurk.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.15056v1&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/AlphaSignalAI/status/1641496876527517696?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;Language Models can Solve Computer Tasks&lt;/strong&gt; - shows that a pre-trained LLM agent can execute computer tasks using a simple prompting scheme where the agent recursively criticizes and improves its outputs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.17491&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/arankomatsuzaki/status/1641609722951516161?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents&lt;/strong&gt; - a paradigm to enhance large language model completions by allowing models to communicate feedback and iteratively improve output; DERA outperforms base GPT-4 on clinically-focused tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.17071&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/johnjnay/status/1642168727796961280?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Natural Selection Favors AIs over Humans&lt;/strong&gt; - discusses why AI systems will become more fit than humans and the potential dangers and risks involved, including ways to mitigate them.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.16200&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/DanHendrycks/status/1641102660412792833?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;Machine Learning for Partial Differential Equations&lt;/strong&gt; - Pa review examining avenues of partial differential equations research advanced by machine learning.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.17078&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/DynamicsSIAM/status/1641608068453777412?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (Mar 20-Mar 26)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;Sparks of Artificial General Intelligence: Early experiments with GPT-4&lt;/strong&gt; - a comprehensive investigation of an early version of GPT-4 when it was still in active development by OpenAI.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.12712&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1639991716349460481?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Reflexion: an autonomous agent with dynamic memory and self-reflection&lt;/strong&gt; - proposes an agent with dynamic memory and self-reflection capabilities to enhance its existing reasoning trace and task-specific action choice abilities.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.11366&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1639991718169722880?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;Capabilities of GPT-4 on Medical Challenge Problems&lt;/strong&gt; - shows that GPT-4 exceeds the passing score on USMLE by over 20 points and outperforms GPT-3.5 as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B).&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/publication/capabilities-of-gpt-4-on-medical-challenge-problems/&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1639991720224989188?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models&lt;/strong&gt; - investigates the potential implications of GPT models and related systems on the US labor market.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.10130&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1639991722263412737?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5. &lt;strong&gt;CoLT5: Faster Long-Range Transformers with Conditional Computation&lt;/strong&gt; - a long-input Transformer model that employs conditional computation, devoting more resources to important tokens in both feedforward and attention layers.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.09752&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1639991723806826499?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;Artificial muses: Generative Artificial Intelligence Chatbots Have Risen to Human-Level Creativity&lt;/strong&gt; - compares human-generated ideas with those generated by generative AI chatbots like ChatGPT and YouChat; reports that 9.4% of humans were more creative than GPT-4 and that GAIs are valuable assistants in the creative process.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.12003&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1639991725442646018?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models&lt;/strong&gt; - a comprehensive capability analysis of GPT series models; evaluates performance on 9 natural language understanding tasks using 21 datasets.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.10420&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1639991727292395520?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;Context-faithful Prompting for Large Language Models&lt;/strong&gt; - presents a prompting technique that aims to improve LLMs&#39; faithfulness using strategies such as opinion-based prompts and counterfactual demonstrations.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.11315&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1639991728882032646?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models&lt;/strong&gt; - a method for extracting room-scale textured 3D meshes from 2D text-to-image models.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.11989&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://lukashoel.github.io/text-to-room/&#34;&gt;Project&lt;/a&gt;&lt;a href=&#34;https://twitter.com/dair_ai/status/1639991730723254274?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;PanGu-Œ£: Towards Trillion Parameter Language Model with Sparse Heterogeneous Computing&lt;/strong&gt; - a trillion parameter language model with sparse heterogeneous computing.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.10845&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1639991732405252100?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (Mar 13-Mar 19)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;GPT-4 Technical Report&lt;/strong&gt; - GPT-4 - a large multimodal model with broader general knowledge and problem-solving abilities.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.08774v2&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1637456913993433089?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;LERF: Language Embedded Radiance Fields&lt;/strong&gt; - a method for grounding language embeddings from models like CLIP into NeRF; this enables open-ended language queries in 3D.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.09553&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1637456915658686465?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;An Overview on Language Models: Recent Developments and Outlook&lt;/strong&gt; - an overview of language models covering recent developments and future directions. It also covers topics like linguistic units, structures, training methods, evaluation, and applications.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.05759&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/omarsar0/status/1635273656858460162?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;Eliciting Latent Predictions from Transformers with the Tuned Lens&lt;/strong&gt; - a method for transformer interpretability that can trace a language model predictions as it develops layer by layer.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.08112&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1637456919819440130?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5. &lt;strong&gt;Meet in the Middle: A New Pre-training Paradigm&lt;/strong&gt; - a new pre-training paradigm using techniques that jointly improve training data efficiency and capabilities of LMs in the infilling task; performance improvement is shown in code generation tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.07295&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1637456922004561920?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;Resurrecting Recurrent Neural Networks for Long Sequences&lt;/strong&gt; - demonstrates that careful design of deep RNNs using standard signal propagation arguments can recover the performance of deep state-space models on long-range reasoning tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.06349&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1637456923795521537?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation&lt;/strong&gt; - a new approach to tune a lightweight and versatile retriever to automatically retrieve prompts to improve zero-shot performance and help mitigate hallucinations.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.08518&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1637456925779456000?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;Patches Are All You Need?&lt;/strong&gt; - proposes ConvMixer, a parameter-efficient fully-convolutional model which replaces self-attention and MLP layers in ViTs with less-expressive depthwise and pointwise convolutional layers.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://openreview.net/forum?id=rAnB7JSMXL&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1637456927784329218?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;NeRFMeshing: Distilling Neural Radiance Fields into Geometrically-Accurate 3D Meshes&lt;/strong&gt; - a compact and flexible architecture that enables easy 3D surface reconstruction from any NeRF-driven approach; distills NeRFs into geometrically-accurate 3D meshes.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.09431&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1637456929705295873?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;High-throughput Generative Inference of Large Language Models with a Single GPU&lt;/strong&gt; - a high-throughput generation engine for running LLMs with limited GPU memory.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.06865&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/FMInference/FlexGen&#34;&gt;Code&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1637456931429183489?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (Mar 6-Mar 12)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;PaLM-E: An Embodied Multimodal Language Model&lt;/strong&gt; - incorporates real-world continuous sensor modalities resulting in an embodied LM that performs tasks such as robotic manipulation planning, visual QA, and other embodied reasoning tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.03378&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://palm-e.github.io/&#34;&gt;Demo&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1634919222420836358?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Prismer: A Vision-Language Model with An Ensemble of Experts&lt;/strong&gt; - a parameter-efficient vision-language model powered by an ensemble of domain experts; it efficiently pools expert knowledge from different domains and adapts it to various vision-language reasoning tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.02506&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/NVlabs/Prismer&#34;&gt;GitHub&lt;/a&gt;, &lt;a href=&#34;https://shikun.io/projects/prismer&#34;&gt;Project&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1634919224505257985?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models&lt;/strong&gt; - it connects ChatGPT and different visual foundation models to enable users to interact with ChatGPT beyond language format.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.04671&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/microsoft/visual-chatgpt&#34;&gt;GitHub&lt;/a&gt; &lt;a href=&#34;https://twitter.com/dair_ai/status/1634919226396794882?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT&lt;/strong&gt; - an overview of generative AI - from GAN to ChatGPT.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.04226&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1634919228339003393?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5. &lt;strong&gt;Larger language models do in-context learning differently&lt;/strong&gt; - shows that with scale, LLMs can override semantic priors when presented with enough flipped labels; these models can also perform well when replacing targets with semantically-unrelated targets.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.03846&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1634919230461345797?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;Foundation Models for Decision Making: Problems, Methods, and Opportunities&lt;/strong&gt; - provides an overview of foundation models for decision making, including tools, methods, and new research directions.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.04129&#34;&gt;Project&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1634919232650760192?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;Hyena Hierarchy: Towards Larger Convolutional Language Models&lt;/strong&gt; - a subquadratic drop-in replacement for attention; it interleaves implicit long convolutions and data-controlled gating and can learn on sequences 10x longer and up to 100x faster than optimized attention.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.10866&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/HazyResearch/safari&#34;&gt;Code&lt;/a&gt;, &lt;a href=&#34;https://ermongroup.github.io/blog/hyena/&#34;&gt;Blog&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1634919234835980289?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;OpenICL: An Open-Source Framework for In-context Learning&lt;/strong&gt; - a new open-source toolkit for in-context learning and LLM evaluation; supports various state-of-the-art retrieval and inference methods, tasks, and zero-/few-shot evaluation of LLMs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.02913&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/Shark-NLP/OpenICL&#34;&gt;Repo&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1634919236954132480?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;MathPrompter: Mathematical Reasoning using Large Language Models&lt;/strong&gt; - a technique that improves LLM performance on mathematical reasoning problems; it uses zero-shot chain-of-thought prompting and verification to ensure generated answers are accurate.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.05398&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1634919239030280197?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;Scaling up GANs for Text-to-Image Synthesis&lt;/strong&gt; - enables scaling up GANs on large datasets for text-to-image synthesis; it‚Äôs found to be orders of magnitude faster at inference time, synthesizes high-resolution images, &amp;amp; supports various latent space editing applications.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.05511&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://mingukkang.github.io/GigaGAN/&#34;&gt;Project&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1634919241198751744?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (Feb 27-Mar 5)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;Language Is Not All You Need: Aligning Perception with Language Models&lt;/strong&gt; - introduces a multimodal large language model called Kosmos-1; achieves great performance on language understanding, OCR-free NLP, perception-language tasks, visual QA, and more.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.14045&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1632383312550416384?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Evidence of a predictive coding hierarchy in the human brain listening to speech&lt;/strong&gt; - finds that human brain activity is best explained by the activations of modern language models enhanced with long-range and hierarchical predictions.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.nature.com/articles/s41562-022-01516-2?utm_source=twitter&amp;amp;utm_medium=organic_social&amp;amp;utm_campaign=evergreen&amp;amp;utm_content=animation&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1632383315029180416?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;EvoPrompting: Language Models for Code-Level Neural Architecture Search&lt;/strong&gt; - combines evolutionary prompt engineering with soft prompt-tuning to find high-performing models; it leverages few-shot prompting which is further improved by using an evolutionary search approach to improve the in-context examples.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.14838&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1632383317302562816?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;Consistency Models&lt;/strong&gt; - a new family of generative models that achieve high sample quality without adversarial training.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.01469&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1632383319152132096?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5. &lt;strong&gt;Goal Driven Discovery of Distributional Differences via Language Descriptions&lt;/strong&gt; - a new task that automatically discovers corpus-level differences via language description in a goal-driven way; applications include discovering insights from commercial reviews and error patterns in NLP systems.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.14233&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://github.com/ruiqi-zhong/D5&#34;&gt;Code&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1632383321035374593?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;High-resolution image reconstruction with latent diffusion models from human brain activity&lt;/strong&gt; - proposes an approach for high-resolution image reconstruction with latent diffusion models from human brain activity.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://sites.google.com/view/stablediffusion-with-brain/&#34;&gt;Project&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1632383323086487554?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;Grounded Decoding: Guiding Text Generation with Grounded Models for Robot Control&lt;/strong&gt; - a scalable approach to planning with LLMs in embodied settings through grounding functions; GD is found to be a general, flexible, and expressive approach to embodied tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://grounded-decoding.github.io/paper.pdf&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://grounded-decoding.github.io/&#34;&gt;Project&lt;/a&gt; &lt;a href=&#34;https://twitter.com/dair_ai/status/1632383325036740610?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;Language-Driven Representation Learning for Robotics&lt;/strong&gt; - a framework for language-driven representation learning from human videos and captions for robotics.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.12766&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/siddk/voltron-robotics&#34;&gt;Models&lt;/a&gt;, &lt;a href=&#34;https://github.com/siddk/voltron-evaluation&#34;&gt;Evaluation&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1632383327154888704?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Dropout Reduces Underfitting&lt;/strong&gt; - demonstrates that dropout can mitigate underfitting when used at the start of training; it counteracts SGD stochasticity and limits the influence of individual batches when training models.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.01500&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1632383328920666121?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;Enabling Conversational Interaction with Mobile UI using Large Language Models&lt;/strong&gt; - an approach that enables versatile conversational interactions with mobile UIs using a single LLM.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.08655&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1632383331286253568?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (Feb 20-26)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;LLaMA: Open and Efficient Foundation Language Models&lt;/strong&gt; - a 65B parameter foundation model released by Meta AI; relies on publicly available data and outperforms GPT-3 on most benchmarks despite being 10x smaller.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1629845535946420226?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Composer: Creative and Controllable Image Synthesis with Composable Conditions&lt;/strong&gt; - a 5B parameter creative and controllable diffusion model trained on billions (text, image) pairs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.09778&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://damo-vilab.github.io/composer-page/&#34;&gt;Project&lt;/a&gt; , &lt;a href=&#34;https://github.com/damo-vilab/composer&#34;&gt;GitHub&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1629845537913548802?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;The Wisdom of Hindsight Makes Language Models Better Instruction Followers&lt;/strong&gt; - an alternative algorithm to train LLMs from feedback; the feedback is converted to instruction by relabeling the original one and training the model, in a supervised way, for better alignment.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.05206&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/tianjunz/HIR&#34;&gt;GitHub&lt;/a&gt; &lt;a href=&#34;https://twitter.com/dair_ai/status/1629845539964481537?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;Active Prompting with Chain-of-Thought for Large Language Models&lt;/strong&gt; - a prompting technique to adapt LLMs to different task-specific example prompts (annotated with human-designed chain-of-thought reasoning); this process involves finding where the LLM is most uncertain and annotating those.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.12246&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/shizhediao/active-prompt&#34;&gt;Code&lt;/a&gt; &lt;a href=&#34;https://twitter.com/dair_ai/status/1629845541847724033?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5. &lt;strong&gt;Modular Deep Learning&lt;/strong&gt; - a survey offering a unified view of the building blocks of modular neural networks; it also includes a discussion about modularity in the context of scaling LMs, causal inference, and other key topics in ML.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.11529&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://www.ruder.io/modular-deep-learning/&#34;&gt;Project&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1629845544037228551?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;Recitation-Augmented Language Models&lt;/strong&gt; - an approach that recites passages from the LLM‚Äôs own memory to produce final answers; shows high performance on knowledge-intensive tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.01296&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1629845546276995075?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;Learning Performance-Improving Code Edits&lt;/strong&gt; - an approach that uses LLMs to suggest functionally correct, performance-improving code edits.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.07867&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1629845548210561029?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;More than you&#39;ve asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models&lt;/strong&gt; - a comprehensive analysis of novel prompt injection threats to application-integrated LLMs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.12173&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1629845550152523777?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Aligning Text-to-Image Models using Human Feedback&lt;/strong&gt; - proposes a fine-tuning method to align generative models using human feedback.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.12192&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1629845552039968780?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;MERF: Memory-Efficient Radiance Fields for Real-time View Synthesis in Unbounded Scenes&lt;/strong&gt; - a memory-efficient radiance field representation for real-time view synthesis of large-scale scenes in a browser.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.12249&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1629845554061606915?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (Feb 13 - 19)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;Symbolic Discovery of Optimization Algorithms&lt;/strong&gt; - a simple and effective optimization algorithm that‚Äôs more memory-efficient than Adam.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.06675&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1627671313874575362?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Transformer models: an introduction and catalog&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.07730&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1627671315678126082?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;3D-aware Conditional Image Synthesis&lt;/strong&gt; - a 3D-aware conditional generative model extended with neural radiance fields for controllable photorealistic image synthesis.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/ML-Papers-of-the-Week/main/xxx&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://www.cs.cmu.edu/~pix2pix3D/&#34;&gt;Project&lt;/a&gt; &lt;a href=&#34;https://twitter.com/dair_ai/status/1627671317355831296?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;The Capacity for Moral Self-Correction in Large Language Models&lt;/strong&gt; - finds strong evidence that language models trained with RLHF have the capacity for moral self-correction. The capability emerges at 22B model parameters and typically improves with scale.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.07459&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1627671319100768260?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;Language Quantized AutoEncoders: Towards Unsupervised Text-Image Alignment&lt;/strong&gt; - an unsupervised method for text-image alignment that leverages pretrained language models; it enables few-shot image classification with LLMs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.00902&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://github.com/lhao499/lqae&#34;&gt;Code&lt;/a&gt; &lt;a href=&#34;https://twitter.com/haoliuhl/status/1625273748629901312?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;Augmented Language Models: a Survey&lt;/strong&gt; - a survey of language models that are augmented with reasoning skills and the capability to use tools.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.07842&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1627671324477820929?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;Geometric Clifford Algebra Networks&lt;/strong&gt; - an approach to incorporate geometry-guided transformations into neural networks using geometric algebra.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.06594&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1627671326176473088?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Auditing large language models: a three-layered approach&lt;/strong&gt; - proposes a policy framework for auditing LLMs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.08500&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1627671327950643200?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;Energy Transformer&lt;/strong&gt; - a transformer architecture that replaces the sequence of feedforward transformer blocks with a single large Associate Memory model; this follows the popularity that Hopfield Networks have gained in the field of ML.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.07253&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1627671329561346050?s=20&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (Feb 6 - 12)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;Toolformer: Language Models Can Teach Themselves to Use Tools&lt;/strong&gt; - introduces language models that teach themselves to use external tools via simple API calls.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.04761&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1624832248691191808?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents&lt;/strong&gt; - proposes using language models for open-world game playing.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.01560&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1624832250717036548?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;A Categorical Archive of ChatGPT Failures&lt;/strong&gt; - a comprehensive analysis of ChatGPT failures for categories like reasoning, factual errors, maths, and coding.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.03494&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1624832252587700230?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery&lt;/strong&gt; - optimizing hard text prompts through efficient gradient-based optimization.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.03668&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1624832254588465156?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5) &lt;strong&gt;Data Selection for Language Models via Importance Resampling&lt;/strong&gt; - proposes a cheap and scalable data selection framework based on an importance resampling algorithm to improve the downstream performance of LMs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.03169&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1624832256400302080?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;Structure and Content-Guided Video Synthesis with Diffusion Models&lt;/strong&gt; - proposes an approach for structure and content-guided video synthesis with diffusion models.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.03011&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://research.runwayml.com/gen1&#34;&gt;Project&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1624832258296229889?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity&lt;/strong&gt; - performs a more rigorous evaluation of ChatGPt on reasoning, hallucination, and interactivity.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.04023&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1624832260213026819?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;Noise2Music: Text-conditioned Music Generation with Diffusion Models&lt;/strong&gt; - proposes diffusion models to generate high-quality 30-second music clips via text prompts.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.03917&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://google-research.github.io/noise2music/&#34;&gt;Project&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1624832262163337220?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Offsite-Tuning: Transfer Learning without Full Model&lt;/strong&gt; - introduces an efficient, privacy-preserving transfer learning framework to adapt foundational models to downstream data without access to the full model.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.04870&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/mit-han-lab/offsite-tuning&#34;&gt;Project&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1624832264029831169?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;Zero-shot Image-to-Image Translation&lt;/strong&gt; - proposes a model for zero-shot image-to-image translation.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.03027&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://pix2pixzero.github.io/&#34;&gt;Project&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1624832265967607813?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (Jan 30-Feb 5)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;REPLUG: Retrieval-Augmented Black-Box Language Models&lt;/strong&gt; - a retrieval-augmented LM framework that adapts a retriever to a large-scale, black-box LM like GPT-3.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.12652&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1622261780725616641?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Extracting Training Data from Diffusion Models&lt;/strong&gt; - shows that diffusion-based generative models can memorize images from the training data and emit them at generation time.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.13188&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1622261782738788353?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;The Flan Collection: Designing Data and Methods for Effective Instruction Tuning&lt;/strong&gt; - release a more extensive publicly available collection of tasks, templates, and methods to advancing instruction-tuned models.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.13688&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1622261784668241922?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;Multimodal Chain-of-Thought Reasoning in Language Models&lt;/strong&gt; - incorporates vision features to elicit chain-of-thought reasoning in multimodality, enabling the model to generate effective rationales that contribute to answer inference.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.00923&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/amazon-science/mm-cot&#34;&gt;Code&lt;/a&gt; &lt;a href=&#34;https://twitter.com/dair_ai/status/1622261786559791105?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5) &lt;strong&gt;Dreamix: Video Diffusion Models are General Video Editors&lt;/strong&gt; - a diffusion model that performs text-based motion and appearance editing of general videos.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.01329&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://dreamix-video-editing.github.io/&#34;&gt;Project&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1622261788497657856?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;Benchmarking Large Language Models for News Summarization&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.13848&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1622261790326259714?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;Mathematical Capabilities of ChatGPT&lt;/strong&gt; - investigates the mathematical capabilities of ChatGPT on a new holistic benchmark called GHOSTS.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.13867&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1622261792238886913?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;Emergence of Maps in the Memories of Blind Navigation Agents&lt;/strong&gt; - trains an AI agent to navigate purely by feeling its way around; no use of vision, audio, or any other sensing (as in animals).&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.13261&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://wijmans.xyz/publication/eom/&#34;&gt;Project&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1622261793987989507?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;SceneDreamer: Unbounded 3D Scene Generation from 2D Image Collections&lt;/strong&gt; - a generative model that synthesizes large-scale 3D landscapes from random noises.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.01330&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1622261795925671936?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;Large Language Models Can Be Easily Distracted by Irrelevant Context&lt;/strong&gt; - finds that many prompting techniques fail when presented with irrelevant context for arithmetic reasoning.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.00093&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1622261798379429888?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (Jan 23-29)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;MusicLM: Generating Music From Text&lt;/strong&gt; - a generative model for generating high-fidelity music from text descriptions.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.11325&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1619716425761042436?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Hungry Hungry Hippos: Towards Language Modeling with State Space Models&lt;/strong&gt; - an approach to reduce the gap, in terms of performance and hardware utilization, between state space models and attention for language modeling.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.14052&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1619716427879174144?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;A Watermark for Large Language Models&lt;/strong&gt; - a watermarking framework for proprietary language models.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.10226&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1619716430127308800?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;Text-To-4D Dynamic Scene Generation&lt;/strong&gt; - a new text-to-4D model for dynamic scene generation from input text.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.11280&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://make-a-video3d.github.io/&#34;&gt;GitHub&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1619718845018828801?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5) &lt;strong&gt;ClimaX: A foundation model for weather and climate&lt;/strong&gt; - a foundation model for weather and climate, including many capabilities for atmospheric science tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.10343&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/tungnd_13/status/1618642574427959296?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;, &lt;a href=&#34;https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/introducing-climax-the-first-foundation-model-for-weather-and-climate/&#34;&gt;Blog&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;Open Problems in Applied Deep Learning&lt;/strong&gt; - If you&#39;re looking for interesting open problems in DL, this is a good reference. Not sure if intentional but it also looks useful to get a general picture of current trends in deep learning with ~300 references.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.11316&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1619719063915339777?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature&lt;/strong&gt; - an approach for zero-shot machine-generated text detection. Uses raw log probabilities from the LLM to determine if the passage was sampled from it.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.11305&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1619719169758613504?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis&lt;/strong&gt; - a new model that aims to regain the competitiveness of GANs for fast large-scale text-to-image synthesis.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.09515&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://sites.google.com/view/stylegan-t/&#34;&gt;Project&lt;/a&gt;, &lt;a href=&#34;https://github.com/autonomousvision/stylegan-t&#34;&gt;Code&lt;/a&gt; &lt;a href=&#34;https://twitter.com/dair_ai/status/1619719293779976193?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Large language models generate functional protein sequences across diverse families&lt;/strong&gt; - an LLM that can generate protein sequences with a predictable function across large protein families.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.nature.com/articles/s41587-022-01618-2&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1619719404618645511?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;The Impossibility of Parallelizing Boosting&lt;/strong&gt; - investigates the possibility of parallelizing boosting.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.09627&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1619719511867015168?s=20&amp;amp;t=ygX07dsAPDF8_jwrxZIo1Q&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (Jan 16-22)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;Google AI Research Recap (2022 Edition)&lt;/strong&gt; - an excellent summary of some notable research Google AI did in 2022.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ai.googleblog.com/2023/01/google-research-2022-beyond-language.html&#34;&gt;Blog&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/JeffDean/status/1615796030611820545?s=20&amp;amp;t=vUEC8AZmrOJnVxuYIEJs5A&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Dissociating language and thought in large language models: a cognitive perspective&lt;/strong&gt; - a review paper on the capabilities of LLMs from a cognitive science perspective.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.06627&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/neuranna/status/1615737072207400962?s=20&amp;amp;t=5iWUK4z_rp1NWst7JRbnwg&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;Human-Timescale Adaptation in an Open-Ended Task Space&lt;/strong&gt; - an agent trained at scale that leads to a general in-content learning algorithm able to adapt to open-ended embodied 3D problems.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.07608&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/FeryalMP/status/1616035293064462338?s=20&amp;amp;t=RN0YZFAXWr-uH2dT2ZTSqQ&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;AtMan: Understanding Transformer Predictions Through Memory Efficient Attention Manipulation&lt;/strong&gt; - an approach to help provide explanations of generative transformer models through memory-efficient attention manipulation.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.08110&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/JonasAndrulis/status/1616722810608427008?s=20&amp;amp;t=vUEC8AZmrOJnVxuYIEJs5A&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5) &lt;strong&gt;Everything is Connected: Graph Neural Networks&lt;/strong&gt; - short overview of key concepts in graph representation learning.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.08210&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/PetarV_93/status/1616379369953394688?s=20&amp;amp;t=AqTVY30Y7IZCultzwnqBPA&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;GLIGEN: Open-Set Grounded Text-to-Image Generation&lt;/strong&gt; - an approach that extends the functionality of existing pre-trained text-to-image diffusion models by enabling conditioning on grounding inputs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.07093&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/hardmaru/status/1615766551113744384?s=20&amp;amp;t=wx0Y18oSmW0YenXjKRAdnA&#34;&gt;Tweet&lt;/a&gt;, &lt;a href=&#34;https://gligen.github.io/&#34;&gt;Project&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;InstructPix2Pix: Learning to Follow Image Editing Instructions&lt;/strong&gt; - proposes a method with the capability of editing images from human instructions.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.09800&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/_akhaliq/status/1615947919286276096?s=20&amp;amp;t=pbRTn8DaPeQFApQ9okkdRg&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;Dataset Distillation: A Comprehensive Review&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.07014&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/omarsar0/status/1615745724473540609?s=20&amp;amp;t=r-pwuB6EhbZLXa5R6mL3NQ&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Learning-Rate-Free Learning by D-Adaptation&lt;/strong&gt; - a new method for automatically adjusting the learning rate during training, applicable to more than a dozen diverse ML problems.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.07733&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/aaron_defazio/status/1616453609956478977?s=20&amp;amp;t=hGWDXu4sT5f1KcH-X1IL9g&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;RecolorNeRF: Layer Decomposed Radiance Field for Efficient Color Editing of 3D Scenes&lt;/strong&gt; - a user-friendly color editing approach for the neural radiance field to achieve a more efficient view-consistent recoloring.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.07958&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/_akhaliq/status/1616265465843548160?s=20&amp;amp;t=duiLmtDvxCwkFmw23rYDmQ&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (Jan 9-15)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;Mastering Diverse Domains through World Models&lt;/strong&gt; - a general algorithm to collect diamonds in Minecraft from scratch without human data or curricula, a long-standing challenge in AI.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.04104v1&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1614676677757661185?s=20&amp;amp;t=3GITA7PeX7pGwrqvt97bYQ&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;Tracr: Compiled Transformers as a Laboratory for Interpretability&lt;/strong&gt; - a compiler for converting RASP programs into transformer weights. This way of constructing NNs weights enables the development and evaluation of new interpretability tools.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.05062&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1614676680165187584?s=20&amp;amp;t=3GITA7PeX7pGwrqvt97bYQ&#34;&gt;Tweet&lt;/a&gt;, &lt;a href=&#34;https://github.com/deepmind/tracr&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;Multimodal Deep Learning&lt;/strong&gt; - multimodal deep learning is a new book published on ArXiv.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.04856&#34;&gt;Book&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1614676682555670528?s=20&amp;amp;t=3GITA7PeX7pGwrqvt97bYQ&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;Forecasting Potential Misuses of Language Models for Disinformation Campaigns‚Äîand How to Reduce Risk&lt;/strong&gt; - new work analyzing how generative LMs could potentially be misused for disinformation and how to mitigate these types of risks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://openai.com/blog/forecasting-misuse/&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1614676684984156160?s=20&amp;amp;t=3GITA7PeX7pGwrqvt97bYQ&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5) &lt;strong&gt;Why do Nearest Neighbor Language Models Work?&lt;/strong&gt; - empirically identifies reasons why retrieval-augmented LMs (specifically k-nearest neighbor LMs) perform better than standard parametric LMs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.02828&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/frankxu2004/knnlm-why&#34;&gt;Code&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1614676687597469696?s=20&amp;amp;t=3GITA7PeX7pGwrqvt97bYQ&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;Memory Augmented Large Language Models are Computationally Universal&lt;/strong&gt; - investigates the use of existing LMs (e.g, Flan-U-PaLM 540B) combined with associative read-write memory to simulate the execution of a universal Turing machine.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.04589&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://twitter.com/dair_ai/status/1614676689908277252?s=20&amp;amp;t=3GITA7PeX7pGwrqvt97bYQ&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;A Survey on Transformers in Reinforcement Learning&lt;/strong&gt; - transformers for RL will be a fascinating research area to track. The same is true for the reverse direction (RL for Transformers)... a notable example: using RLHF to improve LLMs (e.g., ChatGPT).&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.03044&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1614676692538105860?s=20&amp;amp;t=3GITA7PeX7pGwrqvt97bYQ&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;Scaling Laws for Generative Mixed-Modal Language Models&lt;/strong&gt; - introduces scaling laws for generative mixed-modal language models.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.03728&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1614676694920531969?s=20&amp;amp;t=3GITA7PeX7pGwrqvt97bYQ&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;DeepMatcher: A Deep Transformer-based Network for Robust and Accurate Local Feature Matching&lt;/strong&gt; - a transformer-based network showing robust local feature matching, outperforming the state-of-the-art methods on several benchmarks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.02993&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1614676697516752898?s=20&amp;amp;t=3GITA7PeX7pGwrqvt97bYQ&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;Generative Time Series Forecasting with Diffusion, Denoise, and Disentanglement&lt;/strong&gt; - addresses the time series forecasting problem with generative modeling; involves a bidirectional VAE backbone equipped with diffusion, denoising for prediction accuracy, and disentanglement for model interpretability.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.03028&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1614676699915980804?s=20&amp;amp;t=3GITA7PeX7pGwrqvt97bYQ&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Top ML Papers of the Week (Jan 1-8)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Paper&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1) &lt;strong&gt;Muse: Text-To-Image Generation via Masked Generative Transformers&lt;/strong&gt; - introduces Muse, a new text-to-image generation model based on masked generative transformers; significantly more efficient than other diffusion models like Imagen and DALLE-2.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.00704&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://muse-model.github.io/&#34;&gt;Project&lt;/a&gt;, &lt;a href=&#34;https://github.com/lucidrains/muse-maskgit-pytorch&#34;&gt;Code&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1612153095772938241?s=20&amp;amp;t=ChwZWzSmoRlZKnD54fsV6w&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2) &lt;strong&gt;VALL-E Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers&lt;/strong&gt; - introduces VALL-E, a text-to-audio model that performs state-of-the-art zero-shot performance; the text-to-speech synthesis task is treated as a conditional language modeling task.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://valle-demo.github.io/&#34;&gt;Project&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1612153097962328067?s=20&amp;amp;t=ChwZWzSmoRlZKnD54fsV6w&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3) &lt;strong&gt;Rethinking with Retrieval: Faithful Large Language Model Inference&lt;/strong&gt; - shows the potential of enhancing LLMs by retrieving relevant external knowledge based on decomposed reasoning steps obtained through chain-of-thought prompting.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.00303&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1612153100114055171?s=20&amp;amp;t=ChwZWzSmoRlZKnD54fsV6w&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4) &lt;strong&gt;SparseGPT: Massive Language Models Can Be Accurately Pruned In One-Shot&lt;/strong&gt; - presents a technique for compressing large language models while not sacrificing performance; &#34;pruned to at least 50% sparsity in one-shot, without any retraining.&#34;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.00774&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1612153102513360901?s=20&amp;amp;t=ChwZWzSmoRlZKnD54fsV6w&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5) &lt;strong&gt;ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders&lt;/strong&gt; - a performant model based on a fully convolutional masked autoencoder framework and other architectural improvements. CNNs are sticking back!&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.00808&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/facebookresearch/convnext-v2&#34;&gt;Code&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1612153104329281538?s=20&amp;amp;t=ChwZWzSmoRlZKnD54fsV6w&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6) &lt;strong&gt;Large Language Models as Corporate Lobbyists&lt;/strong&gt; - with more capabilities, we are starting to see a wider range of applications with LLMs. This paper utilized large language models for conducting corporate lobbying activities.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.01181&#34;&gt;Paper&lt;/a&gt; , &lt;a href=&#34;https://github.com/JohnNay/llm-lobbyist&#34;&gt;Code&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1612153106355130372?s=20&amp;amp;t=ChwZWzSmoRlZKnD54fsV6w&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7) &lt;strong&gt;Superposition, Memorization, and Double Descent&lt;/strong&gt; - aims to better understand how deep learning models overfit or memorize examples; interesting phenomena observed; important work toward a mechanistic theory of memorization.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://transformer-circuits.pub/2023/toy-double-descent/index.html&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1612153108460892160?s=20&amp;amp;t=ChwZWzSmoRlZKnD54fsV6w&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8) &lt;strong&gt;StitchNet: Composing Neural Networks from Pre-Trained Fragments&lt;/strong&gt; - new idea to create new coherent neural networks by reusing pretrained fragments of existing NNs. Not straightforward but there is potential in terms of efficiently reusing learned knowledge in pre-trained networks for complex tasks.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.01947&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1612153110452903936?s=20&amp;amp;t=ChwZWzSmoRlZKnD54fsV6w&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9) &lt;strong&gt;Iterated Decomposition: Improving Science Q&amp;amp;A by Supervising Reasoning Processes&lt;/strong&gt; - proposes integrated decomposition, an approach to improve Science Q&amp;amp;A through a human-in-the-loop workflow for refining compositional LM programs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.01751&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://github.com/oughtinc/ice&#34;&gt;Code&lt;/a&gt; &lt;a href=&#34;https://twitter.com/dair_ai/status/1612153112638402562?s=20&amp;amp;t=ChwZWzSmoRlZKnD54fsV6w&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10) &lt;strong&gt;A Succinct Summary of Reinforcement Learning&lt;/strong&gt; - a nice overview of some important ideas in RL.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.01379&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/dair_ai/status/1612153114773053446?s=20&amp;amp;t=ChwZWzSmoRlZKnD54fsV6w&#34;&gt;Tweet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;We use a combination of AI-powered tools, analytics, and human curation to build the lists of papers.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://nlpnews.substack.com/&#34;&gt;Subscribe to our NLP Newsletter&lt;/a&gt; to stay on top of ML research and trends.&lt;/p&gt; &#xA;&lt;p&gt;Join our &lt;a href=&#34;https://discord.gg/FzNtjEK9dg&#34;&gt;Discord&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>crablang/crab</title>
    <updated>2023-06-02T01:30:38Z</updated>
    <id>tag:github.com,2023-06-02:/crablang/crab</id>
    <link href="https://github.com/crablang/crab" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A community fork of a language named after a plant fungus. All of the memory-safe features you love, now with 100% less bureaucracy!&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/8974888/231858967-7c37bf1e-335b-4f5a-9760-da97be9f54bb.png&#34; width=&#34;200&#34;&gt; &#xA;&lt;h1&gt;The Crab Programming Language&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://community.crablang.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/CrabLang_Community%20-Join_us-brightgreen?style=plastic&amp;amp;logo=discord&#34; alt=&#34;CrabLang Community&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is the main source code repository for &lt;a href=&#34;https://github.com/crablang/crab&#34;&gt;Crab&lt;/a&gt;. It contains the compiler, standard library, and documentation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note: this README is for &lt;em&gt;users&lt;/em&gt; rather than &lt;em&gt;contributors&lt;/em&gt;.&lt;/strong&gt; If you wish to &lt;em&gt;contribute&lt;/em&gt; to the compiler, you should read &lt;a href=&#34;https://raw.githubusercontent.com/crablang/crab/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; instead.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;To get started with the renamed CrabLang toolchain, run the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sh &amp;lt;(curl https://install.crablang.org -L)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;* currently Unix only&lt;/p&gt; &#xA;&lt;!-- &#xA;Read [&#34;Installation&#34;] from [The Book].&#xA;&#xA;[&#34;Installation&#34;]: https://doc.crablang.org/book/ch01-01-installation.html&#xA;[The Book]: https://doc.crablang.org/book/index.html --&gt; &#xA;&lt;h2&gt;Installing from Source&lt;/h2&gt; &#xA;&lt;p&gt;The Crab build system uses a Python script called &lt;code&gt;x.py&lt;/code&gt; to build the compiler, which manages the bootstrapping process. It lives at the root of the project.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;x.py&lt;/code&gt; command can be run directly on most Unix systems in the following format:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./x.py &amp;lt;subcommand&amp;gt; [flags]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is how the documentation and examples assume you are running &lt;code&gt;x.py&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Some alternative ways are:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# On a Unix shell if you don&#39;t have the necessary `python3` command&#xA;./x &amp;lt;subcommand&amp;gt; [flags]&#xA;&#xA;# On the Windows Command Prompt (if .py files are configured to run Python)&#xA;x.py &amp;lt;subcommand&amp;gt; [flags]&#xA;&#xA;# You can also run Python yourself, e.g.:&#xA;python x.py &amp;lt;subcommand&amp;gt; [flags]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;More information about &lt;code&gt;x.py&lt;/code&gt; can be found by running it with the &lt;code&gt;--help&lt;/code&gt; flag or reading the &lt;a href=&#34;https://crabc-dev-guide.crablang.org/building/how-to-build-and-run.html&#34;&gt;crabc dev guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Dependencies&lt;/h3&gt; &#xA;&lt;p&gt;Make sure you have installed the dependencies:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;python&lt;/code&gt; 3 or 2.7&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;git&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;A C compiler (when building for the host, &lt;code&gt;cc&lt;/code&gt; is enough; cross-compiling may need additional compilers)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;curl&lt;/code&gt; (not needed on Windows)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;pkg-config&lt;/code&gt; if you are compiling on Linux and targeting Linux&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;libiconv&lt;/code&gt; (already included with glibc on Debian-based distros)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To build Crabgo, you&#39;ll also need OpenSSL (&lt;code&gt;libssl-dev&lt;/code&gt; or &lt;code&gt;openssl-devel&lt;/code&gt; on most Unix distros).&lt;/p&gt; &#xA;&lt;p&gt;If building LLVM from source, you&#39;ll need additional tools:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;g++&lt;/code&gt;, &lt;code&gt;clang++&lt;/code&gt;, or MSVC with versions listed on &lt;a href=&#34;https://llvm.org/docs/GettingStarted.html#host-c-toolchain-both-compiler-and-standard-library&#34;&gt;LLVM&#39;s documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;ninja&lt;/code&gt;, or GNU &lt;code&gt;make&lt;/code&gt; 3.81 or later (Ninja is recommended, especially on Windows)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;cmake&lt;/code&gt; 3.13.4 or later&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;libstdc++-static&lt;/code&gt; may be required on some Linux distributions such as Fedora and Ubuntu&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;On tier 1 or tier 2 with host tools platforms, you can also choose to download LLVM by setting &lt;code&gt;llvm.download-ci-llvm = true&lt;/code&gt;. Otherwise, you&#39;ll need LLVM installed and &lt;code&gt;llvm-config&lt;/code&gt; in your path. See &lt;a href=&#34;https://crabc-dev-guide.crablang.org/building/new-target.html#using-pre-built-llvm&#34;&gt;the crabc-dev-guide for more info&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Building on a Unix-like system&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Clone the &lt;a href=&#34;https://github.com/crablang/crablang&#34;&gt;source&lt;/a&gt; with &lt;code&gt;git&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/crablang/crab.git&#xA;cd crab&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Configure the build settings:&lt;/p&gt; &lt;p&gt;The CrabLang build system uses a file named &lt;code&gt;config.toml&lt;/code&gt; in the root of the source tree to determine various configuration settings for the build. Set up the defaults intended for distros to get started. You can see a full list of options in &lt;code&gt;config.example.toml&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;printf &#39;profile = &#34;user&#34; \nchangelog-seen = 2 \n&#39; &amp;gt; config.toml&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you plan to use &lt;code&gt;x.py install&lt;/code&gt; to create an installation, it is recommended that you set the &lt;code&gt;prefix&lt;/code&gt; value in the &lt;code&gt;[install]&lt;/code&gt; section to a directory.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Build and install:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./x.py build &amp;amp;&amp;amp; ./x.py install&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When complete, &lt;code&gt;./x.py install&lt;/code&gt; will place several programs into &lt;code&gt;$PREFIX/bin&lt;/code&gt;: &lt;code&gt;crabc&lt;/code&gt;, the CrabLang compiler, and &lt;code&gt;crablangdoc&lt;/code&gt;, the API-documentation tool. If you&#39;ve set &lt;code&gt;profile = &#34;user&#34;&lt;/code&gt; or &lt;code&gt;build.extended = true&lt;/code&gt;, it will also include &lt;a href=&#34;https://github.com/crablang/crabgo&#34;&gt;Crabgo&lt;/a&gt;, CrabLang&#39;s package manager.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Building on Windows&lt;/h3&gt; &#xA;&lt;p&gt;On Windows, we suggest using &lt;a href=&#34;https://github.com/microsoft/winget-cli&#34;&gt;winget&lt;/a&gt; to install dependencies by running the following in a terminal:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;winget install -e Python.Python.3&#xA;winget install -e Kitware.CMake&#xA;winget install -e Git.Git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then edit your system&#39;s &lt;code&gt;PATH&lt;/code&gt; variable and add: &lt;code&gt;C:\Program Files\CMake\bin&lt;/code&gt;. See &lt;a href=&#34;https://www.java.com/en/download/help/path.html&#34;&gt;this guide on editing the system &lt;code&gt;PATH&lt;/code&gt;&lt;/a&gt; from the Java documentation.&lt;/p&gt; &#xA;&lt;p&gt;There are two prominent ABIs in use on Windows: the native (MSVC) ABI used by Visual Studio and the GNU ABI used by the GCC toolchain. Which version of CrabLang you need depends largely on what C/C++ libraries you want to interoperate with. Use the MSVC build of CrabLang to interop with software produced by Visual Studio and the GNU build to interop with GNU software built using the MinGW/MSYS2 toolchain.&lt;/p&gt; &#xA;&lt;h4&gt;MinGW&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.msys2.org/&#34;&gt;MSYS2&lt;/a&gt; can be used to easily build CrabLang on Windows:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Download the latest &lt;a href=&#34;https://www.msys2.org/&#34;&gt;MSYS2 installer&lt;/a&gt; and go through the installer.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run &lt;code&gt;mingw32_shell.bat&lt;/code&gt; or &lt;code&gt;mingw64_shell.bat&lt;/code&gt; from the MSYS2 installation directory (e.g. &lt;code&gt;C:\msys64&lt;/code&gt;), depending on whether you want 32-bit or 64-bit CrabLang. (As of the latest version of MSYS2 you have to run &lt;code&gt;msys2_shell.cmd -mingw32&lt;/code&gt; or &lt;code&gt;msys2_shell.cmd -mingw64&lt;/code&gt; from the command line instead.)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;From this terminal, install the required tools:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# Update package mirrors (may be needed if you have a fresh install of MSYS2)&#xA;pacman -Sy pacman-mirrors&#xA;&#xA;# Install build tools needed for CrabLang. If you&#39;re building a 32-bit compiler,&#xA;# then replace &#34;x86_64&#34; below with &#34;i686&#34;. If you&#39;ve already got Git, Python,&#xA;# or CMake installed and in PATH you can remove them from this list.&#xA;# Note that it is important that you do **not** use the &#39;python2&#39;, &#39;cmake&#39;,&#xA;# and &#39;ninja&#39; packages from the &#39;msys2&#39; subsystem.&#xA;# The build has historically been known to fail with these packages.&#xA;pacman -S git \&#xA;            make \&#xA;            diffutils \&#xA;            tar \&#xA;            mingw-w64-x86_64-python \&#xA;            mingw-w64-x86_64-cmake \&#xA;            mingw-w64-x86_64-gcc \&#xA;            mingw-w64-x86_64-ninja&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Navigate to CrabLang&#39;s source code (or clone it), then build it:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./x.py build &amp;amp;&amp;amp; ./x.py install&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;MSVC&lt;/h4&gt; &#xA;&lt;p&gt;MSVC builds of CrabLang additionally require an installation of Visual Studio 2017 (or later) so &lt;code&gt;crabc&lt;/code&gt; can use its linker. The simplest way is to get &lt;a href=&#34;https://visualstudio.microsoft.com/downloads/&#34;&gt;Visual Studio&lt;/a&gt;, check the &#34;C++ build tools&#34; and &#34;Windows 10 SDK&#34; workload.&lt;/p&gt; &#xA;&lt;p&gt;(If you&#39;re installing CMake yourself, be careful that &#34;C++ CMake tools for Windows&#34; doesn&#39;t get included under &#34;Individual components&#34;.)&lt;/p&gt; &#xA;&lt;p&gt;With these dependencies installed, you can build the compiler in a &lt;code&gt;cmd.exe&lt;/code&gt; shell with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python x.py build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Right now, building CrabLang only works with some known versions of Visual Studio. If you have a more recent version installed and the build system doesn&#39;t understand, you may need to force crablangbuild to use an older version. This can be done by manually calling the appropriate vcvars file before running the bootstrap.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;CALL &#34;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Auxiliary\Build\vcvars64.bat&#34;&#xA;python x.py build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Specifying an ABI&lt;/h4&gt; &#xA;&lt;p&gt;Each specific ABI can also be used from either environment (for example, using the GNU ABI in PowerShell) by using an explicit build triple. The available Windows build triples are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;GNU ABI (using GCC) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;i686-pc-windows-gnu&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;x86_64-pc-windows-gnu&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;The MSVC ABI &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;i686-pc-windows-msvc&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;x86_64-pc-windows-msvc&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The build triple can be specified by either specifying &lt;code&gt;--build=&amp;lt;triple&amp;gt;&lt;/code&gt; when invoking &lt;code&gt;x.py&lt;/code&gt; commands, or by creating a &lt;code&gt;config.toml&lt;/code&gt; file (as described in &lt;a href=&#34;https://raw.githubusercontent.com/crablang/crab/master/#installing-from-source&#34;&gt;Installing from Source&lt;/a&gt;), and modifying the &lt;code&gt;build&lt;/code&gt; option under the &lt;code&gt;[build]&lt;/code&gt; section.&lt;/p&gt; &#xA;&lt;h3&gt;Configure and Make&lt;/h3&gt; &#xA;&lt;p&gt;While it&#39;s not the recommended build system, this project also provides a configure script and makefile (the latter of which just invokes &lt;code&gt;x.py&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./configure&#xA;make &amp;amp;&amp;amp; sudo make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;configure&lt;/code&gt; generates a &lt;code&gt;config.toml&lt;/code&gt; which can also be used with normal &lt;code&gt;x.py&lt;/code&gt; invocations.&lt;/p&gt; &#xA;&lt;h2&gt;Building Documentation&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;d like to build the documentation, it&#39;s almost the same:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./x.py doc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The generated documentation will appear under &lt;code&gt;doc&lt;/code&gt; in the &lt;code&gt;build&lt;/code&gt; directory for the ABI used. That is, if the ABI was &lt;code&gt;x86_64-pc-windows-msvc&lt;/code&gt;, the directory will be &lt;code&gt;build\x86_64-pc-windows-msvc\doc&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Notes&lt;/h2&gt; &#xA;&lt;p&gt;Since the CrabLang compiler is written in CrabLang, it must be built by a precompiled &#34;snapshot&#34; version of itself (made in an earlier stage of development). As such, source builds require an Internet connection to fetch snapshots, and an OS that can execute the available snapshot binaries.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://doc.crablang.org/nightly/crabc/platform-support.html&#34;&gt;https://doc.crablang.org/nightly/crabc/platform-support.html&lt;/a&gt; for a list of supported platforms. Only &#34;host tools&#34; platforms have a pre-compiled snapshot binary available; to compile for a platform without host tools you must cross-compile.&lt;/p&gt; &#xA;&lt;p&gt;You may find that other platforms work, but these are our officially supported build environments that are most likely to work.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Help&lt;/h2&gt; &#xA;&lt;p&gt;Need help? Join us on discord at &lt;a href=&#34;https://community.crablang.org&#34;&gt;https://community.crablang.org&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/crablang/crab/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;CrabLang is primarily distributed under the terms of both the MIT license and the Apache License (Version 2.0), with portions covered by various BSD-like licenses.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/crablang/crab/master/LICENSE-APACHE&#34;&gt;LICENSE-APACHE&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/crablang/crab/master/LICENSE-MIT&#34;&gt;LICENSE-MIT&lt;/a&gt;, and &lt;a href=&#34;https://raw.githubusercontent.com/crablang/crab/master/COPYRIGHT&#34;&gt;COPYRIGHT&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;h2&gt;Trademark&lt;/h2&gt; &#xA;&lt;p&gt;If you want to use any names or brands associated with Crab or CrabLang, please feel free to do so in any capacity.&lt;/p&gt; &#xA;&lt;p&gt;Third-party logos may be subject to third-party copyrights and trademarks. See &lt;a href=&#34;https://www.crablang.org/policies/licenses&#34;&gt;Licenses&lt;/a&gt; for details.&lt;/p&gt;</summary>
  </entry>
</feed>