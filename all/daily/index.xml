<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-06T01:34:41Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>QSCTech/zju-icicles</title>
    <updated>2022-06-06T01:34:41Z</updated>
    <id>tag:github.com,2022-06-06:/QSCTech/zju-icicles</id>
    <link href="https://github.com/QSCTech/zju-icicles" rel="alternate"></link>
    <summary type="html">&lt;p&gt;浙江大学课程攻略共享计划&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;浙江大学课程攻略共享计划&lt;/h1&gt; &#xA;&lt;h2&gt;前言&lt;/h2&gt; &#xA;&lt;p&gt;来到一所大学，从第一次接触许多课，直到一门一门完成，这个过程中我们时常收集起许多资料和情报。&lt;/p&gt; &#xA;&lt;p&gt;有些是需要在网上搜索的电子书，每次见到一门新课程，Google 一下教材名称，有的可以立即找到，有的却是要花费许多眼力；有些是历年试卷或者 A4 纸，前人精心收集制作，抱着能对他人有用的想法公开，却需要在各个群或者 CC98 中摸索以至于从学长手中代代相传；有些是上完一门课才恍然领悟的技巧，原来这门课重点如此，当初本可以更轻松地完成得更好……&lt;/p&gt; &#xA;&lt;p&gt;我也曾很努力地收集各种课程资料，但到最后，某些重要信息的得到却往往依然是纯属偶然。这种状态时常令我感到后怕与不安。我也曾在课程结束后终于有了些许方法与总结，但这些想法无处诉说，最终只能把花费时间与精力才换来的经验耗散在了漫漫的遗忘之中。&lt;/p&gt; &#xA;&lt;p&gt;我为这一年一年，这么多人孤军奋战的重复劳动感到不平。&lt;/p&gt; &#xA;&lt;p&gt;我希望能够将这些隐晦的、不确定的、口口相传的资料和经验，变为公开的、易于获取的和大家能够共同完善、积累的共享资料。&lt;/p&gt; &#xA;&lt;p&gt;我希望只要是前人走过的弯路，后人就不必再走。这是我的信念，也是我建立这个项目的原因。&lt;/p&gt; &#xA;&lt;h2&gt;特性&lt;/h2&gt; &#xA;&lt;p&gt;本项目至今为止收录了以下内容：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;选课攻略&lt;/li&gt; &#xA; &lt;li&gt;电子版教材&lt;/li&gt; &#xA; &lt;li&gt;平时作业答案&lt;/li&gt; &#xA; &lt;li&gt;历年试卷&lt;/li&gt; &#xA; &lt;li&gt;复习资料&lt;/li&gt; &#xA; &lt;li&gt;开卷考试 A4 纸&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;等等。目前项目已覆盖大多数计科的专业课程。&lt;/p&gt; &#xA;&lt;h2&gt;平台&lt;/h2&gt; &#xA;&lt;p&gt;为什么采用 GitHub 项目作为平台呢？我有以下一些考虑。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;QQ 群大多为年级和专业所分隔，无法长期共同地保有；况且群文件也缺乏组织。&lt;/li&gt; &#xA; &lt;li&gt;GitHub 项目可以使用目录进行文件组织，并且每个目录均可以在显示文件列表的同时显示一个 README，十分适合本项目的需求。&lt;/li&gt; &#xA; &lt;li&gt;GitHub 带有便捷的 Issue 和 Pull Request 协作功能，并且可以方便地对贡献的质量进行监督和调整。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;贡献&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;欢迎贡献！&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;欢迎贡献！&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;欢迎贡献！&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;——因为很重要所以说了三遍&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Issue、PR、纠错、资料、选课/考试攻略，完全欢迎！&lt;/p&gt; &#xA;&lt;p&gt;来自大家的关注、维护和贡献，才是让这个浙江大学独有的攻略本继续存在的动力~&lt;/p&gt; &#xA;&lt;h3&gt;操作方法&lt;/h3&gt; &#xA;&lt;p&gt;提交 PR：Fork 本项目，然后在 GitHub 网页端点击 Upload File 上传文件，发起 PR 即可。留意一下项目的文件组织喔。&lt;/p&gt; &#xA;&lt;p&gt;或者也可以直接附加在 Issue 中，由维护者进行添加。&lt;/p&gt; &#xA;&lt;p&gt;对于教师的评价请一律使用姓名拼音首字母缩写；至于教师提供的课件就不用上传了，因为每年说不定会有更新的嘛。&lt;/p&gt; &#xA;&lt;p&gt;由于本项目体积很大，故可以采用在Github Web端直接上传的方式，具体操作如下：&lt;/p&gt; &#xA;&lt;ol start=&#34;0&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;首先Fork本项目&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;上传文件到已有文件夹：打开对应文件夹，点击绿色Download按钮旁的upload，上传你的文件。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;上传文件到新文件夹：打开任意文件夹，点击绿色Download按钮旁的upload，&lt;strong&gt;把浏览器地址栏中文件夹名称改为你想要新建的文件夹名称，然后回车&lt;/strong&gt;，上传你的文件。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;提醒&lt;/h3&gt; &#xA;&lt;p&gt;有些朋友在提交 PR 的时候可能会注意到自己的 Fork 和我们的主分支有数十甚至上百个不同的 commit 。如果出现这种情况，可以考虑以下两种解决方案：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;如果对git不太熟悉，建议（在备份完成后）先删除你的项目，重新 fork 、上传并重新提交 PR 。&lt;/li&gt; &#xA; &lt;li&gt;如果对git及其工作原理较为熟悉（而且愿意花费时间和流量折腾），可以尝试在 fork 出的项目上进行 rebase 以消除与主分支在历史上的冲突。&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;警告&lt;/h3&gt; &#xA;&lt;p&gt;下列内容为不适合上传的内容。如果你认为缺少这些资料将会影响资源的完整性，请优先考虑放在校内资源平台，或联系你的教师并由教师发布。建议你撰写一个 README 文档并放置一些链接或指引文字来帮助找到这些资源。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;盗版电子书/付费电子书&lt;/li&gt; &#xA; &lt;li&gt;盗版/破解版/绿色版付费软件及其安装包&lt;/li&gt; &#xA; &lt;li&gt;课程/教师主页上列出的内容（请在获得教师许可后上传）&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;如果你认为本仓库的一些文件侵犯了您的权益，请 &lt;a href=&#34;mailto:tech@zjuqsc.com&#34;&gt;向我们发送邮件&lt;/a&gt; 。我们将会从仓库中彻底清除这些文件。&lt;/p&gt; &#xA;&lt;h2&gt;许可&lt;/h2&gt; &#xA;&lt;p&gt;由贡献者编写部分的许可如下：&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh&#34;&gt;CC-BY-NC-SA：署名-非商业性使用-相同方式共享&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;资料仅供参考，请自己判断其适用性。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;其他部分的版权归属于其各自的作者。&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>v2fly/v2ray-core</title>
    <updated>2022-06-06T01:34:41Z</updated>
    <id>tag:github.com,2022-06-06:/v2fly/v2ray-core</id>
    <link href="https://github.com/v2fly/v2ray-core" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A platform for building proxies to bypass network restrictions.&lt;/p&gt;&lt;hr&gt;&lt;div&gt; &#xA; &lt;img width=&#34;190&#34; height=&#34;210&#34; align=&#34;left&#34; src=&#34;https://raw.githubusercontent.com/v2fly/v2fly-github-io/master/docs/.vuepress/public/readme-logo.png&#34; alt=&#34;V2Ray&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;h1&gt;Project V&lt;/h1&gt; &#xA; &lt;p&gt;Project V is a set of network tools that helps you to build your own computer network. It secures your network connections and thus protects your privacy.&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/v2fly/v2ray-core/actions&#34;&gt;&lt;img src=&#34;https://github.com/v2fly/v2ray-core/workflows/Test/badge.svg?sanitize=true&#34; alt=&#34;GitHub Test Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/v2fly/v2ray-core?branch=master&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/v2fly/v2ray-core/branch/master/graph/badge.svg?branch=master&#34; alt=&#34;codecov.io&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://goreportcard.com/report/github.com/v2fly/v2ray-core&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/v2fly/v2ray-core&#34; alt=&#34;codebeat&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.codacy.com/gh/v2fly/v2ray-core/dashboard?utm_source=github.com&amp;amp;utm_medium=referral&amp;amp;utm_content=v2fly/v2ray-core&amp;amp;utm_campaign=Badge_Grade&#34;&gt;&lt;img src=&#34;https://app.codacy.com/project/badge/Grade/e150b7ede2114388921943bf23d95161&#34; alt=&#34;Codacy Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/v2fly/v2ray-core/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/downloads/v2fly/v2ray-core/total.svg?sanitize=true&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Related Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.v2fly.org&#34;&gt;Documentation&lt;/a&gt; and &lt;a href=&#34;https://www.v2fly.org/guide/start.html&#34;&gt;Newcomer&#39;s Instructions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Welcome to translate V2Ray documents via &lt;a href=&#34;https://www.transifex.com/v2fly/public/&#34;&gt;Transifex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Packaging Status&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;If you are willing to package V2Ray for other distros/platforms, please let us know or seek for help via &lt;a href=&#34;https://github.com/v2fly/v2ray-core/issues&#34;&gt;GitHub issues&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://repology.org/project/v2ray/versions&#34;&gt;&lt;img src=&#34;https://repology.org/badge/vertical-allrepos/v2ray.svg?sanitize=true&#34; alt=&#34;Packaging status&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/v2fly/v2ray-core/master/LICENSE&#34;&gt;The MIT License (MIT)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;This repo relies on the following third-party projects:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;In production:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/gorilla/websocket&#34;&gt;gorilla/websocket&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/lucas-clemente/quic-go&#34;&gt;lucas-clemente/quic-go&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/pires/go-proxyproto&#34;&gt;pires/go-proxyproto&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/seiflotfy/cuckoofilter&#34;&gt;seiflotfy/cuckoofilter&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/google/starlark-go&#34;&gt;google/starlark-go&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/jhump/protoreflect&#34;&gt;jhump/protoreflect&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/inetaf/netaddr&#34;&gt;inetaf/netaddr&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For testing only:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/miekg/dns&#34;&gt;miekg/dns&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/h12w/socks&#34;&gt;h12w/socks&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>arc298/instagram-scraper</title>
    <updated>2022-06-06T01:34:41Z</updated>
    <id>tag:github.com,2022-06-06:/arc298/instagram-scraper</id>
    <link href="https://github.com/arc298/instagram-scraper" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Scrapes an instagram user&#39;s photos and videos&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://camo.githubusercontent.com/9ac4a1f7f5ea0f573451b5ddc06e29c8aa113a85/68747470733a2f2f692e696d6775722e636f6d2f6948326a6468562e706e67&#34; align=&#34;right&#34;&gt; &#xA;&lt;h1&gt;Instagram Scraper&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pypi.python.org/pypi/instagram-scraper&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/instagram-scraper.svg?sanitize=true&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://travis-ci.com/arc298/instagram-scraper&#34;&gt;&lt;img src=&#34;https://travis-ci.com/arc298/instagram-scraper.svg?branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/pypi/implementation/instagram-scraper&#34; alt=&#34;PyPI - Implementation&#34;&gt; &lt;img src=&#34;https://img.shields.io/pypi/wheel/instagram-scraper&#34; alt=&#34;PyPI - Wheel&#34;&gt; &lt;a href=&#34;https://ko-fi.com/alexnik&#34;&gt;&lt;img src=&#34;https://uploads-ssl.webflow.com/5c14e387dab576fe667689cf/61e11d6ea0473a3528b575b4_Button-3-p-500.png&#34; alt=&#34;Buy me a beer&#34; height=&#34;21&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;instagram-scraper is a command-line application written in Python that scrapes and downloads an instagram user&#39;s photos and videos. Use responsibly.&lt;/p&gt; &#xA;&lt;img src=&#34;https://cloud.githubusercontent.com/assets/140931/26286476/8232e15e-3e34-11e7-9e1c-9ecda92950e1.gif&#34;&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;To install instagram-scraper:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pip install instagram-scraper&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To update instagram-scraper:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pip install instagram-scraper --upgrade&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, you can clone the project and run the following command to install: Make sure you cd into the &lt;em&gt;instagram-scraper-master&lt;/em&gt; folder before performing the command below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python setup.py install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;To scrape a user&#39;s media:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ instagram-scraper &amp;lt;username&amp;gt; -u &amp;lt;your username&amp;gt; -p &amp;lt;your password&amp;gt;             &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;NOTE: To scrape a private user&#39;s media you must be an approved follower.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;By default, downloaded media will be placed in &lt;code&gt;&amp;lt;current working directory&amp;gt;/&amp;lt;username&amp;gt;&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Providing username and password is optional, if not supplied the scraper runs as a guest. &lt;em&gt;Note: In this case all private user&#39;s media will be unavailable. All user&#39;s stories and high resolution profile pictures will also be unavailable.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;To scrape a hashtag for media:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ instagram-scraper &amp;lt;hashtag without #&amp;gt; --tag          &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;It may be useful to specify the &lt;code&gt;--maximum &amp;lt;#&amp;gt;&lt;/code&gt; argument to limit the total number of items to scrape when scraping by hashtag.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;To specify multiple users, pass a delimited list of users:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ instagram-scraper username1,username2,username3           &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also supply a file containing a list of usernames:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ instagram-scraper -f ig_users.txt           &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# ig_users.txt&#xA;&#xA;username1&#xA;username2&#xA;username3&#xA;&#xA;# and so on...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;The usernames may be separated by newlines, commas, semicolons, or whitespace.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can also supply a file containing a list of location ids:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ instagram-scraper --tag &amp;lt;your_tag_here&amp;gt; --include-location --filter_location_file my_locations.txt           &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# my_locations.txt&#xA;[some_reagion1]&#xA;location_id1&#xA;location_id2&#xA;&#xA;[some_region2]&#xA;location_id3&#xA;location_id4&#xA;&#xA;# and so on...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The resulting directory structure will be:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;your_tag&#xA;├── some_reagion1&#xA;│   └── images_here&#xA;└── some_reagion2&#xA;    └── images_here&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;The locations can only be separated by newlines and spaces.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;OPTIONS&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;--help -h               Show help message and exit.&#xA;&#xA;--login-user  -u        Instagram login user.&#xA;&#xA;--login-pass  -p        Instagram login password.&#xA;&#xA;--followings-input      Use profiles followed by login-user as input&#xA;&#xA;--followings-output     Output profiles from --followings-input to file&#xA;&#xA;--filename    -f        Path to a file containing a list of users to scrape.&#xA;&#xA;--destination -d        Specify the download destination. By default, media will &#xA;                        be downloaded to &amp;lt;current working directory&amp;gt;/&amp;lt;username&amp;gt;.&#xA;&#xA;--retain-username -n    Creates a username subdirectory when the destination flag is&#xA;                        set.&#xA;&#xA;--media-types -t        Specify media types to scrape. Enter as space separated values. &#xA;                        Valid values are image, video, story (story-image &amp;amp; story-video), broadcast&#xA;                        or none. Stories require a --login-user and --login-pass to be defined.&#xA;                      &#xA;--latest                Scrape only new media since the last scrape. Uses the last modified&#xA;                        time of the latest media item in the destination directory to compare.&#xA;&#xA;--latest-stamps         Specify a file to save the timestamps of latest media scraped by user.&#xA;                        This works similarly to `--latest` except the file specified by&#xA;                        `--latest-stamps` will store the last modified time instead of using &#xA;                        timestamps of media items in the destination directory. &#xA;                        This allows the destination directories to be emptied whilst &#xA;                        still maintaining history.&#xA;&#xA;--cookiejar             File in which to store cookies so that they can be reused between runs.&#xA;&#xA;--quiet       -q        Be quiet while scraping.&#xA;&#xA;--maximum     -m        Maximum number of items to scrape.&#xA;&#xA;--media-metadata        Saves the media metadata associated with the user&#39;s posts to &#xA;                        &amp;lt;destination&amp;gt;/&amp;lt;username&amp;gt;.json. Can be combined with --media-types none&#xA;                        to only fetch the metadata without downloading the media.&#xA;&#xA;--include-location      Includes location metadata when saving media metadata. &#xA;                        Implicitly includes --media-metadata.&#xA;&#xA;--profile-metadata      Saves the user profile metadata to  &amp;lt;destination&amp;gt;/&amp;lt;username&amp;gt;.json.&#xA;&#xA;--proxies               Enable use of proxies, add a valid JSON with http or/and https urls.&#xA;                        Example: &#39;{&#34;http&#34;: &#34;http://&amp;lt;ip&amp;gt;:&amp;lt;port&amp;gt;&#34;, &#34;https&#34;: &#34;https://&amp;lt;ip&amp;gt;:&amp;lt;port&amp;gt;&#34; }&#39;&#xA;&#xA;--comments             Saves the comment metadata associated with the posts to &#xA;                       &amp;lt;destination&amp;gt;/&amp;lt;username&amp;gt;.json. Implicitly includes --media-metadata.&#xA;                    &#xA;--interactive -i       Enables interactive login challenge solving. Has 2 modes: SMS and Email&#xA;&#xA;--retry-forever        Retry download attempts endlessly when errors are received&#xA;&#xA;--tag                   Scrapes the specified hashtag for media.&#xA;&#xA;--filter                Scrapes the specified hashtag within a user&#39;s media.&#xA;&#xA;--filter_location       Filter scrape queries by command line location(s) ids&#xA;&#xA;--filter_location_file  Provide location ids by file to filter queries &#xA;&#xA;--location              Scrapes the specified instagram location-id for media.&#xA;&#xA;--search-location       Search for a location by name. Useful for determining the location-id of &#xA;                        a specific place.&#xA;                    &#xA;--template -T           Customize and format each file&#39;s name.&#xA;                        Default: {urlname}&#xA;                        Options:&#xA;                        {username}: Scraped user&#xA;                        {shortcode}: Post shortcode (profile_pic and story are empty)&#xA;                        {urlname}: Original file name from url.&#xA;                        {mediatype}: The type of media being downloaded.&#xA;                        {datetime}: Date and time of upload. (Format: 20180101 01h01m01s)&#xA;                        {date}: Date of upload. (Format: 20180101)&#xA;                        {year}: Year of upload. (Format: 2018)&#xA;                        {month}: Month of upload. (Format: 01-12)&#xA;                        {day}: Day of upload. (Format: 01-31)&#xA;                        {h}: Hour of upload. (Format: 00-23h)&#xA;                        {m}: Minute of upload. (Format: 00-59m)&#xA;                        {s}: Second of upload. (Format: 00-59s)&#xA;&#xA;                        If the template is invalid, it will revert to the default.&#xA;                        Does not work with --tag and --location.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage as library&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pprint import pprint&#xA;import instagram_scraper&#xA;&#xA;args = {&#34;login_user&#34;: &#34;LOGIN&#34;, &#34;login_pass&#34;: &#34;PASSWORD&#34;}&#xA;&#xA;insta_scraper = instagram_scraper.InstagramScraper(**args)&#xA;insta_scraper.authenticate_with_login()&#xA;shared_data = insta_scraper.get_shared_data_userinfo(username=&#39;SCRAPED_USERNAME&#39;)&#xA;&#xA;arr = []&#xA;&#xA;for item in insta_scraper.query_media_gen(shared_data):&#xA;    arr.append(item)&#xA;&#xA;pprint(arr)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Docker&lt;/h2&gt; &#xA;&lt;p&gt;How to install Docker see &lt;a href=&#34;https://docs.docker.com/engine/install/&#34;&gt;https://docs.docker.com/engine/install/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Don&#39;t forget to run postinstall steps for Linux &lt;a href=&#34;https://docs.docker.com/engine/install/linux-postinstall/&#34;&gt;https://docs.docker.com/engine/install/linux-postinstall/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Build&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker build -t instagram-scraper .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Run&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker run -it --rm -v $(pwd)/data:/instagram-scraper/data instagram-scraper -i -d data/&amp;lt;folder_name&amp;gt; &amp;lt;params&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to save &lt;code&gt;cookiejar&lt;/code&gt; to you HDD you have to run it like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker run -it --rm -v $(pwd)/data:/instagram-scraper/data instagram-scraper -i -d data/&amp;lt;folder_name&amp;gt; --cookiejar data/my_cookies &amp;lt;params&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Run built image&lt;/h4&gt; &#xA;&lt;p&gt;You could run already built image from here &lt;a href=&#34;https://github.com/arc298/instagram-scraper/pkgs/container/instagram-scraper/versions&#34;&gt;https://github.com/arc298/instagram-scraper/pkgs/container/instagram-scraper/versions&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker run -it --rm -v $(pwd)/data:/instagram-scraper/data ghcr.io/arc298/instagram-scraper:latest -i -d data/&amp;lt;folder_name&amp;gt; --cookiejar data/my_cookies &amp;lt;params&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Develop&lt;/h2&gt; &#xA;&lt;p&gt;Clone the repo and create a virtualenv&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ virtualenv venv&#xA;$ source venv/bin/activate&#xA;$ python setup.py develop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running Tests&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ python setup.py test&#xA;&#xA;# or just &#xA;&#xA;$ nosetests&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Check the open issues or open a new issue to start a discussion around your feature idea or the bug you found&lt;/li&gt; &#xA; &lt;li&gt;Fork the repository, make your changes, and add yourself to &lt;a href=&#34;https://raw.githubusercontent.com/arc298/instagram-scraper/master/AUTHORS.md&#34;&gt;AUTHORS.md&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Send a pull request&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This is free and unencumbered software released into the public domain.&lt;/p&gt; &#xA;&lt;p&gt;Anyone is free to copy, modify, publish, use, compile, sell, or distribute this software, either in source code form or as a compiled binary, for any purpose, commercial or non-commercial, and by any means.&lt;/p&gt; &#xA;&lt;p&gt;In jurisdictions that recognize copyright laws, the author or authors of this software dedicate any and all copyright interest in the software to the public domain. We make this dedication for the benefit of the public at large and to the detriment of our heirs and successors. We intend this dedication to be an overt act of relinquishment in perpetuity of all present and future rights to this software under copyright law.&lt;/p&gt; &#xA;&lt;p&gt;THE SOFTWARE IS PROVIDED &#34;AS IS&#34;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.&lt;/p&gt; &#xA;&lt;h2&gt;Donations&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ko-fi.com/alexnik&#34;&gt;&lt;img src=&#34;https://media0.giphy.com/media/IyxgVhamKXhfcAEF4h/giphy.gif?cid=790b7611d2e50ed08083edb0daad8317a6814959b047a5db&amp;amp;rid=giphy.gif&amp;amp;ct=g&#34; alt=&#34;Buy me a beer&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>