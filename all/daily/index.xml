<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-06T01:29:53Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>hpcaitech/ColossalAI</title>
    <updated>2023-01-06T01:29:53Z</updated>
    <id>tag:github.com,2023-01-06:/hpcaitech/ColossalAI</id>
    <link href="https://github.com/hpcaitech/ColossalAI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Colossal-AI: A Unified Deep Learning System for Big Model Era&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Colossal-AI&lt;/h1&gt; &#xA;&lt;div id=&#34;top&#34; align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.colossalai.org/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/colossal-ai_logo_vertical.png&#34; alt=&#34;logo&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;Colossal-AI: A Unified Deep Learning System for Big Model Era&lt;/p&gt; &#xA; &lt;h3&gt; &lt;a href=&#34;https://arxiv.org/abs/2110.14883&#34;&gt; Paper &lt;/a&gt; | &lt;a href=&#34;https://www.colossalai.org/&#34;&gt; Documentation &lt;/a&gt; | &lt;a href=&#34;https://github.com/hpcaitech/ColossalAI-Examples&#34;&gt; Examples &lt;/a&gt; | &lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/discussions&#34;&gt; Forum &lt;/a&gt; | &lt;a href=&#34;https://medium.com/@hpcaitech&#34;&gt; Blog &lt;/a&gt;&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/actions/workflows/build.yml&#34;&gt;&lt;img src=&#34;https://github.com/hpcaitech/ColossalAI/actions/workflows/build.yml/badge.svg?sanitize=true&#34; alt=&#34;Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colossalai.readthedocs.io/en/latest/?badge=latest&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/colossalai/badge/?version=latest&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.codefactor.io/repository/github/hpcaitech/colossalai&#34;&gt;&lt;img src=&#34;https://www.codefactor.io/repository/github/hpcaitech/colossalai/badge&#34; alt=&#34;CodeFactor&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/hpcai-tech&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97HuggingFace-Join-yellow&#34; alt=&#34;HuggingFace badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://join.slack.com/t/colossalaiworkspace/shared_invite/zt-z7b26eeb-CBp7jouvu~r0~lcFzX832w&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Slack-join-blueviolet?logo=slack&amp;amp;amp&#34; alt=&#34;slack badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%E5%BE%AE%E4%BF%A1-%E5%8A%A0%E5%85%A5-green?logo=wechat&amp;amp;amp&#34; alt=&#34;WeChat badge&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;| &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/README.md&#34;&gt;English&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/README-zh-Hans.md&#34;&gt;中文&lt;/a&gt; |&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Latest News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2023/01] &lt;a href=&#34;https://www.hpc-ai.tech/blog/colossal-ai-0-2-0&#34;&gt;Hardware Savings Up to 46 Times for AIGC and Automatic Parallelism&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2022/11] &lt;a href=&#34;https://www.hpc-ai.tech/blog/diffusion-pretraining-and-hardware-fine-tuning-can-be-almost-7x-cheaper&#34;&gt;Diffusion Pretraining and Hardware Fine-Tuning Can Be Almost 7X Cheaper&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2022/10] &lt;a href=&#34;https://www.hpc-ai.tech/blog/use-a-laptop-to-analyze-90-of-proteins-with-a-single-gpu-inference-sequence-exceeding&#34;&gt;Use a Laptop to Analyze 90% of Proteins, With a Single-GPU Inference Sequence Exceeding 10,000&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2022/10] &lt;a href=&#34;https://www.hpc-ai.tech/blog/embedding-training-with-1-gpu-memory-and-10-times-less-budget-an-open-source-solution-for&#34;&gt;Embedding Training With 1% GPU Memory and 100 Times Less Budget for Super-Large Recommendation Model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2022/09] &lt;a href=&#34;https://www.hpc-ai.tech/blog/hpc-ai-tech-completes-6-million-seed-and-angel-round-fundraising-led-by-bluerun-ventures-in-the&#34;&gt;HPC-AI Tech Completes $6 Million Seed and Angel Round Fundraising&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Why-Colossal-AI&#34;&gt;Why Colossal-AI&lt;/a&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Features&#34;&gt;Features&lt;/a&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Parallel-Training-Demo&#34;&gt;Parallel Training Demo&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#GPT-3&#34;&gt;GPT-3&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#GPT-2&#34;&gt;GPT-2&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#BERT&#34;&gt;BERT&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#PaLM&#34;&gt;PaLM&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#OPT&#34;&gt;OPT&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#ViT&#34;&gt;ViT&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Recommendation-System-Models&#34;&gt;Recommendation System Models&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Single-GPU-Training-Demo&#34;&gt;Single GPU Training Demo&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#GPT-2-Single&#34;&gt;GPT-2&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#PaLM-Single&#34;&gt;PaLM&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Inference-Energon-AI-Demo&#34;&gt;Inference (Energon-AI) Demo&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#GPT-3-Inference&#34;&gt;GPT-3&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#OPT-Serving&#34;&gt;OPT-175B Online Serving for Text Generation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#BLOOM-Inference&#34;&gt;175B BLOOM&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Colossal-AI-in-the-Real-World&#34;&gt;Colossal-AI for Real World Applications&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#AIGC&#34;&gt;AIGC: Acceleration of Stable Diffusion&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Biomedicine&#34;&gt;Biomedicine: Acceleration of AlphaFold Protein Structure&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Installation&#34;&gt;Installation&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#PyPI&#34;&gt;PyPI&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Install-From-Source&#34;&gt;Install From Source&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Use-Docker&#34;&gt;Use Docker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Community&#34;&gt;Community&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#Cite-Us&#34;&gt;Cite Us&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why Colossal-AI&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://youtu.be/KnXSfjqkKN0&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/JamesDemmel_Colossal-AI.png&#34; width=&#34;600&#34;&gt; &lt;/a&gt; &#xA; &lt;p&gt;Prof. James Demmel (UC Berkeley): Colossal-AI makes training AI models efficient, easy, and scalable.&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;Colossal-AI provides a collection of parallel components for you. We aim to support you to write your distributed deep learning models just like how you write your model on your laptop. We provide user-friendly tools to kickstart distributed training and inference in a few lines.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Parallelism strategies&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Data Parallelism&lt;/li&gt; &#xA;   &lt;li&gt;Pipeline Parallelism&lt;/li&gt; &#xA;   &lt;li&gt;1D, &lt;a href=&#34;https://arxiv.org/abs/2104.05343&#34;&gt;2D&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2105.14500&#34;&gt;2.5D&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2105.14450&#34;&gt;3D&lt;/a&gt; Tensor Parallelism&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2105.13120&#34;&gt;Sequence Parallelism&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1910.02054&#34;&gt;Zero Redundancy Optimizer (ZeRO)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/tree/main/examples/language/gpt/auto_parallel_with_gpt&#34;&gt;Auto-Parallelism&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Heterogeneous Memory Management&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2108.05818&#34;&gt;PatrickStar&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Friendly Usage&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Parallelism based on configuration file&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Inference&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/EnergonAI&#34;&gt;Energon-AI&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Colossal-AI in the Real World&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Biomedicine: &lt;a href=&#34;https://github.com/hpcaitech/FastFold&#34;&gt;FastFold&lt;/a&gt; accelerates training and inference of AlphaFold protein structure&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Parallel Training Demo&lt;/h2&gt; &#xA;&lt;h3&gt;GPT-3&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT3-v5.png&#34; width=&#34;700/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Save 50% GPU resources, and 10.7% acceleration&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;GPT-2&lt;/h3&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2.png&#34; width=&#34;800/&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;11x lower GPU memory consumption, and superlinear scaling efficiency with Tensor Parallelism&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/(updated)GPT-2.png&#34; width=&#34;800&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;24x larger model size on the same hardware&lt;/li&gt; &#xA; &lt;li&gt;over 3x acceleration&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;BERT&lt;/h3&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BERT.png&#34; width=&#34;800/&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2x faster training, or 50% longer sequence length&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;PaLM&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/PaLM-colossalai&#34;&gt;PaLM-colossalai&lt;/a&gt;: Scalable implementation of Google&#39;s Pathways Language Model (&lt;a href=&#34;https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html&#34;&gt;PaLM&lt;/a&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;OPT&lt;/h3&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/OPT_update.png&#34; width=&#34;800/&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/metaseq&#34;&gt;Open Pretrained Transformer (OPT)&lt;/a&gt;, a 175-Billion parameter AI language model released by Meta, which stimulates AI programmers to perform various downstream tasks and application deployments because public pretrained model weights.&lt;/li&gt; &#xA; &lt;li&gt;45% speedup fine-tuning OPT at low cost in lines. &lt;a href=&#34;https://github.com/hpcaitech/ColossalAI-Examples/tree/main/language/opt&#34;&gt;[Example]&lt;/a&gt; &lt;a href=&#34;https://service.colossalai.org/opt&#34;&gt;[Online Serving]&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please visit our &lt;a href=&#34;https://www.colossalai.org/&#34;&gt;documentation&lt;/a&gt; and &lt;a href=&#34;https://github.com/hpcaitech/ColossalAI-Examples&#34;&gt;examples&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h3&gt;ViT&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/ViT.png&#34; width=&#34;450&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;14x larger batch size, and 5x faster training for Tensor Parallelism = 64&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Recommendation System Models&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/CachedEmbedding&#34;&gt;Cached Embedding&lt;/a&gt;, utilize software cache to train larger embedding tables with a smaller GPU memory budget.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Single GPU Training Demo&lt;/h2&gt; &#xA;&lt;h3&gt;GPT-2&lt;/h3&gt; &#xA;&lt;p id=&#34;GPT-2-Single&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2-GPU1.png&#34; width=&#34;450/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;20x larger model size on the same hardware&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;GPT-2-NVME&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2-NVME.png&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;120x larger model size on the same hardware (RTX 3080)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;PaLM&lt;/h3&gt; &#xA;&lt;p id=&#34;PaLM-Single&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/PaLM-GPU1.png&#34; width=&#34;450/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;34x larger model size on the same hardware&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Inference (Energon-AI) Demo&lt;/h2&gt; &#xA;&lt;p id=&#34;GPT-3-Inference&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/inference_GPT-3.jpg&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/EnergonAI&#34;&gt;Energon-AI&lt;/a&gt;: 50% inference acceleration on the same hardware&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;OPT-Serving&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/OPT_serving.png&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://service.colossalai.org/opt&#34;&gt;OPT Serving&lt;/a&gt;: Try 175-billion-parameter OPT online services for free, without any registration whatsoever.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;BLOOM-Inference&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BLOOM%20Inference.PNG&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/EnergonAI/tree/main/examples/bloom&#34;&gt;BLOOM&lt;/a&gt;: Reduce hardware deployment costs of 175-billion-parameter BLOOM by more than 10 times.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Colossal-AI in the Real World&lt;/h2&gt; &#xA;&lt;h3&gt;AIGC&lt;/h3&gt; &#xA;&lt;p&gt;Acceleration of AIGC (AI-Generated Content) models such as &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable Diffusion v1&lt;/a&gt; and &lt;a href=&#34;https://github.com/Stability-AI/stablediffusion&#34;&gt;Stable Diffusion v2&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p id=&#34;diffusion_train&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/Stable%20Diffusion%20v2.png&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/diffusion&#34;&gt;Training&lt;/a&gt;: Reduce Stable Diffusion memory consumption by up to 5.6x and hardware cost by up to 46x (from A100 to RTX3060).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;diffusion_demo&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/DreamBooth.png&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/dreambooth&#34;&gt;DreamBooth Fine-tuning&lt;/a&gt;: Personalize your model using just 3-5 images of the desired subject.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;inference&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/Stable%20Diffusion%20Inference.jpg&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/diffusion&#34;&gt;Inference&lt;/a&gt;: Reduce inference GPU memory consumption by 2.5x.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h3&gt;Biomedicine&lt;/h3&gt; &#xA;&lt;p&gt;Acceleration of &lt;a href=&#34;https://alphafold.ebi.ac.uk/&#34;&gt;AlphaFold Protein Structure&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p id=&#34;FastFold&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/FastFold.jpg&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hpcaitech/FastFold&#34;&gt;FastFold&lt;/a&gt;: accelerating training and inference on GPU Clusters, faster data processing, inference sequence containing more than 10000 residues.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;xTrimoMultimer&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/xTrimoMultimer_Table.jpg&#34; width=&#34;800/&#34;&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/biomap-research/xTrimoMultimer&#34;&gt;xTrimoMultimer&lt;/a&gt;: accelerating structure prediction of protein monomers and multimer by 11x.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Download From Official Releases&lt;/h3&gt; &#xA;&lt;p&gt;You can visit the &lt;a href=&#34;https://www.colossalai.org/download&#34;&gt;Download&lt;/a&gt; page to download Colossal-AI with pre-built CUDA extensions.&lt;/p&gt; &#xA;&lt;h3&gt;Download From Source&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;The version of Colossal-AI will be in line with the main branch of the repository. Feel free to raise an issue if you encounter any problem. :)&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/hpcaitech/ColossalAI.git&#xA;cd ColossalAI&#xA;&#xA;# install dependency&#xA;pip install -r requirements/requirements.txt&#xA;&#xA;# install colossalai&#xA;pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you don&#39;t want to install and enable CUDA kernel fusion (compulsory installation when using fused optimizer):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;NO_CUDA_EXT=1 pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Use Docker&lt;/h2&gt; &#xA;&lt;h3&gt;Pull from DockerHub&lt;/h3&gt; &#xA;&lt;p&gt;You can directly pull the docker image from our &lt;a href=&#34;https://hub.docker.com/r/hpcaitech/colossalai&#34;&gt;DockerHub page&lt;/a&gt;. The image is automatically uploaded upon release.&lt;/p&gt; &#xA;&lt;h3&gt;Build On Your Own&lt;/h3&gt; &#xA;&lt;p&gt;Run the following command to build a docker image from Dockerfile provided.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Building Colossal-AI from scratch requires GPU support, you need to use Nvidia Docker Runtime as the default when doing &lt;code&gt;docker build&lt;/code&gt;. More details can be found &lt;a href=&#34;https://stackoverflow.com/questions/59691207/docker-build-with-nvidia-runtime&#34;&gt;here&lt;/a&gt;. We recommend you install Colossal-AI from our &lt;a href=&#34;https://www.colossalai.org&#34;&gt;project page&lt;/a&gt; directly.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ColossalAI&#xA;docker build -t colossalai ./docker&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the following command to start the docker container in interactive mode.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -ti --gpus all --rm --ipc=host colossalai bash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;Join the Colossal-AI community on &lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/discussions&#34;&gt;Forum&lt;/a&gt;, &lt;a href=&#34;https://join.slack.com/t/colossalaiworkspace/shared_invite/zt-z7b26eeb-CBp7jouvu~r0~lcFzX832w&#34;&gt;Slack&lt;/a&gt;, and &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png&#34; title=&#34;qrcode&#34;&gt;WeChat&lt;/a&gt; to share your suggestions, feedback, and questions with our engineering team.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;If you wish to contribute to this project, please follow the guideline in &lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/CONTRIBUTING.md&#34;&gt;Contributing&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Thanks so much to all of our amazing contributors!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/hpcaitech/ColossalAI/graphs/contributors&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/contributor_avatar.png&#34; width=&#34;800px&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;The order of contributor avatars is randomly shuffled.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;Cite Us&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{bian2021colossal,&#xA;  title={Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training},&#xA;  author={Bian, Zhengda and Liu, Hongxin and Wang, Boxiang and Huang, Haichen and Li, Yongbin and Wang, Chuanrui and Cui, Fan and You, Yang},&#xA;  journal={arXiv preprint arXiv:2110.14883},&#xA;  year={2021}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;right&#34;&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/#top&#34;&gt;back to top&lt;/a&gt;)&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>papers-we-love/papers-we-love</title>
    <updated>2023-01-06T01:29:53Z</updated>
    <id>tag:github.com,2023-01-06:/papers-we-love/papers-we-love</id>
    <link href="https://github.com/papers-we-love/papers-we-love" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Papers from the computer science community to read and discuss.&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;&lt;img src=&#34;http://paperswelove.org/images/logo-top.svg?sanitize=true&#34; alt=&#34;Papers We Love&#34;&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitter.im/papers-we-love/community?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&#34;&gt;&lt;img src=&#34;https://badges.gitter.im/papers-we-love/community.svg?sanitize=true&#34; alt=&#34;Gitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Papers We Love&lt;/strong&gt; (&lt;em&gt;PWL&lt;/em&gt;) is a community built around reading, discussing and learning more about academic computer science papers. This repository serves as a directory of some of the best papers the community can find, bringing together documents scattered across the web. You can also visit the &lt;a href=&#34;http://paperswelove.org/&#34;&gt;Papers We Love site&lt;/a&gt; for more info.&lt;/p&gt; &#xA;&lt;p&gt;Due to &lt;a href=&#34;https://github.com/papers-we-love/papers-we-love/raw/master/.github/CONTRIBUTING.md#respect-content-licenses&#34;&gt;licenses&lt;/a&gt; we cannot always host the papers themselves (when we do, you will see a &lt;span&gt;📜&lt;/span&gt; emoji next to its title in the directory README) but we can provide links to their locations.&lt;/p&gt; &#xA;&lt;p&gt;If you enjoy the papers, perhaps stop by a local chapter meetup and join in on the vibrant discussions around them. You can also discuss &lt;em&gt;PWL&lt;/em&gt; events, the content in this repository, and/or anything related to &lt;em&gt;PWL&lt;/em&gt; on our &lt;a href=&#34;https://paperswelove.slack.com/messages/general/&#34;&gt;Slack&lt;/a&gt;, after &lt;a href=&#34;http://papersweloveslack.herokuapp.com/&#34;&gt;signing-up&lt;/a&gt; to join it, or on our &lt;em&gt;#paperswelove&lt;/em&gt; IRC channel on freenode.&lt;/p&gt; &#xA;&lt;h3&gt;Chapters&lt;/h3&gt; &#xA;&lt;p&gt;Here are our official chapters. Let us know if you are interested in &lt;a href=&#34;https://github.com/papers-we-love/organizers&#34;&gt;starting one&lt;/a&gt; in your city!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.meetup.com/Papers-We-Love-Athens&#34;&gt;Athens&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.meetup.com/Papers-We-Love-Atlanta&#34;&gt;Atlanta&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/Papers-we-love-Bangalore/&#34;&gt;Bangalore&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/Papers-We-Love-Berlin/&#34;&gt;Berlin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.facebook.com/groups/pwlbbsr/&#34;&gt;Bhubaneswar&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/Papers-We-Love-Boston-Cambridge/&#34;&gt;Boston&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/papers-we-love-bucharest/&#34;&gt;Bucharest&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://paperswelove.org/buenos-aires/&#34;&gt;Buenos Aires&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/Papers-We-Love-Chattanooga/&#34;&gt;Chattanooga&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/papers-we-love-chicago/&#34;&gt;Chicago&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/Papers-We-Love-Columbus/&#34;&gt;Columbus, Ohio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/papers-we-love-hyderabad/&#34;&gt;Hyderabad&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.meetup.com/techcorridorio&#34;&gt;Iowa City&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.facebook.com/groups/PapersWeLoveKathmandu/&#34;&gt;Kathmandu&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.facebook.com/groups/PapersWeLoveKyiv&#34;&gt;Kyiv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.paperswelovelb.club&#34;&gt;Lebanon&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/papers-we-love-london&#34;&gt;London&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/papers-we-love-la&#34;&gt;Los Angeles&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/Papers-We-Love-Montreal/&#34;&gt;Montreal&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/papers-we-love/&#34;&gt;New York City&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/Papers-We-Love-Paris/&#34;&gt;Paris&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.meetup.com/papers-we-love-pdx/&#34;&gt;Portland&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/Doo-Things&#34;&gt;Pune&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.meetup.com/Papers-We-Love-Raleigh-Durham/&#34;&gt;Raleigh-Durham&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/Papers-We-Love-San-Diego/&#34;&gt;San Diego&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/papers-we-love-too/&#34;&gt;San Francisco&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/Papers-We-Love-Seattle/&#34;&gt;Seattle&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/seoul-tech-society&#34;&gt;Seoul, Korea&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.facebook.com/groups/paperswelovesg/&#34;&gt;Singapore&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.meetup.com/pt-BR/Papers-We-Love-Teresina/&#34;&gt;Teresina&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/Papers-We-Love-Toronto/&#34;&gt;Toronto&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/Papers-We-Love-Vienna/&#34;&gt;Vienna&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.meetup.com/Papers-We-Love-DC-NoVA/&#34;&gt;Washington, DC&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://pwlwpg.ca/&#34;&gt;Winnipeg&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.meetup.com/Papers-we-love-Zurich/&#34;&gt;Zürich&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All of our meetups follow our &lt;a href=&#34;https://raw.githubusercontent.com/papers-we-love/papers-we-love/master/CODE_OF_CONDUCT.md&#34;&gt;Code of Conduct&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Past Presentations&lt;/h3&gt; &#xA;&lt;p&gt;Check out our &lt;a href=&#34;https://www.youtube.com/user/PapersWeLove&#34;&gt;YouTube&lt;/a&gt; and &lt;a href=&#34;https://www.mixcloud.com/paperswelove/&#34;&gt;MixCloud&lt;/a&gt; (audio-only format) channels.&lt;/p&gt; &#xA;&lt;h2&gt;Info&lt;/h2&gt; &#xA;&lt;p&gt;We&#39;re looking for pull requests related to papers we should add, better organization of the papers we do have, and/or links to other paper-repos we should point to.&lt;/p&gt; &#xA;&lt;h3&gt;Other Good Places to Find Papers&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/user/keeroyz&#34;&gt;2 Minute Papers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bell-labs.com/our-research/technical-journal/&#34;&gt;Bell System Technical Journal, 1922-1983&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://jeffhuang.com/best_paper_awards.html&#34;&gt;Best Paper Awards in Computer Science&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://research.fb.com/publications/&#34;&gt;Facebook&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://scholar.google.com/citations?view_op=top_venues&amp;amp;hl=en&amp;amp;vq=eng&#34;&gt;Google Scholar&lt;/a&gt; (choose a subcategory)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://research.microsoft.com/apps/catalog/default.aspx?t=publications&#34;&gt;Microsoft Research&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://alexott.net/en/fp/books/&#34;&gt;Functional Programming Books Review&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://dspace.mit.edu/handle/1721.1/39813&#34;&gt;MIT&#39;s Artificial Intelligence Lab Publications&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://dsrg.pdos.csail.mit.edu/&#34;&gt;MIT&#39;s Distributed System&#39;s Reading Group&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://arxiv.org/&#34;&gt;arXiv Paper Repository&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scirate.com/&#34;&gt;SciRate&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://doc.cat-v.org/&#34;&gt;cat-v.org&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://yarchive.net/comp/index.html&#34;&gt;y-archive&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.netlib.org/&#34;&gt;netlib&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mmcgrana/services-engineering&#34;&gt;Services Engineering Reading List&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://christophermeiklejohn.com/distributed/systems/2013/07/12/readings-in-distributed-systems.html&#34;&gt;Readings in Distributed Systems&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://samth.github.io/gradual-typing-bib/&#34;&gt;Gradual Typing Bibliography&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.covert.io/the-definitive-security-datascience-and-machinelearning-guide/&#34;&gt;Security Data Science Papers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.cs.cmu.edu/~rwh/papers/index.html&#34;&gt;Research Papers from Robert Harper, Carnegie Mellon University&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lobste.rs/t/pdf&#34;&gt;Lobste.rs tagged as PDF&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://blog.acolyer.org/&#34;&gt;The Morning Paper&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please check out our &lt;a href=&#34;https://github.com/papers-we-love/papers-we-love/wiki/Other-Good-Sources-of-Reading-Material&#34;&gt;wiki-page&lt;/a&gt; for links to blogs, books, exchanges that are worth a good read.&lt;/p&gt; &#xA;&lt;h3&gt;How To Read a Paper&lt;/h3&gt; &#xA;&lt;p&gt;Reading a paper is not the same as reading a blogpost or a novel. Here are a few handy resources to help you get started.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://organizationsandmarkets.com/2010/08/31/how-to-read-an-academic-article/&#34;&gt;How to read an academic article&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://userpages.umbc.edu/~akmassey/posts/2012-02-15-advice-on-reading-academic-papers.html&#34;&gt;Advice on reading academic papers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://violentmetaphors.com/2013/08/25/how-to-read-and-understand-a-scientific-paper-2/&#34;&gt;How to read and understand a scientific paper&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://michaelrbernste.in/2014/10/21/should-i-read-papers.html&#34;&gt;Should I Read Papers?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=8eRx5Wo3xYA&#34;&gt;The Refreshingly Rewarding Realm of Research Papers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://ccr.sigcomm.org/online/files/p83-keshavA.pdf&#34;&gt;How to read a paper&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Applications/Ideas built around Papers We Love&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Love a Paper - &lt;a href=&#34;https://twitter.com/loveapaper&#34;&gt;@loveapaper&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Download papers&lt;/h3&gt; &#xA;&lt;p&gt;Open your favourite terminal and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./scripts/download.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will scrape markdown files for links to PDFs and download papers to their respective directories.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/papers-we-love/papers-we-love/master/scripts/README.md&#34;&gt;README.md&lt;/a&gt; for more options.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing Guidelines&lt;/h2&gt; &#xA;&lt;p&gt;Please take a look at our &lt;a href=&#34;https://github.com/papers-we-love/papers-we-love/raw/master/.github/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; file.&lt;/p&gt; &#xA;&lt;h2&gt;Copyright&lt;/h2&gt; &#xA;&lt;p&gt;The name &#34;Papers We Love&#34; and the logos for the organization are copyrighted, and under the ownership of Papers We Love Ltd, all rights reserved. When starting a chapter, please review &lt;a href=&#34;https://github.com/papers-we-love/papers-we-love/wiki/Creating-a-PWL-chapter&#34;&gt;our guidelines&lt;/a&gt; and ask us about using the logo.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>testerSunshine/12306</title>
    <updated>2023-01-06T01:29:53Z</updated>
    <id>tag:github.com,2023-01-06:/testerSunshine/12306</id>
    <link href="https://github.com/testerSunshine/12306" rel="alternate"></link>
    <summary type="html">&lt;p&gt;12306智能刷票，订票&lt;/p&gt;&lt;hr&gt;&lt;h3&gt;12306 购票小助手&lt;/h3&gt; &#xA;&lt;h4&gt;python版本&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 2.7.10 - 2.7.15&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 3.6 - 3.7.4&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 2.7.9&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;已有功能&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 自动打码&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 自动登录&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 准点预售和捡漏&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 智能候补&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 邮件通知&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; server酱通知&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;依赖库&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;验证码目前可以本地识别，需要下载模型，放于项目根目录，全部代码来源于此项目 &lt;a href=&#34;https://github.com/zhaipro/easy12306&#34;&gt;传送门&lt;/a&gt;，表示感谢 &lt;pre&gt;&lt;code&gt;  1. 模型下载链接:https://pan.baidu.com/s/1rS155VjweWVWIJogakechA  密码:bmlm&#xA;     群里面也可以下载&#xA;  2. git仓库下载：https://github.com/testerSunshine/12306model.git&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;自托管云打码服务器搭建：&lt;a href=&#34;https://github.com/YinAoXiong/12306_code_server&#34;&gt;12306_code_server&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;如果大家有空闲的服务器，可搭建之后在这个 &lt;a href=&#34;https://github.com/testerSunshine/12306/issues/446&#34;&gt;issues&lt;/a&gt; 里面填入自己的服务器(请注意服务器安全！)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;项目依赖 &lt;a href=&#34;https://raw.githubusercontent.com/testerSunshine/12306/master/requirements.txt&#34;&gt;requirements.txt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;安装方法x: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;root用户(避免多python环境产生问题): &lt;code&gt;pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;非root用户（避免安装和运行时使用了不同环境）: &lt;code&gt;pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;许多windows的用户装不了tensorflow的话，可以适当降低版本或者升高版本都是可以的 &lt;pre&gt;&lt;code&gt;1. tensorflow的兼容版本 1.14.0rc\1.14.0rc\1.15.0\1.15.0rc&#xA;以上版本都测试无问题&#xA;2. 如果pip代理的清华源无法下载，可以更换其他源解决此问题&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;项目使用说明&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;服务器启动: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;修改&lt;a href=&#34;https://raw.githubusercontent.com/testerSunshine/12306/master/TickerConfig.py&#34;&gt;配置&lt;/a&gt;文件 &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;可以配置邮箱,配置邮箱的格式在&lt;a href=&#34;https://raw.githubusercontent.com/testerSunshine/12306/master/TickerConfig.py&#34;&gt;配置&lt;/a&gt;里面可以看到ex &lt;pre&gt;&lt;code&gt;# 测试邮箱和server酱是否可用， server酱测试的前提是server酱开关开启&#xA;# 可以配置server酱提醒（推荐）[配置教程](https://www.jianshu.com/p/8d10b5b9c4e3)&#xA;# 用python3 还是python 完全取决于安装的时候配置的环境变量是否为python3,以下启动默认环境变量为python3&#xA;python3 run.py t&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;     &lt;li&gt;配置&lt;a href=&#34;https://raw.githubusercontent.com/testerSunshine/12306/master/TickerConfig.py&#34;&gt;配置&lt;/a&gt;文件的时候，需注意空格和遵循python语法格式&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;启动前请先筛选cdn，这点很&lt;code&gt;重要&lt;/code&gt; &lt;pre&gt;&lt;code&gt;python3 run.py c&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt;启动服务 &lt;pre&gt;&lt;code&gt;python3 run.py r&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt;如果你不知道如何操作，下面的命令可能会帮助你 &lt;pre&gt;&lt;code&gt;python3 run.py -h&#xA;&#xA;——————————————————————————&#xA;sage: run.py [-h] operate&#xA;&#xA;positional arguments:&#xA;  operate     r: 运行抢票程序, c: 过滤cdn, t: 测试邮箱和server酱，server酱&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;如果你的服务器安装了docker与docker-compose, 那么你可以忽略上面的&lt;strong&gt;所有&lt;/strong&gt;步骤，直接按以下步骤操作，即可开始抢票： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;前提条件: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;请确认你安装的docker版本为18.09及以上: &lt;code&gt;docker -v&lt;/code&gt;&lt;/li&gt; &#xA;     &lt;li&gt;请确认你安装的docker-compose版本为1.23.2及以上: &lt;code&gt;docker-compose -v&lt;/code&gt;&lt;/li&gt; &#xA;     &lt;li&gt;请根据自己需要修改好配置文件:&lt;code&gt;TickerConfig.py&lt;/code&gt;&lt;/li&gt; &#xA;     &lt;li&gt;请修改配置文件&lt;code&gt;TickerConfig.py&lt;/code&gt;中的变量&lt;code&gt;AUTO_CODE_TYPE&lt;/code&gt;和&lt;code&gt;HOST&lt;/code&gt;，&lt;code&gt;AUTO_CODE_TYPE&lt;/code&gt;改为&lt;code&gt;3&lt;/code&gt;, HOST改为&lt;code&gt;&#34;captcha:80&#34;&lt;/code&gt;（这里很重要，这是本地打码服务器的配置）&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;运行命令: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;开始抢票：&lt;code&gt;docker-compose up --build -d&lt;/code&gt;&lt;/li&gt; &#xA;     &lt;li&gt;停止抢票：&lt;code&gt;docker-compose down&lt;/code&gt;&lt;/li&gt; &#xA;     &lt;li&gt;查看抢票log: &lt;code&gt;docker logs --follow ticket&lt;/code&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;目录对应说明&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;agency - cdn代理&lt;/li&gt; &#xA; &lt;li&gt;config - 项目配置&lt;/li&gt; &#xA; &lt;li&gt;verify - 自动打码&lt;/li&gt; &#xA; &lt;li&gt;init - 项目主运行目录&lt;/li&gt; &#xA; &lt;li&gt;inter - 接口&lt;/li&gt; &#xA; &lt;li&gt;myException - 异常&lt;/li&gt; &#xA; &lt;li&gt;myUrllib request网络请求库&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;思路图&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;img src=&#34;https://raw.githubusercontent.com/testerSunshine/12306/master/uml/uml.png&#34; alt=&#34;image&#34;&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;项目声明：&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;本软件只供学习交流使用，勿作为商业用途，交流群号 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;1群：286271084(已满)&lt;/li&gt; &#xA;   &lt;li&gt;2群：649992274(已满)&lt;/li&gt; &#xA;   &lt;li&gt;3群：632501142(已满)&lt;/li&gt; &#xA;   &lt;li&gt;4群: 606340519(已满)&lt;/li&gt; &#xA;   &lt;li&gt;5群: 948526733(已满)&lt;/li&gt; &#xA;   &lt;li&gt;7群: 660689659(已满)&lt;/li&gt; &#xA;   &lt;li&gt;8群: 620629239(已满)&lt;/li&gt; &#xA;   &lt;li&gt;6群: 608792930(未满)&lt;/li&gt; &#xA;   &lt;li&gt;9群: 693035807(未满)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;请不要重复加群，一个群就可以了，把机会留给更多人&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;进群先看公告！！！进群先看公告！！！进群先看公告！！！ 重要的事情说三遍&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;能为你抢到一张回家的票，是我最大的心愿&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;日志列子&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;成功log，如果是购票失败的，请带上失败的log给我，我尽力帮你调，也可加群一起交流，程序只是加速买票的过程，并不一定能买到票 &lt;pre&gt;&lt;code&gt;正在第355次查询  乘车日期: 2018-02-12  车次G4741,G2365,G1371,G1377,G1329 查询无票  代理设置 无  总耗时429ms&#xA;车次: G4741 始发车站: 上海 终点站: 邵阳 二等座:有&#xA;正在尝试提交订票...&#xA;尝试提交订单...&#xA;出票成功&#xA;排队成功, 当前余票还剩余: 359 张&#xA;正在使用自动识别验证码功能&#xA;验证码通过,正在提交订单&#xA;提交订单成功！&#xA;排队等待时间预计还剩 -12 ms&#xA;排队等待时间预计还剩 -6 ms&#xA;排队等待时间预计还剩 -7 ms&#xA;排队等待时间预计还剩 -4 ms&#xA;排队等待时间预计还剩 -4 ms&#xA;恭喜您订票成功，订单号为：EB52743573, 请立即打开浏览器登录12306，访问‘未完成订单’，在30分钟内完成支付！&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;使用帮助(一些安装问题和使用反馈较多的问题)：&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;测试邮箱是否可用 &lt;a href=&#34;https://github.com/testerSunshine/12306/issues/107&#34;&gt;邮箱配置问题看issues&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;学生票issues &lt;a href=&#34;https://github.com/testerSunshine/12306/issues/47&#34;&gt;学生票修改&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;依赖安装不对的问题（ImportError）&lt;a href=&#34;https://github.com/testerSunshine/12306/issues/91&#34;&gt;requirements.txt问题&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;若快豆子疑问 &lt;a href=&#34;https://github.com/testerSunshine/12306/issues/67&#34;&gt;点我&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;IOError: 【Errno 0】 Error 问题 &lt;a href=&#34;https://github.com/testerSunshine/12306/issues/159&#34;&gt;点我&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;测试下单接口是否可用，有两个下单接口，随便用哪个都ok&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;如果下载验证码过期或者下载失败的问题，应该是12306封ip的策略，多重试几次，12306现在封服务器(阿里云和腾讯云)ip比较严重，尽量不要放在服务器里面&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;目前12306对服务器ip比较敏感，大家还是在自己家里挂着吧&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;自动更换ip软件目前已支持TPLINK和小米路由器，只限家庭网络&lt;a href=&#34;https://github.com/testerSunshine/AutoRouterIP&#34;&gt;点我跳转&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;感谢一下小伙伴对本项目提供的帮助&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;@&lt;a href=&#34;mailto:sun7127@126.com&#34;&gt;sun7127@126.com&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;@ 才&lt;/li&gt; &#xA; &lt;li&gt;@&lt;a href=&#34;https://github.com/MonsterTan&#34;&gt;MonsterTan&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;以及所有为此项目提供pr的同学&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;更新日志&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/testerSunshine/12306/master/Update.md&#34;&gt;更新日志&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>