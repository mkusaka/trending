<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-06-07T01:29:13Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>topoteretes/cognee</title>
    <updated>2025-06-07T01:29:13Z</updated>
    <id>tag:github.com,2025-06-07:/topoteretes/cognee</id>
    <link href="https://github.com/topoteretes/cognee" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Memory for AI Agents in 5 lines of code&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/topoteretes/cognee&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/dev/assets/cognee-logo-transparent.png&#34; alt=&#34;Cognee Logo&#34; height=&#34;60&#34;&gt; &lt;/a&gt; &#xA; &lt;br&gt; &#xA; &lt;p&gt;cognee - Memory for AI Agents in 5 lines of code&lt;/p&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=1bezuvLwJmw&amp;amp;t=2s&#34;&gt;Demo&lt;/a&gt; . &lt;a href=&#34;https://cognee.ai&#34;&gt;Learn more&lt;/a&gt; 路 &lt;a href=&#34;https://discord.gg/NQPKmU5CCg&#34;&gt;Join Discord&lt;/a&gt; 路 &lt;a href=&#34;https://www.reddit.com/r/AIMemory/&#34;&gt;Join r/AIMemory&lt;/a&gt; &lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://GitHub.com/topoteretes/cognee/network/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/topoteretes/cognee.svg?style=social&amp;amp;label=Fork&amp;amp;maxAge=2592000&#34; alt=&#34;GitHub forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/topoteretes/cognee/stargazers/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/topoteretes/cognee.svg?style=social&amp;amp;label=Star&amp;amp;maxAge=2592000&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/topoteretes/cognee/commit/&#34;&gt;&lt;img src=&#34;https://badgen.net/github/commits/topoteretes/cognee&#34; alt=&#34;GitHub commits&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/topoteretes/cognee/tags/&#34;&gt;&lt;img src=&#34;https://badgen.net/github/tag/topoteretes/cognee&#34; alt=&#34;Github tag&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/cognee&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/badge/cognee&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/topoteretes/cognee/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/topoteretes/cognee/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000&#34; alt=&#34;Contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.producthunt.com/posts/cognee?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-cognee&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=946346&amp;amp;theme=light&amp;amp;period=daily&amp;amp;t=1744472480704&#34; alt=&#34;cognee - Memory for AI Agents  in 5 lines of code | Product Hunt&#34; style=&#34;width: 250px; height: 54px;&#34; width=&#34;250&#34; height=&#34;54&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;Build dynamic memory for Agents and replace RAG using scalable, modular ECL (Extract, Cognify, Load) pipelines.&lt;/p&gt; &#xA; &lt;p&gt;More on &lt;a href=&#34;https://docs.cognee.ai/use-cases&#34;&gt;use-cases&lt;/a&gt; and &lt;a href=&#34;https://github.com/topoteretes/cognee/tree/main/evals&#34;&gt;evals&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p align=&#34;center&#34;&gt;  Available Languages : &lt;a href=&#34;https://raw.githubusercontent.com/topoteretes/cognee/main/assets/community/README.pt.md&#34;&gt;叼 Portugu锚s&lt;/a&gt; 路 &lt;a href=&#34;https://raw.githubusercontent.com/topoteretes/cognee/main/assets/community/README.zh.md&#34;&gt; [涓]&lt;/a&gt; 路 &lt;a href=&#34;https://raw.githubusercontent.com/topoteretes/cognee/main/assets/community/README.ru.md&#34;&gt;佛 泻懈泄&lt;/a&gt; &lt;/p&gt; &#xA; &lt;div style=&#34;text-align: center&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/main/assets/cognee_benefits.png&#34; alt=&#34;Why cognee?&#34; width=&#34;50%&#34;&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Interconnect and retrieve your past conversations, documents, images and audio transcriptions&lt;/li&gt; &#xA; &lt;li&gt;Replaces RAG systems and reduces developer effort, and cost.&lt;/li&gt; &#xA; &lt;li&gt;Load data to graph and vector databases using only Pydantic&lt;/li&gt; &#xA; &lt;li&gt;Manipulate your data while ingesting from 30+ data sources&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;p&gt;Get started quickly with a Google Colab &lt;a href=&#34;https://colab.research.google.com/drive/1jHbWVypDgCLwjE71GSXhRL3YxYhCZzG1?usp=sharing&#34;&gt;notebook&lt;/a&gt; , &lt;a href=&#34;https://deepnote.com/workspace/cognee-382213d0-0444-4c89-8265-13770e333c02/project/cognee-demo-78ffacb9-5832-4611-bb1a-560386068b30/notebook/Notebook-1-75b24cda566d4c24ab348f7150792601?utm_source=share-modal&amp;amp;utm_medium=product-shared-content&amp;amp;utm_campaign=notebook&amp;amp;utm_content=78ffacb9-5832-4611-bb1a-560386068b30&#34;&gt;Deepnote notebook&lt;/a&gt; or &lt;a href=&#34;https://github.com/topoteretes/cognee-starter&#34;&gt;starter repo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Your contributions are at the core of making this a true open source project. Any contributions you make are &lt;strong&gt;greatly appreciated&lt;/strong&gt;. See &lt;a href=&#34;https://raw.githubusercontent.com/topoteretes/cognee/main/CONTRIBUTING.md&#34;&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt; Installation&lt;/h2&gt; &#xA;&lt;p&gt;You can install Cognee using either &lt;strong&gt;pip&lt;/strong&gt;, &lt;strong&gt;poetry&lt;/strong&gt;, &lt;strong&gt;uv&lt;/strong&gt; or any other python package manager. Cognee supports Python 3.8 to 3.12&lt;/p&gt; &#xA;&lt;h3&gt;With pip&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install cognee&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Local Cognee installation&lt;/h2&gt; &#xA;&lt;p&gt;You can install the local Cognee repo using &lt;strong&gt;pip&lt;/strong&gt;, &lt;strong&gt;poetry&lt;/strong&gt; and &lt;strong&gt;uv&lt;/strong&gt;. For local pip installation please make sure your pip version is above version 21.3.&lt;/p&gt; &#xA;&lt;h3&gt;with UV with all optional dependencies&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;uv sync --all-extras&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt; Basic Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Setup&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;import os&#xA;os.environ[&#34;LLM_API_KEY&#34;] = &#34;YOUR OPENAI_API_KEY&#34;&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also set the variables by creating .env file, using our &lt;a href=&#34;https://github.com/topoteretes/cognee/raw/main/.env.template&#34;&gt;template.&lt;/a&gt; To use different LLM providers, for more info check out our &lt;a href=&#34;https://docs.cognee.ai&#34;&gt;documentation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Simple example&lt;/h3&gt; &#xA;&lt;p&gt;This script will run the default pipeline:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import cognee&#xA;import asyncio&#xA;&#xA;&#xA;async def main():&#xA;    # Add text to cognee&#xA;    await cognee.add(&#34;Natural language processing (NLP) is an interdisciplinary subfield of computer science and information retrieval.&#34;)&#xA;&#xA;    # Generate the knowledge graph&#xA;    await cognee.cognify()&#xA;&#xA;    # Query the knowledge graph&#xA;    results = await cognee.search(&#34;Tell me about NLP&#34;)&#xA;&#xA;    # Display the results&#xA;    for result in results:&#xA;        print(result)&#xA;&#xA;&#xA;if __name__ == &#39;__main__&#39;:&#xA;    asyncio.run(main())&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  Natural Language Processing (NLP) is a cross-disciplinary and interdisciplinary field that involves computer science and information retrieval. It focuses on the interaction between computers and human language, enabling machines to understand and process natural language.&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Our paper is out! &lt;a href=&#34;https://arxiv.org/abs/2505.24478&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Read here&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;div style=&#34;text-align: center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/topoteretes/cognee/main/assets/cognee-paper.png&#34; alt=&#34;cognee paper&#34; width=&#34;100%&#34;&gt; &#xA;&lt;/div&gt;  &#xA;&lt;h2&gt;Cognee UI&lt;/h2&gt; &#xA;&lt;p&gt;You can also cognify your files and query using cognee UI.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/topoteretes/cognee/main/assets/cognee-ui-2.webp&#34; width=&#34;100%&#34; alt=&#34;Cognee UI 2&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Try cognee UI out locally &lt;a href=&#34;https://docs.cognee.ai/how-to-guides/cognee-ui&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Understand our architecture&lt;/h2&gt; &#xA;&lt;div style=&#34;text-align: center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/topoteretes/cognee/main/assets/cognee_diagram.png&#34; alt=&#34;cognee concept diagram&#34; width=&#34;100%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Demos&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;What is AI memory:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/8b2a0050-5ec4-424c-b417-8269971503f0&#34;&gt;Learn about cognee&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Simple GraphRAG demo&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/d80b0776-4eb9-4b8e-aa22-3691e2d44b8f&#34;&gt;Simple GraphRAG demo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;cognee with Ollama&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/8621d3e8-ecb8-4860-afb2-5594f2ee17db&#34;&gt;cognee with local models&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;We are committed to making open source an enjoyable and respectful experience for our community. See &lt;a href=&#34;https://github.com/topoteretes/cognee/raw/main/CODE_OF_CONDUCT.md&#34;&gt;&lt;code&gt;CODE_OF_CONDUCT&lt;/code&gt;&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt; Contributors&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/topoteretes/cognee/graphs/contributors&#34;&gt; &lt;img alt=&#34;contributors&#34; src=&#34;https://contrib.rocks/image?repo=topoteretes/cognee&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#topoteretes/cognee&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=topoteretes/cognee&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>unslothai/notebooks</title>
    <updated>2025-06-07T01:29:13Z</updated>
    <id>tag:github.com,2025-06-07:/unslothai/notebooks</id>
    <link href="https://github.com/unslothai/notebooks" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Fine-tune LLMs for free with guided Notebooks on Google Colab, Kaggle, and more.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://unsloth.ai&#34;&gt;&#xA;   &lt;picture&gt; &#xA;    &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20white%20text.png&#34;&gt; &#xA;    &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20black%20text.png&#34;&gt; &#xA;    &lt;img alt=&#34;unsloth logo&#34; src=&#34;https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20black%20text.png&#34; height=&#34;110&#34; style=&#34;max-width: 100%;&#34;&gt; &#xA;   &lt;/picture&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-Alpaca.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/unslothai/unsloth/main/images/start%20free%20finetune%20button.png&#34; height=&#34;48&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/unsloth&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/unslothai/unsloth/main/images/Discord%20button.png&#34; height=&#34;48&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.unsloth.ai&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/unslothai/unsloth/refs/heads/main/images/Documentation%20Button.png&#34; height=&#34;48&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;!--   DO NOT EDIT MANUALLY THIS SECTION UNTIL `end of notebook links`!!   --&gt; &#xA;&lt;!--   THIS SECTION IS GENERATED BY `update_all_notebooks.py` AUTOMATICALLY    --&gt; &#xA;&lt;h2&gt; Fine-tuning Notebooks&lt;/h2&gt; &#xA;&lt;p&gt;Below are our notebooks for Google Colab categorized by model. You can view our &lt;a href=&#34;https://github.com/unslothai/notebooks/#-kaggle-notebooks&#34;&gt;Kaggle notebooks here&lt;/a&gt;.&lt;br&gt;Use our guided notebooks to prep data, train, evaluate, and save your model. View our main &lt;a href=&#34;https://github.com/unslothai/unsloth&#34;&gt;GitHub repo here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Main Notebooks&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Notebook Link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen3 (14B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_%2814B%29-Reasoning-Conversational.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen3-Base (4B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_%284B%29-GRPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Gemma 3 (4B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma3_%284B%29.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3.2 (3B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_%281B_and_3B%29-Conversational.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Phi-4 (14B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4-Conversational.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3.2 Vision (11B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Vision&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_%2811B%29-Vision.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3.1 (8B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_%288B%29-Alpaca.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Mistral v0.3 (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_%287B%29-Conversational.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;DeepSeek-R1-0528-Qwen3 (8B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3.2 (3B) by Meta&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Synthetic Data&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Meta_Synthetic_Data_Llama3_2_%283B%29.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Sesame-CSM (1B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;TTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Sesame_CSM_%281B%29-TTS.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Llama Notebooks&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Notebook Link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3.2 (1B and 3B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_%281B_and_3B%29-Conversational.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3.2 (1B and 3B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Advanced_Llama3_2_(3B)_GRPO_LoRA.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3.1 (8B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_%288B%29-GRPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3.2 (11B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Vision&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_%2811B%29-Vision.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3.2 (1B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;RAFT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_%281B%29-RAFT.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3.1 (8B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Inference&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_%288B%29-Inference.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3.1 (8B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_%288B%29-Alpaca.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3 (8B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Ollama&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_%288B%29-Ollama.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3 (8B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_%288B%29-Alpaca.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3 (8B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ORPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_%288B%29-ORPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3 (8B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_%288B%29-Conversational.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Meta Synthetic Data Llama 3.2 (3B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Data&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Meta_Synthetic_Data_Llama3_2_%283B%29.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Qwen Notebooks&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Notebook Link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen3 (14B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Reasoning Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_%2814B%29-Reasoning-Conversational.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen3-Base (14B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_%2814B%29-Alpaca.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen 2.5 (3B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2.5_%283B%29-GRPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen2.5 Coder (1.5B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Tool Calling&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2.5_Coder_%281.5B%29-Tool_Calling.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen2.5 VL (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Vision&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2.5_VL_%287B%29-Vision.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen2.5 Coder (14B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2.5_Coder_%2814B%29-Conversational.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen2.5 (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2.5_%287B%29-Alpaca.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen2 VL (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Vision&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2_VL_%287B%29-Vision.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen2 (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2_%287B%29-Alpaca.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Gemma Notebooks&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Notebook Link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Gemma 3 (4B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma3_%284B%29.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Gemma 3 (1B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma3_%281B%29-GRPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Gemma 2 (2B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma2_%282B%29-Alpaca.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Gemma 2 (9B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma2_%289B%29-Alpaca.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;CodeGemma (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/CodeGemma_%287B%29-Conversational.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Mistral Notebooks&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Notebook Link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Mistral v0.3 (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_%287B%29-Conversational.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Mistral v0.3 (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;CPT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_%287B%29-CPT.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Mistral v0.3 (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_%287B%29-GRPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Mistral v0.3 (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_%287B%29-Alpaca.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Pixtral (12B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Vision&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Pixtral_%2812B%29-Vision.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Zephyr (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;DPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Zephyr_%287B%29-DPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Mistral Small (22B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_Small_%2822B%29-Alpaca.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Mistral Nemo (12B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_Nemo_%2812B%29-Alpaca.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Mistral (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Text Completion&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_%287B%29-Text_Completion.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Phi Notebooks&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Notebook Link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Phi-4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4-Conversational.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Phi-4 (14B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4_%2814B%29-GRPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Phi-3.5 Mini&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_3.5_Mini-Conversational.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Phi-3 Medium&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_3_Medium-Conversational.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Text-to-Speech (TTS) Notebooks&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Notebook Link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Sesame-CSM&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;TTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Sesame_CSM_%281B%29-TTS.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Orpheus-TTS&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;TTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Orpheus_%283B%29-TTS.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Spark-TTS&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;TTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Spark_TTS_%280_5B%29.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Oute-TTS&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;TTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Oute_TTS_%281B%29.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Oute-TTS&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;TTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Oute_TTS_%281B%29.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llasa TTS (1B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;TTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llasa_TTS_%281B%29.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llasa TTS (3B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;TTS&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llasa_TTS_%283B%29.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Whisper-Large-V3&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;STT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Whisper.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Vision (Multimodal) Notebooks&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Notebook Link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3.2 (11B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Vision&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_%2811B%29-Vision.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen2.5 VL (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Vision&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2.5_VL_%287B%29-Vision.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Pixtral (12B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Vision&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Pixtral_%2812B%29-Vision.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;BERT Notebooks&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Notebook Link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;ModernBERT-large&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/timothelaborie/text_classification_scripts/blob/main/bert_classification.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Specific use-case Notebooks&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Usecase&lt;/th&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Notebook Link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Text Classification&lt;/td&gt; &#xA;   &lt;td&gt;Llama 3.1 (8B)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/timothelaborie/text_classification_scripts/blob/main/unsloth_classification.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Tool Calling&lt;/td&gt; &#xA;   &lt;td&gt;Qwen2.5-Coder (1.5B)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2.5_Coder_(1.5B)-Tool_Calling.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Multiple Datasets&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1njCCbE1YVal9xC83hjdo2hiGItpY_D6t?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;KTO&lt;/td&gt; &#xA;   &lt;td&gt;Qwen2.5-Instruct (1.5B)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1MRgGtLWuZX4ypSfGguFgC-IblTvO2ivM?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Inference Chat UI&lt;/td&gt; &#xA;   &lt;td&gt;LLaMa 3.2 Vision&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Unsloth_Studio.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Conversational&lt;/td&gt; &#xA;   &lt;td&gt;LLaMa 3.2 (1B and 3B)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatML&lt;/td&gt; &#xA;   &lt;td&gt;Mistral (7B)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/15F1xyn8497_dUbxZP4zWmPZ3PJx1Oymv?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Text Completion&lt;/td&gt; &#xA;   &lt;td&gt;Mistral (7B)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_(7B)-Text_Completion.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;GRPO Notebooks&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Notebook Link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;DeepSeek-R1-0528-Qwen3 (8B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/DeepSeek_R1_0528_Qwen3_(8B)_GRPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Phi-4 (14B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4_%2814B%29-GRPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Llama 3.1 (8B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_%288B%29-GRPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Gemma 3 (1B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma3_%281B%29-GRPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen3-Base (4B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_%284B%29-GRPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen 2.5 (3B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2.5_%283B%29-GRPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Mistral v0.3 (7B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_%287B%29-GRPO.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Other Notebooks&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Type&lt;/th&gt; &#xA;   &lt;th&gt;Notebook Link&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Qwen2.5 Coder (1.5B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Tool Calling&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2.5_Coder_%281.5B%29-Tool_Calling.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;TinyLlama (1.1B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Alpaca&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/TinyLlama_%281.1B%29-Alpaca.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Meta Synthetic Data Llama 3.1 (8B)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GRPO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Meta-Synthetic-Data-Llama3.1_%288B%29.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Unsloth&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Studio&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Unsloth_Studio.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;CodeForces cot Finetune for Reasoning on CodeForces&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Reasoning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt; Kaggle Notebooks&lt;/h1&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; Click for all our Kaggle notebooks categorized by model: &lt;/summary&gt; &#xA; &lt;h3&gt;GRPO Notebooks&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Type&lt;/th&gt; &#xA;    &lt;th&gt;Kaggle Link&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Phi 4&lt;/td&gt; &#xA;    &lt;td&gt;GRPO&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Phi_4_(14B)-GRPO.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Llama3.1&lt;/td&gt; &#xA;    &lt;td&gt;GRPO&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Llama3.1_(8B)-GRPO.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Meta Synthetic Data Llama3.1&lt;/td&gt; &#xA;    &lt;td&gt;GRPO&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Meta-Synthetic-Data-Llama3.1_(8B).ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Gemma3&lt;/td&gt; &#xA;    &lt;td&gt;GRPO&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Gemma3_(1B)-GRPO.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Meta Synthetic Data Llama3 2&lt;/td&gt; &#xA;    &lt;td&gt;GRPO&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Meta_Synthetic_Data_Llama3_2_(3B).ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Qwen3&lt;/td&gt; &#xA;    &lt;td&gt;GRPO&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Qwen3_(4B)-GRPO.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Qwen2.5&lt;/td&gt; &#xA;    &lt;td&gt;GRPO&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Qwen2.5_(3B)-GRPO.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Mistral v0.3&lt;/td&gt; &#xA;    &lt;td&gt;GRPO&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Mistral_v0.3_(7B)-GRPO.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h3&gt;Gemma Notebooks&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Type&lt;/th&gt; &#xA;    &lt;th&gt;Kaggle Link&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Gemma3&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Gemma3_(4B).ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Gemma2&lt;/td&gt; &#xA;    &lt;td&gt;Alpaca&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Gemma2_(9B)-Alpaca.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Gemma2&lt;/td&gt; &#xA;    &lt;td&gt;Alpaca&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Gemma2_(2B)-Alpaca.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle CodeGemma&lt;/td&gt; &#xA;    &lt;td&gt;Conversational&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-CodeGemma_(7B)-Conversational.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h3&gt;Llama Notebooks&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Type&lt;/th&gt; &#xA;    &lt;th&gt;Kaggle Link&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Llama3.2&lt;/td&gt; &#xA;    &lt;td&gt;Vision&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Llama3.2_(11B)-Vision.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Llama3.2&lt;/td&gt; &#xA;    &lt;td&gt;Conversational&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Llama3.2_(1B_and_3B)-Conversational.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Llama3.2&lt;/td&gt; &#xA;    &lt;td&gt;RAFT&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Llama3.2_(1B)-RAFT.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Llama3.1&lt;/td&gt; &#xA;    &lt;td&gt;Alpaca&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Llama3.1_(8B)-Alpaca.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Llama3.1&lt;/td&gt; &#xA;    &lt;td&gt;Inference&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Llama3.1_(8B)-Inference.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Llama3&lt;/td&gt; &#xA;    &lt;td&gt;Alpaca&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Llama3_(8B)-Alpaca.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Llama3&lt;/td&gt; &#xA;    &lt;td&gt;Ollama&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Llama3_(8B)-Ollama.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Llama3&lt;/td&gt; &#xA;    &lt;td&gt;Conversational&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Llama3_(8B)-Conversational.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Llama3&lt;/td&gt; &#xA;    &lt;td&gt;ORPO&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Llama3_(8B)-ORPO.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Llasa TTS&lt;/td&gt; &#xA;    &lt;td&gt;TTS&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Llasa_TTS_(3B).ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle TinyLlama&lt;/td&gt; &#xA;    &lt;td&gt;Alpaca&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-TinyLlama_(1.1B)-Alpaca.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Llasa TTS&lt;/td&gt; &#xA;    &lt;td&gt;TTS&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Llasa_TTS_(1B).ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h3&gt;Mistral Notebooks&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Type&lt;/th&gt; &#xA;    &lt;th&gt;Kaggle Link&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Mistral v0.3&lt;/td&gt; &#xA;    &lt;td&gt;Conversational&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Mistral_v0.3_(7B)-Conversational.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Mistral v0.3&lt;/td&gt; &#xA;    &lt;td&gt;Alpaca&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Mistral_v0.3_(7B)-Alpaca.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Mistral v0.3&lt;/td&gt; &#xA;    &lt;td&gt;CPT&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Mistral_v0.3_(7B)-CPT.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Mistral&lt;/td&gt; &#xA;    &lt;td&gt;Text Completion&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Mistral_(7B)-Text_Completion.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Pixtral&lt;/td&gt; &#xA;    &lt;td&gt;Vision&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Pixtral_(12B)-Vision.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Mistral Nemo&lt;/td&gt; &#xA;    &lt;td&gt;Alpaca&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Mistral_Nemo_(12B)-Alpaca.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Zephyr&lt;/td&gt; &#xA;    &lt;td&gt;DPO&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Zephyr_(7B)-DPO.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Mistral Small&lt;/td&gt; &#xA;    &lt;td&gt;Alpaca&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Mistral_Small_(22B)-Alpaca.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h3&gt;Orpheus Notebooks&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Type&lt;/th&gt; &#xA;    &lt;th&gt;Kaggle Link&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Orpheus&lt;/td&gt; &#xA;    &lt;td&gt;TTS&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Orpheus_(3B)-TTS.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h3&gt;Oute Notebooks&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Type&lt;/th&gt; &#xA;    &lt;th&gt;Kaggle Link&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Oute TTS&lt;/td&gt; &#xA;    &lt;td&gt;TTS&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Oute_TTS_(1B).ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h3&gt;Phi Notebooks&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Type&lt;/th&gt; &#xA;    &lt;th&gt;Kaggle Link&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Phi 4&lt;/td&gt; &#xA;    &lt;td&gt;Conversational&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Phi_4-Conversational.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Phi 3.5 Mini&lt;/td&gt; &#xA;    &lt;td&gt;Conversational&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Phi_3.5_Mini-Conversational.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Phi 3 Medium&lt;/td&gt; &#xA;    &lt;td&gt;Conversational&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Phi_3_Medium-Conversational.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h3&gt;Qwen Notebooks&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Type&lt;/th&gt; &#xA;    &lt;th&gt;Kaggle Link&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Qwen3&lt;/td&gt; &#xA;    &lt;td&gt;Reasoning Conversational&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Qwen3_(14B)-Reasoning-Conversational.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Qwen3&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Qwen3_(14B).ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Qwen3&lt;/td&gt; &#xA;    &lt;td&gt;Alpaca&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Qwen3_(14B)-Alpaca.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Qwen2.5&lt;/td&gt; &#xA;    &lt;td&gt;Alpaca&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Qwen2.5_(7B)-Alpaca.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Qwen2.5 Coder&lt;/td&gt; &#xA;    &lt;td&gt;Conversational&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Qwen2.5_Coder_(14B)-Conversational.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Qwen2.5 Coder&lt;/td&gt; &#xA;    &lt;td&gt;Tool Calling&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Qwen2.5_Coder_(1.5B)-Tool_Calling.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Qwen2.5 VL&lt;/td&gt; &#xA;    &lt;td&gt;Vision&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Qwen2.5_VL_(7B)-Vision.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Qwen2 VL&lt;/td&gt; &#xA;    &lt;td&gt;Vision&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Qwen2_VL_(7B)-Vision.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Qwen2&lt;/td&gt; &#xA;    &lt;td&gt;Alpaca&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Qwen2_(7B)-Alpaca.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h3&gt;Spark Notebooks&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Type&lt;/th&gt; &#xA;    &lt;th&gt;Kaggle Link&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Spark TTS&lt;/td&gt; &#xA;    &lt;td&gt;TTS&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Spark_TTS_(0_5B).ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h3&gt;Whisper Notebooks&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Type&lt;/th&gt; &#xA;    &lt;th&gt;Kaggle Link&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Whisper&lt;/td&gt; &#xA;    &lt;td&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Whisper.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA; &lt;h3&gt;Other notebooks Notebooks&lt;/h3&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Type&lt;/th&gt; &#xA;    &lt;th&gt;Kaggle Link&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle CodeForces cot Finetune for Reasoning on CodeForces&lt;/td&gt; &#xA;    &lt;td&gt;Reasoning&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-CodeForces-cot-Finetune_for_Reasoning_on_CodeForces.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Unsloth&lt;/td&gt; &#xA;    &lt;td&gt;Studio&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Unsloth_Studio.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt;Kaggle Sesame CSM&lt;/td&gt; &#xA;    &lt;td&gt;TTS&lt;/td&gt; &#xA;    &lt;td&gt;&lt;a href=&#34;https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/raw/main/nb/Kaggle-Sesame_CSM_(1B)-TTS.ipynb&amp;amp;accelerator=nvidiaTeslaT4&#34;&gt;Open in Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/details&gt; &#xA;&lt;!-- End of Notebook Links --&gt; &#xA;&lt;h1&gt; Contributing to Notebooks&lt;/h1&gt; &#xA;&lt;p&gt;If you&#39;d like to contribute to our notebooks, here&#39;s a guide to get you started:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Find the Template:&lt;/strong&gt; We&#39;ve provided a template notebook called &lt;code&gt;Template_Notebook.ipynb&lt;/code&gt; in the root directory of this project. This template contains the basic structure and formatting guidelines for all notebooks in this collection.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Create Your Notebook:&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Make a copy of &lt;code&gt;Template_Notebook.ipynb&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;Rename the copied file to follow this naming convention: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;strong&gt;LLM Notebooks:&lt;/strong&gt; &lt;code&gt;&amp;lt;Model Name&amp;gt;-&amp;lt;Type&amp;gt;.ipynb&lt;/code&gt; (e.g., &lt;code&gt;Mistral_v0.3_(7B)-Alpaca.ipynb&lt;/code&gt;)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;strong&gt;Vision Notebooks:&lt;/strong&gt; &lt;code&gt;&amp;lt;Model Name&amp;gt;-Vision.ipynb&lt;/code&gt; (e.g., &lt;code&gt;Llava_v1.6_(7B)-Vision.ipynb&lt;/code&gt;)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;strong&gt;Example of &lt;code&gt;&amp;lt;Type&amp;gt;&lt;/code&gt;:&lt;/strong&gt; &lt;code&gt;Alpaca&lt;/code&gt;, &lt;code&gt;Conversational&lt;/code&gt;, &lt;code&gt;CPT&lt;/code&gt;, &lt;code&gt;DPO&lt;/code&gt;, &lt;code&gt;ORPO&lt;/code&gt;, &lt;code&gt;Text_Completion&lt;/code&gt;, &lt;code&gt;CSV&lt;/code&gt;, &lt;code&gt;Inference&lt;/code&gt;, &lt;code&gt;Unsloth_Studio&lt;/code&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA;  &lt;!-- *   Modify the content of your notebook, adding your code, explanations, and any other relevant information. Make sure to follow the structure and guidelines from the template. --&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Place in &lt;code&gt;original_template&lt;/code&gt;:&lt;/strong&gt; Once your notebook is ready, move it to the &lt;code&gt;original_template&lt;/code&gt; directory.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Update Notebooks:&lt;/strong&gt; Run the following command in your terminal: &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python update_all_notebooks.py&#xA;&lt;/code&gt;&lt;/pre&gt; This script will automatically: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Copy your notebook from &lt;code&gt;original_template&lt;/code&gt; to the &lt;code&gt;notebooks&lt;/code&gt; directory.&lt;/li&gt; &#xA;   &lt;li&gt;Update the notebook&#39;s internal sections (like Installation, News) to ensure consistency.&lt;/li&gt; &#xA;   &lt;li&gt;Add your notebook to the appropriate list in this &lt;code&gt;README.md&lt;/code&gt; file.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Create a Pull Request:&lt;/strong&gt; After that, just create a pull request (PR) to merge your changes, making it available for everyone! &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;We appreciate your contributions and look forward to reviewing your notebooks!&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>deepsense-ai/ragbits</title>
    <updated>2025-06-07T01:29:13Z</updated>
    <id>tag:github.com,2025-06-07:/deepsense-ai/ragbits</id>
    <link href="https://github.com/deepsense-ai/ragbits" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Building blocks for rapid development of GenAI applications&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt; Ragbits&lt;/h1&gt; &#xA; &lt;p&gt;&lt;em&gt;Building blocks for rapid development of GenAI applications&lt;/em&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://deepsense.ai/rd-hub/ragbits/&#34;&gt;Homepage&lt;/a&gt; | &lt;a href=&#34;https://ragbits.deepsense.ai&#34;&gt;Documentation&lt;/a&gt; | &lt;a href=&#34;https://deepsense.ai/contact/&#34;&gt;Contact&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://pypi.org/project/ragbits&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/l/ragbits&#34; alt=&#34;PyPI - License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/ragbits&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/ragbits&#34; alt=&#34;PyPI - Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/ragbits&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/ragbits&#34; alt=&#34;PyPI - Python Version&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;h3&gt; Build Reliable &amp;amp; Scalable GenAI Apps&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Swap LLMs anytime&lt;/strong&gt;  Switch between &lt;a href=&#34;https://ragbits.deepsense.ai/how-to/llms/use_llms/&#34;&gt;100+ LLMs via LiteLLM&lt;/a&gt; or run &lt;a href=&#34;https://ragbits.deepsense.ai/how-to/llms/use_local_llms/&#34;&gt;local models&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Type-safe LLM calls&lt;/strong&gt;  Use Python generics to &lt;a href=&#34;https://ragbits.deepsense.ai/how-to/prompts/use_prompting/#how-to-configure-prompts-output-data-type&#34;&gt;enforce strict type safety&lt;/a&gt; in model interactions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Bring your own vector store&lt;/strong&gt;  Connect to &lt;a href=&#34;https://ragbits.deepsense.ai/api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore&#34;&gt;Qdrant&lt;/a&gt;, &lt;a href=&#34;https://ragbits.deepsense.ai/api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore&#34;&gt;PgVector&lt;/a&gt;, and more with built-in support.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Developer tools included&lt;/strong&gt;  &lt;a href=&#34;https://ragbits.deepsense.ai/cli/main/#ragbits-vector-store&#34;&gt;Manage vector stores&lt;/a&gt;, query pipelines, and &lt;a href=&#34;https://ragbits.deepsense.ai/quickstart/quickstart1_prompts/#testing-the-prompt-from-the-cli&#34;&gt;test prompts from your terminal&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Modular installation&lt;/strong&gt;  Install only what you need, reducing dependencies and improving performance.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt; Fast &amp;amp; Flexible RAG Processing&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Ingest 20+ formats&lt;/strong&gt;  Process PDFs, HTML, spreadsheets, presentations, and more. Process data using &lt;a href=&#34;https://github.com/docling-project/docling&#34;&gt;Docling&lt;/a&gt;, &lt;a href=&#34;https://github.com/Unstructured-IO/unstructured&#34;&gt;Unstructured&lt;/a&gt; or create a custom parser.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Handle complex data&lt;/strong&gt;  Extract tables, images, and structured content with built-in VLMs support.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Connect to any data source&lt;/strong&gt;  Use prebuilt connectors for S3, GCS, Azure, or implement your own.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Scale ingestion&lt;/strong&gt;  Process large datasets quickly with &lt;a href=&#34;https://ragbits.deepsense.ai/how-to/document_search/distributed_ingestion/#how-to-ingest-documents-in-a-distributed-fashion&#34;&gt;Ray-based parallel processing&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt; Deploy &amp;amp; Monitor with Confidence&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Real-time observability&lt;/strong&gt;  Track performance with &lt;a href=&#34;https://ragbits.deepsense.ai/how-to/project/use_tracing/#opentelemetry-trace-handler&#34;&gt;OpenTelemetry&lt;/a&gt; and &lt;a href=&#34;https://ragbits.deepsense.ai/how-to/project/use_tracing/#cli-trace-handler&#34;&gt;CLI insights&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Built-in testing&lt;/strong&gt;  Validate prompts &lt;a href=&#34;https://ragbits.deepsense.ai/how-to/prompts/promptfoo/&#34;&gt;with promptfoo&lt;/a&gt; before deployment.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Auto-optimization&lt;/strong&gt;  Continuously evaluate and refine model performance.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Chat UI&lt;/strong&gt;  Deploy &lt;a href=&#34;https://ragbits.deepsense.ai/how-to/chatbots/api/&#34;&gt;chatbot interface&lt;/a&gt; with API, persistance and user feedback.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;To get started quickly, you can install with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install ragbits&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is a starter bundle of packages, containing:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/deepsense-ai/ragbits/tree/main/packages/ragbits-core&#34;&gt;&lt;code&gt;ragbits-core&lt;/code&gt;&lt;/a&gt; - fundamental tools for working with prompts, LLMs and vector databases.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/deepsense-ai/ragbits/tree/main/packages/ragbits-agents&#34;&gt;&lt;code&gt;ragbits-agents&lt;/code&gt;&lt;/a&gt; - abstractions for building agentic systems.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/deepsense-ai/ragbits/tree/main/packages/ragbits-document-search&#34;&gt;&lt;code&gt;ragbits-document-search&lt;/code&gt;&lt;/a&gt; - retrieval and ingestion piplines for knowledge bases.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/deepsense-ai/ragbits/tree/main/packages/ragbits-evaluate&#34;&gt;&lt;code&gt;ragbits-evaluate&lt;/code&gt;&lt;/a&gt; - unified evaluation framework for Ragbits components.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/deepsense-ai/ragbits/tree/main/packages/ragbits-chat&#34;&gt;&lt;code&gt;ragbits-chat&lt;/code&gt;&lt;/a&gt; - full-stack infrastructure for building conversational AI applications.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/deepsense-ai/ragbits/tree/main/packages/ragbits-cli&#34;&gt;&lt;code&gt;ragbits-cli&lt;/code&gt;&lt;/a&gt; - &lt;code&gt;ragbits&lt;/code&gt; shell command for interacting with Ragbits components.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Alternatively, you can use individual components of the stack by installing their respective packages.&lt;/p&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;h3&gt;Basics&lt;/h3&gt; &#xA;&lt;p&gt;To define a prompt and run LLM:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio&#xA;from pydantic import BaseModel&#xA;from ragbits.core.llms import LiteLLM&#xA;from ragbits.core.prompt import Prompt&#xA;&#xA;class QuestionAnswerPromptInput(BaseModel):&#xA;    question: str&#xA;&#xA;class QuestionAnswerPromptOutput(BaseModel):&#xA;    answer: str&#xA;&#xA;class QuestionAnswerPrompt(Prompt[QuestionAnswerPromptInput, QuestionAnswerPromptOutput]):&#xA;    system_prompt = &#34;&#34;&#34;&#xA;    You are a question answering agent. Answer the question to the best of your ability.&#xA;    &#34;&#34;&#34;&#xA;    user_prompt = &#34;&#34;&#34;&#xA;    Question: {{ question }}&#xA;    &#34;&#34;&#34;&#xA;&#xA;llm = LiteLLM(model_name=&#34;gpt-4.1-nano&#34;, use_structured_output=True)&#xA;&#xA;async def main() -&amp;gt; None:&#xA;    prompt = QuestionAnswerPrompt(QuestionAnswerPromptInput(question=&#34;What are high memory and low memory on linux?&#34;))&#xA;    response = await llm.generate(prompt)&#xA;    print(response.answer)&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(main())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Document Search&lt;/h3&gt; &#xA;&lt;p&gt;To build and query a simple vector store index:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio&#xA;from ragbits.core.embeddings import LiteLLMEmbedder&#xA;from ragbits.core.vector_stores import InMemoryVectorStore&#xA;from ragbits.document_search import DocumentSearch&#xA;&#xA;embedder = LiteLLMEmbedder(model_name=&#34;text-embedding-3-small&#34;)&#xA;vector_store = InMemoryVectorStore(embedder=embedder)&#xA;document_search = DocumentSearch(vector_store=vector_store)&#xA;&#xA;async def run() -&amp;gt; None:&#xA;    await document_search.ingest(&#34;web://https://arxiv.org/pdf/1706.03762&#34;)&#xA;    result = await document_search.search(&#34;What are the key findings presented in this paper?&#34;)&#xA;    print(result)&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(run())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Retrieval-Augmented Generation&lt;/h3&gt; &#xA;&lt;p&gt;To build a simple RAG pipeline:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio&#xA;from pydantic import BaseModel&#xA;from ragbits.core.embeddings import LiteLLMEmbedder&#xA;from ragbits.core.llms import LiteLLM&#xA;from ragbits.core.prompt import Prompt&#xA;from ragbits.core.vector_stores import InMemoryVectorStore&#xA;from ragbits.document_search import DocumentSearch&#xA;&#xA;class QuestionAnswerPromptInput(BaseModel):&#xA;    question: str&#xA;    context: list[str]&#xA;&#xA;class QuestionAnswerPromptOutput(BaseModel):&#xA;    answer: str&#xA;&#xA;class QuestionAnswerPrompt(Prompt[QuestionAnswerPromptInput, QuestionAnswerPromptOutput]):&#xA;    system_prompt = &#34;&#34;&#34;&#xA;    You are a question answering agent. Answer the question that will be provided using context.&#xA;    If in the given context there is not enough information refuse to answer.&#xA;    &#34;&#34;&#34;&#xA;    user_prompt = &#34;&#34;&#34;&#xA;    Question: {{ question }}&#xA;    Context: {% for item in context %}&#xA;        {{ item }}&#xA;    {%- endfor %}&#xA;    &#34;&#34;&#34;&#xA;&#xA;embedder = LiteLLMEmbedder(model_name=&#34;text-embedding-3-small&#34;)&#xA;vector_store = InMemoryVectorStore(embedder=embedder)&#xA;document_search = DocumentSearch(vector_store=vector_store)&#xA;llm = LiteLLM(model_name=&#34;gpt-4.1-nano&#34;, use_structured_output=True)&#xA;&#xA;async def run() -&amp;gt; None:&#xA;    question = &#34;What are the key findings presented in this paper?&#34;&#xA;&#xA;    await document_search.ingest(&#34;web://https://arxiv.org/pdf/1706.03762&#34;)&#xA;    result = await document_search.search(question)&#xA;&#xA;    prompt = QuestionAnswerPrompt(QuestionAnswerPromptInput(&#xA;        question=question,&#xA;        context=[element.text_representation for element in result],&#xA;    ))&#xA;    response = await llm.generate(prompt)&#xA;    print(response.answer)&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    asyncio.run(run())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Chatbot interface with UI&lt;/h3&gt; &#xA;&lt;p&gt;To expose your RAG application through Ragbits UI:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from collections.abc import AsyncGenerator&#xA;&#xA;from pydantic import BaseModel&#xA;&#xA;from ragbits.chat.api import RagbitsAPI&#xA;from ragbits.chat.interface import ChatInterface&#xA;from ragbits.chat.interface.types import ChatContext, ChatResponse&#xA;from ragbits.core.embeddings import LiteLLMEmbedder&#xA;from ragbits.core.llms import LiteLLM&#xA;from ragbits.core.prompt import Prompt&#xA;from ragbits.core.prompt.base import ChatFormat&#xA;from ragbits.core.vector_stores import InMemoryVectorStore&#xA;from ragbits.document_search import DocumentSearch&#xA;&#xA;&#xA;class QuestionAnswerPromptInput(BaseModel):&#xA;    question: str&#xA;    context: list[str]&#xA;&#xA;&#xA;class QuestionAnswerPrompt(Prompt[QuestionAnswerPromptInput, str]):&#xA;    system_prompt = &#34;&#34;&#34;&#xA;    You are a question answering agent. Answer the question that will be provided using context.&#xA;    If in the given context there is not enough information refuse to answer.&#xA;    &#34;&#34;&#34;&#xA;    user_prompt = &#34;&#34;&#34;&#xA;    Question: {{ question }}&#xA;    Context: {% for item in context %}{{ item }}{%- endfor %}&#xA;    &#34;&#34;&#34;&#xA;&#xA;&#xA;class MyChat(ChatInterface):&#xA;    &#34;&#34;&#34;Chat interface for fullapp application.&#34;&#34;&#34;&#xA;&#xA;    async def setup(self) -&amp;gt; None:&#xA;        self.embedder = LiteLLMEmbedder(model_name=&#34;text-embedding-3-small&#34;)&#xA;        self.vector_store = InMemoryVectorStore(embedder=self.embedder)&#xA;        self.document_search = DocumentSearch(vector_store=self.vector_store)&#xA;        self.llm = LiteLLM(model_name=&#34;gpt-4.1-nano&#34;, use_structured_output=True)&#xA;&#xA;        await self.document_search.ingest(&#34;web://https://arxiv.org/pdf/1706.03762&#34;)&#xA;&#xA;    async def chat(&#xA;        self,&#xA;        message: str,&#xA;        history: ChatFormat | None = None,&#xA;        context: ChatContext | None = None,&#xA;    ) -&amp;gt; AsyncGenerator[ChatResponse, None]:&#xA;        # Search for relevant documents&#xA;        result = await self.document_search.search(message)&#xA;&#xA;        prompt = QuestionAnswerPrompt(&#xA;            QuestionAnswerPromptInput(&#xA;                question=message,&#xA;                context=[element.text_representation for element in result],&#xA;            )&#xA;        )&#xA;&#xA;        # Stream the response from the LLM&#xA;        async for chunk in self.llm.generate_streaming(prompt):&#xA;            yield self.create_text_response(chunk)&#xA;&#xA;&#xA;if __name__ == &#34;__main__&#34;:&#xA;    RagbitsAPI(MyChat).run()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Rapid development&lt;/h2&gt; &#xA;&lt;p&gt;Create Ragbits projects from templates:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;uvx create-ragbits-app&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Explore &lt;code&gt;create-ragbits-app&lt;/code&gt; repo &lt;a href=&#34;https://github.com/deepsense-ai/create-ragbits-app&#34;&gt;here&lt;/a&gt;. If you have a new idea for a template, feel free to contribute!&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ragbits.deepsense.ai/quickstart/quickstart1_prompts/&#34;&gt;Quickstart&lt;/a&gt; - Get started with Ragbits in a few minutes&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ragbits.deepsense.ai/how-to/prompts/use_prompting/&#34;&gt;How-to&lt;/a&gt; - Learn how to use Ragbits in your projects&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ragbits.deepsense.ai/cli/main/&#34;&gt;CLI&lt;/a&gt; - Learn how to run Ragbits in your terminal&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ragbits.deepsense.ai/api_reference/core/prompt/&#34;&gt;API reference&lt;/a&gt; - Explore the underlying Ragbits API&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions! Please read &lt;a href=&#34;https://github.com/deepsense-ai/ragbits/tree/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Ragbits is licensed under the &lt;a href=&#34;https://github.com/deepsense-ai/ragbits/tree/main/LICENSE&#34;&gt;MIT License&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>