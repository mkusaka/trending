<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-02T01:29:19Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>farshadz1997/Microsoft-Rewards-bot</title>
    <updated>2023-05-02T01:29:19Z</updated>
    <id>tag:github.com,2023-05-02:/farshadz1997/Microsoft-Rewards-bot</id>
    <link href="https://github.com/farshadz1997/Microsoft-Rewards-bot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A simple bot that uses Selenium to farm Microsoft Rewards written in Python&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://forthebadge.com/images/badges/made-with-python.svg?sanitize=true&#34; alt=&#34;cosmetic&#34;&gt; &lt;img src=&#34;https://ForTheBadge.com/images/badges/built-by-developers.svg?sanitize=true&#34; alt=&#34;cosmetic&#34;&gt; &lt;img src=&#34;https://ForTheBadge.com/images/badges/uses-git.svg?sanitize=true&#34; alt=&#34;cosmetic&#34;&gt; &lt;img src=&#34;https://ForTheBadge.com/images/badges/built-with-love.svg?sanitize=true&#34; alt=&#34;cosmetic&#34;&gt; &lt;a href=&#34;https://discord.gg/GaF8fFBtE3&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/GaF8fFBtE3&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;pre align=&#34;center&#34;&gt;&#xA;███╗   ███╗███████╗    ███████╗ █████╗ ██████╗ ███╗   ███╗███████╗██████╗ &#xA;████╗ ████║██╔════╝    ██╔════╝██╔══██╗██╔══██╗████╗ ████║██╔════╝██╔══██╗&#xA;██╔████╔██║███████╗    █████╗  ███████║██████╔╝██╔████╔██║█████╗  ██████╔╝&#xA;██║╚██╔╝██║╚════██║    ██╔══╝  ██╔══██║██╔══██╗██║╚██╔╝██║██╔══╝  ██╔══██╗&#xA;██║ ╚═╝ ██║███████║    ██║     ██║  ██║██║  ██║██║ ╚═╝ ██║███████╗██║  ██║&#xA;╚═╝     ╚═╝╚══════╝    ╚═╝     ╚═╝  ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚══════╝╚═╝  ╚═╝&#xA;        built by @charlesbel upgraded by @farshadz1997      version 2.0&#xA;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Maintained%3F-yes-green.svg?style=for-the-badge&#34; alt=&#34;cosmetic&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge&#34; alt=&#34;cosmetic&#34;&gt; &lt;/p&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;👋 Welcome to the future of automation&lt;/h2&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt;A simple bot that uses selenium to farm Microsoft Rewards written in Python.&lt;/h3&gt; &#xA;&lt;details align=&#34;center&#34;&gt; &#xA; &lt;summary&gt;&lt;h3&gt;GUI versions available&lt;/h3&gt;&lt;/summary&gt; &#xA; &lt;details&gt; &#xA;  &lt;summary&gt;&lt;h4&gt;&lt;a href=&#34;https://github.com/farshadz1997/Microsoft-Rewards-bot-GUI&#34;&gt;PyQt5 version of bot&lt;/a&gt;&lt;/h4&gt;&lt;/summary&gt; &#xA;  &lt;img src=&#34;https://user-images.githubusercontent.com/60227955/206023577-f933334c-edf3-49fe-b30e-12d806847ab7.png&#34; alt=&#34;cosmetic&#34;&gt; &#xA; &lt;/details&gt; &#xA; &lt;details&gt; &#xA;  &lt;summary&gt;&lt;h4&gt;&lt;a href=&#34;https://github.com/farshadz1997/Microsoft-Rewards-bot-GUI-V2&#34;&gt;⭐️New version powered by Flet framework⭐️&lt;/a&gt;&lt;/h4&gt;&lt;/summary&gt; &#xA;  &lt;img src=&#34;https://user-images.githubusercontent.com/60227955/218319443-3f5ea317-e759-4e4c-a847-926b240e2806.png&#34; alt=&#34;cosmetic&#34;&gt; &#xA; &lt;/details&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;Installation&lt;/h2&gt; &#xA;&lt;p allign=&#34;center&#34;&gt;You can also find this repository on &lt;a href=&#34;https://gitlab.com/farshadzargary1997/Microsoft-Rewards-bot&#34;&gt;Gitlab&lt;/a&gt;. You can use the simple installation guide &lt;a href=&#34;https://github.com/farshadz1997/Microsoft-Rewards-bot/raw/master/setup.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For setting up the bot in termux ( android ), follow &lt;a href=&#34;https://raw.githubusercontent.com/farshadz1997/Microsoft-Rewards-bot/master/setup.md#setup-microsoft-rewards-bot-in-termux&#34;&gt;here&lt;/a&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install requirements with the following command : &lt;pre&gt;pip install -r requirements.txt&lt;/pre&gt;&lt;/li&gt; &#xA; &lt;li&gt;Make sure you have Chrome installed (unless your using --edge)&lt;/li&gt; &#xA; &lt;li&gt;Edit the accounts.json.sample with your accounts credentials and rename it by removing &lt;code&gt;.sample&lt;/code&gt; at the end.&lt;br&gt; If you want to add more than one account, the syntax is the following (&lt;code&gt;mobile_user_agent&lt;/code&gt;, &lt;code&gt;proxy&lt;/code&gt; and &lt;code&gt;goal&lt;/code&gt; are optional). Remove &lt;code&gt;mobile_user_agent&lt;/code&gt;, &lt;code&gt;proxy&lt;/code&gt; or &lt;code&gt;goal&lt;/code&gt; from your account if you don&#39;t know how to use them: &lt;pre&gt;&lt;code class=&#34;language-accounts.json&#34;&gt;[&#xA;    {&#xA;        &#34;username&#34;: &#34;Your Email&#34;,&#xA;        &#34;password&#34;: &#34;Your Password&#34;,&#xA;        &#34;totpSecret&#34;: &#34;Your TOTP Secret (optional)&#34;,&#xA;        &#34;mobile_user_agent&#34;: &#34;your preferred mobile user agent&#34;,&#xA;        &#34;proxy&#34;: &#34;HTTP proxy (IP:PORT)&#34;,&#xA;        &#34;goal&#34;: &#34;Amazon&#34;&#xA;    },&#xA;    {&#xA;        &#34;username&#34;: &#34;Your Email 2&#34;,&#xA;        &#34;password&#34;: &#34;Your Password 2&#34;,&#xA;        &#34;totpSecret&#34;: &#34;Your TOTP Secret (optional)&#34;,&#xA;        &#34;mobile_user_agent&#34;: &#34;your preferred mobile user agent&#34;,&#xA;        &#34;proxy&#34;: &#34;HTTP proxy (IP:PORT)&#34;,&#xA;        &#34;goal&#34;: &#34;Xbox Game Pass Ultimate&#34;&#xA;     }&#xA;]   &#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;Due to the limits of Ipapi sometimes it returns an error, and it causes the bot to stop. So you can define the default language and location to prevent it from &lt;a href=&#34;https://github.com/farshadz1997/Microsoft-Rewards-bot/raw/479b2d4b25761d245dc6b3519627162a44d8f85b/ms_rewards_farmer.py#L367&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Run the script&lt;/li&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Use optional arguments&lt;/li&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;--headless&lt;/code&gt; You can use this argument to run the script in headless mode.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--no-images&lt;/code&gt; Prevent images from loading to increase performance.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--dont-check-for-updates&lt;/code&gt; Prevents script from checking updates.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--shuffle&lt;/code&gt; Randomize the order in which accounts are farmed.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--redeem&lt;/code&gt; Enable auto-redeem rewards based on accounts.json goals.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--calculator&lt;/code&gt; Opens GUI calculator with custom options. When using this flag the script will not run.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--session&lt;/code&gt; Use this argument to create session for each account.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--start-at TIME&lt;/code&gt; This argument takes time in 24h format (HH:MM) to run it at the given time.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--everyday&lt;/code&gt; This argument makes the script to stay open and start it again next day at time you start.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--fast&lt;/code&gt; This argument reduces delays of script and make it faster (use this if you have high speed connection).&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--superfast&lt;/code&gt; This argument is faster than fast (use this if you have a very high speed and reliable connection).&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--account-browser ACCOUNT&lt;/code&gt; This argument opens session for given account if it&#39;s already exist else returns error.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--error&lt;/code&gt; When you use this argument, app displays crash error in terminal when it fails.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--telegram TOKEN CHAT_ID&lt;/code&gt; Use this argument to send logs to your telegram through your bot.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--discord WEBHOOK_URL&lt;/code&gt; Use this argument to send logs to your Discord server through webhook.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--skip-unusual&lt;/code&gt; Click on skip for 5 days on unusual activity detection.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--edge&lt;/code&gt; Use Microsoft Edge webdriver instead of Chrome.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--skip-shopping&lt;/code&gt; Skips MSN shopping game.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--repeat-shopping&lt;/code&gt; Repeat MSN shopping game. (So it runs twice per account consecutively)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--no-webdriver-manager&lt;/code&gt; Use system installed webdriver instead of webdriver-manager.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--virtual-display&lt;/code&gt; Use PyVirtualDisplay (intended for Raspberry Pi users).&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--on-finish ACTION&lt;/code&gt; Action to perform on finish from one of the following: shutdown, sleep, hibernate, exit.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--currency CURRENCY&lt;/code&gt; Converts your points into your preferred currency. Available currencies: EUR, USD, AUD, INR, GBP, CAD, JPY, CHF, NZD, ZAR, BRL, CNY, HKD, SGD, THB&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--skip-if-proxy-dead&lt;/code&gt; skips farming a particular account whose supplied proxy is no longer active.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--recheck-proxy&lt;/code&gt; rechecks proxy in case they are reported dead.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--dont-check-internet&lt;/code&gt; Bot won&#39;t look for internet connection if you use this arg.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;--print-to-webhook&lt;/code&gt; Bot will send all the message printed to cli to the webhhok. (will not work if you don&#39;t use either discord or telegram argument).&lt;/li&gt; &#xA;   &lt;li&gt;For example type in your terminal &lt;code&gt;python ms_rewards_farmer.py --start-at 14:30 --everyday --fast --session&lt;/code&gt; You don&#39;t need to use all of arguments.&lt;/li&gt; &#xA;  &lt;/ul&gt; &#xA;  &lt;li&gt;Run the script normally that session and headless disabled.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;Features&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;ul&gt; &#xA; &lt;li&gt;Bing searches (Desktop, Mobile and Edge) with User-Agents&lt;/li&gt; &#xA; &lt;li&gt;Complete automatically the daily set&lt;/li&gt; &#xA; &lt;li&gt;Complete automatically punch cards&lt;/li&gt; &#xA; &lt;li&gt;Complete automatically the others promotions&lt;/li&gt; &#xA; &lt;li&gt;Complete MSN shopping game quiz&lt;/li&gt; &#xA; &lt;li&gt;Headless Mode&lt;/li&gt; &#xA; &lt;li&gt;Multi-Account Management&lt;/li&gt; &#xA; &lt;li&gt;If it faces to an unexpected error then try the account from first&lt;/li&gt; &#xA; &lt;li&gt;Save progress of bot in a log file and use it to pass completed account on the next start at the same day&lt;/li&gt; &#xA; &lt;li&gt;Detect suspended accounts&lt;/li&gt; &#xA; &lt;li&gt;Detect locked accounts&lt;/li&gt; &#xA; &lt;li&gt;Detect unusual activities&lt;/li&gt; &#xA; &lt;li&gt;Uses time out to prevent infinite loop&lt;/li&gt; &#xA; &lt;li&gt;You can assign custom user-agent for mobile like above example&lt;/li&gt; &#xA; &lt;li&gt;Set clock to start it at specific time&lt;/li&gt; &#xA; &lt;li&gt;For Bing search it uses random word at first try and if api failed then it uses google trends&lt;/li&gt; &#xA; &lt;li&gt;Support HTTP proxy&lt;/li&gt; &#xA; &lt;li&gt;Auto-redeem rewards&lt;/li&gt; &#xA; &lt;li&gt;Rewards Calculator &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;AUTO-REDEEM (BETA)&lt;/h2&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;/p&gt;&#xA;&lt;h4 align=&#34;left&#34;&gt;This feature is still in beta! Feel free to try it and report any problems you find. Bear in mind that this feature was designed, so it would only redeem one card from one account each time you run the farmer. This is intentional so your accounts are less likely to get banned. If you do not specify any goal in accounts.json, it will default to Amazon Gift Cards&lt;/h4&gt; &#xA;&lt;br&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;⚠️CAUTION!⚠️&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;h4 align=&#34;center&#34;&gt;Do not use headless mode, it can cause your account to be suspended from Microsoft Rewards.&lt;/h4&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Legal Notice!&lt;/h2&gt; &#xA;&lt;p&gt;I and contributors do not endorse breaking Microsoft’s ToS. This is a proof of concept and purely for educational purposes to learn about Python and Selenium. Contributors and I have learned a lot about Python, Selenium and even using Github and how to collaborate as a team of people remotely. Please take a look at &lt;a href=&#34;https://www.microsoft.com/en-us/servicesagreement/&#34;&gt;Microsoft ToS&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Support me&lt;/h2&gt; &#xA;&lt;p&gt;Your support will be much appreciated&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;b&gt;BTC (BTC network):&lt;/b&gt; bc1qn52jx934nd54vhcv6x5xxsrc7z2qvwf6atcut3&lt;/li&gt; &#xA; &lt;li&gt;&lt;b&gt;ETH (ERC20):&lt;/b&gt; 0x2486D75EC2675833569b85d77b01C2c37097ECc2&lt;/li&gt; &#xA; &lt;li&gt;&lt;b&gt;LTC:&lt;/b&gt; ltc1qc03mnemxewn6z0chfc20yw4samucg6kczmwuf8&lt;/li&gt; &#xA; &lt;li&gt;&lt;b&gt;USDT (ERC20):&lt;/b&gt; 0x2486D75EC2675833569b85d77b01C2c37097ECc2&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>nlpxucan/WizardLM</title>
    <updated>2023-05-02T01:29:19Z</updated>
    <id>tag:github.com,2023-05-02:/nlpxucan/WizardLM</id>
    <link href="https://github.com/nlpxucan/WizardLM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;WizardLM: An Instruction-following LLM Using Evol-Instruct&lt;/h2&gt; &#xA;&lt;p&gt;Empowering Large Pre-Trained Language Models to Follow Complex Instructions&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;a&gt;&lt;img src=&#34;https://raw.githubusercontent.com/nlpxucan/WizardLM/main/imgs/WizardLM.png&#34; alt=&#34;WizardLM&#34; style=&#34;width: 20%; min-width: 300px; display: block; margin: auto;&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg?sanitize=true&#34; alt=&#34;Code License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca/raw/main/DATA_LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg?sanitize=true&#34; alt=&#34;Data License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.python.org/downloads/release/python-390/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.9+-blue.svg?sanitize=true&#34; alt=&#34;Python 3.9+&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;p&gt;At present, our core contributors are fully engaged in preparing the WizardLM-7B model trained with full evolved instructions (&lt;strong&gt;approximately 300k&lt;/strong&gt;). We apologize for any possible delay in responding to your questions. If you find that the demo is temporarily unavailable, please be patient and &lt;strong&gt;wait a while&lt;/strong&gt;. Our contributors regularly check the demo&#39;s status and handle any issues.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🔥 We released &lt;strong&gt;7B&lt;/strong&gt; version of &lt;strong&gt;WizardLM&lt;/strong&gt; trained with &lt;strong&gt;70k&lt;/strong&gt; evolved instructions. Checkout the &lt;a href=&#34;https://arxiv.org/abs/2304.12244&#34;&gt;paper&lt;/a&gt; and &lt;a href=&#34;https://487706ba2456b3ec18.gradio.live&#34;&gt;demo1&lt;/a&gt; , &lt;a href=&#34;https://81189ea0b66d14f256.gradio.live&#34;&gt;demo2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;📣 We are looking for highly motivated students to join us as interns to create more intelligent AI together. Please contact &lt;a href=&#34;mailto:caxu@microsoft.com&#34;&gt;caxu@microsoft.com&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Although on our &lt;strong&gt;complexity-balanced test set&lt;/strong&gt;, &lt;strong&gt;WizardLM-7B has more cases that are preferred by human labelers than ChatGPT&lt;/strong&gt; in the high-complexity instructions (difficulty level &amp;gt;= 8), it still lags behind ChatGPT on the entire test set, and we also consider WizardLM to still be in a &lt;strong&gt;baby state&lt;/strong&gt;. This repository will &lt;strong&gt;continue to improve WizardLM&lt;/strong&gt;, train on larger scales, add more training data, and innovate more advanced large-model training methods.&lt;/p&gt; &#xA;&lt;p&gt;&lt;b&gt;Note for demo usage:&lt;/b&gt; Demo 1-4 are all WizardLM-7B. Please use them as evenly as possible to prevent one of them from being too heavy and responding slowly. We only recommend using &lt;strong&gt;English&lt;/strong&gt; to experience our model. Support for other languages will be introduced in the future. The demo currently only supports &lt;strong&gt;single-turn&lt;/strong&gt; conversation.&lt;/p&gt; &#xA;&lt;h2&gt;Call for Feedbacks&lt;/h2&gt; &#xA;&lt;p&gt;We welcome everyone to use your professional and difficult instructions to evaluate WizardLM, and show us examples of poor performance and your suggestions in the &lt;a href=&#34;https://github.com/nlpxucan/WizardLM/issues&#34;&gt;issue discussion&lt;/a&gt; area. We are focusing on improving the Evol-Instruct now and hope to relieve existing weaknesses and issues in the the next version of WizardLM. After that, we will open the code and pipeline of up-to-date Evol-Instruct algorithm and work with you together to improve it.&lt;/p&gt; &#xA;&lt;h2&gt;Unofficial Video Introductions&lt;/h2&gt; &#xA;&lt;p&gt;Thanks to the enthusiastic friends, their video introductions are more lively and interesting.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=SaJ8wyKMBds&#34;&gt;GET WizardLM NOW! 7B LLM KING That Can Beat ChatGPT! I&#39;m IMPRESSED!&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=I6sER-qivYk&#34;&gt;WizardLM: Enhancing Large Language Models to Follow Complex Instructions&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Case Show&lt;/h2&gt; &#xA;&lt;p&gt;We just sample some cases to demonstrate the performance of WizardLM and ChatGPT on data of varying difficulty, and the details pls refer &lt;a href=&#34;https://github.com/nlpxucan/WizardLM/raw/main/src/case_show.md&#34;&gt;Case Show&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Overview of Evol-Instruct&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/nlpxucan/evol-instruct&#34;&gt;Evol-Instruct&lt;/a&gt; is a novel method using LLMs instead of humans to automatically mass-produce open-domain instructions of various difficulty levels and skills range, to improve the performance of LLMs.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;a&gt;&lt;img src=&#34;https://raw.githubusercontent.com/nlpxucan/WizardLM/main/imgs/git_overall.png&#34; alt=&#34;WizardLM&#34; style=&#34;width: 86%; min-width: 300px; display: block; margin: auto;&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;a&gt;&lt;img src=&#34;https://raw.githubusercontent.com/nlpxucan/WizardLM/main/imgs/git_running.png&#34; alt=&#34;WizardLM&#34; style=&#34;width: 86%; min-width: 300px; display: block; margin: auto;&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/nlpxucan/WizardLM/main/#online-demo&#34;&gt;Online Demo&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/nlpxucan/WizardLM/main/#train_data&#34;&gt;Training Data&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/nlpxucan/WizardLM/main/#wizardlm-weights&#34;&gt;WizardLM Weights&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/nlpxucan/WizardLM/main/#finetune&#34;&gt;Fine-tuning&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/nlpxucan/WizardLM/main/#inference&#34;&gt;Inference&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/nlpxucan/WizardLM/main/#evaluation&#34;&gt;Evaluation&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/nlpxucan/WizardLM/main/#citation&#34;&gt;Citation&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/nlpxucan/WizardLM/main/#disclaimer&#34;&gt;Disclaimer&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Online Demo&lt;/h2&gt; &#xA;&lt;p&gt;We will provide our latest models for you to try for as long as possible. If you find a link is not working, please try another one. At the same time, please try as many &lt;strong&gt;real-world&lt;/strong&gt; and &lt;strong&gt;challenging&lt;/strong&gt; problems that you encounter in your work and life as possible. We will continue to evolve our models with your feedbacks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://487706ba2456b3ec18.gradio.live&#34;&gt;Demo Link&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://81189ea0b66d14f256.gradio.live&#34;&gt;Demo Backup 1&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Training Data&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://huggingface.co/datasets/victor123/evol_instruct_70k&#34;&gt;&lt;code&gt;alpaca_evol_instruct_70k.json&lt;/code&gt;&lt;/a&gt; contains 70K instruction-following data generated from Evol-Instruct. We used it for fine-tuning the WizardLM model. This JSON file is a list of dictionaries, each dictionary contains the following fields:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;instruction&lt;/code&gt;: &lt;code&gt;str&lt;/code&gt;, describes the task the model should perform. Each of the 70K instructions is unique.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;output&lt;/code&gt;: &lt;code&gt;str&lt;/code&gt;, the answer to the instruction as generated by &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;WizardLM Weights&lt;/h2&gt; &#xA;&lt;p&gt;We release [WizardLM] weights as delta weights to comply with the LLaMA model license. You can add our delta to the original LLaMA weights to obtain the WizardLM weights. Instructions:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Get the original LLaMA weights in the huggingface format by following the instructions &lt;a href=&#34;https://huggingface.co/docs/transformers/main/model_doc/llama&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Please download our delta model at the following &lt;a href=&#34;https://huggingface.co/victor123/WizardLM&#34;&gt;link&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Use the following scripts to get WizardLM weights by applying our delta:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;python src/weight_diff_wizard.py recover --path_raw &amp;lt;path_to_step_1_dir&amp;gt; --path_diff &amp;lt;path_to_step_2_dir&amp;gt; --path_tuned &amp;lt;path_to_store_recovered_weights&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Fine-tuning&lt;/h2&gt; &#xA;&lt;p&gt;We fine-tune WizardLM using code from &lt;a href=&#34;https://github.com/AetherCortex/Llama-X&#34;&gt;Llama-X&lt;/a&gt;. We fine-tune LLaMA-7B with the following hyperparameters:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Hyperparameter&lt;/th&gt; &#xA;   &lt;th&gt;LLaMA-7B&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Batch size&lt;/td&gt; &#xA;   &lt;td&gt;64&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Learning rate&lt;/td&gt; &#xA;   &lt;td&gt;2e-5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Epochs&lt;/td&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Max length&lt;/td&gt; &#xA;   &lt;td&gt;2048&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Warmup step&lt;/td&gt; &#xA;   &lt;td&gt;2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LR scheduler&lt;/td&gt; &#xA;   &lt;td&gt;cosine&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;To reproduce our fine-tuning of WizardLM, please follow the following steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;According to the instructions of &lt;a href=&#34;https://github.com/AetherCortex/Llama-X&#34;&gt;Llama-X&lt;/a&gt;, install the environment, download the training code, and deploy.&lt;/li&gt; &#xA; &lt;li&gt;Replace the train.py with the train_freeform.py in our repo(src/train_freeform.py)&lt;/li&gt; &#xA; &lt;li&gt;Execute the following training command:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;deepspeed train_freeform.py \&#xA;    --model_name_or_path /path/to/llama-7B/hf \&#xA;    --data_path /path/to/alpaca_evol_instruct_70k.json \&#xA;    --output_dir /path/to/wizardlm-7B/hf/ft \&#xA;    --num_train_epochs 3 \&#xA;    --model_max_length 2048 \&#xA;    --per_device_train_batch_size 8 \&#xA;    --per_device_eval_batch_size 1 \&#xA;    --gradient_accumulation_steps 1 \&#xA;    --evaluation_strategy &#34;no&#34; \&#xA;    --save_strategy &#34;steps&#34; \&#xA;    --save_steps 800 \&#xA;    --save_total_limit 3 \&#xA;    --learning_rate 2e-5 \&#xA;    --warmup_steps 2 \&#xA;    --logging_steps 2 \&#xA;    --lr_scheduler_type &#34;cosine&#34; \&#xA;    --report_to &#34;tensorboard&#34; \&#xA;    --gradient_checkpointing True \&#xA;    --deepspeed configs/deepspeed_config.json \&#xA;    --fp16 True&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;p&gt;We provide the decoding script for WizardLM, which reads a input file and generates corresponding responses for each sample, and finally consolidates them into an output file.&lt;/p&gt; &#xA;&lt;p&gt;You can specify &lt;code&gt;base_model&lt;/code&gt;, &lt;code&gt;input_data_path&lt;/code&gt; and &lt;code&gt;output_data_path&lt;/code&gt; in src\inference_wizardlm.py to set the decoding model, path of input file and path of output file. The decoding command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python src\inference_wizardlm.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Evaluation&lt;/h3&gt; &#xA;&lt;p&gt;To evaluate Wizard, we conduct human evaluation on the inputs from our human instruct evaluation set &lt;a href=&#34;https://raw.githubusercontent.com/nlpxucan/WizardLM/main/data/WizardLM_testset.jsonl&#34;&gt;&lt;code&gt;WizardLM_testset.jsonl&lt;/code&gt;&lt;/a&gt; . This evaluation set was collected by the authors and covers a diverse list of user-oriented instructions including difficult Coding Generation &amp;amp; Debugging, Math, Reasoning, Complex Formats, Academic Writing, Extensive Disciplines, and so on. We performed a blind pairwise comparison between Wizard and baselines. Specifically, we recruit 10 well-educated annotators to rank the models from 1 to 5 on relevance, knowledgeable, reasoning, calculation and accuracy.&lt;/p&gt; &#xA;&lt;p&gt;WizardLM achieved significantly better results than Alpaca and Vicuna-7b.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;60%&#34;&gt; &lt;a&gt;&lt;img src=&#34;https://raw.githubusercontent.com/nlpxucan/WizardLM/main/imgs/win.png&#34; alt=&#34;WizardLM&#34; style=&#34;width: 60%; min-width: 300px; display: block; margin: auto;&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;In the high-difficulty section of our test set (difficulty level &amp;gt;= 8), WizardLM even outperforms ChatGPT, with a win rate 7.9% larger than Chatgpt (42.9% vs. 35.0%). This indicates that our method can significantly improve the ability of large language models to handle complex instructions.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;60%&#34;&gt; &lt;a&gt;&lt;img src=&#34;https://raw.githubusercontent.com/nlpxucan/WizardLM/main/imgs/windiff.png&#34; alt=&#34;WizardLM&#34; style=&#34;width: 60%; min-width: 300px; display: block; margin: auto;&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h3&gt;Citation&lt;/h3&gt; &#xA;&lt;p&gt;Please cite the repo if you use the data or code in this repo.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{xu2023wizardlm,&#xA;      title={WizardLM: Empowering Large Language Models to Follow Complex Instructions}, &#xA;      author={Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Daxin Jiang},&#xA;      year={2023},&#xA;      eprint={2304.12244},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CL}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;The resources, including code, data, and model weights, associated with this project are restricted for academic research purposes only and cannot be used for commercial purposes. The content produced by any version of WizardLM is influenced by uncontrollable variables such as randomness, and therefore, the accuracy of the output cannot be guaranteed by this project. This project does not accept any legal liability for the content of the model output, nor does it assume responsibility for any losses incurred due to the use of associated resources and output results.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>pixiv/ChatVRM</title>
    <updated>2023-05-02T01:29:19Z</updated>
    <id>tag:github.com,2023-05-02:/pixiv/ChatVRM</id>
    <link href="https://github.com/pixiv/ChatVRM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatVRM&lt;/h1&gt; &#xA;&lt;p&gt;ChatVRMはブラウザで簡単に3Dキャラクターと会話ができるデモアプリケーションです。&lt;/p&gt; &#xA;&lt;p&gt;VRMファイルをインポートしてキャラクターに合わせた声の調整や、感情表現を含んだ返答文の生成などを行うことができます。&lt;/p&gt; &#xA;&lt;p&gt;ChatVRMの各機能は主に以下の技術を使用しています。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ユーザーの音声の認識 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/SpeechRecognition&#34;&gt;Web Speech API(SpeechRecognition)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;返答文の生成 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://platform.openai.com/docs/api-reference/chat&#34;&gt;ChatGPT API&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;読み上げ音声の生成 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://koeiromap.rinna.jp/&#34;&gt;Koeiro API&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;3Dキャラクターの表示 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/pixiv/three-vrm&#34;&gt;@pixiv/three-vrm&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;デモ&lt;/h2&gt; &#xA;&lt;p&gt;GitHub Pagesでデモを公開しています。&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pixiv.github.io/ChatVRM&#34;&gt;https://pixiv.github.io/ChatVRM&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;実行&lt;/h2&gt; &#xA;&lt;p&gt;ローカル環境で実行する場合はこのリポジトリをクローンするか、ダウンロードしてください。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone git@github.com:pixiv/ChatVRM.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;必要なパッケージをインストールしてください。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;パッケージのインストールが完了した後、以下のコマンドで開発用のWebサーバーを起動します。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;実行後、以下のURLにアクセスして動作を確認して下さい。&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://localhost:3000&#34;&gt;http://localhost:3000&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;ChatGPT API&lt;/h2&gt; &#xA;&lt;p&gt;ChatVRMでは返答文の生成にChatGPT APIを使用しています。&lt;/p&gt; &#xA;&lt;p&gt;ChatGPT APIの仕様や利用規約については以下のリンクや公式サイトをご確認ください。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://platform.openai.com/docs/api-reference/chat&#34;&gt;https://platform.openai.com/docs/api-reference/chat&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openai.com/policies/api-data-usage-policies&#34;&gt;https://openai.com/policies/api-data-usage-policies&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Koeiro API&lt;/h2&gt; &#xA;&lt;p&gt;ChatVRMでは返答文の音声読み上げにKoeiro APIを使用しています。&lt;/p&gt; &#xA;&lt;p&gt;Koeiro APIの仕様や利用規約については以下のリンクや公式サイトをご確認ください。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://koeiromap.rinna.jp/&#34;&gt;http://koeiromap.rinna.jp/&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>