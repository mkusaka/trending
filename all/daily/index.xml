<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-30T01:29:51Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ChaoningZhang/MobileSAM</title>
    <updated>2023-06-30T01:29:51Z</updated>
    <id>tag:github.com,2023-06-30:/ChaoningZhang/MobileSAM</id>
    <link href="https://github.com/ChaoningZhang/MobileSAM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This is the offiicial code for Faster Segment Anything (MobileSAM) project that makes SAM lightweight&lt;/p&gt;&lt;hr&gt;&lt;p float=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ChaoningZhang/MobileSAM/master/assets/logo2.png?raw=true&#34; width=&#34;99.1%&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;Faster Segment Anything (MobileSAM)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;span&gt;üìå&lt;/span&gt; MobileSAM paper is available at &lt;a href=&#34;https://www.researchgate.net/publication/371851844_Faster_Segment_Anything_Towards_Lightweight_SAM_for_Mobile_Applications&#34;&gt;ResearchGate&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/pdf/2306.14289.pdf&#34;&gt;arXiv&lt;/a&gt;. The latest version will first appear on &lt;a href=&#34;https://arxiv.org/pdf/2306.14289.pdf&#34;&gt;ResearchGate&lt;/a&gt;, since it takes time for arXiv to update the content.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;üìå&lt;/span&gt; A &lt;strong&gt;demo of MobileSAM&lt;/strong&gt; running on &lt;strong&gt;CPU&lt;/strong&gt; is open at &lt;a href=&#34;https://huggingface.co/spaces/dhkim2810/MobileSAM&#34;&gt;demo link&lt;/a&gt; (A new version with other features will come soon, stay tuned!). On our own Mac i5 CPU, it takes around 3s. On the hugging face demo, the interface and inferior CPUs make it slower but still works fine.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;üçá&lt;/span&gt; Media coverage and Projects that adapt from SAM to MobileSAM (Updates)&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023/06/30&lt;/strong&gt;: MobileSAM has been featured by &lt;a href=&#34;https://twitter.com/_akhaliq?lang=en&#34;&gt;AK&lt;/a&gt; for the second time, see the link &lt;a href=&#34;https://twitter.com/_akhaliq/status/1674410573075718145&#34;&gt;AK&#39;s MobileSAM tweet&lt;/a&gt;. Welcome to retweet.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023/06/29&lt;/strong&gt;: &lt;a href=&#34;https://github.com/vietanhdev/anylabeling&#34;&gt;AnyLabeling&lt;/a&gt; supports MobileSAM for auto-labeling. Thanks for their effort.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023/06/29&lt;/strong&gt;: &lt;a href=&#34;https://github.com/wangsssky/SonarSAM&#34;&gt;SonarSAM&lt;/a&gt; supports MobileSAM for Image encoder full-finetuing. Thanks for their effort.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023/06/29&lt;/strong&gt;: &lt;a href=&#34;https://github.com/continue-revolution/sd-webui-segment-anything&#34;&gt;Stable Diffusion WebUIv&lt;/a&gt; supports MobileSAM. Thanks for their effort.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023/06/28&lt;/strong&gt;: &lt;a href=&#34;https://github.com/IDEA-Research/Grounded-Segment-Anything&#34;&gt;Grounding-SAM&lt;/a&gt; supports MobileSAM with &lt;a href=&#34;https://github.com/IDEA-Research/Grounded-Segment-Anything/tree/main/EfficientSAM&#34;&gt;Grounded-MobileSAM&lt;/a&gt;. Thanks for their effort.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023/06/27&lt;/strong&gt;: MobileSAM has been featured by &lt;a href=&#34;https://twitter.com/_akhaliq?lang=en&#34;&gt;AK&lt;/a&gt;, see the link &lt;a href=&#34;https://twitter.com/_akhaliq/status/1673585099097636864&#34;&gt;AK&#39;s MobileSAM tweet&lt;/a&gt;. Welcome to retweet. &lt;img src=&#34;https://raw.githubusercontent.com/ChaoningZhang/MobileSAM/master/assets/model_diagram.jpg?raw=true&#34; alt=&#34;MobileSAM&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; &lt;strong&gt;How is MobileSAM trained?&lt;/strong&gt; MobileSAM is trained on a single GPU with 100k datasets (1% of the original images) for less than a day. The training code will be available soon.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; &lt;strong&gt;How to Adapt from SAM to MobileSAM?&lt;/strong&gt; Since MobileSAM keeps exactly the same pipeline as the original SAM, we inherit pre-processing, post-processing, and all other interfaces from the original SAM. Therefore, by assuming everything is exactly the same except for a smaller image encoder, those who use the original SAM for their projects can &lt;strong&gt;adapt to MobileSAM with almost zero effort&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; &lt;strong&gt;MobileSAM performs on par with the original SAM (at least visually)&lt;/strong&gt; and keeps exactly the same pipeline as the original SAM except for a change on the image encoder. Specifically, we replace the original heavyweight ViT-H encoder (632M) with a much smaller Tiny-ViT (5M). On a single GPU, MobileSAM runs around 12ms per image: 8ms on the image encoder and 4ms on the mask decoder.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;The comparison of ViT-based image encoder is summarzed as follows:&lt;/p&gt; &#xA;  &lt;table&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;Image Encoder&lt;/th&gt; &#xA;     &lt;th align=&#34;left&#34;&gt;Original SAM&lt;/th&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;MobileSAM&lt;/th&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/thead&gt; &#xA;   &lt;tbody&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Paramters&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;611M&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;5M&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Speed&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;452ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;8ms&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Original SAM and MobileSAM have exactly the same prompt-guided mask decoder:&lt;/p&gt; &#xA;  &lt;table&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;Mask Decoder&lt;/th&gt; &#xA;     &lt;th align=&#34;left&#34;&gt;Original SAM&lt;/th&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;MobileSAM&lt;/th&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/thead&gt; &#xA;   &lt;tbody&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Paramters&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;3.876M&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;3.876M&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Speed&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;4ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;4ms&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The comparison of the whole pipeline is summarized as follows:&lt;/p&gt; &#xA;  &lt;table&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;Whole Pipeline (Enc+Dec)&lt;/th&gt; &#xA;     &lt;th align=&#34;left&#34;&gt;Original SAM&lt;/th&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;MobileSAM&lt;/th&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/thead&gt; &#xA;   &lt;tbody&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Paramters&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;615M&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;9.66M&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Speed&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;456ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;12ms&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; &lt;strong&gt;Original SAM and MobileSAM with a (single) point as the prompt.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p float=&#34;left&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ChaoningZhang/MobileSAM/master/assets/mask_point.jpg?raw=true&#34; width=&#34;99.1%&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; &lt;strong&gt;Original SAM and MobileSAM with a box as the prompt.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p float=&#34;left&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ChaoningZhang/MobileSAM/master/assets/mask_box.jpg?raw=true&#34; width=&#34;99.1%&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;üí™&lt;/span&gt; &lt;strong&gt;Is MobileSAM faster and smaller than FastSAM? Yes!&lt;/strong&gt; MobileSAM is around 7 times smaller and around 5 times faster than the concurrent FastSAM. The comparison of the whole pipeline is summarzed as follows:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Whole Pipeline (Enc+Dec)&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;FastSAM&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MobileSAM&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Paramters&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;68M&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.66M&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Speed&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;64ms&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;span&gt;üí™&lt;/span&gt; &lt;strong&gt;Does MobileSAM aign better with the original SAM than FastSAM? Yes!&lt;/strong&gt; FastSAM is suggested to work with multiple points, thus we compare the mIoU with two prompt points (with different pixel distances) and show the resutls as follows. Higher mIoU indicates higher alignment.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;mIoU&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;FastSAM&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MobileSAM&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;100&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.27&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.73&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;200&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.33&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.71&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;300&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.37&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.74&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;400&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.41&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.73&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;500&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.41&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.73&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;The code requires &lt;code&gt;python&amp;gt;=3.8&lt;/code&gt;, as well as &lt;code&gt;pytorch&amp;gt;=1.7&lt;/code&gt; and &lt;code&gt;torchvision&amp;gt;=0.8&lt;/code&gt;. Please follow the instructions &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;here&lt;/a&gt; to install both PyTorch and TorchVision dependencies. Installing both PyTorch and TorchVision with CUDA support is strongly recommended.&lt;/p&gt; &#xA;&lt;p&gt;Install Mobile Segment Anything:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install git+https://github.com/ChaoningZhang/MobileSAM.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or clone the repository locally and install with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:ChaoningZhang/MobileSAM.git&#xA;cd MobileSAM; pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;GettingStarted&#34;&gt;&lt;/a&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;The MobileSAM can be loaded in the following ways:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from mobile_encoder.setup_mobile_sam import setup_model&#xA;checkpoint = torch.load(&#39;../weights/mobile_sam.pt&#39;)&#xA;mobile_sam = setup_model()&#xA;mobile_sam.load_state_dict(checkpoint,strict=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then the model can be easily used in just a few lines to get masks from a given prompt:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from segment_anything import SamPredictor&#xA;device = &#34;cuda&#34;&#xA;mobile_sam.to(device=device)&#xA;mobile_sam.eval()&#xA;predictor = SamPredictor(mobile_sam)&#xA;predictor.set_image(&amp;lt;your_image&amp;gt;)&#xA;masks, _, _ = predictor.predict(&amp;lt;input_prompts&amp;gt;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or generate masks for an entire image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from segment_anything import SamAutomaticMaskGenerator&#xA;&#xA;mask_generator = SamAutomaticMaskGenerator(mobile_sam)&#xA;masks = mask_generator.generate(&amp;lt;your_image&amp;gt;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;BibTex of our MobileSAM&lt;/h2&gt; &#xA;&lt;p&gt;If you use MobileSAM in your research, please use the following BibTeX entry. &lt;span&gt;üì£&lt;/span&gt; Thank you!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{mobile_sam,&#xA;  title={Faster Segment Anything: Towards Lightweight SAM for Mobile Applications},&#xA;  author={Zhang, Chaoning and Han, Dongshen and Qiao, Yu and Kim, Jung Uk and Bae, Sung Ho and Lee, Seungkyu and Hong, Choong Seon},&#xA;  journal={arXiv preprint arXiv:2306.14289},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;a href=&#34;https://github.com/facebookresearch/segment-anything&#34;&gt;SAM&lt;/a&gt; (Segment Anything) [&lt;b&gt;bib&lt;/b&gt;] &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{kirillov2023segany,&#xA;  title={Segment Anything}, &#xA;  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Doll{\&#39;a}r, Piotr and Girshick, Ross},&#xA;  journal={arXiv:2304.02643},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;a href=&#34;https://github.com/microsoft/Cream/tree/main/TinyViT&#34;&gt;TinyViT&lt;/a&gt; (TinyViT: Fast Pretraining Distillation for Small Vision Transformers) [&lt;b&gt;bib&lt;/b&gt;] &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{tiny_vit,&#xA;  title={TinyViT: Fast Pretraining Distillation for Small Vision Transformers},&#xA;  author={Wu, Kan and Zhang, Jinnian and Peng, Houwen and Liu, Mengchen and Xiao, Bin and Fu, Jianlong and Yuan, Lu},&#xA;  booktitle={European conference on computer vision (ECCV)},&#xA;  year={2022}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt;</summary>
  </entry>
  <entry>
    <title>jasontaylordev/CleanArchitecture</title>
    <updated>2023-06-30T01:29:51Z</updated>
    <id>tag:github.com,2023-06-30:/jasontaylordev/CleanArchitecture</id>
    <link href="https://github.com/jasontaylordev/CleanArchitecture" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Clean Architecture Solution Template for ASP.NET Core&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/jasontaylordev/CleanArchitecture/actions/workflows/dotnet-build.yml&#34;&gt;&lt;img src=&#34;https://github.com/jasontaylordev/CleanArchitecture/actions/workflows/dotnet-build.yml/badge.svg?sanitize=true&#34; alt=&#34;Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/jasontaylordev/CleanArchitecture/actions/workflows/codeql-analysis.yml&#34;&gt;&lt;img src=&#34;https://github.com/jasontaylordev/CleanArchitecture/actions/workflows/codeql-analysis.yml/badge.svg?sanitize=true&#34; alt=&#34;CodeQL&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.nuget.org/packages/Clean.Architecture.Solution.Template&#34;&gt;&lt;img src=&#34;https://img.shields.io/nuget/v/Clean.Architecture.Solution.Template?label=NuGet&#34; alt=&#34;Nuget&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.nuget.org/packages/Clean.Architecture.Solution.Template&#34;&gt;&lt;img src=&#34;https://img.shields.io/nuget/dt/Clean.Architecture.Solution.Template?label=Downloads&#34; alt=&#34;Nuget&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/p9YtBjfgGe&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/893301913662148658?label=Discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/twitter/follow/jasontaylordev?label=Follow&amp;amp;style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Clean Architecture Solution Template&lt;/h1&gt; &#xA;&lt;p&gt;The goal of this template is to provide a straightforward and efficient approach to enterprise application development, leveraging the power of Clean Architecture and ASP.NET Core. Using this template, you can effortlessly create a Single Page App (SPA) with ASP.NET Core and Angular or React, while adhering to the principles of Clean Architecture. Getting started is easy - simply install the &lt;strong&gt;.NET template&lt;/strong&gt; (see below for full details).&lt;/p&gt; &#xA;&lt;h2&gt;Technologies&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/aspnet/core/introduction-to-aspnet-core&#34;&gt;ASP.NET Core 8&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/ef/core/&#34;&gt;Entity Framework Core 8&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://angular.io/&#34;&gt;Angular 15&lt;/a&gt; or &lt;a href=&#34;https://react.dev/&#34;&gt;React 18&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jbogard/MediatR&#34;&gt;MediatR&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://automapper.org/&#34;&gt;AutoMapper&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fluentvalidation.net/&#34;&gt;FluentValidation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nunit.org/&#34;&gt;NUnit&lt;/a&gt;, &lt;a href=&#34;https://fluentassertions.com/&#34;&gt;FluentAssertions&lt;/a&gt;, &lt;a href=&#34;https://github.com/moq&#34;&gt;Moq&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://github.com/jbogard/Respawn&#34;&gt;Respawn&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;p&gt;The template depends on the latest versions of:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dotnet.microsoft.com/download/dotnet/8.0&#34;&gt;.NET 8 SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nodejs.org/en/&#34;&gt;Node.js LTS&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;The easiest way to get started is to install the &lt;a href=&#34;https://www.nuget.org/packages/Clean.Architecture.Solution.Template&#34;&gt;.NET template&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dotnet new install Clean.Architecture.Solution.Template::8.0.0-preview.5.2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once installed, create a new solution using the template:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dotnet new ca-sln -c &amp;lt;Angular|React&amp;gt; --output &amp;lt;YourProjectName&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The above command creates a SPA with Angular or React on ASP.NET Core. Start the application by navigating to &lt;code&gt;./src/WebUI&lt;/code&gt; and running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dotnet run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create use cases (commands or queries) by navigating to &lt;code&gt;./src/Application&lt;/code&gt;, and running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dotnet new ca-usecase --feature TodoLists --name CreateTodoList --useCaseType command --returnType int&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To learn more, run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dotnet new ca-usecase --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Database&lt;/h2&gt; &#xA;&lt;p&gt;The template is configured to use an in-memory database by default. This ensures that all users will be able to run the solution without needing to set up additional infrastructure (e.g. SQL Server).&lt;/p&gt; &#xA;&lt;p&gt;If you would like to use SQL Server, you will need to update &lt;strong&gt;WebUI/appsettings.json&lt;/strong&gt; as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;  &#34;UseInMemoryDatabase&#34;: false,&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Verify that the &lt;strong&gt;DefaultConnection&lt;/strong&gt; connection string within &lt;strong&gt;appsettings.json&lt;/strong&gt; points to a valid SQL Server instance.&lt;/p&gt; &#xA;&lt;p&gt;When you run the application the database will be automatically created (if necessary) and the latest migrations will be applied.&lt;/p&gt; &#xA;&lt;h3&gt;Database Migrations&lt;/h3&gt; &#xA;&lt;p&gt;To use &lt;code&gt;dotnet-ef&lt;/code&gt; for your migrations first ensure that &#34;UseInMemoryDatabase&#34; is disabled, as described within previous section. Then, add the following flags to your command (values assume you are executing from repository root)&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--project src/Infrastructure&lt;/code&gt; (optional if in this folder)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--startup-project src/WebUI&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--output-dir Persistence/Migrations&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For example, to add a new migration from the root folder:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;dotnet ef migrations add &#34;SampleMigration&#34; --project src\Infrastructure --startup-project src\WebUI --output-dir Persistence\Migrations&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Versions&lt;/h2&gt; &#xA;&lt;p&gt;The main branch is now on .NET 8.0. The following previous versions are available:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jasontaylordev/CleanArchitecture/tree/net7.0&#34;&gt;7.0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jasontaylordev/CleanArchitecture/tree/net6.0&#34;&gt;6.0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jasontaylordev/CleanArchitecture/tree/net5.0&#34;&gt;5.0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jasontaylordev/CleanArchitecture/tree/netcore3.1&#34;&gt;3.1&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Learn More&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/dK4Yb6-LxAk&#34;&gt;Clean Architecture with ASP.NET Core 3.0 (GOTO 2019)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jasontaylor.dev/clean-architecture-getting-started/&#34;&gt;Clean Architecture with .NET Core: Getting Started&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;If you are having problems, please let me know by &lt;a href=&#34;https://github.com/jasontaylordev/CleanArchitecture/issues/new/choose&#34;&gt;raising a new issue&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed with the &lt;a href=&#34;https://raw.githubusercontent.com/jasontaylordev/CleanArchitecture/main/LICENSE&#34;&gt;MIT license&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>THUDM/ChatGLM2-6B</title>
    <updated>2023-06-30T01:29:51Z</updated>
    <id>tag:github.com,2023-06-30:/THUDM/ChatGLM2-6B</id>
    <link href="https://github.com/THUDM/ChatGLM2-6B" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ChatGLM2-6B: An Open Bilingual Chat LLM | ÂºÄÊ∫êÂèåËØ≠ÂØπËØùËØ≠Ë®ÄÊ®°Âûã&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGLM2-6B&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; ü§ó &lt;a href=&#34;https://huggingface.co/THUDM/chatglm2-6b&#34; target=&#34;_blank&#34;&gt;HF Repo&lt;/a&gt; ‚Ä¢ üê¶ &lt;a href=&#34;https://twitter.com/thukeg&#34; target=&#34;_blank&#34;&gt;Twitter&lt;/a&gt; ‚Ä¢ üìÉ &lt;a href=&#34;https://arxiv.org/abs/2103.10360&#34; target=&#34;_blank&#34;&gt;[GLM@ACL 22]&lt;/a&gt; &lt;a href=&#34;https://github.com/THUDM/GLM&#34; target=&#34;_blank&#34;&gt;[GitHub]&lt;/a&gt; ‚Ä¢ üìÉ &lt;a href=&#34;https://arxiv.org/abs/2210.02414&#34; target=&#34;_blank&#34;&gt;[GLM-130B@ICLR 23]&lt;/a&gt; &lt;a href=&#34;https://github.com/THUDM/GLM-130B&#34; target=&#34;_blank&#34;&gt;[GitHub]&lt;/a&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; üëã Âä†ÂÖ•Êàë‰ª¨ÁöÑ &lt;a href=&#34;https://join.slack.com/t/chatglm/shared_invite/zt-1udqapmrr-ocT1DS_mxWe6dDY8ahRWzg&#34; target=&#34;_blank&#34;&gt;Slack&lt;/a&gt; Âíå &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/resources/WECHAT.md&#34; target=&#34;_blank&#34;&gt;WeChat&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Read this in &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/README_EN.md&#34;&gt;English&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;‰ªãÁªç&lt;/h2&gt; &#xA;&lt;p&gt;ChatGLM&lt;strong&gt;2&lt;/strong&gt;-6B ÊòØÂºÄÊ∫ê‰∏≠Ëã±ÂèåËØ≠ÂØπËØùÊ®°Âûã &lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34;&gt;ChatGLM-6B&lt;/a&gt; ÁöÑÁ¨¨‰∫å‰ª£ÁâàÊú¨ÔºåÂú®‰øùÁïô‰∫ÜÂàù‰ª£Ê®°ÂûãÂØπËØùÊµÅÁïÖ„ÄÅÈÉ®ÁΩ≤Èó®ÊßõËæÉ‰ΩéÁ≠â‰ºóÂ§ö‰ºòÁßÄÁâπÊÄßÁöÑÂü∫Á°Ä‰πã‰∏äÔºåChatGLM&lt;strong&gt;2&lt;/strong&gt;-6B ÂºïÂÖ•‰∫ÜÂ¶Ç‰∏ãÊñ∞ÁâπÊÄßÔºö&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Êõ¥Âº∫Â§ßÁöÑÊÄßËÉΩ&lt;/strong&gt;ÔºöÂü∫‰∫é ChatGLM Âàù‰ª£Ê®°ÂûãÁöÑÂºÄÂèëÁªèÈ™åÔºåÊàë‰ª¨ÂÖ®Èù¢ÂçáÁ∫ß‰∫Ü ChatGLM2-6B ÁöÑÂü∫Â∫ßÊ®°Âûã„ÄÇChatGLM2-6B ‰ΩøÁî®‰∫Ü &lt;a href=&#34;https://github.com/THUDM/GLM&#34;&gt;GLM&lt;/a&gt; ÁöÑÊ∑∑ÂêàÁõÆÊ†áÂáΩÊï∞ÔºåÁªèËøá‰∫Ü 1.4T ‰∏≠Ëã±Ê†áËØÜÁ¨¶ÁöÑÈ¢ÑËÆ≠ÁªÉ‰∏é‰∫∫Á±ªÂÅèÂ•ΩÂØπÈΩêËÆ≠ÁªÉÔºå&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/#%E8%AF%84%E6%B5%8B%E7%BB%93%E6%9E%9C&#34;&gt;ËØÑÊµãÁªìÊûú&lt;/a&gt;ÊòæÁ§∫ÔºåÁõ∏ÊØî‰∫éÂàù‰ª£Ê®°ÂûãÔºåChatGLM2-6B Âú® MMLUÔºà+23%Ôºâ„ÄÅCEvalÔºà+33%Ôºâ„ÄÅGSM8KÔºà+571%Ôºâ „ÄÅBBHÔºà+60%ÔºâÁ≠âÊï∞ÊçÆÈõÜ‰∏äÁöÑÊÄßËÉΩÂèñÂæó‰∫ÜÂ§ßÂπÖÂ∫¶ÁöÑÊèêÂçáÔºåÂú®ÂêåÂ∞∫ÂØ∏ÂºÄÊ∫êÊ®°Âûã‰∏≠ÂÖ∑ÊúâËæÉÂº∫ÁöÑÁ´û‰∫âÂäõ„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Êõ¥ÈïøÁöÑ‰∏ä‰∏ãÊñá&lt;/strong&gt;ÔºöÂü∫‰∫é &lt;a href=&#34;https://github.com/HazyResearch/flash-attention&#34;&gt;FlashAttention&lt;/a&gt; ÊäÄÊúØÔºåÊàë‰ª¨Â∞ÜÂü∫Â∫ßÊ®°ÂûãÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶ÔºàContext LengthÔºâÁî± ChatGLM-6B ÁöÑ 2K Êâ©Â±ïÂà∞‰∫Ü 32KÔºåÂπ∂Âú®ÂØπËØùÈò∂ÊÆµ‰ΩøÁî® 8K ÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶ËÆ≠ÁªÉÔºåÂÖÅËÆ∏Êõ¥Â§öËΩÆÊ¨°ÁöÑÂØπËØù„ÄÇ‰ΩÜÂΩìÂâçÁâàÊú¨ÁöÑ ChatGLM2-6B ÂØπÂçïËΩÆË∂ÖÈïøÊñáÊ°£ÁöÑÁêÜËß£ËÉΩÂäõÊúâÈôêÔºåÊàë‰ª¨‰ºöÂú®ÂêéÁª≠Ëø≠‰ª£ÂçáÁ∫ß‰∏≠ÁùÄÈáçËøõË°å‰ºòÂåñ„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Êõ¥È´òÊïàÁöÑÊé®ÁêÜ&lt;/strong&gt;ÔºöÂü∫‰∫é &lt;a href=&#34;http://arxiv.org/abs/1911.02150&#34;&gt;Multi-Query Attention&lt;/a&gt; ÊäÄÊúØÔºåChatGLM2-6B ÊúâÊõ¥È´òÊïàÁöÑÊé®ÁêÜÈÄüÂ∫¶ÂíåÊõ¥‰ΩéÁöÑÊòæÂ≠òÂç†Áî®ÔºöÂú®ÂÆòÊñπÁöÑÊ®°ÂûãÂÆûÁé∞‰∏ãÔºåÊé®ÁêÜÈÄüÂ∫¶Áõ∏ÊØîÂàù‰ª£ÊèêÂçá‰∫Ü 42%ÔºåINT4 ÈáèÂåñ‰∏ãÔºå6G ÊòæÂ≠òÊîØÊåÅÁöÑÂØπËØùÈïøÂ∫¶Áî± 1K ÊèêÂçáÂà∞‰∫Ü 8K„ÄÇ&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Êõ¥ÂºÄÊîæÁöÑÂçèËÆÆ&lt;/strong&gt;ÔºöChatGLM2-6B ÊùÉÈáçÂØπÂ≠¶ÊúØÁ†îÁ©∂&lt;strong&gt;ÂÆåÂÖ®ÂºÄÊîæ&lt;/strong&gt;ÔºåÂú®Ëé∑ÂæóÂÆòÊñπÁöÑ‰π¶Èù¢ËÆ∏ÂèØÂêéÔºå‰∫¶&lt;strong&gt;ÂÖÅËÆ∏ÂïÜ‰∏ö‰ΩøÁî®&lt;/strong&gt;„ÄÇÂ¶ÇÊûúÊÇ®ÂèëÁé∞Êàë‰ª¨ÁöÑÂºÄÊ∫êÊ®°ÂûãÂØπÊÇ®ÁöÑ‰∏öÂä°ÊúâÁî®ÔºåÊàë‰ª¨Ê¨¢ËøéÊÇ®ÂØπ‰∏ã‰∏Ä‰ª£Ê®°Âûã ChatGLM3 Á†îÂèëÁöÑÊçêËµ†„ÄÇ&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;ChatGLM2-6B ÂºÄÊ∫êÊ®°ÂûãÊó®Âú®‰∏éÂºÄÊ∫êÁ§æÂå∫‰∏ÄËµ∑Êé®Âä®Â§ßÊ®°ÂûãÊäÄÊúØÂèëÂ±ïÔºåÊÅ≥ËØ∑ÂºÄÂèëËÄÖÂíåÂ§ßÂÆ∂ÈÅµÂÆà&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/MODEL_LICENSE&#34;&gt;ÂºÄÊ∫êÂçèËÆÆ&lt;/a&gt;ÔºåÂãøÂ∞ÜÂºÄÊ∫êÊ®°ÂûãÂíå‰ª£Á†ÅÂèäÂü∫‰∫éÂºÄÊ∫êÈ°πÁõÆ‰∫ßÁîüÁöÑË°çÁîüÁâ©Áî®‰∫é‰ªª‰ΩïÂèØËÉΩÁªôÂõΩÂÆ∂ÂíåÁ§æ‰ºöÂ∏¶Êù•Âç±ÂÆ≥ÁöÑÁî®ÈÄî‰ª•ÂèäÁî®‰∫é‰ªª‰ΩïÊú™ÁªèËøáÂÆâÂÖ®ËØÑ‰º∞ÂíåÂ§áÊ°àÁöÑÊúçÂä°„ÄÇ&lt;strong&gt;ÁõÆÂâçÔºåÊú¨È°πÁõÆÂõ¢ÈòüÊú™Âü∫‰∫é ChatGLM2-6B ÂºÄÂèë‰ªª‰ΩïÂ∫îÁî®ÔºåÂåÖÊã¨ÁΩëÈ°µÁ´Ø„ÄÅÂÆâÂçì„ÄÅËãπÊûú iOS Âèä Windows App Á≠âÂ∫îÁî®„ÄÇ&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Â∞ΩÁÆ°Ê®°ÂûãÂú®ËÆ≠ÁªÉÁöÑÂêÑ‰∏™Èò∂ÊÆµÈÉΩÂ∞ΩÂäõÁ°Æ‰øùÊï∞ÊçÆÁöÑÂêàËßÑÊÄßÂíåÂáÜÁ°ÆÊÄßÔºå‰ΩÜÁî±‰∫é ChatGLM2-6B Ê®°ÂûãËßÑÊ®°ËæÉÂ∞èÔºå‰∏îÊ®°ÂûãÂèóÊ¶ÇÁéáÈöèÊú∫ÊÄßÂõ†Á¥†ÂΩ±ÂìçÔºåÊó†Ê≥ï‰øùËØÅËæìÂá∫ÂÜÖÂÆπÁöÑÂáÜÁ°ÆÊÄßÔºå‰∏îÊ®°ÂûãÊòìË¢´ËØØÂØº„ÄÇ&lt;strong&gt;Êú¨È°πÁõÆ‰∏çÊâøÊãÖÂºÄÊ∫êÊ®°ÂûãÂíå‰ª£Á†ÅÂØºËá¥ÁöÑÊï∞ÊçÆÂÆâÂÖ®„ÄÅËàÜÊÉÖÈ£éÈô©ÊàñÂèëÁîü‰ªª‰ΩïÊ®°ÂûãË¢´ËØØÂØº„ÄÅÊª•Áî®„ÄÅ‰º†Êí≠„ÄÅ‰∏çÂΩìÂà©Áî®ËÄå‰∫ßÁîüÁöÑÈ£éÈô©ÂíåË¥£‰ªª„ÄÇ&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ËØÑÊµãÁªìÊûú&lt;/h2&gt; &#xA;&lt;p&gt;Êàë‰ª¨ÈÄâÂèñ‰∫ÜÈÉ®ÂàÜ‰∏≠Ëã±ÊñáÂÖ∏ÂûãÊï∞ÊçÆÈõÜËøõË°å‰∫ÜËØÑÊµãÔºå‰ª•‰∏ã‰∏∫ ChatGLM2-6B Ê®°ÂûãÂú® &lt;a href=&#34;https://github.com/hendrycks/test&#34;&gt;MMLU&lt;/a&gt; (Ëã±Êñá)„ÄÅ&lt;a href=&#34;https://cevalbenchmark.com/static/leaderboard.html&#34;&gt;C-Eval&lt;/a&gt;Ôºà‰∏≠ÊñáÔºâ„ÄÅ&lt;a href=&#34;https://github.com/openai/grade-school-math&#34;&gt;GSM8K&lt;/a&gt;ÔºàÊï∞Â≠¶Ôºâ„ÄÅ&lt;a href=&#34;https://github.com/suzgunmirac/BIG-Bench-Hard&#34;&gt;BBH&lt;/a&gt;ÔºàËã±ÊñáÔºâ ‰∏äÁöÑÊµãËØÑÁªìÊûú„ÄÇÂú® &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/evaluation/README.md&#34;&gt;evaluation&lt;/a&gt; ‰∏≠Êèê‰æõ‰∫ÜÂú® C-Eval ‰∏äËøõË°åÊµãËØÑÁöÑËÑöÊú¨„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;MMLU&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Average&lt;/th&gt; &#xA;   &lt;th&gt;STEM&lt;/th&gt; &#xA;   &lt;th&gt;Social Sciences&lt;/th&gt; &#xA;   &lt;th&gt;Humanities&lt;/th&gt; &#xA;   &lt;th&gt;Others&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM-6B&lt;/td&gt; &#xA;   &lt;td&gt;40.63&lt;/td&gt; &#xA;   &lt;td&gt;33.89&lt;/td&gt; &#xA;   &lt;td&gt;44.84&lt;/td&gt; &#xA;   &lt;td&gt;39.02&lt;/td&gt; &#xA;   &lt;td&gt;45.71&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B (base)&lt;/td&gt; &#xA;   &lt;td&gt;47.86&lt;/td&gt; &#xA;   &lt;td&gt;41.20&lt;/td&gt; &#xA;   &lt;td&gt;54.44&lt;/td&gt; &#xA;   &lt;td&gt;43.66&lt;/td&gt; &#xA;   &lt;td&gt;54.46&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B&lt;/td&gt; &#xA;   &lt;td&gt;45.46&lt;/td&gt; &#xA;   &lt;td&gt;40.06&lt;/td&gt; &#xA;   &lt;td&gt;51.61&lt;/td&gt; &#xA;   &lt;td&gt;41.23&lt;/td&gt; &#xA;   &lt;td&gt;51.24&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Chat Ê®°Âûã‰ΩøÁî® zero-shot CoT (Chain-of-Thought) ÁöÑÊñπÊ≥ïÊµãËØïÔºåBase Ê®°Âûã‰ΩøÁî® few-shot answer-only ÁöÑÊñπÊ≥ïÊµãËØï&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;C-Eval&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Average&lt;/th&gt; &#xA;   &lt;th&gt;STEM&lt;/th&gt; &#xA;   &lt;th&gt;Social Sciences&lt;/th&gt; &#xA;   &lt;th&gt;Humanities&lt;/th&gt; &#xA;   &lt;th&gt;Others&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM-6B&lt;/td&gt; &#xA;   &lt;td&gt;38.9&lt;/td&gt; &#xA;   &lt;td&gt;33.3&lt;/td&gt; &#xA;   &lt;td&gt;48.3&lt;/td&gt; &#xA;   &lt;td&gt;41.3&lt;/td&gt; &#xA;   &lt;td&gt;38.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B (base)&lt;/td&gt; &#xA;   &lt;td&gt;51.7&lt;/td&gt; &#xA;   &lt;td&gt;48.6&lt;/td&gt; &#xA;   &lt;td&gt;60.5&lt;/td&gt; &#xA;   &lt;td&gt;51.3&lt;/td&gt; &#xA;   &lt;td&gt;49.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B&lt;/td&gt; &#xA;   &lt;td&gt;50.1&lt;/td&gt; &#xA;   &lt;td&gt;46.4&lt;/td&gt; &#xA;   &lt;td&gt;60.4&lt;/td&gt; &#xA;   &lt;td&gt;50.6&lt;/td&gt; &#xA;   &lt;td&gt;46.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Chat Ê®°Âûã‰ΩøÁî® zero-shot CoT ÁöÑÊñπÊ≥ïÊµãËØïÔºåBase Ê®°Âûã‰ΩøÁî® few-shot answer only ÁöÑÊñπÊ≥ïÊµãËØï&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;GSM8K&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Accuracy&lt;/th&gt; &#xA;   &lt;th&gt;Accuracy (Chinese)*&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM-6B&lt;/td&gt; &#xA;   &lt;td&gt;4.82&lt;/td&gt; &#xA;   &lt;td&gt;5.85&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B (base)&lt;/td&gt; &#xA;   &lt;td&gt;32.37&lt;/td&gt; &#xA;   &lt;td&gt;28.95&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B&lt;/td&gt; &#xA;   &lt;td&gt;28.05&lt;/td&gt; &#xA;   &lt;td&gt;20.45&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ÊâÄÊúâÊ®°ÂûãÂùá‰ΩøÁî® few-shot CoT ÁöÑÊñπÊ≥ïÊµãËØïÔºåCoT prompt Êù•Ëá™ &lt;a href=&#34;http://arxiv.org/abs/2201.11903&#34;&gt;http://arxiv.org/abs/2201.11903&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;* Êàë‰ª¨‰ΩøÁî®ÁøªËØë API ÁøªËØë‰∫Ü GSM8K ‰∏≠ÁöÑ 500 ÈÅìÈ¢òÁõÆÂíå CoT prompt Âπ∂ËøõË°å‰∫Ü‰∫∫Â∑•Ê†°ÂØπ&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;BBH&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Accuracy&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM-6B&lt;/td&gt; &#xA;   &lt;td&gt;18.73&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B (base)&lt;/td&gt; &#xA;   &lt;td&gt;33.68&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B&lt;/td&gt; &#xA;   &lt;td&gt;30.00&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ÊâÄÊúâÊ®°ÂûãÂùá‰ΩøÁî® few-shot CoT ÁöÑÊñπÊ≥ïÊµãËØïÔºåCoT prompt Êù•Ëá™ &lt;a href=&#34;https://github.com/suzgunmirac/BIG-Bench-Hard/tree/main/cot-prompts&#34;&gt;https://github.com/suzgunmirac/BIG-Bench-Hard/tree/main/cot-prompts&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Êé®ÁêÜÊÄßËÉΩ&lt;/h2&gt; &#xA;&lt;p&gt;ChatGLM2-6B ‰ΩøÁî®‰∫Ü &lt;a href=&#34;http://arxiv.org/abs/1911.02150&#34;&gt;Multi-Query Attention&lt;/a&gt;ÔºåÊèêÈ´ò‰∫ÜÁîüÊàêÈÄüÂ∫¶„ÄÇÁîüÊàê 2000 ‰∏™Â≠óÁ¨¶ÁöÑÂπ≥ÂùáÈÄüÂ∫¶ÂØπÊØîÂ¶Ç‰∏ã&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Êé®ÁêÜÈÄüÂ∫¶ (Â≠óÁ¨¶/Áßí)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM-6B&lt;/td&gt; &#xA;   &lt;td&gt;31.49&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B&lt;/td&gt; &#xA;   &lt;td&gt;44.62&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;‰ΩøÁî®ÂÆòÊñπÂÆûÁé∞Ôºåbatch size = 1Ôºåmax length = 2048Ôºåbf16 Á≤æÂ∫¶ÔºåÊµãËØïÁ°¨‰ª∂‰∏∫ A100-SXM4-80GÔºåËΩØ‰ª∂ÁéØÂ¢É‰∏∫ PyTorch 2.0.1&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Multi-Query Attention ÂêåÊó∂‰πüÈôç‰Ωé‰∫ÜÁîüÊàêËøáÁ®ã‰∏≠ KV Cache ÁöÑÊòæÂ≠òÂç†Áî®ÔºåÊ≠§Â§ñÔºåChatGLM2-6B ÈááÁî® Causal Mask ËøõË°åÂØπËØùËÆ≠ÁªÉÔºåËøûÁª≠ÂØπËØùÊó∂ÂèØÂ§çÁî®ÂâçÈù¢ËΩÆÊ¨°ÁöÑ KV CacheÔºåËøõ‰∏ÄÊ≠•‰ºòÂåñ‰∫ÜÊòæÂ≠òÂç†Áî®„ÄÇÂõ†Ê≠§Ôºå‰ΩøÁî® 6GB ÊòæÂ≠òÁöÑÊòæÂç°ËøõË°å INT4 ÈáèÂåñÁöÑÊé®ÁêÜÊó∂ÔºåÂàù‰ª£ÁöÑ ChatGLM-6B Ê®°ÂûãÊúÄÂ§öËÉΩÂ§üÁîüÊàê 1119 ‰∏™Â≠óÁ¨¶Â∞±‰ºöÊèêÁ§∫ÊòæÂ≠òËÄóÂ∞ΩÔºåËÄå ChatGLM2-6B ËÉΩÂ§üÁîüÊàêËá≥Â∞ë 8192 ‰∏™Â≠óÁ¨¶„ÄÇ&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;ÈáèÂåñÁ≠âÁ∫ß&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;ÁºñÁ†Å 2048 ÈïøÂ∫¶ÁöÑÊúÄÂ∞èÊòæÂ≠ò&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;ÁîüÊàê 8192 ÈïøÂ∫¶ÁöÑÊúÄÂ∞èÊòæÂ≠ò&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FP16 / BF16&lt;/td&gt; &#xA;   &lt;td&gt;13.1 GB&lt;/td&gt; &#xA;   &lt;td&gt;12.8 GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;INT8&lt;/td&gt; &#xA;   &lt;td&gt;8.2 GB&lt;/td&gt; &#xA;   &lt;td&gt;8.1 GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;INT4&lt;/td&gt; &#xA;   &lt;td&gt;5.5 GB&lt;/td&gt; &#xA;   &lt;td&gt;5.1 GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ChatGLM2-6B Âà©Áî®‰∫Ü PyTorch 2.0 ÂºïÂÖ•ÁöÑ &lt;code&gt;torch.nn.functional.scaled_dot_product_attention&lt;/code&gt; ÂÆûÁé∞È´òÊïàÁöÑ Attention ËÆ°ÁÆóÔºåÂ¶ÇÊûú PyTorch ÁâàÊú¨ËæÉ‰ΩéÂàô‰ºö fallback Âà∞Êú¥Á¥†ÁöÑ Attention ÂÆûÁé∞ÔºåÂá∫Áé∞ÊòæÂ≠òÂç†Áî®È´ò‰∫é‰∏äË°®ÁöÑÊÉÖÂÜµ„ÄÇ&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Êàë‰ª¨‰πüÊµãËØï‰∫ÜÈáèÂåñÂØπÊ®°ÂûãÊÄßËÉΩÁöÑÂΩ±Âìç„ÄÇÁªìÊûúË°®ÊòéÔºåÈáèÂåñÂØπÊ®°ÂûãÊÄßËÉΩÁöÑÂΩ±ÂìçÂú®ÂèØÊé•ÂèóËåÉÂõ¥ÂÜÖ„ÄÇ&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ÈáèÂåñÁ≠âÁ∫ß&lt;/th&gt; &#xA;   &lt;th&gt;Accuracy (MMLU)&lt;/th&gt; &#xA;   &lt;th&gt;Accuracy (C-Eval dev)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BF16&lt;/td&gt; &#xA;   &lt;td&gt;45.47&lt;/td&gt; &#xA;   &lt;td&gt;53.57&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;INT4&lt;/td&gt; &#xA;   &lt;td&gt;43.13&lt;/td&gt; &#xA;   &lt;td&gt;50.30&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;ChatGLM2-6B Á§∫‰æã&lt;/h2&gt; &#xA;&lt;p&gt;Áõ∏ÊØî‰∫éÂàù‰ª£Ê®°ÂûãÔºåChatGLM2-6B Â§ö‰∏™Áª¥Â∫¶ÁöÑËÉΩÂäõÈÉΩÂèñÂæó‰∫ÜÊèêÂçáÔºå‰ª•‰∏ãÊòØ‰∏Ä‰∫õÂØπÊØîÁ§∫‰æã„ÄÇÊõ¥Â§ö ChatGLM2-6B ÁöÑÂèØËÉΩÔºåÁ≠âÂæÖ‰Ω†Êù•Êé¢Á¥¢ÂèëÁé∞ÔºÅ&lt;/p&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;Êï∞ÁêÜÈÄªËæë&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/resources/math.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;Áü•ËØÜÊé®ÁêÜ&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/resources/knowledge.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;ÈïøÊñáÊ°£ÁêÜËß£&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/resources/long-context.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;‰ΩøÁî®ÊñπÂºè&lt;/h2&gt; &#xA;&lt;h3&gt;ÁéØÂ¢ÉÂÆâË£Ö&lt;/h3&gt; &#xA;&lt;p&gt;È¶ñÂÖàÈúÄË¶Å‰∏ãËΩΩÊú¨‰ªìÂ∫ìÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/THUDM/ChatGLM2-6B&#xA;cd ChatGLM2-6B&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ÁÑ∂Âêé‰ΩøÁî® pip ÂÆâË£Ö‰æùËµñÔºö&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;ÔºåÂÖ∂‰∏≠ &lt;code&gt;transformers&lt;/code&gt; Â∫ìÁâàÊú¨Êé®Ëçê‰∏∫ &lt;code&gt;4.30.2&lt;/code&gt;Ôºå&lt;code&gt;torch&lt;/code&gt; Êé®Ëçê‰ΩøÁî® 2.0 ‰ª•‰∏äÁöÑÁâàÊú¨Ôºå‰ª•Ëé∑ÂæóÊúÄ‰Ω≥ÁöÑÊé®ÁêÜÊÄßËÉΩ„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;‰ª£Á†ÅË∞ÉÁî®&lt;/h3&gt; &#xA;&lt;p&gt;ÂèØ‰ª•ÈÄöËøáÂ¶Ç‰∏ã‰ª£Á†ÅË∞ÉÁî® ChatGLM2-6B Ê®°ÂûãÊù•ÁîüÊàêÂØπËØùÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from transformers import AutoTokenizer, AutoModel&#xA;&amp;gt;&amp;gt;&amp;gt; tokenizer = AutoTokenizer.from_pretrained(&#34;THUDM/chatglm2-6b&#34;, trust_remote_code=True)&#xA;&amp;gt;&amp;gt;&amp;gt; model = AutoModel.from_pretrained(&#34;THUDM/chatglm2-6b&#34;, trust_remote_code=True, device=&#39;cuda&#39;)&#xA;&amp;gt;&amp;gt;&amp;gt; model = model.eval()&#xA;&amp;gt;&amp;gt;&amp;gt; response, history = model.chat(tokenizer, &#34;‰Ω†Â•Ω&#34;, history=[])&#xA;&amp;gt;&amp;gt;&amp;gt; print(response)&#xA;‰Ω†Â•Ωüëã!ÊàëÊòØ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã ChatGLM2-6B,ÂæàÈ´òÂÖ¥ËßÅÂà∞‰Ω†,Ê¨¢ËøéÈóÆÊàë‰ªª‰ΩïÈóÆÈ¢ò„ÄÇ&#xA;&amp;gt;&amp;gt;&amp;gt; response, history = model.chat(tokenizer, &#34;Êôö‰∏äÁù°‰∏çÁùÄÂ∫îËØ•ÊÄé‰πàÂäû&#34;, history=history)&#xA;&amp;gt;&amp;gt;&amp;gt; print(response)&#xA;Êôö‰∏äÁù°‰∏çÁùÄÂèØËÉΩ‰ºöËÆ©‰Ω†ÊÑüÂà∞ÁÑ¶ËôëÊàñ‰∏çËàíÊúç,‰ΩÜ‰ª•‰∏ãÊòØ‰∏Ä‰∫õÂèØ‰ª•Â∏ÆÂä©‰Ω†ÂÖ•Áù°ÁöÑÊñπÊ≥ï:&#xA;&#xA;1. Âà∂ÂÆöËßÑÂæãÁöÑÁù°Áú†Êó∂Èó¥Ë°®:‰øùÊåÅËßÑÂæãÁöÑÁù°Áú†Êó∂Èó¥Ë°®ÂèØ‰ª•Â∏ÆÂä©‰Ω†Âª∫Á´ãÂÅ•Â∫∑ÁöÑÁù°Áú†‰π†ÊÉØ,‰Ωø‰Ω†Êõ¥ÂÆπÊòìÂÖ•Áù°„ÄÇÂ∞ΩÈáèÂú®ÊØèÂ§©ÁöÑÁõ∏ÂêåÊó∂Èó¥‰∏äÂ∫ä,Âπ∂Âú®Âêå‰∏ÄÊó∂Èó¥Ëµ∑Â∫ä„ÄÇ&#xA;2. ÂàõÈÄ†‰∏Ä‰∏™ËàíÈÄÇÁöÑÁù°Áú†ÁéØÂ¢É:Á°Æ‰øùÁù°Áú†ÁéØÂ¢ÉËàíÈÄÇ,ÂÆâÈùô,ÈªëÊöó‰∏îÊ∏©Â∫¶ÈÄÇÂÆú„ÄÇÂèØ‰ª•‰ΩøÁî®ËàíÈÄÇÁöÑÂ∫ä‰∏äÁî®ÂìÅ,Âπ∂‰øùÊåÅÊàøÈó¥ÈÄöÈ£é„ÄÇ&#xA;3. ÊîæÊùæË∫´ÂøÉ:Âú®Áù°ÂâçÂÅö‰∫õÊîæÊùæÁöÑÊ¥ªÂä®,‰æãÂ¶ÇÊ≥°‰∏™ÁÉ≠Ê∞¥Êæ°,Âê¨‰∫õËΩªÊüîÁöÑÈü≥‰πê,ÈòÖËØª‰∏Ä‰∫õÊúâË∂£ÁöÑ‰π¶Á±çÁ≠â,ÊúâÂä©‰∫éÁºìËß£Á¥ßÂº†ÂíåÁÑ¶Ëôë,‰Ωø‰Ω†Êõ¥ÂÆπÊòìÂÖ•Áù°„ÄÇ&#xA;4. ÈÅøÂÖçÈ•ÆÁî®Âê´ÊúâÂíñÂï°Âõ†ÁöÑÈ•ÆÊñô:ÂíñÂï°Âõ†ÊòØ‰∏ÄÁßçÂà∫ÊøÄÊÄßÁâ©Ë¥®,‰ºöÂΩ±Âìç‰Ω†ÁöÑÁù°Áú†Ë¥®Èáè„ÄÇÂ∞ΩÈáèÈÅøÂÖçÂú®Áù°ÂâçÈ•ÆÁî®Âê´ÊúâÂíñÂï°Âõ†ÁöÑÈ•ÆÊñô,‰æãÂ¶ÇÂíñÂï°,Ëå∂ÂíåÂèØ‰πê„ÄÇ&#xA;5. ÈÅøÂÖçÂú®Â∫ä‰∏äÂÅö‰∏éÁù°Áú†Êó†ÂÖ≥ÁöÑ‰∫ãÊÉÖ:Âú®Â∫ä‰∏äÂÅö‰∫õ‰∏éÁù°Áú†Êó†ÂÖ≥ÁöÑ‰∫ãÊÉÖ,‰æãÂ¶ÇÁúãÁîµÂΩ±,Áé©Ê∏∏ÊàèÊàñÂ∑•‰ΩúÁ≠â,ÂèØËÉΩ‰ºöÂπ≤Êâ∞‰Ω†ÁöÑÁù°Áú†„ÄÇ&#xA;6. Â∞ùËØïÂëºÂê∏ÊäÄÂ∑ß:Ê∑±ÂëºÂê∏ÊòØ‰∏ÄÁßçÊîæÊùæÊäÄÂ∑ß,ÂèØ‰ª•Â∏ÆÂä©‰Ω†ÁºìËß£Á¥ßÂº†ÂíåÁÑ¶Ëôë,‰Ωø‰Ω†Êõ¥ÂÆπÊòìÂÖ•Áù°„ÄÇËØïÁùÄÊÖ¢ÊÖ¢Âê∏Ê∞î,‰øùÊåÅÂá†ÁßíÈíü,ÁÑ∂ÂêéÁºìÊÖ¢ÂëºÊ∞î„ÄÇ&#xA;&#xA;Â¶ÇÊûúËøô‰∫õÊñπÊ≥ïÊó†Ê≥ïÂ∏ÆÂä©‰Ω†ÂÖ•Áù°,‰Ω†ÂèØ‰ª•ËÄÉËôëÂí®ËØ¢ÂåªÁîüÊàñÁù°Áú†‰∏ìÂÆ∂,ÂØªÊ±ÇËøõ‰∏ÄÊ≠•ÁöÑÂª∫ËÆÆ„ÄÇ&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;‰ªéÊú¨Âú∞Âä†ËΩΩÊ®°Âûã&lt;/h4&gt; &#xA;&lt;p&gt;‰ª•‰∏ä‰ª£Á†Å‰ºöÁî± &lt;code&gt;transformers&lt;/code&gt; Ëá™Âä®‰∏ãËΩΩÊ®°ÂûãÂÆûÁé∞ÂíåÂèÇÊï∞„ÄÇÂÆåÊï¥ÁöÑÊ®°ÂûãÂÆûÁé∞Âú® &lt;a href=&#34;https://huggingface.co/THUDM/chatglm2-6b&#34;&gt;Hugging Face Hub&lt;/a&gt;„ÄÇÂ¶ÇÊûú‰Ω†ÁöÑÁΩëÁªúÁéØÂ¢ÉËæÉÂ∑ÆÔºå‰∏ãËΩΩÊ®°ÂûãÂèÇÊï∞ÂèØËÉΩ‰ºöËä±Ë¥πËæÉÈïøÊó∂Èó¥ÁîöËá≥Â§±Ë¥•„ÄÇÊ≠§Êó∂ÂèØ‰ª•ÂÖàÂ∞ÜÊ®°Âûã‰∏ãËΩΩÂà∞Êú¨Âú∞ÔºåÁÑ∂Âêé‰ªéÊú¨Âú∞Âä†ËΩΩ„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;‰ªé Hugging Face Hub ‰∏ãËΩΩÊ®°ÂûãÈúÄË¶ÅÂÖà&lt;a href=&#34;https://docs.github.com/zh/repositories/working-with-files/managing-large-files/installing-git-large-file-storage&#34;&gt;ÂÆâË£ÖGit LFS&lt;/a&gt;ÔºåÁÑ∂ÂêéËøêË°å&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;git clone https://huggingface.co/THUDM/chatglm2-6b&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Â¶ÇÊûú‰Ω†‰ªé Hugging Face Hub ‰∏ä‰∏ãËΩΩ checkpoint ÁöÑÈÄüÂ∫¶ËæÉÊÖ¢ÔºåÂèØ‰ª•Âè™‰∏ãËΩΩÊ®°ÂûãÂÆûÁé∞&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/THUDM/chatglm2-6b&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ÁÑ∂Âêé‰ªé&lt;a href=&#34;https://cloud.tsinghua.edu.cn/d/674208019e314311ab5c/&#34;&gt;ËøôÈáå&lt;/a&gt;ÊâãÂä®‰∏ãËΩΩÊ®°ÂûãÂèÇÊï∞Êñá‰ª∂ÔºåÂπ∂Â∞Ü‰∏ãËΩΩÁöÑÊñá‰ª∂ÊõøÊç¢Âà∞Êú¨Âú∞ÁöÑ &lt;code&gt;chatglm2-6b&lt;/code&gt; ÁõÆÂΩï‰∏ã„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Â∞ÜÊ®°Âûã‰∏ãËΩΩÂà∞Êú¨Âú∞‰πãÂêéÔºåÂ∞Ü‰ª•‰∏ä‰ª£Á†Å‰∏≠ÁöÑ &lt;code&gt;THUDM/chatglm2-6b&lt;/code&gt; ÊõøÊç¢‰∏∫‰Ω†Êú¨Âú∞ÁöÑ &lt;code&gt;chatglm2-6b&lt;/code&gt; Êñá‰ª∂Â§πÁöÑË∑ØÂæÑÔºåÂç≥ÂèØ‰ªéÊú¨Âú∞Âä†ËΩΩÊ®°Âûã„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Ê®°ÂûãÁöÑÂÆûÁé∞‰ªçÁÑ∂Â§ÑÂú®ÂèòÂä®‰∏≠„ÄÇÂ¶ÇÊûúÂ∏åÊúõÂõ∫ÂÆö‰ΩøÁî®ÁöÑÊ®°ÂûãÂÆûÁé∞‰ª•‰øùËØÅÂÖºÂÆπÊÄßÔºåÂèØ‰ª•Âú® &lt;code&gt;from_pretrained&lt;/code&gt; ÁöÑË∞ÉÁî®‰∏≠Â¢ûÂä† &lt;code&gt;revision=&#34;v1.0&#34;&lt;/code&gt; ÂèÇÊï∞„ÄÇ&lt;code&gt;v1.0&lt;/code&gt; ÊòØÂΩìÂâçÊúÄÊñ∞ÁöÑÁâàÊú¨Âè∑ÔºåÂÆåÊï¥ÁöÑÁâàÊú¨ÂàóË°®ÂèÇËßÅ &lt;a href=&#34;https://huggingface.co/THUDM/chatglm2-6b#change-log&#34;&gt;Change Log&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;ÁΩëÈ°µÁâà Demo&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/resources/web-demo.gif&#34; alt=&#34;web-demo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;È¶ñÂÖàÂÆâË£Ö GradioÔºö&lt;code&gt;pip install gradio&lt;/code&gt;ÔºåÁÑ∂ÂêéËøêË°å‰ªìÂ∫ì‰∏≠ÁöÑ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/web_demo.py&#34;&gt;web_demo.py&lt;/a&gt;Ôºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python web_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Á®ãÂ∫è‰ºöËøêË°å‰∏Ä‰∏™ Web ServerÔºåÂπ∂ËæìÂá∫Âú∞ÂùÄ„ÄÇÂú®ÊµèËßàÂô®‰∏≠ÊâìÂºÄËæìÂá∫ÁöÑÂú∞ÂùÄÂç≥ÂèØ‰ΩøÁî®„ÄÇ&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ÈªòËÆ§‰ΩøÁî®‰∫Ü &lt;code&gt;share=False&lt;/code&gt; ÂêØÂä®Ôºå‰∏ç‰ºöÁîüÊàêÂÖ¨ÁΩëÈìæÊé•„ÄÇÂ¶ÇÊúâÈúÄË¶ÅÂÖ¨ÁΩëËÆøÈóÆÁöÑÈúÄÊ±ÇÔºåÂèØ‰ª•‰øÆÊîπ‰∏∫ &lt;code&gt;share=True&lt;/code&gt; ÂêØÂä®„ÄÇ&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;ÊÑüË∞¢ &lt;a href=&#34;https://github.com/AdamBear&#34;&gt;@AdamBear&lt;/a&gt; ÂÆûÁé∞‰∫ÜÂü∫‰∫é Streamlit ÁöÑÁΩëÈ°µÁâà Demo &lt;code&gt;web_demo2.py&lt;/code&gt;„ÄÇ‰ΩøÁî®Êó∂È¶ñÂÖàÈúÄË¶ÅÈ¢ùÂ§ñÂÆâË£Ö‰ª•‰∏ã‰æùËµñÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install streamlit streamlit-chat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ÁÑ∂ÂêéÈÄöËøá‰ª•‰∏ãÂëΩ‰ª§ËøêË°åÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;streamlit run web_demo2.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ÁªèÊµãËØïÔºåÂ¶ÇÊûúËæìÂÖ•ÁöÑ prompt ËæÉÈïøÁöÑËØùÔºå‰ΩøÁî®Âü∫‰∫é Streamlit ÁöÑÁΩëÈ°µÁâà Demo ‰ºöÊõ¥ÊµÅÁïÖ„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;ÂëΩ‰ª§Ë°å Demo&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/resources/cli-demo.png&#34; alt=&#34;cli-demo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;ËøêË°å‰ªìÂ∫ì‰∏≠ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/cli_demo.py&#34;&gt;cli_demo.py&lt;/a&gt;Ôºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python cli_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Á®ãÂ∫è‰ºöÂú®ÂëΩ‰ª§Ë°å‰∏≠ËøõË°å‰∫§‰∫íÂºèÁöÑÂØπËØùÔºåÂú®ÂëΩ‰ª§Ë°å‰∏≠ËæìÂÖ•ÊåáÁ§∫Âπ∂ÂõûËΩ¶Âç≥ÂèØÁîüÊàêÂõûÂ§çÔºåËæìÂÖ• &lt;code&gt;clear&lt;/code&gt; ÂèØ‰ª•Ê∏ÖÁ©∫ÂØπËØùÂéÜÂè≤ÔºåËæìÂÖ• &lt;code&gt;stop&lt;/code&gt; ÁªàÊ≠¢Á®ãÂ∫è„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;API ÈÉ®ÁΩ≤&lt;/h3&gt; &#xA;&lt;p&gt;È¶ñÂÖàÈúÄË¶ÅÂÆâË£ÖÈ¢ùÂ§ñÁöÑ‰æùËµñ &lt;code&gt;pip install fastapi uvicorn&lt;/code&gt;ÔºåÁÑ∂ÂêéËøêË°å‰ªìÂ∫ì‰∏≠ÁöÑ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/api.py&#34;&gt;api.py&lt;/a&gt;Ôºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python api.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ÈªòËÆ§ÈÉ®ÁΩ≤Âú®Êú¨Âú∞ÁöÑ 8000 Á´ØÂè£ÔºåÈÄöËøá POST ÊñπÊ≥ïËøõË°åË∞ÉÁî®&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -X POST &#34;http://127.0.0.1:8000&#34; \&#xA;     -H &#39;Content-Type: application/json&#39; \&#xA;     -d &#39;{&#34;prompt&#34;: &#34;‰Ω†Â•Ω&#34;, &#34;history&#34;: []}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ÂæóÂà∞ÁöÑËøîÂõûÂÄº‰∏∫&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;{&#xA;  &#34;response&#34;:&#34;‰Ω†Â•ΩüëãÔºÅÊàëÊòØ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã ChatGLM2-6BÔºåÂæàÈ´òÂÖ¥ËßÅÂà∞‰Ω†ÔºåÊ¨¢ËøéÈóÆÊàë‰ªª‰ΩïÈóÆÈ¢ò„ÄÇ&#34;,&#xA;  &#34;history&#34;:[[&#34;‰Ω†Â•Ω&#34;,&#34;‰Ω†Â•ΩüëãÔºÅÊàëÊòØ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã ChatGLM2-6BÔºåÂæàÈ´òÂÖ¥ËßÅÂà∞‰Ω†ÔºåÊ¨¢ËøéÈóÆÊàë‰ªª‰ΩïÈóÆÈ¢ò„ÄÇ&#34;]],&#xA;  &#34;status&#34;:200,&#xA;  &#34;time&#34;:&#34;2023-03-23 21:38:40&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ÊÑüË∞¢ &lt;a href=&#34;&#34;&gt;@hiyouga&lt;/a&gt; ÂÆûÁé∞‰∫Ü OpenAI Ê†ºÂºèÁöÑÊµÅÂºè API ÈÉ®ÁΩ≤ÔºåÂèØ‰ª•‰Ωú‰∏∫‰ªªÊÑèÂü∫‰∫é ChatGPT ÁöÑÂ∫îÁî®ÁöÑÂêéÁ´ØÔºåÊØîÂ¶Ç &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web&#34;&gt;ChatGPT-Next-Web&lt;/a&gt;„ÄÇÂèØ‰ª•ÈÄöËøáËøêË°å‰ªìÂ∫ì‰∏≠ÁöÑ&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/openai_api.py&#34;&gt;openai_api.py&lt;/a&gt; ËøõË°åÈÉ®ÁΩ≤Ôºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python openai_api.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ËøõË°å API Ë∞ÉÁî®ÁöÑÁ§∫‰æã‰ª£Á†Å‰∏∫&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import openai&#xA;if __name__ == &#34;__main__&#34;:&#xA;    openai.api_base = &#34;http://localhost:8000/v1&#34;&#xA;    openai.api_key = &#34;none&#34;&#xA;    for chunk in openai.ChatCompletion.create(&#xA;        model=&#34;chatglm2-6b&#34;,&#xA;        messages=[&#xA;            {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;‰Ω†Â•Ω&#34;}&#xA;        ],&#xA;        stream=True&#xA;    ):&#xA;        if hasattr(chunk.choices[0].delta, &#34;content&#34;):&#xA;            print(chunk.choices[0].delta.content, end=&#34;&#34;, flush=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;‰ΩéÊàêÊú¨ÈÉ®ÁΩ≤&lt;/h2&gt; &#xA;&lt;h3&gt;Ê®°ÂûãÈáèÂåñ&lt;/h3&gt; &#xA;&lt;p&gt;ÈªòËÆ§ÊÉÖÂÜµ‰∏ãÔºåÊ®°Âûã‰ª• FP16 Á≤æÂ∫¶Âä†ËΩΩÔºåËøêË°å‰∏äËø∞‰ª£Á†ÅÈúÄË¶ÅÂ§ßÊ¶Ç 13GB ÊòæÂ≠ò„ÄÇÂ¶ÇÊûú‰Ω†ÁöÑ GPU ÊòæÂ≠òÊúâÈôêÔºåÂèØ‰ª•Â∞ùËØï‰ª•ÈáèÂåñÊñπÂºèÂä†ËΩΩÊ®°ÂûãÔºå‰ΩøÁî®ÊñπÊ≥ïÂ¶Ç‰∏ãÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# ÊåâÈúÄ‰øÆÊîπÔºåÁõÆÂâçÂè™ÊîØÊåÅ 4/8 bit ÈáèÂåñ&#xA;model = AutoModel.from_pretrained(&#34;THUDM/chatglm2-6b&#34;, trust_remote_code=True).quantize(8).cuda()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Ê®°ÂûãÈáèÂåñ‰ºöÂ∏¶Êù•‰∏ÄÂÆöÁöÑÊÄßËÉΩÊçüÂ§±ÔºåÁªèËøáÊµãËØïÔºåChatGLM2-6B Âú® 4-bit ÈáèÂåñ‰∏ã‰ªçÁÑ∂ËÉΩÂ§üËøõË°åËá™ÁÑ∂ÊµÅÁïÖÁöÑÁîüÊàê„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;Â¶ÇÊûú‰Ω†ÁöÑÂÜÖÂ≠ò‰∏çË∂≥ÔºåÂèØ‰ª•Áõ¥Êé•Âä†ËΩΩÈáèÂåñÂêéÁöÑÊ®°ÂûãÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModel.from_pretrained(&#34;THUDM/chatglm2-6b-int4&#34;,trust_remote_code=True).cuda()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- ÈáèÂåñÊ®°ÂûãÁöÑÂèÇÊï∞Êñá‰ª∂‰πüÂèØ‰ª•‰ªé[ËøôÈáå](https://cloud.tsinghua.edu.cn/d/674208019e314311ab5c/)ÊâãÂä®‰∏ãËΩΩ„ÄÇ --&gt; &#xA;&lt;h3&gt;CPU ÈÉ®ÁΩ≤&lt;/h3&gt; &#xA;&lt;p&gt;Â¶ÇÊûú‰Ω†Ê≤°Êúâ GPU Á°¨‰ª∂ÁöÑËØùÔºå‰πüÂèØ‰ª•Âú® CPU ‰∏äËøõË°åÊé®ÁêÜÔºå‰ΩÜÊòØÊé®ÁêÜÈÄüÂ∫¶‰ºöÊõ¥ÊÖ¢„ÄÇ‰ΩøÁî®ÊñπÊ≥ïÂ¶Ç‰∏ãÔºàÈúÄË¶ÅÂ§ßÊ¶Ç 32GB ÂÜÖÂ≠òÔºâ&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModel.from_pretrained(&#34;THUDM/chatglm2-6b&#34;, trust_remote_code=True).float()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Â¶ÇÊûú‰Ω†ÁöÑÂÜÖÂ≠ò‰∏çË∂≥ÁöÑËØùÔºå‰πüÂèØ‰ª•‰ΩøÁî®ÈáèÂåñÂêéÁöÑÊ®°Âûã&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModel.from_pretrained(&#34;THUDM/chatglm2-6b-int4&#34;,trust_remote_code=True).float()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Âú® cpu ‰∏äËøêË°åÈáèÂåñÂêéÁöÑÊ®°ÂûãÈúÄË¶ÅÂÆâË£Ö &lt;code&gt;gcc&lt;/code&gt; ‰∏é &lt;code&gt;openmp&lt;/code&gt;„ÄÇÂ§öÊï∞ Linux ÂèëË°åÁâàÈªòËÆ§Â∑≤ÂÆâË£Ö„ÄÇÂØπ‰∫é Windows ÔºåÂèØÂú®ÂÆâË£Ö &lt;a href=&#34;https://jmeubank.github.io/tdm-gcc/&#34;&gt;TDM-GCC&lt;/a&gt; Êó∂ÂãæÈÄâ &lt;code&gt;openmp&lt;/code&gt;„ÄÇ Windows ÊµãËØïÁéØÂ¢É &lt;code&gt;gcc&lt;/code&gt; ÁâàÊú¨‰∏∫ &lt;code&gt;TDM-GCC 10.3.0&lt;/code&gt;Ôºå Linux ‰∏∫ &lt;code&gt;gcc 11.3.0&lt;/code&gt;„ÄÇÂú® MacOS ‰∏äËØ∑ÂèÇËÄÉ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/FAQ.md#q1&#34;&gt;Q1&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;Mac ÈÉ®ÁΩ≤&lt;/h3&gt; &#xA;&lt;p&gt;ÂØπ‰∫éÊê≠ËΩΩ‰∫Ü Apple Silicon ÊàñËÄÖ AMD GPU ÁöÑ MacÔºåÂèØ‰ª•‰ΩøÁî® MPS ÂêéÁ´ØÊù•Âú® GPU ‰∏äËøêË°å ChatGLM2-6B„ÄÇÈúÄË¶ÅÂèÇËÄÉ Apple ÁöÑ &lt;a href=&#34;https://developer.apple.com/metal/pytorch&#34;&gt;ÂÆòÊñπËØ¥Êòé&lt;/a&gt; ÂÆâË£Ö PyTorch-NightlyÔºàÊ≠£Á°ÆÁöÑÁâàÊú¨Âè∑Â∫îËØ•ÊòØ2.x.x.dev2023xxxxÔºåËÄå‰∏çÊòØ 2.x.xÔºâ„ÄÇ&lt;/p&gt; &#xA;&lt;p&gt;ÁõÆÂâçÂú® MacOS ‰∏äÂè™ÊîØÊåÅ&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/README.md#%E4%BB%8E%E6%9C%AC%E5%9C%B0%E5%8A%A0%E8%BD%BD%E6%A8%A1%E5%9E%8B&#34;&gt;‰ªéÊú¨Âú∞Âä†ËΩΩÊ®°Âûã&lt;/a&gt;„ÄÇÂ∞Ü‰ª£Á†Å‰∏≠ÁöÑÊ®°ÂûãÂä†ËΩΩÊîπ‰∏∫‰ªéÊú¨Âú∞Âä†ËΩΩÔºåÂπ∂‰ΩøÁî® mps ÂêéÁ´ØÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModel.from_pretrained(&#34;your local path&#34;, trust_remote_code=True).to(&#39;mps&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Âä†ËΩΩÂçäÁ≤æÂ∫¶ÁöÑ ChatGLM2-6B Ê®°ÂûãÈúÄË¶ÅÂ§ßÊ¶Ç 13GB ÂÜÖÂ≠ò„ÄÇÂÜÖÂ≠òËæÉÂ∞èÁöÑÊú∫Âô®ÔºàÊØîÂ¶Ç 16GB ÂÜÖÂ≠òÁöÑ MacBook ProÔºâÔºåÂú®Á©∫‰ΩôÂÜÖÂ≠ò‰∏çË∂≥ÁöÑÊÉÖÂÜµ‰∏ã‰ºö‰ΩøÁî®Á°¨Áõò‰∏äÁöÑËôöÊãüÂÜÖÂ≠òÔºåÂØºËá¥Êé®ÁêÜÈÄüÂ∫¶‰∏•ÈáçÂèòÊÖ¢„ÄÇ Ê≠§Êó∂ÂèØ‰ª•‰ΩøÁî®ÈáèÂåñÂêéÁöÑÊ®°Âûã chatglm2-6b-int4„ÄÇÂõ†‰∏∫ GPU ‰∏äÈáèÂåñÁöÑ kernel ÊòØ‰ΩøÁî® CUDA ÁºñÂÜôÁöÑÔºåÂõ†Ê≠§Êó†Ê≥ïÂú® MacOS ‰∏ä‰ΩøÁî®ÔºåÂè™ËÉΩ‰ΩøÁî® CPU ËøõË°åÊé®ÁêÜ„ÄÇ ‰∏∫‰∫ÜÂÖÖÂàÜ‰ΩøÁî® CPU Âπ∂Ë°åÔºåËøòÈúÄË¶Å&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/FAQ.md#q1&#34;&gt;ÂçïÁã¨ÂÆâË£Ö OpenMP&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h3&gt;Â§öÂç°ÈÉ®ÁΩ≤&lt;/h3&gt; &#xA;&lt;p&gt;Â¶ÇÊûú‰Ω†ÊúâÂ§öÂº† GPUÔºå‰ΩÜÊòØÊØèÂº† GPU ÁöÑÊòæÂ≠òÂ§ßÂ∞èÈÉΩ‰∏çË∂≥‰ª•ÂÆπÁ∫≥ÂÆåÊï¥ÁöÑÊ®°ÂûãÔºåÈÇ£‰πàÂèØ‰ª•Â∞ÜÊ®°ÂûãÂàáÂàÜÂú®Â§öÂº†GPU‰∏ä„ÄÇÈ¶ñÂÖàÂÆâË£Ö accelerate: &lt;code&gt;pip install accelerate&lt;/code&gt;ÔºåÁÑ∂ÂêéÈÄöËøáÂ¶Ç‰∏ãÊñπÊ≥ïÂä†ËΩΩÊ®°ÂûãÔºö&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from utils import load_model_on_gpus&#xA;model = load_model_on_gpus(&#34;THUDM/chatglm2-6b&#34;, num_gpus=2)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Âç≥ÂèØÂ∞ÜÊ®°ÂûãÈÉ®ÁΩ≤Âà∞‰∏§Âº† GPU ‰∏äËøõË°åÊé®ÁêÜ„ÄÇ‰Ω†ÂèØ‰ª•Â∞Ü &lt;code&gt;num_gpus&lt;/code&gt; Êîπ‰∏∫‰Ω†Â∏åÊúõ‰ΩøÁî®ÁöÑ GPU Êï∞„ÄÇÈªòËÆ§ÊòØÂùáÂåÄÂàáÂàÜÁöÑÔºå‰Ω†‰πüÂèØ‰ª•‰º†ÂÖ• &lt;code&gt;device_map&lt;/code&gt; ÂèÇÊï∞Êù•Ëá™Â∑±ÊåáÂÆö„ÄÇ&lt;/p&gt; &#xA;&lt;h2&gt;ÂçèËÆÆ&lt;/h2&gt; &#xA;&lt;p&gt;Êú¨‰ªìÂ∫ìÁöÑ‰ª£Á†Å‰æùÁÖß &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache-2.0&lt;/a&gt; ÂçèËÆÆÂºÄÊ∫êÔºåChatGLM2-6B Ê®°ÂûãÁöÑÊùÉÈáçÁöÑ‰ΩøÁî®ÂàôÈúÄË¶ÅÈÅµÂæ™ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/MODEL_LICENSE&#34;&gt;Model License&lt;/a&gt;„ÄÇChatGLM2-6B ÊùÉÈáçÂØπÂ≠¶ÊúØÁ†îÁ©∂&lt;strong&gt;ÂÆåÂÖ®ÂºÄÊîæ&lt;/strong&gt;ÔºåÂú®Ëé∑ÂæóÂÆòÊñπÁöÑ‰π¶Èù¢ËÆ∏ÂèØÂêéÔºå‰∫¶&lt;strong&gt;ÂÖÅËÆ∏ÂïÜ‰∏ö‰ΩøÁî®&lt;/strong&gt;„ÄÇÂ¶ÇÊûúÊÇ®ÂèëÁé∞Êàë‰ª¨ÁöÑÂºÄÊ∫êÊ®°ÂûãÂØπÊÇ®ÁöÑ‰∏öÂä°ÊúâÁî®ÔºåÊàë‰ª¨Ê¨¢ËøéÊÇ®ÂØπ‰∏ã‰∏Ä‰ª£Ê®°Âûã ChatGLM3 Á†îÂèëÁöÑÊçêËµ†„ÄÇÁî≥ËØ∑ÂïÜÁî®ËÆ∏ÂèØ‰∏éÊçêËµ†ËØ∑ËÅîÁ≥ª &lt;a href=&#34;mailto:yiwen.xu@zhipuai.cn&#34;&gt;yiwen.xu@zhipuai.cn&lt;/a&gt;„ÄÇ&lt;/p&gt; &#xA;&lt;h2&gt;ÂºïÁî®&lt;/h2&gt; &#xA;&lt;p&gt;Â¶ÇÊûú‰Ω†ËßâÂæóÊàë‰ª¨ÁöÑÂ∑•‰ΩúÊúâÂ∏ÆÂä©ÁöÑËØùÔºåËØ∑ËÄÉËôëÂºïÁî®‰∏ãÂàóËÆ∫ÊñáÔºåChatGLM2-6B ÁöÑËÆ∫Êñá‰ºöÂú®ËøëÊúüÂÖ¨Â∏ÉÔºåÊï¨ËØ∑ÊúüÂæÖÔΩû&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{zeng2022glm,&#xA;  title={Glm-130b: An open bilingual pre-trained model},&#xA;  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},&#xA;  journal={arXiv preprint arXiv:2210.02414},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{du2022glm,&#xA;  title={GLM: General Language Model Pretraining with Autoregressive Blank Infilling},&#xA;  author={Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},&#xA;  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},&#xA;  pages={320--335},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>