<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-06-09T01:28:57Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>huggingface/lerobot</title>
    <updated>2024-06-09T01:28:57Z</updated>
    <id>tag:github.com,2024-06-09:/huggingface/lerobot</id>
    <link href="https://github.com/huggingface/lerobot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ğŸ¤— LeRobot: End-to-end Learning for Real-World Robotics in Pytorch&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;media/lerobot-logo-thumbnail.png&#34;&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;media/lerobot-logo-thumbnail.png&#34;&gt; &#xA;  &lt;img alt=&#34;LeRobot, Hugging Face Robotics Library&#34; src=&#34;https://raw.githubusercontent.com/huggingface/lerobot/main/media/lerobot-logo-thumbnail.png&#34; style=&#34;max-width: 100%;&#34;&gt; &#xA; &lt;/picture&gt; &lt;br&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/huggingface/lerobot/actions/workflows/nightly-tests.yml?query=branch%3Amain&#34;&gt;&lt;img src=&#34;https://github.com/huggingface/lerobot/actions/workflows/nightly-tests.yml/badge.svg?branch=main&#34; alt=&#34;Tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/huggingface/lerobot&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/huggingface/lerobot/branch/main/graph/badge.svg?token=TODO&#34; alt=&#34;Coverage&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/lerobot&#34; alt=&#34;Python versions&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/huggingface/lerobot/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/lerobot/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/status/lerobot&#34; alt=&#34;Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/lerobot/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/lerobot&#34; alt=&#34;Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/huggingface/lerobot/tree/main/examples&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Examples-green.svg?sanitize=true&#34; alt=&#34;Examples&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/huggingface/lerobot/raw/main/CODE_OF_CONDUCT.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Contributor%20Covenant-v2.1%20adopted-ff69b4.svg?sanitize=true&#34; alt=&#34;Contributor Covenant&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/s3KuuzsPFb&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/C5P34WJ68S?style=flat&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt; &lt;p&gt;State-of-the-art Machine Learning for real-world robotics&lt;/p&gt; &lt;/h3&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;ğŸ¤— LeRobot aims to provide models, datasets, and tools for real-world robotics in PyTorch. The goal is to lower the barrier to entry to robotics so that everyone can contribute and benefit from sharing datasets and pretrained models.&lt;/p&gt; &#xA;&lt;p&gt;ğŸ¤— LeRobot contains state-of-the-art approaches that have been shown to transfer to the real-world with a focus on imitation learning and reinforcement learning.&lt;/p&gt; &#xA;&lt;p&gt;ğŸ¤— LeRobot already provides a set of pretrained models, datasets with human collected demonstrations, and simulation environments to get started without assembling a robot. In the coming weeks, the plan is to add more and more support for real-world robotics on the most affordable and capable robots out there.&lt;/p&gt; &#xA;&lt;p&gt;ğŸ¤— LeRobot hosts pretrained models and datasets on this Hugging Face community page: &lt;a href=&#34;https://huggingface.co/lerobot&#34;&gt;huggingface.co/lerobot&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Examples of pretrained models on simulation environments&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;http://remicadene.com/assets/gif/aloha_act.gif&#34; width=&#34;100%&#34; alt=&#34;ACT policy on ALOHA env&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;http://remicadene.com/assets/gif/simxarm_tdmpc.gif&#34; width=&#34;100%&#34; alt=&#34;TDMPC policy on SimXArm env&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;http://remicadene.com/assets/gif/pusht_diffusion.gif&#34; width=&#34;100%&#34; alt=&#34;Diffusion policy on PushT env&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ACT policy on ALOHA env&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;TDMPC policy on SimXArm env&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Diffusion policy on PushT env&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Acknowledgment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Thanks to Tony Zaho, Zipeng Fu and colleagues for open sourcing ACT policy, ALOHA environments and datasets. Ours are adapted from &lt;a href=&#34;https://tonyzhaozh.github.io/aloha&#34;&gt;ALOHA&lt;/a&gt; and &lt;a href=&#34;https://mobile-aloha.github.io&#34;&gt;Mobile ALOHA&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Thanks to Cheng Chi, Zhenjia Xu and colleagues for open sourcing Diffusion policy, Pusht environment and datasets, as well as UMI datasets. Ours are adapted from &lt;a href=&#34;https://diffusion-policy.cs.columbia.edu&#34;&gt;Diffusion Policy&lt;/a&gt; and &lt;a href=&#34;https://umi-gripper.github.io&#34;&gt;UMI Gripper&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Thanks to Nicklas Hansen, Yunhai Feng and colleagues for open sourcing TDMPC policy, Simxarm environments and datasets. Ours are adapted from &lt;a href=&#34;https://github.com/nicklashansen/tdmpc&#34;&gt;TDMPC&lt;/a&gt; and &lt;a href=&#34;https://www.yunhaifeng.com/FOWM&#34;&gt;FOWM&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Thanks to Antonio Loquercio and Ashish Kumar for their early support.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Download our source code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/huggingface/lerobot.git &amp;amp;&amp;amp; cd lerobot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create a virtual environment with Python 3.10 and activate it, e.g. with &lt;a href=&#34;https://docs.anaconda.com/free/miniconda/index.html&#34;&gt;&lt;code&gt;miniconda&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -y -n lerobot python=3.10 &amp;amp;&amp;amp; conda activate lerobot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install ğŸ¤— LeRobot:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Depending on your platform, If you encounter any build errors during this step you may need to install &lt;code&gt;cmake&lt;/code&gt; and &lt;code&gt;build-essential&lt;/code&gt; for building some of our dependencies. On linux: &lt;code&gt;sudo apt-get install cmake build-essential&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;For simulations, ğŸ¤— LeRobot comes with gymnasium environments that can be installed as extras:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/gym-aloha&#34;&gt;aloha&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/gym-xarm&#34;&gt;xarm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/gym-pusht&#34;&gt;pusht&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For instance, to install ğŸ¤— LeRobot with aloha and pusht, use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install &#34;.[aloha, pusht]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To use &lt;a href=&#34;https://docs.wandb.ai/quickstart&#34;&gt;Weights and Biases&lt;/a&gt; for experiment tracking, log in with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wandb login&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;(note: you will also need to enable WandB in the configuration. See below.)&lt;/p&gt; &#xA;&lt;h2&gt;Walkthrough&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;.&#xA;â”œâ”€â”€ examples             # contains demonstration examples, start here to learn about LeRobot&#xA;|   â””â”€â”€ advanced         # contains even more examples for those who have mastered the basics&#xA;â”œâ”€â”€ lerobot&#xA;|   â”œâ”€â”€ configs          # contains hydra yaml files with all options that you can override in the command line&#xA;|   |   â”œâ”€â”€ default.yaml   # selected by default, it loads pusht environment and diffusion policy&#xA;|   |   â”œâ”€â”€ env            # various sim environments and their datasets: aloha.yaml, pusht.yaml, xarm.yaml&#xA;|   |   â””â”€â”€ policy         # various policies: act.yaml, diffusion.yaml, tdmpc.yaml&#xA;|   â”œâ”€â”€ common           # contains classes and utilities&#xA;|   |   â”œâ”€â”€ datasets       # various datasets of human demonstrations: aloha, pusht, xarm&#xA;|   |   â”œâ”€â”€ envs           # various sim environments: aloha, pusht, xarm&#xA;|   |   â”œâ”€â”€ policies       # various policies: act, diffusion, tdmpc&#xA;|   |   â””â”€â”€ utils          # various utilities&#xA;|   â””â”€â”€ scripts          # contains functions to execute via command line&#xA;|       â”œâ”€â”€ eval.py                 # load policy and evaluate it on an environment&#xA;|       â”œâ”€â”€ train.py                # train a policy via imitation learning and/or reinforcement learning&#xA;|       â”œâ”€â”€ push_dataset_to_hub.py  # convert your dataset into LeRobot dataset format and upload it to the Hugging Face hub&#xA;|       â””â”€â”€ visualize_dataset.py    # load a dataset and render its demonstrations&#xA;â”œâ”€â”€ outputs               # contains results of scripts execution: logs, videos, model checkpoints&#xA;â””â”€â”€ tests                 # contains pytest utilities for continuous integration&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Visualize datasets&lt;/h3&gt; &#xA;&lt;p&gt;Check out &lt;a href=&#34;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/1_load_lerobot_dataset.py&#34;&gt;example 1&lt;/a&gt; that illustrates how to use our dataset class which automatically download data from the Hugging Face hub.&lt;/p&gt; &#xA;&lt;p&gt;You can also locally visualize episodes from a dataset by executing our script from the command line:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python lerobot/scripts/visualize_dataset.py \&#xA;    --repo-id lerobot/pusht \&#xA;    --episode-index 0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It will open &lt;code&gt;rerun.io&lt;/code&gt; and display the camera streams, robot states and actions, like this:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github-production-user-asset-6210df.s3.amazonaws.com/4681518/328035972-fd46b787-b532-47e2-bb6f-fd536a55a7ed.mov?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240505%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20240505T172924Z&amp;amp;X-Amz-Expires=300&amp;amp;X-Amz-Signature=d680b26c532eeaf80740f08af3320d22ad0b8a4e4da1bcc4f33142c15b509eda&amp;amp;X-Amz-SignedHeaders=host&amp;amp;actor_id=24889239&amp;amp;key_id=0&amp;amp;repo_id=748713144&#34;&gt;https://github-production-user-asset-6210df.s3.amazonaws.com/4681518/328035972-fd46b787-b532-47e2-bb6f-fd536a55a7ed.mov?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240505%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20240505T172924Z&amp;amp;X-Amz-Expires=300&amp;amp;X-Amz-Signature=d680b26c532eeaf80740f08af3320d22ad0b8a4e4da1bcc4f33142c15b509eda&amp;amp;X-Amz-SignedHeaders=host&amp;amp;actor_id=24889239&amp;amp;key_id=0&amp;amp;repo_id=748713144&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Our script can also visualize datasets stored on a distant server. See &lt;code&gt;python lerobot/scripts/visualize_dataset.py --help&lt;/code&gt; for more instructions.&lt;/p&gt; &#xA;&lt;h3&gt;Evaluate a pretrained policy&lt;/h3&gt; &#xA;&lt;p&gt;Check out &lt;a href=&#34;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/2_evaluate_pretrained_policy.py&#34;&gt;example 2&lt;/a&gt; that illustrates how to download a pretrained policy from Hugging Face hub, and run an evaluation on its corresponding environment.&lt;/p&gt; &#xA;&lt;p&gt;We also provide a more capable script to parallelize the evaluation over multiple environments during the same rollout. Here is an example with a pretrained model hosted on &lt;a href=&#34;https://huggingface.co/lerobot/diffusion_pusht&#34;&gt;lerobot/diffusion_pusht&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python lerobot/scripts/eval.py \&#xA;    -p lerobot/diffusion_pusht \&#xA;    eval.n_episodes=10 \&#xA;    eval.batch_size=10&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: After training your own policy, you can re-evaluate the checkpoints with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python lerobot/scripts/eval.py -p {OUTPUT_DIR}/checkpoints/last/pretrained_model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;code&gt;python lerobot/scripts/eval.py --help&lt;/code&gt; for more instructions.&lt;/p&gt; &#xA;&lt;h3&gt;Train your own policy&lt;/h3&gt; &#xA;&lt;p&gt;Check out &lt;a href=&#34;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/3_train_policy.py&#34;&gt;example 3&lt;/a&gt; that illustrates how to train a model using our core library in python, and &lt;a href=&#34;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/4_train_policy_with_script.md&#34;&gt;example 4&lt;/a&gt; that shows how to use our training script from command line.&lt;/p&gt; &#xA;&lt;p&gt;In general, you can use our training script to easily train any policy. Here is an example of training the ACT policy on trajectories collected by humans on the Aloha simulation environment for the insertion task:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python lerobot/scripts/train.py \&#xA;    policy=act \&#xA;    env=aloha \&#xA;    env.task=AlohaInsertion-v0 \&#xA;    dataset_repo_id=lerobot/aloha_sim_insertion_human \&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The experiment directory is automatically generated and will show up in yellow in your terminal. It looks like &lt;code&gt;outputs/train/2024-05-05/20-21-12_aloha_act_default&lt;/code&gt;. You can manually specify an experiment directory by adding this argument to the &lt;code&gt;train.py&lt;/code&gt; python command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    hydra.run.dir=your/new/experiment/dir&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the experiment directory there will be a folder called &lt;code&gt;checkpoints&lt;/code&gt; which will have the following structure:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;checkpoints&#xA;â”œâ”€â”€ 000250  # checkpoint_dir for training step 250&#xA;â”‚   â”œâ”€â”€ pretrained_model  # Hugging Face pretrained model dir&#xA;â”‚   â”‚   â”œâ”€â”€ config.json  # Hugging Face pretrained model config&#xA;â”‚   â”‚   â”œâ”€â”€ config.yaml  # consolidated Hydra config&#xA;â”‚   â”‚   â”œâ”€â”€ model.safetensors  # model weights&#xA;â”‚   â”‚   â””â”€â”€ README.md  # Hugging Face model card&#xA;â”‚   â””â”€â”€ training_state.pth  # optimizer/scheduler/rng state and training step&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To use wandb for logging training and evaluation curves, make sure you&#39;ve run &lt;code&gt;wandb login&lt;/code&gt; as a one-time setup step. Then, when running the training command above, enable WandB in the configuration by adding:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    wandb.enable=true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A link to the wandb logs for the run will also show up in yellow in your terminal. Here is an example of what they look like in your browser:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/huggingface/lerobot/main/media/wandb.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Note: For efficiency, during training every checkpoint is evaluated on a low number of episodes. You may use &lt;code&gt;eval.n_episodes=500&lt;/code&gt; to evaluate on more episodes than the default. Or, after training, you may want to re-evaluate your best checkpoints on more episodes or change the evaluation settings. See &lt;code&gt;python lerobot/scripts/eval.py --help&lt;/code&gt; for more instructions.&lt;/p&gt; &#xA;&lt;h4&gt;Reproduce state-of-the-art (SOTA)&lt;/h4&gt; &#xA;&lt;p&gt;We have organized our configuration files (found under &lt;a href=&#34;https://raw.githubusercontent.com/huggingface/lerobot/main/lerobot/configs&#34;&gt;&lt;code&gt;lerobot/configs&lt;/code&gt;&lt;/a&gt;) such that they reproduce SOTA results from a given model variant in their respective original works. Simply running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python lerobot/scripts/train.py policy=diffusion env=pusht&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;reproduces SOTA results for Diffusion Policy on the PushT task.&lt;/p&gt; &#xA;&lt;p&gt;Pretrained policies, along with reproduction details, can be found under the &#34;Models&#34; section of &lt;a href=&#34;https://huggingface.co/lerobot&#34;&gt;https://huggingface.co/lerobot&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contribute&lt;/h2&gt; &#xA;&lt;p&gt;If you would like to contribute to ğŸ¤— LeRobot, please check out our &lt;a href=&#34;https://github.com/huggingface/lerobot/raw/main/CONTRIBUTING.md&#34;&gt;contribution guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Add a new dataset&lt;/h3&gt; &#xA;&lt;p&gt;To add a dataset to the hub, you need to login using a write-access token, which can be generated from the &lt;a href=&#34;https://huggingface.co/settings/tokens&#34;&gt;Hugging Face settings&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;huggingface-cli login --token ${HUGGINGFACE_TOKEN} --add-to-git-credential&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then move your dataset folder in &lt;code&gt;data&lt;/code&gt; directory (e.g. &lt;code&gt;data/aloha_static_pingpong_test&lt;/code&gt;), and push your dataset to the hub with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python lerobot/scripts/push_dataset_to_hub.py \&#xA;--data-dir data \&#xA;--dataset-id aloha_static_pingpong_test \&#xA;--raw-format aloha_hdf5 \&#xA;--community-id lerobot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;code&gt;python lerobot/scripts/push_dataset_to_hub.py --help&lt;/code&gt; for more instructions.&lt;/p&gt; &#xA;&lt;p&gt;If your dataset format is not supported, implement your own in &lt;code&gt;lerobot/common/datasets/push_dataset_to_hub/${raw_format}_format.py&lt;/code&gt; by copying examples like &lt;a href=&#34;https://github.com/huggingface/lerobot/raw/main/lerobot/common/datasets/push_dataset_to_hub/pusht_zarr_format.py&#34;&gt;pusht_zarr&lt;/a&gt;, &lt;a href=&#34;https://github.com/huggingface/lerobot/raw/main/lerobot/common/datasets/push_dataset_to_hub/umi_zarr_format.py&#34;&gt;umi_zarr&lt;/a&gt;, &lt;a href=&#34;https://github.com/huggingface/lerobot/raw/main/lerobot/common/datasets/push_dataset_to_hub/aloha_hdf5_format.py&#34;&gt;aloha_hdf5&lt;/a&gt;, or &lt;a href=&#34;https://github.com/huggingface/lerobot/raw/main/lerobot/common/datasets/push_dataset_to_hub/xarm_pkl_format.py&#34;&gt;xarm_pkl&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Add a pretrained policy&lt;/h3&gt; &#xA;&lt;p&gt;Once you have trained a policy you may upload it to the Hugging Face hub using a hub id that looks like &lt;code&gt;${hf_user}/${repo_name}&lt;/code&gt; (e.g. &lt;a href=&#34;https://huggingface.co/lerobot/diffusion_pusht&#34;&gt;lerobot/diffusion_pusht&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;You first need to find the checkpoint folder located inside your experiment directory (e.g. &lt;code&gt;outputs/train/2024-05-05/20-21-12_aloha_act_default/checkpoints/002500&lt;/code&gt;). Within that there is a &lt;code&gt;pretrained_model&lt;/code&gt; directory which should contain:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;config.json&lt;/code&gt;: A serialized version of the policy configuration (following the policy&#39;s dataclass config).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;model.safetensors&lt;/code&gt;: A set of &lt;code&gt;torch.nn.Module&lt;/code&gt; parameters, saved in &lt;a href=&#34;https://huggingface.co/docs/safetensors/index&#34;&gt;Hugging Face Safetensors&lt;/a&gt; format.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;config.yaml&lt;/code&gt;: A consolidated Hydra training configuration containing the policy, environment, and dataset configs. The policy configuration should match &lt;code&gt;config.json&lt;/code&gt; exactly. The environment config is useful for anyone who wants to evaluate your policy. The dataset config just serves as a paper trail for reproducibility.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To upload these to the hub, run the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;huggingface-cli upload ${hf_user}/${repo_name} path/to/pretrained_model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/huggingface/lerobot/raw/main/lerobot/scripts/eval.py&#34;&gt;eval.py&lt;/a&gt; for an example of how other people may use your policy.&lt;/p&gt; &#xA;&lt;h3&gt;Improve your code with profiling&lt;/h3&gt; &#xA;&lt;p&gt;An example of a code snippet to profile the evaluation of a policy:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from torch.profiler import profile, record_function, ProfilerActivity&#xA;&#xA;def trace_handler(prof):&#xA;    prof.export_chrome_trace(f&#34;tmp/trace_schedule_{prof.step_num}.json&#34;)&#xA;&#xA;with profile(&#xA;    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],&#xA;    schedule=torch.profiler.schedule(&#xA;        wait=2,&#xA;        warmup=2,&#xA;        active=3,&#xA;    ),&#xA;    on_trace_ready=trace_handler&#xA;) as prof:&#xA;    with record_function(&#34;eval_policy&#34;):&#xA;        for i in range(num_episodes):&#xA;            prof.step()&#xA;            # insert code to profile, potentially whole body of eval_policy function&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you want, you can cite this work with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{cadene2024lerobot,&#xA;    author = {Cadene, Remi and Alibert, Simon and Soare, Alexander and Gallouedec, Quentin and Zouitine, Adil and Wolf, Thomas},&#xA;    title = {LeRobot: State-of-the-art Machine Learning for Real-World Robotics in Pytorch},&#xA;    howpublished = &#34;\url{https://github.com/huggingface/lerobot}&#34;,&#xA;    year = {2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>idootop/mi-gpt</title>
    <updated>2024-06-09T01:28:57Z</updated>
    <id>tag:github.com,2024-06-09:/idootop/mi-gpt</id>
    <link href="https://github.com/idootop/mi-gpt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ğŸ  å°†å°çˆ±éŸ³ç®±æ¥å…¥ ChatGPT å’Œè±†åŒ…ï¼Œæ”¹é€ æˆä½ çš„ä¸“å±è¯­éŸ³åŠ©æ‰‹ã€‚&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/idootop/mi-gpt/main/assets/demo.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;MiGPTï¼šæ™ºèƒ½å®¶å±…ï¼Œä»æœªå¦‚æ­¤è´´å¿ƒ â¤ï¸&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.npmjs.com/package/mi-gpt&#34;&gt;&lt;img src=&#34;https://badge.fury.io/js/mi-gpt.svg?sanitize=true&#34; alt=&#34;npm version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/idootop/mi-gpt&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/v/idootop/mi-gpt?color=%23086DCD&amp;amp;label=docker%20image&#34; alt=&#34;Docker Image Version&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;åœ¨è¿™ä¸ªæ•°å­—åŒ–çš„ä¸–ç•Œé‡Œï¼Œå®¶å·²ä¸ä»…ä»…æ˜¯ä¸€ä¸ªå±…ä½çš„åœ°æ–¹ï¼Œè€Œæ˜¯æˆ‘ä»¬æ•°å­—ç”Ÿæ´»çš„å»¶ä¼¸ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;MiGPT&lt;/code&gt; é€šè¿‡å°†å°çˆ±éŸ³ç®±ã€ç±³å®¶æ™ºèƒ½è®¾å¤‡ï¼Œä¸ ChatGPT çš„ç†è§£èƒ½åŠ›å®Œç¾èåˆï¼Œè®©ä½ çš„æ™ºèƒ½å®¶å±…æ›´æ‡‚ä½ ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;MiGPT&lt;/code&gt; ä¸ä»…ä»…æ˜¯å…³äºè®¾å¤‡è‡ªåŠ¨åŒ–ï¼Œè€Œæ˜¯å…³äºï¼š&lt;strong&gt;æ‰“é€ ä¸€ä¸ªæ‡‚ä½ ã€æœ‰æ¸©åº¦ã€ä¸ä½ å…±åŒè¿›åŒ–çš„å®¶&lt;/strong&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æœªæ¥ï¼Œä½ çš„æ¯ä¸ªæ™ºèƒ½å®¶å±…è®¾å¤‡ï¼Œä»ç¯æ³¡ã€æ’åº§ï¼Œåˆ°æ‰«åœ°æœºå™¨äººã€ç”µè§†ç­‰ï¼Œ&lt;/p&gt; &#xA;&lt;p&gt;éƒ½å¯ä»¥ä½œä¸ºä¸€ä¸ªä¸ªç‹¬ç«‹çš„æ™ºèƒ½ä½“ (Agent)ï¼Œæ›´æ™ºèƒ½ã€æ›´è´´å¿ƒçš„å“åº”ä½ çš„æŒ‡ä»¤ã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¿™äº›ç‹¬ç«‹çš„æ™ºèƒ½ä½“ï¼Œä¹Ÿå¯ä»¥å½¼æ­¤æ„ŸçŸ¥ï¼Œå½¼æ­¤é…åˆï¼Œæ„æˆä¸€ä¸ªæ›´å¼ºå¤§çš„åä½œç½‘ç»œã€‚&lt;/p&gt; &#xA;&lt;p&gt;è€Œå°çˆ±éŸ³ç®±å°±åƒæ˜¯ä½ çš„æ™ºèƒ½å®¶å±…ä¸“å±ç®¡å®¶ï¼Œå…¨å¿ƒå…¨æ„ä¸ºä½ æœåŠ¡ï¼Œé‡Šæ”¾æ™ºèƒ½å®¶å±…çš„çœŸæ­£æ½œåŠ›ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;âš¡ï¸ é¡¹ç›®é¢„è§ˆ&lt;/h2&gt; &#xA;&lt;p&gt;ğŸ‘‰ æŸ¥çœ‹å®Œæ•´æ¼”ç¤ºè§†é¢‘ï¼šã€&lt;a href=&#34;https://www.bilibili.com/video/BV1N1421y7qn/?share_source=copy_web&amp;amp;vd_source=5d4e78ff2a0dc6a661baa65f479199c1&#34;&gt;æ•´æ´»ï¼å°†å°çˆ±éŸ³ç®±æ¥å…¥ ChatGPT å’Œè±†åŒ…ï¼Œæ”¹é€ æˆä½ çš„ä¸“å±è¯­éŸ³åŠ©æ‰‹ï½&lt;/a&gt;ã€‘&lt;/p&gt; &#xA;&lt;p&gt;&#xA; &lt;video src=&#34;https://github.com/idootop/mi-gpt/assets/35302658/dc336916-9087-418b-bc1b-04d5534dce8f&#34;&gt;&lt;/video&gt;&lt;/p&gt; &#xA;&lt;h2&gt;âœ¨ é¡¹ç›®äº®ç‚¹&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ“ LLM å›ç­”&lt;/strong&gt;ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œä½ çš„å°çˆ±éŸ³ç®±å˜èº«èŠå¤©é«˜æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨ &lt;a href=&#34;https://chat.openai.com&#34;&gt;ChatGPT&lt;/a&gt; ç­‰å¤§æ¨¡å‹æ¥å›ç­”ä½ çš„é—®é¢˜ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ­ è§’è‰²æ‰®æ¼”&lt;/strong&gt;ã€‚ä¸€ç§’è°ƒæ•™å°çˆ±ï¼Œæ— è®ºæ˜¯æˆä¸ºä½ çš„å®Œç¾ä¼´ä¾£ï¼Œè¿˜æ˜¯é‚£ä¸ªèƒ½å¬ä½ å€¾è¯‰å¿ƒäº‹çš„è´´å¿ƒé—ºèœœï¼Œéƒ½ä¸åœ¨è¯ä¸‹ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ’¬ æµå¼å“åº”&lt;/strong&gt;ã€‚çˆ±æƒ…æ¥å¾—å¤ªå¿«å°±åƒé¾™å·é£ï¼Œè€Œä½ çš„å°çˆ±éŸ³ç®±ä¹Ÿæ˜¯ï¼Œå¯¹ä½ çš„çˆ±æ„ç§’å›ï¼Œçˆ±ä½ ä¸ä¼šè®©ä½ ç­‰å¤ªä¹…ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ§  é•¿çŸ­æœŸè®°å¿†&lt;/strong&gt;ã€‚å°çˆ±éŸ³ç®±ç°åœ¨èƒ½è®°ä½ä½ ä»¬ä¹‹é—´çš„æ¯ä¸€æ¬¡å¯¹è¯ï¼Œè¶ŠèŠè¶Šé»˜å¥‘ï¼Œå°±åƒæ˜¯ä½ èº«è¾¹çš„è€æœ‹å‹ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ”Š è‡ªå®šä¹‰ TTS&lt;/strong&gt;ã€‚åŒå€¦äº†å°çˆ±åŒå­¦çš„è¯­éŸ³ï¼Ÿå¸®ä½ è§£é”&lt;a href=&#34;https://doubao.com&#34;&gt;ã€Œè±†åŒ…ã€&lt;/a&gt;åŒæ¬¾éŸ³è‰²ï¼Œå°±åƒçœŸäººåœ¨å›ä½ çš„æ¶ˆæ¯ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ğŸ¤–ï¸ æ™ºèƒ½å®¶å±… Agent&lt;/strong&gt;ã€‚å¿ƒæƒ…ä¸å¥½ï¼Ÿå°çˆ±ç«‹åˆ»æ‡‚ä½ ï¼Œè‡ªåŠ¨å¸®ä½ æ’­æ”¾å–œæ¬¢çš„éŸ³ä¹ï¼Œè°ƒèŠ‚ç¯å…‰ï¼Œé€—ä½ å¼€å¿ƒã€‚&lt;em&gt;TODO&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸš€ å¯åŠ¨é¡¹ç›®&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;MiGPT&lt;/code&gt; æœ‰ä¸¤ç§å¯åŠ¨æ–¹å¼: &lt;a href=&#34;https://raw.githubusercontent.com/idootop/mi-gpt/main/#docker&#34;&gt;Docker&lt;/a&gt; å’Œ &lt;a href=&#34;https://raw.githubusercontent.com/idootop/mi-gpt/main/#nodejs&#34;&gt;Node.js&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/idootop/mi-gpt&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/v/idootop/mi-gpt?color=%23086DCD&amp;amp;label=docker%20image&#34; alt=&#34;Docker Image Version&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;å¯¹äºç”µè„‘å°ç™½æˆ–è€…ä¸æƒ³è‡ªå·±é…ç½®ä»£ç è¿è¡Œç¯å¢ƒï¼ˆNodeï¼‰çš„åŒå­¦ï¼Œå¯ä»¥ä½¿ç”¨ Docker å¯åŠ¨æ–¹å¼ã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¯·å…ˆæŒ‰ç…§&lt;a href=&#34;https://raw.githubusercontent.com/idootop/mi-gpt/main/#%EF%B8%8F-%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0&#34;&gt;ã€Œé…ç½®å‚æ•°ã€&lt;/a&gt;ç« èŠ‚ï¼Œé…ç½®å¥½ä½ çš„ &lt;code&gt;.env&lt;/code&gt; å’Œ &lt;code&gt;.migpt.js&lt;/code&gt; æ–‡ä»¶ï¼Œç„¶åä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨ dockerï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d  --env-file $(pwd)/.env \&#xA;    -v $(pwd)/.migpt.js:/app/.migpt.js \&#xA;    idootop/mi-gpt:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æ³¨æ„ï¼šåœ¨ Windows ç»ˆç«¯ä¸‹ä¸æ”¯æŒä½¿ç”¨ &lt;code&gt;$(pwd)&lt;/code&gt; è·å–å½“å‰å·¥ä½œè·¯å¾„ï¼Œéœ€è¦å°†é…ç½®æ–‡ä»¶è·¯å¾„æ›¿æ¢ä¸ºç»å¯¹è·¯å¾„ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Node.js&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.npmjs.com/package/mi-gpt&#34;&gt;&lt;img src=&#34;https://badge.fury.io/js/mi-gpt.svg?sanitize=true&#34; alt=&#34;npm version&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;å¦‚æœä½ æ˜¯ä¸€åå‰ç«¯ (Node) å¼€å‘è€…ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ NPM å®‰è£… &lt;code&gt;mi-gpt&lt;/code&gt; å¯åŠ¨ &lt;code&gt;MiGPT&lt;/code&gt;ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;npm install mi-gpt # å®‰è£…ä¾èµ–&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ç„¶åï¼Œåˆ›å»ºå¹¶å¯åŠ¨ &lt;code&gt;MiGPT&lt;/code&gt; å®ä¾‹ã€‚åˆå§‹åŒ–å‚æ•°çš„å…·ä½“å«ä¹‰è¯·çœ‹ä¸‹é¢çš„&lt;a href=&#34;https://raw.githubusercontent.com/idootop/mi-gpt/main/#%EF%B8%8F-%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0&#34;&gt;ã€Œé…ç½®å‚æ•°ã€&lt;/a&gt;ç« èŠ‚ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-typescript&#34;&gt;import { MiGPT } from &#34;mi-gpt&#34;;&#xA;&#xA;async function main() {&#xA;  const client = MiGPT.create({&#xA;    speaker: {&#xA;      userId: &#34;987654321&#34;, // æ³¨æ„ï¼šä¸æ˜¯æ‰‹æœºå·æˆ–é‚®ç®±ï¼Œè¯·åœ¨ã€Œä¸ªäººä¿¡æ¯ã€-ã€Œå°ç±³ IDã€æŸ¥çœ‹&#xA;      password: &#34;123456&#34;, // è´¦å·å¯†ç &#xA;      did: &#34;å°çˆ±éŸ³ç®±Pro&#34;, // å°çˆ±éŸ³ç®± ID æˆ–åœ¨ç±³å®¶ä¸­è®¾ç½®çš„åç§°&#xA;    },&#xA;  });&#xA;  await client.start();&#xA;}&#xA;&#xA;main();&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æ³¨æ„ï¼šæ­¤æ¨¡å¼ä¸‹å¹¶ä¸ä¼šä¸»åŠ¨è¯»å– &lt;code&gt;.env&lt;/code&gt; å’Œ &lt;code&gt;.migpt.json&lt;/code&gt; ä¸­çš„é…ç½®ä¿¡æ¯ï¼Œä½ éœ€è¦è‡ªå·±åˆå§‹åŒ– Node ç¯å¢ƒå˜é‡ï¼Œ&lt;/p&gt; &#xA;&lt;p&gt;å¹¶å°† &lt;code&gt;.migpt.json&lt;/code&gt; ä¸­çš„å‚æ•°ä½œä¸º &lt;code&gt;MiGPT.create&lt;/code&gt; çš„åˆå§‹åŒ–å‚æ•°ä¼ å…¥ã€‚ğŸ‘‰ &lt;a href=&#34;https://github.com/idootop/mi-gpt/raw/example/index.ts&#34;&gt;ç¤ºä¾‹ä»£ç &lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;âš™ï¸ é…ç½®å‚æ•°&lt;/h2&gt; &#xA;&lt;h3&gt;.migpt.js&lt;/h3&gt; &#xA;&lt;p&gt;é‡å‘½åæœ¬é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ &lt;a href=&#34;https://github.com/idootop/mi-gpt/raw/main/.migpt.example.js&#34;&gt;.migpt.example.js&lt;/a&gt; æ–‡ä»¶ä¸º &lt;code&gt;.migpt.js&lt;/code&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ç„¶åï¼Œå°†é‡Œé¢çš„é…ç½®å‚æ•°ä¿®æ”¹æˆä½ è‡ªå·±çš„ï¼Œå‚æ•°å«ä¹‰å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;å‚æ•°åç§°&lt;/th&gt; &#xA;   &lt;th&gt;æè¿°&lt;/th&gt; &#xA;   &lt;th&gt;ç¤ºä¾‹&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;bot&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;name&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;å¯¹æ–¹åç§°ï¼ˆå°çˆ±éŸ³ç®±ï¼‰&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;å‚»å¦&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;profile&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;å¯¹æ–¹çš„ä¸ªäººç®€ä»‹/äººè®¾&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;æ€§åˆ«å¥³ï¼Œæ€§æ ¼ä¹–å·§å¯çˆ±ï¼Œå–œæ¬¢ææ€ªï¼Œçˆ±åƒé†‹ã€‚&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;master&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;name&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸»äººåç§°ï¼ˆæˆ‘è‡ªå·±ï¼‰&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;é™†å°åƒ&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;profile&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¸»äººçš„ä¸ªäººç®€ä»‹/äººè®¾&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;æ€§åˆ«ç”·ï¼Œå–„è‰¯æ­£ç›´ï¼Œæ€»æ˜¯èˆå·±ä¸ºäººï¼Œæ˜¯å‚»å¦çš„ä¸»äººã€‚&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;room&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;name&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¼šè¯ç¾¤åç§°&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;é­”å¹»æ‰‹æœº&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;description&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä¼šè¯ç¾¤ç®€ä»‹&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;å‚»å¦å’Œé™†å°åƒçš„ç§èŠ&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;speaker&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;userId&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://account.xiaomi.com/fe/service/account/profile&#34;&gt;å°ç±³ ID&lt;/a&gt;ï¼ˆæ³¨æ„ï¼šä¸æ˜¯æ‰‹æœºå·æˆ–é‚®ç®±ï¼‰&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;987654321&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;password&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;è´¦æˆ·å¯†ç &lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;123456&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;did&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;å°çˆ±éŸ³ç®± ID æˆ–åç§°&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;å°çˆ±éŸ³ç®± Pro&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;ttsCommand&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;å°çˆ±éŸ³ç®± TTS æŒ‡ä»¤ï¼ˆ&lt;a href=&#34;https://home.miot-spec.com&#34;&gt;å¯åœ¨æ­¤æŸ¥è¯¢&lt;/a&gt;ï¼‰&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;[5, 1]&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;wakeUpCommand&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;å°çˆ±éŸ³ç®±å”¤é†’æŒ‡ä»¤ï¼ˆ&lt;a href=&#34;https://home.miot-spec.com&#34;&gt;å¯åœ¨æ­¤æŸ¥è¯¢&lt;/a&gt;ï¼‰&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;[5, 3]&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;speaker å…¶ä»–å‚æ•°ï¼ˆå¯é€‰ï¼‰&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;callAIKeywords&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;å½“æ¶ˆæ¯ä»¥å…³é”®è¯å¼€å¤´æ—¶ï¼Œä¼šè°ƒç”¨ AI æ¥å“åº”ç”¨æˆ·æ¶ˆæ¯&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;[&#34;è¯·&#34;, &#34;å‚»å¦&#34;]&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;wakeUpKeywords&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;å½“æ¶ˆæ¯ä»¥å…³é”®è¯å¼€å¤´æ—¶ï¼Œä¼šè¿›å…¥ AI å”¤é†’çŠ¶æ€&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;[&#34;å¬å”¤å‚»å¦&#34;, &#34;æ‰“å¼€å‚»å¦&#34;]&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;exitKeywords&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;å½“æ¶ˆæ¯ä»¥å…³é”®è¯å¼€å¤´æ—¶ï¼Œä¼šé€€å‡º AI å”¤é†’çŠ¶æ€&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;[&#34;é€€å‡ºå‚»å¦&#34;, &#34;å…³é—­å‚»å¦&#34;]&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;onEnterAI&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;è¿›å…¥ AI æ¨¡å¼çš„æ¬¢è¿è¯­&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;[&#34;ä½ å¥½ï¼Œæˆ‘æ˜¯å‚»å¦ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ &#34;]&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;onExitAI&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;é€€å‡º AI æ¨¡å¼çš„æç¤ºè¯­&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;[&#34;å‚»å¦å·²é€€å‡º&#34;]&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;onAIAsking&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;AI å¼€å§‹å›ç­”æ—¶çš„æç¤ºè¯­&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;[&#34;è®©æˆ‘å…ˆæƒ³æƒ³&#34;, &#34;è¯·ç¨ç­‰&#34;]&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;onAIReplied&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;AI ç»“æŸå›ç­”æ—¶çš„æç¤ºè¯­&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;[&#34;æˆ‘è¯´å®Œäº†&#34;, &#34;è¿˜æœ‰å…¶ä»–é—®é¢˜å—&#34;]&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;onAIError&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;AI å›ç­”å¼‚å¸¸æ—¶çš„æç¤ºè¯­&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;[&#34;å‡ºé”™äº†ï¼Œè¯·ç¨åå†è¯•å§ï¼&#34;]&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;playingCommand&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;æŸ¥è¯¢å°çˆ±éŸ³ç®±æ˜¯å¦åœ¨æ’­æ”¾ä¸­æŒ‡ä»¤ï¼ˆ&lt;a href=&#34;https://home.miot-spec.com&#34;&gt;å¯åœ¨æ­¤æŸ¥è¯¢&lt;/a&gt;ï¼‰&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;[3, 1, 1]&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;streamResponse&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;æ˜¯å¦å¯ç”¨æµå¼å“åº”ï¼ˆéƒ¨åˆ†å°çˆ±éŸ³ç®±å‹å·ä¸æ”¯æŒæŸ¥è¯¢æ’­æ”¾çŠ¶æ€ï¼Œæ­¤æ—¶éœ€è¦å…³é—­æµå¼å“åº”ï¼‰&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;exitKeepAliveAfter&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;æ— å“åº”ä¸€æ®µæ—¶é—´åï¼Œå¤šä¹…è‡ªåŠ¨é€€å‡ºå”¤é†’æ¨¡å¼ï¼ˆå•ä½ç§’ï¼Œé»˜è®¤ 30 ç§’ï¼‰&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;30&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;ç¯å¢ƒå˜é‡&lt;/h3&gt; &#xA;&lt;p&gt;é‡å‘½åæœ¬é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ &lt;a href=&#34;https://github.com/idootop/mi-gpt/raw/main/.env.example&#34;&gt;.env.example&lt;/a&gt; æ–‡ä»¶ä¸º &lt;code&gt;.env&lt;/code&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ç„¶åï¼Œå°†é‡Œé¢çš„ç¯å¢ƒå˜é‡ä¿®æ”¹æˆä½ è‡ªå·±çš„ï¼Œå‚æ•°å«ä¹‰å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ç¯å¢ƒå˜é‡åç§°&lt;/th&gt; &#xA;   &lt;th&gt;æè¿°&lt;/th&gt; &#xA;   &lt;th&gt;ç¤ºä¾‹&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;OpenAI API å¯†é’¥&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;abc123&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;OPENAI_MODEL&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ä½¿ç”¨çš„ OpenAI æ¨¡å‹&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;gpt-4o&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;OPENAI_BASE_URL&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;å¯é€‰ï¼ŒOpenAI API BaseURL&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;https://api.openai.com/v1&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;å¯é€‰ï¼Œ&lt;a href=&#34;https://www.npmjs.com/package/openai#microsoft-azure-openai&#34;&gt;Microsoft Azure OpenAI&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;abc123&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;æç¤ºéŸ³æ•ˆï¼ˆå¯é€‰ï¼‰&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;AUDIO_SILENT&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;é™éŸ³éŸ³é¢‘é“¾æ¥&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;https://example.com/slient.wav&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;AUDIO_BEEP&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;é»˜è®¤æç¤ºéŸ³é“¾æ¥&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;https://example.com/beep.wav&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;AUDIO_ACTIVE&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;å”¤é†’æç¤ºéŸ³é“¾æ¥&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;https://example.com/active.wav&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;AUDIO_ERROR&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;å‡ºé”™æç¤ºéŸ³é“¾æ¥&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;https://example.com/error.wav&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;è±†åŒ… TTSï¼ˆå¯é€‰ï¼‰&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;TTS_DOUBAO&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;è±†åŒ… TTS æ¥å£&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;https://example.com/tts.wav&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;SPEAKERS_DOUBAO&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;è±†åŒ… TTS éŸ³è‰²åˆ—è¡¨æ¥å£&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;&#34;https://example.com/tts-speakers&#34;&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;ğŸ’¬ å¸¸è§é—®é¢˜&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Qï¼šæ”¯æŒå“ªäº›å‹å·çš„å°çˆ±éŸ³ç®±ï¼Ÿ&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;å¤§éƒ¨åˆ†å‹å·çš„å°çˆ±éŸ³ç®±éƒ½æ”¯æŒï¼Œæ¨èå°çˆ±éŸ³ç®± Proï¼ˆå®Œç¾è¿è¡Œï¼‰ã€‚éƒ¨åˆ†æœºå‹çš„ MioT æ¥å£å¼€æ”¾èƒ½åŠ›å¹¶ä¸å®Œæ•´ï¼Œæ¯”å¦‚å°ç±³éŸ³ç®± Play å¢å¼ºç‰ˆï¼ˆL05Cï¼‰ï¼Œå°†ä¼šå¯¼è‡´ &lt;code&gt;MiGPT&lt;/code&gt; éƒ¨åˆ†åŠŸèƒ½å¼‚å¸¸ï¼Œç›¸å…³ &lt;a href=&#34;https://github.com/idootop/mi-gpt/issues/14&#34;&gt;issue&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Qï¼šé™¤äº† OpenAI è¿˜æ”¯æŒå“ªäº›æ¨¡å‹ï¼Œå¦‚ä½•è®¾ç½®ï¼Ÿ&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;ç†è®ºä¸Šå…¼å®¹ &lt;a href=&#34;https://www.npmjs.com/package/openai&#34;&gt;OpenAI SDK&lt;/a&gt; çš„æ¨¡å‹éƒ½æ”¯æŒï¼Œåªéœ€ä¿®æ”¹ç¯å¢ƒå˜é‡å³å¯æ¥å…¥åˆ° MiGPTã€‚&lt;/p&gt; &#xA;&lt;p&gt;æ¯”å¦‚ï¼š&lt;a href=&#34;https://help.aliyun.com/zh/dashscope/developer-reference/compatibility-of-openai-with-dashscope/?spm=a2c4g.11186623.0.i1&#34;&gt;é€šä¹‰åƒé—®&lt;/a&gt;ã€&lt;a href=&#34;https://platform.01.ai/docs#making-an-api-request&#34;&gt;é›¶ä¸€ä¸‡ç‰©&lt;/a&gt;ã€&lt;a href=&#34;https://platform.moonshot.cn/docs/api/chat&#34;&gt;Moonshot&lt;/a&gt;ã€&lt;a href=&#34;https://platform.deepseek.com/api-docs/&#34;&gt;DeepSeek&lt;/a&gt; ç­‰ï¼Œä»¥ Moonshot ä¸ºä¾‹ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;OPENAI_BASE_URL=https://api.moonshot.cn/v1&#xA;OPENAI_MODEL=moonshot-v1-8k&#xA;OPENAI_API_KEY=$MOONSHOT_API_KEY&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Qï¼šä»€ä¹ˆæ˜¯å”¤é†’æ¨¡å¼ï¼Ÿ&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;å”¤é†’æ¨¡å¼&lt;/code&gt; ç±»ä¼¼äºå°çˆ±æŠ€èƒ½ï¼Œå¯èƒ½è®©ä½ åœ¨è·Ÿå°çˆ±äº’åŠ¨çš„æ—¶å€™ï¼Œæ— éœ€æ¯å¥è¯éƒ½è¦ä»¥â€œå°çˆ±åŒå­¦â€å¼€å¤´å”¤é†’ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å…³äºå”¤é†’æ¨¡å¼çš„æ›´å¤šç»†èŠ‚ï¼Œè¯·æŸ¥çœ‹è¿™é‡Œï¼š&lt;a href=&#34;https://github.com/idootop/mi-gpt/issues/28&#34;&gt;https://github.com/idootop/mi-gpt/issues/28&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Qï¼šæç¤ºç™»å½•å°ç±³è´¦å·å¤±è´¥ï¼Œæ— æ³•æ­£å¸¸å¯åŠ¨&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;è´¦å·å¯†ç ä¸æ­£ç¡®&lt;/strong&gt;ï¼šå°ç±³ ID å¹¶éæ‰‹æœºå·æˆ–é‚®ç®±ï¼Œè¯·åœ¨&lt;a href=&#34;https://account.xiaomi.com/fe/service/account/profile&#34;&gt;ã€Œä¸ªäººä¿¡æ¯ã€-ã€Œå°ç±³ IDã€&lt;/a&gt;æŸ¥çœ‹ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;ç½‘ç»œç¯å¢ƒå¼‚å¸¸&lt;/strong&gt;ï¼šå¦‚æœä½ æ˜¯åœ¨æµ·å¤–æœåŠ¡å™¨ç­‰ï¼Œéä¸­å›½å¤§é™†ç½‘ç»œç¯å¢ƒä¸‹ç™»å½•å°ç±³è´¦å·ï¼Œéœ€è¦å…ˆåŒæ„å°ç±³çš„ã€Œä¸ªäººæ•°æ®è·¨å¢ƒä¼ è¾“ã€åè®®ï¼Œç„¶åæŒ‰ç…§æç¤ºéªŒè¯æ‰‹æœºå·æˆ–é‚®ç®±ï¼Œç­‰å¾…å¤§çº¦ 30 åˆ†é’Ÿä¹‹åå³å¯æ­£å¸¸ç™»å½•ã€‚&lt;a href=&#34;https://github.com/idootop/mi-gpt/issues/22#issuecomment-2150535622&#34;&gt;ğŸ‘‰ ç›¸å…³æ•™ç¨‹&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;Qï¼šå°çˆ±éŸ³ç®±æ”¶åˆ°æ¶ˆæ¯åï¼Œæ²¡æœ‰è°ƒç”¨ AI è¿›è¡Œå›å¤&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;MiGPT&lt;/code&gt; æ”¶åˆ°æ¶ˆæ¯é»˜è®¤ä¸ä¼šè°ƒç”¨ AI è¿›è¡Œå›å¤ï¼Œåªä¼šå›å¤ä»¥å”¤é†’è¯å¼€å¤´çš„æ¶ˆæ¯ï¼Œæ¯”å¦‚ï¼šâ€œè¯·é—® xxxâ€ã€â€œä½  xxxâ€ ç­‰ï¼Œä½ ä¹Ÿå¯ä»¥è‡ªå®šä¹‰å”¤é†’è¯ï¼ˆ&lt;code&gt;callAIKeywords&lt;/code&gt;ï¼‰åˆ—è¡¨ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Qï¼šå°çˆ±éŸ³ç®±æ²¡æœ‰æ’­æ”¾ AI çš„å›ç­”ï¼Œä½†æ§åˆ¶å°æœ‰æ‰“å° AI çš„å›å¤&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;ä¸åŒå‹å·çš„å°çˆ±éŸ³ç®± TTS æŒ‡ä»¤ä¸åŒ: &lt;a href=&#34;https://github.com/idootop/mi-gpt/issues/5#issuecomment-2122881495&#34;&gt;issues#5&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;è¯·åˆ° &lt;a href=&#34;https://home.miot-spec.com&#34;&gt;https://home.miot-spec.com&lt;/a&gt; æŸ¥è¯¢å…·ä½“æŒ‡ä»¤ï¼Œå¹¶ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„ &lt;code&gt;ttsCommand&lt;/code&gt; å‚æ•°ã€‚&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;ğŸ‘‰ æŸ¥çœ‹æ•™ç¨‹&lt;/summary&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/idootop/mi-gpt/main/assets/search.jpg&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/idootop/mi-gpt/main/assets/command.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;strong&gt;Qï¼šå°çˆ±éŸ³ç®±æ²¡æœ‰è¯»å®Œæ•´ä¸ªå¥å­ï¼Œæ€»æ˜¯æˆ›ç„¶è€Œæ­¢&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;éƒ¨åˆ†å‹å·çš„å°çˆ±éŸ³ç®±ä¸æ”¯æŒé€šè¿‡ Mina è·å–è®¾å¤‡æ’­æ”¾çŠ¶æ€ï¼Œåªèƒ½é€šè¿‡ MiOT æŒ‡ä»¤æŸ¥è¯¢ã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¯·åˆ° &lt;a href=&#34;https://home.miot-spec.com&#34;&gt;https://home.miot-spec.com&lt;/a&gt; æŸ¥è¯¢å…·ä½“æŒ‡ä»¤ï¼Œå¹¶ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„ &lt;code&gt;playingCommand&lt;/code&gt; å‚æ•°ã€‚&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;ğŸ‘‰ æŸ¥çœ‹æ•™ç¨‹&lt;/summary&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/idootop/mi-gpt/main/assets/playing.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;å¦‚æœä¿®æ”¹å‚æ•°åé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯´æ˜ä½ çš„è®¾å¤‡ä¸æ”¯æŒé€šè¿‡å¼€æ”¾æ¥å£æŸ¥è¯¢æ’­æ”¾çŠ¶æ€ï¼ˆæ¯”å¦‚ï¼šå°ç±³éŸ³ç®± Play å¢å¼ºç‰ˆï¼‰ï¼Œ&lt;strong&gt;æ­¤é—®é¢˜æ— è§£&lt;/strong&gt;ã€‚å»ºè®®æ›´æ¢å…¶ä»–å‹å·çš„å°çˆ±éŸ³ç®±ï¼ˆæ¨èå°çˆ±éŸ³ç®± Proï¼‰ï¼Œç›¸å…³ &lt;a href=&#34;https://github.com/idootop/mi-gpt/issues/14&#34;&gt;issue&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æˆ–è€…ä½ ä¹Ÿå¯ä»¥å…³é—­é…ç½®æ–‡ä»¶ä¸­çš„æµå¼å“åº”ï¼ˆstreamResponseï¼‰é€‰é¡¹ï¼Œç¡®ä¿å°çˆ±èƒ½å¤Ÿå›å¤å®Œæ•´çš„å¥å­ã€‚ä¸è¿‡éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå…³é—­æµå¼å“åº”åï¼Œå”¤é†’æ¨¡å¼ç­‰åŠŸèƒ½å°†ä¼šå¤±æ•ˆã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Q: ä¸ºä»€ä¹ˆå°çˆ±éŸ³ç®±ä¼šåœ¨ AI å›ç­”ä¹‹å‰æŠ¢è¯ï¼Ÿ&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;ä¸æœ¬é¡¹ç›®çš„å®ç°åŸç†æœ‰å…³ã€‚æœ¬é¡¹ç›®é€šè¿‡è½®è¯¢å°ç±³æ¥å£è·å–æœ€æ–°çš„å¯¹è¯ä¿¡æ¯ï¼Œå½“æ£€æµ‹åˆ°å°çˆ±åœ¨å›å¤çš„æ—¶å€™ä¼šé€šè¿‡æ’­æ”¾é™éŸ³éŸ³é¢‘ç­‰æ–¹å¼å¿«é€Ÿ mute æ‰å°çˆ±åŸæ¥çš„å›å¤ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ä½†æ˜¯ä»å°çˆ±å¼€å§‹å›å¤ï¼Œåˆ°ä¸ŠæŠ¥çŠ¶æ€ç»™å°ç±³æœåŠ¡äº‘ç«¯ï¼Œå†åˆ°æœ¬é¡¹ç›®é€šè¿‡å°ç±³äº‘ç«¯æ¥å£è½®è®­åˆ°è¿™ä¸ªçŠ¶æ€å˜æ›´ï¼Œä¸­é—´ä¼šæœ‰å¤§çº¦ 1 -2 ç§’çš„å»¶è¿Ÿæ—¶é—´ï¼Œæ— è§£ã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¿™ä¸ªé—®é¢˜ï¼Œç†è®ºä¸Šéœ€è¦é€šè¿‡åˆ·æœºæ‰èƒ½å®Œç¾è§£å†³ï¼Œå¯ä»¥å‚è€ƒä¸‹é¢çš„ç›¸å…³è®¨è®ºï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yihong0618/xiaogpt/issues/515#issuecomment-2121602572&#34;&gt;https://github.com/yihong0618/xiaogpt/issues/515#issuecomment-2121602572&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/idootop/mi-gpt/issues/21#issuecomment-2147125219&#34;&gt;https://github.com/idootop/mi-gpt/issues/21#issuecomment-2147125219&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Qï¼šå¯åŠ¨ docker æç¤º ERR_MODULE_NOT_FOUNDï¼Œæ— æ³•æ­£å¸¸å¯åŠ¨&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;åœ¨ Windows ç»ˆç«¯ï¼ˆæ¯”å¦‚ï¼šPowerShellã€cmdï¼‰ä¸‹ï¼Œæ— æ³•ä½¿ç”¨ &lt;code&gt;$(pwd)&lt;/code&gt; è·å–å½“å‰å·¥ä½œç›®å½•ç»å¯¹è·¯å¾„ï¼Œéœ€è¦å¡«å†™ &lt;code&gt;.env&lt;/code&gt; å’Œ &lt;code&gt;.migpt.js&lt;/code&gt; æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ã€‚ç›¸å…³ &lt;a href=&#34;https://github.com/idootop/mi-gpt/issues/26#issuecomment-2151381521&#34;&gt;issue&lt;/a&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;ğŸ‘‰ æŸ¥çœ‹ç¤ºä¾‹&lt;/summary&gt; &#xA; &lt;p&gt;è¯·å°†ä¸‹é¢çš„ &lt;code&gt;/ç»å¯¹è·¯å¾„/&lt;/code&gt; æ›¿æ¢ä¸ºä½ å½“å‰ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼š&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d --env-file /ç»å¯¹è·¯å¾„/.env \&#xA;    -v /ç»å¯¹è·¯å¾„/.migpt.js:/app/.migpt.js \&#xA;    idootop/mi-gpt:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;Windows PowerShell ç»ˆç«¯&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d --env-file $pwd\.env `&#xA;    -v $pwd\.migpt.js:/app/.migpt.js `&#xA;    idootop/mi-gpt:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;Windows cmd ç»ˆç«¯&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d --env-file %cd%\.env ^&#xA;    -v %cd%\.migpt.js:/app/.migpt.js ^&#xA;    idootop/mi-gpt:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;strong&gt;Qï¼šæˆ‘ Clone äº†è¿™ä¸ªä»“åº“ï¼Œä½†æ˜¯æœ¬åœ°å¯åŠ¨å¤±è´¥&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;å¦‚æœä½ æ˜¯é€šè¿‡ clone æœ¬é¡¹ç›®ä»“åº“çš„æ–¹å¼æ¥è¿è¡Œï¼Œè®°å¾—åœ¨ &lt;code&gt;start&lt;/code&gt; ä¹‹å‰å…ˆ &lt;code&gt;build&lt;/code&gt; ä¸€ä¸‹ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pnpm install &amp;amp;&amp;amp; pnpm build &amp;amp;&amp;amp; pnpm start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å¦å¤–ï¼Œ &lt;code&gt;start&lt;/code&gt; å‘½ä»¤é»˜è®¤æ²¡æœ‰æ³¨å…¥ &lt;code&gt;.env&lt;/code&gt; æ–‡ä»¶é‡Œçš„ç¯å¢ƒå˜é‡ã€‚ä½ å¯ä»¥åœ¨ VS Code é‡ŒæŒ‰ F5 ç›´æ¥è¿è¡Œï¼Œä¼šè‡ªåŠ¨è¯»å– &lt;code&gt;.env&lt;/code&gt; ï¼Œæˆ–è€…å°†å¯åŠ¨è„šæœ¬æ”¹ä¸ºï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;node --env-file=.env app.js&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Qï¼šæ€æ ·ä½¿ç”¨è±†åŒ…çš„éŸ³è‰²&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;æ­¤åŠŸèƒ½éœ€è¦è±†åŒ… TTS æ¥å£æ”¯æŒï¼Œæœ¬é¡¹ç›®æš‚ä¸å¯¹å¤–æä¾›æ­¤æœåŠ¡ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Qï¼šæˆ‘è¿˜æœ‰å…¶ä»–é—®é¢˜&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;è¯·åœ¨æ­¤å¤„æäº¤ &lt;a href=&#34;https://github.com/idootop/mi-gpt/issues&#34;&gt;issue&lt;/a&gt; åé¦ˆï¼Œå¹¶æä¾›è¯¦ç»†çš„é—®é¢˜æè¿°å’Œç›¸å…³é”™è¯¯æˆªå›¾ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;ğŸš¨ å…è´£å£°æ˜&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ç›®çš„ï¼Œä¸å¾—ç”¨äºä»»ä½•å•†ä¸šæ´»åŠ¨ã€‚ç”¨æˆ·åœ¨ä½¿ç”¨æœ¬é¡¹ç›®æ—¶åº”éµå®ˆæ‰€åœ¨åœ°åŒºçš„æ³•å¾‹æ³•è§„ï¼Œå¯¹äºè¿æ³•ä½¿ç”¨æ‰€å¯¼è‡´çš„åæœï¼Œæœ¬é¡¹ç›®åŠä½œè€…ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚ æœ¬é¡¹ç›®å¯èƒ½å­˜åœ¨æœªçŸ¥çš„ç¼ºé™·å’Œé£é™©ï¼ˆåŒ…æ‹¬ä½†ä¸é™äºè®¾å¤‡æŸåå’Œè´¦å·å°ç¦ç­‰ï¼‰ï¼Œä½¿ç”¨è€…åº”è‡ªè¡Œæ‰¿æ‹…ä½¿ç”¨æœ¬é¡¹ç›®æ‰€äº§ç”Ÿçš„æ‰€æœ‰é£é™©åŠè´£ä»»ã€‚ ä½œè€…ä¸ä¿è¯æœ¬é¡¹ç›®çš„å‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€åŠæ—¶æ€§ã€å¯é æ€§ï¼Œä¹Ÿä¸æ‰¿æ‹…ä»»ä½•å› ä½¿ç”¨æœ¬é¡¹ç›®è€Œäº§ç”Ÿçš„ä»»ä½•æŸå¤±æˆ–æŸå®³è´£ä»»ã€‚ ä½¿ç”¨æœ¬é¡¹ç›®å³è¡¨ç¤ºæ‚¨å·²é˜…è¯»å¹¶åŒæ„æœ¬å…è´£å£°æ˜çš„å…¨éƒ¨å†…å®¹ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;â¤ï¸ é¸£è°¢&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yihong0618/xiaogpt&#34;&gt;https://github.com/yihong0618/xiaogpt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/inu1255/mi-service&#34;&gt;https://github.com/inu1255/mi-service&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Yonsm/MiService&#34;&gt;https://github.com/Yonsm/MiService&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>hackerb9/lsix</title>
    <updated>2024-06-09T01:28:57Z</updated>
    <id>tag:github.com,2024-06-09:/hackerb9/lsix</id>
    <link href="https://github.com/hackerb9/lsix" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Like &#34;ls&#34;, but for images. Shows thumbnails in terminal using sixel graphics.&lt;/p&gt;&lt;hr&gt;&lt;img align=&#34;right&#34; src=&#34;https://raw.githubusercontent.com/hackerb9/lsix/master/README.md.d/thumb.png&#34;&gt; &#xA;&lt;h1&gt;lsix&lt;/h1&gt; &#xA;&lt;p&gt;Like &#34;ls&#34;, but for images. Shows thumbnails in terminal using &lt;a href=&#34;https://en.wikipedia.org/wiki/Sixel&#34;&gt;sixel&lt;/a&gt; graphics.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;lsix [ FILES ... ]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;h3&gt;Basic Usage&lt;/h3&gt; &#xA;&lt;p&gt;Just typing &lt;code&gt;lsix&lt;/code&gt; will show images in the current working directory. You can also specify filenames and, of course, use shell wild cards (e.g., &lt;code&gt;lsix *jpg *png&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;Because lsix uses ImageMagick pretty much any image format will be supported. However, some may be slow to render (like PDF), so lsix doesn&#39;t show them unless you ask specifically. If you want to force a listing of a certain type of image simply specify the filenames or use a wildcard (&lt;code&gt;*.pdf&lt;/code&gt; in the example below),.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hackerb9/lsix/master/README.md.d/example1.png&#34; alt=&#34;Example 1 of lsix usage&#34; title=&#34;Most basic usage&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Expanding GIFs&lt;/h3&gt; &#xA;&lt;p&gt;If you specify a GIF (or actually any file that has multiple images in it) on the command line, all the frames will get expanded and shown in a montage. For example, &lt;code&gt;lsix nyancat.gif&lt;/code&gt; shows all the frames. Note that GIF stores some frames as only the pixels that differ from the previous frame. &lt;img src=&#34;https://raw.githubusercontent.com/hackerb9/lsix/master/README.md.d/example2.png&#34; alt=&#34;Example 2 of lsix usage&#34; title=&#34;GIFs get expanded&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Terminal background color is detected&lt;/h3&gt; &#xA;&lt;p&gt;You may have noticed that PNGs and SVG files have correct alpha channel for the terminal background. That is because lsix uses terminal escape sequences to try to figure out your foreground and background colors. (Foreground is used for the text fill color.)&lt;/p&gt; &#xA;&lt;p&gt;In the first example below, after running &lt;code&gt;lsix&lt;/code&gt; in a white on black xterm, I sent an escape sequence to swap foreground and background colors. When I ran it again, &lt;code&gt;lsix&lt;/code&gt; detected it and changed the background color to white. Of course, you can pick whatever default colors you want (e.g., &lt;code&gt;xterm -bg blue&lt;/code&gt;, in the second example below).&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hackerb9/lsix/master/README.md.d/example3.png&#34; alt=&#34;Example 3 of lsix usage&#34; title=&#34;Reverse video works&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/hackerb9/lsix/master/README.md.d/example4.png&#34; alt=&#34;Example 4 of lsix usage&#34; title=&#34;Even &#39;xterm -bg blue&#39; works&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Detects if your terminal can display SIXEL graphics inline using &lt;a href=&#34;https://invisible-island.net/xterm/ctlseqs/ctlseqs.html#h2-Sixel-Graphics&#34;&gt;control sequences&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Works great over ssh. Perfect for manipulating those images on the web server when you can&#39;t quite remember what each one was.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Non-bitmap graphics often work fine (.svg, .eps, .pdf, .xcf).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Automatically detects if your terminal, like xterm, can increase the number of color registers to improve the image quality and does so.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Automatically detects terminal&#39;s foreground and background colors.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;In terminals that support dtterm WindowOps, the number of tiles per row will adjust appropriately to the window width.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If there are many images in a directory (&amp;gt;21), lsix will display them one row at a time so you don&#39;t need to wait for the entire montage to be created.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If your filenames are too long, lsix will wrap the text before passing it into ImageMagick&#39;s &lt;code&gt;montage&lt;/code&gt;. (Without lsix, &lt;code&gt;montage&lt;/code&gt; just jumbles long filenames on top of one another.)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You can easily change things like the width of each tile in the montage, the font family, and point size by editing simple variables at the top of the file. &lt;em&gt;(Tip: try &lt;code&gt;convert -list font&lt;/code&gt; to see what fonts you have on your machine.)&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Unicode filenames work fine, as long as your font has the glyphs.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Just put the &lt;a href=&#34;https://raw.githubusercontent.com/hackerb9/lsix/master/lsix&#34;&gt;&lt;code&gt;lsix&lt;/code&gt;&lt;/a&gt; file in your path (e.g., /usr/local/bin) and run it. It&#39;s just a BASH shell script.&lt;/p&gt; &#xA;&lt;p&gt;The only prerequisite software is ImageMagick. If you don&#39;t have it yet, your OS&#39;s package manager will make it easy to get. (E.g., &lt;code&gt;apt-get install imagemagick&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;MacOS users may prefer to install lsix using &lt;code&gt;brew install lsix&lt;/code&gt; which installs ImageMagick, if necessary.&lt;/p&gt; &#xA;&lt;h2&gt;Your Terminal must support Sixel graphics&lt;/h2&gt; &#xA;&lt;p&gt;I developed this using &lt;a href=&#34;https://invisible-island.net/xterm/&#34;&gt;xterm&lt;/a&gt; in vt340 emulation mode, but I believe this should work on any Sixel compatible terminal. You may test your terminal by viewing a single image, like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;convert  foo.jpg  -geometry 800x480  sixel:- &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;XTerm&lt;/h3&gt; &#xA;&lt;p&gt;Note that xterm does not have Sixel mode enabled by default, so you need to either run it like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;xterm -ti vt340&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or, make vt340 the default terminal type for xterm. Add the following to your &lt;code&gt;.Xresources&lt;/code&gt; file and run &lt;code&gt;xrdb -merge .Xresources&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;! Allow sixel graphics. (Try: &#34;convert -colors 16 foo.jpg sixel:-&#34;).&#xA;xterm*decTerminalID&#x9;:&#x9;vt340&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Further, some distributions, such as Fedora, appear to not compile &lt;code&gt;xterm&lt;/code&gt; with sixel support. In that case, try an alternate terminal, such as &lt;code&gt;foot&lt;/code&gt; or &lt;code&gt;mlterm&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;SIXEL compatible terminals&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;XTerm (tested)&lt;/li&gt; &#xA; &lt;li&gt;MLterm (tested)&lt;/li&gt; &#xA; &lt;li&gt;foot (tested)&lt;/li&gt; &#xA; &lt;li&gt;Wezterm (tested)&lt;/li&gt; &#xA; &lt;li&gt;Contour (tested)&lt;/li&gt; &#xA; &lt;li&gt;iTerm2 for Apple MacOS (tested)&lt;/li&gt; &#xA; &lt;li&gt;Konsole (reported)&lt;/li&gt; &#xA; &lt;li&gt;yakuake (reported)&lt;/li&gt; &#xA; &lt;li&gt;WSLtty for Microsoft Windows (reported)&lt;/li&gt; &#xA; &lt;li&gt;MinTTY for Cygwin (Microsoft Windows) (reported)&lt;/li&gt; &#xA; &lt;li&gt;Yaft for Linux framebuffer (tested)&lt;/li&gt; &#xA; &lt;li&gt;VTE (special compilation, reported)&lt;/li&gt; &#xA; &lt;li&gt;sixel-tmux (fork of tmux, reported)&lt;/li&gt; &#xA; &lt;li&gt;ttyd (reported)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;SIXEL incompatible terminals&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;MacOS Terminal, kitty&lt;/li&gt; &#xA; &lt;li&gt;All standard libvte based terminals &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;gnome-terminal&lt;/li&gt; &#xA;   &lt;li&gt;terminator&lt;/li&gt; &#xA;   &lt;li&gt;lxterm&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Alacritty (might work with &lt;a href=&#34;https://github.com/alacritty/alacritty/pull/4763&#34;&gt;a patch&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;Because &lt;code&gt;lsix&lt;/code&gt; is currently designed to be very simple, there are no command line flags, no configuration files, no knobs to twiddle, or frobs to frobnosticate. However, since the script is so simple, if you want to make a change, it&#39;s pretty easy to do just by editing the file. Everything is nicely commented with the most common default variables at the top.&lt;/p&gt; &#xA;&lt;h2&gt;Contact the author&lt;/h2&gt; &#xA;&lt;p&gt;I welcome feedback. If you use lsix and like it or have suggestions for how it can be improved, please go ahead and send your thoughts to me &lt;a href=&#34;https://github.com/hackerb9/lsix/issues/new&#34;&gt;@hackerb9&lt;/a&gt; via GitHub.&lt;/p&gt; &#xA;&lt;h2&gt;Bugs&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;XTerm&#39;s reverse video mode (&lt;code&gt;xterm -rv&lt;/code&gt;) is different from specifying the foreground and background explicitly. There is a way to detect the latter, but not the former. That means the background color will be incorrect for folks who use XTerm&#39;s reverseVideo resource. (See issue #20).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;XTerm&#39;s screen width is currently limited to 1000px due to a misfeature which causes it to silently show nothing. This limitation will be removed once xterm can handle images greater than 1000x1000. [Last tested with XTerm(344)].&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Filenames that begin with &#34;@&#34; are special to ImageMagick and it&#39;ll freak out if you don&#39;t prepend a directory. (&lt;code&gt;lsix ./@foo.png&lt;/code&gt;) (This is a bug in ImageMagick, not lsix).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Specifying the empty string &lt;code&gt;&#34;&#34;&lt;/code&gt; as a filename makes ImageMagick hang. (This appears to be an ImageMagick bug / misfeature).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Long filenames are wrapped, but not intelligently. Would it complicate this script too much to make it prefer to wrap on whites space, dashes, underscores, and periods? Maybe.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Directories specified on the command line are processed as if the user had cd&#39;d to that directory. It wouldn&#39;t be hard to implement recursion, but is there actually a need? I&#39;m reluctant to complicate such a simple script with command line flags.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you run &lt;code&gt;lsix foo.avi&lt;/code&gt;, you&#39;re asking for trouble.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Future Issues&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;The Sixel standard doesn&#39;t appear to have a way to query the size of the graphics screen. Reading the VT340 documentation, it appears your program has to already know the resolution of the device you&#39;re rendering on.&lt;/p&gt; &lt;p&gt;XTerm, as of version 344, has added &lt;a href=&#34;https://invisible-island.net/xterm/ctlseqs/ctlseqs.html#h2-Functions-using-CSI-_-ordered-by-the-final-character_s_&#34;&gt;a control sequence&lt;/a&gt; that solves the problem â€” &lt;code&gt;CSI ? Pi ; Pa ; Pv S&lt;/code&gt; â€” but some terminals, for example &lt;code&gt;mlterm&lt;/code&gt;, haven&#39;t yet implemented it.&lt;/p&gt; &lt;p&gt;There is an alternate way to read the window size using the dtterm WindowOps extension but it is not quite the right solution as the geometry of the Sixel graphics screen is not necessarily the same as the window size. (For example, xterm limits the graphics geometry to 1000x1000, even though the window can actually be larger.) To help with terminals such as mlterm, &lt;code&gt;lsix&lt;/code&gt; will use the dtterm WindowOps as a fallback.&lt;/p&gt; &lt;p&gt;If neither solution works, &lt;code&gt;lsix&lt;/code&gt; will assume you are on a VT340 (800x480) and can fit only 6 tiles per row.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The Sixel standard also lacks a way to query the number of color registers available. I used the extensions from &lt;code&gt;xterm&lt;/code&gt; to do so, but I do not know how widely implemented they are. If a terminal does not respond, &lt;code&gt;lsix&lt;/code&gt; presumes you&#39;re on an original vt340 and uses only 16 color registers. (Sorry, 4-gray vt330 users! Time to upgrade. ;-) )&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;a href=&#34;https://kermitproject.org/&#34;&gt;Kermit project&lt;/a&gt; created a MS-DOS terminal emulator that was popular in the late 1980s/early 1990s. Its sixel implementation is not compatible with lsix because it shows the graphics on a screen separate from the text. However, I noticed one feature in its documentation: an escape sequence to request the current graphics window size and number of colors:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt; ESC [ ? 256 n                  Request screen size report&#xA;&#xA;        Report is ESC [ ? 256; Ph; Pw; Pc n     for graphics systems&#xA;&#xA;        where   Ph is screen height in dots&#xA;                Pw is screen width in dots&#xA;                Pc is number of colors (0, 1 or 16, for none, b/w, ega/vga)&#xA;&#xA;        Report is ESC [ ? 24; 80; 0 n  for pure text mono systems.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Did any other terminal emulators ever use the sequence? Would it be worthwhile to add to &lt;code&gt;lsix&lt;/code&gt;?&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/saitoha/libsixel&#34;&gt;libsixel&lt;/a&gt; is an excellent project for writing programs that can output optimized Sixel graphics commands. Because I have a lot of respect for the project, I feel I should explain why &lt;code&gt;lsix&lt;/code&gt; does not use libsixel.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;(a) I wanted lsix to work everywhere easily. Bash and imagemagick are ubiquitous, so a shell script is a natural solution.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;(b) I wanted &lt;code&gt;lsix&lt;/code&gt; to be simple enough that it could be easily customized and extended by other people. (Including myself.)&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;(c) ImageMagick has better support for reading different formats than stb_image (the library used by libsixel&#39;s &lt;code&gt;img2sixel&lt;/code&gt;). (For example: xpm, svg, 16-bit png, and even sixel files are not recognized by img2sixel). Since ImageMagick can read all of those and write sixel output directly, it made sense to use it for both.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;(d) While libsixel is optimized and would surely be faster than ImageMagick, it&#39;s overkill. For a simple directory listing, this is plenty fast enough.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://invisible-island.net/xterm/ctlseqs/ctlseqs.html&#34;&gt;XTerm Control Sequences&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://imagemagick.org/&#34;&gt;ImageMagick&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://vt100.net/docs/vt3xx-gp/&#34;&gt;VT340 Programmer&#39;s Reference&lt;/a&gt;:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://vt100.net/docs/vt3xx-gp/chapter14.html&#34;&gt;Chapter 14&lt;/a&gt;. Sixel Graphics.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://vt100.net/docs/vt3xx-gp/chapter16.html#S16.3&#34;&gt;Chapter 16&lt;/a&gt; Difference between Level 1 and Level 2 Sixel implementations.&lt;/p&gt; &lt;p&gt;&lt;em&gt;Nota bene: this reference has the sense for DECSDM (sixel display mode) reversed! The actual behaviour of the VT340 is that when DECSDM is reset (the default), sixel scrolling is enabled. This can be done by sending &lt;em&gt;&lt;code&gt;Esc[?80l&lt;/code&gt;&lt;/em&gt;, but lsix does not do so as it would break many current terminal emulators. See issue #41 for details.&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://archive.org/details/bitsavers_decstandar0VideoSystemsReferenceManualDec91_74264381&#34;&gt;DEC STD 070 Video Systems Reference Manual&lt;/a&gt;. A weighty tome which covers nearly everything in exacting detail. I referred mostly to sections 4 (escape sequences) and 9 (sixel programming).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/hackerb9/vt340test&#34;&gt;VT340 Test&lt;/a&gt;, a project to document the actual behaviour of the DEC VT340 hardware.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;http://www.vaxhaven.com/images/f/f7/EK-PPLV2-PM-B01.pdf&#34;&gt;Digital ANSI-Compliant Printing Protocol: Level 2 Programming Reference Manual&lt;/a&gt;, Chapter 5: Sixel Graphics. An excellent and reasonably clear discussion for anyone who wants to generate or parse sixel graphics.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>