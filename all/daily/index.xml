<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-06T01:29:19Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>waylaidwanderer/node-chatgpt-api</title>
    <updated>2023-02-06T01:29:19Z</updated>
    <id>tag:github.com,2023-02-06:/waylaidwanderer/node-chatgpt-api</id>
    <link href="https://github.com/waylaidwanderer/node-chatgpt-api" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A ChatGPT implementation using the official ChatGPT model via OpenAI&#39;s API.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img alt=&#34;CLI demo&#34; src=&#34;https://raw.githubusercontent.com/waylaidwanderer/node-chatgpt-api/main/demos/cli.svg?sanitize=true&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;Update (2023-02-02)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;del&gt;Trying to use &lt;code&gt;text-chat-davinci-002-20230126&lt;/code&gt; with the OpenAI API now returns a 404 error. Someone has already found the new model name, but they are unwilling to share at this time. I will update this repository once I find the new model. If you have any leads, please open an issue or a pull request.&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;In the meantime, I&#39;ve added support for models like &lt;code&gt;text-davinci-003&lt;/code&gt;, which you can use as a drop-in replacement. Keep in mind that &lt;code&gt;text-davinci-003&lt;/code&gt; is not as good as &lt;code&gt;text-chat-davinci-002&lt;/code&gt; (which is trained via RHLF and fine-tuned to be a conversational AI), though results are still very good. &lt;strong&gt;Please note that using &lt;code&gt;text-davinci-003&lt;/code&gt; will cost you credits ($).&lt;/strong&gt;&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;Discord user @pig#8932 has found a working &lt;code&gt;text-chat-davinci-002&lt;/code&gt; model, &lt;code&gt;text-chat-davinci-002-20221122&lt;/code&gt;. I&#39;ve updated the library to use this model.&lt;/p&gt; &#xA;&lt;h1&gt;ChatGPT API&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;A ChatGPT implementation using the official ChatGPT model via OpenAI&#39;s API.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.npmjs.com/package/@waylaidwanderer/chatgpt-api&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/@waylaidwanderer/chatgpt-api.svg?sanitize=true&#34; alt=&#34;NPM&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.npmjs.com/package/@waylaidwanderer/chatgpt-api&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/dt/@waylaidwanderer/chatgpt-api&#34; alt=&#34;npm&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/waylaidwanderer/node-chatgpt-api/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-blue&#34; alt=&#34;MIT License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/waylaidwanderer/node-chatgpt-api/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/waylaidwanderer/node-chatgpt-api&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is an implementation of &lt;a href=&#34;https://chat.openai.com/chat&#34;&gt;ChatGPT&lt;/a&gt; using the official ChatGPT raw model, &lt;code&gt;text-chat-davinci-002&lt;/code&gt;. This model name &lt;code&gt;text-chat-davinci-002-20230126&lt;/code&gt; was briefly leaked while I was inspecting the network requests made by the official ChatGPT website, and I discovered that it works with the &lt;a href=&#34;https://beta.openai.com/docs/api-reference/completions&#34;&gt;OpenAI API&lt;/a&gt;. &lt;strong&gt;Usage of this model currently does not cost any credits.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;As far as I&#39;m aware, I was the first one who discovered this, and usage of the model has since been implemented in libraries like &lt;a href=&#34;https://github.com/acheong08/ChatGPT&#34;&gt;acheong08/ChatGPT&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The previous version of this library that used &lt;a href=&#34;https://github.com/transitive-bullshit/chatgpt-api&#34;&gt;transitive-bullshit/chatgpt-api&lt;/a&gt; is still available on &lt;a href=&#34;https://github.com/waylaidwanderer/node-chatgpt-api/tree/archive/old-version&#34;&gt;the &lt;code&gt;archive/old-version&lt;/code&gt; branch&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;By itself, the model does not have any conversational support, so this library uses a cache to store conversations and pass them to the model as context. This allows you to have persistent conversations with ChatGPT in a nearly identical way to the official website.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Uses the official ChatGPT raw model, &lt;code&gt;text-chat-davinci-002-20221122&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Includes an API server (with Docker support) you can run to use ChatGPT in non-Node.js applications.&lt;/li&gt; &#xA; &lt;li&gt;Includes a &lt;code&gt;ChatGPTClient&lt;/code&gt; class that you can use in your own Node.js applications.&lt;/li&gt; &#xA; &lt;li&gt;Includes a CLI interface where you can chat with ChatGPT.&lt;/li&gt; &#xA; &lt;li&gt;Replicates chat threads from the official ChatGPT website (with conversation IDs and message IDs), with persistent conversations using &lt;a href=&#34;https://www.npmjs.com/package/keyv&#34;&gt;Keyv&lt;/a&gt;. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Conversations are stored in memory by default, but you can optionally &lt;a href=&#34;https://www.npmjs.com/package/keyv#usage&#34;&gt;install a storage adapter&lt;/a&gt; to persist conversations to a database.&lt;/li&gt; &#xA;   &lt;li&gt;The &lt;code&gt;keyv-file&lt;/code&gt; adapter is also included in this package, and can be used to store conversations in a JSON file if you&#39;re using the API server or CLI (see &lt;code&gt;settings.example.js&lt;/code&gt;).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Supports configurable prompt prefixes, and custom names for the user and ChatGPT. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;In essence, this allows you to turn ChatGPT into a different character.&lt;/li&gt; &#xA;   &lt;li&gt;This is currently only configurable on a global level, but I plan to add support for per-conversation customization.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Node.js&lt;/li&gt; &#xA; &lt;li&gt;npm&lt;/li&gt; &#xA; &lt;li&gt;Docker (optional, for API server)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;OpenAI API key&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Module&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm i @waylaidwanderer/chatgpt-api&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-JS&#34;&gt;import ChatGPTClient from &#39;@waylaidwanderer/chatgpt-api&#39;;&#xA;&#xA;const clientOptions = {&#xA;  // (Optional) Parameters as described in https://platform.openai.com/docs/api-reference/completions&#xA;  modelOptions: {&#xA;    // The model is set to text-chat-davinci-002-20221122 by default, but you can override&#xA;    // it and any other parameters here&#xA;    model: &#39;text-chat-davinci-002-20221122&#39;,&#xA;  },&#xA;  // (Optional) Set custom instructions instead of &#34;You are ChatGPT...&#34;.&#xA;  // promptPrefix: &#39;You are Bob, a cowboy in Western times...&#39;,&#xA;  // (Optional) Set a custom name for the user&#xA;  // userLabel: &#39;User&#39;,&#xA;  // (Optional) Set a custom name for ChatGPT&#xA;  // chatGptLabel: &#39;ChatGPT&#39;,&#xA;  // (Optional) Set to true to enable `console.debug()` logging&#xA;  debug: false,&#xA;};&#xA;&#xA;const cacheOptions = {&#xA;  // Options for the Keyv cache, see https://www.npmjs.com/package/keyv&#xA;  // This is used for storing conversations, and supports additional drivers (conversations are stored in memory by default)&#xA;  // For example, to use a JSON file (`npm i keyv-file`) as a database:&#xA;  // store: new KeyvFile({ filename: &#39;cache.json&#39; }),&#xA;};&#xA;&#xA;const chatGptClient = new ChatGPTClient(&#39;OPENAI_API_KEY&#39;, clientOptions, cacheOptions);&#xA;&#xA;const response = await chatGptClient.sendMessage(&#39;Hello!&#39;);&#xA;console.log(response); // { response: &#39;Hi! How can I help you today?&#39;, conversationId: &#39;...&#39;, messageId: &#39;...&#39; }&#xA;&#xA;const response2 = await chatGptClient.sendMessage(&#39;Write a poem about cats.&#39;, { conversationId: response.conversationId, parentMessageId: response.messageId });&#xA;console.log(response2.response); // Cats are the best pets in the world.&#xA;&#xA;const response3 = await chatGptClient.sendMessage(&#39;Now write it in French.&#39;, { conversationId: response2.conversationId, parentMessageId: response2.messageId });&#xA;console.log(response3.response); // Les chats sont les meilleurs animaux de compagnie du monde.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;API Server&lt;/h3&gt; &#xA;&lt;p&gt;You can install the package using&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm i -g @waylaidwanderer/chatgpt-api&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;then run it using &lt;code&gt;chatgpt-api&lt;/code&gt;.&lt;br&gt; This takes an optional &lt;code&gt;--settings=&amp;lt;path_to_settings.js&amp;gt;&lt;/code&gt; parameter, or looks for &lt;code&gt;settings.js&lt;/code&gt; in the current directory if not set, with the following contents:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-JS&#34;&gt;module.exports = {&#xA;  // Your OpenAI API key&#xA;  openaiApiKey: process.env.OPENAI_API_KEY || &#39;&#39;,&#xA;  chatGptClient: {&#xA;    // (Optional) Parameters as described in https://platform.openai.com/docs/api-reference/completions&#xA;    modelOptions: {&#xA;      // The model is set to text-chat-davinci-002-20221122 by default, but you can override&#xA;      // it and any other parameters here&#xA;      model: &#39;text-chat-davinci-002-20221122&#39;,&#xA;    },&#xA;    // (Optional) Set custom instructions instead of &#34;You are ChatGPT...&#34;.&#xA;    // promptPrefix: &#39;You are Bob, a cowboy in Western times...&#39;,&#xA;    // (Optional) Set a custom name for the user&#xA;    // userLabel: &#39;User&#39;,&#xA;    // (Optional) Set a custom name for ChatGPT&#xA;    // chatGptLabel: &#39;ChatGPT&#39;,&#xA;    // (Optional) Set to true to enable `console.debug()` logging&#xA;    debug: false,&#xA;  },&#xA;  // Options for the Keyv cache, see https://www.npmjs.com/package/keyv&#xA;  // This is used for storing conversations, and supports additional drivers (conversations are stored in memory by default)&#xA;  cacheOptions: {},&#xA;  // Options for the API server&#xA;  apiOptions: {&#xA;    port: process.env.API_PORT || 3000,&#xA;    host: process.env.API_HOST || &#39;localhost&#39;,&#xA;    // (Optional) Set to true to enable `console.debug()` logging&#xA;    debug: false,&#xA;  },&#xA;  // If set, ChatGPTClient will use `keyv-file` to store conversations to this JSON file instead of in memory.&#xA;  // However, `cacheOptions.store` will override this if set&#xA;  storageFilePath: process.env.STORAGE_FILE_PATH || &#39;./cache.json&#39;,&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, you can install and run the package directly.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repository: &lt;code&gt;git clone https://github.com/waylaidwanderer/node-chatgpt-api&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Install dependencies with &lt;code&gt;npm install&lt;/code&gt; (if not using Docker)&lt;/li&gt; &#xA; &lt;li&gt;Rename &lt;code&gt;settings.example.js&lt;/code&gt; to &lt;code&gt;settings.js&lt;/code&gt; in the root directory and change the settings where required.&lt;/li&gt; &#xA; &lt;li&gt;Start the server: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;using &lt;code&gt;npm start&lt;/code&gt; or &lt;code&gt;npm run server&lt;/code&gt; (if not using Docker)&lt;/li&gt; &#xA;   &lt;li&gt;using &lt;code&gt;docker-compose up&lt;/code&gt; (requires Docker)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;To start a conversation with ChatGPT, send a POST request to the server&#39;s &lt;code&gt;/conversation&lt;/code&gt; endpoint with a JSON body in the following format:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-JSON&#34;&gt;{&#xA;    &#34;message&#34;: &#34;Hello, how are you today?&#34;,&#xA;    &#34;conversationId&#34;: &#34;your-conversation-id (optional)&#34;,&#xA;    &#34;parentMessageId&#34;: &#34;your-parent-message-id (optional)&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The server will return a JSON object containing ChatGPT&#39;s response:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-JSON&#34;&gt;{&#xA;    &#34;response&#34;: &#34;I&#39;m doing well, thank you! How are you?&#34;,&#xA;    &#34;conversationId&#34;: &#34;your-conversation-id&#34;,&#xA;    &#34;messageId&#34;: &#34;response-message-id&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the request is unsuccessful, the server will return a JSON object with an error message and a status code of 503.&lt;/p&gt; &#xA;&lt;p&gt;If there was an error sending the message to ChatGPT:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-JSON&#34;&gt;{&#xA;    &#34;error&#34;: &#34;There was an error communicating with ChatGPT.&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;CLI&lt;/h3&gt; &#xA;&lt;p&gt;Install the package using the same instructions as the API server.&lt;/p&gt; &#xA;&lt;p&gt;If installed globally:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;chatgpt-cli&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If installed locally:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run cli&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ChatGPT&#39;s responses are automatically copied to your clipboard, so you can paste them into other applications.&lt;/p&gt; &#xA;&lt;h2&gt;Caveats&lt;/h2&gt; &#xA;&lt;p&gt;Since &lt;code&gt;text-chat-davinci-002-20221122&lt;/code&gt; is ChatGPT&#39;s raw model, I had to do my best to replicate the way the official ChatGPT website uses it. After extensive testing and comparing responses, I believe that the model used by ChatGPT has some additional fine-tuning.&lt;br&gt; This means my implementation or the raw model may not behave exactly the same in some ways:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Conversations are not tied to any user IDs, so if that&#39;s important to you, you should implement your own user ID system.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ChatGPT&#39;s model parameters (temperature, frequency penalty, etc.) are unknown, so I set some defaults that I thought would be reasonable.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Conversations are limited to roughly the last 3000 tokens, so earlier messages may be forgotten during longer conversations.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This works in a similar way to ChatGPT, except I&#39;m pretty sure they have some additional way of retrieving context from earlier messages when needed (which can probably be achieved with embeddings, but I consider that out-of-scope for now).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;It is well known that, as part of the fine-tuning, ChatGPT had the following preamble:&lt;/p&gt; &#xA;  &lt;blockquote&gt; &#xA;   &lt;p&gt;&#34;You are ChatGPT, a large language model trained by OpenAI. You answer as concisely as possible for each response (e.g. don’t be verbose). It is very important that you answer as concisely as possible, so please remember this. If you are generating a list, do not have too many items. Keep the number of items short.&lt;br&gt; Knowledge cutoff: 2021-09&lt;br&gt; Current date: 2023-01-31&#34;&lt;/p&gt; &#xA;  &lt;/blockquote&gt; &lt;p&gt;As OpenAI updates ChatGPT, this preamble may also change. The default prompt prefix in my implementation attempts to replicate a similar behavior to the current ChatGPT model.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;d like to contribute to this project, please create a pull request with a detailed description of your changes.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the MIT License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Zero6992/chatGPT-discord-bot</title>
    <updated>2023-02-06T01:29:19Z</updated>
    <id>tag:github.com,2023-02-06:/Zero6992/chatGPT-discord-bot</id>
    <link href="https://github.com/Zero6992/chatGPT-discord-bot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Integrate ChatGPT into your own discord bot&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGPT Discord Bot&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;h3&gt;Build your own Discord bot using ChatGPT&lt;/h3&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;h4&gt;2023-02-03 Update: ChatGPT API working again&lt;/h4&gt; &#xA; &lt;h4&gt;2023-02-02 Update: OpenAI has closed ChatGPT API, temporarily switching to using GPT-3 model&lt;/h4&gt; &#xA; &lt;h4&gt;2023-02-01 Update: Now using the official ChatGPT API&lt;/h4&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;/chat [message]&lt;/code&gt; Chat with ChatGPT!&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/private&lt;/code&gt; ChatGPT switch to private mode&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/public&lt;/code&gt; ChatGPT switch to public mode&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/reset&lt;/code&gt; ChatGPT conversation history will be erased&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Chat&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/206497774-47d960cd-1aeb-4fba-9af5-1f9d6ff41f00.gif&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Mode&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;public mode (default)&lt;/code&gt; the bot directly reply on the channel&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/206565977-d7c5d405-fdb4-4202-bbdd-715b7c8e8415.gif&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;private mode&lt;/code&gt; the bot&#39;s reply can only be seen by the person who used the command&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/206565873-b181e600-e793-4a94-a978-47f806b986da.gif&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Setup&lt;/h1&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Rename the file &lt;code&gt;config.dev.json&lt;/code&gt; to &lt;code&gt;config.json&lt;/code&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Step 1: Create a Discord bot&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Go to &lt;a href=&#34;https://discord.com/developers/applications&#34;&gt;https://discord.com/developers/applications&lt;/a&gt; create an application&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Build a Discord bot under the application&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Get the token from bot setting&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/205949161-4b508c6d-19a7-49b6-b8ed-7525ddbef430.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Store the token to &lt;code&gt;config.json&lt;/code&gt; under the &lt;code&gt;discord_bot_token&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/207357762-94234aa7-aa55-4504-8dfd-9c68ae23a826.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Turn MESSAGE CONTENT INTENT &lt;code&gt;ON&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/205949323-4354bd7d-9bb9-4f4b-a87e-deb9933a89b5.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Invite your bot to your server via OAuth2 URL Generator&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/205949600-0c7ddb40-7e82-47a0-b59a-b089f929d177.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Step 2: Geanerate a OpenAI API key&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Go to &lt;a href=&#34;https://beta.openai.com/account/api-keys&#34;&gt;https://beta.openai.com/account/api-keys&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Click Create new secret key&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/207970699-2e0cb671-8636-4e27-b1f3-b75d6db9b57e.PNG&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Store the SECRET KEY to &lt;code&gt;config.json&lt;/code&gt; under the &lt;code&gt;openAI_key&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Step 3: Run the bot on the desktop&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open a terminal or command prompt&lt;/li&gt; &#xA; &lt;li&gt;Navigate to the directory where you installed the ChatGPT Discord bot&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;python3 main.py&lt;/code&gt; to start the bot&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Step 3: Run the bot with Docker&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Build the Docker image &amp;amp; Run the Docker container &lt;code&gt;docker compose up -d&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Inspect whether the bot works well &lt;code&gt;docker logs -t chatgpt-discord-bot&lt;/code&gt;&lt;/p&gt; &lt;h3&gt;Stop the bot:&lt;/h3&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;docker ps&lt;/code&gt; to see the list of running services&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;docker stop &amp;lt;BOT CONTAINER ID&amp;gt;&lt;/code&gt; to stop the running bot&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Have a good chat!&lt;/h3&gt; &#xA;&lt;h2&gt;Optional: Setup starting prompt&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;A starting prompt would be invoked when the bot is first started or reset&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You can set it up by modifying the content in &lt;code&gt;starting-prompt.txt&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;All the text in the file will be fired as a prompt to the bot&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Get the first message from ChatGPT in your discord channel!&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt; &lt;p&gt;Right-click the channel you want to recieve the message, &lt;code&gt;Copy ID&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/89479282/207697217-e03357b3-3b3d-44d0-b880-163217ed4a49.PNG&#34; alt=&#34;channel-id&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;paste it into &lt;code&gt;config.json&lt;/code&gt; under &lt;code&gt;discord_channel_id &lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>hikari-no-yume/touchHLE</title>
    <updated>2023-02-06T01:29:19Z</updated>
    <id>tag:github.com,2023-02-06:/hikari-no-yume/touchHLE</id>
    <link href="https://github.com/hikari-no-yume/touchHLE" rel="alternate"></link>
    <summary type="html">&lt;p&gt;High-level emulator for iPhone OS apps&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;touchHLE: high-level emulator for iPhone OS apps&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;touchHLE&lt;/strong&gt; is a high-level emulator (HLE) for iPhone OS apps. It runs on modern desktop operating systems, and is written in Rust.&lt;/p&gt; &#xA;&lt;p&gt;As an HLE, touchHLE is radically different from a low-level emulator (LLE) like QEMU. The only code the &lt;a href=&#34;https://github.com/merryhime/dynarmic&#34;&gt;emulated CPU&lt;/a&gt; executes is the app binary and &lt;a href=&#34;https://raw.githubusercontent.com/hikari-no-yume/touchHLE/trunk/touchHLE_dylibs/&#34;&gt;a handful of libraries&lt;/a&gt;; touchHLE takes the place of iPhone OS and provides its own implementations of the system frameworks (Foundation, UIKit, OpenGL ES, OpenAL, etc).&lt;/p&gt; &#xA;&lt;p&gt;The goal of this project is to run games from the early days of iOS. Only iPhone/iPod touch apps for iPhone OS 2.x have been tested so far. Modern/64-bit iOS app support is explicitly a non-goal, and support for apps that aren&#39;t games is unlikely to be prioritized due to the complexity. On the other hand, it&#39;s likely that we&#39;ll attempt to support apps for some newer 32-bit versions (especially 3.x and 4.x) and the iPad in future. iPhone OS 1.x support might be attempted also.&lt;/p&gt; &#xA;&lt;p&gt;Visit our homepage! &lt;a href=&#34;https://touchhle.org/&#34;&gt;https://touchhle.org/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Important disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This project is not affiliated with or endorsed by Apple Inc in any way. iPhone, iPhone OS, iOS, iPod, iPod touch and iPad may be trademarks of Apple Inc in the United States or other countries.&lt;/p&gt; &#xA;&lt;p&gt;Only use touchHLE to emulate software you legally own.&lt;/p&gt; &#xA;&lt;h2&gt;Platform support&lt;/h2&gt; &#xA;&lt;p&gt;touchHLE has been tested and is to be considered supported on x64 Windows and x64 macOS. It may be possible to build it on Linux and on some AArch64 systems (at least one person has succeeded), but we make no guarantees right now. If you&#39;re an Apple Silicon Mac user: don&#39;t worry, the x64 macOS build reportedly works under Rosetta.&lt;/p&gt; &#xA;&lt;p&gt;Architectures other than x64 and AArch64 are completely unsupported, and this is unlikely to change.&lt;/p&gt; &#xA;&lt;p&gt;It would be desirable to eventually support Android. That is probably not too much work.&lt;/p&gt; &#xA;&lt;p&gt;Input methods:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For simulated touch input, there are two options: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Mouse/trackpad input (tap/hold/drag by pressing the left mouse button)&lt;/li&gt; &#xA;   &lt;li&gt;Virtual cursor using the right analog stick on a game controller (tap/hold/drag by pressing the stick or the right shoulder button)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;For simulated accelerometer input (tilt controls), a game controller with a left analog stick is currently required.&lt;/strong&gt; Real accelerometer support will come soon, but it&#39;s not in the first release.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Development status&lt;/h2&gt; &#xA;&lt;p&gt;Real development started in December 2022, and this is so far &lt;a href=&#34;https://hikari.noyu.me/&#34;&gt;a single person&lt;/a&gt;&#39;s full-time passion project. There&#39;s only a single release so far and no promises can be made about the future. Please be patient.&lt;/p&gt; &#xA;&lt;p&gt;Currently, the supported functionality is not much more than what the single supported app uses. The code tries to be reasonably complete where it can, though.&lt;/p&gt; &#xA;&lt;h2&gt;App support&lt;/h2&gt; &#xA;&lt;p&gt;For pretty screenshots and video, &lt;a href=&#34;https://touchhle.org/&#34;&gt;check out the home page!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Super Monkey Ball (2008, App Store launch title), tested versions 1.0, 1.02, 1.3 (1.3 is the most heavily tested) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fully playable, everything works. Among other things: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Sound effects and music&lt;/li&gt; &#xA;     &lt;li&gt;Logo, title, menu, ranking, settings and credits screens&lt;/li&gt; &#xA;     &lt;li&gt;Main Game, Instant Game (Shuffle Play) and Practice game modes&lt;/li&gt; &#xA;     &lt;li&gt;Save game persistence (settings, unlocks, records)&lt;/li&gt; &#xA;     &lt;li&gt;Continuing a previous game after closing and reopening the app&lt;/li&gt; &#xA;     &lt;li&gt;The tutorial (in the versions that have it)&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Consistent full fps (30fps) in release builds even on a fairly underpowered laptop (2017 Retina MacBook, passively cooled!)&lt;/li&gt; &#xA;   &lt;li&gt;Special enhancement: can be run with increased internal resolution via the &lt;code&gt;--scale-hack=&lt;/code&gt; option. Resolutions up to circa 4K have been tested. No noticeable performance impact at small scales (2×, 3×).&lt;/li&gt; &#xA;   &lt;li&gt;Recommended game controller settings: &lt;code&gt;--y-tilt-offset=24&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Known issue: memory leak of approximately 0.2MB/second on macOS. All obvious issues in the emulator itself have been ruled out, so it might be a problem in macOS itself, SDL2, or some other dependency. Thankfully this is slow enough that it shouldn&#39;t be a problem for most play sessions.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;No other apps are known to work right now. This will surely improve in future. :)&lt;/p&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;p&gt;First obtain touchHLE, either a &lt;a href=&#34;https://github.com/hikari-no-yume/touchHLE/releases&#34;&gt;binary release&lt;/a&gt; or by building it yourself (see the next section).&lt;/p&gt; &#xA;&lt;p&gt;You&#39;ll then need an app that you can run. See the “App support” section above. Note that the app binary must be decrypted to be usable.&lt;/p&gt; &#xA;&lt;p&gt;There&#39;s no graphical user interface right now, so you&#39;ll usually need to use the command line to run touchHLE. For first-time users on Windows:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Move the &lt;code&gt;.ipa&lt;/code&gt; file or &lt;code&gt;.app&lt;/code&gt; bundle to the same folder as &lt;code&gt;touchHLE.exe&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Hold the Shift key and Right-click on the empty space in the folder window.&lt;/li&gt; &#xA; &lt;li&gt;Click “Open with PowerShell”.&lt;/li&gt; &#xA; &lt;li&gt;You can then type &lt;code&gt;.\touchHLE.exe &#34;YourAppNameHere.ipa&#34;&lt;/code&gt; (or &lt;code&gt;.app&lt;/code&gt; as appropriate) and press enter.&lt;/li&gt; &#xA; &lt;li&gt;You may want to type &lt;code&gt;.\touchHLE.exe&lt;/code&gt; to see the available options for things like game controllers.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Currently language detection doesn&#39;t work on Windows. To change the language preference reported to the app, you can type &lt;code&gt;SET LANG=&lt;/code&gt; followed by an ISO 639-1 language code, then press Enter, before running the app. Some common language codes are: &lt;code&gt;en&lt;/code&gt; (English), &lt;code&gt;de&lt;/code&gt; (Deutsch), &lt;code&gt;es&lt;/code&gt; (español), &lt;code&gt;fr&lt;/code&gt; (français), &lt;code&gt;it&lt;/code&gt; (italiano) and &lt;code&gt;ja&lt;/code&gt; (日本語). Bear in mind that it&#39;s the app itself that determines which languages are supported, not the emulator.&lt;/p&gt; &#xA;&lt;h1&gt;Building and contributing&lt;/h1&gt; &#xA;&lt;p&gt;Please see the BUILDING.md and CONTRIBUTING.md files in the git repo.&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;touchHLE © 2023 hikari_no_yume and other contributors.&lt;/p&gt; &#xA;&lt;p&gt;The source code of touchHLE itself (not its dependencies) is licensed under the Mozilla Public License, version 2.0.&lt;/p&gt; &#xA;&lt;p&gt;Due to license compatibility concerns, binaries are under the GNU General Public License version 3 or later.&lt;/p&gt; &#xA;&lt;p&gt;For a best effort listing of all licenses of dependencies, build touchHLE and pass the &lt;code&gt;--copyright&lt;/code&gt; flag when running it.&lt;/p&gt; &#xA;&lt;p&gt;Please note that different licensing terms apply to the bundled dynamic libraries (in &lt;code&gt;touchHLE_dylibs/&lt;/code&gt;) and fonts (in &lt;code&gt;touchHLE_fonts/&lt;/code&gt;). Please consult the respective directories for more information.&lt;/p&gt; &#xA;&lt;h1&gt;Thanks&lt;/h1&gt; &#xA;&lt;p&gt;We stand on the shoulders of giants. Thank you to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The authors of and contributors to the many libraries used by this project: &lt;a href=&#34;https://github.com/merryhime/dynarmic&#34;&gt;dynarmic&lt;/a&gt;, &lt;a href=&#34;https://github.com/flier/rust-macho&#34;&gt;rust-macho&lt;/a&gt;, &lt;a href=&#34;https://libsdl.org/&#34;&gt;SDL&lt;/a&gt;, &lt;a href=&#34;https://github.com/Rust-SDL2/rust-sdl2&#34;&gt;rust-sdl2&lt;/a&gt;, &lt;a href=&#34;https://github.com/nothings/stb&#34;&gt;stb_image&lt;/a&gt;, &lt;a href=&#34;https://github.com/kcat/openal-soft&#34;&gt;openal-soft&lt;/a&gt;, &lt;a href=&#34;https://github.com/ruuda/hound&#34;&gt;hound&lt;/a&gt;, &lt;a href=&#34;https://github.com/rustaudio/caf&#34;&gt;caf&lt;/a&gt;, &lt;a href=&#34;https://gitlab.redox-os.org/redox-os/rusttype&#34;&gt;RustType&lt;/a&gt;, &lt;a href=&#34;https://github.com/liberationfonts/liberation-fonts&#34;&gt;the Liberation fonts&lt;/a&gt;, &lt;a href=&#34;https://github.com/googlefonts/noto-cjk&#34;&gt;the Noto CJK fonts&lt;/a&gt;, &lt;a href=&#34;https://github.com/ebarnard/rust-plist&#34;&gt;rust-plist&lt;/a&gt;, &lt;a href=&#34;https://github.com/brendanzab/gl-rs&#34;&gt;gl-rs&lt;/a&gt;, &lt;a href=&#34;https://github.com/onur/cargo-license&#34;&gt;cargo-license&lt;/a&gt;, &lt;a href=&#34;https://github.com/rust-lang/cc-rs&#34;&gt;cc-rs&lt;/a&gt;, &lt;a href=&#34;https://github.com/rust-lang/cmake-rs&#34;&gt;cmake-rs&lt;/a&gt;, and the Rust standard library.&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://www.rust-lang.org/&#34;&gt;Rust project&lt;/a&gt; generally.&lt;/li&gt; &#xA; &lt;li&gt;The various people out there who&#39;ve documented the iPhone OS platform, officially or otherwise. Much of this documentation is linked to within this codebase!&lt;/li&gt; &#xA; &lt;li&gt;The iOS hacking/jailbreaking community.&lt;/li&gt; &#xA; &lt;li&gt;The Free Software Foundation, for making libgcc and libstdc++ copyleft and therefore saving this project from ABI hell.&lt;/li&gt; &#xA; &lt;li&gt;The National Security Agency of the United States of America, for &lt;a href=&#34;https://ghidra-sre.org/&#34;&gt;Ghidra&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Many friends who took an interest in the project and gave suggestions and encouragement.&lt;/li&gt; &#xA; &lt;li&gt;Developers of early iPhone OS apps. What treasures you created!&lt;/li&gt; &#xA; &lt;li&gt;Apple, and NeXT before them, for creating such fantastic platforms.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>