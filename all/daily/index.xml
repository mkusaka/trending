<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-20T01:16:13Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>damo-vilab/AnyDoor</title>
    <updated>2023-12-20T01:16:13Z</updated>
    <id>tag:github.com,2023-12-20:/damo-vilab/AnyDoor</id>
    <link href="https://github.com/damo-vilab/AnyDoor" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official implementations for paper: Anydoor: zero-shot object-level image customization&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;h2 align=&#34;center&#34;&gt;AnyDoor: Zero-shot Object-level Image Customization&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://xavierchen34.github.io/&#34;&gt;&lt;strong&gt;Xi Chen&lt;/strong&gt;&lt;/a&gt; ¬∑ &lt;a href=&#34;https://scholar.google.com/citations?user=JYVCn3AAAAAJ&amp;amp;hl=en&#34;&gt;&lt;strong&gt;Lianghua Huang&lt;/strong&gt;&lt;/a&gt; ¬∑ &lt;a href=&#34;https://scholar.google.com/citations?user=8zksQb4AAAAJ&amp;amp;hl=zh-CN&#34;&gt;&lt;strong&gt;Yu Liu&lt;/strong&gt;&lt;/a&gt; ¬∑ &lt;a href=&#34;https://shenyujun.github.io/&#34;&gt;&lt;strong&gt;Yujun Shen&lt;/strong&gt;&lt;/a&gt; ¬∑ &lt;a href=&#34;https://scholar.google.com/citations?user=7LhjCn0AAAAJ&amp;amp;hl=en&#34;&gt;&lt;strong&gt;Deli Zhao&lt;/strong&gt;&lt;/a&gt; ¬∑ &lt;a href=&#34;https://hszhao.github.io/&#34;&gt;&lt;strong&gt;Hengshuang Zhao&lt;/strong&gt;&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://arxiv.org/abs/2307.09481&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-AnyDoor-red&#34; alt=&#34;Paper PDF&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://damo-vilab.github.io/AnyDoor-Page/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project_Page-AnyDoor-green&#34; alt=&#34;Project Page&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;b&gt;The University of Hong Kong &amp;nbsp; | &amp;nbsp; Alibaba Group | &amp;nbsp; Ant Group &lt;/b&gt; &lt;/p&gt; &#xA;&lt;table align=&#34;center&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/damo-vilab/AnyDoor/main/assets/Figures/Teaser.png&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.12.17]&lt;/strong&gt; Release train &amp;amp; inference &amp;amp; demo code, and pretrained checkpoint.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[Soon]&lt;/strong&gt; Release the new version paper.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[Soon]&lt;/strong&gt; Support online demo.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[On-going]&lt;/strong&gt; Scale-up the training data and release stronger models as the foundaition model for downstream region-to-region generation tasks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[On-going]&lt;/strong&gt; Release specific-designed models for downstream tasks like virtual tryon, face swap, text and logo transfer, etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Install with &lt;code&gt;conda&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda env create -f environment.yaml&#xA;conda activate anydoor&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Additionally, for training, you need to install panopticapi, pycocotools, and lvis-api.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install git+https://github.com/cocodataset/panopticapi.git&#xA;&#xA;pip install pycocotools -i https://pypi.douban.com/simple&#xA;&#xA;pip install lvis&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Download Checkpoints&lt;/h2&gt; &#xA;&lt;p&gt;Download AnyDoor checkpoint:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ModelScope: &lt;a href=&#34;https://modelscope.cn/models/damo/AnyDoor/files&#34;&gt;https://modelscope.cn/models/damo/AnyDoor/files&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;HuggingFace: &lt;a href=&#34;https://huggingface.co/spaces/xichenhku/AnyDoor/tree/main&#34;&gt;https://huggingface.co/spaces/xichenhku/AnyDoor/tree/main&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;We include all the optimizer params for Adam, so the checkpoint is big. You could only keep the &#34;state_dict&#34; to make it much smaller.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Download DINOv2 checkpoint and revise &lt;code&gt;/configs/anydoor.yaml&lt;/code&gt; for the path (line 83)&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;URL: &lt;a href=&#34;https://github.com/facebookresearch/dinov2?tab=readme-ov-file&#34;&gt;https://github.com/facebookresearch/dinov2?tab=readme-ov-file&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Download Stable Diffusion V2.1 if you want to train from scratch.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;URL: &lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-2-1/tree/main&#34;&gt;https://huggingface.co/stabilityai/stable-diffusion-2-1/tree/main&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;p&gt;We provide inference code in &lt;code&gt;run_inference.py&lt;/code&gt; (from Line 222 - ) for both inference single image and inference a dataset (VITON-HD Test). You should modify the data path and run the following code. The generated results are provided in &lt;code&gt;examples/TestDreamBooth/GEN&lt;/code&gt; for single image, and &lt;code&gt;VITONGEN&lt;/code&gt; for VITON-HD Test.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python run_inference.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The inferenced results on VITON-Test would be like [garment, ground truth, generation].&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Noticing that AnyDoor does not contain any specific design/tuning for tryon, we think it would be helpful to add skeleton infos or warped garment, and tune on tryon data to make it better :)&lt;/em&gt;&lt;/p&gt; &#xA;&lt;table align=&#34;center&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/damo-vilab/AnyDoor/main/assets/Figures/tryon.png&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;Our evaluation data for DreamBooth an COCOEE coud be downloaded at Google Drive:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;URL: [to be released]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Gradio demo&lt;/h2&gt; &#xA;&lt;p&gt;Currently, we suport local gradio demo. To launch it, you should firstly modify &lt;code&gt;/configs/demo.yaml&lt;/code&gt; for the path to the pretrained model, and &lt;code&gt;/configs/anydoor.yaml&lt;/code&gt; for the path to DINOv2(line 83).&lt;/p&gt; &#xA;&lt;p&gt;Afterwards, run the script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python run_gradio_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The gradio demo would look like the UI shown below:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üì¢ This version requires users to annotate the mask of the target object, too coarse mask would influence the generation quality. We plan to add mask refine module or interactive segmentation modules in the demo.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table align=&#34;center&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;img src=&#34;https://raw.githubusercontent.com/damo-vilab/AnyDoor/main/assets/Figures/gradio.png&#34;&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Train&lt;/h2&gt; &#xA;&lt;h3&gt;Prepare datasets&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download the datasets that present in &lt;code&gt;/configs/datasets.yaml&lt;/code&gt; and modify the corresponding paths.&lt;/li&gt; &#xA; &lt;li&gt;You could prepare you own datasets according to the formates of files in &lt;code&gt;./datasets&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;If you use UVO dataset, you need to process the json following &lt;code&gt;./datasets/Preprocess/uvo_process.py&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;You could refer to &lt;code&gt;run_dataset_debug.py&lt;/code&gt; to verify you data is correct.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Prepare initial weight&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If your would like to train from scratch, convert the downloaded SD weights to control copy by running:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sh ./scripts/convert_weight.sh  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Start training&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Modify the training hyper-parameters in &lt;code&gt;run_train_anydoor.py&lt;/code&gt; Line 26-34 according to your training resources. We verify that using 2-A100 GPUs with batch accumulation=1 could get satisfactory results after 300,000 iterations.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Start training by executing:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sh ./scripts/train.sh  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üî• Community Contributions&lt;/h2&gt; &#xA;&lt;p&gt;@bdsqlsz&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;AnyDoor for windows: &lt;a href=&#34;https://github.com/sdbds/AnyDoor-for-windows&#34;&gt;https://github.com/sdbds/AnyDoor-for-windows&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Pruned model: &lt;a href=&#34;https://modelscope.cn/models/bdsqlsz/AnyDoor-Pruned/summary&#34;&gt;https://modelscope.cn/models/bdsqlsz/AnyDoor-Pruned/summary&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;This project is developped on the codebase of &lt;a href=&#34;https://github.com/lllyasviel/ControlNet&#34;&gt;ControlNet&lt;/a&gt;. We appreciate this great work!&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find this codebase useful for your research, please use the following entry.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-BibTeX&#34;&gt;@article{chen2023anydoor,&#xA;  title={Anydoor: Zero-shot object-level image customization},&#xA;  author={Chen, Xi and Huang, Lianghua and Liu, Yu and Shen, Yujun and Zhao, Deli and Zhao, Hengshuang},&#xA;  journal={arXiv preprint arXiv:2307.09481},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/Mastering-GitHub-Copilot-for-Paired-Programming</title>
    <updated>2023-12-20T01:16:13Z</updated>
    <id>tag:github.com,2023-12-20:/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming</id>
    <link href="https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A 6 Lesson course teaching everything you need to know about harnessing GitHub Copilot and an AI Paired Programing resource.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming/main/images/GitHub%20101%20-%20Curriculum.png&#34; alt=&#34;Mastering GitHub Copilot for AI Paired Programming&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Mastering GitHub Copilot for AI Paired Programming&lt;/h1&gt; &#xA;&lt;p&gt;A 6 Lesson course teaching everything you need to know about harnessing GitHub Copilot and an AI Paired Programing resource.&lt;/p&gt; &#xA;&lt;p&gt;Unlock the power of collaborative coding with our comprehensive curriculum on Mastering GitHub Copilot for Paired Programming. This cutting-edge program seamlessly integrates AI-driven coding assistance through GitHub Copilot, empowering students to accelerate their coding skills in tandem with a partner. Over the course of 10 engaging hours, participants will navigate through essential setup procedures, leveraging Visual Studio Code and GitHub Copilot Chat for real-time collaboration. Dive deep into GitHub Copilot&#39;s autocompletion, customizable features, and advanced programming techniques, all while embracing AI-driven algorithms. From error handling to unit testing, this curriculum is tailored to instill best practices and enhance code quality. Immerse yourself in a transformative learning experience that fuses the latest AI technology with paired programming strategies, equipping you with the tools needed for success in today&#39;s dynamic software development landscape.&lt;/p&gt; &#xA;&lt;h2&gt;üå± Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To get started, be sure to follow instructions on how to fork lessons to your own GitHub account to be able to change any code and complete the challenges. You can also &lt;a href=&#34;https://docs.github.com/en/get-started/exploring-projects-on-github/saving-repositories-with-stars?WT.mc_id=academic-113596-abartolo&#34;&gt;star (üåü) this repo&lt;/a&gt; to find it easier later.&lt;/p&gt; &#xA;&lt;p&gt;Below are the links to each lesson. Feel free to explore and start at any lesson that interests you the most!&lt;/p&gt; &#xA;&lt;h2&gt;üß† Want to learn more?&lt;/h2&gt; &#xA;&lt;p&gt;After completing this course, check out our &lt;a href=&#34;https://learn.microsoft.com/collections/kkqrhmxoqn54?WT.mc_id=academic-113596-abartolo&#34;&gt;GitHub Copilot Learn Collection&lt;/a&gt; to continue leveling up your AI Paired Programming knowledge!&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Are you a startup or got an idea you want to launch?&lt;/h2&gt; &#xA;&lt;p&gt;Sign up for &lt;a href=&#34;https://foundershub.startups.microsoft.com/signup?WT.mc_id=academic-113596-abartolo&#34;&gt;Microsoft for Startups Founders Hub&lt;/a&gt; to receive &lt;strong&gt;free OpenAI credits&lt;/strong&gt; and up to &lt;strong&gt;$150k towards Azure credits to access OpenAI models through Azure OpenAI Services&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;üôè Want to help?&lt;/h2&gt; &#xA;&lt;p&gt;Here are ways you can contribute to this course:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Find spelling errors or code errors, &lt;a href=&#34;https://github.com/microsoft/&#34;&gt;Raise an issue&lt;/a&gt; or &lt;a href=&#34;https://github.com/microsoft/&#34;&gt;Create a pull request&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Send us your ideas, maybe your ideas for new lessons or exercises, and let us know how we can improve.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìÇ Each lesson includes:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;a written lesson located in the README&lt;/li&gt; &#xA; &lt;li&gt;a challenge or assignment to apply your learning&lt;/li&gt; &#xA; &lt;li&gt;links to extra resources to continue your learning&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üóÉÔ∏è Lessons&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Lesson Link&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Concepts Taught&lt;/th&gt; &#xA;   &lt;th&gt;Learning Goal&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;01&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming/main/01-Introduction-to-GitHub/README.md?WT.mc_id=academic-113596-abartolo&#34;&gt;Introduction to GitHub&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Get started using GitHub in less than an hour.&lt;/td&gt; &#xA;   &lt;td&gt;Introduction to repositories, branches, commits, and pull requests.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;02&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming/main/02-Introduction-to-GitHub-Codespaces?WT.mc_id=academic-113596-abartolo&#34;&gt;Introduction to GitHub Codespaces&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Develop code using GitHub Codespaces and Visual Studio Code!&lt;/td&gt; &#xA;   &lt;td&gt;How to create a codespace, push code from a codespace, select a custom image, and customize a codespace.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;03&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming/main/03-Introduction-to-GitHub-Copilot?WT.mc_id=academic-113596-abartolo&#34;&gt;Introduction to GitHub Copilot&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;GitHub Copilot can help you code by offering autocomplete-style suggestions right in VS Code and Codespaces.&lt;/td&gt; &#xA;   &lt;td&gt;Creating files that will have code generated by Copilot AI for code and comment suggestions.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;04&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming/main/04-Harnessing-GitHub-Copilot-with-JavaScript?WT.mc_id=academic-113596-abartolo&#34;&gt;Harnessing GitHub Copilot with JavaScript&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Use GitHub Copilot, an AI pair programmer that offers autocomplete-style suggestions as you code, to work with JavaScript.&lt;/td&gt; &#xA;   &lt;td&gt;Enable the GitHub Copilot extension in Visual Studio Code. Craft prompts that can generate useful suggestions from GitHub Copilot. Use GitHub Copilot to improve a JavaScript project.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;05&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming/main/05-Harnessing-GitHub-Copilot-with-Python?WT.mc_id=academic-113596-abartolo&#34;&gt;Harnessing GitHub Copilot with Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Use GitHub Copilot, an AI pair programmer that offers autocomplete-style suggestions as you code, to work with Python.&lt;/td&gt; &#xA;   &lt;td&gt;Enable the GitHub Copilot extension in Visual Studio Code. Craft prompts that can generate useful suggestions from GitHub Copilot. Use GitHub Copilot to improve a Python project.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;06&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming/main/06-Creating-Mini-Game-with-GitHub-Copilot?WT.mc_id=academic-113596-abartolo&#34;&gt;Creating a Mini Game with GitHub Copilot&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Harness GitHub Copilot to assist you in building a Python based mini game.&lt;/td&gt; &#xA;   &lt;td&gt;Craft prompts that can generate useful suggestions from GitHub Copilot to incorporate gaming logic and improve your Python based game.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;üéí Other Courses&lt;/h2&gt; &#xA;&lt;p&gt;Our team produces other courses! Check out:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/ml-beginners?WT.mc_id=academic-113596-abartolo&#34;&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/datascience-beginners?WT.mc_id=academic-113596-abartolo&#34;&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/genai-beginners&#34;&gt;Generative AI for Beginners&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/ai-beginners?WT.mc_id=academic-113596-abartolo&#34;&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/webdev-beginners?WT.mc_id=academic-113596-abartolo&#34;&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/iot-beginners?WT.mc_id=academic-113596-abartolo&#34;&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-113596-abartolo&#34;&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>anoma/namada</title>
    <updated>2023-12-20T01:16:13Z</updated>
    <id>tag:github.com,2023-12-20:/anoma/namada</id>
    <link href="https://github.com/anoma/namada" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Rust implementation of Namada, a Proof-of-Stake L1 for interchain asset-agnostic privacy&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Namada&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/anoma/namada/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-GPLv3-blue.svg?sanitize=true&#34; alt=&#34;License: GPL v3&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://github.com/anoma/namada/actions/workflows/build-and-test.yml/badge.svg?branch=main&#34; alt=&#34;CI Status&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://namada.net&#34;&gt;Namada&lt;/a&gt; is a Proof-of-Stake L1 for interchain asset-agnostic privacy. Namada uses CometBFT consensus and enables multi-asset shielded transfers for any native or non-native asset. Namada features full IBC protocol support, a natively integrated Ethereum bridge, a modern proof-of-stake system with automatic reward compounding and cubic slashing, and a stake-weighted governance signalling mechanism. Users of shielded transfers are rewarded for their contributions to the privacy set in the form of native protocol tokens. A multi-asset shielded transfer wallet is provided in order to facilitate safe and private user interaction with the protocol.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Blogpost: &lt;a href=&#34;https://blog.namada.net/introducing-namada-interchain-asset-agnostic-privacy/&#34;&gt;Introducing Namada: Interchain Asset-agnostic Privacy&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìì Docs&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;dev docs: built from &lt;a href=&#34;https://raw.githubusercontent.com/anoma/namada/main/documentation/dev/&#34;&gt;dev mdBook&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Warning&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Here lay dragons: this codebase is still experimental, try at your own risk!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;üíæ Installing&lt;/h2&gt; &#xA;&lt;p&gt;There is a single command to build and install Namada executables from source (the node, the client and the wallet). This command will also verify that a compatible version of &lt;a href=&#34;https://raw.githubusercontent.com/anoma/namada/main/#dependencies&#34;&gt;CometBFT&lt;/a&gt; is available and if not, attempt to install it. Note that currently at least 16GB RAM is needed to build from source.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After installation, the main &lt;code&gt;namada&lt;/code&gt; executable will be available on path.&lt;/p&gt; &#xA;&lt;p&gt;To find how to use it, check out the &lt;a href=&#34;https://docs.namada.net/user-guide/index.html&#34;&gt;User Guide section of the docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For more detailed instructions and more install options, see the &lt;a href=&#34;https://docs.namada.net/user-guide/install/index.html&#34;&gt;Install section&lt;/a&gt; of the User Guide.&lt;/p&gt; &#xA;&lt;h2&gt;‚öôÔ∏è Development&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Build the provided validity predicate and transaction wasm modules&#xA;make build-wasm-scripts-docker&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Before submitting a PR, pls make sure to run the following&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Format the code&#xA;make fmt&#xA;&#xA;# Lint the code&#xA;make clippy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üßæ Logging&lt;/h2&gt; &#xA;&lt;p&gt;To change the log level, set &lt;code&gt;NAMADA_LOG&lt;/code&gt; environment variable to one of:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;error&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;warn&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;info&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;debug&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;trace&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The default is set to &lt;code&gt;info&lt;/code&gt; for all the modules, expect for CombetBFT ABCI, which has a lot of &lt;code&gt;debug&lt;/code&gt; logging.&lt;/p&gt; &#xA;&lt;p&gt;For more fine-grained logging levels settings, please refer to the &lt;a href=&#34;https://docs.rs/tracing-subscriber/0.2.18/tracing_subscriber/struct.EnvFilter.html#directives&#34;&gt;tracing subscriber docs&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;p&gt;To switch on logging in tests that use &lt;code&gt;#[test]&lt;/code&gt; macro from &lt;code&gt;test_log::test&lt;/code&gt;, use &lt;code&gt;RUST_LOG&lt;/code&gt; with e.g. &lt;code&gt;RUST_LOG=info cargo test -- --nocapture&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;How to contribute&lt;/h2&gt; &#xA;&lt;p&gt;Please see the &lt;a href=&#34;https://raw.githubusercontent.com/anoma/namada/main/CONTRIBUTING.md&#34;&gt;contributing page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Dependencies&lt;/h3&gt; &#xA;&lt;p&gt;The ledger currently requires &lt;a href=&#34;https://github.com/cometbft/cometbft/releases/tag/v0.37.2&#34;&gt;CometBFT v0.37.2&lt;/a&gt; is installed and available on path. This can be achieved through following &lt;a href=&#34;https://github.com/cometbft/cometbft/raw/main/docs/guides/install.md&#34;&gt;these instructions&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>