<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-22T01:29:41Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ricklamers/gpt-code-ui</title>
    <updated>2023-05-22T01:29:41Z</updated>
    <id>tag:github.com,2023-05-22:/ricklamers/gpt-code-ui</id>
    <link href="https://github.com/ricklamers/gpt-code-ui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An open source implementation of OpenAI&#39;s ChatGPT Code interpreter&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://github.com/ricklamers/gpt-code-ui/assets/1309307/9ad4061d-2e26-4407-9431-109b650fb022&#34; alt=&#34;GPT-Code logo&#34; width=&#34;240&#34;&gt; &#xA;&lt;p&gt;An open source implementation of OpenAI&#39;s ChatGPT &lt;a href=&#34;https://openai.com/blog/chatgpt-plugins#code-interpreter&#34;&gt;Code interpreter&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Simply ask the OpenAI model to do something and it will generate &amp;amp; execute the code for you.&lt;/p&gt; &#xA;&lt;p&gt;Read the &lt;a href=&#34;https://ricklamers.io/posts/gpt-code&#34;&gt;blog post&lt;/a&gt; to find out more.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Open a terminal and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pip install gpt-code-ui&#xA;$ gptcode&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;User interface&lt;/h2&gt; &#xA;&lt;img src=&#34;https://github.com/ricklamers/gpt-code-ui/assets/1309307/c29c504a-a7ed-4ae0-9360-d7224bc3e3d6&#34; alt=&#34;GPT-Code logo&#34; width=&#34;100%&#34;&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;File upload&lt;/li&gt; &#xA; &lt;li&gt;File download&lt;/li&gt; &#xA; &lt;li&gt;Context awareness (it can refer to your previous messages)&lt;/li&gt; &#xA; &lt;li&gt;Generate code&lt;/li&gt; &#xA; &lt;li&gt;Run code (Python kernel)&lt;/li&gt; &#xA; &lt;li&gt;Model switching (GPT-3.5 and GPT-4)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Misc.&lt;/h2&gt; &#xA;&lt;h3&gt;Using .env for OpenAI key&lt;/h3&gt; &#xA;&lt;p&gt;You can put a .env in the working directory to load the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; environment variable.&lt;/p&gt; &#xA;&lt;h3&gt;Configurables&lt;/h3&gt; &#xA;&lt;p&gt;Set the &lt;code&gt;API_PORT&lt;/code&gt; and &lt;code&gt;WEB_PORT&lt;/code&gt; variables to override the defaults.&lt;/p&gt; &#xA;&lt;p&gt;Set &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt; to change the OpenAI API endpoint that&#39;s being used (note this environment variable includes the protocol &lt;code&gt;https://...&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please do and have a look at the &lt;a href=&#34;https://raw.githubusercontent.com/ricklamers/gpt-code-ui/main/.github/CONTRIBUTING.md&#34;&gt;contributions guide&lt;/a&gt;! This should be a community initiative. I&#39;ll try my best to be responsive.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>XingangPan/DragGAN</title>
    <updated>2023-05-22T01:29:41Z</updated>
    <id>tag:github.com,2023-05-22:/XingangPan/DragGAN</id>
    <link href="https://github.com/XingangPan/DragGAN" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Code for DragGAN (SIGGRAPH 2023)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/XingangPan/DragGAN/main/DragGAN.gif&#34; , width=&#34;700&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Figure:&lt;/strong&gt; &lt;em&gt;Drag your GAN.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold&lt;/strong&gt; &lt;br&gt; Xingang Pan, Ayush Tewari, Thomas Leimkühler, Lingjie Liu, Abhimitra Meka, Christian Theobalt&lt;br&gt; &lt;em&gt;SIGGRAPH 2023 Conference Proceedings&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Code will be released in June.&lt;/p&gt; &#xA;&lt;h2&gt;BibTeX&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{pan2023draggan,&#xA;    title={Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold}, &#xA;    author={Pan, Xingang and Tewari, Ayush, and Leimk{\&#34;u}hler, Thomas and Liu, Lingjie and Meka, Abhimitra and Theobalt, Christian},&#xA;    booktitle = {ACM SIGGRAPH 2023 Conference Proceedings},&#xA;    year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>w-okada/voice-changer</title>
    <updated>2023-05-22T01:29:41Z</updated>
    <id>tag:github.com,2023-05-22:/w-okada/voice-changer</id>
    <link href="https://github.com/w-okada/voice-changer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;リアルタイムボイスチェンジャー Realtime Voice Changer&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;VC Client&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/w-okada/voice-changer/master/README_en.md&#34;&gt;English&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What&#39;s New!&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;v.1.5.3.2&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;support rvc v2&lt;/li&gt; &#xA;   &lt;li&gt;update setting of stored models&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;v.1.5.3.1&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;support sample models&lt;/li&gt; &#xA;   &lt;li&gt;store uploaded models&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;v.1.5.2.9a&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;fix: ServerDeviceMode Channel Setting&lt;/li&gt; &#xA;   &lt;li&gt;fix: model merge issue&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;v.1.5.2.9&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Support DDSP-SVC 3.0 (Ph.1)&lt;/li&gt; &#xA;   &lt;li&gt;Server Device Mode (experimental)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;VC Client とは&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;各種音声変換 AI(VC, Voice Conversion)を用いてリアルタイム音声変換を行うためのクライアントソフトウェアです。サポートしている音声変換 AI は次のものになります。&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;サポートする音声変換 AI （サポート VC） &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/isletennos/MMVC_Trainer&#34;&gt;MMVC&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/svc-develop-team/so-vits-svc&#34;&gt;so-vits-svc&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/liujing04/Retrieval-based-Voice-Conversion-WebUI&#34;&gt;RVC(Retrieval-based-Voice-Conversion)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/yxlllc/DDSP-SVC&#34;&gt;DDSP-SVC&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;本ソフトウェアは、ネットワークを介した利用も可能であり、ゲームなどの高負荷なアプリケーションと同時に使用する場合などに音声変換処理の負荷を外部にオフロードすることができます。&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/48346627/206640768-53f6052d-0a96-403b-a06c-6714a0b7471d.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;複数のプラットフォームに対応しています。&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Windows, Mac(M1), Linux, Google Colab (MMVC のみ)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;使用方法&lt;/h1&gt; &#xA;&lt;!-- 詳細は[こちら](https://zenn.dev/wok/books/0004_vc-client-v_1_5_1_x)に纏まっています。 --&gt; &#xA;&lt;p&gt;大きく 2 つの方法でご利用できます。難易度順に次の通りです。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;事前ビルド済みの Binary での利用&lt;/li&gt; &#xA; &lt;li&gt;Docker や Anaconda など環境構築を行った上での利用&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;本ソフトウェアや MMVC になじみの薄い方は上から徐々に慣れていくとよいと思います。&lt;/p&gt; &#xA;&lt;h2&gt;(1) 事前ビルド済みの Binary での利用&lt;/h2&gt; &#xA;&lt;p&gt;実行形式のバイナリをダウンロードして実行することができます。 Windows 版と Mac 版を提供しています。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Windows 版は、ダウンロードした zip ファイルを解凍して、&lt;code&gt;start_http.bat&lt;/code&gt;を実行してください。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Mac 版はダウンロードファイルを解凍したのちに、&lt;code&gt;startHttp.command&lt;/code&gt;を実行してください。開発元を検証できない旨が示される場合は、再度コントロールキーを押してクリックして実行してください(or 右クリックから実行してください)。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;初回起動時は各種データをダウンロードします。ダウンロードに時間がかかる可能性があります。ダウンロードが完了すると、ブラウザが立ち上がります。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;リモートから接続する場合は、&lt;code&gt;.bat&lt;/code&gt;ファイル(win)、&lt;code&gt;.command&lt;/code&gt;ファイル(mac)の http が https に置き換わっているものを使用してください。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;DDPS-SVC の encoder は hubert-soft のみ対応です。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;RVC で使用する場合の GUI の各項目説明は&lt;a href=&#34;https://raw.githubusercontent.com/w-okada/voice-changer/master/tutorials/tutorial_rvc_ja_latest.md&#34;&gt;こちら&lt;/a&gt;をご覧ください&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ダウンロードはこちらから。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Version&lt;/th&gt; &#xA;   &lt;th&gt;OS&lt;/th&gt; &#xA;   &lt;th&gt;フレームワーク&lt;/th&gt; &#xA;   &lt;th&gt;link&lt;/th&gt; &#xA;   &lt;th&gt;サポート VC&lt;/th&gt; &#xA;   &lt;th&gt;サイズ&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v.1.5.3.2&lt;/td&gt; &#xA;   &lt;td&gt;mac&lt;/td&gt; &#xA;   &lt;td&gt;ONNX(cpu), PyTorch(cpu,mps)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/uc?id=1K0oO6UbDUgtiZ59CUHB1VItsG_6ztSHS&amp;amp;export=download&#34;&gt;normal&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MMVC v.1.5.x, MMVC v.1.3.x, so-vits-svc 4.0, RVC&lt;/td&gt; &#xA;   &lt;td&gt;797MB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;win&lt;/td&gt; &#xA;   &lt;td&gt;ONNX(cpu,cuda), PyTorch(cpu,cuda)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/uc?id=1m791W_wEx6TO135mEPNGngYBL4RLQvDO&amp;amp;export=download&#34;&gt;normal&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MMVC v.1.5.x, MMVC v.1.3.x, so-vits-svc 4.0, so-vits-svc 4.0v2, RVC, DDSP-SVC&lt;/td&gt; &#xA;   &lt;td&gt;2873MB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;(*1) Google Drive からダウンロードできない方は&lt;a href=&#34;https://huggingface.co/wok000/vcclient000/tree/main&#34;&gt;hugging_face&lt;/a&gt;からダウンロードしてみてください (*2) 開発者が AMD のグラフィックボードを持っていないので動作確認していません。onnxruntime-directml を同梱しただけのものです。 (*3) 解凍や起動が遅い場合、ウィルス対策ソフトのチェックが走っている可能性があります。ファイルやフォルダを対象外にして実行してみてください。（自己責任です）&lt;/p&gt; &#xA;&lt;h2&gt;(2) Docker や Anaconda など環境構築を行った上での利用&lt;/h2&gt; &#xA;&lt;p&gt;本リポジトリをクローンして利用します。Windows では WSL2 の環境構築が必須になります。また、WSL2 上で Docker もしくは Anaconda などの仮想環境の構築が必要となります。Mac では Anaconda などの Python の仮想環境の構築が必要となります。事前準備が必要となりますが、多くの環境においてこの方法が一番高速で動きます。&lt;strong&gt;&lt;font color=&#34;red&#34;&gt; GPU が無くてもそこそこ新しい CPU であれば十分動く可能性があります &lt;/font&gt;（下記のリアルタイム性の節を参照）&lt;/strong&gt;。&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/POo_Cg0eFMU&#34;&gt;WSL2 と Docker のインストールの解説動画&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/fba9Zhsukqw&#34;&gt;WSL2 と Anaconda のインストールの解説動画&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Docker での実行は、&lt;a href=&#34;https://raw.githubusercontent.com/w-okada/voice-changer/master/docker_vcclient/README.md&#34;&gt;Docker を使用する&lt;/a&gt;を参考にサーバを起動してください。&lt;/p&gt; &#xA;&lt;p&gt;Anaconda の仮想環境上での実行は、&lt;a href=&#34;https://raw.githubusercontent.com/w-okada/voice-changer/master/README_dev_ja.md&#34;&gt;サーバ開発者向けのページ&lt;/a&gt;を参考にサーバを起動してください。&lt;/p&gt; &#xA;&lt;h1&gt;トラブルシュート&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/w-okada/voice-changer/master/tutorials/trouble_shoot_communication_ja.md&#34;&gt;通信編&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;リアルタイム性（MMVC）&lt;/h1&gt; &#xA;&lt;p&gt;GPU を使用するとほとんどタイムラグなく変換可能です。&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/DannadoriYellow/status/1613483372579545088?s=20&amp;amp;t=7CLD79h1F3dfKiTb7M8RUQ&#34;&gt;https://twitter.com/DannadoriYellow/status/1613483372579545088?s=20&amp;amp;t=7CLD79h1F3dfKiTb7M8RUQ&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;CPU でも最近のであればそれなりの速度で変換可能。&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/DannadoriYellow/status/1613553862773997569?s=20&amp;amp;t=7CLD79h1F3dfKiTb7M8RUQ&#34;&gt;https://twitter.com/DannadoriYellow/status/1613553862773997569?s=20&amp;amp;t=7CLD79h1F3dfKiTb7M8RUQ&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;古い CPU( i7-4770)だと、1000msec くらいかかってしまう。&lt;/p&gt; &#xA;&lt;h1&gt;開発者の署名について&lt;/h1&gt; &#xA;&lt;p&gt;本ソフトウェアは開発元の署名しておりません。下記のように警告が出ますが、コントロールキーを押しながらアイコンをクリックすると実行できるようになります。これは Apple のセキュリティポリシーによるものです。実行は自己責任となります。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/48346627/212567711-c4a8d599-e24c-4fa3-8145-a5df7211f023.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Acknowledgments&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://seiga.nicovideo.jp/seiga/im10792934&#34;&gt;立ちずんだもん素材&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.irasutoya.com/&#34;&gt;いらすとや&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tyc.rei-yumesaki.net/&#34;&gt;つくよみちゃん&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;  本ソフトウェアの音声合成には、フリー素材キャラクター「つくよみちゃん」が無料公開している音声データを使用しています。&#xA;  ■つくよみちゃんコーパス（CV.夢前黎）&#xA;  https://tyc.rei-yumesaki.net/material/corpus/&#xA;  © Rei Yumesaki&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://amitaro.net/&#34;&gt;あみたろの声素材工房&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kikyohiroto1227.wixsite.com/kikoto-utau&#34;&gt;れぷりかどーる&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;利用規約&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;リアルタイムボイスチェンジャーつくよみちゃんについては、つくよみちゃんコーパスの利用規約に準じ、次の目的で変換後の音声を使用することを禁止します。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;■人を批判・攻撃すること。（「批判・攻撃」の定義は、つくよみちゃんキャラクターライセンスに準じます）&#xA;&#xA;■特定の政治的立場・宗教・思想への賛同または反対を呼びかけること。&#xA;&#xA;■刺激の強い表現をゾーニングなしで公開すること。&#xA;&#xA;■他者に対して二次利用（素材としての利用）を許可する形で公開すること。&#xA;※鑑賞用の作品として配布・販売していただくことは問題ございません。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;リアルタイムボイスチェンジャーあみたろについては、あみたろの声素材工房様の次の利用規約に準じます。詳細は&lt;a href=&#34;https://amitaro.net/voice/faq/#index_id6&#34;&gt;こちら&lt;/a&gt;です。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;あみたろの声素材やコーパス読み上げ音声を使って音声モデルを作ったり、ボイスチェンジャーや声質変換などを使用して、自分の声をあみたろの声に変換して使うのもOKです。&#xA;&#xA;ただしその場合は絶対に、あみたろ（もしくは小春音アミ）の声に声質変換していることを明記し、あみたろ（および小春音アミ）が話しているわけではないことが誰でもわかるようにしてください。&#xA;また、あみたろの声で話す内容は声素材の利用規約の範囲内のみとし、センシティブな発言などはしないでください。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;リアルタイムボイスチェンジャー黄琴まひろについては、れぷりかどーるの利用規約に準じます。詳細は&lt;a href=&#34;https://kikyohiroto1227.wixsite.com/kikoto-utau/ter%EF%BD%8Ds-of-service&#34;&gt;こちら&lt;/a&gt;です。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;免責事項&lt;/h1&gt; &#xA;&lt;p&gt;本ソフトウェアの使用または使用不能により生じたいかなる直接損害・間接損害・波及的損害・結果的損害 または特別損害についても、一切責任を負いません。&lt;/p&gt; &#xA;&lt;h1&gt;(1) レコーダー（トレーニング用音声録音アプリ）&lt;/h1&gt; &#xA;&lt;p&gt;MMVC トレーニング用の音声を簡単に録音できるアプリです。 Github Pages 上で実行できるため、ブラウザのみあれば様々なプラットフォームからご利用可能です。 録音したデータは、ブラウザ上に保存されます。外部に漏れることはありません。&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://w-okada.github.io/voice-changer/&#34;&gt;録音アプリ on Github Pages&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/s_GirFEGvaA&#34;&gt;解説動画&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;過去バージョン&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Version&lt;/th&gt; &#xA;   &lt;th&gt;OS&lt;/th&gt; &#xA;   &lt;th&gt;フレームワーク&lt;/th&gt; &#xA;   &lt;th&gt;link&lt;/th&gt; &#xA;   &lt;th&gt;サポート VC&lt;/th&gt; &#xA;   &lt;th&gt;サイズ&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v.1.5.2.9e&lt;/td&gt; &#xA;   &lt;td&gt;mac&lt;/td&gt; &#xA;   &lt;td&gt;ONNX(cpu), PyTorch(cpu,mps)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/uc?id=1W0d7I7619PcO7kjb1SPXp6MmH5Unvd78&amp;amp;export=download&#34;&gt;normal&lt;/a&gt; *1&lt;/td&gt; &#xA;   &lt;td&gt;MMVC v.1.5.x, MMVC v.1.3.x, so-vits-svc 4.0, RVC&lt;/td&gt; &#xA;   &lt;td&gt;796MB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;win&lt;/td&gt; &#xA;   &lt;td&gt;ONNX(cpu,cuda), PyTorch(cpu,cuda)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/uc?id=1tmTMJRRggS2Sb4goU-eHlRvUBR88RZDl&amp;amp;export=download&#34;&gt;normal&lt;/a&gt; *1&lt;/td&gt; &#xA;   &lt;td&gt;MMVC v.1.5.x, MMVC v.1.3.x, so-vits-svc 4.0, so-vits-svc 4.0v2, RVC, DDSP-SVC&lt;/td&gt; &#xA;   &lt;td&gt;2872MB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;v.1.5.3.1&lt;/td&gt; &#xA;   &lt;td&gt;mac&lt;/td&gt; &#xA;   &lt;td&gt;ONNX(cpu), PyTorch(cpu,mps)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/uc?id=1oswF72q_cQQeXhIn6W275qLnoBAmcrR_&amp;amp;export=download&#34;&gt;normal&lt;/a&gt; *1&lt;/td&gt; &#xA;   &lt;td&gt;MMVC v.1.5.x, MMVC v.1.3.x, so-vits-svc 4.0, RVC&lt;/td&gt; &#xA;   &lt;td&gt;796MB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;win&lt;/td&gt; &#xA;   &lt;td&gt;ONNX(cpu,cuda), PyTorch(cpu,cuda)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/uc?id=1AWjDhW4w2Uljp1-9P8YUJBZsIlnhkJX2&amp;amp;export=download&#34;&gt;normal&lt;/a&gt; *1&lt;/td&gt; &#xA;   &lt;td&gt;MMVC v.1.5.x, MMVC v.1.3.x, so-vits-svc 4.0, so-vits-svc 4.0v2, RVC, DDSP-SVC&lt;/td&gt; &#xA;   &lt;td&gt;2872MB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
</feed>