<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-23T01:29:45Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>FlagAlpha/Llama2-Chinese</title>
    <updated>2023-07-23T01:29:45Z</updated>
    <id>tag:github.com,2023-07-23:/FlagAlpha/Llama2-Chinese</id>
    <link href="https://github.com/FlagAlpha/Llama2-Chinese" rel="alternate"></link>
    <summary type="html">&lt;p&gt;最好的中文Llama大模型，完全开源可商用&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; Llama2-Chinese &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/assets/llama.png&#34; alt=&#34;Llama&#34; style=&#34;width: 20%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;font face=&#34;黑体&#34; color=&#34;orange&#34; size=&#34;6&#34;&gt; 最好的中文Llama大模型 &lt;/font&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://llama.family&#34;&gt;在线体验：llama.family&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🗂️ 内容导引&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E5%9B%BD%E5%86%85llama2%E6%9C%80%E6%96%B0%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%E4%B8%8A%E7%BA%BF&#34;&gt;🐼 国内Llama2最新下载地址上线！&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E7%A4%BE%E5%8C%BA%E4%BB%8B%E7%BB%8Dllama2%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA&#34;&gt;🔥 社区介绍：Llama2中文社区&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E6%8B%A9llama2%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA&#34;&gt;为什么选择Llama2中文社区？&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E7%A4%BE%E5%8C%BA%E6%B4%BB%E5%8A%A8&#34;&gt;社区活动&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E7%AB%8B%E5%8D%B3%E5%8A%A0%E5%85%A5%E6%88%91%E4%BB%AC&#34;&gt;立即加入我们！&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E7%A4%BE%E5%8C%BA%E5%85%AC%E5%91%8A&#34;&gt;📢 社区公告&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8822%E6%97%A5llama2%E5%9C%A8%E7%BA%BF%E4%BD%93%E9%AA%8C%E9%93%BE%E6%8E%A5llamafamily%E4%B8%8A%E7%BA%BF%E5%90%8C%E6%97%B6%E5%8C%85%E5%90%ABmeta%E5%8E%9F%E7%89%88%E5%92%8C%E4%B8%AD%E6%96%87%E5%BE%AE%E8%B0%83%E7%89%88%E6%9C%AC&#34;&gt;2023年7月22日：Llama2在线体验链接llama.family上线，同时包含Meta原版和中文微调版本！&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8821%E6%97%A5%E8%AF%84%E6%B5%8B%E4%BA%86meta%E5%8E%9F%E5%A7%8B%E7%89%88llama2-chat%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%AD%E6%96%87%E9%97%AE%E7%AD%94%E8%83%BD%E5%8A%9B&#34;&gt;2023年7月21日：评测了Meta原始版Llama2 Chat模型的中文问答能力！&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8821%E6%97%A5%E6%96%B0%E5%A2%9Ellama2%E6%A8%A1%E5%9E%8B%E7%9A%84huggingface%E7%89%88%E6%9C%AC%E5%9B%BD%E5%86%85%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80&#34;&gt;2023年7月21日：新增Llama2模型的Huggingface版本国内下载地址！&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8820%E6%97%A5%E6%96%B0%E5%A2%9E%E9%A3%9E%E4%B9%A6%E7%9F%A5%E8%AF%86%E5%BA%93%E6%96%87%E6%A1%A3%E6%AC%A2%E8%BF%8E%E5%A4%A7%E5%AE%B6%E4%B8%80%E8%B5%B7%E5%85%B1%E5%BB%BA&#34;&gt;2023年7月20日：新增飞书知识库文档，欢迎大家一起共建！&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8820%E6%97%A5%E5%9B%BD%E5%86%85llama2%E6%9C%80%E6%96%B0%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%E4%B8%8A%E7%BA%BF&#34;&gt;2023年7月20日：国内Llama2最新下载地址上线！&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8819%E6%97%A5%E6%AD%A3%E5%BC%8F%E5%90%AF%E5%8A%A8llama2%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E5%85%B3%E6%B3%A8%E6%88%91%E4%BB%AC%E8%8E%B7%E5%8F%96%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81&#34;&gt;2023年7月19日：正式启动Llama2模型的中文预训练，关注我们获取实时动态！&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8819%E6%97%A5llama2%E5%9B%BD%E5%86%85%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%E6%AD%A3%E5%9C%A8%E5%90%AF%E5%8A%A8%E6%95%AC%E8%AF%B7%E6%9C%9F%E5%BE%85&#34;&gt;2023年7月19日：Llama2国内下载地址正在启动，敬请期待！&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#2023%E5%B9%B47%E6%9C%8819%E6%97%A5%E5%BC%80%E5%90%AFllama2%E4%B8%AD%E6%96%87%E7%A4%BE%E5%8C%BA%E6%AC%A2%E8%BF%8E%E5%A4%A7%E5%AE%B6%E5%8A%A0%E5%85%A5&#34;&gt;2023年7月19日：开启Llama2中文社区，欢迎大家加入！&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90&#34;&gt;📝 数据来源&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2&#34;&gt;⏬ 模型部署&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B&#34;&gt;预训练模型&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#chat%E6%A8%A1%E5%9E%8B&#34;&gt;Chat模型&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%94%A8%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B&#34;&gt;模型调用代码示例&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#gradio%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E9%97%AE%E7%AD%94%E5%B9%B3%E5%8F%B0&#34;&gt;Gradio快速搭建问答平台&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83&#34;&gt;💡 模型微调&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#step1-%E7%8E%AF%E5%A2%83%E5%92%8C%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87&#34;&gt;Step1: 环境和数据准备&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#step2-%E5%BE%AE%E8%B0%83%E8%84%9A%E6%9C%AC&#34;&gt;Step2: 微调脚本&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B&#34;&gt;🥇 模型评测&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99&#34;&gt;📖 学习资料&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#meta%E5%AE%98%E6%96%B9%E5%AF%B9%E4%BA%8Ellama2%E7%9A%84%E4%BB%8B%E7%BB%8D&#34;&gt;Meta官方对于Llama2的介绍&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#llama%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87&#34;&gt;Llama相关论文&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#llama2%E7%9A%84%E8%AF%84%E6%B5%8B%E7%BB%93%E6%9E%9C&#34;&gt;Llama2的评测结果&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E8%87%B4%E8%B0%A2&#34;&gt;🎉 致谢&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E9%97%AE%E9%A2%98%E5%8F%8D%E9%A6%88&#34;&gt;🤔 问题反馈&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🐼 国内Llama2最新下载地址上线！&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-7B官网版本：&lt;a href=&#34;https://pan.xunlei.com/s/VN_kR2fwuJdG1F3CoF33rwpIA1?pwd=z9kf&#34;&gt;https://pan.xunlei.com/s/VN_kR2fwuJdG1F3CoF33rwpIA1?pwd=z9kf&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-7B-Chat官网版本：&lt;a href=&#34;https://pan.xunlei.com/s/VN_kQa1_HBvV-X9QVI6jV2kOA1?pwd=xmra&#34;&gt;https://pan.xunlei.com/s/VN_kQa1_HBvV-X9QVI6jV2kOA1?pwd=xmra&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-13B官网版本：&lt;a href=&#34;https://pan.xunlei.com/s/VN_izibaMDoptluWodzJw4cRA1?pwd=2qqb&#34;&gt;https://pan.xunlei.com/s/VN_izibaMDoptluWodzJw4cRA1?pwd=2qqb&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-13B-Chat官网版本：&lt;a href=&#34;https://pan.xunlei.com/s/VN_iyyponyapjIDLXJCNfqy7A1?pwd=t3xw&#34;&gt;https://pan.xunlei.com/s/VN_iyyponyapjIDLXJCNfqy7A1?pwd=t3xw&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-7B Huggingface版本：&lt;a href=&#34;https://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep&#34;&gt;https://pan.xunlei.com/s/VN_t0dUikZqOwt-5DZWHuMvqA1?pwd=66ep&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-7B-Chat Huggingface版本：&lt;a href=&#34;https://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir&#34;&gt;https://pan.xunlei.com/s/VN_oaV4BpKFgKLto4KgOhBcaA1?pwd=ufir&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-13B Huggingface版本：&lt;a href=&#34;https://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf&#34;&gt;https://pan.xunlei.com/s/VN_yT_9G8xNOz0SDWQ7Mb_GZA1?pwd=yvgf&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Llama2-13B-Chat Huggingface版本：&lt;a href=&#34;https://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg&#34;&gt;https://pan.xunlei.com/s/VN_yA-9G34NGL9B79b3OQZZGA1?pwd=xqrg&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🔥 社区介绍：Llama2中文社区&lt;/h2&gt; &#xA;&lt;p&gt;欢迎来到Llama2中文社区！我们是一个专注于Llama2模型在中文方面的优化和上层建设的高级技术社区。 &lt;strong&gt;*基于大规模中文数据，从预训练开始对Llama2模型进行中文能力的持续迭代升级*&lt;/strong&gt;。 我们热忱欢迎对大模型LLM充满热情的开发者和研究者加入我们的行列。&lt;/p&gt; &#xA;&lt;h3&gt;为什么选择Llama2中文社区？&lt;/h3&gt; &#xA;&lt;p&gt;🚀 &lt;strong&gt;高级工程师团队支持&lt;/strong&gt;：社区有一批专注为大家服务的NLP高级工程师，我们有着强大的技术支持和丰富的经验，为您提供专业的指导和帮助。&lt;/p&gt; &#xA;&lt;p&gt;🎯 &lt;strong&gt;中文优化&lt;/strong&gt;：我们致力于在Llama2模型的中文处理方面进行优化，探索适用于中文的最佳实践，以提升其性能和适应性。&lt;/p&gt; &#xA;&lt;p&gt;💡 &lt;strong&gt;创新交流&lt;/strong&gt;：我们拥有一支富有创造力和经验的社区成员团队，定期组织线上活动、技术研讨和经验分享，促进成员间的创新交流。&lt;/p&gt; &#xA;&lt;p&gt;🌐 &lt;strong&gt;全球联结&lt;/strong&gt;：我们欢迎来自世界各地的开发者加入社区，构建一个开放、多元化的学习和交流平台。&lt;/p&gt; &#xA;&lt;p&gt;🤝 &lt;strong&gt;开放共享&lt;/strong&gt;：我们鼓励社区成员开源分享代码和模型，推动合作共赢，共同促进中文NLP技术的发展。&lt;/p&gt; &#xA;&lt;h3&gt;社区活动&lt;/h3&gt; &#xA;&lt;p&gt;🗓️ &lt;strong&gt;线上讲座&lt;/strong&gt;：邀请行业内专家进行线上讲座，分享Llama2在中文NLP领域的最新技术和应用，探讨前沿研究成果。&lt;/p&gt; &#xA;&lt;p&gt;💻 &lt;strong&gt;项目展示&lt;/strong&gt;：成员可展示自己在Llama2中文优化方面的项目成果，获得反馈和建议，促进项目协作。&lt;/p&gt; &#xA;&lt;p&gt;📚 &lt;strong&gt;学习资源&lt;/strong&gt;：社区维护丰富的学习资料库，包括教程、文档和论文解读，为成员提供全面的学习支持。&lt;/p&gt; &#xA;&lt;p&gt;📝 &lt;strong&gt;论文解读&lt;/strong&gt;：社区成员共同解读与Llama2相关的最新研究论文，深入理解前沿算法和方法。&lt;/p&gt; &#xA;&lt;p&gt;🎉 &lt;strong&gt;主题活动&lt;/strong&gt;：定期举办各类主题活动，包括挑战赛、黑客马拉松和技术沙龙，让社区成员在轻松愉快的氛围中交流和学习。&lt;/p&gt; &#xA;&lt;p&gt;🌟 &lt;strong&gt;奖励计划&lt;/strong&gt;：我们设立奖励计划，对社区中积极参与、贡献优秀的成员给予荣誉和奖励，激励更多优秀人才的加入。&lt;/p&gt; &#xA;&lt;p&gt;📈 &lt;strong&gt;技术咨询&lt;/strong&gt;：我们提供技术咨询服务，解答您在Llama2开发和优化过程中遇到的问题，助您快速攻克难关。&lt;/p&gt; &#xA;&lt;p&gt;🚀 &lt;strong&gt;项目合作&lt;/strong&gt;：鼓励成员间的项目合作，共同探索Llama2在实际应用中的潜力，打造创新解决方案。&lt;/p&gt; &#xA;&lt;h3&gt;立即加入我们！&lt;/h3&gt; &#xA;&lt;p&gt;📚 &lt;strong&gt;愿景&lt;/strong&gt;：无论您是对Llama2已有研究和应用经验的专业开发者，还是对Llama2中文优化感兴趣并希望深入探索的新手，我们都热切期待您的加入。在Llama2中文社区，您将有机会与行业内顶尖人才共同交流，携手推动中文NLP技术的进步，开创更加美好的技术未来！&lt;/p&gt; &#xA;&lt;p&gt;🔗 &lt;strong&gt;温馨提示&lt;/strong&gt;：本社区为专业技术交流平台，我们热切期望志同道合的开发者和研究者加入。请遵守社区准则，共同维护积极向上的学习氛围，任何与Llama2无关的内容和广告将被清理。感谢您的理解和支持！&lt;/p&gt; &#xA;&lt;h2&gt;📢 社区公告&lt;/h2&gt; &#xA;&lt;h4&gt;2023年7月22日：Llama2在线体验链接&lt;a href=&#34;https://llama.family/&#34;&gt;llama.family&lt;/a&gt;上线，同时包含Meta原版和中文微调版本！&lt;/h4&gt; &#xA;&lt;h4&gt;2023年7月21日：评测了Meta原始版Llama2 Chat模型的&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/#-%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B&#34;&gt;中文问答能力&lt;/a&gt;！&lt;/h4&gt; &#xA;&lt;h4&gt;2023年7月21日：新增Llama2模型的Huggingface版本国内下载地址！&lt;/h4&gt; &#xA;&lt;h4&gt;2023年7月20日：新增&lt;a href=&#34;https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink&#34;&gt;飞书知识库文档&lt;/a&gt;，欢迎大家一起共建！&lt;/h4&gt; &#xA;&lt;h4&gt;2023年7月20日：国内Llama2最新下载地址上线！&lt;/h4&gt; &#xA;&lt;h4&gt;2023年7月19日：正式启动Llama2模型的中文预训练，关注我们获取实时动态！&lt;/h4&gt; &#xA;&lt;h4&gt;2023年7月19日：Llama2国内下载地址正在启动，敬请期待！&lt;/h4&gt; &#xA;&lt;h4&gt;2023年7月19日：开启Llama2中文社区，欢迎大家加入！&lt;/h4&gt; &#xA;&lt;h2&gt;📝 数据来源&lt;/h2&gt; &#xA;&lt;p&gt;我们计划通过以下数据来优化Llama2的中文能力:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;类型&lt;/th&gt; &#xA;   &lt;th&gt;描述&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;网络数据&lt;/td&gt; &#xA;   &lt;td&gt;互联网上公开的网络数据，挑选出去重后的高质量中文数据，涉及到百科、书籍、博客、新闻、公告、小说等高质量长文本数据。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/goldsmith/Wikipedia&#34;&gt;Wikipedia&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;中文Wikipedia的数据&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/BAAI-WuDao/Model&#34;&gt;悟道&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;中文悟道开源的200G数据&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/CLUEbenchmark/CLUEDatasetSearch&#34;&gt;Clue&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Clue开放的中文预训练数据，进行清洗后的高质量中文长文本数据&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;竞赛数据集&lt;/td&gt; &#xA;   &lt;td&gt;近年来中文自然语言处理多任务竞赛数据集，约150个&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/esbatmop/MNBVC&#34;&gt;MNBVC&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MNBVC 中清洗出来的部分数据集&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;希望大家如果有较高质量的数据集能够提供给我们，不胜感激!💕💕&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;⏬ 模型部署&lt;/h2&gt; &#xA;&lt;p&gt;Meta在🤗Huggingface上提供了所有模型的下载链接：&lt;a href=&#34;https://huggingface.co/meta-llama&#34;&gt;https://huggingface.co/meta-llama&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;预训练模型&lt;/h3&gt; &#xA;&lt;p&gt;Llama2预训练模型包含7B、13B和70B三个版本&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;模型名称&lt;/th&gt; &#xA;   &lt;th&gt;🤗模型加载名称&lt;/th&gt; &#xA;   &lt;th&gt;下载地址&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-7B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-hf&#34;&gt;模型下载&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-13B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-13b-hf&#34;&gt;模型下载&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-70B&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-70b-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-70b-hf&#34;&gt;模型下载&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Chat模型&lt;/h3&gt; &#xA;&lt;p&gt;Llama2-Chat模型基于预训练模型进行了监督微调，具备更强的对话能力&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;模型名称&lt;/th&gt; &#xA;   &lt;th&gt;🤗模型加载名称&lt;/th&gt; &#xA;   &lt;th&gt;下载地址&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-7b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-chat-hf&#34;&gt;模型下载&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-13B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-13b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-13b-chat-hf&#34;&gt;模型下载&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-70B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;meta-llama/Llama-2-70b-chat-hf&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-70b-chat-hf&#34;&gt;模型下载&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;模型调用代码示例&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;from transformers import AutoTokenizer, AutoModelForCausalLM&#xA;model = AutoModelForCausalLM.from_pretrained(&#39;meta-llama/Llama-2-7b-chat-hf&#39;,device_map=&#39;auto&#39;,torch_dtype=torch.float16,load_in_8bit=True)&#xA;model =model.eval()&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;meta-llama/Llama-2-7b-chat-hf&#39;,use_fast=False)&#xA;tokenizer.pad_token = tokenizer.eos_token&#xA;input_ids = tokenizer([&#39;&amp;lt;s&amp;gt;Human: 介绍一下中国\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#39;], return_tensors=&#34;pt&#34;,add_special_tokens=False).input_ids.to(&#39;cuda&#39;)        &#xA;generate_input = {&#xA;    &#34;input_ids&#34;:input_ids,&#xA;    &#34;max_new_tokens&#34;:512,&#xA;    &#34;do_sample&#34;:True,&#xA;    &#34;top_k&#34;:50,&#xA;    &#34;top_p&#34;:0.95,&#xA;    &#34;temperature&#34;:0.3,&#xA;    &#34;repetition_penalty&#34;:1.3,&#xA;    &#34;eos_token_id&#34;:tokenizer.eos_token_id,&#xA;    &#34;bos_token_id&#34;:tokenizer.bos_token_id,&#xA;    &#34;pad_token_id&#34;:tokenizer.pad_token_id&#xA;}&#xA;generate_ids  = model.generate(**generate_input)&#xA;text = tokenizer.decode(generate_ids[0])&#xA;print(text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Gradio快速搭建问答平台&lt;/h3&gt; &#xA;&lt;p&gt;基于gradio搭建的问答界面，实现了流式的输出，将下面代码复制到控制台运行，以下代码以Llama2-7B-Chat模型为例，&lt;font color=&#34;#006600&#34;&gt;不同模型只需修改一下代码里的模型名称就好了😊&lt;/font&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python examples/chat_gradio.py --model_name_or_path meta-llama/Llama-2-7b-chat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;💡 模型微调&lt;/h2&gt; &#xA;&lt;p&gt;本仓库中提供了基于LoRA的微调代码，未来我们将会扩展更多的微调算法，敬请期待！关于LoRA的详细介绍可以参考论文“&lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;LoRA: Low-Rank Adaptation of Large Language Models&lt;/a&gt;”以及微软Github仓库&lt;a href=&#34;https://github.com/microsoft/LoRA&#34;&gt;LoRA&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;h3&gt;Step1: 环境和数据准备&lt;/h3&gt; &#xA;&lt;p&gt;根据&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/requirements.txt&#34;&gt;requirements.txt&lt;/a&gt;安装对应的环境依赖。&lt;/p&gt; &#xA;&lt;p&gt;在data目录下提供了一份用于模型sft的数据样例：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;训练数据：&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/data/train_sft.csv&#34;&gt;data/train_sft.csv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;验证数据：&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/data/dev_sft.csv&#34;&gt;data/dev_sft.csv&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;每个csv文件中包含一列“text”，每一行为一个训练样例，每个训练样例按照以下格式将问题和答案组织为模型输入，您可以按照以下格式自定义训练和验证数据集：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#34;&amp;lt;s&amp;gt;Human: &#34;+问题+&#34;\n&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: &#34;+答案&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;例如，&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;s&amp;gt;Human: 用一句话描述地球为什么是独一无二的。&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;Assistant: 因为地球是目前为止唯一已知存在生命的行星。&amp;lt;/s&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step2: 微调脚本&lt;/h3&gt; &#xA;&lt;p&gt;我们提供了用于微调的脚本&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/train/sft/finetune.sh&#34;&gt;train/sft/finetune.sh&lt;/a&gt;，通过修改脚本的部分参数实现模型的微调，关于微调的具体代码见&lt;a href=&#34;https://github.com/FlagAlpha/Llama2-Chinese/raw/main/train/sft/finetune_clm_lora.py&#34;&gt;train/sft/finetune_clm_lora.py&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;!-- ## 🚀 未来计划 --&gt; &#xA;&lt;!-- ## 💪 增强能力 --&gt; &#xA;&lt;h2&gt;🥇 模型评测&lt;/h2&gt; &#xA;&lt;p&gt;为了能够更加清晰地了解Llama2模型的中文问答能力，我们筛选了一些具有代表性的中文问题，对Llama2模型进行提问。我们测试的模型包含Meta公开的Llama2-7B-Chat和Llama2-13B-Chat两个版本，没有做任何微调和训练。测试问题筛选自&lt;a href=&#34;https://github.com/AtomEcho/AtomBulb&#34;&gt;AtomBulb&lt;/a&gt;，共95个测试问题，包含：通用知识、语言理解、创作能力、逻辑推理、代码编程、工作技能、使用工具、人格特征八个大的类别。&lt;/p&gt; &#xA;&lt;p&gt;测试中使用的Prompt如下，例如对于问题“列出5种可以改善睡眠质量的方法”：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[INST] &#xA;&amp;lt;&amp;lt;SYS&amp;gt;&amp;gt;&#xA;You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. The answer always been translate into Chinese language.&#xA;&#xA;If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don&#39;t know the answer to a question, please don&#39;t share false information.&#xA;&#xA;The answer always been translate into Chinese language.&#xA;&amp;lt;&amp;lt;/SYS&amp;gt;&amp;gt;&#xA;&#xA;列出5种可以改善睡眠质量的方法&#xA;[/INST]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Llama2-7B-Chat的测试结果见&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/assets/meta_eval_7B.md&#34;&gt;meta_eval_7B.md&lt;/a&gt;，Llama2-13B-Chat的测试结果见&lt;a href=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/assets/meta_eval_13B.md&#34;&gt;meta_eval_13B.md&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;p&gt;通过测试我们发现，Meta原始的Llama2 Chat模型对于中文问答的对齐效果一般，大部分情况下都不能给出中文回答，或者是中英文混杂的形式。因此，基于中文数据对Llama2模型进行训练和微调十分必要，我们的中文版Llama2模型也已经在训练中，近期将对社区开放。&lt;/p&gt; &#xA;&lt;h2&gt;📖 学习资料&lt;/h2&gt; &#xA;&lt;h3&gt;Meta官方对于&lt;a href=&#34;https://ai.meta.com/llama&#34;&gt;Llama2&lt;/a&gt;的介绍&lt;/h3&gt; &#xA;&lt;h3&gt;Llama相关论文&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.13971&#34;&gt;LLaMA: Open and Efficient Foundation Language Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scontent-lax3-2.xx.fbcdn.net/v/t39.2365-6/10000000_663429262362723_1696968207443577320_n.pdf?_nc_cat=101&amp;amp;ccb=1-7&amp;amp;_nc_sid=3c67a6&amp;amp;_nc_ohc=5ol-jUSglG4AX9uTu-j&amp;amp;_nc_ht=scontent-lax3-2.xx&amp;amp;oh=00_AfDVmJr77y3bv5GCbJ26w-stMJNXsZPTwVDlWhoIkkb8Lg&amp;amp;oe=64BDB0D1&#34;&gt;Llama 2: Open Foundation and Fine-Tuned Chat Models&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Llama2的评测结果&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://scontent-lax3-2.xx.fbcdn.net/v/t39.8562-6/361265668_276217774995411_4529778090866658620_n.jpg?_nc_cat=1&amp;amp;ccb=1-7&amp;amp;_nc_sid=6825c5&amp;amp;_nc_ohc=gSMV6flCjbAAX8pE8nm&amp;amp;_nc_ht=scontent-lax3-2.xx&amp;amp;oh=00_AfC53vAix8IkoTlO1Z46g2IfS3p7jb51A8TaIrOK6grRsQ&amp;amp;oe=64BC6826&#34; alt=&#34;Llama2Eval&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;🎉 致谢&lt;/h2&gt; &#xA;&lt;p&gt;感谢原子回声&lt;a href=&#34;https://github.com/AtomEcho&#34;&gt;AtomEcho&lt;/a&gt;团队的技术和资源支持！&lt;/p&gt; &#xA;&lt;p&gt;感谢 @xzsGenius 对Llama2中文社区的贡献！&lt;/p&gt; &#xA;&lt;p&gt;感谢 @Z Potentials社区对Llama2中文社区的支持！&lt;/p&gt; &#xA;&lt;h2&gt;🤔 问题反馈&lt;/h2&gt; &#xA;&lt;p&gt;如有问题，请在GitHub Issue中提交，在提交问题之前，请先查阅以往的issue是否能解决你的问题。&lt;/p&gt; &#xA;&lt;p&gt;礼貌地提出问题，构建和谐的讨论社区。&lt;/p&gt; &#xA;&lt;p&gt;加入&lt;a href=&#34;https://chinesellama.feishu.cn/wiki/space/7257824476874768388?ccm_open_type=lark_wiki_spaceLink&#34;&gt;飞书知识库&lt;/a&gt;，一起共建社区文档。&lt;/p&gt; &#xA;&lt;p&gt;加入微信群讨论😍😍&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/FlagAlpha/Llama2-Chinese/main/assets/wechat.jpeg&#34; alt=&#34;Wechat&#34; style=&#34;width: 100%; display: block; margin: auto;&#34;&gt; &lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>jmorganca/ollama</title>
    <updated>2023-07-23T01:29:45Z</updated>
    <id>tag:github.com,2023-07-23:/jmorganca/ollama</id>
    <link href="https://github.com/jmorganca/ollama" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Get up and running with large language models locally&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; height=&#34;200px&#34; srcset=&#34;https://github.com/jmorganca/ollama/assets/3325447/56ea1849-1284-4645-8970-956de6e51c3c&#34;&gt; &#xA;  &lt;img alt=&#34;logo&#34; height=&#34;200px&#34; src=&#34;https://github.com/jmorganca/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7&#34;&gt; &#xA; &lt;/picture&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;Ollama&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/ollama&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/ollama?style=flat&amp;amp;compact=true&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: Ollama is in early preview. Please report any issues you find.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Run, create, and share large language models (LLMs).&lt;/p&gt; &#xA;&lt;h2&gt;Download&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ollama.ai/download&#34;&gt;Download&lt;/a&gt; for macOS on Apple Silicon (Intel coming soon)&lt;/li&gt; &#xA; &lt;li&gt;Download for Windows and Linux (coming soon)&lt;/li&gt; &#xA; &lt;li&gt;Build &lt;a href=&#34;https://raw.githubusercontent.com/jmorganca/ollama/main/#building&#34;&gt;from source&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;To run and chat with &lt;a href=&#34;https://ai.meta.com/llama&#34;&gt;Llama 2&lt;/a&gt;, the new model by Meta:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama run llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Model library&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;ollama&lt;/code&gt; includes a library of open-source models:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Parameters&lt;/th&gt; &#xA;   &lt;th&gt;Size&lt;/th&gt; &#xA;   &lt;th&gt;Download&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;3.8GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama pull llama2&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2 13B&lt;/td&gt; &#xA;   &lt;td&gt;13B&lt;/td&gt; &#xA;   &lt;td&gt;7.3GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama pull llama2:13b&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Orca Mini&lt;/td&gt; &#xA;   &lt;td&gt;3B&lt;/td&gt; &#xA;   &lt;td&gt;1.9GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama pull orca&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vicuna&lt;/td&gt; &#xA;   &lt;td&gt;7B&lt;/td&gt; &#xA;   &lt;td&gt;3.8GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama pull vicuna&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Nous-Hermes&lt;/td&gt; &#xA;   &lt;td&gt;13B&lt;/td&gt; &#xA;   &lt;td&gt;7.3GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama pull nous-hermes&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Wizard Vicuna Uncensored&lt;/td&gt; &#xA;   &lt;td&gt;13B&lt;/td&gt; &#xA;   &lt;td&gt;7.3GB&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;ollama pull wizard-vicuna&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: You should have at least 8 GB of RAM to run the 3B models, 16 GB to run the 7B models, and 32 GB to run the 13B models.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;h3&gt;Run a model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama run llama2&#xA;&amp;gt;&amp;gt;&amp;gt; hi&#xA;Hello! How can I help you today?&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Create a custom model&lt;/h3&gt; &#xA;&lt;p&gt;Pull a base model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama pull llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create a &lt;code&gt;Modelfile&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;FROM llama2&#xA;&#xA;# set the temperature to 1 [higher is more creative, lower is more coherent]&#xA;PARAMETER temperature 1&#xA;&#xA;# set the system prompt&#xA;SYSTEM &#34;&#34;&#34;&#xA;You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.&#xA;&#34;&#34;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, create and run the model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama create mario -f ./Modelfile&#xA;ollama run mario&#xA;&amp;gt;&amp;gt;&amp;gt; hi&#xA;Hello! It&#39;s your friend Mario.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more examples, see the &lt;a href=&#34;https://raw.githubusercontent.com/jmorganca/ollama/main/examples&#34;&gt;examples&lt;/a&gt; directory.&lt;/p&gt; &#xA;&lt;h3&gt;Pull a model from the registry&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama pull orca&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Listing local models&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;ollama list&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Model packages&lt;/h2&gt; &#xA;&lt;h3&gt;Overview&lt;/h3&gt; &#xA;&lt;p&gt;Ollama bundles model weights, configuration, and data into a single package, defined by a &lt;a href=&#34;https://raw.githubusercontent.com/jmorganca/ollama/main/docs/modelfile.md&#34;&gt;Modelfile&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;picture&gt; &#xA; &lt;source media=&#34;(prefers-color-scheme: dark)&#34; height=&#34;480&#34; srcset=&#34;https://github.com/jmorganca/ollama/assets/251292/2fd96b5f-191b-45c1-9668-941cfad4eb70&#34;&gt; &#xA; &lt;img alt=&#34;logo&#34; height=&#34;480&#34; src=&#34;https://github.com/jmorganca/ollama/assets/251292/2fd96b5f-191b-45c1-9668-941cfad4eb70&#34;&gt; &#xA;&lt;/picture&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;go build .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run it start the server:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./ollama serve &amp;amp;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, run a model!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./ollama run llama2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;REST API&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;code&gt;POST /api/generate&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Generate text from a model.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;curl -X POST http://localhost:11434/api/generate -d &#39;{&#34;model&#34;: &#34;llama2&#34;, &#34;prompt&#34;:&#34;Why is the sky blue?&#34;}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>StudioCherno/Walnut</title>
    <updated>2023-07-23T01:29:45Z</updated>
    <id>tag:github.com,2023-07-23:/StudioCherno/Walnut</id>
    <link href="https://github.com/StudioCherno/Walnut" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Walnut is a simple application framework for Vulkan and Dear ImGui apps&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Walnut&lt;/h1&gt; &#xA;&lt;p&gt;Walnut is a simple application framework built with Dear ImGui and designed to be used with Vulkan - basically this means you can seemlessly blend real-time Vulkan rendering with a great UI library to build desktop applications. The plan is to expand Walnut to include common utilities to make immediate-mode desktop apps and simple Vulkan applications.&lt;/p&gt; &#xA;&lt;p&gt;Currently supports Windows - with macOS and Linux support planned. Setup scripts support Visual Studio 2022 by default.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://hazelengine.com/images/ForestLauncherScreenshot.jpg&#34; alt=&#34;WalnutExample&#34;&gt; &lt;em&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;center&gt;&#xA; &lt;em&gt;Forest Launcher - an application made with Walnut&lt;/em&gt;&#xA;&lt;/center&gt;&#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://visualstudio.com&#34;&gt;Visual Studio 2022&lt;/a&gt; (not strictly required, however included setup scripts only support this)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vulkan.lunarg.com/sdk/home#windows&#34;&gt;Vulkan SDK&lt;/a&gt; (preferably a recent version)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Once you&#39;ve cloned, run &lt;code&gt;scripts/Setup.bat&lt;/code&gt; to generate Visual Studio 2022 solution/project files. Once you&#39;ve opened the solution, you can run the WalnutApp project to see a basic example (code in &lt;code&gt;WalnutApp.cpp&lt;/code&gt;). I recommend modifying that WalnutApp project to create your own application, as everything should be setup and ready to go.&lt;/p&gt; &#xA;&lt;h3&gt;3rd party libaries&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ocornut/imgui&#34;&gt;Dear ImGui&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/glfw/glfw&#34;&gt;GLFW&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nothings/stb&#34;&gt;stb_image&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/g-truc/glm&#34;&gt;GLM&lt;/a&gt; (included for convenience)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Additional&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Walnut uses the &lt;a href=&#34;https://fonts.google.com/specimen/Roboto&#34;&gt;Roboto&lt;/a&gt; font (&lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache License, Version 2.0&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>