<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-05T01:28:07Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>mishalhossin/Discord-Chatbot-Gpt4Free</title>
    <updated>2023-05-05T01:28:07Z</updated>
    <id>tag:github.com,2023-05-05:/mishalhossin/Discord-Chatbot-Gpt4Free</id>
    <link href="https://github.com/mishalhossin/Discord-Chatbot-Gpt4Free" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This is a Python-based Discord Chatbot. This is all free due to the GPT4FREE project&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gpt4Free-Chat-bot ü§ñ&lt;/h1&gt; &#xA;&lt;p&gt;This is a &lt;a href=&#34;https://www.python.org&#34;&gt;Python&lt;/a&gt;-based Discord bot using the &lt;code&gt;discord.py&lt;/code&gt; library. The bot responds to messages, can change its profile picture, and provide latency information. Additionally, it uses the &lt;code&gt;theb&lt;/code&gt; from &lt;a href=&#34;https://github.com/xtekky/gpt4free&#34;&gt;GPT4FREE&lt;/a&gt; for generating responses based on conversation history.&lt;/p&gt; &#xA;&lt;h1&gt;Preview üëÄ&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/91066601/235470838-cad26039-c843-4497-8ba7-fc88c66dab49.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Commands ‚öôÔ∏è‚öôÔ∏è&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Toggle active channel for a server by using &lt;code&gt;!toggleactive&lt;/code&gt; command. ‚ö†Ô∏è (You need to be admin or owner)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/91066601/235982560-d7c068d6-d35f-4153-9723-923a8c31546d.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Toggle if dm should be active or not by using &lt;code&gt;!toggledm&lt;/code&gt; ‚ö†Ô∏è (You need to be admin or owner)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/91066601/235982180-d9926bb6-b6f9-44de-a0f7-045fce0dbda1.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Changes its profile picture with the &lt;code&gt;!pfp [url or attachment]&lt;/code&gt; command.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Provides latency information with the &lt;code&gt;!ping&lt;/code&gt; command.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Changes its username with the &lt;code&gt;!changeusr [New username]&lt;/code&gt; command.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If anything gose wrong use &lt;code&gt;!bonk&lt;/code&gt; to clear history ‚ö†Ô∏è&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Steps to install and run üö© :&lt;/h1&gt; &#xA;&lt;h3&gt;Step 1. üé¨ Git clone repository&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/mishalhossin/Discord-Chatbot-Gpt4Free&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 2. üìÅ Changing directory to cloned directory&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd Discord-Chatbot-Gpt4Free&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 3. üîë Getting discord bot token and enabling intents from &lt;a href=&#34;https://discord.com/developers/applications&#34;&gt;here&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h5&gt;Select application&lt;/h5&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/91066601/235554871-a5f98345-4197-4b55-91d7-1aef0d0680f0.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Enable intents&lt;/h5&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/91066601/235555012-e8427bfe-cffc-4761-bbc0-d1467ca1ff4d.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Get the token !!! by clicking copy&lt;/h5&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/91066601/235555065-6b51844d-dfbd-4b11-a14b-f65dd6de20d9.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Step 4. üîê Rename &lt;code&gt;example.env&lt;/code&gt; to &lt;code&gt;.env&lt;/code&gt; and put the discord token. It will look like this:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;DISCORD_TOKEN=token_from_step_3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/91066601/235554576-74e9e1e5-40ed-49d8-b815-dfecf890892d.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Step 5. ‚öôÔ∏è Install all the dependencies&lt;/h3&gt; &#xA;&lt;h4&gt;Windows:&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you dont have pip already. Run &lt;code&gt;python get-pip.py&lt;/code&gt; on windows&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Linux :&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip3 install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 6. üöÄ Run the bot&lt;/h3&gt; &#xA;&lt;h4&gt;Windows :&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;py main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Linux :&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;python main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 7. Invite the bot&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/91066601/236211332-7ed404aa-6b25-40d9-b3df-516432508043.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;üèÅ Finally talk to the bot&lt;/h3&gt; &#xA;&lt;h4&gt;There are 2 ways to talk to the ai&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Invite your bot and DM (Direct message) it | ‚ö†Ô∏è Make sure you have DM enabled&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;if you want it in server channel use !toggleactive&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;For more awesome commands use &lt;strong&gt;!welp&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/91066601/235474066-d805b10b-168b-4965-b623-6b37470ca6bb.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;‚ú®‚ú®‚ú® Other ways to run ‚ú®‚ú®‚ú®&lt;/h1&gt; &#xA;&lt;h3&gt;Using docker to run &lt;span&gt;üê≥&lt;/span&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Have a working bot token&lt;/li&gt; &#xA; &lt;li&gt;Follow up-to step 4&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Install docker compose on linux machine :&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;apt update -y ; sudo apt upgrade -y; sudo apt autoremove -y; sudo apt install docker-compose -y&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Start the bot in docker container :&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;sudo docker-compose up --build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Using replit to run ‚òÅÔ∏è&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Follow all the steps except &lt;code&gt;step 1&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Have a replit account&lt;/li&gt; &#xA; &lt;li&gt;Please note &lt;code&gt;.env&lt;/code&gt; is found in secrets tab of replit :&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/91066601/235810871-5d4c1469-35fd-42d2-a3a2-3382002877cb.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Config &lt;code&gt;.env&lt;/code&gt; in replit like this :&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/91066601/235811115-689c40e8-660a-448d-83dd-194631324436.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;a href=&#34;https://repl.it/github/mishalhossin/Discord-Chatbot-Gpt4Free&#34;&gt;&lt;img src=&#34;https://repl-badge.jajoosam.repl.co/try.png&#34; alt=&#34;Try on repl.it&#34;&gt;&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;h6&gt;Want something nsfw ? then check this out: &lt;a href=&#34;https://github.com/mishalhossin/Gpt3-sexbot-discord&#34;&gt;SEX-GPT&lt;/a&gt;&lt;/h6&gt;</summary>
  </entry>
  <entry>
    <title>mlc-ai/mlc-llm</title>
    <updated>2023-05-05T01:28:07Z</updated>
    <id>tag:github.com,2023-05-05:/mlc-ai/mlc-llm</id>
    <link href="https://github.com/mlc-ai/mlc-llm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Enable everyone to develop, optimize and deploy AI models natively on everyone&#39;s devices.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MLC LLM&lt;/h1&gt; &#xA;&lt;p&gt;| &lt;a href=&#34;https://mlc.ai/mlc-llm/&#34;&gt;Project&lt;/a&gt; | &lt;a href=&#34;https://mlc.ai/blog/blog/2023/05/01/bringing-accelerated-llm-to-consumer-hardware&#34;&gt;Blog&lt;/a&gt; | &lt;a href=&#34;https://mlc.ai/mlc-llm/#iphone&#34;&gt;Demo: iOS&lt;/a&gt; | &lt;a href=&#34;https://mlc.ai/mlc-llm/#windows-linux-mac&#34;&gt;Demo: CLI&lt;/a&gt; | &lt;a href=&#34;https://mlc.ai/web-llm/&#34;&gt;WebLLM&lt;/a&gt; | &lt;a href=&#34;https://mlc.ai/web-stable-diffusion/&#34;&gt;WebStableDiffusion&lt;/a&gt; |&lt;/p&gt; &#xA;&lt;p&gt;MLC LLM is a &lt;strong&gt;universal solution&lt;/strong&gt; that allows &lt;strong&gt;any language models&lt;/strong&gt; to be &lt;strong&gt;deployed natively&lt;/strong&gt; on a diverse set of hardware backends and native applications, plus a &lt;strong&gt;productive framework&lt;/strong&gt; for everyone to further optimize model performance for their own use cases.&lt;/p&gt; &#xA;&lt;p&gt;Our mission is to &lt;strong&gt;enable everyone to develop, optimize and deploy AI models natively on everyone&#39;s devices&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Everything runs locally with no server support and accelerated with local GPUs on your phone and laptops. &lt;a href=&#34;https://github.com/mlc-ai/mlc-llm/issues/15&#34;&gt;Supported platforms&lt;/a&gt; include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;iPhone, iPad&lt;/li&gt; &#xA; &lt;li&gt;Metal GPUs and Intel/ARM MacBooks;&lt;/li&gt; &#xA; &lt;li&gt;AMD, Intel and NVIDIA GPUs via Vulkan on Windows and Linux;&lt;/li&gt; &#xA; &lt;li&gt;NVIDIA GPUs via CUDA on Windows and Linux;&lt;/li&gt; &#xA; &lt;li&gt;WebGPU on browsers (through companion project &lt;a href=&#34;https://github.com/mlc-ai/web-llm/tree/main&#34;&gt;WebLLM&lt;/a&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://mlc.ai/mlc-llm/&#34;&gt;Check out our instruction page to try out!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/mlc-ai/mlc-llm/main/site/demo.gif&#34; height=&#34;700&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;What is MLC LLM?&lt;/h2&gt; &#xA;&lt;p&gt;In recent years, there has been remarkable progress in generative artificial intelligence (AI) and large language models (LLMs), which are becoming increasingly prevalent. Thanks to open-source initiatives, it is now possible to develop personal AI assistants using open-sourced models. However, LLMs tend to be resource-intensive and computationally demanding. To create a scalable service, developers may need to rely on powerful clusters and expensive hardware to run model inference. Additionally, deploying LLMs presents several challenges, such as their ever-evolving model innovation, memory constraints, and the need for potential optimization techniques.&lt;/p&gt; &#xA;&lt;p&gt;The goal of this project is to enable the development, optimization, and deployment of AI models for inference across a range of devices, including not just server-class hardware, but also users&#39; browsers, laptops, and mobile apps. To achieve this, we need to address the diverse nature of compute devices and deployment environments. Some of the key challenges include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Supporting different models of CPUs, GPUs, and potentially other co-processors and accelerators.&lt;/li&gt; &#xA; &lt;li&gt;Deploying on the native environment of user devices, which may not have python or other necessary dependencies readily available.&lt;/li&gt; &#xA; &lt;li&gt;Addressing memory constraints by carefully planning allocation and aggressively compressing model parameters.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;MLC LLM offers a repeatable, systematic, and customizable workflow that empowers developers and AI system researchers to implement models and optimizations in a productivity-focused, Python-first approach. This methodology enables quick experimentation with new models, new ideas and new compiler passes, followed by native deployment to the desired targets. Furthermore, we are continuously expanding LLM acceleration by broadening TVM backends to make model compilation more transparent and efficient.&lt;/p&gt; &#xA;&lt;h2&gt;How does MLC Enable Universal Native Deployment?&lt;/h2&gt; &#xA;&lt;p&gt;The cornerstone of our solution is machine learning compilation (&lt;a href=&#34;https://mlc.ai/&#34;&gt;MLC&lt;/a&gt;), which we leverage to efficiently deploy AI models. We build on the shoulders of open-source ecosystems, including tokenizers from HuggingFace and Google, as well as open-source LLMs like Llama, Vicuna, Dolly, MOSS and more. Our primary workflow is based on &lt;a href=&#34;https://github.com/apache/tvm/tree/unity&#34;&gt;Apache TVM Unity&lt;/a&gt;, an exciting ongoing development in the Apache TVM Community.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Dynamic shape: We bake a language model as a TVM IRModule with native dynamic shape support, avoiding the need for extra padding to the maximum length and reducing both computation amount and memory usage.&lt;/li&gt; &#xA; &lt;li&gt;Composable ML compilation optimizations: we perform many model deployment optimizations, such as better compilation code transformation, fusion, memory planning, library offloading and manual code optimization can be easily incorporated as TVM&#39;s IRModule transformations exposed as Python APIs.&lt;/li&gt; &#xA; &lt;li&gt;Quantization: We utilize low-bit quantizations to compress the model weights and leverage TVM&#39;s loop-level TensorIR to quickly customize code generations for different compression encoding schemes.&lt;/li&gt; &#xA; &lt;li&gt;Runtime: The final generated libraries run on the native environment, with TVM runtime that comes with minimal dependencies, which supports various GPU driver APIs and native language bindings (C, JavaScript, etc).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/mlc-ai/mlc-llm/main/site/img/diag.svg?sanitize=true&#34; alt=&#34;Architecture Diagram&#34; height=&#34;&#34;&gt; &#xA;&lt;p&gt;Additionally, we also provide a lightweight C++-based example CLI app that showcases how to wrap up the compiled artifacts and necessary pre/post-processing, which will hopefully clarify the workflow to embed them into native applications.&lt;/p&gt; &#xA;&lt;p&gt;As a starting point, MLC generates GPU shaders for CUDA, Vulkan and Metal. It is possible to add more support, such as OpenCL, sycl, webgpu-native, through improvements to TVM compiler and runtime. MLC also supports various CPU targets including ARM and x86 via LLVM.&lt;/p&gt; &#xA;&lt;p&gt;We heavily rely on open-source ecosystem, more specifically, &lt;a href=&#34;https://discuss.tvm.apache.org/t/establish-tvm-unity-connection-a-technical-strategy/13344&#34;&gt;TVM Unity&lt;/a&gt;, an exciting latest development in the TVM project that enables python-first interactive MLC development experiences that allows us to easily compose new optimizations all in Python, and incrementally bring our app to the environment of interest. We also leveraged optimizations such as fused quantization kernels, first class dynamic shape support and diverse GPU backends.&lt;/p&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You might also be interested in &lt;a href=&#34;https://github.com/mlc-ai/web-llm/tree/main&#34;&gt;WebLLM&lt;/a&gt;, our companion derived project that focus on bringing LLM to browsers.&lt;/li&gt; &#xA; &lt;li&gt;Project page for &lt;a href=&#34;https://raw.githubusercontent.com/mlc-ai/mlc-llm/main/site/index.md&#34;&gt;instructions&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/mlc-ai/mlc-llm/main/ios/README.md&#34;&gt;Local build Instructions for ios App&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;You might want to check out our online public &lt;a href=&#34;https://mlc.ai&#34;&gt;Machine Learning Compilation course&lt;/a&gt; for a systematic walkthrough of our approaches.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;This project is initiated by members from CMU catalyst, UW SAMPL, SJTU, OctoML and the MLC community. We would love to continue developing and supporting the open-source ML community.&lt;/p&gt; &#xA;&lt;p&gt;This project is only possible thanks to the shoulders open-source ecosystems that we stand on. We want to thank the Apache TVM community and developers of the TVM Unity effort. The open-source ML community members made these models publicly available. PyTorch and Hugging Face communities that make these models accessible. We would like to thank the teams behind Vicuna, SentencePiece, LLaMA, Alpaca and MOSS. We also would like to thank the Vulkan, Swift, C++, python Rust communities that enables this project.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>immich-app/immich</title>
    <updated>2023-05-05T01:28:07Z</updated>
    <id>tag:github.com,2023-05-05:/immich-app/immich</id>
    <link href="https://github.com/immich-app/immich" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Self-hosted photo and video backup solution directly from your mobile phone.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-green.svg?color=3F51B5&amp;amp;style=for-the-badge&amp;amp;label=License&amp;amp;logoColor=000000&amp;amp;labelColor=ececec&#34; alt=&#34;License: MIT&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/D8JsnBEuKb&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/979116623879368755.svg?label=Discord&amp;amp;logo=Discord&amp;amp;style=for-the-badge&amp;amp;logoColor=000000&amp;amp;labelColor=ececec&#34; atl=&#34;Discord&#34;&gt; &lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/immich-app/immich/main/design/immich-logo.svg?sanitize=true&#34; width=&#34;150&#34; title=&#34;Login With Custom URL&#34;&gt; &lt;/p&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt;Immich - High performance self-hosted photo and video backup solution&lt;/h3&gt; &#xA;&lt;br&gt; &#xA;&lt;a href=&#34;https://immich.app&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/immich-app/immich/main/design/immich-screenshots.png&#34; title=&#34;Main Screenshot&#34;&gt; &lt;/a&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/immich-app/immich/main/README_zh_CN.md&#34;&gt;‰∏≠Êñá&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚ö†Ô∏è The project is under &lt;strong&gt;very active&lt;/strong&gt; development.&lt;/li&gt; &#xA; &lt;li&gt;‚ö†Ô∏è Expect bugs and breaking changes.&lt;/li&gt; &#xA; &lt;li&gt;‚ö†Ô∏è &lt;strong&gt;Do not use the app as the only way to store your photos and videos!&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Content&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://immich.app/docs&#34;&gt;Official Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/orgs/immich-app/projects/1&#34;&gt;Roadmap&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/immich-app/immich/main/#demo&#34;&gt;Demo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/immich-app/immich/main/#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://immich.app/docs/overview/introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://immich.app/docs/install/requirements&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://immich.app/docs/overview/support-the-project&#34;&gt;Contribution Guidelines&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/immich-app/immich/main/#support-the-project&#34;&gt;Support The Project&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;You can find the main documentation, including installation guides, at &lt;a href=&#34;https://immich.app/&#34;&gt;https://immich.app/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;You can access the web demo at &lt;a href=&#34;https://demo.immich.app&#34;&gt;https://demo.immich.app&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;For the mobile app, you can use &lt;code&gt;https://demo.immich.app/api&lt;/code&gt; for the &lt;code&gt;Server Endpoint URL&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;The credential&#xA;email: demo@immich.app&#xA;password: demo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Spec: Free-tier Oracle VM - Amsterdam - 2.4Ghz quad-core ARM64 CPU, 24GB RAM&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Features&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Features&lt;/th&gt; &#xA;   &lt;th&gt;Mobile&lt;/th&gt; &#xA;   &lt;th&gt;Web&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Upload and view videos and photos&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Auto backup when the app is opened&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Selective album(s) for backup&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Download photos and videos to local device&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Multi-user support&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Album and Shared albums&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Scrubbable/draggable scrollbar&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Support RAW (HEIC, HEIF, DNG, Apple ProRaw)&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Metadata view (EXIF, map)&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Search by metadata, objects and CLIP&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Administrative functions (user management)&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Background backup&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Virtual scroll&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OAuth support&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LivePhoto backup and playback&lt;/td&gt; &#xA;   &lt;td&gt;iOS&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;User-defined storage structure&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Public Sharing&lt;/td&gt; &#xA;   &lt;td&gt;N/A&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Support the project&lt;/h1&gt; &#xA;&lt;p&gt;I&#39;ve committed to this project, and I will not stop. I will keep updating the docs, adding new features, and fixing bugs. But I can&#39;t do it alone. So I need your help to give me additional motivation to keep going.&lt;/p&gt; &#xA;&lt;p&gt;As our hosts in the &lt;a href=&#34;https://selfhosted.show/79?t=1418&#34;&gt;selfhosted.show - In the episode &#39;The-organization-must-not-be-name is a Hostile Actor&#39;&lt;/a&gt; said, this is a massive undertaking of what the team and I are doing. And I would love to someday be able to do this full-time, and I am asking for your help to make that happen.&lt;/p&gt; &#xA;&lt;p&gt;If you feel like this is the right cause and the app is something you are seeing yourself using for a long time, please consider supporting the project with the option below.&lt;/p&gt; &#xA;&lt;h2&gt;Donation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sponsors/alextran1502&#34;&gt;Monthly donation&lt;/a&gt; via GitHub Sponsors&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sponsors/alextran1502?frequency=one-time&amp;amp;sponsor=alextran1502&#34;&gt;One-time donation&lt;/a&gt; via GitHub Sponsors&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://liberapay.com/alex.tran1502/&#34;&gt;Librepay&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.buymeacoffee.com/altran1502&#34;&gt;buymeacoffee&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Bitcoin: 1FvEp6P6NM8EZEkpGUFAN2LqJ1gxusNxZX&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>