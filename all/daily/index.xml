<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-17T01:22:09Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>microsoft/UFO</title>
    <updated>2024-02-17T01:22:09Z</updated>
    <id>tag:github.com,2024-02-17:/microsoft/UFO</id>
    <link href="https://github.com/microsoft/UFO" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A UI-Focused Agent for Windows OS Interaction.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;b&gt;UFO&lt;/b&gt; &lt;img src=&#34;https://raw.githubusercontent.com/microsoft/UFO/main/assets/ufo_blue.png&#34; alt=&#34;UFO Image&#34; width=&#34;40&#34;&gt;: A &lt;b&gt;U&lt;/b&gt;I-&lt;b&gt;F&lt;/b&gt;ocused Agent for Windows &lt;b&gt;O&lt;/b&gt;S Interaction &lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/Python-3776AB?&amp;amp;logo=python&amp;amp;logoColor=white-blue&amp;amp;label=3.10%20%7C%203.11&#34; alt=&#34;Python Version&#34;&gt;‚ÄÇ &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&#34; alt=&#34;License: MIT&#34;&gt;&lt;/a&gt;‚ÄÇ &lt;img src=&#34;https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat&#34; alt=&#34;Welcome&#34;&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;strong&gt;UFO&lt;/strong&gt; is a &lt;strong&gt;UI-Focused&lt;/strong&gt; dual-agent framework to fulfill user requests on &lt;strong&gt;Windows OS&lt;/strong&gt; by seamlessly navigating and operating within individual or spanning multiple applications.&lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/microsoft/UFO/main/assets/overview_n.png&#34;&gt; &lt;/h1&gt; &#xA;&lt;h2&gt;üïå Framework&lt;/h2&gt; &#xA;&lt;p&gt;&lt;b&gt;UFO&lt;/b&gt; &lt;img src=&#34;https://raw.githubusercontent.com/microsoft/UFO/main/assets/ufo_blue.png&#34; alt=&#34;UFO Image&#34; width=&#34;24&#34;&gt; operates as a dual-agent framework, encompassing:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;b&gt;AppAgent ü§ñ&lt;/b&gt;, tasked with choosing an application for fulfilling user requests. This agent may also switch to a different application when a request spans multiple applications, and the task is partially completed in the preceding application.&lt;/li&gt; &#xA; &lt;li&gt;&lt;b&gt;ActAgent üëæ&lt;/b&gt;, responsible for iteratively executing actions on the selected applications until the task is successfully concluded within a specific application.&lt;/li&gt; &#xA; &lt;li&gt;&lt;b&gt;Control Interaction üéÆ&lt;/b&gt;, is tasked with translating actions from AppAgent and ActAgent into interactions with the application and its UI controls. It&#39;s essential that the targeted controls are compatible with the Windows &lt;strong&gt;UI Automation&lt;/strong&gt; API.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Both agents leverage the multi-modal capabilities of GPT-Vision to comprehend the application UI and fulfill the user&#39;s request. For more details, please consult our &lt;a href=&#34;https://arxiv.org/abs/2402.07939&#34;&gt;technical report&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/microsoft/UFO/main/assets/framework.png&#34;&gt; &lt;/h1&gt; &#xA;&lt;h2&gt;üÜï News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üìÖ 2024-02-14: Our &lt;a href=&#34;https://arxiv.org/abs/2402.07939&#34;&gt;technical report&lt;/a&gt; is online!&lt;/li&gt; &#xA; &lt;li&gt;üìÖ 2024-02-10: UFO is released on GitHubüéà. Happy Chinese New yearüêâ!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üí• Highlights&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;First Windows Agent&lt;/strong&gt; - UFO is the pioneering agent framework capable of translating user requests in natural language into actionable operations on Windows OS.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Interactive Mode&lt;/strong&gt; - UFO facilitates multiple sub-requests from users within the same session, enabling the completion of complex tasks seamlessly.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Action Safeguard&lt;/strong&gt; - UFO incorporates safeguards to prompt user confirmation for sensitive actions, enhancing security and preventing inadvertent operations.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Easy Extension&lt;/strong&gt; - UFO offers extensibility, allowing for the integration of additional functionalities and control types to tackle diverse and intricate tasks with ease.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;‚ú® Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;üõ†Ô∏è Step 1: Installation&lt;/h3&gt; &#xA;&lt;p&gt;UFO requires &lt;strong&gt;Python &amp;gt;= 3.10&lt;/strong&gt; running on &lt;strong&gt;Windows OS &amp;gt;= 10&lt;/strong&gt;. It can be installed by running the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# [optional to create conda environment]&#xA;# conda create -n ufo python=3.10&#xA;# conda activate ufo&#xA;&#xA;# clone the repository&#xA;git clone https://github.com/microsoft/UFO.git&#xA;cd UFO&#xA;# install the requirements&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;‚öôÔ∏è Step 2: Configure the LLMs&lt;/h3&gt; &#xA;&lt;p&gt;Before running UFO, you need to provide your LLM configurations. Taking OpenAI as an example, you can configure &lt;code&gt;ufo/config/config.yaml&lt;/code&gt; file as follows.&lt;/p&gt; &#xA;&lt;h4&gt;OpenAI&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;API_TYPE: &#34;openai&#34; &#xA;OPENAI_API_BASE: &#34;https://api.openai.com/v1/chat/completions&#34; # The base URL for the OpenAI API&#xA;OPENAI_API_KEY: &#34;YOUR_API_KEY&#34;  # Set the value to the openai key for the llm model&#xA;OPENAI_API_MODEL: &#34;GPTV_MODEL_NAME&#34;  # The only OpenAI model by now that accepts visual input&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Azure OpenAI (AOAI)&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;API_TYPE: &#34;aoai&#34; &#xA;OPENAI_API_BASE: &#34;YOUR_ENDPOINT&#34; # The AOAI API address. Format: https://{your-resource-name}.openai.azure.com/openai/deployments/{deployment-id}/completions?api-version={api-version}&#xA;OPENAI_API_KEY: &#34;YOUR_API_KEY&#34;  # Set the value to the openai key for the llm model&#xA;OPENAI_API_MODEL: &#34;GPTV_MODEL_NAME&#34;  # The only OpenAI model by now that accepts visual input&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;üéâ Step 3: Start UFO&lt;/h3&gt; &#xA;&lt;h4&gt;‚å®Ô∏è You can execute the following on your Windows command Line (CLI):&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# assume you are in the cloned UFO folder&#xA;python -m ufo --task &amp;lt;your_task_name&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will start the UFO process and you can interact with it through the command line interface. If everything goes well, you will see the following message:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Welcome to use UFOüõ∏, A UI-focused Agent for Windows OS Interaction. &#xA; _   _  _____   ___&#xA;| | | ||  ___| / _ \&#xA;| | | || |_   | | | |&#xA;| |_| ||  _|  | |_| |&#xA; \___/ |_|     \___/&#xA;Please enter your request to be completedüõ∏:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;‚ö†Ô∏èReminder:&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Before UFO executing your request, please make sure the targeted applications are active on the system.&lt;/li&gt; &#xA; &lt;li&gt;The GPT-V accepts screenshots of your desktop and application GUI as input. Please ensure that no sensitive or confidential information is visible or captured during the execution process. For further information, refer to &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/UFO/main/DISCLAIMER.md&#34;&gt;DISCLAIMER.md&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Step 4 üé•: Execution Logs&lt;/h3&gt; &#xA;&lt;p&gt;You can find the screenshots taken and request &amp;amp; response logs in the following folder:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./ufo/logs/&amp;lt;your_task_name&amp;gt;/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may use them to debug, replay, or analyze the agent output.&lt;/p&gt; &#xA;&lt;h2&gt;‚ùìGet help&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚ùîGitHub Issues (prefered)&lt;/li&gt; &#xA; &lt;li&gt;For other communications, please contact &lt;a href=&#34;mailto:ufo-agent@microsoft.com&#34;&gt;ufo-agent@microsoft.com&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;üé¨ Demo Examples&lt;/h2&gt; &#xA;&lt;p&gt;We present two demo videos that complete user request on Windows OS using UFO. For more case study, please consult our &lt;a href=&#34;https://arxiv.org/abs/2402.07939&#34;&gt;technical report&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;1Ô∏è‚É£üóëÔ∏è Example 1: Deleting all notes on a PowerPoint presentation.&lt;/h4&gt; &#xA;&lt;p&gt;In this example, we will demonstrate how to efficiently use UFO to delete all notes on a PowerPoint presentation with just a few simple steps. Explore this functionality to enhance your productivity and work smarter, not harder!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/UFO/assets/11352048/cf60c643-04f7-4180-9a55-5fb240627834&#34;&gt;https://github.com/microsoft/UFO/assets/11352048/cf60c643-04f7-4180-9a55-5fb240627834&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;2Ô∏è‚É£üìß Example 2: Composing an email using text from multiple sources.&lt;/h4&gt; &#xA;&lt;p&gt;In this example, we will demonstrate how to utilize UFO to extract text from Word documents, describe an image, compose an email, and send it seamlessly. Enjoy the versatility and efficiency of cross-application experiences with UFO!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/UFO/assets/11352048/aa41ad47-fae7-4334-8e0b-ba71c4fc32e0&#34;&gt;https://github.com/microsoft/UFO/assets/11352048/aa41ad47-fae7-4334-8e0b-ba71c4fc32e0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üìä Evaluation&lt;/h2&gt; &#xA;&lt;p&gt;Please consult the &lt;a href=&#34;https://arxiv.org/pdf/2402.07939.pdf&#34;&gt;WindowsBench&lt;/a&gt; provided in Section A of the Appendix within our technical report. Here are some tips (and requirements) to aid in completing your request:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Prior to UFO execution of your request, ensure that the targeted application is active (though it may be minimized).&lt;/li&gt; &#xA; &lt;li&gt;Occasionally, requests to GPT-V may trigger content safety measures. UFO will attempt to retry regardless, but adjusting the size or scale of the application window may prove helpful. We are actively solving this issue.&lt;/li&gt; &#xA; &lt;li&gt;Currently, UFO supports a limited set of applications and UI controls that are compatible with the Windows &lt;strong&gt;UI Automation&lt;/strong&gt; API. Our future plans include extending support to the Win32 API to enhance its capabilities.&lt;/li&gt; &#xA; &lt;li&gt;Please note that the output of GPT-V may not consistently align with the same request. If unsuccessful with your initial attempt, consider trying again.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìö Citation&lt;/h2&gt; &#xA;&lt;p&gt;Our technical report paper can be found &lt;a href=&#34;https://arxiv.org/abs/2402.07939&#34;&gt;here&lt;/a&gt;. If you use UFO in your research, please cite our paper:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{ufo,&#xA;  title={{UFO: A UI-Focused Agent for Windows OS Interaction}},&#xA;  author={Zhang, Chaoyun and Li, Liqun and He, Shilin and  Zhang, Xu and Qiao, Bo and  Qin, Si and Ma, Minghua and Kang, Yu and Lin, Qingwei and Rajmohan, Saravan and Zhang, Dongmei and  Zhang, Qi},&#xA;  journal={arXiv preprint arXiv:2402.07939},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;üé® Related Project&lt;/h2&gt; &#xA;&lt;p&gt;You may also find &lt;a href=&#34;https://github.com/microsoft/TaskWeaver?tab=readme-ov-file&#34;&gt;TaskWeaver&lt;/a&gt; useful, a code-first LLM agent framework for seamlessly planning and executing data analytics tasks.&lt;/p&gt; &#xA;&lt;h2&gt;‚ö†Ô∏è Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;By choosing to run the provided code, you acknowledge and agree to the following terms and conditions regarding the functionality and data handling practices in &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/UFO/main/DISCLAIMER.md&#34;&gt;DISCLAIMER.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/UFO/main/assets/ufo_blue.png&#34; alt=&#34;logo&#34; width=&#34;30&#34;&gt; Trademarks&lt;/h2&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>gptscript-ai/gptscript</title>
    <updated>2024-02-17T01:22:09Z</updated>
    <id>tag:github.com,2024-02-17:/gptscript-ai/gptscript</id>
    <link href="https://github.com/gptscript-ai/gptscript" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Natural Language Programming&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GPTScript&lt;/h1&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;GPTScript is a new scripting language to automate your interaction with a Large Language Model (LLM), namely OpenAI. The ultimate goal is to create a fully natural language based programming experience. The syntax of GPTScript is largely natural language, making it very easy to learn and use. Natural language prompts can be mixed with traditional scripts such as bash and python or even external HTTP service calls. With GPTScript you can do just about anything like &lt;a href=&#34;https://raw.githubusercontent.com/gptscript-ai/gptscript/main/examples/travel-agent.gpt&#34;&gt;plan a vacation&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/gptscript-ai/gptscript/main/examples/add-go-mod-dep.gpt&#34;&gt;edit a file&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/gptscript-ai/gptscript/main/examples/sqlite-download.gpt&#34;&gt;run some SQL&lt;/a&gt;, or &lt;a href=&#34;https://raw.githubusercontent.com/gptscript-ai/gptscript/main/examples/hacker-news-headlines.gpt&#34;&gt;build a mongodb/flask app&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# example.gpt&#xA;&#xA;Tools: sys.download, sys.exec, sys.remove&#xA;&#xA;Download https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip to a&#xA;random file. Then expand the archive to a temporary location as there is a sqlite&#xA;database in it.&#xA;&#xA;First inspect the schema of the database to understand the table structure.&#xA;&#xA;Form and run a SQL query to find the artist with the most number of albums and output&#xA;the result of that.&#xA;&#xA;When done remove the database file and the downloaded content.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ gptscript ./example.gpt&#xA;&#xA;OUTPUT:&#xA;&#xA;The artist with the most number of albums in the database is Iron Maiden, with a total&#xA;of 21 albums.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;h3&gt;1. Install the latest release&lt;/h3&gt; &#xA;&lt;h4&gt;Homebrew (macOS and Linux)&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;brew install gptscript-ai/tap/gptscript&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Install Script (macOS and Linux):&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl https://get.gptscript.ai/install.sh | sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Manually&lt;/h4&gt; &#xA;&lt;p&gt;Download and install the archive for your platform and architecture from the &lt;a href=&#34;https://github.com/gptscript-ai/gptscript/releases&#34;&gt;releases page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;2. Get an API key from &lt;a href=&#34;https://platform.openai.com/api-keys&#34;&gt;OpenAI&lt;/a&gt;.&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export OPENAI_API_KEY=&#34;your-api-key&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. Run Hello World&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;gptscript https://get.gptscript.ai/echo.gpt --input &#39;Hello, World!&#39;&#xA;&#xA;OUTPUT:&#xA;&#xA;Hello, World!&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The model used by default is &lt;code&gt;gpt-4-turbo-preview&lt;/code&gt; and you must have access to that model in your OpenAI account.&lt;/p&gt; &#xA;&lt;h3&gt;4. Extra Credit: Examples and Run Debugging UI&lt;/h3&gt; &#xA;&lt;p&gt;Clone examples and run debugging UI&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/gptscript-ai/gptscript&#xA;cd gptscript/examples&#xA;&#xA;# Run the debugging UI&#xA;gptscript --server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;How it works&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;GPTScript is composed of tools.&lt;/strong&gt;&lt;/em&gt; Each tool performs a series of actions similar to a function. Tools have available to them other tools that can be invoked similar to a function call. While similar to a function, the tools are primarily implemented with a natural language prompt. &lt;em&gt;&lt;strong&gt;The interaction of the tools is determined by the AI model&lt;/strong&gt;&lt;/em&gt;, the model determines if the tool needs to be invoked and what arguments to pass. Tools are intended to be implemented with a natural language prompt but can also be implemented with a command or HTTP call.&lt;/p&gt; &#xA;&lt;h3&gt;Example&lt;/h3&gt; &#xA;&lt;p&gt;Below are two tool definitions, separated by &lt;code&gt;---&lt;/code&gt;. The first tool does not require a name or description, but every tool after name and description are required. The first tool, has the parameter &lt;code&gt;tools: bob&lt;/code&gt; meaning that the tool named &lt;code&gt;bob&lt;/code&gt; is available to be called if needed.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;tools: bob&#xA;&#xA;Ask Bob how he is doing and let me know exactly what he said.&#xA;&#xA;---&#xA;name: bob&#xA;description: I&#39;m Bob, a friendly guy.&#xA;args: question: The question to ask Bob.&#xA;&#xA;When asked how I am doing, respond with &#34;Thanks for asking &#34;${question}&#34;, I&#39;m doing great fellow friendly AI tool!&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Put the above content in a file named &lt;code&gt;bob.gpt&lt;/code&gt; and run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ gptscript bob.gpt&#xA;&#xA;OUTPUT:&#xA;&#xA;Bob said, &#34;Thanks for asking &#39;How are you doing?&#39;, I&#39;m doing great fellow friendly AI tool!&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Tools can be implemented by invoking a program instead of a natural language prompt. The below example is the same as the previous example but implements Bob using python.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;Tools: bob&#xA;&#xA;Ask Bob how he is doing and let me know exactly what he said.&#xA;&#xA;---&#xA;Name: bob&#xA;Description: I&#39;m Bob, a friendly guy.&#xA;Args: question: The question to ask Bob.&#xA;&#xA;#!python3&#xA;&#xA;import os&#xA;&#xA;print(f&#34;Thanks for asking {os.environ[&#39;question&#39;]}, I&#39;m doing great fellow friendly AI tool!&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;With these basic building blocks you can create complex scripts with AI interacting with AI, your local system, data, or external services.&lt;/p&gt; &#xA;&lt;h2&gt;GPT File Reference&lt;/h2&gt; &#xA;&lt;h3&gt;Extension&lt;/h3&gt; &#xA;&lt;p&gt;GPTScript files use the &lt;code&gt;.gpt&lt;/code&gt; extension by convention.&lt;/p&gt; &#xA;&lt;h3&gt;File Structure&lt;/h3&gt; &#xA;&lt;p&gt;A GPTScript file has one or more tools in the file. Each tool is separated by three dashes &lt;code&gt;---&lt;/code&gt; alone on a line.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;Name: tool1&#xA;Description: This is tool1&#xA;&#xA;Do sample tool stuff.&#xA;&#xA;---&#xA;Name: tool2&#xA;Description: This is tool2&#xA;&#xA;Do more sample tool stuff.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Tool Definition&lt;/h3&gt; &#xA;&lt;p&gt;A tool starts with a preamble that defines the tool&#39;s name, description, args, available tools and additional parameters. The preamble is followed by the tool&#39;s body, which contains the instructions for the tool. Comments in the preamble are lines starting with &lt;code&gt;#&lt;/code&gt; and are ignored by the parser. Comments are not really encouraged as the text is typically more useful in the description, argument descriptions or instructions.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;Name: tool-name&#xA;# This is a comment in the preamble.&#xA;Description: Tool description&#xA;# This tool can invoke tool1 or tool2 if needed&#xA;Tools: tool1, tool2&#xA;Args: arg1: The description of arg1&#xA;      &#xA;Tool instructions go here.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Tool Parameters&lt;/h4&gt; &#xA;&lt;p&gt;Tool parameters are key-value pairs defined at the beginning of a tool block, before any instructional text. They are specified in the format &lt;code&gt;key: value&lt;/code&gt;. The parser recognizes the following keys (case-insensitive and spaces are ignored):&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Name&lt;/code&gt;: The name of the tool.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Model Name&lt;/code&gt;: The OpenAI model to use, by default it uses &#34;gpt-4-turbo-preview&#34;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Description&lt;/code&gt;: The description of the tool. It is important that the properly describes the tool&#39;s purpose as the description is used by the LLM to determine if the tool is to be invoked.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Internal Prompt&lt;/code&gt;: Setting this to &lt;code&gt;false&lt;/code&gt; will disable the built in system prompt for this tool. GPTScript includes a default system prompt to instruct the AI to behave more like a script engine and not a &#34;helpful assistant.&#34;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Tools&lt;/code&gt;: A comma-separated list of tools that are available to be called by this tool. A tool can only call the tools that are defined here. A tool name can reference a name in the current file, or a file relative to the current directory of the tool file, a http(s) URL, or a file in GitHub using github.com/username/repo/file.gpt format. When referencing a file or URL the tool loaded is the first tool in the file. To reference a specific tool in a file or URL use the syntax &lt;code&gt;tool-name from file-or-url&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Args&lt;/code&gt;: Arguments for the tool. Each argument is defined in the format &lt;code&gt;arg-name: description&lt;/code&gt;. All arguments are essentially strings. No other type really exists as all input and output to tools is text based.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Max Tokens&lt;/code&gt;: Set to a number if you wish to limit the maximum number of tokens that can be generated by the LLM.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;JSON Response&lt;/code&gt;: Setting to &lt;code&gt;true&lt;/code&gt; will cause the LLM to respond in a JSON format. If you set true you must also include instructions in the tool to inform the LLM to respond in some JSON structure.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Temperature&lt;/code&gt;: A floating-point number representing the temperature parameter. By default the temperature is 0. Set to a higher number to make the LLM more creative.&lt;/p&gt; &#xA;&lt;h4&gt;Tool Body&lt;/h4&gt; &#xA;&lt;p&gt;The tool body contains the instructions for the tool which can be a natural language prompt or a command to execute. Commands must start with &lt;code&gt;#!&lt;/code&gt; followed by the interpreter (e.g. &lt;code&gt;#!/bin/bash&lt;/code&gt;, &lt;code&gt;#!python3&lt;/code&gt;) a text that will be placed in a file and passed to the interpreter. Arguments can be references in the instructions using the format &lt;code&gt;${arg1}&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;name: echo-ai&#xA;description: A tool that echos the input&#xA;args: input: The input&#xA;&#xA;Just return only &#34;${input}&#34;&#xA;&#xA;---&#xA;name: echo-command&#xA;description: A tool that echos the input&#xA;args: input: The input&#xA;&#xA;#!/bin/bash&#xA;        &#xA;echo &#34;${input}&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Built in Tools&lt;/h2&gt; &#xA;&lt;p&gt;There are several built in tools to do basic things like read/write files, download http content and execute commands. Run &lt;code&gt;gptscript --list-tools&lt;/code&gt; to list all the built-in tools.&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;For more examples check out the &lt;a href=&#34;https://raw.githubusercontent.com/gptscript-ai/gptscript/main/examples&#34;&gt;examples&lt;/a&gt; directory.&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;Join us on Discord: &lt;a href=&#34;https://discord.gg/9sSf4UyAMC&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1204558420984864829?label=Discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright (c) 2023 &lt;a href=&#34;http://acorn.io&#34;&gt;Acorn Labs, Inc.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.apache.org/licenses/LICENSE-2.0&#34;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &#34;AS IS&#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>reorproject/reor</title>
    <updated>2024-02-17T01:22:09Z</updated>
    <id>tag:github.com,2024-02-17:/reorproject/reor</id>
    <link href="https://github.com/reorproject/reor" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AI note-taking app that runs models locally.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;Reor Project&lt;/h1&gt; &#xA;&lt;!-- &lt;p align=&#34;center&#34;&gt;&#xA;    &lt;img src=&#34;logo_or_graphic_representation.png&#34; alt=&#34;Reor Logo&#34;&gt;&#xA;&lt;/p&gt; --&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; A self-organizing AI note-taking app that runs models locally.&lt;/h4&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/reorproject/reor/main/LICENSE&#34;&gt;&lt;img alt=&#34;License&#34; src=&#34;https://img.shields.io/badge/license-GPLv3-blue.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;img alt=&#34;GitHub Release Date - Published_At&#34; src=&#34;https://img.shields.io/github/release-date/reorproject/reor&#34;&gt; &lt;img alt=&#34;GitHub Repo stars&#34; src=&#34;https://img.shields.io/github/stars/reorproject/reor&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Reor&lt;/strong&gt; is an AI-powered desktop note-taking app: it automatically links related ideas, answers questions on your notes and provides semantic search. Everything is stored locally and you can edit your notes with an Obsidian-like markdown editor.&lt;/p&gt; &#xA;&lt;p&gt;The hypothesis of the project is that AI tools for thought should &lt;strong&gt;run models locally&lt;/strong&gt; by default. Reor stands on the shoulders of the giants &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;Llama.cpp&lt;/a&gt;, &lt;a href=&#34;https://github.com/xenova/transformers.js&#34;&gt;Transformers.js&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://github.com/lancedb/lancedb&#34;&gt;LanceDB&lt;/a&gt; to enable both LLMs and embedding models to run locally. (Connecting to OpenAI-compatible APIs like Oobabooga is also supported.)&lt;/p&gt; &#xA;&lt;h3&gt;How can it possibly be &#34;self-organizing&#34;?&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Every note you write is chunked and embedded into an internal vector database.&lt;/li&gt; &#xA; &lt;li&gt;Related notes are connected automatically via vector similarity.&lt;/li&gt; &#xA; &lt;li&gt;LLM-powered Q&amp;amp;A does RAG on the corpus of notes.&lt;/li&gt; &#xA; &lt;li&gt;Everything can be searched semantically.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;One way to think about Reor is as a RAG app with two generators: the LLM and the human. In Q&amp;amp;A mode, the LLM is fed retrieved context from the corpus to help answer a query. Similarly, in editor mode, the human can toggle the sidebar to reveal related notes &#34;retrieved&#34; from the corpus. This is quite a powerful way of &#34;augmenting&#34; your thoughts by cross-referencing ideas in a current note against related ideas from your corpus.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/reorproject/reor/assets/17236551/1bbc1b2d-c3d9-451c-a008-7f12c84f96db&#34;&gt;https://github.com/reorproject/reor/assets/17236551/1bbc1b2d-c3d9-451c-a008-7f12c84f96db&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Getting Started&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download from &lt;a href=&#34;https://reorproject.org&#34;&gt;reorproject.org&lt;/a&gt; or &lt;a href=&#34;https://github.com/reorproject/reor/releases&#34;&gt;releases&lt;/a&gt;. Mac, Linux &amp;amp; Windows are all supported.&lt;/li&gt; &#xA; &lt;li&gt;Install like a normal App.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Running local models&lt;/h3&gt; &#xA;&lt;p&gt;Reor interacts directly with &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;Llama.cpp&lt;/a&gt; libraries so there&#39;s no need to download Ollama. Although right now, we don&#39;t download models for you so you&#39;ll need to download your model of choice manually:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download a GGUF model file. &lt;a href=&#34;https://huggingface.co/models?sort=downloads&amp;amp;search=gguf&#34;&gt;Hugging Face&lt;/a&gt; has this nice page with the most popular models. I recommend starting with a 7B 4-bit model and see how that performs on your system.&lt;/li&gt; &#xA; &lt;li&gt;Connect it in Reor settings under &#34;Add a new local model&#34;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You can also connect to an OpenAI-compatible API like Oobabooga, Ollama or OpenAI itself!&lt;/p&gt; &#xA;&lt;h3&gt;Importing notes from other apps&lt;/h3&gt; &#xA;&lt;p&gt;Reor works within a single directory in the filesystem. You choose the directory on first boot. To import notes/files from another app, you&#39;ll need to populate that directory manually with markdown files. Integrations with other apps are hopefully coming soon!&lt;/p&gt; &#xA;&lt;h3&gt;Building from source&lt;/h3&gt; &#xA;&lt;h4&gt;Clone repo:&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/reorproject/reor.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Install dependencies:&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Run for dev:&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Build:&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;npm run build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Contributions&lt;/h3&gt; &#xA;&lt;p&gt;Contributions are welcome in all areas: features, ideas, bug fixes, design, etc. This is very much a community driven project. There are some open issues to choose from. For new features, please open an issue to discuss it before beginning work on a PR :)&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;GPL-3.0 license. See &lt;code&gt;LICENSE&lt;/code&gt; for details.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Reor means &#34;to think&#34; in Latin.&lt;/em&gt;&lt;/p&gt;</summary>
  </entry>
</feed>