<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-02-17T01:28:27Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>microsoft/OmniParser</title>
    <updated>2025-02-17T01:28:27Z</updated>
    <id>tag:github.com,2025-02-17:/microsoft/OmniParser</id>
    <link href="https://github.com/microsoft/OmniParser" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A simple screen parsing tool towards pure vision based GUI agent&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OmniParser: Screen Parsing tool for Pure Vision Based GUI Agent&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/microsoft/OmniParser/master/imgs/logo.png&#34; alt=&#34;Logo&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2408.00203&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Paper-green&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;游닉 [&lt;a href=&#34;https://microsoft.github.io/OmniParser/&#34;&gt;Project Page&lt;/a&gt;] [&lt;a href=&#34;https://www.microsoft.com/en-us/research/articles/omniparser-v2-turning-any-llm-into-a-computer-use-agent/&#34;&gt;V2 Blog Post&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/microsoft/OmniParser-v2.0&#34;&gt;Models V2&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/microsoft/OmniParser&#34;&gt;Models V1.5&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/spaces/microsoft/OmniParser&#34;&gt;huggingface space (to be updated)&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;OmniParser&lt;/strong&gt; is a comprehensive method for parsing user interface screenshots into structured and easy-to-understand elements, which significantly enhances the ability of GPT-4V to generate actions that can be accurately grounded in the corresponding regions of the interface.&lt;/p&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2025/2] We release OmniParser V2 &lt;a href=&#34;https://huggingface.co/microsoft/OmniParser-v2.0&#34;&gt;checkpoints&lt;/a&gt;. &lt;a href=&#34;https://1drv.ms/v/c/650b027c18d5a573/EWXbVESKWo9Buu6OYCwg06wBeoM97C6EOTG6RjvWLEN1Qg?e=alnHGC&#34;&gt;Watch Video&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2025/2] We introduce OmniTool: Control a Windows 11 VM with OmniParser + your vision model of choice. OmniTool supports out of the box the following large language models - OpenAI (4o/o1/o3-mini), DeepSeek (R1), Qwen (2.5VL) or Anthropic Computer Use. &lt;a href=&#34;https://1drv.ms/v/c/650b027c18d5a573/EehZ7RzY69ZHn-MeQHrnnR4BCj3by-cLLpUVlxMjF4O65Q?e=8LxMgX&#34;&gt;Watch Video&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2025/1] V2 is coming. We achieve new state of the art results 39.5% on the new grounding benchmark &lt;a href=&#34;https://github.com/likaixin2000/ScreenSpot-Pro-GUI-Grounding/tree/main&#34;&gt;Screen Spot Pro&lt;/a&gt; with OmniParser v2 (will be released soon)! Read more details &lt;a href=&#34;https://github.com/microsoft/OmniParser/tree/master/docs/Evaluation.md&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;[2024/11] We release an updated version, OmniParser V1.5 which features 1) more fine grained/small icon detection, 2) prediction of whether each screen element is interactable or not. Examples in the demo.ipynb.&lt;/li&gt; &#xA; &lt;li&gt;[2024/10] OmniParser was the #1 trending model on huggingface model hub (starting 10/29/2024).&lt;/li&gt; &#xA; &lt;li&gt;[2024/10] Feel free to checkout our demo on &lt;a href=&#34;https://huggingface.co/spaces/microsoft/OmniParser&#34;&gt;huggingface space&lt;/a&gt;! (stay tuned for OmniParser + Claude Computer Use)&lt;/li&gt; &#xA; &lt;li&gt;[2024/10] Both Interactive Region Detection Model and Icon functional description model are released! &lt;a href=&#34;https://huggingface.co/microsoft/OmniParser&#34;&gt;Hugginface models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2024/09] OmniParser achieves the best performance on &lt;a href=&#34;https://microsoft.github.io/WindowsAgentArena/&#34;&gt;Windows Agent Arena&lt;/a&gt;!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;Install environment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;conda create -n &#34;omni&#34; python==3.12&#xA;conda activate omni&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Ensure you have the V2 weights downloaded in weights folder (ensure caption weights folder is called icon_caption_florence). If not download them with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;   rm -rf weights/icon_detect weights/icon_caption weights/icon_caption_florence &#xA;   for f in icon_detect/{train_args.yaml,model.pt,model.yaml} icon_caption/{config.json,generation_config.json,model.safetensors}; do huggingface-cli download microsoft/OmniParser-v2.0 &#34;$f&#34; --local-dir weights; done&#xA;   mv weights/icon_caption weights/icon_caption_florence&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- ## [deprecated]&#xA;Then download the model ckpts files in: https://huggingface.co/microsoft/OmniParser, and put them under weights/, default folder structure is: weights/icon_detect, weights/icon_caption_florence, weights/icon_caption_blip2. &#xA;&#xA;For v1: &#xA;convert the safetensor to .pt file. &#xA;```python&#xA;python weights/convert_safetensor_to_pt.py&#xA;&#xA;For v1.5: &#xA;download &#39;model_v1_5.pt&#39; from https://huggingface.co/microsoft/OmniParser/tree/main/icon_detect_v1_5, make a new dir: weights/icon_detect_v1_5, and put it inside the folder. No weight conversion is needed. &#xA;``` --&gt; &#xA;&lt;h2&gt;Examples:&lt;/h2&gt; &#xA;&lt;p&gt;We put together a few simple examples in the demo.ipynb.&lt;/p&gt; &#xA;&lt;h2&gt;Gradio Demo&lt;/h2&gt; &#xA;&lt;p&gt;To run gradio demo, simply run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python gradio_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Model Weights License&lt;/h2&gt; &#xA;&lt;p&gt;For the model checkpoints on huggingface model hub, please note that icon_detect model is under AGPL license since it is a license inherited from the original yolo model. And icon_caption_blip2 &amp;amp; icon_caption_florence is under MIT license. Please refer to the LICENSE file in the folder of each model: &lt;a href=&#34;https://huggingface.co/microsoft/OmniParser&#34;&gt;https://huggingface.co/microsoft/OmniParser&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;游닄 Citation&lt;/h2&gt; &#xA;&lt;p&gt;Our technical report can be found &lt;a href=&#34;https://arxiv.org/abs/2408.00203&#34;&gt;here&lt;/a&gt;. If you find our work useful, please consider citing our work:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{lu2024omniparserpurevisionbased,&#xA;      title={OmniParser for Pure Vision Based GUI Agent}, &#xA;      author={Yadong Lu and Jianwei Yang and Yelong Shen and Ahmed Awadallah},&#xA;      year={2024},&#xA;      eprint={2408.00203},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV},&#xA;      url={https://arxiv.org/abs/2408.00203}, &#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>cordx56/rustowl</title>
    <updated>2025-02-17T01:28:27Z</updated>
    <id>tag:github.com,2025-02-17:/cordx56/rustowl</id>
    <link href="https://github.com/cordx56/rustowl" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Visualize Ownership and Lifetimes in Rust&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt; 游불&lt;br&gt; RustOwl &lt;/h1&gt; &#xA; &lt;p&gt; Visualize ownership and lifetimes in Rust for debugging and optimization &lt;/p&gt; &#xA; &lt;p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/cordx56/rustowl/main/docs/readme-screenshot.png&#34;&gt; &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;RustOwl visualizes ownership movement and lifetimes of variables. When you save Rust source code, it is analyzed, and the ownership and lifetimes of variables are visualized when you hover over a variable or function call.&lt;/p&gt; &#xA;&lt;p&gt;RustOwl visualizes those by using underlines:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;游릴 green: variable&#39;s actual lifetime&lt;/li&gt; &#xA; &lt;li&gt;游릱 blue: immutable borrowing&lt;/li&gt; &#xA; &lt;li&gt;游릵 purple: mutable borrowing&lt;/li&gt; &#xA; &lt;li&gt;游릲 orange: value moved / function call&lt;/li&gt; &#xA; &lt;li&gt;游린 red: lifetime error - diff of lifetime between actual and expected&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Currently, we offer VSCode extension, Neovim plugin and Emacs package. For these editors, move the text cursor over the variable or function call you want to inspect and wait for 2 seconds to visualize the information. We implemented LSP server &lt;code&gt;cargo owlsp&lt;/code&gt; with an extended protocol. So, RustOwl can be used easily from other editor.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;Here we describe how to start using RustOwl with VSCode.&lt;/p&gt; &#xA;&lt;h3&gt;Prerequisite&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;curl&lt;/code&gt;, &lt;code&gt;rustup&lt;/code&gt; and &lt;code&gt;cargo&lt;/code&gt; installed&lt;/li&gt; &#xA; &lt;li&gt;Visual Studio Code (VSCode) installed&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We tested this guide on macOS Sequoia 15.2 on arm64 architecture with VSCode 1.96.4 and &lt;code&gt;rustup&lt;/code&gt; 1.27.1.&lt;/p&gt; &#xA;&lt;p&gt;We also tested this guide on Ubuntu 25.04 on arm64 architecture with VSCode 1.96.4 and &lt;code&gt;rustup&lt;/code&gt; 1.27.1. On Ubuntu, you need to run &lt;code&gt;apt install build-essential&lt;/code&gt; before installing.&lt;/p&gt; &#xA;&lt;p&gt;After installation, the extension will automatically run RustOwl when you save any Rust program in cargo workspace. The initial analysis may take some time, but from the second run onward, compile caching is used to reduce the analysis time.&lt;/p&gt; &#xA;&lt;p&gt;We tested on Windows 11 Education 23H2 on amd64 architecture. For Windows, please clone this repository and build RustOwl manually.&lt;/p&gt; &#xA;&lt;h3&gt;Install RustOwl&lt;/h3&gt; &#xA;&lt;p&gt;To install RustOwl command, run the command below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -L &#34;https://github.com/cordx56/rustowl/releases/download/v0.1.1/install.sh&#34; | sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;VSCode&lt;/h3&gt; &#xA;&lt;p&gt;You can install VSCode extension from &lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=cordx56.rustowl-vscode&#34;&gt;this link&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Also, you can download VSCode extension file ( &lt;code&gt;.vsix&lt;/code&gt; ) from &lt;a href=&#34;https://github.com/cordx56/rustowl/releases/download/v0.1.1/rustowl-vscode-0.1.1.vsix&#34;&gt;this link&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Other editor support&lt;/h2&gt; &#xA;&lt;p&gt;We support Neovim and Emacs. You can also create your own LSP client.&lt;/p&gt; &#xA;&lt;h3&gt;Neovim&lt;/h3&gt; &#xA;&lt;p&gt;Add to plugin manager:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;{ &#34;cordx56/rustowl&#34;, dependencies = { &#34;neovim/nvim-lspconfig&#34; } }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Emacs&lt;/h3&gt; &#xA;&lt;p&gt;Elpaca example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-elisp&#34;&gt;(elpaca&#xA;  (rustowlsp&#xA;    :host github&#xA;    :repo &#34;cordx56/rustowl&#34;&#xA;    :files (:defaults &#34;emacs/*&#34;)))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Build manually&lt;/h2&gt; &#xA;&lt;p&gt;Here, we describe manual install instructions from source code.&lt;/p&gt; &#xA;&lt;h3&gt;RustOwl&lt;/h3&gt; &#xA;&lt;h4&gt;Prerequisite&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;rustup&lt;/code&gt; and &lt;code&gt;cargo&lt;/code&gt; installed &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;You can install &lt;code&gt;rustup&lt;/code&gt; from &lt;a href=&#34;https://rustup.rs/&#34;&gt;this link&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;You need to set up the &lt;code&gt;PATH&lt;/code&gt; environment variable. To do this, follow the instructions provided by the &lt;code&gt;rustup&lt;/code&gt; installer. For example, in bash, run &lt;code&gt;export PATH=$HOME/.cargo/bin:$PATH&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;RustOwl has been tested on macOS Sequoia 15.2 on arm64 architecture with &lt;code&gt;rustup&lt;/code&gt; 1.27.1. We have not tested the installation of dependencies from other package repositories, such as Homebrew. You may need to uninstall any Rust-related packages installed through those repositories first. Other dependencies are locked in the configuration files and will be installed automatically.&lt;/p&gt; &#xA;&lt;p&gt;We have also tested this on Ubuntu 25.04 on arm64 architecture with &lt;code&gt;rustup&lt;/code&gt; 1.27.1. Additional dependencies may be required. We have confirmed that running &lt;code&gt;apt install build-essential&lt;/code&gt; is necessary on a freshly installed Ubuntu for linking.&lt;/p&gt; &#xA;&lt;h4&gt;Build &amp;amp; Run&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd rustowl&#xA;cargo install --path . --locked&#xA;cargo owlsp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;VSCode extension&lt;/h3&gt; &#xA;&lt;h4&gt;Prerequisite&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;VSCode installed &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;You can install VSCode from &lt;a href=&#34;https://code.visualstudio.com/&#34;&gt;this link&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Node.js installed&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;yarn&lt;/code&gt; installed &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;After installing Node.js, You can install &lt;code&gt;yarn&lt;/code&gt; by running &lt;code&gt;npm install -g yarn&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;VSCode extension has been tested on macOS Sequoia 15.2 on arm64 architecture with Visual Studio Code 1.96.4, Node.js v20.16.0, and &lt;code&gt;yarn&lt;/code&gt; 1.22.22. Other dependencies are locked in the configuration files and will be installed automatically.&lt;/p&gt; &#xA;&lt;h4&gt;Build &amp;amp; Run&lt;/h4&gt; &#xA;&lt;p&gt;First, install the dependencies.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd vscode&#xA;yarn install --frozen-lockfile&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then open &lt;code&gt;vscode&lt;/code&gt; directory in VSCode.&lt;/p&gt; &#xA;&lt;p&gt;A notification to install the recommended VSCode extension will appear in the bottom right corner of VSCode. Click the install button, wait for the installation to finish, and then restart VSCode.&lt;/p&gt; &#xA;&lt;p&gt;Open &lt;code&gt;vscode&lt;/code&gt; directory again, and press the &lt;code&gt;F5&lt;/code&gt; key in the VSCode window. A new VSCode window with the extension enabled will appear.&lt;/p&gt; &#xA;&lt;p&gt;Open cargo workspace directory in the new VSCode window.&lt;/p&gt; &#xA;&lt;p&gt;When you save Rust files, decoration indicating the movement of ownership and lifetimes will appear in the editor.&lt;/p&gt; &#xA;&lt;h2&gt;Note&lt;/h2&gt; &#xA;&lt;p&gt;In this tool, due to the limitations of VSCode&#39;s decoration specifications, characters with descenders, such as g or parentheses, may occasionally not display underlines properly. Additionally, we observed that the &lt;code&gt;println!&lt;/code&gt; macro sometimes produces extra output, though this does not affect usability in any significant way.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>mongodb-developer/GenAI-Showcase</title>
    <updated>2025-02-17T01:28:27Z</updated>
    <id>tag:github.com,2025-02-17:/mongodb-developer/GenAI-Showcase</id>
    <link href="https://github.com/mongodb-developer/GenAI-Showcase" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GenAI Cookbook&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;MongoDB&#39;s GenAI Showcase&lt;/h2&gt; &#xA;&lt;p&gt;Welcome to MongoDB&#39;s Generative AI Showcase Repository!&lt;/p&gt; &#xA;&lt;p&gt;Whether you are just starting out on your Generative AI journey, or looking to build advanced GenAI applications, we&#39;ve got you covered. This repository has an exhaustive list of examples and sample applications that cover Retrieval-Augmented Generation (RAG), AI Agents, and industry-specific use cases.&lt;/p&gt; &#xA;&lt;p&gt;Discover how MongoDB integrates into RAG pipelines and AI Agents, serving as a vector database, operational database, and memory provider.&lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;p&gt;This repo mainly contains:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Jupyter notebooks examples for RAG, agentic applications, evaluations etc. under &lt;code&gt;notebooks&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Javascipt and Python apps and demos under &lt;code&gt;apps&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Contributions from our AI partners under &lt;code&gt;partners&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;You will need to connect to a MongoDB cluster to run any of the apps or examples in this repo. Follow these steps to get set up:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Register for a &lt;a href=&#34;https://www.mongodb.com/cloud/atlas/register&#34;&gt;free MongoDB Atlas account&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.mongodb.com/docs/guides/atlas/cluster/&#34;&gt;Create a new database cluster&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.mongodb.com/docs/guides/atlas/connection-string/&#34;&gt;Obtain the connection string&lt;/a&gt; for your database cluster&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions! Please read our &lt;a href=&#34;https://raw.githubusercontent.com/mongodb-developer/GenAI-Showcase/main/CONTRIBUTING.md&#34;&gt;Contribution Guidelines&lt;/a&gt; for more information on how to participate.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/mongodb-developer/GenAI-Showcase/main/LICENSE&#34;&gt;MIT License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Support&lt;/h2&gt; &#xA;&lt;p&gt;As you work through these examples, if you encounter any problems, please &lt;a href=&#34;https://github.com/mongodb-developer/GenAI-Showcase/issues/new&#34;&gt;open a new issue&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Additional Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.mongodb.com/resources/use-cases/artificial-intelligence&#34;&gt;AI Learning Hub&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.mongodb.com/community/forums/c/generative-ai/162&#34;&gt;GenAI Community Forum&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mongodb/docs-notebooks&#34;&gt;Tutorials and code examples from our official docs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>