<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-07T01:26:13Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>HVision-NKU/StoryDiffusion</title>
    <updated>2024-05-07T01:26:13Z</updated>
    <id>tag:github.com,2024-05-07:/HVision-NKU/StoryDiffusion</id>
    <link href="https://github.com/HVision-NKU/StoryDiffusion" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Create Magic Story!&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/f79da6b7-0b3b-4dd7-8dd0-ba0b15306fe6&#34; height=&#34;100&#34;&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h2&gt;StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation &lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://huggingface.co/datasets/huggingface/badges/resolve/main/paper-page-md-dark.svg?sanitize=true&#34; alt=&#34;Paper page&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA; &lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2405.01434&#34;&gt;Paper&lt;/a&gt;]   [&lt;a href=&#34;https://storydiffusion.github.io/&#34;&gt;Project Page&lt;/a&gt;]   [&lt;a href=&#34;https://huggingface.co/spaces/YupengZhou/StoryDiffusion&#34;&gt;🤗 Comic Generation Demo &lt;/a&gt;] &lt;a href=&#34;https://replicate.com/cjwbw/StoryDiffusion&#34;&gt;&lt;img src=&#34;https://replicate.com/cjwbw/StoryDiffusion/badge&#34; alt=&#34;Replicate&#34;&gt;&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;left&#34;&gt; &#xA; &lt;h4&gt;For results sharing and discussion: &lt;a href=&#34;https://discord.gg/hSJZ35fV&#34;&gt;https://discord.gg/hSJZ35fV&lt;/a&gt;&lt;/h4&gt; &#xA; &lt;h4&gt;For codebase and deployment-related discussion: &lt;a href=&#34;https://discord.gg/2HFUHT9p&#34;&gt;https://discord.gg/2HFUHT9p&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Official implementation of &lt;strong&gt;&lt;a href=&#34;&#34;&gt;StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;strong&gt;Demo Video&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/d5b80f8f-09b0-48cd-8b10-daff46d422af&#34;&gt;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/d5b80f8f-09b0-48cd-8b10-daff46d422af&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;🌠 &lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;p&gt;StoryDiffusion can create a magic story by generating consistent images and videos. Our work mainly has two parts:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Consistent self-attention for character-consistent image generation over long-range sequences. It is hot-pluggable and compatible with all SD1.5 and SDXL-based image diffusion models. For the current implementation, the user needs to provide at least 3 text prompts for the consistent self-attention module. We recommend at least 5 - 6 text prompts for better layout arrangement.&lt;/li&gt; &#xA; &lt;li&gt;Motion predictor for long-range video generation, which predicts motion between Condition Images in a compressed image semantic space, achieving larger motion prediction.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;🔥 &lt;strong&gt;Examples&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Comics generation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/b3771cbc-b6ca-4e26-bdc5-d944daf9f266&#34; alt=&#34;1&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Image-to-Video generation （Results are HIGHLY compressed for speed）&lt;/h3&gt; &#xA;&lt;p&gt;Leveraging the images produced through our Consistent Self-Attention mechanism, we can extend the process to create videos by seamlessly transitioning between these images. This can be considered as a two-stage long video generation approach.&lt;/p&gt; &#xA;&lt;p&gt;Note: results are &lt;strong&gt;highly compressed&lt;/strong&gt; for speed, you can visit &lt;a href=&#34;https://storydiffusion.github.io/&#34;&gt;our website&lt;/a&gt; for the high-quality version.&lt;/p&gt; &#xA;&lt;h4&gt;Two-stage Long Videos Generation (New Update)&lt;/h4&gt; &#xA;&lt;p&gt;Combining the two parts, we can generate very long and high-quality AIGC videos.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Video1&lt;/th&gt; &#xA;   &lt;th&gt;Video2&lt;/th&gt; &#xA;   &lt;th&gt;Video3&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/4e7e0f24-5f90-419b-9a1e-cdf36d361b26&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/f509343d-d691-4e2a-b615-7d96381ef7c1&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/4f0f7abb-4ae4-47a6-b692-5bdd8d9c8006&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Long Video Results using Condition Images&lt;/h4&gt; &#xA;&lt;p&gt;Our Image-to-Video model can generate a video by providing a sequence of user-input condition images.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Video1&lt;/th&gt; &#xA;   &lt;th&gt;Video2&lt;/th&gt; &#xA;   &lt;th&gt;Video3&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/af6f5c50-c773-4ef2-a757-6d7a46393f39&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/d58e4037-d8df-4f90-8c81-ce4b6d2d868e&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/40da15ba-f5c1-48d8-84d6-8d327207d696&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Video4&lt;/th&gt; &#xA;   &lt;th&gt;Video5&lt;/th&gt; &#xA;   &lt;th&gt;Video6&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/8f04c9fc-3031-49e3-9de8-83d582b80a1f&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/604107fb-8afe-4052-bda4-362c646a756e&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/b05fa6a0-12e6-4111-abf8-18b8cd84f3ff&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Short Videos&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Video1&lt;/th&gt; &#xA;   &lt;th&gt;Video2&lt;/th&gt; &#xA;   &lt;th&gt;Video3&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/5e7f717f-daad-46f6-b3ba-c087bd843158&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/79aa52b2-bf37-4c9c-8555-c7050aec0cdf&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/9fdfd091-10e6-434e-9ce7-6d6e6d8f4b22&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Video4&lt;/th&gt; &#xA;   &lt;th&gt;Video5&lt;/th&gt; &#xA;   &lt;th&gt;Video6&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/0b219b60-a998-4820-9657-6abe1747cb6b&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/d387aef0-ffc8-41b0-914f-4b0392d9f8c5&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://github.com/HVision-NKU/StoryDiffusion/assets/49511209/3c64958a-1079-4ca0-a9cf-e0486adbc57f&#34; width=&#34;224&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;🚩 &lt;strong&gt;TODO/Updates&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Commic Results of StoryDiffusion.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Video Results of StoryDiffusion.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Source code of Comic Generation&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Source code of gradio demo&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Source code of Video Generation Model&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Pretrained weight of Video Generation Model&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;🔧 Dependencies and Installation&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python &amp;gt;= 3.8 (Recommend to use &lt;a href=&#34;https://www.anaconda.com/download/#linux&#34;&gt;Anaconda&lt;/a&gt; or &lt;a href=&#34;https://docs.conda.io/en/latest/miniconda.html&#34;&gt;Miniconda&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch &amp;gt;= 2.0.0&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create --name storydiffusion python=3.10&#xA;conda activate storydiffusion&#xA;pip install -U pip&#xA;&#xA;# Install requirements&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;How to use&lt;/h1&gt; &#xA;&lt;p&gt;Currently, we provide two ways for you to generate comics.&lt;/p&gt; &#xA;&lt;h2&gt;Use the jupyter notebook&lt;/h2&gt; &#xA;&lt;p&gt;You can open the &lt;code&gt;Comic_Generation.ipynb&lt;/code&gt; and run the code.&lt;/p&gt; &#xA;&lt;h2&gt;Start a local gradio demo&lt;/h2&gt; &#xA;&lt;p&gt;Run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python gradio_app_sdxl_specific_id.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We provide a low GPU Memory cost version, it was test on a machine with 24GB GPU-memory(Tesla A10) and 30GB RAM, and expcted work well with &amp;gt;20 G GPU-memory.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python gradio_app_sdxl_specific_id_low_vram.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions, you are very welcome to email &lt;a href=&#34;mailto:ypzhousdu@gmail.com&#34;&gt;ypzhousdu@gmail.com&lt;/a&gt; and &lt;a href=&#34;mailto:zhoudaquan21@gmail.com&#34;&gt;zhoudaquan21@gmail.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Disclaimer&lt;/h1&gt; &#xA;&lt;p&gt;This project strives to impact the domain of AI-driven image and video generation positively. Users are granted the freedom to create images and videos using this tool, but they are expected to comply with local laws and utilize it responsibly. The developers do not assume any responsibility for potential misuse by users.&lt;/p&gt; &#xA;&lt;h1&gt;BibTeX&lt;/h1&gt; &#xA;&lt;p&gt;If you find StoryDiffusion useful for your research and applications, please cite using this BibTeX:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-BibTeX&#34;&gt;@article{Zhou2024storydiffusion,&#xA;  title={StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation},&#xA;  author={Zhou, Yupeng and Zhou, Daquan and Cheng, Ming-Ming and Feng, Jiashi and Hou, Qibin},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>dev-xo/remix-saas</title>
    <updated>2024-05-07T01:26:13Z</updated>
    <id>tag:github.com,2024-05-07:/dev-xo/remix-saas</id>
    <link href="https://github.com/dev-xo/remix-saas" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Lightweight, Production-Ready Remix Stack for your next SaaS Application.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; 🛍️ Remix SaaS &lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt; A Lightweight, Feature-Rich, and Production-Ready Remix Stack for your next SaaS application. &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt; &lt;a href=&#34;https://remix-saas.fly.dev&#34;&gt;Live Demo&lt;/a&gt; · &lt;a href=&#34;https://github.com/dev-xo/remix-saas/tree/main/docs&#34;&gt;Documentation&lt;/a&gt; · &lt;a href=&#34;https://twitter.com/DanielKanem&#34;&gt;Twitter&lt;/a&gt; &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npx create-remix-saas@latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://remix-saas.fly.dev&#34;&gt;Live Demo&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://remix-saas.fly.dev&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/dev-xo/dev-xo/main/remix-saas/intro.png&#34; alt=&#34;Remix SaaS&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;We&#39;ve created a simple demo that displays all template-provided features. Psst! Give the site a few seconds to load! &lt;em&gt;(It&#39;s running on a free tier!)&lt;/em&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] Remix SaaS is an Open Source Template that shares common bits of code with: &lt;a href=&#34;https://github.com/remix-run/indie-stack&#34;&gt;Indie Stack&lt;/a&gt;, &lt;a href=&#34;https://github.com/epicweb-dev/epic-stack&#34;&gt;Epic Stack&lt;/a&gt;, &lt;a href=&#34;https://github.com/rphlmr/supa-stripe-stack&#34;&gt;Supa Stripe Stack&lt;/a&gt;, and some other amazing Open Source Remix resources. Check them out, please!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Please, read the &lt;a href=&#34;https://github.com/dev-xo/remix-saas/tree/main/docs#remix-saas-documentation&#34;&gt;Getting Started Documentation&lt;/a&gt; to successfully initialize your &lt;strong&gt;Remix SaaS&lt;/strong&gt; Template.&lt;/p&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;If you found &lt;strong&gt;Remix SaaS&lt;/strong&gt; helpful, consider supporting it with a ⭐ &lt;a href=&#34;https://github.com/dev-xo/remix-saas&#34;&gt;Star&lt;/a&gt;. It helps the repository grow and provides the required motivation to continue maintaining the project. Thank you!&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;p&gt;Special thanks to &lt;a href=&#34;https://github.com/mw10013&#34;&gt;@mw10013&lt;/a&gt; who has been part of the Remix SaaS development.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>solana-labs/solana</title>
    <updated>2024-05-07T01:26:13Z</updated>
    <id>tag:github.com,2024-05-07:/solana-labs/solana</id>
    <link href="https://github.com/solana-labs/solana" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Web-Scale Blockchain for fast, secure, scalable, decentralized apps and marketplaces.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://solana.com&#34;&gt; &lt;img alt=&#34;Solana&#34; src=&#34;https://i.imgur.com/IKyzQ6T.png&#34; width=&#34;250&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://crates.io/crates/solana-core&#34;&gt;&lt;img src=&#34;https://img.shields.io/crates/v/solana-core.svg?sanitize=true&#34; alt=&#34;Solana crate&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.rs/solana-core&#34;&gt;&lt;img src=&#34;https://docs.rs/solana-core/badge.svg?sanitize=true&#34; alt=&#34;Solana documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://buildkite.com/solana-labs/solana/builds?branch=master&#34;&gt;&lt;img src=&#34;https://badge.buildkite.com/8cc350de251d61483db98bdfc895b9ea0ac8ffa4a32ee850ed.svg?branch=master&#34; alt=&#34;Build status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/solana-labs/solana&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/solana-labs/solana/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Building&lt;/h1&gt; &#xA;&lt;h2&gt;&lt;strong&gt;1. Install rustc, cargo and rustfmt.&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl https://sh.rustup.rs -sSf | sh&#xA;$ source $HOME/.cargo/env&#xA;$ rustup component add rustfmt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When building the master branch, please make sure you are using the latest stable rust version by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ rustup update&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When building a specific release branch, you should check the rust version in &lt;code&gt;ci/rust-version.sh&lt;/code&gt; and if necessary, install that version by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ rustup install VERSION&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that if this is not the latest rust version on your machine, cargo commands may require an &lt;a href=&#34;https://rust-lang.github.io/rustup/overrides.html&#34;&gt;override&lt;/a&gt; in order to use the correct version.&lt;/p&gt; &#xA;&lt;p&gt;On Linux systems you may need to install libssl-dev, pkg-config, zlib1g-dev, protobuf etc.&lt;/p&gt; &#xA;&lt;p&gt;On Ubuntu:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo apt-get update&#xA;$ sudo apt-get install libssl-dev libudev-dev pkg-config zlib1g-dev llvm clang cmake make libprotobuf-dev protobuf-compiler&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On Fedora:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo dnf install openssl-devel systemd-devel pkg-config zlib-devel llvm clang cmake make protobuf-devel protobuf-compiler perl-core&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;strong&gt;2. Download the source code.&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone https://github.com/solana-labs/solana.git&#xA;$ cd solana&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;strong&gt;3. Build.&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./cargo build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Testing&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Run the test suite:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./cargo test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Starting a local testnet&lt;/h3&gt; &#xA;&lt;p&gt;Start your own testnet locally, instructions are in the &lt;a href=&#34;https://docs.solanalabs.com/clusters/benchmark&#34;&gt;online docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Accessing the remote development cluster&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;devnet&lt;/code&gt; - stable public cluster for development accessible via devnet.solana.com. Runs 24/7. Learn more about the &lt;a href=&#34;https://docs.solanalabs.com/clusters&#34;&gt;public clusters&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Benchmarking&lt;/h1&gt; &#xA;&lt;p&gt;First, install the nightly build of rustc. &lt;code&gt;cargo bench&lt;/code&gt; requires the use of the unstable features only available in the nightly build.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ rustup install nightly&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the benchmarks:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cargo +nightly bench&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Release Process&lt;/h1&gt; &#xA;&lt;p&gt;The release process for this project is described &lt;a href=&#34;https://raw.githubusercontent.com/solana-labs/solana/master/RELEASE.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Code coverage&lt;/h1&gt; &#xA;&lt;p&gt;To generate code coverage statistics:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ scripts/coverage.sh&#xA;$ open target/cov/lcov-local/index.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Why coverage? While most see coverage as a code quality metric, we see it primarily as a developer productivity metric. When a developer makes a change to the codebase, presumably it&#39;s a &lt;em&gt;solution&lt;/em&gt; to some problem. Our unit-test suite is how we encode the set of &lt;em&gt;problems&lt;/em&gt; the codebase solves. Running the test suite should indicate that your change didn&#39;t &lt;em&gt;infringe&lt;/em&gt; on anyone else&#39;s solutions. Adding a test &lt;em&gt;protects&lt;/em&gt; your solution from future changes. Say you don&#39;t understand why a line of code exists, try deleting it and running the unit-tests. The nearest test failure should tell you what problem was solved by that code. If no test fails, go ahead and submit a Pull Request that asks, &#34;what problem is solved by this code?&#34; On the other hand, if a test does fail and you can think of a better way to solve the same problem, a Pull Request with your solution would most certainly be welcome! Likewise, if rewriting a test can better communicate what code it&#39;s protecting, please send us that patch!&lt;/p&gt; &#xA;&lt;h1&gt;Disclaimer&lt;/h1&gt; &#xA;&lt;p&gt;All claims, content, designs, algorithms, estimates, roadmaps, specifications, and performance measurements described in this project are done with the Solana Labs, Inc. (“SL”) good faith efforts. It is up to the reader to check and validate their accuracy and truthfulness. Furthermore, nothing in this project constitutes a solicitation for investment.&lt;/p&gt; &#xA;&lt;p&gt;Any content produced by SL or developer resources that SL provides are for educational and inspirational purposes only. SL does not encourage, induce or sanction the deployment, integration or use of any such applications (including the code comprising the Solana blockchain protocol) in violation of applicable laws or regulations and hereby prohibits any such deployment, integration or use. This includes the use of any such applications by the reader (a) in violation of export control or sanctions laws of the United States or any other applicable jurisdiction, (b) if the reader is located in or ordinarily resident in a country or territory subject to comprehensive sanctions administered by the U.S. Office of Foreign Assets Control (OFAC), or (c) if the reader is or is working on behalf of a Specially Designated National (SDN) or a person subject to similar blocking or denied party prohibitions.&lt;/p&gt; &#xA;&lt;p&gt;The reader should be aware that U.S. export control and sanctions laws prohibit U.S. persons (and other persons that are subject to such laws) from transacting with persons in certain countries and territories or that are on the SDN list. Accordingly, there is a risk to individuals that other persons using any of the code contained in this repo, or a derivation thereof, may be sanctioned persons and that transactions with such persons would be a violation of U.S. export controls and sanctions law.&lt;/p&gt;</summary>
  </entry>
</feed>