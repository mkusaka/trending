<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-01T01:31:37Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>lamini-ai/lamini</title>
    <updated>2023-05-01T01:31:37Z</updated>
    <id>tag:github.com,2023-05-01:/lamini-ai/lamini</id>
    <link href="https://github.com/lamini-ai/lamini" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Lamini: The LLM engine for rapidly customizing models ü¶ô&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lamini-ai/lamini/main/LICENSE.txt&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-CC%20By%204.0-green.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.python.org/downloads/release/python-370/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.7+-blue.svg?sanitize=true&#34; alt=&#34;Python 3.7+&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/psf/black&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true&#34; alt=&#34;Code style: black&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Official repo for Lamini&#39;s data generator for generating instructions to train instruction-following LLMs.&lt;/p&gt; &#xA;&lt;p&gt;All data and LLMs are under a CC-BY license that allows commercial use‚Äîall yours, you own it! ü¶ôü¶ôü¶ô&lt;/p&gt; &#xA;&lt;p&gt;What&#39;s here?&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;a href=&#34;https://raw.githubusercontent.com/lamini-ai/lamini/main/#data-release&#34;&gt;71K dataset of instructions&lt;/a&gt; used for finetuning your own instruction-following LLM (like ChatGPT, which was also trained to follow instructions).&lt;/li&gt; &#xA; &lt;li&gt;The code for the &lt;a href=&#34;https://raw.githubusercontent.com/lamini-ai/lamini/main/#run&#34;&gt;data generator&lt;/a&gt;, which only needs 100 datapoints to start generating 70k+ datapoints. You can customize the original 100+ datapoints to your own domain, to focus the data generator on that domain.&lt;/li&gt; &#xA; &lt;li&gt;Open-source fine-tuned LLMs that follow instructions, fine-tuned using a base Pythia model with the Lamini engine: [&lt;a href=&#34;https://huggingface.co/lamini/instruct-tuned-2.8b&#34;&gt;weights&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/spaces/lamini/instruct-playground&#34;&gt;playground&lt;/a&gt;].&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See our &lt;a href=&#34;https://lamini.ai/blog&#34;&gt;blogpost&lt;/a&gt; for layperson&#39;s terms of what&#39;s going on.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/lamini-ai/lamini/main/assets/process.png&#34; alt=&#34;Lamini Process Step by Step&#34; width=&#34;700&#34;&gt; &#xA;&lt;h2&gt;Authentication to Lamini&lt;/h2&gt; &#xA;&lt;p&gt;Ready to configure your API key? It&#39;s easy-peasy! üîë&lt;/p&gt; &#xA;&lt;p&gt;First, navigate to your &lt;a href=&#34;https://app.lamini.ai&#34;&gt;Lamini account page&lt;/a&gt; to retrieve your unique API key. Remember to keep this key a secret, and don&#39;t expose it in any client-side code or share it with others.&lt;/p&gt; &#xA;&lt;p&gt;Next, create a config file, like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir ~/.powerml&#xA;touch ~/.powerml/configure_llama.yaml # backend system names&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, open the file with a text editor and place your key in it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;production:&#xA;    key: &#34;&amp;lt;YOUR-KEY-HERE&amp;gt;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The best part? The &lt;a href=&#34;https://pypi.org/project/llama-llm&#34;&gt;Lamini python package&lt;/a&gt; will automatically load your key from this config file for you, so you don&#39;t have to worry about it üôå&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re running Lamini in a docker container, make sure to copy/mount this file inside the container üê≥&lt;/p&gt; &#xA;&lt;p&gt;See our &lt;a href=&#34;https://lamini-ai.github.io/auth/&#34;&gt;API docs&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Run&lt;/h2&gt; &#xA;&lt;p&gt;Clone the repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:lamini-ai/lamini.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Using Python üêç&lt;/h3&gt; &#xA;&lt;p&gt;In the repository, install python dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the program, to start generating data üìäüìäüìä&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 generate_data.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Using Docker üê≥&lt;/h3&gt; &#xA;&lt;p&gt;Make sure you have &lt;a href=&#34;https://docs.docker.com/get-docker/&#34;&gt;docker&lt;/a&gt; installed.&lt;/p&gt; &#xA;&lt;p&gt;Then, run this command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./run_generate_data_docker.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Expected Outputs &amp;amp; Autosaved Data ü¶ô&lt;/h2&gt; &#xA;&lt;p&gt;When you run the program, you should start seeing output of a &lt;code&gt;Seed Question&lt;/code&gt;, from the original small dataset in &lt;a href=&#34;https://raw.githubusercontent.com/lamini-ai/lamini/main/seed_tasks.jsonl&#34;&gt;&lt;code&gt;seed_tasks.jsonl&lt;/code&gt;&lt;/a&gt;, and a &lt;code&gt;Novel Question&lt;/code&gt;, which is a generated question based on that &lt;code&gt;Seed Question&lt;/code&gt;.[^1] [^1]: The &lt;code&gt;Seed Questions&lt;/code&gt; in the Lamini seed dataset are instructions (combination of questions and commands), based on the &lt;a href=&#34;https://github.com/yizhongw/self-instruct&#34;&gt;self-instruct dataset&lt;/a&gt;. The generated questions are similar in nature to those and therefore don&#39;t &lt;em&gt;have to&lt;/em&gt; be questions. You can find the seed dataset at &lt;code&gt;data/lamini_dataset.jsonl&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;====== Seed Question =====&#xA; question=&#39;Plan a weekly lunch menu for a school. Write down a main dish, a carbohydrate side dish, a vegetable side dish, and a dessert for each day.&#39;&#xA;===== Novel Question =====&#xA; question=&#39;Write a knock knock story that has the same theme as the given one, but the characters, plots and settings are different&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;These generated questions are saved to &lt;code&gt;data/questions.jsonl&lt;/code&gt;. This JSON file is a list of dictionaries with a &lt;code&gt;question&lt;/code&gt; field.&lt;/p&gt; &#xA;&lt;p&gt;Next, you&#39;ll see a &lt;code&gt;Response&lt;/code&gt; generated for each &lt;code&gt;Novel Question&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;====== Question =====&#xA; question=&#39;Which exercises are best&#39;&#xA;===== Response =====&#xA; response=&#39;It really depends what you want to achieve. If you want to lose weight, I would recommend high intensity interval training (HIIT) because it is really effective. If you want to gain muscle, I would recommend steady-state cardio like running or walking as these help maintain muscle mass. If you are interested in both losing weight and gaining muscle, I would recommend a combination of both HIIT and steady-state cardio.\n\n\nHIIT exercises are: running fast for short periods of time, followed by slow walking or jogging for longer periods of time. An example of a HIIT exercise is called the ‚ÄúLunges&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;These pairs are saved to &lt;code&gt;data/dataset.jsonl&lt;/code&gt;. This JSON file is a list of dictionaries with &lt;code&gt;question&lt;/code&gt; and &lt;code&gt;response&lt;/code&gt; fields.&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s poggers üí•&lt;/p&gt; &#xA;&lt;h2&gt;Modify&lt;/h2&gt; &#xA;&lt;h3&gt;I want to use my own seed data&lt;/h3&gt; &#xA;&lt;p&gt;We suggest creating your own dataset and changing the path to the &lt;a href=&#34;https://raw.githubusercontent.com/lamini-ai/lamini/main/seed_tasks.jsonl&#34;&gt;&lt;code&gt;seed_tasks.jsonl&lt;/code&gt;&lt;/a&gt; in &lt;code&gt;generate_data.py&lt;/code&gt;(./generate_data.py) --- or you can replace &lt;a href=&#34;https://raw.githubusercontent.com/lamini-ai/lamini/main/seed_tasks.jsonl&#34;&gt;&lt;code&gt;seed_tasks.jsonl&lt;/code&gt;&lt;/a&gt; with your own data in the same format. You can of course also modify how the data is loaded or write your own script with the &lt;code&gt;llama-llm&lt;/code&gt; library (pssst, &lt;a href=&#34;https://lamini-ai.github.io/auth/&#34;&gt;API docs&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h3&gt;I only want to generate questions (to start)&lt;/h3&gt; &#xA;&lt;p&gt;In &lt;code&gt;generate_data.py&lt;/code&gt;(./generate_data.py), you can just run &lt;code&gt;generate_questions&lt;/code&gt;. This is a common use case for using human review after the question generation step to filter only the good ones for the next step of generating a response for each question.&lt;/p&gt; &#xA;&lt;h3&gt;I have my own instructions, and just want to generate responses&lt;/h3&gt; &#xA;&lt;p&gt;In &lt;code&gt;generate_data.py&lt;/code&gt;(./generate_data.py), you can just use the function &lt;code&gt;make_pairs&lt;/code&gt; to create the question-response pairs. This is a common use case step to run this stage separately, e.g. after human review of the generated questions, or if there was an error at this step last time.&lt;/p&gt; &#xA;&lt;h3&gt;I want to generate more than 100 instructions&lt;/h3&gt; &#xA;&lt;p&gt;Change the count flag &lt;code&gt;-c&lt;/code&gt; for the number question-repsonse pairs to generate in total. The default is set to 100.&lt;/p&gt; &#xA;&lt;h2&gt;Cleaning&lt;/h2&gt; &#xA;&lt;h3&gt;Using Python üêç&lt;/h3&gt; &#xA;&lt;p&gt;In the repository, run the &lt;code&gt;remove_duplicates.py&lt;/code&gt; to remove duplicate questions from data/dataset.jsonl&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 remove_duplicates.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the program, to run a basic cleaning job on your data üßºüßºüßº&lt;/p&gt; &#xA;&lt;p&gt;In the repository, run the &lt;code&gt;remove_duplicates_completion.py&lt;/code&gt; to remove responses where the model repeats itself from data/dataset.jsonl&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 remove_duplicates_completion.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run the program, to run a more extensive cleaning job on your data üõÅüõÅüõÅ&lt;/p&gt; &#xA;&lt;p&gt;These are examples. Consider using human filtering or writing additional post processing programs to further cleand and improve your data. Your fine-tuned models will thank you!&lt;/p&gt; &#xA;&lt;h2&gt;Data Release&lt;/h2&gt; &#xA;&lt;p&gt;We&#39;ve run this script a few times and saved the results for you to freely use, at &lt;a href=&#34;https://raw.githubusercontent.com/lamini-ai/lamini/main/data/lamini_dataset.jsonl&#34;&gt;&lt;code&gt;data/lamini_dataset.jsonl&lt;/code&gt;&lt;/a&gt; üí∏&lt;/p&gt; &#xA;&lt;p&gt;This file contains 72K instruction-following data for commercial use (ie. feel free to use it for your business! üí∞üìà). It&#39;s the same as the output, a list of dictionaries, each of which contains the following fields:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;question&lt;/code&gt;: &lt;code&gt;str&lt;/code&gt;, describes the task the model should perform. Each of the 52K instructions is unique, as generated by &lt;code&gt;lamini/open&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;response&lt;/code&gt;: &lt;code&gt;str&lt;/code&gt;, the answer to the instruction as generated by &lt;code&gt;lamini/instruct&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;About Lamini&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://lamini.ai/&#34;&gt;Lamini&lt;/a&gt; is the world&#39;s most powerful LLM engine, unlocking the power of generative AI for every company by putting their data to work. It is based on the &lt;a href=&#34;https://en.wikipedia.org/wiki/Lamini&#34;&gt;lamini tribe&lt;/a&gt;, which includes llamas (LLMs!), alpacas, etc.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>t3-oss/t3-env</title>
    <updated>2023-05-01T01:31:37Z</updated>
    <id>tag:github.com,2023-05-01:/t3-oss/t3-env</id>
    <link href="https://github.com/t3-oss/t3-env" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Typesafe Envs made Simple&lt;/h1&gt; &#xA;&lt;p&gt;Deploying your app with invalid environment variables is a hassle. This package helps you to avoid that.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Core package, no framework specific features&#xA;pnpm add @t3-oss/env-core zod&#xA;# or, with options preconfigured for Next.js&#xA;pnpm add @t3-oss/env-nextjs zod&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Currently only supports Zod (which you&#39;ll need to install separately). Bring your own validation library is on the roadmap.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;For full documentation, see &lt;a href=&#34;https://env.t3.gg&#34;&gt;https://env.t3.gg&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;This package supports the full power of Zod, meaning you can use &lt;code&gt;transforms&lt;/code&gt; and &lt;code&gt;default&lt;/code&gt; values.&lt;/p&gt; &#xA;&lt;h3&gt;Define your schema&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ts&#34;&gt;// src/env.mjs&#xA;import { createEnv } from &#34;@t3-oss/env-nextjs&#34;;&#xA;import { z } from &#34;zod&#34;;&#xA;&#xA;export const env = createEnv({&#xA;  /*&#xA;   * Serverside Environment variables, not available on the client.&#xA;   * Will throw if you access these variables on the client.&#xA;   */&#xA;  server: {&#xA;    DATABASE_URL: z.string().url(),&#xA;    OPEN_AI_API_KEY: z.string().min(1),&#xA;  },&#xA;  /*&#xA;   * Environment variables available on the client (and server).&#xA;   *&#xA;   * üí° You&#39;ll get typeerrors if these are not prefixed with NEXT_PUBLIC_.&#xA;   */&#xA;  client: {&#xA;    NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY: z.string().min(1),&#xA;  },&#xA;  /*&#xA;   * Due to how Next.js bundles environment variables on Edge and Client,&#xA;   * we need to manually destructure them to make sure all are included in bundle.&#xA;   *&#xA;   * üí° You&#39;ll get typeerrors if not all variables from `server` &amp;amp; `client` are included here.&#xA;   */&#xA;  runtimeEnv: {&#xA;    DATABASE_URL: process.env.DATABASE_URL,&#xA;    OPEN_AI_API_KEY: process.env.OPEN_AI_API_KEY,&#xA;    NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY:&#xA;      process.env.NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY,&#xA;  },&#xA;});&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Use said schema in your app with autocompletion and type inference&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ts&#34;&gt;// src/app/hello/route.ts&#xA;import { env } from &#34;../env.mjs&#34;;&#xA;&#xA;export const GET = (req: Request) =&amp;gt; {&#xA;  const DATABASE_URL = env.DATABASE_URL;&#xA;  // use it...&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Bring your own validation library - currently only supports Zod.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Validate that all &lt;code&gt;_input&lt;/code&gt; fields are strings to begin with, transforms may be applied on strings.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>Genymobile/scrcpy</title>
    <updated>2023-05-01T01:31:37Z</updated>
    <id>tag:github.com,2023-05-01:/Genymobile/scrcpy</id>
    <link href="https://github.com/Genymobile/scrcpy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Display and control your Android device&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;scrcpy (v2.0)&lt;/h1&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/app/data/icon.svg?sanitize=true&#34; width=&#34;128&#34; height=&#34;128&#34; alt=&#34;scrcpy&#34; align=&#34;right&#34;&gt; &#xA;&lt;p&gt;&lt;em&gt;pronounced &#34;&lt;strong&gt;scr&lt;/strong&gt;een &lt;strong&gt;c&lt;/strong&gt;o&lt;strong&gt;py&lt;/strong&gt;&#34;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;This application mirrors Android devices (video and audio) connected via USB or &lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/device.md#tcpip-wireless&#34;&gt;over TCP/IP&lt;/a&gt;, and allows to control the device with the keyboard and the mouse of the computer. It does not require any &lt;em&gt;root&lt;/em&gt; access. It works on &lt;em&gt;Linux&lt;/em&gt;, &lt;em&gt;Windows&lt;/em&gt; and &lt;em&gt;macOS&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/assets/screenshot-debian-600.jpg&#34; alt=&#34;screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;It focuses on:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;lightness&lt;/strong&gt;: native, displays only the device screen&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;performance&lt;/strong&gt;: 30~120fps, depending on the device&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;quality&lt;/strong&gt;: 1920√ó1080 or above&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;low latency&lt;/strong&gt;: &lt;a href=&#34;https://github.com/Genymobile/scrcpy/pull/646&#34;&gt;35~70ms&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;low startup time&lt;/strong&gt;: ~1 second to display the first image&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;non-intrusiveness&lt;/strong&gt;: nothing is left installed on the Android device&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;user benefits&lt;/strong&gt;: no account, no ads, no internet required&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;freedom&lt;/strong&gt;: free and open source software&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Its features include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/audio.md&#34;&gt;audio forwarding&lt;/a&gt; (Android &amp;gt;= 11)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/recording.md&#34;&gt;recording&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;mirroring with &lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/device.md#turn-screen-off&#34;&gt;Android device screen off&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/control.md#copy-paste&#34;&gt;copy-paste&lt;/a&gt; in both directions&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/video.md&#34;&gt;configurable quality&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Android device screen &lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/v4l2.md&#34;&gt;as a webcam (V4L2)&lt;/a&gt; (Linux-only)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/hid-otg.md&#34;&gt;physical keyboard/mouse simulation (HID)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/hid-otg.md#otg&#34;&gt;OTG mode&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;and more‚Ä¶&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;The Android device requires at least API 21 (Android 5.0).&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/audio.md&#34;&gt;Audio forwarding&lt;/a&gt; is supported for API &amp;gt;= 30 (Android 11+).&lt;/p&gt; &#xA;&lt;p&gt;Make sure you &lt;a href=&#34;https://developer.android.com/studio/debug/dev-options#enable&#34;&gt;enabled USB debugging&lt;/a&gt; on your device(s).&lt;/p&gt; &#xA;&lt;p&gt;On some devices, you also need to enable &lt;a href=&#34;https://github.com/Genymobile/scrcpy/issues/70#issuecomment-373286323&#34;&gt;an additional option&lt;/a&gt; &lt;code&gt;USB debugging (Security Settings)&lt;/code&gt; (this is an item different from &lt;code&gt;USB debugging&lt;/code&gt;) to control it using a keyboard and mouse. Rebooting the device is necessary once this option is set.&lt;/p&gt; &#xA;&lt;p&gt;Note that USB debugging is not required to run scrcpy in &lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/hid-otg.md#otg&#34;&gt;OTG mode&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Get the app&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/linux.md&#34;&gt;Linux&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/windows.md&#34;&gt;Windows&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/macos.md&#34;&gt;macOS&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;User documentation&lt;/h2&gt; &#xA;&lt;p&gt;The application provides a lot of features and configuration options. They are documented in the following pages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/device.md&#34;&gt;Device&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/video.md&#34;&gt;Video&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/audio.md&#34;&gt;Audio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/control.md&#34;&gt;Control&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/window.md&#34;&gt;Window&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/recording.md&#34;&gt;Recording&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/tunnels.md&#34;&gt;Tunnels&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/hid-otg.md&#34;&gt;HID/OTG&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/v4l2.md&#34;&gt;Video4Linux&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/shortcuts.md&#34;&gt;Shortcuts&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/FAQ.md&#34;&gt;FAQ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Genymobile/scrcpy/wiki&#34;&gt;Translations&lt;/a&gt; (not necessarily up to date)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/build.md&#34;&gt;Build instructions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/doc/develop.md&#34;&gt;Developers&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Articles&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.rom1v.com/2018/03/introducing-scrcpy/&#34;&gt;Introducing scrcpy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.genymotion.com/blog/open-source-project-scrcpy-now-works-wirelessly/&#34;&gt;Scrcpy now works wirelessly&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.rom1v.com/2023/03/scrcpy-2-0-with-audio/&#34;&gt;Scrcpy 2.0, with audio&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;If you encounter a bug, please read the &lt;a href=&#34;https://raw.githubusercontent.com/Genymobile/scrcpy/master/FAQ.md&#34;&gt;FAQ&lt;/a&gt; first, then open an &lt;a href=&#34;https://github.com/Genymobile/scrcpy/issues&#34;&gt;issue&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For general questions or discussions, you can also use:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Reddit: &lt;a href=&#34;https://www.reddit.com/r/scrcpy&#34;&gt;&lt;code&gt;r/scrcpy&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Twitter: &lt;a href=&#34;https://twitter.com/scrcpy_app&#34;&gt;&lt;code&gt;@scrcpy_app&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Donate&lt;/h2&gt; &#xA;&lt;p&gt;I&#39;m &lt;a href=&#34;https://github.com/rom1v&#34;&gt;@rom1v&lt;/a&gt;, the author and maintainer of &lt;em&gt;scrcpy&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you appreciate this application, you can &lt;a href=&#34;https://blog.rom1v.com/about/#support-my-open-source-work&#34;&gt;support my open source work&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Licence&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;Copyright (C) 2018 Genymobile&#xA;Copyright (C) 2018-2023 Romain Vimont&#xA;&#xA;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);&#xA;you may not use this file except in compliance with the License.&#xA;You may obtain a copy of the License at&#xA;&#xA;    http://www.apache.org/licenses/LICENSE-2.0&#xA;&#xA;Unless required by applicable law or agreed to in writing, software&#xA;distributed under the License is distributed on an &#34;AS IS&#34; BASIS,&#xA;WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&#xA;See the License for the specific language governing permissions and&#xA;limitations under the License.&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>