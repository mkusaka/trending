<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-31T01:32:08Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>iperov/DeepFaceLab</title>
    <updated>2022-08-31T01:32:08Z</updated>
    <id>tag:github.com,2022-08-31:/iperov/DeepFaceLab</id>
    <link href="https://github.com/iperov/DeepFaceLab" rel="alternate"></link>
    <summary type="html">&lt;p&gt;DeepFaceLab is the leading software for creating deepfakes.&lt;/p&gt;&lt;hr&gt;&lt;table align=&#34;center&#34; border=&#34;0&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h1&gt;DeepFaceLab&lt;/h1&gt; &lt;a href=&#34;https://arxiv.org/abs/2005.05535&#34;&gt; &lt;/a&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.05535&#34;&gt;&lt;img src=&#34;https://static.arxiv.org/static/browse/0.3.0/images/icons/favicon.ico&#34; width=&#34;14&#34;&gt; &lt;/a&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.05535&#34;&gt;https://arxiv.org/abs/2005.05535&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;the leading software for creating deepfakes&lt;/h3&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/DFL_welcome.png&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/logo_tensorflow.png&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/logo_cuda.png&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/logo_directx.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &lt;p&gt;&lt;/p&gt; &lt;p&gt;More than 95% of deepfake videos are created with DeepFaceLab.&lt;/p&gt; &lt;p&gt;DeepFaceLab is used by such popular youtube channels as&lt;/p&gt; &#xA;    &lt;table&gt; &#xA;     &lt;thead&gt; &#xA;      &lt;tr&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/tiktok_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.tiktok.com/@deeptomcruise&#34;&gt;deeptomcruise&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/tiktok_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.tiktok.com/@1facerussia&#34;&gt;1facerussia&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/tiktok_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.tiktok.com/@arnoldschwarzneggar&#34;&gt;arnoldschwarzneggar&lt;/a&gt;&lt;/th&gt; &#xA;      &lt;/tr&gt; &#xA;     &lt;/thead&gt; &#xA;    &lt;/table&gt; &#xA;    &lt;table&gt; &#xA;     &lt;thead&gt; &#xA;      &lt;tr&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/tiktok_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.tiktok.com/@mariahcareyathome?&#34;&gt;mariahcareyathome?&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/tiktok_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.tiktok.com/@diepnep&#34;&gt;diepnep&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/tiktok_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.tiktok.com/@mr__heisenberg&#34;&gt;mr__heisenberg&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/tiktok_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.tiktok.com/@deepcaprio&#34;&gt;deepcaprio&lt;/a&gt;&lt;/th&gt; &#xA;      &lt;/tr&gt; &#xA;     &lt;/thead&gt; &#xA;    &lt;/table&gt; &#xA;    &lt;table&gt; &#xA;     &lt;thead&gt; &#xA;      &lt;tr&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCGf4OlX_aTt8DlrgiH3jN3g/videos&#34;&gt;VFXChris Ume&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCZXbWcv7fSZFTAZV4beckyw/videos&#34;&gt;Sham00k&lt;/a&gt;&lt;/th&gt; &#xA;      &lt;/tr&gt; &#xA;     &lt;/thead&gt; &#xA;    &lt;/table&gt; &#xA;    &lt;table&gt; &#xA;     &lt;thead&gt; &#xA;      &lt;tr&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=A91P2qtPT54&amp;amp;list=PLayt6616lBclvOprvrC8qKGCO-mAhPRux&#34;&gt;Collider videos&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCC0lK2Zo2BMXX-k1Ks0r7dg/videos&#34;&gt;iFake&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCFh3gL0a8BS21g-DHvXZEeQ/videos&#34;&gt;NextFace&lt;/a&gt;&lt;/th&gt; &#xA;      &lt;/tr&gt; &#xA;     &lt;/thead&gt; &#xA;    &lt;/table&gt; &#xA;    &lt;table&gt; &#xA;     &lt;thead&gt; &#xA;      &lt;tr&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCC5BbFxqLQgfnWPhprmQLVg&#34;&gt;Futuring Machine&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCRzgK52MmetD9aG8pDOID3g&#34;&gt;RepresentUS&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/c/corridorcrew/videos&#34;&gt;Corridor Crew&lt;/a&gt;&lt;/th&gt; &#xA;      &lt;/tr&gt; &#xA;     &lt;/thead&gt; &#xA;    &lt;/table&gt; &#xA;    &lt;table&gt; &#xA;     &lt;thead&gt; &#xA;      &lt;tr&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCkHecfDTcSazNZSKPEhtPVQ&#34;&gt;DeepFaker&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/c/DeepFakesinmovie/videos&#34;&gt;DeepFakes in movie&lt;/a&gt;&lt;/th&gt; &#xA;      &lt;/tr&gt; &#xA;     &lt;/thead&gt; &#xA;    &lt;/table&gt; &#xA;    &lt;table&gt; &#xA;     &lt;thead&gt; &#xA;      &lt;tr&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/channel/UCkNFhcYNLQ5hr6A6lZ56mKA&#34;&gt;DeepFakeCreator&lt;/a&gt;&lt;/th&gt; &#xA;       &lt;th&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/user/Jarkancio/videos&#34;&gt;Jarkan&lt;/a&gt;&lt;/th&gt; &#xA;      &lt;/tr&gt; &#xA;     &lt;/thead&gt; &#xA;    &lt;/table&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h1&gt;What can I do using DeepFaceLab?&lt;/h1&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Replace the face&lt;/h2&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/replace_the_face.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;De-age the face&lt;/h2&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/deage_0_1.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/deage_0_2.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=Ddx5B-84ebo&#34;&gt;https://www.youtube.com/watch?v=Ddx5B-84ebo&lt;/a&gt;&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Replace the head&lt;/h2&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/head_replace_0_1.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/head_replace_0_2.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=xr5FHd0AdlQ&#34;&gt;https://www.youtube.com/watch?v=xr5FHd0AdlQ&lt;/a&gt;&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/head_replace_1_1.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/head_replace_1_2.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=RTjgkhMugVw&#34;&gt;https://www.youtube.com/watch?v=RTjgkhMugVw&lt;/a&gt;&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/head_replace_2_1.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/head_replace_2_2.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=R9f7WD0gKPo&#34;&gt;https://www.youtube.com/watch?v=R9f7WD0gKPo&lt;/a&gt;&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Manipulate politicians lips&lt;/h2&gt; &lt;p&gt;(voice replacement is not included!) (also requires a skill in video editors such as &lt;em&gt;Adobe After Effects&lt;/em&gt; or &lt;em&gt;Davinci Resolve&lt;/em&gt;)&lt;/p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/political_speech2.jpg&#34; align=&#34;center&#34;&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=IvY-Abd2FfM&#34;&gt;https://www.youtube.com/watch?v=IvY-Abd2FfM&lt;/a&gt;&lt;/p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/political_speech3.jpg&#34; align=&#34;center&#34;&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/youtube_icon.png&#34; alt=&#34;&#34;&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=ERQlaJ_czHU&#34;&gt;https://www.youtube.com/watch?v=ERQlaJ_czHU&lt;/a&gt;&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h1&gt;Deepfake native resolution progress&lt;/h1&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/deepfake_progress.png&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/make_everything_ok.png&#34; align=&#34;center&#34;&gt; &lt;p&gt;Unfortunately, there is no &#34;make everything ok&#34; button in DeepFaceLab. You should spend time studying the workflow and growing your skills. A skill in programs such as &lt;em&gt;AfterEffects&lt;/em&gt; or &lt;em&gt;Davinci Resolve&lt;/em&gt; is also desirable.&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Mini tutorial&lt;/h2&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=kOIMXt8KK8M&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/mini_tutorial.jpg&#34; align=&#34;center&#34;&gt; &lt;/a&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Releases&lt;/h2&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://tinyurl.com/2p9cvt25&#34;&gt;Windows (magnet link)&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Last release. Use torrent client to download.&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mega.nz/folder/Po0nGQrA#dbbttiNWojCt8jzD4xYaPw&#34;&gt;Windows (Mega.nz)&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Contains new and prev releases.&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://disk.yandex.ru/d/7i5XTKIKVg5UUg&#34;&gt;Windows (yandex.ru)&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Contains new and prev releases.&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://github.com/chervonij/DFL-Colab&#34;&gt;Google Colab (github)&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;by @chervonij . You can train fakes for free using Google Colab.&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://github.com/nagadit/DeepFaceLab_Linux&#34;&gt;Linux (github)&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;by @nagadit&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://github.com/elemantalcode/dfl&#34;&gt;CentOS Linux (github)&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;May be outdated. By @elemantalcode&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table align=&#34;center&#34; border=&#34;0&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Links&lt;/h2&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h3&gt;Guides and tutorials&lt;/h3&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide&#34;&gt;DeepFaceLab guide&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Main guide&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?pid=18459#pid18459&#34;&gt;Faceset creation guide&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;How to create the right faceset&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/thread-guide-deepfacelab-google-colab-tutorial&#34;&gt;Google Colab guide&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Guide how to train the fake on Google Colab&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/thread-deepfacelab-2-0-compositing-in-davinci-resolve-vegas-pro-and-after-effects&#34;&gt;Compositing&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;To achieve the highest quality, compose deepfake manually in video editors such as Davinci Resolve or Adobe AfterEffects&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/thread-deepfacelab-2-0-discussion-tips-suggestions&#34;&gt;Discussion and suggestions&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h3&gt;Supplementary material&lt;/h3&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/forum-celebrity-facesets&#34;&gt;Ready to work facesets&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Celebrity facesets made by community&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/forum-trained-models&#34;&gt;Pretrained models&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Pretrained models made by community&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h3&gt;Communication groups&lt;/h3&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://discord.gg/rxa7h9M6rH&#34;&gt;Discord&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Official discord channel. English / Russian.&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://t.me/joinchat/ElkhqlgJ0I5HhdJyFar80w&#34;&gt;Telegram group&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Official telegram group. English / Russian. For anonymous communication. Don&#39;t forget to hide your phone number&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/forum-russian-community&#34;&gt;–†—É—Å—Å–∫–∏–π —Ñ–æ—Ä—É–º&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://mrdeepfakes.com/forums/&#34;&gt;mrdeepfakes&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;the biggest NSFW English community&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://www.reddit.com/r/DeepFakesSFW/new/&#34;&gt;reddit r/DeepFakesSFW/&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Post your deepfakes there !&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://www.reddit.com/r/RUdeepfakes/new/&#34;&gt;reddit r/RUdeepfakes/&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;–ü–æ—Å—Ç–∏–º —Ä—É—Å—Å–∫–∏–µ –¥–∏–ø—Ñ–µ–π–∫–∏ —Å—é–¥–∞ !&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; QQÁæ§124500433 &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;‰∏≠Êñá‰∫§ÊµÅQQÁæ§ÔºåÂïÜÂä°Âêà‰ΩúÊâæÁæ§‰∏ª&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://www.dfldata.xyz&#34;&gt;dfldata.xyz&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;‰∏≠Êñá‰∫§ÊµÅËÆ∫ÂùõÔºåÂÖçË¥πËΩØ‰ª∂ÊïôÁ®ã„ÄÅÊ®°Âûã„ÄÅ‰∫∫ËÑ∏Êï∞ÊçÆ&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://www.deepfaker.xyz/&#34;&gt;deepfaker.xyz&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;‰∏≠ÊñáÂ≠¶‰π†Á´ôÔºàÈùûÂÆòÊñπ)&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Related works&lt;/h2&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://github.com/iperov/DeepFaceLive&#34;&gt;DeepFaceLive&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Real-time face swap for PC streaming or video calls&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://github.com/neuralchen/SimSwap&#34;&gt;neuralchen/SimSwap&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Swapping face using ONE single photo ‰∏ÄÂº†ÂõæÂÖçËÆ≠ÁªÉÊç¢ËÑ∏&lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;right&#34;&gt; &lt;a href=&#34;https://github.com/deepfakes/faceswap&#34;&gt;deepfakes/faceswap&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34;&gt;Something that was before DeepFaceLab and still remains in the past&lt;/td&gt;&#xA;  &lt;/tr&gt;  &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table align=&#34;center&#34; border=&#34;0&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;How I can help the project?&lt;/h2&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h3&gt;Sponsor deepfake research and DeepFaceLab development.&lt;/h3&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;!--&#xA;&lt;tr&gt;&lt;td colspan=2 align=&#34;center&#34;&gt;&#xA;&lt;a href=&#34;https://www.paypal.com/paypalme/DeepFaceLab&#34;&gt;Donate via Paypal&lt;/a&gt;&#xA;&lt;/td&gt;&lt;/tr&gt;&#xA;--&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;a href=&#34;https://money.yandex.ru/to/41001142318065&#34;&gt;Donate via Yandex.Money&lt;/a&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; bitcoin:bc1qkhh7h0gwwhxgg6h6gpllfgstkd645fefrd5s6z &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h3&gt;Collect facesets&lt;/h3&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p&gt;You can collect faceset of any celebrity that can be used in DeepFaceLab and share it &lt;a href=&#34;https://mrdeepfakes.com/forums/forum-celebrity-facesets&#34;&gt;in the community&lt;/a&gt;&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h3&gt;Star this repo&lt;/h3&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p&gt;Register github account and push &#34;Star&#34; button.&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table align=&#34;center&#34; border=&#34;0&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;h2&gt;Meme zone&lt;/h2&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/meme1.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/meme2.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/iperov/DeepFaceLab/master/doc/meme3.jpg&#34; align=&#34;center&#34;&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td align=&#34;center&#34; width=&#34;50%&#34;&gt; &lt;h2&gt;You don&#39;t need deepfake detector. You need to stop lying.&lt;/h2&gt; &lt;/td&gt;&#xA;   &lt;td align=&#34;center&#34; width=&#34;10%&#34;&gt; &lt;img src=&#34;https://i.imgur.com/z0e0xFB.jpg&#34; align=&#34;center&#34;&gt; &lt;p&gt;V.I. Lenin&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt;&#xA;   &lt;td colspan=&#34;2&#34; align=&#34;center&#34;&gt; &lt;p&gt;&lt;sub&gt;#deepfacelab #deepfakes #faceswap #face-swap #deep-learning #deeplearning #deep-neural-networks #deepface #deep-face-swap #fakeapp #fake-app #neural-networks #neural-nets #tensorflow #cuda #nvidia&lt;/sub&gt;&lt;/p&gt; &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt;</summary>
  </entry>
  <entry>
    <title>troyeguo/koodo-reader</title>
    <updated>2022-08-31T01:32:08Z</updated>
    <id>tag:github.com,2022-08-31:/troyeguo/koodo-reader</id>
    <link href="https://github.com/troyeguo/koodo-reader" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A modern ebook manager and reader with sync and backup capacities for Windows, macOS, Linux and Web&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;left&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/troyeguo/koodo-reader/raw/master/README_cn.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | English&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://i.loli.net/2021/07/30/ZKNMmz54Q3uqlrW.png&#34; width=&#34;96px&#34; height=&#34;96px&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt; Koodo Reader &lt;/h1&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt; A cross-platform ebook reader &lt;/h3&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://koodo.960960.xyz/en&#34;&gt;Download&lt;/a&gt; | &lt;a href=&#34;https://reader.960960.xyz&#34;&gt;Preview&lt;/a&gt; | &lt;a href=&#34;https://troyeguo.notion.site/d1c19a132932465bae1d89dd963c92ea?v=ca8aa69cf25849c18c92b92ba868663b&#34;&gt;Roadmap&lt;/a&gt; | &lt;a href=&#34;https://troyeguo.notion.site/Koodo-Reader-Document-9c767af3d66c459db996bdd08a34c34b&#34;&gt;Document&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Preview&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://i.loli.net/2021/08/08/I37WPYFJcC1jltn.png&#34;&gt; &#xA; &lt;img src=&#34;https://i.loli.net/2021/08/08/G7WvUQFTrEpSCKg.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Feature&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Format support: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;EPUB (&lt;strong&gt;.epub&lt;/strong&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;Scanned document (&lt;strong&gt;.pdf&lt;/strong&gt;, &lt;strong&gt;.djvu&lt;/strong&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;DRM-free Mobipocket (&lt;strong&gt;.mobi&lt;/strong&gt;) and Kindle (&lt;strong&gt;.azw3&lt;/strong&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;Plain text (&lt;strong&gt;.txt&lt;/strong&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;FictionBook (&lt;strong&gt;.fb2&lt;/strong&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;Comic book archive (&lt;strong&gt;.cbr&lt;/strong&gt;, &lt;strong&gt;.cbz&lt;/strong&gt;, &lt;strong&gt;.cbt&lt;/strong&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;Rich text (&lt;strong&gt;.md&lt;/strong&gt;, &lt;strong&gt;.docx&lt;/strong&gt;, &lt;strong&gt;.rtf&lt;/strong&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;Hyper Text (&lt;strong&gt;.html&lt;/strong&gt;, &lt;strong&gt;.xml&lt;/strong&gt;, &lt;strong&gt;.xhtml&lt;/strong&gt;, &lt;strong&gt;.htm&lt;/strong&gt;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Platform support: &lt;strong&gt;Windows&lt;/strong&gt;, &lt;strong&gt;macOS&lt;/strong&gt;, &lt;strong&gt;Linux&lt;/strong&gt; and &lt;strong&gt;Web&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Save your data to &lt;strong&gt;Dropbox&lt;/strong&gt; or &lt;strong&gt;Webdav&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Customize the source folder and synchronize among multiple devices using OneDrive, iCloud, Dropbox, etc.&lt;/li&gt; &#xA; &lt;li&gt;Single-column, two-column, or continuous scrolling layouts&lt;/li&gt; &#xA; &lt;li&gt;Text-to-speech, translation, progress slider, touch screen support, batch import&lt;/li&gt; &#xA; &lt;li&gt;Add bookmarks, notes, highlights to your books&lt;/li&gt; &#xA; &lt;li&gt;Adjust font size, font family, line-spacing, paragraph spacing, background color, text color, margins, and brightness&lt;/li&gt; &#xA; &lt;li&gt;Night mode and theme color&lt;/li&gt; &#xA; &lt;li&gt;Text highlight, underline, boldness, italics and shadow&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Desktop Version: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Stable Version (Recommended): &lt;a href=&#34;https://koodo.960960.xyz/en&#34;&gt;Download&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Developer Version: &lt;a href=&#34;https://github.com/troyeguo/koodo-reader/releases/latest&#34;&gt;Download&lt;/a&gt; ( With new feature and bug fix, but may induce some unknown bugs)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Web VersionÔºö&lt;a href=&#34;https://reader.960960.xyz&#34;&gt;Preview&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Install with Scoop:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;scoop bucket add dorado https://github.com/chawyehsu/dorado&#xA;scoop install dorado/koodo-reader&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install with Homebrew:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;brew install --cask koodo-reader&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install with Docker:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Screenshot&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;b&gt;List mode&lt;/b&gt; &#xA; &lt;img src=&#34;https://i.loli.net/2021/08/08/JyNHfThMs184Um2.png&#34;&gt; &#xA; &lt;b&gt;Cover mode&lt;/b&gt; &#xA; &lt;img src=&#34;https://i.loli.net/2021/08/08/76zkDEAobd4qsmR.png&#34;&gt; &#xA; &lt;b&gt;Reader menu&lt;/b&gt; &#xA; &lt;img src=&#34;https://i.loli.net/2021/08/08/LeEN9gnOvFmfVWA.png&#34;&gt; &#xA; &lt;b&gt;Backup and restore&lt;/b&gt; &#xA; &lt;img src=&#34;https://i.loli.net/2021/08/08/aRIAiYT2dGJQhC1.png&#34;&gt; &#xA; &lt;b&gt;Dark mode and theme color&lt;/b&gt; &#xA; &lt;img src=&#34;https://i.loli.net/2021/08/08/ynqUNpX93xZefdw.png&#34;&gt; &#xA; &lt;b&gt;Note management&lt;/b&gt; &#xA; &lt;img src=&#34;https://i.loli.net/2021/08/09/sARQBoefvGklHwC.png&#34;&gt; &#xA;&lt;/div&gt;  &#xA;&lt;h2&gt;Develop&lt;/h2&gt; &#xA;&lt;p&gt;Make sure that you have installed yarn and git, node&#39;s version on your computer is larger than 14.0.0.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Download the repo&lt;/p&gt; &lt;pre&gt;&lt;code&gt;git clone https://github.com/troyeguo/koodo-reader.git&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Enter desktop mode&lt;/p&gt; &lt;pre&gt;&lt;code&gt;yarn&#xA;yarn dev&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Enter web mode&lt;/p&gt; &lt;pre&gt;&lt;code&gt;yarn&#xA;yarn start&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Translation&lt;/h2&gt; &#xA;&lt;p&gt;Koodo Reader use POEditor to manage localization, Visit &lt;a href=&#34;https://poeditor.com/join/project?hash=fk4qbQTlsk&#34;&gt;here&lt;/a&gt; to edit current translation or add new language&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>hlky/stable-diffusion-webui</title>
    <updated>2022-08-31T01:32:08Z</updated>
    <id>tag:github.com,2022-08-31:/hlky/stable-diffusion-webui</id>
    <link href="https://github.com/hlky/stable-diffusion-webui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Stable Diffusion web UI&lt;/p&gt;&lt;hr&gt;&lt;h3&gt;&lt;a href=&#34;https://github.com/hlky/stable-diffusion&#34;&gt;MAIN REPO&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h2&gt;This repo is for development, there may be bugs and new features&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;span&gt;‚ö†&lt;/span&gt; 2022/08/30 - #297 #307 #308 are major changes. Make sure you &lt;strong&gt;pull from main repo&lt;/strong&gt; &lt;span&gt;‚ö†&lt;/span&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;Questions about &lt;strong&gt;&lt;em&gt;&lt;a href=&#34;https://github.com/hlky/stable-diffusion-webui/wiki/Upscalers&#34;&gt;Upscalers&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;?&lt;/h3&gt; &#xA;&lt;h3&gt;Questions about &lt;strong&gt;&lt;em&gt;&lt;a href=&#34;https://github.com/hlky/stable-diffusion-webui/wiki/Optimized-mode&#34;&gt;Optimized mode&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;?&lt;/h3&gt; &#xA;&lt;h3&gt;Feature request? Use &lt;a href=&#34;https://github.com/hlky/stable-diffusion-webui/discussions&#34;&gt;discussions&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/altryne/sd-webui-colab/blob/main/Stable_Diffusion_WebUi_Altryne.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;More documentation about features, troubleshooting, common issues very soon&lt;/h2&gt; &#xA;&lt;h3&gt;Want to help with documentation? Documented something? Use &lt;a href=&#34;https://github.com/hlky/stable-diffusion-webui/discussions&#34;&gt;Discussions&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Gradio GUI: Idiot-proof, fully featured frontend for both txt2img and img2img generation&lt;/li&gt; &#xA; &lt;li&gt;No more manually typing parameters, now all you have to do is write your prompt and adjust sliders&lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;üî•&lt;/span&gt; &lt;span&gt;üî•&lt;/span&gt; Optimized support!! &lt;span&gt;üî•&lt;/span&gt; &lt;span&gt;üî•&lt;/span&gt;&lt;/li&gt; &#xA; &lt;li&gt;üî• NEW! &lt;a href=&#34;https://github.com/hlky/stable-diffusion&#34;&gt;webui.cmd&lt;/a&gt; updates with any changes in environment.yaml file so the environment will always be up to date as long as you get the new environment.yaml file üî• &lt;span&gt;üî•&lt;/span&gt; no need to remove environment, delete src folder and create again, MUCH simpler! üî•&lt;/li&gt; &#xA; &lt;li&gt;GFPGAN Face Correction üî•: &lt;a href=&#34;https://github.com/hlky/stable-diffusion-webui#gfpgan&#34;&gt;Download the model&lt;/a&gt;Automatically correct distorted faces with a built-in GFPGAN option, fixes them in less than half a second&lt;/li&gt; &#xA; &lt;li&gt;RealESRGAN Upscaling üî•: &lt;a href=&#34;https://github.com/hlky/stable-diffusion-webui#realesrgan&#34;&gt;Download the models&lt;/a&gt; Boosts the resolution of images with a built-in RealESRGAN option&lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;üíª&lt;/span&gt; esrgan/gfpgan on cpu support &lt;span&gt;üíª&lt;/span&gt;&lt;/li&gt; &#xA; &lt;li&gt;Textual inversion üî•: &lt;a href=&#34;https://textual-inversion.github.io/&#34;&gt;info&lt;/a&gt; - requires enabling, see &lt;a href=&#34;https://github.com/hlky/sd-enable-textual-inversion&#34;&gt;here&lt;/a&gt;, script works as usual without it enabled&lt;/li&gt; &#xA; &lt;li&gt;Advanced img2img editor &lt;span&gt;üé®&lt;/span&gt; &lt;span&gt;üî•&lt;/span&gt; &lt;span&gt;üé®&lt;/span&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;üî•&lt;/span&gt;&lt;span&gt;üî•&lt;/span&gt; Mask and crop &lt;span&gt;üî•&lt;/span&gt;&lt;span&gt;üî•&lt;/span&gt;&lt;/li&gt; &#xA; &lt;li&gt;Mask painting (NEW) üñåÔ∏è: Powerful tool for re-generating only specific parts of an image you want to change&lt;/li&gt; &#xA; &lt;li&gt;More k_diffusion samplers üî•üî• : Far greater quality outputs than the default sampler, less distortion and more accurate&lt;/li&gt; &#xA; &lt;li&gt;txt2img samplers: &#34;DDIM&#34;, &#34;PLMS&#34;, &#39;k_dpm_2_a&#39;, &#39;k_dpm_2&#39;, &#39;k_euler_a&#39;, &#39;k_euler&#39;, &#39;k_heun&#39;, &#39;k_lms&#39;&lt;/li&gt; &#xA; &lt;li&gt;img2img samplers: &#34;DDIM&#34;, &#39;k_dpm_2_a&#39;, &#39;k_dpm_2&#39;, &#39;k_euler_a&#39;, &#39;k_euler&#39;, &#39;k_heun&#39;, &#39;k_lms&#39;&lt;/li&gt; &#xA; &lt;li&gt;Loopback (NEW) ‚ûø: Automatically feed the last generated sample back into img2img&lt;/li&gt; &#xA; &lt;li&gt;Prompt Weighting (NEW) üèãÔ∏è: Adjust the strength of different terms in your prompt&lt;/li&gt; &#xA; &lt;li&gt;&lt;span&gt;üî•&lt;/span&gt; gpu device selectable with --gpu &#xA;  &lt;id&gt; &#xA;   &lt;span&gt;üî•&lt;/span&gt;&#xA;  &lt;/id&gt;&lt;/li&gt; &#xA; &lt;li&gt;Memory Monitoring üî•: Shows Vram usage and generation time after outputting.&lt;/li&gt; &#xA; &lt;li&gt;Word Seeds üî•: Use words instead of seed numbers&lt;/li&gt; &#xA; &lt;li&gt;CFG: Classifier free guidance scale, a feature for fine-tuning your output&lt;/li&gt; &#xA; &lt;li&gt;Launcher Automatic üëëüî• shortcut to load the model, no more typing in Conda&lt;/li&gt; &#xA; &lt;li&gt;Lighter on Vram: 512x512 img2img &amp;amp; txt2img tested working on 6gb&lt;/li&gt; &#xA; &lt;li&gt;and ????&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Stable Diffusion web UI&lt;/h1&gt; &#xA;&lt;p&gt;A browser interface based on Gradio library for Stable Diffusion.&lt;/p&gt; &#xA;&lt;p&gt;Original script with Gradio UI was written by a kind anonymopus user. This is a modification.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hlky/stable-diffusion-webui/master/images/txt2img.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hlky/stable-diffusion-webui/master/images/img2img.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hlky/stable-diffusion-webui/master/images/gfpgan.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hlky/stable-diffusion-webui/master/images/esrgan.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;GFPGAN&lt;/h3&gt; &#xA;&lt;p&gt;If you want to use GFPGAN to improve generated faces, you need to install it separately. Download &lt;a href=&#34;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth&#34;&gt;GFPGANv1.3.pth&lt;/a&gt; and put it into the &lt;code&gt;/stable-diffusion/src/gfpgan/experiments/pretrained_models&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;h3&gt;RealESRGAN&lt;/h3&gt; &#xA;&lt;p&gt;Download &lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth&#34;&gt;RealESRGAN_x4plus.pth&lt;/a&gt; and &lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth&#34;&gt;RealESRGAN_x4plus_anime_6B.pth&lt;/a&gt;. Put them into the &lt;code&gt;stable-diffusion/src/realesrgan/experiments/pretrained_models&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;h3&gt;Web UI&lt;/h3&gt; &#xA;&lt;p&gt;When launching, you may get a very long warning message related to some weights not being used. You may freely ignore it. After a while, you will get a message like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Running on local URL:  http://127.0.0.1:7860/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open the URL in browser, and you are good to go.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;The script creates a web UI for Stable Diffusion&#39;s txt2img and img2img scripts. Following are features added that are not in original script.&lt;/p&gt; &#xA;&lt;h3&gt;GFPGAN&lt;/h3&gt; &#xA;&lt;p&gt;Lets you improve faces in pictures using the GFPGAN model. There is a checkbox in every tab to use GFPGAN at 100%, and also a separate tab that just allows you to use GFPGAN on any picture, with a slider that controls how strongthe effect is.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hlky/stable-diffusion-webui/master/images/GFPGAN.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;RealESRGAN&lt;/h3&gt; &#xA;&lt;p&gt;Lets you double the resolution of generated images. There is a checkbox in every tab to use RealESRGAN, and you can choose between the regular upscaler and the anime version. There is also a separate tab for using RealESRGAN on any picture.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hlky/stable-diffusion-webui/master/images/RealESRGAN.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Sampling method selection&lt;/h3&gt; &#xA;&lt;p&gt;txt2img samplers: &#34;DDIM&#34;, &#34;PLMS&#34;, &#39;k_dpm_2_a&#39;, &#39;k_dpm_2&#39;, &#39;k_euler_a&#39;, &#39;k_euler&#39;, &#39;k_heun&#39;, &#39;k_lms&#39; img2img samplers: &#34;DDIM&#34;, &#39;k_dpm_2_a&#39;, &#39;k_dpm_2&#39;, &#39;k_euler_a&#39;, &#39;k_euler&#39;, &#39;k_heun&#39;, &#39;k_lms&#39;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hlky/stable-diffusion-webui/master/images/sampling.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Prompt matrix&lt;/h3&gt; &#xA;&lt;p&gt;Separate multiple prompts using the &lt;code&gt;|&lt;/code&gt; character, and the system will produce an image for every combination of them. For example, if you use &lt;code&gt;a busy city street in a modern city|illustration|cinematic lighting&lt;/code&gt; prompt, there are four combinations possible (first part of prompt is always kept):&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;a busy city street in a modern city&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;a busy city street in a modern city, illustration&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;a busy city street in a modern city, cinematic lighting&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;a busy city street in a modern city, illustration, cinematic lighting&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Four images will be produced, in this order, all with same seed and each with corresponding prompt: &lt;img src=&#34;https://raw.githubusercontent.com/hlky/stable-diffusion-webui/master/images/prompt-matrix.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Another example, this time with 5 prompts and 16 variations: &lt;img src=&#34;https://raw.githubusercontent.com/hlky/stable-diffusion-webui/master/images/prompt_matrix.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Prompt combinations&lt;/h3&gt; &#xA;&lt;p&gt;If you add &#39;@&#39; symbol at start your prompt and change text like this: &lt;code&gt;@(moba|rpg|rts) character (2d|3d) model&lt;/code&gt; it will be produce 3 * 2 combinations or prompt with same seed:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;moba character 2d model&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;rpg character 2d model&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;rts character 2d model&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;moba character 3d model&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;rpg character 3d model&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;rts character 3d model&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you use this feature, batch count will be ignored, because the number of pictures to produce depends on your prompts, but batch size will still work (generating multiple pictures at the same time for a small speed boost).&lt;/p&gt; &#xA;&lt;h3&gt;Flagging (Broken after UI changed to gradio.Blocks() see &lt;a href=&#34;https://github.com/hlky/stable-diffusion-webui/issues/50&#34;&gt;Flag button missing from new UI&lt;/a&gt;)&lt;/h3&gt; &#xA;&lt;p&gt;Click the Flag button under the output section, and generated images will be saved to &lt;code&gt;log/images&lt;/code&gt; directory, and generation parameters will be appended to a csv file &lt;code&gt;log/log.csv&lt;/code&gt; in the &lt;code&gt;/sd&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;but every image is saved, why would I need this?&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;If you&#39;re like me, you experiment a lot with prompts and settings, and only few images are worth saving. You can just save them using right click in browser, but then you won&#39;t be able to reproduce them later because you will not know what exact prompt created the image. If you use the flag button, generation paramerters will be written to csv file, and you can easily find parameters for an image by searching for its filename.&lt;/p&gt; &#xA;&lt;h3&gt;Copy-paste generation parameters&lt;/h3&gt; &#xA;&lt;p&gt;A text output provides generation parameters in an easy to copy-paste form for easy sharing.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hlky/stable-diffusion-webui/master/images/kopipe.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you generate multiple pictures, the displayed seed will be the seed of the first one.&lt;/p&gt; &#xA;&lt;h3&gt;Correct seeds for batches&lt;/h3&gt; &#xA;&lt;p&gt;If you use a seed of 1000 to generate two batches of two images each, four generated images will have seeds: &lt;code&gt;1000, 1001, 1002, 1003&lt;/code&gt;. Previous versions of the UI would produce &lt;code&gt;1000, x, 1001, x&lt;/code&gt;, where x is an iamge that can&#39;t be generated by any seed.&lt;/p&gt; &#xA;&lt;h3&gt;Resizing&lt;/h3&gt; &#xA;&lt;p&gt;There are three options for resizing input images in img2img mode:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Just resize - simply resizes source image to target resolution, resulting in incorrect aspect ratio&lt;/li&gt; &#xA; &lt;li&gt;Crop and resize - resize source image preserving aspect ratio so that entirety of target resolution is occupied by it, and crop parts that stick out&lt;/li&gt; &#xA; &lt;li&gt;Resize and fill - resize source image preserving aspect ratio so that it entirely fits target resolution, and fill empty space by rows/columns from source image&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Example: &lt;img src=&#34;https://raw.githubusercontent.com/hlky/stable-diffusion-webui/master/images/resizing.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Loading&lt;/h3&gt; &#xA;&lt;p&gt;Gradio&#39;s loading graphic has a very negative effect on the processing speed of the neural network. My RTX 3090 makes images about 10% faster when the tab with gradio is not active. By default, the UI now hides loading progress animation and replaces it with static &#34;Loading...&#34; text, which achieves the same effect. Use the --no-progressbar-hiding commandline option to revert this and show loading animations.&lt;/p&gt; &#xA;&lt;h3&gt;Prompt validation&lt;/h3&gt; &#xA;&lt;p&gt;Stable Diffusion has a limit for input text length. If your prompt is too long, you will get a warning in the text output field, showing which parts of your text were truncated and ignored by the model.&lt;/p&gt; &#xA;&lt;h3&gt;Loopback&lt;/h3&gt; &#xA;&lt;p&gt;A checkbox for img2img allowing to automatically feed output image as input for the next batch. Equivalent to saving output image, and replacing input image with it. Batch count setting controls how many iterations of this you get.&lt;/p&gt; &#xA;&lt;p&gt;Usually, when doing this, you would choose one of many images for the next iteration yourself, so the usefulness of this feature may be questionable, but I&#39;ve managed to get some very nice outputs with it that I wasn&#39;t abble to get otherwise.&lt;/p&gt; &#xA;&lt;p&gt;Example: (cherrypicked result; original picture by anon)&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hlky/stable-diffusion-webui/master/images/loopback.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>