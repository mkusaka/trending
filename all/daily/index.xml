<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-07-31T01:20:40Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>freqtrade/freqtrade</title>
    <updated>2024-07-31T01:20:40Z</updated>
    <id>tag:github.com,2024-07-31:/freqtrade/freqtrade</id>
    <link href="https://github.com/freqtrade/freqtrade" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Free, open source crypto trading bot&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade_poweredby.svg?sanitize=true&#34; alt=&#34;freqtrade&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/freqtrade/freqtrade/actions/&#34;&gt;&lt;img src=&#34;https://github.com/freqtrade/freqtrade/workflows/Freqtrade%20CI/badge.svg?sanitize=true&#34; alt=&#34;Freqtrade CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.21105/joss.04864&#34;&gt;&lt;img src=&#34;https://joss.theoj.org/papers/10.21105/joss.04864/status.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://coveralls.io/github/freqtrade/freqtrade?branch=develop&#34;&gt;&lt;img src=&#34;https://coveralls.io/repos/github/freqtrade/freqtrade/badge.svg?branch=develop&amp;amp;service=github&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.freqtrade.io&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/freqtrade/badge/&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codeclimate.com/github/freqtrade/freqtrade/maintainability&#34;&gt;&lt;img src=&#34;https://api.codeclimate.com/v1/badges/5737e6d668200b7518ff/maintainability&#34; alt=&#34;Maintainability&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Freqtrade is a free and open source crypto trading bot written in Python. It is designed to support all major exchanges and be controlled via Telegram or webUI. It contains backtesting, plotting and money management tools as well as strategy optimization by machine learning.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade-screenshot.png&#34; alt=&#34;freqtrade&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This software is for educational purposes only. Do not risk money which you are afraid to lose. USE THE SOFTWARE AT YOUR OWN RISK. THE AUTHORS AND ALL AFFILIATES ASSUME NO RESPONSIBILITY FOR YOUR TRADING RESULTS.&lt;/p&gt; &#xA;&lt;p&gt;Always start by running a trading bot in Dry-run and do not engage money before you understand how it works and what profit/loss you should expect.&lt;/p&gt; &#xA;&lt;p&gt;We strongly recommend you to have coding and Python knowledge. Do not hesitate to read the source code and understand the mechanism of this bot.&lt;/p&gt; &#xA;&lt;h2&gt;Supported Exchange marketplaces&lt;/h2&gt; &#xA;&lt;p&gt;Please read the &lt;a href=&#34;https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/exchanges.md&#34;&gt;exchange specific notes&lt;/a&gt; to learn about eventual, special configurations needed for each exchange.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.binance.com/&#34;&gt;Binance&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://bitmart.com/&#34;&gt;Bitmart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://bingx.com/invite/0EM9RX&#34;&gt;BingX&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.gate.io/ref/6266643&#34;&gt;Gate.io&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.htx.com/&#34;&gt;HTX&lt;/a&gt; (Former Huobi)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://kraken.com/&#34;&gt;Kraken&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://okx.com/&#34;&gt;OKX&lt;/a&gt; (Former OKEX)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/ccxt/ccxt/&#34;&gt;potentially many others&lt;/a&gt;. &lt;em&gt;(We cannot guarantee they will work)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Supported Futures Exchanges (experimental)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.binance.com/&#34;&gt;Binance&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.gate.io/ref/6266643&#34;&gt;Gate.io&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://okx.com/&#34;&gt;OKX&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://bybit.com/&#34;&gt;Bybit&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please make sure to read the &lt;a href=&#34;https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/exchanges.md&#34;&gt;exchange specific notes&lt;/a&gt;, as well as the &lt;a href=&#34;https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/leverage.md&#34;&gt;trading with leverage&lt;/a&gt; documentation before diving in.&lt;/p&gt; &#xA;&lt;h3&gt;Community tested&lt;/h3&gt; &#xA;&lt;p&gt;Exchanges confirmed working by the community:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://bitvavo.com/&#34;&gt;Bitvavo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://www.kucoin.com/&#34;&gt;Kucoin&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;We invite you to read the bot documentation to ensure you understand how the bot is working.&lt;/p&gt; &#xA;&lt;p&gt;Please find the complete documentation on the &lt;a href=&#34;https://www.freqtrade.io&#34;&gt;freqtrade website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Based on Python 3.9+&lt;/strong&gt;: For botting on any operating system - Windows, macOS and Linux.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Persistence&lt;/strong&gt;: Persistence is achieved through sqlite.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Dry-run&lt;/strong&gt;: Run the bot without paying money.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Backtesting&lt;/strong&gt;: Run a simulation of your buy/sell strategy.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Strategy Optimization by machine learning&lt;/strong&gt;: Use machine learning to optimize your buy/sell strategy parameters with real exchange data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Adaptive prediction modeling&lt;/strong&gt;: Build a smart strategy with FreqAI that self-trains to the market via adaptive machine learning methods. &lt;a href=&#34;https://www.freqtrade.io/en/stable/freqai/&#34;&gt;Learn more&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Edge position sizing&lt;/strong&gt; Calculate your win rate, risk reward ratio, the best stoploss and adjust your position size before taking a position for each specific market. &lt;a href=&#34;https://www.freqtrade.io/en/stable/edge/&#34;&gt;Learn more&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Whitelist crypto-currencies&lt;/strong&gt;: Select which crypto-currency you want to trade or use dynamic whitelists.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Blacklist crypto-currencies&lt;/strong&gt;: Select which crypto-currency you want to avoid.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Builtin WebUI&lt;/strong&gt;: Builtin web UI to manage your bot.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Manageable via Telegram&lt;/strong&gt;: Manage the bot with Telegram.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Display profit/loss in fiat&lt;/strong&gt;: Display your profit/loss in fiat currency.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Performance status report&lt;/strong&gt;: Provide a performance status of your current trades.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quick start&lt;/h2&gt; &#xA;&lt;p&gt;Please refer to the &lt;a href=&#34;https://www.freqtrade.io/en/stable/docker_quickstart/&#34;&gt;Docker Quickstart documentation&lt;/a&gt; on how to get started quickly.&lt;/p&gt; &#xA;&lt;p&gt;For further (native) installation methods, please refer to the &lt;a href=&#34;https://www.freqtrade.io/en/stable/installation/&#34;&gt;Installation documentation page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Basic Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Bot commands&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;usage: freqtrade [-h] [-V]&#xA;                 {trade,create-userdir,new-config,new-strategy,download-data,convert-data,convert-trade-data,list-data,backtesting,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-hyperopts,list-markets,list-pairs,list-strategies,list-timeframes,show-trades,test-pairlist,install-ui,plot-dataframe,plot-profit,webserver}&#xA;                 ...&#xA;&#xA;Free, open source crypto trading bot&#xA;&#xA;positional arguments:&#xA;  {trade,create-userdir,new-config,new-strategy,download-data,convert-data,convert-trade-data,list-data,backtesting,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-hyperopts,list-markets,list-pairs,list-strategies,list-timeframes,show-trades,test-pairlist,install-ui,plot-dataframe,plot-profit,webserver}&#xA;    trade               Trade module.&#xA;    create-userdir      Create user-data directory.&#xA;    new-config          Create new config&#xA;    new-strategy        Create new strategy&#xA;    download-data       Download backtesting data.&#xA;    convert-data        Convert candle (OHLCV) data from one format to&#xA;                        another.&#xA;    convert-trade-data  Convert trade data from one format to another.&#xA;    list-data           List downloaded data.&#xA;    backtesting         Backtesting module.&#xA;    edge                Edge module.&#xA;    hyperopt            Hyperopt module.&#xA;    hyperopt-list       List Hyperopt results&#xA;    hyperopt-show       Show details of Hyperopt results&#xA;    list-exchanges      Print available exchanges.&#xA;    list-hyperopts      Print available hyperopt classes.&#xA;    list-markets        Print markets on exchange.&#xA;    list-pairs          Print pairs on exchange.&#xA;    list-strategies     Print available strategies.&#xA;    list-timeframes     Print available timeframes for the exchange.&#xA;    show-trades         Show trades.&#xA;    test-pairlist       Test your pairlist configuration.&#xA;    install-ui          Install FreqUI&#xA;    plot-dataframe      Plot candles with indicators.&#xA;    plot-profit         Generate plot showing profits.&#xA;    webserver           Webserver module.&#xA;&#xA;optional arguments:&#xA;  -h, --help            show this help message and exit&#xA;  -V, --version         show program&#39;s version number and exit&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Telegram RPC commands&lt;/h3&gt; &#xA;&lt;p&gt;Telegram is not mandatory. However, this is a great way to control your bot. More details and the full command list on the &lt;a href=&#34;https://www.freqtrade.io/en/latest/telegram-usage/&#34;&gt;documentation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;/start&lt;/code&gt;: Starts the trader.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/stop&lt;/code&gt;: Stops the trader.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/stopentry&lt;/code&gt;: Stop entering new trades.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/status &amp;lt;trade_id&amp;gt;|[table]&lt;/code&gt;: Lists all or specific open trades.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/profit [&amp;lt;n&amp;gt;]&lt;/code&gt;: Lists cumulative profit from all finished trades, over the last n days.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/forceexit &amp;lt;trade_id&amp;gt;|all&lt;/code&gt;: Instantly exits the given trade (Ignoring &lt;code&gt;minimum_roi&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/fx &amp;lt;trade_id&amp;gt;|all&lt;/code&gt;: Alias to &lt;code&gt;/forceexit&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/performance&lt;/code&gt;: Show performance of each finished trade grouped by pair&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/balance&lt;/code&gt;: Show account balance per currency.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/daily &amp;lt;n&amp;gt;&lt;/code&gt;: Shows profit or loss per day, over the last n days.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/help&lt;/code&gt;: Show help message.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/version&lt;/code&gt;: Show version.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Development branches&lt;/h2&gt; &#xA;&lt;p&gt;The project is currently setup in two main branches:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; - This branch has often new features, but might also contain breaking changes. We try hard to keep this branch as stable as possible.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;stable&lt;/code&gt; - This branch contains the latest stable release. This branch is generally well tested.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;feat/*&lt;/code&gt; - These are feature branches, which are being worked on heavily. Please don&#39;t use these unless you want to test a specific feature.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;h3&gt;Help / Discord&lt;/h3&gt; &#xA;&lt;p&gt;For any questions not covered by the documentation or for further information about the bot, or to simply engage with like-minded individuals, we encourage you to join the Freqtrade &lt;a href=&#34;https://discord.gg/p7nuUNVfP7&#34;&gt;discord server&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue&#34;&gt;Bugs / Issues&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;If you discover a bug in the bot, please &lt;a href=&#34;https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue&#34;&gt;search the issue tracker&lt;/a&gt; first. If it hasn&#39;t been reported, please &lt;a href=&#34;https://github.com/freqtrade/freqtrade/issues/new/choose&#34;&gt;create a new issue&lt;/a&gt; and ensure you follow the template guide so that the team can assist you as quickly as possible.&lt;/p&gt; &#xA;&lt;p&gt;For every &lt;a href=&#34;https://github.com/freqtrade/freqtrade/issues/new/choose&#34;&gt;issue&lt;/a&gt; created, kindly follow up and mark satisfaction or reminder to close issue when equilibrium ground is reached.&lt;/p&gt; &#xA;&lt;p&gt;--Maintain github&#39;s &lt;a href=&#34;https://docs.github.com/en/site-policy/github-terms/github-community-code-of-conduct&#34;&gt;community policy&lt;/a&gt;--&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/freqtrade/freqtrade/labels/enhancement&#34;&gt;Feature Requests&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Have you a great idea to improve the bot you want to share? Please, first search if this feature was not &lt;a href=&#34;https://github.com/freqtrade/freqtrade/labels/enhancement&#34;&gt;already discussed&lt;/a&gt;. If it hasn&#39;t been requested, please &lt;a href=&#34;https://github.com/freqtrade/freqtrade/issues/new/choose&#34;&gt;create a new request&lt;/a&gt; and ensure you follow the template guide so that it does not get lost in the bug reports.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/freqtrade/freqtrade/pulls&#34;&gt;Pull Requests&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Feel like the bot is missing a feature? We welcome your pull requests!&lt;/p&gt; &#xA;&lt;p&gt;Please read the &lt;a href=&#34;https://github.com/freqtrade/freqtrade/raw/develop/CONTRIBUTING.md&#34;&gt;Contributing document&lt;/a&gt; to understand the requirements before sending your pull-requests.&lt;/p&gt; &#xA;&lt;p&gt;Coding is not a necessity to contribute - maybe start with improving the documentation? Issues labeled &lt;a href=&#34;https://github.com/freqtrade/freqtrade/labels/good%20first%20issue&#34;&gt;good first issue&lt;/a&gt; can be good first contributions, and will help get you familiar with the codebase.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; before starting any major new feature work, &lt;em&gt;please open an issue describing what you are planning to do&lt;/em&gt; or talk to us on &lt;a href=&#34;https://discord.gg/p7nuUNVfP7&#34;&gt;discord&lt;/a&gt; (please use the #dev channel for this). This will ensure that interested parties can give valuable feedback on the feature, and let others know that you are working on it.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Always create your PR against the &lt;code&gt;develop&lt;/code&gt; branch, not &lt;code&gt;stable&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;h3&gt;Up-to-date clock&lt;/h3&gt; &#xA;&lt;p&gt;The clock must be accurate, synchronized to a NTP server very frequently to avoid problems with communication to the exchanges.&lt;/p&gt; &#xA;&lt;h3&gt;Minimum hardware required&lt;/h3&gt; &#xA;&lt;p&gt;To run this bot we recommend you a cloud instance with a minimum of:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Minimal (advised) system requirements: 2GB RAM, 1GB disk space, 2vCPU&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Software requirements&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://docs.python-guide.org/en/latest/starting/installation/&#34;&gt;Python &amp;gt;= 3.9&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pip.pypa.io/en/stable/installing/&#34;&gt;pip&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://git-scm.com/book/en/v2/Getting-Started-Installing-Git&#34;&gt;git&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ta-lib.github.io/ta-lib-python/&#34;&gt;TA-Lib&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://virtualenv.pypa.io/en/stable/installation.html&#34;&gt;virtualenv&lt;/a&gt; (Recommended)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.docker.com/products/docker&#34;&gt;Docker&lt;/a&gt; (Recommended)&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>jgraph/drawio-desktop</title>
    <updated>2024-07-31T01:20:40Z</updated>
    <id>tag:github.com,2024-07-31:/jgraph/drawio-desktop</id>
    <link href="https://github.com/jgraph/drawio-desktop" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official electron build of draw.io&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;drawio-desktop&lt;/strong&gt; is a diagramming and whiteboarding desktop app based on &lt;a href=&#34;https://electronjs.org/&#34;&gt;Electron&lt;/a&gt; that wraps the &lt;a href=&#34;https://github.com/jgraph/drawio&#34;&gt;core draw.io editor&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Download built binaries from the &lt;a href=&#34;https://github.com/jgraph/drawio-desktop/releases&#34;&gt;releases section&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Can I use this app for free?&lt;/strong&gt; Yes, under the apache 2.0 license. If you don&#39;t change the code and accept it is provided &#34;as-is&#34;, you can use it for any purpose.&lt;/p&gt; &#xA;&lt;h2&gt;Security&lt;/h2&gt; &#xA;&lt;p&gt;draw.io Desktop is designed to be completely isolated from the Internet, apart from the update process. This checks github.com at startup for a newer version and downloads it from an AWS S3 bucket owned by Github. All JavaScript files are self-contained, the Content Security Policy forbids running remotely loaded JavaScript.&lt;/p&gt; &#xA;&lt;p&gt;No diagram data is ever sent externally, nor do we send any analytics about app usage externally. This means certain functionality for which we do not have a JavaScript implementation do not work in the Desktop build, namely .vsd and Gliffy import.&lt;/p&gt; &#xA;&lt;p&gt;Security and isolating the app are the primarily objectives of draw.io desktop. If you ask for anything that involves external connections enabled in the app by default, the answer will be no.&lt;/p&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;Support is provided on a reasonable business constraints basis, but without anything contractually binding. All support is provided via this repo. There is no private ticketing support.&lt;/p&gt; &#xA;&lt;p&gt;Purchasing draw.io for Confluence or Jira does not entitle you to commercial support for draw.io desktop. The draw.io integrations for Atlassian are sold by Seibert Media, they have no involvement with this project.&lt;/p&gt; &#xA;&lt;h2&gt;Developing&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;draw.io&lt;/strong&gt; is a git submodule of &lt;strong&gt;drawio-desktop&lt;/strong&gt;. To get both you need to clone recursively:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;git clone --recursive https://github.com/jgraph/drawio-desktop.git&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;To run this:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;npm install&lt;/code&gt; (in the root directory of this repo)&lt;/li&gt; &#xA; &lt;li&gt;export DRAWIO_ENV=dev if you want to develop/debug in dev mode.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;npm start&lt;/code&gt; &lt;em&gt;in the root directory of this repo&lt;/em&gt; runs the app. For debugging, use &lt;code&gt;npm start --enable-logging&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Note: If a symlink is used to refer to drawio repo (instead of the submodule), then symlink the &lt;code&gt;node_modules&lt;/code&gt; directory inside &lt;code&gt;drawio/src/main/webapp&lt;/code&gt; also.&lt;/p&gt; &#xA;&lt;p&gt;To release:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Update the draw.io sub-module and push the change. Add version tag before pushing to origin.&lt;/li&gt; &#xA; &lt;li&gt;Wait for the builds to complete (&lt;a href=&#34;https://travis-ci.org/jgraph/drawio-desktop&#34;&gt;https://travis-ci.org/jgraph/drawio-desktop&lt;/a&gt; and &lt;a href=&#34;https://ci.appveyor.com/project/davidjgraph/drawio-desktop&#34;&gt;https://ci.appveyor.com/project/davidjgraph/drawio-desktop&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Go to &lt;a href=&#34;https://github.com/jgraph/drawio-desktop/releases&#34;&gt;https://github.com/jgraph/drawio-desktop/releases&lt;/a&gt;, edit the preview release.&lt;/li&gt; &#xA; &lt;li&gt;Download the windows exe and windows portable, sign them using &lt;code&gt;signtool sign /a /tr http://rfc3161timestamp.globalsign.com/advanced /td SHA256 c:/path/to/your/file.exe&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Re-upload signed file as &lt;code&gt;draw.io-windows-installer-x.y.z.exe&lt;/code&gt; and &lt;code&gt;draw.io-windows-no-installer-x.y.z.exe&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Add release notes&lt;/li&gt; &#xA; &lt;li&gt;Publish release&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: In Windows release, when using both x64 and is32 as arch, the result is one big file with both archs. This is why we split them.&lt;/p&gt; &#xA;&lt;p&gt;Local Storage and Session Storage is stored in the AppData folder:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;macOS: &lt;code&gt;~/Library/Application Support/draw.io&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Windows: &lt;code&gt;C:\Users\&amp;lt;USER-NAME&amp;gt;\AppData\Roaming\draw.io\&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Not open-contribution&lt;/h2&gt; &#xA;&lt;p&gt;draw.io is closed to contributions.&lt;/p&gt; &#xA;&lt;p&gt;The level of complexity of this project means that even simple changes can break a &lt;em&gt;lot&lt;/em&gt; of other moving parts. The amount of testing required is far more than it first seems. If we were to receive a PR, we&#39;d have to basically throw it away and write it how we want it to be implemented.&lt;/p&gt; &#xA;&lt;p&gt;We are grateful for community involvement, bug reports, &amp;amp; feature requests. We do not wish to come off as anything but welcoming, however, we&#39;ve made the decision to keep this project closed to contributions for the long term viability of the project.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>lipku/metahuman-stream</title>
    <updated>2024-07-31T01:20:40Z</updated>
    <id>tag:github.com,2024-07-31:/lipku/metahuman-stream</id>
    <link href="https://github.com/lipku/metahuman-stream" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Real time interactive streaming digital human&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Real time interactive streaming digital human， realize audio video synchronous dialogue. It can basically achieve commercial effects.&lt;br&gt; 实时交互流式数字人，实现音视频同步对话。基本可以达到商用效果&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1PM4m1y7Q2/&#34;&gt;ernerf效果&lt;/a&gt; &lt;a href=&#34;https://www.bilibili.com/video/BV1gm421N7vQ/&#34;&gt;musetalk效果&lt;/a&gt; &lt;a href=&#34;https://www.bilibili.com/video/BV1Bw4m1e74P/&#34;&gt;wav2lip效果&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;支持多种数字人模型: ernerf、musetalk、wav2lip&lt;/li&gt; &#xA; &lt;li&gt;支持声音克隆&lt;/li&gt; &#xA; &lt;li&gt;支持数字人说话被打断&lt;/li&gt; &#xA; &lt;li&gt;支持全身视频拼接&lt;/li&gt; &#xA; &lt;li&gt;支持rtmp和webrtc&lt;/li&gt; &#xA; &lt;li&gt;支持视频编排：不说话时播放自定义视频&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;1. Installation&lt;/h2&gt; &#xA;&lt;p&gt;Tested on Ubuntu 20.04, Python3.10, Pytorch 1.12 and CUDA 11.3&lt;/p&gt; &#xA;&lt;h3&gt;1.1 Install dependency&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n nerfstream python=3.10&#xA;conda activate nerfstream&#xA;conda install pytorch==1.12.1 torchvision==0.13.1 cudatoolkit=11.3 -c pytorch&#xA;pip install -r requirements.txt&#xA;#如果只用musetalk或者wav2lip模型，不需要安装下面的库&#xA;pip install &#34;git+https://github.com/facebookresearch/pytorch3d.git&#34;&#xA;pip install tensorflow-gpu==2.8.0&#xA;pip install --upgrade &#34;protobuf&amp;lt;=3.20.1&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;安装常见问题&lt;a href=&#34;https://raw.githubusercontent.com/lipku/metahuman-stream/main/assets/faq.md&#34;&gt;FAQ&lt;/a&gt;&lt;br&gt; linux cuda环境搭建可以参考这篇文章 &lt;a href=&#34;https://zhuanlan.zhihu.com/p/674972886&#34;&gt;https://zhuanlan.zhihu.com/p/674972886&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;2. Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;默认采用ernerf模型，webrtc推流到srs&lt;/p&gt; &#xA;&lt;h3&gt;2.1 运行srs&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;export CANDIDATE=&#39;&amp;lt;服务器外网ip&amp;gt;&#39;&#xA;docker run --rm --env CANDIDATE=$CANDIDATE \&#xA;  -p 1935:1935 -p 8080:8080 -p 1985:1985 -p 8000:8000/udp \&#xA;  registry.cn-hangzhou.aliyuncs.com/ossrs/srs:5 \&#xA;  objs/srs -c conf/rtc.conf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2.2 启动数字人：&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;如果访问不了huggingface，在运行前&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export HF_ENDPOINT=https://hf-mirror.com&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;用浏览器打开&lt;a href=&#34;http://serverip:8010/rtcpushapi.html&#34;&gt;http://serverip:8010/rtcpushapi.html&lt;/a&gt;, 在文本框输入任意文字，提交。数字人播报该段文字&lt;br&gt; 备注：服务端需要开放端口 tcp:8000,8010,1985; udp:8000&lt;/p&gt; &#xA;&lt;h2&gt;3. More Usage&lt;/h2&gt; &#xA;&lt;h3&gt;3.1 使用LLM模型进行数字人对话&lt;/h3&gt; &#xA;&lt;p&gt;目前借鉴数字人对话系统&lt;a href=&#34;https://github.com/Kedreamix/Linly-Talker&#34;&gt;LinlyTalker&lt;/a&gt;的方式，LLM模型支持Chatgpt,Qwen和GeminiPro。需要在app.py中填入自己的api_key。&lt;/p&gt; &#xA;&lt;p&gt;用浏览器打开&lt;a href=&#34;http://serverip:8010/rtcpushchat.html&#34;&gt;http://serverip:8010/rtcpushchat.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;3.2 声音克隆&lt;/h3&gt; &#xA;&lt;p&gt;可以任意选用下面两种服务，推荐用gpt-sovits&lt;/p&gt; &#xA;&lt;h4&gt;3.2.1 gpt-sovits&lt;/h4&gt; &#xA;&lt;p&gt;服务部署参照&lt;a href=&#34;https://raw.githubusercontent.com/lipku/metahuman-stream/main/tts/README.md&#34;&gt;gpt-sovits&lt;/a&gt;&lt;br&gt; 运行&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python app.py --tts gpt-sovits --TTS_SERVER http://127.0.0.1:9880 --REF_FILE data/ref.wav --REF_TEXT xxx&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;REF_TEXT为REF_FILE中语音内容，时长不宜过长&lt;/p&gt; &#xA;&lt;h4&gt;3.2.2 xtts&lt;/h4&gt; &#xA;&lt;p&gt;运行xtts服务，参照 &lt;a href=&#34;https://github.com/coqui-ai/xtts-streaming-server&#34;&gt;https://github.com/coqui-ai/xtts-streaming-server&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --gpus=all -e COQUI_TOS_AGREED=1 --rm -p 9000:80 ghcr.io/coqui-ai/xtts-streaming-server:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;然后运行，其中ref.wav为需要克隆的声音文件&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python app.py --tts xtts --REF_FILE data/ref.wav --TTS_SERVER http://localhost:9000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.3 音频特征用hubert&lt;/h3&gt; &#xA;&lt;p&gt;如果训练模型时用的hubert提取音频特征，用如下命令启动数字人&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python app.py --asr_model facebook/hubert-large-ls960-ft &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.4 设置背景图片&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;python app.py --bg_img bc.jpg &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.5 全身视频拼接&lt;/h3&gt; &#xA;&lt;h4&gt;3.5.1 切割训练用的视频&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -i fullbody.mp4 -vf crop=&#34;400:400&lt;span&gt;💯&lt;/span&gt;5&#34; train.mp4&amp;nbsp;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;用train.mp4训练模型&lt;/p&gt; &#xA;&lt;h4&gt;3.5.2 提取全身图片&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -i fullbody.mp4 -vf fps=25 -qmin 1 -q:v 1 -start_number 0 data/fullbody/img/%d.jpg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;3.5.2 启动数字人&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;python app.py --fullbody --fullbody_img data/fullbody/img --fullbody_offset_x 100 --fullbody_offset_y 5 --fullbody_width 580 --fullbody_height 1080 --W 400 --H 400&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;--fullbody_width、--fullbody_height 全身视频的宽、高&lt;/li&gt; &#xA; &lt;li&gt;--W、--H 训练视频的宽、高&lt;/li&gt; &#xA; &lt;li&gt;ernerf训练第三步torso如果训练的不好，在拼接处会有接缝。可以在上面的命令加上--torso_imgs data/xxx/torso_imgs，torso不用模型推理，直接用训练数据集里的torso图片。这种方式可能头颈处会有些人工痕迹。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;3.6 不说话时用自定义视频替代&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;提取自定义视频图片&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;ffmpeg -i silence.mp4 -vf fps=25 -qmin 1 -q:v 1 -start_number 0 data/customvideo/img/%d.png&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;运行数字人&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;python app.py --customvideo --customvideo_img data/customvideo/img --customvideo_imgnum 100&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.7 webrtc p2p&lt;/h3&gt; &#xA;&lt;p&gt;此种模式不需要srs&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python app.py --transport webrtc&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;服务端需要开放端口 tcp:8010; udp:50000~60000&lt;br&gt; 用浏览器打开&lt;a href=&#34;http://serverip:8010/webrtcapi.html&#34;&gt;http://serverip:8010/webrtcapi.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;3.8 rtmp推送到srs&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;安装rtmpstream库&lt;br&gt; 参照 &lt;a href=&#34;https://github.com/lipku/python_rtmpstream&#34;&gt;https://github.com/lipku/python_rtmpstream&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;启动srs&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --rm -it -p 1935:1935 -p 1985:1985 -p 8080:8080 registry.cn-hangzhou.aliyuncs.com/ossrs/srs:5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;运行数字人&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python app.py --transport rtmp --push_url &#39;rtmp://localhost/live/livestream&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;用浏览器打开&lt;a href=&#34;http://serverip:8010/echoapi.html&#34;&gt;http://serverip:8010/echoapi.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;3.9 模型用musetalk&lt;/h3&gt; &#xA;&lt;p&gt;暂不支持rtmp推送&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;安装依赖库&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda install ffmpeg&#xA;pip install --no-cache-dir -U openmim &#xA;mim install mmengine &#xA;mim install &#34;mmcv&amp;gt;=2.0.1&#34; &#xA;mim install &#34;mmdet&amp;gt;=3.1.0&#34; &#xA;mim install &#34;mmpose&amp;gt;=1.1.0&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;下载模型&lt;br&gt; 下载MuseTalk运行需要的模型，提供一个下载地址 &lt;a href=&#34;https://caiyun.139.com/m/i?2eAjs2nXXnRgr&#34;&gt;https://caiyun.139.com/m/i?2eAjs2nXXnRgr&lt;/a&gt; 提取码:qdg2 解压后，将models下文件拷到本项目的models下&lt;br&gt; 下载数字人模型，链接: &lt;a href=&#34;https://caiyun.139.com/m/i?2eAjs8optksop&#34;&gt;https://caiyun.139.com/m/i?2eAjs8optksop&lt;/a&gt; 提取码:3mkt, 解压后将整个文件夹拷到本项目的data/avatars下&lt;/li&gt; &#xA; &lt;li&gt;运行&lt;br&gt; python app.py --model musetalk --transport webrtc&lt;br&gt; 用浏览器打开&lt;a href=&#34;http://serverip:8010/webrtcapi.html&#34;&gt;http://serverip:8010/webrtcapi.html&lt;/a&gt;&lt;br&gt; 可以设置--batch_size 提高显卡利用率，设置--avatar_id 运行不同的数字人&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;替换成自己的数字人&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/TMElyralab/MuseTalk.git&#xA;cd MuseTalk&#xA;修改configs/inference/realtime.yaml，将preparation改为True&#xA;python -m scripts.realtime_inference --inference_config configs/inference/realtime.yaml&#xA;运行后将results/avatars下文件拷到本项目的data/avatars下&#xA;方法二&#xA;执行&#xA;cd musetalk &#xA;python simple_musetalk.py --avatar_id 4  --file D:\\ok\\test.mp4&#xA;支持视频和图片生成 会自动生成到data的avatars目录下&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.10 模型用wav2lip&lt;/h3&gt; &#xA;&lt;p&gt;暂不支持rtmp推送&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;下载模型&lt;br&gt; 下载wav2lip运行需要的模型，链接: &lt;a href=&#34;https://pan.baidu.com/s/1yOsQ06-RIDTJd3HFCw4wtA&#34;&gt;https://pan.baidu.com/s/1yOsQ06-RIDTJd3HFCw4wtA&lt;/a&gt; 密码: ltua 将s3fd.pth拷到本项目wav2lip/face_detection/detection/sfd/s3fd.pth, 将wav2lip.pth拷到本项目的models下&lt;br&gt; 数字人模型文件 wav2lip_avatar1.tar.gz, 解压后将整个文件夹拷到本项目的data/avatars下&lt;/li&gt; &#xA; &lt;li&gt;运行&lt;br&gt; python app.py --transport webrtc --model wav2lip --avatar_id wav2lip_avatar1&lt;br&gt; 用浏览器打开&lt;a href=&#34;http://serverip:8010/webrtcapi.html&#34;&gt;http://serverip:8010/webrtcapi.html&lt;/a&gt;&lt;br&gt; 可以设置--batch_size 提高显卡利用率，设置--avatar_id 运行不同的数字人&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;替换成自己的数字人&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd wav2lip&#xA;python genavatar.py --video_path xxx.mp4&#xA;运行后将results/avatars下文件拷到本项目的data/avatars下&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;4. Docker Run&lt;/h2&gt; &#xA;&lt;p&gt;不需要前面的安装，直接运行。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run --gpus all -it --network=host --rm registry.cn-beijing.aliyuncs.com/codewithgpu2/lipku-metahuman-stream:vjo1Y6NJ3N&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;代码在/root/metahuman-stream，先git pull拉一下最新代码，然后执行命令同第2、3步&lt;/p&gt; &#xA;&lt;p&gt;另外提供autodl镜像： &lt;a href=&#34;https://www.codewithgpu.com/i/lipku/metahuman-stream/base&#34;&gt;https://www.codewithgpu.com/i/lipku/metahuman-stream/base&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://raw.githubusercontent.com/lipku/metahuman-stream/main/autodl/README.md&#34;&gt;autodl教程&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;5. 数字人模型文件&lt;/h2&gt; &#xA;&lt;p&gt;可以替换成自己训练的模型(&lt;a href=&#34;https://github.com/Fictionarry/ER-NeRF&#34;&gt;https://github.com/Fictionarry/ER-NeRF&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;.&#xA;├── data&#xA;│   ├── data_kf.json&#xA;│   ├── au.csv&#x9;&#x9;&#x9;&#xA;│   ├── pretrained&#xA;│   └── └── ngp_kf.pth&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;6. 性能分析&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;帧率&lt;br&gt; 在Tesla T4显卡上测试整体fps为18左右，如果去掉音视频编码推流，帧率在20左右。用4090显卡可以达到40多帧/秒。&lt;br&gt; 优化：新开一个线程运行音视频编码推流&lt;/li&gt; &#xA; &lt;li&gt;延时&lt;br&gt; 整体延时3s左右&lt;br&gt; （1）tts延时1.7s左右，目前用的edgetts，需要将每句话转完后一次性输入，可以优化tts改成流式输入&lt;br&gt; （2）wav2vec延时0.4s，需要缓存18帧音频做计算 （3）srs转发延时，设置srs服务器减少缓冲延时。具体配置可看 &lt;a href=&#34;https://ossrs.net/lts/zh-cn/docs/v5/doc/low-latency&#34;&gt;https://ossrs.net/lts/zh-cn/docs/v5/doc/low-latency&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;7. TODO&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 添加chatgpt实现数字人对话&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 声音克隆&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 数字人静音时用一段视频代替&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; MuseTalk&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Wav2Lip&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; SyncTalk&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;如果本项目对你有帮助，帮忙点个star。也欢迎感兴趣的朋友一起来完善该项目。&lt;br&gt; 知识星球: &lt;a href=&#34;https://t.zsxq.com/7NMyO&#34;&gt;https://t.zsxq.com/7NMyO&lt;/a&gt; 沉淀高质量常见问题、最佳实践经验、问题解答&lt;br&gt; 微信公众号：数字人技术&lt;br&gt; &lt;img src=&#34;https://mmbiz.qpic.cn/sz_mmbiz_jpg/l3ZibgueFiaeyfaiaLZGuMGQXnhLWxibpJUS2gfs8Dje6JuMY8zu2tVyU9n8Zx1yaNncvKHBMibX0ocehoITy5qQEZg/640?wxfrom=12&amp;amp;tp=wxpic&amp;amp;usePicPrefetch=1&amp;amp;wx_fmt=jpeg&amp;amp;from=appmsg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>