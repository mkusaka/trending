<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-04T01:23:33Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>cooderl/wewe-rss</title>
    <updated>2024-03-04T01:23:33Z</updated>
    <id>tag:github.com,2024-03-04:/cooderl/wewe-rss</id>
    <link href="https://github.com/cooderl/wewe-rss" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🤗更优雅的微信公众号订阅方式，支持私有化部署、微信公众号RSS生成（基于微信读书）。&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/cooderl/wewe-rss/main/assets/logo.png&#34; width=&#34;80&#34; alt=&#34;预览&#34;&gt; &#xA; &lt;h1 align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/cooderl/wewe-rss&#34;&gt;WeWe RSS&lt;/a&gt;&lt;/h1&gt; &#xA; &lt;p&gt;更优雅的微信公众号订阅方式。&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cooderl/wewe-rss/main/assets/preview1.png&#34; alt=&#34;主界面&#34;&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;功能&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 支持微信公众号订阅（基于微信读书）&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 后台自动定时更新内容&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 微信公众号RSS生成（支持&lt;code&gt;.atom&lt;/code&gt;.&lt;code&gt;rss&lt;/code&gt;.&lt;code&gt;json&lt;/code&gt;格式)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 支持全文内容输出，让阅读无障碍&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;部署&lt;/h2&gt; &#xA;&lt;h3&gt;一键部署（待完善添加模板）&lt;/h3&gt; &#xA;&lt;p&gt;你可以通过以下平台一键部署，只需填写本项目的URL即可。&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zeabur.com/&#34;&gt;Zeabur&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://railway.app/&#34;&gt;Railway&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/cooderl/wewe-rss/issues/32&#34;&gt;HuggingFace部署参考&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Docker Compose 部署&lt;/h3&gt; &#xA;&lt;p&gt;可参考 &lt;a href=&#34;https://github.com/cooderl/wewe-rss/raw/main/docker-compose.yml&#34;&gt;docker-compose.yml&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/cooderl/wewe-rss/raw/main/docker-compose.sqlite.yml&#34;&gt;docker-compose.sqlite.yml&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Docker 命令启动&lt;/h3&gt; &#xA;&lt;h4&gt;Sqlite&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run -d \&#xA;  --name wewe-rss \&#xA;  -p 4000:4000 \&#xA;  -e DATABASE_TYPE=sqlite \&#xA;  -e AUTH_CODE=123567 \&#xA;  -v $(pwd)/data:/app/data \&#xA;  cooderl/wewe-rss-sqlite:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Mysql&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;创建docker网络&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker network create wewe-rss&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;启动 MySQL 数据库&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run -d \&#xA;  --name db \&#xA;  -e MYSQL_ROOT_PASSWORD=123456 \&#xA;  -e TZ=&#39;Asia/Shanghai&#39; \&#xA;  -e MYSQL_DATABASE=&#39;wewe-rss&#39; \&#xA;  -v db_data:/var/lib/mysql \&#xA;  --network wewe-rss \&#xA;  mysql:latest --default-authentication-plugin=mysql_native_password&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;启动 Server&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker run -d \&#xA;  --name wewe-rss \&#xA;  -p 4000:4000 \&#xA;  -e DATABASE_URL=&#39;mysql://root:123456@db:3306/wewe-rss?schema=public&amp;amp;connect_timeout=30&amp;amp;pool_timeout=30&amp;amp;socket_timeout=30&#39; \&#xA;  -e AUTH_CODE=123567 \&#xA;  --network wewe-rss \&#xA;  cooderl/wewe-rss:latest&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cooderl/wewe-rss/main/assets/nginx.example.conf&#34;&gt;Nginx配置参考&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;本地部署&lt;/h3&gt; &#xA;&lt;p&gt;如果你想本地部署，请使用 &lt;code&gt;pnpm install &amp;amp;&amp;amp; pnpm run -r build &amp;amp;&amp;amp; pnpm run start:server&lt;/code&gt; 命令(可以配合 pm2 来守护进程，防止被杀死)。&lt;/p&gt; &#xA;&lt;h2&gt;环境变量&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;AUTH_CODE&lt;/code&gt; （&lt;strong&gt;必填项&lt;/strong&gt;）服务端接口请求授权码，(&lt;code&gt;/feeds&lt;/code&gt;路径不需要)。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;DATABASE_URL&lt;/code&gt; （&lt;strong&gt;必填项&lt;/strong&gt;）数据库地址，例如 &lt;code&gt;mysql://root:123456@127.0.0.1:3306/wewe-rss&lt;/code&gt;。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;DATABASE_TYPE&lt;/code&gt; 数据库类型，使用 &lt;code&gt;sqlite&lt;/code&gt; 时需要填写 &lt;code&gt;sqlite&lt;/code&gt;。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;SERVER_ORIGIN_URL&lt;/code&gt; 服务端访问地址，用于生成RSS的完整路径（外网访问时，设置为服务器的公网 IP 或者域名地址）。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;MAX_REQUEST_PER_MINUTE&lt;/code&gt; 每分钟最大请求次数，默认 60。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;FEED_MODE&lt;/code&gt; 输出模式，可选值 &lt;code&gt;fulltext&lt;/code&gt;（RSS全文模式会使接口响应会变慢，占用更多内存）。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;CRON_EXPRESSION&lt;/code&gt; 定时更新订阅源Cron表达式，默认为 &lt;code&gt;35 5,17 * * *&lt;/code&gt;。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;使用方式&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;进入账号管理，点击添加账号，微信扫码登录微信读书账号。&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img width=&#34;400&#34; src=&#34;https://raw.githubusercontent.com/cooderl/wewe-rss/main/assets/preview2.png&#34;&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;进入公众号源，点击添加，通过提交微信公众号分享链接，订阅微信公众号。 &lt;strong&gt;（添加频率过高容易被封控，等24小时解封）&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img width=&#34;400&#34; src=&#34;https://raw.githubusercontent.com/cooderl/wewe-rss/main/assets/preview3.png&#34;&gt; &#xA;&lt;h2&gt;本地开发&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;安装 nodejs 18 和 pnpm；&lt;/li&gt; &#xA; &lt;li&gt;修改环境变量&lt;code&gt;cp ./apps/web/.env.local.example ./apps/web/.env&lt;/code&gt;和&lt;code&gt;cp ./apps/server/.env.local.example ./apps/server/.env&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;执行 &lt;code&gt;pnpm install &amp;amp;&amp;amp; pnpm dev&lt;/code&gt; 即可。⚠️ 注意：此命令仅用于本地开发，不要用于部署！&lt;/li&gt; &#xA; &lt;li&gt;前端访问 &lt;code&gt;http://localhost:5173&lt;/code&gt; ，后端访问 &lt;code&gt;http://localhost:4000&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;风险声明&lt;/h2&gt; &#xA;&lt;p&gt;为了确保本项目的持久运行，某些接口请求将通过&lt;code&gt;weread.111965.xyz&lt;/code&gt;进行转发。请放心，该转发服务不会保存任何数据。&lt;/p&gt; &#xA;&lt;h2&gt;打赏&lt;/h2&gt; &#xA;&lt;p&gt;如果您觉得我们的项目有价值，并希望帮助我们继续发展，可以用以下几种加密货币打赏:&lt;/p&gt; &#xA;&lt;p&gt;BTC(Bitcoin): &lt;code&gt;1DGU9zRC8cvexq3W92Kzxqg5sNnbWPz9fE&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;ETH(Ethereum, ERC20): &lt;code&gt;0x6bb8cef666c346ac3926fd32edd27d8246dcece0&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;USDT(Tron, TRC20): &lt;code&gt;TLsukYHcXN34RXABZwppRE5AuPp8AWY7Wv&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/cooderl/wewe-rss/main/LICENSE&#34;&gt;MIT&lt;/a&gt; @cooderl&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>naver/dust3r</title>
    <updated>2024-03-04T01:23:33Z</updated>
    <id>tag:github.com,2024-03-04:/naver/dust3r</id>
    <link href="https://github.com/naver/dust3r" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DUSt3R&lt;/h1&gt; &#xA;&lt;p&gt;Official implementation of &lt;code&gt;DUSt3R: Geometric 3D Vision Made Easy&lt;/code&gt;&lt;br&gt; [&lt;a href=&#34;https://dust3r.europe.naverlabs.com/&#34;&gt;Project page&lt;/a&gt;], [&lt;a href=&#34;https://arxiv.org/abs/2312.14132&#34;&gt;DUSt3R arxiv&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/naver/dust3r/main/assets/pipeline1.jpg&#34; alt=&#34;Example of reconstruction from two images&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/naver/dust3r/main/assets/dust3r_archi.jpg&#34; alt=&#34;High level overview of DUSt3R capabilities&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{wang2023dust3r,&#xA;      title={DUSt3R: Geometric 3D Vision Made Easy}, &#xA;      author={Shuzhe Wang and Vincent Leroy and Yohann Cabon and Boris Chidlovskii and Jerome Revaud},&#xA;      year={2023},&#xA;      eprint={2312.14132},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#dust3r&#34;&gt;DUSt3R&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#table-of-contents&#34;&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#get-started&#34;&gt;Get Started&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#checkpoints&#34;&gt;Checkpoints&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#interactive-demo&#34;&gt;Interactive demo&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#usage&#34;&gt;Usage&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#training&#34;&gt;Training&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#demo&#34;&gt;Demo&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#our-hyperparameters&#34;&gt;Our Hyperparameters&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The code is distributed under the CC BY-NC-SA 4.0 License. See &lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Copyright (C) 2024-present Naver Corporation. All rights reserved.&#xA;# Licensed under CC BY-NC-SA 4.0 (non-commercial use only).&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone DUSt3R&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone --recursive https://github.com/naver/dust3r&#xA;cd dust3r&#xA;# if you have already cloned dust3r:&#xA;# git submodule update --init --recursive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Create the environment, here we show an example using conda.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n dust3r python=3.11 cmake=3.14.0&#xA;conda activate dust3r &#xA;conda install pytorch torchvision pytorch-cuda=12.1 -c pytorch -c nvidia  # use the correct version of cuda for your system&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Optional, compile the cuda kernels for RoPE (as in CroCo v2)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# DUST3R relies on RoPE positional embeddings for which you can compile some cuda kernels for faster runtime.&#xA;cd croco/models/curope/&#xA;python setup.py build_ext --inplace&#xA;cd ../../../&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Download pre-trained model&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p checkpoints/&#xA;wget https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth -P checkpoints/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Checkpoints&lt;/h3&gt; &#xA;&lt;p&gt;We provide several pre-trained models:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Modelname&lt;/th&gt; &#xA;   &lt;th&gt;Training resolutions&lt;/th&gt; &#xA;   &lt;th&gt;Head&lt;/th&gt; &#xA;   &lt;th&gt;Encoder&lt;/th&gt; &#xA;   &lt;th&gt;Decoder&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_224_linear.pth&#34;&gt;&lt;code&gt;DUSt3R_ViTLarge_BaseDecoder_224_linear.pth&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;224x224&lt;/td&gt; &#xA;   &lt;td&gt;Linear&lt;/td&gt; &#xA;   &lt;td&gt;ViT-L&lt;/td&gt; &#xA;   &lt;td&gt;ViT-B&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_linear.pth&#34;&gt;&lt;code&gt;DUSt3R_ViTLarge_BaseDecoder_512_linear.pth&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;512x384, 512x336, 512x288, 512x256, 512x160&lt;/td&gt; &#xA;   &lt;td&gt;Linear&lt;/td&gt; &#xA;   &lt;td&gt;ViT-L&lt;/td&gt; &#xA;   &lt;td&gt;ViT-B&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth&#34;&gt;&lt;code&gt;DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;512x384, 512x336, 512x288, 512x256, 512x160&lt;/td&gt; &#xA;   &lt;td&gt;DPT&lt;/td&gt; &#xA;   &lt;td&gt;ViT-L&lt;/td&gt; &#xA;   &lt;td&gt;ViT-B&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;You can check the hyperparameters we used to train these models in the &lt;a href=&#34;https://raw.githubusercontent.com/naver/dust3r/main/#our-hyperparameters&#34;&gt;section: Our Hyperparameters&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Interactive demo&lt;/h3&gt; &#xA;&lt;p&gt;In this demo, you should be able run DUSt3R on your machine to reconstruct a scene.&lt;br&gt; First select images that depicts the same scene.&lt;/p&gt; &#xA;&lt;p&gt;You can adjust the global alignment schedule and its number of iterations.&lt;br&gt; Note: if you selected one or two images, the global alignment procedure will be skipped (mode=GlobalAlignerMode.PairViewer)&lt;br&gt; Hit &#34;Run&#34; and wait.&lt;br&gt; When the global alignment ends, the reconstruction appears.&lt;br&gt; Use the slider &#34;min_conf_thr&#34; to show or remove low confidence areas.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 demo.py --weights checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth&#xA;&#xA;# Use --image_size to select the correct resolution for your checkpoint. 512 (default) or 224&#xA;# Use --local_network to make it accessible on the local network, or --server_name to specify the url manually&#xA;# Use --server_port to change the port, by default it will search for an available port starting at 7860&#xA;# Use --device to use a different device, by default it&#39;s &#34;cuda&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/naver/dust3r/main/assets/demo.jpg&#34; alt=&#34;demo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from dust3r.inference import inference, load_model&#xA;from dust3r.utils.image import load_images&#xA;from dust3r.image_pairs import make_pairs&#xA;from dust3r.cloud_opt import global_aligner, GlobalAlignerMode&#xA;&#xA;if __name__ == &#39;__main__&#39;:&#xA;    model_path = &#34;checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth&#34;&#xA;    device = &#39;cuda&#39;&#xA;    batch_size = 1&#xA;    schedule = &#39;cosine&#39;&#xA;    lr = 0.01&#xA;    niter = 300&#xA;&#xA;    model = load_model(model_path, device)&#xA;    # load_images can take a list of images or a directory&#xA;    images = load_images([&#39;croco/assets/Chateau1.png&#39;, &#39;croco/assets/Chateau2.png&#39;], size=512)&#xA;    pairs = make_pairs(images, scene_graph=&#39;complete&#39;, prefilter=None, symmetrize=True)&#xA;    output = inference(pairs, model, device, batch_size=batch_size)&#xA;&#xA;    # at this stage, you have the raw dust3r predictions&#xA;    view1, pred1 = output[&#39;view1&#39;], output[&#39;pred1&#39;]&#xA;    view2, pred2 = output[&#39;view2&#39;], output[&#39;pred2&#39;]&#xA;    # here, view1, pred1, view2, pred2 are dicts of lists of len(2)&#xA;    #  -&amp;gt; because we symmetrize we have (im1, im2) and (im2, im1) pairs&#xA;    # in each view you have:&#xA;    # an integer image identifier: view1[&#39;idx&#39;] and view2[&#39;idx&#39;]&#xA;    # the img: view1[&#39;img&#39;] and view2[&#39;img&#39;]&#xA;    # the image shape: view1[&#39;true_shape&#39;] and view2[&#39;true_shape&#39;]&#xA;    # an instance string output by the dataloader: view1[&#39;instance&#39;] and view2[&#39;instance&#39;]&#xA;    # pred1 and pred2 contains the confidence values: pred1[&#39;conf&#39;] and pred2[&#39;conf&#39;]&#xA;    # pred1 contains 3D points for view1[&#39;img&#39;] in view1[&#39;img&#39;] space: pred1[&#39;pts3d&#39;]&#xA;    # pred2 contains 3D points for view2[&#39;img&#39;] in view1[&#39;img&#39;] space: pred2[&#39;pts3d_in_other_view&#39;]&#xA;&#xA;    # next we&#39;ll use the global_aligner to align the predictions&#xA;    # depending on your task, you may be fine with the raw output and not need it&#xA;    # with only two input images, you could use GlobalAlignerMode.PairViewer: it would just convert the output&#xA;    # if using GlobalAlignerMode.PairViewer, no need to run compute_global_alignment&#xA;    scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PointCloudOptimizer)&#xA;    loss = scene.compute_global_alignment(init=&#34;mst&#34;, niter=niter, schedule=schedule, lr=lr)&#xA;&#xA;    # retrieve useful values from scene:&#xA;    imgs = scene.imgs&#xA;    focals = scene.get_focals()&#xA;    poses = scene.get_im_poses()&#xA;    pts3d = scene.get_pts3d()&#xA;    confidence_masks = scene.get_masks()&#xA;&#xA;    # visualize reconstruction&#xA;    scene.show()&#xA;&#xA;    # find 2D-2D matches between the two images&#xA;    from dust3r.utils.geometry import find_reciprocal_matches, xy_grid&#xA;    pts2d_list, pts3d_list = [], []&#xA;    for i in range(2):&#xA;        conf_i = confidence_masks[i].cpu().numpy()&#xA;        pts2d_list.append(xy_grid(*imgs[i].shape[:2][::-1])[conf_i])  # imgs[i].shape[:2] = (H, W)&#xA;        pts3d_list.append(pts3d[i].detach().cpu().numpy()[conf_i])&#xA;    reciprocal_in_P2, nn2_in_P1, num_matches = find_reciprocal_matches(*pts3d_list)&#xA;    print(f&#39;found {num_matches} matches&#39;)&#xA;    matches_im1 = pts2d_list[1][reciprocal_in_P2]&#xA;    matches_im0 = pts2d_list[0][nn2_in_P1][reciprocal_in_P2]&#xA;&#xA;    # visualize a few matches&#xA;    import numpy as np&#xA;    from matplotlib import pyplot as pl&#xA;    n_viz = 10&#xA;    match_idx_to_viz = np.round(np.linspace(0, num_matches-1, n_viz)).astype(int)&#xA;    viz_matches_im0, viz_matches_im1 = matches_im0[match_idx_to_viz], matches_im1[match_idx_to_viz]&#xA;&#xA;    H0, W0, H1, W1 = *imgs[0].shape[:2], *imgs[1].shape[:2]&#xA;    img0 = np.pad(imgs[0], ((0, max(H1 - H0, 0)), (0, 0), (0, 0)), &#39;constant&#39;, constant_values=0)&#xA;    img1 = np.pad(imgs[1], ((0, max(H0 - H1, 0)), (0, 0), (0, 0)), &#39;constant&#39;, constant_values=0)&#xA;    img = np.concatenate((img0, img1), axis=1)&#xA;    pl.figure()&#xA;    pl.imshow(img)&#xA;    cmap = pl.get_cmap(&#39;jet&#39;)&#xA;    for i in range(n_viz):&#xA;        (x0, y0), (x1, y1) = viz_matches_im0[i].T, viz_matches_im1[i].T&#xA;        pl.plot([x0, x1 + W0], [y0, y1], &#39;-+&#39;, color=cmap(i / (n_viz - 1)), scalex=False, scaley=False)&#xA;    pl.show(block=True)&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/naver/dust3r/main/assets/matching.jpg&#34; alt=&#34;matching example on croco pair&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;In this section, we present propose a short demonstration to get started with training DUSt3R. At the moment, we didn&#39;t release the training datasets, so we&#39;re going to download and prepare a subset of &lt;a href=&#34;https://github.com/facebookresearch/co3d&#34;&gt;CO3Dv2&lt;/a&gt; - &lt;a href=&#34;https://github.com/facebookresearch/co3d/raw/main/LICENSE&#34;&gt;Creative Commons Attribution-NonCommercial 4.0 International&lt;/a&gt; and launch the training code on it. The demo model will be trained for a few epochs on a very small dataset. It will not be very good.&lt;/p&gt; &#xA;&lt;h3&gt;Demo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&#xA;# download and prepare the co3d subset&#xA;mkdir -p data/co3d_subset&#xA;cd data/co3d_subset&#xA;git clone https://github.com/facebookresearch/co3d&#xA;cd co3d&#xA;python3 ./co3d/download_dataset.py --download_folder ../ --single_sequence_subset&#xA;rm ../*.zip&#xA;cd ../../..&#xA;&#xA;python3 datasets_preprocess/preprocess_co3d.py --co3d_dir data/co3d_subset --output_dir data/co3d_subset_processed  --single_sequence_subset&#xA;&#xA;# download the pretrained croco v2 checkpoint&#xA;mkdir -p checkpoints/&#xA;wget https://download.europe.naverlabs.com/ComputerVision/CroCo/CroCo_V2_ViTLarge_BaseDecoder.pth -P checkpoints/&#xA;&#xA;# the training of dust3r is done in 3 steps.&#xA;# for this example we&#39;ll do fewer epochs, for the actual hyperparameters we used in the paper, see the next section: &#34;Our Hyperparameters&#34;&#xA;# step 1 - train dust3r for 224 resolution&#xA;torchrun --nproc_per_node=4 train.py \&#xA;    --train_dataset &#34;1000 @ Co3d(split=&#39;train&#39;, ROOT=&#39;data/co3d_subset_processed&#39;, aug_crop=16, mask_bg=&#39;rand&#39;, resolution=224, transform=ColorJitter)&#34; \&#xA;    --test_dataset &#34;100 @ Co3d(split=&#39;test&#39;, ROOT=&#39;data/co3d_subset_processed&#39;, resolution=224, seed=777)&#34; \&#xA;    --model &#34;AsymmetricCroCo3DStereo(pos_embed=&#39;RoPE100&#39;, img_size=(224, 224), head_type=&#39;linear&#39;, output_mode=&#39;pts3d&#39;, depth_mode=(&#39;exp&#39;, -inf, inf), conf_mode=(&#39;exp&#39;, 1, inf), enc_embed_dim=1024, enc_depth=24, enc_num_heads=16, dec_embed_dim=768, dec_depth=12, dec_num_heads=12)&#34; \&#xA;    --train_criterion &#34;ConfLoss(Regr3D(L21, norm_mode=&#39;avg_dis&#39;), alpha=0.2)&#34; \&#xA;    --test_criterion &#34;Regr3D_ScaleShiftInv(L21, gt_scale=True)&#34; \&#xA;    --pretrained checkpoints/CroCo_V2_ViTLarge_BaseDecoder.pth \&#xA;    --lr 0.0001 --min_lr 1e-06 --warmup_epochs 1 --epochs 10 --batch_size 16 --accum_iter 1 \&#xA;    --save_freq 1 --keep_freq 5 --eval_freq 1 \&#xA;    --output_dir checkpoints/dust3r_demo_224&#x9;  &#xA;&#xA;# step 2 - train dust3r for 512 resolution&#xA;torchrun --nproc_per_node=4 train.py \&#xA;    --train_dataset &#34;1000 @ Co3d(split=&#39;train&#39;, ROOT=&#39;data/co3d_subset_processed&#39;, aug_crop=16, mask_bg=&#39;rand&#39;, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter)&#34; \&#xA;    --test_dataset=&#34;100 @ Co3d(split=&#39;test&#39;, ROOT=&#39;data/co3d_subset_processed&#39;, resolution=(512,384), seed=777)&#34; \&#xA;    --model=&#34;AsymmetricCroCo3DStereo(pos_embed=&#39;RoPE100&#39;, patch_embed_cls=&#39;ManyAR_PatchEmbed&#39;, img_size=(512, 512), head_type=&#39;linear&#39;, output_mode=&#39;pts3d&#39;, depth_mode=(&#39;exp&#39;, -inf, inf), conf_mode=(&#39;exp&#39;, 1, inf), enc_embed_dim=1024, enc_depth=24, enc_num_heads=16, dec_embed_dim=768, dec_depth=12, dec_num_heads=12)&#34; \&#xA;    --train_criterion &#34;ConfLoss(Regr3D(L21, norm_mode=&#39;avg_dis&#39;), alpha=0.2)&#34; \&#xA;    --test_criterion &#34;Regr3D_ScaleShiftInv(L21, gt_scale=True)&#34; \&#xA;    --pretrained=&#39;checkpoints/dust3r_demo_224/checkpoint-best.pth&#39; \&#xA;    --lr=0.0001 --min_lr=1e-06 --warmup_epochs 1 --epochs 10 --batch_size 4 --accum_iter 4 \&#xA;    --save_freq 1 --keep_freq 5 --eval_freq 1 \&#xA;    --output_dir checkpoints/dust3r_demo_512&#xA;&#xA;# step 3 - train dust3r for 512 resolution with dpt&#xA;torchrun --nproc_per_node=4 train.py \&#xA;    --train_dataset &#34;1000 @ Co3d(split=&#39;train&#39;, ROOT=&#39;data/co3d_subset_processed&#39;, aug_crop=16, mask_bg=&#39;rand&#39;, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter)&#34; \&#xA;    --test_dataset=&#34;100 @ Co3d(split=&#39;test&#39;, ROOT=&#39;data/co3d_subset_processed&#39;, resolution=(512,384), seed=777)&#34; \&#xA;    --model=&#34;AsymmetricCroCo3DStereo(pos_embed=&#39;RoPE100&#39;, patch_embed_cls=&#39;ManyAR_PatchEmbed&#39;, img_size=(512, 512), head_type=&#39;dpt&#39;, output_mode=&#39;pts3d&#39;, depth_mode=(&#39;exp&#39;, -inf, inf), conf_mode=(&#39;exp&#39;, 1, inf), enc_embed_dim=1024, enc_depth=24, enc_num_heads=16, dec_embed_dim=768, dec_depth=12, dec_num_heads=12)&#34; \&#xA;    --train_criterion &#34;ConfLoss(Regr3D(L21, norm_mode=&#39;avg_dis&#39;), alpha=0.2)&#34; \&#xA;    --test_criterion &#34;Regr3D_ScaleShiftInv(L21, gt_scale=True)&#34; \&#xA;    --pretrained=&#39;checkpoints/dust3r_demo_512/checkpoint-best.pth&#39; \&#xA;    --lr=0.0001 --min_lr=1e-06 --warmup_epochs 1 --epochs 10 --batch_size 2 --accum_iter 8 \&#xA;    --save_freq 1 --keep_freq 5 --eval_freq 1 \&#xA;    --output_dir checkpoints/dust3r_demo_512dpt&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Our Hyperparameters&lt;/h3&gt; &#xA;&lt;p&gt;We didn&#39;t release the training datasets, but here are the commands we used for training our models:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# NOTE: ROOT path omitted for datasets&#xA;# 224 linear&#xA;torchrun --nproc_per_node 4 train.py \&#xA;    --train_dataset=&#34; + 100_000 @ Habitat512(1_000_000, split=&#39;train&#39;, aug_crop=16, resolution=224, transform=ColorJitter) + 100_000 @ BlendedMVS(split=&#39;train&#39;, aug_crop=16, resolution=224, transform=ColorJitter) + 100_000 @ MegaDepthDense(split=&#39;train&#39;, aug_crop=16, resolution=224, transform=ColorJitter) + 100_000 @ ARKitScenes(aug_crop=256, resolution=224, transform=ColorJitter) + 100_000 @ Co3d_v3(split=&#39;train&#39;, aug_crop=16, mask_bg=&#39;rand&#39;, resolution=224, transform=ColorJitter) + 100_000 @ StaticThings3D(aug_crop=256, mask_bg=&#39;rand&#39;, resolution=224, transform=ColorJitter) + 100_000 @ ScanNetpp(split=&#39;train&#39;, aug_crop=256, resolution=224, transform=ColorJitter) + 100_000 @ Waymo(aug_crop=128, resolution=224, transform=ColorJitter) &#34; \&#xA;    --test_dataset=&#34; Habitat512(1_000, split=&#39;val&#39;, resolution=224, seed=777) + 1_000 @ BlendedMVS(split=&#39;val&#39;, resolution=224, seed=777) + 1_000 @ MegaDepthDense(split=&#39;val&#39;, resolution=224, seed=777) + 1_000 @ Co3d_v3(split=&#39;test&#39;, mask_bg=&#39;rand&#39;, resolution=224, seed=777) &#34; \&#xA;    --train_criterion=&#34;ConfLoss(Regr3D(L21, norm_mode=&#39;avg_dis&#39;), alpha=0.2)&#34; \&#xA;    --test_criterion=&#39;Regr3D_ScaleShiftInv(L21, gt_scale=True)&#39; \&#xA;    --model=&#34;AsymmetricCroCo3DStereo(pos_embed=&#39;RoPE100&#39;, img_size=(224, 224), head_type=&#39;linear&#39;, output_mode=&#39;pts3d&#39;, depth_mode=(&#39;exp&#39;, -inf, inf), conf_mode=(&#39;exp&#39;, 1, inf), enc_embed_dim=1024, enc_depth=24, enc_num_heads=16, dec_embed_dim=768, dec_depth=12, dec_num_heads=12)&#34; \&#xA;    --pretrained=&#34;checkpoints/CroCo_V2_ViTLarge_BaseDecoder.pth&#34; \&#xA;    --lr=0.0001 --min_lr=1e-06 --warmup_epochs=10 --epochs=100 --batch_size=16 --accum_iter=1 \&#xA;    --save_freq=5 --keep_freq=10 --eval_freq=1 \&#xA;    --output_dir=&#39;checkpoints/dust3r_224&#39;&#xA;&#xA;# 512 linear&#xA;torchrun --nproc_per_node 8 train.py \&#xA;    --train_dataset=&#34; + 10_000 @ Habitat512(1_000_000, split=&#39;train&#39;, aug_crop=16, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ BlendedMVS(split=&#39;train&#39;, aug_crop=16, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ MegaDepthDense(split=&#39;train&#39;, aug_crop=16, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ ARKitScenes(aug_crop=256, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ Co3d_v3(split=&#39;train&#39;, aug_crop=16, mask_bg=&#39;rand&#39;, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ StaticThings3D(aug_crop=256, mask_bg=&#39;rand&#39;, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ ScanNetpp(split=&#39;train&#39;, aug_crop=256, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ Waymo(aug_crop=128, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) &#34; \&#xA;    --test_dataset=&#34; Habitat512(1_000, split=&#39;val&#39;, resolution=(512,384), seed=777) + 1_000 @ BlendedMVS(split=&#39;val&#39;, resolution=(512,384), seed=777) + 1_000 @ MegaDepthDense(split=&#39;val&#39;, resolution=(512,336), seed=777) + 1_000 @ Co3d_v3(split=&#39;test&#39;, resolution=(512,384), seed=777) &#34; \&#xA;    --train_criterion=&#34;ConfLoss(Regr3D(L21, norm_mode=&#39;avg_dis&#39;), alpha=0.2)&#34; \&#xA;    --test_criterion=&#39;Regr3D_ScaleShiftInv(L21, gt_scale=True)&#39; \&#xA;    --model=&#34;AsymmetricCroCo3DStereo(pos_embed=&#39;RoPE100&#39;, patch_embed_cls=&#39;ManyAR_PatchEmbed&#39;, img_size=(512, 512), head_type=&#39;linear&#39;, output_mode=&#39;pts3d&#39;, depth_mode=(&#39;exp&#39;, -inf, inf), conf_mode=(&#39;exp&#39;, 1, inf), enc_embed_dim=1024, enc_depth=24, enc_num_heads=16, dec_embed_dim=768, dec_depth=12, dec_num_heads=12)&#34; \&#xA;    --pretrained=&#39;checkpoints/dust3r_224/checkpoint-best.pth&#39; \&#xA;    --lr=0.0001 --min_lr=1e-06 --warmup_epochs=20 --epochs=200 --batch_size=4 --accum_iter=2 \&#xA;    --save_freq=10 --keep_freq=10 --eval_freq=1 --print_freq=10 \&#xA;    --output_dir=&#39;checkpoints/dust3r_512&#39;&#xA;&#xA;# 512 dpt&#xA;torchrun --nproc_per_node 8 train.py \&#xA;    --train_dataset=&#34; + 10_000 @ Habitat512(1_000_000, split=&#39;train&#39;, aug_crop=16, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ BlendedMVS(split=&#39;train&#39;, aug_crop=16, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ MegaDepthDense(split=&#39;train&#39;, aug_crop=16, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ ARKitScenes(aug_crop=256, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ Co3d_v3(split=&#39;train&#39;, aug_crop=16, mask_bg=&#39;rand&#39;, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ StaticThings3D(aug_crop=256, mask_bg=&#39;rand&#39;, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ ScanNetpp(split=&#39;train&#39;, aug_crop=256, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) + 10_000 @ Waymo(aug_crop=128, resolution=[(512, 384), (512, 336), (512, 288), (512, 256), (512, 160)], transform=ColorJitter) &#34; \&#xA;    --test_dataset=&#34; Habitat512(1_000, split=&#39;val&#39;, resolution=(512,384), seed=777) + 1_000 @ BlendedMVS(split=&#39;val&#39;, resolution=(512,384), seed=777) + 1_000 @ MegaDepthDense(split=&#39;val&#39;, resolution=(512,336), seed=777) + 1_000 @ Co3d_v3(split=&#39;test&#39;, resolution=(512,384), seed=777) &#34; \&#xA;    --train_criterion=&#34;ConfLoss(Regr3D(L21, norm_mode=&#39;avg_dis&#39;), alpha=0.2)&#34; \&#xA;    --test_criterion=&#39;Regr3D_ScaleShiftInv(L21, gt_scale=True)&#39; \&#xA;    --model=&#34;AsymmetricCroCo3DStereo(pos_embed=&#39;RoPE100&#39;, patch_embed_cls=&#39;ManyAR_PatchEmbed&#39;, img_size=(512, 512), head_type=&#39;dpt&#39;, output_mode=&#39;pts3d&#39;, depth_mode=(&#39;exp&#39;, -inf, inf), conf_mode=(&#39;exp&#39;, 1, inf), enc_embed_dim=1024, enc_depth=24, enc_num_heads=16, dec_embed_dim=768, dec_depth=12, dec_num_heads=12)&#34; \&#xA;    --pretrained=&#39;checkpoints/dust3r_512/checkpoint-best.pth&#39; \&#xA;    --lr=0.0001 --min_lr=1e-06 --warmup_epochs=15 --epochs=90 --batch_size=2 --accum_iter=4 \&#xA;    --save_freq=5 --keep_freq=10 --eval_freq=1 --print_freq=10 \&#xA;    --output_dir=&#39;checkpoints/dust3r_512dpt&#39;&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>adrianhajdin/brainwave</title>
    <updated>2024-03-04T01:23:33Z</updated>
    <id>tag:github.com,2024-03-04:/adrianhajdin/brainwave</id>
    <link href="https://github.com/adrianhajdin/brainwave" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Learn to create modern websites with sleek parallax effects and bento box layouts. This course covers everything from stylish UI design to mobile-first principles while strengthening your React.js and Tailwind CSS skills.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;a href=&#34;https://youtu.be/B91wc5dCEBA&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://i.ibb.co/Kqdv8j1/Image-from.png&#34; alt=&#34;Project Banner&#34;&gt; &lt;/a&gt; &#xA; &lt;br&gt; &#xA; &lt;div&gt; &#xA;  &lt;img src=&#34;https://img.shields.io/badge/-Vite-black?style=for-the-badge&amp;amp;logoColor=white&amp;amp;logo=vite&amp;amp;color=646CFF&#34; alt=&#34;vite&#34;&gt; &#xA;  &lt;img src=&#34;https://img.shields.io/badge/-React_JS-black?style=for-the-badge&amp;amp;logoColor=white&amp;amp;logo=react&amp;amp;color=61DAFB&#34; alt=&#34;react.js&#34;&gt; &#xA;  &lt;img src=&#34;https://img.shields.io/badge/-Tailwind_CSS-black?style=for-the-badge&amp;amp;logoColor=white&amp;amp;logo=tailwindcss&amp;amp;color=06B6D4&#34; alt=&#34;tailwindcss&#34;&gt; &#xA; &lt;/div&gt; &#xA; &lt;h3 align=&#34;center&#34;&gt;Modern UI/UX website&lt;/h3&gt; &#xA; &lt;div align=&#34;center&#34;&gt;&#xA;   Build this project step by step with our detailed tutorial on &#xA;  &lt;a href=&#34;https://www.youtube.com/@javascriptmastery/videos&#34; target=&#34;_blank&#34;&gt;&lt;b&gt;JavaScript Mastery&lt;/b&gt;&lt;/a&gt; YouTube. &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;📋 &lt;a name=&#34;table&#34;&gt;Table of Contents&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;🤖 &lt;a href=&#34;https://raw.githubusercontent.com/adrianhajdin/brainwave/main/#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;⚙️ &lt;a href=&#34;https://raw.githubusercontent.com/adrianhajdin/brainwave/main/#tech-stack&#34;&gt;Tech Stack&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;🔋 &lt;a href=&#34;https://raw.githubusercontent.com/adrianhajdin/brainwave/main/#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;🤸 &lt;a href=&#34;https://raw.githubusercontent.com/adrianhajdin/brainwave/main/#quick-start&#34;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;🕸️ &lt;a href=&#34;https://raw.githubusercontent.com/adrianhajdin/brainwave/main/#snippets&#34;&gt;Snippets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;🔗 &lt;a href=&#34;https://raw.githubusercontent.com/adrianhajdin/brainwave/main/#links&#34;&gt;Links&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;🚀 &lt;a href=&#34;https://raw.githubusercontent.com/adrianhajdin/brainwave/main/#more&#34;&gt;More&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;🚨 Tutorial&lt;/h2&gt; &#xA;&lt;p&gt;This repository contains the code corresponding to an in-depth tutorial available on our YouTube channel, &lt;a href=&#34;https://www.youtube.com/@javascriptmastery/videos&#34; target=&#34;_blank&#34;&gt;&lt;b&gt;JavaScript Mastery&lt;/b&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you prefer visual learning, this is the perfect resource for you. Follow our tutorial to learn how to build projects like these step-by-step in a beginner-friendly manner!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/B91wc5dCEBA&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/sujatagunale/EasyRead/assets/151519281/1736fca5-a031-4854-8c09-bc110e3bc16d&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;introduction&#34;&gt;🤖 Introduction&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Brainwave - Modern UI/UX website, developed using React.js and Tailwind CSS, exemplifies modern UI/UX principles. Its sleek design, seamless animations, and overall user experience set a high standard, serving as a reference or inspiration for future modern applications or websites in general.&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re getting started and need assistance or face any bugs, join our active Discord community with over 27k+ members. It&#39;s a place where people help each other out.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.com/invite/n6EdbFJ&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/sujatagunale/EasyRead/assets/151519281/618f4872-1e10-42da-8213-1d69e486d02e&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;tech-stack&#34;&gt;⚙️ Tech Stack&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Vite&lt;/li&gt; &#xA; &lt;li&gt;React.js&lt;/li&gt; &#xA; &lt;li&gt;Tailwind CSS&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;features&#34;&gt;🔋 Features&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;👉 &lt;strong&gt;Beautiful Sections&lt;/strong&gt;: Includes hero, services, features, how to use, roadmap, pricing, footer, and header.&lt;/p&gt; &#xA;&lt;p&gt;👉 &lt;strong&gt;Parallax Animations&lt;/strong&gt;: Engaging effects triggered by mouse movement and scrolling&lt;/p&gt; &#xA;&lt;p&gt;👉 &lt;strong&gt;Complex UI Geometry&lt;/strong&gt;: Utilizes tailwindcss for intricate shapes like circular feature displays, grid lines, and side lines.&lt;/p&gt; &#xA;&lt;p&gt;👉 &lt;strong&gt;Latest UI Trends&lt;/strong&gt;: Incorporates modern design elements such as bento grids.&lt;/p&gt; &#xA;&lt;p&gt;👉 &lt;strong&gt;Cool Gradients&lt;/strong&gt;: Enhances visuals with stylish gradients using Tailwind CSS for cards, buttons, etc.&lt;/p&gt; &#xA;&lt;p&gt;👉 &lt;strong&gt;Responsive&lt;/strong&gt;: Ensures seamless functionality and aesthetics across all devices&lt;/p&gt; &#xA;&lt;p&gt;and many more, including code architecture and reusability&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;quick-start&#34;&gt;🤸 Quick Start&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Follow these steps to set up the project locally on your machine.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Make sure you have the following installed on your machine:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://git-scm.com/&#34;&gt;Git&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nodejs.org/en&#34;&gt;Node.js&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.npmjs.com/&#34;&gt;npm&lt;/a&gt; (Node Package Manager)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Cloning the Repository&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/JavaScript-Mastery-Pro/brainwave.git&#xA;cd brainwave&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Install the project dependencies using npm:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Running the Project&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open &lt;a href=&#34;http://localhost:5173&#34;&gt;http://localhost:5173&lt;/a&gt; in your browser to view the project.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;snippets&#34;&gt;🕸️ Snippets&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;code&gt;.vscode/settings.json&lt;/code&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;editor.defaultFormatter&#34;: &#34;esbenp.prettier-vscode&#34;,&#xA;  &#34;editor.formatOnSave&#34;: true,&#xA;  &#34;editor.codeActionsOnSave&#34;: {&#xA;    &#34;source.fixAll.eslint&#34;: &#34;explicit&#34;,&#xA;    &#34;source.addMissingImports&#34;: &#34;explicit&#34;&#xA;  },&#xA;  &#34;prettier.tabWidth&#34;: 2,&#xA;  &#34;prettier.useTabs&#34;: false,&#xA;  &#34;prettier.semi&#34;: true,&#xA;  &#34;prettier.singleQuote&#34;: false,&#xA;  &#34;prettier.jsxSingleQuote&#34;: false,&#xA;  &#34;prettier.trailingComma&#34;: &#34;es5&#34;,&#xA;  &#34;prettier.arrowParens&#34;: &#34;always&#34;,&#xA;  &#34;[javascriptreact]&#34;: {&#xA;    &#34;editor.defaultFormatter&#34;: &#34;esbenp.prettier-vscode&#34;&#xA;  },&#xA;  &#34;[css]&#34;: {&#xA;    &#34;editor.defaultFormatter&#34;: &#34;vscode.css-language-features&#34;&#xA;  },&#xA;  &#34;[svg]&#34;: {&#xA;    &#34;editor.defaultFormatter&#34;: &#34;jock.svg&#34;&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;code&gt;tailwind.config.js&lt;/code&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;/** @type {import(&#39;tailwindcss&#39;).Config} */&#xA;import { fontFamily } from &#34;tailwindcss/defaultTheme&#34;;&#xA;import plugin from &#34;tailwindcss/plugin&#34;;&#xA;&#xA;export default {&#xA;  content: [&#xA;    &#34;./index.html&#34;,&#xA;    &#34;./src/**/*.{js,ts,jsx,tsx}&#34;,&#xA;    &#34;./public/assets/**/*.{js,ts,jsx,tsx}&#34;,&#xA;  ],&#xA;  theme: {&#xA;    extend: {&#xA;      colors: {&#xA;        color: {&#xA;          1: &#34;#AC6AFF&#34;,&#xA;          2: &#34;#FFC876&#34;,&#xA;          3: &#34;#FF776F&#34;,&#xA;          4: &#34;#7ADB78&#34;,&#xA;          5: &#34;#858DFF&#34;,&#xA;          6: &#34;#FF98E2&#34;,&#xA;        },&#xA;        stroke: {&#xA;          1: &#34;#26242C&#34;,&#xA;        },&#xA;        n: {&#xA;          1: &#34;#FFFFFF&#34;,&#xA;          2: &#34;#CAC6DD&#34;,&#xA;          3: &#34;#ADA8C3&#34;,&#xA;          4: &#34;#757185&#34;,&#xA;          5: &#34;#3F3A52&#34;,&#xA;          6: &#34;#252134&#34;,&#xA;          7: &#34;#15131D&#34;,&#xA;          8: &#34;#0E0C15&#34;,&#xA;          9: &#34;#474060&#34;,&#xA;          10: &#34;#43435C&#34;,&#xA;          11: &#34;#1B1B2E&#34;,&#xA;          12: &#34;#2E2A41&#34;,&#xA;          13: &#34;#6C7275&#34;,&#xA;        },&#xA;      },&#xA;      fontFamily: {&#xA;        sans: [&#34;var(--font-sora)&#34;, ...fontFamily.sans],&#xA;        code: &#34;var(--font-code)&#34;,&#xA;        grotesk: &#34;var(--font-grotesk)&#34;,&#xA;      },&#xA;      letterSpacing: {&#xA;        tagline: &#34;.15em&#34;,&#xA;      },&#xA;      spacing: {&#xA;        0.25: &#34;0.0625rem&#34;,&#xA;        7.5: &#34;1.875rem&#34;,&#xA;        15: &#34;3.75rem&#34;,&#xA;      },&#xA;      opacity: {&#xA;        15: &#34;.15&#34;,&#xA;      },&#xA;      transitionDuration: {&#xA;        DEFAULT: &#34;200ms&#34;,&#xA;      },&#xA;      transitionTimingFunction: {&#xA;        DEFAULT: &#34;linear&#34;,&#xA;      },&#xA;      zIndex: {&#xA;        1: &#34;1&#34;,&#xA;        2: &#34;2&#34;,&#xA;        3: &#34;3&#34;,&#xA;        4: &#34;4&#34;,&#xA;        5: &#34;5&#34;,&#xA;      },&#xA;      borderWidth: {&#xA;        DEFAULT: &#34;0.0625rem&#34;,&#xA;      },&#xA;      backgroundImage: {&#xA;        &#34;radial-gradient&#34;: &#34;radial-gradient(var(--tw-gradient-stops))&#34;,&#xA;        &#34;conic-gradient&#34;:&#xA;          &#34;conic-gradient(from 225deg, #FFC876, #79FFF7, #9F53FF, #FF98E2, #FFC876)&#34;,&#xA;        &#34;benefit-card-1&#34;: &#34;url(assets/benefits/card-1.svg)&#34;,&#xA;        &#34;benefit-card-2&#34;: &#34;url(assets/benefits/card-2.svg)&#34;,&#xA;        &#34;benefit-card-3&#34;: &#34;url(assets/benefits/card-3.svg)&#34;,&#xA;        &#34;benefit-card-4&#34;: &#34;url(assets/benefits/card-4.svg)&#34;,&#xA;        &#34;benefit-card-5&#34;: &#34;url(assets/benefits/card-5.svg)&#34;,&#xA;        &#34;benefit-card-6&#34;: &#34;url(assets/benefits/card-6.svg)&#34;,&#xA;      },&#xA;    },&#xA;  },&#xA;  plugins: [&#xA;    plugin(function ({ addBase, addComponents, addUtilities }) {&#xA;      addBase({});&#xA;      addComponents({&#xA;        &#34;.container&#34;: {&#xA;          &#34;@apply max-w-[77.5rem] mx-auto px-5 md:px-10 lg:px-15 xl:max-w-[87.5rem]&#34;:&#xA;            {},&#xA;        },&#xA;        &#34;.h1&#34;: {&#xA;          &#34;@apply font-semibold text-[2.5rem] leading-[3.25rem] md:text-[2.75rem] md:leading-[3.75rem] lg:text-[3.25rem] lg:leading-[4.0625rem] xl:text-[3.75rem] xl:leading-[4.5rem]&#34;:&#xA;            {},&#xA;        },&#xA;        &#34;.h2&#34;: {&#xA;          &#34;@apply text-[1.75rem] leading-[2.5rem] md:text-[2rem] md:leading-[2.5rem] lg:text-[2.5rem] lg:leading-[3.5rem] xl:text-[3rem] xl:leading-tight&#34;:&#xA;            {},&#xA;        },&#xA;        &#34;.h3&#34;: {&#xA;          &#34;@apply text-[2rem] leading-normal md:text-[2.5rem]&#34;: {},&#xA;        },&#xA;        &#34;.h4&#34;: {&#xA;          &#34;@apply text-[2rem] leading-normal&#34;: {},&#xA;        },&#xA;        &#34;.h5&#34;: {&#xA;          &#34;@apply text-2xl leading-normal&#34;: {},&#xA;        },&#xA;        &#34;.h6&#34;: {&#xA;          &#34;@apply font-semibold text-lg leading-8&#34;: {},&#xA;        },&#xA;        &#34;.body-1&#34;: {&#xA;          &#34;@apply text-[0.875rem] leading-[1.5rem] md:text-[1rem] md:leading-[1.75rem] lg:text-[1.25rem] lg:leading-8&#34;:&#xA;            {},&#xA;        },&#xA;        &#34;.body-2&#34;: {&#xA;          &#34;@apply font-light text-[0.875rem] leading-6 md:text-base&#34;: {},&#xA;        },&#xA;        &#34;.caption&#34;: {&#xA;          &#34;@apply text-sm&#34;: {},&#xA;        },&#xA;        &#34;.tagline&#34;: {&#xA;          &#34;@apply font-grotesk font-light text-xs tracking-tagline uppercase&#34;:&#xA;            {},&#xA;        },&#xA;        &#34;.quote&#34;: {&#xA;          &#34;@apply font-code text-lg leading-normal&#34;: {},&#xA;        },&#xA;        &#34;.button&#34;: {&#xA;          &#34;@apply font-code text-xs font-bold uppercase tracking-wider&#34;: {},&#xA;        },&#xA;      });&#xA;      addUtilities({&#xA;        &#34;.tap-highlight-color&#34;: {&#xA;          &#34;-webkit-tap-highlight-color&#34;: &#34;rgba(0, 0, 0, 0)&#34;,&#xA;        },&#xA;      });&#xA;    }),&#xA;  ],&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;code&gt;index.css&lt;/code&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;@import url(&#34;https://fonts.googleapis.com/css2?family=Sora:wght@300;400;600&amp;amp;display=swap&#34;);&#xA;@import url(&#34;https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@400;600;700&amp;amp;display=swap&#34;);&#xA;@import url(&#34;https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@300&amp;amp;display=swap&#34;);&#xA;&#xA;@tailwind base;&#xA;@tailwind components;&#xA;@tailwind utilities;&#xA;&#xA;:root {&#xA;  --font-sora: &#34;Sora&#34;, sans-serif;&#xA;  --font-code: &#34;Source Code Pro&#34;, monospace;&#xA;  --font-grotesk: &#34;Space Grotesk&#34;, sans-serif;&#xA;}&#xA;&#xA;* {&#xA;  scroll-behavior: smooth;&#xA;}&#xA;&#xA;@layer base {&#xA;  body {&#xA;    @apply font-sans bg-n-8 text-n-1 text-base;&#xA;  }&#xA;}&#xA;&#xA;.rotate-45 {&#xA;  @apply rotate-[45deg];&#xA;}&#xA;&#xA;.rotate-90 {&#xA;  @apply rotate-[90deg];&#xA;}&#xA;&#xA;.rotate-135 {&#xA;  @apply rotate-[135deg];&#xA;}&#xA;&#xA;.rotate-180 {&#xA;  @apply rotate-[180deg];&#xA;}&#xA;&#xA;.rotate-225 {&#xA;  @apply rotate-[225deg];&#xA;}&#xA;&#xA;.rotate-270 {&#xA;  @apply rotate-[270deg];&#xA;}&#xA;&#xA;.rotate-315 {&#xA;  @apply rotate-[315deg];&#xA;}&#xA;&#xA;.rotate-360 {&#xA;  @apply rotate-[360deg];&#xA;}&#xA;&#xA;.-rotate-45 {&#xA;  @apply rotate-[-45deg];&#xA;}&#xA;&#xA;.-rotate-90 {&#xA;  @apply rotate-[-90deg];&#xA;}&#xA;&#xA;.-rotate-135 {&#xA;  @apply rotate-[-135deg];&#xA;}&#xA;&#xA;.-rotate-180 {&#xA;  @apply rotate-[-180deg];&#xA;}&#xA;&#xA;.-rotate-225 {&#xA;  @apply rotate-[-225deg];&#xA;}&#xA;&#xA;.-rotate-270 {&#xA;  @apply rotate-[-270deg];&#xA;}&#xA;&#xA;.-rotate-315 {&#xA;  @apply rotate-[-315deg];&#xA;}&#xA;&#xA;.-rotate-360 {&#xA;  @apply rotate-[-360deg];&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;code&gt;constants/index.js&lt;/code&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import {&#xA;  benefitIcon1,&#xA;  benefitIcon2,&#xA;  benefitIcon3,&#xA;  benefitIcon4,&#xA;  benefitImage2,&#xA;  chromecast,&#xA;  disc02,&#xA;  discord,&#xA;  discordBlack,&#xA;  facebook,&#xA;  figma,&#xA;  file02,&#xA;  framer,&#xA;  homeSmile,&#xA;  instagram,&#xA;  notification2,&#xA;  notification3,&#xA;  notification4,&#xA;  notion,&#xA;  photoshop,&#xA;  plusSquare,&#xA;  protopie,&#xA;  raindrop,&#xA;  recording01,&#xA;  recording03,&#xA;  roadmap1,&#xA;  roadmap2,&#xA;  roadmap3,&#xA;  roadmap4,&#xA;  searchMd,&#xA;  slack,&#xA;  sliders04,&#xA;  telegram,&#xA;  twitter,&#xA;  yourlogo,&#xA;} from &#34;../../public/assets&#34;;&#xA;&#xA;export const navigation = [&#xA;  {&#xA;    id: &#34;0&#34;,&#xA;    title: &#34;Features&#34;,&#xA;    url: &#34;#features&#34;,&#xA;  },&#xA;  {&#xA;    id: &#34;1&#34;,&#xA;    title: &#34;Pricing&#34;,&#xA;    url: &#34;#pricing&#34;,&#xA;  },&#xA;  {&#xA;    id: &#34;2&#34;,&#xA;    title: &#34;How to use&#34;,&#xA;    url: &#34;#how-to-use&#34;,&#xA;  },&#xA;  {&#xA;    id: &#34;3&#34;,&#xA;    title: &#34;Roadmap&#34;,&#xA;    url: &#34;#roadmap&#34;,&#xA;  },&#xA;  {&#xA;    id: &#34;4&#34;,&#xA;    title: &#34;New account&#34;,&#xA;    url: &#34;#signup&#34;,&#xA;    onlyMobile: true,&#xA;  },&#xA;  {&#xA;    id: &#34;5&#34;,&#xA;    title: &#34;Sign in&#34;,&#xA;    url: &#34;#login&#34;,&#xA;    onlyMobile: true,&#xA;  },&#xA;];&#xA;&#xA;export const heroIcons = [homeSmile, file02, searchMd, plusSquare];&#xA;&#xA;export const notificationImages = [notification4, notification3, notification2];&#xA;&#xA;export const companyLogos = [yourlogo, yourlogo, yourlogo, yourlogo, yourlogo];&#xA;&#xA;export const brainwaveServices = [&#xA;  &#34;Photo generating&#34;,&#xA;  &#34;Photo enhance&#34;,&#xA;  &#34;Seamless Integration&#34;,&#xA;];&#xA;&#xA;export const brainwaveServicesIcons = [&#xA;  recording03,&#xA;  recording01,&#xA;  disc02,&#xA;  chromecast,&#xA;  sliders04,&#xA;];&#xA;&#xA;export const roadmap = [&#xA;  {&#xA;    id: &#34;0&#34;,&#xA;    title: &#34;Voice recognition&#34;,&#xA;    text: &#34;Enable the chatbot to understand and respond to voice commands, making it easier for users to interact with the app hands-free.&#34;,&#xA;    date: &#34;May 2023&#34;,&#xA;    status: &#34;done&#34;,&#xA;    imageUrl: roadmap1,&#xA;    colorful: true,&#xA;  },&#xA;  {&#xA;    id: &#34;1&#34;,&#xA;    title: &#34;Gamification&#34;,&#xA;    text: &#34;Add game-like elements, such as badges or leaderboards, to incentivize users to engage with the chatbot more frequently.&#34;,&#xA;    date: &#34;May 2023&#34;,&#xA;    status: &#34;progress&#34;,&#xA;    imageUrl: roadmap2,&#xA;  },&#xA;  {&#xA;    id: &#34;2&#34;,&#xA;    title: &#34;Chatbot customization&#34;,&#xA;    text: &#34;Allow users to customize the chatbot&#39;s appearance and behavior, making it more engaging and fun to interact with.&#34;,&#xA;    date: &#34;May 2023&#34;,&#xA;    status: &#34;done&#34;,&#xA;    imageUrl: roadmap3,&#xA;  },&#xA;  {&#xA;    id: &#34;3&#34;,&#xA;    title: &#34;Integration with APIs&#34;,&#xA;    text: &#34;Allow the chatbot to access external data sources, such as weather APIs or news APIs, to provide more relevant recommendations.&#34;,&#xA;    date: &#34;May 2023&#34;,&#xA;    status: &#34;progress&#34;,&#xA;    imageUrl: roadmap4,&#xA;  },&#xA;];&#xA;&#xA;export const collabText =&#xA;  &#34;With smart automation and top-notch security, it&#39;s the perfect solution for teams looking to work smarter.&#34;;&#xA;&#xA;export const collabContent = [&#xA;  {&#xA;    id: &#34;0&#34;,&#xA;    title: &#34;Seamless Integration&#34;,&#xA;    text: collabText,&#xA;  },&#xA;  {&#xA;    id: &#34;1&#34;,&#xA;    title: &#34;Smart Automation&#34;,&#xA;  },&#xA;  {&#xA;    id: &#34;2&#34;,&#xA;    title: &#34;Top-notch Security&#34;,&#xA;  },&#xA;];&#xA;&#xA;export const collabApps = [&#xA;  {&#xA;    id: &#34;0&#34;,&#xA;    title: &#34;Figma&#34;,&#xA;    icon: figma,&#xA;    width: 26,&#xA;    height: 36,&#xA;  },&#xA;  {&#xA;    id: &#34;1&#34;,&#xA;    title: &#34;Notion&#34;,&#xA;    icon: notion,&#xA;    width: 34,&#xA;    height: 36,&#xA;  },&#xA;  {&#xA;    id: &#34;2&#34;,&#xA;    title: &#34;Discord&#34;,&#xA;    icon: discord,&#xA;    width: 36,&#xA;    height: 28,&#xA;  },&#xA;  {&#xA;    id: &#34;3&#34;,&#xA;    title: &#34;Slack&#34;,&#xA;    icon: slack,&#xA;    width: 34,&#xA;    height: 35,&#xA;  },&#xA;  {&#xA;    id: &#34;4&#34;,&#xA;    title: &#34;Photoshop&#34;,&#xA;    icon: photoshop,&#xA;    width: 34,&#xA;    height: 34,&#xA;  },&#xA;  {&#xA;    id: &#34;5&#34;,&#xA;    title: &#34;Protopie&#34;,&#xA;    icon: protopie,&#xA;    width: 34,&#xA;    height: 34,&#xA;  },&#xA;  {&#xA;    id: &#34;6&#34;,&#xA;    title: &#34;Framer&#34;,&#xA;    icon: framer,&#xA;    width: 26,&#xA;    height: 34,&#xA;  },&#xA;  {&#xA;    id: &#34;7&#34;,&#xA;    title: &#34;Raindrop&#34;,&#xA;    icon: raindrop,&#xA;    width: 38,&#xA;    height: 32,&#xA;  },&#xA;];&#xA;&#xA;export const pricing = [&#xA;  {&#xA;    id: &#34;0&#34;,&#xA;    title: &#34;Basic&#34;,&#xA;    description: &#34;AI chatbot, personalized recommendations&#34;,&#xA;    price: &#34;0&#34;,&#xA;    features: [&#xA;      &#34;An AI chatbot that can understand your queries&#34;,&#xA;      &#34;Personalized recommendations based on your preferences&#34;,&#xA;      &#34;Ability to explore the app and its features without any cost&#34;,&#xA;    ],&#xA;  },&#xA;  {&#xA;    id: &#34;1&#34;,&#xA;    title: &#34;Premium&#34;,&#xA;    description: &#34;Advanced AI chatbot, priority support, analytics dashboard&#34;,&#xA;    price: &#34;9.99&#34;,&#xA;    features: [&#xA;      &#34;An advanced AI chatbot that can understand complex queries&#34;,&#xA;      &#34;An analytics dashboard to track your conversations&#34;,&#xA;      &#34;Priority support to solve issues quickly&#34;,&#xA;    ],&#xA;  },&#xA;  {&#xA;    id: &#34;2&#34;,&#xA;    title: &#34;Enterprise&#34;,&#xA;    description: &#34;Custom AI chatbot, advanced analytics, dedicated account&#34;,&#xA;    price: null,&#xA;    features: [&#xA;      &#34;An AI chatbot that can understand your queries&#34;,&#xA;      &#34;Personalized recommendations based on your preferences&#34;,&#xA;      &#34;Ability to explore the app and its features without any cost&#34;,&#xA;    ],&#xA;  },&#xA;];&#xA;&#xA;export const benefits = [&#xA;  {&#xA;    id: &#34;0&#34;,&#xA;    title: &#34;Ask anything&#34;,&#xA;    text: &#34;Lets users quickly find answers to their questions without having to search through multiple sources.&#34;,&#xA;    backgroundUrl: &#34;assets/benefits/card-1.svg&#34;,&#xA;    iconUrl: benefitIcon1,&#xA;    imageUrl: benefitImage2,&#xA;  },&#xA;  {&#xA;    id: &#34;1&#34;,&#xA;    title: &#34;Improve everyday&#34;,&#xA;    text: &#34;The app uses natural language processing to understand user queries and provide accurate and relevant responses.&#34;,&#xA;    backgroundUrl: &#34;assets/benefits/card-2.svg&#34;,&#xA;    iconUrl: benefitIcon2,&#xA;    imageUrl: benefitImage2,&#xA;    light: true,&#xA;  },&#xA;  {&#xA;    id: &#34;2&#34;,&#xA;    title: &#34;Connect everywhere&#34;,&#xA;    text: &#34;Connect with the AI chatbot from anywhere, on any device, making it more accessible and convenient.&#34;,&#xA;    backgroundUrl: &#34;assets/benefits/card-3.svg&#34;,&#xA;    iconUrl: benefitIcon3,&#xA;    imageUrl: benefitImage2,&#xA;  },&#xA;  {&#xA;    id: &#34;3&#34;,&#xA;    title: &#34;Fast responding&#34;,&#xA;    text: &#34;Lets users quickly find answers to their questions without having to search through multiple sources.&#34;,&#xA;    backgroundUrl: &#34;assets/benefits/card-4.svg&#34;,&#xA;    iconUrl: benefitIcon4,&#xA;    imageUrl: benefitImage2,&#xA;    light: true,&#xA;  },&#xA;  {&#xA;    id: &#34;4&#34;,&#xA;    title: &#34;Ask anything&#34;,&#xA;    text: &#34;Lets users quickly find answers to their questions without having to search through multiple sources.&#34;,&#xA;    backgroundUrl: &#34;assets/benefits/card-5.svg&#34;,&#xA;    iconUrl: benefitIcon1,&#xA;    imageUrl: benefitImage2,&#xA;  },&#xA;  {&#xA;    id: &#34;5&#34;,&#xA;    title: &#34;Improve everyday&#34;,&#xA;    text: &#34;The app uses natural language processing to understand user queries and provide accurate and relevant responses.&#34;,&#xA;    backgroundUrl: &#34;assets/benefits/card-6.svg&#34;,&#xA;    iconUrl: benefitIcon2,&#xA;    imageUrl: benefitImage2,&#xA;  },&#xA;];&#xA;&#xA;export const socials = [&#xA;  {&#xA;    id: &#34;0&#34;,&#xA;    title: &#34;Discord&#34;,&#xA;    iconUrl: discordBlack,&#xA;    url: &#34;#&#34;,&#xA;  },&#xA;  {&#xA;    id: &#34;1&#34;,&#xA;    title: &#34;Twitter&#34;,&#xA;    iconUrl: twitter,&#xA;    url: &#34;#&#34;,&#xA;  },&#xA;  {&#xA;    id: &#34;2&#34;,&#xA;    title: &#34;Instagram&#34;,&#xA;    iconUrl: instagram,&#xA;    url: &#34;#&#34;,&#xA;  },&#xA;  {&#xA;    id: &#34;3&#34;,&#xA;    title: &#34;Telegram&#34;,&#xA;    iconUrl: telegram,&#xA;    url: &#34;#&#34;,&#xA;  },&#xA;  {&#xA;    id: &#34;4&#34;,&#xA;    title: &#34;Facebook&#34;,&#xA;    iconUrl: facebook,&#xA;    url: &#34;#&#34;,&#xA;  },&#xA;];&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;code&gt;components/Section.jsx&lt;/code&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import SectionSvg from &#34;../../public/assets/svg/SectionSvg&#34;;&#xA;&#xA;const Section = ({&#xA;  className,&#xA;  id,&#xA;  crosses,&#xA;  crossesOffset,&#xA;  customPaddings,&#xA;  children,&#xA;}) =&amp;gt; (&#xA;  &amp;lt;div&#xA;    id={id}&#xA;    className={`relative &#xA;    ${&#xA;      customPaddings ||&#xA;      `py-10 lg:py-16 xl:py-20 ${crosses ? &#34;lg:py-32 xl:py-40&#34; : &#34;&#34;}`&#xA;    } ${className || &#34;&#34;}`}&#xA;  &amp;gt;&#xA;    {children}&#xA;&#xA;    &amp;lt;div className=&#34;hidden absolute top-0 left-5 w-0.25 h-full bg-stroke-1 pointer-events-none md:block lg:left-7.5 xl:left-10&#34; /&amp;gt;&#xA;    &amp;lt;div className=&#34;hidden absolute top-0 right-5 w-0.25 h-full bg-stroke-1 pointer-events-none md:block lg:right-7.5 xl:right-10&#34; /&amp;gt;&#xA;&#xA;    {crosses &amp;amp;&amp;amp; (&#xA;      &amp;lt;&amp;gt;&#xA;        &amp;lt;div&#xA;          className={`hidden absolute top-0 left-7.5 right-7.5 h-0.25 bg-stroke-1 ${&#xA;            crossesOffset &amp;amp;&amp;amp; crossesOffset&#xA;          } pointer-events-none lg:block xl:left-10 right-10`}&#xA;        /&amp;gt;&#xA;        &amp;lt;SectionSvg crossesOffset={crossesOffset} /&amp;gt;&#xA;      &amp;lt;/&amp;gt;&#xA;    )}&#xA;  &amp;lt;/div&amp;gt;&#xA;);&#xA;&#xA;export default Section;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;code&gt;components/Roadmap.jsx&lt;/code&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;import Button from &#34;./Button&#34;;&#xA;import Heading from &#34;./Heading&#34;;&#xA;import Section from &#34;./Section&#34;;&#xA;import Tagline from &#34;./TagLine&#34;;&#xA;import { roadmap } from &#34;../constants&#34;;&#xA;import { check2, grid, loading1 } from &#34;../../public/assets&#34;;&#xA;import { Gradient } from &#34;./design/Roadmap&#34;;&#xA;&#xA;const Roadmap = () =&amp;gt; (&#xA;  &amp;lt;Section className=&#34;overflow-hidden&#34; id=&#34;roadmap&#34;&amp;gt;&#xA;    &amp;lt;div className=&#34;container md:pb-10&#34;&amp;gt;&#xA;      &amp;lt;Heading tag=&#34;Ready to get started&#34; title=&#34;What we’re working on&#34; /&amp;gt;&#xA;&#xA;      &amp;lt;div className=&#34;relative grid gap-6 md:grid-cols-2 md:gap-4 md:pb-[7rem]&#34;&amp;gt;&#xA;        {roadmap.map((item) =&amp;gt; {&#xA;          const status = item.status === &#34;done&#34; ? &#34;Done&#34; : &#34;In progress&#34;;&#xA;&#xA;          return (&#xA;            &amp;lt;div&#xA;              className={`md:flex even:md:translate-y-[7rem] p-0.25 rounded-[2.5rem] ${&#xA;                item.colorful ? &#34;bg-conic-gradient&#34; : &#34;bg-n-6&#34;&#xA;              }`}&#xA;              key={item.id}&#xA;            &amp;gt;&#xA;              &amp;lt;div className=&#34;relative p-8 bg-n-8 rounded-[2.4375rem] overflow-hidden xl:p-15&#34;&amp;gt;&#xA;                &amp;lt;div className=&#34;absolute top-0 left-0 max-w-full&#34;&amp;gt;&#xA;                  &amp;lt;img&#xA;                    className=&#34;w-full&#34;&#xA;                    src={grid}&#xA;                    width={550}&#xA;                    height={550}&#xA;                    alt=&#34;Grid&#34;&#xA;                  /&amp;gt;&#xA;                &amp;lt;/div&amp;gt;&#xA;                &amp;lt;div className=&#34;relative z-1&#34;&amp;gt;&#xA;                  &amp;lt;div className=&#34;flex items-center justify-between max-w-[27rem] mb-8 md:mb-20&#34;&amp;gt;&#xA;                    &amp;lt;Tagline&amp;gt;{item.date}&amp;lt;/Tagline&amp;gt;&#xA;&#xA;                    &amp;lt;div className=&#34;flex items-center px-4 py-1 bg-n-1 rounded text-n-8&#34;&amp;gt;&#xA;                      &amp;lt;img&#xA;                        className=&#34;mr-2.5&#34;&#xA;                        src={item.status === &#34;done&#34; ? check2 : loading1}&#xA;                        width={16}&#xA;                        height={16}&#xA;                        alt={status}&#xA;                      /&amp;gt;&#xA;                      &amp;lt;div className=&#34;tagline&#34;&amp;gt;{status}&amp;lt;/div&amp;gt;&#xA;                    &amp;lt;/div&amp;gt;&#xA;                  &amp;lt;/div&amp;gt;&#xA;&#xA;                  &amp;lt;div className=&#34;mb-10 -my-10 -mx-15&#34;&amp;gt;&#xA;                    &amp;lt;img&#xA;                      className=&#34;w-full&#34;&#xA;                      src={item.imageUrl}&#xA;                      width={628}&#xA;                      height={426}&#xA;                      alt={item.title}&#xA;                    /&amp;gt;&#xA;                  &amp;lt;/div&amp;gt;&#xA;                  &amp;lt;h4 className=&#34;h4 mb-4&#34;&amp;gt;{item.title}&amp;lt;/h4&amp;gt;&#xA;                  &amp;lt;p className=&#34;body-2 text-n-4&#34;&amp;gt;{item.text}&amp;lt;/p&amp;gt;&#xA;                &amp;lt;/div&amp;gt;&#xA;              &amp;lt;/div&amp;gt;&#xA;            &amp;lt;/div&amp;gt;&#xA;          );&#xA;        })}&#xA;&#xA;        &amp;lt;Gradient /&amp;gt;&#xA;      &amp;lt;/div&amp;gt;&#xA;&#xA;      &amp;lt;div className=&#34;flex justify-center mt-12 md:mt-15 xl:mt-20&#34;&amp;gt;&#xA;        &amp;lt;Button href=&#34;/roadmap&#34;&amp;gt;Our roadmap&amp;lt;/Button&amp;gt;&#xA;      &amp;lt;/div&amp;gt;&#xA;    &amp;lt;/div&amp;gt;&#xA;  &amp;lt;/Section&amp;gt;&#xA;);&#xA;&#xA;export default Roadmap;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;links&#34;&gt;🔗 Links&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://drive.google.com/file/d/1JKzwPl_hnpjIlNbwfjMagb4HosxnyXbf/view?usp=sharing&#34;&gt;Assets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://drive.google.com/file/d/15WJMOchujvaQ7Kg9e0nGeGR7G7JOeX1K/view?usp=sharing&#34;&gt;Design&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://css-tricks.com/absolute-positioning-inside-relative-positioning/&#34;&gt;Absolute Relative Positioning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jsm-brainwave.com/&#34;&gt;Live Website&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;more&#34;&gt;🚀 More&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Advance your skills with Next.js 14 Pro Course&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Enjoyed creating this project? Dive deeper into our PRO courses for a richer learning adventure. They&#39;re packed with detailed explanations, cool features, and exercises to boost your skills. Give it a go!&lt;/p&gt; &#xA;&lt;a href=&#34;https://jsmastery.pro/next14&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://github.com/sujatagunale/EasyRead/assets/151519281/557837ce-f612-4530-ab24-189e75133c71&#34; alt=&#34;Project Banner&#34;&gt; &lt;/a&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;strong&gt;Accelerate your professional journey with the Expert Training program&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;And if you&#39;re hungry for more than just a course and want to understand how we learn and tackle tech challenges, hop into our personalized masterclass. We cover best practices, different web skills, and offer mentorship to boost your confidence. Let&#39;s learn and grow together!&lt;/p&gt; &#xA;&lt;a href=&#34;https://www.jsmastery.pro/masterclass&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://github.com/sujatagunale/EasyRead/assets/151519281/fed352ad-f27b-400d-9b8f-c7fe628acb84&#34; alt=&#34;Project Banner&#34;&gt; &lt;/a&gt; &#xA;&lt;h1&gt;&lt;/h1&gt;</summary>
  </entry>
</feed>