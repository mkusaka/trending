<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-06-08T01:29:27Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>codexu/note-gen</title>
    <updated>2025-06-08T01:29:27Z</updated>
    <id>tag:github.com,2025-06-08:/codexu/note-gen</id>
    <link href="https://github.com/codexu/note-gen" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A cross-platform Markdown note-taking application dedicated to using AI to bridge recording and writing, organizing fragmented knowledge into a readable note.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://socialify.git.ci/codexu/note-gen/image?custom_description=Cross-Platform+%7C+LLM+%7C+Markdown+%7C++Recording++%26+Writing&amp;amp;description=1&amp;amp;font=Raleway&amp;amp;forks=1&amp;amp;issues=1&amp;amp;logo=https%3A%2F%2Fcamo.githubusercontent.com%2Fbe4a3a39f8724658ad5bc549d63f0454ad4ca98564c73b7b0778704ca5212509%2F68747470733a2f2f73322e6c6f6c692e6e65742f323032352f30352f32362f594d4e67784b5644724238345a74572e706e67&amp;amp;name=1&amp;amp;owner=1&amp;amp;pattern=Circuit+Board&amp;amp;stargazers=1&amp;amp;theme=Light&#34; alt=&#34;note-gen&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;NoteGen&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/codexu/note-gen/actions/workflows/release.yml/badge.svg?branch=release&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/v/release/codexu/note-gen&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/version-alpha-orange&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/downloads/codexu/note-gen/total&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/commit-activity/m/codexu/note-gen&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/codexu/note-gen/dev/.github/README.zh.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/codexu/note-gen/dev/.github/README.ja.md&#34;&gt;Êó•Êú¨Ë™û&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div style=&#34;display: flex; gap: 1rem;&#34;&gt; &#xA; &lt;a href=&#34;https://www.producthunt.com/products/notegen-2?embed=true&amp;amp;utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_source=badge-notegen-2&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=956348&amp;amp;theme=light&amp;amp;t=1749194675492&#34; alt=&#34;NoteGen - A cross-platform Markdown note-taking application | Product Hunt&#34; style=&#34;width: 250px; height: 54px;&#34; width=&#34;250&#34; height=&#34;54&#34;&gt;&lt;/a&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://trendshift.io/repositories/12784&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://trendshift.io/api/badge/repositories/12784&#34; alt=&#34;codexu%2Fnote-gen | Trendshift&#34; style=&#34;width: 250px; height: 55px;&#34; width=&#34;250&#34; height=&#34;55&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Guide&lt;/h2&gt; &#xA;&lt;p&gt;NoteGen is a cross-platform &lt;code&gt;Markdown&lt;/code&gt; note-taking application dedicated to using AI to bridge recording and writing, organizing fragmented knowledge into a readable note.&lt;/p&gt; &#xA;&lt;p&gt;üñ•Ô∏è Official Document: &lt;a href=&#34;https://notegen.top&#34;&gt;https://notegen.top&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;üí¨ Join &lt;a href=&#34;https://github.com/codexu/note-gen/discussions/110&#34;&gt;WeChat/QQ Group&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Why Choose NoteGen?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lightweight: &lt;a href=&#34;https://github.com/codexu/note-gen/releases&#34;&gt;Installation package&lt;/a&gt; is &lt;strong&gt;only 20MB&lt;/strong&gt;, free with no ads or bundled software.&lt;/li&gt; &#xA; &lt;li&gt;Cross-platform: Supports Mac, Windows, Linux, and thanks to &lt;code&gt;Tauri2&lt;/code&gt;&#39;s cross-platform capabilities, will support iOS and Android in the future.&lt;/li&gt; &#xA; &lt;li&gt;Supports multiple recording methods including &lt;code&gt;screenshots&lt;/code&gt;, &lt;code&gt;text&lt;/code&gt;, &lt;code&gt;illustrations&lt;/code&gt;, &lt;code&gt;files&lt;/code&gt;, &lt;code&gt;links&lt;/code&gt;, etc., meeting fragmented recording needs across various scenarios.&lt;/li&gt; &#xA; &lt;li&gt;Native &lt;code&gt;Markdown(.md)&lt;/code&gt; as storage format, no modifications, easy to migrate.&lt;/li&gt; &#xA; &lt;li&gt;Native offline usage, supporting real-time synchronization to &lt;code&gt;GitHub, Gitee private repositories&lt;/code&gt; with history rollback, and WebDAV synchronization.&lt;/li&gt; &#xA; &lt;li&gt;AI-enhanced: Configurable with ChatGPT, Gemini, Ollama, LM Studio, Grok, and other models, with support for custom third-party model configuration.&lt;/li&gt; &#xA; &lt;li&gt;RAG: Your notes are your knowledge base. Support embedding models and reranking models.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Screenshots&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/4f8a3bc5-17f5-4b36-9b17-d87128685257&#34;&gt;https://github.com/user-attachments/assets/4f8a3bc5-17f5-4b36-9b17-d87128685257&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Recording:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://s2.loli.net/2025/05/19/Cs5viKfkqb2HJmd.png&#34; alt=&#34;1.png&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Writing:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://s2.loli.net/2025/05/19/5vwQBPoLr6jzgUA.png&#34; alt=&#34;2.png&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Theme:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://s2.loli.net/2025/05/19/8yU72prmWdsCHeu.png&#34; alt=&#34;3.png&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;From Recording to Writing&lt;/h2&gt; &#xA;&lt;p&gt;Conventional note-taking applications typically don&#39;t provide recording functionality. Users need to manually copy and paste content for recording, which greatly reduces efficiency. When faced with scattered recorded content, it requires significant effort to organize.&lt;/p&gt; &#xA;&lt;p&gt;NoteGen is divided into &lt;code&gt;Recording&lt;/code&gt; and &lt;code&gt;Writing&lt;/code&gt; pages, with the following relationship:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Recordings can be organized into notes and transferred to the writing page for in-depth composition.&lt;/li&gt; &#xA; &lt;li&gt;During writing, you can insert recordings at any time.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Recording&lt;/h3&gt; &#xA;&lt;p&gt;The recording function is similar to an &lt;strong&gt;AI chatbot&lt;/strong&gt;, but when conversing with it, you can associate it with previously recorded content, switching from conversation mode to organization mode to arrange recordings into a readable note.&lt;/p&gt; &#xA;&lt;p&gt;The following auxiliary features can help you record more effectively:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Tags&lt;/strong&gt; to distinguish different recording scenarios.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Personas&lt;/strong&gt; with support for custom prompts to precisely control your AI assistant.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Clipboard Assistant&lt;/strong&gt; that automatically recognizes text or images in your clipboard and records them to your list.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Writing&lt;/h3&gt; &#xA;&lt;p&gt;The writing section is divided into two parts: &lt;strong&gt;File Manager&lt;/strong&gt; and &lt;strong&gt;Markdown Editor&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;File Manager&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Supports management of local Markdown files and GitHub synchronized files.&lt;/li&gt; &#xA; &lt;li&gt;Supports unlimited directory hierarchy.&lt;/li&gt; &#xA; &lt;li&gt;Supports multiple sorting methods.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Markdown Editor&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Supports WYSIWYG, instant rendering, and split-screen preview modes.&lt;/li&gt; &#xA; &lt;li&gt;Supports version control with history rollback.&lt;/li&gt; &#xA; &lt;li&gt;Supports AI assistance for conversation, continuation, polishing, and translation functions.&lt;/li&gt; &#xA; &lt;li&gt;Supports image hosting, uploading images and converting them to Markdown image links.&lt;/li&gt; &#xA; &lt;li&gt;Supports HTML to Markdown conversion, automatically converting copied browser content to Markdown format.&lt;/li&gt; &#xA; &lt;li&gt;Supports outlines, math formulas, mind maps, charts, flowcharts, Gantt charts, sequence diagrams, staves, multimedia, voice reading, title anchors, code highlighting and copying, graphviz rendering, and plantuml UML diagrams.&lt;/li&gt; &#xA; &lt;li&gt;Supports real-time local content saving, delayed (10s without editing) automatic synchronization, and history rollback.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Other Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Global search for quickly finding and jumping to specific content.&lt;/li&gt; &#xA; &lt;li&gt;Image hosting management for convenient management of image repository content.&lt;/li&gt; &#xA; &lt;li&gt;Themes and appearance with support for dark themes and appearance settings for Markdown, code, etc.&lt;/li&gt; &#xA; &lt;li&gt;Internationalization support, currently available in Chinese and English.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to Use?&lt;/h2&gt; &#xA;&lt;h3&gt;Download&lt;/h3&gt; &#xA;&lt;p&gt;Currently supports Mac, Windows, and Linux. Thanks to Tauri2&#39;s cross-platform capabilities, it will support iOS and Android in the future.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/codexu/note-gen/releases&#34;&gt;Download NoteGen (alpha)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Enhancement&lt;/h3&gt; &#xA;&lt;p&gt;The note-taking application can be used directly without configuration. If you want a better experience, please open the settings page to configure AI and synchronization.&lt;/p&gt; &#xA;&lt;h2&gt;Contribute&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/codexu/note-gen/dev/.github/CONTRIBUTING.md&#34;&gt;Read contribution guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/codexu/note-gen/issues/46&#34;&gt;Update plans&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/codexu/note-gen/issues&#34;&gt;Submit bugs or improvement suggestions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/codexu/note-gen/discussions&#34;&gt;Discussions&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/codexu/note-gen/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=codexu/note-gen&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.star-history.com/#codexu/note-gen&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=codexu/note-gen&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>DavidHDev/react-bits</title>
    <updated>2025-06-08T01:29:27Z</updated>
    <id>tag:github.com,2025-06-08:/DavidHDev/react-bits</id>
    <link href="https://github.com/DavidHDev/react-bits" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An open source collection of animated, interactive &amp; fully customizable React components for building stunning, memorable user interfaces.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;br&gt; &#xA; &lt;br&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;src/assets/logos/reactbits-gh-black.svg&#34;&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;src/assets/logos/reactbits-gh-white.svg&#34;&gt; &#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/DavidHDev/react-bits/main/src/assets/logos/reactbits-gh-black.svg?sanitize=true&#34; alt=&#34;react-bits logo&#34; width=&#34;1000&#34;&gt; &#xA; &lt;/picture&gt; &#xA; &lt;br&gt; &#xA; &lt;br&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA;  The largest &amp;amp; most creative library of animated React components. &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;https://github.com/davidhdev/react-bits/stargazers&#34;&gt;&lt;img alt=&#34;GitHub Repo stars&#34; src=&#34;https://img.shields.io/github/stars/davidhdev/react-bits&#34;&gt;&lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/davidhdev/react-bits/raw/main/LICENSE.md&#34;&gt;&lt;img alt=&#34;License&#34; src=&#34;https://img.shields.io/badge/License-MIT-cyan.svg?sanitize=true&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Go to &lt;a href=&#34;https://reactbits.dev/&#34;&gt;reactbits.dev&lt;/a&gt; to view the documentation.&lt;/p&gt; &#xA;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;p&gt;React Bits is a large collection of animated React components made to spice up your web creations. We&#39;ve got animations, components, backgrounds, and awesome stuff that you won&#39;t be able to find anywhere else - all free for you to use! These components are all enhanced with customization options as props, to make it easy for you to get exactly what you need.&lt;/p&gt; &#xA;&lt;h2&gt;Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;60 total components (text animations, animations, components, backgrounds), growing every day&lt;/li&gt; &#xA; &lt;li&gt;All components are lightweight, with minimal dependencies, and highly customizable&lt;/li&gt; &#xA; &lt;li&gt;Designed to integrate seamlessly with any modern React project&lt;/li&gt; &#xA; &lt;li&gt;Each component comes in 4 variants, to keep everyone happy: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;JS + CSS&lt;/li&gt; &#xA;   &lt;li&gt;JS + Tailwind CSS&lt;/li&gt; &#xA;   &lt;li&gt;TS + CSS&lt;/li&gt; &#xA;   &lt;li&gt;TS + Tailwind CSS&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;CLI (&lt;a href=&#34;https://jsrepo.dev&#34;&gt;&lt;img src=&#34;https://jsrepo.dev/badges/jsrepo.svg?sanitize=true&#34; width=&#34;50&#34; alt=&#34;jsrepo&#34;&gt;&lt;/a&gt;)&lt;/h2&gt; &#xA;&lt;p&gt;React Bits uses &lt;a href=&#34;https://jsrepo.dev&#34;&gt;jsrepo&lt;/a&gt; for installing components via CLI. &lt;br&gt; The setup steps can be found on each component&#39;s page in the &lt;a href=&#34;https://reactbits.dev/&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;How To Contribute?&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are welcome! Check the &lt;a href=&#34;https://github.com/DavidHDev/react-bits/issues&#34;&gt;Open Issues&lt;/a&gt; to see how you can help or submit ideas using the &lt;a href=&#34;https://github.com/DavidHDev/react-bits/issues/new?template=2-feature-request.yml&#34;&gt;Feature Request template&lt;/a&gt;.&lt;br&gt; Please review the &lt;a href=&#34;https://github.com/DavidHDev/react-bits/raw/main/CONTRIBUTING.md&#34;&gt;Contribution Guide&lt;/a&gt; and follow our standards. Thanks for your time!&lt;/p&gt; &#xA;&lt;h2&gt;Contributors&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/davidhdev/react-bits/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=davidhdev/react-bits&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;Maintainers&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/DavidHDev&#34;&gt;David Haz&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Stats&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://repobeats.axiom.co/api/embed/b1bf4dc0226458617adbdbf5586f2df953eb0922.svg?sanitize=true&#34; alt=&#34;Alt&#34; title=&#34;Repobeats analytics image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Licensed under the &lt;a href=&#34;https://github.com/davidhdev/react-bits/raw/main/LICENSE.md&#34;&gt;MIT license&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>jwohlwend/boltz</title>
    <updated>2025-06-08T01:29:27Z</updated>
    <id>tag:github.com,2025-06-08:/jwohlwend/boltz</id>
    <link href="https://github.com/jwohlwend/boltz" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official repository for the Boltz biomolecular interaction models&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;div&gt;&#xA;  &amp;nbsp;&#xA; &lt;/div&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/jwohlwend/boltz/main/docs/boltz2_title.png&#34; width=&#34;300&#34;&gt; &#xA; &lt;img src=&#34;https://model-gateway.boltz.bio/a.png?x-pxid=bce1627f-f326-4bff-8a97-45c6c3bc929d&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://doi.org/10.1101/2024.11.19.624167&#34;&gt;Boltz-1&lt;/a&gt; | &lt;a href=&#34;https://bit.ly/boltz2-pdf&#34;&gt;Boltz-2&lt;/a&gt; | &lt;a href=&#34;https://boltz-community.slack.com/join/shared_invite/zt-37b5dxiuo-80rPSDp6lXjD1GTC4bxNIw#/shared-invite/email&#34;&gt;Slack&lt;/a&gt; &lt;br&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jwohlwend/boltz/main/docs/boltz1_pred_figure.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;Boltz is a family of models for biomolecular interaction prediction. Boltz-1 was the first fully open source model to approach AlphaFold3 accuracy. Our latest work Boltz-2 is a new biomolecular foundation model that goes beyond AlphaFold3 and Boltz-1 by jointly modeling complex structures and binding affinities, a critical component towards accurate molecular design. Boltz-2 is the first deep learning model to approach the accuracy of physics-based free-energy perturbation (FEP) methods, while running 1000x faster ‚Äî making accurate in silico screening practical for early-stage drug discovery.&lt;/p&gt; &#xA;&lt;p&gt;All the code and weights are provided under MIT license, making them freely available for both academic and commercial uses. For more information about the model, see the &lt;a href=&#34;https://doi.org/10.1101/2024.11.19.624167&#34;&gt;Boltz-1&lt;/a&gt; and &lt;a href=&#34;https://bit.ly/boltz2-pdf&#34;&gt;Boltz-2&lt;/a&gt; technical reports. To discuss updates, tools and applications join our &lt;a href=&#34;https://join.slack.com/t/boltz-community/shared_invite/zt-34qg8uink-V1LGdRRUf3avAUVaRvv93w&#34;&gt;Slack channel&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: we recommend installing boltz in a fresh python environment&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Install boltz with PyPI (recommended):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install boltz -U&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or directly from GitHub for daily updates:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/jwohlwend/boltz.git&#xA;cd boltz; pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Inference&lt;/h2&gt; &#xA;&lt;p&gt;You can run inference using Boltz with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;boltz predict input_path --use_msa_server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;input_path&lt;/code&gt; should point to a YAML file, or a directory of YAML files for batched processing, describing the biomolecules you want to model and the properties you want to predict (e.g. affinity). To see all available options: &lt;code&gt;boltz predict --help&lt;/code&gt; and for more information on these input formats, see our &lt;a href=&#34;https://raw.githubusercontent.com/jwohlwend/boltz/main/docs/prediction.md&#34;&gt;prediction instructions&lt;/a&gt;. By default, the &lt;code&gt;boltz&lt;/code&gt; command will run the latest version of the model.&lt;/p&gt; &#xA;&lt;h2&gt;Evaluation&lt;/h2&gt; &#xA;&lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Coming soon: updated evaluation code for Boltz-2!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;To encourage reproducibility and facilitate comparison with other models, on top of the existing Boltz-1 evaluation pipeline, we will soon provide the evaluation scripts and structural predictions for Boltz-2, Boltz-1, Chai-1 and AlphaFold3 on our test benchmark dataset, and our affinity predictions on the FEP+ benchamark, CASP16 and our MF-PCBA test set.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/jwohlwend/boltz/main/docs/pearson_plot.png&#34; alt=&#34;Affinity test sets evaluations&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/jwohlwend/boltz/main/docs/plot_test_boltz2.png&#34; alt=&#34;Test set evaluations&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Coming soon: updated training code for Boltz-2!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re interested in retraining the model, currently for Boltz-1 but soon for Boltz-2, see our &lt;a href=&#34;https://raw.githubusercontent.com/jwohlwend/boltz/main/docs/training.md&#34;&gt;training instructions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome external contributions and are eager to engage with the community. Connect with us on our &lt;a href=&#34;https://join.slack.com/t/boltz-community/shared_invite/zt-34qg8uink-V1LGdRRUf3avAUVaRvv93w&#34;&gt;Slack channel&lt;/a&gt; to discuss advancements, share insights, and foster collaboration around Boltz-2.&lt;/p&gt; &#xA;&lt;p&gt;Boltz also runs on Tenstorrent hardware thanks to a &lt;a href=&#34;https://github.com/moritztng/tt-boltz&#34;&gt;fork&lt;/a&gt; by Moritz Th√ºning.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Our model and code are released under MIT License, and can be freely used for both academic and commercial purposes.&lt;/p&gt; &#xA;&lt;h2&gt;Cite&lt;/h2&gt; &#xA;&lt;p&gt;If you use this code or the models in your research, please cite the following papers:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{passaro2025boltz2,&#xA;  author = {Passaro, Saro and Corso, Gabriele and Wohlwend, Jeremy and Reveiz, Mateo and Thaler, Stephan and Somnath, Vignesh Ram and Getz, Noah and Portnoi, Tally and Roy, Julien and Stark, Hannes and Kwabi-Addo, David and Beaini, Dominique and Jaakkola, Tommi and Barzilay, Regina},&#xA;  title = {Boltz-2: Towards Accurate and Efficient Binding Affinity Prediction},&#xA;  year = {2025},&#xA;  doi = {},&#xA;  journal = {}&#xA;}&#xA;&#xA;@article{wohlwend2024boltz1,&#xA;  author = {Wohlwend, Jeremy and Corso, Gabriele and Passaro, Saro and Getz, Noah and Reveiz, Mateo and Leidal, Ken and Swiderski, Wojtek and Atkinson, Liam and Portnoi, Tally and Chinn, Itamar and Silterra, Jacob and Jaakkola, Tommi and Barzilay, Regina},&#xA;  title = {Boltz-1: Democratizing Biomolecular Interaction Modeling},&#xA;  year = {2024},&#xA;  doi = {10.1101/2024.11.19.624167},&#xA;  journal = {bioRxiv}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In addition if you use the automatic MSA generation, please cite:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{mirdita2022colabfold,&#xA;  title={ColabFold: making protein folding accessible to all},&#xA;  author={Mirdita, Milot and Sch{\&#34;u}tze, Konstantin and Moriwaki, Yoshitaka and Heo, Lim and Ovchinnikov, Sergey and Steinegger, Martin},&#xA;  journal={Nature methods},&#xA;  year={2022},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>