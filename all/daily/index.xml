<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-22T01:29:27Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>RupertBenWiser/Web-Environment-Integrity</title>
    <updated>2023-07-22T01:29:27Z</updated>
    <id>tag:github.com,2023-07-22:/RupertBenWiser/Web-Environment-Integrity</id>
    <link href="https://github.com/RupertBenWiser/Web-Environment-Integrity" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Web Environment Integrity API&lt;/h1&gt; &#xA;&lt;p&gt;This repository details the proposal to add a new API for determining the integrity of web environments:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const attestation = await navigator.getEnvironmentIntegrity(&#34;...&#34;);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/RupertBenWiser/Web-Environment-Integrity/main/explainer.md&#34;&gt;explainer&lt;/a&gt; goes gives a high level overview of the proposal.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://rupertbenwiser.github.io/Web-Environment-Integrity/&#34;&gt;spec&lt;/a&gt; currently describes how this is being prototyped in Chromium.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>fullstackhero/dotnet-webapi-boilerplate</title>
    <updated>2023-07-22T01:29:27Z</updated>
    <id>tag:github.com,2023-07-22:/fullstackhero/dotnet-webapi-boilerplate</id>
    <link href="https://github.com/fullstackhero/dotnet-webapi-boilerplate" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Clean Architecture Template for .NET 7.0 WebApi built with Multitenancy Support.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/fullstackhero/dotnet-webapi-boilerplate/actions/workflows/dotnet.yml&#34;&gt;&lt;img src=&#34;https://github.com/fullstackhero/dotnet-webapi-boilerplate/actions/workflows/dotnet.yml/badge.svg?branch=main&#34; alt=&#34;dotnet-cicd&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/fullstackhero/dotnet-webapi-boilerplate/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/fullstackhero/dotnet-webapi-boilerplate?color=2da44e&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/yQWpShsKrf&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/878181478972928011?color=%237289da&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=%237289da&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.nuget.org/packages/FullStackHero.WebAPI.Boilerplate/&#34;&gt;&lt;img src=&#34;https://img.shields.io/nuget/dt/FullStackHero.WebAPI.Boilerplate?color=2da44e&amp;amp;label=nuget%20downloads&amp;amp;logo=nuget&#34; alt=&#34;Nuget downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/iammukeshm&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url/https/twitter.com/iammukeshm.svg?style=social&amp;amp;label=Follow%20%40iammukeshm&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/fullstackhero/dotnet-webapi-boilerplate/main/media/fullstack-hero-dotnet-7-webapi-boilerplate-banner.png&#34; alt=&#34;fullstackhero webapi&#34; title=&#34;fullstackhero webapi&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What&#39;s fullstackhero&#39;s .NET Web API Boilerplate?&lt;/h2&gt; &#xA;&lt;p&gt;fullstackhero&#39;s .NET Web API Boilerplate is a starting point for your next &lt;code&gt;.NET 7 Clean Architecture Project&lt;/code&gt; that incorporates the most essential packages and features your projects will ever need including out of the box Multi-Tenancy support. This project can save well over &lt;code&gt;200+ hours&lt;/code&gt; of development time for your team.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;As the name suggests, this is an API / Server Boilerplate. You can find other Client Boilerplates that consume this API under &lt;code&gt;@fullstackhero&lt;/code&gt; handle.&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Find &lt;code&gt;Blazor WebAssembly Boilerplate&lt;/code&gt; here - &lt;a href=&#34;https://github.com/fullstackhero/blazor-wasm-boilerplate&#34;&gt;https://github.com/fullstackhero/blazor-wasm-boilerplate&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;YouTube Video - .NET Web API Boilerplate | FullStackHero - Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;Watch the Getting started video here&lt;/code&gt; : &lt;a href=&#34;https://www.youtube.com/watch?v=a1mWRLQf9hY&#34;&gt;https://www.youtube.com/watch?v=a1mWRLQf9hY&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=a1mWRLQf9hY&#34;&gt;&lt;img src=&#34;https://codewithmukesh.com/wp-content/uploads/2023/04/fullstackhero-youtube.png&#34; alt=&#34;.NET Web API Boilerplate | FullStackHero - Getting Started&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Goals&lt;/h2&gt; &#xA;&lt;p&gt;The goal of this repository is to provide a complete and feature-rich starting point for any .NET Developer / Team to kick-start their next major project using .NET 7 Web API. This also serves the purpose of learning advanced concepts and implementations such as &lt;code&gt;Multitenancy, CQRS, Onion Architecture, Clean Coding standards, Cloud Deployments with Terraform to AWS, Docker Concepts, CICD Pipelines &amp;amp; Workflows&lt;/code&gt; and so on.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Built on .NET 7.0&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Follows Clean Architecture Principles&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Domain Driven Design&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Cloud Ready. Can be deployed to AWS Infrastructure as ECS Containers using Terraform!&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Docker-Compose File Examples&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Documented at &lt;a href=&#34;https://fullstackhero.net&#34;&gt;fullstackhero.net&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Multi Tenancy Support with Finbuckle &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Create Tenants with Multi Database / Shared Database Support&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Activate / Deactivate Tenants on Demand&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Upgrade Subscription of Tenants - Add More Validity Months to each tenant!&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Supports MySQL, MSSQL, Oracle &amp;amp; PostgreSQL!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Click to See More!&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Uses Entity Framework Core as DB Abstraction&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Flexible Repository Pattern&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Dapper Integration for Optimal Performance&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Serilog Integration with various Sinks - File, SEQ, Kibana&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; OpenAPI - Supports Client Service Generation&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Mapster Integration for Quicker Mapping&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; API Versioning&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Response Caching - Distributed Caching + REDIS&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Fluent Validations&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Audit Logging&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Advanced User &amp;amp; Role Based Permission Management&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Code Analysis &amp;amp; StyleCop Integration with Rulesets&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; JSON Based Localization with Caching&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Hangfire Support - Secured Dashboard&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; File Storage Service&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Test Projects&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; JWT &amp;amp; Azure AD Authentication&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; MediatR - CQRS&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; SignalR Notifications&lt;/li&gt; &#xA;  &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &amp;amp; Much More&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Read Documentation related to this Boilerplate here - &lt;a href=&#34;https://fullstackhero.net/dotnet-webapi-boilerplate/&#34;&gt;https://fullstackhero.net/dotnet-webapi-boilerplate/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Feel free to contribute to the Documentation Repository - &lt;a href=&#34;https://github.com/fullstackhero/docs&#34;&gt;https://github.com/fullstackhero/docs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To get started with this Boilerplate, here are the available options.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install using the &lt;code&gt;FSH CLI&lt;/code&gt; tool. Use this for release versions of the Boilerplate only.&lt;/li&gt; &#xA; &lt;li&gt;Fork the Repository. Use this if you want to always keep your version of the Boilerplate up-to date with the latest changes.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Make sure that your DEV enviroment is setup, &lt;a href=&#34;https://fullstackhero.net/dotnet-webapi-boilerplate/general/development-environment/&#34;&gt;Read the Development Environment Guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;FSH CLI Tool&lt;/h3&gt; &#xA;&lt;h4&gt;Prerequisites&lt;/h4&gt; &#xA;&lt;p&gt;Before creating your first fullstackhero solution, you should ensure that your local machine has:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;.NET 7&lt;/strong&gt; You can find the download &lt;a href=&#34;https://dotnet.microsoft.com/en-us/download/dotnet/7.0&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;NodeJS (16+)&lt;/strong&gt; You can find the download &lt;a href=&#34;https://nodejs.org/en/download&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Installation&lt;/h4&gt; &#xA;&lt;p&gt;After you have installed .NET, you will need to install the &lt;code&gt;fsh&lt;/code&gt; console tool.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;dotnet tool install --global FSH.CLI&#xA;fsh install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This isntall the FSH CLI tools and the associated Templates. You are now ready to create your first FSH project!&lt;/p&gt; &#xA;&lt;h4&gt;FSH .NET WebAPI Boilerplate&lt;/h4&gt; &#xA;&lt;p&gt;Here&#39;s how you would create a Solution using the FSH .NET WebAPI Boilerplate.&lt;/p&gt; &#xA;&lt;p&gt;Simply navigate to a new directory (wherever you want to place your new solution), and open up Command Prompt at the opened directory.&lt;/p&gt; &#xA;&lt;p&gt;Run the following command. Note that, in this demonstration, I am naming my new solution as FSH.Starter.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;fsh api new FSH.Starter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;OR&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;fsh api n FSH.Starter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will create a new .NET 7 WEBAPI solution for you using the FSH Templates. For further steps and details, &lt;a href=&#34;https://fullstackhero.net/dotnet-webapi-boilerplate/general/getting-started/&#34;&gt;Read the Getting Started Guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Update&lt;/h4&gt; &#xA;&lt;p&gt;To update the tool &amp;amp; templates, run the following commands&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;dotnet tool update FSH.CLI --global&#xA;fsh update&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Forking the Repository&lt;/h3&gt; &#xA;&lt;p&gt;You would probably need to take this approach if you want to keep your source code upto date with the latest changes. To get started based on this repository, you need to get a copy locally. You have three options: fork, clone, or download.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Make a fork of this repository in your Github account.&lt;/li&gt; &#xA; &lt;li&gt;Create your new &lt;code&gt;dotnet-webapi-boilerplate&lt;/code&gt; personal project by cloning the forked repository on your personal github.&lt;/li&gt; &#xA; &lt;li&gt;Setup an upstream remote on your personal project pointing to your forked repository using command &lt;code&gt;git remote add upstream https://github.com/{githubuseraccount}/dotnet-webapi-boilerplate&lt;/code&gt; and &lt;code&gt;git remote set-url --push upstream DISABLE&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For step by step instructions, &lt;a href=&#34;https://discord.com/channels/878181478972928011/892573122186838046/933513103688224838&#34;&gt;follow this&lt;/a&gt; and &lt;a href=&#34;https://gist.github.com/0xjac/85097472043b697ab57ba1b1c7530274&#34;&gt;this&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start Guide&lt;/h2&gt; &#xA;&lt;p&gt;So, for a better developer experience, I have added Makefile into the solution. Now that our solution is generated, let&#39;s navigate to the root folder of the solution and open up a command terminal.&lt;/p&gt; &#xA;&lt;p&gt;To build the solution,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, the solution is configured to work with postgresql database (mainly because of hte OS licensing). So, you will have to make sure that postgresql database instance is up and running on your machine. You can modify the connection string to include your username and password. Connections strings can be found at &lt;code&gt;src/Host/Configurations/database.json&lt;/code&gt; and &lt;code&gt;src/Host/Configurations/hangfire.json&lt;/code&gt;. Once that&#39;s done, let&#39;s start up the API server.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make start&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That&#39;s it, the application would connect to the defined postgresql database and start creating tables, and seed required data.&lt;/p&gt; &#xA;&lt;p&gt;For testing this API, we have 3 options.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Swagger @ &lt;code&gt;localhost:5001/swagger&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Postman collections are available &lt;code&gt;./postman&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;ThunderClient for VSCode. This is my personal favorite. You will have to install the Thunderclient extension for VSCode.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The default credentials to this API is:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;    &#34;email&#34;:&#34;admin@root.com&#34;,&#xA;    &#34;password&#34;:&#34;123Pa$$word!&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open up Postman, Thunderclient or Swagger.&lt;/p&gt; &#xA;&lt;p&gt;identity -&amp;gt; get-token&lt;/p&gt; &#xA;&lt;p&gt;This is a POST Request. Here the body of the request will be the JSON (credentials) I specified earlier. And also, remember to pass the tenant id in the header of the request. The default tenant id is &lt;code&gt;root&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Here is a sample CURL command for getting the tokens.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-curl&#34;&gt;curl -X POST \&#xA;  &#39;https://localhost:5001/api/tokens&#39; \&#xA;  --header &#39;Accept: */*&#39; \&#xA;  --header &#39;tenant: root&#39; \&#xA;  --header &#39;Accept-Language: en-US&#39; \&#xA;  --header &#39;Content-Type: application/json&#39; \&#xA;  --data-raw &#39;{&#xA;  &#34;email&#34;: &#34;admin@root.com&#34;,&#xA;  &#34;password&#34;: &#34;123Pa$$word!&#34;&#xA;}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And here is the response.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &#34;token&#34;: &#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJodHRwOi8vc2NoZW1hcy54bWxzb2FwLm9yZy93cy8yMDA1LzA1L2lkZW50aXR5L2NsYWltcy9uYW1laWRlbnRpZmllciI6IjM0YTY4ZjQyLWE0ZDgtNDNlMy1hNzE3LTI1OTczZjZmZTJjNyIsImh0dHA6Ly9zY2hlbWFzLnhtbHNvYXAub3JnL3dzLzIwMDUvMDUvaWRlbnRpdHkvY2xhaW1zL2VtYWlsYWRkcmVzcyI6ImFkbWluQHJvb3QuY29tIiwiZnVsbE5hbWUiOiJyb290IEFkbWluIiwiaHR0cDovL3NjaGVtYXMueG1sc29hcC5vcmcvd3MvMjAwNS8wNS9pZGVudGl0eS9jbGFpbXMvbmFtZSI6InJvb3QiLCJodHRwOi8vc2NoZW1hcy54bWxzb2FwLm9yZy93cy8yMDA1LzA1L2lkZW50aXR5L2NsYWltcy9zdXJuYW1lIjoiQWRtaW4iLCJpcEFkZHJlc3MiOiIxMjcuMC4wLjEiLCJ0ZW5hbnQiOiJyb290IiwiaW1hZ2VfdXJsIjoiIiwiaHR0cDovL3NjaGVtYXMueG1sc29hcC5vcmcvd3MvMjAwNS8wNS9pZGVudGl0eS9jbGFpbXMvbW9iaWxlcGhvbmUiOiIiLCJleHAiOjE2ODA5NDE3MzN9.VYNaNvk2T4YDvQ3wriXgk2W_Vy9zyEEhjveNauNAeJY&#34;,&#xA;  &#34;refreshToken&#34;: &#34;pyxO30zJK8KelpEXF0vPfbSbjntdlbbnxrZAlUFXfyE=&#34;,&#xA;  &#34;refreshTokenExpiryTime&#34;: &#34;2023-04-15T07:15:33.5187598Z&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You will need to pass the &lt;code&gt;token&lt;/code&gt; in the request headers to authenticate calls to the fullstackhero API!&lt;/p&gt; &#xA;&lt;p&gt;For further steps and details, &lt;a href=&#34;https://fullstackhero.net/dotnet-webapi-boilerplate/general/getting-started/&#34;&gt;Read the Getting Started Guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Containerization&lt;/h2&gt; &#xA;&lt;p&gt;The API project, being .NET 7, it is configured to have built-in support for containerization. That means, you really don&#39;t need a Dockerfile to containerize the webapi.&lt;/p&gt; &#xA;&lt;p&gt;To build a docker image, all you have to do is, ensure that docker-desktop or docker instance is running. And run the following command at the root of the solution.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make publish&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also push the docker image directly to dockerhub or any supported registry by using the following command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make publish-to-hub&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You will have to update your docker registry / repo url in the Makefile though!.&lt;/p&gt; &#xA;&lt;h2&gt;Docker Compose&lt;/h2&gt; &#xA;&lt;p&gt;This project also comes with examples of docker compose files, where you can spin up the webapi and database isntance in your local containers with the following commands.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;make dcu #docker compose up - Boots up the webapi &amp;amp; postgresql container&#xA;make dcd #docker compose down - Shuts down the webapi &amp;amp; postgresql containers&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There are also examples for mysql &amp;amp; mssql variations of the fsh webapi. You can find the other docker-compose files under the ./docker-compose folder. Read more about &lt;a href=&#34;https://raw.githubusercontent.com/fullstackhero/dotnet-webapi-boilerplate/main/docker-compose/README.md&#34;&gt;fullstackhero&#39;s docker-compose instructions &amp;amp; files here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Cloud Deployment with Terraform + AWS ECS&lt;/h2&gt; &#xA;&lt;p&gt;This is something you wont get to see very often with boilerplates. But, we do support cloud deployment to AWS using terraform. The terraform files are available at the &lt;code&gt;./terraform&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install Terraform&lt;/li&gt; &#xA; &lt;li&gt;Install &amp;amp; Configure AWS CLI profiles to allow terraform to provision resources for you. I have made a video about &lt;a href=&#34;https://www.youtube.com/watch?v=oY0-1mj4oCo&amp;amp;ab_channel=MukeshMurugan&#34;&gt;AWS Credentials Management&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In brief, the terraform folder has 2 sub-folders.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;backend&lt;/li&gt; &#xA; &lt;li&gt;environments/staging&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The Backend folder is internally used by Terraform for state management and locking. There is a one-time setup you have to do against this folder. Navigate to the backend folder and run the command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;terraform init&#xA;terraform apply -auto-approve&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This would create the required S3 Buckets and DDB table for you.&lt;/p&gt; &#xA;&lt;p&gt;Next is the &lt;code&gt;environments/staging&lt;/code&gt; folder. Here too, run the following command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;terraform init&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once done, you can go the terraform.tfvars file to change the variables like,&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;project tags&lt;/li&gt; &#xA; &lt;li&gt;docker image name&lt;/li&gt; &#xA; &lt;li&gt;ecs cluster name and so on.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;After that, simply back to the root of the solution and run the following command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make ta&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will evaluate your terraform files and create a provision plan for you. Once you are ok, type in &lt;code&gt;yes&lt;/code&gt; and the tool will start to deploy your .NET WebAPI project as containers along with a RDS PostgreSQL intance. You will be receiving the hosted api url once the provisioning is completed!&lt;/p&gt; &#xA;&lt;p&gt;To destroy the deployed resources, run the following&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make td&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Important Links &amp;amp; Documentations&lt;/h2&gt; &#xA;&lt;p&gt;Overview - &lt;a href=&#34;https://fullstackhero.net/dotnet-webapi-boilerplate/general/overview/&#34;&gt;Read&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Getting Started - &lt;a href=&#34;https://fullstackhero.net/dotnet-webapi-boilerplate/general/getting-started/&#34;&gt;Read&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Development Environment - &lt;a href=&#34;https://fullstackhero.net/dotnet-webapi-boilerplate/general/development-environment/&#34;&gt;Learn about setting up the DEV environment&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Participate in Discussions - &lt;a href=&#34;https://github.com/fullstackhero/dotnet-webapi-boilerplate/discussions&#34;&gt;QNA &amp;amp; General Discussions&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Join our Discord - &lt;a href=&#34;https://discord.gg/gdgHRt4mMw&#34;&gt;fullstackhero @ Discord&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Changelogs&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/fullstackhero/dotnet-webapi-boilerplate/raw/main/CHANGELOGS.md&#34;&gt;View Complete Changelogs.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Discord &lt;a href=&#34;https://discord.gg/gdgHRt4mMw&#34;&gt;@fullstackhero&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Facebook Page &lt;a href=&#34;https://facebook.com/codewithmukesh&#34;&gt;@codewithmukesh&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Youtube Channel &lt;a href=&#34;https://youtube.com/c/codewithmukesh&#34;&gt;@codewithmukesh&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed with the &lt;a href=&#34;https://raw.githubusercontent.com/fullstackhero/dotnet-webapi-boilerplate/main/LICENSE&#34;&gt;MIT license&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Support ⭐&lt;/h2&gt; &#xA;&lt;p&gt;Has this Project helped you learn something New? or Helped you at work? Here are a few ways by which you can support.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Leave a star! ⭐&lt;/li&gt; &#xA; &lt;li&gt;Recommend this awesome project to your colleagues. 🥇&lt;/li&gt; &#xA; &lt;li&gt;Do consider endorsing me on LinkedIn for ASP.NET Core - &lt;a href=&#34;https://codewithmukesh.com/linkedin&#34;&gt;Connect via LinkedIn&lt;/a&gt; 🦸&lt;/li&gt; &#xA; &lt;li&gt;Sponsor the project - &lt;a href=&#34;https://opencollective.com/fullstackhero&#34;&gt;opencollective/fullstackhero&lt;/a&gt; ❤️&lt;/li&gt; &#xA; &lt;li&gt;Or, &lt;a href=&#34;https://www.buymeacoffee.com/codewithmukesh&#34;&gt;consider buying me a coffee&lt;/a&gt;! ☕&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/codewithmukesh&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/fullstackhero/dotnet-webapi-boilerplate/main/media/buy-me-a-coffee.png&#34; alt=&#34;buy-me-a-coffee&#34; title=&#34;buy-me-a-coffee&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Code Contributors&lt;/h2&gt; &#xA;&lt;p&gt;This project exists thanks to all the people who contribute. &lt;a href=&#34;https://raw.githubusercontent.com/fullstackhero/dotnet-webapi-boilerplate/main/CONTRIBUTING.md&#34;&gt;Submit your PR and join the elite list!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/fullstackhero/dotnet-webapi-boilerplate/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=fullstackhero/dotnet-webapi-boilerplate&#34; alt=&#34;fsh dotnet webapi contributors&#34; title=&#34;fsh dotnet webapi contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Financial Contributors&lt;/h2&gt; &#xA;&lt;p&gt;Become a financial contributor and help me sustain the project. &lt;a href=&#34;https://opencollective.com/fullstackhero/contribute&#34;&gt;Support the Project!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://opencollective.com/fullstackhero&#34;&gt;&lt;img src=&#34;https://opencollective.com/fullstackhero/individuals.svg?width=890&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Melelery/c-binance-future-quant</title>
    <updated>2023-07-22T01:29:27Z</updated>
    <id>tag:github.com,2023-07-22:/Melelery/c-binance-future-quant</id>
    <link href="https://github.com/Melelery/c-binance-future-quant" rel="alternate"></link>
    <summary type="html">&lt;p&gt;low-cost, high-efficiency, easy-to-implement&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;简介&lt;/h1&gt; &#xA;&lt;p&gt;这是一套经过长时间实盘验证，有超过100亿美金交易量，包含币安合约的数据录入，风控，交易的架构实现，但不包含具体的策略，仅提供一个简单的交易实践演示数据读取，开仓，平仓，以及止盈止损，风控，简单的前端数据展示和分析，前端演示地址：&lt;a href=&#34;http://8.217.121.203/&#34;&gt;8.217.121.203&lt;/a&gt;，目前放1000美金运行着一个年化100%~200%的高频左侧回归策略&lt;/p&gt; &#xA;&lt;p&gt;你可以利用它简单，低成本的实现你的交易逻辑，其大量运用阿里云服务器进行分布式架构，多进程处理，以及飞书进行异常报错和交易信息披露...&lt;/p&gt; &#xA;&lt;p&gt;如果你愿意详细阅读该readme的所有信息，尤其是 &lt;a href=&#34;https://raw.githubusercontent.com/Melelery/c-binance-future-quant/main/#%E6%A8%A1%E5%9D%97%E8%AF%A6%E7%BB%86%E8%A7%A3%E6%9E%90&#34;&gt;模块详细解析&lt;/a&gt; ，那么他同时也会是一部关于币安合约的交易风控，设计架构的经验理解历史，总结了几乎本人所有成功和失败的经验，希望能让后人少踩些坑&lt;/p&gt; &#xA;&lt;h1&gt;优势&lt;/h1&gt; &#xA;&lt;p&gt;低成本，高效率，简单实现是这套系统的三个优势&lt;/p&gt; &#xA;&lt;p&gt;不到1000人民币一个月的成本，实现每分钟扫描1500万次交易对是否满足交易条件&lt;/p&gt; &#xA;&lt;p&gt;除了撮合服务器（C++）外都采用python编写，简单易懂&lt;/p&gt; &#xA;&lt;p&gt;大量的分布式架构实现更快的速度，并且可以根据个人需求，自由伸缩的调控服务器数量来实现成本和性能的平衡&lt;/p&gt; &#xA;&lt;p&gt;通过多重接口读取行情/账户信息，并根据更新时间戳进行整合，最大程度的降低数据风险&lt;/p&gt; &#xA;&lt;p&gt;企业级别的风控安全解决方案&lt;/p&gt; &#xA;&lt;h1&gt;架构&lt;/h1&gt; &#xA;&lt;p&gt;该系统通过一个C++服务器作为主撮合服务器，大量的可伸缩调整的分布式python服务器作为数据采集服务器。&lt;/p&gt; &#xA;&lt;p&gt;将采集的数据，包括Kline ，trades，tick等，喂给C++服务器。&lt;/p&gt; &#xA;&lt;p&gt;交易服务器再从C++服务器统一读取数据，并且在本地端维护一个K线账本，来避开交易所的频率限制，实现高效率，低成本的数据读取。&lt;/p&gt; &#xA;&lt;p&gt;又比如，账户的余额，持仓数据，在币安上有三种方式获取，a是position risk，b是account，c是ws，那么会有三台服务器分别采用这三种方式读取，然后汇入C++服务器进行校对，通过对比更新时间截取最新的数据，然后服务给交易服务器&lt;/p&gt; &#xA;&lt;p&gt;前端数据板块，通过阿里云oss为中介，网页读取oss数据的方式进行展示，隔离数据风险&lt;/p&gt; &#xA;&lt;h1&gt;作者自述&lt;/h1&gt; &#xA;&lt;p&gt;2021年，我从一家top量化公司辞职后做起量化交易，主要战场在币安，这两年间，我从做市商-&amp;gt;趋势-&amp;gt;套利等类型均有涉及，最高峰的时候，在币安一个月有接近20亿美金的交易额。&lt;/p&gt; &#xA;&lt;p&gt;至2023年7月，因为各种原因，大方向上失败了，只遗留下一个朋友的资金在继续运行一个比较稳定盈利的左侧交易策略。&lt;/p&gt; &#xA;&lt;p&gt;这是在这两年时间里面探索出来的一套高效率，低成本的数据读取，录入框架，同时包含了一套风控系统，他更像一个架构，而不是一个实现，你同样可以通过简单的修改替换运用到okex，bybit等等上&lt;/p&gt; &#xA;&lt;p&gt;资金合作或者工作机会（不谈任何涉及策略原理和源码，请开门见山节省双方时间），请联系微信号 melelery 或邮件至&lt;a href=&#34;mailto:c.binance.quant@gmail.com&#34;&gt;c.binance.quant@gmail.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;模块详细解析&lt;/h1&gt; &#xA;&lt;p&gt;我方设计的模块包括 &lt;a href=&#34;https://raw.githubusercontent.com/Melelery/c-binance-future-quant/main/#%E9%80%9A%E7%94%A8%E9%83%A8%E5%88%86&#34;&gt;通用部分&lt;/a&gt; ，&lt;a href=&#34;https://raw.githubusercontent.com/Melelery/c-binance-future-quant/main/#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E9%83%A8%E5%88%86&#34;&gt;数据处理部分&lt;/a&gt; ，&lt;a href=&#34;https://raw.githubusercontent.com/Melelery/c-binance-future-quant/main/#%E5%85%B3%E9%94%AE%E6%93%8D%E4%BD%9C%E9%83%A8%E5%88%86&#34;&gt;关键操作部分&lt;/a&gt; ，&lt;a href=&#34;https://raw.githubusercontent.com/Melelery/c-binance-future-quant/main/#%E5%AE%89%E5%85%A8%E9%A3%8E%E6%8E%A7%E9%83%A8%E5%88%86&#34;&gt;安全风控部分&lt;/a&gt; ，以及没有开源的具体交易逻辑部分&lt;/p&gt; &#xA;&lt;p&gt;该项目的最小化开启需求为 一台web服务器，一台ws服务器，一台tick数据读取服务器，一台one min kline数据读取服务器，以及一台交易服务器&lt;/p&gt; &#xA;&lt;p&gt;你可以根据自己的需求，扩展相关的服务器，例如需要 15 m 的kline，需要trades等等，只需要在这个基础上增加即可，这里没有盘口数据的整合，除了买一卖一。&lt;/p&gt; &#xA;&lt;p&gt;如果你需要更高维度的盘口数据，建议是直接在交易服务器里面进行读取，因为除了kline数据，其他数据进行这种整合并没有太大的实际意义，200个交易对的kline数据，通过这种方式可以减少调用接口的频率，以及在某些接口有延迟的情况下依然能通过校对获得最新数据，但是盘口数据的api就一个，并没有这种需求。&lt;/p&gt; &#xA;&lt;p&gt;盘口数据的延迟只能通过交易服务器的分布式运行稍微解决，比如我方架设了五台交易服务器，运行着一样的开仓关仓逻辑，通过多台服务器的读取数据去避免一些情况下部分服务器读取不到或者延迟较大等意外情况。&lt;/p&gt; &#xA;&lt;p&gt;这里顺便引申出一个交易服务器发出订单的方式，有两种，一种是直接在交易服务器上发出，每台交易服务器承担平均的交易量，比方说我有五台交易服务器，我一个订单的交易量需求是100u，那么就每台服务器负责20u的交易量，如果延迟了或是其他问题，某一台服务器丢失了信号那就是损失20u的交易量，另外一个是做一个中心化的 trade 的web服务器，trade web服务器会以第一次收到交易服务器 发出的交易信号为开仓条件，第一次即开出100%的交易量，两种方式各有适用的地方和优势，需要自行抉择，实际上在webserver文件里面已经整合了第二种方式。&lt;/p&gt; &#xA;&lt;p&gt;我方实盘的项目运行环境为Ubuntu 22.04 64位，Python 3.10.6，由于项目使用的全部库和包都是官方或者热门的，在google可以查找到安装方式，此处不再累述如何安装环境，如果需要最简启动方案，可邮件 &lt;a href=&#34;mailto:c.binance.quant@gmail.com&#34;&gt;c.binance.quant@gmail.com&lt;/a&gt; 联系我方，直接共享系统镜像到你方阿里云账号，收取100 USDT的技术费用&lt;/p&gt; &#xA;&lt;p&gt;我方目前维护的实盘项目，具体服务器配置为，（服务器名即为开源的文件名）&lt;/p&gt; &#xA;&lt;p&gt;一台 wsPosition 服务器，用于通过ws的方式读取币安的仓位和余额数据，汇入ws数据撮合服务器&lt;/p&gt; &#xA;&lt;p&gt;一台positionRisk服务器，用于读取/fapi/v2/positionRisk接口，通过该接口获取仓位信息并实时判断损失，以便于及时止损，该服务器和wsPosition，makerStopLoss，getBinancePosition具备类似功能，之所以设计多种交叉相同功能的服务器，是为了最大限度的防止风险，在币安的某一接口出现延迟的情况下，系统依然可以健壮的运行，以下不再重述&lt;/p&gt; &#xA;&lt;p&gt;一台makerStopLoss服务器，用于从getBinancePosition服务器读取仓位信息后，读取单独的挂单信息，然后预设止损单，之所以与getBinancePosition服务器进行拆分，是因为读取挂单需要的权重较高，拆分成两个ip可以更高频率的进行操作&lt;/p&gt; &#xA;&lt;p&gt;一台getBinancePosition服务器，用于读取/fapi/v2/account接口，获得仓位信息和余额后汇入ws数据撮合服务器&lt;/p&gt; &#xA;&lt;p&gt;一台commission服务器，用于记录流水信息&lt;/p&gt; &#xA;&lt;p&gt;一台checkTimeoutOrders服务器，用于读取/fapi/v1/openOrders接口，查询全部挂单，然后取消超过一定时间的挂单，或者进行一些额外的操作，例如挂单三秒没被吃，则转换成take订单等等&lt;/p&gt; &#xA;&lt;p&gt;一台cancelServer服务器，本质上也是web server服务器，运行webServer文件，用于取消订单&lt;/p&gt; &#xA;&lt;p&gt;一台webServer服务器，本质上也是web server服务器，运行webServer文件，用于大部分程序一开始读取交易对等等&lt;/p&gt; &#xA;&lt;p&gt;两台oneMinKlineToWs服务器，用于低频率读取一分钟线的kline&lt;/p&gt; &#xA;&lt;p&gt;两台volAndRate服务器，用于读取交易量数据做分析并提供给其他服务器&lt;/p&gt; &#xA;&lt;p&gt;十台specialOneMinKlineToWs 服务器，用于高频率读取一分钟线的kline&lt;/p&gt; &#xA;&lt;p&gt;十台tickToWs服务器，用于读取 tick 群信息&lt;/p&gt; &#xA;&lt;p&gt;一台ws服务器，用于C++的数据戳合服务器&lt;/p&gt; &#xA;&lt;p&gt;以及五台交易服务器&lt;/p&gt; &#xA;&lt;p&gt;合计38台服务器，以及一台最低配置的mysql数据库，大部分只需要选用最低配置的抢占式服务器，实际情况下，对于开仓服务器和ws服务器，我购买了高主频类型的服务器，有一倍速度的提升，其他的行情和数据录取服务器并无必要进行这个优化，综合成本一个月不足3000元人民币，大头在流量费用，基本可以满足大部分量化的风控和延迟需求，个人认为上述数目对半砍依然可以满足大部分需求&lt;/p&gt; &#xA;&lt;p&gt;在该项目里，一个单独的模块，需要一台服务器一个IP单独运行，目前基本已经将单模块的https读取频率调教到币安允许的最大值。&lt;/p&gt; &#xA;&lt;p&gt;此处需要说明的是，这里都是以阿里云东京为例子，币安的服务器在亚马逊云东京。&lt;/p&gt; &#xA;&lt;p&gt;而本文所叙述的延迟，其实包含两种延迟，一是读取频率的延迟，二是网络的延迟，这两种延迟综合计算后，才是真实环境下的最终延迟。&lt;/p&gt; &#xA;&lt;p&gt;之所以使用阿里云是因为阿里云抢占式服务器具备成本优势，从而具备读取频率延迟的优势。&lt;/p&gt; &#xA;&lt;p&gt;阿里云网络延迟约为10ms，而亚马逊在不申请内网权限的情况下预计为1~3ms，申请内网则面临锁定ip的问题，即无法通过铺开更多ip的手段去降低延迟。&lt;/p&gt; &#xA;&lt;p&gt;虽然亚马逊云具备更低的延迟，但是由于&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;ws类型的数据读取通常被币安锁定100ms以上的延迟，且ws类型的读取数据具备某些不可确认的风险因素，所以该方式被排除&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;如果采取https读取的方式，某些数据的读取权重高达20，甚至是30，由此推演出需要多IP，进行分布式读取才能具备更高频率，而这个时候，单个IP的成本价格即成了需要考虑的因素，阿里云抢占式服务器的成本一个月不足20人民币，在综合的性价比考虑后，我方选择了日本阿里云。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;该方案并不是一套服务于高频（纳秒级别）交易的解决方案，否则全部都会用C++编写，实际上他是一套追求成本，延迟，开发速度，三者均衡最优解的方案，并为毫秒级别的策略服务&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;通用部分&lt;/h2&gt; &#xA;&lt;h3&gt;react_front文件夹&lt;/h3&gt; &#xA;&lt;p&gt;前端文件，该网页为对外网页，所以强制锁定了一分钟的时间间隔，展示的数据也比较简单，毕竟是对外的，我亦有设计内网详细的数据分析网站，但是这一部分不在此处披露。&lt;/p&gt; &#xA;&lt;p&gt;另外一提，交易后的数据处理，以及前端代码，都是以实现功能为主，所以并不注重性能等其他指标，可参考最下方faq&lt;/p&gt; &#xA;&lt;h3&gt;afterTrade文件夹&lt;/h3&gt; &#xA;&lt;p&gt;服务器如何更新到前端数据的文件，主要原理是利用阿里云oss作为中间件，隔离数据风险&lt;/p&gt; &#xA;&lt;p&gt;其中的tradesUpdate为更细trade记录，需要你在下单的时候先调用webServer的begin_trade_record接口插入交易数据&lt;/p&gt; &#xA;&lt;p&gt;请注意这个接口的设计是基于我自身的需求，因为每个人的量化模型，参数等不同，需要研究的也不一样，所以建议这一块自己重写&lt;/p&gt; &#xA;&lt;p&gt;positionRecord主要记录每分钟的账户余额和持仓价值 ，服务于下面的文件&lt;/p&gt; &#xA;&lt;p&gt;webOssUpdate会整理数据，上传到oss，web前端则从oss中读取数据，并且会整理交易流水记录，形成一个以天为单位的统计表格，该处只是简单的统计了盈利和手续费，你可以自行扩展。&lt;/p&gt; &#xA;&lt;h3&gt;binance_f文件夹&lt;/h3&gt; &#xA;&lt;p&gt;币安涉及到api key的接口的处理包，是从官方推荐的github下载后，进行了二次改造的版本&lt;/p&gt; &#xA;&lt;h3&gt;config.py&lt;/h3&gt; &#xA;&lt;p&gt;通用配置，需要自行配置mysql数据库，以及申请飞书api key等，亦可的替换成其他提醒工具&lt;/p&gt; &#xA;&lt;h3&gt;commonFunction.py&lt;/h3&gt; &#xA;&lt;p&gt;通用方法&lt;/p&gt; &#xA;&lt;h3&gt;updateSymbol/trade_symbol.sql&lt;/h3&gt; &#xA;&lt;p&gt;在数据库中生成trade_symbol表格，该表格将控制系统可执行交易的交易对信息，你也可以改造为录入文件中并从文件中读取&lt;/p&gt; &#xA;&lt;h3&gt;updateSymbol/updateTradeSymbol.sql&lt;/h3&gt; &#xA;&lt;p&gt;向trade_symbol表格录入交易对信息，此处进行了一些特殊处理，主要是适应我方的情况，包括只录入usdt的交易对，不录入指数类型的交易对（如btcdom，football这类型），此处部分字段为配合专业手操工具而设计，用于量化的数据字段实际上只有symbol，status&lt;/p&gt; &#xA;&lt;h3&gt;simpleTrade&lt;/h3&gt; &#xA;&lt;p&gt;一个最基础的交易演示程序，当某个交易对，持仓价值为0且一分钟涨幅&amp;gt;1%的时候开多，当他持仓价值&amp;gt;0且一分钟跌幅小于-0.5%平多，如果你是新手，建议关注updateSymbolInfo()这个函数，价格精度，数量精度，最大平仓数量应该是新手会遇到最多的问题。&lt;/p&gt; &#xA;&lt;h2&gt;数据处理部分&lt;/h2&gt; &#xA;&lt;h3&gt;wsServer.cpp&lt;/h3&gt; &#xA;&lt;p&gt;撮合服务器&lt;/p&gt; &#xA;&lt;p&gt;所有的数据都会汇入这里，部分多来源数据会根据数据自带的更新时间戳判断是否更新该条数据，使用以下命令行可编译成可执行文件&lt;/p&gt; &#xA;&lt;p&gt;g++ wsServer.cpp -o wsServer.out -lboost_system&lt;/p&gt; &#xA;&lt;p&gt;该源码使用了两个库 一个是websocketpp，一个是boost&lt;/p&gt; &#xA;&lt;h3&gt;dataPy/uploadDataPy&lt;/h3&gt; &#xA;&lt;p&gt;将程序从一个阿里云的主控服务器，上传到各个对应的阿里云服务器，运行，然后销毁。&lt;/p&gt; &#xA;&lt;p&gt;这里只展示tick，oneMinKlineToWs，specialOneMinKlineToWs三个数据录入程序的使用，其他程序亦同理&lt;/p&gt; &#xA;&lt;p&gt;该程序可以简单快速的发布分布式运行的程序，到所有符合命名规则的服务器上云运行和销毁。&lt;/p&gt; &#xA;&lt;p&gt;使用前需要将阿里云服务器进行统一命名，如tickToWs_1,tickToWs_2...&lt;/p&gt; &#xA;&lt;p&gt;使用前先从本地上传文件到某一个主控服务器，然后在主控服务器运行该程序，正常运行后，包括主控服务器和实际运行的服务器上的所有硬盘应都被覆盖掉源文件的信息。&lt;/p&gt; &#xA;&lt;p&gt;程序会调用get_aliyun_private_ip_arr_by_name函数，搜索对应字符段的阿里云服务器的私网地址，然后上传，执行，并且在三秒后判断有没有在正常运行&lt;/p&gt; &#xA;&lt;p&gt;如正常运行，则其后会对硬盘数据进行覆盖销毁，防止机密数据泄露，只保留程序在内存运行&lt;/p&gt; &#xA;&lt;p&gt;由于是私网地址的操作，需要在同地域的阿里云服务器上执行该程序&lt;/p&gt; &#xA;&lt;h3&gt;dataPy/oneMinKlineToWs.py&lt;/h3&gt; &#xA;&lt;p&gt;该程序属于分布式运行架构，只需要标准化命名即可无限扩展服务器降低延迟 &lt;img src=&#34;https://github.com/Melelery/c-binance-future-quant/assets/139823868/801409a3-25b7-41c8-b795-d7aa0efd0fe6&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;缓更新的1分钟的K线数据读取程序&lt;/p&gt; &#xA;&lt;p&gt;每次程序运行的时候，会像ws服务器发送目前交易对的总数，每次读取kline数据前，会从ws服务器拿到一个交易对编号，拿取的同时，ws服务器会对编号执行 +1的操作，确保分布式架构的时候，每台扩展oneMinKlineToWs都可以按照最佳顺序读取交易对的kline数据。&lt;/p&gt; &#xA;&lt;p&gt;由于币安的k线数据更新延迟略高于tick数据，k线数据来源于数据库，而tick数据来源于缓存，同时，单symbol的延迟会低于全部交易对信息，所以每次更新前还会再读取一次交易对单独的tick数据去校正最后一条k线数据&lt;/p&gt; &#xA;&lt;p&gt;kline数据会向ws服务器发送两次数据，一次是所有读取到的数据，比如说读取kline的时候，设置limit=45，即读取了最近45条kline的数据，但很显然，前面43条的数据是一直不变的，所以交易服务器只需要长时间（30秒/1分钟...）去校正一次即可，只有最新的两条数据的变化概率是大的，需要实时的去读取。&lt;/p&gt; &#xA;&lt;p&gt;所以我拆分成了两条信息，一个是前两段kline，一个是全部kline，前两段kline用于交易服务器实时读取，实时更新，后面两端则用于一定时间间隔后的校对。&lt;/p&gt; &#xA;&lt;p&gt;缩减消息的长度对于交易服务器解析消息所用的时间有极大的帮助。&lt;/p&gt; &#xA;&lt;p&gt;其他时间间隔的k线，如5分钟 ，15分钟，1小时等等读取和打入ws服务器的过程亦同理，只需要简单的替换文件中的参数即可实现，所以此处不再列出&lt;/p&gt; &#xA;&lt;h3&gt;dataPy/specialOneMinKlineToWs.py&lt;/h3&gt; &#xA;&lt;p&gt;该程序属于分布式运行架构，只需要标准化命名即可无限扩展服务器降低延迟&lt;/p&gt; &#xA;&lt;p&gt;急速更新的1分钟的K线数据读取程序&lt;/p&gt; &#xA;&lt;p&gt;与上面不同的是，此处的读取数据有一个前置的交易量条件，你可以理解为我的量化系统只有满足某个交易量条件的要求时候才会开仓，所以针对这一部分可能开仓的交易对，铺设了专门读取数据的服务器。&lt;/p&gt; &#xA;&lt;p&gt;假设本来有200个交易对轮流读取，限制条件后，变成了20个交易对，那么等于你单个机器的数据读取数据提高了10倍&lt;/p&gt; &#xA;&lt;p&gt;这个只是一个展示程序，实际上你应该根据你的交易条件去自己编写相应的条件，限制数据读取的交易对。&lt;/p&gt; &#xA;&lt;p&gt;其他时间间隔的k线，如5分钟 ，15分钟，1小时等等读取和打入ws服务器的过程亦同理，只需要简单的替换文件中的参数即可实现，所以此处不再列出&lt;/p&gt; &#xA;&lt;h3&gt;dataPy/tickToWs.py&lt;/h3&gt; &#xA;&lt;p&gt;该程序属于分布式运行架构，只需要标准化命名即可无限扩展服务器降低延迟&lt;/p&gt; &#xA;&lt;p&gt;tick数据读取程序会读取阿里云上，所有的tick服务器数量，然后自动锁定该服务器在一秒内的某个时间段内去进行数据读取&lt;/p&gt; &#xA;&lt;p&gt;打个比方，现在我们开通了五台tick服务器，那么tick 1服务器会在每一秒的&amp;gt;=0 &amp;lt;200毫秒的时间段内去读取数据，tick 2会在每一秒的&amp;gt;=200 &amp;lt;400毫秒的时间段内去读取数据...以此类推&lt;/p&gt; &#xA;&lt;p&gt;tick数据在汇入ws服务器后，交易程序读取这部分主要用于修正最新一条kline的最高价格，最低价格和最新价格。&lt;/p&gt; &#xA;&lt;h3&gt;dataPy/useData.py&lt;/h3&gt; &#xA;&lt;p&gt;展示了如何从ws服务器拿取one min kline数据和tick数据后，如何在本地端自行拼合，维护一个k线数据，此处还可以扩展到加入trade vol等数据，原理相同所以不再展示&lt;/p&gt; &#xA;&lt;h2&gt;关键操作部分&lt;/h2&gt; &#xA;&lt;h3&gt;binanceOrdersRecord.py&lt;/h3&gt; &#xA;&lt;p&gt;记录orders信息，方便后续分析，例如可以通过orders的记录分析出发出去的订单的总成交比例等等&lt;/p&gt; &#xA;&lt;h3&gt;binanceTradesRecord.py&lt;/h3&gt; &#xA;&lt;p&gt;记录trades信息，方便后续分析，例如可以通过trades计算出总交易量等等&lt;/p&gt; &#xA;&lt;h3&gt;checkTimeoutOrders.py&lt;/h3&gt; &#xA;&lt;p&gt;检查是否有超时订单并取消，同时可以附加一些交易操作，如maker挂单超过多少秒没有成交则按比例转化成take订单&lt;/p&gt; &#xA;&lt;p&gt;由于需要调用币安获取全部挂单的api，而该api权重极高，为了满足更加灵敏的扫描，我的五个交易服务器同时运行有webserver程序，checkTimeoutOrders会轮流从五个交易服务器读取全部挂单信息&lt;/p&gt; &#xA;&lt;h3&gt;commission.py&lt;/h3&gt; &#xA;&lt;p&gt;记录所有资金流水，这个是最重要的数据，通过他可以计算出手续费，盈利，资金费用等等数据&lt;/p&gt; &#xA;&lt;p&gt;由于commission长时间积累的数据量大，所以这里有两个表，一个是持续记录的表，一个是24小时临时记录的表。&lt;/p&gt; &#xA;&lt;p&gt;24小时记录的临时表主要用于分析最近一天的亏损情况，从而给交易系统进行风险控制&lt;/p&gt; &#xA;&lt;p&gt;比如以下这段代码&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;for key in fourHoursProfitObj:&#xA;    if fourHoursProfitObj[key]&amp;lt;=-150 or oneDayProfitObj[key]&amp;lt;=-1800:&#xA;        banSymbolArr.append(key)&#xA;&#xA;if allOneDayProfit&amp;lt;=-3000:&#xA;    banSymbolArr = [&#34;ALL&#34;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;当读取到某个交易对四小时盈利小于150u或者24小时利润小于1800u时，会向ws服务器发送一个禁止交易的交易对列表，当所有交易对总利润小于-3000u时，则直接全部暂停交易&lt;/p&gt; &#xA;&lt;h3&gt;getBinancePosition.py&lt;/h3&gt; &#xA;&lt;p&gt;通过/fapi/v2/account接口获取币安仓位和余额信息，并且上传到本服务器的80端口，以及ws服务，上传到ws服务器的信息，会与positionRisk和wsPosition拿到信息的更新时间戳进行对比，选择最新的信息发送给交易服务器，本地80端口的json文件为旧版本使用的方案，其他服务器会通过80端口读取json文件获取数据，后面采用了ws但是这里保留下来了，也算是一个额外的采集方案&lt;/p&gt; &#xA;&lt;h3&gt;positionRisk.py&lt;/h3&gt; &#xA;&lt;p&gt;通过/fapi/v2/positionRisk接口获取币安仓位和余额信息，其他同上&lt;/p&gt; &#xA;&lt;h3&gt;wsPosition.py&lt;/h3&gt; &#xA;&lt;p&gt;通过websocket接口获取币安仓位和余额信息，其他同上&lt;/p&gt; &#xA;&lt;h3&gt;makerStopLoss&lt;/h3&gt; &#xA;&lt;p&gt;读取ws服务器读取仓位信息后，读取该币种的币安接口挂单信息，之所以不采用所有symbol的挂单信息，是因为权重太高，会导致止损过于迟钝。&lt;/p&gt; &#xA;&lt;p&gt;在仓位最大值发生超过5%变化的同时，挂出最大止损单，演示文件的写法，是以成本价5%为初始止损价格，并且拆分成五单，每单往后增加0.5%的价格进行止损，防止深度的影响&lt;/p&gt; &#xA;&lt;p&gt;例：现在仓位是1000u，已有止损单，那么当仓位增加到1001u的时候，该系统不会重设止损，因为不满足数量变化&amp;gt;5%的情况，太过灵敏的重设会到权重消耗等等问题&lt;/p&gt; &#xA;&lt;p&gt;如增加到1060u，那么会重新设定五个止损单，初始止损价格为成本价的5%，后续每个止损单依次为5.5%,6%,6.5%,7%,&lt;/p&gt; &#xA;&lt;p&gt;新止损设置完后，系统会读取挂单检查是否成功，确认成功后，才会撤销旧的止损单。&lt;/p&gt; &#xA;&lt;h2&gt;安全风控部分&lt;/h2&gt; &#xA;&lt;p&gt;由于程序源码会带有敏感信息，建议采用dataPy/uploadDataPy的上传方式，统一进行文件的上传，运行，销毁，实现最终只在内存中运行，而覆盖硬盘所有储存的程序信息的目的，仅在本地段保有源码。&lt;/p&gt; &#xA;&lt;p&gt;建议关闭阿里云所有对外的端口，在购买服务器的时候选中将所有服务器置于统一私网前缀IP下，这样即可在关闭外网端口的同时实现功能正常运转和互通，如没有在统一私网前缀IP下，则需要添加对应的私网IP到部分服务器的安全组内&lt;/p&gt; &#xA;&lt;p&gt;在需要操作服务器的时候，再将本地的IP添加到安全组内，并且使用完后即时删除&lt;/p&gt; &#xA;&lt;p&gt;建议币安的api绑定服务器的IP&lt;/p&gt; &#xA;&lt;p&gt;建议保持操作系统的更新&lt;/p&gt; &#xA;&lt;h1&gt;FAQ&lt;/h1&gt; &#xA;&lt;h2&gt;1.为什么不用历史数据先回测&lt;/h2&gt; &#xA;&lt;p&gt;事实上我个人探究量化实打实算起来已经有三年。&lt;/p&gt; &#xA;&lt;p&gt;以历史数据回测后拟合一条折线出来的方式并不是没有尝试过。&lt;/p&gt; &#xA;&lt;p&gt;但是回测的环境要做到与实盘一致的难度可能超过了目前大部分人的估计，我说的一致是绝对的一致，任何一点小差异其实都会在整个过程被放大到最后让你无法接受的程度。&lt;/p&gt; &#xA;&lt;p&gt;并且存在一个无法验证到底是误差还是策略造成的损益差异的问题。&lt;/p&gt; &#xA;&lt;p&gt;因为很可能到你结束项目，还存在数十个你没有发现的误差的地方，而且不具备量化判断这些误差造成损益的可能性。&lt;/p&gt; &#xA;&lt;p&gt;当然这是以我的能力和视角得出的结论。&lt;/p&gt; &#xA;&lt;p&gt;所以自最近半年起，我的思路都是直接上实盘，哪怕是小资金验证后，以实盘的数据为基础去调参&lt;/p&gt; &#xA;&lt;h2&gt;2.部分存在性能改进的可能性&lt;/h2&gt; &#xA;&lt;p&gt;是的，因为这个是一个个人项目，我要负责的事情非常多。&lt;/p&gt; &#xA;&lt;p&gt;所以对于一些不需要追求性能的地方，我都会用最简单的写法带过。&lt;/p&gt; &#xA;&lt;p&gt;比如说orders，trades这些录入数据库是拿最近1000条数据出来比较，没有重复的就插入，这里当然存在性能更优解的写法，但是在我看来意义不大所以我没有花时间去改进。&lt;/p&gt; &#xA;&lt;p&gt;为什么意义不大，因为我用最低配的mysql整套系统运行的过程中cpu和内存的使用比例也没有超过50%。&lt;/p&gt; &#xA;&lt;p&gt;我大部分精力关注在数据录入，交易的性能优化，而忽略交易后数据拉取分析这一块的优化，这一块只要最后的结果是对的即可。&lt;/p&gt; &#xA;&lt;p&gt;交易后的过程，消耗了1个性能还是100个性能，只要没有达到我硬件的峰值，我都不会去寻求改变&lt;/p&gt;</summary>
  </entry>
</feed>