<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-01-14T01:28:09Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>automatisch/automatisch</title>
    <updated>2025-01-14T01:28:09Z</updated>
    <id>tag:github.com,2025-01-14:/automatisch/automatisch</id>
    <link href="https://github.com/automatisch/automatisch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The open source Zapier alternative. Build workflow automation without spending time and money.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Automatisch - Open Source Zapier Alternative&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/2501931/191562539-e42f6c34-03c7-4dc4-bcf9-7f9473a9c64f.png&#34; alt=&#34;Automatisch - Screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;üßê Automatisch is a business automation tool that lets you connect different services like Twitter, Slack, and more to automate your business processes.&lt;/p&gt; &#xA;&lt;p&gt;üí∏ Automating your workflows doesn&#39;t have to be a difficult or expensive process. You also don&#39;t need any programming knowledge to use Automatisch.&lt;/p&gt; &#xA;&lt;h2&gt;Advantages&lt;/h2&gt; &#xA;&lt;p&gt;There are other existing solutions in the market, like Zapier and Integromat, so you might be wondering why you should use Automatisch.&lt;/p&gt; &#xA;&lt;p&gt;‚úÖ One of the main benefits of using Automatisch is that it allows you to store your data on your own servers, which is essential for businesses that handle sensitive user information and cannot risk sharing it with external cloud services. This is especially relevant for industries such as healthcare and finance, as well as for European companies that must adhere to the General Data Protection Regulation (GDPR).&lt;/p&gt; &#xA;&lt;p&gt;ü§ì Your contributions are vital to the development of Automatisch. As an open-source software, anyone can have an impact on how it is being developed.&lt;/p&gt; &#xA;&lt;p&gt;üíô No vendor lock-in. If you ever decide that Automatisch is no longer helpful for your business, you can switch to any other provider, which will be easier than switching from the one cloud provider to another since you have all data and flexibility.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;The official documentation can be found here: &lt;a href=&#34;https://automatisch.io/docs&#34;&gt;https://automatisch.io/docs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Clone the repository&#xA;git clone https://github.com/automatisch/automatisch.git&#xA;&#xA;# Go to the repository folder&#xA;cd automatisch&#xA;&#xA;# Start&#xA;docker compose up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can use &lt;code&gt;user@automatisch.io&lt;/code&gt; email address and &lt;code&gt;sample&lt;/code&gt; password to login to Automatisch. Please do not forget to change your email and password from the settings page.&lt;/p&gt; &#xA;&lt;p&gt;For other installation types, you can check the &lt;a href=&#34;https://automatisch.io/docs/guide/installation&#34;&gt;installation&lt;/a&gt; guide.&lt;/p&gt; &#xA;&lt;h2&gt;Community Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.gg/dJSah9CVrC&#34;&gt;Discord&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/automatischio&#34;&gt;Twitter&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions or problems, please visit our GitHub issues page, and we&#39;ll try to help you as soon as possible.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/automatisch/automatisch/issues&#34;&gt;https://github.com/automatisch/automatisch/issues&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Automatisch Community Edition (Automatisch CE) is an open-source software with the &lt;a href=&#34;https://raw.githubusercontent.com/automatisch/automatisch/main/LICENSE.agpl&#34;&gt;AGPL-3.0 license&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Automatisch Enterprise Edition (Automatisch EE) is a commercial offering with the &lt;a href=&#34;https://raw.githubusercontent.com/automatisch/automatisch/main/LICENSE.enterprise&#34;&gt;Enterprise license&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The Automatisch repository contains both AGPL-licensed and Enterprise-licensed files. We maintain a single repository to make development easier.&lt;/p&gt; &#xA;&lt;p&gt;All files that contain &#34;.ee.&#34; in their name fall under the &lt;a href=&#34;https://raw.githubusercontent.com/automatisch/automatisch/main/LICENSE.enterprise&#34;&gt;Enterprise license&lt;/a&gt;. All other files fall under the &lt;a href=&#34;https://raw.githubusercontent.com/automatisch/automatisch/main/LICENSE.agpl&#34;&gt;AGPL-3.0 license&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/automatisch/automatisch/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for more information.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>kevmo314/scuda</title>
    <updated>2025-01-14T01:28:09Z</updated>
    <id>tag:github.com,2025-01-14:/kevmo314/scuda</id>
    <link href="https://github.com/kevmo314/scuda" rel="alternate"></link>
    <summary type="html">&lt;p&gt;SCUDA is a GPU over IP bridge allowing GPUs on remote machines to be attached to CPU-only machines.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SCUDA: GPU-over-IP&lt;/h1&gt; &#xA;&lt;p&gt;SCUDA is a GPU over IP bridge allowing GPUs on remote machines to be attached to CPU-only machines.&lt;/p&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;h3&gt;CUBLAS Matrix Multiplication using Unified Memory&lt;/h3&gt; &#xA;&lt;p&gt;The below demo displays a NVIDIA GeForce RTX 4090 running on a remote machine (right pane). Left pane is a Mac running a docker container with nvidia utils installed.&lt;/p&gt; &#xA;&lt;p&gt;The docker container runs this &lt;a href=&#34;https://raw.githubusercontent.com/kevmo314/scuda/main/test/cublas_unified.cu&#34;&gt;matrixMulCUBLAS&lt;/a&gt; example. This example not only uses cuBLAS, but also takes advantage of unified memory.&lt;/p&gt; &#xA;&lt;p&gt;You can view the docker image used &lt;a href=&#34;https://raw.githubusercontent.com/kevmo314/scuda/main/deploy/Dockerfile.unified&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/b2db5d82-f214-41cf-8274-b913c04080f9&#34;&gt;https://github.com/user-attachments/assets/b2db5d82-f214-41cf-8274-b913c04080f9&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can see a list of some currently working examples in the &lt;a href=&#34;https://raw.githubusercontent.com/kevmo314/scuda/main/test/&#34;&gt;test folder&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Local development&lt;/h2&gt; &#xA;&lt;p&gt;Building the binaries requires running codegen first. Scuda codegen reads the cuda dependency header files in order to generate rpc calls.&lt;/p&gt; &#xA;&lt;p&gt;To ensure codegen works properly, the proper cuda packages need to be installed on your OS. Take a look at our &lt;a href=&#34;https://raw.githubusercontent.com/kevmo314/scuda/main/Dockerfile.build&#34;&gt;Dockerfile&lt;/a&gt; to see an example.&lt;/p&gt; &#xA;&lt;p&gt;Codegen requires cuBLAS, cuDNN, NVML, etc:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;cudnn_graph_header = find_header_file(&#34;cudnn_graph.h&#34;)&#xA;cudnn_ops_header   = find_header_file(&#34;cudnn_ops.h&#34;)&#xA;cuda_header        = find_header_file(&#34;cuda.h&#34;)&#xA;cublas_header      = find_header_file(&#34;cublas_api.h&#34;)&#xA;cudart_header      = find_header_file(&#34;cuda_runtime_api.h&#34;)&#xA;annotations_header = find_header_file(&#34;annotations.h&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run codegen&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd codegen &amp;amp;&amp;amp; python3 ./codegen.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Ensure there are no errors in the output of the codegen.&lt;/p&gt; &#xA;&lt;h3&gt;Run cmake&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cmake .&#xA;cmake --build .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Cmake will generate a server and a client file depending on your cuda version.&lt;/p&gt; &#xA;&lt;p&gt;Example: &lt;code&gt;libscuda_12_0.so&lt;/code&gt;, &lt;code&gt;server_12_0.so&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;It&#39;s required to run scuda server before initiating client commands.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./local.sh server&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The above command will grep for the generated libscuda + server files. You can also run the binaries directly.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./server_12_0.so&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If successful, the server will start:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Server listening on port 14833...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running the client&lt;/h2&gt; &#xA;&lt;p&gt;Scuda requires you to preload the libscuda binary before executing any cuda commands.&lt;/p&gt; &#xA;&lt;p&gt;Once the server above is running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# update to your desired IP/port&#xA;export SCUDA_SERVER=0.0.0.0&#xA;&#xA;LD_PRELOAD=./libscuda_12_0.so python3 -c &#34;import torch; print(torch.cuda.is_available())&#34;&#xA;&#xA;# or&#xA;&#xA;LD_PRELOAD=./libscuda_12_0.so nvidia-smi&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also use the local shell script to run your commands.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./local.sh run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Motivations&lt;/h2&gt; &#xA;&lt;p&gt;The goal of SCUDA is to enable developers to easily interact with GPUs over a network in order to take advantage of various pools of distributed GPUs. Obviously TCP is slower than traditional methods, but we have plans to minimize performance impact through various methods.&lt;/p&gt; &#xA;&lt;h3&gt;Some use cases / motivations:&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Local testing&lt;/strong&gt; - For testing purposes, the latency added by TCP is acceptable, as the goal is to verify compatibility and performance rather than achieving the lowest latency. The remote GPU can still fully accelerate the application, allowing a developer to run tests they otherwise couldn‚Äôt on their local setup.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Aggregated GPU pools&lt;/strong&gt; - The goal is to centralize GPU management and resource allocation, making it easier to deploy and scale containerized applications that need GPU support without worrying about GPU availability. SCUDA will eventually handle capacity management and pooling.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Remote model training&lt;/strong&gt; - Developers can train models from their laptops or low-power devices, using GPUs optimized for training without needing to deploy a full VM or move the entire development environment to the remote location.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Remote inferencing&lt;/strong&gt; - For remote inferencing, devs can set up their application locally but direct all CUDA calls for model inference to a remote GPU server. The application can thus process large batches of images or video frames using the remote GPU‚Äôs acceleration capabilities.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Remote data processing&lt;/strong&gt; - Developers can run operations like filtering, joining, and aggregating data directly on the remote GPU, while the results are transferred back over the network. Technically, developers can accelerate matrix multiplication or linear algebra computations on large datasets by offloading these computations to a remote GPU; they can run their scripts locally while utilizing the power of a remote machine.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Remote fine-tuning&lt;/strong&gt; - Developers can download a pre-trained model (ex: resnet) and fine-tune it. With SCUDA, training is done remotely using the library to route PyTorch CUDA calls over TCP to a remote GPU, allowing the developer to run the fine-tuning process from their local machine or Jupyter Notebook environment.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Future goals:&lt;/h2&gt; &#xA;&lt;p&gt;See our &lt;a href=&#34;https://raw.githubusercontent.com/kevmo314/scuda/main/TODO.md&#34;&gt;TODO&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Prior Art&lt;/h2&gt; &#xA;&lt;p&gt;This project is inspired by some existing proprietary solutions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.thundercompute.com/&#34;&gt;https://www.thundercompute.com/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.juicelabs.co/&#34;&gt;https://www.juicelabs.co/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/RCUDA&#34;&gt;https://en.wikipedia.org/wiki/RCUDA&lt;/a&gt; (That&#39;s where SCUDA&#39;s name comes from, S is the next letter after R!)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Benchmarks&lt;/h2&gt; &#xA;&lt;p&gt;todo&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>mylinuxforwork/dotfiles</title>
    <updated>2025-01-14T01:28:09Z</updated>
    <id>tag:github.com,2025-01-14:/mylinuxforwork/dotfiles</id>
    <link href="https://github.com/mylinuxforwork/dotfiles" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The ML4W Dotfiles for Hyprland - An advanced and full-featured configuration for the dynamic tiling window manager Hyprland including an easy to use installation script for Arch and Fedora based Linux distributions.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ML4W Dotfiles for Hyprland&lt;/h1&gt; &#xA;&lt;p&gt;An advanced configuration of Hyprland for Arch Linux based distributions. This package includes an installation script to install and setup the required components.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/1b7fec1f-d864-4017-815c-103d657e3686&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;About the screenshot: The dock can be enabled in the Dotfiles Settings app. The waybar theme is ML4W Modern Light.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;YouTube Video &lt;a href=&#34;https://youtu.be/siy2vL94yd0&#34;&gt;https://youtu.be/siy2vL94yd0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Recommendation&lt;/h2&gt; &#xA;&lt;p&gt;I recommend to install a base Hyprland system before installing the ML4W Hyprland Dotfiles. Then you have a stable starting point and can test Hyprland on your system before. Hyprland is complex, under ongoing development and requires additional components.&lt;/p&gt; &#xA;&lt;p&gt;You can find the Hyprland Installation instructions here: &lt;a href=&#34;https://wiki.hyprland.org/Getting-Started/Installation/&#34;&gt;https://wiki.hyprland.org/Getting-Started/Installation/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;The installation should work on all Arch Linux and Fedora based distributions (&amp;gt;2.9.7.0). &lt;a href=&#34;https://github.com/mylinuxforwork/dotfiles/wiki&#34;&gt;You can find more information here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;PLEASE NOTE: Every Linux distribution, setup and personal configuration can be different. Therefore, I cannot guarantee that the ML4W Dotfiles will work everywhere. You can install this at your own risk.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Please make sure that your system is up-to-date.&lt;/p&gt; &#xA;&lt;h3&gt;Arch Linux (based)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;bash &amp;lt;(curl -s https://raw.githubusercontent.com/mylinuxforwork/dotfiles/main/setup-arch.sh)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also install the main release with your preferred AUR helper.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;yay -S ml4w-hyprland&#xA;ml4w-hyprland-setup&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can install the rolling release with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;yay -S ml4w-hyprland-git&#xA;ml4w-hyprland-setup&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please rebuild all packages to ensure that you get the latest commit.&lt;/p&gt; &#xA;&lt;h3&gt;Fedora Linux (based)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;bash &amp;lt;(curl -s https://raw.githubusercontent.com/mylinuxforwork/dotfiles/main/setup-fedora.sh)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Troubleshooting&lt;/h2&gt; &#xA;&lt;p&gt;You can find solutions to common issues in the Wiki troubleshooting section: &lt;a href=&#34;https://github.com/mylinuxforwork/dotfiles/wiki/Troubleshooting&#34;&gt;https://github.com/mylinuxforwork/dotfiles/wiki/Troubleshooting&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Documentation (Wiki)&lt;/h2&gt; &#xA;&lt;p&gt;You can find the complete documentation of the ML4W Dotfiles in the Wiki. &lt;b&gt;&lt;a href=&#34;https://github.com/mylinuxforwork/dotfiles/wiki&#34;&gt;Open the Wiki here&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Thanks for using the ML4W Dotfiles on your system. If you find a problem or a bug, please &lt;a href=&#34;https://github.com/mylinuxforwork/dotfiles/issues&#34;&gt;report your issue on this page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can also visit the &lt;a href=&#34;https://discord.gg/c4fJK7Za3g&#34;&gt;ML4W Discord Server&lt;/a&gt; to start a discussion with other users.&lt;/p&gt; &#xA;&lt;h2&gt;Screenshots&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/47ed1ae0-a660-46f3-9bf5-917da0d3f675&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Wallpaper repository&lt;/h2&gt; &#xA;&lt;p&gt;You can find my wallpaper collection in the repository &lt;a href=&#34;https://github.com/mylinuxforwork/wallpaper&#34;&gt;https://github.com/mylinuxforwork/wallpaper&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Special Thanks&lt;/h2&gt; &#xA;&lt;p&gt;THANK YOU very much for all your support, contributions and ideas:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Tattwamashi Nayak: &lt;a href=&#34;https://github.com/ElectroPerf&#34;&gt;https://github.com/ElectroPerf&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Filippo Aceto: &lt;a href=&#34;https://gitlab.com/filippoaceto&#34;&gt;https://gitlab.com/filippoaceto&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Don Williams: &lt;a href=&#34;https://github.com/dwilliam62&#34;&gt;https://github.com/dwilliam62&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Diana Ward: &lt;a href=&#34;https://github.com/dianaw353&#34;&gt;https://github.com/dianaw353&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Leo: &lt;a href=&#34;https://github.com/eljejer&#34;&gt;https://github.com/eljejer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Guido De Gobbis&lt;/li&gt; &#xA; &lt;li&gt;Teodor Orzechowski: &lt;a href=&#34;https://gitlab.com/sq6gtt&#34;&gt;https://gitlab.com/sq6gtt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Jamie Deppeler: &lt;a href=&#34;https://gitlab.com/bknight2k&#34;&gt;https://gitlab.com/bknight2k&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Yingjie Wang: &lt;a href=&#34;https://gitlab.com/GaugeAndGravity&#34;&gt;https://gitlab.com/GaugeAndGravity&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Daniel Gerber: &lt;a href=&#34;https://gitlab.com/dan.john.gerber&#34;&gt;https://gitlab.com/dan.john.gerber&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Sarthak Siddhpura: &lt;a href=&#34;https://gitlab.com/Codesmith28&#34;&gt;https://gitlab.com/Codesmith28&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gitlab.com/muee&#34;&gt;https://gitlab.com/muee&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;and many more...&lt;/p&gt; &#xA;&lt;p&gt;Thanks to all YouTube subscribers for all your great feedback.&lt;/p&gt; &#xA;&lt;h2&gt;Inspirations&lt;/h2&gt; &#xA;&lt;p&gt;The following projects have inspired me:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/JaKooLit/Hyprland-Dots&#34;&gt;https://github.com/JaKooLit/Hyprland-Dots&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/prasanthrangan/hyprdots&#34;&gt;https://github.com/prasanthrangan/hyprdots&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sudo-harun/dotfiles&#34;&gt;https://github.com/sudo-harun/dotfiles&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dianaw353/hyprland-configuration-rootfs&#34;&gt;https://github.com/dianaw353/hyprland-configuration-rootfs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;and many more...&lt;/p&gt;</summary>
  </entry>
</feed>