<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-15T02:40:31Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>NVIDIAGameWorks/dxvk-remix</title>
    <updated>2023-04-15T02:40:31Z</updated>
    <id>tag:github.com,2023-04-15:/NVIDIAGameWorks/dxvk-remix</id>
    <link href="https://github.com/NVIDIAGameWorks/dxvk-remix" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;dxvk-remix&lt;/h1&gt; &#xA;&lt;p&gt;dxvk-remix is a fork of the &lt;a href=&#34;https://github.com/doitsujin/dxvk&#34;&gt;DXVK&lt;/a&gt; project, which overhauls the fixed-function graphics pipeline implementation in order to remaster games with path tracing.&lt;/p&gt; &#xA;&lt;p&gt;Thanks to all the contributors to DXVK for creating this foundational piece of software, on top of which we were able to build the RTX Remix Runtime.&lt;/p&gt; &#xA;&lt;p&gt;While dxvk-remix is a fork of DXVK, please report bugs encountered with dxvk-remix to this repo rather than to the DXVK project.&lt;/p&gt; &#xA;&lt;h2&gt;Build instructions&lt;/h2&gt; &#xA;&lt;h3&gt;Requirements:&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Windows 10 or 11&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://visualstudio.microsoft.com/vs/older-downloads/&#34;&gt;Visual Studio &lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;VS 2019 is tested&lt;/li&gt; &#xA;   &lt;li&gt;VS 2022 may also work, but it is not actively tested&lt;/li&gt; &#xA;   &lt;li&gt;Note that our build system will always use the most recent version available on the system&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developer.microsoft.com/en-us/windows/downloads/sdk-archive/&#34;&gt;Windows SDK&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;10.0.19041.0 is tested&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mesonbuild.com/&#34;&gt;Meson&lt;/a&gt; - v0.61.4 has been tested, latest version should work &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Follow &lt;a href=&#34;https://mesonbuild.com/SimpleStart.html#installing-meson&#34;&gt;instructions&lt;/a&gt; on how to install and reboot the PC before moving on (Meson will indicate as much)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://vulkan.lunarg.com/sdk/home#windows&#34;&gt;Vulkan SDK&lt;/a&gt; - 1.3.211.0 or newer &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;You may need to uninstall previous SDK if you have an old version&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;Python&lt;/a&gt; - version 3.9 or newer&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h4&gt;Additional notes:&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If any dependency paths change (i.e. new Vulkan library), run &lt;code&gt;meson --reconfigure&lt;/code&gt; in _Compiler64 directory via a command prompt. This may revert some custom VS project settings&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Generate and build dxvk-remix Visual Studio project&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Clone the repository with all submodules:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;git clone --recursive https://github.com/NVIDIAGameWorks/dxvk-remix.git&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;If the clone was made non-recursively and the submodules are missing, clone them separately:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;git submodule update --init --recursive&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install all the &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIAGameWorks/dxvk-remix/main/#requirements&#34;&gt;requirements&lt;/a&gt; before proceeding further&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Make sure PowerShell scripts are enabled&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;One-time system setup: run &lt;code&gt;Set-ExecutionPolicy -ExecutionPolicy RemoteSigned&lt;/code&gt; in an elevated PowerShell prompt, then close and reopen any existing PowerShell prompts&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To generate and build dxvk-remix project, open a command prompt and run&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;powershell -command &#34;&amp;amp; .\build_dxvk_all_ninja.ps1&#34;&lt;/code&gt;&lt;/li&gt; &#xA;   &lt;li&gt;This will build all 3 configurations of dxvk-remix project inside subdirectories of the build tree: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;strong&gt;_Comp64Debug&lt;/strong&gt; - full debug instrumentation, runtime speed may be slow&lt;/li&gt; &#xA;     &lt;li&gt;&lt;strong&gt;_Comp64DebugOptimized&lt;/strong&gt; - partial debug instrumentation (i.e. asserts), runtime speed is generally comparable to that of release configuration&lt;/li&gt; &#xA;     &lt;li&gt;&lt;strong&gt;_Comp64Release&lt;/strong&gt; - fastest runtime&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;This will generate a project in the &lt;strong&gt;_vs&lt;/strong&gt; subdirectory&lt;/li&gt; &#xA;   &lt;li&gt;Only x64 build targets are supported&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open &lt;strong&gt;_vs/dxvk-remix.sln&lt;/strong&gt; in Visual Studio (2019+).&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Do not convert the solution on load if prompted when using a newer version of Visual Studio&lt;/li&gt; &#xA;   &lt;li&gt;Once generated, the project can be built via Visual Studio or via powershell scripts&lt;/li&gt; &#xA;   &lt;li&gt;A build will copy generated DXVK DLLs to any target project as specified in &lt;strong&gt;gametargets.conf&lt;/strong&gt; (see its &lt;a href=&#34;https://raw.githubusercontent.com/NVIDIAGameWorks/dxvk-remix/main/#deploy-built-binaries-to-a-game&#34;&gt;setup section&lt;/a&gt;)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Deploy built binaries to a game&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;First time only: copy &lt;strong&gt;gametargets.example.conf&lt;/strong&gt; to &lt;strong&gt;gametargets.conf&lt;/strong&gt; in the project root&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Update paths in the &lt;strong&gt;gametargets.conf&lt;/strong&gt; for your game. Follow example in the &lt;strong&gt;gametargets.example.conf&lt;/strong&gt;. Make sure to remove &#34;#&#34; from the start of all three lines&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Open and, simply, re-save top-level &lt;strong&gt;meson.build&lt;/strong&gt; file (i.e. via notepad) to update its time stamp, and rerun the build. This will trigger a full meson script run which will generate a project within the Visual Studio solution file and deploy built binaries into games&#39; directories specified in &lt;strong&gt;gametargets.conf&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Project Documentation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/NVIDIAGameWorks/dxvk-remix/main/RtxOptions.md&#34;&gt;Rtx Options&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>kevmo314/magic-copy</title>
    <updated>2023-04-15T02:40:31Z</updated>
    <id>tag:github.com,2023-04-15:/kevmo314/magic-copy</id>
    <link href="https://github.com/kevmo314/magic-copy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Magic Copy is a Chrome extension that uses Meta&#39;s Segment Anything Model to extract a foreground object from an image and copy it to the clipboard.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Magic Copy&lt;/h1&gt; &#xA;&lt;p&gt;Magic Copy is a Chrome extension that uses Meta&#39;s &lt;a href=&#34;https://segment-anything.com/&#34;&gt;Segment Anything Model&lt;/a&gt; to extract a foreground object from an image and copy it to the clipboard.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/511342/230546504-1ed11d08-3dda-422c-b304-e77dbb664e80.mp4&#34;&gt;https://user-images.githubusercontent.com/511342/230546504-1ed11d08-3dda-422c-b304-e77dbb664e80.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://chrome.google.com/webstore/detail/nnifclicibdhgakebbnbfmomniihfmkg&#34;&gt;&lt;img src=&#34;https://storage.googleapis.com/web-dev-uploads/image/WlD8wC6g8khYWPJUsQceQkhXSlv1/UV4C4ybeBTsZt43U4xis.png&#34; alt=&#34;Available on the Chrome Web Store&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://addons.mozilla.org/en-US/firefox/addon/magic-copy/&#34;&gt;&lt;img src=&#34;https://extensionworkshop.com/assets/img/documentation/publish/get-the-addon-178x60px.dad84b42.png&#34; alt=&#34;Available on the Firefox Add-ons Store&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;(This might not be available yet, as the extension is still in review. If you would like to be notified when they do, subscribe to the &lt;a href=&#34;https://github.com/kevmo314/magic-copy/issues/16&#34;&gt;Chrome&lt;/a&gt; or &lt;a href=&#34;https://github.com/kevmo314/magic-copy/issues/17&#34;&gt;Firefox&lt;/a&gt; issues.)&lt;/p&gt; &#xA;&lt;p&gt;Alternatively, the extension can be installed manually:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download the latest &lt;code&gt;magic-copy.zip&lt;/code&gt; from &lt;a href=&#34;https://github.com/kevmo314/magic-copy/releases&#34;&gt;releases&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Extract the ZIP file.&lt;/li&gt; &#xA; &lt;li&gt;In Chrome, go to &lt;code&gt;chrome://extensions/&lt;/code&gt;, enable &#34;Developer mode&#34;, and click &#34;Load unpacked&#34;.&lt;/li&gt; &#xA; &lt;li&gt;Select the folder where the extension was extracted.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Implementation&lt;/h2&gt; &#xA;&lt;p&gt;This extension uses the same procedure as the &lt;a href=&#34;https://segment-anything.com/demo&#34;&gt;Segment Anything Model demo&lt;/a&gt; to extract a foreground object from an image. The only difference is that the extracted object is copied to the clipboard instead of being displayed on the page.&lt;/p&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;h3&gt;Manually&lt;/h3&gt; &#xA;&lt;p&gt;Build the extension with &lt;code&gt;npm&lt;/code&gt; and then run the included &lt;code&gt;./buildcrx.sh&lt;/code&gt; script to generate the &lt;code&gt;crx&lt;/code&gt; file:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npm ci&#xA;npm run build&#xA;./buildcrx.sh -d dist&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;A &lt;code&gt;Dockerfile&lt;/code&gt; is provided to cleanly build the &lt;code&gt;crx&lt;/code&gt; file. To build the extension, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker build --output out .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Self-hosting&lt;/h2&gt; &#xA;&lt;p&gt;The Meta Segment Anything Model requires running the vision transformer on a server to generate the image&#39;s embeddings. Magic Copy uses the same service that their demo uses, however some people may not want to send their images to a third party.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;code&gt;server-example&lt;/code&gt; directory contains a simple example of how to self-host the vision transformer service. It is not meant to be used in production, but rather as a proof of concept to document the input/output format of the service.&lt;/p&gt; &#xA;&lt;p&gt;In particular, Magic Copy (and the SAM demo) expect a POST endpoint that accepts an image file and returns a JSON array of length 1 with the embedding of shape &lt;code&gt;(1, 256, 64, 64)&lt;/code&gt; as a base64 encoded string. See the code for specific details on how to perform this encoding to be compatible with the demo.&lt;/p&gt; &#xA;&lt;p&gt;If you are looking to quickly get the service running, you can use the provided &lt;code&gt;Dockerfile&lt;/code&gt; to build a container and run it. The container will expose port 8000 and will serve the service at the &lt;code&gt;/&lt;/code&gt; endpoint.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker build -t segment-anything .&#xA;docker run --gpus all -p 8000:8000 segment-anything&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In the Magic Copy chrome extension, you can then change the endpoint to &lt;code&gt;http://localhost:8000/&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>openai/consistency_models</title>
    <updated>2023-04-15T02:40:31Z</updated>
    <id>tag:github.com,2023-04-15:/openai/consistency_models</id>
    <link href="https://github.com/openai/consistency_models" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official repo for consistency models.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Consistency Models&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the codebase for &lt;a href=&#34;https://arxiv.org/abs/2303.01469&#34;&gt;Consistency Models&lt;/a&gt;, implemented using PyTorch for conducting large-scale experiments on ImageNet-64, LSUN Bedroom-256, and LSUN Cat-256. We have based our repository on &lt;a href=&#34;https://github.com/openai/guided-diffusion&#34;&gt;openai/guided-diffusion&lt;/a&gt;, which was initially released under the MIT license. Our modifications have enabled support for consistency distillation, consistency training, as well as several sampling and editing algorithms discussed in the paper.&lt;/p&gt; &#xA;&lt;p&gt;The repository for CIFAR-10 experiments is in JAX and will be released separately.&lt;/p&gt; &#xA;&lt;h1&gt;Pre-trained models&lt;/h1&gt; &#xA;&lt;p&gt;We have released checkpoints for the main models in the paper. Before using these models, please review the corresponding &lt;a href=&#34;https://raw.githubusercontent.com/openai/consistency_models/main/model-card.md&#34;&gt;model card&lt;/a&gt; to understand the intended use and limitations of these models.&lt;/p&gt; &#xA;&lt;p&gt;Here are the download links for each model checkpoint:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;EDM on ImageNet-64: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/edm_imagenet64_ema.pt&#34;&gt;edm_imagenet64_ema.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CD on ImageNet-64 with l2 metric: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/cd_imagenet64_l2.pt&#34;&gt;cd_imagenet64_l2.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CD on ImageNet-64 with LPIPS metric: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/cd_imagenet64_lpips.pt&#34;&gt;cd_imagenet64_lpips.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CT on ImageNet-64: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/ct_imagenet64.pt&#34;&gt;ct_imagenet64.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;EDM on LSUN Bedroom-256: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/edm_bedroom256_ema.pt&#34;&gt;edm_bedroom256_ema.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CD on LSUN Bedroom-256 with l2 metric: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/cd_bedroom256_l2.pt&#34;&gt;cd_bedroom256_l2.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CD on LSUN Bedroom-256 with LPIPS metric: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/cd_bedroom256_lpips.pt&#34;&gt;cd_bedroom256_lpips.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CT on LSUN Bedroom-256: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/ct_bedroom256.pt&#34;&gt;ct_bedroom256.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;EDM on LSUN Cat-256: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/edm_cat256_ema.pt&#34;&gt;edm_cat256_ema.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CD on LSUN Cat-256 with l2 metric: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/cd_cat256_l2.pt&#34;&gt;cd_cat256_l2.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CD on LSUN Cat-256 with LPIPS metric: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/cd_cat256_lpips.pt&#34;&gt;cd_cat256_lpips.pt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CT on LSUN Cat-256: &lt;a href=&#34;https://openaipublic.blob.core.windows.net/consistency/ct_cat256.pt&#34;&gt;ct_cat256.pt&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Dependencies&lt;/h1&gt; &#xA;&lt;p&gt;To install all packages in this codebase along with their dependencies, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Model training and sampling&lt;/h1&gt; &#xA;&lt;p&gt;We provide examples of EDM training, consistency distillation, consistency training, single-step generation, and multistep generation in &lt;a href=&#34;https://raw.githubusercontent.com/openai/consistency_models/main/scripts/launch.sh&#34;&gt;cm/scripts/launch.sh&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Evaluations&lt;/h1&gt; &#xA;&lt;p&gt;To compare different generative models, we use FID, Precision, Recall, and Inception Score. These metrics can all be calculated using batches of samples stored in &lt;code&gt;.npz&lt;/code&gt; (numpy) files. One can evaluate samples with &lt;a href=&#34;https://raw.githubusercontent.com/openai/consistency_models/main/evaluations/evaluator.py&#34;&gt;cm/evaluations/evaluator.py&lt;/a&gt; in the same way as described in &lt;a href=&#34;https://github.com/openai/guided-diffusion&#34;&gt;openai/guided-diffusion&lt;/a&gt;, with reference dataset batches provided therein.&lt;/p&gt; &#xA;&lt;h1&gt;Citation&lt;/h1&gt; &#xA;&lt;p&gt;If you find this method and/or code useful, please consider citing&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{song2023consistency,&#xA;  title={Consistency Models},&#xA;  author={Song, Yang and Dhariwal, Prafulla and Chen, Mark and Sutskever, Ilya},&#xA;  journal={arXiv preprint arXiv:2303.01469},&#xA;  year={2023},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>