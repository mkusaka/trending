<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-13T01:31:19Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>danswer-ai/danswer</title>
    <updated>2023-07-13T01:31:19Z</updated>
    <id>tag:github.com,2023-07-13:/danswer-ai/danswer</id>
    <link href="https://github.com/danswer-ai/danswer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Ask Questions in natural language and get Answers backed by private sources. Connects to tools like Slack, GitHub, Confluence, etc.&lt;/p&gt;&lt;hr&gt;&lt;h2 align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.danswer.ai/&#34;&gt; &lt;img width=&#34;50%&#34; src=&#34;https://github.com/danswer-owners/danswer/raw/1fabd9372d66cd54238847197c33f091a724803b/DanswerWithName.png?raw=true)&#34;&gt;&lt;/a&gt; &lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt;OpenSource Enterprise Question-Answering&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://docs.danswer.dev/&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/docs-view-blue&#34; alt=&#34;Documentation&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://join.slack.com/t/danswer/shared_invite/zt-1u5ycen3o-6SJbWfivLWP5LPyp_jftuw&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/slack-join-blue.svg?logo=slack&#34; alt=&#34;Slack&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://discord.gg/TDJ59cGV2X&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/discord-join-blue.svg?logo=discord&amp;amp;logoColor=white&#34; alt=&#34;Discord&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/danswer-ai/danswer/raw/main/README.md&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;https://img.shields.io/static/v1?label=license&amp;amp;message=MIT&amp;amp;color=blue&#34; alt=&#34;License&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.danswer.ai/&#34;&gt;Danswer&lt;/a&gt;&lt;/strong&gt; allows you to ask natural language questions against internal documents and get back reliable answers backed by quotes and references from the source material so that you can always trust what you get back. You can connect to a number of common tools such as Slack, GitHub, Confluence, amongst others.&lt;/p&gt; &#xA;&lt;p&gt;Check out our &lt;strong&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=geNzY1nbCnU&#34;&gt;Video Demo&lt;/a&gt;&lt;/strong&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Features ðŸ’ƒ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Direct QA powered by Generative AI models with answers backed by quotes and source links.&lt;/li&gt; &#xA; &lt;li&gt;Intelligent Document Retrieval (Semantic Search/Reranking) using the latest LLMs.&lt;/li&gt; &#xA; &lt;li&gt;An AI Helper backed by a custom Deep Learning model to interpret user intent.&lt;/li&gt; &#xA; &lt;li&gt;User authentication and document level access management.&lt;/li&gt; &#xA; &lt;li&gt;Connectors to Slack, GitHub, GoogleDrive, Confluence, local files, and web scraping, with more to come.&lt;/li&gt; &#xA; &lt;li&gt;Management Dashboard to manage connectors and set up features such as live update fetching.&lt;/li&gt; &#xA; &lt;li&gt;One line Docker Compose (or Kubernetes) deployment to host Danswer anywhere.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Upcoming&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Chat/Conversation support.&lt;/li&gt; &#xA; &lt;li&gt;Support custom endpoints for Generative AI models or even self-host options.&lt;/li&gt; &#xA; &lt;li&gt;Templates to easily build custom connectors.&lt;/li&gt; &#xA; &lt;li&gt;Personalized search&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>mazzzystar/Queryable</title>
    <updated>2023-07-13T01:31:19Z</updated>
    <id>tag:github.com,2023-07-13:/mazzzystar/Queryable</id>
    <link href="https://github.com/mazzzystar/Queryable" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Run OpenAI&#39;s CLIP model on iPhone to search photos.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Queryable&lt;/h1&gt; &#xA;&lt;a href=&#34;https://apps.apple.com/us/app/queryable-find-photo-by-text/id1661598353?platform=iphone&#34;&gt; &lt;img src=&#34;https://github-production-user-asset-6210df.s3.amazonaws.com/6824141/252914927-51414112-236b-4f7a-a13b-5210f9203198.svg?sanitize=true&#34; alt=&#34;download-on-the-app-store&#34;&gt; &lt;/a&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://apps.apple.com/us/app/queryable-find-photo-by-text/id1661598353?platform=iphone&#34;&gt;&lt;img src=&#34;https://mazzzystar.github.io/images/2022-12-28/Queryable-search-result.jpg&#34; alt=&#34;Queryable&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The open-source code of Queryable, an iOS app, leverages the OpenAI&#39;s &lt;a href=&#34;https://github.com/openai/CLIP&#34;&gt;CLIP&lt;/a&gt; model to conduct offline searches in the &#39;Photos&#39; album. Unlike the category-based search model built into the iOS Photos app, Queryable allows you to use natural language statements, such as &lt;code&gt;a brown dog sitting on a bench&lt;/code&gt;, to search your album. Since it&#39;s offline, your album privacy won&#39;t be compromised by any company, including Apple or Google.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://mazzzystar.github.io/2022/12/29/Run-CLIP-on-iPhone-to-Search-Photos/&#34;&gt;Blog&lt;/a&gt; | &lt;a href=&#34;https://queryable.app/&#34;&gt;Website&lt;/a&gt; | &lt;a href=&#34;https://apps.apple.com/us/app/queryable-find-photo-by-text/id1661598353?platform=iphone&#34;&gt;App Store&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;How does it work?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Encode all album photos using the CLIP Image Encoder, compute image vectors, and save them.&lt;/li&gt; &#xA; &lt;li&gt;For each new text query, compute the corresponding text vector using the Text Encoder.&lt;/li&gt; &#xA; &lt;li&gt;Compare the similarity between this text vector and each image vector.&lt;/li&gt; &#xA; &lt;li&gt;Rank and return the top K most similar results.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The process is as follows:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://mazzzystar.github.io/images/2022-12-28/Queryable-flow-chart.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;For more details, please refer to my blog: &lt;a href=&#34;https://mazzzystar.github.io/2022/12/29/Run-CLIP-on-iPhone-to-Search-Photos/&#34;&gt;Run CLIP on iPhone to Search Photos&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Run on Xcode&lt;/h2&gt; &#xA;&lt;p&gt;Download the &lt;code&gt;ImageEncoder_float32.mlmodelc&lt;/code&gt; and &lt;code&gt;TextEncoder_float32.mlmodelc&lt;/code&gt; from &lt;a href=&#34;https://drive.google.com/drive/folders/12ze3UcqrXt9qeySGh_j_zWE-PWRDTzJv?usp=drive_link&#34;&gt;Google Drive&lt;/a&gt;. Clone this repo, put the downloaded models below &lt;code&gt;CoreMLModels/&lt;/code&gt; path and run Xcode, it should work.&lt;/p&gt; &#xA;&lt;h2&gt;Core ML Export&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;If you only want to run Queryable, you can &lt;strong&gt;skip this step&lt;/strong&gt; and directly use the exported model from &lt;a href=&#34;https://drive.google.com/drive/folders/12ze3UcqrXt9qeySGh_j_zWE-PWRDTzJv?usp=drive_link&#34;&gt;Google Drive&lt;/a&gt;. If you wish to implement Queryable that supports your own native language, or do some model quantization/acceleration work, here are some guidelines.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;The trick is to separate the &lt;code&gt;TextEncoder&lt;/code&gt; and &lt;code&gt;ImageEncoder&lt;/code&gt; at the architecture level, and then load the model weights individually. Queryable uses the OpenAI &lt;a href=&#34;https://github.com/openai/CLIP&#34;&gt;ViT-B/32&lt;/a&gt; model, and I wrote a &lt;a href=&#34;https://github.com/mazzzystar/Queryable/raw/main/PyTorch2CoreML.ipynb&#34;&gt;Jupyter notebook&lt;/a&gt; to demonstrate how to separate, load, and export the Core ML model. The export results of the ImageEncoder&#39;s Core ML have a certain level of precision error, and more appropriate normalization parameters may be needed.&lt;/p&gt; &#xA;&lt;h2&gt;Contributions&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Disclaimer: I am not a professional iOS engineer, please forgive my poor Swift code. You may focus only on the loading, computation, storage, and sorting of the model.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;You can apply Queryable to your own product, but I don&#39;t recommend simply modifying the appearance and listing it on the App Store. If you are interested in optimizing certain aspects(such as &lt;a href=&#34;https://github.com/mazzzystar/Queryable/issues/3&#34;&gt;https://github.com/mazzzystar/Queryable/issues/3&lt;/a&gt;, &lt;a href=&#34;https://github.com/mazzzystar/Queryable/issues/4&#34;&gt;https://github.com/mazzzystar/Queryable/issues/4&lt;/a&gt;, &lt;a href=&#34;https://github.com/mazzzystar/Queryable/issues/5&#34;&gt;https://github.com/mazzzystar/Queryable/issues/5&lt;/a&gt;, &lt;a href=&#34;https://github.com/mazzzystar/Queryable/issues/6&#34;&gt;https://github.com/mazzzystar/Queryable/issues/6&lt;/a&gt;), feel free to submit a PR (Pull Request).&lt;/p&gt; &#xA;&lt;p&gt;If you have any questions/suggestions, here are some contact methods: &lt;a href=&#34;https://discord.com/invite/R3wNsqq3v5&#34;&gt;Discord&lt;/a&gt; | &lt;a href=&#34;https://twitter.com/immazzystar&#34;&gt;Twitter&lt;/a&gt; | &lt;a href=&#34;https://www.reddit.com/r/Queryable/&#34;&gt;Reddit: r/Queryable&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MIT License&lt;/p&gt; &#xA;&lt;p&gt;Copyright (c) 2023 Ke Fang&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>mshumer/gpt-prompt-engineer</title>
    <updated>2023-07-13T01:31:19Z</updated>
    <id>tag:github.com,2023-07-13:/mshumer/gpt-prompt-engineer</id>
    <link href="https://github.com/mshumer/gpt-prompt-engineer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;gpt-prompt-engineer&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/mattshumer_&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/mattshumer_?style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/mshumer/gpt-prompt-engineer/blob/main/gpt_prompt_engineer.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Main Version In Colab&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/drive/16NLMjqyuUWxcokE_NF6RwHD8grwEeoaJ?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open Classification Version In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;Prompt engineering is kind of like alchemy. There&#39;s no clear way to predict what will work best. It&#39;s all about experimenting until you find the right prompt. &lt;code&gt;gpt-prompt-engineer&lt;/code&gt; is a tool that takes this experimentation to a whole new level.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Simply input a description of your task and some test cases, and the system will generate, test, and rank a multitude of prompts to find the ones that perform the best.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Prompt Generation&lt;/strong&gt;: Using GPT-4 and GPT-3.5-Turbo, &lt;code&gt;gpt-prompt-engineer&lt;/code&gt; can generate a variety of possible prompts based on a provided use-case and test cases.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Prompt Testing&lt;/strong&gt;: The real magic happens after the generation. The system tests each prompt against all the test cases, comparing their performance and ranking them using an ELO rating system.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img width=&#34;1563&#34; alt=&#34;Screen Shot 2023-07-04 at 11 41 54 AM&#34; src=&#34;https://github.com/mshumer/gpt-prompt-engineer/assets/41550495/f8171cff-1703-40ca-b9fd-f0aa24d07110&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;ELO Rating System&lt;/strong&gt;: Each prompt starts with an ELO rating of 1200. As they compete against each other in generating responses to the test cases, their ELO ratings change based on their performance. This way, you can easily see which prompts are the most effective.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Classification Version&lt;/strong&gt;: The &lt;code&gt;gpt-prompt-engineer -- Classification Version&lt;/code&gt; notebook is designed to handle classification tasks. It evaluates the correctness of a test case by matching it to the expected output (&#39;true&#39; or &#39;false&#39;) and provides a table with scores for each prompt.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img width=&#34;1607&#34; alt=&#34;Screen Shot 2023-07-10 at 5 22 24 PM&#34; src=&#34;https://github.com/mshumer/gpt-prompt-engineer/assets/41550495/d5c9f2a8-97fa-445d-9c38-dec744f77854&#34;&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://wandb.ai/site/prompts&#34;&gt;Weights &amp;amp; Biases&lt;/a&gt; Logging&lt;/strong&gt;: Optional logging to &lt;a href=&#34;https://wandb.ai/site&#34;&gt;Weights &amp;amp; Biases&lt;/a&gt; of your configs such as temperature and max tokens, the system and user prompts for each part, the test cases used and the final ranked ELO rating for each candidate prompt. Set &lt;code&gt;use_wandb&lt;/code&gt; to &lt;code&gt;True&lt;/code&gt; to use.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/mshumer/gpt-prompt-engineer/blob/main/gpt_prompt_engineer.ipynb&#34;&gt;Open the notebook in Google Colab&lt;/a&gt; or in a local Jupyter notebook. For classification, use &lt;a href=&#34;https://colab.research.google.com/drive/16NLMjqyuUWxcokE_NF6RwHD8grwEeoaJ?usp=sharing&#34;&gt;this one.&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Add your OpenAI API key to the line &lt;code&gt;openai.api_key = &#34;ADD YOUR KEY HERE&#34;&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you have GPT-4 access, you&#39;re ready to move on. If not, change &lt;code&gt;CANDIDATE_MODEL=&#39;gpt-4&#39;&lt;/code&gt; to &lt;code&gt;CANDIDATE_MODEL=&#39;gpt-3.5-turbo&#39;&lt;/code&gt;. If you&#39;re using the classification version, and don&#39;t have GPT-4 access, change &lt;code&gt;model=&#39;gpt-4&#39;&lt;/code&gt; in the second cell to `model=&#39;gpt-3.5-turbo&#39;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;How to Use&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Define your use-case and test cases. The use-case is a description of what you want the AI to do. Test cases are specific prompts that you would like the AI to respond to. For example:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;description = &#34;Given a prompt, generate a landing page headline.&#34; # this style of description tends to work well&#xA;&#xA;test_cases = [&#xA;    {&#xA;        &#39;prompt&#39;: &#39;Promoting an innovative new fitness app, Smartly&#39;,&#xA;    },&#xA;    {&#xA;        &#39;prompt&#39;: &#39;Why a vegan diet is beneficial for your health&#39;,&#xA;    },&#xA;    {&#xA;        &#39;prompt&#39;: &#39;Introducing a new online course on digital marketing&#39;,&#xA;    },&#xA;    {&#xA;        &#39;prompt&#39;: &#39;Launching a new line of eco-friendly clothing&#39;,&#xA;    },&#xA;    {&#xA;        &#39;prompt&#39;: &#39;Promoting a new travel blog focusing on budget travel&#39;,&#xA;    },&#xA;    {&#xA;        &#39;prompt&#39;: &#39;Advertising a new software for efficient project management&#39;,&#xA;    },&#xA;    {&#xA;        &#39;prompt&#39;: &#39;Introducing a new book on mastering Python programming&#39;,&#xA;    },&#xA;    {&#xA;        &#39;prompt&#39;: &#39;Promoting a new online platform for learning languages&#39;,&#xA;    },&#xA;    {&#xA;        &#39;prompt&#39;: &#39;Advertising a new service for personalized meal plans&#39;,&#xA;    },&#xA;    {&#xA;        &#39;prompt&#39;: &#39;Launching a new app for mental health and mindfulness&#39;,&#xA;    }&#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For the classification version, your test cases should be in the format:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;test_cases = [&#xA;    {&#xA;        &#39;prompt&#39;: &#39;I had a great day!&#39;,&#xA;        &#39;output&#39;: &#39;true&#39;&#xA;    },&#xA;    {&#xA;        &#39;prompt&#39;: &#39;I am feeling gloomy.&#39;,&#xA;        &#39;output&#39;: &#39;false&#39;&#xA;    },&#xA;    // add more test cases here&#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt; &lt;p&gt;Choose how many prompts to generate. Keep in mind, this can get expensive if you generate many prompts. 10 is a good starting point.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Call &lt;code&gt;generate_optimal_prompt(description, test_cases, number_of_prompts)&lt;/code&gt; to generate a list of potential prompts, and test and rate their performance. For the classification version, just run the last cell.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The final ELO ratings will be printed in a table, sorted in descending order. The higher the rating, the better the prompt.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img width=&#34;1074&#34; alt=&#34;Screen Shot 2023-07-04 at 11 48 45 AM&#34; src=&#34;https://github.com/mshumer/gpt-prompt-engineer/assets/41550495/324f90b8-c0ee-45fd-b219-6c44d9aa281b&#34;&gt; &#xA;&lt;p&gt;For the classification version, the scores for each prompt will be printed in a table (see the image above).&lt;/p&gt; &#xA;&lt;h2&gt;Contributions are welcome! Some ideas:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;have a number of different system prompt generators that create different styles of prompts, to cover more ground (ex. examples, verbose, short, markdown, etc.)&lt;/li&gt; &#xA; &lt;li&gt;automatically generate the test cases&lt;/li&gt; &#xA; &lt;li&gt;expand the classification version to support more than two classes using tiktoken&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is &lt;a href=&#34;https://github.com/your_username/your_repository/raw/master/LICENSE&#34;&gt;MIT&lt;/a&gt; licensed.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;Matt Shumer - &lt;a href=&#34;https://twitter.com/mattshumer_&#34;&gt;@mattshumer_&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Project Link: &lt;a href=&#34;https://raw.githubusercontent.com/mshumer/gpt-prompt-engineer/main/url&#34;&gt;https://github.com/mshumer/gpt-prompt-engineer&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>