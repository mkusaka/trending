<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-08-18T01:21:28Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>a16z-infra/ai-town</title>
    <updated>2023-08-18T01:21:28Z</updated>
    <id>tag:github.com,2023-08-18:/a16z-infra/ai-town</id>
    <link href="https://github.com/a16z-infra/ai-town" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A MIT-licensed, deployable starter kit for building and customizing your own version of AI town - a virtual town where AI characters live, chat and socialize.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Town üè†üíªüíå&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.convex.dev/ai-town&#34;&gt;Live Demo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/PQUmTBTGmT&#34;&gt;Join our community Discord: AI Stack Devs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;img width=&#34;1454&#34; alt=&#34;Screen Shot 2023-08-14 at 10 01 00 AM&#34; src=&#34;https://github.com/a16z-infra/ai-town/assets/3489963/a4c91f17-23ed-47ec-8c4e-9f9a8505057d&#34;&gt; &#xA;&lt;p&gt;AI Town is a virtual town where AI characters live, chat and socialize.&lt;/p&gt; &#xA;&lt;p&gt;This project is a deployable starter kit for easily building and customizing your own version of AI town. Inspired by the research paper &lt;a href=&#34;https://arxiv.org/pdf/2304.03442.pdf&#34;&gt;&lt;em&gt;Generative Agents: Interactive Simulacra of Human Behavior&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The primary goal of this project, beyond just being a lot of fun to work on, is to provide a platform with a strong foundation that is meant to be extended. The back-end engine natively supports shared global state, transactions, and a journal of all events so should be suitable for everything from a simple project to play around with to a scalable, multi-player game. A secondary goal is to make a JS/TS framework available as most simulators in this space (including the original paper above) are written in Python.&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üíª &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/ai-town/main/#stack&#34;&gt;Stack&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üß† &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/ai-town/main/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üë§ &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/ai-town/main/#customize-your-own-simulation&#34;&gt;Customize - run YOUR OWN simulated world&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üèÜ &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/ai-town/main/#credits&#34;&gt;Credits&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Stack&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Game engine &amp;amp; Database: &lt;a href=&#34;https://convex.dev/&#34;&gt;Convex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;VectorDB: &lt;a href=&#34;https://www.pinecone.io/&#34;&gt;Pinecone&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Auth: &lt;a href=&#34;https://clerk.com/&#34;&gt;Clerk&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Text model: &lt;a href=&#34;https://platform.openai.com/docs/models&#34;&gt;OpenAI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Deployment: &lt;a href=&#34;https://fly.io/&#34;&gt;Fly&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Pixel Art Generation: &lt;a href=&#34;https://replicate.com/&#34;&gt;Replicate&lt;/a&gt;, &lt;a href=&#34;https://serverless.fal.ai/lora&#34;&gt;Fal.ai&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Clone repo and Install packages&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone git@github.com:a16z-infra/ai-town.git&#xA;cd AI-town&#xA;npm install&#xA;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;npm run dev&lt;/code&gt; will fail asking for environment variables. Enter them in the environment variables on your Convex dashboard to proceed. You can get there via &lt;code&gt;npx convex dashboard&lt;/code&gt; or &lt;a href=&#34;https://dashboard.convex.dev&#34;&gt;https://dashboard.convex.dev&lt;/a&gt; See below on how to get the various environnment variables.&lt;/p&gt; &#xA;&lt;p&gt;a. &lt;strong&gt;Set up Clerk&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Go to &lt;a href=&#34;https://dashboard.clerk.com/&#34;&gt;https://dashboard.clerk.com/&lt;/a&gt; and click on &#34;Add Application&#34;&lt;/li&gt; &#xA; &lt;li&gt;Name your application and select the sign-in providers you would like to offer users&lt;/li&gt; &#xA; &lt;li&gt;Create Application&lt;/li&gt; &#xA; &lt;li&gt;Add &lt;code&gt;NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY&lt;/code&gt; and &lt;code&gt;CLERK_SECRET_KEY&lt;/code&gt; to &lt;code&gt;.env.local&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_***&#xA;CLERK_SECRET_KEY=sk_***&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Go to JWT Templates and create a new Convex Template.&lt;/li&gt; &#xA; &lt;li&gt;Copy the JWKS endpoint URL for use below.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;b. &lt;strong&gt;OpenAI API key&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Visit &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;https://platform.openai.com/account/api-keys&lt;/a&gt; to get your OpenAI API key if you&#39;re using OpenAI for your language model.&lt;/p&gt; &#xA;&lt;p&gt;c. &lt;strong&gt;Pinecone API keys&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a Pinecone index by visiting &lt;a href=&#34;https://app.pinecone.io/&#34;&gt;https://app.pinecone.io/&lt;/a&gt; and click on &#34;Create Index&#34;&lt;/li&gt; &#xA; &lt;li&gt;Give it an index name (this will be the environment variable &lt;code&gt;PINECONE_INDEX_NAME&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Fill in Dimension as &lt;code&gt;1536&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Once the index is successfully created, click on &#34;API Keys&#34; on the left side nav and create an API key: copy &#34;Environment&#34; value to &lt;code&gt;PINECONE_ENVIRONMENT&lt;/code&gt; variable, and &#34;Value&#34; to &lt;code&gt;PINECONE_API_KEY&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;d. &lt;strong&gt;Add secrets to the convex dashboard&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npx convex dashboard&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Go to &#34;settings&#34; and add the following environment varables. &lt;code&gt;CLERK_ISSUER_URL&lt;/code&gt; should be the URL from the JWKS endpoint.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;OPENAI_API_KEY  sk-*******&#xA;CLERK_ISSUER_URL  https://****&#xA;PINECONE_API_KEY  ********&#xA;PINECONE_ENVIRONMENT us****&#xA;PINECONE_INDEX_NAME  ********&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Run the code&lt;/h3&gt; &#xA;&lt;p&gt;To run both the front and and back end:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can now visit &lt;a href=&#34;http://localhost:%5BPORT_NUMBER%5D&#34;&gt;http://localhost:[PORT_NUMBER]&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;d rather run the frontend in a separate terminal from Convex (which syncs your backend functions as they&#39;re saved), you can run these two commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run dev:frontend&#xA;npm run dev:backend&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See package.json for details, but dev:backend runs &lt;code&gt;npx convex dev&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;*Note: The simulation will pause after 5 minutes if the window is idle. Loading the page will unpause it. If you want to run the world without the browser, you can comment-out the heartbeat check in &lt;code&gt;convex/engine.ts&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Various commands to run / test / debug&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;To add a new world, seed it, and start it running&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: you can add &lt;code&gt;--no-push&lt;/code&gt; to run these commands without first syncing the functions. If you already have &lt;code&gt;npm run dev&lt;/code&gt; running, this will be faster. If you remove it, it&#39;ll push up the latest version of code before running the command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npx convex run init:reset&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;To go one iteration at a time, you can create a world with&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npx convex run --no-push init:resetFrozen&#xA;&#xA;# for each iteration&#xA;npx convex run --no-push engine:tick &#39;{&#34;worldId&#34;:&#34;&amp;lt;your world id&amp;gt;&#34;,&#34;noSchedule&#34;:true}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;To freeze the back end, in case of too much activity&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npx convex run --no-push engine:freezeAll&#xA;&#xA;# when ready to rerun (defaults to latest world)&#xA;npx convex run --no-push engine:unfreeze&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;To clear all databases&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Many options:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Go to the dashboard &lt;code&gt;npx convex dashboard&lt;/code&gt; and clear tables from there.&lt;/li&gt; &#xA; &lt;li&gt;Adjust the variables in &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/ai-town/main/convex/crons.ts&#34;&gt;&lt;code&gt;crons.ts&lt;/code&gt;&lt;/a&gt; to automatically clear up space from old journal and memory entries.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;npx convex run --no-push testing:debugClearAll&lt;/code&gt; to wipe all the tables.&lt;/li&gt; &#xA; &lt;li&gt;As a fallback, if things are stuck, you can check out the &lt;code&gt;origin/reset-town&lt;/code&gt; git branch. Doing &lt;code&gt;npm run dev&lt;/code&gt; from there will clear your schema, stop your functions, and allow you to delete your tables in the dashboard.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To delete all vectors from the Pinecone index, you can run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;npx convex run --no-push lib/pinecone:deleteAllVectors&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: If you share this index between dev &amp;amp; prod, or between projects, it will wipe them all out. You generally don&#39;t need to be deleting vectors from Pinecone, as each query is indexed on the userId, which is unique between worlds and backend instances.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;To Snoop on messages&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Run the following in a side terminal&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npx convex run testing:listMessages --no-push --watch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or to watch one player&#39;s state:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npx convex run testing:latestPlayer --no-push --watch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See more functions in &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/ai-town/main/convex/testing.ts&#34;&gt;&lt;code&gt;testing.ts&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Deploy the app&lt;/h3&gt; &#xA;&lt;h4&gt;Deploy to fly.io&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Register an account on fly.io and then &lt;a href=&#34;https://fly.io/docs/hands-on/install-flyctl/&#34;&gt;install flyctl&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;If you are using Github Codespaces&lt;/strong&gt;: You will need to &lt;a href=&#34;https://fly.io/docs/hands-on/install-flyctl/&#34;&gt;install flyctl&lt;/a&gt; and authenticate from your codespaces cli by running &lt;code&gt;fly auth login&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run &lt;code&gt;npx convex deploy&lt;/code&gt; to deploy your dev environment to prod environment. Make sure you copy over all secrets to Convex&#39;s prod environment&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run &lt;code&gt;fly launch&lt;/code&gt; under project root. This will generate a &lt;code&gt;fly.toml&lt;/code&gt; that includes all the configurations you will need&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Modify generated &lt;code&gt;fly.toml&lt;/code&gt; to include &lt;code&gt;NEXT_PUBLIC_*&lt;/code&gt; during build time for NextJS to access client side.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;[build]&#xA;  [build.args]&#xA;    NEXT_PUBLIC_CLERK_SIGN_IN_URL=&#34;/sign-in&#34;&#xA;    NEXT_PUBLIC_CLERK_SIGN_UP_URL=&#34;/sign-up&#34;&#xA;    NEXT_PUBLIC_CLERK_AFTER_SIGN_IN_URL=&#34;/&#34;&#xA;    NEXT_PUBLIC_CLERK_AFTER_SIGN_UP_URL=&#34;/&#34;&#xA;    NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=&#34;pk_*****&#34;&#xA;    NEXT_PUBLIC_CONVEX_URL=&#34;https://*******.convex.cloud&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Modify fly.io&#39;s generated &lt;code&gt;Dockerfile&lt;/code&gt; to include new ENV variables right above &lt;code&gt;RUN npm run build&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;ARG NEXT_PUBLIC_CLERK_SIGN_IN_URL&#xA;ARG NEXT_PUBLIC_CLERK_SIGN_UP_URL&#xA;ARG NEXT_PUBLIC_CLERK_AFTER_SIGN_IN_URL&#xA;ARG NEXT_PUBLIC_CLERK_AFTER_SIGN_UP_URL&#xA;ARG NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY&#xA;ARG NEXT_PUBLIC_CONVEX_URL&#xA;&#xA;# Build application&#xA;RUN npm run build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Run &lt;code&gt;fly deploy --ha=false&lt;/code&gt; to deploy the app. The --ha flag makes sure fly only spins up one instance, which is included in the free plan.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;fly scale memory 512&lt;/code&gt; to scale up the fly vm memory for this app.&lt;/li&gt; &#xA; &lt;li&gt;Create a new file &lt;code&gt;.env.prod&lt;/code&gt; locally and fill in all the production-environment secrets. Remember to update &lt;code&gt;NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY&lt;/code&gt; and &lt;code&gt;CLERK_SECRET_KEY&lt;/code&gt; by copying secrets from Clerk&#39;s production instance -&lt;code&gt;cat .env.prod | fly secrets import&lt;/code&gt; to upload secrets. Also remember to update &lt;code&gt;CONVEX_DEPLOYMENT&lt;/code&gt; and &lt;code&gt;NEXT_PUBLIC_CONVEX_URL&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Customize your own simulation&lt;/h2&gt; &#xA;&lt;p&gt;NOTE: every time you change character data, you should re-run &lt;code&gt;npx convex run testing:debugClearAll --no-push&lt;/code&gt; and then &lt;code&gt;npm run dev&lt;/code&gt; to re-upload everything to Convex. This is because character data is sent to Convex on the initial load. However, beware that &lt;code&gt;npx convex run testing:debugClearAll --no-push&lt;/code&gt; WILL wipe all of your data, including your vector store.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create your own characters and stories: All characters and stories, as well as their spritesheet references are stored in &lt;a href=&#34;https://raw.githubusercontent.com/a16z-infra/ai-town/main/convex/characterdata/data.ts#L4&#34;&gt;data.ts&lt;/a&gt;. You can start by changing character descriptions.&lt;/li&gt; &#xA; &lt;li&gt;Updating spritesheets: in &lt;code&gt;data.ts&lt;/code&gt;, you will see this code:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-export&#34;&gt;  {&#xA;    name: &#39;f1&#39;,&#xA;    textureUrl: &#39;/assets/32x32folk.png&#39;,&#xA;    spritesheetData: f1SpritesheetData,&#xA;    speed: 0.1,&#xA;  },...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You should find a sprite sheet for your character, and define sprite motion / assets in the corresponding file (in the above example, &lt;code&gt;f1SpritesheetData&lt;/code&gt; was defined in f1.ts)&lt;/p&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Update the background (environment): &lt;code&gt;convex/maps/firstmap.ts&lt;/code&gt; is where the map gets loaded. The easiest way to export a tilemap is by using &lt;a href=&#34;https://www.mapeditor.org/&#34;&gt;Tiled&lt;/a&gt; -- Tiled exports tilemaps as a CSV and you can convert CSV to a 2d array accepted by firstmap.ts&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;All interactions, background music and rendering on the &#xA;  &lt;game /&gt; component in the project are powered by &lt;a href=&#34;https://pixijs.com/&#34;&gt;PixiJS&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Tilesheet: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://opengameart.org/content/16x16-game-assets&#34;&gt;https://opengameart.org/content/16x16-game-assets&lt;/a&gt; by George Bailey&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://opengameart.org/content/16x16-rpg-tileset&#34;&gt;https://opengameart.org/content/16x16-rpg-tileset&lt;/a&gt; by hilau&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;We used &lt;a href=&#34;https://github.com/pierpo/phaser3-simple-rpg&#34;&gt;https://github.com/pierpo/phaser3-simple-rpg&lt;/a&gt; for the original POC of this project. We have since re-wrote the whole app, but appreciated the easy starting point&lt;/li&gt; &#xA; &lt;li&gt;Original assets by &lt;a href=&#34;https://opengameart.org/content/tiny-rpg-forest&#34;&gt;ansimuz&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The UI is based on original assets by &lt;a href=&#34;https://mounirtohami.itch.io/pixel-art-gui-elements&#34;&gt;Mounir Tohami&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>varunshenoy/opendream</title>
    <updated>2023-08-18T01:21:28Z</updated>
    <id>tag:github.com,2023-08-18:/varunshenoy/opendream</id>
    <link href="https://github.com/varunshenoy/opendream" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An extensible, easy-to-use, and portable diffusion web UI üë®‚Äçüé®&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Opendream: A Web UI For the Rest of Us üí≠ üé®&lt;/h1&gt; &#xA;&lt;p&gt;Opendream brings much needed and familiar features, such as layering, non-destructive editing, portability, and easy-to-write extensions, to your Stable Diffusion workflows. Check out our &lt;a href=&#34;https://twitter.com/varunshenoy_/status/1691506322360201216?s=20&#34;&gt;demo video&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/varunshenoy/opendream/main/images/hero.png&#34; alt=&#34;hero&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;ol start=&#34;0&#34;&gt; &#xA; &lt;li&gt;&lt;em&gt;Prerequisites&lt;/em&gt;: Make sure you have Node installed. You can download it &lt;a href=&#34;https://nodejs.org/en/download&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Clone this repository.&lt;/li&gt; &#xA; &lt;li&gt;Navigate to this project within your terminal and run &lt;code&gt;sh ./run_opendream.sh&lt;/code&gt;. After ~30 seconds, both the frontend and backend of the Opendream system should be up and running.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;Diffusion models have emerged as powerful tools in the world of image generation and manipulation. While they offer significant benefits, these models are often considered black boxes due to their inherent complexity. The current diffusion image generation ecosystem is defined by tools that allow one-off image manipulation tasks to control these models - text2img, in-painting, pix2pix, among others.&lt;/p&gt; &#xA;&lt;p&gt;For example, popular interfaces like &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;Automatic1111&lt;/a&gt;, &lt;a href=&#34;https://midjourney.com/&#34;&gt;Midjourney&lt;/a&gt;, and &lt;a href=&#34;https://beta.dreamstudio.ai/generate&#34;&gt;Stability.AI&#39;s DreamStudio&lt;/a&gt; only support destructive editing: each edit &#34;consumes&#34; the previous image. This means users cannot easily build off of previous images or run multiple experiments on the same image, limiting their options for creative exploration.&lt;/p&gt; &#xA;&lt;h3&gt;Layering and Non-destructive Editing&lt;/h3&gt; &#xA;&lt;p&gt;Non-destructive editing is a method of image manipulation that preserves the original image data while allowing users to make adjustments and modifications without overwriting previous work. This approach facilitates experimentation and provides more control over the editing process by using layers and masks. When you delete a layer, all layers after it also get deleted. This guarantees that all layers currently on the canvas are a product of other existing layers. This also allows one to deterministically &#34;replay&#34; a workflow.&lt;/p&gt; &#xA;&lt;p&gt;Like Photoshop, Opendream supports non-destructive editing out of the box. Learn more about the principles of non-destructive editing in Photoshop &lt;a href=&#34;https://helpx.adobe.com/photoshop/using/nondestructive-editing.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/varunshenoy/opendream/main/images/editing.png&#34; alt=&#34;layers&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Save and Share Workflows&lt;/h3&gt; &#xA;&lt;p&gt;Users can also save their current workflows into a portable file format that can be opened up at a later time or shared with collaborators. In this context, a &#34;state&#34; is just a JSON file describing all of the current layers and how they were created.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/varunshenoy/opendream/main/images/workflow.png&#34; alt=&#34;workflow&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Support Simple to Write, Easy to Install Extensions&lt;/h3&gt; &#xA;&lt;p&gt;As the open-source ecosystem flourishes around these models and tools, extensibility has also become a major concern. While Automatic1111 does offer extensions, they are often difficult to program, use, and install. It is far from being as full-featured as an application like Adobe Photoshop.&lt;/p&gt; &#xA;&lt;p&gt;As new features for Stable Diffusion, like ControlNet, are released, users should be able to seamlessly integrate them into their artistic workflows with minimal overload and time.&lt;/p&gt; &#xA;&lt;p&gt;Opendream makes writing and using new diffusion features as simple as writing a Python function. Keep reading to learn how.&lt;/p&gt; &#xA;&lt;h2&gt;Extensions&lt;/h2&gt; &#xA;&lt;p&gt;From the get-go, Opendream supports two key primitive operations baked into the core system: &lt;code&gt;dream&lt;/code&gt; and &lt;code&gt;mask_and_inpaint&lt;/code&gt;. In this repository, extensions for &lt;code&gt;instruct_pix2pix&lt;/code&gt;, &lt;code&gt;controlnet_canny&lt;/code&gt;, &lt;code&gt;controlnet_openpose&lt;/code&gt;, and &lt;code&gt;sam&lt;/code&gt; (Segment Anything) are provided.&lt;/p&gt; &#xA;&lt;p&gt;Any image manipulation logic can be easily written as an extension. With extensions, you can also decide how certain operations work. For example, you can override the &lt;code&gt;dream&lt;/code&gt; operation to use OpenAI&#39;s DALL-E instead or call a serverless endpoint on a service like AWS or Replicate. &lt;a href=&#34;https://gist.githubusercontent.com/varunshenoy/f029c55536bb7e4fac61a595e836d930/raw/f7e693c8aa42a814d05198c28a843a97c8f6a4c6/baseten_stable_diffusion.py&#34;&gt;Here&#39;s an example using Baseten&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Loading an Existing Extension&lt;/h3&gt; &#xA;&lt;p&gt;There are two ways to load extensions.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install a pre-written one through the Web UI.&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;(Manual)&lt;/em&gt; Download a valid extension file (or write one yourself!) and add it to the &lt;code&gt;opendream/extensions&lt;/code&gt; folder. Instructions for writing your own extension are below.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Here is a sampling of currently supported extensions. You can use the links to install any given extension through the Web UI.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Extension&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Link&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OpenAI&#39;s DALL-E&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://gist.githubusercontent.com/varunshenoy/4a9a6bbfedfa7def28178a8f0563320a/raw/d2d10faa0fad8c2d251e599d962b0c7f62c06db0/dalle.py&#34;&gt;File&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Serverless Stable Diffusion&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://gist.githubusercontent.com/varunshenoy/f029c55536bb7e4fac61a595e836d930/raw/f7e693c8aa42a814d05198c28a843a97c8f6a4c6/baseten_stable_diffusion.py&#34;&gt;File&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Instruct Pix2Pix&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://gist.githubusercontent.com/varunshenoy/894c7a723de6b4651380dd7fa2a81724/raw/fa678d8d6c430421fb481f7023ad76898dd27ad6/instruct_pix2pix.py&#34;&gt;File&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ControlNet Canny&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://gist.githubusercontent.com/varunshenoy/0b0455449454e5856021fe2971b78352/raw/1c08b376b499c25c84976eade71db9aa355dba47/controlnet_canny.py&#34;&gt;File&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ControlNet Openpose&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://gist.githubusercontent.com/varunshenoy/380722906b8ff184569af57e06fd37b7/raw/728832370db0448bc2807ffc9e267635749e6a9f/controlnet_openpose.py&#34;&gt;File&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Segment Anything&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://gist.githubusercontent.com/varunshenoy/5fbc883360e5ab2a3c023ce1e286ddd5/raw/efbc92d27ae2209b15948fb52f657e88c185b349/sam.py&#34;&gt;File&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PhotoshopGPT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://gist.github.com/varunshenoy/63054e7a479f256974416ef45a51e6a0&#34;&gt;Gist&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Note that extensions may have their own requirements you would need to include in the &lt;code&gt;requirements.txt&lt;/code&gt; file. For example, you would need to add &lt;code&gt;openai&lt;/code&gt; if you want to use the DALL-E extension.&lt;/p&gt; &#xA;&lt;p&gt;Feel free to make a PR if you create a useful extension!&lt;/p&gt; &#xA;&lt;h3&gt;Writing Your Own Extension&lt;/h3&gt; &#xA;&lt;p&gt;Users can write their own extensions as follows:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create a new Python file in the &lt;code&gt;opendream/extensions&lt;/code&gt; folder.&lt;/li&gt; &#xA; &lt;li&gt;Write a method with type hints and a &lt;code&gt;@opendream.define_op&lt;/code&gt; decorator. This decorator registers this method with the Opendream backend.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The method has a few requirements:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Parameters must have type hints. These enable the backend to generate a schema for the input which is parsed into form components on the frontend. Valid types include: &lt;code&gt;str&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;, &lt;code&gt;float&lt;/code&gt;, &lt;code&gt;Layer&lt;/code&gt;, &lt;code&gt;MaskLayer&lt;/code&gt;, or &lt;code&gt;ImageLayer&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The only valid return types are a &lt;code&gt;Layer&lt;/code&gt; or a list of &lt;code&gt;Layer&lt;/code&gt; objects.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributions and Licensing&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;Opendream was built by Varun Shenoy, Eric Lou, Shashank Rammoorthy, and Rahul Shiv as a part of Stanford&#39;s &lt;a href=&#34;https://cs348k.stanford.edu/&#34;&gt;CS 348K&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Feel free to provide any contibutions you deem necessary or useful. This project is licensed under the MIT License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>plbrault/youre-the-os</title>
    <updated>2023-08-18T01:21:28Z</updated>
    <id>tag:github.com,2023-08-18:/plbrault/youre-the-os</id>
    <link href="https://github.com/plbrault/youre-the-os" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A game where you are a computer&#39;s OS and you have to manage processes, memory and I/O events.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;You&#39;re the OS!&lt;/h1&gt; &#xA;&lt;p&gt;This is a game where you are the operating system of a computer. As such, you have to manage processes, memory and I/O events. Make sure not to leave processes idling for too long, or the user will get really impatient and reboot you!&lt;/p&gt; &#xA;&lt;p&gt;You can play the game here: &lt;a href=&#34;https://plbrault.github.io/youre-the-os&#34;&gt;https://plbrault.github.io/youre-the-os&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Also available on &lt;a href=&#34;https://drfreckles42.itch.io/youre-the-os&#34;&gt;itch.io&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/plbrault/youre-the-os/main/readme-assets/in_game_screenshot.png&#34; alt=&#34;In-game screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.11&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pypi.org/project/pipenv/&#34;&gt;pipenv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;An empty &lt;code&gt;.venv&lt;/code&gt; directory at the root of the project&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Install dependencies:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pipenv sync --dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Run as a desktop app:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pipenv run desktop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Run web version:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pipenv run web&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Build web version without running:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pipenv run web build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Create &lt;code&gt;web.zip&lt;/code&gt; archive for itch.io:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pipenv run web archive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright (c) 2023 Pier-Luc Brault &lt;a href=&#34;mailto:pier-luc@brault.me&#34;&gt;pier-luc@brault.me&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.&lt;/p&gt; &#xA;&lt;p&gt;This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.&lt;/p&gt; &#xA;&lt;p&gt;You should have received a copy of the GNU General Public License along with this program. If not, see &lt;a href=&#34;https://www.gnu.org/licenses/&#34;&gt;https://www.gnu.org/licenses/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Asset Licenses&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Emojis used in the game are from &lt;a href=&#34;https://openmoji.org/&#34;&gt;OpenMoji&lt;/a&gt;. They are published under the &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0/#&#34;&gt;Creative Commons Attribution-ShareAlike License 4.0&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The image used in the Game Over screen is by &lt;a href=&#34;https://pixabay.com/fr/users/lemonsandtea-10190089/&#34;&gt;Aleksandar Cvetanoviƒá&lt;/a&gt; and is published under the &lt;a href=&#34;https://pixabay.com/service/license/&#34;&gt;Pixabay License&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The game icon was created by user &lt;a href=&#34;https://www.flaticon.com/authors/itim2101&#34;&gt;itim2101&lt;/a&gt; on &lt;a href=&#34;https://www.flaticon.com/&#34;&gt;Flaticon&lt;/a&gt; and is published under the &lt;a href=&#34;https://www.freepikcompany.com/legal#nav-flaticon-agreement&#34;&gt;Flaticon license&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The primary font used in the game is named &lt;em&gt;VT323&lt;/em&gt;, and was designed by Peter Hull. The secondary font is named &lt;em&gt;Victor Mono&lt;/em&gt; and was designed by Rune Bj√∏rner√•s. Both are published under the &lt;a href=&#34;https://scripts.sil.org/cms/scripts/page.php?item_id=OFL_web&#34;&gt;Open Font License&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>