<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-11T01:29:12Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>sashabaranov/go-gpt3</title>
    <updated>2023-02-11T01:29:12Z</updated>
    <id>tag:github.com,2023-02-11:/sashabaranov/go-gpt3</id>
    <link href="https://github.com/sashabaranov/go-gpt3" rel="alternate"></link>
    <summary type="html">&lt;p&gt;OpenAI GPT-3 and DALLÂ·E API wrapper for Go&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;go-gpt3&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://godoc.org/github.com/sashabaranov/go-gpt3&#34;&gt;&lt;img src=&#34;http://img.shields.io/badge/GoDoc-Reference-blue.svg?sanitize=true&#34; alt=&#34;GoDoc&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://goreportcard.com/report/github.com/sashabaranov/go-gpt3&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/sashabaranov/go-gpt3&#34; alt=&#34;Go Report Card&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://beta.openai.com/&#34;&gt;OpenAI GPT-3&lt;/a&gt; API wrapper for Go&lt;/p&gt; &#xA;&lt;p&gt;Installation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;go get github.com/sashabaranov/go-gpt3&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main&#xA;&#xA;import (&#xA;&#x9;&#34;context&#34;&#xA;&#x9;&#34;fmt&#34;&#xA;&#x9;gogpt &#34;github.com/sashabaranov/go-gpt3&#34;&#xA;)&#xA;&#xA;func main() {&#xA;&#x9;c := gogpt.NewClient(&#34;your token&#34;)&#xA;&#x9;ctx := context.Background()&#xA;&#xA;&#x9;req := gogpt.CompletionRequest{&#xA;&#x9;&#x9;Model:     gogpt.GPT3Ada,&#xA;&#x9;&#x9;MaxTokens: 5,&#xA;&#x9;&#x9;Prompt:    &#34;Lorem ipsum&#34;,&#xA;&#x9;}&#xA;&#x9;resp, err := c.CreateCompletion(ctx, req)&#xA;&#x9;if err != nil {&#xA;&#x9;&#x9;return&#xA;&#x9;}&#xA;&#x9;fmt.Println(resp.Choices[0].Text)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Streaming response example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main&#xA;&#xA;import (&#xA;&#x9;&#34;errors&#34;&#xA;&#x9;&#34;context&#34;&#xA;&#x9;&#34;fmt&#34;&#xA;&#x9;&#34;io&#34;&#xA;&#x9;gogpt &#34;github.com/sashabaranov/go-gpt3&#34;&#xA;)&#xA;&#xA;func main() {&#xA;&#x9;c := gogpt.NewClient(&#34;your token&#34;)&#xA;&#x9;ctx := context.Background()&#xA;&#xA;&#x9;req := gogpt.CompletionRequest{&#xA;&#x9;&#x9;Model:     gogpt.GPT3Ada,&#xA;&#x9;&#x9;MaxTokens: 5,&#xA;&#x9;&#x9;Prompt:    &#34;Lorem ipsum&#34;,&#xA;&#x9;&#x9;Stream:    true,&#xA;&#x9;}&#xA;&#x9;stream, err := c.CreateCompletionStream(ctx, req)&#xA;&#x9;if err != nil {&#xA;&#x9;&#x9;return&#xA;&#x9;}&#xA;&#x9;defer stream.Close()&#xA;&#xA;&#x9;for {&#xA;&#x9;&#x9;response, err := stream.Recv()&#xA;&#x9;&#x9;if errors.Is(err, io.EOF) {&#xA;&#x9;&#x9;&#x9;fmt.Println(&#34;Stream finished&#34;)&#xA;&#x9;&#x9;&#x9;return&#xA;&#x9;&#x9;}&#xA;&#xA;&#x9;&#x9;if err != nil {&#xA;&#x9;&#x9;&#x9;fmt.Printf(&#34;Stream error: %v\n&#34;, err)&#xA;&#x9;&#x9;&#x9;return&#xA;&#x9;&#x9;}&#xA;&#xA;&#xA;&#x9;&#x9;fmt.Printf(&#34;Stream response: %v\n&#34;, response)&#xA;&#x9;}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>YuxinWenRick/hard-prompts-made-easy</title>
    <updated>2023-02-11T01:29:12Z</updated>
    <id>tag:github.com,2023-02-11:/YuxinWenRick/hard-prompts-made-easy</id>
    <link href="https://github.com/YuxinWenRick/hard-prompts-made-easy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Hard Prompts Made Easy: Discrete Prompt Tuning for Language Models&lt;/h1&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/YuxinWenRick/hard-prompts-made-easy/main/examples/teaser.png&#34; width=&#34;70%&#34; height=&#34;40%&#34;&gt; &#xA;&lt;p&gt;This code is the official implementation of &lt;a href=&#34;https://arxiv.org/abs/2302.03668&#34;&gt;Hard Prompts Made Easy&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you have any questions, feel free to email Yuxin (&lt;a href=&#34;mailto:ywen@umd.edu&#34;&gt;ywen@umd.edu&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h2&gt;About&lt;/h2&gt; &#xA;&lt;p&gt;From a given image, we first optimize a hard prompt using the PEZ algorithm and CLIP encoders. Then, we take the optimized prompts and feed them into Stable Diffusion to generate new images. The name PEZ (hard &lt;em&gt;&lt;strong&gt;P&lt;/strong&gt;&lt;/em&gt;rompts made &lt;em&gt;&lt;strong&gt;E&lt;/strong&gt;&lt;/em&gt;a&lt;strong&gt;Z&lt;/strong&gt;y) was inspired from the &lt;a href=&#34;https://us.pez.com/collections/dispensers&#34;&gt;PEZ candy dispenser&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Try out&lt;/h2&gt; &#xA;&lt;p&gt;You can try out our demos on Colab &lt;a href=&#34;https://colab.research.google.com/drive/1VSFps4siwASXDwhK_o29dKA9COvTnG8A?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; or Hugging Face Space &lt;a href=&#34;https://huggingface.co/spaces/tomg-group-umd/pez-dispenser&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97-Open%20in%20Spaces-blue.svg?sanitize=true&#34; alt=&#34;Generic badge&#34;&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;More Jupyter notebook examples can be found in the &lt;code&gt;examples/&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;p&gt;We recommand to run more shots to obtain more desirable prompts.&lt;/p&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;PyTorch =&amp;gt; 1.13.0&lt;/li&gt; &#xA; &lt;li&gt;transformers &amp;gt;= 4.23.1&lt;/li&gt; &#xA; &lt;li&gt;diffusers &amp;gt;= 0.11.1&lt;/li&gt; &#xA; &lt;li&gt;sentence-transformers &amp;gt;= 2.2.2&lt;/li&gt; &#xA; &lt;li&gt;ftfy &amp;gt;= 6.1.1&lt;/li&gt; &#xA; &lt;li&gt;mediapy &amp;gt;= 1.1.2&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;Ensure you have python 3 installed.&lt;/p&gt; &#xA;&lt;p&gt;Create a virtual environment, activate it, and install dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ python -m venv .venv&#xA;$ source .venv/bin/activate&#xA;$ pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;A script is provided to perform prompt inversion (finding a prompt from an image or set of images). For examples of other usages, see &lt;a href=&#34;https://raw.githubusercontent.com/YuxinWenRick/hard-prompts-made-easy/main/examples&#34;&gt;the examples folder&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python run.py image.png&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can pass multiple images to optimize a prompt across all images.&lt;/p&gt; &#xA;&lt;h2&gt;Parameters&lt;/h2&gt; &#xA;&lt;p&gt;Config can be loaded from a JSON file. A sample config is provided at &lt;a href=&#34;https://raw.githubusercontent.com/YuxinWenRick/hard-prompts-made-easy/main/sample_config.json&#34;&gt;./sample-config.json&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Config has the following parameters:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;prompt_len&lt;/code&gt;: the number of tokens in the optimized prompt. 16 empirically results in the most generalizable performance. more is not necessarily better.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;iter&lt;/code&gt;: the total number of iterations to run for.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;lr&lt;/code&gt;: the learning weight for the &lt;a href=&#34;https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html&#34;&gt;optimizer&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;weight_decay&lt;/code&gt;: the weight decay for the optimizer.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;prompt_bs&lt;/code&gt;: number of initializations.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;batch_size&lt;/code&gt;: number of target images/prompts used for each iteration.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;clip_model&lt;/code&gt;: the name of the CLiP model for use with . &lt;code&gt;&#34;ViT-H-14&#34;&lt;/code&gt; is the model used in SD 2.0 and Midjourney. &lt;code&gt;&#34;ViT-L-14&#34;&lt;/code&gt; is the model used in SD 1.5. This should ideally match your target generator.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;clip_pretrain&lt;/code&gt;: the name of the pretrained model for &lt;a href=&#34;https://github.com/mlfoundations/open_clip&#34;&gt;open_clip&lt;/a&gt;. For &lt;code&gt;&#34;ViT-H-14&#34;&lt;/code&gt; use &lt;code&gt;&#34;laion2b_s32b_b79k&#34;&lt;/code&gt;. For &lt;code&gt;&#34;ViT-L-14&#34;&lt;/code&gt; use &lt;code&gt;&#34;openai&#34;&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;print_step&lt;/code&gt;: if not null, how often (in steps) to print a line giving current status.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;print_new_best&lt;/code&gt;: whether to print out new best prompts whenver found. will be quite noisy initially.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Language Model Prompt Experiments&lt;/h2&gt; &#xA;&lt;p&gt;You may check the code in &lt;code&gt;prompt_lm/&lt;/code&gt; folder.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>c4s73r/NetworkNightmare</title>
    <updated>2023-02-11T01:29:12Z</updated>
    <id>tag:github.com,2023-02-11:/c4s73r/NetworkNightmare</id>
    <link href="https://github.com/c4s73r/NetworkNightmare" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Network Pentesting Mindmap by Caster&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;NetworkNightmare&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;&#34;Network Nightmare&#34; Mindmap by Caster&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;It is a mindmap for conducting network attacks. For the most part, it will be useful to pentesters or red team operators. The mindmap will be maintained and updated by me.&lt;/p&gt; &#xA;&lt;h2&gt;Cover&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/c4s73r/NetworkNightmare/main/Mindmap_Cover.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Chapters&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Traffic Hijacking&lt;/li&gt; &#xA; &lt;li&gt;MiTM Attacks&lt;/li&gt; &#xA; &lt;li&gt;Dynamic IGP Routing&lt;/li&gt; &#xA; &lt;li&gt;Configuration Exfiltration&lt;/li&gt; &#xA; &lt;li&gt;DoS&lt;/li&gt; &#xA; &lt;li&gt;NAC/802.1X Bypassing&lt;/li&gt; &#xA; &lt;li&gt;GRE Pivoting&lt;/li&gt; &#xA; &lt;li&gt;Cisco EEM for hiding user&lt;/li&gt; &#xA; &lt;li&gt;Authentication Cracking&lt;/li&gt; &#xA; &lt;li&gt;Information Gathering&lt;/li&gt; &#xA; &lt;li&gt;Cisco Passwords&lt;/li&gt; &#xA; &lt;li&gt;VLAN Bypassing&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
</feed>