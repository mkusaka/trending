<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-06-09T01:29:21Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>tensorzero/tensorzero</title>
    <updated>2025-06-09T01:29:21Z</updated>
    <id>tag:github.com,2025-06-09:/tensorzero/tensorzero</id>
    <link href="https://github.com/tensorzero/tensorzero" rel="alternate"></link>
    <summary type="html">&lt;p&gt;TensorZero creates a feedback loop for optimizing LLM applications ‚Äî turning production data into smarter, faster, and cheaper models.&lt;/p&gt;&lt;hr&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9&#34; width=&#34;128&#34; height=&#34;128&#34;&gt; &#xA;&lt;h1&gt;TensorZero&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;TensorZero creates a feedback loop for optimizing LLM applications ‚Äî turning production data into smarter, faster, and cheaper models.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Integrate our model gateway&lt;/li&gt; &#xA; &lt;li&gt;Send metrics or feedback&lt;/li&gt; &#xA; &lt;li&gt;Optimize prompts, models, and inference strategies&lt;/li&gt; &#xA; &lt;li&gt;Watch your LLMs improve over time&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;It provides a &lt;strong&gt;data &amp;amp; learning flywheel for LLMs&lt;/strong&gt; by unifying:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Inference:&lt;/strong&gt; one API for all LLMs, with &amp;lt;1ms P99 overhead&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Observability:&lt;/strong&gt; inference &amp;amp; feedback ‚Üí your database&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Optimization:&lt;/strong&gt; from prompts to fine-tuning and RL&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Evaluations:&lt;/strong&gt; compare prompts, models, inference strategies&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;Experimentation:&lt;/strong&gt; built-in A/B testing, routing, fallbacks&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/&#34; target=&#34;_blank&#34;&gt;Website&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs&#34; target=&#34;_blank&#34;&gt;Docs&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.x.com/tensorzero&#34; target=&#34;_blank&#34;&gt;Twitter&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/slack&#34; target=&#34;_blank&#34;&gt;Slack&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/discord&#34; target=&#34;_blank&#34;&gt;Discord&lt;/a&gt;&lt;/b&gt; &lt;br&gt; &lt;br&gt; &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/quickstart&#34; target=&#34;_blank&#34;&gt;Quick Start (5min)&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/tutorial&#34; target=&#34;_blank&#34;&gt;Comprehensive Tutorial&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/deployment&#34; target=&#34;_blank&#34;&gt;Deployment Guide&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/api-reference&#34; target=&#34;_blank&#34;&gt;API Reference&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/deployment&#34; target=&#34;_blank&#34;&gt;Configuration Reference&lt;/a&gt;&lt;/b&gt; &lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; valign=&#34;top&#34;&gt;&lt;b&gt;What is TensorZero?&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;70%&#34; valign=&#34;top&#34;&gt;TensorZero is an open-source framework for building production-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluations, and experimentation.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; valign=&#34;top&#34;&gt;&lt;b&gt;How is TensorZero different from other LLM frameworks?&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;70%&#34; valign=&#34;top&#34;&gt; 1. TensorZero enables you to optimize complex LLM applications based on production metrics and human feedback.&lt;br&gt; 2. TensorZero supports the needs of industrial-scale LLM applications: low latency, high throughput, type safety, self-hosted, GitOps, customizability, etc.&lt;br&gt; 3. TensorZero unifies the entire LLMOps stack, creating compounding benefits. For example, LLM evaluations can be used for fine-tuning models alongside AI judges. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; valign=&#34;top&#34;&gt;&lt;b&gt;Can I use TensorZero with ___?&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;70%&#34; valign=&#34;top&#34;&gt;Yes. Every major programming language is supported. You can use TensorZero with our Python client, any OpenAI SDK, or our HTTP API.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; valign=&#34;top&#34;&gt;&lt;b&gt;Is TensorZero production-ready?&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;70%&#34; valign=&#34;top&#34;&gt;Yes. Here&#39;s a case study: &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms&#34;&gt;Automating Code Changelogs at a Large Bank with LLMs&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; valign=&#34;top&#34;&gt;&lt;b&gt;How much does TensorZero cost?&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;70%&#34; valign=&#34;top&#34;&gt;Nothing. TensorZero is 100% self-hosted and open-source. There are no paid features.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; valign=&#34;top&#34;&gt;&lt;b&gt;Who is building TensorZero?&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;70%&#34; valign=&#34;top&#34;&gt;Our technical team includes a former Rust compiler maintainer, machine learning researchers (Stanford, CMU, Oxford, Columbia) with thousands of citations, and the chief product officer of a decacorn startup. We&#39;re backed by the same investors as leading open-source projects (e.g. ClickHouse, CockroachDB) and AI labs (e.g. OpenAI, Anthropic).&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;30%&#34; valign=&#34;top&#34;&gt;&lt;b&gt;How do I get started?&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;70%&#34; valign=&#34;top&#34;&gt;You can adopt TensorZero incrementally. Our &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/quickstart&#34;&gt;Quick Start&lt;/a&gt;&lt;/b&gt; goes from a vanilla OpenAI wrapper to a production-ready LLM application with observability and fine-tuning in just 5 minutes.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;h3&gt;üåê LLM Gateway&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Integrate with TensorZero once and access every major LLM provider.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&lt;/tr&gt; &#xA;  &lt;!-- flip highlight order --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;b&gt;Model Providers&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;b&gt;Features&lt;/b&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;left&#34; valign=&#34;top&#34;&gt; &lt;p&gt; The TensorZero Gateway natively supports: &lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/anthropic&#34;&gt;Anthropic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock&#34;&gt;AWS Bedrock&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker&#34;&gt;AWS SageMaker&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/azure&#34;&gt;Azure OpenAI Service&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/deepseek&#34;&gt;DeepSeek&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/fireworks&#34;&gt;Fireworks&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic&#34;&gt;GCP Vertex AI Anthropic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini&#34;&gt;GCP Vertex AI Gemini&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini&#34;&gt;Google AI Studio (Gemini API)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic&#34;&gt;Hyperbolic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/mistral&#34;&gt;Mistral&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/openai&#34;&gt;OpenAI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/together&#34;&gt;Together&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/vllm&#34;&gt;vLLM&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/xai&#34;&gt;xAI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;p&gt; &lt;em&gt; Need something else? Your provider is most likely supported because TensorZero integrates with &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible&#34;&gt;any OpenAI-compatible API (e.g. Ollama)&lt;/a&gt;&lt;/b&gt;. &lt;/em&gt; &lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;left&#34; valign=&#34;top&#34;&gt; &lt;p&gt; The TensorZero Gateway supports advanced features like: &lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks&#34;&gt;Retries &amp;amp; Fallbacks&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations&#34;&gt;Inference-Time Optimizations&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/prompt-templates-schemas&#34;&gt;Prompt Templates &amp;amp; Schemas&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/tutorial#experimentation&#34;&gt;Experimentation (A/B Testing)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/configuration-reference&#34;&gt;Configuration-as-Code (GitOps)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/batch-inference&#34;&gt;Batch Inference&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/multimodal-inference&#34;&gt;Multimodal Inference (VLMs)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/inference-caching&#34;&gt;Inference Caching&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/metrics-feedback&#34;&gt;Metrics &amp;amp; Feedback&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/episodes&#34;&gt;Multi-Step LLM Workflows (Episodes)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;em&gt;&amp;amp; a lot more...&lt;/em&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;p&gt; The TensorZero Gateway is written in Rust ü¶Ä with &lt;b&gt;performance&lt;/b&gt; in mind (&amp;lt;1ms p99 latency overhead @ 10k QPS). See &lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/benchmarks&#34;&gt;Benchmarks&lt;/a&gt;&lt;/b&gt;.&lt;br&gt; &lt;/p&gt; &lt;p&gt; You can run inference using the &lt;b&gt;TensorZero client&lt;/b&gt; (recommended), the &lt;b&gt;OpenAI client&lt;/b&gt;, or the &lt;b&gt;HTTP API&lt;/b&gt;. &lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;&lt;b&gt;Usage: Python ‚Äî TensorZero Client (Recommended)&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt;You can access any provider using the TensorZero Python client.&lt;/p&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;&lt;code&gt;pip install tensorzero&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; &#xA;  &lt;li&gt;Run inference:&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from tensorzero import TensorZeroGateway  # or AsyncTensorZeroGateway&#xA;&#xA;&#xA;with TensorZeroGateway.build_embedded(clickhouse_url=&#34;...&#34;, config_file=&#34;...&#34;) as client:&#xA;    response = client.inference(&#xA;        model_name=&#34;openai::gpt-4o-mini&#34;,&#xA;        # Try other providers easily: &#34;anthropic::claude-3-7-sonnet-20250219&#34;&#xA;        input={&#xA;            &#34;messages&#34;: [&#xA;                {&#xA;                    &#34;role&#34;: &#34;user&#34;,&#xA;                    &#34;content&#34;: &#34;Write a haiku about artificial intelligence.&#34;,&#xA;                }&#xA;            ]&#xA;        },&#xA;    )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;See &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/quickstart&#34;&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;Usage: Python ‚Äî OpenAI Client&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt;You can access any provider using the OpenAI Python client with TensorZero.&lt;/p&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;&lt;code&gt;pip install tensorzero&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; &#xA;  &lt;li&gt;Run inference:&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from openai import OpenAI  # or AsyncOpenAI&#xA;from tensorzero import patch_openai_client&#xA;&#xA;client = OpenAI()&#xA;&#xA;patch_openai_client(&#xA;    client,&#xA;    clickhouse_url=&#34;http://chuser:chpassword@localhost:8123/tensorzero&#34;,&#xA;    config_file=&#34;config/tensorzero.toml&#34;,&#xA;    async_setup=False,&#xA;)&#xA;&#xA;response = client.chat.completions.create(&#xA;    model=&#34;tensorzero::model_name::openai::gpt-4o-mini&#34;,&#xA;    # Try other providers easily: &#34;tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219&#34;&#xA;    messages=[&#xA;        {&#xA;            &#34;role&#34;: &#34;user&#34;,&#xA;            &#34;content&#34;: &#34;Write a haiku about artificial intelligence.&#34;,&#xA;        }&#xA;    ],&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;See &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/quickstart&#34;&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;Usage: JavaScript / TypeScript (Node) ‚Äî OpenAI Client&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt;You can access any provider using the OpenAI Node client with TensorZero.&lt;/p&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Deploy &lt;code&gt;tensorzero/gateway&lt;/code&gt; using Docker. &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/deployment&#34;&gt;Detailed instructions ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Set up the TensorZero configuration.&lt;/li&gt; &#xA;  &lt;li&gt;Run inference:&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-ts&#34;&gt;import OpenAI from &#34;openai&#34;;&#xA;&#xA;const client = new OpenAI({&#xA;  baseURL: &#34;http://localhost:3000/openai/v1&#34;,&#xA;});&#xA;&#xA;const response = await client.chat.completions.create({&#xA;  model: &#34;tensorzero::model_name::openai::gpt-4o-mini&#34;,&#xA;  // Try other providers easily: &#34;tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219&#34;&#xA;  messages: [&#xA;    {&#xA;      role: &#34;user&#34;,&#xA;      content: &#34;Write a haiku about artificial intelligence.&#34;,&#xA;    },&#xA;  ],&#xA;});&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;See &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/quickstart&#34;&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;Usage: Other Languages &amp;amp; Platforms ‚Äî HTTP API&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt;TensorZero supports virtually any programming language or platform via its HTTP API.&lt;/p&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Deploy &lt;code&gt;tensorzero/gateway&lt;/code&gt; using Docker. &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/deployment&#34;&gt;Detailed instructions ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; &#xA;  &lt;li&gt;Run inference:&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -X POST &#34;http://localhost:3000/inference&#34; \&#xA;  -H &#34;Content-Type: application/json&#34; \&#xA;  -d &#39;{&#xA;    &#34;model_name&#34;: &#34;openai::gpt-4o-mini&#34;,&#xA;    &#34;input&#34;: {&#xA;      &#34;messages&#34;: [&#xA;        {&#xA;          &#34;role&#34;: &#34;user&#34;,&#xA;          &#34;content&#34;: &#34;Write a haiku about artificial intelligence.&#34;&#xA;        }&#xA;      ]&#xA;    }&#xA;  }&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;See &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/quickstart&#34;&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;üìà LLM Optimization&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Send production metrics and human feedback to easily optimize your prompts, models, and inference strategies ‚Äî using the UI or programmatically.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h4&gt;Model Optimization&lt;/h4&gt; &#xA;&lt;p&gt;Optimize closed-source and open-source models using supervised fine-tuning (SFT) and preference fine-tuning (DPO).&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&lt;/tr&gt; &#xA;  &lt;!-- flip highlight order --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;b&gt;Supervised Fine-tuning ‚Äî UI&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;b&gt;Preference Fine-tuning (DPO) ‚Äî Jupyter Notebook&lt;/b&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/cf7acf66-732b-43b3-af2a-5eba1ce40f6f&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/a67a0634-04a7-42b0-b934-9130cb7cdf51&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Inference-Time Optimization&lt;/h4&gt; &#xA;&lt;p&gt;Boost performance by dynamically updating your prompts with relevant examples, combining responses from multiple inferences, and more.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&lt;/tr&gt; &#xA;  &lt;!-- flip highlight order --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling&#34;&gt;Best-of-N Sampling&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#mixture-of-n-sampling&#34;&gt;Mixture-of-N Sampling&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/c0edfa4c-713c-4996-9964-50c0d26e6970&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/75b5bf05-4c1f-43c4-b158-d69d1b8d05be&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl&#34;&gt;Dynamic In-Context Learning (DICL)&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#chain-of-thought-cot&#34;&gt;Chain-of-Thought (CoT)&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/d8489e92-ce93-46ac-9aab-289ce19bb67d&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/ea13d73c-76a4-4e0c-a35b-0c648f898311&#34; height=&#34;320&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;em&gt;More coming soon...&lt;/em&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h4&gt;Prompt Optimization&lt;/h4&gt; &#xA;&lt;p&gt;Optimize your prompts programmatically using research-driven optimization techniques.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&lt;/tr&gt; &#xA;  &lt;!-- flip highlight order --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;b&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling&#34;&gt;MIPROv2&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy&#34;&gt;DSPy Integration&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/d81a7c37-382f-4c46-840f-e6c2593301db&#34; alt=&#34;MIPROv2 diagram&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt; TensorZero comes with several optimization recipes, but you can also easily create your own. This example shows how to optimize a TensorZero function using an arbitrary tool ‚Äî here, DSPy, a popular library for automated prompt engineering. &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;em&gt;More coming soon...&lt;/em&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;üîç LLM Observability&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Zoom in to debug individual API calls, or zoom out to monitor metrics across models and prompts over time ‚Äî all using the open-source TensorZero UI.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&lt;/tr&gt; &#xA;  &lt;!-- flip highlight order --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;b&gt;Observability ¬ª Inference&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;b&gt;Observability ¬ª Function&lt;/b&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/2cc3cc9a-f33f-4e94-b8de-07522326f80a&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/00ae6605-8fa0-4efd-8238-ae8ea589860f&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;üìä LLM Evaluations&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Compare prompts, models, and inference strategies using TensorZero Evaluations ‚Äî with support for heuristics and LLM judges.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt;&lt;/tr&gt; &#xA;  &lt;!-- flip highlight order --&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;b&gt;Evaluation ¬ª UI&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;b&gt;Evaluation ¬ª CLI&lt;/b&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;center&#34; valign=&#34;middle&#34;&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;50%&#34; align=&#34;left&#34; valign=&#34;middle&#34;&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose run --rm evaluations \&#xA;  --evaluation-name extract_data \&#xA;  --dataset-name hard_test_cases \&#xA;  --variant-name gpt_4o \&#xA;  --concurrency 5&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4&#xA;Number of datapoints: 100&#xA;‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100/100&#xA;exact_match: 0.83 ¬± 0.03&#xA;semantic_match: 0.98 ¬± 0.01&#xA;item_count: 7.15 ¬± 0.39&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Watch LLMs get better at data extraction in real-time with TensorZero!&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl&#34;&gt;Dynamic in-context learning (DICL)&lt;/a&gt;&lt;/strong&gt; is a powerful inference-time optimization available out of the box with TensorZero. It enhances LLM performance by automatically incorporating relevant historical examples into the prompt, without the need for model fine-tuning.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb&#34;&gt;https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;LLM Engineering with TensorZero&lt;/h2&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.tensorzero.com/docs&#34;&gt; &#xA;  &lt;picture&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6&#34;&gt; &#xA;   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://github.com/user-attachments/assets/e8bc699b-6378-4c2a-9cc1-6d189025e270&#34;&gt; &#xA;   &lt;img alt=&#34;TensorZero Flywheel&#34; src=&#34;https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6&#34; width=&#34;720&#34;&gt; &#xA;  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/&#34;&gt;TensorZero Gateway&lt;/a&gt;&lt;/strong&gt; is a high-performance model gateway written in Rust ü¶Ä that provides a unified API interface for all major LLM providers, allowing for seamless cross-platform integration and fallbacks.&lt;/li&gt; &#xA; &lt;li&gt;It handles structured schema-based inference with &amp;lt;1ms P99 latency overhead (see &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/benchmarks&#34;&gt;Benchmarks&lt;/a&gt;&lt;/strong&gt;) and built-in observability, experimentation, and &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations&#34;&gt;inference-time optimizations&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;It also collects downstream metrics and feedback associated with these inferences, with first-class support for multi-step LLM systems.&lt;/li&gt; &#xA; &lt;li&gt;Everything is stored in a ClickHouse data warehouse that you control for real-time, scalable, and developer-friendly analytics.&lt;/li&gt; &#xA; &lt;li&gt;Over time, &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/recipes&#34;&gt;TensorZero Recipes&lt;/a&gt;&lt;/strong&gt; leverage this structured dataset to optimize your prompts and models: run pre-built recipes for common workflows like fine-tuning, or create your own with complete flexibility using any language and platform.&lt;/li&gt; &#xA; &lt;li&gt;Finally, the gateway&#39;s experimentation features and GitOps orchestration enable you to iterate and deploy with confidence, be it a single LLM or thousands of LLMs.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Our goal is to help engineers build, manage, and optimize the next generation of LLM applications: systems that learn from real-world experience. Read more about our &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/vision-roadmap/&#34;&gt;Vision &amp;amp; Roadmap&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Get Started&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Start building today.&lt;/strong&gt; The &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/quickstart&#34;&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; shows it&#39;s easy to set up an LLM application with TensorZero. If you want to dive deeper, the &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/docs/gateway/tutorial&#34;&gt;Tutorial&lt;/a&gt;&lt;/strong&gt; teaches how to build a simple chatbot, an email copilot, a weather RAG system, and a structured data extraction pipeline.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Questions?&lt;/strong&gt; Ask us on &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/slack&#34;&gt;Slack&lt;/a&gt;&lt;/strong&gt; or &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/discord&#34;&gt;Discord&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Using TensorZero at work?&lt;/strong&gt; Email us at &lt;strong&gt;&lt;a href=&#34;mailto:hello@tensorzero.com&#34;&gt;hello@tensorzero.com&lt;/a&gt;&lt;/strong&gt; to set up a Slack or Teams channel with your team (free).&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Work with us.&lt;/strong&gt; We&#39;re &lt;strong&gt;&lt;a href=&#34;https://www.tensorzero.com/jobs&#34;&gt;hiring in NYC&lt;/a&gt;&lt;/strong&gt;. We&#39;d also welcome &lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/raw/main/CONTRIBUTING.md&#34;&gt;open-source contributions&lt;/a&gt;&lt;/strong&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;We are working on a series of &lt;strong&gt;complete runnable examples&lt;/strong&gt; illustrating TensorZero&#39;s data &amp;amp; learning flywheel.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner&#34;&gt;Optimizing Data Extraction (NER) with TensorZero&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;This example shows how to use TensorZero to optimize a data extraction pipeline. We demonstrate techniques like fine-tuning and dynamic in-context learning (DICL). In the end, an optimized GPT-4o Mini model outperforms GPT-4o on this task ‚Äî at a fraction of the cost and latency ‚Äî using a small amount of training data.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/&#34;&gt;Agentic RAG ‚Äî Multi-Hop Question Answering with LLMs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;This example shows how to build a multi-hop retrieval agent using TensorZero. The agent iteratively searches Wikipedia to gather information, and decides when it has enough context to answer a complex question.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences&#34;&gt;Writing Haikus to Satisfy a Judge with Hidden Preferences&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;This example fine-tunes GPT-4o Mini to generate haikus tailored to a specific taste. You&#39;ll see TensorZero&#39;s &#34;data flywheel in a box&#34; in action: better variants leads to better data, and better data leads to better variants. You&#39;ll see progress by fine-tuning the LLM multiple times.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles/&#34;&gt;Improving LLM Chess Ability with Best-of-N Sampling&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;This example showcases how best-of-N sampling can significantly enhance an LLM&#39;s chess-playing abilities by selecting the most promising moves from multiple generated options.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy&#34;&gt;Improving Math Reasoning with a Custom Recipe for Automated Prompt Engineering (DSPy)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;TensorZero provides a number of pre-built optimization recipes covering common LLM engineering workflows. But you can also easily create your own recipes and workflows! This example shows how to optimize a TensorZero function using an arbitrary tool ‚Äî here, DSPy.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;em&gt;&amp;amp; many more on the way!&lt;/em&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>iib0011/omni-tools</title>
    <updated>2025-06-09T01:29:21Z</updated>
    <id>tag:github.com,2025-06-09:/iib0011/omni-tools</id>
    <link href="https://github.com/iib0011/omni-tools" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Self-hosted collection of powerful web-based tools for everyday tasks. No ads, no tracking, just fast, accessible utilities right from your browser!&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/iib0011/omni-tools/main/src/assets/logo.png&#34; width=&#34;300&#34;&gt; &#xA; &lt;br&gt;&#xA; &lt;br&gt; &#xA; &lt;a href=&#34;https://trendshift.io/repositories/13055&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://trendshift.io/api/badge/repositories/13055&#34; alt=&#34;iib0011%2Fomni-tools | Trendshift&#34; style=&#34;width: 200px;&#34; width=&#34;200&#34;&gt;&lt;/a&gt; &#xA; &lt;br&gt;&#xA; &lt;br&gt; &#xA; &lt;a href=&#34;https://github.com/iib0011/omni-tools/releases&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/version-0.4.0-blue?style=for-the-badge&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://hub.docker.com/r/iib0011/omni-tools&#34;&gt; &lt;img src=&#34;https://img.shields.io/docker/pulls/iib0011/omni-tools?style=for-the-badge&amp;amp;logo=docker&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/iib0011&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/iib0011/omni-tools?style=for-the-badge&amp;amp;logo=github&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://github.com/iib0011/omni-tools/raw/main/LICENSE&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/iib0011/omni-tools?style=for-the-badge&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://discord.gg/SDbbn3hT4b&#34;&gt; &lt;img src=&#34;https://img.shields.io/discord/1342971141823664179?label=Discord&amp;amp;style=for-the-badge&#34;&gt; &lt;/a&gt; &#xA; &lt;br&gt;&#xA; &lt;br&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Welcome to OmniTools, a self-hosted web app offering a variety of online tools to simplify everyday tasks. Whether you are coding, manipulating images/videos, PDFs or crunching numbers, OmniTools has you covered. Please don&#39;t forget to star the repo to support us. Here is the &lt;a href=&#34;https://omnitools.app&#34;&gt;demo&lt;/a&gt; website.&lt;/p&gt; &#xA;&lt;p&gt;All files are processed entirely on the client side: nothing ever leaves your device. Plus, the Docker image is super lightweight at just 28MB, making it fast to deploy and easy to self-host.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/iib0011/omni-tools/main/img.png&#34; alt=&#34;img.png&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/iib0011/omni-tools/main/#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/iib0011/omni-tools/main/#self-hostrun&#34;&gt;Self-host&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/iib0011/omni-tools/main/#contribute&#34;&gt;Contribute&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/iib0011/omni-tools/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/iib0011/omni-tools/main/#contact&#34;&gt;Contact&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;We strive to offer a variety of tools, including:&lt;/p&gt; &#xA;&lt;h2&gt;&lt;strong&gt;Image/Video/Binary Tools&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Image Resizer&lt;/li&gt; &#xA; &lt;li&gt;Image Converter&lt;/li&gt; &#xA; &lt;li&gt;Video Trimmer&lt;/li&gt; &#xA; &lt;li&gt;Video Reverser&lt;/li&gt; &#xA; &lt;li&gt;And more...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;strong&gt;String/List Tools&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Case Converters&lt;/li&gt; &#xA; &lt;li&gt;List Shuffler&lt;/li&gt; &#xA; &lt;li&gt;Text Formatters&lt;/li&gt; &#xA; &lt;li&gt;And more...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;strong&gt;Date and Time Tools&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Date Calculators&lt;/li&gt; &#xA; &lt;li&gt;Time Zone Converters&lt;/li&gt; &#xA; &lt;li&gt;And more...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;strong&gt;Math Tools&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Generate Prime Numbers&lt;/li&gt; &#xA; &lt;li&gt;Generate Perfect Numbers&lt;/li&gt; &#xA; &lt;li&gt;And more...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;strong&gt;Miscellaneous Tools&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;JSON Tools&lt;/li&gt; &#xA; &lt;li&gt;PDF Tools&lt;/li&gt; &#xA; &lt;li&gt;CSV Tools&lt;/li&gt; &#xA; &lt;li&gt;And more...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Stay tuned as we continue to expand and improve our collection!&lt;/p&gt; &#xA;&lt;h2&gt;Self-host/Run&lt;/h2&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d --name omni-tools --restart unless-stopped -p 8080:80 iib0011/omni-tools:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Docker Compose&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;services:&#xA;  omni-tools:&#xA;    image: iib0011/omni-tools:latest&#xA;    container_name: omni-tools&#xA;    restart: unless-stopped&#xA;    ports:&#xA;      - &#34;8080:80&#34;&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contribute&lt;/h2&gt; &#xA;&lt;p&gt;This is a React Project with Typescript Material UI. We use icons from &lt;a href=&#34;https://icon-sets.iconify.design&#34;&gt;Iconify&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Project setup&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/iib0011/omni-tools.git&#xA;cd omni-tools&#xA;npm i&#xA;npm run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Create a new tool&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run script:create:tool my-tool-name folder1 # npm run script:create:tool split pdf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For tools located under multiple nested directories, use:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run script:create:tool my-tool-name folder1/folder2 # npm run script:create:tool compress image/png&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Use &lt;code&gt;folder1\folder2&lt;/code&gt; on Windows.&lt;/p&gt; &#xA;&lt;h3&gt;Run tests&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;For e2e tests&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm run test:e2e&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://api.star-history.com/svg?repos=iib0011/omni-tools&amp;amp;type=Date&#34;&gt; &#xA;&lt;h2&gt;ü§ù Looking to contribute?&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions! You can help by:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;‚úÖ Reporting bugs&lt;/li&gt; &#xA; &lt;li&gt;‚úÖ Suggesting new features in Github issues or &lt;a href=&#34;https://tally.so/r/nrkkx2&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;‚úÖ Improving documentation&lt;/li&gt; &#xA; &lt;li&gt;‚úÖ Submitting pull requests&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can also join our &lt;a href=&#34;https://discord.gg/SDbbn3hT4b&#34;&gt;Discord server&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Contributors&lt;/h3&gt; &#xA;&lt;a href=&#34;https://github.com/iib0011/omni-tools/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=iib0011/omni-tools&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;For any questions or suggestions, feel free to open an issue or contact me at: &lt;a href=&#34;mailto:ibracool99@gmail.com&#34;&gt;ibracool99@gmail.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the MIT License. See the &lt;a href=&#34;https://raw.githubusercontent.com/iib0011/omni-tools/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Daymychen/art-design-pro</title>
    <updated>2025-06-09T01:29:21Z</updated>
    <id>tag:github.com,2025-06-09:/Daymychen/art-design-pro</id>
    <link href="https://github.com/Daymychen/art-design-pro" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Vue 3 admin dashboard template using Vite + TypeScript + Element Plus | vue3 admin | vue-admin ‚Äî focused on user experience and visual design.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;English | &lt;a href=&#34;https://raw.githubusercontent.com/Daymychen/art-design-pro/main/README.zh-CN.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;About Art Design Pro&lt;/h2&gt; &#xA;&lt;p&gt;As a developer, I needed to build admin management systems for multiple projects but found that traditional systems couldn&#39;t fully meet the requirements for user experience and visual design. Therefore, I created Art Design Pro, an open-source admin management solution focused on user experience and rapid development. Based on the ElementPlus design specifications, it has been visually optimized to provide a more beautiful and practical front-end interface, helping you easily build high-quality admin systems.&lt;/p&gt; &#xA;&lt;h2&gt;Demo Images&lt;/h2&gt; &#xA;&lt;h3&gt;Light Theme&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://www.qiniu.lingchen.kim/art_design_pro_readme_cover1.png&#34; alt=&#34;Light Theme&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://www.qiniu.lingchen.kim/art_design_pro_readme_cover2.png&#34; alt=&#34;Light Theme&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Dark Theme&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://www.qiniu.lingchen.kim/art_design_pro_readme_cover3.png&#34; alt=&#34;Dark Theme&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://www.qiniu.lingchen.kim/art_design_pro_readme_cover4.png&#34; alt=&#34;Dark Theme&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Uses the latest technology stack&lt;/li&gt; &#xA; &lt;li&gt;Built-in common business component templates&lt;/li&gt; &#xA; &lt;li&gt;Provides multiple theme modes and customizable themes&lt;/li&gt; &#xA; &lt;li&gt;Beautiful UI design, excellent user experience, and attention to detail&lt;/li&gt; &#xA; &lt;li&gt;System fully supports customization, meeting your personalized needs&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Functionality&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Rich theme switching&lt;/li&gt; &#xA; &lt;li&gt;Global search&lt;/li&gt; &#xA; &lt;li&gt;Lock screen&lt;/li&gt; &#xA; &lt;li&gt;Multi-tabs&lt;/li&gt; &#xA; &lt;li&gt;Global breadcrumbs&lt;/li&gt; &#xA; &lt;li&gt;Multi-language support&lt;/li&gt; &#xA; &lt;li&gt;Icon library&lt;/li&gt; &#xA; &lt;li&gt;Rich text editor&lt;/li&gt; &#xA; &lt;li&gt;Echarts charts&lt;/li&gt; &#xA; &lt;li&gt;Utils toolkit&lt;/li&gt; &#xA; &lt;li&gt;Network exception handling&lt;/li&gt; &#xA; &lt;li&gt;Route-level authentication&lt;/li&gt; &#xA; &lt;li&gt;Sidebar menu authentication&lt;/li&gt; &#xA; &lt;li&gt;Authentication directives&lt;/li&gt; &#xA; &lt;li&gt;Mobile adaptation&lt;/li&gt; &#xA; &lt;li&gt;Excellent persistent storage solution&lt;/li&gt; &#xA; &lt;li&gt;Local data storage validation&lt;/li&gt; &#xA; &lt;li&gt;Code commit validation and formatting&lt;/li&gt; &#xA; &lt;li&gt;Code commit standardization&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Compatibility&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Supports modern mainstream browsers such as Chrome, Safari, Firefox, etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation and Running&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Install dependencies&#xA;pnpm install&#xA;&#xA;# If pnpm install fails, try using the following command to install dependencies&#xA;pnpm install --ignore-scripts&#xA;&#xA;# Start local development environment&#xA;pnpm dev&#xA;&#xA;# Build for production&#xA;pnpm build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Technical Support&lt;/h2&gt; &#xA;&lt;p&gt;QQ Group: &lt;a href=&#34;https://qm.qq.com/cgi-bin/qm/qr?k=Gg6yzZLFaNgmRhK0T5Qcjf7-XcAFWWXm&amp;amp;jump_from=webapi&amp;amp;authKey=YpRKVJQyFKYbGTiKw0GJ/YQXnNF+GdXNZC5beQQqnGZTvuLlXoMO7nw5fNXvmVhA&#34;&gt;821834289&lt;/a&gt; (Click the link to join the group chat)&lt;/p&gt; &#xA;&lt;h2&gt;Donation&lt;/h2&gt; &#xA;&lt;p&gt;If my project has been helpful to you, donations are welcome! Your support will be used to purchase tools like ChatGPT, Cursor, etc., to improve development efficiency and make the project even better. Thank you for your encouragement and support!&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://www.qiniu.lingchen.kim/%E7%BB%84%202%402x%202.png&#34; alt=&#34;Donation QR Code&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>