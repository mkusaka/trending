<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-10-21T01:28:31Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>solana-developers/program-examples</title>
    <updated>2024-10-21T01:28:31Z</updated>
    <id>tag:github.com,2024-10-21:/solana-developers/program-examples</id>
    <link href="https://github.com/solana-developers/program-examples" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A repository of Solana program examples&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Program Examples&lt;/h1&gt; &#xA;&lt;h2&gt;Onchain program examples for &lt;span&gt;‚öì&lt;/span&gt; Anchor &lt;span&gt;ü¶Ä&lt;/span&gt; Native Rust, [TS] TypeScript and &lt;span&gt;üêç&lt;/span&gt; Python&lt;/h2&gt; &#xA;&lt;p&gt;This repo contains Solana onchain programs (referred to as &#39;Smart Contracts&#39; in other blockchains).&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] If you&#39;re new to Solana, you don&#39;t need to create your own programs to perform basic things like making accounts, creating tokens, sending tokens, or minting NFTs. These common tasks are handled with existing programs, for example the System Program (for making account or transferring SOL) or the token program (for creating tokens and NFTs). See the &lt;a href=&#34;https://solana.com/developers&#34;&gt;Solana Developer site&lt;/a&gt; to learn more.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Each folder includes examples for one or more of the following:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;anchor&lt;/code&gt; - Written using &lt;a href=&#34;https://www.anchor-lang.com/&#34;&gt;Anchor&lt;/a&gt;, the most popular framework for Solana Development, which uses Rust. Use &lt;code&gt;anchor build &amp;amp;&amp;amp; anchor deploy&lt;/code&gt; to build &amp;amp; deploy the program. Run &lt;code&gt;anchor run test&lt;/code&gt; to test it.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;native&lt;/code&gt; - Written using Solana&#39;s native Rust crates and vanilla Rust. Use &lt;code&gt;cicd.sh&lt;/code&gt; to build &amp;amp; deploy the program. Run &lt;code&gt;yarn run test&lt;/code&gt; to test it.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;poseidon&lt;/code&gt; - Written using &lt;a href=&#34;https://turbin3.github.io/poseidon&#34;&gt;Poseidon&lt;/a&gt;, which converts your TypeScript code to Anchor Rust.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;seahorse&lt;/code&gt; - Written using the &lt;a href=&#34;https://seahorse-lang.org/&#34;&gt;Seahorse framework&lt;/a&gt;, which converts your Python code to Anchor Rust. Use &lt;code&gt;seahorse build &amp;amp;&amp;amp; anchor deploy&lt;/code&gt; to build &amp;amp; deploy the program. Run &lt;code&gt;anchor run test&lt;/code&gt; to test it.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;If a given example is missing, please send us a PR to add it!&lt;/strong&gt; Our aim is to have every example available in every option. We&#39;d also love to see more programs involving staking, wrapped tokens, oracles, compression and VRF. Follow the &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/CONTRIBUTING.md&#34;&gt;contributing guidelines&lt;/a&gt; to keep things consistent.&lt;/p&gt; &#xA;&lt;h2&gt;The example programs&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Basics&lt;/summary&gt; &#xA; &lt;h3&gt;Hello world&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/hello-solana/README.md&#34;&gt;Hello World on Solana! A minimal program that logs a greeting.&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/hello-solana/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/hello-solana/native&#34;&gt;native&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/hello-solana/seahorse&#34;&gt;seahorse&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Account-data&lt;/h3&gt; &#xA; &lt;p&gt;Store and retrieve data using Solana accounts.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/account-data/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/account-data/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Storing global state - Counter&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/counter/README.md&#34;&gt;Use a PDA to store global state, making a counter that increments when called.&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/counter/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/counter/native&#34;&gt;native&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/counter/seahorse&#34;&gt;seahorse&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Saving per-user state - Favorites&lt;/h3&gt; &#xA; &lt;p&gt;Save and update per-user state on the blockchain, ensuring users can only update their own information.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/favorites/anchor&#34;&gt;anchor&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Checking Instruction Accounts&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/checking-accounts/README.md&#34;&gt;Check that the accounts provided in incoming instructions meet particular criteria.&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/checking-accounts/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/checking-accounts/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Closing Accounts&lt;/h3&gt; &#xA; &lt;p&gt;Close an account and get the Lamports back.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/close-account/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/close-account/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Creating Accounts&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/create-account/README.md&#34;&gt;Make new accounts on the blockchain.&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/create-account/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/create-account/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Cross program invocations&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/cross-program-invocation/README.md&#34;&gt;Invoke an instruction handler from one onchain program in another onchain program.&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/cross-program-invocation/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/cross-program-invocation/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;PDA rent-payer&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/pda-rent-payer/README.md&#34;&gt;Use a PDA to pay the rent for the creation of a new account.&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/pda-rent-payer/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/pda-rent-payer/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Processing instructions&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/processing-instructions/README.md&#34;&gt;Add parameters to an instruction handler and use them.&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/processing-instructions/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/processing-instructions/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Storing date in program derived addresses&lt;/h3&gt; &#xA; &lt;p&gt;Store and retrieve state in Solana.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/program-derived-addresses/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/program-derived-addresses/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Handling accounts that expland in size&lt;/h3&gt; &#xA; &lt;p&gt;How to store state that changes size in Solana.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/realloc/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/realloc/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Calculating account size to determine rent&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/rent/README.md&#34;&gt;Determine the necessary minimum rent by calculating an account&#39;s size.&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/rent/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/rent/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Laying out larger programs&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/repository-layout/README.md&#34;&gt;Layout larger Solana onchain programs.&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/repository-layout/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/repository-layout/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Transferring SOL&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/transfer-sol/README.md&#34;&gt;Send SOL between two accounts.&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/transfer-sol/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/transfer-sol/native&#34;&gt;native&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/basics/transfer-sol/seahorse&#34;&gt;seahorse&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Tokens&lt;/summary&gt; &#xA; &lt;h3&gt;Creating tokens&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/create-token/README.md&#34;&gt;Create a token on Solana with a token symbol and icon.&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/create-token/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/create-token/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Minting NFTS&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/nft-minter/README.md&#34;&gt;Mint an NFT from inside your own onchain program using the Token and Metaplex Token Metadata programs.&lt;/a&gt; Reminder: you don&#39;t need your own program just to mint an NFT, see the note at the top of this README.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/nft-minter/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/nft-minter/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Minting a token from inside a program&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/spl-token-minter/README.md&#34;&gt;Mint a Token from inside your own onchain program using the Token program.&lt;/a&gt; Reminder: you don&#39;t need your own program just to mint an NFT, see the note at the top of this README.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/spl-token-minter/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/spl-token-minter/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Transferring Tokens&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/transfer-tokens/README.md&#34;&gt;Transfer tokens between accounts&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/transfer-tokens/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/transfer-tokens/native&#34;&gt;native&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/transfer-tokens/seahorse&#34;&gt;seahorse&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Allowing users to swap digital assets - Escrow&lt;/h3&gt; &#xA; &lt;p&gt;Allow two users to swap digital assets with each other, each getting 100% of what the other has offered due to the power of decentralization!&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/escrow/anchor&#34;&gt;anchor&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Minting a token from inside a program with a PDA as the mint authority&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/pda-mint-authority/README.md&#34;&gt;Mint a Token from inside your own onchain program using the Token program.&lt;/a&gt; Reminder: you don&#39;t need your own program just to mint an NFT, see the note at the top of this README.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/pda-mint-authority/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/pda-mint-authority/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Creating an Automated Market Maker&lt;/h3&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-swap/README.md&#34;&gt;Create liquidity pools to allow trading of new digital assets and allows users that provide liquidity to be rewarded by creating an Automated Market Maker.&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-swap/anchor&#34;&gt;anchor&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Token Extensions&lt;/summary&gt; &#xA; &lt;h3&gt;Basics - create token mints, mint tokens, and transfer tokens with Token Extensions&lt;/h3&gt; &#xA; &lt;p&gt;Create token mints, mint tokens, and transferr tokens using Token Extensions.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/basics/anchor&#34;&gt;anchor&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Preventing CPIs with CPI guard&lt;/h3&gt; &#xA; &lt;p&gt;Enable CPI guard to prevents certain token action from occurring within CPI (Cross-Program Invocation).&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/cpi-guard/anchor&#34;&gt;anchor&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Using default account state&lt;/h3&gt; &#xA; &lt;p&gt;Create new token accounts that are frozen by default.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/default-account-state/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/default-account-state/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Grouping tokens&lt;/h3&gt; &#xA; &lt;p&gt;Create tokens that belong to larger groups of tokens using the Group Pointer extension.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/group/anchor&#34;&gt;anchor&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Creating token accounts whose owner cannot be changed&lt;/h3&gt; &#xA; &lt;p&gt;Create tokens whose owning program cannot be changed.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/immutable-owner/anchor&#34;&gt;anchor&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Interest bearing tokens&lt;/h3&gt; &#xA; &lt;p&gt;Create tokens that show an &#39;interest&#39; calculation.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/interest-bearing/anchor&#34;&gt;anchor&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Requiring transactions to include descriptive memos&lt;/h3&gt; &#xA; &lt;p&gt;Create tokens where transfers must have a memo describing the transaction attached.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/memo-transfer/anchor&#34;&gt;anchor&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Adding on-chain metadata to the token mint&lt;/h3&gt; &#xA; &lt;p&gt;Create tokens that store their onchain metadata inside the token mint, without needing to use or pay for additional programs.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/metadata/anchor&#34;&gt;anchor&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Allow a designedated account to close a mint&lt;/h3&gt; &#xA; &lt;p&gt;Allow a designated account to close a Mint.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/mint-close-authority/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/mint-close-authority/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Usng multiple token extensions&lt;/h3&gt; &#xA; &lt;p&gt;Use multiple Token Extensions at once.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/multiple-extensions/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Non-transferrable - create tokens that can&#39;t be transferred.&lt;/h3&gt; &#xA; &lt;p&gt;Create tokens that cannot be transferred.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/non-transferable/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/non-transferable/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Permanent Delegate - Create tokens permanently under the control of a particular account&lt;/h3&gt; &#xA; &lt;p&gt;Create tokens that remain under the control of an account, even when transferred elsewhere.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/permanent-delegate/anchor&#34;&gt;anchor&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Create tokens with a transfer-fee.&lt;/h3&gt; &#xA; &lt;p&gt;Create tokens with an inbuilt transfer fee.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/transfer-fee/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/tokens/token-2022/transfer-fee/native&#34;&gt;native&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Compression&lt;/summary&gt; &#xA; &lt;h3&gt;Cnft-burn&lt;/h3&gt; &#xA; &lt;p&gt;Burn compressed NFTs.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/compression/cnft-burn/anchor&#34;&gt;anchor&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Cnft-vault&lt;/h3&gt; &#xA; &lt;p&gt;Store Metaplex compressed NFTs inside a PDA.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/compression/cnft-vault/anchor&#34;&gt;anchor&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h3&gt;Cutils&lt;/h3&gt; &#xA; &lt;p&gt;Work with Metaplex compressed NFTs.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/compression/cutils/anchor&#34;&gt;anchor&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Oracles&lt;/summary&gt; &#xA; &lt;h3&gt;pyth&lt;/h3&gt; &#xA; &lt;p&gt;Use a data source for offchain data (called an Oracle) to perform activities onchain.&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/oracles/pyth/anchor&#34;&gt;anchor&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/solana-developers/program-examples/main/oracles/pyth/seahorse&#34;&gt;seahorse&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;hr&gt;</summary>
  </entry>
  <entry>
    <title>serengil/deepface</title>
    <updated>2024-10-21T01:28:31Z</updated>
    <id>tag:github.com,2024-10-21:/serengil/deepface</id>
    <link href="https://github.com/serengil/deepface" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A Lightweight Face Recognition and Facial Attribute Analysis (Age, Gender, Emotion and Race) Library for Python&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;deepface&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://pepy.tech/project/deepface&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/personalized-badge/deepface?period=total&amp;amp;units=international_system&amp;amp;left_color=grey&amp;amp;right_color=blue&amp;amp;left_text=downloads&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/serengil/deepface/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/serengil/deepface?color=yellow&amp;amp;style=flat&amp;amp;label=%E2%AD%90%20stars&#34; alt=&#34;Stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/serengil/deepface/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;http://img.shields.io/:license-MIT-green.svg?style=flat&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/serengil/deepface/actions/workflows/tests.yml&#34;&gt;&lt;img src=&#34;https://github.com/serengil/deepface/actions/workflows/tests.yml/badge.svg?sanitize=true&#34; alt=&#34;Tests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.17671/gazibtd.1399077&#34;&gt;&lt;img src=&#34;http://img.shields.io/:DOI-10.17671/gazibtd.1399077-blue.svg?style=flat&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://sefiks.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/:blog-sefiks.com-blue.svg?style=flat&amp;amp;logo=wordpress&#34; alt=&#34;Blog&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/@sefiks?sub_confirmation=1&#34;&gt;&lt;img src=&#34;https://img.shields.io/:youtube-@sefiks-red.svg?style=flat&amp;amp;logo=youtube&#34; alt=&#34;YouTube&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/intent/user?screen_name=serengil&#34;&gt;&lt;img src=&#34;https://img.shields.io/:follow-@serengil-blue.svg?style=flat&amp;amp;logo=x&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.patreon.com/serengil?repo=deepface&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https%3A%2F%2Fshieldsio-patreon.vercel.app%2Fapi%3Fusername%3Dserengil%26type%3Dpatrons&amp;amp;style=flat&#34; alt=&#34;Support me on Patreon&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/sponsors/serengil&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/sponsors/serengil?logo=GitHub&amp;amp;color=lightgray&#34; alt=&#34;GitHub Sponsors&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://buymeacoffee.com/serengil&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-buy_me_a%C2%A0coffee-gray?logo=buy-me-a-coffee&#34; alt=&#34;Buy Me a Coffee&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;!-- [![DOI](http://img.shields.io/:DOI-10.1109/ICEET53442.2021.9659697-blue.svg?style=flat)](https://doi.org/10.1109/ICEET53442.2021.9659697) --&gt; &#xA; &lt;!-- [![DOI](http://img.shields.io/:DOI-10.1109/ASYU50717.2020.9259802-blue.svg?style=flat)](https://doi.org/10.1109/ASYU50717.2020.9259802) --&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-icon-labeled.png&#34; width=&#34;200&#34; height=&#34;240&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;DeepFace is a lightweight &lt;a href=&#34;https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/&#34;&gt;face recognition&lt;/a&gt; and facial attribute analysis (&lt;a href=&#34;https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/&#34;&gt;age&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/&#34;&gt;gender&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/&#34;&gt;emotion&lt;/a&gt; and &lt;a href=&#34;https://sefiks.com/2019/11/11/race-and-ethnicity-prediction-in-keras/&#34;&gt;race&lt;/a&gt;) framework for python. It is a hybrid face recognition framework wrapping &lt;strong&gt;state-of-the-art&lt;/strong&gt; models: &lt;a href=&#34;https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/&#34;&gt;&lt;code&gt;VGG-Face&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2018/09/03/face-recognition-with-facenet-in-keras/&#34;&gt;&lt;code&gt;FaceNet&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2019/07/21/face-recognition-with-openface-in-keras/&#34;&gt;&lt;code&gt;OpenFace&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2020/02/17/face-recognition-with-facebook-deepface-in-keras/&#34;&gt;&lt;code&gt;DeepFace&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2020/06/16/face-recognition-with-deepid-in-keras/&#34;&gt;&lt;code&gt;DeepID&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2020/12/14/deep-face-recognition-with-arcface-in-keras-and-python/&#34;&gt;&lt;code&gt;ArcFace&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2020/07/11/face-recognition-with-dlib-in-python/&#34;&gt;&lt;code&gt;Dlib&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;SFace&lt;/code&gt; and &lt;code&gt;GhostFaceNet&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/serengil/deepface/tree/master/benchmarks&#34;&gt;&lt;code&gt;Experiments&lt;/code&gt;&lt;/a&gt; show that &lt;strong&gt;human beings have 97.53% accuracy&lt;/strong&gt; on facial recognition tasks whereas those models already reached and passed that accuracy level.&lt;/p&gt; &#xA;&lt;h2&gt;Installation &lt;a href=&#34;https://pypi.org/project/deepface/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/deepface.svg?sanitize=true&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;The easiest way to install deepface is to download it from &lt;a href=&#34;https://pypi.org/project/deepface/&#34;&gt;&lt;code&gt;PyPI&lt;/code&gt;&lt;/a&gt;. It&#39;s going to install the library itself and its prerequisites as well.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ pip install deepface&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, you can also install deepface from its source code. Source code may have new features not published in pip release yet.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ git clone https://github.com/serengil/deepface.git&#xA;$ cd deepface&#xA;$ pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once you installed the library, then you will be able to import it and use its functionalities.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from deepface import DeepFace&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;A Modern Facial Recognition Pipeline&lt;/strong&gt; - &lt;a href=&#34;https://youtu.be/WnUVYQP4h44&#34;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;A modern &lt;a href=&#34;https://sefiks.com/2020/05/01/a-gentle-introduction-to-face-recognition-in-deep-learning/&#34;&gt;&lt;strong&gt;face recognition pipeline&lt;/strong&gt;&lt;/a&gt; consists of 5 common stages: &lt;a href=&#34;https://sefiks.com/2020/08/25/deep-face-detection-with-opencv-in-python/&#34;&gt;detect&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2020/02/23/face-alignment-for-face-recognition-in-python-within-opencv/&#34;&gt;align&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2020/11/20/facial-landmarks-for-face-recognition-with-dlib/&#34;&gt;normalize&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/&#34;&gt;represent&lt;/a&gt; and &lt;a href=&#34;https://sefiks.com/2020/05/22/fine-tuning-the-threshold-in-face-recognition/&#34;&gt;verify&lt;/a&gt;. While DeepFace handles all these common stages in the background, you don‚Äôt need to acquire in-depth knowledge about all the processes behind it. You can just call its verification, find or analysis function with a single line of code.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Face Verification&lt;/strong&gt; - &lt;a href=&#34;https://youtu.be/KRCvkNCOphE&#34;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This function verifies face pairs as same person or different persons. It expects exact image paths as inputs. Passing numpy or base64 encoded images is also welcome. Then, it is going to return a dictionary and you should check just its verified key.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;result = DeepFace.verify(&#xA;  img1_path = &#34;img1.jpg&#34;,&#xA;  img2_path = &#34;img2.jpg&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-1.jpg&#34; width=&#34;95%&#34; height=&#34;95%&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Face recognition&lt;/strong&gt; - &lt;a href=&#34;https://youtu.be/Hrjp-EStM_s&#34;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://sefiks.com/2020/05/25/large-scale-face-recognition-for-deep-learning/&#34;&gt;Face recognition&lt;/a&gt; requires applying face verification many times. Herein, deepface has an out-of-the-box find function to handle this action. It&#39;s going to look for the identity of input image in the database path and it will return list of pandas data frame as output. Meanwhile, facial embeddings of the facial database are stored in a pickle file to be searched faster in next time. Result is going to be the size of faces appearing in the source image. Besides, target images in the database can have many faces as well.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dfs = DeepFace.find(&#xA;  img_path = &#34;img1.jpg&#34;,&#xA;  db_path = &#34;C:/workspace/my_db&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-6-v2.jpg&#34; width=&#34;95%&#34; height=&#34;95%&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Embeddings&lt;/strong&gt; - &lt;a href=&#34;https://youtu.be/OYialFo7Qo4&#34;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Face recognition models basically represent facial images as multi-dimensional vectors. Sometimes, you need those embedding vectors directly. DeepFace comes with a dedicated representation function. Represent function returns a list of embeddings. Result is going to be the size of faces appearing in the image path.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;embedding_objs = DeepFace.represent(&#xA;  img_path = &#34;img.jpg&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This function returns an array as embedding. The size of the embedding array would be different based on the model name. For instance, VGG-Face is the default model and it represents facial images as 4096 dimensional vectors.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for embedding_obj in embedding_objs:&#xA;  embedding = embedding_obj[&#34;embedding&#34;]&#xA;  assert isinstance(embedding, list)&#xA;  assert (&#xA;    model_name == &#34;VGG-Face&#34;&#xA;    and len(embedding) == 4096&#xA;  )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here, embedding is also &lt;a href=&#34;https://sefiks.com/2020/05/01/a-gentle-introduction-to-face-recognition-in-deep-learning/&#34;&gt;plotted&lt;/a&gt; with 4096 slots horizontally. Each slot is corresponding to a dimension value in the embedding vector and dimension value is explained in the colorbar on the right. Similar to 2D barcodes, vertical dimension stores no information in the illustration.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/embedding.jpg&#34; width=&#34;95%&#34; height=&#34;95%&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Face recognition models&lt;/strong&gt; - &lt;a href=&#34;https://youtu.be/eKOZawGR3y0&#34;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;DeepFace is a &lt;strong&gt;hybrid&lt;/strong&gt; face recognition package. It currently wraps many &lt;strong&gt;state-of-the-art&lt;/strong&gt; face recognition models: &lt;a href=&#34;https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/&#34;&gt;&lt;code&gt;VGG-Face&lt;/code&gt;&lt;/a&gt; , &lt;a href=&#34;https://sefiks.com/2018/09/03/face-recognition-with-facenet-in-keras/&#34;&gt;&lt;code&gt;FaceNet&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2019/07/21/face-recognition-with-openface-in-keras/&#34;&gt;&lt;code&gt;OpenFace&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2020/02/17/face-recognition-with-facebook-deepface-in-keras/&#34;&gt;&lt;code&gt;DeepFace&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2020/06/16/face-recognition-with-deepid-in-keras/&#34;&gt;&lt;code&gt;DeepID&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2020/12/14/deep-face-recognition-with-arcface-in-keras-and-python/&#34;&gt;&lt;code&gt;ArcFace&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2020/07/11/face-recognition-with-dlib-in-python/&#34;&gt;&lt;code&gt;Dlib&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;SFace&lt;/code&gt; and &lt;code&gt;GhostFaceNet&lt;/code&gt;. The default configuration uses VGG-Face model.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;models = [&#xA;  &#34;VGG-Face&#34;, &#xA;  &#34;Facenet&#34;, &#xA;  &#34;Facenet512&#34;, &#xA;  &#34;OpenFace&#34;, &#xA;  &#34;DeepFace&#34;, &#xA;  &#34;DeepID&#34;, &#xA;  &#34;ArcFace&#34;, &#xA;  &#34;Dlib&#34;, &#xA;  &#34;SFace&#34;,&#xA;  &#34;GhostFaceNet&#34;,&#xA;]&#xA;&#xA;#face verification&#xA;result = DeepFace.verify(&#xA;  img1_path = &#34;img1.jpg&#34;,&#xA;  img2_path = &#34;img2.jpg&#34;,&#xA;  model_name = models[0],&#xA;)&#xA;&#xA;#face recognition&#xA;dfs = DeepFace.find(&#xA;  img_path = &#34;img1.jpg&#34;,&#xA;  db_path = &#34;C:/workspace/my_db&#34;, &#xA;  model_name = models[1],&#xA;)&#xA;&#xA;#embeddings&#xA;embedding_objs = DeepFace.represent(&#xA;  img_path = &#34;img.jpg&#34;,&#xA;  model_name = models[2],&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/model-portfolio-20240316.jpg&#34; width=&#34;95%&#34; height=&#34;95%&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;FaceNet, VGG-Face, ArcFace and Dlib are overperforming ones based on experiments - see &lt;a href=&#34;https://github.com/serengil/deepface/tree/master/benchmarks&#34;&gt;&lt;code&gt;BENCHMARKS&lt;/code&gt;&lt;/a&gt; for more details. You can find the measured scores of various models in DeepFace and the reported scores from their original studies in the following table.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Measured Score&lt;/th&gt; &#xA;   &lt;th&gt;Declared Score&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Facenet512&lt;/td&gt; &#xA;   &lt;td&gt;98.4%&lt;/td&gt; &#xA;   &lt;td&gt;99.6%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Human-beings&lt;/td&gt; &#xA;   &lt;td&gt;97.5%&lt;/td&gt; &#xA;   &lt;td&gt;97.5%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Facenet&lt;/td&gt; &#xA;   &lt;td&gt;97.4%&lt;/td&gt; &#xA;   &lt;td&gt;99.2%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Dlib&lt;/td&gt; &#xA;   &lt;td&gt;96.8%&lt;/td&gt; &#xA;   &lt;td&gt;99.3 %&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;VGG-Face&lt;/td&gt; &#xA;   &lt;td&gt;96.7%&lt;/td&gt; &#xA;   &lt;td&gt;98.9%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ArcFace&lt;/td&gt; &#xA;   &lt;td&gt;96.7%&lt;/td&gt; &#xA;   &lt;td&gt;99.5%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GhostFaceNet&lt;/td&gt; &#xA;   &lt;td&gt;93.3%&lt;/td&gt; &#xA;   &lt;td&gt;99.7%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SFace&lt;/td&gt; &#xA;   &lt;td&gt;93.0%&lt;/td&gt; &#xA;   &lt;td&gt;99.5%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OpenFace&lt;/td&gt; &#xA;   &lt;td&gt;78.7%&lt;/td&gt; &#xA;   &lt;td&gt;92.9%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DeepFace&lt;/td&gt; &#xA;   &lt;td&gt;69.0%&lt;/td&gt; &#xA;   &lt;td&gt;97.3%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DeepID&lt;/td&gt; &#xA;   &lt;td&gt;66.5%&lt;/td&gt; &#xA;   &lt;td&gt;97.4%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Conducting experiments with those models within DeepFace may reveal disparities compared to the original studies, owing to the adoption of distinct detection or normalization techniques. Furthermore, some models have been released solely with their backbones, lacking pre-trained weights. Thus, we are utilizing their re-implementations instead of the original pre-trained weights.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Similarity&lt;/strong&gt; - &lt;a href=&#34;https://youtu.be/1EPoS69fHOc&#34;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Face recognition models are regular &lt;a href=&#34;https://sefiks.com/2018/03/23/convolutional-autoencoder-clustering-images-with-neural-networks/&#34;&gt;convolutional neural networks&lt;/a&gt; and they are responsible to represent faces as vectors. We expect that a face pair of same person should be &lt;a href=&#34;https://sefiks.com/2020/05/22/fine-tuning-the-threshold-in-face-recognition/&#34;&gt;more similar&lt;/a&gt; than a face pair of different persons.&lt;/p&gt; &#xA;&lt;p&gt;Similarity could be calculated by different metrics such as &lt;a href=&#34;https://sefiks.com/2018/08/13/cosine-similarity-in-machine-learning/&#34;&gt;Cosine Similarity&lt;/a&gt;, Euclidean Distance or L2 normalized Euclidean. The default configuration uses cosine similarity. According to &lt;a href=&#34;https://github.com/serengil/deepface/tree/master/benchmarks&#34;&gt;experiments&lt;/a&gt;, no distance metric is overperforming than other.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;metrics = [&#34;cosine&#34;, &#34;euclidean&#34;, &#34;euclidean_l2&#34;]&#xA;&#xA;#face verification&#xA;result = DeepFace.verify(&#xA;  img1_path = &#34;img1.jpg&#34;, &#xA;  img2_path = &#34;img2.jpg&#34;, &#xA;  distance_metric = metrics[1],&#xA;)&#xA;&#xA;#face recognition&#xA;dfs = DeepFace.find(&#xA;  img_path = &#34;img1.jpg&#34;, &#xA;  db_path = &#34;C:/workspace/my_db&#34;, &#xA;  distance_metric = metrics[2],&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Facial Attribute Analysis&lt;/strong&gt; - &lt;a href=&#34;https://youtu.be/GT2UeN85BdA&#34;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;DeepFace also comes with a strong facial attribute analysis module including &lt;a href=&#34;https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/&#34;&gt;&lt;code&gt;age&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/&#34;&gt;&lt;code&gt;gender&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/&#34;&gt;&lt;code&gt;facial expression&lt;/code&gt;&lt;/a&gt; (including angry, fear, neutral, sad, disgust, happy and surprise) and &lt;a href=&#34;https://sefiks.com/2019/11/11/race-and-ethnicity-prediction-in-keras/&#34;&gt;&lt;code&gt;race&lt;/code&gt;&lt;/a&gt; (including asian, white, middle eastern, indian, latino and black) predictions. Result is going to be the size of faces appearing in the source image.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;objs = DeepFace.analyze(&#xA;  img_path = &#34;img4.jpg&#34;, &#xA;  actions = [&#39;age&#39;, &#39;gender&#39;, &#39;race&#39;, &#39;emotion&#39;],&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-2.jpg&#34; width=&#34;95%&#34; height=&#34;95%&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Age model got ¬± 4.65 MAE; gender model got 97.44% accuracy, 96.29% precision and 95.05% recall as mentioned in its &lt;a href=&#34;https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/&#34;&gt;tutorial&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Face Detection and Alignment&lt;/strong&gt; - &lt;a href=&#34;https://youtu.be/GZ2p2hj2H5k&#34;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Face detection and alignment are important early stages of a modern face recognition pipeline. &lt;a href=&#34;https://github.com/serengil/deepface/tree/master/benchmarks&#34;&gt;Experiments&lt;/a&gt; show that detection increases the face recognition accuracy up to 42%, while alignment increases it up to 6%. &lt;a href=&#34;https://sefiks.com/2020/02/23/face-alignment-for-face-recognition-in-python-within-opencv/&#34;&gt;&lt;code&gt;OpenCV&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2020/08/25/deep-face-detection-with-opencv-in-python/&#34;&gt;&lt;code&gt;Ssd&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2020/07/11/face-recognition-with-dlib-in-python/&#34;&gt;&lt;code&gt;Dlib&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2020/09/09/deep-face-detection-with-mtcnn-in-python/&#34;&gt;&lt;code&gt;MtCnn&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;Faster MtCnn&lt;/code&gt;, &lt;a href=&#34;https://sefiks.com/2021/04/27/deep-face-detection-with-retinaface-in-python/&#34;&gt;&lt;code&gt;RetinaFace&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sefiks.com/2022/01/14/deep-face-detection-with-mediapipe/&#34;&gt;&lt;code&gt;MediaPipe&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;Yolo&lt;/code&gt;, &lt;code&gt;YuNet&lt;/code&gt; and &lt;code&gt;CenterFace&lt;/code&gt; detectors are wrapped in deepface.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/detector-portfolio-v6.jpg&#34; width=&#34;95%&#34; height=&#34;95%&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;All deepface functions accept optional detector backend and align input arguments. You can switch among those detectors and alignment modes with these arguments. OpenCV is the default detector and alignment is on by default.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;backends = [&#xA;  &#39;opencv&#39;, &#xA;  &#39;ssd&#39;, &#xA;  &#39;dlib&#39;, &#xA;  &#39;mtcnn&#39;, &#xA;  &#39;fastmtcnn&#39;,&#xA;  &#39;retinaface&#39;, &#xA;  &#39;mediapipe&#39;,&#xA;  &#39;yolov8&#39;,&#xA;  &#39;yunet&#39;,&#xA;  &#39;centerface&#39;,&#xA;]&#xA;&#xA;alignment_modes = [True, False]&#xA;&#xA;#face verification&#xA;obj = DeepFace.verify(&#xA;  img1_path = &#34;img1.jpg&#34;, &#xA;  img2_path = &#34;img2.jpg&#34;, &#xA;  detector_backend = backends[0],&#xA;  align = alignment_modes[0],&#xA;)&#xA;&#xA;#face recognition&#xA;dfs = DeepFace.find(&#xA;  img_path = &#34;img.jpg&#34;, &#xA;  db_path = &#34;my_db&#34;, &#xA;  detector_backend = backends[1],&#xA;  align = alignment_modes[0],&#xA;)&#xA;&#xA;#embeddings&#xA;embedding_objs = DeepFace.represent(&#xA;  img_path = &#34;img.jpg&#34;, &#xA;  detector_backend = backends[2],&#xA;  align = alignment_modes[0],&#xA;)&#xA;&#xA;#facial analysis&#xA;demographies = DeepFace.analyze(&#xA;  img_path = &#34;img4.jpg&#34;, &#xA;  detector_backend = backends[3],&#xA;  align = alignment_modes[0],&#xA;)&#xA;&#xA;#face detection and alignment&#xA;face_objs = DeepFace.extract_faces(&#xA;  img_path = &#34;img.jpg&#34;, &#xA;  detector_backend = backends[4],&#xA;  align = alignment_modes[0],&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Face recognition models are actually CNN models and they expect standard sized inputs. So, resizing is required before representation. To avoid deformation, deepface adds black padding pixels according to the target size argument after detection and alignment.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/detector-outputs-20240414.jpg&#34; width=&#34;90%&#34; height=&#34;90%&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://sefiks.com/2021/04/27/deep-face-detection-with-retinaface-in-python/&#34;&gt;RetinaFace&lt;/a&gt; and &lt;a href=&#34;https://sefiks.com/2020/09/09/deep-face-detection-with-mtcnn-in-python/&#34;&gt;MtCnn&lt;/a&gt; seem to overperform in detection and alignment stages but they are much slower. If the speed of your pipeline is more important, then you should use opencv or ssd. On the other hand, if you consider the accuracy, then you should use retinaface or mtcnn.&lt;/p&gt; &#xA;&lt;p&gt;The performance of RetinaFace is very satisfactory even in the crowd as seen in the following illustration. Besides, it comes with an incredible facial landmark detection performance. Highlighted red points show some facial landmarks such as eyes, nose and mouth. That&#39;s why, alignment score of RetinaFace is high as well.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/retinaface-results.jpeg&#34; width=&#34;90%&#34; height=&#34;90%&#34;&gt; &lt;br&gt;&lt;em&gt;The Yellow Angels - Fenerbahce Women&#39;s Volleyball Team&lt;/em&gt; &lt;/p&gt; &#xA;&lt;p&gt;You can find out more about RetinaFace on this &lt;a href=&#34;https://github.com/serengil/retinaface&#34;&gt;repo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Real Time Analysis&lt;/strong&gt; - &lt;a href=&#34;https://youtu.be/-c9sSJcx6wI&#34;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can run deepface for real time videos as well. Stream function will access your webcam and apply both face recognition and facial attribute analysis. The function starts to analyze a frame if it can focus a face sequentially 5 frames. Then, it shows results 5 seconds.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;DeepFace.stream(db_path = &#34;C:/User/Sefik/Desktop/database&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-3.jpg&#34; width=&#34;90%&#34; height=&#34;90%&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Even though face recognition is based on one-shot learning, you can use multiple face pictures of a person as well. You should rearrange your directory structure as illustrated below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;user&#xA;‚îú‚îÄ‚îÄ database&#xA;‚îÇ   ‚îú‚îÄ‚îÄ Alice&#xA;‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Alice1.jpg&#xA;‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Alice2.jpg&#xA;‚îÇ   ‚îú‚îÄ‚îÄ Bob&#xA;‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Bob.jpg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;React UI&lt;/strong&gt; - &lt;a href=&#34;https://youtu.be/IXoah6rhxac&#34;&gt;&lt;code&gt;Demo part-i&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/_waBA-cH2D4&#34;&gt;&lt;code&gt;Demo part-ii&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you intend to perform face verification tasks directly from your browser, &lt;a href=&#34;https://github.com/serengil/deepface-react-ui&#34;&gt;deepface-react-ui&lt;/a&gt; is a separate repository built using ReactJS depending on deepface api.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-and-react.jpg&#34; width=&#34;90%&#34; height=&#34;90%&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Face Anti Spoofing&lt;/strong&gt; - &lt;a href=&#34;https://youtu.be/UiK1aIjOBlQ&#34;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;DeepFace also includes an anti-spoofing analysis module to understand given image is real or fake. To activate this feature, set the &lt;code&gt;anti_spoofing&lt;/code&gt; argument to True in any DeepFace tasks.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/face-anti-spoofing.jpg&#34; width=&#34;40%&#34; height=&#34;40%&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# anti spoofing test in face detection&#xA;face_objs = DeepFace.extract_faces(&#xA;  img_path=&#34;dataset/img1.jpg&#34;,&#xA;  anti_spoofing = True&#xA;)&#xA;assert all(face_obj[&#34;is_real&#34;] is True for face_obj in face_objs)&#xA;&#xA;# anti spoofing test in real time analysis&#xA;DeepFace.stream(&#xA;  db_path = &#34;C:/User/Sefik/Desktop/database&#34;,&#xA;  anti_spoofing = True&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;API&lt;/strong&gt; - &lt;a href=&#34;https://youtu.be/HeKCQ6U9XmI&#34;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;DeepFace serves an API as well - see &lt;a href=&#34;https://github.com/serengil/deepface/tree/master/deepface/api/src&#34;&gt;&lt;code&gt;api folder&lt;/code&gt;&lt;/a&gt; for more details. You can clone deepface source code and run the api with the following command. It will use gunicorn server to get a rest service up. In this way, you can call deepface from an external system such as mobile app or web.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd scripts&#xA;./service.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-api.jpg&#34; width=&#34;90%&#34; height=&#34;90%&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Face recognition, facial attribute analysis and vector representation functions are covered in the API. You are expected to call these functions as http post methods. Default service endpoints will be &lt;code&gt;http://localhost:5005/verify&lt;/code&gt; for face recognition, &lt;code&gt;http://localhost:5005/analyze&lt;/code&gt; for facial attribute analysis, and &lt;code&gt;http://localhost:5005/represent&lt;/code&gt; for vector representation. You can pass input images as exact image paths on your environment, base64 encoded strings or images on web. &lt;a href=&#34;https://github.com/serengil/deepface/tree/master/deepface/api/postman&#34;&gt;Here&lt;/a&gt;, you can find a postman project to find out how these methods should be called.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dockerized Service&lt;/strong&gt; - &lt;a href=&#34;https://youtu.be/9Tk9lRQareA&#34;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/serengil/deepface&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/serengil/deepface?logo=docker&#34; alt=&#34;Docker Pulls&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The following command set will serve deepface on &lt;code&gt;localhost:5005&lt;/code&gt; via docker. Then, you will be able to consume deepface services such as verify, analyze and represent. Also, if you want to build the image by your own instead of pre-built image from docker hub, &lt;a href=&#34;https://github.com/serengil/deepface/raw/master/Dockerfile&#34;&gt;Dockerfile&lt;/a&gt; is available in the root folder of the project.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# docker build -t serengil/deepface . # build docker image from Dockerfile&#xA;docker pull serengil/deepface # use pre-built docker image from docker hub&#xA;docker run -p 5005:5000 serengil/deepface&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-dockerized-v2.jpg&#34; width=&#34;50%&#34; height=&#34;50%&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Command Line Interface&lt;/strong&gt; - &lt;a href=&#34;https://youtu.be/PKKTAr3ts2s&#34;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;DeepFace comes with a command line interface as well. You are able to access its functions in command line as shown below. The command deepface expects the function name as 1st argument and function arguments thereafter.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#face verification&#xA;$ deepface verify -img1_path tests/dataset/img1.jpg -img2_path tests/dataset/img2.jpg&#xA;&#xA;#facial analysis&#xA;$ deepface analyze -img_path tests/dataset/img1.jpg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also run these commands if you are running deepface with docker. Please follow the instructions in the &lt;a href=&#34;https://github.com/serengil/deepface/raw/master/scripts/dockerize.sh#L17&#34;&gt;shell script&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Large Scale Facial Recognition&lt;/strong&gt; - &lt;a href=&#34;https://www.youtube.com/playlist?list=PLsS_1RYmYQQGSJu_Z3OVhXhGmZ86_zuIm&#34;&gt;&lt;code&gt;Playlist&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If your task requires facial recognition on large datasets, you should combine DeepFace with a vector index or vector database. This setup will perform &lt;a href=&#34;https://youtu.be/c10w0Ptn_CU&#34;&gt;approximate nearest neighbor&lt;/a&gt; searches instead of exact ones, allowing you to identify a face in a database containing billions of entries within milliseconds. Common vector index solutions include &lt;a href=&#34;https://youtu.be/Jpxm914o2xk&#34;&gt;Annoy&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/6AmEvDTKT-k&#34;&gt;Faiss&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/2ZYTV9HlFdU&#34;&gt;Voyager&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/EVBhO8rbKbg&#34;&gt;NMSLIB&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/i4GvuOmzKzo&#34;&gt;ElasticSearch&lt;/a&gt;. For vector databases, popular options are &lt;a href=&#34;https://youtu.be/Xfv4hCWvkp0&#34;&gt;Postgres with its pgvector extension&lt;/a&gt; and &lt;a href=&#34;https://youtu.be/yrXlS0d6t4w&#34;&gt;RediSearch&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-big-data.jpg&#34; width=&#34;90%&#34; height=&#34;90%&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Conversely, if your task involves facial recognition on small to moderate-sized databases, you can adopt use relational databases such as &lt;a href=&#34;https://youtu.be/f41sLxn1c0k&#34;&gt;Postgres&lt;/a&gt; or &lt;a href=&#34;https://youtu.be/_1ShBeWToPg&#34;&gt;SQLite&lt;/a&gt;, or NoSQL databases like &lt;a href=&#34;https://youtu.be/dmprgum9Xu8&#34;&gt;Mongo&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/X7DSpUMVTsw&#34;&gt;Redis&lt;/a&gt; or &lt;a href=&#34;https://youtu.be/J_yXpc3Y8Ec&#34;&gt;Cassandra&lt;/a&gt; to perform exact nearest neighbor search.&lt;/p&gt; &#xA;&lt;h2&gt;Contribution&lt;/h2&gt; &#xA;&lt;p&gt;Pull requests are more than welcome! If you are planning to contribute a large patch, please create an issue first to get any upfront questions or design decisions out of the way first.&lt;/p&gt; &#xA;&lt;p&gt;Before creating a PR, you should run the unit tests and linting locally by running &lt;code&gt;make test &amp;amp;&amp;amp; make lint&lt;/code&gt; command. Once a PR sent, GitHub test workflow will be run automatically and unit test and linting jobs will be available in &lt;a href=&#34;https://github.com/serengil/deepface/actions&#34;&gt;GitHub actions&lt;/a&gt; before approval.&lt;/p&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;There are many ways to support a project - starring‚≠êÔ∏è the GitHub repo is just one üôè&lt;/p&gt; &#xA;&lt;p&gt;If you do like this work, then you can support it financially on &lt;a href=&#34;https://www.patreon.com/serengil?repo=deepface&#34;&gt;Patreon&lt;/a&gt;, &lt;a href=&#34;https://github.com/sponsors/serengil&#34;&gt;GitHub Sponsors&lt;/a&gt; or &lt;a href=&#34;https://buymeacoffee.com/serengil&#34;&gt;Buy Me a Coffee&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;a href=&#34;https://www.patreon.com/serengil?repo=deepface&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/patreon.png&#34; width=&#34;30%&#34; height=&#34;30%&#34;&gt; &lt;/a&gt; &#xA;&lt;a href=&#34;https://buymeacoffee.com/serengil&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/serengil/deepface/master/icon/bmc-button.png&#34; width=&#34;25%&#34; height=&#34;25%&#34;&gt; &lt;/a&gt; &#xA;&lt;p&gt;Also, your company&#39;s logo will be shown on README on GitHub if you become a sponsor in gold, silver or bronze tiers.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;Please cite deepface in your publications if it helps your research - see &lt;a href=&#34;https://github.com/serengil/deepface/raw/master/CITATION.md&#34;&gt;&lt;code&gt;CITATIONS&lt;/code&gt;&lt;/a&gt; for more details. Here are its BibTex entries:&lt;/p&gt; &#xA;&lt;p&gt;If you use deepface in your research for facial recogntion or face detection purposes, please cite these publications:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-BibTeX&#34;&gt;@article{serengil2024lightface,&#xA;  title     = {A Benchmark of Facial Recognition Pipelines and Co-Usability Performances of Modules},&#xA;  author    = {Serengil, Sefik and Ozpinar, Alper},&#xA;  journal   = {Journal of Information Technologies},&#xA;  volume    = {17},&#xA;  number    = {2},&#xA;  pages     = {95-107},&#xA;  year      = {2024},&#xA;  doi       = {10.17671/gazibtd.1399077},&#xA;  url       = {https://dergipark.org.tr/en/pub/gazibtd/issue/84331/1399077},&#xA;  publisher = {Gazi University}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-BibTeX&#34;&gt;@inproceedings{serengil2020lightface,&#xA;  title        = {LightFace: A Hybrid Deep Face Recognition Framework},&#xA;  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},&#xA;  booktitle    = {2020 Innovations in Intelligent Systems and Applications Conference (ASYU)},&#xA;  pages        = {23-27},&#xA;  year         = {2020},&#xA;  doi          = {10.1109/ASYU50717.2020.9259802},&#xA;  url          = {https://ieeexplore.ieee.org/document/9259802},&#xA;  organization = {IEEE}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On the other hand, if you use deepface in your research for facial attribute analysis purposes such as age, gender, emotion or ethnicity prediction tasks, please cite this publication.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-BibTeX&#34;&gt;@inproceedings{serengil2021lightface,&#xA;  title        = {HyperExtended LightFace: A Facial Attribute Analysis Framework},&#xA;  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},&#xA;  booktitle    = {2021 International Conference on Engineering and Emerging Technologies (ICEET)},&#xA;  pages        = {1-4},&#xA;  year         = {2021},&#xA;  doi          = {10.1109/ICEET53442.2021.9659697},&#xA;  url          = {https://ieeexplore.ieee.org/document/9659697},&#xA;  organization = {IEEE}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Also, if you use deepface in your GitHub projects, please add &lt;code&gt;deepface&lt;/code&gt; in the &lt;code&gt;requirements.txt&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Licence&lt;/h2&gt; &#xA;&lt;p&gt;DeepFace is licensed under the MIT License - see &lt;a href=&#34;https://github.com/serengil/deepface/raw/master/LICENSE&#34;&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;p&gt;DeepFace wraps some external face recognition models: &lt;a href=&#34;http://www.robots.ox.ac.uk/~vgg/software/vgg_face/&#34;&gt;VGG-Face&lt;/a&gt;, &lt;a href=&#34;https://github.com/davidsandberg/facenet/raw/master/LICENSE.md&#34;&gt;Facenet&lt;/a&gt; (both 128d and 512d), &lt;a href=&#34;https://github.com/iwantooxxoox/Keras-OpenFace/raw/master/LICENSE&#34;&gt;OpenFace&lt;/a&gt;, &lt;a href=&#34;https://github.com/swghosh/DeepFace&#34;&gt;DeepFace&lt;/a&gt;, &lt;a href=&#34;https://github.com/Ruoyiran/DeepID/raw/master/LICENSE.md&#34;&gt;DeepID&lt;/a&gt;, &lt;a href=&#34;https://github.com/leondgarse/Keras_insightface/raw/master/LICENSE&#34;&gt;ArcFace&lt;/a&gt;, &lt;a href=&#34;https://github.com/davisking/dlib/raw/master/dlib/LICENSE.txt&#34;&gt;Dlib&lt;/a&gt;, &lt;a href=&#34;https://github.com/opencv/opencv_zoo/raw/master/models/face_recognition_sface/LICENSE&#34;&gt;SFace&lt;/a&gt; and &lt;a href=&#34;https://github.com/HamadYA/GhostFaceNets/raw/main/LICENSE&#34;&gt;GhostFaceNet&lt;/a&gt;. Besides, age, gender and race / ethnicity models were trained on the backbone of VGG-Face with transfer learning. Similarly, DeepFace wraps many face detectors: &lt;a href=&#34;https://github.com/opencv/opencv/raw/4.x/LICENSE&#34;&gt;OpenCv&lt;/a&gt;, &lt;a href=&#34;https://github.com/opencv/opencv/raw/master/LICENSE&#34;&gt;Ssd&lt;/a&gt;, &lt;a href=&#34;https://github.com/davisking/dlib/raw/master/LICENSE.txt&#34;&gt;Dlib&lt;/a&gt;, &lt;a href=&#34;https://github.com/ipazc/mtcnn/raw/master/LICENSE&#34;&gt;MtCnn&lt;/a&gt;, &lt;a href=&#34;https://github.com/timesler/facenet-pytorch/raw/master/LICENSE.md&#34;&gt;Fast MtCnn&lt;/a&gt;, &lt;a href=&#34;https://github.com/serengil/retinaface/raw/master/LICENSE&#34;&gt;RetinaFace&lt;/a&gt;, &lt;a href=&#34;https://github.com/google/mediapipe/raw/master/LICENSE&#34;&gt;MediaPipe&lt;/a&gt;, &lt;a href=&#34;https://github.com/ShiqiYu/libfacedetection/raw/master/LICENSE&#34;&gt;YuNet&lt;/a&gt;, &lt;a href=&#34;https://github.com/derronqi/yolov8-face/raw/main/LICENSE&#34;&gt;Yolo&lt;/a&gt; and &lt;a href=&#34;https://github.com/Star-Clouds/CenterFace/raw/master/LICENSE&#34;&gt;CenterFace&lt;/a&gt;. Finally, DeepFace is optionally using &lt;a href=&#34;https://github.com/minivision-ai/Silent-Face-Anti-Spoofing/raw/master/LICENSE&#34;&gt;face anti spoofing&lt;/a&gt; to determine the given images are real or fake. License types will be inherited when you intend to utilize those models. Please check the license types of those models for production purposes.&lt;/p&gt; &#xA;&lt;p&gt;DeepFace &lt;a href=&#34;https://thenounproject.com/term/face-recognition/2965879/&#34;&gt;logo&lt;/a&gt; is created by &lt;a href=&#34;https://thenounproject.com/coquet_adrien/&#34;&gt;Adrien Coquet&lt;/a&gt; and it is licensed under &lt;a href=&#34;https://creativecommons.org/licenses/by/3.0/&#34;&gt;Creative Commons: By Attribution 3.0 License&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>rany2/edge-tts</title>
    <updated>2024-10-21T01:28:31Z</updated>
    <id>tag:github.com,2024-10-21:/rany2/edge-tts</id>
    <link href="https://github.com/rany2/edge-tts" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Use Microsoft Edge&#39;s online text-to-speech service from Python WITHOUT needing Microsoft Edge or Windows or an API key&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;edge-tts&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;edge-tts&lt;/code&gt; is a Python module that allows you to use Microsoft Edge&#39;s online text-to-speech service from within your Python code or using the provided &lt;code&gt;edge-tts&lt;/code&gt; or &lt;code&gt;edge-playback&lt;/code&gt; command.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;To install it, run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pip install edge-tts&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you only want to use the &lt;code&gt;edge-tts&lt;/code&gt; and &lt;code&gt;edge-playback&lt;/code&gt; commands, it would be better to use pipx:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pipx install edge-tts&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Basic usage&lt;/h3&gt; &#xA;&lt;p&gt;If you want to use the &lt;code&gt;edge-tts&lt;/code&gt; command, you can simply run it with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ edge-tts --text &#34;Hello, world!&#34; --write-media hello.mp3 --write-subtitles hello.vtt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you wish to play it back immediately with subtitles, you could use the &lt;code&gt;edge-playback&lt;/code&gt; command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ edge-playback --text &#34;Hello, world!&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note the above requires the installation of the &lt;code&gt;mpv&lt;/code&gt; command line player.&lt;/p&gt; &#xA;&lt;p&gt;All &lt;code&gt;edge-tts&lt;/code&gt; commands work in &lt;code&gt;edge-playback&lt;/code&gt; as well.&lt;/p&gt; &#xA;&lt;h3&gt;Changing the voice&lt;/h3&gt; &#xA;&lt;p&gt;If you want to change the language of the speech or more generally, the voice.&lt;/p&gt; &#xA;&lt;p&gt;You must first check the available voices with the &lt;code&gt;--list-voices&lt;/code&gt; option:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ edge-tts --list-voices&#xA;Name: Microsoft Server Speech Text to Speech Voice (af-ZA, AdriNeural)&#xA;ShortName: af-ZA-AdriNeural&#xA;Gender: Female&#xA;Locale: af-ZA&#xA;&#xA;Name: Microsoft Server Speech Text to Speech Voice (am-ET, MekdesNeural)&#xA;ShortName: am-ET-MekdesNeural&#xA;Gender: Female&#xA;Locale: am-ET&#xA;&#xA;Name: Microsoft Server Speech Text to Speech Voice (ar-EG, SalmaNeural)&#xA;ShortName: ar-EG-SalmaNeural&#xA;Gender: Female&#xA;Locale: ar-EG&#xA;&#xA;Name: Microsoft Server Speech Text to Speech Voice (ar-SA, ZariyahNeural)&#xA;ShortName: ar-SA-ZariyahNeural&#xA;Gender: Female&#xA;Locale: ar-SA&#xA;&#xA;...&#xA;&#xA;$ edge-tts --voice ar-EG-SalmaNeural --text &#34;ŸÖÿ±ÿ≠ÿ®ÿß ŸÉŸäŸÅ ÿ≠ÿßŸÑŸÉÿü&#34; --write-media hello_in_arabic.mp3 --write-subtitles hello_in_arabic.vtt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Custom SSML&lt;/h3&gt; &#xA;&lt;p&gt;Support for custom SSML has been removed since 5.0.0 because Microsoft has taken the initiative to prevent it from working. You cannot use custom SSML anymore.&lt;/p&gt; &#xA;&lt;h3&gt;Changing rate, volume and pitch&lt;/h3&gt; &#xA;&lt;p&gt;It is possible to make minor changes to the generated speech.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ edge-tts --rate=-50% --text &#34;Hello, world!&#34; --write-media hello_with_rate_halved.mp3 --write-subtitles hello_with_rate_halved.vtt&#xA;$ edge-tts --volume=-50% --text &#34;Hello, world!&#34; --write-media hello_with_volume_halved.mp3 --write-subtitles hello_with_volume_halved.vtt&#xA;$ edge-tts --pitch=-50Hz --text &#34;Hello, world!&#34; --write-media hello_with_pitch_halved.mp3 --write-subtitles hello_with_pitch_halved.vtt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In addition, it is required to use &lt;code&gt;--rate=-50%&lt;/code&gt; instead of &lt;code&gt;--rate -50%&lt;/code&gt; (note the lack of an equal sign) otherwise the &lt;code&gt;-50%&lt;/code&gt; would be interpreted as just another argument.&lt;/p&gt; &#xA;&lt;h3&gt;Note on the &lt;code&gt;edge-playback&lt;/code&gt; command&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;edge-playback&lt;/code&gt; is just a wrapper around &lt;code&gt;edge-tts&lt;/code&gt; that plays back the generated speech. It takes the same arguments as the &lt;code&gt;edge-tts&lt;/code&gt; option.&lt;/p&gt; &#xA;&lt;h2&gt;Python module&lt;/h2&gt; &#xA;&lt;p&gt;It is possible to use the &lt;code&gt;edge-tts&lt;/code&gt; module directly from Python. For a list of example applications:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rany2/edge-tts/tree/master/examples&#34;&gt;https://github.com/rany2/edge-tts/tree/master/examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rany2/edge-tts/raw/master/src/edge_tts/util.py&#34;&gt;https://github.com/rany2/edge-tts/blob/master/src/edge_tts/util.py&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hasscc/hass-edge-tts/raw/main/custom_components/edge_tts/tts.py&#34;&gt;https://github.com/hasscc/hass-edge-tts/blob/main/custom_components/edge_tts/tts.py&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>