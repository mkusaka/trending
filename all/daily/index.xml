<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-09-28T01:32:57Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>nv-tlabs/GET3D</title>
    <updated>2022-09-28T01:32:57Z</updated>
    <id>tag:github.com,2022-09-28:/nv-tlabs/GET3D</id>
    <link href="https://github.com/nv-tlabs/GET3D" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images (NeurIPS 2022)&lt;br&gt;&lt;sub&gt;Official PyTorch implementation &lt;/sub&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/nv-tlabs/GET3D/master/docs/assets/get3d_model.png&#34; alt=&#34;Teaser image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images&lt;/strong&gt;&lt;br&gt; &lt;a href=&#34;http://www.cs.toronto.edu/~jungao/&#34;&gt;Jun Gao&lt;/a&gt;, &lt;a href=&#34;http://www.cs.toronto.edu/~shenti11/&#34;&gt;Tianchang Shen&lt;/a&gt;, &lt;a href=&#34;http://www.cs.toronto.edu/~zianwang/&#34;&gt;Zian Wang&lt;/a&gt;, &lt;a href=&#34;http://www.cs.toronto.edu/~wenzheng/&#34;&gt;Wenzheng Chen&lt;/a&gt;, &lt;a href=&#34;https://kangxue.org/&#34;&gt;Kangxue Yin&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.ca/citations?user=8q2ISMIAAAAJ&amp;amp;hl=en&#34;&gt;Daiqing Li&lt;/a&gt;, &lt;a href=&#34;https://orlitany.github.io/&#34;&gt;Or Litany&lt;/a&gt;, &lt;a href=&#34;https://zgojcic.github.io/&#34;&gt;Zan Gojcic&lt;/a&gt;, &lt;a href=&#34;https://www.cs.toronto.edu/~fidler/&#34;&gt;Sanja Fidler&lt;/a&gt; &lt;br&gt; &lt;strong&gt;&lt;a href=&#34;https://nv-tlabs.github.io/GET3D/assets/paper.pdf&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://nv-tlabs.github.io/GET3D/&#34;&gt;Project Page&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Abstract: &lt;em&gt;As several industries are moving towards modeling massive 3D virtual worlds, the need for content creation tools that can scale in terms of the quantity, quality, and diversity of 3D content is becoming evident. In our work, we aim to train performant 3D generative models that synthesize textured meshes which can be directly consumed by 3D rendering engines, thus immediately usable in downstream applications. Prior works on 3D generative modeling either lack geometric details, are limited in the mesh topology they can produce, typically do not support textures, or utilize neural renderers in the synthesis process, which makes their use in common 3D software non-trivial. In this work, we introduce GET3D, a Generative model that directly generates Explicit Textured 3D meshes with complex topology, rich geometric details, and high fidelity textures. We bridge recent success in the differentiable surface modeling, differentiable rendering as well as 2D Generative Adversarial Networks to train our model from 2D image collections. GET3D is able to generate high-quality 3D textured meshes, ranging from cars, chairs, animals, motorbikes and human characters to buildings, achieving significant improvements over previous methods.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/nv-tlabs/GET3D/master/docs/assets/teaser_result.jpg&#34; alt=&#34;Teaser Results&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2022-09-22: Code will be uploaded next week!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright © 2022, NVIDIA Corporation &amp;amp; affiliates. All rights reserved.&lt;/p&gt; &#xA;&lt;p&gt;This work is made available under the &lt;a href=&#34;https://github.com/nv-tlabs/GET3D/raw/master/LICENSE.txt&#34;&gt;Nvidia Source Code License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-latex&#34;&gt;@inproceedings{gao2022get3d,&#xA;    title={GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images},&#xA;    author={Jun Gao and Tianchang Shen and Zian Wang and Wenzheng Chen and Kangxue Yin &#xA;        and Daiqing Li and Or Litany and Zan Gojcic and Sanja Fidler},&#xA;    booktitle={Advances In Neural Information Processing Systems},&#xA;    year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>evilsocket/spycast</title>
    <updated>2022-09-28T01:32:57Z</updated>
    <id>tag:github.com,2022-09-28:/evilsocket/spycast</id>
    <link href="https://github.com/evilsocket/spycast" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A crossplatform mDNS enumeration tool.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;SpyCast is a crossplatform mDNS enumeration tool that can work either in active mode by recursively querying services, or in passive mode by only listening to multicast packets.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/E6n3Xwl.png&#34; alt=&#34;spycast&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cargo build --release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;OS specific bundle packages (for example dmg and app bundles on OSX) can be built via:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cargo tauri build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;SpyCast can also be built without the default UI, in which case all output will be printed on the terminal:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cargo build --no-default-features --release&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Running&lt;/h2&gt; &#xA;&lt;p&gt;Run SpyCast in active mode (it will recursively query all available mDNS services):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./target/release/spycast&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Run in passive mode (it won&#39;t produce any mDNS traffic and only listen for multicast packets):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;./target/release/spycast --passive&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Other options&lt;/h2&gt; &#xA;&lt;p&gt;Run &lt;code&gt;spycast --help&lt;/code&gt; for the complete list of options.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is made with ♥ by &lt;a href=&#34;https://twitter.com/evilsocket&#34;&gt;@evilsocket&lt;/a&gt; and it is released under the GPL3 license.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>SagerNet/sing-box</title>
    <updated>2022-09-28T01:32:57Z</updated>
    <id>tag:github.com,2022-09-28:/SagerNet/sing-box</id>
    <link href="https://github.com/SagerNet/sing-box" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The universal proxy platform&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;sing-box&lt;/h1&gt; &#xA;&lt;p&gt;The universal proxy platform.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://sing-box.sagernet.org&#34;&gt;https://sing-box.sagernet.org&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;Copyright (C) 2022 by nekohasekai &amp;lt;contact-sagernet@sekai.icu&amp;gt;&#xA;&#xA;This program is free software: you can redistribute it and/or modify&#xA;it under the terms of the GNU General Public License as published by&#xA;the Free Software Foundation, either version 3 of the License, or&#xA;(at your option) any later version.&#xA;&#xA;This program is distributed in the hope that it will be useful,&#xA;but WITHOUT ANY WARRANTY; without even the implied warranty of&#xA;MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the&#xA;GNU General Public License for more details.&#xA;&#xA;You should have received a copy of the GNU General Public License&#xA;along with this program. If not, see &amp;lt;http://www.gnu.org/licenses/&amp;gt;.&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>