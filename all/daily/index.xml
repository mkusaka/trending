<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-30T01:29:51Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ChaoningZhang/MobileSAM</title>
    <updated>2023-06-30T01:29:51Z</updated>
    <id>tag:github.com,2023-06-30:/ChaoningZhang/MobileSAM</id>
    <link href="https://github.com/ChaoningZhang/MobileSAM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This is the offiicial code for Faster Segment Anything (MobileSAM) project that makes SAM lightweight&lt;/p&gt;&lt;hr&gt;&lt;p float=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ChaoningZhang/MobileSAM/master/assets/logo2.png?raw=true&#34; width=&#34;99.1%&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;Faster Segment Anything (MobileSAM)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;span&gt;ğŸ“Œ&lt;/span&gt; MobileSAM paper is available at &lt;a href=&#34;https://www.researchgate.net/publication/371851844_Faster_Segment_Anything_Towards_Lightweight_SAM_for_Mobile_Applications&#34;&gt;ResearchGate&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/pdf/2306.14289.pdf&#34;&gt;arXiv&lt;/a&gt;. The latest version will first appear on &lt;a href=&#34;https://arxiv.org/pdf/2306.14289.pdf&#34;&gt;ResearchGate&lt;/a&gt;, since it takes time for arXiv to update the content.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;ğŸ“Œ&lt;/span&gt; A &lt;strong&gt;demo of MobileSAM&lt;/strong&gt; running on &lt;strong&gt;CPU&lt;/strong&gt; is open at &lt;a href=&#34;https://huggingface.co/spaces/dhkim2810/MobileSAM&#34;&gt;demo link&lt;/a&gt; (A new version with other features will come soon, stay tuned!). On our own Mac i5 CPU, it takes around 3s. On the hugging face demo, the interface and inferior CPUs make it slower but still works fine.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;ğŸ‡&lt;/span&gt; Media coverage and Projects that adapt from SAM to MobileSAM (Updates)&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023/06/30&lt;/strong&gt;: MobileSAM has been featured by &lt;a href=&#34;https://twitter.com/_akhaliq?lang=en&#34;&gt;AK&lt;/a&gt; for the second time, see the link &lt;a href=&#34;https://twitter.com/_akhaliq/status/1674410573075718145&#34;&gt;AK&#39;s MobileSAM tweet&lt;/a&gt;. Welcome to retweet.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023/06/29&lt;/strong&gt;: &lt;a href=&#34;https://github.com/vietanhdev/anylabeling&#34;&gt;AnyLabeling&lt;/a&gt; supports MobileSAM for auto-labeling. Thanks for their effort.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023/06/29&lt;/strong&gt;: &lt;a href=&#34;https://github.com/wangsssky/SonarSAM&#34;&gt;SonarSAM&lt;/a&gt; supports MobileSAM for Image encoder full-finetuing. Thanks for their effort.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023/06/29&lt;/strong&gt;: &lt;a href=&#34;https://github.com/continue-revolution/sd-webui-segment-anything&#34;&gt;Stable Diffusion WebUIv&lt;/a&gt; supports MobileSAM. Thanks for their effort.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023/06/28&lt;/strong&gt;: &lt;a href=&#34;https://github.com/IDEA-Research/Grounded-Segment-Anything&#34;&gt;Grounding-SAM&lt;/a&gt; supports MobileSAM with &lt;a href=&#34;https://github.com/IDEA-Research/Grounded-Segment-Anything/tree/main/EfficientSAM&#34;&gt;Grounded-MobileSAM&lt;/a&gt;. Thanks for their effort.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2023/06/27&lt;/strong&gt;: MobileSAM has been featured by &lt;a href=&#34;https://twitter.com/_akhaliq?lang=en&#34;&gt;AK&lt;/a&gt;, see the link &lt;a href=&#34;https://twitter.com/_akhaliq/status/1673585099097636864&#34;&gt;AK&#39;s MobileSAM tweet&lt;/a&gt;. Welcome to retweet. &lt;img src=&#34;https://raw.githubusercontent.com/ChaoningZhang/MobileSAM/master/assets/model_diagram.jpg?raw=true&#34; alt=&#34;MobileSAM&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;span&gt;â­&lt;/span&gt; &lt;strong&gt;How is MobileSAM trained?&lt;/strong&gt; MobileSAM is trained on a single GPU with 100k datasets (1% of the original images) for less than a day. The training code will be available soon.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;â­&lt;/span&gt; &lt;strong&gt;How to Adapt from SAM to MobileSAM?&lt;/strong&gt; Since MobileSAM keeps exactly the same pipeline as the original SAM, we inherit pre-processing, post-processing, and all other interfaces from the original SAM. Therefore, by assuming everything is exactly the same except for a smaller image encoder, those who use the original SAM for their projects can &lt;strong&gt;adapt to MobileSAM with almost zero effort&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;â­&lt;/span&gt; &lt;strong&gt;MobileSAM performs on par with the original SAM (at least visually)&lt;/strong&gt; and keeps exactly the same pipeline as the original SAM except for a change on the image encoder. Specifically, we replace the original heavyweight ViT-H encoder (632M) with a much smaller Tiny-ViT (5M). On a single GPU, MobileSAM runs around 12ms per image: 8ms on the image encoder and 4ms on the mask decoder.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;The comparison of ViT-based image encoder is summarzed as follows:&lt;/p&gt; &#xA;  &lt;table&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;Image Encoder&lt;/th&gt; &#xA;     &lt;th align=&#34;left&#34;&gt;Original SAM&lt;/th&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;MobileSAM&lt;/th&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/thead&gt; &#xA;   &lt;tbody&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Paramters&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;611M&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;5M&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Speed&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;452ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;8ms&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Original SAM and MobileSAM have exactly the same prompt-guided mask decoder:&lt;/p&gt; &#xA;  &lt;table&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;Mask Decoder&lt;/th&gt; &#xA;     &lt;th align=&#34;left&#34;&gt;Original SAM&lt;/th&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;MobileSAM&lt;/th&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/thead&gt; &#xA;   &lt;tbody&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Paramters&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;3.876M&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;3.876M&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Speed&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;4ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;4ms&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The comparison of the whole pipeline is summarized as follows:&lt;/p&gt; &#xA;  &lt;table&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;Whole Pipeline (Enc+Dec)&lt;/th&gt; &#xA;     &lt;th align=&#34;left&#34;&gt;Original SAM&lt;/th&gt; &#xA;     &lt;th align=&#34;center&#34;&gt;MobileSAM&lt;/th&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/thead&gt; &#xA;   &lt;tbody&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Paramters&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;615M&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;9.66M&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;Speed&lt;/td&gt; &#xA;     &lt;td align=&#34;left&#34;&gt;456ms&lt;/td&gt; &#xA;     &lt;td align=&#34;center&#34;&gt;12ms&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;span&gt;â­&lt;/span&gt; &lt;strong&gt;Original SAM and MobileSAM with a (single) point as the prompt.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p float=&#34;left&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ChaoningZhang/MobileSAM/master/assets/mask_point.jpg?raw=true&#34; width=&#34;99.1%&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;â­&lt;/span&gt; &lt;strong&gt;Original SAM and MobileSAM with a box as the prompt.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p float=&#34;left&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ChaoningZhang/MobileSAM/master/assets/mask_box.jpg?raw=true&#34; width=&#34;99.1%&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;ğŸ’ª&lt;/span&gt; &lt;strong&gt;Is MobileSAM faster and smaller than FastSAM? Yes!&lt;/strong&gt; MobileSAM is around 7 times smaller and around 5 times faster than the concurrent FastSAM. The comparison of the whole pipeline is summarzed as follows:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Whole Pipeline (Enc+Dec)&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;FastSAM&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MobileSAM&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Paramters&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;68M&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.66M&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Speed&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;64ms&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12ms&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;span&gt;ğŸ’ª&lt;/span&gt; &lt;strong&gt;Does MobileSAM aign better with the original SAM than FastSAM? Yes!&lt;/strong&gt; FastSAM is suggested to work with multiple points, thus we compare the mIoU with two prompt points (with different pixel distances) and show the resutls as follows. Higher mIoU indicates higher alignment.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;mIoU&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;FastSAM&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MobileSAM&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;100&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.27&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.73&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;200&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.33&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.71&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;300&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.37&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.74&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;400&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.41&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.73&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;500&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;0.41&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;0.73&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;The code requires &lt;code&gt;python&amp;gt;=3.8&lt;/code&gt;, as well as &lt;code&gt;pytorch&amp;gt;=1.7&lt;/code&gt; and &lt;code&gt;torchvision&amp;gt;=0.8&lt;/code&gt;. Please follow the instructions &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;here&lt;/a&gt; to install both PyTorch and TorchVision dependencies. Installing both PyTorch and TorchVision with CUDA support is strongly recommended.&lt;/p&gt; &#xA;&lt;p&gt;Install Mobile Segment Anything:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install git+https://github.com/ChaoningZhang/MobileSAM.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or clone the repository locally and install with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:ChaoningZhang/MobileSAM.git&#xA;cd MobileSAM; pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;GettingStarted&#34;&gt;&lt;/a&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;The MobileSAM can be loaded in the following ways:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from mobile_encoder.setup_mobile_sam import setup_model&#xA;checkpoint = torch.load(&#39;../weights/mobile_sam.pt&#39;)&#xA;mobile_sam = setup_model()&#xA;mobile_sam.load_state_dict(checkpoint,strict=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then the model can be easily used in just a few lines to get masks from a given prompt:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from segment_anything import SamPredictor&#xA;device = &#34;cuda&#34;&#xA;mobile_sam.to(device=device)&#xA;mobile_sam.eval()&#xA;predictor = SamPredictor(mobile_sam)&#xA;predictor.set_image(&amp;lt;your_image&amp;gt;)&#xA;masks, _, _ = predictor.predict(&amp;lt;input_prompts&amp;gt;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or generate masks for an entire image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from segment_anything import SamAutomaticMaskGenerator&#xA;&#xA;mask_generator = SamAutomaticMaskGenerator(mobile_sam)&#xA;masks = mask_generator.generate(&amp;lt;your_image&amp;gt;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;BibTex of our MobileSAM&lt;/h2&gt; &#xA;&lt;p&gt;If you use MobileSAM in your research, please use the following BibTeX entry. &lt;span&gt;ğŸ“£&lt;/span&gt; Thank you!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{mobile_sam,&#xA;  title={Faster Segment Anything: Towards Lightweight SAM for Mobile Applications},&#xA;  author={Zhang, Chaoning and Han, Dongshen and Qiao, Yu and Kim, Jung Uk and Bae, Sung Ho and Lee, Seungkyu and Hong, Choong Seon},&#xA;  journal={arXiv preprint arXiv:2306.14289},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;a href=&#34;https://github.com/facebookresearch/segment-anything&#34;&gt;SAM&lt;/a&gt; (Segment Anything) [&lt;b&gt;bib&lt;/b&gt;] &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{kirillov2023segany,&#xA;  title={Segment Anything}, &#xA;  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Doll{\&#39;a}r, Piotr and Girshick, Ross},&#xA;  journal={arXiv:2304.02643},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;a href=&#34;https://github.com/microsoft/Cream/tree/main/TinyViT&#34;&gt;TinyViT&lt;/a&gt; (TinyViT: Fast Pretraining Distillation for Small Vision Transformers) [&lt;b&gt;bib&lt;/b&gt;] &lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{tiny_vit,&#xA;  title={TinyViT: Fast Pretraining Distillation for Small Vision Transformers},&#xA;  author={Wu, Kan and Zhang, Jinnian and Peng, Houwen and Liu, Mengchen and Xiao, Bin and Fu, Jianlong and Yuan, Lu},&#xA;  booktitle={European conference on computer vision (ECCV)},&#xA;  year={2022}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt;</summary>
  </entry>
  <entry>
    <title>jasontaylordev/CleanArchitecture</title>
    <updated>2023-06-30T01:29:51Z</updated>
    <id>tag:github.com,2023-06-30:/jasontaylordev/CleanArchitecture</id>
    <link href="https://github.com/jasontaylordev/CleanArchitecture" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Clean Architecture Solution Template for ASP.NET Core&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/jasontaylordev/CleanArchitecture/actions/workflows/dotnet-build.yml&#34;&gt;&lt;img src=&#34;https://github.com/jasontaylordev/CleanArchitecture/actions/workflows/dotnet-build.yml/badge.svg?sanitize=true&#34; alt=&#34;Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/jasontaylordev/CleanArchitecture/actions/workflows/codeql-analysis.yml&#34;&gt;&lt;img src=&#34;https://github.com/jasontaylordev/CleanArchitecture/actions/workflows/codeql-analysis.yml/badge.svg?sanitize=true&#34; alt=&#34;CodeQL&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.nuget.org/packages/Clean.Architecture.Solution.Template&#34;&gt;&lt;img src=&#34;https://img.shields.io/nuget/v/Clean.Architecture.Solution.Template?label=NuGet&#34; alt=&#34;Nuget&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.nuget.org/packages/Clean.Architecture.Solution.Template&#34;&gt;&lt;img src=&#34;https://img.shields.io/nuget/dt/Clean.Architecture.Solution.Template?label=Downloads&#34; alt=&#34;Nuget&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/p9YtBjfgGe&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/893301913662148658?label=Discord&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/twitter/follow/jasontaylordev?label=Follow&amp;amp;style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Clean Architecture Solution Template&lt;/h1&gt; &#xA;&lt;p&gt;The goal of this template is to provide a straightforward and efficient approach to enterprise application development, leveraging the power of Clean Architecture and ASP.NET Core. Using this template, you can effortlessly create a Single Page App (SPA) with ASP.NET Core and Angular or React, while adhering to the principles of Clean Architecture. Getting started is easy - simply install the &lt;strong&gt;.NET template&lt;/strong&gt; (see below for full details).&lt;/p&gt; &#xA;&lt;h2&gt;Technologies&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/aspnet/core/introduction-to-aspnet-core&#34;&gt;ASP.NET Core 8&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/ef/core/&#34;&gt;Entity Framework Core 8&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://angular.io/&#34;&gt;Angular 15&lt;/a&gt; or &lt;a href=&#34;https://react.dev/&#34;&gt;React 18&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jbogard/MediatR&#34;&gt;MediatR&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://automapper.org/&#34;&gt;AutoMapper&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fluentvalidation.net/&#34;&gt;FluentValidation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nunit.org/&#34;&gt;NUnit&lt;/a&gt;, &lt;a href=&#34;https://fluentassertions.com/&#34;&gt;FluentAssertions&lt;/a&gt;, &lt;a href=&#34;https://github.com/moq&#34;&gt;Moq&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://github.com/jbogard/Respawn&#34;&gt;Respawn&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Dependencies&lt;/h2&gt; &#xA;&lt;p&gt;The template depends on the latest versions of:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dotnet.microsoft.com/download/dotnet/8.0&#34;&gt;.NET 8 SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nodejs.org/en/&#34;&gt;Node.js LTS&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;The easiest way to get started is to install the &lt;a href=&#34;https://www.nuget.org/packages/Clean.Architecture.Solution.Template&#34;&gt;.NET template&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dotnet new install Clean.Architecture.Solution.Template::8.0.0-preview.5.2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once installed, create a new solution using the template:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dotnet new ca-sln -c &amp;lt;Angular|React&amp;gt; --output &amp;lt;YourProjectName&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The above command creates a SPA with Angular or React on ASP.NET Core. Start the application by navigating to &lt;code&gt;./src/WebUI&lt;/code&gt; and running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dotnet run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create use cases (commands or queries) by navigating to &lt;code&gt;./src/Application&lt;/code&gt;, and running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dotnet new ca-usecase --feature TodoLists --name CreateTodoList --useCaseType command --returnType int&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To learn more, run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dotnet new ca-usecase --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Database&lt;/h2&gt; &#xA;&lt;p&gt;The template is configured to use an in-memory database by default. This ensures that all users will be able to run the solution without needing to set up additional infrastructure (e.g. SQL Server).&lt;/p&gt; &#xA;&lt;p&gt;If you would like to use SQL Server, you will need to update &lt;strong&gt;WebUI/appsettings.json&lt;/strong&gt; as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;  &#34;UseInMemoryDatabase&#34;: false,&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Verify that the &lt;strong&gt;DefaultConnection&lt;/strong&gt; connection string within &lt;strong&gt;appsettings.json&lt;/strong&gt; points to a valid SQL Server instance.&lt;/p&gt; &#xA;&lt;p&gt;When you run the application the database will be automatically created (if necessary) and the latest migrations will be applied.&lt;/p&gt; &#xA;&lt;h3&gt;Database Migrations&lt;/h3&gt; &#xA;&lt;p&gt;To use &lt;code&gt;dotnet-ef&lt;/code&gt; for your migrations first ensure that &#34;UseInMemoryDatabase&#34; is disabled, as described within previous section. Then, add the following flags to your command (values assume you are executing from repository root)&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--project src/Infrastructure&lt;/code&gt; (optional if in this folder)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--startup-project src/WebUI&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--output-dir Persistence/Migrations&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For example, to add a new migration from the root folder:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;dotnet ef migrations add &#34;SampleMigration&#34; --project src\Infrastructure --startup-project src\WebUI --output-dir Persistence\Migrations&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Versions&lt;/h2&gt; &#xA;&lt;p&gt;The main branch is now on .NET 8.0. The following previous versions are available:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jasontaylordev/CleanArchitecture/tree/net7.0&#34;&gt;7.0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jasontaylordev/CleanArchitecture/tree/net6.0&#34;&gt;6.0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jasontaylordev/CleanArchitecture/tree/net5.0&#34;&gt;5.0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jasontaylordev/CleanArchitecture/tree/netcore3.1&#34;&gt;3.1&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Learn More&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/dK4Yb6-LxAk&#34;&gt;Clean Architecture with ASP.NET Core 3.0 (GOTO 2019)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jasontaylor.dev/clean-architecture-getting-started/&#34;&gt;Clean Architecture with .NET Core: Getting Started&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;If you are having problems, please let me know by &lt;a href=&#34;https://github.com/jasontaylordev/CleanArchitecture/issues/new/choose&#34;&gt;raising a new issue&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed with the &lt;a href=&#34;https://raw.githubusercontent.com/jasontaylordev/CleanArchitecture/main/LICENSE&#34;&gt;MIT license&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>THUDM/ChatGLM2-6B</title>
    <updated>2023-06-30T01:29:51Z</updated>
    <id>tag:github.com,2023-06-30:/THUDM/ChatGLM2-6B</id>
    <link href="https://github.com/THUDM/ChatGLM2-6B" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ChatGLM2-6B: An Open Bilingual Chat LLM | å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGLM2-6B&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; ğŸ¤— &lt;a href=&#34;https://huggingface.co/THUDM/chatglm2-6b&#34; target=&#34;_blank&#34;&gt;HF Repo&lt;/a&gt; â€¢ ğŸ¦ &lt;a href=&#34;https://twitter.com/thukeg&#34; target=&#34;_blank&#34;&gt;Twitter&lt;/a&gt; â€¢ ğŸ“ƒ &lt;a href=&#34;https://arxiv.org/abs/2103.10360&#34; target=&#34;_blank&#34;&gt;[GLM@ACL 22]&lt;/a&gt; &lt;a href=&#34;https://github.com/THUDM/GLM&#34; target=&#34;_blank&#34;&gt;[GitHub]&lt;/a&gt; â€¢ ğŸ“ƒ &lt;a href=&#34;https://arxiv.org/abs/2210.02414&#34; target=&#34;_blank&#34;&gt;[GLM-130B@ICLR 23]&lt;/a&gt; &lt;a href=&#34;https://github.com/THUDM/GLM-130B&#34; target=&#34;_blank&#34;&gt;[GitHub]&lt;/a&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ &lt;a href=&#34;https://join.slack.com/t/chatglm/shared_invite/zt-1udqapmrr-ocT1DS_mxWe6dDY8ahRWzg&#34; target=&#34;_blank&#34;&gt;Slack&lt;/a&gt; å’Œ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/resources/WECHAT.md&#34; target=&#34;_blank&#34;&gt;WeChat&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Read this in &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/README_EN.md&#34;&gt;English&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ä»‹ç»&lt;/h2&gt; &#xA;&lt;p&gt;ChatGLM&lt;strong&gt;2&lt;/strong&gt;-6B æ˜¯å¼€æºä¸­è‹±åŒè¯­å¯¹è¯æ¨¡å‹ &lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34;&gt;ChatGLM-6B&lt;/a&gt; çš„ç¬¬äºŒä»£ç‰ˆæœ¬ï¼Œåœ¨ä¿ç•™äº†åˆä»£æ¨¡å‹å¯¹è¯æµç•…ã€éƒ¨ç½²é—¨æ§›è¾ƒä½ç­‰ä¼—å¤šä¼˜ç§€ç‰¹æ€§çš„åŸºç¡€ä¹‹ä¸Šï¼ŒChatGLM&lt;strong&gt;2&lt;/strong&gt;-6B å¼•å…¥äº†å¦‚ä¸‹æ–°ç‰¹æ€§ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;æ›´å¼ºå¤§çš„æ€§èƒ½&lt;/strong&gt;ï¼šåŸºäº ChatGLM åˆä»£æ¨¡å‹çš„å¼€å‘ç»éªŒï¼Œæˆ‘ä»¬å…¨é¢å‡çº§äº† ChatGLM2-6B çš„åŸºåº§æ¨¡å‹ã€‚ChatGLM2-6B ä½¿ç”¨äº† &lt;a href=&#34;https://github.com/THUDM/GLM&#34;&gt;GLM&lt;/a&gt; çš„æ··åˆç›®æ ‡å‡½æ•°ï¼Œç»è¿‡äº† 1.4T ä¸­è‹±æ ‡è¯†ç¬¦çš„é¢„è®­ç»ƒä¸äººç±»åå¥½å¯¹é½è®­ç»ƒï¼Œ&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/#%E8%AF%84%E6%B5%8B%E7%BB%93%E6%9E%9C&#34;&gt;è¯„æµ‹ç»“æœ&lt;/a&gt;æ˜¾ç¤ºï¼Œç›¸æ¯”äºåˆä»£æ¨¡å‹ï¼ŒChatGLM2-6B åœ¨ MMLUï¼ˆ+23%ï¼‰ã€CEvalï¼ˆ+33%ï¼‰ã€GSM8Kï¼ˆ+571%ï¼‰ ã€BBHï¼ˆ+60%ï¼‰ç­‰æ•°æ®é›†ä¸Šçš„æ€§èƒ½å–å¾—äº†å¤§å¹…åº¦çš„æå‡ï¼Œåœ¨åŒå°ºå¯¸å¼€æºæ¨¡å‹ä¸­å…·æœ‰è¾ƒå¼ºçš„ç«äº‰åŠ›ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;æ›´é•¿çš„ä¸Šä¸‹æ–‡&lt;/strong&gt;ï¼šåŸºäº &lt;a href=&#34;https://github.com/HazyResearch/flash-attention&#34;&gt;FlashAttention&lt;/a&gt; æŠ€æœ¯ï¼Œæˆ‘ä»¬å°†åŸºåº§æ¨¡å‹çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆContext Lengthï¼‰ç”± ChatGLM-6B çš„ 2K æ‰©å±•åˆ°äº† 32Kï¼Œå¹¶åœ¨å¯¹è¯é˜¶æ®µä½¿ç”¨ 8K çš„ä¸Šä¸‹æ–‡é•¿åº¦è®­ç»ƒï¼Œå…è®¸æ›´å¤šè½®æ¬¡çš„å¯¹è¯ã€‚ä½†å½“å‰ç‰ˆæœ¬çš„ ChatGLM2-6B å¯¹å•è½®è¶…é•¿æ–‡æ¡£çš„ç†è§£èƒ½åŠ›æœ‰é™ï¼Œæˆ‘ä»¬ä¼šåœ¨åç»­è¿­ä»£å‡çº§ä¸­ç€é‡è¿›è¡Œä¼˜åŒ–ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;æ›´é«˜æ•ˆçš„æ¨ç†&lt;/strong&gt;ï¼šåŸºäº &lt;a href=&#34;http://arxiv.org/abs/1911.02150&#34;&gt;Multi-Query Attention&lt;/a&gt; æŠ€æœ¯ï¼ŒChatGLM2-6B æœ‰æ›´é«˜æ•ˆçš„æ¨ç†é€Ÿåº¦å’Œæ›´ä½çš„æ˜¾å­˜å ç”¨ï¼šåœ¨å®˜æ–¹çš„æ¨¡å‹å®ç°ä¸‹ï¼Œæ¨ç†é€Ÿåº¦ç›¸æ¯”åˆä»£æå‡äº† 42%ï¼ŒINT4 é‡åŒ–ä¸‹ï¼Œ6G æ˜¾å­˜æ”¯æŒçš„å¯¹è¯é•¿åº¦ç”± 1K æå‡åˆ°äº† 8Kã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;æ›´å¼€æ”¾çš„åè®®&lt;/strong&gt;ï¼šChatGLM2-6B æƒé‡å¯¹å­¦æœ¯ç ”ç©¶&lt;strong&gt;å®Œå…¨å¼€æ”¾&lt;/strong&gt;ï¼Œåœ¨è·å¾—å®˜æ–¹çš„ä¹¦é¢è®¸å¯åï¼Œäº¦&lt;strong&gt;å…è®¸å•†ä¸šä½¿ç”¨&lt;/strong&gt;ã€‚å¦‚æœæ‚¨å‘ç°æˆ‘ä»¬çš„å¼€æºæ¨¡å‹å¯¹æ‚¨çš„ä¸šåŠ¡æœ‰ç”¨ï¼Œæˆ‘ä»¬æ¬¢è¿æ‚¨å¯¹ä¸‹ä¸€ä»£æ¨¡å‹ ChatGLM3 ç ”å‘çš„æèµ ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;ChatGLM2-6B å¼€æºæ¨¡å‹æ—¨åœ¨ä¸å¼€æºç¤¾åŒºä¸€èµ·æ¨åŠ¨å¤§æ¨¡å‹æŠ€æœ¯å‘å±•ï¼Œæ³è¯·å¼€å‘è€…å’Œå¤§å®¶éµå®ˆ&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/MODEL_LICENSE&#34;&gt;å¼€æºåè®®&lt;/a&gt;ï¼Œå‹¿å°†å¼€æºæ¨¡å‹å’Œä»£ç åŠåŸºäºå¼€æºé¡¹ç›®äº§ç”Ÿçš„è¡ç”Ÿç‰©ç”¨äºä»»ä½•å¯èƒ½ç»™å›½å®¶å’Œç¤¾ä¼šå¸¦æ¥å±å®³çš„ç”¨é€”ä»¥åŠç”¨äºä»»ä½•æœªç»è¿‡å®‰å…¨è¯„ä¼°å’Œå¤‡æ¡ˆçš„æœåŠ¡ã€‚&lt;strong&gt;ç›®å‰ï¼Œæœ¬é¡¹ç›®å›¢é˜ŸæœªåŸºäº ChatGLM2-6B å¼€å‘ä»»ä½•åº”ç”¨ï¼ŒåŒ…æ‹¬ç½‘é¡µç«¯ã€å®‰å“ã€è‹¹æœ iOS åŠ Windows App ç­‰åº”ç”¨ã€‚&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;å°½ç®¡æ¨¡å‹åœ¨è®­ç»ƒçš„å„ä¸ªé˜¶æ®µéƒ½å°½åŠ›ç¡®ä¿æ•°æ®çš„åˆè§„æ€§å’Œå‡†ç¡®æ€§ï¼Œä½†ç”±äº ChatGLM2-6B æ¨¡å‹è§„æ¨¡è¾ƒå°ï¼Œä¸”æ¨¡å‹å—æ¦‚ç‡éšæœºæ€§å› ç´ å½±å“ï¼Œæ— æ³•ä¿è¯è¾“å‡ºå†…å®¹çš„å‡†ç¡®æ€§ï¼Œä¸”æ¨¡å‹æ˜“è¢«è¯¯å¯¼ã€‚&lt;strong&gt;æœ¬é¡¹ç›®ä¸æ‰¿æ‹…å¼€æºæ¨¡å‹å’Œä»£ç å¯¼è‡´çš„æ•°æ®å®‰å…¨ã€èˆ†æƒ…é£é™©æˆ–å‘ç”Ÿä»»ä½•æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­ã€ä¸å½“åˆ©ç”¨è€Œäº§ç”Ÿçš„é£é™©å’Œè´£ä»»ã€‚&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;è¯„æµ‹ç»“æœ&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘ä»¬é€‰å–äº†éƒ¨åˆ†ä¸­è‹±æ–‡å…¸å‹æ•°æ®é›†è¿›è¡Œäº†è¯„æµ‹ï¼Œä»¥ä¸‹ä¸º ChatGLM2-6B æ¨¡å‹åœ¨ &lt;a href=&#34;https://github.com/hendrycks/test&#34;&gt;MMLU&lt;/a&gt; (è‹±æ–‡)ã€&lt;a href=&#34;https://cevalbenchmark.com/static/leaderboard.html&#34;&gt;C-Eval&lt;/a&gt;ï¼ˆä¸­æ–‡ï¼‰ã€&lt;a href=&#34;https://github.com/openai/grade-school-math&#34;&gt;GSM8K&lt;/a&gt;ï¼ˆæ•°å­¦ï¼‰ã€&lt;a href=&#34;https://github.com/suzgunmirac/BIG-Bench-Hard&#34;&gt;BBH&lt;/a&gt;ï¼ˆè‹±æ–‡ï¼‰ ä¸Šçš„æµ‹è¯„ç»“æœã€‚åœ¨ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/evaluation/README.md&#34;&gt;evaluation&lt;/a&gt; ä¸­æä¾›äº†åœ¨ C-Eval ä¸Šè¿›è¡Œæµ‹è¯„çš„è„šæœ¬ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;MMLU&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Average&lt;/th&gt; &#xA;   &lt;th&gt;STEM&lt;/th&gt; &#xA;   &lt;th&gt;Social Sciences&lt;/th&gt; &#xA;   &lt;th&gt;Humanities&lt;/th&gt; &#xA;   &lt;th&gt;Others&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM-6B&lt;/td&gt; &#xA;   &lt;td&gt;40.63&lt;/td&gt; &#xA;   &lt;td&gt;33.89&lt;/td&gt; &#xA;   &lt;td&gt;44.84&lt;/td&gt; &#xA;   &lt;td&gt;39.02&lt;/td&gt; &#xA;   &lt;td&gt;45.71&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B (base)&lt;/td&gt; &#xA;   &lt;td&gt;47.86&lt;/td&gt; &#xA;   &lt;td&gt;41.20&lt;/td&gt; &#xA;   &lt;td&gt;54.44&lt;/td&gt; &#xA;   &lt;td&gt;43.66&lt;/td&gt; &#xA;   &lt;td&gt;54.46&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B&lt;/td&gt; &#xA;   &lt;td&gt;45.46&lt;/td&gt; &#xA;   &lt;td&gt;40.06&lt;/td&gt; &#xA;   &lt;td&gt;51.61&lt;/td&gt; &#xA;   &lt;td&gt;41.23&lt;/td&gt; &#xA;   &lt;td&gt;51.24&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Chat æ¨¡å‹ä½¿ç”¨ zero-shot CoT (Chain-of-Thought) çš„æ–¹æ³•æµ‹è¯•ï¼ŒBase æ¨¡å‹ä½¿ç”¨ few-shot answer-only çš„æ–¹æ³•æµ‹è¯•&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;C-Eval&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Average&lt;/th&gt; &#xA;   &lt;th&gt;STEM&lt;/th&gt; &#xA;   &lt;th&gt;Social Sciences&lt;/th&gt; &#xA;   &lt;th&gt;Humanities&lt;/th&gt; &#xA;   &lt;th&gt;Others&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM-6B&lt;/td&gt; &#xA;   &lt;td&gt;38.9&lt;/td&gt; &#xA;   &lt;td&gt;33.3&lt;/td&gt; &#xA;   &lt;td&gt;48.3&lt;/td&gt; &#xA;   &lt;td&gt;41.3&lt;/td&gt; &#xA;   &lt;td&gt;38.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B (base)&lt;/td&gt; &#xA;   &lt;td&gt;51.7&lt;/td&gt; &#xA;   &lt;td&gt;48.6&lt;/td&gt; &#xA;   &lt;td&gt;60.5&lt;/td&gt; &#xA;   &lt;td&gt;51.3&lt;/td&gt; &#xA;   &lt;td&gt;49.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B&lt;/td&gt; &#xA;   &lt;td&gt;50.1&lt;/td&gt; &#xA;   &lt;td&gt;46.4&lt;/td&gt; &#xA;   &lt;td&gt;60.4&lt;/td&gt; &#xA;   &lt;td&gt;50.6&lt;/td&gt; &#xA;   &lt;td&gt;46.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Chat æ¨¡å‹ä½¿ç”¨ zero-shot CoT çš„æ–¹æ³•æµ‹è¯•ï¼ŒBase æ¨¡å‹ä½¿ç”¨ few-shot answer only çš„æ–¹æ³•æµ‹è¯•&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;GSM8K&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Accuracy&lt;/th&gt; &#xA;   &lt;th&gt;Accuracy (Chinese)*&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM-6B&lt;/td&gt; &#xA;   &lt;td&gt;4.82&lt;/td&gt; &#xA;   &lt;td&gt;5.85&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B (base)&lt;/td&gt; &#xA;   &lt;td&gt;32.37&lt;/td&gt; &#xA;   &lt;td&gt;28.95&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B&lt;/td&gt; &#xA;   &lt;td&gt;28.05&lt;/td&gt; &#xA;   &lt;td&gt;20.45&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;æ‰€æœ‰æ¨¡å‹å‡ä½¿ç”¨ few-shot CoT çš„æ–¹æ³•æµ‹è¯•ï¼ŒCoT prompt æ¥è‡ª &lt;a href=&#34;http://arxiv.org/abs/2201.11903&#34;&gt;http://arxiv.org/abs/2201.11903&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;* æˆ‘ä»¬ä½¿ç”¨ç¿»è¯‘ API ç¿»è¯‘äº† GSM8K ä¸­çš„ 500 é“é¢˜ç›®å’Œ CoT prompt å¹¶è¿›è¡Œäº†äººå·¥æ ¡å¯¹&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;BBH&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Accuracy&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM-6B&lt;/td&gt; &#xA;   &lt;td&gt;18.73&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B (base)&lt;/td&gt; &#xA;   &lt;td&gt;33.68&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B&lt;/td&gt; &#xA;   &lt;td&gt;30.00&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;æ‰€æœ‰æ¨¡å‹å‡ä½¿ç”¨ few-shot CoT çš„æ–¹æ³•æµ‹è¯•ï¼ŒCoT prompt æ¥è‡ª &lt;a href=&#34;https://github.com/suzgunmirac/BIG-Bench-Hard/tree/main/cot-prompts&#34;&gt;https://github.com/suzgunmirac/BIG-Bench-Hard/tree/main/cot-prompts&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;æ¨ç†æ€§èƒ½&lt;/h2&gt; &#xA;&lt;p&gt;ChatGLM2-6B ä½¿ç”¨äº† &lt;a href=&#34;http://arxiv.org/abs/1911.02150&#34;&gt;Multi-Query Attention&lt;/a&gt;ï¼Œæé«˜äº†ç”Ÿæˆé€Ÿåº¦ã€‚ç”Ÿæˆ 2000 ä¸ªå­—ç¬¦çš„å¹³å‡é€Ÿåº¦å¯¹æ¯”å¦‚ä¸‹&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;æ¨ç†é€Ÿåº¦ (å­—ç¬¦/ç§’)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM-6B&lt;/td&gt; &#xA;   &lt;td&gt;31.49&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B&lt;/td&gt; &#xA;   &lt;td&gt;44.62&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ä½¿ç”¨å®˜æ–¹å®ç°ï¼Œbatch size = 1ï¼Œmax length = 2048ï¼Œbf16 ç²¾åº¦ï¼Œæµ‹è¯•ç¡¬ä»¶ä¸º A100-SXM4-80Gï¼Œè½¯ä»¶ç¯å¢ƒä¸º PyTorch 2.0.1&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Multi-Query Attention åŒæ—¶ä¹Ÿé™ä½äº†ç”Ÿæˆè¿‡ç¨‹ä¸­ KV Cache çš„æ˜¾å­˜å ç”¨ï¼Œæ­¤å¤–ï¼ŒChatGLM2-6B é‡‡ç”¨ Causal Mask è¿›è¡Œå¯¹è¯è®­ç»ƒï¼Œè¿ç»­å¯¹è¯æ—¶å¯å¤ç”¨å‰é¢è½®æ¬¡çš„ KV Cacheï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–äº†æ˜¾å­˜å ç”¨ã€‚å› æ­¤ï¼Œä½¿ç”¨ 6GB æ˜¾å­˜çš„æ˜¾å¡è¿›è¡Œ INT4 é‡åŒ–çš„æ¨ç†æ—¶ï¼Œåˆä»£çš„ ChatGLM-6B æ¨¡å‹æœ€å¤šèƒ½å¤Ÿç”Ÿæˆ 1119 ä¸ªå­—ç¬¦å°±ä¼šæç¤ºæ˜¾å­˜è€—å°½ï¼Œè€Œ ChatGLM2-6B èƒ½å¤Ÿç”Ÿæˆè‡³å°‘ 8192 ä¸ªå­—ç¬¦ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;é‡åŒ–ç­‰çº§&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;ç¼–ç  2048 é•¿åº¦çš„æœ€å°æ˜¾å­˜&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;ç”Ÿæˆ 8192 é•¿åº¦çš„æœ€å°æ˜¾å­˜&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FP16 / BF16&lt;/td&gt; &#xA;   &lt;td&gt;13.1 GB&lt;/td&gt; &#xA;   &lt;td&gt;12.8 GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;INT8&lt;/td&gt; &#xA;   &lt;td&gt;8.2 GB&lt;/td&gt; &#xA;   &lt;td&gt;8.1 GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;INT4&lt;/td&gt; &#xA;   &lt;td&gt;5.5 GB&lt;/td&gt; &#xA;   &lt;td&gt;5.1 GB&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ChatGLM2-6B åˆ©ç”¨äº† PyTorch 2.0 å¼•å…¥çš„ &lt;code&gt;torch.nn.functional.scaled_dot_product_attention&lt;/code&gt; å®ç°é«˜æ•ˆçš„ Attention è®¡ç®—ï¼Œå¦‚æœ PyTorch ç‰ˆæœ¬è¾ƒä½åˆ™ä¼š fallback åˆ°æœ´ç´ çš„ Attention å®ç°ï¼Œå‡ºç°æ˜¾å­˜å ç”¨é«˜äºä¸Šè¡¨çš„æƒ…å†µã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;æˆ‘ä»¬ä¹Ÿæµ‹è¯•äº†é‡åŒ–å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚ç»“æœè¡¨æ˜ï¼Œé‡åŒ–å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“åœ¨å¯æ¥å—èŒƒå›´å†…ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;é‡åŒ–ç­‰çº§&lt;/th&gt; &#xA;   &lt;th&gt;Accuracy (MMLU)&lt;/th&gt; &#xA;   &lt;th&gt;Accuracy (C-Eval dev)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BF16&lt;/td&gt; &#xA;   &lt;td&gt;45.47&lt;/td&gt; &#xA;   &lt;td&gt;53.57&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;INT4&lt;/td&gt; &#xA;   &lt;td&gt;43.13&lt;/td&gt; &#xA;   &lt;td&gt;50.30&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;ChatGLM2-6B ç¤ºä¾‹&lt;/h2&gt; &#xA;&lt;p&gt;ç›¸æ¯”äºåˆä»£æ¨¡å‹ï¼ŒChatGLM2-6B å¤šä¸ªç»´åº¦çš„èƒ½åŠ›éƒ½å–å¾—äº†æå‡ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å¯¹æ¯”ç¤ºä¾‹ã€‚æ›´å¤š ChatGLM2-6B çš„å¯èƒ½ï¼Œç­‰å¾…ä½ æ¥æ¢ç´¢å‘ç°ï¼&lt;/p&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;æ•°ç†é€»è¾‘&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/resources/math.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;çŸ¥è¯†æ¨ç†&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/resources/knowledge.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;é•¿æ–‡æ¡£ç†è§£&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/resources/long-context.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;ä½¿ç”¨æ–¹å¼&lt;/h2&gt; &#xA;&lt;h3&gt;ç¯å¢ƒå®‰è£…&lt;/h3&gt; &#xA;&lt;p&gt;é¦–å…ˆéœ€è¦ä¸‹è½½æœ¬ä»“åº“ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/THUDM/ChatGLM2-6B&#xA;cd ChatGLM2-6B&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ç„¶åä½¿ç”¨ pip å®‰è£…ä¾èµ–ï¼š&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;ï¼Œå…¶ä¸­ &lt;code&gt;transformers&lt;/code&gt; åº“ç‰ˆæœ¬æ¨èä¸º &lt;code&gt;4.30.2&lt;/code&gt;ï¼Œ&lt;code&gt;torch&lt;/code&gt; æ¨èä½¿ç”¨ 2.0 ä»¥ä¸Šçš„ç‰ˆæœ¬ï¼Œä»¥è·å¾—æœ€ä½³çš„æ¨ç†æ€§èƒ½ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;ä»£ç è°ƒç”¨&lt;/h3&gt; &#xA;&lt;p&gt;å¯ä»¥é€šè¿‡å¦‚ä¸‹ä»£ç è°ƒç”¨ ChatGLM2-6B æ¨¡å‹æ¥ç”Ÿæˆå¯¹è¯ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from transformers import AutoTokenizer, AutoModel&#xA;&amp;gt;&amp;gt;&amp;gt; tokenizer = AutoTokenizer.from_pretrained(&#34;THUDM/chatglm2-6b&#34;, trust_remote_code=True)&#xA;&amp;gt;&amp;gt;&amp;gt; model = AutoModel.from_pretrained(&#34;THUDM/chatglm2-6b&#34;, trust_remote_code=True, device=&#39;cuda&#39;)&#xA;&amp;gt;&amp;gt;&amp;gt; model = model.eval()&#xA;&amp;gt;&amp;gt;&amp;gt; response, history = model.chat(tokenizer, &#34;ä½ å¥½&#34;, history=[])&#xA;&amp;gt;&amp;gt;&amp;gt; print(response)&#xA;ä½ å¥½ğŸ‘‹!æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6B,å¾ˆé«˜å…´è§åˆ°ä½ ,æ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚&#xA;&amp;gt;&amp;gt;&amp;gt; response, history = model.chat(tokenizer, &#34;æ™šä¸Šç¡ä¸ç€åº”è¯¥æ€ä¹ˆåŠ&#34;, history=history)&#xA;&amp;gt;&amp;gt;&amp;gt; print(response)&#xA;æ™šä¸Šç¡ä¸ç€å¯èƒ½ä¼šè®©ä½ æ„Ÿåˆ°ç„¦è™‘æˆ–ä¸èˆ’æœ,ä½†ä»¥ä¸‹æ˜¯ä¸€äº›å¯ä»¥å¸®åŠ©ä½ å…¥ç¡çš„æ–¹æ³•:&#xA;&#xA;1. åˆ¶å®šè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨:ä¿æŒè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨å¯ä»¥å¸®åŠ©ä½ å»ºç«‹å¥åº·çš„ç¡çœ ä¹ æƒ¯,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚å°½é‡åœ¨æ¯å¤©çš„ç›¸åŒæ—¶é—´ä¸ŠåºŠ,å¹¶åœ¨åŒä¸€æ—¶é—´èµ·åºŠã€‚&#xA;2. åˆ›é€ ä¸€ä¸ªèˆ’é€‚çš„ç¡çœ ç¯å¢ƒ:ç¡®ä¿ç¡çœ ç¯å¢ƒèˆ’é€‚,å®‰é™,é»‘æš—ä¸”æ¸©åº¦é€‚å®œã€‚å¯ä»¥ä½¿ç”¨èˆ’é€‚çš„åºŠä¸Šç”¨å“,å¹¶ä¿æŒæˆ¿é—´é€šé£ã€‚&#xA;3. æ”¾æ¾èº«å¿ƒ:åœ¨ç¡å‰åšäº›æ”¾æ¾çš„æ´»åŠ¨,ä¾‹å¦‚æ³¡ä¸ªçƒ­æ°´æ¾¡,å¬äº›è½»æŸ”çš„éŸ³ä¹,é˜…è¯»ä¸€äº›æœ‰è¶£çš„ä¹¦ç±ç­‰,æœ‰åŠ©äºç¼“è§£ç´§å¼ å’Œç„¦è™‘,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚&#xA;4. é¿å…é¥®ç”¨å«æœ‰å’–å•¡å› çš„é¥®æ–™:å’–å•¡å› æ˜¯ä¸€ç§åˆºæ¿€æ€§ç‰©è´¨,ä¼šå½±å“ä½ çš„ç¡çœ è´¨é‡ã€‚å°½é‡é¿å…åœ¨ç¡å‰é¥®ç”¨å«æœ‰å’–å•¡å› çš„é¥®æ–™,ä¾‹å¦‚å’–å•¡,èŒ¶å’Œå¯ä¹ã€‚&#xA;5. é¿å…åœ¨åºŠä¸Šåšä¸ç¡çœ æ— å…³çš„äº‹æƒ…:åœ¨åºŠä¸Šåšäº›ä¸ç¡çœ æ— å…³çš„äº‹æƒ…,ä¾‹å¦‚çœ‹ç”µå½±,ç©æ¸¸æˆæˆ–å·¥ä½œç­‰,å¯èƒ½ä¼šå¹²æ‰°ä½ çš„ç¡çœ ã€‚&#xA;6. å°è¯•å‘¼å¸æŠ€å·§:æ·±å‘¼å¸æ˜¯ä¸€ç§æ”¾æ¾æŠ€å·§,å¯ä»¥å¸®åŠ©ä½ ç¼“è§£ç´§å¼ å’Œç„¦è™‘,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚è¯•ç€æ…¢æ…¢å¸æ°”,ä¿æŒå‡ ç§’é’Ÿ,ç„¶åç¼“æ…¢å‘¼æ°”ã€‚&#xA;&#xA;å¦‚æœè¿™äº›æ–¹æ³•æ— æ³•å¸®åŠ©ä½ å…¥ç¡,ä½ å¯ä»¥è€ƒè™‘å’¨è¯¢åŒ»ç”Ÿæˆ–ç¡çœ ä¸“å®¶,å¯»æ±‚è¿›ä¸€æ­¥çš„å»ºè®®ã€‚&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;ä»æœ¬åœ°åŠ è½½æ¨¡å‹&lt;/h4&gt; &#xA;&lt;p&gt;ä»¥ä¸Šä»£ç ä¼šç”± &lt;code&gt;transformers&lt;/code&gt; è‡ªåŠ¨ä¸‹è½½æ¨¡å‹å®ç°å’Œå‚æ•°ã€‚å®Œæ•´çš„æ¨¡å‹å®ç°åœ¨ &lt;a href=&#34;https://huggingface.co/THUDM/chatglm2-6b&#34;&gt;Hugging Face Hub&lt;/a&gt;ã€‚å¦‚æœä½ çš„ç½‘ç»œç¯å¢ƒè¾ƒå·®ï¼Œä¸‹è½½æ¨¡å‹å‚æ•°å¯èƒ½ä¼šèŠ±è´¹è¾ƒé•¿æ—¶é—´ç”šè‡³å¤±è´¥ã€‚æ­¤æ—¶å¯ä»¥å…ˆå°†æ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°ï¼Œç„¶åä»æœ¬åœ°åŠ è½½ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ä» Hugging Face Hub ä¸‹è½½æ¨¡å‹éœ€è¦å…ˆ&lt;a href=&#34;https://docs.github.com/zh/repositories/working-with-files/managing-large-files/installing-git-large-file-storage&#34;&gt;å®‰è£…Git LFS&lt;/a&gt;ï¼Œç„¶åè¿è¡Œ&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;git clone https://huggingface.co/THUDM/chatglm2-6b&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å¦‚æœä½ ä» Hugging Face Hub ä¸Šä¸‹è½½ checkpoint çš„é€Ÿåº¦è¾ƒæ…¢ï¼Œå¯ä»¥åªä¸‹è½½æ¨¡å‹å®ç°&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/THUDM/chatglm2-6b&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ç„¶åä»&lt;a href=&#34;https://cloud.tsinghua.edu.cn/d/674208019e314311ab5c/&#34;&gt;è¿™é‡Œ&lt;/a&gt;æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹å‚æ•°æ–‡ä»¶ï¼Œå¹¶å°†ä¸‹è½½çš„æ–‡ä»¶æ›¿æ¢åˆ°æœ¬åœ°çš„ &lt;code&gt;chatglm2-6b&lt;/code&gt; ç›®å½•ä¸‹ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å°†æ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°ä¹‹åï¼Œå°†ä»¥ä¸Šä»£ç ä¸­çš„ &lt;code&gt;THUDM/chatglm2-6b&lt;/code&gt; æ›¿æ¢ä¸ºä½ æœ¬åœ°çš„ &lt;code&gt;chatglm2-6b&lt;/code&gt; æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå³å¯ä»æœ¬åœ°åŠ è½½æ¨¡å‹ã€‚&lt;/p&gt; &#xA;&lt;p&gt;æ¨¡å‹çš„å®ç°ä»ç„¶å¤„åœ¨å˜åŠ¨ä¸­ã€‚å¦‚æœå¸Œæœ›å›ºå®šä½¿ç”¨çš„æ¨¡å‹å®ç°ä»¥ä¿è¯å…¼å®¹æ€§ï¼Œå¯ä»¥åœ¨ &lt;code&gt;from_pretrained&lt;/code&gt; çš„è°ƒç”¨ä¸­å¢åŠ  &lt;code&gt;revision=&#34;v1.0&#34;&lt;/code&gt; å‚æ•°ã€‚&lt;code&gt;v1.0&lt;/code&gt; æ˜¯å½“å‰æœ€æ–°çš„ç‰ˆæœ¬å·ï¼Œå®Œæ•´çš„ç‰ˆæœ¬åˆ—è¡¨å‚è§ &lt;a href=&#34;https://huggingface.co/THUDM/chatglm2-6b#change-log&#34;&gt;Change Log&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;ç½‘é¡µç‰ˆ Demo&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/resources/web-demo.gif&#34; alt=&#34;web-demo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;é¦–å…ˆå®‰è£… Gradioï¼š&lt;code&gt;pip install gradio&lt;/code&gt;ï¼Œç„¶åè¿è¡Œä»“åº“ä¸­çš„ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/web_demo.py&#34;&gt;web_demo.py&lt;/a&gt;ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python web_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ç¨‹åºä¼šè¿è¡Œä¸€ä¸ª Web Serverï¼Œå¹¶è¾“å‡ºåœ°å€ã€‚åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€è¾“å‡ºçš„åœ°å€å³å¯ä½¿ç”¨ã€‚&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;é»˜è®¤ä½¿ç”¨äº† &lt;code&gt;share=False&lt;/code&gt; å¯åŠ¨ï¼Œä¸ä¼šç”Ÿæˆå…¬ç½‘é“¾æ¥ã€‚å¦‚æœ‰éœ€è¦å…¬ç½‘è®¿é—®çš„éœ€æ±‚ï¼Œå¯ä»¥ä¿®æ”¹ä¸º &lt;code&gt;share=True&lt;/code&gt; å¯åŠ¨ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;æ„Ÿè°¢ &lt;a href=&#34;https://github.com/AdamBear&#34;&gt;@AdamBear&lt;/a&gt; å®ç°äº†åŸºäº Streamlit çš„ç½‘é¡µç‰ˆ Demo &lt;code&gt;web_demo2.py&lt;/code&gt;ã€‚ä½¿ç”¨æ—¶é¦–å…ˆéœ€è¦é¢å¤–å®‰è£…ä»¥ä¸‹ä¾èµ–ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install streamlit streamlit-chat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ç„¶åé€šè¿‡ä»¥ä¸‹å‘½ä»¤è¿è¡Œï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;streamlit run web_demo2.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ç»æµ‹è¯•ï¼Œå¦‚æœè¾“å…¥çš„ prompt è¾ƒé•¿çš„è¯ï¼Œä½¿ç”¨åŸºäº Streamlit çš„ç½‘é¡µç‰ˆ Demo ä¼šæ›´æµç•…ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;å‘½ä»¤è¡Œ Demo&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/resources/cli-demo.png&#34; alt=&#34;cli-demo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;è¿è¡Œä»“åº“ä¸­ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/cli_demo.py&#34;&gt;cli_demo.py&lt;/a&gt;ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python cli_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ç¨‹åºä¼šåœ¨å‘½ä»¤è¡Œä¸­è¿›è¡Œäº¤äº’å¼çš„å¯¹è¯ï¼Œåœ¨å‘½ä»¤è¡Œä¸­è¾“å…¥æŒ‡ç¤ºå¹¶å›è½¦å³å¯ç”Ÿæˆå›å¤ï¼Œè¾“å…¥ &lt;code&gt;clear&lt;/code&gt; å¯ä»¥æ¸…ç©ºå¯¹è¯å†å²ï¼Œè¾“å…¥ &lt;code&gt;stop&lt;/code&gt; ç»ˆæ­¢ç¨‹åºã€‚&lt;/p&gt; &#xA;&lt;h3&gt;API éƒ¨ç½²&lt;/h3&gt; &#xA;&lt;p&gt;é¦–å…ˆéœ€è¦å®‰è£…é¢å¤–çš„ä¾èµ– &lt;code&gt;pip install fastapi uvicorn&lt;/code&gt;ï¼Œç„¶åè¿è¡Œä»“åº“ä¸­çš„ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/api.py&#34;&gt;api.py&lt;/a&gt;ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python api.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;é»˜è®¤éƒ¨ç½²åœ¨æœ¬åœ°çš„ 8000 ç«¯å£ï¼Œé€šè¿‡ POST æ–¹æ³•è¿›è¡Œè°ƒç”¨&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -X POST &#34;http://127.0.0.1:8000&#34; \&#xA;     -H &#39;Content-Type: application/json&#39; \&#xA;     -d &#39;{&#34;prompt&#34;: &#34;ä½ å¥½&#34;, &#34;history&#34;: []}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å¾—åˆ°çš„è¿”å›å€¼ä¸º&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;{&#xA;  &#34;response&#34;:&#34;ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚&#34;,&#xA;  &#34;history&#34;:[[&#34;ä½ å¥½&#34;,&#34;ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚&#34;]],&#xA;  &#34;status&#34;:200,&#xA;  &#34;time&#34;:&#34;2023-03-23 21:38:40&#34;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æ„Ÿè°¢ &lt;a href=&#34;&#34;&gt;@hiyouga&lt;/a&gt; å®ç°äº† OpenAI æ ¼å¼çš„æµå¼ API éƒ¨ç½²ï¼Œå¯ä»¥ä½œä¸ºä»»æ„åŸºäº ChatGPT çš„åº”ç”¨çš„åç«¯ï¼Œæ¯”å¦‚ &lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web&#34;&gt;ChatGPT-Next-Web&lt;/a&gt;ã€‚å¯ä»¥é€šè¿‡è¿è¡Œä»“åº“ä¸­çš„&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/openai_api.py&#34;&gt;openai_api.py&lt;/a&gt; è¿›è¡Œéƒ¨ç½²ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python openai_api.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;è¿›è¡Œ API è°ƒç”¨çš„ç¤ºä¾‹ä»£ç ä¸º&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import openai&#xA;if __name__ == &#34;__main__&#34;:&#xA;    openai.api_base = &#34;http://localhost:8000/v1&#34;&#xA;    openai.api_key = &#34;none&#34;&#xA;    for chunk in openai.ChatCompletion.create(&#xA;        model=&#34;chatglm2-6b&#34;,&#xA;        messages=[&#xA;            {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;ä½ å¥½&#34;}&#xA;        ],&#xA;        stream=True&#xA;    ):&#xA;        if hasattr(chunk.choices[0].delta, &#34;content&#34;):&#xA;            print(chunk.choices[0].delta.content, end=&#34;&#34;, flush=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ä½æˆæœ¬éƒ¨ç½²&lt;/h2&gt; &#xA;&lt;h3&gt;æ¨¡å‹é‡åŒ–&lt;/h3&gt; &#xA;&lt;p&gt;é»˜è®¤æƒ…å†µä¸‹ï¼Œæ¨¡å‹ä»¥ FP16 ç²¾åº¦åŠ è½½ï¼Œè¿è¡Œä¸Šè¿°ä»£ç éœ€è¦å¤§æ¦‚ 13GB æ˜¾å­˜ã€‚å¦‚æœä½ çš„ GPU æ˜¾å­˜æœ‰é™ï¼Œå¯ä»¥å°è¯•ä»¥é‡åŒ–æ–¹å¼åŠ è½½æ¨¡å‹ï¼Œä½¿ç”¨æ–¹æ³•å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# æŒ‰éœ€ä¿®æ”¹ï¼Œç›®å‰åªæ”¯æŒ 4/8 bit é‡åŒ–&#xA;model = AutoModel.from_pretrained(&#34;THUDM/chatglm2-6b&#34;, trust_remote_code=True).quantize(8).cuda()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æ¨¡å‹é‡åŒ–ä¼šå¸¦æ¥ä¸€å®šçš„æ€§èƒ½æŸå¤±ï¼Œç»è¿‡æµ‹è¯•ï¼ŒChatGLM2-6B åœ¨ 4-bit é‡åŒ–ä¸‹ä»ç„¶èƒ½å¤Ÿè¿›è¡Œè‡ªç„¶æµç•…çš„ç”Ÿæˆã€‚&lt;/p&gt; &#xA;&lt;p&gt;å¦‚æœä½ çš„å†…å­˜ä¸è¶³ï¼Œå¯ä»¥ç›´æ¥åŠ è½½é‡åŒ–åçš„æ¨¡å‹ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModel.from_pretrained(&#34;THUDM/chatglm2-6b-int4&#34;,trust_remote_code=True).cuda()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- é‡åŒ–æ¨¡å‹çš„å‚æ•°æ–‡ä»¶ä¹Ÿå¯ä»¥ä»[è¿™é‡Œ](https://cloud.tsinghua.edu.cn/d/674208019e314311ab5c/)æ‰‹åŠ¨ä¸‹è½½ã€‚ --&gt; &#xA;&lt;h3&gt;CPU éƒ¨ç½²&lt;/h3&gt; &#xA;&lt;p&gt;å¦‚æœä½ æ²¡æœ‰ GPU ç¡¬ä»¶çš„è¯ï¼Œä¹Ÿå¯ä»¥åœ¨ CPU ä¸Šè¿›è¡Œæ¨ç†ï¼Œä½†æ˜¯æ¨ç†é€Ÿåº¦ä¼šæ›´æ…¢ã€‚ä½¿ç”¨æ–¹æ³•å¦‚ä¸‹ï¼ˆéœ€è¦å¤§æ¦‚ 32GB å†…å­˜ï¼‰&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModel.from_pretrained(&#34;THUDM/chatglm2-6b&#34;, trust_remote_code=True).float()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å¦‚æœä½ çš„å†…å­˜ä¸è¶³çš„è¯ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨é‡åŒ–åçš„æ¨¡å‹&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModel.from_pretrained(&#34;THUDM/chatglm2-6b-int4&#34;,trust_remote_code=True).float()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;åœ¨ cpu ä¸Šè¿è¡Œé‡åŒ–åçš„æ¨¡å‹éœ€è¦å®‰è£… &lt;code&gt;gcc&lt;/code&gt; ä¸ &lt;code&gt;openmp&lt;/code&gt;ã€‚å¤šæ•° Linux å‘è¡Œç‰ˆé»˜è®¤å·²å®‰è£…ã€‚å¯¹äº Windows ï¼Œå¯åœ¨å®‰è£… &lt;a href=&#34;https://jmeubank.github.io/tdm-gcc/&#34;&gt;TDM-GCC&lt;/a&gt; æ—¶å‹¾é€‰ &lt;code&gt;openmp&lt;/code&gt;ã€‚ Windows æµ‹è¯•ç¯å¢ƒ &lt;code&gt;gcc&lt;/code&gt; ç‰ˆæœ¬ä¸º &lt;code&gt;TDM-GCC 10.3.0&lt;/code&gt;ï¼Œ Linux ä¸º &lt;code&gt;gcc 11.3.0&lt;/code&gt;ã€‚åœ¨ MacOS ä¸Šè¯·å‚è€ƒ &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/FAQ.md#q1&#34;&gt;Q1&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;Mac éƒ¨ç½²&lt;/h3&gt; &#xA;&lt;p&gt;å¯¹äºæ­è½½äº† Apple Silicon æˆ–è€… AMD GPU çš„ Macï¼Œå¯ä»¥ä½¿ç”¨ MPS åç«¯æ¥åœ¨ GPU ä¸Šè¿è¡Œ ChatGLM2-6Bã€‚éœ€è¦å‚è€ƒ Apple çš„ &lt;a href=&#34;https://developer.apple.com/metal/pytorch&#34;&gt;å®˜æ–¹è¯´æ˜&lt;/a&gt; å®‰è£… PyTorch-Nightlyï¼ˆæ­£ç¡®çš„ç‰ˆæœ¬å·åº”è¯¥æ˜¯2.x.x.dev2023xxxxï¼Œè€Œä¸æ˜¯ 2.x.xï¼‰ã€‚&lt;/p&gt; &#xA;&lt;p&gt;ç›®å‰åœ¨ MacOS ä¸Šåªæ”¯æŒ&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/README.md#%E4%BB%8E%E6%9C%AC%E5%9C%B0%E5%8A%A0%E8%BD%BD%E6%A8%A1%E5%9E%8B&#34;&gt;ä»æœ¬åœ°åŠ è½½æ¨¡å‹&lt;/a&gt;ã€‚å°†ä»£ç ä¸­çš„æ¨¡å‹åŠ è½½æ”¹ä¸ºä»æœ¬åœ°åŠ è½½ï¼Œå¹¶ä½¿ç”¨ mps åç«¯ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModel.from_pretrained(&#34;your local path&#34;, trust_remote_code=True).to(&#39;mps&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;åŠ è½½åŠç²¾åº¦çš„ ChatGLM2-6B æ¨¡å‹éœ€è¦å¤§æ¦‚ 13GB å†…å­˜ã€‚å†…å­˜è¾ƒå°çš„æœºå™¨ï¼ˆæ¯”å¦‚ 16GB å†…å­˜çš„ MacBook Proï¼‰ï¼Œåœ¨ç©ºä½™å†…å­˜ä¸è¶³çš„æƒ…å†µä¸‹ä¼šä½¿ç”¨ç¡¬ç›˜ä¸Šçš„è™šæ‹Ÿå†…å­˜ï¼Œå¯¼è‡´æ¨ç†é€Ÿåº¦ä¸¥é‡å˜æ…¢ã€‚ æ­¤æ—¶å¯ä»¥ä½¿ç”¨é‡åŒ–åçš„æ¨¡å‹ chatglm2-6b-int4ã€‚å› ä¸º GPU ä¸Šé‡åŒ–çš„ kernel æ˜¯ä½¿ç”¨ CUDA ç¼–å†™çš„ï¼Œå› æ­¤æ— æ³•åœ¨ MacOS ä¸Šä½¿ç”¨ï¼Œåªèƒ½ä½¿ç”¨ CPU è¿›è¡Œæ¨ç†ã€‚ ä¸ºäº†å……åˆ†ä½¿ç”¨ CPU å¹¶è¡Œï¼Œè¿˜éœ€è¦&lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/FAQ.md#q1&#34;&gt;å•ç‹¬å®‰è£… OpenMP&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h3&gt;å¤šå¡éƒ¨ç½²&lt;/h3&gt; &#xA;&lt;p&gt;å¦‚æœä½ æœ‰å¤šå¼  GPUï¼Œä½†æ˜¯æ¯å¼  GPU çš„æ˜¾å­˜å¤§å°éƒ½ä¸è¶³ä»¥å®¹çº³å®Œæ•´çš„æ¨¡å‹ï¼Œé‚£ä¹ˆå¯ä»¥å°†æ¨¡å‹åˆ‡åˆ†åœ¨å¤šå¼ GPUä¸Šã€‚é¦–å…ˆå®‰è£… accelerate: &lt;code&gt;pip install accelerate&lt;/code&gt;ï¼Œç„¶åé€šè¿‡å¦‚ä¸‹æ–¹æ³•åŠ è½½æ¨¡å‹ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from utils import load_model_on_gpus&#xA;model = load_model_on_gpus(&#34;THUDM/chatglm2-6b&#34;, num_gpus=2)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å³å¯å°†æ¨¡å‹éƒ¨ç½²åˆ°ä¸¤å¼  GPU ä¸Šè¿›è¡Œæ¨ç†ã€‚ä½ å¯ä»¥å°† &lt;code&gt;num_gpus&lt;/code&gt; æ”¹ä¸ºä½ å¸Œæœ›ä½¿ç”¨çš„ GPU æ•°ã€‚é»˜è®¤æ˜¯å‡åŒ€åˆ‡åˆ†çš„ï¼Œä½ ä¹Ÿå¯ä»¥ä¼ å…¥ &lt;code&gt;device_map&lt;/code&gt; å‚æ•°æ¥è‡ªå·±æŒ‡å®šã€‚&lt;/p&gt; &#xA;&lt;h2&gt;åè®®&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬ä»“åº“çš„ä»£ç ä¾ç…§ &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache-2.0&lt;/a&gt; åè®®å¼€æºï¼ŒChatGLM2-6B æ¨¡å‹çš„æƒé‡çš„ä½¿ç”¨åˆ™éœ€è¦éµå¾ª &lt;a href=&#34;https://raw.githubusercontent.com/THUDM/ChatGLM2-6B/main/MODEL_LICENSE&#34;&gt;Model License&lt;/a&gt;ã€‚ChatGLM2-6B æƒé‡å¯¹å­¦æœ¯ç ”ç©¶&lt;strong&gt;å®Œå…¨å¼€æ”¾&lt;/strong&gt;ï¼Œåœ¨è·å¾—å®˜æ–¹çš„ä¹¦é¢è®¸å¯åï¼Œäº¦&lt;strong&gt;å…è®¸å•†ä¸šä½¿ç”¨&lt;/strong&gt;ã€‚å¦‚æœæ‚¨å‘ç°æˆ‘ä»¬çš„å¼€æºæ¨¡å‹å¯¹æ‚¨çš„ä¸šåŠ¡æœ‰ç”¨ï¼Œæˆ‘ä»¬æ¬¢è¿æ‚¨å¯¹ä¸‹ä¸€ä»£æ¨¡å‹ ChatGLM3 ç ”å‘çš„æèµ ã€‚ç”³è¯·å•†ç”¨è®¸å¯ä¸æèµ è¯·è”ç³» &lt;a href=&#34;mailto:yiwen.xu@zhipuai.cn&#34;&gt;yiwen.xu@zhipuai.cn&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;å¼•ç”¨&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œæœ‰å¸®åŠ©çš„è¯ï¼Œè¯·è€ƒè™‘å¼•ç”¨ä¸‹åˆ—è®ºæ–‡ï¼ŒChatGLM2-6B çš„è®ºæ–‡ä¼šåœ¨è¿‘æœŸå…¬å¸ƒï¼Œæ•¬è¯·æœŸå¾…ï½&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{zeng2022glm,&#xA;  title={Glm-130b: An open bilingual pre-trained model},&#xA;  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},&#xA;  journal={arXiv preprint arXiv:2210.02414},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{du2022glm,&#xA;  title={GLM: General Language Model Pretraining with Autoregressive Blank Infilling},&#xA;  author={Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},&#xA;  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},&#xA;  pages={320--335},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>