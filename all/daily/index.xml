<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-13T01:32:04Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ange-yaghi/engine-sim</title>
    <updated>2022-08-13T01:32:04Z</updated>
    <id>tag:github.com,2022-08-13:/ange-yaghi/engine-sim</id>
    <link href="https://github.com/ange-yaghi/engine-sim" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Combustion engine simulator that generates realistic audio.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Engine Simulator&lt;/h1&gt; &#xA;&lt;h2&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ange-yaghi/engine-sim/master/docs/public/screenshot_v01.png?raw=true&#34; alt=&#34;Alt text&#34;&gt;&lt;/h2&gt; &#xA;&lt;h2&gt;&lt;strong&gt;Warning: code is in development and will change frequently&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;What is this?&lt;/h2&gt; &#xA;&lt;p&gt;This is a real-time internal combustion engine simulation &lt;strong&gt;designed specifically to produce engine audio and simulate engine response characteristics.&lt;/strong&gt; It is NOT a scientific tool and cannot be expected to provide accurate figures for the purposes of engineering or engine tuning.&lt;/p&gt; &#xA;&lt;h2&gt;Why is the code so sloppy?&lt;/h2&gt; &#xA;&lt;p&gt;I wrote this to demo in a &lt;a href=&#34;https://youtu.be/RKT-sKtR970&#34;&gt;YouTube video&lt;/a&gt;, not as a real product. If you would like it to become a usable product please reach out to me or join my Discord (link can be found in the description of the aforementioned YouTube video). I use this codebase for my own purposes and so it might change frequently and without warning.&lt;/p&gt; &#xA;&lt;h2&gt;How do I use it?&lt;/h2&gt; &#xA;&lt;p&gt;The UI is extremely minimalistic and there are only a few controls used to interact with the engine:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Key/Input&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Action&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;A&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Toggle ignition&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;S&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Hold for starter&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;D&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Enable dyno&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;F&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Enter fullscreen mode&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Shift&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Clutch (hold spacebar to slowly engage/disengage)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Up Arrow&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Up Gear&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Down Arrow&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Down Gear&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Z + Scroll&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Volume&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X + Scroll&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Convolution Level&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;C + Scroll&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;High freq gain&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;V + Scroll&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Low freq noise&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;B + Scroll&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;High freq noise&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;N + Scroll&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Simulation freq&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;M&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Increase View Layer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;,&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Decrease View Layer&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Escape&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Exit the program&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Q, W, E, R&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Change throttle position&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1, 2, 3, 4, 5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Simulation time warp&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Tab&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Change screen&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;How do I build it?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note: this project currently only builds on Windows!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Step 1 - Clone the repository&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;git clone --recurse-submodules https://github.com/ange-yaghi/engine-sim&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Step 2 - Install CMake&lt;/h3&gt; &#xA;&lt;p&gt;Install the latest version of CMake &lt;a href=&#34;https://cmake.org/&#34;&gt;here&lt;/a&gt; if it&#39;s not already installed.&lt;/p&gt; &#xA;&lt;h3&gt;Step 3 - Install Dependencies&lt;/h3&gt; &#xA;&lt;p&gt;You will need to install the following dependencies and CMake will need to be able to locate them (ie. they need to be listed on your PATH):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;1. SDL2&#xA;2. SDL2_image&#xA;3. Boost (make sure to build the optional dependencies)&#xA;4. Flex and Bison&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 4 - Build and Run&lt;/h3&gt; &#xA;&lt;p&gt;From the root directory of the project, run the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir build&#xA;cd build&#xA;cmake ..&#xA;cmake --build .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If these steps are successful, a Visual Studio solution will be generated in &lt;code&gt;build&lt;/code&gt;. You can open this project with Visual Studio and then run the &lt;code&gt;engine-sim-app&lt;/code&gt; project. If you encounter an error telling you that you&#39;re missing DLLs, you will have to copy those DLLs to your EXE&#39;s directory.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Tencent/ncnn</title>
    <updated>2022-08-13T01:32:04Z</updated>
    <id>tag:github.com,2022-08-13:/Tencent/ncnn</id>
    <link href="https://github.com/Tencent/ncnn" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ncnn is a high-performance neural network inference framework optimized for the mobile platform&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Tencent/ncnn/master/images/256-ncnn.png&#34; alt=&#34;NCNN&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;ncnn&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Tencent/ncnn/master/LICENSE.txt&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-BSD--3--Clause-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Tencent/ncnn/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/downloads/Tencent/ncnn/total.svg?sanitize=true&#34; alt=&#34;Download Total Count&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/Tencent/ncnn&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/Tencent/ncnn/branch/master/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://lgtm.com/projects/g/Tencent/ncnn/context:cpp&#34;&gt;&lt;img src=&#34;https://img.shields.io/lgtm/grade/cpp/g/Tencent/ncnn.svg?logo=lgtm&amp;amp;logoWidth=18&#34; alt=&#34;Language grade: C/C++&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;ncnn is a high-performance neural network inference computing framework optimized for mobile platforms. ncnn is deeply considerate about deployment and uses on mobile phones from the beginning of design. ncnn does not have third party dependencies. It is cross-platform, and runs faster than all known open source frameworks on mobile phone cpu. Developers can easily deploy deep learning algorithm models to the mobile platform by using efficient ncnn implementation, create intelligent APPs, and bring the artificial intelligence to your fingertips. ncnn is currently being used in many Tencent applications, such as QQ, Qzone, WeChat, Pitu and so on.&lt;/p&gt; &#xA;&lt;p&gt;ncnn æ˜¯ä¸€ä¸ªä¸ºæ‰‹æœºç«¯æè‡´ä¼˜åŒ–çš„é«˜æ€§èƒ½ç¥ç»ç½‘ç»œå‰å‘è®¡ç®—æ¡†æ¶ã€‚ ncnn ä»è®¾è®¡ä¹‹åˆæ·±åˆ»è€ƒè™‘æ‰‹æœºç«¯çš„éƒ¨ç½²å’Œä½¿ç”¨ã€‚ æ— ç¬¬ä¸‰æ–¹ä¾èµ–ï¼Œè·¨å¹³å°ï¼Œæ‰‹æœºç«¯ cpu çš„é€Ÿåº¦å¿«äºç›®å‰æ‰€æœ‰å·²çŸ¥çš„å¼€æºæ¡†æ¶ã€‚ åŸºäº ncnnï¼Œå¼€å‘è€…èƒ½å¤Ÿå°†æ·±åº¦å­¦ä¹ ç®—æ³•è½»æ¾ç§»æ¤åˆ°æ‰‹æœºç«¯é«˜æ•ˆæ‰§è¡Œï¼Œ å¼€å‘å‡ºäººå·¥æ™ºèƒ½ APPï¼Œå°† AI å¸¦åˆ°ä½ çš„æŒ‡å°–ã€‚ ncnn ç›®å‰å·²åœ¨è…¾è®¯å¤šæ¬¾åº”ç”¨ä¸­ä½¿ç”¨ï¼Œå¦‚ï¼šQQï¼ŒQzoneï¼Œå¾®ä¿¡ï¼Œå¤©å¤© P å›¾ç­‰ã€‚&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;æŠ€æœ¯äº¤æµ QQ ç¾¤ï¼š637093648 (è¶…å¤šå¤§ä½¬) ç­”æ¡ˆï¼šå·å·å·å·å· ï¼ˆå·²æ»¡ï¼‰&lt;/h2&gt; &#xA;&lt;h2&gt;Pocky QQ ç¾¤ï¼ˆMLIR YES!ï¼‰: 677104663(è¶…å¤šå¤§ä½¬) ç­”æ¡ˆï¼šmulti-level intermediate representation&lt;/h2&gt; &#xA;&lt;h2&gt;Telegram Group &lt;a href=&#34;https://t.me/ncnnyes&#34;&gt;https://t.me/ncnnyes&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h2&gt;Discord Channel &lt;a href=&#34;https://discord.gg/YRsxgmF&#34;&gt;https://discord.gg/YRsxgmF&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Current building status matrix&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;System&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;CPU (32bit]&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;CPU (64bit)&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;GPU (32bit)&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;GPU (64bit)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Linux (GCC)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-x86-cpu-gcc&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/linux-x86-cpu-gcc&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-x64-cpu-gcc&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/linux-x64-cpu-gcc&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-x64-gpu-gcc&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/linux-x64-gpu-gcc&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Linux (Clang)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-x86-cpu-clang&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/linux-x86-cpu-clang&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-x64-cpu-clang&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/linux-x64-cpu-clang&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-x64-gpu-clang&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/linux-x64-gpu-clang&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Linux (ARM)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-arm-cpu-gcc&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/linux-arm-cpu-gcc&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-aarch64-cpu-gcc&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/linux-aarch64-cpu-gcc&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Linux (MIPS)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-mips-cpu-gcc&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/linux-mips-cpu-gcc&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-mips64-cpu-gcc&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/linux-mips64-cpu-gcc&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Linux (RISC-V)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-riscv64-cpu-gcc&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/linux-riscv64-cpu-gcc&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Linux (LoongArch)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-loongarch64-cpu-gcc&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/linux-loongarch64-cpu-gcc&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Windows&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Awindows-x86-cpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/windows-x86-cpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Awindows-x64-cpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/windows-x64-cpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Awindows-x64-gpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/windows-x64-gpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Windows (ARM)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Awindows-arm-cpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/windows-arm-cpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Awindows-arm64-cpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/windows-arm64-cpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;macOS&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Amacos-x64-cpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/macos-x64-cpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Amacos-x64-gpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/macos-x64-gpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;macOS (ARM)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Amacos-arm64-cpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/macos-arm64-cpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Amacos-arm64-gpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/macos-arm64-gpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Android&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aandroid-armv7-cpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/android-armv7-cpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aandroid-armv8-cpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/android-armv8-cpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aandroid-armv7-gpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/android-armv7-gpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aandroid-armv8-gpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/android-armv8-gpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Android-x86&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aandroid-x86-cpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/android-x86-cpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aandroid-x64-cpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/android-x64-cpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aandroid-x86-gpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/android-x86-gpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aandroid-x64-gpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/android-x64-gpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;iOS&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aios-cpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/ios-cpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aios-cpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/ios-cpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aios-arm64-gpu&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/ios-arm64-gpu&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;iOS Simulator&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aios-simulator&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/ios-simulator&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aios-simulator&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/ios-simulator&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;WebAssembly&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aweb-assembly&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/web-assembly&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;RISC-V GCC/Newlib&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aelf-riscv32-cpu-gcc&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/elf-riscv32-cpu-gcc&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/actions?query=workflow%3Aelf-riscv64-cpu-gcc&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/workflow/status/Tencent/ncnn/elf-riscv64-cpu-gcc&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;â€”&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Support most commonly used CNN network&lt;/h2&gt; &#xA;&lt;h2&gt;æ”¯æŒå¤§éƒ¨åˆ†å¸¸ç”¨çš„ CNN ç½‘ç»œ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Classical CNN: &lt;a href=&#34;https://github.com/BVLC/caffe/wiki/Model-Zoo#models-used-by-the-vgg-team-in-ilsvrc-2014&#34;&gt;VGG&lt;/a&gt; &lt;a href=&#34;https://github.com/BVLC/caffe/tree/9b891540183ddc834a02b2bd81b31afae71b2153/models/bvlc_alexnet&#34;&gt;AlexNet&lt;/a&gt; &lt;a href=&#34;https://github.com/BVLC/caffe/tree/9b891540183ddc834a02b2bd81b31afae71b2153/models/bvlc_googlenet&#34;&gt;GoogleNet&lt;/a&gt; Inception ...&lt;/li&gt; &#xA; &lt;li&gt;Practical CNN: &lt;a href=&#34;https://github.com/tornadomeet/ResNet&#34;&gt;ResNet&lt;/a&gt; &lt;a href=&#34;https://github.com/liuzhuang13/DenseNet&#34;&gt;DenseNet&lt;/a&gt; &lt;a href=&#34;https://github.com/hujie-frank/SENet&#34;&gt;SENet&lt;/a&gt; &lt;a href=&#34;https://github.com/unsky/FPN&#34;&gt;FPN&lt;/a&gt; ...&lt;/li&gt; &#xA; &lt;li&gt;Light-weight CNN: &lt;a href=&#34;https://github.com/forresti/SqueezeNet&#34;&gt;SqueezeNet&lt;/a&gt; &lt;a href=&#34;https://github.com/tensorflow/models/raw/master/research/slim/nets/mobilenet_v1.md&#34;&gt;MobileNetV1&lt;/a&gt; &lt;a href=&#34;https://github.com/tensorflow/models/raw/master/research/slim/nets/mobilenet/README.md&#34;&gt;MobileNetV2/V3&lt;/a&gt; &lt;a href=&#34;https://github.com/farmingyard/ShuffleNet&#34;&gt;ShuffleNetV1&lt;/a&gt; &lt;a href=&#34;https://github.com/opconty/keras-shufflenetV2&#34;&gt;ShuffleNetV2&lt;/a&gt; &lt;a href=&#34;https://github.com/tensorflow/models/tree/master/research/slim/nets/nasnet&#34;&gt;MNasNet&lt;/a&gt; ...&lt;/li&gt; &#xA; &lt;li&gt;Face Detection: &lt;a href=&#34;https://github.com/ipazc/mtcnn&#34;&gt;MTCNN&lt;/a&gt; &lt;a href=&#34;https://github.com/biubug6/Pytorch_Retinaface&#34;&gt;RetinaFace&lt;/a&gt; &lt;a href=&#34;https://github.com/nihui/ncnn-android-scrfd&#34;&gt;scrfd&lt;/a&gt; ...&lt;/li&gt; &#xA; &lt;li&gt;Detection: &lt;a href=&#34;https://github.com/lzx1413/CAFFE_SSD&#34;&gt;VGG-SSD&lt;/a&gt; &lt;a href=&#34;https://github.com/chuanqi305/MobileNet-SSD&#34;&gt;MobileNet-SSD&lt;/a&gt; &lt;a href=&#34;https://github.com/chuanqi305/SqueezeNet-SSD&#34;&gt;SqueezeNet-SSD&lt;/a&gt; &lt;a href=&#34;https://github.com/chuanqi305/MobileNetv2-SSDLite&#34;&gt;MobileNetV2-SSDLite&lt;/a&gt; &lt;a href=&#34;https://github.com/XiaoyuHuang96/MobilenetV3SSDLite-tfkeras&#34;&gt;MobileNetV3-SSDLite&lt;/a&gt; ...&lt;/li&gt; &#xA; &lt;li&gt;Detection: &lt;a href=&#34;https://github.com/rbgirshick/py-faster-rcnn&#34;&gt;Faster-RCNN&lt;/a&gt; &lt;a href=&#34;https://github.com/daijifeng001/R-FCN&#34;&gt;R-FCN&lt;/a&gt; ...&lt;/li&gt; &#xA; &lt;li&gt;Detection: &lt;a href=&#34;https://github.com/longcw/yolo2-pytorch&#34;&gt;YOLOv2&lt;/a&gt; &lt;a href=&#34;https://github.com/ultralytics/yolov3&#34;&gt;YOLOv3&lt;/a&gt; &lt;a href=&#34;https://github.com/eric612/MobileNet-YOLO&#34;&gt;MobileNet-YOLOv3&lt;/a&gt; &lt;a href=&#34;https://github.com/Tianxiaomo/pytorch-YOLOv4&#34;&gt;YOLOv4&lt;/a&gt; &lt;a href=&#34;https://github.com/ultralytics/yolov5&#34;&gt;YOLOv5&lt;/a&gt; &lt;a href=&#34;https://github.com/WongKinYiu/yolov7&#34;&gt;YOLOv7&lt;/a&gt; &lt;a href=&#34;https://github.com/Megvii-BaseDetection/YOLOX&#34;&gt;YOLOX&lt;/a&gt; ...&lt;/li&gt; &#xA; &lt;li&gt;Detection: &lt;a href=&#34;https://github.com/RangiLyu/nanodet&#34;&gt;NanoDet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Segmentation: &lt;a href=&#34;https://github.com/unsky/FPN&#34;&gt;FCN&lt;/a&gt; &lt;a href=&#34;https://github.com/hszhao/PSPNet&#34;&gt;PSPNet&lt;/a&gt; &lt;a href=&#34;https://github.com/zhixuhao/unet&#34;&gt;UNet&lt;/a&gt; &lt;a href=&#34;https://github.com/dbolya/yolact&#34;&gt;YOLACT&lt;/a&gt; ...&lt;/li&gt; &#xA; &lt;li&gt;Pose Estimation: &lt;a href=&#34;https://github.com/dog-qiuqiu/Ultralight-SimplePose&#34;&gt;SimplePose&lt;/a&gt; ...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;HowTo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/how-to-build&#34;&gt;how to build ncnn library&lt;/a&gt; on Linux / Windows / macOS / Raspberry Pi3 / Android / NVIDIA Jetson / iOS / WebAssembly / AllWinner D1 / Loongson 2K1000&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/how-to-build#pass-for-linux&#34;&gt;Build for Linux / NVIDIA Jetson / Raspberry Pi 3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/how-to-build#pass-for-windows-x64-using-visual-studio-community-2017&#34;&gt;Build for Windows x64 using VS2017&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/how-to-build#pass-for-macos&#34;&gt;Build for macOS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/how-to-build#pass-for-arm-cortex-a-family-with-cross-compiling&#34;&gt;Build for ARM Cortex-A family with cross-compiling&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/how-to-build#pass-for-hisilicon-platform-with-cross-compiling&#34;&gt;Build for Hisilicon platform with cross-compiling&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/how-to-build#pass-for-android&#34;&gt;Build for Android&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/how-to-build#pass-for-ios-on-macos-with-xcode&#34;&gt;Build for iOS on macOS with xcode&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/how-to-build#pass-for-webassembly&#34;&gt;Build for WebAssembly&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/how-to-build#pass-for-allwinner-d1&#34;&gt;Build for AllWinner D1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/how-to-build#pass-for-loongson-2k1000&#34;&gt;Build for Loongson 2K1000&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/how-to-build#pass-for-termux-on-android&#34;&gt;Build for Termux on Android&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/releases&#34;&gt;download prebuild binary package for android and ios&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/use-ncnn-with-alexnet&#34;&gt;use ncnn with alexnet&lt;/a&gt; with detailed steps, recommended for beginners :)&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/use-ncnn-with-alexnet.zh&#34;&gt;ncnn ç»„ä»¶ä½¿ç”¨æŒ‡åŒ— alexnet&lt;/a&gt; é™„å¸¦è¯¦ç»†æ­¥éª¤ï¼Œæ–°äººå¼ºçƒˆæ¨è :)&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://netron.app&#34;&gt;use netron for ncnn model visualization&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://convertmodel.com/#outputFormat=ncnn&#34;&gt;out-of-the-box web model conversion&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/low-level-operation-api&#34;&gt;ncnn low-level operation api&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/param-and-model-file-structure&#34;&gt;ncnn param and model file spec&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/operation-param-weight-table&#34;&gt;ncnn operation param weight table&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/how-to-implement-custom-layer-step-by-step&#34;&gt;how to implement custom layer step by step&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/FAQ-ncnn-throw-error&#34;&gt;ncnn throw error&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/FAQ-ncnn-produce-wrong-result&#34;&gt;ncnn produce wrong result&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/Tencent/ncnn/wiki/FAQ-ncnn-vulkan&#34;&gt;ncnn vulkan&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Supports convolutional neural networks, supports multiple input and multi-branch structure, can calculate part of the branch&lt;/li&gt; &#xA; &lt;li&gt;No third-party library dependencies, does not rely on BLAS / NNPACK or any other computing framework&lt;/li&gt; &#xA; &lt;li&gt;Pure C++ implementation, cross-platform, supports Android, iOS and so on&lt;/li&gt; &#xA; &lt;li&gt;ARM NEON assembly level of careful optimization, calculation speed is extremely high&lt;/li&gt; &#xA; &lt;li&gt;Sophisticated memory management and data structure design, very low memory footprint&lt;/li&gt; &#xA; &lt;li&gt;Supports multi-core parallel computing acceleration, ARM big.LITTLE CPU scheduling optimization&lt;/li&gt; &#xA; &lt;li&gt;Supports GPU acceleration via the next-generation low-overhead Vulkan API&lt;/li&gt; &#xA; &lt;li&gt;Extensible model design, supports 8bit quantization and half-precision floating point storage, can import caffe/pytorch/mxnet/onnx/darknet/keras/tensorflow(mlir) models&lt;/li&gt; &#xA; &lt;li&gt;Support direct memory zero copy reference load network model&lt;/li&gt; &#xA; &lt;li&gt;Can be registered with custom layer implementation and extended&lt;/li&gt; &#xA; &lt;li&gt;Well, it is strong, not afraid of being stuffed with å· QvQ&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;åŠŸèƒ½æ¦‚è¿°&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æ”¯æŒå·ç§¯ç¥ç»ç½‘ç»œï¼Œæ”¯æŒå¤šè¾“å…¥å’Œå¤šåˆ†æ”¯ç»“æ„ï¼Œå¯è®¡ç®—éƒ¨åˆ†åˆ†æ”¯&lt;/li&gt; &#xA; &lt;li&gt;æ— ä»»ä½•ç¬¬ä¸‰æ–¹åº“ä¾èµ–ï¼Œä¸ä¾èµ– BLAS/NNPACK ç­‰è®¡ç®—æ¡†æ¶&lt;/li&gt; &#xA; &lt;li&gt;çº¯ C++ å®ç°ï¼Œè·¨å¹³å°ï¼Œæ”¯æŒ Android / iOS ç­‰&lt;/li&gt; &#xA; &lt;li&gt;ARM Neon æ±‡ç¼–çº§è‰¯å¿ƒä¼˜åŒ–ï¼Œè®¡ç®—é€Ÿåº¦æå¿«&lt;/li&gt; &#xA; &lt;li&gt;ç²¾ç»†çš„å†…å­˜ç®¡ç†å’Œæ•°æ®ç»“æ„è®¾è®¡ï¼Œå†…å­˜å ç”¨æä½&lt;/li&gt; &#xA; &lt;li&gt;æ”¯æŒå¤šæ ¸å¹¶è¡Œè®¡ç®—åŠ é€Ÿï¼ŒARM big.LITTLE CPU è°ƒåº¦ä¼˜åŒ–&lt;/li&gt; &#xA; &lt;li&gt;æ”¯æŒåŸºäºå…¨æ–°ä½æ¶ˆè€—çš„ Vulkan API GPU åŠ é€Ÿ&lt;/li&gt; &#xA; &lt;li&gt;å¯æ‰©å±•çš„æ¨¡å‹è®¾è®¡ï¼Œæ”¯æŒ 8bit &lt;a href=&#34;https://raw.githubusercontent.com/Tencent/ncnn/master/tools/quantize&#34;&gt;é‡åŒ–&lt;/a&gt; å’ŒåŠç²¾åº¦æµ®ç‚¹å­˜å‚¨ï¼Œå¯å¯¼å…¥ caffe/pytorch/mxnet/onnx/darknet/keras/tensorflow(mlir) æ¨¡å‹&lt;/li&gt; &#xA; &lt;li&gt;æ”¯æŒç›´æ¥å†…å­˜é›¶æ‹·è´å¼•ç”¨åŠ è½½ç½‘ç»œæ¨¡å‹&lt;/li&gt; &#xA; &lt;li&gt;å¯æ³¨å†Œè‡ªå®šä¹‰å±‚å®ç°å¹¶æ‰©å±•&lt;/li&gt; &#xA; &lt;li&gt;æ©ï¼Œå¾ˆå¼ºå°±æ˜¯äº†ï¼Œä¸æ€•è¢«å¡å· QvQ&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;supported platform matrix&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;âœ… = known work and runs fast with good optimization&lt;/li&gt; &#xA; &lt;li&gt;âœ”ï¸ = known work, but speed may not be fast enough&lt;/li&gt; &#xA; &lt;li&gt;â” = shall work, not confirmed&lt;/li&gt; &#xA; &lt;li&gt;/ = not applied&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;Windows&lt;/th&gt; &#xA;   &lt;th&gt;Linux&lt;/th&gt; &#xA;   &lt;th&gt;Android&lt;/th&gt; &#xA;   &lt;th&gt;macOS&lt;/th&gt; &#xA;   &lt;th&gt;iOS&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;intel-cpu&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;â”&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;intel-gpu&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;â”&lt;/td&gt; &#xA;   &lt;td&gt;â”&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;amd-cpu&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;â”&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;amd-gpu&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;â”&lt;/td&gt; &#xA;   &lt;td&gt;â”&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;nvidia-gpu&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;â”&lt;/td&gt; &#xA;   &lt;td&gt;â”&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;qcom-cpu&lt;/td&gt; &#xA;   &lt;td&gt;â”&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;qcom-gpu&lt;/td&gt; &#xA;   &lt;td&gt;â”&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;arm-cpu&lt;/td&gt; &#xA;   &lt;td&gt;â”&lt;/td&gt; &#xA;   &lt;td&gt;â”&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;arm-gpu&lt;/td&gt; &#xA;   &lt;td&gt;â”&lt;/td&gt; &#xA;   &lt;td&gt;â”&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;apple-cpu&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;âœ…&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;apple-gpu&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;   &lt;td&gt;âœ”ï¸&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Example project&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nihui/ncnn-android-squeezenet&#34;&gt;https://github.com/nihui/ncnn-android-squeezenet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nihui/ncnn-android-styletransfer&#34;&gt;https://github.com/nihui/ncnn-android-styletransfer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nihui/ncnn-android-mobilenetssd&#34;&gt;https://github.com/nihui/ncnn-android-mobilenetssd&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/moli232777144/mtcnn_ncnn&#34;&gt;https://github.com/moli232777144/mtcnn_ncnn&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nihui/ncnn-android-yolov5&#34;&gt;https://github.com/nihui/ncnn-android-yolov5&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/xiang-wuu/ncnn-android-yolov7&#34;&gt;https://github.com/xiang-wuu/ncnn-android-yolov7&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nihui/ncnn-android-scrfd&#34;&gt;https://github.com/nihui/ncnn-android-scrfd&lt;/a&gt; ğŸ¤©&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/nihui/ncnn-assets/raw/master/20181217/ncnn-2.jpg&#34; width=&#34;360&#34; height=&#34;640&#34;&gt;&lt;img src=&#34;https://github.com/nihui/ncnn-assets/raw/master/20181217/4.jpg&#34; width=&#34;360&#34; height=&#34;640&#34;&gt; &lt;img src=&#34;https://github.com/nihui/ncnn-assets/raw/master/20181217/ncnn-33.jpg&#34; width=&#34;360&#34; height=&#34;640&#34;&gt;&lt;img src=&#34;https://github.com/nihui/ncnn-assets/raw/master/20181217/ncnn-m.png&#34; width=&#34;360&#34; height=&#34;640&#34;&gt; &lt;img src=&#34;https://github.com/nihui/ncnn-android-yolov5/raw/master/screenshot.jpg&#34; width=&#34;360&#34; height=&#34;800&#34;&gt;åŠŸèƒ½æ¦‚è¿°&lt;img src=&#34;https://github.com/nihui/ncnn-android-scrfd/raw/master/screenshot.jpg&#34; width=&#34;360&#34; height=&#34;800&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Tencent/ncnn/master/LICENSE.txt&#34;&gt;BSD 3 Clause&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>openvinotoolkit/openvino</title>
    <updated>2022-08-13T01:32:04Z</updated>
    <id>tag:github.com,2022-08-13:/openvinotoolkit/openvino</id>
    <link href="https://github.com/openvinotoolkit/openvino" rel="alternate"></link>
    <summary type="html">&lt;p&gt;OpenVINOâ„¢ Toolkit repository&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/docs/img/openvino-logo-purple-black.png&#34; width=&#34;400px&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/releases/tag/2022.1&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/version-2022.1-green.svg?sanitize=true&#34; alt=&#34;Stable release&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache_2.0-green.svg?sanitize=true&#34; alt=&#34;Apache License Version 2.0&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/checks-status/openvinotoolkit/openvino/master?label=GitHub%20checks&#34; alt=&#34;GitHub branch checks state&#34;&gt; &lt;img src=&#34;https://img.shields.io/azure-devops/build/openvinoci/b2bab62f-ab2f-4871-a538-86ea1be7d20f/13?label=Public%20CI&#34; alt=&#34;Azure DevOps builds (branch)&#34;&gt; &lt;a href=&#34;https://badge.fury.io/py/openvino&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/openvino.svg?sanitize=true&#34; alt=&#34;PyPI Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/openvino&#34;&gt;&lt;img src=&#34;https://pepy.tech/badge/openvino&#34; alt=&#34;PyPI Downloads&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Contents:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/#what-is-openvino-toolkit&#34;&gt;What is OpenVINO?&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/#components&#34;&gt;Components&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/#supported-hardware-matrix&#34;&gt;Supported Hardware matrix&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/#documentation&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/#tutorials&#34;&gt;Tutorials&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/#products-which-use-openvino&#34;&gt;Products which use OpenVINO&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/#system-requirements&#34;&gt;System requirements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/#how-to-build&#34;&gt;How to build&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/#how-to-contribute&#34;&gt;How to contribute&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/#get-a-support&#34;&gt;Get a support&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/#see-also&#34;&gt;See also&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What is OpenVINO toolkit?&lt;/h2&gt; &#xA;&lt;p&gt;OpenVINOâ„¢ is an open-source toolkit for optimizing and deploying AI inference.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Boost deep learning performance in computer vision, automatic speech recognition, natural language processing and other common tasks&lt;/li&gt; &#xA; &lt;li&gt;Use models trained with popular frameworks like TensorFlow, PyTorch and more&lt;/li&gt; &#xA; &lt;li&gt;Reduce resource demands and efficiently deploy on a range of IntelÂ® platforms from edge to cloud&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This open-source version includes several components: namely &lt;a href=&#34;https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html&#34;&gt;Model Optimizer&lt;/a&gt;, &lt;a href=&#34;https://docs.openvino.ai/latest/openvino_docs_OV_UG_OV_Runtime_User_Guide.html&#34;&gt;OpenVINOâ„¢ Runtime&lt;/a&gt;, &lt;a href=&#34;https://docs.openvino.ai/latest/pot_introduction.html&#34;&gt;Post-Training Optimization Tool&lt;/a&gt;, as well as CPU, GPU, MYRIAD, multi device and heterogeneous plugins to accelerate deep learning inferencing on IntelÂ® CPUs and IntelÂ® Processor Graphics. It supports pre-trained models from the &lt;a href=&#34;https://github.com/openvinotoolkit/open_model_zoo&#34;&gt;Open Model Zoo&lt;/a&gt;, along with 100+ open source and public models in popular formats such as TensorFlow, ONNX, PaddlePaddle, MXNet, Caffe, Kaldi.&lt;/p&gt; &#xA;&lt;h3&gt;Components&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.openvino.ai/latest/openvino_docs_OV_UG_OV_Runtime_User_Guide.html&#34;&gt;OpenVINOâ„¢ Runtime&lt;/a&gt; - is a set of C++ libraries with C and Python bindings providing a common API to deliver inference solutions on the platform of your choice. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/core&#34;&gt;core&lt;/a&gt; - provides the base API for model representation and modification.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/inference&#34;&gt;inference&lt;/a&gt; - provides an API to infer models on device.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/common/transformations&#34;&gt;transformations&lt;/a&gt; - contains the set of common transformations which are used in OpenVINO plugins.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/common/low_precision_transformations&#34;&gt;low precision transformations&lt;/a&gt; - contains the set of transformations which are used in low precision models&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/bindings&#34;&gt;bindings&lt;/a&gt; - contains all awailable OpenVINO bindings which are maintained by OpenVINO team. &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/bindings/c&#34;&gt;c&lt;/a&gt; - provides C API for OpenVINOâ„¢ Runtime&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/bindings/python&#34;&gt;python&lt;/a&gt; - Python API for OpenVINOâ„¢ Runtime&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/plugins&#34;&gt;Plugins&lt;/a&gt; - contains OpenVINO plugins which are maintained in open-source by OpenVINO team. For more information please taje a look to the &lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/#supported-hardware-matrix&#34;&gt;list of supported devices&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/frontends&#34;&gt;Frontends&lt;/a&gt; - contains available OpenVINO frontends which allow to read model from native framework format.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html&#34;&gt;Model Optimizer&lt;/a&gt; - is a cross-platform command-line tool that facilitates the transition between training and deployment environments, performs static model analysis, and adjusts deep learning models for optimal execution on end-point target devices.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.openvino.ai/latest/pot_introduction.html&#34;&gt;Post-Training Optimization Tool&lt;/a&gt; - is designed to accelerate the inference of deep learning models by applying special methods without model retraining or fine-tuning, for example, post-training 8-bit quantization.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/samples&#34;&gt;Samples&lt;/a&gt; - applications on C, C++ and Python languages which shows basic use cases of OpenVINO usages.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Supported Hardware matrix&lt;/h2&gt; &#xA;&lt;p&gt;The OpenVINOâ„¢ Runtime can infer models on different hardware devices. This section provides the list of supported devices.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Device&lt;/th&gt; &#xA;   &lt;th&gt;Plugin&lt;/th&gt; &#xA;   &lt;th&gt;Library&lt;/th&gt; &#xA;   &lt;th&gt;ShortDescription&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td rowspan=&#34;2&#34;&gt;CPU&lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://docs.openvino.ai/nightly/openvino_docs_OV_UG_supported_plugins_CPU.html#doxid-openvino-docs-o-v-u-g-supported-plugins-c-p-u&#34;&gt;Intel CPU&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td&gt;&lt;b&gt;&lt;i&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/plugins/intel_cpu&#34;&gt;openvino_intel_cpu_plugin&lt;/a&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Intel Xeon with IntelÂ® Advanced Vector Extensions 2 (IntelÂ® AVX2), IntelÂ® Advanced Vector Extensions 512 (IntelÂ® AVX-512), and AVX512_BF16, Intel Core Processors with Intel AVX2, Intel Atom Processors with IntelÂ® Streaming SIMD Extensions (IntelÂ® SSE)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://docs.openvino.ai/nightly/openvino_docs_OV_UG_supported_plugins_ARM_CPU.html&#34;&gt;ARM CPU&lt;/a&gt; &lt;/td&gt;&#xA;   &lt;td&gt;&lt;b&gt;&lt;i&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_contrib/tree/master/modules/arm_plugin&#34;&gt;openvino_arm_cpu_plugin&lt;/a&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Raspberry Piâ„¢ 4 Model B, AppleÂ® Mac mini with M1 chip, NVIDIAÂ® Jetson Nanoâ„¢, Androidâ„¢ devices &lt;/td&gt;&#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPU&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.openvino.ai/nightly/openvino_docs_OV_UG_supported_plugins_GPU.html#doxid-openvino-docs-o-v-u-g-supported-plugins-g-p-u&#34;&gt;Intel GPU&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;&lt;i&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/plugins/intel_gpu&#34;&gt;openvino_intel_gpu_plugin&lt;/a&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Intel Processor Graphics, including Intel HD Graphics and Intel Iris Graphics&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GNA&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.openvino.ai/nightly/openvino_docs_OV_UG_supported_plugins_GNA.html#doxid-openvino-docs-o-v-u-g-supported-plugins-g-n-a&#34;&gt;Intel GNA&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;&lt;i&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/plugins/intel_gna&#34;&gt;openvino_intel_gna_plugin&lt;/a&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Intel Speech Enabling Developer Kit, Amazon Alexa* Premium Far-Field Developer Kit, Intel Pentium Silver J5005 Processor, Intel Pentium Silver N5000 Processor, Intel Celeron J4005 Processor, Intel Celeron J4105 Processor, Intel Celeron Processor N4100, Intel Celeron Processor N4000, Intel Core i3-8121U Processor, Intel Core i7-1065G7 Processor, Intel Core i7-1060G7 Processor, Intel Core i5-1035G4 Processor, Intel Core i5-1035G7 Processor, Intel Core i5-1035G1 Processor, Intel Core i5-1030G7 Processor, Intel Core i5-1030G4 Processor, Intel Core i3-1005G1 Processor, Intel Core i3-1000G1 Processor, Intel Core i3-1000G4 Processor&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;VPU&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.openvino.ai/nightly/openvino_docs_IE_DG_supported_plugins_VPU.html#doxid-openvino-docs-i-e-d-g-supported-plugins-v-p-u&#34;&gt;Myriad plugin&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;&lt;i&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/plugins/intel_myriad&#34;&gt;openvino_intel_myriad_plugin&lt;/a&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;IntelÂ® Neural Compute Stick 2 powered by the IntelÂ® Movidiusâ„¢ Myriadâ„¢ X&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Also OpenVINOâ„¢ Toolkit contains several plugins which should simplify to load model on several hardware devices:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Plugin&lt;/th&gt; &#xA;   &lt;th&gt;Library&lt;/th&gt; &#xA;   &lt;th&gt;ShortDescription&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.openvino.ai/nightly/openvino_docs_IE_DG_supported_plugins_AUTO.html#doxid-openvino-docs-i-e-d-g-supported-plugins-a-u-t-o&#34;&gt;Auto&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;&lt;i&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/plugins/auto&#34;&gt;openvino_auto_plugin&lt;/a&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Auto plugin enables selecting Intel device for inference automatically&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.openvino.ai/nightly/openvino_docs_OV_UG_Automatic_Batching.html&#34;&gt;Auto Batch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;&lt;i&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/plugins/auto_batch&#34;&gt;openvino_auto_batch_plugin&lt;/a&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Auto batch plugin performs on-the-fly automatic batching (i.e. grouping inference requests together) to improve device utilization, with no programming effort from the user&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.openvino.ai/nightly/openvino_docs_OV_UG_Hetero_execution.html#doxid-openvino-docs-o-v-u-g-hetero-execution&#34;&gt;Hetero&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;&lt;i&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/plugins/hetero&#34;&gt;openvino_hetero_plugin&lt;/a&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Heterogeneous execution enables automatic inference splitting between several devices&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.openvino.ai/nightly/openvino_docs_OV_UG_Running_on_multiple_devices.html#doxid-openvino-docs-o-v-u-g-running-on-multiple-devices&#34;&gt;Multi&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;b&gt;&lt;i&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/tree/master/src/plugins/auto&#34;&gt;openvino_auto_plugin&lt;/a&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Multi plugin enables simultaneous inference of the same model on several devices in parallel&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;OpenVINOâ„¢ Toolkit is licensed under &lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/LICENSE&#34;&gt;Apache License Version 2.0&lt;/a&gt;. By contributing to the project, you agree to the license and copyright terms therein and release your contribution under these terms.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;h3&gt;User documentation&lt;/h3&gt; &#xA;&lt;p&gt;The latest documentation for OpenVINOâ„¢ Toolkit is availabe &lt;a href=&#34;https://docs.openvino.ai/&#34;&gt;here&lt;/a&gt;. This documentation contains detailed information about all OpenVINO components and provides all important information which could be needed if you create an application which is based on binary OpenVINO distribution or own OpenVINO version without source code modification.&lt;/p&gt; &#xA;&lt;h3&gt;Developer documentation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/#todo-add&#34;&gt;Developer documentation&lt;/a&gt; contains information about architectural decisions which are applied inside the OpenVINO components. This documentation has all necessary information which could be needed in order to contribute to OpenVINO.&lt;/p&gt; &#xA;&lt;h2&gt;Tutorials&lt;/h2&gt; &#xA;&lt;p&gt;The list of OpenVINO tutorials:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks&#34;&gt;Jupiter notebooks&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Products which use OpenVINO&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opencv.org/&#34;&gt;OpenCV&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://onnxruntime.ai/&#34;&gt;ONNX Runtime&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.intel.com/content/www/us/en/developer/tools/devcloud/edge/build/ovtfoverview.html&#34;&gt;OpenVINOâ„¢ Integration with TensorFlow&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tencent/TNN/tree/master&#34;&gt;TNN&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;System requirements&lt;/h2&gt; &#xA;&lt;p&gt;The full information about system requirements depends on platform and available in section &lt;code&gt;System requirement&lt;/code&gt; on dedicated pages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.openvino.ai/latest/openvino_docs_install_guides_installing_openvino_linux.html&#34;&gt;Linux&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.openvino.ai/latest/openvino_docs_install_guides_installing_openvino_windows.html&#34;&gt;Windows&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.openvino.ai/latest/openvino_docs_install_guides_installing_openvino_macos.html&#34;&gt;macOS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.openvino.ai/latest/openvino_docs_install_guides_installing_openvino_raspbian.html&#34;&gt;Raspbian&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to build&lt;/h2&gt; &#xA;&lt;p&gt;Please take a look to &lt;a href=&#34;https://github.com/openvinotoolkit/openvino/wiki#how-to-build&#34;&gt;OpenVINO Wiki&lt;/a&gt; to get more information about OpenVINO build process.&lt;/p&gt; &#xA;&lt;h2&gt;How to contribute&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING&lt;/a&gt; for details. Thank you!&lt;/p&gt; &#xA;&lt;h2&gt;Get a support&lt;/h2&gt; &#xA;&lt;p&gt;Please report questions, issues and suggestions using:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/issues&#34;&gt;GitHub* Issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://stackoverflow.com/questions/tagged/openvino&#34;&gt;&lt;code&gt;openvino&lt;/code&gt;&lt;/a&gt; tag on StackOverflow*&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://software.intel.com/en-us/forums/computer-vision&#34;&gt;Forum&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;See also&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino/wiki&#34;&gt;OpenVINO Wiki&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://storage.openvinotoolkit.org/&#34;&gt;OpenVINO Storage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Additional OpenVINOâ„¢ toolkit modules: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_contrib&#34;&gt;openvino_contrib&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html&#34;&gt;IntelÂ® Distribution of OpenVINOâ„¢ toolkit Product Page&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://software.intel.com/en-us/articles/OpenVINO-RelNotes&#34;&gt;IntelÂ® Distribution of OpenVINOâ„¢ toolkit Release Notes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/nncf&#34;&gt;Neural Network Compression Framework (NNCF)&lt;/a&gt; - a suite of advanced algorithms for model inference optimization including quantization, filter pruning, binarization and sparsity&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/training_extensions&#34;&gt;OpenVINOâ„¢ Training Extensions (OTE)&lt;/a&gt; - convenient environment to train Deep Learning models and convert them using OpenVINO for optimized inference.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/model_server&#34;&gt;OpenVINOâ„¢ Model Server (OVMS)&lt;/a&gt; - a scalable, high-performance solution for serving deep learning models optimized for Intel architectures&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.openvino.ai/nightly/workbench_docs_Workbench_DG_Introduction.html&#34;&gt;DL Workbench&lt;/a&gt; - An alternative, web-based version of OpenVINO designed to make production of pretrained deep learning models significantly easier.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/cvat&#34;&gt;Computer Vision Annotation Tool (CVAT)&lt;/a&gt; - an online, interactive video and image annotation tool for computer vision purposes.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/datumaro&#34;&gt;Dataset Management Framework (Datumaro)&lt;/a&gt; - a framework and CLI tool to build, transform, and analyze datasets.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;* Other names and brands may be claimed as the property of others.&lt;/p&gt;</summary>
  </entry>
</feed>