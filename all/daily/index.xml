<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-26T01:30:06Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>zksync/credo</title>
    <updated>2023-06-26T01:30:06Z</updated>
    <id>tag:github.com,2023-06-26:/zksync/credo</id>
    <link href="https://github.com/zksync/credo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ZK Credo&lt;/h1&gt; &#xA;&lt;h2&gt;Freedom → Progress → Prosperity&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zksync/credo/main/freedom-progress-prosperity.jpeg&#34; alt=&#34;Freedom → Progress → Prosperity&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;History shows us how technology can expand personal freedoms, unleashing creativity and innovation, leading to progress and prosperity.&lt;/p&gt; &#xA;&lt;p&gt;Early civilizations used bookkeeping and ledgers to track transactions, empowering individuals and communities to manage their finances and cooperate. The printing press democratized knowledge by making information affordable, sparking critical thinking and scientific advancement.&lt;/p&gt; &#xA;&lt;p&gt;The Industrial Revolution, powered by the technological breakthroughs of the steam engine and mechanization, propelled unprecedented economic and societal prosperity.&lt;/p&gt; &#xA;&lt;p&gt;In the twentieth century, the rise of cryptography and the Internet transformed communication and information access. This expansion of personal freedoms created economic opportunities for billions of people.&lt;/p&gt; &#xA;&lt;p&gt;Today, we&#39;re at the dawn of a new era with blockchains and Web3. Like the Internet once did for information, Web3 is changing the landscape for digital ownership and value exchange. It offers promising new forms of societal organization, e.g. &#34;network states&#34; [^1].&lt;/p&gt; &#xA;&lt;p&gt;The journey through the waves of the cryptographic revolution is ongoing. With public-key cryptography and blockchains marking the first and second waves, we now face the third: the ZK Revolution. Coupled with Web3, the ZK Revolution is set to redefine our collective future, standing as testament to technology&#39;s power to unlock personal freedom.&lt;/p&gt; &#xA;&lt;h2&gt;The ZK Revolution&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zksync/credo/main/zk-revolution.jpeg&#34; alt=&#34;ZK Revolution&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&#34;ZK&#34; is a term with two meanings. Initially, it stood for &#34;Zero-Knowledge (Proofs)&#34;, or, if you insist, &#34;Zipped by Kryptography&#34; [^2]. Today, &#34;ZK&#34; embodies a certain bigger idea, encapsulated in three properties: Integrity, Privacy, and Magic.&lt;/p&gt; &#xA;&lt;h3&gt;Integrity&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;“Integrity is doing the right thing... even when no one else is looking or will ever know.”&lt;/em&gt; [^3]&lt;/p&gt; &#xA;&lt;p&gt;ZK echoes the &#34;don&#39;t trust, verify&#34; ethos foundational to mathematics, open source, and blockchains. Computational integrity, enabled at any scale by recursive ZK proofs, is the cornerstone of this element.&lt;/p&gt; &#xA;&lt;h3&gt;Privacy&lt;/h3&gt; &#xA;&lt;p&gt;“&lt;em&gt;Privacy is necessary for an open society in the electronic age.”&lt;/em&gt; [^4]&lt;/p&gt; &#xA;&lt;p&gt;In the blockchain sphere, privacy, viewed as a fundamental right, poses challenges uniquely addressed by ZK. Privacy shouldn&#39;t be a gift given to us; it&#39;s a fundamental right we must assert and defend together.&lt;/p&gt; &#xA;&lt;h3&gt;Magic&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;“Any sufficiently advanced technology is indistinguishable from magic.”&lt;/em&gt; [^5]&lt;/p&gt; &#xA;&lt;p&gt;ZK, endearingly dubbed &#34;Magic Moon Math,&#34; is a marvel of technology. It makes the cumbersome simple, converting intricate operations into effortless clicks. It enables integrated systems, where components seamlessly synchronize. Above all, it weaves these wonders while honoring user privacy and control.&lt;/p&gt; &#xA;&lt;h2&gt;The ZK Principles&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zksync/credo/main/zk-principles.jpeg&#34; alt=&#34;ZK Principles&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;We believe that to serve as the foundation of the Internet of Value, decentralized networks must adhere to the following principles:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Trustlessness.&lt;/strong&gt; Users must be able to verify the integrity of transactions and the network state independently, without relying on others.&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Security.&lt;/strong&gt; An attack on any individual user must be as difficult and expensive as attacking the entire network, even for the world’s most powerful actors.&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Reliability.&lt;/strong&gt; The network must consistently and correctly perform its function without failure.&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Censorship-Resistance.&lt;/strong&gt; Users must have the ability to transact on the network without needing permission from anyone.&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Privacy.&lt;/strong&gt; Users must be able to protect their identities and transaction details. Sensitive information is not shared with others in the network without the consent of users.&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Hyperscalability.&lt;/strong&gt; The network must have the capacity to grow with no upper bound while preserving all other critical properties.&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Accessibility.&lt;/strong&gt; Applications and services on the network must be as affordable, easy-to-use and safe as state-of-the-art centralized alternatives.&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Sovereignty.&lt;/strong&gt; Any group of users, even a minority, must have the right to exit — i.e., fork away from the network, while taking their assets with them at a minimal cost.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;At present, Ethereum comes closest to realizing the vision of a blockchain network forming the backbone of the Internet of Value. It stands as a trustless, secure, reliable, censorship-resistant, and sovereign network. However, it currently does not meet the remaining prerequisites: privacy, hyperscalability, and accessibility.&lt;/p&gt; &#xA;&lt;p&gt;Through ZK magic, Web3 on Ethereum can become a stronghold for privacy and achieve limitless scalability while maintaining integrity. In this transformative state, it will be an accessible and affordable sanctuary for digital self-ownership.&lt;/p&gt; &#xA;&lt;p&gt;It aligns with the ZK vision and will empower individuals globally, regardless of location. By unlocking these capabilities, a new wave of freedom, progress, and prosperity, will impact lives globally.&lt;/p&gt; &#xA;&lt;h2&gt;The Collective Action&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zksync/credo/main/the-collective-action.jpeg&#34; alt=&#34;The Collective Action&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;ZK Principles empower a network where trust in operators is not needed to secure users&#39; assets and control. Even if the Lord Voldemort had access to our servers, they couldn&#39;t harm users&#39; ownership or control their assets.&lt;/p&gt; &#xA;&lt;p&gt;However, technology evolves and so do blockchains. The ZK Principles can’t be fully safeguarded through technology alone. To ensure lasting protection, the community must deeply embrace the elusive concept of decentralization.&lt;/p&gt; &#xA;&lt;p&gt;If a network possesses all the mentioned attributes but its governance falls into the hands of a privileged few, it is destined to fail. Such few will tweak the rules for personal gain, eroding network value. The Internet’s history serves as a cautionary tale. Its inception promised decentralization, but over time user data and traffic fell into the control of a few tech giants, shaping the digital landscape to their advantage.&lt;/p&gt; &#xA;&lt;p&gt;To avoid this fate, we believe that the ZK community must be fiercely sovereign by elevating the right to exit into a moral obligation. When the network deviates from its principles, the community must unite and uphold these values by migrating to a new network.&lt;/p&gt; &#xA;&lt;p&gt;Identifying such an erosion of values is not trivial: oppression is often subtle, slowly chipping away at freedom. Oppressors may also publicly punish dissenters to instill fear and encourage &lt;em&gt;collective inaction&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Against these tactics, &lt;em&gt;collective action&lt;/em&gt; is essential. The community must protect minorities and celebrate those who bravely defy oppression. To embed this collective commitment deeply in the community is vital to preserving freedom in the Internet of Value.&lt;/p&gt; &#xA;&lt;p&gt;Realizing these principles requires time and perseverance. A steady, pragmatic approach to decentralization is needed. While short-term compromises might be made, the unwavering long-term vision remains: advancing personal freedom for all.&lt;/p&gt; &#xA;&lt;p&gt;Let us remain resolute in championing digital self-ownership.&lt;/p&gt; &#xA;&lt;p&gt;Onward.&lt;/p&gt; &#xA;&lt;p&gt;[^1]: &lt;a href=&#34;https://thenetworkstate.com/the-network-state-in-one-sentence&#34;&gt;The Network State&lt;/a&gt;. [^2]: &lt;a href=&#34;https://twitter.com/vitalikbuterin/status/1309298689156866048&#34;&gt;Zipped by Kryptography&lt;/a&gt; [^3]: Charles Marshall, Shattering the Glass Slipper. [^4]: &lt;a href=&#34;https://nakamotoinstitute.org/static/docs/cypherpunk-manifesto.txt&#34;&gt;Cypherpunk Manifesto&lt;/a&gt; [^5]: &lt;a href=&#34;https://en.wikipedia.org/wiki/Clarke%27s_three_laws&#34;&gt;Clarke&#39;s Third Law&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>SkalskiP/top-cvpr-2023-papers</title>
    <updated>2023-06-26T01:30:06Z</updated>
    <id>tag:github.com,2023-06-26:/SkalskiP/top-cvpr-2023-papers</id>
    <link href="https://github.com/SkalskiP/top-cvpr-2023-papers" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repository is a curated collection of the most exciting and influential CVPR 2023 papers. 🔥 [Paper + Code]&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;crème de la crème of CVPR 2023&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img width=&#34;600&#34; src=&#34;https://github.com/SkalskiP/top-cvpr-2023-papers/assets/26109316/793d71f5-6034-4342-a8b3-2a08646a6aa0&#34; alt=&#34;vancouver&#34;&gt; &lt;br&gt; &lt;/p&gt; &#xA;&lt;h2&gt;👋 hello&lt;/h2&gt; &#xA;&lt;p&gt;Computer Vision and Pattern Recognition is a massive conference. In &lt;strong&gt;2023&lt;/strong&gt; alone, &lt;strong&gt;9155&lt;/strong&gt; papers were submitted, and &lt;strong&gt;2359&lt;/strong&gt; were accepted. I created this repository to help you search for crème de la crème of CVPR publications. If the paper you are looking for is not on my short list, take a peek at the full &lt;a href=&#34;https://cvpr2023.thecvf.com/Conferences/2023/AcceptedPapers&#34;&gt;list&lt;/a&gt; of accepted papers.&lt;/p&gt; &#xA;&lt;h2&gt;🗞️ papers&lt;/h2&gt; &#xA;&lt;!-- AUTOGENERATED_COURSES_TABLE --&gt; &#xA;&lt;!--&#xA;   WARNING: DO NOT EDIT THIS TABLE MANUALLY. IT IS AUTOMATICALLY GENERATED.&#xA;   HEAD OVER TO CONTRIBUTING.MD FOR MORE DETAILS ON HOW TO MAKE CHANGES PROPERLY.&#xA;--&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;topic&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;title&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;strong&gt;repository / paper&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Segmentation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;OneFormer: One Transformer To Rule Universal Image Segmentation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/SHI-Labs/OneFormer&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/SHI-Labs/OneFormer?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2211.0622&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2211.0622-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Segmentation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;X-Decoder: Generalized Decoding for Pixel, Image and Language&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/microsoft/X-Decoder&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/microsoft/X-Decoder?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2212.1127&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2212.1127-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Segmentation and Generative AI&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Images Speak in Images: A Generalist Painter for In-Context Visual Learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/baaivision/Painter&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/baaivision/Painter?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2212.02499&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2212.02499-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Segmentation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;PACO: Parts and Attributes of Common Objects&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/facebookresearch/paco&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/facebookresearch/paco?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2301.01795&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2301.01795-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Segmentation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/facebookresearch/ov-seg&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/facebookresearch/ov-seg?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2210.0415&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2210.0415-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;NeRF&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;DynIBaR: Neural Dynamic Image-Based Rendering&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/google/dynibar&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/google/dynibar?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2211.11082&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2211.11082-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3D&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via Self-supervised Scene Decomposition&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/MoyGcc/vid2avatar&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/MoyGcc/vid2avatar?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2302.11566&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2302.11566-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Generative AI&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3D-aware Conditional Image Synthesis&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/dunbar12138/pix2pix3d&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/dunbar12138/pix2pix3d?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2302.08509&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2302.08509-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3D&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3D Human Mesh Estimation from Virtual Markers&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ShirleyMaxx/VirtualMarker&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/ShirleyMaxx/VirtualMarker?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2303.11726&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2303.11726-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Transfer Learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;A Data-Based Perspective on Transfer Learning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/MadryLab/data-transfer&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/MadryLab/data-transfer?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2207.05739&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2207.05739-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Segmentation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/NVlabs/ODISE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/NVlabs/ODISE?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2303.04803&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2303.04803-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Generative AI&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/google/dreambooth&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/google/dreambooth?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2208.12242&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2208.12242-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Generative AI&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;InstructPix2Pix: Learning to Follow Image Editing Instructions&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/timothybrooks/instruct-pix2pix&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/timothybrooks/instruct-pix2pix?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2211.098&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2211.098-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Generative AI&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;High-resolution image reconstruction with latent diffusion models from human brain activity&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/yu-takagi/StableDiffusionReconstruction&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/yu-takagi/StableDiffusionReconstruction?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2306.11536&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2306.11536-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Benchmarking&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Beyond mAP: Towards better evaluation of instance segmentation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/rohitrango/beyond-map&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/rohitrango/beyond-map?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2207.01614&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2207.01614-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;NeRF&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;SPIn-NeRF: Multiview Segmentation and Perceptual Inpainting with Neural Radiance Fields&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/SamsungLabs/SPIn-NeRF&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/SamsungLabs/SPIn-NeRF?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2211.12254&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2211.12254-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3D&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Omni3D: A Large Benchmark and Model for 3D Object Detection in the Wild&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/facebookresearch/omni3d&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/facebookresearch/omni3d?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2207.1066&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2207.1066-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3D&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ECON: Explicit Clothed humans Optimized via Normal integration&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/YuliangXiu/ECON&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/YuliangXiu/ECON?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2212.07422&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2212.07422-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3D&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;NeuralLift-360: Lifting An In-the-wild 2D Photo to A 3D Object with 360° Views&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/VITA-Group/NeuralLift-360&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/VITA-Group/NeuralLift-360?style=social&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2211.16431&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2211.16431-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!-- AUTOGENERATED_COURSES_TABLE --&gt; &#xA;&lt;h2&gt;🦸 contribution&lt;/h2&gt; &#xA;&lt;p&gt;We would love your help in making this repository even better! If you know of an amazing paper that isn&#39;t listed here, or if you have any suggestions for improvement, feel free to open an &lt;a href=&#34;https://github.com/SkalskiP/top-cvpr-2023-papers/issues&#34;&gt;issue&lt;/a&gt; or submit a &lt;a href=&#34;https://github.com/SkalskiP/top-cvpr-2023-papers/pulls&#34;&gt;pull request&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Rapptz/discord.py</title>
    <updated>2023-06-26T01:30:06Z</updated>
    <id>tag:github.com,2023-06-26:/Rapptz/discord.py</id>
    <link href="https://github.com/Rapptz/discord.py" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An API wrapper for Discord written in Python.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;discord.py&lt;/h1&gt; &#xA;&lt;p&gt;.. image:: &lt;a href=&#34;https://discord.com/api/guilds/336642139381301249/embed.png&#34;&gt;https://discord.com/api/guilds/336642139381301249/embed.png&lt;/a&gt; :target: &lt;a href=&#34;https://discord.gg/r3sSKJJ&#34;&gt;https://discord.gg/r3sSKJJ&lt;/a&gt; :alt: Discord server invite .. image:: &lt;a href=&#34;https://img.shields.io/pypi/v/discord.py.svg&#34;&gt;https://img.shields.io/pypi/v/discord.py.svg&lt;/a&gt; :target: &lt;a href=&#34;https://pypi.python.org/pypi/discord.py&#34;&gt;https://pypi.python.org/pypi/discord.py&lt;/a&gt; :alt: PyPI version info .. image:: &lt;a href=&#34;https://img.shields.io/pypi/pyversions/discord.py.svg&#34;&gt;https://img.shields.io/pypi/pyversions/discord.py.svg&lt;/a&gt; :target: &lt;a href=&#34;https://pypi.python.org/pypi/discord.py&#34;&gt;https://pypi.python.org/pypi/discord.py&lt;/a&gt; :alt: PyPI supported Python versions&lt;/p&gt; &#xA;&lt;p&gt;A modern, easy to use, feature-rich, and async ready API wrapper for Discord written in Python.&lt;/p&gt; &#xA;&lt;h2&gt;Key Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Modern Pythonic API using &lt;code&gt;async&lt;/code&gt; and &lt;code&gt;await&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Proper rate limit handling.&lt;/li&gt; &#xA; &lt;li&gt;Optimised in both speed and memory.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installing&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Python 3.8 or higher is required&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;To install the library without full voice support, you can just run the following command:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: sh&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Linux/macOS&#xA;python3 -m pip install -U discord.py&#xA;&#xA;# Windows&#xA;py -3 -m pip install -U discord.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Otherwise to get voice support you should run the following command:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: sh&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Linux/macOS&#xA;python3 -m pip install -U &#34;discord.py[voice]&#34;&#xA;&#xA;# Windows&#xA;py -3 -m pip install -U discord.py[voice]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To install the development version, do the following:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: sh&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/Rapptz/discord.py&#xA;$ cd discord.py&#xA;$ python3 -m pip install -U .[voice]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Optional Packages&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;* `PyNaCl &amp;lt;https://pypi.org/project/PyNaCl/&amp;gt;`__ (for voice support)&#xA;&#xA;Please note that when installing voice support on Linux, you must install the following packages via your favourite package manager (e.g. ``apt``, ``dnf``, etc) before running the above commands:&#xA;&#xA;* libffi-dev (or ``libffi-devel`` on some systems)&#xA;* python-dev (e.g. ``python3.8-dev`` for Python 3.8)&#xA;&#xA;Quick Example&#xA;--------------&#xA;&#xA;.. code:: py&#xA;&#xA;    import discord&#xA;&#xA;    class MyClient(discord.Client):&#xA;        async def on_ready(self):&#xA;            print(&#39;Logged on as&#39;, self.user)&#xA;&#xA;        async def on_message(self, message):&#xA;            # don&#39;t respond to ourselves&#xA;            if message.author == self.user:&#xA;                return&#xA;&#xA;            if message.content == &#39;ping&#39;:&#xA;                await message.channel.send(&#39;pong&#39;)&#xA;&#xA;    intents = discord.Intents.default()&#xA;    intents.message_content = True&#xA;    client = MyClient(intents=intents)&#xA;    client.run(&#39;token&#39;)&#xA;&#xA;Bot Example&#xA;~~~~~~~~~~~~~&#xA;&#xA;.. code:: py&#xA;&#xA;    import discord&#xA;    from discord.ext import commands&#xA;&#xA;    intents = discord.Intents.default()&#xA;    intents.message_content = True&#xA;    bot = commands.Bot(command_prefix=&#39;&amp;gt;&#39;, intents=intents)&#xA;&#xA;    @bot.command()&#xA;    async def ping(ctx):&#xA;        await ctx.send(&#39;pong&#39;)&#xA;&#xA;    bot.run(&#39;token&#39;)&#xA;&#xA;You can find more examples in the examples directory.&#xA;&#xA;Links&#xA;------&#xA;&#xA;- `Documentation &amp;lt;https://discordpy.readthedocs.io/en/latest/index.html&amp;gt;`_&#xA;- `Official Discord Server &amp;lt;https://discord.gg/r3sSKJJ&amp;gt;`_&#xA;- `Discord API &amp;lt;https://discord.gg/discord-api&amp;gt;`_&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>