<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-18T01:25:06Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>firefly-iii/firefly-iii</title>
    <updated>2024-02-18T01:25:06Z</updated>
    <id>tag:github.com,2024-02-18:/firefly-iii/firefly-iii</id>
    <link href="https://github.com/firefly-iii/firefly-iii" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Firefly III: a personal finances manager&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://packagist.org/packages/grumpydictator/firefly-iii&#34;&gt;&lt;img src=&#34;https://img.shields.io/packagist/v/grumpydictator/firefly-iii.svg?style=flat-square&#34; alt=&#34;Packagist&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.gnu.org/licenses/agpl-3.0.html&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/firefly-iii/firefly-iii.svg?style=flat-square&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/firefly-iii/firefly-iii/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/firefly-iii/firefly-iii.svg?style=flat-square&#34; alt=&#34;Stargazers&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/main/#support-the-development-of-firefly-iii&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/donate-%24%20%E2%82%AC-brightgreen?style=flat-square&#34; alt=&#34;Donate&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- PROJECT LOGO --&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://firefly-iii.org/&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/develop/.github/assets/img/logo-small.png&#34; alt=&#34;Firefly III&#34; width=&#34;120&#34; height=&#34;178&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt;Firefly III&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; A free and open source personal finance manager &lt;br&gt; &lt;a href=&#34;https://docs.firefly-iii.org/&#34;&gt;&lt;strong&gt;Explore the documentation&lt;/strong&gt;&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://demo.firefly-iii.org/&#34;&gt;View the demo&lt;/a&gt; · &lt;a href=&#34;https://github.com/firefly-iii/firefly-iii/issues&#34;&gt;Report a bug&lt;/a&gt; · &lt;a href=&#34;https://github.com/firefly-iii/firefly-iii/issues&#34;&gt;Request a feature&lt;/a&gt; · &lt;a href=&#34;https://github.com/firefly-iii/firefly-iii/discussions&#34;&gt;Ask questions&lt;/a&gt; &lt;/p&gt; &#xA;&lt;!-- MarkdownTOC autolink=&#34;true&#34; --&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/main/#about-firefly-iii&#34;&gt;About Firefly III&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/main/#purpose&#34;&gt;Purpose&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/main/#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/main/#whos-it-for&#34;&gt;Who&#39;s it for?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/main/#the-firefly-iii-eco-system&#34;&gt;The Firefly III eco-system&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/main/#getting-started&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/main/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/main/#support-the-development-of-firefly-iii&#34;&gt;Support the development of Firefly III&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/main/#do-you-need-help-or-do-you-want-to-get-in-touch&#34;&gt;Do you need help, or do you want to get in touch?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/main/#acknowledgements&#34;&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- /MarkdownTOC --&gt; &#xA;&lt;h2&gt;About Firefly III&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/develop/.github/assets/img/imac-complete.png&#34; alt=&#34;Firefly III on iMac&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&#34;Firefly III&#34; is a (self-hosted) manager for your personal finances. It can help you keep track of your expenses and income, so you can spend less and save more. Firefly III supports the use of budgets, categories and tags. Using a bunch of external tools, you can import data. It also has many neat financial reports available.&lt;/p&gt; &#xA;&lt;p&gt;Firefly III should give you &lt;strong&gt;insight&lt;/strong&gt; into and &lt;strong&gt;control&lt;/strong&gt; over your finances. Money should be useful, not scary. You should be able to &lt;em&gt;see&lt;/em&gt; where it is going, to &lt;em&gt;feel&lt;/em&gt; your expenses and to... wow, I&#39;m going overboard with this aren&#39;t I?&lt;/p&gt; &#xA;&lt;p&gt;But you get the idea: this is your money. These are your expenses. Stop them from controlling you. I built this tool because I started to dislike money. Having money, not having money, paying bills with money, you get the idea. But no more. I want to feel &#34;safe&#34;, whatever my balance is. And I hope this tool can help you. I know it helps me.&lt;/p&gt; &#xA;&lt;h3&gt;Purpose&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/develop/.github/assets/img/ipad-complete.png&#34; alt=&#34;Firefly III on iPad&#34; width=&#34;600&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Personal financial management is pretty difficult, and everybody has their own approach to it. Some people make budgets, other people limit their cashflow by throwing away their credit cards, others try to increase their current cashflow. There are tons of ways to save and earn money. Firefly III works on the principle that if you know where your money is going, you can stop it from going there.&lt;/p&gt; &#xA;&lt;p&gt;By keeping track of your expenses and your income you can budget accordingly and save money. Stop living from paycheck to paycheck but give yourself the financial wiggle room you need.&lt;/p&gt; &#xA;&lt;p&gt;You can read more about the purpose of Firefly III in the &lt;a href=&#34;https://docs.firefly-iii.org/&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;p&gt;Firefly III is pretty feature packed. Some important stuff first:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;It is completely self-hosted and isolated, and will never contact external servers until you explicitly tell it to.&lt;/li&gt; &#xA; &lt;li&gt;It features a REST JSON API that covers almost every part of Firefly III.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The most exciting features are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create &lt;a href=&#34;https://docs.firefly-iii.org/explanation/financial-concepts/recurring/&#34;&gt;recurring transactions to manage your money&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.firefly-iii.org/how-to/firefly-iii/features/rules/&#34;&gt;Rule based transaction handling&lt;/a&gt; with the ability to create your own rules.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Then the things that make you go &#34;yeah OK, makes sense&#34;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;a href=&#34;https://en.wikipedia.org/wiki/Double-entry_bookkeeping_system&#34;&gt;double-entry&lt;/a&gt; bookkeeping system.&lt;/li&gt; &#xA; &lt;li&gt;Save towards a goal using &lt;a href=&#34;https://docs.firefly-iii.org/explanation/financial-concepts/piggies/&#34;&gt;piggy banks&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;View &lt;a href=&#34;https://docs.firefly-iii.org/how-to/firefly-iii/finances/reports/&#34;&gt;income and expense reports&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;And the things you would hope for but not expect:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;2 factor authentication for extra security 🔒.&lt;/li&gt; &#xA; &lt;li&gt;Supports &lt;a href=&#34;https://docs.firefly-iii.org/how-to/firefly-iii/features/currencies/&#34;&gt;any currency you want&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;There is a &lt;a href=&#34;https://docs.firefly-iii.org/how-to/firefly-iii/installation/docker/&#34;&gt;Docker image&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;And to organise everything:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Clear views that should show you how you&#39;re doing.&lt;/li&gt; &#xA; &lt;li&gt;Easy navigation through your records.&lt;/li&gt; &#xA; &lt;li&gt;Lots of charts because we all love them.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Many more features are listed in the &lt;a href=&#34;https://docs.firefly-iii.org/explanation/firefly-iii/about/introduction/&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Who&#39;s it for?&lt;/h2&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/firefly-iii/firefly-iii/develop/.github/assets/img/iphone-complete.png&#34; alt=&#34;Firefly III on iPhone&#34; align=&#34;left&#34; width=&#34;250&#34;&gt; &#xA;&lt;p&gt;This application is for people who want to track their finances, keep an eye on their money &lt;strong&gt;without having to upload their financial records to the cloud&lt;/strong&gt;. You&#39;re a bit tech-savvy, you like open source software and you don&#39;t mind tinkering with (self-hosted) servers.&lt;/p&gt; &#xA;&lt;br clear=&#34;left&#34;&gt; &#xA;&lt;h2&gt;The Firefly III eco-system&lt;/h2&gt; &#xA;&lt;p&gt;Several users have built pretty awesome stuff around the Firefly III API. &lt;a href=&#34;https://docs.firefly-iii.org/references/firefly-iii/third-parties/apps/&#34;&gt;Check out these tools in the documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;There are many ways to run Firefly III&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;There is a &lt;a href=&#34;https://demo.firefly-iii.org&#34;&gt;demo site&lt;/a&gt; with an example financial administration already present.&lt;/li&gt; &#xA; &lt;li&gt;You can &lt;a href=&#34;https://docs.firefly-iii.org/how-to/firefly-iii/installation/self-managed/&#34;&gt;install it on your server&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;You can &lt;a href=&#34;https://docs.firefly-iii.org/how-to/firefly-iii/installation/docker/&#34;&gt;run it using Docker&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;You can &lt;a href=&#34;https://firefly-iii.github.io/kubernetes/&#34;&gt;deploy via Kubernetes&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;You can &lt;a href=&#34;https://www.softaculous.com/softaculous/apps/others/Firefly_III&#34;&gt;install it using Softaculous&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;You can &lt;a href=&#34;https://www.ampps.com/&#34;&gt;install it using AMPPS&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;You can &lt;a href=&#34;https://cloudron.io/store/org.fireflyiii.cloudronapp.html&#34;&gt;install it on Cloudron&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;You can &lt;a href=&#34;https://gist.github.com/ArtisKrumins/ccb24f31d6d4872b57e7c9343a9d1bf0&#34;&gt;install it on Lando&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;You can &lt;a href=&#34;https://github.com/YunoHost-Apps/firefly-iii&#34;&gt;install it on Yunohost&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;You can contact me at &lt;a href=&#34;mailto:james@firefly-iii.org&#34;&gt;james@firefly-iii.org&lt;/a&gt;, you may open an issue in the &lt;a href=&#34;https://github.com/firefly-iii/firefly-iii&#34;&gt;main repository&lt;/a&gt; or contact me through &lt;a href=&#34;https://gitter.im/firefly-iii/firefly-iii&#34;&gt;gitter&lt;/a&gt; and &lt;a href=&#34;https://fosstodon.org/@ff3&#34;&gt;Mastodon&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Of course, there are some &lt;a href=&#34;https://docs.firefly-iii.org/references/support/#contributing-code&#34;&gt;contributing guidelines&lt;/a&gt; and a &lt;a href=&#34;https://github.com/firefly-iii/firefly-iii/raw/main/.github/code_of_conduct.md&#34;&gt;code of conduct&lt;/a&gt;, which I invite you to check out.&lt;/p&gt; &#xA;&lt;p&gt;I can always use your help &lt;a href=&#34;https://docs.firefly-iii.org/references/support/&#34;&gt;squashing bugs&lt;/a&gt;, thinking about &lt;a href=&#34;https://docs.firefly-iii.org/references/support/&#34;&gt;new features&lt;/a&gt; or &lt;a href=&#34;https://docs.firefly-iii.org/how-to/firefly-iii/development/translations/&#34;&gt;translating Firefly III&lt;/a&gt; into other languages.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://sonarcloud.io/dashboard?id=firefly-iii_firefly-iii&#34;&gt;Sonarcloud&lt;/a&gt; scans the code of Firefly III. If you want to help improve Firefly III, check out the latest reports and take your pick!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://sonarcloud.io/dashboard?id=firefly-iii_firefly-iii&#34;&gt;&lt;img src=&#34;https://sonarcloud.io/api/project_badges/measure?project=firefly-iii_firefly-iii&amp;amp;metric=alert_status&#34; alt=&#34;Quality Gate Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://sonarcloud.io/dashboard?id=firefly-iii_firefly-iii&#34;&gt;&lt;img src=&#34;https://sonarcloud.io/api/project_badges/measure?project=firefly-iii_firefly-iii&amp;amp;metric=bugs&#34; alt=&#34;Bugs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://sonarcloud.io/dashboard?id=firefly-iii_firefly-iii&#34;&gt;&lt;img src=&#34;https://sonarcloud.io/api/project_badges/measure?project=firefly-iii_firefly-iii&amp;amp;metric=code_smells&#34; alt=&#34;Code Smells&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://sonarcloud.io/dashboard?id=firefly-iii_firefly-iii&#34;&gt;&lt;img src=&#34;https://sonarcloud.io/api/project_badges/measure?project=firefly-iii_firefly-iii&amp;amp;metric=vulnerabilities&#34; alt=&#34;Vulnerabilities&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;There is also a &lt;a href=&#34;https://github.com/firefly-iii/firefly-iii/security/policy&#34;&gt;security policy&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://bestpractices.coreinfrastructure.org/projects/6335&#34;&gt;&lt;img src=&#34;https://bestpractices.coreinfrastructure.org/projects/6335/badge&#34; alt=&#34;CII Best Practices&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- SPONSOR TEXT --&gt; &#xA;&lt;h2&gt;Support the development of Firefly III&lt;/h2&gt; &#xA;&lt;p&gt;If you like Firefly III and if it helps you save lots of money, why not send me a dime for every dollar saved! 🥳&lt;/p&gt; &#xA;&lt;p&gt;OK that was a joke. If you feel Firefly III made your life better, please consider contributing as a sponsor. Please check out my &lt;a href=&#34;https://www.patreon.com/jc5&#34;&gt;Patreon&lt;/a&gt; and &lt;a href=&#34;https://github.com/sponsors/JC5&#34;&gt;GitHub Sponsors&lt;/a&gt; page for more information. You can also &lt;a href=&#34;https://ko-fi.com/Q5Q5R4SH1&#34;&gt;buy me a ☕️ coffee at ko-fi.com&lt;/a&gt;. Thank you for your consideration.&lt;/p&gt; &#xA;&lt;!-- END OF SPONSOR TEXT --&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This work &lt;a href=&#34;https://github.com/firefly-iii/firefly-iii/raw/main/LICENSE&#34;&gt;is licensed&lt;/a&gt; under the &lt;a href=&#34;https://www.gnu.org/licenses/agpl-3.0.html&#34;&gt;GNU Affero General Public License v3&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;!-- HELP TEXT --&gt; &#xA;&lt;h2&gt;Do you need help, or do you want to get in touch?&lt;/h2&gt; &#xA;&lt;p&gt;Do you want to contact me? You can email me at &lt;a href=&#34;mailto:james@firefly-iii.org&#34;&gt;james@firefly-iii.org&lt;/a&gt; or get in touch through one of the following support channels:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/firefly-iii/firefly-iii/discussions/&#34;&gt;GitHub Discussions&lt;/a&gt; for questions and support&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gitter.im/firefly-iii/firefly-iii&#34;&gt;Gitter.im&lt;/a&gt; for a good chat and a quick answer&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/firefly-iii/firefly-iii/issues&#34;&gt;GitHub Issues&lt;/a&gt; for bugs and issues&lt;/li&gt; &#xA; &lt;li&gt;&lt;a rel=&#34;me&#34; href=&#34;https://fosstodon.org/@ff3&#34;&gt;Mastodon&lt;/a&gt; for news and updates&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- END OF HELP TEXT --&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;Over time, &lt;a href=&#34;https://github.com/firefly-iii/firefly-iii/graphs/contributors&#34;&gt;many people have contributed to Firefly III&lt;/a&gt;. I&#39;m grateful for their support and code contributions.&lt;/p&gt; &#xA;&lt;p&gt;The Firefly III logo is made by the excellent Cherie Woo.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>LargeWorldModel/LWM</title>
    <updated>2024-02-18T01:25:06Z</updated>
    <id>tag:github.com,2024-02-18:/LargeWorldModel/LWM</id>
    <link href="https://github.com/LargeWorldModel/LWM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Large World Model (LWM)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://largeworldmodel.github.io/&#34;&gt;[Project]&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2402.08268&#34;&gt;[Paper]&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/LargeWorldModel&#34;&gt;[Models]&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Large World Model (LWM)&lt;/strong&gt; is a general-purpose large-context multimodal autoregressive model. It is trained on a large dataset of diverse long videos and books using RingAttention, and can perform language, image, and video understanding and generation.&lt;/p&gt; &#xA;&lt;h2&gt;Approach&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/LargeWorldModel/LWM/main/imgs/data.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Current language models fall short in understanding aspects of the world not easily described in words, and struggle with complex, long-form tasks. Video sequences offer valuable temporal information absent in language and static images, making them attractive for joint modeling with language. Such models could develop a understanding of both human textual knowledge and the physical world, enabling broader AI capabilities for assisting humans. However, learning from millions of tokens of video and language sequences poses challenges due to memory constraints, computational complexity, and limited datasets. To address these challenges, we curate a large dataset of diverse videos and books, utilize the RingAttention technique to scalably train on long sequences, and gradually increase context size from 4K to 1M tokens. This paper makes the following contributions: (a) Largest context size neural network: We train one of the largest context size transformers on long video and language sequences, setting new benchmarks in difficult retrieval tasks and long video understanding. (b) Solutions for overcoming vision-language training challenges, including using masked sequence packing for mixing different sequence lengths, loss weighting to balance language and vision, and model-generated QA dataset for long sequence chat. (c) A highly-optimized implementation with RingAttention, masked sequence packing, and other key features for training on millions-length multimodal sequences. (d) Fully open-sourced a family of 7B parameter models capable of processing long text documents (LWM-Text, LWM-Text-Chat) and videos (LWM, LWM-Chat) of over 1M tokens. This work paves the way for training on massive datasets of long video and language to develop understanding of both human knowledge and the multimodal world, and broader capabilities.&lt;/p&gt; &#xA;&lt;h2&gt;LWM Capabilities&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/LargeWorldModel/LWM/main/imgs/single_needle_1M.png&#34;&gt; &#xA; &lt;p&gt; LWM can retrieval facts across 1M context with high accuracy. &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/LargeWorldModel/LWM/main/imgs/long_video_chat_main.png&#34;&gt; &#xA; &lt;p&gt; LWM can answer questions over 1 hour YouTube video. &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/LargeWorldModel/LWM/main/imgs/image_chat.png&#34;&gt; &#xA; &lt;p&gt; LWM can chat with images. &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/LargeWorldModel/LWM/main/imgs/image_video_gen.png&#34;&gt; &#xA; &lt;p&gt; LWM can generate videos and images from text. &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;Install the requirements with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda create -n lwm python=3.10&#xA;pip install -U &#34;jax[cuda12_pip]==0.4.23&#34; -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or set up TPU VM with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sh tpu_requirements.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Available models&lt;/h2&gt; &#xA;&lt;p&gt;There are language-only and video-language versions, offering context sizes from 32K, to 128K, 256K and 1M tokens. The vision-language models are available only in Jax, and the language-only models are available in both PyTorch and Jax. Below are the names of the available models and their corresponding context sizes and capabilities:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model Name&lt;/th&gt; &#xA;   &lt;th&gt;Context Size&lt;/th&gt; &#xA;   &lt;th&gt;Language or Vision-Language&lt;/th&gt; &#xA;   &lt;th&gt;Chat or Base&lt;/th&gt; &#xA;   &lt;th&gt;URL&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LWM-Text-Chat-128K&lt;/td&gt; &#xA;   &lt;td&gt;128K&lt;/td&gt; &#xA;   &lt;td&gt;Language&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;[&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-Chat-128K&#34;&gt;Pytorch&lt;/a&gt;][&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-Chat-128K-Jax&#34;&gt;Jax&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LWM-Text-Chat-256K&lt;/td&gt; &#xA;   &lt;td&gt;256K&lt;/td&gt; &#xA;   &lt;td&gt;Language&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;[&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-Chat-256K&#34;&gt;Pytorch&lt;/a&gt;][&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-Chat-256K-Jax&#34;&gt;Jax&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LWM-Text-Chat-512K&lt;/td&gt; &#xA;   &lt;td&gt;512K&lt;/td&gt; &#xA;   &lt;td&gt;Language&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;[&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-Chat-512K&#34;&gt;Pytorch&lt;/a&gt;][&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-Chat-512K-Jax&#34;&gt;Jax&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LWM-Text-Chat-1M&lt;/td&gt; &#xA;   &lt;td&gt;1M&lt;/td&gt; &#xA;   &lt;td&gt;Language&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;[&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-Chat-1M&#34;&gt;Pytorch&lt;/a&gt;][&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-Chat-1M-Jax&#34;&gt;Jax&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LWM-Text-128K&lt;/td&gt; &#xA;   &lt;td&gt;128K&lt;/td&gt; &#xA;   &lt;td&gt;Language&lt;/td&gt; &#xA;   &lt;td&gt;Base&lt;/td&gt; &#xA;   &lt;td&gt;[&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-128K&#34;&gt;Pytorch&lt;/a&gt;][&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-128K-Jax&#34;&gt;Jax&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LWM-Text-256K&lt;/td&gt; &#xA;   &lt;td&gt;256K&lt;/td&gt; &#xA;   &lt;td&gt;Language&lt;/td&gt; &#xA;   &lt;td&gt;Base&lt;/td&gt; &#xA;   &lt;td&gt;[&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-256K&#34;&gt;Pytorch&lt;/a&gt;][&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-256K-Jax&#34;&gt;Jax&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LWM-Text-512K&lt;/td&gt; &#xA;   &lt;td&gt;512K&lt;/td&gt; &#xA;   &lt;td&gt;Language&lt;/td&gt; &#xA;   &lt;td&gt;Base&lt;/td&gt; &#xA;   &lt;td&gt;[&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-512K&#34;&gt;Pytorch&lt;/a&gt;][&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-512K-Jax&#34;&gt;Jax&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LWM-Text-1M&lt;/td&gt; &#xA;   &lt;td&gt;1M&lt;/td&gt; &#xA;   &lt;td&gt;Language&lt;/td&gt; &#xA;   &lt;td&gt;Base&lt;/td&gt; &#xA;   &lt;td&gt;[&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-1M&#34;&gt;Pytorch&lt;/a&gt;][&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-Text-1M-Jax&#34;&gt;Jax&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LWM-Chat-32K&lt;/td&gt; &#xA;   &lt;td&gt;32K&lt;/td&gt; &#xA;   &lt;td&gt;Vision-Language&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;[&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-32K-Jax&#34;&gt;Jax&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LWM-Chat-128K&lt;/td&gt; &#xA;   &lt;td&gt;128K&lt;/td&gt; &#xA;   &lt;td&gt;Vision-Language&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;[&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-128K-Jax&#34;&gt;Jax&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LWM-Chat-1M&lt;/td&gt; &#xA;   &lt;td&gt;1M&lt;/td&gt; &#xA;   &lt;td&gt;Vision-Language&lt;/td&gt; &#xA;   &lt;td&gt;Chat&lt;/td&gt; &#xA;   &lt;td&gt;[&lt;a href=&#34;https://huggingface.co/LargeWorldModel/LWM-1M-Jax&#34;&gt;Jax&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Code structure&lt;/h2&gt; &#xA;&lt;p&gt;Use &lt;code&gt;scan_query_chunk_size&lt;/code&gt; and &lt;code&gt;scan_key_chunk_size&lt;/code&gt; to control the block size in blockwise compute of the self-attention. Use &lt;code&gt;scan_mlp_chunk_size&lt;/code&gt; to control the block size in blockwise compute of the feedforward network. Use &lt;code&gt;scan_attention=True&lt;/code&gt; and &lt;code&gt;scan_mlp=True&lt;/code&gt; to enable/disable blockwise compute in the self-attention and feed-forward network. Use &lt;code&gt;remat_attention&lt;/code&gt; and &lt;code&gt;remat_mlp&lt;/code&gt; to control the rematerialization policy with &lt;code&gt;nothing_saveable&lt;/code&gt; recommended.&lt;/p&gt; &#xA;&lt;p&gt;You can use &lt;code&gt;mesh_dim=dp, fsdp, tp, sp&lt;/code&gt; to control the degree of parallelism and RingAttention. It is a string of 4 integers separated by commas, representing the number of data parallelism, fully sharded data parallelism, tensor parallelism, and sequence parallelism. For example, &lt;code&gt;mesh_dim=&#39;1,64,4,1&#39;&lt;/code&gt; means 1 data parallelism, 64 fully sharded data parallelism, 4 tensor parallelism, and 1 sequence parallelism. &lt;code&gt;mesh_dim=&#39;1,1,4,64&#39;&lt;/code&gt; means 1 data parallelism, 1 fully sharded data parallelism, 4 tensor parallelism, and 64 sequence parallelism for RingAttention.&lt;/p&gt; &#xA;&lt;h2&gt;Command-line usage&lt;/h2&gt; &#xA;&lt;p&gt;In this section, we provide instructions on how to run each of the provided scripts. For each script, you may need to fill in your own paths and values in the variables described in the beginning of each script.&lt;/p&gt; &#xA;&lt;p&gt;To run each of the following scripts, use &lt;code&gt;bash &amp;lt;script_name&amp;gt;.sh&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Language model training: &lt;code&gt;bash scripts/run_train_text.sh&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Vision-Language model training: &lt;code&gt;bash scripts/run_train_vision_text.sh&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Single Needle Evals (Language Model): &lt;code&gt;bash scripts/run_eval_needle.sh&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Multi Needle Evals (Language Model): &lt;code&gt;bash scripts/run_eval_needle_multi.sh&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Sampling images (Vision-Language Model): &lt;code&gt;bash scripts/run_sample_image.sh&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Sampling videos (Vision-LanguageModel): &lt;code&gt;bash scripts/run_sample_video.sh&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Image / Video understanding (Vision-Language Model): &lt;code&gt;bash scripts/run_vision_chat.sh&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;If you have issues&lt;/h2&gt; &#xA;&lt;p&gt;This is based on the &lt;a href=&#34;https://github.com/lhao499/ring-attention&#34;&gt;codebase&lt;/a&gt; of BPT and RingAttention, with the necessary features for vision-language training. The training and inference have been tested on both TPUv3 and TPUv4.&lt;/p&gt; &#xA;&lt;p&gt;If you encounter bugs, please open a GitHub issue!&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you use this codebase, or otherwise found our work valuable, please cite:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{liu2023world,&#xA;    title={World Model on Million-Length Video and Language with RingAttention},&#xA;    author={Liu, Hao and Yan, Wilson and Zaharia, Matei and Abbeel, Pieter},&#xA;    journal={arXiv preprint},&#xA;    year={2024},&#xA;}&#xA;@article{liu2023ring,&#xA;    title={Ring Attention with Blockwise Transformers for Near-Infinite Context},&#xA;    author={Liu, Hao and Zaharia, Matei and Abbeel, Pieter},&#xA;    journal={International Conference on Learning Representations},&#xA;    year={2024}&#xA;}&#xA;@article{liu2023blockwise,&#xA;    title={Blockwise Parallel Transformer for Large Context Models},&#xA;    author={Liu, Hao and Abbeel, Pieter},&#xA;    journal={Advances in neural information processing systems},&#xA;    year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;LWM&#39;s code and model weights are released under the Apache 2.0 License. See &lt;a href=&#34;https://github.com/LargeWorldModel/lwm/raw/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for further details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>google/generative-ai-dart</title>
    <updated>2024-02-18T01:25:06Z</updated>
    <id>tag:github.com,2024-02-18:/google/generative-ai-dart</id>
    <link href="https://github.com/google/generative-ai-dart" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Google AI SDK for Dart&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Google Generative AI SDK for Dart&lt;/h1&gt; &#xA;&lt;p&gt;The Google Generative AI SDK for Dart allows developers to use state-of-the-art Large Language Models (LLMs) to build language applications.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;API keys&lt;/h3&gt; &#xA;&lt;p&gt;To use the Gemini API, you&#39;ll need an API key. If you don&#39;t already have one, create a key in Google AI Studio: &lt;a href=&#34;https://makersuite.google.com/app/apikey&#34;&gt;https://makersuite.google.com/app/apikey&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Dart samples&lt;/h3&gt; &#xA;&lt;p&gt;See the Dart sample apps at &lt;a href=&#34;https://raw.githubusercontent.com/google/generative-ai-dart/main/samples/dart/&#34;&gt;samples/dart&lt;/a&gt;, including some getting started instructions.&lt;/p&gt; &#xA;&lt;h3&gt;Flutter sample&lt;/h3&gt; &#xA;&lt;p&gt;See a Flutter sample app at &lt;a href=&#34;https://raw.githubusercontent.com/google/generative-ai-dart/main/samples/flutter_app/&#34;&gt;samples/flutter_app&lt;/a&gt;, including some getting started instructions.&lt;/p&gt; &#xA;&lt;h2&gt;Using the SDK in your own app&lt;/h2&gt; &#xA;&lt;p&gt;Add a dependency on the &lt;code&gt;package:google_generative_ai&lt;/code&gt; package via:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;dart pub add google_generative_ai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;flutter pub add google_generative_ai&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Initializing the API client&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;final model = GenerativeModel(model: &#39;gemini-pro&#39;, apiKey: apiKey);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Calling the API&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-dart&#34;&gt;final prompt = &#39;Do these look store-bought or homemade?&#39;;&#xA;final imageBytes = await File(&#39;cookie.png&#39;).readAsBytes();&#xA;final content = [&#xA;  Content.multi([&#xA;    TextPart(prompt),&#xA;    DataPart(&#39;image/png&#39;, imageBytes),&#xA;  ])&#xA;];&#xA;&#xA;final response = await model.generateContent(content);&#xA;print(response.text);&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Find complete documentation for the Google AI SDKs and the Gemini model in the Google documentation: &lt;a href=&#34;https://ai.google.dev/docs&#34;&gt;https://ai.google.dev/docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Packages&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Package&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Version&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/generative-ai-dart/main/pkgs/google_generative_ai/&#34;&gt;google_generative_ai&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The Google Generative AI SDK for Dart - allows access to state-of-the-art LLMs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://pub.dev/packages/google_generative_ai&#34;&gt;&lt;img src=&#34;https://img.shields.io/pub/v/google_generative_ai.svg?sanitize=true&#34; alt=&#34;pub package&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/generative-ai-dart/main/samples/dart/&#34;&gt;samples/dart&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Dart samples for &lt;code&gt;package:google_generative_ai&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/generative-ai-dart/main/samples/flutter_app/&#34;&gt;samples/flutter_app&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A Flutter sample for &lt;code&gt;package:google_generative_ai&lt;/code&gt;.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/google/generative-ai-dart/main/CONTRIBUTING.md&#34;&gt;Contributing&lt;/a&gt; for more information on contributing to the Generative AI SDK for Dart.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The contents of this repository are licensed under the &lt;a href=&#34;http://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache License, version 2.0&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>