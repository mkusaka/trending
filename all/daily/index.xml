<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-14T01:28:13Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>togethercomputer/OpenChatKit</title>
    <updated>2023-03-14T01:28:13Z</updated>
    <id>tag:github.com,2023-03-14:/togethercomputer/OpenChatKit</id>
    <link href="https://github.com/togethercomputer/OpenChatKit" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OpenChatKit&lt;/h1&gt; &#xA;&lt;p&gt;OpenChatKit provides a powerful, open-source base to create both specialized and general purpose chatbots for various applications. The kit includes an instruction-tuned 20 billion parameter language model, a 6 billion parameter moderation model, and an extensible retrieval system for including up-to-date responses from custom repositories. It was trained on the OIG-43M training dataset, which was a collaboration between &lt;a href=&#34;https://www.together.xyz/&#34;&gt;Together&lt;/a&gt;, &lt;a href=&#34;https://laion.ai&#34;&gt;LAION&lt;/a&gt;, and &lt;a href=&#34;https://ontocord.ai&#34;&gt;Ontocord.ai&lt;/a&gt;. Much more than a model release, this is the beginning of an open source project. We are releasing a set of tools and processes for ongoing improvement with community contributions.&lt;/p&gt; &#xA;&lt;p&gt;In this repo, you&#39;ll find code for:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Training an OpenChatKit model&lt;/li&gt; &#xA; &lt;li&gt;Testing inference using the model&lt;/li&gt; &#xA; &lt;li&gt;Augmenting the model with additional context from a retrieval index&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Contents&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#requirements&#34;&gt;Requirements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#pre-trained-weights&#34;&gt;Pre-trained Weights&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#datasets&#34;&gt;Datasets&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#data-contributions&#34;&gt;Data Contributions&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#pretrained-base-model&#34;&gt;Pretrained Base Model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#training-and-finetuning&#34;&gt;Training and Finetuning&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#optional-8bit-adam&#34;&gt;(Optional) 8bit Adam&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#train-gpt-neox-chat-base-20b&#34;&gt;Train GPT-NeoX-Chat-Base-20B&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#converting-weights-to-huggingface-format&#34;&gt;Converting Weights to Huggingface Format&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#inference&#34;&gt;Inference&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#monitoring&#34;&gt;Monitoring&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#loguru&#34;&gt;Loguru&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#weights--biases&#34;&gt;Weights &amp;amp; Biases&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#experimental-retrieval-augmented-models&#34;&gt;Experimental: Retrieval-Augmented Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#citing-openchatkit&#34;&gt;Citing OpenChatKit&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/#acknowledgements&#34;&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Requirements&lt;/h1&gt; &#xA;&lt;p&gt;Before you begin, you need to install PyTorch and other dependencies.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://docs.conda.io/en/latest/miniconda.html&#34;&gt;Miniconda&lt;/a&gt; from their website.&lt;/li&gt; &#xA; &lt;li&gt;Create an environment called OpenChatKit using the &lt;code&gt;environment.yml&lt;/code&gt; file at the root of this repo.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda env create -f environment.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This repo also uses &lt;a href=&#34;https://git-lfs.com/&#34;&gt;Git LFS&lt;/a&gt; to manage some files. Install it using the instructions on their site then run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git lfs install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Pre-trained Weights&lt;/h1&gt; &#xA;&lt;p&gt;GPT-NeoXT-Chat-Base-20B is a 20B-parameter variant of GPT-NeoX, fine-tuned on conversational datasets. We are releasing pre-trained weights for this model as &lt;a href=&#34;https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B&#34;&gt;togethercomputer/GPT-NeoXT-Chat-Base-20B&lt;/a&gt; on Huggingface.&lt;/p&gt; &#xA;&lt;p&gt;More details can be found on the model card for &lt;a href=&#34;https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B&#34;&gt;GPT-NeoXT-Chat-Base-20B&lt;/a&gt; on Huggingface.&lt;/p&gt; &#xA;&lt;h1&gt;Datasets&lt;/h1&gt; &#xA;&lt;p&gt;The chat model was trained on the &lt;a href=&#34;https://huggingface.co/datasets/laion/OIG&#34;&gt;OIG&lt;/a&gt; dataset built by &lt;a href=&#34;https://laion.ai/&#34;&gt;LAION&lt;/a&gt;, &lt;a href=&#34;https://www.together.xyz/&#34;&gt;Together&lt;/a&gt;, and &lt;a href=&#34;https://www.ontocord.ai/&#34;&gt;Ontocord.ai&lt;/a&gt;. To download the dataset from Huggingface run the command below from the root of the repo.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python data/OIG/prepare.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once the command completes, the data will be in the &lt;code&gt;data/OIG/files&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;h2&gt;Data Contributions&lt;/h2&gt; &#xA;&lt;p&gt;You can help make this chat model better by contributing data! See the &lt;a href=&#34;https://github.com/togethercomputer/OpenDataHub&#34;&gt;OpenDataHub&lt;/a&gt; repo for more details.&lt;/p&gt; &#xA;&lt;h1&gt;Pretrained Base Model&lt;/h1&gt; &#xA;&lt;p&gt;As mentioned above, the chat model is a fine-tuned variant of GPT-NeoX-20B from Eleuther AI. To download GPT-NeoX-20B and prepare it for fine tuning, run this command from the root of the repo.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python pretrained/GPT-NeoX-20B/prepare.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The weights for this model will be in the &lt;code&gt;pretrained/GPT-NeoX-20B/EleutherAI_gpt-neox-20b&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Training and Finetuning&lt;/h1&gt; &#xA;&lt;h2&gt;(Optional) 8bit Adam&lt;/h2&gt; &#xA;&lt;p&gt;To use 8bit-adam during training, install the &lt;code&gt;bitsandbytes&lt;/code&gt; package.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install bitsandbytes # optional, to use 8bit-adam&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Train GPT-NeoX-Chat-Base-20B&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;training/finetune_GPT-NeoXT-Chat-Base-20B.sh&lt;/code&gt; script configures and runs the training loop. After downloading the dataset and the base model, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bash training/finetune_GPT-NeoXT-Chat-Base-20B.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The script launches 8 processes with a pipeline-parallel degree of 8 and a data-parallel degree of 1.&lt;/p&gt; &#xA;&lt;p&gt;As the training loop runs, checkpoints are saved to the &lt;code&gt;model_ckpts&lt;/code&gt; directory at the root of the repo.&lt;/p&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://raw.githubusercontent.com/togethercomputer/OpenChatKit/main/training/README.md&#34;&gt;the training README&lt;/a&gt; for more details about customizing the training run.&lt;/p&gt; &#xA;&lt;h1&gt;Converting Weights to Huggingface Format&lt;/h1&gt; &#xA;&lt;p&gt;Before you can use this model to perform inference, it must be converted to the Hugginface format.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir huggingface_models \&#xA;&amp;amp;&amp;amp; python tools/convert_to_hf_gptneox.py \&#xA;     --ckpt-path model_ckpts/GPT-Neo-XT-Chat-Base-20B/checkpoint_5 &#xA;     --save-path /huggingface_models/GPT-NeoXT-Chat-Base-20B &#xA;     --n-stages 8 &#xA;     --n-layer-per-stage 6&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Inference&lt;/h1&gt; &#xA;&lt;p&gt;To help you test the model, we provide a simple test command line test harness to interact with the bot.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python inference/bot.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default the script will load the model named GPT-NeoXT-Chat-Base-20B model under the &lt;code&gt;huggingface_models&lt;/code&gt; directory, but you can override that behavior by specifying &lt;code&gt;--model&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For example, if you want to load the base model from our Huggingface, repo, you can run the following command which downloads the weights from HuggingFace.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python inference/bot.py --model togethercomputer/GPT-NeoXT-Chat-Base-20B&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once the model has loaded, enter text at the prompt and the model will reply.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ python inference/bot.py &#xA;Loading /home/csris/src/github.com/togethercomputer/OpenChatKit/inference/../huggingface_models/GPT-NeoXT-Chat-Base-20B to cuda:1...&#xA;Welcome to OpenChatKit shell.   Type /help or /? to list commands.&#xA;&#xA;&amp;gt;&amp;gt;&amp;gt; Hello.&#xA;Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.&#xA;Hello human.&#xA;&#xA;&amp;gt;&amp;gt;&amp;gt; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Commands are prefixed with a &lt;code&gt;/&lt;/code&gt;, and the &lt;code&gt;/quit&lt;/code&gt; command exits.&lt;/p&gt; &#xA;&lt;h1&gt;Monitoring&lt;/h1&gt; &#xA;&lt;p&gt;By default, the training script simply prints the loss as training proceeds, but it can also output metrics to a file using &lt;a href=&#34;https://github.com/Delgan/loguru&#34;&gt;loguru&lt;/a&gt; or report them to Weights &amp;amp; Biases.&lt;/p&gt; &#xA;&lt;h2&gt;Loguru&lt;/h2&gt; &#xA;&lt;p&gt;Add the flag &lt;code&gt;--train-log-backend loguru&lt;/code&gt; to your training script to log to &lt;code&gt;./logs/file_{time}.log&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Weights &amp;amp; Biases&lt;/h2&gt; &#xA;&lt;p&gt;To use Weights &amp;amp; Biases, first login with your Weights &amp;amp; Biases token.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;wandb login&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And set &lt;code&gt;--train-log-backend wandb&lt;/code&gt; in the training script to enable logging to Weights &amp;amp; Biases.&lt;/p&gt; &#xA;&lt;h1&gt;Experimental: Retrieval-Augmented Models&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;Note: Retrieval is still experimental.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;The code in &lt;code&gt;/retrieval&lt;/code&gt; implements a python package for querying a Faiss index of Wikipedia. The following steps explain how to use this index to augment queries in the test harness with context from the retriever.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download the Wikipedia index.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python data/wikipedia-3sentence-level-retrieval-index/prepare.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Run the bot with the &lt;code&gt;--retrieval&lt;/code&gt; flag.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python inference/bot.py --retrieval&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After starting, the bot will load both the chat model and the retrieval index, which takes a long time. Once the model and the index are loaded, all queries will be augmented with extra context.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ python inference/bot.py --retrieval&#xA;Loading /OpenChatKit/inference/../huggingface_models/GPT-NeoXT-Chat-Base-20B to cuda:0...&#xA;Loading retrieval index...&#xA;Welcome to OpenChatKit shell.   Type /help or /? to list commands.&#xA;&#xA;&amp;gt;&amp;gt;&amp;gt; Where is Zurich?&#xA;Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.&#xA;Where is Zurich?&#xA;Zurich is located in Switzerland.&#xA;&#xA;&amp;gt;&amp;gt;&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;All code in this repository was developed by Together Computer except where otherwise noted. Copyright (c) 2023, Together Computer. All rights reserved. The code is licensed under the Apache 2.0 license.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Copyright 2023 Together Computer&#xA;&#xA;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);&#xA;you may not use this file except in compliance with the License.&#xA;You may obtain a copy of the License at&#xA;&#xA;   http://www.apache.org/licenses/LICENSE-2.0&#xA;&#xA;Unless required by applicable law or agreed to in writing, software&#xA;distributed under the License is distributed on an &#34;AS IS&#34; BASIS,&#xA;WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&#xA;See the License for the specific language governing permissions and&#xA;limitations under the License.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This repository also contains code written by a number of other authors. Such contributions are marked and the relevant licensing is included where appropriate.&lt;/p&gt; &#xA;&lt;p&gt;For full terms, see the LICENSE file. If you have any questions, comments, or concerns about licensing please &lt;a href=&#34;https://www.together.xyz/contact&#34;&gt;contact us&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Citing OpenChatKit&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@software{openchatkit,&#xA;  title = {{OpenChatKit: An Open Toolkit and Base Model for Dialogue-style Applications}},&#xA;  author = {Together Computer},&#xA;  url = {https://github.com/togethercomputer/OpenChatKit}&#xA;  month = {3},&#xA;  year = {2023},&#xA;  version = {0.15},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Acknowledgements&lt;/h1&gt; &#xA;&lt;p&gt;Our model is a fine-tuned version of &lt;a href=&#34;https://huggingface.co/EleutherAI/gpt-neox-20b&#34;&gt;gpt-neox-20b&lt;/a&gt;, a large language model trained by &lt;a href=&#34;https://www.eleuther.ai&#34;&gt;Eleuther AI&lt;/a&gt;. We evaluated our model on &lt;a href=&#34;https://crfm.stanford.edu/helm/latest/&#34;&gt;HELM&lt;/a&gt; provided by the &lt;a href=&#34;https://crfm.stanford.edu&#34;&gt;Center for Research on Foundation Models&lt;/a&gt;. And we collaborated with both &lt;a href=&#34;https://crfm.stanford.edu&#34;&gt;CRFM&lt;/a&gt; and &lt;a href=&#34;http://hazyresearch.stanford.edu&#34;&gt;HazyResearch&lt;/a&gt; at Stanford to build this model.&lt;/p&gt; &#xA;&lt;p&gt;We collaborated with &lt;a href=&#34;https://laion.ai/&#34;&gt;LAION&lt;/a&gt; and &lt;a href=&#34;https://www.ontocord.ai/&#34;&gt;Ontocord.ai&lt;/a&gt; to build the training data used to fine tune this model.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>davinci1012/pinduoduo_backdoor_unpacker</title>
    <updated>2023-03-14T01:28:13Z</updated>
    <id>tag:github.com,2023-03-14:/davinci1012/pinduoduo_backdoor_unpacker</id>
    <link href="https://github.com/davinci1012/pinduoduo_backdoor_unpacker" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Samples and Unpacker of malicious backdoors and exploits developed and used by Pinduoduo&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Pinduoduo恶意代码样本和脱壳机&lt;/h1&gt; &#xA;&lt;p&gt;听说PDD今天开始发律师函删帖抵赖了&lt;img src=&#34;https://user-images.githubusercontent.com/25000885/224233765-5195f16a-f41c-482f-a664-1cf72796651e.png&#34; alt=&#34;PDDNB&#34;&gt;，那就放点新东西出来。&lt;/p&gt; &#xA;&lt;p&gt;拼多多的两个壳，manwe和nvwa之一的manwe脱壳脚本。适用于样本中.mw1文件。.nw0要用nvwa脱壳脚本，过会再放，manwe里面基本已经足够看了。&lt;/p&gt; &#xA;&lt;h2&gt;拼多多manwe一键脱壳脚本&lt;/h2&gt; &#xA;&lt;p&gt;代码在&lt;code&gt;manwe_unpacker&lt;/code&gt;目录，用法如下，或自己改路径：&lt;/p&gt; &#xA;&lt;p&gt;/tmp/mw1.bin放解压出来的文件，在&lt;code&gt;/tmp/final_java/&lt;/code&gt;会生成脱壳后的java class文件，压缩一下拖到jadx里看。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ManweVmpLoader {&#xA;    public static void main(String[] args) throws Throwable {&#xA;        String firmwarePath = &#34;/tmp/mw1.bin&#34;;&#xA;        ManweVmpDataInputStream inputStream = new ManweVmpDataInputStream(Files.newInputStream(Paths.get(firmwarePath)));&#xA;        ManweVmpDex manweVmpDex = new ManweVmpDex(inputStream);&#xA;        System.out.printf(&#34;Load %d class%n&#34;, manweVmpDex.manweVmpClazzes.length);&#xA;        if (inputStream.available() != 0) {&#xA;            throw new RuntimeException(String.format(&#34;%d bytes remaining&#34;, inputStream.available()));&#xA;        }&#xA;        inputStream.close();&#xA;        if (Files.notExists(Paths.get(&#34;/tmp/final_java/&#34;))) {&#xA;            new File(&#34;/tmp/final_java/&#34;).mkdirs();&#xA;        }&#xA;        manweVmpDex.writeClazzes(&#34;/tmp/final_java/&#34;);&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;提取出的恶意样本&lt;/h2&gt; &#xA;&lt;p&gt;PDD的恶意代码以加壳后的文件形式组织，APK自带AliveBaseAbility，其他的都是远程下发，以下称为“样本”。因为有些样本是动态下发，不一定全，如果有这里没有的，欢迎Pull Request补充。&lt;/p&gt; &#xA;&lt;p&gt;样本在samples目录中，包含PDD APK自带的样本，以及其动态下发的样本。动态样本为3.2日之前从安装了PDD的手机里/data/data/com.xunmeng.pinduoduo/files/bot/, /data/data/com.xunmeng.pinduoduo/files/.components/提取出，现在新版本可能被PDD删掉了，有兴趣的可以找下装了之前的版本的手机看下，顺便看下&lt;code&gt;app_mango&lt;/code&gt;目录，里面是配置文件，有惊喜。&lt;/p&gt; &#xA;&lt;p&gt;带符号的样本为PDD 6.2.0提取出(&lt;code&gt;samples/old_alive_base_ability_with_symbol/mw1.bin&lt;/code&gt;)，新版本的APP携带的样本去掉了符号。&lt;/p&gt; &#xA;&lt;p&gt;样本各个都是干货，值得看看。AliveBaseAbility是第一步，davinci仓库中提到的dex只是这个evil plan的第三步，这里其他的是第二步。&lt;/p&gt; &#xA;&lt;h2&gt;其他&lt;/h2&gt; &#xA;&lt;p&gt;一视同仁，平等对待才是好的营商环境，纵容、包庇不是。 据说PDD搞这个的100多号人的团队连夜解散了，删库跑路，是吗？又听说PDD这些漏洞手段被曝光停了之后，DAU出现明显下跌，是吗？ 等下，有人敲门说查水表了，我先出&lt;/p&gt; &#xA;&lt;h2&gt;免责声明&lt;/h2&gt; &#xA;&lt;p&gt;仅用于研究用途，禁止和PDD一样作恶，没靠山别学&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>neovim/neovim</title>
    <updated>2023-03-14T01:28:13Z</updated>
    <id>tag:github.com,2023-03-14:/neovim/neovim</id>
    <link href="https://github.com/neovim/neovim" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Vim-fork focused on extensibility and usability&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/neovim/neovim.github.io/master/logos/neovim-logo-300x87.png&#34; alt=&#34;Neovim&#34;&gt; &lt;p&gt;&lt;a href=&#34;https://neovim.io/doc/&#34;&gt;Documentation&lt;/a&gt; | &lt;a href=&#34;https://app.element.io/#/room/#neovim:matrix.org&#34;&gt;Chat&lt;/a&gt;&lt;/p&gt; &lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://scan.coverity.com/projects/2227&#34;&gt;&lt;img src=&#34;https://scan.coverity.com/projects/2227/badge.svg?sanitize=true&#34; alt=&#34;Coverity Scan analysis&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://neovim.io/doc/reports/clang&#34;&gt;&lt;img src=&#34;https://neovim.io/doc/reports/clang/badge.svg?sanitize=true&#34; alt=&#34;Clang analysis&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://neovim.io/doc/reports/pvs/PVS-studio.html.d&#34;&gt;&lt;img src=&#34;https://neovim.io/doc/reports/pvs/badge.svg?sanitize=true&#34; alt=&#34;PVS-Studio analysis&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://repology.org/metapackage/neovim&#34;&gt;&lt;img src=&#34;https://repology.org/badge/tiny-repos/neovim.svg?sanitize=true&#34; alt=&#34;Packages&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://buildd.debian.org/neovim&#34;&gt;&lt;img src=&#34;https://badges.debian.net/badges/debian/testing/neovim/version.svg?sanitize=true&#34; alt=&#34;Debian CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/neovim/neovim/releases/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/downloads/neovim/neovim/total.svg?maxAge=2592001&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Neovim is a project that seeks to aggressively refactor &lt;a href=&#34;https://www.vim.org/&#34;&gt;Vim&lt;/a&gt; in order to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Simplify maintenance and encourage &lt;a href=&#34;https://raw.githubusercontent.com/neovim/neovim/master/CONTRIBUTING.md&#34;&gt;contributions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Split the work between multiple developers&lt;/li&gt; &#xA; &lt;li&gt;Enable &lt;a href=&#34;https://github.com/neovim/neovim/wiki/Related-projects#gui&#34;&gt;advanced UIs&lt;/a&gt; without modifications to the core&lt;/li&gt; &#xA; &lt;li&gt;Maximize &lt;a href=&#34;https://github.com/neovim/neovim/wiki/Plugin-UI-architecture&#34;&gt;extensibility&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://github.com/neovim/neovim/wiki/Introduction&#34;&gt;Introduction&lt;/a&gt; wiki page and &lt;a href=&#34;https://neovim.io/roadmap/&#34;&gt;Roadmap&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Modern &lt;a href=&#34;https://github.com/neovim/neovim/wiki/Related-projects#gui&#34;&gt;GUIs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/neovim/neovim/wiki/Related-projects#api-clients&#34;&gt;API access&lt;/a&gt; from any language including C/C++, C#, Clojure, D, Elixir, Go, Haskell, Java/Kotlin, JavaScript/Node.js, Julia, Lisp, Lua, Perl, Python, Racket, Ruby, Rust&lt;/li&gt; &#xA; &lt;li&gt;Embedded, scriptable &lt;a href=&#34;https://neovim.io/doc/user/nvim_terminal_emulator.html&#34;&gt;terminal emulator&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Asynchronous &lt;a href=&#34;https://github.com/neovim/neovim/pull/2247&#34;&gt;job control&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/neovim/neovim/pull/2506&#34;&gt;Shared data (shada)&lt;/a&gt; among multiple editor instances&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/neovim/neovim/pull/3470&#34;&gt;XDG base directories&lt;/a&gt; support&lt;/li&gt; &#xA; &lt;li&gt;Compatible with most Vim plugins, including Ruby and Python plugins&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://neovim.io/doc/user/vim_diff.html#nvim-features&#34;&gt;&lt;code&gt;:help nvim-features&lt;/code&gt;&lt;/a&gt; for the full list, and &lt;a href=&#34;https://neovim.io/doc/user/news.html&#34;&gt;&lt;code&gt;:help news&lt;/code&gt;&lt;/a&gt; for noteworthy changes in the latest version!&lt;/p&gt; &#xA;&lt;h2&gt;Install from package&lt;/h2&gt; &#xA;&lt;p&gt;Pre-built packages for Windows, macOS, and Linux are found on the &lt;a href=&#34;https://github.com/neovim/neovim/releases/&#34;&gt;Releases&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/neovim/neovim/wiki/Installing-Neovim#install-from-package&#34;&gt;Managed packages&lt;/a&gt; are in &lt;a href=&#34;https://formulae.brew.sh/formula/neovim&#34;&gt;Homebrew&lt;/a&gt;, &lt;a href=&#34;https://packages.debian.org/testing/neovim&#34;&gt;Debian&lt;/a&gt;, &lt;a href=&#34;https://packages.ubuntu.com/search?keywords=neovim&#34;&gt;Ubuntu&lt;/a&gt;, &lt;a href=&#34;https://packages.fedoraproject.org/pkgs/neovim/neovim/&#34;&gt;Fedora&lt;/a&gt;, &lt;a href=&#34;https://www.archlinux.org/packages/?q=neovim&#34;&gt;Arch Linux&lt;/a&gt;, &lt;a href=&#34;https://voidlinux.org/packages/?arch=x86_64&amp;amp;q=neovim&#34;&gt;Void Linux&lt;/a&gt;, &lt;a href=&#34;https://packages.gentoo.org/packages/app-editors/neovim&#34;&gt;Gentoo&lt;/a&gt;, and more!&lt;/p&gt; &#xA;&lt;h2&gt;Install from source&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://github.com/neovim/neovim/wiki/Building-Neovim&#34;&gt;Building Neovim&lt;/a&gt; wiki page and &lt;a href=&#34;https://neovim.io/doc/user/support.html#supported-platforms&#34;&gt;supported platforms&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;p&gt;The build is CMake-based, but a Makefile is provided as a convenience. After installing the dependencies, run the following command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make CMAKE_BUILD_TYPE=RelWithDebInfo&#xA;sudo make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To install to a non-default location:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make CMAKE_BUILD_TYPE=RelWithDebInfo CMAKE_INSTALL_PREFIX=/full/path/&#xA;make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;CMake hints for inspecting the build:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;cmake --build build --target help&lt;/code&gt; lists all build targets.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;build/CMakeCache.txt&lt;/code&gt; (or &lt;code&gt;cmake -LAH build/&lt;/code&gt;) contains the resolved values of all CMake variables.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;build/compile_commands.json&lt;/code&gt; shows the full compiler invocations for each translation unit.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Transitioning from Vim&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://neovim.io/doc/user/nvim.html#nvim-from-vim&#34;&gt;&lt;code&gt;:help nvim-from-vim&lt;/code&gt;&lt;/a&gt; for instructions.&lt;/p&gt; &#xA;&lt;h2&gt;Project layout&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;├─ cmake/           CMake utils&#xA;├─ cmake.config/    CMake defines&#xA;├─ cmake.deps/      subproject to fetch and build dependencies (optional)&#xA;├─ runtime/         plugins and docs&#xA;├─ src/nvim/        application source code (see src/nvim/README.md)&#xA;│  ├─ api/          API subsystem&#xA;│  ├─ eval/         VimL subsystem&#xA;│  ├─ event/        event-loop subsystem&#xA;│  ├─ generators/   code generation (pre-compilation)&#xA;│  ├─ lib/          generic data structures&#xA;│  ├─ lua/          Lua subsystem&#xA;│  ├─ msgpack_rpc/  RPC subsystem&#xA;│  ├─ os/           low-level platform code&#xA;│  └─ tui/          built-in UI&#xA;└─ test/            tests (see test/README.md)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Neovim contributions since &lt;a href=&#34;https://github.com/neovim/neovim/commit/b17d9691a24099c9210289f16afb1a498a89d803&#34;&gt;b17d96&lt;/a&gt; are licensed under the Apache 2.0 license, except for contributions copied from Vim (identified by the &lt;code&gt;vim-patch&lt;/code&gt; token). See LICENSE for details.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Vim is Charityware.  You can use and copy it as much as you like, but you are&#xA;encouraged to make a donation for needy children in Uganda.  Please see the&#xA;kcc section of the vim docs or visit the ICCF web site, available at these URLs:&#xA;&#xA;        https://iccf-holland.org/&#xA;        https://www.vim.org/iccf/&#xA;        https://www.iccf.nl/&#xA;&#xA;You can also sponsor the development of Vim.  Vim sponsors can vote for&#xA;features.  The money goes to Uganda anyway.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- vim: set tw=80: --&gt;</summary>
  </entry>
</feed>