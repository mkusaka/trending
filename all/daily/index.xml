<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-14T01:30:42Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>baichuan-inc/Baichuan-13B</title>
    <updated>2023-07-14T01:30:42Z</updated>
    <id>tag:github.com,2023-07-14:/baichuan-inc/Baichuan-13B</id>
    <link href="https://github.com/baichuan-inc/Baichuan-13B" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A 13B large language model developed by Baichuan Intelligent Technology&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt; Baichuan-13B &lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;p align=&#34;center&#34;&gt; ğŸ¤— &lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan-13B-Base&#34; target=&#34;_blank&#34;&gt;Baichuan-13B-Base&lt;/a&gt; â€¢ ğŸ¤— &lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan-13B-Chat&#34; target=&#34;_blank&#34;&gt;Baichuan-13B-Chat&lt;/a&gt; â€¢ ğŸ¤– &lt;a href=&#34;https://modelscope.cn/organization/baichuan-inc&#34; target=&#34;_blank&#34;&gt;ModelScope&lt;/a&gt; â€¢ ğŸ’¬ &lt;a href=&#34;https://github.com/baichuan-inc/Baichuan-13B/raw/main/media/wechat.jpeg?raw=true&#34; target=&#34;_blank&#34;&gt;WeChat&lt;/a&gt; &lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/Baichuan-inc/baichuan-13B/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/modelscope/modelscope.svg?sanitize=true&#34; alt=&#34;license&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;h4 align=&#34;center&#34;&gt; &lt;p&gt; &lt;b&gt;ä¸­æ–‡&lt;/b&gt; | &lt;a href=&#34;https://github.com/baichuan-inc/Baichuan-13B/raw/main/README_EN.md&#34;&gt;English&lt;/a&gt; &lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;/h4&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;ä»‹ç»&lt;/h1&gt; &#xA;&lt;p&gt;Baichuan-13B æ˜¯ç”±ç™¾å·æ™ºèƒ½ç»§ &lt;a href=&#34;https://github.com/baichuan-inc/baichuan-7B&#34;&gt;Baichuan-7B&lt;/a&gt; ä¹‹åå¼€å‘çš„åŒ…å« 130 äº¿å‚æ•°çš„å¼€æºå¯å•†ç”¨çš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œåœ¨æƒå¨çš„ä¸­æ–‡å’Œè‹±æ–‡ benchmark ä¸Šå‡å–å¾—åŒå°ºå¯¸æœ€å¥½çš„æ•ˆæœã€‚æœ¬æ¬¡å‘å¸ƒåŒ…å«æœ‰é¢„è®­ç»ƒ (&lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan-13B-Base&#34;&gt;Baichuan-13B-Base&lt;/a&gt;) å’Œå¯¹é½ (&lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan-13B-Chat&#34;&gt;Baichuan-13B-Chat&lt;/a&gt;) ä¸¤ä¸ªç‰ˆæœ¬ã€‚Baichuan-13B æœ‰å¦‚ä¸‹å‡ ä¸ªç‰¹ç‚¹ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;æ›´å¤§å°ºå¯¸ã€æ›´å¤šæ•°æ®&lt;/strong&gt;ï¼šBaichuan-13B åœ¨ &lt;a href=&#34;https://github.com/baichuan-inc/baichuan-7B&#34;&gt;Baichuan-7B&lt;/a&gt; çš„åŸºç¡€ä¸Šè¿›ä¸€æ­¥æ‰©å¤§å‚æ•°é‡åˆ° 130 äº¿ï¼Œå¹¶ä¸”åœ¨é«˜è´¨é‡çš„è¯­æ–™ä¸Šè®­ç»ƒäº† 1.4 ä¸‡äº¿ tokensï¼Œè¶…è¿‡ LLaMA-13B 40%ï¼Œæ˜¯å½“å‰å¼€æº 13B å°ºå¯¸ä¸‹è®­ç»ƒæ•°æ®é‡æœ€å¤šçš„æ¨¡å‹ã€‚æ”¯æŒä¸­è‹±åŒè¯­ï¼Œä½¿ç”¨ ALiBi ä½ç½®ç¼–ç ï¼Œä¸Šä¸‹æ–‡çª—å£é•¿åº¦ä¸º 4096ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;åŒæ—¶å¼€æºé¢„è®­ç»ƒå’Œå¯¹é½æ¨¡å‹&lt;/strong&gt;ï¼šé¢„è®­ç»ƒæ¨¡å‹æ˜¯é€‚ç”¨å¼€å‘è€…çš„ã€ åŸºåº§ ã€ï¼Œè€Œå¹¿å¤§æ™®é€šç”¨æˆ·å¯¹æœ‰å¯¹è¯åŠŸèƒ½çš„å¯¹é½æ¨¡å‹å…·æœ‰æ›´å¼ºçš„éœ€æ±‚ã€‚å› æ­¤æœ¬æ¬¡å¼€æºæˆ‘ä»¬åŒæ—¶å‘å¸ƒäº†å¯¹é½æ¨¡å‹ï¼ˆBaichuan-13B-Chatï¼‰ï¼Œå…·æœ‰å¾ˆå¼ºçš„å¯¹è¯èƒ½åŠ›ï¼Œå¼€ç®±å³ç”¨ï¼Œå‡ è¡Œä»£ç å³å¯ç®€å•çš„éƒ¨ç½²ã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;æ›´é«˜æ•ˆçš„æ¨ç†&lt;/strong&gt;ï¼šä¸ºäº†æ”¯æŒæ›´å¹¿å¤§ç”¨æˆ·çš„ä½¿ç”¨ï¼Œæˆ‘ä»¬æœ¬æ¬¡åŒæ—¶å¼€æºäº† int8 å’Œ int4 çš„é‡åŒ–ç‰ˆæœ¬ï¼Œç›¸å¯¹éé‡åŒ–ç‰ˆæœ¬åœ¨å‡ ä¹æ²¡æœ‰æ•ˆæœæŸå¤±çš„æƒ…å†µä¸‹å¤§å¤§é™ä½äº†éƒ¨ç½²çš„æœºå™¨èµ„æºé—¨æ§›ï¼Œå¯ä»¥éƒ¨ç½²åœ¨å¦‚ Nvidia 3090 è¿™æ ·çš„æ¶ˆè´¹çº§æ˜¾å¡ä¸Šã€‚&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;å¼€æºå…è´¹å¯å•†ç”¨&lt;/strong&gt;ï¼šBaichuan-13B ä¸ä»…å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ï¼Œå¼€å‘è€…ä¹Ÿä»…éœ€é‚®ä»¶ç”³è¯·å¹¶è·å¾—å®˜æ–¹å•†ç”¨è®¸å¯åï¼Œå³å¯ä»¥å…è´¹å•†ç”¨ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Benchmarkç»“æœ&lt;/h1&gt; &#xA;&lt;p&gt;æˆ‘ä»¬åœ¨å„ä¸ªæƒå¨å¤§è¯­è¨€æ¨¡å‹çš„ä¸­è‹±æ–‡ benchmark ä¸Šè¿›è¡Œäº†&lt;code&gt;5-shot&lt;/code&gt;è¯„æµ‹ã€‚ç»“æœå¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://cevalbenchmark.com/index.html#home&#34;&gt;C-Eval&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model 5-shot&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;STEM&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Social Sciences&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Humanities&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Others&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Average&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan-7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;39.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese-Alpaca-Plus-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;45.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vicuna-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese-LLaMA-Plus-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ziya-LLaMA-13B-Pretrain&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;moss-moon-003-base (16B)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Baichuan-13B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;45.9&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;63.5&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;57.2&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;49.3&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;52.4&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Baichuan-13B-Chat&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;43.7&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;64.6&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;56.2&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;49.2&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;51.5&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://arxiv.org/abs/2009.03300&#34;&gt;MMLU&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model 5-shot&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;STEM&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Social Sciences&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Humanities&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Others&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Average&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vicuna-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;60.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;58.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;36.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;53.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese-Alpaca-Plus-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;36.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;48.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;50.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;43.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ziya-LLaMA-13B-Pretrain&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan-7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;48.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;38.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;48.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese-LLaMA-Plus-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;42.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;37.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;39.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;moss-moon-003-base (16B)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;22.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;24.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;23.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Baichuan-13B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;41.6&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;60.9&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;47.4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;58.5&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;51.6&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Baichuan-13B-Chat&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;40.9&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;60.9&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;48.8&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;59.0&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;52.1&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;è¯´æ˜ï¼šæˆ‘ä»¬é‡‡ç”¨äº† MMLU å®˜æ–¹çš„&lt;a href=&#34;https://github.com/hendrycks/test&#34;&gt;è¯„æµ‹æ–¹æ¡ˆ&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/haonan-li/CMMLU&#34;&gt;CMMLU&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model 5-shot&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;STEM&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Humanities&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Social Sciences&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Others&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;China Specific&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Average&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan-7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;44.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vicuna-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;36.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;37.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;39.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.3&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;36.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese-Alpaca-Plus-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;37.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chinese-LLaMA-Plus-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;35.1&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ziya-LLaMA-13B-Pretrain&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;34.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;33.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;31.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;moss-moon-003-base (16B)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;27.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;30.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;28.7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;29.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Baichuan-13B-Base&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;41.7&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;61.1&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;59.8&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;59.0&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;56.4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;55.3&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Baichuan-13B-Chat&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;42.8&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;62.6&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;59.7&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;59.0&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;56.1&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;55.8&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;è¯´æ˜ï¼šCMMLU æ˜¯ä¸€ä¸ªç»¼åˆæ€§çš„ä¸­æ–‡è¯„ä¼°åŸºå‡†ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ä¸­æ–‡è¯­å¢ƒä¸‹çš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬é‡‡ç”¨äº†å…¶å®˜æ–¹çš„&lt;a href=&#34;https://github.com/haonan-li/CMMLU&#34;&gt;è¯„æµ‹æ–¹æ¡ˆ&lt;/a&gt;ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;æ¨¡å‹ç»†èŠ‚&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;æ¨¡å‹åç§°&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;éšè—å±‚ç»´åº¦&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;å±‚æ•°&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;æ³¨æ„åŠ›å¤´æ•°&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;è¯è¡¨å¤§å°&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;æ€»å‚æ•°é‡&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;è®­ç»ƒæ•°æ®ï¼ˆtokensï¼‰&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;ä½ç½®ç¼–ç &lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;æœ€å¤§é•¿åº¦&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan-7B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4,096&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;32&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;64,000&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7,000,559,616&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.2 ä¸‡äº¿&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2104.09864&#34;&gt;RoPE&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4,096&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5,120&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;40&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;64,000&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;13,264,901,120&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1.4 ä¸‡äº¿&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2108.12409&#34;&gt;ALiBi&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4,096&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;æ¨ç†å’Œéƒ¨ç½²&lt;/h1&gt; &#xA;&lt;p&gt;æ¨ç†æ‰€éœ€çš„æ¨¡å‹æƒé‡ã€æºç ã€é…ç½®å·²å‘å¸ƒåœ¨ Hugging Faceï¼š&lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan-13B-Base&#34;&gt;Baichuan-13B-Base&lt;/a&gt; å’Œ &lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan-13B-Chat&#34;&gt;Baichuan-13B-Chat&lt;/a&gt;ã€‚ä¸‹é¢ä»¥ Baichuan-13B-Chat ä¸ºä¾‹ç¤ºèŒƒå¤šç§æ¨ç†æ–¹å¼ã€‚ç¨‹åºä¼šè‡ªåŠ¨ä» Hugging Face ä¸‹è½½æ‰€éœ€èµ„æºã€‚&lt;/p&gt; &#xA;&lt;p&gt;æ¨ç†å‰è¯·å®‰è£…ä¾èµ–ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Pythonä»£ç æ–¹å¼&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; import torch&#xA;&amp;gt;&amp;gt;&amp;gt; from transformers import AutoModelForCausalLM, AutoTokenizer&#xA;&amp;gt;&amp;gt;&amp;gt; from transformers.generation.utils import GenerationConfig&#xA;&amp;gt;&amp;gt;&amp;gt; tokenizer = AutoTokenizer.from_pretrained(&#34;baichuan-inc/Baichuan-13B-Chat&#34;, use_fast=False, trust_remote_code=True)&#xA;&amp;gt;&amp;gt;&amp;gt; model = AutoModelForCausalLM.from_pretrained(&#34;baichuan-inc/Baichuan-13B-Chat&#34;, device_map=&#34;auto&#34;, torch_dtype=torch.float16, trust_remote_code=True)&#xA;&amp;gt;&amp;gt;&amp;gt; model.generation_config = GenerationConfig.from_pretrained(&#34;baichuan-inc/Baichuan-13B-Chat&#34;)&#xA;&amp;gt;&amp;gt;&amp;gt; messages = []&#xA;&amp;gt;&amp;gt;&amp;gt; messages.append({&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;ä¸–ç•Œä¸Šç¬¬äºŒé«˜çš„å±±å³°æ˜¯å“ªåº§&#34;})&#xA;&amp;gt;&amp;gt;&amp;gt; response = model.chat(tokenizer, messages)&#xA;&amp;gt;&amp;gt;&amp;gt; print(response)&#xA;ä¹”æˆˆé‡Œå³°ã€‚ä¸–ç•Œç¬¬äºŒé«˜å³°â€”â€”â€”ä¹”æˆˆé‡Œå³°è¥¿æ–¹ç™»å±±è€…ç§°å…¶ä¸ºk2å³°ï¼Œæµ·æ‹”é«˜åº¦æ˜¯8611ç±³ï¼Œä½äºå–€å–‡æ˜†ä»‘å±±è„‰çš„ä¸­å·´è¾¹å¢ƒä¸Š&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;åœ¨ä¸Šè¿°ä»£ç ä¸­ï¼Œæ¨¡å‹åŠ è½½æŒ‡å®š &lt;code&gt;device_map=&#39;auto&#39;&lt;/code&gt;ï¼Œä¼šä½¿ç”¨æ‰€æœ‰å¯ç”¨æ˜¾å¡ã€‚å¦‚éœ€æŒ‡å®šä½¿ç”¨çš„è®¾å¤‡ï¼Œå¯ä»¥ä½¿ç”¨ç±»ä¼¼ &lt;code&gt;export CUDA_VISIBLE_DEVICES=0,1&lt;/code&gt;ï¼ˆä½¿ç”¨äº†0ã€1å·æ˜¾å¡ï¼‰çš„æ–¹å¼æ§åˆ¶ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;å‘½ä»¤è¡Œå·¥å…·æ–¹å¼&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python cli_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æœ€åè¾“å‡ºç¤ºä¾‹å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan-13B/main/media/cn-cli.png&#34; width=&#34;70%&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;ç½‘é¡µ demo æ–¹å¼&lt;/h2&gt; &#xA;&lt;p&gt;ä¾é streamlitè¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œä¼šåœ¨æœ¬åœ°å¯åŠ¨ä¸€ä¸ª web æœåŠ¡ï¼ŒæŠŠæ§åˆ¶å°ç»™å‡ºçš„åœ°å€æ”¾å…¥æµè§ˆå™¨å³å¯è®¿é—®ã€‚&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;streamlit run web_demo.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æ•ˆæœå¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/baichuan-inc/Baichuan-13B/main/media/cn-web.gif&#34; width=&#34;70%&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Baichuan-13B-Chat ç¤ºä¾‹è¾“å‡º&lt;/h2&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;å†…å®¹åˆ›ä½œ&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;ç”¨æˆ·ï¼š&#xA;ä½ æ˜¯ä¸€ä¸ªå†…å®¹åˆ›ä½œè€…ï¼Œç¼–å†™ä¸€æ®µå…³äºå¯¹é©¬æ–¯å…‹å’Œæ¯”å°”ç›–èŒ¨è®¿é—®ä¸­å›½è§†è§’çš„çŸ­è§†é¢‘è„šæœ¬&#xA;&#xA;Baichun-13B-Chatï¼š&#xA;æ¢ç´¢é©¬æ–¯å…‹ä¸æ¯”å°”Â·ç›–èŒ¨çš„ä¸­å›½ä¹‹æ—…&#xA;&#xA;é•œå¤´1ï¼š(èƒŒæ™¯éŸ³ä¹)ç”»é¢åˆ‡å…¥ï¼Œå±•ç¤ºä¸­å›½çš„ç¹åéƒ½å¸‚æ™¯è±¡ã€‚&#xA;&#xA;æ—ç™½ï¼šæ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„èŠ‚ç›®ï¼Œä»Šå¤©æˆ‘ä»¬å°†å¸¦æ‚¨ä¸€èµ·äº†è§£ä¸¤ä½ç§‘æŠ€å·¨å¤´â€”â€”åŸƒéš†Â·é©¬æ–¯å…‹å’Œæ¯”å°”Â·ç›–èŒ¨åœ¨ä¸­å›½çš„ä¸€æ¬¡ç‰¹æ®Šè®¿é—®ã€‚&#xA;&#xA;é•œå¤´2ï¼š(èƒŒæ™¯éŸ³ä¹)ç”»é¢åˆ‡æ¢è‡³é©¬æ–¯å…‹å’Œæ¯”å°”Â·ç›–èŒ¨æŠµè¾¾ä¸­å›½çš„æœºåœºã€‚&#xA;&#xA;æ—ç™½ï¼šè¿™æ¬¡è®¿é—®æ˜¯ä»–ä»¬é¦–æ¬¡å…±åŒè¸ä¸Šä¸­å›½çš„åœŸåœ°ï¼Œä»–ä»¬å°†åœ¨è¿™é‡Œå±•å¼€ä¸€åœºå…³äºç§‘æŠ€åˆ›æ–°ã€ç¯ä¿å’Œæ•™è‚²çš„å¯¹è¯ã€‚&#xA;&#xA;é•œå¤´3ï¼š(èƒŒæ™¯éŸ³ä¹)ç”»é¢å±•ç¤ºé©¬æ–¯å…‹å’Œæ¯”å°”Â·ç›–èŒ¨å‚è§‚ä¸€å®¶ç”µåŠ¨æ±½è½¦åˆ¶é€ å‚ã€‚&#xA;&#xA;æ—ç™½ï¼šåœ¨è¿™æ¬¡è®¿é—®ä¸­ï¼Œä»–ä»¬é¦–å…ˆå‚è§‚äº†ä¸€å®¶ç”µåŠ¨æ±½è½¦åˆ¶é€ å‚ï¼Œäº†è§£äº†ä¸­å›½åœ¨æ–°èƒ½æºæ±½è½¦é¢†åŸŸçš„æœ€æ–°å‘å±•ã€‚&#xA;&#xA;é•œå¤´4ï¼š(èƒŒæ™¯éŸ³ä¹)ç”»é¢å±•ç¤ºé©¬æ–¯å…‹å’Œæ¯”å°”Â·ç›–èŒ¨å‚åŠ ä¸€åœºå…³äºäººå·¥æ™ºèƒ½çš„è®ºå›ã€‚&#xA;&#xA;æ—ç™½ï¼šéšåï¼Œä»–ä»¬å‚åŠ äº†å…³äºäººå·¥æ™ºèƒ½çš„ä¸€åœºè®ºå›ï¼Œæ¢è®¨äº†è¿™ä¸€é¢†åŸŸçš„å‘å±•è¶‹åŠ¿åŠå…¶å¯¹æœªæ¥çš„å½±å“ã€‚&#xA;&#xA;é•œå¤´5ï¼š(èƒŒæ™¯éŸ³ä¹)ç”»é¢å±•ç¤ºé©¬æ–¯å…‹å’Œæ¯”å°”Â·ç›–èŒ¨å‚è§‚ä¸€æ‰€å­¦æ ¡ã€‚&#xA;&#xA;æ—ç™½ï¼šåœ¨è¿™æ¬¡è®¿é—®ä¸­ï¼Œä»–ä»¬è¿˜å‚è§‚äº†ä¸€æ‰€å­¦æ ¡ï¼Œäº†è§£äº†ä¸­å›½åœ¨æ•™è‚²é¢†åŸŸçš„åˆ›æ–°å®è·µã€‚&#xA;&#xA;é•œå¤´6ï¼š(èƒŒæ™¯éŸ³ä¹)ç”»é¢å±•ç¤ºé©¬æ–¯å…‹å’Œæ¯”å°”Â·ç›–èŒ¨æ¥å—åª’ä½“é‡‡è®¿ã€‚&#xA;&#xA;æ—ç™½ï¼šæœ€åï¼Œä»–ä»¬åœ¨åª’ä½“é‡‡è®¿ç¯èŠ‚è¡¨ç¤ºï¼Œå¸Œæœ›é€šè¿‡è¿™æ¬¡è®¿é—®ï¼Œèƒ½å¤Ÿä¸ºä¸­ç¾ä¸¤å›½åœ¨ç§‘æŠ€åˆ›æ–°ã€ç¯ä¿å’Œæ•™è‚²ç­‰é¢†åŸŸçš„åˆä½œæä¾›ä¸€äº›å¯ç¤ºã€‚&#xA;&#xA;é•œå¤´7ï¼š(èƒŒæ™¯éŸ³ä¹)ç”»é¢åˆ‡å›ç¹åéƒ½å¸‚æ™¯è±¡ã€‚&#xA;&#xA;æ—ç™½ï¼šè¿™å°±æ˜¯é©¬æ–¯å…‹å’Œæ¯”å°”Â·ç›–èŒ¨çš„ä¸­å›½ä¹‹è¡Œï¼Œä»–ä»¬çš„è®¿é—®ä¸ä»…è®©æˆ‘ä»¬çœ‹åˆ°äº†ä¸­å›½åœ¨ç§‘æŠ€åˆ›æ–°æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¹Ÿä¸ºæˆ‘ä»¬æä¾›äº†å…³äºæœªæ¥å‘å±•çš„æ›´å¤šæ€è€ƒã€‚æ„Ÿè°¢æ”¶çœ‹ï¼Œæˆ‘ä»¬ä¸‹æœŸå†è§ï¼&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;å¹¿å‘Šæ–‡æ¡ˆ&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;ç”¨æˆ·ï¼š&#xA;è¯·ä»¥é”€å”®å‘˜çš„è§’è‰²ï¼Œå°†æ´—è¡£æ¶²çš„å¹²å‡€ã€æ— æ®‹ç•™ã€æ— å¼‚å‘³ä»¥åŠé™¤èŒç­‰ä¼˜ç‚¹è¿›è¡Œæ¨é”€&#xA;&#xA;Baichun-13B-Chatï¼š&#xA;å°Šæ•¬çš„é¡¾å®¢ï¼Œæ‚¨å¥½ï¼æˆ‘æ˜¯ä¸€åæ´—è¡£æ¶²é”€å”®å‘˜ï¼Œéå¸¸é«˜å…´ä¸ºæ‚¨ä»‹ç»æˆ‘ä»¬è¿™æ¬¾äº§å“ã€‚æˆ‘ä»¬çš„æ´—è¡£æ¶²å…·æœ‰ä»¥ä¸‹å‡ ä¸ªæ˜¾è‘—ä¼˜ç‚¹ï¼š&#xA;&#xA;å¹²å‡€ï¼šæˆ‘ä»¬çš„æ´—è¡£æ¶²é‡‡ç”¨äº†å…ˆè¿›çš„æ´—æ¶¤æŠ€æœ¯ï¼Œèƒ½å¤Ÿæ·±å…¥è¡£ç‰©çº¤ç»´ï¼Œæœ‰æ•ˆå»é™¤å„ç§æ±¡æ¸ï¼Œè®©æ‚¨çš„è¡£ç‰©ç„•ç„¶ä¸€æ–°ã€‚åŒæ—¶ï¼Œå®ƒä¸ä¼šå¯¹è¡£ç‰©çš„é¢œè‰²å’Œè´¨åœ°é€ æˆä»»ä½•æŸå®³ï¼Œè®©æ‚¨çš„è¡£ç‰©ä¿æŒåŸæœ‰çš„å“è´¨ã€‚&#xA;&#xA;æ— æ®‹ç•™ï¼šä¸ä¼ ç»Ÿçš„æ´—è¡£ç²‰ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ´—è¡£æ¶²åœ¨æ¸…æ´—è¿‡ç¨‹ä¸­ä¸ä¼šäº§ç”Ÿè¿‡å¤šçš„æ³¡æ²«ï¼Œå› æ­¤æ¸…æ´—åçš„è¡£ç‰©æ›´åŠ æŸ”è½¯ï¼Œä¸ä¼šæœ‰é»è…»çš„æ„Ÿè§‰ã€‚æ­¤å¤–ï¼Œå®ƒçš„å»æ±¡èƒ½åŠ›å¼ºï¼Œèƒ½å½»åº•æ´—å‡€è¡£ç‰©ä¸Šçš„æ±¡æ¸ï¼Œé¿å…äº†ä¼ ç»Ÿæ´—è¡£ç²‰å®¹æ˜“æ®‹ç•™åœ¨è¡£ç‰©ä¸Šçš„é—®é¢˜ã€‚&#xA;&#xA;æ— å¼‚å‘³ï¼šæˆ‘ä»¬çš„æ´—è¡£æ¶²é‡‡ç”¨å¤©ç„¶æ¤ç‰©æå–ç‰©ä½œä¸ºåŸæ–™ï¼Œä¸å«æœ‰å®³åŒ–å­¦ç‰©è´¨ï¼Œå› æ­¤åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­ä¸ä¼šäº§ç”Ÿåˆºé¼»çš„æ°”å‘³ã€‚å³ä½¿æ˜¯æ•æ„Ÿè‚Œè‚¤çš„äººç¾¤ä¹Ÿå¯ä»¥æ”¾å¿ƒä½¿ç”¨ï¼Œè®©æ‚¨çš„è¡£ç‰©æ•£å‘å‡ºæ·¡é›…çš„æ¸…é¦™ã€‚&#xA;&#xA;é™¤èŒï¼šä¸ºäº†æ»¡è¶³ç°ä»£äººå¯¹å¥åº·ç”Ÿæ´»çš„éœ€æ±‚ï¼Œæˆ‘ä»¬çš„æ´—è¡£æ¶²ç‰¹åˆ«æ·»åŠ äº†é«˜æ•ˆé™¤èŒæˆåˆ†ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ€ç­è¡£ç‰©ä¸Šçš„ç»†èŒï¼Œä¿æŠ¤æ‚¨å’Œå®¶äººçš„èº«ä½“å¥åº·ã€‚æ— è®ºæ˜¯å©´å¹¼å„¿çš„è¡£ç‰©è¿˜æ˜¯è´´èº«å†…è¡£ï¼Œéƒ½å¯ä»¥æ”¾å¿ƒä½¿ç”¨ã€‚&#xA;&#xA;æ€»ä¹‹ï¼Œæˆ‘ä»¬çš„æ´—è¡£æ¶²å‡­å€Ÿå…¶å¹²å‡€ã€æ— æ®‹ç•™ã€æ— å¼‚å‘³ä»¥åŠé™¤èŒç­‰ä¼˜ç‚¹ï¼Œæˆä¸ºäº†å¹¿å¤§æ¶ˆè´¹è€…çš„é¦–é€‰ã€‚å¦‚æœæ‚¨è¿˜æ²¡æœ‰å°è¯•è¿‡æˆ‘ä»¬çš„äº§å“ï¼Œé‚£ä¹ˆç°åœ¨å°±æ˜¯æœ€å¥½çš„æ—¶æœºã€‚ç›¸ä¿¡å®ƒä¸€å®šä¼šç»™æ‚¨å¸¦æ¥å…¨æ–°çš„æ´—è¡£ä½“éªŒï¼&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;pre&gt;&lt;code&gt;ç”¨æˆ·ï¼š&#xA;å‡†å¤‡ä¸€ä»½ä»¥å® ç‰©é£Ÿå“ä¸ºä¸»é¢˜çš„æŠ¥å‘Šï¼ŒåŒ…æ‹¬æ½œåœ¨æ¶ˆè´¹è€…ï¼Œå¸‚åœºè§„æ¨¡ï¼Œå¸‚åœºæœºé‡ï¼ŒåŠç›ˆåˆ©æ¨¡å¼ç­‰å†…å®¹&#xA;&#xA;&#xA;Baichun-13B-Chatï¼š&#xA;&#xA;ä¸€ã€å¼•è¨€&#xA;&#xA;éšç€äººä»¬ç”Ÿæ´»æ°´å¹³çš„æé«˜å’Œå¯¹å® ç‰©çš„å…³çˆ±ç¨‹åº¦ä¸æ–­åŠ æ·±ï¼Œå® ç‰©é£Ÿå“è¡Œä¸šå¾—åˆ°äº†å¿«é€Ÿå‘å±•ã€‚æœ¬æŠ¥å‘Šå°†å¯¹å® ç‰©é£Ÿå“è¡Œä¸šçš„æ½œåœ¨æ¶ˆè´¹è€…ã€å¸‚åœºè§„æ¨¡ã€å¸‚åœºæœºé‡ä»¥åŠç›ˆåˆ©æ¨¡å¼ç­‰æ–¹é¢è¿›è¡Œåˆ†æï¼Œä»¥æœŸä¸ºç›¸å…³ä¼ä¸šæä¾›æœ‰ç›Šçš„å‚è€ƒä¿¡æ¯ã€‚&#xA;&#xA;äºŒã€æ½œåœ¨æ¶ˆè´¹è€…&#xA;&#xA;1. å…»å® äººç¾¤ï¼šéšç€å…»å® äººæ•°çš„å¢åŠ ï¼Œå® ç‰©é£Ÿå“çš„éœ€æ±‚ä¹Ÿåœ¨ä¸æ–­å¢é•¿ã€‚æ ¹æ®ç»Ÿè®¡æ•°æ®æ˜¾ç¤ºï¼Œ2019å¹´ä¸­å›½åŸé•‡å…»å® (çŠ¬çŒ«)äººå£æ•°é‡å·²è¾¾7355ä¸‡äººï¼ŒåŒæ¯”å¢é•¿4.6%ã€‚é¢„è®¡åˆ°2023å¹´ï¼Œè¿™ä¸€æ•°å­—å°†è¾¾åˆ°8742ä¸‡äººã€‚&#xA;&#xA;2. æ–°ç”Ÿä»£æ¶ˆè´¹è€…ï¼šæ–°ç”Ÿä»£æ¶ˆè´¹è€…åœ¨æ¶ˆè´¹è§‚å¿µä¸Šæ›´åŠ æ³¨é‡å¥åº·ã€ç¯ä¿å’Œä¸ªæ€§åŒ–ï¼Œè¿™ä½¿å¾—ä»–ä»¬æ›´æ„¿æ„ä¸ºå® ç‰©è´­ä¹°é«˜å“è´¨çš„é£Ÿå“ã€‚æ­¤å¤–ï¼Œä»–ä»¬ä¹Ÿæ›´å€¾å‘äºé€šè¿‡ç½‘ç»œå¹³å°äº†è§£å’Œè´­ä¹°å® ç‰©é£Ÿå“ã€‚&#xA;&#xA;ä¸‰ã€å¸‚åœºè§„æ¨¡&#xA;&#xA;1. æ ¹æ®å›½å®¶ç»Ÿè®¡å±€æ•°æ®ï¼Œ2019å¹´æˆ‘å›½å® ç‰©é£Ÿå“å¸‚åœºè§„æ¨¡è¾¾åˆ°äº†1,020äº¿å…ƒäººæ°‘å¸ï¼ŒåŒæ¯”å¢é•¿çº¦10%ã€‚é¢„è®¡åˆ°2023å¹´ï¼Œå¸‚åœºè§„æ¨¡å°†è¾¾åˆ°1,  500äº¿å…ƒäººæ°‘å¸ã€‚&#xA;&#xA;2. ä»äº§å“ç±»å‹æ¥çœ‹ï¼Œå® ç‰©å¹²ç²®å¸‚åœºå æ¯”æœ€é«˜ï¼Œçº¦å æ€»å¸‚åœºçš„70%;å…¶æ¬¡æ˜¯å® ç‰©æ¹¿ç²®ï¼Œå æ¯”çº¦ä¸º20%;å® ç‰©é›¶é£Ÿå¸‚åœºå æ¯”çº¦ä¸º10%ã€‚&#xA;&#xA;å››ã€å¸‚åœºæœºé‡&#xA;&#xA;1. åŠŸèƒ½æ€§å® ç‰©é£Ÿå“ï¼šéšç€æ¶ˆè´¹è€…å¯¹å¥åº·çš„å…³æ³¨åº¦ä¸æ–­æé«˜ï¼Œå…·æœ‰ç‰¹å®šåŠŸèƒ½çš„å® ç‰©é£Ÿå“å¦‚å¤„æ–¹ç²®ã€å‡è‚¥ç²®ç­‰éœ€æ±‚é€æ¸å¢å¤§ã€‚&#xA;&#xA;2. å¤©ç„¶æœ‰æœºå® ç‰©é£Ÿå“ï¼šè¶Šæ¥è¶Šå¤šçš„æ¶ˆè´¹è€…å€¾å‘äºé€‰æ‹©å¤©ç„¶ã€æ— æ·»åŠ å‰‚çš„å® ç‰©é£Ÿå“ï¼Œè¿™ä¹Ÿä¸ºå¸‚åœºå¸¦æ¥äº†æ–°çš„å•†æœºã€‚&#xA;&#xA;3. å®šåˆ¶åŒ–å® ç‰©é£Ÿå“ï¼šé’ˆå¯¹ä¸åŒå“ç§ã€å¹´é¾„ã€ä½“å‹çš„å® ç‰©ï¼Œæ¨å‡ºå®šåˆ¶åŒ–çš„å® ç‰©é£Ÿå“ï¼Œæ»¡è¶³æ¶ˆè´¹è€…ä¸ªæ€§åŒ–éœ€æ±‚ã€‚&#xA;&#xA;äº”ã€ç›ˆåˆ©æ¨¡å¼&#xA;&#xA;1. ä¼ ç»Ÿé”€å”®æ¸ é“ï¼šé€šè¿‡è¶…å¸‚ã€å® ç‰©åº—ã€ç”µå•†å¹³å°ç­‰ä¼ ç»Ÿæ¸ é“é”€å”®å® ç‰©é£Ÿå“ã€‚&#xA;&#xA;2. ç›´é”€æ¨¡å¼ï¼šé€šè¿‡è‡ªå»ºç½‘ç«™æˆ–ä¸ç¬¬ä¸‰æ–¹å¹³å°åˆä½œï¼Œç›´æ¥å‘æ¶ˆè´¹è€…é”€å”®å® ç‰©é£Ÿå“ã€‚&#xA;&#xA;3. ä¼šå‘˜åˆ¶ï¼šé€šè¿‡è®¾ç«‹ä¼šå‘˜åˆ¶åº¦ï¼Œä¸ºä¼šå‘˜æä¾›ä¸“å±ä¼˜æƒ å’ŒæœåŠ¡ï¼Œå¢åŠ å®¢æˆ·ç²˜æ€§ã€‚&#xA;&#xA;4. å¢å€¼æœåŠ¡ï¼šæä¾›å® ç‰©ç¾å®¹ã€å¯„å…»ã€è®­ç»ƒç­‰é™„åŠ æœåŠ¡ï¼Œå®ç°å¤šå…ƒåŒ–ç›ˆåˆ©ã€‚&#xA;&#xA;å…­ã€ç»“è®º&#xA;&#xA;å® ç‰©é£Ÿå“è¡Œä¸šå…·æœ‰å·¨å¤§çš„å¸‚åœºæ½œåŠ›å’Œå‘å±•ç©ºé—´ã€‚ä¼ä¸šåº”æŠ“ä½å¸‚åœºæœºé‡ï¼Œå…³æ³¨æ¶ˆè´¹è€…éœ€æ±‚å˜åŒ–ï¼Œåˆ›æ–°äº§å“&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;ç²¾å‡†é—®ç­”&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;ç”¨æˆ·ï¼š&#xA;ä¸–ç•Œä¸Šç¬¬äºŒé«˜çš„å±±æ˜¯ä»€ä¹ˆå±±&#xA;&#xA;Baichun-13B-Chatï¼š&#xA;ä¹”æˆˆé‡Œå³°(K2) æµ·æ‹”8611ç±³ï¼Œä½äºå–€å–‡æ˜†ä»‘å±±è„‰çš„ä¸­å·´è¾¹å¢ƒä¸Šï¼Œæ˜¯ä¸­å›½ä»¥å¤–ç™»å±±è€…çš„æœ€å¤§è€ƒéªŒï¼Œä¹Ÿæ˜¯ä¸–ç•Œä¸Šæœ€éš¾å¾æœçš„å±±å³°ä¹‹ä¸€ã€‚å®ƒçš„é«˜åº¦ä»…æ¬¡äºç ç©†æœ—ç›å³°ï¼Œä½å±…ä¸–ç•Œç¬¬äºŒã€‚&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;pre&gt;&lt;code&gt;ç”¨æˆ·ï¼š&#xA;æ„å…´é˜‘çŠæ˜¯ä»€ä¹ˆæ„æ€&#xA;&#xA;Baichun-13B-Chatï¼š&#xA;&#34;æ„å…´é˜‘çŠ&#34;æ˜¯ä¸€ä¸ªæ±‰è¯­æˆè¯­ï¼Œå®ƒçš„æ„æ€æ˜¯å½¢å®¹ä¸€ä¸ªäººå…´è‡´ä¸é«˜ï¼Œå…´è¶£å‡å¼±ã€‚è¿™ä¸ªè¯é€šå¸¸ç”¨æ¥æè¿°ä¸€ä¸ªäººåœ¨æŸä¸ªæ´»åŠ¨ä¸­å¤±å»äº†åŸæœ‰çš„çƒ­æƒ…å’Œå…´è¶£ã€‚&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;pre&gt;&lt;code&gt;ç”¨æˆ·ï¼š&#xA;è¯·é—®å¼ºåŒ–å­¦ä¹ é‡Œé¢çš„Reward Shapingæ˜¯ä»€ä¹ˆæ„æ€&#xA;&#xA;Baichun-13B-Chatï¼š&#xA;å¥–åŠ±å¡‘é€ (Reward Shaping)æ˜¯å¼ºåŒ–å­¦ä¹ ä¸­çš„ä¸€ä¸ªæ¦‚å¿µï¼Œå®ƒæ˜¯æŒ‡é€šè¿‡è°ƒæ•´ç¯å¢ƒæˆ–è®¾è®¡ç‰¹å®šçš„å¥–åŠ±å‡½æ•°æ¥å¼•å¯¼æ™ºèƒ½ä½“(Agent)å­¦ä¹ åˆ°æ›´ç¬¦åˆäººç±»æœŸæœ›çš„è¡Œä¸ºã€‚åœ¨ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæ™ºèƒ½ä½“é€šè¿‡ä¸ç¯å¢ƒäº¤äº’æ¥å­¦ä¹ æœ€ä¼˜ç­–ç•¥ï¼Œä½†è¿™ç§æ–¹æ³•å¯èƒ½å¯¼è‡´æ™ºèƒ½ä½“å­¦ä¹ åˆ°ä¸€äº›æ¬¡ä¼˜ç”šè‡³ä¸è‰¯è¡Œä¸ºã€‚&#xA;&#xA;å¥–åŠ±å¡‘é€ çš„ç›®çš„æ˜¯ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œé€šè¿‡äººä¸ºåœ°è°ƒæ•´å¥–åŠ±å‡½æ•°ï¼Œä½¿å¾—æ™ºèƒ½ä½“æ›´å®¹æ˜“å­¦åˆ°æˆ‘ä»¬å¸Œæœ›å®ƒå­¦ä¼šçš„è¡Œä¸ºã€‚è¿™å¯ä»¥é€šè¿‡ä»¥ä¸‹å‡ ç§æ–¹å¼å®ç°ï¼š&#xA;&#xA;1. å¢åŠ æ­£å‘å¥–åŠ±ï¼šå½“æ™ºèƒ½ä½“è¡¨ç°å‡ºæœŸæœ›è¡Œä¸ºæ—¶ï¼Œç»™äºˆå…¶æ›´å¤šçš„å¥–åŠ±ï¼Œä»¥é¼“åŠ±è¿™ç§è¡Œä¸ºã€‚&#xA;2. å‡å°‘è´Ÿå‘å¥–åŠ±ï¼šå½“æ™ºèƒ½ä½“è¡¨ç°å‡ºä¸æœŸæœ›è¡Œä¸ºæ—¶ï¼Œå‡å°‘å¯¹å…¶è¿›è¡Œæƒ©ç½šï¼Œé™ä½å…¶å¯¹è¿™ç§è¡Œä¸ºçš„åå¥½ã€‚&#xA;3. å¼•å…¥æ–°å¥–åŠ±ï¼šä¸ºæ™ºèƒ½ä½“æä¾›é¢å¤–çš„å¥–åŠ±ï¼Œä»¥ä¾¿æ›´å¥½åœ°å¼•å¯¼å…¶å­¦ä¹ ç‰¹å®šè¡Œä¸ºã€‚&#xA;4. æ”¹å˜å¥–åŠ±åˆ†å¸ƒï¼šé€šè¿‡è°ƒæ•´å¥–åŠ±å‡½æ•°ï¼Œä½¿å…¶å…·æœ‰ä¸åŒçš„å¥–åŠ±åˆ†å¸ƒï¼Œä»è€Œå½±å“æ™ºèƒ½ä½“çš„å­¦ä¹ è¿‡ç¨‹ã€‚&#xA;&#xA;æ€»ä¹‹ï¼Œå¥–åŠ±å¡‘é€ æ˜¯ä¸€ç§é€šè¿‡è°ƒæ•´ç¯å¢ƒå’Œå¥–åŠ±å‡½æ•°æ¥å¼•å¯¼æ™ºèƒ½ä½“å­¦ä¹ æ›´å¥½è¡Œä¸ºçš„æ–¹æ³•ï¼Œæœ‰åŠ©äºæé«˜å¼ºåŒ–å­¦ä¹ çš„æ€§èƒ½ã€‚&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;b&gt;è¯­è¨€ç†è§£&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code&gt;ç”¨æˆ·ï¼š&#xA;å°å¼ ç»™é¢†å¯¼ä¹°äº†ä¸€ä¸ªç¤¼ç‰©è¯´ï¼Œè¯´â€œæ„æ€ä¸€ä¸‹â€ï¼Œé¢†å¯¼è¯´â€œä»€ä¹ˆæ„æ€â€ï¼Œå°å¼ å›ç­”è¯´ï¼šâ€œæ²¡ä»€ä¹ˆæ„æ€ï¼Œå°±æ˜¯éšä¾¿æ„æ€æ„æ€â€ã€‚è¯·ä¾æ¬¡è§£è¯»ä¸€ä¸‹å°å¼ è¯´çš„è¿™å‡ ä¸ªâ€œæ„æ€â€çš„å«ä¹‰ã€‚&#xA;&#xA;Baichun-13B-Chatï¼š&#xA;1. ç¬¬ä¸€ä¸ªâ€œæ„æ€â€ï¼šæŒ‡çš„æ˜¯å°å¼ é€ç»™é¢†å¯¼çš„é‚£ä¸ªç¤¼ç‰©ï¼Œè¡¨ç¤ºä»–å·²ç»ä¹°äº†è¿™ä¸ªç¤¼ç‰©å¹¶å‡†å¤‡é€ç»™ä»–ã€‚&#xA;2. ç¬¬äºŒä¸ªâ€œæ„æ€â€ï¼šæŒ‡çš„æ˜¯å°å¼ å¯¹é¢†å¯¼çš„ä¸€ç§ç¤¼è²Œå’Œå°Šé‡ï¼Œè¡¨ç¤ºè‡ªå·±å¹¶æ²¡æœ‰å¿˜è®°ä»–çš„èº«ä»½å’Œåœ°ä½ï¼Œåœ¨è´­ä¹°ç¤¼ç‰©æ—¶ä¹Ÿè€ƒè™‘åˆ°äº†è¿™ä¸€ç‚¹ã€‚&#xA;3. ç¬¬ä¸‰ä¸ªâ€œæ„æ€â€ï¼šæŒ‡çš„æ˜¯å°å¼ å¯¹äºè¿™æ¬¡èµ é€ç¤¼ç‰©çš„è¡Œä¸ºæœ¬èº«çš„æ€åº¦ï¼Œå³ä¸å¸Œæœ›è¿™ä»¶äº‹æƒ…å¼•èµ·è¿‡å¤šçš„å…³æ³¨æˆ–äº‰è®®ï¼Œåªæ˜¯æƒ³è¡¨è¾¾ä¸€ç§å¿ƒæ„è€Œå·²ã€‚&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;æ¨ç†æ€§èƒ½&lt;/h2&gt; &#xA;&lt;p&gt;Baichuan-13B ä½¿ç”¨äº† ALiBi çº¿æ€§åç½®æŠ€æœ¯ï¼Œç›¸å¯¹äº Rotary Embedding è®¡ç®—é‡æ›´å°ï¼Œå¯¹æ¨ç†æ€§èƒ½æœ‰æ˜¾è‘—æå‡ï¼›ä¸æ ‡å‡†çš„ LLaMA-13B ç›¸æ¯”ï¼Œå¹³å‡æ¨ç†é€Ÿåº¦ (tokens/s) å®æµ‹æå‡ 31.6%ï¼š&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;tokens/s&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;19.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan-13B&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;25.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;æµ‹è¯•ç¯å¢ƒå’Œå‚æ•°ï¼šGPU A100-SXM4-80G, PyTorch 2.0.0+cu117, transformers 4.29.1, batch size = 1, ç”Ÿæˆé•¿åº¦ = 2048, ç²¾åº¦ fp16, åŸºäº Baichuan-13B-Base&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;é‡åŒ–éƒ¨ç½²&lt;/h2&gt; &#xA;&lt;p&gt;Baichuan-13B æ”¯æŒ int8 å’Œ int4 é‡åŒ–ï¼Œç”¨æˆ·åªéœ€åœ¨æ¨ç†ä»£ç ä¸­ç®€å•ä¿®æ”¹ä¸¤è¡Œå³å¯å®ç°ã€‚è¯·æ³¨æ„ï¼Œå¦‚æœæ˜¯ä¸ºäº†èŠ‚çœæ˜¾å­˜è€Œè¿›è¡Œé‡åŒ–ï¼Œåº”åŠ è½½åŸå§‹ç²¾åº¦æ¨¡å‹åˆ° CPU åå†å¼€å§‹é‡åŒ–ï¼›é¿å…åœ¨&lt;code&gt;from_pretrained&lt;/code&gt;æ—¶æ·»åŠ &lt;code&gt;device_map=&#39;auto&#39;&lt;/code&gt;æˆ–è€…å…¶å®ƒä¼šå¯¼è‡´æŠŠåŸå§‹ç²¾åº¦æ¨¡å‹ç›´æ¥åŠ è½½åˆ° GPU çš„è¡Œä¸ºçš„å‚æ•°ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å¦‚éœ€ä½¿ç”¨ int8 é‡åŒ–ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModelForCausalLM.from_pretrained(&#34;baichuan-inc/Baichuan-13B-Chat&#34;, torch_dtype=torch.float16, trust_remote_code=True)&#xA;model = model.quantize(8).cuda() &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;åŒæ ·çš„ï¼Œå¦‚éœ€ä½¿ç”¨ int4 é‡åŒ–ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModelForCausalLM.from_pretrained(&#34;baichuan-inc/Baichuan-13B-Chat&#34;, torch_dtype=torch.float16, trust_remote_code=True)&#xA;model = model.quantize(4).cuda()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;å¦å¤–ï¼Œå¦‚æœä½ ä¸æƒ³è°ƒç”¨ quantize åœ¨çº¿é‡åŒ–ï¼Œæˆ‘ä»¬æœ‰é‡åŒ–å¥½çš„ int8 Chat æ¨¡å‹å¯ä¾›ä½¿ç”¨ï¼š&lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan-13B-Chat-int8&#34;&gt;Baichuan-13B-Chat-int8&lt;/a&gt;ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModelForCausalLM.from_pretrained(&#34;baichuan-inc/Baichuan-13B-Chat-int8&#34;, torch_dtype=torch.float16, trust_remote_code=True).cuda()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;é‡åŒ–å‰åå ç”¨æ˜¾å­˜æƒ…å†µå¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Precision&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;GPU Mem (GB)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;bf16 / fp16&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;26.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;int8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;15.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;int4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9.7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;é‡åŒ–ååœ¨å„ä¸ª benchmark ä¸Šçš„ç»“æœå’ŒåŸå§‹ç‰ˆæœ¬å¯¹æ¯”å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model 5-shot&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;C-Eval&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;MMLU&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;CMMLU&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan-13B-Base&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;52.4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;55.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan-13B-Base-int8&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;49.9&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;54.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan-13B-Base-int4&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;47.6&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;46.0&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;51.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;CPU éƒ¨ç½²&lt;/h2&gt; &#xA;&lt;p&gt;Baichuan-13B æ”¯æŒ CPU æ¨ç†ï¼Œä½†éœ€è¦å¼ºè°ƒçš„æ˜¯ï¼ŒCPU çš„æ¨ç†é€Ÿåº¦ç›¸å¯¹è¾ƒæ…¢ã€‚éœ€æŒ‰å¦‚ä¸‹æ–¹å¼ä¿®æ”¹æ¨¡å‹åŠ è½½çš„æ–¹å¼ï¼š&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = AutoModelForCausalLM.from_pretrained(&#34;baichuan-inc/Baichuan-13B-Chat&#34;, torch_dtype=torch.float32, trust_remote_code=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ä½¿ç”¨CPUè¿›è¡Œæ¨ç†å¤§æ¦‚éœ€è¦ 60GB å†…å­˜ã€‚&lt;/p&gt; &#xA;&lt;h1&gt;å£°æ˜&lt;/h1&gt; &#xA;&lt;p&gt;æˆ‘ä»¬åœ¨æ­¤å£°æ˜ï¼Œæˆ‘ä»¬çš„å¼€å‘å›¢é˜Ÿå¹¶æœªåŸºäº Baichuan-13B æ¨¡å‹å¼€å‘ä»»ä½•åº”ç”¨ï¼Œæ— è®ºæ˜¯åœ¨ iOSã€Androidã€ç½‘é¡µæˆ–ä»»ä½•å…¶ä»–å¹³å°ã€‚æˆ‘ä»¬å¼ºçƒˆå‘¼åæ‰€æœ‰ä½¿ç”¨è€…ï¼Œä¸è¦åˆ©ç”¨ Baichuan-13B æ¨¡å‹è¿›è¡Œä»»ä½•å±å®³å›½å®¶ç¤¾ä¼šå®‰å…¨æˆ–è¿æ³•çš„æ´»åŠ¨ã€‚å¦å¤–ï¼Œæˆ‘ä»¬ä¹Ÿè¦æ±‚ä½¿ç”¨è€…ä¸è¦å°† Baichuan-13B æ¨¡å‹ç”¨äºæœªç»é€‚å½“å®‰å…¨å®¡æŸ¥å’Œå¤‡æ¡ˆçš„äº’è”ç½‘æœåŠ¡ã€‚æˆ‘ä»¬å¸Œæœ›æ‰€æœ‰çš„ä½¿ç”¨è€…éƒ½èƒ½éµå®ˆè¿™ä¸ªåŸåˆ™ï¼Œç¡®ä¿ç§‘æŠ€çš„å‘å±•èƒ½åœ¨è§„èŒƒå’Œåˆæ³•çš„ç¯å¢ƒä¸‹è¿›è¡Œã€‚&lt;/p&gt; &#xA;&lt;p&gt;æˆ‘ä»¬å·²ç»å°½æˆ‘ä»¬æ‰€èƒ½ï¼Œæ¥ç¡®ä¿æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ•°æ®çš„åˆè§„æ€§ã€‚ç„¶è€Œï¼Œå°½ç®¡æˆ‘ä»¬å·²ç»åšå‡ºäº†å·¨å¤§çš„åŠªåŠ›ï¼Œä½†ç”±äºæ¨¡å‹å’Œæ•°æ®çš„å¤æ‚æ€§ï¼Œä»æœ‰å¯èƒ½å­˜åœ¨ä¸€äº›æ— æ³•é¢„è§çš„é—®é¢˜ã€‚å› æ­¤ï¼Œå¦‚æœç”±äºä½¿ç”¨ Baichuan-13B å¼€æºæ¨¡å‹è€Œå¯¼è‡´çš„ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€å…¬å…±èˆ†è®ºé£é™©ï¼Œæˆ–æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨æ‰€å¸¦æ¥çš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚&lt;/p&gt; &#xA;&lt;h1&gt;åè®®&lt;/h1&gt; &#xA;&lt;p&gt;å¯¹æœ¬ä»“åº“æºç çš„ä½¿ç”¨éµå¾ªå¼€æºè®¸å¯åè®® &lt;a href=&#34;https://github.com/baichuan-inc/Baichuan-13B/raw/main/LICENSE&#34;&gt;Apache 2.0&lt;/a&gt;ã€‚å¯¹ Baichuan-13B æ¨¡å‹çš„ç¤¾åŒºä½¿ç”¨è§&lt;a href=&#34;https://huggingface.co/baichuan-inc/Baichuan-13B-Chat/resolve/main/Baichuan-13B%20%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf&#34;&gt;ã€ŠBaichuan-13B æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹&lt;/a&gt;ã€‚Baichuan-13B æ”¯æŒå•†ç”¨ã€‚å¦‚æœå°† Baichuan-13B æ¨¡å‹æˆ–å…¶è¡ç”Ÿå“ç”¨ä½œå•†ä¸šç”¨é€”ï¼Œè¯·æ‚¨æŒ‰ç…§å¦‚ä¸‹æ–¹å¼è”ç³»è®¸å¯æ–¹ï¼Œä»¥è¿›è¡Œç™»è®°å¹¶å‘è®¸å¯æ–¹ç”³è¯·ä¹¦é¢æˆæƒï¼šè”ç³»é‚®ç®± &lt;a href=&#34;mailto:opensource@baichuan-inc.com&#34;&gt;opensource@baichuan-inc.com&lt;/a&gt;ã€‚&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>OpenLMLab/MOSS-RLHF</title>
    <updated>2023-07-14T01:30:42Z</updated>
    <id>tag:github.com,2023-07-14:/OpenLMLab/MOSS-RLHF</id>
    <link href="https://github.com/OpenLMLab/MOSS-RLHF" rel="alternate"></link>
    <summary type="html">&lt;p&gt;MOSS-RLHF&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MOSS-RLHF&lt;/h1&gt; &#xA;&lt;h3&gt;&lt;em&gt;MOSS-RLHF &amp;amp; &#34;Secrets of RLHF in Large Language Models Part I: PPO&#34; &lt;br&gt;ğŸ‘‰ &lt;a href=&#34;https://arxiv.org/abs/2307.04964&#34; target=&#34;_blank&#34;&gt;[Technical report]&lt;/a&gt; &lt;a href=&#34;https://openlmlab.github.io/MOSS-RLHF/&#34; target=&#34;_blank&#34;&gt;[Home page]&lt;/a&gt;&lt;/em&gt;&lt;/h3&gt;&#xA;&lt;a href=&#34;https://openlmlab.github.io/MOSS-RLHF/&#34; target=&#34;_blank&#34;&gt; &lt;/a&gt;&#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt;&lt;a href=&#34;https://openlmlab.github.io/MOSS-RLHF/&#34; target=&#34;_blank&#34;&gt; &lt;/a&gt;&lt;a href=&#34;https://arxiv.org/abs/2307.04964&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenLMLab/MOSS-RLHF/main/assets/img/moss.png&#34; alt=&#34;MOSS&#34; style=&#34;width: 50%; min-width: 300px; display: block; margin: auto;&#34;&gt;&lt;/a&gt; &lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenLMLab/MOSS-RLHF/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Code%20License-Apache_2.0-brightgreen.svg?sanitize=true&#34; alt=&#34;Code License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenLMLab/MOSS-RLHF/main/DATA_LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Data%20License-CC%20BY--NC%204.0-blue.svg?sanitize=true&#34; alt=&#34;Data License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/OpenLMLab/MOSS-RLHF/main/MODEL_LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Model%20License-GNU%20AGPL%203.0-red.svg?sanitize=true&#34; alt=&#34;Model License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸŒŸ News&lt;/h2&gt; &#xA;&lt;h3&gt;ğŸ‘‰ Wed, 12. July 2023. We have released Chinese reward model based OpenChineseLlama-7B!&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://huggingface.co/Ablustrund/moss-rlhf-reward-model-7B-zh/tree/main&#34;&gt;moss-rlhf-reward-model-7B-zh&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ§¾ Open-source List&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Open source code for RL training in large language models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; A 7B Chinese reward model based on openChineseLlama.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; A 7B English reward model based on Llama-7B.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; SFT model for English.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Policy model for English after RLHF.&lt;/li&gt; &#xA; &lt;li&gt;...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸŒ  Introduction&lt;/h2&gt; &#xA;&lt;p&gt;Due to the challenges of reward design, environment interaction, and agent training, coupled with huge trial and error cost of large language models, there is a significant barrier for AI researchers to motivate the development of technical alignment and safe landing of LLMs. The stable training of RLHF has still been a puzzle. In this technical report, we intend to help researchers to train their models stably with human feedback.&lt;/p&gt; &#xA;&lt;p&gt;Contributions are summarized as follows:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;We release competitive Chinese and English reward models, respectively, which have good cross-model generalization ability, alleviating the cost of relabeling human preference data;&lt;/li&gt; &#xA; &lt;li&gt;We conduct in-depth analysis on the inner workings of PPO algorithm and propose the PPO-max algorithm to ensure stable model training;&lt;/li&gt; &#xA; &lt;li&gt;We release the complete PPO-max codes to ensure that the LLMs in the current SFT stage can be better aligned with humans.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;div align=&#34;center&#34; width=&#34;100%&#34;&gt; &#xA; &lt;img style=&#34;width: 80%; min-width: 500px; display: block; margin: auto; margin-bottom: 20px&#34; alt=&#34;MOSS-RLHF&#34; src=&#34;https://raw.githubusercontent.com/OpenLMLab/MOSS-RLHF/main/assets/img/img1.jpg&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34; width=&#34;100%&#34;&gt; &#xA; &lt;img style=&#34;width: 80%; min-width: 500px; display: block; margin: auto; margin-bottom: 20px&#34; alt=&#34;MOSS-RLHF&#34; src=&#34;https://raw.githubusercontent.com/OpenLMLab/MOSS-RLHF/main/assets/img/img2.jpg&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;ğŸ”© Requirements &amp;amp; Setup&lt;/h2&gt; &#xA;&lt;p&gt;This repository works on Python 3.8 and PyTorch 1.13.1.&lt;/p&gt; &#xA;&lt;p&gt;We recommend using the &lt;strong&gt;conda&lt;/strong&gt; virtual environment to run the code.&lt;/p&gt; &#xA;&lt;h4&gt;Step 1: Create a new Python virtual environment&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda update conda -n base -c defaults&#xA;conda create -n rlhf python=3.8&#xA;conda activate rlhf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Step 2: Install PyTorch and TensorBoard&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda install pytorch==1.13.1 pytorch-cuda=11.7 tensorboard -c pytorch -c nvidia&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Step 3: Install the remaining dependencies&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda install datasets accelerate safetensors chardet cchardet -c huggingface -c conda-forge&#xA;pip3 install transformers sentencepiece einops triton==1.0.0 rouge jionlp==1.4.14 nltk sacrebleu cpm_kernels&#xA;&#xA;apt install libaio-dev&#xA;DS_BUILD_OPS=1 pip install deepspeed&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;âœ¨ Start training your own model!&lt;/h2&gt; &#xA;&lt;p&gt;Run code in a few steps.&lt;/p&gt; &#xA;&lt;h3&gt;Step 1: Recover Reward model weights&lt;/h3&gt; &#xA;&lt;p&gt;We can not directly release the full weight of the reward model because of protocol restrictions. You can merge the diff weight with original Llama-7B to recover the reward model we used.&lt;/p&gt; &#xA;&lt;p&gt;We upload the diff models, thanks to tatsu-lab, you can recover the reward model follow these steps:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;1) Download the weight diff into your local machine. The weight diff is located at:&#xA;# For English:&#xA;TODO&#xA;# For Chinese:&#xA;https://huggingface.co/Ablustrund/moss-rlhf-reward-model-7B-zh/tree/main&#xA;&#xA;2) Merge the weight diff with the original Llama-7B:&#xA;# For English:&#xA;TODO&#xA;# For Chinese:&#xA;python merge_weight_zh.py recover --path_raw decapoda-research/llama-7b-hf --path_diff ./models/moss-rlhf-reward-model-7B-zh/diff --path_tuned ./models/moss-rlhf-reward-model-7B-zh/recover&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 2: Select your own SFT model&lt;/h3&gt; &#xA;&lt;p&gt;Because of some limitations, we can not release the &lt;strong&gt;Chinese&lt;/strong&gt; SFT model (Currently). You can use your own SFT model, or a strong base model instead of our SFT model.&lt;/p&gt; &#xA;&lt;h3&gt;Step 3: Start training&lt;/h3&gt; &#xA;&lt;p&gt;Run the command below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# For Chinese:&#xA;bash run_zh.sh&#xA;&#xA;# For English:&#xA;TODO&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{zheng2023secrets,&#xA;      title={Secrets of RLHF in Large Language Models Part I: PPO}, &#xA;      author={Rui Zheng and Shihan Dou and Songyang Gao and Wei Shen and Binghai Wang and Yan Liu and Senjie Jin and Qin Liu and Limao Xiong and Lu Chen and Zhiheng Xi and Yuhao Zhou and Nuo Xu and Wenbin Lai and Minghao Zhu and Rongxiang Weng and Wensen Cheng and Cheng Chang and Zhangyue Yin and Yuan Hua and Haoran Huang and Tianxiang Sun and Hang Yan and Tao Gui and Qi Zhang and Xipeng Qiu and Xuanjing Huang},&#xA;      year={2023},&#xA;      eprint={2307.04964},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CL}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>assafelovic/gpt-researcher</title>
    <updated>2023-07-14T01:30:42Z</updated>
    <id>tag:github.com,2023-07-14:/assafelovic/gpt-researcher</id>
    <link href="https://github.com/assafelovic/gpt-researcher" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GPT based autonomous agent that does online comprehensive research on any given topic&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ğŸ” GPT Researcher&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.producthunt.com/posts/gpt-researcher?utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-gpt-researcher&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=404302&amp;amp;theme=light&#34; alt=&#34;GPT Researcher - Autonomous agent designed for comprehensive online research | Product Hunt&#34; style=&#34;width: 250px; height: 54px;&#34; width=&#34;250&#34; height=&#34;54&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://tavily.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Official%20Website-tavily.com-blue?style=flat&amp;amp;logo=world&amp;amp;logoColor=white&#34; alt=&#34;Official Website&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.com/invite/rqw8dnM8&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/rqw8dnM8?style=flat&#34; alt=&#34;Discord Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/assafelovic/gpt-researcher&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/assafelovic/gpt-researcher?style=social&#34; alt=&#34;GitHub Repo stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/assaf_elovic&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/assaf_elovic?style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;GPT Researcher is an autonomous agent designed for comprehensive online research on a variety of tasks.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;The agent can produce detailed, factual and unbiased research reports, with customization options for focusing on relevant resources, outlines, and lessons. Inspired by &lt;a href=&#34;https://github.com/Significant-Gravitas/Auto-GPT&#34;&gt;AutoGPT&lt;/a&gt; and the recent &lt;a href=&#34;https://arxiv.org/abs/2305.04091&#34;&gt;Plan-and-Solve&lt;/a&gt; paper, GPT Researcher addresses issues of speed and determinism, offering a more stable performance and increased speed through parallelized agent work, as opposed to synchronous operations.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Our mission is to empower individuals and organizations with accurate, unbiased, and factual information by leveraging the power of AI.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Why GPT Researcher?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To form objective conclusions for manual research tasks can take time, sometimes weeks to find the right resources and information.&lt;/li&gt; &#xA; &lt;li&gt;Current LLMs are trained on past and outdated information, with heavy risks of hallucinations, making them almost irrelevant for research tasks.&lt;/li&gt; &#xA; &lt;li&gt;Solutions that enable web search (such as ChatGPT + Web Plugin), only consider limited resources that in some cases result in superficial conclusions or biased answers.&lt;/li&gt; &#xA; &lt;li&gt;Using only a selection of resources can create bias in determining the right conclusions for research questions or tasks.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Architecture&lt;/h2&gt; &#xA;&lt;p&gt;The main idea is to run &#34;planner&#34; and &#34;execution&#34; agents, whereas the planner generates questions to research, and the execution agents seek the most related information based on each generated research question. Finally, the planner filters and aggregates all related information and creates a research report. The agents leverage both gpt3.5-turbo-16k and gpt-4 to complete a research task.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img align=&#34;center&#34; height=&#34;500&#34; src=&#34;https://cowriter-images.s3.amazonaws.com/arch.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;More specifcally:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Generate a set of research questions that together form an objective opinion on any given task.&lt;/li&gt; &#xA; &lt;li&gt;For each research question, trigger a crawler agent that scrapes online resources for information relevant to the given task.&lt;/li&gt; &#xA; &lt;li&gt;For each scraped resources, summarize based on relevant information and keep track of its sources.&lt;/li&gt; &#xA; &lt;li&gt;Finally, filter and aggregate all summarized sources and generate a final research report.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/assafelovic/gpt-researcher/assets/13554167/a00c89a6-a295-4dd0-b58d-098a31c40fda&#34;&gt;https://github.com/assafelovic/gpt-researcher/assets/13554167/a00c89a6-a295-4dd0-b58d-098a31c40fda&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸ“ Generate research, outlines, resources and lessons reports&lt;/li&gt; &#xA; &lt;li&gt;ğŸŒ Aggregates over 20 web sources per research to form objective and factual conclusions&lt;/li&gt; &#xA; &lt;li&gt;ğŸ–¥ï¸ Includes an easy-to-use web interface (HTML/CSS/JS)&lt;/li&gt; &#xA; &lt;li&gt;ğŸ” Scrapes web sources with javascript support&lt;/li&gt; &#xA; &lt;li&gt;ğŸ“‚ Keeps track and context of visited and used web sources&lt;/li&gt; &#xA; &lt;li&gt;ğŸ“„ Export research reports to PDF and more...&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 0&lt;/strong&gt; - Install Python 3.11 or later. &lt;a href=&#34;https://www.tutorialsteacher.com/python/install-python&#34;&gt;See here&lt;/a&gt; for a step-by-step guide.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt; - Download the project&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ git clone https://github.com/assafelovic/gpt-researcher.git&#xA;$ cd gpt-researcher&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt; - Install dependencies&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 3&lt;/strong&gt; - Create .env file with your OpenAI Key or simply export it&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ export OPENAI_API_KEY={Your API Key here}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 4&lt;/strong&gt; - Run the agent with FastAPI&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ uvicorn main:app --reload&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 5&lt;/strong&gt; - Go to &lt;a href=&#34;http://localhost:8000&#34;&gt;http://localhost:8000&lt;/a&gt; on any browser and enjoy researching!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;update:&lt;/strong&gt; if you are having issues with weasyprint, please visit their website and follow the installation instructions: &lt;a href=&#34;https://doc.courtbouillon.org/weasyprint/stable/first_steps.html&#34;&gt;https://doc.courtbouillon.org/weasyprint/stable/first_steps.html&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Try it with Docker&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt; - Install Docker&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Follow instructions at &lt;a href=&#34;https://docs.docker.com/engine/install/&#34;&gt;https://docs.docker.com/engine/install/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt; - Create .env file with your OpenAI Key or simply export it&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ export OPENAI_API_KEY={Your API Key here}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 3&lt;/strong&gt; - Run the application&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker-compose up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Step 4&lt;/strong&gt; - Go to &lt;a href=&#34;http://localhost:8000&#34;&gt;http://localhost:8000&lt;/a&gt; on any browser and enjoy researching!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;update:&lt;/strong&gt; if you are having issues with weasyprint, please visit their website and follow the installation instructions: &lt;a href=&#34;https://doc.courtbouillon.org/weasyprint/stable/first_steps.html&#34;&gt;https://doc.courtbouillon.org/weasyprint/stable/first_steps.html&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ›¡ Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This project, GPT Researcher, is an experimental application and is provided &#34;as-is&#34; without any warranty, express or implied. We are sharing codes for academic purposes under the MIT education license. Nothing herein is academic advice, and NOT a recommendation to use in academic or research papers.&lt;/p&gt; &#xA;&lt;p&gt;Our view on unbiased research claims:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The whole point of our scraping system is to reduce incorrect fact. How? The more sites we scrape the less chances of incorrect data. We are scraping 20 per research, the chances that they are all wrong is extremely low.&lt;/li&gt; &#xA; &lt;li&gt;We do not aim to eliminate biases; we aim to reduce it as much as possible. &lt;strong&gt;We are here as a community to figure out the most effective human/llm interactions.&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;In research, people also tend towards biases as most have already opinions on the topics they research about. This tool scrapes many opinions and will evenly explain diverse views that a biased person would never have read.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please note that the use of the GPT-4 language model can be expensive due to its token usage.&lt;/strong&gt; By utilizing this project, you acknowledge that you are responsible for monitoring and managing your own token usage and the associated costs. It is highly recommended to check your OpenAI API usage regularly and set up any necessary limits or alerts to prevent unexpected charges.&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ”§ Troubleshooting&lt;/h2&gt; &#xA;&lt;p&gt;We&#39;re constantly working to provide a more stable version. In the meantime, see here for known issues:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;cannot load library &#39;gobject-2.0-0&#39;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;The issue relates to the library WeasyPrint (which is used to generate PDFs from the research report). Please follow this guide to resolve it: &lt;a href=&#34;https://doc.courtbouillon.org/weasyprint/stable/first_steps.html&#34;&gt;https://doc.courtbouillon.org/weasyprint/stable/first_steps.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Error processing the url&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;We&#39;re using &lt;a href=&#34;https://www.selenium.dev&#34;&gt;Selenium&lt;/a&gt; for site scraping. Some sites fail to be scraped. In these cases, restart and try running again.&lt;/p&gt;</summary>
  </entry>
</feed>