<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-06-28T01:29:14Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>gensyn-ai/rl-swarm</title>
    <updated>2025-06-28T01:29:14Z</updated>
    <id>tag:github.com,2025-06-28:/gensyn-ai/rl-swarm</id>
    <link href="https://github.com/gensyn-ai/rl-swarm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A fully open source framework for creating RL training swarms over the internet.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RL Swarm&lt;/h1&gt; &#xA;&lt;p&gt;RL Swarm is a peer-to-peer system for reinforcement learning. It allows you to train models collaboratively with others in the swarm, leveraging their collective intelligence. It is open source and permissionless, meaning you can run it on a consumer laptop at home or on a powerful GPU in the cloud. You can also connect your model to the Gensyn Testnet to receive an on-chain identity that tracks your progress over time.&lt;/p&gt; &#xA;&lt;p&gt;Currently, we are running the &lt;a href=&#34;https://github.com/open-thought/reasoning-gym/tree/main&#34;&gt;reasoning-gym&lt;/a&gt; swarm on the Testnet. This swarm is designed to train models to solve a diverse set of reasoning tasks using the reasoning-gym dataset. The current list of default models includes:&lt;/p&gt; &#xA;&lt;p&gt;Models:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Gensyn/Qwen2.5-0.5B-Instruct&lt;/li&gt; &#xA; &lt;li&gt;Qwen/Qwen3-0.6B&lt;/li&gt; &#xA; &lt;li&gt;nvidia/AceInstruct-1.5B&lt;/li&gt; &#xA; &lt;li&gt;dnotitia/Smoothie-Qwen3-1.7B&lt;/li&gt; &#xA; &lt;li&gt;Gensyn/Qwen2.5-1.5B-Instruct&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This iteration of rl-swarm is powered by the &lt;a href=&#34;https://github.com/gensyn-ai/genrl-swarm&#34;&gt;GenRL-Swarm&lt;/a&gt; library. It is a fully composable framework for decentralized reinforcement learning which enables users to create and customize their own swarms for reinforcement learning with multi-agent multi-stage environments.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;Your hardware requirements will vary depending on a number of factors including model size and the accelerator platform you use. Users running large NVIDIA GPU will be assigned a model from the large model pool, while users running less powerful hardware will be assigned a model from the small model pool. This design decision is intended to allow users to advance at a similar rate regardless of the hardware they use, maximizing their utility to the swarm.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Supported Hardware&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;arm64 or x86 CPU with minimum 32gb ram (note that if you run other applications during training it might crash training).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;OR&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;CUDA devices (officially supported): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;RTX 3090&lt;/li&gt; &#xA;   &lt;li&gt;RTX 4090&lt;/li&gt; &#xA;   &lt;li&gt;RTX 5090&lt;/li&gt; &#xA;   &lt;li&gt;A100&lt;/li&gt; &#xA;   &lt;li&gt;H100&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;With either configuration, you will need Python &amp;gt;=3.10 (for Mac, you will likely need to upgrade).&lt;/p&gt; &#xA;&lt;h2&gt;⚠️ Please read before continuing ⚠️&lt;/h2&gt; &#xA;&lt;p&gt;This software is &lt;strong&gt;experimental&lt;/strong&gt; and provided as-is for users who are interested in using (or helping to develop) an early version of the Gensyn Protocol for training models.&lt;/p&gt; &#xA;&lt;p&gt;If you care about on-chain participation, you &lt;strong&gt;must&lt;/strong&gt; read the &lt;a href=&#34;https://raw.githubusercontent.com/gensyn-ai/rl-swarm/main/#identity-management&#34;&gt;Identity Management&lt;/a&gt; section below.&lt;/p&gt; &#xA;&lt;p&gt;If you encounter issues, please first check &lt;a href=&#34;https://raw.githubusercontent.com/gensyn-ai/rl-swarm/main/#troubleshooting&#34;&gt;Troubleshooting&lt;/a&gt;. If you cannot find a solution there, please check if there is an open (or closed) &lt;a href=&#34;https://raw.githubusercontent.com/gensyn-ai/issues&#34;&gt;Issue&lt;/a&gt;. If there is no relevant issue, please file one and include 1) all relevant &lt;a href=&#34;https://raw.githubusercontent.com/gensyn-ai/rl-swarm/main/#troubleshooting&#34;&gt;logs&lt;/a&gt;, 2) information about your device (e.g. which GPU, if relevant), and 3) your operating system information.&lt;/p&gt; &#xA;&lt;h2&gt;Instructions&lt;/h2&gt; &#xA;&lt;h3&gt;Run the Swarm&lt;/h3&gt; &#xA;&lt;p&gt;The easiest way to run RL Swarm is using Docker. This ensures a consistent setup across all operating systems with minimal dependencies.&lt;/p&gt; &#xA;&lt;h4&gt;1. Clone this repo&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/gensyn-ai/rl-swarm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2. Install Docker&lt;/h4&gt; &#xA;&lt;p&gt;Make sure you have Docker installed and the Docker daemon is running on your machine. To do that, follow &lt;a href=&#34;https://docs.docker.com/get-started/get-docker/&#34;&gt;these instructions&lt;/a&gt; according to your OS. Ensure you allot sufficient memory to the Docker containers. For example if using Docker Desktop, this can be done by going to Docker Desktop Settings &amp;gt; Resources &amp;gt; Advanced &amp;gt; Memory Limit, and increasing it to the maximum possible value.&lt;/p&gt; &#xA;&lt;h4&gt;3. Start the Swarm&lt;/h4&gt; &#xA;&lt;p&gt;Run the following commands from the root of the repository.&lt;/p&gt; &#xA;&lt;h5&gt;CPU support&lt;/h5&gt; &#xA;&lt;p&gt;If you’re using a Mac or if your machine has CPU-only support:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-compose run --rm --build -Pit swarm-cpu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;GPU support&lt;/h5&gt; &#xA;&lt;p&gt;If you&#39;re using a machine with an officially supported GPU:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-compose run --rm --build -Pit swarm-gpu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Docker compose issue&lt;/h5&gt; &#xA;&lt;p&gt;If &lt;code&gt;docker-compose&lt;/code&gt; does not work when running the above commands, please try &lt;code&gt;docker compose&lt;/code&gt; (no hyphen) instead. I.e. &lt;code&gt; docker compose run --rm --build -Pit swarm-gpu&lt;/code&gt;. This issue sometimes occurs on users running Ubuntu.&lt;/p&gt; &#xA;&lt;h3&gt;Experimental (advanced) mode&lt;/h3&gt; &#xA;&lt;p&gt;If you want to experiment with the &lt;a href=&#34;https://github.com/gensyn-ai/genrl-swarm&#34;&gt;GenRL-Swarm&lt;/a&gt; library and its &lt;a href=&#34;https://github.com/gensyn-ai/genrl-swarm/raw/main/recipes/rgym/rg-swarm.yaml&#34;&gt;configurable parameters&lt;/a&gt;, we recommend you run RL Swarm via shell script:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python3 -m venv .venv&#xA;source .venv/bin/activate&#xA;./run_rl_swarm.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To learn more about experimental mode, check out our &lt;a href=&#34;https://github.com/gensyn-ai/genrl-swarm/raw/main/getting_started.ipynb&#34;&gt;getting started guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Login&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;A browser window will pop open (you&#39;ll need to manually navigate to &lt;a href=&#34;http://localhost:3000/&#34;&gt;http://localhost:3000/&lt;/a&gt; if you&#39;re on a VM).&lt;/li&gt; &#xA; &lt;li&gt;Click &#39;login&#39;.&lt;/li&gt; &#xA; &lt;li&gt;Login with your preferred method.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Huggingface&lt;/h3&gt; &#xA;&lt;p&gt;If you would like to upload your model to Hugging Face, enter your Hugging Face access token when prompted. You can generate one from your Hugging Face account, under &lt;a href=&#34;https://huggingface.co/docs/hub/en/security-tokens&#34;&gt;Access Tokens&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Initial peering and training&lt;/h3&gt; &#xA;&lt;p&gt;From this stage onward your device will begin training. You should see your peer register and vote on-chain &lt;a href=&#34;https://gensyn-testnet.explorer.alchemy.com/address/0xFaD7C5e93f28257429569B854151A1B8DCD404c2?tab=logs&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can also track your training progress in real time:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;On The RL-Swarm Dashboard: &lt;a href=&#34;https://dashboard.gensyn.ai&#34;&gt;dashboard.gensyn.ai&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Identity management&lt;/h2&gt; &#xA;&lt;h3&gt;Introduction&lt;/h3&gt; &#xA;&lt;p&gt;On-chain identity is managed via an Alchemy modal sign-in screen. You need to supply an email address or login via a supported method (e.g. Google). This creates an EOA public/private key (which are stored by Alchemy). You will also receive local session keys in the &lt;code&gt;userApiKey&lt;/code&gt;. Note that these aren&#39;t your EOA public/private keys.&lt;/p&gt; &#xA;&lt;p&gt;During the initial set-up process, you will also create a &lt;code&gt;swarm.pem&lt;/code&gt; file which maintains the identity of your peer. This is then registered on chain using the EOA wallet hosted in Alchemy, triggered using your local api keys. This links the &lt;code&gt;swarm.pem&lt;/code&gt; to the &lt;code&gt;email address&lt;/code&gt; (and corresponding EOA in Alchemy).&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;If you want to link multiple nodes to a single EOA&lt;/strong&gt;, simply sign up each node using the same email address. You will get a new peer ID for each node, however they will all be linked to the same EOA that your email is linked to.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please note&lt;/strong&gt;: if you are using a fork of this repo, or a service organised by someone else (e.g. a &#39;one click deployment&#39; provider) the identity management flow below is not guaranteed.&lt;/p&gt; &#xA;&lt;h3&gt;What this means&lt;/h3&gt; &#xA;&lt;p&gt;In the following two scenarios, everything will work (i.e. you will have an on-chain identity linked with your RL Swarm peer training):&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The very first time you run the node from scratch with a new email address. The smart account will be created fresh and linked with the swarm.pem that is also fresh.&lt;/li&gt; &#xA; &lt;li&gt;If you run it again with a &lt;code&gt;swarm.pem&lt;/code&gt; AND login the original &lt;code&gt;email address&lt;/code&gt; used with that &lt;code&gt;swarm.pem&lt;/code&gt;. Note: this will throw an error into the log on registration but will still be able to sign transactions.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In the following two scenarios, it will not work (i.e. you won&#39;t have an on-chain identity linked with your RL Swarm peer training):&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you keep your &lt;code&gt;swarm.pem&lt;/code&gt; and try to link it to an &lt;code&gt;email address&lt;/code&gt; distinct from the one with which it was first registered.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Therefore, you should do these actions in the following scenarios&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Signed up with &lt;code&gt;email address&lt;/code&gt;, generated &lt;code&gt;swarm.pem&lt;/code&gt;, BUT lost &lt;code&gt;swarm.pem&lt;/code&gt;&lt;/strong&gt; OR &lt;strong&gt;You want to run multiple nodes at once&lt;/strong&gt;: run from scratch with the same email address and generate a new &lt;code&gt;swarm.pem&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Signed up with &lt;code&gt;email address&lt;/code&gt;, generated &lt;code&gt;swarm.pem&lt;/code&gt;, kept &lt;code&gt;swarm.pem&lt;/code&gt;&lt;/strong&gt; -&amp;gt; you can re-run a single node using this pair if you&#39;ve still got them both.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Troubleshooting&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;How do I find my logs?&lt;/strong&gt; You can find them inside the &lt;code&gt;/logs&lt;/code&gt; directory:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;yarn.log&lt;/code&gt;: This file contains logs for the modal login server.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;swarm.log&lt;/code&gt;: This is the main log file for the RL Swarm application.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;wandb/&lt;/code&gt;: This directory contains various logs related to your training runs, including a &lt;code&gt;debug.log&lt;/code&gt; file. These can be updated to Weights &amp;amp; Biases (only available if you log_with wandb).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;My peer &#39;skipped a round&#39;&lt;/strong&gt;: this occurs when your device isn&#39;t fast enough to keep up with the pace of the swarm. For example, if you start training at round 100 and by the time you finish training the rest of the swarm reaches round 102, you will skip round 101 and go straight to 102. This is because your peer is more valuable if it is participating in the active round.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;My model doesn&#39;t seem to be training?&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;If you&#39;re using a consumer device (e.g. a MacBook), it is likely just running slowly - check back in 20 minutes.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Logging in with a new account after previous login?&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Make sure you click &#39;Logout&#39; on the login screen before you leave your previous session&lt;/li&gt; &#xA;   &lt;li&gt;Make sure you delete &lt;code&gt;swarm.pem&lt;/code&gt; from the root directory (try &lt;code&gt;sudo rm swarm.pem&lt;/code&gt;). If you don&#39;t do this, and you previously registered with the peer-id stored in this file, it will disrupt the training process.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Issues with the Login screen&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Upgrade viem&lt;/strong&gt;: some users report issues with the &lt;code&gt;viem&lt;/code&gt; package. There are two fixes: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;in the &lt;code&gt;modal-login/package.json&lt;/code&gt; update: &lt;code&gt;&#34;viem&#34;: &#34;2.25.0&#34;&lt;/code&gt;&lt;/li&gt; &#xA;     &lt;li&gt;in the terminal &lt;code&gt;cd /root/rl-swarm/modal-login/ &amp;amp;&amp;amp; yarn upgrade &amp;amp;&amp;amp; yarn add next@latest &amp;amp;&amp;amp; yarn add viem@latest&lt;/code&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;I&#39;m getting lots of warnings&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This is expected behaviour and usually the output of the package managers or other dependencies. The most common is the below Protobuf warning - which can be ignored &lt;pre&gt;&lt;code&gt;WARNING: The candidate selected for download or install is a yanked version: &#39;protobuf&#39; candidate...&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Issues on VMs/VPSs?&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;How do I access the login screen if I&#39;m running in a VM?&lt;/strong&gt;: port forwarding. Add this SSH flag: &lt;code&gt;-L 3000:localhost:3000&lt;/code&gt; when connecting to your VM. E.g. &lt;code&gt;gcloud compute ssh --zone &#34;us-central1-a&#34; [your-vm] --project [your-project] -- -L 3000:localhost:3000&lt;/code&gt;. Note, some VPSs may not work with &lt;code&gt;rl-swarm&lt;/code&gt;. Check the Gensyn &lt;a href=&#34;https://discord.gg/AdnyWNzXh5&#34;&gt;discord&lt;/a&gt; for up-to-date information on this.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Disconnection/general issues&lt;/strong&gt;: If you are tunneling to a VM and suffer a broken pipe, you will likely encounter OOM or unexpected behaviour the first time you relaunch the script. If you &lt;code&gt;control + c&lt;/code&gt; and kill the script it should spin down all background processes. Restart the script and everything should work normally.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Issues with npm/general installation?&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Try &lt;code&gt;npm install -g node@latest&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;OOM errors on MacBook?&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Try this (experimental) fix to increase memory: &lt;pre&gt;&lt;code&gt;export PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;I have a Windows machine, can I still train a model on the swarm?&lt;/strong&gt;: Yes - but this is not very well tested and may require you to do some debugging to get it set up properly. Install WSL and Linux on your Windows machine using the following instructions: &lt;a href=&#34;https://learn.microsoft.com/en-us/windows/wsl/install&#34;&gt;https://learn.microsoft.com/en-us/windows/wsl/install&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;I want to move my to a different machine and/or restart with a fresh build of the repo, but I want my animal name/peer id to persist.&lt;/strong&gt;: To achieve this simply backup the &lt;code&gt;swarm.pem&lt;/code&gt; file on your current machine and then put it in the corresponding location on your new machine/build of the repo.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;I have multiple GPUs on one machine, can I run multiple peers?&lt;/strong&gt;: Yes - but you&#39;ll need to manually change things. You&#39;ll need to isolate each GPU, install this repo for each GPU, and expose each peer under a different port to pass the modal onboard.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;My round/stage is behind the smart contract/other peers?&lt;/strong&gt;: This is expected behaviour given the different speeds of machines in the network. Once your machine completes it&#39;s current round, it will move to the the current round.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;I want to use a bigger and/or different model in the RL swarm, can I do that?&lt;/strong&gt;: Yes - but we only recommend doing so if you are comfortable understanding what size model can reasonably run on your hardware. If you elect to bring a custom model, just paste the repo/model name into the command line when prompted.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;I am running a model in the swarm on my CPU, have received a python &lt;code&gt;RuntimeError&lt;/code&gt;, and my training progress seems to have stopped.&lt;/strong&gt;: There are several possible causes for this, but before trying anything please wait long enough to be sure your training actually is frozen and not just slow (e.g., wait longer than a single training iteration has previously taken on your machine). If you&#39;re sure training is actually frozen, then some things to try are:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Set this (experimental) fix: &lt;code&gt;export PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 &amp;amp;&amp;amp; ./run_rl_swarm.sh&lt;/code&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>rxi/microui</title>
    <updated>2025-06-28T01:29:14Z</updated>
    <id>tag:github.com,2025-06-28:/rxi/microui</id>
    <link href="https://github.com/rxi/microui" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A tiny immediate-mode UI library&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/3920290/75171571-be83c500-5723-11ea-8a50-504cc2ae1109.png&#34; alt=&#34;microui&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;A &lt;em&gt;tiny&lt;/em&gt;, portable, immediate-mode UI library written in ANSI C&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Tiny: around &lt;code&gt;1100 sloc&lt;/code&gt; of ANSI C&lt;/li&gt; &#xA; &lt;li&gt;Works within a fixed-sized memory region: no additional memory is allocated&lt;/li&gt; &#xA; &lt;li&gt;Built-in controls: window, scrollable panel, button, slider, textbox, label, checkbox, wordwrapped text&lt;/li&gt; &#xA; &lt;li&gt;Works with any rendering system that can draw rectangles and text&lt;/li&gt; &#xA; &lt;li&gt;Designed to allow the user to easily add custom controls&lt;/li&gt; &#xA; &lt;li&gt;Simple layout system&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/3920290/75187058-2b598800-5741-11ea-9358-38caf59f8791.png&#34; alt=&#34;example&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;if (mu_begin_window(ctx, &#34;My Window&#34;, mu_rect(10, 10, 140, 86))) {&#xA;  mu_layout_row(ctx, 2, (int[]) { 60, -1 }, 0);&#xA;&#xA;  mu_label(ctx, &#34;First:&#34;);&#xA;  if (mu_button(ctx, &#34;Button1&#34;)) {&#xA;    printf(&#34;Button1 pressed\n&#34;);&#xA;  }&#xA;&#xA;  mu_label(ctx, &#34;Second:&#34;);&#xA;  if (mu_button(ctx, &#34;Button2&#34;)) {&#xA;    mu_open_popup(ctx, &#34;My Popup&#34;);&#xA;  }&#xA;&#xA;  if (mu_begin_popup(ctx, &#34;My Popup&#34;)) {&#xA;    mu_label(ctx, &#34;Hello world!&#34;);&#xA;    mu_end_popup(ctx);&#xA;  }&#xA;&#xA;  mu_end_window(ctx);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Screenshot&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/3920290/75188642-63ae9580-5744-11ea-9eee-d753ff5c0aa7.png&#34; alt=&#34;screenshot&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://floooh.github.io/sokol-html5/sgl-microui-sapp.html&#34;&gt;&lt;strong&gt;Browser Demo&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/rxi/microui/master/doc/usage.md&#34;&gt;&lt;code&gt;doc/usage.md&lt;/code&gt;&lt;/a&gt; for usage instructions&lt;/li&gt; &#xA; &lt;li&gt;See the &lt;a href=&#34;https://raw.githubusercontent.com/rxi/microui/master/demo&#34;&gt;&lt;code&gt;demo&lt;/code&gt;&lt;/a&gt; directory for a usage example&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Notes&lt;/h2&gt; &#xA;&lt;p&gt;The library expects the user to provide input and handle the resultant drawing commands, it does not do any drawing itself.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;The library is designed to be lightweight, providing a foundation to which you can easily add custom controls and UI elements; pull requests adding additional features will likely not be merged. Bug reports are welcome.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This library is free software; you can redistribute it and/or modify it under the terms of the MIT license. See &lt;a href=&#34;https://raw.githubusercontent.com/rxi/microui/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>coleam00/ottomator-agents</title>
    <updated>2025-06-28T01:29:14Z</updated>
    <id>tag:github.com,2025-06-28:/coleam00/ottomator-agents</id>
    <link href="https://github.com/coleam00/ottomator-agents" rel="alternate"></link>
    <summary type="html">&lt;p&gt;All the open source AI Agents hosted on the oTTomator Live Agent Studio platform!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;What is the Live Agent Studio?&lt;/h1&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://studio.ottomator.ai&#34;&gt;Live Agent Studio&lt;/a&gt; is a community-driven platform developed by &lt;a href=&#34;https://ottomator.ai&#34;&gt;oTTomator&lt;/a&gt; for you to explore cutting-edge AI agents and learn how to implement them for yourself or your business! All agents on this platform are open source and, over time, will cover a very large variety of use cases.&lt;/p&gt; &#xA;&lt;p&gt;The goal with the studio is to build an educational platform for you to learn how to do incredible things with AI, while still providing practical value so that you’ll want to use the agents just for the sake of what they can do for you!&lt;/p&gt; &#xA;&lt;p&gt;This platform is still in beta – expect longer response times under load, a rapidly growing agent library over the coming months, and a lot more content on this platform soon on Cole Medin’s YouTube channel!&lt;/p&gt; &#xA;&lt;h1&gt;What is this Repository for?&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the source code/workflow JSON for all the agents on the Live Agent Studio! Every agent being added to the platform is currently be open sourced here so we can not only create a curated collection of cutting-edge agents together as a community, but also learn from one another!&lt;/p&gt; &#xA;&lt;h2&gt;Tokens&lt;/h2&gt; &#xA;&lt;p&gt;Most agents on the Live Agent Studio cost tokens to use, which are purchasable on the platform. However, when you first sign in you are given some tokens to start so you can use the agents free of charge! The biggest reason agents cost tokens is that we pay for the LLM usage since we host all the agents developed by you and the rest of the community!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://studio.ottomator.ai/pricing&#34;&gt;Purchase Tokens&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Future Plans&lt;/h2&gt; &#xA;&lt;p&gt;As the Live Agent Studio develops, it will become the go-to place to stay on top of what is possible with AI agents! Anytime there is a new AI technology, groundbreaking agent research, or a new tool/library to build agents with, it’ll be featured through agents on the platform. It’s a tall order, but we have big plans for the oTTomator community, and we’re confident we can grow to accomplish this!&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;h3&gt;I want to build an agent to showcase in the Live Agent Studio! How do I do that?&lt;/h3&gt; &#xA;&lt;p&gt;Head on over here to learn how to build an agent for the platform:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://studio.ottomator.ai/guide&#34;&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Also check out &lt;a href=&#34;https://raw.githubusercontent.com/coleam00/ottomator-agents/main/~sample-n8n-agent~&#34;&gt;the sample n8n agent&lt;/a&gt; for a starting point of building an n8n agent for the Live Agent Studio, and &lt;a href=&#34;https://raw.githubusercontent.com/coleam00/ottomator-agents/main/~sample-python-agent~&#34;&gt;the sample Python agent&lt;/a&gt; for Python.&lt;/p&gt; &#xA;&lt;h3&gt;How many tokens does it cost to use an agent?&lt;/h3&gt; &#xA;&lt;p&gt;Each agent will charge tokens per prompt. The number of tokens depends on the agent, as some agents use larger LLMs, some call LLMs multiple times, and some use paid APIs.&lt;/p&gt; &#xA;&lt;h3&gt;Where can I go to talk about all these agents and get help implementing them myself?&lt;/h3&gt; &#xA;&lt;p&gt;Head on over to our Think Tank community and feel free to make a post!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://thinktank.ottomator.ai&#34;&gt;Think Tank Community&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;© 2024 Live Agent Studio. All rights reserved.&lt;br&gt; Created by oTTomator&lt;/p&gt;</summary>
  </entry>
</feed>