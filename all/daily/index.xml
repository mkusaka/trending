<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-10T01:31:10Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>shawwn/llama-dl</title>
    <updated>2023-03-10T01:31:10Z</updated>
    <id>tag:github.com,2023-03-10:/shawwn/llama-dl</id>
    <link href="https://github.com/shawwn/llama-dl" rel="alternate"></link>
    <summary type="html">&lt;p&gt;High-speed download of LLaMA, Facebook&#39;s 65B parameter GPT model&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;llama-dl&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/anitakirkovska/status/1632447982720131074&#34;&gt;&lt;img width=&#34;310&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/59632/222979421-290299aa-b34f-4f3a-97c7-23332fe12c36.png&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=35026902&#34;&gt;HN discussion&lt;/a&gt; | &lt;a href=&#34;https://twitter.com/theshawwn/status/1632238214529400832&#34;&gt;Twitter announcement&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Update (March 7, 3:35 PM CST)&lt;/strong&gt;: Looking to inference from the model? See &lt;a href=&#34;https://github.com/shawwn/llama-dl/issues/1#issuecomment-1458870564&#34;&gt;https://github.com/shawwn/llama-dl/issues/1#issuecomment-1458870564&lt;/a&gt; to use the improved sampler. (Facebook&#39;s sampler was using poor defaults, so no one was able to get anything good out of the model till now.)&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Update (March 5, 12:52 PM CST)&lt;/strong&gt;: &lt;a href=&#34;https://twitter.com/anitakirkovska&#34;&gt;@anitakirkovska&lt;/a&gt; let us use their fabulous llama photo. If you happen to like the new header image as much as I do, be sure to check out their &lt;a href=&#34;https://www.theprompt.io/&#34;&gt;AI newsletter&lt;/a&gt; and their &lt;a href=&#34;https://twitter.com/anitakirkovska/status/1632447982720131074&#34;&gt;tweets about us&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Update (March 5, 9:51 AM CST)&lt;/strong&gt;: HN user MacsHeadroom left a &lt;a href=&#34;https://news.ycombinator.com/item?id=35029766&#34;&gt;valuable comment&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;I&#39;m running LLaMA-65B on a single A100 80GB with 8bit quantization. $1.5/hr on vast.ai&lt;/p&gt; &#xA; &lt;p&gt;The output is at least as good as davinci.&lt;/p&gt; &#xA; &lt;p&gt;I think some early results are using bad repetition penalty and/or temperature settings. I had to set both fairly high to get the best results. (Some people are also incorrectly comparing it to chatGPT/ChatGPT API which is not a good comparison. But that&#39;s a different problem.)&lt;/p&gt; &#xA; &lt;p&gt;I&#39;ve had it translate, write poems, tell jokes, banter, write executable code. It does it all-- and all on a single card.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Intro&lt;/h2&gt; &#xA;&lt;p&gt;This repository contains a high-speed download of LLaMA, Facebook&#39;s 65B parameter model that was recently made available via torrent. (Discussion: &lt;a href=&#34;https://news.ycombinator.com/item?id=35007978&#34;&gt;Facebook LLAMA is being openly distributed via torrents&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;p&gt;It downloads all model weights (7B, 13B, 30B, 65B) in less than two hours on a Chicago Ubuntu server.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;real    98m12.980s&#xA;user    8m8.916s&#xA;sys     5m7.259s&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This works out to 40MB/s (235164838073 bytes in 5892 seconds).&lt;/p&gt; &#xA;&lt;p&gt;Personally, I just wanted to &lt;code&gt;curl&lt;/code&gt; the weights instead of dealing with a torrent. The fact that it&#39;s several times faster was just a nice bonus.&lt;/p&gt; &#xA;&lt;h2&gt;Download&lt;/h2&gt; &#xA;&lt;p&gt;To download all model weights, &lt;code&gt;cd&lt;/code&gt; into the directory you want them, then run this:&lt;/p&gt; &#xA;&lt;p&gt;Linux:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -o- https://raw.githubusercontent.com/shawwn/llama-dl/56f50b96072f42fb2520b1ad5a1d6ef30351f23c/llama.sh | bash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Mac:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;brew install bash&#xA;brew install wget&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -o- https://raw.githubusercontent.com/shawwn/llama-dl/56f50b96072f42fb2520b1ad5a1d6ef30351f23c/llama.sh | $(brew --prefix)/bin/bash&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;(Sorry mac users; they use some array syntax in the script that isn&#39;t supported on the version of bash that ships with Mac.)&lt;/p&gt; &#xA;&lt;p&gt;Running random bash scripts generally isn&#39;t a good idea, but I&#39;ll stake my personal reputation on the fact that this link is safe. (It points to a specific SHA-1 hash rather than &lt;a href=&#34;https://raw.githubusercontent.com/shawwn/llama-dl/main/llama.sh&#34;&gt;https://raw.githubusercontent.com/shawwn/llama-dl/main/llama.sh&lt;/a&gt; so that it&#39;s still safe even in the event that my repo or account got compromised.)&lt;/p&gt; &#xA;&lt;h2&gt;How much space do I need?&lt;/h2&gt; &#xA;&lt;p&gt;219G (235164838073 bytes) total. &lt;a href=&#34;https://gist.github.com/shawwn/bddb2f91aa45fbcdc0dd105d88816e75&#34;&gt;Here&#39;s a file list&lt;/a&gt; with sizes for each.&lt;/p&gt; &#xA;&lt;h2&gt;How do I know this is safe?&lt;/h2&gt; &#xA;&lt;p&gt;I ran this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir LLaMA&#xA;cd LLaMA&#xA;time curl -o- https://raw.githubusercontent.com/shawwn/llama-dl/56f50b96072f42fb2520b1ad5a1d6ef30351f23c/llama.sh | bash&#xA;cd ..&#xA;webtorrent &#39;magnet:?xt=urn:btih:b8287ebfa04f879b048d4d4404108cf3e8014352&amp;amp;dn=LLaMA&amp;amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/webtorrent/webtorrent-cli&#34;&gt;Webtorrent&lt;/a&gt; began seeding immediately, which means every file is identical to what you would&#39;ve gotten via the torrent. So this is just a faster version of the torrent.&lt;/p&gt; &#xA;&lt;img width=&#34;310&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/59632/222940942-0051a645-b561-4f0b-878c-3d195354d526.png&#34;&gt; &#xA;&lt;img width=&#34;310&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/59632/222941107-b4ef0b21-3fa7-40d1-ae56-cbe385e6ac00.png&#34;&gt; &#xA;&lt;h2&gt;How much faster? (Updated)&lt;/h2&gt; &#xA;&lt;p&gt;Roughly 3.6x. As of March 4 2023, the torrent seems to download at around 11MB/s, which implies a download time of around 6 hours. (Help seed it, if you can.)&lt;/p&gt; &#xA;&lt;img width=&#34;300&#34; alt=&#34;image&#34; src=&#34;https://user-images.githubusercontent.com/59632/222940992-f037b12c-c077-4136-8960-b2b1667ddc79.png&#34;&gt; &#xA;&lt;h2&gt;Will I get in trouble for using this download link?&lt;/h2&gt; &#xA;&lt;p&gt;I doubt it. This is using the download link that was leaked in the original torrent. (i.e. the leaker accidentally leaked their own unique download link that Facebook sent them.)&lt;/p&gt; &#xA;&lt;p&gt;Technically, it may be illegal to knowingly use a private download link that was intended for someone else. Realistically, Facebook would risk their ML reputation by going after people who are merely trying to use what they themselves advertise as &#34;open source.&#34;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: Facebook shut off the link a couple hours after this repo went live. I mirrored everything to R2 and updated the script to point to that instead.&lt;/p&gt; &#xA;&lt;p&gt;Note that LLaMA was released under a &lt;a href=&#34;https://github.com/facebookresearch/llama/raw/main/MODEL_CARD.md&#34;&gt;&#34;non-commercial bespoke license&#34;&lt;/a&gt;. Interestingly, Nvidia had a similar arrangement for StyleGAN, but that didn&#39;t stop Artbreeder from using it anyway. Nvidia never seemed to care enough to go after them. But if you &lt;a href=&#34;https://github.com/shawwn/openai-server&#34;&gt;launch your own OpenAI API&lt;/a&gt; and start charging money, don&#39;t be surprised when Facebook&#39;s lawyers come knocking.&lt;/p&gt; &#xA;&lt;h2&gt;Final thoughts&lt;/h2&gt; &#xA;&lt;p&gt;I was shocked that this script was distributed with the original torrent, and that no one seemed to notice (a) that it still works, and (b) is almost 20x faster than the torrent method. I was impatient and curious to try to run 65B on an 8xA100 cluster, so I didn&#39;t want to wait till tomorrow and started poking around, which is when I found this. I decided to just tweet it out and let you, fellow scientists and hackers, enjoy it before Facebook notices and shuts it off.&lt;/p&gt; &#xA;&lt;p&gt;&#34;Power to the people&#34; is an overused trope, but as a research scientist, I feel it&#39;s important to let individual hackers be able to experiment with the same tools, techniques, and systems that professional ML researchers are fortunate to have access to. This is a tricky situation, because at some point between now and 10 years from now, this might become dangerous -- AI alarmists often ask &#34;Would you want random people experimenting with nuclear weapons in their basement?&#34; My answer is &#34;No, but we&#39;re not there yet.&#34;&lt;/p&gt; &#xA;&lt;p&gt;Word on Twitter is that LLaMA&#39;s samples seem worse than GPT-3 by a large margin, but then I realized no one has really been able to try the full 65B model yet, for a combination of reasons. (Mostly lack of access to 8xA100 hardware.) So I decided to try it out for myself and see.&lt;/p&gt; &#xA;&lt;p&gt;Even if it&#39;s GPT-3 level, the fact is, LLaMA is already openly available. The torrent isn&#39;t going anywhere. So my own thoughts on this are mostly irrelevant; determined hackers can get it themselves anyway.&lt;/p&gt; &#xA;&lt;p&gt;But for what it&#39;s worth, my personal opinion is that LLaMA probably isn&#39;t OpenAI-grade -- there&#39;s a big difference between training a model in an academic setting vs when your entire company depends on it for wide-scale commercial success. I wasn&#39;t impressed that 30B didn&#39;t seem to know who Captain Picard was.&lt;/p&gt; &#xA;&lt;p&gt;People have already started decrying this leak as dangerous. But everyone used to say the same thing about 1.5B. (In fact, the allure of 1.5B&#39;s grandiose claims was what drove me to take ML seriously in 2019.) Turns out, four years later, no one really cares about 1.5B anymore, and it certainly didn&#39;t cause wide-scale societal harm. I doubt LLaMA will either.&lt;/p&gt; &#xA;&lt;p&gt;2023 will be interesting. I can&#39;t wait for 2024.&lt;/p&gt; &#xA;&lt;p&gt;Signed with love,&lt;/p&gt; &#xA;&lt;p&gt;Shawn Presser&lt;/p&gt; &#xA;&lt;p&gt;twitter: &lt;a href=&#34;https://twitter.com/theshawwn&#34;&gt;@theshawwn&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;HN: &lt;a href=&#34;https://news.ycombinator.com/user?id=sillysaurusx&#34;&gt;sillysaurusx&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>easychen/openai-gpt-dev-notes-for-cn-developer</title>
    <updated>2023-03-10T01:31:10Z</updated>
    <id>tag:github.com,2023-03-10:/easychen/openai-gpt-dev-notes-for-cn-developer</id>
    <link href="https://github.com/easychen/openai-gpt-dev-notes-for-cn-developer" rel="alternate"></link>
    <summary type="html">&lt;p&gt;如何快速开发一个OpenAI/GPT应用：国内开发者笔记&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;如何快速开发一个OpenAI/GPT应用&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;一个国内开发者的OpenAI/GPT的笔记&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;最近都在问，于是写个文档。本文希望用尽可能少的内容，讲清楚开发一个OpenAI/GPT应用必然用到的知识。&lt;/p&gt; &#xA;&lt;p&gt;欢迎PR补充。&lt;/p&gt; &#xA;&lt;h3&gt;AI/Automation开发交流群&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;电报群 &lt;a href=&#34;https://t.me/+s-5piM3koEphNDY1&#34;&gt;https://t.me/+s-5piM3koEphNDY1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;微信群&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/images/20230308122318.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;目录&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/#chatgpt--openai-%E7%9A%84%E5%85%B3%E7%B3%BB&#34;&gt;ChatGPT &amp;amp;&amp;amp; OpenAI 的关系&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/#openai-api-%E6%8E%A5%E5%8F%A3%E8%83%BD%E5%81%9A%E4%BB%80%E4%B9%88&#34;&gt;OpenAI API 接口能做什么&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/#chat-completions-%E6%8E%A5%E5%8F%A3%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8&#34;&gt;chat completions 接口如何使用？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/#chat-completions-%E6%8E%A5%E5%8F%A3%E5%A6%82%E4%BD%95%E8%AE%A1%E8%B4%B9&#34;&gt;chat completions 接口如何计费？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/#chat-completions-%E6%8E%A5%E5%8F%A3%E8%83%BD%E5%81%9A%E4%BB%80%E4%B9%88-&#34;&gt;chat completions 接口能做什么 ①&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/#chat-completions-%E6%8E%A5%E5%8F%A3%E8%83%BD%E5%81%9A%E4%BB%80%E4%B9%88--1&#34;&gt;chat completions 接口能做什么 ②&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/#%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E5%9B%BD%E5%86%85%E7%94%A8%E6%88%B7%E6%97%A0%E6%B3%95%E6%B3%A8%E5%86%8Copenai%E8%B4%A6%E5%8F%B7%E6%97%A0%E6%B3%95%E8%AE%BF%E9%97%AEopenai%E6%8E%A5%E5%8F%A3%E7%9A%84%E9%97%AE%E9%A2%98&#34;&gt;如何解决国内用户无法注册OpenAI账号、无法访问OpenAI接口的问题？&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/#%E6%B3%A8%E5%86%8Copenai&#34;&gt;注册OpenAI&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/#%E8%AE%BF%E9%97%AEopenai-api&#34;&gt;访问OpenAI API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/#%E9%80%9A%E8%BF%87%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8E%A5%E5%8F%A3%E8%AE%BF%E9%97%AE&#34;&gt;通过第三方接口访问&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ChatGPT &amp;amp;&amp;amp; OpenAI 的关系&lt;/h2&gt; &#xA;&lt;p&gt;ChatGPT 是 OpenAI 推出的应用，使用的是最新的模型；而 OpenAI 开放接口的模型是 gpt-3.5-turbo ，这个模型比 ChatGPT 应用要笨。但 ChatGPT 用的最新模型没有接口，只能通过无头浏览器等方式来使用（不稳定）。&lt;/p&gt; &#xA;&lt;h2&gt;OpenAI API 接口能做什么&lt;/h2&gt; &#xA;&lt;p&gt;能做的事情很多，可以查看&lt;a href=&#34;https://platform.openai.com/docs&#34;&gt;官方文档&lt;/a&gt;，但这个文档中国网络目前无法访问。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/images/20230307155346.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;具体来讲，OpenAI 所有的可用的接口都在里边，包括语音识别和图片生成。但真正智能的其实只有 &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;，因此刚开始不用看其他内容。&lt;/p&gt; &#xA;&lt;p&gt;目前大家看到的绝大部分GPT类应用都是由 &lt;code&gt;gpt-3.5-turbo&lt;/code&gt; 模型的 &lt;code&gt;chat completions&lt;/code&gt; 对话补全接口实现的。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/images/20230307150247.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;chat completions 接口如何使用？&lt;/h2&gt; &#xA;&lt;p&gt;可以通过很多方式来使用，比如使用官方SDK，第三方项目，但其实只需要一个HTTP请求就可以。以下是官方文档给出的例子：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl https://api.openai.com/v1/chat/completions \&#xA;  -H &#39;Content-Type: application/json&#39; \&#xA;  -H &#39;Authorization: Bearer YOUR_API_KEY&#39; \&#xA;  -d &#39;{&#xA;  &#34;model&#34;: &#34;gpt-3.5-turbo&#34;,&#xA;  &#34;messages&#34;: [{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Hello!&#34;}]&#xA;}&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;从里边可以看到，需要的信息有：&lt;/p&gt; &#xA;&lt;p&gt;① 请求地址： &lt;code&gt;https://api.openai.com/v1/chat/completions&lt;/code&gt; 这个地址目前在国内大部分地区已经无法访问了，后边会讲解决办法&lt;/p&gt; &#xA;&lt;p&gt;② 最常用的接口参数包括：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;model: 必填，建议使用 &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;，便宜。计费后边会讲。&lt;/li&gt; &#xA; &lt;li&gt;messages: AI 进行提问的问题或信息。&lt;/li&gt; &#xA; &lt;li&gt;max_tokens: 选填，指定生成回答的最大长度。&lt;/li&gt; &#xA; &lt;li&gt;stream: 选填，是否按流的方式发送内容。&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;其中 messages的格式为：&lt;code&gt;{&#34;role&#34;,&#34;content&#34;}&lt;/code&gt;。一般用 &lt;code&gt;user&lt;/code&gt; 发送用户问题；&lt;code&gt;system&lt;/code&gt; 发送给模型提示信息。&lt;/p&gt; &#xA;&lt;p&gt;例如：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[&#xA;  {&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: &#34;You are a helpful assistant that translates English to French.&#34;},&#xA;  {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Translate the following English text to French: {text}&#34;}&#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;知道了这些基本就可以跑通GPT流程了，其他role可以稍后优化时来做。&lt;/p&gt; &#xA;&lt;h3&gt;Stream 参数&lt;/h3&gt; &#xA;&lt;p&gt;这里单独说一下 stream 参数，当它设置为 true 时，API 会以 SSE（ Server Side Event ）方式返回内容。&lt;/p&gt; &#xA;&lt;p&gt;SSE 本质上还是 HTTP 协议，只不过它是一个长链接，先输出一个 &lt;code&gt;header(&#34;Content-Type: text/event-stream&#34;)&lt;/code&gt; ， 然后持续不断地输出内容直到完成。如果不是做实时聊天，建议直接false掉。&lt;/p&gt; &#xA;&lt;p&gt;需要注意的是，开启stream 后，将不会返回 usage 信息，这对精准计费有影响&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;{&#34;id&#34;:&#34;chatcmpl-6s3hNohxOliHi8zR7m5UTrLm4cWWc&#34;,&#34;object&#34;:&#34;chat.completion.chunk&#34;,&#34;created&#34;:1678341949,&#34;model&#34;:&#34;gpt-3.5-turbo-0301&#34;,&#34;choices&#34;:[{&#34;delta&#34;:{&#34;content&#34;:&#34;我&#34;},&#34;index&#34;:0,&#34;finish_reason&#34;:null}]}&#xA;{&#34;id&#34;:&#34;chatcmpl-6s3hNohxOliHi8zR7m5UTrLm4cWWc&#34;,&#34;object&#34;:&#34;chat.completion.chunk&#34;,&#34;created&#34;:1678341949,&#34;model&#34;:&#34;gpt-3.5-turbo-0301&#34;,&#34;choices&#34;:[{&#34;delta&#34;:{&#34;content&#34;:&#34;没有&#34;},&#34;index&#34;:0,&#34;finish_reason&#34;:null}]}&#xA;{&#34;id&#34;:&#34;chatcmpl-6s3hNohxOliHi8zR7m5UTrLm4cWWc&#34;,&#34;object&#34;:&#34;chat.completion.chunk&#34;,&#34;created&#34;:1678341949,&#34;model&#34;:&#34;gpt-3.5-turbo-0301&#34;,&#34;choices&#34;:[{&#34;delta&#34;:{&#34;content&#34;:&#34;当前&#34;},&#34;index&#34;:0,&#34;finish_reason&#34;:null}]}&#xA;{&#34;id&#34;:&#34;chatcmpl-6s3hNohxOliHi8zR7m5UTrLm4cWWc&#34;,&#34;object&#34;:&#34;chat.completion.chunk&#34;,&#34;created&#34;:1678341949,&#34;model&#34;:&#34;gpt-3.5-turbo-0301&#34;,&#34;choices&#34;:[{&#34;delta&#34;:{&#34;content&#34;:&#34;日期&#34;},&#34;index&#34;:0,&#34;finish_reason&#34;:null}]}&#xA;{&#34;id&#34;:&#34;chatcmpl-6s3hNohxOliHi8zR7m5UTrLm4cWWc&#34;,&#34;object&#34;:&#34;chat.completion.chunk&#34;,&#34;created&#34;:1678341949,&#34;model&#34;:&#34;gpt-3.5-turbo-0301&#34;,&#34;choices&#34;:[{&#34;delta&#34;:{&#34;content&#34;:&#34;的&#34;},&#34;index&#34;:0,&#34;finish_reason&#34;:null}]}&#xA;{&#34;id&#34;:&#34;chatcmpl-6s3hNohxOliHi8zR7m5UTrLm4cWWc&#34;,&#34;object&#34;:&#34;chat.completion.chunk&#34;,&#34;created&#34;:1678341949,&#34;model&#34;:&#34;gpt-3.5-turbo-0301&#34;,&#34;choices&#34;:[{&#34;delta&#34;:{&#34;content&#34;:&#34;实&#34;},&#34;index&#34;:0,&#34;finish_reason&#34;:null}]}&#xA;{&#34;id&#34;:&#34;chatcmpl-6s3hNohxOliHi8zR7m5UTrLm4cWWc&#34;,&#34;object&#34;:&#34;chat.completion.chunk&#34;,&#34;created&#34;:1678341949,&#34;model&#34;:&#34;gpt-3.5-turbo-0301&#34;,&#34;choices&#34;:[{&#34;delta&#34;:{&#34;content&#34;:&#34;时&#34;},&#34;index&#34;:0,&#34;finish_reason&#34;:null}]}&#xA;{&#34;id&#34;:&#34;chatcmpl-6s3hNohxOliHi8zR7m5UTrLm4cWWc&#34;,&#34;object&#34;:&#34;chat.completion.chunk&#34;,&#34;created&#34;:1678341949,&#34;model&#34;:&#34;gpt-3.5-turbo-0301&#34;,&#34;choices&#34;:[{&#34;delta&#34;:{&#34;content&#34;:&#34;信息&#34;},&#34;index&#34;:0,&#34;finish_reason&#34;:null}]}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;一个猜想：通过观察SSE返回的内容，感觉它每次很可能是一次返回一个Token，如果这样的话，直接Count Event数量就可以知道Token数量了，但依然需要自己计算 input 部分的 Token。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;其他参数&lt;/h3&gt; &#xA;&lt;p&gt;接口的其他参数可以看&lt;a href=&#34;https://platform.openai.com/docs/api-reference/chat&#34;&gt;官方文档&lt;/a&gt;，访问不了的同学可以看我做的截图。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/images/20230307143748.png&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/images/20230307143831.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Chat completions 接口如何计费？&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;chat completions&lt;/code&gt; 接口按 token 计费，有一个专门的算法来计算 token。输入和输出全部都会计入到 token 里边，在 &lt;code&gt;chat completions&lt;/code&gt; 接口的 &lt;code&gt;usage&lt;/code&gt; 里边会有具体消耗的 token 数。&lt;/p&gt; &#xA;&lt;p&gt;如果你要自己计算，可以用这个&lt;a href=&#34;https://tiktokenizer.vercel.app&#34;&gt;在线表单&lt;/a&gt;，程序计算可以看看这两个项目：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dqbd/tiktokenizer&#34;&gt;https://github.com/dqbd/tiktokenizer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/tiktoken&#34;&gt;https://github.com/openai/tiktoken&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;除了 &lt;code&gt;gpt-3.5-turbo&lt;/code&gt; 模型的 &lt;code&gt;chat completions&lt;/code&gt; 接口，还有 &lt;code&gt;text-davinci-003&lt;/code&gt; 模型的 &lt;code&gt;text completions&lt;/code&gt; 接口可以用，但是价格更贵，效果更差 🤣&lt;/p&gt; &#xA;&lt;p&gt;你可以在 &lt;a href=&#34;https://openai.com/pricing&#34;&gt;https://openai.com/pricing&lt;/a&gt; 查询到价格，以下是3月中旬的定价&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;Usage&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;gpt-3.5-turbo (ChatGPT)&lt;/td&gt; &#xA;   &lt;td&gt;$0.002 / 1K tokens&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Davinci (InstructGPT)&lt;/td&gt; &#xA;   &lt;td&gt;$0.0200 / 1K tokens&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ada (InstructGPT)&lt;/td&gt; &#xA;   &lt;td&gt;$0.0004 / 1K tokens&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Babbage (InstructGPT)&lt;/td&gt; &#xA;   &lt;td&gt;$0.0005 / 1K tokens&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Curie (InstructGPT)&lt;/td&gt; &#xA;   &lt;td&gt;$0.0020 / 1K tokens&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;chat completions 接口能做什么 ①&lt;/h2&gt; &#xA;&lt;p&gt;虽然 &lt;code&gt;chat completions&lt;/code&gt; 看起来像是一个聊天接口，但接口设计上并没有为聊天优化，因为这个接口是记不住上下文的。&lt;/p&gt; &#xA;&lt;p&gt;为了让对话具有连续性，我们每次请求需要带上上次的聊天记录。有多种方式解决这个问题，一个是直接在messages参数中加上聊天记录。其中，GPT返回的内容用 &lt;code&gt;assistant&lt;/code&gt; role。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[&#xA;     {&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: &#34;You are a helpful assistant.&#34;},&#xA;     {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Who won the world series in 2020?&#34;},&#xA;     {&#34;role&#34;: &#34;assistant&#34;, &#34;content&#34;: &#34;The Los Angeles Dodgers won the World Series in 2020.&#34;},&#xA;     {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Where was it played?&#34;}&#xA; ]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;另一个方式是使用第三方库，比如&lt;code&gt;chatgpt-api&lt;/code&gt;，它可以自动帮你发送聊天记录（通过指定对话的&lt;code&gt;parentMessageId&lt;/code&gt;实现）：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/transitive-bullshit/chatgpt-api&#34;&gt;https://github.com/transitive-bullshit/chatgpt-api&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/images/20230307150942.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;在加上对话记录后，&lt;code&gt;chat completions&lt;/code&gt; 接口就可以制作一个看起来有智能的聊天应用了。&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;如果你要在国内运营聊天机器人之类的话，请记得将内容通过文本内容审核接口进行审核，否则很可能导致被封。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;chat completions 接口能做什么 ②&lt;/h2&gt; &#xA;&lt;p&gt;其实除了对话，GPT有很强的内容总结归纳能力，另外由于它能理解内容结构，同时本身又是语言模型，因此对结构化翻译很擅长。&lt;/p&gt; &#xA;&lt;p&gt;比如，我经常用它翻译JSON和Markdown，大部分情况下效果很好。在自用体验很好的情况下，我们可以将其制作为应用。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/images/20230307151810.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;应用开发非常简单，我只用一天时间开发了&lt;a href=&#34;https://ai.ftqq.com/&#34;&gt;AiBox&lt;/a&gt;，按基本的web应用开发就可以，重点说几个细节：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;提示词：直接把提示词以 system 的 role 提交就可以。&lt;/li&gt; &#xA; &lt;li&gt;Key问题：开发者的Key肯定是不够用的，因此一般会让使用者填写自己的Key。但是国内用户没有海外手机号，无法申请key;申请下来API直接访问也不通，解决方案有几种，后边专门讲&lt;/li&gt; &#xA; &lt;li&gt;Token计算和限制问题：如果使用者用自己的Key，为了提升体验，我们可以提供一个Token计算，让用户知道自己的会花多少钱。另外如果你没有用第三方那个库来分拆，那么一次请求的内容不要超过 max_tokens 的限制。这个值一般是 4096。&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;如何解决国内用户无法注册OpenAI账号、无法访问OpenAI接口的问题？&lt;/h2&gt; &#xA;&lt;p&gt;两个思路，一个是绕道海外去注册，通过代理使用服务；另一个是直接使用第三方代理API服务。前者可以暂时解决当前的问题；后者更方便省心。&lt;/p&gt; &#xA;&lt;h3&gt;注册OpenAI&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;准备一个海外的网络&lt;/li&gt; &#xA; &lt;li&gt;准备一个海外手机号来接收验证短信，可以用&lt;a href=&#34;https://sms-activate.org/?ref=4207095&#34;&gt;海外虚拟号码&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;注册完成后，进入&lt;a href=&#34;https://openai.com/api/&#34;&gt;API页面&lt;/a&gt; 创建Key，然后就可以使用了。&lt;/p&gt; &#xA;&lt;p&gt;这个方案目前可行，是因为OpenAI给每个新用户提供了18美金的免费额度。但是一旦不再提供，就会面临充值的问题。目前OpenAI不接受中国信用卡，因此还必须准备一个海外信用卡。也就是说，要长久稳定的使用，必须有海外信用卡。&lt;/p&gt; &#xA;&lt;p&gt;以前有财付通的海外虚拟信用卡，后来服务下线了。最近看了下，很多500RMB起，还只支持电商网站，感觉不太靠谱 🤣&lt;/p&gt; &#xA;&lt;h3&gt;访问OpenAI API&lt;/h3&gt; &#xA;&lt;p&gt;3月3日开始，国内大部分网络不再能直接访问 OpenAI 接口。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/images/20230307153602.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;因此你需要架设代理来访问OpenAI 接口。你可以将整个服务器代理到海外网络，或者只是简单的通过 Cloudflare 或者 腾讯云函数来部署API代理。&lt;/p&gt; &#xA;&lt;p&gt;相对来说，我觉得腾讯云香港可能稳定点，&lt;a href=&#34;https://github.com/easychen/openai-api-proxy/raw/master/FUNC.md&#34;&gt;教程可以看这里&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/easychen/openai-gpt-dev-notes-for-cn-developer/master/images/20230307155459.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;需要注意的是，部分API代理不支持SSE，因此不能实时返回内容。当然，有同学说腾讯云的 ApiGateway 直接就能代理，但我测试了下没成功。&lt;/p&gt; &#xA;&lt;h3&gt;通过第三方接口访问&lt;/h3&gt; &#xA;&lt;p&gt;如果你搞不定海外手机号和信用卡，或者自己不想架设代理，那么可以考虑用像&lt;a href=&#34;https://api2d.com&#34;&gt;API2D&lt;/a&gt;这样的第三方代理API。&lt;/p&gt; &#xA;&lt;p&gt;主要的优点：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;基本兼容原有接口，只需要改下 API endpoint 和 Key&lt;/li&gt; &#xA; &lt;li&gt;支持国内卡充值，提供最小0.5美金的测试档位，试用很方便&lt;/li&gt; &#xA; &lt;li&gt;接口国内直接可以访问，无需架设代理&lt;/li&gt; &#xA; &lt;li&gt;推荐可以获得点数，这里是我的&lt;a href=&#34;https://api2d.com/r/186008&#34;&gt;推荐链接&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;缺点：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;不支持 stream 参数，因此只能一次性返回内容&lt;/li&gt; &#xA; &lt;li&gt;不支持微信充值，价格比官方略高，大概1.5倍&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;如何知道 OpenAI 接口状态&lt;/h2&gt; &#xA;&lt;p&gt;OpenAI官方提供了一个&lt;a href=&#34;https://status.openai.com/&#34;&gt;状态页&lt;/a&gt;，虽然小故障不怎么显示，但大面积宕机时能看到公告。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1294760/223604103-4093bdd4-4455-4f55-a294-fb7003325000.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>zinclabs/zincsearch</title>
    <updated>2023-03-10T01:31:10Z</updated>
    <id>tag:github.com,2023-03-10:/zinclabs/zincsearch</id>
    <link href="https://github.com/zinclabs/zincsearch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ZincSearch . A lightweight alternative to elasticsearch that requires minimal resources, written in Go.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://goreportcard.com/report/github.com/zinclabs/zincsearch&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/zinclabs/zincsearch&#34; alt=&#34;Go Report Card&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.zinc.dev/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Docs-Docs-green&#34; alt=&#34;Docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/zinclabs/zincsearch&#34;&gt;&lt;img src=&#34;https://codecov.io/github/zinclabs/zincsearch/branch/main/graph/badge.svg?sanitize=true&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;❗Note: If your use case is of log search (app and security logs) instead of app search (implement search feature in your application or website) then you should check &lt;a href=&#34;https://github.com/zinclabs/zincobserve&#34;&gt;zinclabs/zincobserve&lt;/a&gt; project that is specifically built for observability use case.&lt;/p&gt; &#xA;&lt;h1&gt;ZincSearch&lt;/h1&gt; &#xA;&lt;p&gt;ZincSearch is a search engine that does full text indexing. It is a lightweight alternative to Elasticsearch and runs using a fraction of the resources. It uses &lt;a href=&#34;https://github.com/blugelabs/bluge&#34;&gt;bluge&lt;/a&gt; as the underlying indexing library.&lt;/p&gt; &#xA;&lt;p&gt;It is very simple and easy to operate as opposed to Elasticsearch which requires a couple dozen knobs to understand and tune which you can get up and running in 2 minutes&lt;/p&gt; &#xA;&lt;p&gt;It is a drop-in replacement for Elasticsearch if you are just ingesting data using APIs and searching using kibana (Kibana is not supported with zinc. Zinc provides its own UI).&lt;/p&gt; &#xA;&lt;p&gt;Check the below video for a quick demo of Zinc.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=aZXtuVjt1ow&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zinclabs/zincsearch/main/screenshots/zinc-youtube.jpg&#34; alt=&#34;Zinc Youtube&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Playground Server&lt;/h1&gt; &#xA;&lt;p&gt;You could try ZincSearch without installing using below details:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Server&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://playground.dev.zincsearch.com&#34;&gt;https://playground.dev.zincsearch.com&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;User ID&lt;/td&gt; &#xA;   &lt;td&gt;admin&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Password&lt;/td&gt; &#xA;   &lt;td&gt;Complexpass#123&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Note: Do not store sensitive data on this server as its available to everyone on internet. Data will also be cleaned on this server regularly.&lt;/p&gt; &#xA;&lt;h1&gt;Why ZincSearch&lt;/h1&gt; &#xA;&lt;p&gt;While Elasticsearch is a very good product, it is complex and requires lots of resources and is more than a decade old. I built Zinc so it becomes easier for folks to use full text search indexing without doing a lot of work.&lt;/p&gt; &#xA;&lt;h1&gt;Features:&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Provides full text indexing capability&lt;/li&gt; &#xA; &lt;li&gt;Single binary for installation and running. Binaries available under releases for multiple platforms.&lt;/li&gt; &#xA; &lt;li&gt;Web UI for querying data written in Vue&lt;/li&gt; &#xA; &lt;li&gt;Compatibility with Elasticsearch APIs for ingestion of data (single record and bulk API)&lt;/li&gt; &#xA; &lt;li&gt;Out of the box authentication&lt;/li&gt; &#xA; &lt;li&gt;Schema less - No need to define schema upfront and different documents in the same index can have different fields.&lt;/li&gt; &#xA; &lt;li&gt;Index storage in disk (default), s3 or minio (deprecated)&lt;/li&gt; &#xA; &lt;li&gt;aggregation support&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;How to get support&lt;/h1&gt; &#xA;&lt;p&gt;Easiest way to get support is to join the &lt;a href=&#34;https://join.slack.com/t/zincsearch/shared_invite/zt-11r96hv2b-UwxUILuSJ1duzl_6mhJwVg&#34;&gt;Slack channel&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Roadmap items:&lt;/h1&gt; &#xA;&lt;p&gt;Public roadmap is available at &lt;a href=&#34;https://github.com/orgs/zinclabs/projects/3/views/1&#34;&gt;https://github.com/orgs/zinclabs/projects/3/views/1&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Please create an issue if you would like something to be added to the roadmap.&lt;/p&gt; &#xA;&lt;h1&gt;Screenshots&lt;/h1&gt; &#xA;&lt;h2&gt;Search screen&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zinclabs/zincsearch/main/screenshots/search_screen.jpg&#34; alt=&#34;Search screen&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;User management screen&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zinclabs/zincsearch/main/screenshots/users_screen.jpg&#34; alt=&#34;Users screen&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Getting started&lt;/h1&gt; &#xA;&lt;h2&gt;Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;Check &lt;a href=&#34;https://docs.zinc.dev/quickstart/&#34;&gt;Quickstart&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Releases&lt;/h1&gt; &#xA;&lt;p&gt;ZincSearch currently has most of its API contracts frozen. It&#39;s data format may still experience changes as we improve things. Currently ZincSearch is in beta. Data format should become highly stable when we move to GA (version 1).&lt;/p&gt; &#xA;&lt;h1&gt;Editions&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Feature&lt;/th&gt; &#xA;   &lt;th&gt;Zinc&lt;/th&gt; &#xA;   &lt;th&gt;Zinc Cloud&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ideal use case&lt;/td&gt; &#xA;   &lt;td&gt;App search&lt;/td&gt; &#xA;   &lt;td&gt;Logs and Events (Immutable Data)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Storage&lt;/td&gt; &#xA;   &lt;td&gt;Disk&lt;/td&gt; &#xA;   &lt;td&gt;Object (S3), GCS, Azure blob coming soon&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Preferred Use case&lt;/td&gt; &#xA;   &lt;td&gt;App search&lt;/td&gt; &#xA;   &lt;td&gt;Log / event search&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Max data supported&lt;/td&gt; &#xA;   &lt;td&gt;100s of GBs&lt;/td&gt; &#xA;   &lt;td&gt;Petabyte scale&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;High availability&lt;/td&gt; &#xA;   &lt;td&gt;Will be available soon&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Open source&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Yes, &lt;a href=&#34;https://github.com/zinclabs/zincobserve&#34;&gt;ZincObserve&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ES API compatibility&lt;/td&gt; &#xA;   &lt;td&gt;Search and Ingestion&lt;/td&gt; &#xA;   &lt;td&gt;Ingestion only&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GUI&lt;/td&gt; &#xA;   &lt;td&gt;Basic&lt;/td&gt; &#xA;   &lt;td&gt;Advanced for log search&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Cost&lt;/td&gt; &#xA;   &lt;td&gt;Free (self hosting may cost money based on size)&lt;/td&gt; &#xA;   &lt;td&gt;Generous free tier. 1 TB ingest / month free.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Get started&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://docs.zinc.dev/quickstart/&#34;&gt;Quick start&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://observe.zinc.dev&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zinclabs/zincsearch/main/screenshots/get-started-for-free.png&#34; alt=&#34;Sign up&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Community&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;How to develop and contribute to Zinc&lt;/p&gt; &lt;p&gt;Check the &lt;a href=&#34;https://raw.githubusercontent.com/zinclabs/zincsearch/main/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt; . Also check the &lt;a href=&#34;https://github.com/orgs/zinclabs/projects/3&#34;&gt;roadmap items&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Join our Slack Channel&lt;/p&gt; &lt;p&gt;&lt;a href=&#34;https://join.slack.com/t/zinc-nvh4832/shared_invite/zt-11r96hv2b-UwxUILuSJ1duzl_6mhJwVg&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/zinclabs/zincsearch/main/screenshots/slack.png&#34; alt=&#34;Slack&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Join our weChat Group&lt;/p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/zinclabs/zincsearch/main/screenshots/wechat_qr.jpg&#34; width=&#34;300&#34;&gt; &lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>