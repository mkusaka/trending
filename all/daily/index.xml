<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-02T01:30:21Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>hiyouga/ChatGLM-Efficient-Tuning</title>
    <updated>2023-07-02T01:30:21Z</updated>
    <id>tag:github.com,2023-07-02:/hiyouga/ChatGLM-Efficient-Tuning</id>
    <link href="https://github.com/hiyouga/ChatGLM-Efficient-Tuning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Fine-tuning ChatGLM-6B with PEFT | 基于 PEFT 的高效 ChatGLM 微调&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGLM Efficient Tuning&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/stars/hiyouga/ChatGLM-Efficient-Tuning?style=social&#34; alt=&#34;GitHub Repo stars&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/hiyouga/ChatGLM-Efficient-Tuning&#34; alt=&#34;GitHub Code License&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/last-commit/hiyouga/ChatGLM-Efficient-Tuning&#34; alt=&#34;GitHub last commit&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-blue&#34; alt=&#34;GitHub pull request&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Fine-tuning 🤖&lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34;&gt;ChatGLM-6B&lt;/a&gt; model with 🤗&lt;a href=&#34;https://github.com/huggingface/peft&#34;&gt;PEFT&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;👋 Join our &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/ChatGLM-Efficient-Tuning/main/assets/wechat.jpg&#34;&gt;WeChat&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;[ English | &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/ChatGLM-Efficient-Tuning/main/README_zh.md&#34;&gt;中文&lt;/a&gt; ]&lt;/p&gt; &#xA;&lt;h2&gt;Changelog&lt;/h2&gt; &#xA;&lt;p&gt;[23/06/25] Now we align the &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/ChatGLM-Efficient-Tuning/main/src/api_demo.py&#34;&gt;demo API&lt;/a&gt; with the &lt;a href=&#34;https://platform.openai.com/docs/api-reference/chat&#34;&gt;OpenAI&#39;s&lt;/a&gt; format where you can insert the fine-tuned model in arbitrary ChatGPT-based applications.&lt;/p&gt; &#xA;&lt;p&gt;[23/06/25] Now we support fine-tuning the &lt;a href=&#34;https://github.com/THUDM/ChatGLM2-6B&#34;&gt;ChatGLM2-6B&lt;/a&gt; model with our framework! Try &lt;code&gt;--use_v2&lt;/code&gt; argument to fine-tune that model.&lt;/p&gt; &#xA;&lt;p&gt;[23/06/05] Now we support 4-bit LoRA training (aka &lt;a href=&#34;https://github.com/artidoro/qlora&#34;&gt;QLoRA&lt;/a&gt;). Try &lt;code&gt;--quantization_bit 4&lt;/code&gt; argument to work with 4-bit quantized model. (experimental feature)&lt;/p&gt; &#xA;&lt;p&gt;[23/06/01] We implemented a framework supporting the efficient tuning of LLaMA and BLOOM models. Please follow &lt;a href=&#34;https://github.com/hiyouga/LLaMA-Efficient-Tuning&#34;&gt;LLaMA-Efficient-Tuning&lt;/a&gt; if you are interested.&lt;/p&gt; &#xA;&lt;p&gt;[23/05/19] Now we support using the development set to evaluate the model while training. Try &lt;code&gt;--dev_ratio&lt;/code&gt; argument to specify the size of development set.&lt;/p&gt; &#xA;&lt;p&gt;[23/04/29] Now we support training ChatGLM with &lt;strong&gt;Reinforcement Learning with Human Feedback (RLHF)&lt;/strong&gt; ! We provide several examples to run RLHF training, please refer to the &lt;code&gt;examples&lt;/code&gt; folder for details.&lt;/p&gt; &#xA;&lt;p&gt;[23/04/20] Our repo achieved 100 stars within 12 days! Congratulations!&lt;/p&gt; &#xA;&lt;p&gt;[23/04/19] Now we support &lt;strong&gt;merging the weights&lt;/strong&gt; of fine-tuned models trained by LoRA! Try &lt;code&gt;--checkpoint_dir checkpoint1,checkpoint2&lt;/code&gt; argument for continually fine-tuning the models.&lt;/p&gt; &#xA;&lt;p&gt;[23/04/18] Now we support training the &lt;strong&gt;quantized models&lt;/strong&gt; using three fine-tuning methods! Try &lt;code&gt;quantization_bit&lt;/code&gt; argument for training the model in 4/8 bits.&lt;/p&gt; &#xA;&lt;p&gt;[23/04/12] Now we support &lt;strong&gt;training from checkpoints&lt;/strong&gt;! Use &lt;code&gt;--checkpoint_dir&lt;/code&gt; argument to specify the checkpoint model to fine-tune from.&lt;/p&gt; &#xA;&lt;p&gt;[23/04/11] Now we support training with &lt;strong&gt;combined datasets&lt;/strong&gt;! Try &lt;code&gt;--dataset dataset1,dataset2&lt;/code&gt; argument for training with multiple datasets.&lt;/p&gt; &#xA;&lt;h2&gt;Datasets&lt;/h2&gt; &#xA;&lt;p&gt;Our script now supports the following datasets:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca&#34;&gt;Stanford Alpaca (Chinese)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM&#34;&gt;GPT-4 Generated Data&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/train_2M_CN&#34;&gt;BELLE 2M&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/train_1M_CN&#34;&gt;BELLE 1M&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/train_0.5M_CN&#34;&gt;BELLE 0.5M&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M&#34;&gt;BELLE Dialogue 0.4M&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/school_math_0.25M&#34;&gt;BELLE School Math 0.25M&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M&#34;&gt;BELLE Multiturn Chat 0.8M&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/JosephusCheung/GuanacoDataset&#34;&gt;Guanaco Dataset&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M&#34;&gt;Firefly 1.1M&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k&#34;&gt;CodeAlpaca 20k&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/QingyiSi/Alpaca-CoT&#34;&gt;Alpaca CoT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/suolyer/webqa&#34;&gt;Web QA (Chinese)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/thunlp/UltraChat&#34;&gt;UltraChat&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/ChatGLM-Efficient-Tuning/main/data/README.md&#34;&gt;data/README.md&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;p&gt;Some datasets require confirmation before using them, so we recommend logging in with your HuggingFace account using these commands.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install --upgrade huggingface_hub&#xA;huggingface-cli login&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Fine-Tuning Methods&lt;/h2&gt; &#xA;&lt;p&gt;Our script now supports the following fine-tuning methods:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;LoRA&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fine-tuning the low-rank adapters of the model.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/THUDM/P-tuning-v2&#34;&gt;P-Tuning V2&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fine-tuning the prefix encoder of the model.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2012.14913&#34;&gt;Freeze&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fine-tuning the MLPs in the last n blocks of the model.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Full Tuning &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Fine-tuning all the parameters of the model.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Requirement&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.8+ and PyTorch 1.13.1&lt;/li&gt; &#xA; &lt;li&gt;🤗Transformers, Datasets, Accelerate, PEFT and TRL&lt;/li&gt; &#xA; &lt;li&gt;protobuf, cpm_kernels and sentencepiece&lt;/li&gt; &#xA; &lt;li&gt;jieba, rouge_chinese and nltk (used at evaluation)&lt;/li&gt; &#xA; &lt;li&gt;gradio and mdtex2html (used in web_demo.py)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;And &lt;strong&gt;powerful GPUs&lt;/strong&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Data Preparation (optional)&lt;/h3&gt; &#xA;&lt;p&gt;Please refer to &lt;code&gt;data/example_dataset&lt;/code&gt; for checking the details about the format of dataset files. You can either use a single &lt;code&gt;.json&lt;/code&gt; file or a &lt;a href=&#34;https://huggingface.co/docs/datasets/dataset_script&#34;&gt;dataset loading script&lt;/a&gt; with multiple files to create a custom dataset.&lt;/p&gt; &#xA;&lt;p&gt;Note: please update &lt;code&gt;data/dataset_info.json&lt;/code&gt; to use your custom dataset. About the format of this file, please refer to &lt;code&gt;data/README.md&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Dependence Installation (optional)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/hiyouga/ChatGLM-Efficient-Tuning.git&#xA;conda create -n chatglm_etuning python=3.10&#xA;conda activate chatglm_etuning&#xA;cd ChatGLM-Efficient-Tuning&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to enable LoRA or Freeze quantization on Windows, you will be required to install a pre-built version of &lt;code&gt;bitsandbytes&lt;/code&gt; library, which supports CUDA 11.6 or 11.7.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install https://github.com/acpopescu/bitsandbytes/releases/download/v0.37.2-win.1/bitsandbytes-0.37.2-py3-none-any.whl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Fine-tuning with a Single GPU&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_sft.py \&#xA;    --do_train \&#xA;    --dataset alpaca_gpt4_en \&#xA;    --finetuning_type lora \&#xA;    --output_dir path_to_sft_checkpoint \&#xA;    --per_device_train_batch_size 4 \&#xA;    --gradient_accumulation_steps 4 \&#xA;    --lr_scheduler_type cosine \&#xA;    --logging_steps 10 \&#xA;    --save_steps 1000 \&#xA;    --learning_rate 5e-5 \&#xA;    --num_train_epochs 3.0 \&#xA;    --fp16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please refer to our &lt;a href=&#34;https://github.com/hiyouga/ChatGLM-Efficient-Tuning/wiki&#34;&gt;Wiki&lt;/a&gt; about the details of the arguments.&lt;/p&gt; &#xA;&lt;h3&gt;Distributed Fine-tuning with Multiple GPUs&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;accelerate config # configure the environment&#xA;accelerate launch src/train_sft.py # arguments (same as above)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: if you are using LoRA method at fine-tuning, please provide &lt;code&gt;--ddp_find_unused_parameters False&lt;/code&gt; argument to avoid the runtime error.&lt;/p&gt; &#xA;&lt;h3&gt;Training Reward Model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_rm.py \&#xA;    --do_train \&#xA;    --dataset comparison_gpt4_en \&#xA;    --finetuning_type lora \&#xA;    --output_dir path_to_rm_checkpoint \&#xA;    --per_device_train_batch_size 4 \&#xA;    --gradient_accumulation_steps 4 \&#xA;    --lr_scheduler_type cosine \&#xA;    --logging_steps 10 \&#xA;    --save_steps 1000 \&#xA;    --learning_rate 1e-5 \&#xA;    --num_train_epochs 1.0 \&#xA;    --fp16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Training with RLHF&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_ppo.py \&#xA;    --do_train \&#xA;    --dataset alpaca_gpt4_en \&#xA;    --finetuning_type lora \&#xA;    --checkpoint_dir path_to_sft_checkpoint \&#xA;    --reward_model path_to_rm_checkpoint \&#xA;    --output_dir path_to_ppo_checkpoint \&#xA;    --per_device_train_batch_size 2 \&#xA;    --gradient_accumulation_steps 4 \&#xA;    --lr_scheduler_type cosine \&#xA;    --logging_steps 10 \&#xA;    --save_steps 1000 \&#xA;    --learning_rate 1e-5 \&#xA;    --num_train_epochs 1.0 \&#xA;    --fp16&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Evaluation (BLEU and ROUGE_CHINESE)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_sft.py \&#xA;    --do_eval \&#xA;    --dataset alpaca_gpt4_en \&#xA;    --checkpoint_dir path_to_checkpoint \&#xA;    --output_dir path_to_eval_result \&#xA;    --per_device_eval_batch_size 8 \&#xA;    --max_samples 50 \&#xA;    --predict_with_generate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Predict&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDA_VISIBLE_DEVICES=0 python src/train_sft.py \&#xA;    --do_predict \&#xA;    --dataset alpaca_gpt4_en \&#xA;    --checkpoint_dir path_to_checkpoint \&#xA;    --output_dir path_to_predict_result \&#xA;    --per_device_eval_batch_size 8 \&#xA;    --max_samples 50 \&#xA;    --predict_with_generate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;CLI Demo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python src/cli_demo.py \&#xA;    --checkpoint_dir path_to_checkpoint&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Web Demo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python src/web_demo.py \&#xA;    --checkpoint_dir path_to_checkpoint&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Export model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python src/export_model.py \&#xA;    --checkpoint_dir path_to_checkpoint \&#xA;    --output_dir path_to_export&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Hardware Requirements&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Fine-tune method&lt;/th&gt; &#xA;   &lt;th&gt;Batch size&lt;/th&gt; &#xA;   &lt;th&gt;Mode&lt;/th&gt; &#xA;   &lt;th&gt;GRAM&lt;/th&gt; &#xA;   &lt;th&gt;Speed&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRA (r=8)&lt;/td&gt; &#xA;   &lt;td&gt;16&lt;/td&gt; &#xA;   &lt;td&gt;FP16&lt;/td&gt; &#xA;   &lt;td&gt;28GB&lt;/td&gt; &#xA;   &lt;td&gt;8ex/s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRA (r=8)&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;FP16&lt;/td&gt; &#xA;   &lt;td&gt;24GB&lt;/td&gt; &#xA;   &lt;td&gt;8ex/s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRA (r=8)&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;FP16&lt;/td&gt; &#xA;   &lt;td&gt;20GB&lt;/td&gt; &#xA;   &lt;td&gt;8ex/s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRA (r=8)&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;INT8&lt;/td&gt; &#xA;   &lt;td&gt;10GB&lt;/td&gt; &#xA;   &lt;td&gt;8ex/s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRA (r=8)&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;INT4&lt;/td&gt; &#xA;   &lt;td&gt;8GB&lt;/td&gt; &#xA;   &lt;td&gt;8ex/s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;P-Tuning (p=16)&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;FP16&lt;/td&gt; &#xA;   &lt;td&gt;20GB&lt;/td&gt; &#xA;   &lt;td&gt;8ex/s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;P-Tuning (p=16)&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;INT8&lt;/td&gt; &#xA;   &lt;td&gt;16GB&lt;/td&gt; &#xA;   &lt;td&gt;8ex/s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;P-Tuning (p=16)&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;INT4&lt;/td&gt; &#xA;   &lt;td&gt;12GB&lt;/td&gt; &#xA;   &lt;td&gt;8ex/s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Freeze (l=3)&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;FP16&lt;/td&gt; &#xA;   &lt;td&gt;24GB&lt;/td&gt; &#xA;   &lt;td&gt;8ex/s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Freeze (l=3)&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;INT8&lt;/td&gt; &#xA;   &lt;td&gt;12GB&lt;/td&gt; &#xA;   &lt;td&gt;8ex/s&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;RM method&lt;/th&gt; &#xA;   &lt;th&gt;Batch size&lt;/th&gt; &#xA;   &lt;th&gt;Mode&lt;/th&gt; &#xA;   &lt;th&gt;GRAM&lt;/th&gt; &#xA;   &lt;th&gt;Speed&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRA (r=8) + rm&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;FP16&lt;/td&gt; &#xA;   &lt;td&gt;22GB&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRA (r=8) + rm&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;INT8&lt;/td&gt; &#xA;   &lt;td&gt;11GB&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;RLHF method&lt;/th&gt; &#xA;   &lt;th&gt;Batch size&lt;/th&gt; &#xA;   &lt;th&gt;Mode&lt;/th&gt; &#xA;   &lt;th&gt;GRAM&lt;/th&gt; &#xA;   &lt;th&gt;Speed&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRA (r=8) + ppo&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;FP16&lt;/td&gt; &#xA;   &lt;td&gt;23GB&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LoRA (r=8) + ppo&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;INT8&lt;/td&gt; &#xA;   &lt;td&gt;12GB&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: &lt;code&gt;r&lt;/code&gt; is the lora rank, &lt;code&gt;p&lt;/code&gt; is the number of prefix tokens, &lt;code&gt;l&lt;/code&gt; is the number of trainable layers, &lt;code&gt;ex/s&lt;/code&gt; is the examples per second at training. The &lt;code&gt;gradient_accumulation_steps&lt;/code&gt; is set to &lt;code&gt;1&lt;/code&gt;. All are evaluated on a single Tesla V100 (32G) GPU, they are approximated values and may vary in different GPUs.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Fine-tuning ChatGLM: A Case&lt;/h2&gt; &#xA;&lt;h3&gt;Training Results&lt;/h3&gt; &#xA;&lt;p&gt;We use the whole &lt;code&gt;alpaca_gpt4_zh&lt;/code&gt; dataset to fine-tune the ChatGLM model with LoRA (r=8) for one epoch, using the default hyper-parameters. The loss curve during training is presented below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hiyouga/ChatGLM-Efficient-Tuning/main/assets/trainer_state.jpg&#34; alt=&#34;training loss&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Evaluation Results&lt;/h3&gt; &#xA;&lt;p&gt;We select 100 instances in the &lt;code&gt;alpaca_gpt4_zh&lt;/code&gt; dataset to evaluate the fine-tuned ChatGLM model and compute the BLEU and ROUGE scores. The results are presented below.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Score&lt;/th&gt; &#xA;   &lt;th&gt;Original&lt;/th&gt; &#xA;   &lt;th&gt;FZ (l=2)&lt;/th&gt; &#xA;   &lt;th&gt;PT (p=16)&lt;/th&gt; &#xA;   &lt;th&gt;LoRA (r=8)&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BLEU-4&lt;/td&gt; &#xA;   &lt;td&gt;15.75&lt;/td&gt; &#xA;   &lt;td&gt;16.85&lt;/td&gt; &#xA;   &lt;td&gt;16.06&lt;/td&gt; &#xA;   &lt;td&gt;17.01 (&lt;strong&gt;+1.26&lt;/strong&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Rouge-1&lt;/td&gt; &#xA;   &lt;td&gt;34.51&lt;/td&gt; &#xA;   &lt;td&gt;36.62&lt;/td&gt; &#xA;   &lt;td&gt;34.80&lt;/td&gt; &#xA;   &lt;td&gt;36.77 (&lt;strong&gt;+2.26&lt;/strong&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Rouge-2&lt;/td&gt; &#xA;   &lt;td&gt;15.11&lt;/td&gt; &#xA;   &lt;td&gt;17.04&lt;/td&gt; &#xA;   &lt;td&gt;15.32&lt;/td&gt; &#xA;   &lt;td&gt;16.83 (&lt;strong&gt;+1.72&lt;/strong&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Rouge-l&lt;/td&gt; &#xA;   &lt;td&gt;26.18&lt;/td&gt; &#xA;   &lt;td&gt;28.17&lt;/td&gt; &#xA;   &lt;td&gt;26.35&lt;/td&gt; &#xA;   &lt;td&gt;28.86 (&lt;strong&gt;+2.68&lt;/strong&gt;)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Params (%)&lt;/td&gt; &#xA;   &lt;td&gt;/&lt;/td&gt; &#xA;   &lt;td&gt;4.35%&lt;/td&gt; &#xA;   &lt;td&gt;0.06%&lt;/td&gt; &#xA;   &lt;td&gt;0.06%&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;FZ: freeze tuning, PT: P-Tuning V2 (we use &lt;code&gt;pre_seq_len=16&lt;/code&gt; for fair comparison with LoRA), Params: the percentange of trainable parameters.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Compared with Existing Implementations&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B/tree/main/ptuning&#34;&gt;THUDM/ChatGLM-6B&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Official implementation of fine-tuning ChatGLM with &lt;a href=&#34;https://github.com/THUDM/P-tuning-v2&#34;&gt;P-Tuning v2&lt;/a&gt; on the &lt;a href=&#34;https://aclanthology.org/D19-1321.pdf&#34;&gt;ADGEN&lt;/a&gt; dataset.&lt;/li&gt; &#xA;   &lt;li&gt;Our fine-tuning script is largely depend on it. We further implement the &lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;LoRA&lt;/a&gt; tuning method. Additionally, we &lt;strong&gt;dynamically&lt;/strong&gt; pad the inputs to the longest sequence in the batch instead of the maximum length, to accelerate the fine-tuning.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mymusise/ChatGLM-Tuning&#34;&gt;mymusise/ChatGLM-Tuning&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;An unoffical implementation of fine-tuning ChatGLM with &lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;LoRA&lt;/a&gt; on the &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt; dataset.&lt;/li&gt; &#xA;   &lt;li&gt;We borrowed some ideas from it. Our fine-tuning script &lt;strong&gt;integrates&lt;/strong&gt; the data pre-processing part into the training procedure, so we need not generate a pre-processed dataset before training.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ssbuild/chatglm_finetuning&#34;&gt;ssbuild/chatglm_finetuning&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;An unofficial implementation of fine-tuning ChatGLM with several PEFT methods on the &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt; dataset.&lt;/li&gt; &#xA;   &lt;li&gt;Our fine-tuning script is implemented &lt;strong&gt;purely&lt;/strong&gt; with &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;Huggingface transformers&lt;/a&gt; and is independent of the &lt;a href=&#34;https://github.com/ssbuild/deep_training&#34;&gt;deep_training&lt;/a&gt; framework.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lich99/ChatGLM-finetune-LoRA&#34;&gt;lich99/ChatGLM-finetune-LoRA&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;An unofficial implementation of fine-tuning ChatGLM with &lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;LoRA&lt;/a&gt; on the &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt; dataset.&lt;/li&gt; &#xA;   &lt;li&gt;We use the &lt;a href=&#34;https://github.com/huggingface/peft&#34;&gt;Huggingface PEFT&lt;/a&gt; to provide the state-of-the-art PEFT methods.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/liucongg/ChatGLM-Finetuning&#34;&gt;liucongg/ChatGLM-Finetuning&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;An unofficial implementation of fine-tuning ChatGLM with several methods including Freeze, LoRA and P-Tuning on the industrial dataset.&lt;/li&gt; &#xA;   &lt;li&gt;We are aim to incorporate more instruction-following datasets for fine-tuning the ChatGLM model.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yanqiangmiffy/InstructGLM&#34;&gt;yanqiangmiffy/InstructGLM&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;An unofficial implementation of fine-tuning ChatGLM that explores the ChatGLM&#39;s ability on the instruction-following datasets.&lt;/li&gt; &#xA;   &lt;li&gt;Our fine-tuning script integrates the data pre-processing part in to the training procedure.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;TODO&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Employing &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt; to easily build applications that are capable of leveraging external knowledge upon fine-tuned ChatGLM models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Implementing the alignment algorithms to align human preferrences. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-chat&#34;&gt;RLHF&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/GanjinZero/RRHF&#34;&gt;RRHF&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/OptimalScale/LMFlow&#34;&gt;RAFT&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Incorporating &lt;a href=&#34;https://github.com/brightmart/nlp_chinese_corpus&#34;&gt;Chinese datasets&lt;/a&gt; into the training sets. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://github.com/LianjiaTech/BELLE&#34;&gt;BELLE&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/CLUEbenchmark/pCLUE&#34;&gt;pCLUE&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/CLUEbenchmark/CLUECorpus2020&#34;&gt;CLUECorpus&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/datasets/JosephusCheung/GuanacoDataset&#34;&gt;GuanacoDataset&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M&#34;&gt;FireflyDataset&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Incorporating &lt;a href=&#34;https://openai.com/blog/chatgpt&#34;&gt;ChatGPT&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://openai.com/research/gpt-4&#34;&gt;GPT-4&lt;/a&gt; self-chat data into the training sets. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;a href=&#34;https://github.com/project-baize/baize-chatbot&#34;&gt;Baize&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM&#34;&gt;GPT-4-LLM&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Implementing the Freeze-Tuning and P-Tuning method.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Supporting Multi-GPUs fine-tuning.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Adding script for evaluation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Loading from checkpoint.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Fine-tuning the quantized model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Writing a guidebook about how to fine-tune ChatGLM with this framework.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Combining with state-of-the-art model editing algorithms. (&lt;em&gt;e.g. &lt;a href=&#34;https://arxiv.org/abs/2110.11309&#34;&gt;MEND&lt;/a&gt;&lt;/em&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Incorporating the &lt;a href=&#34;https://huggingface.co/datasets/OpenAssistant/oasst1&#34;&gt;OpenAssistant Conversations Dataset&lt;/a&gt; for SFT and alignment.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Incorporating the high quality Chinese instruction dataset &lt;a href=&#34;https://huggingface.co/datasets/BAAI/COIG&#34;&gt;COIG&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This repository is licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/hiyouga/ChatGLM-Efficient-Tuning/main/LICENSE&#34;&gt;Apache-2.0 License&lt;/a&gt;. Please follow the &lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B/raw/main/MODEL_LICENSE&#34;&gt;Model License&lt;/a&gt; to use ChatGLM-6B model.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If this work is helpful, please cite as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@Misc{chatglm-efficient-tuning,&#xA;  title = {ChatGLM Efficient Tuning},&#xA;  author = {hiyouga},&#xA;  howpublished = {\url{https://github.com/hiyouga/ChatGLM-Efficient-Tuning}},&#xA;  year = {2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;This repo benefits from &lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34;&gt;ChatGLM-6B&lt;/a&gt;, &lt;a href=&#34;https://github.com/mymusise/ChatGLM-Tuning&#34;&gt;ChatGLM-Tuning&lt;/a&gt; and &lt;a href=&#34;https://github.com/yuanzhoulvpi2017/zero_nlp&#34;&gt;yuanzhoulvpi2017/zero_nlp&lt;/a&gt;. Thanks for their wonderful works.&lt;/p&gt; &#xA;&lt;h2&gt;Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=hiyouga/ChatGLM-Efficient-Tuning&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>toeverything/AFFiNE</title>
    <updated>2023-07-02T01:30:21Z</updated>
    <id>tag:github.com,2023-07-02:/toeverything/AFFiNE</id>
    <link href="https://github.com/toeverything/AFFiNE" rel="alternate"></link>
    <summary type="html">&lt;p&gt;There can be more than Notion and Miro. AFFiNE is a next-gen knowledge base that brings planning, sorting and creating all together. Privacy first, open-source, customizable and ready to use.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1 style=&#34;border-bottom: none&#34;&gt; &lt;b&gt;&lt;a href=&#34;https://affine.pro&#34;&gt;AFFiNE.PRO&lt;/a&gt;&lt;/b&gt;&lt;br&gt; The Next-Gen Collaborative Knowledge Base &lt;br&gt; &lt;/h1&gt; &#xA; &lt;p&gt; AFFiNE is a next-gen knowledge base that brings planning, sorting and creating all together.&lt;br&gt; Privacy first, open-source, customizable and ready to use - a free replacement for Notion &amp;amp; Miro. &lt;br&gt; &lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;!--&#xA;Make New Badge Pattern badges inline&#xA;See https://github.com/all-?/all-contributors/issues/361#issuecomment-637166066&#xA;--&gt; &#xA; &lt;!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section --&gt; &#xA; &lt;!-- ALL-CONTRIBUTORS-BADGE:END --&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://app.affine.pro&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Try%20It%20Online%20%E2%86%92-rgb(84,56,255)?style=flat-square&amp;amp;logoColor=white&amp;amp;logo=affine&#34; alt=&#34;AFFiNE Web&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://affine.pro/download&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-macOS_M_Chip%20%E2%86%92-black?style=flat-square&amp;amp;logo=apple&amp;amp;logoColor=white&#34; alt=&#34;AFFiNE macOS M1/M2 Chip&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://affine.pro/download&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-macOS_x86%20%E2%86%92-black?style=flat-square&amp;amp;logo=apple&amp;amp;logoColor=white&#34; alt=&#34;AFFiNE macOS x64&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://affine.pro/download&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Windows%20%E2%86%92-blue?style=flat-square&amp;amp;logo=windows&amp;amp;logoColor=white&#34; alt=&#34;AFFiNE Window x64&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://affine.pro/download&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Linux%20%E2%86%92-yellow?style=flat-square&amp;amp;logo=linux&amp;amp;logoColor=white&#34; alt=&#34;AFFiNE Linux&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/toeverything/AFFiNE/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/downloads/toeverything/AFFiNE/total&#34; alt=&#34;Releases&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/toeverything/AFFiNE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/toeverything/AFFiNE.svg?style=flat&amp;amp;logo=github&amp;amp;colorB=red&amp;amp;label=stars&#34; alt=&#34;stars-icon&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/toeverything/AFFiNE/master/#contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/all_contributors-66-orange.svg?style=flat-square&#34; alt=&#34;All Contributors&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/toeverything/AFFiNE&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/toeverything/affine/branch/master/graphs/badge.svg?branch=master&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://nodejs.org/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/node-%3E=18.16.1-success&#34; alt=&#34;Node-version-icon&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.typescriptlang.org/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/package-json/dependency-version/toeverything/affine/dev/typescript&#34; alt=&#34;TypeScript-version-icon&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://reactjs.org/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/package-json/dependency-version/toeverything/AFFiNE/react?filename=apps%2Fweb%2Fpackage.json&amp;amp;color=rgb(97%2C228%2C251)&#34; alt=&#34;React-version-icon&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/toeverything/blocksuite&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/package-json/dependency-version/toeverything/AFFiNE/@blocksuite/store?color=6880ff&amp;amp;filename=apps%2Fweb%2Fpackage.json&amp;amp;label=blocksuite&#34; alt=&#34;blocksuite-icon&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.rust-lang.org/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Rust-1.70.0-dea584&#34; alt=&#34;Rust-version-icon&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;a href=&#34;http://affine.pro&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-AFFiNE-06449d?style=social&amp;amp;logo=affine&#34; height=&#34;25&#34;&gt;&lt;/a&gt; &amp;nbsp; &#xA; &lt;a href=&#34;https://community.affine.pro&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Community-424549?style=social&amp;amp;logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAXNJREFUWEftlitLRUEURtdVEVExWUx2qxgNVouoXYtNDP4Tw20WtftAsItZrHaTYBJREZ98MAc248wcZxi4CGfSeezHmm/23kyPAa/egPPTAXQK/FsFBP7ldVDRZoqcgO9I+2bHy3ZIJBfTCPCZM1tqAxwBmzUBrNQNbEx+5b0B5oEN4NCBrAMnMaiUAuPAs3HU82TLEZwBqwGbaJ4UgKQ8CFR6SoEl4LIWwCJwZQCegKkWBWLHVKSActvdzgG3DqitDf3/VQBskBDALrDnAKXUo3ueAF5KinAf2DKOmnzD7l214bdbA6hC1XHZNQa8hSBC0hwDa57xDHDvvvWB7ciOZoE79+8CWPbsBGc769eFxJdWIKcuyIdRoG3W7AAC1dJkHDIOo8B78+4rEBo8r4AkLFk6Jk3HaeDBBTgHVmIAfpJUz+cAFXVBreQCvQYW/lqEjV1NAMUMqpAaxQMHyDnjYtuS+0BxstwaqJooFqxToFPgB5FuPCEB6XK2AAAAAElFTkSuQmCC&#34; height=&#34;25&#34;&gt;&lt;/a&gt; &amp;nbsp; &#xA; &lt;a href=&#34;https://discord.com/invite/yz6tGVsf5p&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Discord-424549?style=social&amp;amp;logo=discord&#34; height=&#34;25&#34;&gt;&lt;/a&gt; &amp;nbsp; &#xA; &lt;a href=&#34;https://t.me/affineworkos&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Telegram-red?style=social&amp;amp;logo=telegram&#34; height=&#34;25&#34;&gt;&lt;/a&gt; &amp;nbsp; &#xA; &lt;a href=&#34;https://twitter.com/AffineOfficial&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Twitter-red?style=social&amp;amp;logo=twitter&#34; height=&#34;25&#34;&gt;&lt;/a&gt; &amp;nbsp; &#xA; &lt;a href=&#34;https://medium.com/@affineworkos&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Medium-red?style=social&amp;amp;logo=medium&#34; height=&#34;25&#34;&gt;&lt;/a&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;em&gt;See docs, canvas and tables are hyper merged with AFFiNE - just like the word affine (əˈfʌɪn | a-fine).&lt;/em&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/79301703/230892907-5fd5c0c5-1665-4d75-8a35-744e0afc36a5.gif&#34; alt=&#34;img_v2_37a7cc04-ab3f-4405-ae9a-f84ceb4c948g&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Join our community&lt;/h2&gt; &#xA;&lt;p&gt;Before we tell you how to get started with AFFiNE, we&#39;d like to shamelessly plug our awesome user and developer communities across &lt;a href=&#34;https://community.affine.pro/c/start-here/&#34;&gt;official social platforms&lt;/a&gt;! Once you’re familiar with using the software, maybe you will share your wisdom with others and even consider joining the &lt;a href=&#34;https://community.affine.pro/c/start-here/affine-ambassador&#34;&gt;AFFiNE Ambassador program&lt;/a&gt; to help spread AFFiNE to the world.&lt;/p&gt; &#xA;&lt;h2&gt;Getting started &amp;amp; staying tuned with us.&lt;/h2&gt; &#xA;&lt;p&gt;⚠️ Please note that AFFiNE is still under active development and is not yet ready for production use. ⚠️&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://app.affine.pro&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?label=Try%20it%20Online&amp;amp;logo=affine&amp;amp;message=%E2%86%92&amp;amp;style=for-the-badge&#34; alt=&#34;affine.pro&#34;&gt;&lt;/a&gt; No installation or registration required! Head over to our website and try it out now.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://community.affine.pro&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?label=Join%20the%20community&amp;amp;message=%E2%86%92&amp;amp;style=for-the-badge&#34; alt=&#34;community.affine.pro&#34;&gt;&lt;/a&gt; Our wonderful community, where you can meet and engage with the team, developers and other like-minded enthusiastic user of AFFiNE.&lt;/p&gt; &#xA;&lt;p&gt;Star us, and you will receive all releases notifications from GitHub without any delay! &lt;img src=&#34;https://user-images.githubusercontent.com/79301703/230891830-0110681e-8c7e-483b-b6d9-9e42b291b9ef.gif&#34; alt=&#34;rbU3YmmsQT&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Hyper merged&lt;/strong&gt; — Write, draw and plan all at once. Assemble any blocks you love on any canvas you like to enjoy seamless transitions between workflows with AFFiNE.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Privacy focussed&lt;/strong&gt; — AFFiNE is built with your privacy in mind and is one of our key concerns. We want you to keep control of your data, allowing you to store it as you like, where you like while still being able to freely edit and view your data on-demand.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Offline-first&lt;/strong&gt; - With your privacy in mind we also decided to go offline-first. This means that AFFiNE can be used offline, whether you want to view or edit, with support for conflict-free merging when you are back online.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Clean, intuitive design&lt;/strong&gt; — With AFFiNE you can concentrate on editing with a clean and modern interface. Which is responsive, so it looks great on tablets too, and mobile support is coming in the future.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Modern Block Editor with Markdown support&lt;/strong&gt; — A modern block editor can help you not only for docs, but slides and tables as well. When you write in AFFiNE you can use Markdown syntax which helps create an easier editing experience, that can be experienced with just a keyboard. And this allows you to export your data cleanly into Markdown.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Collaboration&lt;/strong&gt; — Whether you want to collaborate with yourself across multiple devices, or work together with others, support for collaboration and multiplayer is out-of-the-box, which makes it easy for teams to get started with AFFiNE.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Choice of multiple languages&lt;/strong&gt; — Thanks to community contributions AFFiNE offers support for multiple languages. If you don&#39;t find your language or would like to suggest some changes we welcome your contributions.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/79301703/230893796-dc707955-e4e5-4a42-a3c9-18d1ea754f6f.gif&#34; alt=&#34;img_v2_3a4ee0da-6dd7-48cb-8f19-5411f86768ag&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Bug Reports&lt;/th&gt; &#xA;   &lt;th&gt;Feature Requests&lt;/th&gt; &#xA;   &lt;th&gt;Questions/Discussions&lt;/th&gt; &#xA;   &lt;th&gt;AFFiNE Community&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/toeverything/AFFiNE/issues/new?assignees=&amp;amp;labels=bug%2Cproduct-review&amp;amp;template=BUG-REPORT.yml&amp;amp;title=TITLE&#34;&gt;Create a bug report&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/toeverything/AFFiNE/issues/new?assignees=&amp;amp;labels=feat%2Cproduct-review&amp;amp;template=FEATURE-REQUEST.yml&amp;amp;title=TITLE&#34;&gt;Submit a feature request&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/toeverything/AFFiNE/discussions&#34;&gt;Check GitHub Discussion&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://community.affine.pro&#34;&gt;Vist the AFFiNE Community&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Something isn&#39;t working as expected&lt;/td&gt; &#xA;   &lt;td&gt;An idea for a new feature, or improvements&lt;/td&gt; &#xA;   &lt;td&gt;Discuss and ask questions&lt;/td&gt; &#xA;   &lt;td&gt;A place to ask, learn and engage with others&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Calling all developers, testers, tech writers and more! Contributions of all types are more than welcome, you can read more in &lt;a href=&#34;https://raw.githubusercontent.com/toeverything/AFFiNE/master/docs/types-of-contributions.md&#34;&gt;docs/types-of-contributions.md&lt;/a&gt;. If you are interested in contributing code, read our &lt;a href=&#34;https://raw.githubusercontent.com/toeverything/AFFiNE/master/docs/CONTRIBUTING.md&#34;&gt;docs/CONTRIBUTING.md&lt;/a&gt; and feel free to check out our GitHub issues to get stuck in to show us what you’re made of.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Before you start contributing, please make sure you have read and accepted our &lt;a href=&#34;https://github.com/toeverything/affine/edit/master/.github/CLA.md&#34;&gt;Contributor License Agreement&lt;/a&gt;. To indicate your agreement, simply edit this file and submit a pull request.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;For &lt;strong&gt;bug reports&lt;/strong&gt;, &lt;strong&gt;feature requests&lt;/strong&gt; and other &lt;strong&gt;suggestions&lt;/strong&gt; you can also &lt;a href=&#34;https://github.com/toeverything/AFFiNE/issues/new/choose&#34;&gt;create a new issue&lt;/a&gt; and choose the most appropriate template for your feedback.&lt;/p&gt; &#xA;&lt;p&gt;For &lt;strong&gt;translation&lt;/strong&gt; and &lt;strong&gt;language support&lt;/strong&gt; you can visit our &lt;a href=&#34;https://community.affine.pro/c/i18n-general&#34;&gt;i18n General Space&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Looking for &lt;strong&gt;others ways to contribute&lt;/strong&gt; and wondering where to start? Check out the &lt;a href=&#34;https://community.affine.pro/c/start-here/affine-ambassador&#34;&gt;AFFiNE Ambassador program&lt;/a&gt;, we work closely with passionate community members and provide them with a wide-range of support and resources.&lt;/p&gt; &#xA;&lt;p&gt;If you have questions, you are welcome to contact us. One of the best places to get more info and learn more is in the &lt;a href=&#34;https://community.affine.pro&#34;&gt;AFFiNE Community&lt;/a&gt; where you can engage with other like-minded individuals.&lt;/p&gt; &#xA;&lt;h2&gt;Ecosystem&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://affine-storybook.vercel.app/&#34;&gt;@affine/component&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;AFFiNE Component Resources&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://affine-storybook.vercel.app/&#34;&gt;&lt;img src=&#34;https://img.shields.io/codecov/c/github/toeverything/affine?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/toeverything/AFFiNE/master/packages/y-indexeddb&#34;&gt;@toeverything/y-indexeddb&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;IndexedDB database adapter for Yjs&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.npmjs.com/package/@toeverything/y-indexeddb&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/dm/@toeverything/y-indexeddb?style=flat-square&amp;amp;color=eee&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/toeverything/AFFiNE/master/packages/theme&#34;&gt;@toeverything/theme&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;AFFiNE theme&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.npmjs.com/package/@toeverything/theme&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/dm/@toeverything/theme?style=flat-square&amp;amp;color=eee&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Plugins&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Plugins are a way to extend the functionality of AFFiNE.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/toeverything/AFFiNE/master/plugins/bookmark-block&#34;&gt;@affine/bookmark-block&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A block for bookmarking a website&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/toeverything/AFFiNE/master/plugins/copilot&#34;&gt;@affine/copilot&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;AI Copilot that help you document writing&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Thanks&lt;/h2&gt; &#xA;&lt;p&gt;We would also like to give thanks to open-source projects that make AFFiNE possible:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/toeverything/BlockSuite&#34;&gt;BlockSuite&lt;/a&gt; - 💠 BlockSuite is the open-source collaborative editor project behind AFFiNE.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/toeverything/OctoBase&#34;&gt;OctoBase&lt;/a&gt; - 🐙 OctoBase is the open-source database behind AFFiNE, local-first, yet collaborative. A light-weight, scalable, data engine written in Rust.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yjs/yjs&#34;&gt;Yjs&lt;/a&gt; - Fundamental support of CRDTs for our implementation on state management and data sync.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/electron/electron&#34;&gt;Electron&lt;/a&gt; - Build cross-platform desktop apps with JavaScript, HTML, and CSS.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/facebook/react&#34;&gt;React&lt;/a&gt; - View layer support and web GUI framework.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rust-lang/rust&#34;&gt;Rust&lt;/a&gt; - High performance language that extends the ability and availability of our real-time backend, OctoBase.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pmndrs/jotai&#34;&gt;Jotai&lt;/a&gt; - Primitive and flexible state management for React.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mui/material-ui&#34;&gt;MUI&lt;/a&gt; - Our most used graphic UI component library.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Jack-Works/async-call-rpc&#34;&gt;async-call-rpc&lt;/a&gt; - A lightweight JSON RPC client &amp;amp; server.&lt;/li&gt; &#xA; &lt;li&gt;Other upstream &lt;a href=&#34;https://github.com/toeverything/AFFiNE/network/dependencies&#34;&gt;dependencies&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Thanks a lot to the community for providing such powerful and simple libraries, so that we can focus more on the implementation of the product logic, and we hope that in the future our projects will also provide a more easy-to-use knowledge base for everyone.&lt;/p&gt; &#xA;&lt;h1&gt;Contributors&lt;/h1&gt; &#xA;&lt;p&gt;We would like to express our gratitude to all the individuals who have already contributed to AFFiNE! If you have any AFFiNE-related project, documentation, tool or template, please feel free to contribute it by submitting a pull request to our curated list on GitHub: &lt;a href=&#34;https://github.com/toeverything/awesome-affine&#34;&gt;awesome-affine&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;a href=&#34;https://github.com/toeverything/affine/graphs/contributors&#34;&gt; &lt;img alt=&#34;contributors&#34; src=&#34;https://opencollective.com/affine/contributors.svg?width=890&amp;amp;button=false&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;Self-Host&lt;/h2&gt; &#xA;&lt;p&gt;Get started with Docker and deploy your own feature-rich, restriction-free deployment of AFFiNE - check the &lt;a href=&#34;https://github.com/toeverything/AFFiNE/pkgs/container/affine-self-hosted&#34;&gt;latest packages&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Hiring&lt;/h2&gt; &#xA;&lt;p&gt;Some amazing companies including AFFiNE are looking for developers! Are you interested in helping build with AFFiNE and/or its partners? Check out some of the latest &lt;a href=&#34;https://raw.githubusercontent.com/toeverything/AFFiNE/master/docs/jobs.md&#34;&gt;jobs available&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Upgrading&lt;/h2&gt; &#xA;&lt;p&gt;For upgrading information please see our &lt;a href=&#34;https://affine.pro/blog?tag=Release%20Note&#34;&gt;update page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Feature Request&lt;/h2&gt; &#xA;&lt;p&gt;For feature request please see &lt;a href=&#34;https://community.affine.pro/c/feature-requests/&#34;&gt;community.affine.pro&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Is it awesome?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/AffineOfficial/followers&#34;&gt;These people&lt;/a&gt; seem to like it.&lt;/p&gt; &#xA;&lt;h2&gt;Building&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/toeverything/AFFiNE/master/docs/BUILDING.md&#34;&gt;BUILDING.md&lt;/a&gt; for instructions on how to build AFFiNE from source code.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions from everyone. See &lt;a href=&#34;https://raw.githubusercontent.com/toeverything/AFFiNE/master/docs/contributing/tutorial.md&#34;&gt;docs/contributing/tutorial.md&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/toeverything/AFFiNE/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>homanp/superagent</title>
    <updated>2023-07-02T01:30:21Z</updated>
    <id>tag:github.com,2023-07-02:/homanp/superagent</id>
    <link href="https://github.com/homanp/superagent" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🥷 Superagent - Build, deploy, and manage LLM-powered agents&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;Superagent 🥷&lt;/h1&gt; &#xA; &lt;p&gt;&lt;strong&gt;Build, deploy, and manage LLM-powered agents&lt;/strong&gt; &lt;a href=&#34;https://Superagent.sh&#34;&gt;Superagent.sh&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt; &lt;img alt=&#34;GitHub Contributors&#34; src=&#34;https://img.shields.io/github/contributors/homanp/Superagent&#34;&gt; &lt;img alt=&#34;GitHub Last Commit&#34; src=&#34;https://img.shields.io/github/last-commit/homanp/Superagent&#34;&gt; &lt;img alt=&#34;&#34; src=&#34;https://img.shields.io/github/repo-size/homanp/Superagent&#34;&gt; &lt;img alt=&#34;GitHub Issues&#34; src=&#34;https://img.shields.io/github/issues/homanp/Superagent&#34;&gt; &lt;img alt=&#34;GitHub Pull Requests&#34; src=&#34;https://img.shields.io/github/issues-pr/homanp/Superagent&#34;&gt; &lt;img alt=&#34;Github License&#34; src=&#34;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&#34;&gt; &lt;img alt=&#34;Discord&#34; src=&#34;https://img.shields.io/discord/1110910277110743103?label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=plastic&amp;amp;color=d7b023)%5D(https://discord.gg/e8j7mgjDUK&#34;&gt; &lt;/p&gt; &#xA; &lt;br&gt; &#xA; &lt;img alt=&#34;Superagent UI&#34; src=&#34;https://raw.githubusercontent.com/homanp/superagent/main/ui/public/superagent.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;🧐 What is this?&lt;/h2&gt; &#xA;&lt;p&gt;Superagent is a powerful tool that simplifies the configuration and deployment of LLM (Large Language Model) Agents to production. It provides a range of features and functionalities to make it easier for developers to build, manage and deploy AI agents to production including features such as built in memory and document retrieval via vector dbs, powerful tools, webhooks, cron jobs etc.&lt;/p&gt; &#xA;&lt;h2&gt;🥷 Superagent Cloud&lt;/h2&gt; &#xA;&lt;p&gt;If you are looking for a plug-n-play way getting started be sure to checkout &lt;a href=&#34;https://Superagent.sh&#34;&gt;Superagent.sh&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;🔎 Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Checkout the &lt;a href=&#34;https://docs.Superagent.sh/&#34;&gt;full documentation here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;🚧 Roadmap&lt;/h2&gt; &#xA;&lt;p&gt;You can follow the &lt;a href=&#34;https://github.com/users/homanp/projects/4&#34;&gt;roadmap here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🛠️ Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;To get started with Superagent, follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Clone the Superagent repository into a public GitHub repository or fork it from &lt;a href=&#34;https://github.com/homanp/Superagent/fork&#34;&gt;https://github.com/homanp/Superagent/fork&lt;/a&gt;. If you plan to distribute the code, keep the source code public.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/homanp/Superagent.git&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To run the script, simply execute it using:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bash setup.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;See the setup instructions for the UI in the &lt;code&gt;ui&lt;/code&gt; folder.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;💡 Examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Runing Superagent with &lt;a href=&#34;https://github.com/homanp/nextjs-Superagent&#34;&gt;NextJS&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;👨🏽‍💻 SDKs&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/homanp/superagent-js&#34;&gt;Javascript&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/homanp/superagent-py&#34;&gt;Python&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🫶 Contributions&lt;/h2&gt; &#xA;&lt;p&gt;Superagent is an open-source project, and contributions are welcome. If you would like to contribute, you can create new features, fix bugs, or improve the infrastructure. Please refer to the &lt;a href=&#34;https://github.com/homanp/Superagent/raw/main/.github/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; file in the repository for more information on how to contribute.&lt;/p&gt; &#xA;&lt;p&gt;We appreciate your contributions and aim to make it easy for anyone to create and run LLM Agents in production using Superagent.&lt;/p&gt; &#xA;&lt;h2&gt;⭐ Partners&lt;/h2&gt; &#xA;&lt;p&gt;A big thanks to all partners that support the development of &lt;strong&gt;Superagent&lt;/strong&gt;!&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;🌿 &lt;a href=&#34;https://buildwithfern.com/&#34;&gt;Fern&lt;/a&gt;&lt;/strong&gt;: Fern helps create SDKs and client libraries from OpenAPI specs. Superagent uses Fern for all of the client libraries and SDKs we provide. A big shout out for the support!&lt;/p&gt; &#xA;&lt;h2&gt;🙏 Support&lt;/h2&gt; &#xA;&lt;p&gt;We appreciate all the support you can give us, either with contributions, feedback, bug reports or feature requests. Drop a star and share Superagent to the world!&lt;/p&gt;</summary>
  </entry>
</feed>