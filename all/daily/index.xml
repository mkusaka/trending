<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-07-25T01:29:29Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>langchain-ai/rag-from-scratch</title>
    <updated>2025-07-25T01:29:29Z</updated>
    <id>tag:github.com,2025-07-25:/langchain-ai/rag-from-scratch</id>
    <link href="https://github.com/langchain-ai/rag-from-scratch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RAG From Scratch&lt;/h1&gt; &#xA;&lt;p&gt;LLMs are trained on a large but fixed corpus of data, limiting their ability to reason about private or recent information. Fine-tuning is one way to mitigate this, but is often &lt;a href=&#34;https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts&#34;&gt;not well-suited for factual recall&lt;/a&gt; and &lt;a href=&#34;https://www.glean.com/blog/how-to-build-an-ai-assistant-for-the-enterprise&#34;&gt;can be costly&lt;/a&gt;. Retrieval augmented generation (RAG) has emerged as a popular and powerful mechanism to expand an LLM&#39;s knowledge base, using documents retrieved from an external data source to ground the LLM generation via in-context learning. These notebooks accompany a &lt;a href=&#34;https://youtube.com/playlist?list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&amp;amp;feature=shared&#34;&gt;video playlist&lt;/a&gt; that builds up an understanding of RAG from scratch, starting with the basics of indexing, retrieval, and generation. &lt;img src=&#34;https://github.com/langchain-ai/rag-from-scratch/assets/122662504/54a2d76c-b07e-49e7-b4ce-fc45667360a1&#34; alt=&#34;rag_detail_v2&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&#34;&gt;Video playlist&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>