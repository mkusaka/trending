<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-03-27T01:28:38Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Akkudoktor-EOS/EOS</title>
    <updated>2025-03-27T01:28:38Z</updated>
    <id>tag:github.com,2025-03-27:/Akkudoktor-EOS/EOS</id>
    <link href="https://github.com/Akkudoktor-EOS/EOS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repository features an Energy Optimization System (EOS) that optimizes energy distribution, usage for batteries, heat pumps&amp; household devices. It includes predictive models for electricity prices (planned), load forecasting&amp; dynamic optimization to maximize energy efficiency &amp; minimize costs. Founder Dr. Andreas Schmitz (YouTube @akkudoktor)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Energy System Simulation and Optimization&lt;/h1&gt; &#xA;&lt;p&gt;This project provides a comprehensive solution for simulating and optimizing an energy system based on renewable energy sources. With a focus on photovoltaic (PV) systems, battery storage (batteries), load management (consumer requirements), heat pumps, electric vehicles, and consideration of electricity price data, this system enables forecasting and optimization of energy flow and costs over a specified period.&lt;/p&gt; &#xA;&lt;p&gt;Documentation can be found at &lt;a href=&#34;https://akkudoktor-eos.readthedocs.io/en/latest/&#34;&gt;Akkudoktor-EOS&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Involved&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/Akkudoktor-EOS/EOS/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;System requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python &amp;gt;= 3.11, &amp;lt; 3.13&lt;/li&gt; &#xA; &lt;li&gt;Architecture: amd64, aarch64 (armv8)&lt;/li&gt; &#xA; &lt;li&gt;OS: Linux, Windows, macOS&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Note: For Python 3.13 some dependencies (e.g. &lt;a href=&#34;https://github.com/python-pendulum/Pendulum&#34;&gt;Pendulum&lt;/a&gt;) are not yet available on &lt;a href=&#34;https://pypi.org&#34;&gt;https://pypi.org&lt;/a&gt; and have to be manually compiled (a recent &lt;a href=&#34;https://www.rust-lang.org/tools/install&#34;&gt;Rust&lt;/a&gt; installation is required).&lt;/p&gt; &#xA;&lt;p&gt;Other architectures (e.g. armv6, armv7) are unsupported for now, because a multitude of dependencies are not available on &lt;a href=&#34;https://piwheels.org&#34;&gt;https://piwheels.org&lt;/a&gt; and have to be built manually (a recent Rust installation and &lt;a href=&#34;https://gcc.gnu.org/&#34;&gt;GCC&lt;/a&gt; are required, Python 3.11 is recommended).&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Docker images (amd64/aarch64) can be found at &lt;a href=&#34;https://hub.docker.com/r/akkudoktor/eos&#34;&gt;akkudoktor/eos&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Following sections describe how to locally start the EOS server on &lt;code&gt;http://localhost:8503&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Run from source&lt;/h3&gt; &#xA;&lt;p&gt;Install dependencies in virtual environment:&lt;/p&gt; &#xA;&lt;p&gt;Linux:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m venv .venv&#xA;.venv/bin/pip install -r requirements.txt&#xA;.venv/bin/pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Windows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;python -m venv .venv&#xA; .venv\Scripts\pip install -r requirements.txt&#xA; .venv\Scripts\pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, start the EOS server to access it at &lt;code&gt;http://localhost:8503&lt;/code&gt; (API docs at &lt;code&gt;http://localhost:8503/docs&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;p&gt;Linux:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;.venv/bin/python src/akkudoktoreos/server/eos.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Windows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;.venv\Scripts\python src/akkudoktoreos/server/eos.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;p&gt;Start EOS with following command to access it at &lt;code&gt;http://localhost:8503&lt;/code&gt; (API docs at &lt;code&gt;http://localhost:8503/docs&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Configuration&lt;/h2&gt; &#xA;&lt;p&gt;This project uses the &lt;code&gt;EOS.config.json&lt;/code&gt; file to manage configuration settings.&lt;/p&gt; &#xA;&lt;h3&gt;Default Configuration&lt;/h3&gt; &#xA;&lt;p&gt;A default configuration file &lt;code&gt;default.config.json&lt;/code&gt; is provided. This file contains all the necessary configuration keys with their default values.&lt;/p&gt; &#xA;&lt;h3&gt;Custom Configuration&lt;/h3&gt; &#xA;&lt;p&gt;Users can specify a custom configuration directory by setting the environment variable &lt;code&gt;EOS_DIR&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If the directory specified by &lt;code&gt;EOS_DIR&lt;/code&gt; contains an existing &lt;code&gt;config.json&lt;/code&gt; file, the application will use this configuration file.&lt;/li&gt; &#xA; &lt;li&gt;If the &lt;code&gt;EOS.config.json&lt;/code&gt; file does not exist in the specified directory, the &lt;code&gt;default.config.json&lt;/code&gt; file will be copied to the directory as &lt;code&gt;EOS.config.json&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Configuration Updates&lt;/h3&gt; &#xA;&lt;p&gt;If the configuration keys in the &lt;code&gt;EOS.config.json&lt;/code&gt; file are missing or different from those in &lt;code&gt;default.config.json&lt;/code&gt;, they will be automatically updated to match the default settings, ensuring that all required keys are present.&lt;/p&gt; &#xA;&lt;h2&gt;Classes and Functionalities&lt;/h2&gt; &#xA;&lt;p&gt;This project uses various classes to simulate and optimize the components of an energy system. Each class represents a specific aspect of the system, as described below:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;Battery&lt;/code&gt;: Simulates a battery storage system, including capacity, state of charge, and now charge and discharge losses.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;PVForecast&lt;/code&gt;: Provides forecast data for photovoltaic generation, based on weather data and historical generation data.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;Load&lt;/code&gt;: Models the load requirements of a household or business, enabling the prediction of future energy demand.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;Heatpump&lt;/code&gt;: Simulates a heat pump, including its energy consumption and efficiency under various operating conditions.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;Strompreis&lt;/code&gt;: Provides information on electricity prices, enabling optimization of energy consumption and generation based on tariff information.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;EMS&lt;/code&gt;: The Energy Management System (EMS) coordinates the interaction between the various components, performs optimization, and simulates the operation of the entire energy system.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;These classes work together to enable a detailed simulation and optimization of the energy system. For each class, specific parameters and settings can be adjusted to test different scenarios and strategies.&lt;/p&gt; &#xA;&lt;h3&gt;Customization and Extension&lt;/h3&gt; &#xA;&lt;p&gt;Each class is designed to be easily customized and extended to integrate additional functions or improvements. For example, new methods can be added for more accurate modeling of PV system or battery behavior. Developers are invited to modify and extend the system according to their needs.&lt;/p&gt; &#xA;&lt;h2&gt;Server API&lt;/h2&gt; &#xA;&lt;p&gt;See the Swagger API documentation for detailed information: &lt;a href=&#34;https://petstore3.swagger.io/?url=https://raw.githubusercontent.com/Akkudoktor-EOS/EOS/refs/heads/main/openapi.json&#34;&gt;EOS OpenAPI Spec&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Further resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://meintechblog.de/2024/09/05/andreas-schmitz-joerg-installiert-mein-energieoptimierungssystem/&#34;&gt;Installation guide (de)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>kubernetes/ingress-nginx</title>
    <updated>2025-03-27T01:28:38Z</updated>
    <id>tag:github.com,2025-03-27:/kubernetes/ingress-nginx</id>
    <link href="https://github.com/kubernetes/ingress-nginx" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Ingress NGINX Controller for Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ingress NGINX Controller&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://bestpractices.coreinfrastructure.org/projects/5691&#34;&gt;&lt;img src=&#34;https://bestpractices.coreinfrastructure.org/projects/5691/badge&#34; alt=&#34;CII Best Practices&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://goreportcard.com/report/github.com/kubernetes/ingress-nginx&#34;&gt;&lt;img src=&#34;https://goreportcard.com/badge/github.com/kubernetes/ingress-nginx&#34; alt=&#34;Go Report Card&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/kubernetes/ingress-nginx.svg?sanitize=true&#34; alt=&#34;GitHub license&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/kubernetes/ingress-nginx.svg?sanitize=true&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx/raw/main/CONTRIBUTING.md&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/contributions-welcome-orange.svg?sanitize=true&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;ingress-nginx is an Ingress controller for Kubernetes using &lt;a href=&#34;https://www.nginx.org/&#34;&gt;NGINX&lt;/a&gt; as a reverse proxy and load balancer.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/&#34;&gt;Learn more about Ingress on the Kubernetes documentation site&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Get started&lt;/h2&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://kubernetes.github.io/ingress-nginx/deploy/&#34;&gt;Getting Started&lt;/a&gt; document.&lt;/p&gt; &#xA;&lt;p&gt;Do not use in multi-tenant Kubernetes production installations. This project assumes that users that can create Ingress objects are administrators of the cluster. See the &lt;a href=&#34;https://kubernetes.github.io/ingress-nginx/faq/#faq&#34;&gt;FAQ&lt;/a&gt; for more.&lt;/p&gt; &#xA;&lt;h2&gt;Troubleshooting&lt;/h2&gt; &#xA;&lt;p&gt;If you encounter issues, review the &lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/docs/troubleshooting.md&#34;&gt;troubleshooting docs&lt;/a&gt;, &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx/issues&#34;&gt;file an issue&lt;/a&gt;, or talk to us on the &lt;a href=&#34;https://kubernetes.slack.com/messages/ingress-nginx&#34;&gt;#ingress-nginx channel&lt;/a&gt; on the Kubernetes Slack server.&lt;/p&gt; &#xA;&lt;h2&gt;Changelog&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx/releases&#34;&gt;the list of releases&lt;/a&gt; for all changes. For detailed changes for each release, please check the &lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/changelog&#34;&gt;changelog-$version.md&lt;/a&gt; file for the release version. For detailed changes on the &lt;code&gt;ingress-nginx&lt;/code&gt; helm chart, please check the changelog folder for a specific version. &lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/charts/ingress-nginx/changelog&#34;&gt;CHANGELOG-$current-version.md&lt;/a&gt; file.&lt;/p&gt; &#xA;&lt;h3&gt;Supported Versions table&lt;/h3&gt; &#xA;&lt;p&gt;Supported versions for the ingress-nginx project mean that we have completed E2E tests, and they are passing for the versions listed. Ingress-Nginx versions &lt;strong&gt;may&lt;/strong&gt; work on older versions, but the project does not make that guarantee.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Supported&lt;/th&gt; &#xA;   &lt;th&gt;Ingress-NGINX version&lt;/th&gt; &#xA;   &lt;th&gt;k8s supported version&lt;/th&gt; &#xA;   &lt;th&gt;Alpine Version&lt;/th&gt; &#xA;   &lt;th&gt;Nginx Version&lt;/th&gt; &#xA;   &lt;th&gt;Helm Chart Version&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🔄&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.12.1&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.32, 1.31, 1.30,&amp;nbsp;1.29, 1.28&lt;/td&gt; &#xA;   &lt;td&gt;3.21.3&lt;/td&gt; &#xA;   &lt;td&gt;1.25.5&lt;/td&gt; &#xA;   &lt;td&gt;4.12.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🔄&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.12.0&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.32, 1.31, 1.30,&amp;nbsp;1.29, 1.28&lt;/td&gt; &#xA;   &lt;td&gt;3.21.0&lt;/td&gt; &#xA;   &lt;td&gt;1.25.5&lt;/td&gt; &#xA;   &lt;td&gt;4.12.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🔄&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.12.0-beta.0&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.32, 1.31, 1.30,&amp;nbsp;1.29, 1.28&lt;/td&gt; &#xA;   &lt;td&gt;3.20.3&lt;/td&gt; &#xA;   &lt;td&gt;1.25.5&lt;/td&gt; &#xA;   &lt;td&gt;4.12.0-beta.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🔄&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.11.5&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; &#xA;   &lt;td&gt;3.21.3&lt;/td&gt; &#xA;   &lt;td&gt;1.25.5&lt;/td&gt; &#xA;   &lt;td&gt;4.11.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🔄&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.11.4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; &#xA;   &lt;td&gt;3.21.0&lt;/td&gt; &#xA;   &lt;td&gt;1.25.5&lt;/td&gt; &#xA;   &lt;td&gt;4.11.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🔄&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.11.3&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.30,&amp;nbsp;1.29, 1.28, 1.27, 1.26&lt;/td&gt; &#xA;   &lt;td&gt;3.20.3&lt;/td&gt; &#xA;   &lt;td&gt;1.25.5&lt;/td&gt; &#xA;   &lt;td&gt;4.11.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🔄&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.11.2&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.30,&amp;nbsp;1.29, 1.28, 1.27, 1.26&lt;/td&gt; &#xA;   &lt;td&gt;3.20.0&lt;/td&gt; &#xA;   &lt;td&gt;1.25.5&lt;/td&gt; &#xA;   &lt;td&gt;4.11.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🔄&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.11.1&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.30,&amp;nbsp;1.29, 1.28, 1.27, 1.26&lt;/td&gt; &#xA;   &lt;td&gt;3.20.0&lt;/td&gt; &#xA;   &lt;td&gt;1.25.5&lt;/td&gt; &#xA;   &lt;td&gt;4.11.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;🔄&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.11.0&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.30,&amp;nbsp;1.29, 1.28, 1.27, 1.26&lt;/td&gt; &#xA;   &lt;td&gt;3.20.0&lt;/td&gt; &#xA;   &lt;td&gt;1.25.5&lt;/td&gt; &#xA;   &lt;td&gt;4.11.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.10.6&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt; &#xA;   &lt;td&gt;3.21.0&lt;/td&gt; &#xA;   &lt;td&gt;1.25.5&lt;/td&gt; &#xA;   &lt;td&gt;4.10.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.10.5&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.30,&amp;nbsp;1.29, 1.28, 1.27, 1.26&lt;/td&gt; &#xA;   &lt;td&gt;3.20.3&lt;/td&gt; &#xA;   &lt;td&gt;1.25.5&lt;/td&gt; &#xA;   &lt;td&gt;4.10.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.10.4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.30,&amp;nbsp;1.29, 1.28, 1.27, 1.26&lt;/td&gt; &#xA;   &lt;td&gt;3.20.0&lt;/td&gt; &#xA;   &lt;td&gt;1.25.5&lt;/td&gt; &#xA;   &lt;td&gt;4.10.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.10.3&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.30,&amp;nbsp;1.29, 1.28, 1.27, 1.26&lt;/td&gt; &#xA;   &lt;td&gt;3.20.0&lt;/td&gt; &#xA;   &lt;td&gt;1.25.5&lt;/td&gt; &#xA;   &lt;td&gt;4.10.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.10.2&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.30,&amp;nbsp;1.29, 1.28, 1.27, 1.26&lt;/td&gt; &#xA;   &lt;td&gt;3.20.0&lt;/td&gt; &#xA;   &lt;td&gt;1.25.5&lt;/td&gt; &#xA;   &lt;td&gt;4.10.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.10.1&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.30,&amp;nbsp;1.29, 1.28, 1.27, 1.26&lt;/td&gt; &#xA;   &lt;td&gt;3.19.1&lt;/td&gt; &#xA;   &lt;td&gt;1.25.3&lt;/td&gt; &#xA;   &lt;td&gt;4.10.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;v1.10.0&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.29, 1.28, 1.27, 1.26&lt;/td&gt; &#xA;   &lt;td&gt;3.19.1&lt;/td&gt; &#xA;   &lt;td&gt;1.25.3&lt;/td&gt; &#xA;   &lt;td&gt;4.10.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;v1.9.6&lt;/td&gt; &#xA;   &lt;td&gt;1.29, 1.28, 1.27, 1.26, 1.25&lt;/td&gt; &#xA;   &lt;td&gt;3.19.0&lt;/td&gt; &#xA;   &lt;td&gt;1.21.6&lt;/td&gt; &#xA;   &lt;td&gt;4.9.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;v1.9.5&lt;/td&gt; &#xA;   &lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt; &#xA;   &lt;td&gt;3.18.4&lt;/td&gt; &#xA;   &lt;td&gt;1.21.6&lt;/td&gt; &#xA;   &lt;td&gt;4.9.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;v1.9.4&lt;/td&gt; &#xA;   &lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt; &#xA;   &lt;td&gt;3.18.4&lt;/td&gt; &#xA;   &lt;td&gt;1.21.6&lt;/td&gt; &#xA;   &lt;td&gt;4.8.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;v1.9.3&lt;/td&gt; &#xA;   &lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt; &#xA;   &lt;td&gt;3.18.4&lt;/td&gt; &#xA;   &lt;td&gt;1.21.6&lt;/td&gt; &#xA;   &lt;td&gt;4.8.*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;v1.9.1&lt;/td&gt; &#xA;   &lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt; &#xA;   &lt;td&gt;3.18.4&lt;/td&gt; &#xA;   &lt;td&gt;1.21.6&lt;/td&gt; &#xA;   &lt;td&gt;4.8.*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;v1.9.0&lt;/td&gt; &#xA;   &lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt; &#xA;   &lt;td&gt;3.18.2&lt;/td&gt; &#xA;   &lt;td&gt;1.21.6&lt;/td&gt; &#xA;   &lt;td&gt;4.8.*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;v1.8.4&lt;/td&gt; &#xA;   &lt;td&gt;1.27, 1.26, 1.25, 1.24&lt;/td&gt; &#xA;   &lt;td&gt;3.18.2&lt;/td&gt; &#xA;   &lt;td&gt;1.21.6&lt;/td&gt; &#xA;   &lt;td&gt;4.7.*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;v1.7.1&lt;/td&gt; &#xA;   &lt;td&gt;1.27, 1.26, 1.25, 1.24&lt;/td&gt; &#xA;   &lt;td&gt;3.17.2&lt;/td&gt; &#xA;   &lt;td&gt;1.21.6&lt;/td&gt; &#xA;   &lt;td&gt;4.6.*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;v1.6.4&lt;/td&gt; &#xA;   &lt;td&gt;1.26, 1.25, 1.24, 1.23&lt;/td&gt; &#xA;   &lt;td&gt;3.17.0&lt;/td&gt; &#xA;   &lt;td&gt;1.21.6&lt;/td&gt; &#xA;   &lt;td&gt;4.5.*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;v1.5.1&lt;/td&gt; &#xA;   &lt;td&gt;1.25, 1.24, 1.23&lt;/td&gt; &#xA;   &lt;td&gt;3.16.2&lt;/td&gt; &#xA;   &lt;td&gt;1.21.6&lt;/td&gt; &#xA;   &lt;td&gt;4.4.*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;v1.4.0&lt;/td&gt; &#xA;   &lt;td&gt;1.25, 1.24, 1.23, 1.22&lt;/td&gt; &#xA;   &lt;td&gt;3.16.2&lt;/td&gt; &#xA;   &lt;td&gt;1.19.10†&lt;/td&gt; &#xA;   &lt;td&gt;4.3.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;v1.3.1&lt;/td&gt; &#xA;   &lt;td&gt;1.24, 1.23, 1.22, 1.21, 1.20&lt;/td&gt; &#xA;   &lt;td&gt;3.16.2&lt;/td&gt; &#xA;   &lt;td&gt;1.19.10†&lt;/td&gt; &#xA;   &lt;td&gt;4.2.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://kubernetes.io/blog/2021/07/26/update-with-ingress-nginx/&#34;&gt;this article&lt;/a&gt; if you want upgrade to the stable Ingress API.&lt;/p&gt; &#xA;&lt;h2&gt;Get Involved&lt;/h2&gt; &#xA;&lt;p&gt;Thanks for taking the time to join our community and start contributing!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;This project adheres to the &lt;a href=&#34;https://git.k8s.io/community/code-of-conduct.md&#34;&gt;Kubernetes Community Code of Conduct&lt;/a&gt;. By participating in this project, you agree to abide by its terms.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Contributing&lt;/strong&gt;: Contributions of all kinds are welcome!&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Read &lt;a href=&#34;https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/CONTRIBUTING.md&#34;&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; for information about setting up your environment, the workflow that we expect, and instructions on the developer certificate of origin that we require.&lt;/li&gt; &#xA;   &lt;li&gt;Join our Kubernetes Slack channel for developer discussion : &lt;a href=&#34;https://kubernetes.slack.com/archives/C021E147ZA4&#34;&gt;#ingress-nginx-dev&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;Submit GitHub issues for any feature enhancements, bugs, or documentation problems. &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Please make sure to read the &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx/raw/main/CONTRIBUTING.md#issue-reporting-guidelines&#34;&gt;Issue Reporting Checklist&lt;/a&gt; before opening an issue. Issues not conforming to the guidelines &lt;strong&gt;may be closed immediately&lt;/strong&gt;.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Join our &lt;a href=&#34;https://groups.google.com/a/kubernetes.io/g/ingress-nginx-dev/c/ebbBMo-zX-w&#34;&gt;ingress-nginx-dev mailing list&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Support&lt;/strong&gt;:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Join the &lt;a href=&#34;https://kubernetes.slack.com/messages/CANQGM8BA/&#34;&gt;#ingress-nginx-users&lt;/a&gt; channel inside the &lt;a href=&#34;http://slack.kubernetes.io/&#34;&gt;Kubernetes Slack&lt;/a&gt; to ask questions or get support from the maintainers and other users.&lt;/li&gt; &#xA;   &lt;li&gt;The &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx/issues&#34;&gt;GitHub issues&lt;/a&gt; in the repository are &lt;strong&gt;exclusively&lt;/strong&gt; for bug reports and feature requests.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Discuss&lt;/strong&gt;: Tweet using the &lt;code&gt;#IngressNginx&lt;/code&gt; hashtag or sharing with us &lt;a href=&#34;https://twitter.com/IngressNGINX&#34;&gt;@IngressNginx&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/ingress-nginx/raw/main/LICENSE&#34;&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>joanrod/star-vector</title>
    <updated>2025-03-27T01:28:38Z</updated>
    <id>tag:github.com,2025-03-27:/joanrod/star-vector</id>
    <link href="https://github.com/joanrod/star-vector" rel="alternate"></link>
    <summary type="html">&lt;p&gt;StarVector is a foundation model for SVG generation that transforms vectorization into a code generation task. Using a vision-language modeling architecture, StarVector processes both visual and textual inputs to produce high-quality SVG code with remarkable precision.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;💫 StarVector: Generating Scalable Vector Graphics Code from Images and Text&lt;/h1&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/joanrod/star-vector/main/assets/starvector-xyz.png&#34; alt=&#34;starvector&#34; style=&#34;width: 800px; display: block; margin-left: auto; margin-right: auto;&#34;&gt; &#xA; &lt;a href=&#34;https://arxiv.org/abs/2312.11556&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;arXiv&#34; src=&#34;https://img.shields.io/badge/arXiv-StarVector-red?logo=arxiv&#34; height=&#34;25&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://starvector.github.io/&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;Website&#34; src=&#34;https://img.shields.io/badge/%F0%9F%8C%8E_Website-starvector.github.io-blue.svg?sanitize=true&#34; height=&#34;25&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://huggingface.co/starvector/starvector-1b-im2svg&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;HF Models: StarVector&#34; src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20_Model-StarVector--1B-ffc107?color=ffc107&amp;amp;logoColor=white&#34; height=&#34;25&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://huggingface.co/starvector/starvector-8b-im2svg&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;HF Models: StarVector&#34; src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20_Model-StarVector--8B-ffc107?color=ffc107&amp;amp;logoColor=white&#34; height=&#34;25&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://huggingface.co/datasets/starvector/svg-stack&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;HF Dataset: SVG-Stack&#34; src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20_Data-SVG--Stack-ffc107?color=ffc107&amp;amp;logoColor=white&#34; height=&#34;25&#34;&gt; &lt;/a&gt; &#xA; &lt;a href=&#34;https://huggingface.co/collections/starvector/starvector-svg-datasets-svg-bench-67811204a76475be4dd66d09&#34; target=&#34;_blank&#34;&gt; &lt;img alt=&#34;HF Dataset: SVG-Bench&#34; src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20_Benchmark-SVG--Bench-ffc107?color=ffc107&amp;amp;logoColor=white&#34; height=&#34;25&#34;&gt; &lt;/a&gt; &#xA; &lt;div style=&#34;font-family: charter;&#34;&gt; &#xA;  &lt;a href=&#34;https://joanrod.github.io&#34; target=&#34;_blank&#34;&gt;Juan A. Rodriguez&lt;/a&gt;, &#xA;  &lt;a href=&#34;https://abhaypuri.github.io/portfolio/&#34; target=&#34;_blank&#34;&gt;Abhay Puri&lt;/a&gt;, &#xA;  &lt;a href=&#34;https://shubhamagarwal92.github.io/&#34; target=&#34;_blank&#34;&gt;Shubham Agarwal&lt;/a&gt;, &#xA;  &lt;a href=&#34;https://scholar.google.ca/citations?user=8vRS7F0AAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34;&gt;Issam H. Laradji&lt;/a&gt;, &#xA;  &lt;a href=&#34;https://scholar.google.es/citations?user=IwBx73wAAAAJ&amp;amp;hl=ca&#34; target=&#34;_blank&#34;&gt;Pau Rodriguez&lt;/a&gt;, &#xA;  &lt;a href=&#34;https://scholar.google.es/citations?user=1jHvtfsAAAAJ&amp;amp;hl=ca&#34; target=&#34;_blank&#34;&gt;David Vazquez&lt;/a&gt;, &#xA;  &lt;a href=&#34;https://scholar.google.com/citations?user=1ScWJOoAAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34;&gt;Chris Pal&lt;/a&gt;, &#xA;  &lt;a href=&#34;https://scholar.google.com/citations?user=aVfyPAoAAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34;&gt;Marco Pedersoli&lt;/a&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;🔥 News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;March 2025: &lt;strong&gt;StarVector Accepted at CVPR 2025&lt;/strong&gt;, &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;StarVector has been accepted at CVPR 2025! Check out the paper [&lt;a href=&#34;https://arxiv.org/abs/2312.11556&#34;&gt;Link&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;Check out our website for more information [&lt;a href=&#34;https://starvector.github.io/&#34;&gt;Link&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;StarVector models are now available on HuggingFace! [&lt;a href=&#34;https://huggingface.co/starvector/starvector-1b-im2svg&#34;&gt;Link&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/starvector/starvector-8b-im2svg&#34;&gt;Link&lt;/a&gt;]&lt;/li&gt; &#xA;   &lt;li&gt;SVGBench and SVG-Stack datasets are now available on HuggingFace Datasets! [&lt;a href=&#34;https://huggingface.co/datasets/starvector/svg-bench&#34;&gt;Link&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/datasets/starvector/svg-stack&#34;&gt;Link&lt;/a&gt;]&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🚀 Introduction&lt;/h2&gt; &#xA;&lt;p&gt;StarVector is a multimodal vision-language model for Scalable Vector Graphics (SVG) generation. It can be used to perform image2SVG and text2SVG generation. We pose image generation as a code generation task, using the power of multimodal VLMs&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/joanrod/star-vector/main/assets/starvector-teaser.png&#34; alt=&#34;starvector&#34; style=&#34;width: 900px; display: block; margin-left: auto; margin-right: auto;&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;: Scalable Vector Graphics (SVGs) are vital for modern image rendering due to their scalability and versatility. Previous SVG generation methods have focused on curve-based vectorization, lacking semantic understanding, often producing artifacts, and struggling with SVG primitives beyond \textit{path} curves. To address these issues, we introduce StarVector, a multimodal large language model for SVG generation. It performs image vectorization by understanding image semantics and using SVG primitives for compact, precise outputs. Unlike traditional methods, StarVector works directly in the SVG code space, leveraging visual understanding to apply accurate SVG primitives. To train StarVector, we create SVG-Stack, a diverse dataset of 2M samples that enables generalization across vectorization tasks and precise use of primitives like ellipses, polygons, and text. We address challenges in SVG evaluation, showing that pixel-based metrics like MSE fail to capture the unique qualities of vector graphics. We introduce SVG-Bench, a benchmark across 10 datasets, and 3 tasks: Image-to-SVG, Text-to-SVG generation, and diagram generation. Using this setup, StarVector achieves state-of-the-art performance, producing more compact and semantically rich SVGs.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Multimodal Architecture&lt;/h3&gt; &#xA;&lt;p&gt;StarVector uses a multimodal architecture to process images and text. When performing Image-to-SVG (or image vectorization), the image is projected into visual tokens, and SVG code is generated. When performing Text-to-SVG, the model only recieves the text instruction (no image is provided), and a novel SVG is created. The LLM is based of StarCoder, which we leverage to transfer coding skills to SVG generation.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/joanrod/star-vector/main/assets/starvector-arch.png&#34; alt=&#34;starvector&#34; style=&#34;width: 700px; display: block; margin-left: auto; margin-right: auto;&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;📖 Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joanrod/star-vector/main/#installation&#34;&gt;💿 Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joanrod/star-vector/main/#quick-start---image2svg-generation&#34;&gt;🏎️ Quick Start - Image2SVG Generation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joanrod/star-vector/main/#models&#34;&gt;🎨 Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joanrod/star-vector/main/#datasets---svg-bench&#34;&gt;📊 Datasets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joanrod/star-vector/main/#training&#34;&gt;🏋️‍♂️ Training&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joanrod/star-vector/main/#validation-on-svg-benchmarks-svg-bench&#34;&gt;🏆 Evaluation on SVG-Bench&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joanrod/star-vector/main/#starvector-demo&#34;&gt;🧩 Demo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joanrod/star-vector/main/#citation&#34;&gt;📚 Citation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/joanrod/star-vector/main/#license&#34;&gt;📝 License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repository and navigate to star-vector folder&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/joanrod/star-vector.git&#xA;cd star-vector&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Install Package&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;conda create -n starvector python=3.11.3 -y&#xA;conda activate starvector&#xA;pip install --upgrade pip  # enable PEP 660 support&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Install additional packages for training&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -e &#34;.[train]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Upgrade to latest code base&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;git pull&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Quick Start - Image2SVG Generation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;from PIL import Image&#xA;from starvector.model.starvector_arch import StarVectorForCausalLM&#xA;from starvector.data.util import process_and_rasterize_svg&#xA;&#xA;model_name = &#34;starvector/starvector-8b-im2svg&#34;&#xA;&#xA;starvector = StarVectorForCausalLM.from_pretrained(model_name)&#xA;&#xA;starvector.cuda()&#xA;starvector.eval()&#xA;&#xA;image_pil = Image.open(&#39;assets/examples/sample-0.png&#39;)&#xA;image = starvector.process_images([image_pil])[0].cuda()&#xA;batch = {&#34;image&#34;: image}&#xA;&#xA;raw_svg = starvector.generate_im2svg(batch, max_length=1000)[0]&#xA;svg, raster_image = process_and_rasterize_svg(raw_svg)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Use it from HuggingFace AutoModel&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;from PIL import Image&#xA;from transformers import AutoModelForCausalLM, AutoTokenizer, AutoProcessor&#xA;from starvector.data.util import process_and_rasterize_svg&#xA;import torch&#xA;&#xA;model_name = &#34;starvector/starvector-8b-im2svg&#34;&#xA;&#xA;starvector = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, trust_remote_code=True)&#xA;processor = starvector.model.processor&#xA;tokenizer = starvector.model.svg_transformer.tokenizer&#xA;&#xA;starvector.cuda()&#xA;starvector.eval()&#xA;&#xA;image_pil = Image.open(&#39;assets/examples/sample-18.png&#39;)&#xA;&#xA;image = processor(image_pil, return_tensors=&#34;pt&#34;)[&#39;pixel_values&#39;].cuda()&#xA;if not image.shape[0] == 1:&#xA;    image = image.squeeze(0)&#xA;batch = {&#34;image&#34;: image}&#xA;&#xA;raw_svg = starvector.generate_im2svg(batch, max_length=4000)[0]&#xA;svg, raster_image = process_and_rasterize_svg(raw_svg)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Models&lt;/h2&gt; &#xA;&lt;p&gt;We provide &lt;a href=&#34;https://huggingface.co/collections/starvector/starvector-models-6783b22c7bd4b43d13cb5289&#34;&gt;Hugging Face 🤗 model checkpoints&lt;/a&gt; for image2SVG vectorization, for 💫 StarVector-8B and 💫 StarVector-1B. These are the results on SVG-Bench, using the DinoScore metric.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;SVG-Stack&lt;/th&gt; &#xA;   &lt;th&gt;SVG-Fonts&lt;/th&gt; &#xA;   &lt;th&gt;SVG-Icons&lt;/th&gt; &#xA;   &lt;th&gt;SVG-Emoji&lt;/th&gt; &#xA;   &lt;th&gt;SVG-Diagrams&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AutoTrace&lt;/td&gt; &#xA;   &lt;td&gt;0.942&lt;/td&gt; &#xA;   &lt;td&gt;0.954&lt;/td&gt; &#xA;   &lt;td&gt;0.946&lt;/td&gt; &#xA;   &lt;td&gt;0.975&lt;/td&gt; &#xA;   &lt;td&gt;0.874&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Potrace&lt;/td&gt; &#xA;   &lt;td&gt;0.898&lt;/td&gt; &#xA;   &lt;td&gt;0.967&lt;/td&gt; &#xA;   &lt;td&gt;0.972&lt;/td&gt; &#xA;   &lt;td&gt;0.882&lt;/td&gt; &#xA;   &lt;td&gt;0.875&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;VTracer&lt;/td&gt; &#xA;   &lt;td&gt;0.954&lt;/td&gt; &#xA;   &lt;td&gt;0.964&lt;/td&gt; &#xA;   &lt;td&gt;0.940&lt;/td&gt; &#xA;   &lt;td&gt;0.981&lt;/td&gt; &#xA;   &lt;td&gt;0.882&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Im2Vec&lt;/td&gt; &#xA;   &lt;td&gt;0.692&lt;/td&gt; &#xA;   &lt;td&gt;0.733&lt;/td&gt; &#xA;   &lt;td&gt;0.754&lt;/td&gt; &#xA;   &lt;td&gt;0.732&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LIVE&lt;/td&gt; &#xA;   &lt;td&gt;0.934&lt;/td&gt; &#xA;   &lt;td&gt;0.956&lt;/td&gt; &#xA;   &lt;td&gt;0.959&lt;/td&gt; &#xA;   &lt;td&gt;0.969&lt;/td&gt; &#xA;   &lt;td&gt;0.870&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DiffVG&lt;/td&gt; &#xA;   &lt;td&gt;0.810&lt;/td&gt; &#xA;   &lt;td&gt;0.821&lt;/td&gt; &#xA;   &lt;td&gt;0.952&lt;/td&gt; &#xA;   &lt;td&gt;0.814&lt;/td&gt; &#xA;   &lt;td&gt;0.822&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPT-4-V&lt;/td&gt; &#xA;   &lt;td&gt;0.852&lt;/td&gt; &#xA;   &lt;td&gt;0.842&lt;/td&gt; &#xA;   &lt;td&gt;0.848&lt;/td&gt; &#xA;   &lt;td&gt;0.850&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;💫 StarVector-1B (🤗 &lt;a href=&#34;https://huggingface.co/starvector/starvector-1b-im2svg&#34;&gt;Link&lt;/a&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;0.926&lt;/td&gt; &#xA;   &lt;td&gt;0.978&lt;/td&gt; &#xA;   &lt;td&gt;0.975&lt;/td&gt; &#xA;   &lt;td&gt;0.929&lt;/td&gt; &#xA;   &lt;td&gt;0.943&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;💫 StarVector-8B (🤗 &lt;a href=&#34;https://huggingface.co/starvector/starvector-8b-im2svg&#34;&gt;Link&lt;/a&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;0.966&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;0.982&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;0.984&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;0.981&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;0.959&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: StarVector models will not work for natural images or illustrations, as they have not been trained on those images. They excel in vectorizing icons, logotypes, technical diagrams, graphs, and charts.&lt;/p&gt; &#xA;&lt;h2&gt;Datasets - SVG-Bench&lt;/h2&gt; &#xA;&lt;p&gt;SVG-Bench is a benchmark for evaluating SVG generation models. It contains 10 datasets, and 3 tasks: Image-to-SVG, Text-to-SVG, and Diagram-to-SVG.&lt;/p&gt; &#xA;&lt;p&gt;See our &lt;a href=&#34;https://huggingface.co/collections/starvector/starvector-svg-datasets-67811204a76475be4dd66d09&#34;&gt;Huggingface 🤗 Dataset Collection&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Train&lt;/th&gt; &#xA;   &lt;th&gt;Val&lt;/th&gt; &#xA;   &lt;th&gt;Test&lt;/th&gt; &#xA;   &lt;th&gt;Token Length&lt;/th&gt; &#xA;   &lt;th&gt;SVG Primitives&lt;/th&gt; &#xA;   &lt;th&gt;Annotation&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SVG-Stack (🤗 &lt;a href=&#34;https://huggingface.co/datasets/starvector/svg-stack&#34;&gt;Link&lt;/a&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;2.1M&lt;/td&gt; &#xA;   &lt;td&gt;108k&lt;/td&gt; &#xA;   &lt;td&gt;5.7k&lt;/td&gt; &#xA;   &lt;td&gt;1,822 ± 1,808&lt;/td&gt; &#xA;   &lt;td&gt;All&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/starvector/text2svg-stack&#34;&gt;Captions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SVG-Stack_sim (🤗 &lt;a href=&#34;https://huggingface.co/datasets/starvector/svg-stack-simple&#34;&gt;Link&lt;/a&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;601k&lt;/td&gt; &#xA;   &lt;td&gt;30.1k&lt;/td&gt; &#xA;   &lt;td&gt;1.5k&lt;/td&gt; &#xA;   &lt;td&gt;2k ± 918&lt;/td&gt; &#xA;   &lt;td&gt;Vector path&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SVG-Diagrams (🤗 &lt;a href=&#34;https://huggingface.co/datasets/starvector/svg-diagrams&#34;&gt;Link&lt;/a&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;472&lt;/td&gt; &#xA;   &lt;td&gt;3,486 ± 1,918&lt;/td&gt; &#xA;   &lt;td&gt;All&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SVG-Fonts (🤗 &lt;a href=&#34;https://huggingface.co/datasets/starvector/svg-fonts&#34;&gt;Link&lt;/a&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;1.8M&lt;/td&gt; &#xA;   &lt;td&gt;91.5k&lt;/td&gt; &#xA;   &lt;td&gt;4.8k&lt;/td&gt; &#xA;   &lt;td&gt;2,121 ± 1,868&lt;/td&gt; &#xA;   &lt;td&gt;Vector path&lt;/td&gt; &#xA;   &lt;td&gt;Font letter&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SVG-Fonts_sim (🤗 &lt;a href=&#34;https://huggingface.co/datasets/starvector/svg-fonts-simple&#34;&gt;Link&lt;/a&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;1.4M&lt;/td&gt; &#xA;   &lt;td&gt;71.7k&lt;/td&gt; &#xA;   &lt;td&gt;3.7k&lt;/td&gt; &#xA;   &lt;td&gt;1,722 ± 723&lt;/td&gt; &#xA;   &lt;td&gt;Vector path&lt;/td&gt; &#xA;   &lt;td&gt;Font letter&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SVG-Emoji (🤗 &lt;a href=&#34;https://huggingface.co/datasets/starvector/svg-emoji&#34;&gt;Link&lt;/a&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;8.7k&lt;/td&gt; &#xA;   &lt;td&gt;667&lt;/td&gt; &#xA;   &lt;td&gt;668&lt;/td&gt; &#xA;   &lt;td&gt;2,551 ± 1,805&lt;/td&gt; &#xA;   &lt;td&gt;All&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SVG-Emoji_sim (🤗 &lt;a href=&#34;https://huggingface.co/datasets/starvector/svg-emoji-simple&#34;&gt;Link&lt;/a&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;580&lt;/td&gt; &#xA;   &lt;td&gt;57&lt;/td&gt; &#xA;   &lt;td&gt;96&lt;/td&gt; &#xA;   &lt;td&gt;2,448 ± 1,026&lt;/td&gt; &#xA;   &lt;td&gt;Vector Path&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SVG-Icons (🤗 &lt;a href=&#34;https://huggingface.co/datasets/starvector/svg-icons&#34;&gt;Link&lt;/a&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;80.4k&lt;/td&gt; &#xA;   &lt;td&gt;6.2k&lt;/td&gt; &#xA;   &lt;td&gt;2.4k&lt;/td&gt; &#xA;   &lt;td&gt;2,449 ± 1,543&lt;/td&gt; &#xA;   &lt;td&gt;Vector path&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SVG-Icons_sim (🤗 &lt;a href=&#34;https://huggingface.co/datasets/starvector/svg-icons-simple&#34;&gt;Link&lt;/a&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;80,435&lt;/td&gt; &#xA;   &lt;td&gt;2,836&lt;/td&gt; &#xA;   &lt;td&gt;1,277&lt;/td&gt; &#xA;   &lt;td&gt;2,005 ± 824&lt;/td&gt; &#xA;   &lt;td&gt;Vector path&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;SVG-FIGR (🤗 &lt;a href=&#34;https://huggingface.co/datasets/starvector/FIGR-SVG&#34;&gt;Link&lt;/a&gt;)&lt;/td&gt; &#xA;   &lt;td&gt;270k&lt;/td&gt; &#xA;   &lt;td&gt;27k&lt;/td&gt; &#xA;   &lt;td&gt;3k&lt;/td&gt; &#xA;   &lt;td&gt;5,342 ± 2,345&lt;/td&gt; &#xA;   &lt;td&gt;Vector path&lt;/td&gt; &#xA;   &lt;td&gt;Class, Caption&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;We offer a summary of statistics about the datasets used in our training and evaluation experiments. This datasets are included in SVG-Bench. The subscript &lt;em&gt;sim&lt;/em&gt; stands for the simplified version of the dataset, as required by some baselines.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;h3&gt;Confirm dependencies are installed&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -e &#34;.[train]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Set environment variables&lt;/h3&gt; &#xA;&lt;p&gt;We recommend setting the following environment variables:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  export HF_HOME=&amp;lt;path to the folder where you want to store the models&amp;gt;&#xA;  export HF_TOKEN=&amp;lt;your huggingface token&amp;gt;&#xA;  export WANDB_API_KEY=&amp;lt;your wandb token&amp;gt;&#xA;  export OUTPUT_DIR=&amp;lt;path/to/output&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;cd the root of the repository.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;cd star-vector&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Image2SVG Pretraining (Stage 1)&lt;/h3&gt; &#xA;&lt;p&gt;We have different training approaches for StarVector-1B and StarVector-8B. StarVector-1B can be trained using Deepspeed, while StarVector-8B requires FSDP.&lt;/p&gt; &#xA;&lt;h4&gt;StarVector-1B Training&lt;/h4&gt; &#xA;&lt;p&gt;You can use the following command to train StarVector-1B on SVG-Stack for the Image2SVG vectorization task, using Deepspeed and Accelerate&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# StarVector-1B&#xA;accelerate launch --config_file configs/accelerate/deepspeed-8-gpu.yaml starvector/train/train.py config=configs/models/starvector-1b/im2svg-stack.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;StarVector-8B Training&lt;/h4&gt; &#xA;&lt;p&gt;You can use the following command to train StarVector-8B on SVG-Stack for the Image2SVG vectorization task, using FSDP and Accelerate. We provide the torchrun command to support multi-nodes and multi-GPUs.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# StarVector-8B&#xA;torchrun \&#xA;  --nproc-per-node=8 \&#xA;  --nnodes=1 \&#xA;  starvector/train/train.py \&#xA;  config=configs/models/starvector-8b/im2svg-stack.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Finetuning StarVector (Stage 2)&lt;/h3&gt; &#xA;&lt;p&gt;After pretraining StarVector on image vectorization, we finetune it on additional SVG tasks like Text2SVG, and SVG-Bench datasets.&lt;/p&gt; &#xA;&lt;h4&gt;Text2SVG Finetuning&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# StarVector-1B&#xA;accelerate launch --config_file config/accelerate/deepspeed-8-gpu.yaml starvector/train/train.py config=configs/models/starvector-1b/text2svg-stack.yaml&#xA;&#xA;# StarVector-8B&#xA;torchrun \&#xA;  --nproc-per-node=8 \&#xA;  --nnodes=1 \&#xA;  starvector/train/train.py \&#xA;  config=configs/models/starvector-8b/text2svg-stack.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;SVG-Bench Finetuning&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# StarVector-1B&#xA;accelerate launch --config_file config/accelerate/deepspeed-8-gpu.yaml starvector/train/train.py config=configs/models/starvector-1b/im2svg-{fonts,icons,emoji}.yaml&#xA;&#xA;# StarVector-8B&#xA;torchrun \&#xA;  --nproc-per-node=8 \&#xA;  --nnodes=1 \&#xA;  starvector/train/train.py \&#xA;  config=configs/models/starvector-8b/im2svg-{fonts,icons,emoji}.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We also provide shell scripts in &lt;code&gt;scripts/train/*&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Validation on SVG Benchmarks (⭐ SVG-Bench)&lt;/h2&gt; &#xA;&lt;p&gt;We validate StarVector on ⭐ SVG-Bench Benchmark. We provide the SVGValidator class that allows you to run StarVector using &lt;strong&gt;1) the HuggingFace generation backend&lt;/strong&gt; or &lt;strong&gt;2) the VLLM backend&lt;/strong&gt;. The later is substantially faster thanks to the use of Paged Attention.&lt;/p&gt; &#xA;&lt;h3&gt;HuggingFace Generation Backend&lt;/h3&gt; &#xA;&lt;p&gt;Let&#39;s start with the evaluation for StarVector-1B and StarVector-8B on SVG-Stack, using the HuggingFace generation backend (StarVectorHFAPIValidator). To override the input arguments, you can add cli args following the yaml file structure.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# StarVector-1B on SVG-Stack, using the HuggingFace backend &#xA;python starvector/validation/validate.py \&#xA;config=configs/generation/hf/starvector-1b/im2svg.yaml \&#xA;dataset.name=starvector/svg-stack&#xA;&#xA;# StarVector-8B on SVG-Stack, using the vanilla HuggingFace generation API&#xA;python starvector/validation/validate.py \&#xA;config=configs/generation/hf/starvector-8b/im2svg.yaml \&#xA;dataset.name=starvector/svg-stack&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;vLLM Backend&lt;/h3&gt; &#xA;&lt;p&gt;For using the vLLM backend (StarVectorVLLMAPIValidator), first install our StarVector fork of VLLM, &lt;a href=&#34;https://github.com/starvector/vllm&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/starvector/vllm.git&#xA;cd vllm&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, launch the using the vllm config file (it uses StarVectorVLLMValidator):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# StarVector-1B&#xA;python starvector/validation/validate.py \&#xA;config=configs/generation/vllm/starvector-1b/im2svg.yaml \&#xA;dataset.name=starvector/svg-stack&#xA;&#xA;# StarVector-8B&#xA;python starvector/validation/validate.py \&#xA;config=configs/generation/vllm/starvector-8b/im2svg.yaml \&#xA;dataset.name=starvector/svg-stack&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We provide evaluation scripts in &lt;code&gt;scripts/eval/*&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;StarVector Demo&lt;/h2&gt; &#xA;&lt;p&gt;The demo provides two options for converting images to SVG code:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;HuggingFace generation functionality&lt;/li&gt; &#xA; &lt;li&gt;VLLM (recommended) - offers faster generation speed&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Option 1: HuggingFace Generation with Gradio Web UI&lt;/h3&gt; &#xA;&lt;p&gt;We provide a Gradio web UI for you to play with our model.&lt;/p&gt; &#xA;&lt;h4&gt;Launch a controller&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;python -m starvector.serve.controller --host 0.0.0.0 --port 10000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Launch a gradio web server.&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;python -m starvector.serve.gradio_web_server --controller http://localhost:10000 --model-list-mode reload --port 7000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You just launched the Gradio web interface. Now, you can open the web interface with the URL printed on the screen. You may notice that there is no model in the model list. Do not worry, as we have not launched any model worker yet. It will be automatically updated when you launch a model worker.&lt;/p&gt; &#xA;&lt;h4&gt;Launch a model worker&lt;/h4&gt; &#xA;&lt;p&gt;This is the actual &lt;em&gt;worker&lt;/em&gt; that performs the inference on the GPU. Each worker is responsible for a single model specified in &lt;code&gt;--model-path&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;python -m starvector.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path joanrodai/starvector-1.4b&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Wait until the process finishes loading the model and you see &#34;Uvicorn running on ...&#34;. Now, refresh your Gradio web UI, and you will see the model you just launched in the model list.&lt;/p&gt; &#xA;&lt;p&gt;You can launch as many workers as you want, and compare between different model checkpoints in the same Gradio interface. Please keep the &lt;code&gt;--controller&lt;/code&gt; the same, and modify the &lt;code&gt;--port&lt;/code&gt; and &lt;code&gt;--worker&lt;/code&gt; to a different port number for each worker.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;vllm serve starvector/starvector-8b-im2svg --chat-template configs/chat-template.jinja --trust-remote-code --port 8001 --max-model-len 16000&#xA;&#xA;python -m starvector.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port &amp;lt;different from 40000, say 40001&amp;gt; --worker http://localhost:&amp;lt;change accordingly, i.e. 40001&amp;gt; --model-path &amp;lt;ckpt2&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Option 2: Launch VLLM&lt;/h4&gt; &#xA;&lt;ol start=&#34;0&#34;&gt; &#xA; &lt;li&gt;Remember to clone the starvector/vllm fork (it has modifications for starvector).&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;git clone https://github.com/starvector/vllm.git&#xA;cd vllm&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Call this to launch the VLLM endpoint&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;vllm serve starvector/starvector-1b-im2svg --chat-template configs/chat-template.jinja --trust-remote-code --port 8000 --max-model-len 8192&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Create the demo for VLLM&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;python -m starvector.serve.vllm_api_gradio.controller --host 0.0.0.0 --port 10000&#xA;python -m starvector.serve.vllm_api_gradio.gradio_web_server --controller http://localhost:10000 --model-list-mode reload --port 7000&#xA;python -m starvector.serve.vllm_api_gradio.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-name starvector/starvector-1b-im2svg --vllm-base-url http://localhost:8000&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Add more models by serving them with VLLM and calling a new model worker&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;vllm serve starvector/starvector-8b-im2svg --chat-template configs/chat-template.jinja --trust-remote-code --port 8001 --max-model-len 16384&#xA;&#xA;python -m starvector.serve.vllm_api_gradio.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40001 --worker http://localhost:40001 --model-name starvector/starvector-8b-im2svg --vllm-base-url http://localhost:8001&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{rodriguez2024starvector,&#xA;      title={StarVector: Generating Scalable Vector Graphics Code from Images and Text}, &#xA;      author={Juan A. Rodriguez and Abhay Puri and Shubham Agarwal and Issam H. Laradji and Pau Rodriguez and Sai Rajeswar and David Vazquez and Christopher Pal and Marco Pedersoli},&#xA;      year={2024},&#xA;      eprint={2312.11556},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV},&#xA;      url={https://arxiv.org/abs/2312.11556}, &#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the Apache License, Version 2.0 - see the &lt;a href=&#34;https://raw.githubusercontent.com/joanrod/star-vector/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</summary>
  </entry>
</feed>