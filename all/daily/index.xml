<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-14T01:25:50Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>amitsangani/Llama-2</title>
    <updated>2023-12-14T01:25:50Z</updated>
    <id>tag:github.com,2023-12-14:/amitsangani/Llama-2</id>
    <link href="https://github.com/amitsangani/Llama-2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;All the projects related to Llama&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Llama&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to my Repo! &lt;span&gt;😄&lt;/span&gt; This repository contains notebooks:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;That can be run on Google Colab to understand how to use Llama 2 models&lt;/li&gt; &#xA; &lt;li&gt;Examples of fine-tuning Llama 2 models with different datasets (you can)&lt;/li&gt; &#xA; &lt;li&gt;Prompt-engineering with open source tools/frameworks such as Langchain, FAISS, etc&lt;/li&gt; &#xA; &lt;li&gt;and other fun stuff you can do with Llama!&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>lobehub/lobe-chat</title>
    <updated>2023-12-14T01:25:50Z</updated>
    <id>tag:github.com,2023-12-14:/lobehub/lobe-chat</id>
    <link href="https://github.com/lobehub/lobe-chat" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🤖 Lobe Chat - an open-source, high-performance chatbot framework that supports speech synthesis, multimodal, and extensible Function Call plugin system. Supports one-click free deployment of your private ChatGPT/LLM web application.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name=&#34;readme-top&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img height=&#34;120&#34; src=&#34;https://registry.npmmirror.com/@lobehub/assets-logo/1.0.0/files/assets/logo-3d.webp&#34;&gt; &#xA; &lt;img height=&#34;120&#34; src=&#34;https://gw.alipayobjects.com/zos/kitchen/qJ3l3EPsdW/split.svg?sanitize=true&#34;&gt; &#xA; &lt;img height=&#34;120&#34; src=&#34;https://registry.npmmirror.com/@lobehub/assets-emoji-anim/1.0.0/files/assets/robot.webp&#34;&gt; &#xA; &lt;h1&gt;Lobe Chat&lt;/h1&gt; &#xA; &lt;p&gt;LobeChat is an open-source, high-performance chatbot framework&lt;br&gt;that supports speech synthesis, multimodal, and extensible (&lt;a href=&#34;https://sspai.com/post/81986&#34;&gt;Function Call&lt;/a&gt;) plugin system. &lt;br&gt; Supports one-click free deployment of your private ChatGPT/LLM web application.&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;English&lt;/strong&gt; · &lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/README.zh-CN.md&#34;&gt;简体中文&lt;/a&gt; · &lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/CHANGELOG.md&#34;&gt;Changelog&lt;/a&gt; · &lt;a href=&#34;https://github.com/lobehub/lobe-chat/wiki&#34;&gt;Wiki&lt;/a&gt; · &lt;a href=&#34;https://github.com/lobehub/lobe-chat/issues&#34;&gt;Report Bug&lt;/a&gt; · &lt;a href=&#34;https://github.com/lobehub/lobe-chat/issues&#34;&gt;Request Feature&lt;/a&gt;&lt;/p&gt; &#xA; &lt;!-- SHIELD GROUP --&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/lobehub/lobe-chat/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/lobehub/lobe-chat?color=369eff&amp;amp;labelColor=black&amp;amp;logo=github&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/lobehub/lobe-chat&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/v/lobehub/lobe-chat?color=369eff&amp;amp;label=docker&amp;amp;labelColor=black&amp;amp;logo=docker&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://chat-preview.lobehub.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/website?down_message=offline&amp;amp;label=vercel&amp;amp;labelColor=black&amp;amp;logo=vercel&amp;amp;style=flat-square&amp;amp;up_message=online&amp;amp;url=https%3A%2F%2Fchat-preview.lobehub.com&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/AYFPHvv2jT&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1127171173982154893?color=5865F2&amp;amp;label=discord&amp;amp;labelColor=black&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/actions/workflows/lobehub/lobe-chat/test.yml&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/lobehub/lobe-chat/test.yml?label=test&amp;amp;labelColor=black&amp;amp;logo=githubactions&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/actions/workflows/lobehub/lobe-chat/release.yml&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/lobehub/lobe-chat/release.yml?label=release&amp;amp;labelColor=black&amp;amp;logo=githubactions&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lobehub/lobe-chat/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/release-date/lobehub/lobe-chat?labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/lobehub/lobe-chat/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/lobehub/lobe-chat?color=c4f042&amp;amp;labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lobehub/lobe-chat/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/lobehub/lobe-chat?color=8ae8ff&amp;amp;labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lobehub/lobe-chat/network/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/lobehub/lobe-chat?color=ffcb47&amp;amp;labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lobehub/lobe-chat/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/lobehub/lobe-chat?color=ff80eb&amp;amp;labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lobehub/lobe-chat/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/license/lobehub/lobe-chat?color=white&amp;amp;labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://opencollective.com/lobehub&#34; title=&#34;Become 🩷 LobeHub Sponsor&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Sponsor%20LobeHub-f04f88?logo=opencollective&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Share LobeChat Repository&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://x.com/intent/tweet?hashtags=chatbot%2CchatGPT%2CopenAI&amp;amp;text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.&amp;amp;url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-share%20on%20x-black?labelColor=black&amp;amp;logo=x&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://t.me/share/url%22?text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20%23chatbot%20%23chatGPT%20%23openAI&amp;amp;url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-share%20on%20telegram-black?labelColor=black&amp;amp;logo=telegram&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://api.whatsapp.com/send?text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat%20%23chatbot%20%23chatGPT%20%23openAI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-share%20on%20whatsapp-black?labelColor=black&amp;amp;logo=whatsapp&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.reddit.com/submit?title=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20%23chatbot%20%23chatGPT%20%23openAI&amp;amp;url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-share%20on%20reddit-black?labelColor=black&amp;amp;logo=reddit&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://service.weibo.com/share/share.php?sharesource=weibo&amp;amp;title=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20%23chatbot%20%23chatGPT%20%23openAI&amp;amp;url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-share%20on%20weibo-black?labelColor=black&amp;amp;logo=sinaweibo&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;sup&gt;Pioneering the new age of thinking and creating. Built for you, the Super Individual.&lt;/sup&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://gw.alipayobjects.com/zos/kitchen/RKnWrrfuMl/welcome.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt; &#xA; &lt;h4&gt;TOC&lt;/h4&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-getting-started--join-our-community&#34;&gt;👋🏻 Getting Started &amp;amp; Join Our Community&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-features&#34;&gt;✨ Features&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#%EF%B8%8F-performance&#34;&gt;⚡️ Performance&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-self-hosting&#34;&gt;🛳 Self Hosting&lt;/a&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#a-deploying-with-vercel-or-zeabur&#34;&gt;&lt;code&gt;A&lt;/code&gt; Deploying with Vercel or Zeabur&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#b-deploying-with-docker&#34;&gt;&lt;code&gt;B&lt;/code&gt; Deploying with Docker&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#environment-variable&#34;&gt;Environment Variable&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-ecosystem&#34;&gt;📦 Ecosystem&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-plugins&#34;&gt;🧩 Plugins&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#%EF%B8%8F-local-development&#34;&gt;⌨️ Local Development&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-contributing&#34;&gt;🤝 Contributing&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-sponsor&#34;&gt;🩷 Sponsor&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-more-products&#34;&gt;🔗 More Products&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;h4&gt;&lt;/h4&gt; &#xA; &lt;br&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;👋🏻 Getting Started &amp;amp; Join Our Community&lt;/h2&gt; &#xA;&lt;p&gt;Please be aware that LobeChat is currently under active development, and feedback is welcome for any &lt;a href=&#34;https://img.shields.io/github/issues/lobehub/lobe-chat.svg?style=flat&#34;&gt;issues&lt;/a&gt; encountered.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;a href=&#34;https://chat-preview.lobehub.com&#34;&gt;&lt;img src=&#34;https://img.shields.io/website?down_message=offline&amp;amp;label=try%20lobechat&amp;amp;labelColor=black&amp;amp;logo=vercel&amp;amp;style=for-the-badge&amp;amp;up_message=online&amp;amp;url=https%3A%2F%2Fchat-preview.lobehub.com&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;No installation or registration necessary! Visit our website to experience it firsthand.&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://discord.gg/AYFPHvv2jT&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/1127171173982154893?color=5865F2&amp;amp;label=discord&amp;amp;labelColor=black&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=for-the-badge&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT]&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Star Us&lt;/strong&gt;, You will receive all release notifications from GitHub without any delay ~ ⭐️&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://gw.alipayobjects.com/zos/kitchen/0hcO8QiU9c/star.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;amp;theme=dark&amp;amp;type=Date&#34;&gt; &#xA;  &lt;img width=&#34;100%&#34; src=&#34;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;amp;type=Date&#34;&gt; &#xA; &lt;/picture&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;✨ Features&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github-production-user-asset-6210df.s3.amazonaws.com/17870709/284072129-382bdf30-e3d6-4411-b5a0-249710b8ba08.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;&lt;code&gt;1&lt;/code&gt; Visual Model Support&lt;/h4&gt; &#xA;&lt;p&gt;LobeChat now supports OpenAI&#39;s latest &lt;a href=&#34;https://platform.openai.com/docs/guides/vision&#34;&gt;&lt;code&gt;gpt-4-vision&lt;/code&gt;&lt;/a&gt; model with visual recognition capabilities, a multimodal intelligence that can perceive visuals. Users can easily upload or drag and drop images into the dialogue box, and the agent will be able to recognize the content of the images and engage in intelligent conversation based on this, creating smarter and more diversified chat scenarios.&lt;/p&gt; &#xA;&lt;p&gt;This feature opens up new interactive methods, allowing communication to transcend text and include a wealth of visual elements. Whether it&#39;s sharing images in daily use or interpreting images within specific industries, the agent provides an outstanding conversational experience.&lt;/p&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github-production-user-asset-6210df.s3.amazonaws.com/17870709/284072124-c9853d8d-f1b5-44a8-a305-45ebc0f6d19a.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;&lt;code&gt;2&lt;/code&gt; TTS &amp;amp; STT Voice Speech&lt;/h4&gt; &#xA;&lt;p&gt;LobeChat supports Text-to-Speech (TTS) and Speech-to-Text (STT) technologies, enabling our application to convert text messages into clear voice outputs, allowing users to interact with our conversational agent as if they were talking to a real person. Users can choose from a variety of voices to pair with the agent.&lt;/p&gt; &#xA;&lt;p&gt;Moreover, TTS offers an excellent solution for those who prefer auditory learning or desire to receive information while busy. In LobeChat, we have meticulously selected a range of high-quality voice options (OpenAI Audio, Microsoft Edge Speech) to meet the needs of users from different regions and cultural backgrounds. Users can choose the voice that suits their personal preferences or specific scenarios, resulting in a personalized communication experience.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;In the process of implementing this feature, we found that there was no satisfactory TTS (Text-to-Speech) frontend library available on the market. As a result, we invested a lot of effort, including data conversion, audio progress management, and speech visualization, among other tasks.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT]&lt;/p&gt; &#xA; &lt;p&gt;Therefore, we decided to refine our implementation and make it open source, hoping to assist developers who wish to implement TTS. &lt;a href=&#34;https://github.com/lobehub/lobe-tts&#34;&gt;@lobehub/tts&lt;/a&gt; is a high-quality TTS toolkit developed in TypeScript, which supports usage both on the server-side and in the browser.&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Server-side:&lt;/strong&gt; With just 15 lines of code, you can achieve high-quality voice generation capabilities comparable to OpenAI&#39;s TTS service. It currently supports EdgeSpeechTTS, MicrosoftTTS, OpenAITTS, and OpenAISTT.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Browser-side:&lt;/strong&gt; It provides high-quality React Hooks and visual audio components, supporting common functions such as loading, playing, pausing, and dragging the timeline. Additionally, it offers a very rich set of capabilities for adjusting the audio track styles.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github-production-user-asset-6210df.s3.amazonaws.com/17870709/268670883-33c43a5c-a512-467e-855c-fa299548cce5.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;&lt;code&gt;3&lt;/code&gt; Function Calling Plugin System&lt;/h4&gt; &#xA;&lt;p&gt;The plugin ecosystem of LobeChat is a significant extension of its core functionalities, greatly enhancing the practicality and flexibility of ChatGPT. By leveraging plugins, ChatGPT can perform real-time information retrieval and processing, such as automatically fetching the latest news headlines to provide users with immediate and relevant information. Moreover, these plugins are not limited to news aggregation but can also extend to other practical functions, such as quick document retrieval, e-commerce platform data access, and various third-party services.&lt;/p&gt; &#xA;&lt;p&gt;&#xA; &lt;video controls src=&#34;https://github.com/lobehub/lobe-chat/assets/28616219/f29475a3-f346-4196-a435-41a6373ab9e2&#34; muted=&#34;false&#34;&gt;&lt;/video&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP]&lt;/p&gt; &#xA; &lt;p&gt;To aid developers in joining this ecosystem, we provide comprehensive development resources in the &lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-plugins&#34;&gt;🧩 Plugin System&lt;/a&gt; section. This includes detailed component development documentation, a fully-featured software development kit (SDK), and template files—all designed to simplify the development process and lower the barrier to entry for developers.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT]&lt;/p&gt; &#xA; &lt;p&gt;We welcome developers to use these resources to unleash their creativity and write feature-rich, user-friendly plugins. With collective efforts, we can continuously expand the boundaries of chat applications and explore a more intelligent and efficient creativity platform.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;!-- PLUGIN LIST --&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Official Plugin&lt;/th&gt; &#xA;   &lt;th&gt;Repository&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://chat-preview.lobehub.com/settings/agent&#34;&gt;Clock Time&lt;/a&gt;&lt;br&gt;&lt;sup&gt;By &lt;strong&gt;LobeHub&lt;/strong&gt; on &lt;strong&gt;2023-11-01&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lobehub/chat-plugin-clock-time&#34;&gt;lobehub/chat-plugin-clock-time&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Display a clock to show current time&lt;br&gt;&lt;code&gt;clock&lt;/code&gt; &lt;code&gt;time&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://chat-preview.lobehub.com/settings/agent&#34;&gt;Website Crawler&lt;/a&gt;&lt;br&gt;&lt;sup&gt;By &lt;strong&gt;LobeHub&lt;/strong&gt; on &lt;strong&gt;2023-08-17&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lobehub/chat-plugin-web-crawler&#34;&gt;lobehub/chat-plugin-web-crawler&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Extract content from web links&lt;br&gt;&lt;code&gt;web&lt;/code&gt; &lt;code&gt;content-crawler&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://chat-preview.lobehub.com/settings/agent&#34;&gt;Search Engine&lt;/a&gt;&lt;br&gt;&lt;sup&gt;By &lt;strong&gt;LobeHub&lt;/strong&gt; on &lt;strong&gt;2023-08-15&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lobehub/chat-plugin-search-engine&#34;&gt;lobehub/chat-plugin-search-engine&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Query search engine to get information&lt;br&gt;&lt;code&gt;web&lt;/code&gt; &lt;code&gt;search&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://chat-preview.lobehub.com/settings/agent&#34;&gt;Realtime Weather&lt;/a&gt;&lt;br&gt;&lt;sup&gt;By &lt;strong&gt;LobeHub&lt;/strong&gt; on &lt;strong&gt;2023-08-12&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lobehub/chat-plugin-realtime-weather&#34;&gt;lobehub/chat-plugin-realtime-weather&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Get realtime weather information&lt;br&gt;&lt;code&gt;weather&lt;/code&gt; &lt;code&gt;realtime&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;📊 Total plugins: &lt;a href=&#34;https://github.com/lobehub/lobe-chat-plugins&#34;&gt;&lt;kbd&gt;&lt;strong&gt;5&lt;/strong&gt;&lt;/kbd&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;!-- PLUGIN LIST --&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github-production-user-asset-6210df.s3.amazonaws.com/17870709/268670869-f1ffbf66-42b6-42cf-a937-9ce1f8328514.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;&lt;code&gt;4&lt;/code&gt; Agent Market&lt;/h4&gt; &#xA;&lt;p&gt;In the LobeChat Agent Marketplace, creators can discover a vibrant and innovative community that brings together a multitude of well-designed agents, which not only play an important role in work scenarios but also offer great convenience in learning processes. Our marketplace is not just a showcase platform but also a collaborative space. Here, everyone can contribute their wisdom and share the agents they have developed.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP]&lt;/p&gt; &#xA; &lt;p&gt;By &lt;a href=&#34;https://github.com/lobehub/lobe-chat-agents&#34;&gt;🤖/🏪 Submit Agents&lt;/a&gt;, you can easily submit your agent creations to our platform. Importantly, LobeChat has established a sophisticated automated internationalization (i18n) workflow, capable of seamlessly translating your agent into multiple language versions. This means that no matter what language your users speak, they can experience your agent without barriers.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT]&lt;/p&gt; &#xA; &lt;p&gt;We welcome all users to join this growing ecosystem and participate in the iteration and optimization of agents. Together, we can create more interesting, practical, and innovative agents, further enriching the diversity and practicality of the agent offerings.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;!-- AGENT LIST --&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Recent Submits&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://chat-preview.lobehub.com/market?agent=dream-psychoanalyst&#34;&gt;Dream Analyst&lt;/a&gt;&lt;br&gt;&lt;sup&gt;By &lt;strong&gt;&lt;a href=&#34;https://github.com/ghyghoo8&#34;&gt;ghyghoo8&lt;/a&gt;&lt;/strong&gt; on &lt;strong&gt;2023-12-13&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Input a dream and I will help you analyze it.&lt;br&gt;&lt;code&gt;dream&lt;/code&gt; &lt;code&gt;master&lt;/code&gt; &lt;code&gt;think&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://chat-preview.lobehub.com/market?agent=payroll-game&#34;&gt;Payroll Game&lt;/a&gt;&lt;br&gt;&lt;sup&gt;By &lt;strong&gt;&lt;a href=&#34;https://github.com/ghyghoo8&#34;&gt;ghyghoo8&lt;/a&gt;&lt;/strong&gt; on &lt;strong&gt;2023-12-13&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td&gt;In this salary negotiation game, you&#39;ll be facing the notorious &#39;Iron Rooster,&#39; a boss known for being tight-fisted. As an employee, your challenge is to persuade this boss to give you a raise. However, no matter how reasonable your arguments are, the &#39;Iron Rooster&#39; always finds a way to reject them. Get ready with your arguments for a clever and humorous showdown!&lt;br&gt;&lt;code&gt;game&lt;/code&gt; &lt;code&gt;boss&lt;/code&gt; &lt;code&gt;payroll&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://chat-preview.lobehub.com/market?agent=gradio-coding&#34;&gt;Python Coder Gradio&lt;/a&gt;&lt;br&gt;&lt;sup&gt;By &lt;strong&gt;&lt;a href=&#34;https://github.com/Igroshka&#34;&gt;Igroshka&lt;/a&gt;&lt;/strong&gt; on &lt;strong&gt;2023-12-12&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Python programmer experienced with Gradio for Hugging Face.&lt;br&gt;&lt;code&gt;programming&lt;/code&gt; &lt;code&gt;assistant&lt;/code&gt; &lt;code&gt;python&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://chat-preview.lobehub.com/market?agent=translate-eng-expert&#34;&gt;English Translation Expert&lt;/a&gt;&lt;br&gt;&lt;sup&gt;By &lt;strong&gt;&lt;a href=&#34;https://github.com/caolixiang&#34;&gt;caolixiang&lt;/a&gt;&lt;/strong&gt; on &lt;strong&gt;2023-12-12&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Perfect Translation&lt;br&gt;&lt;code&gt;translate&lt;/code&gt; &lt;code&gt;expert&lt;/code&gt; &lt;code&gt;english&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;📊 Total agents: &lt;a href=&#34;https://github.com/lobehub/lobe-chat-agents&#34;&gt;&lt;kbd&gt;&lt;strong&gt;63&lt;/strong&gt;&lt;/kbd&gt; &lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;!-- AGENT LIST --&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://gw.alipayobjects.com/zos/kitchen/69x6bllkX3/pwa.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;&lt;code&gt;5&lt;/code&gt; Progress Web App&lt;/h4&gt; &#xA;&lt;p&gt;We deeply understand the importance of providing a seamless experience for users in today&#39;s multi-device environment. Therefore, we have adopted Progressive Web Application (&lt;a href=&#34;https://support.google.com/chrome/answer/9658361&#34;&gt;PWA&lt;/a&gt;) technology, a modern web technology that elevates web applications to an experience close to that of native apps.&lt;/p&gt; &#xA;&lt;p&gt;Through PWA, LobeChat can offer a highly optimized user experience on both desktop and mobile devices while maintaining its lightweight and high-performance characteristics. Visually and in terms of feel, we have also meticulously designed the interface to ensure it is indistinguishable from native apps, providing smooth animations, responsive layouts, and adapting to different device screen resolutions.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;If you are unfamiliar with the installation process of PWA, you can add LobeChat as your desktop application (also applicable to mobile devices) by following these steps:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Launch the Chrome or Edge browser on your computer.&lt;/li&gt; &#xA;  &lt;li&gt;Visit the LobeChat webpage.&lt;/li&gt; &#xA;  &lt;li&gt;In the upper right corner of the address bar, click on the &lt;kbd&gt;Install&lt;/kbd&gt; icon.&lt;/li&gt; &#xA;  &lt;li&gt;Follow the instructions on the screen to complete the PWA Installation.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://gw.alipayobjects.com/zos/kitchen/R441AuFS4W/mobile.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;&lt;code&gt;6&lt;/code&gt; Mobile Device Adaptation&lt;/h4&gt; &#xA;&lt;p&gt;We have carried out a series of optimization designs for mobile devices to enhance the user&#39;s mobile experience. Currently, we are iterating on the mobile user experience to achieve smoother and more intuitive interactions. If you have any suggestions or ideas, we welcome you to provide feedback through GitHub Issues or Pull Requests.&lt;/p&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://gw.alipayobjects.com/zos/kitchen/pvus1lo%26Z7/darkmode.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;&lt;code&gt;7&lt;/code&gt; Theme Mode Selection&lt;/h4&gt; &#xA;&lt;p&gt;As a design-engineering-oriented application, LobeChat places great emphasis on users&#39; personalized experiences, hence introducing flexible and diverse theme modes, including a light mode for daytime and a dark mode for nighttime. Beyond switching theme modes, a range of color customization options allow users to adjust the application&#39;s theme colors according to their preferences. Whether it&#39;s a desire for a sober dark blue, a lively peach pink, or a professional gray-white, users can find their style of color choices in LobeChat.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP]&lt;/p&gt; &#xA; &lt;p&gt;The default configuration can intelligently recognize the user&#39;s system color mode and automatically switch themes to ensure a consistent visual experience with the operating system. For users who like to manually control details, LobeChat also offers intuitive setting options and a choice between chat bubble mode and document mode for conversation scenarios.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h4&gt;What&#39;s more&lt;/h4&gt; &#xA;&lt;p&gt;Beside these features, LobeChat also have much better basic technique underground:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 💨 &lt;strong&gt;Quick Deployment&lt;/strong&gt;: Using the Vercel platform or docker image, you can deploy with just one click and complete the process within 1 minute without any complex configuration.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 🌐 &lt;strong&gt;Custom Domain&lt;/strong&gt;: If users have their own domain, they can bind it to the platform for quick access to the dialogue agent from anywhere.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 🔒 &lt;strong&gt;Privacy Protection&lt;/strong&gt;: All data is stored locally in the user&#39;s browser, ensuring user privacy.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 💎 &lt;strong&gt;Exquisite UI Design&lt;/strong&gt;: With a carefully designed interface, it offers an elegant appearance and smooth interaction. It supports light and dark themes and is mobile-friendly. PWA support provides a more native-like experience.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 🗣️ &lt;strong&gt;Smooth Conversation Experience&lt;/strong&gt;: Fluid responses ensure a smooth conversation experience. It fully supports Markdown rendering, including code highlighting, LaTex formulas, Mermaid flowcharts, and more.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;✨ more features will be added when LobeChat evolve.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;You can find our upcoming &lt;a href=&#34;https://github.com/lobehub/lobe-chat/projects&#34;&gt;Roadmap&lt;/a&gt; plans in the Projects section.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;⚡️ Performance&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;The complete list of reports can be found in the &lt;a href=&#34;https://github.com/lobehub/lobe-chat/wiki/Lighthouse&#34;&gt;📘 Lighthouse Reports&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Desktop&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Mobile&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/lighthouse/lighthouse/chat/desktop/pagespeed.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/lighthouse/lighthouse/chat/mobile/pagespeed.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://lobehub.github.io/lobe-chat/lighthouse/chat/desktop/chat_preview_lobehub_com_chat.html&#34;&gt;📑 Lighthouse Report&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://lobehub.github.io/lobe-chat/lighthouse/chat/mobile/chat_preview_lobehub_com_chat.html&#34;&gt;📑 Lighthouse Report&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;🛳 Self Hosting&lt;/h2&gt; &#xA;&lt;p&gt;LobeChat provides Self-Hosted Version with Vercel and &lt;a href=&#34;https://hub.docker.com/r/lobehub/lobe-chat&#34;&gt;Docker Image&lt;/a&gt;. This allows you to deploy your own chatbot within a few minutes without any prior knowledge.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;A&lt;/code&gt; Deploying with Vercel or Zeabur&lt;/h3&gt; &#xA;&lt;p&gt;If you want to deploy this service yourself on either Vercel or Zeabur, you can follow these steps:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Prepare your &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;OpenAI API Key&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Click the button below to start deployment: Log in directly with your GitHub account, and remember to fill in the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;(required) and &lt;code&gt;ACCESS_CODE&lt;/code&gt; (recommended) on the environment variable section.&lt;/li&gt; &#xA; &lt;li&gt;After deployment, you can start using it.&lt;/li&gt; &#xA; &lt;li&gt;Bind a custom domain (optional): The DNS of the domain assigned by Vercel is polluted in some areas; binding a custom domain can connect directly.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Deploy with Vercel&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Deploy with Zeabur&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat&amp;amp;env=OPENAI_API_KEY&amp;amp;envDescription=Find%20your%20OpenAI%20API%20Key%20by%20click%20the%20right%20Learn%20More%20button.&amp;amp;envLink=https%3A%2F%2Fplatform.openai.com%2Faccount%2Fapi-keys&amp;amp;project-name=lobe-chat&amp;amp;repository-name=lobe-chat&#34;&gt;&lt;img src=&#34;https://vercel.com/button&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://zeabur.com/templates/VZGGTI&#34;&gt;&lt;img src=&#34;https://zeabur.com/button.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;h4&gt;Keep Updated&lt;/h4&gt; &#xA;&lt;p&gt;If you have deployed your own project following the one-click deployment steps in the README, you might encounter constant prompts indicating &#34;updates available.&#34; This is because Vercel defaults to creating a new project instead of forking this one, resulting in an inability to detect updates accurately.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP]&lt;/p&gt; &#xA; &lt;p&gt;We suggest you redeploy using the following steps, &lt;a href=&#34;https://github.com/lobehub/lobe-chat/wiki/Upstream-Sync&#34;&gt;📘 Maintaining Updates with LobeChat Self-Deployment&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;&lt;code&gt;B&lt;/code&gt; Deploying with Docker&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/lobehub/lobe-chat&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/v/lobehub/lobe-chat?color=369eff&amp;amp;label=docker&amp;amp;labelColor=black&amp;amp;logo=docker&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/lobehub/lobe-chat&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/image-size/lobehub/lobe-chat?color=369eff&amp;amp;labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/lobehub/lobe-chat&#34;&gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/lobehub/lobe-chat?color=45cc11&amp;amp;labelColor=black&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;We provide a Docker image for deploying the LobeChat service on your own private device. Use the following command to start the LobeChat service:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-fish&#34;&gt;$ docker run -d -p 3210:3210 \&#xA;  -e OPENAI_API_KEY=sk-xxxx \&#xA;  -e ACCESS_CODE=lobe66 \&#xA;  lobehub/lobe-chat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP]&lt;/p&gt; &#xA; &lt;p&gt;If you need to use the OpenAI service through a proxy, you can configure the proxy address using the &lt;code&gt;OPENAI_PROXY_URL&lt;/code&gt; environment variable:&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-fish&#34;&gt;$ docker run -d -p 3210:3210 \&#xA;  -e OPENAI_API_KEY=sk-xxxx \&#xA;  -e OPENAI_PROXY_URL=https://api-proxy.com/v1 \&#xA;  -e ACCESS_CODE=lobe66 \&#xA;  lobehub/lobe-chat&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;For detailed instructions on deploying with Docker, please refer to the &lt;a href=&#34;https://github.com/lobehub/lobe-chat/wiki/Docker-Deployment&#34;&gt;📘 Docker Deployment Guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;Environment Variable&lt;/h3&gt; &#xA;&lt;p&gt;This project provides some additional configuration items set with environment variables:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Environment Variable&lt;/th&gt; &#xA;   &lt;th&gt;Required&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Example&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;This is the API key you apply on the OpenAI account page&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;sk-xxxxxx...xxxxxx&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;OPENAI_PROXY_URL&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;If you manually configure the OpenAI interface proxy, you can use this configuration item to override the default OpenAI API request base URL&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;https://api.chatanywhere.cn/v1&lt;/code&gt;&lt;br&gt;The default value is&lt;br&gt;&lt;code&gt;https://api.openai.com/v1&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;OPENAI_FUNCTION_REGIONS&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;When you deploy Lobe-Chat using Vercel and need to specify the region for the Edge Function that handles requests to the OpenAI API, you can use this configuration. The value should be a comma-separated array of strings.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;iad1,sfo1&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;ACCESS_CODE&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;Add a password to access this service; you can set a long password to avoid leaking&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;awCTe)re_r74&lt;/code&gt; or &lt;code&gt;rtrt_ewee3@09!&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;The complete list of environment variables can be found in the &lt;a href=&#34;https://github.com/lobehub/lobe-chat/wiki/Environment-Variable&#34;&gt;📘 Environment Variables&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;📦 Ecosystem&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;NPM&lt;/th&gt; &#xA;   &lt;th&gt;Repository&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Version&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.npmjs.com/package/@lobehub/ui&#34;&gt;@lobehub/ui&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lobehub/lobe-ui&#34;&gt;lobehub/lobe-ui&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Lobe UI is an open-source UI component library dedicated to building AIGC web applications.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.npmjs.com/package/@lobehub/ui&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/@lobehub/ui?color=369eff&amp;amp;labelColor=black&amp;amp;logo=npm&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.npmjs.com/package/@lobehub/tts&#34;&gt;@lobehub/tts&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lobehub/lobe-tts&#34;&gt;lobehub/lobe-tts&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Lobe TTS is a high-quality &amp;amp; reliable TTS/STT React Hooks library&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.npmjs.com/package/@lobehub/tts&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/@lobehub/tts?color=369eff&amp;amp;labelColor=black&amp;amp;logo=npm&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.npmjs.com/package/@lobehub/lint&#34;&gt;@lobehub/lint&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lobehub/lobe-lint&#34;&gt;lobehub/lobe-lint&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;LobeLint provides configurations for ESlint, Stylelint, Commitlint, Prettier, Remark, and Semantic Release for LobeHub.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.npmjs.com/package/@lobehub/lint&#34;&gt;&lt;img src=&#34;https://img.shields.io/npm/v/@lobehub/lint?color=369eff&amp;amp;labelColor=black&amp;amp;logo=npm&amp;amp;logoColor=white&amp;amp;style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;@lobehub/assets&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lobehub/lobe-assets&#34;&gt;lobehub/assets&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Logo assets, favicons, webfonts for LobeHub.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;🧩 Plugins&lt;/h2&gt; &#xA;&lt;p&gt;Plugins provide a means to extend the &lt;a href=&#34;https://sspai.com/post/81986&#34;&gt;Function Calling&lt;/a&gt; capabilities of LobeChat. They can be used to introduce new function calls and even new ways to render message results. If you are interested in plugin development, please refer to our &lt;a href=&#34;https://github.com/lobehub/lobe-chat/wiki/Plugin-Development&#34;&gt;📘 Plugin Development Guide&lt;/a&gt; in the Wiki.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lobehub/lobe-chat-plugins&#34;&gt;lobe-chat-plugins&lt;/a&gt;: This is the plugin index for LobeChat. It accesses index.json from this repository to display a list of available plugins for LobeChat to the user.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lobehub/chat-plugin-template&#34;&gt;chat-plugin-template&lt;/a&gt;: This is the plugin template for LobeChat plugin development.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lobehub/chat-plugin-sdk&#34;&gt;@lobehub/chat-plugin-sdk&lt;/a&gt;: The LobeChat Plugin SDK assists you in creating exceptional chat plugins for Lobe Chat.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lobehub/chat-plugins-gateway&#34;&gt;@lobehub/chat-plugins-gateway&lt;/a&gt;: The LobeChat Plugins Gateway is a backend service that provides a gateway for LobeChat plugins. We deploy this service using Vercel. The primary API POST /api/v1/runner is deployed as an Edge Function.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE]&lt;/p&gt; &#xA; &lt;p&gt;The plugin system is currently undergoing major development. You can learn more in the following issues:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;[x] &lt;a href=&#34;https://github.com/lobehub/lobe-chat/issues/73&#34;&gt;&lt;strong&gt;Plugin Phase 1&lt;/strong&gt;&lt;/a&gt;: Implement separation of the plugin from the main body, split the plugin into an independent repository for maintenance, and realize dynamic loading of the plugin.&lt;/li&gt; &#xA;  &lt;li&gt;[x] &lt;a href=&#34;https://github.com/lobehub/lobe-chat/issues/97&#34;&gt;&lt;strong&gt;Plugin Phase 2&lt;/strong&gt;&lt;/a&gt;: The security and stability of the plugin&#39;s use, more accurately presenting abnormal states, the maintainability of the plugin architecture, and developer-friendly.&lt;/li&gt; &#xA;  &lt;li&gt;[ ] &lt;a href=&#34;https://github.com/lobehub/lobe-chat/issues/149&#34;&gt;&lt;strong&gt;Plugin Phase 3&lt;/strong&gt;&lt;/a&gt;: Higher-level and more comprehensive customization capabilities, support for plugin authentication, and examples.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;⌨️ Local Development&lt;/h2&gt; &#xA;&lt;p&gt;You can use GitHub Codespaces for online development:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://codespaces.new/lobehub/lobe-chat&#34;&gt;&lt;img src=&#34;https://github.com/codespaces/badge.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Or clone it for local development:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://bun.sh&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-speedup%20with%20bun-black?logo=bun&amp;amp;style=for-the-badge&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-fish&#34;&gt;$ git clone https://github.com/lobehub/lobe-chat.git&#xA;$ cd lobe-chat&#xA;$ bun install&#xA;$ bun dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;🤝 Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions of all types are more than welcome; if you are interested in contributing code, feel free to check out our GitHub &lt;a href=&#34;https://github.com/lobehub/lobe-chat/issues&#34;&gt;Issues&lt;/a&gt; and &lt;a href=&#34;https://github.com/lobehub/lobe-chat/projects&#34;&gt;Projects&lt;/a&gt; to get stuck in to show us what you’re made of.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/lobehub/lobe-chat/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%AF_pr_welcome-%E2%86%92-ffcb47?labelColor=black&amp;amp;style=for-the-badge&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lobehub/lobe-chat-agents&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%96/%F0%9F%8F%AA_submit_agent-%E2%86%92-c4f042?labelColor=black&amp;amp;style=for-the-badge&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lobehub/lobe-chat-plugins&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A7%A9/%F0%9F%8F%AA_submit_plugin-%E2%86%92-95f3d9?labelColor=black&amp;amp;style=for-the-badge&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;a href=&#34;https://github.com/lobehub/lobe-chat/graphs/contributors&#34; target=&#34;_blank&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;tbody&gt;&#xA;   &lt;tr&gt; &#xA;    &lt;th colspan=&#34;2&#34;&gt; &lt;br&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=lobehub/lobe-chat&#34;&gt;&lt;br&gt;&lt;br&gt; &lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt; &#xA;     &lt;picture&gt; &#xA;      &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=active&amp;amp;period=past_28_days&amp;amp;owner_id=131470832&amp;amp;repo_ids=643445235&amp;amp;image_size=2x3&amp;amp;color_scheme=dark&#34;&gt; &#xA;      &lt;img src=&#34;https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=active&amp;amp;period=past_28_days&amp;amp;owner_id=131470832&amp;amp;repo_ids=643445235&amp;amp;image_size=2x3&amp;amp;color_scheme=light&#34;&gt; &#xA;     &lt;/picture&gt; &lt;/td&gt; &#xA;    &lt;td rowspan=&#34;2&#34;&gt; &#xA;     &lt;picture&gt; &#xA;      &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://next.ossinsight.io/widgets/official/compose-org-participants-growth/thumbnail.png?activity=active&amp;amp;period=past_28_days&amp;amp;owner_id=131470832&amp;amp;repo_ids=643445235&amp;amp;image_size=4x7&amp;amp;color_scheme=dark&#34;&gt; &#xA;      &lt;img src=&#34;https://next.ossinsight.io/widgets/official/compose-org-participants-growth/thumbnail.png?activity=active&amp;amp;period=past_28_days&amp;amp;owner_id=131470832&amp;amp;repo_ids=643445235&amp;amp;image_size=4x7&amp;amp;color_scheme=light&#34;&gt; &#xA;     &lt;/picture&gt; &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td&gt; &#xA;     &lt;picture&gt; &#xA;      &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=new&amp;amp;period=past_28_days&amp;amp;owner_id=131470832&amp;amp;repo_ids=643445235&amp;amp;image_size=2x3&amp;amp;color_scheme=dark&#34;&gt; &#xA;      &lt;img src=&#34;https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=new&amp;amp;period=past_28_days&amp;amp;owner_id=131470832&amp;amp;repo_ids=643445235&amp;amp;image_size=2x3&amp;amp;color_scheme=light&#34;&gt; &#xA;     &lt;/picture&gt; &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt;&#xA; &lt;/table&gt; &lt;/a&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;🩷 Sponsor&lt;/h2&gt; &#xA;&lt;p&gt;Every bit counts and your one-time donation sparkles in our galaxy of support! You&#39;re a shooting star, making a swift and bright impact on our journey. Thank you for believing in us – your generosity guides us toward our mission, one brilliant flash at a time.&lt;/p&gt; &#xA;&lt;a href=&#34;https://opencollective.com/lobehub&#34; target=&#34;_blank&#34;&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://readme-wizard.lobehub.com/api/sponsor?themeMode=dark&#34;&gt; &#xA;  &lt;img src=&#34;https://readme-wizard.lobehub.com/api/sponsor&#34;&gt; &#xA; &lt;/picture&gt; &lt;/a&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;🔗 More Products&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/lobehub/sd-webui-lobe-theme&#34;&gt;🤯 Lobe Theme&lt;/a&gt;:&lt;/strong&gt; The modern theme for Stable Diffusion WebUI, exquisite interface design, highly customizable UI, and efficiency-boosting features.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/lobehub/lobe-commit/tree/master/packages/lobe-i18n&#34;&gt;🌏 Lobe i18n&lt;/a&gt; :&lt;/strong&gt; Lobe i18n is an automation tool for the i18n (internationalization) translation process, powered by ChatGPT. It supports features such as automatic splitting of large files, incremental updates, and customization options for the OpenAI model, API proxy, and temperature.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/lobehub/lobe-commit/tree/master/packages/lobe-commit&#34;&gt;💌 Lobe Commit&lt;/a&gt;:&lt;/strong&gt; Lobe Commit is a CLI tool that leverages Langchain/ChatGPT to generate Gitmoji-based commit messages.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;right&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;&lt;h4&gt;📝 License&lt;/h4&gt;&lt;/summary&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://app.fossa.com/projects/git%2Bgithub.com%2Flobehub%2Flobe-chat&#34;&gt;&lt;img src=&#34;https://app.fossa.com/api/projects/git%2Bgithub.com%2Flobehub%2Flobe-chat.svg?type=large&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;Copyright © 2023 &lt;a href=&#34;https://github.com/lobehub&#34;&gt;LobeHub&lt;/a&gt;. &lt;br&gt; This project is &lt;a href=&#34;https://raw.githubusercontent.com/lobehub/lobe-chat/main/LICENSE&#34;&gt;MIT&lt;/a&gt; licensed.&lt;/p&gt; &#xA;&lt;!-- LINK GROUP --&gt;</summary>
  </entry>
  <entry>
    <title>llmware-ai/llmware</title>
    <updated>2023-12-14T01:25:50Z</updated>
    <id>tag:github.com,2023-12-14:/llmware-ai/llmware</id>
    <link href="https://github.com/llmware-ai/llmware" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Providing enterprise-grade LLM-based development framework, tools, and fine-tuned models.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;llmware&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.9_%7C_3.10%7C_3.11-blue?color=blue&#34; alt=&#34;Static Badge&#34;&gt; &lt;img src=&#34;https://img.shields.io/pypi/v/llmware?color=blue&#34; alt=&#34;PyPI - Version&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;llmware&lt;/code&gt; is a unified, open, extensible framework for LLM-based application patterns including Retrieval Augmented Generation (RAG). This project provides a comprehensive set of tools that anyone can use – from beginner to the most sophisticated AI developer – to rapidly build industrial-grade enterprise LLM-based applications. &lt;em&gt;Key differentiators include: source citation for Q &amp;amp; A scenarios, fact checking, and other guardrails for model hallucination&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;With &lt;code&gt;llmware&lt;/code&gt;, our goal is to contribute to and help catalyze an open community around the new combination of open, extensible technologies being assembled to accomplish fact-based generative workflows.&lt;/p&gt; &#xA;&lt;h2&gt;🎯 Key features&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;llmware&lt;/code&gt; is an integrated framework comprised of four major components:&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;&lt;u&gt;Retrieval&lt;/u&gt;: Assemble fact-sets &lt;/b&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;A comprehensive set of querying methods: semantic, text, and hybrid retrieval with integrated metadata.&lt;/li&gt; &#xA;  &lt;li&gt;Ranking and filtering strategies to enable semantic search and rapid retrieval of information.&lt;/li&gt; &#xA;  &lt;li&gt;Web scrapers, Wikipedia integration, and Yahoo Finance API integration as additional tools to assemble fact-sets for generation.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;&lt;u&gt;Prompt&lt;/u&gt;: Tools for sophisticated generative scenarios &lt;/b&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Connect Models:&lt;/strong&gt; Open interface designed to support AI21, Ai Bloks READ-GPT, Anthropic, Cohere, HuggingFace Generative models, llmware BLING and DRAGON models, OpenAI.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Prepare Sources:&lt;/strong&gt; Tools for packaging and tracking a wide range of materials into model context window sizes. Sources include files, websites, audio, AWS Transcribe transcripts, Wikipedia and Yahoo Finance.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Prompt Catalog:&lt;/strong&gt; Dynamically configurable prompts to experiment with multiple models without any change in the code.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Post Processing:&lt;/strong&gt; a full set of metadata and tools for evidence verification, classification of a response, and fact-checking.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Human in the Loop:&lt;/strong&gt; Ability to enable user ratings, feedback, and corrections of AI responses.&lt;/li&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Auditability:&lt;/strong&gt; A flexible state mechanism to capture, track, analyze and audit the LLM prompt lifecycle&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;&lt;u&gt;Vector Embeddings&lt;/u&gt;: swappable embedding models and vector databases&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Custom trained sentence transformer embedding models and support for embedding models from Cohere, Google, HuggingFace Embedding models, and OpenAI.&lt;/li&gt; &#xA;  &lt;li&gt;Mix-and-match among multiple options to find the right solution for any particular application.&lt;/li&gt; &#xA;  &lt;li&gt;Out-of-the-box support for 3 vector databases - Milvus, FAISS, and Pinecone.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;&lt;u&gt;Parsing and Text Chunking&lt;/u&gt;: Prepare your data for RAG&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Parsers for: PDF, PowerPoint, Word, Excel, HTML, Text, WAV, AWS Transcribe transcripts.&lt;/li&gt; &#xA;  &lt;li&gt;A complete set of text-chunking tools to separate information and associated metadata to a consistent block format.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;h4&gt;📚 Explore &lt;a href=&#34;https://github.com/llmware-ai/llmware/raw/main/examples/README.md&#34;&gt;additional llmware capabilities&lt;/a&gt; and 🎬 Check out these videos on how to quickly get started with RAG:&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0naqpH93eEU&#34;&gt;Fast Start to RAG with LLMWare Open Source Library&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=tAGz6yR14lw&#34;&gt;Use Retrieval Augmented Generation (RAG) without a Database&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=8aV5p3tErP0&#34;&gt;Use small LLMs for RAG for Contract Analysis (feat. LLMWare)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=JjgqOZ2v5oU&#34;&gt;RAG using CPU-based (No-GPU required) Hugging Face Models with LLMWare on your laptop&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🌱 Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;1. Install llmware:&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install llmware&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 -m pip install llmware&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/llmware-ai/llmware/main/#%EF%B8%8F-working-with-the-llmware-github-repository&#34;&gt;Working with llmware&lt;/a&gt; for other options to get up and running.&lt;/p&gt; &#xA;&lt;h3&gt;2. MongoDB and Milvus&lt;/h3&gt; &#xA;&lt;p&gt;MongoDB and Milvus are optional and used to provide production-grade database and vector embedding capabilities. The fastest way to get started is to use the provided Docker Compose file which takes care of running them both:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -o docker-compose.yaml https://raw.githubusercontent.com/llmware-ai/llmware/main/docker-compose.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and then run the containers:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose up -d&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Not ready to install MongoDB or Milvus? Check out what you can do without them in our &lt;a href=&#34;https://github.com/llmware-ai/llmware/raw/main/examples/README.md#using-llmware-without-mongodb-or-an-embedding-database&#34;&gt;examples section&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/llmware-ai/llmware/main/#%EF%B8%8F-alternate-options-for-running-mongodb-and-milvus&#34;&gt;Running MongoDB and Milvus&lt;/a&gt; for other options to get up and running with these optional dependencies.&lt;/p&gt; &#xA;&lt;h3&gt;3. 🔥 Start coding - Quick Start For RAG 🔥&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# This example demonstrates Retrieval Augmented Retrieval (RAG):&#xA;import os&#xA;from llmware.library import Library&#xA;from llmware.retrieval import Query&#xA;from llmware.prompts import Prompt&#xA;from llmware.setup import Setup&#xA;&#xA;# Update this value with your own API Key, either by setting the env var or editing it directly here:&#xA;openai_api_key = os.environ[&#34;OPENAI_API_KEY&#34;]&#xA;&#xA;# A self-contained end-to-end example of RAG&#xA;def end_to_end_rag():&#xA;    &#xA;    # Create a library called &#34;Agreements&#34;, and load it with llmware sample files&#xA;    print (f&#34;\n &amp;gt; Creating library &#39;Agreements&#39;...&#34;)&#xA;    library = Library().create_new_library(&#34;Agreements&#34;)&#xA;    sample_files_path = Setup().load_sample_files()&#xA;    library.add_files(os.path.join(sample_files_path,&#34;Agreements&#34;))&#xA;&#xA;    # Create vector embeddings for the library using the &#34;industry-bert-contracts model and store them in Milvus&#xA;    print (f&#34;\n &amp;gt; Generating vector embeddings using embedding model: &#39;industry-bert-contracts&#39;...&#34;)&#xA;    library.install_new_embedding(embedding_model_name=&#34;industry-bert-contracts&#34;, vector_db=&#34;milvus&#34;)&#xA;&#xA;    # Perform a semantic search against our library.  This will gather evidence to be used in the LLM prompt&#xA;    print (f&#34;\n &amp;gt; Performing a semantic query...&#34;)&#xA;    os.environ[&#34;TOKENIZERS_PARALLELISM&#34;] = &#34;false&#34; # Avoid a HuggingFace tokenizer warning&#xA;    query_results = Query(library).semantic_query(&#34;Termination&#34;, result_count=20)&#xA;&#xA;    # Create a new prompter using the GPT-4 and add the query_results captured above&#xA;    prompt_text = &#34;Summarize the termination provisions&#34;&#xA;    print (f&#34;\n &amp;gt; Prompting LLM with &#39;{prompt_text}&#39;&#34;)&#xA;    prompter = Prompt().load_model(&#34;gpt-4&#34;, api_key=openai_api_key)&#xA;    sources = prompter.add_source_query_results(query_results)&#xA;&#xA;    # Prompt the LLM with the sources and a query string&#xA;    responses = prompter.prompt_with_source(prompt_text, prompt_name=&#34;summarize_with_bullets&#34;)&#xA;    for response in responses:&#xA;        print (&#34;\n &amp;gt; LLM response\n&#34; + response[&#34;llm_response&#34;])&#xA;    &#xA;    # Finally, generate a CSV report that can be shared&#xA;    print (f&#34;\n &amp;gt; Generating CSV report...&#34;)&#xA;    report_data = prompter.send_to_human_for_review()&#xA;    print (&#34;File: &#34; + report_data[&#34;report_fp&#34;] + &#34;\n&#34;)&#xA;&#xA;end_to_end_rag()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Response from end-to-end RAG example&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; python examples/rag_with_openai.py&#xA;&#xA; &amp;gt; Creating library &#39;Agreements&#39;...&#xA;&#xA; &amp;gt; Generating vector embeddings using embedding model: &#39;industry-bert-contracts&#39;...&#xA;&#xA; &amp;gt; Performing a semantic query...&#xA;&#xA; &amp;gt; Prompting LLM with &#39;Summarize the termination provisions&#39;&#xA;&#xA; &amp;gt; LLM response&#xA;- Employment period ends on the first occurrence of either the 6th anniversary of the effective date or a company sale.&#xA;- Early termination possible as outlined in sections 3.1 through 3.4.&#xA;- Employer can terminate executive&#39;s employment under section 3.1 anytime without cause, with at least 30 days&#39; prior written notice.&#xA;- If notice is given, the executive is allowed to seek other employment during the notice period.&#xA;&#xA; &amp;gt; Generating CSV report...&#xA;File: /Users/llmware/llmware_data/prompt_history/interaction_report_Fri Sep 29 12:07:42 2023.csv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;📚 See 20+ &lt;a href=&#34;https://github.com/llmware-ai/llmware/raw/main/examples/README.md&#34;&gt;llmware examples&lt;/a&gt; for more RAG examples and other code samples and ideas.&lt;/h4&gt; &#xA;&lt;h3&gt;4. Accessing LLMs and setting-up API keys &amp;amp; secrets&lt;/h3&gt; &#xA;&lt;p&gt;To get started with a proprietary model, you need to provide your own API Keys. If you don&#39;t yet have one, more information can be found at: &lt;a href=&#34;https://docs.ai21.com/docs/quickstart&#34;&gt;AI21&lt;/a&gt;, &lt;a href=&#34;https://www.aibloks.com/contact-us&#34;&gt;Ai Bloks&lt;/a&gt;, &lt;a href=&#34;https://docs.anthropic.com/claude/reference/getting-started-with-the-api&#34;&gt;Anthropic&lt;/a&gt;, &lt;a href=&#34;https://cohere.com/&#34;&gt;Cohere&lt;/a&gt;, &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/generative-ai/start/quickstarts/api-quickstart&#34;&gt;Google&lt;/a&gt;, &lt;a href=&#34;https://help.openai.com/en/collections/3675940-getting-started-with-openai-api&#34;&gt;OpenAI&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;API keys and secrets for models, aws, and pinecone can be set-up for use in environment variables or managed however you prefer.&lt;/p&gt; &#xA;&lt;p&gt;You can also access the &lt;code&gt;llmware&lt;/code&gt; public model repository which includes out-of-the-box custom trained sentence transformer embedding models fine-tuned for the following industries: Insurance, Contracts, Asset Management, SEC. These domain specific models along with llmware&#39;s generative BLING model series (&#34;Best Little Instruction-following No-GPU-required&#34;) and DRAGON model series (&#34;Delivering RAG on ...&#34;) are available at &lt;a href=&#34;https://huggingface.co/llmware&#34;&gt;llmware on Huggingface&lt;/a&gt;. Explore using the model repository and the &lt;code&gt;llmware&lt;/code&gt; Huggingface integration in &lt;a href=&#34;https://github.com/llmware-ai/llmware/raw/main/examples/README.md&#34;&gt;llmware examples&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;🔹 Alternate options for running MongoDB and Milvus&lt;/h2&gt; &#xA;&lt;p&gt;There are several options for getting MongoDB running&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;🐳 A. Run mongo container with docker &lt;/b&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d -p 27017:27017  -v mongodb-volume:/data/db --name=mongodb mongo:latest&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;🐳 B. Run container with docker compose &lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt;Create a &lt;em&gt;docker-compose.yaml&lt;/em&gt; file with the content:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;version: &#34;3&#34;&#xA;&#xA;services:&#xA;  mongodb:&#xA;    container_name: mongodb&#xA;    image: &#39;mongo:latest&#39;&#xA;    volumes:&#xA;      - mongodb-volume:/data/db&#xA;    ports:&#xA;      - &#39;27017:27017&#39;&#xA;&#xA;volumes:&#xA;    llmware-mongodb:&#xA;      driver: local&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;and then run:&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker compose up&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;📖 C. Install MongoDB natively &lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt;See the &lt;a href=&#34;https://www.mongodb.com/docs/manual/installation/&#34;&gt;Official MongoDB Installation Guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;🔗 D. Connect to an existing MongoDB deployment &lt;/b&gt;&lt;/summary&gt; &#xA; &lt;p&gt;You can connect to an existing MongoDB deployment by setting the connection string to the environment variable, &lt;code&gt;COLLECTION_DB_URI&lt;/code&gt;. See the example script, &lt;a href=&#34;https://github.com/llmware-ai/llmware/raw/main/examples/using_mongo_atlas.py&#34;&gt;Using Mongo Atlas&lt;/a&gt;, for detailed information on how to use Mongo Atlas as the NoSQL and/or Vector Database for &lt;code&gt;llmware&lt;/code&gt;.&lt;/p&gt; &#xA; &lt;p&gt;Additional information on finding and formatting connection strings can be found in the &lt;a href=&#34;https://www.mongodb.com/docs/manual/reference/connection-string/&#34;&gt;MongoDB Connection Strings Documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;✍️ Working with the llmware Github repository&lt;/h2&gt; &#xA;&lt;p&gt;The llmware repo can be pulled locally to get access to all the examples, or to work directly with the latest version of the llmware code.&lt;/p&gt; &#xA;&lt;h3&gt;Pull the repo locally&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone git@github.com:llmware-ai/llmware.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or download/extract a &lt;a href=&#34;https://github.com/llmware-ai/llmware/archive/refs/heads/main.zip&#34;&gt;zip of the llmware repository&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Run llmware natively&lt;/h3&gt; &#xA;&lt;p&gt;Update the local copy of the repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git pull&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Download the shared llmware native libraries and dependencies by running the load_native_libraries.sh script. This pulls the right wheel for your platform and extracts the llmware native libraries and dependencies into the proper place in the local repository.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./scripts/dev/load_native_libraries.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;At the top level of the llmware repository run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;✨ Getting help or sharing your ideas with the community&lt;/h2&gt; &#xA;&lt;p&gt;Questions and discussions are welcome in our &lt;a href=&#34;https://github.com/llmware-ai/llmware/discussions&#34;&gt;github discussions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Interested in contributing to llmware? We welcome involvement from the community to extend and enhance the framework!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;💡 What&#39;s your favorite model or is there one you&#39;d like to check out in your experiments?&lt;/li&gt; &#xA; &lt;li&gt;💡 Have you had success with a different embedding databases?&lt;/li&gt; &#xA; &lt;li&gt;💡 Is there a prompt that shines in a RAG workflow?&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Information on ways to participate can be found in our &lt;a href=&#34;https://github.com/llmware-ai/llmware/raw/main/CONTRIBUTING.md#contributing-to-llmware&#34;&gt;Contributors Guide&lt;/a&gt;. As with all aspects of this project, contributing is governed by our &lt;a href=&#34;https://github.com/llmware-ai/llmware/raw/main/CODE_OF_CONDUCT.md&#34;&gt;Code of Conduct&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;📣 Release notes and Change Log&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Supported Operating Systems:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;MacOS&lt;/li&gt; &#xA; &lt;li&gt;Linux&lt;/li&gt; &#xA; &lt;li&gt;Windows&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Supported Vector Databases:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Milvus&lt;/li&gt; &#xA; &lt;li&gt;FAISS&lt;/li&gt; &#xA; &lt;li&gt;Pinecone&lt;/li&gt; &#xA; &lt;li&gt;MongoDB Atlas Vector Search&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Prereqs:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;All Platforms: &lt;a href=&#34;https://www.python.org/about/gettingstarted/&#34;&gt;Python v3.9 - 3.11&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;To enable the OCR parsing capabilities, install &lt;a href=&#34;https://tesseract-ocr.github.io/tessdoc/Installation.html&#34;&gt;Tesseract v5.3.3&lt;/a&gt; and &lt;a href=&#34;https://poppler.freedesktop.org/&#34;&gt;Poppler v23.10.0&lt;/a&gt; native packages.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Optional:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.docker.com/get-docker/&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Known issues:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A segmentation fault can occur when parsing if the native package for mongo-c-driver is 1.25 or above. To address this issue, install the latest version of llmware or downgrade mongo-c-driver to v1.24.4.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;b&gt;🚧 Change Log&lt;/b&gt;&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;8 Dec 2023: llmware v0.1.11&lt;/strong&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;New fast start examples for high volume Document Ingestion and Embeddings with Milvus.&lt;/li&gt; &#xA;    &lt;li&gt;New LLMWare &#39;Pop up&#39; Inference Server model class and example script.&lt;/li&gt; &#xA;    &lt;li&gt;New Invoice Processing example for RAG.&lt;/li&gt; &#xA;    &lt;li&gt;Improved Windows stack management to support parsing larger documents.&lt;/li&gt; &#xA;    &lt;li&gt;Enhancing debugging log output mode options for PDF and Office parsers.&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;30 Nov 2023: llmware v0.1.10&lt;/strong&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Windows added as a supported operating system.&lt;/li&gt; &#xA;    &lt;li&gt;Further enhancements to native code for stack management.&lt;/li&gt; &#xA;    &lt;li&gt;Minor defect fixes.&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;24 Nov 2023: llmware v0.1.9&lt;/strong&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Markdown (.md) files are now parsed and treated as text files.&lt;/li&gt; &#xA;    &lt;li&gt;PDF and Office parser stack optimizations which should avoid the need to set ulimit -s.&lt;/li&gt; &#xA;    &lt;li&gt;New llmware_models_fast_start.py example that allows discovery and selection of all llmware HuggingFace models.&lt;/li&gt; &#xA;    &lt;li&gt;Native dependencies (shared libraries and dependencies) now included in repo to faciliate local development.&lt;/li&gt; &#xA;    &lt;li&gt;Updates to the Status class to support PDF and Office document parsing status updates.&lt;/li&gt; &#xA;    &lt;li&gt;Minor defect fixes including image block handling in library exports.&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;17 Nov 2023: llmware v0.1.8&lt;/strong&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Enhanced generation performance by allowing each model to specific the trailing space parameter.&lt;/li&gt; &#xA;    &lt;li&gt;Improved handling for eos_token_id for llama2 and mistral.&lt;/li&gt; &#xA;    &lt;li&gt;Improved support for Hugging Face dynamic loading&lt;/li&gt; &#xA;    &lt;li&gt;New examples with the new llmware DRAGON models.&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;14 Nov 2023: llmware v0.1.7&lt;/strong&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Moved to Python Wheel package format for PyPi distribution to provide seamless installation of native dependencies on all supported platforms.&lt;/li&gt; &#xA;    &lt;li&gt;ModelCatalog enhancements: &#xA;     &lt;ul&gt; &#xA;      &lt;li&gt;OpenAI update to include newly announced ‘turbo’ 4 and 3.5 models.&lt;/li&gt; &#xA;      &lt;li&gt;Cohere embedding v3 update to include new Cohere embedding models.&lt;/li&gt; &#xA;      &lt;li&gt;BLING models as out-of-the-box registered options in the catalog. They can be instantiated like any other model, even without the “hf=True” flag.&lt;/li&gt; &#xA;      &lt;li&gt;Ability to register new model names, within existing model classes, with the register method in ModelCatalog.&lt;/li&gt; &#xA;     &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;li&gt;Prompt enhancements: &#xA;     &lt;ul&gt; &#xA;      &lt;li&gt;“evidence_metadata” added to prompt_main output dictionaries allowing prompt_main responses to be plug into the evidence and fact-checking steps without modification.&lt;/li&gt; &#xA;      &lt;li&gt;API key can now be passed directly in a prompt.load_model(model_name, api_key = “[my-api-key]”)&lt;/li&gt; &#xA;     &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;li&gt;LLMWareInference Server - Initial delivery: &#xA;     &lt;ul&gt; &#xA;      &lt;li&gt;New Class for LLMWareModel which is a wrapper on a custom HF-style API-based model.&lt;/li&gt; &#xA;      &lt;li&gt;LLMWareInferenceServer is a new class that can be instantiated on a remote (GPU) server to create a testing API-server that can be integrated into any Prompt workflow.&lt;/li&gt; &#xA;     &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;03 Nov 2023: llmware v0.1.6&lt;/strong&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Updated packaging to require mongo-c-driver 1.24.4 to temporarily workaround segmentation fault with mongo-c-driver 1.25.&lt;/li&gt; &#xA;    &lt;li&gt;Updates in python code needed in anticipation of future Windows support.&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;27 Oct 2023: llmware v0.1.5&lt;/strong&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Four new example scripts focused on RAG workflows with small, fine-tuned instruct models that run on a laptop (&lt;code&gt;llmware&lt;/code&gt; &lt;a href=&#34;https://huggingface.co/llmware&#34;&gt;BLING&lt;/a&gt; models).&lt;/li&gt; &#xA;    &lt;li&gt;Expanded options for setting temperature inside a prompt class.&lt;/li&gt; &#xA;    &lt;li&gt;Improvement in post processing of Hugging Face model generation.&lt;/li&gt; &#xA;    &lt;li&gt;Streamlined loading of Hugging Face generative models into prompts.&lt;/li&gt; &#xA;    &lt;li&gt;Initial delivery of a central status class: read/write of embedding status with a consistent interface for callers.&lt;/li&gt; &#xA;    &lt;li&gt;Enhanced in-memory dictionary search support for multi-key queries.&lt;/li&gt; &#xA;    &lt;li&gt;Removed trailing space in human-bot wrapping to improve generation quality in some fine-tuned models.&lt;/li&gt; &#xA;    &lt;li&gt;Minor defect fixes, updated test scripts, and version update for Werkzeug to address &lt;a href=&#34;https://github.com/llmware-ai/llmware/security/dependabot/2&#34;&gt;dependency security alert&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;20 Oct 2023: llmware v0.1.4&lt;/strong&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;GPU support for Hugging Face models.&lt;/li&gt; &#xA;    &lt;li&gt;Defect fixes and additional test scripts.&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;13 Oct 2023: llmware v0.1.3&lt;/strong&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;MongoDB Atlas Vector Search support.&lt;/li&gt; &#xA;    &lt;li&gt;Support for authentication using a MongoDB connection string.&lt;/li&gt; &#xA;    &lt;li&gt;Document summarization methods.&lt;/li&gt; &#xA;    &lt;li&gt;Improvements in capturing the model context window automatically and passing changes in the expected output length.&lt;/li&gt; &#xA;    &lt;li&gt;Dataset card and description with lookup by name.&lt;/li&gt; &#xA;    &lt;li&gt;Processing time added to model inference usage dictionary.&lt;/li&gt; &#xA;    &lt;li&gt;Additional test scripts, examples, and defect fixes.&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;06 Oct 2023: llmware v0.1.1&lt;/strong&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;Added test scripts to the github repository for regression testing.&lt;/li&gt; &#xA;    &lt;li&gt;Minor defect fixes and version update of Pillow to address &lt;a href=&#34;https://github.com/llmware-ai/llmware/security/dependabot/1&#34;&gt;dependency security alert&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;02 Oct 2023: llmware v0.1.0&lt;/strong&gt; 🔥 Initial release of llmware to open source!! 🔥&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt;</summary>
  </entry>
</feed>