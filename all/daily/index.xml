<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-10-29T01:26:22Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>vercel/next-learn</title>
    <updated>2023-10-29T01:26:22Z</updated>
    <id>tag:github.com,2023-10-29:/vercel/next-learn</id>
    <link href="https://github.com/vercel/next-learn" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Learn Next.js Starter Code&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Learn Next.js&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains starter templates and final code for &lt;a href=&#34;https://nextjs.org/learn&#34;&gt;Learn Next.js&lt;/a&gt; courses:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üÜï &lt;a href=&#34;https://nextjs.org/learn&#34;&gt;Learn Next.js App Router, Data Fetching, Databases, and Auth&lt;/a&gt; (&lt;a href=&#34;https://next-learn-dashboard.vercel.sh&#34;&gt;demo&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nextjs.org/learn-pages-router/basics/create-nextjs-app&#34;&gt;Learn Basics and TypeScript&lt;/a&gt; (&lt;a href=&#34;https://next-learn-starter.vercel.app&#34;&gt;demo&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nextjs.org/learn-pages-router/seo/introduction-to-seo&#34;&gt;Learn SEO&lt;/a&gt; (&lt;a href=&#34;https://next-seo-starter.vercel.app&#34;&gt;demo&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributions&lt;/h2&gt; &#xA;&lt;p&gt;The code for the example apps you build using Next.js Learn live in this repository and we&#39;d be grateful for your contributions.&lt;/p&gt; &#xA;&lt;p&gt;The course curriculum is currently not open sourced, but you can &lt;a href=&#34;https://github.com/vercel/next-learn/issues/new&#34;&gt;create an issue&lt;/a&gt; if you find a mistake.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>bluesky-social/social-app</title>
    <updated>2023-10-29T01:26:22Z</updated>
    <id>tag:github.com,2023-10-29:/bluesky-social/social-app</id>
    <link href="https://github.com/bluesky-social/social-app" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Bluesky Social application for Web, iOS, and Android&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Bluesky Social App&lt;/h1&gt; &#xA;&lt;p&gt;Welcome friends! This is the codebase for the Bluesky Social app.&lt;/p&gt; &#xA;&lt;p&gt;Get the app itself:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Web: &lt;a href=&#34;https://bsky.app&#34;&gt;bsky.app&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;iOS: &lt;a href=&#34;https://apps.apple.com/us/app/bluesky-social/id6444370199&#34;&gt;App Store&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Android: &lt;a href=&#34;https://play.google.com/store/apps/details?id=xyz.blueskyweb.app&amp;amp;hl=en_US&amp;amp;gl=US&#34;&gt;Play Store&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Development Resources&lt;/h2&gt; &#xA;&lt;p&gt;This is a &lt;a href=&#34;https://reactnative.dev/&#34;&gt;React Native&lt;/a&gt; application, written in the TypeScript programming language. It builds on the &lt;code&gt;atproto&lt;/code&gt; TypeScript packages (like &lt;a href=&#34;https://www.npmjs.com/package/@atproto/api&#34;&gt;&lt;code&gt;@atproto/api&lt;/code&gt;&lt;/a&gt;), code for which is also on open source, but in &lt;a href=&#34;https://github.com/bluesky-social/atproto&#34;&gt;a different git repository&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;There is a small amount of Go language source code (in &lt;code&gt;./bskyweb/&lt;/code&gt;), for a web service that returns the React Native Web application.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/bluesky-social/social-app/main/docs/build.md&#34;&gt;Build Instructions&lt;/a&gt; are a good place to get started with the app itself.&lt;/p&gt; &#xA;&lt;p&gt;The Authenticated Transfer Protocol (&#34;AT Protocol&#34; or &#34;atproto&#34;) is a decentralized social media protocol. You don&#39;t &lt;em&gt;need&lt;/em&gt; to understand AT Protocol to work with this application, but it can help. Learn more at:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://atproto.com/guides/overview&#34;&gt;Overview and Guides&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bluesky-social/atproto/discussions&#34;&gt;Github Discussions&lt;/a&gt; üëà Great place to ask questions&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://atproto.com/specs/atp&#34;&gt;Protocol Specifications&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blueskyweb.xyz/blog/3-6-2022-a-self-authenticating-social-protocol&#34;&gt;Blogpost on self-authenticating data structures&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The Bluesky Social application encompases a set of schemas and APIs built in the overall AT Protocol framework. The namespace for these &#34;Lexicons&#34; is &lt;code&gt;app.bsky.*&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributions&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;While we do accept contributions, we prioritize high quality issues and pull requests. Adhering to the below guidelines will ensure a more timely review.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;strong&gt;Rules:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;We may not respond to your issue or PR.&lt;/li&gt; &#xA; &lt;li&gt;We may close an issue or PR without much feedback.&lt;/li&gt; &#xA; &lt;li&gt;We may lock discussions or contributions if our attention is getting DDOSed.&lt;/li&gt; &#xA; &lt;li&gt;We&#39;re not going to provide support for build issues.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Guidelines:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Check for existing issues before filing a new one please.&lt;/li&gt; &#xA; &lt;li&gt;Open an issue and give some time for discussion before submitting a PR.&lt;/li&gt; &#xA; &lt;li&gt;Stay away from PRs like... &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Changing &#34;Post&#34; to &#34;Skeet.&#34;&lt;/li&gt; &#xA;   &lt;li&gt;Refactoring the codebase, eg to replace mobx with redux or something.&lt;/li&gt; &#xA;   &lt;li&gt;Adding entirely new features without prior discussion.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Remember, we serve a wide community of users. Our day to day involves us constantly asking &#34;which top priority is our top priority.&#34; If you submit well-written PRs that solve problems concisely, that&#39;s an awesome contribution. Otherwise, as much as we&#39;d love to accept your ideas and contributions, we really don&#39;t have the bandwidth. That&#39;s what forking is for!&lt;/p&gt; &#xA;&lt;h2&gt;Forking guidelines&lt;/h2&gt; &#xA;&lt;p&gt;You have our blessing ü™Ñ‚ú® to fork this application! However, it&#39;s very important to be clear to users when you&#39;re giving them a fork.&lt;/p&gt; &#xA;&lt;p&gt;Please be sure to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Change all branding in the repository and UI to clearly differentiate from Bluesky.&lt;/li&gt; &#xA; &lt;li&gt;Change any support links (feedback, email, terms of service, etc) to your own systems.&lt;/li&gt; &#xA; &lt;li&gt;Replace any analytics or error-collection systems with your own so we don&#39;t get super confused.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Security disclosures&lt;/h2&gt; &#xA;&lt;p&gt;If you discover any security issues, please send an email to &lt;a href=&#34;mailto:security@bsky.app&#34;&gt;security@bsky.app&lt;/a&gt;. The email is automatically CCed to the entire team and we&#39;ll respond promptly.&lt;/p&gt; &#xA;&lt;h2&gt;Are you a developer interested in building on atproto?&lt;/h2&gt; &#xA;&lt;p&gt;Bluesky is an open social network built on the AT Protocol, a flexible technology that will never lock developers out of the ecosystems that they help build. With atproto, third-party can be as seamless as first-party through custom feeds, federated services, clients, and more.&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re a developer interested in building on atproto, we&#39;d love to email you a Bluesky invite code. Simply share your GitHub (or similar) profile with us via &lt;a href=&#34;https://forms.gle/BF21oxVNZiDjDhXF9&#34;&gt;this form&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License (MIT)&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/bluesky-social/social-app/main/LICENSE&#34;&gt;./LICENSE&lt;/a&gt; for the full license.&lt;/p&gt; &#xA;&lt;h2&gt;P.S.&lt;/h2&gt; &#xA;&lt;p&gt;We ‚ù§Ô∏è you and all of the ways you support us. Thank you for making Bluesky a great place!&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>xxlong0/Wonder3D</title>
    <updated>2023-10-29T01:26:22Z</updated>
    <id>tag:github.com,2023-10-29:/xxlong0/Wonder3D</id>
    <link href="https://github.com/xxlong0/Wonder3D" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A cross-domain diffusion model for 3D reconstruction from a single image&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Wonder3D&lt;/h1&gt; &#xA;&lt;p&gt;Single Image to 3D using Cross-Domain Diffusion&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.15008&#34;&gt;Paper&lt;/a&gt; | &lt;a href=&#34;https://www.xxlong.site/Wonder3D/&#34;&gt;Project page&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/spaces/flamehaze1115/Wonder3D-demo&#34;&gt;Hugging Face Demo&lt;/a&gt; | &lt;a href=&#34;https://github.com/camenduru/Wonder3D-colab&#34;&gt;Colab from @camenduru&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/xxlong0/Wonder3D/main/assets/fig_teaser.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Wonder3D reconstructs highly-detailed textured meshes from a single-view image in only 2 ‚àº 3 minutes. Wonder3D first generates consistent multi-view normal maps with corresponding color images via a cross-domain diffusion model, and then leverages a novel normal fusion method to achieve fast and high-quality reconstruction.&lt;/p&gt; &#xA;&lt;h2&gt;Schedule&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Inference code and pretrained models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Huggingface demo.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; New model trained on the whole Objaverse dataset.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Preparation for inference&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install packages in &lt;code&gt;requirements.txt&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-angular2html&#34;&gt;conda create -n wonder3d&#xA;conda activate wonder3d&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install tiny-cuda-nn PyTorch extension for mesh extraction: &lt;code&gt;pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch&lt;/code&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Download the &lt;a href=&#34;https://connecthkuhk-my.sharepoint.com/:f:/g/personal/xxlong_connect_hku_hk/EgSHPyJAtaJFpV_BjXM3zXwB-UMIrT4v-sQwGgw-coPtIA&#34;&gt;checkpoints&lt;/a&gt; and into the root folder.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Inference&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Make sure you have the following models.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Wonder3D&#xA;|-- ckpts&#xA;    |-- unet&#xA;    |-- scheduler.bin&#xA;    ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Predict foreground mask as the alpha channel. We use &lt;a href=&#34;https://clipdrop.co/remove-background&#34;&gt;Clipdrop&lt;/a&gt; to segment the foreground object interactively. You may also use &lt;code&gt;rembg&lt;/code&gt; to remove the backgrounds.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# !pip install rembg&#xA;import rembg&#xA;result = rembg.remove(result)&#xA;result.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Run Wonder3d to produce multiview-consistent normal maps and color images. Then you can check the results in the folder &lt;code&gt;./outputs&lt;/code&gt;. (we use rembg to remove backgrounds of the results, but the segmemtations are not always perfect.)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;accelerate launch --config_file 1gpu.yaml test_mvdiffusion_seq.py \&#xA;            --config mvdiffusion-joint-ortho-6views.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bash run_test.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Mesh Extraction&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ./instant-nsr-pl&#xA;bash run.sh output_folder_path scene_name&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Our generated normals and color images are defined in orthographic views, so the reconstructed mesh is also in orthographic camera space. If you use MeshLab to view the meshes, you can click &lt;code&gt;Toggle Orthographic Camera&lt;/code&gt; in &lt;code&gt;View&lt;/code&gt; tab.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find this repository useful in your project, please cite the following work. :)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{long2023wonder3d,&#xA;      title={Wonder3D: Single Image to 3D using Cross-Domain Diffusion}, &#xA;      author={Xiaoxiao Long and Yuan-Chen Guo and Cheng Lin and Yuan Liu and Zhiyang Dou and Lingjie Liu and Yuexin Ma and Song-Hai Zhang and Marc Habermann and Christian Theobalt and Wenping Wang},&#xA;      year={2023},&#xA;      eprint={2310.15008},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>