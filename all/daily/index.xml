<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-07-15T01:31:11Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>gz-yami/mall4cloud</title>
    <updated>2022-07-15T01:31:11Z</updated>
    <id>tag:github.com,2022-07-15:/gz-yami/mall4cloud</id>
    <link href="https://github.com/gz-yami/mall4cloud" rel="alternate"></link>
    <summary type="html">&lt;p&gt;⭐️⭐️⭐️ Springcloud商城 O2O商城 小程序商城 PC商城 H5商城 APP商城 Java商城 分销商城 多用户商城 uniapp商城 微服务商城&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/gz-yami/mall4cloud/master/doc/img/readme/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20211203094919.png&#34; alt=&#34;输入图片说明&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;一个基于Spring Cloud、Nacos、Seata、Mysql、Redis、RocketMQ、canal、ElasticSearch、minio的微服务B2B2C电商商城系统，采用主流的互联网技术架构、全新的UI设计、支持集群部署、服务注册和发现以及拥有完整的订单流程等，代码完全开源，没有任何二次封装，是一个非常适合二次开发的电商平台系统。&lt;/p&gt; &#xA;&lt;h2&gt;前言&lt;/h2&gt; &#xA;&lt;p&gt;本商城致力于为中大型企业打造一个功能完整、易于维护的微服务B2B2C电商商城系统，采用主流微服务技术实现。后台管理系统包含平台管理，店铺管理、商品管理、订单管理、规格管理、权限管理、资源管理等模块。&lt;/p&gt; &#xA;&lt;h2&gt;文档&lt;/h2&gt; &#xA;&lt;p&gt;这代码有没有文档呀？ 当然有啦，你已经下载了，在doc这个文件夹上，实在不知道，我就给链接出来咯：&lt;/p&gt; &#xA;&lt;p&gt;gitee：&lt;a href=&#34;https://gitee.com/gz-yami/mall4cloud/tree/master/doc&#34;&gt;https://gitee.com/gz-yami/mall4cloud/tree/master/doc&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;本项目是一个极度遵守阿里巴巴代码规约的项目，以下是代码规约扫描结果&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/gz-yami/mall4cloud/master/doc/img/readme/%E9%98%BF%E9%87%8C%E4%BB%A3%E7%A0%81%E8%A7%84%E7%BA%A6%E6%89%AB%E6%8F%8F%E7%BB%93%E6%9E%9C.png&#34; alt=&#34;阿里代码规约扫描结果&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;具体目录结构和代码规范，可以查看 &lt;a href=&#34;https://gitee.com/gz-yami/mall4cloud/tree/master/doc/%E4%BB%A3%E7%A0%81%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84&#34;&gt;https://gitee.com/gz-yami/mall4cloud/tree/master/doc/%E4%BB%A3%E7%A0%81%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;授权&lt;/h2&gt; &#xA;&lt;p&gt;除开源版本外，本商城还提供商业版本的商城，欲知详情，请访问官网。&lt;/p&gt; &#xA;&lt;p&gt;商城官网：&lt;a href=&#34;https://www.mall4j.com&#34;&gt;https://www.mall4j.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;商城使用 AGPLv3 开源，请遵守 AGPLv3 的相关条款，或者联系作者获取商业授权(&lt;a href=&#34;https://www.mall4j.com&#34;&gt;https://www.mall4j.com&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;h2&gt;项目链接&lt;/h2&gt; &#xA;&lt;p&gt;JAVA后台：&lt;a href=&#34;https://gitee.com/gz-yami/mall4cloud&#34;&gt;https://gitee.com/gz-yami/mall4cloud&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;平台端：&lt;a href=&#34;https://gitee.com/gz-yami/mall4cloud-platform&#34;&gt;https://gitee.com/gz-yami/mall4cloud-platform&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;商家端：&lt;a href=&#34;https://gitee.com/gz-yami/mall4cloud-multishop&#34;&gt;https://gitee.com/gz-yami/mall4cloud-multishop&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;uni-app：&lt;a href=&#34;https://gitee.com/gz-yami/mall4cloud-uniapp&#34;&gt;https://gitee.com/gz-yami/mall4cloud-uniapp&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;演示地址&lt;/h2&gt; &#xA;&lt;p&gt;商业版演示地址：&lt;/p&gt; &#xA;&lt;p&gt;pc端：&lt;a href=&#34;https://cloud-pc.mall4j.com&#34;&gt;https://cloud-pc.mall4j.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;H5端：&lt;a href=&#34;https://h5.mall4j.com/cloud&#34;&gt;https://h5.mall4j.com/cloud&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;小程序：微信搜索 “mall4j微服务版”&lt;/p&gt; &#xA;&lt;h2&gt;目录结构规范&lt;/h2&gt; &#xA;&lt;p&gt;我们也有自己的目录结构&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://gitee.com/gz-yami/mall4cloud/raw/master/doc/img/%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E5%92%8C%E8%A7%84%E8%8C%83/%E5%BA%94%E7%94%A8%E5%88%86%E5%B1%82.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;VO（View Object）：显示层对象，通常是 Web 向模板渲染引擎层传输的对象。&lt;/li&gt; &#xA; &lt;li&gt;DTO（Data Transfer Object）：数据传输对象，前端像后台进行传输的对象，类似于param。&lt;/li&gt; &#xA; &lt;li&gt;BO（Business Object）：业务对象，内部业务对象，只在内部传递，不对外进行传递。&lt;/li&gt; &#xA; &lt;li&gt;Model：模型层，此对象与数据库表结构一一对应，通过 Mapper 层向上传输数据源对象。&lt;/li&gt; &#xA; &lt;li&gt;Controller：主要是对外部访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。为了简单起见，一些与事务无关的代码也在这里编写。&lt;/li&gt; &#xA; &lt;li&gt;FeignClient：由于微服务之间存在互相调用，这里是内部请求的接口。&lt;/li&gt; &#xA; &lt;li&gt;Controller：主要是对内部访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。为了简单起见，一些与事务无关的代码也在这里编写。&lt;/li&gt; &#xA; &lt;li&gt;Service 层：相对具体的业务逻辑服务层。&lt;/li&gt; &#xA; &lt;li&gt;Manager 层：通用业务处理层，它有如下特征： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;1） 对第三方平台封装的层，预处理返回结果及转化异常信息，适配上层接口。&lt;/li&gt; &#xA;   &lt;li&gt;2） 对 Service 层通用能力的下沉，如缓存方案、中间件通用处理。&lt;/li&gt; &#xA;   &lt;li&gt;3） 与 DAO 层交互，对多个 DAO 的组合复用。&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Mapper持久层：数据访问层，与底层 MySQL进行数据交互。&lt;/li&gt; &#xA; &lt;li&gt;Listener：监听 &lt;code&gt;RocketMQ&lt;/code&gt; 进行处理，有时候会监听&lt;code&gt;easyexcel&lt;/code&gt;相关数据。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;关于&lt;code&gt;FeignClient&lt;/code&gt;，由于微服务之间存在互相调用，&lt;code&gt;Feign&lt;/code&gt; 是http协议，理论上是为了解耦，而实际上提供方接口进行修改，调用方却没有进行修改的时候，会造成异常，所以我们抽取出来。还有就是对内暴露的接口，是很多地方都公用的，所以我们还将接口抽取了出了一个模块，方便引用。可以看到&lt;code&gt;mall4cloud-api&lt;/code&gt;这个模块下是所有对内&lt;code&gt;feign&lt;/code&gt;接口的信息。&lt;/p&gt; &#xA;&lt;h2&gt;目录结构&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;mall4cloud&#xA;├─mall4cloud-api -- 内网接口&#xA;│  ├─mall4cloud-api-auth  -- 授权对内接口&#xA;│  ├─mall4cloud-api-biz  -- biz对内接口&#xA;│  ├─mall4cloud-api-leaf  -- 美团分布式id生成接口&#xA;│  ├─mall4cloud-api-multishop  -- 店铺对内接口&#xA;│  ├─mall4cloud-api-order  -- 订单对内接口&#xA;│  ├─mall4cloud-api-platform  -- 平台对内接口&#xA;│  ├─mall4cloud-api-product  -- 商品对内接口&#xA;│  ├─mall4cloud-api-rbac  -- 用户角色权限对内接口&#xA;│  ├─mall4cloud-api-search  -- 搜索对内接口&#xA;│  └─mall4cloud-api-user  -- 用户对内接口&#xA;├─mall4cloud-auth  -- 授权校验模块&#xA;├─mall4cloud-biz  -- mall4cloud 业务代码。如图片上传/短信等&#xA;├─mall4cloud-common -- 一些公共的方法&#xA;│  ├─mall4cloud-common-cache  -- 缓存相关公共代码&#xA;│  ├─mall4cloud-common-core  -- 公共模块核心（公共中的公共代码）&#xA;│  ├─mall4cloud-common-database  -- 数据库连接相关公共代码&#xA;│  ├─mall4cloud-common-order  -- 订单相关公共代码&#xA;│  ├─mall4cloud-common-product  -- 商品相关公共代码&#xA;│  ├─mall4cloud-common-rocketmq  -- rocketmq相关公共代码&#xA;│  └─mall4cloud-common-security  -- 安全相关公共代码&#xA;├─mall4cloud-gateway  -- 网关&#xA;├─mall4cloud-leaf  -- 基于美团leaf的生成id服务&#xA;├─mall4cloud-multishop  -- 商家端&#xA;├─mall4cloud-order  -- 订单服务&#xA;├─mall4cloud-payment  -- 支付服务&#xA;├─mall4cloud-platform  -- 平台端&#xA;├─mall4cloud-product  -- 商品服务&#xA;├─mall4cloud-rbac  -- 用户角色权限模块&#xA;├─mall4cloud-search  -- 搜索模块&#xA;└─mall4cloud-user  -- 用户服务&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;技术选型&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/gz-yami/mall4cloud/master/doc/img/readme/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6.png&#34; alt=&#34;技术框架&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;系统架构图&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/gz-yami/mall4cloud/master/doc/img/readme/%E6%9E%B6%E6%9E%84%E5%9B%BE.png&#34; alt=&#34;架构图&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;商城部署后 API 地址&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;服务&lt;/th&gt; &#xA;   &lt;th&gt;地址&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mall4cloud-gatway 网关服务&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://127.0.0.1:9000&#34;&gt;http://127.0.0.1:9000&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mall4cloud-auth 授权校验服务&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://127.0.0.1:9101&#34;&gt;http://127.0.0.1:9101&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mall4cloud-biz 业务代码服务（如图片上传/短信等）&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://127.0.0.1:9000&#34;&gt;http://127.0.0.1:9000&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mall4cloud-leaf 基于美团leaf的生成id服务&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://127.0.0.1:9100&#34;&gt;http://127.0.0.1:9100&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mall4cloud-multishop 商家服务&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://127.0.0.1:9103&#34;&gt;http://127.0.0.1:9103&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mall4cloud-order 订单服务&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://127.0.0.1:9106&#34;&gt;http://127.0.0.1:9106&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mall4cloud-payment 支付服务&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://127.0.0.1:9113&#34;&gt;http://127.0.0.1:9113&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mall4cloud-product 商品服务&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://127.0.0.1:9112&#34;&gt;http://127.0.0.1:9112&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mall4cloud-rbac 用户角色服务&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://127.0.0.1:9102&#34;&gt;http://127.0.0.1:9102&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mall4cloud-search 搜索服务&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://127.0.0.1:9108&#34;&gt;http://127.0.0.1:9108&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;mall4cloud-user 用户服务&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://127.0.0.1:9105&#34;&gt;http://127.0.0.1:9105&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;部署教程&lt;/h2&gt; &#xA;&lt;p&gt;部署教程请参考该文件夹下的&lt;code&gt;/基本开发文档/mall4cloud开发环境搭建.md&lt;/code&gt;以及&lt;code&gt;/开发环境搭建&lt;/code&gt;目录下的中间件安装。&lt;/p&gt; &#xA;&lt;h2&gt;代码运行相关截图&lt;/h2&gt; &#xA;&lt;h3&gt;1.后台截图&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;平台端&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/gz-yami/mall4cloud/master/doc/img/readme/image-20210705152109738.png&#34; alt=&#34;image-20210705152109738&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;商家端&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/gz-yami/mall4cloud/master/doc/img/readme/image-20210705151729559.png&#34; alt=&#34;image-20210705151729559&#34;&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/gz-yami/mall4cloud/master/doc/img/readme/image-20210705151847270.png&#34; alt=&#34;image-20210705151847270&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;2.小程序截图&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/gz-yami/mall4cloud/master/doc/img/readme/%E5%B0%8F%E7%A8%8B%E5%BA%8F.png&#34; alt=&#34;小程序-1625472143277&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;3.uni-app截图&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/gz-yami/mall4cloud/master/doc/img/readme/uniapp.png&#34; alt=&#34;uniapp-1625469707350&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;提交反馈&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Mall4j官网 &lt;a href=&#34;https://www.mall4j.com&#34;&gt;https://www.mall4j.com&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;mall4cloud开源技术QQ群：561496886&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;如需购买商业版源码，请联系商务微信&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;https://19838323.s21i.faiusr.com/4/4/ABUIABAEGAAgksmNlAYojomK2gIwrAI4rAI!160x160.png&#34; alt=&#34;输入图片说明&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;springboot版本商城请点击&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://gitee.com/gz-yami/mall4j&#34;&gt;https://gitee.com/gz-yami/mall4j&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;你的点赞鼓励，是我们前进的动力~&lt;/h2&gt; &#xA;&lt;h2&gt;你的点赞鼓励，是我们前进的动力~&lt;/h2&gt; &#xA;&lt;h2&gt;你的点赞鼓励，是我们前进的动力~&lt;/h2&gt;</summary>
  </entry>
  <entry>
    <title>srush/GPU-Puzzles</title>
    <updated>2022-07-15T01:31:11Z</updated>
    <id>tag:github.com,2022-07-15:/srush/GPU-Puzzles</id>
    <link href="https://github.com/srush/GPU-Puzzles" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Solve puzzles. Learn CUDA.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GPU Puzzles&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;by &lt;a href=&#34;http://rush-nlp.com&#34;&gt;Sasha Rush&lt;/a&gt; - &lt;a href=&#34;https://twitter.com/srush_nlp&#34;&gt;srush_nlp&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/srush/GPU-Puzzles/raw/main/cuda.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;GPU architectures are critical to machine learning, and seem to be becoming even more important every day. However you can be an expert in machine learning without ever touching GPU code. It is a bit weird to be work always through abstraction.&lt;/p&gt; &#xA;&lt;p&gt;This notebook is an attempt teach beginner GPU programming in a completely interactive fashion. Instead of providing text with concepts, it throws you right into coding and building GPU kernels. The exercises use NUMBA which directly maps Python code to CUDA kernels. It looks like Python but is basically identical to writing low-level CUDA code. In a few hours, I think you can go from basics to understanding the real algorithms that power 99% of deep learning today. If you do want to read the manual, it is here:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://numba.readthedocs.io/en/stable/cuda/index.html&#34;&gt;NUMBA CUDA Guide&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;I recommend doing these in Colab, as it is easy to get started. Be sure to make your own copy, turn on GPU mode in the settings (&lt;code&gt;Runtime / Change runtime type&lt;/code&gt;, then set &lt;code&gt;Hardware accelerator&lt;/code&gt; to &lt;code&gt;GPU&lt;/code&gt;), and then get to coding.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/srush/GPU-Puzzles/blob/main/GPU_puzzlers.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;(If you are into this style of puzzle, also check out my &lt;a href=&#34;https://github.com/srush/Tensor-Puzzles&#34;&gt;Tensor Puzzles&lt;/a&gt; for PyTorch.)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!pip install -qqq git+https://github.com/danoneata/chalk@srush-patch-1&#xA;!wget -q https://github.com/srush/GPU-Puzzles/raw/main/robot.png https://github.com/srush/GPU-Puzzles/raw/main/lib.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numba&#xA;import numpy as np&#xA;import warnings&#xA;from lib import CudaProblem, Coord&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;warnings.filterwarnings(&#xA;    action=&#34;ignore&#34;, category=numba.NumbaPerformanceWarning, module=&#34;numba&#34;&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Puzzle 1: Map&lt;/h2&gt; &#xA;&lt;p&gt;Implement a &#34;kernel&#34; (GPU function) that adds 10 to each position of vector &lt;code&gt;a&lt;/code&gt; and stores it in vector &lt;code&gt;out&lt;/code&gt;. You have 1 thread per position.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt; This code looks like Python but it is really CUDA! You cannot use standard python tools like list comprehensions or ask for Numpy properties like shape or size (if you need the size, it is given as an argument). The puzzles only require doing simple operations, basically +, *, simple array indexing, for loops, and if statements. If you get an error it is probably because you did something fancy :).&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Tip: Think of the function &lt;code&gt;call&lt;/code&gt; as being run 1 time for each thread. The only difference is that &lt;code&gt;cuda.threadIdx.x&lt;/code&gt; changes each time.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def map_spec(a):&#xA;    return a + 10&#xA;&#xA;&#xA;def map_test(cuda):&#xA;    def call(out, a) -&amp;gt; None:&#xA;        local_i = cuda.threadIdx.x&#xA;        # FILL ME IN (roughly 1 lines)&#xA;&#xA;    return call&#xA;&#xA;&#xA;SIZE = 4&#xA;out = np.zeros((SIZE,))&#xA;a = np.arange(SIZE)&#xA;problem = CudaProblem(&#xA;    &#34;Map&#34;, map_test, [a], out, threadsperblock=Coord(SIZE, 1), spec=map_spec&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Map&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_15_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [0. 0. 0. 0.]&#xA;Spec : [10 11 12 13]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Puzzle 2 - Zip&lt;/h2&gt; &#xA;&lt;p&gt;Implement a kernel that adds together each position of &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; and stores it in &lt;code&gt;out&lt;/code&gt;. You have 1 thread per position.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def zip_spec(a, b):&#xA;    return a + b&#xA;&#xA;&#xA;def zip_test(cuda):&#xA;    def call(out, a, b) -&amp;gt; None:&#xA;        local_i = cuda.threadIdx.x&#xA;        # FILL ME IN (roughly 1 lines)&#xA;&#xA;    return call&#xA;&#xA;&#xA;SIZE = 4&#xA;out = np.zeros((SIZE,))&#xA;a = np.arange(SIZE)&#xA;b = np.arange(SIZE)&#xA;problem = CudaProblem(&#xA;    &#34;Zip&#34;, zip_test, [a, b], out, threadsperblock=Coord(SIZE, 1), spec=zip_spec&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Zip&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_19_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [0. 0. 0. 0.]&#xA;Spec : [0 2 4 6]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Puzzle 3 - Guards&lt;/h2&gt; &#xA;&lt;p&gt;Implement a kernel that adds 10 to each position of &lt;code&gt;a&lt;/code&gt; and stores it in &lt;code&gt;out&lt;/code&gt;. You have more threads than positions.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def map_guard_test(cuda):&#xA;    def call(out, a, size) -&amp;gt; None:&#xA;        local_i = cuda.threadIdx.x&#xA;        # FILL ME IN (roughly 2 lines)&#xA;&#xA;    return call&#xA;&#xA;&#xA;SIZE = 4&#xA;out = np.zeros((SIZE,))&#xA;a = np.arange(SIZE)&#xA;problem = CudaProblem(&#xA;    &#34;Guard&#34;,&#xA;    map_guard_test,&#xA;    [a],&#xA;    out,&#xA;    [SIZE],&#xA;    threadsperblock=Coord(8, 1),&#xA;    spec=map_spec,&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Guard&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_24_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [0. 0. 0. 0.]&#xA;Spec : [10 11 12 13]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Puzzle 4 - Map 2D&lt;/h2&gt; &#xA;&lt;p&gt;Implement a kernel that adds 10 to each position of &lt;code&gt;a&lt;/code&gt; and stores it in &lt;code&gt;out&lt;/code&gt;. Input &lt;code&gt;a&lt;/code&gt; is 2D and square. You have more threads than positions.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def map_2D_test(cuda):&#xA;    def call(out, a, size) -&amp;gt; None:&#xA;        local_i = cuda.threadIdx.x&#xA;        local_j = cuda.threadIdx.y&#xA;        # FILL ME IN (roughly 2 lines)&#xA;&#xA;    return call&#xA;&#xA;&#xA;SIZE = 2&#xA;out = np.zeros((SIZE, SIZE))&#xA;a = np.arange(SIZE * SIZE).reshape((SIZE, SIZE))&#xA;problem = CudaProblem(&#xA;    &#34;Map 2D&#34;, map_2D_test, [a], out, [SIZE], threadsperblock=Coord(3, 3), spec=map_spec&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Map 2D&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_28_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [[0. 0.]&#xA; [0. 0.]]&#xA;Spec : [[10 11]&#xA; [12 13]]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Puzzle 5 - Broadcast&lt;/h2&gt; &#xA;&lt;p&gt;Implement a kernel that adds &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; and stores it in &lt;code&gt;out&lt;/code&gt;. Inputs &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are vectors. You have more threads than positions.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def broadcast_test(cuda):&#xA;    def call(out, a, b, size) -&amp;gt; None:&#xA;        local_i = cuda.threadIdx.x&#xA;        local_j = cuda.threadIdx.y&#xA;        # FILL ME IN (roughly 2 lines)&#xA;&#xA;    return call&#xA;&#xA;&#xA;SIZE = 2&#xA;out = np.zeros((SIZE, SIZE))&#xA;a = np.arange(SIZE).reshape(SIZE, 1)&#xA;b = np.arange(SIZE).reshape(1, SIZE)&#xA;problem = CudaProblem(&#xA;    &#34;Broadcast&#34;,&#xA;    broadcast_test,&#xA;    [a, b],&#xA;    out,&#xA;    [SIZE],&#xA;    threadsperblock=Coord(3, 3),&#xA;    spec=zip_spec,&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Broadcast&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_32_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [[0. 0.]&#xA; [0. 0.]]&#xA;Spec : [[0 1]&#xA; [1 2]]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Puzzle 6 - Blocks&lt;/h2&gt; &#xA;&lt;p&gt;Implement a kernel that adds 10 to each position of &lt;code&gt;a&lt;/code&gt; and stores it in &lt;code&gt;out&lt;/code&gt;. You have fewer threads per block than the size of &lt;code&gt;a&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Tip: A block is a group of threads. The number of threads per block is limited, but we can have many different blocks. Variable &lt;code&gt;cuda.blockIdx&lt;/code&gt; tells us what block we are in.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def map_block_test(cuda):&#xA;    def call(out, a, size) -&amp;gt; None:&#xA;        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x&#xA;        # FILL ME IN (roughly 2 lines)&#xA;&#xA;    return call&#xA;&#xA;&#xA;SIZE = 9&#xA;out = np.zeros((SIZE,))&#xA;a = np.arange(SIZE)&#xA;problem = CudaProblem(&#xA;    &#34;Blocks&#34;,&#xA;    map_block_test,&#xA;    [a],&#xA;    out,&#xA;    [SIZE],&#xA;    threadsperblock=Coord(4, 1),&#xA;    blockspergrid=Coord(3, 1),&#xA;    spec=map_spec,&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Blocks&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_37_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [0. 0. 0. 0. 0. 0. 0. 0. 0.]&#xA;Spec : [10 11 12 13 14 15 16 17 18]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Puzzle 7 - Blocks 2D&lt;/h2&gt; &#xA;&lt;p&gt;Implement the same kernel in 2D. You have fewer threads per block than the size of &lt;code&gt;a&lt;/code&gt; in both directions.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def map_block2D_test(cuda):&#xA;    def call(out, a, size) -&amp;gt; None:&#xA;        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x&#xA;        # FILL ME IN (roughly 4 lines)&#xA;&#xA;    return call&#xA;&#xA;&#xA;SIZE = 5&#xA;out = np.zeros((SIZE, SIZE))&#xA;a = np.ones((SIZE, SIZE))&#xA;&#xA;problem = CudaProblem(&#xA;    &#34;Blocks 2D&#34;,&#xA;    map_block2D_test,&#xA;    [a],&#xA;    out,&#xA;    [SIZE],&#xA;    threadsperblock=Coord(3, 3),&#xA;    blockspergrid=Coord(2, 2),&#xA;    spec=map_spec,&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Blocks 2D&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_41_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [[0. 0. 0. 0. 0.]&#xA; [0. 0. 0. 0. 0.]&#xA; [0. 0. 0. 0. 0.]&#xA; [0. 0. 0. 0. 0.]&#xA; [0. 0. 0. 0. 0.]]&#xA;Spec : [[11. 11. 11. 11. 11.]&#xA; [11. 11. 11. 11. 11.]&#xA; [11. 11. 11. 11. 11.]&#xA; [11. 11. 11. 11. 11.]&#xA; [11. 11. 11. 11. 11.]]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Puzzle 8 - Shared&lt;/h2&gt; &#xA;&lt;p&gt;Implement a kernel that adds 10 to each position of &lt;code&gt;a&lt;/code&gt; and stores it in &lt;code&gt;out&lt;/code&gt;. You have fewer threads per block than the size of &lt;code&gt;a&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: Each block can only have a &lt;em&gt;constant&lt;/em&gt; amount of shared memory that threads in that block can read and write to. This needs to be a literal python constant not a variable. After writing to shared memory you need to call &lt;code&gt;cuda.syncthreads&lt;/code&gt; to ensure that threads do not cross.&lt;/p&gt; &#xA;&lt;p&gt;(This example does not really need shared memory or syncthreads, but it is a demo.)&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;TPB = 4&#xA;def shared_test(cuda):&#xA;    def call(out, a, size) -&amp;gt; None:&#xA;        shared = cuda.shared.array(TPB, numba.float32)&#xA;        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x&#xA;        local_i = cuda.threadIdx.x&#xA;&#xA;        if i &amp;lt; size:&#xA;            shared[local_i] = a[i]&#xA;            cuda.syncthreads()&#xA;&#xA;        # FILL ME IN (roughly 2 lines)&#xA;&#xA;    return call&#xA;&#xA;&#xA;SIZE = 8&#xA;out = np.zeros(SIZE)&#xA;a = np.ones(SIZE)&#xA;problem = CudaProblem(&#xA;    &#34;Shared&#34;,&#xA;    shared_test,&#xA;    [a],&#xA;    out,&#xA;    [SIZE],&#xA;    threadsperblock=Coord(TPB, 1),&#xA;    blockspergrid=Coord(2, 1),&#xA;    spec=map_spec,&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Shared&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             1 |             0 |             0 |             1 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_47_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [0. 0. 0. 0. 0. 0. 0. 0.]&#xA;Spec : [11. 11. 11. 11. 11. 11. 11. 11.]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Puzzle 9 - Pooling&lt;/h2&gt; &#xA;&lt;p&gt;Implement a kernel that sums together the last 3 position of &lt;code&gt;a&lt;/code&gt; and stores it in &lt;code&gt;out&lt;/code&gt;. You have 1 thread per position. You only need 1 global read and 1 global write per thread.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Tip: Remember to be careful about syncing.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def pool_spec(a):&#xA;    out = np.zeros(*a.shape)&#xA;    for i in range(a.shape[0]):&#xA;        out[i] = a[max(i - 2, 0) : i + 1].sum()&#xA;    return out&#xA;&#xA;&#xA;TPB = 8&#xA;def pool_test(cuda):&#xA;    def call(out, a, size) -&amp;gt; None:&#xA;        shared = cuda.shared.array(TPB, numba.float32)&#xA;        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x&#xA;        local_i = cuda.threadIdx.x&#xA;        # FILL ME IN (roughly 8 lines)&#xA;&#xA;    return call&#xA;&#xA;&#xA;SIZE = 8&#xA;out = np.zeros(SIZE)&#xA;a = np.arange(SIZE)&#xA;problem = CudaProblem(&#xA;    &#34;Pooling&#34;,&#xA;    pool_test,&#xA;    [a],&#xA;    out,&#xA;    [SIZE],&#xA;    threadsperblock=Coord(TPB, 1),&#xA;    blockspergrid=Coord(1, 1),&#xA;    spec=pool_spec,&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Pooling&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_52_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [0. 0. 0. 0. 0. 0. 0. 0.]&#xA;Spec : [ 0.  1.  3.  6.  9. 12. 15. 18.]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Puzzle 10 - Dot Product&lt;/h2&gt; &#xA;&lt;p&gt;Implement a kernel that computes the dot-product of &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; and stores it in &lt;code&gt;out&lt;/code&gt;. You have 1 thread per position. You only need 1 global read and 1 global write per thread.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Note: For this problem you don&#39;t need to worry about number of shared reads. We will handle that challenge later.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def dot_spec(a, b):&#xA;    return a @ b&#xA;&#xA;&#xA;TPB = 8&#xA;def dot_test(cuda):&#xA;    def call(out, a, b, size) -&amp;gt; None:&#xA;        shared = cuda.shared.array(TPB, numba.float32)&#xA;&#xA;        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x&#xA;        local_i = cuda.threadIdx.x&#xA;        # FILL ME IN (roughly 9 lines)&#xA;&#xA;    return call&#xA;&#xA;&#xA;SIZE = 8&#xA;out = np.zeros(1)&#xA;a = np.arange(SIZE)&#xA;b = np.arange(SIZE)&#xA;problem = CudaProblem(&#xA;    &#34;Dot&#34;,&#xA;    dot_test,&#xA;    [a, b],&#xA;    out,&#xA;    [SIZE],&#xA;    threadsperblock=Coord(SIZE, 1),&#xA;    blockspergrid=Coord(1, 1),&#xA;    spec=dot_spec,&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Dot&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_56_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [0.]&#xA;Spec : 140&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Puzzle 11 - 1D Convolution&lt;/h2&gt; &#xA;&lt;p&gt;Implement a kernel that computes a 1D convolution between &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; and stores it in &lt;code&gt;out&lt;/code&gt;. You need to handle the general case. You only need 2 global reads and 1 global write per thread.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def conv_spec(a, b):&#xA;    out = np.zeros(*a.shape)&#xA;    len = b.shape[0]&#xA;    for i in range(a.shape[0]):&#xA;        out[i] = sum([a[i + j] * b[j] for j in range(len) if i + j &amp;lt; a.shape[0]])&#xA;    return out&#xA;&#xA;&#xA;MAX_CONV = 5&#xA;TPB = 8&#xA;TPB_MAX_CONV = TPB + MAX_CONV&#xA;def conv_test(cuda):&#xA;    def call(out, a, b, a_size, b_size) -&amp;gt; None:&#xA;        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x&#xA;        local_i = cuda.threadIdx.x&#xA;&#xA;        # FILL ME IN (roughly 17 lines)&#xA;&#xA;    return call&#xA;&#xA;&#xA;# Test 1&#xA;&#xA;SIZE = 6&#xA;CONV = 3&#xA;out = np.zeros(SIZE)&#xA;a = np.arange(SIZE)&#xA;b = np.arange(CONV)&#xA;problem = CudaProblem(&#xA;    &#34;1D Conv (Simple)&#34;,&#xA;    conv_test,&#xA;    [a, b],&#xA;    out,&#xA;    [SIZE, CONV],&#xA;    Coord(1, 1),&#xA;    Coord(TPB, 1),&#xA;    spec=conv_spec,&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# 1D Conv (Simple)&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_59_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [0. 0. 0. 0. 0. 0.]&#xA;Spec : [ 5.  8. 11. 14.  5.  0.]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Test 2&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;out = np.zeros(15)&#xA;a = np.arange(15)&#xA;b = np.arange(4)&#xA;problem = CudaProblem(&#xA;    &#34;1D Conv (Full)&#34;,&#xA;    conv_test,&#xA;    [a, b],&#xA;    out,&#xA;    [15, 4],&#xA;    Coord(2, 1),&#xA;    Coord(TPB, 1),&#xA;    spec=conv_spec,&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# 1D Conv (Full)&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_62_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]&#xA;Spec : [14. 20. 26. 32. 38. 44. 50. 56. 62. 68. 74. 80. 41. 14.  0.]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Puzzle 12 - Prefix Sum&lt;/h2&gt; &#xA;&lt;p&gt;Implement a kernel that computes a sum over &lt;code&gt;a&lt;/code&gt; and stores it in &lt;code&gt;out&lt;/code&gt;. If the size of &lt;code&gt;a&lt;/code&gt; is greater than the block size, only store the sum of each block.&lt;/p&gt; &#xA;&lt;p&gt;We will do this using the &lt;a href=&#34;https://en.wikipedia.org/wiki/Prefix_sum&#34;&gt;parallel prefix sum&lt;/a&gt; algorithm in shared memory. That is, each step of the algorithm should sum together half the remaining numbers. Follow this diagram:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/35882/178757889-1c269623-93af-4a2e-a7e9-22cd55a42e38.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;TPB = 8&#xA;def sum_spec(a):&#xA;    out = np.zeros((a.shape[0] + TPB - 1) // TPB)&#xA;    for j, i in enumerate(range(0, a.shape[-1], TPB)):&#xA;        out[j] = a[i : i + TPB].sum()&#xA;    return out&#xA;&#xA;&#xA;def sum_test(cuda):&#xA;    def call(out, a, size: int) -&amp;gt; None:&#xA;        cache = cuda.shared.array(TPB, numba.float32)&#xA;        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x&#xA;        local_i = cuda.threadIdx.x&#xA;        # FILL ME IN (roughly 12 lines)&#xA;&#xA;    return call&#xA;&#xA;&#xA;# Test 1&#xA;&#xA;SIZE = 8&#xA;out = np.zeros(1)&#xA;inp = np.arange(SIZE)&#xA;problem = CudaProblem(&#xA;    &#34;Sum (Simple)&#34;,&#xA;    sum_test,&#xA;    [inp],&#xA;    out,&#xA;    [SIZE],&#xA;    Coord(1, 1),&#xA;    Coord(TPB, 1),&#xA;    spec=sum_spec,&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Sum (Simple)&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_67_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [0.]&#xA;Spec : [28.]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Test 2&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;SIZE = 15&#xA;out = np.zeros(2)&#xA;inp = np.arange(SIZE)&#xA;problem = CudaProblem(&#xA;    &#34;Sum (Full)&#34;,&#xA;    sum_test,&#xA;    [inp],&#xA;    out,&#xA;    [SIZE],&#xA;    Coord(2, 1),&#xA;    Coord(TPB, 1),&#xA;    spec=sum_spec,&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Sum (Full)&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_70_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [0. 0.]&#xA;Spec : [28. 77.]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Puzzle 13 - Axis Sum&lt;/h2&gt; &#xA;&lt;p&gt;Implement a kernel that computes a sum over each row of &lt;code&gt;a&lt;/code&gt; and stores it in &lt;code&gt;out&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;TPB = 8&#xA;def sum_spec(a):&#xA;    out = np.zeros((a.shape[0], (a.shape[1] + TPB - 1) // TPB))&#xA;    for j, i in enumerate(range(0, a.shape[-1], TPB)):&#xA;        out[..., j] = a[..., i : i + TPB].sum(-1)&#xA;    return out&#xA;&#xA;&#xA;def axis_sum_test(cuda):&#xA;    def call(out, a, size: int) -&amp;gt; None:&#xA;        cache = cuda.shared.array(TPB, numba.float32)&#xA;        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x&#xA;        local_i = cuda.threadIdx.x&#xA;        batch = cuda.blockIdx.y&#xA;        # FILL ME IN (roughly 12 lines)&#xA;&#xA;    return call&#xA;&#xA;&#xA;BATCH = 4&#xA;SIZE = 6&#xA;out = np.zeros((BATCH, 1))&#xA;inp = np.arange(BATCH * SIZE).reshape((BATCH, SIZE))&#xA;problem = CudaProblem(&#xA;    &#34;Axis Sum&#34;,&#xA;    axis_sum_test,&#xA;    [inp],&#xA;    out,&#xA;    [SIZE],&#xA;    Coord(1, BATCH),&#xA;    Coord(TPB, 1),&#xA;    spec=sum_spec,&#xA;)&#xA;problem.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Axis Sum&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_73_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [[0.]&#xA; [0.]&#xA; [0.]&#xA; [0.]]&#xA;Spec : [[ 15.]&#xA; [ 51.]&#xA; [ 87.]&#xA; [123.]]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Puzzle 14 - Matrix Multiply!&lt;/h2&gt; &#xA;&lt;p&gt;Implement a kernel that multiplies square matrices &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; and stores it in &lt;code&gt;out&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Tip: The most efficient algorithm here will copy a block into shared memory before computing each of the individual row-column dot products. This is easy to do if the matrix fits in shared memory. Do that case first. Then update your code to compute a partial dot-product and then iteratively move the part that you copied into shared memory.&lt;/em&gt; You should be able to do the hard case in 6 global reads.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def matmul_spec(a, b):&#xA;    return a @ b&#xA;&#xA;&#xA;TPB = 3&#xA;def mm_oneblock_test(cuda):&#xA;    def call(out, a, b, size: int) -&amp;gt; None:&#xA;        a_shared = cuda.shared.array((TPB, TPB), numba.float32)&#xA;        b_shared = cuda.shared.array((TPB, TPB), numba.float32)&#xA;&#xA;        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x&#xA;        j = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y&#xA;        local_i = cuda.threadIdx.x&#xA;        local_j = cuda.threadIdx.y&#xA;        # FILL ME IN (roughly 14 lines)&#xA;&#xA;    return call&#xA;&#xA;# Test 1&#xA;&#xA;SIZE = 2&#xA;out = np.zeros((SIZE, SIZE))&#xA;inp1 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE))&#xA;inp2 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE)).T&#xA;&#xA;problem = CudaProblem(&#xA;    &#34;Matmul (Simple)&#34;,&#xA;    mm_oneblock_test,&#xA;    [inp1, inp2],&#xA;    out,&#xA;    [SIZE],&#xA;    Coord(1, 1),&#xA;    Coord(TPB, TPB),&#xA;    spec=matmul_spec,&#xA;)&#xA;problem.show(sparse=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Matmul (Simple)&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_76_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [[0. 0.]&#xA; [0. 0.]]&#xA;Spec : [[ 1  3]&#xA; [ 3 13]]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Test 2&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;SIZE = 8&#xA;out = np.zeros((SIZE, SIZE))&#xA;inp1 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE))&#xA;inp2 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE)).T&#xA;&#xA;problem = CudaProblem(&#xA;    &#34;Matmul (Full)&#34;,&#xA;    mm_oneblock_test,&#xA;    [inp1, inp2],&#xA;    out,&#xA;    [SIZE],&#xA;    Coord(3, 3),&#xA;    Coord(TPB, TPB),&#xA;    spec=matmul_spec,&#xA;)&#xA;problem.show(sparse=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Matmul (Full)&#xA; &#xA;   Score (Max Per Thread):&#xA;   |  Global Reads | Global Writes |  Shared Reads | Shared Writes |&#xA;   |             0 |             0 |             0 |             0 | &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/srush/GPU-Puzzles/main/GPU_puzzlers_files/GPU_puzzlers_79_1.svg?sanitize=true&#34; alt=&#34;svg&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;problem.check()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Failed Tests.&#xA;Yours: [[0. 0. 0. 0. 0. 0. 0. 0.]&#xA; [0. 0. 0. 0. 0. 0. 0. 0.]&#xA; [0. 0. 0. 0. 0. 0. 0. 0.]&#xA; [0. 0. 0. 0. 0. 0. 0. 0.]&#xA; [0. 0. 0. 0. 0. 0. 0. 0.]&#xA; [0. 0. 0. 0. 0. 0. 0. 0.]&#xA; [0. 0. 0. 0. 0. 0. 0. 0.]&#xA; [0. 0. 0. 0. 0. 0. 0. 0.]]&#xA;Spec : [[  140   364   588   812  1036  1260  1484  1708]&#xA; [  364  1100  1836  2572  3308  4044  4780  5516]&#xA; [  588  1836  3084  4332  5580  6828  8076  9324]&#xA; [  812  2572  4332  6092  7852  9612 11372 13132]&#xA; [ 1036  3308  5580  7852 10124 12396 14668 16940]&#xA; [ 1260  4044  6828  9612 12396 15180 17964 20748]&#xA; [ 1484  4780  8076 11372 14668 17964 21260 24556]&#xA; [ 1708  5516  9324 13132 16940 20748 24556 28364]]&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>macrozheng/springcloud-learning</title>
    <updated>2022-07-15T01:31:11Z</updated>
    <id>tag:github.com,2022-07-15:/macrozheng/springcloud-learning</id>
    <link href="https://github.com/macrozheng/springcloud-learning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;一套涵盖大部分核心组件使用的Spring Cloud教程，包括Spring Cloud Alibaba及分布式事务Seata，基于Spring Cloud Greenwich及SpringBoot 2.1.7。篇篇精华，涵盖大部分应用场景。&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;springcloud-learning&lt;/h1&gt; &#xA;&lt;p&gt; &lt;a href=&#34;#公众号&#34;&gt;&lt;img src=&#34;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/badge/%E5%85%AC%E4%BC%97%E5%8F%B7-macrozheng-blue.svg?sanitize=true&#34; alt=&#34;公众号&#34;&gt;&lt;/a&gt; &lt;a href=&#34;#公众号&#34;&gt;&lt;img src=&#34;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/badge/%E4%BA%A4%E6%B5%81-%E5%BE%AE%E4%BF%A1%E7%BE%A4-2BA245.svg?sanitize=true&#34; alt=&#34;交流&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/macrozheng/mall-swarm&#34;&gt;&lt;img src=&#34;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/badge/Cloud%E7%89%88%E6%9C%AC-mall--swarm-brightgreen.svg?sanitize=true&#34; alt=&#34;SpringCloud版本&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/macrozheng/mall&#34;&gt;&lt;img src=&#34;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/badge/%E5%90%8E%E5%8F%B0%E9%A1%B9%E7%9B%AE-mall-blue.svg?sanitize=true&#34; alt=&#34;后台项目&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/macrozheng/mall-admin-web&#34;&gt;&lt;img src=&#34;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/badge/%E5%89%8D%E7%AB%AF%E9%A1%B9%E7%9B%AE-mall--admin--web-green.svg?sanitize=true&#34; alt=&#34;前端项目&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;简介&lt;/h2&gt; &#xA;&lt;p&gt;一套涵盖大部分核心组件使用的Spring Cloud教程，包括Spring Cloud Alibaba及分布式事务Seata，基于Spring Cloud Greenwich及SpringBoot 2.1.7。24篇文章，篇篇精华，34个Demo，涵盖大部分应用场景。&lt;/p&gt; &#xA;&lt;h2&gt;目录&lt;/h2&gt; &#xA;&lt;h3&gt;概述&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/springcloud.html&#34;&gt;Spring Cloud 整体架构概览&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Spring Cloud 组件&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/eureka.html&#34;&gt;Spring Cloud Eureka：服务注册与发现&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/ribbon.html&#34;&gt;Spring Cloud Ribbon：负载均衡的服务调用&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/hystrix.html&#34;&gt;Spring Cloud Hystrix：服务容错保护&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/hystrix_dashboard.html&#34;&gt;Hystrix Dashboard：断路器执行监控&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/feign.html&#34;&gt;Spring Cloud OpenFeign：基于Ribbon和Hystrix的声明式服务调用&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/zuul.html&#34;&gt;Spring Cloud Zuul：API网关服务&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/config.html&#34;&gt;Spring Cloud Config：外部集中化配置管理&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/bus.html&#34;&gt;Spring Cloud Bus：消息总线&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/sleuth.html&#34;&gt;Spring Cloud Sleuth：分布式请求链路跟踪&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/consul.html&#34;&gt;Spring Cloud Consul：服务治理与配置中心&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/gateway.html&#34;&gt;Spring Cloud Gateway：新一代API网关服务&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Spring Cloud Alibaba&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/nacos.html&#34;&gt;Spring Cloud Alibaba：Nacos 作为注册中心和配置中心使用&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/sentinel.html&#34;&gt;Spring Cloud Alibaba：Sentinel实现熔断与限流&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/seata.html&#34;&gt;使用Seata彻底解决Spring Cloud中的分布式事务问题&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Spring Cloud Oauth2&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/oauth2.html&#34;&gt;Spring Cloud Security：Oauth2使用入门&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/oauth2_jwt.html&#34;&gt;Spring Cloud Security：Oauth2结合JWT使用&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/oauth2_sso.html&#34;&gt;Spring Cloud Security：Oauth2实现单点登录&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;微服务监控&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/admin.html&#34;&gt;Spring Boot Admin：微服务应用监控&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;微服务解决方案&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/gateway_oauth2.html&#34;&gt;微服务权限终极解决方案，Spring Cloud Gateway + Oauth2 实现统一认证和鉴权！&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/knife4j_cloud.html&#34;&gt;微服务聚合Swagger文档，这波操作是真的香！&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/oauth2_custom.html&#34;&gt;我扒了半天源码，终于找到了Oauth2自定义处理结果的最佳方案！&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/sa_token_cloud_start.html&#34;&gt;开箱即用！看看人家的微服务权限解决方案，那叫一个优雅！&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.macrozheng.com/cloud/retrofit_cloud.html&#34;&gt;再见Feign！推荐一款微服务间调用神器，跟SpringCloud绝配！&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;项目结构&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;springcloud-learning&#xA;├── eureka-server -- eureka注册中心&#xA;├── eureka-security-server -- 带登录认证的eureka注册中心&#xA;├── eureka-client -- eureka客户端&#xA;├── user-service -- 提供User对象CRUD接口的服务&#xA;├── ribbon-service -- ribbon服务调用测试服务&#xA;├── hystrix-service -- hystrix服务调用测试服务&#xA;├── turbine-service -- 聚合收集hystrix实例监控信息的服务&#xA;├── hystrix-dashboard -- 展示hystrix实例监控信息的仪表盘&#xA;├── feign-service -- feign服务调用测试服务&#xA;├── zuul-proxy -- zuul作为网关的测试服务&#xA;├── config-server -- 配置中心服务&#xA;├── config-security-server -- 带安全认证的配置中心服务&#xA;├── config-client -- 获取配置的客户端服务&#xA;├── consul-config-client -- 用于演示consul作为配置中心的consul客户端&#xA;├── consul-user-service -- 注册到consul的提供User对象CRUD接口的服务&#xA;├── consul-service -- 注册到consul的ribbon服务调用测试服务&#xA;├── api-gateway -- gateway作为网关的测试服务&#xA;├── admin-server -- admin监控中心服务&#xA;├── admin-client -- admin监控中心监控的应用服务&#xA;├── admin-security-server -- 带登录认证的admin监控中心服务&#xA;├── oauth2-server -- oauth2认证测试服务&#xA;├── oauth2-jwt-server -- 使用jwt的oauth2认证测试服务&#xA;├── oauth2-client -- 单点登录的oauth2客户端服务&#xA;├── nacos-config-client -- 用于演示nacos作为配置中心的nacos客户端&#xA;├── nacos-user-service -- 注册到nacos的提供User对象CRUD接口的服务&#xA;├── nacos-ribbon-service -- 注册到nacos的ribbon服务调用测试服务&#xA;├── sentinel-service -- sentinel功能测试服务&#xA;├── seata-order-service -- 整合了seata的订单服务&#xA;├── seata-storage-service -- 整合了seata的库存服务&#xA;├── seata-account-service -- 整合了seata的账户服务&#xA;├── micro-oauth2 -- Gateway + Oauth2 实现统一认证和鉴权&#xA;└── micro-knife4j -- Gateway + Knife4j聚合API文档&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;公众号&lt;/h2&gt; &#xA;&lt;p&gt;学习不走弯路，关注公众号「&lt;strong&gt;macrozheng&lt;/strong&gt;」，回复「&lt;strong&gt;学习路线&lt;/strong&gt;」，获取mall项目专属学习路线！&lt;/p&gt; &#xA;&lt;p&gt;加微信群交流，公众号后台回复「&lt;strong&gt;加群&lt;/strong&gt;」即可。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/banner/qrcode_for_macrozheng_258.jpg&#34; alt=&#34;公众号图片&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>