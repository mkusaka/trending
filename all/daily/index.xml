<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-11-07T01:28:19Z</updated>
  <subtitle>Daily Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>django/django</title>
    <updated>2024-11-07T01:28:19Z</updated>
    <id>tag:github.com,2024-11-07:/django/django</id>
    <link href="https://github.com/django/django" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Web framework for perfectionists with deadlines.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;====== Django&lt;/h1&gt; &#xA;&lt;p&gt;Django is a high-level Python web framework that encourages rapid development and clean, pragmatic design. Thanks for checking it out.&lt;/p&gt; &#xA;&lt;p&gt;All documentation is in the &#34;&lt;code&gt;docs&lt;/code&gt;&#34; directory and online at &lt;a href=&#34;https://docs.djangoproject.com/en/stable/&#34;&gt;https://docs.djangoproject.com/en/stable/&lt;/a&gt;. If you&#39;re just getting started, here&#39;s how we recommend you read the docs:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;First, read &lt;code&gt;docs/intro/install.txt&lt;/code&gt; for instructions on installing Django.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Next, work through the tutorials in order (&lt;code&gt;docs/intro/tutorial01.txt&lt;/code&gt;, &lt;code&gt;docs/intro/tutorial02.txt&lt;/code&gt;, etc.).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If you want to set up an actual deployment server, read &lt;code&gt;docs/howto/deployment/index.txt&lt;/code&gt; for instructions.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You&#39;ll probably want to read through the topical guides (in &lt;code&gt;docs/topics&lt;/code&gt;) next; from there you can jump to the HOWTOs (in &lt;code&gt;docs/howto&lt;/code&gt;) for specific problems, and check out the reference (&lt;code&gt;docs/ref&lt;/code&gt;) for gory details.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;See &lt;code&gt;docs/README&lt;/code&gt; for instructions on building an HTML version of the docs.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Docs are updated rigorously. If you find any problems in the docs, or think they should be clarified in any way, please take 30 seconds to fill out a ticket here: &lt;a href=&#34;https://code.djangoproject.com/newticket&#34;&gt;https://code.djangoproject.com/newticket&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;To get more help:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Join the &lt;code&gt;#django&lt;/code&gt; channel on &lt;code&gt;irc.libera.chat&lt;/code&gt;. Lots of helpful people hang out there. &lt;code&gt;Webchat is available &amp;lt;https://web.libera.chat/#django&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Join the django-users mailing list, or read the archives, at &lt;a href=&#34;https://groups.google.com/group/django-users&#34;&gt;https://groups.google.com/group/django-users&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Join the &lt;code&gt;Django Discord community &amp;lt;https://discord.gg/xcRH6mN4fa&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Join the community on the &lt;code&gt;Django Forum &amp;lt;https://forum.djangoproject.com/&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To contribute to Django:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Check out &lt;a href=&#34;https://docs.djangoproject.com/en/dev/internals/contributing/&#34;&gt;https://docs.djangoproject.com/en/dev/internals/contributing/&lt;/a&gt; for information about getting involved.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To run Django&#39;s test suite:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Follow the instructions in the &#34;Unit tests&#34; section of &lt;code&gt;docs/internals/contributing/writing-code/unit-tests.txt&lt;/code&gt;, published online at &lt;a href=&#34;https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/unit-tests/#running-the-unit-tests&#34;&gt;https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/unit-tests/#running-the-unit-tests&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Supporting the Development of Django&lt;/h1&gt; &#xA;&lt;p&gt;Django&#39;s development depends on your contributions.&lt;/p&gt; &#xA;&lt;p&gt;If you depend on Django, remember to support the Django Software Foundation: &lt;a href=&#34;https://www.djangoproject.com/fundraising/&#34;&gt;https://www.djangoproject.com/fundraising/&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>haydenbleasel/next-forge</title>
    <updated>2024-11-07T01:28:19Z</updated>
    <id>tag:github.com,2024-11-07:/haydenbleasel/next-forge</id>
    <link href="https://github.com/haydenbleasel/next-forge" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Production-grade Turborepo template for Next.js apps.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;next-forge&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Production-grade Turborepo template for Next.js apps.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/haydenbleasel/next-forge&#34;&gt;next-forge&lt;/a&gt; is a &lt;a href=&#34;https://nextjs.org/&#34;&gt;Next.js&lt;/a&gt; project boilerplate for modern web application. It is designed to be a comprehensive starting point for new apps, providing a solid, opinionated foundation with a minimal amount of configuration.&lt;/p&gt; &#xA;&lt;p&gt;Clone the repo using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;npx next-forge init [my-project]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then read the &lt;a href=&#34;https://www.next-forge.com/docs&#34;&gt;docs&lt;/a&gt; for more information.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>iterative/datachain</title>
    <updated>2024-11-07T01:28:19Z</updated>
    <id>tag:github.com,2024-11-07:/iterative/datachain</id>
    <link href="https://github.com/iterative/datachain" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AI-data warehouse to enrich, transform and analyze data from cloud storages&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;================ |logo| DataChain&lt;/h1&gt; &#xA;&lt;p&gt;|PyPI| |Python Version| |Codecov| |Tests|&lt;/p&gt; &#xA;&lt;p&gt;.. |logo| image:: docs/assets/datachain.svg :height: 24 .. |PyPI| image:: &lt;a href=&#34;https://img.shields.io/pypi/v/datachain.svg&#34;&gt;https://img.shields.io/pypi/v/datachain.svg&lt;/a&gt; :target: &lt;a href=&#34;https://pypi.org/project/datachain/&#34;&gt;https://pypi.org/project/datachain/&lt;/a&gt; :alt: PyPI .. |Python Version| image:: &lt;a href=&#34;https://img.shields.io/pypi/pyversions/datachain&#34;&gt;https://img.shields.io/pypi/pyversions/datachain&lt;/a&gt; :target: &lt;a href=&#34;https://pypi.org/project/datachain&#34;&gt;https://pypi.org/project/datachain&lt;/a&gt; :alt: Python Version .. |Codecov| image:: &lt;a href=&#34;https://codecov.io/gh/iterative/datachain/graph/badge.svg?token=byliXGGyGB&#34;&gt;https://codecov.io/gh/iterative/datachain/graph/badge.svg?token=byliXGGyGB&lt;/a&gt; :target: &lt;a href=&#34;https://codecov.io/gh/iterative/datachain&#34;&gt;https://codecov.io/gh/iterative/datachain&lt;/a&gt; :alt: Codecov .. |Tests| image:: &lt;a href=&#34;https://github.com/iterative/datachain/actions/workflows/tests.yml/badge.svg&#34;&gt;https://github.com/iterative/datachain/actions/workflows/tests.yml/badge.svg&lt;/a&gt; :target: &lt;a href=&#34;https://github.com/iterative/datachain/actions/workflows/tests.yml&#34;&gt;https://github.com/iterative/datachain/actions/workflows/tests.yml&lt;/a&gt; :alt: Tests&lt;/p&gt; &#xA;&lt;p&gt;DataChain is a modern Pythonic data-frame library designed for artificial intelligence. It is made to organize your unstructured data into datasets and wrangle it at scale on your local machine. Datachain does not abstract or hide the AI models and API calls, but helps to integrate them into the postmodern data stack.&lt;/p&gt; &#xA;&lt;h1&gt;Key Features&lt;/h1&gt; &#xA;&lt;p&gt;üìÇ &lt;strong&gt;Storage as a Source of Truth.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Process unstructured data without redundant copies from S3, GCP, Azure, and local file systems.&lt;/li&gt; &#xA; &lt;li&gt;Multimodal data support: images, video, text, PDFs, JSONs, CSVs, parquet.&lt;/li&gt; &#xA; &lt;li&gt;Unite files and metadata together into persistent, versioned, columnar datasets.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;üêç &lt;strong&gt;Python-friendly data pipelines.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Operate on Python objects and object fields.&lt;/li&gt; &#xA; &lt;li&gt;Built-in parallelization and out-of-memory compute without SQL or Spark.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;üß† &lt;strong&gt;Data Enrichment and Processing.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Generate metadata using local AI models and LLM APIs.&lt;/li&gt; &#xA; &lt;li&gt;Filter, join, and group by metadata. Search by vector embeddings.&lt;/li&gt; &#xA; &lt;li&gt;Pass datasets to Pytorch and Tensorflow, or export them back into storage.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;üöÄ &lt;strong&gt;Efficiency.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Parallelization, out-of-memory workloads and data caching.&lt;/li&gt; &#xA; &lt;li&gt;Vectorized operations on Python object fields: sum, count, avg, etc.&lt;/li&gt; &#xA; &lt;li&gt;Optimized vector search.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;.. code:: console&lt;/p&gt; &#xA;&lt;p&gt;$ pip install datachain&lt;/p&gt; &#xA;&lt;h1&gt;Selecting files using JSON metadata&lt;/h1&gt; &#xA;&lt;p&gt;A storage consists of images of cats and dogs (&lt;code&gt;dog.1048.jpg&lt;/code&gt;, &lt;code&gt;cat.1009.jpg&lt;/code&gt;), annotated with ground truth and model inferences in the &#39;json-pairs&#39; format, where each image has a matching JSON file like &lt;code&gt;cat.1009.json&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: json&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;{&#xA;    &#34;class&#34;: &#34;cat&#34;, &#34;id&#34;: &#34;1009&#34;, &#34;num_annotators&#34;: 8,&#xA;    &#34;inference&#34;: {&#34;class&#34;: &#34;dog&#34;, &#34;confidence&#34;: 0.68}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example of downloading only &#34;high-confidence cat&#34; inferred images using JSON metadata:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from datachain import Column, DataChain&#xA;&#xA;meta = DataChain.from_json(&#34;gs://datachain-demo/dogs-and-cats/*json&#34;, object_name=&#34;meta&#34;)&#xA;images = DataChain.from_storage(&#34;gs://datachain-demo/dogs-and-cats/*jpg&#34;)&#xA;&#xA;images_id = images.map(id=lambda file: file.path.split(&#39;.&#39;)[-2])&#xA;annotated = images_id.merge(meta, on=&#34;id&#34;, right_on=&#34;meta.id&#34;)&#xA;&#xA;likely_cats = annotated.filter((Column(&#34;meta.inference.confidence&#34;) &amp;gt; 0.93) \&#xA;                               &amp;amp; (Column(&#34;meta.inference.class_&#34;) == &#34;cat&#34;))&#xA;likely_cats.export_files(&#34;high-confidence-cats/&#34;, signal=&#34;file&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Data curation with a local AI model&lt;/h1&gt; &#xA;&lt;p&gt;Batch inference with a simple sentiment model using the &lt;code&gt;transformers&lt;/code&gt; library:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install transformers&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The code below downloads files the cloud, and applies a user-defined function to each one of them. All files with a positive sentiment detected are then copied to the local directory.&lt;/p&gt; &#xA;&lt;p&gt;.. code:: py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from transformers import pipeline&#xA;from datachain import DataChain, Column&#xA;&#xA;classifier = pipeline(&#34;sentiment-analysis&#34;, device=&#34;cpu&#34;,&#xA;                model=&#34;distilbert/distilbert-base-uncased-finetuned-sst-2-english&#34;)&#xA;&#xA;def is_positive_dialogue_ending(file) -&amp;gt; bool:&#xA;    dialogue_ending = file.read()[-512:]&#xA;    return classifier(dialogue_ending)[0][&#34;label&#34;] == &#34;POSITIVE&#34;&#xA;&#xA;chain = (&#xA;   DataChain.from_storage(&#34;gs://datachain-demo/chatbot-KiT/&#34;,&#xA;                          object_name=&#34;file&#34;, type=&#34;text&#34;)&#xA;   .settings(parallel=8, cache=True)&#xA;   .map(is_positive=is_positive_dialogue_ending)&#xA;   .save(&#34;file_response&#34;)&#xA;)&#xA;&#xA;positive_chain = chain.filter(Column(&#34;is_positive&#34;) == True)&#xA;positive_chain.export_files(&#34;./output&#34;)&#xA;&#xA;print(f&#34;{positive_chain.count()} files were exported&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;13 files were exported&lt;/p&gt; &#xA;&lt;p&gt;.. code:: shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ls output/datachain-demo/chatbot-KiT/&#xA;15.txt 20.txt 24.txt 27.txt 28.txt 29.txt 33.txt 37.txt 38.txt 43.txt ...&#xA;$ ls output/datachain-demo/chatbot-KiT/ | wc -l&#xA;13&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;LLM judging chatbots&lt;/h1&gt; &#xA;&lt;p&gt;LLMs can work as universal classifiers. In the example below, we employ a free API from Mistral to judge the &lt;code&gt;publicly available&lt;/code&gt;_ chatbot dialogs. Please get a free Mistral API key at &lt;a href=&#34;https://console.mistral.ai&#34;&gt;https://console.mistral.ai&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;.. code:: shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pip install mistralai (Requires version &amp;gt;=1.0.0)&#xA;$ export MISTRAL_API_KEY=_your_key_&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;DataChain can parallelize API calls; the free Mistral tier supports up to 4 requests at the same time.&lt;/p&gt; &#xA;&lt;p&gt;.. code:: py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from mistralai import Mistral&#xA;from datachain import File, DataChain, Column&#xA;&#xA;PROMPT = &#34;Was this dialog successful? Answer in a single word: Success or Failure.&#34;&#xA;&#xA;def eval_dialogue(file: File) -&amp;gt; bool:&#xA;     client = Mistral()&#xA;     response = client.chat.complete(&#xA;         model=&#34;open-mixtral-8x22b&#34;,&#xA;         messages=[{&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: PROMPT},&#xA;                   {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: file.read()}])&#xA;     result = response.choices[0].message.content&#xA;     return result.lower().startswith(&#34;success&#34;)&#xA;&#xA;chain = (&#xA;   DataChain.from_storage(&#34;gs://datachain-demo/chatbot-KiT/&#34;, object_name=&#34;file&#34;)&#xA;   .settings(parallel=4, cache=True)&#xA;   .map(is_success=eval_dialogue)&#xA;   .save(&#34;mistral_files&#34;)&#xA;)&#xA;&#xA;successful_chain = chain.filter(Column(&#34;is_success&#34;) == True)&#xA;successful_chain.export_files(&#34;./output_mistral&#34;)&#xA;&#xA;print(f&#34;{successful_chain.count()} files were exported&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;With the instruction above, the Mistral model considers 31/50 files to hold the successful dialogues:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ ls output_mistral/datachain-demo/chatbot-KiT/&#xA;1.txt  15.txt 18.txt 2.txt  22.txt 25.txt 28.txt 33.txt 37.txt 4.txt  41.txt ...&#xA;$ ls output_mistral/datachain-demo/chatbot-KiT/ | wc -l&#xA;31&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Serializing Python-objects&lt;/h1&gt; &#xA;&lt;p&gt;LLM responses may contain valuable information for analytics ‚Äì such as the number of tokens used, or the model performance parameters.&lt;/p&gt; &#xA;&lt;p&gt;Instead of extracting this information from the Mistral response data structure (class &lt;code&gt;ChatCompletionResponse&lt;/code&gt;), DataChain can serialize the entire LLM response to the internal DB:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from mistralai import Mistral&#xA;from mistralai.models import ChatCompletionResponse&#xA;from datachain import File, DataChain, Column&#xA;&#xA;PROMPT = &#34;Was this dialog successful? Answer in a single word: Success or Failure.&#34;&#xA;&#xA;def eval_dialog(file: File) -&amp;gt; ChatCompletionResponse:&#xA;     client = MistralClient()&#xA;     return client.chat(&#xA;         model=&#34;open-mixtral-8x22b&#34;,&#xA;         messages=[{&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: PROMPT},&#xA;                   {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: file.read()}])&#xA;&#xA;chain = (&#xA;   DataChain.from_storage(&#34;gs://datachain-demo/chatbot-KiT/&#34;, object_name=&#34;file&#34;)&#xA;   .settings(parallel=4, cache=True)&#xA;   .map(response=eval_dialog)&#xA;   .map(status=lambda response: response.choices[0].message.content.lower()[:7])&#xA;   .save(&#34;response&#34;)&#xA;)&#xA;&#xA;chain.select(&#34;file.name&#34;, &#34;status&#34;, &#34;response.usage&#34;).show(5)&#xA;&#xA;success_rate = chain.filter(Column(&#34;status&#34;) == &#34;success&#34;).count() / chain.count()&#xA;print(f&#34;{100*success_rate:.1f}% dialogs were successful&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;     file   status      response     response          response&#xA;     name                  usage        usage             usage&#xA;                   prompt_tokens total_tokens completion_tokens&#xA;0   1.txt  success           547          548                 1&#xA;1  10.txt  failure          3576         3578                 2&#xA;2  11.txt  failure           626          628                 2&#xA;3  12.txt  failure          1144         1182                38&#xA;4  13.txt  success          1100         1101                 1&#xA;&#xA;[Limited by 5 rows]&#xA;64.0% dialogs were successful&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Iterating over Python data structures&lt;/h1&gt; &#xA;&lt;p&gt;In the previous examples, datasets were saved in the embedded database (&lt;code&gt;SQLite&lt;/code&gt;_ in folder &lt;code&gt;.datachain&lt;/code&gt; of the working directory). These datasets were automatically versioned, and can be accessed using &lt;code&gt;DataChain.from_dataset(&#34;dataset_name&#34;)&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Here is how to retrieve a saved dataset and iterate over the objects:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;chain = DataChain.from_dataset(&#34;response&#34;)&#xA;&#xA;# Iterating one-by-one: support out-of-memory workflow&#xA;for file, response in chain.limit(5).collect(&#34;file&#34;, &#34;response&#34;):&#xA;    # verify the collected Python objects&#xA;    assert isinstance(response, ChatCompletionResponse)&#xA;&#xA;    status = response.choices[0].message.content[:7]&#xA;    tokens = response.usage.total_tokens&#xA;    print(f&#34;{file.get_uri()}: {status}, file size: {file.size}, tokens: {tokens}&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;gs://datachain-demo/chatbot-KiT/1.txt: Success, file size: 1776, tokens: 548&#xA;gs://datachain-demo/chatbot-KiT/10.txt: Failure, file size: 11576, tokens: 3578&#xA;gs://datachain-demo/chatbot-KiT/11.txt: Failure, file size: 2045, tokens: 628&#xA;gs://datachain-demo/chatbot-KiT/12.txt: Failure, file size: 3833, tokens: 1207&#xA;gs://datachain-demo/chatbot-KiT/13.txt: Success, file size: 3657, tokens: 1101&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Vectorized analytics over Python objects&lt;/h1&gt; &#xA;&lt;p&gt;Some operations can run inside the DB without deserialization. For instance, let&#39;s calculate the total cost of using the LLM APIs, assuming the Mixtral call costs $2 per 1M input tokens and $6 per 1M output tokens:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;chain = DataChain.from_dataset(&#34;mistral_dataset&#34;)&#xA;&#xA;cost = chain.sum(&#34;response.usage.prompt_tokens&#34;)*0.000002 \&#xA;           + chain.sum(&#34;response.usage.completion_tokens&#34;)*0.000006&#xA;print(f&#34;Spent ${cost:.2f} on {chain.count()} calls&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: shell&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Spent $0.08 on 50 calls&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;PyTorch data loader&lt;/h1&gt; &#xA;&lt;p&gt;Chain results can be exported or passed directly to PyTorch dataloader. For example, if we are interested in passing image and a label based on file name suffix, the following code will do it:&lt;/p&gt; &#xA;&lt;p&gt;.. code:: py&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from torch.utils.data import DataLoader&#xA;from transformers import CLIPProcessor&#xA;&#xA;from datachain import C, DataChain&#xA;&#xA;processor = CLIPProcessor.from_pretrained(&#34;openai/clip-vit-base-patch32&#34;)&#xA;&#xA;chain = (&#xA;    DataChain.from_storage(&#34;gs://datachain-demo/dogs-and-cats/&#34;, type=&#34;image&#34;)&#xA;    .map(label=lambda name: name.split(&#34;.&#34;)[0], params=[&#34;file.name&#34;])&#xA;    .select(&#34;file&#34;, &#34;label&#34;).to_pytorch(&#xA;        transform=processor.image_processor,&#xA;        tokenizer=processor.tokenizer,&#xA;    )&#xA;)&#xA;loader = DataLoader(chain, batch_size=1)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Tutorials&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Getting Started&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Multimodal &amp;lt;https://github.com/iterative/datachain-examples/blob/main/multimodal/clip_fine_tuning.ipynb&amp;gt;&lt;/code&gt;_ (try in &lt;code&gt;Colab &amp;lt;https://colab.research.google.com/github/iterative/datachain-examples/blob/main/multimodal/clip_fine_tuning.ipynb&amp;gt;&lt;/code&gt;__)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;LLM evaluations &amp;lt;https://github.com/iterative/datachain-examples/blob/main/llm/llm_chatbot_evaluation.ipynb&amp;gt;&lt;/code&gt;_ (try in &lt;code&gt;Colab &amp;lt;https://colab.research.google.com/github/iterative/datachain-examples/blob/main/llm/llm_chatbot_evaluation.ipynb&amp;gt;&lt;/code&gt;__)&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Reading JSON metadata &amp;lt;https://github.com/iterative/datachain-examples/blob/main/formats/json-metadata-tutorial.ipynb&amp;gt;&lt;/code&gt;_ (try in &lt;code&gt;Colab &amp;lt;https://colab.research.google.com/github/iterative/datachain-examples/blob/main/formats/json-metadata-tutorial.ipynb&amp;gt;&lt;/code&gt;__)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributions&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are very welcome. To learn more, see the &lt;code&gt;Contributor Guide&lt;/code&gt;_.&lt;/p&gt; &#xA;&lt;h2&gt;Community and Support&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Docs &amp;lt;https://datachain.dvc.ai/&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;File an issue&lt;/code&gt;_ if you encounter any problems&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Discord Chat &amp;lt;https://dvc.org/chat&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Email &amp;lt;mailto:support@dvc.org&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Twitter &amp;lt;https://twitter.com/DVCorg&amp;gt;&lt;/code&gt;_&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;.. _PyPI: &lt;a href=&#34;https://pypi.org/&#34;&gt;https://pypi.org/&lt;/a&gt; .. _file an issue: &lt;a href=&#34;https://github.com/iterative/datachain/issues&#34;&gt;https://github.com/iterative/datachain/issues&lt;/a&gt; .. github-only .. _Contributor Guide: CONTRIBUTING.rst .. _Pydantic: &lt;a href=&#34;https://github.com/pydantic/pydantic&#34;&gt;https://github.com/pydantic/pydantic&lt;/a&gt; .. _publicly available: &lt;a href=&#34;https://radar.kit.edu/radar/en/dataset/FdJmclKpjHzLfExE.ExpBot%2B-%2BA%2Bdataset%2Bof%2B79%2Bdialogs%2Bwith%2Ban%2Bexperimental%2Bcustomer%2Bservice%2Bchatbot&#34;&gt;https://radar.kit.edu/radar/en/dataset/FdJmclKpjHzLfExE.ExpBot%2B-%2BA%2Bdataset%2Bof%2B79%2Bdialogs%2Bwith%2Ban%2Bexperimental%2Bcustomer%2Bservice%2Bchatbot&lt;/a&gt; .. _SQLite: &lt;a href=&#34;https://www.sqlite.org/&#34;&gt;https://www.sqlite.org/&lt;/a&gt; .. _Getting Started: &lt;a href=&#34;https://datachain.dvc.ai/&#34;&gt;https://datachain.dvc.ai/&lt;/a&gt; .. |Flowchart| image:: &lt;a href=&#34;https://github.com/iterative/datachain/raw/main/docs/assets/flowchart.png?raw=true&#34;&gt;https://github.com/iterative/datachain/blob/main/docs/assets/flowchart.png?raw=true&lt;/a&gt; :alt: DataChain FlowChart&lt;/p&gt;</summary>
  </entry>
</feed>