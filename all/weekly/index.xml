<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub All Languages Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-09-17T01:44:30Z</updated>
  <subtitle>Weekly Trending of All Languages in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ECTO-1A/AppleJuice</title>
    <updated>2023-09-17T01:44:30Z</updated>
    <id>tag:github.com,2023-09-17:/ECTO-1A/AppleJuice</id>
    <link href="https://github.com/ECTO-1A/AppleJuice" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Apple BLE proximity pairing message spoofing&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AppleJuice&lt;/h1&gt; &#xA;&lt;h4&gt;Apple BLE Proximity Pairing Message Spoofing&lt;/h4&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;h3&gt;&lt;span&gt;üî¥&lt;/span&gt; Disclaimer&lt;/h3&gt; &#xA; &lt;p&gt;These scripts are an experimental PoC that uses Bluetooth Low Energy (BLE) to send proximity pairing messages to Apple devices.&lt;br&gt; This project is created for educational purposes and cannot be used for law violation or personal gain. The author of this project is not responsible for any possible harm caused by the materials of this project.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Updates&lt;/h2&gt; &#xA;&lt;h3&gt;After &lt;a href=&#34;https://techcrunch.com/2023/09/05/flipper-zero-hacking-iphone-flood-popups/&#34;&gt;Techryptic&#39;s attempt to steal the work of myself and WillyJL&lt;/a&gt;, Willy has taken the time to give an insanely in-depth timeline of the events and proof of the work being stolen (Git and my typos dont lie!) Check out the full report below and please help us spread the word that the person who has been all over the news outlets claiming this as their work, stole the code and gave none of the actual developers credit.&lt;br&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://willyjl.dev/blog/the-controversy-behind-apple-ble-spam&#34;&gt;The Controversy Behind Apple BLE Spam&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;Flipper Zero&lt;/h3&gt; &#xA;&lt;p&gt;Thanks to the amazing work of &lt;a href=&#34;https://github.com/Willy-JL/Willy-JL&#34;&gt;Willy-JL&lt;/a&gt; this has been added to the &lt;a href=&#34;https://github.com/Flipper-XFW/Xtreme-Firmware&#34;&gt;Flipper Zero Xtreme Firmware&lt;/a&gt;. It&#39;s currently in dev and will be officially released in the next update.&lt;/p&gt; &#xA;&lt;h4&gt;To install it now, follow the guide below from the Xtreme Firmware page to clone and compile the current dev build that contains the Apple BLE Spam app.&lt;/h4&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; &lt;strong&gt;Warning!&lt;/strong&gt; &lt;br&gt; We will not give basic support for compiling in our server. This is intended for people that already &lt;em&gt;know&lt;/em&gt; what they are doing!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;To download the needed tools:&#xA;$ git clone --recursive --jobs 8 https://github.com/Flipper-XFW/Xtreme-Firmware.git&#xA;$ cd Xtreme-Firmware/&#xA;&#xA;To flash directly to the Flipper (Needs to be connected via USB, qFlipper closed)&#xA;$ ./fbt flash_usb_full&#xA;&#xA;To compile a TGZ package&#xA;$ ./fbt updater_package&#xA;&#xA;To build and launch a single app:&#xA;$ ./fbt launch APPSRC=some_appid&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;ESP-32&lt;/h3&gt; &#xA;&lt;p&gt;Thanks to &lt;a href=&#34;https://github.com/ronaldstoner&#34;&gt;ronaldstoner&lt;/a&gt; for porting this over to the ESP-32&lt;/p&gt; &#xA;&lt;h3&gt;Android&lt;/h3&gt; &#xA;&lt;p&gt;Check out this in-depth walk though by &lt;a href=&#34;https://www.mobile-hacker.com/2023/09/07/spoof-ios-devices-with-bluetooth-pairing-messages-using-android/&#34;&gt;Mobile Hacker&lt;/a&gt; about running AppleJuice on a rooted Android phone.&lt;/p&gt; &#xA;&lt;h2&gt;About This Project&lt;/h2&gt; &#xA;&lt;p&gt;This was created in response to the various AppleTV spoof messages being sent out during &lt;a href=&#34;https://techcrunch.com/2023/08/14/researcher-says-they-were-behind-iphone-popups-at-def-con/&#34;&gt;DEF CON 31&lt;/a&gt;. After experiencing it first hand, I had to figure out what was happening. The existing research projects I could find (see &lt;em&gt;credits&lt;/em&gt;) had great info but were both a couple years out of date with broken package dependencies, so I decided to take what I could from them and start building from there.&lt;/p&gt; &#xA;&lt;h2&gt;Hardware Requirements&lt;/h2&gt; &#xA;&lt;p&gt;To run these scripts you need a Linux machine with an internal Bluetooth card or a USB Bluetooth adapter.&lt;/p&gt; &#xA;&lt;p&gt;All original testing was done on a Lenovo T480 with a built-in Bluetooth adapter.&lt;br&gt; Later tested on Raspberry Pi 3B+ and Raspberry Pi Zero W running Kali Linux with a &lt;a href=&#34;https://zexmte.com/collections/bluetooth-adapter/products/plug-play-long-range-bluetooth-5-1-usb-adapter&#34;&gt;Zexmte Long Range USB Bluetooth 5.1 Adapter with Dual Antenna&lt;/a&gt;.&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/ECTO-1A/AppleJuice/assets/112792126/a6f2b9fa-ca26-45c1-a440-681beb55c76e&#34; width=&#34;300&#34;&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Range&lt;/strong&gt; &lt;br&gt; Range of messages by device type&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Device&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Range&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Lenovo&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Couple feet from machine&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Raspberry Pi and long range adapter&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;20+ feet indoors in heavy BLE traffic&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Installation Instructions&lt;/h2&gt; &#xA;&lt;p&gt;Please follow in this exact order or you might run into issues with bluetooth dependencies.&lt;/p&gt; &#xA;&lt;h3&gt;Clone the Main Repo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/ECTO-1A/AppleJuice.git &amp;amp;&amp;amp; cd ./AppleJuice&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Install dependencies&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt update &amp;amp;&amp;amp; sudo apt install -y bluez libpcap-dev libev-dev libnl-3-dev libnl-genl-3-dev libnl-route-3-dev cmake libbluetooth-dev&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Dependencies requiring manual installation&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; &lt;strong&gt;Warning&lt;/strong&gt; &lt;br&gt; The &lt;code&gt;pybluez&lt;/code&gt; library is broken on GitHub and needs to be installed manually&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Download the latest version &#xA;pip install git+https://github.com/pybluez/pybluez.git#egg=pybluez&#xA;&#xA;pycrypto is not maintained, be sure to install pycryptodome instead &#xA;pip install pycryptodome&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Install requirements&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Execute scripts without &lt;code&gt;sudo&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;To be able to run without sudo, you need to set the capabilities of the python binary to allow it to access raw sockets. This is done with the following command&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo setcap cap_net_raw,cap_net_admin+eip $(eval readlink -f $(which python))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Reboot Machine&lt;/h3&gt; &#xA;&lt;p&gt;Several users have reported the need for a reboot after installing the bluetooth packages in order for everything to work properly.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h4&gt;Before running the script, check that your Bluetooth adapter is connected and showing as &lt;code&gt;hci0&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;p&gt;Run &lt;code&gt;hcitool dev&lt;/code&gt; to get a list of connected adapters&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hcitool dev&#xA;Devices:&#xA;    hci0    00:00:7C:00:3A:13&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;span&gt;üìù&lt;/span&gt; &lt;strong&gt;Note&lt;/strong&gt; &lt;br&gt; If the adapter is showing as &lt;code&gt;hci1&lt;/code&gt; you will need to edit the &lt;code&gt;dev_id&lt;/code&gt; variable in the scripts to match&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;Available options&lt;/h3&gt; &#xA;&lt;p&gt;All messages have been combined into a single app. You can now run &lt;code&gt;app.py&lt;/code&gt; to get a list of available options.&lt;br&gt; To run the script use &lt;code&gt;-d (number of message)&lt;/code&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt; &lt;br&gt; &lt;code&gt;app.py -d 13&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python3 app.py&#xA;Please select a message option using -d.&#xA;Available message options:&#xA;1: Airpods&#xA;2: Airpods Pro&#xA;3: Airpods Max&#xA;4: Airpods Gen 2&#xA;5: Airpods Gen 3&#xA;6: Airpods Pro Gen 2&#xA;7: PowerBeats&#xA;8: PowerBeats Pro&#xA;9: Beats Solo Pro&#xA;10: Beats Studio Buds&#xA;11: Beats Flex&#xA;12: BeatsX&#xA;13: Beats Solo3&#xA;14: Beats Studio3&#xA;15: Beats Studio Pro&#xA;16: Beats Fit Pro&#xA;17: Beats Studio Buds+&#xA;18: AppleTV Setup&#xA;19: AppleTV Pair&#xA;20: AppleTV New User&#xA;21: AppleTV AppleID Setup&#xA;22: AppleTV Wireless Audio Sync&#xA;23: AppleTV Homekit Setup&#xA;24: AppleTV Keyboard&#xA;25: AppleTV &#39;Connecting to Network&#39;&#xA;26: Homepod Setup&#xA;27: Setup New Phone&#xA;28: Transfer Number to New Phone&#xA;29: TV Color Balance&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;beatssolopro.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Model&lt;/strong&gt;: Beats Solo Pro&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;img src=&#34;https://github.com/ECTO-1A/AppleJuice/assets/112792126/c3218a09-7aef-483b-957d-f3c19a55fc08&#34; width=&#34;300&#34;&gt; &#xA;&lt;p&gt;&lt;code&gt;airpods_max.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;Model&lt;/strong&gt;: Airpods Max&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;img src=&#34;https://github.com/ECTO-1A/AppleJuice/assets/112792126/5eea40e8-d7c1-4324-9f3d-1425228d0458&#34; width=&#34;300&#34;&gt; &#xA;&lt;h3&gt;Credit&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/furiousMAC/continuity&#34;&gt;FuriousMAC&lt;/a&gt; and &lt;a href=&#34;https://github.com/hexway/apple_bleee&#34;&gt;Hexway&lt;/a&gt; for all the prior research on Apple BLE, Continuity, and building the Wireshark disector.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://infosec.exchange/@jb0x168/110879394826675242&#34;&gt;Jae Bochs&lt;/a&gt; for &lt;a href=&#34;https://techcrunch.com/2023/08/14/researcher-says-they-were-behind-iphone-popups-at-def-con/&#34;&gt;exposing this to me at DEF CON 31&lt;/a&gt; which made me jump into learning about BLE.&lt;/li&gt; &#xA; &lt;li&gt;Guillaume Celosia and Mathieu Cunche for reverse engineering &lt;a href=&#34;https://petsymposium.org/2020/files/papers/issue1/popets-2020-0003.pdf%22&#34;&gt;Proximity Pairing&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>godotengine/godot</title>
    <updated>2023-09-17T01:44:30Z</updated>
    <id>tag:github.com,2023-09-17:/godotengine/godot</id>
    <link href="https://github.com/godotengine/godot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Godot Engine ‚Äì Multi-platform 2D and 3D game engine&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Godot Engine&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://godotengine.org&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/godotengine/godot/master/logo_outlined.svg?sanitize=true&#34; width=&#34;400&#34; alt=&#34;Godot Engine logo&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h2&gt;2D and 3D cross-platform game engine&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://godotengine.org&#34;&gt;Godot Engine&lt;/a&gt; is a feature-packed, cross-platform game engine to create 2D and 3D games from a unified interface.&lt;/strong&gt; It provides a comprehensive set of &lt;a href=&#34;https://godotengine.org/features&#34;&gt;common tools&lt;/a&gt;, so that users can focus on making games without having to reinvent the wheel. Games can be exported with one click to a number of platforms, including the major desktop platforms (Linux, macOS, Windows), mobile platforms (Android, iOS), as well as Web-based platforms and &lt;a href=&#34;https://docs.godotengine.org/en/latest/tutorials/platform/consoles.html&#34;&gt;consoles&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Free, open source and community-driven&lt;/h2&gt; &#xA;&lt;p&gt;Godot is completely free and open source under the very permissive &lt;a href=&#34;https://godotengine.org/license&#34;&gt;MIT license&lt;/a&gt;. No strings attached, no royalties, nothing. The users&#39; games are theirs, down to the last line of engine code. Godot&#39;s development is fully independent and community-driven, empowering users to help shape their engine to match their expectations. It is supported by the &lt;a href=&#34;https://sfconservancy.org/&#34;&gt;Software Freedom Conservancy&lt;/a&gt; not-for-profit.&lt;/p&gt; &#xA;&lt;p&gt;Before being open sourced in &lt;a href=&#34;https://github.com/godotengine/godot/commit/0b806ee0fc9097fa7bda7ac0109191c9c5e0a1ac&#34;&gt;February 2014&lt;/a&gt;, Godot had been developed by &lt;a href=&#34;https://github.com/reduz&#34;&gt;Juan Linietsky&lt;/a&gt; and &lt;a href=&#34;https://github.com/punto-&#34;&gt;Ariel Manzur&lt;/a&gt; (both still maintaining the project) for several years as an in-house engine, used to publish several work-for-hire titles.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/godotengine/godot-design/master/screenshots/editor_tps_demo_1920x1080.jpg&#34; alt=&#34;Screenshot of a 3D scene in the Godot Engine editor&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Getting the engine&lt;/h2&gt; &#xA;&lt;h3&gt;Binary downloads&lt;/h3&gt; &#xA;&lt;p&gt;Official binaries for the Godot editor and the export templates can be found &lt;a href=&#34;https://godotengine.org/download&#34;&gt;on the homepage&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Compiling from source&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://docs.godotengine.org/en/latest/contributing/development/compiling&#34;&gt;See the official docs&lt;/a&gt; for compilation instructions for every supported platform.&lt;/p&gt; &#xA;&lt;h2&gt;Community and contributing&lt;/h2&gt; &#xA;&lt;p&gt;Godot is not only an engine but an ever-growing community of users and engine developers. The main community channels are listed &lt;a href=&#34;https://godotengine.org/community&#34;&gt;on the homepage&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The best way to get in touch with the core engine developers is to join the &lt;a href=&#34;https://chat.godotengine.org&#34;&gt;Godot Contributors Chat&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To get started contributing to the project, see the &lt;a href=&#34;https://raw.githubusercontent.com/godotengine/godot/master/CONTRIBUTING.md&#34;&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation and demos&lt;/h2&gt; &#xA;&lt;p&gt;The official documentation is hosted on &lt;a href=&#34;https://docs.godotengine.org&#34;&gt;Read the Docs&lt;/a&gt;. It is maintained by the Godot community in its own &lt;a href=&#34;https://github.com/godotengine/godot-docs&#34;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://docs.godotengine.org/en/latest/classes/&#34;&gt;class reference&lt;/a&gt; is also accessible from the Godot editor.&lt;/p&gt; &#xA;&lt;p&gt;We also maintain official demos in their own &lt;a href=&#34;https://github.com/godotengine/godot-demo-projects&#34;&gt;GitHub repository&lt;/a&gt; as well as a list of &lt;a href=&#34;https://github.com/godotengine/awesome-godot&#34;&gt;awesome Godot community resources&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;There are also a number of other &lt;a href=&#34;https://docs.godotengine.org/en/latest/community/tutorials.html&#34;&gt;learning resources&lt;/a&gt; provided by the community, such as text and video tutorials, demos, etc. Consult the &lt;a href=&#34;https://godotengine.org/community&#34;&gt;community channels&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.codetriage.com/godotengine/godot&#34;&gt;&lt;img src=&#34;https://www.codetriage.com/godotengine/godot/badges/users.svg?sanitize=true&#34; alt=&#34;Code Triagers Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hosted.weblate.org/engage/godot-engine/?utm_source=widget&#34;&gt;&lt;img src=&#34;https://hosted.weblate.org/widgets/godot-engine/-/godot/svg-badge.svg?sanitize=true&#34; alt=&#34;Translate on Weblate&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.tickgit.com/browse?repo=github.com/godotengine/godot&#34;&gt;&lt;img src=&#34;https://badgen.net/https/api.tickgit.com/badgen/github.com/godotengine/godot&#34; alt=&#34;TODOs&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>guoyww/AnimateDiff</title>
    <updated>2023-09-17T01:44:30Z</updated>
    <id>tag:github.com,2023-09-17:/guoyww/AnimateDiff</id>
    <link href="https://github.com/guoyww/AnimateDiff" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official implementation of AnimateDiff.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AnimateDiff&lt;/h1&gt; &#xA;&lt;p&gt;This repository is the official implementation of &lt;a href=&#34;https://arxiv.org/abs/2307.04725&#34;&gt;AnimateDiff&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2307.04725&#34;&gt;AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning&lt;/a&gt;&lt;/strong&gt; &lt;br&gt; Yuwei Guo, Ceyuan Yang*, Anyi Rao, Yaohui Wang, Yu Qiao, Dahua Lin, Bo Dai&lt;/p&gt; &#xA;&lt;p style=&#34;font-size: 0.8em; margin-top: -1em&#34;&gt;*Corresponding Author&lt;/p&gt; &#xA;&lt;!-- [Arxiv Report](https://arxiv.org/abs/2307.04725) | [Project Page](https://animatediff.github.io/) --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2307.04725&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2307.04725-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://animatediff.github.io/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project-Website-green&#34; alt=&#34;Project Page&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://openxlab.org.cn/apps/detail/Masbfca/AnimateDiff&#34;&gt;&lt;img src=&#34;https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg?sanitize=true&#34; alt=&#34;Open in OpenXLab&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/guoyww/AnimateDiff&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-yellow&#34; alt=&#34;Hugging Face Spaces&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023/09/10]&lt;/strong&gt; New Motion Module release ! &lt;code&gt;mm_sd_v15_v2.ckpt&lt;/code&gt; was trained on larger resolution &amp;amp; batch size, and gains noticabe quality improvements.Check it out at &lt;a href=&#34;https://drive.google.com/drive/folders/1EqLC65eR1-W-sGD0Im7fkED6c8GkiNFI?usp=sharing&#34;&gt;Google Drive&lt;/a&gt; / &lt;a href=&#34;https://huggingface.co/guoyww/animatediff&#34;&gt;HuggingFace&lt;/a&gt; and use it with &lt;code&gt;configs/inference/inference-v2.yaml&lt;/code&gt;. Example: &lt;pre&gt;&lt;code&gt;python -m scripts.animate --config configs/prompts/v2/5-RealisticVision.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; Here is a qualitative comparison between &lt;code&gt;mm_sd_v15.ckpt&lt;/code&gt; (left) and &lt;code&gt;mm_sd_v15_v2.ckpt&lt;/code&gt; (right): &#xA;  &lt;table class=&#34;center&#34;&gt; &#xA;   &lt;tbody&gt;&#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/compare/old_0.gif&#34;&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/compare/new_0.gif&#34;&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/compare/old_1.gif&#34;&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/compare/new_1.gif&#34;&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/compare/old_2.gif&#34;&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/compare/new_2.gif&#34;&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/compare/old_3.gif&#34;&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/compare/new_3.gif&#34;&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt;&#xA;  &lt;/table&gt; &lt;/li&gt; &#xA; &lt;li&gt;GPU Memory Optimization, ~12GB VRAM to inference&lt;/li&gt; &#xA; &lt;li&gt;User Interface: &lt;a href=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/#gradio-demo&#34;&gt;Gradio&lt;/a&gt;, A1111 WebUI Extension &lt;a href=&#34;https://github.com/continue-revolution/sd-webui-animatediff&#34;&gt;sd-webui-animatediff&lt;/a&gt; (by &lt;a href=&#34;https://github.com/continue-revolution&#34;&gt;@continue-revolution&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Google Colab: &lt;a href=&#34;https://colab.research.google.com/github/camenduru/AnimateDiff-colab/blob/main/AnimateDiff_colab.ipynb&#34;&gt;Colab&lt;/a&gt; (by &lt;a href=&#34;https://github.com/camenduru&#34;&gt;@camenduru&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Common Issues&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Installation&lt;/summary&gt; &#xA; &lt;p&gt;Please ensure the installation of &lt;a href=&#34;https://github.com/facebookresearch/xformers&#34;&gt;xformer&lt;/a&gt; that is applied to reduce the inference memory.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Various resolution or number of frames&lt;/summary&gt; Currently, we recommend users to generate animation with 16 frames and 512 resolution that are aligned with our training settings. Notably, various resolution/frames may affect the quality more or less. &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;How to use it without any coding&lt;/summary&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt; &lt;p&gt;Get lora models: train lora model with &lt;a href=&#34;https://github.com/continue-revolution/sd-webui-animatediff&#34;&gt;A1111&lt;/a&gt; based on a collection of your own favorite images (e.g., tutorials &lt;a href=&#34;https://www.youtube.com/watch?v=mfaqqL5yOO4&#34;&gt;English&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=N1tXVR9lplM&#34;&gt;Japanese&lt;/a&gt;, &lt;a href=&#34;https://www.bilibili.com/video/BV1fs4y1x7p2/&#34;&gt;Chinese&lt;/a&gt;) or download Lora models from &lt;a href=&#34;https://civitai.com/&#34;&gt;Civitai&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Animate lora models: using gradio interface or A1111 (e.g., tutorials &lt;a href=&#34;https://github.com/continue-revolution/sd-webui-animatediff&#34;&gt;English&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=zss3xbtvOWw&#34;&gt;Japanese&lt;/a&gt;, &lt;a href=&#34;https://941ai.com/sd-animatediff-webui-1203.html&#34;&gt;Chinese&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;Be creative togther with other techniques, such as, super resolution, frame interpolation, music generation, etc.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ol&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Animating a given image&lt;/summary&gt; &#xA; &lt;p&gt;We totally agree that animating a given image is an appealing feature, which we would try to support officially in future. For now, you may enjoy other efforts from the &lt;a href=&#34;https://github.com/talesofai/AnimateDiff&#34;&gt;talesofai&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Contributions from community&lt;/summary&gt; Contributions are always welcome!! The &#xA; &lt;code&gt;dev&lt;/code&gt; branch is for community contributions. As for the main branch, we would like to align it with the original technical report :) &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Setups for Inference&lt;/h2&gt; &#xA;&lt;h3&gt;Prepare Environment&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;We updated our inference code with xformers and a sequential decoding trick. Now AnimateDiff takes only ~12GB VRAM to inference, and run on a single RTX3090 !!&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/guoyww/AnimateDiff.git&#xA;cd AnimateDiff&#xA;&#xA;conda env create -f environment.yaml&#xA;conda activate animatediff&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Download Base T2I &amp;amp; Motion Module Checkpoints&lt;/h3&gt; &#xA;&lt;p&gt;We provide two versions of our Motion Module, which are trained on stable-diffusion-v1-4 and finetuned on v1-5 seperately. It&#39;s recommanded to try both of them for best results.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git lfs install&#xA;git clone https://huggingface.co/runwayml/stable-diffusion-v1-5 models/StableDiffusion/&#xA;&#xA;bash download_bashscripts/0-MotionModule.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may also directly download the motion module checkpoints from &lt;a href=&#34;https://drive.google.com/drive/folders/1EqLC65eR1-W-sGD0Im7fkED6c8GkiNFI?usp=sharing&#34;&gt;Google Drive&lt;/a&gt; / &lt;a href=&#34;https://huggingface.co/guoyww/animatediff&#34;&gt;HuggingFace&lt;/a&gt; / &lt;a href=&#34;https://civitai.com/models/108836&#34;&gt;CivitAI&lt;/a&gt;, then put them in &lt;code&gt;models/Motion_Module/&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;h3&gt;Prepare Personalize T2I&lt;/h3&gt; &#xA;&lt;p&gt;Here we provide inference configs for 6 demo T2I on CivitAI. You may run the following bash scripts to download these checkpoints.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;bash download_bashscripts/1-ToonYou.sh&#xA;bash download_bashscripts/2-Lyriel.sh&#xA;bash download_bashscripts/3-RcnzCartoon.sh&#xA;bash download_bashscripts/4-MajicMix.sh&#xA;bash download_bashscripts/5-RealisticVision.sh&#xA;bash download_bashscripts/6-Tusun.sh&#xA;bash download_bashscripts/7-FilmVelvia.sh&#xA;bash download_bashscripts/8-GhibliBackground.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Inference&lt;/h3&gt; &#xA;&lt;p&gt;After downloading the above peronalized T2I checkpoints, run the following commands to generate animations. The results will automatically be saved to &lt;code&gt;samples/&lt;/code&gt; folder.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m scripts.animate --config configs/prompts/1-ToonYou.yaml&#xA;python -m scripts.animate --config configs/prompts/2-Lyriel.yaml&#xA;python -m scripts.animate --config configs/prompts/3-RcnzCartoon.yaml&#xA;python -m scripts.animate --config configs/prompts/4-MajicMix.yaml&#xA;python -m scripts.animate --config configs/prompts/5-RealisticVision.yaml&#xA;python -m scripts.animate --config configs/prompts/6-Tusun.yaml&#xA;python -m scripts.animate --config configs/prompts/7-FilmVelvia.yaml&#xA;python -m scripts.animate --config configs/prompts/8-GhibliBackground.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To generate animations with a new DreamBooth/LoRA model, you may create a new config &lt;code&gt;.yaml&lt;/code&gt; file in the following format:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;NewModel:&#xA;  path: &#34;[path to your DreamBooth/LoRA model .safetensors file]&#34;&#xA;  base: &#34;[path to LoRA base model .safetensors file, leave it empty string if not needed]&#34;&#xA;&#xA;  motion_module:&#xA;    - &#34;models/Motion_Module/mm_sd_v14.ckpt&#34;&#xA;    - &#34;models/Motion_Module/mm_sd_v15.ckpt&#34;&#xA;    &#xA;  steps:          25&#xA;  guidance_scale: 7.5&#xA;&#xA;  prompt:&#xA;    - &#34;[positive prompt]&#34;&#xA;&#xA;  n_prompt:&#xA;    - &#34;[negative prompt]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then run the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m scripts.animate --config [path to the config file]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Steps for Training&lt;/h2&gt; &#xA;&lt;h3&gt;Dataset&lt;/h3&gt; &#xA;&lt;p&gt;Before training, download the videos files and the &lt;code&gt;.csv&lt;/code&gt; annotations of &lt;a href=&#34;https://maxbain.com/webvid-dataset/&#34;&gt;WebVid10M&lt;/a&gt; to the local mechine. Note that our examplar training script requires all the videos to be saved in a single folder. You may change this by modifying &lt;code&gt;animatediff/data/dataset.py&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Configuration&lt;/h3&gt; &#xA;&lt;p&gt;After dataset preparations, update the below data paths in the config &lt;code&gt;.yaml&lt;/code&gt; files in &lt;code&gt;configs/training/&lt;/code&gt; folder:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;train_data:&#xA;  csv_path:     [Replace with .csv Annotation File Path]&#xA;  video_folder: [Replace with Video Folder Path]&#xA;  sample_size:  256&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Other training parameters (lr, epochs, validation settings, etc.) are also included in the config files.&lt;/p&gt; &#xA;&lt;h3&gt;Training&lt;/h3&gt; &#xA;&lt;p&gt;To train motion modules&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;torchrun --nnodes=1 --nproc_per_node=1 train.py --config configs/training/training.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To finetune the unet&#39;s image layers&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;torchrun --nnodes=1 --nproc_per_node=1 train.py --config configs/training/image_finetune.yaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Gradio Demo&lt;/h2&gt; &#xA;&lt;p&gt;We have created a Gradio demo to make AnimateDiff easier to use. To launch the demo, please run the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda activate animatediff&#xA;python app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, the demo will run at &lt;code&gt;localhost:7860&lt;/code&gt;. &lt;br&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/figs/gradio.jpg&#34; style=&#34;width: 50em; margin-top: 1em&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Gallery&lt;/h2&gt; &#xA;&lt;p&gt;Here we demonstrate several best results we found in our experiments.&lt;/p&gt; &#xA;&lt;table class=&#34;center&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_01/01.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_01/02.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_01/03.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_01/04.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p style=&#34;margin-left: 2em; margin-top: -1em&#34;&gt;ModelÔºö&lt;a href=&#34;https://civitai.com/models/30240/toonyou&#34;&gt;ToonYou&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_02/01.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_02/02.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_02/03.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_02/04.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p style=&#34;margin-left: 2em; margin-top: -1em&#34;&gt;ModelÔºö&lt;a href=&#34;https://civitai.com/models/4468/counterfeit-v30&#34;&gt;Counterfeit V3.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_03/01.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_03/02.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_03/03.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_03/04.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p style=&#34;margin-left: 2em; margin-top: -1em&#34;&gt;ModelÔºö&lt;a href=&#34;https://civitai.com/models/4201/realistic-vision-v20&#34;&gt;Realistic Vision V2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_04/01.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_04/02.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_04/03.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_04/04.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p style=&#34;margin-left: 2em; margin-top: -1em&#34;&gt;ModelÔºö &lt;a href=&#34;https://civitai.com/models/43331/majicmix-realistic&#34;&gt;majicMIX Realistic&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_05/01.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_05/02.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_05/03.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_05/04.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p style=&#34;margin-left: 2em; margin-top: -1em&#34;&gt;ModelÔºö&lt;a href=&#34;https://civitai.com/models/66347/rcnz-cartoon-3d&#34;&gt;RCNZ Cartoon&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_06/01.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_06/02.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_06/03.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_06/04.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p style=&#34;margin-left: 2em; margin-top: -1em&#34;&gt;ModelÔºö&lt;a href=&#34;https://civitai.com/models/33208/filmgirl-film-grain-lora-and-loha&#34;&gt;FilmVelvia&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Community Cases&lt;/h4&gt; &#xA;&lt;p&gt;Here are some samples contributed by the community artists. Create a Pull Request if you would like to show your results hereüòö.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_07/init.jpg&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_07/01.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_07/02.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_07/03.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_07/04.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p style=&#34;margin-left: 2em; margin-top: -1em&#34;&gt; Character ModelÔºö&lt;a href=&#34;https://civitai.com/models/13237/genshen-impact-yoimiya&#34;&gt;Yoimiya&lt;/a&gt; (with an initial reference image, see &lt;a href=&#34;https://github.com/talesofai/AnimateDiff&#34;&gt;WIP fork&lt;/a&gt; for the extended implementation.) &lt;/p&gt;&#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_08/01.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_08/02.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_08/03.gif&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/guoyww/AnimateDiff/main/__assets__/animations/model_08/04.gif&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p style=&#34;margin-left: 2em; margin-top: -1em&#34;&gt; Character ModelÔºö&lt;a href=&#34;https://civitai.com/models/9850/paimon-genshin-impact&#34;&gt;Paimon&lt;/a&gt;; Pose ModelÔºö&lt;a href=&#34;https://civitai.com/models/107295/or-holdingsign&#34;&gt;Hold Sign&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;BibTeX&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{guo2023animatediff,&#xA;  title={AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning},&#xA;  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Wang, Yaohui and Qiao, Yu and Lin, Dahua and Dai, Bo},&#xA;  journal={arXiv preprint arXiv:2307.04725},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contact Us&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Yuwei Guo&lt;/strong&gt;: &lt;a href=&#34;mailto:guoyuwei@pjlab.org.cn&#34;&gt;guoyuwei@pjlab.org.cn&lt;/a&gt;&lt;br&gt; &lt;strong&gt;Ceyuan Yang&lt;/strong&gt;: &lt;a href=&#34;mailto:yangceyuan@pjlab.org.cn&#34;&gt;yangceyuan@pjlab.org.cn&lt;/a&gt;&lt;br&gt; &lt;strong&gt;Bo Dai&lt;/strong&gt;: &lt;a href=&#34;mailto:daibo@pjlab.org.cn&#34;&gt;daibo@pjlab.org.cn&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;Codebase built upon &lt;a href=&#34;https://github.com/showlab/Tune-A-Video&#34;&gt;Tune-a-Video&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>